Proceedings of the ACL-HLT 2011 Student Session, pages 75?80,Portland, OR, USA 19-24 June 2011. c?2011 Association for Computational LinguisticsTowards a Framework forAbstractive Summarization of Multimodal DocumentsCharles F. GreenbackerDept.
of Computer & Information SciencesUniversity of DelawareNewark, Delaware, USAcharlieg@cis.udel.eduAbstractWe propose a framework for generating an ab-stractive summary from a semantic model of amultimodal document.
We discuss the type ofmodel required, the means by which it can beconstructed, how the content of the model israted and selected, and the method of realizingnovel sentences for the summary.
To this end,we introduce a metric called information den-sity used for gauging the importance of con-tent obtained from text and graphical sources.1 IntroductionThe automatic summarization of text is a promi-nent task in the field of natural language processing(NLP).
While significant achievements have beenmade using statistical analysis and sentence extrac-tion, ?true abstractive summarization remains a re-searcher?s dream?
(Radev et al, 2002).
Althoughexisting systems produce high-quality summaries ofrelatively simple articles, there are limitations as tothe types of documents these systems can handle.One such limitation is the summarization of mul-timodal documents: no existing system is able to in-corporate the non-text portions of a document (e.g.,information graphics, images) into the overall sum-mary.
Carberry et al (2006) showed that the con-tent of information graphics is often not repeatedin the article?s text, meaning important informationmay be overlooked if the graphical content is not in-cluded in the summary.
Systems that perform statis-tical analysis of text and extract sentences from theoriginal article to assemble a summary cannot accessthe information contained in non-text components,let alne seamlessly combine that information withthe extracted text.
The problem is that informationfrom the text and graphical components can only beintegrated at the conceptual level, necessitating a se-mantic understanding of the underlying concepts.Our proposed framework enables the genera-tion of abstractive summaries from unified semanticmodels, regardless of the original format of the in-formation sources.
We contend that this frameworkis more akin to the human process of conceptual in-tegration and regeneration in writing an abstract, ascompared to the traditional NLP techniques of rat-ing and extracting sentences to form a summary.Furthermore, this approach enables us to generatesummary sentences about the information collectedfrom graphical formats, for which there are no sen-tences available for extraction, and helps avoid theissues of coherence and ambiguity that tend to affectextraction-based summaries (Nenkova, 2006).2 Related WorkSummarization is generally seen as a two-phase pro-cess: identifying the important elements of the doc-ument, and then using those elements to constructa summary.
Most work in this area has focused onextractive summarization, assembling the summaryfrom sentences representing the information in adocument (Kupiec et al, 1995).
Statistical methodsare often employed to find key words and phrases(Witbrock and Mittal, 1999).
Discourse structure(Marcu, 1997) also helps indicate the most impor-tant sentences.
Various machine learning techniqueshave been applied (Aone et al, 1999; Lin, 1999), aswell as approaches combining surface, content, rel-75evance and event features (Wong et al, 2008).However, a few efforts have been directed to-wards abstractive summaries, including the modifi-cation (i.e., editing and rewriting) of extracted sen-tences (Jing and McKeown, 1999) and the genera-tion of novel sentences based on a deeper under-standing of the concepts being described.
Lexicalchains, which capture relationships between relatedterms in a document, have shown promise as an in-termediate representation for producing summaries(Barzilay and Elhadad, 1997).
Our work shares sim-ilarities with the knowledge-based text condensationmodel of Reimer and Hahn (1988), as well as withRau et al (1989), who developed an information ex-traction approach for conceptual information sum-marization.
While we also build a conceptual model,we believe our method of construction will producea richer representation.
Moreover, Reimer and Hahndid not actually produce a natural language sum-mary, but rather a condensed text graph.Efforts towards the summarization of multimodaldocuments have included na?
?ve approaches relyingon image captions and direct references to the im-age in the text (Bhatia et al, 2009), while content-based image analysis and NLP techniques are beingcombined for multimodal document indexing andretrieval in the medical domain (Ne?ve?ol et al, 2009).3 MethodOur method consists of the following steps: buildingthe semantic model, rating the informational con-tent, and generating a summary.
We construct thesemantic model in a knowledge representation basedon typed, structured objects organized under a foun-dational ontology (McDonald, 2000).
To analyze thetext, we use Sparser,1 a linguistically-sound, phrasestructure-based chart parser with an extensive andextendible semantic grammar (McDonald, 1992).For the purposes of this proposal, we assume a rela-tively complete semantic grammar exists for the do-main of documents to be summarized.
In the proto-type implementation (currently in progress), we aremanually extending an existing grammar on an as-needed basis, with plans for large-scale learning ofnew rules and ontology definitions as future work.Projects like the Never-Ending Language Learner1https://github.com/charlieg/Sparser(Carlson et al, 2010) may enable us to induce theseresources automatically.Although our framework is general enough tocover any image type, as well as other modalities(e.g., audio, video), since image understanding re-search has not yet developed tools capable of ex-tracting semantic content from every possible im-age, we must restrict our focus to a limited class ofimages for the prototype implementation.
Informa-tion graphics, such as bar charts and line graphs, arecommonly found in popular media (e.g., magazines,newspapers) accompanying article text.
To integratethis graphical content, we use the SIGHT system(Demir et al, 2010b) which identifies the intendedmessage of a bar chart or line graph along with othersalient propositions conveyed by the graphic.
Ex-tending the prototype to incorporate other modalitieswould not entail a significant change to the frame-work.
However, it would require adding a modulecapable of mapping the particular modality to its un-derlying message-level semantic content.The next sections provide detail regarding thesteps of our method, which will be illustrated ona short article from the May 29, 2006 edition ofBusinessweek magazine entitled, ?Will Medtronic?sPulse Quicken?
?2 This particular article was chosendue to good coverage in the existing Sparser gram-mar for the business news domain, and because it ap-pears in the corpus of multimodal documents madeavailable by the SIGHT project.3.1 Semantic ModelingFigure 1 shows a high-level (low-detail) overviewof the type of semantic model we can build usingSparser and SIGHT.
This particular example mod-els the article text (including title) and line graphfrom the Medtronic article.
Each box representsan individual concept recognized in the document.Lines connecting boxes correspond to relationshipsbetween concepts.
In the interest of space, the in-dividual attributes of the model entries have beenomitted from this diagram, but are available in Fig-ure 2, which zooms into a fragment of the modelshowing the concepts that are eventually rated mostsalient (Section 3.2) and selected for inclusion in2Available at http://www.businessweek.com/magazine/content/06_22/b3986120.htm.76Company1StockPriceChange1Idiom1BeatForecast1EarningsForecast1EarningsReport1Group2Prediction2MakeAnnouncement1AmountPerShare1AmountPerShare2WhQuestion1Group3Comparison3RevenuePct1Market2RevenuePct1 Company3Comparison1GrowthSlowed1Market1MissForecast1SalesForecast1Comparison2 CounterArgument1MarketFluctuations1 Protected1EarningsForecast2AmountPerShare3EarningsForecast3AmountPerShare4SalesForecast2SalesForecast3StockOwnership1Company4EmployedAt1EarningsGrowth1Prediction4Prediction3Person2GainMarketShare1StockRating2HistoricLow1Group1Prediction1Person1EmployedAt1Company2StockRating1TargetStockPrice1AmountPerShare2StockPriceChange3StockPriceChange2LineGraph1Volatile1ChangeTrend1AmountPerShare5AmountPerShare6AmountPerShare7Figure 1: High-level overview of semantic model for Medtronic article.the summary (Section 3.3).
The top portion of eachbox in Figure 2 indicates the name of the conceptualcategory (with a number to distinguish between in-stances), the middle portion shows various attributesof the concept with their values, and the bottom por-tion contains some of the original phrasings fromthe text that were used to express these concepts(formally stored as a synchronous TAG) (McDon-ald and Greenbacker, 2010)).
Attribute values in an-gle brackets (<>) are references to other concepts,hash symbols (#) refer to a concept or category thathas not been instantiated in the current model, andeach expression is preceded by a sentence tag (e.g.,?P1S4?
stands for ?paragraph 1, sentence 4?
).P1S1: "medical devicegiant Medtronic"P1S5: "Medtronic"Name: "Medtronic"Stock: "MDT"Industry: (#pacemakers,#defibrillators,#medical devices)Company1P1S4: "Investment firmHarris Nesbitt'sJoanne Wuensch"P1S7: "Wuensch"FirstName: "Joanne"LastName: "Wuensch"Person1P1S4: "a 12-monthtarget of 62"Person: <Person 1>Company: <Company 1>Price: $62.00Horizon: #12_monthsTargetStockPrice1Figure 2: Detail of Figure 1 showing concepts rated mostimportant and selected for inclusion in the summary.As illustrated in this example, concepts conveyedby the graphics in the document can also be includedin the semantic model.
The overall intended mes-sage (ChangeTrend1) and additional propositions(Volatile1, StockPriceChange3, etc.)
that SIGHTextracts from the line graph and deems importantare added to the model produced by Sparser by sim-ply inserting new concepts, filling slots for existingconcepts, and creating new connections.
This way,information gathered from both text and graphicalsources can be integrated at the conceptual level re-gardless of the format of the source.3.2 Rating ContentOnce document analysis is complete and the seman-tic model has been built, we must determine whichconcepts conveyed by the document and capturedin the model are most salient.
Intuitively, the con-cepts containing the most information and havingthe most connections to other important concepts inthe model are those we?d like to convey in the sum-mary.
We propose the use of an information den-sity metric (ID) which rates a concept?s importancebased on a number of factors:3?
Completeness of attributes: the concept?sfilled-in slots (f ) vs. its total slots (s) [?satura-tion level?
], and the importance of the concepts(ci) filling these slots [a recursive value]:fs ?
log(s) ?
?fi=1 ID(ci)3The first three factors are similar to the dominant slotfillers, connectivity patterns, and frequency criteria describedby Reimer and Hahn (1988).77?
Number of connections/relationships (n) withother concepts (cj), and the importance of theseconnected concepts [a recursive value]:?nj=1 ID(cj)?
Number of expressions (e) realizing the con-cept in the current document?
Prominence based on document and rhetoricalstructure (WD & WR), and salience assessedby the graph understanding system (WG)Saturation refers to the level of completeness withwhich the knowledge base entry for a given conceptis ?filled-out?
by information obtained from the doc-ument.
As information is collected about a concept,the corresponding slots in its concept model entryare assigned values.
The more slots that are filled,the more we know about a given instance of a con-cept.
When all slots are filled, the model entry forthat concept is ?complete,?
at least as far as the on-tological definition of the concept category is con-cerned.
As saturation level is sensitive to the amountof detail in the ontology definition, this factor mustbe normalized by the number of attribute slots in itsdefinition, thus log(s) above.In Figure 3 we can see an example of relativesaturation level by comparing the attribute slots forCompany2 with that of Company1 in Figure 2.Since the ?Stock?
slot is filled for Medtronic andremains empty for Harris Nesbitt, we say that theconcept for Company1 is more saturated (i.e., morecomplete) than that of Company2.P1S4: "Investment firmHarris Nesbitt"Name: "Harris Nesbitt"Stock:Industry: (#investments)Company2Figure 3: Detail of Figure 1 showing example conceptwith unfilled attribute slot.Document and rhetorical structure (WD and WR)take into account the location of a concept withina document (e.g., mentioned in the title) and theuse of devices highlighting particular concepts (e.g.,juxtaposition) in computing the overall ID score.For the intended message and informational proposi-tions conveyed by the graphics, the weights assignedby SIGHT are incorporated into ID as WG.After computing the ID of each concept, we willapply Demir?s (2010a) graph-based ranking algo-rithm to select items for the summary.
This algo-rithm is based on PageRank (Page et al, 1999), butwith several changes.
Beyond centrality assessmentbased on relationships between concepts, it also in-corporates apriori importance nodes that enable usto capture concept completeness, number of expres-sions, and document and rhetorical structure.
Moreimportantly from a generation perspective, Demir?salgorithm iteratively selects concepts one at a time,re-ranking the remaining items by increasing theweight of related concepts and discounting redun-dant ones.
Thus, we favor concepts that ought to beconveyed together while avoiding redundancy.3.3 Generating a SummaryAfter we determine which concepts are most im-portant as scored by ID, the next step is to de-cide what to say about them and express these el-ements as sentences.
Following the generation tech-nique of McDonald and Greenbacker (2010), the ex-pressions observed by the parser and stored in themodel are used as the ?raw material?
for express-ing the concepts and relationships.
The two mostimportant concepts as rated in the semantic modelbuilt from the Medtronic article would be Company1(?Medtronic?)
and Person1 (?Joanne Wuensch,?
astock analyst).
To generate a single summary sen-tence for this document, we should try to find someway of expressing these concepts together using theavailable phrasings.
Since there is no direct linkbetween these two concepts in the model (see Fig-ure 1), none of the collected phrasings can expressboth concepts at the same time.
Instead, we need tofind a third concept that provides a semantic link be-tween Company1 and Person1.
If multiple optionsare available, deciding which linking concept to usebecomes a microplanning problem, with the choicedepending on linguistic constraints and the relativeimportance of the applicable linking concepts.In this example, a reasonable selection would beTargetStockPrice1 (see Figure 1).
Combining orig-inal phrasings from all three concepts (via substi-tution and adjunction operations on the underlyingTAG trees), along with a ?built-in?
realization inher-ited by the TargetStockPrice category (a subtype ofExpectation ?
not shown in the figure), produces a78construction resulting in this final surface form:Wuensch expects a 12-month target of 62for medical device giant Medtronic.Thus, we generate novel sentences, albeit with some?recycled?
expressions, to form an abstractive sum-mary of the original document.Studies have shown that nearly 80% of human-written summary sentences are produced by a cut-and-paste technique of reusing original sentencesand editing them together in novel ways (Jing andMcKeown, 1999).
By reusing selected short phrases(?cutting?)
coupled together with generalized con-structions (?pasting?
), we can generate abstractssimilar to human-written summaries.The set of available expressions is augmentedwith numerous built-in schemas for realizing com-mon relationships such as ?is-a?
and ?has-a,?
aswell as realizations inherited from other concep-tual categories in the hierarchy.
If the knowledgebase persists between documents, storing the ob-served expressions and making them available forlater use when realizing concepts in the same cat-egory, the variety of utterances we can generate isincreased.
With a sufficiently rich set of expres-sions, the reliance on straightforward ?recycling?
isreduced while the amount of paraphrasing and trans-formation is increased, resulting in greater noveltyof production.
By using ongoing parser observationsto support the generation process, the more the sys-tem ?reads,?
the better it ?writes.
?4 EvaluationAs an intermediate evaluation, we will rate the con-cepts stored in a model built only from text and usethis rating to select sentences containing these con-cepts from the original document.
These sentenceswill be compared to another set chosen by traditionalextraction methods.
Human judges will be askedto determine which set of sentences best capturesthe most important concepts in the document.
This?checkpoint?
will allow us to assess how well oursystem identifies the most salient concepts in a text.The summaries ultimately generated as final out-put by our prototype system will be evaluatedagainst summaries written by human authors, aswell as summaries created by extraction-based sys-tems and a baseline of selecting the first few sen-tences.
For each comparison, participants will beasked to indicate a preference for one summaryover another.
We propose to use preference-strengthjudgment experiments testing multiple dimensionsof preference (e.g., accuracy, clarity, completeness).Compared to traditional rating scales, this alterna-tive paradigm has been shown to result in betterevaluator self-consistency and high inter-evaluatoragreement (Belz and Kow, 2010).
This allows alarger proportion of observed variations to be ac-counted for by the characteristics of systems under-going evaluation, and can result in a greater numberof significant differences being discovered.Automatic evaluation, though desirable, is likelyunfeasible.
As human-written summaries have onlyabout 60% agreement (Radev et al, 2002), there isno ?gold standard?
to compare our output against.5 DiscussionThe work proposed herein aims to advance the state-of-the-art in automatic summarization by offering ameans of generating abstractive summaries from asemantic model built from the original article.
Byincorporating concepts obtained from non-text com-ponents (e.g., information graphics) into the seman-tic model, we can produce unified summaries ofmultimodal documents, resulting in an abstract cov-ering the entire document, rather than one that ig-nores potentially important graphical content.AcknowledgmentsThis work was funded in part by the National Insti-tute on Disability and Rehabilitation Research (grant#H133G080047).
The author also wishes to thankKathleen McCoy, Sandra Carberry, and David Mc-Donald for their collaborative support.ReferencesChinatsu Aone, Mary E. Okurowski, James Gorlinsky,and Bjornar Larsen.
1999.
A Trainable Summarizerwith Knowledge Acquired from Robust NLP Tech-niques.
In Inderjeet Mani and Mark T. Maybury, edi-tors, Advances in Automated Text Summarization.
MITPress.Regina Barzilay and Michael Elhadad.
1997.
Using lex-ical chains for text summarization.
In In Proceedings79of the ACL Workshop on Intelligent Scalable Text Sum-marization, pages 10?17, Madrid, July.
ACL.Anja Belz and Eric Kow.
2010.
Comparing ratingscales and preference judgements in language evalu-ation.
In Proceedings of the 6th International NaturalLanguage Generation Conference, INLG 2010, pages7?16, Trim, Ireland, July.
ACL.Sumit Bhatia, Shibamouli Lahiri, and Prasenjit Mitra.2009.
Generating synopses for document-elementsearch.
In Proceeding of the 18th ACM Conferenceon Information and Knowledge Management, CIKM?09, pages 2003?2006, Hong Kong, November.
ACM.Sandra Carberry, Stephanie Elzer, and Seniz Demir.2006.
Information graphics: an untapped resource fordigital libraries.
In Proceedings of the 29th AnnualInternational ACM SIGIR Conference on Researchand Development in Information Retrieval, SIGIR ?06,pages 581?588, Seattle, August.
ACM.Andrew Carlson, Justin Betteridge, Bryan Kisiel, BurrSettles, Estevam R. Hruschka Jr., and Tom M.Mitchell.
2010.
Toward an architecture for never-ending language learning.
In Proceedings of the 24thConference on Artificial Intelligence (AAAI 2010),pages 1306?1313, Atlanta, July.
AAAI.Seniz Demir, Sandra Carberry, and Kathleen F. Mc-Coy.
2010a.
A discourse-aware graph-based content-selection framework.
In Proceedings of the 6th In-ternational Natural Language Generation Conference,INLG 2010, pages 17?26, Trim, Ireland, July.
ACL.Seniz Demir, David Oliver, Edward Schwartz, StephanieElzer, Sandra Carberry, and Kathleen F. McCoy.2010b.
Interactive SIGHT into information graphics.In Proceedings of the 2010 International Cross Dis-ciplinary Conference on Web Accessibility, W4A ?10,pages 16:1?16:10, Raleigh, NC, April.
ACM.Hongyan Jing and Kathleen R. McKeown.
1999.
Thedecomposition of human-written summary sentences.In Proceedings of the 22nd Annual International ACMSIGIR Conference on Research and Development inInformation Retrieval, SIGIR ?99, pages 129?136,Berkeley, August.
ACM.Julian Kupiec, Jan Pedersen, and Francine Chen.
1995.A trainable document summarizer.
In Proceedingsof the 18th Annual International ACM SIGIR Confer-ence on Research and Development in Information Re-trieval, SIGIR ?95, pages 68?73, Seattle, July.
ACM.Chin-Yew Lin.
1999.
Training a selection function forextraction.
In Proceedings of the 8th InternationalConference on Information and Knowledge Manage-ment, CIKM ?99, pages 55?62, Kansas City, Novem-ber.
ACM.Daniel C. Marcu.
1997.
The Rhetorical Parsing, Summa-rization, and Generation of Natural Language Texts.Ph.D.
thesis, University of Toronto, December.David D. McDonald and Charles F. Greenbacker.
2010.?If you?ve heard it, you can say it?
- towards an ac-count of expressibility.
In Proceedings of the 6th In-ternational Natural Language Generation Conference,INLG 2010, pages 185?190, Trim, Ireland, July.
ACL.David D. McDonald.
1992.
An efficient chart-basedalgorithm for partial-parsing of unrestricted texts.
InProceedings of the 3rd Conference on Applied NaturalLanguage Processing, pages 193?200, Trento, March.ACL.David D. McDonald.
2000.
Issues in the repre-sentation of real texts: the design of KRISP.
InLucja M. Iwan?ska and Stuart C. Shapiro, editors, Nat-ural Language Processing and Knowledge Represen-tation, pages 77?110.
MIT Press, Cambridge, MA.Ani Nenkova.
2006.
Understanding the process of multi-document summarization: content selection, rewriteand evaluation.
Ph.D. thesis, Columbia University,January.Aure?lie Ne?ve?ol, Thomas M. Deserno, Ste?fan J. Darmoni,Mark Oliver Gu?ld, and Alan R. Aronson.
2009.
Nat-ural language processing versus content-based imageanalysis for medical document retrieval.
Journal of theAmerican Society for Information Science and Tech-nology, 60(1):123?134.Lawrence Page, Sergey Brin, Rajeev Motwani, and TerryWinograd.
1999.
The pagerank citation ranking:Bringing order to the web.
Technical Report 1999-66, Stanford InfoLab, November.
Previous number:SIDL-WP-1999-0120.Dragomir R. Radev, Eduard Hovy, and Kathleen McKe-own.
2002.
Introduction to the special issue on sum-marization.
Computational Linguistics, 28(4):399?408.Lisa F. Rau, Paul S. Jacobs, and Uri Zernik.
1989.
In-formation extraction and text summarization using lin-guistic knowledge acquisition.
Information Process-ing & Management, 25(4):419 ?
428.Ulrich Reimer and Udo Hahn.
1988.
Text condensationas knowledge base abstraction.
In Proceedings of the4th Conference on Artificial Intelligence Applications,CAIA ?88, pages 338?344, San Diego, March.
IEEE.Michael J. Witbrock and Vibhu O. Mittal.
1999.
Ultra-summarization: a statistical approach to generatinghighly condensed non-extractive summaries.
In Pro-ceedings of the 22nd Annual International ACM SIGIRConference on Research and Development in Informa-tion Retrieval, SIGIR ?99, pages 315?316, Berkeley,August.
ACM.Kam-Fai Wong, Mingli Wu, and Wenjie Li.
2008.Extractive summarization using supervised and semi-supervised learning.
In Proceedings of the 22nd Int?lConference on Computational Linguistics, COLING?08, pages 985?992, Manchester, August.
ACL.80
