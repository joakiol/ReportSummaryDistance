DIASUMM: Flexible Summarizat ion ofSpontaneous Dialogues in Unrestricted DomainsKlaus Zechner and Alex WaibelLaJlguage 'l~chnologies InstituteCarnegie Mellon University5000 Forbes AvenuePittsbm:gh, PA 115213, USA{zechner., waibel}@cs, cmu.
eduAbstractIn this paper, we present a summa.rization systemfor spontaneous dialogues which consists of a novelmulti-stage architectm'e.
It is specifically aimed ataddressing issues related to tlle nature of the l;extsbeing spoken vs. written and being diMogical vs.monologica.l.
The system is embedded in a. graph-ical user interface ~md was developed and tested ontranscripts of recorded telephone conversations inEnglish and Spanish (CAI,LHOMI,;).1 Introduct ionSumma.rization of written docmnents has recentlyO' been a. focus for much research in NI,t ~ ( ~.o., (Maniand 1Vlasq~ury , 1997; AAAI, 1998; Mani el.
al., 1998;ACL, 2000), to nanle some of tile Inajol: events inthis field ill the past few years).
Ilowever, very lit-tle a.ttention has been given so far to the summa-riza.tion of spol, r('~n language, even less of conversa-lions vs. monologic'al texts.
We believe tha.t sum-mariza.tion of speech will bccoJne increasingly moreimportant, a.s the ~ml(mnt of online audio daLa.
growsand demand for r~tl)id browsing, skimming, a.nd a.e-cess of speech data increases.
Another applicationwhich particulm:ly pertains to our interest in spo--ken dialogue summarization would be the generationof meeting minutes for archival purposes a.nd/or toupdate l)a.rticil)a.nts .joining a.t la.ter stages on qm'progress of the conversa.tion so far.Sunmmrization of dialogues within l imilcd do-mains ha.s been attempted within the context ofthe VERBMOBII, pl:ojcct ("protocol generation",(Alexandersson and Poller, 1998)) or by SRI's MIMIsummarizer (Kameyama et ~d., 1996).
l{ecent workon spoken language summarization i unrestricteddomains has focused ahnost exclusively on Broad-cast News, mostly due to the spoken hmguage trackof recent TREC evaluations (Oarofolo et al, 1997;Garotblo et al, 1999).
(Waibel et a.1., 1(.
)98) describea Meeting Browser where summaries earl be gener-ated using technology established for written texts.(Va.lenza.
el.
M., 1999) go one step further and incofpora.te knowledge from the speech recognizer (con-fidence scores) into their summarization system, aswell.We a.rgue that the nature of spoken dialogues, to-gether with their textual representations a speechrecognizer hypotheses, requires a. set of specific al>proa.ches to make summarization feasible for thistext genre.As a demonstrable proof of concept, we presentthe multi-stage a.rchitecture of the summa.rizationsystem I)IASUMM which can flexibly deal with spo-ken di,dogues in English and Spa.nish, without anyrestrictions of domahl.
Since it cannot rely on a.nydomain specific knowledge base, it uses shallow sta-tisticaJ approaches and presents (possibly modified)ca:lracts from the original text.
as summa.ry.We.
present results of several evaluations of oursystem using human transcripts of spontaneous tele-phone conversations in English and Spanish from the(~,AI,LIIOME corl)/ls ((LI)C), 1996), in particular theaccura.cy of the topic segmentation and in\[brmat.ioncondensing components (sections (5 and 7).
Also, IbrI.he purpose of a global evaluation, a user study wasl~ei:%i:med which a.ddresscd in\[or\]nation access t.inJea.nd a.ccura.ey of retaine.d information eompa.ring dif-ferent versions of summaries (section 10).This paper is organized as follows: In the next sec-tion, we provide, a.n ow;rview a.bout t}ie in,till issuesIbr summa.rization of Sl)oken dialogues and indicateI;hc "~l)l)roaches we, are taking in our system.
Wethen present he system a.rchitecture (section 3), fol-lowed by a. detailed description of the readier buildingblocks (sections <1 to 8).
After a. brief elmra.cteriza-tion of the (2 UI (section 9) we describe a user studyfor global system evaluation in section 10.
We con-clude the pa.per with a smmnary and a brief outlookin section 11.2 Issues and Approaches: OverviewIn this section, we give a,n overview about the mainissues that a.ny sunmmrizat;ion system for spoken di-a.logues has to address mid indica.te the approach weare taking for each of these in I)IASUMM.In a generM sense, when dealing with writtentexts, usually there is plenty of information avail-able which can be used lbr the purpose of summa-968rization, such as capitalization, i)un(-tuation ~narks,t,itles, passage head(rs, i)aragral)h boundaries, orother ,nark-ul)S. (hfforl.mud.ely, however, ,,onc (.
)fthis holds for :q)ccch data whh:h arrives as a streamof word l,ok('w; from ;I recognizer, (:ut iuto "utt(.q'-antes" by using a silence heuristi('.2.1.
Lack of  clause.
1)OulldariesOne of the mosl.
serious issues is the lack el senten(:eor clause boundaries in spoken dialogues whi(:h ixparticularly problemati(: .
;in(:e scnten(:es, clauses, orl)aragral)hs a.re (.
:onsidercd the "minimal re,its" invirtually all existil,g summarizat ion systcu,s.
\'Vheuhumans speak, they so,lletillles pause durinq a(:\]a.use, and not always at.
l.he eml of a claus(', whi(:hmeans that the outl)ut of a r(;coguizer (whi(:h us,t-ally uses some silelme-heuristics to cut the segments)frequently does nol real,eli Iogi(:al sep, l,en(:e or clauseboundaries, l,ooking at five I';nglish (~A,,I,HOM,,: (li-alogues with an average ii/11111)(".1' of :{20 iltl\[.
('3'a,l('.c~.qeat.h, we find on average 30 such "(:ontinuations" oflogical clauses over automa.ti(:ally detcrmiued a(:ous-tit" segment I)ounda.ries.
lu a smmnary,  this cancause a. r(;du(:tion in coh(,,ren(:c and r<~dability ofthe outlmt.We address this issue I)y linking adjac(;nt tm'nsof th(; smue sl)eaker together if the silence betweenthem ix less than a given col,sl.\[/llt (se(;tioll d).2.2 Distr i lml ;c .d int ' (n 'mat io l lSiuce we have multi-pari,y conversations as o\])l)oscdto Inonologi('al texts, sonmtimcs the cru(:ial in\['or-matiou is found in a question-auswer-l)air , i.e., itinvolv('s more than oue Sl)eaker; extracting ouly thequestion or only the auswer wo,ld be meaninglessin ma.ny cases.
We found that on average about10% el' the speaker turns belong to such question-answer l)airs in five examined English (~AIA,IIOMEdialogues.
Often, either the question or the answerix very shoI:t and does not contain any words withhigh relevan(:c. In order not to "lose" these shorttutus at a later stage, when only the n~ost, relevantturns are extracted, we link them to the matchingquestion/answer ahead of/.
ime, using two differentmethods to detect questions aud their answers (sec-tion 4).2.3 D is t luent  speechSpeech disfluencies in spontaneous convers,ttions - -such as fillers, repetitions, repairs, or unfinishedclauses -- can make transcril)ts (and summary  ex-tracts) quite ha.rd to read and also introduce all tin-wanted bias to relevance computat ions (e.g., wordrepetitions would cause a higher word count tbr therepeated content words; words in untinished clauseswould be included in the word count.
)'l'o alleviate this problem, we employ a clean-uptilter pipeline, which eliminates liller words and ,:el)-el.it.ions, and segments the tm'ns into short clauses(sectiou 5).
\Ve also remove incomplete clauses, typ-ically sentem:c-iuitial repairs, at this stage of our'.syst?lu.
This "clea.niug-up" serves two main pur-1)oscs: (i) it.
im:rea~cs tim readabilit3~ (for the fiually(;xtracl.cd segments); and (ii)it.
~nakcs the text moretractable by subsequent modules.The following exalnl)le com\])arcs a turn before andafter t.he clean-up component:before: I MEAN WE LOSE WE LOSE I CAN'T ICAN'T DO ANYTHING ABOUT IT SOafter: we lose / i can't do anythingabout it2.4 Lack of tel)i(" l)oundaries(;AI,I,IIOME s\])c'e(;h data is lll/llti-to\])ica\] I)tlt doesuot include mark<q) \['or pa.ragral)hs, nor al,y tolfie-inforlJ,ative headers.
Tyl)ically, we lind about 5 I0(.lilt'erent opics within a 10-mimd;e segment of a di--ah)gue, i.e., the.
topic changes about every 1 2 min-utes in these conversations.
To facilitate browsingand smHtlmrization, we thus have to discover topi-(:ally coherent, segl,lents automatical ly.
This is doneusing a TextTi l ing approach, adapted t'ron~ (l\]earst,\]997) (section (i).2.5 Speech.
reeog l f i zer  e r rorsImst but not least, we face t.he l)roblcm of iml)er-t'e(:t word a(:cura(:y of sl)eech recognizers, l)articu-larly when (h'.a~ling with Sl)OUl.a\]mous t)eech over alarge vo(:al)uhu'y aud over a low I);mdwi(Ith (:hamJe\],SIIC\]I \[~S l,h(~ (',AI,I,IIOME ({at;tl)asc's which we Juainlyused for develol)lnent , testing, and evaluatiou of oursyste/n.
(hu'r(mt recognizers tyl)ically exhibit worderror rates \['or l,hese (:orl)ora ill the order of 50%.
InI)IASUMM's hfl'ormation condensation component,the relevaucc weights of speaker ttlr,ls (:all be ad-justed to take into acc.omd, their word confidencescores from 1.111; sl)eech recognizer.
That  way we canreduce the likelihood of extra.eting passages with alarger amount of word lnisreeognitions (Zeclmer and\Vaibel, 201111).
lu this 1)aper, however, the focus willbe exclusively on results of our evaluations on hu-man generated transcripts.
No information from thespeech recognizer nor from the acoustic signal (otherthan inter-utterance pause durations) are used.
Weare aware that in particular prosodic informationmay be of help for tasks such as the detection ofsentence boundaries, speech acts, or topic bound-aries (l\]irschberg ~md Nakatani, 1998; Shriberg etal., 1998; Stolcke et al, 2000), but the investigationof the integration of this additional source of i n fermarion is beyond the scope of this pal)er and lel't tbrfuture work.3 System Arch i tec tureThe global system architecture of I)IASUMM is a1)ipeline of the tbllowing lbur major components:969inputtor \]CLEAN ~ Turn Linkingand TELE !i\] Clean-up Filter!I i\]Jinput fo r .
Topic SegmentationTRANSi lInformation Condensation ~ TRANSiL1 71-  - - - \]7 7 -  ~ CLEANTelegraphic Reduction TELEFignre 1: System architectureturn linking; clean-up filter; topic segmentation; andinformation condensation.
A. fifth component isadded a.t the end for the purpose of telegraphic re-duction, so that we can maximize the informationcontent in a given amount of space.
The system ar-chitecture is shown in Figure 1.
It also indicates thethree major types of smnmaries which can be gener-ated by l)Ia SUMM: 'P\]~ANS ("transcript"): not usingthe linking and clean-up components; CLEAN: ris-ing the main four components; 'I'EI,E ("telegraphic"summary): additionally, using the telegraphic reduc-tion component.The following sections describe the components ofDIASUMM ill more detail.4 Turn  L ink ingThe two main objectives of this component are: (i)to form turns which contain a set of full (and notpartial) clauses; and (ii) to forln turn-pairs in caseswhere we have a question-answer pair in the dia-logue.To achieve the first objective, we scan the input foradjacent turns of one speaker and link them togetherif their time-stamp distance is below a pre-specifiedthreshold 0.
If the threshold is too small, we don'tget most of the (logical) turn continuations acrossutterance boundaries, if it is too large, we run therisk of "skipping" over short but potentiMly relevantDaglnents of the speaker on the other channel.
Weexperimented with thresholds between 0.0 and 2.0seconds and determined a local performance maxi-mum around 0 = 1..0.For the second objective, to form turn-pairs whichcomprise a question-answer information exchangebetween two dialogue participants, we need to detectwh- and yes-uo-questions i  the dialogue.
We tested\] English \] SpanishAnnotated l)ataturns 1603 1185Wh-questions /12 78yes-no-questions /t3 98questions total 85 (5.3%) 176 (14.9%)Automatic Detection Results (F1)SA classifierPOS rulesraudom baseline0.24 0.220.22 0.370.02 0.13Tahle 1: Q-A-pair distribution in the data and ex-pel'imental results for automatic Q-A-detectiontwo approa.ches: (a) a I tMM based speech a.ct (SA)classifier (\]/Jes, \] 999) and (b) a set of part-of-speech(POS) based rules.
The SA classifier was trained olldialogues which were manually annotated for speechacts, using parts of the SWITCIIBOARI) corpus (God-frey et al, 1992) for Fmglish and CALLIIOMF, forSpanish.
The corresponding answers for the de-tected questions were hypothesized in the first turnwith a. different sl)eaker , following the question-turn.Table 1 shows the results of these experiments for 5English and 5 Spanish CAI,L\]IOME dialogues, corn-payed to a baseline of randomly assigning n questionspeech acts, n being the number of question-turnsmarked by human a.nnotal~ors.
We report Fl-seores,where F1 - ~ with P=preeision and /g--recall.We note that while the results \[br the SA-classifierand the rule-based approach are very similar for En-glish, the rule-based apl~roach yields better resultstbr Spanish.
The much higher random baseline forSpanish can be explained by the higher incidence ofquestions in the Spanish data (14.9?/(, vs. 5.3% forEnglish).5 C lean-up  F i l te rThe clean-up component is a sequence of moduleswhich serve the purposes of (a) rendering the tran-scripts more readable, (b) simplifying the input forsubsequent components, and (c) avoiding unwantedbias for relevance computations ( ee section 2).
Allthis has to happen without losing essential informa-tion that could be relevant in a summary.
Whileother work (\]\]eeman et al, 1996; Stolcke et al, 1998)was concerned with building classifiers that can de-tect and possibly correct wn:ious speech disfluencies,our implementntion is of a much simpler design.
Itdoes not require as much lnanual annota.ted train-ing data and uses individual components for everymajor category of disfluency.1t While we have not yet numerical ly evaluated the per fo fmance of this component,  its output  is deemed very natura l  toread by system users.
Since the focus and goals of this contpo-nent are somewhat  different han l)reviotts work in that  area,meaningful  compar isons are hard to make.970Single or multiple word repetitions, fillers (e.g.,"uhm"), and discourse markers without semanticcontent (e.g., "you know") a.re removed fl:om the in-put, some short forms axe expanded (e.g., "we'll"-+ "we will"), a.nd fl'cquent word sequences arecombined into a single token (e.g., % lot of" -+"a_lot_of").Longer tm'ns are segmented into shorl clauses,which are defined a.s consisting of at least a. sub-ject and a.n inIlectcd verbal form.
While (Stolckeand Shriberg, 1996) use n-gram models for this task,and (C~awald~t et al, 1997) use neura.l networks, wedecided to use a. rule-based approach (using worda,nd POS information), whose performa.nce provedto be compat'able with the results in the cited \])~-pets (1,'~ > 0.85, error < 0.05).
~leo, .
several of tile clea.n-up filter's components, weina.ke use of Brill's POS ta.gger (Ih:ill, I,(),qd).
ForFmglish, we use ~t modified version of Brilt's originalt~g set, and the tagger was adapted and retra.ined forSl)oken langua.ge orl)ora, (CAIAAIOME a.lKl SWITCll-tlOalU)) (Zechner, 1997).
For S1)anish, we crea.tedour own tag set., derived from the l,l)C lexicon andfront the CI{ATEI/.
project (LeOn, 1994), and trainedthe tagger on ma.nua.lly annotated (~;AI,I,IIOME dia-logues, l!
'urthernlore, a. POS based sha.lk)w chunkparser (Zechner a.nd Wa.ibel, 1998) is used to fill.('.,'(,tit.
likely ca.ndidates for incomplete, clauses dne tospeech repair or interrul)tion by the other Slleaker.6 Topic Segmentation,~illce CAI,I,IIOME dialogues are a.lways multi-topica.I,segmenting them into tOl)ical units is an important:;tel) in our summa.riza.tion system.
'.l'his allows usto l)rovi(le "signature?'
information (frcqllenl; coil-tent words) about every topic to the user as a. hell)for faster 1)rowsing and accessing the dat.a., l,'ur-thel:more, the subsequent informa.tio, condensationCOI\]l\])Ollent ca.ll ~,VolYk on smaller parts of the diaJoguea.nd thus opera.re more ellieiently.Following (l{oguraev and Ii{cnnedy, 1997; Ba.rzi-la.y and Elhadad, 1997) who use 'l'extTiling (llcarst,1997) for their summa.riza.tion systems of writtentext,  we adapted this algorithm (it.s block compar-ison version) R)r sl)eech data: we choose turns tobe minimal units a.nd compute block simila.rity be-tween l)locl(s of k turns every d turns.
We use 9English and 15 Spanish @ALI,tIOMI,; dialogues, man-ually annota.ted for topic bounda.ries, to determinethe optinmm wdues for a set of TextTiling pm:am-eters and ~t.
the same time to eva.lua.te the accu-racy of this algorithm.
'.re do this, we ran a.n n-R)ldcross-wdidation (".jack-l~nifing") where ~dl dia.loguesbut one are used to determine the 1)est parameters"train set") m,d the remaining dia.logue is used as2'\]'lie COIIIIIDA'isoII W~:tS (\[OllC OI1 t.he S~-tllle <latat set as  usedm (Gav;ddh ctal.
,  1997).English Spanishblocksize k 25 15sample distance d 2 2rounds of smoothing r 2 lsmoothing width s 2 \]'l.
'able 2: OptimM 'l>xt'.l.
'iling pa.rameters for Englishand Spanish CAI,IAIOME dialoguesnmnber of dbdoguesr~mdom baselinetest set avg.
(%nseen data")train set a~vg.
("seen dat?
')English Spanish9 150.34 0.350.58 0.530.69 0.58'l'~d)le 3: Topic segmenta.tion results for English andSpa.nish CAI,IAIOMI,: dialogues (Fl-Scores)a held-out d~ta.
set for eva.luation ("test set").
Thisprocess is rcpea.ted n times and average results arereported.
Ta.ble 2 shows the set of p~u:ameters whichworked best for most diak)gues ~md 'Fable 3 showstile eva.hm.tion results of the cross-validation exper-iment.
/,'~-scores improve I)y 18-2d% absohtte overthe random baseline for unseen a.nd by 23 35% forseen data., the performance for E\]@ish being betterthan for Spanish.
'l'hese results, albeit achieved ona.
quite different ext genre, are well in line with theresults in (llea.rst, 1997) who reports a.n absolute im-provement of a, bout :20% over a, random baseline forseen data.7 Information CondensationThe informa,tion condensa, tion COml)onent is the coreo\[' our sysl,en:~, lilts pUrl)OSe is to determine weightsfor terms and turns (or linked turn-i)airs ) and thento rank the turns a.ccording to their relewmce withineach topical segment of the dialogue.For term-weighting, lf*idf-insl)ired formula.e(Sa.lton and Buckley, 1990) are used to empha.sizewords which are in the "middle range" of fl:equencyin the dialogue a.nd do not a.pl)eat: in a. stop list.
:~For turn--ranking, we use a version of the "maximaln,argina.l relevance" (MMI{) algorithm (Ca.rbonelland Goldstein, 1998), where emphasis is given toliurns which conta.in ma.ny highly weighted terms tot"the current segment ("sa.lience") a.nd are sutficientlydissimila.r to previously ranked turns (to minimizeredunda.ncy).For 9 English and l d Spanish dialogues, the "mostrelevant" turns were nmrl~ed lay hmnan coders.
Weran a. series of cross-validation experiments o (a,) op-timize the parameters of this component related totJ'*idf a.nd MMR computa,tion and to (b) deterlnine31,'or l,;nglish, our stop list comprises 557 words, for Span-ish, 831 words.971how well this information condensing component canmatch tile human relewmce annotations.Summarization results are comlmted using 1 l-pt-avg precision scores t`or ranked turn lists where themaximum precision of the list of retrieved turnsis averaged in the 11 evenly spaced intervals be-tween recall=\[0,0.1),\[0.1,0.2), .
.
\[1.0,1.:1)(Saltonand McGill, 1.983).
4 Table 4 shows the results fromthese experiments.
Similar to other experiments inthe summarization literature (Ma.ni et a.l., 1998), wefind a wide performance variation across differenttexts.8 Telegraphic ReductionThe purpose of this component is to maximize infor-mation in a tixed amount of space.
We shorten theOUClmt of the summarizer to a "telegraphic style";that way, more inrorma.tion can be included in asummary of k words (02: n bytes).
Since we onlyuse shallow methods for textual analysis that donot generate a. dependency structure, we cannot usecomplex methods for text reduction as described,e.g., in (Jing, 2000).
Our method simply excludeswords occurring in the stop list fl:om the summary,except for some highly inforlnative words such as 'T'or  ~11ot ~ .9 User  In ter face  and  SystemPer fo r lnanceSince we want to enable interactive summarizationwhich a.llows ~ user to browse through a dialogueqnickly Co search for information he is interestedin, we have integrated our summarization systeminto a 3AVA-based graphical user interface ("Meet-ing Browser") (Bert et al, 2000).
This interface alsointegrates the output of a speech recognizer (Yu etal., 1.999), and can display a wide variety of infer1nation about a conversation, including speech acts,dialogue games, and emotions.For sumlnarization, the user can determine thesize of the summary and which topical segmentshe wants to have displayed.
Ite can also rocusthe summary on particular content words ("query-based summary")  or exclude words from considera-tion ("dynamic stop list expansion").Smmnarizing a 10 minute segment of a CALL-hOME dialogue with our system takes on average lessthan 30 seconds on a 167 MHz 320 MB Sun Ultralworkstation.S4 We are aware that  this annotat ion and evaluat ion schemeis far fl'om opt lmah it does neither reflect the fact that  turnsare not necessari ly the best units for extract ion or that  the11-pt-avg precision score is not optimal ly suited for the sum-mar izat ion task.
We thus have recently developed a newword-based method  for annotat ion  and evaluat ion of spon-taneous peech (Zechner, 2000).5The average was computed  over five English dialogues.10 Human Study1(1.1 Exper iment  Set;upIll order to ewduate the system as a. whole, we con-ducted a study with humans in the loop to 1)e able Cocolnpare three types of summaries (TITANS, CLEAN,TELE, see section 3) with the fllll original transcript.We address these two main questions in this study:(i) how fast can information be identified using dif-ferent types of summaries?
(ii) how accurately is theinformation preserved, comparing different types ofsummaries?We did not only ask the user "narrow" questionsfor a specific piece of information - -  along the linesof the Q-A-evaluation part.
of the SUMMAC confer-ence (Mani eC a.l., 1998) -- but also very "global",non-specific questions, tied Co a. parCicular (topical)segment of the dialogue.The experiment was conducted as follows: Sub-jeers were given 24 texts each, aceompa.nied by eithera generic question ("What is the topic of the discus-sion in this text segment?")
or three specitic ques-tions (e.g., "Which clothes did speaker A buy.'?
").The texts were drawn from five topical segmentseach rrom five English CAIAAIOME dialogues.
(; Theyhave four difl>rent formats: (a) fldl transcripts (i.e.,the transcript of the whole segment) (FULL); (b)summa.ry of the raw transcripts (without linking andclea.n--up) ('rll.aNS); (c) cleaned-up summary (usingall four major components of our  sys ten l )  (C,I,I,;AN);and (d) telegram suln21\]a, ry (der ived  r ron \ ]  (c),  us ingalso Cite Celegraphic reduct.ion component) (TI';LE).
'l'he texts or for,,,a.t,, (b), (c), a.nd (d) were gener-ated 1;o have the saaue length: 40% of (a), i.e., weuse a 60% reduction rate.
All these formats canbe accotnpanied by either a. generic or three speciticquestions: hence there are eight types of tasks foreach of the 24: texts.We divided the subjects in eight groups such thatno subject had to l)erform more than one task onthe same text and we distributed the different Casksevenly \['or each group.
Thus we cau make unbiasedcomparisons across texts and tasks.The answer accuracy vs. a pre-defined answer keywas manually assessed on a 6 point discrete scalebetween 0.0 and 1.0.10.2 ll,esults and DiscussionOf the 27 subjects taking part in this experiment,we included 24 subjects iu the evaluation; 3 sub-jects were excluded who were extreme outliers withrespect o average answer time or score (not within/* + -2sCddev).From the results in Table 5 we observe the fol-lowing trends with respect to answer accuracy andresponse time:SOne of the 25 segments  was set aside for demonst rat ionpurposes.972English Spanishnun+her of dialogues 9 14turns t)er dialogue ma.rked ;ts relevant I)y human coders 12% 25%I l-pt-a.vg precision (average over t.ol)i(:a.l segnlent.s) 0.45 0.5.0score variation between (liak)gues 0.2 0.49 0.15 0.8TM)Ie 4: Smmnarizat ion result;s for English and S1)anisll (I~AI,I,IIOMEI,'ornmt tra ns (:lea.n \] tele'\]'ime vs. A(:c. T in .
:  \] Ae(.
'l'ime \[ A( C. I T ime \[ Ac(generic (q = 72)specific (q = 216)L full T ime~ Ace.I 0._(,.
1D.
): s, -~ec .-%~ \[ 07739'l'M)le 5: Average a.nsw('r times (i,, sect a.nd a.ccuracy scores (\[0.0-1.0\]) over eight dilferent tasks (number ofsubjects=2d; q:=mmd)er of questions l)er task type).summary  l,ypegeneric / indicativespeci\[ic / informative\[ !
)/).s I    wci.,l \]Lr Ls 1 ?
t  .0' l 'able 6: Ilela.tive answer accuracies in % for dill'~,rentSl)l\]llll~/ri(~S* ge~w'ric questions ("indicative summarie,s", thetask being to identi\[y the topic o\[' a text): ThetWO c leaned u D StlllnFla,ries tool(  M)out, the sameLime to in;ocess I)ui.
had lower a eeura('y scoresthan tim v(;rsion directly u:dug the trans(:ril)l..* spcc~/ir quest.ions ("ilfl'orlnal.ive sunllllaries",the (.ask being Io lilM Sl)ecilie intLrllml ion in t\]l(~re?t): (I) The accuracy advant, age of the rawI,ranscripl, sun lmaries ('I'R, A NS) over  the c leal ledu\]) versions (CLlCAN) is only small (,oZ :;Latis-tica.lly signitieant: L:-0.748) 7.
(2) 'l'her(" is asui)eriority of the 'l'l,;lA,,-StllnlHary to t)o(;h otJmrkinds ('rFLI.
: is significa.nlJy more ;,iCCtllX/|l(2 (h~-/.llCLEAN \[()r 1) "~ 0.0~r)).l,'rom this w(; conjecture thai.
our methods for (:us-tomizaJ.ion of the summaries to spoken dialogues ismostly relewmt for inJ'ormativc, but llot so tUll(;hfor indi,:,tivc smmmu'ization.
We drink that el.hermethods, such as lists of signature l)hrases would l)en tor0 effective to use lbr the \]al;tcr \[mrl)ose.
'l)dtle 6 shows the answer accuracy for the threedifferent smmnary  tyl)es relative 1;o the accuracy oftile fldl transcripl, texts of l, he sa.me segmenl,s (':rela-tive ~mswer a.ccm:acy").
We, observe that; tit(: r('l~d;iveaccuracy reduction for all smnn\]aries i markedlylower than the reduction of tc'xt size: all sunmmrieswere reduced from the full transcripts l)y 60%,whereas tile answer a(:(:uracy only drops between 9%(TITANS) a,tld 24% (CI,EAN) l()l" the generic quest, ions,7111 \['DA;\[,, ill 2, of 5 dialogues.
I,\]m CI,I.1AN SIIllllllD, l'y scoresm:e higher tllall th<>se of the 'I'IIANS summaries.and between 20% ('rF, l,l~,) and 29% (CI,F, AN) fOl: thespeci\[ic questions.
This proves that our systeln isable to retain most of the relevant information intim summaries.As for average' answer times, we see a. ma.rked re-duction (3()0{,) of all sunmm.ries coulparcd to the fulltexts in l,hc .qcneric case; for the SlmCific ease, thet ime reduction is sonlewhat sma.ller (l 5% 25%).One shortcoming of the current, system is thai; itoper~d;es on turns (or \[;tlrll-pa.irs) as minimal units\['or extraction, tn \[Stture work, we will investigatepossil)ilities to reduce the minimal units ot7 extrac--l.ion l.o tim level of chmses or sent.<m<:es, wilhoul, givlike; Ul) the idea of linking cross-slxmker information.1 1 Summary  and  l g l tu re  Work\Ve have presented a sunmmrizat ion sysl,e~ for six)ken dialogues which is constructed to address keydifl)renees of spolcen vs. written langua.ge, dia.loguesvs.
monologues, and inul|.i-topical vs. mono-topicaltexts.
The system cleans up the input for speechdisfluencies, links t.urns together into coherent in-formation units, determines tOlfica.l segments, andextracts the most relevant pieces of informal, ion ina user-customiza.ble way.
I~;vahml,ions of major sys-tem (:Oral)Orients and of t.he systeJn as a. whole were1)erfornmd.
'l'hc results of a user sl, udy show thatwith a. sutmna ry size of d0%, between 71% and 911%of the inlbrma.tion of the fill\] text is ret.a.ined in thesummary,  depending on tile type of summary  andtim Lyl)('s of quest, ions being asked.\?c' are currently extending the system to be ableto ha.ndle different levels of granularity for extract;ion(clauses, sentences, turns), leurthermore, we plan toinvestigate the, integration of l)rosodic informationinto several (-onq)onents of our system.12 AcknowledgementsWe wa.nt, l,o tha.nk the almotators for their ell'errs aimKlaus Hies for providing l.he automatic speech a(:t973tagger.
We appreciate comments and suggestionst?om Alon Lavie, Marsal Gawtld~/, Jade Goldstein,Thomas MacCracken, and the &llonymotls l:eviewerson earlier drafts of this paper.This work was funded in part by the VEf{BMOBI1,project of the Federal Republic of Oerma,ny, ATR -Interpreting Telecommunications Research L~l)ora-tories of Japan, and the US l)epartment of l)efense.Re ferencesAAAI, editor.
1998.
Proceedin9s of the AAAI-98 SpringSymposium on Intelligent Te.vt Summarization, Stan\]ord,CA.ACL.
2000.
Proceedings of thc ANLP/NAACL-2000 Work-shop on Automatic Summarization, Seattle, WA, May.Jan Alexaudersson and Peter Poller.
1998.
Towards mul-tilingual protocol generation for spontaneous speech dia-logues.
In Proceedings of the INLG-98, Niagara-on-the-lahc, Canada, ilugust.f{cgina Barzilay and Michael Elhadad.
1997.
Using lexicalchains for text summarization.
In ilCL/EACL-97 Work-shop on Intelligent and Scalable Te.vt Summarization.Michael Bert, l{alph Gross, llua Yu, Xiaojin Zhu, Yue Pan,Jie Yang, and Alex Waibel.
2000.
Multimodal meetingtracker.
In Proceedings o\] the Conference on Content-Based Multimedia Information Access, IHAO-2000, Paris,l<7'ance, April.Braniinir Boguraev and Chrlstol)hcr I(cnnedy.
1997.Salience-based characterisation of text documents.
InA CID/EA CL- 97 Workshop on Intelligent and Scalable TextSummarization.Eric Brill.
1994.
Some advances in transforlnation-I)~ed partof speech tagging.
In Proceeedings o.f AAAI-9/~.Jaime Carbonell mid Jade Goldstein.
1998.
The use of MMR,diversity-based reranking for reordering docunlents andproducing summaries.
In Proceedings o.f the 21st ACM-SIGIJg International Co,florence on Research and Devel-opment in lnJormation ll.ctrieval, Melbour~;c, Australia.Johl\] S. Garofolo, Ellen M. Voorhees, Vincent M. Stanford,and l(aren Sparck .\]ones.
\]997.
TI{I\]C-6 1997 spoken doc-IllllellL retriewfl track overview and results.
In Proceed-in9s o.\[ the 1997 "17H?C-6 Conference, Gaithe'rsburg, MI),November, pages 83 -91.John S. Garofolo, Ellen M. Voorhees, Cedric G. P. Auzanne,and Vincent M. Stratford.
1999.
Spoken doculnent re-trieval: 1998 evaluation aud investigation of new inetrics.In Proceedings of the ESCA workshop: Accessing informa-tion in spoken audio, pages 1-7.
Camloridge, UK, April.Morsel Gawddh, Klaus Zechner, and Gregory Aist.
1997.Iligh perforlnauce s gnlentation f spontaneous speech us-ing part of speech and trigger word infornmtion.
In Pro-eeedin9 s of the 5th ANLP Conference, Washington DO,pages 12-15.J.
J. Godfrey, E. C. ltolliman, and J. Mcl)mfiel.
1992.SWITCttBOARD: telephone speech corpus for research middevelopment.
In Proceedings of the IUASSP-92, vohnne 1,pages 517-520.Martl A. IIearst.
1997.
TextTiling: Segmenting text intomulti-paragraph subtopic passages.
Computational Lin.-guistics, 2311):33-64, March.Peter A. IIeeman, Ieyung he Loken-Khn, and James 1:.
Allen.1996.
Oombining the detection and correction of speechrepairs.
In Proceedin9s of ICSLP-96.Julia Ilirsehberg mid Christine Nakatmfi.
1998.
Acousticindicators of topic segmentation.
In Proceedings o.f theICSLP-98, Sydney, Australia.IIongyan Jing.
2000.
Sentence reduction for automatic textsum,narlzation.
In Proceedings of ANIH~-NAA CL-2000,Seattle, WA, May, pages 310-;315.Megumi Kameyama, Goh Kawai, and isao Arima.
1996.
Areal-tinie systcni for summarizing human-human sponta-neous spoken dialogues.
Ill Proceedings of the ICSLP-96,pages 681-684.Linguistic Data Consortium (LDC).
1996.
CallHome alldCallFriend LVCSR databases.Fernando S~nchez \[,edn.
1994.
Spanish l.agset for tileCI~.ATIBR project, http://xxx.lanl.gov/cinp-lg/9406023.lndetjeet Mani and Mark Maybury, editors.
1997.
Proceed-in gs of the A CL/ICA CL '97 Workshop on Intelligent Scal-able Text Summarization, Madrid, Spain.\]ndet:ieet Mani, I)avid ltouse, Gary Klein, l,ynetteHirschman, Leo Obrst, Therese Firmin, MichaelChrzanowsld, and lJeth Sundheim.
1998.
The 'I'\]P-STER SUMMAC text summarization evaluation.
MitreTechnical Report MTIi 98W0000138, October 1998.Klaus liles.
1999.
ItMM and neural network based speechact detectiou.
\]n Proceedings o\] the ICASSP-99, Phoenix,Arizona, March.Gerard Salton and Chris Buckley.
1990.
\]?lexlble text match-ing for information retrieval.
'Pcchnical report, CornellUniversity, Department ofComputer Science, TR.
90-1158,September.Germ'd Salton and Michael J. McGill.
1983.
Introduction toModern Information ltetrieval.
McO,'aw IIill, q\~kyo etc.Elizabeth Shriberg, Rebecca Bates, Andreas Stolcke, Paulq)*ylor, Daniel aurafsky, Klaus f{ies, Noah Coccaro, l{achelMartin, Marie Meteer, and Carol Van Ess-Dykema.
1998.
(Jan prosody aid the automatic classification ofdialog actsin conversational speech?
Lan9aa9 e and Speech, ,1113-4):439 487.Andrew,s Stolcke and l~lizabeth Shriberg.
1996.
Automaticlinguistic segmentation f conversational speech.
In Pro-ceedings o\] the I6'SL\]~-96, pages 1005-1008.Andreas Stolcke, Elizabeth Shriberg, Rebecca Bates, MarlOstendorf, Dilek IIakkani, Madelei,m Plauche, (JSkhanTfir, and Yu tin.
1998.
Automatic detection of sentence1ooundm:ies and disfluencies based on recognized words.
InProceedings of the ICSLP-98, Sydney, Australia, Decen>bet, volunm 5, pages 2247--2250.Andreas 8tolcke, ISlizabeth Shriberg, l)ilek IIakkani-Tfir, andGSkhan q'fir.
2000.
Prosody-based automatic segmenta-tion of speech into sentences and topics.
Speech Comn~u-"nhcatio'a., 32(1-2).l/obin Valenza, 3kmy l~obinson, Marianne l\]ickcy, and l{ogerTucker.
199,(/.
Sunnnarisation of Sl)oken audio through in-forniatiou extraction, tn Proceedings o,f the /'TSCA work-shop: Aceessin.9 i~fformatio'n i~ spoken audio, pages 111116.
C.2ambridge, UK, April.Alex Waibel, Michael Belt, and Michael Finke.
1998.
Meet-ing browser: Tracking and summarizillg meetings, in Pro-ceedings of the DARPA Broadcast News l/Vo'rkshop.Hue Yu, Michael Finke, and Alex Waibel.
1999.
Progressill atltonlatic meeting transcril)tion.
\]n Proceedings qfEUI~OSI'EECI1-99, Budapest, lhm9ary, September.Klaus Zeehner and Alex \?aibel.
1998.
Using chunk basedpartial parsing of spontaneous speech in unrestricted do-mains for reducing word error rate in speech recognition.In Proceedings of COLING-A CL 98, \]WIontreal, Canada.Klaus Zechner and Alex Waibel.
2000.
Minimizing word errorrate in textual suinnlaries of spoken lmiguage.
\]u Procced-ings o\] the First Meeting o.f the North American Chapter o.fthe Association for Computational Linguistics, NAACL-2000, Seattle, WA, April/May, pages 186-193.Klaus Zechner.
1997.
Building chunk level represen-tations for spontmmous peech in unrestricted do-mains: The CHUNI';Y system and its al)plication toreranking N-best lists of a speech recognizer.
Mas-ter's thesis (project report), Oh/I_U, available fl'om:http  : / /wuu.
es .
emu.
edu/-zechner/publ icat  ons.
html.Klaus Zechner.
2000.
A word-based annota-tion and evaluation scheme for summariza-tion of Sl)ontancoIJs speech.
Awfilablc fi'onihttp://www.cs.
?,,,,.eduFzechner/pubiications.i,1:ml.974
