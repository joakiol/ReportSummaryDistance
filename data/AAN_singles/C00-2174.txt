Chinese Generation in a Spoken Dialogue Translation SystemHua Wu, Taiyi Huang, Chengqing Zong and Bo XuNational Laboratory of Pattern Recognition, Institute of AutomationChinese Academy of Sciences, Beijing 100080, ChinaE-mail: { wh, huang, cqzong, xubo } @nlpr.ia.ac.cnAbstract:A Chinese generation module in a speech tospeech dialogue translation system is presentedhe:re.
The input of the generation module is theunderspecified semantic representation.
Its designis strongly influenced by the underspecification fthe inlmtS and the necessity of real-time androbust processing.
We design an efficientgeneration system comprising a task-orientedmicroplanner and a general surface realizationmodule for Chinese.
The microplanner performsthe lexical and syntactic choice and makesinferences fiOln the input and domain knowledge.The output of the microplanner is fullyinstantiated.
This enables the surface realizer totraverse ltle input in a top-down, depth-firstfashion, which in turn speeds the wholegeneration procedure.
The surface realizer alsocombines the template method and deepgeneration technology in the same formalism.Preliminary results are also presented in thispaper.1,, In t roduct ionIn this paper, we will present the core aspectsof the generation component of our speech tospeech dialogue translation system, the domain ofwhich is hotel reservation.
The whole systemconsists of five modules: speech recognizentranslator, dialogue manageh generator and speechsynthesizer.
And the system takes the interlinguamethod in order to achieve multilinguality.
Herethe interlingua is an underspecified selnanticrepresentation (USR).
And the target language isChinese in this paper.Reiter (Reiter 1995) made a clear distinctionbetween templates and deep generation.
Thetemplate method is rated as efficient but inflexible,while deep generation method is considered asflexible but inefficient.
So the hybrid method tocombine both the methods has been adopted in thelast few years.
Busemann (Busemann 1996) usedhybrid method to allow template, canned texts andgeneral rules appearing in one formalism and totackle the problem of the inefficiency of thegrammar-based surface generation system.
Pianta(Pianta 1999) used the mixed representationapproach to allow the system to choose betweendeep generation technology and template method.Our system keeps the surface generationmodule general for Chinese.
At the same time, wecan also deal with templates in tile input withoutchanging tile whole generation process.
If tileattribute in the feature structure is "template",then the value must be taken as a word string,which will appear in the output withoutmodification.
The surface generation moduleassumes  the input as a predicate-argumentstructure, which is called intermediaterepresentation here.
And any input of it must befirst converted into an intermediate r presentation.The whole generation process can bemodularized fimher into two separate components:microplanner and syntactic realizer.
Themicroplanner is task-oriented.
The input is anUSR and the function of it is to plan an utteranceon a phrase- or sentence-level.
It maps conceptsdefined in the domain to a functionalrepresentation which is used by the syntacticgeneration components to realize an appropriatesurface string for it.
The functional description ismade of feature structures, the attribute-value1141pairs.
And the functional representation serves asthe intermediate representation between themicroplanner and the syntactic generator.
Theintermediate representation is fully instantiated.This enables the surface realizer to traverse theinput in a top-down, depth-first fashion to workout a grammatically correct word string for theinput, which in turn speeds the whole generatiouprocedure.
So our system use a task-orientedmicroplanner and a general surface realizer.
Themain advantage is that it is easy to adapt thesystem to other domains and maintain theflexibility of the system.In this paper, section 2 gives a briefdescription of our semantic representation.Section 3 presents our method on themicroplanning procedure.
Section 4 describes thesyntactic generation module.
Section 5 presentsthe preliminary results of our generation system.Section 6 presents discussions and future work.2.
Semantic RepresentationThe most obvious characteristics of theselnantic representation are its independence ofpeculiarities of any language and itsunderspecification.
But it lnUSt capture thespeaker's intent.
The whole semanticrepresentation has up to four components asshown iu figure l: speaker tag, speech act, topicand arguments.The speaker tag is either "a" lbr agent or "c"for customer to indicate who is speaking.
Thespeech act indicates the speaker's intent.
The topicexpresses the current focus.
The argumentsindicate other inforlnatiou which is necessary toexpress the entire meaning of the source sentence.USR::= speaker: speech act: topic: m'gumentSpeaker::= alcSpeech_act ::= give-information I request-information\[...Topic ::= (concept = attribute) ^Argument ::= (concept=attribute)l*Figure 1 Underspecified Semantic RepresentationBoth the topic and arguments are made up ofattribute-value pairs in functional formalisms.
Theattribute can be any concept defined in the dolnainof hotel reservation.
The value can be an atomicsymbol or recursively an attribute-value pair.
Thesymbol "^" in the topic expression indicate thatthe expression can appears zero to one time, whileThe symbol "*" iu the argument expression showsthat the expression can appears zero to any times.And the attribute-value pairs are order free.
Bothtopic and arguments are optional parts in the USR.Let us consider a complex semanticexpression extracted from our corpus.
It is shownin Example I:a: give-information: (available -- (room =(room- type = double ))) : (price = (quantity=200&240,currency=dollor)) I (1)In Example 1, the speech act is give-information, which means that the agent isoffering information to the customer.
The topicindicates there are double rooms.
The argumentslist the prices of double rooms, which shows thatthere are two kinds of double rooms available.
Sothe meaning of this representation is " We havetwo kinds of double rooms which cost 200 mad240 dollars respectively".
From the USR, thekinds of rooms are not expressed explicitly in theformat.
Only from the composite value of theconcept "price " can we judge there are two kindsof rooms because the price is different.
This isonly one example of underspecification, whichneeds inferences from the input and the domainknowledge.3.
The MicroplannerThe input to our microplanner is theunderspecified semantic representation.
From theabove semantic representation, we can see that itis underspecified because it lacks infornlationsuch as predicate-argument structure, cognitivestatus of referents, or restrictive/attribute fimctionof semantic properties.
Some of the non-specifiedpieces of ilfformation such as predicate/argumentstructure are essential to generate a correcttranslation of the source sentence.
Fortmmtely,much of the information which is not explicitlyrepresented can be inferred fiom defaultknowledge about the specific domain and thegeneral world knowledge.The lnicroplanner includes two parts:sentence-level planning and phrase-level planning.1142The sentence planner maps the semanticrepresentation into predicate argument structure.And the phrase planner maps the concepts definedin the domain into Chinese phrases.In order to express rules, we design a formatt'or them.
The rules are represented as pattern-constraints-action triples.
A pattern is to bematched with part of the input on the sentencelevel and with the concepts on the phrase level.The constraints describe additional context-dependent requirements to be fulfilled by theinput.
And the action part describes the predicateargument structure and other information such asmood and sentence type.
An example describiug asentence-level rule is shown in Figure 2.
((speaker= a ) ( speech_act =give-information )( topic= available ) ( topic_value = room ));//pattern(exist(concept, 'price' )); //constraint( (cat = clause) ( mood = declarative)( tense = present) (voice = active)(sentence type = possessive)(predicate ='4f')(args = (((case - pos)(lex :- #get(attribute, 'room' )))((case = bel)(cat = de)(modifier-(#gct(altributc, 'price' )))(auxiliary = 'l'l{j'))))(!optiolml: pre_mod = ( time = #get ( attribute,'lime')))); //actionFigure 2 Example Microplanning l>,uleFirst, we match the pattern part with the inputUSI>,.
If matched, the constraint is tested.
In theexample, the concept price lnust exist in the input.The action part describes the whole sentencestructure such as predicate argument structure,sentence type, voice, mood.
The symbol "#get" inthe action part indicates thai the value can beobtained by accessing the phrase rules or thedictionary to colnplete the structure recursively.The "#get" expression has two parameters.
Thefirst parameter can be "concept" or "attribute" toindicate to access the dictionary and phrase ruesrespectively.
The second parameter is a conceptdefined in the domain.
In the example, the "#get"expression is used to get the value of the domainconcepts room and price respectively.
The symbol"optionah" indicates that the attribute-value pairbehind it is optional.
If the input has the concept,we fill it.After the sentence- and phrase-level phmning,we must access the Chinese dictionary to get thepart-of-speech of the lexicon and other syntacticinformation.
If the input is the representation iExample I, the result of the microplanning isshown in Figure 3.
(cat  = clat, se)( sentence_type =possessive)(mood = declarative)( tense = present) (voice = active)(predicate =((cat=vcm) (lex ='4f')))(args=(((case = pos)(cat = nct)(lex ='~J, Vl'iq'))((case = bel)(cat =de)(modi fier=((cat=mp)(cardinal =((cat=nc)(n l=((cat=num) (lex='200'))(n2=((cat=num)(lex="240'))(qtf= ((cat=ncl) ( lex ='0~)t\]'))))(at, x il iary =(lex =' I'1I'.1'))))lVigure 3 Microplanning Result for Example 1In the above example, "cat" indicates thecategory of the sentence, plnases or words.
"h'x"denotes the Chinese words.
"case" describes thesemantic roles of the arguments.Target language generation in dialoguetranslation systems imposes strong constraints onthe whole generation.
A prominent pmblena is thenon-welformedness of the input.
It forces thegeneration module to be robust to cope with theerroneous and incomplete input data.
In this level,we design some general rules.
The input is first tobe matched with the specific rules.
If there is norules matched, we access the general rules tomatch with the input.
In this way, although theinput is somehow ill-formed, the output stillincludes the main information of the input.
Anexample is shown in (2).
The utterance issupposed for the custom to accept he single roomoffered by the agent.
But the speech act is wrongbecause the speech act "ok" is only used to1143indicate' that the custol-u and tile agenl has agreedon one Iopic.c: ok: ( room = ( room-type := single,quantity= 1 )): (2)Although example (2) is ill formed, itincludes most information of the source sentence.Our robust generator can produce the sentenceshown in (3).Cl'i-)kf/iJ~J: ( yes, a single roont ) (3)4.
Syntactic realizatimThe syntactic realizer proceeds from themicroplannir~g result as shown in t"igure 3.
Therealizer is based on a flmctional uuificati,,mfornmlism.lit tMs module, we also introduce thetemplate nlethod.
If lhe input includes anattribute~wflue pair which uses "template" as fileattribute, then rite wflue is taken as canned lexts orword strhws wilh slots.
It will appear in the outputwithout any modificati(m. So we can embed tiletemplate into the surface realization withoutmodifying tlw whoh: generation l)rocedure.
Whenthe hybrid method is used, the input is firstmatched with the templates defined.
If matched,the inputs will go lo llle surface realizer directly,skiplfing tl,c microplanning process.The task of the Chinese realizer i:; as tollows:, Define the sentence struclure?
Provide ordering constraints among thesyntactic onstituents of the sentence?
Select the functional words4.1 \]Intermediate RepresentationThe intermediate representation(IR) is madeup of feature structures.
It corresponds to thepredicate argument structure.
The aim is tonormalize the input of tile surface realizer.
It is ofconsiderable practical benefit to keep the rulebasis as independent as possible front externalconditions (such as the domain and output of tilepreceding system).The intermediate representation includesthree parts: predicate int"ormation, obligatoryarguments and optional arguments.
The predicateinR)rmation describes the top-level information ina clause includiug the main verb, lhe mood, thevoice, and so on.
The obligatory arguments areslots of roles that must be filled in a clause for itto be contplete.
And the optional argumentsspecify the location, the time, the purpose of theevent etc.
They arc optional because they do notaffect rite contpleteness of a clause.
An example isshown in Figure 4.
The input is for the sentence"{~J~ l'f\] ~\]l~ 1{ 1'1 @) \  \[)iJ li!.~ ?"
(Do you have singlerooms now?).
"agrs" antt '?opt" in Figure 4represent obligatory arguntents and optionalarguments respectively.
((cat = clause)( sentence )ype =possessive)(mood: yes-no)( lense = present) (wfice -: active)(predicate =((cat=veto) (lex ="(J")))(args=(((case :-: pos)(ca!
-pron)(lex ='{?j<{f\]'))((case "- bel) (cai ~:nct)(lex=' "l%)v. \['(iJ '))))(opt=(d me=((cat=:adv) tie x=' J:l)lu (I i')))))Fip, urc 4 F, xample Intermediate l),el)rescnlalion4.2 Chinese ReallizalionIn tile synlaclic generation module, we useihe \[unclional unification fommlism.
At tile samelime, we make use of dlc systclnic viewpoirl/ oflhe systcrnic function grammar.
The rule system ismade up of many sub-.sysienls such as transitivilysystem, mood system, tense system and voicesystcllt.
The input 111ust depend on all of thesesystems to make difR:rent level decisions.In a spoken dialogue Iranslalion system, real=lime generation is tile basic requiremenl.
As wesee froln the input as shown in Figure 3, the inlmtto the syntaclic generation provides enoughiuformation about sentence and phrase structme.Most of the informatiou in tile input ix instautiatcd,such as the verb, the subcategorization frame andthe phrase members.
So the generation engine cantraverse the input in a top-down, depth-firstfashion using tmification algorithm (Elhadad1992).
The whole syntactic generation process isdescribed in Figure 5.The input is an intermediate representationand the output is Chinese texts.
The sentenceunification phase defines the sentence structureand orders the components anloDg, tile sentence.1144The phrase unification phase dcl'ines the phrasestructure, orders the co~nponenls inside thephrases and adds the function words.
UnlikeEnglish, Chinese has no morphological markersfor tenses and moods.
They arc expressed withfmlclional words.
Selecting functiolml wordscorrectly is crilical for Chillesc generation.,qelltellCC\[ ~'t "~''~'-t ~unifica|ion ~lst?
-- -- !
'-;~7~II1 I - tlni fcatiOll \]~CXtFigure 5 Sleps of the Synlacfic generatorThe whole unification procedure is:,, Unify the input with the grammar at thesentence l vel.?
identify the conslitules inside the inptll?
Unify the constituents with tile grammar a!
thephrase level recursively in a top-down, depth-first fashion.5.
ResultsThe current version of the system has beentested on our hotel reservation corpus (ChengqingZong, 1999).
The whole corpus includes about 90dialogues, annotated by hand with underspecificdsemantic representation.
I1 contains about 3000USRs.
Now we have 23 speech acls and about 60concepts in lhe corpus.The generation lnodulc is tested on allsentences in the corpus.
And 90% of the generatedsentences arc rated as grammatically andsemantically correct.
The other 10% are rated aswrong because the mood of the sentences i notconect.
This is mainly caused by the lack of thedialogue context.6.
Discussion and Future WorkIn spoken language translation systems, oneproblem is the ill-formed input.
How to tackle thisproblem robustly is very important.
At themicroplanning level, we design some generalrules.
The input is first to be matched with thesl~e<:ific roles.
If there is no rules matched, weaccess the gene.ral roles to Inalch with the input.
Inthis way, although the inl)U!
is somehow ill-formed, the output includes the main informationof the input.
And at the surface realization level,we make some relaxation on tests to improve therobuslness, l;,.g, oMigatory arguments may bemissing in the utterance.
This can be caused byellipsis in sentences such as the utterances "{:\]{: ~J~."
(stay for three days).
We have to accept it as asentence without the subject because they areacceptable in spoken Chinese and often appear indaily dialogues.We arc planning to l:tuther increase therobustness of the system.
And if possible, we alsohope to adapt our generation system to other(lolnaills.AcknowledgementsThe research work described in lhis paper isSulsportcd by the National Natural Sciencet;oundation of China under grant number69835030 and by the National '863' Hi-TcchProgram under grant nunlber 863-306-ZT03-02-2.Thanks also go to several allonyl/lOtlS l'eVieWel'Sfor their valuable comments.Reference ;Stephan I} uscmann.
(1996) Best- first surl'acerealization.
In t i le Eighth lntcrnatiolml Naturall.anguagc Generation Workshop, Sussex, pages 101-I10Michael Elhadad and Jacques Robin.
(1992)Controlling Content P.calization with FunctionalUnification Grammars.
Aspects of Automated NaturalLanguage Generation.
t51)89 - 104E.Pianta, M.Tovcna.
(1999) XIG: Generating fromInterchange Format Using Mixed Representation.AAAI'99Ehud Reiter.
(1995) NLG vs. Templates.
In lhe FiflhEt, ropcan Workshop on Natural Language Generation,Leiden,Chengqing Zong, Hua Wu, Taiyi Huang, Be Xu.
(1999)Analysis on Characteristics of Chinese SpokenLanguage.
In the Fiflh Natural Language ProcessingPacific Rim Symposium, 151)358-3621145
