Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 178?185,Baltimore, Maryland USA, June 26?27, 2014.c?2014 Association for Computational LinguisticsThe UA-Prompsit hybrid machine translation system for the 2014Workshop on Statistical Machine TranslationV?
?ctor M. S?anchez-Cartagena,?
?Juan Antonio P?erez-Ortiz,?Felipe S?anchez-Mart??nez??Dep.
de Llenguatges i Sistemes Inform`atics,Universitat d?Alacant, E-03071, Alacant, Spain?Prompsit Language Engineering,Av.
Universitat, s/n.
Edifici Quorum III, E-03202, Elx, Spain{vmsanchez,japerez,fsanchez}@dlsi.ua.esAbstractThis paper describes the system jointly de-veloped by members of the Departamentde Llenguatges i Sistemes Inform`aticsat Universitat d?Alacant and the Promp-sit Language Engineering company forthe shared translation task of the 2014Workshop on Statistical Machine Trans-lation.
We present a phrase-based sta-tistical machine translation system whosephrase table is enriched with informationobtained from dictionaries and shallow-transfer rules like those used in rule-basedmachine translation.
The novelty of ourapproach lies in the fact that the transferrules used were not written by humans, butautomatically inferred from a parallel cor-pus.1 IntroductionThis paper describes the system jointly submittedby the Departament de Llenguatges i Sistemes In-form`atics at Universitat d?Alacant and the Promp-sit Language Engineering company to the sharedtranslation task of the ACL 2014 Ninth Workshopon Statistical Machine Translation (WMT 2014).We participated in the English?French translationtask with a hybrid system that combines, in aphrase-based statistical machine translation (PB-SMT) system, bilingual phrases obtained from par-allel corpora in the usual way (Koehn, 2010, ch.5), and also bilingual phrases obtained from theexisting dictionaries in the Apertium rule-basedmachine translation (RBMT) platform (Forcada etal., 2011) and a number of shallow-transfer ma-chine translation rules automatically inferred froma small subset of the training corpus.Among the different approaches for adding lin-guistic information to SMT systems (Costa-Juss`aand Farr?us, 2014), we followed the path we startedwith our submission to the Spanish?English WMT2011 shared translation task (S?anchez-Cartagenaet al., 2011b) which consisted of enriching thephrase table of a PBSMT system with phrase pairsgenerated using the dictionaries and rules in theApertium (Forcada et al., 2011) Spanish?EnglishRBMT system; our approach was one of the win-ners1(together with two online SMT systems thatwere not submitted for the task but were includedin the evaluation by the organisers and a system bySystran) in the pairwise manual evaluation of theEnglish?Spanish translation task (Callison-Burchet al., 2011).
In this submission, however, weonly borrow the dictionaries from the ApertiumEnglish?French RBMT system and use them to au-tomatically infer the rules from a parallel corpus.We therefore avoid the need for human-writtenrules, which are usually written by trained experts,and explore a novel way to add morphologicalinformation to PBSMT.
The rules inferred fromcorpora and used to enlarge the phrase table areshallow-transfer rules that build their output withthe help of the bilingual dictionary and work onflat intermediate representations (see section 3.1);no syntactic parsing is consequently required.The rest of the paper is organised as follows.The following section outlines related hybrid ap-proaches.
Section 3 formally defines the RBMTparadigm and summarises the method followedto automatically infer the shallow-transfer rules,whereas the enrichment of the phrase table is de-scribed in section 4.
Sections 5 and 6 describe, re-spectively, the resources we used to build our sub-mission and the results achieved for the English?French language pair.
The paper ends with someconcluding remarks.2 Related workLinguistic data from RBMT systems have alreadybeen used to enrich SMT systems (Tyers, 2009;Schwenk et al., 2009; Eisele et al., 2008; S?anchez-Cartagena et al., 2011a).
We have already proved1No other system was found statistically significantly bet-ter using the sign test at p ?
0.10.178that using hand-written rules and dictionaries fromRBMT yields better results than using only dictio-naries (S?anchez-Cartagena et al., 2011a).However, in the approach we present in this pa-per, rules are automatically inferred from a paral-lel corpus after converting it into the intermedi-ate representation used by the Apertium RBMTplatform (see section 3.3).
It can be thereforeseen as a novel method to add morphological in-formation to SMT, as factored translation modelsdo (Koehn and Hoang, 2007; Graham and vanGenabith, 2010).
Unlike factored models, we donot estimate independent statistical models for thetranslation of the different factors (lemmas, lexi-cal categories, morphological inflection attributes,etc.)
and for the generation of the final surfaceforms.
Instead, we first infer a set of rules that dealwith the grammatical divergences between the lan-guages involved by performing operations such asreorderings, gender and number agreements, etc.Afterwards, we add synthetic phrase pairs gener-ated from these rules and the Apertium dictionar-ies to the data from which the well-known, classi-cal PBSMT models (Koehn, 2010) are estimated.The rules in our approach operate on the source-language (SL) morphological attributes of the in-put words and on the target-language (TL) mor-phological attributes of their translation accordingto a bilingual dictionary.
In addition, they do nocontain probabilities or scores, thus they increasethe predictability of the output and can be easilycorrected by humans.
This fact also represents asignificant difference with the probabilistic rulesused by certain approaches that aim at improvingthe grammaticality of the SMT output (Riezler andMaxwell III, 2006; Bojar and Haji?c, 2008).With respect to the rule inference approach,other approaches such as those by S?anchez-Mart?
?nez and Forcada (2009) and Caseli et al.
(2006) can be found in literature; however, our ap-proach is the first strategy for shallow-transfer ruleinference which generalises to unseen combina-tions of morphological inflection attributes in thetraining corpus (S?anchez-Cartagena et al., 2014).3 Inferring shallow-transfer rules fromparallel corpora3.1 Shallow-transfer rule-based machinetranslationThe RBMT process can be split into three differentsteps (Hutchins and Somers, 1992): (i) analysis ofthe SL text to build an SL intermediate represen-tation; (ii) transfer from that SL intermediate rep-resentation into a TL intermediate representation;and (iii) generation of the final translation from theTL intermediate representation.Shallow-transfer RBMT systems use relativelysimple intermediate representations, which arebased on lexical forms consisting of lemma, partof speech and morphological inflection informa-tion of the words, and apply simple shallow-transfer rules that operate on sequences of lexicalforms: this kind of systems do not perform fullparsing.
For instance, for translating the Englishsentence I like Pierre?s house into French withthe Apertium shallow-transfer RBMT platform wehave used to build our submission, the followingsteps are carried out.
First, the sentence is anal-ysed as the following sequence of lexical forms:I PRN-p:1.num:sglike VB-t:pres.p:?
:num:?Pierre PN?s POShouse N-gen:?.num:sgThis sequence is made up of a personal pronoun(PRN) in first person (p:1) singular (num:sg)with lemma I, the verb (VB) like in present tense(t:pres), a proper noun (PN) with lemma Pierre,the possessive ending (POS), and a noun (N) in sin-gular with lemma house.
Some morphological in-flection attributes have an empty value ?
becausethey do not apply to the corresponding language.Then, structural transfer rules are applied to ob-tain the TL intermediate representation with thehelp of the bilingual dictionary, which providesthe individual translation of each SL lexical form(including its morphological information).
In thiscase, two rules are applied: the first one makes theverb to agree with the personal pronoun, while thesecond one translates the English possessive con-struction into French.
The resulting sequence ofTL lexical forms is:Je PRN-p:1.num:sgaime VB-t:pres.p:1:num:sgle DT-gen:f.num:sgmaison N-gen:f.num:sgde PRPierre PNNote that a preposition (PR) with lemma de and adeterminer (DT) with lemma le and the same gen-der and number as the common noun have beenadded by the rule.
Finally, the translation into TLis generated from the TL lexical forms: J?aime lamaison de Pierre.179s1: PN s2: POS s3: N-gen:*.num:*t1: le DT-gen:$3t.num:$3st2: N-gen:$3t.num:$3st3: de PR t4: PNFigure 1: Shallow-transfer rule for the translation of the English Saxon genitive construction into French.3.2 A rule formalism suitable for ruleinferenceFigure 1 shows the second rule applied in theexample from the previous section encoded withthe formalism we have defined for rule infer-ence (S?anchez-Cartagena et al., 2014).
Each rulecontains a sequence of SL word classes (depictedas the sequence of boxes at the top of the figure)and TL word classes (the sequence of boxes be-low them).
The sequence of SL word classes de-fines the set of sequences of lexical forms whichwill match the rule.
Each SL word class sidefinesthe conditions that must be met by the i-th lexicalform matching the rule and contains an optionallemma (no lemma means that any SL lemma is al-lowed), a lexical category and a set of morpholog-ical inflection attributes and their expected values.A wildcard (asterisk) as the value of a morpholog-ical inflection attribute means that it matches anypossible value.
Thus, the rule from the examplematches any proper noun followed by a possessiveending and a noun, regardless of its gender andnumber.As regards the TL word classes, they containthe same elements as the SL word classes and de-fine the output of the rule.
An empty lemma in aTL word class means that it is obtained by lookingup in the bilingual dictionary the SL lexical formmatching the aligned SL word class (alignmentsare represented as lines connecting SL and TLword classes).
The reference value $ismeans thatthe value of a morphological inflection attribute iscopied from the SL lexical form matching the i-thSL word class, while the reference value $itmeansthat the value is taken from the TL lexical form ob-tained after looking up in the bilingual dictionarythe aforementioned SL lexical form.
The rule de-picted in Figure 1 generates a sequence of four TLlexical forms.
The first one is a determiner whoselemma is le, its gender is obtained from the genderof the TL lexical form resulting after looking up inthe bilingual dictionary the third matching SL lex-ical form ($3t), that is, the common noun, while itsnumber is directly obtained from the same SL lexi-cal form before dictionary look-up ($3s).
Althoughthey have not been used in this example, explicitvalues can be used in the morphological inflectionattributes of the SL and TL word classes, thus re-stricting the SL lexical forms to which the rule canbe applied to those having the values in the corre-sponding SL word classes,2and explicitly statingthe value that the TL lexical forms produced bythe rule will have, respectively.3.3 Rule inference algorithmThe set of rules that will be used to generate thephrase pairs that will be integrated into the PB-SMT system?s phrase table, encoded with the for-malism presented in the previous section, are ob-tained from the parallel corpus by applying thesteps described in this section.
They are a subsetof the steps followed by S?anchez-Cartagena et al.
(2014) to infer shallow-transfer rules to be used inApertium from small parallel corpora.First, both sides of the parallel corpus are mor-phologically analysed and converted into the inter-mediate representations used by Apertium.
Wordalignments are then obtained by symmetrising(using the refined intersection method proposedby Och and Ney (2003)) the set of alignmentsprovided by GIZA++ (Och and Ney, 2003) whenit is run on both translations directions.
After-wards, the bilingual phrase pairs compatible withthe alignments are extracted as it is usually donein SMT (Koehn, 2010, Sec.
5.2.3), and those thatare not compatible with the bilingual dictionary ofthe Apertium English?French RBMT system3or2In addition to that criterion, our formalism also permitsrestricting the application of a rule to the SL lexical formsthat, after being looked up in the bilingual dictionary, theTL lexical forms obtained from them have specific morpho-logical inflection attribute values (S?anchez-Cartagena et al.,2014) although no restrictions of this type are imposed in therule depicted in Figure 1.3If the words that belong to open lexical categories (thosethat carry the meaning of the sentence: nouns, verbs, adjec-tives, etc.)
are aligned with other words that do not matchthe translation present in the bilingual dictionary, the rule in-180contain punctuation marks or unknown words arediscarded.
Finally, from each bilingual phrase pair,all the possible rules which correctly reproduce it?when the rule is applied to the SL side of thephrase pair, its TL side is obtained?
are gener-ated as follows.
First, a very specific rule, whichmatches only the SL phrase in the bilingual phrasepair is generated; more general rules are then cre-ated by modifying this initial rule.
The modifica-tions to the initial rule consist of removing lem-mas from the SL and TL word classes, introduc-ing wildcard values in the morphological inflec-tion attributes of the SL word classes and addingreference values in the morphological inflection at-tributes of the TL word classes.
The result of thisprocess is a huge set of rules with different levelsof generalisation.
Obviously, not all the rules inthis set will be used: the best ones are automati-cally selected by considering all the rules obtainedfrom the different bilingual phrase pairs extractedfrom the corpus and finding the minimum set ofrules that meets the following two conditions:1.
Each bilingual phrase pair is correctly repro-duced by at least one rule.2.
If a rule matches the SL side of bilingualphrase pair but does not correctly reproduceits TL side, there is another rule that is morespecific (i.e.
less general) than it, and cor-rectly reproduces its TL side.This minimisation problem is formulated as an in-teger linear programming4problem (Garfinkel andNemhauser, 1972) and solved using the branchand cut algorithm (Xu et al., 2009).From the small subset of the huge initial rulesobtained by solving the minimisation problem, therules whose effect can be achieved by combiningshorter rules or by translating all or some of thewords in isolation (i.e.
word for word) are re-moved.
In this way, the number of rules is furtherreduced and long rules, which are more prone toovergeneralisation because they are inferred fromfewer bilingual phrase pairs, are discarded.5ference algorithm is likely to infer many very specific rulesthat try to correct that lexical mismatch.
Since the aim ofour approach is learning general rules that deal with thegrammatical divergences between languages, the bilingualphrases that contain the aforementioned alignments are dis-carded.
Words from closed lexical categories, that usuallysuffer deeper changes when the sentence is translated to a dif-ferent language, are not subject to this restriction.4An integer linear programming problem involves the op-timisation (maximisation or minimisation) of a linear objec-tive function subject to linear inequality constraints.5Although longer rules contain more context information,4 Enhancing phrase-based SMT withshallow-transfer linguistic resourcesThe set of shallow-transfer rules inferred from theparallel corpus are integrated in the PBSMT sys-tem, together with the RBMT dictionaries, usingthe same method we used for our WMT 2011shared translation task subsmission (S?anchez-Cartagena et al., 2011b).
However, it is importantto stress that, until now, this strategy had only beentested when the rules to be integrated were hand-written and not automatically obtained from cor-pora.Our strategy involves adding to the phrase ta-ble of the PBSMT system all the bilingual phrasepairs which either match a shallow-transfer rule oran entry in the bilingual dictionary.
Generating theset of bilingual phrase pairs which match bilingualdictionary entries is straightforward.
First, all theSL surface forms that are recognised by Apertiumand their corresponding lexical forms are gener-ated.
Then, these SL lexical forms are translatedusing the bilingual dictionary, and finally their TLsurface forms are generated.Bilingual phrase pairs which match structuraltransfer rules are generated in a similar way.
First,the SL sentences to be translated are analysed withApertium to get their SL lexical forms, and thenthe sequences of lexical forms that match a struc-tural transfer rule are translated with that rule andpassed through the rest of the Apertium pipelinein order to get their translations.
If a sequenceof SL lexical forms is matched by more than onestructural transfer rule, it will be used to generateas many bilingual phrase pairs as different rulesit matches.
This differs from the way in whichApertium translates, as it only applies the longestrule.
Note also that the test set is used to guide thephrase extraction in order to avoid the generationof an unmanageable set of phrase pairs.We add these bilingual phrase pairs directly tothe phrase table, rather than adding them to thetraining corpus and relying on the phrase extrac-tion algorithm (Koehn, 2010, sec.
5.2.3), in orderto avoid splitting the multi-word expressions pro-vided by Apertium into smaller phrases (Schwenket al., 2009, sec.
2).
The bilingual phrase pairsare added only once to the list of corpus-extractedphrase pairs, and then the phrase translation prob-abilities are computed by relative frequency asusual (Koehn, 2010, sec.
5.2.5).
A boolean featurefor our rule inferring algorithm there are fewer bilingualphrases from which to infer them, and consequently fewerevidence from which to extract the right reference attributes.181function to flag bilingual phrase pairs obtainedfrom the RBMT resources is added to the phrasetable in order to conveniently weight the syntheticRBMT phrase pairs.5 System trainingWe built a baseline PBSMT Moses (Koehn etal., 2007) system6from a subset of the paral-lel corpora distributed as part of the WMT 2014shared translation task, namely Europarl (Koehn,2005), News Commentary and Common Crawl,and a subset of the French monolingual corpora,namely Common Crawl, Europarl, News Com-mentary and News Crawl.
The language modelwas built with the KenLM language modellingtoolkit (Heafield et al., 2013), which was usedto train a 5-gram language model using inter-polated Kneser-Ney discounting (Goodman andChen, 1998).
Word alignments were computedby means of GIZA++ (Och and Ney, 2003).
Theweights of the different feature functions were op-timised by means of minimum error rate train-ing (Och, 2003) on the 2013 WMT test set.7The phrase table of this baseline system wasthen enriched with phrase pairs generated fromrules automatically inferred from the concatena-tion of the test corpora distributed for the WMT2008?2012 shared translation tasks, and from theEnglish?French bilingual dictionary in the Aper-tium platform.8Since the minimisation problemwhich needs to be solved in order to obtain therules is very time-consuming, we chose a smallrule inference corpus similar to this year?s test set.The bilingual dictionary, which contains mappingsbetween SL and TL lemmas, consists of 13 088 en-tries and is quite small compared to the Spanish?English bilingual dictionary we used in our sub-mission to WMT 2011 (S?anchez-Cartagena et al.,2011b), which consisted of 326 228 bilingual en-tries.
This is because the English?French Aper-tium linguistic resources were automatically builtby crossing data from other existing languagepairs.Table 1 summarises the data about the corporaused to build our submission, both for the PBSMTbaseline system and for the rules used to enrich itsphrase table.The corpus used to automatically infer the rules6No factored models were used.7The corpora can be downloaded from http://www.statmt.org/wmt14/translation-task.html.8https://svn.code.sf.net/p/apertium/svn/incubator/apertium-en-frTask Corpus SentencesTranslation modelEuroparl 2 007 723News Commentary 183 251Common Crawl 3 244 152Total 5 435 126Total clean 4 196 987Language modelCommon Crawl 3 244 152Europarl 2 190 579News Commentary 227 013News Crawl 30 451 749Total 36 113 493Rule inference newstest 2008?2012 13 071Tuning newstest2013 3 000Test newstest2014 3 003Table 1: Size of the corpora used in the experi-ments.
The bilingual training corpora was cleanedup to remove empty parallel sentences and thosecontaining more than 40 tokens.was split into two parts: the larger one (4/5 ofthe corpus) was used for actual rule inference asdescribed in section 3.3; the remaining corpuswas used as a development corpus as explainednext.
For each rule z, first the proportion r(z) ofbilingual phrase pairs correctly reproduced by therule divided by the number of bilingual phrasesit matches is computed.
Rules whose proportionr(z) is lower than a threshold value ?
are thendiscarded before solving the minimisation prob-lem.
The value of ?
is chosen so that it maximises,on the development corpus, the BLEU score (Pap-ineni et al., 2002) obtained by an Apertium-basedsystem which uses the inferred rules; in our sub-mission ?
= 0.15.
In addition, rules that do notcorrectly reproduce at least 100 bilingual phrasepairs were also discarded in order to make the min-imisation problem computationally feasible.6 Results and discussionTable 2 reports the translation performance asmeasured by BLEU (Papineni et al., 2002),TER (Snover et al., 2006) and METEOR (Baner-jee and Lavie, 2005) achieved by the baseline PB-SMT, our submission (UA-Prompsit), Apertiumwhen it uses the set of inferred rules, and Aper-tium when it uses no rules at all (word-for-wordtranslation).
The size of the phrase table and theamount of unknown words in the test set are alsoreported when applicable.According to the three evaluation metrics, thetranslation performance of our submission is veryclose to that of the PBSMT baseline (slightly bet-ter according to BLEU and TER, and slightlyworse according to METEOR).
The difference be-tween both systems computed by paired bootstrap182system BLEU TER METEOR # of unknown words phrase table sizebaseline 0.3232 0.5807 0.5441 870 100 530 734UA-Prompsit 0.3258 0.5781 0.5432 861 100 585 182Apertium-rules 0.0995 0.7767 0.3168 4 743 -Apertium-word-for-word 0.0631 0.8368 0.2617 4 743 -Table 2: Case-insensitive BLEU, TER, and METEOR scores obtained, on the newstest2014 test set, bythe baseline PBSMT system (baseline), the hybrid system submitted to the WMT 2014 shared translationtask (UA-Prompsit), Apertium when it uses the set of inferred rules (Apertium-rules), and Apertiumwhen it uses no rules at all (Apertium-word-for-word).
The number of unknown words and the size ofthe phrase table are also reported when applicable.resampling (Koehn, 2004) is not statistically sig-nificant for any of the three evaluation metrics(1 000 iterations, p = 0.05).An inspection of the 86 rules inferred showsthat they encode some of the transformations thatone would expect from a set of English?Frenchrules, such as gender and number agreements be-tween nouns, determiners and adjectives, prepo-sition changes, and the introduction of the aux-iliary verb avoir for the past tense.
In addition,the improvement over word-for-word translationachieved when they are used by Apertium is statis-tically significant for the three evaluation metrics.One of the reasons for not improving the base-line PBMT system might be the small coverageof the Apertium dictionaries.
As already men-tioned in the previous section, the English?Frenchbilingual dictionary has a low number of entriescompared to more mature language pairs in Aper-tium which have around 20 times more bilingualentries.
Table 1 shows some effects of such asmall dictionary: the number of unknown wordsfor the Apertium-based system is really high, andwith regards to UA-Prompsit, its coverage barelyincreases when compared to the PBSMT baseline.We plan to test the approach presented in this paperwith language pairs for which more mature dictio-naries are available in the Apertium project.In addition to this, due to the tight schedule, wehad to remove the rules not reproducing at least100 bilingual phrase pairs in order to solve the min-imisation problem in a short amount of time.
Thishas clearly reduced the amount of rules inferredand prevented some useful information present inthe parallel corpus from being incorporated in theform of rules.
For instance, no rule matching asequence longer than 3 lexical forms has been ex-tracted (long bilingual phrases are less frequentthan short ones).
Future research directions foralleviating this problem include setting the mini-mum number of reproduced bilingual phrases in-dependently for each sequence of SL lexical cate-gories (S?anchez-Cartagena et al., 2014).7 Concluding remarksWe have presented the MT system submittedjointly by the Departament de Llenguatges i Sis-temes Inform`atics at Universitat d?Alacant andPrompsit Language Engineering to the WMT2014 shared translation task.
We developed ahybrid system for the English?French languagepair which enriches the phrase table of a stan-dard PBSMT system with phrase pairs generatedfrom the Apertium RBMT dictionaries and a set ofshallow-transfer rules automatically inferred froma parallel corpus, also with the help of the dic-tionaries.
This submission aims at solving onestrong limitation of a previous submission of ourteam (S?anchez-Cartagena et al., 2011b): the needfor a hand-crafted set of shallow-transfer rules,which can only be written by people with a deepknowledge of the languages involved.
Our ap-proach outperforms a standard PBSMT systembuilt from the same data by a small, non statisti-cally significant margin, according to two of thethree evaluation metrics used.
The low coverageof the dictionaries used and the aggressive pruningcarried out when solving the minimisation prob-lem needed to infer the rules are probably the rea-sons behind such a small improvement over thebaseline.AcknowledgementsWork funded by Universitat d?Alacant throughproject GRE11-20, by the Spanish Ministryof Economy and Competitiveness throughprojects TIN2009-14009-C02-01 and TIN2012-32615, by Generalitat Valenciana through grantACIF/2010/174 (VALi+d programme), and bythe European Union Seventh Framework Pro-gramme FP7/2007-2013 under grant agreementPIAP-GA-2012-324414 (Abu-MaTran).183ReferencesS.
Banerjee and A. Lavie.
2005.
Meteor: An auto-matic metric for mt evaluation with improved corre-lation with human judgments.
In Proceedings of theACL Workshop on Intrinsic and Extrinsic EvaluationMeasures for Machine Translation and/or Summa-rization, pages 65?72.O.
Bojar and J. Haji?c.
2008.
Phrase-based and deepsyntactic English-to-Czech statistical machine trans-lation.
In Proceedings of the third Workshop on Sta-tistical Machine translation, pages 143?146.
Associ-ation for Computational Linguistics.C.
Callison-Burch, P. Koehn, C. Monz, and O. Zaidan.2011.
Findings of the 2011 workshop on statisti-cal machine translation.
In Proceedings of the SixthWorkshop on Statistical Machine Translation, pages22?64, Edinburgh, Scotland, July.
Association forComputational Linguistics.H.
M. Caseli, M. G. V. Nunes, andM.
L. Forcada.
2006.Automatic induction of bilingual resources fromaligned parallel corpora: application to shallow-transfer machine translation.
Machine Translation,20(4):227?245.
Published in 2008.M.
R. Costa-Juss`a and M. Farr?us.
2014.
Statisticalmachine translation enhancements through linguis-tic levels: A survey.
ACM Comput.
Surv., 46(3).A.
Eisele, C. Federmann, H. Saint-Amand, M. Jelling-haus, T. Herrmann, and Y. Chen.
2008.
Us-ing Moses to integrate multiple rule-based machinetranslation engines into a hybrid system.
In Proceed-ings of the Third Workshop on Statistical MachineTranslation, pages 179?182, Columbus, Ohio.M.
L. Forcada, M.
Ginest?
?-Rosell, J. Nordfalk,J.
O?Regan, S. Ortiz-Rojas, J.
A. P?erez-Ortiz,G.
Ram?
?rez-S?anchez F.
S?anchez-Mart?
?nez, and F. M.Tyers.
2011.
Apertium: a free/open-source platformfor rule-based machine translation.
Machine Trans-lation, 25(2):127?144.
Special Issue: Free/Open-Source Machine Translation.R.
S. Garfinkel and G. L. Nemhauser.
1972.
Integerprogramming, volume 4.
Wiley New York.J.
Goodman and S. F. Chen.
1998.
An empiricalstudy of smoothing techniques for language model-ing.
Technical Report TR-10-98, Harvard Univer-sity, August.Y.
Graham and J. van Genabith.
2010.
Factor tem-plates for factored machine translation models.
InIWSLT 2010 : 7th International Workshop on Spo-ken Language Translation, pages 275?283.K.
Heafield, I. Pouzyrevsky, J. H. Clark, and P. Koehn.2013.
Scalable modified Kneser-Ney languagemodel estimation.
In Proceedings of the 51st An-nual Meeting of the Association for ComputationalLinguistics, pages 690?696, Sofia, Bulgaria, August.W.
J. Hutchins and H. L. Somers.
1992.
An introduc-tion to machine translation, volume 362.
AcademicPress New York.P.
Koehn and Hieu Hoang.
2007.
Factored trans-lation models.
In Proceedings of the 2007 JointConference on Empirical Methods in Natural Lan-guage Processing and Computational Natural Lan-guage Learning (EMNLP-CoNLL), pages 868?876,Prague.P.
Koehn, H. Hoang, A. Birch, C. Callison-Burch,M.
Federico, N. Bertoldi, B. Cowan, W. Shen,C.
Moran, R. Zens, et al.
2007.
Moses: OpenSource Toolkit for Statistical Machine Translation.In Annual Meeting of the Association for Computa-tional Linguistics (ACL), demonstration session.P.
Koehn.
2004.
Statistical significance tests for ma-chine translation evaluation.
In Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing, volume 4, pages 388?395.P.
Koehn.
2005.
Europarl: A parallel corpus for statisti-cal machine translation.
In Proceedings of the TenthMachine Translation Summit, pages 12?16, Phuket,Thailand, September.P.
Koehn.
2010.
Statistical Machine Translation.
Cam-bridge University Press.F.
J. Och and H. Ney.
2003.
A systematic comparisonof various statistical alignment models.
Computa-tional Linguistics, 29:19?51, March.F.
J. Och.
2003.
Minimum error rate training in statis-tical machine translation.
In Proceedings of the 41stAnnual Meeting on Association for ComputationalLinguistics, pages 160?167, Sapporo, Japan.K.
Papineni, S. Roukos, T. Ward, and W. Zhu.
2002.Bleu: a method for automatic evaluation of machinetranslation.
In Proceedings of the 40th Annual Meet-ing of the ACL, pages 311?318.S.
Riezler and J. T. Maxwell III.
2006.
Grammati-cal machine translation.
In Proceedings of the mainconference on Human Language Technology Confer-ence of the North American Chapter of the Associa-tion of Computational Linguistics, pages 248?255.Association for Computational Linguistics.V.
M. S?anchez-Cartagena, F.
S?anchez-Mart?
?nez, andJ.
A. P?erez-Ortiz.
2011a.
Integrating shallow-transfer rules into phrase-based statistical machinetranslation.
In Proceedings of the XIII MachineTranslation Summit, pages 562?569, Xiamen, China,September.V.
M. S?anchez-Cartagena, F.
S?anchez-Mart?
?nez, andJ.
A. P?erez-Ortiz.
2011b.
The Universitat d?Alacanthybrid machine translation system for wmt 2011.
InProceedings of the Sixth Workshop on Statistical Ma-chine Translation, pages 457?463, Edinburgh, Scot-land, July.
Association for Computational Linguis-tics.184V.
M. S?anchez-Cartagena, J.
A. P?erez-Ortiz, andF.
S?anchez-Mart??nez.
2014.
A generalised align-ment template formalism and its application to theinference of shallow-transfer machine translationrules from scarce bilingual corpora.
ComputerSpeech and Language.
Submitted to the Special Is-sue on Hybrid Machine Translation.F.
S?anchez-Mart?
?nez and M. L. Forcada.
2009.
Infer-ring shallow-transfer machine translation rules fromsmall parallel corpora.
Journal of Artificial Intelli-gence Research, 34(1):605?635.H.
Schwenk, S. Abdul-Rauf, L. Barrault, and J. Senel-lart.
2009.
SMT and SPE Machine Transla-tion Systems for WMT?09.
In Proceedings of theFourth Workshop on Statistical Machine Translation,StatMT ?09, pages 130?134, Stroudsburg, PA, USA.Association for Computational Linguistics.M.
Snover, B. Dorr, R. Schwartz, L. Micciulla, andJ.
Makhoul.
2006.
A study of translation edit ratewith targeted human annotation.
In In Proceedingsof Association for Machine Translation in the Amer-icas, pages 223?231.F.
M. Tyers.
2009.
Rule-based augmentation of train-ing data in Breton?French statistical machine trans-lation.
In Proceedings of the 13th Annual Confer-ence of the European Association of Machine Trans-lation, pages 213?217.Y.
Xu, T. K. Ralphs, L. Lad?anyi, and M. J. Saltzman.2009.
Computational experience with a softwareframework for parallel integer programming.
IN-FORMS Journal on Computing, 21(3):383?397.185
