A Knowledge-free Method for Capitalized Word DisambiguationAndre i  M ikheev*Harlequin Ltd., L ismore House, 127 George Street, Edinburgh EH72 4JN, UKmikheev@harlequin, co. ukAbst rac tIn this paper we present an approach to the dis-ambiguation of capitalized words when they areused in the positions where capitalization is ex-pected, such as the first word in a sentence orafter a period, quotes, etc..
Such words can actas proper names or can be just capitalized vari-ants of common words.
The main feature ofour approach is that it uses a minimum of pre-built resources and tries to dynamically inferthe disambiguation clues from the entire docu-ment.
The approach was thoroughly tested andachieved about 98.5% accuracy on unseen textsfrom The New York Times 1996 corpus.1 In t roduct ionDisambiguation of capitalized words in mixed-case texts has hardly received much attentionin the natural language processing and infor-mation retrieval communities, but in fact itplays an important role in many tasks.
Cap-italized words usually denote proper names -names of organizations, locations, people, arti-facts, etc.
- but there are also other positions inthe text where capitalization is expected.
Suchambiguous positions include the first word ina sentence, words in all-capitalized titles or ta-ble entries, a capitalized word after a colon oropen quote, the first capitalized word in a list-entry, etc.
Capitalized words in these and someother positions present a case of ambiguity -they can stand for proper names as in "Whitelater said ...", or they can be just capitalizedcommon words as in "White elephants are ...".Thus the disambiguation of capitalized words inthe ambiguous positions leads to the identifica-tion of proper names I and in this paper we will* Also at HCRC, University of Edinburgh1This is not entirely true - adjectives derived from lo-cations such as American, French, etc., are always writ-use these two terms interchangeably.
Note thatthis task, does not involve the classification ofproper names into semantic ategories (person,organization, location, etc.)
which is the objec-tive of the Named Entity Recognition task.Many researchers observed that commonlyused upper/ lower case normalization does notnecessarily help document retrieval.
Church in(Church, 1995) among other simple text nor-malization techniques tudied the effect of casenormalization for different words and showedthat "...sometimes case variants refer to thesame thing (hurricane and Hurricane), some-times they refer to different things (continentaland Continental) and sometimes they don't re-fer to much of anything (e.g.
anytime and Any-time)."
Obviously these differences are due tothe fact that some capitalized words stand forproper names (such as Continental- the nameof an airline) and some don't.Proper names are the main concern of theNamed Entity Recognition subtask (Chinchor,1998) of Information Extraction.
There the dis-ambiguation of the first word of a sentence (andin other ambiguous positions) is one of the cen-tral problems.
For instance, the word "Black"in the sentence-initial position can stand fora person's surname but can also refer to thecolour.
Even in multi-word capitalized phrasesthe first word can belong to the rest of thephrase or can be just an external modifier.
Inthe sentence "Daily, Mason and Partners losttheir court case" it is clear that "Daily, Masonand Partners" is the name of a company.
In thesentence "Unfortunately, Mason and Partnerslost their court case" the name of the companydoes not involve the word "unfortunately", butten capitalized but in fact can stand for an adjective(American president) as well as a proper noun (he wasan American).159the word "Daily" is just as common a word as"unfortunately".Identification of proper names is also impor-tant in Machine Translation because normallyproper names hould be transliterated (i.e.
pho-netically translated) rather than properly (se-mantically) translated.
In confidential texts,such as medical records, proper names must beidentified and removed before making such textsavailable to unauthorized people.
And in gen-eral, most of the tasks which involve differentkinds of text analysis will benefit from the ro-bust disambiguation of capitalized words intoproper names and capitalized common words.Despite the obvious importance of this prob-lem, it was always considered part of largertasks and, to  the authors' knowledge, was notstudied closely with full attention.
In the part-of-speech tagging field, the disambiguation ofcapitalized words is treated similarly to thedisambiguation of common words.
However,as Church (1988) rightly pointed out "Propernouns and capitalized words are particularlyproblematic: some capitalized words are propernouns and some are not.
Estimates from theBrown Corpus can be misleading.
For exam-ple, the capitalized word "Acts" is found twicein Brown Corpus, both times as a proper noun(in a title).
It would be misleading to inferfrom this evidence that the word "Acts" is al-ways a proper noun."
Church then proposed toinclude only high frequency capitalized wordsin the lexicon and also label words as propernouns if they are "adjacent o" other capital-ized words.
For the rest of capitalized commonwords he suggested that a small probability ofproper noun interpretation should be assumedand then one should hope that the surroundingcontext will help to make the right assignment.This approach is successful for some cases but,as we pointed out above, a sentence-initial cap-italized word which is adjacent o other capital-ized words is not necessarily a part of a propername, and also many common nouns and pluralnouns can be used as proper names (e.g.
Rid-ers) and their contextual expectations are nottoo different from their usual parts of speech.In the Information Extraction field the dis-ambiguation of capitalized words in the am-biguous positions was always tightly linked tothe classification of the proper names into se-mantic classes such as person name, location,company name, etc.
and to the resolution ofcoreference between the identified and classi-fied proper names.
This gave rise to the meth-ods which aim at these tasks simultaneously.
(Mani&MacMillan, 1995) describe a methodof using contextual clues such as appositives("PERSON, the daughter of a prominent localphysician") and felicity conditions for identify-ing names.
The contextual clues themselves arethen tapped for data concerning the referentsof the names.
The advantage of this approachis that these contextual clues not only indicatewhether a capitalized word is a proper name,but they also determine its semantic lass.
Thedisadvantage of this method is in the cost anddifficulty of building a wide-coverage s t of con-textual clues and the dependence of these con-textual clues on the domain and text genre.Contextual clues are very sensitive to the spe-cific lexical and syntactic onstructions and theclues developed for the news-wire texts are notuseful for legal or medical texts.In this paper we present a novel approach tothe problem of capitalized word disambiguation.The main feature of our approach is that it usesa minimum of pre-built resources and tries todynamically infer the disambiguation clues fromthe entire document under processing.
Thismakes our approach domain and genre inde-pendent and thus inexpensive to apply whendealing with unrestricted texts.
This approachwas used in a named entity recognition system(Mikheev et al, 1998) where it proved to beone of the key factors in the system achieving anearly human performance in the 7th MessageUnderstanding Conference (MUC'7) evaluation(Chinchor, 1998).2 Bot tom-L ine  Per fo rmanceIn general, the disambiguation of capitalizedwords in the mixed case texts doesn't seem tobe too difficult: if a word is capitalized in an un-ambiguous position, e.g., not after a period orother punctuation which might require the fol-lowing word to be capitalized (such as quotes orbrackets), it is a proper name or part of a multi-word proper name.
However, when a capitalizedword is used in a position where it is expectedto be capitalized, for instance, after a period orin a title, our task is to decide whether it acts160Total WordsProper NamesCommon WordsAll Wordstokens types2,677 665826 3391,851 326Known Wordstokens types2,012 384171 681,841 316Unknown Wordstokens types665 281655 27110 10Table 1: Distribution of capitalized word-tokens/word-types in the ambiguous positions.as a proper name or as the expected capitalizedcommon word.The first obvious strategy for decidingwhether a capitalized word in an ambiguous po-sition is a proper name or not is to apply lexi-con lookup (possibly enhanced with a morpho-logical word guesser, e.g., (Mikheev, 1997)) andmark as proper names the words which are notlisted in the lexicon of common words.
Let usinvestigate this strategy in more detail: In ourexperiments we used a corpus of 100 documents(64,337 words) from The New York Times 1996.This corpus was balanced to represent differentdomains and was used for the formal test runof the 7th Message Understanding Conference(MUC'7) (Chinchor, 1998) in the Named En-tity Recognition task.First we ran a simple zoner which identi-fied ambiguous positions for capitalized words -capitalized words after a period, quotes, colon,semicolon, in all-capital sentences and titlesand in the beginnings of itemized list entries.The 64,337-word corpus contained 2,677 cap-italized words in ambiguous positions, out ofwhich 2,012 were listed in the lexicon of En-glish common words.
Ten common words werenot listed in the lexicon and not guessed by ourmorphological guesser: "Forecasters", "Bench-mark", "Eeverybody", "Liftoff", "Download-ing", "Pretax", "Hailing", "Birdbrain", "Opt-ing" and "Standalone".
In all our experimentswe did not try to disambiguate between singu-?
lar and plural proper names and we also didnot count as an error the adjectival reading ofwords which are always written capitalized (e.g.American, Russian, Okinawian, etc.).
The dis-tribution of proper names among the ambiguouscapitalized words is shown in Table 1.Table 1 allows one to estimate the perfor-mance of the lexicon lookup strategy which wetake as the bottom-line.
First, using this strat-egy we would wrongly assign the ten commonwords which were not listed in the lexicon.
Moredamaging is the biind assignment of the com-mon word category to the words listed in thelexicon: out of 2,012 known word-tokens 171actually were used as proper names.
This in to-tal would give us 181 errors out of 2,677 tries- about a 6.76% misclassification error on capi-talized word-tokens in the ambiguous positions.The lexicon lookup strategy can be enhancedby accounting for the immediate context of thecapitalized words in question.
However, cap-italized words in the ambiguous positions arenot easily disambiguated by their surroundingpart-of-speech context as attempted by part-of-speech taggers.
For instance, many surnamesare at the same time nouns or plural nouns inEnglish and thus in both variants can be fol-lowed by a past tense verb.
Capitalized wordsin the phrases Sails rose ... or Feeling him-sell.., can easily be interpreted either way andonly knowledge of semantics disallows the pluralnoun interpretation of Stars can read.Another challenge is to decide whether thefirst capitalized word belongs to the group of thefollowing proper nouns or is an external modifierand therefore not a proper noun.
For instance,All American Bank is a single phrase but in AllState Police the word "All" is an external mod-ifier and can be safely decapitalized.
One mightargue that a part-of-speech tagger can capturethat in the first case the word "All" modified asingular proper noun ("Bank") and hence is notgrammatical as an external modifier and in thesecond case it is a grammatical external modi-fier since it modifies a plural proper noun ("Po-lice") but a simple counter-example - All Amer-ican Games - defeats this line of reasoning.The third challenge is of a more local nature- it reflects a capitalization convention adoptedby the author.
For instance, words which re-flect the occupation of a person can be used inan honorific mode e.g.
"Chairman Mao" vs.161"ATT chairman Smith" or "Astronaut MarioRunko" vs. "astronaut Mario Runko".
Whensuch a phrase opens a sentence, looking at thesentence only, even a human classifier has trou-bles in making a decision.To evaluate the performance of part-of-speechtaggers on the proper-noun identification taskwe ran an HMM trigram tagger (Mikheev, 1997)and the Brill tagger (Brill,.1995) on our cor-pus.
Both taggers used the Penn Treebank tag-set and were trained on the Wall Street Jour-nal corpus (Marcus et al, 1993).
Since for ourtask the mismatch between plural proper noun(NNPS) and singular proper noun (NNP) was notimportant we did not count this as an error.
De-pending on the smoothing technique, the HMMtagger performed in the range of 5.3%-4.5% ofthe misclassification error on capitalized com-mon words in the ambiguous positions, and theBrill tagger showed a similar pattern when wevaried the lexicon acquisition heuristics.The taggers handled the cases when a poten-tial adjective was followed by a verb or adverb( "Golden added .. ") well but they got confusedwith a potential noun followed by a verb oradverb ( "Butler was .." vs. "Safety was .. "),probably because the taggers could not distin-guish between concrete and mass nouns.
Notsurprisingly the taggers did not do well on po-tential plural nouns and gerunds - none of themwere assigned as a proper noun.
The taggersalso could not handle the case when a poten-tial noun or adjective was followed by anothercapitalized word ("General Accounting Office")well.
In general, when the taggers did not havestrong lexical preferences, apart from severalobvious cases they tended to assign a commonword category to known capitalized words in theambiguous positions and the performance of thepart-of-speech tagging approach was only about2% superior to the simple bottom-line strategy.3 Our  Knowledge-Free  MethodAs we discussed above, the bad news (well, notreally news) is that virtually any common wordcan potentially act as a proper name or part ofa multi-word proper name.
Fortunately, thereis good news too: ambiguous things are usu-ally unambiguously introduced at least once inthe text unless they are part of common knowl-edge presupposed to be known by the readers.This is an observation which can be applied toa broader class of tasks.
For example, peopleare often referred to by their surnames (e.g.
"Black") but usually introduced at least oncein the text either with their first name ("JohnBlack") or with their title/profession affiliation("Mr. Black", "President Bush") and it is onlywhen their names are common knowledge thatthey don't need an introduction ( e.g.
"Castro","Gorbachev").In the case of proper name identification weare not concerned with the semantic class of aname (e.g.
whether it is a person name or loca-tion) but we simply want to distinguish whetherthis word in this particular occurrence acts asa proper name or part of a multi-word propername.
If we restrict our scope only to a singlesentence, we might find that there is just notenough information to make a confident deci-sion.
For instance, Riders in the sentence "Rid-ers said later.." is equally likely to be a propernoun, a plural proper noun or a plural com-mon noun but if in the same text we find "JohnRiders" this sharply increases the proper nouninterpretation and conversely if we find "manyriders" this suggests the plural noun interpre-tation.
Thus our suggestion is to look at theunambiguous usage of the words in question inthe entire document.3.1 The  Sequence  St ra tegyOur first strategy for the disambiguation of cap-italized words in ambiguous positions is to ex-plore sequences of proper nouns in unambigu-ous positions.
We call it the Sequence Strategy.The rationale behind this is that if we detect aphrase of two or more capitalized words and thisphrase starts from an unambiguous position wecan be reasonably confident hat even when thesame phrase starts from an unreliable positionall its words still have to be grouped togetherand hence are proper nouns.
Moreover, this ap-plies not just to the exact replication of  such aphrase but to any partial ordering of its words ofsize two or more preserving their sequence.
Forinstance, if we detect a phrase Rocket SystemsDevelopment Co. in the middle of a sentence,we can mark words in the sub-phrases RocketSystems, Rocket Systems Co., Rocket Co., Sys-terns Development, etc.
as proper nouns even ifthey occur at the beginning of a sentence or inother ambiguous positions.
A span of capital-162Proper Names Common Words TotalAll AmbiguousDisambiguated +Sequence Strategy +Single Word +AssignmentStop-List -t-AssignmentAll Wordstokens types826 3397951620Known Words All Wordstokens types tokens types171 68 1,851 32654 1,568 2181 8 81483Known Words All Wordstokens types tokens types1,841 316 2,677 6651,563 2133 30 00 05101007001,265 1433 3316 1401 125 320 0192 1081 10 00 099 00 011 00 043 1,2701 30 2980 00 00 5298 7002,363 5349 962 250 01,780 3404 4298 700 0 0Lexicon Lookup + 223 0 0 0 223 99Assignment - 0 5 0 0 5 5Left Unassigned 30 22 30 22 275 100 275 100 305 122Table 2: Disambiguated capitalized word-tokens/types in the ambiguous positions.ized words can also include lower-cased words oflength three or shorter.
This allows us to cap-ture phrases like A ~ M, The Phantom of theOpera., etc.
We generate partial orders fromsuch phrases in a similar way but insist that ev-ery generated sub-phrase should start and endwith a capitalized word.To make the Sequence Strategy robust to po-tential capitalization errors in the document wealso use a set of negative vidence.
This set isessentially a set of all lower-cased words of thedocument with their following words (bigrams).We don't attempt here to build longer sequencesand their partial orders because we cannot ingeneral restrict the scope of dependencies insuch sequences.
The negative vidence is thenused together with the positive evidence of theSequence Strategy and block the proper nameassignment when controversy is found.
For in-stance, if in a document he system detects acapitalized phrase "The President" in an un-ambiguous position, then it will be assigned asa proper name even if found in ambiguous po-sitions in the same document.
To be more pre-cise the method will assign the word "The" as aproper noun since it should be grouped togetherwith the word "President" into a single propername.
However, if in the same document hesystem detects an alternative vidence .g.
"thePresident" or "the president" - it then blockssuch assignment as unsafe.The Sequence Strategy strategy is extremelyuseful when dealing with names of organizationssince many of them are multi-word phrases com-posed from common words.
And indeed, as isshown in Table 2, the precision of this strat-egy was 100% and the recall about 7.5%: outof 826 proper names in ambiguous positions, 62were marked and all of them were marked cor-rectly.
If we concentrate only on difficult caseswhen proper names are at the same time com-mon words of English, the recall of the SequenceStrategy rises to 18.7%: out of 171 commonwords which acted as proper names 32 were cor-rectly marked.
Among such words were "News"from "News Corp.", "Rocket" from "RocketSystems Co.", "Coast" from "Coast Guard" and"To" from "To B. Super".3.2 Single Word Ass ignmentThe Sequence Strategy is accurate, but it cov-ers only a part of potential proper names inambiguous positions and at the same time itdoes not cover cases when capitalized words donot act as proper names.
For this purpose wedeveloped another strategy which also uses in-formation from the entire document.
We callthis strategy Single Word Assignment,  and itcan be summarized as follows: if we detect aword which in the current document is seencapitalized in an unambiguous position and atthe same time it is not used lower-cased, thisword in this particular document, even when163used capitalized in ambiguous positions, is verylikely to stand for a proper name as well.
Andconversely, if we detect a word which in thecurrent document is used only lower-cased inunambiguous positions, it is extremely unlikelythat this word will act as a proper name in anambiguous position and thus, such a word canbe marked as a common word.
The only consid-eration here should be made for high frequencysentence-initial words which do not normallyact as proper names: even if such a word isobserved in a document only as a proper name(usually as part of a multi-word proper name),it is still not safe to mark it as a proper name inambiguous positions.
Note, however, that thesewords can be still marked as proper names (orrather as parts of proper multi-word names) bythe Sequence Strategy.
To build such list ofstop-words we ran the Sequence Strategy andSingle Word Assignment on the Brown Corpus(Francis&Kucera, 1982), and reliably collected100 most frequent sentence-initial words.Table 2 shows the success of the Single WordAssignment strategy: it marked 511 propernames from which 510 were marked correctly,and it marked 1,273 common words from which1,270 were marked correctly.
The only wordwhich was incorrectly marked as a proper namewas the word "Insurance" in "Insurance com-pany ..." because in the same document therewas a proper phrase "China-Pacific InsuranceCo."
and no lower-cased occurrences of theword "insurance" were found.
The three wordsincorrectly marked as common words were:"Defence" in "Defence officials ..", "Trade" in"Trade Representation ffice .." and "Satellite"in "Satellite Business News".
Five out of tenwords which were not listed in the lexicon ("Pre-tax", "Benchmark", "Liftoff', "Downloading"and "Standalone") were correctly marked ascommon words because they were found to ex-ist lower-cased in the text.
In general the errorrate of the assignment by this method was 4 outof 1,784 which is less than 0.02%.
It is interest-ing to mention that when we ran Single WordAssignment without the stop-list, it incorrectlymarked as proper names only three extra com-mon words ("For", "People" and "MORE").3.3 Tak ing  Care  of  the  RestAfter Single Word Assignment we applied a sim-ple strategy of marking as common words allunassigned words which were found in the stop-list of the most frequent sentence-initial words.This gave us no errors and covered extra 298common words.
In fact, we could use this strat-egy before Single Word Assignment, since thewords from the stop-list are not marked at thatpoint anyway.
Note, however, that the SequenceStrategy still has to be applied prior to the stop-list assignment.
Among the words which failedto be assigned by either of our strategies were243 proper names, but only 30 of them werein fact ambiguous, since they were listed in thelexicon of common words.
So at this point wemarked as proper names all unassigned wordswhich were not listed in the lexicon of commonwords.
This gave us 223 correct assignmentsand 5 incorrect ones - the remaining five out ofthese ten common words which were not listedin the lexicon.
So, in total, by the combinationof the described methods we achieved aprecision of correct ly -ass igned __ 2363 - -  99.62%al l_assigned - -  2363+9-and  a reca l l  of  al l_assigned __ 2363+9 __ 88 .7%.total_ambiguous - -  2677 - -Now we have to decide what to do with the re-maining 305 words which failed to be assigned.Among such words there are 275 common wordsand 30 proper names, so if we simply mark allthese words as common words we will increaseour recall to 100% with some decrease in pre-cision - from 99.62% down to 98.54%.
Amongthe unclassified proper names there were a fewwhich could be dealt by a part-of-speech tag-get: "Gray, chief...", "Gray said...", "Bill Lat-tanzi...", "Bill Wade...", "Bill Gates...", "Burns, an..." and "..Golden added".
Another four un-classified proper names were capitalized wordswhich followed the "U.S." abbreviation e.g."U.S.
Supreme Court".
This is a difficult caseeven for sentence boundary disambiguation sys-terns ((Mikheev, 1998), (Palmer&Hearst, 1997)and (Reynar&Ratnaparkhi, 1997)) which arebuilt for exactly that purpose, i.e., to decidewhether a capitalized word which follows an ab-breviation is attached to it or whether there is asentence boundary between them.
The "U.S."abbreviation is one of the most difficult onesbecause it can be as often seen at the end ofa sentence as in the beginning of multi-wordproper names.
Another nine unclassified propernames were stable phrases like "Foreign Min-ister", "Prime Minister", "Congressional Re-publicans", "Holy Grail", etc.
mentioned just164once in a document.
And, finally, about sevenor eight unclassified proper names were diffi-cult to account for at all e.g.
"Sate-owned"or "Freeman Zhang".
Some of the above men-tioned proper names could be resolved if we ac-cumulate multi-word proper names across sev-eral documents, i.e., we can use informationfrom one document when we deal with another.This can be seen as an extension to our Se-quence Strategy with the only difference thatthe proper noun sequences have to be taken notonly from the current document but from thecache memory and all multi-word proper namesidentified in a document are to be appendedto that cache.
When we tried this strategy onour test corpus we were able to correctly assign14 out of 30 remaining proper names which in-creased the system's precision on the corpus to99.13% with 100% recall.4 D iscuss ionIn this paper we presented an approach to thedisambiguation of capitalized common wordswhen they are used in positions where capi-talization is expected.
Such words can act asproper names or can be just capitalized variantsof common words.
The main feature of our ap-proach is that it uses a minimum of pre-builtresources - we use only a list of common wordsof English and a list of the most frequent wordswhich appear in the sentence-stating positions.Both of these lists were acquired without anyhuman intervention.
To compensate for the lackof pre-acquired knowledge, the system tries toinfer disambiguation clues from the entire doc-ument itself.
This makes our approach domainindependent and closely targeted to each docu-ment.
Initially our method was developed usingthe training data of the MUC-7 evaluation andtested on the withheld test-set as described inthis paper.
We then applied it to the BrownCorpus and achieved similar results with degra-dation of only 0.7% in precision, mostly due tothe text zoning errors and unknown words.
Wedeliberately shaped our approach so it does notrely on pre-compiled statistics but rather actsby analogy.
This is because the most interest-ing events are inherently infrequent and, hence,are difficult to collect reliable statistics for, andat the same time pre-compiled statistics wouldbe smoothed across multiple documents ratherthan targeted to a specific document.The main strategy of our approach is to scanthe entire document for unambiguous usages ofwords which have to be disambiguated.
Thefact that the pre-built resources are used onlyat the latest stages of processing (Stop-ListAssignment and Lexicon Lookup Assignment)ensures that the system can handle unknownwords and disambiguate ven very implausibleproper names.
For instance, it correctly as-signed five out of ten unknown common words.Among the difficult cases resolved by the sys-tem were a multi-word proper name "To B. Su-per" where both "To" and "Super" were cor-rectly identified as proper nouns and a multi-word proper name "The Update" where "The"was correctly identified as part of the maga-zine name.
Both "To" and "The" were listedin the stop-list and therefore were very implau-sible to classify as proper nouns but neverthe-less the system handled them correctly.
In itsgeneric configuration the system achieved pre-cision of 99.62% with recall of 88.7% and preci-sion 98.54% with 100% recall.
When we en-hanced the system with a multi-word propername cache memory the performance improvedto 99.13% precision with 100% recall.
This isa statistically significant improvement againstthe bottom-line performance which fared about94% precision with 100% recall.One of the key factors to the success in theproposed method is an accurate zoning of thedocuments.
Since our method relies on the cap-italization in unambiguous positions - such po-sitions should be robustly identified.
In thegeneral case this is not too difficult but oneshould take care of titles, quoted speech andlist entries - otherwise if treated as ordinarytext they can provide false candidates for cap-italization.
Our method in general is not toosensitive to the capitalization errors: the Se-quence Strategy is complimented with the neg-ative evidence.
This together with the fact thatit is rare when several words appear by mistakemore than once makes this strategy robust.
TheSingle Word Assignment strategy uses the stoplist which includes the most frequent commonwords.
This screens out many potential errors.One notable difficulty for the Single Word As-signment represent words which denote profes-sion/title affiliations.
These words modifying165a person name might require capitalization -"Sheriff John Smith", but in the same docu-ment they can appear lower-cased - "the sher-iff".
When the capitalized variant occurs onlyas sentence initial our method predicts that itshould be decapitalized.
This, however, is anextremely difficult case even for human index-ers - some writers tend to use certain profes-sions such as Sheriff, Governor, Astronaut, etc.,as honorific affiliations and others tend to dootherwise.
This is a generally difficult case forSingle Word Assignment - when a word is usedas a proper name and as a common word inthe same document, and especially when one ofthese usages occurs only in an ambiguous posi-tion.
For instance, in a document about steelthe only occurrence of "Steel Company" hap-pened to start a sentence.
This lead to an er-roneous assignment of the word "Steel" as com-mon noun.
Another example: in a documentabout "the Acting Judge", the word "acting"in a sentence "Acting on behalf.." was wronglyclassified as a proper name.The described approach is very easy to imple-ment and it does not require training or installa-tion of other software.
The system can be usedas it is and, by implementing the cache mem-ory of multi-word proper names, it can be tar-geted to a specific domain.
The system can alsobe used as a pre-processor to a part-of-speechtagger or a sentence boundary disambiguationprogram which can try to apply more sophisti-cated methods to unresolved capitalized wordsIn fact, as a by-product of its performance,our system disambiguated about 17% (9 out of60) of ambiguous entence boundaries when anabbreviation was followed by a capitalized word.Apart from collecting an extensive cache ofmulti-word proper names, another useful strat-egy which we are going to test in the future isto collect a list of common words which, at thebeginning of a sentence, act most frequently asproper names and to use such a list in a simi-lar fashion to the list of stop-words.
Such a listcan be collected completely automatically butthis requires a corpus or corpora much largerthan the Brown Corpus because the relevantsentences are rather infrequent.
We are alsoplanning to investigate the sensitivity of ourmethod to the document size in more detail.Re ferencesBrill E. 1995 "Transformation-based error-drivenlearning and natural language parsing: a casestudy in part-of-speech tagging" In Computa-tional Linguistics 21 (4), pp.
543-565N.
Chinchor 1998 Overview of MUC-7.
InSeventh Message Understanding Conference(MUC- 7) : Proceedings of a Conferenceheld in Fairfax, VA, April 29-May 1, 1998.www.
muc.
saic.
com/muc_7_proceedings/overwiew, htmlK.
Church 1995 "One Term Or Two?"
In Pro-ceedings of the 18th Annual Internationals ACMSIGIR Conference on Research and Developmentin Information Retrieval (SIGIR'95), SeattleK.
Church 1988 A Stochastic parts program andnoun-phrase parser for unrestricted text.
In Pro-ceedings of the Second A CL Conference on Ap-plied Natural Language Processing (ANLP'88),Austin, TexasW.
Francis and H. Kucera 1982 Frequency Analysisof English Usage.
Boston MA: Houghton Mifflin.D.
D. Palmer and M. A. Hearst 1997.
Adaptive Mul-tilingual Sentence Boundary Disambiguation.
InComputational Linguistics, 23 (2), pp.
241-269I.
Mani and T.R.
MacMillan 1995 IdentifyingUnknown Proper Names in Newswire Text InB.
Boguraev and J. Pustejovsky, eds., CorpusProcessing for Lexical Acquisition, MIT Press.M.
Marcus, M.A.
Marcinkiewicz, and B. Santorini1993.
Building a Large Annotated Corpus of En-glish: The Penn Treebank.
In Computational Lin-guistics, vol 19(2), ACL.A.
Mikheev.
1998 "Feature Lattices for Maxi-mum Entropy Modelling" In Proceedings of the36th Conference of the Association for Compu-tational Linguistics (A CL/COLING'98), pp 848-854.
Montreal, Quebec.A.
Mikheev.
1997 "Automatic Rule Induction forUnknown Word Guessing."
In ComputationalLinguistics 23 (3), pp.
405-423A.
Mikheev.
1997 "LT POS - the LTGpart of speech tagger."
Language Tech-nology Group, University of Edinburgh.www.
Itg.
ed.
ac.
uk/software/posA.
Mikheev, C. Grover and M. Moens 1998 De-scription of the LTG system used for MUC-7.In Seventh Message Understanding Confer-ence (MUC-7): Proceedings of a Conferenceheld in Fairfax, VA, April 29-May I, 1998.www.muc, saic.
com/muc_7_proceedings/ltg-muc7.
psJ.
C. Reynar and A. Ratnaparkhi 1997.
A Max-imum Entropy Approach to Identifying SentenceBoundaries.
In Proceedings of the Fifth A CL Con-ference on Applied Natural Language Processing(ANLP'97), Washington D.C., ACL.166
