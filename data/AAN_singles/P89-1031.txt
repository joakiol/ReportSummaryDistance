EVALUATING DISCOURSE PROCESSING ALGORITHMSMarilyn A. WalkerHewlett Packard LaboratoriesFi lton Rd., Bristol, England B$12 6QZ, U.K.& University of Pennsylvanialyn%lwalker~hplb.hpl .hp.comAbstractIn order to take steps towards establishing a method-ology for evaluating Natural Language systems, weconducted a case study.
We attempt to evaluate twodifferent approaches to anaphoric processing in dis-course by comparing the accuracy and coverage oftwo published algorithms for finding the co-specifiersof pronouns in naturally occurring texts and dia-logues.
We present the quantitative r sults of hand-simulating these algorithms, but this analysis natu-rally gives rise to both a qualitative valuation andrecommendations for performing such evaluations ingeneral.
We illustrate the general difficulties encoun-tered with quantitative evaluation.
These are prob-lems with: (a) allowing for underlying assumptions,(b) determining how to handle underspecifications,and (c) evaluating the contribution of false positivesand error chaining.1 Introduct ionIn the course of developing natural anguage inter-faces, computational linguists are often in the posi-tion of evaluating different theoretical pproaches tothe analysis of natural anguage (NL).
They mightwant to (a) evaluate and improve on a current sys-tem, (b) add a capability to a system that it didn'tpreviously have, (c) combine modules from differentsystems.Consider the goal of adding a discourse compo-nent to a system, or evaluating and improving onethat is already in place.
A discourse module mightcombine theories on, e.g., centering or local focus-ing \[GJW83, Sid79\], global focus \[Gro77\], coher-ence relations\[Hob85\], event" reference \[Web86\], in-tonational structure \[PH87\], system vs. user be-liefs \[Po186\], plan or intent recognition or production\[(3o578, AP86, SIS1\], control\[WSSS\], or complex syn-tactic structures \[Pri85\].
How might one evaluate therelative contributions ofeach of these factors or com-pare two approaches to the same problem?In order to take steps towards establishing amethodology for doing this type of comparison, weconducted a case study.
We attempt o evalu-ate two different approaches to anaphoric processingin discourse by comparing the accuracy and cover-age of two published algorithms for finding the co-specifiers of pronouns in naturally occurring texts anddialogues\[Hob76b, BFP87\].
Thus there are two partsto this paper: we present he quantitative r sults ofhand-simulating these algorithms (henceforth Hobbsalgorithm and BFP algorithm), but this analysis nat-urally gives rise to both a qualitative valuation andrecommendations for performing such evaluations ingeneral.
We illustrate the general difficulties encoun-tered with quantitative evaluation.
These are prob-lems with: (a) allowing for underlying assumptions,(b) determining how to handle underspecifications,and (c) evaluating the contribution of false positivesand error chaining.Although both algorithms are part of theories ofdiscourse that posit the interaction of the algorithmwith an inference or intentional component, we willnot use reasoning in tandem with the algorithm's op-eration.
We have made this choice because we wantto be able to analyse the performance of the algo-rithms across different domains.
We focus on thelinguistic basis of these approaches, using only selec-tional restrictions, so that our analysis is independentof the vagaries of a particular knowledge representa-tion.
Thus what we are evaluating is the extent towhich these algorithms suffice to narrow the searchof an inference component I.
This analysis gives usl But  note the def init ion of success in sect ion 2.1.251some indication of the contribution of syntactic on-straints, task structure and global focus to anaphoricprocessing.The data on which we compare the algorithms areimportant if we are to evaluate claims of general-ity.
If we look at types of NL input, one clear di-vision is between textual and interactive input.
Arelated, though not identical factor is whether thelanguage being analysed is produced by more thanone person, although this distinction may be con-fluted in textual material such as novels that containreported conversations.
Within two-person interac-tive dialogues, there are the task-oriented master-slave type, where all the expertise and hence muchof the initiative, rests with one person.
In other two-person dialogues, both parties may contribute dis-course entities to the conversation on a more equalbasis.
Other factors of interest are whether the di-alogues are human-to-human or human-to-computer,as well as the modality of communication, e.g.
spokenor typed, since some researchers have indicated thatdialogues, and particularly uses of reference withinthem, vary along these dimensions \[Coh84, Tho80,GSBC86, D J89, WS89\].We analyse the performance of the algorithms onthree types of data.
Two of the samples are those thatHobbs used when developing his algorithm.
One is anexcerpt from a novel and the other a sample of jour-nalistic writing.
The remaining sample is a set of 5human-human, keyboard-mediated, task-oriented di-alogues about the assembly of a plastic water pump\[Coh84\].
This covers only a subset of the above types.Obviously it would be instructive to conduct a similaranalysis on other textual types.2 QuantitativeEvaluati0n-Black Box2.1 The  A lgor i thmsWhen embarking on such a comparison, it would beconvenient to assume that the inputs to the algo-rithms are identical and compare their outputs.
Un-fortunately since researchers do not even agree onwhich phenomena can be explained syntactically andwhich semantically, the boundaries between two mod-ules are rarely the same in NL systems.
In this casethe BFP centering algorithm and Hobbs algorithmboth make ASSUMPTIONS about other system com-ponents.
These are, in some sense, a further specifi-cation of the operation of tile algorithms that mustbe made in order to hand-simulate the algorithms.There are two major sets of assumptions, based ondiscourse segmentation and syntactic representation.We attempt o make these explicit for each algorithmand pinpoint where the algorithms might behave dif-ferently were these assumptions not well-founded.In addition, there may be a number of UNDER-SPECIFICATIONS in the descriptions of the algorithms.These often arise because theories that attempt ocategorize naturally occurring data and algorithmsbased On them will always be prey to previously un-encountered examples.
For example, since the BFPsalience hierarchy for discourse ntities is based ongrammatical relation, an implicit assumption is thatan utterance only has one subject.
However the novelWheels has many examples of reported ialogue suchas She continued, unperturbed, ~Mr.
Vale quotesthe Bible about air pollution."
One might wonderwhether the subject is She or Mr. Vale.
In somecases, the algorithm might need to be further speci-ficied in order to be able to process any of the data,whereas in others they may just highlight where thealgorithm needs to be modified (see section 3.2).
Ingeneral we count underspecifications as failures.Finally, it may not be clear what the DEFINITIONOF SUCCESS is.
In particular it is not clear what todo in those cases where an algorithm produces multi-ple or partial interpretations.
In this situation a sys-tem might flag the utterance as ambiguous and drawin support from other discourse components.
Thisarises in the present analysis for two reasons: (1) theconstraints given by \[GJW86\] do not always allowone to choose a preferred interpretation, (2) the BFPalgorithm proposes equally ranked interpretations inparallel.
This doesn't happen with the Robbs algo-rithm because it proposes interpretations in a sequen-tial manner, one at a time.
We chose to count as afailure those situations in which the BFP algorithmonly reduces the number of possible interpretations,but Robbs algorithm stops with a correct interpre-tation.
This ignores the fact that tIobbs may haverejected a number of interpretations before stopping.We also have not needed to make a decision on how toscore an algorithm that only finds one interpretationfor an utterance that humans find ambiguous.2.1.1 Centering algorithmThe centering algorithm as defined by Brennan,Friedman and Pollard, (BFP algorithm), is derivedfrom a set of rules and constraints put forth by Grosz,252Joshi and Weinstein \[GJW83, GJW86\].
We shall notreproduce this algorithm here (See \[BFP87\]).
Thereare two main structures in the centering algorithm,the CB, the BACKWARD LOOKING CENTER, which iswhat the discourse is 'about',  and an ordered list,CF, of FORWARD LOOKING CENTERS, which are thediscourse entities available to the next utterance forpronorninalization.
The centering framework predictsthat in a local coherent stretch of dialogue, speakerswill prefer to CONTINUE talking about the same dis-course entity, that the CB will be the highest rankedentity of the previous utterance's forward centers thatis realized in the current utterance, and that if any-thing is pronominalized the CB must be.In the centering framework, the order of theforward-centers list is intended to reflect the salienceof discourse entities.
The BFP  algorithm orders thislist bY grammatical relation of the complements ofthe main verb, i.e.
first the subject, then object,then indirect object, then other subcategorized-forcomplements, then noun phrases found in adjunctclauses.
This captures the intuition that subjects aremore salient than other discourse entities.The BFP  algorithm added linguistic constraintson CONTRA-INDEXING to the centering framework.These constraints are exemplified by the fact that,in the sentence he Hkes him, the entity cospecified byhe cannot be the same as that cospecified by him.
Wesay that he and him are CONTRA-INDEXED.
The BFPalgorithm depends on semantic processing to precom-pute these constraints, since they are derived fromthe syntactic structure, and depend on some notionof c-command\[Rei76\].
The other assumption that isdependent on syntax is that the the representationsof discourse entities can be marked with the gram-matical function through which they were realized,e.g.
subject.The BFP  algorithm assumes that some other mech~anism can structure both written texts and task-oriented dialogues into hierarchical segments.
Thepresent concern is not with whether there might bea grammar of discourse that determines this struc-ture, or whether it is derived from the cues thatcooperative speakers give hearers to aid in process-ing.
Since centering is a local phenomenon and isintended to operate within a segment, we needed todeduce a segmental structure in order to analyse thedata.
Speaker's intentions, task structure, cue wordslike O.K.
now.., intonational properties of utterances,coherence relations, the scoping of modal, operators,and mechanisms for shift'ing control between dis-course participants have all been proposed as waysof determining discourse segmentation \[Gro77, GS86,Rei85, PH87, HL87, Hob78, Hob85, Rob88, WS88\].Here, we use a combination of orthography, anaphoradistribution, cue words and task structure.
The rulesare"?
In published texts, a paragraph is a new seg-ment unless the first sentence has a pronoun insubject position or a pronoun where none of thepreceding sentence-internal noun phrases matchits syntactic features.?
In the task-oriented dialogues, the action PICK-UP marks task boundaries hence segment bound-aries.
Cue words like nezt, then, and now alsomark segment boundaries.
These will usually co-occur but either one is sufficient for marking asegment boundary.BFP never state that cospecifiers for pronounswithin the same segment are preferred over those inprevious segments, but this is an implicit assump-tion, since this line of research is derived from Sid-ner's work on local focusing.
Segment initial utter-ances therefore are the only situation where the BFPalgorithm will prefer a within-sentence noun phraseas the cospecifier of a pronoun.2.1.2 Hobbs  ~ a lgor i thmThe Hobbs algorithm is based on searching for apronoun's co-specifier in the syntactic parse tree ofinput sentences \[Hob76b\].
We reproduce this algo-rithm in full in the appendix along with an example.Hobbs algorithm operates on one sentence at a time,but the structure of previous sentences in the dis-course is available.
It is stated in terms of searcheson parse trees.
When looking for an intrasententialantecedent, these searches are conducted in a left-to-right, breadth-first manner.
However, when lookingfor a pronoun's antecedent within a sentence, it willgo sequentially further and further up the tree to theleft of the pronoun, and that failing will look in theprevious sentence.
Hobbs does not assume a segmen-tation of discourse structure in this algorithm; thealgorithm will go back arbitrarily far in the text tofind an antecedent.
In more recent work, Hobbs usesthe notion of COHERENCE RELATIONS to structure thediscourse \[HM87\].The order by which Hobbs' algorithm traverses theparse tree is the closest thing in his framework to pre-dictions about which discourse entities are salient.
Inthe main it prefers co-specifiers for pronouns that253are within the same sentence, and also ones thatare closer to the pronoun in tile sentence.
Thisamounts to a claim that different discourse ntitiesare salient, depending on the position of a pronounin a sentence.
When seeking an intersentential co-specification, Hobbs algorithm searches the parse treeof the previous utterance breadth-first, from left toright.
This predicts that entities realized in subjectposition are more salient, since even if an adjunctclause linearly precedes the main subject, any nounphrases within it will be deeper in the parse tree.
Thisalso means that objects and indirect objects will beamong the first possible antecedents found, and ingeneral that the depth of syntactic embedding is animportant determiner of discourse prominence.Turning to the assumptions about syntax, we notethat Hobbs assumes that one can produce the cor-rect syntactic structure for an utterance, with all ad-junct phrases attached at the proper point of theparse tree.
In addition, in order to obey linguisticconstraints on coreference, the algorithm depends onthe existence of a N parse tree node, which denotesa noun phrase without its determiner (See the ex-ample in the Appendix).
Hobbs algorithm procedu-rally encodes contra-indexing constraints by skippingover NP  nodes whose N node dominates the part ofthe parse tree in which the pronoun is found, whichmeans that he cannot guarantee that two contra-indexed pronouns will not choose the same NP asa co-specifier.Hobbs also assumes that his algorithm can some-how collect discourse entities mentioned alone intosets as co-specifiers of plural anaphors.
Hobbs dis-cusses at length other assumptions that he makesabout the capabilities of an interpretive process thatoperates before the algorithm \[Hob76b\].
This in-cludes such things as being able to recover syntac-tically recoverable omitted text, such as elided verbphrases, and the identities of the speakers and hearersin a dialogue.2.1.3 SummaryA major component of any discourse algorithm is theprediction of which entities are salient, even thoughall the factors that contribute to the salience of a dis-course entity have not been identified \[Pri81, Pri85,BF83, HTD86\].
So an obvious question is when thetwo algorithms actually make different predictions.The main difference is that the choice of a co-specifierfor a pronoun in the Hobbs algorithm depends in parton the position of that pronoun in the sentence.
Inthe centering framework, no matter what criteria oneuses to order the forward-centers li t, pronouns takethe most salient entities as antecedents, irrespectiveof that pronoun's position.
Hobbs ordering of enti-ties from a previous utterance varies from BFP inthat possessors come before case-marked objects andindirect objects, and there may be some other differ-ences as well but none of them were relevant o theanalysis that follows.The effects ot" some of the assumptions are mea-surable and we will attempt o specify exactly whatthese effects are, however some are not, e.g.
we can-not measure the effect of Hobbs' syntax assumptionsince it is difficult to say how likely one is to get thewrong parse.
We adopt the set collection assumptionfor both algorithms as well as the ability to recoverthe identity of speakers and hearers in dialogue.2.2 Quant i ta t ive  Resu l ts  o f  the  A lgo -r i thmsThe texts on which the algorithms are analysed arethe first chapter of Arthur Hailey's novel Wheels, andthe July 7, 1975 edition of Newsweek.
The sentencesin Wheels are short and simple with long sequencesconsisting of reported conversation, so it is similar toa conversational text.
The articles from Newsweekare typical of journalistic writing.
For each text,the first 100 occurrences of singular and plural third-person pronouns were used to test the performance ofthe algorithms.
The task-dialogues contain a total of81 uses of it and no other pronouns except for I andyou.
In the figures below note that possessives likeh/a are counted along with he and that accusativeslike him and her are counted as he and she 2.WheelsNewsweekTasksN Hobbs100 .88100 8981 51BFP907949Figure I: Number correct for both algorithms forWheels, Newsweek and Task DialoguesWe performed three analyses on the quantitativeresults.
A comparison of the two algorithms on eachdata set individually and an overall analysis on thethree data sets combined revealed no significant digferences in the performance of the two algorithms2Hobbe reports his Mgoritlun's performance and the exam-plea it fails on in \[Hob76b, Hob76a\].
The numbers reportedhere vary slightly from those.
This is probably due to a dis-crepancy in exactly what the data.set consisted of.254(X 2 = 3.25, not significant).
In addition for eachalgorithm alone we tested whether there were signif-icant differences in performance for different extualtypes.
Both of the algorithms performed significantlyworse on the task dialogues (X 2 = 22.05 for Hobbs,X 2 = 21.55 for BFP, p < 0.05).We might wonder with what confidence we shouldview these numbers.
A significant factor that mustbe considered is the contribution of FALSE POSITIVESand ERROR CHAINING.
A FALSE POSITIVE is whenan algorithm gets the right answer for the wrong rea-son.
A very simple example of this phenomena isillustrated by this sequence from one of the task dia-logues.Expl: Now put IT in the pan of water.Exp2: Stand IT up.Exps: Pump the little handle with the red capon IT.Clil.
okExp4.
Does IT work?
?The first it in Expl refers to the pump.
Hobbsalgorithm gets the right antecedent for it in Exp3,which is the little handle, but then fails on it in Exp4,whereas the BFP algorithm has the pump centered atExpl and continues to select that as the antecedentfor it throughout the text.
This means BFP gets thewrong co-specifier in Exps but this error allows it toget the correct co-specifier in Exp4.Another type of false positive example is "Every-body and HIS brother suddenly wants to be the Presi-dent's friend, n said one aide.
Hobbs gets this correctas long as one is willing to accept that Everybody isreally the antecedent of his.
It seems to me that thismight be an idiomatic use.ERROR CHAINING refers to the fact that once an al-gorithm makes an error, other errors can result.
Con-sider:Cli1: Sorry no luck.Expx: I bet IT's the stupid red thing.Exp2: Take IT out.Cli2: Ok.
IT is stuck.In this example once an algorithm fails at Expx itwill fail on Exp2 and Cli2 as well since the choices ofa cospeciller in the following examples are dependenton the choice in Expl.It isn't possible to measure the effect of false pos-itives, since in some sense they are subjective judge-ments.
However one can and should measure the ef-fects of error chaining, since reporting numbers thatcorrect for error chaining is misleading, but if the er-ror that produced the error chain can be correctedthen the algorithm might show a significant improve-ment.
In this analysis, error chains contributed 22failures to Hobbs' algorithm and 19 failures to BFP.3 Qua l i ta t iveEva luat ion -G lass  BoxThe numbers presented in the previous section areintuitively unsatisfying.
They tell us nothing aboutwhat makes the algorithms more or less general, orhow they might be improved.
In addition, given theassumptions that we needed to make in order to pro-duce them, one might wonder to what extent he datais a result of these assumptions.
Figure 1 also fails toindicate whether the two algorithms missed the sameexamples or are covering a different set of phenomena,i.e.
what the relative distribution of the successes andfailures are.
But having done the hand-simulation iorder to produce such numbers, all of this informa-tion is available.
In this section we will first discussthe relative importance of various factors that go intoproducing the numbers above, then discuss if the al-gorithms can be modified since the flexibility of aframework in allowing one to make modifications ian important dimension of evaluation.3.1 DistributionsThe figures 2, 3 and 4 show for each pronominal cat-egory, the distribution of successes and failures forboth algorithms.HESHETHEYTotalBoth Neither Hobbs BFPonly only66 1 166 3 35 1 183 5 5 7Figure 2: Distribution on WheelsSince the main purpose of evaluation must be toimprove the theory that we are evaluating, the mostinteresting cases are the ones on which the algo-rithrns' performance varies and those that neither al-gorithm gets correct.
We discuss these below.255HEITTHEYTotalBoth Neither Hobbs BFPonly only53 8 2I i  5 4 I13 377 8 12 3Figure 3: Distribution on NewsweekI Both Neither Hobbs BFPonly onlyIT 48 29 3 1Figure 4: Distribution on Task Dialogues3.1.1 BothIn the Wheels data, 4 examples rest on the assump-tion that the identities of speakers and hearers is re-coverable.
For example in The GM president smiled.
"Except Henry will be damned forceful and the paperswon't print all HIS language.
~, getting the his correcthere depends on knowing that it is the GM presidentspeaking.
Only 4 examples rest on being able to pro-duce collections or discourse ntities, and 2 of theseoccurred with an explicit instruction to the hearer toproduce such a collection by using the phrase themboth.3.1.2 Hobbs  onlyThere are 21 cases that Hobbs gets that BFP don't,and of these these a few classes stand out.
In ev-ery case the relevant factor is Hobbs' preference forintrasentential co-specifiers.One class, (n = 3), is exemplified by Put the lit-tle black ring into the the large blue CAP with thehole in IT.
All three involved using the prepositionwith in a descriptive adjunct on a noun phrase.
Itmay be that with-adjuncts are common in visual de-scriptions, since they were only found in our data inthe task dialogues, and a quick inspection of Grosz'stask-oriented dialogues revealed some as well\[Deu74\].Another class, (n = 7), are possessives.
In somecases the possessive co-specified with the subject ofthe sentence, e.g.
The SENATE took time fromITS paralyzing New Hampshire election debate tovote agreement, and in others it was within a rela-tive clause and co-specified with the subject of thatclause, e.g.
The auto industry should be able to pro-duce a totally safe, defect-free CAR that doesn't pol-lute ITS environment.Other cases seem to be syntactically marked sub-ject matching with constructions that link two Sclauses (n = 8).
These are uses of more-than in e.g.but Chamberlain grossed about $8.3 million more thanHE could have made by selling on the home front.There also are S-if-S cases, as in Mondale said: "Ithink THE MAFIA would be broke if'IT conducted allits business that way."
We also have subject match-ing in AS-AS examples as in ... and the resulting EX-POSURE to daylight has become as uncomfortable asIT  was unaccustomed, as well as in sentential com-plements, such as But another liberal, Minnesota'sWalter MONDALE, said HE had found a lot of in-competence in the agency's operations.
The fact thatquite a few of these are also marked with But may besignificant.In terms of the possible effects that we noted ear-lier, the DEFINITION OF SUCCESS (see section 2.1 fa-vors Hobbs (n = 2).
Consider:K: Next take the red piece that is the small-est and insert it into the hole in the side ofthe large plastic tube.
IT goes in the holenearest he end with the engravings on IT.The Hobbs algorithm will correctly choose the endas the antecedent for the second it.
The BFP al-gorithm on the other hand will get two interpreta-tions, one in which the second it co-specifies the redpiece and one in which it co-specifies the end.
Theyare both CONTINUING interpretations since the firstit co-specifies the CB, but the constraints don't makea choice.3.1.3 BFP  onlyAll of the examples on which BFP succeed and Hobbsfails have to do with extended iscussion of one dis-course entity.
For instance:Expt: Now take the blue cap with the twoprongs sticking out (CB -- blue cap)Exp2: and fit the little piece of pink plastic on IT.Ok?
(CB= blue cap)Clit : ok.Exp3: Insert the rubber ring into that blue cap.
(CB= blue cap)Exp4: Now screw IT onto the cylinder.On this example, Hobbs fails by choosing the co-specifier of it in Exp4 to be the rubber ring, even256though the whole segment has been about the bluecap.Another example from the novel WHEELS is givenbelow.
On this one Hobbs gets the first use of hebut then misses the next four, as a result of missingthe second one by choosing a housekeeper as the co-specifier for HIS...An executive vice-president of Ford waspreparing to leave for Detroit Metropoli-tan Airport.
HE had already breakfasted,alone.
A housekeeper had brought a tray toHIS desk in the softly lighted study where,since 5 a.m., HE had been alternately read-ing memoranda (mostly on special blue sta-tionery which Ford vice-presidents u ed inimplementing policy) and dictating crisp in-structions into a recording machine.
HE hadscarcely looked up, either as the mall ar-rived, or while eating, as HE accomplishedin an hour what would have taken...Since an ezecutive vice-president is centered in thefirst sentence, and continued in each following sen-tence, the BFP algorithm will correctly choose thecospecifier.3.1.4 Ne i therAmong the examples that neither algorithm gets cor-rectly are 20 examples from the task dialogues of itreferring to the global focus, the pump.
In 15 cases,these shifts to global focus are marked syntacticallywith a cue word such as Now, and are not markedin 5 cases.
Presumably they are felicitous ince thepump is visually salient.
Besides the global focuscases, pronominal references to entities that were notlinguistically introduced are rare.
The only other ex-ample is an implicit reference to 'the problem' of thepump not working:Clil: Sorry no luck.Expl: I bet IT's the stupid red thing.We have only two examples of sentential or VPanaphora ltogether, such as Madam Chairwoman,said Colby at last, I am trying to ran a secret intelli-gence service.
IT  u~as a forlorn hope.
Neither Hobbsalgorithm nor BFP attempt o cover these examples.Three of the examples are uses of it that seem tobe lexicalized with certain verbs, e.g.
They hit IToff real well.
One can imagine these being treated asphrasal lexical items, and therefore not handled byan anaphoric processing component\[AS89\].Most of the interchanges in the task dialogues con-sist of the client responding to cotmnands with cuessuch as O.K.
or Ready to let the expert know whenthey have completed a task.
When both partiescontribute discourse ntities to the common ground,both algorithms may fail (n = 4).Consider:Expl: Now we have a little red piece leftExp2: and I don't know what to do with IT.Clil: Well, there is a hole in the green plungerinside the cylinder.Expa: I don't think IT goes in THERE.Exp4: I think IT may belong in the blue caponto which you put the pink pieceof plastic.In Exp3, one might claim that it and there are con-traindexed, and that there can be properly resolvedto a hole, so that it cannot be any of the noun phrasesin the prepositional phrases that modify a hole, butwhether any theory of contra-indexing actually give.us this is questionable.The main factor seems to be that even thoughExpt is not syntactically a question, the little redpiece is the focus of a question, and as such is infocus despite the fact that the syntactic onstructionthere is supposedly focuses a hole in the green plunger...\[Sid79\].
These examples uggest hat a questionedentity is left focused until the point in the dialogue atwhich the question is resolved.
The fact that well hasbeen noted as a marker of response to questions up-ports this analysis\[Sch87\].
Thus the relevant factorhere may be the switching of control among discourseparticipants \[WS88\].
These mixed-initiati.ve f aturesmake these sequences inherently different han text.3.2 ModifiabilityTask structure in the pump dialogues is an importantfactor especially as it relates to the use of global focus.Twenty of the cases on which both algorithms fail arereferences to the pump, which is the global focus.
Wecan include a global focus in the centering framework,as a separate notion from the current CB.
This meansthat in the 15 out of 20 cases where the shift to globalfocus is identifiably marked with a cue-word such asnow, the segment rules will allow BFP to get theglobal focus examples.BFP can add the VP and the S onto the end of the257forward centers list, as Sidner does in her algorithmfor local focusing \[Sid79\].
This lets BFP get the twoexamples of event anaphora.
Hobbs discusses the factthat his algorithm cannot be modified to get eventanaphora in \[Hob76b\].Another interesting fact is that in every case inwhich Hobbs' algorithm gets the correct co-specifierand BFP didn't, the relevant factor is Hobbs' pref-erence for intrasentential co-specifiers.
One viewon these cases may be that these are not discourseanaphora, but there seems to be no principled wayto make this distinction.
However, Carter has pro-posed some extensions to Sidner's algorithm for lo-cal focusing that seem to be relevant here(chap.
6,\[Car87\]).
He argues that intra-sentential candidates(ISCs) should be preferred over candidates from theprevious utterance, ONLY in the cases where no dis-course center has been established or the discoursecenter is rejected for syntactic or selectional reasons.He then uses Hobbs algorithm to produce an orderingof these ISCs.
This is compatible with the centeringframework since it is underspecifled as to whether oneshould always choose to establish a discourse centerwith a co-specifier from a previous utterance.
If weadopt Carter's rule into the centering framework, wefind that of the 21 cases that Hobbs gets that BFPdon't, in 7 cases there is no discourse center estab-lished, and in another 4 the current center can be re-jected on the basis of syntactic or sortal information.Of these Carter's rule clearly gets 5, and another 3seem to rest on whether one might want to establisha discourse ntity from a previous utterance.
Sincethe addition of this constraint does not allow BFP toget any examples that neither algorithm got, it seemsthat this combination is a way of making the best outof both algorithms.The addition of these modifications changes thequantitative results.
See the Figure 5.NWheels 100Newsweek 100Tasks 81Hobbs BFP88 9389 8451 64Figure 5: Number correct for both algorithms afterModifications, for Wheels, Newsweek and Task Dia-loguesHowever, the statistical analyses still show thatthere is no significant difference in the performanceof the algorithms in general.
It is also still the casethat the performance of each algorithm significantlyvaries depending on tile data.
Tile only significantdifference as a result of the modifcations is that tileBFP algorithm now performs ignificantly better oiltile pump dialogues alone (X 2 = 4.3 I, p < .05).4 Conc lus ionWe can benefit in two ways from performing suchevaluations: (a) we get general results on a methodol-ogy for doing evaluation, (b) we discover ways we canimprove current heories.
A split of evaluation effortsinto quantitative versus qualitative is incoherent.
Wecannot trust the results of a quantitative valuationwithout doing a considerable amount of qualitativeanalyses and we should perform our qualitative anal-yses on those components hat make a significant con-tribution to the quantitative results; we need to beable to measure the effect of various factors.
Thesemeasurements must be made by doing comparisonsat the data level.In terms of general results, we have identified somefactors that make evaluations of this type more com-plicated and which might lead us to evaluate solelyquantitative results with care.
These are: (a) To de-cide how to evaluate UNDERSPECIFICATIONS and thecontribution of ASSUMPTIONS, and (b) To determinethe effects of FALSE POSITIVES and ERKOR CHAINING.We advocate an approach in which the contributionof each underspeeification a d assumption is tabu-lated as well as the effect of error chains.
If a prin-cipled way could be found to identify false positives,their effect should be reported as well as part of anyquantitative valuation.In addition, we have takeri a few steps towards de-termining the relative importance of different factorsto the successful operation of discourse modules.
Thepercent of successes that both  algorithms get indi-cates that syntax has a strong influence, and that atthe very least we can reduce the amount of inferencerequired.
In 590?
to 82% of the cases both algorithmsget the correct result.
This probably means that in alarge number of cases there was no potential conflictof co-specifiers.
In addition, this analysis has shown,that at least for task-oriented dialogues global focusis a significant factor, and in general discourse struc-ture is more important in the task dialogues.
How-ever simple devices uch as cue words may go a longway toward determining this structure.Finally, we should note that doing evaluations suchas this allows us to determine the GENERALITY of our258approaches.
Since the performance of both Hobbsand BFP varies according to the type of the text, andin fact was significantly worse on the task dialoguesthan on the texts, we might question how their per-formance would vary on other inputs.
An annotatedcorpus comprising some of the various NL input typessuch as those I discussed in the introduction wouldgo a long way towards giving us a basis against which-we could evaluate the generality of our theories.5 AcknowledgementsDavid Carter, Phil Cohen, Nick Haddock, JerryHobbs, Aravind Joshi, Don Knuth, Candy Sidner,Phil Stenton, Bonnie Webber, and Steve Whittakerhave provided valuable insights toward this endeavorand critical comments on a multiplicity of earlier ver-sions of this paper.
Steve Whittaker advised me onthe statistical analyses.
I would like to thank JerryHobbs for encouraging me to do this in the first place.ReferenceslAP861\[AS89\]\[BF83\]\[BFP87\]\[Car87\]James F. Allen and C. Raymond Perranlt.Analyzing intention in utterances.
In Bar-bara J. Grc6z, Karen Sparck Jones, andBonnie Lynn Webber, editors, Readings inNatural Language Processing, pages 419-422, Morgan Kauffman, Los Altos, Ca.,1986.Anne Abeille and Yves Schabes.
Parsingidioms in lexicalized tags.
In Proc.
27thAnnual Meeting of the ACL, Associationof Computational Linguistics, pages 161-65, 1989.Roger Brown and Deborah Fish.
The psy-chological causality implicit in language.Cognition, 14:237-273, 1983.Susan E. Brennan, Marilyn Walker Fried-man, and Carl J. Pollard.
A center-ing approach to pronouns.
In Proc.
25thAnnual Meeting of the ACL, Associationof Computational Linguistics, pages 155-162, Stanford University, Stanford, Ca.,1987.David M. Carter.
Interpreting Anaphorsin Natural Language Texts.
Ellis Hot-wood, 1987.\[Coh78\]\[Coh84\]\[Deu74\]\[D J89\]\[GJw831\[GJWS6\]\[Gro77\]\[cs861\[GSBC861\[HL87\]Phillip R. Cohen.
On Knowing What toSay: Planning Speech Acts.
Technical Re-port 118, University of Toronto; Depart-ment of Computer Science, 1978.Phillip R. Cohen.
The pragmatics of re-ferring and the modality of conununica-tion.
Computational Linguistics, 10:97-146, 1984.Barbara Grosz Deutsch.
Typescripts oftask oriented ialogs.
August 1974.Nits Dahlback and Arne Jonsson.
Empiri-cal studies of discourse representations fornatural language interfaces.
In Proc.
27thAnnual Meeting of the ACL, Associationof Computational Linguistics, pages 291-298, 1989.Barbara J. Grosz, Aravind K. Joshi, andScott Weinstein.
Providing a unified ac-count of definite noun phrases in dis-course.
In Proc.
21st Annual Meeting ofthe ACL, Association of ComputationalLinguistics, pages 44-50, Cambridge, MA,1983.Barbara J. Grosz, Aravind K. Joshi, andScott Weinstein.
Towards a computa-tional theory of discourse interpretation.1986.
Preliminary draft.Barbara J. Grosz.
The Representationand Use of Focus in Dialogue Understand-ing.
Technical Report 151, SRI Interna-tional, 333 Ravenswood Ave, Menlo Park,Ca.
94025, 1977.Barbara J. Grosz and Candace L. Sidner.Attentions, intentions and the structureof discourse.
Computational Linguistics,12:pp.
175-204, 1986.Raymonde Guindon, P. Sladky, H. Brun-ner, and J. Conner.
The structure of user-adviser dialogues: is there method in theirmadness?
In Proc.
24st Annual Meetingof the ACL, Association of ComputationalLinguistics, pages 224-230, 1986.Julia Hirschberg and Diane Litmus.
Nowlets talk about now: identifying cuephrases intonationally.
In Proc.
25th An-nual Meeting of the ACL, Associationof Computational Linguistics, pages 163-259\[HM87\]\[HobTSa\]\[Hob76b\]\[Hob78\]\[HobS5\]\[HTD861\[PH87\]\[Po186\]\[Pri81\]171, Stanford University, Stanford, Ca., \[Pri85\]1987.Jerry R. Hobbs and Paul Martin.
LocalPragmatics.
Technical Report, SRI In-ternational, 333 P~venswood Ave., MenloPark, Ca 94025, 1987.Jerry R. Hobbs.
A Computational Ap-proach to Discourse Analysis.
Techni-cal Report 76-2, Department ofComputerScience, City College, City University ofNew York, 1976.Jerry R. Hobbs.
Pronoun Resolution.Technical Report 76-1, Department ofComputer Science, City College, City Uni-versity of New York, 1976.Jerry R. Hobbs.
Why is Discourse Coher-ent?
Technical Report 176, SRI Interna-tional, 383 Ravenswood Ave., Menlo Park,Ca 94025, 1978.Jerry R. Hobbs.
On the Coherence andStructure of Discourse.
Technical Re-port CSLI-85-37, Center for the Study ofLanguage and Information, Ventura Hall,Stanford University, Stanford, CA 94305,1985.Susan B. Hudson, Michael K. Tanenhaus,and Gary S. Dell.
The effect of the dis-course center on the local coherence of adiscourse.
Technical Report, University ofRochester, 1986.Janet Pierrehum-bert and Julia Hirsehberg.
The meaningof intonational contours in the interpreta-tion of discourse.
In Proc.
Symposium onIntentions and Plans in Communicationand Discourse, Monterey, Ca., 1987.Martha Pollack.
A model of plan infer-ence that distinguishes between the be-liefs of actors andobservers.
In Proc.
$4stAnnual Meeting of the ACL, Associationof Computational Linguistics, pages 207-214, Columbia University, New York, N.Y,1986.Ellen F. Prince.
Toward a taxonomy ofgiven-new information.
In Radical Prag-matics, Academic Press, 1981.\[Rei76\]\[Rei85\]\[ROBS8\]\[Sch87\]\[SI81\]\[Sid79\]\[Tho80\]\[Web86\]\[ws88\]\[ws89\]Ellen F. Prince.
Fancy syntax and sharedknowledge.
Journal of Pragmatics, pp.65-81, 1985.T.
Reinhart.
The Syntactic Domain ofAnaphora.
PhD thesis, MIT, CambridgeMass., 1976.Rachel Reichman.
Getting Computers toTalk Like You and Me.
MIT Press, Cam-bridge, MA, 1985.Craige Roberts.
Modal Subordina-tion and Pronominal Anaphora in Dis-course.
Technical Report No.
127, CSLI,May,1988.
Also to appear in Linguisticsand Philosophy.Deborah Schiffrin.
Discourse Markers.Cambridge University Press, 1987.Candace Sidner and David Israel.
Rec-ognizing intended meaning and speak-ers plans.
In Proc.
InternationalJoint Conference on Artificial Intelli-gence, pages 203-208, Vancouver, BC,Canada, 1981.Candace L. Sidner.
"Toward a computa-tional theory of definite anaphora compre-hension in English.
Technical Report AI-TR-537, MIT, 1979.Bozena Henisz Thompson.
Linguis-tic analysis of natural language com-munication with computers.
In COL-ING80: Proc.
8th International Con-terence on Computational Linguistics.Tokyo, pages 190-201, 1980.Bonnie Lynn Webber.
Two Steps Closerto Event Reference.
Technical Report MS-CIS-86-74, Linc Lab 42, Department ofComputer and Information Science, Uni-versity of Pennsylvania, 1986.Steve Whittaker and Phil Stenton.
Cuesand control in expert client dialogues.
InProc.
26th Annual Meeting of the ACL,Association of Computational Linguistics,1988.Steve Whittaker and Phil Stenton.
Userstudies and the design of natural languagesystems.
In Proc.
27th Annual Meetingof the ACL, Association of ComputationalLinguistics, pages 116-123, 1989.260A The Hobbs algorithmThe algorithm and an example is reproduced below.In it, NP denotes NOUN PHRASE and S denotes SEN-TENCE.1.
Begin at the NP node immediately dominatingthe pronoun in the parse tree of S.2.
Go up the tree until you encounter an NP or Snode.
Call this node X, and call the path usedto reach it p.3.
Traverse all branches below node X to the leftof path p in a left-to-right breadth-first fashion.Propose as the antecedent any NP node encoun-tered that has an NP or S node on the path fromit to X.4.
If X is not the highest S node in the sentence,continue to step 5.
Otherwise traverse the sur-face parse trees of previous entences in the textin reverse chronological order until an acceptableantecedent is found; each tree is traversed in aleft-to-right, breadth-first manner, and when anNP node is encountered, it is proposed as theantecedent.5.
From node X, go up the tree to the first NP orS node encountered.
Call this new node X, andcall the path traversed to reach it p.6.
If X is an NP node and if the path p to X didnot pass through the N node that X immediatelydominates, propose X as the antecedent.7.
Traverse all branches below node X to the leftof path p in a left-to-right, breadth-first manner,but do not go below any NP  or S node encoun-tered.
Propose any NP  or S node encounteredas the antecedent.8.
Go  to step 4.The purpose of steps 2 and 3 is to observe thecontra.indexing constraints.
Let us consider a sim-ple conversational sequence.UI: Lyn's morn is a gardener.U2: Craige likes her.We are trying to find the antecedent for her in thesecond utterance.
Let us go through the algorithmstep by step, using the parse trees for UI and U2 inthe figure.1.
NPs labels the starting point of step 1./NP2ILynSl/ \NPt VP/ \ IDet N V\ I I's room is\NPIDetIa\N3\NlgardenerS2 /q :NP4 VP "I / "<'-.Craige V NPsI Ilikes herFigure 6: Parse Trees for Ut and U2...$2 is called X.
We mark the path p with a dottedline.We traverse S~ to the left of p. We encounterNP4 but it does not have an NP  or S node be-tween it and X.
This means that NP4 is contra-indexed with NPs.
Note that if the structurecorresponded to Craige"s morn likes her then theNP  for Craige would be an NP  to the left ofp that has an NP  node between it and X, andCraige would be selected as the antecedent forher.The node X is the highest S node in U2, so wego to the previous sentence Ut.
As we traversethe tree of Ut, the first NP we encounter is NP1,so Lyn's morn is proposed as the antecedent forher and we are done.261
