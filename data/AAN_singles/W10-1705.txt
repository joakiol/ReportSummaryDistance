Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 60?66,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational Linguistics2010 Failures in English-Czech Phrase-Based MT ?Ondr?ej Bojar and Kamil KosCharles University in Prague, Institute of Formal and Applied Linguistics ( ?UFAL)Malostranske?
na?me?st??
25, Praha 1, CZ-11800, Czech Republicbojar@ufal.mff.cuni.cz, kamilkos@email.czAbstractThe paper describes our experiments withEnglish-Czech machine translation forWMT101 in 2010.
Focusing primarilyon the translation to Czech, our additionsto the standard Moses phrase-based MTpipeline include two-step translation toovercome target-side data sparseness andoptimization towards SemPOS, a metricbetter suited for evaluating Czech.
Unfor-tunately, none of the approaches bring asignificant improvement over our standardsetup.1 IntroductionCzech is a flective language with very rich mor-phological system.
Translation between Czechand English poses different challenges for each ofthe directions.When translating from Czech, the word orderusually needs only minor changes (despite the is-sue of non-projectivity, a phenomenon occurringat 2% of words but in 23% of Czech sentences,see Hajic?ova?
et al (2004) and Holan (2003)).
Amuch more severe issue is caused by the Czech vo-cabulary size.
Fortunately, this can be to a certainextent mitigated by backing-off to Czech lemmasif the exact forms are not available.We are primarily interested in the harder task oftranslating to Czech and most of the paper dealswith this direction.
After a brief specification ofdata sets, pre-processing and evaluation methodin this section, we provide details on the issueof Czech vocabulary size (Section 2).
We de-scribe our current attempts at generating Czech?The work on this project was supported by the grantsEuroMatrixPlus (FP7-ICT-2007-3-231720 of the EU and7E09003 of the Czech Republic), GA ?CR P406/10/P259, andMSM 0021620838.
Thanks to David Kolovratn?
?k for the helpwith manual evaluation.1http://www.statmt.org/wmt10/word forms in Section 3.
Partly due to the largevocabulary size of Czech, BLEU score (Papineniet al, 2002) correlates rather poorly with humanjudgments.
We summarize our efforts to use a bet-ter metric in the model optimization in Section 4.The final Section 5 lists the exact configurationsof our English?Czech primary submissions forWMT10, including the back-off to lemmas we usefor Czech-to-English.1.1 Data and Pre-Processing PipelineThroughout the paper, we use CzEng 0.9 (Bojarand ?Zabokrtsky?, 2009)2 as our main parallel cor-pus.
Following CzEng authors?
request, we didnot use sections 8* and 9* reserved for evaluationpurposes.As the baseline training dataset (?Small?
in thefollowing) only the news domain of CzEng (126kparallel sentences) is used.
For large-scale ex-periments (?Large?
in the following) and our pri-mary WMT10 submissions, we use all CzEng do-mains except navajo and add the EMEA corpus(Tiedemann, 2009)3 ,4 of 7.5M parallel sententes.As our monolingual data we use by default onlythe target side of the parallel corpus.
For experi-ments reported here, we also use the monolingualdata provided by WMT10 organizers for Czech.Our primary WMT10 submission includes furthermonolingual data, see Section 5.1.We use a slightly modified tokenization rulescompared to CzEng export format.
Most notably,we normalize English abbreviated negation andauxiliary verbs (?couldn?t?
?
?could not?)
andattempt at normalizing quotation marks to distin-guish between the opening and closing one follow-2http://ufal.mff.cuni.cz/czeng3http://urd.let.rug.nl/tiedeman/OPUS4Unfortunately, the EMEA corpus is badly tokenized onthe Czech side.
Most frequently, fractional numbers are splitinto several tokens (e.g.
?3, 14?).
We attempted to reconstructthe original detokenized form using a small set of regular ex-pressions.60Large Small DevSents 7.5M 126.1k 2.5kCzech Tokens 79.2M 2.6M 55.8kEnglish Tokens 89.1M 2.9M 49.9kCzech Vocabulary 923.1k 138.7k 15.4kEnglish Vocabulary 646.3k 64.7k 9.4kCzech Lemmas 553.5k 60.3k 9.5kEnglish Lemmas 611.4k 53.8k 7.7kTable 1: Corpus and vocabulary sizes.ing proper typesetting rules.The rest of our pre-processing pipeline matchesthe processing employed in CzEng (Bojar and?Zabokrtsky?, 2009).5 We use ?supervised truecas-ing?, meaning that we cast the case of the lemmato the form, relying on our morphological analyz-ers and taggers to identify proper names, all otherwords are lowercased.The differences in relations between Czech andEnglish Large and Small datasets can be attributedeither to domain differences or possibly due tonoise in CzEng.1.2 EvaluationWe use WMT10 development sets for tuning(news-test2008) and evaluation (news-test2009).The official scores on news-test2010 are givenonly in the main WMT10 paper and not here.The BLEU scores reported in this paper arebased on truecased word forms in the original to-kenization as provided by the decoder.
Thereforethey are likely to differ from figures reported else-where.The ?
value given with each BLEU score is theaverage of the distances to the lower and upperempirical 95% confidence bounds estimated usingbootstrapping (Koehn, 2004).2 Issues of Czech Vocabulary SizeTable 1 summarizes the differences of Czech andEnglish vocabulary sizes in our parallel corpora.We see that the vocabulary size of Czech forms(truecased) is more than double compared to En-glish in the Small dataset and significantly largerin the Large dataset as well.
On the other hand,the number of distinct Czech and English lemmasis nearly identical.5Due to the subsequent processing, incl.
parsing, the tok-enization of English follows PennTreebenk style.
The ratherunfortunate convention of treating hyphenated words as sin-gle tokens increases our out-of-vocabulary rate.
Next time,we will surely post-tokenize the parsed text.Distortion LimitTOpts 3 6 10 30 401 0.2 0.3 0.3 0.3 0.35 0.8 0.9 1.0 1.0 1.010 1.1 1.3 1.5 1.5 1.520 1.2 1.5 1.7 1.7 1.750 1.2 1.5 1.7 1.7 1.7100 1.2 1.5 1.7 1.7 1.7Table 3: Percentage of sentences reachable inCzech-to-English small setting with various dis-tortion limits and translation options per coverage(TOpts) (BLEU score 14.76?0.44).2.1 Out-of-Vocabulary RatesTable 2 lists out-of-vocabulary (OOV) rates of ourSmall and Large data setting given the develop-ment corpus.
We calculate the rates for both thecomplete corpus and the restricted set of phrasesextracted from the corpus.
(Note that higher-ordern-gram rates are estimated using phrases as inde-pendent units, no combination of phrases is per-formed.)
We also list the effective OOV rate forEnglish-to-Czech translation where all (English)words from each source sentence can be also pro-duced in the hypothesis.We see that in the small setting, the OOV rateis almost double for Czech than for English.
TheOOV is significantly decreased by enlarging thecorpus or lemmatizing the word forms.If we consider only the words available in thephrase tables, the issue of Czech with limited datais striking: 10?12% of devset tokens are not avail-able in the training data.2.2 Reachability of Training and ReferenceTranslationsSchwartz (2008) extended Moses to support ?con-straint decoding?, that is to perform an exhaustivesearch through the space of hypotheses in order toreach the reference translation (and get its score).The current implementation of the exhaustivesearch in Moses is in fact subject to several con-figuration parameters, most importantly the num-ber of translation options considered for each span(-max-trans-opt-per-coverage) and thedistortion limit (-distortion-limit).Given his aim, Schwartz (2008) uses the outputof four MT systems translating from different lan-guages to English as the references and notes thatonly around 10% of the reference translations arereachable by an independent Swedish-English MTsystem.61n-grams Out of Corpus Voc.
n-grams Out of Phrase-Table Voc.Dataset Language 1 2 3 4 1 2 3 4Large Czech 2.2% 30.5% 70.2% 90.3% 3.9% 44.1% 82.2% 95.6%Large English 1.5% 13.7% 47.3% 78.8% 2.1% 22.4% 63.5% 89.1%Large Czech + English input sent 1.5% 29.4% 69.6% 90.1% 3.1% 42.8% 81.5% 95.3%Small Czech 6.7% 48.1% 83.0% 95.5% 12.5% 65.4% 91.9% 98.6%Small English 3.6% 28.1% 68.3% 90.9% 6.3% 45.4% 84.3% 97.0%Small Czech + English input sent 5.2% 46.6% 82.4% 95.2% 10.6% 63.7% 91.2% 98.3%Small Czech lemmas 4.1% 36.3% 75.8% 92.8% 5.8% 52.6% 87.7% 97.4%Small English lemmas 3.4% 24.6% 64.6% 89.4% 6.9% 53.2% 87.9% 97.5%Small Czech + English input sent lemmas 3.1% 35.7% 75.6% 92.8% 5.1% 38.1% 80.8% 96.2%Table 2: Out-of-vocabulary rates.Distortion LimitTOpts 3 6 10 30 401 0.4 0.4 0.4 0.4 0.45 1.5 1.9 2.0 2.0 2.010 2.5 3.2 3.5 3.5 3.520 3.7 5.0 5.5 5.6 5.650 4.9 6.7 8.0 8.6 8.6100 5.3 7.6 9.1 9.4 9.4Table 4: Percentage of sentences reachable inCzech-to-English large setting, two alternative de-coding paths to translate from Czech lemma ifthe form is not available in the translation table(BLEU score 18.70?0.46).We observe that reaching man-made referencetranslations in Czech-to-English translation is farharder.
Table 3 provides the figures for small datasetting (and no phrase table filtering).
The bestreachability we can hope for is given in Table 4where we allow to use source word lemmas if theexact form is not available.
We see that the defaultlimits (50 translation options per span and distor-tion limit of 6) leave us with only 6.7% sentencesreachable.While not directly important for your training,the figures still underpin the issue of sparse data inCzech-English translation.3 Targetting Czech Word FormsBojar (2007) experimented with several transla-tion scenarios, including what we will call Mor-phG, i.e.
the independent translation of lemma tolemma and tag to tag followed by a generation stepto produce target-side word form.
With the smalltraining set available then, the MorphG model per-formed equally well as a simpler direct translationfollowed by target-side tagging and an additionaln-gram model over morphological tags.
Koehnand Hoang (2007) reports even a large loss withMorphG for German-to-English if the alternativeof direct form-to-form translation is not available.Bojar et al (2009b) applied the two alternativedecoding paths (direct form-to-form and MorphG,labelled ?T+C+C&T+T+G?)
to English-Czech butthey were able to use only 84k sentences.
Forthe full training set of 2.2M sentences, the modelwas too big to fit in reasonable disk limits.
Moreimportantly, already in the small data setting, thecomplex model suffered from little stability dueto abundance of features (5 features per phrase-table plus tree features for three LMs), so nearlythe same performance on the development set gavelargely varying quality on the independent test set.The most important issue of the MorphG setup,however, is the explosion of translation options.Due to the ?synchronous factors?
approach ofMoses (Koehn and Hoang, 2007), all translationoptions have to be fully constructed before themain search begins.
The MorphG model how-ever licenses too many possible combinations oflemmas, tags and final word forms, so the prun-ing of translation options strikes hard, causingsearch errors.
For more details, see Bojar et al(2009a) where a similar issue occurs for treelet-based translation.3.1 Two-Step TranslationIn order to avoid the explosion of the translationoptions6, we experimented with two-step transla-tion.The first step translates from English to lemma-tized Czech augmented to preserve important se-mantic properties known from the source phrase.The second step is a monotone translation fromthe lemmas to fully inflected Czech.
The idea be-hind the delimitation is that all the morphologicalproperties of Czech words that can be established6and also motivated when we noticed that reading MToutput to lemmatized Czech is sometimes more pleasant andinformative than regular phrase-based output62Data Size Simple Two-StepParallel Mono BLEU SemPOS BLEU SemPOSSmall Small 10.28?0.40 29.92 10.38?0.38 30.01Small Large 12.50?0.44 31.01 12.29?0.47 31.40Large Large 14.17?0.51 33.07 14.06?0.49 32.57Table 5: Performance of direct (Simple) and two-step factored translation in small and large data setting.regardless the English source should not cause par-allel data sparseness and clutter the search.
In-stead, they should be decided based on context inthe second phase only.Specifically, the intermediate Czech representsmost words as tuples containing only: lemma,negation, grade (of adjectives and adverbs), num-ber (of nouns, adjectives, verbs) and detailed partof speech (constraining also e.g.
verb tense ofCzech verbs).
Some words are handled separately:?
Pronouns, punctuation and the verbs ?by?t?
(tobe) and ?m??t?
(to have) are represented usingtheir lowecased full forms because they are veryfrequent, often auxiliary to other words andtheir exact form best captures the available andnecessary detail of many morphological andsyntactic properties.?
Prepositions are represented using their lemmasand case because the case of a noun phrase isactually introduced by the governing word (e.g.the verb that subcategorized for the noun phraseor the preposition for prepositional phrases).Table 5 compares the scores of the simplephrase-based and the two-step translation via aug-mented Czech lemmas as described above.
Thesmall and large parallel data denote the datasetsdescribed in Section 1.1.
The small monolingualset means just the news domain of CzEng, whilethe large monolingual set means WMT10 mono-lingual Czech texts (and no CzEng data).
Notethat the monolingual data serve three purposes inthe two-step approach: the language model for thefirst phase, the translation model in the secondphase (monotone and restricted to phrase-lengthof 1; longer phrases did not bring significant im-provement either), and the language model of thesecond phase.
Ignoring the opportunity to use themonolingual set as the language model in the firstphase already hurts the performance.We see that the results as evaluated both byBLEU and SemPOS (see Section 4 below) arerather mixed but not that surprising.
There is anegligible gain in the Small-Small setting, a mixedoutcome in the Small-Large and a little loss in theTwo- Both Both-Step Fine Wrong Simple TotalTwo-Step 23 4 8 - 35Both Fine 7 14 17 5 43Both Wrong 8 1 28 2 39Simple - 3 7 23 33Total 38 22 60 30 150Table 6: Manual micro-evaluation of Simple(12.50?0.44) vs. Two-step (12.29?0.47) modelin the Small-Large setting.Large-Large setting.The most interesting result is the Small-Largesetting: BLEU (insignificantly) prefers the simpleand SemPOS the two-step model.
It thus seemsthat a large target-side LM is sufficient to improvethe BLEU score, despite the untackled issue ofbilingual data sparseness.We carried out a quick manual evaluation of150 sentences by two annotators (one of the au-thors and a third person; systems anonymized):for each input segment, either one of the outputsis distinguishably better or both are equally wrongor equally acceptable.
As listed in the confusionmatrix in Table 6, each annotator independentlymarginally prefers the two-step approach but theintersection does not confirm that.7 One goodthingis that the annotators do not completely con-tradict each other?s preference.Ultimately, we did not use the two-step ap-proach in our primary submission, but we feelthere is still some unexploited potential in thisphrase-based approximation of the technique sep-arating properties of words handled in the transla-tion phase from properties implied by the target-side (grammatical) context only.
Certainly, therepresentation of the intermediate language can7Of the 23 sentences improved by the two-step setup,about three quarters indeed had an improvement in lexicalcoverage or better morphological choice of a word.
Of the23 sentences where the two-step model hurts, about a halfsuffered from errors related to superfluous auxiliary words inCzech that seem to be introduced by a bias towards word-for-word translation.
This bias is not inherent to the model,only the (normalized) phrase penalty weight happened to getnearly three times bigger than in the simple model.63be still improved, and more importantly, the sec-ond phase of monotone decoding could be handledby a more appropriate model capable of includingmore additional (source) context features.84 Optimizing towards SemPOSIn our setup, we use minimum error-rate training(MERT, Och (2003)) to optimize weights of modelcomponents.
In the standard implementation inMoses, BLEU (Papineni et al, 2002) is used asthe objective function, despite its rather disputablecorrelation with human judgments of MT quality.Kos and Bojar (2009) introduced SemPOS, ametric that performs much better in terms of cor-relation to human judgments when translating toCzech.
Naturally, we wanted to optimize towardsSemPOS.SemPOS computes the overlapping of autose-mantic (content-bearing) word lemmas in the can-didate and reference translations given a fine-grained semantic part of speech (sempos9), as de-fined in Hajic?
et al (2006), and outputs averageoverlapping score over all sempos types.The SemPOS metric outperformed commonmetrics as BLEU, TER (Snover et al, 2006) or anadaptation of Meteor (Lavie and Agarwal, 2007)for Czech on test sets from WMT08 (Callison-Burch et al, 2008).4.1 Integrating SemPOS to MERTIn our experiments we used Z-MERT (Zaidan,2009), a recent implementation of the MERT al-gorithm, to optimize model parameters.The SemPOS metric requires to remove all aux-iliary words and to identify the (deep-syntactic)lemmas and semantic part of speech for autose-mantic words.
When employed in MERT train-ing, the whole n-best list of candidates has to pro-cessed like this at each iteration.We use the TectoMT platform ( ?Zabokrtsky?
andBojar, 2008)10 for the linguistic processing.
Tec-toMT follows the complete pipeline of tagging,surface-syntactic analysis and deep-syntactic anal-ysis, which is the best but rather costly way to ob-tain the required information.Therefore, we use two different ways of obtain-ing lemmas and semantic parts of speech in the8We are grateful to Trevor Cohn for the suggestion.9In the following text we will use SemPOS to denote theSemPOS metric.
When speaking about the semantic part ofspeech, we will write sempos type or sempos tag.10http://ufal.mff.cuni.cz/tectomt/BLEU SemPOS Iters TimeTectoMT 10.11?0.40 29.69 20 2d12.0hin MERT 9.53?0.39 29.69 10 1d12.0hFactored 9.46?0.37 29.36 10 2.4htranslation 8.20?0.37 29.68 - -6.96?0.33 27.79 9 1.7hTable 7: Five independent MERT runs optimizingtowards SemPOS with semantic parts of speechand lemmas provided either by TectoMT on thefly or by Moses factored translation.MERT loop:?
indeed apply TectoMT processing to the n-bestlist at each iteration (parallelized to 15 CPUs),?
apply TectoMT to the training data, express the(deep) lemma and sempos as additional factorsusing a blank value for auxiliary words, and us-ing Moses factored translation to translate fromEnglish forms to triplets of Czech form, deeplemma and sempos.Table 7 lists several ZMERT runs when opti-mizing a simple form?form phrase-based model(small data setting) towards SemPOS.
One obser-vation is that using TectoMT in the MERT loopis unbearably costly and we avoided it in the sub-sequent experiments.
More importantly, from thehuge differences in the final BLEU as well as Sem-POS scores (evaluated on the independent test set),we see how unstable the search is.SemPOS, while good at comparing differentMT systems, is very bad at comparing candidatesfrom a single system in an n-best list.
This can beeasily explained by its low sensitivity to precision:SemPOS disregards word forms as well as all aux-iliary words.
This is a good thing to compare verydifferent candidates (where each of the systems al-ready struggled to produce a coherent output) butis of very little help when comparing candidates ofa single system, because these candidates tend todiffer rather in forms than in lexical choice.4.2 Combination of SemPOS and BLEUTo compensate for some of the shortcomings ofSemPOS, we also attempted to optimize towardsa linear combination of SemPOS and BLEU.This should increase the suitability of the metricfor MERT optimization because BLEU will takecorrect word forms into account while SemPOSshould promote better lexical choice (possibly notconfirmed by BLEU due to a different word formthan in the reference).Table 8 provides the results of various weight64W.
BLEU SemPOS W. BLEU SemPOS1:0 10.42?0.38 29.91 3:1 10.30?0.39 30.031:1 10.15?0.39 29.81 10:1 10.17?0.40 29.581:1 9.42?0.37 29.30 1:2 10.11?0.38 29.802:1 10.37?0.38 29.95 1:10 9.44?0.40 29.74Table 8: Optimizing towards a linear combina-tion of BLEU and SemPOS (weights in this order),small data setting.BLEU SemPOSBLEU alone 14.08?0.50 32.44SemPOS-BLEU (1:1) 13.79?0.55 33.17Table 9: Optimizing towards BLEU and/or Sem-POS in large data setting.settings, including the optimization towardsBLEU alone using ZMERT implementation.
Wesee that the stability is much better, only few runssuffered a minor loss (including 1:1 in one case).Unfortunately, the differences in final BLEU andSemPOS scores are all within confidence intervalswhen trained on the small dataset.Table 9 documents that in our large data set-ting, MERT indeed achieves slightly higher Sem-POS (and lower BLEU) when optimizing towardsit.
This corresponds with the intuition that withmore variance in lexical choices available in thephrase tables, SemPOS can help to balance modelfeatures.
The current set of weights is rather lim-ited, so our future experiments should focus on ac-tually providing means to e.g.
domain adaptationby using features indicating the applicability of aphrase in a specific domain.5 Our Primary Submissions to WMT105.1 English-to-Czech TranslationGiven the little or no improvements achieved bythe many configurations we tried, our English-to-Czech primary submission is rather simple:?
Standard GIZA++ word alignment based on both sourceand target lemmas.?
Two alternative decoding paths; forms always truecased:form+tag?form & form?form.The first path is more specific and helps to preserve coresyntactic elements in the sentence.
Without the tag, am-biguous English words could often all translate as e.g.nouns, leading to no verb in the Czech sentence.
The de-fault path serves as a back-off.?
Significance filtering of the phrase tables (Johnson et al,2007) implemented for Moses by Chris Dyer; default set-tings of filter value a+e and the cut-off 30.?
Two separate 5-gram Czech LMs of truecased forms eachof which interpolates models trained on the followingdatasets; the interpolation weights were set automaticallyusing SRILM (Stolcke, 2002) based on the target side ofLarge SmallBacked-off by source lemmas 18.95?0.45 14.95?0.48form?form only 18.41?0.44 14.73?0.47Table 10: Translation from Czech better whenbacked-off by source lemmas.the development set:11?
Interpolated CzEng domains: news, web, fiction.
Therationale behind the selection of the domains is that weprefer prose-like texts for LM estimation (and not e.g.technical documentation) while we want as much paral-lel data as possible.?
Interpolated monolingual corpora: WMT09monolingual, WMT10 monolingual, CzechNational Corpus (Kocek et al, 2000) sectionsSYN2000+2005+2006PUB.?
Lexicalized reordering (or-bi-fe) based on forms.?
Standard Moses MERT towards BLEU.5.2 Czech-to-English TranslationFor Czech-to-English translation we experimentedwith far fewer configuration options.
Our primarysubmission is configured as follows:?
Two alternative decoding paths; forms always truecased:form?form & lemma?form.?
Significance filtering as in Section 5.1.?
5-gram English LM based on CzEng English side only.12?
Lexicalized reordering (or-bi-fe) based on forms.?
Standard Moses MERT towards BLEU.Table 10 documents the utility of the additionaldecoding path from Czech lemmas in both smalland large setting, surprisingly less significant inthe small setting.
Later experiments with systemcombination by Kenneth Heafield indicated thatwhile our system is not among the top three, itbrings an advantage to the combination.6 ConclusionWe provided an extensive documentation of Czechdata sparseness issue for machine translation.
Weattempted to tackle the problem of constructingthe target-side form by a two-step translation setupand the problem of unreliable automatic evalua-tion by employing a new metric in MERT loop,neither with much success so far.
Both of the at-tempts however deserve further exploration.
Ad-ditionally, we provide the exact configurations ofour WMT10 primary submissions.11The subsequent MERT training using the same develop-ment test may suffer from overestimating the language modelweights, but we did not observe the issue, possibly due toonly moderate overlap of the datasets.12We attempted to use a second LM trained on English Gi-gaword by Chris Callison-Burch, but we observed a drop inBLEU score from 18.95?0.45 to 18.03?0.44 probably dueto different tokenization guidelines applied.65ReferencesOndr?ej Bojar and Zdene?k ?Zabokrtsky?.
2009.
CzEng0.9: Large Parallel Treebank with Rich Annotation.Prague Bulletin of Mathematical Linguistics, 92.Ondr?ej Bojar, Miroslav Jan?
?c?ek, and MiroslavTy?novsky?.
2009a.
Evaluation of Tree Transfer Sys-tem.
Project Euromatrix - Deliverable 3.4, Instituteof Formal and Applied Linguistics, Charles Univer-sity in Prague.Ondr?ej Bojar, David Marec?ek, Va?clav Nova?k, Mar-tin Popel, Jan Pta?c?ek, Jan Rous?, and Zdene?k?Zabokrtsky?.
2009b.
English-Czech MT in 2008.In Proc.
of Fourth Workshop on Statistical MachineTranslation, ACL, Athens, Greece.Ondr?ej Bojar.
2007.
English-to-Czech Factored Ma-chine Translation.
In Proc.
of the Second Workshopon Statistical Machine Translation, ACL, Prague,Czech Republic, June.Chris Callison-Burch, Cameron Fordyce, PhilippKoehn, Christof Monz, and Josh Schroeder.
2008.Further Meta-Evaluation of Machine Translation.
InProc.
of the Third Workshop on Statistical MachineTranslation, ACL, Columbus, Ohio.Jan Hajic?, Jarmila Panevova?, Eva Hajic?ova?, PetrSgall, Petr Pajas, Jan ?Ste?pa?nek, Jir???
Havelka,Marie Mikulova?, Zdene?k ?Zabokrtsky?, and Magda?Sevc???kova?
Raz??mova?.
2006.
Prague DependencyTreebank 2.0.
LDC2006T01, ISBN: 1-58563-370-4.Eva Hajic?ova?, Jir???
Havelka, Petr Sgall, Kater?ina Vesela?,and Daniel Zeman.
2004.
Issues of Projectivity inthe Prague Dependency Treebank.
The Prague Bul-letin of Mathematical Linguistics, 81.Toma?s?
Holan.
2003.
K syntakticke?
analy?ze c?esky?ch(!)ve?t.
In MIS 2003.
MATFYZPRESS.Howard Johnson, Joel Martin, George Foster, andRoland Kuhn.
2007.
Improving translation qual-ity by discarding most of the phrasetable.
In Proc.of EMNLP-CoNLL, Prague, Czech Republic.Jan Kocek, Marie Kopr?ivova?, and Karel Kuc?era, edi-tors.
2000.
?Cesky?
na?rodn??
korpus - u?vod a pr???ruc?kauz?ivatele.
FF UK - ?U ?CNK, Prague.Philipp Koehn and Hieu Hoang.
2007.
Factored Trans-lation Models.
In Proc.
of EMNLP.Philipp Koehn.
2004.
Statistical Significance Testsfor Machine Translation Evaluation.
In Proc.
ofEMNLP, Barcelona, Spain.Kamil Kos and Ondr?ej Bojar.
2009.
Evaluation ofMachine Translation Metrics for Czech as the Tar-get Language.
The Prague Bulletin of MathematicalLinguistics, 92.Alon Lavie and Abhaya Agarwal.
2007.
Meteor:An Automatic Metric for MT Evaluation with HighLevels of Correlation with Human Judgments.
InProc.
of the Second Workshop on Statistical Ma-chine Translation, ACL, Prague, Czech Republic.Franz Josef Och.
2003.
Minimum Error Rate Trainingin Statistical Machine Translation.
In Proc.
of ACL,Sapporo, Japan.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a Method for AutomaticEvaluation of Machine Translation.
In Proc.
of ACL,Philadelphia, Pennsylvania.Lane Schwartz.
2008.
Multi-source translation meth-ods.
In Proc.
of AMTA.Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-nea Micciulla, and John Makhoul.
2006.
A Studyof Translation Edit Rate with Targeted Human An-notation.
In Proc.
of AMTA.Andreas Stolcke.
2002.
SRILM ?
An Extensible Lan-guage Modeling Toolkit.
In Proc.
of Intl.
Conf.
onSpoken Language Processing, volume 2.Jo?rg Tiedemann.
2009.
News from OPUS - A Col-lection of Multilingual Parallel Corpora with Toolsand Interfaces.
In Proc.
of Recent Advances in NLP(RANLP).Zdene?k ?Zabokrtsky?
and Ondr?ej Bojar.
2008.
TectoMT,Developer?s Guide.
Technical Report TR-2008-39,Institute of Formal and Applied Linguistics, CharlesUniversity in Prague.Omar F. Zaidan.
2009.
Z-MERT: A Fully Config-urable Open Source Tool for Minimum Error RateTraining of Machine Translation Systems.
ThePrague Bulletin of Mathematical Linguistics, 91.66
