Proceedings of ACL-08: HLT, pages 977?985,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsEvaluating a Crosslinguistic Grammar Resource:A Case Study of WambayaEmily M. BenderUniversity of WashingtonDepartment of LinguisticsBox 354340Seattle WA 98195-4340ebender@u.washington.eduAbstractThis paper evaluates the LinGO Grammar Ma-trix, a cross-linguistic resource for the de-velopment of precision broad coverage gram-mars, by applying it to the Australian languageWambaya.
Despite large typological differ-ences between Wambaya and the languageson which the development of the resource wasbased, the Grammar Matrix is found to pro-vide a significant jump-start in the creation ofthe grammar for Wambaya: With less than 5.5person-weeks of development, the Wambayagrammar was able to assign correct seman-tic representations to 76% of the sentences ina naturally occurring text.
While the workon Wambaya identified some areas of refine-ment for the Grammar Matrix, 59% of theMatrix-provided types were invoked in the fi-nal Wambaya grammar, and only 4% of theMatrix-provided types required modification.1 IntroductionHand-built grammars are often dismissed as too ex-pensive to build on the one hand, and too brittleon the other.
Nevertheless, they are key to variousNLP applications, including those benefiting fromdeep natural language understanding (e.g., textualinference (Bobrow et al, 2007)), generation of well-formed output (e.g., natural language weather alertsystems (Lareau and Wanner, 2007)) or both (as inmachine translation (Oepen et al, 2007)).
Of par-ticular interest here are applications concerning en-dangered languages: Endangered languages repre-sent a case of minimal linguistic resources, typicallylacking even moderately-sized corpora, let alnetreebanks.
In the best case, one finds well-crafteddescriptive grammars, bilingual dictionaries, and ahandful of translated texts.
The methods of pre-cision grammar engineering are well-suited to tak-ing advantage of such resources.
At the same time,the applications of interest in the context of endan-gered languages emphasize linguistic precision: im-plemented grammars can be used to enrich existinglinguistic documentation, to build grammar check-ers in the context of language standardization, andto create software language tutors in the context oflanguage preservation efforts.The LinGO Grammar Matrix (Bender et al, 2002;Bender and Flickinger, 2005; Drellishak and Ben-der, 2005) is a toolkit for reducing the cost of creat-ing broad-coverage precision grammars by prepack-aging both a cross-linguistic core grammar and aseries of libraries of analyses of cross-linguisticallyvariable phenomena, such as major-constituent wordorder or question formation.
The Grammar Ma-trix was developed initially on the basis of broad-coverage grammars for English (Flickinger, 2000)and Japanese (Siegel and Bender, 2002), and hassince been extended and refined as it has been usedin the development of broad-coverage grammars forNorwegian (Hellan and Haugereid, 2003), ModernGreek (Kordoni and Neu, 2005), and Spanish (Ma-rimon et al, 2007), as well as being applied to 42other languages from a variety of language familiesin a classroom context (Bender, 2007).This paper aims to evaluate both the utility of theGrammar Matrix in jump-starting precision gram-mar development and the current state of its cross-linguistic hypotheses through a case study of a977language typologically very different from any ofthe languages above: the non-Pama-Nyungan Aus-tralian language Wambaya (Nordlinger, 1998).The remainder of this paper is structured as fol-lows: ?2 provides background on the Grammar Ma-trix and Wambaya, and situates the project with re-spect to related work.
?3 presents the implementedgrammar of Wambaya, describes its development,and evaluates it against unseen, naturally occurringtext.
?4 uses the Wambaya grammar and its devel-opment as one point of reference to measure the use-fulness and cross-linguistic validity of the GrammarMatrix.
?5 provides further discussion.2 Background2.1 The LinGO Grammar MatrixThe LinGO Grammar Matrix is situated theoreti-cally within Head-Driven Phrase Structure Gram-mar (HPSG; Pollard and Sag, 1994), a lexicalist,constraint-based framework.
Grammars in HPSGare expressed as a collection of typed feature struc-tures which are arranged into a hierarchy such thatinformation shared across multiple lexical entries orconstruction types is represented only on a single su-pertype.
The Matrix is written in the TDL (type de-scription language) formalism, which is interpretedby the LKB parser, generator, and grammar develop-ment environment (Copestake, 2002).
It is compati-ble with the broader range of DELPH-IN tools, e.g.,for machine translation (L?nning and Oepen, 2006),treebanking (Oepen et al, 2004) and parse selection(Toutanova et al, 2005).The Grammar Matrix consists of a cross-linguistic core type hierarchy and a collection ofphenomenon-specific libraries.
The core type hierar-chy defines the basic feature geometry, the ways thatheads combine with arguments and adjuncts, linkingtypes for relating syntactic to semantic arguments,and the constraints required to compositionally buildup semantic representations in the format of Min-imal Recursion Semantics (Copestake et al, 2005;Flickinger and Bender, 2003).
The libraries providecollections of analyses for cross-linguistically vari-able phenomena.
The current libraries include anal-yses of major constituent word order (SOV, SVO,etc), sentential negation, coordination, and yes-noquestion formation.
The Matrix is accessed througha web-based configuration system1 which elicits ty-pological information from the user-linguist througha questionnaire and then outputs a grammar consist-ing of the Matrix core plus selected types and con-straints from the libraries according to the specifica-tions in the questionnaire.2.2 WambayaWambaya is a recently extinct language of the WestBarkly family from the Northern Territory in Aus-tralia (Nordlinger, 1998).
Wambaya was selectedfor this project because of its typological propertiesand because it is extraordinarily well-documentedby Nordlinger in her 1998 descriptive grammar.Perhaps the most striking feature of Wambaya isits word order: it is a radically non-configurationallanguage with a second position auxiliary/clitic clus-ter.
That is, aside from the constraint that verbalclauses require a clitic cluster (marking subject andobject agreement and tense, aspect and mood) insecond position, the word order is otherwise free, tothe point that noun phrases can be non-contiguous,with head nouns and their modifiers separated by un-related words.
Furthermore, head nouns are gener-ally not required: argument positions can be instan-tiated by modifiers only, or, if the referent is clearfrom the context, by no nominal constituent of anykind.
It has a rich system of case marking, and ad-nominal modifiers agree with the heads they modifyin case, number, and four genders.
An example isgiven in (1) (Nordlinger, 1998, 223).2(1) Ngaragana-ngujagrog-PROP.IV.ACCngiy-a3.SG.NM.A-PSTgujinganjanga-nimother.II.ERGjiyawugivengabulu.milk.IV.ACC?
(His) mother gave (him) milk with grog init.?
[wmb]In (1), ngaragana-nguja (?grog-proprietive?, or?having grog?)
is a modifier of ngabulu milk.
Theyagree in case (accusative) and gender (class IV), butthey are not contiguous within the sentence.To relate such discontinuous noun phrases to ap-propriate semantic representations where ?having-1http://www.delph-in.net/matrix/customize/matrix.cgi2In this example, the glosses II, IV, and NM indicate genderand ACC and ERG indicate case.
A stands for ?agent?, PST for?past?, and PROP for ?proprietive?.978grog?
and ?milk?
are predicated of the same entity re-quires a departure from the ordinary way that headsare combined with arguments and modifiers com-bined with heads in HPSG in general and in theMatrix in particular.3 In the Grammar Matrix, asin most work in HPSG, lexical heads record the de-pendents they require in valence lists (SUBJ, COMPS,SPR).
When a head combines with one of its ar-guments, the result is a phrase with the same va-lence requirements as the head daughter, minus theone corresponding to the argument that was just sat-isfied.
In contrast, the project described here hasexplored a non-cancellation analysis for Wambaya:even after a head combines with one of its argu-ments, that argument remains on the appropriate va-lence list of the mother, so that it is visible for furthercombination with modifiers.
In addition, heads cancombine directly with modifiers of their arguments(as opposed to just modifiers of themselves).Argument realization and the combination ofheads and modifiers are fairly fundamental aspectsof the system implemented in the Matrix.
In lightof the departure described above, it is interesting tosee to what extent the Matrix can still support rapiddevelopment of a precision grammar for Wambaya.2.3 Related WorkThere are currently many multilingual grammar en-gineering projects under active development, in-cluding ParGram, (Butt et al, 2002; King et al,2005), the MetaGrammar project (Kinyon et al,2006), KPML (Bateman et al, 2005), Grammix(Mu?ller, 2007) and OpenCCG (Baldridge et al,2007).
Among approaches to multilingual grammarengineering, the Grammar Matrix?s distinguishingcharacteristics include the deployment of a sharedcore grammar for crosslinguistically consistent con-straints and a series of libraries modeling vary-ing linguistic properties.
Thus while other workhas successfully exploited grammar porting betweentypologically related languages (e.g., Kim et al,2003), to my knowledge, no other grammar port-ing project has covered the same typological dis-3A linearization-based analysis as suggested by Donohueand Sag (1999) for discontinuous constituents in Warlpiri (an-other Australian language), is not available, because it relies ondisassociating the constituent structure from the surface order ofwords in a way that is not compatible with the TDL formalism.tance attempted here.
The current project is alsosituated within a broader trend of using computa-tional linguistics in the service of endangered lan-guage documentation (e.g., Robinson et al, 2007,see also www.emeld.org).3 Wambaya grammar3.1 DevelopmentThe Wambaya grammar was developed on the basisof the grammatical description in Nordlinger 1998,including the Wambaya-English translation lexiconand glosses of individual example sentences.
Thedevelopment test suite consisted of all 794 distinctpositive examples from Ch.
3?8 of the descriptivegrammar.
This includes elicited examples as wellas (sometimes simplified) naturally occurring exam-ples.
They range in length from one to thirteenwords (mean: 3.65).
The test suite was extractedfrom the descriptive grammar at the beginning of theproject and used throughout with only minor refine-ments as errors in formatting were discovered.
Theregression testing facilities of [incr tsdb()] allowedfor rapid experimentation with alternative analysesas new phenomena were brought into the grammar(cf.
Oepen et al, 2002).With no prior knowledge of this language beyondits most general typological properties, we were ableto develop in under 5.5 person-weeks of develop-ment time (210 hours) a grammar able to assign ap-propriate analyses to 91% of the examples in the de-velopment set.4 The 210 hours include 25 hours ofan RA?s time entering lexical entries, 7 hours spentpreparing the development test suite, and 15 hourstreebanking (using the LinGO Redwoods software(Oepen et al, 2004) to annotate the intended parsefor each item).
The remainder of the time was ordi-nary grammar development work.5In addition, this grammar has relatively low am-biguity, assigning on average 11.89 parses per itemin the development set.
This reflects the fact that thegrammar is modeling grammaticality: the rules are4An additional 6% received some analysis, but not one thatmatched the translation given in the reference grammar.5These numbers do not include the time put into the origi-nal field work and descriptive grammar work.
Nordlinger (p.c.
)estimates that as roughly 28 linguist-months, plus the nativespeaker consultants?
time.979meant to exclude ungrammatical strings as well asare unwarranted analyses of grammatical strings.3.2 ScopeThe grammar encodes mutually interoperable anal-yses of a wide variety of linguistic phenomena, in-cluding:?
Word order: second position clitic cluster, other-wise free word order, discontinuous noun phrases?
Argument optionality: argument positions with noovert head?
Linking of syntactic to semantic arguments?
Case: case assignment by verbs to dependents?
Agreement: subject and object agreement in per-son and number (and to some extent gender) markedin the clitic cluster, agreement between nouns andadnominal modifiers in case, number and gender?
Lexical adverbs, including manner, time, and loca-tion, and adverbs of negation, which vary by clausetype (declarative, imperative, or interrogative)?
Derived event modifiers: nominals (nouns, adjec-tives, noun phrases) used as event modifiers withmeaning dependent on their case marking?
Lexical adjectives, including demonstratives ad-verbs, numerals, and possessive adjectives, as wellas ordinary intersective adjectives?
Derived nominal modifiers: modifiers of nouns de-rived from nouns, adjectives and verbs, including theproprietive, privative, and ?origin?
constructions?
Subordinate clauses: clausal complements ofverbs like ?tell?
and ?remember?, non-finite subor-dinate clauses such as purposives (?in order to?)
andclauses expressing prior or simultaneous events?
Verbless clauses: nouns, adjectives, and adverbs,lexical or derived, functioning as predicates?
Illocutionary force: imperatives, declaratives, andinterrogatives (including wh questions)?
Coordination: of clauses and noun phrases?
Other: inalienable possession, secondary predi-cates, causatives of verbs and adjectives3.3 Sample AnalysisThis section provides a brief description of the anal-ysis of radical non-configurationality in order togive a sense of the linguistic detail encoded in theWambaya grammar and give context for the evalu-ation of the Wambaya grammar and the GrammarMatrix in later sections.The linguistic analyses encoded in the grammarserve to map the surface strings to semantic repre-sentations (in Minimal Recursion Semantics (MRS)format (Copestake et al, 2005)).
The MRS in Fig-ure 1 is assigned to the example in (1).6 It in-cludes the basic propositional structure: a situationof ?giving?
in which the first argument, or agent, is?mother?, the second (recipient) is some third-personentity, and the third (patient), is ?milk?
which is alsorelated to ?grog?
through the proprietive relation.
Itis marked as past tense, and as potentially a state-ment or a question, depending on the intonation.7,8A simple tree display of the parse giving rise tothis MRS is given in Figure 2.
The non-branchingnodes at the bottom of the tree represent the lexicalrules which associate morphosyntactic informationwith a word according to its suffixes.
The generalleft-branching structure of the tree is a result of theanalysis of the second-position clitic cluster: Theclitic clusters are treated as argument-compositionauxiliaries, which combine with a lexical verb and?inherit?
all of the verb?s arguments.
The auxiliariesfirst pick up all dependents to the right, and thencombine with exactly one constituent to the left.The grammar is able to connect x7 (the index of?milk?)
to both the ARG3 position of the ?give?
rela-tion and the ARG1 position of the proprietive rela-tion, despite the separation between ngaraganaguja(?grog-PROP.IV.ACC?)
and ngabulu (?milk.IV.ACC?
)in the surface structure, as follows: The auxiliaryngiya is subject to the constraints in (2), meaningthat it combines with a verb as its first complementand then the verb?s complements as its remainingcomplements.9 The auxiliary can combine with itscomplements in any order, thanks to a series of head-complement rules which realize the nth element of6The grammar in fact finds 42 parses for this example.
Theone associated with the MRS in Figure 1 best matches the in-tended interpretation as indicated by the gloss of the example.7The relations are given English predicate names for theconvenience of the grammar developer, and these are not in-tended as any kind of interlingua.8This MRS is ?fragmented?
in the sense that the labels ofseveral of the elementary predications (eps) are not related toany argument position of any other ep.
This is related to thefact that the grammar doesn?t yet introduce quantifiers for anyof the nominal arguments.9In this and other attribute value matrices displayed, featurepaths are abbreviated and detail not relevant to the current pointis suppressed.980?????????????????
?LTOP h1INDEX e2 (prop-or-ques, past)RELS???
?grog n relLBL h3ARG0 x4 (3, iv)???,??????
?proprietive a relLBL h5ARG0 e6ARG1 x7 (3, iv)ARG2 x4???????,??
?mother n relLBL h8ARG0 x9 (3sg, ii)???,?????????
?give v relLBL h1ARG0 e2ARG1 x9ARG2 x10 (3)ARG3 x7??????????,??
?milk n relLBL h5ARG0 x7???
?HCONS ?
??????????????????
?Figure 1: MRS for (1)VVADJADJADJNNNgaraganagujaVVVVVVVngiyaNNNgujinganjanganiVVjiyawuNNNngabuluFigure 2: Phrase structure tree for (1)the COMPS list.
It this example, it first picks upthe subject gujinganjangani (?mother-ERG?
), thenthe main verb jiyawu (?give?
), and then the objectngabulu (?milk-ACC?).
(2) ?????????
?lexemeHEAD verb [AUX +]SUBJ ?
1 ?COMPS??
?HEAD verb [AUX ?
]SUBJ ?
1 ?COMPS 2????
2?????????
?The resulting V node over ngiya gujinganjanganijiyawu ngabulu is associated with the constraintssketched in (3).
(3) ???????????????????????????
?phraseHEAD verb [AUX +]SUBJ????
?1 N:?mother?INDEX x9CASE ergINST +?????COMPS????
?V:?give?SUBJ ?
1 ?COMPS ?
2 , 3 ?INST +????,???
?2 NINDEX x10CASE accINST ?????,???
?3 N:?milk?INDEX x7CASE accINST +????????????????????????????????
?Unlike in typical HPSG approaches, the informa-tion about the realized arguments is still exposedin the COMPS and SUBJ lists of this constituent.10This makes the necessary information availableto separately-attaching modifiers (such as ngara-ganaguja (?grog-PROP.IV.ACC?))
so that they cancheck for case and number/gender compatibility andconnect the semantic index of the argument theymodify to a role in their own semantic contribution(in this case, the ARG1 of the ?proprietive?
relation).3.4 EvaluationThe grammar was evaluated against a sample of nat-urally occurring data taken from one of the textstranscribed and translated by Nordlinger (1998)(?The two Eaglehawks?, told by Molly NurlanymaGrueman).
Of the 92 sentences in this text, 20 over-lapped with items in the development set, so the10The feature INST, newly proposed for this analysis, recordsthe fact that they have been instantiated by lexical heads.981correct parsed unparsed averageincorrect ambiguityExisting 50% 8% 42% 10.62vocabw/added 76% 8% 14% 12.56vocabTable 1: Grammar performance on held-out dataevaluation was carried out only on the remaining72 sentences.
The evaluation was run twice: oncewith the grammar exactly as is, including the exist-ing lexicon, and a second time after new lexical en-tries were added, using only existing lexical types.In some cases, the orthographic components of thelexical rules were also adjusted to accommodate thenew lexical entries.
In both test runs, the analyses ofeach test item were hand-checked against the trans-lation provided by Nordlinger (1998).
An item iscounted as correctly analyzed if the set of analysesreturned by the parser includes at least one with anMRS that matches the dependency structure, illocu-tionary force, tense, aspect, mood, person, number,and gender information indicated.The results are shown in Table 1: With only lexi-cal additions, the grammar was able to assign a cor-rect parse to 55 (76%) of the test sentences, withan average ambiguity over these sentences of 12.56parses/item.3.5 Parse selectionThe parsed portion of the development set (732items) constitutes a sufficiently large corpus to traina parse selection model using the Redwoods disam-biguation technology (Toutanova et al, 2005).
Aspart of the grammar development process, the parseswere annotated using the Redwoods parse selectiontool (Oepen et al, 2004).
The resulting treebankwas used to select appropriate parameters by 10-foldcross-validation, applying the experimentation envi-ronment and feature templates of (Velldal, 2007).The optimal feature set included 2-level grandpar-enting, 3-grams of lexical entry types, and both con-stituent weight features.
In the cross-validation tri-als on the development set, this model achieved aparse selection accuracy of 80.2% (random choicebaseline: 23.9%).
A model with the same featureswas then trained on all 544 ambiguous examplesfrom the development set and used to rank the parsesof the test set.
It ranked the correct parse (exactmatch) highest in 75.0% of the test sentences.
Thisis well above the random-choice baseline of 18.4%,and affirms the cross-linguistic validity of the parse-selection techniques.3.6 SummaryThis section has presented the Matrix-derived gram-mar of Wambaya, illustrating its semantic represen-tations and analyses and measuring its performanceagainst held-out data.
I hope to have shown thegrammar to be reasonably substantial, and thus aninteresting case study with which to evaluate theGrammar Matrix itself.4 Evaluation of Grammar MatrixIt is not possible to directly compare the develop-ment of a grammar for the same language, by thesame grammar engineer, with and without the assis-tance of the Grammar Matrix.
Therefore, in this sec-tion, I evaluate the usefulness of the Grammar Ma-trix by measuring the extent to which the Wambayagrammar as developed makes use of types defined inMatrix as well as the extent to which Matrix-definedtypes had to be modified.
The former is in somesense a measure of the usefulness of the Matrix, andthe latter is a measure of its correctness.While the libraries and customization systemwere used in the initial grammar development, thisevaluation primarily concerns itself with the Matrixcore type hierarchy.
The customization-providedWambaya-specific type definitions for word order,lexical types, and coordination constructions wereused for inspiration, but most needed fairly exten-sive modification.
This is particularly unsurprisingfor basic word order, where the closest available op-tion (?free word order?)
was taken, in the absenceof a pre-packaged analysis of non-configurationalityand second-position phenomena.
The other changesto the library output were largely side-effects of thisfundamental difference.Table 2 presents some measurements of the over-all size of the Wambaya grammar.
Since HPSGgrammars consist of types organized into a hierarchyand instances of those types, the unit of measure forthese evaluations will be types and/or instances.
The982NMatrix types 891ordinary 390pos disjunctions 591Wambaya-specific types 911Phrase structure rules 83Lexical rules 161Lexical entries 1528Table 2: Size of Wambaya grammarMatrix core types w/ POS typesDirectly used 132 34% 136 15%Indirectly used 98 25% 584 66%Total types used 230 59% 720 81%Types unused 160 41% 171 19%Types modified 16 4% 16 2%Total 390 100% 891 100%Table 3: Matrix core types used in Wambaya grammarWambaya grammar includes 891 types defined inthe Matrix core type hierarchy.
These in turn include390 ordinary types, and 591 ?disjunctive?
types, thepowerset of 9 part of speech types.
These are pro-vided in the Matrix so that Matrix users can easilyrefer to classes of, say, ?nouns and verbs?
or ?nounsand verbs and adjectives?.
The Wambaya-specificportion of the grammar includes 911 types.
Thesetypes are invoked in the definitions of the phrasestructure rules, lexical rules, and lexical entries.Including the disjunctive part-of-speech types,just under half (49%) of the types in the grammar areprovided by the Matrix.
However, it is necessary tolook more closely; just because a type is provided inthe Matrix core hierarchy doesn?t mean that it is in-voked by any rules or lexical entries of the Wambayagrammar.
The breakdown of types used is given inTable 3.
Types that are used directly are either calledas supertypes for types defined in the Wambaya-specific portion of the grammar, or used as the valueof some feature in a type constraint in the Wambaya-specific portion of the grammar.
Types that are usedindirectly are either ancestor types to types that areused directly, or types that are used as the value ofa feature in a constraint in the Matrix core typeson a type that is used (directly or indirectly) by theWambaya-specific portion of the grammar.Relatively few (16) of the Matrix-provided typesneeded to be modified.
These were types thatwere useful, but somehow unsuitable, and typicallydeeply interwoven into the type system, such thatnot using and them and defining parallel types intheir place would be inconvenient.Setting aside the types for part of speech disjunc-tions, 59% of the Matrix-provided types are invokedby the Wambaya-specific portion of the grammar.While further development of the Wambaya gram-mar might make use of some of the remaining 41%of the types, this work suggests that there is a sub-stantial amount of information in the Matrix coretype hierarchy which would better be stored as partof the typological libraries.
In particular, the analy-ses of argument realization implemented in the Ma-trix were not used for this grammar.
The typesassociated with argument realization in configura-tional languages should be moved into the word-order library, which should also be extended to in-clude an analysis of Wambaya-style radical non-configurationality.
At the same time, the lexicalamalgamation analysis of the features used in long-distance dependencies (Sag, 1997) was found to beincompatible with the approach to argument realiza-tion in Wambaya, and a phrasal amalgamation anal-ysis was implemented instead.
This again suggeststhat lexical v. phrasal amalgamation should be en-coded in the libraries, and selected according to theword order pattern of the language.As for parts of speech, of the nine types providedby the Matrix, five were used in the Wambaya gram-mar (verb, noun, adj, adv, and det) and four were not(num, conj, comp, and adp(osition)).
Four disjunc-tive types were directly invoked, to describe phe-nomena applying to nouns and adjectives, verbs andadverbs, anything but nouns, and anything but de-terminers.
While it was convenient to have the dis-junctive types predefined, it also seems that a muchsmaller set of types would suffice in this case.
Sincethe nine proposed part of speech types have varyingcrosslinguistic validity (e.g., not all languages haveconjunctions), it might be better to provide softwaresupport for creating the disjunctive types as the needarises, rather than predefining them.Even though the number of Matrix-provided typesis small compared to the grammar as a whole, therelatively short development time indicates that thetypes that were incorporated were quite useful.
Inproviding the fundamental organization of the gram-983mar, to the extent that that organization is consistentwith the language modeled, these types significantlyease the path to creating a working grammar.The short development time required to create theWambaya grammar presents a qualitative evaluationof the Grammar Matrix as a crosslinguistic resource,as one goal of the Grammar Matrix is to reduce thecost of developing precision grammars.
The factthat a grammar capable of assigning valid analy-ses to an interesting portion of sentences from natu-rally occurring text could be developed in less than5.5 person-weeks of effort suggests that this goalis indeed met.
This is particularly encouraging inthe case of endangered and other resource-poor lan-guages.
A grammar such as the one described herecould be a significant aide in analyzing additionaltexts as they are collected, and in identifying con-structions that have not yet been analyzed (cf.
Bald-win et al 2005).5 ConclusionThis paper has presented a precision, hand-builtgrammar for the Australian language Wambaya, andthrough that grammar a case study evaluation ofthe LinGO Grammar Matrix.
True validation ofthe Matrix qua hypothesized linguistic universals re-quires many more such case studies, but this firsttest is promising.
Even though Wambaya is in somerespects very different from the well-studied lan-guages on which the Matrix is based, the existingmachinery otherwise worked quite well, providing asignificant jump-start to the grammar developmentprocess.
While the Wambaya grammar has a longway to go to reach the complexity and range oflinguistic phenomena handled by, for example, theLinGO English Resource Grammar, it was shown toprovide analyses of an interesting portion of a natu-rally occurring text.
This suggests that the method-ology of building such grammars could be profitablyincorporated into language documentation efforts.The Grammar Matrix allows new grammars to di-rectly leverage the expertise in grammar engineeringgained in extensive work on previous grammars ofbetter-studied languages.
Furthermore, the designof the Matrix is such that it is not a static object,but intended to evolve and be refined as more lan-guages are brought into its purview.
Generalizingthe core hierarchy and libraries of the Matrix to sup-port languages like Wambaya can extend its typo-logical reach and further its development as an in-vestigation in computational linguistic typology.AcknowledgmentsI would like to thank Rachel Nordlinger for pro-viding access to the data used in this work in elec-tronic form, as well as for answering questions aboutWambaya; Russ Hugo for data entry of the lexicon;Stephan Oepen for assistance with the parse rankingexperiments; and Scott Drellishak, Stephan Oepen,and Laurie Poulson for general discussion.
This ma-terial is based upon work supported by the NationalScience Foundation under Grant No.
BCS-0644097.ReferencesJ.
Baldridge, S. Chatterjee, A. Palmer, and B. Wing.2007.
DotCCG and VisCCG: Wiki and programmingparadigms for improved grammar engineering withOpenCCG.
In T.H.
King and E.M. Bender, editors,GEAF 2007, Stanford, CA.
CSLI.T.
Baldwin, J. Beavers, E.M. Bender, D. Flickinger, AraKim, and S. Oepen.
2005.
Beauty and the beast: Whatrunning a broad-coverage precision grammar over theBNC taught us about the grammar ?
and the corpus.In S. Kepser and M. Reis, editors, Linguistic Evidence:Empirical, Theoretical, and Computational Perspec-tives, pages 49?70.
Mouton de Gruyter, Berlin.J.A.
Bateman, I.
Kruijff-Korbayova?, and G.-J.
Kruijff.2005.
Multilingual resource sharing across both re-lated and unrelated languages: An implemented, open-source framework for practical natural language gen-eration.
Research on Language and Computation,3(2):191?219.E.M.
Bender and D. Flickinger.
2005.
Rapid prototypingof scalable grammars: Towards modularity in exten-sions to a language-independent core.
In IJCNLP-05(Posters/Demos), Jeju Island, Korea.E.M.
Bender, D. Flickinger, and S. Oepen.
2002.
Thegrammar matrix: An open-source starter-kit for therapid development of cross-linguistically consistentbroad-coverage precision grammars.
In J. Carroll,N.
Oostdijk, and R. Sutcliffe, editors, Proceedings ofthe Workshop on Grammar Engineering and Evalua-tion, COLING 19, pages 8?14, Taipei, Taiwan.E.M.
Bender.
2007.
Combining research and pedagogyin the development of a crosslinguistic grammar re-source.
In T.H.
King and E.M. Bender, editors, GEAF2007, Stanford, CA.
CSLI.984D.G.
Bobrow, C. Condoravdi, R.S.
Crouch, V. de Paiva,L.
Karttunen, T.H.
King, R. Nairn, L. Price, and A Za-enen.
2007.
Precision-focused textual inference.
InACL-PASCAL Workshop on Textual Entailment andParaphrasing, Prague, Czech Republic.M.
Butt, H. Dyvik, T.H.
King, H. Masuichi, andC.
Rohrer.
2002.
The parallel grammar project.
InJ.
Carroll, N. Oostdijk, and R. Sutcliffe, editors, Pro-ceedings of the Workshop on Grammar Engineeringand Evaluation at COLING 19, pages 1?7.A.
Copestake, D. Flickinger, C. Pollard, and I.A.
Sag.2005.
Minimal recursion semantics: An introduction.Research on Language & Computation, 3(2?3):281?332.A.
Copestake.
2002.
Implementing Typed Feature Struc-ture Grammars.
CSLI, Stanford, CA.C.
Donohue and I.A.
Sag.
1999.
Domains in Warlpiri.Paper presented at HPSG 99, University of Edinburgh.S.
Drellishak and E.M. Bender.
2005.
A coordinationmodule for a crosslinguistic grammar resource.
In Ste-fan Mu?ller, editor, HPSG 2005, pages 108?128, Stan-ford.
CSLI.D.
Flickinger and E.M. Bender.
2003.
Compositional se-mantics in a multilingual grammar resource.
In E.M.Bender, D. Flickinger, F. Fouvry, and M. Siegel, edi-tors, Proceedings of the Workshop on Ideas and Strate-gies for Multilingual Grammar Development, ESSLLI2003, pages 33?42, Vienna, Austria.D.
Flickinger.
2000.
On building a more efficient gram-mar by exploiting types.
Natural Language Engineer-ing, 6 (1):15 ?
28.L.
Hellan and P. Haugereid.
2003.
NorSource: An ex-ercise in Matrix grammar-building design.
In E.M.Bender, D. Flickinger, F. Fouvry, and M. Siegel, edi-tors, Proceedings of the Workshop on Ideas and Strate-gies for Multilingual Grammar Development, ESSLLI2003, pages 41?48, Vienna, Austria.R.
Kim, M. Dalrymple, R.M.
Kaplan, T.H.
King, H. Ma-suichi, and T. Ohkuma.
2003.
Multilingual grammardevelopment via grammar porting.
In E.M. Bender,D.
Flickinger, F. Fouvry, and M. Siegel, editors, Pro-ceedings of the Workshop on Ideas and Strategies forMultilingual Grammar Development, ESSLLI 2003,pages 49?56, Vienna, Austria.T.H.
King, M. Forst, J. Kuhn, and M. Butt.
2005.
Thefeature space in parallel grammar writing.
Researchon Language and Computation, 3(2):139?163.A.
Kinyon, O. Rambow, T. Scheffler, S.W.
Yoon, andA.K.
Joshi.
2006.
The metagrammar goes multilin-gual: A cross-linguistic look at the V2-phenomenon.In TAG+8, Sydney, Australia.V.
Kordoni and J. Neu.
2005.
Deep analysis of ModernGreek.
In K-Y Su, J. Tsujii, and J-H Lee, editors, Lec-ture Notes in Computer Science, volume 3248, pages674?683.
Springer-Verlag, Berlin.F.
Lareau and L. Wanner.
2007.
Towards a genericmultilingual dependency grammar for text generation.In T.H.
King and E.M. Bender, editors, GEAF 2007,pages 203?223, Stanford, CA.
CSLI.J.T.
L?nning and S. Oepen.
2006.
Re-usable tools forprecision machine translation.
In COLING|ACL 2006Interactive Presentation Sessions, pages 53 ?
56, Syd-ney, Australia.M.
Marimon, N. Bel, and N. Seghezzi.
2007.
Test-suiteconstruction for a Spanish grammar.
In T.H.
Kingand E.M. Bender, editors, GEAF 2007, Stanford, CA.CSLI.Stefan Mu?ller.
2007.
The Grammix CD-ROM: A soft-ware collection for developing typed feature structuregrammars.
In T.H.
King and E.M. Bender, editors,GEAF 2007, Stanford, CA.
CSLI.R.
Nordlinger.
1998.
A Grammar of Wambaya, NorthernAustralia.
Research School of Pacific and Asian Stud-ies, The Australian National University, Canberra.S.
Oepen, E.M. Bender, U. Callmeier, D. Flickinger, andM.
Siegel.
2002.
Parallel distributed grammar engi-neering for practical applications.
In Proceedings ofthe Workshop on Grammar Engineering and Evalua-tion, COLING 19, Taipei, Taiwan.S.
Oepen, D. Flickinger, K. Toutanova, and C.D.
Man-ning.
2004.
LinGO Redwoods.
A rich and dynamictreebank for HPSG.
Journal of Research on Languageand Computation, 2(4):575 ?
596.Stephan Oepen, Erik Velldal, Jan Tore Lnning, PaulMeurer, Victoria Rosn, and Dan Flickinger.
2007.Towards hybrid quality-oriented machine translation.On linguistics and probabilities in MT.
In TMI 2007,Skvde, Sweden.C.
Pollard and I.A.
Sag.
1994.
Head-Driven PhraseStructure Grammar.
CSLI, Stanford, CA.S.
Robinson, G. Aumann, and S. Bird.
2007.
Managingfieldwork data with Toolbox and the Natural LanguageToolkit.
Language Documentation and Conservation,1:44?57.I.A.
Sag.
1997.
English relative clause constructions.Journal of Linguistics, 33(2):431 ?
484.M.
Siegel and E.M. Bender.
2002.
Efficient deep pro-cessing of Japanese.
In Proceedings of the 3rd Work-shop on Asian Language Resources and InternationalStandardization, COLING 19, Taipei, Taiwan.K.
Toutanova, C.D.
Manning, D. Flickinger, andS.
Oepen.
2005.
Stochastic HPSG parse selectionusing the Redwoods corpus.
Journal of Research onLanguage and Computation, 3(1):83 ?
105.E.
Velldal.
2007.
Empirical Realization Ranking.
Ph.D.thesis, University of Oslo, Department of Informatics.985
