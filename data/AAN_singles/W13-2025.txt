Proceedings of the BioNLP Shared Task 2013 Workshop, pages 170?177,Sofia, Bulgaria, August 9 2013. c?2013 Association for Computational LinguisticsBacteria Biotope Detection, Ontology-based Normalization, and RelationExtraction using Syntactic RulesI?lknur KaradenizDepartment of Computer EngineeringBog?azic?i University34342, Bebek, I?stanbul, Turkeyilknur.karadeniz@boun.edu.trArzucan O?zgu?rDepartment of Computer EngineeringBog?azic?i University34342, Bebek, I?stanbul, Turkeyarzucan.ozgur@boun.edu.trAbstractThe absence of a comprehensive databaseof locations where bacteria live is an im-portant obstacle for biologists to under-stand and study the interactions betweenbacteria and their habitats.
This paper re-ports the results to a challenge, set forth bythe Bacteria Biotopes Task of the BioNLPShared Task 2013.
Two systems are ex-plained: Sub-task 1 system for identifyinghabitat mentions in unstructured biomedi-cal text and normalizing them through theOntoBiotope ontology and Sub-task 2 sys-tem for extracting localization and part-of relations between bacteria and habitats.Both approaches rely on syntactic rulesdesigned by considering the shallow lin-guistic analysis of the text.
Sub-task 2system also makes use of discourse-basedrules.
The two systems achieve promisingresults on the shared task test data set.1 IntroductionAs the number of publications in the biomedicaldomain continues to increase rapidly, informationretrieval systems which extract valuable informa-tion from these publications have become moreimportant for scientists to access and utilize theknowledge contained in them.Most previous tasks on biomedical informa-tion extraction focus on identifying interactionsand events among bio-molecules (Krallinger et al2008; Kim et al 2009).
The Bacteria BiotopeTask (Bossy et al 2011; Bossy et al 2012) is oneof the new challenges in this domain, which wasfirstly presented in the BioNLP 2011 Shared Task.The main goals of the Bacteria Biotope Task wereto extract bacteria locations, categorize them intoone of the eight types (Environment, Host, Host-Part, Geographical, Water, Food, Medical, Soil),and detect Localization and PartOf events betweenbacteria and habitats.
Automatically extractingthis information from textual sources is crucial forcreating a comprehensive database of bacteria andhabitat relations.
Such a resource would be ofgreat value for research studies and applicationsin several fields such as microbiology, health sci-ences, and food processing.Three teams participated in the BacteriaBiotope Task using different methodologies(Bossy et al 2011; Bossy et al 2012).
BibliomeINRA (Ratkovic et al 2012), which achieved thebest F-score (45%) among these teams, imple-mented a system which used both linguistic fea-tures and reasoning over an ontology to predict lo-cation boundaries and types.
Bibliome also uti-lized some resources such as NCBI Taxonomy1,list of Agrovoc geographical names2, and an in-house developed ontology for specific locationtypes.
UTurku (Bjo?rne et al 2012), presented amachine-learning based system which can be usedto find solutions for all main tasks with a few al-teration in the system.
UTurku used this genericsystem with additional named entity recognitionpatterns and external resources, whereas JAIST(Nguyen and Tsuruoka, 2011) used CRFs in orderto recognize entities and their types.UTurku and JAIST treated event extraction as aclassification problem by using machine learningapproaches, while Bibliome created and utilizeda trigger-word list.
Bibliome tried to find eventsby checking if a trigger-word and entities co-occurin the scope of the same sentence.
Bibliome wasthe only team that considered coreference resolu-tion.
Not considering coreference resolution de-teriorated the performance of JAIST?s system lessthan that of UTurku?s system, since JAIST?s sys-tem operated in the scope of a paragraph, whileUTurku?s system operated in the scope of a sen-1http://www.ncbi.nlm.nih.gov/Taxonomy/2http://aims.fao.org/standards/agrovoc/about170tence.The Bacteria Biotope Task (BB) in the BioNLP2013 Shared Task (Bossy et al 2013) gives an-other opportunity to scientists to develop and com-pare their systems on a reliable platform.
This taskcontains three subtasks.
For Sub-task 1, partici-pants are expected to detect the names and posi-tions of habitat entities, as well as to normalizethese habitats through the OntoBiotope (MBTO)Ontology concepts.
For Sub-task 2, when thenames, types, and positions of the entities (bacte-ria, habitat, geographical) are given, participantsare expected to extract relations which can be ei-ther between bacteria and habitat pairs (Localiza-tion event) or between host and host part pairs(PartOf event).
Sub-task 3 is the same as Sub-task 2, except that the gold standard entities arenot provided to the participants.In this paper, we present two systems, onefor Sub-task 1 (Entity Detection and Categoriza-tion) and one for Sub-task 2 (Localization Rela-tion Extraction) of the Bacteria Biotope Task inthe BioNLP 2013 Shared Task.
Both systems arerule-based and utilize the shallow syntactic analy-sis of the documents.
The Sub-task 2 system alsomakes use of the discourse of the documents.
Thetechnical details of our systems are explained inthe following sections.2 Data SetThe corpus provided by the organizers was cre-ated by collecting documents from many differ-ent web sites, which contain general informationabout bacteria and habitats.
The data set, consist-ing of 52 training, 26 development, and 26 testdocuments, was annotated by the bioinformati-cians of the Bibliome team of MIG Laboratory atthe Institut National de Recherche Agronomique(INRA).For the training and development phases of Sub-task 1, document texts with manually annotatedhabitat entities and the concepts assigned to themthrough the OntoBiotope ontology were provided,while in the test phase, only the unannotated docu-ment texts were given by the task organizers.
TheOntoBiotope ontology which contains 1,700 con-cepts organized in a hierarchy of is-a relations wasalso provided by the organizers for this task.For the training and development phases of Sub-task 2, document texts with manually annotatedbacteria, habitat and geographical entities, as wellas the localization and part-of relations were pro-vided, while in the test phase, document texts an-notated only for bacteria, habitat and geographicalentities were given.3 Bacteria Biotope Detection andOntology-based NormalizatonFor Sub-task 1 (Entity Detection and Categoriza-tion), we implemented a system which appliessyntactic rules to biomedical text after a pre-processing phase, where a given text is split intosentences and parsed using a shallow parser.
Theworkflow of our Sub-task 1 system is shown inFigure 1.
Firstly, each input file is split into sen-tences using the Genia Sentence Splitter (Geni-aSS) (Saetre et al 2007).
The outputs of thesplitter are given to the Genia Tagger (Tsuruokaet al 2005; Tsuruoka and Tsujii, 2005) as inputfiles with the aim of obtaining the lemmas, thepart-of-speech (POS) tags, and the constituent cat-egories of the words in the given biomedical text(e.g., surface form: ticks; lemma: tick; POS tag:NNS; phrase structure: I-NP).
We utilized thesesyntactic information at the following steps of oursystem.In the following subsections, a detailed expla-nation for the detection of habitat boundaries andtheir normalization through the OntoBiotope On-tology concepts is provided.3.1 Entity Boundary DetectionEntity boundary detection, which is the first step ofSub-task 1, includes automatic extraction of habi-tat entities from a given natural language text, anddetection of the entity boundaries precisely.
Inother words, the habitat boundaries that are re-trieved from the texts should not include any un-necessary and non-informative words.
In order toachieve this goal, we assume that bacteria habitatsare embedded in text as noun phrases, and all nounphrases are possible candidates for habitat entities.Based on this assumption, our system follows thesteps that are explained below by using the mod-ules that are shown in Figure 1.As explained before, the Sentence Splitter,POS Tagger, and Shallow Parser are the mod-ules that are utilized in the pre-processing phase.The Noun Phrase Extractor & Simplifiermodule firstly detects the noun phrases in thetext by using the Genia Tagger and then post-processes these noun phrases by using some syn-171POS TaggerSentence SplitterNoun Phrase  Extractor & SimplifierHabitat Name Recognizer & NormalizerHabitat Na e Recognizer & Nor alizerSyntactic RulesShallow ParserLemmatizerDocumentsOntologyNormalized Habitat EntitiesFigure 1: Workflow of the Sub-task 1 Systemtactic rules.
The functions of this module includethe removal of some unnecessary words from thenoun phrases, which are not informative for envi-ronmental locations of bacteria.
To distinguish in-formative words from non-informative ones, oursystem utilizes the POS Tags of each word thatcompose the noun phrases in question.
For ex-ample, words that have determiners or possessivepronouns as their POS Tags should not be includedto the boundaries of the candidate habitat enti-ties.
For example, the in the noun phrase ?thesoybean plant Glycine max?
and its in the nounphrase ?its infectious saliva?
are eliminated fromthe candidate noun phrases, restricting the habi-tat boundary, and creating new candidate nounphrases.The Noun Phrase Extractor & Simplifier mod-ule also includes a mechanism to handle nounphrases that contain the conjunction ?and?.
First,such noun phrases are separated from the conjunc-tion ?and?
into two sub-phrases.
Next, each sub-phrase is searched in the OntoBiotope ontology.If the ontology entries matched for the two sub-phrases have the same direct ancestor (i.e., thetwo ontology entries have a common is-a relation),then the noun phrase consisting of the two sub-phrases connected with the conjunction ?and?
isidentified as a single habitat entity.
On the otherhand, if the ontology entries matched for the twosub-phrases don?t have a common direct ances-tor, then each sub-phrase is identified as a sepa-rate habitat entity.
For example, each of the entityboundaries of the phrases ?nasal and oral cav-ity?
, ?fresh and salt water?, and ?human andsheep?
are handled differently from each other asdescribed below.?
For the first phrase, ?nasal?
is the first sub-phrase and ?oral cavity?
is the second sub-phrase.
The direct ancestor (i.e., the first levelis-a concept) of the first sub-phrase ?nasal?is ?respiratory tract part?
and that of thesecond sub-phrase ?oral cavity?
is ?buccal?.Since ?respiratory tract part?
and ?buccal?is-a concepts are not the same, ?nasal cav-ity?
and ?oral cavity?
are generated as twoseparate habitats.
In other words, if there isnot a direct common is-a concept betweenthe matching terms for the sub-phrases inthe OntoBiotope ontology, then one habitatentity ?nasal cavity?
is generated from thenoun phrase by adding the second part of thesecond sub-phrase ?cavity?
to the first sub-phrase ?nasal?
and another entity is gener-ated by taking the second sub-phrase as awhole ?oral cavity?.?
For the second sample phrase, ?fresh?
is thefirst sub-phrase and ?salt water?
is the sec-ond sub-phrase.
The first sub-phrase ?fresh?matches with an ontology entry whose directancestor is ?environmental water with chem-ical property?
and the second sub-phrase?salt water?
matches with an ontology entrythat has two different direct ancestors ?en-vironmental water with chemical property?and ?saline water?.
Since ?environmentalwater with chemical property?
is a commonancestor for both sub-phrases in the ontology,a single habitat entity ?fresh and salt water?is generated.
In other words, if there is a di-rect common ancestor between the matchingterms for the sub-phrases in the OntoBiotopeontology, then only one habitat entity that iscomposed of the whole noun phrase is gener-ated.172?
For the third phrase, ?human?
is the firstsub-phrase and ?sheep?
is the second sub-phrase.
In this case, two separate habitat en-tities ?human?
and ?sheep?
are generated di-rectly from the two sub-phrases since theydon?t have a common ancestor in the ontol-ogy.At the end of these phases, purified sub-nounphrases, which are habitat entity candidates whoseboundaries are roughly determined by the deletionof non-informative modifiers from noun phrases,are obtained.To determine whether a candidate noun phraseis a habitat entity or not, the Habitat Name Rec-ognizer & Normalizer module searches all on-tology entries, which compose the OntoBiotopeOntology, to find an exact match with the candi-date noun phrase or with parts of it.
In this step,the names, exact synonyms, and related synonymsof ontology entries (ontology entry features) arecompared with the candidate noun phrase.
[Term]id: MBTO:00001828name: digestive tractrelated synonym: ?gastrointestinal tract?
[TyDI:23802]exact synonym: ?GI tract?
[TyDI:23803]related synonym: ?intestinal region?
[TyDI:23805]related synonym: ?gastrointestinal?
[TyDI:23806]exact synonym: ?GIT?
[TyDI:23807]related synonym: ?alimentary canal?
[TyDI:24621]is a: MBTO:00000797 !
organTable 1: First ontology entity match for humangastrointestinal tract.For example, if our candidate noun phrase is?the human gastrointestinal tract?, after the post-processing phase, the purified candidate phrasewill be ?human gastrointestinal tract?.
Whenthe search step for this simplified candidate entityis handled, two different ontology entries are re-turned by our system as matches (see Table 1 forthe first ontology entry match and Table 2 for thesecond one).
These two ontology entries are re-turned as results by our system because the firstone contains the related synonym: ?gastrointesti-nal tract?
and the second one contains the name:human.
Since the system returns matches forthe candidate noun phrase ?human gastrointesti-nal tract?, it is verified that one or more habitatentities can be extracted from this phrase.To detect the exact habitat boundaries, manuallydeveloped syntactic rules are utilized in addition to[Term]id: MBTO:00001402name: humanrelated synonym: ?person?
[TyDI:25453]related synonym: ?individual?
[TyDI:25454]exact synonym: ?subject?
[TyDI:25374]exact synonym: ?homo sapiens?
[TyDI:26681]related synonym: ?people?
[TyDI:25455]is a: MBTO:00001514 !
mammalianTable 2: Second ontology entity match for humangastrointestinal tract.the ontology entry matching algorithm, which isused for entity verification of a candidate phrase.Our system determines the boundaries accordingto the following syntactic rules:?
If an ontology entry matches exactly with thenoun phrase, take the boundaries of the nounphrase as the boundaries of the habitat, anduse the whole phrase to create a new habitatentity.?
If an ontology entry matches beginning fromthe first word of the noun phrase, but doesnot match totally, take the boundaries of thematched parts of the phrase, and create a newhabitat entity using the partial phrase.?
If an ontology entry matches beginning froman internal word of the noun phrase, take theboundaries of the noun phrase as the bound-aries of the habitat, and use the whole phraseto create a new habitat entity.
For exam-ple, in Table 1, the match of the noun phrase?human gastrointestinal tract?
with the re-lated synonym: ?gastrointestinal tract?
gen-erates ?human gastrointestinal tract?
as ahabitat entity.In many cases habitat entity names occur in dif-ferent inflected forms in text.
For example, thehabitat name ?human?, can occur in text in its plu-ral form as ?humans?.
We used the Lemmatizermodule in order to be able to match the differ-ent inflected forms of habitat names occurring intext against the corresponding entires in the Onto-Biotope ontology.
This module applies the rulesdescribed above to the lemmatized forms of thecandidate noun phrases, which are obtained usingthe Genia Tagger.After running the same algorithm also for lem-matized forms of the noun phrase, a merging algo-rithm is used for the matching results of the sur-173face and lemmatized forms of the noun phrases inorder to create an output file, which contains thepredicted habitat entities and their positions in theinput text.3.2 Ontology CategorizationFor Sub-task 1, detection of the entities and theirboundaries is not sufficient.
In order to obtainnormalized entity names, participants are also ex-pected to assign at least one ontology conceptfrom the OntoBiotope Ontology to all habitat en-tities, which are automatically extracted by theirsystems from the input text.While our system detects entities and theirboundaries (as explained in detail in Section 3.1),it also assigns ontology concepts to the re-trieved entities.
All assigned concepts are ref-erenced by the MBTO-IDs of the matched on-tology entries (e.g, MBTO:00001402 for humanand MBTO:00001828 for human gastrointestinaltract) (see Table 3).4 Event ExtractionFor Sub-task 2 (Localization Event ExtractionTask), we used different methods according to therelation type that we are trying to extract.
Theworkflow of our system is shown in Figure 2.
Thedetails of our approach are explained in the fol-lowing sub-sections.4.1 Localization Event ExtractionIn order to extract localization relations, we as-sume that discourse changes with the beginning ofa new paragraph.
Our system firstly splits the in-put text into paragraphs.
Next, the entities (bacte-ria and habitats) that occur in the given paragraphare identified.
We assume that the paragraph isabout the bacterium whose name occurs first in theparagraph.
Therefore, we assign all the habitat en-tities to that bacterium.
If the name of this bac-terium occurs in previous paragraphs as well, thenthe boundary of the bacterium entity is set to itsfirst occurrence in the document.We also have a special case for boundary de-termination of bacteria in the localization rela-tion.
If a bacterium name contains the word?strain?
, we assign the first occurrence of itsname without the word ?strain?
(e.g, Bifidobac-terium longum NCC2705 instead of Bifidobac-terium longum strain NCC2705).Figure 2: Workflow of the Sub-task 2 System4.2 PartOf Event ExtractionIn order to detect partOf relations between hostsand host parts in a given biomedical text, we as-sumed that such relations can only exist if thehost and the host part entities occur in the sameparagraph.
Based on this assumption, we pro-pose that if a habitat name is a subunit of the termwhich identifies another habitat that passes in thesame discourse, then they are likely to be relatedthrough a partOf relation.
In other words, if onehabitat contains the other one, and obeys somesyntactic rules, then there is a relation.
For exam-ple, ?respiratory track of animals?
is a habitat and?animals?
is another habitat, both of which are inthe same paragraph.
Since the ?respiratory trackof animals?
phrase contains the ?animals?
phraseand the word ?of?, and the ?animals?
phrase is onthe right hand side of the ?respiratory track of ani-mals?
phrase, our system detects a partOf relationbetween them.5 EvaluationThe official evaluation results on the test set areprovided using different criteria for the two sub-tasks by the task organizers3.3http://2013.bionlp-st.org/tasks/bacteria-biotopes/test-results174EntityID Boundary EntityT1 Habitat 113 118 humanT2 Habitat 113 141 human gastrointestinal tractID EntityID ReferenceN1 OntoBiotope Annotation:T1 Referent:MBTO:00001402N2 OntoBiotope Annotation:T2 Referent:MBTO:00001828Table 3: Detected entities and boundaries from the human gastrointestinal tract noun phraseFor Sub-task 1, submissions are evaluated con-sidering the Slot Error Rate (SER), which dependson the number of substitutions S, deletions D, in-sertions I, and N. N is the number of habitats inthe reference, while D and I are the number ofreference and predicted entities that could not bepaired, respectively.SER =S + D + IN(1)The number of substitutions S is calculated byusing Equation 2.
Here J is the Jaccard index be-tween the reference and the predicted entity, whichmeasures the accuracy of the boundaries of thepredicted entity (Bossy et al 2012).
W is a param-eter that defines the semantic similarity betweenthe ontology concepts related to the reference en-tity and to the predicted entity (Wang et al 2007).This similarity is based on the is-a relationshipsbetween concepts, and used for penalizing ances-tor/descendent predictions more compared to sib-ling predictions as it approaches to 1.S = J ?W (2)For Sub-task 2, precision, recall, and f-scoremetrics are used for evaluation.
In the followingsubsections, our official evaluation results for Sub-task 1 and Sub-task 2 are given.5.1 Results of Sub-task 1Our official evaluation results on test set are shownin Table 4.
Our system ranked second according tothe SER value among four participating systems inthe shared task.The official results of our system on the test setfor entity boundary detection are shown in Table 5.Our system obtained the smallest SER value fordetecting the entity boundaries (i.e., the best per-formance) among the other participating systems.Our ontology categorization evaluation resultson the test set, which do not take into account theMain ResultsS 112.70I 43D 89M 305.30P 520SER 0.48Recall 0.60Precision 0.59F1 0.59Table 4: Main results on test set for Sub-task 1(En-tity Boundary Detection & Ontology Categoriza-tion)Entity Boundary EvaluationS 82.71M 335.29SER 0.42Recall 0.66Precision 0.64F1 0.65Table 5: Entity boundary detection results on thetest set for Sub-task 1entities?
boundaries are shown in Table 6.
Our sys-tem ranked second on the main evaluation wherethe parameter w (described in Section 5) was setto 0.65.
As shown in the table, as the w value in-creases, our results get better.
According to the of-ficial results, our system ranked first for w = 1 withthe highest f-score, and our SER result is same asthe best system for w = 0.8.The parameter w can can be seen as a penal-ization value for the false concept references.
Asw increases, the false references to distant ances-tors and descendants of the true reference conceptsare penalized more, whereas as w decreases thefalse references to the siblings are penalized moreseverely.The results also show that our system is able toachieve balanced precision and recall values.
Inother words, the recall and precision values areclose to each other.175w S M SER Recall Precision F1 38.64 379.36 0.34 0.75 0.73 0.740.8 44.90 373.10 0.35 0.74 0.72 0.730.65 50.95 367.05 0.36 0.72 0.71 0.710.1 70.78 347.22 0.40 0.68 0.67 0.68Table 6: Ontology Categorization results for Sub-task 1 on the test set5.2 Results of Sub-task 2The precision, recall, and f-measure metrics areused to evaluate the Sub-task 2 results on the testset.
Our main evaluation results, which considerdetection of both Localization and PartOf event re-lations for Sub-task 2 are shown in the first row ofTable 7, whereas our results that are calculated forthe two event types separately are shown in the Lo-calization and PartOf rows of the table.
Accord-ing to the official results, our system ranked thirdfor detecting all event types.
On the other hand, itachieved the best results for detecting the PartOfevents.Recall Precision FAll 0.21 0.38 0.27Localization 0.23 0.38 0.29PartOf 0.15 0.40 0.22Table 7: Main results on test set for Sub-task 26 ConclusionIn this study, we presented two systems that areimplemented in the scope of the BioNLP SharedTask 2013 - Bacteria Biotope Task.
The aim ofthe Sub-task 1 system is the identification of habi-tat mentions in unstructured biomedical text andtheir normalization through the OntoBiotope on-tology, whereas the goal of the Sub-task 2 systemis the extraction of localization and part-of rela-tions between bacteria and habitats when the enti-ties are given.
Both systems are based on syntacticrules designed by considering the shallow syntac-tic analysis of the text, while the Sub-task 2 systemalso makes use of discourse-based rules.According to the official evaluation, both of oursystems achieved promising results on the sharedtask test data set.
Based on the main evaluationwhere the parameter w is set to 0.65, our Sub-task1 system ranked second among four participatingsystems and it ranked first for predicting the entityboundaries when ontology categorization outputsare not considered.
The results show that our sys-tem performs better as w increases and achievesthe best performance when w = 1 and w = 0.8.
OurSub-task 2 system achieved encouraging results byranking first in predicting the PartOf events, andranking third when all event types are considered.The proposed systems can be enhanced by in-corporating a stemming module and includingmore syntax and discourse based rules.AcknowledgmentsThis work has been supported by Marie CurieFP7-Reintegration-Grants within the 7th Euro-pean Community Framework Programme.ReferencesJari Bjo?rne, Filip Ginter, and Tapio Salakoski.
2012.University of Turku in the BioNLP?11 Shared Task.BMC Bioinformatics, 13 Suppl 11:S4.Robert Bossy, Julien Jourde, Philippe Bessie`res,Maarten van de Guchte, and Claire Ne?dellec.
2011.Bionlp shared task 2011: bacteria biotope.
In Pro-ceedings of the BioNLP Shared Task 2011 Work-shop, BioNLP Shared Task ?11, pages 56?64,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Robert Bossy, Julien Jourde, Alain P. Manine, PhilippeVeber, Erick Alphonse, Maarten van de Guchte,Philippe Bessieres, and Claire Nedellec.
2012.BioNLP Shared Task - The Bacteria Track.
BMCBioinformatics, 13(Suppl 11):S3+.Robert Bossy, Wiktoria Golik, Zorana Ratkovic,Philippe Bessir`es, and Claire Ne?dellec.
2013.BioNLP shared task 2013 - an overview of the bac-teria biotope task.
In Proceedings of BioNLP SharedTask 2013 Workshop, Sofia, Bulgaria, AUG. Associ-ation for Computational Linguistics.Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-nobu Kano, and Jun?ichi Tsujii.
2009.
Overviewof bionlp?09 shared task on event extraction.
InProceedings of the Workshop on Current Trends inBiomedical Natural Language Processing: SharedTask, BioNLP ?09, pages 1?9, Stroudsburg, PA,USA.
Association for Computational Linguistics.Martin Krallinger, Florian Leitner, Carlos Rodriguez-penagos, and Alfonso Valencia.
2008.
Overview ofthe protein-protein interaction annotation extractiontask of biocreative ii.
Genome Biology, pages 2?4.Nhung T. H. Nguyen and Yoshimasa Tsuruoka.
2011.Extracting bacteria biotopes with semi-supervisednamed entity recognition and coreference resolution.In Proceedings of the BioNLP Shared Task 2011Workshop, BioNLP Shared Task ?11, pages 94?101,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.176Zorana Ratkovic, Wiktoria Golik, and Pierre Warnier.2012.
Event extraction of bacteria biotopes: aknowledge-intensive NLP-based approach.
BMCBioinformatics, 13:S8+.Rune Saetre, Kazuhiro Yoshida, Akane Yakushiji,Yusuke Miyao, Yuichiro Matsubayashi, and TomokoOhta.
2007.
AKANE System: Protein-ProteinInteraction Pairs in the BioCreAtIvE2 Challenge,PPI-IPS subtask.
In Lynette Hirschman, MartinKrallinger, and Alfonso Valencia, editors, Proceed-ings of the Second BioCreative Challenge Workshop.Yoshimasa Tsuruoka and Jun?ichi Tsujii.
2005.
Bidi-rectional inference with the easiest-first strategy fortagging sequence data.
In HLT ?05: Proceedingsof the conference on Human Language Technologyand Empirical Methods in Natural Language Pro-cessing, pages 467?474.
Association for Computa-tional Linguistics.Yoshimasa Tsuruoka, Yuka Tateishi, Jin-Dong Kim,Tomoko Ohta, John McNaught, Sophia Ananiadou,and Jun?ichi Tsujii.
2005.
Developing a Ro-bust Part-of-Speech Tagger for Biomedical Text.
InPanayiotis Bozanis and Elias N. Houstis, editors,Advances in Informatics, volume 3746, chapter 36,pages 382?392.
Springer Berlin Heidelberg.J.
Z. Wang, Z.
Du, R. Payattakool, P. S. Yu, andC.
F. Chen.
2007.
A new method to measure thesemantic similarity of GO terms.
Bioinformatics,23(10):1274?1281, May.177
