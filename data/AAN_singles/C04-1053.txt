Evaluating Cross-Language Annotation Transfer in the MultiSemCor CorpusLuisa BENTIVOGLI, Pamela FORNER, Emanuele PIANTAITC-irstVia Sommarive, 1838050 Povo ?
TrentoItaly{bentivo, forner, pianta}@itc.itAbstractIn this paper we illustrate and evaluate an approachto the creation of high quality linguisticallyannotated resources based on the exploitation ofaligned parallel corpora.
This approach is based onthe assumption that if a text in one language hasbeen annotated and its translation has not,annotations can be transferred from the source textto the target using word alignment as a bridge.
Thetransfer approach has been tested in the creation ofthe MultiSemCor corpus, an English/Italianparallel corpus created on the basis of the EnglishSemCor corpus.
In MultiSemCor texts are alignedat the word level and semantically annotated with ashared inventory of senses.
We present someexperiments carried out to evaluate the differentsteps involved in the methodology.
The results ofthe evaluation suggest that the cross-languageannotation transfer methodology is a promisingsolution allowing for the exploitation of existing(mostly English) annotated resources to bootstrapthe creation of annotated corpora in new (resource-poor) languages with greatly reduced human effort.1 IntroductionLarge-scale language resources play a crucial rolefor a steady progress in the field of NaturalLanguage Processing (NLP), as they are essentialfor carrying out basic research and for buildingportable and robust systems with broad coverage.More specifically, given the advances of machinelearning statistical methods for NLP, withsupervised training methods leading the way tomajor improvements in performance on differenttasks, a particularly valuable resource is nowrepresented by large linguistically annotatedcorpora.Up until some years ago, linguistically annotatedcorpora were only produced through manualannotation, or by manual check of automaticallyproduced annotations.
Unfortunately, manualannotation is a very difficult and time-consumingtask, and this fact has led to a shortage of manual-quality annotated data.
The scarcity of large sizeannotated corpora is more acute for languagesdifferent from English, for which even minimalamounts of data are still missing.
This state ofaffairs makes it clear that any endeavour aiming atreducing the human effort needed to producemanual-quality labelled data will be highlybeneficial to the field.Recent studies have shown that a valuableopportunity for breaking the annotated resourcebottleneck is represented by parallel corpora,which can be exploited in the creation of resourcesfor new languages via projection of annotationsavailable in another language.
This paperrepresents our contribution to the research in thisfield.
We present a novel methodology to create asemantically annotated corpus by exploitinginformation contained in an already annotatedcorpus, using word alignment as a bridge.
Themethodology has been applied in the creation ofthe MultiSemCor corpus.
MultiSemCor is anEnglish/Italian parallel corpus which is beingcreated on the basis of the English SemCor corpusand where the texts are aligned at the word leveland semantically annotated with a shared inventoryof senses.Given the promising results of a pilot studypresented in (Bentivogli and Pianta, 2002), theMultiSemCor corpus is now under development.
Inthis paper we focus on a thorough evaluation of thesteps involved in the transfer methodology.
Weevaluate the performance of a new version of theword alignment system and the final quality of theannotations transferred from English to Italian.
InSection 2 we lay out the annotation transfermethodology and summarize some related work.
InSection 3 we discuss some problematic issuesrelated to the methodology which will beextensively tested and evaluated in Section 4.
InSection 5 we report about the state of developmentof the MultiSemCor corpus and, finally, in Section6 we present conclusions and our thoughts onfuture work.2 The Annotation Transfer MethodologyThe MultiSemCor project (Bentivogli and Pianta,2002) aims at building an English/Italian parallelcorpus, aligned at the word level and annotatedwith PoS, lemma and word sense.
The parallelcorpus is created by exploiting the SemCor corpus(Landes et al, 1998), which is a subset of theEnglish Brown corpus containing about 700,000running words.
In SemCor all the words are taggedby PoS, and more than 200,000 content words arealso lemmatized and sense-tagged with referenceto the WordNet lexical database1 (Fellbaum, 1998).The main hypothesis underlying thismethodology is that, given a text and its translationinto another language, the semantic information ismostly preserved during the translation process.Therefore, if the texts in one language have beensemantically annotated and their translations havenot, annotations can be transferred from the sourcelanguage to the target using word alignment as abridge.The first problem to be solved in the creation ofMultiSemCor was the fact that the Italiantranslations of the SemCor texts did not exist.
Oursolution was to have the translations made byprofessional translators.
Given the high costs ofbuilding semantically annotated corpora, requiringspecific skills and very specialized training, wethink that manually translating the annotatedcorpus and automatically transferring theannotations may be preferable to hand-labelling acorpus from scratch.
Not only are translators moreeasily available than linguistic annotators, buttranslations may be a more flexible and durablekind of annotation.
Moreover, the annotationtransfer methodology has the further advantage ofproducing a parallel corpus.With respect to a situation in which thetranslation of a corpus is already available, acorpus translated on purpose presents theadvantage that translations can be ?controlled?,i.e.
carried out following criteria aiming atmaximizing alignment and annotation transfer.
Ourprofessional translators are asked to use,preferably, the same dictionaries used by the wordaligner, and to maximize, whenever possible, thelexical correspondences between source and targettexts.
The translators are also told that thecontrolled translation criteria should never befollowed to the detriment of a good Italian prose.Controlled translations cost the same as freetranslations, while having the advantage of1WordNet is an English lexical database, developedat Princeton University, in which nouns, verbs,adjectives, and adverbs are organized into sets ofsynonyms (synsets) and linked to each other by meansof various lexical and semantic relationships.
In the lastyears, within the NLP community WordNet has becomethe reference lexicon for almost all tasks involving wordsense disambiguation (see, for instance, the Sensevalcompetition).enhancing the performances of the annotationtransfer procedure.Once the SemCor texts have been translated, thestrategy for creating MultiSemCor consists of (i)automatically aligning Italian and English texts atthe word level, and (ii) automatically transferringthe word sense annotations from English to thealigned Italian words.
The final result of theMultiSemCor project is an Italian corpus annotatedwith PoS, lemma and word sense, but also analigned parallel corpus lexically annotated with ashared inventory of word senses.
Morespecifically, the sense inventory used isMultiWordNet (Pianta et al, 2002), a multilinguallexical database in which the Italian component isstrictly aligned with the English WordNet.2.1 Related WorkThe idea of obtaining linguistic information abouta text in one language by exploiting parallel orcomparable texts in another language has beenexplored in the field of Word SenseDisambiguation (WSD) since the early 90?s, themost representative works being (Brown et al,1991), (Gale et al, 1992), and (Dagan and Itai,1994).In more recent years, Ide et al (2002) present amethod to identify word meanings starting from amultilingual corpus.
A by-product of applying thismethod is that once a word in one language isword-sense tagged, the translation equivalents inthe parallel texts are also automatically annotated.Cross-language tagging is the goal of the workby Diab and Resnik (2002), who present a methodfor word sense tagging both the source and targettexts of parallel bilingual corpora with theWordNet sense inventory.Parallel to the studies regarding the projection ofsemantic information, more recently the NLPcommunity has also explored the possibility ofexploiting translation to project more syntax-oriented annotations.
Yarowsky et al (2001)describe a successful method consisting of (i)automatic annotation of English texts, (ii) cross-language projection of annotations onto targetlanguage texts, and (iii) induction of noise-robusttaggers for the target language.
A further step ismade in (Hwa et al, 2002) and (Cabezas et al,2001), which address the task of acquiring adependency treebank by bootstrapping fromexisting linguistic resources for English.
Finally, in(Riloff et al, 2002) a method is presented forrapidly creating Information Extraction (IE)systems for new languages by exploiting existingIE systems via cross-language projection.The results of all the above mentioned studiesshow how previous major investments in Englishannotated corpora and tool development can beeffectively leveraged across languages, allowingthe development of accurate resources and tools inother languages without comparable human effort.3 Quality IssuesThe MultiSemCor project raises a number oftheoretical and practical issues.
For instance: istranslational language fully representative of thegeneral use of language in the same way asoriginal language is?
To what extent are the lexicaof different languages comparable?
Thesetheoretical issues have already been presented in(Pianta and Bentivogli, 2003) and will not bediscussed here.
In the following, we address theissue of the quality of the annotation resulting fromthe application of the methodology.As opposed to automatic word sensedisambiguation tasks, the MultiSemCor projectspecifically aims at producing manual-qualityannotated data.
Therefore, a potential risk whichneeds to be faced is represented by the possibledegradation of the Italian annotation qualitythrough the various steps of the annotation transferprocedure.
A number of factors must be taken intoaccount.
First, annotation errors can be found inthe original English texts.
Then, the word alignermay align words incorrectly, and finally thetransfer of the semantic annotations may not beapplicable to certain translation pairs.SemCor quality.
The English SemCor corpus hasbeen manually annotated.
However, someannotation errors can be found in the texts (seeFellbaum et al, 1998, for SemCor taggers?confidence ratings).
As an example, the wordpocket in the sentence ?He put his hands on hispockets?
was incorrectly tagged with the WordNetsynset {pouch, sac, sack, pocket -- an enclosedspace} instead of the correct one {pocket -- a smallpouch in a garment for carrying small articles}.Word alignment quality.
The feasibility of theentire MultiSemCor project heavily depends on theavailability of an English/Italian word aligner withvery good performance in terms of recall and,more importantly, precision.Transfer quality.
Even when both the originalEnglish annotations and the word alignment arecorrect, a number of cases still remain for whichthe transfer of the annotation is not applicable.
Anannotation is not transferable from the sourcelanguage to the target when the translationequivalent does not preserve the lexical meaning ofthe source language.
In these cases, if thealignment process puts the two expressions incorrespondence, then the transfer of the senseannotation from the source to the target language isnot correct.The first main cause of incorrect transfer isrepresented by translation equivalents which arenot cross-language synonyms of the sourcelanguage words.
For example, in a sentence of thecorpus the English word meaning is translated withthe Italian word motivo (reason, grounds) which issuitable in that specific context but is not asynonymic translation of the English word.
In thiscase, if the two words are aligned, the transfer ofthe sense annotation from English is not correct asthe English sense annotation is not suitable for theItalian word.
A specific case of non-synonymoustranslation occurs when a translation equivalentdoes not belong to the same lexical category of thesource word.
For example, the English verb tocoexist in the sentence ?the possibility for man tocoexist with animals?
has been translated with theItalian noun coesistenza (coexistence) in ?lepossibilit?
di coesistenza tra gli uomini e glianimali?.
Even if the translation is suitable for thatcontext, the English sense of the verb cannot betransferred to the Italian noun.
Sometimes, non-synonymous translations are due to errors in theItalian translation, as in pull translated as spingere(push).A second case which offers challenge to thesense annotation transfer is phrasalcorrespondence, occurring when a target phrasehas globally the same meaning as thecorresponding source phrase, but the single wordsof the phrase are not cross-language synonyms oftheir corresponding source words.
For example, theexpression a dreamer sees has been translated asuna persona sogna (a person dreams).
The Italiantranslation maintains the synonymy at the phraselevel but the single component words do not.Therefore, if the single words were aligned anytransfer from English to Italian would be incorrect.Another example of phrasal correspondence, inwhich the semantic equivalence between words inthe source and target phrase is even fuzzier, isgiven by the English phrase the days would getshorter and shorter translated as imminente finedei tempi (imminent end of times).Another controversial cause of possible incorrecttransfer is represented by the case in which thetranslation equivalent is indeed a cross-languagesynonym of the source expression but it is not alexical unit.
This usually happens with lexicalgaps, i.e.
when a language expresses a conceptwith a lexical unit whereas the other languageexpresses the same concept with a freecombination of words, as for instance the Englishword successfully which can only be translatedwith the Italian free combination of words consuccesso (with success).
However, it can also bethe result of a choice made by the translator whodecides to use a free combination of words insteadof a possible lexical unit, as in empiricallytranslated as in modo empirico (in an empiricalmanner) instead of empiricamente.
In these casesthe problem arises because in principle if the targetexpression is not a lexical unit it cannot beannotated as a whole.
On the contrary, eachcomponent of the free combination of wordsshould be annotated with its respective sense.In the next Section we will address these qualityissues in order to assess the extent to which theyaffect the cross-language annotation transfermethodology.4 Evaluation of the Annotation TransferMethodologyA number of experiments have been carried out inorder to test the various steps involved in theannotation transfer methodology.
More precisely,we evaluated the performances of the wordalignment system and the quality of the finalannotation of the Italian corpus.4.1 Word AlignmentWord alignment is the first crucial step in themethodology applied to build MultiSemCor.
Theword aligner used in the project is KNOWA(KNOwledge-intensive Word Aligner), anEnglish/Italian word aligner, developed at ITC-irst,which relies mostly on information contained inthe Collins bilingual dictionary, available inelectronic format.
KNOWA also exploits amorphological analyzer and a multiwordrecognizer for both English and Italian.
For adetailed discussion of the characteristics of thistool, see (Pianta and Bentivogli, 2004).Some characteristics of the MultiSemCorscenario make the alignment task easier forKNOWA.
First, in SemCor all multiwordsincluded in WordNet are explicitly marked.
ThusKNOWA does not need to recognize Englishmultiwords, although it still needs to recognize theItalian ones.
Second, within MultiSemCor wordalignment is done with the final aim of transferringlexical annotations from English to Italian.
Sinceonly content words have word sense annotations inSemCor, it is more important that KNOWAbehaves correctly on content words, which areeasier to align than functional words.To evaluate the word aligner performance on theMultiSemCor task we created a gold standardcomposed of three English unseen texts (br-f43,br-l10, br-j53) taken randomly from theSemCor corpus.
For each English text both acontrolled and a free translation were made.
Giventhe expectation that free translations are lesssuitable for word alignment, we decided to testKNOWA also on them in order to verify if theannotation transfer methodology can be applied toalready existing parallel corpora.The six resulting pairs of texts were manuallyaligned following a set of alignment guidelineswhich have been defined taking into account thework done in similar word alignment projects(Melamed, 2001).
Annotators were asked to aligndifferent kinds of units (simple words, segments ofmore than one word, parts of words) and to markdifferent kinds of semantic correspondencebetween the aligned units, e.g.
full correspondence(synonymic), non synonymic, changes in lexicalcategory, phrasal correspondence.
Inter-annotatoragreement was measured with the Dice coefficientproposed in (V?ronis and Langlais, 2000) and canbe considered satisfactory as it turned out to be87% for free translations and 92% for controlledtranslations.
As expected, controlled translationsproduced a better agreement rate betweenannotators.For assessing the performance of KNOWA, thestandard notions of Precision, Recall, andCoverage have been used following (V?ronis andLanglais, 2000).
See (Och and Ney, 2003) andArenberg et al, 2000) for different evaluationmetrics.
The performance of KNOWA applied tothe MultiSemCor gold standard in a full-textalignment task is shown in Table 1.
These results,which compare well with those reported in theliterature (V?ronis, 2000) show that, as expected,controlled translations allow for a better alignmentbut also that free translations may be satisfactorilyaligned.The evaluation of KNOWA with respect to theEnglish content words which have a semantic tagin SemCor is reported in Tables 2 and 3, for bothfree and controlled translations and broken downby Part of Speech.Precision Recall CoverageFree 83.5 57.9 60.0Controlled 88.4 67.5  74.9Table 1: KNOWA on Full-textPrecision Recall CoverageNouns 93.7 81.1 86.5Verbs 85.6 70.3 82.1Adjectives 95.6 64.7 67.7Adverbs 88.4 38.5 43.5Total 91.2 68.2 74.8Table 2: KNOWA on sense-tagged words only(Free translations)Precision Recall CoverageNouns 95.9 82.5 86.1Verbs 90.7 76.8 84.7Adjectives 95.2 69.9 73.5Adverbs 90.4 51.6 57.1Total 93.9 74.6 79.5Table 3: KNOWA on sense-tagged words only(Controlled translations)We can see that ignoring function words theperformance of the word aligner improves in bothprecision and recall.4.2 Italian Annotation QualityAs pointed out in Section 3, even in the case of aperfect word alignment the transfer of theannotations from English to the correctly alignedItalian words can still be a source of errors in theresulting Italian annotations.
In order to evaluatethe quality of the annotations automaticallytransferred to Italian, a new gold standard wascreated starting from SemCor text br-g11.
TheEnglish text, containing 2,153 tokens and 1,054semantic annotations, was translated into Italian ina controlled modality.
The resulting Italian text iscomposed of 2,351 tokens, among which 1,085 arecontent words to be annotated.
The English textand its Italian translation were manually alignedand the Italian text was manually semanticallyannotated taking into account the annotations ofthe English words.
Each time an Englishannotation was appropriate for the Italiancorresponding word, the annotator used it also forItalian.
Otherwise, the annotator did not use theoriginal English annotation for the Italian word andlooked in WordNet for a suitable annotation.Moreover, when the English annotations werenot suitable for annotating the Italian words, theannotator explicitly distinguished between wrongEnglish annotations and English annotations thatcould not be transferred to the Italian translationequivalents.
The errors in the English annotationsamount to 24 cases.
Non-transferable annotationsamount to 155, among which 143 are due to lackof synonymy at lexical level and 12 to translationequivalents which are not lexical units.The differences between the English and Italiantext with respect to the number of tokens andannotations have also been analysed.
The Italiantext has about 200 tokens and 31 annotated wordsmore than the English text.
The difference in thenumber of tokens is due to various factors.
First,there are grammatical characteristics specific to theItalian language, such as a different usage ofarticles, or a greater usage of reflexive verbs whichleads to a higher number of clitics.
For example,the English sentence ?as cells coalesced?
must betranslated into Italian as ?quando le cellule siunirono?.
Then, we have single English wordstranslated into Italian with free combinations ofwords (ex: down translated as verso il basso) andmultiwords which are recognized in English andnot recognized in Italian (e.g.
one token fornucleic_acid in the English text and two tokens inthe Italian text, one for acido and one fornucleico).
As regards content words to beannotated, we would have expected that theirnumber was the same both in English and Italian.In fact, the difference we found is much lower thanthe difference between tokens.
This difference isexplained by the fact that some English contentwords have not been annotated.
For example,modal and auxiliary verbs (to have, to be, can,may, to have to, etc.)
and partitives (some, any)where systematically left unannotated in theEnglish text whereas they have been annotated forItalian.The automatic procedures for word alignmentand annotation transfer were run on text br-g11and evaluated against the gold standard.
The totalnumber of transferred senses amounts to 879.Among them, 756 are correct and 123 are incorrectfor the Italian words.
Table 4 summarizes theresults in terms of precision, recall and coveragewith respect to both English annotations available(1,054) and Italian words to be annotated (1,085).We can see that the final quality of the Italianannotations is acceptable, the precision amountingto 86.0%.
The annotation error rate of 14.0% hasbeen analyzed in order to classify the differentfactors affecting the transfer methodology.
Table 5reports the data about the composition of theincorrect transfer.Comparing the number of annotation errors inthe English source, as marked up during thecreation of the gold standard (24), with the numberof errors in the Italian annotation due to errors inthe original annotation (22), we can see that almostall of the source errors have been transferred,contributing in a consistent way to the overallItalian annotation error rate.As regards word alignment, br-g11 was arelatively easy text as the performance of KNOWA(i.e.
96.5%) is higher than that obtained with thetest set (see Table 3).Precision Recall CoverageWrt English 86.0 71.7 83.4Wrt Italian 86.0 69.7 81.0Table 4: Annotation evaluation on text br-g11# %English annotation errors 22 2.5Word alignment errors 31 3.5Non-transferable annotations 70 8.0Total incorrect transfers 123 14.0Table 5: Composition of the incorrect transferThe last source of annotation errors isrepresented by words which have been correctlyaligned but whose word sense annotation cannot betransferred.
This happens with (i) translationequivalents which are lexical units but are notcross-language synonyms, and (ii) translationequivalents which are cross-language synonymsbut are not lexical units.
In practice, given thedifficulty in deciding what is a lexical unit andwhat is not, we decided to accept the transfer of aword sense from an English lexical unit to anItalian free combination of words (see for instanceocchiali da sole annotated with the sense ofsunglasses).
Therefore, only the lack of synonymyat lexical level has been considered an annotationerror.The obtained results are encouraging.
Amongthe 143 non-synonymous translations marked inthe gold standard, only 70 have been aligned by theword alignment system, showing that KNOWA iswell suited to the MultiSemCor task.
The reason isthat it relies on bilingual dictionaries where non-synonymous translations are quite rare.
This can bean advantage with respect to statistics-based wordaligners, which are expected to be able to align agreat number of non-synonymous translations, thusintroducing more errors in the transfer procedure.A final remark about the evaluation concerns theproportion of non-transferable word senses withrespect to errors in the original Englishannotations.
It is sometimes very difficult todistinguish between annotation errors and non-transferable word senses, also because we are notEnglish native speakers.
Thus, we preferred to beconservative in marking English annotations aserrors unless in very clear cases.
This approachmay have reduced the number of the errors in theoriginal English corpus and augmented the numberof non-transferable word senses, thus penalizingthe transfer procedure itself.Summing up, the cross-language annotationtransfer methodology produces an Italian corpuswhich is tagged with a final precision of 86.0%.After the application of the methodology 19.0% ofthe Italian words still need to be annotated (see theannotation coverage of 81.0%).
We think that,given the precision and coverage rates obtainedfrom the evaluation, the corpus as it results fromthe automatic procedure can be profitably used.However, even in the case that a manual revision isenvisaged, we think that hand-checking theautomatically tagged corpus and manuallyannotating the remaining 19% still results to becost effective with respect to annotating the corpusfrom scratch.5 The MultiSemCor Corpus Up to NowWe are currently working at the extensiveapplication of the annotation transfer methodologyfor the creation of the MultiSemCor corpus.
Up tonow, MultiSemCor is composed of 29 Englishtexts aligned at the word level with theircorresponding Italian translations.
Both source andtarget texts are annotated with POS, lemma, andword sense.
More specifically, as regards Englishwe have 55,935 running words among which29,655 words are semantically annotated (fromSemCor).
As for Italian, the corpus amounts to59,726 running words among which 23,095 wordsare annotated with word senses that have beenautomatically transferred from English.MultiSemCor can be a useful resource for avariety of tasks, both as a monolingualsemantically annotated corpus and as a parallelaligned corpus.
As an example, we are alreadyusing it to automatically enrich the Italiancomponent of MultiWordNet, the reference lexiconof MultiSemCor.
As a matter of fact, out of the23,095 Italian words automatically sense-tagged,5,292 are not yet present in MultiWordNet and willbe added to it.
Moreover, the Italian component ofMultiSemCor is being used as a gold standard forthe evaluation of Word Sense Disambiguationsystems working on Italian.
Besides NLPapplications, MultiSemCor is also suitable to beconsulted by humans through a Web interface(Ranieri et al, 2004) which is available at:http://tcc.itc.it/projects/multisemcor.6 Conclusion and future directionsWe have presented and evaluated an approach tothe creation of high quality semantically annotatedresources based on the exploitation of alignedparallel corpora.
The results obtained from thethorough evaluation of the different steps involvedin the methodology confirm the feasibility of theMultiSemCor project.
The cross-lingual annotationtransfer methodology is going to be applied also tothe remaining 157 SemCor texts, which arecurrently being translated into Italian.As regards future research directions within thetransfer annotation paradigm, it would beinteresting to extend the methodology to otherlanguages, e.g.
Spanish, for which a WordNetexists and can be aligned with MultiWordNet.Moreover, as the Brown Corpus, used to createSemCor, has been syntactically annotated withinthe English Penn Treebank, the syntacticannotations of the SemCor texts are also available.We are planning to explore the possibility oftransferring the syntactic annotations from theEnglish to the Italian texts of MultiSemCor.ReferencesL.
Ahrenberg, M. Merkel, H. Sagvall and A. J.Tiedemann.
2000.
Evaluation of word alignmentsystems.
In Proceedings of LREC 2000, Athens,Greece.L.
Bentivogli and E. Pianta.
2002.
OpportunisticSemantic Tagging.
In Proceedings of LREC-2002, Las Palmas, Canary Islands, Spain.P.
F. Brown, S. A. Della Pietra, V. J. Della Pietra,and R. L. Mercer.
1991.
Word-SenseDisambiguation using Statistical Methods.
InProceedings of ACL?91, Berkeley, California,USA.C.
Cabezas, B. Dorr and P. Resnik.
2001.
SpanishLanguage Processing at University of Maryland:Building Infrastructure for MultilingualApplications.
In Proceedings of the 2ndInternational Workshop on Spanish LanguageProcessing and Language Technologies, Jaen,Spain.I.
Dagan and A. Itai.
1994.
Word SenseDisambiguation Using a Second LanguageMonolingual Corpus.
Computational Linguistics:20(4):563-596.M.
Diab and P. Resnik.
2002.
An unsupervisedmethod for word sense tagging using parallelcorpora.
In In Proceedings of ACL 2002,Philadelphia, USA .C.
Fellbaum, J. Grabowski and S. Landes.
1998.Performance and confidence in a semanticannotation task.
In Fellbaum, C.
(ed.).
1998.WordNet: An Electronic Lexical Database.
TheMIT Press, Cambridge (Mass.).C.
Fellbaum (ed.).
1998.
WordNet: An ElectronicLexical Database.
The MIT Press, Cambridge(Mass.).W.
A. Gale, K. W. Church and D. Yarowsky.1992.
Using Bilingual Materials to DevelopWord Sense Disambiguation Methods.
InProceedings of the Fourth InternationalConference on Theoretical and MethodologicalIssues in Machine Translation.
Montreal,Canada.R.
Hwa, P. Resnik and A. Weinberg.
2002.Breaking the Resource Bottleneck forMultilingual Parsing.
In Proceedings of theLREC-2002 Workshop on "Linguistic KnowledgeAcquisition and Representation: BootstrappingAnnotated Language Data'', Las Palmas, CanaryIslands, Spain.N.
Ide, T. Erjavec, and D. Tufis.
2002.
SenseDiscrimination with Parallel Corpora.
InProceedings of ACL'02 Workshop on WordSense Disambiguation: Recent Successes andFuture Directions, Philadelphia, USA.S.
Landes C. Leacock, and R.I. Tengi.
1998.Building semantic concordances.
In Fellbaum, C.(ed.)
(1998) WordNet: An Electronic LexicalDatabase.
The MIT Press, Cambridge (Mass.).I.
D. Melamed.
2001.
Empirical Methods forExploiting Parallel Texts.
The MIT Press,Cambridge (Mass.).F.J.
Och and H. Ney.
2003.
A systematiccomparison of various statistical alignmentmodels.
Computational Linguistics, 29(1):19-53.E.
Pianta and L. Bentivogli.
2004.
Knowledgeintensive word alignment with KNOWA.
InProceedings of Coling 2004, Geneva,Switzerland.E.
Pianta and L. Bentivogli.
2003.
Translation asAnnotation.
In Proceedings of the AI*IA 2003Workshop ?Topics and Perspectives of NaturalLanguage Processing in Italy?, Pisa, Italy.E.
Pianta, L. Bentivogli and C. Girardi.
2002.MultiWordNet: developing an alignedmultilingual database.
In Proceedings of theFirst Global WordNet Conference, Mysore,India.M.
Ranieri, E. Pianta and L. Bentivogli.
2004.Browsing Multilingual Information with theMultiSemCor Web Interface.
In Proceedings ofthe LREC-2004 Workshop ?The amazing utilityof parallel and comparable corpora?, Lisbon,Portugal.E.
Riloff, C. Schafer and D. Yarowsky.
2002.Inducing information extraction systems for newlanguages via cross-language projection.
InProceedings of Coling 2002, Taipei, Taiwan.J.
V?ronis and  P. Langlais.
2000.
Evaluation ofparallel text alignment systems.
In V?ronis, J.(ed.).
2000.
Parallel Text Processing, KluwerAcademic Publishers, Dordrecht.J.
V?ronis (ed.).
2000.
Parallel Text Processing.Kluwer Academic Publishers, Dordrecht.D.
Yarowsky, G. Ngai and R. Wicentowski.
2001.Inducing Multilingual Text Analysis Tools viaRobust Projection across Aligned Corpora.
InProceedings of HLT 2001, San Diego,California, USA.
