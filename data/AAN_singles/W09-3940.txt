Proceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue, pages 286?289,Queen Mary University of London, September 2009. c?2009 Association for Computational LinguisticsSpoken Tutorial Dialogue and the Feeling of Another?s KnowingDiane LitmanUniversity of PittsburghPittsburgh, PA 15260 USAlitman@cs.pitt.eduKate Forbes-RileyUniversity of PittsburghPittsburgh, PA 15260 USAforbesk@cs.pitt.eduAbstractWe hypothesize that monitoring the accu-racy of the ?feeling of another?s know-ing?
(FOAK) is a useful predictor of tu-torial dialogue system performance.
Wetest this hypothesis in the context of awizarded spoken dialogue tutoring system,where student learning is the primary per-formance metric.
We first present our cor-pus, which has been annotated with re-spect to student correctness and uncer-tainty.
We then discuss the derivation ofFOAK measures from these annotations,for use in building predictive performancemodels.
Our results show that monitoringthe accuracy of FOAK is indeed predictiveof student learning, both in isolation and inconjunction with other predictors.1 IntroductionDetecting and exploiting knowledge of a speaker?suncertainty has been studied in several researchcommunities.
Spoken language researchers haveidentified statistically significant relationships be-tween speaker uncertainty and linguistic proper-ties of utterances such as prosody and lexical con-tent (Liscombe et al, 2005; Dijkstra et al, 2006;Pon-Barry, 2008).
Spoken dialogue researchersin turn are studying whether responding to userstates such as uncertainty can improve systemperformance as measured by usability and effi-ciency (Tsukahara and Ward, 2001; Pon-Barry etal., 2006; Forbes-Riley and Litman, 2009a).
Inthe psycholinguistics community, uncertainty hasbeen studied in the context of metacognitive abil-ities, e.g.
the ability to monitor the accuracyof one?s own knowledge (?Feeling of Knowing?
(FOK)), and the ability to monitor the FOK ofsomeone else (?Feeling of Another?s Knowing?
(FOAK)) (Smith and Clark, 1993; Brennan andWilliams, 1995).Here we take a spoken dialogue systems per-spective on FOAK, and investigate whether mon-itoring the accuracy of FOAK is a useful con-struct for predictive performance modeling.
Ourstudy uses data previously collected with a wiz-arded spoken dialogue tutoring system, where stu-dent learning is the primary performance metric.Section 2 reviews several relevant constructs andmeasures from the area of metacognition.
Sec-tion 3 introduces our dialogue corpus and its usercorrectness and uncertainty annotations.
Section 4presents our method for measuring monitoring ac-curacy of FOAK from these annotations, whileSection 5 shows how we use these measures tobuild predictive performance models.
Our resultsshow that monitoring the accuracy of FOAK is in-deed a significant positive predictor of learning,both in isolation and over and above other predic-tors.
As discussed in Section 6, increasing mon-itoring accuracy of FOAK is thus one avenue foralso potentially increasing performance, which weplan to explore in future versions of our system.2 Feeling of Another?s Knowing?Feeling of knowing?
(FOK) refers to peoples?ability to accurately monitor their own knowl-edge, e.g.
to know whether they have answereda question correctly.
Psycholinguistics researchhas shown that speakers display FOK in conver-sation using linguistic cues such as filled pausesand prosody (Smith and Clark, 1993).
Of perhapsmore relevance to dialogue systems, research hasalso shown that listeners can use the same cuesto monitor the FOK of someone else, i.e.
?feel-286ing of another?s knowing?
(FOAK) (Brennan andWilliams, 1995).To quantify knowledge monitoring, measures ofmonitoring accuracy have been proposed.
For ex-ample, consider an FOK experimental paradigm,where subjects 1) respond to a set of generalknowledge questions, 2) take a FOK survey, judg-ing whether or not1 they think they would rec-ognize the answer to each question in a multiplechoice test, and 3) take such a recognition test.
Asshown in Figure 1, such data can be summarized inan array where each cell represents a mutually ex-clusive option: the row labels represent the possi-ble FOK judgments (Y/N), while the columns rep-resent the possible results of the multiple choicetest (Y/N).Recognition=Y Recognition=NJudgment=Y a bJudgment=N c dGamma = (a)(d)?
(b)(c)(a)(d)+(b)(c) HC =(a+d)?
(b+c)(a+d)+(b+c)Figure 1: Measuring Monitoring Accuracy.Given such an array, the relationship betweenthe correctness and the judgment of FOK for an-swers can be measured using the standard formu-las in Figure 1: Gamma and the Harmann coef-ficient (HC) measure relative and absolute knowl-edge monitoring accuracy, respectively.
We useboth metrics in the performance modeling exper-iments described in Section 5, as both measureshave been well studied and there is a lack of con-sensus regarding their relative benefits (e.g.
(Niet-feld et al, 2006)).
Note that both range in valuefrom -1 (no monitoring accuracy) to 1 (perfectmonitoring accuracy).3 DataThis research uses a corpus of 405 dialogues be-tween 81 students and ITSPOKE-WOZ.
The cor-pus was collected in an experiment showing thatperformance improved when ITSPOKE-WOZ re-sponded to the uncertainty in student answers,over and above correctness (Forbes-Riley and Lit-man, 2009a).ITSPOKE-WOZ is a semi-automatic versionof ITSPOKE (Intelligent Tutoring SPOKEn di-alogue system), which is a speech-enhanced ver-sion of the Why2-Atlas qualitative physics tu-tor (VanLehn et al, 2002).
Recent versions of1Likert scale rating schemes are also possible.ITSPOKE have also been enhanced to detect andrespond to student uncertainty, by parameterizingthe dialogue manager so that it can adapt con-tingently based on student correctness and/or un-certainty (to test various ways of responding touncertainty).
In ITSPOKE-WOZ, a few compo-nents (speech recognition, language understand-ing, and uncertainty detection) have been replacedby a human ?wizard?, to test the upper-bound per-formance of adapting to uncertainty in a spokendialogue system (i.e.
without the noise introducedby speech and language processing).The experimental procedure was as follows:Students (1) read background material, (2) tooka multiple-choice pretest, (3) worked through fiveproblems with ITSPOKE-WOZ (1 per dialogue),(4) took a survey, and (5) took a posttest simi-lar to the pretest.
Each student turn in the cor-pus was annotated2 in real-time by the wizard dur-ing the experiment, using binary tags representingstudent Uncertainty (uncertain (U), nonuncertain(nonU)) and student Correctness (correct (C), in-correct (I)).
Figure 2 shows an annotated dialogueexcerpt.ITSPOKE-WOZ6: Now let?s find the forces exerted on thecar in the VERTICAL direction during the collision.
First,what vertical force is always exerted on an object near thesurface of the earth?USER6: gravity (nonU,C)ITSPOKE-WOZ7: Fine.
In addition to the downward forceof gravity, one other force is exerted on the car in the VER-TICAL direction during the collision.
We haven?t discussedthis force yet, because we only dealt with freefalling objectsbefore this problem.
But you may recall this other verticalforce from the reading.
What is it?USER7: um ... the friction from the air ... or the wind (U,I)ITSPOKE-WOZ8: Great try, but I think you know there?sa mistake in your answer.
Let?s work it out.
We know thatgravity can?t be the only vertical force on the car, because .
.
.Figure 2: Annotated Corpus Excerpt.4 PredictorsTo derive our performance models, we useposttest score as the dependent measure, and in-clude pretest score among the independent mea-sures.
This allows us to measure learning gain,not just final test score.
We also include addi-tional independent measures computed from thewizard?s uncertainty and correctness annotations,2In prior ITSPOKE corpora, this wizard displayed in-terannotator agreement of 0.85 and 0.62 Kappa on correct-ness and uncertainty, respectively (Forbes-Riley and Litman,2008).287as detailed below.
Note that all measures are com-puted on a per student basis (over all 5 dialogues).Table 1 shows means and standard deviations ofall measures across all 81 students.Measure Mean Std.
Dev.pretest .51 .15posttest .75 .14%C .79 .09%U .23 .11Gamma .77 .17HC .59 .16Table 1: Descriptive Corpus Statistics.The percentage of student turns annotated ascorrect (%C) and as uncertain (%U) normalizethe raw counts of the wizard?s C and U annota-tions.
Similar measures predict learning in priorexperiments by ourselves and others (e.g (Litmanet al, 2009)) and thus serve as useful baselines.In our corpus, 79% of a student?s turns are an-swered correctly on average, while 77% are an-swered without uncertainty.The monitoring accuracy measures Gammaand HC were introduced in Section 2.
To con-struct an array like that shown in Figure 1, wemap the first and second rows to our uncertaintyannotations NonU and U, and map the columns toour correctness annotations C and I.
In (Dijkstraet al, 2006), high and low FOK/FOAK judgmentsare similarly associated with speaker certainty anduncertainty, respectively.
Note that in our annota-tion scheme, NonU answers are either certain orneutral.5 Results: Predicting Student LearningGiven the above measures, our first prediction ex-periment measures the partial Pearson?s correla-tion between each of the independent measuresand posttest, after first controlling for pretest toaccount for learning gain.
Our goal here is exam-ine the predictive utility of the correctness, uncer-tainty, and monitoring dimensions in isolation.Table 2 shows the statistically significant resultsof the partial correlations.
The table shows the in-dependent measure, the corresponding Pearson?sCorrelation Coefficient (R), and the significance ofthe correlation (p).
As can be seen, both monitor-ing measures are positively correlated with learn-ing, with HC providing better predictive utilitythan Gamma.
However, %C is even more pre-dictive of learning than either monitoring measure.Interestingly, the uncertainty measure %U in andof itself does not show predictive utility in thisdata.Measure R p%C .52 .00Gamma .36 .00HC .42 .00Table 2: Partial Correlations with Posttest (p <.05).Our second prediction experiment uses PAR-ADISE to build a learning model that can po-tentially include multiple independent measures.As in prior PARADISE applications (e.g.
(Mo?ller,2005)), we train the models using stepwise mul-tiple linear regression, which automatically deter-mines the measures to include in the model.
Ourgoal here is to explore whether monitoring accu-racy provides any added value to our correctnessand uncertainty measures.When all measures are made available for pre-dicting learning, we see that monitoring accuracyas measured byHC does add value over and abovecorrectness: the stepwise procedure includes HCin the model, as it significantly accounts for morevariance than just including %C and pretest.
Inparticular, the application of PARADISE showsthat the following performance function providesthe best significant training fit to our data (R2 =.71, p < .01):postest = .44?%C+ .21?pretest+ .20?HCThe equation shows each selected measure and its(standardized) weight; larger weights indicate pa-rameters with greater relative predictive power inaccounting for posttest variance.
%C is signifi-cant at p < .01, while pretest and HC are eachsignificant at p < .05, with the coefficients all pos-itive.
Like the correlations, our regression demon-strates the predictive utility of the accuracy andmonitoring measures, but not the uncertainty mea-sure.
The model further shows that while correctlyanswering the system?s questions (%C) is predic-tive of learning, also including FOAK monitoringaccuracy (HC) significantly increases the model?spredictive power.6 Conclusion and Future DirectionsThis paper explores whether knowledge monitor-ing accuracy is a useful construct for understand-ing dialogue system performance.
In particular,288we demonstrate the utility of combining previ-ously studied correctness and uncertainty annota-tions, using a measure of FOAK monitoring ac-curacy.
Our results show that while the correct-ness of a user?s response predicts learning, the un-certainty with which a user conveys a responsedoes not.
In contrast, the ability to monitor FOAKaccuracy predicts learning, in isolation and overand above correctness.
We believe that monitor-ing accuracy will be a relevant construct for otherdialogue applications involving knowledge asym-metry, such as problem solving, instruction giv-ing, and trouble shooting (e.g.
(Janarthanam andLemon, 2008)).In future work we plan to use our results to in-form a modification of our system aimed at im-proving inferred user knowledge monitoring abil-ities; we will better measure such improvementsby incorporating FOK ratings into our testing.
Inaddition, we recently found interactions betweenlearning and both user domain expertise and gen-der (Forbes-Riley and Litman, 2009b); we willinvestigate whether similar interactions extend toknowledge monitoring metrics.
Since our corpuscontains dialogues with both uncertainty-adaptiveand non-adaptive versions of ITSPOKE-WOZ, wealso plan to examine whether differing dialoguestrategies influence the learned predictive models.Finally, we plan to replicate our analyses in a di-alogue corpus we recently collected using a fullyautomated version of our system.AcknowledgementsNSF #0631930 supports this work.
We thank H.Ai, P. Jordan, and the reviewers for helpful com-ments.ReferencesS.
E. Brennan and M. Williams.
1995.
The feelingof another?s knowing: Prosody and filled pauses ascues to listeners about the metacognitive states ofspeakers.
Journal of Memory and Language.C.
Dijkstra, E. Krahmer, and M. Swerts.
2006.
Ma-nipulating uncertainty: The contribution of differentaudiovisual prosodic cues to the perception of confi-dence.
In Proc.
Speech Prosody.K.
Forbes-Riley and D. J. Litman.
2008.
Analyz-ing dependencies between student certainness statesand tutor responses in a spoken dialogue corpus.
InL.
Dybkjaer and W. Minker, editors, Recent Trendsin Discourse and Dialogue.
Springer.K.
Forbes-Riley and D. Litman.
2009a.
Adapting tostudent uncertainty improves tutoring dialogues.
InProc.
Intl.
Conf.
on Artificial Intelligence in Educa-tion.K.
Forbes-Riley and D. Litman.
2009b.
A usermodeling-based performance analysis of a wizardeduncertainty-adaptive dialogue system corpus.
InProc.
Interspeech, Brighton, UK, September.S.
Janarthanam and O.
Lemon.
2008.
User simulationsfor online adaptation and knowledge-alignment introubleshooting dialogue systems.
In Proc.
SEM-dial.J.
Liscombe, J. Venditti, and J. Hirschberg.
2005.
De-tecting certainness in spoken tutorial dialogues.
InProc.
Interspeech.D.
Litman, J. Moore, M. Dzikovska, and E. Farrow.2009.
Using natural language processing to analyzetutorial dialogue corpora across domains and modal-ities.
In Proc.
Intl.
Conf.
on Artificial Intelligence inEducation.S.
Mo?ller.
2005.
Parameters for quantifying the in-teraction with spoken dialogue telephone services.In Proc.
SIGdial Workshop on Discourse and Dia-logue.J.
L. Nietfeld, C. K. Enders, and G. Schraw.
2006.
AMonte Carlo comparison of measures of relative andabsolute monitoring accuracy.
Educational and Psy-chological Measurement.H.
Pon-Barry, K. Schultz, E. O. Bratt, B. Clark, andS.
Peters.
2006.
Responding to student uncertaintyin spoken tutorial dialogue systems.
Intl.
Journal ofArtificial Intelligence in Education.H.
Pon-Barry.
2008.
Prosodic manifestations of confi-dence and uncertainty in spoken language.
In Proc.Interspeech.V.
L. Smith and H. H. Clark.
1993.
On the course ofanswering questions.
Journal of Memory and Lan-guage.W.
Tsukahara and N. Ward.
2001.
Responding to sub-tle, fleeting changes in the user?s internal state.
InProc.
SIG-CHI on Human factors in computing sys-tems.K.
VanLehn, P. W. Jordan, C.
Rose?, D. Bhembe,M.
Bo?ttner, A. Gaydos, M. Makatchev, U. Pap-puswamy, M. Ringenberg, A. Roque, S. Siler, R. Sri-vastava, and R. Wilson.
2002.
The architecture ofWhy2-Atlas: A coach for qualitative physics essaywriting.
In Proc.
Intl.
Conf.
on Intelligent TutoringSystems.289
