c?
2002 Association for Computational LinguisticsNear-Synonymy and Lexical ChoicePhilip Edmonds?
Graeme Hirst?Sharp Laboratories of Europe Limited University of TorontoWe develop a new computational model for representing the fine-grained meanings of near-synonyms and the differences between them.
We also develop a lexical-choice process that candecide which of several near-synonyms is most appropriate in a particular situation.
This researchhas direct applications in machine translation and text generation.We first identify the problems of representing near-synonyms in a computational lexiconand show that no previous model adequately accounts for near-synonymy.
We then propose apreliminary theory to account for near-synonymy, relying crucially on the notion of granularityof representation, in which the meaning of a word arises out of a context-dependent combinationof a context-independent core meaning and a set of explicit differences to its near-synonyms.
Thatis, near-synonyms cluster together.We then develop a clustered model of lexical knowledge, derived from the conventional on-tological model.
The model cuts off the ontology at a coarse grain, thus avoiding an awkwardproliferation of language-dependent concepts in the ontology, yet maintaining the advantagesof efficient computation and reasoning.
The model groups near-synonyms into subconceptualclusters that are linked to the ontology.
A cluster differentiates near-synonyms in terms of fine-grained aspects of denotation, implication, expressed attitude, and style.
The model is generalenough to account for other types of variation, for instance, in collocational behavior.An efficient, robust, and flexible fine-grained lexical-choice process is a consequence of aclustered model of lexical knowledge.
To make it work, we formalize criteria for lexical choiceas preferences to express certain concepts with varying indirectness, to express attitudes, andto establish certain styles.
The lexical-choice process itself works on two tiers: between clustersand between near-synonyns of clusters.
We describe our prototype implementation of the system,called I-Saurus.1.
IntroductionA word can express a myriad of implications, connotations, and attitudes in additionto its basic ?dictionary?
meaning.
And a word often has near-synonyms that differfrom it solely in these nuances of meaning.
So, in order to find the right word touse in any particular situation?the one that precisely conveys the desired meaningand yet avoids unwanted implications?one must carefully consider the differencesbetween all of the options.
Choosing the right word can be difficult for people, letalone present-day computer systems.For example, how can a machine translation (MT) system determine the best En-glish word for the French be?vue when there are so many possible similar but slightly?
Sharp Laboratories of Europe Limited, Oxford Science Park, Edmund Halley Road, Oxford OX4 4GB,England.
E-mail: phil@sharp.co.uk.?
Department of Computer Science, University of Toronto, Ontario, Canada M5S 3G4.
E-mail:gh@cs.toronto.edu.106Computational Linguistics Volume 28, Number 2different translations?
The system could choose error, mistake, blunder, slip, lapse, boner,faux pas, boo-boo, and so on, but the most appropriate choice is a function of how be?vueis used (in context) and of the difference in meaning between be?vue and each of the En-glish possibilities.
Not only must the system determine the nuances that be?vue conveysin the particular context in which it has been used, but it must also find the Englishword (or words) that most closely convey the same nuances in the context of the otherwords that it is choosing concurrently.
An exact translation is probably impossible, forbe?vue is in all likelihood as different from each of its possible translations as they arefrom each other.
That is, in general, every translation possibility will omit some nuanceor express some other possibly unwanted nuance.
Thus, faithful translation requiresa sophisticated lexical-choice process that can determine which of the near-synonymsprovided by one language for a word in another language is the closest or mostappropriate in any particular situation.
More generally, a truly articulate natural lan-guage generation (NLG) system also requires a sophisticated lexical-choice process.The system must to be able to reason about the potential effects of every availableoption.Consider, too, the possibility of a new type of thesaurus for a word processor that,instead of merely presenting the writer with a list of similar words, actually assiststhe writer by ranking the options according to their appropriateness in context andin meeting general preferences set by the writer.
Such an intelligent thesaurus wouldgreatly benefit many writers and would be a definite improvement over the simplisticthesauri in current word processors.What is needed is a comprehensive computational model of fine-grained lexicalknowledge.
Yet alhough synonymy is one of the fundamental linguistic phenomenathat influence the structure of the lexicon, it has been given far less attention in lin-guistics, psychology, lexicography, semantics, and computational linguistics than theequally fundamental and much-studied polysemy.
Whatever the reasons?philosophy,practicality, or expedience?synonymy has often been thought of as a ?non-problem?
:either there are synonyms, but they are completely identical in meaning and henceeasy to deal with, or there are no synonyms, in which case each word can be handledlike any other.
But our investigation of near-synonymy shows that it is just as com-plex a phenomenon as polysemy and that it inherently affects the structure of lexicalknowledge.The goal of our research has been to develop a computational model of lexicalknowledge that can adequately account for near-synonymy and to deploy such amodel in a computational process that could ?choose the right word?
in any situa-tion of language production.
Upon surveying current machine translation and naturallanguage generation systems, we found none that performed this kind of genuinelexical choice.
Although major advances have been made in knowledge-based mod-els of the lexicon, present systems are concerned more with structural paraphrasingand a level of semantics allied to syntactic structure.
None captures the fine-grainedmeanings of, and differences between, near-synonyms, nor the myriad of criteria in-volved in lexical choice.
Indeed, the theories of lexical semantics upon which present-day systems are based don?t even account for indirect, fuzzy, or context-dependentmeanings, let alne near-synonymy.
And frustratingly, no one yet knows how toimplement the theories that do more accurately predict the nature of word mean-ing (for instance, those in cognitive linguistics) in a computational system (see Hirst[1995]).In this article, we present a new model of lexical knowledge that explicitly accountsfor near-synonymy in a computationally implementable manner.
The clustered modelof lexical knowledge clusters each set of near-synonyms under a common, coarse-107Edmonds and Hirst Near-Synonymy and Lexical Choicegrained meaning and provides a mechanism for representing finer-grained aspects ofdenotation, attitude, style, and usage that differentiate the near-synonyms in a cluster.We also present a robust, efficient, and flexible lexical-choice algorithm based on theapproximate matching of lexical representations to input representations.
The modeland algorithm are implemented in a sentence-planning system called I-Saurus, andwe give some examples of its operation.2.
Near-Synonymy2.1 Absolute and Near-SynonymyAbsolute synonymy, if it exists at all, is quite rare.
Absolute synonyms would be ableto be substituted one for the other in any context in which their common sense isdenoted with no change to truth value, communicative effect, or ?meaning?
(however?meaning?
is defined).
Philosophers such as Quine (1951) and Goodman (1952) arguethat true synonymy is impossible, because it is impossible to define, and so, perhapsunintentionally, dismiss all other forms of synonymy.
Even if absolute synonymy werepossible, pragmatic and empirical arguments show that it would be very rare.
Cruse(1986, page 270) says that ?natural languages abhor absolute synonyms just as natureabhors a vacuum,?
because the meanings of words are constantly changing.
More for-mally, Clark (1992) employs her principle of contrast, that ?every two forms contrastin meaning,?
to show that language works to eliminate absolute synonyms.
Either anabsolute synonym would fall into disuse or it would take on a new nuance of mean-ing.
At best, absolute synonymy is limited mostly to dialectal variation and technicalterms (underwear (AmE) : pants (BrE); groundhog : woodchuck; distichous : two-ranked; ple-sionym : near-synonym), but even these words would change the style of an utterancewhen intersubstituted.Usually, words that are close in meaning are near-synonyms (or plesionyms)1?almost synonyms, but not quite; very similar, but not identical, in meaning; not fullyintersubstitutable, but instead varying in their shades of denotation, connotation, im-plicature, emphasis, or register (DiMarco, Hirst, and Stede 1993).2 Section 4 gives amore formal definition.Indeed, near-synonyms are pervasive in language; examples are easy to find.
Lie,falsehood, untruth, fib, and misrepresentation, for instance, are near-synonyms of oneanother.
All denote a statement that does not conform to the truth, but they differfrom one another in fine aspects of their denotation.
A lie is a deliberate attemptto deceive that is a flat contradiction of the truth, whereas a misrepresentation maybe more indirect, as by misplacement of emphasis, an untruth might be told merelyout of ignorance, and a fib is deliberate but relatively trivial, possibly told to saveone?s own or another?s face (Gove 1984).
The words also differ stylistically; fib is aninformal, childish term, whereas falsehood is quite formal, and untruth can be usedeuphemistically to avoid some of the derogatory implications of some of the otherterms (Gove [1984]; compare Coleman and Kay?s [1981] rather different analysis).
Wewill give many more examples in the discussion below.1 In some of our earlier papers, we followed Cruse (1986) in using the term plesionym for near-synonym,the prefix plesio- meaning ?near?.
Here, we opt for the more-transparent terminology.
See Section 4 fordiscussion of Cruse?s nomenclature.2 We will not add here to the endless debate on the normative differentiation of the near-synonymsnear-synonym and synonym (Egan 1942; Sparck Jones 1986; Cruse 1986; Church et al 1994).
It issufficient for our purposes at this point to simply say that we will be looking at sets of words that areintuitively very similar in meaning but cannot be intersubstituted in most contexts without changingsome semantic or pragmatic aspect of the message.108Computational Linguistics Volume 28, Number 2Error implies a straying from a proper course and suggests guilt as may lie in failure to takeproper advantage of a guide.
.
.
.
Mistake implies misconception, misunderstanding, a wrongbut not always blameworthy judgment, or inadvertence; it expresses less severe criticism thanerror.
Blunder is harsher than mistake or error; it commonly implies ignorance or stupidity, some-times blameworthiness.
Slip carries a stronger implication of inadvertence or accident than mis-take, and often, in addition, connotes triviality.
Lapse, though sometimes used interchangeablywith slip, stresses forgetfulness, weakness, or inattention more than accident; thus, one says alapse of memory or a slip of the pen, but not vice versa.
Faux pas is most frequently applied toa mistake in etiquette.
Bull, howler, and boner are rather informal terms applicable to blundersthat typically have an amusing aspect.Figure 1An entry (abridged) from Webster?s New Dictionary of Synonyms (Gove 1984).2.2 Lexical Resources for Near-SynonymyIt can be difficult even for native speakers of a language to command the differencesbetween near-synonyms well enough to use them with invariable precision, or to ar-ticulate those differences even when they are known.
Moreover, choosing the wrongword can convey an unwanted implication.
Consequently, lexicographers have com-piled many reference books (often styled as ?dictionaries of synonyms?)
that explicitlydiscriminate between members of near-synonym groups.
Two examples that we willcite frequently are Webster?s New Dictionary of Synonyms (Gove 1984), which discrimi-nates among approximately 9,000 words in 1,800 near-synonym groups, and Choose theRight Word (Hayakawa 1994), which covers approximately 6,000 words in 1,000 groups.The nuances of meaning that these books adduce in their entries are generally muchmore subtle and fine-grained than those of standard dictionary definitions.
Figure 1shows a typical entry from Webster?s New Dictionary of Synonyms, which we will use asa running example.
Similar reference works include Bailly (1970), Be?nac (1956), Fer-nald (1947), Fujiwara, Isogai, and Muroyama (1985), Room (1985), and Urdang (1992),and usage notes in dictionaries often serve a similar purpose.
Throughout this article,examples that we give of near-synonyms and their differences are taken from thesereferences.The concept of difference is central to any discussion of near-synonyms, for if twoputative absolute synonyms aren?t actually identical, then there must be somethingthat makes them different.
For Saussure (1916, page 114), difference is fundamental tothe creation and demarcation of meaning:In a given language, all the words which express neighboring ideas help defineone another?s meaning.
Each of a set of synonyms like redouter (?to dread?
),craindre (?to fear?
), avoir peur (?to be afraid?)
has its particular value only becausethey stand in contrast with one another.
.
.
.
No word has a value that can beidentified independently of what else is in its vicinity.There is often remarkable complexity in the differences between near-synonyms.3Consider again Figure 1.
The near-synonyms in the entry differ not only in the ex-pression of various concepts and ideas, such as misconception and blameworthiness,but also in the manner in which the concepts are conveyed (e.g., implied, suggested,3 This contrasts with Markman and Gentner?s work on similarity (Markman and Gentner 1993; Gentnerand Markman 1994), which suggests that the more similar two items are, the easier it is to representtheir differences.109Edmonds and Hirst Near-Synonymy and Lexical ChoiceTable 1Examples of near-synonymic variation.Type of variation ExampleAbstract dimension seep : dripEmphasis enemy : foeDenotational, indirect error : mistakeDenotational, fuzzy woods : forestStylistic, formality pissed : drunk : inebriatedStylistic, force ruin : annihilateExpressed attitude skinny : thin : slim, slenderEmotive daddy : dad : fatherCollocational task : jobSelectional pass away : dieSubcategorization give : donateexpressed, connoted, and stressed), in the frequency with which they are conveyed(e.g., commonly, sometimes, not always), and in the degree to which they are conveyed(e.g., in strength).2.3 Dimensions of VariationThe previous example illustrates merely one broad type of variation, denotationalvariation.
In general, near-synonyms can differ with respect to any aspect of theirmeaning (Cruse 1986):?
denotational variations, in a broad sense, including propositional, fuzzy,and other peripheral aspects?
stylistic variations, including dialect and register?
expressive variations, including emotive and attitudinal aspects?
structural variations, including collocational, selectional, and syntacticvariationsBuilding on an earlier analysis by DiMarco, Hirst, and Stede (1993) of the types ofdifferentiae used in synonym discrimination dictionaries, Edmonds (1999) classifiesnear-synonymic variation into 35 subcategories within the four broad categories above.Table 1 gives a number of examples, grouped into the four broad categories above,which we will now discuss.2.3.1 Denotational Variations.
Several kinds of variation involve denotation, taken ina broad sense.4 DiMarco, Hirst, and Stede (1993) found that whereas some differen-tiae are easily expressed in terms of clear-cut abstract (or symbolic) features such as4 The classic opposition of denotation and connotation is not precise enough for our needs here.
Thedenotation of a word is its literal, explicit, and context-independent meaning, whereas its connotationis any aspect that is not denotational, including ideas that color its meaning, emotions, expressedattitudes, implications, tone, and style.
Connotation is simply too broad and ambiguous a term.
It oftenseems to be used simply to refer to any aspect of word meaning that we don?t yet understand wellenough to formalize.110Computational Linguistics Volume 28, Number 2continuous/intermittent (Wine {seeped | dripped} from the barrel), many are not.
In fact,denotational variation involves mostly differences that lie not in simple features butin full-fledged concepts or ideas?differences in concepts that relate roles and aspectsof a situation.
For example, in Figure 1, ?severe criticism?
is a complex concept thatinvolves both a criticizer and a criticized, the one who made the error.
Moreover, twowords can differ in the manner in which they convey a concept.
Enemy and foe, forinstance, differ in the emphasis that they place on the concepts that compose them,the former stressing antagonism and the latter active warfare rather than emotionalreaction (Gove 1984).Other words convey meaning indirectly by mere suggestion or implication.
Thereis a continuum of indirectness from suggestion to implication to denotation; thus slip?carries a stronger implication of inadvertence?
than mistake.
Such indirect meaningsare usually peripheral to the main meaning conveyed by an expression, and it is usu-ally difficult to ascertain definitively whether or not they were even intended to beconveyed by the speaker; thus error merely ?suggests guilt?
and a mistake is ?not al-ways blameworthy.?
Differences in denotation can also be fuzzy, rather than clear-cut.The difference between woods and forest is a complex combination of size, primitive-ness, proximity to civilization, and wildness.52.3.2 Stylistic Variations.
Stylistic variation involves differences in a relatively small,finite set of dimensions on which all words can be compared.
Many stylistic dimen-sions have been proposed by Hovy (1988), Nirenburg and Defrise (1992), Stede (1993),and others.
Table 1 illustrates two of the most common dimensions: inebriated is formalwhereas pissed is informal; annihilate is a more forceful way of saying ruin.2.3.3 Expressive Variations.
Many near-synonyms differ in their marking as to thespeaker?s attitude to their denotation: good thing or bad thing.
Thus the same personmight be described as skinny, if the speaker wanted to be deprecating or pejorative,slim or slender, if he wanted to be more complimentary, or thin if he wished to beneutral.
A hindrance might be described as an obstacle or a challenge, depending uponhow depressed or inspired the speaker felt about the action that it necessitated.6 Aword can also indirectly express the emotions of the speaker in a possibly finite setof emotive ?fields?
; daddy expresses a stronger feeling of intimacy than dad or father.Some words are explicitly marked as slurs; a slur is a word naming a group of people,the use of which implies hatred or contempt of the group and its members simply byvirtue of its being marked as a slur.2.3.4 Structural Variations.
The last class of variations among near-synonyms involvesrestrictions upon deployment that come from other elements of the utterance and, re-ciprocally, restrictions that they place upon the deployment of other elements.
In eithercase, the restrictions are independent of the meanings of the words themselves.7 The5 ?A ?wood?
is smaller than a ?forest?, is not so primitive, and is usually nearer to civilization.
Thismeans that a ?forest?
is fairly extensive, is to some extent wild, and on the whole not near large townsor cities.
In addition, a ?forest?
often has game or wild animals in it, which a ?wood?
does not, apartfrom the standard quota of regular rural denizens such as rabbits, foxes and birds of various kinds?
(Room 1985, page 270).6 Or, in popular psychology, the choice of word may determine the attitude: ?
[Always] substitutechallenge or opportunity for problem.
.
.
.
Instead of saying I?m afraid that?s going to be a problem, say Thatsounds like a challenging opportunity?
(Walther 1992, page 36).7 It could be argued that words that differ only in these ways should count not merely as near-synonymsbut as absolute synonyms.111Edmonds and Hirst Near-Synonymy and Lexical Choicerestrictions may be either collocational, syntactic, or selectional?that is, dependent ei-ther upon other words or constituents in the utterance or upon other concepts denoted.Collocational variation involves the words or concepts with which a word can becombined, possibly idiomatically.
For example, task and job differ in their collocationalpatterns: one can face a daunting task but not ?face a daunting job.
This is a lexical restric-tion, whereas in selectional restrictions (or preferences) the class of acceptable objectsis defined semantically, not lexically.
For example, unlike die, pass away may be usedonly of people (or anthropomorphized pets), not plants or animals: ?Many cattle passedaway in the drought.Variation in syntactic restrictions arises from differing syntactic subcategorization.It is implicit that if a set of words are synonyms or near-synonyms, then they areof the same syntactic category.8 Some of a set of near-synonyms, however, might besubcategorized differently from others.
For example, the adjective ajar may be usedpredicatively, not attributively (The door is ajar; ?the ajar door), whereas the adjectiveopen may be used in either position.
Similarly, verb near-synonyms (and their nomi-nalizations) may differ in their verb class and in the alternations that they they mayundergo (Levin 1993).
For example, give takes the dative alternation, whereas donatedoes not: Nadia gave the Van Gogh to the museum; Nadia gave the museum the Van Gogh;Nadia donated the Van Gogh to the museum; ?Nadia donated the museum the Van Gogh.Unlike the other kinds of variation, collocational, syntactic, and selectional varia-tions have often been treated in the literature on lexical choice, and so we will havelittle more to say about them here.2.4 Cross-Linguistic Near-SynonymyNear-synonymy rather than synonymy is the norm in lexical transfer in translation:the word in the target language that is closest to that in the source text might be anear-synonym rather than an exact synonym.
For example, the German word Wald issimilar in meaning to the English word forest, but Wald can denote a rather smallerand more urban area of trees than forest can; that is, Wald takes in some of the Englishword woods as well, and in some situations, woods will be a better translation of Waldthan forest.
Similarly, the German Geho?lz takes in the English copse and the ?smaller?part of woods.
We can think of Wald, Geho?lz, forest, woods, and copse as a cross-linguisticnear-synonym group.Hence, as with a group of near-synonyms from a single language, we can speakof the differences in a group of cross-linguistic near-synonyms.
And just as there arereference books to advise on the near-synonym groups of a single language, thereare also books to advise translators and advanced learners of a second language oncross-linguistic near-synonymy.
As an example, we show in Figures 2 and 3 (abridge-ments of) the entries in Farrell (1977) and Batchelor and Offord (1993) that explicate,from the perspective of translation to and from English, the German and French near-synonym clusters that correspond to the English cluster for error that we showed inFigure 1.2.5 SummaryWe know that near-synonyms can often be intersubstituted with no apparent changeof effect on a particular utterance, but, unfortunately, the context-dependent nature8 A rigorous justification of this point would run to many pages, especially for near-synonyms.
Forexample, it would have to be argued that the verb sleep and the adjective asleep are not merelynear-synonyms that just happen to differ in their syntactic categories, even though the sentences Emilysleeps and Emily is asleep are synonymous or nearly so.112Computational Linguistics Volume 28, Number 2MISTAKE, ERROR.
Fehler is a definite imperfection in a thing which ought not to be there.
Inthis sense, it translates both mistake and error.
Irrtum corresponds to mistake only in the sense of?misunderstanding?, ?misconception?, ?mistaken judgment?, i.e.
which is confined to the mind,not embodied in something done or made.
[footnote:] Versehen is a petty mistake, an oversight,a slip due to inadvertence.
Mi?griff and Fehlgriff are mistakes in doing a thing as the resultof an error in judgment.Figure 2An entry (abridged) from Dictionary of German Synonyms (Farrell 1977).impair (3) blunder, errorbe?vue (3?2) blunder (due to carelessness or ignorance)faux pas (3?2) mistake, error (which affects a person adversely socially or in his/her career,etc)bavure (2) unfortunate error (often committed by the police)be?tise (2) stupid error, stupid wordsgaffe (2?1) boob, clangerFigure 3An entry (abridged) from Using French Synonyms (Batchelor and Offord 1993).
Theparenthesized numbers represent formality level from 3 (most formal) to 1 (least formal).of lexical knowledge is not very well understood as yet.
Lexicographers, for in-stance, whose job it is to categorize different uses of a word depending on context,resort to using mere ?frequency?
terms such as sometimes and usually (as in Fig-ure 1).
Thus, we cannot yet make any claims about the influence of context on near-synonymy.In summary, to account for near-synonymy, a model of lexical knowledge willhave to incorporate solutions to the following problems:?
The four main types of variation are qualitatively different, so each mustbe separately modeled.?
Near-synonyms differ in the manner in which they convey concepts,either with emphasis or indirectness (e.g., through mere suggestionrather than denotation).?
Meanings, and hence differences among them, can be fuzzy.?
Differences can be multidimensional.
Only for clarity in our aboveexplication of the dimensions of variation did we try to select examplesthat highlighted a single dimension.
However, as Figure 1 shows, blunderand mistake, for example, actually differ on several denotationaldimensions as well as on stylistic and attitudinal dimensions.?
Differences are not just between simple features but involve conceptsthat relate roles and aspects of the situation.?
Differences often depend on the context.3.
Near-Synonymy in Computational Models of the LexiconClearly, near-synonymy raises questions about fine-grained lexical knowledge repre-sentation.
But is near-synonymy a phenomenon in its own right warranting its own113Edmonds and Hirst Near-Synonymy and Lexical Choicelegs=2BirdelegantPeacockgrayelegantJuncolegs=4smartDoglegs=0,2,4live-bearingMammalelegantlegs=4Catlegs=2smartHumanblue-greenegg-layingAnimalPfaujuncocatpussKatzeMiezepeacockbirdHundspugletanimalhumanpersonMenschPersonTierS?ugetiermammalhounddogJunkoVogelFigure 4A simplistic hierarchy of conceptual schemata with connections to their lexical entries forEnglish and German.special account, or does it suffice to treat near-synonyms the same as widely differingwords?
We will argue now that near-synonymy is indeed a separately characterizablephenomenon of word meaning.Current models of lexical knowledge used in computational systems, which arebased on decompositional and relational theories of word meaning (Katz and Fodor1963; Jackendoff 1990; Lyons 1977; Nirenburg and Defrise 1992; Lehrer and Kittay 1992;Evens 1988; Cruse 1986), cannot account for the properties of near-synonyms.
In thesemodels, the typical view of the relationship between words and concepts is that eachelement of the lexicon is represented as a conceptual schema or a structure of suchschemata.
Each word sense is linked to the schema or the conceptual structure that itlexicalizes.
If two or more words denote the same schema or structure, all of them areconnected to it; if a word is ambiguous, subentries for its different senses are connectedto their respective schemata.
In this view, then, to understand a word in a sentenceis to find the schema or schemata to which it is attached, disambiguate if necessary,and add the result to the output structure that is being built to represent the sentence.Conversely, to choose a word when producing an utterance from a conceptual structureis to find a suitable set of words that ?cover?
the structure and assemble them into asentence in accordance with the syntactic and pragmatic rules of the language (Nogierand Zock 1992; Stede 1999).A conceptual schema in models of this type is generally assumed to contain aset of attributes or attribute?value pairs that represent the content of the concept anddifferentiate it from other concepts.
An attribute is itself a concept, as is its value.
Theconceptual schemata are themselves organized into an inheritance hierarchy, taxon-omy, or ontology; often, the ontology is language-independent, or at least language-neutral, so that it can be used in multilingual applications.
Thus, the model might look114Computational Linguistics Volume 28, Number 2fibuntruthmensongementeriemisrepresentationcontrev?rit?lieUntrue-AssertionAccidental-UntruthAccidental-Contrary-UntruthIndirect-Deliberate-UntruthDirect-Deliberate-UntruthDeliberate-UntruthSmall-Joking-UntruthSmall-Face-Saving-Deliberate-UntruthFigure 5One possible hierarchy for the various English and French words for untrue assertions.Adapted from Hirst (1995).like the simplified fragment shown in Figure 4.
In the figure, the rectangles representconcept schemata with attributes; the arrows between them represent inheritance.
Theovals represent lexical entries in English and German; the dotted lines represent theirconnection to the concept schemata.9Following Frege?s (1892) or Tarski?s (1944) truth-conditional semantics, the conceptthat a lexical item denotes in such models can be thought of as a set of features that areindividually necessary and collectively sufficient to define the concept.
Such a viewgreatly simplifies the word?concept link.
In a text generation system, for instance, thefeatures amount to the necessary applicability conditions of a word; that is, they haveto be present in the input in order for the word to be chosen.
Although such modelshave been successful in computational systems, they are rarely pushed to representnear-synonyms.
(The work of Barnett, Mani, and Rich [1994] is a notable exception;they define a relation of semantic closeness for comparing the denotations of wordsand expressions; see Section 9.)
They do not lend themselves well to the kind of fine-grained and often fuzzy differentiation that we showed earlier to be found in near-synonymy, because, in these models, except as required by homonymy and absolutesynonymy, there is no actual distinction between a word and a concept: each memberof a group of near-synonyms must be represented as a separate concept schema (orgroup of schemata) with distinct attributes or attribute values.
For example, Figure 5shows one particular classification of the fib group of near-synonyms in English andFrench.10 A similar proliferation of concepts would be required for various error clusters(as shown earlier in Figures 1, 2, and 3).9 This outline is intended as a syncretism of many models found in the interdisciplinary literature and isnot necessarily faithful to any particular one.
For examples, see the papers in Evens (1988) (especiallySowa [1988]) and in Pustejovsky and Bergler (1992) (especially Nirenburg and Levin [1992], Sowa[1992], and Burkert and Forster [1992]); for a theory of lexico-semantic taxonomies, see Kay (1971).
Fora detailed construction of the fundamental ideas, see Barsalou (1992); although we use the term schemainstead of frame, despite Barsalou?s advice to the contrary, we tacitly accept most elements of hismodel.
For bilingual aspects, see Kroll and de Groot (1997).10 We do not claim that a bilingual speaker necessarily stores words and meanings from differentlanguages together.
In this model, if the concepts are taken to be language independent, then it doesnot matter if one overarching hierarchy or many distinct hierarchies are used.
It is clear, however, thatcross-linguistic near-synonyms do not have exactly the same meanings and so require distinct conceptsin this model.115Edmonds and Hirst Near-Synonymy and Lexical ChoiceAlthough some systems have indeed taken this approach (Emele et al 1992), thiskind of fragmentation is neither easy nor natural nor parsimonious.
Hirst (1995) showsthat even simple cases lead to a multiplicity of nearly identical concepts, therebydefeating the purpose of a language-independent ontology.
Such a taxonomy cannotefficiently represent the multidimensional nature of near-synonymic variation, nor canit account for fuzzy differences between near-synonyms.
And since the model defineswords in terms of only necessary and sufficient truth-conditions, it cannot accountfor indirect expressions of meaning and for context-dependent meanings, which areclearly not necessary features of a word?s meaning.Moreover, a taxonomic hierarchy emphasizes hyponymy, backgrounding all otherrelations, which appear to be more important in representing the multidimensionalnature of fine-grained word meaning.
It is not even clear that a group of synonymscan be structured by hyponymy, except trivially (and ineffectively) as hyponyms all ofthe same concept.The model also cannot easily or tractably account for fuzzy differences or the full-fledged concepts required for representing denotational variation.
First-order logic,rather than the description logic generally used in ontological models, would at leastbe required to represent such concepts, but reasoning about the concepts in lexicalchoice and other tasks would then become intractable as the model was scaled up torepresent all near-synonyms.In summary, present-day models of the lexicon have three kinds of problems withrespect to near-synonymy and fine-grained lexical knowledge: the adequacy of cov-erage of phenomena related to near-synonymy; engineering, both in the design ofan efficient and robust lexical choice process and in the design of lexical entries fornear-synonyms; and the well-known issues of tractability of reasoning about conceptsduring natural language understanding and generation.Nevertheless, at a coarse grain, the ontological model does have practical and the-oretical advantages in efficient paraphrasing, lexical choice, and mechanisms for infer-ence and reasoning.
Hence, to build a new model of lexical knowledge that takes intoaccount the fine-grainedness of near-synonymy, a logical way forward is to start withthe computationally proven ontological model and to modify or extend it to accountfor near-synonymy.
The new model that we will present below will rely on a muchmore coarsely grained ontology.
Rather than proliferating conceptual schemata to ac-count for differences between near-synonyms, we will propose that near-synonymsare connected to a single concept, despite their differences in meaning, and are dif-ferentiated at a subconceptual level.
In other words, the connection of two or morewords to the same schema will not imply synonymy but only near-synonymy.
Dif-ferentiation between the near-synonyms?the fine tuning?will be done in the lexicalentries themselves.4.
Near-Synonymy and Granularity of RepresentationTo introduce the notion of granularity to our discussion, we first return to the problemof defining near-synonymy.Semanticists such as Ullmann (1962), Cruse (1986), and Lyons (1995) have at-tempted to define near-synonymy by focusing on ?propositional?
meaning.
Cruse, forexample, contrasts cognitive synonyms and plesionyms; the former are words that,when intersubstituted in a sentence, preserve its truth conditions but may change theexpressive meaning, style, or register of the sentence or may involve different idiosyn-116Computational Linguistics Volume 28, Number 2cratic collocations (e.g., violin : fiddle),11 whereas intersubstituting the latter changesthe truth conditions but still yields semantically similar sentences (e.g., misty : foggy).Although these definitions are important for truth-conditional semantics, they are notvery helpful for us, because plesionymy is left to handle all of the most interestingphenomena discussed in Section 2.
Moreover, a rigorous definition of cognitive syn-onymy is difficult to come up with, because it relies on the notion of granularity, whichwe will discuss below.Lexicographers, on the other hand, have always treated synonymy as near-synonymy.
They define synonymy in terms of likeness of meaning, disagreeing onlyin how broad the definition ought to be.
For instance, Roget followed the vague prin-ciple of ?the grouping of words according to ideas?
(Chapman 1992, page xiv).
Andin the hierarchical structure of Roget?s Thesaurus, word senses are ultimately groupedaccording to proximity of meaning: ?the sequence of terms within a paragraph, farfrom being random, is determined by close, semantic relationships?
(page xiii).
Thelexicographers of Webster?s New Dictionary of Synonyms define a synonym as ?one oftwo or more words .
.
.
which have the same or very nearly the same essential mean-ing.
.
.
.
Synonyms can be defined in the same terms up to a certain point?
(Egan 1942,pages 24a?25a).
Webster?s Collegiate Thesaurus uses a similar definition that involves thesharing of elementary meanings, which are ?discrete objective denotations uncoloredby .
.
.
peripheral aspects such as connotations, implications, or quirks of idiomaticusage?
(Kay 1988, page 9a).
Clearly, the main point of these definitions is that near-synonyms must have the same essential meaning but may differ in peripheral orsubordinate ideas.
Cruse (1986, page 267) actually refines this idea and suggests thatsynonyms (of all types) are words that are identical in ?central semantic traits?
anddiffer, if at all, only in ?peripheral traits.?
But how can we specify formally just howmuch similarity of central traits and dissimilarity of peripheral traits is allowed?
Thatis, just what counts as a central trait and what as a peripheral trait in defining a word?To answer this question, we introduce the idea of granularity of representationof word meaning.
By granularity we mean the level of detail used to describe orrepresent the meanings of a word.
A fine-grained representation can encode subtledistinctions, whereas a coarse-grained representation is crude and glosses over vari-ation.
Granularity is distinct from specificity, which is a property of concepts ratherthan representations of concepts.
For example, a rather general (unspecific) concept,say Human, could have, in a particular system, a very fine-grained representation, in-volving, say, a detailed description of the appearance of a human, references to relatedconcepts such as Eat and Procreate, and information to distinguish the concept fromother similar concepts such as Animal.
Conversely, a very specific concept could havea very coarse-grained representation, using only very general concepts; we could rep-resent a Lexicographer at such a coarse level of detail as to say no more than that itis a physical object.Near-synonyms can occur at any level of specificity, but crucially it is the finegranularity of the representations of their meanings that enables one to distinguishone near-synonym from another.
Thus, any definition of near-synonymy that does nottake granularity into account is insufficient.
For example, consider Cruse?s cognitivesynonymy, discussed above.
On the one hand, at an absurdly coarse grain of rep-resentation, any two words are cognitive synonyms (because every word denotes a?thing?).
But on the other hand, no two words could ever be known to be cognitivesynonyms, because, even at a fine grain, apparent cognitive synonyms might be fur-11 What?s the difference between a violin and a fiddle?
No one minds if you spill beer on a fiddle.117Edmonds and Hirst Near-Synonymy and Lexical Choicether distinguishable by a still more fine-grained representation.
Thus, granularity isessential to the concept of cognitive synonymy, as which pairs of words are cognitivesynonyms depends on the granularity with which we represent their propositionalmeanings.
The same is true of Cruse?s plesionyms.
So in the end, it should not benecessary to make a formal distinction between cognitive synonyms and plesionyms.Both kinds of near-synonyms should be representable in the same formalism.By taking granularity into account, we can create a much more useful definitionof near-synonymy, because we can now characterize the difference between essentialand peripheral aspects of meaning.
If we can set an appropriate level of granularity,the essential meaning of a word is the portion of its meaning that is representableonly above that level of granularity, and peripheral meanings are those portions rep-resentable only below that level.But what is the appropriate level of granularity, the dividing line between coarse-grained and fine-grained representations?
We could simply use our intuition?orrather, the intuitions of lexicographers, which are filtered by some amount of ob-jectivity and experience.
Alternatively, from a concern for the representation of lexicalknowledge in a multilingual application, we can view words as (language-specific)specializations of language-independent concepts.
Given a hierarchical organizationof coarse-grained language-independent concepts, a set of near-synonyms is simply aset of words that all link to the same language-independent concept (DiMarco, Hirst,and Stede 1993; Hirst 1995).
So in this view, near-synonyms share the same proposi-tional meaning just up to the point in granularity defined by language dependence.Thus we have an operational definition of near-synonymy: If the same concept hasseveral reasonable lexicalizations in different languages, then it is a good candidate forbeing considered a language-independent concept, its various lexicalizations formingsets of near-synonyms in each language.12Granularity also explains why it is more difficult to represent near-synonyms in alexicon.
Near-synonyms are so close in meaning, sharing all essential coarse-grainedaspects, that they differ, by definition, in only aspects representable at a fine grain.And these fine-grained representations of differences tend to involve very specificconcepts, typically requiring complex structures of more general concepts that aredifficult to represent and to reason with.
The matter is only made more complicatedby there often being several interrelated near-synonyms with interrelated differences.On the other hand, words that are not near-synonyms?those that are merely similar inmeaning (dog : cat) or not similar at all (dog : hat)?could presumably be differentiatedby concepts at a coarse-grained, and less complex, level of representation.5.
A Model of Fine-Grained Lexical KnowledgeOur discussion of granularity leads us to a new model of lexical knowledge in whichnear-synonymy is handled on a separate level of representation from coarse-grainedconcepts.5.1 Outline of the ModelOur model is based on the contention that the meaning of an open-class content word,however it manifests itself in text or speech, arises out of a context-dependent combina-tion of a basic inherent context-independent denotation and a set of explicit differences12 EuroWordNet?s Inter-Lingual-Index (Vossen 1998) links the synsets of different languages in such amanner, and Resnik and Yarowsky (1999) describe a related notion for defining word sensescross-lingually.118Computational Linguistics Volume 28, Number 2to its near-synonyms.
(We don?t rule out other elements in the combination, but theseare the main two.)
Thus, word meaning is not explicitly represented in the lexicon butis created (or generated, as in a generative model of the lexicon [Pustejovsky 1995])when a word is used.
This theory preserves some aspects of the classical theories?thebasic denotation can be modeled by an ontology?but the rest of a word?s meaningrelies on other nearby words and the context of use (cf.
Saussure).
In particular, eachword and its near synonyms form a cluster.13The theory is built on the following three ideas, which follow from our observa-tions about near-synonymy.
First, the meaning of any word, at some level of gran-ularity, must indeed have some inherent context-independent denotational aspect toit?otherwise, it would not be possible to define or ?understand?
a word in isolationof context, as one in fact can (as in dictionaries).
Second, nuances of meaning, althoughdifficult or impossible to represent in positive, absolute, and context-independentterms, can be represented as differences, in Saussure?s sense, between near-synonyms.That is, every nuance of meaning that a word might have can be thought of as a rela-tion between the word and one or more of its near-synonyms.
And third, differencesmust be represented not by simple features or truth conditions, but by structures thatencode relations to the context, fuzziness, and degrees of necessity.For example, the word forest denotes a geographical tract of trees at a coarsegrain, but it is only in relation to woods, copse, and other near-synonyms that onecan fully understand the significance of forest (i.e., that it is larger, wilder, etc.).
Theword mistake denotes any sort of action that deviates from what is correct and alsoinvolves some notion of criticism, but it is only in relation to error and blunder thatone sees that the word can be used to criticize less severely than these alternativesallow.
None of these differences could be represented in absolute terms, because thatwould require defining some absolute notion of size, wildness, or severity, whichseems implausible.
So, at a fine grain, and only at a fine grain, we make explicituse of Saussure?s notion of contrast in demarcating the meanings of near-synonyms.Hence, the theory holds that near-synonyms are explicitly related to each other notat a conceptual level but at a subconceptual level?outside of the (coarser-grained)ontology.
In this way, a cluster of near-synonyms is not a mere list of synonyms; ithas an internal structure that encodes fine-grained meaning as differences betweenlexical entries, and it is situated between a conceptual model (i.e., the ontology) anda linguistic model.Thus the model has three levels of representation.
Current computational theo-ries suggest that at least two levels of representation, a conceptual?semantic leveland a syntactic?semantic level, are necessary to account for various lexico-semanticphenomena in computational systems, including compositional phenomena such asparaphrasing (see, for instance, Stede?s [1999] model).
To account for fine-grainedmeanings and near-synonymy, we postulate a third, intermediate level (or a splittingof the conceptual?semantic level).
Thus the three levels are the following:A conceptual?semantic level.|A subconceptual/stylistic?semantic level.|A syntactic?semantic level.13 It is very probable that many near-synonym clusters of a language could be discovered automaticallyby applying statistical techniques, such as cluster analysis, on large text corpora.
For instance, Churchet al (1994) give some results in this area.119Edmonds and Hirst Near-Synonymy and Lexical ChoiceFrenchGermanEnglishd?cr?tersommersoulEnglishindividualenjoindrearticleobjectentitything itemEnglishcommanderordonnerblundermistakeerreursomeonefautemortalfaux pasbavureslipb?vueerrorFehlerSchnitzerMi?griffpersonVersehenb?tiseimpairFrenchhowlerlapseIrrtumhumanGeneric-OrderEnglishbiddirectenjoincommandorderObjectThingGeneric-ErrorPersonActivitySituationFigure 6A clustered model of lexical knowledgeSo, taking the conventional ontological model as a starting point, we cut off theontology at a coarse grain and cluster near-synonyms under their shared conceptsrather than linking each word to a separate concept.
The resulting model is a clus-tered model of lexical knowledge.
On the conceptual?semantic level, a cluster hasa core denotation that represents the essential shared denotational meaning of itsnear-synonyms.
On the subconceptual/stylistic?semantic level, we represent the fine-grained differences between the near-synonyms of a cluster in denotation, style, andexpression.
At the syntactic?semantic level, syntactic frames and collocational relationsrepresent how words can be combined with others to form sentences.Figure 6 depicts a fragment of the clustered model.
It shows how the clusters ofthe near-synonyms of error, order, person, and object in several languages could be rep-resented in this model.
In the figure, each set of near-synonyms forms a cluster linkedto a coarse-grained concept defined in the ontology: Generic-Error, Generic-Order,Person, and Object, respectively.
Thus, the core denotation of each cluster is the con-cept to which it points.
Within each cluster, the near-synonyms are differentiated at thesubconceptual/stylistic level of semantics, as indicated by dashed lines between thewords in the cluster.
(The actual differences are not shown in the figure.)
The dashedlines between the clusters for each language indicate similar cross-linguistic differenti-120Computational Linguistics Volume 28, Number 2errorblunderCAUSE-OFCOREATTRIBUTEACTORATTRIBUTEDEGREEACTORATTRIBUTEPejorativeMisconceptionStupidityConcretenesshighlowBlameworthinessmediumlow highActivityPerson DeviationFigure 7The core denotation and some of the peripheral concepts of the cluster of error nouns.
The twolarge regions, bounded by the solid line and the dashed line, show the concepts (and attitudesand styles) that can be conveyed by the words error and blunder in relation to each other.ation between some or all of the words of each cluster.
Not all words in a cluster needbe differentiated, and each cluster in each language could have its own ?vocabulary?for differentiating its near-synonyms, though in practice one would expect an overlapin vocabulary.
The figure does not show the representation at the syntactic?semanticlevel.
We can now describe the internal structure of a cluster in more detail, startingwith two examples.Figure 7 depicts part of the representation of the cluster of error nouns (error,mistake, blunder, .
.
.
); it is explicitly based on the entry from Webster?s New Dictionaryof Synonyms shown in Figure 1.
The core denotation, the shaded region, representsan activity by a person (the actor) that is a deviation from a proper course.14 In themodel, peripheral concepts are used to represent the denotational distinctions of near-synonyms.
The figure shows three peripheral concepts linked to the core concept:Stupidity, Blameworthiness, and Misconception.
The peripheral concepts representthat a word in the cluster can potentially express, in relation to its near-synonyms,the stupidity of the actor of the error, the blameworthiness of the actor (of differentdegrees: low, medium, or high), and misconception as cause of the error.
The repre-sentation also contains an expressed attitude, Pejorative, and the stylistic dimensionof Concreteness.
(Concepts are depicted as regular rectangles, whereas stylistic di-mensions and attitudes are depicted as rounded rectangles.)
The core denotation andperipheral concepts together form a directed graph of concepts linked by relations;14 Specifiying the details of an actual cluster should be left to trained knowledge representation experts,who have a job not unlike a lexicographer?s.
Our model is intended to encode such knowledge once itis elucidated.121Edmonds and Hirst Near-Synonymy and Lexical ChoiceCOREenjoin orderDEGREEATTRIBUTElow highmediumACTEEACTORATTRIBUTEhighlow mediumATTRIBUTEACTOR ACTEESAYERSAYINGSAYEEACTORPersonAuthorityOfficialActivityPersonCommunicatePeremptoryWarnFormalityPerformImperativeFigure 8The core denotation and peripheral concepts of the cluster of order verbs.
The two largeregions, bounded by the solid line and the dashed line, show the concepts that can beconveyed by the words order and enjoin in relation to each other.the individual concepts and relations are defined in the ontology.
But although allof the near-synonyms in the cluster will convey the concepts in the core denotation,the peripheral concepts that will be conveyed depend on each near-synonym.
This isdepicted by the two large regions in the figure (bounded by the solid line and thedashed line), which each contain the concepts, styles, and attitudes conveyed by theirassociated near-synonyms, blunder and error, respectively.
Thus, error conveys a degreeof Blameworthiness compared to the higher degree that blunder conveys; error doesnot convey Stupidity whereas blunder does; blunder can also express a Pejorativeattitude toward the actor, but error does not express any attitude; and error and blunderdiffer stylistically in their degree of Concreteness.
Notice that the attitude connectsto the concept Person, because all attitudes must be directed toward some entity inthe situation.
Stylistic dimensions such as Concreteness, on the other hand, are com-pletely separate from the graph of concepts.
Also, the indirectness of expression ofeach of the peripheral concepts by each of the near-synonyms is not shown in this di-agram (but see below).
The Appendix gives the complete representation of this clusterin the formalism of our model.Similarly, Figure 8 depicts the cluster of order verbs (order, enjoin, command, .
.
.
),including three of its peripheral concepts and one stylistic dimension.
In this cluster,the core represents a communication by a person (the sayer) to another person (thesayee) of an activity that the sayee must perform.
The core includes several conceptsthat are not actually lexicalized by any of the words in the cluster (e.g., the sayer of the122Computational Linguistics Volume 28, Number 2order) but that nevertheless have to be represented because the peripheral conceptsrefer to them.
(Such concepts are indicated by dashed rectangles.)
The peripheralconcepts represent the idea that a near-synonym can express the authority of thesayer (with possible values of Official or Peremptory), a warning to the sayee, andthe imperativeness of the activity (with possible values of low, medium, or high).
Thefigure shows the difference between order (the region bounded by the solid line) andenjoin (the region bounded by the dashed line).5.2 Core DenotationThe core denotation of a cluster is the inherent context-independent (and in this formu-lation of the model, language-neutral) denotation shared by all of its near-synonyms.The core denotation must be specified at a level of granularity sufficient to form a use-ful cluster of near-synonyms (i.e., at the right level of granularity so that, for instance,human and person fall into the same cluster, but dwarf and giant do not; see Section 4).A core denotation is represented as a directed graph of concepts linked by rela-tions.
The graph can be of arbitrary size, from a single concept (such as Generic-Error)up to any number of interrelated concepts (as shown in Figures 7 and 8).
It mustbe specified in enough detail, however, for the peripheral concepts to also be speci-fied.
For instance, in the error cluster, it was not possible to use the simple conceptGeneric-Error, because the peripheral concepts of the cluster refer to finer-grainedaspects of the concept (the actor and the deviation); hence we used a finer-grainedrepresentation of the concept.5.3 Peripheral ConceptsPeripheral concepts form the basic vocabulary of fine-grained denotational distinc-tions.
They are used to represent non-necessary and indirect aspects of word meaning.That is, they are concepts that might be implied, suggested, emphasized, or otherwisewhen a word is used, but not always.
For instance, in differentiating the error words, alexicographer would first decide that the basic peripheral concepts required might be?stupidity?, ?blameworthiness?, ?criticism?, ?misconception?, ?accidentalness?, and ?inat-tention?.
Then the lexicographer would proceed to distinguish the near-synonyms interms of these concepts, for instance, by specifying that blunder involves a higherdegree of blameworthiness than error.More formally, peripheral concepts are structures of concepts defined in the sameontology that core denotations are defined in.
In fact, every peripheral concept in acluster must ?extend?
the core denotation in some way, because, after all, peripheralconcepts represent ideas related to the core meaning of a cluster of near-synonyms.But peripheral concepts are represented separately from the core denotation.Moreover, since peripheral concepts are defined in the ontology, they can be rea-soned about, which, in principle, makes the formalism robust to variation in repre-sentation.
That is, if a lexicographer used, say, ?responsibility?
to define mistake and?blameworthiness?
to define blunder, the words could still be compared, because in-ference would find a connection between ?responsibility?
and ?blameworthiness?.
SeeSection 6.1 below for more discussion on this point.5.4 Distinctions between Near-SynonymsFollowing Hirst (1995), we would like to represent differences explicitly as first-classobjects (so that we can reason about them during processing).
While we don?t adoptan explicit formalism, for reasons of practicality of representation, our implicit for-malism provides a method for computing explicit differences as needed (as we?llsee in Section 6.1).
Thus we associate with each near-synonym in a cluster a set of123Edmonds and Hirst Near-Synonymy and Lexical ChoiceTable 2Examples of distinctions of words.Denotational distinctions:Binary: blunder: (usually medium implication Stupidity)Continuous: blunder: (always medium implication(Blameworthiness (DEGREE high)))Discrete: order: (always medium implication(Authority (ATTRIBUTE (Peremptory))))Expressive distinctions:blunder: (always medium pejorative V1)Stylistic distinctions:blunder: (high concreteness)error: (low concreteness)Note: See the Appendix for the details.
In the expressive distinction, V1is a variable that refers to the actor of the error as specified in the coredenotation, and in the denotational distinction high is a fuzzy set of valuesin the range [0, 1].distinctions that are taken to be relative within the cluster; the cluster establishes thelocal frame of reference for comparing them.
So a word?s set of distinctions implic-itly differentiates the word from its near-synonyms.
In other words, if one consid-ers the peripheral concepts, attitudes, styles, and so on, to be dimensions, then theset of distinctions situates a word in a multidimensional space relative to its near-synonyms.
We define three types of distinction below: denotational, expressive, andstylistic.5.4.1 Denotational Distinctions.
In our formalism, each denotational distinction refersto a particular peripheral concept and specifies a value on that dimension, which canbe binary (i.e., is or isn?t expressed), continuous (i.e., takes a possibly fuzzy value inthe range [0, 1]), or discrete (i.e., takes a conceptual structure as a value).Now, in Section 2.3.1 we observed that indirectness forms a continuum (sugges-tion, implication, denotation), and, following the method used by lexicographers in near-synonym guides, points on the continuum are modulated up or down by a strength,which can take the values weak, medium, or strong.
To also account for context depen-dence at least as well as lexicographers do, we include a measure of the frequencywith which the peripheral concept is conveyed by the word.
This can take one of fivevalues (never, seldom, sometimes, often, always).
When the problem of context dependenceis better understood, this part of the formalism will need to be changed.Thus, a denotational distinction of a word w is a quadruple of components asfollows:w: (frequency strength indirectness concept)The first part of Table 2 gives some examples for the distinctions of Figures 7 and 8.5.4.2 Expressive Distinctions.
Since a word can express a speaker?s attitude towardpotentially any entity in a situation, an expressive distinction must include a referenceto the entity.
As for the attitude itself, we take a conservative approach, for now, and124Computational Linguistics Volume 28, Number 2define only three possible attitudes: favorable, neutral, and pejorative.
Thus, an expressivedistinction has the following form:w: (frequency strength attitude entity)Frequency and strength have the same role as above.
The entity is actually a reference(i.e., a variable) to one of the concepts specified in the core denotation of peripheralconcepts.
The second part of Table 2 gives an example.5.4.3 Stylistic Distinctions.
Although we take a rather basic approach to representingstylistic distinctions, that does not imply that style is easy to capture.
Style is one of themost difficult of lexical phenomena to account for, since it affects the text at a pragmaticlevel and is highly influenced by context.
Since there is as yet no comprehensive theoryof style, our approach is similar to past approaches, such as those of DiMarco and Hirst(1993), Stede (1993), and Hovy (1988).Unlike the denotational distinctions discussed above, stylistic features have aglobal or absolute quality to them.
We can compare all words, whether or not they arenear-synonyms, on various stylistic dimensions, such as formality and concreteness.Because style is a global aspect of text, a certain style can be (and should be) achievedby more than just lexical choice; structural choices are just as important (DiMarco andHirst 1993).
Hence, in defining a set of stylistic dimensions, we must look for globalstylistic features that can be carried not only by words but also by syntactic and largertext structures.
Our stylistic dimensions include, but are not limited to, formality,force, concreteness, floridity, and familiarity.Stylistic variation also differs from the other types of variation in being relatedsolely to the lexeme itself and not to its denotation or conceptual meaning (thoughin a deeper sense style is certainly related to meaning).
So in representing stylisticdistinctions we don?t have to make any reference to entities or other aspects of the coredenotation or peripheral concepts in a cluster.
Thus, we represent a stylistic distinctionas follows:w: (degree dimension)where degree can take a value of low, medium, or high (though more values could easilybe added to increase the precision).
The third part of Table 2 gives two examples.6.
Lexical SimilarityIt is not sufficient merely to represent differences between near-synonyms; we mustalso be able to use these representations effectively.
For lexical choice, among othertasks, we need to be able to compare the similarities of pairs of near-synonyms.
Forexample, in a transfer-based MT system, in order to translate the French word bavureinto English, we need to compare the similarities of at least the three pairs bavure : error,bavure : mistake, and bavure : blunder and choose the English word whose meaningis closest to bavure, subject to any constraints arising from the context.
And in textgeneration or interlingual MT, we need to be able to compare the similarities of each ofseveral near-synonyms to a particular semantic representation or conceptual structurein order to choose the one that is closest to it in meaning.Now, the general problem of measuring the semantic distance between wordsor concepts has received much attention.
This century, Wittgenstein (1953) formu-lated the notion of family resemblance?that several things can be related because125Edmonds and Hirst Near-Synonymy and Lexical Choicethey overlap with respect to a set of properties, no property being common to all ofthe words?which Rosch (1978) then used as the basis for the prototype theory ofmeaning.
Recent research in computational linguistics has focused more on develop-ing methods to compute the degree of semantic similarity between any two words,or, more precisely, between the simple or primitive concepts15 denoted by any twowords.There are many different similarity measures, which variously use taxonomic lex-ical hierarchies or lexical-semantic networks, large text corpora, word definitions inmachine-readable dictionaries or other semantic formalisms, or a combination of these(Dagan, Marcus, and Markovitch 1993; Kozima and Furugori 1993; Pereira, Tishby, andLee 1993; Church et al 1994; Grefenstette 1994; Resnik 1995; McMahon and Smith 1996;Jiang and Conrath 1997; Schu?tze 1998; Lin 1998; Resnik and Diab 2000; Budanitsky1999; Budanitsky and Hirst 2001, 2002).
Unfortunately, these methods are generally un-helpful in computing the similarity of near-synonyms because the measures lack therequired precision.
First, taxonomic hierarchies and semantic networks inherently treatnear-synonyms as absolute synonyms in grouping near-synonyms into single nodes(e.g., in WordNet).
In any case, as we argued in Section 3, taxonomies are inappropriatefor modeling near-synonyms.
Second, as we noted in Section 2.2, standard dictionarydefinitions are not usually fine-grained enough (they define the core meaning but notall the nuances of a word) and can even be circular, defining each of several near-synonyms in terms of the other near-synonyms.
And third, although corpus-basedmethods (e.g., Lin?s [1998]) do compute different similarity values for different pairsof near-synonyms of the same cluster, Church et al (1994) and Edmonds (1997) showthat such methods are not yet capable of uncovering the more subtle differences inthe use of near-synonyms for lexical choice.But one benefit of the clustered model of lexical knowledge is that it naturallylends itself to the computation of explicit differences or degrees of similarity betweennear-synonyms.
Although a fully effective similarity measure for near-synonyms stilleludes us, in this section we will characterize the problem and give a solution to onepart of it: computing the similarity of individual lexical distinctions.6.1 Computing the Similarity of Near-SynonymsIn the clustered model of lexical knowledge, a difference between two near-synonymsis encoded implicitly in two sets of relative distinctions.
From two such sets of distinc-tions, one can compute, or build, an explicit representation of the difference betweentwo near-synonyms.
Thus, the difference between, or similarity of, two near-synonymsdepends on the semantic content of their representations on the subconceptual/stylisticlevel (cf.
Resnik and Diab [2000], in which similarity is computed according to thestructure, rather than content, of lexical conceptual structure representations of verbs;see Jackendoff [1983] and Dorr [1993]).Comparing two sets of distinctions is not straightforward, however, because, near-synonyms often differ on seemingly incommensurate dimensions.
That is, the dis-tinctions of one near-synonym will often not match those of another near-synonym,leaving no basis for comparison.
For instance, in Figure 9, bavure and mistake align ononly two of five denotational dimensions (Blameworthiness and Criticism), and thisassumes that each of the near-synonyms was represented using the exact same pe-15 By primitive concepts, we mean named concepts, or concepts that can be lexicalized by a single word,even though they may be defined in terms of other concepts in an ontology.126Computational Linguistics Volume 28, Number 2Diff ("bavure" / "mistake") =(( [usually / unknown] [medium / unknown] [implication / unknown](Stupidity (ATTRIBUTE-OF V1)) )( [always / sometimes] medium implication(Blameworthiness (ATTRIBUTE-OF V1) (DEGREE [more / ])) )( always medium implication\\(Criticism (ACTEE V1) (ATTRIBUTE (Severity (DEGREE [more / ])))) )( [unknown / always] [unknown / medium] [unknown / implication](Misconception (CAUSE-OF V2) (ACTOR V1)) )( [unknown / always] [unknown / weak] [unknown / implication](Accident (CAUSE-OF V2) (ACTOR V1)) )( [always / unknown] [medium / unknown] [implication / unknown](Unfortunate (ATTRIBUTE-OF ROOT)) )( [usually / always] medium [pejorative / neutral] V1 )( [more / ] concreteness ) )Figure 9A structure that explicitly represents the difference between bavure and mistake.
The separatestructures were merged, and where they differed, the two values are shown within squarebrackets separated by a /.ripheral concepts to begin with (i.e., both with Blameworthiness rather than, say,one with Blameworthiness and the other with a closely related concept such asResponsibility).
Can one even compare an error that is caused by a misconceptionto an error that is stupid?
(See Figure 3 for bavure.
)When several dimensions are commensurate, how should one compute similarity?Consider the near-synonyms of forest: Is it possible to decide whether a ?large andwild?
tract of trees is closer to a ?small wild?
one or to a ?medium-sized non-wild?one?
In other words, how much of a change in the size of a forest will compensate foran opposite change in its wildness?Part of the solution lies in the fact that the dimensions of any cluster are neveractually completely incommensurate; usually they will have interrelationships that canbe both modeled in the ontology and exploited when comparing the representationsof words.
For instance, in the cluster of near-synonyms of forest, the wildness of a tractof trees is related to its size and distance from civilization (which one can infer fromone?s knowledge about forests and wildlife; e.g., most wildlife tries to avoid people);so there may be a way of comparing a ?wild?
tract of trees to a ?large?
tract of trees.And in the error cluster, the dimensions are related in similar ways because of theirsemantics and pragmatics (e.g., responsibility leads to blameworthiness, which oftenleads to criticism, and stupidity often leads to a pejorative attitude).
Certainly theseinterrelationships influence both what can be coherently represented in a cluster andhow similar near-synonyms are.
And such relationships can be represented in theknowledge base, and hence reasoned about; a complete model, however, is out of thescope of this article.The interaction of the dimensions within a cluster is not yet very well studied, sofor a partial solution, we make the simplifying assumptions that the dimensions of acluster are independent and that each can be reduced to a true numeric dimension.1616 Certainly, numeric values are necessary at some level of representation.
As we?ve seen, nuances ofmeaning and style are not always clear-cut but can be vague, fuzzy, and continuously variable.
Using anumerical method would seem to be the most intuitive way of computing similarity, which we have todo to compare and choose appropriate lexical items.127Edmonds and Hirst Near-Synonymy and Lexical ChoiceThus, two distinctions d1 and d2 are commensurate if the following two conditionshold:?
d1 and d2 are of the same type (i.e., stylistic, expressive, or denotational).?
If d1 and d2 are stylistic, then they involve the same stylistic dimension;if they are expressive, then they refer to the same entity; and if they aredenotational, then they involve the same peripheral concept.6.2 Computing the Similarity of DistinctionsGiven our simplifications from above, a word?s set of distinctions situates it in a numericmultidimensional space.
Consider a function Sim: D ?
D ?
[0, 1], for computing thesimilarity of two commensurate lexical distinctions taken from the set D of all possibledistinctions that can be represented in a particular cluster.
A value of 0 means thatthe distinctions are completely different (or can?t even be compared), and a value of1 means that they are equivalent (though not necessarily identical, as two equivalentdistinctions might be structurally different).Hence, each type of distinction requires its own similarity function:Sim(d1, d2) =????????
?0.0 if d1 and d2 are not commensurateSimdenotational(d1, d2) if d1 and d2 are denotationalSimexpressive(d1, d2) if d1 and d2 are expressiveSimstylistic(d1, d2) if d1 and d2 are stylistic(1)Each of the similarity functions must compare the values that the pair of distinctionshas on each of their components (see Section 5.4).
To arrive at a final numerical value,we must reduce each component to a real-valued dimension and assign each symbolicvalue for that component to a numeric position on the line.
Edmonds (1999) givescomplete details of the formulas we developed.There is, however, a remaining interesting problem: How does one compute thedegree of similarity of two conceptual structures?
Denotational distinctions sometimesinvolve complex structures of concepts, and these structures must be somehow com-pared to determine their numeric degree of similarity.
For instance, we might needto decide how similar a high degree of blameworthiness is to a moderate degree ofblameworthiness, or to blameworthiness.
Or, we might need to decide how similarofficial authority is to peremptory authority, or how similar arbitrary power is toperemptory authority (where arbitrariness is a kind of peremptoriness and authorityis a kind of power).
Computing this type of similarity is clearly different from, butrelated to, the problem of computing the similarity of primitive concepts (or words).We have to consider not only the content but also the structure of the representations.We are not aware of any research on the general problem of computing the similar-ity of arbitrary conceptual structures, though some related work has been done in thearea of description logics.
Cohen, Borgida, and Hirsh (1992), for example, formalize a?least common subsumer?
operation that returns the largest set of commonalities be-tween two descriptions.
And Resnik and Diab (2000) use a technique, attributed to Lin,of decomposing a structure into feature sets.
Edmonds (1999) describes a technique forsimultaneously traversing a pair of conceptual structures under the assumption thatthe structures will be ?similar?
because they are commensurate.
Still, a good solutionto this problem remains an open issue.128Computational Linguistics Volume 28, Number 2GenerationAnalysisnuancesnuancesRecoverclustersInterlingualrep.
Target TextExpressFrenchclustersEnglishONTOLOGYSource TextContextinstantiatesFigure 10Lexical analysis and choice in machine translation.7.
Lexical Choice7.1 Architectures for Lexical ChoiceThe clustered model of lexical knowledge is applicable to both the lexical-analysisand lexical-choice phases of a machine translation system.
Figure 10 shows that dur-ing analysis, fine-grained lexical knowledge of the source language is accessed, inconjunction with the context, to determine possibilities of what is expressed in thesource language text.
Then, depending on the type of MT system (i.e., transfer orinterlingual), the appropriate target language words can be chosen: The possibilitiesbecome preferences for choice.
Recovering nuances of expression from source text iscurrently an open problem, which we do not explore further here (but see Edmonds[1998] for some preliminary work).
In this section we concentrate on the second phaseof MT and show that robust, efficient, flexible, and accurate fine-grained lexical choiceis a natural consequence of a clustered model.Lexical choice, as we see it, is more than a problem of mapping from concepts towords, as the previous section might have implied; it is a problem of selecting wordsso as to meet or satisfy a large set of possibly conflicting preferences to express certainnuances in certain ways, to establish the desired style, and to respect collocationaland syntactic constraints.
So lexical choice?genuine lexical choice?is making choicesbetween options rather than merely finding the words for concepts, as was the case inmany early text generation systems (for instance, BABEL [Goldman 1975], MUMBLE[McDonald 1983], and TEXT [McKeown 1985]).
This kind of lexical choice is nowthought to be the central task in text generation (or, at least, sentence generation),because it interacts with almost every other task involved.
Indeed, many recent textgeneration systems, including MOOSE (Stede 1999), ADVISOR II (Elhadad, McKeown,and Robin 1997), and Hunter-Gatherer (Beale et al 1998), among others (see Reiterand Dale?s [1997] survey), adopt this view, yet their lexical-choice components do notaccount for near-synonymy.
Without loss of generality, we will look at fine-grainedlexical choice in the context of one of these systems: Stede?s MOOSE (1999).The input to MOOSE is a ?SitSpec,?
that is, a specification of a situation repre-sented on the conceptual?semantic level as a graph of instances of concepts linked129Edmonds and Hirst Near-Synonymy and Lexical Choiceby relations.
MOOSE outputs a complete well-formed ?SemSpec,?
or semantic speci-fication on the syntactic?semantic level, from which the Penman sentence realizationsystem can generate language.17 MOOSE processes the input in two stages.
It firstgathers all of the lexical items (as options for choice) whose conceptual?semantic rep-resentation covers any part of the SitSpec.
Then it chooses a set of lexical items thatsatisfy Stede?s three criteria for sentence planning: the input SitSpec is completely cov-ered (and so is completely lexicalized without redundancy); a well-formed SemSpeccan be built out of the partial SemSpecs associated with each of the chosen lexicalitems; and as many of the preferences are satisfied as possible.
MOOSE supports pref-erences, but only those that require structural decisions, such as choosing a causativeover inchoative verb alternation.
The main goal of Stede?s work was to account forstructural paraphrase in sentence generation, not near-synonymy.In the general case of sentence planning, given a set of input constraints andpreferences, a sentence planner will make a large number of decisions of differenttypes?lexical, syntactic, and structural?each of which has the potential to satisfy any,some, or all of the input preferences (while trying to satisfy the constraints, of course).It is unlikely that any particular set of preferences can all be satisfied simultaneously,so some kind of conflict resolution strategy is required in order to manage the decision-making task.
It is not within the scope of this paper to develop solutions to this generalproblem (but see Nirenburg, Lesser, and Nyberg [1989], Wanner and Hovy [1996],Elhadad, McKeown, and Robin [1997], and Stede [1999] for a variety of solutions).Instead, we will discuss the following two new issues that arise in managing theinteractions between lexical choices that a clustered model brings out:?
We will argue for a unified model for representing any type ofpreference for lexical choice.?
We describe a two-tiered model of lexical choice that is theconsequence of a clustered model of lexical knowledge.Then, we will end the section with a brief description of our software implementationof the model, called I-Saurus.7.2 Constraints and PreferencesSimple systems for lexical choice need only to make sure that the denotations of thewords chosen in response to a particular input exactly match the input.
But whenwe use fine-grained aspects of meaning, the lexical-choice process, and so, in turn, itsinput, will ultimately be more complex.
But with so many possibilities and options,choosing from among them will necessarily involve not only degrees of satisfyingvarious criteria, but also trade-offs among different criteria.
Some of the criteria will behard constraints (i.e., a SitSpec), ensuring that the basic desired meaning is accuratelyconveyed, and others will be preferences.The main difference between a constraint and a preference is that a preferenceis allowed to be satisfied to different degrees, or even not at all, depending on thedecisions that are made during sentence planning.
A preference can be satisfied by17 A SemSpec is a fully lexicalized sentence plan in Penman?s Sentence Plan Language (SPL).
SPL isdefined in terms of the Penman Upper Model, a model of meaning at the syntactic?semantic level,which ensures that the SemSpec is well-formed linguistically.
Penman can thus turn any SemSpec intoa well-formed sentence without having to make any open-class lexical decisions (Penman NaturalLanguage Group 1989; Stede 1999)130Computational Linguistics Volume 28, Number 2a single decision or collectively by a group of decisions.18 And because conflicts andtrade-offs might arise in the satisfaction of several preferences at once, each preferencemust have an externally assigned importance factor.Many types of preference pertain to lexical choice, including emphasizing an as-pect of an entity in a situation, using normal words or a certain dialect, using wordswith a particular phonology (e.g., words that rhyme), using different near-synonymsfor variety or the same word as before for consistency, and so on.
All should beformalizable in a unified model of preference, but we have started with three typescorresponding to the subconceptual level of the clustered model: denotational (or se-mantic), expressive, and stylistic preferences.Denotational preferences are distinct from denotational constraints, but there isno theoretical difference in the nature of a ?preferred?
meaning to a ?constrained?meaning.
Hence, we can represent both in the same SitSpec formalism.
Thus, a deno-tational preference is a tuple consisting of a partial SitSpec and a preferred method ofexpression, which takes a value on the continuum of indirectness (see Section 5.4).
Anexpressive preference requests the expression of a certain attitude toward a certainentity that is part of the situation.
Thus, an expressive preference is a tuple consist-ing of a reference to the entity and the stance that the system should take: favor,remain neutral, or disfavor.
A stylistic preference, for now, is simply a value (of low,medium, or high) on one of the stylistic dimensions.
We will see some examples inSection 8.7.2.1 Satisfying Preferences by Lexical Choice.
In the best case, it will be possibleto simultaneously satisfy all of the input preferences by choosing appropriate near-synonyms from appropriate clusters.
But if none of the available options will sat-isfy, to any degree, a particular preference, then that preference is trivially impossibleto satisfy (by lexical choice).
But even when there are options available that satisfya particular preference, various types of conflicts can arise in trying to satisfy sev-eral preferences at once, making it impossible to use any of those options.
At thelevel of clusters, for instance, in choosing a particular cluster in order to satisfy onepreference, we might be therefore unable to satisfy another preference that can besatisfied only by a different, competing cluster: We might choose the cluster of theerr verbs (to err, to blunder) because of the simplicity or directness of its syntax: Johnerred; but we would not be able simultaneously to satisfy a preference for implyinga misconception by choosing, say, mistake from the cluster of error nouns: John made amistake.Similar trade-offs occur when choosing among the near-synonyms of the samecluster.
Such lexical gaps, where no single word can satisfy all of the input preferencesthat a cluster can potentially satisfy, are common.
For instance, in English, it?s hardto talk about a mistake without at least some overtones of criticism; in Japanese onecan: with ayamari instead of machigai (Fujiwara, Isogai, and Muroyama 1985).
Thereis also no near-synonym of error in English that satisfies preferences to imply bothstupidity and misconception; blunder satisfies the former but not the latter, and mistakevice versa.
Similarly, there is no formal word for an untrue statement (i.e., a lie) thatalso expresses that the lie is insignificant; fib is an option, but it is not a formal word.And there is no word for a tract of trees that is both large and not wild; forest has theformer property, woods the latter.18 A preference is like a floating constraint (Elhadad, McKeown, and Robin 1997) in that it can besatisfied by different types of decision in sentence planning but differs in that it may be satisfied todifferent degrees.131Edmonds and Hirst Near-Synonymy and Lexical ChoiceTwo separate simultaneous choices might also conflict in their satisfaction of a sin-gle preference.
That is, the preference might be satisfied by one choice and negativelysatisfied by another choice.
For instance, it might happen that one word is chosen inorder to express a favorable attitude toward a participant in a particular situation andanother word is chosen that inadvertently expresses a pejorative attitude toward thesame person if that second word is chosen in order to satisfy some other preference.And of course, stylistic decisions can often conflict (e.g., if one has to choose bothformal and informal words).Our solution to resolving such lexical gaps and conflicting preferences is to use anapproximate matching algorithm that attempts to satisfy collectively as many of thepreferences as possible (each to the highest degree possible) by choosing, on two tiers,the right words from the right clusters.19 We will describe this model in Section 7.3.7.2.2 Compatibility of Preferences.
But what happens when it is impossible to simul-taneously satisfy two preferences under any circumstances?
We have assumed up tonow that the set of preferences in the input is consistent or well-formed.
This is often areasonable assumption.
In the context of MT, for instance, we can assume that a ?good?analysis stage would output only well-formed expressions free of incompatibilities.But two preferences may be incompatible, and we would like our system to beable to detect such situations.
For instance, preferences for both low and high severityare incompatible; not only is it impossible for a word to simultaneously express bothideas, but if the system were to attempt to satisfy both, it might output a dissonantexpression20 such as ?I (gently) chided Bill for his (careless) blunder?
(the preferenceto harshly criticize Bill is satisfied by blunder, and the preference to gently criticize Billis satisfied by chide).
(Of course, a dissonant expression is not always undesirable; itmight be used for special effect.)
This kind of incompatibility is easy to detect in ourformalism, because peripheral concepts are explicitly modeled as dimensions.
Thereare, of course, other types of incompatibility, such as denotational and contextualincompatibilities, but we won?t discuss them further here (see Edmonds [1999]).7.3 Two-Tiered Lexical ChoiceAssume now that all of the options for choice have been identified by the system.
Inour system, these options are the clusters whose core denotations match part of theinput SitSpec.
Ignoring the coverage and well-formedness constraints for now, twodifferent, mutually constraining types of decision must be made:?
Choosing from several competing cluster options.?
Choosing a near-synonym from a cluster option.We believe that it is important to separate the processes for making these two typesof decision?even though they must interact?because of their different choice criteriaand effects.
The former type involves choosing between options of differing coarse-grained semantic content and resulting syntactic structure (i.e., paraphrases): clusters19 A complementary approach is to paraphrase the input and hence explicitly express a preferredimplication or mitigate against an unwanted implication (for instance, by generating insignificant liewhen fib is too informal).
A sentence planner, like MOOSE, is designed to generate such structuralparaphrases, so we have concentrated on the lexical issues here.20 Dissonance is one form of semantic anomaly that Cruse (1986) defines by example: ?Arthur is amarried bachelor.
?132Computational Linguistics Volume 28, Number 2have different core denotations, after all.
Here, issues of syntactic and semantic styleare involved, as one can choose how the semantic content is to be incorporated.
Onthe other hand, the latter type of decision involves options that might have subtlesemantic and stylistic differences but result in the same syntactic structure (thoughcollocational and subcategorization structure can vary).In other words, lexical choice is a two-tiered process that must find both theappropriate set of cluster options and the appropriate set of lexical items (one fromeach chosen cluster option) whose contributing SemSpec fragments can be unified intoa complete well-formed SemSpec.
Of course, many possible SemSpecs can usually begenerated, but the real problem is to find the combination of cluster options and lexicalitems that globally satisfy as many of the input preferences as possible.For instance, Figure 11 depicts the state of processing the SitSpec for the utteranceby John of an untrue statement just before lexical choice occurs.
There are four clus-ter options (denoted by the suffix C): say C and tell-a-lie C match subgraphs ofthe SitSpec rooted at say1, untruth C matches the graph rooted at lie1, and John Cmatches john1.
Now, the system could choose the tell-a-lie C cluster and the John Ccluster, which fully cover the SitSpec, and then choose the words John and lie to comeup with John lies, or the system could choose John and prevaricate for John prevaricates.The system could also choose the say C, untruth C and John C clusters, and then thewords tell, fib, and John, to end up with John tells a fib.
These alternatives?there aremany others?are different in structure, meaning, and style.
Which best satisfies theinput preferences, whatever they may be?We can formally define fine-grained lexical choice (within sentence planning) asfollows.
Given an input SitSpec S and a set of compatible preferences P, the goal is tofind a set C of i cluster options and a word wi from each ci ?
C such that?
every node of S is covered by exactly one ci?
the partial SemSpecs of all the words wi can be combined into awell-formed SemSpec SP?
Satisfaction(P, SP) is maximized over all possible SemSpecsThe first criterion ensures complete coverage without redundancy of the input SitSpec,so the desired meaning, at a coarse grain, is expressed; the second ensures that aSemSpec can be constructed that will lead to a grammatical sentence; and the thirdensures that the preferences are collectively satisfied as much as is possible by anysentence plan.
The third criterion concerns us here; the first two are dealt with inMOOSE.As we said earlier, a thorough understanding of the interacting decisions in lexicalchoice is still an open problem, because it is context dependent.
Our present solutionis simply to assume that no complex interaction between decisions takes place.
So,assuming that each option has an associated numeric score (the degree to which itsatisfies all of the preferences), we can simply choose the set of options that maximizesthe sum of the scores, subject to the other constraints of building a proper sentenceplan.
Thus, we do not provide a solution to how the context affects the combinationof the scores.
So, given a sentence plan SP and a set of preferences P, we haveSatisfaction(P, SP) =?w?SPWSat(P, w).
(2)133Edmonds and Hirst Near-Synonymy and Lexical Choicesay_CCluster optionuntruth_CJohn_CSitSpectell-a-lie_CNonconformityequivocatelie ThingUntruthfibPersonCommunicatePersonStatementlieprevaricationJohnfalsehoodmisrepresentationJohnfibnonconform1john1 lie1say1untruthCommunicateprevaricatePersonsaytellATTRIBUTESAYERATTRIBUTESAYERSAYINGSAYINGSAYERSAYERSAYINGSAYERFigure 11The state of processing just before lexical choice on the input for John tells a lie.
Four clustershave become options; each is shown with its core denotation and near-synonyms.
Solid arrowsin the SitSpec indicate relations between instances of concepts.
Solid arrows in the clusteroptions relate concepts in the core denotations.
Dashed arrows link SitSpec nodes to thecluster options that cover subgraphs rooted at the nodes.where WSat is the degree to which w satisfies the preferences P (see Equation (3)).The most preferred sentence plan SP?
is thus the one whose set of word choicesmaximizes Satisfaction(P, SP?).
This function accounts for trade-offs in the satisfactionof preferences, because it finds the set of words that collectively satisfy as many of thepreferences as possible, each to the highest degree possible.Each word in SP has to be chosen from a distinct cluster.
Thus, given?
a particular cluster c in the set of all cluster options?
a list W of candidate near-synonyms of c, ordered according to aprespecified criterion (some candidates of the cluster might have alreadybeen ruled out because of collocational constraints)134Computational Linguistics Volume 28, Number 2?
a set Pc ?
P of compatible preferences, each of which can potentially besatisfied by a word in c, with associated importances: Imp: P ?
[0, 1]find the first candidate w?
?
W such that WSat(P, w?)
is maximized.We use an approximate-matching algorithm to compute WSat(P, w).
Under thesimplification that its value depends on the degree to which w individually satisfieseach of the preferences in Pc, the algorithm computes WSat(P, w) by combining theset of scores Sat(p, w) for all p ?
Pc.
Various combination functions are plausible, in-cluding simple functions, such as a weighted average or a distance metric, and morecomplex functions that could, for instance, take into account dependencies betweenpreferences.21 Deciding on this function is a subject for future research that will em-pirically evaluate the efficacy of various possibilities.
For now, we define WSat as aweighted average of the individual scores, taking into account the importance factors:WSat(P, w) = WSat(Pc, w) =?p?PcImp(p)|Pc|Sat(p, w) (3)For a given preference p ?
Pc, the degree to which p is satisfied by w, Sat(p, w),is reducible to the problem of computing similarity between lexical distinctions, forwhich we already have a solution (see Equation (1)).
Thus,Sat(p, w) = Sim(d(p), d(w)) (4)where d(p) is a kind of pseudo-distinction generated from p to have the same formas a lexical distinction, putting it on equal footing to d(w), and d(w) is the distinctionof w that is commensurate with d(p), if one exists.7.4 Implementation: I-SaurusI-Saurus, a sentence planner that splits hairs, extends Stede?s MOOSE (1999) with themodifications formalized above for fine-grained lexical choice.
It takes a SitSpec anda set of preferences as input, and outputs a sentence plan in Penman?s SPL, whichPenman generates as a sentence in English.
(Section 8 provides an example.
)Now, finding the best set of options could involve a lengthy search process.
Anexhaustive search through all possible sentence plans to find the one that maximizesSatisfaction(P, SP) can be very time-inefficient: In the relatively small example given inSection 8, there are 960 different sentence plans to go through.
To avoid an exhaustivesearch, we use the following heuristic, adopted from Stede (1999): In order to findthe globally preferred sentence plan, make the most preferred local choices.
That is,whenever a (local) decision is made between several options, choose the option withthe highest score.
Thus, we postulate that the most preferred sentence plan will beone of the first few sentence plans generated, though we offer no proof beyond ourintuition that complex global effects are relatively rare, which is also a justification forthe simplifications we made above.Figure 12 gives an algorithm for two-tiered lexical choice embedded in MOOSE?ssentence planner.
The main additions are the procedures Next-Best-Cluster-Option and21 For instance, we might want to consider a particular preference only after some other preference hasbeen satisfied (or not) or only to resolve conflicts when several words satisfy another preference to thesame degree.135Edmonds and Hirst Near-Synonymy and Lexical ChoiceBuild-Sentence-Plan(node, P)(1) c ?Next-Best-Cluster-Option(node, P)if we?ve tried all the options then return ?fail?
(2) w ?Next-Best-Near-Synonym(c, P)if we?ve tried all the near-synonyms in c then backtrack to (1)p ?
partial SemSpec of wif p has external variables thenfor each external variable v in ps ?
Build-Sentence-Plan(node bound to v, P)if s = ?fail?
thenbacktrack to (2)elseattach s to p at vreturn pFigure 12The sentence-planning algorithm.
This algorithm outputs the most preferred completewell-formed SemSpec for a subgraph rooted at given node in the SitSpec.Next-Best-Near-Synonym.
(Note, however, that this version of the algorithm does notshow how complete coverage or well-formedness is ensured.)
Next-Best-Cluster-Optionmoves through the cluster options that cover part of the SitSpec rooted at node inorder of preference.
As we said above, structural decisions on this tier of lexical choiceare outside the scope of this article, but we can assume that an algorithm will in duecourse be devised for ranking the cluster options according to criteria supplied in theinput.
(In fact, MOOSE can rank options according to preferences to foreground orbackground participants, in order to make them more or less salient, but this is onlya start.)
Next-Best-Near-Synonym steps through the near-synonyms for each cluster inorder of preference as computed by WSat(P, w).7.5 SummaryThe two-tiered lexical-choice algorithm (and sentence-planning algorithm) developedin this section is as efficient as any algorithm developed to date for a conventionalmodel of lexical knowledge (without near-synonyms), because it can find the appro-priate cluster or clusters just as easily as the latter can find a word; A cluster in ourmodel corresponds to an individual word in the conventional model.
And choosing anear-synonym from a cluster is efficient because there are normally only a few of themper cluster.
The system does not have to search the entire lexicon.
The full complex-ity of representing and using fine-grained lexical differences is partitioned into smallclusters.
The process is also robust, ensuring that the right meaning (at a coarse grain)is lexicalized even if a ?poor?
near-synonym is chosen in the end.
And when the rightpreferences are specified in the input, the algorithm is accurate in its choice, attemptingto meet as many preferences as possible while also satisfying the constraints.8.
ExampleA formal evaluation of I-Saurus would require both a substantial lexicon of clustersand a large test suite of input data correlated with the desired output sentences.
Build-ing such a suite would be a substantial undertaking in itself.
Barring this, we could136Computational Linguistics Volume 28, Number 2Table 3Four simultaneous preferences and the six candidates of the untruth C cluster.Preferences:1 (imply (significance1 (ATTRIBUTE-OF lie1) (DEGREE low)))2 (imply (intend1 (ACTOR john1) (ACTEE mislead1)))3 (disfavor john1)4 (low formality)CandidatePreference fib lie misrepresentation untruth prevarication falsehood1 Insignificance 1.00 0.00 0.00 0.00 0.00 0.002 Deliberateness 0.50 1.00 0.75 0.25 0.75 0.003 Disfavor 0.50 0.63 0.50 0.50 0.50 0.504 Low formality 1.00 0.50 0.50 0.50 0.00 0.50Total Score 3.00 2.13 1.75 1.25 1.25 1.00Note: For each candidate, we show the satisfaction scores (Sat) for each individualpreference and the total satisfaction scores (WSat): fib scores highest.evaluate I-Saurus as an MT system, in terms of coverage and of quality (intelligibility,fidelity, and fluency).
Unfortunately, I-Saurus is but a prototype with a small exper-imental lexicon, so we can only show by a few examples that it chooses the mostappropriate words given a variety of input preferences.Returning again the situation of John and his lie (Figure 11), consider the set of foursimultaneous preferences shown in the top part of Table 3.
The bottom part shows thescores for each candidate in the untruth C cluster.
If this cluster option were chosen,then I-Saurus would choose the noun fib, because it simultaneously and maximallysatisfies all of the preferences as shown by the score of WSat({1, 2, 3, 4}, fib) = 3.00.
Butnote that if fib were not available, then the second-place lie would be chosen, leavingunsatisfied the preference to express insignificance.Now, for a whole sentence, consider the SitSpec shown in Table 4.
For this, I-Saurus can generate 960 different sentence plans, including plans that realize thesentences John commands an alcoholic to lie and John orders a drunkard to tell a fib.
I-Saurus can be so prolific because of the many possible combinations of the near-synonyms of the six clusters involved: John C (one near-synonym), alcoholic C (tennear-synonyms), order C (six near-synonyms), say C (two near-synonyms), untruth C(six near-synonyms), and tell-a-lie C (four near-synonyms).The bottom part of Table 4 shows the variety of output that is possible when eachindividual preference and various combinations of simultaneous preferences (casesi?x) are input to the system.
(The numbered preferences are listed at the top of thetable.)
So for example, if we input preference 3 (high formality), the system outputsJohn enjoins an inebriate to prevaricate.
The output appears stilted in some cases becauseno other parameters, such as desired verb tense, were given to Penman and becausethe system has no knowledge of collocational constraints.
Of course, we could havedefined many other preferences (and combinations of preferences), but we chose theseparticular ones in order to show some of the interesting interactions that occur amongthe cluster options during processing; they are not meant to be representative of whata user would normally ask of the system.Consider, for instance, case iv.
Here, one cluster can satisfy preference 6 (pejorativeattitude), and another cluster can satisfy preference 10 (misconception), but neither137Edmonds and Hirst Near-Synonymy and Lexical ChoiceTable 4A sample of output sentences of I-Saurus given an input SitSpec and various preferences andcombinations of preferences (cases i?x).SitSpec:(order1 (SAYER john1)(SAYEE alcoholic1)(SAYING (perform1 (ACTOR alcoholic1)(ACTEE (tell1 (SAYER alcoholic1)(SAYING (lie1(ATTRIBUTE nonconform1))))))))Preferences:1 (low formality)2 (medium formality)3 (high formality)4 (high concreteness)5 (favor alcoholic1)6 (disfavor alcoholic1)7 (imply (authority1 (ATTRIBUTE-OF john1) (ATTRIBUTE official1)))8 (imply (authority1 (ATTRIBUTE-OF john1) (ATTRIBUTE peremptory1)))9 (imply (significance1 (ATTRIBUTE-OF lie1) (DEGREE low)))10 (imply (misconceive1 (ACTOR alcoholic1) (CAUSE-OF lie1)))11 (imply (contradict2 (ACTOR lie1) (ATTRIBUTE categorical2)))Case Input preferences OutputNone John commands an alcoholic to lie.1 John commands a drunk to fib.2 John commands an alcoholic to lie.3 John enjoins an inebriate to prevaricate.4 John directs a drunkard to tell a lie.5 John commands a tippler to fib.6 John commands a drunk to lie.7 John commands an alcoholic to lie.8 John orders an alcoholic to lie.9 John commands an alcoholic to fib.10 John commands an alcoholic to tell an untruth.11 John commands an alcoholic to lie.i 2, 4 John directs a drunkard to tell a lie.ii 1, 9 John commands a drunk to fib.iii 3, 6 John enjoins a drunkard to prevaricate.iv 6, 10 John commands a drunkard to tell an untruth.v 3, 9 John enjoins an inebriate to fib.vi 3, 7, 9 John commands an inebriate to fib.vii 3, 8, 9 John orders an inebriate to fib.viii 3, 6, 8, 9 John orders a drunkard to fib.ix 3, 5 John enjoins a tippler to tell a prevarication.x 3, 5, 11 John enjoins a tippler to tell a prevarication.cluster can satisfy both preferences on its own.
So the system chooses drunkard, becauseit is pejorative, and untruth, because it implies a misconception.
No other combinationof choices from the two clusters could have simultaneously satisfied both preferences.And finally, consider case v, which illustrates a clash in the satisfaction of one ofthe preferences.
Fib is chosen despite the fact that it is informal, because it is the onlyword that implies an insignificant lie.
But the system compensates by choosing two138Computational Linguistics Volume 28, Number 2other formal words: enjoin and inebriate.
If we add a preference to this case to implythat John has official authority (case vi), then I-Saurus system chooses command insteadof enjoin, further sacrificing high formality.9.
Related WorkMost computational work on near-synonymy has been motivated by lexical mismatchesin machine translation (Kameyama et al 1991).
In interlingual MT, an intermediaterepresentational scheme, such as an ontology in knowledge-based machine translation(KBMT) (Nirenburg et al 1992), or lexical-conceptual structures in UNITRAN (Dorr1993) is used in encoding lexical meaning (and all other meaning).
But as we showedin Section 3, such methods don?t work at the fine grain necessary for near-synonymy,despite their effectiveness at a coarse grain.
To overcome these problems but retain theinterlingual framework, Barnett, Mani, and Rich (1994) describe a method of generat-ing natural-sounding text that is maximally close in meaning to the input interlingualrepresentation.
Like us, they define the notion of semantic closeness, but whereas theyrely purely on denotational representations and (approximate) logical inference in ad-dition to lexical features for relative naturalness, we explicitly represent fine-grainedaspects on a subconceptual level and use constraints and preferences, which gives flex-ibility and robustness to the lexical-choice process.
Viegas (1998), on the other hand,describes a preliminary solution that accounts for semantic vagueness and underspec-ification in a generative framework.
Although her model is intended to account fornear-synonymy, she does not explicitly discuss it.Transfer-based MT systems use a bilingual lexicon to map words and expressionsfrom one language to another.
Lists, sometimes huge, of handcrafted language-pair-specific rules encode the knowledge to use the mapping (e.g., in SYSTRAN [Gerberand Yang 1997]).
EuroWordNet (Vossen 1998) could be used in such a system.
ItsInter-Lingual-Index provides a language-independent link between synsets in differentlanguages and has an explicit relation, EQ NEAR SYNONYM, for relating synsets thatare not directly equivalent across languages.
But, as in individual WordNets, there isno provision for representing differences between near-synonyms.In statistical MT, there would seem to be some promise for handling near-synon-ymy.
In principle, a system could choose the near-synonym that is most probable giventhe source sentence and the target-language model.
Near-synonymy seems to havebeen of little concern, however, in statistical MT research: The seminal researchers,Brown et al (1990), viewed such variations as a matter of taste; in evaluating theirsystem, two different translations of the same source that convey roughly the samemeaning (perhaps with different words) are considered satisfactory translations.
Morerecently, though, Foster, Isabelle, and Plamondon (1997) show how such a model canbe used in interactive MT, and Langkilde and Knight (1998) in text generation.
Suchmethods are unfortunately limited in practice, because it is too computationally ex-pensive to go beyond a trigram model (only two words of context).
Even if a statisticalapproach could account for near-synonymy, Edmonds (1997) showed that its strengthis not in choosing the right word, but rather in determining which near-synonym ismost typical or natural in a given context.
So such an approach would not be so usefulin goal-directed applications such as text generation, or even in sophisticated MT.10.
ConclusionEvery natural language processing system needs some sort of lexicon, and for manysystems, the lexicon is the most important component.
Yet, real natural language pro-139Edmonds and Hirst Near-Synonymy and Lexical Choicecessing systems today rely on a relatively shallow coverage of lexical phenomena,which unavoidably restricts their capabilities and thus the quality of their output.
(Ofcourse, shallow lexical semantics is a necessary starting point for a practical system,because it allows for broad coverage.)
The research reported here pushes the lexicalcoverage of natural language systems to a deeper level.The key to the clustered model of lexical knowledge is its subconceptual/stylisticlevel of semantic representation.
By introducing this level between the traditional con-ceptual and syntactic levels, we have developed a new model of lexical knowledgethat keeps the advantages of the conventional model?efficient paraphrasing, lexicalchoice (at a coarse grain), and mechanisms for reasoning?but overcomes its short-comings concerning near-synonymy.
The subconceptual/stylistic level is more expres-sive than the top level, yet it allows for tractable and efficient processing becauseit ?partitions,?
or isolates, the expressiveness (i.e., the non-truth-conditional seman-tics and fuzzy representations) in small clusters.
The model reconciles fine-grainedlexical knowledge with coarse-grained ontologies using the notion of granularity ofrepresentation.The next stage in this work is to build a more extensive lexicon of near-synonymclusters than the few handwritten clusters that were built for the simple implementa-tion described in this article.
To this end, Inkpen and Hirst (2001a, 2001b) are develop-ing a method to automatically build a clustered lexicon of 6,000 near-synonyms (1,000clusters) from the machine-readable text of Hayakawa?s Choose the Right Word (1994).Besides MT and NLG, we envision other applications of the model presentedin this article.
For instance, an interactive dictionary?an intelligent thesaurus?wouldactively help a person to find and choose the right word in any context.
Rather thanmerely list possibilities, it would rank them according to the context and to parameterssupplied by the user and would also explain potential effects of any choice, whichwould be especially useful in computer-assisted second-language instruction.
Or themodel could be applied in the automatic (post)editing of text in order to make thetext conform to a certain stylistic standard or to make a text more readable or naturalto a given audience.We leave a number of open problems for another day, including recovering nu-ances from text (see Edmonds [1998] for a preliminary discussion); evaluating theeffectiveness of the similarity measures; determining the similarity of conceptual struc-tures; understanding the complex interaction of lexical and structural decisions duringlexical choice; exploring the requirements for logical inference in the model; model-ing other aspects of fine-grained meaning, such as emphasis; and understanding thecontext-dependent nature of lexical differences and lexical knowledge.Appendix: An Example Representation: The Error ClusterThe following is the representation of the cluster of error nouns in our formalism.Tokens ending in l represent lexical items.
In upper case are either variables (forcross-reference) or relations; it should be clear from the context which is which.
Cap-italized tokens are concepts.
In lower case are values of various features (such as?indirectness?
and ?strength?)
defined in the model.
We have not discussed many ofthe implementation details in this article, including p-link and covers (see Edmonds[1999]).
(defcluster error C;;; from Gove (1984):syns (error l mistake l blunder l slip l lapse l howler l)140Computational Linguistics Volume 28, Number 2:core (ROOT Generic-Error):p-link ((V1 (:and (Person V1) (ACTOR ROOT V1)))(V2 (:and (Deviation V2) (ATTRIBUTE ROOT V2)))):covers (ROOT):periph((P1 Stupidity (ATTRIBUTE-OF V1))(P2 Blameworthiness (ATTRIBUTE-OF V1))(P3 Criticism (ACTEE V1) (ATTRIBUTE (P31 Severity)))(P4 Misconception (CAUSE-OF V2) (ACTOR V1))(P5 Accident (CAUSE-OF V2) (ACTOR V1))(P6 Inattention (CAUSE-OF V2) (ACTOR V1))):distinctions (;; Blunder commonly implies stupidity.
(blunder l usually medium implication P1);; Mistake does not always imply blameworthiness, blunder sometimes.
(mistake l sometimes medium implication (P2 (DEGREE ?medium)))(error l always medium implication (P2 (DEGREE ?medium)))(blunder l sometimes medium implication (P2 (DEGREE ?high)));; Mistake implies less severe criticism than error.
;; Blunder is harsher than mistake or error.
(mistake l always medium implication (P31 (DEGREE ?low)))(error l always medium implication (P31 (DEGREE ?medium)))(blunder l always medium implication (P31 (DEGREE ?high)));; Mistake implies misconception.
(mistake l always medium implication P4);; Slip carries a stronger implication of accident than mistake.
;; Lapse implies inattention more than accident.
(slip l always medium implication P5)(mistake l always weak implication P5)(lapse l always weak implication P5)(lapse l always medium implication P6);; Blunder expresses a pejorative attitude towards the person.
(blunder l always medium pejorative V1);; Blunder is a concrete word, error and mistake are abstract.
(blunder l high concreteness)(error l low concreteness)(mistake l low concreteness);; Howler is an informal term(howler l low formality)))AcknowledgmentsOur work is financially supported by theNatural Sciences and Engineering ResearchCouncil of Canada, the Ontario GraduateScholarship program, and the University ofToronto.
For discussions, suggestions, andcomments on this work, we are grateful toJack Chambers, Mark Chignell, Robert Dale,Chrysanne DiMarco, Paul Deane, SteveGreen, Eduard Hovy, Brian Merrilees, JohnMylopoulos, Kazuko Nakajima, SergeiNirenburg, Geoffrey Nunberg, HenrySchoght, Manfred Stede and the anonymousreviewers of Computational Linguistics.ReferencesBailly, Rene?.
1970.
Dictionnaire des synonymesde la langue franc?aise.
Librairie Larousse,Paris.141Edmonds and Hirst Near-Synonymy and Lexical ChoiceBarnett, James, Inderjeet Mani, and ElaineRich.
1994.
Reversible machinetranslation: What to do when thelanguages don?t match up.
In TomekStrzalkowski, editor, Reversible Grammar inNatural Language Processing.
KluwerAcademic, pages 321?364.Barsalou, Lawrence W. 1992.
Frames,concepts, and conceptual fields.
InAdrienne Lehrer and Eva Fedder Kittay,editors, Frames, Fields, and Contrasts: NewEssays in Semantic and Lexical Organization,pages 21?74.
Lawrence Erlbaum.Batchelor, Ronald E. and Malcolm H.Offord.
1993.
Using French Synonyms.Cambridge University Press.Beale, Stephen, Sergei Nirenburg, EvelyneViegas, and Leo Wanner.
1998.De-constraining text generation.
InProceedings of the Ninth InternationalWorkshop on Natural Language Generation,pages 48?57.Be?nac, Henri.
1956.
Dictionnaire dessynonymes.
Librairie Hachette, Paris.Brown, Peter F., John Cooke, Stephen A.Della Pietra, Vincent J. Della Pietra,Frederick Jelinek, John D. Lafferty,Robert L. Mercer, and Paul S. Roossin.1990.
A statistical approach to machinetranslation.
Computational Linguistics,16(2):79?85.Budanitsky, Alexander.
1999.
Measuringsemantic relatedness and its applications.Master?s thesis, technical reportCSRG-390, Department of ComputerScience, University of Toronto, Toronto,Canada.
Available at http://www.cs.toronto.edu/compling/Publications/Abstracts/Theses/Budanistsky-thabs.html.Budanitsky, Alexander and Graeme Hirst.2001.
Semantic distance in WordNet: Anexperimental, application-orientedevaluation of five measures.
In Workshopon WordNet and Other Lexical Resources:Second Meeting of the North AmericanChapter of the Association for ComputationalLinguistics, pages 29?34, Pittsburgh.Budanitsky, Alexander and Graeme Hirst.2002.
Lexical semantic relatedness.Manuscript in preparation.Burkert, Gerrit and Peter Forster.
1992.Representation of semantic knowledgewith term subsumption languages.
InJames Pustejovsky and Sabine Bergler,editor, Lexical Semantics and KnowledgeRepresentation: First SIGLEX Workshop.Lecture Notes in Artificial Intelligence627.
Springer-Verlag, pages 75?85.Chapman, Robert L, editor.
1992.
Roget?sInternational Thesaurus.
5th edition.HarperCollins Publishers.Church, Kenneth Ward, William Gale,Patrick Hanks, Donald Hindle, andRosamund Moon.
1994.
Lexicalsubstitutability.
In B. T. S. Atkins andA.
Zampolli, editors, ComputationalApproaches to the Lexicon.
OxfordUniversity Press, pages 153?177.Clark, Eve V. 1992.
Conventionality andcontrast: Pragmatic principles with lexicalconsequences.
In Adrienne Lehrer andEva Fedder Kittay, editors, Frames, Fields,and Contrasts: New Essays in Semantic andLexical Organization.
Lawrence Erlbaum,pages 171?188.Cohen, William W., Alex Borgida, andHaym Hirsh.
1992.
Computing leastcommon subsumers in description logic.In Proceedings of the Tenth NationalConference on Artificial Intelligence(AAAI-92), pages 754?760.Coleman, Linda and Paul Kay.
1981.Prototype semantics: The English wordlie.
Language, 57(1):26?44.Cruse, D. Alan.
1986.
Lexical Semantics.Cambridge University Press.Dagan, Ido, Shaul Marcus, and ShaulMarkovitch.
1993.
Contextual wordsimilarity and estimation from sparsedata.
In Proceedings of the 31st AnnualMeeting of the Association for ComputationalLinguistics, pages 164?171.DiMarco, Chrysanne and Graeme Hirst.1993.
A computational theory ofgoal-directed style in syntax.Computational Linguistics, 19(3):451?500.DiMarco, Chrysanne, Graeme Hirst, andManfred Stede.
1993.
The semantic andstylistic differentiation of synonyms andnear-synonyms.
In AAAI SpringSymposium on Building Lexicons for MachineTranslation, pages 114?121, Stanford, CA,March.Dorr, Bonnie J.
1993.
Machine Translation: AView from the Lexicon.
MIT Press.Edmonds, Philip.
1997.
Choosing the wordmost typical in context using a lexicalco-occurrence network.
In Proceedings ofthe 35th Annual Meeting of the Association forComputational Linguistics, pages 507?509,Madrid, Spain.Edmonds, Philip.
1998.
Translatingnear-synonyms: Possibilities andpreferences in the interlingua.
InProceedings of the AMTA/SIG-IL SecondWorkshop on Interlinguas, pages 23?30,Langhorne, PA. (Proceedings published astechnical report MCCS-98-316,Computing Research Laboratory, NewMexico State University.
)142Computational Linguistics Volume 28, Number 2Edmonds, Philip.
1999.
SemanticRepresentations of Near-Synonyms forAutomatic Lexical Choice.
Ph.D. thesis,Department of Computer Science,University of Toronto.
Available athttp://www.cs.toronto.edu/compling/Publications/ Abstracts/Theses/EdmondsPhD-thabs.html.Egan, Rose F. 1942.
?Survey of the history ofEnglish synonymy?
and ?Synonym:Analysis and definition.?
Reprinted inPhilip B. Gove, editor, Webster?s NewDictionary of Synonyms.
Merriam-Webster,Springfield, MA, pp.
5a?31a.Elhadad, Michael, Kathleen McKeown, andJacques Robin.
1997.
Floating constraintsin lexical choice.
Computational Linguistics,23(2):195?240.Emele, Martin, Ulrich Heid, Stefan Momma,and Re?mi Zajac.
1992.
Interactionsbetween linguistic constraints: Proceduralvs.
declarative approaches.
MachineTranslation, 7(1?2):61?98.Evens, Martha, editor.
1988.
RelationalModels of the Lexicon: RepresentingKnowledge in Semantic Networks.Cambridge University Press.Farrell, Ralph Barstow.
1977.
Dictionary ofGerman Synonyms.
3rd edition.
CambridgeUniversity Press.Fernald, James C., editor.
1947.
Funk &Wagnall?s Standard Handbook of Synonyms,Antonyms, and Prepositions.
Funk &Wagnall?s, New York.Foster, George, Pierre Isabelle, and PierrePlamondon.
1997.
Target-text mediatedinteractive machine translation.
MachineTranslation, 12:175?194.Frege, Gottlob.
1892.
U?ber Sinn undBedeutung.
Zeitschrift fu?r Philosophie undPhilosophie Kritik, 100:25?50.
Englishtranslation: On sense and reference.
In P.Geach and M. Black, editors, Translationsfrom the Philosophical Writings of GottlobFrege.
Blackwell, 1960.Fujiwara, Yoichi, Hideo Isogai, and ToshiakiMuroyama.
1985.
Hyogen ruigo jiten.Tokyodo Shuppan, Tokyo.Gentner, Dedre and Arthur B. Markman.1994.
Structural alignment in comparison:No difference without similarity.Psychological Science, 5(3):152?158.Gerber, Laurie, and Jin Yang.
1997.SYSTRAN MT dictionary development.
InMachine Translation: Past, Present, andFuture: Proceedings of Machine TranslationSummit VI, pages 211?218, San Diego, CA.Goldman, Neil M. 1975.
Conceptualgeneration.
In Roger C. Schank, editor,Conceptual Information Processing.North-Holland, Amsterdam, pages289?371.Goodman, Nelson.
1952.
On likeness ofmeaning.
In L. Linsky, editor, Semanticsand the Philosophy of Language.
Universityof Illinois Press, pages 67?74.Gove, Philip B., editor.
1984.
Webster?s NewDictionary of Synonyms.
Merriam-Webster,Springfield, MA.Grefenstette, Gregory.
1994.
Explorations inAutomatic Thesaurus Discovery.
KluwerAcademic Publishers.Hayakawa, S. I., editor.
1994.
Choose theRight Word: A Contemporary Guide toSelecting the Precise Word for Every Situation.2nd edition, revised by Eugene Ehrlich.HarperCollins Publishers, New York.Hirst, Graeme.
1995.
Near-synonymy andthe structure of lexical knowledge.
InAAAI Symposium on Representation andAcquisition of Lexical Knowledge: Polysemy,Ambiguity, and Generativity, pages 51?56,Stanford, CA, March.Hovy, Eduard.
1988.
Generating NaturalLanguage Under Pragmatic Constraints.Lawrence Erlbaum Associates.Inkpen, Diana Zaiu and Graeme Hirst.2001a.
Experiments on extractingknowledge from a machine-readabledictionary of synonym differences.
InAlexander Gelbukh, editor, ComputationalLinguistics and Intelligent Text Processing(Proceedings, Second Conference on IntelligentText Processing and ComputationalLinguistics, Mexico City, February 2001),Lecture Notes in Computer Science 2004.Springer-Verlag, pages 264?278.Inkpen, Diana Zaiu and Graeme Hirst.2001b.
Building a lexical knowledge-baseof near-synonym differences.
Workshop onWordNet and Other Lexical Resources, SecondMeeting of the North American Chapter of theAssociation for Computational Linguistics,pages 47?52, Pittsburgh.Jackendoff, Ray.
1983.
Semantic andCognition.
MIT Press.Jackendoff, Ray.
1990.
Semantic Structures.MIT Press.Jiang, Jay J. and David W. Conrath.
1997.Semantic similarity based on corpusstatistics and lexical taxonomy.
InProceedings of the International Conference forResearch on Computational Linguistics(ROCLING X), Taiwan.Kameyama, Megumi, Ryo Ochitani, StanleyPeters, and Hidetoshi Sirai.
1991.Resolving translation mismatches withinformation flow.
In Proceedings of the 29thAnnual Meeting of the Association forComputational Linguistics, pages 193?200.Katz, Jerrold J. and Jerry A. Fodor.
1963.The structure of a semantic theory.143Edmonds and Hirst Near-Synonymy and Lexical ChoiceLanguage, 39:170?210.Kay, Maire?
Weir, editor.
1988.
Webster?sCollegiate Thesaurus.
Merriam-Webster,Springfield, MA.Kay, Paul.
1971.
Taxonomy and semanticcontrast.
Language, 47(4):866?887.Kozima, Hideki and Teiji Furugori.
1993.Similarity between words computed byspreading activation on an Englishdictionary.
In Proceedings of the SixthConference of the European Chapter of theAssociation for Computational Linguistics,pages 232?239, Utrecht, Netherlands.Kroll, Judith F. and Annette M.B.
de Groot.1997.
Lexical and conceptual memory inthe bilingual: Mapping form to meaningin two languages.
In Annette M.B.
deGroot and Judith F. Kroll, editors, Tutorialsin Bilingualism: Psycholinguistic Perspectives.Lawrence Erlbaum, pages 169?199.Langkilde, Irene and Kevin Knight.
1998.The practical value of n-grams ingeneration.
In Proceedings of the NinthInternational Workshop on Natural LanguageGeneration, pages 248?255,Niagara-on-the-Lake, Canada.Lehrer, Adrienne and Eva Feder Kittay.1992.
Introduction.
In Adrienne Lehrerand Eva Feder Kittay, editors, Frames,Fields, and Contrasts: New Essays in Semanticand Lexical Organization.
LawrenceErlbaum, pages 1?20.Levin, Beth.
1993.
English Verb Classes andAlternations: A Preliminary Investigation.University of Chicago Press.Lin, Dekang.
1998.
Automatic retrieval andclustering of similar words.
In Proceedingsof the 36th Annual Meeting of the Associationfor Computational Linguistics and the 17thInternational Conference on ComputationalLinguistics (COLING-ACL-98), pages768?774, Montreal.Lyons, John.
1977.
Semantics.
CambridgeUniversity Press.Lyons, John.
1995.
Linguistic Semantics: AnIntroduction.
Cambridge University Press.Markman, Arthur B. and Dedre Gentner.1993.
Splitting the differences: Astructural alignment view of similarity.Journal of Memory and Language, 32:517?535.McDonald, David D. 1983.
Descriptiondirected control: Its implications fornatural language generation.
In NickCercone, editor, Computational Linguistics,International Series in Modern AppliedMathematics and Computer Science 5.Plenum Press, New York, pages 111?129.Reprinted in B. J. Grosz, K. Sparck Jones,and B. L. Webber, editors, Readings inNatural Language Processing.
MorganKaufmann, 1986, pages 519?537.McKeown, Kathleen R. 1985.
Text Generation:Using Discourse Strategies and FocusConstraints to Generate Natural LanguageText.
Cambridge University Press.McMahon, John G. and Francis J. Smith.1996.
Improving statistical languagemodel performance with automaticallygenerated word hierarchies.
ComputationalLinguistics, 22(2):217?248.Nirenburg, Sergei, Jaime Carbonell, MasaruTomita, and Kenneth Goodman.
1992.Machine Translation: A Knowledge-BasedApproach.
Morgan Kaufmann.Nirenburg, Sergei and Christine Defrise.1992.
Application-oriented computationalsemantics.
In Michael Rosner andRoderick Johnson, editors, ComputationalLinguistics and Formal Semantics.Cambridge University Press, pages223?256.Nirenburg, Sergei, Victor Lesser, and EricNyberg.
1989.
Controlling a languagegeneration planner.
In Proceedings of the11th International Joint Conference onArtificial Intelligence, pages 1524?1530.Nirenburg, Sergei and Lori Levin.
1992.Syntax-driven and ontology-driven lexicalsemantics.
In James Pustejovsky andSabine Bergler, editors, Lexical Semanticsand Knowledge Representation: First SIGLEXWorkshop.
Lecture Notes in ArtificialIntelligence 627.
Springer-Verlag, pages5?20.Nogier, Jean-Franc?ois and Michael Zock.1992.
Lexical choice as pattern matching.Knowledge-Based Systems, 5:200?212.Penman Natural Language Group.
1989.The Penman reference manual.
Technicalreport, Information Sciences Institute ofthe University of Southern California.Pereira, Fernando, Naftali Tishby, andLillian Lee.
1993.
Distributional clusteringof English words.
In Proceedings of the 31stAnnual Meeting of the Association forComputational Linguistics, pages 183?190.Pustejovsky, James.
1995.
The GenerativeLexicon.
MIT Press.Pustejovsky, James and Sabine Bergler,editors.
1992.
Lexical Semantics andKnowledge Representation: First SIGLEXWorkshop.
Lecture Notes in ArtificialIntelligence 627.
Springer-Verlag.Quine, W. V. O.
1951.
Two dogmas ofempiricism.
Philosophical Review, 60:20?43.Reiter, Ehud and Robert Dale.
1997.Building applied natural languagegeneration systems.
Natural LanguageEngineering, 3(1):57?88.Resnik, Philip.
1995.
Using informationcontent to evaluate semantic similarity ina taxonomy.
In Proceedings of the 14th144Computational Linguistics Volume 28, Number 2International Joint Conference on ArtificialIntelligence, pages 448?453, Montreal.Resnik, Philip and Mona Diab.
2000.Measuring verb similarity.
In Proceedingsof the 22nd Annual Meeting of the CognitiveScience Society (COGSCI 2000).Resnik, Philip, and David Yarowsky.
1999.Distinguishing systems anddistinguishing senses: New evaluationmethods for word sense disambiguation.Natural Language Engineering, 5(2):135?146.Room, Adrian.
1985.
Dictionary of ConfusingWords and Meanings.
Dorset, New York.Rosch, Eleanor.
1978.
Principles ofcategorization.
In Eleanor Rosch andBarbara B. Lloyd, editors, Cognition andcategorization.
Lawrence ErlbaumAssociates, pages 27?48.Saussure, Ferdinand de.
1916.
Cours delinguistique ge?ne?rale.
Translated by RoyHarris as Course in General Linguistics,London: G. Duckworth, 1983.Schu?tze, Hinrich.
1998.
Automatic wordsense discrimination.
ComputationalLinguistics, 24(1):97?123.Sowa, John F. 1988.
Using a lexicon ofcanonical graphs in a semantic interpreter.In Martha Evens, editor, Relational Modelsof the Lexicon: Representing Knowledge inSemantic Networks.
Cambridge UniversityPress, pages 113?137.Sowa, John F. 1992.
Logical structures in thelexicon.
In James Pustejovsky and SabineBergler, editors, Lexical Semantics andKnowledge Representation: First SIGLEXWorkshop.
Lecture Notes in ArtificialIntelligence 627.
Springer-Verlag, pages39?60.Sparck Jones, Karen.
1986.
Synonymy andSemantic Classification.
EdinburghUniversity Press.Stede, Manfred.
1993.
Lexical choice criteriain language generation.
In Proceedings ofthe Sixth Conference of the European Chapterof the Association for ComputationalLinguistics, pages 454?459, Utrecht,Netherlands.Stede, Manfred.
1999.
Lexical Semantics andKnowledge Representation in MultilingualText Generation.
Kluwer Academic.Tarski, Alfred.
1944.
The semanticconception of truth.
Philosophy andPhenomenological Research, 4:341?375.Ullmann, Stephen.
1962.
Semantics: AnIntroduction to the Science of Meaning.Blackwell.Urdang, Laurence.
1992.
Dictionary ofDifferences.
Bloomsbury, London.Viegas, Evelyne.
1998.
Multilingualcomputational semantic lexicons inaction: The WYSINWYG approach toNLG.
In Proceedings of the 36th AnnualMeeting of the Association for ComputationalLinguistics and the 17th InternationalConference on Computational Linguistics(COLING-ACL-98), pages 1321?1327,Montreal, Canada.Vossen, Piek.
1998.
EuroWordNet: AMultilingual Database with Lexical SemanticNetworks.
Kluwer Academic.Walther, George.
1992.
Power Talking: 50Ways to Say What You Mean and Get WhatYou Want.
Berkley, New York.Wanner, Leo and Eduard Hovy.
1996.
TheHealthDoc sentence planner.
InProceedings of the Eighth InternationalWorkshop on Natural Language Generation,pages 1?10.Wittgenstein, Ludwig.
1953.
PhilosophicalInvestigations.
Blackwell.
