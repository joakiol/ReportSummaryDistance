Domain Knowledge EngineeringBased on Encyclopedias and the Web Text*SUI ZhifangInstitute ofComputationalLinguistics,Peking Universityszf@pku.edu.cnCUI GaoyingInstitute ofComputationalLinguistics,Peking Universitycuigy@pku.edu.cnDING WansongInstitute ofComputationalLinguistics,Peking Universitydws@pku.edu.cnZHANG QinlongInstitute ofComputationalLinguistics,Peking Universityzql@pku.edu.cn*  This  research was funded by 973 Natural Basic Research Program of China 2004CB318102 and Natural SciencesFoundation of Beijing 4052019AbstractDomain knowledge is the fundamentalresources required by all intelligentinformation processing systems.
Withthe upsurge of new technology and newproducts in various domains, themanual construction and updating ofdomain knowledge base can hardlymeet the real needs of applicationsystems, in terms of coverage oreffectiveness.Based on natural language text analysis,this paper intends to draw a basicframework for the construction ofdomain knowledge base.
Usingencyclopedia resources and textinformation resources on the Web, wefocus on the method of constructingdomain knowledge base throughtechnologies in natural language textanalysis and machine learning.Moreover, an open network platformwill be developed, through whichcommon users can work with domainexperts to contribute domainknowledge.The technology can be applied to theconstruction and updating of domainknowledge base for intelligentinformation processing, and it can alsoprovide help for the knowledgeupdating of encyclopedias.Keywords: Domain knowledge base,Natural language text analysis, machinelearning, encyclopedia, open platform1 IntroductionDomain knowledge is the indispensable resourcefor an intelligent information processing system.With the XSsurge of technology, more and morenew technology, new product and newtechniques come into being.
The manualconstruction and updating domain knowledgebase can hardly meet the real needs ofapplication systems, in terms of coverage oreffectiveness.
In order to improve the robust ofan information system, we need to study acomputer-aided method to solve the bottleneckof domain knowledge acquisition.The Institute of Computational Linguistics,Peking University, now cooperates withEncyclopedia of China Publishing Hall on theproject of human-machine interactiveencyclopedia knowledge engineering.
We wantto study how to exploit, use and updateencyclopedia resource properly.
We will use thetechnique of natural language processing,machine learning and text mining to acquiredomain knowledge semi-automatically from1both encyclopedia and the Web text.Furthermore, we set up an open platform fordomain knowledge acquisition, so that commonnetwork users and domain experts can worktogether to contribute new domain knowledge.Based on this technology, we can build domainknowledge base on each domain.
Thistechnology can be used as an important methodof constructing and updating the domainknowledge base for the intelligent informationretrieval and extraction systems.
In the sametime, it can also provide help for the knowledgeupdating of encyclopedias.2 Related worksThe researches on knowledge acquisition can bedivided into three parts: artificial construction,semi-automatic construction and automaticconstruction.Artificial methods are usually used inconstructing the common sense knowledge base,such as CYC[1], WordNet[2], EuroWordNet[3],HowNet[4], and CCD[5] etc.
That?s becausecommon sense is steady comparatively and itcan not be affected by the task, also it can bereused by various kinds of system whenconstructed.
For instance, since the WordNetwas established in 1985, it had been widely usedin IR, Text categorization, QA system etc.Similarly, the HowNet is being used in manyChinese information procession systems.
It?sworthy of large-scale devotion for long-timeusing.On the contrary, domain knowledge is tiedwith some concrete domain.
Once theapplication domain changed, we need to re-construct the domain knowledge base.Furthermore, domain knowledge updatescontinually, so that the domain knowledge baseshould be updates frequently.
So it?s unrealisticto construct the domain knowledge basemanually.In the way of constructing domain knowledgebase, the semi-automatic method is mainly used.
[6][7][8][9][10] established the platform ofhuman-computer interactively working for theconstruction of domain knowledge base.
Theyuse various kinds of text processing andlanguage analysis tools, which have thefunctions of morphological analysis, partialsyntactic analysis, partial semantic analysis,with the mode of online cooperation, helpingknowledge engineers or domain experts to findthe domain concepts and the relations amongthem.
The acquired knowledge can be addedinto the domain knowledge base.
All thesemethods try to use pattern matching or variouslayers of NLP technology to acquire domainknowledge from large-scale free text.
Free textis easy to get, however, it comes from differentkinds of domain, including complicatedlanguage phenomenon hence is hard tounderstand.
It?s difficult to extract knowledgereliably using current technology of NLP andmachine learning from such free text.
If therenot exists a pre-defined basic domain knowledgearchitecture, it is difficult to acquire theconcepts and the relations relative to the domain.Also, among the above-mentioned methods, theconstruction of domain knowledge base dependson the expert?s point of view and opinions.However, it?s very difficult to let experts toconstruct the ?real-time?
domain architectureobjectively and roundly and hence express itclearly in the given time.3 Domain Knowledge EngineeringBased on Encyclopedias and the WebtextIn this paper, we propose a technology ofdomain knowledge engineering based onencyclopedias and the web text.
(ncyclopedia isthe embodiment of the systematization andcentralization of existed domain knowledge.
Theknowledge has been compiled and modified bymany experts.
Compared with free text, there aremore canonical and NLP technologies can beused comparatively easily to extract knowledgefrom it.
Since the knowledge in encyclopedia ismore systematic, we can easily construct thebasic frame of domain knowledge.
So we willuse NLP technology and machine learningmethod to construct the kernel of domainknowledge based on the analysis of theencyclopedia.
Then based on the kernel ofdomain knowledge base, we can extract domainknowledge from other text resources.There exist some researches on extractingknowledge from the encyclopedia [11] [12] [13][14].
These researches use the encyclopedias asthe only source to acquire knowledge.
However,with the high-speed improvement in each2domain, there is severe knowledge lag inencyclopedias.
So it is inadequate to useencyclopedias as the only source for knowledgeacquisition.
We need to learn more domainknowledge from other text resource besidesencyclopedias.With the surge of Internet, information in it isincreasing exponentially.
Abundant knowledgelies in this huge Web resource.
If we can extractknowledge from the Web, we could update andexpand domain knowledge base most efficiently.Standing in the computational linguistics?
point,we focus on retrieving information from thecontent rather than from the structure of theWeb.This paper studies the technology of domainknowledge engineering.
Using encyclopediaresource and text information resource on theWeb, we focus on the method of constructingdomain knowledge base through technologies innatural language text analysis and machinelearning.
Moreover, an open network platformwill be developed, through which common userscan work together with domain experts tocontribute domain knowledge.4 Strategy and Research Plan4.1 Learning the style of knowledge-dense text from encyclopediasThe compilation of encyclopedias alwaysfollows some specified compilatory model.Encyclopedias have the relatively formal dictionand different compilatory model for differentkinds of entries.
Because of that, theparaphrasable text in encyclopedias has clearermodel to express the relation among concepts inmost cases.
For instance, ?X is a kind of ?Y?,?X is composed of A, B, C and D?, ?A, B and Cmake up D?, ?X can be divided into A, B and C?.Through recognizing the terms and partialparsing for the paraphrasable text in theencyclopedia, we could learn the patterns, whichexpress the relations among concepts.Furthermore, we could learn the styles ofknowledge dense text based on those patterns.Next step, we will follow the styles and combinethe HTML target set to acquire more knowledgedense text fragments from the web.
Based onsuch knowledge-dense text, some deeper naturallanguage processing technologies could be usedto extract domain knowledge reliably.4.2 Automatic extraction of termsThrough analyzing the characters and expressionforms of Chinese terms, we learn termknowledge from large-scale domain corpus andterm bank.
Using natural language processingmethod combing rule and statistics, we canautomatically extract Chinese terms from corpus.A term is a kind of phrases, whosecomponents are close related.
Further more, ithas strong domain feature.
The close relation ofthe components in a term can be capturedthrough calculating the static association ratebetween the words that compose a termcandidate.
The linguistic feature can be capturedthrough analysis the grammatical structuralinformation of the terms.
While the domainfeature of a term can be captured through thedomain component that has the possibility ofcomposing a term.
For example, ?movableterminal?
and ?social economy?
are bothcomposed by the close related components.While, the former is a term in the domain ofinformation science and technology, and thelatter is just a common phrase instead of a term.The reason lies in that the former has the domainfeature comes from one of its components?terminal?, while the latter has not the domainfeature.We will use the above characteristic andrepresentation forms of a term to performautomatic term extraction.
The system ofautomatic term extraction includes two phases:learning stage and application stage.In the stage of learning, we use a series ofmachine learning methods to get various kindsof integrated knowledge for automatic termextraction from a large-scale corpus and a termbank.
These knowledge includes the innerstructural knowledge of terms, the statisticaldomain features of term component, thestatistical mutual information between thecomponents of terms, the outer environmentfeatures of terms and the distinct text-levelfeatures of term recognition etc...
In the stage ofapplication, through an efficient model, we useall these various types of knowledge intoautomatic term extraction.34.3 Design and implementation ofpartially analysis technologyoriented for knowledge-dense textThe knowledge-dense text fragments (includingencyclopedia and the Web text segments whosestyle is similar to encyclopedias) is relativelysimple.
Therefore, it?s possible to implementdeeper analysis on it using the natural languageprocessing technology.We use comprehensive language knowledgeand statistical technique together to designlanguage analysis method oriented forknowledge-dense text.
We will use thecomprehensive language knowledge resource,such as The Grammatical Dictionary-base ofContemporary Chinese, Chinese SemanticDictionary, Chinese Concept Dictionary (CCD),and Termbank of Information Technology,which was developed by Institute ofComputational Linguistics (ICL) of PekingUniversity.
Moreover, we will design a naturallanguage partial parsing and understandingtechnology combining statistic technology baseon the 80,000,000 words IT corpus.
Concretely,on the base of the developed software such asword segmentation, POS tagging, termextraction and identification, skeletaldependency analysis of sentence, we willcombine semantic restrict information withsyntax rules, so that during syntax analysis wecan get the semantic restrict informationbetween syntax components at the same time.We will label semantic roles for predicate-headand its central valency components usingChinese Semantic Dictionary.
So we can getshallow case frames of sentences after naturallanguage partial parsing and understanding fortext sentences.
And domain knowledge will beextracted in the later stage from this analysisresult.4.4 Establishing the basic knowledgedescription frame based on theencyclopediaThe knowledge of encyclopedia is relativelysystematic, mature and intensive.
On thisfoundation, it is easier to set up a basic domainknowledge base which includes the kernel ofdomain knowledge.
In the encyclopedia, everysubject is described by attributes, and differentsubjects are organized hierarchically.Figure1: An example of the fragments ofdomain knowledge frameworkFor example as showed in Figure1, aiming atthe subject ?Input equipment?
in the domain ofcomputer hardware, the encyclopedia describesthe basic knowledge around the subject frommany of point of views such as components,function, classification etc, which we callattributes here.
On the other hand, ?Inputequipment?, ?Output equipment?, ?Terminalunit?
constitute the subject ?computer I/Oequipment?
; furthermore, ?Input equipment?,?Computer storage equipment?, ?Networkequipment?
are also components of the?Computer hardware?.
This paper will make the?classification + Attribute?
as the basicknowledge description method for constructingthe basic domain knowledge base.
When thebasic knowledge description method is set up,we take every entry in the encyclopedia as asubject, through analyzing the correlativesentence and recognizing the key terms in theparaphrase text and the relations among theterms, we can describe the basic knowledge onthis subject.
In the next step, we may coupleseveral subjects in the same domain gradually inorder to construct the basic domain knowledgebase in this domain.4.5 Using bootstrapping method toexpand domain knowledge baseThe structure of the web text is incompact, andthe diction is not canonical enough.
However,the web text is easy to get and contains a greatamount of new knowledge.
So based on the4basic domain knowledge base, we can select theknowledge dense text fragments from the webresource as the source to acquire more newknowledge.We collect language patterns, which areknown showing some kind of domainknowledge from encyclopedia.
Using thelanguage patterns as the seed set, we could learnmore language patterns from the web text usingboot strapping machine learning method.
Usingthe expanded seed set, we could learn morelanguage patterns from the larger text.
Thistechnique can expand domain knowledge baseiteratively.The system structure is as Figure2.Figure2: The system structure for domainknowledge acquisition.4.6 Developing open platform fordomain knowledge collectingWith the rapid development of Internet, peoplecould communicate and collaborate without faceto face.
They can share work and collaboratethrough the web.
So we constructed an openhuman-computer interactive platform to call ondomain knowledge experts and spaciouscommon network users to collaborate togetherand contribute new domain knowledge.
Thisplatform could also assist the experts ofencyclopedia in editing and managing newdomain knowledge.5 Current result5.1 Automatic extraction of termsWe have exploited a term extraction system,including term extraction, human-computerinteractive updating etc.
The system is made upof basic source layer, learning layer, applicationlayer and service layer.We select the texts from 16 representativeChinese journals in the field of science andtechnology to construct the testing set.The Principles for TestingFirst of all, we manually tagged the terms in thetesting texts.
The principles we used in termtagging is very strict, that is, we only tag thelongest terms in the texts, while ignore any ofthe term fragments in a longest term.
Forexample, for the word sequence ???
??
??
(Interface Technology Specification)?, weonly select ???
??
??
(InterfaceTechnology Specification)?
as a term, whileignore ???
??
(Interface Technology?,although it may be also a term in other context.Similarly, for word sequence ???
??
??
(Digital Television Signal)?, we only select???????
(Digital Television Signal)?
asa term, while ignore ???
??
(DigitalTelevision)?.The above testing principles may result in agreat decrease of the precision and recall of termrecognition.
However, through these principles,we can find more problems existed in the termrecognition algorithm.The Testing ResultsBased on the above testing principles, we get theprecision and recall of term recognition as Table1.RECALL PRECISION THE JOURNALSOF THETESTINGTEXTS% %Semi-ConductorTechnology (1999-01)65.6 55.1Telecom Science(1998-01)52.9 60.4Computer and thePeripheralEquipments (1999-01)52.9 71.25The Research andProgress of SolidElectronics (2000-01)57.6 62.4Compute-AidedDesign and (1999-01)60.0 54.6ComputerEngineering (1999-04)65.1 73.4ComputerApplication (1999-01)57.2 68.9AutomaticMeasure andControl (1998-02)51 59.5Control Theoryand Application(1999-01)49.4 64.1Software (1998-01) 52.6 54.1Micro-Electronics(1999-01)65.6 55.0WirelessCommunicationTechnology (2000-01)57.7 69.6Remote Sensing(1999-01)67.1 62.1System Emulation(1999-01)64.9 75.4MotionalCommunication(1999-01)61 51.3Chinese CableTelevision (2000-01)60.0 57.0AVERAGE 57.8 62.2Table 1: Testing ResultThere is no unique standard for term?sdetermination.
What is a term?
What is acommon word?
What is a term fragment?
It isdifficult to give an objective and uniquestandard that is operable for computers.Therefore, what the automatic term recognitionsystem find can only be taken as the termcandidates attached with the confidences.
Westill need the human terminology experts to givea final confirmation of the terms.Our software includes human-computerinteractive updating interface besides automaticterm extraction.
The interactive updatinginterface is as Figure3:Figure3: The interactive updating interface afterterm extraction5.2 Set up the basic database ofencyclopediaA lot of key concepts in the encyclopedia arewell-marked with hyperlinks, titles, bookmarksand other Html tags according to different kindsof information respectively in the paraphrasabletext.
Using the information supplied by ?Chinaencyclopedia?
e-press, we put encyclopediasubject information, relationship betweensubjects and term hierarchy into database toform an encyclopedia database for a primarydomain knowledge base.The core structure of encyclopedia database ispresented as (main entry, relation term,relationship).
Main entry is the entry that islisted in the encyclopedia.
Relation terms are thehyperlink, bookmark, subtitle and so on.
Therelationship between main term and theseelements now is null that need to be added withhuman assistance.For example, the paraphrasable text of term?frequency divider?
is showed in the database asTable2.Main entry Relation term RelationshipFrequencydividerCrystaloscillatorUnknownFrequencydividerImpulsefrequencydividerUnknownFrequencydividerTrigger UnknownFrequency Regenerate Unknown6divider frequencydividerFrequencydividerTrigger UnknownFrequencydividerRegeneratefrequencydividerUnknownTable2: the database fragment for the term?frequency divider?5.3 Attribute relation templateextractionattribute relation type template exampledefinition xxx?/??/??/???/???/???/?
?substitutable namemarkxxx?/??/?
xxxcountry xxx???
?xxx?nationality xxx?/?
?native place or homeplace???/??
xxx/xxx?experience ???
xxx??
xxx?
?literature ??/??/??/??xxx/???
xxx/???
xxx/????
xxxworking experience xxx??
xxx?xxx??
xxx??
xxx???
xxx???
xxx????
xxx???xxx????
xxxachievement andinfluence???
xxx/?
xxx??/xxx??
?Table3: The examples of the attributerelation template of human entryWe have semi-automatically extracted severalattribute relation templates for human entriesfrom encyclopedia text.
The attribute relationtemplate of human entry examples are as Table3.5.4 Open platform for domainknowledge collectionWe design the open platform for domainknowledge collection using ASP.NET networkprogramming technology.
We establishinteractive working relation among domainknowledge engineers, domain experts andcommon users through the platform.
Thefunctions including:z Domain knowledge requirement collection:on-line collection of new term entries ofcurrent domain, which are needed by theusers.z Domain knowledge supply collection: on-line collection of more detailed attributeinformation of the new terms.z On-line management: systemadministrators manage new terminformation, which were submitted on lineby the users.The interface of the platform is as Figure4.Figure4: The interface of the open platform fordomain knowledge collection6 ConclusionThe construction of domain knowledge base is akind of high intelligent knowledge engineering.Since there is still have big gap between currentlevel of technological development and realneed, it is unrealistic to build domain knowledgebase using automatic method or manual methodonly.
However, in the human-computerinteraction process, how to sufficiently absorbthe knowledge resource which human being hasalready mastered and use it to supervise7automatic acquisition of new knowledge?
Howto call together knowledge engineers, domainexperts and common network users and realizemulti-member collaboration during the updatingand extending process of domain knowledgebase?
These are the key problems to be settled inthe knowledge engineering domain.
This papertries to do some exploration on these aspects.References[1] http://www.opencyc.org/[2] http://www.cogsci.princeton.edu/~wn[3] http://www.illc.uva.nl/EuroWordNet/[4] http://www.keenage.com[5] Yu Jiangshen, Liu Yang, Yu Shiwen, Thespecification of the Chinese Concept Dictionary,Journal of Chinese Language and Computing,Vol.13, 2003.
[6]A.Maedche, S.Staab, Semi-AutomaticEngineering of Ontologies from text, Proceedingsof International Conference on SoftwareEngineering and Knowledge Engineering (SEKE'2000), Chicago, IL, USA, 2000[7] Szpakowicz,S., Semi-automatic acquisition ofconceptual structure from technical texts,International journal of Man-machine Studies,33(4),385-397,1990[8] Biebow, B., Szulman, S., TERMINAE: alinguistic-based tool for the building of domainontology.
In Dieter fensel, Rudi Studer (eds.
),Knowledge Acquisition, Modeling andManagement, pp.49-66, 1999[9] Lapalut, S., How to handle multiple expertisefrom several experts: a general text clusteringapproach.
In F. Maurer (Ed.
), Proc.
2nd KnowledgeEngineering Forum (KEF?96), Karlsruhe, Jan.,1996.
[10] Mikheev, A., Finch, S., A workbench foracquisition of ontological knowledge from naturaltext.
In proc.
Of the 7th conference of theEuropean Chapter for Computational Linguistics(EACL?95), Dublin, Ireland, pp.
194-201, 1995[11] Richard Hull, Fernando Gomez, Automaticacquisition of biographic knowledge fromencyclopedic texts, ExpertSystems withApplications, 16(1999), pp.261-270, 1999[12] Fernando Gomez, Richard Hull, Carlos Segami,1994, Acquiring Knowledge from EncyclopedicTexts, Proceedings of the 4th ACL Conference onApplied Natural Language Processing, Stuttgart,Germany, 1994[13] Song Rou, Xu Yong, An Experiment onKnowledge Extraction from an EncyclopediaBased on Lexicon Semantics, pp.101-112, 2002[14] Gu Fang, Cao Cungen, Biological KnowledgeAcquisition from the Electronic Encyclopedia ofChina, Proceedings of ICYCS?2001, pp.1199-1203, 20018
