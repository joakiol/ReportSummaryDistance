Proceedings of the NAACL HLT Workshop on Semantic Evaluations: Recent Achievements and Future Directions, pages 19?27,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsOne Translation per DiscourseMarine CarpuatCenter for Computational Learning SystemsColumbia University475 Riverside Drive, New York, NY 10115marine@ccls.columbia.eduAbstractWe revisit the one sense per discourse hypoth-esis of Gale et al in the context of machinetranslation.
Since a given sense can be lex-icalized differently in translation, do we ob-serve one translation per discourse?
Analy-sis of manual translations reveals that the hy-pothesis still holds when using translations inparallel text as sense annotation, thus con-firming that translational differences repre-sent useful sense distinctions.
Analysis ofStatistical Machine Translation (SMT) out-put showed that despite ignoring documentstructure, the one translation per discourse hy-pothesis is strongly supported in part becauseof the low variability in SMT lexical choice.More interestingly, cases where the hypoth-esis does not hold can reveal lexical choiceerrors.
A preliminary study showed that en-forcing the one translation per discourse con-straint in SMT can potentially improve trans-lation quality, and that SMT systems mightbenefit from translating sentences within theirentire document context.1 IntroductionThe one sense per discourse hypothesis formulatedby Gale et al (1992b) has proved to be a simpleyet powerful observation and has been successfullyused in word sense disambiguation (WSD) and re-lated tasks (e.g., Yarowsky (1995); Agirre and Rigau?The author was partially funded by GALE DARPA Con-tract No.
HR0011-06-C-0023.
Any opinions, findings and con-clusions or recommendations expressed in this material arethose of the authors and do not necessarily reflect the views ofthe Defense Advanced Research Projects Agency.(1996)).
In this paper, we investigate its potentialusefulness in the context of machine translation.A growing body of work suggests that transla-tional differences represent observable sense distinc-tions that are useful in applications.
In monolin-gual WSD, word alignments in parallel corpora havebeen successfully used as learning evidence (Resnikand Yarowsky, 1999; Diab and Resnik, 2002; Nget al, 2003).
In Statistical Machine Translation(SMT), recent work shows that WSD helps trans-lation quality when the WSD system directly usestranslation candidates as sense inventories (Carpuatand Wu, 2007; Chan et al, 2007; Gime?nez andMa`rquez, 2007).In this paper, we revisit the one sense per dis-course hypothesis using word translations in paral-lel text as senses.
Our first goal is to empiricallyevaluate whether the one translation per documenthypothesis holds on French-English reference cor-pora, thus verifying whether translations exhibit thesame properties as monolingual senses.
Our secondgoal consists in evaluating whether the one trans-lation per discourse hypothesis has the potential tobe as useful to statistical machine translation as theone sense per discourse hypothesis to WSD.
Cur-rent Statistical Machine Translation (SMT) systemstranslate one sentence at a time, ignoring any docu-ment level information.
Implementing a one trans-lation per document constraint might help provideconsistency in translation for sentences drawn fromthe same document.After briefly discussing related work, we willshow that the one translation per discourse hypoth-esis holds on automatic word alignments of manu-ally translated data.
Despite ignoring any informa-tion beyond the sentential level, automatic SMT out-19put also strongly exhibits the one translation per dis-course property.
In addition, we will show that hav-ing more than one translation per discourse in SMToutput often reveals lexical choice errors, and thatenforcing the constraint might help improve overallconsistency across sentences and translation qualitythroughout documents.2 Related WorkIn the original one sense per discourse study, Galeet al (1992b) considered a sample of 9 polyse-mous English words.
A total of 5 judges wereshowed pairs of concordance lines for these wordstaken from Grolier?s Encyclopedia and asked toidentify whether they shared the same sense.
Re-sults strongly support the one sense per discoursehypothesis: 94% of polysemous words drawn fromthe same document have the same sense.
The ex-periment was replicated with the same conclusionon the Brown corpus.
Yarowsky (1995) successfullyused this observation as an approximate annotationtechnique in an unsupervised WSD model.A subsequent larger scale study of polysemybased on the WordNet sense inventory in the SEM-COR corpus does not support the hypothesis asstrongly (Krovetz, 1998).
Only 77% of ambiguouswords have a single sense per discourse.
Analysisrevealed that the one sense per discourse hypothesisis only supported for homonymous senses and notfor finer-grained sense distinction.In machine translation, discourse level informa-tion has only been indirectly used by adaptation oftranslation or language models to specific genre ortopics (e.g., Foster and Kuhn (2007); Koehn andSchroeder (2007)).
While phrase-based SMT mod-els incorporate the one sense per collocation hypoth-esis by attempting to translate phrases rather thansingle words (Koehn et al, 2007), the one sense perdiscourse hypothesis has not been explicitly used inSMT modeling.
Even the recent generation of SMTmodels that explicitly use WSD modeling to per-form lexical choice rely on sentence context ratherthan wider document context and translate sentencesin isolation (Carpuat and Wu, 2007; Chan et al,2007; Gime?nez and Ma`rquez, 2007; Stroppa et al,2007; Specia et al, 2008).
Other context-sensitiveSMT approaches (Gimpel and Smith, 2008) andglobal lexical choice models (Bangalore et al, 2007)also translate sentences independently.3 One translation per discourse inreference translationsIn this section we investigate whether the one senseper discourse hypothesis holds in translation.
Doesone sense per discourse mean one translation perdiscourse?On the one hand, one translation per discoursemight be too strict a constraint to allow for variationsin lexicalization of a given sense.
While a WSD taskproduces a set of predefined sense labels, a singlesense might be correctly translated in many differ-ent ways in a full sentence translation.On the other hand, if the author of the source lan-guage text is assumed to consistently use one senseper word per document, translators might also preferconsistent translations of the same source languageword throughout a document.
In addition, translatedtext tends to exhibit more regularities than originaltext, as shown by machine learning approches todiscriminate between ?translationese?
and originaltexts (Baroni and Bernardini, 2006) although pat-terns of syntactic regularity seemed more informa-tive than lexical choice for those experiments.3.1 Manual translation dataWe will test the one translation per discourse hy-pothesis on a corpus of French and English trans-lations, using standard freely available MT data setsand software.We use a corpus of 90 French-English news arti-cles made available for the WMT evaluations1.
Alldevelopment data that contained article boundarieswere used.
The data is split into two sets of about27k words each as described in Table 1.
The arti-cles cover topics ranging from international and lo-cal politics to sports and music.
They are drawnfrom a wide variety of newspapers and magazinesoriginally published in various European languages.As a result, even though only a single English ref-erence translation is available, it was produced byseveral different interpreters.
It would have been in-teresting to perform this analysis with multiple ref-erences, but this is unfortunately not possible with1http://www.statmt.org/wmt09/translation-task.html20Test set Language Sentences Tokens Types Singletonsno.
1French 1070 27440 5958 3727English (ref) 1070 24544 5566 3342English (SMT) 1070 24758 5075 2932no.
2French 1080 27924 6150 3839English (ref) 1080 24825 5686 3414English (SMT) 1080 25128 5240 3080Table 1: Data statistics for the bilingual corpus, including the French side, the manually translated English side (ref)and the automatic English translations (SMT)the French-English data currently available.Since golden word-alignments are not available,we automatically word align the corpus using stan-dard SMT training techniques.
Using IBM-4 align-ment models learned on the large WMT trainingcorpus (see Section 4.1 for more details), we alignGIZA++(Och and Ney, 2003) to obtain the IBM-4 alignments in both translation directions, expandtheir intersection with additional links using thegrow-diag-final-and heuristic (Koehn et al, 2007).This creates a total of 51660 alignment links, andabout 89% of French tokens are aligned to at leastone English token.
Note that all links involving stop-words are not considered for the rest of the study.3.2 One translation per discourse holdsFor every French lemma that occurs more than oncein a document, we compute the number of Englishtranslations.
In order to allow for morphological andsyntactic variations, we compute those statistics us-ing English lemmas obtained by running Treetagger(Schmid, 1994) with the standard French and En-glish parameter settings2.
A higher level of general-ization is introduced by conducting the same analy-sis using stems, which are simply defined as 4-letterprefixes.We have a total of 2316 different lemma types and6603 lemma-document pairs.
The scale of this em-pirical evaluation is much larger than in Gale et al(1992a) where only 9 target words were consideredand in Krovetz (1998) which used the entire SEM-COR corpus vocabulary.The resulting distribution of number of Englishtranslations per French word-document pair is givenin the first half of Table 2.
Remarkably, more than2http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/98% of the French lemmas are aligned to no morethan 2 English translations and 80% of French lem-mas have a single translation per document.
Whilethese numbers are not as high as the 94% agreementreported by Gale et al (1992b) in their empiricalstudy, they still strongly support the one translationper discourse hypothesis.Generalizing from lemmas to stems yields a 4.3point increase in the percentage of French lemmaswith a single translation per document.
Note thatusing stems might yield to false positives since dif-ferent words can share the same prefix, however,since we only compare words that align to the sameFrench word in a given document, the amount ofnoise introduced should be small.
Manual inspec-tion shows that this increase is often due to varia-tions in the POS of the translation, more specificallyvariations between noun and verb forms which sharethe same 4-letter prefix as can be seen in the follow-ing examples:verb vs. noun conclude vs. conclusion,investigate vs. investigation,apply vs. application, injectvs.
injection, establish vs.establishment, criticize vs.critism, recruit vs. recruitment,regulate vs. regulation3.3 Exceptions: one sense but more than onetranslation per discourseWe investigate what happens in the 15 to 20% ofcases where a French word is not consistenly trans-lated throughout a document.
Do these translationdifferences reflect sense ambiguity in French, or arethey close variations in English lexical choice?
For21reference SMTlemmas stems lemmas stems1 80.82% 85.14% 83.03% 86.38%2 17.88% 13.91% 15.43% 12.47%3 01.12% 00.95% 01.25% 00.85%4 00.18% 00.00% 00.17% 00.22%Table 2: Distribution of number of English translation perdocument using the word-aligned reference translationsand the automatic SMT translationsa given French word, how semantically similar arethe various English translations?We measure semantic similarity using the shortestpath length in WordNet (Fellbaum, 1998) as imple-mented in the WordNet Similarity package (Peder-sen et al, 2004).
The path length is defined as thenumber of WordNet nodes or synsets in a path be-tween two words: words that belong to the samesynset therefore have a shortest path length of 1,while words that are related via a common synonym,hypernym or hyponym have a shortest path length of2.
Note that this similarity metric is only defined fortwo WordNet vocabulary words of the same POS.For 57% of the French lemmas with multipletranslations, those translations can be linked by aWordNet path of no more than 4 nodes.
In 19% ofthe cases, the translations belong to the same synset,another 19% are separated by a path of length 2 only.Given that sense distinctions in WordNet are veryfine-grained, these numbers show that the transla-tions have very similar meanings.
In other words,while the one sense per translation hypothesis doesnot hold for those 57%, the one sense per discoursehypothesis still holds.Examples of those synonymous translations aregiven below:synonyms with SPL = 1 adjust and adapt,earn and gain, movie and film,education and training, holidayand daysynonyms with SPL = 2 travel andcirculate, scientist andresearcher, investigation andinquiry, leave and abandon,witness and eyewitnesssynonyms with SPL = 3 ratio andproportion, quiet and peace, planeand aircraft3.4 Exceptions: more than one sense perdiscourseAmong the words with a high WordNet path lengthor no existing path, we find translations that arenot synonyms or semantically similar words, but re-lated words sometimes with different POS.
They fallwithin two categories.The first category is that of fine-grained sense dis-tinctions for which the one sense per discourse hy-pothesis has been showed to break for monolingualWordNet sense distinctions Krovetz (1998).
How-ever, for those closely related words, it would bepossible to write correct English translations that usethe same English form throughout a document.Nationality translation Tibet vs. Tibetan,French vs. France, Paris vs.Parisian, Europe vs. European,French vs. FrenchmanAgent/entity policeman vs. police,alderman vs. cityThe second category of not identical but relatedtranslations is explained by a limitation of our ex-periment set-up: we are looking at single-wordtranslations while the translation of a longer mul-tiword phrase should be considered as a whole.
Inthe following example, the French word e?missionis aligned to both emission and greenhouse inthe same document, because French does not re-peat the long phrase e?mission de gaz a` effetde serre throughout the document, while themore concise English translation greenhouse gasemissions is used throughout:Fr apre`s la pe?riode de re?duction dese?missions [...] la Hongrie apris l?engagement de re?duire lese?missions de gaz a` effet de serrede 6 pour cent [...]En [...] to cut greenhouse gasemissions after 2012 [...]Hungary agreed to cut itsgreenhouse gas emissions by 6percent [...]Finally, there are a few rare instances where thedifferent translations for a French word reflect a22sense distinction in French and could not be cor-rectly translated in English with the same Englishword.
These are cases where both the one sense perdiscourse hypothesis and the one translation per dis-course break, and where it is not possible to para-phrase the English sentences to fullfill either con-straints.
In these instances, the French word isused in two different senses related by metonymy,but the metonymy relation does not translate intoEnglish and two non-synonym English words areused as a result.
For instance, the French wordbureau translates to both office and desk in thesame document, while retraite translates both toretirement and pension.We found a single instance where two homonymsenses of the French word coffre are in the samesentence.
This sentence seems to be a headline,which suggests that the author or translator delib-erately used the ambiguous repetition to attract theattention of the reader.Fr un coffre dans le coffreEn a trunk in the boot4 One translation per discourse in SMTWe now turn to empirically testing the one transla-tion per discourse hypothesis on automatically trans-lated text.While there is an implicit assumption that a well-written document produced by a human writer willnot introduce unncessary ambiguities, most SMTsystems translate one sentence at a time, without anymodel of discourse or document.
This might suggestthat the one translation per discourse hypothesis willnot be as strongly supported as by manual transla-tions.However, this effect might be compensated by thetendency of automatically translated text to exhibitlittle variety in lexical choice as MT systems tend toproduce very literal word for word translations.
Ascan be seen in Table 1 the reference translations usea larger vocabulary than the automatic translationsfor the same text.4.1 Automatically translated dataWe build a standard SMT system and automaticallytranslate the data set described in Section 3.1.
Westrictly follow the instructions for building a phrase-based SMT system that is close to the state-of-the-art in the WMT evaluations3, using the large trainingsets of about 460M words from Europarl and news.We use the Moses phrase-based statistical ma-chine translation system (Koehn et al, 2007) andfollow standard training, tuning and decoding strate-gies.
The translation model consists of a stan-dard Moses phrase-table with lexicalized reorder-ing.
Bidirectional GIZA++ word alignments areintersected using the grow-diag-final-and heuristic.Translations of phrases of up to 7 words long arecollected and scored with translation probilities andlexical weighting.
The English language model isa 4-gram model with Kneser-Ney smoothing, builtwith the SRI language modeling toolkit (Stolcke,2002).The word alignment between French input sen-tences and English SMT output is easily obtainedas a by-product of decoding.
We have a total of56003 alignment links, and 96% of French tokensare linked to a least one English translation.4.2 One translation per discourse holdsWe perform the same analysis as for the manualtranslations.
The distribution of the number of trans-lations for a given French word that occurs repeat-edly in a document still strongly supports the onetranslation per document hypothesis (Table 2).
Infact, SMT lexical choice seems to be more regularthan in manual translations.4.3 Exceptions: where SMT and referencedisagreeAgain, it is interesting to look at instances where thehypothesis is not verified.
We will not focus on theexceptions that fall in the categories previously ob-served in Section 3.
Instead, we take a closer lookat cases where the reference consistently uses thesame English translation, while SMT selects differ-ent translation candidates.There are cases where the SMT system arbitrar-ily chooses different synonymous translation candi-dates for the same word in different sentences.
Thisis not incorrect but will affect translation qualityas measured by automatic metrics which compare3http://www.statmt.org/wmt09/baseline.html23Test set Decoding Input METEOR BLEU NISTno.
1Moses 49.05 20.45 6.135+postprocess (transprob) 48.73 19.93 6.064+postprocess (bestmatch) 50.01 20.64 6.220+decode (transprob) 49.04 20.44 6.128+decode (bestmatch) 49.36 20.70 6.179no.
2Moses 49.60 21.10 6.211+postprocess (transprob) 49.20 20.43 6.128+postprocess (bestmatch) 50.56 21.19 6.291+decode (transprob) 49.58 21.02 6.201+decode (bestmatch) 50.60 21.21 6.243Table 3: Enforcing one translation per discourse can help METEOR, BLEU and NIST scores when using the super-vised sense disambiguation technique (bestmatch).
Relying on the unsupervised context-independent SMT translationprobabilities (transprob) does not help.matches between SMT output and manually trans-lated references.
For instance, in a single docu-ment, the French agents pathoge`nes translatesto both (1) pathogens and (2) disease-causingagents while the reference consistently translatesto pathogens.
Similarly, the French phrase parmiles de?tenus is inconsistently translated to amongdetainees and among those arrested in thesame document.Synonym translations detainees vs.arrested, apartment vs. flat,good vs. beautiful, unit vs.cellHowever, the majority of differences in trans-lation reflect lexical choice errors.
For in-stance, the French adjective biologique is in-correctly disambiguated as organic in the phrasefille biologique which should be translated asbiological daughter.SMT lexical choice errors conseiller:advisor vs. councillor,arrondissement: district vs.rounding-off, bal: ball vs.court, biologique: biological vs.organic, assurance: insurance vs.assurance, franchise: franknessvs.
deductibleWhile some of those translation distinctions canbe explained by differences in topics, all of thoseFrench words occur in a large number of documentsand cannot be disambiguated by topic alone.
Thissuggests that local sentential context is not sufficientto correctly disambiguate translation candidates.5 Detecting SMT errorsBased on the observations from the previous sec-tion, we further evaluate whether breaking the onetranslation per discourse hypothesis is indicative ofa translation error.
For this purpose, we attempt tocorrect the translations provided by the Moses SMTsystem by enforcing the one translation per dis-course constraint and evaluate the impact on trans-lation quality.5.1 Enforcing one translation per discourseIn order to get a sense of the potential impact of theone translation per discourse constraint in SMT, weattempt to enforce it using two simple postprocess-ing techniques.First, we select a set of French words whichare not consistently translated to a single Englishwords in a given document.
We apply a documentfrequency-based filter to select content words foreach document.
This yields a set of 595 French tar-get word types occurring in a total of 89 documents.Second, we propose a single English translationfor all the occurrences of the French target in adocument.
We used two different strategies: (1)the fully unsupervised strategy consists in select-ing the translation with highest probability amongthose produced by the baseline SMT system, and24Moses Young people under 25 years face various drawbacks when a contract with an assurance atan accessible price , as can be the low experience in the conduct and seniority of drivinglicences .+postprocess young people under 25 years against various drawbacks when a contract with an insuranceat an accessible price , as can be the small experience in the conduct and seniority of drivinglicences .Moses drivers the most far-sighted can opt for insurance any risk with frankness , so that they getblankets insurance to any risk but at a price more accessible .+postprocess drivers the most far-sighted can opt for insurance any risk with exemption , so that they getblankets insurance to any risk but at a price more accessible .Moses ?
These ill are isolated , nurses puts gloves rubber and masks of protection and we haveantibiotics adapted to treat them , ?
said Tibor Nyulasi .+postprocess ?
These patient are isolated , personnel puts gloves rubber and masks of protection and wehave antibiotics appropriate to treat them , ?
say Tibor Nyulasi .Moses according to the Ministry of Defence , they also served to make known to the public the realaims of the presence of the army abroad .+postprocess according to the Ministry of Defence , they also use to make known to the public the realpurpose of the presence of the army abroad .Moses the public authorities also prepare Christmas .+postprocess the public authorities also puritan Christmas .Table 4: Examples of translation improvement (bold) and degradation (italics) by enforcing the one translation perdiscourse constraint through postprocessing(2) the supervised strategy picks, among the base-line SMT translations, the one that matches the ref-erence.
Note that the supervised strategy does notpredict perfect translations, but an approximation ofthe golden translations: in addition to noise in wordalignments due to phrasal translations, the transla-tions selected are lemmas that might not be in thecorrectly inflected form for use in the full sentencetranslation.Third, we integrate the selected translation candi-dates by (1) postprocessing the baseline SMT out-put - the translations of the French target word aresimply replaced by the recommended translation,and (2) encouraging the SMT system to choose therecommended translations by annotating SMT in-put using the xml input markup scheme - again,this approach is not optimal as it introduces ad-ditional translation candidates without probabilityscores and forces single word translation to competewith phrasal translation even if they are consistent.5.2 Impact on translation qualityAs reported in Table 3, small increases in METEOR(Banerjee and Lavie, 2005), BLEU (Papineni et al,2002) and NIST scores (Doddington, 2002) suggestthat SMT output matches the references better af-ter postprocessing or decoding with the suggestedlemma translations.
Examples of both improved anddegraded lexical choice are given in Table 4.Since we are modifying translations for a limitedset of single-words only, only 10% to 30% of the testset sentences are translated differently.
We manu-ally inspected a random sample of 100 of those sen-tence pairs for two different systems: postprocess(bestmatch) and decode (bestmatch).
For each sen-tence pair, we determined whether the ?one senseper discourse?
processing improved, degraded ormade no difference in translation quality comparedto the baseline Moses output.
Among the sentencepairs where a real change in translation quality wasobserved, the postprocessing heuristic yielded im-provements in 62.5% (decode) and 64.5% (postpro-cess) of sentences considered.
For 41% (decode)and 57% (postprocess) of the sentences in the sam-25ple, changes only consisted of synonym substitution,morphological variations or local reorderings whichdid not impact translation quality.Taken together, these results suggest that the ?onesense per discourse?
constraint should be useful toSMT and that it would be worthwile to integrate itdirectly into SMT modeling.6 ConclusionWe investigated the one sense per discourse hy-pothesis (Gale et al, 1992b) in the context of ma-chine translation.
Analysis of manual translationsshowed that the hypothesis still holds when usingtranslations in parallel text as sense annotation, thusconfirming that translational differences representuseful sense distinctions.
Analysis of SMT out-put showed that despite ignoring document struc-ture, the one translation per discourse hypothesis isstrongly supported in part because of the low vari-ability in SMT lexical choice.
More interestingly,cases where the hypothesis does not hold can re-veal lexical choice errors in an unsupervised fash-ion.
A preliminary study showed that enforcingthe one translation per discourse constraint in SMTcan potentially improve translation quality, and thatSMT systems might benefit from translating sen-tences within their entire document context.In future work, we will (1) evaluate whether onetranslation per discourse holds for other languagepairs such as Arabic-English and Chinese-English,which are not as closely related as French-Englishand for which multiple reference corpora are avail-able, and (2) directly implement the one translationper discourse constraint within SMT.ReferencesEneko Agirre and German Rigau.
Word sense dis-ambiguation using conceptual density.
In Pro-ceedings of COLING?96, pages 16?22, Copen-hagen, Denmark, 1996.Satanjeev Banerjee and Alon Lavie.
METEOR:An automatic metric for MT evaluation with im-proved correlation with human judgement.
InProceedings of Workshop on Intrinsic and Extrin-sic Evaluation Measures for MT and/or Summa-rization at the 43th Annual Meeting of the Associ-ation of Computational Linguistics (ACL-2005),Ann Arbor, Michigan, June 2005.Srinivas Bangalore, Patrick Haffner, and StephanKanthak.
Statistical machine translation throughglobal lexical selection and sentence reconstruc-tion.
In Proceedings of the 45th Annual Meetingof the Association of Computational Linguistics,pages 152?159, Prague, Czech Republic, June2007.
Association for Computational Linguistics.Marco Baroni and Silvia Bernardini.
A new ap-proach to the study of translationese: Machine-learning the difference between original andtranslated text.
Literary and Linguistic Comput-ing, 21(3):259?274, 2006.Marine Carpuat and Dekai Wu.
Improving statis-tical machine translation using word sense dis-ambiguation.
In Proceedings of the 2007 JointConference on Empirical Methods in NaturalLanguage Processing and Computational Natu-ral Language Learning (EMNLP-CoNLL 2007),pages 61?72, Prague, June 2007.Yee Seng Chan, Hwee Tou Ng, and David Chi-ang.
Word sense disambiguation improves statis-tical machine translation.
In 45th Annual Meetingof the Association for Computational Linguistics(ACL-07), Prague, June 2007.Mona Diab and Philip Resnik.
An unsupervisedmethod for word sense tagging using parallel text.In Proceedings of the 40th Annual Meeting of theAssociation for Computational Linguistics, pages255?262, Philadelphia, Pennsylvania, July 2002.George Doddington.
Automatic evaluation ofmachine translation quality using n-gram co-occurrence statistics.
In Proceedings of theHuman Language Technology conference (HLT-2002), San Diego, CA, 2002.Christiane Fellbaum, editor.
WordNet: An Elec-tronic Lexical Database.
MIT Press, 1998.George Foster and Roland Kuhn.
Mixture-modeladaptation for SMT.
In Proceedings of the Sec-ond Workshop on Statistical Machine Translation,pages 128?135, Prague, Czech Republic, June2007.William A. Gale, Kenneth W. Church, and DavidYarowsky.
A method for disambiguating word26senses in a large corpus.
Computers and the Hu-manities, 26:415?439, 1992.William A. Gale, Kenneth W. Church, and DavidYarowsky.
One sense per discourse.
In Proceed-ings of the workshop on Speech and Natural Lan-guage, Harriman, NY, February 1992.Jesu?s Gime?nez and Llu?
?s Ma`rquez.
Context-awarediscriminative phrase selection for statistical ma-chine translation.
In Workshop on Statistical Ma-chine Translation, Prague, June 2007.Kevin Gimpel and Noah Smith.
Rich source-side context for statistical machine translation.In Workshop on Statistical Machine Translation,Columbus, Ohio, June 2008.Philipp Koehn and Josh Schroeder.
Experiments indomain adaptation for statistical machine transla-tion.
In Workshop on Statistical Machine Trans-lation, Prague, June 2007.Philipp Koehn, Hieu Hoang, Alexandra Birch,Chris Callison-Burch, Marcello Federico, NicolaBertoldi, Brooke Cowan, Wade Shen, ChristineMoran, Richard Zens, Chris Dyer, Ondrej Bojar,Alexandra Constantin, and Evan Herbst.
Moses:Open source toolkit for statistical machine trans-lation.
In Annual Meeting of the Association forComputational Linguistics (ACL), demonstrationsession, Prague, Czech Republic, June 2007.Robert Krovetz.
More than one sense per discourse.In NEC Princeton NJ Labs., Research Memoran-dum, 1998.Hwee Tou Ng, Bin Wang, and Yee Seng Chan.
Ex-ploiting parallel texts for word sense disambigua-tion: An empirical study.
In Proceedings of ACL-03, Sapporo, Japan, pages 455?462, 2003.Franz Josef Och and Hermann Ney.
A system-atic comparison of various statistical alignmentmodels.
Computational Linguistics, 29(1):19?52,2003.Kishore Papineni, Salim Roukos, Todd Ward, andWei-Jing Zhu.
BLEU: a method for automaticevaluation of machine translation.
In Proceedingsof the 40th Annual Meeting of the Association forComputational Linguistics, 2002.Ted Pedersen, Siddharth Patwardhan, and JasonMichelizzi.
WordNet::Similarity - Measuring therelatedness of concepts.
In Proceedings of FifthAnnual Meeting of the North American Chap-ter of the Association for Computational Linguis-tics (NAACL-04), pages 38?41, Boston, MA, May2004.Philip Resnik and David Yarowsky.
Distinguisingsystems and distinguishing senses: New evalua-tion methods for word sense disambiguation.
Nat-ural Language Engineering, 5(2):113?133, 1999.Helmut Schmid.
Probabilistic part?of?speech tag-ging using decision trees.
In Proceedings of theConference on New Methods in Language Pro-cessin, pages 44?49, Manchester, UK, 1994.Lucia Specia, Baskaran Sankaran, and Maria dasGrac?as Volpe Nunes.
n-best reranking for the ef-ficient integration of word sense disambiguationand statistical machine translation.
In Proceed-ings of the Conference on Computational Linguis-tics and Intelligent Text Processing (CICLing?08),Haifa, Israel, February 2008.Andreas Stolcke.
SRILM?an extensible languagemodeling toolkit.
In International Conference onSpoken Language Processing, Denver, Colorado,September 2002.Nicolas Stroppa, Antal van den Bosch, and AndyWay.
Exploiting source similarity for smt usingcontext-informed features.
In Proceedings of the11th Conference on Theoretical and Methodolog-ical Issues in Machine Translation (TMI 2007),Skovde, Sweden, September 2007.David Yarowsky.
Unsupervised word sense disam-biguation rivaling supervised methods.
In Pro-ceedings of the 33rd Annual Meeting of the As-sociation for Computational Linguistics, pages189?196, Cambridge, MA, 1995.27
