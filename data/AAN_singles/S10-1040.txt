Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 186?189,Uppsala, Sweden, 15-16 July 2010.c?2010 Association for Computational LinguisticsSZTERGAK : Feature Engineering for Keyphrase ExtractionG?abor BerendDepartment of InformaticsUniversity of Szeged2.
?Arp?ad t?er Szeged, H-6720, Hungaryberendg@inf.u-szeged.huRich?ard FarkasHungarian Academy of Sciences103.
Tisza Lajos k?or?utSzeged, H-6720, Hungaryrfarkas@inf.u-szeged.huAbstractAutomatically assigning keyphrases todocuments has a great variety of applica-tions.
Here we focus on the keyphraseextraction of scientific publications andpresent a novel set of features for the su-pervised learning of keyphraseness.
Al-though these features are intended for ex-tracting keyphrases from scientific papers,because of their generality and robust-ness, they should have uses in other do-mains as well.
With the help of these fea-tures SZTERGAK achieved top results onthe SemEval-2 shared task on AutomaticKeyphrase Extraction from Scientific Arti-cles and exceeded its baseline by 10%.1 IntroductionKeyphrases summarize the content of documentswith the most important phrases.
They can bevaluable in many application areas, ranging frominformation retrieval to topic detection.
However,since manually assigned keyphrases are rarely pro-vided and creating them by hand would be costlyand time-consuming, their automatic generationis of great interest nowadays.
Recent state-of-the-art systems treat this kind of task as a super-vised learning task, in which phrases of a docu-ment should be classified with respect to their keyphrase characteristics based on manually labeledcorpora and various feature values.This paper focuses on the task of keyphrase ex-traction from scientific papers and we shall intro-duce new features that can significantly improvethe overall performance.
Although the experimen-tal results presented here are solely based on sci-entific articles, due to the robustness and univer-sality of the features, our approach is expected toachieve good results when applied on other do-mains as well.2 Related workIn keyphrase extraction tasks, phrases are ex-tracted from one document that are the most char-acteristic of its content (Liu et al, 2009; Wit-ten et al, 1999).
In these approaches keyphraseextraction is treated as a classification task, inwhich certain n-grams of a specific document actas keyphrase candidates, and the task is to classifythem as proper keyphrases or not.While Frank et al (1999) exploited domain spe-cific knowledge to improve the quality of auto-matic tagging, others like Liu et al (2009) analyzeterm co-occurence graphs.
It was Nguyen and Kan(2007) who dealt with the special characteristics ofscientific papers and introduced the state-of-the-art feature set to keyphrase extraction tasks.
Herewe will follow a similar approach and make sig-nificant improvements by the introduction of novelfeatures.3 The SZTERGAK systemThe SZTERGAK framework treats the reproduc-tion of reader-assigned keyphrases as a supervisedlearning task.
In our setting a restricted set of to-ken sequences extracted from the documents wasused as classification instances.
These instanceswere ranked regarding to their posteriori proba-bilities of the keyphrase class, estimated by aNa?
?ve Bayes classifier.
Finally, we chose the top-15 candidates as keyphrases.Our features can be grouped into four main cat-egories: those that were calculated solely fromthe surface characteristics of phrases, those thattook into account the document that contained akeyphrase, those that were obtained from the givendocument set and those that were based on exter-nal sources of information.1863.1 PreprocessingSince there are parts of a document (e.g.
tablesor author affiliations) that can not really contributeto the keyphrase extractor, several preprocessingsteps were carried out.
Preprocessing included theelimination of author affiliations and messy lines.The determination of the full title of an articlewould be useful, however, it is not straightforwardbecause of multi-line titles.
To solve this prob-lem, a web query was sent with the first line ofa document and its most likely title was chosenby simply selecting the most frequently occurringone among the top 10 responses provided by theGoogle API.
This title was added to the document,and all the lines before the first occurrence of theline Abstract were omitted.Lines unlikely to contain valuable informationwere also excluded from the documents.
Theselines were identified according to statistical dataof their surface forms (e.g.
the average andthe deviation of line lengths) and regular expres-sions.
Lastly, section and sentence boundarieswere found in a rule-based way, and the POS andsyntactic tagging (using the Stanford parser (Kleinand Manning, 2003)) of each sentence were car-ried out.When syntactically parsed sentences were ob-tained, keyphrase aspirants were extracted.
The 1to 4-long token sequences that did not start or endwith a stopword and consisted only of POS-codesof an adjective, a noun or a verb were de-fined to be possible keyphrases (resulting in classi-fication instances).
Tokens of key phrase aspirantswere stemmed to store them in a uniform way, butthey were also appended by the POS-code of thederived form, so that the same root forms were dis-tinguished if they came from tokens having differ-ent POS-codes, like there shown in Table 1.Textual Appearance Canonical formregulations regul nnsRegulation regul nnregulates regul vbzregulated regul vbnTable 1: Standardization of document terms.3.2 The extended feature setThe features characterizing the extractedkeyphrase aspirants can be grouped into fourmain types, namely phrase-, document-, corpus-level and external knowledge-based features.Below we will describe the different types offeatures as well as those of KEA (Witten et al,1999) which are cited as default features by mostof the literature dealing with keyphrase extraction.3.2.1 Standard featuresFeatures belonging to this set contain those ofKEA, namely Tf-idf and the first occurrence.The Tf-idf feature assigns the tf-idf metric toeach keyphrase aspirant.The first occurrence feature contains the rela-tive first position for each keyphrase aspirant.
Thefeature value was obtained by dividing the abso-lute first token position of a phrase by the numberof tokens of the document in question.3.2.2 Phrase-level featuresFeatures belonging to this group were calcu-lated solely based on the keyphrase aspirantsthemselves.
Such features are able to get thegeneral characteristics of phrases functioning askeyphrases.Phrase length feature contains the number oftokens a keyphrase aspirant consists of.POS feature is a nominal one that storesthe POS-code sequence of each keyphrase aspi-rant.
(For example, for the phrase full JJspace NN its value was JJ NN.
)Suffix feature is a binary feature that storesinformation about whether the original form ofa keyphrase aspirant finished with some specificending according to a subset of the Michigan Suf-ficiency Exams?
Suffix List.13.2.3 Document-level featuresSince keyphrases should summarize the particulardocument they represent, and phrase-level featuresintroduced above were independent of their con-text, document-level features were also invented.Acronymity feature functions as a binary fea-ture that is assigned a true value iff a phrase islikely to be an extended form of an acronym in thesame document.
A phrase is treated as an extendedform of an acronym if it starts with the same letteras the acronym present in its document and it alsocontains all the letters of the acronym in the verysame order as they occur in the acronym.PMI feature provides a measure of the mul-tiword expression nature of multi-token phrases,1http://www.michigan-proficiency-exams.com/suffix-list.html187and it is defined in Eq.
(1), where p(ti) is thedocument-level probability of the occurrence ofith token in the phrase.
This feature value is a gen-eralized form of pointwise mutual information forphrases with an arbitrary number of tokens.pmi(t1, t2, ..., tn) =log(p(t1,t2,...,tn)p(t1)?p(t2)?...
?p(tn))log(p(t1, t2, ..., tn))n?1(1)Syntactic feature values refer to the averageminimal normalized depth of the NP-rooted parsesubtrees that contain a given keyphrase aspirant atthe leaf nodes in a given document.3.2.4 Corpus-level featuresCorpus-level features are used to determine therelative importance of keyphrase aspirants basedon a comparison of corpus-level and document-level frequencies.The sf-isf feature was created to deal with logi-cal positions of keyphrases and the formula shownin Eq.
(2) resembles that of tf-idf scores (henceits name, i.e.
Section Frequency-Inverted SectionFrequency).
This feature value favors keyphraseaspirants k that are included in several sections ofdocument d (sf ), but are present in a relativelysmall number of sections in the overall corpus(isf ).
Phrases with higher sf-isf scores for a givendocument are those that are more relevant with re-spect to that document.sfisf(k, d) = sf(k, d) ?
isf(k) (2)Keyphraseness feature is a binary one whichhas a true value iff a phrase is one of the 785 dif-ferent author-assigned keyphrases provided in thetraining and test corpora.3.2.5 External knowledge-based featuresApart from relying on the given corpus, further en-hancements in performance can be obtained by re-lying on external knowledge sources.Wikipedia-feature is assigned a true valuefor keyphrase aspirants for which there exists aWikipedia article with the same title.
Preliminaryexperiments showed that this feature is noisy, thuswe also investigated a relaxed version of it, whereoccurrences of Wikipedia article titles were lookedfor only in the title and abstract of a paper.Besides using Wikipedia for feature calculation,it was also utilized to retrieve semantic orienta-tions of phrases.
Making use of redirect links ofWikipedia, the semantic relation of synonymityFeature combinations F-scoreStandard features (SF) 14.57SF + phrase length feature 20.93SF + POS feature 19.60SF + suffix feature 16.35SF + acronymity feature 16.87SF + PMI feature 15.68SF + syntactic feature 14.20SF + sf-isf feature 14.79SF + keyphraseness feature 15.17SF + Wikipedia feature - full paper 14.37SF + Wikipedia feature - abstract 16.50SF + Wikipedia redirect 14.50Shared Task best baseline 12.87All features 23.82All features - keyphraseness excluded 22.11Table 2: Results obtained with different features.can be exploited.
For example, as there exists aredirection between Wikipedia articles XML andExtensible Markup Language, it may beassumed that these phrases mean the same.
Forthis reason during the training phase we treateda phrase equivalent to its redirected version, i.e.if there is a keyphrase aspirant that is not as-signed in the gold-standard reader annotation butthe Wikipedia article with the same title has a redi-rection to such a phrase that is present among pos-itive keyphrase instances of a particular document,the original phrase can be treated as a positive in-stance as well.
In this way the ratio of positive ex-amples could be increased from 0.99% to 1.14%.4 Results and discussionThe training and test sets of the shared task (Kimet al, 2010) consisted of 144 and 100 scien-tific publications from the ACL repository, respec-tively.
Since the primary evaluation of the sharedtask was based on the top-15 ranked automatickeyphrases compared to the keyphrases assignedby the readers of the articles, these results are re-ported here.
The evaluation results can be seen inTable 2 where the individual effect of each featureis given in combination with the standard features.It is interesting to note the improvement ob-tained by extending standard features with thesimple feature of phrase length.
This indicatesthat though the basic features were quite good,they did not take into account the point that reader188keyphrases are likely to consist of several words.Morphological features, such as POS or suffixfeatures were also among the top-performing ones,which seems to show that most of the keyphrasestend to have some common structure.
In contrast,the syntactic feature made some decrease in theperformance when it was combined just with thestandard ones.
This can be due to the fact that theinput data were quite noisy, i.e.
some inconsisten-cies arose in the data during the pdf to text con-version of articles, which made it difficult to parsesome sentences correctly.It was also interesting to see that Wikipedia fea-ture did not improve the result when it was appliedto the whole document.
However, our previous ex-periences on keyphrase extraction from scientificabstracts showed that this feature can be very use-ful.
Hence, we relaxed the feature to handle occur-rences just from the abstract.
This modification ofthe feature yielded a 14.8% improvement in the F-measure.
A possible explanation for this is thatWikipedia has articles of very common phrases(such as Calculation or Result) and the dis-tribution of such non-keyphrase terms is higher inthe body of the articles than in abstracts.The last row of Table 2 contains the resultachieved by the complete feature set excludingkeyphraseness.
As keyphraseness exploits author-assigned keyphrases and ?
to the best of ourknowledge ?
other participants of the shared taskdid not utilize author-assigned keyphrases, this re-sult is present in the final ranking of the sharedtask systems.
However, we believe that if the taskis to extract keyphrases from an article to gain se-mantic meta-data for an NLP application (e.g.
forinformation retrieval or summarization), author-assigned keyphrases are often present and can bevery useful.
This latter statement was proved byone of our experiments where we used the au-thor keyphrases assigned to the document itself asa binary feature (instead of using the pool of allkeyphrases).
This feature set could achieve an F-score of 27.44 on the evaluation set and we believethat this should be the complete feature set in areal-world semantic indexing application.5 ConclusionsIn this paper we introduced a wide set of new fea-tures that are able to enhance the overall perfor-mance of supervised keyphrase extraction applica-tions.
Our features include those calculated simplyon surface forms of keyphrase aspirants, those thatmake use of the document- and corpus-level envi-ronment of phrases and those that rely on exter-nal knowledge.
Although features were designedto the specific task of extracting keyphrases fromscientific papers, due to their generality it is highlyassumable that they can be successfully utilized ondifferent domains as well.The features we selected in SZTERGAK per-formed well enough to actually achieve thethird place on the shared task by excluding thekeyphraseness feature and would be the first byusing any author-assigned keyphrase-based fea-ture.
It is also worth emphasizing that we thinkthat there are many possibilities to further extendthe feature set (e.g.
with features that take thesemantic relatedness among keyphrase aspirantsinto account) and significant improvement couldbe achievable.AcknowledgementThe authors would like to thank the annotators ofthe shared task for the datasets used in the sharedtask.
This work was supported in part by theNKTH grant (project codename TEXTREND).ReferencesEibe Frank, Gordon W. Paynter, Ian H. Witten, CarlGutwin, and Craig G. Nevill-Manning.
1999.Domain-specific keyphrase extraction.
In Proceed-ing of 16th IJCAI, pages 668?673.Su Nam Kim, Olena Medelyan, Min-Yen Kan, andTimothy Baldwin.
2010.
Semeval-2010 task 5 : Au-tomatic keyphrase extraction from scientific articles.In Proc.
of the 5th SIGLEX Workshop on SemanticEvaluation.Dan Klein and Christopher D. Manning.
2003.
Ac-curate unlexicalized parsing.
In Proceedings of the41st Meeting of the Association for ComputationalLinguistics, pages 423?430.Zhiyuan Liu, Peng Li, Yabin Zheng, and MaosongSun.
2009.
Clustering to find exemplar terms forkeyphrase extraction.
In Proceedings of the 2009Conference on EMNLP.Thuy Dung Nguyen and Minyen Kan. 2007.Keyphrase extraction in scientific publications.
InProc.
of International Conference on Asian DigitalLibraries (ICADL 07), pages 317?326.Ian H. Witten, Gordon W. Paynter, Eibe Frank, CarlGutwin, and Craig G. Nevill-Manning.
1999.
Kea:Practical automatic keyphrase extraction.
In ACMDL, pages 254?255.189
