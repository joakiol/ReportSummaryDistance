Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 753?762,Austin, Texas, November 1-5, 2016. c?2016 Association for Computational LinguisticsFast Coupled Sequence Labeling on Heterogeneous Annotationsvia Context-aware PruningZhenghua Li, Jiayuan Chao, Min Zhang?, Jiwen YangSoochow University, Suzhou, China{zhli13,minzhang,jwyang}@suda.edu.cn, chaojiayuan.china@gmail.comAbstractThe recently proposed coupled sequence label-ing is shown to be able to effectively exploitmultiple labeled data with heterogeneous an-notations but suffer from severe inefficiencyproblem due to the large bundled tag space (Liet al, 2015).
In their case study of part-of-speech (POS) tagging, Li et al (2015) man-ually design context-free tag-to-tag mappingrules with a lot of effort to reduce the tag space.This paper proposes a context-aware prun-ing approach that performs token-wise con-straints on the tag space based on contextualevidences, making the coupled approach effi-cient enough to be applied to themore complextask of joint word segmentation (WS) andPOS tagging for the first time.
Experimentsshow that using the large-scale People Dailyas auxiliary heterogeneous data, the coupledapproach can improve F-score by 95.55 ?94.88 = 0.67% on WS, and by 90.58 ?89.49 = 1.09% on joint WS&POS on PennChinese Treebank.
All codes are released athttp://hlt.suda.edu.cn/~zhli.1 IntroductionIn statistical natural language processing, manuallylabeled data is inevitable for model supervision, butis also very expensive to build.
However, due tothe long-debated differences in underlying linguistictheories or emphasis of application, there often existmultiple labeled corpora for the same or similar tasksfollowing different annotation guidelines (Jiang et?Correspondence authorEspecially our nation economy declines .CTB ??
?/AD ?/PN ?/NN ?
?/NN ?
?/VV ?/PUPD ?
?/d ?/v ?
?/n ?
?/n ?
?/v ?/wTable 1: An example of heterogeneous annotations.al., 2009).
For instance, in Chinese language pro-cessing, Penn Chinese Treebank version 5 (CTB5) isa widely used benchmark data and contains about 20thousand sentences annotated with word boundaries,part-of-speech (POS) tags, and syntactic structures(Xue et al, 2005; Xia, 2000), whereas People?sDaily corpus (PD)1 is a large-scale corpus annotatedwithwords and POS tags, containing about 300 thou-sand sentences from the first half of 1998 of People?sDaily newspaper (Yu et al, 2003).
Table 1 gives anexample with both CTB and PD annotations.
We cansee that CTB and PD differ in both word boundarystandards and POS tag sets.Previous work on exploiting heterogeneous datamainly focuses on indirect guide-feature methods.The basic idea is to use one resource to generateextra guide features on another resource (Jiang etal., 2009; Sun and Wan, 2012), which is similar tostacked learning (Nivre and McDonald, 2008).
Liet al (2015) propose a coupled sequence labelingapproach that can directly learn and predict two het-erogeneous annotations simultaneously.
The basicidea is to transform a single-side tag into a set ofbundled tags for weak supervision based on the ideaof ambiguous labeling.
Due to the huge size of thebundled tag space, their coupled model is extremelyinefficient.
They then carefully design tag-to-tag1http://icl.pku.edu.cn/icl_groups/corpustagging.asp753mapping rules to constrain the search space.
Theircase study on POS tagging shows that the coupledmodel outperforms the guide-feature method.
How-ever, the requirement of manually designed mappingrules makes their approach less attractive, since suchmapping rules may be very difficult to construct formore complex tasks such as joint word segmentation(WS) and POS tagging.This paper proposes a context-aware pruning ap-proach that can effectively solve the inefficiencyproblem of the coupled model, making coupled se-quence labeling more generally applicable.
Specifi-cally, this work makes the following contributions:(1) We propose and systematically compare twoways for realizing context-aware pruning, i.e.,online and offline pruning.
Experiments onPOS tagging show that both online and offlinepruning can greatly improve the model effi-ciency with little accuracy loss.
(2) We for the first time apply coupled sequencelabeling to the more complex task of jointWS&POS tagging.
Experiments show thatonline pruning works badly due to the muchlarger tag set while offline pruning workswell.
Further analysis gives a clear explanationand leads to more insights in learning fromambiguous labeling.
(3) Experiments on joint WS&POS tagging showthat our coupled approach with offline pruningimproves F-score by 95.55 ?
94.88 = 0.67%onWS, and by 90.58?89.49 = 1.09% on jointWS&POS on CTB5-test over the baseline, andis also consistently better than the guide-featuremethod.2 Coupled Sequence LabelingGiven an input sequence of n tokens, denoted byx = w1...wn, coupled sequence tagging aims to si-multaneously predict two tag sequences ta = ta1...tanand tb = tb1...tbn, where tai ?
T a and tbi ?
T b(1 ?
i ?
n), and T a and T b are two differentpredefined tag sets.
Alternatively, we can view thetwo tag sequences as one bundled tag sequence t =[ta, tb] = [ta1, tb1]...[tan, tbn], where [tai , tbi ] ?
T a ?
T bis called a bundled tag.In this work, we treat CTB as the first-side anno-tation and PD as the second-side.
For POS tagging,T a is the set of POS tags in CTB, and T b is the setof POS tags in PD, and we ignore the word boundarydifferences in the two datasets, following Li et al(2015).
We have |T a| = 33 and |T b| = 38.For joint WS&POS tagging, we employ the stan-dard four-tag label set to mark word boundaries,among which B, I, E respectively represent that theconcerned character situates at the begining, inside,end position of a word, and S represents a single-character word.
Then, we concatenate word bound-ary labels with POS tags.
For instance, the firstthree characters in Table 1 correspond to ?
?/B@AD?/I@AD ?/E@AD?
in CTB, and to ?
?/B@d ?/E@d?/S@v?
in PD.
We have |T a| = 99 and |T b| = 128.2.1 Coupled Conditional Random Field (CRF)Following Li et al (2015), we build the coupledsequence labeling model based on a bigram linear-chain CRF (Lafferty et al, 2001).
The conditionalprobability of a bundled tag sequence t is:p(t|x, S?
; ?)
= eScore(x,t;?
)Z(x, S?
; ?
)Z(x, S?
; ?)
=?t?S?eScore(x,t;?
)(1)where ?
is the feature weights; Z(x, S?
; ?)
is thenormalization factor; S?
is the search space includingall legal tag sequences for x.
We use T?i ?
T a ?
T bto denote the set of all legal tags for token wi, soS?
= T?1 ?
?
?
?
?
T?n.According to the linear-chain Markovian assump-tion, the score of a bundled tag sequence is:Score(x, t; ?)
= ?
?
f(x, [ta, tb])n+1?i=1?
???
?fjoint(x, i, [tai?1, tbi?1], [tai , tbi ])fsep_a(x, i, tai?1, tai )fsep_b(x, i, tbi?1, tbi)???
(2)where f(x, [ta, tb]) is the accumulated sparse featurevector; fjoint/sep_a/sep_b(x, i, t?, t) share the same listof feature templates, and return local feature vectorsfor tagging wi?1 as t?
and wi as t.Traditional single-side tagging models can onlyexploit a single set of separate features fsep_a(.)
orfsep_b(.).
In contrast, the coupled model makes754use of all three sets of features.
Li et al (2015)demonstrate that the joint features fjoint(.)
capturethe implicit mappings between heterogeneous anno-tations, and the separate features function as back-offfeatures for alleviating the data sparseness problemof the joint features.For the feature templates, we follow Li et al(2015) and adopt those described in Zhang and Clark(2008) for POS tagging, and use those described inZhang et al (2014b) for joint WS&POS tagging.2.2 Learn from Incomplete DataThe key challenge for coupled sequence labeling isthat both CTB and PD are non-overlapping and eachcontains only one-side annotations.
Based on theidea of ambiguous labeling, Li et al (2015) firstconcatenate a single-side tag with many possiblesecond-side tags, and then use the set of bundled tagsas possibly-correct references during training.Suppose x = w1...wn is a training sentence fromCTB, and ta = t?a1...t?an is the manually labeled tagsequence.
Then we define Ti = {t?ai } ?
T b as theset of possibly-correct bundled tags, and S = T1 ??
?
?
?Tn as a exponential-size set of possibly-correctbundled tag sequences used for model supervision.Given x and the whole legal search space S?
, theprobability of the possibly-correct space S ?
S?
is:p(S|x, S?
; ?)
=?t?Vp(t|x, S?
; ?)
= Z(x,S; ?
)Z(x, S?
; ?)
(3)where Z(x,S; ?)
is analogous to Z(x, S?
; ?)
in Eq.
(3) but only sums over S.Given D = {(xj ,Sj , S?j)}Nj=1, the gradient of thelog likelihood is:?LL(D; ?)??
=?log?j p(Sj |xj , S?j ; ?)?
?=?j(?logZ(xj ,Sj ; ?)??
?
?logZ(xj , S?j ; ?)??
)=?j(Et|xj ,Sj ;?
[f(xj , t)] ?
Et|xj ,S?j ;?
[f(xj , t)])(4)where the two terms are the feature expectationsunder Sj and S?j respectively.
And the detailedderivations are as follows:?logZ(x,S; ?)?
?= 1Z(x,S; ?)
??
?t?S eScore(x,t;?)??=?t?S(eScore(x,t;?
)Z(x,S; ?)
?
?Score(x, t; ?)??
)=?t?Sp(t|x,S; ?)
?
f(x, t)=Et|x,S;?
[f(x, t)](5)Please notice that t = [ta, tb] denotes a bundledtag sequence in this context of coupled sequencelabeling.2.3 Efficiency IssueUnder complete mapping, each one-side tag ismapped to all the-other-side tags for constructingbundled tags, producing a very huge set of legalbundled tags T?i = T a ?
T b.
Using the classicForward-Backward algorithm, we still needO(n ?
|T a|2 ?
|T b|2) time complexity to computeEt|x,S?;?
[f(x, t)], which is prohibitively expensive.2In order to improve efficiency, Li et al (2015) pro-pose to use a set of context-free tag-to-tag mappingrules for reducing the search space.
For example,we may specify that the CTB POS tag ?NN?
canonly be concatenated with a set of PD tags like ?
{n,vn, ns}?.3 With much effort, they propose a setof relaxed mapping rules that greatly reduces thenumber of bundled tags from |T a| ?
|T b| = 33 ?38 = 1, 254 to 179 for POS tagging.3 Context-aware PruningUsing manually designed context-free tag-to-tagmapping rules to constrain the search space hastwo major drawbacks.
On the one hand, for morecomplex problems such as joint WS&POS tagging,it becomes very difficult to design proper mappingrules due to the much larger tag set.
On the otherhand, the experimental results in Li et al (2015)2In contrast, computingEt|x,S;?
[f(x, t)] is not the bottleneck,since |Ti| = |T b| for CTB or |Ti| = |T a| for PD.3Please refer to http://hlt.suda.edu.cn/~zhli/resources/pos-mapping-CTB-PD.html for their detailedmapping rules.755?B@ADI@AD E@AD S@PN[I@AD,E@d][I@AD,E@v][I@NN,E@d][I@NN,E@v]Bundled tags?
??
,#11%#$',#99,#$'  (#Y%#Y6#Y(#G  Figure 1: Illustration of context-aware pruning with r = 2 ona CTB training sentence.suggest that the coupled model can best learn theimplicit context-sensitive mapping relationshipsbetween annotations under complete mapping,and imposing strict tag-to-tag mapping constraintsusually hurts tagging accuracy.In this work, our intuition is that the mappingrelationships between heterogeneous annotations arehighly context-sensitive.
Therefore, we propose acontext-aware pruning approach to more accuratelycapture such mappings, thus solving the efficiencyissue.
The basic idea is to consider only a smallset of most likely bundled tags, instead of the wholebundled tag space T a ?
T b, based on evidences ofsurrounding contexts.
Specifically, for each tokenwi, we only keep r one-side tags according to sep-arate features fsep_a/b(.)
for each side, and then usethe remaining single-side tags to construct T?i and Ti.We use the second character ??/I@AD?
in Fig.1 as an example.
We list the single-side tags inthe descending order of their marginal probabilitiesaccording to fsep_a/b(.).
Then we only keep r = 2single-side tags, used as T ai and T bi .
Then T?i = T a?T b contains the four bundled tags shown in the upperbox, known as the whole possible tag set for search-ing.
And Ti = {t?a}?T b contains two bundled tags,as marked in bold, knowns as the possibly-correcttag set, since t?a is the manually labeled tag.
The casewhen the word has the second-side manually-labeledtag {t?b} can be similarly handled.Beside r, we use another hyper-parameter ?
tofurther reduce the number of one-side tag candidates.The intuition is that inmany cases, wemay only needto use a smaller number r?
< r of possible candi-dates, since the remaining tags are very unlikely onesaccording to the marginal probabilities.
Therefore,for each itemwi, we define r?
as the smallest numberpruneBaseline TaggerCTBCTB-train PD-trainCTB-dev CTB-test PD-testPD-devBaseline TaggerPDprunetrain trainn-fold: train & prune n-fold: train & pruneprunepruneFigure 2: Workflow of offline pruning.of most likely candidate tags whose accumulativeprobability is larger than ?.
Then, we only keep themin(r?, r) most likely candidate tags.We have |T?i| = r2 without considering the ac-cumulated probability threshold ?.
Thus, it requiresO(nr4) time complexity to compute Et|x,S?;?
[f(x, t)]using the Forward-Backward algorithm.In the following, we propose two ways for real-izing context-aware pruning, i.e., online and offlinepruning.
Their comparison and analysis are given inthe experiment parts.3.1 Online PruningThe online pruning approach directly uses the cou-pled model to perform pruning.
Given a sentence,we first use a subset of features fsep_a(.)
and corre-sponding feature weights trained so far to computemarginal probabilities of first-side tags, and thenanalogously process the second-side tags based onfsep_b(.).
This requires roughly the same time com-plexity as two baseline models.
Then the marginalprobabilities are used for pruning.3.2 Offline PruningThe offline pruning approach is a little bit morecomplex, and uses many additional single-side tag-ging models for pruning.
Fig.
2 shows the work-flow.
Particularly, n-fold jack-knifing is adoptedto perform pruning on the same-side training data.Finally, all training/dev/test datasets of CTB and PDare preprocessed in an offline way, so that each wordin a sentence has a set of most likely CTB tags (T ai )and another set of most likely PD tags (T bi ).4 Experiment SettingsData.
Following Li et al (2015), we use CTB5 andPD for the heterogeneous data.
Under the standard756data split of CTB5, the training/dev/test datasetscontain 16, 091/803/1, 910 sentences respectively.For PD, we use the 46, 815 sentences in January1998 as the training data, the first 2, 000 sentencesin February as the development data, and the first5, 000 sentences in June as the test data.Evaluation Metrics.
We use the standard token-wise tagging accuracy for POS tagging.
For jointWS&POS tagging, besides character-wise taggingaccuracy, we also use the standard precision (P),recall (R), and F-score of only words (WS) or POS-tagged words (WS&POS).Parameter settings.
Stochastic gradient descent(SGD) is adopted to train the baseline single-sidetagging models, the guide-feature models, and thecoupled models.4For the coupled models, we directly follow thesimple corpus-weighting strategy proposed in Li etal.
(2015) to balance the contribution of the twodatasets.
We randomly sample 5, 000 CTB-trainsentences and 5, 000 PD-train sentences, which arethen merged and shuffled for one-iteration training.After each iteration, the coupled model is evaluatedon both CTB-dev and PD-dev, providing us twosingle-side tag accuracies, one on CTB-side tags,and the other on PD-dev tags.
Another advantageof using a subset of training data in one iterationis to monitor the training progress in smaller steps.For fair comparison, when building the baselineand guide-feature models, we also randomly sample5, 000 training sentences from the whole trainingdata for one-iteration training, and then report antagging accuracy on development data.
For all mod-els, the training terminates if peak accuracies stopimproving within 30 consecutive iterations, and weuse the model that performs the best on developmentdata for final evaluation on test data.5 Experiments on POS Tagging5.1 Parameter TuningFor both online and offline pruning, we need to de-cide the maximum number of single-side tag candi-dates r and the accumulative probability threshold ?for further truncating the candidates.
Table 2 shows4We use the implementation of SGD in CRFsuite (http://www.chokkan.org/software/crfsuite/), and set b = 30as the batch-size and C = 0.1 as the regularization factor.r ?
Accuracy (%) #Tags (pruned)CTB5-dev PD-dev CTB-side PD-sideOnline Pruning2 0.98 94.25 95.03 2.0 2.04 0.98 95.06 95.66 3.9 4.08 0.98 95.14 95.83 6.3 7.416 0.98 95.12 95.81 7.8 14.18 0.90 95.15 95.79 3.7 6.38 0.95 95.13 95.82 5.1 7.18 0.99 95.15 95.74 7.4 7.98 1.00 95.15 95.76 8.0 8.0Offline Pruning8 0.9999 94.95 96.05 4.1 5.116 0.9999 95.15 96.09 5.2 7.632 0.9999 95.13 96.09 5.5 9.316 0.99 94.42 95.77 1.6 2.216 0.999 95.02 96.10 2.6 4.016 0.99999 95.10 96.09 6.8 8.9Table 2: POS tagging performance of online and offline pruningwith different r and ?
on CTB5 and PD.the tagging accuracies and the averaged numbers ofsingle-side tags for each token after pruning.The first major row tunes the two hyper-parameters for online pruning.
We first fix ?
= 0.98and increase r from 2 to 8, leading to consistentlyimproved accuracies on both CTB5-dev and PD-dev.
No further improvement is gained with r = 16,indicating that tags below the top-8 are mostly veryunlikely ones and thus insignificant for computingfeature expectations.
Then we fix r = 8 and trydifferent ?.
We find that ?
has little effect ontagging accuracies but influences the numbers ofremaining single-side tags.
We choose r = 8 and?
= 0.98 for final evaluation.The second major row tunes r and ?
for offlinepruning.
Different from online pruning, ?
has muchgreater effect on the number of remaining single-sidetags.
Under ?
= 0.9999, increasing r from 8 to 16leads to 0.20%accuracy improvement on CTB5-dev,but using r = 32 has no further gain.
Then we fixr = 16 and vary ?
from 0.99 to 0.99999.
We chooser = 16 and ?
= 0.9999 for offline pruning for finalevaluation, which leaves each word with about 5.2CTB-tags and 7.6 PD-tags on average.757Accuracy (%) SpeedCTB5-test PD-test Toks/SecCoupled (Offline) 94.83 95.90 246Coupled (Online) 94.74 95.95 365Coupled (No Prune) 94.58 95.79 3Coupled (Relaxed) 94.63 95.87 127Guide-feature 94.35 95.63 584Baseline 94.07 95.82 1573Li et al (2012b) 94.60 ?
?Table 3: POS tagging performance of difference approaches onCTB5 and PD.5.2 Main ResultsTable 3 summarizes the accuracies on the test dataand the tagging speed during the test phase.
?Cou-pled (No Prune)?
refers to the coupled model withcomplete mapping in Li et al (2015), which mapseach one-side tag to all the-other-side tags.
?Coupled(Relaxed)?
refers the coupled model with relaxedmapping in Li et al (2015), which maps a one-sidetag to a manually-designed small set of the-other-side tags.
Li et al (2012b) report the state-of-the-art accuracy on this CTB data, with a joint model ofChinese POS tagging and dependency parsing.It is clear that both online and offline pruninggreatly improve the efficiency of the coupled modelby about two magnitudes, without the need of acarefully predefined set of tag-to-tagmapping rules.5Moreover, the coupled model with offline pruningachieves 0.76% accuracy improvement on CTB5-test over the baseline model, and 0.48% over ourreimplemented guide-feature approach of Jiang et al(2009).
The gains on PD-test are marginal, possiblydue to the large size of PD-train, similar to the resultsin Li et al (2015).6 Experiments on Joint WS&POS Tagging6.1 Parameter TuningTable 4 shows results for tuning r and ?.
Fromthe results in the first major row, we can see thatin the online pruning method, ?
seems useless andr becomes the only threshold for pruning unlikelysingle-side tags.
The accuracies are much inferior to5Due to the model complexity of ?Coupled (No Prune)?, wediscard all low-frequency (< 3) features in the training data tospeed up training.
This explains why ?Coupled (No Prune)?
hasslightly lower accuracies than ?Coupled (Relaxed)?.r ?
Accuracy (%) #Tags (pruned)CTB5-dev PD-dev CTB-side PD-sideOnline Pruning8 1.00 90.41 89.91 8.0 8.016 0.95 90.65 90.22 15.9 16.016 0.99 90.77 90.49 16.0 16.016 1.00 90.79 90.49 16.0 16.0Offline Pruning8 0.995 91.22 91.62 2.6 3.116 0.995 91.66 91.85 3.2 4.332 0.995 91.67 91.87 3.5 5.616 0.95 90.69 91.30 1.6 2.116 0.99 91.64 91.92 2.5 3.516 0.999 91.62 91.75 5.1 6.4Table 4: WS&POS tagging performance of online and offlinepruning with different r and ?
on CTB5 and PD.those from the offline pruning approach.
We believethat the accuracies can be further improved withlarger r, which would nevertheless lead to severeinefficiency issue.
Based on the results, we chooser = 16 and ?
= 1.00 for final evaluation.The second major row tries to decide r and ?
forthe offline pruning approach.
Under ?
= 0.995,increasing r from 8 to 16 improves accuracies bothon CTB5-dev and PD-dev, but further using r = 32leads to little gain.
Then we fix r = 16 and vary?
from 0.95 to 0.999.
Using ?
= 0.95 leaves only1.6 CTB tags and 2.1 PD tags for each character, buthas a large accuracy drop.
We choose r = 16 and?
= 0.995 for offline pruning for final evaluation,which leaves each character with 3.2 CTB-tags and4.3 PD-tags on average.6.2 Main ResultsTable 5 summarizes the accuracies on the test dataand the tagging speed (characters per second) duringthe test phase.
?Coupled (No Prune)?
is not tried dueto the prohibitive tag set size in joint WS&POS tag-ging, and ?Coupled (Relaxed)?
is also skipped sinceit seems impossible to manually design reasonabletag-to-tag mapping rules in this case.In terms of efficiency, the coupled model withoffline pruning is on par with the baseline single-sidetagging model.66The time estimation does not include the two separateprocesses of pruning single-side tags, which is approximately758P/R/F (%) on CTB5-test P/R/F (%) on PD-test SpeedOnly WS Joint WS&POS Only WS Joint WS&POS Char/SecCoupled (Offline) 95.65/95.46/95.55 90.68/90.49/90.58 96.39/95.86/96.12 92.70/92.19/92.44 115Coupled (Online) 95.17/94.71/94.94 89.80/89.37/89.58 95.76/95.45/95.60 91.71/91.41/91.56 26Guide-feature 95.26/94.89/95.07 89.96/89.61/89.79 95.99/95.33/95.66 91.92/91.30/91.61 27Baseline 95.00/94.77/94.88 89.60/89.38/89.49 96.56/96.00/96.28 92.74/92.20/92.47 119Table 5: WS&POS tagging performance of difference approaches on CTB5 and PD.00.10.20.30.40.50.60.70.80.911 2 3 4 5 6 7 8 >8Averaged MarginalProbabilityKth-best Tagonline pruningoffline pruningFigure 3: Probability distribution with online/offline pruningfor the task of joint WS&POS.In terms of F-score, the coupled model withoffline pruning achieves 0.67% (WS) and 1.09%(WS&POS) gains on CTB5-test over the baselinemodel, and 0.48% (WS) and 0.79% (WS&POS)over our reimplemented guide-feature approachof Jiang et al (2009).
Similar to the case of POStagging, the baseline model is very competitive onPD-test due to the large scale of PD-train.6.3 AnalysisOnline vs. offline pruning.
The averaged numbersof single-side tags after pruning in Table 4 and2), suggest that the online pruning approach worksbadly in assigning proper marginal probabilities todifferent tags.
Our first guess is that in online prun-ing, the weights of separate features are optimizedas a part of the coupled model, and thus producingsomewhat flawed probabilities.
However, our fur-ther analysis gives a more convincing explanation.Fig.
3 compares the distribution of averagedprobabilities of kth-best CTB-side tags after onlineand offline pruning.
The statistics are gathered onCTB5-test.
Under online pruning, the averagedprobability of the best tag is only about 0.4, whichis surprisingly low and cannot be explained with theequal to the time of two baseline models.aforementioned improper optimization issue.
Pleasenote that both the online and offline models uses thebest choices of r and ?
based on Table 4, and aretrained until convergence.After a few trials of reducing the size of PD-trainfor training the coupled model, we realize that theunderlying reason is that ambiguous labeling makesthe probability mass more uniformly distributed,since for a PD-train sentence, the characters onlyhave the gold-standard PD-side tags, and the modelbasically uses all CTB-side tags as gold-standardanswers.
Thanks to the CTB-train sentences, themodel may be able to choose the correct tag, butinevitably becomes more indecisive at the same timedue to the PD-train sentences.In contrast, the offline pruning approach directlyuses two baseline models for pruning, which is ajob perfectly suitable for the baseline models.
Theentropy of the probability distribution for onlinepruning is about 1.524 while that for offline pruningis only 0.355.Error distributions.
To better understand thegains from the coupled approach, we show the F-score of specific POS tags for both the baselineand coupled models in Fig.
4, in the descendingorder of absolute F-score improvements.
The largestimprovement is from words tagged as ?LB?
(mostlyfor the word ??
?, marking a certain type of passiveconstruction), and the F-score increases by 65.22 ?54.55 = 10.67%.
Nearly all POS tags have moreor less F-score improvement.
Due to the spacelimit, we only show the tags with more than 2.0%improvement.
The most noticeable exception is thatF-score drops by 84.80 ?
86.49 = ?1.69% forwords tagged as ?OD?
(ordinal numbers, as opposedto cardinal numbers).In terms of words, we find the largest gain is from?????/NR?
(Luxemburgo, place name), whichappears 11 times in CTB5-test, with an absolute75950556065707580859095100LB DER SP CS DEV VE BA P VV ODF-score(%)baselinecoupledFigure 4: F-score comparison between the baseline and coupledWS&POS tagging models on different CTB POS tags.F (%) on CTB5X-testOnly WS Joint WS&POSCoupled (Offline) 98.01 94.39Guide-feature 97.96 94.06Baseline 97.37 93.23Sun and Wan (2012) ?
94.36Jiang et al (2009) 98.23 94.03Table 6: WS&POS tagging performance of difference ap-proaches on CTB5X and PD.improvement of 90.00 ?
16.67 = 73.33% in recallratio.
The reason is that PD-train contains a lot ofrelated words such as ?????
(Luxembourg, placename) and ???????
(Krayzelburg, personname) while CTB5-train has none.6.4 Comparison with Previous WorkIn order to compare with previous work, we alsorun our models on CTB5X and PD, where CTB5Xadopts a different data split of CTB5 and is widelyused in previous research on joint WS&POStagging (Jiang et al, 2009; Sun and Wan, 2012).CTB5X-dev/test only contain 352/348 sentencesrespectively.
Table 6 presents the F scores onCTB5X-test.
We can see that the coupled modelwith offline pruning achieves 0.64% (WS) and1.16% (WS&POS) F-score improvements overthe baseline model, and 0.05% (WS) and 0.33%(WS&POS) over the guide-feature approach.The original guide-feature method in Jiang et al(2009) achieves 98.23% and 94.03% F-score, whichis very close to the results of our reimplementedmodel.
The sub-word stacking approach of Sun andWan (2012) can be understood as a more complexvariant of the basic guide-feature method.7The results on both the larger CTB5-test (in Ta-ble 5) and CTB5X-test suggest that the coupledapproach is more consistent and robust than theguide-feature method.
The reason may be two-fold.
First, in the coupled approach, the model isable to actively learn the implicit mappings betweentwo sets of annotations, whereas the guide-featuremodel can only passively learn when to trust theautomatically produced tags.
Second, the coupledapproach can directly learn from both heterogeneoustraining datasets, thus covering more phenomena oflanguage usage.7 Related WorkA lot of research has been devoted to design an effec-tive way to exploit non-overlapping heterogeneouslabeled data, especially in Chinese language process-ing, where such heterogeneous resources are ubiqui-tous due to historical reasons.
Jiang et al (2009) firstpropose the guide-feature approach, which is similarto stacked learning (Nivre andMcDonald, 2008), forjoint WS&POS tagging on CTB and PD.
Sun andWan (2012) further extend the guide-feature methodand propose a more complex sub-word stacking ap-proach.
Qiu et al (2013) propose a linear coupledmodel similar to that of Li et al (2015).
The keydifference is that the model of Qiu et al (2013) onlyuses separate features, while Li et al (2015) and thiswork explore joint features as well.Li et al (2012a) apply the guide-feature idea todependency parsing on CTB and PD.
Zhang et al(2014a) extend a shift-reduce dependency parsingmodel in order to simultaneously learn and producetwo heterogeneous parse trees, which however as-sumes the existence of training data with both-sideannotations.Our context-aware pruning approach is similar tocoarse-to-fine pruning in parsing community (Kooand Collins, 2010; Rush and Petrov, 2012), which isa useful technique that allows us to use very complexparsing models without too much efficiency cost.The idea is first to use a simple and basic off-shelfmodel to prune the search space and only keep highlylikely dependency links, and then let the complex7Sun and Wan (2012) achieve 94.68% F-score on CTB5X-test by further employing a re-training strategy.760model infer in the remaining search space.
Weissand Taskar (2010) propose structured prediction cas-cades: a sequence of increasingly complex modelsthat progressively filter the space of possible outputs,and provide theoretical generalization bounds on anovel convex loss function that balances pruningerror with pruning efficiency.This work is also closely related with multi-tasklearning, which aims to jointly learn multiplerelated tasks with the benefit of using interactivefeatures under a share representation (Ben-Davidand Schuller, 2003; Ando and Zhang, 2005;Parameswaran and Weinberger, 2010).
However, asfar as we know, multi-task learning usually assumesthe existence of data with labels for multiple tasks atthe same time, which is unavailable in our scenario,making our problem more particularly difficult.Our coupled CRF model is similar to a factorialCRF (Sutton et al, 2004), in the sense that thebundled tags can be factorized into two connectedlatent variables.
Initially, factorial CRFs are de-signed to jointly model two related (and typicallyhierarchical) sequential labeling tasks, such as POStagging and chunking.
In this work, our coupledCRF model jointly handles two same tasks withdifferent annotation schemes.
Moreover, this workprovides a natural way to learn from incompleteannotations where one sentence only contains one-side labels.Learning with ambiguous labeling is previouslyexplored for classification (Jin and Ghahramani,2002), sequence labeling (Dredze et al, 2009),parsing (Riezler et al, 2002; T?ckstr?m et al,2013).
Recently, researchers propose to derivenatural annotations from web data to superviseChinese word segmentation models in the form ofambiguous labeling (Jiang et al, 2013; Liu et al,2014; Yang and Vozila, 2014).8 ConclusionThis paper proposes a context-aware pruning ap-proach for the coupled sequence labeling model ofLi et al (2015).
The basic idea is to more accuratelyconstrain the bundled tag space of a token accordingto its contexts in the sentence, instead of usingheuristic context-free tag-to-tag mapping rules inthe original work.
We propose and compare twodifferent ways of realizing pruning, i.e., online andoffline pruning.
In summary, extensive experimentsleads to the following findings.
(1) Offline pruning works well on both POS tag-ging and joint WS&POS tagging, whereas on-line pruning only works well on POS taggingbut fails on joint WS&POS tagging due to themuch larger tag set.
Further analysis showsthat the reason is that under online pruning,ambiguous labeling during training makes theprobabilities of single-side tags more evenlydistributed.
(2) In terms of tagging accuracy and F-score, thecoupled approach with offline pruning outper-forms the baseline single-side tagging model bylargemargin, and is also consistently better thanthe mainstream guide-feature method on bothPOS tagging and joint WS&POS tagging.AcknowledgmentsThe authors would like to thank the anonymousreviewers for the helpful comments.
We are verygrateful to Meishan Zhang for inspiring us to useonline pruning to improve the efficiency of the cou-pled approach.
We also thank Wenliang Chen forthe helpful discussions.
This work was supportedby National Natural Science Foundation of China(Grant No.
61525205, 61502325, 61432013).ReferencesRie Kubota Ando and Tong Zhang.
2005.
A frameworkfor learning predictive structures from multiple tasksand unlabeled data.
Journal of Machine LearnResearch, 6:1817?1853.Shai Ben-David and Reba Schuller.
2003.
Exploitingtask relatedness for multiple task learning.
In COLT.Mark Dredze, Partha Pratim Talukdar, and Koby Cram-mer.
2009.
Sequence learning from data with multiplelabels.
In ECML/PKDD Workshop on Learning fromMulti-Label Data.Wenbin Jiang, Liang Huang, and Qun Liu.
2009.
Au-tomatic adaptation of annotation standards: Chineseword segmentation and POS tagging ?
a case study.In Proceedings of ACL, pages 522?530.Wenbin Jiang, Meng Sun, Yajuan L?, Yating Yang, andQun Liu.
2013.
Discriminative learning with naturalannotations: Word segmentation as a case study.
InProceedings of ACL, pages 761?769.761Rong Jin and Zoubin Ghahramani.
2002.
Learning withmultiple labels.
In Proceedings of NIPS.Terry Koo and Michael Collins.
2010.
Efficient third-order dependency parsers.
In ACL, pages 1?11.John Lafferty, Andrew McCallum, and Fernando Pereira.2001.
Conditional random fields: Probabilistic modelsfor segmenting and labeling sequence data.
InProceedings of ICML 2001, pages 282?289.Zhenghua Li, Wanxiang Che, and Ting Liu.
2012a.Exploiting multiple treebanks for parsing with qua-sisynchronous grammar.
In ACL, pages 675?684.Zhenghua Li, Min Zhang, Wanxiang Che, and TingLiu.
2012b.
A separately passive-aggressive trainingalgorithm for joint POS tagging and dependencyparsing.
In COLING, pages 1681?1698.Zhenghua Li, Jiayuan Chao, Min Zhang, and WenliangChen.
2015.
Coupled sequence labeling onheterogeneous annotations: POS tagging as a casestudy.
In Proceedings of ACL, pages 1783?1792.Yijia Liu, Yue Zhang, Wanxiang Che, Ting Liu, andFan Wu.
2014.
Domain adaptation for CRF-basedChinese word segmentation using free annotations.
InProceedings of EMNLP, pages 864?874.Joakim Nivre and Ryan McDonald.
2008.
Integratinggraph-based and transition-based dependency parsers.In Proceedings of ACL, pages 950?958.S.
Parameswaran and K.Q.
Weinberger.
2010.
Largemargin multi-task metric learning.
In J. Lafferty,C.
K. I. Williams, J. Shawe-Taylor, R.S.
Zemel, andA.
Culotta, editors, Advances in Neural InformationProcessing Systems 23, pages 1867?1875.Xipeng Qiu, Jiayi Zhao, and Xuanjing Huang.
2013.Joint Chinese word segmentation and POS tagging onheterogeneous annotated corpora with multiple tasklearning.
In Proceedings of EMNLP, pages 658?668.Stefan Riezler, Tracy H. King, Ronald M. Kaplan,Richard Crouch, John T. III Maxwell, and MarkJohnson.
2002.
Parsing the wall street journalusing a lexical-functional grammar and discriminativeestimation techniques.
In Proceedings of ACL, pages271?278.Alexander Rush and Slav Petrov.
2012.
Vine pruningfor efficient multi-pass dependency parsing.
InProceedings of NAACL-2012, pages 498?507.Weiwei Sun and Xiaojun Wan.
2012.
Reducingapproximation and estimation errors for Chineselexical processing with heterogeneous annotations.
InProceedings of ACL, pages 232?241.Charles Sutton, Khashayar Rohanimanesh, and AndrewMcCallum.
2004.
Dynamic conditional randomfields: Factorized probabilistic models for labelingand segmenting sequence data.
In InternationalConference on Machine Learning (ICML).Oscar T?ckstr?m, Ryan McDonald, and Joakim Nivre.2013.
Target language adaptation of discriminativetransfer parsers.
In Proceedings of NAACL, pages1061?1071.DavidWeiss and Ben Taskar.
2010.
Structured predictioncascades.
In Proceedings of International Conferenceon Artificial Intelligence and Statistics (AISTATS).Fei Xia.
2000.
The part-of-speech tagging guidelines forthe penn Chinese treebank 3.0.
In Technical Report,Linguistic Data Consortium.Nianwen Xue, Fei Xia, Fu-Dong Chiou, and MarthaPalmer.
2005.
The Penn Chinese Treebank: Phrasestructure annotation of a large corpus.
In NaturalLanguage Engineering, volume 11, pages 207?238.Fan Yang and Paul Vozila.
2014.
Semi-supervisedChinese word segmentation using partial-label learn-ing with conditional random fields.
In Proceedings ofEMNLP, pages 90?98.Shiwen Yu, Huiming Duan, Xuefeng Zhu, Bin Swen,and Baobao Chang.
2003.
Specification for corpusprocessing at Peking University: Word segmentation,POS tagging and phonetic notation (In Chinese).
Jour-nal of Chinese Language and Computing, 13(2):121?158.Yue Zhang and Stephen Clark.
2008.
Joint word segmen-tation and POS tagging using a single perceptron.
InProceedings of ACL-08: HLT, pages 888?896.Meishan Zhang, Wanxiang Che, Yanqiu Shao, and TingLiu.
2014a.
Jointly or separately: Which is better forparsing heterogeneous dependencies?
In Proceedingsof COLING, pages 530?540.Meishan Zhang, Yue Zhang, Wanxiang Che, and TingLiu.
2014b.
Character-level Chinese dependencyparsing.
In Proceedings of ACL, pages 1326?1336.762
