Proceedings of the 2010 Workshop on Applications of Tree Automata in Natural Language Processing, ACL 2010, pages 19?27,Uppsala, Sweden, 16 July 2010. c?2010 Association for Computational LinguisticsParsing and Translation AlgorithmsBased on Weighted Extended Tree TransducersAndreas Maletti?Departament de Filologies Roma`niquesUniversitat Rovira i VirgiliTarragona, SpainGiorgio SattaDepartment of Information EngineeringUniversity of PaduaPadua, ItalyAbstractThis paper proposes a uniform frame-work for the development of parsing andtranslation algorithms for weighted ex-tended (top-down) tree transducers and in-put strings.
The asymptotic time complex-ity of these algorithms can be improvedin practice by exploiting an algorithm forrule factorization in the above transducers.1 IntroductionIn the field of statistical machine translation, con-siderable interest has recently been shown fortranslation models based on weighted tree trans-ducers.
In this paper we consider the so-calledweighted extended (top-down) tree transducers(WXTTs for short).
WXTTs have been proposedby Graehl and Knight (2004) and Knight (2007)and are rooted in similar devices introduced ear-lier in the formal language literature (Arnold andDauchet, 1982).WXTTs have enough expressivity to representhierarchical syntactic analyses for natural lan-guage sentences and can directly model most ofthe elementary operations that rule the processof translation between natural languages (Knight,2007).
Furthermore, the use of weights and in-ternal states allows the encoding of statistical pa-rameters that have recently been shown to be ex-tremely useful in discriminating likely translationsfrom less plausible ones.For an WXTT M , the parsing problem is tradi-tionally defined for a pair of trees t and u and re-quires as output some representation of the set ofall computations ofM that map t into u. Similarly,the translation problem forM is defined for an in-put tree t and requires as output some representa-tion of the set of all computations of M mapping t?Financially supported by the Ministerio de Educacio?n yCiencia (MEC) grant JDCI-2007-760.into any other tree.
When we deal with naturallanguage processing applications, however, pars-ing and translation are most often represented onthe basis of input strings rather than trees.
Sometricks are then applied to map the problem backto the case of input trees.
As an example in thecontext of machine translation, let w be some in-put string to be translated.
One can intermediatelyconstruct a tree automaton Mw that recognizes theset of all possible trees that have w as yield withinternal nodes from the input alphabet of M .
Thisautomaton Mw is further transformed into a treetransducer implementing a partial identity trans-lation.
This transducer is then composed with M(relational composition) to obtain a transducer thatrepresents all translations of w. This is usuallycalled the ?cascaded?
approach.In contrast with the cascaded approach above,which may be rather inefficient, we investigate amore direct technique for both parsing and transla-tion of strings based on WXTTs.
We do this by ex-tending to WXTTs the well-known BAR-HILLELconstruction defined for context-free grammars(Bar-Hillel et al, 1964) and for weighted context-free grammars (Nederhof and Satta, 2003).
Wethen derive computational complexity results forparsing and translation of input strings on the ba-sis of WXTTs.
Finally, we develop a novel fac-torization algorithm for WXTTs that, in practicalapplications, can reduce the asymptotic complex-ity for such problems.2 Preliminary definitionsLet ?
be an associative binary operation on a set S.If S contains an element 1 such that 1?s = s = s?1for every s ?
S, then (S, ?, 1) is a monoid.
Sucha monoid (S, ?, 1) is commutative if the identitys1 ?s2 = s2 ?s1 holds for all s1, s2 ?
S. A commu-tative semiring (S,+, ?, 0, 1) is an algebraic struc-ture such that:?
(S,+, 0) and (S, ?, 1) are commutative19monoids,?
?
distributes over + (from both sides), and?
s ?
0 = 0 = 0 ?
s for every s ?
S.From now on, let (S,+, ?, 0, 1) be a com-mutative semiring.
An alphabet is a finiteset of symbols.
A weighted string automa-ton [WSA] (Schu?tzenberger, 1961; Eilenberg,1974) is a system N = (P,?, J, ?, F ) where?
P and ?
are alphabets of states and inputsymbols, respectively,?
J, F : P ?
S assign initial and final weights,respectively, and?
?
: P ?
??
P ?
S assigns a weight to eachtransition.The transition weight mapping ?
can be under-stood as square matrices ?
(?, ?, ?)
?
SP?P for ev-ery ?
?
?.
The WSA N is deterministic if?
J(p) 6= 0 for at most one p ?
P and?
for every p ?
P and ?
?
?
there exists atmost one p?
?
P such that ?
(p, ?, p?)
6= 0.We now proceed with the semantics of N .
Wewill define the initial algebra semantics here; al-ternative, equivalent definitions of the semanticsexist (Sakarovitch, 2009).
Let w ?
??
be an in-put string, ?
?
?, and p, p?
?
P be two states.We extend ?
to a mapping h?
: P ?
??
?
P ?
Srecursively as follows:h?
(p, ?, p?)
={1 if p = p?0 otherwiseh?
(p, ?w, p?)
=?p???P?
(p, ?, p??)
?
h?(p?
?, w, p?)
.Consequently,h?
(p, uw, p?)
=?p???Ph?
(p, u, p??)
?
h?(p?
?, w, p?
)for all p, p?
?
P and u,w ?
??.
Then the matrixh?
(?, ?1 ?
?
?
?k, ?)
equals ?
(?, ?1, ?)
?
.
.
.
?
?
(?, ?k, ?
).Thus, if the semiring operations can be performedin constant time and access to ?
(p, ?, q) is in con-stant time for every p, q ?
P , then for everyw ?
??
we can compute the matrix h?
(?, w, ?)
intime O(|w| ?
|P |3) because it can be computed by|w| ?
1 matrix multiplications.The WSA N computes the map N : ??
?
S,which is defined for every w ?
??
by1N(w) =?p,p?
?PJ(p) ?
h?
(p, w, p?)
?
F (p?)
.1We overload the symbol N to denote both the WSA andits recognized mapping.
However, the intended meaning willalways be clear from the context.Since we will also consider individual runs,let us recall the run semantics as well.
Letw = ?1 ?
?
?
?k ?
??
be an input string of length k.Then any mapping r : [0, k] ?
P is a run of Non w, where [0, k] denotes the set of integers be-tween (inclusive) 0 and k. A run can be under-stood as a vector of states and thus we some-times write ri instead of r(i).
The weight ofsuch a run r, denoted by wtN (r), is defined bywtN (r) =?ki=1 ?
(ri?1, ?i, ri).
Thenh?
(p, w, p?)
=?r : [0,k]?Pr0=p,rk=p?wtN (r)for every p, p?
?
P and w ?
?
?.3 Weighted extended tree transducersNext, we move to tree languages, for which weneed to introduce some additional notation.
Let?
be a ranked alphabet, that is, an alphabetwhose symbols have a unique associated arity.
Wewrite ?k to denote the set of all k-ary symbolsin ?.
We use the special nullary symbol e ?
?0 tosyntactically represent the empty string ?.
The setof ?-trees indexed by a set V , denoted by T?
(V ),is the smallest set satisfying both of the followingconditions:?
for every v ?
V , the single node labeled v,written v, is a tree of T?
(V ),?
for every ?
?
?k and t1, .
.
.
, tk ?
T?
(V ),the tree with a root node labeled ?
andtrees t1, .
.
.
, tk as its k children, written?
(t1, .
.
.
, tk), belongs to T?
(V ).Throughout this paper we sometimes write ?
() asjust ?.
In the following, let t ?
T?
(V ).
The setof positions Pos(t) ?
N?
of a tree t ?
T?
(V ) isrecursively defined as follows:Pos(v) = {?
}Pos(t) = {?}
?
{iw | 1 ?
i ?
k,w ?
Pos(ti)}for every v ?
V , ?
?
?k, and t1, .
.
.
, tk ?
T?
(V )where t = ?
(t1, .
.
.
, tk).
The label of t at posi-tion w ?
Pos(t) is denoted by t(w).
The size ofthe tree t ?
T?
is defined as |t| = |Pos(t)|.
Forevery w ?
Pos(t) the subtree of t that is rootedat w is denoted by subt(w); i.e.,subt(?)
= tsub?
(t1,...,tk)(iw) = subti(w)20for every ?
?
?k, t1, .
.
.
, tk ?
T?
(V ), 1 ?
i ?
k,and w ?
Pos(ti).
Finally, the set of vari-ables var(t) is given byvar(t) = {v ?
V | ?w ?
Pos(t) : t(w) = v} .If for every v ?
var(t) there exists exactly onew ?
Pos(t) such that t(w) = v, then t is linear.We use the fixed sets X = {xi | i ?
1} andY = {yi,j | 1 ?
i < j} of formal variablesand the subsets Xk = {xi | 1 ?
i ?
k} andYk = {yi,j | 1 ?
i < j ?
k} for every k ?
0.Note thatX0 = ?.
For everyH ?
?0?X?Y , theH-yield of t is recursively defined by ydH(t) = tif t ?
H \ {e}, ydH(t) = ydH(t1) ?
?
?
ydH(tk) ift = ?
(t1, .
.
.
, tk) with ?
?
?k and k ?
1, andydH(t) = ?
otherwise.
If H = ?0 ?X ?
Y , thenwe also omit the index and just write yd(t).Let l ?
T?
(V ) and ?
: V ?
T?
(V ).
Thenl?
denotes the result obtained from l by replacingevery occurrence of v ?
V by ?(v).
The k-foldapplication is denoted by l?k.
If l?k = l?k+1 forsome k ?
0, then we denote l?k by l??.
In addi-tion, if V = Xk, then we write l[?
(x1), .
.
.
, ?
(xk)]instead of l?.
We write C?
(Xk) for the subsetof those trees of T?
(Xk) such that every vari-able of x ?
Xk occurs exactly once in it.
Givent ?
T?
(X), we write dec(t) for the set{(l, t1, .
.
.
, tk)??
?l ?
C?
(Xk), l[t1, .
.
.
, tk] = t,t1, .
.
.
, tk ?
T?
(X)}A (linear and nondeleting) weighted extended(top-down) tree transducer [WXTT] (Arnold andDauchet, 1975; Arnold and Dauchet, 1976; Lilin,1981; Arnold and Dauchet, 1982; Maletti et al,2009) is a system M = (Q,?,?, I, R) where?
Q is an alphabet of states,?
?
and ?
are ranked alphabets of input andoutput symbols, respectively,?
I : Q?
S assigns initial weights, and?
R is a finite set of rules of the form(q, l)s?
(q1 ?
?
?
qk, r) with q, q1, .
.
.
, qk ?
Q,l ?
C?
(Xk) and r ?
C?
(Xk), and s ?
Ssuch that {l, r} 6?
X .Let us discuss the final restriction imposed onthe rules of a WXTT.
Essentially, it disallows rulesof the form (q, x1)s?
(q?, x1) with q, q?
?
Q ands ?
S. Such pure epsilon rules only change thestate and charge a cost.
However, they can yieldinfinite derivations (and with it infinite productsand sums) and are not needed in our applications.The WXTT M is standard if ydX(r) = x1 ?
?
?xkfor every (q, l)s?
(q1 ?
?
?
qk, r) ?
R. This restric-tion enforces that the order of the variables is fixedon the right-hand side r, but since the order is ar-bitrary in the left-hand side l (and the names of thevariables are inconsequential), it can be achievedeasily without loss of generality.
If there are sev-eral rules that differ only in the naming of the vari-ables, then their weights should be added to obtaina single standard rule.
To keep the presentationsimple, we also construct nonstandard WXTTs inthe sequel.
However, we implicitly assume thatthose are converted into standard WXTTs.The semantics of a standard WXTT is in-spired by the initial-algebra semantics for classi-cal weighted top-down and bottom-up tree trans-ducers (Fu?lo?p and Vogler, 2009) [also called top-down and bottom-up tree series transducers by En-gelfriet et al (2002)].
Note that our semanticsis equivalent to the classical term rewriting se-mantics, which is presented by Graehl and Knight(2004) and Graehl et al (2008), for example.
Infact, we will present an equivalent semantics basedon runs later.
Let M = (Q,?,?, I, R) be aWXTT.
We present a definition that is more gen-eral than immediately necessary, but the general-ization will be useful later on.
For every n ?
N,p1, .
.
.
, pn ?
Q, and L ?
R, we define themapping hp1??
?pnL : T?
(Xn) ?
T?
(Xn) ?
SQ byhp1??
?pnL (xi, xi)pi = 1 for every 1 ?
i ?
n andhp1??
?pnL (t, u)q=?(l,t1,...,tk)?dec(t)(r,u1,...,uk)?dec(u)(q,l)s?(q1??
?qk,r)?Ls ?k?i=1hp1??
?pnL (ti, ui)qi (1)for all remaining t ?
T?
(Xn), u ?
T?
(Xn), andq ?
Q.
Note that for each nonzero summand in (1)one of the decompositions dec(t) and dec(u) mustbe proper (i.e., either l /?
X or r /?
X).
Thisimmediately yields that the sum is finite and therecursion well-defined.
The transformation com-puted by M , also denoted by M , is the map-ping M : T?
?
T?
?
S, which is defined byM(t, u) =?q?Q I(q)?hR(t, u)q for every t ?
T?and u ?
T?.Let us also introduce a run semantics for theWXTT (Q,?,?, I, R).
The rank of a rule?
= (q, l)s?
(q1 ?
?
?
qk, r) ?
R, denoted by rk(?
),is rk(?)
= k. This turns R into a ranked alphabet.The input state of ?
is in(?)
= q, the ith outputstate is outi(?)
= qi for every 1 ?
i ?
k, and21the weight of ?
is wt(?)
= s. A tree r ?
TR(X)is called run if in(r(wi)) = outi(r(w)) for everywi ?
Pos(r) and 1 ?
i ?
rk(r(w)) such thatr(wi) ?
R. The weight of a run r ?
TR(X) iswt(r) =?w?Pos(r),r(w)?Rwt(r(w)) .The evaluation mappings pi1 : TR(X) ?
T?
(X)and pi2 : TR(X) ?
T?
(X) are defined for everyx ?
X , ?
= (q, l)s?
(q1 ?
?
?
qk, r) ?
R, andr1, .
.
.
, rk ?
TR(X) by pi1(x) = x, pi2(x) = x,andpi1(?
(r1, .
.
.
, rk)) = l[pi1(r1), .
.
.
, pi1(rk)]pi2(?
(r1, .
.
.
, rk)) = r[pi2(r1), .
.
.
, pi2(rk)] .We obtain the weighted tree transformation for ev-ery t ?
T?
and u ?
T?
as follows2M(t, u) =?run r?TRt=pi1(r),u=pi2(r)I(in(r(?)))
?
wt(r) .This approach is also called the bimorphism ap-proach (Arnold and Dauchet, 1982) to tree trans-formations.4 Input and output restrictions of WXTTIn this section we will discuss the BAR-HILLELconstruction for the input and the output part of aWXTT M .
This construction essentially restrictsthe input or output of the WXTT M to the stringlanguage recognized by a WSA N .
Contrary to(direct or inverse) application, this constructionis supposed to yield another WXTT.
More pre-cisely, the constructed WXTT should assign toeach translation (t, u) the weight assigned to itby M multiplied by the weight assigned by Nto the yield of t (or u if the output is restricted).Since our WXTTs are symmetric, we will actu-ally only need one construction.
Let us quicklyestablish the mentioned symmetry statement.
Es-sentially we just have to exchange left- and right-hand sides and redistribute the states in those left-and right-hand sides accordingly.From now on, let M = (Q,?,?, I, R) be aWXTT.Theorem 1.
There exists a WXTT M ?
such thatM ?
(u, t) = M(t, u) for every t ?
T?
and u ?
T?.2We immediately also use M for the run semantics be-cause the two semantics trivially coincide.Proof.
Let M ?
= (Q,?,?, I, R?)
be the WXTTsuch thatR?
= {(q, r)s?
(w, l) | (q, l)s?
(w, r) ?
R} .It should be clear that M ?
(u, t) = M(t, u) for ev-ery t ?
T?
and u ?
T?.With the symmetry established, we now onlyneed to present the BAR-HILLEL construction foreither the input or output side.
Without loss ofgenerality, let us assume that M is standard.
Wethen choose the output side here because the orderof variables is fixed in it.
Note that we sometimesuse the angled parentheses ???
and ???
instead ofparentheses for clarity.Definition 2.
Let N = (P,?, J, ?, F ) be a WSAwith ?
= ?0 \ {e}.
We construct the output prod-uct Prod(M,N) = (P?Q?P,?,?, I ?, R?)
suchthat?
I ?
(?p, q, p??)
= J(p) ?
I(q) ?
F (p?)
for everyp, p?
?
P and q ?
Q,?
for every rule (q, l)s?
(q1 ?
?
?
qk, r) ?
R andevery p0, .
.
.
, pk, p?0, .
.
.
, p?k ?
P , let(q?, l)s?s0?...?sk??????
(q?1 ?
?
?
q?k, r) ?
R?where?
q?
= ?p0, q, p?k?,?
q?i = ?p?i?1, qi, pi?
for every 1 ?
i ?
k,?
yd(r) = w0x1w1 ?
?
?wk?1xkwk withw0, .
.
.
, wk ?
?
?, and?
si = h?
(pi, wi, p?i) for every 0 ?
i ?
k.Let ?
= (q, l)s?
(q1 ?
?
?
qk, r) ?
R. Thesize of ?
is |?| = |l| + |r|.
The size andrank of the WXTT M are |M | =??
?R|?|and rk(M) = max?
?R rk(?
), respectively.
Fi-nally, the maximal output yield length of M , de-noted by len(M), is the maximal length of yd(r)for all rules (q, l)s?
(q1 ?
?
?
qk, r) ?
R.The size and rank of Prod(M,N) are inO(|M | ?
|P |2 rk(M)+2) and rk(M), respec-tively.
We can compute Prod(M,N) in timeO(|R| ?
len(M) ?
|P |2 rk(M)+5).
If N is de-terministic, then the size of Prod(M,N) isin O(|M | ?
|P |rk(M)+1) and the required time isinO(|R| ?
len(M) ?
|P |rk(M)+1).
Next, let us provethat our BAR-HILLEL construction is actually cor-rect.Theorem 3.
Let M and N be as in Defini-tion 2, and let M ?
= Prod(M,N).
ThenM ?
(t, u) = M(t, u) ?N(yd(u)) for every t ?
T?and u ?
T?.22Proof.
Let M ?
= (Q?,?,?, I ?, R?).
First, a sim-ple proof shows thathR?
(t, u)?p,q,p??
= hR(t, u)q ?
h?
(p, yd(u), p?
)for every t ?
T?, u ?
T?, q ?
Q, and p, p?
?
P .Now we can prove the main statement as follows:M ?
(t, u)=?q?
?Q?I ?(q?)
?
hR?
(t, u)q?=?p,p?
?Pq?QI ?
(?p, q, p??)
?
hR(t, u)q ?
h?
(p, yd(u), p?
)= M(t, u) ?N(yd(u))for every t ?
T?
and u ?
T?.Note that the typical property of many BAR-HILLEL constructions, namely that a run of Mand a run of N uniquely determine a runof Prod(M,N) and vice versa, does not hold forour construction.
In fact, a run of M and a runof N uniquely determine a run of Prod(M,N),but the converse does not hold.
We could modifythe construction to enable this property at the ex-pense of an exponential increase in the number ofstates of Prod(M,N).
However, since those re-lations are important for our applications, we ex-plore the relation between runs in some detail here.To simplify the discussion, we assume, withoutloss of generality, that M is standard and s = s?for every two rules (q, l)s?
(w, r) ?
R and(q, l)s??
(w, r) ?
R. Moreover, we assume thesymbols of Definition 2.
For every r?
?
TR?
(X),we let base(r?)
denote the run obtained from r?
byreplacing each symbol(q?, l)s?s0?...?sk??????
(q?1 ?
?
?
q?k, r)by just (q, l)s?
(q1 ?
?
?
qk, r) ?
R. Thus, we re-place a rule (which is a symbol) of R?
by the un-derlying rule of R. We start with a general lemma,which we believe to be self-evident.Lemma 4.
Let r?
?
TR?
and n = |yd(pi2(r?
))|.Then wtM ?(r?)
= wtM (base(r?))??r?R??
wtN (r)where R??
is a nonempty subset of{r : [0, n]?
P | in(r?(?))
= ?r0, q, rn?
}.Let us assume that N is trim (i.e., all states arereachable and co-reachable) and unambiguous.
Inthis case, for every ?1 ?
?
?
?k ?
??
and p, p?
?
Pthere is at most one successful run r : [0, k] ?
Psuch that?
?
(ri?1, ?i, ri) 6= 0 for every 1 ?
i ?
k, and?
r0 = p and rk = p?.This immediately yields the following corollary.Corollary 5 (of Lemma 4).
Let N be trim andunambiguous.
For every r?
?
TR?
we havewtM ?(r?)
= wtM (base(r?))
?
wtN (r)for some r : [0, n]?
P with n = |yd(pi2(r?
))|.We now turn to applications of the product con-struction.
We first consider the translation prob-lem for an input string w and a WXTTM .
We canrepresent w as a trim and unambiguous WSA Nwthat recognizes the language {w} with weightof 1 on each transition (which amounts to ignor-ing the weight contribution of Nw).
Then the in-put product transducer Mw = Prod(Nw,M) pro-vides a compact representation of the set of allcomputations of M that translate the string w.From Corollary 5 we have that the weights ofthese computations are also preserved.
Thus,Mw(T?
?
T?)
=?(t,u)?T?
?T?Mw(t, u) is theweight of the set of string translations of w.As usual in natural language processing ap-plications, we can exploit appropriate semiringsand compute several useful statistical parametersthrough Mw(T?
?
T?
), as for instance the high-est weight of a computation, the inside probabil-ity and the rule expectations; see (Li and Eisner,2009) for further discussion.One could also construct in linear time the rangetree automaton for Mw, which can be interpretedas a parsing forest with all the weighted trees as-signed to translations of w under M .
If we fur-ther assume thatM is unambiguous, thenMw willalso have this property, and we can apply standardtechniques to extract from Mw the highest scorecomputation.
In machine translation applications,the unambiguity assumption is usually met, andavoids the so-called ?spurious?
ambiguity, that is,having several computations for an individual pairof trees.The parsing problem for input strings w and ucan be treated in a similar way, by restricting Mboth to the left and to the right.5 Rule factorizationAs already discussed, the time complexity of theproduct construction is an exponential functionof the rank of the transducer.
Unfortunately,it is not possible in the general case to cast a23WXTT into a normal form such that the rank isbounded by some constant.
This is also expectedfrom the fact that the translation problem for sub-classes of WXTTs such as synchronous context-free grammars is NP-hard (Satta and Peserico,2005).
Nonetheless, there are cases in which arank reduction is possible, which might result inan improvement of the asymptotical run-time ofour construction.Following the above line, we present here alinear time algorithm for reducing the rank of aWXTT under certain conditions.
Similar algo-rithms for tree-based transformation devices havebeen discussed in the literature.
Nesson et al(2008) consider synchronous tree adjoining gram-mars; their algorithm is conceptually very sim-ilar to ours, but computationally more demand-ing due to the treatment of adjunction.
Follow-ing that work, we also demand here that the newWXTT ?preserves?
the recursive structure of theinput WXTT, as formalized below.
Galley et al(2004) algorithm also behaves in linear time, butdeals with the different problem of tree to stringtranslation.
Rank reduction algorithms for string-based translation devices have also been discussedby Zhang et al (2006) and Gildea et al (2006).Recall that M = (Q,?,?, I, R) is a standardWXTT.
Let M ?
= (Q?,?,?, I ?, R?)
be a WXTTwith Q ?
Q?.3 Then M ?
is a structure-preservingfactorization of M if?
I ?
(q) = I(q) for every q ?
Q and I ?
(q) = 0otherwise, and?
hp1???pnR?
(t, u)q = hp1??
?pnR (t, u)q for everyq, p1, .
.
.
, pn ?
Q, t ?
T?
(Xn), andu ?
T?
(Xn).In particular, we have hR?
(t, u)q = hR(t, u)q forn = 0.
Consequently, M ?
and M are equivalentbecauseM ?
(t, u) =?q?Q?I ?
(q) ?
hR?
(t, u)q=?q?QI(q) ?
hR(t, u)q = M(t, u) .Note that the relation ?is structure-preserving fac-torization of?
is reflexive and transitive, and thus, apre-order.
Moreover, in a ring (actually, additivelycancellative semirings are sufficient) it is also anti-symmetric, and consequently, a partial order.3Actually, an injective mapping Q ?
Q?
would be suffi-cient, but since the naming of the states is arbitrary, we im-mediately identify according to the injective mapping.Informally, a structure-preserving factorizationofM consists in a set of new rules that can be com-posed to provide the original rules and preservetheir weights.
We develop an algorithm for findinga structure-preserving factorization by decompos-ing each rule as much as possible.
The algorithmcan then be iterated for all the rules in the WXTT.The idea underlying our algorithm is very simple.Let ?
= (q, l)s?
(q1 ?
?
?
qk, r) ?
R be an origi-nal rule.
We look for subtrees l?
and r?
of l and r,respectively, such that var(l?)
= var(r?).
The con-dition that var(l?)
= var(r?)
is derived from thefact that hq1??
?qkR (l?, r?
)q = 0 if var(l?)
6= var(r?
).We then split ?
into two new rules by ?excis-ing?
subtrees l?
and r?
from l and r, respectively.In the remaining trees the ?excised?
trees are re-placed with some fresh variable.
The tricky partis the efficient computation of the pairs (wl, wr),since in the worst case the number of such pairsis in ?
(|l| ?
|r|), and na?
?ve testing of the conditionvar(l?)
= var(r?)
takes time O(rk(?
)).Let us start with the formal development.
Recallthe doubly-indexed set Y = {yi,j | 1 ?
i < j}.Intuitively speaking, the variable yi,j willrepresent the set {xi, .
.
.
, xj}.
With thisintuition in mind, we define the mappingvars : T?
(X ?
Y )?
N3?
as follows:vars(xi) = (i, i, 1)vars(yi,j) = (i, j, j ?
i+ 1)and vars(?
(t1, .
.
.
, tk)) is(kmin`=1vars(t`)1,kmax`=1vars(t`)2,k?`=1vars(t`)3)for every i, j ?
N with i < j, ?
?
?k, andt1, .
.
.
, tk ?
T?
(X ?
Y ).
Clearly, vars(t) canbe computed in time O(|t|), which also in-cludes the computation of vars(u) for every sub-tree u of t. In addition, vars(t)3 = |var(t)|for all linear t ?
T?(X).
Finally, ift ?
T?
(X), then vars(t)1 and vars(t)2 are theminimal and maximal index i ?
N such thatxi ?
var(t), respectively (they are ?
and 0,respectively, if var(t) = ?).
For better read-ability, we use minvar(t) and maxvar(t) forvars(t)1 and vars(t)2, respectively.Let ?
= (q, l)s?
(q1 ?
?
?
qk, r) ?
R be an origi-nal rule.
In the following, we will use minvar(t),maxvar(t), and |var(t)| freely for all subtrees tof l and r and assume that they are precomputed,24which can be done in time O(|?|).
Moreover, wewill freely use the test ?var(t) = var(u)?
for sub-trees t and u of l and r, respectively.
This test canbe performed in constant time [disregarding thetime needed to precompute vars(t) and vars(u)]by the equivalent test?
minvar(t) = minvar(u),?
maxvar(t) = maxvar(u),?
|var(t)| = maxvar(t)?minvar(t) + 1, and?
|var(u)| = maxvar(u)?minvar(u) + 1.Our factorization algorithm is presented in Al-gorithm 1.
Its first two parameters hold the left-and right-hand side (l, r), which are to be decom-posed.
The third and fourth parameter should ini-tially be x1.
To simplify the algorithm, we assumethat it is only called with left- and right-hand sidesthat (i) contain the same variables and (ii) containat least two variables.
These conditions are en-sured by the algorithm for the recursive calls.
Thealgorithm returns a decomposition of (l, r) in theform of a set D ?
T?
(X ?
Y ) ?
T?
(X ?
Y )such that var(l?)
= var(r?)
for every (l?, r?)
?
D.Moreover, all such l?
and r?
are linear.
Finally, thepairs in D can be composed (by means of point-wise substitution at the variables of Y ) to form theoriginal pair (l, r).Before we move on to formal properties of Al-gorithm 1, let us illustrate its execution on an ex-ample.Example 6.
We work with the left-hand sidel = ?
(x1, ?
(x3, x2)) and the right-hand sider = ?(?
(x1, ?(?
(x2, x3)))).
Then |var(l)| ?
2and var(l) = var(r).
Let us trace the callDECOMPOSE(l, r, x1, x1).
The condition in line 1is clearly false, so we proceed with line 3.
Thecondition is true for i = 1, so we continue withDECOMPOSE(l, ?
(x1, ?(?
(x2, x3))), x1, ?
(x1)).This time neither the condition in line 1 nor thecondition in line 3 are true.
In line 6, j is set to 1and we initialize r?1 = x1 and r?2 = ?(?
(x2, x3)).Moreover, the array h is initialized to h(1) = 1,h(2) = 2, and h(3) = 2.
Now let us discuss themain loop starting in line 12 in more detail.
First,we consider i = 1.
Since l1 = x1, the condition inline 13 is fulfilled and we set l?1 = x1 and proceedwith the next iteration (i = 2).
This time the condi-tion of line 13 is false because l2 = ?
(x3, x2) andvar(l2) = var(rh(2)) = var(r2) = {x2, x3}.
Con-sequently, j is set to 2 and l?2 = r?2 = y2,3.
Next,DECOMPOSE(?
(x3, x2), ?(?
(x2, x3)), x1, x1) isprocessed.
Let us suppose that it generates theset D. Then we returnD ?
{(?
(x1, y2,3), ?(?
(x1, y2,3)))} .Finally, let us quickly discuss how the set Dis obtained.
Since the condition in line 3 istrue, we have to evaluate the recursive callDECOMPOSE(?
(x3, x2), ?
(x2, x3), x1, ?
(x1)).Now, j = 2, h(2) = 1, and h(3) = 2.Moreover, r?1 = x2 and r?2 = x3.
In themain loop starting in line 12, the condition ofline 13 is always fulfilled, which yields thatl?1 = x3 and l?2 = x2.
Thus, we return{(?
(x3, x2), ?(?
(x2, x3)))}, which is exactly theinput because decomposition completely failed.Thus, the overall decomposition of l and r is{(?
(x1, y2,3), ?(?
(x1, y2,3))),(?
(x3, x2), ?(?
(x2, x3)))} ,which, when the second pair is substituted (point-wise) for y2,3 in the first pair, yields exactly (l, r).Informally, the rules are obtained as followsfromD.
If all variables occur in a pair (l?, r?)
?
D,then the left-hand side is assigned to the originalinput state.
Furthermore, for every variable yi,j weintroduce a new fresh state qi,j whereas the vari-able xi is associated to qi.
In this way, we deter-mine the states in the right-hand side.Formally, let ?
= (q, l)s?
(q1 ?
?
?
qk, r)be the original rule and D be the result ofDECOMPOSE(l, r, x1, x1) of Algorithm 1.
In ad-dition, for every 1 ?
i < j ?
k, let q?,i,j be a newstate such that q?,1,k = q.
LetQ??
= {q, q1, .
.
.
, qk} ?
{q?,i,j | 1 ?
i < j ?
k} .Then for every (l?, r?)
?
D we obtain the rule(q?,minvar(r?),maxvar(r?
), l?)s??
(p1 ?
?
?
pn, r?
)where ydX?Y (r?)
= z1 ?
?
?
zn,s?
={s if vars(r?
)3 = k1 otherwiseq?` ={qj if z` = xjq?,i,j if z` = yi,jfor every 1 ?
` ?
n. The rules obtained in thisfashion are collected in R?
?.4 The WXTT dec(M)is dec(M) = (Q?,?,?, I ?, R?)
where4Those rules need to be normalized to obtain a standardWXTT.25Algorithm 1 DECOMPOSE(l, r, l?, r?)
computing the decomposition of linear l ?
T?
(Xk) andr ?
T?
(Xk) with var(l) = var(r) and |var(l)| ?
2.if l = ?
(l1, .
.
.
, lm) and there exists i ?
N is such that var(li) = var(l) then2: return DECOMPOSE(li, r, l?[?
(l1, .
.
.
, li?1, x1, li+1, .
.
.
, lm)], r?
[x1])if r = ?
(r1, .
.
.
, rn) and there exists i ?
N is such that var(ri) = var(r) then4: return DECOMPOSE(l, ri, l?
[x1], r?[?
(r1, .
.
.
, ri?1, x1, ri+1, .
.
.
, rn)])let l = ?
(l1, .
.
.
, lm) and r = ?
(r1, .
.
.
, rn)6: j = minvar(r)for all 1 ?
i ?
n do8: r?i = riwhile j ?
maxvar(ri) do10: h(j) = i; j = j + 1D = ?12: for all 1 ?
i ?
m doif |var(li)| ?
1 or var(li) 6= var(rh(minvar(li))) then14: l?i = lielse16: j = h(minvar(li))l?i = r?j = yminvar(li),maxvar(li)18: D = D ?
DECOMPOSE(li, rj , x1, x1)return D ?
{(l?[?
(l?1, .
.
.
, l?m)], r?[?
(r?1, .
.
.
, r?n)])}?
Q?
= Q ????R,rk(?)?2Q??,?
I ?
(q) = I(q) for every q ?
Q and I ?
(q) = 0otherwise, and?
R?
is{?
?
R | rk(?)
< 2} ????R,rk(?)?2R??
.To measure the success of the factorization, weintroduce the following notion.
The degree of M ,denoted by deg(M), is the minimal rank of allstructure-preserving factorizations M ?
of M ; i.e.,deg(M) = minM ?
a structure-preservingfactorization of Mrk(M ?)
.Then the goal of this section is the efficient com-putation of a structure-preserving factorizationM ?of M such that rk(M ?)
= deg(M).Theorem 7.
The WXTT dec(M) is a structure-preserving factorization of M such thatrk(dec(M)) = deg(M).
Moreover, dec(M) canbe computed in time O(|M |).Proof.
Let us only discuss the run-time complex-ity shortly.
Clearly, DECOMPOSE(l, r, x1, x1)should be called once for each rule(q, l)s?
(q1 ?
?
?
qk, r) ?
R. In lines 1?4 thestructure of l and r is inspected and the prop-erties var(li) = var(l) and var(ri) = var(r)are tested in constant time.
Mind that we pre-computed vars(l) and vars(r), which can bedone in linear time in the size of the rule.
Theneach subtree ri is considered in lines 7?10 inconstant time.
Finally, we consider all direct inputsubtrees li in lines 12?18.
The tests involvingthe variables are all performed in constant timedue to the preprocessing step that computesvars(l) and vars(r).
Moreover, at most onerecursive call to DECOMPOSE is generated foreach input subtree ti.
So if we implement theunion in lines 18 and 19 by a constant-timeoperation (such as list concatenation, which canbe done since it is trivially a disjoint union), thenwe obtain the linear time-complexity.6 Concluding remarksIn this paper we have shown how to restrict com-putations of WXTTs to given input and outputWSA, and have discussed the relevance of thistechnique for parsing and translation applicationsover input strings, resulting in the computation oftranslation forests and other statistical parametersof interest.
We have also shown how to factorizetransducer rules, resulting in an asymptotic reduc-tion in the complexity for these algorithms.In machine translation applications transduc-ers usually have very large sets of rules.
Oneshould then specialize the restriction constructionin such a way that the number of useless rulesfor Prod(Nw,M) is considerably reduced, result-ing in a more efficient construction.
This can beachieved by grounding the construction of the newrules by means of specialized strategies, as usuallydone for parsing based on context-free grammars;see for instance the parsing algorithms by Younger(1967) or by Earley (1970).26ReferencesAndre?
Arnold and Max Dauchet.
1975.
Transductionsinversibles de fore?ts.
The`se 3e`me cycle M. Dauchet,Universite?
de Lille.Andre?
Arnold and Max Dauchet.
1976.
Bi-transductions de fore?ts.
In ICALP, pages 74?86.
Ed-inburgh University Press.Andre?
Arnold and Max Dauchet.
1982.
Morphismeset bimorphismes d?arbres.
Theoret.
Comput.
Sci.,20(1):33?93.Yehoshua Bar-Hillel, Micha Perles, and EliyahuShamir.
1964.
On formal properties of simplephrase structure grammars.
In Yehoshua Bar-Hillel,editor, Language and Information: Selected Essayson their Theory and Application, chapter 9, pages116?150.
Addison Wesley.Jay Earley.
1970.
An efficient context-free parsing al-gorithm.
Commun.
ACM, 13(2):94?102.Samuel Eilenberg.
1974.
Automata, Languages, andMachines, volume 59 of Pure and Applied Math.Academic Press.Joost Engelfriet, Zolta?n Fu?lo?p, and Heiko Vogler.2002.
Bottom-up and top-down tree series transfor-mations.
J. Autom.
Lang.
Combin., 7(1):11?70.Zolta?n Fu?lo?p and Heiko Vogler.
2009.
Weighted treeautomata and tree transducers.
In Manfred Droste,Werner Kuich, and Heiko Vogler, editors, Hand-book of Weighted Automata, EATCS Monographs onTheoret.
Comput.
Sci., chapter IX, pages 313?403.Springer.Michel Galley, Mark Hopkins, Kevin Knight, andDaniel Marcu.
2004.
What?s in a translation rule?In Proc.
HLT-NAACL, pages 273?280.
Associationfor Computational Linguistics.Daniel Gildea, Giorgio Satta, and Hao Zhang.
2006.Factoring synchronous grammars by sorting.
InProc.
CoLing/ACL, pages 279?286.
Association forComputational Linguistics.Jonathan Graehl and Kevin Knight.
2004.
Trainingtree transducers.
In HLT-NAACL, pages 105?112.Association for Computational Linguistics.
Seealso (Graehl et al, 2008).Jonathan Graehl, Kevin Knight, and Jonathan May.2008.
Training tree transducers.
ComputationalLinguistics, 34(3):391?427.Kevin Knight.
2007.
Capturing practical naturallanguage transformations.
Machine Translation,21(2):121?133.Zhifei Li and Jason Eisner.
2009.
First- and second-order expectation semirings with applications tominimum-risk training on translation forests.
InProc.
EMNLP, pages 40?51.
Association for Com-putational Linguistics.Eric Lilin.
1981.
Proprie?te?s de clo?ture d?une extensionde transducteurs d?arbres de?terministes.
In CAAP,volume 112 of LNCS, pages 280?289.
Springer.Andreas Maletti, Jonathan Graehl, Mark Hopkins,and Kevin Knight.
2009.
The power of ex-tended top-down tree transducers.
SIAM J. Comput.,39(2):410?430.Mark-Jan Nederhof and Giorgio Satta.
2003.
Prob-abilistic parsing as intersection.
In Proc.
IWPT,pages 137?148.
Association for Computational Lin-guistics.Rebecca Nesson, Giorgio Satta, and Stuart M. Shieber.2008.
Optimal k-arization of synchronous tree-adjoining grammar.
In Proc.
ACL, pages 604?612.Association for Computational Linguistics.Jacques Sakarovitch.
2009.
Rational and recognisablepower series.
In Manfred Droste, Werner Kuich, andHeiko Vogler, editors, Handbook of Weighted Au-tomata, EATCS Monographs on Theoret.
Comput.Sci., chapter IV, pages 105?174.
Springer.Giorgio Satta and Enoch Peserico.
2005.
Somecomputational complexity results for synchronouscontext-free grammars.
In Proc.
HLT-EMNLP,pages 803?810.
Association for Computational Lin-guistics.Marcel Paul Schu?tzenberger.
1961.
On the definitionof a family of automata.
Information and Control,4(2?3):245?270.Daniel H. Younger.
1967.
Recognition and parsing ofcontext-free languages in time n3.
Inform.
Control,10(2):189?208.Hao Zhang, Liang Huang, Daniel Gildea, and KevinKnight.
2006.
Synchronous binarization for ma-chine translation.
In Proc.
HLT-NAACL, pages 256?263.
Association for Computational Linguistics.27
