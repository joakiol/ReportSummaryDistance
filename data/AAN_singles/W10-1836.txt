Proceedings of the Fourth Linguistic Annotation Workshop, ACL 2010, pages 222?226,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsThe Revised Arabic PropBankWajdi Zaghouani?
, Mona Diab?
, Aous Mansouri?,Sameer Pradhan?
and Martha Palmer?
?Linguistic Data Consortium, ?Columbia University,?University of Colorado, ?BBN Technologieswajdiz@ldc.upenn.edu, mdiab@ccls.columbia.edu, aous.mansouri@colorado.edu,pradhan@bbn.com, martha.palmer@colorado.eduAbstractThe revised Arabic PropBank (APB) reflectsa number of changes to the data and the proc-ess of PropBanking.
Several changes stemfrom Treebank revisions.
An automatic proc-ess was put in place to map existing annota-tion to the new trees.
We have revised theoriginal 493 Frame Files from the Pilot APBand added 1462 new files for a total of 1955Frame Files with 2446 framesets.
In additionto a heightened attention to sense distinctionsthis cycle includes a greater attempt to ad-dress complicated predicates such as lightverb constructions and multi-word expres-sions.
New tools facilitate the data taggingand also simplify frame creation.1 IntroductionRecent years have witnessed a surge in availableautomated resources for the Arabic language.
1These resources can now be exploited by thecomputational linguistics community with theaim of improving the automatic processing ofArabic.
This paper discusses semantic labeling.Shallow approaches to semantic processing aremaking large advances in the direction of effi-ciently and effectively deriving application rele-vant explicit semantic information from text(Pradhan et al, 2003; Gildea and Palmer, 2002;Pradhan et al, 2004; Gildea and Jurafsky, 2002;Xue and Palmer, 2004; Chen and Rambow,2003; Carreras and Marquez, 2005; Moschitti,2004; Moschitti et al, 2005; Diab et al, 2008).Indeed, the existence of semantically annotatedresources in English such as FrameNet (Baker etal., 1998) and PropBank (Kingsbury and Palmer,2003; Palmer et al, 2005) corpora have marked asurge in efficient approaches to automatic se-1 In this paper, we use Arabic to refer to Modern StandardArabic (MSA).mantic labeling of the English language.
For ex-ample, in the English sentence, ?John enjoysmovies?, the predicate is ?enjoys?
and the firstargument, the subject, is ?John?, and the secondargument, the object, is ?movies?.
?John?
wouldbe labeled as the agent/experiencer and ?movies?would be the theme/content.
According to Prop-Bank, ?John?
is labeled Arg0 (or enjoyer) and?movies?
is labeled Arg1 (or thing enjoyed).
Cru-cially, that independent of the labeling formalismadopted, the labels do not vary in different syn-tactic constructions, which is why propositionannotation is different from syntactic Treebankannotation.
For instance, if the example abovewas in the passive voice, ?Movies are enjoyed byJohn?, ?movies?
is still the Theme/Content (Arg1)and (thing enjoyed), while ?John?
remains theAgent/Experiencer (Arg0) and (enjoyer).
Like-wise for the example ?John opened the door?
vs.?The door opened?, in both of these examples?the door?
is the Theme (Arg1).
In addition toEnglish, there are PropBank efforts in Chinese(Xue et al, 2009), Korean (Palmer et al 2006)and Hindi (Palmer et al, 2009), as well as Fra-meNet annotations in Chinese, German, Japa-nese, Spanish and other languages (Hans 2009).Being able to automatically apply this level ofanalysis to Arabic is clearly a desirable goal, andindeed, we began a pilot Arabic PropBank effortseveral years ago (Palmer et al, 2008).In this paper, we present recent work on adaptingthe original pilot Arabic Proposition Bank (APB)annotation to the recent changes that have beenmade to the Arabic Treebank (Maamouri et al,2008).
These changes have presented both lin-guistic and engineering challenges as describedin the following sections.
In Section 2 we discussmajor linguistics changes in the Arabic Treebankannotation, and any impact they might have forthe APB effort.
In Section 3 we discuss the engi-neering ramifications of adding and deletingnodes from parse trees, which necessitates mov-222ing all of the APB label pointers to new tree lo-cations.
Finally, in Section 4 we discuss the cur-rent APB annotation pipeline, which takes intoaccount all of these changes.
We conclude with astatement of our current goals for the project.2 Arabic Treebank Revision and APBThe Arabic syntactic Treebank Part 3 v3.1 wasrevised according to the new Arabic TreebankAnnotation Guidelines.
Major changes have af-fected the NP structure and the classification ofverbs with clausal arguments, as well as im-provements to the annotation in general.2The Arabic Treebank (ATB) is at the core of theAPB annotations.
The current revisions have re-sulted in a more consistent treebank that is closerin its analyses to traditional Arabic grammar.The ATB was revised for two levels of linguisticrepresentation, namely morphological informa-tion and syntactic structure.
Both of thesechanges have implications for APB annotations.The new ATB introduced more consistency inthe application of morphological features to POStags, hence almost all relevant words in the ATBhave full morphological features of number,gender, case, mood, and definiteness associatedwith them.
This more comprehensive applicationhas implications on agreement markers betweennouns and their modifiers and predicative verbsand their arguments, allowing for more consis-tent semantic analysis in the APB.In particular, the new ATB explicitly marks thegerunds in Arabic known as maSAdir (singularmaSdar.)
MaSAdirs, now annotated as VN, aretypically predicative nouns that take argumentsthat should receive semantic roles.
The nounsmarked as VN are embedded in a new kind ofsyntactic S structure headed by a VN and havingsubject and object arguments similar to verbalarguments.
This syntactic structure, namely S-NOM, was present in previous editions/versionsof the ATB but it was headed by a regular noun,hence it was difficult to find.
This explicit VNannotation allows the APB effort to take thesenew categories into account as predicates.
Forinstance [????
]VN [-??
]ARG0 [?????
?????
]ARG1,transliterated as takab~udi-,  meaning 'suffered'2 For a complete description of the new Treebank annotationguidelines, see (Arabic Treebank Morphological and Syn-tactic Annotation Guidelines 2008) athttp://projects.ldc.upenn.edu/ArabicTreebank/.is an example of predicative nominal togetherwith its semantically annotated arguments ARG0transliterated as -him, meaning 'they' and ARG1transliterated as xasA}ira kabiyrap, meaning'heavy losses'.Other changes in the ATB include idafa con-structions (a means of expressing possession)and the addition of a pseudo-verb POS tag for aparticular group of particles traditionally knownas ?the sisters of  ???
<in~a 'indeed' ?.
These havevery little impact on the APB annotation.3 Revised Treebank processingOne of the challenges that we faced during theprocess of revising the APB was the transfer ofthe already existing annotation to the newly re-vised trees -- especially since APB data encodingis tightly coupled with the explicit tree structure.Some of the ATB changes that affected APBprojection from the old pilot effort to the newtrees are listed as follows:i.
Changes to the tree structureii.
Changes to the number of tokens -- bothmodification (insertion and deletion) oftraces and modification to some tokeni-zationiii.
Changes in parts of speechiv.
Changes to sentence breaksThe APB modifications are performed within theOntoNotes project (Hovy et al 2006), we havedirect access to the OntoNotes DB Tool, whichwe extended to facilitate a smooth transition.
Thetool is modified to perform a three-step mappingprocess:a) De-reference the existing (tree) node-levelannotations to the respective token spans;b) Align the original token spans to the best pos-sible token spans in the revised trees.
This wasusually straight forward, but sometimes the to-kenization affected the boundaries of a span inwhich case careful heuristics had to be employedto find the correct mapping.
We incorporated thestandard "diff" utility into the API.
A simplespace separated token-based diff would not com-pletely align cases where the tokenization hadbeen changed in the new tree.
For these cases wehad to back-off to a character based alignment torecover the alignments.
This two-pass strategyworks better than using character-based align-223ment as a default since the diff tool does not haveany specific domain-level constraints and getsspurious alignments;c) Create the PropBank (tree) node-pointers forthe revised spans.As expected, this process is not completelyautomatic.
There are cases where we can deter-ministically transfer the annotations to the newtrees, and other cases (especially ones that in-volve decision making based on newly addedtraces) where we cannot.
We automatically trans-ferred all the annotation that could be done de-terministically, and flagged all the others for hu-man review.
These cases were grouped into mul-tiple categories for the convenience of the anno-tators.
Some of the part of speech changes in-validated some existing annotations, and creatednew predicates to annotate.
In the first case, wesimply dropped the existing annotations on theaffected nodes, and in the latter we just creatednew pointers to be annotated.
We could auto-matically map roughly 50% of the annotations.The rest are being manually reviewed.4 Annotation Tools and Pipeline4.1 Annotation processAPB consists of two major portions: the lexiconresource of Frame Files and the annotated cor-pus.
Hence, the process is divided into framingand annotation (Palmer et al, 2005).Currently, we have four linguists (framers) creat-ing predicate Frame Files.
Using the frame crea-tion tool Cornerstone, a Frame File is created fora specific lemma found in the Arabic Treebank.The information in the Frame File must includethe lemma and at least one frameset.Previously, senses were lumped together into asingle frame if they shared the same argumentstructure.
In this effort, however, we are attempt-ing to be more sensitive to the different sensesand consequently each unique sense has its ownframeset.
A frameset contains an English defini-tion, the argument structure for the frameset, aset of (parsed) Arabic examples as an illustration,and it may include Arabic synonyms to furtherhelp the annotators with sense disambiguation.Figure 1 illustrates the Frameset for the verb????? }
isotamaE 'to listen'Predicate: {isotamaE ????
?Roleset id: f1, to listenArg0: entity listeningArg1: thing listenedFigure 1.
The frameset of the verb {isotamaERel: {isotamaE, ????
?Arg0: -NONE- *Gloss: HeArg1: ???
??????
?Gloss: to their demandsExample: ?????
???
??????
?Figure 2.
An example annotation for a sentencecontaining the verb {isotamaEIn addition to the framers, we also have five na-tive Arabic speakers as annotators on the team,using the annotation tool Jubilee (described be-low).
Treebanked sentences from the ATB areclearly displayed in Jubilee, as well as the rawtext for that sentence at the bottom of the screen.The verb that needs to be tagged is clearlymarked on the tree for the annotators.
A drop-down menu is available for the annotators to useso that they may choose a particular frameset forthat specific instance.
Once a frameset is chosenthe argument structure will be displayed for themto see.
As a visual aid, the annotators may alsoclick on the ?example?
button in order to see theexamples for that particular frameset.
Finally, thecomplements of the predicate are tagged directlyon the tree, and the annotators may move on tothe next sentence.
Figure 2 illustrates a sampleannotation.Once the data has been double-blind annotated,the adjudication process begins.
An adjudicator,a member of the framing team, provides the GoldStandard annotation by going over the taggedinstances to settle any differences in the choices.Occasionally a verb will be mis-lemmatized (e.g.the instance may actually be ?????
sah~al 'to causeto become easy' but it is lemmatized under ????
?sahul-u 'to be easy' which looks identical withoutvocalization.)
At this point the lemmas are cor-rected and sent back to the annotators to tag be-fore the adjudicators can complete their work.The framers and annotators meet regularly atleast every fortnight.
These meetings are impor-tant for the framers since they may need to con-vey to the annotators any changes or issues withthe frames, syntactic matters, or anything elsethat may require extra training or preparation for224the annotators.
It is important to note that whilethe framers are linguists, the annotators are not.This means that the annotators must be instructedon a number of things including, but not limitedto, how to read trees, and what forms a constitu-ent, as well as how to get familiar with the toolsin order to start annotating the data.
Therefore,little touches, such as the addition of Arabicsynonyms to the framesets (especially since notall of the annotators have the same level of flu-ency in English), or confronting specific linguis-tic phenomena via multiple modalities are a nec-essary part of the process.
To these meetings, theannotators mostly bring their questions and con-cerns about the data they are working on.
Werely heavily on the annotator?s language skills.They take note of whether a frame appears to beincorrect, is missing an argument, or is missing asense.
And since they go through every instancein the data, annotators are instrumental for point-ing out any errors the ATB.
Since everything isdiscussed together as a group people frequentlybenefit from the conversations and issues that areraised.
These bi-monthly meetings not only helpmaintain a certain level of quality control butestablish a feeling of cohesion in the group.The APB has decided to thoroughly tackle lightverb constructions and multi-word expressions aspart of an effort to facilitate mapping betweenthe different languages that are being Prop-Banked.
In the process of setting this up a num-ber of challenges have surfaced which include:how can we cross-linguistically approach thesephenomena in a (semi) integrated manner, howto identify one construction from the other, figur-ing out a language specific reliable diagnostictest, and whether we deal with these construc-tions as a whole unit or as separate parts; andhow?
(Hwang, et al, 2010)4.2 ToolsFrameset files are created in an XML format.During the Pilot Propbank project these fileswere created manually by editing the XML filerelated to a particular predicate.
This proved tobe time consuming and prone to many formattingerrors.
The Frame File creation for the revisedAPB is now performed with the recently devel-oped Cornerstone tool (Choi et al, 2010a), whichis a PropBank frameset editor that allows thecreation and editing of Propbank framesets with-out requiring any prior knowledge of XML.Moreover, the annotation is now performed byJubilee, a new annotation tool, which has im-proved the annotation process by displaying sev-eral types of relevant syntactic and semantic in-formation at the same time.
Having everythingdisplayed helps the annotator quickly absorb andapply the necessary syntactic and semantic in-formation pertinent to each predicate for consis-tent and efficient annotation (Choi et al,20010b).
Both tools are available as Open Sourcetools on Google code.34.3 Current Annotation Status and GoalsWe have currently created 1955 verb predicateFrame Files which correspond to 2446 framesets,since one verb predicate Frame File can containone or more framesets.
We will reconcile theprevious Arabic PropBank with the new Tree-bank and create an additional 3000 Frame files tocover the rest of the ATB3 verb types.5 ConclusionThis paper describes the recently revived andrevised APB.
The changes in the ATB have af-fected the APB in two fundamentally differentways.
More fine-grained POS tags facilitate thetasks of labeling predicate argument structures.However, all of the tokenization changes haverendered the old pointers obsolete, and newpointers to the new constituent boundaries haveto be supplied.
This task is underway, as well asthe task of creating several thousand additionalFrame Files to complete predicate coverage ofATB3.AcknowledgmentsWe gratefully acknowledge a grant from the De-fense Advanced Research Projects Agency(DARPA/IPTO) under the GALE program,DARPA/CMO Contract No.
HR0011-06-C-0022, subcontract from BBN, Inc. We also thankAbdel-Aati Hawwary and Maha Saliba Fosterand our annotators for their invaluable contribu-tions to this project.ReferencesBoas, Hans C. 2009.
Multilingual FrameNets.
InComputational Lexicography: Methods and Appli-cations.
Berlin: Mouton de Gruyter.
pp.
x+352Carreras, Xavier & Llu?s M?rquez.
2005.
Introductionto the CoNLL-2005 shared task: Semantic role la-beling.
In Proceedings of CoNLL-2005, Ann Ar-bor, MI, USA.3 http://code.google.com/p/propbank/225Chen, John & Owen Rambow.
2003.
Use of deeplinguistic features for the recognition and labelingof semantic arguments.
In Proceedings of the 2003Conference on Empirical Methods in Natural Lan-guage Processing, Sapporo, Japan.Choi, Jinho D., Claire Bonial, & Martha Palmer.2010a.
Propbank Instance Annotation GuidelinesUsing a Dedicated Editor,Cornerstone.
In Proceed-ings of the 7th International Conference on Lan-guage Resources and Evaluation(LREC'10),Valletta, Malta.Choi, Jinho D., Claire Bonial, & Martha Palmer.2010b.
Propbank Instance Annotation GuidelinesUsing a Dedicated Editor,Jubilee.
In Proceedingsof the 7th International Conference on LanguageResources and Evaluation (LREC'10),Valletta,Malta.Diab, Mona, Alessandro Moschitti, & Daniele Pighin.2008.
Semantic Role Labeling Systems for Arabicusing Kernel Methods.
In Proceedings of ACL.
As-sociation for Computational Linguistics, Colum-bus, OH, USA.Gildea, Daniel & Daniel Jurafsky.
2002.
Automaticlabeling of semantic roles.
Computational Linguis-tics, 28(3):245?288.Gildea, Daniel & Martha Palmer.
2002.
The necessityof parsing for predicate argument recognition.
InProceedings of the 40th Annual Conference of theAssociation for Computational Linguistics (ACL-02), Philadelphia, PA, USA.Gusfield, Dan.
1997.
Algorithms on Strings, Treesand Sequences.
Cambridge University Press,Cambridge, UK.Habash, Nizar & Owen Rambow.
2007.
Arabic dia-critization through full morphological tagging.
InHLT-NAACL 2007; Companion Volume, Short Pa-pers, Association for Computational Linguistics,pages 53?56, Rochester, NY, USA.Hovy, Eduard, Mitchell Marcus, Martha Palmer,Lance Ramshaw & Ralph Weischedel.
2006.OntoNotes: The 90% Solution.
In Proceedings ofHLT-NAACL 2006, New York, USA.Hwang, Jena D., Archna Bhatia, Clare Bonial, AousMansouri, Ashwini Vaidya, Nianwen Xue & Mar-tha Palmer.
2010.
PropBank Annotation of Multi-lingual Light Verb Constructions.
In Proceedingsof the LAW-ACL 2010.
Uppsala, Sweden.Maamouri, Mohamed, Ann Bies, Seth Kulick.
2008.Enhanced Annotation and Parsing of the ArabicTreebank.
In Proceedings of INFOS 2008, Cairo,Egypt.M?rquez, Llu?s.
2009.
Semantic Role Labeling.
Past,Present and Future .
TALP Research Center.
Tech-nical University of Catalonia.
Tutorial at ACL-IJCNLP 2009.Moschitti, Alessandro.
2004.
A study on convolutionkernels for shallow semantic parsing.
In proceed-ings of the 42th Conference on Association forComputational Linguistic (ACL-2004), Barcelona,Spain.Moschitti, Alessandro, Ana-Maria Giuglea, Bonaven-tura Coppola, & Roberto Basili.
2005.
Hierarchicalsemantic role labeling.
In Proceedings of CoNLL-2005, Ann Arbor, MI, USA.Martha Palmer, Olga Babko-Malaya, Ann Bies, MonaDiab, Mohamed Maamouri, Aous Mansouri, WajdiZaghouani.
2008.
A Pilot Arabic Propbank.
InProceedings of LREC 2008, Marrakech, Morocco.Palmer, Martha, Rajesh Bhatt, Bhuvana Narasimhan,Owen Rambow, Dipti Misra Sharma, & Fei Xia.2009.
Hindi Syntax: Annotating Dependency,Lexical Predicate-Argument Structure, and PhraseStructure.
In The 7th International Conference onNatural Language Processing (ICON-2009), Hy-derabad, India.Palmer, Martha, Daniel Gildea, & Paul Kingsbury.2005.
The Proposition Bank: An Annotated Corpusof Semantic Roles.
Computational Linguistics, 31,1 (Mar.
2005), 71-106.Palmer, Martha, Shijong Ryu, Jinyoung Choi, SinwonYoon, & Yeongmi Jeon.
2006.
LDC CatalogLDC2006T03.Pradhan, Sameer, Kadri Hacioglu, Wayne Ward,James H. Martin, & Daniel Jurafsky.
2003.
Seman-tic role parsing: Adding semantic structure to un-structured text.
In Proceedings of ICDM-2003,Melbourne, USA.Pradhan, Sameer S., Wayne H Ward, Kadri Hacioglu,James H Martin, & Dan Jurafsky.
2004.
Shallowsemantic parsing using support vector machines.
InSusan Dumais, Daniel Marcu, & Salim Roukos,editors, HLT-NAACL 2004: Main Proceedings,pages 233?240, Boston, MA, USA.Xue, Nianwen & Martha Palmer.
2004.
Calibratingfeatures for semantic role labeling.
In Dekang Lin& Dekai Wu, editors, Proceedings of ACL-EMNLP2004, pages 88?94, Barcelona, Spain.Xue, Nianwen & Martha Palmer.
2009.
Adding se-mantic roles to the Chinese Treebank.
NaturalLanguage Engineering, 15 Jan. 2009, 143-172.226
