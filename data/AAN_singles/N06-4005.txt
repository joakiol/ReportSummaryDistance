Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume, pages 269?272,New York City, June 2006. c?2006 Association for Computational LinguisticsAquaLog: An ontology-driven Question Answering System to interfacethe Semantic WebVanessa Lopez GarciaKnowledge Media InstituteThe Open University.Walton Hall, Milton Keynes,MK7 6AA United Kingdom.v.lopez@open.ac.ukEnrico MottaKnowledge Media InstituteThe Open University.Walton Hall, Milton Keynes,MK7 6AA United Kingdom.e.motta@open.ac.ukVictoria UrenKnowledge Media InstituteThe Open University.Walton Hall, Milton Keynes,MK7 6AA United Kingdom.v.s.uren@open.ac.ukAbstractThe semantic web (SW) vision is one inwhich rich, ontology-based semanticmarkup will become widely available.The availability of semantic markup onthe web opens the way to novel, sophisti-cated forms of question answering.AquaLog is a portable question-answeringsystem which takes queries expressed innatural language (NL) and an ontology asinput, and returns answers drawn fromone or more knowledge bases (KB).AquaLog presents an elegant solution inwhich different strategies are combinedtogether in a novel way.
AquaLog novelontology-based relation similarity servicemakes sense of user queries.1 IntroductionAquaLog (Lopez, 2005) is a fully implementedontology-driven Question Answering (QA) sys-tem1, which takes an ontology and a NL query asan input and returns answers drawn from semanticmarkup (viewed as a KB) compliant with the inputontology.
In contrast with much existing work onontology-driven QA, which tends to focus on theuse of ontologies to support query expansion ininformation retrieval (Mc Guinness, 2004),AquaLog exploits the availability of semanticstatements to provide precise answers to complexqueries expressed in NL.AquaLog makes use of the GATE NLP plat-form, string distance metric, generic lexical re-sources, such as WordNet, as well as the structure1 AquaLog is available as Open Source https://sourceforge.net/projects/aqualogof the input ontology, to make sense of the termsand relations expressed in the input query with re-spect to the target KB.
Naturally, these terms andrelations match the terminology familiar to the userrather than those used in the ontology.We say that AquaLog is portable because theconfiguration time required to customize the sys-tem for a particular ontology is negligible.
We be-lieve that in the SW scenario it makes sense toprovide a NL query interface portable with respectto ontologies, our AquaLog system allows tochoose an ontology and then ask queries with re-spect to its universe of discourse.
The reason forthis is that the architecture of the system and thereasoning methods are domain-independent,  rely-ing on an understanding of general-purpose knowl-edge representation languages, such as OWL2, andthe use of generic lexical resources, such asWordNet.Moreover, AquaLog learning mechanism en-sures that, for a given ontology and a particularcommunity jargon used by end users, its perform-ance improves over time, as the users can easilycorrect mistakes and allow AquaLog to learn novelassociations between the NL relations used by us-ers and the ontology structure.Approach.
AquaLog uses a sequential processmodel (see Fig.
1), in which NL input is first trans-lated into a set of intermediate representations ?called Query Triples, by the Linguistic Compo-nent.
The Linguistic Component uses the GATEinfrastructure and resources (Cunningham, 2002)to obtain a set of syntactic annotations associatedwith the input query and to classify the query.Once this is done, it becomes straight-forward forthe Linguistic Component to automatically createthe Query-Triples.
Then, these query triples are2 A plug-in mechanism and a generic API ensure that different KnowledgeRepresentation languages can be used.269further processed and interpreted by the RelationSimilarity Service Component (RSS), which useslexical resources and the ontology to map them toontology-compliant semantic markup or triples.NL SENTENCEINPUTLINGUISTIC&QUERY CLASSIFICATIONRELATIONSIMILARITYSERVICEINFERENCEENGINEQUERYTRIPLESONTOLOGYCOMPATIBLETRIPLESANSWERFig.
1.
AquaLog data model2 Linguistic ComponentThe Linguistic Component?s task is to map the NLinput query to the Query-Triple.
GATE  (Cunning-ham, 2002) infrastructure and resources (e.g.
proc-essing resources like ANNIE) are part of theLinguistic Component.After the execution of the GATE controller, aset of syntactic annotations associated with the in-put query are returned.
These annotations includeinformation about sentences, tokens, nouns andverbs.
For example, we get voice and tense for theverbs and categories for the nouns, such as deter-minant, singular/plural, conjunction, possessive,determiner, preposition, existential, wh-determiner,etc.
When developing AquaLog we extended theset of annotations returned by GATE, by identify-ing terms, relations, question indicators(which/who/when.
etc.)
and patterns or types ofquestions.
This is achieved through the use of Japegrammars, which consist of a set of phases, thatrun sequentially, and each phase is defined as a setof pattern rules, which allow us to recognize regu-lar expressions using previous annotations indocuments.Thanks to this architecture that takes advantageof the Jape grammars, although we can still onlydeal with a subset of NL, it is possible to extendthis subset in a relatively easy way by updating theregular expressions in the Jape grammars.
Thisensures the easy portability of the system with re-spect to both ontologies and natural languages.Currently, the linguistic component, through theJape grammars, dynamically identifies around 14different linguistic categories or intermediate rep-resentations, including: basic queries requiring anaffirmation/negation or a description as an answer;or the big set of queries constituted by a wh-question (such as the ones starting with: what,who, when, where, are there any, does any-body/anyone or how many, and imperative com-mands like list, give, tell, name, etc.
), like ?arethere any PhD students in dotkom??
where the re-lation is implicit or unknown or ?which is the jobtitle of John??
where no information about the typeof the expected answer is provided; etc.Categories tell us not only  the kind of solu-tion that needs to be achieved, but also they givean indication of the most likely common problemsthat the system will need to deal with to understandthis particular NL query and in consequence itguides the process of creating the equivalent in-termediate representation.
Categories are the driv-ing force to generate an answer by combining thetriples in an appropriate way.
For example, in?who are the academics involved in the semanticweb??
the triple will be of the form <generic term,relation, second term>, i.e.
<academics, involved,semantic web>.
A query with a equivalent triplerepresentation is ?which technologies has KMiproduced?
?, where the triple will be <technologies,has produced, KMi>.
However, a query like ?arethere any PhD students in akt??
has anotherequivalent representation, where the relation is im-plicit or unknown <phd students, ?, akt> .
Otherqueries may provide little information about thetype of the expected answer, i.e.
?what is the jobtitle of John?
?, or they can be just a generic en-quiry about someone or something, i.e.
?who isVanessa?
?, ?what is an ontology?
?At this stage we do not have to worry about get-ting the representation completely right as the in-terpretation is completely domain independent.The role of the triple-based intermediate represen-tation is simply to provide an easy way to representthe NL query and to manipulate the input for theRSS.
Consider the request ?List all the projects inthe knowledge media institute about the semanticweb?, where both ?in knowledge media institute?and ?about semantic web?
are modifiers (i.e.
theymodify the meaning of other syntactic constitu-ents).
The problem here is to identify the constitu-ent to which each modifier has to be attached.
TheRSS is responsible for resolving this ambiguitythrough the use of the ontology, or by interactingwith the user.
The linguistic component?s task istherefore to pass the ambiguity problem to the RSSthrough the intermediate representation.270Nevertheless, a query can be a composition oftwo basic queries.
In this case, the intermediaterepresentation usually consists of two triples, onetriple per relationship.
There are different ways inwhich queries can be combined.
Firstly, queriescan be combined by using a ?and?
or ?or?
conjunc-tion operator, as in ?which projects are funded byepsrc and are about semantic web??.
This querywill generate two Query-Triples: <projects, funded,epsrc> and <projects, ?, semantic web> and thesubsequent answer will be a combination of bothlists obtained after resolving each triple.
Secondly,a query may be conditioned to a second query, asin ?which researchers wrote publications related tosocial aspects??
which generates the Query-Triples<researchers, wrote, publications> and <which are,related, social aspects>,where the second clausemodifies one of the terms in the first triple.
In thisexample, ambiguity cannot be solved by linguisticprocedures; therefore the term to be modified bythe second clause remains uncertain.3 Relation Similarity ServiceThis is the backbone of the QA system.
The RSScomponent is invoked after the NL query has beentransformed into a term-relation form and classi-fied into the appropriate category.
Essentially theRSS tries to make sense of the input query by look-ing at the structure of the ontology, string metrics3,WordNet, and a domain-dependent lexicon ob-tained by the Learning Mechanism.In any non-trivial NL system, it is important todeal with the various sources of ambiguity.
Somesentences are structurally ambiguous and althoughgeneral world knowledge does not resolve this am-biguity, within a specific domain it may happenthat only one of the interpretations is possible.
Thekey issue here is to determine some constraintsderived from the domain knowledge and to applythem in order to resolve ambiguity.
Whether theambiguity cannot be resolved by domain knowl-edge the only reasonable course of action is to getthe user to choose between the alternative readings.Moreover, since every item on the onto-triple is anentry point in the KB or ontology the user has thepossibility to navigate through them.
In fact, toensure user acceptance of the system justificationsare provided for every step of the user interaction.3 http://secondstring.sourceforge.net/4 Related WorkThis scenario is similar to research in NL queriesto databases (NLIDB).
However, the SW providesa new and potentially important context in whichresults from this research area can be applied.There are linguistic problems common in mostkinds of NL understanding systems, see (Androut-sopoulos, 1995) for an overview of the state of theart.
In contrast with the latest generation of NLIDBsystems (see (Popescu, 2003) for recent work)AquaLog uses an intermediate representation fromthe representation of the user?s query (NL frontend) to the representation of an ontology complianttriple, from which an answer can be directly in-ferred.
It takes advantage of the use of ontologiesin a way that the entire process highly portable andit is easy to handle unknown vocabulary.
For in-stance, in PRECISE (Popescu, 2003) the problemof finding a mapping from the tokenization to thedatabase requires that all tokens must be distinct,questions with unknown words are not semanti-cally tractable and cannot be handled.
In contrastwith PRECISE, AquaLog interpret the user queryby means of the ontology vocabulary and structurein order to make sense of unknown vocabularywhich appears not to have any match.Current work on QA is somewhat different innature from AquaLog as they are open-domainsystems.
QA applications to text typically involve(Hirschman, 2001) identifying the semantic type ofthe entity sought by the question (a date, a per-son?
); and determining key words or relations tobe use in matching candidate answers.
Moreover,as pointed by Srihari et al (Srihari, 2004) NamedEntity (NE) tagging is often necessary.
The maindifferences between AquaLog and open-domainssystems are: (1) it is not necessary to build hierar-chies or heuristic to recognize NE, as all the se-mantic information needed is in the ontology.
(2)AquaLog has mechanisms to exploit the relation-ships to understand a query.
Nevertheless, the RSSgoal is to map the relationships in the Query-Tripleinto an ontology-compliant-triple.
Both AquaLogand open-domain systems attempt to find syno-nyms plus their morphological variants.
AquaLogalso automatically classifies the question beforehand, based on the kind of triple needed, whilemost of the open-domain QA systems classifyquestions according to their answer target.
Thetriple contains information not only about the an-271swer expected, but also about the relationships ofthe other terms in the query.
To conclude, otherQA systems also follow a relational data model(triple-based), e.g.
the START ?object-property-value?
approach (Katz, 2002).5 AquaLog in action: illustrative example.For demonstration purposes AquaLog applicationis used with the AKT ontology in the context of theacademic domain in our department (Lei, 2006),e.g., AquaLog translates the query ?what is thehomepage of Peter who has an interest on the se-mantic web?"
into a conjunction of ontology-compliant non-ground triples: <what is?, has-web-address, peter-scott> & <person?, has-research-interest, Semantic Web area>.Consider the query ?what is the homepage ofPeter??
on Fig.
2.
Given that the system is unableto disambiguate between Peter-Scott, Peter-Sharpe,etc, user feedback is required.
Also the user is callto disambiguate that ?homepage?
is the same that?has-web-address?
as it is the first time the systemcame across this term, no synonyms have beenidentified, and the ontology does not provide fur-ther ways to disambiguate.
The system will learnthe mapping and context for future occasions.Fig.
2.
Example of user disambiguationOn Fig.
3 we are asking for the web address of Pe-ter, who has an interest in SW.
In this caseAquaLog does not need any assistance from theuser, given that only one of the Peters has an inter-est in SW. Also the similarity relation between?homepage?
and ?has-web-address?
has beenlearned by the Learning Mechanism.
When theRSS comes across a query like that it has to accessto the ontology information to recreate the contextand complete the ontology triples.
In that way, itrealizes that ?who has an interest on the SemanticWeb?
is a modifier of the term ?Peter?.Fig.
3.
Example of AquaLog disambiguationReferencesAndroutsopoulos, I., Ritchie, G.D., Thanisch P.: NaturalLanguage Interfaces to Databases - An Introduction.Natural Language Engineering, 1(1) (1995) 29-81.Cunningham, H., Maynard, D., Bontcheva, K., Tablan,V.
: GATE: A Framework and Graphical DevelopmentEnvironment for Robust NLP Tools and Applications.In Proceedings of the 40th Anniversary Meeting of theAssociation for Computational Linguistics (2002).Hirschman, L., Gaizauskas, R.: Natural Language ques-tion answering: the view from here.
Natural LanguageEngineering, Special Issue on Question Answering,7(4) (2001) 275-300.Katz, B., et al: Omnibase: Uniform Access to Heteroge-neous Data for QA.
In Proceedings of the 7th Interna-tional Workshop on Applications of Natural Languageto Information Systems (NLDB) (2002)Lopez, V., Pasin, M., and Motta, E. AquaLog: An Ontol-ogy-portable Question Answering System for the Se-mantic Web.
In proceeding of the ESWC (2005).Mc Guinness, D.: Question Answering on the SemanticWeb.
IEEE Intelligent Systems, 19(1), 2004.Popescu, A., M., Etzioni, O., Kautz, H., A.: Towards atheory of natural language interfaces to databases.
InProceedings of the 2003 International Conference onIntelligent User Interfaces, (2003) 149-157Srihari, K., Li, W., Li, X.: Information Extraction Sup-ported QA, In T. Strzalkowski & S. Harabagiu (Eds.
),in Advances in Open- Domain Question Answering.Kluwer Academic Publishers (2004)Lei, Y., Sabou, M., Lopez, V., Zhu, J., Uren, V. andMotta.
E. An Infrastructure for Acquiring high QualitySemantic Metadata.
In proceedings of the 3rd Euro-pean Semantic Web Conference.
Montenegro, (2006).272
