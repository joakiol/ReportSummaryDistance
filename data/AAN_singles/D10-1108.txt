Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1110?1118,MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Association for Computational LinguisticsA Semi-Supervised Method to Learn and Construct Taxonomies using theWebZornitsa Kozareva and Eduard HovyUSC Information Sciences Institute4676 Admiralty WayMarina del Rey, CA 90292-6695{kozareva,hovy}@isi.eduAbstractAlthough many algorithms have been devel-oped to harvest lexical resources, few organizethe mined terms into taxonomies.
We pro-pose (1) a semi-supervised algorithm that usesa root concept, a basic level concept, and re-cursive surface patterns to learn automaticallyfrom the Web hyponym-hypernym pairs sub-ordinated to the root; (2) a Web based conceptpositioning procedure to validate the learnedpairs?
is-a relations; and (3) a graph algorithmthat derives from scratch the integrated tax-onomy structure of all the terms.
Comparingresults with WordNet, we find that the algo-rithm misses some concepts and links, but alsothat it discovers many additional ones lackingin WordNet.
We evaluate the taxonomizationpower of our method on reconstructing partsof the WordNet taxonomy.
Experiments showthat starting from scratch, the algorithm canreconstruct 62% of the WordNet taxonomy forthe regions tested.1 IntroductionA variety of NLP tasks, including inference, tex-tual entailment (Glickman et al, 2005; Szpektoret al, 2008), and question answering (Moldovanet al, 1999), rely on semantic knowledge derivedfrom term taxonomies and thesauri such as Word-Net.
However, the coverage of WordNet is still lim-ited in many regions (even well-studied ones such asthe concepts and instances below Animals and Peo-ple), as noted by researchers such as (Pennacchiottiand Pantel, 2006) and (Hovy et al, 2009) who per-form automated semantic class learning.
This hap-pens because WordNet and most other existing tax-onomies are manually created, which makes themdifficult to maintain in rapidly changing domains,and (in the face of taxonomic complexity) makesthem hard to build with consistency.
To surmountthese problems, it would be advantageous to havean automatic procedure that can not only augmentexisting resources but can also produce taxonomiesfor existing and new domains and tasks starting fromscratch.The main stages of automatic taxonomy induc-tion are term extraction and term organization.
Inrecent years there has been a substantial amount ofwork on term extraction, including semantic classlearning (Hearst, 1992; Riloff and Shepherd, 1997;Etzioni et al, 2005; Pasca, 2004; Kozareva et al,2008), relation acquisition between entities (Girjuet al, 2003; Pantel and Pennacchiotti, 2006; Davi-dov et al, 2007), and creation of concept lists (Katzand Lin, 2003).
Various attempts have been made tolearn the taxonomic organization of concepts (Wid-dows, 2003; Snow et al, 2006; Yang and Callan,2009).
Among the most common is to start with agood ontology and then to try to position the miss-ing concepts into it.
(Snow et al, 2006) maximizethe conditional probability of hyponym-hypernymrelations given certain evidence, while (Yang andCallan, 2009) combines heterogenous features likecontext, co-occurrence, and surface patterns to pro-duce a more-inclusive inclusion ranking formula.The obtained results are promising, but the problemof how to organize the gathered knowledge whenthere is no initial taxonomy, or when the initial tax-onomy is grossly impoverished, still remains.1110The major problem in performing taxonomy con-struction from scratch is that overall concept po-sitioning is not trivial.
It is difficult to discoverwhether concepts are unrelated, subordinated, orparallel to each other.
In this paper, we address thefollowing question: How can one induce the taxo-nomic organization of concepts in a given domainstarting from scratch?The contributions of this paper are as follows:?
An automatic procedure for harvestinghyponym-hypernym pairs given a domain ofinterest.?
A ranking mechanism for validating the learnedis-a relations between the pairs.?
A graph-based approach for inducing the taxo-nomic organization of the harvested terms start-ing from scratch.?
An experiment on reconstructing WordNet?staxonomy for given domains.Before focusing on the harvesting and taxonomyinduction algorithms, we are going to describe somebasic terminology following (Hovy et al, 2009).
Aterm is an English word (for our current purposes,a noun or a proper name).
A concept is an item inthe classification taxonomy we are building.
A rootconcept is a fairly general concept which is locatedon the high level of the taxonomy.
A basic-levelconcept corresponds to the Basic Level categoriesdefined in Prototype Theory in Psychology (Rosch,1978).
For example, a dog, not a mammal or a col-lie.
An instance is an item in the classification tax-onomy that is more specific than a concept.
For ex-ample, Lassie, not a dog or collie .The rest of the paper is organized as follows.
Sec-tion 2 reviews related work.
Section 3 describes thetaxonomization framework.
Section 4 discusses theexperiments.
We conclude in Section 5.2 Related WorkThe first stage of automatic taxonomy induction,term and relation extraction, is relatively well-understood.
Methods have matured to the point ofachieving high accuracy (Girju et al, 2003; Panteland Pennacchiotti, 2006; Kozareva et al, 2008).
Theproduced output typically contains flat lists of termsand/or ground instance facts (lion is-a mammal)and general relation types (mammal is-a animal).Most approaches use either clustering or patternsto mine knowledge from structured and unstructuredtext.
Clustering approaches (Lin, 1998; Lin and Pan-tel, 2002; Davidov and Rappoport, 2006) are fullyunsupervised and discover relations that are not di-rectly expressed in text.
Their main drawback is thatthey may or may not produce the term types andgranularities useful to the user.
In contrast, pattern-based approaches harvest information with high ac-curacy, but they require a set of seeds and surfacepatterns to initiate the learning process.
These meth-ods are successfully used to collect semantic lex-icons (Riloff and Shepherd, 1997; Etzioni et al,2005; Pasca, 2004; Kozareva et al, 2008), encyclo-pedic knowledge (Suchanek et al, 2007), conceptlists (Katz and Lin, 2003), and relations betweenterms, such as hypernyms (Ritter et al, 2009; Hovyet al, 2009) and part-of (Girju et al, 2003; Panteland Pennacchiotti, 2006).However, simple term lists are not enough to solvemany problems involving natural language.
Termsmay be augmented with information that is requiredfor knowledge-intensive tasks such as textual entail-ment (Glickman et al, 2005; Szpektor et al, 2008)and question answering (Moldovan et al, 1999).
Tosupport inference, (Ritter et al, 2010) learn the se-lectional restrictions of semantic relations, and (Pen-nacchiotti and Pantel, 2006) ontologize the learnedarguments using WordNet.Taxonomizing the terms is a very powerfulmethod to leverage added information.
Subordi-nated terms (hyponyms) inherit information fromtheir superordinates (hypernyms), making it unnec-essary to learn all relevant information over and overfor every term in the language.
But despite many at-tempts, no ?correct?
taxonomization has ever beenconstructed for the terms of, say, English.
Typically,people build term taxonomies (and/or richer struc-tures like ontologies) for particular purposes, usingspecific taxonomization criteria.
Different tasks andcriteria produce different taxonomies, even when us-ing the same basic level concepts.
This is becausemost basic level concepts admit to multiple perspec-tives, while each task focuses on one, or at most two,perspectives at a time.
For example, a dolphin is aMammal (and not a Fish) to a biologist, but is a Fish1111(and hence not a Mammal) to a fisherman or anyonebuilding or visiting an aquarium.
More confusingly,a tiger and a puppy are both Mammals and hencebelong close together in a typical taxonomy, but atiger is a WildAnimal (in the perspective of Animal-Function) and a JungleDweller (in the perspective ofHabitat), while a puppy is a Pet (as function) and aHouseAnimal (as habitat), which would place themrelatively far from one another.
Attempts at pro-ducing a single multi-perspective taxonomy fail dueto the complexity of interaction among perspectives,and people are notoriously bad at constructing tax-onomies adherent to a single perspective when giventerms from multiple perspectives.
This issue and themajor alternative principles for taxonomization arediscussed in (Hovy, 2002).It is therefore not surprising that the secondstage of automated taxonomy induction is harder toachieve.
As mentioned, most attempts to learn tax-onomy structures start with a reasonably completetaxonomy and then insert the newly learned termsinto it, one term at a time (Widdows, 2003; Pasca,2004; Snow et al, 2006; Yang and Callan, 2009).
(Snow et al, 2006) guide the incremental approachby maximizing the conditional probability over aset of relations.
(Yang and Callan, 2009) introducea taxonomy induction framework which combinesthe power of surface patterns and clustering throughcombining numerous heterogeneous features.Still, one would like a procedure to organize theharvested terms into a taxonomic structure startingfresh (i.e., without using an initial taxonomic struc-ture).
We propose an approach that bridges the gapbetween the term extraction algorithms that focusmainly on harvesting but do not taxonomize, andthose that accept a new term and seek to enrich an al-ready existing taxonomy.
Our aim is to perform bothstages: to extract the terms of a given domain and toinduce their taxonomic organization without any ini-tial taxonomic structure and information.
This taskis challenging because it is not trivial to discoverboth the hierarchically related and the parallel (per-spectival) organizations of concepts.
Achieving thisgoal can provide the research community with theability to produce taxonomies for domains for whichcurrently there are no existing or manually createdontologies.3 Building Taxonomies from Scratch3.1 Problem FormulationWe define our task as:Task Definition: Given a root concept, a basic levelconcept or an instance, and recursive lexico-syntacticpatterns, (1) harvest in bootstrapping fashion hy-ponyms and hypernyms subordinated to the root; (2)filter out erroneous information (extracted conceptsand isa relations); (3) organize the harvested con-cepts into a taxonomy structure.!
"#!$%&'%$()%*&+%#!%,#-!%*& ./0#1-!%*&/%#,(+0#%*&.-#)(+0#%*& 2-22-$*&-)(2-$&103&10)4%5&%$%6/-)!&./%%!-/&1%%#&73%#&6"2-&$(0)&Figure 1: Taxonomy Induction from Scratch.Figure 1 shows an example of the task.
Start-ing with the root concept animal and the basiclevel concept lion, the algorithm learns newterms like tiger, puma, deer, donkey of classanimal.
Next for each basic level concept, thealgorithm harvests hypernyms and learns that alion is-a vertebrate, chordate, feline and mammal.Finally, the taxonomic structure of each basiclevel concept and its hypernyms is induced: ani-mal?chordate?vertebrate?mammal?feline?lion.3.2 Knowledge HarvestingThe main objective of our work is not the creationof a new harvesting algorithm, but rather the or-ganization of the harvested information in a tax-onomy structure starting from scratch.
There aremany algorithms for hyponym and hypernym har-vesting from the Web.
In our experiments, we usethe doubly-anchored lexico-syntactic patterns andbootstrapping algorithm introduced by (Kozareva etal., 2008) and (Hovy et al, 2009).1112We are interested in using this approach, becauseit is: (1) simple and easy to implement; (2) requiresminimal supervision using only one root conceptand a term to learn new hyponyms and hypernymsassociated to the root; (3) reports higher precisionthan current semantic class algorithms (Etzioni etal., 2005; Pasca, 2004); and (4) adapts easily to dif-ferent domains.The general framework of the knowledge harvest-ing algorithm is shown in Figure 2.1.
Given:a hyponym pattern Pi={concept such as seedand *}a hypernym pattern Pc={* such as term1 andterm2}a root concept roota term called seed for Pi2.
build a query using Pi3.
submit Pi to Yahoo!
or other search engine4.
extract terms occupying the * position5.
take terms from step 4 and go to step 2.6. repeat steps 2?5 until no new terms are found7.
rank terms by outDegree8.
for ?
terms with outDegree>0, build a queryusing Pc9.
submit Pc to Yahoo!
or other search engine10.
extract concepts (hypernyms) occupying the *position11.
rank concepts by inDegreeFigure 2: Knowledge Harvesting Framework.The algorithm starts with a root concept, seedterm1 of type root and a doubly-anchored pattern(DAP) such as ?<root> such as <seed> and *?which learns on the * position new terms of typeroot.
The newly learned terms, which can be eitherinstances, basic level or intermediate concepts, areplaced into the position of the seed in the DAP pat-tern, and the bootstrapping process is repeated.
Theprocess ceases when no new terms are found.To separate the true from incorrect terms, we usea graph-based algorithm in which each vertex u isa term, and an each edge (u, v) ?
E correspondsto the direction in which the term u discovered theterm v. The graph is weighted w(u, v) according1The input term can be an instance, a basic level or an in-termediate concept.
An intermediate concept is the one that islocated between the basic level and root concepts.to the number of times the term pair u-v is seenin unique web snippets.
The terms are ranked byoutDegree(u)=??
(u,v)?Ew(u,v)|V |?1 which counts thenumber of outgoing links of node u normalized bythe total number of nodes in the graph excluding thecurrent.
The algorithm considers as true terms withoutDegree>0.All harvested terms are automatically fed into thehypernym extraction phase.
We use the natural or-der in which the terms discovered each other andplace them into an inverse doubly-anchored pattern(DAP?1) ?
* such as <term1> and <term2>?
tolearn hypernyms on the * position.
Similarly webuild a graph with nodes h denoting the hypernymsand nodes t1-t2 denoting the term pairs.
The edges(h, t1 ?
t2) ?
E?
show the direction in which theterm pair discovered the hypernym.
The hypernymsare ranked by inDegree(h)=??(t1?t2,h)?E?
w(t1?t2, h) which rewards hypernyms that are frequentlydiscovered by various term pairs.
The output ofthe algorithm is a list of is-a relations between thelearned terms (instances, basic level or intermediateconcepts) and their corresponding hypernyms.
Forexample, deer is-a herbivore, deer is-a ruminant,deer is-a mammal.3.3 Graph-Based Taxonomy InductionIn the final stage of our algorithm, we induce theoverall taxonomic structure using information aboutthe pairwise positioning of the terms.
In the knowl-edge harvesting and filtering phases, the algorithmlearned is-a relations between the root and the terms(instances, basic level or intermediate concepts), aswell as the harvested hypernyms and the terms.
Theonly missing information is the positioning of the in-termediate concepts located between the basic leveland the root such as mammals, vertibrates, felines,chordates, among others.We introduce a concept positioning (CP) proce-dure that uses a set of surface patterns: ?X such asY?, ?X are Y that?, ?X including Y?, ?X like Y?,?such X as Y?
to learn the hierarchical relations forall possible concept pairs.
For each concept pair,say chordates and vertebrates, we issue the twofollowing queries:(a) chordates such as vertebrates(b) vertebrates such as chordates1113If (a) returns more web hits than (b), then chordatessubsumes (or is broader than) vertebrates, other-wise vertebrates subsumes chordates.
For thispair the such as pattern returned 7 hits for (a) and0 hits for (b), so that the overall magnitude of thedirection of the relation is weak.
To accumulatestronger evidence, we issue web queries with theremaining patterns.
For the same concept pair, theoverall magnitude of ?X including Y?
is 5820 hitsfor (a) and 0 for (b).As shown in Figure 3, the concept positioning pat-terns cannot always determine the direct taxonomicorganization between two concepts as in the caseof felines and chordates, felines and vertebrates.One reason is that the concepts are located on dis-tant taxonomic levels.
We humans typically exem-plify concepts using more proximate ones.
There-fore, the concept positioning procedure can find ev-idence for the relation ?mammals?felines?, but notfor ?chordates?felines?.!"#$!%&'()*(+)!*(,&-(%#"(,&$!$$!%,&%#."&/0.)1!*(,&!"#$!%&/0.)1!*(,&'()*(+)!*(,&$!$$!%,&-(%#"(,&%#.
"&Figure 3: Concept Positioning and Induced Taxonomy.After the concept positioning procedure has ex-plored all concept pairs, we encounter two phenom-ena: (1) direct links between some concepts aremissing and (2) multiple paths can be taken to reachfrom one concept to another.To surmount these problems, we employ agraph based algorithm that finds the longestpath in the graph G?
?=(V ?
?, E??).
The nodesV ?
?={it1, h1, h2, .., hn, r} represent the input term,its hypernyms, and the root.
An edge (tm, tn) ?
E?
?indicates that there is a path between the terms tmand tn.
The direction tm ?
tn indicates the termsubordination discovered during the CP procedure.The objective is to find the longest path in G??
be-tween the root and the input term.
Intuitively, find-ing the longest paths is equivalent to finding the tax-onomic organization of all concepts.First, if present, we eliminate all cycles from thegraph.
Then, we find all nodes that have no prede-cessor and those that have no successor.
Intuitively,a node with no predecessors p is likely to be posi-tioned on the top of the taxonomy (e.g.
animal),while a node with no successor s is likely to be lo-cated at the bottom (e.g.
terms like lion, tiger, puma,or concepts like krill predators that could not be re-lated to an instance or a basic level concept duringthe CP procedure).
We represent the directed graphas an adjacency matrix A = [am,n], where am,n is1 if (tm, tn) is an edge of G?
?, and 0 otherwise.
Foreach (p, s) pair, we find the list of all paths connect-ing p with s. In the end, from all discovered can-didate paths, the algorithm returns the longest one.The same graph-based taxonomization procedure isrepeated for the rest of the basic level concepts andtheir hypernyms.4 Experiments and ResultsTo evaluate the performance of a taxonomy induc-tion algorithm, one can compare against a simpletaxonomy composed of 2?3 levels.
However, onecannot guarantee that the algorithm can learn largerhierarchies completely or correctly.Animals provide a good example of the true com-plexity of concept organization: there are manytypes, they are of numerous kinds, people take nu-merous perspectives over them, and they are rela-tively well-known to human annotators.
In addition,WordNet has a very rich and deep taxonomic struc-ture for animals that can be used for direct compar-ison.
We further evaluate our algorithm on the do-mains of Plants and Vehicles, which share some ofthese properties.4.1 Data CollectionWe have run the knowledge harvesting algorithm onthe semantic classes Animals, Plants and Vehiclesstarting with only one seed example such as lions,cucumbers and cars respectively.First, we formed and submitted the DAP patternas web queries to Yahoo!Boss.
We retrieved thetop 1000 web snippets for each query.
We keptall unique terms and term pairs.
Second, we usedthe learned term pairs to form and submit new web1114queries DAP?1.
In this step, the algorithm harvestedthe hypernyms associated with each term.
We keptall unique triples composed of a hypernym and theterm pairs that extracted it.
The algorithm ran untilcomplete exhaustion for 8 iterations for Animals, 10iterations for Plants and 18 iterations of Vehicles.Table 1 shows the total number of terms extractedby the Web harvesting algorithm during the firststage.
In addition, we show the number of terms thatpassed the outDegree threshold.
We found that themajority of the learned terms for Animals are basiclevel concepts, while for Plants and Vehicles they area mixture of basic level and intermediate concepts.Animals Plants Vehicles#Extracted Terms 1855 2801 1425#outDegree(Term)> 0 858 1262 581Table 1: Learned Terms.Since human based evaluation of all harvestedterms is time consuming and costly, we have se-lected 90 terms located at the beginning, in the mid-dle and in the end of the outDegree ranking.
Table2 summarizes the results.Plants #CorrectByHand #inWN PrecByHandrank[1-30] 29 28 .97rank[420-450] 29 21 .97rank[1232-1262] 27 19 .90Vehicles #CorrectByHand #inWN PrecByHandrank[1-30] 29 27 .97rank[193-223] 22 18 .73rank[551-581] 25 19 .83Table 2: Term Evaluation.Independently, we can say that the precision of theharvesting algorithm is from 73 to 90%.
In the caseof Vehicles, we found that the learned terms in themiddle ranking do not refer to the meaning of vehi-cle as a transportation devise, but to the meaning ofvehicle as media (i.e.
seminar, newspapers), com-munication and marketing.
For the same category,the algorithm learned many terms which are missingfrom WordNet such as BMW, bakkies, two-wheeler,all-terrain-vehicle among others.The second stage of the harvesting algorithm con-cerns hypernym extraction.
Table 3 shows the totalnumber of hypernyms harvested for all term pairs.The top 20 highly ranked concepts by inDegree arethe most descriptive terms for the domain.
However,if we are interested in learning a larger set of hy-pernyms, we found that inDegree is not sufficientby itself.
For example, highly frequent but irrele-vant hypernyms such as meats, others are rankedat the top of the list, while low frequent but rele-vant ones such as protochordates, hooved-mammals,homeotherms are discarded.
This shows that weneed to develop additional and more sensitive mea-sures for hypernym ranking.Animals Plants Vehicles#Extracted Hypernyms 1904 8947 2554#inDegree(Hypernyms)> 10 110 294 100Table 3: Learned Hypernyms.Table 4 shows some examples of the learned an-imal hypernyms which were annotated by humansas: correct but not present in WordNet; borderlinewhich depending on the application could be valu-able to have or exclude; and incorrect.CorrectNotInWN {colony|social} insects, grazers, monogastricscamelid, {mammalian|land|areal} predators{australian|african} wildlife, filter feedershard shelled invertebrates, pelagicsbottom dwellersBorderline prehistoric animals, large herbivorespocket pets, farm raised fish, roaring catsendangered mammals, mysterious hunterstop predators, modern-snakes, heavy gameIncorrect frozen foods, native mammals, red meatsfurry predators, others, resources, sortsproducts, items, proteinTable 4: Examples of Learned Animal Hypernyms.The annotators found that 9% of the harvested is-a relations are missing from WordNet.
For example,cartilaginous fish ?
shark; colony insects?
bees;filter feeders?
tube anemones among others.
Thisshows that despite its completeness, WordNet hasstill room for improvement.4.2 A Test: Reconstructing WordNetAs previously discussed in (Hovy et al, 2009), it isextremely difficult even for expert to manually con-struct and evaluate the correctness of the harvestedtaxonomies.
Therefore, we decided to evaluate theperformance of our taxonomization approach recon-structing WordNet Animals, Plants and Vehicles tax-onomies.1115Given a domain, we select from 140 to 170 ofthe harvested terms.
For each term, we retrieve allWordNet hypernyms located on the path between theinput term and the root that is animal, plant or ve-hicle depending on the domain of interest.
We havefound that 98% of the WordNet terms are also har-vested by our knowledge acquisition algorithm.
Thismeans that being able to reconstruct WordNet?s tax-onomy is equivalent to evaluating the performanceof our taxonomy induction approach.Table 5 summarizes the characteristics of the tax-onomies for the regions tested.
For each domain,we show the total number of terms that must be or-ganized, and the total number of is-a relations thatmust be induced.Animals Plants Vehicles#terms 684 554 140#is-a 4327 2294 412average depth 6.23 4.12 3.91max depth 12 8 7min depth 1 1 1Table 5: Data for WordNet reconstruction.Among the three domains we have tested, An-imals is the most complex and richest one.
Themaximum number of levels our algorithm must in-fer is 11, the minimum is 1 and the average taxo-nomic depth is 6.2.
In total there are three basic levelconcepts (longhorns, gaur and bullock) with maxi-mum depth, twenty terms (basic level and intermedi-ate concepts) with minimum depth and ninety-eightterms (wombat, viper, rat, limpkin) with depth 6.Plants is also a very challenging domain, becauseit contains a mixture of scientific and general termssuch as magnoliopsida and flowering plant.4.3 EvaluationTo evaluate the performance of our taxonomy induc-tion approach, we use the following measures:Precision = #is?a found in WordNet and by system#is?a found by systemRecall = #is?a found in WordNet and by system#is?a found in WordNetTable 6 shows results of the taxonomy inductionof the Vehicles domain using different concept po-sitioning patterns.
The most productive ones are:?X are Y that?
and ?X including Y?.
However, thehighest yield is obtained when we combine evidencefrom all patterns.Vehicles Precision RecallX such as Y .99 (174/175) .42 (174/410)X are Y that .99 (206/208) .50 (206/410)X including Y .96 (165/171) .40 (165/410)X like Y .96 (137/142) .33 (137/410)such X as Y .98 (44/45) .11 (44/410)AllPatterns .99 (246/249) .60 ( 246/410)Table 6: Evaluation of the Induced Vehicle Taxonomy.Table 7 shows results of the taxonomization ofthe Animals and Plants domains.
Overall, the ob-tained results are very encouraging given the factthat we started from scratch without the usage ofany taxonomic structure.
Precision is robust, but wemust further improve recall.
Our observation for thelower recall is that some intermediate concepts re-late mostly to the high level ones, but not to the basiclevel concepts.Precision RecallAnimals .98 (1643/1688) .38 (1643/4327)Plants .97 (905/931) .39 (905/2294)Table 7: Evaluation of the Induced Animal and Plant Tax-onomies.Figure 4 shows an example of the taxonomy in-duced by our algorithm for the vipers, rats, wom-bats, ducks, emus, moths and penguins basic levelconcepts and their WordNet hypernyms.animalsaquatic_vertebrates chordates invertebratesvertebrates arthropodsaquatic_birdsduckspenguinsinsectsmothsbirdsemusmammalsreptilesmarsupials placentalsrodentswombats ratsmetatherianssnakesvipersFigure 4: Induced Taxonomy for Animals.The biggest challenge of the taxonomization pro-cess is the merging of independent taxonomic per-1116spectives (a deer is a grazer in BehaviorByFeeding,a wildlife in BehaviorByHabitat, a herd in Behavior-SocialGroup and an even-toed ungulate in Morpho-logicalType) into a single hierarchy.5 Conclusions and Future WorkWe are encouraged by the ability of the taxonomiza-tion algorithm to reconstruct WordNet?s Animal hi-erarchy, which is one of its most complete and elab-orated.
In addition, we have also evaluated the per-formance of our algorithm with the Plant and Vehi-cle WordNet hierarchies.Currently, our automated taxonomization algo-rithm is able to build some of the quasi-independentperspectival taxonomies (Hovy et al, 2009).
How-ever, further research is required to develop methodsthat reliably (a) identify the number of independentperspectives a concept can take (or seems to take inthe domain text), and (b) classify any harvested terminto one or more of them.
The result would greatlysimplify the task of the taxonomization stage.We note that despite this richness, WordNet hasmany concepts like camelid, filter feeder, mono-gastrics among others which are missing, but theharvesting algorithm can provide.
Another promis-ing line of research would investigate the combina-tion of the two styles of taxonomization algorithms:first, the one described here to produce an initial (setof) taxonomies, and second, the term-insertion algo-rithms developed in prior work.AcknowledgmentsWe acknowledge the support of DARPA contractnumber FA8750-09-C-3705.
We thank Mark John-son for the valuable discussions on taxonomy evalu-ation.
We thank the reviewers for their useful feed-back and suggestions.ReferencesDmitry Davidov and Ari Rappoport.
2006.
Efficient un-supervised discovery of word categories using sym-metric patterns and high frequency words.
In Proceed-ings of the 21st International Conference on Compu-tational Linguistics and the 44th annual meeting of theACL, pages 297?304.Dmitry Davidov, Ari Rappoport, and Moshel Koppel.2007.
Fully unsupervised discovery of concept-specific relationships by web mining.
In Proceedingsof the 45th Annual Meeting of the Association of Com-putational Linguistics, pages 232?239.Oren Etzioni, Michael Cafarella, Doug Downey, Ana-Maria Popescu, Tal Shaked, Stephen Soderland,Daniel S. Weld, and Alexander Yates.
2005.
Unsuper-vised named-entity extraction from the web: an exper-imental study.
Artificial Intelligence, 165(1):91?134,June.Roxana Girju, Adriana Badulescu, and Dan Moldovan.2003.
Learning semantic constraints for the automaticdiscovery of part-whole relations.
In Proceedings ofthe 2003 Conference of the North American Chapter ofthe Association for Computational Linguistics on Hu-man Language Technology, pages 1?8.Oren Glickman, Ido Dagan, and Moshe Koppel.
2005.A probabilistic classification approach for lexical tex-tual entailment.
In Proceedings, The Twentieth Na-tional Conference on Artificial Intelligence and theSeventeenth Innovative Applications of Artificial Intel-ligence Conference, pages 1050?1055.Marti Hearst.
1992.
Automatic acquisition of hyponymsfrom large text corpora.
In Proceedings of the 14thconference on Computational linguistics, pages 539?545.Eduard H. Hovy, Zornitsa Kozareva, and Ellen Riloff.2009.
Toward completeness in concept extraction andclassification.
In Proceedings of the 2009 Conferenceon Empirical Methods in Natural Language Process-ing, EMNLP 2009, pages 948?957.Eduard Hovy.
2002.
Comparing sets of semantic rela-tions in ontologies.
The Semantics of Relationships:An Interdisciplinary Perspective, pages 91?110.Boris Katz and Jimmy Lin.
2003.
Selectively using rela-tions to improve precision in question answering.
In InProceedings of the EACL-2003 Workshop on NaturalLanguage Processing for Question Answering, pages43?50.Zornitsa Kozareva, Ellen Riloff, and Eduard Hovy.
2008.Semantic class learning from the web with hyponympattern linkage graphs.
In Proceedings of ACL-08:HLT, pages 1048?1056.Dekang Lin and Patrick Pantel.
2002.
Concept discoveryfrom text.
In Proceedings of the 19th internationalconference on Computational linguistics, pages 1?7.Dekang Lin.
1998.
Automatic retrieval and clusteringof similar words.
In Proceedings of the 17th interna-tional conference on Computational linguistics, pages768?774.Dan I. Moldovan, Sanda M. Harabagiu, Marius Pasca,Rada Mihalcea, Richard Goodrum, Roxana Girju, andVasile Rus.
1999.
Lasso: A tool for surfing the answernet.
In TREC.Patrick Pantel and Marco Pennacchiotti.
2006.
Espresso:Leveraging generic patterns for automatically harvest-ing semantic relations.
In Proceedings of 21st Interna-tional Conference on Computational Linguistics and111744th Annual Meeting of the Association for Computa-tional Linguistics, ACL 2006.Marius Pasca.
2004.
Acquisition of categorized namedentities for web search.
In Proceedings of the thir-teenth ACM international conference on Informationand knowledge management, pages 137?145.Marco Pennacchiotti and Patrick Pantel.
2006.
Ontolo-gizing semantic relations.
In ACL-44: Proceedings ofthe 21st International Conference on ComputationalLinguistics and the 44th annual meeting of the Associ-ation for Computational Linguistics, pages 793?800.Ellen Riloff and Jessica Shepherd.
1997.
A Corpus-Based Approach for Building Semantic Lexicons.
InProceedings of the Second Conference on EmpiricalMethods in Natural Language Processing, pages 117?124.Alan Ritter, Stephen Soderland, and Oren Etzioni.
2009.What is this, anyway: Automatic hypernym discovery.In Proceedings of AAAI Spring Symposium on Learn-ing by Reading and Learning to Read.Alan Ritter, Mausam, and Oren Etzioni.
2010.
A la-tent dirichlet alocation method for selectional prefer-ences.
In to appear in Proceedings of the Associationfor Computational Linguistics ACL2010.Eleanor Rosch.
1978.
Principles of categorization.Rion Snow, Daniel Jurafsky, and Andrew Y. Ng.
2006.Semantic taxonomy induction from heterogenous ev-idence.
In Proceedings of 21st International Confer-ence on Computational Linguistics and 44th AnnualMeeting of the Association for Computational Linguis-tics, ACL.Fabian M. Suchanek, Gjergji Kasneci, and GerhardWeikum.
2007.
Yago: a core of semantic knowledge.In WWW ?07: Proceedings of the 16th internationalconference on World Wide Web, pages 697?706.Idan Szpektor, Ido Dagan, Roy Bar-Haim, and JacobGoldberger.
2008.
Contextual preferences.
In ACL2008, Proceedings of the 46th Annual Meeting ofthe Association for Computational Linguistics, pages683?691.Dominic Widdows.
2003.
Unsupervised methods for de-veloping taxonomies by combining syntactic and sta-tistical information.
In Proceedings of HLT-NAACL.Hui Yang and Jamie Callan.
2009.
A metric-basedframework for automatic taxonomy induction.
InACL-IJCNLP ?09: Proceedings of the Joint Confer-ence of the 47th Annual Meeting of the ACL and the 4thInternational Joint Conference on Natural LanguageProcessing of the AFNLP: Volume 1, pages 271?279.1118
