Proceedings of the Sixth Workshop on Innovative Use of NLP for Building Educational Applications, pages 65?75,Portland, Oregon, 24 June 2011. c?2011 Association for Computational LinguisticsExploring Effective Dialogue Act Sequencesin One-on-one Computer Science Tutoring DialoguesLin Chen, Barbara Di EugenioComputer ScienceU.
of Illinois at Chicagolchen43,bdieugen@uic.eduDavide FossatiComputer ScienceCarnegie Mellon U. in Qatardavide@fossati.usStellan Ohlsson, David CosejoPsychologyU.
of Illinois at Chicagostellan,dcosej1@uic.eduAbstractWe present an empirical study of one-on-one human tutoring dialogues in the domainof Computer Science data structures.
Weare interested in discovering effective tutor-ing strategies, that we frame as discoveringwhich Dialogue Act (DA) sequences corre-late with learning.
We employ multiple lin-ear regression, to discover the strongest mod-els that explain why students learn duringone-on-one tutoring.
Importantly, we define?flexible?
DA sequence, in which extraneousDAs can easily be discounted.
Our experi-ments reveal several cognitively plausible DAsequences which significantly correlate withlearning outcomes.1 IntroductionOne-on-one tutoring has been shown to be a very ef-fective form of instruction compared to other educa-tional settings.
Much research on discovering whythis is the case has focused on the analysis of theinteraction between tutor and students (Fox, 1993;Graesser et al, 1995; Lepper et al, 1997; Chi et al,2001).
In the last fifteen years, many such analyseshave been approached from a Natural Language Pro-cessing (NLP) perspective, with the goal of build-ing interfaces that allow students to naturally inter-act with Intelligent Tutoring Systems (ITSs) (Mooreet al, 2004; Cade et al, 2008; Chi et al, 2010).There have been two main types of approaches tothe analysis of tutoring dialogues.
The first kindof approach compares groups of subjects interact-ing with different tutors (Graesser et al, 2004; Van-Lehn et al, 2007), in some instances contrasting thenumber of occurrences of relevant features betweenthe groups (Evens and Michael, 2006; Chi et al,2010).
However, as we already argued in (Ohlssonet al, 2007), this code-and-count methodology onlyfocuses on what a certain type of tutor (assumed tobe better according to certain criteria) does differ-ently from another tutor, rather than on strategiesthat may be effective independently from their fre-quencies of usage by different types of tutor.
Indeedwe had followed this same methodology in previouswork (Di Eugenio et al, 2006), but a key turningpoint for our work was to discover that our expertand novice tutors were equally effective (please seebelow).The other kind of approach uses linear regressionanalysis to find correlations between dialogue fea-tures and learning gains (Litman and Forbes-Riley,2006; Di Eugenio et al, 2009).
Whereas linearregression is broadly used to analyze experimentaldata, only few analyses of tutorial data or tutoringexperiments use it.
In this paper, we followLitman and Forbes-Riley (2006) in correlating se-quences of Dialogue Acts (DAs) with learning gains.We extend that work in that our bigram and trigramDAs are not limited to tutor-student DA bigrams ?Litman and Forbes-Riley (2006) only considers bi-grams where one DA comes from the tutor?s turnand one from the student?s turn, in either order.
Im-portantly, we further relax constraints on how thesesequences are built, in particular, we are able tomodel DA sequences that include gaps.
This allowsus to discount the noise resulting from interveningDAs that do not contribute to the effectiveness ofthe specific sequence.
For example, if we want to65explore sequences in which the tutor first providessome knowledge to solve the problem (DPI) andthen knowledge about the problem (DDI) (DPI andDDI will be explained later), an exchange such asthe one in Figure 1 should be taken into account(JAC and later LOW are the tutors, students are indi-cated with a numeric code, such as 113 in Figure 1).However, if we just use adjacent utterances, the okfrom the student (113) interrupts the sequence, andwe could not take this example into account.
By al-lowing gaps in our sequences, we test a large numberof linear regression models, some of which result insignificant models that can be used as guidelines todesign an ITS.
Specifically, these guidelines will beused for further improvement of iList, an ITS thatprovides feedback on linked list problems and thatwe have developed over the last few years.
Fivedifferent versions of iList have been evaluated with220 users (Fossati et al, 2009; Fossati et al, 2010).iList is available at http://www.digitaltutor.net, andhas been used by more than 550 additional users at15 different institutions.JAC: so we would set k equal to e and then delete.
[DPI]113: ok.JAC: so we?ve inserted this whole list in here.
[DDI]113: yeah.Figure 1: {DPI, DDI} Sequence ExcerptThe rest of the paper is organized as follows.In Section 2, we describe the CS-Tutoring corpus,including data collection, transcription, and anno-tation.
In Section 3, we introduce our methodol-ogy that combines multiple linear regression with n-grams of DAs that allow for gaps.
We discuss ourexperiments and results in Section 4.2 The CS Tutoring Corpus2.1 Data CollectionDuring the time span of 3 semesters, we collected acorpus of 54 one-on-one tutoring sessions on Com-puter Science data structures: linked list, stack andbinary search tree.
(In the following context, wewill refer them as Lists, Stacks and Trees).
Each stu-dent only participated in one session, and was ran-domly assigned to one of two tutors: LOW, an expe-rienced Computer Science professor, with more than30 years of teaching experience; or JAC, a senior un-dergraduate student in Computer Science, with onlyone semester of previous tutoring experience.
In theend 30 students interacted with LOW and 24 withJAC.Students took a pre-test right before the tutoringsession, and an identical post-test immediately after.The test had two problems on Lists, two problems onStacks, and four problems on Trees.
Each problemwas graded out of 5 points, for a possible maximumscore of 10 points each for Lists and Stacks, and 20points for Trees.
Pre and post-test scores for eachtopic were later normalized to the [0..1] interval, andlearning gains were computed.Table 1 includes information on session length.Note that for each topic, the number of sessions islower than 54.
The tutor was free to tutor on whathe felt was more appropriate, after he was given aninformal assessment of the student?s performance onthe pre-test (tutors were not shown pre-tests to avoidthat they?d tutor to the pre-test only).
Hence, notevery student was tutored on every topic.Topic N Session length (minutes)Min Max Total ?
?Lists 52 3.4 41.4 750.4 14.4 5.8Stacks 46 0.3 9.4 264.5 5.8 1.8Trees 53 9.1 40.0 1017.6 19.2 6.6Sessions 54 12.8 61.1 2032.5 37.6 6.1Table 1: CS Tutoring Corpus - DescriptivesEach tutoring session was videotaped.
The cam-era was pointing at the sheets of paper on which tu-tors and students were writing during the session.The videos were all transcribed.
The transcriptswere produced according to the rules and conven-tions described in the transcription manual of theCHILDES project (MacWhinney, 2000).
Dialogueexcerpts included in this paper show some of thetranscription conventions.
For example, ?+...?denotes trailing, ?xxx?
unintelligible speech and?#?
a short pause (see Figure 2).
The CHILDEStranscription manual also provides directions on ut-terance segmentation.An additional group of 53 students (controlgroup) took the pre- and post-tests, but instead ofparticipating in a tutoring session they attended a40 minute lecture about an unrelated CS topic.
Therationale for such a control condition was to assess66LOW: what?s the if?
[Prompt]LOW: well of course, don?t do this if t two is null so if ttwo isn?t null we can do that and xxx properly # thinkingI put it in here.
[DPI]LOW: or else if t two is null that?s telling us that this isthe +.
.
.
[Prompt,FB]Figure 2: {Prompt,DPI,FB} sequence excerptwhether by simply taking the pre-test students wouldlearn about data-structures, and hence, to tease outwhether any learning we would see in the tutoredconditions would be indeed due to tutoring.The learning gain, expressed as the differencebetween post-score and pre-score, of students thatreceived tutoring was significantly higher than thelearning gain of the students in the control group, forall the topics.
This was showed by ANOVA betweenthe aggregated group of tutored students and thecontrol group, and was significant at the p < 0.01for each topic.
There was no significant differencebetween the two tutored conditions in terms of learn-ing gain.
The fact that students did not learn morewith the experienced tutor was an important findingthat led us to question the approach of comparingand contrasting more and less experienced tutors.Please refer to (Di Eugenio et al, 2009) for furtherdescriptive measurements of the corpus.2.2 Dialogue Act AnnotationMany theories have been proposed as concerns DAs,and there are many plausible inventories of DAs, in-cluding for tutorial dialogue (Evens and Michael,2006; Litman and Forbes-Riley, 2006; Boyer et al,2010).
We start from a minimalist point of view,postulating that, according to current theories ofskill acquisition (Anderson, 1986; Sun et al, 2005;Ohlsson, 2008), at least the following types of tuto-rial intervention can be explained in terms of whyand how they might support learning:1.
A tutor can tell the student how to perform thetask.2.
A tutor can state declarative information aboutthe domain.3.
A tutor can provide feedback:(a) positive, to confirm that a correct but tentativestep is in fact correct;(b) negative, to help a student detect and correct anerror.We first read through the entire corpus and exam-ined it for impressions and trends, as suggested by(Chi, 1997).
Our informal assessment convinced usthat our minimalist set of tutoring moves was an ap-propriate starting point.
For example, contrary tomuch that has been written about an idealized so-cratic type of tutoring where students build knowl-edge by themselves (Chi et al, 1994), our tutorsare rather directive in style, namely, they do a lotof telling and stating.
Indeed our tutors talk a lot,to the tune of producing 93.5% of the total words!We translated the four types above into the follow-ing DAs: Direct Procedural Instruction (DPI), Di-rect Declarative Instruction (DDI), Positive Feed-back (+FB), and Negative Feedback (-FB).
Besidesthose 4 categories, we additionally annotated thecorpus for Prompt (PT), since our tutors did explic-itly invite students to be active in the interaction.We also annotated for Student Initiative (SI), to cap-ture active participation on the part of the student?s.SI occurs when the student proactively produces ameaningful utterance, by providing unsolicited ex-planation (see Figures 6 and 4), or by asking ques-tions.
As we had expected, SIs are not as frequent asother moves (see below).
However, this is preciselythe kind of move that a regression analysis wouldtease out from others, if it correlates with learning,even if it occurs relatively infrequently.
This indeedhappens in two models, see Table 8.Direct Procedural Instruction(DPI) occurs whenthe tutor directly tells the student what task to per-form.
More specifically:?
Utterances containing correct steps that lead tothe solution of a problem, e.g.
see Figure 1.?
Utterances containing high-level steps or sub-goals (it wants us to put the new node that con-tains G in it, after the node that contains B).?
Utterances containing tactics and strategies (sowith these kinds of problems, the first thing Ihave to say is always draw pictures).?
Utterances where the tutor talked in the first-person but in reality the tutor instructed the stu-dent on what to do (So I?m pushing this valueonto a stack.
So I?m pushing G back on).Direct Declarative Instruction (DDI) occurredwhen the tutor provided facts about the domain or67a specific problem.
The key to determine if an ut-terance is DDI is that the tutor is telling the studentsomething that he or she ostensibly does not alreadyknow.
Common sense knowledge is not DDI ( tenis less than eleven ).
Utterances annotated as DDIinclude:?
Providing general knowledge about data struc-tures (the standard format is right child is al-ways greater than the parent, left child is al-ways less than the parent).?
Telling the student information about a specificproblem (this is not a binary search tree).?
Conveying the results of a given action (so nowsince we?ve eliminated nine, it?s gone).?
Describing pictures of data structures (and thenthere is a link to the next node).Prompts (PT) occur when the tutor attempts toelicit a meaningful contribution from the student.We code for six types of tutor prompts, including:?
Specific prompt: An attempt to get a specificresponse from the student (that?s not b so whatdo we want to do?).?
Diagnosing: The tutor attempts to determinethe student?s knowledge state (why did you puta D there?).?
Confirm-OK: The tutor attempts to determine ifthe student understood or if the student is pay-ing attention (okay, got that idea?).?
Fill-in-the-blank: The tutor does not completean utterance thereby inviting the student tocomplete the utterance, e.g.
see Figure 2.Up to now we have discussed annotations for ut-terances that do not explicitly address what the stu-dent has said or done.
However, many tutoringmoves concern providing feedback to the student.Indeed as already known but not often acted upon inITS interfaces, tutors do not just point out mistakes,but also confirm that the student is making correctsteps.
While the DAs discussed so far label singleutterances, our positive and negative feedback (+FBand -FB) annotations comprise a sequence of con-secutive utterances, that starts where the tutor startsproviding feedback.
We opted for a sequence of ut-terances rather than for labeling one single utterancebecause we found it very difficult to pick one singleutterance as the one providing feedback, when thetutor may include e.g.
an explanation that we con-sider to be part of feedback.
Positive feedback oc-curs when the student says or does something cor-rect, either spontaneously or after being promptedby the tutor.
The tutor acknowledges the correctnessof the student?s utterance, and possibly elaborates onit with further explanation.
Negative feedback oc-curs when the student says or does something incor-rect, either spontaneously or after being promptedby the tutor.
The tutor reacts to the mistake and pos-sibly provides some form of explanation.After developing a first version of the codingmanual, we refined it iteratively.
During each itera-tion, two human annotators independently annotatedseveral dialogues for one DA at a time, comparedoutcomes, discussed disagreements, and fine-tunedthe scheme accordingly.
This process was repeateduntil a sufficiently high inter-coder agreement wasreached.
The Kappa values we obtained in the fi-nal iteration of this process are listed in Table 2(Di Eugenio and Glass, 2004; Artstein and Poesio,2008).
In Table 2, the ?Double Coded*?
columnrefers to the sessions that we double coded to cal-culate the inter-coder agreement.
This number doesnot include the sessions which were double codedwhen coders were developing the coding manual.The numbers of double-coded sessions differ by DAsince it depends on the frequency on the particularDA (recall that we coded for one DA at a time).For example, since Student Initiatives (SI) are not asfrequent, we needed to double code more sessionsto find a number of SI?s high enough to compute ameaningful Kappa (in our whole corpus, there are1157 SIs but e.g.
4957 Prompts).Category Double Coded* KappaDPI 10 .7133Feedback 5 .6747DDI 10 .8018SI 14 .8686Prompt 8 .9490Table 2: Inter-Coder Agreement in CorpusThe remainder of the corpus was then indepen-dently annotated by the two annotators.
For ourfinal corpus, for the double coded sessions we didnot come to a consensus label when disagreementsarose; rather, we set up a priority order based on68topic and coder (e.g., during development of thecoding scheme, when coders came to consensuscoding, which coder?s interpretation was chosenmore often), and we chose the annotation by a cer-tain coder based on that order.As a final important note, given our codingscheme some utterances have more than one label(see Figures 2 and 4), whereas others are not la-belled at all.
Specifically, most student utterances,and some tutor utterances, are not labelled (see Fig-ures 1 and 4).3 Method3.1 Linear Regression ModelsIn this work, we adopt a multiple regression model,because it can tell us how much variation in learningoutcomes is explained by the variation of individualfeatures in the data.
The features we use include pre-test score, the length of the tutoring sessions, andDAs, both the single DAs we annotated for and DAn-grams, i.e.
DA sequences of length n. Pre-testscore is always included since the effect of previ-ous knowledge on learning is well established, andconfirmed in our data (see all Models 1 in Table 4);indeed multiple linear regression allows us to factorout the effect of previous knowledge on learning, byquantifying the predictive power of features that areadded beyond pre-test score.3.2 n-gram Dialogue Act Modeln-grams (sequences of n units, such as words, POStags, dialogue acts) have been used to derive lan-guage models in computational linguistics for a longtime, and have proven effective in tasks like part-of-speech tagging, spell checking.Our innovation with regard to using DA n-gramsis to allow gaps in the sequence.
This allows usto extract the sequences that are really effective,and to eliminate noise.
Note that from the pointof view of an effective sequence, noise is anythingthat does not contribute to the sequence.
For ex-ample, a tutor?s turn may be interrupted by a stu-dent?s acknowledgments, such as ?OK?
or ?Uh-hah?
(see Figure 1).
Whereas these acknowledgmentsperform fundamental functions in conversation suchas grounding (Clark, 1992), they may not directlycorrelate with learning (a hypothesis to test).
If wecounted them in the sequence, they would contributetwo utterances, transforming a 3 DA sequence into a5 DA sequence.
As well known, the higher the n, thesparser the data becomes, i.e., the fewer sequencesof length n we find, making the task of discover-ing significant correlations all the harder.
Note thatsome of the bigrams in (Litman and Forbes-Riley,2006) could be considered to have gaps, since theypair one student move (say SI) with each tutor movecontained in the next tutor turn (eg, in our Figure 6they would derive two bigrams [SI, FB], and [SI,Prompt]).
However, this does not result in a system-atic exploration of all possible sequences of a certainlength n, with all possible gaps of length up to m, aswe do here.The tool that allows us to leave gaps in sequencesis part of Apache Lucene,1 an open source full textsearch library.
It provides strong capabilities tomatch and count efficiently.
Our counting methodis based on two important features provided byLucene, that we already used in other work (Chenand Di Eugenio, 2010) to detect uncertainty in dif-ferent types of corpora.?
Synonym matching: We can specify severaldifferent tokens at the same position in a fieldof a document, so that each of them can be usedto match the query.?
Precise gaps: With Lucene, we can preciselyspecify the gap between the matched query andthe indexed documents (sequences of DAs inour case) using a special type of query calledSpanNearQuery.To take advantage of Lucene as described above,we use the following algorithm to index our corpus.1.
For each Tutor-Topic session, we generate n-gram utterance sequences ?
note that these aresequences of utterances at this point, not ofDAs.2.
We prune utterance sequences where either 0or only 1 utterance is annotated with a DA, be-cause we are mining sequences with at least 2DAs.
Recall that given our annotation, some ut-terances are not annotated (see e.g.
Figure 1).3.
After pruning, for each utterance sequence, wegenerate a Lucene document: each DA label onan utterance will be treated as a token, multiple1http://lucene.apache.org/69labels on the same utterance will be treated as?synonyms?.By indexing annotations as just described, weavoid the problem of generating too many combina-tions of labels.
After indexing, we can use SpanN-earQuery to query the index.
SpanNearQuery allowsus to specify the position distance allowed betweeneach term in the query.Figure 3 is the field of the generated Lucene doc-ument corresponding to the utterance sequences inFigure 4.
We can see that each utterance of the tu-tor is tagged with 2 DAs.
Those 2 DAs produce 2tokens, which are put into the same position.
Thetokens in the same position act as synonyms to eachother during the query.Figure 3: Lucene Document Example for DAs258: okay.JAC: its right child is eight.
[DDI, FB]258: uh no it has to be greater than ten.
[SI]JAC: right so it?s not a binary search tree # it?s not a b s t,right?
[DDI,Prompt]Figure 4: {FB, SI, DDI} is most effective in Trees4 Experiments and ResultsHere we build on our previous results reportedin (Di Eugenio et al, 2009).
There we had shownthat, for lists and stacks, models that include positiveand negative feedback are significant and explainmore of the variance with respect to models that onlyinclude pre-test score, or include pre-test score andsession length.
Table 4 still follows the same ap-proach, but adds to the regression models the addi-tional DAs, DPI, DDI, Prompt and SI that had notbeen included in that earlier work.
The column Mrefers to three types of models, Model 1 only in-cludes Pre-test, Model 2 adds session length to Pre-test, and Model 3 adds to Pre-test all the DAs.
As ev-idenced by the table, only DPI provides a marginallysignificant contribution, and only for lists.
Note thatlength is not included in Model 3?s.
We did run allthe equivalent models to Model 3?s including length.The R2?s stay the same (literally, to the second dec-imal digit), or minimally decrease.
However, in allthese Model 3+?s that include length no DA is sig-nificant, hence we consider them as less explana-tory than the Model 3?s in Table 4: finding that alonger dialogue positively affects learning does nottell us what happens during that dialogue which isconducive to learning.Note that the ?
weights on the pre-test are al-ways negative in every model, namely, students withhigher pre-test scores learn less than students withlower pre-test scores.
This is an example of the well-known ceiling effect: students with more previousknowledge have less learning opportunity.
Also no-ticeable is that the R2 for the Trees models are muchhigher than for Lists and Stacks, and that for Treesno DA is significant (although there will be signifi-cant trigram models that involve DAs for Trees).
Wehave observed that Lists are in general more diffi-cult than Stacks and Trees (well, at least than binarysearch trees) for students.Topic Pre-Test ?
Gain ?Lists .40 .27 .14 .25Stacks .29 .30 .31 .24Trees .50 .26 .30 .24Table 3: Learning gains and t-test statisticsIndeed Table 3 shows that in the CS-tutoring cor-pus the average learning gain is only .14 for Lists,but .31 for Stacks and .30 for Trees; whereas stu-dents have the lowest pre-test score on Stacks, andhence they have more opportunities for learning,they learn as much for Trees, but not for Lists.We now examine whether DA sequences help usexplain why student learn.
We have run 24 sets oflinear regression experiments, which are grouped asthe following 6 types of models.?
With DA bigrams (DA sequences of length 2):?
Gain ?
DA Bigram?
Gain ?
DA Bigram + Pre-test Score?
Gain ?
DA Bigram + Pre-test Score +Session Length?
With DA trigrams (DA sequences of length 3):?
Gain ?
DA Trigram?
Gain ?
DA Trigram + Pre-test Score?
Gain ?
DA Trigram + Pre-test Score +Session LengthFor each type of model:70Topic M Predictor ?
R2 PLists1 Pre-test ?.47 .20 < .0012Pre-test ?.43 .29 < .001Length .01 < .0013Pre-test ?.500.377< .001+FB .020 < .01-FB .039 nsDPI .004 < .1DDI .001 nsSI .005 nsPrompt .001 nsStacks1 Pre-test ?.46 .296 < .0012 Pre-test ?.46 .280 < .001Length ?.002 ns3Pre-test ?.465.275< .001+FB ?.017 < .01-FB ?.045 nsDPI .007 nsDDI .001 nsSI .008 nsPrompt ?.006 nsTrees1 Pre-test ?.739 .676 < .0012 Pre-test ?.733 .670 < .001Length .001 ns3Pre-test ?.712.667< .001+FB ?.002 ns-FB ?.018 nsDPI ?.001 nsDDI ?.001 nsSI ?.001 nsPrompt ?.001 nsAll1 Pre-test ?.505 .305 < .0012 Pre-test ?.528 .338 < .001Length .06 < .0013Pre-test ?.573.382< .001+FB .009 < .001-FB ?.024 nsDPI .001 nsDDI .001 nsSI .001 nsPrompt .001 nsTable 4: Linear Regression ?
Human Tutoring1.
We index the corpus according to the length ofthe sequence (2 or 3) using the method we in-troduced in section 3.2.2.
We generate all the permutations of all the DAswe annotated for within the specified length;count the number of occurrences of each per-mutation using Lucene?s SpanNearQuery al-lowing for gaps of specified length.
Gaps canspan from 0 to 3 utterances; for example, theexcerpt in Figure 1 will be counted as a {DPI,DDI} bigram with a gap of length 1.
Gaps canbe discontinuous.3.
We run linear regressions2 on the six types ofmodels listed above, generating actual modelsby replacing a generic DA bi- or tri-gram witheach possible DA sequence we generated instep 2.4.
We output those regression results, in which thewhole model and every predictor are at leastmarginally significant (p < 0.1).The number of generated significant models isshown in Figure 5.
In the legend of the Figure,B stands for Bigram DA sequence, T stands forTrigram DA sequence, L stands for session Length,P stands for Pre-test score.
Not surprisingly, Fig-ure 5 shows that, as the allowed gap increases inlength, the number of significant models increasestoo, which give us more models to analyze.0102030405060Gap AllowedNumber of Significant Models0 1 2 3?????????
?PredictorsTT+PT+P+LBB+PB+P+LFigure 5: Gaps Allowed vs.
Significant ModelsFigure 5 shows that there are a high number ofsignificant models.
In what follows we will presentfirst of all those that improve on the models thatdo not use sequences of DAs, as presented in Ta-ble 4.
Improvement here means not only that theR2 is higher, but that the model is more appropriateas an approximation of a tutor strategy, and hence,constitutes a better guideline for an ITS.
For exam-ple, take model 3 for Lists in Table 4.
It tells usthat positive feedback (+FB) and direct proceduralinstruction (DPI) positively correlate with learning2We used rJava, http://www.rforge.net/rJava/71gains.
However, this obviously cannot mean that ourITS should only produce +FB and DPI.
The ITS isinteracting with the student, and it needs to tune itsstrategies according to what happens in the interac-tion; model 3 doesn?t even tell us if +FB and DPIshould be used together or independently.
Modelsthat include sequences of DAs will be more usefulfor the design of an ITS, since they point out whatsequences of DAs the ITS may use, even if they stilldon?t answer the question, when should the ITS en-gage in a particular sequence ?
we have addressedrelated issues in our work on iList (Fossati et al,2009; Fossati et al, 2010).4.1 Bigram Models{DPI, Feedback} Model Indeed the first signifi-cant models that include a DA bigram include the{DPI, Feedback} DA sequence.
Note that we distin-guish between models that employ Feedback (FB)without distinguishing between positive and nega-tive feedback; and models where the type of feed-back is taken into account (+FB, -FB).
Table 5 showsthat for Lists, a sequence that includes DPI followedby any type of feedback (Feedback, +FB, -FB) pro-duces significant models when the model includespre-test.
Table 5 and all tables that follow includethe column Gap that indicates the length of the gapwithin the DA sequence with which that model wasobtained.
When, as in Table 5, multiple numbersappear in the Gap column, this indicates that themodel is significant with all those gap settings.
Weonly show the ?, R2 and P values for the gap lengthwhich generates the highest R2 for a model, and thecorresponding gap length is in bold font: for exam-ple, the first model for Lists in Table 5 is obtainedwith a gap length = 2.
For Lists, these models are notas predictive as Model 3 in Table 4, however we be-lieve they are more useful from an ITS design pointof view: they tell us that when the tutor gives directinstruction on how to solve the problem, within ashort span of dialogue the tutor produces feedback,since (presumably) the student will have tried to ap-ply that DPI.
For Stacks, a {DPI, -FB} model (with-out taking pre-test into account) significantly corre-lates (p < 0.05) with learning gain, and marginallysignificantly correlates with learning gain when themodel also includes pre-test score.
This latter modelis actually more predictive than Model 3 for Stacksin Table 4 that includes +FB but not DPI.
We cansee the ?
weight is negative for the sequence {DPI,-FB} in the Stacks model.
No models including thebigram {DPI, -FB} are significant for Trees.Topic Predictor ?
R2 P GapListsDPI, -FB .039 .235 <.001 2, 3Pre-test ?.513 < .001DPI, +FB .019.339<.0010, 1, 2, 3Pre-test ?.492 < .001Length .011 < 0.05DPI, FB .016.333<.050, 1, 2, 3Pre-test ?.489 < .001Length .011 < 0.05StacksDPI, -FB ?.290 .136 <.05 0, 1, 2, 3DPI, -FB ?.187 .342 <.1 0, 1, 2, 3Pre-test ?.401 < .001Table 5: DPI, Feedback Model{FB, DDI} Model A natural question arises:since Feedback following DPI results in significantmodels, are there any significant models which in-clude sequences whose first component is a Feed-back move?
We found only two that are signif-icant, when Feedback is followed by DDI (DirectDeclarative Instruction).
Note that here we are notdistinguishing between negative and positive feed-back.
Those models are shown in Table 6.
TheLists model is not more effective than the originalModel 3 for Lists in Table 4, but the model for Treesis slightly more explanatory than the best modelfor Trees in that same table, and includes a bigrammodel, whereas in Table 4, only pre-test is signifi-cant for Trees.Topic Predictor ?
R2 P GapListsFB, DDI .1478.321<.11Pre-test ?.470 < .001Length .011 < .05Trees FB, DDI .0709 .6953 <.05 0Pre-test ?.7409 < .001Table 6: {FB, DDI} Model4.2 Trigram Models{DPI, FB, DDI} Model Given our significant bi-gram models for DPI followed by FB, and FB fol-lowed by DDI, it is natural to ask whether the com-bined trigram model {DPI, FB, DDI} results in asignificant model.
It does for the topic List, asshown in table 7, however again the R2 is lower than72that of Model 3 in Table 4.
This suggests that an ef-fective tutoring sequence is to provide instruction onhow to solve the problem (DPI), then Feedback onwhat the student does, and finally some declarativeinstruction (DDI).Topic Predictor ?
R2 P GapListsDPI, FB, DDI .156.371<.011Pre-test ?.528 < .001Length .012 < .05Table 7: {DPI, FB, DDI} ModelMore effective trigram models include Promptand SI.
Up to now, only one model including se-quences of DAs was superior to the simpler modelsin Table 4.
Interestingly, different trigrams that stillinclude some form of Feedback, DPI or DDI, andthen either Prompt or SI (Student Initiative) result inmodels that exhibit slightly higher R2; additionallyin all these models the trigram predictor is highlysignificant.
These models are listed in table 8 (notethat the two Trees models differ because in one FB isgeneric Feedback, irregardless of orientation, in theother it?s +FB, i.e., positive feedback).
In detail, im-provements in R2 are 0.0382 in topic Lists, 0.12 intopic Stacks and 0.0563 in topic Trees.
The highestimprovement is in Stacks.Topic Predictor ?
R2 P GapListsPT,DPI,FB .266.415<.010Pre-test ?.463 < .001Length .011 < .05Stacks DDI,FB,PT ?.06 .416 <.01 1Pre-test ?.52 < .001Trees +FB,SI,DDI .049 .732 <.01 1Pre-test ?.746 < .001Trees FB,SI,DDI .049 .732 <.01 1Pre-test ?.746 < .001Table 8: Highest R2 ModelsIt is interesting to note that the model for Lists addPrompt at the beginning to a bigram that had alreadybeen found to contribute to a significant model.
ForTrees, likewise, we add another DA to the bigram{FB,DDI} that had been found to be significant; thistime, it is Student Initiative (SI) and it occurs inthe middle.
This indicates that, after the tutor pro-vides feedback, the student takes the initiative, andthe tutor responds with one piece of information thestudent didn?t know (DDI).
Of course, the role ofPrompts and SI is not surprising, although interest-ingly they are significant only in association withcertain tutor moves.
It is well known that studentslearn more when they build knowledge by them-selves, either by taking the initiative (SI), or afterthe tutor prompts them to do so (Chi et al, 1994;Chi et al, 2001).LOW: it?s backwards # it?s got four elements, but theyare backwards.
[DDI]234: so we have do it again.
[SI]LOW: so do it again.
[FB]LOW: do what again?
[Prompt]Figure 6: {DDI, FB, PT} is most effective in Stacks4.3 Other modelsWe found other significant models, specifically,{DDI,DPI} for all three topics, and {-FB,SI} forLists.
However, their R2 are very low, and muchlower than any of the other models presented sofar.
Besides models that include only one DA se-quence and pre-test score to predict learning gain,we also ran experiments to see if adding multipleDA sequences to pre-test score will lead to signifi-cant models ?
namely, we experimented with mod-els which include two sequences as predictors, say,the two bigrams {-FB,SI} and {FB,DDI}.
However,no significant models were found.5 ConclusionsIn this paper, we explored effective tutoring strate-gies expressed as sequence of DAs.
We first pre-sented the CS-Tutoring corpus.
By relaxing the DAn-gram definition via the fuzzy matching providedby Apache Lucene, we managed to discover severalDA sequences that significantly correlate with learn-ing gain.
Further, we discovered models with higherR2 than models which include only one single DA,which are also more informative from the point ofview of the design of interfaces to ITSs.6 AcknowledgmentsThis work was mainly supported by ONR (N00014-00-1-0640), and by the UIC Graduate College(2008/2009 Dean?s Scholar Award).
Partial sup-port is also provided by NSF (ALT-0536968, IIS-0905593).73ReferencesJohn R. Anderson.
1986.
Knowledge compilation: Thegeneral learning mechanism.
Machine learning: Anartificial intelligence approach, 2:289?310.Ron Artstein and Massimo Poesio.
2008.
Inter-coderagreement for computational linguistics.
Computa-tional Linguistics, 34(4):555?596.
Survey Article.Kristy Elizabeth Boyer, Robert Phillips, Amy Ingram,Eun Young Ha, Michael Wallis, Mladen Vouk, andJames Lester.
2010.
Characterizing the effectivenessof tutorial dialogue with Hidden Markov Models.
InIntelligent Tutoring Systems, pages 55?64.
Springer.Whitney L. Cade, Jessica L. Copeland, Natalie K. Per-son, and Sidney K. D?Mello.
2008.
Dialogue modesin expert tutoring.
In Intelligent Tutoring Systems,volume 5091 of Lecture Notes in Computer Science,pages 470?479.
Springer Berlin / Heidelberg.Lin Chen and Barbara Di Eugenio.
2010.
A luceneand maximum entropy model based hedge detectionsystem.
In Proceedings of the Fourteenth Confer-ence on Computational Natural Language Learning,pages 114?119, Uppsala, Sweden, July.
Associationfor Computational Linguistics.Michelene T. H. Chi, Nicholas de Leeuw, Mei-HungChiu, and Christian LaVancher.
1994.
Eliciting self-explanations improves understanding.
Cognitive Sci-ence, 18(3):439?477.Michelene T. H. Chi, Stephanie A. Siler, Takashi Ya-mauchi, and Robert G. Hausmann.
2001.
Learningfrom human tutoring.
Cognitive Science, 25:471?533.Min Chi, Kurt VanLehn, and Diane Litman.
2010.
Themore the merrier?
Examining three interaction hy-potheses.
In Proceedings of the 32nd Annual Confer-ence of the Cognitive Science Society (CogSci2010),Portland,OR.Michelene T.H.
Chi.
1997.
Quantifying qualitative anal-yses of verbal data: A practical guide.
Journal of theLearning Sciences, 6(3):271?315.Herbert H. Clark.
1992.
Arenas of Language Use.
TheUniversity of Chicago Press, Chicago, IL.Barbara Di Eugenio and Michael Glass.
2004.
TheKappa statistic: a second look.
Computational Lin-guistics, 30(1):95?101.
Squib.Barbara Di Eugenio, Trina C. Kershaw, Xin Lu, AndrewCorrigan-Halpern, and Stellan Ohlsson.
2006.
To-ward a computational model of expert tutoring: a firstreport.
In FLAIRS06, the 19th International FloridaAI Research Symposium, Melbourne Beach, FL.Barbara Di Eugenio, Davide Fossati, Stellan Ohlsson,and David Cosejo.
2009.
Towards explaining effec-tive tutorial dialogues.
In Annual Meeting of the Cog-nitive Science Society, pages 1430?1435, Amsterdam,July.Martha W. Evens and Joel A. Michael.
2006.
One-on-one Tutoring by Humans and Machines.
Mahwah, NJ:Lawrence Erlbaum Associates.Davide Fossati, Barbara Di Eugenio, Christopher Brown,Stellan Ohlsson, David Cosejo, and Lin Chen.
2009.Supporting Computer Science curriculum: Exploringand learning linked lists with iList.
IEEE Transac-tions on Learning Technologies, Special Issue on Real-World Applications of Intelligent Tutoring Systems,2(2):107?120, April-June.Davide Fossati, Barbara Di Eugenio, Stellan Ohlsson,Christopher Brown, and Lin Chen.
2010.
Generat-ing proactive feedback to help students stay on track.In ITS 2010, 10th International Conference on Intelli-gent Tutoring Systems.
Poster.Barbara A.
Fox.
1993.
The Human Tutorial DialogueProject: Issues in the design of instructional systems.Lawrence Erlbaum Associates, Hillsdale, NJ.Arthur C. Graesser, Natalie K. Person, and Joseph P.Magliano.
1995.
Collaborative dialogue patterns innaturalistic one-to-one tutoring.
Applied CognitivePsychology, 9:495?522.Arthur C. Graesser, Shulan Lu, George Tanner Jack-son, Heather Hite Mitchell, Mathew Ventura, AndrewOlney, and Max M. Louwerse.
2004.
AutoTutor:A tutor with dialogue in natural language.
Behav-ioral Research Methods, Instruments, and Computers,36:180?193.Mark R. Lepper, Michael F. Drake, and TeresaO?Donnell-Johnson.
1997.
Scaffolding techniques ofexpert human tutors.
In K. Hogan and M. Pressley, ed-itors, Scaffolding student learning: Instructional ap-proaches and issues.
Cambridge, MA: Brookline.Diane Litman and Kate Forbes-Riley.
2006.
Correla-tions between dialogue acts and learning in spokentutoring dialogues.
Natural Language Engineering,12(02):161?176.Brian MacWhinney.
2000.
The Childes Project: Toolsfor Analyzing Talk: Transcription format and pro-grams, volume 1.
Psychology Press, 3 edition.Johanna D. Moore, Kaska Porayska-Pomsta, SebastianVarges, and Claus Zinn.
2004.
Generating TutorialFeedback with Affect.
In FLAIRS04, Proceedings ofthe Seventeenth International Florida Artificial Intel-ligence Research Society Conference.Stellan Ohlsson, Barbara Di Eugenio, Bettina Chow, Da-vide Fossati, Xin Lu, and Trina C. Kershaw.
2007.Beyond the code-and-count analysis of tutoring dia-logues.
In Proceedings of the 13th International Con-ference on Artificial Intelligence in Education, pages349?356, Los Angeles, CA, July.
IOS Press.Stellan Ohlsson.
2008.
Computational models of skillacquisition.
The Cambridge handbook of computa-tional psychology, pages 359?395.74Ron Sun, Paul Slusarz, and Chris Terry.
2005.
The Inter-action of the Explicit and the Implicit in Skill Learn-ing: A Dual-Process Approach.
Psychological Re-view, 112:159?192.Kurt VanLehn, Arthur C. Graesser, G. Tanner Jackson,Pamela W. Jordan, Andrew Olney, and Carolyn P.Rose?.
2007.
When are tutorial dialogues more effec-tive than reading?
Cognitive Science, 31(1):3?62.75
