Proceedings of ACL-08: HLT, pages 165?173,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsTrainable Generation of Big-Five Personality Stylesthrough Data-driven Parameter EstimationFranc?ois MairesseCambridge University Engineering DepartmentTrumpington StreetCambridge, CB2 1PZ, United Kingdomfarm2@eng.cam.ac.ukMarilyn WalkerDepartment of Computer ScienceUniversity of SheffieldSheffield, S1 4DP, United Kingdomlynwalker@gmail.comAbstractPrevious work on statistical language gen-eration has primarily focused on grammat-icality and naturalness, scoring generationpossibilities according to a language modelor user feedback.
More recent work hasinvestigated data-driven techniques for con-trolling linguistic style without overgenera-tion, by reproducing variation dimensions ex-tracted from corpora.
Another line of workhas produced handcrafted rule-based systemsto control specific stylistic dimensions, suchas politeness and personality.
This paperdescribes a novel approach that automati-cally learns to produce recognisable varia-tion along a meaningful stylistic dimension?personality?without the computational costincurred by overgeneration techniques.
Wepresent the first evaluation of a data-drivengeneration method that projects multiple per-sonality traits simultaneously and on a contin-uous scale.
We compare our performance to arule-based generator in the same domain.1 IntroductionOver the last 20 years, statistical language models(SLMs) have been used successfully in many tasksin natural language processing, and the data avail-able for modeling has steadily grown (Lapata andKeller, 2005).
Langkilde and Knight (1998) firstapplied SLMs to statistical natural language genera-tion (SNLG), showing that high quality paraphrasescan be generated from an underspecified representa-tion of meaning, by first applying a very undercon-strained, rule-based overgeneration phase, whoseoutputs are then ranked by an SLM scoring phase.Since then, research in SNLG has explored a rangeof models for both dialogue and text generation.One line of work has primarily focused on gram-maticality and naturalness, scoring the overgener-ation phase with a SLM, and evaluating againsta gold-standard corpus, using string or tree-matchmetrics (Langkilde-Geary, 2002; Bangalore andRambow, 2000; Chambers and Allen, 2004; Belz,2005; Isard et al, 2006).Another thread investigates SNLG scoring mod-els trained using higher-level linguistic featuresto replicate human judgments of utterance quality(Rambow et al, 2001; Nakatsu and White, 2006;Stent and Guo, 2005).
The error of these scoringmodels approaches the gold-standard human rank-ing with a relatively small training set.A third SNLG approach eliminates the overgen-eration phase (Paiva and Evans, 2005).
It appliesfactor analysis to a corpus exhibiting stylistic vari-ation, and then learns which generation parametersto manipulate to correlate with factor measurements.The generator was shown to reproduce intended fac-tor levels across several factors, thus modelling thestylistic variation as measured in the original corpus.Our goal is a generation technique that can tar-get multiple stylistic effects simultaneously andover a continuous scale, controlling stylistic di-mensions that are commonly understood and thusmeaningful to users and application developers.Our intended applications are output utterancesfor intelligent training or intervention systems,video game characters, or virtual environmentavatars.
In previous work, we presented PERSON-AGE, a psychologically-informed rule-based genera-tor based on the Big Five personality model, and weshowed that PERSONAGE can project extreme per-sonality on the extraversion scale, i.e.
both intro-verted and extraverted personality types (Mairesseand Walker, 2007).
We used the Big Five modelto develop PERSONAGE for several reasons.
First,the Big Five has been shown in psychology to ex-165Trait High LowExtraversion warm, assertive, sociable, excitement seeking, active,spontaneous, optimistic, talkativeshy, quiet, reserved, passive, solitary, moodyEmotional stability calm, even-tempered, reliable, peaceful, confident neurotic, anxious, depressed, self-consciousAgreeableness trustworthy, considerate, friendly, generous, helpful unfriendly, selfish, suspicious, uncooperative, ma-liciousConscientiousness competent, disciplined, dutiful, achievement striving disorganised, impulsive, unreliable, forgetfulOpenness to experience creative, intellectual, curious, cultured, complex narrow-minded, conservative, ignorant, simpleTable 1: Example adjectives associated with extreme values of the Big Five trait scales.plain much of the variation in human perceptions ofpersonality differences.
Second, we believe that theadjectives used to develop the Big Five model pro-vide an intuitive, meaningful definition of linguis-tic style.
Table 1 shows some of the trait adjec-tives associated with the extremes of each Big Fivetrait.
Third, there are many studies linking person-ality to linguistic variables (Pennebaker and King,1999; Mehl et al, 2006, inter alia).
See (Mairesseand Walker, 2007) for more detail.In this paper, we further test the utility of basingstylistic variation on the Big Five personality model.The Big Five traits are represented by scalar val-ues that range from 1 to 7, with values normallydistributed among humans.
While our previouswork targeted extreme values of individual traits,here we show that we can target multiple person-ality traits simultaneously and over the continuousscales of the Big Five model.
Section 2 describesa novel parameter-estimation method that automat-ically learns to produce recognisable variation forall Big Five traits, without overgeneration, imple-mented in a new SNLG called PERSONAGE-PE.We show that PERSONAGE-PE generates targets formultiple personality dimensions, using linear andnon-linear parameter estimation models to predictgeneration parameters directly from the scalar tar-gets.
Section 3.2 shows that humans accurately per-ceive the intended variation, and Section 3.3 com-pares PERSONAGE-PE (trained) with PERSONAGE(rule-based; Mairesse and Walker, 2007).
We delaya detailed discussion of related work to Section 4,where we summarize and discuss future work.2 Parameter Estimation ModelsThe data-driven parameter estimation method con-sists of a development phase and a generation phase(Section 3).
The development phase:1.
Uses a base generator to produce multiple utter-ances by randomly varying its parameters;2.
Collects human judgments rating the personality ofeach utterance;3.
Trains statistical models to predict the parametersfrom the personality judgments;7.006.005.004.003.002.001.00 Agreeableness rating3020100FrequencyFigure 1: Distribution of average agreeableness ratingsfrom the 2 expert judges for 160 random utterances.4.
Selects the best model for each parameter via cross-validation.2.1 Base GeneratorWe make minimal assumptions about the input tothe generator to favor domain independence.
Theinput is a speech act, a potential content pool thatcan be used to achieve that speech act, and five scalarpersonality parameters (1. .
.7), specifying values forthe continuous scalar dimensions of each trait inthe Big Five model.
See Table 1.
This requires abase generator that generates multiple outputs ex-pressing the same input content by varying linguis-tic parameters related to the Big Five traits.
Westart with the PERSONAGE generator (Mairesse andWalker, 2007), which generates recommendationsand comparisons of restaurants.
We extend PER-SONAGE with new parameters for a total of 67 pa-rameters in PERSONAGE-PE.
See Table 2.
Theseparameters are derived from psychological studiesidentifying linguistic markers of the Big Five traits(Pennebaker and King, 1999; Mehl et al, 2006, in-ter alia).
As PERSONAGE?s input parameters aredomain-independent, most parameters range contin-uously between 0 and 1, while pragmatic marker in-sertion parameters are binary, except for the SUB-JECT IMPLICITNESS, STUTTERING and PRONOMI-166Parameters DescriptionContent parameters:VERBOSITY Control the number of propositions in the utteranceRESTATEMENTS Paraphrase an existing proposition, e.g.
?Chanpen Thai has great service, it has fantastic waiters?REPETITIONS Repeat an existing propositionCONTENT POLARITY Control the polarity of the propositions expressed, i.e.
referring to negative or positive attributesREPETITIONS POLARITY Control the polarity of the restated propositionsCONCESSIONS Emphasise one attribute over another, e.g.
?even if Chanpen Thai has great food, it has bad service?CONCESSIONS POLARITY Determine whether positive or negative attributes are emphasisedPOLARISATION Control whether the expressed polarity is neutral or extremePOSITIVE CONTENT FIRST Determine whether positive propositions?including the claim?are uttered firstSyntactic template selection parameters:SELF-REFERENCES Control the number of first person pronounsCLAIM COMPLEXITY Control the syntactic complexity (syntactic embedding)CLAIM POLARITY Control the connotation of the claim, i.e.
whether positive or negative affect is expressedAggregation operations:PERIOD Leave two propositions in their own sentences, e.g.
?Chanpen Thai has great service.
It has nice decor.
?RELATIVE CLAUSE Aggregate propositions with a relative clause, e.g.
?Chanpen Thai, which has great service, has nice decor?WITH CUE WORD Aggregate propositions using with, e.g.
?Chanpen Thai has great service, with nice decor?CONJUNCTION Join two propositions using a conjunction, or a comma if more than two propositionsMERGE Merge the subject and verb of two propositions, e.g.
?Chanpen Thai has great service and nice decor?ALSO CUE WORD Join two propositions using also, e.g.
?Chanpen Thai has great service, also it has nice decor?CONTRAST - CUE WORD Contrast two propositions using while, but, however, on the other hand, e.g.
?While Chanpen Thai has greatservice, it has bad decor?, ?Chanpen Thai has great service, but it has bad decor?JUSTIFY - CUE WORD Justify a proposition using because, since, so, e.g.
?Chanpen Thai is the best, because it has great service?CONCEDE - CUE WORD Concede a proposition using although, even if, but/though, e.g.
?Although Chanpen Thai has great service, ithas bad decor?, ?Chanpen Thai has great service, but it has bad decor though?MERGE WITH COMMA Restate a proposition by repeating only the object, e.g.
?Chanpen Thai has great service, nice waiters?CONJ.
WITH ELLIPSIS Restate a proposition after replacing its object by an ellipsis, e.g.
?Chanpen Thai has .
.
.
, it has great service?Pragmatic markers:SUBJECT IMPLICITNESS Make the restaurant implicit by moving the attribute to the subject, e.g.
?the service is great?NEGATION Negate a verb by replacing its modifier by its antonym, e.g.
?Chanpen Thai doesn?t have bad service?SOFTENER HEDGES Insert syntactic elements (sort of, kind of, somewhat, quite, around, rather, I think that, it seems that, it seemsto me that) to mitigate the strength of a proposition, e.g.
?Chanpen Thai has kind of great service?
or ?It seemsto me that Chanpen Thai has rather great service?EMPHASIZER HEDGES Insert syntactic elements (really, basically, actually, just) to strengthen a proposition, e.g.
?Chanpen Thai hasreally great service?
or ?Basically, Chanpen Thai just has great service?ACKNOWLEDGMENTS Insert an initial back-channel (yeah, right, ok, I see, oh, well), e.g.
?Well, Chanpen Thai has great service?FILLED PAUSES Insert syntactic elements expressing hesitancy (like, I mean, err, mmhm, you know), e.g.
?I mean, ChanpenThai has great service, you know?
or ?Err... Chanpen Thai has, like, great service?EXCLAMATION Insert an exclamation mark, e.g.
?Chanpen Thai has great service!
?EXPLETIVES Insert a swear word, e.g.
?the service is damn great?NEAR-EXPLETIVES Insert a near-swear word, e.g.
?the service is darn great?COMPETENCE MITIGATION Express the speaker?s negative appraisal of the hearer?s request, e.g.
?everybody knows that .
.
.
?TAG QUESTION Insert a tag question, e.g.
?the service is great, isn?t it?
?STUTTERING Duplicate the first letters of a restaurant?s name, e.g.
?Ch-ch-anpen Thai is the best?CONFIRMATION Begin the utterance with a confirmation of the restaurant?s name, e.g.
?did you say Chanpen Thai?
?INITIAL REJECTION Begin the utterance with a mild rejection, e.g.
?I?m not sure?IN-GROUP MARKER Refer to the hearer as a member of the same social group, e.g.
pal, mate and buddyPRONOMINALIZATION Replace occurrences of the restaurant?s name by pronounsLexical choice parameters:LEXICAL FREQUENCY Control the average frequency of use of each content word, according to BNC frequency countsWORD LENGTH Control the average number of letters of each content wordVERB STRENGTH Control the strength of the selected verbs, e.g.
?I would suggest?
vs. ?I would recommend?Table 2: The 67 generation parameters whose target values are learned.
Aggregation cue words, hedges, acknowl-edgments and filled pauses are learned individually (as separate parameters), e.g.
kind of is modeled differently thansomewhat in the SOFTENER HEDGES category.
Parameters are detailed in previous work (Mairesse and Walker, 2007).NALIZATION parameters.2.2 Random Sample Generation and ExpertJudgmentsWe generate a sample of 160 random utterances byvarying the parameters in Table 2 with a uniform dis-tribution.
This sample is intended to provide enoughtraining material for estimating all 67 parametersfor each personality dimension.
Following Mairesseand Walker (2007), two expert judges (not the au-thors) familiar with the Big Five adjectives (Table 1)evaluate the personality of each utterance using theTen-Item Personality Inventory (TIPI; Gosling et al,2003), and also judge the utterance?s naturalness.Thus 11 judgments were made for each utterance fora total of 1760 judgments.
The TIPI outputs a ratingon a scale from 1 (low) to 7 (high) for each Big Fivetrait.
The expert judgments are approximately nor-167mally distributed; Figure 1 shows the distribution foragreeableness.2.3 Statistical Model TrainingTraining data is created for each generationparameter?i.e.
the output variable?to train statis-tical models predicting the optimal parameter valuefrom the target personality scores.
The models arethus based on the simplifying assumption that thegeneration parameters are independent.
Any person-ality trait whose correlation with a generation deci-sion is below 0.1 is removed from the training data.This has the effect of removing parameters that donot correlate strongly with any trait, which are set toa constant default value at generation time.
Sincethe input parameter values may not be satisfiabledepending on the input content, the actual genera-tion decisions made for each utterance are recorded.For example, the CONCESSIONS decision value isthe actual number of concessions produced in theutterance.
To ensure that the models?
output cancontrol the generator, the generation decision valuesare normalized to match the input range (0. .
.1) ofPERSONAGE-PE.
Thus the dataset consists of 160utterances and the corresponding generation deci-sions, each associated with 5 personality ratings av-eraged over both judges.Parameter estimation models are trained to predicteither continuous (e.g.
VERBOSITY) or binary (e.g.EXCLAMATION) generation decisions.
We comparevarious learning algorithms using the Weka toolkit(with default values unless specified; Witten andFrank, 2005).
Continuous parameters are modeledwith a linear regression model (LR), an M5?
modeltree (M5), and a model based on support vector ma-chines with a linear kernel (SVM).
As regressionmodels can extrapolate beyond the [0, 1] interval, theoutput parameter values are truncated if needed?atgeneration time?before being sent to the base gen-erator.
Binary parameters are modeled using clas-sifiers that predict whether the parameter is enabledor disabled.
We test a Naive Bayes classifier (NB), aj48 decision tree (J48), a nearest-neighbor classifierusing one neighbor (NN), a Java implementation ofthe RIPPER rule-based learner (JRIP), the AdaBoostboosting algorithm (ADA), and a support vector ma-chines classifier with a linear kernel (SVM).Figures 2, 3 and 4 show the models learned forthe EXCLAMATION (binary), STUTTERING (contin-uous), and CONTENT POLARITY (continuous) pa-rameters in Table 2.
The models predict generationparameters from input personality scores; note thatCondition Class Weight--------- ----- ------if extraversion > 6.42 then 1 else 0 1.81if extraversion > 4.42 then 1 else 0 0.38if extraversion <= 6.58 then 1 else 0 0.22if extraversion > 4.71 then 1 else 0 0.28if agreeableness > 5.13 then 1 else 0 0.42if extraversion <= 6.58 then 1 else 0 0.14if extraversion > 4.79 then 1 else 0 0.19if extraversion <= 6.58 then 1 else 0 0.17Figure 2: AdaBoost model predicting the EXCLAMATIONparameter.
Given input trait values, the model outputsthe class yielding the largest sum of weights for the rulesreturning that class.
Class 0 = disabled, class 1 = enabled.
(normalized) Content polarity =0.054- 0.102 * (normalized) emotional stability+ 0.970 * (normalized) agreeableness- 0.110 * (normalized) conscientiousness+ 0.013 * (normalized) openness toexperienceFigure 3: SVM model with a linear kernel predicting theCONTENT POLARITY parameter.sometimes the best performing model is non-linear.Given input trait values, the AdaBoost model in Fig-ure 2 outputs the class yielding the largest sum ofweights for the rules returning that class.
For ex-ample, the first rule of the EXCLAMATION modelshows that an extraversion score above 6.42 out of7 would increase the weight of the enabled class by1.81.
The fifth rule indicates that a target agreeable-ness above 5.13 would further increase the weightby .42.
The STUTTERING model tree in Figure 4lets us calculate that a low emotional stability (1.0)together with a neutral conscientiousness and open-ness to experience (4.0) yield a parameter value of.62 (see LM2), whereas a neutral emotional stabil-ity decreases the value down to .17.
Figure 4 alsoshows how personality traits that do not affect theparameter are removed, i.e.
emotional stability, con-scientiousness and openness to experience are thetraits that affect stuttering.
The linear model in Fig-ure 3 shows that agreeableness has a strong effecton the CONTENT POLARITY parameter (.97 weight),but emotional stability, conscientiousness and open-ness to experience also have an effect.2.4 Model SelectionThe final step of the development phase identifiesthe best performing model(s) for each generationparameter via cross-validation.
For continuous pa-168?
3.875 > 3.875ConscientiousnessEmotional stability?
4.375 > 4.375Stuttering =-0.0136 * emotional stability+ 0.0098 * conscientiousness+ 0.0063 * openness to experience+ 0.0126Stuttering =-0.1531 * emotional stability+ 0.004 * conscientiousness+ 0.1122 * openness to experience+ 0.3129Stuttering =-0.0142 * emotional stability+ 0.004 * conscientiousness+ 0.0076 * openness to experience+ 0.0576Figure 4: M5?
model tree predicting the STUTTERING parameter.Continuous parameters LR M5 SVMContent parameters:VERBOSITY 0.24 0.26 0.21RESTATEMENTS 0.14 0.14 0.04REPETITIONS 0.13 0.13 0.08CONTENT POLARITY 0.46 0.46 0.47REPETITIONS POLARITY 0.02 0.15 0.06CONCESSIONS 0.23 0.23 0.12CONCESSIONS POLARITY -0.01 0.16 0.07POLARISATION 0.20 0.21 0.20Syntactic template selection:CLAIM COMPLEXITY 0.10 0.33 0.26CLAIM POLARITY 0.04 0.04 0.05Aggregation operations:INFER - WITH CUE WORD 0.03 0.03 0.01INFER - ALSO CUE WORD 0.10 0.10 0.06JUSTIFY - SINCE CUE WORD 0.03 0.07 0.05JUSTIFY - SO CUE WORD 0.07 0.07 0.04JUSTIFY - PERIOD 0.36 0.35 0.21CONTRAST - PERIOD 0.27 0.26 0.26RESTATE - MERGE WITH COMMA 0.18 0.18 0.09CONCEDE - ALTHOUGH CUE WORD 0.08 0.08 0.05CONCEDE - EVEN IF CUE WORD 0.05 0.05 0.03Pragmatic markers:SUBJECT IMPLICITNESS 0.13 0.13 0.04STUTTERING INSERTION 0.16 0.23 0.17PRONOMINALIZATION 0.22 0.20 0.17Lexical choice parameters:LEXICAL FREQUENCY 0.21 0.21 0.19WORD LENGTH 0.18 0.18 0.15Table 3: Pearson?s correlation between parameter modelpredictions and continuous parameter values, for differ-ent regression models.
Parameters that do not correlatewith any trait are omitted.
Aggregation operations are as-sociated with a rhetorical relation (e.g.
INFER).
Resultsare averaged over a 10-fold cross-validation.rameters, Table 3 evaluates modeling accuracy bycomparing the correlations between the model?s pre-dictions and the actual parameter values in the testfolds.
Table 4 reports results for binary parameterclassifiers, by comparing the F-measures of the en-abled class.
Best performing models are identifiedin bold; parameters that do not correlate with anytrait or that produce a poor modeling accuracy areomitted.The CONTENT POLARITY parameter is modeledBinary parameters NB J48 NN ADA SVMPragmatic markers:SOFTENER HEDGESkind of 0.00 0.00 0.16 0.11 0.10rather 0.00 0.00 0.02 0.01 0.01quite 0.14 0.08 0.09 0.07 0.06EMPHASIZER HEDGESbasically 0.00 0.00 0.02 0.01 0.01ACKNOWLEDGMENTSyeah 0.00 0.00 0.04 0.03 0.03ok 0.13 0.07 0.06 0.05 0.05FILLED PAUSESerr 0.32 0.20 0.24 0.22 0.19EXCLAMATION 0.23 0.34 0.36 0.38 0.34EXPLETIVES 0.27 0.18 0.24 0.17 0.15IN-GROUP MARKER 0.40 0.31 0.31 0.24 0.21TAG QUESTION 0.32 0.21 0.21 0.15 0.13CONFIRMATION 0.00 0.00 0.07 0.04 0.04Table 4: F-measure of the enabled class for classifica-tion models of binary parameters.
Parameters that donot correlate with any trait are omitted.
Results are av-eraged over a 10-fold cross-validation.
JRIP models arenot shown as they never perform best.the most accurately, with the SVM model in Fig-ure 3 producing a correlation of .47 with the true pa-rameter values.
Models of the PERIOD aggregationoperation also perform well, with a linear regressionmodel yielding a correlation of .36 when realizinga justification, and .27 when contrasting two propo-sitions.
CLAIM COMPLEXITY and VERBOSITY arealso modeled successfully, with correlations of .33and .26 using a model tree.
The model tree control-ling the STUTTERING parameter illustrated in Fig-ure 4 produces a correlation of .23.
For binary pa-rameters, Table 4 shows that the Naive Bayes classi-fier is generally the most accurate, with F-measuresof .40 for the IN-GROUP MARKER parameter, and.32 for both the insertion of filled pauses (err) andtag questions.
The AdaBoost algorithm best predictsthe EXCLAMATION parameter, with an F-measure of.38 for the model in Figure 2.169# Traits End Rating Nat Output utterance1.a Extraversion high 4.42 4.79 Radio Perfecto?s price is 25 dollars but Les Routiers provides adequate food.
Iimagine they?re alright!Agreeableness high 4.941.bEmotional stability high 5.355.04Let?s see, Les Routiers and Radio Perfecto... You would probably appreciate them.Radio Perfecto is in the East Village with kind of acceptable food.
Les Routiers islocated in Manhattan.
Its price is 41 dollars.Conscientiousness high 5.212.a Extraversion low 3.65 3.21 Err... you would probably appreciate Trattoria Rustica, wouldn?t you?
It?s inManhattan, also it?s an italian restaurant.
It offers poor ambience, also it?s quite costly.Agreeableness low 4.022.bEmotional stability low 4.134.50 Trattoria Rustica isn?t as bad as the others.
Err... even if it?s costly, it offers kind ofadequate food, alright?
It?s an italian place.Openness to low 3.85experienceTable 5: Example outputs controlled by the parameter estimation models for a comparison (#1) and a recommendation(#2), with the average judges?
ratings (Rating) and naturalness (Nat).
Ratings are on a scale from 1 to 7, with 1 = verylow (e.g.
neurotic or introvert) and 7 = very high on the dimension (e.g.
emotionally stable or extraverted).3 Evaluation ExperimentThe generation phase of our parameter estimationSNLG method consists of the following steps:1.
Use the best performing models to predict parame-ter values from the desired personality scores;2.
Generate the output utterance using the predictedparameter values.We then evaluate the output utterances using naivehuman judges to rate their perceived personality andnaturalness.3.1 Evaluation MethodGiven the best performing model for each genera-tion parameter, we generate 5 utterances for eachof 5 recommendation and 5 comparison speech acts.Each utterance targets an extreme value for two traits(either 1 or 7 out of 7) and neutral values for the re-maining three traits (4 out of 7).
The goal is for eachutterance to project multiple traits on a continuousscale.
To generate a range of alternatives, a Gaus-sian noise with a standard deviation of 10% of thefull scale is added to each target value.Subjects were 24 native English speakers (12male and 12 female graduate students from a rangeof disciplines from both the U.K. and the U.S.).
Sub-jects evaluate the naturalness and personality of eachutterance using the TIPI (Gosling et al, 2003).
Tolimit the experiment?s duration, only the two traitswith extreme target values are evaluated for eachutterance.
Subjects thus answered 5 questions for50 utterances, two from the TIPI for each extremetrait and one about naturalness (250 judgments intotal per subject).
Subjects were not told that theutterances were intended to manifest extreme traitvalues.
Table 5 shows several sample outputs andthe mean personality ratings from the human judges.For example, utterance 1.a projects a high extraver-sion through the insertion of an exclamation markbased on the model in Figure 2, whereas utterance2.a conveys introversion by beginning with the filledpause err.
The same utterance also projects a lowagreeableness by focusing on negative propositions,through a low CONTENT POLARITY parameter valueas per the model in Figure 3.
This evaluation ad-dresses a number of open questions discussed below.Q1: Is the personality projected by models trained onratings from a few expert judges recognised by alarger sample of naive judges?
(Section 3.2)Q2: Can a combination of multiple traits within a singleutterance be detected by naive judges?
(Section 3.2)Q3: How does PERSONAGE-PE compare to PERSON-AGE, a psychologically-informed rule-based gen-erator for projecting extreme personality?
(Sec-tion 3.3)Q4: Does the parameter estimation SNLG method pro-duce natural utterances?
(Section 3.4)3.2 Parameter Estimation EvaluationTable 6 shows that extraversion is the dimensionmodeled most accurately by the parameter estima-tion models, producing a .45 correlation with thesubjects?
ratings (p < .01).
Emotional stability,agreeableness, and openness to experience ratingsalso correlate strongly with the target scores, withcorrelations of .39, .36 and .17 respectively (p <.01).
Additionally, Table 6 shows that the magni-tude of the correlation increases when consideringthe perception of a hypothetical average subject, i.e.smoothing individual variation by averaging the rat-ings over all 24 judges, producing a correlation ravgup to .80 for extraversion.
These correlations areunexpectedly high; in corpus analyses, significantcorrelations as low as .05 to .10 are typically ob-served between personality and linguistic markers(Pennebaker and King, 1999; Mehl et al, 2006).Conscientiousness is the only dimension whoseratings do not correlate with the target scores.
The170comparison with rule-based results in Section 3.3suggests that this is not because conscientiousnesscannot be exhibited in our domain or manifested ina single utterance, so perhaps this arises from dif-fering perceptions of conscientiousness between theexpert and naive judges.Trait r ravg eExtraversion .45 ?
.80 ?
1.89Emotional stability .39 ?
.64 ?
2.14Agreeableness .36 ?
.68 ?
2.38Conscientiousness -.01 -.02 2.79Openness to experience .17 ?
.41 ?
2.51?
statistically significant correlationp < .05, ?
p = .07 (two-tailed)Table 6: Pearson?s correlation coefficient r and mean ab-solute error e between the target personality scores andthe 480 judges?
ratings (20 ratings per trait for 24 judges);ravg is the correlation between the personality scores andthe average judges?
ratings.Table 6 shows that the mean absolute error variesbetween 1.89 and 2.79 on a scale from 1 to 7.
Suchlarge errors result from the decision to ask judges toanswer just the TIPI questions for the two traits thatwere the extreme targets (See Section 3.1), becausethe judges tend to use the whole scale, with approx-imately normally distributed ratings.
This meansthat although the judges make distinctions leading tohigh correlations, they do so on a compressed scale.This explains the large correlations despite the mag-nitude of the absolute error.Table 7 shows results evaluating whether utter-ances targeting the extremes of a trait are perceiveddifferently.
The ratings differ significantly for alltraits but conscientiousness (p ?
.001).
Thus pa-rameter estimation models can be used in applica-tions that only require discrete binary variation.Trait Low HighExtraversion 3.69 5.06 ?Emotional stability 3.75 4.75 ?Agreeableness 3.42 4.33 ?Conscientiousness 4.16 4.15Openness to experience 3.71 4.06 ??
statistically significant differencep ?
.001 (two-tailed)Table 7: Average personality ratings for the utterancesgenerated with the low and high target values for eachtrait on a scale from 1 to 7.It is important to emphasize that generation pa-rameters were predicted based on 5 target person-ality values.
Thus, the results show that individ-ual traits are perceived even when utterances projectother traits as well, confirming that the Big Five the-ory models independent dimensions and thus pro-vides a useful and meaningful framework for mod-eling variation in language.
Additionally, althoughwe do not directly evaluate the perception of mid-range values of personality target scores, the resultssuggest that mid-range personality is modeled cor-rectly because the neutral target scores do not affectthe perception of extreme traits.3.3 Comparison with Rule-Based GenerationPERSONAGE is a rule-based personality generatorbased on handcrafted parameter settings derivedfrom psychological studies.
Mairesse and Walker(2007) show that this approach generates utterancesthat are perceptibly different along the extraversiondimension.
Table 8 compares the mean ratings ofthe utterances generated by PERSONAGE-PE withratings of 20 utterances generated by PERSONAGEfor each extreme of each Big Five scale (40 for ex-traversion, resulting in 240 handcrafted utterances intotal).
Table 8 shows that the handcrafted parame-ter settings project a significantly more extreme per-sonality for 6 traits out of 10.
However, the learnedparameter models for neuroticism, disagreeableness,unconscientiousness and openness to experience donot perform significantly worse than the handcraftedgenerator.
These findings are promising as we dis-cuss further in Section 4.Method Rule-based Learned parametersTrait Low High Low HighExtraversion 2.96 5.98 3.69 ?
5.05 ?Emotional stability 3.29 5.96 3.75 4.75 ?Agreeableness 3.41 5.66 3.42 4.33 ?Conscientiousness 3.71 5.53 4.16 4.15 ?Openness to experience 2.89 4.21 3.71 ?
4.06?,?
significant increase or decrease of the variation rangeover the average rule-based ratings (p < .05, two-tailed)Table 8: Pair-wise comparison between the ratings ofthe utterances generated using PERSONAGE-PE with ex-treme target values (Learned Parameters), and the ratingsfor utterances generated with Mairesse andWalker?s rule-based PERSONAGE generator, (Rule-based).
Ratings areaveraged over all judges.3.4 Naturalness EvaluationThe naive judges also evaluated the naturalness ofthe outputs of our trained models.
Table 9 showsthat the average naturalness is 3.98 out of 7, which issignificantly lower (p < .05) than the naturalness ofhandcrafted and randomly generated utterances re-ported by Mairesse and Walker (2007).
It is possi-ble that the differences arise from judgments of ut-terances targeting multiple traits, or that the naive171judges are more critical.Trait Rule-based Random LearnedAll 4.59 4.38 3.98Table 9: Average naturalness ratings for utterances gen-erated using (1) PERSONAGE, the rule-based generator,(2) the random utterances (expert judges) and (3) the out-puts of PERSONAGE-PE using the parameter estimationmodels (Learned, naive judges).
The means differ sig-nificantly at the p < .05 level (two-tailed independentsample t-test).4 ConclusionWe present a new method for generating linguis-tic variation projecting multiple personality traitscontinuously, by combining and extending previousresearch in statistical natural language generation(Paiva and Evans, 2005; Rambow et al, 2001; Is-ard et al, 2006; Mairesse and Walker, 2007).
Whilehandcrafted rule-based approaches are limited tovariation along a small number of discrete points(Hovy, 1988; Walker et al, 1997; Lester et al, 1997;Power et al, 2003; Cassell and Bickmore, 2003; Pi-wek, 2003; Mairesse and Walker, 2007; Rehm andAndre?, in press), we learn models that predict pa-rameter values for any arbitrary value on the varia-tion dimension scales.
Additionally, our data-drivenapproach can be applied to any dimension that ismeaningful to human judges, and it provides an ele-gant way to project multiple dimensions simultane-ously, by including the relevant dimensions as fea-tures of the parameter models?
training data.Isard et al (2006) and Mairesse and Walker(2007) also propose a personality generationmethod, in which a data-driven personality modelselects the best utterance from a large candidate set.Isard et al?s technique has not been evaluated, whileMairesse and Walker?s overgenerate and score ap-proach is inefficient.
Paiva and Evans?
techniquedoes not overgenerate (2005), but it requires a searchfor the optimal generation decisions according tothe learned models.
Our approach does not requireany search or overgeneration, as parameter estima-tion models predict the generation decisions directlyfrom the target variation dimensions.
This tech-nique is therefore beneficial for real-time genera-tion.
Moreover the variation dimensions of Paivaand Evans?
data-driven technique are extracted froma corpus: there is thus no guarantee that they canbe easily interpreted by humans, and that they gen-eralise to other corpora.
Previous work has shownthat modeling the relation between personality andlanguage is far from trivial (Pennebaker and King,1999; Argamon et al, 2005; Oberlander and Now-son, 2006; Mairesse et al, 2007), suggesting that thecontrol of personality is a harder problem than thecontrol of data-driven variation dimensions.We present the first human perceptual evaluationof a data-driven stylistic variation method.
In termsof our research questions in Section 3.1, we showthat models trained on expert judges to project mul-tiple traits in a single utterance generate utteranceswhose personality is recognized by naive judges.There is only one other similar evaluation of anSNLG (Rambow et al, 2001).
Our models performonly slightly worse than a handcrafted rule-basedgenerator in the same domain.
These findings arepromising as (1) parameter estimation models areable to target any combination of traits over the fullrange of the Big Five scales; (2) they do not benefitfrom psychological knowledge, i.e.
they are trainedon randomly generated utterances.This work also has several limitations that shouldbe addressed in future work.
Even though theparameters of PERSONAGE-PE were suggested bypsychological studies (Mairesse and Walker, 2007),some of them are not modeled successfully by ourapproach, and thus omitted from Tables 3 and 4.This could be due to the relatively small develop-ment dataset size (160 utterances to optimize 67 pa-rameters), or to the implementation of some param-eters.
The strong parameter-independence assump-tion could also be responsible, but we are not awareof any state of the art implementation for learn-ing multiple dependent variables, and this approachcould further aggravate data sparsity issues.In addition, it is unclear why PERSONAGE per-forms better for projecting extreme personalityand produces more natural utterances, and whyPERSONAGE-PE fails to project conscientiousnesscorrectly.
It might be possible to improve the pa-rameter estimation models with a larger sample ofrandom utterances at development time, or with ad-ditional extreme data generated using the rule-basedapproach.
Such hybrid models are likely to performbetter for extreme target scores, as they are trainedon more uniformly distributed ratings (e.g.
com-pared to the normal distribution in Figure 1).
In ad-dition, we have only shown that personality can beexpressed by information presentation speech-actsin the restaurant domain; future work should assessthe extent to which the parameters derived from psy-chological findings are culture, domain, and speechact dependent.172ReferencesS.
Argamon, S. Dhawle, M. Koppel, and J. Pennebaker.Lexical predictors of personality type.
In Proceedingsof the Joint Annual Meeting of the Interface and theClassification Society of North America, 2005.S.
Bangalore and O. Rambow.
Exploiting a probabilistichierarchical model for generation.
In Proceedings ofthe 18th International Conference on ComputationalLinguistics (COLING), pages 42?48, 2000.A.
Belz.
Corpus-driven generation of weather forecasts.In Proceedings of the 3rd Corpus Linguistics Confer-ence, 2005.J.
Cassell and T. Bickmore.
Negotiated collusion: Mod-eling social language and its relationship effects in in-telligent agents.
User Modeling and User-Adapted In-teraction, 13:89?132, 2003.N.
Chambers and J. Allen.
Stochastic language genera-tion in a dialogue system: Toward a domain indepen-dent generator.
In Proceedings 5th SIGdial Workshopon Discourse and Dialogue, 2004.S.
D. Gosling, P. J. Rentfrow, and W. B. Swann.
Avery brief measure of the big five personality domains.Journal of Research in Personality, 37:504?528, 2003.E.
Hovy.
Generating Natural Language under PragmaticConstraints.
Lawrence Erlbaum Associates, 1988.A.
Isard, C. Brockmann, and J. Oberlander.
Individualityand alignment in generated dialogues.
In Proceedingsof the 4th International Natural Language GenerationConference (INLG), pages 22?29, 2006.I.
Langkilde and K. Knight.
Generation that exploitscorpus-based statistical knowledge.
In Proceedings ofthe 36th Annual Meeting of the Association for Com-putational Linguistics (ACL), pages 704?710, 1998.I.
Langkilde-Geary.
An empirical verification of coverageand correctness for a general-purpose sentence genera-tor.
In Proceedings of the 1st International Conferenceon Natural Language Generation, 2002.M.
Lapata and F. Keller.
Web-based models for natu-ral language processing.
ACM Transactions on Speechand Language Processing, 2:1?31, 2005.J.
Lester, S. Converse, S. Kahler, S. Barlow, B. Stone,and R. Bhogal.
The persona effect: affective impactof animated pedagogical agents.
Proceedings of theSIGCHI conference on Human factors in computingsystems, pages 359?366, 1997.F.
Mairesse and M. A. Walker.
PERSONAGE: Personal-ity generation for dialogue.
In Proceedings of the 45thAnnual Meeting of the Association for ComputationalLinguistics (ACL), pages 496?503, 2007.F.
Mairesse, M. A. Walker, M. R. Mehl, and R. K. Moore.Using linguistic cues for the automatic recognition ofpersonality in conversation and text.
Journal of Artifi-cial Intelligence Research (JAIR), 30:457?500, 2007.M.
R. Mehl, S. D. Gosling, and J. W. Pennebaker.
Person-ality in its natural habitat: Manifestations and implicitfolk theories of personality in daily life.
Journal ofPersonality and Social Psychology, 90:862?877, 2006.C.
Nakatsu and M. White.
Learning to say it well:Reranking realizations by predicted synthesis quality.In Proceedings of the 44th Annual Meeting of the As-sociation for Computational Linguistics (ACL), pages1113?1120, 2006.J.
Oberlander and S. Nowson.
Whose thumb is it any-way?
classifying author personality from weblog text.In Proceedings of the 44th Annual Meeting of the As-sociation for Computational Linguistics (ACL), 2006.D.
S. Paiva and R. Evans.
Empirically-based control ofnatural language generation.
In Proceedings of the43rd Annual Meeting of the Association for Compu-tational Linguistics (ACL), pages 58?65, 2005.J.
W. Pennebaker and L. A.
King.
Linguistic styles: Lan-guage use as an individual difference.
Journal of Per-sonality and Social Psychology, 77:1296?1312, 1999.P.
Piwek.
A flexible pragmatics-driven language gener-ator for animated agents.
In Proceedings of AnnualMeeting of the European Chapter of the Associationfor Computational Linguistics (EACL), 2003.R.
Power, D. Scott, and N. Bouayad-Agha.
Generatingtexts with style.
In Proceedings of the 4th Interna-tional Conference on Intelligent Text Processing andComputational Linguistics, 2003.O.
Rambow, M. Rogati, and M. A. Walker.
Evaluating atrainable sentence planner for a spoken dialogue travelsystem.
In Proceedings of the 39th Annual Meeting ofthe Association for Computational Linguistics (ACL),2001.M.
Rehm and E. Andre?.
From annotated multi-modal corpora to simulated human-like behaviors.In I. Wachsmuth and G. Knoblich, editors, Model-ing Communication with Robots and Virtual Humans.Springer, Berlin, Heidelberg, in press.A.
Stent and H. Guo.
A new data-driven approachfor multimedia presentation generation.
In Proc.
Eu-roIMSA, 2005.M.
A. Walker, J. E. Cahn, and S. J. Whittaker.
Improvis-ing linguistic style: Social and affective bases for agentpersonality.
In Proceedings of the 1st Conference onAutonomous Agents, pages 96?105, 1997.I.
H. Witten and E. Frank.
Data Mining: Practical ma-chine learning tools and techniques.
Morgan Kauf-mann, San Francisco, CA, 2005.173
