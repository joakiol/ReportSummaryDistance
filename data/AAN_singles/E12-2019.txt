Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 92?96,Avignon, France, April 23 - 27 2012. c?2012 Association for Computational LinguisticsA platform for collaborative semantic annotationValerio Basile and Johan Bos and Kilian Evang and Noortje Venhuizen{v.basile,johan.bos,k.evang,n.j.venhuizen}@rug.nlCenter for Language and Cognition Groningen (CLCG)University of Groningen, The NetherlandsAbstractData-driven approaches in computationalsemantics are not common because thereare only few semantically annotated re-sources available.
We are building alarge corpus of public-domain English textsand annotate them semi-automatically withsyntactic structures (derivations in Com-binatory Categorial Grammar) and seman-tic representations (Discourse Representa-tion Structures), including events, thematicroles, named entities, anaphora, scope, andrhetorical structure.
We have created awiki-like Web-based platform on which acrowd of expert annotators (i.e.
linguists)can log in and adjust linguistic analyses inreal time, at various levels of analysis, suchas boundaries (tokens, sentences) and tags(part of speech, lexical categories).
Thedemo will illustrate the different features ofthe platform, including navigation, visual-ization and editing.1 IntroductionData-driven approaches in computational seman-tics are still rare because there are not manylarge annotated resources that provide empiri-cal information about anaphora, presupposition,scope, events, tense, thematic roles, named en-tities, word senses, ellipsis, discourse segmenta-tion and rhetorical relations in a single formal-ism.
This is not surprising, as it is challenging andtime-consuming to create such a resource fromscratch.Nevertheless, our objective is to develop alarge annotated corpus of Discourse Representa-tion Structures (Kamp and Reyle, 1993), com-prising most of the aforementioned phenomena:the Groningen Meaning Bank (GMB).
We aim toreach this goal by:1.
Providing a wiki-like platform supportingcollaborative annotation efforts;2.
Employing state-of-the-art NLP software forbootstrapping semantic analysis;3.
Giving real-time feedback of annotation ad-justments in their resulting syntactic and se-mantic analysis;4.
Ensuring kerfuffle-free dissemination ofour semantic resource by considering onlypublic-domain texts for annotation.We have developed the wiki-like platform fromscratch simply because existing annotation sys-tems, such as GATE (Dowman et al 2005), NITE(Carletta et al 2003), or UIMA (Hahn et al2007), do not offer the functionality required fordeep semantic annotation combined with crowd-sourcing.In this description of our platform, we motivateour choice of data and explain how we manage it(Section 2), we describe the complete toolchainof NLP components employed in the annotation-feedback process (Section 3), and the Web-basedinterface itself is introduced, describing how lin-guists can adjust boundaries of tokens and sen-tences, and revise tags of named entities, parts ofspeech and lexical categories (Section 4).2 DataThe goal of the Groningen Meaning Bank is toprovide a widely available corpus of texts, withdeep semantic annotations.
The GMB only com-prises texts from the public domain, whose dis-tribution isn?t subject to copyright restrictions.Moreover, we include texts from various genresand sources, resulting in a rich, comprehensive92corpus appropriate for use in various disciplineswithin NLP.The documents in the current version of theGMB are all in English and originate from fourmain sources: (i) Voice of America (VOA), an on-line newspaper published by the US Federal Gov-ernment; (ii) the Manually Annotated Sub-Corpus(MASC) from the Open American National Cor-pus (Ide et al 2010); (iii) country descriptionsfrom the CIA World Factbook (CIA) (Central In-telligence Agency, 2006), in particular the Back-ground and Economy sections, and (iv) a col-lection of Aesop?s fables (AF).
All these docu-ments are in the public domain and are thus redis-tributable, unlike for example the WSJ data usedin the Penn Treebank (Miltsakaki et al 2004).Each document is stored with a separate filecontaining metadata.
This may include the lan-guage the text is written in, the genre, date ofpublication, source, title, and terms of use of thedocument.
This metadata is stored as a simplefeature-value list.The documents in the GMB are categorizedwith different statuses.
Initially, newly added doc-uments are labeled as uncategorized.
As we man-ually review them, they are relabeled as eitheraccepted (document will be part of the next sta-ble version, which will be released in regular in-tervals), postponed (there is some difficulty withthe document that can possibly be solved in thefuture) or rejected (something is wrong with thedocument form, i.e., character encoding, or withthe content, e.g., it contains offensive material).Currently, the GMB comprises 70K Englishtext documents (Table 1), corresponding to 1,3million sentences and 31,5 million tokens.Table 1: Documents in the GMB, as of March 5, 2012Documents VOA MASC CIA AF AllAccepted 4,651 34 515 0 5,200Uncategorized 61,090 0 0 834 61,924Postponed 2,397 339 3 1 2,740Rejected 184 27 4 0 215Total 68,322 400 522 835 70,0793 The NLP ToolchainThe process of building the Groningen MeaningBank takes place in a bootstrapping fashion.
Achain of software is run, taking the raw text docu-ments as input.
The output of this automatic pro-cess is in the form of several layers of stand-offannotations, i.e., files with links to the original,raw documents.We employ a chain of NLP components thatcarry out, respectively, tokenization and sentenceboundary detection, POS tagging, lemmatization,named entity recognition, supertagging, parsingusing the formalism of Combinatory CategorialGrammar (Steedman, 2001), and semantic anddiscourse analysis using the framework of Dis-course Representation Theory (DRT) (Kamp andReyle, 1993) with rhetorical relations (Asher,1993).The lemmatizer used is morpha (Minnen et al2001), the other steps are carried out by the C&Ctools (Curran et al 2007) and Boxer (Bos, 2008).3.1 Bits of WisdomAfter each step in the toolchain, the intermediateresult may be automatically adjusted by auxiliarycomponents that apply annotations provided byexpert users or other sources.
These annotationsare represented as ?Bits of Wisdom?
(BOWs): tu-ples of information regarding, for example, tokenand sentence boundaries, tags, word senses or dis-course relations.
They are stored in a MySQLdatabase and can originate from three differentsources: (i) explicit annotation changes made byexperts using the Explorer Web interface (see Sec-tion 4); (ii) an annotation game played by non-experts, similar to ?games with a purpose?
likePhrase Detectives (Chamberlain et al 2008) andJeux de Mots (Artignan et al 2009); and (iii) ex-ternal NLP tools (e.g.
for word sense disambigua-tion or co-reference resolution).Since BOWs come from various sources, theymay contradict each other.
In such cases, a judgecomponent resolves the conflict, currently by pre-ferring the most recent expert BOW.
Future workwill involve the application of different judgingtechniques.3.2 Processing CycleThe widely known open-source tool GNU makeis used to orchestrate the toolchain while avoid-ing unnecessary reprocessing.
The need to rerunthe toolchain for a document arises in three sit-uations: a new BOW for that document is avail-able; a new, improved version of one of the com-ponents is available; or reprocessing is forced bya user via the ?reprocess?
button in the Web inter-face.
A continually running program, the ?updat-93Figure 1: A screenshot of the web interface, displaying a tokenised document.ing daemon?, is responsible for calling make forthe right document at the right time.
It checks thedatabase for new BOWs or manual reprocessingrequests in very short intervals to ensure immedi-ate response to changes experts make via the Webinterface.
It also updates and rebuilds the compo-nents in longer intervals and continuously loopsthrough all documents, remaking them with thenewest versions of the components.
The numberof make processes that can run in parallel is con-figurable; standard techniques of concurrent pro-gramming are used to prevent more than one makeprocess from working simultaneously on the samedocument.4 The Expert InterfaceWe developed a wiki-like Web interface, calledthe GMB Explorer, that provides users access tothe Groningen Meaning Bank.
It fulfills threemain functions: navigation and search through thedocuments, visualization of the different levels ofannotation, and manual correction of the annota-tions.
We will discuss these functions below.4.1 Navigation and SearchThe GMB Explorer allows navigation through thedocuments of the GMB with their stand-off an-notations (Figure 1).
The default order of docu-ments is based on their size in terms of numberof tokens.
It is possible to apply filters to restrictthe set of documents to be shown: showing onlydocuments from a specific subcorpus, or specifi-cally showing documents with/without warningsgenerated by the NLP toolchain.The Explorer interface comes with a built-insearch engine.
It allows users to pose single- ormulti-word queries.
The search results can thenbe restricted further by looking for a specific lex-ical category or part of speech.
A more advancedsearch system that is based on a semantic lexiconwith lexical information about all levels of anno-tation is currently under development.4.2 VisualizationThe different visualization options for a documentare placed in tabs: each tab corresponds to a spe-cific layer of annotation or additional informa-tion.
Besides the raw document text, users canview its tokenized version, an interactive deriva-tion tree per sentence, and the semantic represen-tation of the entire discourse in graphical DRSformat.
There are three further tabs in the Ex-plorer: a tab containing the warnings produced bythe NLP pipeline (if any), one containing the Bitsof Wisdom that have been collected for the docu-ment, and a tab with the document metadata.The sentences view allows the user to show orhide sub-trees per sentence and additional infor-mation such as POS-tags, word senses, supertagsand partial, unresolved semantics.
The deriva-tions are shown using the CCG notation, gener-ated by XSLT stylesheets applied to Boxer?s XMLoutput.
An example is shown in Figure 2.The discourse view shows a fully resolvedsemantic representation in the form of a DRS withFigure 2: An example of a CCG derivation as shownin GMB Explorer.94Figure 3: An example of the semantic representationsin the GMB, with DRSs representing discourse units.rhetorical relations.
Clicking on discourse unitsswitches the visualization between text and se-mantic representation.
Figure 3 shows how DRSsare visualized in the Web interface.4.3 EditingSome of the tabs in the Explorer interface have an?edit?
button.
This allows registered users to man-ually correct certain types of annotations.
Cur-rently, the user can edit the tokenization view andon the derivation view.
Clicking ?edit?
in the to-kenization view gives an annotator the possibilityto add and remove token and sentence boundariesin a simple and intuitive way, as Figure 4 illus-trates.
This editing is done in real-time, followingthe WYSIWYG strategy, with tokens separatedby spaces and sentences separated by new lines.In the derivation view, the annotator can changepart-of-speech tags and named entity tags by se-lecting a tag from a drop-down list (Figure 5).Figure 4: Tokenization edit mode.
Clicking on thered ???
removes a sentence boundary after the token;clicking on the green ?+?
adds a sentence boundary.Figure 5: Tag edit mode, showing derivation with par-tial DRSs and illustrating how to adjust a POS tag.As the updating daemon is running continu-ally, the document is immediately reprocessed af-ter editing so that the user can directly view thenew annotation with his BOW taken into account.Re-analyzing a document typically takes a fewseconds, although for very large documents it cantake longer.
It is also possible to directly rerunthe NLP toolchain on a specific document via the?reprocess?
button, in order to apply the most re-cent version of the software components involved.The GMB Explorer shows a timestamp of the lastprocessing for each document.We are currently working on developing newediting options, which allow users to change dif-ferent aspects of the semantic representation, suchas word senses, thematic roles, co-reference andscope.5 DemoIn the demo session we show the functionality ofthe various features in the Web-based user inter-face of the GMB Explorer, which is available on-line via: http://gmb.let.rug.nl.We show (i) how to navigate and searchthrough all the documents, including the refine-ment of search on the basis of the lexical cate-gory or part of speech, (ii) the operation of the dif-ferent view options, including the raw, tokenized,derivation and semantics view of each document,and (iii) how adjustments to annotations can be re-alised in the Web interface.
More concretely, wedemonstrate how boundaries of tokens and sen-tences can be adapted, and how different types oftags can be changed (and how that affects the syn-tactic, semantic and discourse analysis).In sum, the demo illustrates innovation in theway changes are made and how they improve thelinguistic analysis in real-time.
Because it is aweb-based platform, it paves the way for a collab-orative annotation effort.
Currently it is activelyin use as a tool to create a large semantically an-notated corpus for English texts: the GroningenMeaning Bank.95ReferencesGuillaume Artignan, Mountaz Hascoe?t, and MathieuLafourcade.
2009.
Multiscale visual analysis oflexical networks.
In 13th International Confer-ence on Information Visualisation, pages 685?690,Barcelona, Spain.Nicholas Asher.
1993.
Reference to Abstract Objectsin Discourse.
Kluwer Academic Publishers.Johan Bos.
2008.
Wide-Coverage Semantic Analy-sis with Boxer.
In J. Bos and R. Delmonte, editors,Semantics in Text Processing.
STEP 2008 Confer-ence Proceedings, volume 1 of Research in Compu-tational Semantics, pages 277?286.
College Publi-cations.J.
Carletta, S. Evert, U. Heid, J. Kilgour, J. Robert-son, and H. Voormann.
2003.
The NITE XMLtoolkit: flexible annotation for multi-modal lan-guage data.
Behavior Research Methods, Instru-ments, and Computers, 35(3):353?363.Central Intelligence Agency.
2006.
The CIA WorldFactbook.
Potomac Books.John Chamberlain, Massimo Poesio, and Udo Kr-uschwitz.
2008.
Addressing the Resource Bottle-neck to Create Large-Scale Annotated Texts.
InJohan Bos and Rodolfo Delmonte, editors, Seman-tics in Text Processing.
STEP 2008 Conference Pro-ceedings, volume 1 of Research in ComputationalSemantics, pages 375?380.
College Publications.James Curran, Stephen Clark, and Johan Bos.
2007.Linguistically Motivated Large-Scale NLP withC&C and Boxer.
In Proceedings of the 45th An-nual Meeting of the Association for ComputationalLinguistics Companion Volume Proceedings of theDemo and Poster Sessions, pages 33?36, Prague,Czech Republic.Mike Dowman, Valentin Tablan, Hamish Cunning-ham, and Borislav Popov.
2005.
Web-assisted an-notation, semantic indexing and search of televisionand radio news.
In Proceedings of the 14th Interna-tional World Wide Web Conference, pages 225?234,Chiba, Japan.U.
Hahn, E. Buyko, K. Tomanek, S. Piao, J. Mc-Naught, Y. Tsuruoka, and S. Ananiadou.
2007.An annotation type system for a data-driven NLPpipeline.
In Proceedings of the Linguistic Annota-tion Workshop, pages 33?40, Prague, Czech Repub-lic, June.
Association for Computational Linguis-tics.Nancy Ide, Christiane Fellbaum, Collin Baker, and Re-becca Passonneau.
2010.
The manually annotatedsub-corpus: a community resource for and by thepeople.
In Proceedings of the ACL 2010 Confer-ence Short Papers, pages 68?73, Stroudsburg, PA,USA.Hans Kamp and Uwe Reyle.
1993.
From Discourse toLogic; An Introduction to Modeltheoretic Seman-tics of Natural Language, Formal Logic and DRT.Kluwer, Dordrecht.Eleni Miltsakaki, Rashmi Prasad, Aravind Joshi, andBonnie Webber.
2004.
The Penn Discourse Tree-bank.
In In Proceedings of LREC 2004, pages2237?2240.Guido Minnen, John Carroll, and Darren Pearce.2001.
Applied morphological processing of en-glish.
Journal of Natural Language Engineering,7(3):207?223.Mark Steedman.
2001.
The Syntactic Process.
TheMIT Press.96
