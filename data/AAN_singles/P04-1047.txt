Large-Scale Induction and Evaluation of Lexical Resources from thePenn-II TreebankRuth O?Donovan, Michael Burke, Aoife Cahill, Josef van Genabith, Andy WayNational Centre for Language Technology and School of ComputingDublin City UniversityGlasnevinDublin 9Ireland{rodonovan,mburke,acahill,josef,away}@computing.dcu.ieAbstractIn this paper we present a methodology for ex-tracting subcategorisation frames based on anautomatic LFG f-structure annotation algorithmfor the Penn-II Treebank.
We extract abstractsyntactic function-based subcategorisation frames(LFG semantic forms), traditional CFG category-based subcategorisation frames as well as mixedfunction/category-based frames, with or withoutpreposition information for obliques and particle in-formation for particle verbs.
Our approach doesnot predefine frames, associates probabilities withframes conditional on the lemma, distinguishes be-tween active and passive frames, and fully reflectsthe effects of long-distance dependencies in thesource data structures.
We extract 3586 verb lem-mas, 14348 semantic form types (an average of 4per lemma) with 577 frame types.
We present alarge-scale evaluation of the complete set of formsextracted against the full COMLEX resource.1 IntroductionLexical resources are crucial in the constructionof wide-coverage computational systems based onmodern syntactic theories (e.g.
LFG, HPSG, CCG,LTAG etc.).
However, as manual construction ofsuch lexical resources is time-consuming, error-prone, expensive and rarely ever complete, it is of-ten the case that limitations of NLP systems basedon lexicalised approaches are due to bottlenecks inthe lexicon component.Given this, research on automating lexical acqui-sition for lexically-based NLP systems is a partic-ularly important issue.
In this paper we present anapproach to automating subcategorisation frame ac-quisition for LFG (Kaplan and Bresnan, 1982) i.e.grammatical function-based systems.
LFG has twolevels of structural representation: c(onstituent)-structure, and f(unctional)-structure.
LFG differ-entiates between governable (argument) and non-governable (adjunct) grammatical functions.
Sub-categorisation requirements are enforced throughsemantic forms specifying the governable grammat-ical functions required by a particular predicate (e.g.FOCUS?(?
SUBJ)(?
OBLon)?).
Our approach isbased on earlier work on LFG semantic form extrac-tion (van Genabith et al, 1999) and recent progressin automatically annotating the Penn-II treebankwith LFG f-structures (Cahill et al, 2004b).
De-pending on the quality of the f-structures, reliableLFG semantic forms can then be generated quitesimply by recursively reading off the subcategoris-able grammatical functions for each local predvalue at each level of embedding in the f-structures.The work reported in (van Genabith et al, 1999)was small scale (100 trees), proof of concept andrequired considerable manual annotation work.
Inthis paper we show how the extraction process canbe scaled to the complete Wall Street Journal (WSJ)section of the Penn-II treebank, with about 1 mil-lion words in 50,000 sentences, based on the au-tomatic LFG f-structure annotation algorithm de-scribed in (Cahill et al, 2004b).
In addition to ex-tracting grammatical function-based subcategorisa-tion frames, we also include the syntactic categoriesof the predicate and its subcategorised arguments,as well as additional details such as the prepositionsrequired by obliques, and particles accompanyingparticle verbs.
Our method does not predefine theframes to be extracted.
In contrast to many otherapproaches, it discriminates between active and pas-sive frames, properly reflects long distance depen-dencies and assigns conditional probabilities to thesemantic forms associated with each predicate.Section 2 reviews related work in the area ofautomatic subcategorisation frame extraction.
Ourmethodology and its implementation are presentedin Section 3.
Section 4 presents the results of ourlexical extraction.
In Section 5 we evaluate thecomplete extracted lexicon against the COMLEXresource (MacLeod et al, 1994).
To our knowl-edge, this is the largest evaluation of subcategorisa-tion frames for English.
In Section 6, we concludeand give suggestions for future work.2 Related WorkCreating a (subcategorisation) lexicon by hand istime-consuming, error-prone, requires considerablelinguistic expertise and is rarely, if ever, complete.In addition, a system incorporating a manually con-structed lexicon cannot easily be adapted to specificdomains.
Accordingly, many researchers have at-tempted to construct lexicons automatically, espe-cially for English.
(Brent, 1993) relies on local morphosyntacticcues (such as the -ing suffix, except where such aword follows a determiner or a preposition otherthan to) in the untagged Brown Corpus as proba-bilistic indicators of six different predefined subcat-egorisation frames.
The frames do not include de-tails of specific prepositions.
(Manning, 1993) ob-serves that Brent?s recognition technique is a ?rathersimplistic and inadequate approach to verb detec-tion, with a very high error rate?.
Manning feedsthe output from a stochastic tagger into a finite stateparser, and applies statistical filtering to the parsingresults.
He predefines 19 different subcategorisationframes, including details of prepositions.
Applyingthis technique to approx.
4 million words of NewYork Times newswire, Manning acquires 4900 sub-categorisation frames for 3104 verbs, an average of1.6 per verb.
(Ushioda et al, 1993) run a finite stateNP parser on a POS-tagged corpus to calculate therelative frequency of just six subcategorisation verbclasses.
In addition, all prepositional phrases aretreated as adjuncts.
For 1565 tokens of 33 selectedverbs, they report an accuracy rate of 83%.
(Briscoe and Carroll, 1997) observe that in thework of (Brent, 1993), (Manning, 1993) and (Ush-ioda et al, 1993), ?the maximum number of distinctsubcategorization classes recognized is sixteen, andonly Ushioda et al attempt to derive relative subcat-egorization frequency for individual predicates?.
Incontrast, the system of (Briscoe and Carroll, 1997)distinguishes 163 verbal subcategorisation classesby means of a statistical shallow parser, a classifierof subcategorisation classes, and a priori estimatesof the probability that any verb will be a memberof those classes.
More recent work by Korhonen(2002) on the filtering phase of this approach hasimproved results.
Korhonen experiments with theuse of linguistic verb classes for obtaining more ac-curate back-off estimates for use in hypothesis se-lection.
Using this extended approach, the averageresults for 45 semantically classified test verbs eval-uated against hand judgements are precision 87.1%and recall 71.2%.
By comparison, the average re-sults for 30 verbs not classified semantically are pre-cision 78.2% and recall 58.7%.Carroll and Rooth (1998) use a hand-writtenhead-lexicalised context-free grammar and a textcorpus to compute the probability of particular sub-categorisation scenarios.
The extracted frames donot contain details of prepositions.More recently, a number of researchers haveapplied similar techniques to derive resources forother languages, especially German.
One of these,(Schulte im Walde, 2002), induces a computationalsubcategorisation lexicon for over 14,000 Germanverbs.
Using sentences of limited length, she ex-tracts 38 distinct frame types, which contain max-imally three arguments each.
The frames may op-tionally contain details of particular prepositionaluse.
Her evaluation on over 3000 frequently occur-ring verbs against the German dictionary Duden -Das Stilwo?rterbuch is similar in scale to ours and isdiscussed further in Section 5.There has also been some work on extractingsubcategorisation details from the Penn Treebank.
(Kinyon and Prolo, 2002) introduce a tool whichuses fine-grained rules to identify the arguments,including optional arguments, of each verb occur-rence in the Penn Treebank, along with their syn-tactic functions.
They manually examined the 150+possible sequences of tags, both functional and cat-egorial, in Penn-II and determined whether the se-quence in question denoted a modifier, argument oroptional argument.
Arguments were then mappedto traditional syntactic functions.
As they do not in-clude an evaluation, currently it is impossible to sayhow effective this technique is.
(Xia et al, 2000) and (Chen and Vijay-Shanker,2000) extract lexicalised TAGs from the Penn Tree-bank.
Both techniques implement variations onthe approaches of (Magerman, 1994) and (Collins,1997) for the purpose of differentiating betweencomplement and adjunct.
In the case of (Xia et al,2000), invalid elementary trees produced as a resultof annotation errors in the treebank are filtered outusing linguistic heuristics.
(Hockenmaier et al, 2002) outline a method forthe automatic extraction of a large syntactic CCGlexicon from Penn-II.
For each tree, the algorithmannotates the nodes with CCG categories in a top-down recursive manner.
In order to examine thecoverage of the extracted lexicon in a manner simi-lar to (Xia et al, 2000), (Hockenmaier et al, 2002)compared the reference lexicon acquired from Sec-tions 02-21 with a test lexicon extracted from Sec-tion 23 of the WSJ.
It was found that the referenceCCG lexicon contained 95.09% of the entries in thetest lexicon, while 94.03% of the entries in the testTAG lexicon also occurred in the reference lexicon.Both approaches involve extensive correction andclean-up of the treebank prior to lexical extraction.3 Our MethodologyThe first step in the application of our methodologyis the production of a treebank annotated with LFGf-structure information.
F-structures are featurestructures which represent abstract syntactic infor-mation, approximating to basic predicate-argument-modifier structures.
We utilise the automatic anno-tation algorithm of (Cahill et al, 2004b) to derivea version of Penn-II where each node in each treeis annotated with an LFG functional annotation (i.e.an attribute value structure equation).
Trees are tra-versed top-down, and annotation is driven by cate-gorial, basic configurational, trace and Penn-II func-tional tag information in local subtrees of mostlydepth one (i.e.
CFG rules).
The annotation proce-dure is dependent on locating the head daughter, forwhich the scheme of (Magerman, 1994) with somechanges and amendments is used.
The head is anno-tated with the LFG equation ?=?.
Linguistic gen-eralisations are provided over the left (the prefix)and the right (suffix) context of the head for eachsyntactic category occurring as the mother node ofsuch heads.
To give a simple example, the rightmostNP to the left of a VP head under an S is likely tobe its subject (?
SUBJ =?
), while the leftmost NPto the right of the V head of a VP is most proba-bly its object (?
OBJ =?).
(Cahill et al, 2004b)provide four sets of annotation principles, one fornon-coordinate configurations, one for coordinateconfigurations, one for traces (long distance depen-dencies) and a final ?catch all and clean up?
phase.Distinguishing between argument and adjunct is aninherent step in the automatic assignment of func-tional annotations.The satisfactory treatment of long distance de-pendencies by the annotation algorithm is impera-tive for the extraction of accurate semantic forms.The Penn Treebank employs a rich arsenal of tracesand empty productions (nodes which do not re-alise any lexical material) to co-index displaced ma-terial with the position where it should be inter-preted semantically.
The algorithm of (Cahill etal., 2004b) translates the traces into correspondingre-entrancies in the f-structure representation (Fig-ure 1).
Passive movement is also captured and ex-pressed at f-structure level using a passive:+ an-notation.
Once a treebank tree is annotated withfeature structure equations by the annotation algo-rithm, the equations are collected and passed to aconstraint solver which produces the f-structures.In order to ensure the quality of the seman-SS-TPC- 1NPU.N.VPVsignsNPtreatyNPDettheNheadlineVPVsaidST- 1??????
?TOPIC[SUBJ[PRED U.N.]PRED signOBJ[PRED treaty]]1SUBJ[SPEC thePRED headline]PRED sayCOMP 1??????
?Figure 1: Penn-II style tree with long distance depen-dency trace and corresponding reentrancy in f-structuretic forms extracted by our method, we must firstensure the quality of the f-structure annotations.
(Cahill et al, 2004b) measure annotation qualityin terms of precision and recall against manuallyconstructed, gold-standard f-structures for 105 ran-domly selected trees from section 23 of the WSJsection of Penn-II.
The algorithm currently achievesan F-score of 96.3% for complete f-structures and93.6% for preds-only f-structures.1Our semantic form extraction methodology isbased on the procedure of (van Genabith et al,1999): For each f-structure generated, for eachlevel of embedding we determine the local PREDvalue and collect the subcategorisable grammat-ical functions present at that level of embed-ding.
Consider the f-structure in Figure 1.
Fromthis we recursively extract the following non-empty semantic forms: say([subj,comp]),sign([subj,obj]).
In effect, in both (vanGenabith et al, 1999) and our approach seman-tic forms are reverse engineered from automaticallygenerated f-structures for treebank trees.
We ex-tract the following subcategorisable syntactic func-tions: SUBJ, OBJ, OBJ2, OBLprep, OBL2prep, COMP,XCOMP and PART.
Adjuncts (e.g.
ADJ, APP etc)are not included in the semantic forms.
PARTis not a syntactic function in the strict sense butwe capture the relevant co-occurrence patterns ofverbs and particles in the semantic forms.
Justas OBL includes the prepositional head of the PP,PART includes the actual particle which occurs e.g.add([subj,obj,part:up]).In the work presented here we substantially ex-tend the approach of (van Genabith et al, 1999) as1Preds-only measures only paths ending in PRED:VALUE sofeatures such as number, person etc are not included.regards coverage, granularity and evaluation: First,we scale the approach of (van Genabith et al, 1999)which was proof of concept on 100 trees to the fullWSJ section of the Penn-II Treebank.
Second, ourapproach fully reflects long distance dependencies,indicated in terms of traces in the Penn-II Tree-bank and corresponding re-entrancies at f-structure.Third, in addition to abstract syntactic function-based subcategorisation frames we compute framesfor syntactic function-CFG category pairs, both forthe verbal heads and their arguments and also gen-erate pure CFG-based subcat frames.
Fourth, ourmethod differentiates between frames captured foractive or passive constructions.
Fifth, our methodassociates conditional probabilities with frames.In contrast to much of the work reviewed in theprevious section, our system is able to produce sur-face syntactic as well as abstract functional subcat-egorisation details.
To incorporate CFG details intothe extracted semantic forms, we add an extra fea-ture to the generated f-structures, the value of whichis the syntactic category of the pred at each levelof embedding.
Exploiting this information, the ex-tracted semantic form for the verb sign looks as fol-lows: sign(v,[subj(np),obj(np)]).We have also extended the algorithm to deal withpassive voice and its effect on subcategorisation be-haviour.
Consider Figure 2: not taking voice intoaccount, the algorithm extracts an intransitive frameoutlaw([subj]) for the transitive outlaw.
Tocorrect this, the extraction algorithm uses the fea-ture value pair passive:+, which appears in thef-structure at the level of embedding of the verb inquestion, to mark that predicate as occurring in thepassive: outlaw([subj],p).In order to estimate the likelihood of the cooc-currence of a predicate with a particular argumentlist, we compute conditional probabilities for sub-categorisation frames based on the number of tokenoccurrences in the corpus.
Given a lemma l and anargument list s, the probability of s given l is esti-mated as:P(s|l) := count(l, s)?ni=1 count(l, si)We use thresholding to filter possible error judge-ments by our system.
Table 1 shows the attestedsemantic forms for the verb accept with their as-sociated conditional probabilities.
Note that werethe distinction between active and passive not takeninto account, the intransitive occurrence of acceptwould have been assigned an unmerited probability.subj : spec : quant : pred : alladjunct : 2 : pred : almostadjunct : 3 : pred : remainparticiple : pres4 : obj : adjunct : 5 : pred : cancer-causingpers : 3pred : asbestosnum : sgpform : ofpers : 3pred : usenum : plpassive : +adjunct : 1 : obj : pred : 1997pform : byxcomp : subj : spec: quant : pred : alladjunct : 2 : pred : almost......passive : +xcomp : subj : spec: quant : pred : alladjunct : 2 : pred : almost......passive : +pred : outlawtense : pastpred : bepred : willmodal : +Figure 2: Automatically generated f-structurefor the string wsj 0003 23?By 1997, almostall remaining uses of cancer-causingasbestos will be outlawed.
?Semantic Form Frequency Probabilityaccept([subj,obj]) 122 0.813- accept([subj],p) 9 0.060accept([subj,comp]) 5 0.033- accept([subj,obl:as],p) 3 0.020accept([subj,obj,obl:as]) 3 0.020accept([subj,obj,obl:from]) 3 0.020- accept([subj]) 2 0.013accept([subj,obj,obl:at]) 1 0.007accept([subj,obj,obl:for]) 1 0.007accept([subj,obj,xcomp]) 1 0.007Table 1: Semantic Forms for the verb accept markedwith p for passive use.4 ResultsWe extract non-empty semantic forms2 for 3586verb lemmas and 10969 unique verbal semanticform types (lemma followed by non-empty argu-ment list).
Including prepositions associated withthe OBLs and particles, this number rises to 14348,an average of 4.0 per lemma (Table 2).
The num-ber of unique frame types (without lemma) is 38without specific prepositions and particles, 577 with(Table 3).
F-structure annotations allow us to distin-guish passive and active frames.5 COMLEX EvaluationWe evaluated our induced (verbal) semantic formsagainst COMLEX (MacLeod et al, 1994).
COM-2Frames with at least one subcategorised grammatical func-tion.Without Prep/Part With Prep/PartSem.
Form Types 10969 14348Active 8516 11367Passive 2453 2981Table 2: Number of Semantic Form TypesWithout Prep/Part With Prep/Part# Frame Types 38 577# Singletons 1 243# Twice Occurring 1 84# Occurring max.
5 7 415# Occurring > 5 31 162Table 3: Number of Distinct Frames for Verbs (not in-cluding syntactic category for grammatical function)LEX defines 138 distinct verb frame types withoutthe inclusion of specific prepositions or particles.The following is a sample entry for the verbreimburse:(VERB :ORTH ?reimburse?
:SUBC ((NP-NP)(NP-PP :PVAL (?for?
))(NP)))Each verb has a :SUBC feature, specifyingits subcategorisation behaviour.
For example,reimburse can occur with two noun phrases(NP-NP), a noun phrase and a prepositional phraseheaded by ?for?
(NP-PP :PVAL (?for?))
or a singlenoun phrase (NP).
Note that the details of the subjectnoun phrase are not included in COMLEX frames.Each of the complement types which make up thevalue of the :SUBC feature is associated with a for-mal frame definition which looks as follows:(vp-frame np-np :cs ((np 2)(np 3)):gs (:subject 1 :obj 2 :obj2 3):ex ?she asked him his name?
)The value of the :cs feature is the constituent struc-ture of the subcategorisation frame, which lists thesyntactic CF-PSG constituents in sequence.
Thevalue of the :gs feature is the grammatical struc-ture which indicates the functional role played byeach of the CF-PSG constituents.
The elements ofthe constituent structure are indexed, and referencedin the :gs field.
This mapping between constituentstructure and functional structure makes the infor-mation contained in COMLEX suitable as an eval-uation standard for the LFG semantic forms whichwe induce.5.1 COMLEX-LFG MappingWe devised a common format for our induced se-mantic forms and those contained in COMLEX.This is summarised in Table 4.
COMLEX doesnot distinguish between obliques and objects so weconverted Obji to OBLi as required.
In addition,COMLEX does not explicitly differentiate betweenCOMPs and XCOMPs, but does encode control in-formation for any Comps which occur, thus allow-ing us to deduce the distinction automatically.
Themanually constructed COMLEX entries provided uswith a gold standard against which we evaluated theautomatically induced frames for the 2992 (active)verbs that both resources have in common.LFG COMLEX MergedSUBJ Subject SUBJOBJ Object OBJOBJ2 Obj2 OBJ2OBL Obj3 OBLOBL2 Obj4 OBL2COMP Comp COMPXCOMP Comp XCOMPPART Part PARTTable 4: COMLEX and LFG Syntactic FunctionsWe use the computed conditional probabilities to seta threshold to filter the selection of semantic forms.As some verbs occur less frequently than others wefelt it was important to use a relative rather than ab-solute threshold.
For a threshold of 1%, we disre-gard any frames with a conditional probability ofless than or equal to 0.01.
We carried out the evalu-ation in a similar way to (Schulte im Walde, 2002).The scale of our evaluation is comparable to hers.This allows us to make tentative comparisons be-tween our respective results.
The figures shown inTable 5 are the results of three different kinds ofevaluation with the threshold set to 1% and 5%.
Theeffect of the threshold increase is obvious in thatPrecision goes up for each of the experiments whileRecall goes down.For Exp 1, we excluded prepositional phrases en-tirely from the comparison, i.e.
assumed that PPswere adjunct material (e.g.
[subj,obl:for] becomes[subj]).
Our results are better for Precision than forRecall compared to Schulte im Walde (op cit.
), whoreports Precision of 74.53%, Recall of 69.74% andan F-score of 72.05%.Exp 2 includes prepositional phrases but notparameterised for particular prepositions (e.g.
[subj,obl:for] becomes [subj,obl]).
While our fig-ures for Recall are again lower, our results forPrecision are considerably higher than those ofSchulte im Walde (op cit.)
who recorded Preci-sion of 60.76%, Recall of 63.91% and an F-scoreof 62.30%.For Exp.
3, we used semantic forms which con-tained details of specific prepositions for any sub-categorised prepositional phrase.
Our Precision fig-ures are again high (in comparison to 65.52% asrecorded by (Schulte im Walde, 2002)).
However,Threshold 1% Threshold 5%P R F-Score P R F-ScoreExp.
1 79.0% 59.6% 68.0% 83.5% 54.7% 66.1%Exp.
2 77.1% 50.4% 61.0% 81.4% 44.8% 57.8%Exp.
2a 76.4% 44.5% 56.3% 80.9% 39.0% 52.6%Exp.
3 73.7% 22.1% 34.0% 78.0% 18.3% 29.6%Exp.
3a 73.3% 19.9% 31.3% 77.6% 16.2% 26.8%Table 5: COMLEX Comparisonour Recall is very low (compared to the 50.83% thatSchulte im Walde (op cit.)
reports).
Consequentlyour F-score is also low (Schulte im Walde (op cit.
)records an F-score of 57.24%).
Experiments 2a and3a are similar to Experiments 2 and 3 respectivelyexcept they include the specific particle associatedwith each PART.5.1.1 Directional PrepositionsThere are a number of possible reasons for ourlow recall scores for Experiment 3 in Table 5.
Itis a well-documented fact (Briscoe and Carroll,1997) that subcategorisation frames (and their fre-quencies) vary across domains.
We have extractedframes from one domain (the WSJ) whereas COM-LEX was built using examples from the San JoseMercury News, the Brown Corpus, several literaryworks from the Library of America, scientific ab-stracts from the U.S. Department of Energy, andthe WSJ.
For this reason, it is likely to containa greater variety of subcategorisation frames thanour induced lexicon.
It is also possible that dueto human error COMLEX contains subcategorisa-tion frames, the validity of which may be in doubt.This is due to the fact that the aim of the COMLEXproject was to construct as complete a set of subcat-egorisation frames as possible, even for infrequentverbs.
Lexicographers were allowed to extrapo-late from the citations found, a procedure whichis bound to be less certain than the assignment offrames based entirely on existing examples.
Our re-call figure was particularly low in the case of eval-uation using details of prepositions (Experiment 3).This can be accounted for by the fact that COMLEXerrs on the side of overgeneration when it comes topreposition assignment.
This is particularly true ofdirectional prepositions, a list of 31 of which hasbeen prepared and is assigned in its entirety by de-fault to any verb which can potentially appear withany directional preposition.
In a subsequent exper-iment, we incorporate this list of directional prepo-sitions by default into our semantic form inductionprocess in the same way as the creators of COM-LEX have done.
Table 6 shows the results of thisexperiment.
As expected there is a significant im-Precision Recall F-ScoreExperiment 3 81.7% 40.8% 54.4%Experiment 3a 83.1% 35.4% 49.7%Table 6: COMLEX Comparison using p-dir(Thresholdof 1%)Passive Precision Recall F-ScoreExperiment 2 80.2% 54.7% 65.1%Experiment 2a 79.7% 46.2% 58.5%Experiment 3 72.6% 33.4% 45.8%Experiment 3a 72.3% 29.3% 41.7%Table 7: Passive evaluation (Threshold of 1%)provement in the recall figure, being almost doublethe figures reported in Table 5 for Experiments 3and 3a.5.1.2 Passive EvaluationTable 7 presents the results of our evaluation ofthe passive semantic forms we extract.
It wascarried out for 1422 verbs which occur with pas-sive frames and are shared by the induced lexiconand COMLEX.
As COMLEX does not provide ex-plicit passive entries, we applied Lexical Redun-dancy Rules (Kaplan and Bresnan, 1982) to auto-matically convert the active COMLEX frames totheir passive counterparts.
For example, the COM-LEX entry see([subj,obj]) is converted tosee([subj]).
The resulting precision is veryhigh, a slight increase on that for the active frames.The recall score drops for passive frames (from54.7% to 29.3%) in a similar way to that for activeframes when prepositional details are included.5.2 Lexical Accession RatesAs well as evaluating the quality of our extractedsemantic forms, we also examine the rate at whichthey are induced.
(Charniak, 1996) and (Krotov etal., 1998) observed that treebank grammars (CFGsextracted from treebanks) are very large and growwith the size of the treebank.
We were interested indiscovering whether the acquisition of lexical mate-rial on the same data displays a similar propensity.Figure 3 displays the accession rates for the seman-tic forms induced by our method for sections 0?24of the WSJ section of the Penn-II treebank.
Whenwe do not distinguish semantic forms by category,all semantic forms together with those for verbs dis-play smaller accession rates than for the PCFG.We also examined the coverage of our system ina similar way to (Hockenmaier et al, 2002).
We ex-tracted a verb-only reference lexicon from Sections02-21 of the WSJ and subsequently compared thisto a test lexicon constructed in the same way from05000100001500020000250000  5  10  15  20  25No.of SFs/RulesWSJ SectionAll SF FramesAll VerbsAll SF Frames, no categoryAll Verbs, no categoryPCFGFigure 3: Accession Rates for Semantic Forms and CFGRulesEntries also in reference lexicon: 89.89%Entries not in reference lexicon: 10.11%Known words: 7.85%- Known words, known frames: 7.85%- Known words, unknown frames: -Unknown words: 2.32%- Unknown words, known frames: 2.32%- Unknown words, unknown frames: -Table 8: Coverage of induced lexicon on unseendata (Verbs Only)Section 23.
Table 8 shows the results of this ex-periment.
89.89% of the entries in the test lexiconappeared in the reference lexicon.6 ConclusionsWe have presented an algorithm and its implementa-tion for the extraction of semantic forms or subcate-gorisation frames from the Penn-II Treebank, auto-matically annotated with LFG f-structures.
We havesubstantially extended an earlier approach by (vanGenabith et al, 1999).
The original approach wassmall-scale and ?proof of concept?.
We have scaledour approach to the entire WSJ Sections of Penn-II (50,000 trees).
Our approach does not predefinethe subcategorisation frames we extract as manyother approaches do.
We extract abstract syntac-tic function-based subcategorisation frames (LFGsemantic forms), traditional CFG category-basedframes as well as mixed function-category basedframes.
Unlike many other approaches to subcate-gorisation frame extraction, our system properly re-flects the effects of long distance dependencies anddistinguishes between active and passive frames.Finally our system associates conditional probabil-ities with the frames we extract.
We carried out anextensive evaluation of the complete induced lexi-con (not just a sample) against the full COMLEXresource.
To our knowledge, this is the most exten-sive qualitative evaluation of subcategorisation ex-traction in English.
The only evaluation of a similarscale is that carried out by (Schulte im Walde, 2002)for German.
Our results compare well with hers.We believe our semantic forms are fine-grained andby choosing to evaluate against COMLEX we setour sights high: COMLEX is considerably moredetailed than the OALD or LDOCE used for otherevaluations.Currently work is under way to extend the cov-erage of our acquired lexicons by applying ourmethodology to the Penn-III treebank, a more bal-anced corpus resource with a number of text gen-res (in addition to the WSJ sections).
It is impor-tant to realise that the induction of lexical resourcesis part of a larger project on the acquisition ofwide-coverage, robust, probabilistic, deep unifica-tion grammar resources from treebanks.
We are al-ready using the extracted semantic forms in parsingnew text with robust, wide-coverage PCFG-basedLFG grammar approximations automatically ac-quired from the f-structure annotated Penn-II tree-bank (Cahill et al, 2004a).
We hope to be able toapply our lexical acquisition methodology beyondexisting parse-annotated corpora (Penn-II and Penn-III): new text is parsed by our PCFG-based LFG ap-proximations into f-structures from which we canthen extract further semantic forms.
The work re-ported here is part of the core component for boot-strapping this approach.As the extraction algorithm we presented derivessemantic forms at f-structure level, it is easily ap-plied to other, even typologically different, lan-guages.
We have successfully ported our automaticannotation algorithm to the TIGER Treebank, de-spite German being a less configurational languagethan English, and extracted wide-coverage, proba-bilistic LFG grammar approximations and lexicalresources for German (Cahill et al, 2003).
Cur-rently, we are migrating the technique to Spanish,which has freer word order than English and lessmorphological marking than German.
Preliminaryresults have been very encouraging.7 AcknowledgementsThe research reported here is supported by Enter-prise Ireland Basic Research Grant SC/2001/186and an IRCSET PhD fellowship award.ReferencesM.
Brent.
1993.
From Grammar to Lexicon: Unsu-pervised Learning of Lexical Syntax.
Computa-tional Linguistics, 19(2):203?222.E.
Briscoe and J. Carroll.
1997.
Automatic Extrac-tion of Subcategorization from Corpora.
In Pro-ceedings of the 5th ACL Conference on AppliedNatural Language Processing, pages 356?363,Washington, DC.A.
Cahill, M. Forst, M. McCarthy, R. O?Donovan,C.
Rohrer, J. van Genabith, and A. Way.2003.
Treebank-Based Multilingual Unification-Grammar Development.
In Proceedings of theWorkshop on Ideas and Strategies for Multilin-gual Grammar Development at the 15th ESSLLI,pages 17?24, Vienna, Austria.A.
Cahill, M. Burke, R. O?Donovan, J. van Gen-abith, and A.
Way.
2004a.
Long-Distance De-pendency Resolution in Automatically AcquiredWide-Coverage PCFG-Based LFG Approxima-tions.
In Proceedings of the 42nd Annual Con-ference of the Association for Computational Lin-guistics (ACL-04), Barcelona, Spain.A.
Cahill, M. McCarthy, M. Burke, R. O?Donovan,J.
van Genabith, and A.
Way.
2004b.
EvaluatingAutomatic F-Structure Annotation for the Penn-II Treebank.
Journal of Research on Languageand Computation.G.
Carroll and M. Rooth.
1998.
Valence Induc-tion with a Head-Lexicalised PCFG.
In Proceed-ings of the 3rd Conference on Empirical Meth-ods in Natural Language Processing, pages 36?45, Granada, Spain.E.
Charniak.
1996.
Tree-bank Grammars.
In AAAI-96: Proceedings of the Thirteenth National Con-ference on Artificial Intelligence, MIT Press,pages 1031?1036, Cambridge, MA.J.
Chen and K. Vijay-Shanker.
2000.
AutomatedExtraction of TAGs from the Penn Treebank.
InProceedings of the 38th Annual Meeting of theAssociation of Computational Linguistics, pages65?76, Hong Kong.M.
Collins.
1997.
Three generative lexicalisedmodels for statistical parsing.
In Proceedings ofthe 35th Annual Meeting of the Association forComputational Linguistics, pages 16?23.J.
Hockenmaier, G. Bierner, and J. Baldridge.
2002.Extending the Coverage of a CCG System.
Jour-nal of Language and Computation, (2).R.
Kaplan and J. Bresnan.
1982.
Lexical Func-tional Grammar: A Formal System for Gram-matical Representation.
In Joan Bresnan, editor,The Mental Representation of Grammatical Re-lations, pages 206?250.
MIT Press, Cambridge,MA, Mannheim, 8th Edition.A.
Kinyon and C. Prolo.
2002.
Identifying Verb Ar-guments and their Syntactic Function in the PennTreebank.
In Proceedings of the 3rd LREC Con-ference, pages 1982?1987, Las Palmas, Spain.A.
Korhonen.
2002.
Subcategorization Acquisition.PhD thesis published as Techical Report UCAM-CL-TR-530, Computer Laboratory, University ofCambridge, UK.A.
Krotov, M. Hepple, R. Gaizauskas, and Y. Wilks.1998.
Compacting the Penn Treebank Grammar.In Proceedings of COLING-ACL?98, pages 669?703, Montreal, Canada.C.
MacLeod, R. Grishman, and A. Meyers.
1994.The Comlex Syntax Project: The First Year.
InProceedings of the ARPA Workshop on HumanLanguage Technology, pages 669?703, Prince-ton, NJ.D.
Magerman.
1994.
Natural Language Parsingas Statistical Pattern Recognition.
PhD Thesis,Stanford University, CA.C.
Manning.
1993.
Automatic Acquisition of aLarge Subcategorisation Dictionary from Cor-pora.
In Proceedings of the 31st Annual Meetingof the Association for Computational Linguistics,pages 235?242, Columbus, OH.S.
Schulte im Walde.
2002.
Evaluating Verb Sub-categorisation Frames learned by a German Sta-tistical Grammar against Manual Definitions inthe Duden Dictionary.
In Proceedings of the 10thEURALEX International Congress, pages 187?197, Copenhagen, Denmark.A.
Ushioda, D. Evans, T. Gibson, and A. Waibel.1993.
The Automatic Acquisition of Frequenciesof Verb Subcategorization Frames from TaggedCorpora.
In SIGLEX ACL Workshop on the Ac-quisition of Lexical Knowledge from Text, pages95?106, Columbus, OH.J.
van Genabith, A.
Way, and L. Sadler.
1999.
Data-driven Compilation of LFG Semantic Forms.
InEACL-99 Workshop on Linguistically InterpretedCorpora, pages 69?76, Bergen, Norway.F.
Xia, M. Palmer, and A. Joshi.
2000.
A UniformMethod of Grammar Extraction and its Applica-tions.
In Proceedings of the Conference on Em-pirical Methods in Natural Language Processing(EMNLP-2000), pages 53?62, Hong Kong.
