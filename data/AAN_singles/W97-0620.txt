Dia logue Strategies for Improving the Usabi l i ty  of Te lephoneHuman-Mach ine  Communicat ionMorena Danieli, Elisabetta Gerbino, and Loreta M. MoisaCSELT - Centro Studi e Laborator i  TelecomunicazioniVia G. Reiss-Romoli 2741-10148, Torino, Italiadanieli,gerbino,loret a@cselt .itAbst rac tInteractions with spoken language systemsmay present breakdowns that are due toerrors in the acoustic decoding of user ut-terances.
Some of these errors have impor-tant consequences in reducing the natural-ness of human-machine dialogues.
In thispaper we identify some typologies of recog-nition errors that cannot be recovered ur-ing the syntactico-semantic analysis, butthat may be effectively approached at thedialogue level.
We will describe how non-understanding and the effects of misrecog-nition are dealt with by Dialogos, a real-time spoken dialogue system that allowsusers to access a database of railway in-formation by telephone.
We will discussthe importance of supporting confirmationturns, and clarification and correction sub-dialogues.
We will show the positive ffectsof robust dialogue management and dia-logue state dependent language modeling,by taking into account both the recogni-tion and understanding performance, andthe success rate of dialogue transactions.1 In t roduct ionDuring the last few years the recognition of sponta-neous speech in telephone applications "has greatlyimproved; nevertheless spoken dialogue betweencomputers and inexperienced users still presentssome problematic ssues that reduce the user satis-faction in interacting with spoken language systems.The occurrence of errors in the acoustic decod-ing of users' utterance is the potential cause of mis-communication in oral interaction with spoken lan-guage systems.
Some of these errors have importantconsequences in reducing the naturalness ofhuman-machine dialogues.
Sometimes a robust approach inparsing and the use of language models during recog-nition are not sufficient o avoid recognition break-downs.
The recognition performance has a directimpact on the requirements hat the dialogue mod-ules of spoken language systems have to meet.
Inorder to increase the usability of the applications, di-alogue management modules have to deal with par-tial or total breakdowns of the lower levels of anal-ysis by preventing and detecting miscommunicationsources.In this paper we identify some typologies of recog-nition errors that cannot be recovered uring thesyntactico-semantic analysis, but that may be effec-tively approached at the dialogue level.
Our anal-ysis and the methodologies we describe have beentested in a task-oriented telephone application, butwe deem that some considerations may also be use-ful for other display-less human-machine commu-nication applications.
We will describe how non-understanding and the effects of misrecognition aredealt with in Dialogos, a real-time spoken languagesystem that allows/users to access a database of rail-way information by using the telephone.
A detaileddescription of the different modules of Dialogos maybe found in (Albesano et al, 1997).
In this paperwe will discuss the importance of supporting confir-mation turns, and clarification and correction subdi-alogues.
The dialogue module of Dialogos makes anextensive use of context knowledge: contextual in-formation is used not only for validating or rejectingsemantic interpretations, but it is also sent to thelower levels of input analysis for helping the recog-nizer.
We will show that the positive ffects of robustdialogue management and dialogue state dependentlanguage modeling may be evaluated by taking intoaccount both the recognition and understanding per-formance, and the success rate of dialogue transac-tions.From our experience we may conclude that ifwe provide robust behaviour in our dialogue sys-tems, speech is a viable interface even with rela-tively low word accuracy rates.
Nevertheless webelieve that some important issues are still unex-plored, and one of these is related to the weight hatrecognition errors have with respect o the degreeof co-operativeness of the users.
These open issuesand some experimental data that emphasize theirI14urgency will be discussed in the section on experi-mental data.2 Recogn i t ion  er rors  andnatura lness  o f  d ia logueState-of-the-art systems that receive their input byhigh-quality microphone have word accuracy scoresabove 90%.
However, the recognition of spontaneousspeech in telephone nvironment is below that rate.Actually, the telephone input of the recognizer maygreatly differ from the uttered acoustic signal, due tothe noisy environment of the call, and to the qualityof the telephone microphone and propagation et-work.Most current task-oriented applications of tele-phone human-machine dialogue are developed forbeing used by a large population of potential users.These applications require speaker independent real-time systems, and the opportunity of having trainingsessions with the system cannot be provided.
Thespeaker independent recognizers designed for suchapplications assure the coverage of a great numberof speakers, but some aspects of the speech modal-ity of some users can induce the recognizer to makemistakes, especially in recognizing long sentences.The adverse recognition environment and the vari-ability in user dependent features are the most fre-quent reasons of three kinds of recognition errors.The speech community usually classifies these errorsinto deletions, insertions, and substitutions.
Someof them may be prevented by using language modelsduring the recognition.At present, some approaches to language model-ing take advantage of contextual information sentby the dialogue model.
However, the task of the di-alogue state dependent language modeling is moredifficult in some application domains.
For example,some of the task-oriented systems that give informa-tion about railway timetable, or flight scheduling,have large vocabularies that contain an huge num-ber of words belonging to the same class: for exam-ple, Dialogos vocabulary is 3,500 words, including2,983 proper names of places; another example is theLIMSI Arise Railway Information system (Lamel etal., 1996) that has 1,500 words, including more than680 station names.
This peculiarity directly impactson the performance of the language models, that isin these applications, language modeling predictionsare weaker: when the dialogue prediction says thatnext user's utterance is likely to be about a depar-ture place, this does not exclude that the recognizersubstitutes the actually uttered name with a pho-netically similar one.
Only the user is able to detectsuch kinds of errors.
In this situation the dialoguesystem should identify the user's detection of mis-communication and provide appropriate repairs.All the problems described above lead to the de-crease of the recognition performance and of the us-ability of spoken language systems.
More specifi-cally, they identify some severe requirements thatspoken dialogue modules have to meet.
In particu-lar, dialogue systems for telephone applications haveto rely not only on an adequate model of the humanuser, but they should also implement particular tech-niques for preventing and recovering communicationbreakdowns.3 P revent ion  and  Repa i r  o fM iscommunicat ion3.1 Prevent ion of miscommunicat ionThe user modeling of the dialogue module of Dialo-gos is based on the assumption that both the systemand the user are active agents that cooperate in or-der to fulfill the goal of the speech interaction.
Inthe application domain of Dialogos the goal of theinteraction is to collect all the parameters that arenecessary to access the railway database for retriev-ing the information that satisfy user's needs.T1-S:T2-U:T3-S:T4-U:T5-S:T6-U:Hello, This is Tra in  Enqu i ry  Service.Please speak after the tone.Please s ta te  your  depar ture  and your  dest inat ion.Voglio par t i re  da  Mi ls(no)-  Mi lano di sera.Vado da  Mi lano a Roma.I mould like to leave from Milano ... Milanoin the evening.\[ am going from Milano to Rome.VOGLIO PAB.TIB.E DA NO MILANO SERAVADO DA MILANO P,.OMAWANT LEA VE FROM NO MILANO EVENINGGO FROM MILANO TO ROMA< confirm=NO, dep-city=MILANO,< arr.city=ROMA, part-day=EVENING>Do you want  to go f rom Mi lano to Romaleaving in the evening?Si ... da  Mi lano a Roma di sera.Yes ... from Milano to Roma in the evening.SI BLOW DA MILANO ROMA SEtLAYES BLOW FROM MILANO ROMA EVENING< confirm=YES, dep.city=MILANO,arr-city=ROMA, dep.t ime=EVENING>There are many t ra ins  in the evening.Which hour  do you want  to leave?Mah ... mi d ica  se c 'e '  qua lcosa  nile otto.Who knows ... Tell me if there is something ateight.MATTINO GINOSA ALLE  OTTOMORNING GINOSA AT  E IGHT<part-day=MORNING, city=GINOSA,hour=EIGHTyTT-S: Tra in  243 leaves f rom Mi lano Cent ra le  at  8:20 p.m.;it arr ives at Roma Termini  at  S a.m.Do you need addi t ional  in format ion  about  this t ra in?Figure 1: Excerpt from the Dialogos corpusAs it was explained above, telephone recognitionis error-prone.
For preventing recognition errors thedialogue system sends to the lower levels of anal-ysis information about the domain objects focusedduring each turn of the interaction; this informationallows the triggering of context dependent languagemodels that help to constraint the lexical choices at115the recognition level (see section 4).
Moreover, inorder to detect recognition or interpretation errorsthat occurred in previous turns, the dialogue systemtakes advantage from the global history of the inter-action and it only accepts interpretations of user'sinput that are coherent with the dialogue history.For example, let us consider the excerpt from theDialogos corpus shown in Figure 1.
In the exam-ple, on the left, the letter 'T' stands for 'Turn', theletters 'U' and 'S' stand for user and system, respec-tively.
In each user's turn we reported in Italianthe original user's utterance and its English transla-tion (in italics).
Then we have transcribed the bestdecoded sequence (in ALL CAPS), that is the rec-ognizer output.
The translations into English of thebest decoded sequences are shown in ALL CAPS (initalics).
The task-oriented semantic frames (the in-put of the dialogue module) have been put betweenangles.
The system turns have been only reportedin their English translation.In T2-U the user utterance contains an hesita-tion when uttering the name of the departure city,"Milano".
The first part of the word, "Mila-" wasmisrecognized as a noise, and the last syllable wasrecognized as "no", that the parser interpreted as thenegation adverb "no".
In this initial dialogue con-text there were no parameters to be denied, and thedialogue module was able to discard this informationrelated to the negative adverb.
It addressed the userwith the request of confirmation of T3-S. T4-U wasa confirmation turn of the user.
After having con-sulted the data in the railway database, the systemrealized that the number of connections between Mi-lano and Roma in the evening was high, and it sug-gested the user to choose a more precise departuretime (T5-S).
In T6-U the utterance segment "mah... mi dica se c'e' qualcosa" (who knows ... tell me ifthere is something) was misrecognized as "matt inoGinosa" (morning Ginosa, where "Ginosa" is thename of an Italian village).
As a consequence, theparser output contains another value for the part-of-day parameter and a departure hour.
However, thedialogue discarded the information about the part-of-day, since this conflicted with a parameter valuethat the user had already confirmed, and only thesecond part of the utterance interpretation was re-tained (that is, the departure hour).
In this casethe insertion of a concept due to misrecognition wasrepaired at the dialogue level 1 .As we can see from the example, the dialoguemodule makes use of confirmation turns because itdeals with potentially incorrect information.
How-ever, the need for confirmations may result in a lack1This version of Dialogos only considers the first bestsolution.
If the expected information is not found in thesemantic representation f the current user's utterance,the dialogue system hypothesizes that something wentwrong in the previous analysis, and it interprets thatsituation as an occurrence of non-understanding.of naturalness of the telephone human-machine dia-logues.
In order to reduce the number of confirma-tion turns, we use the following strategies:?
the dialogue system avoids confirmation turnswhen the acquired information is coherent withthe dialogue history and with the current focus?
the dialogue system asks for multiple confirma-tions of the acquired parameters (as in T3-S)?
the dialogue system asks for implicit confirma-tions whenever it is possible (as "From Milanoto Roma.
When do you want to travel?
")3.2 Repa i r  of  miscommunicat ionSometimes the detection of some recognition errors(for example, the substitution of an uttered wordwith another one of the same class) is outside ofthe capabilities of both the parser and the dialoguemodules.
On the contrary, in principle the useris able to detect and correct such errors, and of-ten she does it immediately or in subsequent turns.In (Danieli, 1996) an analysis of such phenomena isoffered, and the method described in that paper iscurrently implemented in Dialogos.
The approachis based on pragmatic-based xpectations about thesemantic ontent of the user utterance in the nextturn.
The theoretical background is the account ofhuman-human conversation given by (Grice, 1967),re-interpreted in the context of human-computerconversation.
In particular, the dialogue system isable to deal with non-understandings and misunder-standings (see (Hirst et al, 1994) for the classifica-tion of non-understanding, misunderstanding, andmisconception), and it may recognize the occurrenceof a miscommunication phenomena on the basis ofthe occurrence of two pragmatic ounterparts, thatis the deviation of the the user's behaviour from thesystem expectations, and the generation of a conver-sational implicature.Non-understanding is recognized by the dialoguesystem as soon as it happens, because the systemis not able to find any interpretation of the currentuser turn.
On the contrary, misunderstandings aremore difficult to detect and solve, because usuallythe dialogue system may get an interpretation of theuser's utterance, but that interpretation is not theone intended by the speaker.
If the user's correctionof a misunderstanding occurs when the parameter isfocused (that is, it occurs as a third-turn repair, see(Schegloff, 1992)), the focusing mechanism and thedialogue expectations allow to grasp the correctionimmediately.
However, it is more problematic to de-tect user's corrections if they happen some turns af-ter the occurrence of the errors.
The dialogue systeminitially interprets user's correction with respect oits current set of expectations.
As soon as it realizesthat there is a deviation of the user behaviour fromthe expected behaviour, it hypothesizes a misunder-standing, and it re-interprets the current utterance116on the basis of the context of the misunderstood ut-terance (thanks to a focus-shifting mechanism).Finally, the output of the parsing module may beonly partially determined.
In that case the dialoguemodule initiates clarification subdialogues.
Let usdiscuss the excerpt shown in Figure 2.TI-S:T2-U:T3-S:T4-U:T5-S:Hello, Th is  is Tra in  Enqui ry  Service.P lease speak  af ter  the tone.P lease s ta te  your  depar ture  and  your  dest inat ion.A Firenze.To F i renze.BLOW F IRENZEBL 0 W F IR  ENZE< ?
i ty=F IRENZE>Are  your  leaving from Firenze or go ing to F i renze?Devo andare  a Firenze.I have to go to F irenze.DEVO ANDARE A F IRENZEMUST GO TO F IRENZE< ar r -c i ty=F IRENZE>To Firenze.
Where  are you leaving f rom?Figure 2: Example of miscommunicationIn T2-U the arrival city is recognized and under-stood as a generic city, the dialogue strategy doesnot reject this information but it enters a clarifi-cation subdialogue in order to solve the ambiguity(T3-S and T4-U).
The last turn of the system isa dialogue act that fulfill two communicative goals,that is the (implicit) confirmation of the arrival cityand the request of the departure city.
However, clar-ification subdialogues may be avoided if the dialogueexpectations allow to choose an interpretation f am-biguous input.Clarification subdialogues may also occur in caseof parser outputs that contain inconsistent relatedinformation.
Those may be so either because ofrecognition errors, or because of user's misconcep-tions.
In our application domain misconceptions,i.e.
errors in the prior knowledge of a participant,usuMly concern the expression of departure dates,as in the dialogue xcerpt shown in Figure 3.
Theconversation took place on Thursday February, 27th1997:TI-S:T2-U:T3-S:What  date  do you travel?Voglio partire domenico ... il p r imo mayo.I want  to leave on Sunday  ... March,  Ist .VOGLIO PART IRE  DOMENICA O PR IMO MARZOWANT LEAVE SUNDAY @ F IRST  MARCH< w-day ,SUNDAY day=FIRST  month=MARCH>Are your travelling on March, Ist or next Sunday?Figure 3: Example of miscommunication due to mis-conceptionThe dialogue system recognizes the misconcep-tion in T2-U because the week day, the day, andthe month are n6t interpretable with respect o itsknowledge of the year's calendar (and the computerpresumes that its calendar is correct).
Moreover thedialogue system finds that different chunks of the in-formation supplied by the user could be coherentlyinterpretable.
Since it has no principled way to de-cide between them, it initiates the clarification sub-dialogue of T3-S.4 D ia logue  Sta te  DependentLanguage Mode l ingThe dialogue module makes use of pragmatic-basedexpectations about the semantic ontent of the nextuser's utterance.
In order to improve speech recog-nition performance the contextual knowledge maybe used as a constraint for the language models.Contextual information is sent to the lower levelsof analysis by communicating the dialogue act pro-duced by the system for addressing the user.
In Dial-ogos there are four classes of dialogue acts (request,confirmation, clarification, and request plus confir-mation).
Each class is further specialized with theindication of the focused parameters: for example"request:date of departure" if the system is askingthe user to provide a departure date, "request-plus-confirmation: departure-plus-arrival", when the sys-tem is addressing the user with a feed-back aboutthe departure city and a request of the arrival city,and so on.
The information about the system dialogact is called "dialogue prediction".
The recognizermakes use of the predictions by selecting a specificlanguage model which was trained on a coherent par-tition of the training corpus (Popovici and Baggia,1997).The training set was collected in previous experi-mentationsof the system: users' responses to specificsystem dialog act were classified for training differentlanguage models.
At present, the speech recognizermakes use of a class-based bigram model; then, inorder to re-score the n-best decoded sequences, ituses a class-based trigram model.In order to measure the improvements in recogni-tion performance obtained using dialogue state de-pendent language models, we compared the differ-ences in the Word Accuracy (WA) and SentenceUnderstanding (SU) rates obtained using differentlanguage models on the same test set.
The test setincluded 2,040 utterances, randomly selected fromcorpus data collected uring a field trial of Dialogoswith 500 unexperienced subjects.
In the first exper-iment, a single context-independent la guage modelwas used; it was trained on a set of 15,575 utterances(produced by Italian native speakers).
In the secondexperiment, a set of dialogue state dependent mod-els, trained on the same training set of the first ex-periment, was used; however in this case the trainingset was encoded according to the different dialoguestates, as explained above.
The error rate reductionbetween the two experiments i 8.6% of WA and10.9% of SU.
Moreover, with an improved acousticI17model (trained on a domain dependent training-set)the error reduction is even greater (over 12%) forboth WA and SU.5 Experimental DataThe Dialogos corpus consists of 1,404 dialogues, in-cluding 13,123 utterances.
All the calls were per-formed over the public telephone network and in dif-ferent environments (house, office, street, and car).The WA and SU results on the global utterancecorpus were: 61% for WA and 76% for SU.
Theseresults were greatly influenced by the quality of thetelephone acoustic signal, and by the noise environ-ment.
Moreover, several city names contained in thedictionary of the system could be easily confused.The overall system performance was measuredwith the Transaction Success (TS) metric, i.e.
themeasure of the success of the system in providingusers with the information they require (Danieli andGerbino, 1995).
The TS rate was 70% on the 1,404dialogues.
By excluding from the corpus a set of dia-logues that failed for users' errors, we obtained a TSresult of 84%.
The average successful dialogue dura-tion is about 2 minutes: in most of the dialogues allthe parameters were acquired and confirmed uringthe first minute of user-system interaction.It is an open issue if a spoken dialogue system hasto generate a clarification subdialogue when facedwith ambiguity or unclear input.
For example, thesystem described in (Allen et al, 1996) was designedon the basis of the principle that it was better to as-sume an interpretation and, of course, to be ableto understand corrections when they arise.
On thecontrary, Dialogos was designed to enter clarificationsubdialogues when faced with input that cannot re-ceive a single coherent interpretation i  the dialoguecontext.
Actually, we think that in general the strat-egy implemented by (Allen et al, 1996) may be moreeffective for the naturalness of the dialogue, how-ever we believe that the effectiveness of that choicegreatly depends on the ability of the users to graspinconsistencies in the system feed-back.
In the Di-alogos corpus we observed that while subjects wereusually able to correct errors in confirmation turnsthat concern a single information, or two semanti-cally related information (such departure and ar-rival); on the contrary, some errors were not cor-rected when the feedback was offered together witha system initiative, or when the system asked to con-firm information that had not strong relationships.The dialogue shown in Figure 4 is a typical example.The acoustic decoding of "Allora" (a word thatis used in Italian for taking turn) was erroneous:it was substituted with "All 'una" (at one o'clock).This was interpreted as a departure hour.
A con-junct confirmation of departure hour and arrival citywas asked and the user confirmed both of them.
Innext section we will elaborate more on users' error.T i -S :T2-U:T3-S:T4-U:Hello, Th is  is Tra in  Enqu i ry  Service.Please speak  after the tone.Please s ta te  your  depar ture  and  your  dest inat ion.A l lora  ... vado a Mi lano.Then ...
I am going to Mi lano.ALL 'UNA VADO A MILANOAT ONE GO TO MILANO<hour=UNA,  a r r -e i ty=MILANO>Do you want  to go to Mi lano leaving at 13:00?Si.Yes.SlYESFigure 4: Example of erroneous confirmationFor the sake of the present discussion, this exampleshows us that users are not always able to correcterrors: on the contrary, we have seen above that thepercentage of users' errors is high.
In order to eval-uate the effectiveness of the different approaches toface ambiguity we should experiment the differentstrategies on the same domain, or at least with thesame interaction modality (phone or microphone).However, we have obtained some data that may givesome insights on the issue.
In the Dialogos corpuswe have calculated the number of turns necessaryfor acquiring departure and arrival cities in the suc-cessful dialogues.
While 64% of the users were ableto give them in two turns (that is without experi-encing recognition errors), the remaining 36% tookfrom three to eight turns, i.e.
these users' spent incorrection from three to eight turns.
Since the per-centage of users that was not able to detect recogni-tion errors is around 16%, we may hypothesize thata part of the subjects that experienced clarificationsubdialogues would have failed to give the correctvalues of the task parameters.
Moreover, if we con-sider the cost of clarifications and repairs in termsof time, that is not awfully high: giving departureand arrival in less than three turns (that is, withoutclarifications or repair) takes from 20 to 29 seconds,while the entering of repair subdialogues increasedthis time of an average of 25 seconds on the totalaverage time of the dialogues.6 DiscussionBy analizing the Dialogos corpus, we identified sometopics that require further work.The first one is related to the need for goal man-agement: in the task domain of Dialogos the goal isfixed during all the dialogue, but that is a simpli-fication of the travel inquiry domain, introduced tocontrol the complexity of interaction in order to meetthe real-time requirement.
However, we believe thatthe ability of the dialogue system to support goalmanagement would greatly increase the naturalnessof dialogue, as the work by (Allen et al, 1996) shows.The second problematic issue is related to the im-pact that recognition errors have on the user be-118haviour.
By examining the Dialogos corpus we col-lected evidence that some critical situations occurwhen the users make experience of repetitive recog-nition errors.
The recognition errors seem to causea cognitive overload in the users that influence theirdegree of co-operativeness.
In our task domain mostof the recognition errors occur during the recogni-tion of departure city and arrival city.
When usersare asked to repeat a city name that was misrec-ognized by the system, some of them modify theirway of speaking: they repeat the name louder, orspelt it, or even accept a misrecognized name pro-posed by the system.
In this corpus 15.1% of thedialogues failed for users' errors.
Similar behaviourhas been described in (Bernsen, Dybkjaer, and Dy-bkjaer, 1996).During the evaluation of the Dialogos corpus weclassified the users' errors into two main classes:1. the user confirmed a task parameter value thatderived from a misrecognition (76% of the users'errors) after having experienced several recog-nition errors;2. the user accepted a task parameter derived froma word that was inserted by the recognizer andinterpreted by the parser (24%).We applied the above classification i  a differentexperimental set-up: in May 1996 a laboratory testwas designed to study the reaction of users to differ-ent speech technologies and dialogue strategies ap-plied to the railway information domain.
48 naivesubjects took part in the experiment: they wereequally distributed by sex; the age range was from 18to 62 years.
The subjects of this experiment calledDialogos and another spoken dialogue system.
Eachof them played two different predetermined scenar-ios with each system; after the trial, they were in-terviewed (the discussion of this experiment may befound in (Billi, Castagneri, and Danieli, 1997)).
Byanalyzing the 96 dialogues between Dialogos andthe experimental subjects, we found that the oc-currence of users' errors could be classified into thetwo classes described above, that is users' errorswere always condomitant with substitutions or in-sertions in the best-decoded sequence.
In partic-ular, in both the experiments subjects reaction torecognition errors was characterized by an alterationin the way of speaking.
In the interviews collectedin the second experimented, the subjects that madeerrors expressed the fatigue in experimenting repet-itive recognition errors.
However, we hypothesizethat the non-cooperative b haviour may be partiallydue to the artificial experimental conditions: we areplanning to experiment the current version of Dialo-gos in a real environment with users that really needto take trains for travelling all around Italy, and thatwill use the system for having timetable information.While there are clearly many aspects in whichour current approach requires further work, we mayclaim that speech is a viable interface if we providespoken systems with robust dialogue management.We have shown that the use of contextual infor-mation in different system modules may reduce therecognition errors, and increase the usability of tele-phone human-computer dialogue.7 AcknowledgementsThe work of the first and the second authors waspartially supported by the LE3-4229 project, ARISE(Automatic Railway Information System for Eu-rope), promoted by the Commissions of the Euro-pean Communities, DG XIII (Telecommunications,Information Market and Exploitation of Research).The third author is a researcher of ICI (Institutul deCercetari n Informatica, Bucarest, Romania): thework reported in this paper was implemented whileshe was visiting CSELT.Re ferencesAlbesano, Dario, Paolo Baggia, Morena Danieli,Roberto Gemello, Elisabetta Gerbino, and Clau-dio Rullent.
1997.
A Robust System for Human-Machine Dialogue in Telephony-Based Applica-tions.
In International Journal of Speech Tech-nology, Kluwer Academic Publishers.
To appear.Allen, James F., Bradford W. Miller, Eric K. Ring-ger, Teresa Sikorski.
1996.
A Robust System forNatural Spoken Dialogue.
In Proceedings of the34th annual Meeting of the A CL, Santa Cruz, Cal-ifornia.
Association for Computational Linguis-tics, Morristown, New Jersey.Bernsen Niels O., Laila Dybkjaer, and Hans Dy-bkjaer.
1996.
User Errors in Spoken Human-Machine Dialogue.
In Proceedings of the ECAI-95 Workshop on Spoken Language Systems, Bu-dapest, Hungary.Billi, Roberto, Giuseppe Castagneri, and MorenaDanieli.
1997.
Field trial evaluations of two differ-ent information inquiry systems.
In Speech Com-munications.
To appear.Danieli, Morena.
1996.
On the Use of Expectationsfor Detecting and Repairing Human-Machine Mis-communications.
In Proceedings of AAAI-96Workshop on Detecting, Preventing and Repair-ing Human.Machine Miscommunications, Port-land, OR., pagesDanieli, Morena and Elisabetta Gerbino.
1995.Metrics for evaluating dialogue strategies in a spo-ken language system.
In Proceedings of the 1995AAAI Spring Symposium on Empirical Methodsin Discourse Interpretation and Generation, pages34-39.119Grice, Paul H. 1967.
Logic and Conversation.
InCole, P., and Morgan, J. eds.
1975.
Syntax and Se-maniics, New York and London: Academic Press.Hirst, Graeme, Susan McRoy, Peter Heeman,Philip Edmonds, Diane Horton.
1994.
Repair-ing conversational misunderstandings and non-understandings.
In Speech Communication, vol-ume 15, pages 213-229.Lamel Lori, Jean Luc Gauvain, Samir K. Bennacef,Laurence Devillers, Saliha Foukia, Jean-JacquesGangolf, and Sophie Rosset.
1996.
Field Tri-als of a Telephone Service for Rail Travel Infor-mation.
In Proceedings of IVTTA-1996, IEEEThird Workshop Interactive Voice Technology forTelecommunications Applications, Basking Ridge,New Jersey.Popovici, Cosmin and Paolo Baggia.
1997.
Spe-cialized Language Models Using Dialogue Predic-tions.
In Proceedings of ICCASP-97, Munchen,Germany.Schegloff, Emanuel A.
1992.
Repair after next turn:The last structurally provided efense of intersub-jectivity in conversation.
In American Journal ofSociology, Volume 97, Number 5, pages 1295-1345120
