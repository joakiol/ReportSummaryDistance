Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 81?88,Sydney, July 2006. c?2006 Association for Computational LinguisticsA High-Accurate Chinese-English NE Backward Translation SystemCombining Both Lexical Information and Web StatisticsConrad Chen Hsin-Hsi ChenDepartment of Computer Science and Information Engineering, NationalTaiwan University, Taipei, Taiwandrchen@nlg.csie.ntu.edu.tw hhchen@csie.ntu.edu.twAbstractNamed entity translation is indispensablein cross language information retrievalnowadays.
We propose an approach ofcombining lexical information, web sta-tistics, and inverse search based onGoogle to backward translate a Chinesenamed entity (NE) into English.
Our sys-tem achieves a high Top-1 accuracy of87.6%, which is a relatively good per-formance reported in this area until pre-sent.1 IntroductionTranslation of named entities (NE) attracts muchattention due to its practical applications inWorld Wide Web.
The most challenging issuebehind is: the genres of NEs are various, NEs areopen vocabulary and their translations are veryflexible.Some previous approaches use phonetic simi-larity to identify corresponding transliterations,i.e., translation by phonetic values (Lin and Chen,2002; Lee and Chang, 2003).
Some approachescombine lexical (phonetic and meaning) and se-mantic information to find corresponding transla-tion of NEs in bilingual corpora (Feng et al,2004; Huang et al, 2004; Lam et al, 2004).These studies focus on the alignment of NEs inparallel or comparable corpora.
That is called?close-ended?
NE translation.In ?open-ended?
NE translation, an arbitraryNE is given, and we want to find its correspond-ing translations.
Most previous approaches ex-ploit web search engine to help find translatingcandidates on the Internet.
Al-Onaizan andKnight (2003) adopt language models to generatepossible candidates first, and then verify thesecandidates by web statistics.
They achieve a Top-1 accuracy of about 72.6% with Arabic-to-English translation.
Lu et al (2004) use statisticsof anchor texts in web search result to identifytranslation and obtain a Top-1 accuracy of about63.6% in translating English out-of-vocabulary(OOV) words into Traditional Chinese.
Zhang etal.
(2005) use query expansion to retrieve candi-dates and then use lexical information, frequen-cies, and distances to find the correct translation.They achieve a Top-1 accuracy of 81.0% andclaim that they outperform state-of-the-art OOVtranslation techniques then.In this paper, we propose a three-step ap-proach based on Google to deal with open-endedChinese-to-English translation.
Our system inte-grates various features which have been used byprevious approaches in a novel way.
We observethat most foreign Chinese NEs would have theircorresponding English translations appearing intheir returned snippets by Google.
Therefore wecombine lexical information and web statistics tofind corresponding translations of given Chineseforeign NEs in returned snippets.
A highly effec-tive verification process, inverse search, is thenadopted and raises the performance in a signifi-cant degree.
Our approach achieves an overallTop-1 accuracy of 87.6% and a relatively highTop-4 accurracy of 94.7%.2 BackgroundTranslating NEs, which is different from translat-ing common words, is an ?asymmetric?
transla-tion.
Translations of an NE in various languagescan be organized as a tree according to the rela-tions of translation language pairs, as shown inFigure 1.
The root of the translating tree is theNE in its original language, i.e., initially de-81nominated.
We call the translation of an NEalong the tree downward as a ?forward transla-tion?.
On the contrary, ?backward translation?
isto translate an NE along the tree upward.Figure 1.
Translating tree of ?Cien a?os soledad?.Generally speaking, forward translation is eas-ier than backward translation.
On the one hand,there is no unique answer to forward translation.Many alternative ways can be adopted to forwardtranslate an NE from one language to another.For example, ?Jordan?
can be translated into ???
(Qiao-Dan)?, ???
(Qiao-Deng)?, ???
(Yue-Dan)?, and so on.
On the other hand, thereis generally one unique corresponding term inbackward translation, especially when the targetlanguage is the root of the translating tree.In addition, when the original NE appears indocuments in the target language in forwardtranslation, it often comes together with a corre-sponding translation in the target language(Cheng et al, 2004).
That makes forward transla-tion less challenging.
In this paper, we focus ourstudy on Chinese-English backward translation,i.e., the original language of NE and the targetlanguage in translation is English, and the sourcelanguage to be translated is Chinese.There are two important issues shown belowto deal with backward translation of NEs orOOV words.?
Where to find the corresponding translation??
How to identify the correct translation?NEs seldom appear in multi-lingual or evenmono-lingual dictionaries, i.e., they are OOV orunknown words.
For unknown words, where canwe find its corresponding translation?
A bilin-gual corpus might be a possible solution.
How-ever, NEs appear in a vast context and bilingualcorpora available can only cover a small propor-tion.
Most text resources are monolingual.
Canwe find translations of NEs in monolingual cor-pora?
While mentioning a translated name duringwriting, sometimes we would annotate it with itsoriginal name in the original foreign language,especially when the name is less commonlyknown.
But how often would it happen?
Withour testing data, which would be introduced inSection 4, over 97% of translated NEs wouldhave its original NE appearing in the first 100returned snippets by Google.
Figure 2 showsseveral snippets returned by Google which con-tains the original NE of the given foreign NE.Figure 2.
Several Traditional Chinese snippets of??????
returned by Google which containsthe translation ?The Old Man and the Sea?.When translations can be found in snippets,the next work would be identifying which nameis the correct translation of NEs.
First we shouldknow how NEs would be translated.
The com-monest case is translating by phonetic values, orso-called transliteration.
Most personal namesand location names are transliterated.
NEs mayalso be translated by meaning.
It is the way inwhich most titles and nicknames and some or-ganization names would be translated.
Anothercommon case is translating by phonetic valuesfor some parts and by meaning for the others.
Forexample, ?Sears Tower?
is translated into ????
(Xi-Er-Si) ?
?
(tower)?
in Chinese.
NEswould sometimes be translated by semantics orcontents of the entity it indicates, especially withmovies.
Table 1 summarizes the possible trans-lating ways of NEs.
From the above discussion,we may use similarities in phonetic values,meanings of constituent words, semantics, and soCEPS ??
?-- ????;-1?
?, ???????????????????.
???
?, Symbolic Means of the Author "The Old Man and theSea" ...
?
?, ?????????????????????????????????????????????????????????
...www.ceps.com.tw/ec/ecjnlarticleView.aspx?jnlcattype=1&jnlptype=4&jnltype=29&jnliid=1370&i... - 26k - ????
- ????.
:JSDVD Mall:.
????-????????-????
?
?????-????
(DTS) ?
???????
?
??????
16-??
?
??
?
?????
?
????-?????
?
????-???
...
????-????.
TheOld Man and The Sea.
4715320115018, ?????????
...mall.jsdvd.com/product_info.php?products_id=3198 - 48k - ????
- ????
- ???
?82on to identify corresponding translations.
Besidesthese linguistic features, non-linguistic featuressuch as statistical information may also help usewell.
We would discuss how to combine thesefeatures to identify corresponding translation indetail in the next section.3 Chinese-to-English NE TranslationAs we have mentioned in the last section, wecould find most English translations in Chineseweb page snippets.
We thus base our system onweb search engine: retrieving candidates fromreturned snippets, combining both linguistic andstatistical information to find the correct transla-tion.
Our system can be split into three steps:candidate retrieving, candidate evaluating, andcandidate verifying.
An overview of our systemis given in Figure 3.Figure 3.
An Overview of the System.In the first step, the NE to be translated, GN,is sent to Google to retrieve traditional Chineseweb pages, and a simple English NE recognitionmethod and several preprocessing proceduresare applied to obtain possible candidates fromreturned snippets.
In the second step, four fea-tures (i.e., phonetic values, word senses, recur-rences, and relative positions) are exploited togive these candidates a score.
In the last step, thecandidates with higher scores are sent to Googleagain.
Recurrence information and relative posi-tions concerning with the candidate to be veri-fied of GN in returned snippets are countedalong with the scores to decide the final rankingof candidates.
These three steps will be detailedin the following subsections.3.1 Retrieving CandidatesBefore we can identify possible candidates, wemust retrieve them first.
In the returned tradi-tional Chinese snippets by Google, there are stillmany English fragments.
Therefore, the firsttask our system would do is to separate theseEnglish fragments into NEs and non-NEs.
Wepropose a simple method to recognize possibleNEs.
All fragments conforming to the followingproperties would be recognized as NEs:?
The first and the last word of the fragmentare numerals or capitalized.?
There are no three or more consequent low-ercase words in the fragment.?
The whole fragment is within one sentence.After retrieving possible NEs in returned snip-pets, there are still some works to do to make aTranslating Way Description ExamplesTranslating by Pho-netic ValuesThe translation would have a similarpronunciation to its original NE.
?New York?
and ???
(pronounced as Niu-Yue)?Translating by Mean-ingThe translation would have a similar or arelated meaning to its original NE.??
(red)?
(chamber)?
(dream)?
and ?TheDream of the Red Chamber?Translating by Pho-netic Values for SomeParts and by Meaningfor the OthersThe entire NE is supposed to be trans-lated by its meaning and the name partsare transliterated.
?Uncle Tom?s Cabin?
and ???
(pronouncedas Tang-Mu)???(uncle?s)??
(cabin)?Translating by BothPhonetic Values andMeaningThe translation would have both a similarpronunciation and a similar meaning toits original NE.
?New Yorker?
and ???
(pronounced as Niu-Yue)?
(people, pronounced as Ke)?Translating NEs byHeterographyThe NE is translated by these hetero-graphic words in neighboring languages.????
and ?Yokohama?, ??????
and?Ichiro Suzuki?Translating by Se-mantic or ContentThe NE is translated by its semantic orthe content of the entity it refers to.
?The Mask?
and ???
(modern)?
(great)?
(saint)?Parallel Names NE is initially denominated as more thanone name or in more than one language.????
(Sun Zhong-Shan)?
and ?Sun Yat-Sen?Table 1.
Possible translating ways of NEs.83finer candidate list for verification.
First, theremight be many different forms for a same NE.For example, ?Mr.
& Mrs. Smith?
may also ap-pear in the form of ?Mr.
and Mrs.
Smith?, ?Mr.And Mrs.
Smith?, and so on.
To deal with thesealiasing forms, we transform all different formsinto a standard form for the later ranking andidentification.
The standard form follows thefollowing rules:?
All letters are transformed into upper cases.?
Words consist ??
?s are split.?
Symbols are rewritten into words.For example, all forms of ?Mr.
& Mrs. Smith?would be transformed into ?MR.
AND MRS.SMITH?.The second work we should complete beforeranking is filtering useless substrings.
An NEmay comprise many single words.
These com-ponent words may all be capitalized and thus allsubstrings of this NE would be fetched as candi-dates of our translation work.
Therefore, sub-strings which always appear with a same preced-ing and following word are discarded here, sincethey would have a zero recurrence score in thenext step, which would be detailed in the nextsubsection.3.2 Evaluating CandidatesAfter candidate retrieving, we would obtain asequence of m candidates, C1, C2, ?, Cm.
Anintegrated evaluating model is introduced to ex-ploit four features (phonetic values, word senses,recurrences, and relative positions) to scorethese m candidates, as the following equationsuggests:),(),(),(GNCLScoreGNCSScoreGNCScoreiii?=LScore(Ci,GN) combines phonetic values andword senses to evaluate the lexical similaritybetween Ci and GN.
SScore(Ci,GN) concernsboth recurrences information and relative posi-tions to evaluate the statistical relationship be-tween Ci and GN.
These two scores are thencombined to obtain Score(Ci,GN).
How to esti-mate LScore(Cn, GN) and SScore(Cn, GN) wouldbe discussed in detail in the following subsec-tions.3.2.1 Lexical SimilarityThe lexical similarity concerns both phoneticvalues and word senses.
An NE may consist ofmany single words.
These component wordsmay be translated either by phonetic values orby word senses.
Given a translation pair, wecould split them into fragments which could bebipartite matched according to their translationrelationships, as Figure 4 shows.Figure 4.
The translation relationships of ????????
?.To identify the lexical similarity between twoNEs, we could estimate the similarity scores be-tween the matched fragment pairs first, and thensum them up as a total score.
We postulate thatthe matching with the highest score is the correctmatching.
Therefore the problem becomes aweighted bipartite matching problem, i.e., giventhe similarity scores between any fragment pairs,to find the bipartite matching with the highestscore.
In this way, our next problem is how toestimate the similarity scores between fragments.We treat an English single word as a fragmentunit, i.e., each English single word correspondsto one fragment.
An English candidate Ci con-sisting of n single words would be split into nfragment units, Ci1, Ci2, ?, Cin.
We define a Chi-nese fragment unit that it could comprise one tofour characters and may overlap each other.
Afragment unit of GN can be written as GNab,which denotes the ath to bth characters of GN,and b - a < 4.
The linguistic similarity score be-tween two fragments is:)},(),,({),(ijabijabijabCGNWSSimCGNPVSimMaxCGNLSim =Where PVSim() estimates the similarity in pho-netic values while WSSim() estimate it in wordsenses. Phonetic ValueIn this paper, we adopt a simple but novelmethod to estimate the similarity in phoneticvalues.
Unlike many approaches, we don?t in-troduce an intermediate phonetic alphabet sys-tem for comparison.
We first transform the Chi-nese fragments into possible English strings, andthen estimate the similarity between transformedstrings and English candidates in surface strings,as Figure 5 shows.
However, similar pronuncia-tions does not equal to similar surface strings.Two quite dissimilar strings may have very simi-lar pronunciations.
Therefore, we take this strat-84egy: generate all possible transformations, andregard the one with the highest similarity as theEnglish candidate.Figure 5.
Phonetic similarity estimation of oursystem.Edit distances are usually used to estimate thesurface similarity between strings.
However, thetypical edit distance does not completely satisfythe requirement in the context of translationidentification.
In translation, vowels are an unre-liable feature.
There are many variations in pro-nunciation of vowels, and the combinations ofvowels are numerous.
Different combinations ofvowels may have a same phonetic value, how-ever, same combinations may pronounce totallydifferently.
The worst of all, human often arbi-trarily determine the pronunciation of unfamiliarvowel combinations in translation.
For these rea-sons, we adopt the strategy that vowels can beignored in transformation.
That is to say when itis hard to determine which vowel combinationshould be generated from given Chinese frag-ments, we can only transform the more certainpart of consonants.
Thus during the calculationof edit distances, the insertion of vowels wouldnot be calculated into edit distances.
Finally, themodified edit distance between two strings Aand B is defined as follow:???
==???=??????????+??+?+?===?????
?elseBAiftsRepconsonantaisBifvowlaisBiftInstsReptsEDtsEDtInstsEDtsEDssEDttEDtsttBABABABABABA,1,0),(,1,0)(),()1,1(,1),1(),()1,(min),()0,(),0(The modified edit distances are then transformedto similarity scores:)}(),(max{))(),((1),(BLenALenBLenALenEDBAPVSim BA?
?=Len() denotes the length of the string.
In theabove equation, the similarity scores are rangedfrom 0 to 1.We build the fixed transformation table manu-ally.
All possible transformations from Chinesetransliterating characters to corresponding Eng-lish strings are built.
If we cannot precisely indi-cate which vowel combination should be trans-formed, or there are too many possible combina-tions, we ignores vowels.
Then we use a trainingset of 3,000 transliteration names to examinepossible omissions due to human ignorance. Word SensesMore or less similar to the estimation of pho-netic similarity, we do not use an intermediaterepresentation of meanings to estimate wordsense similarity.
We treat the English transla-tions in the C-E bilingual dictionary (referenceremoved for blind review) directly as the wordsenses of their corresponding Chinese word en-tries.
We adopt a simple 0-or-1 estimation ofword sense similarity between two strings A andB, as the following equation suggests:??????
?=dictionary in theofon  translatia is  if ,1dictionary in theofon  translatianot  is  if,0),( ABABBAWSSimAll the Chinese foreign names appearing in testdata is removed from the dictionary.From the above equations we could derivethat LSim() of fragment pairs is also ranged from0 to 1.
Candidates to be evaluated may comprisedifferent number of component words, and thiswould result the different scoring base of theweighted bipartite matching.
We should normal-ize the result scores of bipartite matching.
As aresult, the following equation is applied:??????????????+??=?
?GNabCGNLSimCCGNLSimGNCLScoreijabijabCGN ijabiCGN ijabiin  characters of # Total)1(),(,in   wordsof # Total),(min),(and  pairs matched alland  pairs matched all3.2.2 Statistical SimilarityTwo pieces of information are concerned to-gether to estimate the statistical similarity: recur-rences and relative positions.
A candidate Cimight appear l times in the returned snippets, asCi,1, Ci,2, ?, Ci,l.
For each Ci,k, we find the dis-85tance between it and the nearest GN in the re-turned snippets, and then compute the relativeposition scores as the following equation:?
?
14/),(1),(,,+=kiki CGNDistanceGNCRPIn other words, if the candidate is adjacent to thegiven NE, it would have a relative position scoreof 1.
Relative position scores of all Ci,k would besummed up to obtain the primitive statisticalscore:PSS(Ci, GN) = ?k RP(Cn,k, GN)As we mentioned before, since the impreci-sion of NE recognition, most substrings of NEswould also be recognized as candidates.
Thiswould result a problem.
There are often typos inthe information provided on the Internet.
If somecomponent word of an NE is misspelled, thesubstrings constituted by the rest words wouldhave a higher statistical score than the correctNE.
To prevent such kind of situations, we in-troduce entropy of the context of the candidate.If a candidate has a more varied context, it ismore possible to be an independent term insteadof a substring of other terms.
Entropy providessuch a property: if the possible cases are morevaried, there is higher entropy, and vice versa.Entropy function here concerns the possiblecases of the most adjacent word at both ends ofthe candidate, as the following equation suggests:??????
?==?i iCT irNPTiriNCNCTNCNCTCEntropyelse ,/log/1context  possible of #  while,1) ofContext (Where NCTr and NCi denote the appearing timesof the rth context CTr and the candidate Ci in thereturned snippets respectively, and NPTi denotesthe total number of different cases of the contextof Ci.
Since we want to normalize the entropy to0~1, we take NPTi as the base of the logarithmfunction.While concerning context combinations, onlycapitalized English word is discriminated.
Allother words would be viewed as one sort?OTHER?.
For example, assuming the contextof ?David?
comprises three times of (Craig,OTHER), three times of (OTHER, Stern), andsix times of (OTHER, OTHER), then:946.0)126log126123log123123log123()David"" ofContext (333 =?+?+?=EntropyNext we use Entropy(Context of Ci) to weightthe primitive score PSS(Ci, GN) to obtain thefinal statistical score.
:)() ofContext ()(,GNCPSSCEntropy,GNCSScoreiii?=3.3 Verifying CandidatesIn evaluating candidate, we concern only theappearing frequencies of candidates when theNE to be translated is presented.
In the otherdirection, we should also concern the appearingfrequencies of the NE to be translated when thecandidate is presented to prevent common wordsgetting an improper high score in evaluation.
Weperform the inverse search approach for thissake.
Like the evaluation of statistical scores inthe last step, candidates are sent to Google toretrieve Traditional Chinese snippets, and thesame equation of SScore() is computed concern-ing the candidate.
However, since there are toomany candidates, we cannot perform this proc-ess on all candidates.
Therefore, an eliminationmechanism is adopted to select candidates forverification.
The elimination mechanism worksas follows:1.
Send the Top-3 candidates into Google forverification.2.
Count SScore(GN, Ci).
(Notice that the or-der of the parameter is reversed.)
Re-weightScore(Ci, GN) by multiplying SScore(GN,Ci)3.
Re-rank candidates4.
After re-ranking, if new candidates becomethe Top-3 ones, redo the first step.
Other-wise end this process.The candidates have been verified would be re-corded to prevent duplicate re-weighting andunnecessary verification.There is one problem in verification weshould concern.
Since we only consider recur-rence information in both directions, but not co-occurrence information, this would result someproblem when dealing rarely used translations.For example, ?Peter Pan?
can be translated into?????
or ?????
(both pronounced as Bi-De-Pan) in Chinese, but most people would usethe former translation.
Thus if we send ?PeterPan?
to verification when translating ????
?,we would get a very low score.To deal with this situation, we adopt the strat-egy of disbelieving verification in some situa-86tions.
If all candidates have scores lower thanthe threshold, we presume that the given NE is ararely used translation.
In this situation, we useonly Score(Cn, GN) estimated by  the evaluationstep to rank its candidates, without multiplyingSScore(GN, Ci) of the inverse search.
Thethreshold is set to 1.5 by heuristic, since we con-sider that a commonly used translation is sup-posed to have their SScore() larger than 1 in bothdirections.4 ExperimentsTo evaluate the performance of our system, 15common users are invited to provide 100 foreignNEs per user.
These users are asked to simulatea scenario of using web search machine to per-form cross-lingual information retrieval.
Theproportion of different types of NEs is roughlyconformed to the real distribution, except forcreation titles.
We gathers a larger proportion ofcreation titles than other types of NEs, since theways of translating creation titles is less regularand we may use them to test how much helpcould the web statistics provide.After removing duplicate entries provided byusers, finally we obtain 1,119 nouns.
Amongthem 7 are not NEs, 65 are originated from Ori-ental languages (Chinese, Japanese, and Korean),and the rest 1,047 foreign NEs are our main ex-perimental subjects.
Among these 1,047 namesthere are 455 personal names, 264 locationnames, 117 organization names, 196 creationtitles, and 15 other types of NEs.Table 2 and Figure 5 show the performance ofthe system with different types of NEs.
Wecould observe that the translating performance isbest with location names.
It is within our expec-tation, since location names are one of the mostlimited NE types.
Human usually provide loca-tion names in a very limited range, and thusthere are less location names having ambiguoustranslations and less rare location names in thetest data.
Besides, because most location namesare purely transliterated, it can give us someclues about the performance of our phoneticmodel.Our system performs worst with creation titles.One reason is that the naming and translatingstyle of creation titles are less formulated.
Manytitles are not translated by lexical information,but by semantic information or else.
For exam-ple, ?Mr.
& Mrs. Smith?
is translated into ??????(Smiths?
Mission)?
by the content of thecreation it denotes.
Another reason is that manytitles are not originated from English, such as ?leNozze di Figaro?.
It results the C-E bilingualdictionary cannot be used in recognizing wordsense similarity.
A more serious problem withtitles is that titles generally consist of more sin-gle words than other types of NEs.
Therefore, inthe returned snippets by Google, the correcttranslation is often cut off.
It would results agreat bias in estimating statistical scores.Table 3 compares the result of different fea-ture combinations.
It considers only foreign NEsin the test data.
From the result we could con-clude that both statistical and lexical features arehelpful for translation finding, while the inversesearch are the key of our system to achieve agood performance.60%65%70%75%80%85%90%95%100%1 5 9 13 17 21 25 29RankingRecall at TOPNPERLOCORGTitleOtherOrientalNon-NEFigure 5.
Curve of recall versus ranking.Top-1 Top-2 Top-4 Top-MTotal Num Recall Num Recall Num Recall Num RecallPER 455 408 89.7% 430 94.5% 436 95.8% 443 97.3%LOC 264 242 91.7% 252 95.5% 253 95.8% 264 100.0%ORG 117 98 83.8% 106 90.6% 108 92.3% 114 97.4%TITLE 196 151 77.0% 168 85.7% 181 92.3% 189 96.4%Other 15 10 66.7% 13 86.7% 14 93.3% 15 100.0%All NE 1047 909 87.6% 969 92.6% 992 94.7% 1025 97.9%Oriental 65 47 72.3% 52 80.0% 55 84.6% 60 92.3%Non-NE 7 6 85.7% 6 85.7% 6 85.7% 7 100.0%Overall 1119 962 86.0% 1027 91.8% 1053 94.1% 1092 97.6%Table 2.
Experiment results of our system with different NE types.87Top-1 Top-2 Top-4Num Recall Num Recall Num RecallSScore 540 51.6% 745 71.2% 887 84.7%LScore 721 68.9% 789 75.4% 844 80.6%SScore + LScore 837 79.9% 916 87.5% 953 91.0%+ Inverse Search 909 87.6% 969 92.6% 992 94.7%Table 3.
Experiment results of our system with different feature combinations.From the result we could also find that oursystem has a high recall of 94.7% while consid-ering top 4 candidates.
If we only count in thegiven NEs with their correct translation appear-ing in the returned snippets, the recall would goto 96.8%.
This achievement may be not yet goodenough for computer-driven applications, but itis certainly a good performance for user querying.5 ConclusionIn this study we combine several relatively sim-ple implementations of approaches that havebeen proposed in the previous studies and obtaina very good performance.
We find that the Inter-net is a quite good source for discovering NEtranslations.
Using snippets returned by Googlewe can efficiently reduce the number of the pos-sible candidates and acquire much useful infor-mation to verify these candidates.
Since thenumber of candidates is generally less than proc-essing with unaligned corpus, simple models canperforms filtering quite well and the over-fittingproblem is thus prevented.From the failure cases of our system, (see Ap-pendix A) we could observe that the performanceof this integrated approach could still be boostedby more sophisticated models, more extensivedictionaries, and more delicate training mecha-nisms.
For example, performing stemming oradopting a more extensive dictionary might en-hance the accuracy of estimating word sensesimilarity; the statistic formula can be replacedby more formal measures such as co-occurrencesor mutual information to make a more preciseassessment of statistical relationship.
These taskswould be our future works in developing a moreaccurate and efficient NE translation system.ReferenceAl-Onaizan, Yaser and Kevin Knight.
2002.
Translat-ing Named Entities Using Monolingual and Bilin-gual Resources.
ACL 2002: 400-408.Cheng, Pu-Jen, J.W.
Teng, R.C.
Chen, J.H.
Wang,W.H.
Lu, and L.F. Chien.
Translating unknownqueries with web corpora for cross-language in-formation retrieval.
SIGIR 2004: 146-153.Feng, Donghui, Lv Y., and Zhou M. 2004.
A NewApproach for English-Chinese Named EntityAlignment.
EMNLP 2004: 372-379.Huang, Fei, Stephan Vogel, and Alex Waibel.
2003.Improving Named Entity Translation CombiningPhonetic and Semantic Similarities.
HLT-NAACL2004: 281-288.Lam, Wai, Ruizhang Huang, and Pik-Shan Cheung.2004.
Learning phonetic similarity for matchingnamed entity translations and mining new transla-tions.
SIGIR 2004: 289-296.Lee, Chun-Jen and Jason S. Chang.
2003.
Acquisitionof.
English-Chinese Transliterated Word Pairsfrom Parallel-Aligned Texts.
HLT-NAACL 2003.Workshop on Data Driven MT: 96-103.Lin, Wei-Hao and Hsin-Hsi Chen.
2002.
BackwardMachine Transliteration by Learning PhoneticSimilarity.
Proceedings of CoNLL-2002: 139-145.Lu, Wen-Hsiang, Lee-Feng Chien, and Hsi-Jian Lee.2004.
Anchor Text Mining for Translation of WebQueries: A Transitive Translation Approach.
ACMTransactions on Information Systems 22(2): 242-269.Zhang, Ying, Fei Huang, and Stephan Vogel.
2005.Mining translations of OOV terms from the webthrough cross-lingual query expansion.
SIGIR2005: 669-670.Zhang, Ying and Phil Vines.
2004.
Using the web forautomated translation extraction in cross-languageinformation retrieval.
SIGIR 2004: 162-169.Appendix A.
Some Failure Cases of OurSystemGN Top 1  Correct Translation Rank??
CBS SADDAM HUSSEIN 2???
JERSEY NEW JERSEY 2????
ONLINE ARABIAN NIGHTS 2????
ROYCE ROLLS ROYCE 2?????
NBA JULIUS ERVING 2???
LAVIGNE AVRIL LAVIGNE 2??
JK JK.
ROWLING 2????
RICKY DAVIS CELTICS 8????
MONET IMPRESSION SUNRISE 9??
TUPOLEV TU USSR 33?????
NBA MEDVENDENKO N/A?????
TOS SYMPHONY NO.
5 N/A????
AROUND03 CUORE N/A???
JACK LAYTON DEMOCRATIC PARTY N/A88
