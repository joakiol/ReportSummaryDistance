Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 254?265,Paris, October 2009. c?2009 Association for Computational LinguisticsParsing Directed Acyclic Graphswith Range Concatenation GrammarsPierre Boullier and Beno?
?t SagotAlpage, INRIA Paris-Rocquencourt & Universite?
Paris 7Domaine de Voluceau ?
Rocquencourt, BP 105 ?
78153 Le Chesnay Cedex, France{Pierre.Boullier,Benoit.Sagot}@inria.frAbstractRange Concatenation Grammars (RCGs)are a syntactic formalism which possessesmany attractive properties.
It is more pow-erful than Linear Context-Free RewritingSystems, though this power is not reachedto the detriment of efficiency since its sen-tences can always be parsed in polynomialtime.
If the input, instead of a string, is aDirected Acyclic Graph (DAG), only sim-ple RCGs can still be parsed in polyno-mial time.
For non-linear RCGs, this poly-nomial parsing time cannot be guaranteedanymore.
In this paper, we show how thestandard parsing algorithm can be adaptedfor parsing DAGs with RCGs, both in thelinear (simple) and in the non-linear case.1 IntroductionThe Range Concatenation Grammar (RCG)formalism has been introduced by Boullier tenyears ago.
A complete definition can befound in (Boullier, 2004), together with someof its formal properties and a parsing algorithm(qualified here of standard) which runs inpolynomial time.
In this paper we shall onlyconsider the positive version of RCGs whichwill be abbreviated as PRCG.1 PRCGs arevery attractive since they are more powerfulthan the Linear Context-Free Rewriting Systems(LCFRSs) by (Vijay-Shanker et al, 1987).
In factLCFRSs are equivalent to simple PRCGs whichare a subclass of PRCGs.
Many Mildly Context-Sensitive (MCS) formalisms, including TreeAdjoining Grammars (TAGs) and various kindsof Multi-Component TAGs, have already been1Negative RCGs do not add formal power since bothversions exactly cover the class PTIME of languagesrecognizable in deterministic polynomial time (see (Boullier,2004) for an indirect proof and (Bertsch and Nederhof, 2001)for a direct proof).translated into their simple PRCG counterpart inorder to get an efficient parser for free (see forexample (Barthe?lemy et al, 2001)).However, in many Natural Language Process-ing applications, the most suitable input for aparser is not a sequence of words (forms, ter-minal symbols), but a more complex representa-tion, usually defined as a Direct Acyclic Graph(DAG), which correspond to finite regular lan-guages, for taking into account various kinds ofambiguities.
Such ambiguities may come, amongothers, from the output of speech recognition sys-tems, from lexical ambiguities (and in particularfrom tokenization ambiguities), or from a non-deterministic spelling correction module.Yet, it has been shown by (Bertsch andNederhof, 2001) that parsing of regular languages(and therefore of DAGs) using simple PRCGs ispolynomial.
In the same paper, it is also proventhat parsing of finite regular languages (the DAGcase) using arbitrary RCGs is NP-complete.This papers aims at showing how thesecomplexity results can be made concrete in aparser, by extending a standard RCG parsingalgorithm so as to handle input DAGs.
Wewill first recall both some basic definitions andtheir notations.
Afterwards we will see, with aslight modification of the notion of ranges, howit is possible to use the standard PRCG parsingalgorithm to get in polynomial time a parse forestwith a DAG as input.2 However, the resultingparse forest is valid only for simple PRCGs.
Inthe non-linear case, and consistently with thecomplexity results mentioned above, we show thatthe resulting parse forest needs further processingfor filtering out inconsistent parses, which mayneed an exponential time.
The proposed filteringalgorithm allows for parsing DAGs in practicewith any PRCG, including non-linear ones.2The notion of parse forest is reminiscent of the workof (Lang, 1994).2542 Basic notions and notations2.1 Positive Range Concatenation GrammarsA positive range concatenation grammar (PRCG)G = (N,T, V, P, S) is a 5-tuple in which:?
T and V are disjoint alphabets of terminalsymbols and variable symbols respectively.?
N is a non-empty finite set of predicates offixed arity (also called fan-out).
We writek = arity(A) if the arity of the predicate A isk.
A predicate A with its arguments is notedA(~?)
with a vector notation such that |~?| = kand ~?
[j] is its jth argument.
An argument is astring in (V ?
T )?.?
S is a distinguished predicate called the startpredicate (or axiom) of arity 1.?
P is a finite set of clauses.
A clause cis a rewriting rule of the form A0( ~?0) ?A1( ~?1) .
.
.
Ar( ~?r) where r, r ?
0 is itsrank, A0( ~?0) is its left-hand side or LHS,and A1( ~?1) .
.
.
Ar( ~?r) its right-hand side orRHS.
By definition c[i] = Ai(~?i), 0 ?
i ?
rwhere Ai is a predicate and ~?i its arguments;we note c[i][j] its jth argument; c[i][j] is ofthe form X1 .
.
.
Xnij (the Xk?s are terminalor variable symbols), while c[i][j][k], 0 ?k ?
nij is a position within c[i][j].For a given clause c, and one of its predicatesc[i] a subargument is defined as a substring of anargument c[i][j] of the predicate c[i].
It is denotedby a pair of positions (c[i][j][k], c[i][j][k?
]), withk ?
k?.Let w = a1 .
.
.
an be an input string in T ?,each occurrence of a substring al+1 .
.
.
au is a pairof positions (w[l], w[u]) s.t.
0 ?
l ?
u ?
ncalled a range and noted ?l..u?w or ?l..u?
whenw is implicit.
In the range ?l..u?, l is its lowerbound while u is its upper bound.
If l = u,the range ?l..u?
is an empty range, it spans anempty substring.
If ?1 = ?l1..u1?, .
.
.
and?m = ?lm..um?
are ranges, the concatenation of?1, .
.
.
, ?m noted ?1 .
.
.
?m is the range ?
= ?l..u?if and only if we have ui = li+1, 1 ?
i < m,l = l1 and u = um.If c = A0( ~?0) ?
A1( ~?1) .
.
.
Ar( ~?r) is aclause, each of its sub-arguments (c[i][j][k], c[i][j][k? ])
may take a range?
= ?l..u?
as value: we say that it is instantiatedby ?.
However, the instantiation of a subargumentis subjected to the following constraints.?
If the subargument is the empty string (i.e.,k = k?
), ?
is an empty range.?
If the subargument is a terminal symbol (i.e.,k + 1 = k?
and Xk?
?
T ), ?
is such thatl + 1 = u and au = Xk?
.
Note that severaloccurrences of the same terminal symbolmay be instantiated by different ranges.?
If the subargument is a variable symbol(i.e., k + 1 = k?
and Xk?
?
V ),any occurrence (c[i?][j?
][m], c[i?][j?][m?])
ofXk?
is instantiated by ?.
Thus, eachoccurrence of the same variable symbol mustbe instantiated by the same range.?
If the subargument is the string Xk+1 .
.
.
Xk?
,?
is its instantiation if and only if we have?
= ?k+1 .
.
.
?k?
in which ?k+1, .
.
.
, ?k?
arerespectively the instantiations of Xk+1, .
.
.
,Xk?
.If in c we replace each argument by itsinstantiation, we get an instantiated clause notedA0(~?0) ?
A1(~?1) .
.
.
Ar(~?r) in which eachAi(~?i) is an instantiated predicate.A binary relation called derive and noted ?G,wisdefined on strings of instantiated predicates.
If ?1and ?2 are strings of instantiated predicates, wehave?1 A0(~?0) ?2 ?G,w ?1 A1(~?1) .
.
.
Am( ~?m) ?2if and only if A0(~?0) ?
A1(~?1) .
.
.
Am( ~?m) is aninstantiated clause.The (string) language of a PRCG G is theset L(G) = {w | S(?0..|w|?w) +?G,w ?}.
Inother words, an input string w ?
T ?, |w| =n is a sentence of G if and only there exists acomplete derivation which starts from S(?0..n?
)(the instantiation of the start predicate on thewhole input text) and leads to the empty string(of instantiated predicates).
The parse forest of wis the CFG whose axiom is S(?0..n?)
and whoseproductions are the instantiated clauses used in allcomplete derivations.3We say that the arity of a PRCG is k, and wecall it a k-PRCG, if and only if k is the maximum3Note that this parse forest has no terminal symbols (itslanguage is the empty string).255arity of its predicates (k = maxA?N arity(A)).We say that a k-PRCG is simple, we have a simplek-PRCG, if and only if each of its clause is?
non-combinatorial: the arguments of its RHSpredicates are single variables;?
non-erasing: each variable which occur inits LHS (resp.
RHS) also occurs in its RHS(resp.
LHS);?
linear: there are no variables which occurmore than once in its LHS and in its RHS.The subclass of simple PRCGs is of importancesince it is MCS and is the one equivalent toLCFRSs.2.2 Finite AutomataA non-deterministic finite automaton (NFA) isthe 5-tuple A = (Q,?, ?, q0, F ) where Q is anon empty finite set of states, ?
is a finite setof terminal symbols, ?
is the ternary transitionrelation ?
= {(qi, t, qj)|qi, qj ?
Q?
t ?
??{?
}},q0 is a distinguished element of Q called the initialstate and F is a subset of Q whose elements arecalled final states.
The size of A, noted |A|, is itsnumber of states (|A| = |Q|).We define the ternary relation ??
on Q???
?Qas the smallest set s.t.
??
= {(q, ?, q) | q ?
Q} ?
{(q1, xt, q3) | (q1, x, q2) ?
??
?
(q2, t, q3) ?
?}.
If(q, x, q?)
?
?
?, we say that x is a path between qand q?.
If q = q0 and q?
?
F , x is a complete path.The language L(A) defined (generated, recog-nized, accepted) by the NFA A is the set of all itscomplete paths.We say that a NFA is empty if and only if itslanguage is empty.
Two NFAs are equivalent ifand only if they define the same language.
ANFA is ?-free if and only if its transition relationdoes not contain a transition of the form (q1, ?, q2).Every NFA can be transformed into an equivalent?-free NFA (this classical result and those recalledbelow can be found, e.g., in (Hopcroft and Ullman,1979)).As usual, a NFA is drawn with the followingconventions: a transition (q1, t, q2) is an arrowlabelled t from state q1 to state q2 which areprinted with a surrounded circle.
Final states aredoubly circled while the initial state has a singleunconnected, unlabelled input arrow.A deterministic finite automaton (DFA) is aNFA in which the transition relation ?
is atransition function, ?
: Q ?
?
?
Q. Inother words, there are no ?-transitions and if(q1, t, q2) ?
?, t 6= ?
and ?
(q1, t, q?2) ?
?
withq?2 6= q2.
Each NFA can be transformed bythe subset construction into an equivalent DFA.Moreover, each DFA can be transformed by aminimization algorithm into an equivalent DFAwhich is minimal (i.e., there is no other equivalentDFA with fewer states).2.3 Directed acyclic graphsFormally, a directed acyclic graph (DAG) D =(Q,?, ?, q0, F ) is an NFA for which there existsa strict order relation < on Q such that (p, t, q) ??
?
p < q.
Without loss of generality we mayassume that < is a total order.Of course, as NFAs, DAGs can be transformedinto equivalent deterministic or minimal DAGs.3 DAGs and PRCGsA DAG D is recognized (accepted) by a PRCGG if and only if L(D) ?
L(G) 6= ?.
A trivialway to solve this recognition (or parsing) problemis to extract the complete paths of L(D) (whichare in finite number) one by one and to parseeach such string with a standard PRCG parser, the(complete) parse forest for D being the union ofeach individual forest.4 However since DAGs maydefine an exponential number of strings w.r.t.
itsown size,5 the previous operation would take anexponential time in the size of D, and the parseforest would also have an exponential size.The purpose of this paper is to show thatit is possible to directly parse a DAG (withoutany unfolding) by sharing identical computations.This sharing may lead to a polynomial parse timefor an exponential number of sentences, but, insome cases, the parse time remains exponential.3.1 DAGs and RangesIn many NLP applications the source text cannotbe considered as a sequence of terminal symbols,but rather as a finite set of finite strings.
As4These forests do not share any production (instantiatedclause) since ranges in a particular forest are all relatedto the corresponding source string w (i.e., are all of theform ?i..j?w).
To be more precise the union operation onindividual forests must be completed in adding productionswhich connect the new (super) axiom (say S?)
with each rootand which are, for each w of the form S?
?
S(?0..|w|?w).5For example the language (a|b)n, n > 0 which contains2n strings can be defined by a minimal DAG whose size isn + 1.256mentioned in th introduction, this non-uniquestring could be used to encode not-yet-solvedambiguities in the input.
DAGs are a convenientway to represent these finite sets of strings byfactorizing their common parts (thanks to theminimization algorithm).In order to use DAGs as inputs for PRCGparsing we will perform two generalizations.The first one follows.
Let w = t1 .
.
.
tn be astring in some alphabet ?
and let Q = {qi | 0 ?i ?
n} be a set of n + 1 bounds with a total orderrelation <, we have q0 < q1 < .
.
.
< qn.
Thesequence ?
= q0t1q1t2q2 .
.
.
tnqn ?
Q?(?
?Q)nis called a bounded string which spells w. A rangeis a pair of bounds (qi, qj) with qi < qj noted?pi..pj?pi and any triple of the form (qi?1tiqi)is called a transition.
All the notions aroundPRCGs defined in Section 2.1 easily generalizefrom strings to bounded strings.
It is also the casefor the standard parsing algorithm of (Boullier,2004).Now the next step is to move from boundedstrings to DAGs.
Let D = (Q,?, ?, q0, F ) be aDAG.
A string x ?
??
s.t.
we have (q1, x, q2) ???
is called a path between q1 and q2 and a string?
= qt1q1 .
.
.
tpqp ?
Q ?
(?
?
{?}
?
Q)?
is abounded path and we say that ?
spells t1t2 .
.
.
tp.A path x from q0 to f ?
F is a complete pathand a bounded path of the form q0t1 .
.
.
tnf withf ?
F is a complete bounded path.
In thecontext of a DAG D, a range is a pair of states(qi, qj) with qi < qj noted ?qi..qj?D.
A range?qi..qj?D is valid if and only if there exists apath from qi to qj in D. Of course, any range?p..q?D defines its associated sub-DAG D?p..q?
=(Q?p..q?,?
?p..q?, ?
?p..q?, p, {q}) as follows.
Itstransition relation is ??p..q?
= {(r, t, s) | (r, t, s) ??
?
(p, x?, r), (s, x?
?, q) ?
??}.
If ??p..q?
= ?
(i.e., there is no path between p and q), D?p..q?
isthe empty DAG, otherwise Q?p..q?
(resp.
??p..q?
)are the states (resp.
terminal symbols) of thetransitions of ??p..q?.
With this new definition ofranges, the notions of instantiation and derivationeasily generalize from bounded strings to DAGs.The language of a PRCG G for a DAGD is defined by?L (G,D) = ?f?F {x |S(?q0..f?D) +?G,D ?}.
Let x ?
L(D), it is not verydifficult to show that if x ?
L(G) then we havex ?
?L (G,D).
However, the converse is not true(see Example 1), a sentence of L(D)?
?L (G,D)may not be in L(G).
To put it differently, if weuse the standard RCG parser, with the ranges ofa DAG, we produce the shared parse-forest forthe language?L (G,D) which is a superset ofL(D) ?
L(G).However, if G is a simple PRCG, we havethe equality L(G) = ?D is a DAG?L (G,D).Note that the subclass of simple PRCGs is ofimportance since it is MCS and it is the oneequivalent to LCFRSs.
The informal reason ofthe equality is the following.
If an instantiatedpredicate Ai(~?i) succeeds in some RHS, thismeans that each of its ranges ~?i[j] = ?k..l?D hasbeen recognized as being a component of Ai, moreprecisely their exists a path from k to l in D whichis a component of Ai.
The range ?k..l?D selectsin D a set ?
?k..l?D of transitions (the transitionsused in the bounded paths from k to l).
Becauseof the linearity of G, there is no other range in thatRHS which selects a transition in ?
?k..l?D .
Thusthe bounded paths selected by all the ranges of thatRHS are disjoints.
In other words, any occurrenceof a valid instantiated range ?i..j?D selects a set ofpaths which is a subset of L(D?i..j?
).Now, if we consider a non-linear PRCG, insome of its clauses, there is a variable, say X,which has several occurrences in its RHS (if weconsider a top-down non-linearity).
Now assumethat for some input DAG D, an instantiation ofthat clause is a component of some completederivation.
Let ?p..q?D be the instantiation of Xin that instantiated clause.
The fact that a predicatein which X occurs succeeds means that there existpaths from p to q in D?p..q?.
The same thing standsfor all the other occurrences of X but nothingforce these paths to be identical or not.Example 1.Let us take an example which will be usedthroughout the paper.
It is a non-linear 1-PRCGwhich defines the language anbncn, n ?
0 asthe intersection of the two languages a?bncn andanbnc?.
Each of these languages is respectivelydefined by the predicates a?bncn and anbnc?
; thestart predicate is anbncn.2571234a bb cFigure 1: Input DAG associated with ab|bc.anbncn(X) ?
a?bncn(X) anbnc?
(X)a?bncn(aX) ?
a?bncn(X)a?bncn(X) ?
bncn(X)bncn(bXc) ?
bncn(X)bncn(?)
?
?anbnc?
(Xc) ?
anbnc?(X)anbnc?
(X) ?
anbn(X)anbn(aXb) ?
anbn(X)anbn(?)
?
?If we use this PRCG to parse the DAG ofFigure 1 which defines the language {ab, bc},we (erroneously) get the non-empty parse for-est of Figure 2 though neither ab nor bc is inanbncn.6 It is not difficult to see that the problemcomes from the non-linear instantiated variableX?1..4?
in the start node, and more precisely fromthe actual (wrong) meaning of the three differ-ent occurrences of X?1..4?
in anbncn(X?1..4?)
?a?bncn(X?1..4?)
anbnc?(X?1..4?).
The first occur-rence in its RHS says that there exists a path inthe input DAG from state 1 to state 4 which is ana?bncn.
The second occurrence says that thereexists a path from state 1 to state 4 which is ananbnc?.
While the LHS occurrence (wrongly) saysthat there exists a path from state 1 to state 4 whichis an anbncn.
However, if the two X?1..4?
?s in theRHS had selected common paths (this is not pos-sible here) between 1 and 4, a valid interpretationcould have been proposed.With this example, we see that the difficulty ofDAG parsing only arises with non-linear PRCGs.If we consider linear PRCGs, the sub-class ofthe PRCGs which is equivalent to LCFRSs, the6In this forest oval nodes denote different instantiatedpredicates, while its associated instantiated clauses arepresented as its daughter(s) and are denoted by square nodes.The LHS of each instantiated clause shows the instantiationof its LHS symbols.
The RHS is the corresponding sequenceof instantiated predicates.
The number of daughters of eachsquare node is the number of its RHS instantiated predicates.standard algorithm works perfectly well with inputDAGs, since a valid instantiation of an argumentof a predicate in a clause by some range ?p..q?means that there exists (at least) one path betweenp and q which is recognized.The paper will now concentrate on non-linearPRCGs, and will present a new valid parsingalgorithm and study its complexities (in space andtime).In order to simplify the presentation weintroduce this algorithm as a post-processing passwhich will work on the shared parse-forest outputby the (slightly modified) standard algorithmwhich accepts DAGs as input.3.2 Parsing DAGs with non-linear PRCGsThe standard parsing algorithm of (Boullier, 2004)working on a string w can be sketched as follows.It uses a single memoized boolean functionpredicate(A, ~?)
where A is a predicate and ~?
is avector of ranges whose dimension is arity(A).
Theinitial call to that function has the form predicate(S, ?0..|w|?).
Its purpose is, for each A0-clause, toinstantiate each of its symbols in a consistant way.For example if we assume that the ith argument ofthe LHS of the current A0-clause is ?
?iXaY ??
?i andthat the ith component of ~?0 is the range ?pi..qi?
aninstantiation of X, a an Y by the ranges ?pX ..qX?,?pa..qa?
and ?pY ..qY ?
is such that we have pi ?pX ?
qX = pa < qa = pa + 1 = pY ?
qY ?
qiand w = w?aw??
with |w?| = pa.
Since the PRCGis non bottom-up erasing, the instantiation of allthe LHS symbols implies that all the argumentsof the RHS predicates Ai are also instantiated andgathered into the vector of ranges ~?i.
Now, foreach i (1 ?
i ?
|RHS|), we can call predicate(Ai, ~?i).
If all these calls succeed, the instantiatedclause can be stored as a component of the sharedparse forest.7In the case of a DAG D = (Q,?, ?, q0, F ) asinput, there are two slight modifications, the ini-tial call is changed by the conjunctive call pred-icate(S, ?q0..f1?)
?
.
.
.?
predicate (S, ?q0..f|F |?
)with fi ?
F 8 and the terminal symbol a can be in-stantiated by the range ?pa..qa?D only if (pa, a, qa)7Note that such an instantiated clause could beunreachable from the (future) instantiated start symbol whichwill be the axiom of the shared forest considered as a CFG.8Technically, each of these calls produces a forest.
Theseindividual forests may share subparts but their roots are alldifferent.
In order to have a true forest, we introduce anew root, the super-root whose daughters are the individualforests.258anbncn?1..4?anbncn(X?1..4?)
?
a?bncn?1..4?
anbnc??1..4?a?bncn?1..4?a?bncn(X?1..4?)
?
bncn?1..4?anbnc??1..4?anbnc?(X?1..4?)
?
anbn?1..4?bncn?1..4?bncn(b?1..3?
X?3..3?
c?3..4?)
?
bncn?3..3?anbn?1..4?anbn(a?1..2?
X?2..2?
b?2..4?)
?
anbn?2..2?bncn?3..3?bncn(??3..3?)
?
?anbn?2..2?anbn(??2..2?)
?
?Figure 2: Parse forest for the input DAG ab|bc.is a transition in ?.
The variable symbol X canbe instantiated by the range ?pX ..qX?D only if?pX ..qX?D is valid.3.3 Forest FilteringWe assume here that for a given PRCG G wehave built the parse forest of an input DAG D asexplained above and that each instantiated clauseof that forest contains the range ?pX ..qX?D ofeach of its instantiated symbols X.
We have seenin Example 1 that this parse forest is valid if G islinear but may well be unvalid if G is non-linear.In that latter case, this happens because the range?pX ..qX?D of each instantiation of the non-linearvariable X selects the whole sub-DAG D?pX ..qX?while each instantiation should only select a sub-language of L(D?pX ..qX?).
For each occurrence ofX in the LHS or RHS of a non-linear clause, itssub-languages could of course be different fromthe others.
In fact, we are interested in theirintersections: If their intersections are non empty,this is the language which will be associated with?pX ..qX?D, otherwise, if their intersections areempty, then the instantiation of the consideredclause fails and must thus be removed from theforest.
Of course, we will consider that thelanguage (a finite number of strings) associatedwith each occurrence of each instantiated symbolis represented by a DAG.The idea of the forest filtering algorithmis to first compute the DAGs associated witheach argument of each instantiated predicateduring a bottom-up walk.
These DAGs arecalled decorations.
This processing will performDAG compositions (including intersections, assuggested above), and will erase clauses in whichempty intersections occur.
If the DAG associatedwith the single argument of the super-root isempty, then parsing failed.Otherwise, a top-down walk is launched(see below), which may also erase non-validinstantiated clauses.
If necessary, the algorithmis completed by a classical CFG algorithm whicherase non productive and unreachable symbolsleaving a reduced grammar/forest.In order to simplify our presentation we willassume that the PRCGs are non-combinatorialand bottom-up non-erasing.
However, wecan note that the following algorithm can begeneralized in order to handle combinatorialPRCGs and in particular with overlappingarguments.9 Moreover, we will assume that theforest is non cyclic (or equivalently that all cycleshave previously been removed).109For example the non-linear combinatorial clauseA(XY Z) ?
B(XY ) B(Y Z) has overlapping arguments.10By a classical algorithm from the CFG technology.2593.3.1 The Bottom-Up WalkFor this principle algorithm, we assume that foreach instantiated clause in the forest, a DAGwill be associated with each occurrence of eachinstantiated symbol.
More precisely, for a giveninstantiated A0-clause, the DAGs associated withthe RHS symbol occurrences are composed (seebelow) to build up DAGs which will be associatedwith each argument of its LHS predicate.
For eachLHS argument, this composition is directed by thesequence of symbols in the argument itself.The forest is walked bottom-up starting from itsleaves.
The constraint being that an instantiatedclause is visited if and only if all its RHSinstantiated predicates have already all beenvisited (computed).
This constraint can besatisfied for any non-cyclic forest.To be more precise, consider an instantiationc?
= A0(~?0) ?
A1(~?1) .
.
.
Ap( ~?p) of the clausec = A0( ~?0) ?
A1( ~?1) .
.
.
Am( ~?m), we performthe following sequence:1.
If the clause is not top-down linear (i.e.,there exist multiple occurrences of the samevariables in its RHS arguments), for suchvariable X let the range ?pX ..qX?
be itsinstantiation (by definition, all occurrencesare instantiated by the same range), weperform the intersection of the DAGsassociated with each instantiated predicateargument X.
If one intersection results inan empty DAG, the instantiated clause isremoved from the forest.
Otherwise, weperform the following steps.2.
If a RHS variable Y is linear, it occurs once inthe jth argument of predicate Ai.
We performa brand new copy of the DAG associated withthe jth argument of the instantiation of Ai.3.
At that moment, all instantiated variableswhich occur in c?
are associated with a DAG.For each occurrence of a terminal symbol tin the LHS arguments we associate a (new)DAG whose only transition is (p, t, q) wherep and q are brand new states with, of course,p < q.4.
Here, all symbols (terminals or variables) areassociated with disjoints DAGs.
For eachLHS argument ~?0[i] = Xi1 .
.
.
Xij .
.
.
Xipi ,we associate a new DAG which is theconcatenation of the DAGs associated withthe symbols Xi1, .
.
.
, Xij , .
.
.
and Xipi .5.
Here each LHS argument of c?
is associatedwith a non empty DAG, we then reportthe individual contribution of c?
into the(already computed) DAGs associated withthe arguments of its LHS A0(~?0).
The DAGassociated with the ith argument of A0(~?0) isthe union (or a copy if it is the first time) of itsprevious DAG value with the DAG associatedwith the ith argument of the LHS of c?.This bottom-up walk ends on the super-root with afinal decoration say R. In fact, during this bottom-up walk, we have computed the intersection of thelanguages defined by the input DAG and by thePRCG (i.e., we have L(R) = L(D) ?
L(G)).Example 2.1 2 3 4abb cbFigure 3: Input DAG associated with abc|ab|bc.With the PRCG of Example 1 and the inputDAG of Figure 3, we get the parse forest ofFigure 4 whose transitions are decorated by theDAGs computed by the bottom-up algorithm.11The crucial point to note here is the intersectionwhichis performed between {abc, bc} and {abc, ab} onanbncn(X?1..4?)
?
a?bncn?1..4?
anbnc??1..4?
.
Thenon-empty set {abc} is the final result assigned tothe instantiated start symbol.
Since this result isnon empty, it shows that the input DAG D is rec-ognized by G. More precisely, this shows that thesub-language of D which is recognized by G is{abc}.However, as shown in the previous example, the(undecorated) parse forest is not the forest builtfor the DAG L(D) ?
L(G) since it may containnon-valid parts (e.g., the transitions labelled {bc}or {ab} in our example).
In order to get the11For readability reasons these DAGs are represented bytheir languages (i.e., set of strings).
Bottom-up transitionsfrom instantiated clauses to instantiated predicates reflectsthe computations performed by that instantiated clausewhile bottom-up transitions from instantiated predicates toinstantiated clauses are the union of the DAGs entering thatinstantiated predicate.260anbncn?1..4?anbncn(X?1..4?)
?
a?bncn?1..4?
anbnc??1..4?a?bncn?1..4?a?bncn(X?1..4?)
?
bncn?1..4?a?bncn(a?1..2?
X?2..4?)
?
a?bncn?2..4?anbnc??1..4?anbnc?(X?1..4?)
?
anbn?1..4?anbnc?(X?1..3?
c?3..4? )
?
anbnc??1..3?bncn?1..4?bncn(b?2..3?
X?3..3?
c?3..4?)
?
bncn?3..3?a?bncn?2..4?a?bncn(X?2..4?)
?
bncn?2..4?anbn?1..4?anbn(a?1..2?
X?2..2?
b?2..4?)
?
anbn?2..2?anbnc??1..3?anbnc?(X?1..3?)
?
anbn?1..3?bncn?3..3?bncn(??3..3?)
?
?bncn?2..4?bncn(b?2..3?
X?3..3?
c?3..4?)
?
bncn?3..3?anbn?2..2?anbn(??2..2?)
?
?anbn?1..3?anbn(a?1..2?
X?2..2?
b?2..3?)
?
anbn?2..2?
{abc}{abc, bc} {abc, ab}{bc}{abc}{ab}{abc}{bc} {abc} {ab} {abc}{bc} {bc} {ab} {ab}{?}{bc}{?}{ab}{?}{bc}{?}{ab}{?}
{?
}Figure 4: Bottom-up decorated parse forest for the input DAG abc|ab|bc.261right forest (i.e., to get a PRCG parser ?
nota recognizer ?
which accepts a DAG as input)we need to perform another walk on the previousdecorated forest.3.3.2 The Top-Down WalkThe idea of the top-down walk on the parseforest decorated by the bottom-up walk is to(re)compute all the previous decorations startingfrom the bottom-up decoration associated withthe instantiated start predicate.
It is to be notedthat (the language defined by) each top-downdecoration is a subset of its bottom-up counterpart.However, when a top-down decoration becomesempty, the corresponding subtree must be erasedfrom the forest.
If the bottom-up walk succeeds,we are sure that the top-down walk will notresult in an empty forest.
Moreover, if weperform a new bottom-up walk on this reducedforest, the new bottom-up decorations will denotethe same language as their top-down decorationscounterpart.The forest is walked top-down starting fromthe super-root.
The constraint being that aninstantiated A(~?
)-clause is visited if and only if allthe occurrences of A(~?)
occurring in the RHS ofinstantiated clauses have all already been visited.This constraint can be satisfied for any non-cyclicforest.Initially, we assume that each argument of eachinstantiated predicate has an empty decoration,except for the argument of the super-root which isdecorated by the DAG R computed by the bottom-up pass.Now, assume that a top-down decoration hasbeen (fully) computed for each argument ofthe instantiated predicate A0(~?0).
For eachinstantiated clause of the form c?
= A0(~?0) ?A1(~?1) .
.
.
Ai(~?i) .
.
.
Am( ~?m), we perform thefollowing sequence:121.
We perform the intersection of the top-downdecoration of each argument of A0(~?0) withthe decoration computed by the bottom-uppass for the same argument of the LHSpredicate of c?.
If the result is empty, c?
iserased from the forest.2.
For each LHS argument, the previous resultsare dispatched over the symbols of this12The decoration of each argument of Ai(~?i) is eitherinitially empty or has already been partially computed.argument.13 Thus, each instantiated LHSsymbol occurrence is decorated by its ownDAG.
If the considered clause has severaloccurrences of the same variable in the LHSarguments (i.e., is bottom-up non-linear),we perform the intersection of these DAGsin order to leave a single decoration perinstantiated variable.
If an intersection resultsin an empty DAG, the current clause is erasedfrom the forest.3.
The LHS instantiated variable decorationsare propagated to the RHS arguments.
Thispropagation may result in DAG concatena-tions when a RHS argument is made up ofseveral variables (i.e., is combinatorial).4.
At last, we associate to each argumentof Ai(~?i) a new decoration which iscomputed as the union of its previous top-down decoration with the decoration justcomputed.Example 3.
When we apply the previous al-gorithm to the bottom-up parse forest of Exam-ple 2, we get the top-down parse forest of Fig-ure 5.
In this parse forest, erased parts arelaid out in light gray.
The more noticable pointsw.r.t.
the bottom-up forest are the decorations be-tween anbncn(X?1..4?)
?
a?bncn?1..4?
anbnc?
?1..4?and its RHS predicates a?bncn?1..4?
andanbnc??1..4?
which are changed both to {abc}instead of {abc, bc} and {abc, ab}.
These twochanges induce the indicated erasings.13Assume that ~?0[k] = ?p..q?D, that the decoration DAGassociated with the kth argument of A0( ~?0) is D??p..q?
=(Q??p..q?,?
?p..q?, ??
?p..q?, p?, F ??p..q?)
(we have L(D??p..q?)
?L(D?p..q?))
and that ~?0[k] = ?1kX?2k and that ?i..j?D is theinstantiation of the symbol X in c?.
Our goal is to extractfrom D??p..q?
the decoration DAG D??i..j?
associated withthat instantiated occurrence of X.
This computation can behelped if we maintain, associated with each decoration DAGa function, say d, which maps each state of the decorationDAG to a set of states (bounds) of the input DAG D. If, as wehave assumed, D is minimal, each set of states is a singleton,we can write d(p?)
= p, d(f ?)
= q for all f ?
?
F ?
?p..q?and more generally d(i?)
?
Q if i?
?
Q?.
Let I ?
= {i?
|i?
?
Q??p..q?
?
d(i?)
= i} and J ?
= {j?
| j?
?
Q??p..q?
?d(j?)
= j}.
The decoration DAG D??i..j?
is such thatL(D??i..j?)
=Si??I?,j??J?
{x | x is a path from i?
to j?
}.Of course, together with the construction of D??i..j?
, itsassociated function d must also be built.262anbncn?1..4?anbncn(X?1..4?)
?
a?bncn?1..4?
anbnc??1..4?a?bncn?1..4?a?bncn(X?1..4?)
?
bncn?1..4?a?bncn(a?1..2?
X?2..4?)
?
a?bncn?2..4?anbnc??1..4?anbnc?(X?1..4?)
?
anbn?1..4?anbnc?(X?1..3?
c?3..4? )
?
anbnc??1..3?bncn?1..4?bncn(b?2..3?
X?3..3?
c?3..4?)
?
bncn?3..3?a?bncn?2..4?a?bncn(X?2..4?)
?
bncn?2..4?anbn?1..4?anbn(a?1..2?
X?2..2?
b?2..4?)
?
anbn?2..2?anbnc??1..3?anbnc?(X?1..3?)
?
anbn?1..3?bncn?3..3?bncn(??3..3?)
?
?bncn?2..4?bncn(b?2..3?
X?3..3?
c?3..4?)
?
bncn?3..3?anbn?2..2?anbn(??2..2?)
?
?anbn?1..3?anbn(a?1..2?
X?2..2?
b?2..3?)
?
anbn?2..2?
{abc}{abc} {abc}?{abc}?{abc}?
{abc} ?
{abc}?
{bc} ?
{ab}?{bc}?{ab}{?}{bc}{?}{ab}{?}
{?
}Figure 5: Top-down decorated parse forest for the input DAG abc|ab|bc.2633.4 Time and Space ComplexitiesIn this Section we study the time and sizecomplexities of the forest filtering algorithm.Let us consider the sub-DAG D?p..q?
of theminimal input DAG D and consider any (finite)regular language L ?
L(D?p..q?
), and let DL bethe minimal DAG s.t.
L(DL) = L. We show, onan example, that |DL| may be an exponential w.r.t.|D?p..q?|.Consider, for a given h > 0, the language(a|b)h. We know that this language can berepresented by the minimal DAG with h+1 statesof Figure 6.Assume that h = 2k and consider thesub-language L2k of (a|b)2k (nested well-parenthesized strings) which is defined by1.
L2 = {aa, bb} ;2. k > 1, L2k = {axa, bxb | x ?
L2k?2},It is not difficult to see that the DAG in Figure 7defines L2k and is minimal, but its size 2k+2 ?
2is an exponential in the size 2k+1 of the minimalDAG for the language (a|b)2k .This results shows that, there exist cases inwhich some minimal DAGs D?
that define sub-languages of minimal DAGs D may have aexponential size (i.e., |D?| = O(2|D|).
In otherwords, when, during the bottom-up or top-downwalk, we compute union of DAGs, we may fallon these pathologic DAGs that will induce acombinatorial explosion in both time and space.3.5 Implementation IssuesOf course, many improvements may be broughtto the previous principle algorithms in practicalimplementations.
Let us cite two of them.
First itis possible to restrict the number of DAG copies:a DAG copy is not useful if it is the last referenceto that DAG.We shall here devel the second point on a littlemore: if an argument of a predicate is neverused in ant non-linearity, it is only a waste oftime to compute its decoration.
We say that Ak,the kth argument of the predicate A is a non-linear predicate argument if there exists a clausec in which A occurs in the RHS and whosekth argument has at least one common variableanother argument Bh of some predicate B ofthe RHS (if B = A, then of course k and hmust be different).
It is clear that Bh is thennon-linear as well.
It is not difficult to see thatdecorations needs only to be computed if they areassociated with a non-linear predicate argument.
Itis possible to compute those non-linear predicatearguments statically (when building the parser)when the PRCG is defined within a single module.However, if the PRCG is given in several modules,this full static computation is no longer possible.The non-linear predicate arguments must thusbe identified at parse time, when the wholegrammar is available.
This rather trivial algorithmwill not be described here, but it should benoted that it is worth doing since in practice itprevents decoration computations which can takean exponential time.4 ConclusionIn this paper we have shown how PRCGs canhandle DAGs as an input.
If we consider the linearPRCG, the one equivalent to LCFRS, the parsingtime remains polynomial.
Moreover, input DAGsnecessitate only rather cosmetic modifications inthe standard parser.In the non-linear case, the standard parser mayproduce illegal parses in its output shared parseforest.
It may even produce a (non-empty) sharedparse forest though no sentences of the input DAGare in the language defined by our non-linearPRCG.
We have proposed a method which usesthe (slightly modified) standard parser but prunes,within extra passes, its output forest and leaves alland only valid parses.
During these extra bottom-up and top-down walks, this pruning involvesthe computation of finite languages by means ofconcatenation, union and intersection operations.The sentences of these finite languages are alwayssubstrings of the words of the input DAG D.We choose to represent these intermediate finitelanguages by DAGs instead of sets of stringsbecause the size of a DAG is, at worst, of the sameorder as the size of a set of strings but it could, insome cases, be exponentially smaller.However, the time taken by this extra pruningpass cannot be guaranteed to be polynomial,as expected from previously known complexityresults (Bertsch and Nederhof, 2001).
We haveshown an example in which pruning takes anexponential time and space in the size of D. Thedeep reason comes from the fact that if L is afinite (regular) language defined by some minimalDAG D, there are cases where a sub-language of2640 1 2 h?
1 habababFigure 6: Input DAG associated with the language (a|b)h, h > 0.123456789101112131415............2k+2 ?
42k+2 ?
32k+2 ?
2ababababababababababababababFigure 7: DAG associated with the language of nested well-parenthesized strings of length 2k.L may require to be defined by a DAG whose sizeis an exponential in the size of D. Of course thiscombinatorial explosion is not a fatality, and wemay wonder whether, in the particular case of NLPit will practically occur?ReferencesFranois Barthe?lemy, Pierre Boullier, Philippe De-schamp, and ?Eric de la Clergerie.
2001.
Guidedparsing of range concatenation languages.
In Pro-ceedings of the 39th Annual Meeting of the Associ-ation for Comput.
Linguist.
(ACL?01), pages 42?49,University of Toulouse, France.Eberhard Bertsch and Mark-Jan Nederhof.
2001.
Onthe complexity of some extensions of rcg parsing.
InProceedings of IWPT?01, Beijing, China.Pierre Boullier, 2004.
New Developments in Pars-ing Technology, volume 23 of Text, Speech andLanguage Technology, chapter Range Concatena-tion Grammars, pages 269?289.
Kluwer AcademicPublishers, H. Bunt, J. Carroll, and G. Satta edition.Jeffrey D. Hopcroft and John E. Ullman.
1979.Introduction to Automata Theory, Languages, andComputation.
Addison-Wesley, Reading, Mass.Bernard Lang.
1994.
Recognition can be harder thanparsing.
Computational Intelligence, 10(4):486?494.K.
Vijay-Shanker, David Weir, and Aravind K.Joshi.
1987.
Characterizing structural descriptionsproduced by various grammatical formalisms.
InProceedings of the 25th Meeting of the Associationfor Comput.
Linguist.
(ACL?87), pages 104?111,Stanford University, CA.265
