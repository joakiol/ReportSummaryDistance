Proceedings of SSST-6, Sixth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 1?9,Jeju, Republic of Korea, 12 July 2012. c?2012 Association for Computational LinguisticsWSD for n-best reranking and local language modeling in SMTMarianna Apidianaki, Guillaume Wisniewski?, Artem Sokolov, Aure?lien Max?, Franc?ois Yvon?LIMSI-CNRS?
Univ.
Paris SudBP 133, F-91403, Orsay Cedex, Francefirstname.lastname@limsi.frAbstractWe integrate semantic information at twostages of the translation process of a state-of-the-art SMT system.
A Word Sense Disam-biguation (WSD) classifier produces a proba-bility distribution over the translation candi-dates of source words which is exploited intwo ways.
First, the probabilities serve torerank a list of n-best translations produced bythe system.
Second, the WSD predictions areused to build a supplementary language modelfor each sentence, aimed to favor translationsthat seem more adequate in this specific sen-tential context.
Both approaches lead to sig-nificant improvements in translation perfor-mance, highlighting the usefulness of sourceside disambiguation for SMT.1 IntroductionWord Sense Disambiguation (WSD) is the task ofidentifying the sense of words in texts by referenceto some pre-existing sense inventory.
The selec-tion of the appropriate inventory and WSD methodstrongly depends on the goal WSD intends to serve:recent methods are increasingly oriented towardsthe disambiguation needs of specific end applica-tions, and explicitly aim at improving the overallperformance of complex Natural Language Process-ing systems (Ide and Wilks, 2007; Carpuat and Wu,2007).
This task-oriented conception of WSD ismanifested in the area of multilingual semantic pro-cessing: supervised methods, which were previouslyshown to give the best results, are being abandonedin favor of unsupervised ones that do not rely on pre-annotated training data.
Accordingly, pre-definedsemantic inventories, that usually served to providethe lists of candidate word senses, are being replacedby senses relevant to the considered applications anddirectly identified from corpora by means of wordsense induction methods.In a multilingual setting, the sense inventoriesneeded for disambiguation are generally built fromall possible translations of words or phrases in a par-allel corpus (Carpuat and Wu, 2007; Chan et al,2007), or by using more complex representationsof the semantics of translations (Apidianaki, 2009;Mihalcea et al, 2010; Lefever and Hoste, 2010).However, integrating this semantic knowledge intoStatistical Machine Translation (SMT) raises sev-eral challenges: the way in which the predictions ofthe WSD classifier have to be taken into account;the type of context exploited for disambiguation;the target words to be disambiguated (?all-words?WSD vs. WSD restricted to target words satisfy-ing specific criteria); the use of a single classifierversus building separate classifiers for each sourceword; the quantity and type of data used for trainingthe classifier (e.g., use of raw data or of more ab-stract representations, such as lemmatization, allow-ing to deal with sparseness issues), and many oth-ers.
Seemingly, the optimal way to take advantageof WSD predictions remains an open issue.In this work, we carry out a set of experimentsto investigate the impact of integrating the predic-tions of a cross-lingual WSD classifier into an SMTsystem, at two different stages of the translation pro-cess.
The first approach exploits the probability dis-tribution built by the WSD classifier over the set oftranslations of words found in the parallel corpus,1for reranking the translations in the n-best list gen-erated by the SMT system.
Words in the list thatmatch one of the proposed translations are boostedand are thus more likely to appear in the final trans-lation.
Our results on the English-French IWSLT?11task show substantial improvements in translationquality.
The second approach provides a tighter in-tegration of the WSD classifier with the rest of thesystem: using the WSD predictions, an additionalsentence specific language model is estimated andused during decoding.
These additional local mod-els can be used as an external knowledge source toreinforce translation hypotheses matching the pre-diction of the WSD system.In the rest of the paper, we present related workon integrating semantic information into SMT (Sec-tion 2).
The WSD classifier used in the current studyis described in Section 3.
We then present the twoapproaches adopted for integrating the WSD out-put into SMT (Section 4).
Evaluation results arepresented in Section 5, before concluding and dis-cussing some avenues for future work.2 Related workWord sense disambiguation systems generally workat the word level: given an input word and its con-text, they predict its (most likely) meaning.
Atthe same time, state-of-the-art translation systemsall consider groups of words (phrases, tuples, etc.
)rather than single words in the translation process.This discrepancy between the units used in MT andthose used in WSD is one of the major difficul-ties in integrating word predictions into the decoder.This was, for instance, one of the reasons for thesomewhat disappointing results obtained by Carpuatand Wu (2005) when the output of a WSD systemwas directly incorporated into a Chinese-EnglishSMT system.
Because of this difficulty, other cross-lingual semantics works have considered only sim-plified tasks, like blank-filling, without addressingthe integration of the WSD models in full-scale MTsystems (Vickrey et al, 2005; Specia, 2006).Since the pioneering work of Carpuat and Wu(2005), several more successful ways to take WSDpredictions into account have been proposed.
Forinstance, Carpuat and Wu (2007) proposed to gen-eralize the WSD system so that it performs a fullyphrasal multiword disambiguation.
However, giventhat the number of phrases is far larger than the num-ber of words, this approach suffers from sparsityand computational problems, as it requires traininga classifier for each entry of the phrase table.Chan et al (2007) introduced a way to modify therule weights of a hierarchical translation system toreflect the predictions of their WSD system.
Whiletheir approach and ours are built on the same intu-ition (an adaptation of a model to incorporate wordpredictions) their work is specific to hierarchicalsystems, while ours can be applied to any decoderthat uses a language model.
Haque et al (2009) etHaque et al (2010) introduce lexico-syntactic de-scriptions in the form of supertags as source lan-guage context-informed features in a phrase-basedSMT and a state-of-the-art hierarchical model, re-spectively, and report significant gains in translationquality.Closer to our work, Mauser et al (2009) and Pa-try and Langlais (2011) train a global lexicon modelthat predicts the bag of output words from the bagof input words.
As no explicit alignment betweeninput and output words is used, words are chosenbased on the (global) input context.
For each inputsentence, the decoder considers these word predic-tions as an additional feature that it uses to define anew model score which favors translation hypothe-ses containing words predicted by the global lexiconmodel.
A difference between this approach and ourwork is that instead of using a global lexicon model,we disambiguate a subset of the words in the inputsentence by employing a WSD classifier that cre-ates a probability distribution over the translationsof each word in its context.The unsupervised cross-lingual WSD classifierused in this work is similar to the one proposed inApidianaki (2009).
The original classifier disam-biguates new instances of words in context by se-lecting the most appropriate cluster of translationsamong a set of candidate clusters found in an auto-matically built bilingual sense inventory.
The senseinventory exploited by the classifier is created bya cross-lingual word sense induction (WSI) methodthat reveals the senses of source words by groupingtheir translations into clusters according to their se-mantic proximity, revealed by a distributional sim-ilarity calculation.
The resulting clusters represent2the source words?
candidate senses.
This WSDmethod gave good results in a word prediction taskbut, similarly to the work of Vickrey et al (2005)and of Specia (2006), the predictions are not inte-grated into a complete MT system.3 The WSD classifierOur WSD classifier is a variation of the one intro-duced in Apidianaki (2009).
The main differenceis that here the classifier serves to discriminate be-tween unclustered translations of a word and to as-sign a probability to each translation for new in-stances of the word in context.
Each translation isrepresented by a source language feature vector thatthe classifier uses for disambiguation.
All experi-ments carried out in this study are for the English(EN) - French (FR) language pair.3.1 Source Language Feature VectorsPreprocessing The information needed by the clas-sifier is gathered from the EN-FR training data pro-vided for the IWSLT?11 evaluation task.1 Thedataset consists of 107,268 parallel sentences, word-aligned in both translation directions using GIZA++(Och and Ney, 2003).
We disambiguate EN wordsfound in the parallel corpus that satisfy the set ofcriteria described below.Two bilingual lexicons are built from the align-ment results and filtered to eliminate spurious align-ments.
First, translation correspondences with aprobability lower than a threshold are discarded;2then translations are filtered by part-of-speech(PoS), keeping for each word only translations per-taining to the same grammatical category;3 finally,only intersecting alignments (i.e., correspondencesfound in the lexicons of both directions) are retained.Given that the lexicons contain word forms, the in-tersection is calculated based on lemmatization in-formation in order to perform a generalization overthe contents of the lexicons.
For instance, if the ENadjective regular is translated by habituelle (femi-1http://www.iwslt2011.org/2The translation probabilities between word tokens arefound in the translation table produced by GIZA++; the thresh-old is set to 0.01.3For this filtering, we employ a PoS and lemmatization lex-icon built after tagging both parts of the training corpus withTreeTagger (Schmid, 1994).nine singular form of the adjective habituel) in theEN-FR lexicon, but is found to translate habituel(masculine singular form) in the other direction,the EN-FR correspondence regular/habituelle is re-tained (because the two variants of the adjective arereduced to the same lemma).All lexicon entries satisfying the above criteria areretained and used for disambiguation.
In these initialexperiments, we disambiguate English words havingless than 20 French translations in the lexicon.
EachFrench translation of an English word that appearsmore than once in the training corpus4 is character-ized by a weighted English feature vector built fromthe training data.Vector building The feature vectors correspondingto the translations are built by exploiting informationfrom the source contexts (Apidianaki, 2008; Grefen-stette, 1994).
For each translation of an EN word w,we extract the content words that co-occur with win the corresponding source sentences of the parallelcorpus (i.e.
the content words that occur in the samesentence as w whenever it is translated by this trans-lation).
The extracted source language words con-stitute the features of the vector built for the transla-tion.For each translation Ti of w, let N be the numberof features retained from the corresponding sourcecontext.
Each feature Fj (1 ?
j ?
N) receives a to-tal weight tw(Fj,Ti) defined as the product of thefeature?s global weight, gw(Fj), and its local weightwith that translation, lw(Fj,Ti):tw(Fj,Ti) = gw(Fj) ?
lw(Fj,Ti) (1)The global weight of a feature Fj is a function ofthe number Ni of translations (Ti?s) to which Fj is re-lated, and of the probabilities (pi j) that Fj co-occurswith instances of w translated by each of the Ti?s:gw(Fj) = 1?
?Ti pi j log(pi j)Ni(2)Each of the pi j?s is computed as the ratio betweenthe co-occurrence frequency of Fj with w whentranslated as Ti, denoted as cooc frequency(Fj,Ti),4We do not consider hapax translations because they oftencorrespond to alignment errors.3and the total number of features (N) seen with Ti:pi j =cooc frequency(Fj,Ti)N(3)Finally, the local weight lw(Fj,Ti) between Fj and Tidirectly depends on their co-occurrence frequency:lw(Fj,Ti) = log(cooc frequency(Fj,Ti)) (4)3.2 Cross-Lingual WSDThe weighted feature vectors corresponding to thedifferent translations of an English word are usedfor disambiguation.5 As noted in Section 3.1, wedisambiguate source words satisfying a set of crite-ria.
Disambiguation is performed by comparing thevector associated with each translation to the newcontext of the words in the input sentences from theIWSLT?11 test set.More precisely, the information contained in eachvector is exploited by the WSD classifier to producea probability distribution over the translations, foreach new instance of a word in context.
We dis-ambiguate word forms (not lemmas) in order to di-rectly use the selected translations in the translatedtexts.
However, we should note that in some casesthis reduces the role of WSD to distinguishing be-tween different forms of one word and no differentsenses are involved.
Using more abstract represen-tations (corresponding to senses) is one of the per-spectives of this work.The classifier assigns a score to each transla-tion by comparing information in the correspondingsource vector to information found in the new con-text.
Given that the vector features are lemmatized,the new context is lemmatized as well and the lem-mas of the content words are gathered in a bag ofwords.
The adequacy of each translation for a newinstance of a word is estimated by comparing thetranslation?s vector with the bag of words built fromthe new context.
If common features are found be-tween the new context and a translation vector, anassociation score is calculated corresponding to themean of the weights of the common features rela-tively to the translation (i.e.
found in its vector).
In5The vectors are not used for clustering the translations asin Apidianaki (2009) but all translations are considered as can-didate senses.Equation (5), (CFj)|CF |j=1 is the set of common fea-tures between the translation vector Vi and the newcontext C and tw is the weight of a CF with transla-tion Ti (cf.
formula (1)).assoc score(Vi,C) =?|CF |j=1 tw(CFj,Ti)|CF| (5)The scores assigned to the different translations of asource word are normalized to sum up to one.In this way, a subset of the words that occur in theinput sentences from the test set are annotated withtheir translations and the associated scores (contex-tual probabilities), as shown in the example in Fig-ure 1.6 The WSD classifier makes predictions onlyfor the subset of the words found in the source partof the parallel test set that were retained from the ini-tial EN-FR lexicon after filtering.
Table 1 presentsthe total coverage of the WSD method as well as itscoverage for words of different PoS, with a focuson content words.
We report the number of disam-biguated words for each content PoS (cf.
third col-umn) and the corresponding percentage, calculatedon the basis of the total number of words pertainingto this PoS (cf.
second column).
We observe thatthe coverage of the method on nouns and adjectivesis higher than the one on verbs.
Given the rich ver-bal morphology of French, several verbs have a veryhigh number of translations in the bilingual lexicon(over 20) and are not handled during disambigua-tion.
The same applies to function words (articles,prepositions, conjunctions, etc.)
included in the ?allPoS?
category.4 Integrating Semantics into SMTIn this section, we present two ways to integrateWSD predictions into an SMT decoder.
The firstone (Section 4.1) is a simple method based on n-best reranking.
This method, already proposed inthe literature (Specia et al, 2008), allows us to eas-ily evaluate the impact of WSD predictions on au-tomatic translation quality.
The second one (Sec-tion 4.2) builds on the idea, introduced in (Crego etal., 2010), of using an additional language model to6Some source words are tagged with only one translation(e.g.
stones {pierres(1.000)}) because their other translationsin the lexicon occurred only once in the training corpus and,consequently, were not considered.4PoS # of words # of WSD predictions %Nouns 5535 3472 62.72Verbs 5336 1269 23.78Adjs 1787 1249 69.89Advs 2224 1098 49.37all content PoS 14882 7088 47.62all PoS 27596 8463 30.66Table 1: Coverage of the WSD methodyou know, one of the intense {intenses(0.305), forte(0.306), intense(0.389)} pleasures oftravel {transport(0.334), voyage(0.332), voyager(0.334)} and one of the delights of ethnographicresearch {recherche(0.225), research(0.167), e?tudes(0.218), recherches(0.222), e?tude(0.167)} isthe opportunity {possibilite?
(0.187), chance(0.185), opportunite?s(0.199), occasion(0.222), opportu-nite?
(0.207)} to live amongst those who have not forgotten {oubli(0.401), oublie?s(0.279), ou-blie?e(0.321)} the old {ancien(0.079), a?ge(0.089), anciennes(0.072), a?ge?es(0.100), a?ge?s(0.063), an-cienne(0.072), vieille(0.093), ans(0.088), vieux(0.086), vieil(0.078), anciens(0.081), vieilles(0.099)}ways {fac?ons(0.162), manie`res(0.140), moyens(0.161), aspects(0.113), fac?on(0.139), moyen(0.124),manie`re(0.161)} , who still feel their past {passe?e(0.269), autrefois(0.350), passe?
(0.381)} in thewind {e?olienne(0.305), vent(0.392), e?oliennes(0.304)} , touch {touchent(0.236), touchez(0.235),touche(0.235), toucher(0.293)} it in stones {pierres(1.000)} polished by rain {pluie(1.000)} ,taste {gou?t(0.500), gou?ter(0.500)} it in the bitter {amer(0.360), ame`re(0.280), amertume(0.360)}leaves {feuilles(0.500), feuillages(0.500)} of plants {usines(0.239), centrales(0.207), plantes(0.347),ve?ge?taux(0.207)}.Figure 1: Input sentence with WSD informationdirectly integrate the prediction of the WSD systeminto the decoder.4.1 N-best List RerankingA simple way to influence translation hypotheses se-lection with WSD information is to use the WSDprobabilities of translation variants to produce an ad-ditional feature appended to the n-best list after itsgeneration.
The feature value should reflect the de-gree to which a particular hypothesis includes pro-posed WSD variants for the respective words.
Re-running the standard MERT optimization procedureon the augmented features gives a new set of modelweights, that are used to rescore the n-best list.We propose the following method of features con-struction.
Given the phrase alignment informationbetween a source sentence and a hypothesis, we ver-ify if one or more of the proposed WSD variants forthe source word occur in the corresponding phrase ofthe translation hypothesis.
If this is the case, the cor-responding probabilities are additively accumulatedfor the current hypothesis.
At the end, two featuresare appended to each hypothesis in the n-best list:the total score accumulated for the hypothesis andthe same score normalized by the number of wordsin the hypothesis.Two MERT initialization schemes were consid-ered: (1) all model weights are initialized to zero,and (2) all the weights of ?standard?
features are ini-tialized to the values found by MERT and the newWSD features to zero.4.2 Local Language ModelsWe propose to adapt the approach introduced inCrego et al (2010) as an alternative way to inte-grate the WSD predictions within the decoder: foreach sentence to be translated, an additional lan-guage model (LM) is estimated and taken into ac-count during decoding.
As this additional ?local?model depends on the source sentence, it can beused as an external source of knowledge to reinforcetranslation hypotheses complying with criteria pre-dicted from the whole source sentence.
For instance,the unigram probabilities of the additional LM canbe derived from the (word) predictions of a WSDsystem, bigram probabilities from the prediction ofphrases and so on and so forth.
Although this ap-proach was suggested in (Crego et al, 2010), this5is, to the best of our knowledge, the first time it isexperimentally validated.In practice, the predictions of the WSD systemdescribed in Section 3 can be integrated by defining,for each sentence, an additional unigram languagemodel as follows:?
each translation predicted by the WSD classi-fier can be generated by the language modelwith the probability estimated by the WSDclassifier; no information about the sourceword that has been disambiguated is consid-ered;?
the probability of unknown words is set to asmall arbitrary constant.Even if most of the words composing the transla-tion hypothesis are considered as unknown words,hypotheses that contain the words predicted by theWSD system still have a higher LM score and aretherefore preferred.
Note that even if we only useunigram language models in our experiments, assenses are predicted at the word level, our approachis able to handle disambiguation of phrases as well.This approach has two main advantages over ex-isting ways to integrate WSD predictions in an SMTsystem.
First, no hard decisions are made: errorsof the WSD can be ?corrected?
by the translation.Second, sense disambiguation at the word level isnaturally and automatically propagated at the phraselevel: the additional LM is influencing all phrasepairs using one of the predicted words.Compared to the reranking approach introducedin the previous section, this method results in atighter integration with the decoder.
In particu-lar, the WSD predictions are applied before search-space pruning and are therefore expected to have amore important role.5 Evaluation5.1 Experimental SettingIn all our experiments, we considered the TED-talk English to French data set provided by theIWSLT?11 evaluation campaign, a collection of pub-lic speeches on a variety of topics.
We used theMoses decoder (Koehn et al, 2007).The TED-talk corpus is a small data set madeof a monolingual corpus (111,431 sentences) usedto estimate a 4-gram language model with KN-smoothing, and a bilingual corpus (107,268 sen-tences) used to extract the phrase table.
All dataare tokenized, cleaned and converted to lowercaseletters using the tools provided by the WMT orga-nizers.7 We then use a standard training pipeline toconstruct the translation model: the bitext is alignedusing GIZA++, symmetrized using the grow-diag-final-and heuristic; the phrase table is extracted andscored using the tools distributed with Moses.
Fi-nally, systems are optimized using MERT on the934 sentences of the dev-2010 set.
All evalua-tions are performed on the 1,664 sentences of thetest-2010 set.5.2 BaselineIn addition to the models introduced in Section 4,we considered two other supplementary models asbaselines.
The first one uses the IBM 1 model esti-mated during the SMT system training as a simpleWSD system: for each source sentence, a unigramadditional language model is defined by taking, foreach source, the 20 best translations according to theIBM 1 model and their probability.
Model 1 hasbeen shown to be one of the best performing fea-tures to be added to an SMT system in a rerankingstep (Och et al, 2004) and can be seen as a naiveWSD classifier.To test the validity of our approach, we repli-cate the ?oracle?
experiments of Crego et al (2010)and estimate the best gain our method can achieve.These experiments consist in using the reference totrain a local n-gram language model (with n in therange 1 to 3) which amounts, in the local languagemodel method of Section 4.2, to assuming that theWSD system correctly predicted a single translationfor each source word.5.3 ResultsTable 2 reports the results of our experiments.
Itappears that, for the considered task, sense disam-biguation improves translation performance: n-bestrescoring results in a 0.37 BLEU improvement andusing an additional language model brings about animprovement of up to a 0.88 BLEU.
In both cases,MERT assigns a large weight to the additional fea-7http://statmt.org/wmt08/scripts.tgz6method BLEU METEORbaseline ?
29.63 53.78rescoring WSD (zero init) 30.00 54.26WSD (reinit) 29.58 53.96additional LMoracle 3-gram 43.56 64.64oracle 2-gram 39.36 62.92oracle 1-gram 42.92 69.39IBM 1 30.18 54.36WSD 30.51 54.38Table 2: Evaluation results on the TED-talk task of our two methods to integrate WSD predictions.PoS baseline WSDNouns 67.57 69.06Verbs 45.97 47.76Adjectives 51.79 53.94Adverbs 52.17 56.25Table 3: Contrastive lexical evaluation: % of words correctly translated within each PoS classtures during tuning.
When rescoring n-best, an im-provement is observed only when the weights areinitialized to zero and not to the weights resultingfrom the previous optimization, maybe because ofthe difficulty to exit the local minimum MERT hadfound earlier.As expected, integrating the WSD predictionswith an additional language model results in a largerimprovement than simple rescoring, which showsthe importance of applying this new source of in-formation early in the translation pipeline, beforesearch space pruning.
Also note that the system us-ing the IBM 1 predictions is outperformed by thesystem using the WSD classifier introduced in Sec-tion 3, showing the quality of its predictions.Oracle experiments stress the high potential ofthe method introduced in (Crego et al, 2010) as away to integrate external sources of knowledge: allthree conditions result in large improvements overthe baseline and the proposed methods.
It must,however, be noted that contrary to the WSD methodintroduced in Section 3, these oracle experimentsrely on sense predictions for all source words andnot only content words.
Surprisingly enough, pre-dicting phrases instead of words results only in asmall improvement.
Additional experiments are re-quired to explain why 2-gram oracle achieved sucha low performance.5.4 Contrastive lexical evaluationAll the measures used for evaluating the impactof WSD information on translation show improve-ments, as discussed in the previous section.
Wecomplement these results with another measure oftranslation performance, proposed by Max et al(2010), which allows for a more fine-grained con-trastive evaluation of the translations produced bydifferent systems.
The method permits to comparethe results produced by the systems on differentword classes and to take into account the sourcewords that were actually translated.
We focus thisevaluation on the classes of content words (nouns,adjectives, verbs and adverbs) on which WSD hadan important coverage.
Our aim is, first, to ex-plore how these words are handled by a WSD-informed SMT system (the system using the lo-cal language models) compared to the baseline sys-tem that does not exploit any semantic informa-tion; and, second, to investigate whether their dis-ambiguation influences the translation of surround-ing non-disambiguated words.Table 3 reports the percentage of words cor-rectly translated by the semantically-informed sys-tem within each content word class: consistent gainsin translation quality are observed for all parts-of-speech compared to the baseline, and the best resultsare obtained for nouns.7baseline WSDw?2 w?1 w+1 w+2 w?2 w?1 w+1 w+2Nouns 64.01 68.69 75.17 64.6 65.47 70.46 76.3 66.6Verbs 68.67 67.58 63 62.19 69.98 68.89 64.85 64.25Adjectives 63.1 64.39 64.28 66.55 64.09 65.65 64.76 69.33Adverbs 70.8 69.44 68.67 66.38 71 71.21 70 67.22Table 4: Impact of WSD prediction on the surrounding wordsTable 4 shows how the words surrounding a dis-ambiguated word w (noun, verb, adjective or adverb)in the text are handled by the two systems.
Moreprecisely, we look at the translation of words in theimmediate context of w, i.e.
at positions w?2, w?1,w+1 and w+2.
The left column reports the percent-age of correct translations produced by the baselinesystem (without disambiguation) for words in thesepositions; the right column shows the positive im-pact that the disambiguation of a word has on thetranslation of its neighbors.
Note that this time welook at disambiguated words and their context with-out evaluating the correctness of the WSD predic-tions.
Nevertheless, even in this case, consistentgains are observed when WSD information is ex-ploited.
For instance, when a noun is disambiguated,70.46% and 76.3% of the immediately preceding(w?1) and following (w+1) words, respectively, arecorrectly translated, versus 68.69% and 75.17% ofcorrect translations produced by the baseline system.6 Conclusion and future workThe preliminary results presented in this paper onintegrating cross-lingual WSD into a state-of-the-art SMT system are encouraging.
Both adopted ap-proaches (n-best rescoring and local language mod-eling) benefit from the predictions of the proposedcross-lingual WSD classifier.
The contrastive eval-uation results further show that WSD improves notonly the translation of disambiguated words, but alsothe translation of neighboring words in the inputtexts.We consider various ways for extending thiswork.
First, future experiments will involve the useof more abstract representations of senses than indi-vidual translations, by applying a cross-lingual wordsense induction method to the training corpus priorto disambiguation.
We will also experiment withdisambiguation at the level of lemmas, to reducesparseness issues, and with different ways for han-dling lemmatized predictions by the SMT systems.Furthermore, we intend to extend the coverage of theWSD method by exploring other filtering methodsfor cleaning the alignment lexicons, and by address-ing the disambiguation of words of all PoS.AcknowledgmentsThis work was partly funded by the European Unionunder the FP7 project META-NET (T4ME), Con-tract No.
249119, and by OSEO, the French agencyfor innovation, as part of the Quaero Program.ReferencesMarianna Apidianaki.
2008.
Translation-oriented WordSense Induction Based on Parallel Corpora.
In Pro-ceedings of the Sixth International Conference on Lan-guage Resources and Evaluation (LREC?08), Mar-rakech, Morocco.Marianna Apidianaki.
2009.
Data-driven SemanticAnalysis for Multilingual WSD and Lexical Selectionin Translation.
In Proceedings of the 12th Confer-ence of the European Chapter of the Association forComputational Linguistics (EACL-09), pages 77?85,Athens, Greece.Marine Carpuat and Dekai Wu.
2005.
Word Sense Dis-ambiguation vs. Statistical Machine Translation.
InProceedings of the 43rd Annual Meeting of the Asso-ciation for Computational Linguistics (ACL?05), pages387?394, Ann Arbor, Michigan.Marine Carpuat and Dekai Wu.
2007.
Improving Sta-tistical Machine Translation using Word Sense Disam-biguation.
In Proceedings of the Joint EMNLP-CoNLLConference, pages 61?72, Prague, Czech Republic.Yee Seng Chan, Hwee Tou Ng, and David Chiang.
2007.Word Sense Disambiguation Improves Statistical Ma-chine Translation.
In Proceedings of the 45th AnnualMeeting of the Association for Computational Linguis-tics (ACL-07), pages 33?40, Prague, Czech Republic.8Josep Maria Crego, Aure?lien Max, and Franc?ois Yvon.2010.
Local lexical adaptation in Machine Transla-tion through triangulation: SMT helping SMT.
InProceedings of the 23rd International Conference onComputational Linguistics (Coling 2010), pages 232?240, Beijing, China.Gregory Grefenstette.
1994.
Explorations in AutomaticThesaurus Discovery.
Kluwer Academic Publishers,Norwell, MA.Rejwanual Haque, Sudip Naskar, Yanjun Ma, and AndyWay.
2009.
Using supertags as source language con-text in SMT.
In Proceedings of the 13th Annual Meet-ing of the European Association for Machine Transla-tion (EAMT 2009), pages 234?241, Barcelona, Spain.Rejwanul Haque, Sudip Kumar Naskar, Antal Van DenBosch, and Andy Way.
2010.
Supertags as source lan-guage context in hierarchical phrase-based SMT.
InProceedings of AMTA 2010: The Ninth Conference ofthe Association for Machine Translation in the Ameri-cas, pages 210?219, Denver, CO.N.
Ide and Y. Wilks.
2007.
Making Sense About Sense.In E. Agirre and P. Edmonds, editors, Word Sense Dis-ambiguation, Algorithms and Applications, pages 47?73.
Springer.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open sourcetoolkit for statistical machine translation.
In Proceed-ings of the 45th Annual ACL Meeting, Companion Vol-ume Proceedings of the Demo and Poster Sessions,pages 177?180, Prague, Czech Republic.Els Lefever and Veronique Hoste.
2010.
SemEval-2010Task 3: Cross-lingual Word Sense Disambiguation.In Proceedings of the 5th International Workshop onSemantic Evaluations (SemEval-2), ACL 2010, pages15?20, Uppsala, Sweden.Arne Mauser, Sas?a Hasan, and Hermann Ney.
2009.
Ex-tending statistical machine translation with discrimi-native and trigger-based lexicon models.
In Proceed-ings of the Conference on Empirical Methods in Nat-ural Language Processing (EMNLP), pages 210?217,Singapore, August.Aure?lien Max, Josep Maria Crego, and Franc?ois Yvon.2010.
Contrastive Lexical Evaluation of MachineTranslation.
In Proceedings of the Seventh Interna-tional Conference on Language Resources and Evalu-ation (LREC?10), Valletta, Malta.Rada Mihalcea, Ravi Sinha, and Diana McCarthy.
2010.SemEval-2010 Task 2: Cross-Lingual Lexical Sub-stitution.
In Proceedings of the 5th InternationalWorkshop on Semantic Evaluations (SemEval-2), ACL2010, pages 9?14, Uppsala, Sweden.Franz Josef Och and Hermann Ney.
2003.
A SystematicComparison of Various Statistical Alignment Models.Computational Linguistics, 29(1):19?51.Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur,Anoop Sarkar, Kenji Yamada, Alex Fraser, ShankarKumar, Libin Shen, David Smith, Katherine Eng,Viren Jain, Zhen Jin, and Dragomir Radev.
2004.
Asmorgasbord of features for statistical machine transla-tion.
In Proceedings of HLT-NAACL 2004, pages 161?168, Boston, Massachusetts, USA.Alexandre Patry and Philippe Langlais.
2011.
Going be-yond word cooccurrences in global lexical selectionfor statistical machine translation using a multilayerperceptron.
In Proceedings of 5th International JointConference on Natural Language Processing, pages658?666, Chiang Mai, Thailand, November.Helmut Schmid.
1994.
Probabilistic Part-of-Speech Tag-ging Using Decision Trees.
In Proceedings of the In-ternational Conference on New Methods in LanguageProcessing, pages 44?49, Manchester, UK.Lucia Specia, Baskaran Sankaran, and Maria DasGrac?as Volpe Nunes.
2008. n-Best Reranking for theEfficient Integration of Word Sense Disambiguationand Statistical Machine Translation.
In Proceedings ofthe 9th international conference on Computational lin-guistics and intelligent text processing, CICLing?08,pages 399?410, Berlin, Heidelberg.
Springer-Verlag.Lucia Specia.
2006.
A Hybrid Relational Approach forWSD - First Results.
In Proceedings of the COL-ING/ACL 2006 Student Research Workshop, pages 55?60, Sydney, Australia.David Vickrey, Luke Biewald, Marc Teyssier, andDaphne Koller.
2005.
Word-Sense Disambiguationfor Machine Translation.
In Proceedings of the JointConference on Human Language Technology / Empir-ical Methods in Natural Language Processing (HLT-EMNLP), pages 771?778, Vancouver, Canada.9
