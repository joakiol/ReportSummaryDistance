Proceedings of the Second Workshop on Hybrid Approaches to Translation, pages 42?50,Sofia, Bulgaria, August 8, 2013. c?2013 Association for Computational LinguisticsAn English-to-Hungarian Morpheme-based Statistical MachineTranslation System with Reordering RulesLa?szlo?
J. Laki, Attila Nova?k, Borba?la Siklo?siMTA-PPKE Language Technology Research GroupPa?zma?ny Pe?ter Catholic University, Faculty of Information Technology50/a Pra?ter Street, 1083 Budapest, Hungary{surname.firstname}@itk.ppke.huAbstractPhrase-based statistical machine transla-tion systems can generate translations ofreasonable quality in the case of languagepairs with similar structure and word or-der.
However, if the languages are moredistant from a grammatical point of view,the quality of translations is much behindthe expectations, since the baseline trans-lation system cannot cope with long dis-tance reordering of words and the mappingof word internal grammatical structures.In our paper, we present a method that triesto overcome these problems in the case ofEnglish-Hungarian translation by apply-ing reordering rules prior to the translationprocess and by creating morpheme-basedand factored models.
Although automaticevaluation scores do not reliably reflect theimprovement in all cases, human evalua-tion of our systems shows that readabil-ity and accuracy of the translations wereimproved both by reordering and applyingricher models.1 IntroductionPhrase-based statistical machine translation sys-tems rely on statistical observations derived fromphrase alignments automatically extracted fromparallel bilingual corpora.
The main advantage ofapplying SMT is its language-independence.
Thephrase-based model works well for language pairswith similar syntactic structure and word order.However, phrase-based models fail to handlegreat word-order differences adequately.
We de-scribe our attempt to improve performance bytransforming source language (English) sentencesto a structure similar to that of the correspondingtarget (Hungarian) sentence.
We also describe ourapproach for handling data sparseness due to theinadequate coverage of linguistic structures by thelimited training corpus.
It is a common problem inthe case of translation to agglutinating languageslike Hungarian, where a much greater amount oftraining data would be necessary to provide ade-quate statistics than what is necessary for closelyrelated language pairs involving only morphologi-cally less complex languages.2 Machine Translation from English toHungarianEnglish and Hungarian are rather distant regardingmorphological and syntactic structure and wordorder.
Hungarian, like Finish or Turkish, is anagglutinating and compounding language, whichmorphological processes yield a huge number ofdifferent word forms.
This, combined with freeword order of main grammatical constituents andsystematically different word order in NP?s andPP?s, results in poor performance of traditionalphrase-based SMT systems.
In order to have anSMT system produce correct translations of highquality, it is required to have a relevant statisti-cal model acquired from bilingual corpora.
Thus,even if a corpus of a substantial size were available(which is not the case), both the alignment phaseof constructing a translation model and translationitself would be compromised by the high numberof seldom or never seen word forms.3 Related workFor language pairs having very different syntacticstructure and word order, research has shifted to-wards using hierarchical models or the use of hy-brid methods, such as augmenting purely statisti-cal approaches by handmade rules as a preprocess-ing step.
Such extensions have proved to improveresults significantly in systems translating fromEnglish to German, Arabic or Turkish and severalother languages (Yeniterzi and Oflazer, 2010; Go-42jun and Fraser, 2012; Collins et al 2005).
Thehybrid models applied to English-Hungarian ma-chine translation that we present in this paper be-long to the latter line of research.We applied both reordering and morphologicalsegmentation in order to handle both word orderproblems and data sparseness caused by agglu-tination.
Luong et al(2010) applied only mor-phological analysis in the case of translation fromEnglish to Finnish.
On the other hand, Yeniterziand Oflazer (2010) described an approach for En-glish to Turkish translation, in which they appliedboth syntactic source-side reordering and morpho-logical segmentation.
In their work, morphemesconstructing a single word were joined during thetranslation process, but in our experiments, thismethod increased data sparseness in the trainingset, decreasing the quality of the final translationrather than improving it.
Another difference be-tween Yeniterzi and Oflazer (2010)?s and our workis that they applied the morphological generatorintegrated in the SMT system, while we used ourcomputational morphology on SMT output as aword form generator, generating final word formsin cases, where the SMT system was not able tofind it.Relying on recent trends and results of researchin the field of machine translation, we believe thatneither a purely rule-based nor a statistical methodby itself is an optimal way to handle the problem.Our work reflects this attitude by applying hand-made language-specific rules.
Some works, suchas (Jiang et al 2010; Holmqvist et al 2012; Gen-zel, 2010) have also tried deriving such reorderingrules automatically.A further method to apply would be using a hi-erarchical tree-based translation system, also aug-mented by reordering rules and morphologicalsegmentation.
Such a method is presented in (Gaoet al 2011), but focusing on a narrower problemand applying it to Chinese to English translation.4 Hybrid morpheme-based machinetranslation system with reorderingrulesIn order to mitigate the aforementioned difficultiesregarding word order and data sparseness, we cre-ated a hybrid system with different preprocessingand decoding solutions.
First we applied reorder-ing rules in order to transform the source sentenceto a structure more appropriate for word alignmentTest Train# of sentences 1000 1,026,836Words(AVG per sent.
)en 14.137 14.173hu 11.672 11.764Morphemes(AVG per sent.
)en 16.764 16.768hu 18.391 18.429Table 1: Size of training and test datasets mea-sured in the number of sentences, average numberof words per sentences and the average number ofmorphemes per sentences on the English and Hun-garian sides.and phrase extraction.
The problem of lexicalgranularity (i.e.
the relatively substantial differ-ence in the number of words in the correspondingsentences, see Table 1) was also to be solved.
Weexplored two approaches: a) increasing the num-ber of tokens on both sides using morphemes in-stead of words and b) decreasing the number ofword tokens on the English side to approximatethat of the corresponding Hungarian sentences.4.1 Reordering rulesIn order to augment the phrase-based SMT sys-tem, we defined reordering rules as a preprocess-ing step.
The goal of these transformations is tomove words in the English source sentence to po-sitions that correspond to their place in the Hun-garian translation.
Fig.
1 illustrates the trans-formation process on the phrase the sons of themany merchants living in the city.
E.g., the sub-phrase living in the city is transformed to the orderthe city in living corresponding to the Hungariantranslation ?a va?ros+ban e?lo??
as shown in Fig.
1a.Our rules apply only to those word order differ-ences, which are systematically present betweenthe two grammars (e.g.
prepositions vs. case end-ings/postpositions).
We did not intend to handlefree word order variations of Hungarian, where thesame meaning can be expressed with several dif-ferent orderings, since the actual word order in asentence is not only determined by syntactic rules,but also by pragmatic factors.Dependency structure: Reordering rules areguided by dependency relations.
After generat-ing a context-free parse, these relations are ex-tracted by the Stanford parser (Marneffe et al2006) that we used in our experiments.
The depen-dency structure of our example is shown in Fig.
1b.Thus the example phrase merchants living inthe city is transformed along the relations PART-43(a) Word alignment of a sentence pair before and after reorder-ing(b) Dependency structure of the sentence: The sons of the manymerchants living in the city(c) The process of reordering along dependency relations.Figure 1: Word alignment, dependency relations and reorderingMOD(merchant, living)1, PREP(living, in)1 andPOBJ(in, city)1.
First the preposition is attachedto the child of the POBJ relation, then they arepositioned before the noun phrase preceding it asshown in Fig.
1c.
The resulting word order the cityin living merchants corresponds to the Hungarianstructure ?a va?ros+ban e?lo?
kereskedo?k?.Since these levels of analysis depend on eachother, errors arising at each phase propagate andcumulate through the whole process having a sig-nificant effect on reordering.
Even though weused the lexicalized version of the Stanford parser,which is reported to work more accurately, itstill very often generates agrammatical parses withagreement errors and odd PoS sequences as shownin Table 2 (showing only the generated PoS tag se-quences here).1PARTMOD=participial modifier, PREP=prepositionalmodifier, POBJ=object of preposition.
The fulllist of dependency relations can be found inhttp://nlp.stanford.edu/software/dependencies_manual.pdf-/: 100/CD million/CD sound/NN good/JJto/TO me/PRP ./.For/IN airline/NN personnel/NNS ,/, we/PRPcash/NN personal/JJ checks/VBZ up/RPto/TO $/$ 100/CD ./.Table 2: Examples of low level errors (verbstagged as nouns and vice versa) that affect reorder-ing and translationMorpheme-based restructuring: Due to theagglutinating nature of Hungarian, many func-tion words in English are expressed as suffixesin the Hungarian translation.
In order to enablethe phrase-based system to have them correspondto each other, we applied morphological analy-sis on the Hungarian sentences segmenting eachword to their morphological constituents.
To an-notate the Hungarian side of the corpus, we usedthe PurePos automated morphological annotationsystem (Orosz and Nova?k, 2012).
A simple ex-ample is a phrase like in my house, which is44transformed to the form house my in correspond-ing to the single word ?ha?zamban?
in Hungarian.The morphological segmentation of this word isha?z[N]+am[PxS1]+ban[Ine]1.
Defining and ap-plying the rules for such short phrases is not partic-ularly difficult.
However, related words in longersentences can be much further separated from eachother and they may be involved in more than onerelation, which often results in an interaction ofword order constraints.
In a similar manner, somerules insert morphological elements correspond-ing to those present in the Hungarian sentence,but not explicitly expressed in English, such asthe accusative case suffix or subject agreement ofverbs.
These pieces of implicit structural informa-tion can be induced from the dependency relations.For example, in the English phrase giving/VBGa/DT present/NN, the word present is tagged asacc (based on its object role) corresponding to theHungarian accusative -t suffix resulting in the re-ordered phrase of giving a present+acc now per-fectly aligning to the Hungarian structure of ?adniegy aja?nde?k+ot?4.2 Lexical granularityThe number of words is often rather different in apair of Hungarian and English sentences enforcingthe alignment module of the SMT system to cre-ate one-to-many or many-to-many alignments, orsimply leave tokens unaligned.
Such alignmentsoften result in missing or ?hallucinated?
words inthe translation.
Table 1 shows the differences inthe average number of words and morphemes inour parallel corpus.
The average number of wordsis smaller in Hungarian than in the English sen-tences.
On the other hand, at least at the granu-larity of the morphological analysis we applied toour data, the number of morphemes is higher inHungarian than in English.
The number of tokenson both sides can be made more similar by eitherdecreasing the number of words on the Englishside by joining function words corresponding toHungarian suffixes or by increasing the number onboth sides using morphemes as tokens.As the difference is primarily due to the factthat some English function words are representedas suffixes in Hungarian, the relative differencebetween the number of morphemes in the cor-responding sentences is lower than that of thewords.
So one possible approach to solving the1PxS1=Possessor:1Sg=?my?, Ine=Inessive=?in?lexical granularity difference problem is to usemorphemes instead of words.
One problem withmorpheme-based translation is that it is often thecase in longer sentences that instances of the samefunctional morpheme belong to more than one dif-ferent word in the sentence.
This causes inde-terminacies in the alignment process (because themodels implemented in the Giza++ word alignercannot be forced to assume locally monotonealignment at the places where we in fact know thatthe alignment should be monotone), which oftenresults in erroneous phrases being extracted fromthe training corpus.
For example, if there are twonouns in a sentence and one of them is plural, thenthe [PL] tag corresponding to this feature mightland at another noun.The difficulty of aligning very frequent func-tional morphemes is illustrated by the fact thatin the Giza++ alignments created from our train-ing corpus, 39% of the nominal plural ([PL])morphemes remained unaligned, 13% was not at-tached to the noun it should have been attached to,because the alignment was not monotone, while1% was aligned to several (up to eight) instancesof the corresponding morpheme.
Alignment is notthe only problem: some indivisible morpheme se-quences (like noun+plural) should always stay to-gether but we had concerns that, unless it is con-strained to monotone decoding, the baseline dis-tortion model of the decoder will often scatter suf-fixes throughout the sentence instead.
A lexical-ized reordering model can be expected to solvethis problem, thus we used lexical reordering inour models but for comparison we also tested howeach model performs when the decoder is con-strained to monotone decoding.Another approach we tested was fusing sepa-rate words on the English side that correspond toa single word in the Hungarian sentence (model-ing English as an agglutinating language) to avoidthe aligner connecting these morphemes to someother words on the Hungarian side and using afactored model to try to solve the data sparse-ness issues this move results in.
For example,possessive determiners are attached to the headnoun as suffixes in this model like the correspond-ing possessive suffixes in Hungarian : the phrasemy/PRP$ own/JJ mother/NN is transformed to theform own/JJ mother/NN my/PRP$, which corre-sponds to the Hungarian phrase saja?t anya?
m.By applying either of the morpheme-token-45based or the factored morphosyntactic-feature-based solution, the translations generated by theSMT system contain sequences of lemmas andmorphosyntactic tags, thus, in order to get the fi-nal form of the translated sentence, the surfaceform of the words have to be generated from themorpheme sequence.
In our experiments, we ap-plied the word form generator module of the Hu-mor morphological analyzer to the output of thedecoder (Nova?k, 2003; Pro?sze?ky and Kis, 1999).4.3 Factored translationThe Moses SMT toolkit (Koehn et al 2007),which we used in our experiments, is suitable forimplementing factored translation models.
Insteadof relying on just the surface form of the words,further annotations such as morphological analy-sis can be used in the process of a factored trans-lation.
Translation factors might be the surfaceform of each word, its lemma, its main PoS tagand its morphosyntactic features.
During factoredtranslation, there is an opportunity to use multipletranslation models, generation models or contex-tual language models.
Since the system has thepossibility to use any combination of these, in the-ory it is able to generate better translations usingsparse linguistic data than a word-based baselinesystem.
This feature is vital in cases where someabstraction is necessary, because some words inthe sentence to be translated or generated are miss-ing from the training set.To see how well a factored model performs inthe case of translation to an agglutinating lan-guage, we also trained a factored translation sys-tem combined with our reordering rules.
The fac-tors in our case were of the form: lemma/PoS |PoS+morphtags, where PoS is the main part-of-speech tag and morphtags are the rest of themorphological features and extra morphemes at-tached to the word as described in Section 4.2.Training the system with this combination of fac-tors to handle data sparseness issues seems reason-able in theory; however, translation of lexical andgrammatical factors is compromised by a seriousweakness of the factored translation implementa-tion in Moses.
If the two factors are treated as con-nected at training time, then if a certain combina-tion of a lemma and its morphology is not presentin the translation models, which is very frequent inthe case of an agglutinating language, then it cannot be translated even if both the lemma and themorphological feature set are represented in thetraining corpus separately.
In such cases none ofthe factors are translated and the source word iscopied to the output untranslated.Another method of training a factored model isto translate factors independently.
This could in-deed solve data sparseness problems, but, as wenoted during our experiments, another problemarises in this case: at translation time, translationsof morphological tags often land at wrong lem-mas.
This is due to the fact when translating aphrase, the system selects a translation having oneword order, e.g.
[Det N V], for one factor (the lem-mas) and another, e.g.
[V Det N] for the other (themorphosyntactic tags).
This results in ill-formedstructures, such as nominal morphosyntactic fea-tures landing on verbs and verbal morphosyntac-tic features landing on nouns etc., thus, althoughthe translation might contain the relevant transla-tions regarding both lemmas and morphologicalfeatures, the final sentence will be an inconsistentmixture of them, making generation of the rightword forms impossible.
Due to word order vari-ations in Hungarian, this situation turned out tobe rather frequent, affecting 21% of our 1000 testsentences.In order to improve translations compromisedby inconsistent mapping of lemmas and morphol-ogy, we introduced a postprocessing step extract-ing and restoring the proper positions of the mor-phological tags in the result of factored transla-tions.
Relying on the alignment information, theproper position of each morphological tag in thesequence can be found.
At translation time, Mosescan output which source words each target phrasewas translated from.
We introduced two auxil-iary factors to the phrase table that represent align-ments of our two main factors.
If the alignments inthe two factors mismatch, we can realign them us-ing the auxiliary alignment factors (using the wordorder in the lemma factor as pivot).
Once havingthe factors rematched, the two factors of the targettranslation are unified and the morphological gen-erator can be applied to generate the final wordforms.
As it is evident from the evaluation datapresented in Section 5, the realignment of factorsconsistently improved the quality of translationsproduced by all factored models.465 Experiments and resultsWe performed experiments on word-based,morpheme-based and factored translations fromEnglish to Hungarian with and without applyingour reordering rules as a preprocessing step.
Wealso contrasted the performance of our experi-mental systems with that of some commercialsystems: the rule-based MetaMorpho (Nova?ket al 2008; Nova?k, 2009) and the major com-mercial translation services, Google Translateand Bing Translator, which apply their languageindependent statistical systems trained on hugeparallel corpora.
Low BLEU scores of translationsgenerated by these systems (compared to thoseusually obtained for other languages) indicatethat machine translation to Hungarian is indeed adifficult task.In all of our experiments, the Moses (Koehn etal., 2007) toolkit was used for building the trans-lation models and performing the translation taskitself, using IRSTLM (Federico et al 2008) tobuild language models.
Wherever it was neces-sary, PurePos (Orosz and Nova?k, 2012) was usedfor morphological analysis and generation, and theStanford Parser (Marneffe et al 2006) for con-stituent and dependency parsing.5.1 DatasetsAs training data, we used the Hunglish (Varga etal., 2005) corpus, created by BME MOKK2 andthe Research Institute for Linguistics of the Hun-garian Academy of Sciences.
This corpus containsparallel texts from the following domains: litera-ture and magazines, legal texts and movie subti-tles.
There is a great degree of variation in thequality of different parts of the corpus.
We auto-matically eliminated sentence pairs from the cor-pus that caused technical problems, but overalltranslation quality was not checked.The corpus we used for training the sys-tem consists of 1,026,836 parallel sentenceswith 14,553,765 words on the English side and12,079,557 on the Hungarian side.
For testing pur-poses, a 1000-sentence-long portion was selectedfrom the same corpus with one reference transla-tion.
Automatic evaluation was performed on thisset using the BLEU evaluation metric.
Results foreach system are listed in Table 3.2MOKK Centre for Media Research and Education atthe Department of Sociology and Communication, BudapestUniversity of Technology and Economics5.2 Baseline systemsWe built a word-based, a morpheme-based, and afactored baseline system (featured as w, m and f inTable 3), not using the reordering rules describedin Section 4.1, each trained using Moses.For the word-based baseline model w, the onlypreprocessing we applied was standard tokeniza-tion and lowercasing.
A phrase table with a phraselength limit of 7 was extracted, and a 5-gram lan-guage model was built.
A lexicalized reorderingmodel with a distortion limit of 6 was used in thisbaseline model (and all other models with non-monotone decoding).We evaluated this system using two automaticmetrics: the usual word-based BLEU (w-BLEU)and, in order to have a relevant base of compari-son to the other systems, a morpheme-based score(mm-BLEU), which in the case of the word-basedbaseline was computed applying morphologicalanalysis to the translations.
mm-BLEU is based oncounts of identical abstract morpheme sequencesin the generated and the reference translations in-stead of identical word sequences.
Note that thisdiffers from m-BLEU as used in e.g.
(Clifton andSarkar, 2011), which is BLEU applied to pseudo-morphs generated by an unsupervised segmenter.mm-BLEU measures the ability of the system togenerate the correct morphemes in the transla-tions.The second baseline system m was trained onmorphologically segmented sentences, thus theoutput of the decoder is a sequence of morphemes.A BLEU score computed on the output of the de-coder in this case is mm-BLEU.
The morpholog-ical generator was applied to the output of theMoses decoder in order to acquire the final wordforms.
The morpheme-based system m performedbetter in terms of mm-BLEU, although it got alower w-BLEU score.The third, factored baseline model f was outper-formed by the two other models both in terms ofw-BLEU and mm-BLEU, even when the problemcaused by a different word order in the factors wasfixed as described in Section 4.3 (the system fx).5.3 Reordered modelsBased on considerations described in Sections 4.1and 4.2, we performed reordering as a prepro-cessing step both at training and translation time.Models using this configuration were also evalu-ated applying the same w-BLEU and mm-BLEU47ID w-BLEU mm-BLEUw-based baseline (w) 14.57% 59.32%m-based baseline mon.
(mm) 11.69% 63.18%m-based baseline (m) 12.19% 63.87%factored baseline monotone(fm)9.70% 56.00%factored baseline mon.
fixed(fmx)9.84% 57.09%w-based reord.
(wre) 14.83% 58.06%w-based reord.
joined (wre ) 13.05% 57.21%m-based reord.
mon.
(mrem) 12.01% 64.24%m-based reord.
(mre) 12.22% 64.94%fact.
reord.
mon.
(frem) 10.50% 59.56%fact.
reord.
mon.
fixed(fremx)10.64% 60.28%fact.
reord.
(fre) 10.78% 59.97%fact.
reord.
fixed (frex) 10.88% 60.83%Google Translate (goo) 15.68% 55.86%Bing Translator (bing) 12.16% 53.05%MetaMorpho (mmo) 6.86% 50.97%Table 3: Automatic evaluation scores for systemstested in the experiments.metrics.
We implemented various morpheme-based, factored and word-based reordered mod-els.
The two word-based setups performed thesame transformations moving function words, thedifference between the two was only whether themoved words were kept as distinct words (wre) orjoined to the target word as suffixes to form a sin-gle word form (wre ).
The models allowed furtherreordering during decoding using a lexicalized re-ordering model.The morpheme-based (mre) and the factoredmodels (fre and frex, the latter with factor mis-alignment fixed) were contrasted with alterna-tive setups where the decoder was constrainedto monotone decoding (mrem, frem, fremx).
Wehad concerns that in the case of the morpheme-based model the decoder might move suffixes toincorrect positions.
However, using a lexicalizedreordering model prevented these problems andthe systems with reordering during decoding per-formed consistently better.
Monotone decodingblocked the decoder from fixing word order in thepreverbal field of the comment part of Hungariansentences, where strict word order constraints ap-ply in contrast to the free word order of the topicand the postverbal part of the comment.
While ourreordering rules did not capture these constraintsdepending on various subtle features of the actu-ally selected translation that cannot be reliably in-ferred from the English original, the lexically con-strained reordering performed by the decoder didmanage to generate translations that conformed tothem at least to some extent.The results presented in Table 3 show that thereordered wre, mre and frex models obtained con-sistently higher BLEU scores than the correspond-ing baseline models (the only exception being themm-BLEU score of the wre model).
Althoughthe BLEU scores do not show this clearly, thetranslations generated by the wre model are farworse than the output of any other system due toa high number of untranslated ?agglutinating En-glish?
words with function words attached to con-tent words as suffixes.Figure 4 shows the translation results of our dif-ferent systems.
As it can be seen, mre performedthe best, regarding fluency and reflecting the orig-inal meaning.6 Human evaluationIt has been shown that system rankings based onsingle reference BLEU scores often do not cor-respond to how humans evaluate the translations.For this reason, automatic evaluation has for along time not been used to officially rank systemsat Workshops on Statistical Machine Translation(WMT) (Callison-Burch et al 2007).
In our work,we presented results of automated evaluation us-ing a single reference BLEU metrics, but we alsoinvestigated translations generated by each sys-tem using human evaluation, applying the rankingscheme used at WMT workshops to officially ranksystems.300 sentences were randomly chosen from thetest set for the purpose of human evaluation.Five annotators evaluated translations generatedby each of the above described systems plus thereference translation in the corpus with regard totranslation quality (considering both adequacy andfluency in a single quality ranking).
The order oftranslations was randomized for each sentence anda balanced number of comparisons was performedfor each system pair.
The systems were rankedbased on a score that was defined as the numberof times the output of a system was deemed notworse than that of the other in pairwise compar-isons divided by the number of pairwise compar-isons.
The aggregate results of human evaluationare listed in Table 5.Manual investigation of the translation outputsrevealed that the system incorporating morpholog-ical and syntactic information are better at captur-ing grammatical relations in the original text andrendering them in the translation by generating the48original English After you were picked up at sea , our listening post in Malta intercepted that fax .reordered English after/[IN] you/[PRP] be/[VB] [Past] pick/[VB] [PPart] up/[RP] at/[IN] sea/[NN] ,/[,]our/[PRP$] listen/[VB] [ING] post/[NN] in/[IN] malta/[NNP] intercept/[VB] [PPart] that/[DT]fax/[NN] ./[.
]morpheme basedtranslationmiuta?n/[KOT] felvesz/[IGE] [Past] [t3] [Def] maga/[FN NM] [e3] [ACC] a/[DET] tenger/[FN][SUP] ,/[PUNCT] hallgat/[IGE] [Past] [e3] [Def] a/[DET] hely/[FN] [PSt1] ,/[PUNCT]hogy/[KOT] ma?lta/[FN] [INE] a?ll/[IGE] [Past] [e3] [Def] ez/[FN NM] [ACC] a/[DET] fax/[FN][ACC] ./[PUNCT]final translation Miuta?n felvette?k maga?t a tengeren , hallgatta a helyu?nk , hogy ma?lta a?llta ezt a faxot .back-translation After you were picked up at sea, our listening post caught the fax in Malta.baseline translation Azuta?n , hogy felvette a tengeren , a ma?ltai hallgatta az emelkedo?
, hogy fax .back-translation After you, he picked it up at the sea, and that Malta were caught, that it is a fax.Hungarian reference Miuta?n o?nt kihala?szta?k , ezt fogta?k el egy ma?ltai posta?n .back-translation After you were fished out, this was caught at a post in Malta.Table 4: Translation results of our systems with hand made backtranslations for comparison with thereference.ref mmo goo bing mre frex m fx w wre wre88.33 76.30 72.80 61.66 55.60 55.42 54.28 52.03 51.33 50.89 37.57Table 5: Human evaluation ranking of systems measured as percentage of generating a translation notworse than the other in pairwise comparisonsappropriate inflected forms.
Rule-based reorder-ing also improved quality when using linguisti-cally rich models.
The only ones that performedworse than the baseline were the word-based re-ordered solutions, especially the one based on?agglutinating English?, the poor performance ofwhich came as no surprise.
BLEU scores do notcorrespond well to human judgments.
Of ourmodels, the wre system had the highest BLEUscore, however, human evaluation ranked thatworse than any of the morpheme-based systems.Moreover, MetaMorpho, the commercial systemhaving highest rank had by far the lowest BLEUscore.Considering all the systems in the ranking pro-cedure, it can be observed that the reference trans-lation used also for measuring BLEU score doesnot always represent the best translation eitheraccording to our evaluators.
It is worth not-ing though that there was a rather significantvariance in the ranking of reference translationsdue to some evaluators ranking them much lessfavourably than others (75.29% vs. 92.98%).7 ConclusionWe performed several experiments on English-Hungarian machine translation.
Automatic eval-uation consistently scored models including rule-based reordering higher than systems not includ-ing it.
Human evaluation confirmed that applyingreordering and morphological segmentation doesimprove translation quality in the case of translat-ing to an agglutinating language like Hungarian.Our models are not yet on par with commer-cial systems.
The rather limited amount of train-ing corpus that also has serious quality problemsis certainly one factor playing a role in this.
Ourfuture plans include enlarging and improving ourtraining corpus, improving alignment and compo-nents of the syntactic annotation and reorderingchain as well as experimenting with combinationof morpheme-based and factored models.AcknowledgementThis work was partially supported by TA?MOP ?4.2.1.B ?
11/2/KMR-2011-0002 and TA?MOP ?4.2.2./B ?
10/1-2010-0014.ReferencesChris Callison-Burch, Cameron Fordyce, PhilippKoehn, Christof Monz, and Josh Schroeder.
2007.
(Meta-)evaluation of machine translation.
In Pro-ceedings of the Second Workshop on StatisticalMachine Translation, StatMT ?07, pages 136?158,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Ann Clifton and Anoop Sarkar.
2011.
Combin-ing morpheme-based machine translation with post-processing morpheme prediction.
In Proceedings ofthe 49th Annual Meeting of the Association for Com-putational Linguistics: Human Language Technolo-gies - Volume 1, HLT ?11, pages 32?42, Stroudsburg,49PA, USA.
Association for Computational Linguis-tics.Michael Collins, Philipp Koehn, and Ivona Kuc?erova?.2005.
Clause restructuring for statistical machinetranslation.
In Proceedings of the 43rd AnnualMeeting on Association for Computational Linguis-tics, ACL ?05, pages 531?540, Stroudsburg, PA,USA.
Association for Computational Linguistics.Marcello Federico, Nicola Bertoldi, and Mauro Cet-tolo.
2008.
Irstlm: an open source toolkit forhandling large scale language models.
In INTER-SPEECH, pages 1618?1621.Yang Gao, Philipp Koehn, and Alexandra Birch.
2011.Soft dependency constraints for reordering in hier-archical Phrase-Based translation.
In Proceedingsof the 2011 Conference on Empirical Methods inNatural Language Processing, pages 857?868, Ed-inburgh, Scotland, UK., jul.
Association for Compu-tational Linguistics.Dmitriy Genzel.
2010.
Automatically learning source-side reordering rules for large scale machine transla-tion.
In COLING, pages 376?384.Anita Gojun and Alexander Fraser.
2012.
Determin-ing the placement of German verbs in English-to-German SMT.
In Walter Daelemans, Mirella La-pata, and Llus Mrquez, editors, EACL, pages 726?735.
The Association for Computer Linguistics.Hieu Hoang.
2007.
Factored translation models.
InIn Proceedings of the 2007 Joint Conference onEmpirical Methods in Natural Language Process-ing and Computational Natural Language Learning(EMNLP-CoNLL, pages 868?876.Maria Holmqvist, Sara Stymne, Lars Ahrenberg, andMagnus Merkel.
2012.
Alignment-based reorderingfor SMT.
In Nicoletta Calzolari (Conference Chair)et al editor, Proceedings of the Eight InternationalConference on Language Resources and Evaluation(LREC?12), Istanbul, Turkey, may.
European Lan-guage Resources Association (ELRA).Jie Jiang, Jinhua Du, and Andy Way.
2010.
Source-side syntactic reordering patterns with functionalwords for improved phrase-based SMT.
In Pro-ceedings of SSST-4, Fourth Workshop on Syntax andStructure in Statistical Translation, pages 19?27,Beijing.P.
Koehn, H. Hoang, A. Birch, C. Callison-Burch,M.
Federico, N. Bertoldi, B. Cowan, W. Shen,C.
Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,and E. Herbst.
2007.
Moses: Open Source Toolkitfor Statistical Machine Translation.
In Proceed-ings of the ACL 2007 Demo and Poster Sessions,pages 177?180, Prague.
Association for Computa-tional Linguistics.Minh-Thang Luong, Preslav Nakov, and Min-Yen Kan.2010.
A hybrid morpheme-word representation formachine translation of morphologically rich lan-guages.
In Proceedings of the 2010 Conference onEmpirical Methods in Natural Language Process-ing, EMNLP ?10, pages 148?157, Stroudsburg, PA,USA.
Association for Computational Linguistics.Marie-Catherine De Marneffe, Bill Maccartney, andChristopher D. Manning.
2006.
Generating typeddependency parses from phrase structure parses.
InIn LREC 2006.Attila Nova?k, La?szlo?
Tihanyi, and Ga?bor Pro?sze?ky.2008.
The MetaMorpho translation system.
InProceedings of the Third Workshop on StatisticalMachine Translation, StatMT ?08, pages 111?114,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Attila Nova?k.
2003.
What is good Humor like?In I. Magyar Sza?mto?ge?pes Nyelve?szeti Konferencia,pages 138?144, Szeged.
SZTE.Attila Nova?k.
2009.
MorphoLogic?s submission forthe WMT 2009 Shared Task.
In Proceedings of theFourth Workshop on Statistical Machine Translationat EACL 2009, Athens, Greece.Gyo?rgy Orosz and Attila Nova?k.
2012.
PurePos ?
anopen source morphological disambiguator.
In Pro-ceedings of the 9th International Workshop on Nat-ural Language Processing and Cognitive Science.,Wroclaw, Poland.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a method for automaticevaluation of machine translation.
In Proceedingsof the 40th Annual Meeting on Association for Com-putational Linguistics, ACL ?02, pages 311?318,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Ga?bor Pro?sze?ky and Bala?zs Kis.
1999.
A unification-based approach to morpho-syntactic parsing of ag-glutinative and other (highly) inflectional languages.In Proceedings of the 37th annual meeting of theAssociation for Computational Linguistics on Com-putational Linguistics, ACL ?99, pages 261?268,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.D.
Varga, L. Ne?meth, P. Hala?csy, A. Kornai, V. Tro?n,and V. Nagy.
2005.
Parallel corpora for mediumdensity languages.
In Recent Advances in NaturalLanguage Processing (RANLP 2005), pages 590?596.Reyyan Yeniterzi and Kemal Oflazer.
2010.
Syntax-to-morphology mapping in factored phrase-based sta-tistical machine translation from English to Turkish.In Proceedings of the 48th Annual Meeting of the As-sociation for Computational Linguistics, ACL ?10,pages 454?464, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.50
