Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 99?105,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsAutomatic Detection of Cognates Using Orthographic AlignmentAlina Maria Ciobanu, Liviu P. DinuFaculty of Mathematics and Computer Science, University of BucharestCenter for Computational Linguistics, University of Bucharestalina.ciobanu@my.fmi.unibuc.ro,ldinu@fmi.unibuc.roAbstractWords undergo various changes when en-tering new languages.
Based on the as-sumption that these linguistic changes fol-low certain rules, we propose a methodfor automatically detecting pairs of cog-nates employing an orthographic align-ment method which proved relevant for se-quence alignment in computational biol-ogy.
We use aligned subsequences as fea-tures for machine learning algorithms inorder to infer rules for linguistic changesundergone by words when entering newlanguages and to discriminate betweencognates and non-cognates.
Given a listof known cognates, our approach does notrequire any other linguistic information.However, it can be customized to integratehistorical information regarding languageevolution.1 IntroductionCognates are words in different languages havingthe same etymology and a common ancestor.
In-vestigating pairs of cognates is very useful in his-torical and comparative linguistics, in the studyof language relatedness (Ng et al, 2010), phy-logenetic inference (Atkinson et al, 2005) andin identifying how and to what extent languageschange over time.
In other several research ar-eas, such as language acquisition, bilingual wordrecognition (Dijkstra et al, 2012), corpus lin-guistics (Simard et al, 1992), cross-lingual infor-mation retrieval (Buckley et al, 1997) and ma-chine translation (Kondrak et al, 2003), the con-dition of common etymology is usually not essen-tial and cognates are regarded as words with highcross-lingual meaning and orthographic or pho-netic similarity.The wide range of applications in which cog-nates prove useful attracted more and more at-tention on methods for detecting such relatedpairs of words.
This task is most challengingfor resource-poor languages, for which etymologi-cally related information is not accessible.
There-fore, the research (Inkpen et al, 2005; Mulloni andPekar, 2006; Hauer and Kondrak, 2011) focusedon automatic identification of cognate pairs, start-ing from lists of known cognates.In this paper, we propose a method for automat-ically determining pairs of cognates across lan-guages.
The proposed method requires a list ofknown cognates and, for languages for which ad-ditional linguistic information is available, it canbe customized to integrate historical informationregarding the evolution of the language.
The restof the paper is organized as follows: in Section2 we present and analyze alternative methods andrelated work in this area.
In Section 3 we intro-duce our approach for detection of cognates us-ing orthographic alignment.
In Section 4 we de-scribe the experiments we conduct and we reportand analyze the results, together with a compari-son with previous methods.
Finally, in Section 5we draw the conclusions of our study and describeour plans for extending the method.2 Related WorkThere are three important aspects widely investi-gated in the task of cognate identification: seman-tic, phonetic and orthographic similarity.
Theywere employed both individually (Simard et al,1992; Inkpen et al, 2005; Church, 1993) and com-bined (Kondrak, 2004; Steiner et al, 2011) in or-der to detect pairs of cognates across languages.For determining semantic similarity, external lexi-cal resources, such as WordNet (Fellbaum, 1998),or large corpora, might be necessary.
For measur-ing phonetic and orthographic proximity of cog-nate candidates, string similarity metrics can beapplied, using the phonetic or orthographic wordforms as input.
Various measures were investi-99gated and compared (Inkpen et al, 2005; Hall andKlein, 2010); Levenshtein distance (Levenshtein,1965), XDice (Brew and McKelvie, 1996) andthe longest common subsequence ratio (Melamed,1995) are among the most frequently used metricsin this field.
Gomes and Lopes (2011) proposedSpSim, a more complex method for computing thesimilarity of cognate pairs which tolerates learnedtransitions between words.Algorithms for string alignment were success-fully used for identifying cognates based on boththeir forms, orthographic and phonetic.
Delmestriand Cristianini (2010) used basic sequence align-ment algorithms (Needleman and Wunsch, 1970;Smith and Waterman, 1981; Gotoh, 1982) to ob-tain orthographic alignment scores for cognatecandidates.
Kondrak (2000) developed the ALINEsystem, which aligns words?
phonetic transcrip-tions based on multiple phonetic features and com-putes similarity scores using dynamic program-ming.
List (2012) proposed a framework for au-tomatic detection of cognate pairs, LexStat, whichcombines different approaches to sequence com-parison and alignment derived from those used inhistorical linguistics and evolutionary biology.The changes undergone by words when enter-ing from one language into another and the trans-formation rules they follow have been successfullyemployed in various approaches to cognate detec-tion (Koehn and Knight, 2000; Mulloni and Pekar,2006; Navlea and Todirascu, 2011).
These ortho-graphic changes have also been used in cognateproduction, which is closely related to the task ofcognate detection, but has not yet been as inten-sively studied.
While the purpose of cognate de-tection is to determine whether two given wordsform a cognate pair, the aim of cognate produc-tion is, given a word in a source language, toautomatically produce its cognate pair in a tar-get language.
Beinborn et al (2013) proposed amethod for cognate production relying on statis-tical character-based machine translation, learn-ing orthographic production patterns, and Mul-loni (2007) introduced an algorithm for cognateproduction based on edit distance alignment andthe identification of orthographic cues when wordsenter a new language.3 Our ApproachAlthough there are multiple aspects that are rel-evant in the study of language relatedness, suchas orthographic, phonetic, syntactic and semanticdifferences, in this paper we focus only on lexicalevidence.
The orthographic approach relies on theidea that sound changes leave traces in the orthog-raphy and alphabetic character correspondencesrepresent, to a fairly large extent, sound correspon-dences (Delmestri and Cristianini, 2010).Words undergo various changes when enteringnew languages.
We assume that rules for adaptingforeign words to the orthographic system of thetarget languages might not have been very welldefined in their period of early development, butthey may have since become complex and proba-bly language-specific.
Detecting pairs of cognatesbased on etymology is useful and reliable, but, forresource-poor languages, methods which requireless linguistic knowledge might be necessary.
Ac-cording to Gusfield (1997), an edit transcript (rep-resenting the conversion of one string to another)and an alignment are mathematically equivalentways of describing relationships between strings.Therefore, because the edit distance was widelyused in this research area and produced good re-sults, we are encouraged to employ orthographicalignment for identifying pairs of cognates, notonly to compute similarity scores, as was previ-ously done, but to use aligned subsequences asfeatures for machine learning algorithms.
Our in-tuition is that inferring language-specific rules foraligning words will lead to better performance inthe task of cognate identification.3.1 Orthographic AlignmentString alignment is closely related to the taskof sequence alignment in computational biology.Therefore, to align pairs of words we employ theNeedleman-Wunsch global alignment algorithm(Needleman and Wunsch, 1970), which is mainlyused for aligning sequences of proteins or nu-cleotides.
Global sequence alignment aims at de-termining the best alignment over the entire lengthof the input sequences.
The algorithm uses dy-namic programming and, thus, guarantees to findthe optimal alignment.
Its main idea is that anypartial path of the alignment along the optimalpath should be the optimal path leading up to thatpoint.
Therefore, the optimal path can be deter-mined by incremental extension of the optimalsubpaths (Schuler, 2002).
For orthographic align-ment, we consider words as input sequences andwe use a very simple substitution matrix, which100gives equal scores to all substitutions, disregard-ing diacritics (e.g., we ensure that e and `e arematched).3.2 Feature ExtractionUsing aligned pairs of words as input, we extractfeatures around mismatches in the alignments.There are three types of mismatches, correspond-ing to the following operations: insertion, deletionand substitution.
For example, for the Romanianword exhaustiv and its Italian cognate pair esaus-tivo, the alignment is as follows:e x h a u s t i v -e s - a u s t i v oThe first mismatch (between x and s) is causedby a substitution, the second mismatch (betweenh and -) is caused by a deletion from source lan-guage to target language, and the third mismatch(between - and o) is caused by an insertion fromsource language to target language.
The featureswe use are character n-grams around mismatches.We experiment with two types of features:i) n-grams around gaps, i.e., we account onlyfor insertions and deletions;ii) n-grams around any type of mismatch, i.e.,we account for all three types of mismatches.The second alternative leads to better perfor-mance, so we account for all mismatches.
Asfor the length of the grams, we experiment withn ?
{1, 2, 3}.
We achieve slight improvements bycombining n-grams, i.e., for a given n, we use alli-grams, where i ?
{1, ..., n}.
In order to provideinformation regarding the position of the features,we mark the beginning and the end of the wordwith a $ symbol.
Thus, for the above-mentionedpair of cognates, (exhaustiv, esaustivo), we extractthe following features when n = 2:x>s ex>es xh>s-h>- xh>s- ha>-a->o v->vo -$>o$For identical features we account only once.Therefore, because there is one feature (xh>s-)which occurs twice in our example, we have 8 fea-tures for the pair (exhaustiv, esaustivo).3.3 Learning AlgorithmsWe use Naive Bayes as a baseline and we exper-iment with Support Vector Machines (SVMs) tolearn orthographic changes and to discriminate be-tween pairs of cognates and non-cognates.
Weput our system together using the Weka work-bench (Hall et al, 2009), a suite of machine learn-ing algorithms and tools.
For SVM, we use thewrapper provided by Weka for LibSVM (Changand Lin, 2011).
We use the radial basis functionkernel (RBF), which can handle the case whenthe relation between class labels and attributes isnon-linear, as it maps samples non-linearly into ahigher dimensional space.
Given two instances xiand xj, where xi?
Rn, the RBF kernel functionfor xiand xjis defined as follows:K(xi, xj) = exp(??||xi?
xj||2), ?
> 0,where ?
is a kernel parameter.We split the data in two subsets, for trainingand testing, with a 3:1 ratio, and we perform gridsearch and 3-fold cross validation over the train-ing set in order to optimize hyperparameters cand ?.
We search over {1, 2, ..., 10} for c andover {10?5, 10?4, ..., 104, 105} for ?.
The valueswhich optimize accuracy on the training set are re-ported, for each pair of languages, in Table 3.4 Experiments4.1 DataWe apply our method on an automatically ex-tracted dataset of cognates for four pairs oflanguages: Romanian-French, Romanian-Italian,Romanian-Spanish and Romanian-Portuguese.
Inorder to build the dataset, we apply the method-ology proposed by Ciobanu and Dinu (2014) onthe DexOnline1machine-readable dictionary forRomanian.
We discard pairs of words for whichthe forms across languages are identical (i.e., theRomanian word matrice and its Italian cognatepair matrice, having the same form), because thesepairs do not provide any orthographic changes tobe learned.
For each pair of languages we de-termine a number of non-cognate pairs equal tothe number of cognate pairs.
Finally, we ob-tain 445 pairs of cognates for Romanian-French2,3,477 for Romanian-Italian, 5,113 for Romanian-Spanish and 7,858 for Romanian-Portuguese.
Be-cause we need sets of approximately equal size for1http://dexonline.ro2The number of pairs of cognates is much lower forFrench than for the other languages because there are numer-ous Romanian words which have French etymology and, inthis paper, we do not consider these words to be cognate can-didates.1011st2nd3rd4th5thIT iu>io un>on l->le t$>-$ -$>e$FR un>on ne>n- iu>io t?i>ti e$>-$ES -$>o$ t?i>ci ?>?on ie>i?o at>adPT ie>?ao at?>ac?
t?i>c?
?a i$>-$ ?a$>a$Table 1: The most relevant orthographic cues foreach pair of languages determined on the entiredatasets using the ?2attribute evaluation methodimplemented in Weka.1st2nd3rd4th5thIT -$>e$ -$>o$ ?a$>a$ ?>re t?i>ziFR e$>-$ un>on ne>n- iu>io t?i>tiES -$>o$ e$>-$ t?i>ci ?a$>a$ at>adPT -$>o$ ?a$>a$ e$>-$ -$>r$ -$>a$Table 2: The most frequent orthographic cues foreach pair of languages determined on the cognatelists using the raw frequencies.comparison across languages, we keep 400 pairsof cognates and 400 pairs of non-cognates for eachpair of languages.
In Tables 1 and 2 we provide,for each pair of languages, the five most relevant2-gram orthographic changes, determined usingthe ?2distribution implemented in Weka, and thefive most frequent 2-gram orthographic changes inthe cognate pairs from our dataset3.
None of thetop ranked orthographic cues occurs at the begin-ning of the word, while many of them occur at theend of the word.
The most frequent operation inTables 1 and 2 is substitution.4.2 Results AnalysisWe propose a method for automatic detectionof cognate pairs using orthographic alignment.We experiment with two machine-learning ap-proaches: Naive Bayes and SVM.
In Table 3 wereport the results of our research.
We report then-gram values for which the best results are ob-tained and the hyperparameters for SVM, c and ?.The best results are obtained for French and Span-ish, while the lowest accuracy is obtained for Por-tuguese.
The SVM produces better results for alllanguages except Portuguese, where the accuracyis equal.
For Portuguese, both Naive Bayes andSVM misclassify more non-cognates as cognates3For brevity, we use in the tables the ISO 639-1 codes forlanguage abbreviation.
We denote pairs of languages by thetarget language, given the fact that Romanian is always thesource language in our experiments.than viceversa.
A possible explanation might bethe occurrence, in the dataset, of more remotelyrelated words, which are not labeled as cognates.We plan to investigate this assumption and to ap-ply the proposed method on other datasets in ourfuture work.4.3 Comparison with Previous MethodsWe investigate the performance of the method wepropose in comparison to previous approaches forautomatic detection of cognate pairs based on or-thographic similarity.
We employ several ortho-graphic metrics widely used in this research area:the edit distance (Levenshtein, 1965), the longestcommon subsequence ratio (Melamed, 1995) andthe XDice metric (Brew and McKelvie, 1996)4.In addition, we use SpSim (Gomes and Lopes,2011), which outperformed the longest commonsubsequence ratio and a similarity measure basedon the edit distance in previous experiments.
Toevaluate these metrics on our dataset, we use thesame train/test sets as we did in our previous ex-periments and we follow the strategy described in(Inkpen et al, 2005).
First, we compute the pair-wise distances between pairs of words for eachorthographic metric individually, as a single fea-ture5.
In order to detect the best threshold for dis-criminating between cognates and non-cognates,we run a decision stump classifier (provided byWeka) on the training set for each pair of lan-guages and for each metric.
A decision stump is adecision tree classifier with only one internal nodeand two leaves corresponding to our two class la-bels.
Using the best threshold value selected foreach metric and pair of languages, we further clas-sify the pairs of words in our test sets as cognatesor non-cognates.
In Table 4 we report the resultsfor each approach.
Our method performs betterthan the orthographic metrics considered as indi-vidual features.
Out of the four similarity met-rics, SpSim obtains, overall, the best performance.These results support the relevance of accountingfor orthographic cues in cognate identification.4We use normalized similarity metrics.
For the edit dis-tance, we subtract the normalized value from 1 in order toobtain similarity.5SpSim cannot be computed directly, as the other metrics,so we introduce an additional step in which we use 1/3 of thetraining set (only cognates are needed) to learn orthographicchanges.
In order to maintain a stratified dataset, we discardan equal number of non-cognates in the training set and thenwe compute the distances for the rest of the training set andfor the test set.
We use the remaining of the initial trainingset for the next step of the procedure.102Naive Bayes SVMP R A n P R A n c ?IT 0.72 0.93 79.0 1 0.76 0.92 81.5 1 1 0.10FR 0.81 0.91 82.0 2 0.84 0.89 87.0 2 10 0.01ES 0.79 0.92 84.0 1 0.85 0.88 86.5 2 4 0.01PT 0.67 0.88 73.0 2 0.70 0.78 73.0 2 10 0.01Table 3: Results for automatic detection of cognates using orthographic alignment.
We report the preci-sion (P), recall (R) and accuracy (A) obtained on the test sets and the optimal n-gram values.
For SVMwe also report the optimal hyperparameters c and ?
obtained during cross-validation on the training sets.EDIT LCSR XDICE SPSIMP R A t P R A t P R A t P R A tIT 0.67 0.97 75.0 0.43 0.68 0.91 75.0 0.51 0.66 0.98 74.0 0.21 0.66 0.98 74.5 0.44FR 0.76 0.93 82.0 0.30 0.76 0.90 81.5 0.42 0.77 0.79 78.0 0.26 0.86 0.83 85.0 0.59ES 0.77 0.91 82.0 0.56 0.72 0.97 80.0 0.47 0.72 0.99 80.5 0.19 0.81 0.90 85.0 0.64PT 0.62 0.99 69.5 0.34 0.59 0.99 65.5 0.34 0.57 0.99 63.5 0.10 0.62 0.97 69.0 0.39Table 4: Comparison with previous methods for automatic detection of cognate pairs based on orthog-raphy.
We report the precision (P), recall (R) and accuracy (A) obtained on the test sets and the optimalthreshold t for discriminating between cognates and non-cognates.5 Conclusions and Future WorkIn this paper we proposed a method for automaticdetection of cognates based on orthographic align-ment.
We employed the Needleman-Wunsch al-gorithm (Needleman and Wunsch, 1970) for se-quence alignment widely-used in computationalbiology and we used aligned pairs of words toextract rules for lexical changes occurring whenwords enter new languages.
We applied ourmethod on an automatically extracted dataset ofcognates for four pairs of languages.As future work, we plan to extend our methodon a few levels.
In this paper we used a verysimple substitution matrix for the alignment algo-rithm, but the method can be adapted to integratehistorical information regarding language evolu-tion.
The substitution matrix for the alignment al-gorithm can be customized with language-specificinformation, in order to reflect the probability ofa character to change into another.
An importantachievement in this direction belongs to Delmestriand Cristianini (2010), who introduced PAM-likematrices, linguistic-inspired substitution matriceswhich are based on information regarding ortho-graphic changes.
We plan to investigate the con-tribution of using this type of substitution matricesfor our method.We intend to investigate other approaches tostring alignment, such as local alignment (Smithand Waterman, 1981), and other learning algo-rithms for discriminating between cognates andnon-cognates.
We plan to extend our analysis withmore language-specific features, where linguisticknowledge is available.
First, we intend to use thepart of speech as an additional feature.
We assumethat some orthographic changes are dependent onthe part of speech of the words.
Secondly, we wantto investigate whether accounting for the commonancestor language influences the results.
We areinterested to find out if the orthographic rules de-pend on the source language, or if they are ratherspecific to the target language.
Finally, we plan tomake a performance comparison on cognate pairsversus word-etymon pairs and to investigate falsefriends (Nakov et al, 2007).We further intend to adapt our method for cog-nate detection to a closely related task, namelycognate production, i.e., given an input word w,a related language L and a set of learned rules fororthographic changes, to produce the cognate pairof w in L.AcknowledgementsWe thank the anonymous reviewers for their help-ful and constructive comments.
The contributionof the authors to this paper is equal.
Research sup-ported by CNCS UEFISCDI, project number PN-II-ID-PCE-2011-3-0959.103ReferencesQuentin D. Atkinson, Russell D. Gray, Geoff K.Nicholls, and David J. Welch.
2005.
From Wordsto Dates: Water into Wine, Mathemagic or Phylo-genetic Inference?
Transactions of the PhilologicalSociety, 103:193?219.Lisa Beinborn, Torsten Zesch, and Iryna Gurevych.2013.
Cognate Production using Character-basedMachine Translation.
In Proceedings of the 6th In-ternational Joint Conference on Natural LanguageProcessing, IJCNLP 2013, pages 883?891.Chris Brew and David McKelvie.
1996.
Word-PairExtraction for Lexicography.
In Proceeding of Text,Speech and Dialogue, TSD 1996, pages 45?55.Chris Buckley, Mandar Mitra, Janet A. Walz, andClaire Cardie.
1997.
Using Clustering and Super-Concepts Within SMART: TREC 6.
In Proceedingsof the 6th Text Retrieval Conference, TREC 1997,pages 107?124.Chih-Chung Chang and Chih-Jen Lin.
2011.LIBSVM: A Library for Support Vector Ma-chines.
ACM Transactions on Intelligent Sys-tems and Technology, 2:27:1?27:27.
Soft-ware available at http://www.csie.ntu.edu.tw/?cjlin/libsvm.Kenneth W. Church.
1993.
Char align: A programfor aligning parallel texts at the character level.
InProceedings of the 31st Annual Meeting of the As-sociation for Computational Linguistics, ACL 1993,pages 1?8.Alina Maria Ciobanu and Liviu P. Dinu.
2014.
Build-ing a Dataset of Multilingual Cognates for the Ro-manian Lexicon.
In Proceedings of the 9th Interna-tional Conference on Language Resources and Eval-uation, LREC 2014.Antonella Delmestri and Nello Cristianini.
2010.String Similarity Measures and PAM-like Matricesfor Cognate Identification.
Bucharest Working Pa-pers in Linguistics, 12(2):71?82.Ton Dijkstra, Franc Grootjen, and Job Schepens.
2012.Distributions of Cognates in Europe as Based onLevenshtein Distance.
Bilingualism: Language andCognition, 15:157?166.Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database.
MIT Press, Cambridge,Massachusetts.Lu?
?s Gomes and Jos?e Gabriel Pereira Lopes.
2011.Measuring spelling similarity for cognate identifi-cation.
In Proceedings of the 15th Portugese Con-ference on Progress in Artificial Intelligence, EPIA2011, pages 624?633.
Software available at http://research.variancia.com/spsim.Osamu Gotoh.
1982.
An improved algorithm formatching biological sequences.
Journal of Molec-ular Biology, 162(3):705?708.Dan Gusfield.
1997.
Algorithms on Strings, Trees andSequences: computer science and computational bi-ology.
Cambridge University Press New York, NY,USA.David Hall and Dan Klein.
2010.
Finding CognateGroups Using Phylogenies.
In Proceedings of the48th Annual Meeting of the Association for Compu-tational Linguistics, ACL 2010, pages 1030?1039.Mark Hall, Eibe Frank, Geoffrey Holmes, BernhardPfahringer, Peter Reutemann, and Ian H. Witten.2009.
The WEKA data mining software: an up-date.
SIGKDD Explorations, 11(1):10?18.
Soft-ware available at http://www.cs.waikato.ac.nz/ml/weka.Bradley Hauer and Grzegorz Kondrak.
2011.
Cluster-ing semantically equivalent words into cognate setsin multilingual lists.
In 5th International Joint Con-ference on Natural Language Processing, IJCNLP2011, pages 865?873.Diana Inkpen, Oana Frunza, and Grzegorz Kondrak.2005.
Automatic Identification of Cognates andFalse Friends in French and English.
In Proceed-ings of the International Conference on Recent Ad-vances in Natural Language Processing, RANLP2005, pages 251?257.Philipp Koehn and Kevin Knight.
2000.
Estimat-ing Word Translation Probabilities from UnrelatedMonolingual Corpora Using the EM Algorithm.
InProceedings of the 17th National Conference on Ar-tificial Intelligence and 12th Conference on Inno-vative Applications of Artificial Intelligence, pages711?715.Grzegorz Kondrak, Daniel Marcu, and Keven Knight.2003.
Cognates Can Improve Statistical TranslationModels.
In Proceedings of the 2003 Conferenceof the North American Chapter of the Associationfor Computational Linguistics on Human LanguageTechnology, HLT-NAACL 2003, pages 46?48.Grzegorz Kondrak.
2000.
A New Algorithm for theAlignment of Phonetic Sequences.
In Proceedingsof the 1st North American Chapter of the Asso-ciation for Computational Linguistics Conference,NAACL 2000, pages 288?295.Grzegorz Kondrak.
2004.
Combining Evidence inCognate Identification.
In Proceedings of the 17thConference of the Canadian Society for Computa-tional Studies of Intelligence on Advances in Artifi-cial Intelligence, pages 44?59.Vladimir I. Levenshtein.
1965.
Binary Codes Capableof Correcting Deletions, Insertions, and Reversals.Soviet Physics Doklady, 10:707?710.Johann-Mattis List.
2012.
LexStat: Automatic De-tection of Cognates in Multilingual Wordlists.
InProceedings of the EACL 2012 Joint Workshop ofLINGVIS and UNCLH, pages 117?125.104Dan Melamed.
1995.
Automatic Evaluation and Uni-form Filter Cascades for Inducing N-Best Transla-tion Lexicons.
In Proceedings of the 3rd Workshopon Very Large Corpora.Andrea Mulloni and Viktor Pekar.
2006.
Automaticdetection of orthographic cues for cognate recog-nition.
In In Proceedings of the 5th InternationalConference on Language Resources and Evaluation,LREC 2006, pages 2387?2390.Andrea Mulloni.
2007.
Automatic Prediction of Cog-nate Orthography Using Support Vector Machines.In Proceedings of the 45th Annual Meeting of theACL: Student Research Workshop, ACL 2007, pages25?30.Svetlin Nakov, Preslav Nakov, and Elena Paskaleva.2007.
Cognate or False Friend?
Ask the Web!
InProceedings of the RANLP 2007 Workshop ?Acqui-sition and Management of Multilingual Lexicons?,pages 55?62.Mirabela Navlea and Amalia Todirascu.
2011.
UsingCognates in a French-Romanian Lexical AlignmentSystem: A Comparative Study.
In Proceedings ofthe International Conference on Recent Advances inNatural Language Processing, RANLP 2011, pages247?253.Saul B. Needleman and Christian D. Wunsch.
1970.A general method applicable to the search for simi-larities in the amino acid sequence of two proteins.Journal of Molecular Biology, 48(3):443 ?
453.Ee-Lee Ng, Beatrice Chin, Alvin W. Yeo, and BaliRanaivo-Malanc?on.
2010.
Identification of Closely-Related Indigenous Languages: An OrthographicApproach.
Int.
J. of Asian Lang.
Proc., 20(2):43?62.Gregory D. Schuler.
2002.
Sequence Alignment andDatabase Searching.
Bioinformatics: A PracticalGuide to the Analysis of Genes and Proteins, 43.
A.D. Baxevanis and B. F. F. Ouellette, John Wiley &Sons, Inc., New York, USA.Michel Simard, George F. Foster, and Pierre Isabelle.1992.
Using Cognates to Align Sentences in Bilin-gual Corpora.
In Proceedings of the 4th Interna-tional Conference on Theoretical and Methodologi-cal Issues in Machine Translation.Temple F. Smith and Michael S. Waterman.
1981.Identification of common molecular subsequences.Journal of Molecular Biology, 147(1):195?197.Lydia Steiner, Peter F. Stadler, and Michael Cysouw.2011.
A pipeline for computational historical lin-guistics.
Language Dynamics and Change, 1(1):89?127.105
