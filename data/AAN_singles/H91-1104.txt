Very Large Annotated Database of American EnglishMitch Marcus, Principal InvestigatorDepartment  of Computer  and Informat ion ScienceUniversity of PennsylvaniaPhi ladelphia,  PA 19104--6389emaih mitch@cis.upenn.eduPROJECT GOALSTo construct a data base (the "Penn Treebank") of writ-ten and transcribed spoken American English annotatedwith detailed grammatical structure.
This data base willserve as a national resource, providing training material fora wide variety of approaches to automatic language acqui-sition, a reference standard for the rigorous evaluation ofsome components of natural language understanding sys-tems, and a research tool for the investigation of the gram-mar of naturally spoken English.RECENT RESULTSTreebankWe have provided up to 4.5 million words of preliminaryTreebank material tagged for part of speech (POS) to 10different sites in the U.S., including DARPA contractors,industrial research labs and universities.
We have finishedPOS tagging of 351 MUC-3 messages (about 100K words)and grammatical annotation of a subset of 88, which areavailable by anonymous FTP.After early concerns about productivity, we investigateda range of methods for syntactic annotation (henceforth,tree banking) with respect to annotator speed, for anno-tators posteditting the output of Hindle's Fidditch parser.Key results:1.
Annotators take substantially onger to learn tree bank-ing than the POS annotation task, with substantialincreases in speed occuring after 2 months of training.2.
Annotators can postedit the full output of Hindle'sparser at an average speed of 100-200 words per hourafter three weeks, and 400-500 words per hour aftertwo months.3.
Reducing the output to a far more skeletal represen-tation increases average speed to 700-750 words perhour.
At this speed, we can maintain an output of 2.5million words a year of "treebanked" sentences, witheach sentence posteditted once.Since December 1, we have annotated about 250K wordsof text, with 1/3 bracketted by more than one annotator.LearningWe have developed, in collaboration with UNISYS, aparsing algorithm for unrestricted text which uses a pro-bability-based scoring function to select the "best" parse.The parser, Pearl, is a time-asynchronous bottom-up chartparser with Earley-type top-down prediction which pursuesthe highest-scoring theory in the chart, where the score ofa theory represents the extent to which the context of thesentence predicts that interpretation.
This parser differsfrom previous tochastic parsers in that it uses a richer formof context to predict likelihood.
Trained on a corpus of1100 sentences from MIT's Voyager direction-finding systemand using the string grammar from UNISYS' PUNDITLanguage Understanding System, Pearl correctly parsed 35out of 40 or 88% of test sentences from previously unseenVoyager sentences.We have also adapted Church's PARTS tagger, fromAT&T Bell Labs, to operate independently of particular tagsets, and have developed software for retraining the taggerwhich is available to those who have obtained a license touse the version of PARTS which AT&T distributes.PLANS FOR THE COMING YEAR?
Automatic methods for consistency checking betweenannotators need to be developed.?
We expect to use our retrained version of PARTS toretag the preliminary corpus and then adjudicate be-tween it and the output of the retrained tagger.
Weexpect that the error rate will drop to well under 1%on correct ags, at an additional cost of 5 minutes per1000 words.?
We intend to begin work on automatic grammar ex-traction from POS tagged corpora, combining earlierwork in bracketting using information theoretic mea-sures with notions of phrase structure (so-called "X-bar theory") from competence linguistics.?
We expect to tree bank lots and lots of sentences.430
