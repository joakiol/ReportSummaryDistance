Proceedings of TextGraphs-9: the workshop on Graph-based Methods for Natural Language Processing, pages 48?55,October 29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsThe Modular Community Structure of Linguistic Predication NetworksAaron GerowComputation InstituteUniversity of ChicagoChicago, IL, USAgerow@uchicago.eduJames EvansDept.
of Sociology & Computation InstituteUniversity of ChicagoChicago, IL, USAjevans@uchicago.eduAbstractThis paper examines the structure of lin-guistic predications in English text.
Iden-tified by the copular ?is-a?
form, predi-cations assert category membership (hy-pernymy) or equivalence (synonymy) be-tween two words.
Because predicationexpresses ontological structure, we hy-pothesize that networks of predicationswill form modular groups.
To measurethis, we introduce a semantically mo-tivated measure of predication strengthto weight relevant predications observedin text.
Results show that predicationsdo indeed form modular structures with-out any weighting (Q ?
0.6) and thatusing predication strength increases thismodularity (Q ?
0.9) without discard-ing low-frequency items.
This highlevel of modularity supports the network-based analysis and the use of predicationstrength as a way to extract dense semanticclusters.
Additionally, words?
centralitywithin communities exhibits slight corre-lation with hypernym depths in WordNet,underscoring the ontological organizationof predication.1 Introduction & BackgroundStatistical patterns in language use are evident atmany levels and have proved useful in an increas-ingly wide range of computational and cognitiveapplications.
Statistical regularities offer a wayto quantify and model how people create, encodeand use knowledge about the world.
Statementsspecifically about ?what things are?
(ie.
onto-logical statements) offer uniquely transparent evi-dence about peoples?
knowledge of the world.
Ourresearch adopts a corpus-based approach in whichnetworks of predications are analyzed to assess theunderlying structure of ontological assertions.Word-word predications, observed as the copu-lar is-a form in English, are important because,unlike most grammatical constructions that havefew semantic constraints, predications tend to im-ply category membership or equivalence.
Take (i)and (ii) for example:(i) Safety is always a primary concern.
(ii) This organization is an institutionwhere [...].
(i) is a category assertion (safety as a type of con-cern) and (ii) is an equivalence assertion (organi-zation is an institution).
Most predications can beinterpreted as category memberships like (i); ex-plicit articulation of equivalence is actually quiterare in language (Cimiano, 2006; Cimiano andV?olker, 2005).
Although some categorical pred-ications are metaphorical, many of these are inter-preted using category matching or analogical map-ping processes (Glucksberg et al., 1997; Bowdleand Gentner, 2005).
In both semantic interpreta-tions, predications naturally form a directed net-work of words.
Consisting primarily of categoryassertions, the structure of this network should ex-hibit a degree of natural clustering owing naturalcategories of the those things it represents.Network representations of language have beenused to describe a wide range of structures in lan-guage, including word-word and word-documentco-occurrences, term collocations, dependencystructure and named entity relations.
Networks ofgrammatical relations have been found to differ-entiate word-classes (Ferrer i Cancho et al., 2004)and semantic networks can be used to model vo-cabulary growth (Steyvers and Tenenbaum, 2005).Co-occurrence networks, which are perhaps themost widely studied natural language network, arethe foundation of many vector-space models (Lan-dauer and Dumais, 1997; Turney et al., 2010)and can be used to mine synonyms (Cohen etal., 2005), disambiguate word senses (Agirre et48al., 2014; Biemann, 2006) and even help markthe quality of essays (Foltz et al., 1999).
Spec-tral methods applied to linguistic networks havebeen used to differentiate languages (Ferrer i Can-cho et al., 2004), word-classes (Sun and Korho-nen, 2009) and genres of text (Ferrer i Cancho etal., 2007).
Using spectral methods, research hasalso found that syntactic and semantic distribu-tional similarity networks have considerably dif-ferent structure (Biemann et al., 2009).
The useof lexical graphs (networks of words) in particu-lar, pre-dates modern NLP (Rapoport et al., 1966),though the approach continues to influence a va-riety of NLP and information retrieval tasks likesummarization and retrieval (Erkan and Radev,2004; V?eronis, 2004).
Network-based methodshave even used community detection, similar tothe algorithm described in this paper, to extractspecialist terms from sets of multi-theme docu-ments (Grineva et al., 2009) as well as unstruc-tured texts (Gerow, 2014).Because predications naturally form directedchains of ontological assertions, we hypothesizethat their underlying structure is systematic andmodular, given its representation of naturally or-ganized things in the world.
Our method employscommunity detection on networks of noun-nounpredications as a way to assess the overall struc-ture of predication, but it could be extended tohypernym and category extraction tasks (Hearst,1992; Caraballo, 1999).
Specifically, we test forcommunity structure in predications and explorewhether this structure becomes more highly re-solved when using a semantic measure of predica-tion strength introduced in the following section.We also predict that central nodes (i.e.
words)in individual modules will correlate to categori-cal super-ordinance or hypernymy.
Thus, we firstseek to assess the overall community structureof predication, testing whether or not it is moreresolved using a novel measure of predicationstrength.
Second, within communities of predi-cations, we compare the words?
closeness central-ity to their positions in WordNet?s hypernym tree(Miller, 1995).2 MethodUnlike co-occurrence networks, where words arerelated simply by proximity, predication networksare built using extracted grammatical relation-ships.
The implied relationship in a co-occurrencenetwork provides a natural way to weight edges,but predications have no analogue to a proximity-based weighting scheme.
One option would be toweight edges by the number of times given pred-ications were observed.
While this is perhaps themost obvious way to account for important predi-cations, it risks exaggerating high-frequency itemsthat are common for reasons other than importance(perhaps they are idioms, collocates or found inabnormally strong colligational structures).
Fre-quency weighting would also be susceptible tonoise from the many low-frequency items.
To ad-dress these concerns, we introduce a semanticallyinformed measure of predication relevance.Wilks?
(1975; 1978) theory of preference se-mantics proposes that subject- and object-verb re-lationships evince ?selectional preference?, whichcan be thought of as the disposition verbs haveto select certain arguments ?
particular classes ofsubjects or objects.
To operationalize selectionalpreference, Resnik (1997) introduced selectionalpreference strength to measure the disposition or?preference?
of a verb, v:SR(v) =?c?CP (c|v) logP (c|v)P (c)(1)where C is a set of semantic classes from whichv can select and R is the grammatical relation inquestion.
Note that SR(v) is effectively the sumK-L divergence between the probabilities of v andc for all classes.
In a corpus-based setting, theprobability of any word can be estimated by itsrelative frequency: P (x) =f(x)?if(xi).
Resnik goeson to define a measure of selectional associationbetween a verb and a specific class, c:AR(v, c) =1SR(v)P (c|v) logP (c|v)P (c)(2)In the typical form of selectional preference induc-tion ?
the task of estimating likelihoods over allclasses ?
Eq.
2 is used to measure a verb?s pref-erence for classes of nominal subjects or objectslike vehicles, insects, birds, etc.
(Resnik, 1997;Shutova et al., 2013).To test our assumptions regarding the modu-lar structure of predications in English, a mea-sure like selectional association should accountfor predicates?
diversity (or uniformity) of attach-ment.
That is, the preference a predicate has to49operate on a wide or narrow range of words.
To ac-count for this, we add a term, U(p), to account forthe relative number of unique words a predicate phas been observed to predicate.
Note that this isnot the total number of predications involving p,which would produce problematically high valueswere p to collocate strongly with the words it pred-icates.
Instead, U(p) addresses and normalizes forthe diversity with which p is applied.
Additionally,instead of using a pre-set collection of semanticclasses on which predication is assumed to oper-ate, each predicate is treated as its own class.
Fora predication consisting of word w predicated byp, predication strength is defined as follows:PS(w, p) =1SR(p)logP (w|p)U(p)P (w)(3)PS thus combines three important properties ofpredications: the relative frequency of a givenpredication P (w|p), the relative frequency of aword P (w) and the diversity of a word?s poten-tial predications U(p).
Defined like this, U(p)helps diminish the contribution of predicates thatare widely applicable, under the assumption thatbeing widely used, they are in-fact somewhat lesssignificant.
Using this measure to weight edgesin a predication network should help diminishthe contribution of exceptionally frequent predica-tions as well as that from low-frequency predica-tions without excluding them.An example predication network is shown inFigure 1.
In these networks, a network is con-structed over a set of documents where nodes arethe words in a predication, the direction follow-ing the is-a link.
Thus, example (i) would re-sult in a link from safety to concern with weight1.
Were another predication involving concern tobe observed, another edge would be added fromthat node.
Note that circularities are allowed eventhough this example is acyclic.
To assess predi-cation strength as a relevance function, we com-pare the community structure of weighted andunweighted networks.
The example in Figure 1shows a sample network (top) and the communi-ties extracted from the unweighted and weightedversions of the same network (middle and bottom).Note the changes in community assignments fromthe unweighted version to the weighted.
In par-ticular, observe the new clusters in the weightednetwork around money, factor and murder.
If ourFigure 1: Predication network from the enTen-Ten corpus (pruned by frequency ?
170): the ini-tial network (top), communities assigned by theInfomap algorithm for the unweighted network(middle) and for the network weighted by predi-cation strength (bottom).50intuitions about the systematic nature of linguis-tic predication is correct, there should be at leasta moderate degree of community structure in theunweighted networks, and if predication displayssemantic preference similar to selectional associa-tion, this community structure should be strongerfor networks weighted by predication strength.The school librarian may be the person that controls [...]You may find Rachel is the one person who may [...]Neither the state nor its government is a person.An arbitrator is a person who is appointed [...]On the other hand, an expert is a person to fix [...]After all, the vendor is the person best able to [...]An expert need not be an individual person.The innocent party is a natural person.If the indemnifier is a natural person, [...]consumers who are natural persons under the Directive.Table 1: Sample predications involving forms ofthe word person as the target in the BNC.
In eachcase an edge would connect the predicate (in ital-ics) to person (in bold).3 ResultsTo explore the structure of predication networks,we analyzed two corpora using the method de-scribed above: the British National Corpus (BNC)(Leech et al., 2001) and the enTenTen web corpus.Predications were extracted templates over a POS-tagged version of each corpus using the Sketch En-gine1tool (Kilgarriff et al., 2004).
The BNC con-tained about 112 million tokens and the enTenTencollection has 3.2 billion tokens.
For each collec-tion, the top 1,000 most frequent nouns provideda seed set from which to extract all predicateand predicate of relations2(see examples inTable 1).
For the BNC, this resulted in 40,721predications (14,319 unique) and 260,555 (20,651unique) for the enTenTen collection.
Predicationstrength scores were computed for every pred-ication using within-corpus relative frequencies.These scores were used to weight edges in oneversion of the predication network, whereas theedge-weights of the ?unweighted?
version wereuniformly set to 1.0.
No node-weighting was ap-plied in either case.1http://www.sketchengine.co.uk/2"NN.?.?"
[tag="WP"|tag="PNQ"|tag="CJT"]?[tag="RB.?
"|tag="RB"|tag="VM"]0,5[lemma="be" & tag="V.*"] "RB.?"0,2[tag="DT.?
"|tag="PP$"]0,1 "CD"0,2[tag="JJ.?"|tag="RB.?"|word=","]0,3"NN.?.?
"0,2 2:"NN.?.?"
[tag!="NN.?.?
"]Two methods were used to extract communitiesfrom the predication networks: the Infomap andwalktrap algorithms.
By using two methods, weattain some assurance that our findings are not ar-tifacts of the assumptions underlying either algo-rithm.
The Infomap algorithm is an information-theoretic method that exploits the analogue be-tween optimizing a compression dictionary andsimplifying a graph by describing ?flow?
throughnodes (Rosvall and Bergstrom, 2008).
Infomap as-sumes edges in a network induce such flow andby deriving a minimum description of this flow,the algorithm can find multi-level communitiesin large networks (Rosvall and Bergstrom, 2011).The second method, walktrap, operationalizes theintuition that a large set of short random walks ona network will leave walkers on some groups ofnodes more often than others (Pons and Latapy,2005).
By setting the walk distance to a smallvalue, relative to a network?s density, walkers willtend toward communities if the walker sample issufficient.
These algorithms are both known towork well with large, directed networks and nei-ther imposed intractable computational burdens atour scale (Fortunato, 2010; Lancichinetti and For-tunato, 2009).
Because both algorithms require aconnected network, our analysis is restricted to thelargest connected component (LCC) for all net-works, though we have no reason to believe resultswould differ significantly for other components.Community assignments can be assessed bymeasuring how self-contained or ?modular?
theresulting communities are.
Modularity was intro-duced as a way to choose the level of an optimalcut for hierarchical partitioning algorithms, analo-gous to the level in the dendrogram that yields thebest communities (Newman and Girvan, 2004).For a network with adjacency matrix A and com-munity assignments c, modularity is defined as:Q =12m?ijAij?kikj2m?
(ci, cj) (4)where m is the number of edges and kiis thedegree of node i.
?
(ci, cj) is 1 when the com-munity assignment of node i is the same as thatfor node j. Modularity measures how likely it isthat nodes in a community are connected to oneanother as opposed to nodes in other communi-ties.
Modularity is defined from -1.0 to 1.0 andgraphs where Q > 0.6 are conventionally said tohave relatively strong community structure (New-51man, 2010).
Here, we use modularity instead ofa measure of semantic similarity or semantic co-herence because predication is seldom an asser-tion of equivalence or similarity.
This means thatalthough words in predication communities maybe related in an ontological sense, such an assess-ment would not expose the level of independencebetween the communities.Weighted and unweighted networks from bothcorpora were submitted to each community detec-tion algorithm, the results of which were assessedusing modularity.
We also carried out this anal-ysis on frequency-weighted networks, the resultsof which were similar to the unweighted config-uration, but are not reported for sake of brevity.Figure 2 shows the modularity for each config-uration with varying minimum predication fre-quency (the number of times a predication hadto occur to be included).
Varying the minimumfrequency thresholds helps simulate the effect ofcorpus-size on the algorithm.
In the BNC, un-weighted networks with no minimum edge fre-quency show slight modularity (Q = 0.30),whereas in weighted networks it is quite strong(Q = 0.89).
The enTenTen corpus exhibits agap between the unweighted (Q = 0.61) andweighted networks (Q = 0.88) at low edge thresh-olds.
This shows that predication strength is help-ful in weighting relevant items without exclud-ing low-frequency observations.
The lower mod-ularity scores (Q; Eq.
4) in the unweighted net-works may be due to more novel, loose or figura-tive associations found in low-frequency predica-tions that inappropriately connect unrelated com-munities.
Interestingly, scores for unweighted andweighted networks converge up to a point as theminimum frequency increases (reducing the sizeof the network).
This pruning is helpful for theunweighted networks, but has little effect on theweighted versions.
In all cases, sparsity takes atoll as the LCC becomes quite small.
The reasonfor the eventual decline as the LCC shrinks below70 nodes is because communities are less likely toform at all in small networks.In addition to the highly modular structure, thecommunities of predications themselves are likelyto represent some semantic organization.
Specifi-cally, we looked for a categorical structure withinthe communities by comparing words to the hy-pernym tree in WordNet (Miller, 1995).
Intu-itively, one would expect words that are central inFigure 2: Modularity of predication networks inthe BNC (top) and enTenTen (bottom).
Note, asthe minimum frequency increases (bottom axis)and the LCC contains fewer and fewer nodes (topaxis), the community detection algorithms maynot produce a solution with more than one com-munity, resulting in undefined modularity.a community to be members of higher-level cate-gories.
In figure 1, for example, summer, hour andholiday all point to time, one could infer that timeis a shared hypernym.
We use closeness centrality,a graph-theoretic measure of node?s average prox-imity to other nodes, as a within-community mea-sure of super-ordinance (i.e.
hypernymy).
Thoughthere a number of network centrality measures,closeness centrality is a robust measure, though ittends not to scale well to larger networks becauseit requires computing the distance between everypair of nodes (Friedl et al., 2010).52The centrality scores in the communities werecompared to WordNet using the first sense-entryfor each node (which is typically the most com-mon) and words not found in the tree were dis-carded.
For the unweighted networks across bothcorpora, we found a mean Spearman correlation ofr=0.35 (p < 0.01; using Fisher?s transformation)for the Infomap algorithm and r=0.38 (p < 0.01)for walktrap.
In the weighted versions, Infomapproduced r=0.41 (p < 0.01) and walktrap pro-duced r=0.44 (p < 0.01).
This confirms thatpredication communities tend to specify categor-ical knowledge is moderately similar to WordNet.Note these correlation values are comparable be-tween the weighted and unweighted networks, im-plying that relevance, as selectional association, isnot an important marker of the communities?
hy-pernymic composition.4 DiscussionThe analysis in this paper is an attempt to iden-tify whether or not ontological knowledge ex-pressed in text consists of meaningful clusters.With the network representation and our measureof predication strength, results indicate that pred-ication forms strong community structures.
Over-all, results point to the highly modular nature ofpredication, previously unreported in language.This confirms our prediction that predication com-prises systematic clusters of related things and thehigher modularity observed in networks weightedby predication strength implies that predicationexhibits a form of selectional preference.
Predi-cation?s strong community structure is importantbecause it supports the use of linguistic patternsin establishing ontological representations, whichnaturally form higher-level groups.Technically, our measure of predicationstrength, which is built on prior assessments ofselectional preference, identifies the modularsemantic structure of predication even whenlow frequency predications are included.
Thismay be because low-frequency predications aremore likely to inscribe novel, loose or figurativeassociations that reach between semantic clustersto inappropriately decrease the overall modularityif not down-weighted.
As a result, more sys-tematic comparison of weighted and unweightednetworks, and the relative location of predica-tion within these structures, will reveal wheresemantic innovation and figurative assertions aremost likely to occur.
The predication networksanalyzed rely on a relatively tight definition ofpredication, one that, in other languages, may notbe accessible by the copular form.
Additionally,the two literal interpretations of linguistic predica-tions, equivalence or category membership, mayalso not be common in all languages.
To the extentthat parsers or taggers are available, a comparativeanalysis would broaden the understanding ofpredication in general.Given their high modularity, predication struc-tures could be exploited further for a number ofNLP tasks.
The correlations between centralityand hypernym depth mean that predication net-works could help construct or update categoricaltaxonomies.
For example, these networks couldhelp automate the construction of a hypernym tax-onomy with weighted branches, potentially aug-menting resources like WordNet (Ruiz-Casado etal., 2005; Miller, 1995).
One could also ex-amine the growth, combination and bifurcationof specific communities to help track ontologicalcommitments, either over time as shifts in lan-guage structures (Gerow and Ahmad, 2012), oracross genre and domain (Davies, 2010).
Fur-ther, because predication encodes categorical in-formation, its community structure may also en-code higher-level relations where strong inter-community links imply relationships betweenclasses of objects.Our study examined the topographical struc-ture of English predications in general, struc-ture that consists, in large part, of hypernym re-lations.
Though the relations in the examinednetworks are defined by copular is-a predica-tion structure, within-community hierarchies cor-related only moderately with the hypernym hierar-chy in WordNet.
This implies that the predicationscomprising our networks are either not entirelyhypernymic or that WordNet is not a good base-line.
Indeed, predication is a grammatical rela-tionship that often asserts synonymy or figurativehypernymy (perhaps sometimes also metonymy)and it is not apparent from the surface structurehow these semantic interpretation could be disam-biguated.
One reason this correlation is not higheris likely to do with the low coverage of the copularform as evidence of hypernymy (Hearst, 1992).Further work regarding the structure of predi-cations could build on the network framework toevaluate the communities themselves.
What prop-53erties differentiate communities?
Are there se-mantic, lexical or statistical properties that con-tribute to the formation of communities?
Are therediscernible differences between words that typifycommunities as opposed to those that bridge com-munities?
Predication communities are primar-ily semantic in nature, implying that central nodeswould typify meaningful aspects of their commu-nity.
It would also be relatively easy to extendnetwork representations to address more qualita-tive aspects such as coherence, word norms andword associations.
Indeed, a variety of corpus-based research could employ network-based meth-ods like those exemplified in this paper, capitaliz-ing on graph-theory, social network analysis andstatistical physics, without departing from rela-tional structures inherent to language.AcknowledgmentsThis work was supported by a grant from theTempleton Foundation to the Metaknowledge Re-search Network and grant #1158803 from the Na-tional Science Foundation.ReferencesEneko Agirre, Oier Lpez de Lacalle, and Aitor Soroa.2014.
Random walks for knowledge-based wordsense disambiguation.
Computational Linguistics,40(1):57?84.Chris Biemann, Monojit Choudhury, and AnimeshMukherjee.
2009.
Syntax is from mars while se-mantics from venus!
: insights from spectral analysisof distributional similarity networks.
In Proceedingsof the ACL-IJCNLP 2009 Conference Short Papers,pages 245?248.Chris Biemann.
2006.
Chinese whispers: an efficientgraph clustering algorithm and its application to nat-ural language processing problems.
In Proceedingsof the first workshop on graph based methods fornatural language processing, pages 73?80.Brian F. Bowdle and Dedre Gentner.
2005.
The careerof metaphor.
Psychological Review, 112(1):193.Sharon A. Caraballo.
1999.
Automatic constructionof a hypernym-labeled noun hierarchy from text.
InProceedings of the 37th annual meeting of the Asso-ciation for Computational Linguistics on Computa-tional Linguistics, pages 120?126.Philipp Cimiano and Johanna V?olker.
2005.Text2onto.
In Natural language processing and in-formation systems, pages 227?238.
Springer.Philipp Cimiano.
2006.
Ontology learning from text.Springer.Aaron M. Cohen, William R. Hersh, ChristopherDubay, and K. Spackman.
2005.
Using co-occurrence network structure to extract synonymousgene and protein names from medline abstracts.BMC Bioinformatics, 6(1):103.Mark Davies.
2010.
The corpus of contemporaryamerican english as the first reliable monitor cor-pus of english.
Literary and linguistic computing,25(4):447?464.G?unes Erkan and Dragomir R Radev.
2004.
Lexrank:Graph-based lexical centrality as salience in textsummarization.
Journal of Artificial IntelligenceResearch, 22(1):457?479.Ramon Ferrer i Cancho, Ricard V Sol?e, and ReinhardK?ohler.
2004.
Patterns in syntactic dependency net-works.
Physical Review E, 69(5):051915.Ramon Ferrer i Cancho, Andrea Capocci, and GuidoCaldarelli.
2007.
Spectral methods cluster wordsof the same class in a syntactic dependency net-work.
International Journal of Bifurcation andChaos, 17(07):2453?2463.Peter W. Foltz, Darrell Laham, and Thomas K. Lan-dauer.
1999.
Automated essay scoring: Applica-tions to educational technology.
In World Confer-ence on Educational Multimedia, Hypermedia andTelecommunications, pages 939?944.Santo Fortunato.
2010.
Community detection ingraphs.
Physics Reports, 486(3):75?174.Dipl-Math Bettina Friedl, Julia Heidemann, et al.2010.
A critical review of centrality measures insocial networks.
Business & Information SystemsEngineering, 2(6):371?385.Aaron Gerow and Khurshid Ahmad.
2012.
Diachronicvariation in grammatical relationships.
In Proceed-ings of the 24th International Conference on Com-putational Linguistics (COLING 2012).Aaron Gerow.
2014.
Extracting clusters of special-ist terms from unstructured text.
In Proceedings of2014 Conference on Empirical Methods in NaturalLanguage Processing (forthcoming).Sam Glucksberg, Matthew S. McGlone, and DeannaManfredi.
1997.
Property attribution in metaphorcomprehension.
Journal of memory and language,36(1):50?67.Maria Grineva, Maxim Grinev, and Dmitry Lizorkin.2009.
Extracting key terms from noisy and multi-theme documents.
In Proceedings of the 18th inter-national conference on World wide web, pages 661?670.Marti A Hearst.
1992.
Automatic acquisition of hy-ponyms from large text corpora.
In Proceedingsof the 14th conference on computational linguistics-Volume 2, pages 539?545.54Adam Kilgarriff, Pavel Rychl, Pavel Smr, and DavidTugwell.
2004.
The sketch engine.
In Proceedingsof EURALEX 2004, pages 105?116.Andrea Lancichinetti and Santo Fortunato.
2009.Community detection algorithms: a comparativeanalysis.
Physical Review E, 80(5):056117.Thomas K. Landauer and Susan T. Dumais.
1997.A solution to plato?s problem: The latent semanticanalysis theory of acquisition, induction, and rep-resentation of knowledge.
Psychological Review,104(2):211.Geoffrey Leech, Paul Rayson, and Andrew Wilson.2001.
Word frequencies in written and spoken En-glish: based on the British National Corpus.
Long-man.George A. Miller.
1995.
Wordnet: a lexicaldatabase for english.
Communications of the ACM,38(11):39?41.Mark E. J. Newman and M. Girvan.
2004.
Finding andevaluating community structure in networks.
Physi-cal Review E, 69(2):026113.Mark E. J. Newman.
2010.
Networks: an introduction.Oxford University Press.Pascal Pons and Matthieu Latapy.
2005.
Computingcommunities in large networks using random walks.In Computer and Information Sciences-ISCIS 2005,pages 284?293.
Springer.Anatol Rapoport, Amnon Rapoport, William P Livant,and John Boyd.
1966.
A study of lexical graphs.Foundations of Language, pages 338?376.Philip Resnik.
1997.
Selectional preference and sensedisambiguation.
In Proceedings of the ACL SIGLEXWorkshop on Tagging Text with Lexical Semantics:Why, What, and How, pages 52?57.Martin Rosvall and Carl T. Bergstrom.
2008.
Maps ofrandom walks on complex networks reveal commu-nity structure.
Proceedings of the National Academyof Sciences, 105(4):1118?1123.Martin Rosvall and Carl T. Bergstrom.
2011.
Mul-tilevel compression of random walks on networksreveals hierarchical organization in large integratedsystems.
PloS one, 6(4):e18209.Maria Ruiz-Casado, Enrique Alfonseca, and PabloCastells.
2005.
Automatic extraction of semanticrelationships for wordnet by means of pattern learn-ing from wikipedia.
In Natural Language Process-ing and Information Systems, pages 67?79.
Springer.Ekaterina Shutova, Simone Teufel, and Anna Korho-nen.
2013.
Statistical metaphor processing.
Com-putational Linguistics, 39(2):301?353.Mark Steyvers and Joshua B. Tenenbaum.
2005.
Thelarge-scale structure of semantic networks: Statisti-cal analyses and a model of semantic growth.
Cog-nitive Science, 29(1):41?78.Lin Sun and Anna Korhonen.
2009.
Improving verbclustering with automatically acquired selectionalpreferences.
In Proceedings of the 2009 Confer-ence on Empirical Methods in Natural LanguageProcessing: Volume 2-Volume 2, pages 638?647.Peter D. Turney, Patrick Pantel, et al.
2010.
Fromfrequency to meaning: Vector space models of se-mantics.
Journal of Artificial Intelligence Research,37(1):141?188.Jean V?eronis.
2004.
Hyperlex: lexical cartographyfor information retrieval.
Computer Speech & Lan-guage, 18(3):223?252.Yorick Wilks.
1975.
A preferential, pattern-seeking,semantics for natural language inference.
ArtificialIntelligence, 6(1):53?74.Yorick Wilks.
1978.
Making preferences more active.Artificial Intelligence, 11(3):197?223.55
