Dependency Structure Analysis and Sentence BoundaryDetection in Spontaneous JapaneseKazuya Shitaoka?
Kiyotaka Uchimoto?
Tatsuya Kawahara?
Hitoshi Isahara?
?School of Informatics,Kyoto UniversityYoshida-honmachi, Sakyo-ku,Kyoto 606-8501, Japan,{shitaoka,kawahara}@ar.media.kyoto-u.ac.jp?National Institute of Informationand Communications Technology3-5 Hikari-dai, Seika-cho, Soraku-gun,Kyoto 619-0289, Japan,{uchimoto,isahara}@nict.go.jpAbstractThis paper describes a project to detect dependen-cies between Japanese phrasal units called bunsetsus,and sentence boundaries in a spontaneous speechcorpus.
In monologues, the biggest problem with de-pendency structure analysis is that sentence bound-aries are ambiguous.
In this paper, we proposetwo methods for improving the accuracy of sentenceboundary detection in spontaneous Japanese speech:One is based on statistical machine translation us-ing dependency information and the other is basedon text chunking using SVM.
An F-measure of 84.9was achieved for the accuracy of sentence bound-ary detection by using the proposed methods.
Theaccuracy of dependency structure analysis was alsoimproved from 75.2% to 77.2% by using automat-ically detected sentence boundaries.
The accuracyof dependency structure analysis and that of sen-tence boundary detection were also improved by in-teractively using both automatically detected depen-dency structures and sentence boundaries.1 IntroductionThe ?Spontaneous Speech: Corpus and Pro-cessing Technology?
project has been sponsor-ing the construction of a large spontaneousJapanese speech corpus, Corpus of SpontaneousJapanese (CSJ) (Maekawa et al, 2000).
TheCSJ is the biggest spontaneous speech corpus inthe world, and it is a collection of monologuesand dialogues, the majority being monologuessuch as academic presentations.
The CSJ in-cludes transcriptions of speeches as well as audiorecordings.
Approximately one tenth of the CSJhas been manually annotated with informationabout morphemes, sentence boundaries, depen-dency structures, discourse structures, and soon.
The remaining nine tenths of the CSJhave been annotated semi-automatically.
A fu-ture goal of the project is to extract sentenceboundaries, dependency structures, and dis-course structures from the remaining transcrip-tions.
This paper focuses on methods for au-tomatically detecting sentence boundaries anddependency structures in Japanese spoken text.In many cases, Japanese dependency struc-tures are defined in terms of the dependencyrelationships between Japanese phrasal unitscalled bunsetsus.
To define dependency rela-tionships between all bunsetsus in spontaneousspeech, we need to define not only the depen-dency structures in all sentences but also theinter-sentential relationships, or, discourse re-lationships, between the sentences, as depen-dency relationships between bunsetsus.
How-ever, it is difficult to define and detect discourserelationships between sentences because of sig-nificant inconsistencies in human annotationsof discourse structures, especially with regardto spontaneous speech.
We also need to knowintra-sentential dependency structures in orderto use the results of dependency structure anal-ysis for sentence compaction in automatic textsummarization or case frame acquisition.
Be-cause it is difficult to define discourse relation-ships between sentences, depending on the ac-tual application, it is usually enough to defineand detect the dependency structure of eachsentence.
Therefore, the CSJ was annotatedwith intra-sentential dependency structures forsentences in the same way this is usually donefor a written text corpus.
However, there isa big difference between a written text corpusand a spontaneous speech corpus: In sponta-neous speech, especially when it is long, sen-tence boundaries are often ambiguous.
In theCSJ, therefore, sentence boundaries were de-fined based on clauses whose boundaries wereautomatically detected by using surface infor-mation (Maruyama et al, 2003), and they weredetected manually (Takanashi et al, 2003).
Ourdefinition of sentence boundaries follows thedefinition used in the CSJ.Almost all previous research on Japanese de-pendency structure analysis dealt with depen-dency structures in written text (Fujio and Mat-sumoto, 1998; Haruno et al, 1998; Uchimoto etal., 1999; Uchimoto et al, 2000; Kudo and Mat-sumoto, 2000).
Although Matsubara and col-leagues did investigate dependency structuresin spontaneous speech (Matsubara et al, 2002),the target speech was dialogues where the ut-terances were short and sentence boundariescould be easily defined based on turn-takingdata.
In contrast, we investigated dependencystructures in spontaneous and long speeches inthe CSJ.
The biggest problem in dependencystructure analysis with spontaneous and longspeeches is that sentence boundaries are am-biguous.
Therefore, sentence boundaries shouldbe detected before or during dependency struc-ture analysis in order to obtain the dependencystructure of each sentence.In this paper, we first describe the problemswith dependency structure analysis of sponta-neous speech.
Because the biggest problem isambiguous sentence boundaries, we focus onsentence boundary detection and propose twomethods for improving the accuracy of detec-tion.2 Dependency Structure Analysisand Sentence Boundary Detectionin Spontaneous JapaneseFirst, let us briefly describe how dependencystructures can be represented in a Japanese sen-tence.
In Japanese sentences, word order israther free, and subjects and objects are oftenomitted.
In languages having such characteris-tics, the syntactic structure of a sentence is gen-erally represented by the relationship betweenphrasal units, or bunsetsus, based on a depen-dency grammar.
Phrasal units, or bunsetsus,are minimal linguistic units obtained by seg-menting a sentence naturally in terms of seman-tics and phonetics.
Each bunsetsu consists ofone or more morphemes.
For example, the sen-tence ????????????
(kare-wa yukkuriaruite-iru, He is walking slowly)?
can be dividedinto three bunsetsus, ???
(kare-wa, he)?, ?????
(yukkuri, slowly)?
and ??????
(aruite-iru, is walking)?.
In this sentence, the first andsecond bunsetsus depend on the third one.There are many differences between writ-ten text and spontaneous speech, and thereare problems peculiar to spontaneous speechin dependency structure analysis and sentenceboundary detection.
The following sections de-scribe some typical problems and our solutions.2.1 Problems with DependencyStructure AnalysisAmbiguous sentence boundariesAs described in Section 1, in this study, weassumed that ambiguous sentence bound-aries is the biggest problem in dependencystructure analysis of spontaneous speech.So in this paper, we mainly focus on thisproblem and describe our solution to it.Independent bunsetsusIn spontaneous speech, we sometimes findthat modifiees are missing because utter-ance planning changes in the middle of thespeech.
Also, we sometimes find bunsetsuswhose dependency relationships are uselessfor understanding the utterance.
These in-clude fillers such as ????
(anoh, well)?and ????
(sonoh, well)?, adverbs thatbehave like fillers such as ???
(mou)?,responses such as ???
(hai, yes)?
and ???
(un, yes)?, conjunctions such as ??
(de, and)?, and disfluencies.
In these cases,bunsetsus are assumed to be independent,and as a result, they have no modifiees inthe CSJ.
For example, 14,988 bunsetsus in188 talks in the CSJ are independent.We cannot ignore fillers, responses, anddisfluencies because they frequently ap-pear in spontaneous speech.
However,we can easily detect them by using themethod proposed by Asahara and Mat-sumoto (Asahara and Matsumoto, 2003).In this paper, fillers, responses, and disflu-encies were eliminated before dependencystructure analysis and sentence boundarydetection by using morphological informa-tion and labels.
In the CSJ, fillers and re-sponses are interjections, and almost all ofthem are marked with label (F).
Disfluen-cies are marked with label (D).In this paper, every independent bunsetsuwas assumed to depend on the next one.However, practically speaking, indepen-dent bunsetsus should be correctly detectedas ?independent?.
This detection is one ofour future goals.Crossed dependencyIn general, dependencies in Japanese writ-ten text do not cross.
In contrast, de-pendencies in spontaneous speech some-times do.
For example, ????
(kore-ga,this)?
depends on ?????
(tadashii-to, isright)?
and ???
(watashi-wa, I)?
dependson ???
(omou, think)?
in the sentence ???????????????
?, where ??
?denotes a bunsetsu boundary.
Therefore,the two dependencies cross.However, there are few number of crosseddependencies in the CSJ: In 188 talks, wefound 689 such dependencies for total of170,760 bunsetsus.
In our experiments,therefore, we assumed that dependenciesdid not cross.
Correctly detecting crosseddependencies is one of our future goals.Self-correctionWe often find self-corrections in sponta-neous speech.
For example, in the 188 talksin the CSJ there were 2,544 self-corrections.In the CSJ, self-corrections are representedas dependency relationships between bun-setsus, and label D is assigned to them.Coordination and appositives are also rep-resented as dependency relationships be-tween bunsetsus, and labels P and A areassigned to them, respectively.
The defi-nitions of coordination and appositives fol-low those of the Kyoto University text cor-pus (Kurohashi and Nagao, 1997).
Boththe labels and the dependencies shouldbe detected for applications such as au-tomatic text summarization.
However, inthis study, we detected only the dependen-cies between bunsetsus, and we did it in thesame manner as in previous studies usingwritten text.InversionInversion occurs more frequently in spon-taneous speech than in written text.
Forexample, in the 188 talks in the CSJ therewere 172 inversions.
In the CSJ, inver-sions are represented as dependency rela-tionships going in the direction from rightto left.
In this study, we thought it impor-tant to detect dependencies, and we man-ually changed their direction to that fromleft to right.
The direction of dependencyhas been changed to that from left to right.2.2 Problems with Sentence BoundaryDetectionIn spontaneous Japanese speech, sentenceboundaries are ambiguous.
In the CSJ, there-fore, sentence boundaries were defined basedon clauses whose boundaries were automaticallydetected using surface information (Maruyamaet al, 2003), and they were detected manually(Takanashi et al, 2003).
Clause boundaries canbe classified into the following three groups.Absolute boundaries , or sentence bound-aries in their usual meaning.
Such bound-aries are often indicated by verbs in theirbasic form.Strong boundaries , or points that can be re-garded as major breaks in utterances andthat can be used for segmentation.
Suchboundaries are often indicated by clauseswhose rightmost words are ??
(ga, but)?,or ??
(shi, and)?.Weak boundaries , or points that canbe used for segmentation because theystrongly depend on other clauses.
Suchboundaries are often indicated by clauseswhose rightmost words are ???
(node, be-cause)?, or ???
(tara, if)?.These three types of boundary differ in thedegree of their syntactic and semantic com-pleteness and the dependence of their sub-sequent clauses.
Absolute boundaries andstrong boundaries are usually defined as sen-tence boundaries.
However, sentence bound-aries in the CSJ are different from these twotypes of clause boundaries, and the accuracyof rule-based automatic sentence boundary de-tection in the 188 talks in the CSJ has an F-measure of approximately 81, which is the ac-curacy for a closed test.
Therefore, we need amore accurate sentence boundary detection sys-tem.Shitaoka et al (Shitaoka et al, 2002) pro-posed a method for detecting sentence bound-aries in spontaneous Japanese speech.
Theirdefinition of sentence boundaries is approxi-mately the same as that of absolute bound-aries described above.
In this method, sen-tence boundary candidates are extracted bycharacter-based pattern matching using pauseduration.
However, it is difficult to extractappropriate candidates by this method be-cause there is a low correlation between pausesand the strong and weak boundaries describedabove.
It is also hard to detect noun-finalclauses by character-based pattern matching.One method based on machine learning, amethod based on maximum entropy models,has been proposed by Reynar and Ratnaparkhi(Reynar and Ratnaparkhi, 2000).
However, thetarget in their study was written text.
Thismethod cannot readily used for spontaneousspeech because in speech, there are no punc-tuation marks such as periods.
Other featuresof utterances should be used to detect sentenceboundaries in spontaneous speech.3 Approach of DependencyStructure Analysis and SentenceBoundary DetectionThe outline of the processes is shown in Fig-ure 1.0: MorphologicalAnalysis1: Sentence BoundaryDetection (Baseline)3: Dependency StructureAnalysis (Baseline)2: Sentence BoundaryDetection (SVM)5: Sentence BoundaryDetection (Language model)6: Sentence BoundaryDetection (SVM)7: Dependency StructureAnalysis (Again)clauseexpressionpausedurationword 3-gram modelpausedurationclauseexpressionwordinformation(A)(B)wordInformationdistancebetweenbunsetsus(C)(A) + information ofdependencies(B) + information ofdependencies4: DependencyStructure AnalysisFigure 1: Outline of dependency structure anal-ysis and sentence boundary detection.3.1 Dependency Structure AnalysisIn statistical dependency structure analysis ofJapanese speech, the likelihood of dependencyis represented by a probability estimated by adependency probability model.Given sentence S, let us assume that it isuniquely divided into n bunsetsus, b1, .
.
.
, bn,and that it is represented as an ordered set ofbunsetsus, B = {b1, .
.
.
, bn}.
Let D be an or-dered set of dependencies in the sentence and letDibe a dependency whose modifier is bunsetsubi(i = 1, .
.
.
, n ?
1).
Let us also assume thatD = {D1, .
.
.
,Dn?1}.
Statistical dependencystructure analysis finds dependencies that max-imize probability P (D|S) given sentence S.The conventional statistical model (Collins,1996; Fujio and Matsumoto, 1998; Haruno etal., 1998; Uchimoto et al, 1999) uses onlythe relationship between two bunsetsus to es-timate the probability of dependency, whereasthe model in this study (Uchimoto et al, 2000)takes into account not only the relationship be-tween two bunsetsus but also the relationshipbetween the left bunsetsu and all the bunsetsusto its right.
This model uses more informationthan the conventional model.We implemented this model within a max-imum entropy modeling framework.
The fea-tures used in the model were basically attributesof bunsetsus, such as character strings, partsof speech, and types of inflections, as well asthose that describe the relationships betweenbunsetsus, such as the distance between bun-setsus.
Combinations of these features were alsoused.
To find Dbest, we analyzed the sentencesbackwards (from right to left).
In the backwardanalysis, we can limit the search space effec-tively by using a beam search.
Sentences canalso be analyzed deterministically without greatloss of accuracy (Uchimoto et al, 1999).
So weanalyzed a sentence backwards and determinis-tically.3.2 Sentence Boundary DetectionBased on Statistical MachineTranslation (Conventional method(Shitaoka et al, 2002))The framework for statistical machine trans-lation is formulated as follows.
Given in-put sequence X, the goal of statistical ma-chine translation is to find the best output se-quence, Y , that maximizes conditional proba-bility P (Y |X):maxYP (Y |X) = maxYP (Y )P (X |Y ) (1)The problem of sentence boundary detectioncan be reduced to the problem of translat-ing a sequence of words, X, that does not in-clude periods but instead includes pauses intoa sequence of words, Y , that includes peri-ods.
Specifically, in places where a pausemight be converted into a period, which meansP (X|Y ) = 1, the decision whether a periodshould be inserted or not is made by comparinglanguage model scores P (Y ?)
and P (Y ??).
Here,the difference between Y ?
and Y ??
is in that oneincludes a period in a particular place and theother one does not.We used a model that uses pause durationand surface expressions around pauses as trans-lation model P (X|Y ).
We used expressionsaround absolute and strong boundaries as de-scribed in Section 2.2 as surface expressionsaround pauses.
A pause preceding or follow-ing surface expressions can be converted intoa period.
Specifically, pauses following expres-sions ??
(to)?, ???
(nai)?, and ??
(ta)?, andpauses preceding expression ??
(de)?, can beconverted into a period when these pauses arelonger than average.
A pause preceding or fol-lowing other surface expressions can be con-verted into a period even if its duration is short.To calculate P (Y ), we used a word 3-grammodel trained with transcriptions in the CSJ.3.3 Sentence Boundary DetectionUsing Dependency Information(Method 1)There are three assumptions that should be sat-isfied by the rightmost bunsetsu in every sen-tence.
In the following, this bunsetsu is referredto as the target bunsetsu.
(1) One or more bunsetsus depend on thetarget bunsetsu.
(Figure 2)Since every bunsetsu depends on another bun-setsu in the same sentence, the second rightmostbunsetsu always depends on the rightmost bun-setsu in any sentence, except in inverted sen-tences.
In inverted sentences in this study, wechanged the direction of all dependencies to thatfrom left to right.One or moreBunsetsus dependFigure 2: One or more bunsetsus depend onthe target bunsetsu.
(?|?
represents a sentenceboundary.
)(2) There is no bunsetsu that dependson a bunsetsu beyond the target bunsetsu.
(Figure 3)Each bunsetsu in a sentence depends on a bun-setsu in the same sentence.
(3) The probability of the target bun-setsu is low.
(Figure 4)The target bunsetsu does not depend on anybunsetsu.No bunsetsu depend in this wayFigure 3: There is no bunsetsu that depends ona bunsetsu beyond the target bunsetsu.This probability should be lowFigure 4: Probability of the target bunsetsu islow.Bunsetsus that satisfy assumptions (1)-(3)are extracted as rightmost bunsetsu candidatesin a sentence.
Then, for every point follow-ing the extracted bunsetsus and for every pausepreceding or following the expressions describedin Section 3.2, a decision is made regardingwhether a period should be inserted or not.In assumption (2), bunsetsus that depend on abunsetsu beyond 50 bunsetsus are ignored be-cause no such long-distance dependencies werefound in the 188 talks in the CSJ used in our ex-periments.
Bunsetsus whose dependency prob-ability is very low are also ignored because thereis a high possibility that these bunsetsus?
depen-dencies are incorrect.
Let this threshold proba-bility be p, and let the threshold probability inassumption (3) be q.
The optimal parameters pand q are determined by using held-out data.In this approach, about one third of allbunsetsu boundaries are extracted as sentenceboundary candidates.
So, an output sequenceis selected from all possible conversion patternsgenerated using two words to the left and twowords to the right of each sentence boundarycandidate.
To perform this operation, we useda beam search with a width of 10 because anumber of conversion patterns can be generatedwith such a search.3.4 Sentence Boundary DetectionBased on Machine Learning(Method 2)We use Support Vector Machine (SVM) as amachine learning model and we approached theproblem of sentence boundary detection as atext chunking task.
We used YamCha (Kudoand Matsumoto, 2001) as a text chunker, whichis based on SVM and uses polynomial kernelfunctions.
To determine the appropriate chunklabel for a target word, YamCha uses two wordsto the right and two words to the left of thetarget word as statistical features, and it useschunk labels that are dynamically assigned tothe two preceding or the two following wordsas dynamic features, depending on the analysisdirection.
To solve the multi-class problem, weused pairwise classification.
This method gen-erates N ?
(N ?
1)/2 classifiers for all pairs ofclasses, N , and makes a final decision by theirweighted voting.The features used in our experiments are thefollowing:1.
Morphological information of the three wordsto the right and three words to the left of thetarget word, such as character strings, pronun-ciation, part of speech, type of inflection, andinflection form2.
Pause duration normalized in terms of Maha-lanobis distance3.
Clause boundaries4.
Dependency probability of the target bunsetsu5.
The number of bunsetsus that depend on thetarget bunsetsu and their dependency proba-bilitiesWe used the IOE labeling scheme for properchunking, and the following parameters forYamCha.?
Degree of polynomial kernel: 3rd?
Analysis direction: Left to right?
Multi-class method: Pairwise4 Experiments and DiscussionIn our experiments, we used the transcriptionsof 188 talks in the CSJ.
We used 10 talks fortesting.
Dependency structure analysis resultswere evaluated for closed- and open-test data interms of accuracy, which was defined as the per-centage of correct dependencies out of all depen-dencies.
In Tables 1 to 3, we use words ?closed?and ?open?
to describe the results obtained forclosed- and open-test data, respectively.
Sen-tence boundary detection results were evaluatedin terms of F-measure.First, we show the baseline accuracy of depen-dency structure analysis and sentence boundarydetection.
The method described in Section 3.2was used as a baseline method for sentenceboundary detection (Process 1 in Figure 1).
Totrain the language model represented by P (Y ),we used the transcriptions of 178 talks exclud-ing the test data.
The method described in Sec-tion 3.1 was used as a baseline method for de-pendency structure analysis.
(Process 3 in Fig-ure 1) As sentence boundaries, we used the re-sults of the baseline method for sentence bound-ary detection.
We obtained an F-measure of75.6, a recall of 64.5%, and a precision of 94.2%for the sentence boundary detection in our ex-periments.
The dependency structure analysisaccuracy was 75.2% for the open data and 80.7%for the closed data.The dependency probability of the rightmostbunsetsus in a given sentence was not calculatedin our model.
So, we assumed that the right-most bunsetsus depended on the next bunsetsuand that the dependency probability was 0.5when we used dependency information in theexperiments described in the following sections.4.1 Sentence Boundary DetectionResults Obtained by Method 1We evaluated the results obtained by themethod described in Section 3.3.
The resultsof baseline dependency structure analysis wereused as dependency information (Process 5 inFigure 1).First, we investigated the optimal values ofparameters p and q described in Section 3.3 byusing held-out data, which differed from the testdata and consisted of 15 talks.
The optimal val-ues of p and q were, respectively, 0 and 0.9 forthe open-test data, and 0 and 0.8 for the closed-test data.
These values were used in the follow-ing experiments.
The value of p was 0, and theseresults show that bunsetsus that depended on abunsetsu beyond 50 bunsetsus were ignored asdescribed in assumption (2) in Section 3.3.The obtained results are shown in Table 1.When dependency information was used, the F-measure increased by approximately 1.4 for theopen-test data and by 2.0 for the closed testdata, respectively.
Although the accuracy of de-pendency structure analysis for closed test datawas about 5.5% higher than that for the open-test data, the difference between the accuraciesof sentence boundary detection for the closed-and open-test data was only about 0.6%.
Theseresults indicate that equivalent accuracies canbe obtained for both open- and closed-test datain detecting dependencies related to sentenceboundaries.When all the extracted candidates were con-sidered as sentence boundaries without us-ing language models, the accuracy of sentenceboundary detection obtained by using the base-line method was 68.2%(769/1,127) in recall and81.5%(769/943) in precision, and that obtainedby using Method 1 was 87.2%(983/1,127) in re-call and 27.7%(983/3,544) in precision.
The re-sults show that additional 214 sentence bound-ary candidates were correctly extracted by us-ing dependency information.
However, only108 sentence boundaries were chosen out ofthe 214 candidates when language models wereused.
We investigated in detail the pointsthat were not chosen and found errors in noun-final clauses, clauses where the rightmost con-stituents were adjectives or verbs such as ????
(it to-omou, think)?
or ?????
(it wa-muzukashii, difficult)?, and clauses where therightmost constituents were ??????
(it to-Table 1: Sentence boundary detection resultsobtained by using dependency information.recall precision FWith dependency 74.1% 82.5% 78.0information (open) (835/1,127) (835/1,012)With dependency 74.2% 83.5% 78.6information (closed) (836/1,127) (836/1,001)baseline 64.5% 94.2% 76.6(727/1,127) (727/772)iu-no-wa, because)?
and ?????
(it to-si-te-wa, as)?, and so on.
Some errors, except forthose in noun-final clauses, could have been cor-rectly detected if we had had more trainingdata.We also found that periods were sometimeserroneously inserted when preceding expres-sions were ??
(ga, but)?, ????
(mashite,and)?, and ?????
(keredomo, but)?, whichare typically the rightmost constituents of a sen-tence, as weel as ??
(te, and)?, which is not,typically, the rightmost constituent of a sen-tence.
The language models were not good atdiscriminating between subtle differences.4.2 Sentence Boundary DetectionResults Obtained by Method 2We evaluated the results obtained by themethod described in Section 3.4 (Process 6 inFigure 1).
For training, we used 178 talks ex-cluding test data.The results are shown in Table 2.
The F-measure was about 6.9 points higher than thatdescribed in Section 4.1.
The results showthat the approach based on machine learningis more effective than that based on statisti-cal machine translation.
The results also showthat the accuracy of sentence boundary detec-tion can be increased by using dependency in-formation in Method 2.
However, we found thatthe amount of accuracy improvement achievedby using dependency information depended onthe method used.
This may be because otherfeatures used in SVM may provide informationsimilar to dependency information.
For exam-ple, Feature 1 described in Section 3.4 mightprovide information similar to that in Features4 and 5.
Although in our experiments we usedonly three words to the right and three wordsto the left of the target word, the degradationin accuracy without dependency informationwas slight.
This may be because long-distancedependencies may not be related to sentenceboundaries, or because Feature 5 does not con-tribute to increasing the accuracy because theaccuracy of dependency structure analysis in de-tecting long-distance dependencies is not high.Table 2: Sentence boundary detection resultsobtained by using SVM.recall precision FWith dependency 80.0% 90.3% 84.9information (open) (902/1,127) (902/999)With dependency 79.7% 90.5% 84.9information (closed) (900/1,127) (900/994)Without 79.3% 90.1% 84.4dependency information (894/1,127) (894/992)Table 3: Dependency structure analysis resultsobtained with automatically detected sentenceboundaries.open closedWith results in Section 4.1 75.8% 81.2%With results in Section 4.2 77.2% 82.5%Baseline 75.2% 80.7%4.3 Dependency Structure AnalysisResultsWe evaluated the results of dependency struc-ture analysis obtained when sentence bound-aries detected automatically by the two meth-ods described above were used as inputs (Pro-cess 7 in Figure 1).
The results are shown inTable 3.
The accuracy of dependency structureanalysis improved by about 2% when the mostaccurate and automatically detected sentenceboundaries were used as inputs.
This is be-cause more sentence boundaries were detectedcorrectly, and the number of bunsetsus that de-pended on those in other sentences decreased.We investigated the accuracy of dependencystructure analysis when 100% accurate sentenceboundaries were used as inputs.
The accuracywas 80.1% for the open-test data, and 86.1%for the closed-test data.
Even when the sen-tence boundary detection was perfect, the er-ror rate was approximately 14% even for theclosed-test data.
The accuracy of dependencystructure analysis for spoken text was about 8%lower than that for written text (newspapers).We speculate that this is because spoken texthas no punctuation marks and many bunsetsusdepend on others far from them because of in-sertion structures.
These problems need to beaddressed in future studies.5 ConclusionThis paper described a project to detect depen-dencies between bunsetsus and sentence bound-aries in a spontaneous speech corpus.
It ismore difficult to detect dependency structuresin spontaneous spoken speech than in writtentext.
The biggest problem is that sentenceboundaries are ambiguous.
We proposed twomethods for improving the accuracy of sentenceboundary detection in spontaneous Japanesespeech.
Using these methods, we obtained anF-measure of 84.9 for the accuracy of sentenceboundary detection.
The accuracy of depen-dency structure analysis was also improved from75.2% to 77.2% by using automatically detectedsentence boundaries.
The accuracy of depen-dency structure analysis and that of sentenceboundary detection were improved by interac-tively using automatically detected dependencyinformation and sentence boundaries.There are several future directions.
In the fu-ture, we would like to solve the problems thatwe found in our experiments.
In particular, wewant to reduce the number of errors due to in-serted structures and solve other problems de-scribed in Section 2.1.ReferencesMasayuki Asahara and Yuji Matsumoto.
2003.
Filler andDisfluency Identification Based on Morphological Analysisand Chunking.
In Proceedings of the ISCA & IEEE Work-shop on Spontaneous Speech Processing and Recognition,pages 163?166.Michael Collins.
1996.
A New Statistical Parser Based onBigram Lexical Dependencies.
In Proceedings of the ACL,pages 184?191.Masakazu Fujio and Yuji Matsumoto.
1998.
Japanese Depen-dency Structure Analysis based on Lexicalized Statistics.In Proceedings of the EMNLP, pages 87?96.Masahiko Haruno, Satoshi Shirai, and Yoshifumi Ooyama.1998.
Using Decision Trees to Construct a PracticalParser.
In Proceedings of the COLING-ACL, pages 505?511.Taku Kudo and Yuji Matsumoto.
2000.
Japanese Depen-dency Structure Analysis Based on Support Vector Ma-chines.
In Proceedings of the EMLNP, pages 18?25.Taku Kudo and Yuji Matsumoto.
2001.
Chunking with sup-port vector machines.
In Proceedings of the NAACL.Sadao Kurohashi and Makoto Nagao.
1997.
Building aJapanese Parsed Corpus while Improving the Parsing Sys-tem.
In Proceedings of the NLPRS, pages 451?456.Kikuo Maekawa, Hanae Koiso, Sadaoki Furui, and HitoshiIsahara.
2000.
Spontaneous Speech Corpus of Japanese.In Proceedings of the LREC2000, pages 947?952.Takehiko Maruyama, Hideki Kashioka, Tadashi Kumano, andHideki tanaka.
2003.
Rules for Automatic Clause Bound-ary Detection and Their Evaluation.
In Proceedings ofthe Nineth Annual Meeting of the Association for NaturalLanguage proceeding, pages 517?520.
(in Japanese).Shigeki Matsubara, Takahisa Murase, Nobuo Kawaguchi, andYasuyoshi Inagaki.
2002.
Stochastic Dependency Parsingof Spontaneous Japanese Spoken Language.
In Proceedingsof the COLING2002, pages 640?645.Jeffrey C. Reynar and Adwait Ratnaparkhi.
2000.
A Max-imum Entropy Approach to Identifying Sentence Bound-aries.
In Proceedings of the ANLP, pages 16?19.Kazuya Shitaoka, Tatsuya Kawahara, and Hiroshi G. Okuno.2002.
Automatic Transformation of Lecture Transcrip-tion into Document Style using Statistical Framework.
InIPSJ?WGSLP SLP-41-3, pages 17?24.
(in Japanese).Katsuya Takanashi, Takehiko Maruyama, Kiyotaka Uchi-moto, and Hitoshi Isahara.
2003.
Identification of ?Sen-tences?
in Spontaneous Japanese ?
Detection and Mod-ification of Clause Boundaries ?.
In Proceedings of theISCA & IEEE Workshop on Spontaneous Speech Process-ing and Recognition, pages 183?186.Kiyotaka Uchimoto, Satoshi Sekine, and Hitoshi Isahara.1999.
Japanese Dependency Structure Analysis Based onMaximum Entropy Models.
In Proceedings of the EACL,pages 196?203.Kiyotaka Uchimoto, Masaki Murata, Satoshi Sekine, and Hi-toshi Isahara.
2000.
Dependency Model Using PosteriorContext.
In Proceedings of the IWPT, pages 321?322.
