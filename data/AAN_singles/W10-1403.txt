Proceedings of the NAACL HLT 2010 First Workshop on Statistical Parsing of Morphologically-Rich Languages, pages 22?30,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsTwo methods to incorporate local morphosyntactic features in Hindi de-pendency parsingBharat Ram Ambati, Samar Husain, Sambhav Jain, Dipti Misra Sharmaand Rajeev SangalLanguage Technologies Research Centre, IIIT-Hyderabad, India - 500032.
{ambati,samar}@research.iiit.ac.in, sambhav-jain@students.iiit.ac.in,{dipti,sangal}@mail.iiit.ac.inAbstractIn this paper we explore two strategies to in-corporate local morphosyntactic features inHindi dependency parsing.
These features areobtained using a shallow parser.
We first ex-plore which information provided by the shal-low parser is most beneficial and show thatlocal morphosyntactic features in the form ofchunk type, head/non-head information,chunk boundary information, distance to theend of the chunk and suffix concatenation arevery crucial in Hindi dependency parsing.
Wethen investigate the best way to incorporatethis information during dependency parsing.Further, we compare the results of various ex-periments based on various criterions and dosome error analysis.
All the experiments weredone with two data-driven parsers, MaltParserand MSTParser, on a part of multi-layered andmulti-representational Hindi Treebank whichis under development.
This paper is also thefirst attempt at complete sentence level pars-ing for Hindi.1 IntroductionThe dependency parsing community has since afew years shown considerable interest in parsingmorphologically rich languages with flexible wordorder.
This is partly due to the increasing availabil-ity of dependency treebanks for such languages,but it is also motivated by the observation that theperformance obtained for these languages have notbeen very high (Nivre et al, 2007a).
Attempts athandling various non-configurational aspects inthese languages have pointed towards shortcom-ings in traditional parsing methodologies (Tsarfatyand Sima'an, 2008; Eryigit et al, 2008; Seddah etal., 2009; Husain et al, 2009; Gadde et al, 2010).Among other things, it has been pointed out thatthe use of language specific features may play acrucial role in improving the overall parsing per-formance.
Different languages tend to encode syn-tactically relevant information in different ways,and it has been hypothesized that the integration ofmorphological and syntactic information could bea key to better accuracy.
However, it has also beennoted that incorporating these language specificfeatures in parsing is not always straightforwardand many intuitive features do not always work inexpected ways.In this paper we explore various strategies to in-corporate local morphosyntactic features in Hindidependency parsing.
These features are obtainedusing a shallow parser.
We conducted experimentswith two data-driven parsers, MaltParser (Nivre etal., 2007b) and MSTParser (McDonald et al,2006).
We first explore which information pro-vided by the shallow parser is most beneficial andshow that local morphosyntactic features in theform of chunk type, head/non-head information,chunk boundary information, distance to the end ofthe chunk and suffix concatenation are very crucialin Hindi dependency parsing.
We then investigatethe best way to incorporate this information duringdependency parsing.
All the experiments weredone on a part of multi-layered and multi-representational Hindi Treebank (Bhatt et al,2009)1.The shallow parser performs three tasks, (a) itgives the POS tags for each lexical item, (b) pro-vides morphological features for each lexical item,and (c) performs chunking.
A chunk is a minimal(non-recursive) phrase consisting of correlated,inseparable words/entities, such that the intra-chunk dependencies are not distorted (Bharati et1 This Treebank is still under development.
There are currently27k tokens with complete sentence level annotation.22al., 2006).
Together, a group of lexical items withsome POS tag and morphological features within achunk can be utilized to automatically computelocal morphosyntactic information.
For example,such information can represent the postposi-tion/case-marking in the case of noun chunks, or itmay represent the tense, aspect and modality(TAM) information in the case of verb chunks.
Inthe experiments conducted for this paper such localinformation is automatically computed and incor-porated as a feature to the head of a chunk.
In gen-eral, local morphosyntactic features correspond toall the parsing relevant local linguistic features thatcan be utilized using the notion of chunk.
Previous-ly, there have been some attempts at using chunkinformation in dependency parsing.
Attardi andDell?Orletta (2008) used chunking information inparsing English.
They got an increase of 0.35% inlabeled attachment accuracy and 0.47% in unla-beled attachment accuracy over the state-of-the-artdependency parser.Among the three components (a-c, above), theparsing accuracy obtained using the POS feature istaken as baseline.
We follow this by experimentswhere we explore how each of morph and chunkfeatures help in improving dependency parsingaccuracy.
In particular, we find that local morpho-syntactic features are the most crucial.
These expe-riments are discussed in section 2.
In section 3 wewill then see an alternative way to incorporate thebest features obtained in section 2.
In all the pars-ing experiments discussed in section 2 and 3, ateach step we explore all possible features and ex-tract the best set of features.
Best features of oneexperiment are used when we go to the next set ofexperiments.
For example, when we explore theeffect of chunk information, all the relevant morphinformation from previous set of experiments istaken into account.This paper is also the first attempt at completesentence level parsing for Hindi.
Due to the availa-bility of dependency treebank for Hindi (Begum etal., 2008), there have been some previous attemptsat Hindi data-driven dependency parsing (Bharatiet al, 2008; Mannem et al, 2009; Husain et al,2009).
Recently in ICON-09 NLP Tools Contest(Husain, 2009; and the references therein), rule-based, constraint based, statistical and hybrid ap-proaches were explored for dependency parsing.Previously, constraint based approaches to Indianlanguage (IL) dependency parsing have also beenexplored (Bharati et al, 1993, 1995, 2009b,2009c).
All these attempts, however, were findinginter-chunk dependency relations, given gold-standard POS and chunk tags.
Unlike these pre-vious parsers, the dependencies in this work arebetween lexical items, i.e.
the dependency tree iscomplete.The paper is arranged as follows, in section 2and 3, we discuss the parsing experiments.
In sec-tion 4, we describe the data and parser settings.Section 5 gives the results and discusses some re-lated issues.
General discussion and possible futurework is mentioned in section 6.
We conclude thepaper in section 7.2 Getting the best linguistic featuresAs mentioned earlier, a shallow parser consists ofthree main components, (a) POS tagger, (b) mor-phological analyzer and (c) chunker.
In this sectionwe systematically explore what is the effect ofeach of these components.
We?ll see in section 2.3that the best features of a-c can be used to computelocal morphosyntactic features that, as the resultsshow, are extremely useful.2.1 Using POS as feature (PaF):In this experiment we only use the POS tag infor-mation of individual words during dependencyparsing.
First a raw sentence is POS-tagged.
ThisPOS-tagged sentence is then given to a parser topredict the dependency relations.
Figure 1, showsthe steps involved in this approach for (1).
(1)  raama   ne         eka     seba        khaayaa?Ram?
ERG    ?one?
?apple?
?ate?
?Ram ate an apple?Figure 1: Dependency parsing using only POS informa-tion from a shallow parser.23In (1) above, ?NN?, ?PSP?, ?QC?, ?NN?
and ?VM?are the POS tags2 for raama, ne, eka, seba andkhaayaa respectively.
This information is providedas a feature to the parser.
The result of this experi-ment forms our baseline accuracy.2.2 Using Morph as feature (MaF):In addition to POS information, in this experimentwe also use the morph information for each token.This morphological information is provided as afeature to the parser.
Morph has the following in-formation?
Root: Root form of the word?
Category: Course grained POS?
Gender: Masculine/Feminine/Neuter?
Number: Singular/Plural?
Person: First/Second/Third person?
Case: Oblique/Direct case?
Suffix: Suffix of the wordTake raama in (1), its morph information com-prises of root = ?raama?, category = ?noun?
gender= ?masculine?, number = ?singular?, person =?third?, case = ?direct?, suffix = ?0?.
Similarly,khaayaa (?ate?)
has the following morph informa-tion.
root = ?khaa?, category = ?verb?
gender =?masculine?, numer = ?singular?, person = ?third?,case = ?direct?, suffix = ?yaa?.Through a series of experiments, the most cru-cial morph features were selected.
Root, case andsuffix turn out to be the most important features.Results are discussed in section 5.2.3 Using local morphosyntax as feature(LMSaF)Along with POS and the most useful morph fea-tures (root, case and suffix), in this experiment wealso use local morphosyntactic features that reflectvarious chunk level information.
These featuresare:?
Type of the chunk?
Head/non-head of the chunk2 NN: Common noun, PSP: Post position, QC: Cardinal, VM:Verb.
A list of complete POS tags can be found here:http://ltrc.iiit.ac.in/MachineTrans/research/tb/POS-Tag-List.pdf.
The POS/chunk tag scheme followed in the Treebankis described in Bharati et al (2006).?
Chunk boundary information?
Distance to the end of the chunk?
Suffix concatenationIn example 1 (see section 2.1), there are twonoun chunks and one verb chunk.
raama and sebaare the heads of the noun chunks.
khaayaa is thehead of the verb chunk.
We follow standard IOB3notation for chunk boundary.
raama,  eka andkhaayaa are at the beginning (B) of their respectivechunks.
ne and seba are inside (I) their respectivechunks.
raama is at distance 1 from the end of thechunk and ne is at a distance 0 from the end of thechunk.Once we have a chunk and morph feature likesuffix, we can perform suffix concatenation auto-matically.
A group of lexical items with some POStags and suffix information within a chunk can beutilized to automatically compute this feature.
Thisfeature can, for example, represent the postposi-tion/case-marking in the case of noun chunk, or itmay represent the tense, aspect and modality(TAM) information in the case of verb chunks.Note that, this feature becomes part of the lexicalitem that is the head of a chunk.
Take (2) as a casein point:(2) [NP raama/NNP   ne/PSP]     [NP seba/NN]?Ram?
ERG                ?apple?
[VGF khaa/VM     liyaa/VAUX]?eat?
?PRFT?
?Ram ate an apple?The suffix concatenation feature for khaa, whichis the head of the VGF chunk, will be ?0+yaa?
andis formed by concatenating the suffix of the mainverb with that of its auxiliary.
Similarly, the suffixconcatenation feature for raama, which is head ofthe NP chunk, will be ?0+ne?.
This feature turnsout to be very important.
This is because in Hindi(and many other Indian languages) there is a directcorrelation between the TAM markers and the casethat appears on some nominals (Bharati et al,1995).
In (2), for example, khaa liyaa togethergives the past perfective aspect for the verb khaa-naa ?to eat?.
Since, Hindi is split ergative, the sub-ject of the transitive verb takes an ergative casemarker when the verb is past perfective.
Similar3 Inside, Outside, Beginning of the chunk.24correlation between the case markers and TAMexist in many other cases.3 An alternative approach to use best fea-tures: A 2-stage setup (2stage)So far we have been using various informationsuch as POS, chunk, etc.
as features.
Rather thanusing them as features and doing parsing at one go,we can alternatively follow a 2-stage setup.
In par-ticular, we divide the task of parsing into:?
Intra-chunk dependency parsing?
Inter-chunk dependency parsingWe still use POS, best morphological features(case, suffix, root) information as regular featuresduring parsing.
But unlike LMSaF mentioned insection 2.3, where we gave local morphosyntacticinformation as a feature, we divided the task ofparsing into sub-tasks.
A similar approach was alsoproposed by Bharati et al (2009c).
During intra-chunk dependency parsing, we try to find the de-pendency relations of the words within a chunk.Following which, chunk heads of each chunk with-in a sentence are extracted.
On these chunk headswe run an inter-chunk dependency parser.
For eachchunk head, in addition to POS tag, useful morpho-logical features, any useful intra-chunk informationin the form of lexical item, suffix concatenation,dependency relation are also given as a feature.Figure 2: Dependency parsing using chunk information:2-stage approach.Figure 2 shows the steps involved in this ap-proach for (1).
There are two noun chunks and oneverb chunk in this sentence.
raama and seba arethe heads of the noun chunks.
khaaya is the headof the verb chunk.
The intra-chunk parser attachesne to raama and eka to seba with dependency la-bels ?lwg__psp?
and ?nmod__adj?4 respectively.Heads of each chunk along with its POS, morpho-logical features, local morphosyntactic features andintra-chunk features are extracted and given to in-ter-chunk parser.
Using this information the inter-chunk dependency parser marks the dependencyrelations between chunk heads.
khaaya becomesthe root of the dependency tree.
raama and sebaare attached to khaaya with dependency labels ?k1?and ?k2?5 respectively.4 Experimental SetupIn this section we describe the data and the parsersettings used for our experiments.4.1 DataFor our experiments we took 1228 dependencyannotated sentences (27k tokens), which havecomplete sentence level annotation from the newmulti-layered and multi-representational HindiTreebank (Bhatt et al, 2009).
This treebank is stillunder development.
Average length of these sen-tences is 22 tokens/sentence and 10chunks/sentence.
We divided the data into twosets, 1000 sentences for training and 228 sentencesfor testing.4.2 Parsers and settingsAll experiments were performed using two data-driven parsers, MaltParser6 (Nivre et al, 2007b),and MSTParser7 (McDonald et al, 2006).4 nmod__adj is an intra-chunk label for quantifier-noun mod-ification.
lwg__psp is the label for post-position marker.
De-tails of the labels can be seen in the intra-chunk guidelineshttp://ltrc.iiit.ac.in/MachineTrans/research/tb/IntraChunk-Dependency-Annotation-Guidelines.pdf5 k1 (karta) and k2 (karma) are syntactico-semantic labelswhich have some properties of both grammatical roles andthematic roles.
k1 behaves similar to subject and agent.
k2behaves similar to object and patient (Bharati et al, 1995;Vaidya et al, 2009).
For complete tagset, see (Bharati et al,2009).6 Malt Version 1.3.17 MST Version 0.4b25Malt MST+MaxEntCross-validation Test-set Cross-validation Test-setUAS LAS LS UAS LAS LS UAS LAS LS UAS LAS LSPaF 89.4 78.2 80.5 90.4 80.1 82.4 86.3 75.1 77.9 87.9 77.0 79.3MaF 89.6 80.5 83.1 90.4 81.7 84.1 89.1 79.2 82.5 90.0 80.9 83.9LMSaF 91.5 82.7 84.7 91.8 84.0 86.2 90.8 79.8 82.0 92.0 81.8 83.82stage 91.8 83.3 85.3 92.4 84.4 86.3 92.1 82.2 84.3 92.7 84.0 86.2Table 1: Results of all the four approaches using gold-standard shallow parser information.Malt is a classifier based shift/reduce parser.
Itprovides option for six parsing algorithms, namely,arc-eager, arc-standard, convington projective, co-vington non-projective, stack projective, stack ea-ger and stack lazy.
The parser also provides optionfor libsvm and liblinear learning model.
It usesgraph transformation to handle non-projective trees(Nivre and Nilsson, 2005).
MST uses Chu-Liu-Edmonds (Chu and Liu, 1965; Edmonds, 1967)Maximum Spanning Tree algorithm for non-projective parsing and Eisner's algorithm for pro-jective parsing (Eisner, 1996).
It uses online largemargin learning as the learning algorithm (McDo-nald et al, 2005).
In this paper, we use MST onlyfor unlabeled dependency tree and use a separatemaximum entropy model8 (MaxEnt) for labeling.Various combination of features such as node, itsparent, siblings and children were tried out beforearriving at the best results.As the training data size is small we did 5-foldcross validation on the training data for tuning theparameters of the parsers and for feature selection.Best settings obtained using cross-validated dataare applied on test set.
We present the results bothon cross validated data and on test data.For the Malt Parser, arc-eager algorithm gavebetter performance over others in all the approach-es.
Libsvm consistently gave better performanceover liblinear in all the experiments.
For SVM set-tings, we tried out different combinations of bestSVM settings of the same parser on different lan-guages in CoNLL-2007 shared task (Hall et al,2007) and applied the best settings.
For featuremodel, apart from trying best feature settings of thesame parser on different languages in CoNLL-2007 shared task (Hall et al, 2007), we also triedout different combinations of linguistically intui-tive features and applied the best feature model.The best feature model is same as the feature mod-el used in Ambati et al (2009a), which is the best8 http://maxent.sourceforge.net/performing system in the ICON-2009 NLP ToolsContest (Husain, 2009).For the MSTParser, non-projective algorithm,order=2 and training-k=5 gave best results in allthe approaches.
For the MaxEnt, apart from somegeneral useful features, we experimented consider-ing different combinations of features of node, par-ent, siblings, and children of the node.5 Results and AnalysisAll the experiments discussed in section 2 and 3were performed considering both gold-standardshallow parser information and automatic shallowparser9 information.
Automatic shallow parser usesa rule based system for morph analysis, aCRF+TBL based POS-tagger and chunker.
Thetagger and chunker are 93% and 87% accurate re-spectively.
These accuracies are obtained after us-ing the approach of PVS and Gali, (2007) on largertraining data.
In addition, while using automaticshallow parser information to get the results, wealso explored using both gold-standard and auto-matic information during training.
As expected,using automatic shallow parser information fortraining gave better performance than using goldwhile training.Table 1 and Table 2 shows the results of the fourexperiments using gold-standard and automaticshallow parser information respectively.
We eva-luated our experiments based on unlabeled attach-ment score (UAS), labeled attachment score (LAS)and labeled score (LS) (Nivre et al, 2007a).
BestLAS on test data is 84.4% (with 2stage) and 75.4%(with LMSaF) using gold and automatic shallowparser information respectively.
These results areobtained using MaltParser.
In the following sub-section we discuss the results based on differentcriterion.9 http://ltrc.iiit.ac.in/analyzer/hindi/26Malt MST+MaxEntCross-validation Test-set Cross-validation Test-setUAS LAS LS UAS LAS LS UAS LAS LS UAS LAS LSPaF 82.2 69.3  73.4  84.6  72.9  76.5  79.4  66.5  70.7  81.6  69.4  73.1MaF 82.5 71.6  76.1  84.0  73.6  77.6  82.3  70.4  75.4  83.4  72.7  77.3LMSaF 83.2 73.0  77.0  85.5  75.4  78.9  82.6  71.3  76.1  85.0  73.4  77.32stage 79.0 69.5 75.6 79.6 71.1 76.8 78.8  66.6  72.6 80.1  69.7  75.4Table 2: Results of all the four experiments using automatic shallow parser information.POS tags provide very basic linguistic informa-tion in the form of broad grained categories.
Thebest LAS for PaF while using gold and automatictagger were 80.1% and 72.9% respectively.
Themorph information in the form of case, suffix androot information proved to be the most importantfeatures.
But surprisingly, gender, number and per-son features didn?t help.
Agreement patterns inHindi are not straightforward.
For example, theverb agrees with k2 if the k1 has a post-position; itmay also sometimes take the default features.
In apassive sentence, the verb agrees only with k2.
Theagreement problem worsens when there is coordi-nation or when there is a complex verb.
It is un-derstandable then that the parser is unable to learnthe selective agreement pattern which needs to befollowed.LMSaF on the other hand encode richer infor-mation and capture some local linguistic patterns.The first four features in LMSaF (chunk type,chunk boundary, head/non-head of chunk and dis-tance to the end of chunk) were found to be usefulconsistently.
The fifth feature, in the form of suffixconcatenation, gave us the biggest jump, and cap-tures the correlation between the TAM markers ofthe verbs and the case markers on the nominals.5.1 Feature comparison: PaF, MaF vs.LMSaFDependency labels can be classified as two typesbased on their nature, namely, inter-chunk depen-dency labels and intra-chunk labels.
Inter-chunkdependency labels are syntacto-semantic in nature.Whereas intra-chunk dependency labels are purelysyntactic in nature.Figure 3, shows the f-measure for top six inter-chunk and intra-chunk dependency labels for PaF,MaF, and LMSaF using Maltparser on test datausing automatic shallow parser information.
Thefirst six labels (k1, k2, pof, r6, ccof, and k7p) arethe top six inter-chunk labels and the next six la-bels (lwg__psp, lwg__aux, lwg__cont, rsym,nmod__adj, and pof__cn) are the top six intra-chunk labels.
First six labels (inter-chunk) corres-pond to 28.41% and next six labels (intra-chunk)correspond to 48.81% of the total labels in the testdata.
The figure shows that with POS informationalone, f-measure for top four intra-chunk labelsreached more than 90% accuracy.
The accuracyincreases marginally with the addition of morphand local morphosytactic features.
The results cor-roborates with our intuition that intra-chunk de-pendencies are mostly syntactic.
For example,consider an intra-chunk label ?lwg__psp?.
This isthe label for postposition marker.
A post-positionmarker succeeding a noun is attached to that nounwith the label ?lwg__psp?.
POS tag for post-position marker is PSP.
So, if a NN (commonnoun) or a NNP (proper noun) is followed by aPSP (post-position marker), then the PSP will beattached to the preceding NN/NNP with the de-pendency label ?lwg_psp?.
As a result, providingPOS information itself gave an f-measure of 98.3%for ?lwg_psp?.
With morph and local morphosy-tactic features, this got increased to 98.4%.
How-ever, f-measure for some labels like ?nmod__adj?is around 80% only.
?nmod__adj?
is the label foradjective-noun, quantifier-noun modifications.Low accuracy for these labels is mainly due to tworeasons.
One is POS tag errors.
And the other isattachment errors due to genuine ambiguities suchas compounding.For inter-chunk labels (first six columns in thefigure 3), there is considerable improvement in thef-measure using morph and local morphosytacticfeatures.
As mentioned, local morphosyntactic fea-tures provide local linguistic information.
For ex-ample, consider the case of verbs.
At POS level,there are only two tags ?VM?
and ?VAUX?
formain verbs and auxiliary verbs respectively (Bha-rati et al, 2006).
Information about finite/non-finiteness is not present in the POS tag.
But, atchunk level there are four different chunk tags for2730405060708090100k1 k2 pof r6 ccof k7p lwg__psp lwg__vaux lwg__cont rsym nmod__adj pof__cnPaFMaFLMaFFigure 3: F-measure of top 6, inter-chunk and intra-chunk labels for PaF, MaF and LMSaF approaches using Malt-parser on test data using automatic shallow parser information.verbs, namely VGF, VGNF, VGINF and VGNN.They are respectively, finite, non-finite, infinitivaland gerundial chunk tags.
The difference in theverbal chunk tag is a good cue for helping theparser in identifying different syntactic behavior ofthese verbs.
Moreover, a finite verb can becomethe root of the sentence, whereas a non-finite orinfinitival verb can?t.
Thus, providing chunk in-formation also helped in improving the correctidentification of the root of the sentence.Similar to Prague Treebank (Hajicova, 1998),coordinating conjuncts are heads in the treebankthat we use.
The relation between a conjunct andits children is shown using ?ccof?
label.
A coordi-nating conjuct takes children of similar type only.For example, a coordinating conjuct can have twofinite verbs or two non-finite verbs as its children,but not a finite verb and a non-finite verb.
Suchinstances are also handled more effectively ifchunk information is incorporated.
The largest in-crease in performance, however, was due to the?suffix concatenation?
feature.
Significant im-provement in the core inter-chunk dependency la-bels (such as k1, k2, k4, etc.)
due to this feature isthe main reason for the overall improvement in theparsing accuracy.
As mentioned earlier, this is be-cause this feature captures the correlation betweenthe TAM markers of the verbs and the case mark-ers on the nominals.5.2 Approach comparison: LMSaF vs. 2stageBoth LMSaF and 2stage use chunk information.
InLMSaF, chunk information is given as a featurewhereas in 2stage, sentence parsing is divided intointra-chunk and inter-chunk parsing.
Both the ap-proaches have their pros and cons.
In LMSaF aseverything is done in a single stage there is muchricher context to learn from.
In 2stage, we can pro-vide features specific to each stage which can?t bedone in a single stage approach (McDonald et al,2006).
But in 2stage, as we are dividing the task,accuracy of the division and the error propagationmight pose a problem.
This is reflected in the re-sults where the 2-stage performs better than thesingle stage while using gold standard information,but lags behind considerably when the features areautomatically computed.During intra-chunk parsing in the 2stage setup,we tried out using both a rule-based approach anda statistical approach (using MaltParser).
The rulebased system performed slightly better (0.1%LAS) than statistical when gold chunks are consi-dered.
But, with automatic chunks, the statisticalapproach outperformed rule-based system with adifference of 7% in LAS.
This is not surprisingbecause, the rules used are very robust and mostlybased on POS and chunk information.
Due to er-rors induced by the automatic POS tagger andchunker, the rule-based system couldn?t performwell.
Consider a small example chunk given be-low.
((    NPmeraa ?my?
PRPbhaaii ?brother?
NN))As per the Hindi chunking guidelines (Bharati etal., 2006), meraa and bhaaii should be in two sepa-rate chunks.
And as per Hindi dependency annota-tion guidelines (Bharati et al, 2009), meraa isattached to bhaaii with a dependency label ?r6?10.When the chunker wrongly chunks them in a single10?r6?
is the dependency label for genitive relation.28chunk, intra-chunk parser will assign the depen-dency relation for meraa.
Rule based system cannever assign ?r6?
relation to meraa as it is an inter-chunk label and the rules used cannot handle suchcases.
But in a statistical system, if we train theparser using automatic chunks instead of goldchunks, the system can potentially assign ?r6?
la-bel.5.3 Parser comparison: MST vs. MaltIn all the experiments, results of MaltParser areconsistently better than MST+MaxEnt.
We knowthat Maltparser is good at short distance labelingand MST is good at long distance labeling (McDo-nald and Nivre, 2007).
The root of the sentence isbetter identified by MSTParser than MaltParser.Our results also confirm this.
MST+MaxEnt andMalt could identify the root of the sentence with anf-measure of 89.7% and 72.3% respectively.
Pres-ence of more short distance labels helped Malt tooutperform MST.
Figure 5, shows the f-measurerelative to dependency length for both the parserson test data using automatic shallow parser infor-mation for LMSaF.304050607080901000 5 10 15+Dependency Lengthf-measureMaltMST+MaxEntFigure 5: Dependency arc f-measure relative to depen-dency length.6 Discussion and Future WorkWe systematically explored the effect of variouslinguistic features in Hindi dependency parsing.Results show that POS, case, suffix, root, alongwith local morphosyntactic features help depen-dency parsing.
We then described 2 methods toincorporate such features during the parsingprocess.
These methods can be thought as differentparadigms of modularity.
For practical reasons (i.e.given the POS tagger/chunker accuracies), it iswiser to use this information as features rather thandividing the task into two stages.As mentioned earlier, this is the first attempt atcomplete sentence level parsing for Hindi.
So, wecannot compare our results with previous attemptsat Hindi dependency parsing, due to, (a) The dataused here is different and (b) we produce completesentence parses rather than chunk level parses.As mentioned in section 5.1, accuracies of intra-chunk dependencies are very high compared tointer-chunk dependencies.
Inter-chunk dependen-cies are syntacto-semantic in nature.
The parserdepends on surface syntactic cues to identify suchrelations.
But syntactic information alone is alwaysnot sufficient, either due to unavailability or due toambiguity.
In such cases, providing some semanticinformation can help in improving the inter-chunkdependency accuracy.
There have been attempts atusing minimal semantic information in dependencyparsing for Hindi (Bharati et al, 2008).
Recently,Ambati et al (2009b) used six semantic featuresnamely, human, non-human, in-animate, time,place, and abstract for Hindi dependency parsing.Using gold-standard semantic features, theyshowed considerable improvement in the core in-ter-chunk dependency accuracy.
Some attempts atusing clause information in dependency parsing forHindi (Gadde et al, 2010) have also been made.These attempts were at inter-chunk dependencyparsing using gold-standard POS tags and chunks.We plan to see their effect in complete sentenceparsing using automatic shallow parser informationalso.7 ConclusionIn this paper we explored two strategies to incorpo-rate local morphosyntactic features in Hindi de-pendency parsing.
These features were obtainedusing a shallow parser.
We first explored whichinformation provided by the shallow parser is use-ful  and showed that local morphosyntactic fea-tures in the form of chunk type, head/non-headinfo, chunk boundary info, distance to the end ofthe chunk and suffix concatenation are very crucialfor Hindi dependency parsing.
We then investi-gated the best way to incorporate this informationduring dependency parsing.
Further, we comparedthe results of various experiments based on variouscriterions and did some error analysis.
This paperwas also the first attempt at complete sentence lev-el parsing for Hindi.29ReferencesB.
R. Ambati, P. Gadde, and K. Jindal.
2009a.
Experi-ments in Indian Language Dependency Parsing.
InProc of the ICON09 NLP Tools Contest: Indian Lan-guage Dependency Parsing, pp 32-37.B.
R. Ambati, P. Gade, C. GSK and S. Husain.
2009b.Effect of Minimal Semantics on Dependency Pars-ing.
In Proc of RANLP09 student paper workshop.G.
Attardi and F. Dell?Orletta.
2008.
Chunking and De-pendency Parsing.
In Proc of LREC Workshop onPartial Parsing: Between Chunking and Deep Pars-ing.
Marrakech, Morocco.R.
Begum, S. Husain, A. Dhwaj, D. Sharma, L. Bai, andR.
Sangal.
2008.
Dependency annotation scheme forIndian languages.
In Proc of IJCNLP-2008.A.
Bharati, V. Chaitanya and R. Sangal.
1995.
NaturalLanguage Processing: A Paninian Perspective, Pren-tice-Hall of India, New Delhi.A.
Bharati, S. Husain, B. Ambati, S. Jain, D. Sharma,and R. Sangal.
2008.
Two semantic features make allthe difference in parsing accuracy.
In Proc of ICON.A.
Bharati, R. Sangal, D. M. Sharma and L. Bai.
2006.AnnCorra: Annotating Corpora Guidelines for POSand Chunk Annotation for Indian Languages.
Tech-nical Report (TR-LTRC-31), LTRC, IIIT-Hyderabad.A.
Bharati, D. M. Sharma, S. Husain, L. Bai, R. Begamand R. Sangal.
2009a.
AnnCorra: TreeBanks for In-dian Languages, Guidelines for Annotating HindiTreeBank.http://ltrc.iiit.ac.in/MachineTrans/research/tb/DS-guidelines/DS-guidelines-ver2-28-05-09.pdfA.
Bharati, S. Husain, D. M. Sharma and R. Sangal.2009b.
Two stage constraint based hybrid approachto free word order language dependency parsing.
InProc.
of IWPT.A.
Bharati, S. Husain, M. Vijay, K. Deepak, D. M.Sharma and R. Sangal.
2009c.
Constraint Based Hy-brid Approach to Parsing Indian Languages.
In Procof PACLIC 23.
Hong Kong.
2009.R.
Bhatt, B. Narasimhan, M. Palmer, O. Rambow, D.M.
Sharma and F. Xia.
2009.
Multi-Representationaland Multi-Layered Treebank for Hindi/Urdu.
InProc.
of the Third LAW at 47th ACL and 4th IJCNLP.Y.J.
Chu and T.H.
Liu.
1965.
On the shortest arbores-cence of a directed graph.
Science Sinica, 14:1396?1400.J.
Edmonds.
1967.
Optimum branchings.
Journal ofResearch of the National Bureau of Standards,71B:233?240.J.
Eisner.
1996.
Three new probabilistic models for de-pendency parsing: An exploration.
In Proc ofCOLING-96, pp.
340?345.G.
Eryigit, J. Nivre, and K. Oflazer.
2008.
DependencyParsing of Turkish.
Computational Linguistics 34(3),357-389.P.
Gadde, K. Jindal, S. Husain, D. M. Sharma, and R.Sangal.
2010.
Improving Data Driven DependencyParsing using Clausal Information.
In Proc ofNAACL-HLT 2010, Los Angeles, CA.E.
Hajicova.
1998.
Prague Dependency Treebank: FromAnalytic to Tectogrammatical Annotation.
In Proc ofTSD?98.J.
Hall, J. Nilsson, J. Nivre, G. Eryigit, B. Megyesi, M.Nilsson and M. Saers.
2007.
Single Malt or Blended?A Study in Multilingual Parser Optimization.
In Procof the CoNLL Shared Task Session of EMNLP-CoNLL 2007, 933?939.S.
Husain.
2009.
Dependency Parsers for Indian Lan-guages.
In Proc of ICON09 NLP Tools Contest: In-dian Language Dependency Parsing.
Hyderabad,India.S.
Husain, P. Gadde, B. Ambati, D. M. Sharma and R.Sangal.
2009.
A modular cascaded approach to com-plete parsing.
In Proc.
of the COLIPS IALP.P.
Mannem, A. Abhilash and A. Bharati.
2009.
LTAG-spinal Treebank and Parser for Hindi.
In Proc of In-ternational Conference on NLP, Hyderabad.
2009.R.
McDonald, K. Crammer, and F. Pereira.
2005.
On-line large-margin training of dependency parsers.
InProc of ACL.
pp.
91?98.R.
McDonald, K. Lerman, and F. Pereira.
2006.
Multi-lingual dependency analysis with a two-stage discri-minative parser.
In Proc of the Tenth (CoNLL-X), pp.216?220.R.
McDonald and J. Nivre.
2007.
Characterizing theerrors of data-driven dependency parsing models.
InProc.
of EMNLP-CoNLL.J.
Nivre, J.
Hall, S. Kubler, R. McDonald, J. Nilsson,  S.Riedel and D. Yuret.
2007a.
The CoNLL 2007Shared Task on Dependency Parsing.
In Proc ofEMNLP/CoNLL-2007.J.
Nivre, J.
Hall, J. Nilsson, A. Chanev, G. Eryigit, S.K?bler, S. Marinov and E Marsi.
2007b.
MaltParser:A language-independent system for data-driven de-pendency parsing.
Natural Language Engineering,13(2), 95-135.J.
Nivre and J. Nilsson.
2005.
Pseudo-projective depen-dency parsing.
In Proc.
of ACL-2005, pp.
99?106.Avinesh PVS and K. Gali.
2007.
Part-Of-Speech Tag-ging and Chunking Using Conditional RandomFields and Transformation Based Learning.
In Procof the SPSAL workshop during IJCAI '07.D.
Seddah, M. Candito and B. Crabb?.
2009.
Crossparser evaluation: a French Treebanks study.
In Proc.of IWPT, 150-161.R.
Tsarfaty and K. Sima'an.
2008.
Relational-Realizational Parsing.
In Proc.
of CoLing, 889-896.A.
Vaidya, S. Husain, P. Mannem, and D. M. Sharma.2009.
A karaka-based dependency annotation schemefor English.
In Proc.
of CICLing, 41-52.30
