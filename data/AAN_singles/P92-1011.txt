COMPARING TWO GRAMMAR-BASED GENERATIONA CASE STUDYMiroslav Martinovic and Tomek StrzalkowskiCourant Institute of Mathematical SciencesNew York University715 Broadway, rm.
704New York, N.Y., 10003ALGORITHMS:ABSTRACTIn this paper we compare two grammar-based gen-eration algorithms: the Semantic-Head-Driven Genera-tion Algorithm (SHDGA), and the Essential ArgumentsAlgorithm (EAA).
Both algorithms have successfullyaddressed several outstanding problems in grammar-based generation, including dealing with non-mono-tonic compositionality of representation, left-recursion,deadlock-prone rules, and nondeterminism.
We con-centrate here on the comparison of selected properties:generality, efficiency, and determinism.
We show thatEAA's traversals of the analysis tree for a given lan-guage construct, include also the one taken on bySHDGA.
We also demonstrate specific and commonsituations in which SHDGA will invariably run intoserious inefficiency and nondeterminism, and whichEAA will handle in an efficient and deterministicmanner.
We also point out that only EAA allows totreat he underlying rammar in a truly multi-directionalmanner.1.
INTRODUCTIONRecently, two important new algorithms have beenpublished (\[SNMP89\], \[SNMP90\], \[S90a\], \[S90b\] and\[$91\]) that address the problem of automated genera-tion of natural language xpressions from a structuredrepresentation f meaning.
Both algorithms follow thesame general principle: given a grammar, and a struc-tured representation f meaning, produce one or morecorresponding surface strings, and do so with a mini-mal possible ffort.
In this paper we limit our analysisof the two algorithms to unification-based formalisms.The first algorithm, which we call here the Seman-tic-Head-Driven Generation Algorithm (SHDGA), usesinformation about semantic heads ~ in grammar rulesto obtain the best possible traversal of the generationtree, using a mixed top-down/bottom-up strategy.The semantic head of a rule is the literal on the right-handside that shares the semantics with the literal on the left.The second algorithm, which we call the Essential Ar-guments Algorithm (EAA), rearranges grammar pro-ductions at compile time in such a way that a simpletop-down left-to-right evaluation will follow an opti-mal path.Both algorithms have resolved several outstandingproblems in dealing with natural language grammars,including handling of left recursive rules, non-mono-tonic compositionality of representation, and deadlock-prone rules 2.
In this paper we attempt to compare thesetwo algorithms along their generality and efficiencylines.
Throughout this paper we follow the notation usedin \[SNMP90\].2.
MAIN CHARACTERISTICS OF SHDGA'SAND EAA'S TRAVERSALSSHDGA traverses the derivation tree in the seman-tic-head-first fashion.
Starting from the goal predicatenode (called the root), containing a structured repre-sentation (semantics) from which to generate, it selectsa production whose leg-hand side semantics unifies withthe semantics of the root.
If the selected productionpasses the semantics unchanged from the left to somenonterminal on the right (the so-called chain rule), thislater nonterminal becomes the new root and the algo-rithm is applied recursively.
On the other hand, if noright-hand side literal has the same semantics as theroot (the so called non-chain rule), the production isexpanded, and the algorithm is reeursively applied toevery literal on its right-hand side.
When the evalu-ation of a non-chain rule is completed, SHDGA con-nects its left-hand side literal (called the pivot) to theinitial root using (in a backward manner) a series ofappropriate chain rules.
At this time, all remainingliterals in the chain rules are expanded in a fixed order(left-to-right).812 Deadlock-prone rules are rules in which the order of the ex-pansion of right-hand side literals cannot be determined locally(i.e.
using only information available inthis rule).Since SHDGA traverses the derivation tree ha thefashion described above, this traversal is neither top-down ('I'D), nor bottom-up (BU), nor left-to-right (LR)globally, with respect o the entire tree.
However, itis LR locally, when the siblings of the semantic headliteral are selected for expansion on the right-hand sideof a chain rule, or when a non-chain rule is evaluated.In fact the overall traversal strategy combines both theTD mode (non-chain rule application) and the BU mode(backward application of chain rules).EAA takes a unification grammar (usually Prolog-coded) and normalizes it by rewriting certain left re-cursive rules and altering the order of right-hand sidenonterminals in other rules.
It reorders literals ha theoriginal grammar (both locally within each rule, andglobally between different rules) ha such a way that theoptimal traversal order is achieved for a given evalu-ation strategy (eg.
top-down left-to-righ0.
This restruc-turing is done at compile time, so in effect a newexecutable grammar is produced.
The resulting parseror generator is TD but not LR with respect to the origi-nal grammar, however, the new grammar is evaluatedTD and LR (i.e., using a standard Prolog interpreter).As a part of the node reordering process EAA calcu-lates the minimal sets of essential arguments (msea's)for all literals ha the grammar, which in turn will al-low to project an optimal evaluation order.
The opti-mal evaluation order is achieved by expanding only thoseliterals which are ready at any given moment, i.e., thosethat have at least one of their mseas instantiated.
Thefollowing example illustrates the traversal strategies ofboth algorithms.
The grammar is taken from \[SNMP90\],and normalized to remove deadlock-prone rules in orderto simplify the exposition?
(0) sentence/deel(S)--> s(f'mite)/S.
(1) sentence/imp(S) -- > vp(nonfmite,\[np(_)/you\])IS., , .
.
.
.
.
(2) s(Form)/S - > Subj, vp(Form,\[Subj/S.. .
.
?
??
.
(3) vp(Form,Subcat)/S -- > v(Form,Z)/S,vpl(Form,Z)/Subcat.
(4) vpl(Form,\[Compl\[ Z\])/Ar --> vpl(Form, Z)/Ar,Compl.
(5) vpl(Form,Ar)/Ar.
(6) vp(Form,\[Subj\])/S -- > v(Form,\[Subj\])/VP,anx(Form, \[Subj\],VP)/S.
(7) anx(Form,\[Subjl,S)/S.
(8) aux(Form,\[Subjl,A)/Z--> adv(A)/B,aux(Form\[Subj\],B)/Z.. .
.
.
.
.
.
(9) v(finite,\[np(_)/O,np(3-sing)lS\])llove(S,O) -- >\[loves\].
(10) v(f'mite, \[np(_)/O,p/up,np(3 -sing)/S\])/call_up(S,O) -- > \[calls\].
(11) v(fmite,\[np(3-sing)/S\])/leave(S) -- > \[leaves\].. .
.
.
.
.
?
(12) np(3-sing)/john -- > \[john\].
(13) np(3-pl)/friends -- > \[friends\].
(14) adv(VP)/often(VP)--> \[often\].The analysis tree for both algorithms i presented onthe next page.
(Figure 1.).
The input semantics i givenas decl(call_up~ohnfriends)).
The output string be-comes john calls up friends.
The difference lists foreach step are also provided.
They are separated fromthe rest of the predicate by the symbol I- The differ-ent orders in which the two algorithms expand thebranches of the derivation tree and generate the termi-nal nodes are marked, ha italics for SHDGA, and inroman case for EAA.
The rules that were applied ateach level are also given.If  EAA is rerun for alternative solutions, it will pro-duce the same output string, but the order in which nodesvpl (finite,\[p/up,np(3-sing)/john\])/\[Subj\]/Sl_S2, andnp(..)/~ends/S2__l\] (level 4), and also, vp1(finite,\[np(3-sing)/john\])/\[Subj\]/S1_S12, and p/up/S12_S2, at thelevel below, are visited, will be reversed.
This hap-pens because both literals in both pairs are ready forthe expansion at the moment when the selection is tobe made.
Note that the traversal made by SHDGA andthe first traversal taken by EAA actually generate theterminal nodes ha the same order.
This property isformally defined below.Definition.
Two traversals T' and T"  of a tree T aresaid to be the same-to-a-subtree (stas), if the follow-hag claim holds: Let N be any node of the tree T, andS~ ..... S all subtrees rooted at N. If the order in whichthe subtrees will be taken on for the traversal by T' isS?
..... S. n and by T"  S. t ..... S.", then SJ =SJ .....
S."=S.
".s s .1 J l .I t j(S~ is one of the subtrees rooted at N, for any k, and 1)Stas however does not imply that the order in whichthe nodes are visited will necessarily be the same.3 EAA eliminates such rules using lobal node reordering (\[$91\]).82sentence/decl(call._up0ohn, frie ds)) I St ring_\[ls(ftnite)/call up(john, friends) IString._\[\]SubJ l String_SOnpO-slng)/joh n IString_SOnp(3-sing)/john I UohnlS0LS010/  Rule (12)john/V IVq)(rmJte,ISubjl)/caUup(john,trien~) I S0_\[\]v(finite,Z)/call_up0ohn, friends) I SOSI vpl(nnlte,Z)/lSubjl I Sl \[1v(finite,\[np( )/friends,p/up, np(3-~ng)/john\])/ vpl(finite, \[npO/friends,p/up, n (3-sing)/john\])/i~t\]l_u p(j oh n, friends) I lcalls\[ SII._Sl \[SubjllSl_.\[\]S Rule(lO)calls vpl(finite, \[p/up,ni)(3-singJIjohn\])/\[Subj\] I IS2I I $ 6 RUle (4)vpl(flnite, \[np(3-sing)/john)/\[Subj\] \[ SI._S12 p/uplSl2_S2l o/upll~l~l_S24 7 RUle(S)6 I s  v'pl(fln~,\[np(3-slng)/john\])/\[np(3-si~ljohn\] l Sl_ SlH up URule ~0)Rule (1)Rul?~Sule~up(_)/rr~lS2_\[lnp(3-pl)/frlendsl\[~l Ill8 1 9 Rule (13)11I friends IIIFIGURE 1: EAA's and SHDGA's Traversals of An Analysis Tree.3.
GENERALITY-WISE SUPERIORITY OFEAA OVER SHDGAThe traversals by SHDGA and EAA as marked onthe graph are stas.
This means that the order in whichthe terminals were produced (the leaves were visited)is the same (in this case: calls up friends john).
As notedpreviously, EAA can make other traversals to producethe same output string, and the order in which theterminals are generated will be different in each case.
(This should not be confused with the order of the ter-minals in the output string, which is always the same).The orders in which terminals are generated during al-ternative EAA traversals are: up calls friends john,friends calls up john, friends up calls john.
In general,EAA can be forced to make a traversal correspondingto any permutation of ready literals in the right-handside of a rule.We should notice that in the above example SHDGAhappened to make all the right moves, i.e., it alwaysexpanded a literal whose msea happened to be instan-tiated.
As we will see in the following sections, thiswill not always be the case for SHDGA and will be-come a source of serious efficiency problems.
On theother hand, whenever SHDGA indeed follows anoptimal traversal, EAA will have a traversal that is same-to-a-subtree with it.The previous discussion can be summarized by thenext theorem.83Theorem: If the SHDGA, at each particular step dur-ing its implicit traversal of the analysis tree, visits onlythe vertices representing literals that have at least oneof their sets of essential arguments instantiated atthemoment of the visit, then the traversal taken by theSHDGA is the same-to-a-subtree (stas) as one of thetraversals taken by EAA.The claim of the theorem is an immediate consequenceof two facts.
The first is that the EAA always selectsfor the expansion one of the literals with a msea cur-rently instantiated.
The other is the definition oftraversals being same-to-a-subtree (always choosing thesame subtree for the next traversal).The following simple extract from a grammar, de-fining a wh-question, illustrates the forementioned (seeFigure 2. below):.
.
.
.
.
.
.
.
.
?
(1) whques/WhSem--> whsubj(Num)/WhSubj,whpred(Num,Tense, \[WhSubj,WhObj\])/WhSem, whobj/WhObj.o .o  .
.
.
.
.
.
.. .
.
.
.
.
.
, .
?
(2) whsubj(_.
)/who -- > \[who\].
(3) whsubj(__)/what --> \[what\].??
.
.
.
.
.
.
, ?
(4) whpred(sing,perf, \[Subj, Obj\])/wrote(Subj, Obj)-> \[wrote\].. .
.
?
.
, , , ?
,(5) whobj/this--> \[this\].?
?oo ,ooo?
?The input semantics for this example iswrote(who,this), and the output string who wrote this.The numbering for the edges taken by the SHDGA isgiven in italics, and for the EAA in roman case.
Bothalgorithm~ expand the middle subtree first, then the left,and finally the right one.Each of the three subtrees has only one path, there-fore the choices of their subtrees are unique, and there-fore both algorithms agree on that, too.
However, theway they actually traverse these subtrees i  different.For example, the middle subtree is traversed bottom-up by SHDGA and top-down by EAA.
whpred isexpanded first by SI-IDGA (because it shares the se-mantics with the root, and there is an applicable non-chain rule), and also by EAA (because it is the onlyliteral on the right-hand side of the rule (1) that hasone of its msea's instantiated (its semantics)).After the middle subtree is completely expanded, bothsibling literals for the whpred have their semantics in-stantiated and thus they are both ready for expansion.We must note that SHDGA will always elect he left-most literal (in this case, whsubj), whether it is readyor not.
EAA will select he same in the first pass, butit will expand whobj first, and then whsubj, if we forcea second pass.
In the first pass, the terminals are gen-erated in the order wrote who this, while in the secondpass the order is wrote this who.
The first traversal forEAA, and the only one for SHDGA are same-to-a-subtree.4.
EFFICIENCY-WISE SUPERIORITY OFEAA OVER SHDGAThe following example is a simplified fragment of aparser-oriented grammar for yes or no questions.
Usingthis fragment we will illustrate some deficiencies ofSHDGA.o .
?o .ooo .
.
(1) sentence/ques(askif(S)) -- > yesnoq/askif(S).
(2i" ye's'noq/asld f(S)-->auxverb(Num,Pers,Form)/Aux,subj (Num,Pers)/Subj,mainverb(Form, \[Sub j, Obj\])/Verb,obj(_,J/Obj,adj(\[Verb\])/S.wb,p~wr~e(wko.a,~) \[ Q,m_Uwhs~bj (Num) /WhSJ j  l (~ ,es  R I  whpred(Num, Form, \[WhSubj,WhObjD/wrole(who,this) I R IR2wl~bj/WhObj I~_111 2wrote1 I3 3 ~4 4w~ thhH l l~ i l l  !
I!~TJ, t *  O)su~4er31 I I  ~"  11FIGURE 2: EAA's and SHDGA's STAS Traversals of Who Question's Analysis Tree.84(3) auxverb(sing, one,pres__perf)/laave(pres__perf, sing)--> \[have\].
(4) aux_verb(sing,one,pres_cont)/be(pres_cont,sing-l)--> \[am\].
(5) auxverb(sing,one,pres)/do(pres,sing- 1) -- > \[do\].
(6) aux_verb(sing,two,pres)/do(pres,sing-2)--> \[do\].
(7) aux_verb(sing,three,pres)/do(pres,sing-3) -- >\[does\].
(8) aux_verb(pl,one,pres)/do(pres,pl-1) -- > \[do\].
(9) subj(Num,Pers)/Subj -- > np(Num, Pers,su)/Subj.
(10) obj(Num,Pers)/Obj -- > np(Num,Pers,ob)/Obj.
(11) np(Num,Pers,Case)/NP--> noun(Num,Pers, Case)/NP.
(12) np(Num,Pers,Case)/NP--> pnoun(Num,Pers, Case)/NP.
(13) pnoun(sing,two,su)/you -- > \[you\].
(14) pnoun(sing,three,ob)/him -- > \[him\].
(15) main_verb(pres,\[Subj,Obj\])/see(Subj,Obj)- ->  \[see\].
(15a) main_verb(pres__perf, \[Subj, Obj \])/seen(Subj, Obj )--> \[seen\].
(15b) mainverb(perf, \[Subj,Obj\])/saw(Subj, O j)- ->  \[saw\].
(16) adj(\[Verb\])/often(Verb)--> \[often\].The analysis tree (given on Figure 3.)
for the inputsemantics ques ( askif (often (see (you,him) ) ) ) (theoutput string being do you see him often) is presentedbelow.Both algorithms start with the rule (1).
SHDGA se-lects (1) because it has the left-hand side nonterminalwith the same semantics as the root, and it is a non-chain rule.
EAA selects (1) because its left-hand sideunifies with the initial query (-?- sentence (OutString__G)/ ques(askif(often(see(you,him)))) ).Next, rule (2) is selected by both algorithms.
Again,by SHDGA, because it has the left-hand side nonter-minal with the same semantics as the current root(yesnoq/askif...), and it is a non-chain rule; and by EAA,because the yesnoq/askif.., is the only nonterminal onthe right-hand side of the previously chosen rule andit has an instantiated msea (its semantics).
The crucialdifference takes place when the right-hand side of rule(2) is processed.
EAA deterministically selects adj forexpansion, because it is the only rhs literal with aninstantiated msea's.
As a result of expanding adj, themain verb semantics becomes instantiated, and thereforemain__verb is the next literal selected for expansion.
Afterprocessing of main_verb is completed, Subject, Object,and Tense variables are instantiated, sothat both subjand obj become ready.
Also, the tense argument foraux_verb is instantiated (Form in rule (2)).
After subj,se ntee~e/ques(askifloft en(see(yoo,him)))) \] String_\[\]' I 1yesnoqlaskiffonenlsee(you,him))) \[ String_\[\]Ru~ (z)Ruleaux_verb(sing,t wo, pres)/do(pres,sing-2) \[ Idol ROI_R0Rule(o)11 3doV 1sobj(sing,two)/ main_verb(pres, \[you, him\])/ obj(sing,three)youI\[youlRl\] RI see(you,him) \] \[see \[R2\]_R2 him \[ \[him \] R3\]_R3Role (9) Rule (15) Rule (10)5 6 4 7 8 10np(sing,two,su)/ see np(sing,three,ob)/you I \[you I R I\]_RI 1I II1 him I\[him \[ R3\]_R3Rule.z)\[ Rule(l,) I6 5 9 9pnoun(sing,two,su)/ pnoun(slng,three,ob)/you I \[you\[ R I \ ]R I  him l \[him I R3LR3Rule (13) \] Rule (14) I7 4 10 8you himll I  / /  IV /Vadj(\[see(you,him) \])/often(see(you, him)) I\[one~ I \ [ I L lRule (16) I3 11oftenI VFIGURE 3: EAA's and SHDGA's Traversals of If Question's Analysis Tree.85and obj are expanded (in any order), Num, and Persfor aux_verb are bound, and finally aux_verb is ready,too.In contrast, the SHDGA will proceed by selectingthe leftmost literal (auxverb(Num,Pers,Form)/Aux) ofthe rule (2).
At this moment, none of its arguments iinstantiated and any attempt to unify with an auxiliaryverb in a lexicon will succeed.
Suppose then that haveis returned and unified with aux_verb with pres._perfas Tense and sing_l as Number.
This restricts furtherchoices of subj and main_verb.
However, obj will stillbe completely randomly chosen, and then adj will rejectall previous choices.
The decision for rejecting themwill come when the literal adj is expanded, because itssemantics is often(see(you,him)) as inherited fromyesnoq, but it does not match the previous choices foraux_verb, subj, main_verb, and obj.
Thus we are forcedto backtrack repeatedly, and it may be a while beforethe correct choices are made.In fact the same problem will occur whenever SHDGAselects a rule for expansion such that its leftmost right-hand side literal (first to be processed) is not ready.Since SHDGA does not check for readiness before ex-panding apredicate, other examples similar to the onediscussed above can be found easily.
We may also pointout that the fragment used in the previous example isextracted from an actual computer grammar for Eng-lish (Sager's String Grammar), and therefore, it is notan artificial problem.The only way to avoid such problems with SHDGAwould be to rewrite the underlying rammar, so thatthe choice of the most instantiated literal on the righthandside of a rule is forced.
This could be done by chang-ing rule (2) in the example above into several rules whichuse meta nonterminals Aux, Subj, Main_Verb, and Objin place of literals attx verb, subj, mainverb, and objrespectively, as shown below:.
.
.
.
.
?
.
.
.
.yesnoq/askif(S)--> askif/S.askif/S -- >Aux, Subj, Main Verb, Obj,adj (\[Verb\],\[Aux,S-ubj,Main_Verb,Obj\])IS.. .
.
.
.
.
.
.
.
.Since Aux, Subj, Main_Verb, and Obj are uninstan-tiated variables, we are forced to go directly to adj first.After adj is expanded the nonterminals tothe left of itwill become properly instantiated for expansion, so ineffect heir expansion has been delayed.However, this solution seems to put additional bur-den on the grammar writer, who need not be aware ofthe evaluation strategy to be used for its grammar.Both algorithms handle left recursion satisfactorily.SHDGA processes recursive chain rules rules in a con-strained bottom-up fashion, and this also includes dead-lock prone rules.
EAA gets rid of left recursive rulesduring the grammar normalization process that takesplace at compile-time, thus avoiding the run-timeoverhead.5.
MULTI-DIRECTIONALITYAnother property of EAA regarded as superior overthe SHDGA is its mult-direcfionality.
EAA can be usedfor parsing as well as for generation.
The algorithmwill simply recognize that the top-level msea is nowthe string, and will adjust o the new situation.
More-over, EAA can be run in any direction paved by thepredicates' mseas as they become instantiated atthe timea rule is taken up for expansion.In contrast, SHDGA can only be guaranteed toworkin one direction, given any particular grammar, althoughthe same architecture can apparently be used for bothgeneration, \[SNMP90\], and parsing, \[K90\], \[N89\].The point is that some grammars (as shown in theexample above) need to be rewritten for parsing orgeneration, or else they must be constructed in such away so as to avoid indeterminacy.
While it is possibleto rewrite grammars in a form appropriate for head-first computation, there are real grammars which willnot evaluate fficiently with SHDGA, even though EAAcan handle such grammars with no problems.6.
CONCLUSIONIn this paper we discussed several aspects of two natu-ral language generation algorithms: SHDGA and EAA.Both algorithms operate under the same general set ofconditions, that is, given a grammar, and a structuredrepresentation f meaning, they attempt to produce oneor more corresponding surface strings, and do so witha minimal possible effort.
We analyzed the perform-ance of each algorithm in a few specific situations, andconcluded that EAA is both more general and more ef-ficient algorithm than SHDGA.
Where EAA enforcesthe optimal traversal of the derivation tree by precom-puting all possible orderings for nonterminal expan-sion, SHDGA can be guaranteed to display a compa-86rable performance only if its grammar is appropriatelydesigned, and the semantic heads are carefully assigned(manually).
With other grammars SHDGA will follownon-optimal generation paths which may lead to ex-treme inefficiency.In addition, EAA is a truly multi-directional lgo-rithm, while SHDGA is not, which is a simple conse-quence of the restricted form of grammar that SHDGAcan safely accept.This comparison can be broadened in several direc-tions.
For example, an interesting problem that remainsto be worked out is a formal characterization f thegrammars for which each of the two generation algo-rithms is guaranteed toproduce a finite and/or opti-mal search tree.
Moreover, while we showed thatSHDGA will work properly only on a subset of EAA'sgrammars, there may be legitimate g ~  that neitheralgorithm can handle.7.
ACKNOWLEDGEMENTSThis paper is based upon work supported by theDefense Advanced Research Project Agency underContract N00014-90-J-1851 from the Office of NavalResearch, the National Science Foundation under GrantIRI-89-02304, and the Canadian Institute for Robot-ics and Intelligent Systems (IRIS).REFERENCES\[C78\] COLMERAUER, A.
1978.
"Metamor-phosis Grammars."
In Natural Language Communi-cation with Computers, Edited by L. Bole.
LectureNotes in Computer Science, 63.
Springer-Verlag, NewYork, NY, pp.
133-189.\[D90a\] DYMETMAN, M. 1990.
"A Gener-alized Greibach Normal Form for DCG's."
CCRIT,Laval, Quebec: Ministere des Communications Can-ada.\[D90b\] DYMETMAN, M. 1990.
"Left-Re-cursion Elimination, Guiding, and Bidirectionality inLexical Grammars."
To Appear.\[DA84\] DAHL, V., and ABRAMSON, H.1984.
"On Gapping Grammars."
Proceedings of theSecond International Conference on LogicProgramming.Uppsala, Sweden, pp.
77-88.\[DI88\] DYMETMAN, M., and ISABELLE,P.
1988.
"Reversible Logic Grammars for MachineTranslation."
Proceedings of the 2nd InternationalConference on Theoretical nd Methodological Issuesin Machine Translation of Natural Languages.
Car-negie-Mellon University, Pittsburgh, PA.\[DIP90\] DYMETMAN, M., ISABELLE, P.,and PERRAULT, F. 1991.
"A Symmetrical Approachto Parsing and Generation."
Proceedings of the 13thInternational Conference on Computational Linguis-tics (COLING-90).
Helsinki, Finland, Vol.
3., pp.
90-96.\[GM89\] GAZDAR, G., and MELLISH, C.1989.
Natural ?zmguage Processing inProlog.
Addison-Wesley, Reading, MA.\[K90\] KAY, M. 1990.
"Head-Driven Pars-ing."
In M. Tomita (ed.
), Current Issues in ParsingTechnology, Kluwer Academic Publishers, Dordrecht,the Netherlands.\[K84\] KAY, M. 1984.
"Functional Unifica-tion Grammar: A Formalism for Machine Translation.
"Proceedings of the lOth International Conference onComputational Linguistics (COLING-84).
StanfordUniversity, Stanford, CA., pp.
75-78.\[N89\] VAN NOORD, G. 1989.
~An Over-view of Head-Driven Bottom-Up Generation."
In Pro-ceedings of the Second European Workshop on Natu-ral Language Generation.
Edinburgh, Scotland.\[PS90\] PENG, P., and STRZALKOWSKI, T.1990.
"An Implementation f A Reversible Grammar.
"Proceedings of the 8th Conference of the Catmdian So-ciety for the Computational Studies of Intelligence(CSCS1-90).
University of Ottawa, Ottawa, Ontario,pp.
121-127.\[S90a\] STRZALKOWSKI, T. 1990.
"How toInvert A Natural Language Parser into An Efficient Gen-erator: An Algorithm for Logic Grammars."
Proceed-ings of the 13th International Conference on Compu-tational Linguistics (COLING-90).
Helsinki, Finland,Vol.
2., pp.
90-96.\[S90b\] STRZALKOWSKI, T. 1990.
"Revers-ible Logic Grammars for Natural Language Parsing andGeneration."
Computational Intelligence Journal,Volume 6., pp.
145-171.87\[$91\] STRZALKOWSKI, T. 1991.
"A Gen-eral Computational Method for Grammar Inversion.
"Proceedings era Workshop Sponsored by the SpecialInterest Groups on Generation and Parsing of the ACL.Berkeley, CA., pp.
91-99.\[SNMP89\] SHIEBER, S.M., VAN NOORD,G., MOORE, R.C., and PEREIRA, F.C.N.
1989.
"ASemantic-Head-Driven G eration Algorithm for Uni-fication-Based Formalisms."
Proceedings of the 27thMeeting of the ACL.
Vancouver, B.C., pp.
7-17.\[SNMP90\] SHIEBER, S.M., VAN NOORD,G., MOORE, R.C., and PEREIRA, F.C.N.
1990.
"Semantic-Head-Driven G eration."
ComputationalLinguistics, Volume 16, Number 1.\[W88\] WEDEKIND, J.
1988.
"Generation asStructure Driven Derivation.
* Proceedings of the 12thInternational Conference on Computational Linguis-tics (COL1NG-88).
Budapest, Hungary, pp.
732-737.08
