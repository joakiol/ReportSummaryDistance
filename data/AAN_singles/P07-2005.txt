Proceedings of the ACL 2007 Demo and Poster Sessions, pages 17?20,Prague, June 2007. c?2007 Association for Computational LinguisticsSystem Demonstration of On-Demand Information ExtractionSatoshi SekineNew York University715 Broadway, 7th floorNew York, NY 10003 USAsekine@cs.nyu.eduAkira Oda 1)Toyohashi University of Technology1-1 Hibarigaoka, Tenpaku-cho,Toyohashi, Aichi 441-3580 Japanoda@ss.ics.tut.ac.jpAbstractIn this paper, we will describe ODIE, theOn-Demand Information Extraction system.Given a user?s query, the system will pro-duce tables of the salient information aboutthe topic in structured form.
It produces thetables in less than one minute without anyknowledge engineering by hand, i.e.
pat-tern creation or paraphrase knowledgecreation, which was the largest obstacle intraditional IE.
This demonstration is basedon the idea and technologies reported in(Sekine 06).
A substantial speed-up overthe previous system (which required about15 minutes to analyze one year of newspa-per) was achieved through a new approachto handling pattern candidates; now lessthan one minute is required when using 11years of newspaper corpus.
In addition,functionality was added to facilitate inves-tigation of the extracted information.1 IntroductionThe goal of information extraction (IE) is to extractinformation about events in structured form fromunstructured texts.
In traditional IE, a great deal ofknowledge for the systems must be coded by handin advance.
For example, in the later MUC evalua-tions, system developers spent one month for theknowledge engineering to customize the system tothe given test topic.
Improving portability is neces-sary to make Information Extraction technologyuseful for real users and, we believe, lead to abreakthrough for the application of the technology.1) This work was conducted when the first author was ajunior research scientist at New York University.Sekine (Sekine 06) proposed ?On-demand in-formation extraction (ODIE)?
: a system whichautomatically identifies the most salient structuresand extracts the information on the topic the userdemands.
This new IE paradigm becomes feasibledue to recent developments in machine learning forNLP, in particular unsupervised learning methods,and is created on top of a range of basic languageanalysis tools, including POS taggers, dependencyanalyzers, and extended Named Entity taggers.This paper describes the demonstration system ofthe new IE paradigm, which incorporates somenew ideas to make the system practical.2 Algorithm OverviewWe will present an overview of the algorithm inthis section.
The details can be found in (Sekine06).The basic functionality of the system is the fol-lowing.
The user types a query / topic descriptionin keywords (for example, ?merge, acquire, pur-chase?).
Then tables will be created automaticallywhile the user is waiting, rather than in a month ofhuman labor.
These tables are expected to showinformation about the salient relations for the topic.There are six major components in the system.1) IR system: Based on the query given by theuser, it retrieves relevant documents from thedocument database.
We used a simple TF/IDFIR system we developed.2) Pattern discovery: The texts are analyzed usinga POS tagger, a dependency analyzer and anExtended Named Entity (ENE) tagger, whichwill be explained in (5).
Then sub-trees of de-pendency trees which are relatively frequent inthe retrieved documents compared to the entirecorpus are identified.
The sub-trees to be usedmust satisfy some restrictions, including having17between 2 and 6 nodes, having a predicate ornominalization as the head of the sub-tree, andhaving at least one NE.
We introduced upperand lower frequency bounds for the sub-trees tobe used, as we found the medium frequencysub-trees to be the most useful and least noisy.We compute a score for each pattern based onits frequency in the retrieved documents and inthe entire collection.
The top scoring sub-treeswill be called patterns, which are expected toindicate salient relationships of the topic andwhich will be used in the later components.
Wepre-compute such information as much as pos-sible in order to enable usably prompt responseto queries.3) Paraphrase discovery: In order to find semanticrelationships between patterns, i.e.
to find pat-terns which should be used to build the sametable, we use lexical knowledge such as Word-Net and paraphrase discovery techniques.
Theparaphrase discovery was conducted off-lineand created a paraphrase knowledge base.4) Table construction: In this component, the pat-terns created in (2) are linked based on theparaphrase knowledge base created by (3), pro-ducing sets of patterns which are semanticallyequivalent.
Once the sets of patterns are created,these patterns are applied to the documents re-trieved by the IR system (1).
The matched pat-terns pull out the entity instances from the sen-tences and these entities are aligned to build thefinal tables.5) Extended NE tagger: Most of the participants inevents are likely to be Named Entities.
How-ever, the traditional NE categories are not suffi-cient to cover most participants of variousevents.
For example, the standard MUC?s 7 NEcategories (i.e.
person, location, organization,percent, money, time and date) miss productnames (e.g.
Windows XP, Boeing 747), eventnames (Olympics, World War II), numericalexpressions other than monetary expressions,etc.
We used the Extended NE with 140 catego-ries and a tagger developed for these categories.3 Speed-enhancing technologyThe largest computational load in this system is theextraction and scoring of the topic-relevant sub-trees.
In the previous system, 1,000 top-scoringsub-trees are extracted from all possible (on theorder of hundreds of thousands) sub-trees in thetop 200 relevant articles.
This computation tookabout 14 minutes out of the total 15 minutes of theentire process.
The difficulty is that the set of toparticles is not predictable, as the input is arbitraryand hence the list of sub-trees is not predictable,too.
Although a state-of-the-art tree mining algo-rithm (Abe et al 02) was used, the computation isstill impracticable for a real system.The solution we propose in this paper is to pre-compute all possibly useful sub-trees in order toreduce runtime.
We enumerate all possible sub-trees in the entire corpus and store them in a data-base with frequency and location information.
Toreduce the size of the database, we filter the pat-terns, keeping only those satisfying the constraintson frequency and existence of predicate and namedentities.
However, it is still a big challenge, be-cause in this system, we use 11 years of newspaper(AQUAINT corpus, with duplicate articles re-moved) instead of the one year of newspaper (NewYork Times 95) used in the previous system.
Withthis idea, the response time of the demonstrationsystem is reduced significantly.The statistics of the corpus and sub-trees are asfollows.
The entire corpus includes 1,031,124 arti-cles and 24,953,026 sentences.
The frequencythresholds for sub-trees to be used is set to morethan 10 and less than 10,000; i.e.
sub-trees of thosefrequencies in the corpus are expected to containmost of the salient relationships with minimumnoise.
The sub-trees with frequency less than 11account for a very large portion of the data; 97.5%of types and 66.3% of instances, as shown in Table1.
The sub-trees of frequency of 10,001 or moreare relatively small; only 76 kinds and only 2.5%of the instances.Frequency 10,001 ormore10,000-11 10 or less76 975,269 38,158,887# of type~0.0% 2.5% 97.5%2,313,347 29,257,437 62,097,271# of instance2.5% 31.2% 66.3%Table 1.
Frequency of sub-treesWe assign ID numbers to all 1 million sub-treesand 25 million sentences and those are mutuallylinked in a database.
Also, 60 million NE occur-rences in the sub-trees are identified and linked to18the sub-tree and sentence IDs.
In the process, thesentences found by the IR component are identi-fied.
Then the sub-trees linked to those sentencesare gathered and the scores are calculated.
Thoseprocesses can be done by manipulation of the data-base in a very short time.
The top sub-trees areused to create the output tables using NE occur-rence IDs linked to the sub-trees and sentences.4 A DemonstrationIn this section, a simple demonstration scenario ispresented with an example.
Figure 1 shows theinitial page.
The user types in any keywords in thequery box.
This can be anything, but as a tradi-tional IR system is used for the search, the key-words have to include expressions which are nor-mally used in relevant documents.
Examples ofsuch keywords are ?merge, acquisition, purchase?,?meet, meeting, summit?
and ?elect, election?,which were derived from ACE event types.Then, normally within one minute, the systemproduces tables, such as those shown in Figure 2.All extracted tables are listed.
Each table containssentence ID, document ID and information ex-tracted from the sentence.
Some cells are empty ifthe information can?t be extracted.Figure 1.
Screenshot of the initial page5 EvaluationThe evaluation was conducted using scenariosbased on 20 of the ACE event types.
The accuracyof the extracted information was evaluated byjudges for 100 rows selected at random.
Of theserows, 66 were judged to be on target and correct.Another 10 were judged to be correct and relatedto the topic, but did not include the essential in-formation of the topic.
The remaining 24 includedNE errors and totally irrelevant information (insome cases due to word sense ambiguity; e.g.?fine?
weather vs.?fine?
as a financial penalty).Figure 2.
Screenshot of produced tables196 Other FunctionalityFunctionality is provided to facilitate the user?saccess to the extracted information.
Figure 3 showsa screenshot of the document from which the in-formation was extracted.
Also the patterns used tocreate each table can be found by clicking the tab?patterns?
(shown in Figure 4).
This could help theuser to understand the nature of the table.
The in-formation includes the frequency of the pattern inthe retrieved documents and in the entire corpus,and the pattern?s score.Figure 3.
Screenshot of document viewFigure 4.
Screenshot of pattern information7 Future WorkWe demonstrated the On-Demand Information Ex-traction system, which provides usable responsetime for a large corpus.
We still have several im-provements to be made in the future.
One is to in-clude more advanced and accurate natural lan-guage technologies to improve the accuracy andcoverage.
For example, we did not use a corefer-ence analyzer, and hence information which wasexpressed using pronouns or other anaphoric ex-pressions can not be extracted.
Also, more seman-tic knowledge including synonym, paraphrase orinference knowledge should be included.
The out-put table has to be more clearly organized.
In par-ticular, we can?t display role information as col-umn headings.
The keyword input requirement isvery inconvenient.
For good performance, the cur-rent system requires several keywords occurring inrelevant documents; this is an obvious limitation.On the other hand, there are systems which don?tneed any user input to create the structured infor-mation (Banko et al 07) (Shinyama and Sekine 06).The latter system tries to identify all possible struc-tural relations from a large set of unstructureddocuments.
However, the user?s information needsare not predictable and the question of whether wecan create structured information for all possibleneeds is still a big challenge.AcknowledgementsThis research was supported in part by the Defense Ad-vanced Research Projects Agency as part of theTranslingual Information Detection, Extraction  andSummarization (TIDES) program, under Grant N66001-001-1-8917 from the Space and Naval Warfare SystemsCenter, San Diego, and by the National Science Founda-tion under Grant IIS-00325657.
This paper does notnecessarily reflect the position of the U.S. Government.We would like to thank our colleagues at New YorkUniversity, who provided useful suggestions and dis-cussions, including, Prof. Ralph Grishman and Mr. Yu-suke Shinyama.ReferencesKenji Abe, Shinji Kawasone, Tatsuya Asai, Hiroki Ari-mura and Setsuo Arikawa.
2002.
?Optimized Sub-structure Discovery for Semi-structured Data?.PKDD-02.Michele Banko, Michael J Cafarella, Stephen Soderland,Matt Broadhead and Oren Etzioni.
2007.
?Open In-formation Extraction from Web?.
IJCAI-07.Satoshi Sekine.
2006.
?On-Demand Information Extrac-tion?.
COLING-ACL-06.Yusuke Shinyama and Satoshi Sekine, 2006.
?Preemp-tive Information Extraction using Unrestricted Rela-tion Discovery?.
HLT-NAACL-2006.20
