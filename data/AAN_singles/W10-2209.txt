Proceedings of the 11th Meeting of the ACL-SIGMORPHON, ACL 2010, pages 72?77,Uppsala, Sweden, 15 July 2010. c?2010 Association for Computational LinguisticsComparing Canonicalizations of Historical German TextBryan JurishBerlin-Brandenburg Academy of SciencesBerlin, Germanyjurish@bbaw.deAbstractHistorical text presents numerous chal-lenges for contemporary natural languageprocessing techniques.
In particular, theabsence of consistent orthographic con-ventions in historical text presents difficul-ties for any system requiring reference toa static lexicon accessed by orthographicform.
In this paper, we present threemethods for associating unknown histori-cal word forms with synchronically activecanonical cognates and evaluate their per-formance on an information retrieval taskover a manually annotated corpus of his-torical German verse.1 IntroductionHistorical text presents numerous challenges forcontemporary natural language processing tech-niques.
In particular, the absence of consistent or-thographic conventions in historical text presentsdifficulties for any system requiring reference to afixed lexicon accessed by orthographic form, suchas document indexing systems (Sokirko, 2003;Cafarella and Cutting, 2004), part-of-speech tag-gers (DeRose, 1988; Brill, 1992; Schmid, 1994),simple word stemmers (Lovins, 1968; Porter,1980), or more sophisticated morphological ana-lyzers (Geyken and Hanneforth, 2006; Clematide,2008).When adopting historical text into such a sys-tem, one of the most crucial tasks is the associa-tion of one or more extant equivalents with eachword of the input text: synchronically active typeswhich best represent the relevant features of theinput word.
Which features are considered ?rel-evant?
here depends on the application in ques-tion: for a lemmatization task only the root lex-eme is relevant, whereas syntactic parsing mayrequire additional morphosyntactic features.
Forcurrent purposes, extant equivalents are to be un-derstood as canonical cognates, preserving boththe root(s) and morphosyntactic features of the as-sociated historical form(s), which should suffice(modulo major grammatical and/or lexical seman-tic shifts) for most natural language processingtasks.In this paper, we present three methods for au-tomatic discovery of extant canonical cognatesfor historical German text, and evaluate their per-formance on an information retrieval task over asmall gold-standard corpus.2 Canonicalization MethodsIn this section, we present three methods for au-tomatic discovery of extant canonical cognatesfor historical German input: phonetic conflation(Pho), Levenshtein edit distance (Lev), and aheuristic rewrite transducer (rw).
The variousmethods are presented individually below, andcharacterized in terms of the linguistic resourcesrequired for their application.
Formally, eachcanonicalization method R is defined by a char-acteristic conflation relation ?R, a binary rela-tion on the set A?
of all strings over the finitegrapheme alphabet A. Prototypically, ?Rwill bea true equivalence relation, inducing a partitioningof A?
into equivalence classes or ?conflation sets?
[w]R= {v ?
A?
: v ?Rw}.2.1 Phonetic ConflationIf we assume despite the lack of consistent or-thographic conventions that historical graphemicforms were constructed to reflect phonetic forms,and if the phonetic system of the target languageis diachronically more stable than the graphematicsystem, then the phonetic form of a word shouldprovide a better clue to its extant cognates (if any)than a historical graphemic form alone.
Taken to-gether, these assumptions lead to the canonicaliza-72tion technique referred to here as phonetic confla-tion.In order to map graphemic forms to phoneticforms, we may avail ourselves of previous workin the realm of text-to-speech synthesis, a domainin which the discovery of phonetic forms for ar-bitrary text is an often-studied problem (Allen etal., 1987; Dutoit, 1997), the so-called ?letter-to-sound?
(LTS) conversion problem.
The phoneticconversion module used here was adapted fromthe LTS rule-set distributed with the IMS GermanFestival package (Mo?hler et al, 2001), and com-piled as a finite-state transducer (Jurish, 2008).In general, the phonetic conflation strategymaps each (historical or extant) input word w ?A?
to a unique phonetic form pho(w) by means ofa computable function pho : A?
?
P?,1 conflat-ing those strings which share a common phoneticform:w ?Phov :?
pho(w) = pho(v) (1)2.2 Levenshtein Edit DistanceAlthough the phonetic conflation technique de-scribed in the previous section is capable of suc-cessfully identifying a number of common histor-ical graphematic variation patterns such as ey/ei,?/o?, th/t, and tz/z, it fails to conflate historicalforms with any extant equivalent whenever thegraphematic variation leads to non-identity of therespective phonetic forms, as determined by theLTS rule-set employed.
In particular, whenevera historical variation would effect a pronuncia-tion difference in synchronic forms, that varia-tion will remain uncaptured by a phonetic con-flation technique.
Examples of such phoneticallysalient variations with respect to the simplifiedIMS German Festival rule-set include guot/gut?good?, liecht/licht ?light?, tiuvel/teufel ?devil?,and wolln/wollen ?want?.In order to accommodate graphematic variationphenomena beyond those for which strict pho-netic identity of the variant forms obtains, we mayemploy an approximate search strategy based onthe simple Levenshtein edit distance (Levenshtein,1966; Navarro, 2001).
Formally, let Lex ?
A?be the lexicon of all extant forms, and let dLev:A??A??
N represent the Levenshtein distanceover grapheme strings, then define for every inputword w ?
A?
the ?best?
synchronic equivalent1P is a finite phonetic alphabet.bestLev(w) as the unique extant word v ?
Lexwith minimal edit-distance to the input word:2bestLev(w) = arg minv?LexdLev(w, v) (2)Ideally, the image of a word w under bestLevwillitself be the canonical cognate sought,3 leading toconflation of all strings which share a common im-age under bestLev:w ?Levv :?
bestLev(w) = bestLev(v) (3)The function bestLev(w) : A??
Lex can becomputed using a variant of the Dijkstra algorithm(Dijkstra, 1959) even when the lexicon is infinite(as in the case of productive nominal compositionin German) whenever the set Lex can be repre-sented by a finite-state acceptor (Mohri, 2002; Al-lauzen and Mohri, 2009; Jurish, 2010).
For currentpurposes, we used the (infinite) input languageof the TAGH morphology transducer (Geyken andHanneforth, 2006) stripped of proper names, ab-breviations, and foreign-language material to ap-proximate Lex.2.3 Rewrite TransducerWhile the simple edit distance conflation tech-nique from the previous section is quite powerfuland requires for its implementation only a lexiconof extant forms, the Levenshtein distance itself ap-pears in many cases too coarse to function as areliable predictor of etymological relations, sinceeach edit operation (deletion, insertion, or substi-tution) is assigned a cost independent of the char-acters operated on and of the immediate contextin the strings under consideration.
This operand-independence of the traditional Levenshtein dis-tance results in a number of spurious conflationssuch as those given in Table 1.In order to achieve a finer-grained and thusmore precise mapping from historical forms to ex-tant canonical cognates while preserving some de-gree of the robustness provided by the relaxationof the strict identity criterion implicit in the edit-distance conflation technique, a non-deterministicweighted finite-state ?rewrite?
transducer was de-veloped to replace the simple Levenshtein met-ric.
The rewrite transducer was compiled from a2We assume that whenever multiple extant minimal-distance candidate forms exist, one is chosen randomly.3Note here that every extant form is its own ?best?equivalent: w ?
Lex implies bestLev(w) = w, sincedLev(w,w) = 0 < dLev(w, v) for all v 6= w.73w bestLev(w) Extant Equivalentaug aus ?out?
auge ?eye?faszt fast ?almost?
fasst ?grabs?ouch buch ?book?
auch ?also?ram rat ?advice?
rahm ?cream?vol volk ?people?
voll ?full?Table 1: Example spurious Levenshtein distanceconflationsheuristic two-level rule-set (Karttunen et al, 1987;Kaplan and Kay, 1994; Laporte, 1997) whose 306rules were manually constructed to reflect linguis-tically plausible patterns of diachronic variationas observed in the lemma-instance pairs automat-ically extracted from the full 5.5 million wordDWB verse corpus (Jurish, 2008).
In particu-lar, phonetic phenomena such as schwa deletion,vowel shift, voicing alternation, and articulatorylocation shift are easily captured by such rules.Of the 306 heuristic rewrite rules, 131 manipu-late consonant-like strings, 115 deal with vowel-like strings, and 14 operate directly on syllable-like units.
The remaining 46 rules define expan-sions for explicitly marked elisions and unrecog-nized input.
Some examples of rules used by therewrite transducer are given in Table 2.Formally, the rewrite transducer ?rwdefinesa pseudo-metric J?rwK : A??
A??
R?onall string pairs (Mohri, 2009).
Assuming thenon-negative tropical semiring (Simon, 1987) isused to represent transducer weights, analagous tothe transducer representation of the Levenshteinmetric (Allauzen and Mohri, 2009), the rewritepseudo-metric can be used as a drop-in replace-ment for the Levenshtein distance in Equations (2)and (3), yielding Equations (4) and (5):bestrw(w) = arg minv?LexJ?rwK(w, v) (4)w ?rwv :?
bestrw(w) = bestrw(v) (5)3 Evaluation3.1 Test CorpusThe conflation techniques described above weretested on a corpus of historical German verseextracted from the quotation evidence in a sin-gle volume of the digital first edition of the dic-tionary Deutsches Wo?rterbuch ?DWB?
(Bartz etal., 2004).
The test corpus contained 11,242 to-kens of 4157 distinct word types, discounting non-alphabetic types such as punctuation.
Each cor-pus type was manually assigned one or more ex-tant equivalents based on inspection of its occur-rences in the whole 5.5 million word DWB versecorpus in addition to secondary sources.
Only ex-tinct roots, proper names, foreign and other non-lexical material were not explicitly assigned anyextant equivalent at all; such types were flaggedand treated as their own canonical cognates, i.e.identical to their respective ?extant?
equivalents.In all other cases, equivalence was determined bydirect etymological relation of the root in additionto matching morphosyntactic features.
Problem-atic types were marked as such and subjected toexpert review.
296 test corpus types represent-ing 585 tokens were ambiguously associated withmore than one canonical cognate.
In a second an-notation pass, these remaining ambiguities wereresolved on a per-token basis.3.2 Evaluation MeasuresThe three conflation strategies from Section 2were evaluated using the gold-standard test corpusto simulate a document indexing and query sce-nario.
Formally, let G ?
A?
?
A?
represent thefinite set of all gold-standard pairs (w, w?)
with w?the manually determined canonical cognate for thecorpus type w, and let Q = {w?
: ?
(w, w?)
?
G}be the set of all canonical cognates represented inthe corpus.
Then define for a binary conflation re-lation ?Ron A?
and a query string q ?
Q the setsrelevant(q), retrievedR(q) ?
G of relevant andretrieved gold-standard pairs as:relevant(q) = {(w, w?)
?
G : w?
= q}retrievedR(q) = {(w, w?)
?
G : w ?Rq}Type-wise precision and recall can then be de-fined directly as:prG=???
?q?QretrievedR(q) ?
relevant(q)???????q?QretrievedR(q)???rcG=???
?q?QretrievedR(q) ?
relevant(q)???????q?Qrelevant(q)??
?If tpR(q) = retrievedR(q) ?
relevant(q) rep-resents the set of true positives for a query q,then token-wise precision and recall are definedin terms of the gold-standard frequency function74From ?
To / Left Right ?Cost?
Example(s)?
?
e / (A\{e}) # ?
5 ?
aug; auge ?eye?z ?
s / s ?
1 ?
faszt; fasst ?grabs?o ?
a / u ?
1 ?
ouch; auch ?also??
?
h / V C ?
5 ?
ram; rahm ?cream?l ?
ll / ?
8 ?
vol; voll ?full?Table 2: Some example heuristics used by the rewrite transducer.
Here, ?
represents the empty string,# represents a word boundary, and V,C ?
A are sets of vowel-like and consonant-like characters,respectively.fG: G ?
N as:prfG=?q?Q,g?tpR(q)fG(g)?q?Q,g?retrievedR(q)fG(g)rcfG=?q?Q,g?tpR(q)fG(g)?q?Q,g?relevant(q)fG(g)We use the unweighted harmonic precision-recall averageF(van Rijsbergen, 1979) as a com-posite measure for both type- and token-wise eval-uation modes:F(pr, rc) =2 ?
pr ?
rcpr + rc3.3 ResultsThe elementary canonicalization function for eachof the conflation techniques4 was applied to theentire test corpus to simulate a corpus indexingrun.
Running times for the various methods ona 1.8GHz Linux workstation using the gfsmxlC library are given in Table 3.
The Levenshteinedit-distance technique is at a clear disadvantagehere, roughly 150 times slower than the phonetictechnique and 40 times slower than the special-ized heuristic rewrite transducer.
This effect isassumedly due to the density of the search space(which is maximal for an unrestricted Levenshteineditor), since the gfsmxl greedy k-best searchof a Levenshtein transducer cascade generates atleast |A| configurations per character, and a sin-gle backtracking step requires an additional 3|A|heap extractions (Jurish, 2010).
Use of specializedlookup algorithms (Oflazer, 1996) might amelio-rate such problems.Qualitative results for several conflation tech-niques with respect to the DWB verse test corpusare given in Table 4.
An additional conflation rela-tion ?Id?
using strict identity of grapheme strings4pho, bestLevand bestrwfor the phonetic, Levenshtein,and heuristic rewrite transducer methods respectivelyMethod Time ThroughputPho 1.82 sec 7322 tok/secLev 278.03 sec 48 tok/secrw 7.02 sec 1898 tok/secTable 3: Processing time for elementary canoni-calization functions(w ?Idv :?
w = v) was tested to provide abaseline for the methods described in Section 2.As expected, the strict identity baseline relationwas the most precise of all methods tested, achiev-ing 99.9% type-wise and 99.1% token-wise pre-cision.
This is unsurprising, since the Id methodyields false positives only when a historical formis indistinguishable from a non-equivalent extantform, as in the case of the mapping wider ;wieder (?again?)
and the non-equivalent extantform wider (?against?).
Despite its excellent pre-cision, the baseline method?s recall was the low-est of any tested method, which supports the claimthat a synchronically-oriented lexicon cannot ad-equately account for a corpus of historical text.Type-wise recall was particularly low (70.8%), in-dicating that diachronic variation was more com-mon in low-frequency types.Surprisingly, the phonetic and Levenshteinedit-distance methods performed similarly forall measures except token-wise precision, inwhich Lev incurred 61.6% fewer errors thanPho.
Given their near-identical type-wiseprecision, this difference can be attributedto a small number of phonetic misconfla-tions involving high-frequency types, such aswider?wieder (?against???again?
), statt?stadt,(?instead???city?
), and in?ihn (?in???him?
).Contrary to expectations, Lev did not yieldany recall improvements over Pho, although theunion of the two underlying conflation relations75Type-wise % Token-wise %R prGrcGFGprfGrcfGFfGId 99.9 70.8 82.9 99.1 83.7 90.7Pho 96.7 80.1 87.6 92.7 89.6 91.1Lev 96.6 78.9 86.9 97.2 87.8 92.2rw 98.5 88.4 93.2 98.2 93.4 95.8Pho |Lev 94.1 84.3 88.9 91.3 91.6 91.5Pho | rw 96.1 89.8 92.8 92.5 94.5 93.5Table 4: Qualitative evaluation of various conflation techniques(?Pho |Lev= ?Pho?
?Lev) achieved a type-wiserecall of 84.3% (token-wise recall 91.6%), whichsuggests that these two methods complement oneanother when both an LTS module and a high-coverage lexicon of extant types are available.Of the methods described in Section 2, theheuristic rewrite transducer ?rwperformed bestoverall, with a type-wise harmonic mean F of93.2% and a token-wise F of 95.8%.
While ?rwincurred some additional precision errors com-pared to the na?
?ve graphemic identity method Id,these were not as devastating as those incurredby the phonetic or Levenshtein distance meth-ods, which supports the claim from Section 2.3that a fine-grained context-sensitive pseudo-metricincorporating linguistic knowledge can more ac-curately model diachronic processes than an all-purpose metric like the Levenshtein distance.Recall was highest for the composite phonetic-rewrite relation ?Pho | rw=?Pho?
?rw, althoughthe precision errors induced by the phonetic com-ponent outweighed the comparatively small gainin recall.
The best overall performance is achievedby the heuristic rewrite transducer ?rwon its own,yielding a reduction of 60.3% in type-wise recallerrors and of 59.5% in token-wise recall errors,while minimizing the number of newly introducedprecision errors.4 Conclusion & OutlookWe have presented three different methods forassociating unknown historical word forms withsynchronically active canonical cognates.
Theheuristic mapping of unknown forms to extantequivalents by means of linguistically motivatedcontext-sensitive rewrite rules yielded the best re-sults in an information retrieval task on a corpusof historical German verse, reducing type-wiserecall errors by over 60% compared to a na?
?vetext-matching strategy.
Depending on the avail-ability of linguistic resources (e.g.
phonetizationrule-sets, lexica), use of phonetic canonicalizationand/or Levenshtein edit distance may provide amore immediately accessible route to improved re-call for other languages or applications, at the ex-pense of some additional loss of precision.We are interested in verifying our results us-ing larger corpora than the small test corpus usedhere, as well as extending the techniques describedhere to other languages and domains.
In par-ticular, we are interested in comparing the per-formance of the domain-specific rewrite trans-ducer used here to other linguistically motivatedlanguage-independent metrics such as (Covington,1996; Kondrak, 2000).AcknowledgementsThe work described above was funded by aDeutsche Forschungsgemeinschaft (DFG) grant tothe project Deutsches Textarchiv.
Additionally,the author would like to thank Jo?rg Didakowski,Oliver Duntze, Alexander Geyken, Thomas Han-neforth, Henriette Scharnhorst, Wolfgang Seeker,Kay-Michael Wu?rzner, and this paper?s anony-mous reviewers for their helpful feedback andcomments.ReferencesCyril Allauzen and Mehryar Mohri.
2009.
Linear-space computation of the edit-distance between astring and a finite automaton.
In London Algorith-mics 2008: Theory and Practice.
College Publica-tions.Jonathan Allen, M. Sharon Hunnicutt, and DennisKlatt.
1987.
From Text to Speech: the MITalk sys-tem.
Cambridge University Press.Hans-Werner Bartz, Thomas Burch, Ruth Christmann,Kurt Ga?rtner, Vera Hildenbrandt, Thomas Schares,and Klaudia Wegge, editors.
2004.
Der Digitale76Grimm.
Deutsches Wo?rterbuch von Jacob und Wil-helm Grimm.
Zweitausendeins, Frankfurt am Main.Eric Brill.
1992.
A simple rule-based part-of-speechtagger.
In Proceedings of ANLP-92, 3rd Conferenceon Applied Natural Language Processing, pages152?155, Trento, Italy.Mike Cafarella and Doug Cutting.
2004.
BuildingNutch: Open source search.
Queue, 2(2):54?61.Simon Clematide.
2008.
An OLIF-based open inflec-tion resource and yet another morphological systemfor German.
In Storrer et al (Storrer et al, 2008),pages 183?194.Michael A. Covington.
1996.
An algorithm to alignwords for historical comparison.
ComputationalLinguistics, 22:481?496.Stephen DeRose.
1988.
Grammatical category disam-biguation by statistical optimization.
ComputationalLinguistics, 14(1):31?39.Edsger W. Dijkstra.
1959.
A note on two problemsin connexion with graphs.
Numerische Mathematik,1:269?271.Thierry Dutoit.
1997.
An Introduction to Text-to-Speech Synthesis.
Kluwer, Dordrecht.Alexander Geyken and Thomas Hanneforth.
2006.TAGH: A complete morphology for German basedon weighted finite state automata.
In ProceedingsFSMNLP 2005, pages 55?66, Berlin.
Springer.Bryan Jurish.
2008.
Finding canonical forms for his-torical German text.
In Storrer et al (Storrer et al,2008), pages 27?37.Bryan Jurish.
2010.
Efficient online k-best lookup inweighted finite-state cascades.
To appear in StudiaGrammatica.Ronald M. Kaplan and Martin Kay.
1994.
Regu-lar models of phonological rule systems.
Compu-tational Linguistics, 20(3):331?378.Lauri Karttunen, Ronald M. Kay, and Kimmo Kosken-niemi.
1987.
A compiler for two-level phonologicalrules.
In M. Dalrymple, R. Kaplan, L. Karttunen,K.
Koskenniemi, S. Shaio, and M. Wescoat, editors,Tools for Morphological Analysis, volume 87-108 ofCSLI Reports, pages 1?61.
CSLI, Stanford Univer-sity, Palo Alto, CA.Gregorz Kondrak.
2000.
A new algorithm for thealignment of phonetic sequences.
In ProceedingsNAACL, pages 288?295.
?Eric Laporte.
1997.
Rational transductions for pho-netic conversion and phonology.
In EmmanuelRoche and Yves Schabes, editors, Finite-State Lan-guage Processing.
MIT Press, Cambridge, MA.Vladimir I. Levenshtein.
1966.
Binary codes capa-ble of correcting deletions, insertions, and reversals.Soviet Physics Doklady, 10(1966):707?710.Julie Beth Lovins.
1968.
Development of a stemmingalgorithm.
Mechanical Translation and Computa-tional Linguistics, 11:22?31.Mehryar Mohri.
2002.
Semiring frameworks andalgorithms for shortest-distance problems.
Jour-nal of Automata, Languages and Combinatorics,7(3):321?350.Mehryar Mohri.
2009.
Weighted automata algorithms.In Handbook of Weighted Automata, Monographsin Theoretical Computer Science, pages 213?254.Springer, Berlin.Gregor Mo?hler, Antje Schweitzer, and Mark Breit-enbu?cher, 2001.
IMS German Festival manual, ver-sion 1.2.
Institute for Natural Language Processing,University of Stuttgart.Gonzalo Navarro.
2001.
A guided tour to approx-imate string matching.
ACM Computing Surveys,33(1):31?88.Kemal Oflazer.
1996.
Error-tolerant finite-state recog-nition with applications to morphological analysisand spelling correction.
Computational Linguistics,22(1):73?89.Martin F. Porter.
1980.
An algorithm for suffix strip-ping.
Program, 14(3):130?137.Helmut Schmid.
1994.
Probabilistic part-of-speechtagging using decision trees.
In International Con-ference on New Methods in Language Processing,pages 44?49, Manchester, UK.Imre Simon.
1987.
The nondeterministic complex-ity of finite automata.
Technical Report RT-MAP-8073, Instituto de Matema?tica e Estat?
?stica da Uni-versidade de Sa?o Paulo.Alexey Sokirko.
2003.
A technical overview ofDWDS/dialing concordance.
Talk delivered at themeeting Computational linguistics and intellectualtechnologies, Protvino, Russia.Angelika Storrer, Alexander Geyken, AlexanderSiebert, and Kay-Michael Wu?rzner, editors.
2008.Text Resources and Lexical Knowledge.
Mouton deGruyter, Berlin.C.
J. van Rijsbergen.
1979.
Information Retrieval.Butterworth-Heinemann, Newton, MA.77
