Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 1?10,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsUnsupervised Induction of Semantic Roleswithin a Reconstruction-Error Minimization FrameworkIvan Titov Ehsan KhoddamUniversity of Amsterdam{titov|e.khoddammohammadi}@uva.nlAbstractWe introduce a new approach to unsupervisedestimation of feature-rich semantic role la-beling models.
Our model consists of twocomponents: (1) an encoding component: asemantic role labeling model which predictsroles given a rich set of syntactic and lexi-cal features; (2) a reconstruction component:a tensor factorization model which relies onroles to predict argument fillers.
When thecomponents are estimated jointly to minimizeerrors in argument reconstruction, the inducedroles largely correspond to roles defined in an-notated resources.
Our method performs onpar with most accurate role induction methodson English and German, even though, unlikethese previous approaches, we do not incorpo-rate any prior linguistic knowledge about thelanguages.1 IntroductionShallow semantic representations, and semantic rolelabels in particular, have a long history in linguis-tics (Fillmore, 1968).
More recently, with an emer-gence of large annotated resources such as Prop-Bank (Palmer et al, 2005) and FrameNet (Baker etal., 1998), automatic semantic role labeling (SRL)has attracted a lot of attention (Gildea and Jurafsky,2002; Carreras and M`arquez, 2005; Surdeanu et al,2008; Haji?c et al, 2009; Das et al, 2010).Semantic role representations encode the under-lying predicate-argument structure of sentences, or,more specifically, for every predicate in a sentencethey identify a set of arguments and associate eachargument with an underlying semantic role, suchas an agent (an initiator or doer of the action) ora patient (an affected entity).
Semantic roles havemany potential applications in NLP and have beenshown to benefit question answering (Shen and Lap-ata, 2007; Kaisser and Webber, 2007), textual entail-ment (Sammons et al, 2009), machine translation(Wu and Fung, 2009; Liu and Gildea, 2010; Wu etal., 2011; Gao and Vogel, 2011), and dialogue sys-tems (Basili et al, 2009; van der Plas et al, 2009),among others.Most current statistical approaches to SRL are su-pervised, requiring large quantities of human an-notated data to estimate model parameters.
How-ever, such resources are expensive to create and onlyavailable for a small number of languages.
More-over, when moved to a new domain (e.g., from newscorpora to blogs or biomedical texts), the perfor-mance of these models tends to degrade substan-tially (Pradhan et al, 2008).
The scarcity of an-notated data has motivated the research into unsu-pervised learning of semantic representations (Swierand Stevenson, 2004; Grenager and Manning, 2006;Lang and Lapata, 2010; Lang and Lapata, 2011a;Lang and Lapata, 2011b; Titov and Klementiev,2012a; F?urstenau and Rambow, 2012; Garg andHenderson, 2012).
The existing methods have anumber of serious shortcomings.
First, they makevery strong assumptions, for example, assuming thatarguments are conditionally independent of eachother given the predicate.
Second, unlike state-of-the-art supervised parsers, they rely on a very sim-plistic set of features of a sentence.
These fac-tors lead to models being insufficiently expressive tocapture the syntax-semantics interface, inadequate1handling of language ambiguity and, overall, in-troduces a restrictive upper bound on their perfor-mance.
Moreover, these approaches are especiallyproblematic for languages with freer word orderthan English, where richer features are necessaryto account for interactions between surface realiza-tions, syntax and semantics.
For example, the twomost accurate previous models (Titov and Klemen-tiev, 2012a; Lang and Lapata, 2011a) both treat therole induction task as clustering of argument signa-tures: an argument signature encodes key syntacticproperties of an argument realization and consists ofa syntactic function of an argument along with ad-ditional information such as an argument positionwith respect to the predicate.
Though it is possibleto design signatures which mostly map to a singlerole, this set-up limits oracle performance even forEnglish, and can be quite restrictive for languageswith freer word order.
These shortcomings are in-herent limitations of the modeling frameworks usedin previous work (primarily generative modeling oragglomerative clustering), and cannot be addressedby simply incorporating more features or relaxingsome of the modeling assumptions.In this work, we propose a method for effectiveunsupervised estimation of feature-rich models ofsemantic roles.
We demonstrate that reconstruction-error objectives, which have been shown to be effec-tive primarily for training neural networks, are wellsuited for inducing feature-rich log-linear models ofsemantics.
Our model consists of two components:a log-linear feature-rich semantic role labeler anda tensor-factorization model which captures inter-action between semantic roles and argument fillers.When estimated jointly on unlabeled data, roles in-duced by the model mostly corresponds to roles de-fined in existing resources by annotators.Our method rivals the most accurate semanticrole induction methods on English and German(Titov and Klementiev, 2012a; Lang and Lapata,2011a).
Importantly, no prior knowledge aboutthe languages was incorporated in our feature-richmodel, whereas the clustering counterparts reliedon language-specific argument signatures.
Theselanguages-specific priors were crucial for their suc-cess.
For example, using English-specific argumentsignatures for German with the Bayesian model ofTitov and Klementiev (2012a) results in a drop ofperformance from clustering F1 of 80.9% to consid-erably lower 78.3% (our model yields 81.4%).
Thisconfirms the intuition that using richer features helpsto capture the syntax-semantics interface in multi-lingual settings, reducing the need for language-specific model engineering, as is highly desirable inunsupervised learning.The rest of the paper is structured as follows.
Sec-tion 2 begins with a definition of the semantic rolelabeling task and discusses some specifics of the un-supervised setting.
In Section 3, we describe our ap-proach, starting with a general motivation and pro-ceeding to technical details of the model (Section3.3) and the learning procedure (Section 3.4).
Sec-tion 4 provides both evaluation and analysis.
Finally,additional related work is presented in Section 5.2 Task DefinitionThe SRL task involves prediction of predicate argu-ment structure, i.e.
both identification of argumentsand assignment of labels according to their under-lying semantic role.
For example, in the followingsentences:(a) [AgentMary] opened [Patientthe door].
(b) [PatientThe door] opened.
(c) [PatientThe door] was opened [Agentby Mary].Mary always takes an agent role for the predicateopen, and door is always a patient.In this work we focus on the labeling stage ofsemantic role labeling.
Identification, though animportant problem, can be tackled with heuris-tics (Lang and Lapata, 2011a; Grenager and Man-ning, 2006; de Marneffe et al, 2006), with unsuper-vised techniques (Abend et al, 2009) or potentiallyby using a supervised classifier trained on a smallamount of data.3 ApproachAt the core of our approach is a statistical model en-coding an interdependence between a semantic rolestructure and its realization in a sentence.
In the un-supervised learning setting, sentences, their syntac-tic representations and argument positions (denotedby x) are observable whereas the associated seman-tic roles r are latent and need to be induced by the2model.
The idea which underlines much of latentvariable modeling is that a good latent representa-tion is the one which helps us to reconstruct x. Inpractice, we are not interested in predicting x, as xis observable, but rather interested in inducing ap-propriate latent representations (i.e.
r).
Thus, itis crucial to design the model in such a way thatthe good r (the one predictive of x) indeed encodesroles, rather than some other form of abstraction.In what follows, we will refer to roles usingtheir names, though, in the unsupervised setting, ourmethod, as any other latent variable model, will notyield human-interpretable labels for them.
We willuse the following sentence as a motivating examplein our discussion of the model:[AgentThe police] charged [Patientthedemonstrators] [Instrumentwith batons].The model consists of two components.
The firstcomponent is responsible for prediction of argumenttuples based on roles and the predicate.
In our exper-iments, in this component, we represent argumentsas lemmas of their lexical heads (e.g., baton insteadof with batons).
We also restrict ourselves to onlyverbal predicates.
Intuitively, we can think of pre-dicting one argument at a time (see Figure 1(b)):an argument (e.g., demonstrator in our example) ispredicted based on the predicate lemma (charge),the role assigned to this argument (i.e.
Patient)and other role-argument pairs ((Agent, police) and(Instrument, baton)).
While learning to predictarguments, the inference algorithm will search forrole assignments which simplify this prediction taskas much as possible.
Our hypothesis is that theseassignments will correspond to roles accepted in lin-guistic theories (or, more importantly, useful in prac-tical applications).
Why is this hypothesis plausi-ble?
Primarily because these semantic representa-tions were introduced as an abstraction capturing theessence of a situation (or a event).
And the underly-ing situation and participant roles in this situation(rather than surface linguistic details like argumentorder or syntactic functions) are precisely what im-pose constraints on admissible argument tuples.The reconstruction component is not the only partof the model.
Crucially, what we referred to aboveas ?searching for role assignments to simplify ar-gument prediction?
would actually correspond tolearning another component: a semantic role labelerwhich predicts roles relying on a rich set of sentencefeatures.
These two components will be estimatedjointly in such a way as to minimize errors in recov-ering arguments.
The role labeler will be the end-product of learning: it will be used to process newsentences, and it will be compared to existing meth-ods in our evaluation.3.1 Shortcomings of generative modelingThe above paragraph can be regarded as our desider-ata; now we discuss how to achieve them.
The stan-dard way to approach latent variable modeling isto use the generative framework: that is to definea family of joint models p(x, y|?)
and estimate theparameters ?
by, for example, maximizing the likeli-hood.
Generative models of semantics (Titov andKlementiev, 2012a; Titov and Klementiev, 2011;Modi et al, 2012; O?Connor, 2013; Kawahara et al,2014) necessarily make very strong independenceassumptions (e.g., arguments are conditionally inde-pendent of each other given the predicate) and usesimplistic features of x and y.
Thus, they cannotmeet the desiderata stated above.
Importantly, theyare also much more simplistic in their assumptionsthan state-of-the-art supervised role labelers (Erkand Pado, 2006; Johansson and Nugues, 2008; Daset al, 2010).3.2 Reconstruction error minimizationGenerative modeling is not the only way to learn la-tent representations.
One alternative, popular in theneural network community, is to instead use autoen-coders and optimize the reconstruction error (Hin-ton, 1989; Vincent et al, 2008).
In autoencoders,a latent representation y (their hidden layer) is pre-dicted from x by an encoding model and then this yis used to recover x?with a reconstruction model (seeFigure 1(a)).
Parameters of the encoding and recon-struction components are chosen so as to minimizesome form of the reconstruction error, for example,the Euclidean distance ?
(x, x?)
= ||x?x?||2.
Thoughcurrently popular only within the deep learning com-munity, latent variable models other than neural net-works can also be trained this way, moreover:?
the encoding and reconstruction models can be-long to different model families;3ReconstructedinputEncodingReconstructionInputy 2 RpLatent representationFeature representation of "The police charged...  " (    )Semantic role prediction( = Encoding)charge(Agent: police,   Patient:  demonstrator,   Instrument: baton)demonstratorArgument prediction( = Reconstruction)Hiddenp(r|x,w)Feature-rich model"Argument prediction" model(a) (b)x 2 Rmx?
2 Rmp(ai|a i, r, v, ?
)xFigure 1: (a) An autoencoder from Rmto Rp(typically p < m).
(b) Modeling roles within the reconstruction-errorminimization framework.?
the reconstruction component may be focusedon recovering a part of x rather than the entirex, and, in doing so, can rely not only on y buton the remaining part of x.These observations are crucial as they allow us toimplement our desiderata.
More specifically, the en-coding model will be a feature-rich classifier whichpredicts semantic roles for a sentence, and the re-construction model is the model which predicts anargument given its role, and given the rest of the ar-guments and their roles.
The idea of training linearmodels by minimizing the reconstruction error waspreviously explored by Daum?e (2009) and very re-cently by Ammar et al (2014).3.3 Modeling semantics within thereconstruction-error frameworkThere are several possible ways to translate the ideasabove into a specific method, and we consider oneof the simplest instantiations.
For simplicity, in thediscussion (but not in our experiments), we assumethat exactly one predicate is realized in each sen-tence x.
As we mentioned above, we focus onlyon argument labeling: we assume that argumentsa = (a1, .
.
.
, aN), ai?
A, are known, and onlytheir roles r = (r1, .
.
.
, rN), ri?
R need to beinduced.
For the encoder (i.e.
the semantic role la-beler), we use a log-linear model:p(r|x,w) ?
exp(wTg(x, r)),where g(x, r) is a feature vector encoding interac-tions between sentence x and the semantic role rep-resentation r. Any model can be used here as longas the posterior distributions of roles rican be effi-ciently computed or approximated (we will see whyin Section 3.4).
In our experiments, we used a modelwhich factorizes over individual arguments (i.e.
a setof independent logistic regression classifiers).The reconstruction component predicts an argu-ment (e.g., the ith argument ai) given the seman-tic roles r, the predicate v and other argumentsa?i= (a1, .
.
.
, ai?1, ai+1, .
.
.
, aN) with a bilinearsoftmax model:p(ai|a?i, r,v,C,u)=exp(uTaiCTv,ri?j 6=iCv,rjuaj)Z(r, v, i), (1)ua?
Rd(for every a ?
A) and Cv,r?
Rk?d(forevery verb v and every role r ?
R) are model pa-rameters, Z(r, v, i) is the partition function ensur-ing that the probabilities sum to one.
Intuitively,embeddings ua, when learned from data, will en-code semantic properties of an argument: for ex-ample, embeddings for the words demonstrator andprotestor should be somewhere near each other inRdspace, and further away from that for the wordcat.
The product Cv,ruais a k-dimensional vec-tor encoding beliefs about other arguments based onthe argument-role pair (a, r).
For example, seeingthe argument demonstrator in the Patient posi-tion for the predicate charge, one would predict thatthe Agent is perhaps the word police, and the roleInstrument is filled by the word baton or perhaps4(a water) cannon.
On the contrary, if the Patientis cat then the Agent is more likely to be dog thanpolice.
In turn, the dot product (Cv,riuai)TCv,rjuajis large if these expectations are met for the argu-ment pair (ai, aj), and small otherwise.
Intuitively,this objective corresponds to scoring argument tu-ples according toh(a, r, v, C,u) =?i 6=juTaiCTv,riCv,rjuaj, (2)hinting at connections to (coupled) tensor and matrixfactorization methods (Nickel et al, 2011; Y?lmazet al, 2011; Bordes et al, 2011; Riedel et al, 2013)and distributional semantics (Mikolov et al, 2013;Pennington et al, 2014).
Note also that the recon-struction model does not have access to any fea-tures of the sentence (e.g., argument order or syn-tax), forcing the roles to convey all the necessaryinformation.This factorization can be thought of as a general-ization of the notion of selection preferences.
Selec-tional preferences characterize the set of argumentslicensed for a given role of a given predicate: for ex-ample, Agent for the predicate charge can be policeor dog but not table or idea.
In our generalization,we model soft restrictions imposed not only by therole itself but also by other arguments and their as-signment to roles.In practice, we extend the model slightly: (1) weintroduce a word-specific bias (a scalar bafor ev-ery a ?
A) in the argument prediction model (equa-tion (1)); (2) we smooth the model by using a sumof predicate-specific and cross-predicate projectionmatrices (Cv,r+ Cr) instead of just Cv,r.3.4 LearningParameters of both model components (w, u and C)are learned jointly: the natural objective associatedwith every sentence would be the following:N?i=1log?rp(ai|a?i, r, v, C,u)p(r|x,w).
(3)However optimizing this objective is not practicalin its exact form for two reasons: (1) marginaliza-tion over r is exponential in the number of argu-ments; (2) the partition function Z(r, v, i) requiressummation over the entire set of potential argumentlemmas.
We use existing techniques to address bothchallenges.In order to deal with the first challenge, we usea basic mean-field approximation.
Namely, insteadof computing an expectation of p(ai|a?i, r,v,C,u)under p(r|x,w), as in (3), we use the posterior dis-tributions ?is= p(ri = s|x,w) and score the argu-ment predictions asp(ai|a?i,?,v,C,u) =exp (?i(ai,a?i))Z(?, v, i)(4)?i(ai,a?i) = uTai(?s?isCv,s)T?
?j 6=i(?s?jsCv,s)uaj,where ?
are the posteriors for all the arguments,and ?i(a,a?i) is the score associated with predict-ing lemma a for the argument i.In order to address the second problem, the com-putation of Z(?, v, i), we use a negative samplingtechnique (see, e.g., Mikolov et al (2013)).
Morespecfically, we get rid of the softmax in equation (4)and optimize the following sentence-level objective:N?i=1[log ?(?i(ai,a?i))??a?
?Slog ?
(?i(a?,a?i))], (5)where S is a random sample of n elements from theunigram distribution of lemmas, and ?
is the logisticsigmoid function.Assuming that the posteriors ?
can be derived ina closed form, the gradients of the objective (5) withrespect to parameters of both the encoding compo-nent (w) and the reconstruction component (C, uand b) can be computed using back propagation.In our experiments, we used the AdaGrad algo-rithm (Duchi et al, 2011) to perform the optimiza-tion.The learning algorithm is quite efficient, as thereconstruction computation is bilinear, whereas thecomputation of the posteriors ?
(and the computa-tion of their gradients) from the semantic roler la-beling component (encoder) is not much more ex-pensive than discriminative supervised learning of5the role labeler.
Moreover, the computations canbe sped up substantially by observing that the sum?s?isCv,sin expression (4) can be precomputedfor all i, and reused across predictions of differentarguments of the same predicate.
At test time, onlythe linear semantic role labeler is used, so the infer-ence is straightforward.4 Experiments4.1 Data and evaluation metricsWe considered English and German in our experi-ments.
For each language, we replicated experimen-tal set-ups used in previous work.For English, we followed Lang and Lap-ata (2010) and used the dependency version of Prop-Bank (Palmer et al, 2005) released for the CoNLL2008 shared task (Surdeanu et al, 2008).
Thedataset is divided into three segments.
As in the pre-vious work on unsupervised role labeling, we usedthe largest segment (the original CoNLL training set,sections 2-21) both for evaluation and learning.
Thisis permissible as unsupervised models do not usegold labels in training.
The two small segments (sec-tions 22 and 23) were used for model development.In our experiments, we relied on gold standard syn-tax and gold standard argument identification, as thisset-up allows us to evaluate against much of the pre-vious work.
We refer the reader to Lang and Lap-ata (2010) for details of the experimental set-up.There has not been much work on unsupervisedinduction of roles for languages other than English,perhaps primarily because of the above-mentionedmodel limitations.
For German, we replicate theset-up considered in Titov and Klementiev (2012b).They used the CoNLL 2009 version (Haji?c et al,2009) of the SALSA corpus (Burchardt et al, 2006).Instead of using syntactic parses provided in theCoNLL dataset, they re-parsed it with the MALTdependency parser (Nivre et al, 2004).
Similarly,rather than relying on gold standard annotations forargument identification, they used a supervised clas-sifier to predict argument positions.
Details of thepreprocessing can be found in Titov and Klemen-tiev (2012b).As in most previous work on unsupervised SRL,we evaluate our model using purity, collocation andtheir harmonic mean F1.
Purity (PU) measures theaverage number of arguments with the same goldrole label in each cluster, collocation (CO) measuresto what extent a specific gold role is represented bya single cluster.
More formally:PU =1N?imaxj|Gj?
Ci|where if Ciis the set of arguments in the i-th in-duced cluster, Gjis the set of arguments in the jthgold cluster, andN is the total number of arguments.Similarly, for collocation:CO =1N?jmaxi|Gj?
Ci|We compute the aggregate PU, CO, and F1 scoresover all predicates in the same way as Lang and La-pata (2010): we weight the scores for each predi-cate by the number of times its arguments occur andcompute the weighted average.4.2 Parameters and featuresFor the semantic role labeling (encoding) compo-nent, we relied on 14 feature patterns used for ar-gument labeling in a popular supervised role la-beler (Johansson and Nugues, 2008).
These patternsinclude non-trivial syntactic features, such as a de-pendency path between the target predicate and theconsidered argument.
The resulting feature spaceis quite large (49,474 feature instantiations for ourEnglish dataset) and arguably sufficient to accu-rately capture syntax-semantics interface for mostlanguages.
We refer the reader to the original publi-cation for details (Johansson and Nugues, 2008: Ta-ble 2).
Importantly, the dimensionality of the fea-ture space is very different from the one used typi-cally in unsupervised SRL.
In principle, any featurescould be used here but we chose these 14 feature pat-terns, as they all are fairly simple and generic.
Theycan also be easily extracted from any treebank.
Weused the same feature patterns both for English andGerman.
However, there is little doubt that somelanguage-specific feature engineering and the useof language-specific priors or constraints (e.g., pos-terior regularization (Ganchev et al, 2010)) wouldbenefit the performance.
Faithful to our goal of con-structing the simplest possible feature-rich model,6we use logistic classifiers independently predictingrole distribution for every argument.For the reconstruction component, both for En-glish and German, we set the embedding dimension-ality d, the projection dimensionality k and the num-ber of negative samples n to 30, 15 and 20, respec-tively.
The model was not sensitive to the parameter|R|, defining the number of roles as long it was largeenough (see Section 4.3 for more discussion).
Fortraining, we used uniform random initialization andAdaGrad (Duchi et al, 2011).
Any model selections(e.g., choosing the number of epochs) was done onthe basis of the respective held-out set.4.3 Results4.3.1 EnglishTable 1 summarizes the results of our method, aswell as those of alternative approaches and base-lines.Following (Lang and Lapata, 2010), we use abaseline (SyntF) which simply clusters predicate ar-guments according to the dependency relation totheir head.
A separate cluster is allocated for eachof 20 most frequent relations in the dataset and anadditional cluster is used for all other relations.
Asobserved in the previous work (Lang and Lapata,2011a), this is a hard baseline to beat.We also compare with previous approaches: thelatent logistic classification model (Lang and La-pata, 2010) (labeled LLogistic), the agglomerativeclustering method (Lang and Lapata, 2011a) (Ag-glom), the graph partitioning approach (Lang andLapata, 2011b) (GraphPart), the global role order-ing model (Garg and Henderson, 2012) (RoleOrder-ing).
We also report results of an improved ver-sion of Agglom, recently reported by Lang and La-pata (2014) (Agglom+).
The strongest previousmodel is Bayes: Bayes is the most accurate (?cou-pled?)
version of the Bayesian model of Titov andKlementiev (2012a), estimated from the CoNLLdataset without relying on any external data.
Titovand Klementiev (2012a) also showed that usingBrown clusters induced from a large external cor-pus resulted in an 0.5% improvement in F1 but thatversion is not entirely comparable to other systemsinduced solely from the CoNLL text.Our model outperforms or performs on par withPU CO F1Our Model 79.7 86.2 82.8Bayes 89.3 76.6 82.5Agglom+ 87.9 75.6 81.3RoleOrdering 83.5 78.5 80.9Agglom 88.7 73.0 80.1GraphPart 88.6 70.7 78.6LLogistic 79.5 76.5 78.0SyntF 81.6 77.5 79.5Table 1: Results on English (PropBank / CoNLL 2008).best previous models in terms of F1.
Interestingly,the purity and collocation balance is very differentfor our model and for the rest of the systems.
Infact, our model induces at most 4-6 roles (even if|R| is much larger).
On the contrary, Bayes predictsmore than 30 roles for the majority of frequent pred-icates (e.g., 43 roles for the predicate include or 35for say).
Though this tendency reduces the purityscores for our model, this also means that our rolesare more human interpretable.
For example, agentsand patients are clearly identifiable in the model pre-dictions.
Our model has similar purity to the syntac-tic baseline but outperforms it vastly according tothe collocation metric, suggesting that we go sub-stantially beyond recovering syntactic relations.In additional experiments, we observed that ourmodel, in some regimes, starts to induce roles spe-cific to individual verb senses or specific to groups ofsemantically similar predicates.
This suggests thatadding a latent variable capturing predicate sensesand conditioning the reconstruction component onthis variable may not only result in a more infor-mative semantic representation (i.e.
include verbsenses) but also improve the role induction perfor-mance.
We leave this exploration for future work.4.3.2 GermanFor German, we replicate the experimental set-uppreviously used by Titov and Klementiev (2012b).As for English, we report results of the syntacticbaseline (SyntF).
The results for all approaches arepresented in Table 2.
We compare against Bayes(De) ?
the Bayes model with argument signaturesspecialized for German (as reported in Titov andKlementiev (2012b)).
We also consider the original7PU CO F1Our Model 76.4 87.0 81.4Bayes (De) 86.8 75.7 80.9Bayes (En) 80.6 76.0 78.3SyntF 83.1 79.3 81.2Table 2: Results on German (SALSA / CoNLL 2009).version of the Bayes model (denoted as Bayes (En)).Recently, Lang and Lapata (2014) evaluated theirAgglom+ on a version of the same German SALSAdataset.
Their best result is F1 of 79.2%, however,this score and our results are not directly compara-ble.
Instead of using the CoNLL dataset, they pro-cessed the corpus themselves.
They also relied onsyntactic features from a constituent parser whereaswe used dependency representations.The overall picture for German closely resemblesthe one for English.
Our method achieves resultscomparable to the best method evaluated in this set-ting.
Importantly, parameters and features of ourmodel for German and English are identical.
Onthe contrary, one can see that specialization of argu-ment signatures was crucial for the Bayesian model.Also, similarly to English, our method induces lessfine-grain sets of semantic roles but achieves muchhigher collocation scores.5 Additional Related WorkIn recent years, unsupervised approaches to seman-tic role induction have attracted considerable atten-tion.
However, there exist other ways to addresslack of coverage provided by existing semantically-annotated resources.One natural direction is semi-supervised rolelabeling, where both annotated and unannotateddata is used to estimate a model.
Previous semi-supervised approaches to SRL can be mostly re-garded as extensions to supervised learning by ei-ther incorporating word features induced from un-nannoted texts (Collobert and Weston, 2008; De-schacht and Moens, 2009) or creating some formof ?surrogate?
supervision (He and Gildea, 2006;F?urstenau and Lapata, 2009).
Benefits from usingunlabeled data were moderate, and more significantfor the harder SRL version, frame-semantic pars-ing (Das and Smith, 2011).Another important direction includes cross-lingual approaches (Pado and Lapata, 2009; van derPlas et al, 2011; Kozhevnikov and Titov, 2013)which leverage resources from resource-rich lan-guages, as well as parallel data, to produce anno-tation or models for resource-poor languages.
How-ever, both translation shifts and noise in word align-ments harm the performance of cross-lingual meth-ods.
Nevertheless, even joint unsupervised induc-tion across languages appears to be beneficial (Titovand Klementiev, 2012b).Unsupervised learning has also been one of thecentral paradigms for the closely-related area ofrelation extraction (RE), where several techniqueshave been proposed to cluster semantically similarverbalizations of relations (Lin and Pantel, 2001;Banko et al, 2007; Yao et al, 2011).
Similarly toSRL, unsupervised methods for RE mostly rely ongenerative modeling and agglomerative clustering.From the learning perspective, methods which usethe reconstruction-error objective to estimate linearmodels (Ammar et al, 2014; Daum?e III, 2009) arecertainly related.
However, they do not considerlearning factorization models, and they also do notdeal with semantics.
Tensor factorization methodsused in the context of modeling knoweldge bases(e.g., (Bordes et al, 2011)) are also close in spirit.However, they do not deal with inducing semanticsbut rather factorize existing relations (i.e.
rely onsemantics).6 Conclusions and DiscussionThis work introduces a method for inducing feature-rich semantic role labelers from unannoated text.
Inour approach, we view a semantic role representa-tion as an encoding of a latent relation between apredicate and a tuple of its arguments.
We capturethis relation with a probabilistic tensor factorizationmodel.
The factorization model (relying on seman-tic roles) and a feature-rich model (predicting theroles) are jointly estimated by optimizing an objec-tive which favours accurate reconstruction of argu-ments given the latent semantic representation (andother arguments).
Our estimation method yields asemantic role labeler which achieves state-of-the-artresults both on English and German.Unlike previous work on role induction, in our8approach, virtually any computationally tractablestructured model can be used as a role labeler, in-cluding almost any semantic role labeler introducedin the context of supervised SRL (see, e.g., CoNLLshared tasks (Carreras and M`arquez, 2005; Sur-deanu et al, 2008; Haji?c et al, 2009)).
This opensinteresting possibilities to extend our approach tothe semi-supervised setting.
Previous unsupervisedSRL models make too strong assumption and use toolimited features to effectively exploit labeled data.For our model, the reconstruction objective can beeasily combined with the likelihood objective, yield-ing a potentially powerful semi-supervised method.We leave this direction for future work.AcknowledgementsThis work is partially supported by a Google focusedaward on natural language understanding.
The authorsthank Dipanjan Das, Ashutosh Modi, Alexis Palmer andthe anonymous reviewers for their suggestions.ReferencesO.
Abend, R. Reichart, and A. Rappoport.
2009.
Unsu-pervised argument identification for semantic role la-beling.
In ACL-IJCNLP.W.
Ammar, C. Dyer, and N. Smith.
2014.
Conditionalrandom field autoencoders for unsupervised structuredprediction.
In NIPS.Collin F. Baker, Charles J. Fillmore, and John B. Lowe.1998.
The Berkeley FrameNet project.
In ACL-COLING.M.
Banko, M. J. Cafarella, S. Soderland, M. Broadhead,and O. Etzioni.
2007.
Open information extractionfrom the web.
In IJCAI.R.
Basili, D. De Cao, D. Croce, B. Coppola, and A. Mos-chitti.
2009.
Cross-language frame semantics transferin bilingual corpora.
In CICLING.A.
Bordes, J. Weston, R. Collobert, and Y. Bengio.
2011.Learning structured embeddings of knowledge bases.In AAAI.A.
Burchardt, K. Erk, A. Frank, A. Kowalski, S. Pado,and M. Pinkal.
2006.
The SALSA corpus: a germancorpus resource for lexical semantics.
In LREC.X.
Carreras and L. M`arquez.
2005.
Introduction to theCoNLL-2005 Shared Task: Semantic Role Labeling.In CoNLL.R.
Collobert and J. Weston.
2008.
A unified architecturefor natural language processing: Deep neural networkswith multitask learning.
In ICML.D.
Das and N. A. Smith.
2011.
Semi-supervised frame-semantic parsing for unknown predicates.
In ACL.D.
Das, N. Schneider, D. Chen, and N. A. Smith.
2010.Probabilistic frame-semantic parsing.
In NAACL.H.
Daum?e III.
2009.
Unsupervised search-based struc-tured prediction.
In ICML.M.-C. de Marneffe, B. MacCartney, and C.r D. Man-ning.
2006.
Generating typed dependency parses fromphrase structure parses.
In LREC.K.
Deschacht and M.-F. Moens.
2009.
Semi-supervisedsemantic role labeling using the latent words languagemodel.
In Proceedings of EMNLP.J.
Duchi, E. Hazan, and Y.
Singer.
2011.
Adaptive sub-gradient methods for online learning and stochasticoptimization.
The Journal of Machine Learning Re-search, 12:2121?2159.K.
Erk and S. Pado.
2006.
Shalmaneser?a toolchain forshallow semantic parsing.
In LREC.C.
J. Fillmore.
1968.
The case for case.
In Bach E. andHarms R.T., editors, Universals in Linguistic Theory,pages 1?88.
Holt, Rinehart, and Winston, New York.H.
F?urstenau and M. Lapata.
2009.
Graph alignment forsemi-supervised semantic role labeling.
In EMNLP.H.
F?urstenau and O. Rambow.
2012.
Unsupervised in-duction of a syntax-semantics lexicon using iterativerefinement.
In Proceedings of the First Joint Confer-ence on Lexical and Computational Semantics.K.
Ganchev, J. Graca, J. Gillenwater, and B. Taskar.2010.
Posterior regularization for structured latentvariable models.
Journal of Machine Learning Re-search (JMLR), 11:2001?2049.Q.
Gao and S. Vogel.
2011.
Corpus expansion for statis-tical machine translation with semantic role label sub-stitution rules.
In ACL:HLT.N.
Garg and J. Henderson.
2012.
Unsupervised semanticrole induction with global role ordering.
In ACL.D.
Gildea and D. Jurafsky.
2002.
Automatic la-belling of semantic roles.
Computational Linguistics,28(3):245?288.T.
Grenager and C. Manning.
2006.
Unsupervised dis-covery of a statistical verb lexicon.
In EMNLP.J.
Haji?c, M. Ciaramita, R. Johansson, D. Kawahara, M.A.Mart?
?, L. M`arquez, A. Meyers, J. Nivre, S.
Pad?o,J.
?St?ep?anek, P. Stra?n?ak, M. Surdeanu, N. Xue, andY.
Zhang.
2009.
The CoNLL-2009 shared task:Syntactic and semantic dependencies in multiple lan-guages.
In Proceedings of the 13th Conference onComputational Natural Language Learning (CoNLL-2009), June 4-5.S.
He and D. Gildea.
2006.
Self-training and co-trainingfor semantic role labeling: Primary report.
Technicalreport, Technical Report 891, University of Rochester.9G.
E. Hinton.
1989.
Connectionist learning procedures.Artificial intelligence, 40(1):185?234.R.
Johansson and P. Nugues.
2008.
Dependency-basedsyntactic-semantic analysis with PropBank and Nom-Bank.
In CoNLL.M.
Kaisser and B. Webber.
2007.
Question answeringbased on semantic roles.
In ACL Workshop on DeepLinguistic Processing.D.
Kawahara, D. Peterson, O. Popescu, and M. Palmer.2014.
Inducing example-based semantic frames froma massive amount of verb uses.
In EACL.M.
Kozhevnikov and I. Titov.
2013.
Crosslingual trans-fer of semantic role models.
In ACL.J.
Lang and M. Lapata.
2010.
Unsupervised induction ofsemantic roles.
In ACL.J.
Lang and M. Lapata.
2011a.
Unsupervised semanticrole induction via split-merge clustering.
In ACL.J.
Lang and M. Lapata.
2011b.
Unsupervised semanticrole induction with graph partitioning.
In EMNLP.J.
Lang and M. Lapata.
2014.
Similarity-driven semanticrole induction via graph partitioning.
ComputationalLinguistics, 40(3):633?669.D.
Lin and P. Pantel.
2001.
DIRT ?
discovery of infer-ence rules from text.
In KDD.D.
Liu and D. Gildea.
2010.
Semantic role features formachine translation.
In Coling.T.
Mikolov, K. Chen, G. Corrado, and J.
Dean.
2013.Efficient estimation of word representations in vectorspace.
arXiv preprint arXiv:1301.3781.A.
Modi, I. Titov, and A. Klementiev.
2012.
Unsuper-vised induction of frame-semantic representations.
InNAACL Workshop on Inducing Linguistic Structure.M.
Nickel, V. Tresp, and H.-P. Kriegel.
2011.
A three-way model for collective learning on multi-relationaldata.
In ICML.J.
Nivre, J.
Hall, and J. Nilsson.
2004.
Memory-baseddependency parsing.
In Proc.
of the Eighth Confer-ence on Computational Natural Language Learning,pages 49?56, Boston, USA.B.
O?Connor.
2013.
Learning frames from text with anunsupervised latent variable model.
Technical report,CMU.S.
Pado and M. Lapata.
2009.
Cross-lingual annotationprojection for semantic roles.
Journal of Artificial In-telligence Research, 36:307?340.M.
Palmer, D. Gildea, and P. Kingsbury.
2005.
Theproposition bank: An annotated corpus of semanticroles.
Computational Linguistics, 31(1):71?106.J.
Pennington, R. Socher, and C. D. Manning.
2014.Glove: Global vectors for word representation.
InEMNLP.S.
Pradhan, W. Ward, and J. H. Martin.
2008.
Towardsrobust semantic role labeling.
Computational Linguis-tics, 34:289?310.S.
Riedel, L. Yao, A. McCallum, and B. M. Marlin.
2013.Relation extraction with matrix factorization and uni-versal schemas.
In NAACL.M.
Sammons, V. Vydiswaran, T. Vieira, N. Johri,M.
Chang, D. Goldwasser, V. Srikumar, G. Kundu,Y.
Tu, K. Small, J.
Rule, Q.
Do, and D. Roth.
2009.Relation alignment for textual entailment recognition.In Text Analysis Conference (TAC).D.
Shen and M. Lapata.
2007.
Using semantic roles toimprove question answering.
In EMNLP.M.
Surdeanu, A. Meyers, R. Johansson, L. M`arquez, andJ.
Nivre.
2008.
The CoNLL-2008 shared task on jointparsing of syntactic and semantic dependencies.
InCoNLL 2008: Shared Task.R.
Swier and S. Stevenson.
2004.
Unsupervised seman-tic role labelling.
In EMNLP.I.
Titov and A. Klementiev.
2011.
A Bayesian model forunsupervised semantic parsing.
In ACL.I.
Titov and A. Klementiev.
2012a.
A Bayesian approachto semantic role induction.
In EACL.I.
Titov and A. Klementiev.
2012b.
Crosslingual induc-tion of semantic roles.
In ACL.L.
van der Plas, J. Henderson, and P. Merlo.
2009.
Do-main adaptation with artificial data for semantic pars-ing of speech.
In NAACL.L.
van der Plas, P. Merlo, and J. Henderson.
2011.
Scal-ing up automatic cross-lingual semantic role annota-tion.
In ACL.P.
Vincent, H. Larochelle, Y. Bengio, and P.-A.
Man-zagol.
2008.
Extracting and composing robust fea-tures with denoising autoencoders.
In ICML.D.
Wu and P. Fung.
2009.
Semantic roles for SMT: Ahybrid two-pass model.
In NAACL.D.
Wu, M. Apidianaki, M. Carpuat, and L. Specia, ed-itors.
2011.
Proc.
of Fifth Workshop on Syntax, Se-mantics and Structure in Statistical Translation.
ACL.L.
Yao, A. Haghighi, S. Riedel, and A. McCallum.
2011.Structured relation discovery using generative models.In EMNLP.K.
Y. Y?lmaz, A. T. Cemgil, and U. Simsekli.
2011.
Gen-eralised coupled tensor factorisation.
In NIPS.10
