Proceedings of the 3rd Workshop on Computational Linguistics for Literature (CLfL) @ EACL 2014, pages 40?49,Gothenburg, Sweden, April 27, 2014. c?2014 Association for Computational LinguisticsFrom Speaker Identification to Affective Analysis:A Multi-Step System for Analyzing Children?s StoriesElias Iosif?
and Taniya Mishra??
School of ECE, Technical University of Crete, Chania 73100, Greece?
AT&T Labs, 33 Thomas Street, New York, NY 10007, USAiosife@telecom.tuc.gr, taniya@research.att.comAbstractWe propose a multi-step system for theanalysis of children?s stories that is in-tended to be part of a larger text-to-speech-based storytelling system.
A hybrid ap-proach is adopted, where pattern-basedand statistical methods are used along withutilization of external knowledge sources.This system performs the following storyanalysis tasks: identification of charac-ters in each story; attribution of quotesto specific story characters; identificationof character age, gender and other salientpersonality attributes; and finally, affectiveanalysis of the quoted material.
The differ-ent types of analyses were evaluated usingseveral datasets.
For the quote attribution,as well as for the gender and age estima-tion, substantial improvement over base-line was realized, whereas results for per-sonality attribute estimation and valenceestimation are more modest.1 IntroductionChildren love listening to stories.
Listening tostories ?
read or narrated ?
has been shownto be positively correlated with children?s linguis-tic and intellectual development (Natsiopoulou etal., 2006).
Shared story reading with parents orteachers helps children to learn about vocabulary,syntax and phonology, and to develop narrativecomprehension and awareness of the concepts ofprint, all of which are linked to developing readingand writing skills (National Early Literacy Panel2008).
While acknowledging that the parentalrole in storytelling is irreplaceable, we considertext-to-speech (TTS) enabled storytelling systems(Rusko et al., 2013; Zhang et al., 2003; Theuneet al., 2006) to be aligned with the class of child-oriented applications that aim to aid learning.For a TTS-based digital storytelling system tosuccessfully create an experience as engaging ashuman storytelling, the underlying speech synthe-sis system has to narrate the story in a ?story-telling speech style?
(Theune et al., 2006), gen-erate dialogs uttered by different characters usingsynthetic voices appropriate for each character?sgender, age and personality (Greene et al., 2012),and express quotes demonstrating emotions suchas sadness, fear, happiness, anger and surprise(Alm, 2008) with realistic expression (Murray andArnott, 2008).
However, before any of the afore-mentioned requirements ?
all related to speechgeneration ?
can be met, the text of the story hasto be analyzed to identify which portions of thetext should be rendered by the narrator and whichby each of the characters in the story, who are thedifferent characters in the story, what is each char-acter?s gender, age, or other salient personality at-tributes that may influence the voice assigned tothat character, and what is the expressed affect ineach of the character quotes.Each of these text analysis tasks has been ap-proached in past work (as described in our Re-lated Works section).
However, there appears tobe no single story analysis system that performsall four of these tasks, which can be pipelined withone of the many currently available text-to-speechsystems to build a TTS-based storyteller system.Without such a story analysis system, it will not bepossible to develop an engaging and lively digitalstoryteller system, despite the prevalence of sev-eral mature TTS systems.40In this paper, we present a multi-step text analy-sis system for analyzing children?s stories that per-forms all four analysis tasks: (i) Character Identi-fication, i.e., identifying the different characters inthe story, (ii) Quote Attribution, i.e., identifyingwhich portions of the text should be rendered bythe narrator versus by particular characters in thestory, (iii) Character Attribute Identification, i.e.,identifying each character?s gender, age, or salientpersonality attributes that may influence the voicethat the speech synthesis system assigns to eachcharacter, and (iv) Affective Analysis, i.e., esti-mating the affect of the character quotes.This story analysis system was developed tobe part of a larger TTS-based storyteller systemaimed at children.
As a result, the data used fordeveloping the computational models or rules ineach step of our system were obtained from chil-dren?s stories.
A majority of children?s storiesare short.
They often contain multiple characters,each with different personalities, genders, age,ethnicities, etc., with some characters even be-ing anthropomorphic, e.g., the singing candlestickor the talking teapot.
In addition, there are sev-eral prototypical templates characterizing the maincharacters in the story (Rusko et al., 2013).
How-ever, character development is limited in these sto-ries due to the shorter length of text.
Overall,children?s stories can be regarded as a parsimo-nious yet fertile framework for developing compu-tational models for literature analysis in general.2 Related WorkElson and McKeown (2010) used rule-based andstatistical learning approaches to identify candi-date characters and attribute each quote to the mostlikely speaker.
Two broad approaches for the iden-tification of story characters were followed: (i)named entity recognition, and (ii) identificationof character nominals, e.g., ?her grandma?, usingsyntactic patterns.
A long list of heuristics forcharacter identification is proposed in (Mamedeand Chaleira, 2004).
He et al.
(2013) use a su-pervised machine learning approach to address thesame problem, though many of their preliminarysteps and input features are similar to those used in(Elson and McKeown, 2010).
Our character iden-tification and quote attribution is based on syntac-tic and heuristic rules that is motivated by each ofthese works.There are two interesting sub-problems relatedto quote attribution.
First is the problem of iden-tifying anaphoric speakers, i.e., in the utterance?Hello?, he said, which character is referred to bythe pronoun he?
This problem is addressed in (El-son and McKeown, 2010) and (He et al., 2013) butnot in (Mamede and Chaleira, 2004).
The secondproblem is resolving utterance chains with implicitspeakers.
Elson and McKeown (2010) describeand address two basic types of utterance chains: (i)one-character chains, and (ii) intertwined chains.In these chains of utterances, the speaker is notexplicitly mentioned because the author relies onthe shared understanding with the reader that adja-cent pieces of quoted speech are not independent(Zhang et al., 2003; Elson and McKeown, 2010).They are either a continuation of the same charac-ter?s speech (one-character chains) or a dialoguebetween the two characters (intertwined chains).In (Zhang et al., 2003), the quote-identificationmodule detects whether a piece of quoted speechis a new quote (NEW), spoken by a speaker dif-ferent from the previous speaker, or a continuationquote (CONT) spoken by the same speaker as thatof the previous quote.
He et al.
(2013) also iden-tified similar chains of utterances and addressedtheir attribution to characters using a model-basedapproach.
In this work, we address both sub-problems, namely, anaphoric speaker and implicitspeaker identification.Cabral et al.
(2006) have shown that assign-ing an appropriate voice for a character in a digi-tal storyteller system is significant for understand-ing a story, perceiving affective content, perceiv-ing the voice as credible, and overall listener sat-isfaction.
Greene et al.
(2012) have shown thatthe appropriateness of the voice assigned to a syn-thetic character is strongly related to knowing thegender, age and other salient personality attributesof the character.
Given this, we have developedrule-based, machine-learning-based and resource-based approaches for estimation of character gen-der, age and salient personality attributes.
In con-trast, the majority of past works on the analysis ofchildren stories for TTS-based storytelling is lim-ited to the attribution of quotes to speakers, thoughstudies that focused on anaphoric speaker iden-tification have also approached character genderestimation such as (Elson and McKeown, 2010)and (He et al., 2013).
The utilization of availableresources containing associations between personnames and gender was followed in (Elson and41McKeown, 2010).
In (He et al., 2013), associ-ations between characters and their gender wereperformed using anaphora rules (Mitkov, 2002).There is of course a significant body of workfrom other research areas that are related to theestimation of character attributes, similar to whatwe have attempted in our work.
Several shal-low linguistic features were proposed in (Schleret al., 2006) for gender identification, applied tothe identification of users in social media.
Severalsocio-linguistic features were proposed in (Rao etal., 2010) for estimating the age and gender ofTwitter users.
The identification of personality at-tributes from text is often motivated by psycho-logical models.
In (Celli, 2012), a list of linguis-tic features were used for the creation of charactermodels in terms of the the Big Five personality di-mensions (Norman, 1963).Analysis of text to estimate affect or sentimentis a relatively recent research topic that has at-tracted great interest, as reflected by a series ofshared evaluation tasks, e.g., analysis of newsheadlines (Strapparava and Mihalcea, 2007) andtweets (Nakov et al., 2013).
Relevant applicationsdeal with numerous domains such as blogs (Baloget al., 2006), news stories (Lloyd et al., 2005), andproduct reviews (Hu and Liu, 2004).
In (Turneyand Littman, 2002), the affective ratings of un-known words were predicted using the affectiveratings for a small set of words (seeds) and the se-mantic relatedness between the unknown and theseed words.
An example of sentence-level analy-sis was proposed in (Malandrakis et al., 2013).
In(Alm et al., 2005) and (Alm, 2008), linguistic fea-tures were used for affect analysis in fairy tales.
Inour work, we employ a feature set similar to thatin (Alm et al., 2005).
We deal with the predictionof three basic affective labels which are adequatefor the intended application (i.e., storytelling sys-tem), while in (Alm, 2008) more fine-grained pre-dictions are considered.The integration of various types of analysis con-stitutes the distinguishing character of our work.3 Overview of System ArchitectureThe system consists of several sub-systems thatare linked in a pipeline.
The input to the systemis simply the text of a story with no additionalannotation.
The story analysis is performed se-quentially, with each sub-system extracting spe-cific information needed to perform the four anal-ysis tasks laid out in this paper.3.1 Linguistic PreprocessingThe first step is linguistic pre-processing of thestories.
This includes (i) tokenization, (ii) sen-tence splitting and identification of paragraphboundaries, (iii) part-of-speech (POS) tagging,(iv) lemmatization, (v) named entity recognition,(vi) dependency parsing, and (vii) co-referenceanalysis.
These sub-tasks ?
except task (ii) ?were performed using the Stanford CoreNLP suiteof tools (CoreNLP, 2014).
Sentence splitting andidentification of paragraph boundaries was per-formed using a splitter developed by Piao (2014).Linguistic information extracted by this analysis isexploited by the subsequent parts of the pipeline.3.2 Identification of Story CharactersThe second step is identifying candidate charac-ters (i.e., entities) that appear in the stories underanalysis.
A story character is not necessarily astory speaker.
A character may appear in the storybut may not have any quote associated with himand hence, is not a speaker.
Characters in chil-dren?s stories can either be human or non-humanentities, i.e., animals and non-living objects, ex-hibiting anthropomorphic traits.
The interactionsamong characters can either be human-to-humanor human-to-non-human interactions.We used two approaches for identifying storycharacters motivated by (Elson and McKeown,2010): 1) named entity recognition was used foridentifying proper names, e.g., ?Hansel?, 2) aset of part-of-speech patterns was used for theextraction of human and non-human charactersthat were not represented by proper names, e.g.,?wolf?.
The used patterns are: 1) (DT|CD)(NN|NNS), 2) DT JJ (NN|NNS), 3) NN POS(NN|NNS), and 4) PRP$ JJ (NN|NNS).These POS-based patterns are quite generic, al-lowing for the creation of large sets of characters.In order to restrict the characters, world knowl-edge was incorporated through the use of Word-Net (Fellbaum, 2005).
A similar approach wasalso followed in (Elson and McKeown, 2010).
Foreach candidate character the hierarchy of its hy-pernyms was traversed up to the root.
Regardingpolysemous characters the first two senses wereconsidered.
A character was retained if any of itshypernyms was found to fall into certain types ofWordNet concepts: person, animal, plant, artifact,spiritual being, physical entity.423.3 Quote Attribution & SpeakerIdentificationHere the goal is to attribute (or assign) each quoteto a specific story character from the set identifiedin the previous step.
The identification of quotesin the story is based on a simple pattern-based ap-proach: the quote boundaries are signified by therespective symbols, e.g., ?
and ?.
The pattern isapplied at the sentence level.The quotes are not modeled as NEW/CONT asin (Zhang et al., 2003), however, we adopt a moresophisticated approach for the quote attribution.Three types of attribution are possible in our sys-tem: 1) explicit mention of speakers, e.g., ?Done!
?said Hans, merrily, 2) anaphoric mention of speak-ers, e.g., ?How happy am I!?
cried he, 3) sequenceof quotes, e.g., ?And where did you get the pig??.
.
.
?I gave a horse for it.?.
In the first type of attri-bution, the speaker is explicitly mentioned in thevicinity of the quote.
This is also true for the sec-ond type, however, a pronominal anaphora is usedto refer to the the speaker.
The first two attributiontypes are characterized by the presence of ?within-quote?
(e.g., ?Done!?)
and ?out-of-quote?
(e.g.,?said Hans, merrily.?)
content.
This is not thecase for the third attribution type for which only?in-quote?
content is available.
We refer to suchquotes as ?pure?
quotes.
Each attribution type isdetailed below.Preliminary filtering of characters.
Beforequote-attribution is performed, the list of storycharacters is pruned by identifying the charactersthat are ?passively?
associated with speech verbs(SV).
This is applied at the sentence level.
Someexamples of speech verbs are: said, responds, sing,etc.
For instance, in ?.
.
.
Hans was told .
.
.
?,?Hans?
is a passive character.
The passive char-acters were identified via the following relationsextracted by dependency parsing: nsubjpass(passive nominal subject) and pobj (object of apreposition).
Given a sentence that includes oneor more quotes, the respective passive characterswere not considered as candidate speakers.
Someother criteria for pruning of list of characters toidentify candidate speakers are presented in Sec-tion 4.2 (see the three schemes for Tasks 1-2).Explicit mention of speakers.
Several syntac-tic patterns were applied to associate quotes withexplicit mention of speakers in their vicinity tocharacters from the pruned list of story charac-ters.
These patterns were developed around SV.In the example above, ?Hans?
is associated withthe quote ?Done!?
via the SV ?said?.
Variationsof the following basic patterns (Elson and McKe-own, 2010) were used: 1) QT SV CH, 2) QT CHSV, and 3) CH SV QT, where QT denotes a quoteboundary and CH stands for a story character.
Forexample, a variation of the first pattern is QT SVthe?
CH, where ?
stands for zero or one oc-currence of ?the?.A limitation of the aforementioned patternsis that they capture associations when the CHand SV occur in close textual distance.
Asa result, distant associations are missed, e.g.,?Hans stood looking on for a while, and at lastsaid, ?
You must .
.
.
??.
In order to addressthis distant association issue, we examined thecollapsed-ccprocessed-dependenciesoutput besides the basic-dependenciesout-put of the Stanford CoreNLP dependency engine(de Marneffe and Manning, 2012).
The formercaptures more distant relations compared tothe latter.
We specifically extract the characterreference CH either from the dependency relationnsubj, which links a speech verb SV with a CHthat is the syntactic subject of a clause, or from thedependency relation dobj, which links a SV witha CH that is the direct object of the speech verb,across a conjunct (e.g., and).
A similar approachwas used in (He et al., 2013).Anaphoric mention of speakers.
The sameprocedure was followed as in the case of the ex-plicit mentions of speakers described above.
Thedifference is that CH included the following pro-nouns: ?he?, ?she?, ?they?, ?himself?, ?herself?,and ?themselves?.
After associating a pronounwith a quote, the quote was attributed to a storycharacter via co-reference resolution.
This wasdone using the co-reference analysis performedby CoreNLP.
If a pronominal anaphora was notresolved by the CoreNLP analysis, the follow-ing heuristic was adopted.
The previous n para-graphs1 were searched and the pronoun under in-vestigation was mapped to the closest (in termsof textual proximity) story character that had thesame gender as the pronoun (see Section 3.4.1 re-garding gender estimation).
During the paragraphsearch, anaphoric mentions were also taken intoconsideration followed by co-reference resolution.Despite the above approaches, it is possible tohave non-attributed quotes.
In such cases, the fol-1For the reported results n was set to 5.43lowing procedure is followed for those story sen-tences that: (i) do not constitute ?pure?
quotes(i.e., consist of ?in-quote?
and ?out-of-quote?
con-tent), and (ii) include at least one ?out-of-quote?SV: 1) all the characters (as well as pronouns) thatoccur within the ?out-of-quote?
content are aggre-gated and serve as valid candidates for attribution,2) if multiple characters and pronouns exist, thenthey are mapped (if possible) via co-reference res-olution in order to narrow down the list of attri-bution candidates, and 3) the quote is attributedto the nearest quote character (or pronoun).
Forthe computation of the textual distance both quoteboundaries (i.e., start and end) are considered.
Ifthe quote is attributed to a pronoun that was notmapped to any character, then co-reference reso-lution is applied.Sequence of ?pure?
quotes.
Sentences thatare ?pure?
quotes (i.e., include ?in-quote?
con-tent only) are not attributed to any story charac-ter via the last two attribution methods.
?Pure?quotes are attributed as follows: The sentencesare parsed sequentially starting from the begin-ning of the story.
Each time a character is encoun-tered within a sentence, it is pushed into a ?bag-of-characters?.
This is done until a non-attributed?pure?
quote is found.
At this point we assumethat the candidate speakers for the current (andnext) ?pure?
quote are included within the ?bag-of-characters?.
This is based on the hypothesisthat the author ?introduces?
the speakers beforetheir utterances.
The subsequent ?pure?
quotes areexamined in order to spot any included characters.Such characters are regarded as ?good?
candidatesenabling the pruning of the list of candidate speak-ers.
The goal is to end up with exactly two candi-date speakers for a back and forth dialogue.
Then,the initiating speaker is identified by taking intoaccount the order of names mentioned within thequote.
Then, the quote attribution is performed inan alternating fashion.
For example, consider asequence of four non-attributed ?pure?
quotes anda bag of two2 candidate speakers, siand sj.
If siwas identified as the initiating speaker, then the 1stand the 3th quote are attributed to it, while the 2ndand the 4th quote are attributed to sj.
Finally, the?bag-of-characters?
is reset, and the same processis repeated for the rest of the story.Identification of speakers.
The speakers for a2If more than two candidates exist, then the system givesambiguous attributions, i.e., multiple speakers for one quote.given story are identified by selecting those char-acters that were attributed at least one quote.3.4 Gender, Age and Personality AttributesThe next three steps in our system involve estima-tion of the (i) gender, (ii) age, and (iii) personalityattributes for the identified speakers.3.4.1 Gender EstimationWe used a hybrid approach for estimating the gen-der of the story characters.
This is applied to char-acters (rather than only speakers) because the gen-der information is exploited during the attributionof quotes (see Section 3.3).
The characterization?hybrid?
refers to the fusion of two different typesof information: (i) linguistic information extractedfrom the story under analysis, and (ii) informationtaken from external resources that do not dependon the analyzed story.
Regarding the story-specificinformation, the associations between charactersand third person pronouns (identified via anaphoraresolution) were counted.
The counts were used inorder to estimate the gender probability.The story-independent resources that we usedare: (a) the U.S. Social Security Administrationbaby name database (Security, 2014), in whichperson names are linked with gender and (b) alarge name-gender association list developed us-ing a corpus-based bootstrapping approach, whicheven included the estimated gender for non-personentities (Bergsma and Lin, 2006).
For each entityincluded in (b) a numerical estimate is providedfor each gender.
As in the case of story-specific in-formation, those estimates were utilized for com-puting the gender probability.
Using the above in-formation the following procedure was followedfor each character: The external resource (a) wasused when the character name occurred in it.
Oth-erwise, the information from the external resource(b) and the story-specific information was takeninto account.
If the speaker was covered by bothtypes of information, the respective gender prob-abilities were compared and the gender was esti-mated to be the one corresponding to the high-est probability.
If the character was not coveredby the story-specific information, the external re-source (b) was used.3.4.2 Age EstimationWe used a machine-learning based approach forage estimation.
The used features are presented inTable 1, while they were extracted from speaker44quotes, based on the assumption that speakers ofdifferent ages use language differently.
TheNo.
Description1 count of .
, ;2 count of ,3 count of !4 count of 1st person singular pronouns5 count of negative particles6 count of numbers7 count of prepositions8 count of pronouns9 count of ?10 count of tokens longer than 6 letters11 count of 1st pers.
(sing.
& plur.)
pronouns12 count of quote tokens13 count of 1st person plural pronouns14 count of 2nd person singular pronouns15 count of quote positive words16 count of quote negative words17 count of nouns18 count of verbs19 count of adjectives20 count of adverbs21 up to 3-grams extracted from quoteTable 1: Common feature set.development of this feature set was inspired by(Celli, 2012) and (Alm et al., 2005).
All fea-tures were extracted from the lemmatized form ofquotes.
Also, all feature counts (except Feature21) were normalized by Feature 12.
For com-puting the counts of positive and negative words(Feature 15 and 16) we used the General Inquirerdatabase (Stone et al., 1966).
Feature 21 standsfor n-grams (up to 3-grams) extracted from thespeaker quotes.
Two different schemes were fol-lowed for extracting this feature: (i) using thequote as-is, i.e., its lexical form, and (ii) using thepart-of-speech tags of quote.
So, two slightly dif-ferent feature sets were defined: 1) ?lex?
: No.1-20+ lexical form for No.21, 2) ?pos?
: No.1-20 + POStags for No.213.4.3 Estimation of Personality AttributesA machine-learning based approach was also usedfor personality attribute estimation.
For estimat-ing the personality attributes of story speakers, thelinguistic feature set (see Table 1) used in the taskfor age estimation was used again .
Again our ap-proach was based on the assumption that wordspeople use reflect their personality, and the lattercan be estimated by these linguistic features.3.5 Affective AnalysisThe last step of our system is the estimation ofthe affective content of stories.
The analysis isperformed for each identified quote.
The featurespresented in Table 1 are extracted for each quoteand affect is estimated using a machine-learningmodel, based on the assumption that such featuresserve as cues for revealing the underlying affectivecontent (Alm et al., 2005; Alm, 2008).4 Experiments and EvaluationHere we present the experimental evaluation ofour system in performing the following tasks: 1)speaker-to-quote attribution, 2) gender estimation,3) age estimation, 4) identification of personalityattributes, and 5) affective analysis of stories.4.1 Datasets UsedThe datasets used for our experiments along withthe related tasks are presented in Table 2.No.
Task Type of dataset1 Quote attribution STORIES2 Gender estimation STORIES3 Age estimation QUOTES(1,2)4 Personality attrib.
QUOTES(3,4)5 Affective analysis STORY-AFFECTTable 2: Experiment datasets and related tasks.Tasks 1-2.
For the first two tasks (quote-to-speaker attribution, and gender estimation) weused a dataset (STORIES) consisting of 17 chil-dren stories selected from Project Gutenberg3 .This set of stories includes 98 unique speakerswith 554 quotes assigned to them.
The averagenumber of sentences and quotes per story is 61.8and 32.5, respectively.
The average sentence andquote length is 30.4 and 29.0 tokens, respectively.Each speaker was attributed 5.7 quotes on aver-age.
Ground truth annotation, which involved as-signing quotes to speakers and labeling gender,was performed by one4 annotator.
The follow-ing ground truth labels were used to mark gender:?male?, ?female?, and ?plural?.3www.telecom.tuc.gr/?iosife/chst.html4Due to the limited ambiguity of the task, the availabilityof a single annotator was considered acceptable.45Task 3.
Evaluation of the age estimation task wasperformed with respect to two different (propri-etary) datasets QUOTES1 and QUOTES2.
Thesedatasets consisted of individual quotes assigned topopular children?s story characters.
The datasetQUOTES1 consisted of 6361 quotes assigned to69 unique speakers.
The average quote lengthequals 7.6 tokens, while each speaker was at-tributed 141.4 quotes on average.
The datasetQUOTES2 consisted of 23605 quotes assigned to262 unique speakers.
The average quote lengthequals 8.3 tokens, while each speaker was at-tributed 142.6 quotes on average.
For ground truthannotation, four annotators were employed.
Theannotators were asked to use the following agelabels: ?child?
(0?15 years old), ?young adult?
(16?35 y.o.
), ?middle-aged?
(36?55 y.o.
), and ?el-derly?
(56?
y.o.).
The age of each character wasinferred by the annotators either based on personalknowledge of these stories or by consulting pub-licly available sources online.
The inter-annotatoragreement equals to 70%.Task 4.
To evaluate system performance on Task4, two datasets QUOTES3 and QUOTES4, con-sisting of individual quotes assigned to popularchildren?s story characters, were used.
The setQUOTES3 consisted of 68 individual charactersand QUOTES4 consisted of 328 individual charac-ters.
The ground truth assignment, assigning eachcharacter with personality attributes, was extractedfrom a free, public collaborative wiki (Wiki,2014).
Since the wiki format allows people to addor edit information, we considered the personalityattributes extracted from this wiki to be the aver-age ?crowd?s opinion?
of these characters.
Of theopen-ended list of attributes that were used to de-scribe the characters, in this task we attempted toextract the following salient personality attributes:?beautiful?, ?brave?, ?cowardly?, ?evil?, ?feisty?,?greedy?, ?handsome?, ?kind?, ?loving?, ?loyal?,?motherly?, ?optimistic?, ?spunky?, ?sweet?, and?wise?.
The pseudo-attribute ?none?
was usedwhen a character was not described with any ofthose aforementioned attributes.Task 5.
An annotated dataset, referred to asSTORY-AFFECT in this paper, consisting of 176stories was used.
Each story sentence (regard-less if quotes were included or not) was anno-tated regarding primary emotions and mood us-ing the following labels: ?angry?
(AN), ?dis-gusted?
(DI), ?fearful?
(FE), ?happy?
(HA), ?neu-tral?
(NE), ?sad?
(SA), ?positive surprise?
(SU+),and ?negative surprise?
(SU?).
Overall, two anno-tators were employed, while each annotator pro-vided two annotations: one for emotion and onefor mood.
More details about this dataset are pro-vided in (Alm, 2008).Instead of using the aforementioned emo-tions/moods as annotated, we adopted a 3-classscheme for sentence affect (valence): ?negative?,?neutral?, and ?positive?.
In order to align theexisting annotations to our three-class scheme thefollowing mapping5 was adopted: (i) AN, DI, FE,SA were mapped to negative affect, (ii) NE wasmapped to neutral affect, and (iii) HA was mappedto positive affect.
Given the proposed mapping,we retained those sentences (in total 11018) thatexhibited at least 75% annotation agreement.4.2 Evaluation ResultsThe evaluation results for the aforementionedtasks are presented below.Tasks 1-2.
The quote-to-speaker attribution wasevaluated in terms of precision (ATp), while theestimation of speakers?
gender was evaluated interms of precision (Gp) and recall (Gr).
Note thatGpincludes both types of errors: (i) erroneous ageestimation, and (ii) estimations for story charac-ters that are not true speakers.
In order to excludethe second type of error, the precision of genderestimation was also computed for only the truestory speaker identified by the system (G?p).
ForSpeaker filter.
ATpGpGrG?pBaseline 0.010 0.33310 stories (subset of dataset)Scheme 1 0.833 0.780 0.672 0.929Scheme 2 0.868 0.710 0.759 0.917Scheme 3 0.835 0.710 0.759 0.91717 stories (full dataset)Scheme 2 0.845 0.688 0.733 0.892Table 3: Quote attribution and gender estimation.a subset of the STORIES dataset that included 10stories, the following schemes were used for filter-ing of candidate speakers: (i) Scheme 1: all speak-ers linked with speech verbs, (ii) Scheme 2: speak-ers, who are persons or animals or spiritual entitiesaccording to their first WordNet sense, linked withspeech verbs , and (iii) Scheme 3: as Scheme 2,5SU+/?
were excluded for simplicity.46but the first two WordNet senses were considered.For the full STORIES dataset (17 stories) Scheme2 was used.
The results are presented in Table 3 in-cluding the weighted averages of precision and re-call.
Using random guesses, the baseline precisionis 0.010 and 0.333 for quote-to-speaker attributionand gender estimation, respectively.
For the subsetof 10 stories, the highest speaker-to-quote attribu-tion attribution is obtained by Scheme 2.
Whenthis scheme is applied over the entire dataset, sub-stantially high6 precision (0.892) is achieved in theestimation of gender of true story speakers.Task 3.
For the estimation of age using quote-based features, a boosting approach was fol-lowed using BoosTexter (Schapire and Singer,2000).
For evaluation, 10-fold cross valida-Dataset Relaxed Exactlex pos lex posBaseline 0.625 0.250QUOTES1 0.869 0.883 0.445 0.373QUOTES2 0.877 0.831 0.450 0.435BOTH 0.886 0.858 0.464 0.383Table 4: Age estimation: average accuracy.tion (10FCV) was used for the QUOTES1 andQUOTES2 datasets for the ?lex?
and ?pos?
fea-ture sets.
The results are reported in Table 4 interms of average classification accuracy.
In thistable, BOTH refers to the datasets QUOTES1 andQUOTES2 combined together.
The evaluationwas performed according to two schemes: (i) ?re-laxed match?
: the prediction is considered as cor-rect even if it deviates one class from the true one,e.g., ?child?
and ?middle-aged?
considered as cor-rect for ?young adult?, and (ii) ?exact match?
: theprediction should exactly match the true label.
Therelaxed scheme was motivated by the nature of in-tended application (storytelling system) for whichsuch errors are tolerable.
For the exact matchscheme, the obtained performance is higher7 thanthe baseline (random guess) that equals to 0.250.The accuracy for the relaxed scheme is quite high,i.e., greater than 0.85 for almost all cases.
On aver-age, the ?lex?
feature set appears to yield slightlyhigher performance than the ?pos?
set.Task 4.
The personality attributes were estimatedusing BoosTexter fed with the ?lex?
feature set.10FCV was used for evaluation, while the aver-6Statistically significant at 95% lev.
(t-test wrt baseline).7Statistically significant at 95% lev.
(t-test wrt baseline).age accuracy was computed by taking into accountthe top five attributes predicted for each charac-ter.
The baseline accuracy equals 0.31 given thatrandom guesses are used.
Moderate performancewas achieved for the QUOTES3 and QUOTES4datasets, 0.426 and 0.411, respectively.Task 5.
The affect of story sentences was esti-mated via BoosTexter using the ?lex?
and ?pos?feature sets.
As in the previous two tasks 10FCVwas applied for evaluation purposes.
Using ran-dom guesses, the baseline accuracy is 0.33.
Theaverage accuracy for the ?lex?
and ?pos?
featuresets is 0.838 and 0.658, respectively8 .
It is clearthat the use of the ?lex?
set outperforms the resultsyielded by the ?pos?
set.5 Conclusions and Future DirectionsIn this paper, we described the development of amulti-step system aimed for story analysis withparticular emphasis on analyzing children?s sto-ries.
The core idea was the integration of sev-eral systems into a single pipelined system.
Theproposed methodology has a strong hybrid char-acter in that it employs different approaches thatrange from pattern-based to machine learning-based to the incorporation of external knowledgeresources.
Going beyond the usual task of worksin this genre, i.e., speaker-to-quote attribution, theproposed system also supports the estimation ofspeaker-oriented attributes and affect estimation.Very promising results were obtained for quote at-tribution and estimation of speaker gender, as wellas for age assuming an application-depended errortolerance.
The estimation of personality attributesand the affective analysis of story sentences re-main open research problems, while the results aremore modest especially for the former task.In the next phase of our work, we hope to im-prove and generalize each individual componentof the proposed system.
The most challenging as-pects of the system, dealing with personality at-tributes and affective analysis, will be further in-vestigated.
Towards this task, psychological mod-els, e.g., the Big Five model, can provide usefultheoretical and empirical findings.
Last but notleast, the proposed system will be evaluated withinthe framework of a digital storytelling applicationincluding metrics related with user experience.8Statistically significant at 90% lev.
(t-test wrt baseline).47ReferencesC.
O. Alm, D. Roth, and R. Sproat.
2005.
Emotionsfrom text: Machine learning for text-based emotionprediction.
In Proc.
of Conference on Human Lan-guage Technology and Empirical Methods in Natu-ral Language Processing, pages 579?586.C.
O. Alm.
2008.
Affect in Text and Speech.
Ph.D.thesis, University of Illinois at Urbana-Champaign.K.
Balog, G. Mishne, and M. de Rijke.
2006.
Whyare they excited?
identifying and explaining spikesin blog mood levels.
In Proc.
11th Conference of theEuropean Chapter of the Association for Computa-tional Linguistics, pages 207?210.S.
Bergsma and D. Lin.
2006.
Bootstrapping path-based pronoun resolution.
In Proc.
of Conferenceon Computational Lingustics / Association for Com-putational Linguistics, pages 33?40.J.
Cabral, L. Oliveira, G. Raimundo, and A. Paiva.2006.
What voice do we expect from a syntheticcharacter?
In Proceedings of SPECOM, pages 536?539.F.
Celli.
2012.
Unsupervised personality recognitionfor social network sites.
In Proc.
of Sixth Interna-tional Conference on Digital Society.CoreNLP.
2014.
Stanford CoreNLP tool.http://nlp.stanford.edu/software/corenlp.shtml.M.-C. de Marneffe and C. D. Manning.
2012.
Stanfordtyped dependencies manual.D.
K. Elson and K. R. McKeown.
2010.
Automaticattribution of quoted speech in literary narrative.
InProc.
of Twenty-Fourth AAAI Conference on Artifi-cial Intelligence.C.
Fellbaum.
2005.
Wordnet and wordnets.
InK.
Brown et al., editor, Encyclopedia of Languageand Linguistics, pages 665?670.
Oxford: Elsevier.E.
Greene, T. Mishra, P. Haffner, and A. Conkie.
2012.Predicting character-appropriate voices for a TTS-based storyteller system.
In Proc.
of Interspeech.H.
He, D. Barbosa, and G. Kondrak.
2013.
Identifica-tion of speakers in novels.
In Proc.
of 51st AnnualMeeting of the Association for Computational Lin-guistics, pages 1312?1320.M.
Hu and B. Liu.
2004.
Mining and summarizingcustomer reviews.
In Proc.
of Conference on Knowl-edge Discovery and Data Mining, KDD ?04, pages168?177.L.
Lloyd, D. Kechagias, and S. Skiena.
2005.
Lydia:A system for large-scale news analysis.
In Proc.SPIRE, number 3772 in Lecture Notes in ComputerScience, pages 161?166.N.
Malandrakis, A. Potamianos, E. Iosif, andS.
Narayanan.
2013.
Distributional semanticmodels for affective text analysis.
IEEE Transac-tions on Audio, Speech, and Language Processing,21(11):2379?2392.N.
Mamede and P. Chaleira.
2004.
Character identifi-cation in children stories.
In J. Vicedo, P. Martnez-Barco, R. Muoz, and M. Saiz Noeda, editors, Ad-vances in Natural Language Processing, volume3230 of Lecture Notes in Computer Science, pages82?90.
Springer Berlin Heidelberg.R.
Mitkov.
2002.
Anaphora Resolution.
Longman.I.
R. Murray and J. L. Arnott.
2008.
Applying an anal-ysis of acted vocal emotions to improve the simu-lation of synthetic speech.
Computer Speech andLanguage, 22(2):107?129.P.
Nakov, S. Rosenthal, Z. Kozareva, V. Stoyanov,A.
Ritter, and T. Wilson.
2013.
Semeval 2013 task2: Sentiment analysis in twitter.
In Proc.
of SecondJoint Conference on Lexical and Computational Se-mantics (*SEM), Seventh International Workshop onSemantic Evaluation, pages 312?320.T.
Natsiopoulou, M. Souliotis, and A. G. Kyridis.2006.
Narrating and reading folktales and pic-ture books: storytelling techniques and approacheswith preschool children.
Early Childhood Re-search and Practice, 8(1).
Retrieved on Jan 13th,2014 from http://ecrp.uiuc.edu/v8n1/natsiopoulou.html.T.
W. Norman.
1963.
Toward an adequate taxonomy ofpersonality attributes: Replicated factor structure inpeer nomination personality rating.
Journal of Ab-normal and Social Psychology, 66:574?583.S.
Piao.
2014.
Sentence splitting pro-gram.
http://text0.mib.man.ac.uk:8080/scottpiao/sent_detector.D.
Rao, D. Yarowsky, A. Shreevats, and M. Gupta.2010.
Classifying latent user attributes in twitter.
InProc.
of the 2nd International Workshop on Searchand Mining User-generated Contents, pages 37?44.M.
Rusko, M. Trnka, S. Darjaa, and J. Hamar.
2013.The dramatic piece reader for the blind and visu-ally impaired.
In Proc.
of 4th Workshop on Speechand Language Processing for Assistive Technolo-gies, pages 83?91.R.
E. Schapire and Y.
Singer.
2000.
Boostexter: Aboosting-based system for text categorization.
Ma-chine.
Learning, 39(2-3):135?168.J.
Schler, M. Koppel, S. Argamon, and J. W. Pen-nebaker.
2006.
Effects of age and gender on blog-ging.
In Proc.
of AAAI Spring Symposium: Compu-tational Approaches to Analyzing Weblogs.Social Security.
2014.
U.S. social security adminis-tration baby name database.
http://www.ssa.gov/OACT/babynames/limits.html.48P.
J.
Stone, D. C. Dunphy, M. S. Smith, and D. M.Ogilvie.
1966.
The General Inquirer: A ComputerApproach to Content Analysis.
MIT Press.C.
Strapparava and R. Mihalcea.
2007.
Semeval 2007task 14: Affective text.
In Proc.
SemEval, pages 70?74.M.
Theune, K. Meijs, and D. Heylen.
2006.
Gener-ating expressive speech for storytelling applications.In IEEE Transactions on Audio, Speech and Lan-guage Processing, pages 1137?1144.P.
Turney and M. L. Littman.
2002.
Unsupervisedlearning of semantic orientation from a hundred-billion-word corpus (technical report erc-1094).Disney Wiki.
2014.
Description of Disney char-acters.
http://disney.wikia.com/wiki/Category:Disney_characters#.J.
Y. Zhang, A. W. Black, and R. Sproat.
2003.
Iden-tifying speakers in children?s stories for speech syn-thesis.
In Proc.
of Interspeech.49
