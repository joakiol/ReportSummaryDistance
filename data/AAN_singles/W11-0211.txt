Proceedings of the 2011 Workshop on Biomedical Natural Language Processing, ACL-HLT 2011, pages 92?100,Portland, Oregon, USA, June 23-24, 2011. c?2011 Association for Computational LinguisticsTowards Morphologically Annotated Corpusof Hospital Discharge Reports in PolishMa?gorzata MarciniakInstitute of Computer Science PASul.
J.K. Ordona 21,01-237 Warszawa, Polandmm@ipipan.waw.plAgnieszka MykowieckaInstitute of Computer Science PASul.
J.K. Ordona 21,01-237 Warszawa, Polandagn@ipipan.waw.plAbstractThe paper discuses problems in annotatinga corpus containing Polish clinical data withlow level linguistic information.
We proposean approach to tokenization and automaticmorphologic annotation of data that uses ex-isting programs combined with a set of do-main specific rules and vocabulary.
Finallywe present the results of manual verificationof the annotation for a subset of data.1 IntroductionAnnotated corpora are knowledge resources indis-pensable to the design, testing and evaluation oflanguage tools.
Medical language differs signifi-cantly from the everyday language used in newspa-pers, magazines or fiction.
Therefore, general lan-guage corpora are insufficient when creating toolsfor (bio)medical text processing.There are several biomedical corpora available forEnglish such as GENIA (Kim et al, 2010) ?
thebest known and most used one, containing MED-LINE abstracts annotated on several levels; BioInfer(Pyysalo et al, 2007) targeted at protein, gene, andRNA relationships annotation; or CLEF (Roberts etal., 2009) containing 20,000 cancer patient recordsannotated with clinical relations.
Medical corporaare also collected for lesser spoken languages, e.g.MEDLEX ?
Swedish medical corpus (Kokkinakis,2006); IATROLEXI project for Greek (Tsalidis etal., 2007); or Norwegian corpus of patients?
histories(R?st et al, 2008).
The paper (Cohen et al, 2005)contains a survey of 6 biomedical corpora.
The au-thors emphasize the importance of a standard formatand give guidelines for careful annotation and eval-uation of corpora.The immediate goal of the paper is to estab-lish and test a method of annotating Polish clini-cal data with low level linguistic information, i.e.token and morpheme descriptions.
The research isdone on a relatively small set of data (more than450,000 tokens) but to gain the experience neces-sary to create a much larger annotated corpus of Pol-ish medical texts.
We would like to use our cor-pus to refine and test domain tools for: tagging,Named Entity Recognition or annotation of nominalphrases.
We have already annotated the corpus withsemantic information (Marciniak and Mykowiecka,2011) using an existing rule based extraction sys-tem (Mykowiecka et al, 2009) and performed exper-iments with machine learning approaches to seman-tic labeling (Mykowiecka and Marciniak, 2011).Thus, to enable the realization of various scientificgoals, a detailed and universal morphologic annota-tion of the corpus was introduced.The division into tokens is the first level of textanalysis.
It is frequently performed without payingspecial attention to potential problems, just by di-viding text on spaces, line breaks and punctuationmarks.
In many applications this is quite a satis-factory solution, but in case of texts that contain alot of non-letter characters, using universal tokeniza-tion rules frequently causes problems.
Some exam-ples, in the case of using the Penn Treebank tok-enization scheme in annotating the GENIA corpuswere pointed out in (Teteisi and Tsujii, 2006).
Jiangand Zhai (2007) show the importance of tokeniza-tion strategies in the biomedical domain, and the in-92fluence of this process on the results of informationretrieval.
Our approach consists of dividing text intosimple tokens which can be grouped at subsequentlevels of analysis using domain specific knowledge.For languages with rich inflection, like Polish,morphological annotation is indispensable for fur-ther text analysis.
As there are no Polish taggerswhich can analyze medical texts, nor medical lexi-cons containing inflected forms, we combine a gen-eral purpose tagger with a set of domain specificrules referring to a small data induced vocabulary.A portion of the automatically annotated data waschecked by two linguists to assess data quality.
Theresults obtained are given in 8.
Currently, the entiredataset is undergoing manual verification.2 Linguistic Characteristics of TextsThe corpus consists of 460 hospital discharge re-ports of diabetic patients, collected between theyears 2001 and 2006 in one of Warsaw?s hospi-tals.
These documents are summaries of hospitaltreatment and are originally written in MS Wordwith spelling correction turned on, so the errors ob-served are mainly in words that are not included inthe dictionary.
The documents are converted intoplain text files to facilitate their linguistic analysisand corpus construction.
Clinical data include infor-mation serving identification purposes (names andaddresses) which are substituted by symbolic codesbefore making the documents accessible for furtheranalysis.
The annonymization task was performedin order to make the data available for scientific pur-poses.
We plan to inspect the data manually, to re-move all indirect information enabling a patient?sidentification, and negotiate the terms for makingthe corpus publicly available.Each document is 1.5 ?
2.5 pages long, and be-gins with the identification information of the pa-tient and his/her visit in hospital.
Next, the follow-ing information is given in short form: significantpast and current illnesses, diagnoses and patient?shealth at the beginning of the hospitalization.
Af-ter these data, the document describes results of ex-aminations such as height, weight, BMI and bloodpressure, ophthalmology examinations, blood tests,lipid profile tests, radiology or ultrasound.
This partof the document may also contain descriptions of at-tempts to select the best treatment for the patient.The summary of the document starts from the wordEpikryza ?Discharge abstract?.
Its length is abouthalf a page of text.
It contains: data about a pa-tient?s diabetes, a description of diabetic complica-tions, and other illnesses, selected examination re-sults and surgical interventions, information abouteducation, diet observed, self monitoring, patient?sreactions, and other remarks.
Finally, all recommen-dations are mentioned, including information aboutprescribed diet, insulin treatment (type and doses)and oral medication.Most information is given as free-form text, butthe vocabulary of these documents is very spe-cific, and significantly differs from texts includedin corpora of general Polish like IPIPAN Corpus(Przepi?rkowski, 2004) or NKJP (National Corpusof Polish, http://nkjp.pl).
The texts con-tain many dates in different formats, and a lot oftest results with numerical values, whose descrip-tions are omitted in NKJP.
The texts contains alsoa lot of medication names, like Cefepime or Ac-ard not present in any general Polish dictionary.Some of them are multi-word names like DiaprelMR, Mono Mack Depot, Mixtard 10.
The samemedication can be referred to in different ways de-pending on international or Polish spelling rules(e.g.
Amitriptylinum and its Polish equivalent Amit-ryptylina).
Polish names could be inflected by cases(e.g.
Amitryptylinygen).In documents, many diagnoses are written inLatin.
In the following examples the whole phrasesare in Latin: Retinopathia diabetica simplex cummaculopathia oc.
sin.
?simple diabetic retinopathywith maculopathy of the left eye?
; or Laryngitischronica.
Otitis media purulenta chronica dex.
?Chronic laryngitis.
Chronic purulent inflammationof the middle right ear?.
Sometimes foreign expres-sions are thrown into a Polish sentences: Ascitesduz?a ilos?c?
p?ynu w jamie brzusznej mie?dzy pe?tlamijelit .
.
.
?Ascites a lot of fluid in abdominal cavitybetween intestinal loops .
.
.
?
?
only the first wordis not in Polish.3 Corpus descriptionThe corpus is annotated with morphological and se-mantic information.
The standard of annotation fol-93lows the TEI P5 guidelines advised for annotation ofbiomedical corpora, see (Erjavec et al, 2003).
Ourcorpus format is based on the one accepted for theNKJP corpus (Przepi?rkowski and Ban?ski, 2009).According to this scheme, every annotation is de-scribed in a separate file.
Each discharge documentis represented by a catalog containing the followingfive files:?
xxx.txt ?
plain text of the original annonymizeddocument;?
xxx.xml ?
text of the document (in the form asin xxx.txt file) divided into numbered sectionswhich are in turn divided into paragraphs;?
xxx_segm.xml ?
token limits and types (29classes);?
xxx_morph.xml ?
morphological information(lemmas and morphological feature values);?
xxx_sem.xml ?
semantic labels and limits.4 TokenizationThe first level of text analysis is its segmentationinto tokens.
In general, most tokens in texts arelowercase words, words beginning with a capital let-ter and punctuation marks.
The most common (thusthe most important) tokenization problem is then todecide whether a particular dot ends a sentence orbelongs to the preceding abbreviation (or both).
Insome texts there are also many numbers represent-ing dates, time points, time intervals or various nu-merical values.
For texts in which uniform standardsof expressing these notions are obeyed, recognizingsuch complex tokens is much easier and simplifiesfurther text analysis.In medical texts the problem of non-word tokensis harder than in the case of newspapers or novelcontent as they constitute a much larger portionof the text itself.
Apart from descriptions of time(dates, hours, periods of time) there are numbers thatrefer to values of different medical tests or medicinedoses and sizes.
There are also many specificnames which sometimes contain non-letter charac-ters (e.g.
Na+) as well as locally used abbreviationsand acronyms.
An additional difficulty is caused bythe lack of will to obey writing standards.
Physi-cians use different ways of describing dates (e.g.02.09.2004, 30.09/1.10.2003, 06/01/2004, 14.05.05,28 .04.
05, 12.05.2005r.)
or time (8:00 vs 8.00).They also do not pay enough attention to punctu-ation rules and mix Polish and English standards ofwriting decimal numbers.
In Polish we use a commanot a dot, but the influence of English results in com-mon usage of the decimal point.
Sometimes bothnotations can be found in the same line of text.
Fur-ther, the sequence ?2,3?
may mean either ?2.3?
or twoseparate values: ?2?
and ?3?.Two tools used in the process of constructingthe corpus have embedded tokenizers.
The firstone is a part of the information extraction systemSProUT (Droz?dz?yn?ski et al, 2004) which was usedto write grammars identifying semantically impor-tant pieces of text.
The general assumption adoptedwhile building its tokenizer was ?not to interpret toomuch?, which means that tokens are relatively sim-ple and do not rely on any semantic interpretation.Their self explanatory names, together with tokenexamples and their frequencies in the entire inputdata set, are listed in table 1.Two other tokenization modules are embedded inthe TaKIPI tagger used to disambiguate the morpho-logical descriptions of word forms (Piasecki, 2007).The first one divides all character sequences intowords and non-words which are assigned the ign la-bel.
The second tokenizer interprets these non-wordsequences and assigns them ttime, tdate, turi (for se-quences with dots inside) and tsym labels.
It alsoapplies a different identification strategy for tokenlimits ?
for all non-word tokens only a space or aline break ends a token.
Although treating a date(15.10.2004r) or a range (1500-2000) as one tokenis appropriate, in the case of sequences where spacesare omitted by mistake, the resulting tokens are of-ten too long (e.g.
?dnia13/14.07.04?, ?iVS-1,5?
).After analyzing the results given by three differ-ent tokenizers we decided to use the token classesidentified by the SProUT tokenizer and align itsresults with the results of the ?simple?
TaKIPI to-kenizer.
SProUT tokens which were longer thanTaKIPI tokens, e.g.
?1x2mg?, ?100mg?, ?50x16x18?,were divided into smaller onces.
The changesintroduced to token limits concern those tokensof the other_symbol type which contain punctua-tion marks.
The other_symbol class comprises se-quences which do not fit into any other class, i.e.94symbols for which separate classes are not defined(e.g.
?=?)
and mixed sequences of letters and digits.In this latter case a token ends only when a space ora line break is encountered.
The most typical casewhen this strategy fails in our data is the sequence?HbA1c:?
as the name of the test according to thetokenizer rules is classified as an ?other_symbol?the following colon is not separated.
There arealso other similar sequences: ?HbA1c=9,1%:?
or?(HbA1C?.
To make the results more uniform we di-vided these tokens on punctuation characters.
Thisprocess resulted in replacing 1226 complex tokensby 4627 simple ones.
Among these newly cre-ated tokens the most numerous class was lower-case_word and numbers which were formed afterseparating numbers and unit names, e.g.
10g, 100cmand sequences describing repetitions or sizes, like2x3, 2mmx5mm.
The longest sequence of this kindwas ?ml/min.,GFR/C-G/-37,5ml/min/1,73m2?.
Thisstring was divided into 18 tokens by TAKIPI but fi-nally represented as 23 tokens in the corpus.
Finally,in the entire data set 465004 tokens (1802864 char-acters) were identified.
The most numerous classrepresents numbers ?
18.8% (9% of characters), allpunctuation characters constitute 25% of the totalnumber of tokens (6.5% characters).5 Morphological analysiesMorphological annotation was based on the resultsobtained by the publicly available Polish POS tag-ger TaKIPI that cooperates with Morfeusz SIAT(Wolin?ski, 2006) ?
a general-purpose morpholog-ical analyzer of Polish.
For each word, it assignsall possible interpretations containing: its base form,part of speech, and complete morphological charac-terization (e.g.
case, gender, number, aspect if rel-evant).
The description is exhaustive and aimed atfurther syntactic analyses of texts.The annotation is done in three steps.
In thefirst one the documents are analyzed and disam-biguated by TaKIPI.
TaKIPI can be combined withthe Guesser module (Piasecki and Radziszewski,2007) which suggests tags for words which are notin the dictionary.
We decided to use this modulebecause otherwise 70600 tokens representing wordsand acronyms that occur in the documents would beassigned an unknown description.
The gain from itsTable 1: Token types and number of occurrencesnumberstoken class name & examples initial finalall_capital_word: ALT, B, HDL, HM 18369 18416any_natural_number 85766 87246apostrophe 14 14back_slash 7 7closing_bracket 2661 2663colon 12426 12427comma 28799 28831dot 47261 47269exclamation_sign 49 49first_capital_word: Al, Amikacin, Wysokie 43136 43269hyphen 4720 4725lowercase_word: antygen, aorta 192305 193368mixed_word_first_capital: AgHBs, IIo, 513 514NovoRapidmixed_word_first_lower: antyHBS, dlAST 989 1003number_word_first_capital: 200Hz, 14HN 48 0number_word_first_lower: 100ml, 200r 1kaps 650 0opening_bracket 3344 3355other_symbol: (132x60mm), 1,34x3,25, 3161 2868HbA1c=10,3%,percentage_tok 4461 4478question_mark 207 209quotation 1 1semicolon 455 455slash 10340 10353word_number_first_capital: AST34, B6 1195 1195word_number_first_lower: mm3, pH6 1865 1854word_with_hyphen_first_capital: B-hCG, 163 163Anty-HBsword_with_hyphen_first_lower: m-ce, p-cia?
402 402all tokens 463307 465004usage is however not so evident, as tags and baseforms suggested by Guesser are quite often incor-rect ?
in one test set, only 272 forms out of 1345were analyzed correctly.The analyses of TaKIPI results shows that thereare many systematic errors.
They can be correctedglobally.
An example of such an error is the de-scription of medication names produced by Guesser.Their morphologic tags are often correct, but theproblem is with gender assignment in case of mascu-line forms.
In Polish there are three subtypes of mas-culine gender: personal, animate and inanimate, andGuesser quite often uses personal masculine genderinstead of the inanimate one while analyzing med-ication names.
The second most common problemconcerns base forms, because all base forms createdby the module are written with a small letter.
So inthe case of proper names, all base forms have to becorrected.
Moreover, TaKIPI do not disambiguateall tags ?
certain forms still have more than one pos-sible description.95Thus, to limit the number of manual changesneeded in the final version of the corpus, we post-process the results with a set of rules (see section 7)created on the basis of a list of all different tokendescriptions.
The rules mainly correct the annota-tions of domain related tokens like acronyms andunits: BMI, HbA1c, RR, USG, Hz or kcal; medi-cation names e.g.
Diaprel, its diaprel base form ischanged into Diaprel; and other domain terms likedekarboksylazie (?decarboxylaseloc?)
for which themasculine base form was suggested dekarboksylazinstead of feminine dekarboksylaza.
Moreover, tagsof misspelled tokens and foreign words are assignedto tokens during this stage and if there is more thanone description attached to a token, then the moreprobable in the domain is chosen.Finally, the morphology analyses are manuallycorrected.
This is done by two linguists.
The re-sults are compared and corrected by a third annota-tor.
The first results are described in section 8.6 TagsFor each token, TaKIPI assigns its base form,POS, and full morphological description.
Forexample, the token badania that has the baseform badanie ?examination?
is classified in all 579occurrences as a neutral noun.
In 566 casesit is classified as a singular form in genitiveand is assigned the tag subst:sg:gen:n (substan-tive:singular:genitive:neutral); in 13 cases as a plu-ral noun including 8 nominative forms, 4 accusativeand even one vocative (unreliable in medical texts).TaKIPI assigns the unknown tag (ign) to numbers,so we introduced the number tag to represent nu-merical values in the corpus.
It is assigned to 18.8%of tokens.The set of potential morphological tags consistsof more than 4000 elements.
In our corpus only 450different tags are represented, in comparison to over1000 tags used in the general Polish IPIPAN corpus(Przepi?rkowski, 2005).In the rest of this section we describe tags usedfor the classification of strings that are not properlyclassified by TaKIPI.
If no tag described in the sec-tion suits a token, the tag tsym is assigned to it.
Inparticular, all patient codes (like d2005_006) havethe tsym tag.6.1 ErrorsSpelling errors in the corpus are left as they are.
Mis-spelled tokens are assigned the base form equal tothe token, and one of the following tags dependingon the type of error:?
err_spell describes misspelled tokens likebia3ko instead of bia?ko (?protein?).
In the cor-pus we provide additional information with thecorrected input token, its base form and mor-phological tag.?
err_conj describes concatenations like cukrzy-cowej2000 (?diabetic2000?).
In this case weadd the correct form cukrzycowej 2000 to thecorpus but do not add its description.?
err_disj_f describes the first part of an in-correctly disjointed word.
For example theword cis?nienie (?pressure?)
was divided intotwo parts ci and s?nienie, (by chance, both arevalid Polish words).?
err_disj_r describes the second part of the in-correctly disjointed word.The last three categories can be supplementedwith spell description if necessary.
For example thetoken Bylaw is a concatenation of the misspelledword By?a (?was?)
with the preposition w (?in?).
Thistoken has the tag err_conj_spell, and the By?a wcorrection is added.6.2 AbbreviationsThere are many abbreviations in the documents.Some of them are used in general Polish like prof(?professor?)
or dr (?doctor), but there are many ab-breviations that are specific to the medical domain.For example in the descriptions of USG examina-tions the letter t denotes te?tnica (?artery?
), while ttrefers to the same word in plural, although usu-ally there is no number related difference e.g.
wit(?vitamin?)
can be used in plural and singular con-text.
Sometimes it is not a single word but thewhole phrase which is abbreviated, e.g.
NLPZ isthe acronym of the noun phrase Niesterydowe LekiPrzeciwZapalne ?Non-Steroidal Anti-InflammatoryDrugs?, and wpw is an abbreviation of the prepo-sitional phrase w polu widzenia ?in field of view?.96Abbreviations and acronyms obtain the tag acron.Moreover, it is possible to insert the full form corre-sponding to them.Acronyms denoting units obtain the tag unit.Units in common usage are not explained: mm, kg,h, but if a unit is typical to the medical domain, itsfull form is given (e.g.
HBD means tydzien?
ciaz?y?week of pregnancy?
).We also distinguish two tags describing prefixesand suffixes.
The token makro (?macro?)
in thephrase makro i mikroangiopatia (?macro and mi-croangiopathy?)
has the tag prefix, while the suffixtag describes, for example, the part ma of the string10-ma which indicates instrumental case of number10, like in: cukrzyca rozpoznana przed 10-ma laty(?diabetes diagnosed 10 years ago?
).6.3 Foreign WordsForeign words receive the foreign tag.
This tag canbe elaborated with information on the part of speech,so for example, Acne has the tag foreign_subst.
Itis possible to attach a Polish translation to foreignwords.7 Correction RulesCorrection rules are created on the basis of a listof different tokens, their base form, and tags thatoccurred in the corpus.
Each rule is applied to allmatching form descriptions of tokens in the alreadytagged data.We use the method of global changes because wewant to decrease the number of manual correctionsin the corpus on the final, manual stage.
It shouldbe noted that without context it is impossible to cor-rect all morphological tags.
We can only eliminateevident errors but we cannot decide, for example,if a particular description of a token badanie ?ex-amination?
(see section 6) is correct or not.
Allthese tags can be verified only if we know the con-text where they occurred.
However, quite a lot ofchanges can be made correctly in any context, e.g.changes of gender of a medication name (Lorindenfinto Lorindenm3), or in the prevailing number ofcases, e.g.
assigning to zwolnienie the gerund tag?slowing?
(11 occurrences) instead of less frequentin the texts noun ?sick leave?
only one occurrence(TaKIPI leaves both descriptions).There are two main types of correction rules ofwhich syntax is given in (1?2).
?#?
is a separator;the character ?>?
indicates the new token descriptionthat is applied to the corpus; after || additional in-formation can be noted.
In case of rule (1) it couldbe a text that explains the meaning of acronyms, ab-breviations or foreign words, while for rule (2), acorrected token, base form and tag can be given.This additional information might be used for creat-ing a corpus without spelling errors, dictionaries ofabbreviations or foreign words used in the medicaldomain.
(1) token#base form#tag#>token#new base form#new tag#|| ?string?
(optionally)(2) token#base form#tag#>token#token#error_spell# ||corr.
token#corr.
base form#new tag#The first scheme is useful for changing the baseform or the tag of a token.
See example (3) wherethe first letter of the base form is capitalized and per-sonal masculine gender m1 is changed into inani-mate masculine gender m3.
(3) Insulatard#insulatard#subst:sg:nom:m1#>Insulatard#Insulatard#subst:sg:nom:m3#The second scheme is applied to a token grani-ach ?ridges?
(in mountain) that represents the exist-ing but unreliable word in the medical domain.
Forall of its occurrences in our data (3 cases) it is sub-stituted by granicach ?limits?
by the following cor-rection rule:(4) graniach#gran?#subst:pl:loc:f#>granicach#granicach#err_spell# ||granicach#granica#subst:pl:loc:f#If there is more than one interpretation left byTaKIPI, all are mentioned before the character ?>?.See example (5) where two different base forms arepossible for the token barku and both have the sametag assigned.
The first base form bark (?shoulder?
)is definitely more probable in the medical domainthan the second one barek (?small bar?
or ?cocktailcabinet?
), so the rule chooses the first description.
(5) barku#bark#subst:sg:gen:m3##barek#subst:sg:gen:m3#>barku#bark#subst:sg:gen:m3#97Table 2 presents the frequencies of top level mor-phological classes: directly after running the tagger,after changing the token limits and after applying au-tomatic changes.
In the last column the number ofdifferent forms in every POS class is presented.Most part of speech names are self explanatory,the full list and description of all morphological tagscan be found in (Przepi?rkowski, 2004), the newlyintroduced tags are marked with ?.
Of all words(all tags apart form interpunction, number and tsym)the most numerous groups are nouns (substantive)?
54% and adjectives ?
15% of wordform occur-rences.Table 2: Morpheme types and numbers of occurrencestagger after tok.
final corpusresults change differentPOS tag number of tag occurences formsadj 35305 35041 36848 3576adv 2323 2323 2437 245conj 5852 5852 5680 36prep 29400 29400 26120 71pron 302 302 142 21subst 82215 82215 105311 5093verb forms: 24743 24741 19912 2001fin 2173 2173 1900 190ger 9778 9778 4677 423ppas 5593 5593 6170 551other 7199 7197 7165 837qub 4244 4242 2452 67num 703 703 703 34ign 160951 163629 0 0acron?
0 0 30003 678unit?
0 0 28290 82prefix?
0 0 13 5suffix?
0 0 36 6tsym?
0 0 534 462interp 115323 116556 116556 21number?
0 0 87898 1386err_disj?
0 0 179 129err_spell?
0 0 560 440foreign?
0 0 1330 184total 461361 465004 465004 14537If we don?t take into account number, tsym andthe punctuation tokens, we have a corpus of 348461tokens (TW) out of which 78854 (29.81%) werechanged.
The most frequent changes concerned in-troducing domain related unit and acronym classes(nearly 72% of changes).
Quite a number of changeswere responsible for the capitalization of propername lemmata.
In table 3 the numbers of some othertypes of changes are presented.Table 3: Morphological tag changestype of change number % % ofof changes TWbase formcapitalization only 6164 13.8 4.12other 25503 32.34 9.64POSto acron & unit 56697 71.90 21.43to other 10547 13.37 3.99grammatical features (without acron and unit)only case 109 0.13 0.04only gender 1663 2.11 0.62other 13215 16.75 4.99Table 4: Manual correctionbasic tags all tagsall tokens 8919 8919without numbers and interp 4972 4972unchanged 4497 4451changed 475 521same changes accepted 226 228same changes not accepted 1 1different changes none accepted 4 5different changes.
accepted 1 3 4different changes.
accepted 2 40 42only 1st annot.
changes - accepted 15 48only 2nd annot.
changes - accepted 128 124only 1nd annot.
changes - not accepted 47 47only 2nd annot.
changes - not accepted 0 08 Manual CorrectionThe process of manual correction of the corpus isnow in progress.
It is performed using an editorspecially prepared for visualization and facilitationof the task of correcting the corpus annotation at alllevels.
In this section we present conclusions on thebases of 8 documents corrected by two annotators(highly experienced linguists).
In the case of incon-sistent corrections the opinion of a third annotatorwas taken into account.
The process of annotationchecking took about 2x20 hours.From a total number of 8919 tokens in the dataset,the verification of 4972 (words, acronyms, units)was essential, the remaining 3947 tokens representnumbers, punctuation and tsym tokens.
The correc-tion rules changed the descriptions of 1717 (34%)tokens, only 87 cases were limited to the changeof a lowercase letter into a capital letter of thebase form.
Manual verification left 4497 token de-scriptions unchanged, while 10.6% of descriptionswere modified (evaluation of TaKIPI by Karwin?skaand Przepi?rkowski (2009) reports 91.3% accuracy).Kappa coefficient was equal to 0.983 for part of98speech and 0.982 for case assignment (when it is ap-plicable).
The results of manual correction are givenin table 4.
The ?basic tags?
column gives the numberof changes of the base form and tag, while the ?alltags?
column takes into account all changes, includ-ing descriptions of the correct word form in case ofspelling errors, explanations of acronyms or units.More detailed analysis of annotation inconsisten-cies shows two main sources of errors:?
lack of precision in guidelines resulted inchoosing different base forms in case ofspelling errors and different labeling of caseswith the lack of diacritics which resulted in cor-rect but not the desired forms;?
some errors were unnoticed by one of the an-notators (just cost of manual work), e.g.
in thedata there are many strings ?W?
and ?w?
whichmay be either acronyms or prepositions.There are only a few cases that represent realmorphological difficulties, e.g.
differentiating adjec-tives and participles (5 cases among the annotators).Some examples of different case and gender assign-ments were also observed.
They are mostly errorsconsisting in correcting only one feature instead oftwo, or a wrong choice of a case for long phrases.9 Conclusions and Further WorkThe problems described in the paper are twofold,some of them are language independent like tok-enization, description of: abbreviations, acronyms,foreign expressions and spelling errors; while theothers are specific for rich-morphology languages.Our experiment showed that analyzing specializedtexts written in highly inflected language with a gen-eral purpose morphologic analyzer can give satis-factory results if it is combined with manually cre-ated global domain dependent rules.
Our rules werecreated on the basis of a sorted list of all token de-scriptions.
That allowed us to analyze a group of to-kens with the same base form e.g.
an inflected noun.Additional information concerning the frequency ofeach description, indicated which token correctionswould be important.Unfortunately, the process of rule creation is time-consuming (it took about 90 hours to create them).To speed up the process we postulate to preparethree sets of tokens for which rules will be createdseparately.
The first one shall contain tokens whichare not recognized by a morphological analyzer, andhence requiring transformation rules to be createdfor them.
The second set shall contain tokens withmore than one interpretation, for which a decision isnecessary.
Finally we propose to take into accountthe set of frequent descriptions.
Infrequent tokenscan be left to the manual correction stage as it is eas-ier to correct them knowing the context.At the moment our corpus contains three annota-tion levels ?
segmentation into tokens, morpholog-ical tags and semantic annotation.
After the firstphase of corpus creation we decided to introducean additional level of annotation ?
extended tok-enization, see (Marcus Hassler, 2006).
Current tok-enization divides text into simple unstructured frag-ments.
This solution makes it easy to address anyimportant fragment of a text, but leaves the inter-pretation of all complex strings to the next levels ofanalysis.
A new extended tokenization is planned tocreate higher level tokens, semantically motivated.It will allow the annotation of complex strings like:dates (02.12.2004, 02/12/2004); decimal numbers;ranges (10 - 15, 10-15); sizes and frequencies (10x 15, 10x15); complex units (mm/h);abbreviationswith full stops (r. ?
rok ?year?
); acronyms contain-ing non-letter characters (K+); complex medicationnames (Mono Mack Depot).Extended tokens can be recognized by rules tak-ing into account two aspects: specificity of thedomain and problems resulting from careless typ-ing.
In the case of abbreviations and acronyms,the best method is to use dictionaries, but someheuristics can be useful too.
Electronic dictionar-ies of acronyms and abbreviations are not availablefor Polish, but on the basis of annotated data, a do-main specific lexicon can be created.
Moreover, wewant to test ideas from (Kokkinakis, 2008), the au-thor presents a method for the application of theMeSH lexicon (that contains English and Latin data)to Swedish medical corpus annotation.
We will usea similar approach for acronyms and complex medi-cation name recognition.99ReferencesK.
Bretonnel Cohen, Lynne Fox, Philip V. Ogren, andLawrence Hunter.
2005.
Corpus design for biomed-ical natural language processing.
In Proceedings ofthe ACL-ISMB Workshop on Linking Biological Liter-ature, Ontologies and Databases: Mining BiologicalSemantics, pages 38?45, Detroit, June.
Association forComputational Linguistics.Witold Droz?dz?yn?ski, Hans-Ulrich Krieger, Jakub Pisko-rski, Ulrich Sch?fer, and Feiyu Xu.
2004.
ShallowProcessing with Unification and Typed Feature Struc-tures ?
Foundations and Applications.
German AIJournal KI-Zeitschrift, 01/04.Toma Erjavec, Yuka Tateisi, Jin dong Kim, Tomoko Ohta,and Jun ichi Tsujii.
2003.
Encoding Biomedical Re-sources in TEI: the Case of the GENIA Corpus.
InProceedings of the ACL 2003, Workshop on NaturalLanguage Processing in Biomedicine, pages 97?104.Jing Jiang and Chengxiang Zhai.
2007.
An Empiri-cal Study of Tokenization Strategies for BiomedicalInformation Retrieval.
Information Retrieval, 10(4?5):341?363.Danuta Karwan?ska and Adam Przepi?rkowski.
2009.
Onthe evaluation of two Polish taggers.
In The proceed-ings of Practical Applications in Language and Com-puters PALC 2009.Jin-Dong Kim, Tomoko Ohtai, and Jun?ichi Tsujii.
2010.Multilevel Annotation for Information Extraction In-troduction to the GENIA Annotation.
In Linguis-tic Modeling of Information and Markup Languages,pages 125?142.
Springer.Dimitrios Kokkinakis.
2006.
Collection, Encoding andLinguistic Processing of a Swedish Medical Corpus?
The MEDLEX Experience.
In Proceedings of theFifth International Language Resources and Evalua-tion (LREC?06), pages 1200?1205.Dimitrios Kokkinakis.
2008.
A Semantically Anno-tated Swedish Medical Corpus.
In Proceedings of theSixth International Language Resources and Evalua-tion (LREC?08), pages 32?38.Ma?gorzata Marciniak and Agnieszka Mykowiecka.2011.
Construction of a medical corpus based on in-formation extraction results.
Control & Cybernetics.in preparation.G?nther Fliedl Marcus Hassler.
2006.
Text prepara-tion throughextended tokenization.
Data Mining VII:Data, Text and Web Mining and their Business Appli-cations, 37.Agnieszka Mykowiecka and Ma?gorzata Marciniak.2011.
Automatic semantic labeling of medical textswith feature structures.
In The Text Speech and Dia-logue Conference 2011 (submitted).Agnieszka Mykowiecka, Ma?gorzata Marciniak, andAnna Kups?c?.
2009.
Rule-based information extrac-tion from patients?
clinical data.
Journal of Biomedi-cal Informatics, 42:923?936.Maciej Piasecki and Adam Radziszewski.
2007.
PolishMorphological Guesser Based on a Statistical A TergoIndex.
In 2nd International Symposium Advancesin Artificial Intelligence and Applications (AAIA?07),wis?a, Poland, pages 247?256.Maciej Piasecki.
2007.
Polish tagger TaKIPI: Rule basedconstruction and optimisation.
Task Quarterly, 11(1?2):151?167.Adam Przepi?rkowski and Piotr Ban?ski.
2009.
XMLtext intechange format in the National Corpus of Pol-ish.
In The proceedings of Practical Applications inLanguage and Computers PALC 2009, pages 245?250.Adam Przepi?rkowski.
2004.
Korpus IPI PAN.
Wersjawste?pna / The IPI PAN Corpus: Preliminary version.IPI PAN.Adam Przepi?rkowski.
2005.
The IPI PAN Corpusin numbers.
In Zygmunt Vetulani, editor, Proc.
ofthe 2nd Language & Technology Conference, Poznan?,Poland.Sampo Pyysalo, Filip Ginter, Juho Heimonen, JariBj?rne, Jorma Boberg, Jouni J?rvinen, and TapioSalakoski.
2007.
BioInfer: a corpus for informationextraction in the biomedical domain.
BMC Bioinfor-matics, 8.Angus Roberts, Robert Gaizauskas, Mark Hepple,George Demetriou, Yikun Guo, Ian Roberts, and An-drea Setzer.
2009.
Building a semantically annotatedcorpus of clinical texts.
Journal of Biomedical Infor-matics, 42(5):950?966.Thomas Brox R?st, Ola Huseth, ?ystein Nytr?, and An-ders Grimsmo.
2008.
Lessons from developing anannotated corpus of patient histories.
Journal of Com-puting Science and Engineering, 2(2):162?179.Yuka Teteisi and Jun?ichi Tsujii.
2006.
GENIA An-notation Guidelines for Tokenization and POS Tag-ging.
Technical report, Tsujii Laboratory, Universityof Tokyo.Christos Tsalidis, Giorgos Orphanos, Elena Mantzari,Mavina Pantazara, Christos Diolis, and AristidesVagelatos.
2007.
Developing a Greek biomedical cor-pus towards text mining.
In Proceedings of the CorpusLinguistics Conference (CL2007).Marcin Wolin?ski.
2006.
Morfeusz ?
a Practical Tool forthe Morphological Analysis of Polish.
In Mieczys?awK?opotek, S?awomir Wierzchon?, and Krzysztof Tro-janowski, editors, IIS:IIPWM?06 Proceedings, Ustron,Poland, pages 503?512.
Springer.100
