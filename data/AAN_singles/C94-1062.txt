NOTES ON LR PARSER DES IGNChrister SamuelssonSwedish Ins t i tu te  of Computer  Sc ience,Box 1263 S-164 28 K ls ' ra ,  Sweden.
lg-maih christer@sics.se1 INTRODUCTIONThis paper discusses the design of an LR parser fora specific high-coverage English grammar.
The de-sign principles, though, are applicable to a large classof unification-based grammars where the constraintsare realized as Prolog terms and applied monotonicallythrough instantiation, where there is no right move-ment, and where left movement is handled by gapthreading.The I,R.
parser was constructed for experiments onprobabilistic parsing and speedup learning, see \[10\].
LI{parsers are suitable for probabilistic parsing since theycontain a representation of the current parsing state,namely the stack and the input string, and since theactions of the parsing tables are easily attributed prob-abilities conditional on this parsing state.
LR parsersare suitable for the speedup learning application sincetile learne~ grantmar Ls much larger than the originalgrammar, and the prefixes of tile learned rules over-lap to a very high degree, circumstances that are far"from ideal for the system's original parser.
Even thoughthese ends influenced the design of the parser, this ar-ticle does not focus on these applications but rather onthe design and testing of the parser itself.2 LR  PARSINGAn LI{ parser is a type of shift-reduce parser originallydevised by Knuth for programming languages \[4\].
Thesuccess of LR.
parsing lies ill handling a number of gram-mar rules simultaneously, rather than attempting oneat a time, by the use of prefix merging.
LI~.
parsing ingeneral is well described in \[1\], and its application tonatural-language processing in \[12\].An LR parser is basically a pushdown automaton,i.e.
it has a pushdown stack in addition to a finite setof internal states, and a reader head for scanning theinput string from left to right, one symbol at a time.
Infact, the "b"  in "LW' stands for left-to-right scanningof the input string.
The "W' stands for eonstr, ctingthe rightmost derivation in reverse.The stack is used in a characteristic way: The itemson the stack consist of alternating rammar symbolsand states.
The current state is the state on top of thestack.
The most distinguishing feature of an LR.
parseris however the form of the transition relation - -  theaction and gore tables.
A non-deterministic LR parsercan in each step perform one of four basic actions.
Instate S with lookahead symbol Syra it can:1. accept (S, Sym) : l lalt and signal success.2.
sh i f t (S ,Sym,S2) :  Consume the sylnbol Sym,place it on tile stack, and transit to state $2.3.
reduce (S, Sym, R) : l'op off a number of items Doratile stack corresponding to tim I{IIS of grammarrule R, inspect the stack for tile ohl state S1, placethe LttS of rule tt on tile stack, and transit to state$2 determined by goto(Sl ,LHS,S2).4. error(S,Sym):  Fail and backtrack.PreIix merging is accomplished by each internalstate corresponding to a set of l)artially processed gram-mar rules, so-called "dotted items" containing a dot (.
)to mark the current position.
Since the grammar ofFig.
1 contains Rules 2, 3, and 4, there will be a statecontaining the dotted itemsVP -~ V .VP  --~ V .
NPVP  -~ V .
NP  NPThis state corresponds to just having found a verb (V).Which of the three rules to apply in the end will bedetermined by the rest of the inl)ut string; at this pointno commitment has been made to either.Cornpiling L\[{.
parsing tables consists of construct-ing the internal states (i.e.
sets of dotted items) andfrom these deriving the sl,ift, reduce, accept and toteentrie.s of tile transition relation.
New states can be in-(h, ced from previous ones; given a state S1, anotherstate S2 reachable from it.
by goto(Sl ,Sym,S2) (orsh i f t (S l ,Sym,S2)  if Sym is a terulinal symlml) can beconstructed as Ibllows:I.
Select all items in state S1 where a particular sym-bol gym follows immediately afte,' the (lot and movethe dot to after this symbol.
This yiehls the kernelitems of state S2.2.
Construct the non-kernel closure by repeatedlyadding a so-called non-kernel item (with the dotat the beginning of the I{IIS) for each grammarrule whose LIIS matches a syn,bo\] following the(lot of some item in $2.Consider for example the grammar of Fig.
1, which willgenerate the states of Fig.
2.
State I can be constructedfrom State 0 by adwmcing the dot in S --~ .
NP  VP  andNP --+ ?
NP  I ' P  to form the items S ---+ NP  .
VP  andNP  --~ N I '  ?
PP ,  which constitute tire kernel of State 1.The non-kernel items are generated by the grauunar386S --~ NP VP (1)l q '  -~  v (2)vs,  .-+ V NS' (3)VP -~ V NP  NP  (4)VP -+  VP P I '  (5)NP - ,  l )e t  N (6 )N I '  -~  tb 'on  (7)NI '  -+ N I '  I ' P  (8)1' t  > -+ Prep  NP  (9)Figure 1: A toy grainniarrules for VPs and PPs, the categories following the dotin the new items, namely Ihlles 2, 3, 4, 5 aml 9.Using this method, the set <>f all parsing slates canI>e induced from an initial state whose single kernel itemhas the top symbol of the grammar preceded by thedot as its RI\[S (the item S' --+ ?
S of State 0 in Vig.
2).The accept, shift and goto e.ntries fall out autonmticallyfrom this procedure.
Any dotted item where the dotis at the end of the I{,IIS gives rise to a reduction l)ythe corresl>onding gramm~tr rule.
Thus it remains todetermine the lookahead sylnbols of the reduce enl, ries.In Simple LIt (SLR) the h)okahead is any termiualsymbol that can imnlediately follow any symbol of thesaltle tylie as the LIIS of tile rule.
In l,ookAhead 1,1L(LALIL) it is lilly terminal sylnbol that cali ilriiue(liatelyfollow the LIlS giwm that it was constructed using thisrule in this state, hi general, I,AI,R gives COilsiderablyfewer reduce entries than SI,I{., and thus results in fasterparsing.
Ill the experiments this reduced the l)arsingtiines by 30 %.3 PROBLEMS WITH LR  PARSINGThe l)roblems of applying the Lit-parsing scheme tolarge tmification grammars for natural language, ratherthan small context:free grammars for progranmling lan-guages, stem from three sources.
The tirst is that syu>bol matching no h)nger consists of checlcing atomic sym-bols for equality, but rather comparing COml)h~x \['eaLur(~structm'es.
The second is tile high lewq of ambiguityof natural hmguage and the resulting non-determinism.The third is tile sheer size.
of the gratllli'mrs.Straight-forward resorting to a context-free back:bone grammar and subsequent filtering using the fullconstraints of the underlying unification gramnrar (U(1)is an al>proaeh taken by lbr example \[3\], The I)roblemwith this al>proaeh is that the I>redictive power of I, heunification grammar is so vastly diluted when featurel>ropagation is omitted.
Firstly, the context-free l>ack-bone gramniar will ill general allow very irutlly Illoreanalyses titan the unification grammar, leading to l>oorparser performance.
Secondly, the fe.ature propagationnecessary for gap threa<ling to prevent n<mq.erminationdue to empty productions is obstructed.On the other haml, the treatment of 1,he full \[l(~constraiuts in the parsing-tal)le consLructioil phase isassociated with a nmnber of problemg most of whichSta le  0 f i l a te  1,q' -~  .
S S -+ NP .
V I "S -+ .
NP VP  NP  -+ NP .
PPNP  -+ ?
l ) ,q  N V f '  - ,  ?
VNP  ~ ?
l ' ron  V I '  -+ .
V NPNP  - ,  .
NP  PP  VP  -> .
V N I '  N I 'S ta te  ~ V I '  -~  ?
VP  1 '1 'NP ~ l ) c t .
N PP  -~  .
ib ' cp  NP,(;talc 3 ,fftalcNP ~ l ' ron  .
,';' ~ ,q ?Elate 5 Slalc 6',S' - ,  NP  V f ' .
VP  --,  V.VP -+ VP .
l ' F  VP  - ,  V .
N I 'I ' P  - , .
P rep  N I '  VP  -~  V .
N I '  NPS ta le  7 NI> -~ .
te l  NNP - ~ N I '  I ' P .
NP  -~ .
t ' ronS ta te  3 NP  -~ ?
NI '  PPI ' P  -~  Prep  ?
NP  S ta le  ON I '  ~ ?
l)ct N VP  - ,  V I '  I ' P .Nt '  ~ .
P rou  S la te  10NP  - ,  .
NP  1'1 > NP  -+ l )e t  N .f i t<de 1 1 ,~ta lc  12VP  - ,  VNP .
VP  ~ VNI  >NP.V I  > -~ V NP .
NP  NP  -+ NP .
PPN \ ]  > -- ,  NP .
PP  PP  - - ,  .
P rep  NPNP  -- ,  .
I ) c t  N S ta le  13N I '  .
.
.
.
15"on I ' P  - ,  lb ' c  v NF .N l '  ~ .
NP P l '  NP  --* NP .
P I 'PP  - -  .
l b ' cp  N I '  P f '  -~  ?
P rep  NPFigure 2: The internal stales of the toy grammarare discussed in \[,5\].
One of the main questions is thatof cquality or similarity between linguistic objects.Consider constructing the non-kernel items usingU(~ phrases following the dot in items ah'eady in theset fo~/l>rediction.
If such a phrase unifies with theIAISld a graulmar ule and we add the uew item withthis instantiation, we Ilee(\[ a mecl,ufism to ensure ter-mination the risk is that we add more aim moreiilsl.anLiated versiolls of the same il.e.nl hl(lelhdtely.
Onemight object that this is easily renmdied I)y only addiugitems I.hat are llot sllbsllllled by :Lily previous ones.
UN-\['ortunaLely, this does uot work, since it is quite possibleto ge l le ra te  all infinite se(luence of items none of whichsuhsunles tile other, see \[9\].
This problem call I)e solvedby using so called "resl;rictors" to block out the featurel)rol)agatioll eading to  non-termination, see Ill\], hutstill the number of items t\[lat are slight variants of one-another may I)e quite large.
In her paper \[5\], Nakazawaproposes a simple and elegant solution to this problem:"While the C LOS U ILE proced ure makes top-downpredictions in the same way its beh)re \[using thefull constraints of the unitication grammar\], newitems ;tre added without instantlation.
Sinceonly original productions in a gl'itlllltl~Lr appear asitems, productions ~tre added am new items onlyonce and the nontermlnation problem does notoccur, as is the case of the I,R parsing algorithmwith atomic categoric.s.
"387Unfortunately, even with this simplification, computingtile non-kernel closure is quite time-consuming for largeunification grammars.Empty productions are a type of grammar ules thatconstitutes a notorious problem for parser developers.The LIIS of these grammar ifles have no realizationin the inlmt string since their RIIS are empty.
Theyare used to model movement as in the sentence Whalidoes John seek ei .,2, which is viewed as a transfornrationof John seeks what?.
This is an example of left move-ment, since the word "what" has been moved to theleft.
Examples of right movement are rare in English,but frequent in other languages, the prime exarnple be-ing German subordinate clauses.The particular unification grammar used keepstrack of moved phrases by employing gap threading,i.e.
by passing around a list of moved phrases to ensurethat an empty production is only applicable if thereis a moved phrase elsewhere in the sentence to licenseits use, see \[6\] pp.
125--129.
As LR parsing is a pars-lug strategy employing bottom-up rule prediction, it isnecessary to limit the applicability of these empty pro-ductions by the use of top-down filtering.4 PARSER DES IGNThe parser was implemented and tested in SICStus Pro-log using a version of the SRI Core Language Engine(CLE) \[2\] adapted to the air4ravel information-service(NFIS) domain for a spoken-language translation task\[8\].
The CLE ordinarily employs a shift-reduce parserwhere each rule is tried in turn, although filtering us-ing precompiled parsing tables makes it acceptably fast.The ATIS domain is a common ARPA testbench, attdthe CLE performance on it is comparable to that ofother systems.In fact, two slightly ditferent versions of tile parserwere constructed, one for the original grammar, em-ploying a mechanism for gap handling, as described inSection 4.2, and one for the learned grammar, whereno such mechanism is needed, since this grammar lacksempty productions, l~xperirnents were carried out ow~rcorpora of 100-200 test sentences, using SLI{ parsingtables, to measure the impact on parser performance ofthe various modifications described below.A depth-first, backtracking LI/.
parser was used werethe parsing is split into three phases:1.
Phase one is the LI{ parsing phase.
The grammarused here is the generalized unification grammardescribed in Section 4.1 below.
The output is aparse tree indicating how tile rules were applied tothe input word string and what constraints wereassociated with eaelt word.2.
Phase two applies the full constraints of the syn-tactic rules of the unification grammar and lexiconto the output parse tree of phase one.3.
Phase three applies the constraints of the compo-sitional semantic rules of the grammar.For tile learned grarmnar, phase two and three coin-cide, since tile learned rules include coml)ositional se-mantic constraints.
Each rule referred to in the outputparse tree of phase one may be a generalization overseveral ditDrent rules of tit(; unification grammar.
Like-wise, the constraints associated with each word can bea generalization over several distinct lexicon entries.
Inphase two, these difli~rent ways of applying the full con-straints of the syntactic rules and the lexicon, and withthe learned grammar also tile compositional semanticconstraints, are attempted non-deterministically.The lookahead symbols, on the other hand, areground Prolog terms.
Firstly, this means that theycan be computed e\[llciently in the LAI,I{.
case.
Sec-ondly, this avoids trivial reduction ambignities where aparticular reduction is performed once for each possi-ble ruapping of the next word to a lookahead symbol.This is done by producing the set of all possible looka-head symbols \['or the next word at once, rather thanproducing one at a time non-deterministieally.
Eachreduction is associated with another set of lookaheadsymbols.
The intersection is taken, and the result ispassed on to the next parsing cycle.Prefix merging means theft rules starting with sim-ilar phrases are processed together until they branchaway.
q'he problem with this in conjunction with aunification gramrnar is that it is not clear what "simi-lar phrase" means.
The choice made here is to regardphrases that rnap to tile same CF symbol as similar:Def in i t ion:  Two phrases are similar if theymap to the same conic*t-free symbol.Since the processing is performed by applying colt-straints incrementally and monotonically, where con-straints are realized as Prolog terms and these are ill-stantiated stepwise, it is important hat a UG phrasemap to tile same CF symbol regardless of its degree ofinstantiation l'or this delinition to be useful.
The map-ping of t ic  phrases to CF symbols used in the experi-ments was the naive one, where UG phrases mapl)ed totheir syntactic ategories, (i.e.
Prolog terms mapped totheir \['unctors), save that vert)s with different comple-ments (intransitive, transitive, etc.)
were distinguished.4.1 G,mera l i zat ionThe grammar used in phase one is not a eontexl.-fl'eebackbone grammar, nor the original unification gram-mar.
Instead a generalized unification grammar is em-ployed.
This generalization is accomplish using anti-unification.
Tiffs is the dual of uniIication it con-structs tim least general term that subsumes two giwmterms --- and was first described in \[7\].
This operation isoften refe.rred to as generalization i the computational-linguistics literature.
If 7' is the anti-unification of Ttand 7), then 7' subsumes Tl and 5" subsumes 5".,, andif any other terrn 7" subsumes both of 7'1 and 5/~, thenT' snbsunqes 7'.
Anti-uniflcation is a built-in predicateof SICStus Prolog and quite acceptably fast.For each context-free rule, a generalized UG rule isconstructed that is the generalization over all UG rules388that lnltp to that  context-free rule.
If there is onlyone such orightal UG rule, the full constraints of thennification grammar are applied already ill phase one.Siwilarly, the symbols of the action and gore tablesare not context-free symbols.
Tliey are the general-izations of all relevant similar UG phrases.
For exam-pie, each entry in the goto table will have as a sym-bol the generalization of a set of UG phrases.
TheseUG phrases are those that map to the same context-free symbol; occur in a UG rule that corresponds toan item where this CF symlml immedhttely follows theclot; and ill such a UC, rule occur at tile position im-mediately following tile clot.
For example, tile synibolof the gore (or shift) entry for verbs between State 1and State 6 of Fig.
2 is the anti-unification of tim RIISverbs of tile UG rules inapping to lhlles 2, 3 and 4, e.g.vp: \[agr=Agr\] => \[v : \[agr=Agr,sub=intran\] \ ] .vp : \ [agr=Agr\ ]  => \[v : \ [agr=/ lgr ,  sub=?ran\[ ,np : \ [agr= \] \ ] .vp: \[agr=Jtgr\] =>\[v : \ [agr=Agr ,  sub=di t ran \ ] ,  np : l as t= \] , np : \ [agr= \] \ ] .which is v: \[agr=_,sub= \].
llere the vahle of the sub-categorization feature sub is left unspecilied.l,exical arnbignity iii the input sentence is handledin the same wliy.
For each word, a generalized phrase isconstructed from all similar phrases it can lie analyzedas.
Again, if there is no lexical ambiguity within the CFsymbol, the fllll UO constraints are apl)lied.
Nothing isdone about lexical an-lbignities outside of the sltnie CFsymbol, though.In the experiments, using the UG constraints, in-stead of their generalizations, for tile LR-parsing phaseled to an increase in median normalized parsing tinie lfrom a.1 to 3.8, i.e.
by 20 %.
This wits also typi-Gaily tile case for the individual parsing times.
In themachine-learning experiments, where normally severalUG rules mapped to the same CF rule, this effect wasmore marked; it led to an increase hi parsing time by afactor of fiw.
'.On tile other hand, using truly context-free sylnbolsfor I, II.
parsing actually leads to non-ternqhiation due tothe empty productions.
Even when banning einpty pro-ductions, the parsing times increase, by orders of lilag~-nitude; tim vast majority (86 %) of the.
test sentenceswere timed out after ten minutes and still the nornial-ized parsing time exceeded 100 hi more than half (,54%) of the cases.
This shouhl be compared with the0,220 tigure using generalized UG eonstraiuts.
Ill themaehine-learnlng experiments, this lead to an increasein processhig time by ~ factor 100.4.2 Gap hand l ingA technique for l imit ing the applicability of enll)ty pro-due?ions is eniployed in the version for tile originalgr~ulllnar.
It is only correct for left lnoveFltellt.
~illoethere are no empty productions in the learned gram-mar, there is no need for gap handling here.The idea is that in order for an empty production tobe applicable, some grammar ule must have placed a'rite parsing time for the Lit parser divided by the parsingtime for the original )arser.phrase corresponding to tile inow;d one on the gap list.
'\['htls a ga 1) list is maintained where phrases corresl)ond-ins to ltotenti~d left uloventent are added whenever ~lstate is visited where there is a "gap-adding phrase" im-n-lediately following the dot in any item.
The elementsof the gap list ar0 tile corresponding CF symbols.
Atthis point the stack is "back-checked", asdefined below,to see if the gap-adding rule really is applicalde.Ilack-cl/ecking ineans matching the prefixes of thekernel itelns agldnst ile stack in each state.
The.
ratio-nale for this is twofohl.
Firstly, capturing constraintson phrases previously obscured by grainmar ules thathave now brancl,ed off.
Secondly, cal)tur}ng featureagreement between phrases lit prefixes of greater lengththan one.
In general this was not useful; it simply re-suited in a small overhead.
Ill conjunction with gaphandlhlg, however, it proved essential.The gap list is enlptled after al~plying ~ui einpty pro-duction.
This is not correct if several phrases are mow;dusing the same gap list, or for conjunctions where tilegall threading is shared between thecoitiuncts.
For therefiner reasoli two different gap lists are employed()lie for (auxiliary) verbs and erie for lnaXillrlal l:,rojec-tions such as Nl's, PPs, Adjl 's a.lid AdvPs.Ill the experhnents, on\[it?ins the gal)-handlhlg pro-oedure led to non-tern-ihiatlon; even just olnitthig theback-checking did so.
Ily reinovhlg enipty produc-tions all together, the parshig tinies decreased all Ofder of nl,%gnitude.
; tile lnedian normalized parsing tinledropped to 0.270.
Thls reduced tile number of analysesof some selitences, and n\],%lly seato\[ices f~dled to parseat all.
New~rtheless, this indicates that these rules liaw~a strollS, adverse effect ell parser performallce,5 COMPILER DES IGNWe turn now to the design of the compiler that con-structs tile parshlg tables for tile gralnmar.
All, houghthe conlpilal, ion step involves a fair alnonnt of pro- andImStl)rocessing, tile latter two consist (if rather Illlilltel'-esting ltlenial tasks.The llarsilig, t;dlles are constrllcted ilslng thecont, ext-free backbolle l~ralllllial', liul, also here thereis Ol)llorl,unity for interleaving with the full U(-', ('Oll-strahlts.
The clomlre oller~d, ion w.r.t, the non-kernelitchiS is characteristic for the method.The first point is viewing the closure operation asoperal.htg oi1 sots.
(Jonsider the closltrel3 predicateof Fig.
3. u Froin ~ui item already hi the set, a setof non-kernel iteins is generated and its union with theoriginal set is taken.
The.
truly new items are added totiu; agenda driving tile process.The second point is nutl, ehhtg the correspondhlgphrases of the unification grammar when predictingnon-kernel items.
This is done by the call to the predi-cate check ug ru les /4  of Fig.
3, and ensures that the2 \[ ain hldebted to Mats  C&rlssOli for this sc'lielill.'.
All eMcleiitilnl)lelnellt&tlol/of the \])l'illiii01v{!
sl.
'LoperD.tlons Sllch its illllOll ;llldilltel'sectloll isprovided by \[.he Ol'?lt!l'ed-.set-illaniliillli?1Oll packageof the SICStus library.
These ln'hnitiw:s presuppose that the sets;ire represented its el'tiered lists D.Iltl COIISlSt Of grotlnd tel'illS.389c losure(Set ,C losure)  : -c losure(Set ,Set ,C losure) .closure(\[\], Closure, Closure).closure(\[ItemlItems\], SetO, Closure) :-findall(Nkltem,n k_item(Item,NkItem),RkItems),union(SetO,Nkltems,Setl,NewItems),merge(NewItems,Items,ltemsl),closure(Itemsl,Setl,Closure).n_k_ i t  em ( i t  em(Rule l ,_ ,  RHS0,RItS),i tem(Rule2,  LHS2, RHS2 ,RIIS2) ) : -gllS = \[LHS2I_\],cf  ru le  (Rule2, LIIS2, RtlS2),check_ug_rules (Rule 1, Rule2 ,RHS0 ,RHS).Figure 3: The non-kernel closnre flmctionphrase immediately following the "(lot" in some UCIrule mapping to Rulol  unifies with the LIIS of some UGrule mapping to Rule2.
In i t  em(Ruqe, LHS, RltS0, RIts),Ru le  is an atomic rule identifier and RltS0 and RHS forma difference list marking the position of the (lot.This is a compromise between performing the clo-sure operation with full UG constraints and perform-ing it efficiently, and achieves the same net effect as themethod in Section 3 advocated by Nakazawa.
Espe-cially in the machine-learning application, where ratherlarge grammars are used, compiler performance is amost critical issue.In the experiments, omitting the checking of UGrules when performing the closure operation leads tonon-termination when parsing.
This is because theback-checking table for the gap handler becomes toogeneral.
For the learned grammar, this made construct-ing the internal states prohibitively time-consuming.6 SUMMARYThe design of the Lit.
parser and compiler is based ol,interleaving context-free processing with applying thefull constraints of the unification grammar.Using a context-free description-level has the ad-vantages of providing a criterion for similarity betweenUG phrases, allowing efficient processing both at com-pile time and runtime, and providing a basis for prob-M>ilistic analysis.
The former makes prefix merging,which is tim very core of LR parsing, well-defined forunification grammars, and enables using a generalizedunification grammar in the Ll{ parsing phase, which isone of the major innovations of the scheme.
This andprefix merging are vital when working with the learnedgrammar since many rules overlap totally or partiallyon the context-free l vel.Interleaving context-free processing with applyingthe fidl constraints of the unitlcation grammar to prunethe search space restores ome of the predictive powerlost using a context-free backbone grammar.
In par-ticular, using the full U(~ constraints "inside" the non-kernel closure operation to achieve the effect of usingthe unification grammar itself for performing this oper-ation constitutes another important innow~tlon.The experiments emphasize the importance of re-stricting the applicability of emI)ty productions throughthe use of top-down filtering.
Thus the main remain-ing issue is to improve the gap handliIlg nm(;hanisrn tol)erform real gap threading.ACKNOWLEDGEMENTSI wish to thank Mats Carlsson for wduabh."
advice onProlog implementation issues and Ivan I\]retan, RobertMoore and Manny I{ayner for clear-sighted commentson draft versions of this article and related publications,and for useful suggestions to improvements.References\[1\] Aho, Alfred V., Ra.vi Sethi and .leffrey D. Ulhnan(1986).
Compiler.s, l'rineiples, Techniques and Tools,Addlso n- Wesley.\[2\] Alshawl, lliyan editor (1992).
77++: Core Lan~luage l'SJ-ginc, MIT Press.\[3\] Briscoe, Ted, and John Carroll (1993).
"GenerldizedProbabilistic LR Parsing of Nattmd Language (Cor-pora) with lJnifiea.tion-Hased C, rgltllnltrs", Computa-tionalLin.q~dslies 19 1, pp.
25 59, 1993.\[4\] Knnth, l)onatd l".
(1965).
"On the translation of la.n-guages from left to fight.
", h~formation aud Conhvl 86, pp.
607 (;:19.\[5\] Nakaza.wa, Tsuneko (19'.)1).
"An I"xtended LR Parsing.Algorithm for Qrammltrs \[Jsing l;'eltture-l~ased Syntac-tic Categories", EA (.
'L 91, pp.
69 -74.\[6\] Pereira, l?ernando C. N., and Stuart M. Shieber (1987).Prolog a,M Natural Language Analgsis, CSLI Le(:tureNote 1O.\[7\] Plotkht, (;ordon 1).
(1970).
"A Note on Inductive (1en-eralization", Machi~w lntelllg+mee 5, pp.
153-163.\[8\] Rayner, M., I1.
Alshawi, I. Bretan, 1).
C+trter, V. I)i-ggdakis, B.
(laml)il.ck, .I.
I(a..ia, .I.
I(arlgren, It.
l,yberg,P.
Price, ,q. Puhnan and (;.
Samuelsson (1993).
"A.qpeeeh to Speech Translation System Fh,ilt l"rom ~tan-dam Coml)onents" , I'roes.
A RI'A workshop on IlumanLanguage 7}ehnologg.\[9\] $a,nuelsson, Christer (199a).
"Avoiding Non-termina-tion in Unification (',ramm~trs", NLULP 98, pp.
4--16.\[i0\] Samuelsson, Christer, and Manny Ibt.y,,er (1991).
"Quantitative Evahmtion of \]'~xphulation-Based L arll-ing its itll Optimization Tool for a I+a)'ge-Seale Naturall+angu,'tge System", IJCAI 91, pp.
609-615.\[11\] Shieber, Stuart M. (1985).
"Using Restrictions to Ex-tend Parsing Algorithms for Complex-l?e;tture-lbtsedFormalisms", ACL 85, pp.
145 152.\[12\] To,nita, M~ttsurn (I986).
EJfieicnt l'a,'si),g of Natu-ral Lauguage.
A Fast Algorithm.\[or l))'aetical Sgstem.%Khtwer.390
