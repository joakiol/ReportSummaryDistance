Proceedings of the 2009 Workshop on Graph-based Methods for Natural Language Processing, ACL-IJCNLP 2009, pages 1?4,Suntec, Singapore, 7 August 2009.c?2009 ACL and AFNLPSocial (distributed) language modeling, clustering and dialectometryDavid EllisFacebookPalo Alto, CAdellis@facebook.comAbstractWe present ongoing work in a scalable,distributed implementation of over 200million individual language models, eachcapturing a single user?s dialect in a givenlanguage (multilingual users have severalmodels).
These have a variety of prac-tical applications, ranging from spam de-tection to speech recognition, and dialec-tometrical methods on the social graph.Users should be able to view any contentin their language (even if it is spoken bya small population), and to browse our sitewith appropriately translated interface (au-tomatically generated, for locales with lit-tle crowd-sourced community effort).1 IntroductionWe approach several key questions from a data-driven (statistical) perspective, drawing on large,dynamic annotated corpora:1.
What social factors affect language change(and evolution)?
How?2.
How do individuals adjust their speech orwriting depending on context and audience?
(e.g., register, formality, humor, reference)3.
What are the minimum requirements for alanguage (or dialect)?
(e.g., number of speakers, corpus size)4.
Is a common language necessary for commu-nication?Can a pidgin be predicted from its speaker-population?To this end, we describe a framework for lan-guage modeling on the social graph, which incor-porates similarity clustering and lays the ground-work for personalized (and multimodal) machinetranslation.2 Related WorkResearch on large scale language model-ing (Brants et al, 2007) has addressed sharding,smoothing and integration with a machine transla-tion pipeline.
Our work takes a similar approach,using Hadoop (Borthakur, 2007) and Hive toquery and process distributed data.
Social annota-tions enhanced smoothing for language modelingin the context of information retrieval (Xu etal., 2007), and hierarchical Bayesian networkswere used (Zhou et al, 2008) to incorporate userdomain interest in such models.
Language modelsare often used to detect spam, including in socialbookmarking (Bogers and van den Bosch, 2008).Proposed scoring models for socialsearch (Schenkel et al, 2008) use friendshipstrengths and an extension of term frequency1.These could benefit from a deeper integration withfriends?
language models, perhaps to approximatea user-specific inverse document frequency, ratherthan treat each tag by a user as equally relevant toall his friends of a given (relationship) strength.Strehl et al (2000) found that similarity clusteringperform best using weighted graph partitioning.3 Language ModelAn individual?s language model is a mixture oftheir locale (or another language they speak) andtoken frequencies from the content they produce(write) and consume (read).
Since we have hun-dreds of milliions of users, each of whose lan-guage model can depend on a variety of datasources, it is essential to distribute these counts(and other figures derived from them) in a way thatoptimizes the efficiency of our access patterns2.We also tried clustering users, and represent-ing the language of each as deviations from itsneighbors (or the norm of the cluster).
However,1Called ?socially-enhanced tag frequency?.2See Section 5 for discussion of a variety of use cases.1there are significantly more edges than nodes inour graph (more friendships than people), so thisalternative is less efficient.An individual?s language use varies greatly de-pending on his interlocutor or audience3.
Mes-sages I send (privately) to a friend differ in stylefrom comments I make on a public photo of mynephew, which in turn differ from my writing styleas realized in an academic or industry paper or ar-ticle.An obvious optimization is to describe a min-imum spanning tree (MST) on the graph, whereeach edge is weighted according to the similarityof dialects associated with the nodes (individuals,groups or other entities) it connects.
Then, lan-guage models of nodes connected by the MST candepend on each other?s counts.
Singletons defaultto the general language model from their locale.3.1 Detecting DeviationsPeople who aren?t friends (and have no mutualfriends or other evident connection) may yet usemore similar language than siblings.
This exam-ple seems highly improbable or unnatural, and infact serves as a good heuristic for detecting com-promised, spam-sending accounts (even if not or-ganized in a botnet).If a user sends a message with high perplexity:1.
Their account is compromised, and beingused to spam (or phish) their friends.2.
They are using a different language thanusual.
Users are often bilingual (sometimesmulti)-, so we may not yet have realized theyare proficient in a given language.3.
There may be a problem with the languagemodel:(a) large vocabulary (tends to inflate per-plexity)(b) genre mix (user interface v. user com-munication)3.2 Locale InductionA regional cluster of personal language modelscan be combined to create a new locale.
A crowd-sourced translation process (Ellis, 2009) can thus3This is not novel in or of itself, but the scale of our dataand experiments should lead to finer-grained understanding,both of issues peculiar to a single language or its family, andof language universals (or.patterns; priors likely intuitivelyencoded).be bootstrapped by indirect community contribu-tions.4 Machine TranslationFor an English-sepaking user, in order to opti-mize the probability of the target (translated) sen-tence given its source (Foreign), we follow Ochand Ney?s (2004) optimization of a set of featurefunctions:?e = argmaxeM?m=1?mhm(e,f)It is thus easy for us to aggregate scores frommultiple language models (e.g., from individualscomprising your network of friends or others youinteract with).Our distributed, individual language models canbe a component of personalized machine transla-tion, where the target language may be a penpal?s.Either the decoder incorporates the counts fromuser communications by supplementing the lan-guage model used in its n-best candidate search,or it uses the locale?s general language model andfactors in individual variance in a rescoring step.We plan to offer inline statistical machine trans-lation (SMT) of user-generated content, where thetranslation model combines features from:1.
Our (interface) translations corpus for thelanguage pair2.
Related langauges or dialects43.
Linguistic rules (Ellis, 2009), in some com-bination of:(a) Explicitly encoded(b) Induced from training corpora(c) Borrowed from related languages (esp.for relatively minor or resource-poor)4.1 Sparse DataData sparseness is clearly an issue for modelingwith this degree of specificity, so we explore arange of possible smoothing techniques, as wellas methods for leveraging resources from relatedlanguages (Genzel, 2005).
If a user signed up forFacebook last week, (s)he may not yet have con-nected with many friends or shared much content(which exacerbates the problem).4e.g.
Spanish (Argentina, Spain), Chinese (Mandarin,Cantonese (Hong Kong, Taiwan)), or Finnish and its neigh-bors: inc. Estonian, S?ami, Komi2Domain adaptation is also important, since thebase corpus is for a user interface: usually moreformal, less varied than conversation.
Ideally, wewould like to capture not only language change(diversion, creolization) but an individual?s lin-guistic evolution in a variety of contexts:?
She learns a language, practices its use, be-comes increasingly accustomed to its twistsand turns (syntactic, lexical, morphological,etc.)?
His mood shifts, he moves into a new apart-ment or city, let alne grander (potentiallydynamic) features of context?
A startup company is suddently more visible(e.g., resulting from press coverage, or a techblogger?s reference), and so an image (andwebsite design, copy) revamp is in order.?
Afflicted with post-traumatic stress, aftersensory deprivation, or in cases of neurologi-cal disorders or brain damage.5 SimilarityWe use a pipeline to cluster strings (to suggesttranslations) and users (based on language use):1.
Preprocessing?
normalization (lowercasing)?
{segment,{lemmat,token}iz}ation2.
Similarity (pick one)?
fuzzy (hash) similarity5?
string edit distance?
phonetic (or phonological) edit distance?
language model perplexity?
KL-divergence (btn.
language models)3.
Clustering (modular: select-an-algo)?
hierarchical (agglomerative or divisive)?
K-means (partitioning)?
graph-theoretic methods (cover as op-posed to cluster)This is architected for ease of experimentationand modification, testing and tuning, so any com-bination of the above should be functional.
Someapplications of similarity require high accuracybut can be processed offline, whereas others needto be computed in less than ten milliseconds in re-sponse to a live query.5i.e., Jaccard coefficient (Wikipedia, 2008)Figure 1: Visualization of a user?s friends, wherethe extent of each type of relationship or commu-nication is indicated by saturation (shade of blue)of the connection.6 EvaluationAlthough the components we use can be (and inmost cases, have been) thoroughly evaluated inrelative isolation, it is important to understand theconsequences of their use in concert.
Improve-ments to spam detection should be evident both intests on annotated6data and in decreased reportsor complaints from users.User-generated metadata, in some cases a sim-ple report of offensive content or a friend?s com-promised account, is a natural source of both la-beled test data and training data.
Our customerservice processes are thus tightly integrated withmachine learning efforts.
See Figure 1 for commu-nications in a small segment of the social graph.7 ConclusionPreliminary experiments with user-initiated ma-chine translation of friend-generated content sug-gest it will soon be valuable.
It is crucial to designthis in a scalable way, such that it extends to arbi-trarily many languages7, both draws on and sup-6Either a binary classification (spam or non-spam) or agradient scale, possibly incorporating dimensions of phishi-ness, spamminess, or other types of solicitousness.7Including underrepresented ones like Oshindonga.3ports our internationalization efforts, and shouldbe useful on mobile devices (including in the spo-ken modality).Our introductory questions (from Section 1) arefar from fully answered, but we hope this workmight help to address them.1.
The number and strength of connections,speed and frequency of communication, anddiversity of languages individuals are ex-posed to all have strong influences on lan-guage change.2.
Stylistic variations in an individual?s lan-guage are evident in that it can be more accu-rately captured as a mixture of models, eachof which is suited to a specific situation, style,or set of interlocutors.3.
Two speakers is sufficient for a language.
Asmall model can adequately describe a lan-guage, if each data point is a deviation fromanother language.4.
A common language is far from necessary forcommunication8.
A set of arbitrary individu-als?
language models can be combined (andpruned, evolved) to derive the pidgin theymight speak.7.1 Future WorkSocial natural language processing is (in a sense)in its infancy.
We hope to capture aspects of itsevolution, just as the field comes to better describeand understand ongoing changes in human lan-guages.
We have not yet satisfactorily answeredour second question, but expect more fine-grainedanalyses to follow, using our framework to com-pare and contrast a variety of languages (fromBantu to Balinese) and phenomena (inside jokes,cross-linguistic usage of l33t and txt msg terms).We hope to facilitate this by providing an APIto allow researchers access to anonymized9, ag-gregated data.AcknowledgmentsThis technology is developed with support fromi18n team (engineers, language managers and oth-ers) at Facebook, and all our international users.8Photos, emoticons and tone of voice (for example) goa long way.
We hope personalized (including speech-to-speech) translation will continue to bridge the language di-vide.9Also honoring users?
privacy settings.Thanks to our data scientists for the visualizationof a user?s friends, and the extent of communica-tion connecting them.ReferencesToine Bogers and Antal van den Bosch.
2008.
Usinglanguage models for spam detection in social book-marking.
In Proceedings of the ECML/PKDD Dis-covery Challenge.Dhruba Borthakur, 2007.
The Hadoop Distributed FileSystem: Architecture and Design.
The Apache Soft-ware Foundation.Thorsten Brants, Ashok C. Popat, Peng Xu, Franz J.Och, and Jeffrey Dean.
2007.
Large languagemodels in machine translation.
In Proceedingsof the 2007 Joint Conference on Empirical Meth-ods in Natural Language Processing and Com-putational Natural Language Learning (EMNLP-CoNLL), pages 858?867.David Ellis.
2009.
A case study in community-driven translation of a fast-changing website.
InProceedings of the 13th International Conference onHuman-Computer Interaction HCII (to appear), SanDiego, California, USA.Dmitriy Genzel.
2005.
Creating Algorithms forParsers and Taggers for Resource-Poor LanguagesUsing a Related Resource-Rich Language.
Ph.D.thesis, Brown University.Franz Josef Och and Hermann Ney.
2004.
The align-ment template approach to statistical machine trans-lation.
Comput.
Linguist., 30(4):417?449.Ralf Schenkel, Tom Crecelius, Mouna Kacimi, ThomasNeumann, Josiane Parreira, Marc Spaniol, and Ger-hard Weikum.
2008.
Social wisdom for search andrecommendation, June.Er Strehl, Joydeep Ghosh, and Raymond Mooney.2000.
Impact of similarity measures on web-pageclustering.
In In Workshop on Artificial Intelligencefor Web Search (AAAI 2000, pages 58?64.
AAAI.Wikipedia.
2008.
Jaccard?s similarity coefficient.Shengliang Xu, Shenghua Bao, Yunbo Cao, and YongYu.
2007.
Using social annotations to improve lan-guage model for information retrieval.
In Proceed-ings of the sixteenth ACM conference on Conferenceon information and knowledge management, pages1003?1006.
CIKM.Ding Zhou, Jiang Bian, Shuyi Zheng, Hongyuan Zha,and Lee C. Giles.
2008.
Exploring social an-notations for information retrieval.
In WWW ?08:Proceeding of the 17th international conference onWorld Wide Web, pages 715?724, New York, NY,USA.
ACM.4
