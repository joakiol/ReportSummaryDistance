Proceedings of the SIGDIAL 2014 Conference, pages 327?331,Philadelphia, U.S.A., 18-20 June 2014.c?2014 Association for Computational LinguisticsMarkovian Discriminative Modeling for Dialog State TrackingHang Ren, Weiqun Xu, Yonghong YanThe Key Laboratory of Speech Acoustics and Content UnderstandingInstitute of Acoustics, Chinese Academy of Sciences21 North 4th Ring West Road, Beijing, China, 100190{renhang, xuweiqun, yanyonghong}@hccl.ioa.ac.cnAbstractDiscriminative dialog state tracking hasbecome a hot topic in dialog research com-munity recently.
Compared to genera-tive approach, it has the advantage of be-ing able to handle arbitrary dependent fea-tures, which is very appealing.
In thispaper, we present our approach to theDSTC2 challenge.
We propose to use dis-criminative Markovian models as a natu-ral enhancement to the stationary discrim-inative models.
The Markovian structureallows the incorporation of ?transitional?features, which can lead to more effi-ciency and flexibility in tracking user goalchanges.
Results on the DSTC2 datasetshow considerable improvements over thebaseline, and the effects of the Markoviandependency is tested empirically.1 IntroductionSpoken dialog systems (SDS) have become muchmore popular these days, but still far from wideadoption.
One of the most outstanding problemsthat affect user experience in an SDS is due toautomatic speech recognition (ASR) and spokenlanguage understanding (SLU) errors.
While theadvancement of ASR technology has a positive ef-fect on SDS, it is possible to improve the SDS userexperience by designing a module which explicitlyhandles ASR and SLU errors.
With accurately es-timated dialog state, the dialog manager could se-lect more effective and flexible dialog actions, re-sulting in shorter dialogs and higher dialog successrate.
Dialog state tracking is the task of identifyingthe correct dialog state (user action, user goal, etc.
)from ASR and SLU outputs in the presence of er-rors.
Commercial dialog systems these days usu-ally use simple dialog state tracking strategies thatonly consider the most probable SLU output.
Pre-vious research shows that several errors in dialogstate tracking can be rectified by considering thefull N-best results from the ASR and SLU compo-nents (Williams, 2012).
Thus it is very importantto develop robust and practical dialog state track-ing models.In statistical dialog state tracking, modelscan be roughly divided into two major classes,i.e.
generative and discriminative.
Generative(Bayesian) dialog tracking models are prevalentin early studies due to its close relationship withthe POMDP dialog management model (Young etal., 2013).
Generative models generally use Dy-namic Bayesian Networks to model the observa-tion probability P (Ot|St) and transition probabil-ity P (St|St?1), where Otand Stare observationsand dialog state at turn t. In a discriminativemodel, the conditional probability P (St|Ot1) ismodeled directly, where Ot1is all the observationsfrom turn 1 to t. One problem with the generativemodels is that the independent assumptions are al-ways not realistic.
For example, N-best hypothe-ses are often assumed independent of each other,which is flawed in realistic scenarios (Williams,2012).
Furthermore, it is intrinsically difficult forgenerative models to handle overlapping features,which prevents model designers from incorporat-ing arbitrarily large feature set.
Discriminativemodel does not suffer from the above problems asthere is no need to make any assumptions aboutthe probabilistic dependencies of the features.
Asa result.
it is potentially able to handle much largerfeature sets and to make more accurate predic-tions (Bohus and Rudnicky, 2006).
Discrimina-tive models also tend to be more data-driven, un-like generative models in which many sub-modelsparameters are heuristically tuned.2 DSTC1 revisitedThe first Dialog State Tracking Challenge(DSTC1) for the first time provided a commontest bed for various state tracking methods, and327several participants employed various discrimi-native models in the challenge.
DSTC1 providedreal user dialog corpora in the domain of busroute service to evaluate performance of variousstate tracking methods.
In DSTC1 there are 9teams with 27 submissions, where discriminative,generative and rule-based models are used in thechallenge.
Maximum entropy models (Lee andEskenazi, 2013), conditional random fields (Lee,2013) and neural networks (Henderson et al.,2013) are the most frequently used discriminativemodels, which gave competitive results on severalmetrics.
It has been empirically analyzed that dis-criminative methods are especially advantageouswhen the ASR/SLU confidence scores are poorlyestimated (Williams et al., 2013).3 Discriminative modeling in dialog statetrackingIn the design of a slot-filling or task-oriented di-alog systems, dialog state tracking can be consid-ered as a classification problem, i.e.
assigning pre-defined values to a fixed number of slots.
Onemajor problem in the formulation is that in com-plex dialog scenarios the number of classes tendsto be very big, resulting in extremely sparse train-ing instances for each class.
This sparsity affectsthe classification performance.
A large predic-tion domain also leads to computation inefficiencywhich makes the model less practical.
Usually wecould focus only on the on-list hypotheses, whichare the hypotheses appeared in the SLU results,and all the other values in the slot value set aregrouped into a meta category Other.
It is simi-lar to the partition concept in HIS (Young et al.,2010), and by doing this we could reduce the num-ber of classes to a reasonable size.
We use Yttodenote the prediction domain at turn t. Althoughthe number of classes is reduced by focusing onthe dynamically generated Yt, some classes willstill suffer from the lack of training instances, andwhat is even worse is that a large portion of theclasses will not have any training data, since inpractical SDS deployment it is hard to collect alarge dialog corpus.
To handle the data sparsenessproblem, parameters are often shared across dif-ferent slots, or even data sets, and by doing this themodel complexity could be effectively controlledand the overfitting problem would be alleviated.Williams proposed to use various techniques frommulti-domain learning to improve model perfor-Monday: 0.5Thursday: 0.2Other: 0.3Monday: 0.7Tuesday: 0.1Thursday: 0.1Other: 0.1Observationsfrom turn 1 to tTurn t-1 Turn tFigure 1: Markovian discriminative model depen-dency diagram.
In this figure the dialog state issimplified to a single slot variable: date, the do-main of the slot typically increases as dialog con-tinues, which includes all the slot values appearedas SLU results.
As indicated by the arrows, Stdepends on St?1and Ot1.
In stationary discrimi-native model, there?s no dependency between ad-jacent turns indicated by the upper arrow.mance (Williams, 2013), which could be taken asanother way of parameter sharing.3.1 Markovian discriminative modelA dialog can be naturally seen as a temporal se-quence involving a user and an agent, where strongdependencies exist between adjacent turns.
In typ-ical task-oriented dialogs, users often change theirgoals when their original object cannot be satis-fied.
Even when the true user goal stays constantin a dialog session, the agent?s perception of it willtend to evolve and be more accurate as the con-versation proceeds, and thus the dialog state willoften change.
The states at adjacent turns are sta-tistically correlated, and therefore it is importantto leverage this natural temporal relationship intracking dialog state.
We enhance the stationarydiscriminative model in a similar way as describedin (McCallum et al., 2000), by assuming Marko-vian dependency between adjacent turns.Thus, the original probability P (St|Ot1) can befactored into the following form:P (St|Ot1) = (1)?St?1?SP (St|Ot1, St?1)P (St?1|Ot?11)The graphical model is shown is figure1.
Unlike stationary discriminative models,328we model the conditional transition probabilityP (St|Ot1, St?1) instead of P (St|Ot1) and the dia-log state is updated according to equation 1 at eachturn.
The feature functions in the structured modelcan depend on the state of the previous turn, whichwe call transitional features.It is worth noting that stationary discriminativemodel can include features built from dialog his-tory (Metallinou et al., 2013).
The major dif-ference in utilizing this information from our ap-proach is that by explicitly assuming the Marko-vian dependency, the structured model is able toexploit the whole probabilistic dialog state distri-bution of the previous turn.
The previous dialogstate St?1is inferred from previous dialog historyOt?11, which contains higher level hypotheses thanthe raw history features.
Apart from that, the struc-tured model can also use any stationary featuresbuilt from Ot1, which makes the stationary modela special case of the structured one.3.2 Neural network classifierWe use the family of multi-layer neural net-works to model the transition probabilityP (St|Ot?11, St?1).
To allow for the use of thedynamic prediction domain, we utilize a forwardnetwork structure similar to (Henderson et al.,2013).
Feature vectors for each class in Ytarefed into the model and forwarded through severalhidden layers for non-linear transformation in thehope that deeper layers may form higher abstrac-tion of the raw inputs.
The parameter vectors foreach class are shared.
For each feature vectorthe model generates a real score.
The scores forall the classes in Ytare then normalized using asoftmax function resulting in valid probabilities.yi= Wl?1?
gl?1(.
.
.
g1(W1?Xi) .
.
.)
(2)PY= Softmax(y1, .
.
.
, y|Yt|) (3)where g1to gl?1are sigmoid functions, Wiis theweight matrix for linear transformation at layer iand Xi= f(Ot1, yi) is the feature vector for classi.
We also test maximum entropy models, whichcan be seen as a simple neural network withouthidden layers:P (Y = y|Ot1) =e??f(Ot1,y)?y?Ye?
?f(Ot1,y)(4)4 DSTC2 challengeDSTC2 is the second round of Dialog State Track-ing Challenge, and it provides dialog corporacollected from real human-machine dialogs in arestaurant domain.
The corpora are split into la-beled training and development sets and unlabeledtest set.
Test sets are collected from a SDS dif-ferent from the training and development set toreflect the mismatch in real deployment.
UnlikeDSTC1, the user goal often changes in DSTC2when the condition specified by the user cannotbe met.
For evaluation DSTC2 defined a numberof metrics among which several featured metricsare selected.
Besides tracking user goals (the val-ues of each slot), two additional states method andrequested slots are also defined, which track themethod to query and the slots requested by usersrespectively.
Further details about DSTC2 couldbe found in (Henderson et al., 2014).5 Feature setWe briefly describe the feature set used in our sys-tem.
We only use the live SLU information pro-vided by the organizers, and no extra external datais used.
The features used can be divided into twoclasses.stationary features which only depend on theobservations and the class (slot value) pre-dicted at current turn in the form of f(yt, Ot).transitional features that can also depends onthe predicted class at the previous turn in theform of f(yt, yt?1, Ot).Stationary features include:?
SLU Scores: confidence scores of the currentprediction binned into boolean values, rawscores are also added as real features.?
SLU Status: whether the prediction is denied,informed and confirmed in the current turn.?
Dialog history: whether the prediction hasbeen denied, informed and confirmed in allthe dialog turns until the current one.?
User/system action: The most probable useraction and the machine action in the currentturn.The transitional features are as follows:?
Transition1: whether the predictions in theprevious and the current turn are the same.329Name Model Class Hidden layersEntry1 MEMM ?Entry2 Structured NN [50]Entry3 Structured NN [50, 30]MLP Stationary NN [50, 30]Table 1: Configurations of models.
The modelMLP uses the same structure as Entry3, but with-out the transitional features described in section 5.Number in brackets denotes the number of unitsused in each hidden layers.?
Transition2: joint feature of Transition1 inconjunction with the machine action in cur-rent turn, i.e.
for each machine cation, Tran-sision1 is replicated and only the one corre-sponding to the machine action at current turnis activated.Transitional features are specific to Markovianmodels while stationary features can be used inany discriminative models.6 Model trainingMarkovian models in various forms are tested tofind the most appropriate structure for the task.Models for ?method?
and ?state?
are built sepa-rately using similar structured models.When using the maximum entropy model tobuild the conditional probability, the Markovianmodel is equivalent to the maximum-entropyMarkov model (MEMM) model introduced in(McCallum et al., 2000).
More sophisticated neu-ral networks with different configurations are usedto fit the model to more complex patterns in theinput features.
In tracking the state ?goal?, thejoint distribution of slots is built assuming differ-ent slots are independent of each other.
From theperspective of practical implementation, one ad-vantage of the simpler MEMM model is that thetraining objective is convex.
Thus the optimiza-tion routine is guaranteed to find the global opti-mum, while neural networks with hidden layers al-ways have many local optima which require care-ful initialization of the parameters.
LBFGS (Liuand Nocedal, 1989) is used in optimizing the batchlog-likelihood objective and L1 and L2 regulariz-ers are used to penalize the model from overfitting.We train the model on the training set, the devel-opment set is used for model selection and modelsproduced at each training iteration are evaluated.State Tracker ACC L2 CA05GoalBaseline 0.619 0.738 0.000Entry1 0.707 0.447 0.223Entry2 0.713 0.437 0.207Entry3 0.718 0.461 0.100MLP 0.713 0.448 0.128MethodBaseline 0.875 0.217 0.000Entry1 0.865 0.228 0.199Entry2 0.871 0.211 0.290Entry3 0.871 0.210 0.287MLP 0.946 0.092 0.000RequestedBaseline 0.884 0.196 0.000Entry1 0.932 0.118 0.057Entry2 0.947 0.093 0.218Entry3 0.951 0.085 0.225MLP 0.863 0.231 0.291Table 2: Evaluation results on the DSTC2 test set.ACC stands for accuracy, L2 measures the Eu-clidean distance between the predicted distributionand the ground truth vector with only the correcthypothesis set to 1.
CA05 is the correct accep-tance rate when false acceptance rate is 5%.
De-tails of the metrics can be found in (Henderson etal., 2014).
Except L2, the larger the scores, thebetter the performance.In DSTC2 we submitted 3 trackers, an additionaltracker without the transitional features is trainedafterwards for comparison.
Configurations of themodels are described in table 1.7 Experiments and part of the resultsFeatured metrics on the test set are shown in ta-ble 2.
By most metrics our models are superiorto the simple baseline.
Especially in tracking usergoals which is the most important state to track inDSTC2, the discriminative trackers show consid-erable performance gain.
Judging from the per-formance of Entry1 to Entry3, we can concludethat the more complex 2-layer neural networkshave better performance.
Markovian neural net-works can fit to the training instances with muchmore flexibility than the simple MEMM model.We have also trained a standard multi-layer neuralnetwork (MLP) model by disabling all the transi-tional features.
By comparing the model ?Entry 3?and ?MLP?, which share the same network struc-ture, we explicitly test the effect of the Marko-vian structure.
On the state ?goal?
and ?requested?,the Markovian model shows better tracking accu-330racies, which means that the Markovian structurehas a positive effect on fitting the target.
But intracking the state ?method?, the MLP model hasthe best performance among all the models com-pared.
Thus although the log-likelihood increasesconsiderably on the training set by adding the tran-sitional features, the overfiting to the training set ismore serious in tracking ?method?.8 ConclusionWe described the models used in the DSTC2 chal-lenge.
We proposed a novel approach to enhanc-ing the model capability of stationary discrimina-tive models in dialog state tracking by assumingMarkovian dependencies between adjacent turns.The results showed better performance than thesimple baseline which uses the most probable hy-pothesis, and we empirically compared the mod-els with and without the Markovian dependency.In future work, more discriminative models in dif-ferent forms could be compared to evaluate theircapability, and the effects of the Markovian struc-ture and transitional features needs to be furtherstudied.AcknowledgmentsWe would like to thank the DSTC committee fortheir great efforts in organizing the challenge.
Wealso thank the anonymous reviewers for their con-structive comments.This work is partially supported by the Na-tional Natural Science Foundation of China (Nos.10925419, 90920302, 61072124, 11074275,11161140319, 91120001), the Strategic Prior-ity Research Program of the Chinese Academyof Sciences (Grant Nos.
XDA06030100,XDA06030500), the National 863 Program (No.2012AA012503) and the CAS Priority Deploy-ment Project (No.
KGZD-EW-103-2).ReferencesDan Bohus and Alex Rudnicky.
2006.
A k-hypotheses+ other belief updating model.
In Proc.of the AAAI Workshop on Statistical and EmpiricalMethods in Spoken Dialogue Systems.Matthew Henderson, Blaise Thomson, and SteveYoung.
2013.
Deep neural network approach forthe dialog state tracking challenge.
In Proceedingsof the SIGDIAL 2013 Conference, pages 467?471,Metz, France, August.
Association for Computa-tional Linguistics.Matthew Henderson, Blaise Thomson, and JasonWilliams.
2014.
The second dialog state trackingchallenge.
In Proceedings of the SIGDIAL 2014Conference, Baltimore, U.S.A., June.Sungjin Lee and Maxine Eskenazi.
2013.
Recipe forbuilding robust spoken dialog state trackers: Dialogstate tracking challenge system description.
In Pro-ceedings of the SIGDIAL 2013 Conference, pages414?422, Metz, France, August.
Association forComputational Linguistics.Sungjin Lee.
2013.
Structured discriminative modelfor dialog state tracking.
In Proceedings of theSIGDIAL 2013 Conference, pages 442?451, Metz,France, August.
Association for Computational Lin-guistics.Dong C Liu and Jorge Nocedal.
1989.
On the limitedmemory bfgs method for large scale optimization.Mathematical programming, 45(1-3):503?528.Andrew McCallum, Dayne Freitag, and Fernando C. N.Pereira.
2000.
Maximum entropy markov mod-els for information extraction and segmentation.
InPat Langley, editor, ICML, pages 591?598.
MorganKaufmann.Angeliki Metallinou, Dan Bohus, and Jason Williams.2013.
Discriminative state tracking for spoken di-alog systems.
In Proceedings of the 51st AnnualMeeting of the Association for Computational Lin-guistics, pages 466?475, Sofia, Bulgaria, August.Association for Computational Linguistics.Jason Williams, Antoine Raux, Deepak Ramachan-dran, and Alan Black.
2013.
The dialog state track-ing challenge.
In Proceedings of the SIGDIAL 2013Conference, page 404?413, Metz, France, August.Association for Computational Linguistics.Jason Williams.
2012.
A critical analysis of twostatistical spoken dialog systems in public use.
In2012 IEEE Spoken Language Technology Workshop(SLT), pages 55?60.Jason Williams.
2013.
Multi-domain learning andgeneralization in dialog state tracking.
In Proceed-ings of the SIGDIAL 2013 Conference, pages 433?441, Metz, France, August.
Association for Compu-tational Linguistics.Steve Young, Milica Ga?si?c, Simon Keizer, Franc?oisMairesse, Jost Schatzmann, Blaise Thomson, andKai Yu.
2010.
The hidden information state model:A practical framework for POMDP-based spokendialogue management.
Computer Speech & Lan-guage, 24(2):150?174.Steve Young, Milica Ga?si?c, Blaise Thomson, and Ja-son D Williams.
2013.
Pomdp-based statistical spo-ken dialog systems: A review.
Proceedings of theIEEE, 101(5):1160?1179.331
