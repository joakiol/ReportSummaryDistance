Last WordsWhat Computational Linguists Can Learnfrom Psychologists (and Vice Versa)Emiel Krahmer?Tilburg University1.
IntroductionSometimes I am amazed by how much the field of computational linguistics haschanged in the past 15 to 20 years.
In the mid 1990s, I was working at a research institutewhere language and speech technologists worked in relatively close quarters.
Speechtechnology seemed on the verge of a major breakthrough; this was around the time thatBill Gates was quoted in Business Week as saying that speech was not just the future ofWindows, but the future of computing itself.
At the same time, language technologywas, well, nowhere.
Bill Gates certainly wasn?t championing language technology inthose days.
And while the possible applications of speech technology seemed endless(who would use a keyboard in 2010, when speech-driven user interfaces would have re-placed traditional computers?
), the language people were thinking hard about possibleapplications for their admittedly somewhat immature technologies.Predicting the future is a tricky thing.
No major breakthrough came for speechtechnology?I am still typing this.
However, language technology did change almostbeyond recognition.
Perhaps one of the main reasons for this has been the explosivegrowth of the Internet, which helped language technology in two different ways.
Onthe one hand it instigated the development and refinement of techniques needed forsearching in document collections of unprecedented size, on the other it resulted in alarge increase of freely available text data.
Recently, language technology has been par-ticularly successful for tasks where huge amounts of textual data is available to whichstatistical machine learning techniques can be applied (Halevy, Norvig, and Pereira2009).
As a result of these developments, mainstream computational linguistics is nowa successful, application-oriented discipline which is particularly good at extractinginformation from sequences of words.But there is more to language than that.
For speakers, words are the result of acomplex speech production process; for listeners, they are what starts off the similarlycomplex comprehension process.
However, in many current applications no attention isgiven to the processes by which words are produced nor to the processes by which theycan be understood.
Language is treated as a product not as a process, in the terminologyof Clark (1996).
In addition, we use language not only as a vehicle for factual infor-mation exchange; speakers may realise all sorts of other intentions with their words:They may want to convince others to do or buy something, they may want to inducea particular emotion in the addressee, and so forth.
These days, most of computationallinguistics (with a few notable exceptions, more about which subsequently) has little to?
Tilburg Centre for Creative Computing (TiCC), Communication and Cognition research group, TilburgUniversity, The Netherlands.
E-mail: e.j.krahmer@uvt.nl.?
2010 Association for Computational LinguisticsComputational Linguistics Volume 36, Number 2say about how people produce and comprehend language, nor about what the possibleeffects of language could be.It wasn?t always like this; early work in computational linguistics took a different(and more ambitious) perspective.
Winograd (1980), to give one more or less ran-dom example, explicitly treated language understanding and production as cognitiveprocesses, which interacted with other cognitive modules such as visual perception;Hovy (1990), to give another, presented a computational model that generated differenttexts from the same underlying facts, depending on pragmatic, interpersonal con-straints.
It is interesting to observe thatWinograd andHovy built on both computationaland psychological research, something which is increasingly rare in the field of compu-tational linguistics, a point made convincingly by Reiter (2007).
By now, it is generallyaccepted that the problems that Winograd, Hovy, and others tried to tackle are verycomplex, and that the current emphasis on more well-delimited problems is probablya good thing.
However, it is not difficult to come up with computational applicationsfor which a better understanding would be required of language as a process and theeffects language may have on a user (interactive virtual agents which try to persuade auser to do something, for example).
To learn more about how speakers and addresseesmanage to accurately produce and comprehend complex and potentially ambiguoussentences in real time, and how theymay use these sentences for a whole range of inten-tions, we have to turn to psycholinguistics and social psychology, respectively.
So let ussample some of the recent findings in these fields, and see if and how they might benefitcomputational linguistics.
Interestingly, we will find many places where more attentionto what goes on in computational linguistics would benefit psychologists as well.2.
Language Use and Its Social ImpactSocial psychologists study persons and the relations they have with others andwith groups.
Various social psychologists have concentrated on language (althoughperhaps not as many as you would expect given the importance of language forsocial interactions).
A number of different approaches can be discerned, one of whichconcentrates on the psychological functions of function words (Chung and Pennebaker2007).
Function words are understood here to include pronouns, prepositions, articles,conjunctions, and auxiliary verbs.2.1 On the Psychological Functions of PronounsOne reliable finding of this perspective is that first person singular pronouns are associ-ated with negative affective states.
For example, in one study it was found that currentlydepressed students used I and me more often than students who were not currentlydepressed, and of the latter group those who had known periods of depression usedthem more frequently than those who had never had such an episode (Rude, Gortner,and Pennebaker 2004).
Another study found that suicidal poets used first person sin-gular pronouns in their poems more frequently than non-suicidal poets (Stirman andPennebaker 2001).
Of course, whether a speaker tends to use I or we more frequentlyis also indicative of self- versus other-centeredness.
An analysis of blogs following theevents of September 11 revealed that bloggers?
use of I and me dropped in the hoursfollowing the attack, while simultaneously their use ofwe and us increased (Cohn,Mehl,and Pennebaker 2004); this switch is interpreted by the authors as indicating that people286Krahmer Last Wordswere focusing less on themselves during this period, but instead focusing more on theirfriends and families.
In a completely different study of adult speakers (both male andfemale) who underwent testosterone therapy, it was found that as testosterone levelsdropped, so did their use of I pronouns, while simultaneously the use of non-I pronounsincreased (Pennebaker et al 2004).Pennebaker and colleagues report comparable effects of age, gender, status, and cul-ture on personal pronoun use (Chung and Pennebaker 2007).
Their corpus (or ?archive?,as they call it) contains over 400,000 text files, frommany different authors and collectedover many years.
It is interesting to observe that Pennebaker was an early adapter ofcomputers for his analyses, simply because performing them manually was too time-consuming.
The general approach in these analyses is to determine beforehand whatthe ?interesting?
words are and then simply to count them in the relevant texts, withouttaking the linguistic context into account.
This obviously creates errors: The relativefrequency of first-person pronouns may be indicative of depression, as we have justseen, but a sentence such as I love life seems a somewhat implausible cue for a depressedstate of mind.
Chung and Pennebaker (2007, page 345) themselves give the example ofmad, which is counted as an anger and negative emotion word, and they point out thatthis is wrong for I?m mad about my lover.
Clearly, standard methods from computationallinguistics could be used to address this problem, for instance by looking at words incontext and n-grams.
Another problem which Chung and Pennebaker mention, andwhich will be familiar to many computational linguists, is the problem of decidingwhich are the interesting words to count.
Here techniques such as feature constructionand selection could be of help.
As I will argue in what follows, the observations ofPennebaker and colleagues are potentially interesting for computational linguistics aswell, but let us first look at another relevant set of psychological findings.2.2 On the Psychological Functions of Interpersonal LanguageA different strand of research on language and social psychology focuses on inter-personal verbs (a subset of what computational linguists more commonly refer to astransitive verbs): verbs which express relations between people (Semin 2009).
In theirmodel of interpersonal language (the Linguistic Categorization Model), Semin andFiedler (1988) make a distinction between different kinds of verbs and their positionon the concrete?abstract dimension.
Descriptive action verbs (Romeo kisses Juliet) areassumed to be the most concrete, since they refer to a single, observable event.
This isdifferent for state verbs (Romeo loves Juliet), which describe psychological states insteadof single perceptual events, and are therefore more abstract.
Most abstract, accordingto Semin and Fiedler, are adjectives (Romeo is romantic), because they generalize overspecific events and objects and only refer to characteristics of the subject.The thing to note is that the same event can, in principle, be referred to in all thesedifferent forms; a speaker has the choice of using a more concrete or a more abstractway to refer to an event (e.g., John can be described as, from more to less concrete,hitting a person, hating a person, or being aggressive).
Interestingly, the abstractnesslevel a speaker opts for tells us something about that speaker.
This has been found,for instance, in the communication of ingroup (think of people with the same cul-tural identity or supporting the same soccer team) and outgroup (different identity,different team) behavior.
There is considerable evidence that speakers describe negativeingroup and positive outgroup behavior in more concrete terms (e.g., using actionverbs), thereby indicating that the behavior is more incidental, whereas positive ingroup287Computational Linguistics Volume 36, Number 2and negative outgroup behaviors are described in relatively abstract ways (e.g., morefrequently using adjectives), suggesting a more enduring characteristic (see, e.g., Maasset al 1989).
Maass and colleagues showed this phenomenon, which they dubbed theLinguistic Intergroup Bias, for different Contrada (neighborhoods) participating in thefamous Palio di Siena horse races, reporting about their own performance and that ofthe other neighborhoods.
Moreover, Wigboldus, Semin, and Spears (2000) have shownthat addressees do indeed pick up these implications, and Douglas and Sutton (2006)reveal that speakers who describe the behavior of others in relatively abstract terms areperceived to have biased attitudes and motives as opposed to speakers who describethis behavior in more concrete ways.It has been argued that concrete versus abstract language is not only relevant for,for example, the communication of stereotypes, but also has more fundamental effects,for instance influencing the way people perceive the world (Stapel and Semin 2007).In a typical experiment, Stapel and Semin first subtly prime participants with eitherabstract or concrete language.
This can be done using scrambled sentences, whereparticipants are given four words (romantic is lamp Romeo) with the instruction to forma grammatical sentence from three of them, or by giving participants a word-searchpuzzle where the words to search for are the primes.
After this, participants perform aseemingly unrelated task, where their perceptual focus (either on the global picture oron the details) is measured.
Stapel and Semin show that processing abstract language(adjectives) results in a more global perception, whereas processing concrete language(descriptive action verbs) leads to more perceptual attention to details.At this point, a computational linguist (and probably other linguists as well) mightstart to wonder about the comparison between verbs and adjectives, and by the claimthat adjectives are abstract.
What about adjectives like blonde, young, and thin?
Theseseem to be much more concrete than adjectives such as aggressive or honest.
And whatabout nouns?
There a distinction between concrete (office chair) and abstract (hypothesis)seems to exist as well.
This raises the question whether it is the differences in inter-personal language use or the more general distinction between concrete and abstractlanguagewhich causes the observed effects on perception; a recent series of experimentssuggests it is the latter (Krahmer and Stapel 2009).2.3 What Can Computational Linguists Learn?The social psychological findings briefly described here could have an impact on com-putational linguistics, with potential applications for both text understanding and gen-eration.
So far, it seems fair to say that most computational linguists have concentratedso much on trying to understand text or on generating coherent texts that the subtleeffects that language may have on the reader were virtually ignored.
Function wordswere originally not the words computational linguists found most interesting.
Theywere considered too frequent; early Information Retrieval applications listed functionwords on ?stop lists?
?lists of words that should be ignored during processing?andmany IR applications still do.
The work of Pennebaker and colleagues indicates thatpronouns (as well as other function words) do carry potentially relevant information,for instance about the mental state of the author of a document.
Interestingly, for com-putational applications such as opinion mining and sentiment analysis (Pang and Lee2008) as well as author attribution and stylometry (Holmes 1998), function words havebeen argued to be relevant as well, but it seems that research on the social psychologyof language has made little or no impact on this field.288Krahmer Last WordsConsider sentiment analysis, for instance, which is the automatic extraction of?opinion-oriented?
information (e.g., whether an author feels positive or negative abouta certain product) from text.
This is a prime example of an emerging research area incomputational linguistics which moves beyond factual information exchange (althoughthe preferred approach to this problem very much fits with the paradigm sketched byHalevy et al [2009]: take a large set of data and apply machine learning to it).
Pangand Lee (2008) offer an extensive overview of research related to sentiment analysis,but do not discuss any of the psychological studies mentioned herein (in fact, of the332 papers they cite, only one or two could conceivably be interpreted as psychologicalin the broadest interpretation).
What is especially interesting is that their discussionof why sentiment analysis is difficult echoes the discussion of Chung and Pennebaker(2007) on the problems of counting words (by sheer coincidence they even discussessentially the same example: madden).These findings may also have ramifications for the generation of documents.
If youdevelop an application which automatically produces texts from non-textual data, youmight want to avoid excessive use of the first-person pronoun, lest your readers thinkyour computer is feeling down.
If you want your readers to skim over the details ofwhat is proposed in a generated text, use abstract language.
In addition, you may wantto use action verbs when describing your own accomplishments, and adjectives to referto those of others (but do it in a subtle way, because people might notice).3.
Language Comprehension and ProductionWhile the link between computational linguistics and social psychology has seldombeen explored, there has been somewhat more interaction with psycholinguistics.
Per-haps most of this interaction has involved natural language understanding.
Variousearly parsing algorithms were inspired by human sentence processing, which is hardlysurprising: human listeners are remarkably efficient in processing and adequately re-sponding to potentially highly ambiguous sentences.
Later, when large data sets ofparsed sentences became available, the focus in computational linguistics shifted todeveloping statistical models of language processing.
Interestingly, recent psycholin-guistic sentence processing models are inspired in turn by statistical techniques fromcomputational linguistics (Chater and Manning 2006; Crocker in press; Jurafsky 2003;Pado, Crocker, and Keller 2009).3.1 On Producing Referring ExpressionsThe situation is somewhat different for natural language generation, although superfi-cially the same kind of interaction can be observed here (albeit with a few years delay).The seminal work by Dale and Reiter (1995) on the generation of referring expressionswas explicitly inspired by psycholinguistic work.
Dale and Reiter concentrated on thegeneration of distinguishing descriptions, such as the large black dog, which single outone target object by ruling out the distractors (typically a set of other domestic animalsof different sizes and colors).
Given that the number of distractors may be quite largeand given that each target can be referred to in multiple ways, one of the main issuesin this area is how to keep the search manageable.
Current algorithms for referringexpression generation, building on the foundations laid by Dale and Reiter, are goodat quickly computing which set of properties uniquely characterizes a target among a289Computational Linguistics Volume 36, Number 2set of distractors.
Some of these algorithms are capable of generating distinguishingdescriptions that human judges find more helpful and better formulated than human-produced distinguishing descriptions for the same targets (Gatt, Belz, and Kow 2009).To some this might suggest that the problem is solved.
This conclusion, however,would be too hasty.
Most of the algorithms use some very unrealistic assumptionswhich limit their applicability.
Interestingly, these assumptions can be traced backdirectly to classic psycholinguistic work on the production of referring expressions(Olson 1970).
Clark and Bangerter (2004) criticize a number of the unstated assumptionsin Olson?s approach: Reference is treated as a one-step process (a speaker plans andproduces a complete description, and nothing else, in one go) and during that processthe speaker does not take the prior interaction with the addressee into account.
Bymerely substituting computer for speaker these comments are directly applicable to mostcurrent generation algorithms as well.The problem, unfortunately, is that recent psycholinguistic research suggests thatthese assumptions are wrong.
Often this research looks at how speakers produce re-ferring expressions while interacting with an addressee, and one thing that is oftenfound is that speakers adapt to their conversational partners while producing refer-ring expressions (Clark and Wilkes-Gibbs 1986; Brennan and Clark 1996; Metzing andBrennan 2003).
This kind of ?entrainment?
or ?alignment?
(Pickering and Garrod 2004)may apply at the level of lexical choice; if a speaker refers to a couch using the wordsofa instead of the more common couch, the addressee is more likely to use sofa insteadof couch as well later on in the dialogue (Branigan et al in press).
But the speaker andaddressee may also form a general ?conceptual pact?
on how to refer to some object,deciding together, for instance, to refer to a tangram figure as the tall ice skater.Although adaptation itself is uncontroversial, psycholinguists argue about theextent to which speakers are capable of taking the perspective of the addressee intoaccount (Kronmu?ller and Barr 2007; Brennan and Hanna 2009; Brown-Schmidt 2009),with some researchers presenting evidence that speakers may have considerabledifficulty doing this (Horton and Keysar 1996; Keysar, Lin, and Barr 2003).
In WardlowLane et al (2006) people are instructed to refer to simple targets (geometrical figures thatmay be small or larger) in the context of three distractor objects, two of which are visibleto both speaker and addressee (shared) whereas the other is visible to the speaker only(privileged).
If speakers would be able to take the addressees?
perspective into accountwhen referring, the privileged distractor should not play a role in determining whichproperties to include in the distinguishing description.
However, Wardlow Lane andcolleagues found that speakers do regularly take the privileged distractor into account(for instance adding a modifier small when referring to the target, even though all theshared objects are small and only the privileged one is large).
Interestingly, speakersdo this more often when explicitly told that they should not leak information aboutthe privileged object, which Wardlow Lane et al interpret as an ironic processingeffect of the kind observed by Dostoevsky (?Try to pose for yourself this task: not tothink of a polar bear, and you will see that the cursed thing will come to mind everyminute?
).Another interesting psycholinguistic finding is that speakers often include moreinformation in their referring expressions than is strictly needed for identification (Arts2004; Engelhardt, Bailey, and Ferreira 2006), for instance referring to a dog as the largeblack curly haired dog in a situation where there is only one large black dog.
Again,that speakers are not always ?Gricean?
(?be as informative as required, but not moreinformative?)
is generally agreed upon, but there is an ongoing debate about why andhow speakers overspecify, some arguing that it simplifies the search of the speaker290Krahmer Last Words(Engelhardt, Bailey, and Ferreira 2006) whereas others suggest that overspecified refer-ences are particularly beneficial for the addressee (Paraboni, van Deemter, andMasthoff2007).3.2 What Can Computational Linguists Learn?Why are these psycholinguistic findings about the way human speakers refer relevantfor generation algorithms?
First of all, human-likeness is an important evaluation crite-rion, so algorithms that are good at emulating human referring expressions are likely tooutperform algorithms that are not.
Moreover, it is interesting to observe that generatingoverspecified expressions is computationally cheaper than producing minimal ones(Dale and Reiter 1995).
In a similar vein, it can be argued that alignment and adaptationmay reduce the search space of the generation algorithm, because they limit the numberof possibilities that have to be considered.It is worth emphasizing that psycholinguistic theories have little to say about howspeakers quickly decide which properties, from the large set of potential ones, to use ina referring expression.
In addition, whereas notions such as adaptation, alignment, andoverspecification are intuitively appealing, it has turned out to be remarkably difficultto specify how these processes operate exactly.
In fact, a common criticism is that theywould greatly benefit from ?explicit computational modeling?
(Brown-Schmidt andTanenhaus 2004).
Of course, solving choice problems and computational modeling areprecisely what computational linguistics has to offer.
So although generation algorithmsmay benefit a lot from incorporating insights from psycholinguistics, they in turn havethe potential to further research in psycholinguistics as well.4.
DiscussionIn this brief, highly selective, and somewhat biased overview of work on language inseveral areas of psychology, we have seen that words may give valuable informationabout the person who produces them (but how to select and count them is tricky), thatabstract or concrete language may tell you something about the opinions and attitudesa speaker has and may even influence how you perceive things (but the linguistic intu-itions about what is abstract, andwhat concrete, need somework), and that speakers areremarkably efficient when producing referring expressions, in part because they adaptto their addressee and do not necessarily try to be as brief as possible (but making theseintuitive notions precise is difficult).
Psychological findings such as these are not merelyintriguing, but could be of real use for computational linguistic applications related todocument understanding or generation (and, conversely, techniques and insights fromcomputational linguistics could be helpful for psychologists as well).
Of course, somecomputational linguists do extensively rely on psychological findings for building theirapplications (you know who you are), just as some psychologists use sophisticatedcomputational and statistical models rather than human participants for their studies(this is especially true in psycholinguistics).
But these are exceptions, and certainly donot belong to mainstream computational linguistics or psychology.
Which raises oneobvious question: Why isn?t there more interaction between these two communities?There seem to be at least three reasons for this.
First, and most obvious, manyresearchers are not aware of what happens outside their own specialized field.
Thearticles in psychology are fairly accessible (usually no complex statistical models oroverformalized algorithms there), but many computational linguists may feel that it291Computational Linguistics Volume 36, Number 2would be a better investment of their limited time to read some more of the 17,000(and counting) journal, conference, and workshop papers they have not yet read in theinvaluable ACL Anthology.
For psychologists presumably similar considerations apply,with the additional complication that many of the anthology papers require a substan-tial amount of technical prior knowledge.
In addition, it might be that the differentpublication cultures are a limiting factor here as well: for psychologists, journals are themain publication outlet; for them most non-journal publications have a low status andhence might be perceived as not worth exploring.Another perhaps more interesting reason is that psychologists and computationallinguists have subtly different general objectives.
Psychologists want to get a betterunderstanding of people; how their social context determines their language behavior,how they produce and comprehend sentences, and so on.
Their models are evaluatedin terms of whether there is statistical evidence for their predictions in actual humanbehavior.
Computational linguists evaluate their models (?algorithms?)
on large col-lections of human-produced data; one model is better than another if it accounts formore of the data.
Of course, a model can perform well when evaluated on human data,but be completely unrealistic from a psychological point of view.
If a computationallinguist develops a referring expression generation algorithm (or a machine translationsystem or an automatic summarizer) which accounts for the data in a way which ispsychologically unrealistic, the work will generally not be of interest to psychologists.Conversely, if psychological insights are difficult to formalize or require complex algo-rithms or data structures, computational linguists are likely not to be enthusiastic aboutapplying them.
Obviously, this hinders cross-pollination of ideas as well.Third, and somewhat related to the previous point, it sometimes seems that compu-tational linguists see trees where psychologists see a forest.
Psychologists appear to bemost interested in showing a general effect (and are particularly appreciative of cleverand elegant experimental designs which reveal these effects); if merely counting wordsalready gives you a statistically reliable effect, thenwhy bother with amore complicatedway of counting n-grams and worrying about back-off smoothing to deal with datasparseness?
Doing so would conceivably give you a better estimate of the significanceand size of your effect, but would probably not change your story in any fundamentalway.
Computational linguists, by contrast, evaluate their models on (often shared) data-sets (and tend to be more impressed by technical prowess?e.g., new statistical machinelearning models?or by smart ways of automatically collecting large quantities of data);each data point that is processed incorrectly by their model offers a potential advantagefor someone else?s model.In view of observations such as these, it is perhaps not surprising that compu-tational linguists and psychologists have remained largely unaware of each other?swork so far.
Predicting the future is a tricky thing, but it seems not unlikely that mostcomputational linguists and psychologists will continue going their own way in thefuture.
Nevertheless, I hope to have shown here that both communities could benefitfrom the occasional foray into the others?
territory.
For psychologists, the tools and tech-niques developed by computational linguists could further their research, by helping tomake their models and theories more explicit and hence easier to test and compare.For computational linguists, insights from both the social psychology of language andfrom psycholinguists could contribute to a range of applications, from opinion miningto text understanding and generation.
Obviously, this contribution could be on thelevel of ?words?, but a more substantial contribution is conceivable as well.
As wehave seen, psychologists are particularly strong in explanatory theories (on affect, oninteraction, etc.)
and perhaps taking these as starting points for our applications (e.g.,292Krahmer Last Wordson affective and interactive generation) could make them theoretically more interestingand empirically more adequate.AcknowledgmentsThanks to Robert Dale for inviting me towrite a Last Words piece on this topic andfor his useful comments on an earlierversion.
This piece grew out of discussions Ihad over the years with both computationallinguists and psychologists, includingMartijn Balsters, Kees van Deemter, AlbertGatt, Roger van Gompel, Erwin Marsi,Diederik Stapel, Marc Swerts, Marie?tTheune, and Ad Vingerhoets.
Needlessto say, I alone am responsible for thesimplifications and opinions in this work.I received financial support from theNetherlands Organization for ScientificResearch (NWO), via the Vici project?Bridging the gap between computationallinguistics and psycholinguistics: The caseof referring expressions?
(277-70-007),which is gratefully acknowledged.ReferencesArts, Anja.
2004.
Overspecification inInstructive Texts.
Unpublished Ph.D.thesis, Tilburg University.Branigan, Holly P., Martin J. Pickering, JamiePearson, and Janet F. McLean.
(in press).Linguistic alignment between humansand computers.
Journal of Pragmatics.Brennan, Susan and Herbert H. Clark.
1996.Conceptual pacts and lexical choice inconversation.
Journal of ExperimentalPsychology, 22(6):1482?1493.Brennan, Susan E. and Joy E. Hanna.
2009.Partner-specific adaptation in dialog.Topics in Cognitive Science, 1(2):274?291.Brown-Schmidt, S. and M. Tanenhaus.
2004.Priming and alignment: Mechanism orconsequence?
commentary on Pickeringand Garrod 2004.
Behavioral and BrainSciences, 27:193?194.Brown-Schmidt, Sarah.
2009.
Partner-specificinterpretation of maintained referentialprecedents during interactive dialog.Journal of Memory and Language,61:171?190.Chater, Nick and Christopher D. Manning.2006.
Probabilistic models of languageprocessing and acquisition.
Trends inCognitive Science, 10:335?344.Chung, C. K. and James W. Pennebaker.
2007.The psychological function of functionwords.
In K. Fiedler, editor, SocialCommunication: Frontiers of SocialPsychology.
Psychology Press, New York,pages 343?359.Clark, Herbert H. 1996.
Using Language.Cambridge University Press,Cambridge, UK.Clark, Herbert H. and Adrian Bangerter.2004.
Changing ideas about reference.
InIra A. Noveck and Dan Sperber, editors,Experimental Pragmatics.
PalgraveMacmillan, Basingstoke, pages 25?49.Clark, Herbert H. and Deanna Wilkes-Gibbs.1986.
Referring as a collaborative process.Cognition, 22:1?39.Cohn, M., M. Mehl, and James W.Pennebaker.
2004.
Linguistic markersof psychological change surroundingSeptember 11, 2001.
PsychologicalScience, 15:687?693.Crocker, Matthew W. (in press).Computational psycholinguistics.
In AlexClark, Chris Fox, and Shalom Lappin,editors, Computational Linguistics andNatural Language Processing Handbook.Wiley Blackwell, London, UK.Dale, Robert and Ehud Reiter.
1995.Computational interpretations of theGricean maxims in the generation ofreferring expressions.
Cognitive Science,18:233?263.Douglas, Karen and Robbie Sutton.2006.
When what you say about otherssays something about you: Languageabstraction and inferences aboutdescribers?
attitudes and goals.
Journalof Experimental Social Psychology, 42:500?508.Engelhardt, Paul E., Karl G. D. Bailey, andFernanda Ferreira.
2006.
Do speakers andlisteners observe the Gricean Maxim ofQuantity?
Journal of Memory and Language,54:554?573.Gatt, Albert, Anja Belz, and Eric Kow.
2009.The tuna-reg challenge 2009: Overviewand evaluation results.
In Proceedingsof the 12th European Workshop onNatural Language Generation (ENLG),pages 174?182, Athens.Halevy, Alon, Peter Norvig, and FernandoPereira.
2009.
The unreasonableeffectiveness of data.
IEEE IntelligentSystems, 24:8?12.Holmes, David I.
1998.
The evolution ofstylometry in humanities scholarship.Literary and Linguistic Computing,13:111?117.293Computational Linguistics Volume 36, Number 2Horton, W. S. and B. Keysar.
1996.
Whendo speakers take into account commonground?
Cognition, 59:91?117.Hovy, Eduard H. 1990.
Pragmatics andnatural language generation.
ArtificialIntelligence, 43:153?197.Jurafsky, Dan.
2003.
Probabilisticmodeling in psycholinguistics: Linguisticcomprehension and production.
In RensBod, Jennifer Hay, and Stefanie Jannedy,editors, Probabilistic Linguistics.
MIT Press,Cambridge, MA, pages 39?96.Keysar, B., S. Lin, and D. J. Barr.
2003.Limits on theory of mind use in adults.Cognition, 89:25?41.Krahmer, Emiel and Diederik Stapel.
2009.Abstract language, global perception:How language shapes what we see.
InProceedings of the Annual Meeting of theCognitive Science Society, pages 286?291,Amsterdam.Kronmu?ller, E. and Dale Barr.
2007.Perspective-free pragmatics: Brokenprecedents and the recovery-from-preemption hypothesis.
Journal ofMemory and Language, 56:436?455.Maass, A., D. Salvi, L. Arcuri, and G. Semin.1989.
Language use in intergroup contexts:The linguistic intergroup bias.
Journalof Personality and Social Psychology,57:981?993.Metzing, Charles A. and Susan E. Brennan.2003.
When conceptual pacts are broken:Partner effects on the comprehension ofreferring expressions.
Journal of Memoryand Language, 49:201?213.Olson, David R. 1970.
Language andthought: Aspects of a cognitive theoryof semantics.
Psychological Review,77:257?273.Pado, Ulrike, Matthew W. Crocker, andFrank Keller.
2009.
A probabilistic modelof semantic plausibility in sentenceprocessing.
Cognitive Science, 33:794?838.Pang, B. and L. Lee.
2008.
Opinion miningand sentiment analysis.
Foundations andTrends in Information Retrieval, 2:1?135.Paraboni, Ivandre?, Kees van Deemter,and Judith Masthoff.
2007.
Generatingreferring expressions: Making referentseasy to identity.
Computational Linguistics,33:229?254.Pennebaker, James W., C. Groom, D. Loew,and J. Dabbs.
2004.
Testosterone as a socialinhibitor: Two case studies of the effect oftestosterone treatment on language.
Journalof Abnormal Psychology, 113:172?175.Pickering, Martin and Simon Garrod.
2004.Towards a mechanistic psychology ofdialogue.
Behavioural and Brain Sciences,27:169?226.Reiter, Ehud.
2007.
The shrinking horizons ofcomputational linguistics.
ComputationalLinguistics, 33:283?287.Rude, S., E. Gortner, and James W.Pennebaker.
2004.
Language use ofdepressed and depression-vulnerablecollege students.
Cognition and Emotion,18:1121?1133.Semin, Gu?n.
2009.
Language and socialcognition.
In F. Strack and J. Fo?rster,editors, Social Cognition: The Basis of HumanInteraction.
Psychology Press, London,pages 269?290.Semin, Gu?n and Klaus Fiedler.
1988.
Thecognitive functions of linguistic categoriesin describing persons: Social cognition andlanguage.
Journal of Personality and SocialPsychology, 34:558?568.Stapel, Diederik and Gu?n Semin.
2007.The magic spell of language.
Journal ofPersonality and Social Psychology, 93:23?33.Stirman, Shannon and James W. Pennebaker.2001.
Word use in the poetry of suicidaland nonsuicidal poets.
PsychosomaticMedicine, 63:517?522.Wardlow Lane, Liane, Michelle Groisman,and Victor S. Ferreira.
2006.
Don?t talkabout pink elephants!
: Speakers?
controlover leaking private information duringlanguage production.
Psychological Science,17:273?277.Wigboldus, Danie?l, Gu?n Semin, and RussellSpears.
2000.
How do we communicatestereotypes?
linguistic bases andinferential consequences.
Journal ofPersonality and Social Psychology, 78:5?18.Winograd, Terry.
1980.
What does it mean tounderstand language?
Cognitive Science,4:209?241.294
