Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 1095?1104,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsHarnessing Cognitive Features for Sarcasm DetectionAbhijit Mishra?, Diptesh Kanojia?, Seema Nagar?, Kuntal Dey?,Pushpak Bhattacharyya?
?Indian Institute of Technology Bombay, India?IBM Research, India?
{abhijitmishra, diptesh, pb}@cse.iitb.ac.in?
{senagar3, kuntadey}@in.ibm.comAbstractIn this paper, we propose a novel mecha-nism for enriching the feature vector, forthe task of sarcasm detection, with cogni-tive features extracted from eye-movementpatterns of human readers.
Sarcasm detec-tion has been a challenging research prob-lem, and its importance for NLP applica-tions such as review summarization, dia-log systems and sentiment analysis is wellrecognized.
Sarcasm can often be tracedto incongruity that becomes apparent asthe full sentence unfolds.
This presenceof incongruity- implicit or explicit- affectsthe way readers eyes move through thetext.
We observe the difference in the be-haviour of the eye, while reading sarcasticand non sarcastic sentences.
Motivated bythis observation, we augment traditionallinguistic and stylistic features for sarcasmdetection with the cognitive features ob-tained from readers eye movement data.We perform statistical classification usingthe enhanced feature set so obtained.
Theaugmented cognitive features improve sar-casm detection by 3.7% (in terms of F-score), over the performance of the bestreported system.1 IntroductionSarcasm is an intensive, indirect and complex con-struct that is often intended to express contemptor ridicule1.
Sarcasm, in speech, is multi-modal,involving tone, body-language and gestures alongwith linguistic artifacts used in speech.
Sarcasmin text, on the other hand, is more restrictive whenit comes to such non-linguistic modalities.
Thismakes recognizing textual sarcasm more challeng-ing for both humans and machines.1The Free DictionarySarcasm detection plays an indispensable rolein applications like online review summarizers, di-alog systems, recommendation systems and senti-ment analyzers.
This makes automatic detectionof sarcasm an important problem.
However, ithas been quite difficult to solve such a problemwith traditional NLP tools and techniques.
This isapparent from the results reported by the surveyfrom Joshi et al (2016).
The following discussionbrings more insights into this.Consider a scenario where an online reviewergives a negative opinion about a movie throughsarcasm: ?This is the kind of movie you see be-cause the theater has air conditioning?.
It is dif-ficult for an automatic sentiment analyzer to as-sign a rating to the movie and, in the absenceof any other information, such a system maynot be able to comprehend that prioritizing theair-conditioning facilities of the theater over themovie experience indicates a negative sentimenttowards the movie.
This gives an intuition to why,for sarcasm detection, it is necessary to go beyondtextual analysis.We aim to address this problem by exploitingthe psycholinguistic side of sarcasm detection, us-ing cognitive features extracted with the help ofeye-tracking.
A motivation to consider cogni-tive features comes from analyzing human eye-movement trajectories that supports the conjec-ture: Reading sarcastic texts induces distinctiveeye movement patterns, compared to literal texts.The cognitive features, derived from human eyemovement patterns observed during reading, in-clude two primary feature types:1.
Eye movement characteristic features ofreaders while reading given text, comprisinggaze-fixaions (i.e,longer stay of gaze on a vi-sual object), forward and backward saccades(i.e., quick jumping of gaze between two po-sitions of rest).10952.
Features constructed using the statistical anddeeper structural information contained ingraph, created by treating words as verticesand saccades between a pair of words asedges.The cognitive features, along with textual fea-tures used in best available sarcasm detectors, areused to train binary classifiers against given sar-casm labels.
Our experiments show significant im-provement in classification accuracy over the stateof the art, by performing such augmentation.Feasibility of Our ApproachSince our method requires gaze data from humanreaders to be available, the methods practicabilitybecomes questionable.
We present our views onthis below.Availability of Mobile Eye-trackersAvailability of inexpensive embedded eye-trackerson hand-held devices has come close to realitynow.
This opens avenues to get eye-trackingdata from inexpensive mobile devices from a hugepopulation of online readers non-intrusively, andderive cognitive features to be used in predic-tive frameworks like ours.
For instance, Co-gisen: (http://www.sencogi.com) has a patent (ID:EP2833308-A1) on ?eye-tracking using inexpen-sive mobile web-cams?.Applicability ScenarioWe believe, mobile eye-tracking modules could bea part of mobile applications built for e-commerce,online learning, gaming etc.
where automaticanalysis of online reviews calls for better solutionsto detect linguistic nuances like sarcasm.
To givean example, let?s say a book gets different reviewson Amazon.
Our system could watch how read-ers read the review using mobile eye-trackers, andthereby, decide whether the text contains sarcasmor not.
Such an application can horizontally scaleacross the web and will help in improving auto-matic classification of online reviews.Since our approach seeks human mediation, onemight be tempted to question the approach of re-lying upon eye-tracking, an indirect indicator, in-stead of directly obtaining man-made annotations.We believe, asking a large number of internet au-dience to annotate/give feedback on each and ev-ery sentence that they read online, following a setof annotation instructions, will be extremely intru-sive and may not be responded well.
Our system,on the other hand, can be seamlessly integratedinto existing applications and as the eye-trackingprocess runs in the background, users will not beinterrupted in the middle of the reading.
This,thus, offers a more natural setting where humanmediation can be availed without intervention.Getting Users?
Consent for Eye-trackingEye-tracking technology has already been uti-lized by leading mobile technology developers(like Samsung) to facilitate richer user experiencesthrough services like Smart-scroll (where a user?seye movement determines whether a page has tobe scrolled or not) and Smart-lock (where user?sgaze position decides whether to lock the screenor not).
The growing interest of users in us-ing such services takes us to a promising situa-tion where getting users?
consent to record eye-movement patterns will not be difficult, though itis yet not the current state of affairs.Disclaimer: In this work, we focus on detect-ing sarcasm in non-contextual and short-text set-tings prevalent in product reviews and social me-dia.
Moreover, our method requires eye-trackingdata to be available in the test scenario.2 Related WorkSarcasm, in general, has been the focus of re-search for quite some time.
In one of the pio-neering works Jorgensen et al (1984) explainedhow sarcasm arises when a figurative meaning isused opposite to the literal meaning of the utter-ance.
In the word of Clark and Gerrig (1984), sar-casm processing involves canceling the indirectlynegated message and replacing it with the impli-cated one.
Giora (1995), on the other hand, de-fine sarcasm as a mode of indirect negation that re-quires processing of both negated and implicatedmessages.
Ivanko and Pexman (2003) define sar-casm as a six tuple entity consisting of a speaker,a listener, Context, Utterance, Literal Propositionand Intended Proposition and study the cognitiveaspects of sarcasm processing.Computational linguists have previously ad-dressed this problem using rule based and sta-tistical techniques, that make use of : (a) Un-igrams and Pragmatic features (Carvalho et al,2009; Gonz?alez-Ib?anez et al, 2011; Barbieri etal., 2014; Joshi et al, 2015) (b) Stylistic patterns(Davidov et al, 2010) and patterns related to situa-tional disparity (Riloff et al, 2013) and (c) Hastag1096interpretations (Liebrecht et al, 2013; Maynardand Greenwood, 2014).Most of the previously done work on sar-casm detection uses distant supervision basedtechniques (ex: leveraging hashtags) and stylis-tic/pragmatic features (emoticons, laughter ex-pressions such as ?lol?
etc).
But, detectingsarcasm in linguistically well-formed structures,in absence of explicit cues or information (likeemoticons), proves to be hard using such linguis-tic/stylistic features alone.With the advent of sophisticated eye-trackers and electro/magneto-encephalographic(EEG/MEG) devices, it has been possible todelve deep into the cognitive underpinnings ofsarcasm understanding.
Filik (2014), using aseries of eye-tracking and EEG experiments tryto show that for unfamiliar ironies, the literalinterpretation would be computed first.
Theyalso show that a mismatch with context wouldlead to a re-interpretation of the statement, asbeing ironic.
Camblin et al (2007) show that inmulti-sentence passages, discourse congruencehas robust effects on eye movements.
This alsoimplies that disrupted processing occurs for dis-course incongruent words, even though they areperfectly congruous at the sentence level.
In ourprevious work (Mishra et al, 2016), we augmentcognitive features, derived from eye-movementpatterns of readers, with textual features to detectwhether a human reader has realized the presenceof sarcasm in text or not.The recent advancements in the literature dis-cussed above, motivate us to explore gaze-basedcognition for sarcasm detection.
As far as weknow, our work is the first of its kind.3 Eye-tracking Database for SarcasmAnalysisSarcasm often emanates from incongruity (Camp-bell and Katz, 2012), which enforces the brain toreanalyze it (Kutas and Hillyard, 1980).
This, inturn, affects the way eyes move through the text.Hence, distinctive eye-movement patterns maybe observed in the case of successful processingof sarcasm in text in contrast to literal texts.This hypothesis forms the crux of our methodfor sarcasm detection and we validate this usingour previously released freely available sarcasmdataset2(Mishra et al, 2016) enriched with gaze2http://www.cfilt.iitb.ac.in/cognitive-nlp?
S ?
S ?
NS ?
NS t pP1 319 145 196 97 14.1 5.84E-39P2 415 192 253 130 14.0 1.71E-38P3 322 173 214 160 9.5 3.74E-20P4 328 170 191 96 13.9 1.89E-37P5 291 151 183 76 11.9 2.75E-28P6 230 118 136 84 13.2 6.79E-35P7 488 268 252 141 15.3 3.96E-43Table 1: T-test statistics for average fixation dura-tion time per word (in ms) for presence of sarcasm(represented by S) and its absence (NS) for partic-ipants P1-P7.information.3.1 Document DescriptionThe database consists of 1,000 short texts, eachhaving 10-40 words.
Out of these, 350 are sar-castic and are collected as follows: (a) 103 sen-tences are from two popular sarcastic quote web-sites3, (b) 76 sarcastic short movie reviews aremanually extracted from the Amazon Movie Cor-pus (Pang and Lee, 2004) by two linguists.
(c)171 tweets are downloaded using the hashtag #sar-casm from Twitter.
The 650 non-sarcastic texts areeither downloaded from Twitter or extracted fromthe Amazon Movie Review corpus.
The sentencesdo not contain words/phrases that are highly topicor culture specific.
The tweets were normalizedto make them linguistically well formed to avoiddifficulty in interpreting social media lingo.
Everysentence in our dataset carries positive or negativeopinion about specific ?aspects?.
For example, thesentence ?The movie is extremely well cast?
haspositive sentiment about the aspect ?cast?.The annotators were seven graduate studentswith science and engineering background, andpossess good English proficiency.
They weregiven a set of instructions beforehand and are ad-vised to seek clarifications before they proceed.The instructions mention the nature of the task,annotation input method, and necessity of headmovement minimization during the experiment.3.2 Task DescriptionThe task assigned to annotators was to read sen-tences one at a time and label them with withbinary labels indicating the polarity (i.e., posi-tive/negative).
Note that, the participants were not3http://www.sarcasmsociety.com,http://www.themarysue.com/funny-amazon-reviews1097instructed to annotate whether a sentence is sar-castic or not., to rule out the Priming Effect (i.e., ifsarcasm is expected beforehand, processing incon-gruity becomes relatively easier (Gibbs, 1986)).The setup ensures its ?ecological validity?
in twoways: (1) Readers are not given any clue that theyhave to treat sarcasm with special attention.
Thisis done by setting the task to polarity annotation(instead of sarcasm detection).
(2) Sarcastic sen-tences are mixed with non sarcastic text, whichdoes not give prior knowledge about whether theforthcoming text will be sarcastic or not.The eye-tracking experiment is conducted byfollowing the standard norms in eye-movementresearch (Holmqvist et al, 2011).
At a time,one sentence is displayed to the reader alongwith the ?aspect?
with respect to which the an-notation has to be provided.
While reading, anSR-Research Eyelink-1000 eye-tracker (monocu-lar remote mode, sampling rate 500Hz) recordsseveral eye-movement parameters like fixations (along stay of gaze) and saccade (quick jumping ofgaze between two positions of rest) and pupil size.The accuracy of polarity annotation varies be-tween 72%-91% for sarcastic texts and 75%-91%for non-sarcastic text, showing the inherent dif-ficulty of sentiment annotation, when sarcasmis present in the text under consideration.
An-notation errors may be attributed to: (a) lackof patience/attention while reading, (b) issuesrelated to text comprehension, and (c) confu-sion/indecisiveness caused due to lack of context.For our analysis, we do not discard the incor-rect annotations present in the database.
Sinceour system eventually aims to involve online read-ers for sarcasm detection, it will be hard to segre-gate readers who misinterpret the text.
We makea rational assumption that, for a particular text,most of the readers, from a fairly large popula-tion, will be able to identify sarcasm.
Under thisassumption, the eye-movement parameters, aver-aged across all readers in our setting, may not besignificantly distorted by a few readers who wouldhave failed to identify sarcasm.
This assumptionis applicable for both regular and multi-instancebased classifiers explained in section 6.4 Analysis of Eye-movement DataWe observe distinct behavior during sarcasm read-ing, by analyzing the ?fixation duration on thetext?
(also referred to as ?dwell time?
in the lit-Word IDTime (  mi li s econds )P1 P2 P3S2: The lead actress is terrible and I cannot be convinced she is supposed to be some forensic genius.S1: I'll always cherish the original misconception I had of you..Figure 1: Scanpaths of three participants for twonegatively polar sentences sentence S1 and S2.Sentence S1 is sarcastic but S2 is not.erature) and ?scanpaths?
of the readers.4.1 Variation in the Average FixationDuration per WordSince sarcasm in text can be expected to inducecognitive load, it is reasonable to believe that itwould require more processing time (Ivanko andPexman, 2003).
Hence, fixation duration nor-malized over total word count should usually behigher for a sarcastic text than for a non-sarcasticone.
We observe this for all participants in ourdataset, with the average fixation duration perword for sarcastic texts being at least 1.5 timesmore than that of non-sarcastic texts.
To testthe statistical significance, we conduct a two-tailed t-test (assuming unequal variance) to com-pare the average fixation duration per word for sar-castic and non-sarcastic texts.
The hypothesizedmean difference is set to 0 and the error tolerancelimit (?)
is set to 0.05.
The t-test analysis, pre-sented in Table 1, shows that for all participants,a statistically significant difference exists betweenthe average fixation duration per word for sar-casm (higher average fixation duration) and non-sarcasm (lower average fixation duration).
Thisaffirms that the presence of sarcasm affects the du-ration of fixation on words.It is important to note that longer fixationsmay also be caused by other linguistic subtleties(such as difficult words, ambiguity and syntacti-cally complex structures) causing delay in com-prehension, or occulomotor control problems forc-ing readers to spend time adjusting eye-muscles.So, an elevated average fixation duration per wordmay not sufficiently indicate the presence of sar-casm.
But we would also like to share that, for our1098I will always cherish theoriginal mis-conception I had of youFigure 2: Saliency graph of participant P1 for thesentence I will always cherish the original miscon-ception I had of you.dataset, when we considered readability (Fleschreadability ease-score (Flesch, 1948)), number ofwords in a sentence and average character perword along with the sarcasm label as the predic-tors of average fixation duration following a linearmixed effect model (Barr et al, 2013), sarcasm la-bel turned out to be the most significant predictorwith a maximum slope.
This indicates that averagefixation duration per word has a strong connectionwith the text being sarcastic, at least in our dataset.We now analyze scanpaths to gain more in-sights into the sarcasm comprehension process.4.2 Analysis of ScanpathsScanpaths are line-graphs that contain fixationsas nodes and saccades as edges; the radii of thenodes represent the fixation duration.
A scanpathcorresponds to a participant?s eye-movement pat-tern while reading a particular sentence.
Figure 1presents scanpaths of three participants for the sar-castic sentence S1 and the non-sarcastic sentenceS2.
The x-axis of the graph represents the se-quence of words a reader reads, and the y-axis rep-resents a temporal sequence in milliseconds.Consider a sarcastic text containing incongru-ous phrases A and B.
Our qualitative scanpath-analysis reveals that scanpaths with respect to sar-casm processing have two typical characteristics.Often, a long regression - a saccade that goes toa previously visited segment - is observed when areader starts reading B after skimming through A.In a few cases, the fixation duration on A and Bare significantly higher than the average fixationduration per word.
In sentence S1, we see longand multiple regressions from the two incongru-ous phrases ?misconception?
and ?cherish?, anda few instances where phrases ?always cherish?and ?original misconception?
are fixated longerthan usual.
Such eye-movement behaviors are notseen for S2.Though sarcasm induces distinctive scanpathslike the ones depicted in Figure 1 in the observedexamples, presence of such patterns is not suffi-cient to guarantee sarcasm; such patterns may alsopossibly arise from literal texts.
We believe that acombination of linguistic features, readability oftext and features derived from scanpaths wouldhelp discriminative machine learning models learnsarcasm better.5 Features for Sarcasm DetectionWe describe the features used for sarcasm detec-tion in Table 2.
The features enlisted under lex-ical,implicit incongruity and explicit incongruityare borrowed from various literature (predomi-nantly from Joshi et al (2015)).
These featuresare essential to separate sarcasm from other formssemantic incongruity in text (for example ambi-guity arising from semantic ambiguity or frommetaphors).
Two additional textual features viz.readability and word count of the text are alsotaken under consideration.
These features are usedto reduce the effect of text hardness and text lengthon the eye-movement patterns.5.1 Simple Gaze Based FeaturesReaders?
eye-movement behavior, characterizedby fixations, forward saccades, skips and regres-sions, can be directly quantified by simple statis-tical aggregation (i.e., either computing featuresfor individual participants and then averaging orperforming a multi-instance based learning as ex-plained in section 6).
Since these eye-movementattributes relate to the cognitive process in reading(Rayner and Sereno, 1994), we consider these asfeatures in our model.
Some of these features havebeen reported by Mishra et al (2016) for modelingsarcasm understandability of readers.
However, asfar as we know, these features are being introducedin NLP tasks like textual sarcasm detection for thefirst time.
The values of these features are believedto increase with the increase in the degree of sur-prisal caused by incongruity in text (except skipcount, which will decrease).5.2 Complex Gaze Based FeaturesFor these features, we rely on a graph structure,namely ?saliency graphs?, derived from eye-gazeinformation and word sequences in the text.Constructing Saliency Graphs:For each reader and each sentence, we construct a?saliency graph?, representing the reader?s atten-1099Subcategory Feature Name Type IntentCategory: Textual Sarcasm Features, Source: Joshi et.
al.Lexical Presence of Unigrams (UNI) Boolean Unigrams in the training corpusPunctuations (PUN) Real Count of punctuation marksImplicit In-congruityImplicit Incongruity (IMP) Boolean Incongruity of extracted implicit phrases (Rilof et.al,2013)Explicit Incongruity (EXP) Integer Number of times a word follows a word of opposite po-larityLargest Pos/Neg Subsequence (LAR) Integer Length of the largest series of words with polarities un-changedExplicit Positive words (+VE) Integer Number of positive wordsIncongruity Negative words (-VE) Integer Number of negative wordsLexical Polarity (LP) Integer Sentence polarity found by supervised logistic regres-sionCategory: Cognitive Features.
We introduce these features for sarcasm detection.Readability (RED) Real Flesch Readability Ease (Flesch, 1948) score of the sen-tenceTextual Number of Words (LEN) Integer Number of words in the sentenceAvg.
Fixation Duration (FDUR) Real Sum of fixation duration divided by word countAvg.
Fixation Count (FC) Real Sum of fixation counts divided by word countAvg.
Saccade Length (SL) Real Sum of saccade lengths (measured by number of words)divided by word countSimple Regression Count (REG) Real Total number of gaze regressionsGaze Skip count (SKIP) Real Number of words skipped divided by total word countBased Count of regressions from second halfto first half of the sentence (RSF)Real Number of regressions from second half of the sentenceto the first half of the sentence (given the sentence isdivided into two equal half of words)Largest Regression Position (LREG) Real Ratio of the absolute position of the word from which aregression with the largest amplitude (number of pixels)is observed, to the total word count of sentenceEdge density of the saliency gazegraph (ED)Real Ratio of the number of directed edges to vertices in thesaliency gaze graph (SGG)Fixation Duration at Left/Source(F1H, F1S)Real Largest weighted degree (LWD) and second largestweighted degree (SWD) of the SGG considering the fix-ation duration of word i of edge EijComplex Fixation Duration at Right/Target(F2H, F2S)Real LWD and SWD of the SGG considering the fixation du-ration of word j of edge EijGaze Forward Saccade Word Count ofSource (PSH, PSS)Real LWD and SWD of the SGG considering the number offorward saccades between words i and j of an edge EijBased Forward Saccade Word Count of Des-tination (PSDH, PSDS)Real LWD and SWD of the SGG considering the total dis-tance (word count) of forward saccades between wordsi and j of an edge EijRegressive Saccade Word Count ofSource (RSH, RSS)Real LWD and SWD of the SGG considering the number ofregressive saccades between words i and j of an edgeEijRegressive Saccade Word Count ofDestination (RSDH, RSDS)Real LWD and SWD of the SGG considering the totaldistance (word count) of regressive saccades betweenwords i and j of an edge EijTable 2: The complete set of features used in our system.tion characteristics.
A saliency graph for a sen-tence S for a readerR, represented asG = (V,E),is a graph with vertices (V ) and edges (E) whereeach vertex v ?
V corresponds to a word inS (may not be unique) and there exists an edgee ?
E between vertices v1and v2if R performs atleast one saccade between the words correspond-ing to v1 and v2.Figure 2 shows an example of a saliencygraph.A saliency graph may be weighted, but notnecessarily connected, for a given text (as theremay be words in the given text with no fixation onthem).
The ?complex?
gaze features derived fromsaliency graphs are also motivated by the theoryof incongruity.
For instance, Edge Density of asaliency graph increases with the number of dis-tinct saccades, which could arise from the com-plexity caused by presence of sarcasm.
Similarly,the highest weighted degree of a graph is expectedto be higher, if the node corresponds to a phrase,incongruous to some other phrase in the text.6 The Sarcasm ClassifierWe interpret sarcasm detection as a binary clas-sification problem.
The training data constitutes1100Features P(1) P(-1) P(avg) R(1) R(-1) R(avg) F(1) F(-1) F(avg) KappaMulti Layered Neural NetworkUnigram 53.1 74.1 66.9 51.7 75.2 66.6 52.4 74.6 66.8 0.27Sarcasm (Joshi et.
al.)
59.2 75.4 69.7 51.7 80.6 70.4 55.2 77.9 69.9 0.33Gaze 62.4 76.7 71.7 54 82.3 72.3 57.9 79.4 71.8 0.37Gaze+Sarcasm 63.4 75 70.9 48 84.9 71.9 54.6 79.7 70.9 0.34N?aive BayesUnigram 45.6 82.4 69.4 81.4 47.2 59.3 58.5 60 59.5 0.24Sarcasm (Joshi et.
al.)
46.1 81.6 69.1 79.4 49.5 60.1 58.3 61.6 60.5 0.25Gaze 57.3 82.7 73.8 72.9 70.5 71.3 64.2 76.1 71.9 0.41Gaze+Sarcasm 46.7 82.1 69.6 79.7 50.5 60.8 58.9 62.5 61.2 0.26Original system by Riloff et.al.
: Rule Based with implicit incongruityOrdered 60 30 49 50 39 46 54 34 47 0.10Unordered 56 28 46 40 42 41 46 33 42 0.16Original system by Joshi et.al.
: SVM with RBF KernelSarcasm (Joshi et.
al.)
73.1 69.4 70.7 22.6 95.5 69.8 34.5 80.4 64.2 0.21SVM Linear: with default parametersUnigram 56.5 77 69.8 58.6 75.5 69.5 57.5 76.2 69.6 0.34Sarcasm (Joshi et.
al.)
59.9 78.7 72.1 61.4 77.6 71.9 60.6 78.2 72 0.39Gaze 65.9 75.9 72.4 49.7 86 73.2 56.7 80.6 72.2 0.38Gaze+Sarcasm 63.7 79.5 74 61.7 80.9 74.1 62.7 80.2 74 0.43Multi Instance Logistic Regression: Best Performing ClassifierGaze 65.3 77.2 73 53 84.9 73.8 58.5 80.8 73.1 0.41Gaze+Sarcasm 62.5 84 76.5 72.6 76.7 75.3 67.2 80.2 75.7 0.47Table 3: Classification results for different feature combinations.
P?
Precision, R?Recall, F?
F?score,Kappa?
Kappa statistics show agreement with the gold labels.
Subscripts 1 and -1 correspond to sar-casm and non-sarcasm classes respectively.SentenceGold SarcasmGaze Gaze+Sarcasm1.
I would like to live in Manchester, England.
The transition between Manch-ester and death would be unnoticeable.S NSS S2.
Helped me a lot with my panic attacks.
I took 6 mg a day for almost 20 years.Can?t stop of course but it makes me feel very comfortable.NS SNS NS3.
Forgot to bring my headphones to the gym this morning, the music they playin this gym pumps me up so much!S SNS NS4.
Best show on satellite radio!!
No doubt about it.
The little doggy companyhas nothing even close.NS SNS STable 4: Example test-cases with S and NS representing labels for sarcastic and not-sarcastic respectively.994 examples created using our eye-movementdatabase for sarcasm detection.
To check the ef-fectiveness of our feature set, we observe the per-formance of multiple classification techniques onour dataset through a stratified 10-fold cross val-idation.
We also compare the classification accu-racy of our system and the best available systemsproposed by Riloff et al (2013) and Joshi et al(2015) on our dataset.
Using Weka (Hall et al,2009) and LibSVM (Chang and Lin, 2011) APIs,we implement the following classifiers:?
N?aive Bayes classifier?
Support Vector Machines (Cortes and Vap-nik, 1995) with default hyper-paramaters?
Multilayer Feed Forward Neural Network?
Multi Instance Logistic Regression(MILR) (Xu and Frank, 2004)6.1 ResultsTable 3 shows the classification results consider-ing various feature combinations for different clas-sifiers and other systems.
These are:?
Unigram (with principal components of uni-gram feature vectors),?
Sarcasm (the feature-set reported by Joshi etal.
(2015) subsuming unigram features andfeatures from other reported systems)?
Gaze (the simple and complex cognitive fea-tures we introduce, along with readabilityand word count features), and?
Gaze+Sarcasm (the complete set of features).110170 80 90 10060657075Training data %Avg.F-Score70 80 90 1000.20.4Training data %Avg.Kappa(a) (b)Unigrams GazeSarcasm Sarcasm+GazeFigure 3: Effect of training data size on classifica-tion in terms of (a) F-score and (b) Kappa statistics20 40 60 80 100RED*RDSH**ED**FC**PSS**RSH**PSH*+VE*F1S**SKIP**SL**F1H**RSS*IMP*F2S*UNILEN*F2H**LREG**FDUR*X: Avg.
Merit (Chi-squared)Y:Features20 40 60 80*RSDH**RSDS**ED**PSS**FC**RSH**F1S**PSH**SKIP*+VE*SL**RSS**F1H**F2S*IMP*F2H*UNILEN*LREG**FDUR*X: Avg.
Merit (InfoGain)Y:FeaturesFigure 4: Significance of features observed byranking the features using Attribute Evaluationbased on Information Gain and Attribute Evalu-ation based on Chi-squared test.
The length of thebar corresponds to the average merit of the feature.Features marked with * are gaze features.For all regular classifiers, the gaze features areaveraged across participants and augmented withlinguistic and sarcasm related features.
For theMILR classifier, the gaze features derived fromeach participant are augmented with linguistic fea-tures and thus, a multi instance ?bag?
of features isformed for each sentence in the training data.
Thismulti-instance dataset is given to an MILR clas-sifier, which follows the standard multi instanceassumption to derive class-labels for each bag.For all the classifiers, our feature combinationoutperforms the baselines (considering only uni-gram features) as well as (Joshi et al, 2015), withthe MILR classifier getting an F-score improve-ment of 3.7% and Kappa difference of 0.08.
Wealso achieve an improvement of 2% over the base-line, using SVM classifier, when we employ ourfeature set.
We also observe that the gaze fea-tures alone, also capture the differences betweensarcasm and non-sarcasm classes with a high-precision but a low recall.To see if the improvement obtained is statisti-cally significant over the state-of-the art systemwith textual sarcasm features alone, we performMcNemar test.
The output of the SVM classifierusing only linguistic features used for sarcasm de-tection by Joshi et al (2015) and the output of theMILR classifier with the complete set of featuresare compared, setting threshold ?
= 0.05.
Therewas a significant difference in the classifier?s accu-racy with p(two-tailed) = 0.02 with an odds-ratioof 1.43, showing that the classification accuracyimprovement is unlikely to be observed by chancein 95% confidence interval.6.2 Considering Reading Time as a CognitiveFeature along with Sarcasm FeaturesOne may argue that, considering simple measuresof reading effort like ?reading time?
as cognitivefeature instead of the expensive eye-tracking fea-tures for sarcasm detection may be a cost-effectivesolution.
To examine this, we repeated our ex-periments with ?reading time?
considered as theonly cognitive feature, augmented with the tex-tual features.
The F-scores of all the classifiersturn out to be close to that of the classifiers con-sidering sarcasm feature alone and the differencein the improvement is not statistically significant(p > 0.05).
One the other hand, F-scores withgaze features are superior to the F-scores whenreading time is considered as a cognitive feature.6.3 How Effective are the Cognitive FeaturesWe examine the effectiveness of cognitive featureson the classification accuracy by varying the inputtraining data size.
To examine this, we create a1102stratified (keeping the class ratio constant) randomtrain-test split of 80%:20%.
We train our classifierwith 100%, 90%, 80% and 70% of the trainingdata with our whole feature set, and the featurecombination from Joshi et al (2015).
The good-ness of our system is demonstrated by improve-ments in F-score and Kappa statistics, shown inFigure 3.We further analyze the importance of featuresby ranking the features based on (a) Chi squaredtest, and (b) Information Gain test, using Weka?sattribute selection module.
Figure 4 shows the top20 ranked features produced by both the tests.
Forboth the cases, we observe 16 out of top 20 fea-tures to be gaze features.
Further, in each of thecases, Average Fixation Duration per Word andLargest Regression Position are seen to be the twomost significant features.6.4 Example CasesTable 4 shows a few example cases from the ex-periment with stratified 80%-20% train-test split.?
Example sentence 1 is sarcastic, and requiresextra-linguistic knowledge (about poor livingconditions at Manchester).
Hence, the sar-casm detector relying only on textual featuresis unable to detect the underlying incongruity.However, our system predicts the label suc-cessfully, possibly helped by the gaze fea-tures.?
Similarly, for sentence 2, the false sense ofpresence of incongruity (due to phrases like?Helped me?
and ?Can?t stop?)
affects thesystem with only linguistic features.
Our sys-tem, though, performs well in this case also.?
Sentence 3 presents a false-negative casewhere it was hard for even humans to get thesarcasm.
This is why our gaze features (andsubsequently the complete set of features) ac-count for erroneous prediction.?
In sentence 4, gaze features alone false-indicate presence of incongruity, whereas thesystem predicts correctly when gaze and lin-guistic features are taken together.From these examples, it can be inferred that,only gaze features would not have sufficed to ruleout the possibility of detecting other forms of in-congruity that do not result in sarcasm.6.5 Error AnalysisErrors committed by our system arise from mul-tiple factors, starting from limitations of the eye-tracker hardware to errors committed by linguis-tic tools and resources.
Also, aggregating vari-ous eye-tracking parameters to extract the cogni-tive features may have caused information loss inthe regular classification setting.7 ConclusionIn the current work, we created a novel frame-work to detect sarcasm, that derives insights fromhuman cognition, that manifests over eye move-ment patterns.
We hypothesized that distinctiveeye-movement patterns, associated with readingsarcastic text, enables improved detection of sar-casm.
We augmented traditional linguistic fea-tures with cognitive features obtained from read-ers?
eye-movement data in the form of simplegaze-based features and complex features derivedfrom a graph structure.
This extended feature-setimproved the success rate of the sarcasm detectorby 3.7%, over the best available system.
Usingcognitive features in an NLP Processing systemlike ours is the first proposal of its kind.Our general approach may be useful in otherNLP sub-areas like sentiment and emotion anal-ysis, text summarization and question answering,where considering textual clues alone does notprove to be sufficient.
We propose to augment thiswork in future by exploring deeper graph and gazefeatures.
We also propose to develop models forthe purpose of learning complex gaze feature rep-resentation, that accounts for the power of indi-vidual eye movement patterns along with the ag-gregated patterns of eye movements.AcknowledgmentsWe thank the members of CFILT Lab, especiallyJaya Jha and Meghna Singh, and the students ofIIT Bombay for their help and support.ReferencesFrancesco Barbieri, Horacio Saggion, and FrancescoRonzano.
2014.
Modelling sarcasm in twitter, anovel approach.
ACL 2014, page 50.Dale J Barr, Roger Levy, Christoph Scheepers, andHarry J Tily.
2013.
Random effects structure forconfirmatory hypothesis testing: Keep it maximal.Journal of memory and language, 68(3):255?278.1103C.
Christine Camblin, Peter C. Gordon, and Tamara Y.Swaab.
2007.
The interplay of discourse congru-ence and lexical association during sentence pro-cessing: Evidence from {ERPs} and eye tracking.Journal of Memory and Language, 56(1):103 ?
128.John D Campbell and Albert N Katz.
2012.
Are therenecessary conditions for inducing a sense of sarcas-tic irony?
Discourse Processes, 49(6):459?480.Paula Carvalho, Lu?
?s Sarmento, M?ario J Silva, andEug?enio De Oliveira.
2009.
Clues for detect-ing irony in user-generated contents: oh...!!
it?sso easy;-).
In Proceedings of the 1st internationalCIKM workshop on Topic-sentiment analysis formass opinion, pages 53?56.
ACM.Chih-Chung Chang and Chih-Jen Lin.
2011.
LIB-SVM: A library for support vector machines.
ACMTransactions on Intelligent Systems and Technology,2:27:1?27:27.
Software available at http://www.csie.ntu.edu.tw/?cjlin/libsvm.Herbert H Clark and Richard J Gerrig.
1984.
On thepretense theory of irony.Corinna Cortes and Vladimir Vapnik.
1995.
Support-vector networks.
Machine learning, 20(3):273?297.Dmitry Davidov, Oren Tsur, and Ari Rappoport.
2010.Semi-supervised recognition of sarcastic sentencesin twitter and amazon.
In Proceedings of the Four-teenth Conference on Computational Natural Lan-guage Learning, pages 107?116.
Association forComputational Linguistics.Hartmut; Wallington Katie; Page Jemma Filik,Ruth; Leuthold.
2014.
Testing theories of ironyprocessing using eye-tracking and erps.
Journal ofExperimental Psychology: Learning, Memory, andCognition, 40(3):811?828.Rudolph Flesch.
1948.
A new readability yardstick.Journal of applied psychology, 32(3):221.Raymond W. Gibbs.
1986.
Comprehension and mem-ory for nonliteral utterances: The problem of sarcas-tic indirect requests.
Acta Psychologica, 62(1):41 ?57.Rachel Giora.
1995.
On irony and negation.
Discourseprocesses, 19(2):239?264.Roberto Gonz?alez-Ib?anez, Smaranda Muresan, andNina Wacholder.
2011.
Identifying sarcasm in twit-ter: a closer look.
In Proceedings of the 49th An-nual Meeting of the Association for ComputationalLinguistics: Human Language Technologies: shortpapers-Volume 2, pages 581?586.
Association forComputational Linguistics.Mark Hall, Eibe Frank, Geoffrey Holmes, BernhardPfahringer, Peter Reutemann, and Ian H Witten.2009.
The weka data mining software: an update.ACM SIGKDD explorations newsletter, 11(1):10?18.Kenneth Holmqvist, Marcus Nystr?om, Richard An-dersson, Richard Dewhurst, Halszka Jarodzka, andJoost Van de Weijer.
2011.
Eye tracking: A com-prehensive guide to methods and measures.
OxfordUniversity Press.Stacey L Ivanko and Penny M Pexman.
2003.
Contextincongruity and irony processing.
Discourse Pro-cesses, 35(3):241?279.Julia Jorgensen, George A Miller, and Dan Sperber.1984.
Test of the mention theory of irony.
Journalof Experimental Psychology: General, 113(1):112.Aditya Joshi, Vinita Sharma, and Pushpak Bhat-tacharyya.
2015.
Harnessing context incongruityfor sarcasm detection.
Proceedings of 53rd AnnualMeeting of the Association for Computational Lin-guistics, Beijing, China, page 757.Aditya Joshi, Pushpak Bhattacharyya, and Mark JamesCarman.
2016.
Automatic sarcasm detection: Asurvey.
CoRR, abs/1602.03426.Marta Kutas and Steven A Hillyard.
1980.
Readingsenseless sentences: Brain potentials reflect seman-tic incongruity.
Science, 207(4427):203?205.Christine Liebrecht, Florian Kunneman, and Antalvan den Bosch.
2013.
The perfect solution fordetecting sarcasm in tweets# not.
WASSA 2013,page 29.Diana Maynard and Mark A Greenwood.
2014.
Whocares about sarcastic tweets?
investigating the im-pact of sarcasm on sentiment analysis.
In Proceed-ings of LREC.Abhijit Mishra, Diptesh Kanojia, and Pushpak Bhat-tacharyya.
2016.
Predicting readers?
sarcasm un-derstandability by modeling gaze behavior.
In Pro-ceedings of AAAI.Bo Pang and Lillian Lee.
2004.
A sentimental educa-tion: Sentiment analysis using subjectivity summa-rization based on minimum cuts.
In Proceedings ofthe 42nd annual meeting on Association for Compu-tational Linguistics, page 271.
Association for Com-putational Linguistics.Keith Rayner and Sara C Sereno.
1994.
Eye move-ments in reading: Psycholinguistic studies.Ellen Riloff, Ashequl Qadir, Prafulla Surve, Lalin-dra De Silva, Nathan Gilbert, and Ruihong Huang.2013.
Sarcasm as contrast between a positive senti-ment and negative situation.
In EMNLP, pages 704?714.Xin Xu and Eibe Frank.
2004.
Logistic regression andboosting for labeled bags of instances.
In Advancesin knowledge discovery and data mining, pages 272?281.
Springer.1104
