Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 675?685,Avignon, France, April 23 - 27 2012. c?2012 Association for Computational LinguisticsIdentifying Broken Plurals, Irregular Gender,and Rationality in Arabic TextSarah Alkuhlani and Nizar HabashCenter for Computational Learning SystemsColumbia University{sma2149,nh2142}@columbia.eduAbstractArabic morphology is complex, partly be-cause of its richness, and partly becauseof common irregular word forms, such asbroken plurals (which resemble singularnouns), and nouns with irregular gender(feminine nouns that look masculine andvice versa).
In addition, Arabic morpho-syntactic agreement interacts with the lex-ical semantic feature of rationality, whichhas no morphological realization.
In thispaper, we present a series of experimentson the automatic prediction of the latentlinguistic features of functional gender andnumber, and rationality in Arabic.
We com-pare two techniques, using simple maxi-mum likelihood (MLE) with back-off anda support vector machine based sequencetagger (Yamcha).
We study a number oforthographic, morphological and syntacticlearning features.
Our results show thatthe MLE technique is preferred for wordsseen in the training data, while the Yam-cha technique is optimal for unseen words,which are our real target.
Furthermore, weshow that for unseen words, morphologicalfeatures help beyond orthographic featuresand that syntactic features help even more.A combination of the two techniques im-proves overall performance even further.1 IntroductionArabic morphology is complex, partly becauseof its richness, and partly because of its com-plex morpho-syntactic agreement rules which de-pend on functional features not necessarily ex-pressed in word forms.
Particularly challeng-ing are broken plurals (which resemble singu-lar nouns), nouns with irregular gender (mascu-line nouns that look feminine and feminine nounsthat look masculine), and the semantic featureof rationality, which has no morphological re-alization (Smr?, 2007b; Alkuhlani and Habash,2011).
These features heavily participate in Ara-bic morpho-syntactic agreement.
Alkuhlani andHabash (2011) show that without proper model-ing, Arabic agreement cannot be accounted forin about a third of all noun-adjective pairs anda quarter of verb-subject pairs.
They also reportthat over half of all plurals in Arabic are irregular,8% of nominals have irregular gender and almosthalf of all proper nouns and 5% of all nouns arerational.In this paper, we present results on the taskof automatic identification of functional gender,number and rationality of Arabic words in con-text.
We consider two supervised learning tech-niques: a simple maximum-likelihood model withback-off (MLE) and a support-vector-machine-based sequence tagger, Yamcha (Kudo and Mat-sumoto, 2003).
We consider a large number oforthographic, morphological and syntactic learn-ing features.
Our results show that the MLE tech-nique is preferred for words seen in the trainingdata, while the Yamcha technique is optimal forunseen words, which are our real target.
Further-more, we show that for unseen words, morpho-logical features help beyond orthographic featuresand that syntactic features help even more.
Acombination of the two techniques improves over-all performance even further.This paper is structured as follows: Sec-tions 2 and 3 present relevant linguistic facts andrelated work, respectively.
Section 4 presents thedata collection we use and the metrics we target.Section 5 discusses our approach.
And Section 6presents our results.675VRB??
?J?SBJ OBJ MODNOM NOM PRTH.
AJ??
@ A???
?
?MOD MOD OBJNOM NOM NOM	??JKYm?
'@ ?YKYg.
??Jj.
??
@MOD MODNOM NOM?G.
Q??
@ ??'Y??
@Word ystlhm AlktAb AlHdy?wn qSSA jdydh?
mn Almjtm?
Al?rby AlqdymForm MS MS MP MS FS NaNa MS MS MSFunc MSN MPR MPN FPI FSN NaNaNa MSI MSN MSNGloss be-inspired the-writers the-modern stories new from culture Arab ancientEnglish ?Modern writers are inspired by ancient Arab culture to write new stories .
?Figure 1: An example Arabic sentence showing its dependency representation together with the form-based andfunctional gender and number features and rationality.
The dependency tree is in the CATiB treebank represen-tation (Habash and Roth, 2009).
The shown POS tags are VRB ?verb?, NOM ?nominal (noun/adjective)?, andPRT ?particle?.
The relations are SBJ ?subject?, OBJ ?object?
and MOD ?modifier?.
The form-based featuresare only for gender and number.2 Linguistic FactsArabic has a rich and complex morphology.
Inaddition to being both templatic (root/pattern) andconcatenative (stems/affixes/clitics), Arabic?s op-tional diacritics add to the degree of word ambi-guity.
We focus on two problems of Arabic mor-phology: the discrepancy between morphologicalform and function; and the complexity of morpho-syntactic agreement rules.2.1 Form and FunctionArabic nominals (i.e.
nouns, proper nouns andadjectives) and verbs inflect for gender: mascu-line (M ) and feminine (F ), and for number: sin-gular (S), dual (D) and plural (P ).
These featuresare regularly expressed using a set of suffixes thatuniquely convey gender and number combina-tions: +?
(MS), ?+ +h?1 (FS), 	?
?+ +wn (MP ),and H@+ +At (FP ).
For example, the adjectiveQ?A?
mAhr ?clever?
has the following forms amongothers: Q?A?
mAhr (MS), ?Q?A?
mAhrh?
(FS),1Arabic transliteration is presented in the Habash-Soudi-Buckwalter (HSB) scheme (Habash et al 2007): (in alpha-betical order) Abt?jHxd?rzs?SDT ?D?
?fqklmnhwy and the ad-ditional symbols: ?
Z, ?
@, ?A @, ?A@, w??
', y?
Z?
', h?
?, ?
?.??Q?A?
mAhrwn (MP ), and H@Q?A?
mAhrAt(FP ).
For a sizable minority of words, thesefeatures are expressed templatically, i.e., throughpattern change, coupled with some singular suf-fix.
A typical example of this phenomenon is theclass of broken plurals, which accounts for overhalf of all plurals (Alkuhlani and Habash, 2011).In such cases, the form of the morphology (sin-gular suffix) is inconsistent with the word?s func-tional number (plural).
For example, the wordI.
KA?
kAtb (MS) ?writer?
has the broken plural:H. AJ?
ktAb ( MSMP ).2 See the second word in the ex-ample in Figure 1, which is the word H. AJ?
ktAb?writers?
prefixed with the definite article Al+.
Inaddition to broken plurals, Arabic has words withirregular gender, e.g., the feminine singular ad-jective ?red?
Z @Q?g HmrA?
(MSFS ), and the nouns?
?J?
g xlyfh?
( FSMS ) ?caliph?
and ?
?Ag HAml (MSFS )?pregnant?.
Verbs and nominal duals do not dis-play this discrepancy.2.2 Morpho-syntactic AgreementArabic gender and number features participate inmorpho-syntactic agreement within specific con-2This nomenclature denotes ( F ormF unction ).676structions such as nouns with their adjectivesand verbs with their subjects.
Arabic agreementrules are more complex than the simple match-ing rules found in languages such as Spanish(Holes, 2004; Habash, 2010).
For instance, Ara-bic adjectives agree with the nouns they mod-ify in gender and number except for plural ir-rational (non-human) nouns, which always takefeminine singular adjectives.
Rationality (?hu-manness?
???A?
Q?/??A??)
is a morpho-lexicalfeature that is narrower than animacy.
Englishexpresses it mainly in pronouns (he/she vs. it)and relativizers (men who... vs. cars/cowswhich...).
We follow the convention by Alkuh-lani and Habash (2011) who specify rationalityas part of the functional features of the word.The values of this feature are: rational (R), irra-tional (I), and not-specified (N ).
N is assigned toverbs, adjectives, numbers and quantifiers.3 Forexample, in Figure 1, the plural rational nounH.
AJ??
@ AlktAb ( MSMPR ) ?writers?
takes the pluraladjective 	??JKYm?
'@ AlHdy?wn ( MPMPN ) ?modern?
;while the plural irrational word A???
qSSA ?sto-ries?
( MSFPI ) takes the feminine singular adjective?YKYg.
jdydh?
( FSFSN ).3 Related WorkMuch work has been done on Arabic morpholog-ical analysis, morphological disambiguation andpart-of-speech (POS) tagging (Al-Sughaiyer andAl-Kharashi, 2004; Soudi et al 2007; Habash,2010).
The bulk of this work does not addressform-function discrepancy or morpho-syntacticagreement issues.
This includes the most com-monly used resources and tools for Arabic NLP:the Buckwalter Arabic Morphological Analyzer(BAMA) (Buckwalter, 2004) which is used in thePenn Arabic Tree Bank (PATB) (Maamouri et al2004), and the various POS tagging and morpho-logical disambiguation tools trained using them(Diab et al 2004; Habash and Rambow, 2005).There are some important exceptions (Goweder etal., 2004; Habash, 2004; Smr?, 2007b; Elghamryet al 2008; Abb?s et al 2004; Attia, 2008;3We previously defined the rationality value N as not-applicable when we only considered nominals (Alkuhlaniand Habash, 2011).
In this work, we rename the rationalityvalue N as not-specified without changing its meaning.
Weuse the value Na (not-applicable) for parts-of-speech thatdo not have a meaningful value for any feature, e.g., prepo-sitions have gender, number and rationality values of Na.Altantawy et al 2010; Alkuhlani and Habash,2011).In terms of resources, Smr?
(2007b)?s workcontrasting illusory (form) features and functionalfeatures inspired our distinction of morphologi-cal form and function.
However, unlike him, wedo not distinguish between sub-functional (logi-cal and formal) features.
His ElixirFM analyzer(Smr?, 2007a) extends BAMA by including func-tional number and some functional gender infor-mation, but not rationality.
This analyzer wasused as part of the annotation of the Prague Ara-bic Dependency Treebank (PADT) (Smr?
and Ha-jic?, 2006).
More recently, Alkuhlani and Habash(2011) built on the work of Smr?
(2007b) and ex-tended beyond it to fully annotate functional gen-der, number and rationality in the PATB part 3.We use their resource to train and evaluate oursystem.In terms of techniques, Goweder et al(2004)investigated several approaches using root andpattern morphology for identifying broken plu-rals in undiacritized Arabic text.
Their effort re-sulted in an improved stemming system for Ara-bic information retrieval that collapses singularsand plurals.
They report results on identifyingbroken plurals out of context.
Similar to them,we undertake the task of identifying broken plu-rals; however, we also target the templatic gen-der and rationality features, and we do this in-context.
Elghamry et al(2008) presented an auto-matic cue-based algorithm that uses bilingual andmonolingual cues to build a web-extracted lexi-con enriched with gender, number and rationalityfeatures.
Their automatic technique achieves anF-score of 89.7% against a gold standard set.
Un-like them, we use a manually annotated corpus totrain and test the prediction of gender, number andrationality features.Our approach to identifying these features ex-plores a large set of orthographic, morphologicaland syntactic learning features.
This is very muchfollowing several previous efforts in Arabic NLPin which different tagsets and morphological fea-tures have been studied for a variety of purposes,e.g., base phrase chunking (Diab, 2007) and de-pendency parsing (Marton et al 2010).
In thispaper we use the parser of Marton et al(2010)as our source of syntactic learning features.
Wefollow their splits for training, development andtesting.6774 Problem DefinitionOur goal is to predict the functional gender, num-ber and rationality features for all words.4.1 Corpus and Experimental SettingsWe use the corpus of Alkuhlani and Habash(2011), which is based on the PATB.
The corpuscontains around 16.6K sentences and over 400Ktokens.
We use the train/development/test splitsof Marton et al(2010).
We train on a quarter ofthe training set and classify words in sequence.We only use a portion of the training data to in-crease the percentage of words unseen in training.We also compare to using all of the training datain Section 6.7.Our data is gold tokenized; however, all ofthe features we use are predicted using MADA(Habash and Rambow, 2005) following the workof Marton et al(2010).
Words whose tags are un-known in the training set are excluded from theevaluation, but not training.
In terms of ambigu-ity, the percentage of word types with ambiguousgender, number and rationality in the train set is1.35%, 0.79%, and 4.8% respectively.
These per-centages are consistent with how we perform onthese features, with number being the easiest andrationality the hardest.4.2 MetricsWe report all results in terms of token accuracy.Evaluation is done for the following sets: allwords, seen words, and unseen words.
A word isconsidered seen if it is in the training data regard-less of whether it appears with the same lemmaand POS tag or not.
Defining seen words this waymakes the decision on whether a word is seen orunseen unaffected by lemma and/or POS predic-tion errors in the development and test sets.
Us-ing our definition of seen words, 34.3% of wordstypes (and 10.2% of word tokens) in the devel-opment set have not been seen in quarter of thetraining set.We train single classifiers for G (gender), N(number), R (rationality), GN and GNR, and eval-uate them.
We also combine the tags of the sin-gle classifiers into larger tags (G+N, GN+R andG+N+R).5 ApproachOur approach involves using two techniques:MLE with back-off and Yamcha.
For each tech-nique, we explore the effects of different learningfeatures and try to come up with the best tech-nique and feature set for each target feature.5.1 Learning FeaturesWe investigate the contribution of different learn-ing features in predicting functional gender, num-ber and rationality features.
The learning featuresare explored in the following order:Orthographic Features These features are or-ganized in two sets: W1 is the unnormalized formof the word, and W2 includes W1 plus letter n-grams.
The n-grams used are the first letter, firsttwo letters, last letter, and last two letters of theword form.
We tried using the Alif/Ya normalizedforms of the words (Habash, 2010), but these be-haved consistently worse than the unnormalizedforms.Morphological Features We explore the fol-lowing morphological features inspired by thework of Marton et al(2010):?
POS tags.
We experiment with different POStag sets: CATiB-6 (6 tags) (Habash et al 2009),CATiB-EX (44 tags), Kulick (34 tags) (Kulick etal., 2006), Buckwalter (BW) (Buckwalter, 2004),which is the tag used in the PATB (430 tags),and a reduced form of BW tag that ignores caseand mood (BW-) (217 tags).
These tags differ intheir granularity and range from very specific tags(Buckwalter) to more general tags (CATiB).?
Lemma.
We use the diacritized lemma(Lemma), and the normalized and undiacritizedform of the lemma, the LMM (LMM).?
Form-based features.
Form-based features(F) are extracted from the word form and do notnecessarily reflect functional features.
These fea-tures are form-based gender, form-based number,person and the definite article.Syntactic Features We use the following syn-tactic features (SYN) derived from the CATiB de-pendency version of the PATB (Habash and Roth,2009): parent, dependency relation, order of ap-pearance (the word comes before or after its par-ent), the distance between the word and its parent,and the parent?s orthographic and morphologicalfeatures.678For all of these features, we train on gold val-ues, but only experiment with predicted values inthe development and test sets.
For predicting mor-phological features, we use the MADA system(Habash and Rambow, 2005).
The MADA sys-tem corrects for suboptimal orthographic choicesand effectively produces a consistent and unnor-malized orthography.
For the syntactic features,we use Marton et al(2010)?s system.5.2 TechniquesWe describe below the two techniques we ex-plored.MLE with Back-off We implemented an MLEsystem with multiple back-off modes using ourset of linguistic features.
The order of the back-offis from specific to general.
We start with an MLEsystem that uses only the word form, and backsoff to the most common feature value across allwords (excluding unknown and Na values).
Thissimple MLE system is used as a baseline.As we add more features to the MLE system,it tries to match all these features to predict thevalue for a given word.
If such a combination offeatures is not seen in the training set, the sys-tem backs off to a more general combination offeatures.
For example, if an MLE system is us-ing the features W2+LMM+BW, the system triesto match this combination.
If it is not seen intraining, the system backs off to the following set:LMM+BW, and tries to return the most commonvalue for this POS tag and lemma combination.
Ifagain it fails to find a match, it backs off to BW,and returns the most common value for that par-ticular POS tag.
If no word is seen with this POStag, the system returns the most common valueacross all words.Yamcha Sequence Tagger We use Yamcha(Kudo and Matsumoto, 2003), a support-vector-machine-based sequence tagger.
We perform dif-ferent experiments with the different sets of fea-tures presented above.
After that, we apply aconsistency filter that ensures that every word-lemma-pos combination always gets the samevalue for gender, number and rationality features.Yamcha in its default settings tags words using awindow of two words before and two words af-ter the word being tagged.
This gives Yamcha anadvantage over the MLE system which tags eachword independently.Single vs Joint Classification In this paper, weonly discuss systems trained for a single classifier(for gender, for number and for rationality).
Inexperiments we have done, we found that trainingsingle classifiers and combining their outcomesalmost always outperforms a single joint classi-fier for the three target features.
In other words,combining the results of G and N (G+N) outper-forms the results of the single classifier GN.
Thesame is also true for G+N+R, which outperformsGNR and GN+R.
Therefore, we only present theresults for the single classifiers G, N, R and theircombination G+N+R.6 ResultsWe perform a series of experiments increasing infeature complexity.
We greedily select which fea-tures to pass on to the next level of experiments.In cases of ties, we pass the top two performersto the next step.
We discuss each of these exper-iments next for both the MLE and Yamcha tech-niques.
Statistical significance is measured usingthe McNemar test of statistical significance (Mc-Nemar, 1947).6.1 Experiment Set I: OrthographicFeaturesThe first set of experiments uses the orthographicfeatures.
See Table 1.
The MLE system with theword only feature (W1) is effectively our base-line.
It does surprisingly well for seen cases.
Infact it is the highest performer across all exper-iments in this paper for seen cases.
For unseencases, it produces a miserable and expected lowscore of 21.0% accuracy.
The addition of the n-gram features (W2) improves statistically signif-icantly over W1 for unseen cases, but it is indis-tinguishable for seen cases.
The Yamcha systemshows the same difference in results between W1and W2.Across the two sets of features, the MLE sys-tem consistently outperforms Yamcha in the caseof seen words, while Yamcha does better for un-seen words.
This can be explained by the fact thatthe MLE system matches only on the word formand if the word is unseen, it backs off to the mostcommon value across all words.
Moreover, Yam-cha uses some limited context information that al-lows it to generalize for unseen words.Among the target features, number is the easi-est to predict, while rationality is the hardest.679MLE YamchaG N R G+N+R G N R G+N+RFeatures seen unseen seen unseen seen unseen seen unseen seen unseen seen unseen seen unseen seen unseenW1 99.2 61.6 99.3 69.2 97.4 44.7 97.0 21.0 95.9 67.8 96.7 72.0 94.5 67.4 90.2 35.2W2 99.2 81.7 99.3 81.6 97.4 63.4 97.0 49.1 97.1 86.6 97.7 87.1 95.6 82.0 92.8 65.5Table 1: Experiment Set I: Baselines and simple orthographic features.
W1 is the word only.
W2 is the wordwith additional 1-gram and 2-gram prefix and suffix features.
All numbers are accuracy percentages.MLE YamchaG N R G+N+R G N R G+N+RFeatures seen unseen seen unseen seen unseen seen unseen seen unseen seen unseen seen unseen seen unseenW2+F 99.2 86.9 99.3 88.9 97.4 63.4 96.9 51.9 97.7 89.8 98.1 91.7 96.0 83.5 93.8 72.0W2+Lemma 97.4 68.3 97.6 71.5 95.6 70.3 95.2 33.8 97.4 86.8 97.7 86.4 96.1 82.2 93.3 65.4W2+LMM 99.1 68.8 99.3 71.7 97.2 67.6 96.8 33.2 97.5 86.7 97.9 86.6 96.1 82.6 93.5 65.7W2+CATIB 99.1 85.0 99.3 83.8 97.4 70.0 97.1 56.2 97.5 87.9 98.0 88.6 96.0 83.5 93.6 69.7W2+CATIB-EX 99.1 85.7 99.3 84.3 97.4 70.4 97.1 56.7 97.5 88.0 97.9 88.1 96.0 83.6 93.6 69.9W2+Kulick 99.0 86.7 99.1 85.6 97.1 78.7 96.7 65.5 97.3 88.8 97.9 89.4 95.8 83.5 93.3 70.9W2+BW- 99.0 88.8 99.0 88.8 97.0 80.7 96.6 68.5 97.5 89.7 98.0 91.2 96.0 85.2 93.7 73.2W2+BW 98.6 87.9 98.5 88.8 96.8 80.3 95.9 67.8 97.5 89.5 97.9 89.5 96.1 85.7 93.7 72.8Table 2: Experiment Set II.a: Morphological features: (i) form-based gender and number, (ii) lemma and LMM(undiacritized lemma) and (iii) a variety of POS tag sets.
For each subset, the best performers are bolded.6.2 Experiment Set II: MorphologicalFeaturesIndividual Morphological Features In this setof experiments, we use our best system from theprevious set, W2, and add individual morpholog-ical features to it.
We organize these features inthree sub-groups: (i) form-based features (F), (ii)lemma and LMM, and (iii) the five POS tag sets.See Table 2.The F, Lemma and LMM improve over thebaseline in terms of unseen words for both MLEand Yamcha techniques.
However, for seenwords, these systems do worse than or equal to thebaseline when the MLE technique is used.
TheMLE system in these cases tries to match the wordand its morphological features as a single unit andif such a combination is not seen, it backs off tothe morphological feature which is more general.Since we are using predicted data, prediction er-rors could be the reason behind this decrease inaccuracy for seen words.
Among these systems,W2+F is the best for both Yamcha and MLE ex-cept for rationality which is expected since thereare no form-based features for rationality.
In thisset of experiments, Yamcha consistently outper-forms MLE when it comes to unseen words, butfor seen words, MLE does better almost always.LMM overall does better than Lemma.
This isreasonable given that LMM is easier to predict;although LMM is more ambiguous.As for the POS tag sets, looking at the MLEresults, CATIB-EX is the best performer for seenwords, and BW- is the best for unseen.
CATIB-6is a general POS tag set and since the MLE tech-nique is very strict in its matching process (an ex-act match or no match), using a general key tomatch on adds a lot of ambiguity.
With Yamcha,BW and BW- are the best among all POS.
Yamchais still doing consistently better in terms of unseenwords.
The best two systems from both Yamchaand MLE are used as the basic systems for thenext subset of experiments where we combine themorphological features.Combined Morphological Features Until thispoint, all experiments using the two techniquesare similar.
In this subset, MLE explores the ef-fect of using the CATIB-EX and BW- with othermorphological features.
And Yamcha exploresthe effect of using BW- and BW with other mor-phological features.
See Table 3.
Again, Yamchais still doing consistently better in terms of unseenwords, but when it comes to seen words, MLEperforms better.
For seen words, our best resultscome from MLE using CATIB-EX and LMM.
Forunseen words, our best results come from Yam-cha with the BW- tag and the form-based features680MLE YamchaFeatures: G N R G+N+R Features: G N R G+N+RW2 seen unseen seen unseen seen unseen seen unseen W2 seen unseen seen unseen seen unseen seen unseen+CATIB-EX 99.1 85.7 99.3 84.3 97.4 70.4 97.0 56.7 +BW 97.5 89.5 97.9 89.5 96.1 85.7 93.7 72.8+F 98.7 88.6 99.1 89.4 94.9 70.4 94.3 59.7 +F 97.8 90.6 98.2 92.4 96.3 85.3 94.2 75.4+LMM 99.1 78.9 99.3 80.4 97.3 69.6 96.9 44.7 +LMM 97.6 88.9 98.1 88.9 96.5 85.7 94.1 72.3+LMM+F 98.7 89.9 99.0 89.7 94.8 69.6 94.2 58.1 +LMM+F 98.1 90.4 98.4 92.5 96.7 85.8 94.8 75.9+BW- 99.0 88.8 99.0 88.8 97.0 80.7 96.6 68.5 +BW- 97.5 89.7 98.0 91.2 96.0 85.2 93.7 73.2+F 99.0 88.8 99.1 89.9 97.0 80.7 96.6 69.6 +F 97.7 90.7 98.2 92.5 96.1 85.6 94.0 75.3+LMM 98.9 90.0 99.0 88.0 97.0 83.6 96.6 69.8 +LMM 97.7 89.6 98.1 90.4 96.2 85.1 94.0 72.5+LMM+F 98.9 90.0 99.0 89.1 97.0 83.6 96.6 70.8 +LMM+F 98.0 90.3 98.2 92.4 96.5 85.7 94.5 75.1Table 3: Experiment Set II.b: Combining different morphological features.YamchaG N R G+N+RFeatures: seen unseen seen unseen seen unseen seen unseenW2 +BW +F+SYN 97.3 90.6 97.8 92.5 96.1 86.1 93.5 76.0W2 +BW +LMM+SYN 97.4 89.1 97.5 88.3 96.2 86.0 93.4 71.7W2 +BW +LMM+F+SYN 97.5 90.8 98.0 92.5 96.4 86.2 93.8 76.2W2 +BW- +F+SYN 97.4 90.7 97.9 92.7 96.1 85.2 93.5 75.0W2 +BW- +LMM+SYN 97.4 89.5 97.7 89.8 96.1 85.7 93.4 72.1W2 +BW- +LMM+F+SYN 97.4 90.8 97.9 92.7 96.2 85.3 93.6 75.2Table 4: Experiment Set III: Syntactic features.for both gender and number.
For rationality, thebest features to use with Yamcha are BW, LMMand form-based features.
The lemma seems to ac-tually hurt when predicting gender and number.This can be explained by the fact that gender andnumber features are often properties of the wordform and not of the lemma.
This is different forrationality, which is a property of the lemma andtherefore, we expect the lemma to help.The fact that the predicted BW set helps is notconsistent with previous work by Marton et al(2010).
In that effort, BW helps parsing only inthe gold condition.
BW prediction accuracy islow because it includes case endings.
We pos-tulate that perhaps in our task, which is far morelimited than general parsing, errors in case pre-diction may not matter too much.
The more com-plex tag set may actually help establish good lo-cal agreement sequences (even if incorrect case-wise), which is relevant to the target features.6.3 Experiment Set III: Syntactic FeaturesThis set of experiments adds syntactic featuresto the experiments in set II.
We add syntax tothe systems that uses Yamcha only since it isnot obvious how to add syntactic information tothe MLE system.
Syntax improves the predic-tion accuracy for unseen words but not for seenwords.
In Yamcha, we can argue that the +/-2word window allows some form of shallow syn-tax modeling, which is why Yamcha is doing bet-ter from the start.
But the longer distance featuresare helping even more, perhaps because they cap-ture agreement relations.
The overall best systemfor unseen words is W2+BW+LMM+F+SYN,except for number, where W2+BW-+F+SYNis slightly better.
In terms of G+N+Rscores, W2+BW+LMM+F+SYN is statisticallysignificantly better than all other systems inthis set for seen and unseen words, ex-cept for unseen words with W2+BW+F+SYN.W2+BW+LMM+F+SYN is also statistically sig-nificantly better than its non-syntactic variant forboth seen and unseen words.
The prediction ac-curacy for seen words is still not as good as theMLE systems.6.4 System CombinationThe simple MLE W1 system, which happens to bethe baseline, is the best predictor for seen words,and the more advanced Yamcha system using syn-tactic features is the best predictor for unseenwords.
Next, we create a new system that takesadvantage of the two systems.
We use the sim-ple MLE W1 system for seen words, and Yam-cha with syntax for unseen words.
For unseen681words, since each target feature has its own set ofbest learning features, we also build a combina-tion system that uses the best systems for gender,number and rationality and combine their outputinto a single system for unseen words.
For genderand rationality, we use W2+BW+LMM+F+SYN,and for number, we use W2+BW-+F+SYN.
Asexpected the combination system outperforms thebasic systems.
For comparison: The MLE W1system gets an (all, seen, unseen) scores of (89.3,97.0, 21.0) for G+N+R, while the best singleYamcha syntactic system gets (92.0, 93.8, 76.2);the combination on the other hand gets (94.9,97.0, 76.2).
The overall (all) improvement overthe MLE baseline or the best Yamcha translatesinto 52% error reduction or 36% error reduction,respectively.6.5 Error AnalysisWe conducted an analysis of the errors in the out-put of the combination system as well as the twosystems that contributed to it.In the combination system, out of the total er-ror in G+N+R (5.1%), 53% of the cases are forseen words (3.0% of all seen) and 47% for unseenwords (23.8% of all unseen).
Overall, rational-ity errors are the biggest contributor to G+N+Rerror at 73% relative, followed by gender (33%relative) and number (26% relative).
Among er-ror cases of seen words, rationality errors soar to87% relative, almost four times the correspondinggender and number errors (27% and 22%, respec-tively).
However, among error cases of unseenwords, rationality errors are 57% relative, whilegender and number corresponding errors are (39%and 31%, respectively).
As expected, rational-ity is much harder to tag than gender and numberdue to its higher word-form ambiguity and depen-dence on context.We classified the type of errors in the MLE sys-tem for seen words, which we use in the combi-nation system.
We found that 86% of the G+N+Rerrors involve an ambiguity in the training datawhere the correct answer was present but not cho-sen.
This is an expected limitation of the MLE ap-proach.
In the rest of the cases, the correct answerwas not actually present in the training data.
Theproportion of ambiguity errors is almost identicalfor gender, number and rationality.
However ra-tionality overall is the biggest cause of error, sim-ply due to its higher degree of ambiguity.All seen unseenMLE W1 88.5 96.8 21.2Yamcha BW+LMM+F 91.4 94.1 70.4Yamcha BW+LMM+F+SYN 91.0 93.3 72.2Combination 94.1 96.8 72.4Table 5: Results on blind test.
Scores forAll/Seen/Unseen are shown for the G+N+R condition.We compare the MLE word baseline, with the bestYamcha system with and without syntactic featuresand the combined system.Since the Yamcha system uses MADA features,we investigated the effect of the correctness ofMADA features on the system prediction accu-racy.
The overall MADA accuracy in identifyingthe lemma and the Buckwalter tag together ?
avery harsh measure ?
is 77.0% (79.3% for seenand 56.8% for unseen).
Our error analysis showsthat when MADA is correct, the prediction ac-curacy for G+N+R is 95.6%, 96.5% and 84.4%for all, seen and unseen, respectively.
However,this accuracy goes down to 79.2%, 82.5% and65.5% for all, seen and unseen, respectively, whenMADA is wrong.
This suggests that the Yam-cha system suffers when MADA makes wrongchoices and improving MADA would lead to im-provement in the system?s performance.6.6 Blind TestFinally, we apply our baseline, best combinationmodel and best single Yamcha syntactic model(with and without syntax) to the blind test set.The results are in Table 5.
The results in the blindtest are consistent with the development set.
TheMLE baseline is best on seen words, Yamcha isbest on unseen words, syntactic features help inhandling unseen words, and overall combinationimproves over all specific systems.6.7 Additional Training DataAfter experimenting on quarter of the train set tooptimize for various settings, we train our com-bination system on the full train set and achieve(96.0, 96.8, 74.9) for G+N+R (all, seen, unseen)on the development set and (96.5, 96.8, 65.6)on the blind test set.
As expected, the overall(all) scores are higher simply due to the addi-tional training data.
The results on seen and un-seen words, which are redefined against the largertraining set, are not higher than results for thequarter training data.
Of course, these numbers682should not be compared directly.
The number ofunseen word tokens in the full train set is 3.7%compared to 10.2% in quarter of the train set.6.8 Comparison with MADAWe compare our results with the form-basedfeatures from the state-of-the-art morphologicalanalyzer MADA (Habash and Rambow, 2005).We use the form-based gender and number fea-tures produced by MADA after we filter MADAchoices by tokenization.
Since MADA does notgive a rationality value, we assign the value I (ir-rational) to nouns and proper nouns and the valueN (not-specified) to verbs and adjectives.
Every-thing else receives Na (not-applicable).
The POStags are determined by MADA.On the development set, MADA achieves(72.6, 73.1, 58.6) for G+N+R (all, seen, unseen),where the seen/unseen distinction is based on thefull training set in the previous section and is pro-vided for comparison reasons only.
The results forthe test set are (71.4, 72.2, 53.7).
These results areconsistent with our expectation that MADA willdo badly on this task since it is not designed forit (Alkuhlani and Habash, 2011).
We should re-mind the reader that MADA-derived features areused as machine learning features in this paper,where they actually help.
In the future, we plan tointegrate this task inside of MADA.6.9 Extrinsic EvaluationWe use the predicted gender, number and rational-ity features that we get from training on the fulltrain set in a dependency syntactic parsing exper-iment.
The parsing feature set we use is the bestperforming feature set described in (Marton et al2011), which used an earlier unpublished versionof our MLE model.
The parser we use is the Easy-First Parser (Goldberg and Elhadad, 2010).
Moredetails on this parsing experiment is in Marton etal.
(2012).The functional gender and number features in-crease the labeled attachment score by 0.4% abso-lute over a comparable model that uses the form-based gender and number features.
Rationality onthe other hand does not help much.
One possiblereason for this is the lower quality of the predictedrationality feature compared to the other features.Another possible reason is that the rationality fea-ture is not utilized optimally in the parser.7 Conclusions and Future WorkWe presented a series of experiments for auto-matic prediction of the latent features of func-tional gender and number, and rationality in Ara-bic.
We compared two techniques, a simple MLEwith back-off and an SVM-based sequence tag-ger, Yamcha, using a number of orthographic,morphological and syntactic features.
Our con-clusions are that for words seen in training, theMLE model does best; for unseen word, Yamchadoes best; and most interestingly, we found thatsyntactic features help the prediction for unseenwords.In the future, we plan to explore training on pre-dicted features instead of gold features to mini-mize the effect of tagger errors.
Furthermore, weplan to use our tools to collect vocabulary not cov-ered by commonly used morphological analyzersand try to assign them correct functional features.Finally, we would like to use our predictions forgender, number and rationality as learning fea-tures for relevant NLP applications such as senti-ment analysis, phrase-based chunking and namedentity recognition.AcknowledgmentsWe would like to thank Yuval Marton for helpwith the parsing experiments.
The first author wasfunded by a scholarship from the Saudi ArabianMinistry of Higher Education.
The rest of thework was funded under DARPA projects numberHR0011-08-C-0004 and HR0011-08-C-0110.ReferencesRamzi Abb?s, Joseph Dichy, and Mohamed Has-soun.
2004.
The Architecture of a Standard ArabicLexical Database.
Some Figures, Ratios and Cat-egories from the DIINAR.1 Source Program.
InAli Farghaly and Karine Megerdoomian, editors,COLING 2004 Computational Approaches to Ara-bic Script-based Languages, pages 15?22, Geneva,Switzerland, August 28th.
COLING.Imad Al-Sughaiyer and Ibrahim Al-Kharashi.
2004.Arabic Morphological Analysis Techniques: AComprehensive Survey.
Journal of the AmericanSociety for Information Science and Technology,55(3):189?213.Sarah Alkuhlani and Nizar Habash.
2011.
A Corpusfor Modeling Morpho-Syntactic Agreement in Ara-bic: Gender, Number and Rationality.
In Proceed-ings of the 49th Annual Meeting of the Association683for Computational Linguistics (ACL?11), Portland,Oregon, USA.Mohamed Altantawy, Nizar Habash, Owen Rambow,and Ibrahim Saleh.
2010.
Morphological Analy-sis and Generation of Arabic Nouns: A MorphemicFunctional Approach.
In Proceedings of the seventhInternational Conference on Language Resourcesand Evaluation (LREC), Valletta, Malta.Mohammed Attia.
2008.
Handling Arabic Morpho-logical and Syntactic Ambiguity within the LFGFramework with a View to Machine Translation.Ph.D.
thesis, The University of Manchester, Manch-ester, UK.Tim Buckwalter.
2004.
Buckwalter arabic morpho-logical analyzer version 2.0.
LDC catalog numberLDC2004L02, ISBN 1-58563-324-0.Mona Diab, Kadri Hacioglu, and Daniel Jurafsky.2004.
Automatic Tagging of Arabic Text: FromRaw Text to Base Phrase Chunks.
In Proceed-ings of the 5th Meeting of the North Ameri-can Chapter of the Association for ComputationalLinguistics/Human Language Technologies Con-ference (HLT-NAACL04), pages 149?152, Boston,MA.Mona Diab.
2007.
Towards an Optimal POS tag setfor Modern Standard Arabic Processing.
In Pro-ceedings of Recent Advances in Natural LanguageProcessing (RANLP), Borovets, Bulgaria.Khaled Elghamry, Rania Al-Sabbagh, and Nagwa El-Zeiny.
2008.
Cue-based bootstrapping of Arabicsemantic features.
In JADT 2008: 9es Journ?esinternationales d?Analyse statistique des Donn?esTextuelles.Yoav Goldberg and Michael Elhadad.
2010.
An effi-cient algorithm for easy-first non-directional depen-dency parsing.
In Human Language Technologies:The 2010 Annual Conference of the North AmericanChapter of he Association for Computational Lin-guistics, pages 742?750, Los Angeles, California,June.
Association for Computational Linguistics.Abduelbaset Goweder, Massimo Poesio, Anne DeRoeck, and Jeff Reynolds.
2004.
Identifying Bro-ken Plurals in Unvowelised Arabic Text.
In DekangLin and Dekai Wu, editors, Proceedings of EMNLP2004, pages 246?253, Barcelona, Spain, July.Nizar Habash and Owen Rambow.
2005.
Arabic Tok-enization, Part-of-Speech Tagging and Morpholog-ical Disambiguation in One Fell Swoop.
In Pro-ceedings of the 43rd Annual Meeting of the Associa-tion for Computational Linguistics (ACL?05), pages573?580, Ann Arbor, Michigan.Nizar Habash and Ryan Roth.
2009.
CATiB: TheColumbia Arabic Treebank.
In Proceedings of theACL-IJCNLP 2009 Conference Short Papers, pages221?224, Suntec, Singapore.Nizar Habash, Abdelhadi Soudi, and Tim Buckwalter.2007.
On Arabic Transliteration.
In A. van denBosch and A. Soudi, editors, Arabic Computa-tional Morphology: Knowledge-based and Empir-ical Methods.
Springer.Nizar Habash, Reem Faraj, and Ryan Roth.
2009.Syntactic Annotation in the Columbia Arabic Tree-bank.
In Proceedings of MEDAR InternationalConference on Arabic Language Resources andTools, Cairo, Egypt.Nizar Habash.
2004.
Large Scale Lexeme BasedArabic Morphological Generation.
In Proceedingsof Traitement Automatique des Langues Naturelles(TALN-04), pages 271?276.
Fez, Morocco.Nizar Habash.
2010.
Introduction to Arabic NaturalLanguage Processing.
Morgan & Claypool Pub-lishers.Clive Holes.
2004.
Modern Arabic: Structures, Func-tions, and Varieties.
Georgetown Classics in ArabicLanguage and Linguistics.
Georgetown UniversityPress.Taku Kudo and Yuji Matsumoto.
2003.
Fast Meth-ods for Kernel-Based Text Analysis.
In Proceed-ings of the 41st Annual Meeting of the Associationfor Computational Linguistics (ACL?03), pages 24?31, Sapporo, Japan, July.Seth Kulick, Ryan Gabbard, and Mitch Marcus.
2006.Parsing the Arabic Treebank: Analysis and Im-provements.
In Proceedings of the Treebanksand Linguistic Theories Conference, pages 31?42,Prague, Czech Republic.Mohamed Maamouri, Ann Bies, Tim Buckwalter, andWigdan Mekki.
2004.
The Penn Arabic Treebank:Building a Large-Scale Annotated Arabic Corpus.In NEMLAR Conference on Arabic Language Re-sources and Tools, pages 102?109, Cairo, Egypt.Yuval Marton, Nizar Habash, and Owen Rambow.2010.
Improving Arabic Dependency Parsing withLexical and Inflectional Morphological Features.
InProceedings of the NAACL HLT 2010 First Work-shop on Statistical Parsing of Morphologically-RichLanguages, pages 13?21, Los Angeles, CA, USA,June.Yuval Marton, Nizar Habash, and Owen Rambow.2011.
Improving Arabic Dependency Parsing withForm-based and Functional Morphological Fea-tures.
In Proceedings of the 49th Annual Meet-ing of the Association for Computational Linguis-tics (ACL?11), Portland, Oregon, USA.Yuval Marton, Nizar Habash, and Owen Rabmow.2012.
Dependency Parsing of Modern Stan-dard Arabic with Lexical and Inflectional Features.Manuscript submitted for publication.Quinn McNemar.
1947.
Note on the sampling errorof the difference between correlated proportions orpercentages.
Psychometrika, 12(2):153?157.Otakar Smr?
and Jan Hajic?.
2006.
The Other Ara-bic Treebank: Prague Dependencies and Functions.In Ali Farghaly, editor, Arabic Computational Lin-guistics: Current Implementations.
CSLI Publica-tions.684Otakar Smr?.
2007a.
ElixirFM ?
implementation offunctional arabic morphology.
In ACL 2007 Pro-ceedings of the Workshop on Computational Ap-proaches to Semitic Languages: Common Issuesand Resources, pages 1?8, Prague, Czech Repub-lic.
ACL.Otakar Smr?.
2007b.
Functional Arabic Morphology.Formal System and Implementation.
Ph.D. thesis,Charles University in Prague, Prague, Czech Re-public.Abdelhadi Soudi, Antal van den Bosch, and G?n-ter Neumann, editors.
2007.
Arabic Computa-tional Morphology.
Knowledge-based and Empiri-cal Methods, volume 38 of Text, Speech and Lan-guage Technology.
Springer, August.685
