Deep Semantic Analysis of TextJames F. Allen1,2Mary Swift1Will de Beaumont21University of Rochester (USA)2Institute for Human and Machine Cognition, Pensacola (USA)email: james@cs.rochester.eduAbstractWe describe a graphical logical form as a semantic representation for textunderstanding.
This representation was designed to bridge the gap be-tween highly expressive "deep" representations of logical forms and moreshallow semantic encodings such as word senses and semantic relations.It preserves rich semantic content while allowing for compact ambigu-ity encoding and viable partial representations.
We describe our systemfor semantic text processing, which has the TRIPS parser at the core,augmented with statistical preprocessing techniques and online lexicallookup.
We also present an evaluation metric for the representation anduse it to evaluate the performance of the TRIPS parser on the commontask paragraphs.343344 Allen, Swift, and de Beaumont1 IntroductionAs building rich semantic representations of text becomes more feasible, it is impor-tant to develop standard representations of logical form that can be used to share dataand compare approaches.
In this paper, we describe some general characteristics thatsuch a logical form language should have, then present a graphical representation de-rived from the LF used in the TRIPS system (Allen et al, 2007).The Logical Form is a representation that serves as the interface between structuralanalysis of text (i.e., parsing) and the subsequent use of the information to produceknowledge, whether it be for learning by reading, question answering, or dialogue-based interactive systems.It?s important to distinguish two separable problems, namely the ontology used andthe structure of the logical form language (LFL).
The ontology determines the set ofword senses and semantic relations that can be used.
The LFL determines how theseelements can be structured to capture the meaning of sentences.
We are addressing thelatter in the paper.
Consider some principles for designing useful LFs.Preserve Rich Semantic Content in PhrasingThe LFL should allow one to express the dependencies and subtleties that are ex-pressed in the sentence.
On the simple end, this means the LFL should allow us torepresent the differences between the NP The pigeon house, which is a type of house,and the house pigeon, which is a type of pigeon.
On the more complicated end, theLFL should be able to capture complex quantifier structures such as those in the NPsNearly all peaches, or Every dog but one, and phenomena such as modal operators,predicate modifiers, and explicit sets.One might argue that capturing such complex phenomena in the LFL is prematureat this time, as existing techniques are unlikely to be able to produce them reliably.On the other hand, if we don?t allow such subtleties in the gold-standard LFL, we willtend to stifle long-term work on the difficult problems since it is not reflected in thescore in evaluations.Encoding ambiguity compactly when possibleThis issue has a long history in the literature, with the most classic case being quan-tifier scoping.
Underspecified representations of quantifier scoping are a prime fo-cus in the development of modern logical form languages such as MRS (Copestakeet al, 2006), and work goes all the way back to early natural language systems (e.g.Woods, 1978).
Other techniques for compactly encoding ambiguity include preposi-tional phrase attachment, and most critically, the use of vague predicates and relations.For example, for many cases of noun-noun modification, the exact semantic relationbetween the nouns cannot be determined, and actually need not be determined pre-cisely to be understood.Enable Viable Partial InterpretationsIn many cases, because of limitations in current processing, or because of the fragmen-tary nature of the language input itself, a system will only be able to construct partialinterpretations.
The LFL should be constructed in a way such that partial representa-tions are easily compared with full representations.
In particular, the interpretation ofDeep Semantic Analysis of Text 345a fragment should be a subset of the full logical form of the entire sentence.
It is afortunate circumstance that representations that tend to compactly encode ambiguitytend also to have this subset property.
(SPEECHACT SA_TELL)(F FOLLOW chase)):CONTENT(THE ANIMAL cat):THEME(QUANTIFIER ANIMAL dog):AGENT(OP FREQUENCY usually)):MODPRES:TENSEEVERY:QUAN(F LIVING-PROPERTY-VAL hungry):MOD:OF:OF(PRO PERSON my):ASSOC-WITHFigure 1: An LF Graph for ?Every hungry dog usually chases my cat?2 Overview of LF GraphsAn example LF-graph is shown in Figure 1.
This graph introducesmuch of the formal-ism.
Each node represents either a speechact, a proposition, a generalized quantifier,an operator or a kind.
Nodes are labelled in three parts, the specifier, indicating thesemantic function of node, the type, indicating conceptual class drawn from the on-tology, and the word from the input.
The latter allows us to relate the nodes in theLF graph back to the input.
The edges are labelled with semantic roles that indicateargument structure and other critical properties such as modification relationships.Consider each of the core node types.
The first term type captures the meaningsof fragments that define eventualities (i.e., events and properties).
For instance, thenode (F FOLLOW chase) in Figure 1 refers to an eventuality of the type FOLLOW(which would be defined in the ontology).
Additional information about the even-tuality is captured by the outgoing edges, which identify two arguments, the :Agentand the :Theme, and one other that provides the tense information for later contextualinterpretation (PRES is the present tense).The second node type captures generalized quantifier constructions.
The node(THE ANIMAL cat) indicates a definite description referring to an object of typeANIMAL in the ontology.
Generalized quantifiers that have universal import are in-dicated as shown in the node (QUANTIFIER ANIMAL dog), where an edge labelled:QUAN gives the specific quantifier involved.
Note also the presence of a modificationto the type (the :MOD) arc, which points to another eventuality, namely (F LIVING-PROPERTY-VAL hungry), which in turn has an argument (:OF) pointing back to themodified node.
The :MOD link is critical for capturing dependencies that allow us toreconstruct the full logical form from the graph.
For instance, it allows us to retain thedistinction between head noun and the modifiers (e.g., the pigeon house vs the housepigeon).Table 1 shows the core set of generalized quantifiers used in TRIPS (and subse-quently interpreted in discourse processing, especially reference resolution.
A largeset of quantifiers that indicate the size (e.g., many, some, five, at most three, a few, ...)346 Allen, Swift, and de Beaumontare treated as an indefinite construction with a (often vague) size modifier.Table 1: Core Generalized QuantifiersType DescriptionTHE a definite form(we expect to be able to resolve it from context)A an indefinite form(we expect it to introduce new objects)PRO a pronoun form(we expect it to be resolved from local context)IMPRO an implicit anaphoric formBARE forms with no specifier and ambiguous betweengeneric, kind, and indefiniteQUANTIFIER ?universally?
quantified constructions (e.g., EVERY)QUANTITY-TERM a quantity expressed in units (e.g., three pounds)WH-TERM ?wh?
terms as in questions (e.g., which trucks)KIND the definition of a kind (aka lambda abstraction)The next term type specifies modal operators, and seen in Figure 1 as the node (OPFREQUENCY usually).
The operator nodes must be distinguished from the terms forpredications (F) to support algorithms for quantifier and operator scoping.The final class of node in Figure 1 is the speech act performed by an utterance:(SPEECHACT TELL).
This has no third argument as it does not arise from any singleword in the utterance.
The semantic role :content indicates the propositional content ofthe speech act, and additional roles indicating the speaker and hearer are suppressed.Speech acts havemodifiers in order to handle phenomena such as discourse adverbials.
(SPEECHACT SA_WH-QUESTION)(WH-TERM PERSON who):FOCUS (F ACTIVE-PERCEPTION see):CONTENT(THE SET):THEME:EXPERIENCERPAST:TENSE(QUANTITY-TERM NUMBER):SIZE(KIND ENGINE engine)):OF3:VALUE(F SIZE-VAL small)):MOD :OFFigure 2: The LF graph for ?Who saw the three small engines?Figure 2 shows another LF graph which captures some additional key construc-tions.
It shows another speech act, for Wh-questions, and shows the handling of plu-rals.
LF graphs distinguish explicitly between singular and plurals by modeling sets,in which an :of argument that points to the type of objects in the set.The KIND operator is used to define these types (aka lambda abstraction).
Thusthe three small engines is a SET of size three with elements of KIND ENGINE andwhich are small.LF-graphs are interesting as they offer the possibility of comparing the semanticcontent of different approaches, ranging from shallow approaches that identify wordDeep Semantic Analysis of Text 347senses and semantic roles, to complex representations produced by state-of-the-artdeep parsers.
On the shallow side, a word sense disambiguation system would producea set of nodes with the word senses labeled from an ontology, but not indicating aspecifier, and not capturing any semantic roles.
A system that identifies semanticroles can capture its results using the edges of the graph.On the other hand, we can show that the LF-graph formalism is equivalent to theTRIPS logical form language (LFL), which is a ?flat?
scope-underspecified represen-tation of a reference modal logic with generalized quantifiers and lambda abstraction.We have developed an efficient quantifier scoping algorithm on this LFL that con-structs possible fully-scoped forms in the reference logic, and we can prove that wederive the same sets of possible interpretations as the representations constructed byMRS (Manshadi et al, 2008).
Figure 3 shows the TRIPS logical form that producedFigure 1, and Figure 4 shows one of the interpretations produced by the scoping algo-rithm.
(SPEECHACT a1 TELL :content f1)(F f1 (:* FOLLOW Chase) :agent x :theme y)(EVERY x (:* ANIMAL Dog) :mod f2)(F f2 (:* LIVING-PROPERTY-VAL Hungry) :of x)(A y (:* ANIMAL Cat))(OP p1 (:* FREQUENCY usually) :of f1)Figure 3: TRIPS Logical Form of ?Every hungry dog usually chases a cat?Every(x, Dog(x) ^ Hungry(f2) ^ theme(f2,x),Frequent(A(y, Cat(y),Chase(f1) ^ agent(f1,x) ^ theme(f1,y))))Figure 4: One possible scoped interpretation shown in reference representationCoreferenceThe final information encoded in the LF graphs is coreference information.
Referen-tial expressions are connected to their antecedents using a :coref arc.
Note this canonly encode referential relations to antecedents that actually appear previously in thetext.
Simple forms of bridging reference can also be encoded using the insertion ofIMPRO nodes that stand in for implicit arguments, and may then co-refer with termsin the graph.3 The LF Ontology and Word SensesThe LF ontology is the source of the semantic types and semantic roles that are used inthe LF graphs.
In this paper, we use the LF ontology of the TRIPS system.
The TRIPSontology also defines a rich set of semantic features that are crucial for constraining348 Allen, Swift, and de Beaumontambiguity at multiple levels of language processing.
For example, the grammar usesselectional restrictions to guide word sense disambiguation and prepositional phraseattachment during parsing, and reference resolution uses the semantic features to iden-tify valid referents and discard invalid ones.The TRIPS LF ontology is designed to be linguistically motivated and domainindependent.
The semantic types and selectional restrictions are driven by linguis-tic considerations rather than requirements from reasoning components in the system(Dzikovska et al, 2003).
Word senses are defined based on subcategorization patternsand domain independent selectional restrictions.
As much as possible the semantictypes in the LF ontology are compatible with types found in FrameNet (Johnson andFillmore, 2000).
FrameNet generally provides a good level of abstraction for appli-cations since the frames are derived from corpus examples and can be reliably distin-guished by human annotators.
However we use a smaller, more general set of semanticroles for linking the syntactic and semantic arguments rather than FrameNet?s exten-sive set of specialized frame elements.
The LF ontology defines approximately 650semantic types and 30 semantic roles.
See Dzikovska et al (2004) for more discus-sion of the relationship between FrameNet and the LF ontology.
We also expandedour verb coverage by integrating VerbNet entries (Swift, 2005; Crabbe et al, 2006).The LF ontology also differs from FrameNet in its use of a rich semantic featureset.
Our semantic features are an extended version of EuroWordNet (Vossen, 1997).There are five top-level distinctions: physical object, abstract object, situation, timeand proposition.
Subtypes are defined to capture distinctions in lexical aspect, spatialabstractions (point, region...), origins (natural, artifact...) and so on.We are not attempting to capture all possible word senses in our ontology.
Rather,we are looking for the level of abstraction that affects linguistic processing, and leavefiner distinctions for subsequent discourse processing and inference.
In order notto lose information in the LF, our word senses are a tuple of form (:* <LF-type><word-type>), where the LF-type comes from the Ontology, and the <word-type>is a canonicalized version of the word.
For example, the property of a switch/devicebeing on or off is associated with an LF type ARTIFACT-PROPERTY-VAL.
Anothersense of on is its spatial reading, of type SPATIAL-LOC, which also includes wordssuch as behind and in front of.
These two senses of on are:(:* ARTIFACT-PROPERTY-VAL ON)(:* SPATIAL-LOC ON).Though we don?t have the space to describe it here, TRIPS provides an ontologymapping capability that allows developers to easily map the TRIPS LF forms to adomain-specific ontology (Dzikovska et al, 2008).4 System OverviewMuch recent text processing work has focused on developing ?shallow?, statisticallydriven, techniques.
We have taken a different approach.
We use statistical methods asa preprocessing step to provide guidance to a deep parsing system that uses a detailed,hand-built, grammar of English with a rich set of semantic restrictions.
This way, wehope to obtain deeper, more accurate interpretations.
Because the parser was devel-Deep Semantic Analysis of Text 349oped to identify likely fragments when an entire interpretation cannot be constructed,we believe it can match statistical methods in its precision and recall measures.The TRIPS grammar is a lexicalized context-free grammar, augmented with featurestructures and feature unification.
The grammar is motivated from X-bar theory, anddraws on principles fromGPSG (e.g., head and foot features) and HPSG.
The search inthe parser is controlled by a set of hand-build rule preferences encoded as weights onthe rules, together with a heavy use of selectional restrictions (encoded in the lexiconand ontology) to eliminate semantically anomalous sense combinations.The TRIPS parser uses a packed-forest chart representation and builds constituentsbottom-up using a best-first search strategy similar to A*, based on rule and lexi-cal weights and the influences of the techniques addressed below.
The search termi-nates when a pre-specified number of spanning constituents have been found or a pre-specified maximum chart size is reached.
The chart is then searched using a dynamicprogramming algorithm to find the least cost sequence of constituents according to acost table that can be varied by genre.
For instance, when processing text as in the ex-periments reported here, we mostly expect UTT constituents encoding the speech actTELL, then less likely the speech acts WH-QUESTION and YN-QUESTION and wedon?t expect dialog-based speech acts such as CONFIRM or GREET.
In addition, wealso assign costs to non-sentential constituents (e.g., NPs, ADVPs, etc).
The resultingleast cost sequence produces a set of logical forms that are the results reported here.Here we describe the different ways that shallow methods contribute to deep pro-cessing.Using PreprocessorsFirst, statistical processing is used as a preprocessor.
The TRIPS parser accepts a wordlattice as input, which we have used when working with speech recognition where wewant to consider multiple word hypotheses simultaneously.
We have used this capa-bility to allow for preprocessors as well.
For instance, we use multiple named entityrecognizers (NER) to identify names of people, companies, geographical locations,and so on.
The output of the NERs are treated as additional constituent hypotheses inthe input to the parser.
As an example, consider the sentence The New York Times is anewspaper.
Assuming an NER identifies The New York Times as a name with semantictype PUBLICATION, the input to the parser will be:(word "the" 1 2)(word "new" 2 3)(word "york" 3 4)(word "times" 4 5)(constit "the new york times" 1 5:syn (NAME :class PUBLICATION))(word "is" 5 6)(word "a" 6 7)(word "newspaper" 7 8)As the parser runs, it chooses between interpreting the words individually or usingthe name, depending on what produces the best overall interpretation.
In addition, weuse a specialized recognizer that identifies possible street addresses (e.g., 15 N 25th350 Allen, Swift, and de BeaumontSt NE).
Note we don?t need specialized NERs for dates and times as they are handledin the main grammar.Part of Speech TaggingWe also use a part-of-speech tagger to preprocess the input and provide a likely POStag (or set of tags) for consideration by the parser.
Rather than eliminating the inter-pretations that do not match, the parser simply assigns more weight to interpretationsconsistent with the tags.
This allows the parser to override bad POS assignments insome cases.Using on-line resourcesWe have built a system called WordFinder that draws on WordNet (Miller, 1995) andCOMLEX (Grishman et al, 1994) to construct (underspecified) lexical representa-tions using mapping rules from high-level WordNet classes into our LF ontology.
Wedeliberately stay at a fairly abstract level as we would rather have a few semanticallyabstract lexical entries rather than the many highly-specific senses found in WordNet,which we have not found useful for parsing.Using Preferences during ParsingPreferences (either syntactic or semantic) can be given to the parser based on statis-tical or other analyses.
We have used the Collins parser as a preprocessor to extracthypotheses for the three constituents (NP, VP, and ADVP) which in pretests had aprecision greater than 60% (Swift et al, 2004).
For instance, for the sentence TheNew York Times is a newspaper, the Collins preprocessor would produce the follow-ing preferences:(NP 1 5) (NP 6 8) (VP 5 8) (S 1 8)With simple sentences, this information has little effect.
But on longer complexsentences, we found that the preferences allow us to produce more accurate interpre-tations in faster time.
Note again that the parser is not required to follow this advice?
all this information does is add a preference for such interpretations.Another mechanismwe use is logical form preference patterns.
Local form patternsof predicate types and arguments can be specified with preference scores.
Considerthe sentence ?He put the box in the corner near the house?.
Although the locationadverbial ?near the house?
could possibly describe the putting event, it is much morelikely that it modifies the corner.
Thus the pattern (PUT :agent :theme :destination) ispreferred over the pattern (PUT :agent :theme :destination :location).
We have onlytested this capability so far with hand-specified patterns, though we plan to start exper-iments using learned patterns derived from propositions extracted from corpora (e.g.van Durme et al, 2008).
The overall system, using all these techniques, is showngraphically in Figure 5.5 An Evaluation Metric for LF GraphsIn this section we define an evaluation metric for LF-graphs that allows us to quantifyour system performance against gold standard representations.Deep Semantic Analysis of Text 351named entityrecognizersaddressrecognizerstatisticalparserInputChartnamehypothesesaddresshypothesesBracketingPreferencessemanticpreferencesLF formpreferencesWordnet Wordfindernew lexical entriesCore Lexicon & LF OntologyGrammarParserContentExtractorFinalLogicalFormInputOutputChartwordhypothesesComlexPOStaggingPOShypsFigure 5: Using Shallow Methods to Inform Deep Parsing (the subsystems in dottedovals were not used in the reported evaluations)The evaluation metric between a gold LF graph G and a test LF graph T is definedas the maximum score produced by any node/edge alignment from the gold to the testLF.
More formally, an alignment A is a 1-1 mapping from the nodes of the gold graphto nodes of the test graph (or to a pseudo empty node if there is no correspondingnode in the test graph).
Once we have defined a scoring metric between aligned nodesand edges, we define the match between a gold and test graph as the maximum scoreproduced by an alignment.
While complex scoring functions can be used, our resultsreported here use a simple measure:NscoreA(n) = 2 if both the indicator and word in the label of n matchesthe label of A(n), 1 if one of them matches, and 0 otherwise.EscoreA(e) = 1 if e connect nodes n1 and n2, and there is an edge betweenA(n1) and A(n2) with same label, 0 otherwise.Gscore(G,T) = maxA(Sumn,ein(NscoreA(n)+EscoreA(e))Once we know Gscore(G,T), we can compute semantic precision and recall measuresby comparing this to the G and T graphs aligned with themselves, which gives us themaximum possible gold and test scores.Precision(G,T) = Gscore(G,T)/Gscore(T,T)Recall(G,T) = Gscore(G,T)/Gscore(G,G)A more general function of node matching would be more informative.
For in-stance, with words not in our core lexicon, we usually derive an abstract sense that isnot the most specific sense in our ontology, however is an abstraction of the correctsense.
A scoring function that would give such cases partial credit would have raisedour scores (cf.
Resnik and Yarowsky, 1997).Evaluation Procedure and ResultsTo evaluate our system on the shared texts, we built gold representations for each.
Wedid this by first generating an LF-graph by running the system, and then correcting this352 Allen, Swift, and de Beaumont(SPEECHACT SA_TELL)(F (:* DISPERSE SPREAD)):CONTENT(BARE (:* ACTION DISTRIBUTION)):THEME(F (:* TO-LOC TO)):MOD(F (:* EVENT-TIME-REL ONCE)):MODW::PAST:TENSE:OF(KIND (:* SUBSTANCE ELECTRICITY)):ASSOC-WITH(KIND (:* NON-MEASURE-ORDERED-DOMAIN SCALE)):ASSOC-WITH(F (:* SIZE-VAL BROAD)):MOD:OF:OF(THE SET):VAL(A SET):MEMBER(A SET):MEMBER(KIND ROOT):OF(KIND (:* LOCATION FARM)):OF(KIND (:* DISTRICT TOWN)):OF(KIND (:* LOCATION COUNTRY)):ASSOC-WITH(F (:* START START))(F (:* TRANSFORMATION SUBSIDE)):EFFECT(BARE (:* USE USE)):THEMEW::PAST:TENSE(BARE (:* SUBSTANCE ENERGY)):THEME(KIND (:* AIR-CURRENT WIND)):ASSOC-WITH(F (:* SPATIAL-LOC IN)):MOD:OF:VAL(THE (:* COUNTRY USA))(THE UNITED STATES):NAME-OF(F (:* ADJUST PICK-UP))(F (:* CONJUNCT BUT))(PRO (:* REFERENTIAL-SEM IT)):THEME(F (:* FREQUENCY AGAIN)):MOD(F (:* EVENT-TIME-REL AFTER)):MODW::PAST:TENSE:COREF:OF :OF:SIT-VAL(THE (:* LACK SHORTAGE))(KIND (:* FATS-OILS OIL)):OF(THE (:* COUNTRY USA)):ASSOC-WITH(F (:* TIME-SPAN-REL IN)):MOD(THE U PUNC-PERIOD S PUNC-PERIOD):NAME-OF:OF(THE TIME-RANGE):VAL1970:DECADE(F (:* SCHEDULED-TIME-MODIFIER EARLY)):MOD :OF:SIT-VAL:OF:VAL:MODFigure 6: Hand built gold standard for ?Once broad-scale electricity distributionspread to farms and country towns, use of wind energy in the United States startedto subside, but it picked up again after the U.S. oil shortage in the early 1970s.
?by hand using a graphical editor.
Figure 6 illustrates the gold standard for a sampleparagraph.Table 2 reports the results on our baseline system, which was the first run we madeon the shared texts once they became available.
In addition, we report results on thelatest version of the system after making some lexicon and grammar additions basedon problems found in parsing the paragraphs.Table 2: Evaluation ResultsBase System Final SystemText Prec Recall Prec Recall1 ?physics?
70.1% 70.1% 73.4% 80.0%2 ?cancer?
62.1% 71.9% 71.9% 79.3%3 ?dining?
86.7% 90.4% 90.8% 94.6%4 ?dogs?
63.0% 68.6% 63.8% 69.1%5 ?guns?
55.0% 64.0% 63.8% 73.4%6 ?gardens?
47.4% 53.6% 59.7% 62.0%7 ?wind?
n/a n/a 65.8% 76.3%Average 64.1% 69.7% 69.9% 76.4%Specifically, we added 16 new lexical items (1 verb, 12 nouns, 2 adjectives and 1adverb); 17 new or modified senses for existing lexical items; 3 new ontology conceptsand one grammar rule, to handle the formulation of meters per second as ?m/s?.6 ConclusionWe have described a graphical logical form language for expressing a significantamount of the semantic content in natural text.
The representation allows for thespecification of partial information extracted from sentences, yet is expressive enoughto capture many of the subtleties and complications present in linguistically motivatedDeep Semantic Analysis of Text 353approaches, including supporting complex processes such as quantifier scoping, ref-erence resolution, and reasoning.We also briefly described a hybrid system architecture centered around a domain-general, broad coverage parsing framework capable of producing deep analyses oftexts.
Statistical and corpora-based approaches serve to inform the parsing in order toachieve a balance between depth of analysis and broad coverage.We find the results very encouraging, given this is our first evaluation of the sys-tem on text rather than dialog.
While it is hard to quantify exactly without furtherdetailed analysis, the remaining errors probably break down roughly evenly betweengaps in grammatical coverage, word sense disambiguation errors and inadequacies inour search.
Looking at grammatical coverage, the single biggest problem appears tobe conjoined sentences with subject ellipsis.
Regarding our search problems, becausewe are building semantic structures rather than syntactic, the search space is much big-ger than a traditional CFG.
We believe that integrating a statistical parser preprocessorand the LF-preference mechanism will start to address this problem.Acknowledgments This work was supported by grants from the National ScienceFoundation (#0748942), the Defense Advanced Research Projects Agency (FA8750-07-D-0185), and the Of[fb01]ce of Naval Research (N000140510314).ReferencesAllen, J., M. Dzikovska, M. Manshadi, and M. Swift (2007, June).
Deep linguisticprocessing for spoken dialogue systems.
In ACL 2007 Workshop on Deep Linguis-tic Processing, pp.
49?56.
Association for Computational Linguistics.Copestake, A., D. Flickinger, C. Pollard, and I.
Sag (2006).
Minimal recursion se-mantics: An introduction.
Research on Language and Computation 3(4), 281?332.Crabbe, B., M. Dzikovska, W. de Beaumont, and M. Swift (2006, June).
Extendingthe coverage of a domain independent dialog lexicon with VerbNet.
In Proceedingsof the Third International Workshop on Scalable Natural Language Understanding(ScaNLU06) at HLT-NAACL 2006, pp.
25?32.Dzikovska, M., J. Allen, and M. Swift (2008).
Linking semantic and knowledgerepresentations in a multi-domain dialogue system.
J. Log.
and Comput.
18(3),405?430.Dzikovska, M., M. Swift, and J. Allen (2003, August).
Integrating linguistic and do-main knowledge for spoken dialogue systems in multiple domains.
In Proceedingsof Workshop on Knowledge and Reasoning in Practical Dialogue Systems at the18th International Joint Conference on Artificial Intelligence (IJCAI-2003), Aca-pulco, Mexico, pp.
383?389.Dzikovska, M., M. Swift, and J. Allen (2004, May).
Building a computational lexiconand ontology with FrameNet.
In Proceedings of Workshop on Building Lexical Re-sources with Semantically Annotated Corpora at The 4th International Conferenceon Language Resources and Evaluation (LREC?04), pp.
53?60.354 Allen, Swift, and de BeaumontGrishman, R., C. Macleod, and A. Meyers (1994).
Comlex syntax: Building a com-putational lexicon.
In COLING, pp.
268?272.Johnson, C. and C. J. Fillmore (2000).
The FrameNet tagset for frame-semantic andsyntactic coding of predicate-argument structure.
In Proceedings of the first confer-ence on North American chapter of the Association for Computational Linguistics,San Francisco, CA, USA, pp.
56?62.
Morgan Kaufmann Publishers Inc.Manshadi, M., J. Allen, and M. Swift (2008, August).
Toward a universal under-specifed semantic representation.
In 13th Conference on Formal Grammar (FG2008).Miller, G. A.
(1995).
Wordnet: a lexical database for english.
Commun.
ACM 38(11),39?41.Resnik, P. and D. Yarowsky (1997, June).
A perspective on word sense disambigua-tion methods and their evaluation.
In Proceedings of SIGLEX ?97, pp.
79?86.Swift, M. (2005, February).
Towards automatic verb acquisition from VerbNet forspoken dialog processing.
In K. Erk, A. Melinger, and S. S. im Walde (Eds.
),Proceedings of InterdisciplinaryWorkshop on the Identification and Representationof Verb Features and Verb Classes, pp.
115?120.Swift, M., J. Allen, and D. Gildea (2004, Aug 23?Aug 27).
Skeletons in the parser:Using a shallow parser to improve deep parsing.
In COLING ?04: Proceedings ofthe 20th international conference on Computational Linguistics, Morristown, NJ,USA, pp.
383?389.
Association for Computational Linguistics.van Durme, B., T. Qian, and L. K. Schubert (2008, Aug 18?Aug 22).
Class-drivenattribute extraction.
In COLING ?08: Proceedings of the 24th international confer-ence on Computational Linguistics.
Association for Computational Linguistics.Vossen, P. (1997, March 5-7).
EuroWordNet: a multilingual database for informationretrieval.
In Proceedings of the DELOS workshop on Cross-language InformationRetrieval, Zurich.Woods, W. A.
(1978).
Semantics and quantification in natural language question an-swering.
Advances in Computers 17, 1?87.
