Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 19?24,Baltimore, Maryland USA, June 23-24, 2014.c?2014 Association for Computational LinguisticsCommunity Evaluation and Exchange of Word Vectorsat wordvectors.orgManaal Faruqui and Chris DyerCarnegie Mellon UniversityPittsburgh, PA, 15213, USA{mfaruqui, cdyer}@cs.cmu.eduAbstractVector space word representations are use-ful for many natural language process-ing applications.
The diversity of tech-niques for computing vector representa-tions and the large number of evaluationbenchmarks makes reliable comparison atedious task both for researchers devel-oping new vector space models and forthose wishing to use them.
We presenta website and suite of offline tools thatthat facilitate evaluation of word vectorson standard lexical semantics benchmarksand permit exchange and archival by userswho wish to find good vectors for theirapplications.
The system is accessible at:www.wordvectors.org.1 IntroductionData-driven learning of vector-space word embed-dings that capture lexico-semantic properties isa technique of central importance in natural lan-guage processing.
Using co-occurrence statisticsfrom a large corpus of text (Deerwester et al.,1990; Turney and Pantel, 2010), it is possibleto construct high-quality semantic vectors ?
asjudged by both correlations with human judge-ments of semantic relatedness (Turney, 2006;Agirre et al., 2009) and as features for down-stream applications (Turian et al., 2010).
A num-ber of approaches that use the internal representa-tions from models of word sequences (Collobertand Weston, 2008) or continuous bags-of-contextwordsets (Mikolov et al., 2013) to arrive at vectorrepresentations have also been shown to likewisecapture co-occurrence tendencies and meanings.With an overwhelming number of techniquesto obtain word vector representations the task ofcomparison and choosing the vectors best suitablefor a particular task becomes difficult.
This isfurther aggravated by the large number of exist-ing lexical semantics evaluation benchmarks be-ing constructed by the research community.
Forexample, to the best of our knowledge, for evaluat-ing word similarity between a given pair of words,there are currently at least 10 existing bench-marks1that are being used by researchers to provethe effectiveness of their word vectors.In this paper we describe an online applicationthat provides the following utilities:?
Access to a suite of word similarity evalua-tion benchmarks?
Evaluation of user computed word vectors?
Visualizing word vectors in R2?
Evaluation and comparison of the availableopen-source vectors on the suite?
Submission of user vectors for exhaustive of-fline evaluation and leader board ranking?
Publicly available repository of word vectorswith performance detailsAvailability of such an evaluation system willhelp in enabling better consistency and uniformityin evaluation of word vector representations aswell as provide an easy to use interface for end-users in a similar spirit to Socher et al.
(2013a),a website for text classification.2Apart from theonline demo version, we also provide a softwarethat can be run in an offline mode on the commandline.
Both the online and offline tools will be keptupdated with continuous addition of new relevanttasks and vectors.1www.wordvectors.org/suite.php2www.etcml.com192 Word Similarity BenchmarksWe evaluate our word representations on 10 dif-ferent benchmarks that have been widely used tomeasure word similarity.
The first one is the WS-3533dataset (Finkelstein et al., 2001) containing353 pairs of English words that have been assignedsimilarity ratings by humans.
This data was fur-ther divided into two fragments by Agirre et al.
(2009) who claimed that similarity (WS-SIM) andrelatedness (WS-REL)4are two different kindsof relations and should be dealt with separately.The fourth and fifth benchmarks are the RG-65(Rubenstein and Goodenough, 1965) and the MC-30 (Miller and Charles, 1991) datasets that contain65 and 30 pairs of nouns respectively and havebeen given similarity rankings by humans.
Thesediffer from WS-353 in that it contains only nounswhereas the former contains all kinds of words.The sixth benchmark is the MTurk-2875(Radinsky et al., 2011) dataset that constitutes 287pairs of words and is different from the previ-ous benchmarks in that it has been constructedby crowdsourcing the human similarity ratingsusing Amazon Mechanical Turk (AMT).
Simi-lar in spirit is the MTruk-7716(Halawi et al.,2012) dataset that contains 771 word pairs whosesimilarity was crowdsourced from AMT.
An-other, AMT created dataset is the MEN7bench-mark (Bruni et al., 2012) that consists of 3000word pairs, randomly selected from words thatoccur at least 700 times in the freely availableukWaC and Wackypedia8corpora combined.The next two benchmarks were created to putemphasis on different kinds of word types.
Tospecifically emphasize on verbs, Yang and Pow-ers (2006) created a new benchmark YP-130 of130 verb pairs with human similarity judgements.Since, most of the earlier discussed datasets con-tain word pairs that are relatively more frequent ina corpus, Luong et al.
(2013) create a new bench-3http://www.cs.technion.ac.il/?gabr/resources/data/wordsim353/4http://alfonseca.org/eng/research/wordsim353.html5http://tx.technion.ac.il/?kirar/Datasets.html6http://www2.mta.ac.il/?gideon/mturk771.html7http://clic.cimec.unitn.it/?elia.bruni/MEN.html8http://wacky.sslmit.unibo.it/doku.php?id=corporamark (Rare-Word)9that contains rare-words bysampling words from different frequency bins to atotal of 2034 word pairs.We calculate similarity between a given pairof words by the cosine similarity between theircorresponding vector representation.
We then re-port Spearman?s rank correlation coefficient (My-ers and Well, 1995) between the rankings pro-duced by our model against the human rankings.Multilingual Benchmarks.
As is the case withmost NLP problems, the lexical semantics evalua-tion benchmarks for languages other than Englishhave been limited.
Currently, we provide a linkto some of these evaluation benchmarks from ourwebsite and in future will expand the website toencompass vector evaluation for other languages.3 VisualizationThe existing benchmarks provide ways of vectorevaluation in a quantitative setting.
To get an ideaof what kind of information the vectors encode it isimportant to see how these vectors represent wordsin n-dimensional space, where n is the lengthof the vector.
Visualization of high-dimensionaldata is an important problem in many different do-mains, and deals with data of widely varying di-mensionality.
Over the last few decades, a varietyof techniques for the visualization of such high-dimensional data have been proposed (de Oliveiraand Levkowitz, 2003).Since visualization in n dimensions is hardwhen n >= 3, we use the t-SNE (van der Maatenand Hinton, 2008) tool10to project our vectors intoR2.
t-SNE converts high dimensional data set intoa matrix of pairwise similarities between individ-ual elements and then provides a way to visual-ize these distances in a way which is capable ofcapturing much of the local structure of the high-dimensional data very well, while also revealingglobal structure such as the presence of clusters atseveral scales.In the demo system, we give the user an optionto input words that they need to visualize whichare fed to the t-SNE tool and the produced imagesare shown to the user on the webpage.
These im-ages can then be downloaded and used.
We have9http://www-nlp.stanford.edu/?lmthang/morphoNLM/10http://homepage.tudelft.nl/19j49/t-SNE_files/tsne_python.zip20Figure 1: Antonyms (red) and synonyms (green) of beautiful represented by Faruqui and Dyer (2014)(left) and Huang et al.
(2012) (right).included two datasets by default which exhibit dif-ferent properties of the language:?
Antonyms and synonyms of beautiful?
Common male-female nouns and pronounsIn the first plot, ideally the antonyms (ugly,hideous, .
.
. )
and synonyms (pretty, gorgeous,.
.
. )
of beautiful should form two separate clus-ters in the plot.
Figure 1 shows the plots of theantonyms and synonyms of the word beautiful fortwo available embeddings.
The second defaultword plot is the gender data set, every word inwhich has a male and a female counterpart (ex.grandmother and grandfather), this data set ex-hibits both local and global properties.
Locally,the male and female counterparts should occur inpairs together and globally there should be twoseparate clusters of male and female.4 Word Vector Representations4.1 Pre-trained VectorsWe haves collected several standard pre-trainedword vector representations freely available for re-search purposes and provide a utility for the userto test them on the suite of benchmarks, as wellas try out the visualization functionality.
The usercan also choose the option to choose two differenttypes of word vectors and compare their perfor-mance on the benchmarks.
We will keep addingword vectors on the website as and when they arereleased.
The following word vectors have beenincluded in our collection:Metaoptimize.
These word embeddings11havebeen trained in (Turian et al., 2010) using a neu-ral network language model and were shown tobe useful for named entity recognition (NER) andphrase chunking.SENNA.
It is a software12which outputs a hostof predictions: part-of-speech (POS) tags, chunk-ing, NER etc (Collobert et al., 2011).
The soft-ware uses neural word embeddings trained overWikipedia data for over 2 months.RNNLM.
The recurrent neural network lan-guage modeling toolkit13comes with somepre-trained embeddings on broadcast newsdata (Mikolov et al., 2011).Global Context.
Huang et al.
(2012) present amodel to incorporate document level informationinto embeddings to generate semantically more in-formed word vector representations.
These em-beddings14capture both local and global contextof the words.Skip-Gram.
This model is a neural network lan-guage model except for that it does not have ahidden layer and instead of predicting the targetword, it predicts the context given the target word(Mikolov et al., 2013).
These embeddings aremuch faster to train15than the other neural em-beddings.11http://metaoptimize.com/projects/wordreprs/12http://ronan.collobert.com/senna/13http://rnnlm.org/14http://nlp.stanford.edu/?socherr/ACL2012_wordVectorsTextFile.zip15https://code.google.com/p/word2vec/21Figure 2: Vector selection interface (right) of the demo system.Multilingual.
Faruqui and Dyer (2014) proposea method based on canonical correlation analy-sis to produce more informed monolingual vec-tors using multilingual knowledge.
Their methodis shown to perform well for both neural embed-dings and LSA (Deerwester et al., 1990) basedvectors.164.2 User-created VectorsOur demo system provides the user an option toupload their word vectors to perform evaluationand visualization.
However, since the size of theword vector file will be huge due to a lot of in-frequent words that are not useful for evaluation,we give an option to filter the word vectors fileto only include the words required for evaluation.The script and the vocabulary file can be found onthe website online.5 Offline Evaluation & Public AccessWe provide an online portal where researchers canupload their vectors which are then be evaluatedon a variety of NLP tasks and then placed on theleader board.17The motivation behind creatingsuch a portal is to make it easier for a user to se-lect the kind of vector representation that is mostsuitable for their task.
In this scenario, instead ofasking the uploader to filter their word vectors fora small vocabulary, they will be requested to up-load their vectors for the entire vocabulary.16http://cs.cmu.edu/?mfaruqui/soft.html17We provide an initial list of some such tasks to which wewill later add more tasks as they are developed.5.1 Offline EvaluationSyntactic & semantic relations.
Mikolov et al.
(2013) present a new semantic and syntactic re-lation dataset composed of analogous word pairsof size 8869 and 10675 pairs resp..
It containspairs of tuples of word relations that follow a com-mon relation.
For example, in England : Lon-don :: France : Paris, the two given pairs of wordsfollow the country-capital relation.
We use thevector offset method (Mikolov et al., 2013) tocompute the missing word in these relations.
Thisis non-trivial |V |-way classification task where Vis the size of the vocabulary.Sentence Completion.
The Microsoft Researchsentence completion dataset contains 1040 sen-tences from each of which one word has been re-moved.
The task is to correctly predict the miss-ing word from a given list of 5 other words persentence.
We average the word vectors of a givensentence qsent=?Ni=1,i 6=jqwi/N , where wjisthe missing word and compute the cosine similar-ity of qsentvector with each of the options.
Theword with the highest similarity is chosen as themissing word placeholder.Sentiment Analysis Socher et al.
(2013b) havecreated a treebank which contains sentences an-notated with fine-grained sentiment labels on boththe phrase and sentence level.
They show thatcompositional vector space models can be usedto predict sentiment at these levels with high ac-curacy.
The coarse-grained treebank, containingonly positive and negative classes has been splitinto training, development and test datasets con-22Figure 3: Screenshot of the command line version showing word similarity evaluation.taining 6920, 872 and 1821 sentences respectively.We train a logistic regression classifier with L2regularization on the average of the word vectorsof a given sentence to predict the coarse-grainedsentiment tag at the sentence level.TOEFL Synonyms.
These are a set of 80 ques-tions compiled by Landauer and Dutnais (1997),where a given word needs to be matched to itsclosest synonym from 4 given options.
A num-ber of systems have reported their results on thisdataset.18We use cosine similarity to identify theclosest synonym.5.2 Offline SoftwareAlong with the web demo system we are makingavailable a software which can be downloaded andbe used for evaluation of vector representations of-fline on all the benchmarks listed above.
Since, wecannot distribute the evaluation benchmarks alongwith the software because of licensing issues, wewould give links to the resources which should bedownloaded prior to using the software.
This soft-ware can be run on a command line interface.
Fig-ure 3 shows a screenshot of word similarity evalu-ation using the software.5.3 Public AccessUsually corpora that the vectors are trained uponare not available freely because of licensing issuesbut it is easier to release the vectors that have beentrained on them.
In the system that we have devel-oped, we give the user an option to either make thevectors freely available for everyone to use under aGNU General Public License19or a Creative Com-mons License.20If the user chooses not to makethe word vectors available, we would evaluate the18http://aclweb.org/aclwiki/index.php?title=TOEFL_Synonym_Questions_(State_of_the_art)19https://www.gnu.org/copyleft/gpl.html20https://creativecommons.org/licenses/by-nc-sa/4.0/legalcodevectors and give it a position in the leader boardwith proper citation to the publications/softwares.6 ConclusionIn this paper we have presented a demo system thatsupports rapid and consistent evaluation of wordvector representations on a variety of tasks, visual-ization with an easy-to-use web interface and ex-change and comparison of different word vectorrepresentations.
The system also provides accessto a suite of evaluation benchmarks both for En-glish and other languages.
The functionalities ofthe system are aimed at: (1) Being a portal forsystematic evaluation of lexical semantics tasksthat heavily rely on word vector representation, (2)Making it easier for an end-user to choose the mostsuitable vector representation schema.AcknowledgementsWe thank members of Noah?s Ark and c-lab fortheir helpful comments about the demo system.Thanks to Devashish Thakur for his help in set-ting up the website.
This work was supported bythe NSF through grant IIS-1352440.ReferencesEneko Agirre, Enrique Alfonseca, Keith Hall, JanaKravalova, Marius Pas?ca, and Aitor Soroa.
2009.A study on similarity and relatedness using distribu-tional and wordnet-based approaches.
In Proceed-ings of NAACL, NAACL ?09, pages 19?27, Strouds-burg, PA, USA.Elia Bruni, Gemma Boleda, Marco Baroni, andNam Khanh Tran.
2012.
Distributional semanticsin technicolor.
In Proceedings of the 50th AnnualMeeting of the Association for Computational Lin-guistics (Volume 1: Long Papers), pages 136?145,Jeju Island, Korea, July.
Association for Computa-tional Linguistics.Ronan Collobert and Jason Weston.
2008.
A unifiedarchitecture for natural language processing: deep23neural networks with multitask learning.
In Pro-ceedings of the 25th international conference onMachine learning, ICML ?08, pages 160?167, NewYork, NY, USA.
ACM.Ronan Collobert, Jason Weston, L?eon Bottou, MichaelKarlen, Koray Kavukcuoglu, and Pavel Kuksa.2011.
Natural language processing (almost) fromscratch.
J. Mach.
Learn.
Res., 12:2493?2537,November.Maria Cristina Ferreira de Oliveira and Haim Lev-kowitz.
2003.
From visual data exploration to vi-sual data mining: A survey.
IEEE Trans.
Vis.
Com-put.
Graph., 9(3):378?394.S.
C. Deerwester, S. T. Dumais, T. K. Landauer, G. W.Furnas, and R. A. Harshman.
1990.
Indexing bylatent semantic analysis.
Journal of the AmericanSociety for Information Science.Manaal Faruqui and Chris Dyer.
2014.
Improvingvector space word representations using multilingualcorrelation.
In Proceedings of the 14th Conferenceof the European Chapter of the Association for Com-putational Linguistics, Gothenburg, Sweden, April.Association for Computational Linguistics.Lev Finkelstein, Evgeniy Gabrilovich, Yossi Matias,Ehud Rivlin, Zach Solan, Gadi Wolfman, and Ey-tan Ruppin.
2001.
Placing search in context: theconcept revisited.
In WWW ?01: Proceedings of the10th international conference on World Wide Web,pages 406?414, New York, NY, USA.
ACM Press.Guy Halawi, Gideon Dror, Evgeniy Gabrilovich, andYehuda Koren.
2012.
Large-scale learning of wordrelatedness with constraints.
In KDD, pages 1406?1414.Eric H Huang, Richard Socher, Christopher D Man-ning, and Andrew Y Ng.
2012.
Improving wordrepresentations via global context and multiple wordprototypes.
In Proceedings of the 50th ACL: LongPapers-Volume 1, pages 873?882.Thomas K Landauer and Susan T. Dutnais.
1997.
Asolution to platos problem: The latent semantic anal-ysis theory of acquisition, induction, and represen-tation of knowledge.
Psychological review, pages211?240.Minh-Thang Luong, Richard Socher, and Christo-pher D. Manning.
2013.
Better word representa-tions with recursive neural networks for morphol-ogy.
In CoNLL, Sofia, Bulgaria.Tomas Mikolov, Stefan Kombrink, Anoop Deoras,Lukar Burget, and J Cernock`y.
2011.
Rnnlm?recurrent neural network language modeling toolkit.Proc.
of the 2011 ASRU Workshop, pages 196?201.Tomas Mikolov, Kai Chen, Greg Corrado, and Jef-frey Dean.
2013.
Efficient estimation of wordrepresentations in vector space.
arXiv preprintarXiv:1301.3781.George A. Miller and Walter G. Charles.
1991.
Con-textual correlates of semantic similarity.
Languageand Cognitive Processes, 6(1):1?28.Jerome L. Myers and Arnold D. Well.
1995.
ResearchDesign & Statistical Analysis.
Routledge, 1 edition,June.Kira Radinsky, Eugene Agichtein, EvgeniyGabrilovich, and Shaul Markovitch.
2011.
Aword at a time: computing word relatedness usingtemporal semantic analysis.
In Proceedings of the20th international conference on World wide web,WWW ?11, pages 337?346, New York, NY, USA.ACM.Herbert Rubenstein and John B. Goodenough.
1965.Contextual correlates of synonymy.
Commun.
ACM,8(10):627?633, October.Richard Socher, Romain Paulus, Bryan McCann,Kai Sheng Tai, and Andrew Y. Hu, JiaJi Ng.
2013a.etcml.com - easy text classification with machinelearning.
In Advances in Neural Information Pro-cessing Systems (NIPS 2013).Richard Socher, Alex Perelygin, Jean Wu, JasonChuang, Christopher D. Manning, Andrew Y. Ng,and Christopher Potts.
2013b.
Recursive deep mod-els for semantic compositionality over a sentimenttreebank.
In Proceedings of the 2013 Conference onEmpirical Methods in Natural Language Process-ing, pages 1631?1642, Stroudsburg, PA, October.Association for Computational Linguistics.Joseph Turian, Lev Ratinov, and Yoshua Bengio.
2010.Word representations: a simple and general methodfor semi-supervised learning.
In Proceedings of the48th ACL, ACL ?10, pages 384?394, Stroudsburg,PA, USA.Peter D. Turney and Patrick Pantel.
2010.
From fre-quency to meaning : Vector space models of se-mantics.
Journal of Artificial Intelligence Research,pages 141?188.Peter D. Turney.
2006.
Similarity of semantic rela-tions.
Comput.
Linguist., 32(3):379?416, Septem-ber.Laurens van der Maaten and Geoffrey Hinton.
2008.Visualizing Data using t-SNE.
Journal of MachineLearning Research, 9:2579?2605, November.Dongqiang Yang and David M. W. Powers.
2006.
Verbsimilarity on the taxonomy of wordnet.
In In the 3rdInternational WordNet Conference (GWC-06), JejuIsland, Korea.24
