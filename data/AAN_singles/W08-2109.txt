CoNLL 2008: Proceedings of the 12th Conference on Computational Natural Language Learning, pages 65?72Manchester, August 2008Improving Word Segmentation by Simultaneously Learning PhonotacticsDaniel BlanchardComputer & Information SciencesUniversity of Delawaredsblanch@udel.eduJeffrey HeinzLinguistics & Cognitive ScienceUniversity of Delawareheinz@udel.eduAbstractThe most accurate unsupervised word seg-mentation systems that are currently avail-able (Brent, 1999; Venkataraman, 2001;Goldwater, 2007) use a simple unigrammodel of phonotactics.
While this sim-plifies some of the calculations, it over-looks cues that infant language acquisitionresearchers have shown to be useful forsegmentation (Mattys et al, 1999; Mattysand Jusczyk, 2001).
Here we explore theutility of using bigram and trigram phono-tactic models by enhancing Brent?s (1999)MBDP-1 algorithm.
The results showthe improved MBDP-Phon model outper-forms other unsupervised word segmenta-tion systems (e.g., Brent, 1999; Venkatara-man, 2001; Goldwater, 2007).1 IntroductionHow do infants come to identify words in thespeech stream?
As adults, we break up speechinto words with such ease that we often thinkthat there are audible pauses between words in thesame sentence.
However, unlike some written lan-guages, speech does not have any completely reli-able markers for the breaks between words (Coleand Jakimik, 1980).
In fact, languages vary on howthey signal the ends of words (Cutler and Carter,1987), which makes the task even more daunting.Adults at least have a lexicon they can use to rec-ognize familiar words, but when an infant is firstborn, they do not have a pre-existing lexicon toconsult.
In spite of these challenges, by the age ofc?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.six months infants can begin to segment words outof speech (Bortfeld et al, 2005).
Here we presentan efficient word segmentation system aimed tomodel how infants accomplish the task.While an algorithm that could reliably extractorthographic representations of both novel and fa-miliar words from acoustic data is something wewould like to see developed, following earlier re-searchers, we simplify the problem by using a textthat does not contain any word boundary markers.Hereafter, we use the phrase ?word segmentation?to mean some process which adds word boundariesto a text that does not contain them.This paper?s focus is on unsupervised, incre-mental word segmentation algorithms; i.e., thosethat do not rely on preexisting knowledge of a par-ticular language, and those that segment the cor-pus one utterance at a time.
This is in contrastto supervised word segmentation algorithms (e.g.,Teahan et al, 2000), which are typically used forsegmenting text in documents written in languagesthat do not put spaces between their words likeChinese.
(Of course, unsupervised word segmen-tation algorithms also have this application.)
Thisalso differs from batch segmentation algorithms(Goldwater, 2007; Johnson, 2008b; Fleck, 2008),which process the entire corpus at least once be-fore outputting a segmentation of the corpus.
Un-supervised incremental algorithms are of interestto some psycholinguists and acquisitionists inter-ested in the problem of language learning, as wellas theoretical computer scientists who are inter-ested in what unsupervised, incremental modelsare capable of achieving.Phonotactic patterns are the rules that deter-mine what sequences of phonemes or allophonesare allowable within words.
Learning the phono-tactic patterns of a language is usually modeled65separately from word segmentation; e.g., currentphonotactic learners such as Coleman and Pierre-humbert (1997), Heinz (2007), or Hayes and Wil-son (2008) are given word-sized units as input.However, infants appear to simultaneously learnwhich phoneme combinations are allowable withinwords and how to extract words from the input.
Itis reasonable that the two processes feed into oneanother, and when infants acquire a critical mass ofphonotactic knowledge, they use it to make judge-ments about what phoneme sequences can occurwithin versus across word boundaries (Mattys andJusczyk, 2001).
We use this insight, also suggestedby Venkataraman (2001) and recently utilized byFleck (2008) in a different manner, to enhanceBrent?s (1999) model MBDP-1, and significantlyincrease segmentation accuracy.
We call this mod-ified segmentation model MBDP-Phon.2 Related Work2.1 Word SegmentationThe problem of unsupervised word segmentationhas attracted many earlier researchers over thepast fifty years (e.g., Harris, 1954; Olivier, 1968;de Marcken, 1995; Brent, 1999).
In this section,we describe the base model MBDP-1, along withtwo other segmentation approaches, Venkataraman(2001) and Goldwater (2007).
In ?4, we compareMBDP-Phon to these models in more detail.
Fora thorough review of word segmentation literature,see Brent (1999) or Goldwater (2007).2.1.1 MBDP-1Brent?s (1999) MBDP-1 (Model Based Dy-namic Programming) algorithm is an implemen-tation of the INCDROP framework (Brent, 1997)that uses a Bayesian model of how to generate anunsegmented text to insert word boundaries.
Thegenerative model consists of five steps:1.
Choose a number of word types, n.2.
Pick n distinct strings from ?+#, which willmake up the lexicon, L. Entries in L are la-beled W1.
.
.Wn.
W0= $, where $ is theutterance boundary marker.3.
Pick a function, f , which maps word types totheir frequency in the text.4.
Choose a function, s, to map positions in thetext to word types.5.
Concatenate the words in the order specifiedby s, and remove the word delimiters (#).It is important to note that this model treats thegeneration of the text as a single event in the prob-ability space, which allows Brent to make a num-ber of simplifying assumptions.
As the values forn,L, f, and s completely determine the segmenta-tion, the probability of a particular segmentation,wm, can be calculated as:P (wm) = P (n,L, f, s) (1)To allow the model to operate on one utterance ata time, Brent states the probability of each word inthe text as a recursive function, R(wk), where wkis the text up to and including the word at positionk, wk.
Furthermore, there are two specific casesfor R: familiar words and novel words.
If wkisfamiliar, the model already has the word in its lex-icon, and its score is calculated as in Equation 2.R(wk) =f(wk)k?(f(wk)?
1f(wk))2(2)Otherwise, the word is novel, and its score is cal-culated using Equation 31(Brent and Tao, 2001),R(wk) =6pi2?nk?P?(a1)...P?(aq)1?P?(#)?
(n?1n)2(3)where P?is the probability of a particularphoneme occurring in the text.
The third term ofthe equation for novel words is where the model?sunigram phonotactic model comes into play.
Wedetail how to plug a more sophisticated phonotac-tic learning model into this equation in ?3.
Withthe generative model established, MBDP-1 uses aViterbi-style search algorithm to find the segmen-tation for each utterance that maximizes the R val-ues for each word in the segmentation.Venkataraman (2001) notes that considering thegeneration of the text as a single event is un-likely to be how infants approach the segmenta-tion problem.
However, MBDP-1 uses an incre-mental search algorithm to segment one utteranceat a time, which is more plausible as a model ofinfants?
word segmentation.1Brent (1999) originally described the novel word scoreas R(wk) =6pi2?nkk?P?(Wnk)1?nk?1nk??nkj=1P?(Wj)?
(nk?1nk)2,where P?is the probability of all the phonemes in the wordoccurring together, but the denominator of the third term wasdropped in Brent and Tao (2001).
This change drasticallyspeeds up the model, and only reduces segmentation accuracyby ?
0.5%.662.1.2 Venkataraman (2001)MBDP-1 is not the only incremental unsuper-vised segmentation model that achieves promis-ing results.
Venkataraman?s (2001) model tracksMBDP-1?s performance so closely that Batchelder(2002) posits that the models are performing thesame operations, even though the authors describethem differently.Venkataraman?s model uses a more traditional,smoothed n-gram model to describe the distribu-tion of words in an unsegmented text.2The mostprobable segmentation is retrieved via a dynamicprogramming algorithm, much like Brent (1999).We use MBDP-1 rather than Venkataraman?sapproach as the basis for our model only because itwas more transparent how to plug in a phonotacticlearning module at the time this project began.2.1.3 Goldwater (2007)We also compare our results to a segmenter putforward by Goldwater (2007).
Goldwater?s seg-menter uses an underlying generative model, muchlike MBDP-1 does, only her language model isdescribed as a Dirichlet process (see also John-son, 2008b).
While this model uses a unigrammodel of phoneme distribution, as did MBDP-1, itimplements a bigram word model like Venkatara-man (2001).
A bigram word model is useful inthat it prevents the segmenter from assuming thatfrequent word bigrams are not simply one word,which Goldwater observes happen with a unigramversion of her model.Goldwater uses a Gibbs sampler augmentedwith simulated annealing to sample from the pos-terior distribution of segmentations and deter-mine the most likely segmentation of each utter-ance.3This approach requires non-incrementallearning.4We include comparison with Goldwa-ter?s segmenter because it outperforms MBDP-1and Venkataraman (2001) in both precision andrecall, and we are interested in whether an incre-mental algorithm supplemented with phonotacticlearning can match its performance.2.2 Phonotactic LearningPhonotactic acquisition models have seen a surgein popularity recently (e.g., Coleman and Pierre-2We refer the reader to Venkataraman (2001) for the de-tails of this approach.3We direct the reader to Goldwater (2007) for details.4In our experiments and those in Goldwater (2007), thesegmenter runs through the corpus 1000 times before out-putting the final segmentation.humbert, 1997; Heinz, 2007; Hayes and Wilson,2008).
While Hayes and Wilson present a morecomplex Maximum Entropy phonotactic model intheir paper than the one we add to MBDP-1, theyalso evaluate a simple n-gram phonotactic learneroperating over phonemes.
The input to the mod-els is a list of English onsets and their frequencyin the lexicon, and the basic trigram learner simplykeeps track of the trigrams it has seen in the cor-pus.
They test the model on novel words with ac-ceptable rhymes?some well-formed (e.g., [kIp]),and some less well-formed (e.g., [stwIk])?so anyill-formedness is attributable to onsets.
This ba-sic trigram model explains 87.7% of the variancein the scores that Scholes (1966) reports his 7thgrade students gave when subjected to the sametest.
When Hayes and Wilson run their MaximumEntropy phonotactic learning model with n-gramsover phonological features, the r-score increasessubstantially to 95.6%.Given the success and simplicity of the basic n-gram phonotactic model, we choose to integratethis with MBDP-1.3 Extending MBDP-1 with PhonotacticsThe main contribution of our work is addinga phonotactic learning component to MBDP-1(Brent, 1999).
As we mention in ?2.1.1, the thirdterm of Equation 3 is where MBDP-1?s unigramphonotactic assumption surfaces.
The originalmodel simply multiplies the probabilities of all thephonemes in the word together and divides by oneminus the probability of a particular phoneme be-ing the word boundary to come up with probabil-ity of the phoneme combination.
The order of thephonemes in the word has no effect on its score.The only change we make to MBDP-1 is to thethird term of Equation 3.
In MBDP-Phon this be-comesq?i=0PMLE(ai.
.
.
aj) (4)where ai.
.
.
ajis an n-gram inside a proposedword, and a0and aqare both the word boundarysymbol, #5.It is important to note that probabilities calcu-lated in Equation 4 are maximum likelihood esti-mates of the joint probability of each n-gram in theword.
The maximum likelihood estimate (MLE)5The model treats word boundary markers like a phonemefor the purposes of storing n-grams (i.e., a word boundarymarker may occur anywhere within the n-grams).67for a particular n-gram inside a word is calculatedby dividing the total number of occurrences of thatn-gram (including in the word we are currently ex-amining) by the total number of n-grams (includ-ing those in the current word).
The numbers ofn-grams are computed with respect to the obtainedlexicon, not the corpus, and thus the frequency oflexical items in the corpus does not affect the n-gram counts, just like Brent?s unigram phonotacticmodel and other phonotactic learning models (e.g.,Hayes and Wilson, 2008).We use the joint probability instead of the con-ditional probability which is often used in compu-tational linguistics (Manning and Sch?utze, 1999;Jurafsky and Martin, 2000), because of our intu-ition that the joint probability is truer to the ideathat a phonotactically well-formed word is madeup of n-grams that occur frequently in the lexicon.On the other hand, the conditional probability isused when one tries to predict the next phonemethat will occur in a word, rather than judging thewell-formedness of the word as a whole.6We are able to drop the denominator that wasoriginally in Equation 3, because P?
(#) is zerofor an n-gram model when n > 1.
This sim-ple modification allows the model to learn whatphonemes are more likely to occur at the begin-nings and ends of words, and what combinationsof phonemes rarely occur within words.What is especially interesting about this mod-ification is that the phonotactic learning compo-nent estimates the probabilities of the n-grams byusing their relative frequencies in the words thesegmenter has extracted.
The phonotactic learneris guaranteed to see at least two valid patterns inevery utterance, as the n-grams that occur at thebeginnings and ends of utterances are definitelyat the beginnings and ends of words.
This al-lows the learner to provide useful information tothe segmenter even early on, and as the segmentercorrectly identifies more words, the phonotacticlearner has more correct data to learn from.
Notonly is this mutually beneficial process supportedby evidence from language acquisitionists (Mat-tys et al, 1999; Mattys and Jusczyk, 2001), it alsoresembles co-training (Blum and Mitchell, 1998).We refer to the extended version of Brent?s model6This intuition is backed up by preliminary results sug-gesting MBDP-Phon performs better when usingMLEs of thejoint probability as opposed to conditional probability.
Thereis an interesting question here, which is beyond the scope ofthis paper, so we leave it for future investigation.described above as MBDP-Phon.4 Evaluation4.1 The CorpusWe run all of our experiments on the Bernstein-Ratner (1987) infant-directed speech corpus fromthe CHILDES database (MacWhinney and Snow,1985).
This is the same corpus that Brent (1999),Goldwater (2007), and Venkataraman (2001) eval-uate their models on, and it has become the defacto standard for segmentation testing, as unlikeother corpora in CHILDES, it was phoneticallytranscribed.We examine the transcription system Brent(1999) uses and conclude some unorthodoxchoices were made when transcribing the corpus.Specifically, some phonemes that are normallyconsidered distinct are combined into one symbol,which we call a bi-phone symbol.
These phonemescombinations include diphthongs and vowels fol-lowed by /?/.
Another seemingly arbitrary deci-sion is the distinction between stressed and un-stressed syllabic /?/ sound (i.e., there are differ-ent symbols for the /?/ in ?butter?
and the /?/ in?bird?)
since stress is not marked elsewhere in thecorpus.
To see the effect of these decisions, wemodified the corpus so that the bi-phone symbolswere split into two7and the syllabic /?/ symbolswere collapsed into one.4.2 AccuracyWe ran MBDP-1 on the original corpus, and themodified version of the corpus.
As illustrated byFigures 1 and 2, MBDP-1 performs worse on themodified corpus with respect to both precision andrecall.
As MBDP-1 and MBDP-Phon are both iter-ative learners, we calculate segmentation precisionand recall values over 500-utterance blocks.
PerBrent (1999) and Goldwater (2007), precision andrecall scores reflect correctly segmented words,not correctly identified boundaries.We also test to see how the addition of an n-gramphonotactic model affects the segmentation accu-racy of MBDP-Phon by comparing it to MBDP-1 on our modified corpus.8As seen in Figure 3,MBDP-Phon using bigrams (henceforth MBDP-Phon-Bigrams) is consistently more precise in its7We only split diphthongs whose first phoneme can occurin isolation in English, so the vowels in ?bay?
and ?boat?
werenot split.8We also compare MBDP-Phon to MBDP-1 on the origi-nal corpus.
The results are given in Tables 1 and 2.680.450.500.550.600.650.700.75500 1500 2500 3500 4500 5500 6500 7500 8500 9500PrecisionUtterances ProcessedModified OriginalFigure 1: Precision of MBDP-1 on both corpora.0.400.450.500.550.600.650.700.750.80500 1500 2500 3500 4500 5500 6500 7500 8500 9500RecallUtterances ProcessedModified OriginalFigure 2: Recall of MBDP-1 on both corpora.segmentation thanMBDP-1, and bests it by?
18%in the last block.
Furthermore, MBDP-Phon-Bigrams significantly outpaces MBDP-1 with re-spect to recall only after seeing 1000 utterances,and finishes the corpus ?
10% ahead of MBDP-1 (see Figure 4).
MBDP-Phon-Trigrams does notfair as well in our tests, falling behind MBDP-1and MBDP-Phon-Bigrams in recall, and MBDP-Phon-Bigrams in precision.
We attribute this poorperformance to the fact that we are not currentlysmoothing the n-gram models in any way, whichleads to data sparsity issues when using trigrams.We discuss a potential solution to this problem in?5.Having established that MBDP-Phon-Bigramssignificantly outperforms MBDP-1, we compareits segmentation accuracy to those of Goldwater(2007) and Venkataraman (2001).9As before, we9We only examine Venkataraman?s unigram model, as hisbigram and trigram models perform better on precision, butworse on recall.0.500.550.600.650.700.750.800.85500 1500 2500 3500 4500 5500 6500 7500 8500 9500PrecisionUtterances ProcessedMBDP-1 MBDP-Bigrams MBDP-TrigramsFigure 3: Precision of MBDP-1 and MBDP-Phonon modified corpus.0.400.450.500.550.600.650.700.750.800.85500 1500 2500 3500 4500 5500 6500 7500 8500 9500RecallUtterances ProcessedMBDP-1 MBDP-Bigrams MBDP-TrigramsFigure 4: Recall of MBDP-1 and MBDP-Phon onmodified corpus.run the models on the entire corpus, and then mea-sure their performance over 500-utterance blocks.MBDP-Phon-Bigrams edges out Goldwater?smodel in precision on our modified corpus, withan average precision of 72.79% vs. Goldwa-ter?s 70.73% (Table 1).
If we drop the first 500-utterance block for MBDP-Phon-Bigrams becausethe model is still in the early learning stages,whereas Goldwater?s has seen the entire corpus, itsaverage precision increases to 73.21% (Table 1).When considering the recall scores in Table 2,it becomes clear that MBDP-Phon-Bigrams has aclear advantage over the other models.
Its aver-age recall is higher than or nearly equal to bothof the other models?
maximum scores.
SinceVenkataraman?s (2001) model performs similarlyto MBDP-1, it is no surprise that MBDP-Phon-Bigrams achieves higher precision and recall.69MBDP-Phon-BigramsVenkataraman GoldwaterOriginal: Utterances 0 to 9790Avg.
72.84% 67.46% 67.87%Max.
79.91% 71.79% 71.98%Min.
63.97% 61.77% 61.87%Modified: Utterances 0 to 9790Avg.
72.79% 59.64% 70.73%Max.
80.60% 66.84% 74.61%Min.
64.78% 52.54% 65.29%Modified: Utterances 500 to 9790Avg.
73.21% 59.54% 70.59%Max.
80.60% 66.84% 74.61%Min.
67.40% 52.54% 65.29%Table 1: Precision statistics for MBDP-Phon-Bigrams, Goldwater, and Venkataraman on bothcorpora over 500-utterance blocks.The only metric by which MBDP-Phon-Bigrams does not outperform the other algorithmsis lexical precision, as shown in Table 3.
Lexi-cal precision is the ratio of the number of correctlyidentified words in the lexicon to the total numberof words in the lexicon (Brent, 1999; Venkatara-man, 2001).10The relatively poor performanceof MBDP-Phon-Bigrams is due to the incrementalnature of the MBDP algorithm.
Initially, it makesnumerous incorrect guesses that are added to thelexicon, and there is no point at which the lexi-con is purged of earlier erroneous guesses (c.f.
theimproved lexical precision when omitting the firstblock in Table 3).
On the other hand, Goldwater?salgorithm runs over the corpus multiple times, andonly produces output when it settles on a final seg-mentation.In sum, MBDP-Phon-Bigrams significantly im-proves the accuracy of MBDP-1, and achievesbetter performance than the models described inVenkataraman (2001) and Goldwater (2007).5 Future WorkThere are many ways to implement phonotacticlearning.
One idea is to to use n-grams over phono-logical features, as per Hayes and Wilson (2008).Preliminary results have shown that we need to addsmoothing to our n-grammodel, and we plan to use10See Brent (1999) for a discussion of the meaning of thisstatistic.MBDP-Phon-BigramsVenkataraman GoldwaterOriginal: Utterances 0 to 9790Avg.
72.03% 70.02% 71.02%Max.
79.31% 75.59% 76.79%Min.
44.71% 42.57% 64.32%Modified: Utterances 0 to 9790Avg.
74.63% 66.24% 70.48%Max.
82.45% 70.47% 74.79%Min.
47.63% 44.71% 63.74%Modified: Utterances 500 to 9790Avg.
76.05% 67.37% 70.28%Max.
82.45% 70.47% 74.79%Min.
71.92% 63.86% 63.74%Table 2: Recall statistics for MBDP-Phon-Bigrams, Goldwater, and Venkataraman on bothcorpora over 500-utterance blocks.Modified Kneser-Ney smoothing (Chen and Good-man, 1998).Another approach would be to develop asyllable-based phonotactic model (Coleman andPierrehumbert, 1997).
Johnson (2008b) achievesimpressive segmentation results by adding a sylla-ble level with Adaptor grammars.Some languages (e.g., Finnish, and Navajo)contain long-distance phonotactic constraints thatcannot be learned by n-gram learners (Heinz,2007).
Heinz (2007) shows that precedence-basedlearners?which work like a bigram model, butwithout the restriction that the elements in the bi-gram be adjacent?can handle many long-distanceagreement patterns (e.g., vowel and consonantalharmony) in the world?s languages.
We posit thatadding such a learner to MBDP-Phon would allowit to handle a greater variety of languages.Since none of these approaches to phonotacticlearning depend on MBDP-1, it is also of interestto integrate phonotactic learners with other wordsegmentation strategies.In addition to evaluating segmentation modelsintegrated with phonotactic learning on their seg-mentation performance, it would be interesting toevaluate the quality of the phonotactic grammarsobtained.
A good point of comparison for Englishare the constraints obtained by Hayes and Wilson(2008), since the data with which they tested theirphonotactic learner is publicly available.Finally, we are looking forward to investigat-70MBDP-Phon-BigramsVenkataraman GoldwaterOriginal: Utterances 0 to 9790Avg.
47.69% 49.78% 56.50%Max.
49.71% 52.95% 63.09%Min.
46.30% 41.83% 55.33%Modified: Utterances 0 to 9790Avg.
48.31% 45.98% 58.03%Max.
50.42% 48.90% 65.58%Min.
41.74% 36.57% 56.43%Modified: Utterances 500 to 9790Avg.
54.34% 53.06% 57.95%Max.
63.76% 54.35% 62.30%Min.
51.31% 51.95% 56.52%Table 3: Lexical precision statistics for MBDP-Phon-Bigrams, Goldwater, and Venkataraman onboth corpora over 500-utterance blocks.ing the abilities of these segmenters on corporaof different languages.
Fleck (2008) tests her seg-menter on a number of corpora, including Arabicand Spanish, and Johnson (2008a) applies his seg-menter to a corpus of Sesotho.6 ConclusionFrom the results established in ?4, we can con-clude that MBDP-Phon using a bigram phonotac-tic model is more accurate than the models de-scribed in Brent (1999), Venkataraman (2001), andGoldwater (2007).
The n-gram phonotactic modelimproves overall performance, and is especiallyuseful for corpora that do not encode diphthongswith bi-phone symbols.
The main reason thereis such a marked improvement with MBDP-Phonvs.
MBDP-1 when the bi-phone symbols were re-moved from the original corpus is that these bi-phone symbols effectively allow MBDP-1 to havea select few bigrams in the cases where it wouldotherwise over-segment.The success of MBDP-Phon is not clear evi-dence that the INCDROP framework (Brent, 1997)is superior to Venkataraman or Goldwater?s mod-els.
We imagine that adding a phonotactic learningcomponent to either of their models would also im-prove their performance.We also tentatively conclude that phonotacticpatterns can be learned from unsegmented text.However, the phonotactic patterns learned by ourmodel ought to be studied in detail to see how wellthey match the phonotactic patterns of English.MBDP-Phon?s performance reinforces the the-ory put forward by language acquisition re-searchers that phonotactic knowledge is a cue forword segmentation (Mattys et al, 1999; Mattysand Jusczyk, 2001).
Furthermore, our results in-dicate that learning phonotactic patterns can oc-cur simultaneously with word segmentation.
Fi-nally, further investigation of the simultaneous ac-quisition of phonotactics and word segmentationappears fruitful for theoretical and computationallinguists, as well as acquisitionists.AcknoledgementsWe are grateful to Roberta Golinkoff who inspiredthis project.
We also thank Vijay Shanker forvaluable discussion, Michael Brent for the corpus,and Sharon Goldwater for the latest version of hercode.ReferencesBatchelder, Eleanor Olds.
2002.
Bootstrapping thelexicon: a computational model of infant speechsegmentation.
Cognition, 83(2):167?206.Bernstein-Ratner, Nan.
1987.
The phonology ofparent child speech, volume 6.
Erlbaum, Hills-dale, NJ.Blum, Avrim and Tom Mitchell.
1998.
Combininglabeled and unlabeled data with co-training.
InWorkshop on Computational Learning Theory,pages 92?100.Bortfeld, Heather, James Morgan, RobertaGolinkoff, and Karen Rathbun.
2005.
Mommyand me: Familiar names help launch babies intospeech-stream segmentation.
PsychologicalScience, 16(4):298?304.Brent, Michael R. 1997.
Towards a unified modelof lexical acquisition and lexical access.
Journalof Psycholinguistic Research, 26(3):363?375.Brent, Michael R. 1999.
An efficient, probabilis-tically sound algorithm for segmentation andword discovery.
Machine Learning, 34:71?105.Brent, Michael R and Xiaopeng Tao.
2001.
Chi-nese text segmentation with mbdp-1: Makingthe most of training corpora.
In 39th AnnualMeeting of the ACL, pages 82?89.Chen, Stanley F and Joshua Goodman.
1998.
Anempirical study of smoothing techniques for lan-guage modeling.
Technical Report TR-10-98,71Center for Research in Computing Technology,Harvard University.Cole, Ronald and Jola Jakimik.
1980.
A model ofspeech perception, pages 136?163.
LawrenceErlbaum Associates, Hillsdale, NJ.Coleman, John and Janet Pierrehumbert.
1997.Stochastic phonological grammars and accept-ability.
In Third Meeting of the ACL SIGPHON,pages 49?56.
ACL, Somerset, NJ.Cutler, Anne and David Carter.
1987.
The predom-inance of strong initial syllables in the englishvocabulary.
Computer Speech and Language,2(3-4):133?142.de Marcken, Carl.
1995.
Acquiring a lexicon fromunsegmented speech.
In 33rd Annual Meetingof the ACL, pages 311?313.Fleck, Margaret M. 2008.
Lexicalized phonotacticword segmentation.
In 46th Annual Meeting ofthe ACL, pages 130?138.
ACL, Morristown, NJ.Goldwater, Sharon.
2007.
NonparametricBayesian Models of Lexical Acquisition.
Ph.D.thesis, Brown University, Department of Cogni-tive and Linguistic Sciences.Harris, Zellig.
1954.
Distributional structure.Word, 10(2/3):146?62.Hayes, Bruce and Colin Wilson.
2008.
A maxi-mum entropy model of phonotactics and phono-tactic learning.
Linguistic Inquiry.Heinz, Jeffrey.
2007.
Inductive Learning of Phono-tactic Patterns.
Ph.D. thesis, University of Cali-fornia, Los Angeles, Department of Linguistics.Johnson, Mark.
2008a.
Unsupervised word seg-mentation for sesotho using adaptor grammars.In Tenth Meeting of ACL SIGMORPHON, pages20?27.
ACL, Morristown, NJ.Johnson, Mark.
2008b.
Using adaptor grammarsto identify synergies in the unsupervised acqui-sition of linguistic structure.
In 46th AnnualMeeting of the ACL, pages 398?406.
ACL, Mor-ristown, NJ.Jurafsky, Daniel and James Martin.
2000.
Speechand Language Processing.
Prentice-Hall.MacWhinney, Brian and Catherine Snow.
1985.The child language data exchange system.
Jour-nal of child language, 12(2):271?95.Manning, Christopher and Hinrich Sch?utze.
1999.Foundations of Statistical Natural LanguageProcessing.
MIT Press.Mattys, Sven and Peter Jusczyk.
2001.
Phonotac-tic cues for segmentation of fluent speech by in-fants.
Cognition, 78:91?121.Mattys, Sven, Peter Jusczyk, Paul Luce, and JamesMorgan.
1999.
Phonotactic and prosodic effectson word segmentation in infants.
Cognitive Psy-chology, 38:465?494.Olivier, Donald.
1968.
Stochastic Grammars andLanguage Acquisition Mechanisms.
Ph.D. the-sis, Harvard Univerity.Scholes, Robert.
1966.
Phonotactic Grammatical-ity.
Mouton, The Hague.Teahan, W. J., Rodger McNab, Yingying Wen, andIan H. Witten.
2000.
A compression-based al-gorithm for chinese word segmentation.
Com-putational Linguistics, 26(3):375?393.Venkataraman, Anand.
2001.
A statistical modelfor word discovery in transcribed speech.
Com-putational Linguistics, 27(3):352?372.72
