Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 824?832,Beijing, August 2010Automatic Discovery of Feature Sets for Dependency ParsingPeter Nilsson Pierre NuguesDepartment of Computer ScienceLund Universitypeter.nilsson.lund@telia.com Pierre.Nugues@cs.lth.seAbstractThis paper describes a search procedureto discover optimal feature sets for depen-dency parsers.
The search applies to theshift?reduce algorithm and the feature setsare extracted from the parser configura-tion.
The initial feature is limited to thefirst word in the input queue.
Then, theprocedure uses a set of rules founded onthe assumption that topological neighborsof significant features in the dependencygraph may also have a significant contri-bution.
The search can be fully automatedand the level of greediness adjusted withthe number of features examined at eachiteration of the discovery procedure.Using our automated feature discoveryon two corpora, the Swedish corpus inCoNLL-X and the English corpus inCoNLL 2008, and a single parser system,we could reach results comparable or bet-ter than the best scores reported in theseevaluations.
The CoNLL 2008 test setcontains, in addition to a Wall Street Jour-nal (WSJ) section, an out-of-domain sam-ple from the Brown corpus.
With sets of15 features, we obtained a labeled attach-ment score of 84.21 for Swedish, 88.11 onthe WSJ test set, and 81.33 on the Browntest set.1 IntroductionThe selection of relevant feature sets is crucialto the performance of dependency parsers andthis process is still in large part manual.
More-over, feature sets are specific to the languages be-ing analyzed and a set optimal for, say, Englishcan yield poor results in Chinese.
With depen-dency parsers being applied today to dozens oflanguages, this makes the parametrization of aparser both a tedious and time-consuming opera-tion.
Incidentally, the advent of machine-learningmethods seems to have shifted the tuning steps inparsing from polishing up grammar rules to theoptimization of feature sets.
And as with the writ-ing of a grammar, the selection of features is achallenging task that often requires a good deal ofeffort and inspiration.Most automatic procedures to build feature setsresort to greedy algorithms.
Forward selectionconstructs a set by adding incrementally featuresfrom a predetermined superset while backwardelimination removes them from the superset (At-tardi et al, 2007).
Both methods are sometimescombined (Nivre et al, 2006b).
The selection pro-cedures evaluate the relevance of a candidate fea-ture in a set by its impact on the overall parsingscore: Does this candidate improve or decreasethe performance of the set?Greedy search, although it simplifies the designof feature sets, shows a major drawback as it startsfrom a closed superset of what are believed to bethe relevant features.
There is a broad consen-sus on a common feature set including the wordsclose to the top of the stack or the beginning of thequeue, for the shift?reduce algorithm, but no clearidea on the limits of this set.In this paper, we describe an automatic discov-ery procedure that is not bounded by any priorknowledge of a set of potentially relevant features.It applies to the shift?reduce algorithm and the ini-824tial feature consists solely of the first word of thequeue.
The search explores nodes along axes ofthe parser?s data structures and the partially builtgraph using proximity rules to uncover sequencesof relevant, efficient features.
Using this proce-dure on the Swedish corpus in CoNLL-X and theEnglish corpus in CoNLL 2008, we built featuresets that enabled us to reach a labeled attachmentscore of 84.21 for Swedish, 88.11 on the WallStreet Journal section of CoNLL 2008, and 81.33on the Brown part of it with a set cardinality of 15.2 Transition-based ParsingTransition-based methods (Covington, 2001;Nivre, 2003; Yamada and Matsumoto, 2003;Zhang and Clark, 2009) have become a popularapproach in multilingual dependency parsing be-cause of their speed and performance.
Transition-based methods share common properties andbuild a dependency graph from a sequence of ac-tions, where each action is determined using a fea-ture function.
In a data-driven context, the func-tion is typically implemented as a classifier andthe features are extracted from the partially builtgraph and the parser?s data structures, most oftena queue and a stack.2.1 Parser ImplementationIn this study, we built a parser using Nivre?s al-gorithm (Nivre, 2003).
The parser complexity islinear and parsing completes in at most 2n+1 op-erations, where n is the length of the sentence.
Ta-ble 1 shows the transitions and actions to constructa dependency graph.Given a sentence to parse, we used a classifier-based guide to predict the transition sequence toapply.
At each step, the guide extracts featuresfrom the parser configuration and uses them as in-put to a classifier to predict the next transition.
Be-fore training the classification models, we projec-tivized the corpus sentences (Kunze, 1967; Nivreand Nilsson, 2005).
We did not attempt to recovernonprojective sentences after parsing.2.2 Training and Parsing ProcedureWe extracted the features using a gold-standardparsing of the training set.
We organized the clas-sification, and hence the feature extraction, as aAction Parser configurationInit.
?nil,W, /0?End ?S,nil,G?LeftArc ?n|S,n?|Q,G?
??S,n?|Q,G?{?n?,n?
}?RightArc ?n|S,n?|Q,G?
??n?|n|S,Q,G?{?n,n??
}?Reduce ?n|S,Q,G?
?
?S,Q,G?Shift ?S,n|Q,G?
?
?n|S,Q,G?Table 1: Parser transitions (Nivre, 2003).
W isthe input, G, the graph, S, the stack, and Q, thequeue.
The triple ?S,Q,G?
represents the parserconfiguration and n, n ?, and n??
are lexical tokens.?n?,n?
represents an arc from n?
to n.two-step process.
The first step determines the ac-tion among LeftArc, RightArc, Reduce, and Shift;the second one, the grammatical function, if theaction is either a left arc or a right arc.Once the features are extracted, we train thecorresponding models that we apply to the testcorpus to predict the actions and the arc labels.3 Feature DiscoveryWe designed an automatic procedure to discoverand select features that is guided by the structureof the graph being constructed.
The search al-gorithm is based on the assumption that if a fea-ture makes a significant contribution to the parsingperformance, then one or more of its topologicalneighbors in the dependency graph may also besignificant.
The initial state, from which we de-rive the initial feature, consists of the first word inthe queue.
There is no other prior knowledge onthe features.3.1 Node AttributesIn the discovery procedure, we considered thenodes of four data structures: the queue, the stack,the sentence, and the graph being constructed.We extracted three attributes (or fields) from eachnode: two static ones, the lexical value of thenode and its part of speech, and a dynamic oneevaluated at parse time: the dependency label ofthe arc linking the node to its head, if it exists.We denoted the attributes of node w, respectively,825LEX(w), POS(w), and DEP(w).
These attributesare used as input by most dependency parsers,whatever the language being parsed.3.2 Search AxesThe feature search covers three different axes: theparser?s data structures ?
the queue and the stack?, the graph being constructed, and the sentence.Given a feature set at step n of the discovery pro-cedure, we defined a successor function that gen-erates the set of topological neighbors of all themembers in the feature set alng these three axes.For a particular feature:The data structure axis consists of the nodes inthe stack and the queue.
The immediateneighbors of a node in the stack are the ad-jacent nodes above and below.
In the queue,these are the adjacent nodes before and af-ter it.
The top node on the stack and thenext node in the queue have a special con-nection, since they are the ones used by theparser when creating an arc.
Therefore, weconsidered them as immediate neighbors toeach other.
For a node that is neither in thestack, nor in the queue, there is no connec-tion along this axis.The graph axes traverse the partially con-structed graph horizontally and vertically.The horizontal axis corresponds to thesibling nodes connected by a common head(Figure 1).
The immediate neighbors of anode are its nearest siblings to the left andto the right.
The vertical axis correspondsto the head and child nodes.
The immediateneighbors are the head node as well as theleftmost and rightmost child nodes.
There isno connection for nodes not yet part of thegraph.The sentence axis traverses the nodes in the or-der they occur in the original sentence.
Theimmediate neighbors of a node are the previ-ous and next words in the sentence.4 Representing Features and TheirNeighborsWe represented features with a parameter formatpartly inspired by MaltParser (Nivre et al, 2006a).HeadLeft siblingCNRight siblingLeftmost child Rightmost childVertical axisHorizontal axisFigure 1: The vertical and horizontal axes, respec-tively in light and dark gray, relative to CN.Each parameter consists of two parts.
The firstone represents a node in a data structure (STACKor QUEUE) and an attribute:The nodes are identified using a zero-based in-dex.
Thus STACK1 designates the secondnode on the stack.The attribute of a node is one of part of speech(POS), lexical value (LEX), or dependencylabel (DEP), as for instance LEX(QUEUE0)that corresponds to the lexical value of thefirst token in the queue.The second part of the parameter is an optionalnavigation path that allows to find other destina-tion nodes in the graph.
It consists of a sequenceof instructions to move from the start node to thedestination node.
The list of possible instructionsare:?
h: head of the current node;?
lc/rc: leftmost/rightmost child of the node;?
pw/ f w: previous/following word of thenode in the original sentence.An example of a feature obtained using the nav-igation part is POS(STACK1 lc pw), which is in-terpreted as: start from STACK1.
Then, using theinstructions lc and pw, move to the left child of thestart node and to the previous word of this child inthe sentence.
The requested feature is the part ofspeech of the destination node.8265 Initial State and Successor FunctionThe feature discovery is an iterative procedure thatgrows the feature set with one new feature at eachiteration.
We called generation such an iteration,where generation 1 consists of a single node.
Wedenoted FeatSeti = { f1, f2, ..., fi} the feature setobtained at generation i.Although the features of a classifier can beviewed as a set, we also considered them as a tu-ple, where Feati = ?
f1, f2, ..., fi?
is the i-tuple atgeneration i and fk, the individual feature discov-ered at generation k with 1 6 k 6 i.
This enablesus to keep the order in which the individual fea-tures are obtained during the search.5.1 Initial StateWe start the feature search with the empty set, /0,that, by convention, has one neighbor: the firstnode in the queue QUEUE0.
We chose this nodebecause this is the only one which is certain toexist all along the parsing process.
Intuitively,this is also obvious that QUEUE0 plays a signifi-cant role when deciding a parsing action.
We de-fined the successor function of the empty set as:SUCC( /0) = {POS(QUEUE0),LEX(QUEUE0)}.5.2 Successors of a NodeThe successors of a node consist of itself and allits topological neighbors along the three axes withtheir three possible attributes: part of speech, lex-ical value, and dependency label.
For a particularfeature in FeatSet, the generation of its successorsis carried out through the following steps:1.
Interpret the feature with its possible naviga-tion path and identify the destination node n.2.
Find all existing immediate neighboringnodes of n along the three search axes.3.
Assign the set of attributes ?
POS, LEX , andDEP ?
to n and its neighboring nodes.If at any step the requested node does not exist,the feature evaluates to NOTHING.5.3 Rules to Generate NeighborsThe generation of all the neighbors of the featuresin FeatSet may create duplicates as a same nodecan sometimes be reached from multiple paths.For instance, if we move to the leftmost child of anode and then to the head of this child, we returnto the original node.To compute the successor function, we built aset of rules shown in Table 2.
It corresponds toa subset of the rules described in the axis search(Sect.
3.2) so that it omits the neighbors of a nodethat would unavoidably create redundancies.
Thethird column in Table 2 shows the rules to gener-ate the neighbors of POS(QUEUE0).
They corre-spond to the rows:PL.
This stands for the POS and LEX attributesof the node.
We only add LEX(QUEUE0)as we already have POS(QUEUE0).PLD lc and PLD rc.
POS, LEX , and DEP of thenode?s leftmost and rightmost children.PLD pw.
POS, LEX , and DEP of the previousword in the original string.
The followingword is the same as the next node in thequeue, which is added in the next step.
Forthat reason, following word is not added.PL QUEUE1.
POS and LEX of QUEUE1.PLD STACK0.
POS, LEX , and DEP of STACK0.This rule connects the queue to the top nodeof the stack.Table 3 summarizes the results of the rule appli-cation and shows the complete list of successorsof POS(QUEUE0).
In this way, the search for anode?s neighbors along the axes is reduced to onedirection, either left or right, or up or down, thatwill depend on the topological relation that intro-duced the node in the feature set.6 Feature Selection AlgorithmAt each generation, we compute the Cartesianproduct of the current feature tuple Feati and theset defined by its neighbors.
We define the set ofcandidate tuples CandFeati+1 at generation i+ 1as:CandFeati+1 = {Feati}?SUCC(Feati),where we have Card(CandFeati+1) =Card(SUCC(Feati)).The members of CandFeati+1 are ranked ac-cording to their parsing score on the development827Data structures Navigation pathsSTACK0 STACKn,n > 0 QUEUE0 QUEUEn,n > 0 h lc, rc ls rs pw fwPLD PLD PL PL h h hPLD h PLD h lc lc lc lc lcPLD lc PLD lc PLD lc rc rc rc rc rcPLD rc PLD rc PLD rc ls ls ls ls lsPLD ls PLD ls rs rs rs rs rsPLD rs PLD rs pw pw pw pw pwPLD pw PLD pw PLD pw fw fw fw fw fwPLD fw PLD fwPLD STACK1 PLD STACKn+1 PL QUEUE1 PL QUEUEn+1PL QUEUE0 PLD STACK0Table 2: Rules to compute the successors of a node.
For each node category given in row 2, theprocedure adds the features in the column headed by the category.
PLD stands for the POS, LEX ,and DEP attributes.
In the right-hand side of the table, the category corresponds to the last instructionof the navigation path, if it exists, for instance pw in the feature POS(STACK1 lc pw).
We read thesix successors of this node in the fifth column headed by pw: STACK1 lc pw h, STACK1 lc pw lc,STACK1 lc pw rc, STACK1 lc pw ls, STACK1 lc pw rs, and STACK1 lc pw pw.
We then apply all theattributes to these destination nodes to generate the features.Initial feature POS QUEUE 0Successors LEX QUEUE 0PLD QUEUE 0 lcPLD QUEUE 0 rcPLD QUEUE 0 pwPL QUEUE 1PLD STACK 0Table 3: Features generated by the successor func-tion SUCC({POS(QUEUE0)}).
PLD stands forthe three attributes POS, LEX , and DEP of thenode; PL for POS and LEX .set and when applying a greedy best-first search,Feati+1 is assigned with the tuple yielding thehighest score:Feati+1 ?
eval best(CandFeati+1).The procedure is repeated with the immediateneighbors of Feati+1 until the improvement of thescore is below a certain threshold.We extended this greedy version of the discov-ery with a beam search that retains the N-bestsuccessors from the candidate set.
In our exper-iments, we used beam widths of 4 and 8.7 Experimental SetupIn a first experiment, we used the Swedish cor-pus of the CoNLL-X shared task (Buchholz andMarsi, 2006).
In a second experiment, we appliedthe feature discovery procedure to the English cor-pus from CoNLL 2008 (Surdeanu et al, 2008), adependency corpus converted from the Penn Tree-bank and the Brown corpus.
In both experiments,we used the LIBSVM package (Chang and Lin,2001) with a quadratic kernel, ?
= 0.2, C = 0.4,and ?
= 0.1.
These parameters are identical toNivre et al (2006b) to enable a comparison of thescores.We evaluated the feature candidates on a de-velopment set using the labeled and unlabeled at-tachment scores (LAS and UAS) that we com-puted with the eval.pl script from CoNLL-X.As there was no development set for the Swedishcorpus, we created one by picking out every 10thsentence from the training set.
The training wasthen carried out on the remaining part of the set.8 Feature Discovery on a SwedishCorpusIn a first run, the search was optimized for theUAS.
In a second one, we optimized the LAS.
Wealso report the results we obtained subsequentlyon the CoNLL-X test set as an indicator of how828well the training generalized.8.1 The First and Second GenerationsTable 4 shows the feature performance at the firstgeneration sorted by UAS.
The first row shows thetwo initial feature candidates, ?POS(QUEUE0)?and ?LEX(QUEUE0)?.
The third row showsthe score produced by the initial features alone.The next rows show the unlabeled and labeledattachment scores with feature pairs combiningone of the initial features and the one listed inthe row.
The combination of POS(QUEUE0)and POS(STACK0) yielded the best UAS: 74.02.The second feature improves the performance ofPOS(QUEUE0) by more than 30 points from43.49.For each generation, we applied a beamsearch.
We kept the eight best pairs as start-ing states for the second generation and weadded their neighboring nodes.
Table 5 showsthe eight best results out of 38 for the pair?POS(QUEUE0),POS(STACK0)?.Parent state: ?POS(QUEUE0),POS(STACK0)?Dev set Test setUAS LAS UAS LAS Successors79.50 65.34 79.07 65.86 P QUEUE 178.73 66.98 76.04 64.51 L STACK 0 fw77.42 63.08 74.63 61.86 L QUEUE 177.06 64.54 75.28 62.90 L QUEUE 0 pw76.83 66.01 73.61 63.77 L QUEUE 076.63 63.62 74.75 63.17 P STACK 0 fw76.44 64.24 74.09 62.02 L STACK 076.39 63.12 73.99 61.16 L QUEUE 0 lcTable 5: Ranking the successors of?POS(QUEUE0),POS(STACK0)?
on theSwedish corpus.
Out of the 38 successors,we show the eight that yielded the best results.
Pstands for POS, L for LEX , and D for DEP.8.2 Optimizing the Unlabeled AttachementScoreWe iterated the process over a total of 16 gener-ations.
Table 6, left-hand side, shows the list ofthe best scores for each generation.
The scores onthe development set increased steadily until gen-eration 13, then reached a plateau, and declinedaround generation 15.
The test set closely fol-lowed the development set with values about 1%lower.
On this set, we reached a peak performanceat generation 12, after which the results decreased.Table 6, right-hand side, shows the features pro-ducing the final score in their order of inclusionin the feature set.
As we applied a beam search,a feature listed at generation i does not necessarycorrespond to the highest score for this generation,but belongs to the feature tuple producing the bestresult at generation 16.8.3 Optimizing the Labeled AttachementScoreWe also applied the feature discovery with asearch optimized for the labeled attachment score.This time, we reduced the beam width used in thesearch from 8 to 4 as we noticed that the candi-dates between ranks 5 and 8 never contributed tothe best scoring feature set for any generation.We observed a score curve similar to that of theUAS-optimized search.
The train set followed thedevelopment set with increasing values for eachgeneration but 1-2% lower.
The optimal value wasobtained at generation 15 with 84.21% for the testset.
Then, the score for the test set decreased.9 Feature Discovery on a Corpus ofEnglishThe training and development sets of the CoNLL2008 corpus contain text from the Wall StreetJournal exclusively.
The test set contains textfrom the Brown corpus as well as from the WallStreet Journal.
Table 7 shows the results after 16generations.
We used a beam width of 4 and thetests were optimized for the unlabeled attachmentscore.
As for Swedish, we reached the best scoresaround generation 14-15.
The results on the in-domain test set peaked at 90.89 and exceeded theresults on the development set.
As expected, theresults for the out-of-domain corpus were lower,87.50, however the drop was limited to 3.4.10 Discussion and ConclusionThe results we attained with feature set sizes assmall as 15 are competitive or better than figures829Parent state ?POS(QUEUE0)?
?LEX(QUEUE0)?UAS LAS Successors UAS LAS Successors43.49 26.45 None 42.76 23.56 None74.02 59.67 POS STACK 0 65.86 52.18 POS STACK 067.77 54.50 LEX STACK 0 58.59 45.51 LEX STACK 058.37 41.83 POS QUEUE 0 pw 51.98 37.70 POS QUEUE 0 pw55.28 38.49 LEX QUEUE 0 pw 50.44 29.71 POS QUEUE 151.53 30.43 POS QUEUE 1 50.38 35.24 LEX QUEUE 0 pw51.05 32.66 LEX QUEUE 0 lc 49.37 32.27 POS QUEUE 049.71 31.54 POS QUEUE 0 lc 48.91 27.77 LEX QUEUE 149.49 29.18 LEX QUEUE 1 48.66 29.91 LEX QUEUE 0 lc49.37 32.27 LEX QUEUE 0 47.25 28.92 LEX QUEUE 0 rc48.68 29.34 DEP STACK 0 47.09 28.65 POS QUEUE 0 lc48.47 30.84 LEX QUEUE 0 rc 46.68 27.08 DEP QUEUE 0 lc46.77 26.86 DEP QUEUE 0 lc 45.69 27.83 POS QUEUE 0 rc46.40 29.95 POS QUEUE 0 rc 44.77 26.17 DEP STACK 042.27 25.21 DEP QUEUE 0 pw 44.43 26.47 DEP QUEUE 0 rc41.04 26.56 DEP QUEUE 0 rc 41.87 23.04 DEP QUEUE 0 pwTable 4: Results of the beam search on the Swedish corpus at the first generation with the two initialfeature candidates, ?POS(QUEUE0)?
and ?LEX(QUEUE0)?, respectively on the left- and right-handside of the table.
The third row shows the score produced by the initial features alone and the next rows,the figures for the candidate pairs combining the initial feature and the successor listed in the row.
Theeight best combinations shown in bold are selected for the next generation.Generation Dev set Test set FeaturesUAS LAS UAS LAS1 43.49 26.45 45.93 30.19 POS QUEUE 02 74.02 59.67 71.60 58.37 POS STACK 03 79.50 65.34 79.07 65.86 POS QUEUE 14 83.58 71.76 82.75 70.98 LEX STACK 0 fw5 85.96 76.03 84.82 74.75 LEX STACK 06 87.23 77.32 86.34 76.52 LEX QUEUE 0 lc7 88.42 80.00 87.67 78.99 POS STACK 18 89.43 81.56 88.09 80.26 LEX QUEUE 19 89.84 83.20 88.69 82.33 LEX QUEUE 010 90.23 83.89 89.17 83.31 DEP STACK 0 lc11 90.49 84.31 89.58 83.85 POS STACK 0 fw12 90.73 84.47 89.66 83.83 LEX STACK 0 fw ls13 90.81 84.60 89.52 83.75 LEX STACK 0 fw ls lc14 90.81 84.70 89.32 83.73 POS STACK 1 h15 90.85 84.67 89.13 83.21 LEX STACK 1 rs16 90.84 84.68 88.65 82.75 POS STACK 0 fw ls rcTable 6: Best results for each generation on the Swedish corpus, optimized for UAS.
Figures in bolddesignate the best scores.
The right-hand side of the table shows the feature sequence producing thebest result at generation 16.830Generation Dev set Test set WSJ Test set Brown FeaturesUAS LAS UAS LAS UAS LAS1 45.25 33.77 45.82 34.49 52.12 40.70 POS QUEUE 02 64.42 55.64 64.71 56.44 71.29 62.41 LEX STACK 03 78.62 68.77 78.99 70.30 78.67 65.17 POS QUEUE 14 81.83 76.67 82.46 77.82 80.57 72.95 LEX STACK 0 fw5 84.43 79.78 84.89 80.88 84.03 76.99 POS STACK 06 85.95 81.60 86.61 82.93 84.55 77.80 DEP QUEUE 0 lc7 86.95 82.73 87.73 84.09 85.26 78.48 LEX STACK 18 88.03 83.62 88.52 84.74 85.66 78.73 LEX QUEUE 19 88.61 84.97 89.15 86.20 86.29 79.86 LEX QUEUE 010 89.09 85.43 89.47 86.60 86.43 80.02 POS QUEUE 211 89.54 85.87 90.25 87.40 87.00 80.75 POS STACK 0 pw12 89.95 86.21 90.63 87.77 86.87 80.46 POS QUEUE 313 90.26 86.56 90.64 87.80 87.35 80.86 POS STACK 1 pw14 90.54 86.81 90.71 87.88 87.50 81.30 POS QUEUE 0 pw15 90.61 86.94 90.89 88.11 87.47 81.33 LEX STACK 0 lc16 90.65 87.00 90.88 88.09 87.42 81.28 POS STACK 0 pw lsTable 7: Best results for each generation.
English corpus.
Selection optimized for UAS.reported by state-of-the-art transition-based sys-tems.
We reached a UAS of 89.66 on the CoNLL-X Swedish corpus.
On the same corpus, the topscores reported in the shared task were slightlylower: 89.54 and 89.50.
Our best LAS was 84.21,and the two best scores in CoNLL-X were 84.58and 82.55.
Our results for the English corpus fromCoNLL 2008 were optimized for an unlabeled at-tachment score and we obtained 90.89 for the in-domain test set and 87.50 for the out-of-domainone.
Our best LAS were 88.11 and 81.33.
Officialresults in CoNLL 2008 only reported the labeledattachment scores, respectively 90.13 and 82.811.We believe these results remarkable.
We used asingle-parser system as opposed to ensemble sys-tems and the results on the Brown corpus showan excellent resilience and robustness on out-of-domain data.
The automatic discovery producedresults matching or exceeding comparable sys-tems, although no prior knowledge of the lan-guage being analyzed was used and no feature setwas provided to the parser.Although, a systematic search requires no in-tuitive guessing, it still consumes a considerable1Results are not exactly comparable as we used theCoNLL-X evaluation script that gives slightly higher figures.machine time.
Due to the learning algorithm weuse, SVM, training a model takes between 1 and130 hours depending on the size of the corpus.The number of models to train at each generationcorresponds to the number of feature candidatestimes the beam width.
The first generation con-tains about 15 feature candidates per feature setand since features are only added, the number ofcandidates can grow to 100 at generation 10.We believe there is a margin for improvementboth in the parsing scores and in the time neededto determine the feature sets.
Our scores in Swed-ish were obtained with models trained on 90% ofthe training set.
They could probably be slightlyimproved if they had been trained on a com-plete set.
In our experiments, we used three at-tributes: the part of speech, lexical value, and de-pendency label of the node.
These attributes couldbe extended to lemmas and grammatical features.SVMs yield a high performance, but they are slowto train.
Logistic regression with, for instance,the LIBLINEAR package (Fan et al, 2008) wouldcertainly reduce the exploration time.831AcknowledgmentsThe research leading to these results has receivedfunding from the European community?s seventhframework program FP7/2007-2013, challenge 2,cognitive systems, interaction, robotics, undergrant agreement No 230902?ROSETTA.ReferencesAttardi, Giuseppe, Felice Dell?Orletta, Maria Simi,Atanas Chanev, and Massimiliano Ciaramita.
2007.Multilingual dependency parsing and domain adap-tation using DeSR.
In Proceedings of the CoNLLShared Task Session of EMNLP-CoNLL 2007, pages1112?1118, Prague, Czech Republic, June.
Associ-ation for Computational Linguistics.Buchholz, Sabine and Erwin Marsi.
2006.
CoNLL-X shared task on multilingual dependency parsing.In Proceedings of the Tenth Conference on Com-putational Natural Language Learning (CoNLL-X),pages 149?164, New York City, June.
Associationfor Computational Linguistics.Chang, Chih-Chung and Chih-Jen Lin.
2001.
LIB-SVM: a library for support vector machines.Software available at http://www.csie.ntu.edu.tw/?cjlin/libsvm.Covington, Michael A.
2001.
A fundamental algo-rithm for dependency parsing.
In Proceedings of the39th Annual ACM Southeast Conference, Athens,Georgia.Fan, Rong-En, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin.
2008.
LIBLINEAR:A library for large linear classification.
Journal ofMachine Learning Research, 9:1871?1874.Kunze, Ju?rgen.
1967.
Die Behandlung nicht-projektiver Strukturen bei der syntaktischen Anal-yse und Synthese des englischen und des deutschen.In MASPEREVOD-67: Internationales Symposiumder Mitgliedsla?nder des RGW, pages 2?15, Bu-dapest, 10.?13.
Oktober.Nivre, Joakim and Jens Nilsson.
2005.
Pseudo-projective dependency parsing.
In Proceedingsof the 43rd Annual Meeting of the Associationfor Computational Linguistics (ACL?05), pages 99?106, Ann Arbor, June.Nivre, Joakim, Johan Hall, and Jens Nilsson.
2006a.Maltparser: A data-driven parser-generator for de-pendency parsing.
In Proceedings of the fifth in-ternational conference on Language Resources andEvaluation (LREC2006), pages 2216?2219, Genoa,May 24-26.Nivre, Joakim, Johan Hall, Jens Nilsson, Gu?lsenEryigit, and Svetoslav Marinov.
2006b.
Labeledpseudo-projective dependency parsing with supportvector machines.
In Proceedings of the Tenth Con-ference on Computational Natural Language Learn-ing (CoNLL), pages 221?225, New York, June, 8-9.Nivre, Joakim.
2003.
An efficient algorithm forprojective dependency parsing.
In Proceedings ofthe 8th International Workshop on Parsing Tech-nologies (IWPT 03), pages 149?160, Nancy, 23-25April.Surdeanu, Mihai, Richard Johansson, Adam Meyers,Llu?
?s Ma`rquez, and Joakim Nivre.
2008.
TheCoNLL 2008 shared task on joint parsing of syn-tactic and semantic dependencies.
In CoNLL 2008:Proceedings of the 12th Conference on Computa-tional Natural Language Learning, pages 159?177,Manchester, August.Yamada, Hiroyasu and Yuji Matsumoto.
2003.
Sta-tistical dependency analysis with support vectormachines.
In Proceedings of the 8th Interna-tional Workshop on Parsing Technologies (IWPT03), pages 195?206, Nancy, 23-25 April.Zhang, Yue and Stephen Clark.
2009.
Transition-based parsing of the Chinese treebank using a globaldiscriminative model.
In Proceedings of the 11thInternational Conference on Parsing Technologies(IWPT 09), pages 162?171, Paris, October.832
