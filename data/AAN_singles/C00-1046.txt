Automatic Refinement of a POS TaggerUsing a Reliable Parser and Plain Text CorporaHideki Hirakawa, Kenji Ono, Yulniko YoshimuraHuman Interface LaboratoryCorporate Research & Development CenterToshiba CorporationKonmkai-Toshiba-cho 1, Saiwai-ku, Kawasaki, 212-8582, Japan{hideki.hirakawa, kenj i2.ono, yulniko.yoshimura} @toshiba.co.jpAbstractThis paper proposes a new unsupervised learning method for obtaining English part-of-specch(POS) disambiguation rules which would improve thc accuracy of a POS tagger.
Thismethod has been implemented in the experimental system APRAS (Automatic POS RuleAcquisition System), which extracts POS disambiguation rules fl'om plain text corpora byutilizing different ypes of coded linguistic knowledge, i.e., POS tagging rules and syntacticparsing rules, which arc already stored in a fully implemented MT system.In our ext)eriment , he obtained rules were applied to 1.7% of the sentences in a non-trainingcorpus.
For this group of sentences, 78.4% of the changes made in tagging results were animprovement.
We also saw a 15.5 % improvement in tagging and parsing speed and an 8.0 %increase of parsable sentences.1 Int roduct ionMuch research has been donc Oll knowledgeacquisition fiom large-scalc annotated corporaas a rich source of linguistic knowledge.
M~tiorworks done to create English POS taggers(henceforth, "taggers"), for example, include(Church 1988), (Kupicc 1992), (Brill 1992)and(Voutilaincn et al 1992).
The problem with thisframework, however, is that such reliablecorpora are hardly awdlable duc to a hugeamount of the labor-intensive work required.
Incase of the acquisition of non-core knowledge,such as specific, lexically or dolnain dependentknowledge, preparation of annotated corporabecomes more serious problem.One viable approach then is to utilize plain textcorpora instead, as in (Mikheev 1996).
But Themethod proposed by (Mikheev 1996) has itsown weaknesses, in that it is restricted in scope.That is, it aims to acquire rules for unknownwords in corpora fi'om their ending characterswithout looking at the context.
In the meantime,(Brill 1995a) (Brill 1995b) proposed a method toacquire contcxt-dcpendent POS disambiguationrules and created an accurate tagger, even from avery small aunotated text by combiningsupervised and tmsupcrviscd learning.
Thewcakness of his method is that the effect ofunsupervised learning decreases as the trainingcorpus size increases.The problem in using plain text corpora forknowledge acquisition is that we need a humansupervisor who can evaluate and sift theobtained knowledge.
An alternative to thiswould be to use a number of modules of a well-developed NLP system which stores most of thchighly reliable general rules.
Here, one modulefimctions as a supervisor for other modules,since all these modules arc designed to workcooperatively and the knowledgcs tored in eachmodule are correlated.Keeping this idea in mind, we propose a newunsupervised learning method for obtaininglinguistic rules fi'om plain text corpora using theexisting linguistic knowledge.
This method hasbeen implemented in the rule extraction systemAPRAS (Automatic POS Rule Acquisition313System), which automatically acquires rnles forrefining the morphological analyzer (taggcr) inour English-Japanese MT system ASTRANSAC(Hirakawa ct al.
1991) through the interactionbetween the system's tagger and parser on theassumption that they are considerably accurate.This paper is organized as follows: Section 2illustrates the basic idea of our method; Section3 gives the outline of APRAS; Sections 4 and 5describe our experiments.2 Basic IdeaOur MT system has a tagger which can generateranked POS sequences of input sentencesaccording to their plausibility and also a parserwhich judges the parsability of the derived POSsequences one by one until a parsable one isfound ~ .
in our framework, this tagger can beviewed as a POS candidate generator, and theparser as a sifter.Now sentences can be categorized into thefollowing three:(P )  a balanced sentence, whose top rankedsequence, or initial POS sequence, isparsable,(Q) a conflicting sentence, in which the topranked scquencc is unparsable, but there areparsable ones in the rest of the sequences;and(R)  an unparsable sentence, in which all thePOS sequences are unparsable.Before going on to our main discussion, we willbriefly explain the terminology used in thispaper.
Here we call a highest-ranking parsablePOS sequence as the "Most Preferable _PParsablePOS sequence," or simply "MPP POSsequence."
For our purposes, we will make useof balanced sentences and conflicting sentences.We call the POS of a word in the initial POSsequence as its "initially tagged POS" and that inthe MPP POS sequence as its "parsable POS.
"We call the word whose initially tagged POSand parsable POS differ as a "focus word."
Sincethe tagger is accurate, we can expect only a fewPOS differences between the initial and MPPPOS sequences for a sentence.
Finally, let us callHere only top-N POS scquenccs are tried, where Nis a pre-defined constant to limit parsing time.the POS's of the preceding and succeedingwords as the "POS context of the focus word.
"Conflicting sentences, and their initial POSsequences, parsable POS sequences, and focuswords can be automatically cxtracted.
Throughextraction out of a large amount of plain textcorpora combined with statistical filtering, itwould be possible to automatically select theproper POS conditions that could determinePOS's of focus words.
Then, we extract "POSAdjusting rules" or "PA rules" defined as below:PA rule: W(IPOS) ---> W(PPOS): CC: ContextW :WordIPOS: Initially tagged POSPPOS: Parsable POSMeans "Give priority to the parsable POSover the initially tagged POS in a particularcontext shown as 'C'.
"PA rules do not determine POS's of words fromtheir context, but change the judgement made bythe tagger in a particular context.
Extracted PArules arc independent rules to the tagger and theparser used in the extraction.
At the samc time,these rules are optimized for the tagger and theparser, since they are derived only fromconflicting sentences, not from balancedsentences.
Hence, the knowledge already codedin the system will not be extracted.I11 the following section, we give the outline ofAPRAS focusing on its two modules.3 Outline of APRASFig.
1 shows the application of APRAS to anMT system.
APRAS works in two phases, a ruleextraction phase and a rule application phase.Note that the same tagger and the parser of theMT system are used throughout.314I'A rule extraction phase PA rule application phase ---qYaining CoqmsMf Systcm ~- APP, AS\[ GenorationJRule caMidatcgctlcralion JM'I' Systm~ ~\[ Generation \]Figure 1 : Application of APRAS to an MT SystemIn the rule extraction phase, the tagger analyzeseach sentence in a training corpus and producesplausible POS sequences.
The parser then judgesthe parsability of each POS sequence.
Whenevera conflicting sentence appears, the rolegeneration module outputs the candidates of PArules.After all PA rule candidates for this trainingcorpus are generated, the rule filtering modulestatistically weighs the validity of obtained PArule candidates, and filters out unreliable rules.Sentences in the training corpus are notmmslated in this phase.In the rule application phase, both the alreadyinstalled POS rulcs and the acquired PA rulesare used for tagging.
A sentence is parsed andthen translated into target language.
PA rulesbasically act to avoid the taggcr's wastefulgeneration of POS sequences.
This wouldimprove the ranking of POS sequences thetagger outputs and also increase the chances thatthe parser will find a parsable or better POSsequence in the improved ranking.3.1 Rule Generation ModulePA rule candidates are generated fronlconflicting sentences.
Balanced and unparsablesentences generate no PA rule candidate.
Thewords in balanced sentences arc recorded alongwith their POS's and POS contexts to be used inthe rule filtering module.
Whenever the systemenconllters a conflicting sentence in a trainingcorpus, the system compares the initial POSsequence with the MPP POS sequence of thescntcncc and picks up focus words.
Then, forevery focus word, the system generates a PArule candidate which consists of a focus word,its initially tagged POS, parsable POS, and thePOS context, i.e., the preceding POS's and thesucceeding POS's.t:ig.
2 illustrates how a PA rulc candidate isgenerated.
The focus word is 'rank', its initiallytagged POS is "(verb)', its parsable POS is"(noun)', and the POS context is "(verb)-(determiner)-$-'in'-(dcterminer)", where "$'denotes the focus word.
The POS context iscomposed of preceding two POS's andsucceeding two POS's.
ttere surface words canbe used instead of POS, like "in' in the example.The generated PA rule candidate can be read as:If the word 'rank' appears in a POS context"(verb)-(determiner)-$-'in'-(determiner)", thengive priority to "(noun)' over "(verb)'.In this rule generation module, two importantfactors should be taken into account: namely,context size and levels of abstraction.
If weexpand the context of a focus word, the PA ruleshould gain accuracy.
But its frequency in thetraining corpus would drop, thereby making itdifficult to perform statistical filtering.
Toensure statistical reliability, we need a large-315Input sentence1?
?
?
n \ ]ove  II(Focus word),, ,, ,, ,,the ', rank  ', in ', the', .
.
.I I I IInitial POS sequenceo ?
?.
, ?MPP POS sequencePA rule candidate:POS tagger output Parser outputQ O 4Q ?
J6 ?
OD O gV, ?
?Vdeto ?
??
o ,detvti, ?
??
, ,11in det .
.
.?
?
?
?
o ?
* * ??
?
?
.
?
,  * * *in det .
.
.PA rule generationunparsable?
?
?unparsableparsablerank(verb) -+ rank(norm) : (verb)-(determiner)-$-'in'-(determiner)Initially tagged POS Parsable POS POS contextFigure 2: PA Rulesized training corpus.
At present we set thecontext size to be two words.In choosing adequate levels of abstraction orspecification of POS in the context, we groupedtogether those POS tags which influence thechoice of POS of a focus word in a similarlnanner as one super-POS tag, as in (Haruno &Matsumoto 1997).
We also changed some POStags for functional words like prepositions andwords such as "be' and "have' to tags whichdenote their literal forms, because the choice ofPOS of a focus word is highly dependent on theword itsclf.
As a result, we obtained 513 POStags including 16 POS tags for nouns, 17 forverbs, 410 for prepositions and phrasalprepositions, and 70 for adjectives and adverbs.3.2 Rule Filtering ModuleThis section deals with how to statistically filterout inappropriate rules from the generated PArule candidates.
For this purpose, we introducewhat we call "adjustment ratios.
"Table 1 shows the parsing process of a sentencein which word W appears in POS context C: P1-P2-$-P3-P4.
In this context, the word W has twopossible POS's, X and Y.
Case A shows the caseof balanced sentences where the tagger firsttagged W with X and the parser found itparsable.
Case B shows the case of conflictingsentences where the tagger first tagged W withCandidate Generationunparsable X and then with Y which proved tobe parsable 2.Let N,, and Nb be the number of semcnces incases A and B, respectively.
Assume the parseris accurate nough to be able to judge a majorityof sentences with correct POS contexts to beparsable 3, and those with incorrect POSunparsable.Table 1 : Transition of POS of Win Parsing Process for Context CPOSw, cX I APOSI~cX ---> POS,~cY BThen, adjustment ratios can be fornmlated asfollows :2 Here only two possibilities, namely X and Y, arcconsidered.
However it is easy to generalize thetransition process for cases where focus words havemore than two POS candidates.3 The accuracy of POS sequences accepted by ourparser is more than 99% (Yoshimura 1995).4 Financial Times(1992-1994, approx.
210,000documents) in NIST Standard Reference Data TRECDocument Database: Disk4 (Special No.
22),National Institute of Standards and Technology, U.S.Department of Commerce (http://www.nist.gov/srd).316N b adjustment ratio,:.lc (X --> Y ) -N, +N hWhen the value is high, the tagger shouldchangc the POS from X to Y, whereas when thevalue is low, the tagger should not changc thePOS in the given context.
Thus, based on thestatistics of an accurate parscr's judgement,adjustment ratios can be a criterion for thevalidity of PA rules.
The rules whose adjustmentratios are above the threshold are extracted andoutput as PA rules.
The threshold is fixed byexamining PA rule candidates as will belnentioned in the next section.
More importantly,PA rules are considered to be "optimized' to theparser.
First, the selection and application ofinappropriate PA rules do not ilnmcdiatelydeteriorate he parser output, since PA rules onlyserve to eliminate wasteful generation of POSsentences.
Second, the existence of inappropriatePA rulcs eventually shortens the processing timefor those sentences for which the parserproduces an errorneous syntactic structure due toa lack of syntactic knowledge.4 Rule Extraction ExperimentWe applied the method described in Section 3.2to English news articles (6,684,848 sentences,530MB) 4 as a training corpus and obtained300,438 different PA rule candidates.
Sincerules with low ficquencics do not have reliableadjustment ratios, we omitted rules with afrequency below 6 and thus obtained 17,731rules.Table 2: Adjustment Ratios and the Validity of ExtractedRulesAdjustment I Total Valid (%)ratio(%)2O25241615151517161829I 21ol0-910-1920-2930-3940-4950-5960-6970-7980-8990-99100totalInvalid (%)To verify the validity of adjustment ratio-basedrule selection method described ill Section 3.2,we examined some of the obtained PA ruleswhose frequencies are 10, 20, and 30, referringto the original sentences froln which they weregenerated, and classified the rules into thefollowing three categories.
(p )  Valid: applicable to any sentence.
(O)lnvalid: inapplicable to every sentence.This type of rule is derived when anincorrect POS sequence was judged to beparsable, due to a lack of coverage ofparsing rules in the parser.
(R)  Undecidable: The derived rule is neithervalid nor invalid, either because the POScontext or POS specifications areinsufficient to uniquely determine the POSof the focus word, or because both theinitially tagged POS and the parsable POSare inadequate for the POS context.An example of (3) is:trading(preseut particle) ---> trading(noun):(noun)-'oP-$-(dcterminer)-(noun)The word "trading" is a prcscnt pallicle insentences like ".. index features represent a moreconvenient and liquid way of trading all indexbasket han ...," while it is a noun ill selltcnecslike "By the close of trading the deal was quotedat 99.82 bid.
"Table 2 shows the result of the classification.
Asis clear in the table, for adjustmcnt ratios bclow30 %, there arc more invalid rules than validrulcs, and for adjustment ratios above 30 %, theconverse is true.
The percentage ofinvalid rules is small above 60 %.These results prove the validity of ouradjustment ratio-based rule selection1 framework.
By setting the threshold to5 60%, we can extract in an unsupervised10 manner PA rules of which 86% are6 valid and 7% invalid, but the presence4 of such invalid PA rules are unlikely to4 cause a serious deterioration, as0 mentioned previously.
Incidentally,1 rules whose adjustment ratio is below0 30 % could be used as prohibition rules1 to be applied in the given POS contexts.4 These rules are not used in the nextexperiment.Undccid-able0 (0) 19 (95)3 (12) 17 (68)4 (17) 10 (42)8 (50) 2 (13)10 (67) 1 (7)7 (47) 4 (27)15 (1oo) o (o)15 (88) 1 (6)15 (94) 1 (6)14 (78) 3 (17)23 (79) 2 (7)114 60 36317Thus, we eliminated the extracted 17,731 ruleswhose adjustment ratio are below 60% andobtained 4,494 rules such as :group(V) --~ group(N):(ADV)-(N)-$-(NAME)-(CC)report(N) ---> report(V):(ADV)-','-$ -(NAME)-(NAME)related(VP) ---> related(PP) :(NAME)-(CC)-$-(N)-(PNC)open(V) --> open(ADJ) :(N)-','-$-(N)-','further(V) --;, further(ADV) :'to'-(V)-$-(NU)-(DEM)where ADJ=adjective, ADV=adverb,CC=coordinate conjuction, DET=determiner,DEM=demonstrative, NAMEP=place name,N=noun, NAME=proper noun, NT=nounmeaning "time", NU=noun meaning "unit",PP=past particle, PNC=punctuation mark otherthan commas, V=verb (other than past form),VP=verb (past form).5 Rule Application ExperimentBy using PA rules, we can expect hat:( P) the process time would be reduced byobtaining a parsable POS sequence at anearlier stage, and(O) both tagging precision and parsing accuracywould improve.To prove the above statements, we applied the3,921 PA rules 5 extracted in the previousexperiment for tagging entirely different Englishnews articles (146,229 sentences; 2.26MWords ) from the training corpus.
Among them,2,421 sentences (1.7%) or 2,476 words(0.11%) satisfied the conditions of these PArules, which were then tagged and parsed withand without the PA rules.
We measured thedifference in the elapsed time 6 and the number5 Out of 4,494, 573 rules have been eliminated in thisexperiment.
These cases involved distinction betweencompound words (cx.
"that is'(adverb)) and non-compound words (ex.
"that(pronoun)+is(vex'b)').
Thisaccompanies changes in the window of context,which requires further esearch.6 The elapsed time is measured on WorkStation SUNcounted of successfully parsed sentences.
Theresult is shown in Table 3.
The tagging time wasextended by 11.5%, but the parsing time and thetotal processing time were reduced by 24% and15.5%, respectively, while the ratio ofsuccessfully parsed sentences improved by8.0%.We also examined 524 POS differences out ofall the resulting differences in the tagger'soutputs made by the PA rules, and obtained thefollowing figures.- Improved: 411 (78.4%)- Worse: 84 (16.0%)- Neither improved nor worse 29 (5.5%)Out of the 84 worsened cases, 43 were due toinvalid rules acquired through wrong parsingbecause of a lack of sufficient parsing rules.There are highly fiequent expressionscharacteristic of financial reports which ourparser cannot parse.
However, again, this kind ofinvalid rules would not make a significantdifference in the final output of the parser.
Theremaining 32 cases were due to learning fi'omwrongly segmented sets of words and also fiomdistinct header expressions like "FT 14 MAY 91/ World News in Brief".
These errors can beeasily eliminated by not learning from these data.Adopting the rule accuracy obtained fiom theabove examination, we can expect 62.4%(78.4% - 16.0%) improvement for words withPA-rule applied.
Since PA-mles are applied to0.11% of the words in corpus, 0.07%improvement of POS tagging is expected.
Wcmeasured the tagging precision with and withoutthe acquired PA rules for a test corpuscontainging 5,630 words, and observed that theprecision rose to 98.65% fi'om the initial 98.60%,i.e.
0.05% improvement.
Since PA rules arelexically based rules, the ratio of sentenceswhich satisfied the rule conditions is rather low,but the number of those sentences wouldincrease in proportion to the number of PA rulesacquired.If we expand the size of a training corpus, wecould obtain much more PA rules.
In fact, weobserved many valid rules in the eliminated PArule candidates whose frequency is immediatelyUltra U 1E/200.318Table 3 : Processing Time and Parsable Sentence RatioTagging time(sec.
)Parsing time(sec.
)Total processing time(sec.
)Parsable sentence ratioWithout PA rules79.40252.17331.5764.0%With PA rules88.49(+9.09, + 11.5%)191.73(-60.44, -24.0%)280.22(-51.35, - 15.5%)72.0%below the threshold.
Since the observedfrequency distribution of PA rules wasexponential, we can expect PA rules wouldincrease xponentially by expanding the size ofa training corpus.This expansion also enables us to specify POScontext in detail, like widening the contextwindow, subcategorizing POS tags employed incontext, assigning onc surface fimctional wordto a lexical tag, etc.
To make detailedclassification fully effective, we will need togeneralize specific rules to the level that reflectsthe maximum distinction of individualexamples.6 ConclusionIn this paper we presented a new approach toacquiring linguistic knowledge automaticallyfrom plain text corpora, and proved itsfeasibility by the experiment.
Our methodutilizes well-developed modules in a NLPsystem, including a tagger and a parser, andenables us to extract wflid rules with highaccuracy.
It is robust in that the application ofthe extracted incorrect knowledge does notcause a serious performance deterioration.As a first step to obtaining lexically dependentknowledge, we examined the validity ofobtained POS rules to measure the viability ofour unsupervised learning method fi'om plaintext corpora.
In the future we will expand thesize of training corpora and make use of invalidPA rules with a low adjustment ratio.ReferencesBrill, Eric.
1992: A Shlq)le Rule-Based Part ofSpeech Tagger, in Proceedings of the ThirdConference on Applied Natural LanguageProcessing, pp.
152-155.Brill, Eric.
1995a: 7)'an.y/brmation-Based Error-Driven Learning and Natural LanguagePJvcexsing: A Case Study in Part-oJ'-SpeechTagging, in Computational Linguistics, Volume 21,Number 4.Brill, Eric.
1995b: Unmq~ervised Learning ofDLs'ambiguation Rules Jbr Part of Speech Tagging,Workshop on Very Large Corpora.Church, Kenneth.
1988: A Stochastic Parts Programand Noun Phrase Parser Jbr Um'estricted Text, inProceedings of the Second Conference on AppliedNatural Language Processing, Austin, Texas,pp.126-143.Haruno, Masahiko and Yuji Matsumoto.
1997:Mistalce-Driven Mixtm'e of HielzHvhical TagContext Trees, in Proceedings of the 35th AnnualMeeting of the Association of CompntationalLinguistics, Madrid, Spain.llirakawa, tlideki, Hiroyasu Nogami and Shin'yaAmano.
1991 : E.I/.IE Machine TranslatioJl SystemASTRANSAC-Extensions toward l'crsonalization,in Proceedings of MT SUMMIT-Ill, Washington,D.C., 1991, pp.73-80.Kupicc, Julian.
1992: Robust Part-of Speech TaggingUsing a llidden Markov Model, Computer Speech& Language, 6(3), pp.225-242.Mikhecv, Andrei.
1996: Unsupervived Lcarnit~g qfWord-Categow Guessit N Rules, in Proceedings ofthe 34th Annual Meeting of the Association ofComputational Linguistics, Santa Cruz, California.Voutilainen, Atro, Juha tteikkilfi and Arto Anttila.1992: CONSTRAINT GRAMMAR OF ENGLISII -A PelJbrmance-Oriented Intlwduction, Publicationsof the Department of General Linguistics,University of Helsinki, No.21.Yoshimura, Yumiko.
1995: Selection of Englis'hPart-of Speech Strings Uxing Syntactic AnalysishTJbrmation, in Proceedings of the 50th AnnualConvention of IPS Japan, 3-65, March (inJapanese).319
