Combining Prediction by Partial Matching and Logistic Regressionfor Thai Word SegmentationOhm SornilDepartment of Computer ScienceNational Institute of DevelopmentAdministration, Bangkok, Thailandosornil@as.nida.ac.thPaweena ChaiwanaromNational Statistical OfficeBangkok, Thailandpaweena@nso.go.thAbstractWord segmentation is an important part ofmany applications, including informationretrieval, information filtering, documentanalysis, and text summarization.
In Thailanguage, the process is complicated sincewords are written continuously, and theirstructures are not well-defined.
A recognizedeffective approach to word segmentation isLongest Matching, a method based ondictionary.
Nevertheless, this method suffersfrom character-level and syllable-levelambiguities in determining word boundaries.This paper proposes a technique to Thai wordsegmentation using a two-step approach.
First,text is segmented, using an application ofPrediction by Partial Matching, into syllableswhose structures are more well-defined.
Thisreduces the earlier type of ambiguity.
Then,the syllables are combined into words by anapplication of a syllable-level longestmatching method together with a logisticregression model which takes into accountcontextual information.
The experimentalresults show the syllable segmentationaccuracy of more than 96.65% and the overallword segmentation accuracy of 97%.1 IntroductionIn Thai language, characters are written withoutexplicit word boundaries.
Depending on thecontexts, there can be many ways to break a stringinto words, for instance, "?????"
can be segmentedas "??*???"
or "???*??
", and "?????????"
can besegmented as "????*??*???"
or "????*???*??".
Thiscomplicates the task of identifying wordboundaries.Longest matching is the most popular approachto Thai word segmentation (Pooworawan, 1986).The algorithm scans text from left to right andselects the longest match with a dictionary entry ateach point, in a greedy fashion.
However, longestpossible words may not comply with the actualmeanings.
For example, "????????????????"
issegmented by the longest matching as "???????-???-???-???"
instead of the correct segmentation "???????-??-????-???".
This type of ambiguity is referred to ascharacter-level ambiguity.
In addition, "??????????????????????"
is segmented as "???-??????-????-???-??????"
insteadof the correct segmentation "???-???-???????-???-??????
".This is referred to as syllable-level ambiguity.The technique we propose is a two-step processto word segmentation.
In the first step, text issegmented into a sequence of syllables, whosestructures are more well-defined.
This reduces thecharacter-level ambiguity.
The remaining syllable-level ambiguity is the task of combining thosesyllables into words.2 Related WorkIn addition to the longest matching algorithm,discussed earlier, the maximum matchingalgorithm (Sornlertlamvanich, 1993) was proposedto get around the greedy characteristic of thelongest matching algorithm by generating allpossible segmentations for a sentence and thenselecting the one which contains the fewestnumber of entries in the dictionary.An application of statistical techniques wasproposed by (Pornprasertkul, 1994), using aViterbi-based approach to exploit statisticalinformation derived from grammatical tags.
Later,(Kawtrakul and Chalathip, 1995) and (Meknawinet al, 1997) used variants of the trigram model tocompute the most likely segmentation.
(Theeramunkong and Sornlertlamvanich, 2000)observed that, in Thai language, some contiguouscharacters tend to be inseparable units, called Thaicharacter cluster (TCC), and proposed a set ofrules to group characters into TCCs for the purposeof text retrieval.3 Syllable SegmentationPrediction by Partial Matching (PPM) (Bell etal., 1990; Cleary and Witten, 1984), a symbolwisecompression scheme, is used to build the model forThai text.
PPM generates a prediction for eachinput symbol based on its previous context (i.e., afew, say k, forecoming symbols in the text).
Theprediction is encoded in form of conditionalprobability, conditioned on the preceding context.PPM maintains predictions, computed from thetraining data, for the largest context (k) as well asall shorter contexts in tables, as shown in Table 2.Syllable segmentation can be viewed as theproblem of inserting spaces between pairs ofcharacters in the text.
Thai language consists of 66distinct characters.
Treating each characterindividually as in (Teahan et al, 2000) requires alarge amount of training data in order to calculateall the probabilities in the tables, as well as a largeamount of table space and time to lookup datafrom the tables.
We reduce the amount of trainingdata required by partitioning the characters into 16types, as shown in Table 1.
As a side effect of thecharacter classification, the algorithm can handlesyllables not present in the training data.
Eachcharacter is represented by its respective typesymbol.
For instance "???*????*??*???*?????*???????*???*???"
isrepresented as: "de*zdps*mu*hlt*asthg*ahsutss*aor*fst".
We then compute the predictions for eachsymbol as described in the previous section, andthe results are shown in Table 2.Table 1: Types of Thai CharactersWe illustrate the insertion of spaces betweencharacters using text "???????????".
In Thai, tonals arenot useful for the segmentation purpose, thus arefirst filtered out, and the text is converted to"de*fs*mu*hl".Given an order of k, the algorithm computes thelikelihood of each possible next symbol (i.e., thenext character in the text or a space) byconsidering a context of size k at a time and thenproceed to the next symbol in the text.
The processis repeated until the text is exhausted.
From thetext "de*fs*mu*hl", the model for space insertionbecomes a tree-like structure, as shown in Figure 1.In order to predict the next symbol, thealgorithm follows the concept of PPM byattempting to find first the context of length k (k =2 in this example) for this symbol in the contexttable (i.e., e*->f).
If the context is not found, itpasses the probability of the escape character atthis level and goes down one level to the (k-1)context table to find the current context of lengthk-1 (i.e., *->f).
The process is repeated until acontext is found.
If it continues to fail to find acontext, it may go down ultimately to order (-1)corresponding to equiprobable level for which theprobability of any next character is 1/|A|, where Ais the number of distinct characters.If, on the other hand, a context of length q, 0<=q<=k, is found, then the probability of this nextcharacter is estimated to be the product ofprobabilities of escape characters at levels k, k-1,..., q+1 multiplied by the probability for thecontext found at the q-th level.To handle zero frequency, we use method D(PPMD) (Witten and Bell, 1991) where the escapecharacter gets a probability of (d/2n), and thesymbol gets a probability of (2c-1)/2n where n isthe total number of symbols seen previously, d isthe total number of distinct contexts, and c is thetotal number of contexts that appear in the string.After the tree-like structure is created, thealgorithm selects as the final result the path withthe highest probability at the lowest node.
Thiscorresponds to the path that gives the bestcompression according to the PPM textcompression method.Table 2: PPM Tables (Order 2) AfterProcessing the StringFigure 1: Space Insertion ModelTo improve the efficiency of the algorithm, thestructure can be pruned by the following set ofrules, generated from the language analysis:The nodes surrounded by a rectangle in Figure 1are pruned according to the rules above.
Thus, theydo not generate further subtrees.4 Combining Syllables into WordsIn this section, we propose a technique to formwords by combining syllables together.
In order tocombine syllables into words, for each sentence wefirst locate ambiguous sequences of syllables, i.e.,syllable sequences that can be combined in manyways.
The forward and backward syllable-levellongest matching are performed.
These algorithmsare modified from the original longest matching,described in Section 1, by considering syllable as aunit, instead of character.
For instance, a syllablesequence "???*???*????*???*????"
is processedaccording to the forward longest matching as "??????*???????*????
", while as "??????*????*???????"
accordingto the backward longest matching.
Theinconsistencies between the two algorithmssuggest ambiguous sequences of syllables in thesentence.
In this example, an ambiguous sequenceof syllables is "????*???*????
".After identifying ambiguous syllable sequences,we perform the following steps:Step 1: Between the results of the forward andbackward longest matching, the one with all wordsappearing in the dictionary is selected as the resultof the ambiguous sequence.
If both results satisfythis condition, go to Step 2.Step 2: The result with the least number ofwords is taken as the answer.
If the number ofwords are equal, go to Step 3.Step 3: A logistic regression model forcombining syllables is consulted.
This step will bediscussed in details below.Sylla-ble 1Sylla-ble 2Sylla-ble 3Sylla-ble 4Merge(Y/N)1 ???
???
???
????
N2 ???
???
????
???
Y3 ???
????
???
??????
NTable 3: Syllable Organization for theLogistic Regression Model4.1 Logistic Regression Model for CombiningSyllablesThe model to combine syllables is built uponBinary Logistic Regression whose answers areeither combine or not combine.
The modelconsiders four consecutive syllables at a time whenmodeling the decision of whether to combine themiddle two syllables together.
The first and thefourth syllables are considered the context of thetwo middle ones.
Table 3 shows the organizationof data for the model.
In the first row, the trainingdata specifies that syllables "???"
and "???"
(with thepreceding contextual syllable "???"
and thefollowing contextual syllable "????")
should not becombined.
The model is trained by every row ofthe training data.
The result is a trained logisticregression model that can be used for guidingwhether the middle two syllables should becombined in the context of the surroundingsyllables (the first and the fourth syllables).In the model, each syllable (in Table 3) isrepresented by a set of features.
The syllablesunder consideration (the second and the thirdsyllables) are represented by 65 features, listed inTable 4.The contextual syllables (the first and the fourth)are represented by a fewer number of features tomake it less specific to the training contexts.
Thevariables for contextual syllables are thosestatistically significant to the prediction, returnedwith the regression.
The final set consists of 35variables, as shown in Table 5.
The value of eachvariable is either 1 or -1 which means either thesyllable contains or does not contain that particularcharacter, respectively.Var# Char Var# Char Var# Char1 ?
23 ?
452 ?
24 ?
463 ?
25 ?
474 ?
26 ?
485 ?
27 ?
496 ?
28 ?
507 ?
29 ?
518 ?
30 ?
529 ?
31 ?
5310 ?
32 ?
5411 ?
33 ?
5512 ?
34 ?
5613 ?
35 ?
5714 ?
36 ?
5815 ?
37 ?
5916 ?
38 ?
6017 ?
39 ?
6118 ?
40 ?
6219 ?
41 ?
6320 ?
42 ?
6421 ?
43 ?
6522 ?
44 ?Table 4: Syllable Representation for the Secondand Third Syllables5 Experimental EvaluationIn the first experiment, we evaluate the proposedsyllable segmentation method.
The algorithm istrained with 2,200 syllables, manually segmentedfrom a dictionary.
The test data used is a textexcerpt from a thesis written in Thai.
The results inTable 6 show that the algorithm at order 4 yieldsthe best result which is, from the 1,714 manuallysegmented syllables, the algorithm correctlyidentifies 1,694 (or 98.83%) of them correctly.Figure 2 shows an example of segmentationresults.Var# Char Var# Char Var# Char1 ?
13 ?
252 ?
14 ?
263 ?
15 274 ?
16 285 ?
17 296 ?
18 307 ?
19 318 ?
20 329 ?
21 3310 ?
22 3411 ?
23 3512 ?
24Table 5: Syllable Representation for theFirst and Fourth SyllablesOrder Accuracy1 77.36%2 96.38%3 98.54%4 98.83%5 98.19%Table 6: Results of the PPM Modelat Different OrdersNext, we evaluate the proposed algorithm atorder 4 against five 1,000-syllable test texts whichare not part of the text used in the training.
Theresults in Table 7 show 96.65 to 98.26%segmentation accuracy.Order Accuracy1 77.36%2 96.38%3 98.54%4 98.83%5 98.19%Table 7: Results of Five 1,000-Syllable TextsTo evaluate the syllable combination technique,we create 50 ambiguous test cases.
The resultsshow that 47 cases (94%) are segmented correctlyusing the technique proposed, in which 13 casesare correctly segmented in Step 1; 11 cases arecorrectly segmented in Step 2, and 23 cases arecorrectly segmented in Step 3.An evaluation of the entire process of wordsegmentation (i.e., from syllable segmentation tosyllable combination) shows an accuracy of97.17% by which 76.92% of those incorrectsegmentation roots from incorrect syllablesegmentation.Example Text Syllable SegmentationResult??????????????????????????????????????????????
????????????
?????????????????????
??????
?????????????
?????????????????????
??????????????????????????????????????
??????????
??
????
???
????
???
?
?????????????????
????????????
??????????????????????????????????????????????????????????????????
???????????????????????????????????????
???????????????????????????????????????????????????????????????????????????
??????????????????????????????????????????????*??*???*???
*???*????*??*???*???*????*???*???*??*???*????*?*???*???*??????*????*???*????*???*????*???*???*???*???*???*???*????*????*??*???*??*???*??*??*???*???*???*???*???*???*??*????*???*???*???*??*???*???*?????*???*??*???*???*????*????*???*??*???*??*??*???*??*???*???*???*????*??*??????*??*????*??*???*????*????*???*????*???*???*???*???*??*???*???*???*????*??*??*???*???*???*???*???*?????*??*??*???*???*???*??*???*????*???*????*??*???*???*???*???*??*???*???*???*??*??*???*???*???*???*???*????*????*???*???*????*???*???*??????*???*???*???*???*??*????*???*?????*???*???*???*?
?Figure 2: An Example of Syllable SegmentationLastly, we use the same test data however withcorrectly identified syllables, the performanceshows 99.35% accuracy.
This emphasizes theimportance of pre-segmenting syllables and at thesame time indicates that the proposed syllablecombining method is effective.6 ConclusionThis paper proposes a two-step approach to Thaiword segmentation.
Studying the characteristics ofThai language, we find that word segmentationpossesses ambiguities at both character andsyllable levels.
The proposed technique consists oftwo steps.
The first step is designed to reduce thecharacter-level ambiguity by focusing onextracting syllables whose structures are morewell-defined.
Then the second step combinessyllables into words by using binary logisticregression model.
Experimental evaluationsemphasize the importance of pre-identifyingsyllables correctly, show the accuracy of applyingPPM to syllable segmentation of 98%, and indicatethe effectiveness of the proposed approach tocombine syllables into words.
The overall accuracyof Thai word segmentation is 97.17%.ReferencesW.
Aroonmanakun 2002.
Collocation and ThaiWord Segmentation.
Proceedings of SNLP-Oriental COCOSDA.T.
C. Bell, J. G. Cleary, and I. H. Witten 1990.Text Compression.
Prentice Hall, NJ.J.
G. Cleary and I. H. Witten 1984.
DataCompression Using Adaptive Coding and PartialString Matching.
IEEE Transactions onCommunications, 32(4):396-402.A.
Kawtrakul and T. Chalathip 1995.
A StatisticalAp-proach to Thai Morphological Analyzer.Natural Lan-guage Processing and IntelligentInformation System Technology ResearchLaboratory.S.
Meknavin, P. Charenpornsawat, and B.Kijsirikul 1997.
Feature-based Thai WordsSegmentation.
NLPRS, Incorporating SNLP-97.Y.
Poowarawan 1986.
Dictionary-based ThaiSyllable Separation.
Proceedings of the NinthElectronics Engineering Conference.A.
Pornprasertkul 1994.
Thai Syntactic Analysis.Ph.D.
thesis, Asian Institute of Technoloty.V.
Sornlertlamvanich 1993.
Word Segmentationfor Thai in a Machine Translation System.Journal of NECTEC.W.
J. Teahan, Yingying Wen, R. McNab, and I. H.Witten 2000.
A Compression-Based Algorithmfor Chinese Word Segmentation.
ComputationalLinguistics, 26(3), 375-393.I.
H. Witten and T. C. Bell 1991.
The Zero-Frequency Problem: Estimating the Probabilitiesof Novel Events in Adaptive Text Compression.IEEE Transactions on Information Theory, 37(4):1085-1094.T.
Theeramunkong and V. Sornlertlamvanich2000.
Character Cluster Based Thai InformationRetrieval.
Proceedings of the 5th InternationalWorkshop in Information Retrieval with AsianLanguages.
