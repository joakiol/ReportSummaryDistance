Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 233?240Manchester, August 2008Retrieving Bilingual Verb?noun Collocations by IntegratingCross-Language Category HierarchiesFumiyo Fukumoto Yoshimi Suzuki Kazuyuki Yamashita?Interdisciplinary Graduate School ofMedicine and EngineeringUniv.
of Yamanashi{fukumoto, ysuzuki}@yamanashi.ac.jp?The Center for Educational ResearchFaculty of Education and Human SciencesUniv.
of Yamanashikazuyuki@yamanashi.ac.jpAbstractThis paper presents a method of retriev-ing bilingual collocations of a verb andits objective noun from cross-lingual docu-ments with similar contents.
Relevant doc-uments are obtained by integrating cross-language hierarchies.
The results showed a15.1% improvement over the baseline non-hierarchy model, and a 6.0% improvementover use of relevant documents retrievedfrom a single hierarchy.
Moreover, wefound that some of the retrieved colloca-tions were domain-specific.1 IntroductionA bilingual lexicon is important for cross-lingualNLP applications, such as CLIR, and multilingualtopic tracking.
Much of the previous work on find-ing bilingual lexicons has made use of comparablecorpora, which exhibit various degrees of paral-lelism.
Fung et al (2004) described corpora rang-ing from noisy parallel, to comparable, and finallyto very non-parallel.
Obviously, the latter are easyto collect because very non-parallel corpora con-sist of sets of documents in two different languagesfrom the same period of dates.
However, a goodsolution is required to produce a higher quality oflexicon retrieval.In this paper, we focus on English and Japanesebilingual verb?objective noun collocations whichwe call verb?noun collocations and retrieve themusing very non-parallel corpora.
The method firstfinds cross-lingual relevant document pairs withsimilar contents from non-parallel corpora, andc?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.then we estimate bilingual verb?noun collocationswithin these relevant documents.
Relevant doc-uments are defined here as pairs of English andJapanese documents that report identical or closelyrelated contents, e.g., a pair of documents describ-ing an aircraft crash and the ensuing investigationto compensate the victims?
families or any safetymeasures proposed as a result of the crash.
Inthe task of retrieving cross-lingual relevant docu-ments, it is crucial to identify an event as some-thing occurs at some specific place and time asso-ciated with some specific action.
One solution is touse a topic, i.e., category in the hierarchical struc-ture, such as Internet directories.
Although a topicis not an event, it can be a broader class of event.Therefore, it is helpful for retrieving relevant docu-ments, and thus bilingual verb?noun collocations.Consider the Reuters?96 and Mainichi newspaperdocuments shown in Figure 1.
The documents re-port on the same event, ?Russian space station col-lides with cargo craft,?
were published within twodays of each other, and have overlapping content.Moreover, as indicated by the double-headed ar-rows in the figure, there are a number of bilingualcollocations.
However, as shown in Figure 1, theReuters document is classified into ?Science andTechnology,?
while the Mainichi document is clas-sified into ?Space Navigation?.
This is natural be-cause categories in the hierarchical structures aredefined by different human experts.
Therefore, ahierarchy tends to have some bias in both defininghierarchical structure and classifying documents,and as a result some hierarchies written in one lan-guage are coarse-grained, while others written inother languages are fine-grained.
Our attempt us-ing the results of integrating different hierarchiesfor retrieving relevant documents was postulatedto be able to solve this defect of the differences in233Figure 1: Relevant document pairshierarchies, and to improve the efficiency and effi-cacy of retrieving collocations.2 System DescriptionThe method consists of three steps: integrating cat-egory hierarchies, retrieving cross-lingual relevantdocuments, and retrieving collocations from rele-vant documents.2.1 Integrating HierarchiesThe method for integrating different category hier-archies does not simply merge two different hier-archies into a large hierarchy, but instead retrievespairs of categories, where each category is relevantto each other.1 The procedure consists of two sub-steps: Cross-language text classification (CLTC)and estimating category correspondences.2.1.1 Cross-language text classificationThe corpora we used are the Reuters?96 and theRWCP of the Mainichi Japanese newspapers.
Inthe CLTC task, we used English and Japanese datato train the Reuters?96 categorical hierarchy andthe Mainichi UDC code hierarchy (Mainichi hier-archy), respectively.
In the Reuters?96 hierarchy,the system was trained using labeled English doc-uments, and classified translated labeled Japanese1The reason for retrieving pairs of categories is that eachcategorical hierarchy is defined by individual human experts,and different linguists often identify different numbers of cat-egories for the same concepts.
Therefore, it is impossible tohandle full integration of hierarchies.Figure 2: Cross-language text classificationdocuments.
Similarly, for Mainichi hierarchy,the system was trained using labeled Japanesedocuments, and classified translated labeled En-glish documents.
We used Japanese-English andEnglish-Japanese MT software.We used a learning model, Support Vector Ma-chines (SVMs) (Vapnik, 1995), to classify docu-ments, as SVMs have been shown to be effectivefor text classification.
We used the ?One-against-the-Rest?
version of the SVMs at each level of a hi-erarchy.
We classify test documents using a hierar-chy by learning separate classifiers at each internalnode of the hierarchy.
We used a Boolean func-tion b(L1)&&?
?
?&&b(Lm), where b(Li) is a deci-sion threshold value of the i-th hierarchical level.The process is repeated by greedily selecting sub-branches until a leaf is reached.We classified translated Mainichi documentswith Mainichi category m into Reuters categoriesusing SVMs classifiers.
Similarly, each translatedReuters document with category r was classifiedinto Mainichi categories.
Figure 2 illustrates theclassification of Reuters and Mainichi documents.A document with Mainichi category ?m1?
is clas-sified into Reuters category ?r12?, and a docu-ment with Reuters category ?r1?
is classified intoMainichi category ?m21?.
As a result, we ob-tained category pairs, e.g., (r12, m1), and (m21,r1), from the documents assigned to the categoriesin each hierarchy.2.1.2 Estimating category correspondencesThe assumption of category correspondences isthat semantically similar categories, such as ?Eq-uity markets?
and ?Bond markets?
exhibit simi-lar statistical properties than dissimilar categories,such as ?Equity markets?
and ?Sports?.
We ap-plied ?2 statistics to the results of CLTC.
Let ustake a look at the Reuters?96 hierarchy.
Sup-234pose that the translated Mainichi document withMainichi category m ?
M (where M is a set ofMainichi categories) is assigned to Reuters cate-gory r ?
R (R is a set of Reuters?96 categories).We can retrieve Reuters and Mainichi categorypairs, and estimate category correspondences ac-cording to the ?2 statistics shown in Eq.
(1).
?2(r, m) =f(r, m)?
E(r,m)E(r,m)(1)where E(r, m) = Sr?SmSR,Sr=?k?Mf(r, k), SR=?r?RSr.Here, the co-occurrence frequency of r and m,f(r,m) is equal to the number of category m doc-uments assigned to r. Similar to the Reuters hier-archy, we can estimate category correspondencesfrom Mainichi hierarchy, and extract a pair (r, m)according to the ?2 value.
We note that the sim-ilarity obtained by each hierarchy does not havea fixed range.
Thus, we apply the normalizationstrategy shown in Eq.
(2) to the results obtainedby each hierarchy to bring the similarity value intothe range [0,1].
?2new(r, m) =?2old(r,m)?
?2min(r,m)?2max(r,m)?
?2min(r,m).
(2)Let SPrand SPmare a set of pairs obtained byReuters hierarchy and Mainichi hierarchy, respec-tively.
We construct the set of r and m categorypairs, SP(r,m)= {(r,m) | (r,m) ?
SPr?
SPm},where each pair is sorted in descending order of ?2value.
For each pair of SP(r,m), if the value of ?2is higher than a lower bound L?2, two categories,r and m, are regarded as similar.22.2 Retrieval of Relevant DocumentsWe used the results of category correspondencesfrom the Reuters and Mainichi hierarchies to re-trieve relevant documents.
Recall that we usedEnglish and Japanese documents with quite dif-ferent hierarchical structures.
The task thus con-sists of two criteria: retrieving relevant documentsbased on English (we call this Int hi & Eng) andin Japanese (Int hi & Jap).
Let dri(1 ?
i ?
s) be aReuters document that is classified into the Reuterscategory r. Let dmj(1 ?
j ?
t) be a Mainichi2We set ?2 value of each element of SP(r,m)to a highervalue of either (r,m) ?
SPror (r,m) ?
SPm.Figure 3: Retrieving relevant documentsdocument that belongs to the Mainichi category m.Here, s and t are the number of documents classi-fied into r and m, respectively.
Each Reuters doc-ument driis translated into a Japanese documentdr mtiby an MT system.
Each Mainichi documentdmjis translated into an English document dm mtj.Retrieving relevant documents itself is quitesimple.
As illustrated in Figure 3, in ?Int hi& Eng?
with a set of similar categories consist-ing of r and m, for each Reuters and translatedMainichi document, we calculate BM25 similari-ties between them.BM25(dri, dm mtj) =?w?dm mtjw(1)(k1+ 1)tfK + tf(k3+ 1)qtfk3+ qtf, (3)where w is a word within dm mtj, and w(1) is theweight of w, w(1) = log (N?n+0.5)(n+0.5).
N is the num-ber of Reuters documents within the same categoryr, and n is the number of documents which con-tains w. K refers to k1((1 ?
b) + bdlavdl).
k1, b,and k3are parameters and set to 1, 1, and 1,000,respectively.
dl is the document length of driandavdl is the average document length in words.
tfand qtf are the frequency of occurrence of w in dri,and dm mtj, respectively.
If the similarity value be-tween them is higher than a lower bound L?, weregarded these as relevant documents.
The pro-cedure is applied to all documents belonging tothe sets of similar categories.
?Int hi & Jap?
isthe same as ?Int hi & Eng?
except for the use ofdr mtiand dmjfor comparison.
We compared theperformance of these tasks, and found that ?Int hi& Eng?
was better than ?Int hi & Jap?.
In section3, we show results with ?Int hi & Eng?
due to lackof space.2352.3 Acquisition of Bilingual CollocationsThe final step is to estimate bilingual correspon-dences from relevant documents.
All Japanesedocuments were parsed using the syntactic ana-lyzer CaboCha (Kudo and Matsumoto, 2003).
En-glish documents were parsed with the syntactic an-alyzer (Lin, 1993).
In both English and Japanese,we extracted all the dependency triplets(obj, n, v).Here, n refers to a noun which is an object(obj)of a verb v in a sentence.3 Hereafter, we de-scribe the Reuters English dependency triplet asvnr, and that of Mainichi as vnm.
The method toretrieve bilingual correspondences consists of twosub-steps: document-based retrieval and sentence-based retrieval.2.3.1 Document-based retrievalWe extract vnrand vnmpairs from the resultsof relevant documents:{vnr, vnm} s.t.
?dri vnr,?dmj vnmBM25(dri, dm mtj) ?
L?.
(4)Next, we estimate the bilingual correspondencesaccording to the ?2(vnr, vnm) statistics shown inEq.
(1).
In Eq.
(1), we replace r by vnrand m byvnm.
f(r,m) is replaced by f(vnr, vnm), i.e., theco-occurrence frequency of vnrand vnm.2.3.2 Sentence-based retrievalWe note that bilingual correspondences ob-tained by document-based retrieval are not reli-able.
This is because many verb?noun colloca-tions appear in a pair of relevant documents, ascan be seen from Figure 1.
Therefore, we appliedsentence-based retrieval to the results obtained bydocument-based retrieval.
First, we extract vnrand vnmpairs the ?2 values of which are higherthan 0.
Next, for each vnrand vnmpair, we as-sign sentence-based similarity:S sim(vnr, vnm) =maxS vnr?Setr,S vnm?Setmsim(S vnr, S vnm) .
(5)Here, Setrand Setmare a set of sentences thatinclude vnrand vnm, respectively.
The similaritybetween S vnrand S vnmis shown in Eq.
(6).3We used the particle ?wo?
as an object relationship inJapanese.sim(S vnr, S vnm) =co(S vnr?
Smtvnm)| S vnr| + | Smtvnm| ?2co(S vnr?
Smtvnm) + 2, (6)where |X| is the number of content words in a sen-tence X, and co(S vnr?
Smtvnm) refers to thenumber of content words that appear in both S vnrand Smt vnm.
Smtvnmis a translation result ofS vmm.
We retrieved vnrand vnmas a bilinguallexicon that satisfies:{vnr, vnm} = argmax{vnr?
?BP (vnm), vnm}S sim(vnr?, vnm) , (7)where BP (vnm) is a set of bilingual verb?nounpairs, each of which includes vnmon the Japaneseside.3 Experiments3.1 Integrating hierarchies3.1.1 Experimental setupWe used Reuters?96 and UDC code hierarchies.The Reuters?96 corpus from 20th Aug. 1996 to19th Aug. 1997 consists of 806,791 documentsorganized into coarse-grained categories, i.e., 126categories with a four-level hierarchy.
The RWCPcorpus labeled with UDC codes selected from1994 Mainichi newspaper consists of 27,755 doc-uments organized into a fine-grained categories,i.e., 9,951 categories with a seven-level hierarchy(RWCP., 1998).
We used Japanese-English andEnglish-Japanese MT software (Internet Honyaku-no-Ousama for Linux, Ver.5, IBM Corp.) forCLTC.
We divided both Reuters?96 (from 20thAug.
1996 to 19th May 1997) and RWCP corporainto two equal sets: a training set to train SVMclassifiers, and a test set for TC to generate pairsof similar categories.
We divided the test set intotwo parts: the first was used to estimate thresholds,i.e., a decision threshold b used in CLTC, and lowerbound L?2; and the second was used to generatepairs of similar categories using the threshold.
Wechose b = 0 for each level of a hierarchy.
The lowerbound L?2was .003.We selected 109 categories from Reuters and4,739 categories from Mainichi, which have atleast five documents in each set.
We used con-tent words for both English and Japanese docu-ments.
We compared the results obtained by hi-erarchical approach to those obtained by the flat236Table 1: Performance of category correspondencesHierarchy FlatPrec Rec F1 Prec Rec F1Mai & Reu .503 .463 .482 .462 .389 .422Reu .342 .329 .335 .240 .296 .265Mai .157 .293 .204 .149 .277 .194non-hierarchical approach.
Moreover, in the hier-archical approach, we applied a Boolean functionto each test document.For evaluation of category correspondences, weused F1-score (F1) which is a measure that bal-ances precision (Prec) and recall (Rec).
Let Corbe a set of correct category pairs.4 The precise def-initions of the precision and recall of the task aregiven below:Prec =| {(r, m) | (r,m) ?
Cor, ?2(r, m) ?
L?2} || {(r, m) | ?2(r, m) ?
L?2} |Rec =| {(r, m) | (r,m) ?
Cor, ?2(r, m) ?
L?2} || {(r, m) | (r,m) ?
Cor} |3.1.2 ResultsTable 1 shows F1 of category correspondenceswith L?2= .003.
?Mai & Reu?
shows the resultsobtained by our method.
?Mai?
and ?Reu?
showthe results using only one hierarchy.
For example,?Mai?
shows the results in which both Mainichiand translated Reuters documents are classifiedinto categories with Mainichi hierarchy, and esti-mated category correspondences.Integrating hierarchies is more effective thanonly a single hierarchy.
Moreover, we found ad-vantages in the F1 for the hierarchical approach(?Hierarchy?
in Table 1) in comparison with abaseline flat approach (?Flat?).
We note that theresult of ?Mai?
was worse than that of ?Reu?
inboth approaches.
One reason is that the accuracyof TC.
The micro-average F1 of TC for Reuters hi-erarchy was .815, while that of Mainichi was .673,as Mainichi hierarchy consists of many categories,and the number of training data for each categorywere smaller than those of Reuters.
The results ob-tained by our method depend on the performanceof TC.
Therefore, it will be necessary to examinesome semi-supervised learning techniques to im-prove classification accuracy.4The classification was determined to be correct if the twohuman judges agreed on the evaluation.Table 2: Data for retrieving documentsJap ?
Eng(?
3) Total # of doc.
Total # ofJap Eng relevant doc.26/06/97 391 15,482 5133.2 Relevant document retrieval3.2.1 Experimental setupThe training data for choosing the lower boundL?used in the relevant document retrieval isReuters and RWCP from 13th to 21st Jun.
1997.The difference in dates between them is less than?
3 days.
For example, when the date of theRWCP document is 18th Jun., the correspondingReuters date is from 15th to 21st Jun.
We choseL?that maximized the average F1 among them.Table 2 shows the test data, i.e., the total numberof collected documents and the number of relateddocuments collected manually for the evaluation.5We implemented the following approaches includ-ing related work, and compared these results withthose obtained by our methods, Int hi & Eng.1.
No hierarchy: Categories with each hierar-chy are not used in the approach.
The ap-proach is the same as the method reported byCollier et al (1998) except for term weightsand similarities.
We calculate similarities be-tween Reuters and translated Mainichi docu-ments, where the difference in dates is lessthan ?
3 days.
(No hi & Eng).2.
Hierarchy: The approach uses only Reutershierarchy (we call this Reu Hierarchy).Reuters documents and translated Mainichidocuments are classified into categories withReuters hierarchy.
We calculate BM25between Reuters and Mainichi documentswithin the same category.
The procedure isapplied for all categories of the hierarchies.The judgment of relevant documents was thesame as our method: if the value of similarity be-tween two documents is higher than a lower boundL?, we regarded them as relevant documents.3.2.2 ResultsThe retrieval results are shown in Table 3 andFigure 4.
Table 3 shows best performance of eachmethod against L?.
As can be seen clearly fromTable 3 and Figure 4, the results with integratinghierarchies improved overall performance.5The classification was determined by two human.237Table 3: Retrieval performancePrec Rec F1-score L?No hi & Eng .417 .322 .363 40Reu Hierarchy .356 .544 .430 20Int hi & Eng .839 .585 .689 20Figure 4: F1 of retrieving relevant documentsTable 4 shows the total number of documentpairs (P), Reuters (E), and Mainichi documents (J),which satisfied the similarity lower bound L?.
Asshown in Table 4, the number of retrieved pairsby non-hierarchy approach was much greater thanthat of ?Int hi & Eng?
at all L?values.
This is be-cause pairs are retrieved by using only the BM25.Therefore, many of the document pairs retrieveddo not have closely related contents, even if L?isset to a higher value.The results of a single hierarchy showed re-call of .544, while that of the integrating hier-archies was .585 at the same L?value (20), asshown in Table 3.
This is because in the sin-gle hierarchy method, there are some translatedMainichi documents that are not correctly clas-sified into categories with the Reuters hierarchy.For example, ?Hashimoto remarks on fx rates?in Mainichi documents should be classified intoReuters category ?Forex markets,?
but it was clas-sified into ?Government?.
As a result, ?U.S.
Trea-sury has no comment on Hashimoto fx remarks?in Reuters category ?Forex markets?
and the doc-ument ?Hashimoto?
are not retrieved by a singlehierarchy approach.
In contrast, in the integrat-ing method, these two documents are classifiedcorrectly into a pair of similar categories, i.e., the?U.S Treasury?
is classified into Reuters category?Forex markets?, and the ?Hashimoto?
is clas-sified into Mainichi category ?Money and bank-ing?.
These observations show that our methodcontributes to the retrieval of relevant documents.Table 4: # of documents vs L?Approach Lower Bound L?100 80 60 40 20p 188 319 630 1,229 3,000No hi & Eng E 150 272 543 987 2,053J 13 16 19 22 25p 12 17 25 47 186Reu Hierarchy E 8 12 19 36 142J 8 10 12 18 25p 46 61 83 135 218Int hi & Eng E 32 43 60 99 158J 4 4 5 7 9Table 5: # of J/E document pairs with L?Approach & (L?)
pairs Eng JapNo hi & Eng (40) 3,042,166 428,042 70,080Reu Hierarchy (20) 27,181,243 43,0181 99,452Int hi & Eng (20) 81,904,243 45,965 654,7873.3 Bilingual Verb?noun CollocationsFinally, we report the results of bilingual verb?noun collocations.3.3.1 Experimental setupThe data for relevant document retrieval was theReuters and Mainichi corpora from the same pe-riod, i.e., 20th Aug. 1996 to 19th Aug. 1997.
Thetotal number of Reuters documents was 806,791,and that of Mainichi was 119,822.
As the num-ber of Reuters documents was far greater than thatof Mainichi documents, we estimated collocationsfrom the results of cross-lingually retrieving rele-vant English documents with Japanese query doc-uments.
The difference in dates between them wasless than ?
3 days.
Table 5 shows retrieved rele-vant documents that showed best performance ofeach method against L?.
From these data, we ex-tracted bilingual verb-noun collocations.3.3.2 ResultsTable 6 shows the numbers of English andJapanese monolingual verb?noun collocations,those of candidate collocations against whichbilingual correspondences were estimated, andthose of correct collocations.
?D & S?
of candidatecollocations indicates the number of collocationswhen we applied both document- and sentence-based retrieval.
?Doc?
indicates the number of col-locations when we applied only document-basedretrieval.
?D & S?
and ?Doc?
of correct colloca-tions show the number of correct collocations inthe topmost 1,000 according to sentence similar-ity and the ?2 statistics, respectively.
As shown in238Table 6, the results obtained by integrating hierar-chies showed a 15.1% (32.8 - 17.7) improvementover the baseline non-hierarchy model, and a 6.0%(32.8 - 26.8) improvement over use of a single hi-erarchy.
We manually compared those 328 bilin-gual collocations with an existing bilingual lexi-con where 78 of them (23.8%) were not includedin it.6 Moreover, 168 of 328 (51.2%) were notcorrectly translated by Japanese-English MT soft-ware.7 These observations clearly support the use-fulness of the method.It is very important to compare the column?rate?
for the numbers of candidate collocationswith that for the numbers of correct collocations.In all approaches, sentence-based retrieval waseffective in removing useless collocations, espe-cially in our method, about 1.5% of the sizeobtained by ?Doc?
was retrieved, while about4.6(328/72) times the number of correct colloca-tions were obtained in the topmost 1,000 colloca-tions.
These observations showed that sentence-based retrieval contributes to a marked reductionin the number of useless collocations without a de-crease in accuracy.The last column in Table 6 shows the results us-ing Inverse Rank Score (IRS), which is a measureof system performance by considering the rank ofcorrect bilingual collocations within the candidatecollocations.
It is the sum of the inverse rank ofeach matching collocations, e.g., correct colloca-tions by manual evaluation matches at ranks 2 and4 give an IRS of 12+ 14= 0.75.
With at most 1,000collocations, the maximum IRS score is 7.485, andthe higher the IRS value, the better the system per-formance.
As shown in Table 6, the performanceby integrating hierarchies was much better thanthat of the non-hierarchical approach, and slightlybetter than those obtained by a single hierarchy.However, correct retrieved collocations were dif-ferent from each other.
Table 7 lists examples ofbilingual collocations obtained by a single hierar-chy and integrating hierarchies.
The category is?Sport?.8 (x,y) of category pair in Table 7 refer toReuters and Mainichi category correspondences.Examples in Table 7 denote only English verb?6We used an existing bilingual lexicon, Eijiro on the Web,1.91 million words, (http://www.alc.co.jp) for evaluation.
Ifcollocations were not included, the estimation was deter-mined by two human judges.7The number of words in the Japanese-English dictionary(Internet Honyaku-no-Ousama for Linux, Ver.5, IBM Corp.)was about 250,000.8We obtained 98 category pairs in the Sport category.noun collocations.It is interesting to note that 12 of 154 colloca-tions, such as ?earn medal?
and ?block shot?
ob-tained by integrating hierarchies were also ob-tained by a single hierarchy approach.
How-ever, other collocations such as ?get strikeout?
and?make birdie?
which were obtained in a particularcategory (Sport, Baseball) and (Sport, Golf), didnot appear in either of the results using a singlehierarchy or a non hierarchical approach.
Theseobservations again clearly support the usefulnessof our method.4 Previous WorkMuch of the previous work on finding bilinguallexicons used comparable corpora.
One attemptinvolved directly retrieving bilingual lexicons fromcorpora.
One approach focused on extracting wordtranslations (Gaussier et al, 2004).
The techniqueswere based on the idea that semantically similarwords appear in similar contexts.
Unlike paral-lel corpora, the position of a word in a documentis useless for translation into the other language.In these techniques, the frequency of words in themonolingual document is calculated and their con-textual similarity is measured across languages.Another approach focused on sentence extraction(Fung and Cheung, 2004).
One limitation of allthese methods is that they need to control the ex-perimental evaluation to avoid estimation of everybilingual lexicon appearing in comparable corpora.The alternative consists of two steps: first, cross-lingual relevant documents are retrieved fromcomparable corpora, then bilingual term corre-spondences within these relevant documents areestimated.
Thus, the accuracy depends on the per-formance of relevant documents retrieval.
Muchof the previous work in finding relevant docu-ments used MT systems or existing bilingual lexi-cons to translate one language into another.
Doc-ument pairs are then retrieved using some mea-sure of document similarity.
Another approach toretrieving relevant documents involves the collec-tion of relevant document URLs from the WWW(Resnik and Smith, 2003).
Utsuro et al (2003)proposed a method for acquiring bilingual lex-icons that involved retrieval of relevant Englishand Japanese documents from news sites on theWWW.
Our work is also applicable to retrievalof relevant documents on the web because it es-timates every bilingual lexicon only appearing in239Table 6: Numbers of monolingual and bilingual verb?noun collocationsApproach & (L?)
# of Candidate collocations # of Correct collocations Inverse(top 1,000) rank scoreMonolingual patterns # of collocations rate # of collocations rate(D & S/ (D & S/ (top 1,000)Jap Eng D & S Doc Doc) D & S Doc Doc) D & S DocNo hi & Eng (40) 25,163 44,762 25,163 6,976,214 .361 177 62 2.9 1.35 0.71Reu Hierarchy (20) 10,576 37,022 10,576 1,272,102 .831 268 64 4.2 2.24 1.41Int hi & Eng (20) 8,347 21,524 8,347 560,472 1.489 328 72 4.6 2.33 1.46Table 7: Examples of bilingual verb?noun collocationsApproach & (L?)
Category or # of collocations # of correct Examples (English)category pair D & S Doc collocations(%)Reu Hierarchy (20) Sport 262 19,391 36(13.7) create chance, earn medal, feel pressureblock shot, establish record, take chance(Sport, Baseball) 110 8,838 24(21.8) get strikeout, leave base, throw pitch(Sport, Relay) 177 3,418 18(10.2) lead ranking, run km, win athletic(Sport, Tennis) 115 2,656 32(27.8) lose prize money, play exhibition gameInt hi & Eng (20) (Sport, Golf) 131 2,654 28(21.4) make birdie, have birdie, hole putt, miss putt(Sport, Soccer) 86 1,317 34(39.5) block shot, score defender, give free kick(Sport, Sumo) 75 773 2(2.7) lead sumo, set championship(Sport, Ski jump) 68 661 10(14.7) postpone downhill, earn medal(Sport, Football) 37 461 6(16.2) play football, lease football stadiuma set of smaller documents belonging to pairs ofsimilar categories.
Munteanu and Marcu (2006)proposed a method for extracting parallel sub-sentential fragments from very non-parallel bilin-gual corpora.
The method is based on the fact thatvery non-parallel corpora has none or few goodsentence pairs, while existing methods for exploit-ing comparable corpora look for parallel data atthe sentence level.
Their methodology is the firstaimed at detecting sub-sentential correspondences,while they have not reported that the method isalso applicable for large amount of data with goodperformance, especially in the case of large-scaleevaluation such as that presented in this paper.5 ConclusionWe have developed an approach to bilingual verb?noun collocations from non-parallel corpora.
Theresults showed the effectiveness of the method.Future work will include: (i) applying the methodto retrieve other types of collocations (Smadja,1993), and (ii) evaluating the method using Inter-net directories.ReferencesCollier, N., H. Hirakawa, and A. Kumano.
1998.
MachineTranslation vs.
Dictionary Term Translation - a Compar-ison for English-Japanese News Article Alignment.
InProc.
of 36th ACL and 17th COLING., pages 263?267.Fung, P. and P. Cheung.
2004.
Mining Very Non-ParallelCorpora: Parallel Sentence and Lexicon Extraction vieBootstrapping and EM.
In Proc.
of EMNLP2004., pages57?63.Gaussier, E., H-M. Renders, I. Matveeva, C. Goutte, andH.
De?jean.
2004.
A Geometric View on Bilingual Lex-icon Extraction from Comparable Corpora.
In Proc.
of42nd ACL, pages 527?534.Kudo, T. and Y. Matsumoto.
2003.
Fast Methods for Kernel-based Text Analysis.
In Proc.
of 41th ACL, pages 24?31.Lin, D. 1993.
Principle-based Parsing without Overgenera-tion.
In Proc.
of 31st ACL, pages 112?120.Munteanu, D. S. and D. Marcu.
2006.
Extracting ParallelSub-Sentential Fragments from Non-Parallel Corpora.
InProc.
of 21st COLING and 44th ACL., pages 81?88.Resnik, P. and N. A. Smith.
2003.
The Web as a ParallelCorpus.
Computational Linguistics., 29(3):349?380.RWCP.
1998.
Rwc Text Database.
In Real World ComputingPartnership.Smadja, F. 1993.
Retrieving Collocations from Text: Xtract.Computational Linguistics., 19(1):243?178.Utsuro, T., T. Horiuchi, T. Hamamoto, K. Hino, andT.
Nakayama.
2003.
Effect of Cross-Language IR inBilingual Lexicon Acquisition from Comparable Corpora.In Proc.
of 10th EACL., pages 355?362.Vapnik, V. 1995.
The Nature of Statistical Learning Theory.Springer.240
