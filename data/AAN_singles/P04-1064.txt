Aligning words using matrix factorisationCyril Goutte, Kenji Yamada and Eric GaussierXerox Research Centre Europe6, chemin de MaupertuisF-38240 Meylan, FranceCyril.Goutte,Kenji.Yamada,Eric.Gaussier@xrce.xerox.comAbstractAligning words from sentences which are mutualtranslations is an important problem in different set-tings, such as bilingual terminology extraction, Ma-chine Translation, or projection of linguistic fea-tures.
Here, we view word alignment as matrix fac-torisation.
In order to produce proper alignments,we show that factors must satisfy a number of con-straints such as orthogonality.
We then propose analgorithm for orthogonal non-negative matrix fac-torisation, based on a probabilistic model of thealignment data, and apply it to word alignment.
Thisis illustrated on a French-English alignment taskfrom the Hansard.1 IntroductionAligning words from mutually translated sentencesin two different languages is an important and dif-ficult problem.
It is important because a word-aligned corpus is typically used as a first step in or-der to identify phrases or templates in phrase-basedMachine Translation (Och et al, 1999), (Tillmannand Xia, 2003), (Koehn et al, 2003, sec.
3), orfor projecting linguistic annotation across languages(Yarowsky et al, 2001).
Obtaining a word-alignedcorpus usually involves training a word-based trans-lation models (Brown et al, 1993) in each directionsand combining the resulting alignments.Besides processing time, important issues arecompleteness and propriety of the resulting align-ment, and the ability to reliably identify general N-to-M alignments.
In the following section, we in-troduce the problem of aligning words from a cor-pus that is already aligned at the sentence level.
Weshow how this problem may be phrased in termsof matrix factorisation.
We then identify a numberof constraints on word alignment, show that theseconstraints entail that word alignment is equivalentto orthogonal non-negative matrix factorisation, andwe give a novel algorithm that solves this problem.This is illustrated using data from the shared tasksof the 2003 HLT-NAACL Workshop on Buildingle droit de permis ne augmente pasthe licence fee does not increaseFigure 1: 1-1, M-1, 1-N and M-N alignments.and Using Parallel Texts (Mihalcea and Pedersen,2003).2 Word alignmentsWe address the following problem: Given a sourcesentence f = f1 .
.
.
fi .
.
.
fI and a target sentencee = e1 .
.
.
ej .
.
.
eJ , we wish to find words fi and ejon either side which are aligned, ie in mutual corre-spondence.
Note that words may be aligned withoutbeing directly ?dictionary translations?.
In order tohave proper alignments, we want to enforce the fol-lowing constraints:Coverage: Every word on either side must bealigned to at least one word on the other side(Possibly taking ?null?
words into account).Transitive closure: If fi is aligned to ej and e`, anyfk aligned to e` must also de aligned to ej .Under these constraints, there are only 4 typesof alignments: 1-1, 1-N, M-1 and M-N (fig.
1).Although the first three are particular cases whereN=1 and/or M=1, the distinction is relevant, becausemost word-based translation models (eg IBM mod-els (Brown et al, 1993)) can typically not accom-modate general M-N alignments.We formalise this using the notion of cepts: acept is a central pivot through which a subset of e-words is aligned to a subset of f -words.
GeneralM-N alignments then correspond to M-1-N align-ments from e-words, to a cept, to f -words (fig.
2).Cepts naturally guarantee transitive closure as longas each word is connected to a single cept.
In ad-dition, coverage is ensured by imposing that eachle droit de permis ne augmente pasthe licence fee does not increase(1) (2) (3)(4)Figure 2: Same as figure 1, using cepts (1)-(4).English wordsceptsMotsfrancaisMotsfrancaisceptsEnglish wordsFigure 3: Matrix factorisation of the example fromfig.
1, 2.
Black squares represent alignments.word is connected to a cept.
A unique constrainttherefore guarantees proper alignments:Propriety: Each word is associated to exactly onecept, and each cept is associated to at least oneword on each side.Note that our use of cepts differs slightly from thatof (Brown et al, 1993, sec.3), inasmuch cepts maynot overlap, according to our definition.The motivation for our work is that better wordalignments will lead to better translation mod-els.
For example, we may extract better chunksfor phrase-based translation models.
In addition,proper alignments ensure that cept-based phraseswill cover the entire source and target sentences.3 Matrix factorisationAlignments between source and target words maybe represented by a I ?
J alignment matrix A =[aij ], such that aij > 0 if fi is aligned with ej andaij = 0 otherwise.
Similarly, given K cepts, wordsto cepts alignments may be represented by a I ?K matrix F and a J ?
K matrix E, with positiveelements indicating alignments.
It is easy to see thatmatrix A = F ?
E> then represents the resultingword-to-word alignment (fig.
3).Let us now assume that we start from a I?J ma-trix M = [mij ], which we call the translation ma-trix, such that mij ?
0 measures the strength of theassociation between fi and ej (large values meanclose association).
This may be estimated using atranslation table, a count (eg from a N-best list), etc.Finding a suitable alignment matrix A correspondsto finding factors F and E such that:M?
F ?
S ?
E> (1)where without loss of generality, we introduce a di-agonal K ?
K scaling matrix S which may givedifferent weights to the different cepts.
As factorsF and E contain only positive elements, this is aninstance of non-negative matrix factorisation, akaNMF (Lee and Seung, 1999).
Because NMF de-composes a matrix into additive, positive compo-nents, it naturally yields a sparse representation.In addition, the propriety constraint imposes thatwords are aligned to exactly one cept, ie each rowof E and F has exactly one non-zero component, aproperty we call extreme sparsity.
With the notationF = [Fik], this means that:?i, ?k 6= l, Fik.Fil = 0As line i contains a single non-zero element, eitherFik or Fil must be 0.
An immediate consequence isthat?i Fik.Fil = 0: columns of F are orthogonal,that is F is an orthogonal matrix (and similarly, Eis orthogonal).
Finding the best alignment startingfrom M therefore reduces to performing a decom-position into orthogonal non-negative factors.4 An algorithm for OrthogonalNon-negative Matrix FactorisationStandard NMF algorithms (Lee and Seung, 2001)do not impose orthogonality between factors.
Wepropose to perform the Orthogonal Non-negativeMatrix Factorisation (ONMF) in two stages: Wefirst factorise M using Probabilistic Latent Seman-tic Analysis, aka PLSA (Hofmann, 1999), then weorthogonalise factors using a Maximum A Poste-riori (MAP) assignment of words to cepts.
PLSAmodels a joint probability P (f, e) as a mixtureof conditionally independent multinomial distribu-tions:P (f, e) =?cP (c)P (f |c)P (e|c) (2)With F = [P (f |c)], E = [P (e|c)] and S =diag(P (c)), this is exactly eq.
1.
Note also thatdespite the additional matrix S, if we set E =[P (e, c)], then P (f |e) would factor as F ?
E>, theoriginal NMF formulation).
All factors in eq.
2are (conditional) probabilities, and therefore posi-tive, so PLSA also implements NMF.The parameters are learned from a matrix M =[mij ] of (fi, ej) counts, by maximising the like-lihood using the iterative re-estimation formula ofthe Expectation-Maximisation algorithm (Dempsteret al, 1977), cf.
fig.
4.
Convergence is guaran-teed, leading to a non-negative factorisation of M.The second step of our algorithm is to orthogonaliseE-step: P (c|fi, ej) =P (c)P (fi|c)P (ej |c)?cP (c)P (fi|c)P (ej |c)(3)M-step: P (c) = 1N?ijmijP (c|fi, ej) (4)M-step: P (fi|c) ?
?jmijP (c|fi, ej) (5)M-step: P (ej |c) ?
?imijP (c|fi, ej) (6)Figure 4: The EM algorithm iterates these E andM-steps until convergence.the resulting factors.
Each source word fi is as-signed the most probable cept, ie cept c for whichP (c|fi) ?
P (c)P (fi|c) is maximal.
Factor F istherefore set to:Fik ?
{ 1 if k = argmaxc P (c|fi)0 otherwise (7)where proportionality ensures that column of F sumto 1, so that F stays a conditional probability ma-trix.
We proceed similarly for target words ej toorthogonalise E. Thanks to the MAP assignment,each line of F and E contains exactly one non-zeroelement.
We saw earlier that this is equivalent tohaving orthogonal factors.
The result is therefore anorthogonal, non-negative factorisation of the origi-nal translation matrix M.4.1 Number of ceptsIn general, the number of cepts is unknown andmust be estimated.
This corresponds to choos-ing the number of components in PLSA, a classi-cal model selection problem.
The likelihood maynot be used as it always increases as componentsare added.
A standard approach to optimise thecomplexity of a mixture model is to maximise thelikelihood, penalised by a term that increases withmodel complexity, such as AIC (Akaike, 1974) orBIC (Schwartz, 1978).
BIC asymptotically choosesthe correct model size (for complete models), whileAIC always overestimates the number of compo-nents, but usually yields good predictive perfor-mance.
As the largest possible number of cepts ismin(I, J), and the smallest is 1 (all fi aligned toall ej), we estimate the optimal number of ceptsby maximising AIC or BIC between these two ex-tremes.4.2 Dealing with null alignmentsAlignment to a ?null?
word may be a feature of theunderlying statistical model (eg IBM models), or itmay be introduced to accommodate words whichhave a low association measure with all other words.Using PLSA, we can deal with null alignments in aprincipled way by introducing a null word on eachside (f0 and e0), and two null cepts (?f-null?
and?e-null?)
with a 1-1 alignment to the correspond-ing null word, to ensure that null alignments willonly be 1-N or M-1.
This constraint is easily im-plemented using proper initial conditions in EM.Denoting the null cepts as cf?
and ce?, 1-1 align-ments between null cepts and the corresponding nullwords impose the conditions:1.
P (f0|cf?)
= 1 and ?i 6= 0, P (fi|cf?)
= 0;2.
P (e0|ce?)
= 1 and ?j 6= 0, P (ej |ce?)
= 0.Stepping through the E-step and M-step equations(3?6), we see that these conditions are preserved byeach EM iteration.
In order to deal with null align-ments, the model is therefore augmented with twonull cepts, for which the probabilities are initialisedaccording to the above conditions.
As these are pre-served through EM, we maintain proper 1-N and M-1 alignments to the null words.
The main differencebetween null cepts and the other cepts is that werelax the propriety constraint and do not force nullcepts to be aligned to at least one word on eitherside.
This is because in many cases, all words froma sentence can be aligned to non-null words, and donot require any null alignments.4.3 Modelling noiseMost elements of M usually have a non-zero asso-ciation measure.
This means that for proper align-ments, which give zero probability to alignmentsoutside identified blocks, actual observations haveexactly 0 probability, ie the log-likelihood of param-eters corresponding to proper alignments is unde-fined.
We therefore refine the model, adding a noisecomponent indexed by c = 0:P (f, e) =?c>0P (c)P (f |c)P (e|c)+P (c = 0)P (f, e|c = 0)The simplest choice for the noise component is auniform distribution, P (f, e|c = 0) ?
1.
E-stepand M-steps in eqs.
(3?6) are unchanged for c > 0,and the E-step equation for c = 0 is easily adapted:P (c=0|f, e) ?
P (c=0)P (f, e|c=0).5 ExampleWe first illustrate the factorisation process on asimple example.
We use the data provided forthe French-English shared task of the 2003 HLT-NAACL Workshop on Building and Using Par-allel Texts (Mihalcea and Pedersen, 2003).
Thedata is from the Canadian Hansard, and referencealignments were originally produced by Franz Ochand Hermann Ney (Och and Ney, 2000).
Usingthe entire corpus (20 million words), we trainedEnglish?French and French?English IBM4 mod-els using GIZA++.
For all sentences from the trialand test set (37 and 447 sentences), we generated upto 100 best alignments for each sentence and in eachdirection.
For each pair of source and target words(fi, ej), the association measure mij is simply thenumber of times these words were aligned togetherin the two N-best lists, leading to a count between 0(never aligned) and 200 (always aligned).We focus on sentence 1023, from the trial set.Figure 5 shows the reference alignments togetherwith the generated counts.
There is a background?noise?
count of 3 to 5 (small dots) and the largestcounts are around 145-150.
The N-best counts seemto give a good idea of the alignments, althoughclearly there is no chance that our factorisation al-gorithm will recover the alignment of the two in-stances of ?de?
to ?need?, as there is no evidence forit in the data.
The ambiguity that the factorisationwill have to address, and that is not easily resolvedusing, eg, thresholding, is whether ?ont?
should bealigned to ?They?
or to ?need?.The N-best count matrix serves as the transla-tion matrix.
We estimate PLSA parameters forK = 1 .
.
.
6, and find out that AIC and BIC reachtheir maximum for K = 6.
We therefore select 6cepts for this sentence, and produce the alignmentmatrices shown on figure 6.
Note that the orderof the cepts is arbitrary (here the first cept corre-spond ?et?
?
?and?
), except for the null cepts whichare fixed.
There is a fixed 1-1 correspondence be-tween these null cepts and the corresponding nullwords on each side, and only the French words ?de?are mapped to a null cept.
Finally, the estimatednoise level is P (c = 0) = 0.00053.
The ambigu-ity associated with aligning ?ont?
has been resolvedthrough cepts 4 and 5.
In our resulting model,P (c=4|?ont?)
?
0.40 while P (c=6|?ont?)
?
0.54:The MAP assignment forces ?ont?
to be aligned tocept 5 only, and therefore to ?need?.Note that although the count for (need,ont) isslightly larger than the count for (they,ont) (cf.
fig.5), this is not a trivial result.
The model was able toresolve the fact that they and need had to be alignedto 2 different cepts, rather than eg a larger ceptcorresponding to a 2-4 alignment, and to produceproper alignments through the use of these cepts.6 ExperimentsIn order to perform a more systematic evaluation ofthe use of matrix factorisation for aligning words,we tested this technique on the full trial and test datafrom the 2003 HLT-NAACL Workshop.
Note thatthe reference data has both ?Sure?
and ?Probable?alignments, with about 77% of all alignments in thelatter category.
On the other hand, our system pro-poses only one type of alignment.
The evaluationis done using the performance measures describedin (Mihalcea and Pedersen, 2003): precision, recalland F-score on the probable and sure alignments, aswell as the Alignment Error Rate (AER), which inour case is a weighted average of the recall on thesure alignments and the precision on the probable.Given an alignment A and gold standards GS andGP (for sure and probable alignments, respectively):PT =|A ?
GT ||A| (8)RT =|A ?
GT ||GT |(9)FT =2PT RTPT + RT= 2|A ?
GT ||GT |+ |A|(10)where T is either S or P , and:AER = 1?
|GS |RS + |A|PP|GS |+ |A|(11)Using these measures, we first evaluate the per-formance on the trial set (37 sentences): as weproduce only one type of alignment and evaluateagainst ?Sure?
and ?Probable?, we observe, as ex-pected, that the recall is very good on sure align-ments, but precision relatively poor, with the re-verse situation on the probable alignments (table 1).This is because we generate an intermediate numberof alignments.
There are 338 sure and 1446 prob-able alignments (for 721 French and 661 Englishwords) in the reference trial data, and we produce707 (AIC) or 766 (BIC) alignments with ONMF.Most of them are at least probably correct, as at-tested by PP , but only about half of them are in the?Sure?
subset, yielding a low value of PS .
Sim-ilarly, because ?Probable?
alignments were gener-ated as the union of alignments produced by twoannotators, they sometimes lead to very large M-N alignments, which produce on average 2.5 to 2.7alignments per word.
By contrast ONMF producesless than 1.2 alignments per word, hence the lowvalue of RP .
As the AER is a weighted average ofRS and PP , the resulting AER are relatively low forour method.Reference alignmentsNULLtheyneedtoysandentertainment .NULLlesenfantsontbesoindejouetsetdeloisirs.N?best countsNULLtheyneedtoysandentertainment .NULLlesenfantsontbesoindejouetsetdeloisirs.Figure 5: Left: reference alignments, large squares are sure, medium squares are probable; Right: accumu-lated counts from IBM4 N-best lists, bigger squares are larger counts.f?to?cept alignmentcept1cept2cept3cept4cept5cept6f?nulle?nullNULLlesenfantsontbesoindejouetsetdeloisirs.
?e?to?cept alignmentNULLtheyneedtoysandentertainment .e?nullf?nullcept6cept5cept4cept3cept2cept1=Resulting alignmentNULLtheyneedtoysandentertainment .NULLlesenfantsontbesoindejouetsetdeloisirs.Figure 6: Resulting word-to-cept and word-to-word alignments for sentence 1023.Method PS RS FS PP RP FP AERONMF + AIC 45.26% 94.67% 61.24% 86.56% 34.30% 49.14% 10.81%ONMF + BIC 42.69% 96.75% 59.24% 83.42% 35.82% 50.12% 12.50%Table 1: Performance on the 37 trial sentences for orthogonal non-negative matrix factorisation (ONMF)using the AIC and BIC criterion for choosing the number of cepts, discounting null alignments.We also compared the performance on the 447test sentences to 1/ the intersection of the align-ments produced by the top IBM4 alignments in ei-ther directions, and 2/ the best systems from (Mi-halcea and Pedersen, 2003).
On limited resources,Ralign.EF.1 (Simard and Langlais, 2003) producedthe best F -score, as well as the best AER whenNULL alignments were taken into account, whileXRCE.Nolem.EF.3 (Dejean et al, 2003) producedthe best AER when NULL alignments were dis-counted.
Tables 2 and 3 show that ONMF improveson several of these results.
In particular, we get bet-ter recall and F -score on the probable alignments(and even a better precision than Ralign.EF.1 in ta-ble 2).
On the other hand, the performance, and inparticular the precision, on sure alignments is dis-mal.
We attribute this at least partly to a key dif-ference between our model and the reference data:Method PS RS FS PP RP FP AERONMF + AIC 49.86% 95.12% 65.42% 84.63% 37.39% 51.87% 11.76%ONMF + BIC 46.50% 96.01% 62.65% 80.92% 38.69% 52.35% 14.16%IBM4 intersection 71.46% 90.04% 79.68% 97.66% 28.44% 44.12% 5.71%HLT-03 best F 72.54% 80.61% 76.36% 77.56% 38.19% 51.18% 18.50%HLT-03 best AER 55.43% 93.81% 69.68% 90.09% 35.30% 50.72% 8.53%Table 2: Performance on the 447 English-French test sentences, discounting NULL alignments, for orthog-onal non-negative matrix factorisation (ONMF) using the AIC and BIC criterion for choosing the number ofcepts.
HLT-03 best F is Ralign.EF.1 and best AER is XRCE.Nolem.EF.3 (Mihalcea and Pedersen, 2003).our model enforces coverage and makes sure thatall words are aligned, while the ?Sure?
referencealignments have no such constraints and actuallyhave a very bad coverage.
Indeed, less than half thewords in the test set have a ?Sure?
alignment, whichmeans that a method which ensures that all wordsare aligned will at best have a sub 50% precision.
Inaddition, many reference ?Probable?
alignments arenot proper alignments in the sense defined above.Note that the IBM4 intersection has a bias similarto the sure reference alignments, and performs verywell in FS , PP and especially in AER, even thoughit produces very incomplete alignments.
This pointsto a particular problem with the AER in the contextof our study.
In fact, a system that outputs exactlythe set of sure alignments achieves a perfect AER of0, even though it aligns only about 23% of words,clearly an unacceptable drawback in many applica-tions.
We think that this issue may be addressedin two different ways.
One time-consuming possi-bility would be to post-edit the reference alignmentto ensure coverage and proper alignments.
An-other possibility would be to use the probabilisticmodel to mimic the reference data and generate both?Sure?
and ?Probable?
alignments using eg thresh-olds on the estimated alignment probabilities.
Thisapproach may lead to better performance accordingto our metrics, but it is not obvious that the pro-duced alignments will be more reasonable or evenuseful in a practical application.We also tested our approach on the Romanian-English task of the same workshop, cf.
table 4.The ?HLT-03 best?
is our earlier work (Dejean etal., 2003), simply based on IBM4 alignment us-ing an additional lexicon extracted from the corpus.Slightly better results have been published since(Barbu, 2004), using additional linguistic process-ing, but those were not presented at the workshop.Note that the reference alignments for Romanian-English contain only ?Sure?
alignments, and there-fore we only report the performance on those.
In ad-dition, AER = 1?FS in this setting.
Table 4 showsthat the matrix factorisation approach does not offerany quantitative improvements over these results.
Again of up to 10 points in recall does not offset alarge decrease in precision.
As a consequence, theAER for ONMF+AIC is about 10% higher than inour earlier work.
This seems mainly due to the factthat the ?HLT-03 best?
produces alignments for onlyabout 80% of the words, while our technique en-sure coverage and therefore aligns all words.
Theseresults suggest that remaining 20% seem particu-larly problematic.
These quantitative results aredisappointing given the sofistication of the method.It should be noted, however, that ONMF providesthe qualitative advantage of producing proper align-ments, and in particular ensures coverage.
This maybe useful in some contexts, eg training a phrase-based translation system.7 Discussion7.1 Model selection and stabilityLike all mixture models, PLSA is subject to lo-cal minima.
Although using a few random restartsseems to yield good performance, the results ondifficult-to-align sentences may still be sensitive toinitial conditions.
A standard technique to stabilisethe EM solution is to use deterministic annealing ortempered EM (Rose et al, 1990).
As a side effect,deterministic annealing actually makes model se-lection easier.
At low temperature, all componentsare identical, and they differentiate as the temper-ature increases, until the final temperature, wherewe recover the standard EM algorithm.
By keep-ing track of the component differentiations, we mayconsider multiple effective numbers of componentsin one pass, therefore alleviating the need for costlymultiple EM runs with different cept numbers andmultiple restarts.7.2 Other association measuresONMF is only a tool to factor the original trans-lation matrix M, containing measures of associa-tions between fi and ej .
The quality of the re-sulting alignment greatly depends on the way M isMethod PS RS FS PP RP FP AERONMF + AIC 42.88% 95.12% 59.11% 75.17% 37.20% 49.77% 18.63%ONMF + BIC 40.17% 96.01% 56.65% 72.20% 38.49% 50.21% 20.78%IBM4 intersection 56.39% 90.04% 69.35% 81.14% 28.90% 42.62% 15.43%HLT-03 best 72.54% 80.61% 76.36% 77.56% 36.79% 49.91% 18.50%Table 3: Performance on the 447 English-French test sentences, taking NULL alignments into account, fororthogonal non-negative matrix factorisation (ONMF) using the AIC and BIC criterion for choosing thenumber of cepts.
HLT-03 best is Ralign.EF.1 (Mihalcea and Pedersen, 2003).no NULL alignments with NULL alignmentsMethod PS RS FS AER PS RS FS AERONMF + AIC 70.34% 65.54% 67.85% 32.15% 62.65% 62.10% 62.38% 37.62%ONMF + BIC 55.88% 67.70% 61.23% 38.77% 51.78% 64.07% 57.27% 42.73%HLT-03 best 82.65% 62.44% 71.14% 28.86% 82.65% 54.11% 65.40% 34.60%Table 4: Performance on the 248 Romanian-English test sentences (only sure alignments), for orthogonalnon-negative matrix factorisation (ONMF) using the AIC and BIC criterion for choosing the number ofcepts.
HLT-03 best is XRCE.Nolem (Mihalcea and Pedersen, 2003).filled.
In our experiments we used counts from N-best alignments obtained from IBM model 4.
Thisis mainly used as a proof of concept: other strate-gies, such as weighting the alignments according totheir probability or rank in the N-best list would benatural extensions.
In addition, we are currently in-vestigating the use of translation and distortion ta-bles obtained from IBM model 2 to estimate M ata lower cost.
Ultimately, it would be interestingto obtain association measures mij in a fully non-parametric way, using corpus statistics rather thantranslation models, which themselves perform somekind of alignment.
We have investigated the useof co-occurrence counts or mutual information be-tween words, but this has so far not proved success-ful, mostly because common words, such as func-tion words, tend to dominate these measures.7.3 M-1-0 alignmentsIn our model, cepts ensure that resulting alignmentsare proper.
There is however one situation in whichimproper alignments may be produced: If the MAPassigns f-words but no e-words to a cept (becausee-words have more probable cepts), we may pro-duce ?orphan?
cepts, which are aligned to wordsonly on one side.
One way to deal with this situa-tion is simply to remove cepts which display this be-haviour.
Orphaned words may then be re-assignedto the remaining cepts, either directly or after re-training PLSA on the remaining cepts (this is guar-anteed to converge as there is an obvious solutionfor K = 1).7.4 Independence between sentencesOne natural comment on our factorisation scheme isthat cepts should not be independent between sen-tences.
However it is easy to show that the fac-torisation is optimally done on a sentence per sen-tence basis.
Indeed, what we factorise is the associ-ation measures mij .
For a sentence-aligned corpus,the association measure between source and tar-get words from two different sentence pairs shouldbe exactly 0 because words should not be alignedacross sentences.
Therefore, the larger translationmatrix (calculated on the entire corpus) is blockdiagonal, with non-zero association measures onlyin blocks corresponding to aligned sentence.
Asblocks on the diagonal are mutually orthogonal, theoptimal global orthogonal factorisation is identi-cal to the block-based (ie sentence-based) factori-sation.
Any corpus-induced dependency betweenalignments from different sentences must thereforebe built in the association measure mij , and can-not be handled by the factorisation method.
Notethat this is the case in our experiments, as model 4alignments rely on parameters obtained on the en-tire corpus.8 ConclusionIn this paper, we view word alignment as 1/ estimat-ing the association between source and target words,and 2/ factorising the resulting association measureinto orthogonal, non-negative factors.
For solvingthe latter problem, we propose an algorithm forONMF, which guarantees both proper alignmentsand good coverage.
Experiments carried out on theHansard give encouraging results, in the sense thatwe improve in several ways over state-of-the-art re-sults, despite a clear bias in the reference align-ments.
Further investigations are required to ap-ply this technique on different association measures,and to measure the influence that ONMF may have,eg on a phrase-based Machine Translation system.AcknowledgementsWe acknowledge the Machine Learning group atXRCE for discussions related to the topic of wordalignment.
We would like to thank the three anony-mous reviewers for their comments.ReferencesH.
Akaike.
1974.
A new look at the statisticalmodel identification.
IEEE Tr.
Automatic Con-trol, 19(6):716?723.A.-M. Barbu.
2004.
Simple linguistic methods forimproving a word alignment algorithm.
In Lepoids des mots ?
Proc.
JADT04, pages 88?98.P.
F. Brown, S. A. Della Pietra, V. J. Della Pietra,and R. L. Mercer.
1993.
The mathematics ofstatistical machine translation: Parameter estima-tion.
Computational linguistics, 19:263?312.H.
Dejean, E. Gaussier, C. Goutte, and K. Yamada.2003.
Reducing parameter space for word align-ment.
In HLT-NAACL 2003 Workshop: Buildingand Using Parallel Texts, pages 23?26.A.
P. Dempster, N. M. Laird, and D. B. Ru-bin.
1977.
Maximum likelihood from incom-plete data via the EM algorithm.
J. Royal Sta-tistical Society, Series B, 39(1):1?38.T.
Hofmann.
1999.
Probabilistic latent semanticanalysis.
In Uncertainty in Artificial Intelligence,pages 289?296.P.
Koehn, F. Och, and D. Marcu.
2003.
Statisticalphrase-based translation.
In Proc.
HLT-NAACL2003.D.
D. Lee and H. S. Seung.
1999.
Learning theparts of objects by non-negative matrix factoriza-tion.
Nature, 401:788?791.D.
D. Lee and H. S. Seung.
2001.
Algorithms fornon-negative matrix factorization.
In NIPS*13,pages 556?562.R.
Mihalcea and T. Pedersen.
2003.
An evalua-tion exercise for word alignment.
In HLT-NAACL2003 Workshop: Building and Using ParallelTexts, pages 1?10.F.
Och and H. Ney.
2000.
A comparison of align-ment models for statistical machine translation.In Proc.
COLING?00, pages 1086?1090.F.
Och, C. Tillmann, and H. Ney.
1999.
Improvedalignment models for statistical machine transla-tion.
In Proc.
EMNLP, pages 20?28.K.
Rose, E. Gurewitz, and G. Fox.
1990.
A deter-ministic annealing approach to clustering.
Pat-tern Recognition Letters, 11(11):589?594.G.
Schwartz.
1978.
Estimating the dimension of amodel.
The Annals of Statistics, 6(2):461?464.M.
Simard and P. Langlais.
2003.
Statisticaltranslation alignment with compositionality con-straints.
In HLT-NAACL 2003 Workshop: Build-ing and Using Parallel Texts, pages 19?22.C.
Tillmann and F. Xia.
2003.
A phrase-based uni-gram model for statistical machine translation.
InProc.
HLT-NAACL 2003.D.
Yarowsky, G. Ngai, and R. Wicentowski.
2001.Inducing multilingual text analysis tools via ro-bust projection across aligned corpora.
In Proc.HLT 2001.
