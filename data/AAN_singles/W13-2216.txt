Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 141?147,Sofia, Bulgaria, August 8-9, 2013 c?2013 Association for Computational LinguisticsPhraseFix: Statistical Post-Editing of TectoMTPetra Galu?c?
?kov?, Martin Popel, and Ondr?ej BojarCharles University in Prague, Faculty of Mathematics and PhysicsInstitute of Formal and Applied LinguisticsMalostransk?
n?me?st?
25, Prague, Czech Republic{galuscakova,popel,bojar}@ufal.mff.cuni.czAbstractWe present two English-to-Czech systemsthat took part in the WMT 2013 sharedtask: TECTOMT and PHRASEFIX.
Theformer is a deep-syntactic transfer-basedsystem, the latter is a more-or-less stan-dard statistical post-editing (SPE) appliedon top of TECTOMT.
In a brief survey, weput SPE in context with other system com-bination techniques and evaluate SPE vs.another simple system combination tech-nique: using synthetic parallel data fromTECTOMT to train a statistical MT sys-tem (SMT).
We confirm that PHRASEFIX(SPE) improves the output of TECTOMT,and we use this to analyze errors in TEC-TOMT.
However, we also show that ex-tending data for SMT is more effective.1 IntroductionThis paper describes two submissions to theWMT 2013 shared task:1 TECTOMT ?
a deep-syntactic tree-to-tree system and PHRASEFIX ?statistical post-editing of TECTOMT using Moses(Koehn et al 2007).
We also report on exper-iments with another hybrid method where TEC-TOMT is used to produce additional (so-calledsynthetic) parallel training data for Moses.
Thismethod was used in CU-BOJAR and CU-DEPFIXsubmissions, see Bojar et al(2013).2 Overview of Related WorkThe number of approaches to system combinationis enormous.
We very briefly survey those thatform the basis of our work reported in this paper.2.1 Statistical Post-EditingStatistical post-editing (SPE, see e.g.
Simard et al(2007), Dugast et al(2009)) is a popular method1http://www.statmt.org/wmt13for improving outputs of a rule-based MT sys-tem.
In principle, SPE could be applied to anytype of first-stage system including a statisticalone (Oflazer and El-Kahlout, 2007; B?chara et al2011), but most benefit could be expected frompost-editing rule-based MT because of the com-plementary nature of weaknesses and advantagesof rule-based and statistical approaches.SPE is usually done with an off-the-shelf SMTsystem (e.g.
Moses) which is trained on output ofthe first-stage system aligned with reference trans-lations of the original source text.
The goal of SPEis to produce translations that are better than boththe first-stage system alone and the second-stageSMT trained on the original training data.Most SPE approaches use the reference trans-lations from the original training parallel corpusto train the second-stage system.
In contrast,Simard et al(2007) use human-post-edited first-stage system outputs instead.
Intuitively, the lat-ter approach achieves better results because thehuman-post-edited translations are closer to thefirst-stage output than the original reference trans-lations.
Therefore, SPE learns to perform thechanges which are needed the most.
However, cre-ating human-post-edited translations is laboriousand must be done again for each new (version ofthe) first-stage system in order to preserve its fulladvantage over using the original references.2Rosa et al(2013) have applied SPE onEnglish?Czech SMT outputs.
They have usedthe approach introduced by B?chara et al(2011),but no improvement was achieved.
However, theirrule-based post-editing were found helpful.Our SPE setting (called PHRASEFIX) usesTECTOMT as the first-stage system and Moses asthe second-stage system.
Ideally, TECTOMT pre-2If more reference translations are available, it would bebeneficial to choose such references for training SPE whichare most similar to the first-stage outputs.
However, in ourexperiments only one reference is available.141serves well-formed syntactic sentence structures,and the SPE (Moses) fixes low fluency wordings.2.2 MT Output CombinationAn SPE system is trained to improve the outputof a single first-stage system.
Sometimes, more(first-stage) systems are available, and we wouldlike to combine them.
In MT output selection,for each sentence one system?s translation is se-lected as the final output.
In MT output combi-nation, the final translation of each sentence is acombination of phrases from several systems.
Inboth approaches, the systems are treated as blackboxes, so only their outputs are needed.
In thesimplest setting, all systems are supposed to beequally good/reliable, and the final output is se-lected by voting, based on the number of shared n-grams or language model scores.
The number andthe identity of the systems to be combined there-fore do not need to be known in advance.
More so-phisticated methods learn parameters/weights spe-cific for the individual systems.
These methodsare based e.g.
on confusion networks (Rosti et al2007; Matusov et al 2008) and joint optimizationof word alignment, word order and lexical choice(He and Toutanova, 2009).2.3 Synthetic Data CombinationAnother way to combine several first-stage sys-tems is to employ a standard SMT toolkit, e.g.Moses.
The core of the idea is to use the n first-stage systems to prepare synthetic parallel dataand include them in the training data for the SMT.Corpus Combination (CComb) The easiestmethod is to use these n newly created paral-lel corpora as additional training data, i.e.
trainMoses on a concatenation of the original paral-lel sentences (with human-translated references)and the new parallel sentences (with machine-translated pseudo-references).Phrase Table Combination (PTComb) An-other method is to extract n phrase tables inaddition to the original phrase table and ex-ploit the Moses option of multiple phrase tables(Koehn and Schroeder, 2007).
This means thatgiven the usual five features (forward/backwardphrase/lexical log probability and phrase penalty),we need to tune 5 ?
(n+1) features.
Because suchMERT (Och, 2003) tuning may be unstable forhigher n, several methods were proposed wherethe n+1 phrase tables are merged into a single one(Eisele et al 2008; Chen et al 2009).
Another is-sue of phrase table combination is that the sameoutput can be achieved with phrases from severalphrase tables, leading to spurious ambiguity andthus less diversity in n-best lists of a given size(see Chen et al(2009) for one possible solution).CComb does not suffer from the spurious ambi-guity issue, but it does not allow to tune specialfeatures for the individual first-stage systems.In our experiments, we use both CComb andPTComb approaches.
In PTComb, we use TEC-TOMT as the only first-stage system and Moses asthe second-stage system.
We use the two phrasetables separately (the merging is not needed; 5 ?
2is still a reasonable number of features in MERT).In CComb, we concatenate English?Czech par-allel corpus with English?
?synthetic Czech?
cor-pus translated from English using TECTOMT.
Asingle phrase table is created from the concate-nated corpus.3 TECTOMTTECTOMT is a linguistically-motivated tree-to-tree deep-syntactic translation system with trans-fer based on Maximum Entropy context-sensitivetranslation models (Marec?ek et al 2010) andHidden Tree Markov Models (?abokrtsk?
andPopel, 2009).
It employs some rule-based compo-nents, but the most important tasks in the analysis-transfer-synthesis pipeline are based on statisticsand machine learning.
There are three main rea-sons why it is a suitable candidate for SPE andother hybrid methods.?
TECTOMT has quite different distributionand characteristics of errors compared tostandard SMT (Bojar et al 2011).?
TECTOMT is not tuned for BLEU usingMERT (its development is rather driven by hu-man inspection of the errors although differentsetups are regularly evaluated with BLEU as anadditional guidance).?
TECTOMT uses deep-syntactic dependencylanguage models in the transfer phase, but itdoes not use standard n-gram language mod-els on the surface forms because the current syn-thesis phase supports only 1-best output.The version of TECTOMT submitted to WMT2013 is almost identical to the WMT 2012 version.Only a few rule-based components (e.g.
detectionof surface tense of English verbs) were refined.142Corpus Sents TokensCzech EnglishCzEng 15M 205M 236Mtmt(CzEng) 15M 197M 236MCzech Web Corpus 37M 627M ?WMT News Crawl 25M 445M ?Table 1: Statistics of used data.4 Common Experimental SetupAll our systems (including TECTOMT) weretrained on the CzEng (Bojar et al 2012) par-allel corpus (development and evaluation sub-sets were omitted), see Table 1 for statistics.We translated the English side of CzEng withTECTOMT to obtain ?synthetic Czech?.
Thisway we obtained a new parallel corpus, denotedtmt(CzEng), with English?
synthetic Czech sen-tences.
Analogically, we translated the WMT2013 test set (newstest2013) with TECTOMT andobtained tmt(newstest2013).
Our baseline SMTsystem (Moses) trained on CzEng corpus only wasthen also used for WMT 2013 test set transla-tion, and we obtained smt(newstest2013).
For allMERT tuning, newstest2011 was used.4.1 AlignmentAll our parallel data were aligned with GIZA++(Och and Ney, 2003) and symmetrized withthe ?grow-diag-final-and?
heuristics.
This ap-plies also to the synthetic corpora tmt(CzEng),tmt(newstest2013),3 and smt(newstest2013).For the SPE experiments, we decided to basealignment on (genuine and synthetic Czech) lem-mas, which could be acquired directly from theTECTOMT output.
For the rest of the experiments,we approximated lemmas with just the first fourlowercase characters of each (English and Czech)token.4.2 Language ModelsIn all our experiments, we used three languagemodels on truecased forms: News Crawl as pro-vided by WMT organizers,4 the Czech side ofCzEng and the Articles section of the Czech Web3Another possibility was to adapt TECTOMT to outputsource-to-target word alignment, but GIZA++ was simpler touse also due to different internal tokenization in TECTOMTand our Moses pipeline.4The deep-syntactic LM of TECTOMT was trained onlyon this News Crawl data ?
http://www.statmt.org/wmt13/translation-task.html (sets 2007?2012).BLEU 1-TERTECTOMT 14.71?0.53 35.61?0.60PHRASEFIX 17.73?0.54 35.63?0.65Filtering 14.68?0.50 35.47?0.57Mark Reliable Phr.
17.87?0.55 35.57?0.66Mark Identities 17.87?0.57 35.85?0.68Table 2: Comparison of several strategies of SPE.Best results are in bold.Corpus (Spoustov?
and Spousta, 2012).We used SRILM (Stolcke, 2002) with modifiedKneser-Ney smoothing.
We trained 5-grams onCzEng; on the other two corpora, we trained 7-grams and pruned them if the (training set) per-plexity increased by less than 10?14 relative.
Thedomain of the pruned corpora is similar to the testset domain, therefore we trained 7-grams on thesecorpora.
Adding CzEng corpus can then increasethe results only very slightly ?
training 5-grams onCzEng is therefore sufficient and more efficient.Each of the three LMs got its weight as-signed by MERT.
Across the experiments, CzechWeb Corpus usually gained the largest portion ofweights (40?17% of the total weight assigned tolanguage models), WMT News Crawl was the sec-ond (32?15%), and CzEng was the least useful(15?7%), perhaps due to its wide domain mixture.5 SPE ExperimentsWe trained a base SPE system as described in Sec-tion 2.1 and dubbed it PHRASEFIX.First two rows of Table 2 show that the first-stage TECTOMT system (serving here as the base-line) was significantly improved in terms of BLEU(Papineni et al 2002) by PHRASEFIX (p < 0.001according to the paired bootstrap test (Koehn,2004)), but the difference in TER (Snover etal., 2006) is not significant.5 The preliminaryresults of WMT 2013 manual evaluation showonly a minor improvement: TECTOMT=0.476vs.
PHRASEFIX=0.484 (higher means better, fordetails on the ranking see Callison-Burch et al(2012)).5The BLEU and TER results reported here slightly differfrom the results shown at http://matrix.statmt.org/matrix/systems_list/1720 because of differ-ent tokenization and normalization.
It seems that statmt.orgdisables the --international-tokenizationswitch, so e.g.
the correct Czech quotes (?word?)
are nottokenized, hence the neighboring tokens are never countedas matching the reference (which is tokenized as " word ").143Despite of the improvement, PHRASEFIX?sphrase table (synthetic Czech ?
genuine Czech)still contains many wrong phrase pairs that worsenthe TECTOMT output instead of improving it.They naturally arise in cases where the genuineCzech is a too loose translation (or when theEnglish-Czech sentence pair is simply misalignedin CzEng), and the word alignment between gen-uine and synthetic Czech struggles.Apart from removing such garbage phrase pairs,it would also be beneficial to have some controlover the SPE.
For instance, we would like to gen-erally prefer the original output of TECTOMT ex-cept for clear errors, so only reliable phrase pairsshould be used.
We examine several strategies:Phrase table filtering.
We filter out all phrasepairs with forward probability ?
0.7 and all sin-gleton phrase pairs.
These thresholds were setbased on our early experiments.
Similar filteringwas used by Dugast et al(2009).Marking of reliable phrases.
This strategy issimilar to the previous one, but the low-frequencyphrase pairs are not filtered-out.
Instead, a specialfeature marking these pairs is added.
The subse-quent MERT of the SPE system selects the bestweight for this indicator feature.
The frequencyand probability thresholds for marking a phrasepair are the same as in the previous case.Marking of identities A special feature indicat-ing the equality of the source and target phrase ina phrase pair is added.
In general, if the outputof TECTOMT matched the reference, then suchoutput was probably good and does not need anypost-editing.
These phrase pairs should be perhapsslightly preferred by the SPE.As apparent from Table 2, marking either reli-able phrases or identities is useful in our SPE set-ting in terms of BLEU score.
In terms of TERmeasure, marking the identities slightly improvesPHRASEFIX.
However, none of the improvementsis statistically significant.6 Data Combination ExperimentsWe now describe experiments with phrase tableand corpus combination.
In the training step, thesource-language monolingual corpus that servesas the basis of the synthetic parallel data canbe:?
the source side of the original parallel trainingcorpus (resulting in tmt(CzEng)),?
a huge source-language monolingual corpus forwhich no human translations are available (wehave not finished this experiment yet),?
the source side of the test set (resulting intmt(newstest2013) if translated by TECTOMTor smt(newstest2013) if translated by baselineconfiguration of Moses trained on CzEng), or?
a combination of the above.There is a trade-off in the choice: the sourceside of the test set is obviously most useful forthe given input, but it restricts the applicability (allsystems must be installed or available online in thetesting time) and speed (we must wait for the slow-est system and the combination).So far, in PTComb we tried adding the fullsynthetic CzEng (?CzEng + tmt(CzEng)?
), addingthe test set (?CzEng + tmt(newstest2013)?
and?CzEng + smt(newstest2013)?
), and adding both(?CzEng + tmt(CzEng) + tmt(newstest2013)?).
InCComb, we concatenated CzEng and full syn-thetic CzEng (?CzEng + tmt(CzEng)?
).There are two flavors of PTComb: either thetwo phrase tables are used both at once as alter-native decoding paths (?Alternative?
), where eachsource span is equipped with translation optionsfrom any of the tables, or the synthetic Czechphrase table is used only as a back-off method if asource phrase is not available in the primary table(?Back-off?).
The back-off model was applied tosource phrases of up to 5 tokens.Table 3 summarizes our results with phrase ta-ble and corpus combination.
We see that addingsynthetic data unrelated to the test set does bringonly a small benefit in terms of BLEU in the caseof CComb, and we see a small improvement inTER in two cases.
Adding the (synthetic) transla-tion of the test set helps.
However, adding trans-lated source side of the test set is helpful only ifit is translated by the TECTOMT system.
If ourbaseline system is used for this translation, the re-sults even slightly drop.Somewhat related experiments for pivot lan-guages by Galu?c??kov?
and Bojar (2012) showeda significant gain when the outputs of a rule-basedsystem were added to the training data of Moses.In their case however, the genuine parallel corpuswas much smaller than the synthetic data.
Thebenefit of unrelated synthetic data seems to van-ish with larger parallel data available.144Training Data for Moses Decoding Type BLEU 1-TERbaseline: CzEng ?
18.52?0.57 36.41?0.66tmt(CzEng) ?
15.96?0.53 33.67?0.63CzEng + tmt(CzEng) CComb 18.57?0.57 36.47?0.64CzEng + tmt(CzEng) PTComb Alternative 18.42?0.58 36.47?0.65CzEng + tmt(CzEng) PTComb Back-off 18.38?0.57 36.25?0.65CzEng + tmt(newstest2013) PTComb Alternative 18.68?0.57 37.00?0.65CzEng + smt(newstest2013) PTComb Alternative 18.46?0.54 36.59?0.65CzEng + tmt(CzEng) + tmt(newstest2013) PTComb Alternative 18.85?0.58 37.03?0.66Table 3: Comparison of several strategies used for Synthetic Data Combination (PTComb ?
phrase tablecombination and CComb ?
corpus combination).BLEU Judged betterSPE 17.73?0.54 123PTComb 18.68?0.57 152Table 4: Automatic (BLEU) and manual (numberof sentences judged better than the other system)evaluation of SPE vs. PTComb.7 Discussion7.1 Comparison of SPE and PTCombAssuming that our first-stage system, TECTOMT,guarantees the grammaticality of the output (sadlyoften not quite true), we see SPE and PTCombas two complementary methods that bring in thegoods of SMT but risk breaking the grammati-cality.
Intuitively, SPE feels less risky, becauseone would hope that the post-edits affect short se-quences of words and not e.g.
the clause structure.With PTComb, one relies purely on the phrase-based model and its well-known limitations withrespect to grammatical constraints.Table 4 compares the two approaches empir-ically.
For SPE, we use the default PHRASE-FIX; for PTComb, we use the option ?CzEng +tmt(newstest2013)?.
The BLEU scores are re-peated.We ran a small manual evaluation where threeannotators judged which of the two outputs wasbetter.
The identity of the systems was hidden,but the annotators had access to both the sourceand the reference translation.
Overall, we col-lected 333 judgments over 120 source sentences.Of the 333 judgments, 17 marked the two systemsas equally correct, and 44 marked the systems asincomparably wrong.
Across the remaining 275non-tying comparisons, PTComb won ?
152 vs.123.We attribute the better performance of PTCombto the fact that, unlike SPE, it has direct access tothe source text.
Also, the risk of flawed sentencestructure in PTComb is probably not too bad, butthis can very much depend on the language pair.English?Czech translation does not need muchreordering in general.Based on the analysis of the better marked re-sults of the PTComb system, the biggest problemis the wrong selection of the word and word form,especially for verbs.
PTComb also outperformsSPE in processing of frequent phrases and sub-ordinate clauses.
This problem could be solvedby enhancing fluency in SPE or by incorporat-ing more training data.
Another possibility wouldbe to modify TECTOMT system to produce morethan one-best translation as the correct word orword form may be preserved in sequel transla-tions.7.2 Error Analysis of TECTOMTWhile SPE seems to perform worse, it has aunique advantage: it can be used as a feedbackfor improving the first stage system.
We can eitherinspect the filtered SPE phrase table or differencesin translated sentences.After submitting our WMT 2013 systems, thiscomparison allowed us to spot a systematic errorin TECTOMT tagging of latin-origin words:source pancreasTECTOMT slinivek [plural]PHRASEFIX slinivky [singular] br?i?n?The part-of-speech tagger used in TECTOMT in-correctly detects pancreas as plural, and the wrongmorphological number is used in the synthesis.PHRASEFIX correctly learns that the plural formslinivek should be changed to singular slinivky,which has also a higher language model score.Moreover, PHRASEFIX also learns that the trans-145lation of pancreas should be two words (br?i?n?means abdominal).
TECTOMT currently uses asimplifying assumption of 1-to-1 correspondencebetween content words, so it is not able to producethe correct translation in this case.Another example shows where PHRASEFIXrecovered from a lexical gap in TECTOMT:source people who are strong-willedTECTOMT lid?
, kter??
jsou siln?
willedPHRASEFIX lid?
, kter??
maj?
silnou vu?liTECTOMT?s primary translation model considersstrong-willed an OOV word, so a back-off dictio-nary specialized for hyphen compounds is used.However, this dictionary is not able to translatewilled.
PHRASEFIX corrects this and also theverb jsou = are (the correct Czech translation ismaj?
silnou vu?li = have a strong will).Finally, PHRASEFIX can also break things:source You won?t be happy hereTECTOMT Nebudete ?t?astn?
tadyPHRASEFIX Vy tady ?t?astn?
[you here happy]Here, PHRASEFIX damaged the translation byomitting the negative verb nebudete = you won?t.8 ConclusionStatistical post-editing (SPE) and phrase tablecombination (PTComb) can be seen as two com-plementary approaches to exploiting the mutualbenefits of our deep-transfer system TECTOMTand SMT.We have shown that SPE improves the results ofTECTOMT.
Several variations of SPE have beenexamined, and we have further improved SPE re-sults by marking identical and reliable phrases us-ing a special feature.
However, SMT still out-performs SPE according to BLEU and TER mea-sures.
Finally, employing PTComb, we have im-proved the baseline SMT system by utilizing ad-ditional data translated by the TECTOMT system.A small manual evaluation suggests that PTCombis on average better than SPE, though in about onethird of sentences SPE was judged better.
In ourfuture experiments, we plan to improve SPE byapplying techniques suited for monolingual align-ment, e.g.
feature-based aligner considering wordsimilarity (Rosa et al 2012) or extending the par-allel data with vocabulary identities to promotealignment of the same word form (Dugast et al2009).
Marking and filtering methods for SPE alsodeserve a deeper study.
As for PTComb, we planto combine several sources of synthetic data (in-cluding a huge source-language monolingual cor-pus).AcknowledgementsThis research is supported by the grantsGAUK 9209/2013, FP7-ICT-2011-7-288487(MosesCore) of the European Union and SVVproject number 267 314.
We thank the twoanonymous reviewers for their comments.ReferencesHanna B?chara, Yanjun Ma, and Josef van Genabith.2011.
Statistical post-editing for a statistical MTsystem.
MT Summit XIII, pages 308?315.Ondr?ej Bojar, Milo?
Ercegovc?evic?, Martin Popel, andOmar Zaidan.
2011.
A Grain of Salt for the WMTManual Evaluation.
In Proc.
of WMT, pages 1?11,Edinburgh, Scotland.
ACL.Ondr?ej Bojar, Zdene?k ?abokrtsk?, Ondr?ej Du?ek, Pe-tra Galu?c?
?kov?, Martin Majli?, David Marec?ek, Jir??Mar?
?k, Michal Nov?k, Martin Popel, and Ale?
Tam-chyna.
2012.
The Joy of Parallelism with CzEng1.0.
In Proc.
of LREC, pages 3921?3928, Istanbul,Turkey.
ELRA.Ondr?ej Bojar, Rudolf Rosa, and Ale?
Tamchyna.
2013.Chimera ?
Three Heads for English-to-Czech Trans-lation.
In Proc.
of WMT.Chris Callison-Burch, Philipp Koehn, Christof Monz,Matt Post, Radu Soricut, and Lucia Specia.
2012.Findings of the 2012 Workshop on Statistical Ma-chine Translation.
In Proc.
of WMT, Montreal,Canada.
ACL.Yu Chen, Michael Jellinghaus, Andreas Eisele,Yi Zhang, Sabine Hunsicker, Silke Theison, Chris-tian Federmann, and Hans Uszkoreit.
2009.
Com-bining Multi-Engine Translations with Moses.
InProc.
of WMT, pages 42?46, Athens, Greece.
ACL.Lo?c Dugast, Jean Senellart, and Philipp Koehn.2009.
Statistical Post Editing and Dictionary Ex-traction: Systran/Edinburgh Submissions for ACL-WMT2009.
In Proc.
of WMT, pages 110?114,Athens, Greece.
ACL.Andreas Eisele, Christian Federmann, Herv?
Saint-Amand, Michael Jellinghaus, Teresa Herrmann, andYu Chen.
2008.
Using Moses to Integrate Multi-ple Rule-Based Machine Translation Engines into aHybrid System.
In Proc.
of WMT, pages 179?182,Columbus, Ohio.
ACL.Petra Galu?c??kov?
and Ondr?ej Bojar.
2012.
ImprovingSMT by Using Parallel Data of a Closely RelatedLanguage.
In Proc.
of HLT, pages 58?65, Amster-dam, Netherlands.
IOS Press.146Xiaodong He and Kristina Toutanova.
2009.
Joint Op-timization for Machine Translation System Combi-nation.
In Proc.
of EMNLP, pages 1202?1211, Sin-gapore.
ACL.Philipp Koehn and Josh Schroeder.
2007.
Experimentsin Domain Adaptation for Statistical Machine Trans-lation.
In Proc.
of WMT, pages 224?227, Prague,Czech Republic.
ACL.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondr?ej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: OpenSource Toolkit for Statistical Machine Translation.In Proc.
of ACL, pages 177?180, Prague, Czech Re-public.
ACL.Philipp Koehn.
2004.
Statistical Significance Testsfor Machine Translation Evaluation.
In Proc.
ofEMNLP, Barcelona, Spain.David Marec?ek, Martin Popel, and Zdene?k ?abokrt-sk?.
2010.
Maximum entropy translation modelin dependency-based MT framework.
In Proc.
ofMATR, pages 201?206.
ACL.Evgeny Matusov, Gregor Leusch, Rafael E. Banchs,Nicola Bertoldi, Daniel Dechelotte, Marcello Fed-erico, Muntsin Kolss, Young-Suk Lee, Jose B.Marino, Matthias Paulik, Salim Roukos, HolgerSchwenk, and Hermann Ney.
2008.
System Combi-nation for Machine Translation of Spoken and Writ-ten Language.
IEEE, 16(7):1222?1237.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Comput.
Linguist., 29(1):19?51.Franz Josef Och.
2003.
Minimum Error Rate Trainingin Statistical Machine Translation.
In Proc.
of ACL,Sapporo, Japan.Kemal Oflazer and Ilknur Durgar El-Kahlout.
2007.Exploring different representational units inEnglish-to-Turkish statistical machine translation.In Proc.
of WMT, pages 25?32.
ACL.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a method for automaticevaluation of machine translation.
In Proc.
of ACL,pages 311?318, Stroudsburg, PA, USA.
ACL.Rudolf Rosa, Ondr?ej Du?ek, David Marec?ek, and Mar-tin Popel.
2012.
Using Parallel Features in Parsingof Machine-Translated Sentences for Correction ofGrammatical Errors.
In Proc.
of SSST, pages 39?48,Jeju, Republic of Korea.
ACL.Rudolf Rosa, David Marec?ek, and Ale?
Tamchyna.2013.
Deepfix: Statistical Post-editing of StatisticalMachine Translation Using Deep Syntactic Analy-sis.
Sofia, Bulgaria.
ACL.Antti-Veikko Rosti, Necip Fazil Ayan, Bing Xiang,Spyros Matsoukas, Richard Schwartz, and BonnieDorr.
2007.
Combining Outputs from MultipleMachine Translation Systems.
In Proc.
of NAACL,pages 228?235, Rochester, New York.
ACL.Michel Simard, Cyril Goutte, and Pierre Isabelle.2007.
Statistical Phrase-Based Post-Editing.
InProc.
of NAACL, pages 508?515, Rochester, NewYork.
ACL.Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-nea Micciulla, and John Makhoul.
2006.
A study oftranslation edit rate with targeted human annotation.In Proc.
of Association for Machine Translation inthe Americas, pages 223?231.Johanka Spoustov?
and Miroslav Spousta.
2012.
AHigh-Quality Web Corpus of Czech.
In Proc.
ofLREC, Istanbul, Turkey.
ELRA.Andreas Stolcke.
2002.
SRILM ?
an extensible lan-guage modeling toolkit.
In Proc.
of ICSLP, pages257?286.Zdene?k ?abokrtsk?
and Martin Popel.
2009.
HiddenMarkov Tree Model in Dependency-based MachineTranslation.
In Proc.
of IJCNLP, pages 145?148,Suntec, Singapore.147
