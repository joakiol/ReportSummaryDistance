Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 236?246,Austin, Texas, November 1-5, 2016. c?2016 Association for Computational LinguisticsLearning Sentence Embeddings with Auxiliary Tasksfor Cross-Domain Sentiment ClassificationJianfei YuSchool of Information SystemsSingapore Management Universityjfyu.2014@phdis.smu.edu.sgJing JiangSchool of Information SystemsSingapore Management Universityjingjiang@smu.edu.sgAbstractIn this paper, we study cross-domain senti-ment classification with neural network archi-tectures.
We borrow the idea from StructuralCorrespondence Learning and use two auxil-iary tasks to help induce a sentence embeddingthat supposedly works well across domains forsentiment classification.
We also propose tojointly learn this sentence embedding togetherwith the sentiment classifier itself.
Experi-ment results demonstrate that our proposedjoint model outperforms several state-of-the-art methods on five benchmark datasets.1 IntroductionWith the growing need of correctly identifying thesentiments expressed in subjective texts such asproduct reviews, sentiment classification has re-ceived continuous attention in the NLP communityfor over a decade (Pang et al, 2002; Pang and Lee,2004; Hu and Liu, 2004; Choi and Cardie, 2008;Nakagawa et al, 2010).
One of the big challengesof sentiment classification is how to adapt a senti-ment classifier trained on one domain to a differentnew domain.
This is because sentiments are oftenexpressed with domain-specific words and expres-sions.
For example, in the Movie domain, wordssuch as moving and engaging are usually positive,but they may not be relevant in the Restaurant do-main.
Since labeled data is expensive to obtain, itwould be very useful if we could adapt a modeltrained on a source domain to a target domain.Much work has been done in sentiment analysisto address this domain adaptation problem (Blitzeret al, 2007; Pan et al, 2010; Bollegala et al,2011; Ponomareva and Thelwall, 2012; Bollegalaet al, 2016).
Among them, an appealing methodis the Structural Correspondence Learning (SCL)method (Blitzer et al, 2007), which uses pivot fea-ture prediction tasks to induce a projected featurespace that works well for both the source and the tar-get domains.
The intuition behind is that these pivotprediction tasks are highly correlated with the orig-inal task.
For sentiment classification, Blitzer et al(2007) first chose pivot words which have high mu-tual information with the sentiment labels, and thenset up the pivot prediction tasks to be the predictionsof each of these pivot words using the other words.However, the original SCL method is based ontraditional discrete feature representations and lin-ear classifiers.
In recent years, with the advancesof deep learning in NLP, multi-layer neural net-work models such as RNNs and CNNs have beenwidely used in sentiment classification and achievedgood performance (Socher et al, 2013; Dong etal., 2014a; Dong et al, 2014b; Kim, 2014; Tanget al, 2015).
In these models, dense, real-valuedfeature vectors and non-linear classification func-tions are used.
By using real-valued word embed-dings pre-trained from a large corpus, these mod-els can take advantage of the embedding space thatpresumably better captures the syntactic and se-mantic similarities between words.
And by usingnon-linear functions through multi-layer neural net-works, these models represent a more expressive hy-pothesis space.
Therefore, it would be interesting toexplore how these neural network models could beextended for cross-domain sentiment classification.236There has been some recent studies on neuralnetwork-based domain adaptation (Glorot et al,2011; Chen et al, 2012; Yang and Eisenstein, 2014).They use Stacked Denoising Auto-encoders (SDA)to induce a hidden representation that presumablyworks well across domains.
However, SDA is fullyunsupervised and does not consider the end task weneed to solve, i.e., the sentiment classification task.In contrast, the idea behind SCL is to use carefully-chosen auxiliary tasks that correlate with the endtask to induce a hidden representation.
Another lineof work aims to learn a low dimensional represen-tation for each feature in both domains based onpredicting its neighboring features (Yang and Eisen-stein, 2015; Bollegala et al, 2015).
Different fromthese methods, we aim to directly learn sentence em-beddings that work well across domains.In this paper, we aim to extend the main idea be-hind SCL to neural network-based solutions to sen-timent classification to address the domain adapta-tion problem.
Specifically, we borrow the idea ofusing pivot prediction tasks from SCL.
But insteadof learning thousands of pivot predictors and per-forming singular value decomposition on the learnedweights, which all relies on linear transformations,we introduce only two auxiliary binary predictiontasks and directly learn a non-linear transformationthat maps an input to a dense embedding vector.Moreover, different from SCL and the auto-encoder-based methods, in which the hidden feature repre-sentation and the final classifier are learned sequen-tially, we propose to jointly learn the hidden featurerepresentation together with the sentiment classifi-cation model itself, and we show that joint learningworks better than sequential learning.We conduct experiments on a number of differentsource and target domains for sentence-level sen-timent classification.
We show that our proposedmethod is able to achieve the best performance com-pared with a number of baselines for most of thesedomain pairs.2 Related WorkDomain Adaptation: Domain adaptation is a gen-eral problem in NLP and has been well studiedin recent years (Blitzer et al, 2006; Daume?
III,2007; Jiang and Zhai, 2007; Dredze and Crammer,2008; Titov, 2011; Yu and Jiang, 2015).
For sen-timent classification, most existing domain adap-tation methods are based on traditional discretefeature representations and linear classifiers.
Oneline of work focuses on inducing a general low-dimensional cross-domain representation based onthe co-occurrences of domain-specific and domain-independent features (Blitzer et al, 2007; Pan et al,2010; Pan et al, 2011).
Another line of work tries toderive domain-specific sentiment words (Bollegalaet al, 2011; Li et al, 2012).
Our proposed methodis similar to the first line of work in that we also aimto learn a general, cross-domain representation (sen-tence embeddings in our case).Neural Networks for Sentiment Classification:A recent trend of deep learning enhances variouskinds of neural network models for sentiment clas-sification, including Convolutional Neural Networks(CNNs), Recursive Neural Network (ReNNs) andRecurrent Neural Network (RNNs), which havebeen shown to achieve competitive results acrossdifferent benchmarks (Socher et al, 2013; Dong etal., 2014a; Dong et al, 2014b; Kim, 2014; Tang etal., 2015).
Inspired by their success in standard in-domain settings, it is intuitive for us to apply theseneural network models to domain adaptation set-tings.Denoising Auto-encoders for Domain Adapta-tion: Denoising Auto-encoders have been exten-sively studied in cross-domain sentiment classifica-tion, since the representations learned through multi-layer neural networks are robust against noise duringdomain adaptation.
The initial application of thisidea is to directly employ stacked denoising auto-encoders (SDA) by reconstructing the original fea-tures from data that are corrupted with noise (Glo-rot et al, 2011), and Chen et al (2012) proposedto analytically marginalize out the corruption duringSDA training.
Later Yang and Eisenstein (2014) fur-ther showed that their proposed structured dropoutnoise strategy can dramatically improve the effi-ciency without sacrificing the accuracy.
However,these methods are still based on traditional discreterepresentation and do not exploit the idea of usingauxiliary tasks that are related to the end task.
Incontrast, the sentence embeddings learned from ourmethod are derived from real-valued feature vectorsand rely on related auxiliary tasks.2373 MethodIn this section we present our sentence embedding-based domain adaptation method for sentiment clas-sification.
We first introduce the necessary notationand an overview of our method.
we then delve intothe details of the method.3.1 Notation and Method OverviewWe assume that each input is a piece of text consist-ing of a sequence of words.
For the rest of this paper,we assume each input is a sentence, although ourmethod is general enough for longer pieces of text.Let x = (x1, x2, .
.
.)
denote a sentence where eachxi ?
{1, 2, .
.
.
, V } is a word in the vocabulary andV is the vocabulary size.
Let the sentiment label ofxbe y ?
{+,?
}where + denotes a positive sentimentand ?
a negative sentiment.
We further assume thatwe are given a set of labeled training sentences froma source domain, denoted by Ds = {(xsi , ysi )}Nsi=1.Also, we have a set of unlabeled sentences from atarget domain, denoted by Dt = {xti}Nti=1.
Our goalis to learn a good sentiment classifier from both Dsand Dt such that the classifier works well on the tar-get domain.A baseline solution without considering any do-main difference is to simply train a classifier usingDs, and with the recent advances in neural network-based methods to sentence classification, we con-sider a baseline that uses a multi-layer neural net-work such as a CNN or an RNN to perform the clas-sification task.
To simplify the discussion and focuson the domain adaptation ideas we propose, we willleave the details of the neural network model we usein Section 3.5.
For now, we assume that a multi-layer neural network is used to transform each inputx into a sentence embedding vector z.
Let us usef?
to denote the transformation function parameter-ized by ?, that is, z = f?(x).
Next, we assumethat a linear classifier such as a softmax classifier islearned to map z to a sentiment label y.We introduce two auxiliary tasks which presum-ably are highly correlated with the sentiment classi-fication task itself.
Labels for these auxiliary taskscan be automatically derived from unlabeled data inboth the source and the target domains.
With thehelp of the two auxiliary tasks, we learn a non-lineartransformation function f??
from unlabeled data anduse it to derive a sentence embedding vector z?
fromsentence x, which supposedly works better acrossdomains.
Finally we use the source domain?s train-ing data to learn a linear classifier on the represen-tation z ?
z?, where ?
is the operator that concate-nates two vectors.
Figure 1 gives the outline of ourmethod.3.2 Auxiliary TasksOur two auxiliary tasks are about whether an in-put sentence contains a positive or negative domain-independent sentiment word.
The intuition is thefollowing.
If we have a list of domain-independentpositive sentiment words, then an input sentence thatcontains one of these words, regardless of the do-main the sentence is from, is more likely to containan overall positive sentiment.
For example, a sen-tence containing the word good is likely to be over-all positive.
Moreover, the rest of the sentence ex-cluding the word good may contain domain-specificwords or expressions that also convey a positive sen-timent.
For example, in the sentence ?The laptopis good and goes really fast,?
we can see that theword fast is a domain-specific sentiment word, andits sentiment polarity correlates with that of the wordgood, which is domain-independent.
Therefore, wecan hide the domain-independent positive words ina sentence and try to use the other words in the sen-tence to predict whether the original sentence con-tains a domain-independent positive word.
There aretwo things to note about this auxiliary task: (1) Thelabel of the task can be automatically derived pro-vided that we have the domain-independent positiveword list.
(2) The task is closely related to the orig-inal task of sentence-level sentiment classification.Similarly, we can introduce a task to predict the ex-istence of a domain-independent negative sentimentword in a sentence.Formally, let us assume that we have two domain-independent sentiment word lists, one for the posi-tive sentiment and the other for the negative senti-ment.
Details of how these lists are obtained willbe given in Section 3.5.
Borrowing the term fromSCL, we refer to these sentiment words as pivotwords.
For each sentence x, we replace all the oc-currences of these pivot words with a special tokenUNK.
Let g(?)
be a function that denotes this pro-cedure, that is, g(x) is the resulting sentence with238Sentiment ClassificationSentenceEmbeddingWordEmbedding31The  laptop is     good and    goes  really  fast The  laptop is     UNK   and    goes  really  fastSharedLookupTableAuxiliary TasksOriginal Sentence New Sentence without PivotsCNN/RNN CNN/RNNFigure 1: The Outline of our Proposed Method.UNK tokens.
We then introduce two binary labelsfor g(x).
The first label u indicates whether theoriginal sentence x contains at least one domain-independent positive sentiment word, and the sec-ond label v indicates whether x contains at least onedomain-independent negative sentiment word.
Fig-ure 1 shows an example sentence x, its modified ver-sion g(x) and the labels u and v for x.
We furtheruse Da = {(xi, ui, vi)}Nai=1 to denote a set of train-ing sentences for the auxiliary tasks.
Note that thesentences in Da can be from the sentences in Dsand Dt, but they can also be from other unlabeledsentences.3.3 Sentence Embeddings for DomainAdaptationWith the two auxiliary tasks, we can learn a neuralnetwork model in a standard way to produce sen-tence embeddings that work well for the auxiliarytasks.
Specifically, we still use ??
to denote the pa-rameters of the neural network that produces the sen-tence embeddings (and f??
the corresponding trans-formation function), and we use ?+ and ??
to de-note the parameters of two softmax classifiers forthe two auxiliary tasks, respectively.
Using cross-entropy loss, we can learn ??
by minimizing the fol-lowing loss function:J(??,?+,??
)= ??
(x,u,v)?Da(log p(u|f??
(g(x));?+)+ log p(v|f??(g(x));??
)),where p(y|z;?)
is the probability of label y givenvector z and parameter ?
under softmax regression.With the learned ?
?, we can derive a sentence em-bedding z?
from any sentence.
Although we couldsimply use this embedding z?
for sentiment classi-fication through another softmax classifier, this maynot be ideal because z?
is transformed from g(x),which has the domain-independent sentiment wordsremoved.
Similar to SCL and some other previouswork, we concatenate the embedding vector z?
withthe standard embedding vector z for the final classi-fication.3.4 Joint LearningAlthough we can learn ??
using Da as a first step,here we also explore a joint learning setting.
In thissetting, ??
is learned together with the neural net-work model used for the end task, i.e., sentimentclassification.
This way, the learning of ??
dependsnot only on Da but also on Ds, i.e., the sentiment-labeled training data from the source domain.Specifically, we use ?
to denote the parametersfor a neural network that takes the original sentencex and transforms it to a sentence embedding (and f?the corresponding transformation function).
We use?
to denote the parameters of a softmax classifierthat operates on the concatenated sentence embed-ding z ?
z?
for sentiment classification.
With jointlearning, we try to minimize the following loss func-239tion:J(?,??,?,?+,??
)= ??
(x,y)?Ds(log p(y|f?(x)?
f??(g(x));?))??
(x,u,v)?Da(log p(u|f??
(g(x));?+)+ log p(v|f??(g(x));??
)).We can see that this loss function contains two parts.The first part is the cross-entropy loss based on thetrue sentiment labels of the sentences in Ds.
Thesecond part is the loss based on the auxiliary tasksand the data Da, which are derived from unlabeledsentences.Finally, to make a prediction on a sentence, weuse the learned ?
and ??
to derive a sentence embed-ding f?
(x) ?
f??
(g(x)), and then use the softmaxclassifier parameterized by the learned ?
to make thefinal prediction.3.5 Implementation DetailsIn this section we explain some of the model details.Pivot Word SelectionRecall that the two auxiliary tasks depend on twodomain-independent sentiment word lists, i.e., pivotword lists.
Different from Blitzer et al (2007), weemploy weighted log-likelihood ratio (WLLR) to se-lect the most positive and negative words in both do-mains as pivots.
The reason is that in our prelimi-nary experiments we observe that mutual informa-tion (used by Blitzer et al (2007)) is biased towardslow frequency words.
Some high frequency wordsincluding good and great are scored low.
In com-parison, WLLR does not have this issue.
The sameobservation was also reported previously by Li et al(2009).More specifically, we first tokenize the sentencesin Ds and Dt and perform part-of-speech taggingusing the NLTK toolkit.
Next, we extract only ad-jectives, adverbs and verbs with a frequency of atleast 3 in the source domain and at least 3 in the tar-get domain.
We also remove negation words such asnot and stop words using a stop word list.
We thenmeasure each remaining candidate word?s relevanceto the positive and the negative classes based on Dsby computing the following scores:r(w, y) = p?
(w|y) log p?(w|y)p?(w|y?)
,where w is a word, y ?
{+,?}
is a sentiment label,y?
is the opposite label of y, and p?
(w|y) is the empir-ical probability of observing w in sentences labeledwith y.
We can then rank the candidate words in de-creasing order of r(w,+) and r(w,?).
Finally, weselect the top 25% from each ranked list as the finallists of pivot words for the positive and the nega-tive sentiments.
Some manual inspection shows thatmost of these words are indeed domain-independentsentiment words.Neural Network ModelOur framework is general and potentially we canuse any neural network model to transform an in-put sentence to a sentence embedding vector.
In thispaper, we adopt a CNN-based approach because ithas been shown to work well for sentiment classi-fication.
Specifically, each word (including the to-ken UNK) is represented by a word embedding vec-tor.
Let W ?
Rd?V denote the lookup table forwords, where each column is a d-dimensional em-bedding vector for a word type.
Two separate CNNsare used to process x and g(x), and their mecha-nisms are the same.
For a word xi in each CNN, theembedding vectors inside a window of size n cen-tered at i are concatenated into a new vector, whichwe refer to as ei ?
Rnd.
A convolution operationis then performed by applying a filter F ?
Rh?ndon ei to produce a hidden vector hi = m(Fei + b),where b ?
Rh is a bias vector and m is an element-wise non-linear transformation function.
Note thatwe pad the original sequence in front and at the backto ensure that at each position i we have n vectorsto be combined into hi.
After the convolution op-eration is applied to the whole sequence, we obtainH = [h1,h2, .
.
.
], and we apply a max-over-timepooling operator to take the maximum value of eachrow of H to obtain an overall hidden vector, i.e., zfor x and z?
for g(x).It is worth noting that the two neural networkscorresponding to f?
and f??
share the same wordembedding lookup table.
This lookup table is ini-tialized with word embeddings from word2vec1 and1https://code.google.com/p/word2vec/240is updated during our learning process.
Note that thetoken UNK is initialized as a zero vector and neverupdated.3.6 Differences from SCLAlthough our method is inspired by SCL, there area number of major differences: (1) Our method isbased on neural network models with continuous,dense feature representations and non-linear trans-formation functions.
SCL is based on discrete,sparse feature vectors and linear transformations.
(2) Although our pivot word selection is similar tothat of SCL, in the end we only use two auxiliarytasks while SCL uses much more pivot predictiontasks.
(3) We can directly learn the transformationfunction f ??
that produces the hidden representation,while SCL relies on SVD to learn the projectionfunction.
(4) We perform joint learning of the auxil-iary tasks and the end task, i.e., sentiment classifica-tion, while SCL performs the learning in a sequentialmanner.4 Experiments4.1 Data Sets and Experiment SettingsData Set # Sentences # WordsMovie1(MV1) 10662 18765Movie2(MV2) 9613 16186Camera(CR) 3770 5340Laptop(LT) 1907 2837Restaurant(RT) 1572 2930Table 1: Statistics of our data sets.To evaluate our proposed method, we conductexperiments using five benchmark data sets.
Thedata sets are summarized in Table 1.
Movie12 andMovie23 are movie reviews labeled by Pang and Lee(2005) and Socher et al (2013), respectively.
Cam-era4 are reviews of digital products such as MP3players and cameras (Hu and Liu, 2004).
Laptop andRestaurant5 are laptop and restaurant reviews taken2https://www.cs.cornell.edu/people/pabo/movie-review-data/3http://nlp.stanford.edu/sentiment/4http://www.cs.uic.edu/?liub/FBS/sentiment-analysis.html5Note that the original data set is for aspect-level sentimentanalysis.
We remove sentences with opposite polarities towardsdifferent aspects, and use the consistent polarity as the sentence-level sentiment of each remaining sentence.from SemEval 2015 Task 12.We consider 18 pairs of data sets where the twodata sets come from different domains.6 For neuralnetwork-based methods, we randomly pick 200 sen-tences from the target domain as the development setfor parameter tuning, and the rest of the data fromthe target domain as the test data.4.2 Baselines and HyperparametersWe consider the following baselines:Naive is a non-domain-adaptive baseline based onbag-of-word representations.SCL is our implementation of the Structural Corre-spondence Learning method.
We set the number ofinduced features K to 100 and rescale factor ?
= 5,and we use 1000 pivot words based on our prelimi-nary experiments.mDA is our implementation of marginalized De-noising Auto-encoders (Chen et al, 2012), oneof the state-of-the-art domain adaptation methods,which learns a shared hidden representation by re-constructing pivot features from corrupted inputs.Following Yang and Eisenstein (2014), we employthe efficient and effective structured dropout noisestrategy without any parameter.
The top 500 fea-tures are chosen as pivots based on our preliminaryexperiments.NaiveNN is a non-domain-adaptive baseline basedon CNN, as described in Section 3.5.Aux-NN is a simple combination of our auxiliarytasks with NaiveNN, which treats the derived la-bel of two auxiliary tasks as two features and thenappends them to the hidden representation learnedfrom CNN, followed by a softmax classifier.SCL-NN is a naive combination of SCL withNaiveNN, which appends the induced representationfrom SCL to the hidden representation learned fromCNN, followed by a softmax classifier.mDA-NN is similar to SCL-NN but uses the hiddenrepresentation derived from mDA.Sequential is our proposed method without jointlearning, which first learns ??
based on Da and thenlearns ?
and ?
based on Ds with fixed ?
?.Joint is our proposed joint learning method, that is,we jointly learn ?
and ?
?.6Because Movie1 and Movie2 come from the same domain,we do not take this pair.241Task MethodSource Target Naive Naive++ SCL++ mDA++ NaiveNN Aux-NN SCL-NN mDA-NN Sequential JointMV1 LT 0.656 0.739 0.742 0.742 0.773 0.779 0.776 0.780 0.774 0.804?MV1 RT 0.625 0.742 0.750 0.761 0.802 0.794 0.817 0.819 0.814 0.825?MV1 CR 0.609 0.684 0.688 0.688 0.721 0.717 0.734 0.730 0.717 0.747?MV2 LT 0.699 0.760 0.765 0.772 0.805 0.811 0.800 0.811 0.808 0.827?MV2 RT 0.696 0.761 0.768 0.778 0.813 0.819 0.824 0.825 0.833 0.840?MV2 CR 0.644 0.697 0.705 0.706 0.738 0.732 0.736 0.756 0.745 0.768?CR LT 0.780 0.791 0.802 0.806 0.848 0.848 0.846 0.850 0.856 0.858?CR RT 0.746 0.784 0.782 0.789 0.827 0.835 0.841 0.839 0.835 0.844?CR MV1 0.593 0.597 0.612 0.612 0.685 0.689 0.689 0.692 0.687 0.696?CR MV2 0.609 0.629 0.644 0.640 0.735 0.726 0.734 0.731 0.735 0.736LT RT 0.736 0.781 0.800 0.810 0.819 0.820 0.823 0.852 0.841 0.840LT MV1 0.574 0.601 0.612 0.630 0.711 0.703 0.702 0.709 0.705 0.707LT MV2 0.588 0.632 0.645 0.663 0.742 0.745 0.739 0.747 0.746 0.747LT CR 0.736 0.762 0.768 0.780 0.791 0.796 0.803 0.819 0.803 0.817RT LT 0.732 0.777 0.777 0.799 0.817 0.822 0.831 0.826 0.828 0.834?RT MV1 0.580 0.604 0.618 0.643 0.721 0.726 0.724 0.734 0.722 0.724RT MV2 0.605 0.630 0.633 0.664 0.761 0.762 0.756 0.772 0.757 0.765RT CR 0.689 0.708 0.704 0.732 0.764 0.772 0.759 0.774 0.772 0.779?Average 0.661 0.704 0.712 0.723 0.770 0.772 0.774 0.781 0.777 0.787Table 2: Comparison of classification accuracies of different methods.
?
indicates that our joint method is significantly better thanNaiveNN, Aux-NN, SCL-NN and mDA-NN with p < 0.05 based on McNemar?s paired significance test.For Naive, SCL and mDA, we use LibLinear7 totrain linear classifiers and use its default hyperpa-rameters.
In all the tasks, we use unigrams and bi-grams with a frequency of at least 4 as features forclassification.
For the word embeddings, we set thedimension d to 300.
For CNN, we set the windowsize to 3.
Also, the size of the hidden representa-tions z and z?
is set to 100.
Following Kim (2014),the non-linear activation function in CNN is Relu,the mini-batch size is 50, the dropout rate ?
equals0.5, and the hyperparameter for the l2 norms is setto be 3.
For Naive, SCL and mDA, we do not usethe 200 sentences in the development set for tuningparameters.
Hence, for fair comparison, we also in-clude settings where the 200 sentences are added tothe training set.
We denote these settings by ++.4.3 ResultsIn Table 2, we report the results of all the methods.It is easy to see that the performance of Naive isvery limited, and the incorporation of 200 reviewsin the development set (Naive++) brings in 4.3% ofimprovement on average.
SCL++ and mDA++ canfurther improve the average accuracy respectively7http://www.csie.ntu.edu.tw/cjlin/liblinear/by 0.8% and 1.9%, which verifies the usefulness ofthese two domain adaptation methods.
However, wecan easily see that the performance of these domainadaptation methods based on discrete, bag-of-wordrepresentations is even much lower than the non-domain-adaptive method on continuous representa-tions (NaiveNN).
This confirms that it is useful todevelop domain adaptation methods based on em-bedding vectors and neural network models.Moreover, we can find that the performance ofsimply appending two features from auxiliary tasksto NaiveNN (i.e., Aux-NN) is quite close to thatof NaiveNN on most data set pairs, which showsthat it is not ideal for domain adaptation.
In addi-tion, although the shared hidden representations de-rived from SCL and mDA are based on traditionalbag-of-word representations, SCL-NN and mDA-NN can still improve the performance of NaiveNNon most data set pairs, which indicates that the de-rived shared hidden representations by SCL and bymDA can generalize better across domains and aregenerally useful for domain adaptation.Finally, it is easy to see that our method withjoint learning outperforms SCL-NN on almost allthe data set pairs.
And in comparison with mDA-NN, our method with joint learning can also outper-242Task MethodSource Target NaiveNN mDA-NN JointMV1 LT 0.802 0.799 0.816?MV1 RT 0.816 0.820 0.838?MV1 CR 0.744 0.757 0.767?MV2 LT 0.823 0.830 0.839?MV2 RT 0.837 0.829 0.850?MV2 CR 0.753 0.769 0.773?CR LT 0.853 0.863 0.870?CR RT 0.840 0.856 0.851CR MV1 0.699 0.701 0.704?CR MV2 0.745 0.741 0.745LT RT 0.839 0.849 0.849LT MV1 0.714 0.710 0.720?LT MV2 0.759 0.767 0.766LT CR 0.803 0.815 0.814RT LT 0.825 0.839 0.841RT MV1 0.724 0.737 0.732RT MV2 0.762 0.771 0.768RT CR 0.773 0.777 0.783?Average 0.784 0.790 0.796Table 3: Comparison of our method Joint with NaiveNN andmDA-NN in a setting where some labeled target data is used.form it on most data set pairs, especially when thesize of the labeled data in the source domain is rela-tively large.
Furthermore, we can easily observe thatfor our method, joint learning generally works bet-ter than sequential learning.
All these observationsshow the advantage of our joint learning method.In Table 3, we also show the comparison betweenmDA-NN and our model under a setting some la-beled target data is used.
Specifically, we randomlyselect 100 sentences from the development set andmix them with the training set.
We can observe thatour method Joint outperforms NaiveNN and mDA-NN by 1.2% and 0.6%, respectively, which furtherconfirms the effectiveness of our model.
But, incomparison with the setting where no target data isavailable, the average improvement of our methodover NaiveNN is relatively small.Hence, to give a deeper analysis, we further showthe comparison of Joint and NaiveNN with respectto the number of labeled target data in Figure 2.
Notethat for space limitation, we only present the resultson MV2?
RT and MV2?
CR.
Similar trends havebeen observed on other data set pairs.
As we cansee from Figure 2, the difference between the per-formance of NaiveNN and that of Joint graduallydecreases with the increase of the number of labeled0 20 40 60 80 1000.720.740.760.780.80.820.840.86the number of labeled target dataAccuracyMV2RT?JointMV2RT?NaiveNNMV2CR?JointMV2CR?NaiveNNFigure 2: The influence of the number of labeled target data.target data.
This indicates that our joint model ismuch more effective when no or small number oflabeled target data is available.4.4 Case StudyTo obtain a better understanding of our method, weconduct a case study where the source is CR and thetarget is RT.For each sentiment polarity, we try to extract themost useful trigrams for the final predictions.
Re-call that our CNN models use a window size of 3,which corresponds to trigrams.
By tracing the finalprediction scores back through the neural network,we are able to locate the trigrams which have con-tributed the most through max-pooling.
In Table 4,we present the most useful trigrams of each polarityextracted by NaiveNN and by the two componentsof our sequential and joint method.
Sequential-original and Joint-original refer to the CNN cor-responding to f?
while Sequential-auxiliary andJoint-auxiliary refer to the CNN corresponding tof??
, which is related to the auxiliary tasks.In Table 4, we can easily observe that forNaiveNN, the most important trigrams are domain-independent, which contain some general senti-ment words like good, great and disappointing.For our sequential model, the most important tri-grams captured by Sequential-original are simi-lar to NaiveNN, but due to the removal of thepivot words in each sentence, the most impor-tant trigrams extracted by Sequential-auxiliary aredomain-specific, including target-specific sentimentwords like oily, friendly and target-specific aspectwords like flavor, atmosphere.
But since aspectwords are irrelevant to our sentiment classification243Method Negative Sentiment Positive Sentimentdisappointing * *, disgusting * *, it is not, * * great, good * *,* * best, * i love,NaiveNN slow * *, * too bad, * * terrible, place is not, was very good,* * excellent,unpleasant experience *, would not go, * the only wonderful * *, * * amazing, * * nicedisgusting * *, disappointing * *, * * terrible * * great, good * *, * * best, * i love,Sequential-original expensive * *, it is not, unpleasant experience *, * highly recommended, * * excellent,slow * *, * too bad, probably would not, awful * * wonderful * *, is amazing *, is the perfectdisgusting * *, never go back, money * *, delicious * *, friendly * *, food * *,Sequential-auxiliary rude * *, flavor * *, * this place, oily * *, food is UNK, * highly UNK, fresh * *,prices * *, inedible !
*, this place survives atmosphere * *, * i highly, nyc * *disgusting * *, soggy * *, disappointing * *, * * great, good * *, * * best, * i love,Joint-original * too bad, * would never, it is not, rude * *, * * amazing, delicious * *,* * terrible, place is not, disappointment * * back * *, * i highly, of my favoritesoggy * *, disgusting * *, rude * *, delicious * *, go back *, is always fresh,Joint-auxiliary disappointment * *, not go back, was not fresh, friendly * *, to die for, also very UNK,prices * *, inedible !
*, oily * *, overpriced * * of my favorite, food * *, * i highly, delicious !
*Table 4: Comparison of the most useful trigrams chosen by our method and by NaiveNN on CR?
RT.
Here * denotes a ?padding?,which we added at the beginning and the end of each sentence.
The domain-specific sentiment words are in bold.task, it might bring in some noise and affect theperformance of our sequential model.
In contrastto Sequential-auxiliary, Joint-auxiliary is jointlylearnt with the sentiment classification task, and it iseasy to see that most of its extracted trigrams aretarget-specific sentiment words.
Also, for Joint-original, since we share the word embeddings oftwo components and do not remove any pivot, it isintuitive to see that the extracted trigrams containboth domain-independent and domain-specific sen-timent words.
These observations agree with ourmotivations behind the model.Finally, we also sample several sentences fromthe test dataset, i.e., RT, to get a deeper insight ofour joint model.
Although NaiveNN and Sequen-tial correctly predict sentiments of the following twosentences:1.
?I?ve also been amazed at all the new addi-tions in the past few years: A new Jazz Bar, the mostfantastic Dining Garden, the Best Thin Crust Pizzas,and now a Lasagna Menu which is to die for!?2.
?The have a great cocktail with Citrus Vodkaand lemon and lime juice and mint leaves that is todie for!
?Both of them give wrong predictions on anotherthree sentences containing to die for:3.
?Try their chef?s specials?
they are to die for.?4.
?Their tuna tartar appetizer is to die for.?5.
?It?s to die for!
?.However, since to die for co-occurs with somegeneral sentiment words like fantastic, best andgreat in previous two sentences, our joint model canimplicitly learn that to die for is highly correlatedwith the positive sentiment via our auxiliary tasks,and ultimately make correct predictions for the lat-ter three sentences.
This further indicates that ourjoint model can identify more domain-specific sen-timent words in comparison with NaiveNN and Se-quential, and therefore improve the performance.5 ConclusionsWe presented a domain adaptation method for senti-ment classification based on sentence embeddings.Our method induces a sentence embedding thatworks well across domains, based on two auxil-iary tasks.
We also jointly learn the cross-domainsentence embedding and the sentiment classifier.Experiment results show that our proposed jointmethod can outperform several highly competi-tive domain adaptation methods on 18 source-targetpairs using five benchmark data sets.
Moreover, fur-ther analysis confirmed that our method is able topick up domain-specific sentiment words.AcknowledgmentThis research is supported by the Singapore Na-tional Research Foundation under its InternationalResearch Centre@Singapore Funding Initiative andadministered by the IDM Programme Office, MediaDevelopment Authority (MDA).244ReferencesJohn Blitzer, Ryan McDonald, and Fernando Pereira.2006.
Domain adaptation with structural correspon-dence learning.
In Proceedings of the 2006 Con-ference on Empirical Methods in Natural LanguageProcessing, pages 120?128.
Association for Compu-tational Linguistics.John Blitzer, Mark Dredze, and Fernando Pereira.
2007.Biographies, bollywood, boom-boxes and blenders:Domain adaptation for sentiment classification.
InProceedings of the 45th Annual Meeting of the Asso-ciation of Computational Linguistics, pages 440?447,Prague, Czech Republic, June.
Association for Com-putational Linguistics.Danushka Bollegala, David Weir, and John Carroll.2011.
Using multiple sources to construct a sentimentsensitive thesaurus for cross-domain sentiment clas-sification.
In Proceedings of the 49th Annual Meet-ing of the Association for Computational Linguistics:Human Language Technologies-Volume 1, pages 132?141.
Association for Computational Linguistics.Danushka Bollegala, Takanori Maehara, and Ken-ichiKawarabayashi.
2015.
Unsupervised cross-domainword representation learning.
In Proceedings of the53rd Annual Meeting of the Association for Computa-tional Linguistics and the 7th International Joint Con-ference on Natural Language Processing (Volume 1:Long Papers), pages 730?740, Beijing, China, July.Association for Computational Linguistics.Danushka Bollegala, Tingting Mu, and John Goulermas.2016.
Cross-domain sentiment classification usingsentiment sensitive embeddings.
IEEE Transactionson Knowledge & Data Engineering, 6(2):398?410.Minmin Chen, Zhixiang Eddie Xu, Kilian Q. Weinberger,and Fei Sha.
2012.
Marginalized denoising autoen-coders for domain adaptation.
In Proceedings of the29th International Conference on Machine Learning.Yejin Choi and Claire Cardie.
2008.
Learning with com-positional semantics as structural inference for subsen-tential sentiment analysis.
In Proceedings of the Con-ference on Empirical Methods in Natural LanguageProcessing, pages 793?801.
Association for Compu-tational Linguistics.Hal Daume?
III.
2007.
Frustratingly easy domain adapta-tion.
In Proceedings of the 45th Annual Meeting of theAssociation of Computational Linguistics, pages 256?263.Li Dong, Furu Wei, Chuanqi Tan, Duyu Tang, MingZhou, and Ke Xu.
2014a.
Adaptive recursive neuralnetwork for target-dependent twitter sentiment classi-fication.
In Proceedings of the 52nd Annual Meetingof the Association for Computational Linguistics (Vol-ume 2: Short Papers), pages 49?54, Baltimore, Mary-land, June.
Association for Computational Linguistics.Li Dong, Furu Wei, Ming Zhou, and Ke Xu.
2014b.Adaptive multi-compositionality for recursive neuralmodels with applications to sentiment analysis.
InTwenty-Eighth AAAI Conference on Artificial Intelli-gence.Mark Dredze and Koby Crammer.
2008.
Online meth-ods for multi-domain learning and adaptation.
In Pro-ceedings of the Conference on Empirical Methods inNatural Language Processing, pages 689?697.Xavier Glorot, Antoine Bordes, and Yoshua Bengio.2011.
Domain adaptation for large-scale sentimentclassification: A deep learning approach.
In In Pro-ceedings of the Twenty-eight International Conferenceon Machine Learning.Minqing Hu and Bing Liu.
2004.
Mining and summa-rizing customer reviews.
In Proceedings of the tenthACM SIGKDD international conference on Knowl-edge discovery and data mining, pages 168?177.ACM.Jing Jiang and ChengXiang Zhai.
2007.
Instance weight-ing for domain adaptation in nlp.
In Proceedings ofthe 45th Annual Meeting of the Association of Compu-tational Linguistics, pages 264?271.Yoon Kim.
2014.
Convolutional neural networks for sen-tence classification.
In Proceedings of the 2014 Con-ference on Empirical Methods in Natural LanguageProcessing (EMNLP), pages 1746?1751.
Associationfor Computational Linguistics, October.Shoushan Li, Rui Xia, Chengqing Zong, and Chu-RenHuang.
2009.
A framework of feature selection meth-ods for text categorization.
In Proceedings of the JointConference of the 47th Annual Meeting of the ACLand the 4th International Joint Conference on NaturalLanguage Processing of the AFNLP: Volume 2-Volume2, pages 692?700.
Association for Computational Lin-guistics.Fangtao Li, Sinno Jialin Pan, Ou Jin, Qiang Yang, and Xi-aoyan Zhu.
2012.
Cross-domain co-extraction of sen-timent and topic lexicons.
In Proceedings of the 50thAnnual Meeting of the Association for ComputationalLinguistics: Long Papers-Volume 1, pages 410?419.Association for Computational Linguistics.Tetsuji Nakagawa, Kentaro Inui, and Sadao Kurohashi.2010.
Dependency tree-based sentiment classificationusing crfs with hidden variables.
In Human LanguageTechnologies: The 2010 Annual Conference of theNorth American Chapter of the Association for Com-putational Linguistics, pages 786?794.
Association forComputational Linguistics.Sinno Jialin Pan, Xiaochuan Ni, Jian-Tao Sun, QiangYang, and Zheng Chen.
2010.
Cross-domain senti-ment classification via spectral feature alignment.
In245Proceedings of the 19th international conference onWorld wide web, pages 751?760.
ACM.Sinno Jialin Pan, Ivor W Tsang, James T Kwok, andQiang Yang.
2011.
Domain adaptation via transfercomponent analysis.
Neural Networks, IEEE Transac-tions on, 22(2):199?210.Bo Pang and Lillian Lee.
2004.
A sentimental education:Sentiment analysis using subjectivity summarizationbased on minimum cuts.
In Proceedings of the 42ndannual meeting on Association for Computational Lin-guistics, page 271.
Association for Computational Lin-guistics.Bo Pang and Lillian Lee.
2005.
Seeing stars: Ex-ploiting class relationships for sentiment categoriza-tion with respect to rating scales.
In Proceedings ofthe 43rd Annual Meeting on Association for Compu-tational Linguistics, pages 115?124.
Association forComputational Linguistics.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
: sentiment classification using ma-chine learning techniques.
In Proceedings of the ACL-02 conference on Empirical methods in natural lan-guage processing-Volume 10, pages 79?86.
Associa-tion for Computational Linguistics.Natalia Ponomareva and Mike Thelwall.
2012.
Doneighbours help?
: an exploration of graph-based al-gorithms for cross-domain sentiment classification.
InProceedings of the 2012 Joint Conference on Empir-ical Methods in Natural Language Processing andComputational Natural Language Learning, pages655?665.
Association for Computational Linguistics.Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang,Christopher D. Manning, Andrew Ng, and ChristopherPotts.
2013.
Recursive deep models for semanticcompositionality over a sentiment treebank.
In Pro-ceedings of the 2013 Conference on Empirical Meth-ods in Natural Language Processing, pages 1631?1642, Seattle, Washington, USA, October.
Associationfor Computational Linguistics.Duyu Tang, Bing Qin, and Ting Liu.
2015.
Docu-ment modeling with gated recurrent neural networkfor sentiment classification.
In Proceedings of the2015 Conference on Empirical Methods in NaturalLanguage Processing, pages 1422?1432, Lisbon, Por-tugal, September.
Association for Computational Lin-guistics.Ivan Titov.
2011.
Domain adaptation by constraininginter-domain variability of latent feature representa-tion.
In Proceedings of the 49th Annual Meeting ofthe Association for Computational Linguistics: Hu-man Language Technologies, pages 62?71.Yi Yang and Jacob Eisenstein.
2014.
Fast easy unsuper-vised domain adaptation with marginalized structureddropout.
In Proceedings of the 52nd Annual Meetingof the Association for Computational Linguistics (Vol-ume 2: Short Papers), pages 538?544.Yi Yang and Jacob Eisenstein.
2015.
Unsupervisedmulti-domain adaptation with feature embeddings.
InProceedings of the North American Chapter of the As-sociation for Computational Linguistics, pages 672?682.Jianfei Yu and Jing Jiang.
2015.
A hassle-free unsuper-vised domain adaptation method using instance sim-ilarity features.
In Proceedings of the 53rd AnnualMeeting of the Association for Computational Linguis-tics and the 7th International Joint Conference on Nat-ural Language Processing (Volume 2: Short Papers),pages 168?173, Beijing, China, July.
Association forComputational Linguistics.246
