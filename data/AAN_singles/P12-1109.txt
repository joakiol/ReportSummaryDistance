Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 1035?1044,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsA Broad-Coverage Normalization System for Social Media LanguageFei Liu Fuliang Weng Xiao JiangResearch and Technology CenterRobert Bosch LLC{fei.liu, fuliang.weng}@us.bosch.com{fixed-term.xiao.jiang}@us.bosch.comAbstractSocial media language contains huge amountand wide variety of nonstandard tokens, cre-ated both intentionally and unintentionally bythe users.
It is of crucial importance to nor-malize the noisy nonstandard tokens beforeapplying other NLP techniques.
A majorchallenge facing this task is the system cov-erage, i.e., for any user-created nonstandardterm, the system should be able to restore thecorrect word within its top n output candi-dates.
In this paper, we propose a cognitively-driven normalization system that integratesdifferent human perspectives in normalizingthe nonstandard tokens, including the en-hanced letter transformation, visual priming,and string/phonetic similarity.
The systemwas evaluated on both word- and message-level using four SMS and Twitter data sets.Results show that our system achieves over90% word-coverage across all data sets (a10% absolute increase compared to state-of-the-art); the broad word-coverage can alsosuccessfully translate into message-level per-formance gain, yielding 6% absolute increasecompared to the best prior approach.1 IntroductionThe amount of user generated content has increaseddrastically in the past few years, driven by the pros-perous development of the social media websitessuch as Twitter, Facebook, and Google+.
As of June2011, Twitter has attracted over 300 million usersand produces more than 2 billion tweets per week(Twitter, 2011).
In a broader sense, Twitter mes-sages, SMS messages, Facebook updates, chat logs,Emails, etc.
can all be considered as ?social text?,which is significantly different from the traditionalnews text due to the informal writing style and theconversational nature.
The social text serves as avery valuable information source for many NLP ap-plications, such as the information extraction (Ritteret al, 2011), retrieval (Subramaniam et al, 2009),summarization (Liu et al, 2011a), sentiment analy-sis (Celikyilmaz et al, 2010), etc.
Yet existing sys-tems often perform poorly in this domain due theto extensive use of the nonstandard tokens, emoti-cons, incomplete and ungrammatical sentences, etc.It is reported that the Stanford named entity recog-nizer (NER) experienced a performance drop from90.8% to 45.8% on tweets (Liu et al, 2011c); thepart-of-speech (POS) tagger and dependency parserdegraded 12.2% and 20.65% respectively on tweets(Foster et al, 2011).
It is therefore of great impor-tance to normalize the social text before applying thestandard NLP techniques.
Text normalization is alsocrucial for building robust text-to-speech (TTS) sys-tems, which need to determine the pronunciationsfor nonstandard words in the social text.The goal of this work is to automatically con-vert the noisy nonstandard tokens observed in thesocial text into standard English words.
We aimfor a robust text normalization system with ?broadcoverage?, i.e., for any user-created nonstandard to-ken, the system should be able to restore the correctword within its top n candidates (n = 1, 3, 10...).This is a very challenging task due to two facts:first, there exists huge amount and a wide varietyof nonstandard tokens.
(Liu et al, 2011b) foundmore than 4 million distinct out-of-vocabulary to-kens in the Edinburgh Twitter corpus (Petrovic etal., 2010); second, the nonstandard tokens consist10352gether (6326) togetha (919) tgthr (250) togeda (20)2getha (1266) togather (207) t0gether (57) toqethaa (10)2gthr (178) togehter (94) togeter (49) 2getter (10)u (3240535) ya (460963) yo (252274) yaa (17015)yaaa (7740) yew (7591) yuo (467) youz (426)yoooooou (186) youy (105) yoiu (128) yoooouuuu (82)Table 1: Nonstandard tokens and their frequencies in theEdinburgh Twitter corpus.
The corresponding standardwords are ?together?
and ?you?, respectively.of a mixture of both unintentional misspellings andintentionally-created tokens for various reasons1, in-cluding the needs for speed, ease of typing (Crystal,2009), sentiment expressing (e.g., ?coooool?
(Brodyand Diakopoulos, 2011)), intimacy and social pur-pose (Thurlow, 2003), etc., making it even harder todecipher the social messages.
Table 1 shows someexample nonstandard tokens.Existing spell checkers and normalization sys-tems rely heavily on lexical/phonetic similarity toselect the correct candidate words.
This may notwork well since a good portion of the correct wordslie outside the specified similarity threshold (e.g.,(tomorrow, ?tmrw?
)2), yet the number of candidatesincreases dramatically as the system strives to in-crease the coverage by enlarging the threshold.
(Hanand Baldwin, 2011) reported an average of 127 can-didates per nonstandard token with the correct-wordcoverage of 84%.
The low coverage score also en-forces an undesirable performance ceiling for thecandidate reranking approaches.
Different from pre-vious work, we tackle the text normalization prob-lem from a cognitive-sensitive perspective and in-vestigate the human rationales for normalizing thenonstandard tokens.
We argue that there exists a setof letter transformation patterns that humans use todecipher the nonstandard tokens.
Moreover, the ?vi-sual priming?
effect may play an important role inhuman comprehension of the noisy tokens.
?Prim-ing?
represents an implicit memory effect.
For ex-ample, if a person reads a list of words including theword table, and is later asked to complete a wordstarting with tab-, it is very likely that he answerstable since the person is primed.In this paper, we propose a broad-coverage nor-malization system by integrating three human per-1For this reason, we will use the term ?nonstandard tokens?instead of ?ill-formed tokens?
throughout the paper.2We use the form (standard word, ?nonstandard token?)
todenote an example nonstandard token and its correspondingstandard word.spectives, including the enhanced letter transforma-tion, visual priming, and the string and phoneticsimilarity.
For an arbitrary nonstandard token, thethree subnormalizers each suggest their most con-fident candidates from a different perspective.
Thecandidates can then be heuristically combined orreranked using a message-level decoding process.We evaluate the system on both word- and message-level using four SMS and Twitter data sets.
Resultsshow that our system can achieve over 90% word-coverage with limited number of candidates and thebroad word-coverage can be successfully translatedinto message-level performance gain.
In addition,our system requires no human annotations, thereforecan be easily adapted to different domains.2 Related workText normalization, in its traditional sense, is thefirst step of a speech synthesis system, where thenumbers, dates, acronyms, etc.
found in the real-world text were converted into standard dictionarywords, so that the system can pronounce them cor-rectly.
Spell checking plays an important role in thisprocess.
(Church and Gale, 1991; Mays et al, 1991;Brill and Moore, 2000) proposed to use the noisychannel framework to generate a list of correctionsfor any misspelled word, ranked by the correspond-ing posterior probabilities.
(Sproat et al, 2001) en-hanced this framework by calculating the likelihoodprobability as the chance of a noisy token and its as-sociated tag being generated by a specific word.With the rapid growth of SMS and social me-dia content, text normalization system has drawn in-creasing attention in the recent decade, where thefocus is on converting the noisy nonstandard tokensin the informal text into standard dictionary words.
(Choudhury et al, 2007) modeled each standard En-glish word as a hidden Markov model (HMM) andcalculated the probability of observing the noisy-token under each of the HMM models; (Cook andStevenson, 2009) calculated the sum of the probabil-ities of a noisy token being generated by a specificword and a word formation process; (Beaufort et al,2010) employed the weighted finite-state machines(FSMs) and rewriting rules for normalizing FrenchSMS; (Pennell and Liu, 2010) focused on tweets cre-ated by handsets and developed a CRF tagger fordeletion-based abbreviation.
The text normalizationproblem was also tackled under the machine transla-1036tion (MT) or speech recognition (ASR) framework.
(Aw et al, 2006) adapted a phrase-based MT modelfor normalizing SMS and achieved satisfying per-formance.
(Kobus et al, 2008) showed that using astatistical MT system in combination with an anal-ogy of the ASR system improved performance inFrench SMS normalization.
(Pennell and Liu, 2011)proposed a two-phase character-level MT system forexpanding the abbreviations into standard text.Recent work also focuses on normalizing theTwitter messages, which is generally considered amore challenging task.
(Han and Baldwin, 2011) de-veloped classifiers for detecting the ill-formed wordsand generated corrections based on the morpho-phonemic similarity.
(Liu et al, 2011b) proposedto normalize the nonstandard tokens without explic-itly categorizing them.
(Xue et al, 2011) adoptedthe noisy-channel framework and incorporated or-thographic, phonetic, contextual, and acronym ex-pansion factors in calculating the likelihood proba-bilities.
(Gouws et al, 2011) revealed that differentpopulations exhibit different shortening styles.Most of the above systems limit their processingscope to certain categories (e.g., deletion-based ab-breviations, misspellings) or require large-scale hu-man annotated corpus for training, which greatlyhinders the scalability of the system.
In this paper,we propose a novel cognitively-driven text normal-ization system that robustly tackle both the unin-tentional misspellings and the intentionally-creatednoisy tokens.
We propose a global context-basedapproach to purify the automatically collected train-ing data and learn the letter transformation pat-terns without human supervision.
We also proposea cognitively-grounded ?visual priming?
approachthat leverages the ?priming?
effect to suggest thecandidate words.
By integrating different perspec-tives, our system can successfully mimic the hu-man rationales and yield broad word-coverage onboth SMS and Twitter messages.
To the best of ourknowledge, we are the first to integrate these humanperspectives in the text normalization system.3 Broad-Coverage Normalization SystemIn this section, we describe our broad-coverage nor-malization system, which consists of four key com-ponents.
For a standard/nonstandard token, threesubnormalizers each suggest their most confidentb - - - - d a y f - o t o zh u b b i e(1) birthday --> bday(2) photos --> fotoz(4) hubby --> hubbieb i r t h d a yp h o t o sh u b b ys o m e 1 - -(6) someone --> some1s o m e o n en u t h i n -(3) nothing --> nuthinn o t h i n g4 - - e v a -(5) forever --> 4evaf o r e v e rFigure 1: Examples of nonstandard tokens generated byperforming letter transformation on the dictionary words.candidates from a different perspective3: ?EnhancedLetter Transformation?
automatically learns a setof letter transformation patterns and is most effec-tive in normalizing the intentionally created non-standard tokens through letter insertion, repetition,deletion, and substitution (Section 3.1); ?VisualPriming?
proposes candidates based on the visualcues and a primed perspective (Section 3.2); ?SpellChecker?
corrects the misspellings (Section 3.3).The fourth component, ?Candidate Combination?introduces various strategies to combine the candi-dates with or without the local context (Section 3.4).Note that it is crucial to integrate different humanperspectives so that the system is flexible in pro-cessing both unintentional misspellings and variousintentionally-created noisy tokens.3.1 Enhanced Letter TransformationGiven a noisy token ti seen in the text, the lettertransformation subnormalizer produces a list of cor-rection candidates si under the noisy channel model:s?
= argmaxsip(si|ti) = argmaxsip(ti|si)p(si)where we assume each nonstandard token ti is de-pendent on only one English word si, that is, weare not considering acronyms (e.g., ?bbl?
for ?beback later?)
in this study.
p(si) can be calculatedas the unigram count from a background corpus.
Weformulate the process of generating a nonstandardtoken ti from the dictionary word si using a lettertransformation model, and use the model confidenceas the probability p(ti|si).
Figure 1 shows severalexample (word, token) pairs.To form a nonstandard token, each letter in thedictionary word can be labeled with: (a) one of the0-9 digits; (b) one of the 26 characters including it-self; (c) the null character ?-?
; (d) a letter combi-nation4.
This transformation process from dictio-3For the dictionary word, we allow the subnormalizers toeither return the word itself or candidates that are the possiblyintended words in the given context (e.g., (with, ?wit?
)).4The set of letter combinations used in this work are {ah, ai,aw, ay, ck, ea, ey, ie, ou, te, wh}1037nary words to nonstandard tokens will be learnedby a character-level sequence labeling system us-ing the automatically collected (word, token) pairs.Next, we create a large lookup table by applying thecharacter-level labeling system to the standard dic-tionary words and generate multiple variations foreach word using the n-best labeling output, the la-beling confidence is used as p(ti|si).
During testing,we search this lookup table to find the best candidatewords for the nonstandard tokens.
For tokens withletter repetition, we first generate a set of variantsby varying the repetitive letters (e.g.
Ci = {?pleas?,?pleeas?, ?pleaas?, ?pleeaas?, ?pleeeaas?}
for ti ={?pleeeaas?
}), then select the maximum posteriorprobability among all the variants:p(ti|si) = maxt?i?Cip(t?i|si)Different from the work in (Liu et al, 2011b), weenhanced the letter transformation process with twonovel aspects: first, we devise a set of phoneme-,syllable-, morpheme- and word-boundary based fea-tures that effectively characterize the formation pro-cess of the nonstandard tokens; second, we proposea global context-aware approach to purify the auto-matically collected training (word, token) pairs, re-sulting system yielded similar performance but withonly one ninth of the original data.
We name thissubnormalizer ?Enhanced Letter Transformation?.3.1.1 Context-Aware Training Pair SelectionManual annotation of the noisy nonstandard to-kens takes a lot of time and effort.
(Liu et al, 2011b)proposed to use Google search engine to automati-cally collect large amount of training pairs.
Yet theresulting (work, token) pairs are often noisy, con-taining pairs such as (events, ?ents?
), (downtown,?downto?
), etc.
The ideal training data should con-sist of the most frequent nonstandard tokens pairedwith the corresponding corrections, so that the sys-tem can learn from the most representative lettertransformation patterns.Motivated by research on word sense disambigua-tion (WSD) (Mihalcea, 2007), we hypothesize thenonstandard token and the standard word share a lotof common terms in their global context.
For exam-ple, ?luv?
and ?love?
share ?i?, ?you?, ?u?, ?it?, etc.among their top context words.
Based on this find-ing, we propose to filter out the low-quality train-ing pairs by evaluating the global contextual simi-larity between the word and token.
To the best ofour knowledge, we are the first to explore this globalcontextual similarity for the text normalization task.Given a noisy (word, token) pair, we constructtwo context vectors vi and vj by collecting themost frequent terms appearing before or after thework/token.
We consider two terms on each sideof the word/token as context and restrict the vectorlength to the top 100 terms.
The frequency informa-tion were calculated using a large background cor-pus; stopwords were not excluded from the contextvector.
The contextual similarity of the (word, to-ken) pair is defined as the cosine similarity betweenthe context vectors vi and vj :ContextSim(vi, vj) =Pnk=1 wi,k ?
wj,kqPnk=1 w2i,k ?qPnk=1 w2j,kwhere wi,k is the weight of term tk within the con-text of term ti.
The term weights are defined using anormalized TF-IDF method:wi,k =TFi,kTFi?
log(NDFk)where TFi,k is the count of term tk appearing withinthe context of term ti; TFi is the total count of ti inthe corpus.
TFi,kTFi is therefore the relative frequencyof tk appearing in the context of ti; log( NDFk ) de-notes the inverse document frequency of tk, calcu-lated as the logarithm of total tweets (N ) divided bythe number of tweets containing tk.To select the most representative (word, token)pairs for training, we rank the automatically col-lected 46,288 pairs by the token frequency, filterout pairs whose contextual similarity lower than athreshold ?
(set empirically at 0.0003), and retainonly the top portion (5,000 pairs) for experiments.3.1.2 Character-level Sequence LabelingFor a dictionary word si, we use the conditionalrandom fields (CRF) model to perform character-level labeling to generate its variant ti.
In the train-ing stage, we align the collected (word, token) pairsat the character level (Liu et al, 2011b), then con-struct a feature vector for each letter of the dictio-nary word, using its mapped character as the ref-erence label.
This aligned data set is used to traina CRF model (Lafferty et al, 2001; Kudo, 2005)1038Character a d v e r t i s e m e n t sPhoneme AE D V ER ER T AY Z M AH N T SPhoneme boundary O O O B1 L1 O O O O O O O O OSyllable boundary B L B I L B I I L B I I I LMorpheme boundary B I I I I I I I L B I I L UWord boundary B I I I I I I I I I I I I LTable 2: Example boundary tags for word ?advertise-ments?
on the phoneme-, syllable-, morpheme-, andword-level, labeled with the ?BILOU?
encoding scheme.with L-BFGS optimization.
We use the charac-ter/phoneme n-gram and binary vowel features as in(Liu et al, 2011b), but develop a set of boundaryfeatures to effectively characterize the letter trans-formation process.We notice that in creating the nonstandard tokens,humans tend to drop certain letter units from theword or replace them with other letters.
For exam-ple, in abbreviating ?advertisements?
to ?ads?, hu-mans may first break the word into smaller units?ad-ver-tise-ment-s?, then drop the middle parts.This also conforms with the word construction the-ory where a word is composed of smaller units andconstruction rules.
Based on this assumption, wedecompose the dictionary words on the phoneme-,syllable-, morpheme-, and word-level5 and use the?BILOU?
tagging scheme (Ratinov and Roth, 2009)to represent the unit boundary, where ?BILOU?stands for B(egin), I(nside), L(ast), O(utside), andU(nit-length) of the corresponding unit6.
Example?BILOU?
boundary tags were shown in Table 2.On top of the boundary tags, we develop a set ofconjunction features to accurately pinpoint the cur-rent character position.
We consider conjunctionfeatures formed by concatenating character positionin syllable and current syllable position in the word(e.g., conjunction feature ?L B?
for the letter ?d?
inTable 2).
A similar set of features are also devel-oped on morpheme level.
We consider conjunctionof character/vowel feature and their boundary tagson the syllable/morpheme/word level; conjunctionof phoneme and phoneme boundary tags, and ab-solute position of current character within the corre-5Phoneme decomposition is generated using the (Jiampo-jamarn et al, 2007) algorithm to map up to two letters tophonemes (2-to-2 alignment); syllable boundary acquired bythe hyphenation algorithm (Liang, 1983); morpheme boundarydetermined by toolkit Morfessor 1.0 (Creutz and Lagus, 2005).6For phoneme boundary, we use ?B1?
and ?L1?
to representtwo different characters aligned to one phoneme and ?B2?, ?L2?represent same characters aligned to one phoneme.sponding syllable/morpheme/word.We use the aforementioned features to train theCRF model, then apply the model on dictionarywords si to generate multiple variations ti for eachword.
When a nonstandard token is seen during test-ing, we apply the noisy channel to generate a list ofbest candidate words: s?
= argmaxsip(ti|si)p(si).3.2 Visual Priming ApproachA second key component of the broad-coverage nor-malization system is a novel ?Visual Priming?
sub-normalizer.
It is built on a cognitively-driven ?prim-ing?
effect, which has not been explored by otherstudies yet was shown to be effective across all ourdata sets.
?Priming?7 is an implicit memory effect causedby spreading neural networks (Tulving and Stark,1982).
As an example, in the word-stem comple-tion task, participants are given a list of study words,and then asked to complete word ?stems?
consistingof first 3 letters.
A priming effect is observed whenparticipants complete stems with words on the studylist more often than with the novel words.
The studylist activates parts of the human brain right beforethe stem completion task, later when a word stem isseen, less additional activation is needed for one tochoose a word from the study list.We argue that the ?priming?
effect may play animportant role in human comprehension of the noisytokens.
A person familiarized with the ?social talk?is highly primed with the most commonly usedwords; later when a nonstandard token shows onlyminor visual cues or visual stimulus, it can still bequickly recognized by the person.
In this process,the first letter or first few letters of the word serveas a very important visual stimulus.
Based on thisassumption, we introduce the ?priming?
subnormal-izer based only on the word frequency and the minorvisual stimulus.
Concretely, this approach proposescandidate words based on the following equation:V isualPrim(si|ti) =len(LCS(ti, si))len(ti)?
log(TF (si))Where TF (si) is the term frequency of si as in thebackground social text corpus; log(TF (si)) primesthe system with the most common words in the so-cial text; LCS(?)
means the longest common char-acter subsequence; len(?)
denotes the length of the7http://en.wikipedia.org/wiki/Priming (psychology)1039character sequence.
Together len(LCS(ti,si))len(ti) pro-vides the minor visual stimulus from ti.
Note thatthe first character has been shown to be a crucial vi-sual cue for the brain to understand jumbled words(Davis, ), we therefore consider as candidates onlythose words si that start with the same character asti.
In the case that the nonstandard token ti startswith a digit (e.g., ?2moro?
), we use the mostly likelycorresponding letter to search the candidates (thosestarting with letter ?t?).
This setting also effectivelyreduces the candidate search space.The ?visual priming?
subnormalizer promotes thecandidate words that are frequently used in the so-cial talk and also bear visual similarity with thegiven noisy token.
It slightly deviates from the tradi-tional ?priming?
notion in that the frequency infor-mation were acquired from the global corpus ratherthan from the prior context.
This approach also in-herently follows the noisy channel framework, withp(ti|si) represents the visual stimulus and p(si) be-ing the logarithm of frequency.
The candidate wordsare ranked by s?
= argmaxsiV isualPrim(si|ti).We show that the ?priming?
subnormalizer is robustacross data sets abide its simplistic representation.3.3 Spell CheckerThe third subnormalizer is the spell checker, whichcombines the string and phonetic similarity algo-rithms and is most effective in normalizing the mis-spellings.
We use the Jazzy spell checker (Idzelis,2005) that integrates the DoubleMetaphone phoneticmatching algorithm and the Levenshtein distance us-ing the near-miss strategy, which enables the in-terchange of two adjacent letters, and the replac-ing/deleting/adding of letters.3.4 Candidate CombinationEach of the three subnormalizers is a stand-alonesystem and can suggest corrections for the nonstan-dard tokens.
Yet we show that each subnormal-izer mimics a different perspective that humans useto decode the nonstandard tokens, as a result, ourbroad-coverage normalization system is built by in-tegrating candidates from the three subnormalizersusing various strategies.For a noisy token seen in the informal text, themost convenient way of system combination is toharvest up to n candidates from each of the sub-normalizers, and use the pool of candidates (up to3n) as the system output.
This sets an upper boundfor other candidate combination strategies, and wename this approach ?Oracle?.A second combination strategy is to give higherpriority to candidates from high-precision subsys-tems.
Both ?Letter Transformation?
and ?SpellChecker?
have been shown to have high precision insuggesting corrections (Liu et al, 2011b), while ?Vi-sual Priming?
may not yield high precision due toits definition.
We therefore take the top-3 candidatesfrom each of the ?Letter Tran.?
and ?Spell Checker?subsystems, but put candidates from ?Letter Tran.
?ahead of ?Spell Checker?
if the confidence of thebest candidate is greater than a threshold ?
and viceversa.
The list of candidates is then compensated us-ing the ?Visual Priming?
output until the total num-ber reaches n. We name this approach ?Word-level?combination since no message-level context infor-mation is involved.Based on the ?Word-level?
combination output,we can further rerank all the candidates using amessage-level Viterbi decoding process (Pennell andLiu, 2011) where the local context information isused to select the best candidate.
This approach isnamed ?Message-level?
combination.4 Experiments4.1 Experimental SetupWe use four SMS and Twitter data sets to evaluatethe system effectiveness.
Statistics of these data setsare summarized in Table 3.
Data set (1) to (3) areused for word-level evaluation; data set (4) for bothword- and message-level evaluation.
In Table 3, wealso present the number of distinct nonstandard to-kens found in each data set, and notice that only asmall portion of the nonstandard tokens correspondto multiple standard words.
We calculate the dic-tionary coverage of the manually annotated wordssince this sets an upper bound for any normaliza-tion system.
We use the Edinburgh Twitter corpus(Petrovic et al, 2010) as the background corpus forfrequency calculation, and a dictionary containing82,324 words.8 The nonstandard tokens may consistof both numbers/characters and apostrophe.8The dictionary is created by combining the CMU (CMU,2007) and Aspell (Atkinson, 2006) dictionaries and droppingwords with frequency < 20 in the background corpus.
?rt?
andall single characters except ?a?
and ?i?
are excluded.1040Index Domain Time Period #Msgs#Uniq Nonstan.
%Nonstan.
Tkns %Dict cov.ReferenceTokens w/ Multi-cands of cands(1) SMS Around 2007 n/a 303 1.32% 100% (Choudhury et al, 2007)(2) Twitter Nov 2009 ?
Feb 2010 6150 3802 3.87% 99.34% (Liu et al, 2011)(3) SMS/Twitter Aug 2009 4660 2040 2.41% 96.84% (Pennell and Liu, 2011)(4) Twitter Aug 2010 ?
Oct 2010 549 558 2.87% 99.10% (Han and Baldwin, 2011)Table 3: Statistics of different SMS and Twitter data sets.The goal of word-level normalization is to convertthe list of distinct nonstandard tokens into standardwords.
For each nonstandard token, the system isconsidered correct if any of the corresponding stan-dard words is among the n-best output from the sys-tem.
We adopt this word-level n-best accuracy tomake our results comparable to other state-of-the-artsystems.
On message-level, we evaluate the 1-bestsystem output using precision, recall, and f-score,calculated respective to the nonstandard tokens.4.2 Word-level ResultsThe word-level results are presented in Table 4, 5,and 6, evaluated on data set (1), (2), (3) respectively.We present the n-best accuracy (n = 1, 3, 10, 20) ofthe system as well as the ?Oracle?
results generatedby pooling the top-20 candidates from each of thethree subnormalizers.
The best prior results on thedata sets are also included in the tables.We notice that the broad-coverage system outper-forms all other systems on the reported data sets.It achieves about 90% word-level accuracy on dataset (1) and (2) with the top-10 candidates (an aver-age 10% performance gain compared to (Liu et al,2011b)).
This is of crucial importance to a normal-ization system, since the high accuracy and limitednumber of candidates will enable more sophisticatedreranking or supervised learning techniques to se-lect the best candidate.
We also observe the ?Ora-cle?
system has averagely only 5% gap to the dic-tionary coverage.
A detailed analysis shows that thehuman annotators perform many semantic/grammarcorrections as well as inconsistent annotations, e.g.,(sleepy, ?zzz?
), (disliked, ?unliked?).
These are outof the capabilities of the current text normalizationsystem and partly explains the remaining 5% gap.Regarding the subnormalizer performance, thespell checker yields only 50% to 60% accuracy onall data sets, indicating that the vast amount of theintentionally created nonstandard tokens can hardlybe tackled by a system relies solely on the lexi-cal/phonetic similarity.
The ?Visual Priming?
sub-SMS Dataset Word Level Accuracy (%)(303 pairs) 1-best 3-best 10-best 20-best OracleJazzy Spell Checker 43.89 55.45 56.77 56.77 n/aVisual Priming 54.13 74.92 84.82 87.13 n/aEnhanced Letter Tran.
61.06 74.92 80.86 82.51 n/aBroad-Cov.
System 64.36 80.20 89.77 91.75 94.06(Pennell et al, 2011)?
60.39 74.58 75.57 75.57 n/a(Liu et al, 2011) 62.05 75.91 81.19 81.19 n/a(Cook et al, 2009) 59.4 n/a 83.8 87.8 n/a(Choudhury et al, 2007)?
59.9 n/a 84.3 88.7 n/aTable 4: Word-level results on data set (1).
?
denotessystem requires human annotations for training.Twitter Dataset Word Level Accuracy (%)(3802 pairs) 1-best 3-best 10-best 20-best OracleJazzy Spell Checker 47.19 56.92 59.13 59.18 n/aVisual Priming 54.34 70.59 80.83 84.74 n/aEnhanced Letter Tran.
61.05 70.07 74.04 74.75 n/aBroad-Cov.
System 69.81 82.51 92.24 93.79 95.71(Liu et al, 2011) 68.88 78.27 80.93 81.17 n/aTable 5: Word-level results on data set (2).normalizer performs surprisingly well and shows ro-bust performance across all data sets.
A minor side-effect is that the candidates were restricted to havethe same first letter with the noisy token, this setsthe upper bound of the approach to 89.77%, 92.45%,and 93.51%, respectively on data set (1), (2), and (3).Compared to other subnormalizers, the ?EnhancedLetter Tran.?
is effective at normalizing intention-ally created tokens and has better precision regard-ing its top candidate (n = 1).
We demonstrate thecontext-aware training pair selection results in Fig-ure 2, by plotting the learning curve using differentamounts of training data, ranging from 1,000 (word,token) pairs to the total 46,288 pairs.
We notice thatthe system can effectively learn the letter transfor-mation patterns from a small number of high qualitytraining pairs.
The final system was trained using thetop 5,000 pairs and the lookup table was created bygenerating 50 variations for each dictionary word.4.3 Message-level ResultsThe goal of message-level normalization is to re-place each occurrence of the nonstandard token withthe candidate word that best fits the local context.1041SMS/Twitter Dataset Word Level Accuracy (%)(2404 pairs) 1-best 3-best 10-best 20-best OracleJazzy Spell Checker 39.89 46.51 48.54 48.67 n/aVisual Priming 54.12 68.59 78.83 83.11 n/aEnhanced Letter Tran.
57.65 67.18 71.01 71.88 n/aBroad-Cov.
System 64.39 78.29 86.56 88.69 91.60(Pennell et al, 2011)?
37.40 n/a n/a 72.38 n/aTable 6: Word-level results on data set (3).
?
denotessystem requires human annotations for training.646668707274761K2K5K10K20KAll (~45K)Amount of Training PairsNonstandard Token Cov.
(%)Random SelectionContext-awareSelectionFigure 2: Learning curve of the enhanced letter transfor-mation system using random training pair selection or thecontext-aware approach.
Evaluated on data set (2).We use the word-level ?Broad-Cov.
System?
forcandidate suggestion and the Viterbi algorithm formessage-level decoding.
The system is evaluated ondata set (4) and results shown in Table 7.
Followingresearch in (Han and Baldwin, 2011), we focus onthe the normalization task and assume perfect non-standard token detection.The ?Word-level w/o Context?
results are gen-erated by replacing each nonstandard token usingthe 1-best word-level candidate.
Although the re-placement process is static, it results in 70.97% f-score due to the high performance of the word-levelsystem.
We explore two language models (LM)for the Viterbi decoding process.
First, a bigramLM is trained using the Edinburgh Twitter corpus(53,794,549 English tweets) with the SRILM toolkit(Stolcke, 2002) and Kneser-Ney smoothing; second,we retrieve the bigram probabilities from the Mi-crosoft Web N-gram API (Wang et al, 2010) sincethis represents a more comprehensive web-basedcorpus.
During decoding, we use the ?VisualPrim?score as the emission probability, since this scorebest fits the log scale and applies to all candidates.For the Twitter LM, we apply a scaling factor of0.5 to the ?VisualPrim?
score to make it compara-ble in scale to the LM probabilities.
We use the 3-best word-level candidates for Viterbi decoding.
Inaddition, we add the commonly used corrections forTwitter Dataset Message-level P/R/F(549 Tweets) Precision (%) Recall (%) F-score (%)Word-level w/o Context 75.69 66.81 70.97w/ ContextWeb LM 79.12 77.11 78.10Twitter LM 84.13 78.38 81.15(Han and Baldwin, 2011)?
75.30 75.30 75.30Table 7: Message-level results on data set (4).
?
denotessystem requires human annotations for training.16 single-characters, e.g., for ?r?, ?c?, we add ?are?,?see?
to the candidate list if they are not already pre-sented.
A default ?VisualPrim?
score (?
= 25) isused for these candidates.
As seen from Table 7,both Web LM and Twitter LM achieve better perfor-mance than the best prior results, with Twitter LMoutperforms the Web LM, yielding a f-score of 81%.This shows that a vanilla Viterbi decoding process isable to outperform the fine-tuned supervised systemgiven competitive word-level candidates.
In future,we will investigate other comprehensive message-level candidate reranking process.5 ConclusionIn this paper, we propose a broad-coverage normal-ization system for the social media language with-out using the human annotations.
It integrates threekey components: the enhanced letter transformation,visual priming, and string/phonetic similarity.
Thesystem was evaluated on both word- and message-level using four SMS and Twitter data sets.
We showthat our system achieves over 90% word-coverageacross all data sets and the broad word-coverage canbe successfully translated into message-level perfor-mance gain.
We observe that the social media is anemotion-rich language, therefore future normaliza-tion system will need to address various sentiment-related expressions, such as emoticons (?
:d?, ?X-8?
), interjections (?bwahaha?, ?brrrr?
), acronyms(?lol?, ?lmao?
), etc., whether and how these expres-sions should be normalized is an unaddressed issueand worths future investigation.AcknowledgmentsWe thank the three anonymous reviewers for theirinsightful comments and valuable input.
We thankProf.
Yang Liu, Deana Pennell, Bo Han, and Prof.Tim Baldwin for sharing the annotated data and theuseful discussions.
Part of this work was done whileXiao Jiang was a research intern in Bosch Research.1042ReferencesKevin Atkinson.
2006.
Gnu aspell.
http://aspell.net/.AiTi Aw, Min Zhang, Juan Xiao, and Jian Su.
2006.
Aphrase-based statistical model for sms text normaliza-tion.
In Proceedings of COLING/ACL, pages 33?40.Richard Beaufort, Sophie Roekhaut, Louise-Ame?lieCougnon, and Ce?drick Fairon.
2010.
A hybridrule/model-based finite-state framework for normaliz-ing sms messages.
In Proceedings of ACL, pages 770?779.Eric Brill and Robert C. Moore.
2000.
An improvederror model for noisy channel spelling correction.
InProceedings of ACL.Samuel Brody and Nicholas Diakopoulos.
2011.Cooooooooooooooollllllllllllll!!!!!!!!!!!!!!
Using wordlengthening to detect sentiment in microblogs.
In Pro-ceedings of EMNLP, pages 562?570.Asli Celikyilmaz, Dilek Hakkani-Tur, and Junlan Feng.2010.
Probabilistic model-based sentiment analysis oftwitter messages.
In Proceedings of the IEEE Work-shop on Spoken Language Technology, pages 79?84.Monojit Choudhury, Rahul Saraf, Vijit Jain, AnimeshMukherjee, Sudeshna Sarkar, and Anupam Basu.2007.
Investigation and modeling of the structure oftexting language.
International Journal on DocumentAnalysis and Recognition, 10(3):157?174.Kenneth W. Church and William A. Gale.
1991.
Prob-ability scoring for spelling correction.
Statistics andComputing, 1:93?103.CMU.
2007.
The cmu pronouncing dictionary.http://www.speech.cs.cmu.edu/cgi-bin/cmudict.Paul Cook and Suzanne Stevenson.
2009.
An unsuper-vised model for text messages normalization.
In Pro-ceedings of the NAACL HLT Workshop on Computa-tional Approaches to Linguistic Creativity, pages 71?78.Mathias Creutz and Krista Lagus.
2005.
Unsupervisedmorpheme segmentation and morphology inductionfrom text corpora using morfessor 1.0.
In Computerand Information Science, Report A81, Helsinki Uni-versity of Technology.David Crystal.
2009.
Txtng: The gr8 db8.
Oxford Uni-versity Press.Matt Davis.
Reading jumbled texts.
http://www.mrc-cbu.cam.ac.uk/personal/matt.davis/Cmabrigde/.Jennifer Foster, Ozlem Cetinoglu, Joachim Wagner,Joseph Le Roux, Stephen Hogan, Joakim Nivre,Deirdre Hogan, and Josef van Genabith.
2011.
#hard-toparse: POS tagging and parsing the twitterverse.
InProceedings of the AAAI Workshop on Analyzing Mi-crotext, pages 20?25.Stephan Gouws, Donald Metzler, Congxing Cai, and Ed-uard Hovy.
2011.
Contextual bearing on linguisticvariation in social media.
In Proceedings of the ACLWorkshop on Language in Social Media, pages 20?29.Bo Han and Timothy Baldwin.
2011.
Lexical normalisa-tion of short text messages: Makn sens a #twitter.
InProceedings of ACL, pages 368?378.Mindaugas Idzelis.
2005.
Jazzy: The java open sourcespell checker.
http://jazzy.sourceforge.net/.Sittichai Jiampojamarn, Grzegorz Kondrak, and TarekSherif.
2007.
Applying many-to-many alignmentsand hidden markov models to letter-to-phoneme con-version.
In Proceedings of HLT/NAACL, pages 372?379.Catherine Kobus, Franc?ois Yvon, and Ge?raldineDamnati.
2008.
Normalizing sms: Are two metaphorsbetter than one?
In Proceedings of COLING, pages441?448.Taku Kudo.
2005.
CRF++: Yet another CRF took kit.http://crfpp.sourceforge.net/.John Lafferty, Andrew McCallum, and Fernando Pereira.2001.
Conditional random fields: Probabilistic mod-els for segmenting and labeling sequence data.
In Pro-ceedings of ICML, pages 282?289.Franklin Mark Liang.
1983.
Word hy-phen-a-tion bycom-put-er.
In PhD Dissertation, Stanford University.Fei Liu, Yang Liu, and Fuliang Weng.
2011a.
Whyis ?sxsw?
trending?
Exploring multiple text sourcesfor twitter topic summarization.
In Proceedings of theACL Workshop on Language in Social Media (LSM),pages 66?75.Fei Liu, Fuliang Weng, Bingqing Wang, and Yang Liu.2011b.
Insertion, deletion, or substitution?
Normal-izing text messages without pre-categorization nor su-pervision.
In Proceedings of ACL, pages 71?76.Xiaohua Liu, Shaodian Zhang, Furu Wei, and MingZhou.
2011c.
Recognizing named entities in tweets.In Proceedings of ACL, pages 359?367.Eric Mays, Fred J. Damerau, and Robert L. Mercer.1991.
Context based spelling correction.
InformationProcessing and Management: An International Jour-nal, 27(5):517?522.Rada Mihalcea.
2007.
Using wikipedia for auto-matic word sense disambiguation.
In Proceedings ofNAACL, pages 196?203.Deana L. Pennell and Yang Liu.
2010.
Normalizationof text messages for text-to-speech.
In Proceedings ofICASSP, pages 4842?4845.Deana L. Pennell and Yang Liu.
2011.
A character-level machine translation approach for normalizationof sms abbreviations.
In Proceedings of the 5th Inter-national Joint Conference on Natural Language Pro-cessing, pages 974?982.Sasa Petrovic, Miles Osborne, and Victor Lavrenko.2010.
The edinburgh twitter corpus.
In Proceedings1043of the NAACL HLT Workshop on Computational Lin-guistics in a World of Social Media, pages 25?26.Lev Ratinov and Dan Roth.
2009.
Design challengesand misconceptions in named entity recognition.
InProceedings of CoNLL, pages 147?155.Alan Ritter, Sam Clark, Mausam, and Oren Etzioni.2011.
Named entity recognition in tweets: An experi-mental study.
In Proceedings of EMNLP.Richard Sproat, Alan W. Black, Stanley Chen, ShankarKumar, Mari Ostendorf, and Christopher Richards.2001.
Normalization of non-standard words.
Com-puter Speech and Language, 15(3):287?333.Andreas Stolcke.
2002.
SRILM ?
An extensible lan-guage modeling toolkit.
In Proceedings of ICSLP,pages 901?904.L.
Venkata Subramaniam, Shourya Roy, Tanveer A.Faruquie, and Sumit Negi.
2009.
A survey of typesof text noise and techniques to handle noisy text.
InProceedings of AND.Crispin Thurlow.
2003.
Generation txt?
the sociolin-guistics of young people?s text-messaging.
DiscourseAnalysis Online.Endel Tulving and Daniel L. Schacter; Heather A. Stark.1982.
Priming effects in word fragment comple-tion are independent of recognition memory.
Journalof Experimental Psychology: Learning, Memory andCognition, 8(4).Twitter.
2011. http://en.wikipedia.org/wiki/Twitter.Kuansan Wang, Christopher Thrasher, Evelyne Viegas,Xiaolong Li, and Bo june (Paul) Hsu.
2010.
Anoverview of microsoft web n-gram corpus and appli-cations.
In Proceedings of NAACL-HLT, pages 45?48.Zhenzhen Xue, Dawei Yin, and Brian D. Davison.
2011.Normalizing microtext.
In Proceedings of the AAAIWorkshop on Analyzing Microtext, pages 74?79.1044
