Proceedings of the 12th Conference of the European Chapter of the ACL, pages 282?290,Athens, Greece, 30 March ?
3 April 2009. c?2009 Association for Computational LinguisticsRich bitext projection features for parse rerankingAlexander Fraser Renjing WangInstitute for Natural Language ProcessingUniversity of Stuttgart{fraser,wangrg}@ims.uni-stuttgart.deHinrich Schu?tzeAbstractMany different types of features havebeen shown to improve accuracy in parsereranking.
A class of features that thus farhas not been considered is based on a pro-jection of the syntactic structure of a trans-lation of the text to be parsed.
The intu-ition for using this type of bitext projec-tion feature is that ambiguous structuresin one language often correspond to un-ambiguous structures in another.
We showthat reranking based on bitext projectionfeatures increases parsing accuracy signif-icantly.1 IntroductionParallel text or bitext is an important knowledgesource for solving many problems such as ma-chine translation, cross-language information re-trieval, and the projection of linguistic resourcesfrom one language to another.
In this paper, weshow that bitext-based features are effective in ad-dressing another NLP problem, increasing the ac-curacy of statistical parsing.
We pursue this ap-proach for a number of reasons.
First, one lim-iting factor for syntactic approaches to statisticalmachine translation is parse quality (Quirk andCorston-Oliver, 2006).
Improved parses of bi-text should result in improved machine translation.Second, as more and more texts are available inseveral languages, it will be increasingly the casethat a text to be parsed is itself part of a bitext.Third, we hope that the improved parses of bitextwill serve as higher quality training data for im-proving monolingual parsing using a process sim-ilar to self-training (McClosky et al, 2006).It is well known that different languages encodedifferent types of grammatical information (agree-ment, case, tense etc.)
and that what can be leftunspecified in one language must be made explicitNPNPNPDTaNNbabyCCandNPDTaNNwomanSBARwho had gray hairFigure 1: English parse with high attachmentin another.
This information can be used for syn-tactic disambiguation.
However, it is surprisinglyhard to do this well.
We use parses and alignmentsthat are automatically generated and hence imper-fect.
German parse quality is considered to beworse than English parse quality, and the annota-tion style is different, e.g., NP structure in Germanis flatter.We conduct our research in the framework ofN-best parse reranking, but apply it to bitext andadd only features based on syntactic projectionfrom German to English.
We test the idea that,generally, English parses with more isomorphismwith respect to the projected German parse are bet-ter.
The system takes as input (i) English sen-tences with a list of automatically generated syn-tactic parses, (ii) a translation of the English sen-tences into German, (iii) an automatically gen-erated parse of the German translation, and (iv)an automatically generated word alignment.
Weachieve a significant improvement of 0.66 F1 (ab-solute) on test data.The paper is organized as follows.
Section 2outlines our approach and section 3 introduces themodel.
Section 4 describes training and section 5presents the data and experimental results.
In sec-tion 6, we discuss previous work.
Section 7 ana-lyzes our results and section 8 concludes.282NPNPDTaNNbabyCCandNPNPDTaNNwomanSBARwho had gray hairFigure 2: English parse with low attachmentCNPNPARTeinNNBabyKONundNPARTeineNNFrau,,Sdie...Figure 3: German parse with low attachment2 ApproachConsider the English sentence ?He saw a baby anda woman who had gray hair?.
Suppose that thebaseline parser generates two parses, containingthe NPs shown in figures 1 and 2, respectively, andthat the semantically more plausible second parsein figure 2 is correct.
How can we determine thatthe second parse should be favored?
Since we areparsing bitext, we can observe the German trans-lation which is ?Er sah ein Baby und eine Frau,die graue Haare hatte?
(glossed: ?he saw a babyand a woman, who gray hair had?).
The singularverb in the subordinate clause (?hatte?
: ?had?)
in-dicates that the subordinate S must be attached lowto ?woman?
(?Frau?)
as shown in figure 3.We follow Collins?
(2000) approach to discrim-inative reranking (see also (Riezler et al, 2002)).Given a new sentence to parse, we first select thebest N parse trees according to a generative model.Then we use new features to learn discriminativelyhow to rerank the parses in this N-best list.
Weuse features derived using projections of the 1-bestGerman parse onto the hypothesized English parseunder consideration.In more detail, we take the 100 best Englishparses from the BitPar parser (Schmid, 2004) andrerank them.
We have a good chance of finding theoptimal parse among the 100-best1.
An automati-cally generated word alignment determines trans-lational correspondence between German and En-glish.
We use features which measure syntactic di-1Using an oracle to select the best parse results in an F1of 95.90, an improvement of 8.01 absolute over the baseline.vergence between the German and English trees totry to rank the English trees which have less diver-gence higher.
Our test set is 3718 sentences fromthe English Penn treebank (Marcus et al, 1993)which were translated into German.
We hold outthese sentences, and train BitPar on the remain-ing Penn treebank training sentences.
The averageF1 parsing accuracy of BitPar on this test set is87.89%, which is our baseline2.
We implementfeatures based on projecting the German parse toeach of the English 100-best parses in turn via theword alignment.
By performing cross-validationand measuring test performance within each fold,we compare our new system with the baseline onthe 3718 sentence set.
The overall test accuracywe reach is 88.55%, a statistically significant im-provement over baseline of 0.66.Given a word alignment of the bitext, the sys-tem performs the following steps for each Englishsentence to be parsed:(i) run BitPar trained on English to generate 100-best parses for the English sentence(ii) run BitPar trained on German to generate the1-best parse for the German sentence(iii) calculate feature function values which mea-sure different kinds of syntactic divergence(iv) apply a model that combines the feature func-tion values to score each of the 100-best parses(v) pick the best parse according to the model3 ModelWe use a log-linear model to choose the best En-glish parse.
The feature functions are functionson the hypothesized English parse e, the Germanparse g, and the word alignment a, and they as-sign a score (varying between 0 and infinity) thatmeasures syntactic divergence.
The alignment ofa sentence pair is a function that, for each Englishword, returns a set of German words that the En-glish word is aligned with as shown here for thesentence pair from section 2:Er sah ein Baby und eine Frau , die graue HaarehatteHe{1} saw{2} a{3} baby{4} and{5} a{6}woman{7} who{9} had{12} gray{10} hair{11}Feature function values are calculated either bytaking the negative log of a probability, or by usinga heuristic function which scales in a similar fash-2The test set is very challenging, containing English sen-tences of up to 99 tokens.283ion3.
The form of the log-linear model is shown ineq.
1.
There are M feature functions h1, .
.
.
, hM .The vector ?
is used to control the contribution ofeach feature function.p?
(e|g, a) =exp(?
?i ?ihi(e, g, a))?e?
exp(?
?i ?ihi(e?, g, a))(1)Given a vector of weights ?, the best Englishparse e?
can be found by solving eq.
2.
The modelis trained by finding the weight vector ?
whichmaximizes accuracy (see section 4).e?
= argmaxep?
(e|g, a)= argmineexp(?i?ihi(e, g, a)) (2)3.1 Feature FunctionsThe basic idea behind our feature functions is thatany constituent in a sentence should play approx-imately the same syntactic role and have a similarspan as the corresponding constituent in a trans-lation.
If there is an obvious disagreement, itis probably caused by wrong attachment or othersyntactic mistakes in parsing.
Sometimes in trans-lation the syntactic role of a given semantic consti-tutent changes; we assume that our model penal-izes all hypothesized parses equally in this case.For the initial experiments, we used a set of 34probabilistic and heuristic feature functions.BitParLogProb (the only monolingual feature)is the negative log probability assigned by BitParto the English parse.
If we set ?1 = 1 and ?i = 0for all i 6= 1 and evaluate eq.
2, we will select theparse ranked best by BitPar.In order to define our feature functions, we firstintroduce auxiliary functions operating on indi-vidual word positions or sets of word positions.Alignment functions take an alignment a as an ar-gument.
In the descriptions of these functions weomit a as it is held constant for a sentence pair (i.e.,an English sentence and its German translation).f(i) returns the set of word positions of Germanwords aligned with an English word at position i.f ?
(i) returns the leftmost word position of theGerman words aligned with an English word at po-sition i, or zero if the English word is unaligned.f?1(i) returns the set of positions of English3For example, a probability of 1 is a feature value of 0,while a low probability is a feature value which is ?
0.words aligned with a German word at position i.f ?
?1(i) returns the leftmost word position of theEnglish words aligned with a German word at po-sition i, or zero if the German word is unaligned.We overload the above functions to allow the ar-gument i to be a set, in which case union is used,for example, f(i) = ?j?if(j).
Positions in atree are denoted with integers.
First, the POS tagsare numbered from 1 to the length of the sentence(i.e., the same as the word positions).
Constituentshigher in the tree are also indexed using consecu-tive integers.
We refer to the constituent that hasbeen assigned index i in the tree t as ?constituent iin tree t?
or simply as ?constituent i?.
The follow-ing functions have the English and German treesas an implicit argument; it should be obvious fromthe argument to the function whether the indexi refers to the German tree or the English tree.When we say ?constituents?, we include nodeson the POS level of the tree.
Our syntactic treesare annotated with a syntactic head for each con-stituent.
Finally, the tag at position 0 is NULL.mid2sib(i) returns 0 if i is 0, returns 1 if i hasexactly two siblings, one on the left of i and oneon the right, and otherwise returns 0.head(i) returns the index of the head of i. Thehead of a POS tag is its own position.tag(i) returns the tag of i.left(i) returns the index of the leftmost sibling ofi.right(i) returns the index of the rightmost sibling.up(i) returns the index of i?s parent.?
(i) returns the set of word positions covered byi.
If i is a set, ?
returns all word positions betweenthe leftmost position covered by any constituent inthe set and the rightmost position covered by anyconstituent in the set (inclusive).n(A) returns the size of the set A.c(A) returns the number of characters (includingpunctuation and excluding spaces) covered by theconstituents in set A.JpiK is 1 if pi is true, and 0 otherwise.l and m are the lengths in words of the English andGerman sentences, respectively.3.1.1 Count Feature FunctionsFeature CrdBin counts binary events involvingthe heads of coordinated phrases.
If in the Englishparse we have a coordination where the EnglishCC is aligned only with a German KON, and bothhave two siblings, then the value contributed toCrdBin is 1 (indicating a constraint violation) un-284less the head of the English left conjunct is alignedwith the head of the German left conjunct and like-wise the right conjuncts are aligned.
Eq.
3 calcu-lates the value of CrdBin.l?i=1J(tag(i) = CCKJ(n(f(i)) = 1K mid2sib(i)mid2sib(f ?
(i)) Jtag(f ?
(i)) = KON-CDKJ[head(left(f ?
(i))) 6= f ?
(head(left(i)))] OR[head(right(f ?
(i))) 6= f ?
(head(right(i)))]K (3)Feature Q simply captures a mismatch betweenquestions and statements.
If an English sentence isparsed as a question but the parallel German sen-tence is not, or vice versa, the feature value is 1;otherwise the value is 0.3.1.2 Span Projection Feature FunctionsSpan projection features calculate the percentagedifference between a constituent?s span and thespan of its projection.
Span size is measured incharacters or words.
To project a constituent ina parse, we use the word alignment to project allword positions covered by the constituent and thenlook for the smallest covering constituent in theparse of the parallel sentence.CrdPrj is a feature that measures the diver-gence in the size of coordination constituents andtheir projections.
If we have a constituent (XP1CC XP2) in English that is projected to a Germancoordination, we expect the English and Germanleft conjuncts to span a similar percentage of theirrespective sentences, as should the right conjuncts.The feature computes a character-based percent-age difference as shown in eq.
4.l?i=1Jtag(i) = CCKJn(f(i)) = 1K (4)Jtag(f ?
(i)) = KON-CDKmid2sib(i)mid2sib(f ?(i))(|c(?
(left(i)))r ?c(?
(left(f ?
(i))))s |+|c(?
(right(i)))r ?c(?
(right(f ?
(i))))s |)r and s are the lengths in characters of the En-glish and German sentences, respectively.
In theEnglish parse in figure 1, the left conjunct has 5characters and the right conjunct has 6, while infigure 2 the left conjunct has 5 characters and theright conjunct has 20.
In the German parse (fig-ure 3) the left conjunct has 7 characters and theright conjunct has 27.
Finally, r = 33 and s = 42.Thus, the value of CrdPrj is 0.48 for the first hy-pothesized parse and 0.05 for the second, whichcaptures the higher divergence of the first Englishparse from the German parse.POSParentPrj is based on computing the spandifference between all the parent constituents ofPOS tags in a German parse and their respectivecoverage in the corresponding hypothesized parse.The feature value is the sum of all the differences.POSPar(i) is true if i immediately dominates aPOS tag.
The projection direction is from Germanto English, and the feature computes a percentagedifference which is character-based.
The value ofthe feature is calculated in eq.
5, where M is thenumber of constituents (including POS tags) in theGerman tree.M?i=1JPOSPar(i)K|c(?
(i))s ?c(?(f?1(?
(i))))r |(5)The right conjunct in figure 3 is a POSParentthat corresponds to the coordination NP in fig-ure 1, contributing a score of 0.21, and to the rightconjunct in figure 2, contributing a score of 0.04.For the two parses of the full sentences contain-ing the NPs in figure 1 and figure 2, we sum over7 POSParents and get a value of 0.27 for parse 1and 0.11 for parse 2.
The lower value for parse2 correctly captures the fact that the first Englishparse has higher divergence than the second due toincorrect high attachment.AbovePOSPrj is similar to POSParentPrj, butit is word-based and the projection direction isfrom English to German.
Unlike POSParentPrjthe feature value is calculated over all constituentsabove the POS level in the English tree.Another span projection feature function isDTNNPrj, which projects English constituents ofthe form (NP(DT)(NN)).
DTNN(i) is true if iis an NP immediately dominating only DT andNN.
The feature computes a percentage differencewhich is word-based, shown in eq.
6.L?i=1JDTNN(i)K|n(?
(i))l ?n(?(f(?
(i))))m | (6)L is the number of constituents in the Englishtree.
This feature is designed to disprefer parses285where constituents starting with ?DT NN?, e.g.,(NP (DT NN NN NN)), are incorrectly split intotwo NPs, e.g., (NP (DT NN)) and (NP (NN NN)).This feature fires in this case, and projects the (NP(DT NN)) into German.
If the German projectionis a surprisingly large number of words (as shouldbe the case if the German also consists of a deter-miner followed by several nouns) then the penaltypaid by this feature is large.
This feature is impor-tant as (NP (DT NN)) is a very common construc-tion.3.1.3 Probabilistic Feature FunctionsWe use Europarl (Koehn, 2005), from which weextract a parallel corpus of approximately 1.22million sentence pairs, to estimate the probabilis-tic feature functions described in this section.For the PDepth feature, we estimate Englishparse depth probability conditioned on Germanparse depth from Europarl by calculating a sim-ple probability distribution over the 1-best parsepairs for each parallel sentence.
A very deep Ger-man parse is unlikely to correspond to a flat En-glish parse and we can penalize such a parse usingPDepth.
The index i refers to a sentence pair inEuroparl, as does j.
Let li and mi be the depthsof the top BitPar ranked parses of the English andGerman sentences, respectively.
We calculate theprobability of observing an English tree of depthl?
given German tree of depth m?
as the maxi-mum likelihood estimate, shown in eq.
7, where?
(z, z?)
= 1 if z = z?
and 0 otherwise.
To avoidnoisy feature values due to outliers and parse er-rors, we bound the value of PDepth at 5 as shownin eq.
84.p(l?|m?)
=?i ?
(l?, li)?
(m?,mi)?j ?(m?,mj)(7)min(5,?
log10(p(l?|m?)))
(8)The full parse of the sentence containing the En-glish high attachment has a parse depth of 8 whilethe full parse of the sentence containing the En-glish low attachment has a depth of 9.
Their fea-ture values given the German parse depth of 6 are?
log10(0.12) = 0.93 and ?
log10(0.14) = 0.84.The wrong parse is assigned a higher feature valueindicating its higher divergence.The feature PTagEParentGPOSGParent mea-sures tagging inconsistency based on estimating4Throughout this paper, assume log(0) = ?
?.the probability that for an English word at posi-tion i, the parent of its POS tag has a particularlabel.
The feature value is calculated in eq.
10.q(i, j) = p(tag(up(i))|tag(j), tag(up(j))) (9)l?i=1min(5,?j?f(i) ?
log10(q(i, j))n(f(i)) ) (10)Consider (S(NP(NN fruit))(VP(V flies))) and(NP(NN fruit)(NNS flies)) with the translation(NP(NNS Fruchtfliegen)).
Assume that ?fruit?and ?flies?
are aligned with the German com-pound noun ?Fruchtfliegen?.
In the incorrect En-glish parse the parent of the POS of ?fruit?
isNP and the parent of the POS of ?flies?
is VP,while in the correct parse the parent of the POS of?fruit?
is NP and the parent of the POS of ?flies?is NP.
In the German parse the compound nounis POS-tagged as an NNS and the parent is anNP.
The probabilities considered for the two En-glish parses are p(NP|NNS,NP) for ?fruit?
in bothparses, p(VP|NNS,NP) for ?flies?
in the incorrectparse, and p(NP|NNS,NP) for ?flies?
in the cor-rect parse.
A German NNS in an NP has a higherprobability of being aligned with a word in an En-glish NP than with a word in an English VP, so thesecond parse will be preferred.As with the PDepth feature, we use relativefrequency to estimate this feature.
When an En-glish word is aligned with two words, estimation ismore complex.
We heuristically give each Englishand German pair one count.
The value calculatedby the feature function is the geometric mean5 ofthe pairwise probabilities, see eq.
10.3.1.4 Other FeaturesOur best system uses the nine features we havedescribed in detail so far.
In addition, we imple-mented the following 25 other features, which didnot improve performance (see section 7): (i) 7?ptag?
features similar to PTagEParentGPOSG-Parent but predicting and conditioning on differ-ent combinations of tags (POS tag, parent of POS,grandparent of POS)(ii) 10 ?prj?
features similar to POSParentPrjmeasuring different combinations of character andword percentage differences at the POS parent and5Each English word has the same weight regardless ofwhether it was aligned with one or with more German words.286POS grandparent levels, projecting from both En-glish and German(iii) 3 variants of the DTNN feature function(iv) A NPPP feature function, similar to theDTNN feature function but trying to counteract abias towards (NP (NP) (PP)) units(v) A feature function which penalizes aligningclausal units to non-clausal units(vi) The BitPar rank4 TrainingLog-linear models are often trained using theMaximum Entropy criterion, but we train ourmodel directly to maximize F1.
We score F1 bycomparing hypothesized parses for the discrimi-native training set with the gold standard.
To tryto find the optimal ?
vector, we perform direct ac-curacy maximization, meaning that we search forthe ?
vector which directly optimizes F1 on thetraining set.Och (2003) has described an efficient exact one-dimensional accuracy maximization technique fora similar search problem in machine translation.The technique involves calculating an explicitrepresentation of the piecewise constant functiongm(x) which evaluates the accuracy of the hy-potheses which would be picked by eq.
2 from aset of hypotheses if we hold all weights constant,except for the weight ?m, which is set to x. Thisis calculated in one pass over the data.The algorithm for training is initialized with achoice for ?
and is described in figure 4.
The func-tion F1(?)
returns F1 of the parses selected using?.
Due to space we do not describe step 8 in detail(see (Och, 2003)).
In step 9 the algorithm per-forms approximate normalization, where featureweights are forced towards zero.
The implemen-tation of step 9 is straight-forward given the Mexplicit functions gm(x) created in step 8.5 Data and ExperimentsWe used the subset of the Wall Street Journalinvestigated in (Atterer and Schu?tze, 2007) forour experiments, which consists of all sentencesthat have at least one prepositional phrase attach-ment ambiguity.
This difficult subset of sentencesseems particularly interesting when investigatingthe potential of information in bitext for improv-ing parsing performance.
The first 500 sentencesof this set were translated from English to Germanby a graduate student and an additional 3218 sen-1: Algorithm TRAIN(?
)2: repeat3: add ?
to the set s4: let t be a set of 1000 randomly generated vectors5: let ?
= argmax??
(s?t) F1(?
)6: let ??
= ?7: repeat8: repeatedly run one-dimensional error minimiza-tion step (updating a single scalar of the vector ?
)until no further error reduction9: adjust each scalar of ?
in turn towards 0 such thatthere is no increase in error (if possible)10: until no scalar in ?
changes in last two steps (8 and9)11: until ?
= ?
?12: return ?Figure 4: Sketch of the training algorithmtences by a translation bureau.
We withheld these3718 English sentences (and an additional 1000reserved sentences) when we trained BitPar on thePenn treebank.Parses.
We use the BitPar parser (Schmid,2004) which is based on a bit-vector im-plementation (cf.
(Graham et al, 1980)) ofthe Cocke-Younger-Kasami algorithm (Kasami,1965; Younger, 1967).
It computes a compactparse forest for all possible analyses.
As all pos-sible analyses are computed, any number of bestparses can be extracted.
In contrast, other treebankparsers use sophisticated search strategies to findthe most probable analysis without examining theset of all possible analyses (Charniak et al, 1998;Klein and Manning, 2003).
BitPar is particularlyuseful for N-best parsing as the N-best parses canbe computed efficiently.For the 3718 sentences in the translated set, wecreated 100-best English parses and 1-best Ger-man parses.
The German parser was trained onthe TIGER treebank.
For the Europarl corpus, wecreated 1-best parses for both languages.Word Alignment.
We use a word alignmentof the translated sentences from the Penn tree-bank, as well as a word alignment of the Europarlcorpus.
We align these two data sets togetherwith data from the JRC Acquis (Steinberger et al,2006) to try to obtain better quality alignments (itis well known that alignment quality improves asthe amount of data increases (Fraser and Marcu,2007)).
We aligned approximately 3.08 millionsentence pairs.
We tried to obtain better alignmentquality as alignment quality is a problem in manycases where syntactic projection would otherwisework well (Fossum and Knight, 2008).287System Train +base Test +base1 Baseline 87.89 87.892 Contrastive 88.70 0.82 88.45 0.56(5 trials/fold)3 Contrastive 88.82 0.93 88.55 0.66(greedy selection)Table 1: Average F1 of 7-way cross-validationTo generate the alignments, we used Model 4(Brown et al, 1993), as implemented in GIZA++(Och and Ney, 2003).
As is standard practice, wetrained Model 4 with English as the source lan-guage, and then trained Model 4 with German asthe source language, resulting in two Viterbi align-ments.
These were combined using the Grow DiagFinal And symmetrization heuristic (Koehn et al,2003).Experiments.
We perform 7-way cross-validation on 3718 sentences.
In each fold of thecross-validation, the training set is 3186 sentences,while the test set is 532 sentences.
Our results areshown in table 1.
In row 1, we take the hypothesisranked best by BitPar.
In row 2, we train using thealgorithm outlined in section 4.
To cancel out anyeffect caused by a particularly effective or ineffec-tive starting ?
value, we perform 5 trials each time.Columns 3 and 5 report the improvement over thebaseline on train and test respectively.
We reachan improvement of 0.56 over the baseline usingthe algorithm as described in section 4.Our initial experiments used many highly cor-related features.
For our next experiment we usegreedy feature selection.
We start with a ?
vectorthat is zero for all features, and then run the errorminimization without the random generation ofvectors (figure 4, line 4).
This means that we addone feature at a time.
This greedy algorithm windsup producing a vector with many zero weights.
Inrow 3 of table 1, we used the greedy feature selec-tion algorithm and trained using F1, resulting ina performance of 0.66 over the baseline which isour best result.
We performed a planned one-tailedpaired t-test on the F1 scores of the parses selectedby the baseline and this system for the 3718 sen-tences (parses were taken from the test portionof each fold).
We found that there is a signifi-cant difference with the baseline (t(3717) = 6.42,p < .01).
We believe that using the full set of 34features (many of which are very similar to oneanother) made the training problem harder with-out improving the fit to the training data, and thatgreedy feature selection helps with this (see alsosection 7).6 Previous WorkAs we mentioned in section 2, work on parsereranking is relevant, but a vital difference is thatwe use features based only on syntactic projectionof the two languages in a bitext.
For an overviewof different types of features that have been used inparse reranking see Charniak and Johnson (2005).Like Collins (2000) we use cross-validation totrain our model, but we have access to much lessdata (3718 sentences total, which is less than 1/10of the data Collins used).
We use rich feature func-tions which were designed by hand to specificallyaddress problems in English parses which can bedisambiguated using the German translation.Syntactic projection has been used to bootstraptreebanks in resource poor languages.
Some ex-amples of projection of syntactic parses from En-glish to a resource poor language for which noparser is available are the works of Yarowsky andNgai (2001), Hwa et al (2005) and Goyal andChatterjee (2006).
Our work differs from theirsin that we are performing a parse reranking taskin English using knowledge gained from Germanparses, and parsing accuracy is generally thoughtto be worse in German than in English.Hopkins and Kuhn (2006) conducted researchwith goals similar to ours.
They showed how tobuild a powerful generative model which flexiblyincorporates features from parallel text in four lan-guages, but were not able to show an improvementin parsing performance.
After the submission ofour paper for review, two papers outlining relevantwork were published.
Burkett and Klein (2008)describe a system for simultaneously improvingChinese and English parses of a Chinese/Englishbitext.
This work is complementary to ours.
Thesystem is trained using gold standard trees in bothChinese and English, in contrast with our systemwhich only has access to gold standard trees in En-glish.
Their system uses a tree alignment whichvaries within training, but this does not appear tomake a large difference in performance.
They usecoarsely defined features which are language in-dependent.
We use several features similar to theirtwo best performing sets of features, but in con-trast with their work, we also define features whichare specifically aimed at English disambiguationproblems that we have observed can be resolved288using German parses.
They use an in-domainChinese parser and out-of-domain English parser,while for us the English parser is in-domain andthe German parser is out-of-domain, both of whichmake improving the English parse more difficult.Their Maximum Entropy training is more appro-priate for their numerous coarse features, whilewe use Minimum Error Rate Training, which ismuch faster.
Finally, we are projecting from a sin-gle German parse which is a more difficult prob-lem.
Fossum and Knight (2008) outline a systemfor using Chinese/English word alignments to de-termine ambiguous English PP-attachments.
Theyfirst use an oracle to choose PP-attachment deci-sions which are ambiguous in the English side of aChinese/English bitext, and then build a classifierwhich uses information from a word alignment tomake PP-attachment decisions.
No Chinese syn-tactic information is required.
We use automati-cally generated German parses to improve Englishsyntactic parsing, and have not been able to find asimilar phenomenon for which only a word align-ment would suffice.7 AnalysisWe looked at the weights assigned during thecross-validation performed to obtain our best re-sult.
The weights of many of the 34 features wedefined were frequently set to zero.
We sortedthe features by the number of times the relevant?
scalar was zero (i.e., the number of folds ofthe cross-validation for which they were zero; thegreedy feature selection is deterministic and so wedo not run multiple trials).
We then reran the samegreedy feature selection algorithm as was used intable 1, row 3, but this time using only the top9 feature values, which were the features whichwere active on 4 or more folds6.
The result was animprovement on train of 0.84 and an improvementon test of 0.73.
This test result may be slightlyoverfit, but the result supports the inference thatthese 9 feature functions are the most important.We chose these feature functions to be describedin detail in section 3.
We observed that the variantsof the similar features POSParentPrj and Above-POSPrj projected in opposite directions and mea-sured character and word differences, respectively,and this complementarity seems to help.6We saw that many features canceled one another out ondifferent folds.
For instance either the word-based or thecharacter-based version of DTNN was active in each fold,but never at the same time as one another.We also tried to see if our results dependedstrongly on the log-linear model and training algo-rithm, by using the SVM-Light ranker (Joachims,2002).
In order to make the experiment tractable,we limited ourselves to the 8-best parses (ratherthan 100-best).
Our training algorithm and modelwas 0.74 better than the baseline on train and 0.47better on test, while SVM-Light was 0.54 betterthan baseline on train and 0.49 better on test (us-ing linear kernels).
We believe that the results arenot unduly influenced by the training algorithm.8 ConclusionWe have shown that rich bitext projection featurescan improve parsing accuracy.
This confirms thehypothesis that the divergence in what informationdifferent languages encode grammatically can beexploited for syntactic disambiguation.
Improvedparsing due to bitext projection features should behelpful in syntactic analysis of bitexts (by way ofmutual syntactic disambiguation) and in comput-ing syntactic analyses of texts that have transla-tions in other languages available.AcknowledgmentsThis work was supported in part by DeutscheForschungsgemeinschaft Grant SFB 732.
Wewould like to thank Helmut Schmid for support ofBitPar and for his many helpful comments on ourwork.
We would also like to thank the anonymousreviewers.ReferencesMichaela Atterer and Hinrich Schu?tze.
2007.
Preposi-tional phrase attachment without oracles.
Computa-tional Linguistics, 33(4).Peter F. Brown, Stephen A. Della Pietra, Vincent J.Della Pietra, and R. L. Mercer.
1993.
The mathe-matics of statistical machine translation: parameterestimation.
Computational Linguistics, 19(2).David Burkett and Dan Klein.
2008.
Two lan-guages are better than one (for syntactic parsing).
InEMNLP.Eugene Charniak and Mark Johnson.
2005.
Coarse-to-fine n-best parsing and MaxEnt discriminativereranking.
In ACL.Eugene Charniak, Sharon Goldwater, and Mark John-son.
1998.
Edge-based best-first chart parsing.
InProceedings of the Sixth Workshop on Very LargeCorpora.289Michael Collins.
2000.
Discriminative reranking fornatural language parsing.
In ICML.Victoria Fossum and Kevin Knight.
2008.
Using bilin-gual Chinese-English word alignments to resolvePP-attachment ambiguity in English.
In AMTA.Alexander Fraser and Daniel Marcu.
2007.
Measuringword alignment quality for statistical machine trans-lation.
Computational Linguistics, 33(3).Shailly Goyal and Niladri Chatterjee.
2006.
Parsingaligned parallel corpus by projecting syntactic re-lations from annotated source corpus.
In Proceed-ings of the COLING/ACL main conference postersessions.Susan L. Graham, Michael A. Harrison, and Walter L.Ruzzo.
1980.
An improved context-free recognizer.ACM Transactions on Programming Languages andSystems, 2(3).Mark Hopkins and Jonas Kuhn.
2006.
A frameworkfor incorporating alignment information in parsing.In Proceedings of the EACL 2006 Workshop onCross-Language Knowledge Induction.Rebecca Hwa, Philip Resnik, Amy Weinberg, ClaraCabezas, and Okan Kolak.
2005.
Bootstrappingparsers via syntactic projection across parallel texts.Nat.
Lang.
Eng., 11(3).Thorsten Joachims.
2002.
Optimizing search en-gines using clickthrough data.
In Proceedings of theEighth ACM SIGKDD.Takao Kasami.
1965.
An efficient recognition and syn-tax analysis algorithm for context-free languages.Technical Report AFCRL-65-7558, Air Force Cam-bridge Research Laboratory.Dan Klein and Christopher Manning.
2003.
A* pars-ing: fast exact viterbi parse selection.
In HLT-NAACL.Philipp Koehn, Franz J. Och, and Daniel Marcu.
2003.Statistical phrase-based translation.
In HLT-NAACL.Philipp Koehn.
2005.
Europarl: a parallel corpus forstatistical machine translation.
In MT Summit X.Mitchell P. Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1993.
Building a large annotatedcorpus of English: the Penn treebank.
Computa-tional Linguistics, 19(2).David McClosky, Eugene Charniak, and Mark John-son.
2006.
Effective self-training for parsing.
InHLT-NAACL.Franz J. Och and Hermann Ney.
2003.
A systematiccomparison of various statistical alignment models.Computational Linguistics, 29(1).Franz J. Och.
2003.
Minimum error rate training instatistical machine translation.
In ACL.Chris Quirk and Simon Corston-Oliver.
2006.
The im-pact of parse quality on syntactically-informed sta-tistical machine translation.
In EMNLP.Stefan Riezler, Tracy H. King, Ronald M. Kaplan,Richard S. Crouch, John T. Maxwell III, and MarkJohnson.
2002.
Parsing the Wall Street Journal us-ing a lexical-functional grammar and discriminativeestimation techniques.
In ACL.Helmut Schmid.
2004.
Efficient parsing of highly am-biguous context-free grammars with bit vectors.
InCOLING.Ralf Steinberger, Bruno Pouliquen, Anna Widiger,Camelia Ignat, Tomaz Erjavec, Dan Tufis, andDaniel Varga.
2006.
The JRC-Acquis: a multilin-gual aligned parallel corpus with 20+ languages.
InLREC.David Yarowsky and Grace Ngai.
2001.
Inducing mul-tilingual POS taggers and NP bracketers via robustprojection across aligned corpora.
In NAACL.Daniel H. Younger.
1967.
Recognition of context-freelanguages in time n3.
Information and Control, 10.290
