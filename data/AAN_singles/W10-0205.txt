Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 35?44,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsA Corpus-based Method for Extracting Paraphrases of Emotion TermsFazel KeshtkarUniversity of OttawaOttawa, ON, K1N 6N5, Canadaakeshtka@site.uOttawa.caDiana InkpenUniversity of OttawaOttawa, ON, K1N 6N5, Canadadiana@site.uOttawa.caAbstractSince paraphrasing is one of the crucial tasksin natural language understanding and gener-ation, this paper introduces a novel techniqueto extract paraphrases for emotion terms, fromnon-parallel corpora.
We present a bootstrap-ping technique for identifying paraphrases,starting with a small number of seeds.
Word-Net Affect emotion words are used as seeds.The bootstrapping approach learns extractionpatterns for six classes of emotions.
We useannotated blogs and other datasets as textsfrom which to extract paraphrases, based onthe highest-scoring extraction patterns.
Theresults include lexical and morpho-syntacticparaphrases, that we evaluate with humanjudges.1 IntroductionParaphrases are different ways to express the sameinformation.
Algorithms to extract and automati-cally identify paraphrases are of interest from bothlinguistic and practical points of view.
Many ma-jor challenges in Natural Language Processing ap-plications, for example multi-document summariza-tion, need to avoid repetitive information from theinput documents.
In Natural Language Genera-tion, paraphrasing is employed to create more var-ied and natural text.
In our research, we ex-tract paraphrases for emotions, with the goal of us-ing them to automatically-generate emotional texts(such as friendly or hostile texts) for conversationsbetween intelligent agents and characters in educa-tional games.
Paraphrasing is applied to generatetext with more variety.
To our knowledge, most cur-rent applications manually collect paraphrases forspecific applications, or they use lexical resourcessuch as WordNet (Miller et al, 1993) to identifyparaphrases.This paper introduces a novel method for ex-tracting paraphrases for emotions from texts.
Wefocus on the six basic emotions proposed by Ek-man (1992): happiness, sadness, anger, disgust,surprise, and fear.We describe the construction of the paraphrasesextractor.
We also propose a k-window algorithmfor selecting contexts that are used in the paraphraseextraction method.
We automatically learn patternsthat are able to extract the emotion paraphrases fromcorpora, starting with a set of seed words.
We usedata sets such as blogs and other annotated cor-pora, in which the emotions are marked.
We usea large collection of non-parallel corpora which aredescribed in Section 3.
These corpora contain manyinstances of paraphrases different words to expressthe same emotion.An example of sentence fragments for oneemotion class, happiness, is shown in Table 1.
Fromthem, the paraphrase pair that our method willextract is:"so happy to see""very glad to visit".In the following sections, we give an overview ofrelated work on paraphrasing in Section 2.
In Sec-tion 3 we describe the datasets used in this work.We explain the details of our paraphrase extractionmethod in Section 4.
We present results of our evalu-ation and discuss our results in Section 5, and finallyin Section 6 we present the conclusions and futurework.35his little boy was so happy to see himprincess and she were very glad to visit himTable 1: Two sentence fragments (candidate contexts)from the emotion class happy, from the blog corpus.2 Related WorkThree main approaches for collecting paraphraseswere proposed in the literature: manual collection,utilization of existing lexical resources, and corpus-based extraction of expressions that occur in similarcontexts (Barzilay and McKeown, 2001).
Manually-collected paraphrases were used in natural languagegeneration (NLG) (Iordanskaja et al, 1991).
Langk-ilde et al (1998) used lexical resources in statisticalsentence generation, summarization, and question-answering.
Barzilay and McKeown (2001) used acorpus-based method to identify paraphrases from acorpus of multiple English translations of the samesource text.
Our method is similar to this method,but it extracts paraphrases only for a particular emo-tion, and it needs only a regular corpus, not a parallelcorpus of multiple translations.Some research has been done in paraphrase ex-traction for natural language processing and genera-tion for different applications.
Das and Smith (2009)presented a approach to decide whether two sen-tences hold a paraphrase relationship.
They ap-plied a generative model that generates a paraphraseof a given sentence, then used probabilistic infer-ence to reason about whether two sentences sharethe paraphrase relationship.
In another research,Wang et.
al (2009) studied the problem of extract-ing technical paraphrases from a parallel softwarecorpus.
Their aim was to report duplicate bugs.
Intheir method for paraphrase extraction, they used:sentence selection, global context-based and co-occurrence-based scoring.
Also, some studies havebeen done in paraphrase generation in NLG (Zhaoet al, 2009), (Chevelu et al, 2009).
Bootstrappingmethods have been applied to various natural lan-guage applications, for example to word sense dis-ambiguation (Yarowsky, 1995), lexicon constructionfor information extraction (Riloff and Jones, 1999),and named entity classification (Collins and Singer,1999).
In our research, we use the bootstrapping ap-proach to learn paraphrases for emotions.3 DataThe text data from which we will extract paraphrasesis composed of four concatenated datasets.
Theycontain sentences annotated with the six basic emo-tions.
The number of sentences in each datasetis presented in Table 2.
We briefly describe thedatasets, as follows.3.1 LiveJournal blog datasetWe used the blog corpus that Mishne collected forhis research (Mishne, 2005).
The corpus contains815,494 blog posts from Livejournal 1, a free we-blog service used by millions of people to createweblogs.
In Livejournal, users are able to option-ally specify their current emotion or mood.
To se-lect their emotion/mood users can choose from a listof 132 provided moods.
So, the data is annotatedby the user who created the blog.
We selected onlythe texts corresponding to the six emotions that wementioned.3.2 Text Affect DatasetThis dataset (Strapparava and Mihalcea, 2007) con-sists of newspaper headlines that were used in theSemEval 2007-Task 14.
It includes a developmentdataset of 250 annotated headlines, and a test datasetof 1000 news headlines.
We use all of them.
The an-notations were made with the six basic emotions onintensity scales of [-100, 100], therefore a thresholdis used to choose the main emotion of each sentence.3.3 Fairy Tales DatasetThis dataset consists in 1580 annotated sentences(Alm et al, 2005), from tales by the Grimm brothers,H.C.
Andersen, and B. Potter.
The annotations usedthe extended set of nine basic emotions of Izard(1971).
We selected only those marked with the sixemotions that we focus on.3.4 Annotated Blog DatasetWe also used the dataset provided by Aman and Sz-pakowicz (2007).
Emotion-rich sentences were se-lected from personal blogs, and annotated with thesix emotions (as well as a non-emotion class, thatwe ignore here).
They worked with blog posts andcollected directly from the Web.
First, they prepared1http://www.livejournalinc.com36Dataset Happiness Sadness Anger Disgust Surprise FearLiveJournal 7705 1698 4758 1191 1191 3996TextAffect 334 214 175 28 131 166Fairy tales 445 264 216 217 113 165Annotated blog dataset 536 173 115 115 172 179Table 2: The number of emotion-annotated sentences in each dataset.Figure 1: High-level view of the paraphrase extractionmethod.a list of seed words for six basic emotion categoriesproposed by Ekman (1992).
Then, they took wordscommonly used in the context of a particular emo-tion.
Finally, they used the seed words for eachcategory, and retrieved blog posts containing one ormore of those words for the annotation process.4 Method for Paraphrase ExtractionFor each of the six emotions, we run our methodon the set of sentences marked with the correspond-ing emotion from the concatenated corpus.
Westart with a set of seed words form WordNet Af-fect (Strapparava and Valitutti, 2004), for each emo-tion of interest.
The number of seed words is the fol-lowing: for happiness 395, for surprise 68, for fear140, for disgust 50, for anger 250, and for sadness200.
Table 3 shows some of seeds for each categoryof emotion.Since sentences are different in our datasetsand they are not aligned as parallel sentences asin (Barzilay and McKeown, 2001), our algorithmconstructs pairs of similar sentences, based on thelocal context.
On the other hand, we assume that,if the contexts surrounding two seeds look similar,then these contexts are likely to help in extractingnew paraphrases.Figure 1 illustrates the high-level architecture ofour paraphrase extraction method.
The input to themethod is a text corpus for a emotion category anda manually defined list of seed words.
Before boot-strapping starts, we run the k-window algorithm onevery sentence in the corpus, in order to constructcandidate contexts.
In Section 4.5 we explain howthe bootstrapping algorithm processes and selectsthe paraphrases based on strong surrounding con-texts.
As it is shown in Figure 1, our method hasseveral stages: extracting candidate contexts, usingthem to extract patterns, selecting the best patterns,extracting potential paraphrases, and filtering themto obtain the final paraphrases.4.1 PreprocessingDuring preprocessing, HTML and XML tags areeliminated from the blogs data and other datasets,then the text is tokenized and annotated with partof speech tags.
We use the Stanford part-of-speechtagger and chunker (Toutanova et al, 2003) to iden-tify noun and verb phrases in the sentences.
In thenext step, we use a sliding window based on thek-window approach, to identify candidate contextsthat contain the target seeds.4.2 The k-window AlgorithmWe use the k-window algorithm introduced byBostad (2003) in order to identify all the tokenssurrounding a specific term in a window withsize of ?k.
Here, we use this approach to ex-tract candidate patterns for each seed, from thesentences.
We start with one seed and truncateall contexts around the seed within a window of?k words before and ?k words after the seed,until all the seeds are processed.
For these exper-iments, we set the value of k to ?5.
Therefore37Happiness: avidness, glad, warmheartedness, exalt, enjoy, comforting, joviality, amorous, joyful,like, cheer, adoring, fascinating, happy, impress, great, satisfaction, cheerful, charmed, romantic, joy,pleased, inspire, good, fulfill, gladness, merrySadness: poor, sorry, woeful, guilty, miserable, glooming, bad, grim, tearful, glum, mourning, joyless,sadness, blue, rueful, hamed, regret, hapless, regretful, dismay, dismal, misery, godforsaken, oppression,harass, dark, sadly, attritionAnger: belligerence, envious, aggravate, resentful, abominate, murderously, greedy, hatred, disdain,envy, annoy, mad, jealousy, huffiness, sore, anger, harass, bother, enraged, hateful, irritating, hostile,outrage, devil, irritate, angryDisgust: nauseous, sicken, foul, disgust, nausea, revolt, hideous, horror, detestable, wicked, repel,offensive, repulse, yucky, repulsive, queasy, obscene, noisomeSurprise: wondrous, amaze, gravel, marvel, fantastic, wonderful, surprising, marvelous, wonderment,astonish, wonder, admiration, terrific, dumfounded, trounceFear: fearful, apprehensively, anxiously, presage, horrified, hysterical, timidity, horrible, timid,fright, hesitance, affright, trepid, horrific, unassertive, apprehensiveness, hideous, scarey, cruel, panic,scared, terror, awful, dire, fear, dread, crawl, anxious, distrust, diffidenceTable 3: Some of the seeds from WordNet Affect for each category of emotion.the longest candidate contexts will have the formw1, w2, w3, w4, w5, seed, w6, w7, w8, w9, w10, w11.In the next subsection, we explain what features weextract from each candidate context, to allow us todetermine similar contexts.4.3 Feature ExtractionPrevious research on word sense disambiguation oncontextual analysis has acknowledged several localand topical features as good indicators of word prop-erties.
These include surrounding words and theirpart of speech tags, collocations, keywords in con-texts (Mihalcea, 2004).
Also recently, other fea-tures have been proposed: bigrams, named entities,syntactic features, and semantic relations with otherwords in the context.We transfer the candidate phrases extracted by thesliding k-window into the vector space of features.We consider features that include both lexical andsyntactic descriptions of the paraphrases for all pairsof two candidates.
The lexical features include thesequence of tokens for each phrase in the paraphrasepair; the syntactic feature consists of a sequence ofpart-of-speech (PoS) tags where equal words andwords with the same root and PoS are marked.For example, the value of the syntactic feature forthe pair ?
?so glad to see??
and ?
?veryhappy to visit??
is ?RB1 JJ1 TO V B1?and ?RB1 JJ2 TO V B2?, where indices indicateCandidate context: He was further annoyed by the jay bird?PRP VBD RB VBN IN DT NN NN?,65,8,?VBD RB?,?,was,?,?,?,He/PRP,was/VBD,further/RB,annoyed,by/IN,the/DT,jay/NN,bird/NN,?,?,jay,?,?IN DT NN?,2,2,0,1Table 4: An example of extracted features.word equalities.
However, based on the above ev-idences and our previous research, we also investi-gate other features that are well suited for our goal.Table 5 lists the features that we used for paraphraseextraction.
They include some term frequency fea-tures.
As an example, in Table 4 we show extractedfeatures from a relevant context.4.4 Extracting PatternsFrom each candidate context, we extracted the fea-tures as described above.
Then we learn extractionpatterns, in which some words might be substitutedby their part-of-speech.
We use the seeds to buildinitial patterns.
Two candidate contexts that con-tain the same seed create one positive example.
Byusing each initial seed, we can extract all contextssurrounding these positive examples.
Then we se-lect the stronger ones.
We used Collins and Singermethod (Collins and Singer, 1999) to compute thestrength of each example.
If we consider x as a con-text, the strength as a positive example of x is de-38Features DescriptionF1 Sequence of part-of-speechF2 Length of sequence in bytesF3 Number of tokensF4 Sequence of PoS between the seed and the first verb before the seedF5 Sequence of PoS between the seed and the first noun before the seedF6 First verb before the seedF7 First noun before the seedF8 Token before the seedF9 SeedF10 Token after the seedF11 First verb after the seedF12 First noun after the seedF13 Sequence of PoS between the seed and the first verb after the seedF14 Sequence of PoS between the seed and the first noun after the seedF15 Number of verbs in the candidate contextF16 Number of nouns in the candidate contextF17 Number of adjective in the candidate contextF18 Number of adverbs in the candidate contextTable 5: The features that we used for paraphrase extraction.fined as:Strength(x) = count(x+)/count(x) (1)In Equation 1, count(x+) is the number of timescontext x surrounded a seed in a positive exampleand count(x) is frequency of the context x. Thisallows us to score the potential pattern.4.5 Bootstrapping Algorithm for ParaphraseExtractionOur bootstrapping algorithm is summarized in Fig-ure 2.
It starts with a set of seeds, which are consid-ered initial paraphrases.
A set of extraction patternsis initially empty.
The algorithm generates candidatecontexts, from the aligned similar contexts.
The can-didate patterns are scored by how many paraphrasesthey can extract.
Those with the highest scores areadded to the set of extraction patterns.
Using the ex-tended set of extraction patterns, more paraphrasepairs are extracted and added to the set of para-phrases.
Using the enlarged set of paraphrases, moreextraction patterns are extracted.
The process keepsiterating until no new patterns or no new paraphrasesare learned.Our method is able to accumulate a large lexi-con of emotion phrases by bootstrapping from themanually initialized list of seed words.
In each it-eration, the paraphrase set is expanded with relatedphrases found in the corpus, which are filtered byusing a measure of strong surrounding context sim-ilarity.
The bootstrapping process starts by select-ing a subset of the extraction patterns that aim toextract the paraphrases.
We call this set the patternpool.
The phrases extracted by these patterns be-come candidate paraphrases.
They are filtered basedon how many patterns select them, in order to pro-duce the final paraphrases from the set of candidateparaphrases.5 Results and EvaluationThe result of our algorithm is a set of extraction pat-terns and a set of pairs of paraphrases.
Some of theparaphrases extracted by our system are shown inTable 6.
The paraphrases that are considered correctare shown under Correct paraphrases.
As explainedin the next section, two human judges agreed thatthese are acceptable paraphrases.
The results con-sidered incorrect by the two judges are shown un-39Algorithm 1: Bootstrapping Algorithm.For each seed for an emotionLoop until no more paraphrases or no more contexts are learned.1- Locate the seeds in each sentence2- Find similar contexts surrounding a pair of two seeds3- Analyze all contexts surrounding the two seeds to extractthe strongest patterns4- Use the new patterns to learn more paraphrasesFigure 2: Our bootstrapping algorithm for extracting paraphrases.der Incorrect paraphrases.
Our algorithm learnt 196extraction patterns and produced 5926 pairs of para-phrases.
Table 7 shows the number of extraction pat-terns and the number of paraphrase pairs that wereproduced by our algorithm for each class of emo-tions.
For evaluation of our algorithm, we use twotechniques.
One uses human judges to judge if asample of paraphrases extracted by our method arecorrect; we also measures the agreement betweenthe judges (See Section 5.1).
The second estimatesthe recall and the precision of our method (See Sec-tion 5.2.
In the following subsections we describethese evaluations.5.1 Evaluating Correctness with HumanJudgesWe evaluate the correctness of the extracted para-phrase pairs, using the same method as Brazilay andMcKeown (2001).
We randomly selected 600 para-phrase pairs from the lexical paraphrases producedby our algorithm: for each class of emotion weselected 100 paraphrase pairs.
We evaluated theircorrectness with two human judges.
They judgedwhether the two expressions are good paraphrasesor not.We provided a page of guidelines for the judges.We defined paraphrase as ?approximate conceptualequivalence?, the same definition used in (Barzilayand McKeown, 2001).
Each human judge had tochoose a ?Yes?
or ?No?
answer for each pair of para-phrases under test.
We did not include example sen-tences containing these paraphrases.
A similar Ma-chine Translation evaluation task for word-to-wordtranslation was done in (Melamed, 2001).Figure 3 presents the results of the evaluation: thecorrectness for each class of emotion according tojudge A, and according to judge B.
The judges weregraduate students in computational linguistics, na-tive speakers of English.We also measured the agreement between the twojudges and the Kappa coefficient (Siegel and Castel-lan, 1988).
If there is complete agreement betweentwo judges Kappa is 1, and if there is no agreementbetween the judges then Kappa = 0.
The Kappavalues and the agreement values for our judges arepresented in Figure 4.The inter-judge agreement over all the para-phrases for the six classes of emotions is 81.72%,which is 490 out of the 600 paraphrases pairs in oursample.
Note that they agreed that some pairs aregood paraphrases, or they agreed that some pairsare not good paraphrases, that is why the numbersin Figure 4 are higher than the correctness numbersfrom Figure 3.
The Kappa coefficient compensatesfor the chance agreement.
The Kappa value overall the paraphrase pairs is 74.41% which shows asignificant agreement.Figure 3: The correctness results according the judge Aand judge B, for each class of emotion.5.2 Estimating RecallEvaluating the Recall of our algorithm is difficultdue to following reasons.
Our algorithm is not ableto cover all the English words; it can only detect40DisgustCorrect paraphrases:being a wicked::getting of evil; been rather sick::feeling rather nauseated;feels somewhat queasy::felt kind of sick; damn being sick::am getting sickIncorrect paraphrases:disgusting and vile::appealing and nauseated; get so sick::some truly disgustingFearCorrect paraphrases:was freaking scared::was quite frightened; just very afraid::just so scared;tears of fright::full of terror; freaking scary::intense fear;Incorrect paraphrases:serious panic attack::easily scared; not necessarily fear::despite your fearAngerCorrect paraphrases:upset and angry::angry and pissed; am royally pissed::feeling pretty angry;made me mad::see me angry; do to torment::just to spiteIncorrect paraphrases:very pretty annoying::very very angry; bitter and spite::tired and angryHappinessCorrect paraphrases:the love of::the joy of; in great mood::in good condition;the joy of::the glad of; good feeling::good moodIncorrect paraphrases:as much eagerness::as many gladness; feeling smart::feel happySadnessCorrect paraphrases:too depressing::so sad; quite miserable::quite sorrowful;strangely unhappy::so misery; been really down::feel really sadIncorrect paraphrases:out of pity::out of misery; akward and depressing::terrible and gloomySurpriseCorrect paraphrases:amazement at::surprised by; always wonder::always surprised;still astounded::still amazed; unexpected surprise::got shockedIncorrect paraphrases:passion and tremendous::serious and amazing; tremendous stress::huge shockTable 6: Examples of paraphrases extracted by our algorithm (correctly and incorrectly).41Class of Emotion # Paraphrases Pairs # Extraction PatternsDisgust 1125 12Fear 1004 31Anger 670 47Happiness 1095 68Sadness 1308 25Surprise 724 13Total 5926 196Table 7: The number of lexical and extraction patterns produced by the algorithm.Figure 4: The Kappa coefficients and the agreement be-tween the two human judges.paraphrasing relations with words which appearedin our corpus.
Moreover, to compare directly withan electronic thesaurus such as WordNet is not fea-sible, because WordNet contains mostly synonymsets between words, and only a few multi-word ex-pressions.
We decided to estimate recall manually,by asking a human judge to extract paraphrases byhand from a sample of text.
We randomly selected60 texts (10 for each emotion class) and asked thejudge to extract paraphrases from these sentences.For each emotion class, the judge extracted expres-sions that reflect the emotion, and then made pairsthat were conceptually equivalent.
It was not feasi-ble to ask a second judge to do the same task, be-cause the process is time-consuming and tedious.In Information Retrieval, Precision and Recall aredefined in terms of a set of retrieved documents anda set of relevant documents 2.
In the following sec-tions we describe how we compute the Precision andRecall for our algorithm compared to the manually2http://en.wikipedia.org/wiki/Category of Emotions Precision RecallDisgust 82.33% 92.91%Fear 82.64% 88.20%Anger 93.67% 80.57%Happiness 82.00% 90.89%Sadness 82.00% 89.88%Surprise 79.78% 89.50%Average 84.23% 88.66%Table 8: Precision and Recall for a sample of texts, foreach category of emotion, and their average.extracted paraphrases.From the paraphrases that were extracted by thealgorithm from the same texts, we counted howmany of them were also extracted by the humanjudge.
Equation 2 defines the Precision.
On av-erage, from 89 paraphrases extracted by the algo-rithm, 74 were identified as paraphrases by the hu-man judge (84.23%).
See Table 8 for the values forall the classes.P =#Correctly Retrieved Paraphrases by the AlgorithmAll Paraphrases Retrieved by the Algorithm(2)For computing the Recall we count how many ofthe paraphrases extracted by the human judge werecorrectly extracted by the algorithm (Equation 3).R =#Correctly Retrieved Paraphrases by the AlgorithmAll Paraphrases Retrieved by the Human Judge(3)5.3 Discussion and Comparison to RelatedWorkTo the best of our knowledge, no similar researchhas been done in extracting paraphrases for emotionterms from corpora.
However, Barzilay and McKe-own (2001) did similar work to corpus-based iden-42tification of general paraphrases from multiple En-glish translations of the same source text.
We cancompare the pros and cons of our method comparedto their method.
The advantages are:?
In our method, there is no requirement for thecorpus to be parallel.
Our algorithm uses theentire corpus together to construct its boot-strapping method, while in (Barzilay and McK-eown, 2001) the parallel corpus is needed in or-der detect positive contexts.?
Since we construct the candidate contextsbased on the k-window approach, there is noneed for sentences to be aligned in our method.In (Barzilay and McKeown, 2001) sentencealignment is essential in order to recognizeidentical words and positive contexts.?
The algorithm in (Barzilay and McKeown,2001) has to find positive contexts first, thenit looks for appropriate patterns to extract para-phrases.
Therefore, if identical words do notoccur in the aligned sentences, the algorithmfails to find positive contexts.
But, our al-gorithm starts with given seeds that allow usto detect positive context with the k-windowmethod.A limitation of our method is the need for the initialseed words.
However, obtaining these seed wordsis not a problem nowadays.
They can be found inon line dictionaries, WordNet, and other lexical re-courses.6 Conclusion and Future WorkIn this paper, we introduced a method for corpus-based extraction of paraphrases for emotion terms.We showed a method that used a bootstrapping tech-nique based on contextual and lexical features andis able to successfully extract paraphrases using anon-parallel corpus.
We showed that a bootstrappingalgorithm based on contextual surrounding contextfeatures of paraphrases achieves significant perfor-mance on our data set.In future work, we will extend this techniques toextract paraphrases from more corpora and for moretypes of emotions.
In terms of evaluation, we willuse the extracted paraphrases as features in machinelearning classifiers that classify candidate sentencesinto classes of emotions.
If the results of the classifi-cation are good, this mean the extracted paraphrasesare of good quality.ReferencesCecilia Ovesdotter Alm, Dan Roth, and Richard Sproat.2005.
Emotions from text: machine learning for text-based emotion prediction.
In Proceedings of the Hu-man Language Technology Conference Conference onEmpirical Methods in Natural Language Processing(HLT/EMNLP 2005).Saima Aman and Stan Szpakowicz.
2007.
Identifyingexpressions of emotion in text.
In TSD, pages 196?205.Regina Barzilay and Kathleen McKeown.
2001.
Extract-ing paraphrases from a parallel corpus.
In Proceedingof ACL/EACL, 2001, Toulouse.Thorstein Bostad.
2003.
Sentence Based Automatic Sen-timent Classification.
Ph.D. thesis, University of Cam-bridge, Computer Speech Text and Internet Technolo-gies (CSTIT), Computer Laboratory, Jan.Jonathan Chevelu, Thomas Lavergne, Yves Lepage, andThierry Moudenc.
2009.
Introduction of a new para-phrase generation tool based on Monte-Carlo sam-pling.
In Proceedings of ACL-IJCNLP 2009, Singa-pore, pages 249?25.Michael Collins and Yoram Singer.
1999.
Unsupervisedmodels for named entity classification.
In proceedingsof the Joint SIGDAT Conference on Empirical Meth-ods in Natural Language Processing and Very LargeCorpora.Dipanjan Das and Noah A. Smith.
2009.
Paraphraseidentification as probabilistic quasi-synchronousrecognition.
In Proceedings of ACL-IJCNLP 2009,Singapore, pages 468?476.Paul Ekman.
1992.
An argument for basic emotions.Cognition and Emotion, 6:169?200.L.
Iordanskaja, Richard Kittredget, and Alain Polguere,1991.
Natural Language Generation in Artificial In-telligence and Computational Linguistics.
KluwerAcademic.Carroll E. Izard.
1971.
The Face of Emotion.
Appleton-Century-Crofts., New York.Irene Langkilde and Kevin Knight.
1998.
Generationthat exploits corpus-based statistical knowledge.
InCOLING-ACL.Ilya Dan Melamed.
2001.
Empirical Methods for Ex-ploiting Parallel Texts.
MIT Press.Rada Mihalcea.
2004.
Co-training and self-trainingfor word sense disambiguation.
In Natural LanguageLearning (CoNLL 2004), Boston, May.43George Miller, Richard Beckwith, Christiane Fellbaum,Derek Gross, and Katherine Miller, 1993.
Introduc-tion to Wordnet: An On-Line Lexical Database.
Cog-nitive Science Laboratory, Princeton University, Au-gust.Gilad Mishne.
2005.
Experiments with mood classifica-tion in blog posts.
ACM SIGIR.Ellen Riloff and Rosie Jones.
1999.
Learning dictio-naries for information extraction by multi-level boot-strapping.
In Proceedings of the Sixteenth NationalConference on Artificial Intelligence, page 10441049.The AAAI Press/MIT Press.Sidney Siegel and John Castellan, 1988.
Non ParametricStatistics for Behavioral Sciences.
.
McGraw-Hill.Carlo Strapparava and Rada Mihalcea.
2007.
Semeval-2007 task 14: Affective text.
In Proceedings of the 4thInternational Workshop on the Semantic Evaluations(SemEval 2007), Prague, Czech Republic, June 2007.Carlo Strapparava and Alessandro Valitutti.
2004.Wordnet-affect: an affective extension of wordnet.
InProceedings of the 4th International Conference onLanguage Resources and Evaluation (LREC 2004),Lisbon, May 2004, pages 1083?1086.Kristina Toutanova, Dan Klein, Christopher Manning,and Yoram Singer.
2003.
Feature-rich part-of-speechtagging with a cyclic dependency network.
In Pro-ceedings of HLT-NAACL, pages 252?259.Xiaoyin Wang, David Lo, Jing Jiang, Lu Zhang, andHong Mei.
2009.
Extracting paraphrases of tech-nical terms from noisy parallel software corpora.
InProceedings of ACL-IJCNLP 2009, Singapore, pages197?200.David Yarowsky.
1995.
Unsupervised word sense dis-ambiguation rivaling supervised methods.
In Proceed-ings of the 33rd Annual Meeting of the Association forComputational Linguistics, pages 189?196.Shiqi Zhao, Xiang Lan, Ting Liu, , and Sheng Li.2009.
Application-driven statistical paraphrase gen-eration.
In Proceedings of ACL-IJCNLP 2009, Singa-pore, pages 834?842.44
