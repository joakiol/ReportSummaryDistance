Statistical Matching of Two OntologiesSatosh i  Sek ineComputer '  Scmnce Depar tmentNew York Umvermty715 Broadway,  7th floorNew York,  NY  10003 USA\[seklne \[klyo7793\] @cs nyu eduKiyosh i  Sudo Takano  OginoE lec t romc D lc tmnary  Research78-1 Sakumahlgan ,  Kanda,  Chmda-kuTokyo,  101-0026 Japanoglno@edr co 3P1 In t roductmnStandardizing ontologms ~s a challenging taskOntologms have been created based on differentbackgrounds, different purposes and different peo-ple However, standardizing them is useful notonly for applications, uch as Machine Translationand Information Retrmval, but also to Improve the.ontologms themselves During the process of stan-dardization, people can find bugs or gaps in on-tologms So standardlzatmn b ngs benefits com-pared to just using them separately There is acommittee for standardlzmg ontologaes at ANSI,the "ANSI Ad-Hoc Group for Ontology Stan-dards" (Hovy 1996)Although there have been a few attempts tomerge and compare ontologaes, th,s work ~s stillat a prehmmary stage of research (Ogmo et al1997) attempts manual mergang of EDR (EDR1996) (Mlyoshl et al1996) and WordNet (Word-net) (Miller 1995), (Utlyama and Hashlda 1997)used statistical methods to merge EDR and Word-Net (Pangloss) is also working on standardizingontologms It is certain that manual methods havegreat difficulty in matching the entire ontologlesIt would require three thousand years for a per-son to check all possible node pairings, if the twoontologms have 40 000 nodes each.and eachjudge-ment takes a minute So automatic methods areneeded to find matches automatically or at leastto narrow down the candidates for matchingIn this paper, we investigate a simple statisticalmethod for matching two ontologms The methodcan appl~ to any ontologms which are formulatedfrom ls-a relationships In our experiments, weused EDR and \VotdNet Tins ~ork is sumlar tothe work in (UtL~ama nd Hashlda 1997) Theydefined the task as the MWM (Maximum V~elgntklatch) of bipartite graphs, an approach whichis bas~cally common to most ontology matchingschemes The information they used is partiallyfuzzy, i e for calculating the distance between twonodes, they used the information from each nodeand its neighborhood, not distinguishing betweenmformatmn from parent and child nodes How-ever, since the structure of the ontologms (the re-lation between parent and children) is slgmficant,it might be better to utilize such structural refor-mation In our experiments, we will focus on thisissue, rather than trying to achieve a higher per-formance The importance of parent, child andgrandchild information will be examined We willconduct several experiments with or without someof the mformatlon It is also important to dlsco~erwhat welghtmg balance gives good matches2 Onto log iesFirst we will briefly explain the ontologms we usedm our experiments2.1 EDRThe EDR Concept Dmtlonary contains 400,000concepts hsted m the Japanese and Enghsh WordDmtlonanes of 200,000 words each The EDRConcept Dictionary is one of the five types of EDRdictionaries, the others are the Word Dmtlonarmsfor English and Japanese the Blhngual Dictio-nary, the Coocurrence Dictionary, and the Tech-mcal Telmmology Dxctlonar} The EDR Con-cept Dictionary consists of three sub-dmuonanesthe Headconcept Dlctxonaz} contains concept ex-planations m natural language (both m Engh~hand Japanese),~the Concept Classification Dmuo-nar} contains a set of ls-a relationships, and theConcept Description Dictionary contains pairs ofconcepts that have certain semantic relationshipsother than ls-a relationship 1 e object, agent9oal, zmplement a-object (object of a particular at-tribute), place, scene and causeThe Concept Classification Dmtlonar~ classifiesall the 400 000 concepts based on their meaningA polysemous ~ord is put into several word cias-sffieatmns (concepts) As multiple inheritance l~allowed, the entire structure is not a tree but aDAG (directed acychc graph) There are 6,000intermediate nodes and the maximum depth is 162 2 WordNetWordNet (Wordnet) is an English ontology Thenodes are represented by a set of synonym words(called ' s?
nsets ') WordNet contains 60,557 noun69synsets, 11,363 adjective synsets, and 3,243 ad-verb synsets Between synsets, there are rela-tions whmh include (but are not hmited to) hy-pernymy/hyponymy, antonymy, entailment andmeronymy/holonymy A word or collocatmn mayappear m more than one synset, and in more thanone part of speech The words m a synset axe log-ically grouped such that  they are interchangeablem some context3 ExperimentsThe basic idea of the matching m to find the dm-tance (similarity) between a node in EDIt and anode m WordNet There could be several strate-gins for defining a distance between two nodes, ~ewill use the words attached to each node and itsparent, child and grandchild m the computatmnWe did not use the descmptmns of conceptsAs a prehmmary experiment, we restricted thenumber of nodes to be considered, because bothontologms are big We used the nodes at the top5 levels (distance from the top is at most 5) anddeleted nodes which have no English words and nodescendents In EDIt  (some EDIt nodes have onlyJapanese words) This left 14,712 nodes In EDItand 5,185 m WordNet Even with these restric-tion, the number of possible pmrmgs Is 76,281,720Our target m to find good matches among them3 1 Definit ion of  DistanceThe dmtance between nodes is defined based onthe notion which ~s commonly used, the dine co-efficient Assume the node N1 m ontologyl hasnl words and N~ m ontology2 has n2 words, andthere are m words m common The dice coefficmnt(DC) is defined as follows2mDC(NI ,N2)  =nl  -t- n 2Now we define the basic distance as 1 minus the~alue The smaller the distance, the closer the twonodes2mdzst(N1, N~) = 1 (1)n 1 -4- n2We now define the distance of two nodes(N1,N~.)
based on the basra dlstance definitionThe words m parents, children and glandchildrenare also used Such nodes are taken as a bag ofnodes, le  only one set of words is created foreach category regardless of the number of node~Such a bag of nodes is represented as N parent andso on The distance of each category is calcu-lated just hke the basic d~stance In the followingequation, cat should be replaced by parent, ztsel/,chzld and gchdd (for grandchild)dzstcat(N1,N2) = dzst(N~at,N~ ~t)2rn cat= 1Then interpolation is used to merge the fourbasic distances in order to keep the rangefrom 0 to 1 We Introduce four coefficientscParent,cttsel/,acMld,c gch~ld tO define the node dls-tance , D(Nt ,  N2)D(N1,N2) = c p .
.
.
.
t dzstP~.e,~t(N1,N2 ) +c 't~e~/ d:st'ts~i(Ni,N~) +cCa'ta dzstChad(Ni,N2) +cgchtld dzstgChaU(N1, N2)cParent "1" cttself "f" cChtld + C gch'ld : 1 (2)The coefficients (cent's) will be the lraportantfactor in the experiments As will be describedm the next section, we use several combinationsof the coefficients to observe which mformation tsimportant3 2 Exper imentsWe conducted eight experiments using differentcombinations of the coefficients The first expem-ment uses only the reformation in the nodes them-selves, while other expemments use the node andparent, the node and children, or all four setsTable 1 shows the coefficient combinations usedm the expemmentsE?2345678parents self child gch i ld00  10 00 0000 03 07 00-00  05 05 00O0 07  03 O003  07  O0 O0 -02 05 03 O002 06 02 0002 05 02 01- -Table.1 Coefficmnt- C0mbmatlon3 2 1 Ana lysm of  the  statmt~cal  resul tsBefore descmblng the e~aluatlon results, someinteresting anal~ ses are presented m thin sectmnThese analyses do not concern directly the evalu-atlon of the experiment, but indicate the natmeof the expemments Ol the nature of the ontolog~esNumber  of  outputsWe used a threshold to resulct the nuInber ofoutputs If the distance ~s greater than 0 9, theresult is not generated Table 2 shows the numberof outputs m each experiment Itecall that thereare 76,281,720-possible pairings of nodes It isinteresting to see that the numbers are almost thesame The number of outputs in E'cperlment-4is shghtly smaller, we believe thin is because theweight asmgned to the nodes themsel~es, wluchgl~es the greatest contmbutmn, ~s low70Experiment (Coefficients)(00, ~ o, 00,00)2 (00 ,07 ,03 ,00)3 (00, 05, 05,00)4 (00, 03, 0 7, 00)5 (03, 07, 00,00)" 6 (02 ,05 ,03 ,00)7 (02, 06, 0 2, 00)8 (02, 05, 02, 0 1)Output10,27510,15110,1519,09310,79910,09810,20610,028Table 2 Number of OutputsThe numbers are around 10,000, which repre-sents 0 013% of the possible matches This sug-gests that there is a posslblllty of narrowing downthe matches to be examined by a human, as thedistance 0 9 ,s very large and the number of out-puts ,s so small To prove th,s assumption, wehave to conduct an evaluatmn to see ff there aregood matches which were not generated Th,s ,sbeyond the evaluatmn m thls paper, because itreqmres manual matching from scratch We willdiscuss this laterComplete MatchWe can find the number of complete matches(which have exactly the same word(s)) by count-mg the pmrs w~th d,stance 0 0 m Expenment-1The number of complete matches i 1778, whlch ,sqmte large compared to the number of nodes un-der conslderatmn m WordNet (about 5,000) Also,by counting up the number of pmrs w,th distance0 0 m Experiment-5, we can find parent-completematches whmh are complete matches where theparents also have the same words The number ofparent-complete matches is 1 This is surprisinglysmall, even cons,dermg that we used only subsetsof the 0ntologms The only parent-match is thefollowing-parent Invertebratechild arthropodNaturally people mlght guess that there would bemore parent-complete matches For example, thename of a mammal might be a plaus,ble candi-date (where the parent is "mammal" and childis, for example, "elephant") However, this is notthe case "Elephant" and "mammal" appear asfollows (unrelated nodes are not sho~n)EDR<no Engl~.sh word, Japanese=mammal>+ .
.
.
.
.
<mammal, J -Descnptxon-\[ an ~nstance of mammal>+ ..... <elephant>WordNet<mammal>+ ..... <probos c~dean, probosc~dlan>+ ...... <elephant>Thls is one of the typlcal problems of ontolog}deslgn, how detail concepts should be mtrocucedAlso, there is a translatlon problem m EDR,  ,esometimes there ,s words or a descnptmn m onlyone languageThere are some other "reasons why the numberof parent-matches ,s so small?
Some nodes m EDR have no words assocl-ated wlth them Thls is how the EDR Class,-ficatlon Dmtlonary was deslgned It ~s basedon the classfficat,on of words into some pre-defined boxes, and not creating hmrarchy ofwords It would be better to use the con-cept descnptlons of the dlctlonary, althoughit is not clear how to compare a s)nset (set ofwords) and a descnptlon Also, we mlght beable to use mformatlon written m Japanesewhen there ,s no Enghsh word but there areJapanese words?
WordNet uses a synset to represent a node,whereas EDR's  node Is pnmarlly representedby a descriptlon, there could be differencescaused by thls The average numbers ofwords m a node are also differentThere were no chlldren-matches, whmh arecomplete matches where the words m the childnodes are also the same The closest matches mExperiment-2 and 3 are the followingEDRparent (*) yearchildren school yearWordNetparent (*) yearchildren anomallstlc year, lunaryear, school year, academlc year,solar year, troplcal year, astro-nomlcal year, equinoctial year(There are actually 4 child nodes )3 2 2 EvaluatmnAs ~t ~s lmposs~ble to evaluate all the results, ~eselected four ranges (rank 1 to 20, 501 to 520, 2001to 2020, and 9001 to 9020) and the data m theseranges was evaluated manually E~aluatmn ~asdone by putting the matches into three categories?
A Two nodes are completel:y the same con-cept?
B Other than A and C?
C Two nodes me completely d~fferent con-ceptsCategory B includes several different things, in-cluding partml matches and ambiguous cases b3the manual evaluatmn However, the number ofresults m th~s category was not so large, so ~tshould not affeSt the overall evaluatmn Table 3shows the evaluatmn result The columns repre-sent the four ranges and the each row representsone of the e,ght experiments An element has71Experiment 1-20 501-520 2001-2020 9001-9020-1(00, 10,00,00)2 (00, 07,03,  00)3 (00, 05,05,  00)4 (00,03,07,  00)5 (03, o 7, o o, oo)6 (02 ,05 ,03 ,00)7 (02 ,06 ,02 ,00)8 (02, 05,02,01)311116 8/1111611/13 6/1113611113 6/1113211117 10131710/1/9 7/1/1211/1 /8  6 /1 /1311 /1 /8  6 /1 /1311 /1 /8  6 /1 /134/2 /143 /3 /143 /3 /144 /4 /122 /3 /152 /3 /152 /3 /152 /3 /155/4/111/2/17i'/2/175/5/106 /5 /95 /9 /61/7/125/6 /9Table 3 Evaluauon Result.q ,~  ?three numbers, corresponding to the categorms A,B and C, separated by "/" We can't make a directcomparison to other methods For example, while(Utlyama and Hashlda 1997) also used EDR andWordNet, they used only.connected componentsand we i/v/pose d the level restnctmn However,relative comparisons among our 8 experiments ar, emeaningful and important We will discuss themm the next section3 3 DmcussmnUsing only the nodes themselves (Exp-1)In Experiment-i, only the words m the nodes be-mg compared are used The evaluatmn result wasnot very good For example, there are only 3matches of category A m the highest range Basedon an exammatmn of the results, we observed thatthis is due to word polysemy Even ff two nodeshave a word m common, the word could have sev-eral meanings, and hence the corresponding odescould have different meamngs For example, theword "love" can mean "emotion" or "no point intenms" To see how the results we obtained m~ghtarise, suppose a word has 4 senses in ontology1and 5 m ontology2, and there are 3 senses whichare the same m the' two ontologms Then there are20 pairings of the senses and out of them only3can be judged as category A Although this is justan assumptmn, the reahty m~ght not be that farfrom this explanation based on the observation ofthe resultAdd ing  chdd nodes (Exp-2,3,4)In Experiment-2,3 and 4, we used the mforma-tmn of the nodes themselves and their child nodesThe evaluatmn results for Experiment-2 and 3 arethe same, both of them have 6 A's in the h~ghestrange The number is twine that in Expenment-1 This improvement is due to dlsamblguatmn ofpolysemous words For example, the same senseof a polysemous word might have similar wordsin the child nodes, whereas it might be rare thatdifferent senses have the same words m the twoontologmsIn Experiment-4, we put more weight on childnodes rather than the nodes themselves Thisexperiment was conducted based on the assump-tmn that the number of words m child nodes maybe much larger than the number of words in thenodes themselves However, th~s turns out to givea degradation at the higher range Observing theresult, the matches at the h~gher range have ~er~few words m the child nodes If the number ofchdd nodes are small in both ontologms and theyhave many m common, the d~stance between thenodes becomes extremely small Th~s could beboth beneficml and harmful It can p,ck up somematches which could not be found m Experiment-1, but the matches could be good or bad ones Thefollowmg example is a good one which is actuallyfound at the ninth rank m Experiment-4EDItparent(*) No Engllsh word, J-descrlptlon"target anlmals huntlng or flshlng"chlldren game, k111WordNetpareni; (*) prey, quarrychildren gameAdd ing  parent  nodes (Exp-5)In Experiment-5, the words in the nodes them-selves and their parent nodes are used It canbe naturally thought that the words in the par-ent nodes are useful to dlsamblguate polysemouswords The result confirmed this In the high-est range, category A has 10 matches out of 20which ,s three t,mes as much as m Experiment-I,and twice that m Experiment-2 and 3Using parents ,  self and chddren (Exp-6,7)In Expernnent-6 and 7 ~olds in parent, self andchild nodes are used with different welghtmgs Alle~aluaUon results are ~dentlcal e<cept he lowestrange, and these have the largest number of A'sat the hlghest range among all of the experimentsThis mdmates that three sources together isbetterthan any two or an~ single source of reformationAdd ing  grandchdd nodes (Exp-8)Finally, m Experiment-8, words m all four kindsof nodes, parent, self, child and grandchild, areused The evaluation result is the same as that m72Experiment-6, and we could not see improvementby adding grandchild information Actually, byobserving the result, we can see that the informa-tion at the grandchild level is not so usefulObserv ing the evaluat ion processFrom the evaluation process, we understand thata human uses not only the four kinds of mforma-tmn, but also mformatmn ,n grandparent or thesuccessor's nodes Some ,mprovement rmght beobta, ned if we used such mformatmn Also, wem,ght be able to achmve more improvement byusing sibhng nodes, and the result of distance cal-culation of other nodesAs we presented by the example of "mammal"and "elephant", there are the cases where m oneontology a relatmnshlp m parent-child, but m theother ontology ~t m a grandparent-grandchild re-laUonsh,p or a slbhng-relationship It would bebetter ff we took the charactenstms of each ontol- "ogy and differences of the ontologms into accountm the calculatmn In particular, the reformationm ancestors might be very usefulOther  distance definit ionsIn our method, we simply used the dice coefficmntHowever, we can use more comphcated orsophmt,-cared measures For example, (Resmk 1995) pro-posed a measure of semant,c similarity based onthe notmn of information content Although thinproposal defines mmflanty between two nodes ma single taxonomy or ontology, we may be able toapply , tm our mtuatmn(Aglrre et al1995) proposed conceptual dm-tance between odes on ontologles captured by aConceptual Density formula It is also a defimtmnm a single ontologyRecently, (O'Hara and et al1998) conductedan experiment of matchmg two ontologms, Word-consider the characteristics of the ontologms Onegoal of our future ~ork is to understand how toincorporate such characteristics into these statm-t,cal methods5 AcknowledgementsWe would like to thank ProfRalph Grmhmanat New York Un,verslty for his suggestions andanonymous revmwers who gave us some severecommentsReferencesEneko Aglrre and German Rlgau, "A Proposal forWord sense Dmamb,guatmn using Conceptionaldistance" Proc of the 1st Internatzonal Confer-ence on Recent Advances m natural LanguageProcessing 1995EDRElectromc D1ctmnary Version 1 5 TechmcalGuide EDR TR2-O07, 1996Eduard Hovy "Creating aLarge Ontology", ANSIAd Hoc Group on Ontology, Stanford Umver-sity, 1996George Miller "WordNet A lex,cal database forEnglish" Communzcatzons f the ACM, 38{1i)pp39-~1, 1995Hldeo Mlyoshl, Ken j, Sugiyama, Masah~roKobayash, and Takano Ogmo "An Overview ofthe EDR Electronic D,ctionary and the CurrentStatus of Its Utflmatmn", Proc o/COLING-g6,1996Takano Ogmo, Hldeo Mlyoshl, MasahlroKobayashl, Fumlhlto Nmhmo and Junhch, Tsu-ju "An Experiment on Matching EDR ConceptClassfficahon Dictionary with WordNet', Proco/IJICAI-97, 1997Net and the Mlkrokosmos Ontology They used .i~..Tom O'Hara, Kaw Mahesh and Serge, Nlren-the definmon proposed m (Resmk 1995) among . '
burg, "LexlcalAcqu~sltmn with WordNet andother heunstms It m not so clear hov~"to comparethe method to our method, as they used severalheur,stms whmh m not d,rectly comparable to ourmethod However we noticed that it is a very Im-portant o mvestlgate their methods4 Conc lus ionWe proposed a statmtmal method of matching twoontologms Since It m impossible to exhaust,velyconsider all matches by hand, automatic methodsto mak~ matches or to narrow down the cand,datematches are needed Although the experimentsare prehmmary, they show what kinds of mforma-tmn m useful m statmtlcal matching We foundthat parent nodes, bemdes the nodes themselves,are the most useful for matching by dmamb,guat-mg the synonyms of words The best performancewas achieved by using words m parent, tself andchild nodes We observed that ~t is important othe Mlkrokosmos Ontolog)" Proc o/the COL-ING/ACL Workshop on Usage of WordNet mNatural Language Processzng Systems t998Pangloss Project (InformaUon Scmnces Insutute(ISl) / Uinver-mty of Southern Cahforma (USC)) homepage"ht tp / /www ,s, edu/natural-language/nlp.at.is, html"Phlhp Resmk, "Using Information Content toEvaluate Semant,c S,mflant~ m a Taxonomy"Proc o/ the 14th Internatwnal Joint Confer-ence on Artzficzal Intelhgence, 1995UTtYAMA Masao, HASHIDA Ko,tL "Bottom-up Ahgnment of Ontologms" Proc of IJCAI97Workshop on Ontologzes and Multdzngual Nat-ural Language Processing 1997WordNet Homepage"ht tp / /www cogsc, princeton edu/wn/"73
