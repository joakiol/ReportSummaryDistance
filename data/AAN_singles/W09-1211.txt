Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL): Shared Task, pages 73?78,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsExploring Multilingual Semantic Role LabelingBaoli Li, Martin Emms, Saturnino Luz, Carl VogelDepartment of Computer ScienceTrinity College DublinDublin 2, Ireland{baoli.li,mtemms,luzs,vogel}@cs.tcd.ieAbstractThis paper describes the multilingual semanticrole labeling system of Computational Lin-guistics Group, Trinity College Dublin, for theCoNLL-2009 SRLonly closed shared task.The system consists of two cascaded compo-nents: one for disambiguating predicate wordsense, and the other for identifying and classi-fying arguments.
Supervised learning tech-niques are utilized in these two components.As each language has its unique characteris-tics, different parameters and strategies haveto be taken for different languages, either forproviding functions required by a language orfor meeting the tight deadline.
The system ob-tained labeled F1 69.26 averaging over sevenlanguages (Catalan, Chinese, Czech, English,German, Japanese, and Spanish), which ranksthe system fourth among the seven systemsparticipating the SRLonly closed track.1 IntroductionSemantic role labeling, which aims at computa-tionally identifying and labeling arguments ofpredicate words, has become a leading researchproblem in computational linguistics with the ad-vent of various supporting resources (e.g.
corporaand lexicons) (M?rquez et al, 2008).
Word seman-tic dependencies derived by semantic role labelingare assumed to facilitate automated interpretationof natural language texts.
Moreover, techniques forautomatic annotation of semantic dependencies canalso play an important role in adding metadata tocorpora for the purposes of machine translationand speech processing.
We are currently investi-gating such techniques as part of our research intointegrated language technology in the Center forNext Generation Localization (CNGL,http://www.cngl.ie).
The multilingual nature of theCoNLL-2009 shared task on syntactic and seman-tic dependency analysis, which includes Catalan,Chinese, Czech, English, German, Japanese, andSpanish (Haji?
et al, 2009), makes it a good test-bed for our research.We decided to participate in the CoNLL-2009shared task at the beginning of March, signed theagreement for getting the training data on March2nd, 2009, and obtained all the training data (espe-cially the part from LDC) on March 4th, 2009.
Dueto the tight time constraints of the task, we chose touse existing packages to implement our system.These time constraints also meant that we had toresort to less computationally intensive methods tomeet the deadline, especially for some large data-sets (such as the Czech data).
In spite of these dif-ficulties and resource limitations, we are proud tobe among the 21 teams who successfully submittedthe results1.As a new participant, our goals in attending theCoNLL-2009 SRLonly shared task were to gainmore thorough knowledge of this line of researchand its state-of-the-art, and to explore how well asystem quickly assembled with existing packagescan fare at this hard semantic analysis problem.Following the successful approaches taken bythe participants of the CoNLL-2008 shared task(Surdeanu et al, 2008) on monolingual syntacticand semantic dependency analysis, we designedand implemented our CoNLL-2009 SRLonly sys-tem with pipeline architecture.
Two main compo-nents are cascaded in this system: one is fordisambiguating predicate word sense 2 , and theother for identifying and classifying arguments for1According to our correspondence with Dr. Jan Haji?, totally31 teams among 60 registered ones signed and got the evalua-tion data.2As predicate words are marked in the CoNLL-2009 datasets,we don?t need to identify predicate words.73predicate words.
Different supervised learningtechniques are utilized in these two components.For predicate word sense disambiguation (WSD),we have experimented with three algorithms: SVM,kNN, and Na?ve Bayes.
Based on experimentalresults on the development datasets, we choseSVM and kNN to produce our submitted officialresults.
For argument identification and classifica-tion, we used a maximum entropy classifier for allthe seven datasets.
As each language has its uniquecharacteristics and peculiarities within the dataset,different parameters and strategies have to be takenfor different languages (as detailed below), eitherfor providing functions required by a language orfor meeting the tight deadline.
Our official submis-sion obtained 69.26 labeled F1 averaging over theseven languages, which ranks our system fourthamong the seven systems in the SRLonly closedtrack.The rest of this paper is organized as follows.Section 2 discusses the first component of our sys-tem for predicate word sense disambiguation.
Sec-tion 3 explains how our system detects andclassifies arguments with respect to a predicateword.
We present experiments in Section 4, andconclude in Section 5.2 Predicate Word Sense DisambiguationThis component tries to determine the sense of apredicate word in a specific context.
As a sense ofa predicate word is often associated with a uniqueset of possible semantic roles, this task is alsocalled role set determination.
Based on the charac-teristics of different languages, we take differentstrategies in this step, but the same feature set isused for different languages.2.1 MethodsIntuitively, each predicate word should be treatedindividually according to the list of its possiblesenses.
We therefore designed an initial solutionbased on the traditional methods in WSD: repre-sent each sense as a vector from its definition orexamples; describe the predicate word for disam-biguation as a vector derived from its context; andfinally output the sense which has the highest simi-larity with the current context.
We also consideredusing singular value decomposition (SVD) to over-come the data sparseness problem.
Unfortunately,we found this solution didn?t work well in our pre-liminary experiments.
The main problem is that thedefinition of each sense of a predicate word is notavailable.
What we have is just a few example con-texts for one sense of a predicate word, and thesecontexts are often not informative enough forWSD.
On the other hand, our limited computingresources could not afford SVD operation on ahuge matrix.We finally decided to take each sense tag as aclass tag across different words and transform thedisambiguation problem into a normal multi-classcategorization problem.
For example, in the Eng-lish datasets, all predicates with ?01?
as a senseidentifier were counted as examples for the class?01?.
With this setting, a predicate word may beassigned an invalid sense tag.
It is an indirect solu-tion, but works well.
We think there are at leasttwo possible reasons: firstly, most predicate wordstake their popular sense in running text.
For exam-ple, in the English dataset (training and develop-ment), 160,477 of 185,406 predicate occurrences(about 86.55%) take their default sense ?01?.
Sec-ondly, predicates may share some common rolesets, even though their senses may not be exactlythe same, e.g.
?tell?
and ?inform?.Unlike the datasets in other languages, the Japa-nese dataset doesn?t have specialized sense tagsannotated for each predicate word, so we simplycopy the predicted lemma of a predicate word to itsPRED field.
For other datasets, we derived a train-ing sample for each predicate word, whose classtag is its sense tag.
Then we trained a model fromthe generated training data with a supervised learn-ing algorithm, and applied the learned model forpredicting the sense of a predicate word.
This isour base solution.When transforming the datasets, the Czech dataneeds some special processing because of itsunique annotation format.
The sense annotation fora predicate word in the Czech data does not takethe form ?LEMMA.SENSE?.
In most cases, nospecialized sense tags are annotated.
The PREDfield of these words only contains ?LEMMA?.
Inother cases, the disambiguated senses are anno-tated with an internal representation, which isgiven in a predicate word lexicon.
We decomposedthe internal representation of each predicate wordinto two parts: word index id and sense tag.
Forexample, from ?zv??en?
v-w10004f2?
we know ?v-w10004?
is the index id of word ?zv??en?
?, and?f2?
is its sense tag.
We then use these derived74sense tags as class tags and add a class tag ?=?
forsamples without specialized sense tag.For each predicate word, we derive a vector de-scribing its context and attributes, each dimensionof which corresponds to a feature.
We list the fea-ture types in the next subsection.
Features appear-ing only once are removed.
The TF*IDF weightingschema is used to calculate the weight of a feature.Three different algorithms were tried during thedevelopment period: support vector machines(SVM), distance-weighted k-Nearest Neighbor(kNN) (Li et al, 2004), and Na?ve Bayes with mul-tinomial model (Mccallum and Nigam, 1998).
Asto the SVM algorithm, we used the robustLIBSVM package (Chang and Lin, 2001), with alinear kernel and default values for other parame-ters.
The algorithms achieving the best results inour preliminary experiments are chosen for differ-ent languages: SVM for Catalan, Chinese, andSpanish; kNN for German (k=20).We used kNN for English (k=20) and Czech(k=10) because we could not finish training withSVM on these two datasets in limited time.
Evenwith kNN algorithm, we still had trouble with theEnglish and Czech datasets, because thousands oftraining samples make the prediction for theevaluation data unacceptably slow.
We thereforehad to further constrain the search space for a newpredicate word to those samples containing thesame predicate word.
If there are not samples con-taining the same predicate word in the training data,we will assign it the most popular sense tag (e.g.?01?
for English).How to use the provided predicate lexicons is achallenging issue.
Lexicons for different languagestake different formats and the information includedin different lexicons is quite different.
We deriveda sense list lexicon from the original predicatelexicon for Chinese, Czech, English, and German.Each entry in a sense list lexicon contains a predi-cate word, its internal representation (especially forCzech), and a list of sense tags that the predicatecan have.
Then we obtained a variant of our basesolution, which uses the sense list of a predicateword to filter impossible senses.
It works as fol-lows:- Disambiguate a new predicate with the basesolution;- Choose the most possible sense from all thecandidate senses obtained in step 1: if thebase classifier doesn?t output a vector ofprobabilities for classes, only checkwhether the predicted one is a valid sensefor the predicate;- If there is not a valid sense for a new predi-cate (including the cases where the predi-cate does not have an entry in the sense listlexicon), output the most popular sense tag;Unfortunately, preliminary experiments on theGerman and Chinese datasets didn?t support to in-clude such a post-processing stage.
The perform-ance with this filtering became a little worse.Therefore, we decided not to use it generally, butone exception is for the Czech data.With kNN algorithm, we can greatly reduce thetime for training the Czech data, but we do haveproblem with prediction, as there are totally469,754 samples in the training dataset.
It?s a time-consuming task to calculate the similarities be-tween a new sample and all the samples in thetraining dataset to find its k nearest neighbors, thuswe have to limit the search space to those samplesthat contain the predicate word for disambiguation.To process unseen predicate words, we used thederived sense list lexicon: if a predicate word fordisambiguation is out of the sense list lexicon, wesimply copy its predicted lemma to the PRED field;if no sample in the training dataset has the samepredicate word, we take its first possible sense inthe sense list lexicon.
With this strategy, our sys-tem can process the huge Czech dataset in shorttime.2.2 FeaturesThe features we used in this step include3:a.
[Lemma | (Lemma with POS)] of all words in the sen-tence;b.
Attributes of predicate word, which is obtained fromPFEAT field by splitting the field at symbol ?|?
andremoving the invalid attribute of ?*?;c.
[Lemma | POS] bi-grams of predicate word and its[previous | following] one word;d. [Lemma | POS] tri-grams of predicate word and its[previous | following] two words;e. [Lemma | (Lemma with POS)] of its most [left | right]child;f. [(Lemma+Dependency_Relation+Lemma) | (POS+Dependency_Relation+POS)] of predicate word andits most [left | right] child;3We referred to those CoNLL-2008 participants?
reports, e.g.
(Ciaramita et al, 2008), when we designed the feature sets forthe two components.75g.
[Lemma | (Lemma with POS)] of the head of the pre-dicate word;h. [(Lemma+Dependency_Relation+Lemma) | (POS+D-ependency_Relation+POS)] of predicate word and itshead;i.
[Lemma | (Lemma with POS)] of its [previous | fol-lowing] two brothers;j.
[Lemma | POS | (Dependency relation)] bi-gram ofpredicate word and its [previous | following] onebrother;k. [Lemma | POS | (Dependency relation)] tri-gram ofpredicate word and its [previous | following] twobrothers.3 Argument Identification and Classifica-tionThe second component of our system is used todetect and classify arguments with respect to apredicate word.
We take a joint solution rather thansolve the problem in two consecutive steps: argu-ment identification and argument classification.3.1 MethodsBy introducing an additional argument type tag ?_?for non-arguments, we transformed the two tasks(i.e.
argument identification and argument classifi-cation) into one multi-class classification problem.As a word can play different roles with respect todifferent predicate words and a predicate word canbe an argument of itself, we generate a training setby deriving a training example from each word-predicate pair.
For example, if a sentence with twopredicates has 7 words, we will derive 7*2=14training examples.
Therefore, the number of train-ing examples generated in this step will be aroundL times larger than that obtained in the previousstep, where L is the average length of sentences.We chose to use maximum entropy algorithm inthis step because of its success in the CoNLL-2008shared task (Surdeanu et al, 2008).
Le Zhang?smaximum entropy package (Zhang, 2006) is inte-grated in our system.The Czech data cause much trouble again for us,as the training data derived by the above strategybecame even larger.
We had to use a special strat-egy for the Czech data: we selectively chose word-predicate pairs for generating the training dataset.In other words, not all possible combinations areused.
We chose the following words with respectto each predicate: the first and the last two wordsof a sentence; the words between the predicate andany argument of it; two words before the predicateor any argument; and two words after the predicateor any argument.In the Czech and Japanese data, some wordsmay play multiple roles with respect to a predicateword.
We thus have to consider multi-label classi-fication problem (Tsoumakas and Katakis, 2007)for these two languages?
data.
We tried the follow-ing two solutions:?
Take each role type combination as a classand transform the multi-label problem to asingle-label classification problem;?
Classify a word with a set of binary classi-fiers: consider each role type individuallywith a binary classifier; any possible roletype will be output; if no role type is ob-tained after considering all the role types,the role type with the highest confidencevalue will be output; and, if ?_?
is outputwith any other role type, remove it.We used the second solution in our officialsubmission, but we finally found these two solu-tions perform almost the same.
The performancedifference is very small.
We found the cases withmulti-labels (actually at most two) in the trainingdata are very limited: 690 of 414,326 in the Czechdata and 113 of 46,663 in the Japanese data.3.2 FeaturesThe features we used in this step include:a.
Whether the current word is a predicate;b.
[Lemma | POS] of current word and its [previous | fol-lowing] one word;c. [Lemma | POS] bi-grams of current word and its [pre-vious | following] one word;d. POS tri-grams of current word, its previous word andits following word;e. Dependency relation of current word to its head;f. [Lemma | POS] of the head of current word;g. [Lemma | POS] bi-grams of current word and its head;h. [(Lemma+Dependency_Relation+Lemma) | (POS+Dependency_Relation+POS)] of current word and itshead;i.
[Lemma | POS] of its most [left | right] child;j.
[Lemma | POS] bi-grams of current word and its most[left | right] child;k. [(Lemma+Dependency_Relation+Lemma) | (POS+Dependency_Relation+POS) of current word and itsmost [left | right] child;l. The number of children of the current word and thepredicate word;m. Attributes of the current word, which is obtained fromPFEAT field by splitting the field at symbol ?|?
andremoving the invalid attribute of ?*?;n.
The sense tag of the predicate word;76o.
[Lemma | POS] of the predicate word and its head;p. Dependency relation of the predicate word to its head;q.
[Lemma | POS] bi-grams of the predicate word and itshead;r. [(Lemma+Dependency_Relation+Lemma) | (POS+Dependency_Relation+POS)] of the predicate word andits head;s. [Lemma | POS] of the most [left | right] child of thepredicate word;t. [(Lemma+Dependency_Relation+Lemma) | (POS+Dependency_Relation+POS)] of predicate word and itshead;u.
[Lemma | POS] bi-gram of the predicate word and itsmost [left | right] child;v. [(Lemma+Dependency_Relation+Lemma) | (POS+Dependency_Relation+POS)] of the predicate word andits most [left | right] child;w. The relative position of the current word to the predi-cate one: before, after, or on;x.
The distance of the current word to the predicate one;y.
The relative level (up, down, or same) and level dif-ference on the syntactic dependency tree of the currentword to the predicate one;z.
The length of the shortest path between the currentword and the predicate word.4 Experiments4.1 DatasetsThe datasets of the CoNLL-2009 shared task con-tain seven languages: Catalan (CA), Chinese (CN),Czech (CZ), English (EG), German (GE), Japanese(JP), and Spanish (SP).
The training and evaluationdata of each language (Taul?
et al, 2008; Xue etal., 2008; Haji?
et al, 2006; Palmer et al, 2002;Burchardt et al, 2006; Kawahara et al, 2002) havebeen converted to a uniform CoNLL Shared Taskformat.
Each participating team is required toprocess all seven language datasets.Lanuage CA CN CZ EN GE JP SPSize (KB) 48974 41340 94284 58155 41091 8948 52430# of Sen-tences 14924 24039 43955 40613 38020 4643 15984# of Predi-cate words 42536 110916 469754 185404 17988 27251 48900Avg.
# ofPredicatesper sentence2.85 4.61 10.69 4.57 0.47 5.87 3.06popularsense taga2(37%)01(90%)=(81%)01(87%)1(75%)=(100%)a2(39%)Table 1.
Statistical information of the seven languagedatasets (training and development).Table 1 shows some statistical information ofboth training and development data for each lan-guage.
The total size of the uncompressed originaldata without lexicons is about 345MB.
The Czechdataset is the largest one containing 43,955 sen-tences and 469,754 predicate words, while theJapanese dataset the smallest one.
On average,10.69 predicate words appear in a Czech sentence,while only 0.47 predicate words exist in a Germansentence.
The most popular sense tag in the Czechdatasets is ?=?, which means the PRED field hasthe same value as the PLEMMA field or theFORM field.
About 81% of Czech predicate wordstake this value.4.2 Experimental ResultsF1 is used as the main evaluation metric in theCoNLL-2009 shared task.
As to the SRLonly track,a joint semantic labeled F1, which considers predi-cate word sense disambiguation and argument la-beling equally, is used to rank systems.Avg.
CA CN CZ EG GE JP SP69.26 74.06 70.37 57.46 69.63 67.76 72.03 73.54Table 2.
Official results of our system.Table 2 gives the official results of our systemon the evaluation data.
The system obtained thebest result (74.06) on the Catalan data, but per-formed very poor (57.46) on the Czech data.
Ex-cept the Czech data, our system performs quitestable on the other six language data with mean of71.23 and standard deviation of 2.42.Avg.
CA CN CZ EG GE JP SPOver-all F1 69.47 74.12 70.52 57.57 70.24 67.97 72.17 73.68Pred.WSDF186.9 84.42 94.54 72.23 92.98 81.09 99.07 83.96ArgI&CF157.24 69.29 57.71 33.19 58.25 60.64 52.72 68.86ArgI&CPR69.77 73.43 72.48 62.14 70.14 66.63 69.37 74.23ArgI&CRE49.77 65.6 47.94 22.64 49.81 55.64 42.52 64.21Table 3.
Results of our system after fixing a minor bug.After submitting the official results, we foundand fixed a minor bug in the implementation of thesecond component.
Table 3 presents the results ofour system after fixing this bug.
The overall per-formance doesn?t change much.
We further ana-lyzed the bottlenecks by checking the performanceof different components.At the predicate WSD part, our system worksreasonable with labeled F1 86.9, but the perform-ance on the Czech data is lower than that of a base-line system that constantly chooses the mostpopular sense tag.
If we use this baseline solution,77we can get predicate WSD F1 78.66, which furtherincreases the overall labeled F1 on the Czech datato 61.68 from 57.57 and the overall labeled F1over the seven languages to 70.05 from 69.47.From table 3, we can see our system performsrelatively poorly for argument identification andclassification (57.24 vs. 86.9).
The system seemstoo conservative for argument identification, whichmakes the recall very lower.
We explored somestrategies for improving the performance of thesecond component, e.g.
separating argument iden-tification and argument classification, and usingfeature selection (with DF threshold) techniques,but none of them helps much.
We are thinking thefeatures currently used may not be effectiveenough, which deserves further study.5 Conclusion and Future WorkIn this paper, we describe our system for theCoNLL-2009 shared task -- SRLonly closed track.Our system was built on existing packages with apipeline architecture, which integrated two cas-caded components: predicate word sense disam-biguation and argument identification andclassification.
Our system performs well at disam-biguating the sense of predicate words, but poorlyat identifying and classifying arguments.
In thefuture, we plan to explore much effective featuresfor argument identification and classification.AcknowledgmentsThis research was funded by Science FoundationIreland under the CNGL grant.
We used the IITACCluster in our initial experiments.
We thank IITAC,the HEA, the National Development Plan and theTrinity Centre for High Performance Computingfor their support.
We are also obliged to JohnKeeney for helping us running our system on theCNGL servers.ReferencesAljoscha Burchardt, Katrin Erk, Anette Frank, AndreaKowalski, Sebastian Pad?
and Manfred Pinkal.
2006.The SALSA Corpus: a German Corpus Resource forLexical Semantics.
Proceedings of the 5th Interna-tional Conference on Language Resources and Eval-uation (LREC-2006).
Genoa, Italy.Chih-Chung Chang and Chih-Jen Lin.
2001.
LIBSVM:a library for support vector machines.
Softwareavailable at http://www.csie.ntu.edu.tw/~cjlin/libsvm.Massimiliano Ciaramita, Giuseppe Attardi, FeliceDell?Orletta, and Mihai Surdeanu.
2008.
DeSRL: ALinear-Time Semantic Role Labeling System.
Pro-ceedings of the CoNLL-2008.Jan Haji?, Massimiliano Ciaramita, Richard Johansson,Daisuke Kawahara, Maria Antonia Mart?, Llu?sM?rquez, Adam Meyers, Joakim Nivre, SebastianPad?, Jan ?t?p?nek, Pavel Stra?
?k, Mihai Surdeanu,Nianwen Xue and Yi Zhang.
2009.
The CoNLL-2009Shared Task: Syntactic and Semantic Dependenciesin Multiple Languages.
Proceedings of the 13thConference on Computational Natural LanguageLearning (CoNLL-2009).
Boulder, Colorado, USA.Jan Haji?, Jarmila Panevov?, Eva Haji?ov?, Petr Sgall,Petr Pajas, Jan ?t?p?nek, Ji??
Havelka, MarieMikulov?
and Zden?k ?abokrtsk?.
2006.
The PragueDependency Treebank 2.0.
Linguistic DataConsortium, USA.
ISBN 1-58563-370-4.Daisuke Kawahara, Sadao Kurohashi and Koiti Hasida.2002.
Construction of a Japanese Relevance-taggedCorpus.
Proceedings of the 3rd International Confer-ence on Language Resources and Evaluation (LREC-2002).
Las Palmas, Spain.Baoli Li, Qin Lu and Shiwen Yu.
2004.
An Adaptive k-Nearest Neighbor Text Categorization Strategy.
ACMTransactions on Asian Language InformationProcessing, 3(4): 215-226.Llu?s M?rquez, Xavier Carreras, Kenneth C. Litkowskiand Suzanne Stevenson.
2008.
Semantic Role Label-ing: An Introduction to the Special Issue.
Computa-tional Linguistics, 34(2):145-159.Andrew Mccallum and Kamal Nigam.
1998.
A Com-parison of Event Models for Naive Bayes Text Clas-sification.
Proceedings of AAAI/ICML-98 Workshopon Learning for Text Categorization.Mihai Surdeanu, Richard Johansson, Adam Meyers,Lluis Marquez and Joakim Nivre.
2008.
The CoNLL-2008 Shared Task on Joint Parsing of Syntactic andSemantic Dependencies.
Proceedings of the 12thConference on Computational Natural LanguageLearning (CoNLL-2008).Mariona Taul?, Maria Ant?nia Mart?
and MartaRecasens.
2008.
AnCora: Multilevel AnnotatedCorpora for Catalan and Spanish.
Proceedings of the6th International Conference on Language Resourcesand Evaluation (LREC-2008).
Marrakech, Morocco.Grigorios Tsoumakas and Ioannis Katakis.
2007.
Multi-Label Classification: An Overview.
InternationalJournal of Data Warehousing and Mining, 3(3):1-13.Nianwen Xue and Martha Palmer.
2009.
Addingsemantic roles to the Chinese Treebank.
NaturalLanguage Engineering, 15(1):143-172.Le Zhang.
2006.
Maximum Entropy Modeling Toolkitfor Python and C++.
Software available athttp://homepages.inf.ed.ac.uk/s0450736/maxent_toolkit.html.78
