Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 321?324,Suntec, Singapore, 4 August 2009.c?2009 ACL and AFNLPThe Contribution of Stylistic Information toContent-based Mobile Spam FilteringDae-Neung Sohn and Jung-Tae Lee and Hae-Chang RimDepartment of Computer and Radio Communications EngineeringKorea UniversitySeoul, 136-713, South Korea{danny,jtlee,rim}@nlp.korea.ac.krAbstractContent-based approaches to detectingmobile spam to date have focused mainlyon analyzing the topical aspect of a SMSmessage (what it is about) but not on thestylistic aspect (how it is written).
In thispaper, as a preliminary step, we investigatethe utility of commonly used stylistic fea-tures based on shallow linguistic analysisfor learning mobile spam filters.
Experi-mental results show that the use of stylis-tic information is potentially effective forenhancing the performance of the mobilespam filters.1 IntroductionMobile spam, also known as SMS spam, is a sub-set of spam that involves unsolicited advertisingtext messages sent to mobile phones through theShort Message Service (SMS) and has increas-ingly become a major issue from the early 2000swith the popularity of mobile phones.
Govern-ments and many service providers have taken var-ious countermeasures in order to reduce the num-ber of mobile spam (e.g.
by imposing substantialfines on spammers, blocking specific phone num-bers, creating an alias address, etc.).
Nevertheless,the rate of mobile spam continues to rise.Recently, a more technical approach to mobilespam filtering based on the content of a SMS mes-sage has started gaining attention in the spam re-search community.
G?omez Hidalgo et al (2006)previously explored the use of statistical learning-based classifiers trained with lexical features, suchas character and word n-grams, for mobile spamfiltering.
However, content-based spam filteringdirected at SMS messages are very challenging,due to the fact that such messages consist of onlya few words.
More recent studies focused on ex-panding the feature set for learning-based mobilespam classifiers with additional features, such asorthogonal sparse word bi-grams (Cormack et al,2007a; Cormack et al, 2007b).Collectively, the features exploited in earliercontent-based approach to mobile spam filteringare topical terms or phrases that statistically in-dicate the spamness of a SMS message, such as?loan?
or ?70% off sale?.
However, there isno guarantee that legitimate (non-spam) messageswould not contain such expressions.
Any of usmay send a SMS message such as ?need ur ad-vise on private loans, plz call me?
or ?mary,abc.com is having 70% off sale today?.
For cur-rent content-based mobile spam filters, there is achance that they would classify such legitimatemessages as spam.
This motivated us to not onlyrely on the message content itself but incorporatenew features that reflect its ?style,?
the manner inwhich the content is expressed, in mobile spam fil-tering.The main goal of this paper is to investigate thepotential of stylistic features in improving the per-formance of learning-based mobile spam filters.
Inparticular, we adopt stylistic features previouslysuggested in authorship attribution studies basedon stylometry, the statistical analysis of linguisticstyle.1Our assumption behind adopting the fea-tures from authorship attribution are as follows:?
There are two types of SMS message senders,namely spammers and non-spammers.?
Spammers have distinctive linguistic stylesand writing behaviors (as opposed to non-spammers) and use them consistently.?
The SMS message as an end product carriesthe author?s ?fingerprints?.1Authorship attribution involves identifying the author ofa text given some stylistic characteristics of authors?
writing.See Holmes (1998) for overview.321Although there are many types of stylistic fea-tures suggested in the literature, we make use ofthe ones that are readily computable and countablefrom SMS message texts without any complex lin-guistic analysis as a preliminary step, includingword and sentence lengths (Mendenhall, 1887),frequencies of function words (Mosteller and Wal-lace, 1964), and part-of-speech tags and tag n-grams (Argamon-Engelson et al, 1998; Koppel etal., 2003; Santini, 2004).Our experimental result on a large-scale, realworld SMS dataset demonstrates that the newlyadded stylistic features effectively contributes tostatistically significant improvement on the perfor-mance of learning-based mobile spam filters.2 Stylistic Feature SetAll stylistic features listed below have been auto-matically extracted using shallow linguistic analy-sis.
Note that most of them have been motivatedfrom previous stylometry studies.2.1 Length features: LENMendenhall (1887) first created the idea of count-ing word lengths to judge the authorship of texts,followed by Yule (1939) and Morton (1965) withthe use of sentence lengths.
In this paper, we mea-sure the overall byte length of SMS messages andthe average byte length of words in the message asfeatures.2.2 Function word frequencies: FWMotivated from a number of stylometry studiesbased on function words including Mosteller andWallace (1964), Tweedie et al (1996) and Arg-amon and Levitan (2005), we measure the fre-quencies of function words in SMS messages asfeatures.
The intuition behind function words isthat due to their high frequency in languages andhighly grammaticalized roles, such words are un-likely to be subject to conscious control by the au-thor and that the frequencies of different functionwords would vary greatly across different authors(Argamon and Levitan, 2005).2.3 Part-of-speech n-grams: POSFollowing the work of Argamon-Engelson et al(1998), Koppel et al (2003), Santini (2004) andGamon (2004), we extract part-of-speech n-grams(up to trigrams) from the SMS messages and usetheir frequencies as features.
The idea behind theirutility is that spammers would favor certain syn-tactic constructions in their messages.2.4 Special characters: SCWe have observed that many SMS messages con-tain special characters and that their usage variesbetween spam and non-spam messages.
For in-stance, non-spammers often use special charactersto create emoticons to express their mood, such as?:-)?
(smiling) or ?T T?
(crying), whereas spam-mers tend to use special character or patterns re-lated to monetary matters, such as ?$$$?
or ?%?.Therefore, we also measured the ratio of specialcharacters, the number of emoticons, and the num-ber of special character patterns in SMS messagesas features.23 Learning a Mobile Spam FilterIn this paper, we use maximum entropy model,which have shown robust performance in varioustext classification tasks in the literature, for learn-ing the mobile spam filter.
Simply put, given anumber of training samples (in our case, SMSmessages), each with a label Y (where Y = 1 ifspam and 0 otherwise) and a feature vector x, thefilter learns a vector of feature weight parametersw.
Given a test sample X with its feature vector x,the filer outputs the conditional probability of pre-dicting the data as spam, P (Y = 1|X = x).
Weuse the L-BFGS algorithm (Malouf, 2002) and theInformation Gain (IG) measure for parameter esti-mation and feature selection, respectively.4 Experiments4.1 SMS test collectionsWe use a collection of mobile SMS messages inKorean, with 18,000 (60%) legitimate messagesand 12,000 (40%) spam messages.
This collec-tion is based on one used in our previous work(Sohn et al, 2008) augmented with 10,000 newmessages.
Note that the size is approximately 30times larger than the most previous work by Cor-mack et al (2007a) on mobile spam filtering.4.2 Feature settingWe compare three types of feature sets, as follows:2For emoticon and special pattern counts, we used man-ually constructed lexicons consisting of 439 emoticons and229 special patterns.322?
Baseline: This set consists of lexical featuresin SMS messages, including words, charac-ter n-grams, and orthogonal sparse word bi-grams (OSB)3.
This feature set representsthe content-based approaches previously pro-posed by G?omez Hidalgo et al (2006), Cor-mack et al (2007a) and Cormack et al(2007b).?
Proposed: This feature set consists of all thestylistic features mentioned in Section 2.?
Combined: This set is a combination of boththe baseline and proposed feature sets.For all three sets, we make use of 100 features withthe highest IG values.4.3 Evaluation measuresSince spam filtering task is very sensitive to false-positives (i.e.
legitimate classified as spam) andfalse-negatives (i.e.
spam classified as legitimate),special care must be taken when choosing an ap-propriate evaluation criterion.Following the TREC Spam Track, we evalu-ate the filters using ROC curves that plot false-positive rate against false-negative rate.
As a sum-mary measure, we report one minus area underthe ROC curve (1?AUC) as a percentage withconfidence intervals, which is the TREC?s officialevaluation measure.4Note that lower 1?AUC(%)value means better performance.
We used theTREC Spam Filter Evaluation Toolkit5in order toperform the ROC analysis.4.4 ResultsAll experiments were performed using 10-foldcross validation.
Statistical significance of differ-ences between results were computed with a two-tailed paired t-test.
The symbol ?
indicates statis-tical significance over an appropriate baseline atp < 0.01 level.Table 1 reports the 1?AUC(%) summary foreach feature settings listed in Section 4.2.
Noticethat Proposed achieves significantly better perfor-mance than Baseline.
(Recall that the smaller, the3OSB refers to words separated by 3 or fewer words,along with an indicator of the difference in word positions;for example, the expression ?the quick brown fox?
wouldinduce following OSB features: ?the (0) quick?, ?the (1)brown?, ?the (2) fox?, ?quick (0) brown?, ?quick (1) fox?,and ?brown (0) fox?
(Cormack et al, 2007a).4For detail on ROC analysis, see Cormack et al (2007a).5Available at http://plg.uwaterloo.ca/.trlynam/spamjig/Feature set 1?AUC (%)Baseline 10.7227 [9.4476 - 12.1176]Proposed 4.8644?
[4.2726 - 5.5886]Combined 3.7538?
[3.1186 - 4.4802]Table 1: Performance of different feature settings.50.0010.001.0050.0010.001.000.100.01FalseNegativeRate(logit scale)False Positve Rate (logit scale)CombinedProposedBaselineFigure 1: ROC curves of different feature settings.better.)
An even greater performance gain is ob-tained by combining both Proposed and Baseline.This clearly indicates that stylistic aspects of SMSmessages are potentially effective for mobile spamfiltering.Figure 1 shows the ROC curves of each fea-ture settings.
Notice the tradeoff when Proposedis used solely with comparison to Baseline; false-positive rate is worsened in return for gaining bet-ter false-negative rate.
Fortunately, when both fea-ture sets are combined, false-positive rate is re-mained unchanged while the lowest false-negativerate is achieved.
This suggests that the addition ofstylistic features contributes to the enhancement offalse-negative rate while not hurting false-positiverate (i.e.
the cases where spam is classified as le-gitimate are significantly lessened).In order to evaluate the contribution of differenttypes of stylistic features, we conducted a seriesof experiments by removing features of a specifictype at a time from Combined.
Table 2 shows thedetailed result.
Notice that LEN and SC featuresare the most helpful, since the performance dropssignificantly after removing either of them.
Inter-estingly, FW and POS features show similar con-tributions; we suggest that these two feature typeshave similar effects in this filtering task.We also conducted another series of experi-ments, by adding one feature type at a time toBaseline.
Table 3 reports the results.
Notice thatLEN features are consistently the most helpful.The most interesting result is that POS featurescontinuously contributes the least.
We carefully323Feature set 1?AUC (%)Combined 3.7538 [3.1186 - 4.4802]?
LEN 4.7351?
[4.0457 - 5.6405]?
FW 3.9823?
[3.3048 - 4.5930]?
POS 4.0712?
[3.4057 - 4.8630]?
SC 4.7644?
[4.1012 - 5.4350]Table 2: Performance by removing one stylisticfeature set from the Combined set.Feature set 1?AUC (%)Baseline 10.7227 [9.4476 - 12.1176]+ LEN 5.5275?
[4.0457 - 6.6281]+ FW 6.0828?
[5.1783 - 6.9249]+ POS 9.6103?
[8.7190 - 11.0579]+ SC 7.5288?
[6.6049 - 8.4466]Table 3: Performance by adding one stylistic fea-ture set to the Baseline set.hypothesize that the result is due to high depen-dencies between POS and lexical features.5 DiscussionIn this paper, we have introduced new features thatindicate the written style of texts for content-basedmobile spam filtering.
We have also shown that thestylistic features are potentially useful in improv-ing the performance of mobile spam filters.This is definitely a work in progress, and muchmore experimentation is required.
Deep linguis-tic analysis-based stylistic features, such as con-text free grammar production frequencies (Ga-mon, 2004) and syntactic rewrite rules in an au-tomatic parse (Baayen et al, 1996), that have al-ready been successfully used in the stylometry lit-erature may be considered.
Perhaps most impor-tantly, the method must be tested on various mo-bile spam data sets written in languages other thanKorean.
These would be our future work.ReferencesShlomo Argamon and Shlomo Levitan.
2005.
Measur-ing the usefulness of function words for authorshipattribution.
In Proceedings of ACH/ALLC ?05.Shlomo Argamon-Engelson, Moshe Koppel, and GalitAvneri.
1998.
Style-based text categorization:What newspaper am i reading?
In Proceedings ofAAAI ?98 Workshop on Text Categorization, pages1?4.H.
Baayen, H. van Halteren, and F. Tweedie.
1996.Outside the cave of shadows: using syntactic annota-tion to enhance authorship attribution.
Literary andLinguistic Computing, 11(3):121?132.Gordon V. Cormack, Jos?e Mar?
?a G?omez Hidalgo, andEnrique Puertas S?anz.
2007a.
Spam filtering forshort messages.
In Proceedings of CIKM ?07, pages313?320.Gordon V. Cormack, Jos?e Mar?
?a G?omez Hidalgo, andEnrique Puertas S?anz.
2007b.
Feature engineeringfor mobile (sms) spam filtering.
In Proceedings ofSIGIR ?07, pages 871?872.Michael Gamon.
2004.
Linguistic correlates of style:Authorship classification with deep linguistic analy-sis features.
In Proceedings of COLING ?04, page611.Jos?e Mar?
?a G?omez Hidalgo, Guillermo CajigasBringas, Enrique Puertas S?anz, and Francisco Car-rero Garc??a.
2006.
Content based sms spam filter-ing.
In Proceedings of DocEng ?06, pages 107?114.David I. Holmes.
1998.
The evolution of stylometryin humanities scholarship.
Literary and LinguisticComputing, 13(3):111?117.Moshe Koppel, Shlomo Argamon, and Anat R. Shi-moni.
2003.
Automatically categorizing writtentexts by author gender.
Literary and LinguisticComputing, 17(4):401?412.Robert Malouf.
2002.
A comparison of algorithmsfor maximum entropy parameter estimation.
In Pro-ceedings of COLING ?02, pages 1?7.T.
C. Mendenhall.
1887.
The characteristic curves ofcomposition.
Science, 9(214):237?246.A.
Q. Morton.
1965.
The authorship of greek prose.Journal of the Royal Statistical Society Series A(General), 128(2):169?233.Frederick Mosteller and David L. Wallace.
1964.
In-ference and Disputed Authorship: The Federalist.Addison-Wesley.Marina Santini.
2004.
A shallow approach to syntacticfeature extraction for genre classification.
In Pro-ceedings of CLUK Colloquium ?04.Dae-Neung Sohn, Joong-Hwi Shin, Jung-Tae Lee,Seung-Wook Lee, and Hae-Chang Rim.
2008.Contents-based korean sms spam filtering usingmorpheme unit features.
In Proceedings of HCLT?08, pages 194?199.E.
J. Tweedie, S. Singh, and D. I. Holmes.
1996.
Neu-ral network applications in stylometry: The federal-ist papers.
Computers and the Humanities, 30:1?10.G.
Udny Yule.
1939.
On sentence-length as a statisti-cal characteristic of style in prose, with applicationto two cases of disputed authorship.
Biometrika,30(3-4):363?390.324
