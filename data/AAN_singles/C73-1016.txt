GEar J.
VAN DER STEENA TI~EATMENT OF INDEPENDENT SEMANTICCOMPONENTS1.
A TREATMENT OF INDEPENDENT SEMANTIC COMPONENTSTo distinguish things, we use terms which characterize them for us.For two balls it may be their color, for two people it may be theirheight, or their manner of speaking.
In order to illustrate the differ-ences in meaning for many words J. j. KATZ and J.
A. FODOR (1963)proposed the use of "semantic haracteristics ".
They give an exam-ple for the meanings of man and ball:man-  .
.
.
-  (physical object) - -  (human) -  (adult) - -  (male)ball~ - - .
.
.
-  (social activity) - -  (large) - -  (assembly)ba l l~-  .
.
.
-  (physical object)D. BOLINGER (1965) proposed the systematizing of these character-istics, with hierarchic structures, so that the meaning of the wordbachelor could be represented by a row of characteristics (fig.
1).bachelorhuman~- -  ,.
an~nalmale "~""~"~' -~ed ucand phocizmadult military hierarchic hirsutenonbecoming hierarchic permanent maleunmated noble inferior adultinferior youngdependent nubileproximate unmatedyoung~g.l.Here the meaning of a word is given by a refering it to other words.These words, in their turn, can be referenced by other words.
Thereis the feeling that from here endless references will originate.Let us suppose that there are a number of elementary characteris-tics which can not be expressed in other characteristics.
We shall call~ m m i P .
lmWlmal r "uamm=-  ~ " "=,=- - ,~  ~ w ~  _ _ ~  .
.
.
.
- -  .
.
.
.
.
.
.
.202 GERT.
J .
VAN DER STEENthem el ... ez.
The question if they correspond with any existing wordor expression let be leaved as it is, just as the limitation of  I.
We shallrepresent the meaning of a word by the intensity of the presence ofspecific characteristics er If we construct a model in an/-dimensionalvector-space with unit-vectors _el ... _ei we may represent the meaningof a word or expression W by the vector W = wx _e~ + w2_e~ + ... ++w~zwi thw~>O for i=1  ... LThe common in the meaning of two words is the sum of the com-mon in each of  the basis characteristics.In our model this is for the vectorsI I IV=.~ v,e, and W= ~ w,f, : V NW=.~ min(v,,w,) ei=1 i~ l  i~ lFor I = 2 refer to fig.
2.?~: I IF ig .
2 .For the determination of  the norm of the vectors we consider thatthe common of  V and W is determined via their characteristics.
Ourconsciousness can evaluate the factors v~ and w~ only one by one.
There-fore we put as norm:!II v i i  = v,.i=1Therewith is!l i e  n _wll =i~ l  ,by definition called the measure Of association between _V and W.(rain is the minimum-function, e.g.
rain (5, 7 )= 5).To test this model we designed two tests (G.J.
VAN ,r~r STE~N,'1971).In the first test, individuals are asked to write down 12 words,starting with the word bird, and, relative to the associations betweenthem, to indicate the measure of  the association.
This has to be a num-ber between 0 and 10; ' 0 '  for: "no  association ", ' 10' for: "syn-A TREATMENT OF INDEPENDENT SEMANTIC COMPONENTS 203onym".
For an example: see table 1.
For the Words W1 to WI~.
in ourmodel, we use the equations:I(1) .~, rain (w'nl,, wn2, )= v,a,,,2i=1for 1 < nl < N-1nl < n2 ~< N (here N = 12)wherein the numbers v,l,, 2 are given.
From these equations the un-knowns wn i (i = 1, .... 1; n = 1 .
.
.
.
, N) have to be solved.
At the sametime, the number of  characteristics I has to be determined.
An upperlimit for I is the number of equations: each association runs over aseparate characteristic.We determine I and the unknown wn?
by an iteration-process.Suppose that the factors wn~ (1 ~< n ~< N; 1 ~< i < I1) are determined(/1 = 1, 2..1-1).
Then we may write:,,c~,+1) = vii,) (1 ~< nl ~ N-l,  nl < n2 ~< N) rain (wnlz:, wn21) + Vnl,n 2 nl,n2with v m and ,,re+l) = (wnl, wn2).
nl,n2 ~ l)nl,n2 Vnl,n2 .~, raini=I~+1Let us denote the sum of all v's in step/1 q- 1 with S, soN-1 NS = .~ .~ ,,(~'+~) ~nl,n2n l= l  n2=nl+lTo minimize I we try to solve the system with S as small as pos-sible.
By successively assuming that a specific wn,, is the smallest ofall wn, 1 's we can determine for each of the suppositions the sum S.We choose now the wn,1 which belongs to the smallest sum S. If thereare more sums S with this value then there are more refined criteriaavailable.
Suppose this is wnllc In the equationrain (wnl,l, wn2,1 ) q- !,~t1+11 = vl~0 ?
~nl,n2 nl,n2 ?we choose then wnl,~ = v,,1,2.
"~I') Therewith Vnl,ne"(Z'+l) = 0. wn2z, wil l  bedetermined later.In all equations wherein wnl,~ appears v,l,, 2''(z'+1) can now be determined.In the remaining equations we now apply the same process till therestays at last one equation, for instance~(11+1) l)(lt) min (wn3iI, wn4,)-q-",3,,~ = .3,,~204 GERT J.
VAN DER $TEENHere we choose wn3,,----wn41, = ,',3,,,4.~'(I') Therewith our iteration stepfor I1 has been ended.
When all vc~,+l) ___ 0 then I---- I1 and the whole - n i ,n jiteration-process has come to an end.The process is illustrated in table 2 for 4 words with associationsVl,~ = 3, Vl,3 = 6, Vl,4 = 8, v~,3 = 2, v~,t = 4 and va,4 = 5 (randomlychosen).
With si we denote the sum which belongs to a w i which ap-pears in a line with the lowest v.With some small modifications this solution-scheme can be usedalso if some equations have been deleted in the beginning; in otherswords: when some associations are not given.
This is illustrated intable 3 with the same v's as in table 2, except for vl,3 which is omitted.The small modification concerns the calculation of si: we divide s iby the number of lines minus 1 in which wj.
appears.Wc now try our model by omitting some of the given associationsfrom one individual.
According to the foregoing method we deter-mine the number of characteristics I and the vector-representations ofthe words.
From them we calculate the omitted associations with theaid of formula (1).
For the discrepancies between the thus predictedand the omitted associations we can determine statistically an esti-mation.If the associations are randomly given then the mean and the stan-dard-deviation do agree indeed with their calculated values.
If theassociations are given by test-persons these numbers are significantlylower.There are interesting discrepancies if associations are left out whichexpress an extra aspect of meaning.
In a specific case the words bird,leg, table and chair were given among others.
If the association betweenleg and bird was left out an association of 0 was predicted, as it shouldbe.
The number of characteristics was decreased by one.The evaluation of associations between given words by test-per-sons is subjective.
This, however, plays no role here: the relations be-tween a number of consciousness-contents are concerned.
If the test-individual is not consistent in his evaluations then the discrepanciesbetween the given and the predicted associations become greater.
Inpractice there seems to be a good correlation of consistency in evalua-tion and the intelligence-level of the test-person.On a more reliable level are the extended observations of the lan-guage expressions of a test-individual.
For this purpose a second testwas designed.
As source material 20 pages of the novel De verliezersof Anna Blaman were taken.
With the aid of the programming languageA TREATMENT OF INDEPENDENT SEMANTIC COMPONENTS 205SNOBOL a frequency-table was made for all words in that piece" of thetext.
From them 20 words with a high frequency were chosen whichare relevant wkh regard to each other.
Then it was determined howmany times each of the 20 words was found together with each of theother words in the same sentence.
This number was taken as a mea-sure of the associations between the words.
If we leave out the 0-as-sociations and predict heir associations by the method of the first testour model will not be unreliable if we predict he value 0.Indeed, it appears that there are O's predicted, except in associationsbetween ouns and the words mine and your which give values 2 and3, and some, randomly distributed, exceptions.
The method of predic-tion of 0-associations was chosen to avoid the rather crude measureof association.
This measure was used because of the absence of a well-defined method to detect coherent subphrases.
If two words neveroccur together in a phrase they will certainly never appear in the samesub-phrase.It will be interesting to try this model on the common usage oflanguages.
The obtained vector-representations can be transferred toother characteristic systems by means of matrix-manipulations.
A fur-ther extension lies in the determination f the representation f wordsin different natural anguages with a mutual comparison and eventualtransformation of the representations.
The measure of association iscritical here.
This should be refined by using more knowledge aboutthe syntactic structure of the sentences.A further estriction lies in the number of developed characteristics.For the first test this was approximately 13, for the second approximately76.
From these 76, the first 20 were the most relevant.
The remainingcharacteristics served more to compensate for several small discrep-ancies.
By chancing to a larger amount of language information thenumber of relevant characteristics will naturally increase.
11 Programming languages used: PL/I, FORTRAN and SNOBOLMachines used: mM 360/65 and PDV-9.A FORTZAN-II program for determining the semantic omponents from given asso-ciatiom is available upon request.t~Z000e~0o~or~ot~ Ol0 0000 0 0 00 0 t~0~0O 0 0 00 0 0 0u.l0 u~~0~0UZ Q t.~ O0or.z.1~0D0r~oUZ or~~0~000~ ~ ~- I ~ ~ ~ ~ ~ I~O ~REFERENCESD.
BouNarm, The atomization of meaning,in ~ Language ,, XLI (1965) 4, pp.
555-573.J.
J. KATZ, J.
A. FODOR, The structure of asemantic theory, in, Language ~, XXXIX(1963) 2, pp.
170-210.G.
J.
VAN D~ STY, Semantic processesin artificial intelligence systems (in Dutch),Delft, 1971.e47I\] I\] ~,III\]ii i~~GII IIII II~ uLIII~Gi L i, ?ii ii\[Iin~GII~Gt t t f tttt t  t ttt t  IItfLf t~bIIIIo~I\]0IIliII?II"&II II ~I~G~Gilliil IIli ~I ""tott~ t t t t: iI ui t t t t; tt : t tt t t tT i: t J tvIIo~IT b\]~o ~ ?~?
~ ?
~
