Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: System Demonstrations,pages 67?70, Dublin, Ireland, August 23-29 2014.A Sentence Judgment System for Grammatical Error DetectionLung-Hao Lee 1,2, Liang-Chih Yu3,4, Kuei-Ching Lee1,2,Yuen-Hsien Tseng1, Li-Ping Chang5, Hsin-Hsi Chen21Information Technology Center, National Taiwan Normal University2Dept.
of Computer Science and Information Engineering, National Taiwan University3Dept.
of Information Management, Yuen Ze University4Innovation Center for Big Data and Digital Convergence, Yuen Ze University5Mandarin Training Center, National Taiwan Normal Universitylcyu@saturn.yzu.edu.tw, {lhlee, johnlee, lchang,samtseng}@ntnu.edu.tw, hhchen@ntu.edu.twAbstractThis study develops a sentence judgment system using both rule-based and n-gram statisticalmethods to detect grammatical errors in Chinese sentences.
The rule-based method provides142 rules developed by linguistic experts to identify potential rule violations in input sentences.The n-gram statistical method relies on the n-gram scores of both correct and incorrect trainingsentences to determine the correctness of the input sentences, providing learners with im-proved understanding of linguistic rules and n-gram frequencies.1 IntroductionChina?s growing global influence has prompted a surge of interest in learning Chinese as a foreignlanguage (CFL), and this trend is expected to continue.
This has driven an increase in demand for au-tomated IT-based tools designed to assist CFL learners in mastering the language, including so-calledMOOCs (Massive Open Online Courses) which allows huge numbers of learners to simultaneouslyaccess instructional opportunities and resources.
This, in turn, has driven demand for automatic proof-reading techniques to help instructors review and respond to the large volume of assignments and testssubmitted by enrolled learners.However, whereas many computer-assisted learning tools have been developed for use by studentsof English as a Foreign Language (EFL), support for CFL learners is relatively sparse, especially interms of tools designed to automatically detect and correct Chinese grammatical errors.
For example,while Microsoft Word has integrated robust English spelling and grammar checking functions foryears, such tools for Chinese are still quite primitive.
In contrast to the plethora of research related toEFL learning, relatively few studies have focused on grammar checking for CFL learners.
Wu et al.
(2010) proposed relative position and parse template language models to detect Chinese errors writtenby US learner.
Yu and Chen (2012) proposed a classifier to detect word-ordering errors in Chinesesentences from the HSK dynamic composition corpus.
Chang et al.
(2012) proposed a penalized prob-abilistic First-Order Inductive Learning (pFOIL) algorithm for error diagnosis.
In summary, althoughthere are many approaches and tools to help EFL learners, the research problem described above forCFL learning is still under-explored.
In addition, no common platform is available to compare differ-ent approaches and to promote the study of this important issue.This study develops a sentence judgment system using both rule-based and n-gram statistical meth-ods to detect grammatical errors in sentences written by CFL learners.
Learners can input Chinese sen-tences into the proposed system to check for possible grammatical errors.
The rule-based method usesa set of rules developed by linguistic experts to identify potential rule violations in input sentences.This work is licensed under a Creative Commons Attribution 4.0 International Licence.
Page numbers and proceedings footerare added by the organisers.
Licence details: http://creativecommons.org/licenses/by/4.0/67The n-grtences toproved ucan alsoassignme2 A SFigure 1http://sjfshown inpart-of-sgrammatods deteinformatence, as?
( IThe ru(towardsfrequencdetail the2.1 PrChineseLanguagnese wousually scorpus-bMa, 200ed word????
?POS:Wwords, tlexicon aPOS tagam statisticadeterminenderstandinbe incorporants and testentence Jushows the.itc.ntnu.eduthe upperpeech taggiical error dect grammaticion, the expshown in the?
?
?from   hele-based me)) cannot bey of the bigpre-processe-processinis written we Processingrd segmenteuffers fromased learnin2).
This is fos with parts-???
(Obord?
sequenhe translationd therefore?SHI?
is a tal method rethe correctng of both linted into onls.dgement Suser interf.tw/demo/.
Lpart of Fig.ng, and thentection.
Finaal errors.
Olanation of tbottom par?
?re    go   towthod showsused after aram ??
?ing, rule-bagithout word(NLP) taskrs are generthe unknowg method isllowed by aof-speech (Tama is the pce  shownn of a foreiis extractedg to represenFigure 1.lies on the ness of the inguistic rulesine CFL MOystemace of theearners can1.
Each inppassed tolly, an inputherwise, it whe matchedt of Fig.
1.
F?ads  north.
)a rule violatverb (e.g., ??
(go towardsed method,boundaries.s, texts musally trainedn word (i.e.,used to mergreliable andsai and Cheresident ofas follows:gn proper naby the unkt the be-verScreenshot-gram scorput sentenceand n-gramOC platformsentence jusubmit singut sentenceboth the rut sentence will be markrules and n-gor instance,ion is detec??
(go)).
Ts) is relativand n-gramAs a result,t undergo auby an inputthe out-of-ve unknowncost-effectin, 2004).
Fthe USA).Nb:??
?me ???
?nown wordb ??
?.of the sentenes of both cs.
The systefrequenciess to help asdgment sysle or multipis pre-procele-based anill be markeed as correcram frequenthe followinted and explhe n-gram fre low.
The fstatistical mprior to thetomatic wolexicon andocabulary, owords to tacve POS-taggor example,It was segmSHI:?
N?
(Obama)detection mece judgemenorrect and inm helps lea.
In addition,sess and/ortem, whichle sentencesssed for wod n-gram std as incorret ( ).
In adcies are alsg sentence iains that a pequencies alollowing suethod.implementard segmentaprobabilityr OOV) prokle the OOVing methodtake the Chented and tac:??
Nais not likelychanism.
Int system.correct trainrners develothe proposescore the nucan be accthrough thrd segmentaatistical metct ( ) if bodition to theo presenteds marked asreposition (eso shows thbsections detion of mostion.
Autommodels.
Hoblem.
In thisproblem (Cto label theinese sentengged in the:??.
Amoto be incluthis case, thing sen-p an im-d systemmbers ofessed ate textboxtion andhods forth meth-decisionfor refer-incorrect:.g., ??
?at the thescribe int Naturalatic Chi-wever, itstudy, ahen andsegment-ce ??
?form ofng theseded in ae special682.2 Rule-based Linguistic AnalysisSeveral symbols are used to represent the syntactic rules to facilitate the detection of errors embeddedin Chinese sentences written by CFL learners: (1) ?*?
is a wild card, with ?Nh*?
denoting all subordi-nate tags of ?Nh?, e.g., ?Nhaa,?
?Nhab,?
?Nhac,?
?Nhb,?
and ?Nhc?.
(2) ?-?
means an exclusion fromthe previous representation, with ?N*-Nab-Nbc?
indicating that the corresponding word should be anynoun (N*) excluding countable entity nouns (Nab) and surnames (Nbc).
(3) ?/?
means an alternative(i.e., ?or?
), where the expression ???/??/???
(some/these/those) indicates that one of thesethree words satisfies the rule.
(4) The rule mx{W1 W2} denotes the mutual exclusivity of the twowords W1 and W2.
(5) ?<?
denotes the follow-by condition, where the expression ?Nhb  <  Nep?means the POS-tag ?Nep?
follows the tag ?Nhb?
that can exist several words ahead of the ?Nep?.Using such rule symbols, we manually constructed syntactic rules to cover errors that frequently oc-cur in sentences written by CFL learners.
We adopted the ?Analysis of 900 Common Erroneous Sam-ples of Chinese Sentences?
(Cheng, 1997) as the development set to handcraft the linguistic rules withsyntactic information.
If an input sentence satisfies any syntactic rule, the system will report the inputas suspected of containing grammatical errors, creating a useful tool for autonomous CFL learners.2.3 N-gram Statistical AnalysisLanguage modeling approaches to grammatical error detection are usually based on a score (log prob-ability) output by an n-gram model trained on a large corpus.
A sentence with grammatical errors usu-ally has a low n-gram score.
However, choosing an appropriate threshold to determine whether a sen-tence is correct is still a nontrivial task.
Therefore, this study proposes the use of n-gram scores of cor-rect and incorrect sentences to build the respective correct and incorrect statistical models for gram-matical error detection.
That is, a given sentence is denoted as incorrect (i.e., having grammatical er-rors) if its probability score output by the statistical model of incorrect sentences (i.e., the incorrectmodel) is greater than that of correct sentences (i.e., the correct model).To build the incorrect and correct statistical models, a total of 19,080 sentences with grammaticalerrors were extracted from the HSK dynamic composition corpus.
These sentences were then manual-ly corrected.
An n-gram (n= 2 and 3) language model was then built from the Sinica corpus releasedby the Association for Computational Linguistics and Chinese Language Processing (ACLCLP) usingthe SRILM toolkit (Stolcke, 2002).
The trained language model was used to assign an n?gram scorefor each correct and incorrect sentence, which were then used to build the respective correct and incor-rect models based on a normal probability density function (Manning and Sch?tze, 1999).
Both mod-els can then be used to evaluate each test sentence by transforming its n-gram score into a probabilityscore to determine whether the sentence is correct or not.3 Performance EvaluationThe test set included 880 sentences with grammatical errors generated by CSL learners in the NCKUChinese Language Center, and the corresponding 880 manually corrected sentences.
For the rule-based approach, a total of 142 rules were developed to identify incorrect sentences.
For the n-gramstatistical approach, both bi-gram and tri-gram language models were used for the correct and incor-rect statistical models.
In addition to precision, recall, and F1, the false positive rate (FPR) was definedas the number of correct sentences incorrectly identified as incorrect sentences divided by the totalnumber of correct sentences in the test set.Table 1 shows the comparative results of the rule-based and n-gram statistical approaches to gram-matical error detection.
The results show that the rule-based approach achieved high precision, lowrecall and low FPR.
Conversely, the n-gram-based approach yielded low precision, high recall andhigh FPR.
In addition, the tri-gram model outperformed the bi-gram model for all metrics.
Given thedifferent results yielded by the rule-based and n-gram statistical approaches, we present different com-binations of these two methods for comparison.
The ?OR?
combination means that a given sentence isidentified as incorrect by only one of the methods, while the ?AND?
combination means that a givensentence is identified as incorrect by both methods.
The results show that the ?OR?
combination yield-ed better recall than the individual methods, and the ?AND?
combination yielded better precision andFPR than the individual methods.
Thus, the choice of methods may depend on application require-ments or preferences69Method Precision Recall F1 False Positive RateRule 0.857 0.224 0.356 0.0382-gram 0.555 0.751 0.638 0.6033-gram 0.585 0.838 0.689 0.595Rule OR 2-gram 0.500 1.000 0.667 1.000Rule OR 3-gram 0.502 1.000 0.668 0.993Rule AND 2-gram 0.924 0.083 0.153 0.007Rule AND 3-gram 0.924 0.083 0.153 0.007Table 1.
Comparative results of the rule-based and n-gram statistical approaches.Many learner corpora exist for EFL for use in machine learning, including the International Corpusof Learner English (ICLE) and Cambridge Learner Corpus (CLC).
But collecting a representativesample of authentic errors from CFL learners poses a challenge.
In addition, English and Chinesegrammars are markedly different.
In contrast to syntax-oriented English language, Chinese is dis-course-oriented, with meaning often expressed in several clauses to make a complete sentence.
Thesecharacteristics make syntactic parsing difficult, due to long dependency between words in a clause oracross clauses in a sentence.
These difficulties constrain system performance.4 ConclusionsThis study presents a sentence judgment system developed using both rule-based and n-gram statisti-cal methods to detect grammatical errors in sentences written by CFL learners.
The system not onlyalerts learners to potential grammatical errors in their input sentences, but also helps them learn aboutlinguistic rules and n-gram frequencies.
The major contributions of this work include: (a) demonstrat-ingg the feasibility of detecting grammatical errors in sentences written by CFL learners, (b) develop-ing a system to facilitate autonomous learning among CFL learners and (c) collecting real grammaticalerrors  from CFL learners for the construction of a Chinese learner corpus.AcknowledgmentsThis research was partially supported by Ministry of Science and Technology, Taiwan under the grantNSC102-2221-E-155-029-MY3, NSC 102-2221-E-002-103-MY3, and the "Aim for the Top Universi-ty Project" sponsored by the Ministry of Education, Taiwan.ReferenceAndreas Stolcke.
2002.
SRILM ?
An extensible language modeling toolkit.
Proceedings of ICSLP?02, pages901-904.Chi-Hsin Yu and Hsin-Hsi Chen.
2012.
Detecting word ordering errors in Chinese sentences for learning Chi-nese as a foreign language.
Proceedings of COLING?12, pages 3003-3018.Christopher D. Manning and Hinrich Sch?tze.
1999.
Foundations of Statistical Natural Language Processing.MIT Press.
Cambridge, MA.Chung-Hsien Wu, Chao-Hung Liu, Matthew Harris and Liang-Chih Yu.
2010.
Sentence correction incorporatingrelative position and parse template language model.
IEEE Transactions on Audio, Speech, and LanguageProcessing, 18(6):1170-1181.Keh-Jiann Chen and Wei-Yun Ma.
2002.
Unknown word extraction for Chinese documents.
Proceedings ofCOLING?02, pages 169-175.M.
Cheng.
1997.
Analysis of 900 Common Erroneous Samples of Chinese Sentences - for Chinese Learnersfrom English Speaking Countries (in Chinese).
Beijing, CN: Sinolingua.Ru-Ying Chang, Chung-Hsien Wu, and Philips K. Prasetyo.
2012.
Error diagnosis of Chinese sentences usinginductive learning algorithm and decomposition-based testing mechanism.
ACM Transactions on Asian Lan-guage Information Processing, 11(1):Article 3.Yu-Fang Tsai and Keh-Jiann Chen.
2004.
Reliable and cost-effective pos-tagging.
International Journal ofComputational Linguistics and Chinese Language Processing, 9(1):83-96.70
