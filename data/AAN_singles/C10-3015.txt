Coling 2010: Demonstration Volume, pages 57?60,Beijing, August 2010Multiword Expressions in the wild?The mwetoolkit comes in handyCarlos Ramisch??
Aline Villavicencio?
Christian Boitet??
GETALP ?
Laboratory of Informatics of Grenoble, University of Grenoble?
Institute of Informatics, Federal University of Rio Grande do Sul{ceramisch,avillavicencio}@inf.ufrgs.br Christian.Boitet@imag.frAbstractThe mwetoolkit is a tool for auto-matic extraction of Multiword Expres-sions (MWEs) from monolingual corpora.It both generates and validates MWE can-didates.
The generation is based on sur-face forms, while for the validation, a se-ries of criteria for removing noise are pro-vided, such as some (language indepen-dent) association measures.1 In this paper,we present the use of the mwetoolkitin a standard configuration, for extractingMWEs from a corpus of general-purposeEnglish.
The functionalities of the toolkitare discussed in terms of a set of selectedexamples, comparing it with related workon MWE extraction.1 MWEs in a nutshellOne of the factors that makes Natural LanguageProcessing (NLP) a challenging area is the factthat some linguistic phenomena are not entirelycompositional or predictable.
For instance, whydo we prefer to say full moon instead of total moonor entire moon if all these words can be consid-ered synonyms to transmit the idea of complete-ness?
This is an example of a collocation, i.e.
asequence of words that tend to occur together andwhose interpretation generally crosses the bound-aries between words (Smadja, 1993).
More gen-erally, collocations are a frequent type of mul-tiword expression (MWE), a sequence of wordsthat presents some lexical, syntactic, semantic,pragmatic or statistical idiosyncrasies (Sag et al,2002).
The definition of MWE also includes awide range of constructions like phrasal verbs (go1The first version of the toolkit was presented in(Ramisch et al, 2010b), where we described a language- andtype-independent methodology.ahead, give up), noun compounds (ground speed),fixed expressions (a priori) and multiword termi-nology (design pattern).
Due to their heterogene-ity, MWEs vary in terms of syntactic flexibility(let alne vs the moon is at the full) and semanticopaqueness (wheel chair vs pass away).While fairly studied and analysed in generalLinguistics, MWEs are a weakness in currentcomputational approaches to language.
This isunderstandable, since the manual creation of lan-guage resources for NLP applications is expen-sive and demands a considerable amount of ef-fort.
However, next-generation NLP systems needto take MWEs into account, because they corre-spond to a large fraction of the lexicon of a na-tive speaker (Jackendoff, 1997).
Particularly inthe context of domain adaptation, where we wouldlike to minimise the effort of porting a given sys-tem to a new domain, MWEs are likely to play acapital role.
Indeed, theoretical estimations showthat specialised lexica may contain between 50%and 70% of multiword entries (Sag et al, 2002).Empirical evidence confirms these estimations: asan example, we found that 56.7% of the termsannotated in the Genia corpus are composed bytwo or more words, and this is an underestimationsince it does not include general-purpose MWEssuch as phrasal verbs and fixed expressions.The goal of mwetoolkit is to aid lexicog-raphers and terminographers in the task of creat-ing language resources that include multiword en-tries.
Therefore, we assume that, whenever a tex-tual corpus of the target language/domain is avail-able, it is possible to automatically extract inter-esting sequences of words that can be regarded ascandidate MWEs.2 Inside the black boxMWE identification is composed of two phases:first, we automatically generate a list of candi-57mle = c(w1 .
.
.wn)Ndice = n?
c(w1 .
.
.wn)?ni=1 c(wi)pmi = log2c(w1 .
.
.wn)E(w1 .
.
.wn)t-score = c(w1 .
.
.wn)?E(w1 .
.
.wn)?c(w1 .
.
.wn)Figure 1: A candidate is a sequence of words w1 town, with word counts c(w1) .
.
.c(wn) and n-gramcount c(w1 .
.
.wn) in a corpus with N words.
Theexpected count if words co-occurred by chance isE(w1 .
.
.wn)?
c(w1)...c(wn)Nn?1 .dates from the corpus; then we filter them, so thatwe can discard as much noise as possible.
Can-didate generation uses flat linguistic informationsuch as surface forms, lemmas and parts of speech(POS).2 We can then define target sequences ofPOS, such as VERB NOUN sequences, or evenmore fine-grained constraints which use lemmas,like take NOUN and give NOUN, or POS patternsthat include wildcards that stand for any word orPOS.3 The optimal POS patterns for a given do-main, language and MWE type can be definedbased on the analysis of the data.For the candidate filtering a set of associationmeasures (AMs), listed in figure 1, are calculatedfor each candidate.
A simple threshold can sub-sequently be applied to filter out all the candidatesfor which the AMs fall below a user-defined value.If a gold standard is available, the toolkit can builda classifier, automatically annotating each candi-date to indicate whether it is contained in the goldstandard (i.e.
it is regarded as a true MWE) ornot (i.e.
it is regarded as a non-MWE).4 Thisannotation is not used to filter the lists, but only2If tools like a POS tagger are not available for a lan-guage/domain, it is possible to generate simple n-gram lists(n = 1..10), but the quality will be inferior.
A possible solu-tion is to filter out candidates on a keyword basis, e.g.
froma list of stopwords).3Although syntactic information can provide better re-sults for some types of MWEs, like collocations (Seretan,2008), currently no syntactic information is allowed as a cri-terion for candidate generation, keeping the toolkit as simpleand language independent as possible.4The gold standard can be a dictionary or a manually an-notated list of candidates.candidate fEP fgoogle classstatus quo 137 1940K TrueUS navy 4 1320K FalseInternational Cooperation 2 1150K FalseCooperation Agreement 188 115K TruePanama Canal 2 753K Truesecurity institution 5 8190 Falselending institution 4 54800 Truehuman right 2 251K TrueHuman Rights 3067 3400K Falsepro-human right 2 34 FalseTable 1: Example of MWE candidates extractedby mwetoolkit.by the classifier to learn the relation between theAMs and the MWE class of the candidate.
Thisis particularly useful because, to date, it remainsunclear which AM performs better for a partic-ular type or language, and the classifier appliesmeasures according to their efficacy in filteringthe candidates.Some examples of output are pre-sented in table 1.3 Getting startedThe toolkit is open source software that canbe freely downloaded (sf.net/projects/mwetoolkit).
As a demonstration, we presentthe extraction of noun-noun compounds from thegeneral-purpose English Europarl (EP) corpus5.To preprocess the corpus, we used the sen-tence splitter and tokeniser provided with EP, fol-lowed by a lowercasing treatment (integrated inthe toolkit), and lemmatisation and POS taggingusing the TreeTagger6.
The tagset was simplifiedsince some distinctions among plural/singular andproper nouns were irrelevant.From the preprocessed corpus, we obtained allsequences of 2 nouns, which resulted in 176,552unique noun compound candidates.
Then, we ob-tained the corpus counts for the bigrams and theircomponent unigrams in the EP corpus.
Adopt-ing the web as a corpus, we also use the numberof pages retrieved by Google and by Yahoo!
as5www.statmt.org/europarl.6http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/.58raw ENEuroparlsentence-split,lowercased,tokenised, POS-tagged,lemmatised Europarl  Preprocessingnoun-nouncandidatesfiltered-1candidatesfiltered-2candidates  Count candidatesThresholdAssociation meas.Sort and thresholdmwetoolkitFigure 2: Step-by-step demonstration on the EPcorpus.counts.
The mwetoolkit implements a cachemechanism to avoid redundant queries, but tospeed up the process7, we filtered out all candi-dates occurring less than two times in EP, whichreduced the list of candidates to 64,551 entries(filtered-1 candidates in figure 2).For the second filtering step, we calculatedfour AMs for each of the three frequency sources(EP, Google and Yahoo!).
Some results on ma-chine learning applied to the candidate lists ofthe mwetoolkit can be found in Ramisch et al(2010b).
Here, we will limit ourselves to a dis-cussion on some advantages and inconvenients ofthe chosen approach by analysing a list of selectedexamples.4 Pros and consOne of the biggest advantages of our approach isthat, since it is language independent, it is straight-forward to apply it on corpora in virtually anylanguage.
Moreover, it is not dependent on aspecific type of construction or syntactic formal-ism.
Of course, since it only uses limited linguis-tic information, the accuracy of the resulting listscan always be further improved with language-dependent tools.
In sum, the toolkit allows usersto perform systematic MWE extraction with con-sistent intermediary files and well defined scriptsand arguments (avoiding the need for a series of adhoc separate scripts).
Even if some basic knowl-edge about how to run Python scripts and how to7Yahoo!
limits the queries to 5,000/day.pass arguments to the command line is necessary,the user is not required to be a programmer.Nested MWEs are a problem in the currentapproach.
Table 1 shows two bigrams Interna-tional Cooperation and Cooperation Agreement,both evaluated as False candidates.
However, theycould be considered as parts of a larger MWE In-ternational Cooperation Agreement, but with thecurrent methodology it is not possible to detectthis kind of situation.
Another case where thecandidate contains a MWE is the example pro-human right, and in this case it would be neces-sary to separate the prefix from the MWE, i.e.
tore-tokenise the words around the MWE candidate.Indeed, tools for consistent tokenisation, speciallyconcerning dashes and slashes, could improve thequality of the results, in particular for specialisedcorpora.The toolkit provides full integration with websearch engine APIs.
The latter, however, are oflimited utility because search engines are not onlyslow but also return more or less arbitrary num-bers, some times even inconsistent (Ramisch etal., 2010c).
When large corpora like EP are avail-able, we suggest that it is better to use its countsrather than web counts.
The toolkit provides anefficient indexing mechanism, allowing for arbi-trary n-grams to be counted in linear time.The automatic evaluation of the candidates willalways be limited by the coverage of the referencelist.
In the examples, Panama Canal is consid-ered as a true MWE whereas US navy is not, butboth are proper names and the latter should alsobe included as a true candidate.
The same happensfor the candidates Human Rights and human right.The mwetoolkit is an early prototype whosesimple design allows fine tuning of knowledge-poor methods for MWE extraction.
However, webelieve that there is room for improvement at sev-eral points of the extraction methodology.5 From now onOne of our goals for future versions is to be ableto extract bilingual MWEs from parallel or com-parable corpora automatically.
This could be donethrough the inclusion of automatic word align-ment information.
Some previous experimentsshow, however, that this may not be enough, as59automatic word alignment uses almost no lin-guistic information and its output is often quitenoisy (Ramisch et al, 2010a).
Combining align-ment and shallow linguistic information seems apromising solution for the automatic extractionof bilingual MWEs.
The potential uses of theselexica are multiple, but the most obvious appli-cation is machine translation.
On the one hand,MWEs could be used to guide the word align-ment process.
For instance, this could solve theproblem of aligning a language where compoundsare separate words, like French, with a languagethat joins compound words together, like Ger-man.
In statistical machine translation systems,MWEs could help to filter phrase tables or to boostthe scores of phrases which words are likely tobe multiwords.Some types of MWE (e.g.
collo-cations) could help in the semantic disambigua-tion of words in the source language.
The senseof a word defined by its collocate can allow tochose the correct target word or expression (Sere-tan, 2008).We would also like to improve the techniquesimplemented for candidate filtering.
Related workshowed that association measures based on con-tingency tables are more robust to data sparseness(Evert and Krenn, 2005).
However, they are pair-wise comparisons and their application on arbi-trarily long n-grams is not straightforward.
Anheuristics to adapt these measures is to apply themrecursively over increasing n-gram length.
Otherfeatures that could provide better classificationare context words, linguistic information comingfrom simple word lexica, syntax, semantic classesand domain-specific keywords.
While for poor-resourced languages we can only count on shallowlinguistic information, it is unreasonable to ignoreavailable information for other languages.
In gen-eral, machine learning performs better when moreinformation is available (Pecina, 2008).We would like to evaluate our toolkit on severaldata sets, varying the languages, domains and tar-get MWE types.
This would allow us to assignits quantitative performance and to compare it toother tools performing similar tasks.
Additionally,we could evaluate how well the classifiers performacross languages and domains.
In short, we be-lieve that the mwetoolkit is an important firststep toward robust and reliable MWE treatment.It is a freely available core application providingflexible tools and coherent up-to-date documenta-tion, and these are essential characteristics for theextension and support of any computer system.AcknowledgementsThis research was partly supported by CNPq(Projects 479824/2009-6 and 309569/2009-5),FINEP and SEBRAE (COMUNICA projectFINEP/SEBRAE 1194/07).ReferencesEvert, Stefan and Brigitte Krenn.
2005.
Using smallrandom samples for the manual evaluation of statis-tical association measures.
Comp.
Speech & Lang.Special issue on MWEs, 19(4):450?466.Jackendoff, Ray.
1997.
Twistin?
the night away.
Lan-guage, 73:534?559.Pecina, Pavel.
2008.
Reference data for czech colloca-tion extraction.
In Proc.
of the LREC Workshop To-wards a Shared Task for MWEs (MWE 2008), pages11?14, Marrakech, Morocco, Jun.Ramisch, Carlos, Helena de Medeiros Caseli, AlineVillavicencio, Andr?
Machado, and Maria Jos?
Fi-natto.
2010a.
A hybrid approach for multiword ex-pression identification.
In Proc.
of the 9th PROPOR(PROPOR 2010), volume 6001 of LNCS (LNAI),pages 65?74, Porto Alegre, RS, Brazil.
Springer.Ramisch, Carlos, Aline Villavicencio, and ChristianBoitet.
2010b.
mwetoolkit: a framework for multi-word expression identification.
In Proc.
of the Sev-enth LREC (LREC 2010), Malta, May.
ELRA.Ramisch, Carlos, Aline Villavicencio, and ChristianBoitet.
2010c.
Web-based and combined languagemodels: a case study on noun compound identifica-tion.
In Proc.
of the 23th COLING (COLING 2010),Beijing, China, Aug.Sag, Ivan, Timothy Baldwin, Francis Bond, AnnCopestake, and Dan Flickinger.
2002.
Multi-word expressions: A pain in the neck for NLP.In Proc.
of the 3rd CICLing (CICLing-2002), vol-ume 2276/2010 of LNCS, pages 1?15, Mexico City,Mexico, Feb. Springer.Seretan, Violeta.
2008.
Collocation extraction basedon syntactic parsing.
Ph.D. thesis, University ofGeneva, Geneva, Switzerland.Smadja, Frank A.
1993.
Retrieving collocations fromtext: Xtract.
Comp.
Ling., 19(1):143?177.60
