Towards a Semantic Classication of Spanish Verbs Based onSubcategorisation InformationEva Esteve FerrerDepartment of InformaticsUniversity of SussexBrighton, BN1 9QH, UKE.Esteve-Ferrer@sussex.ac.ukAbstractWe present experiments aiming at an automaticclassification of Spanish verbs into lexical semanticclasses.
We apply well-known techniques that havebeen developed for the English language to Span-ish, proving that empirical methods can be re-usedthrough languages without substantial changes inthe methodology.
Our results on subcategorisationacquisition compare favourably to the state of the artfor English.
For the verb classification task, we usea hierarchical clustering algorithm, and we comparethe output clusters to a manually constructed classi-fication.1 IntroductionLexical semantic classes group together words thathave a similar meaning.
Knowledge about verbsis especially important, since verbs are the primarymeans of structuring and conveying meaning in sen-tences.
Manually built semantic classifications ofEnglish verbs have been used for different applica-tions such as machine translation (Dorr, 1997), verbsubcategorisation acquisition (Korhonen, 2002a) orparsing (Schneider, 2003).
(Levin, 1993) has estab-lished a large-scale classification of English verbsbased on the hypothesis that the meaning of a verband its syntactic behaviour are related, and there-fore semantic information can be induced from thesyntactic behaviour of the verb.
A classificationof Spanish verbs based on the same hypothesis hasbeen developed by (Va?zquez et al, 2000).
But man-ually constructing large-scale verb classifications isa labour-intensive task.
For this reason, variousmethods for automatically classifying verbs usingmachine learning techniques have been attempted((Merlo and Stevenson, 2001), (Stevenson and Joa-nis, 2003), (Schulte im Walde, 2003)).In this article we present experiments aiming atautomatically classifying Spanish verbs into lexi-cal semantic classes based on their subcategorisa-tion frames.
We adopt the idea that a description ofverbs in terms of their syntactic behaviour is usefulfor acquiring their semantic properties.
The classi-fication task at hand is achieved through a processthat requires different steps: we first extract from apartially parsed corpus the probabilities of the sub-categorisation frames for each verb.
Then, the ac-quired probabilities are used as features describingthe verbs and given as input to an unsupervised clas-sification algorithm that clusters together the verbsaccording to the similarity of their descriptions.
Forthe task of acquiring verb subcategorisation frames,we adapt to the specificities of the Spanish languagewell-known techniques that have been developedfor English, and our results compare favourably tothe sate of the art results obtained for English (Ko-rhonen, 2002b).
For the verb classification task, weuse a hierarchical clustering algorithm, and we com-pare the output clusters to a manually constructedclassification developed by (Va?zquez et al, 2000).2 Acquisition of SpanishSubcategorisation FramesSubcategorisation frames encode the informationof how many arguments are required by the verb,and of what syntactic type.
Acquiring the subcat-egorization frames for a verb involves, in the firstplace, distinguishing which constituents are its ar-guments and which are adjuncts, elements that givean additional piece of information to the sentence.Moreover, sentences contain other constituents thatare not included in the subcategorisation frames ofverbs: these are sub-constituents that are not struc-turally attached to the verb, but to other constituents.2.1 Methodology and MaterialsWe experiment our methodology on two corpora ofdifferent sizes, both consisting of Spanish newswiretext: a 3 million word corpus, hereafter called smallcorpus, and a 50 million word corpus, hereaftercalled large corpus.
They are both POS taggedand partially parsed using the MS-analyzer, a par-tial parser for Spanish that includes named entitiesrecognition (Atserias et al, 1998).In order to collect the frequency distributionsof Spanish subcategorisation frames, we adapt amethodology that has been developed for Englishto the specificities of the Spanish language ((Brent,1993), (Manning, 1993), (Korhonen, 2002b)).
Itconsists in extracting from the corpus pairs madeof a verb and its co-occurring constituents that are apossible pattern of a frame, and then filtering outthe patterns that do not have a probability of co-occurrence with the verb high enough to be consid-ered its arguments.We establish a set of 11 possible Spanish subcat-egorisation frames.
These are the plausible combi-nations of a maximum of 2 of the following con-stituents: nominal phrases, prepositional phrases,temporal sentential clauses, gerundive sententialclauses, infinitival sentential clauses, and infinitivalsentential clauses introduced by a preposition.
Theindividual prepositions are also taken into accountas part of the subcategorisation frame types.Adapting a methodology that has been thoughtfor English presents a few problems, because En-glish is a language with a strong word order con-straint, while in Spanish the order of constituents isfreer.
Although the unmarked order of constituentsis Subject Verb Object with the direct object pre-ceding the indirect object, in naturally occurringlanguage the constituents can be moved to non-canonical positions.
Since we extract the patternsfrom a partially parsed corpus, which has no infor-mation on the attachment or grammatical functionof the constituents, we have to take into accountthat the extraction is an approximation.
There arevarious phenomena that can lead us to an erroneousextraction of the constituents.
As an illustrative ex-ample, in Spanish it is possible to have an inversionin the order of the objects, as can be observed insentence (1), where the indirect object a Straw (?toStraw?)
precedes the direct object los alegatos (?thepleas?).
(1) El gobierno chileno presentara?
hoy a Strawlos alegatos (.
.
.
).
?The Chilean government will present today toStraw the pleas (.
.
.
)?.Dealing with this kind of phenomenon introducessome noise in the data.
Matching a pattern for asubcategorisation frame from sentence (1), for ex-ample, we would misleadingly induce the pattern[ PP(a)] for the verb presentar, ?present?, whenin fact the correct pattern for this sentence is [ NPPP(a)].The solution we adopt for dealing with the vari-ations in the order of constituents is to take intoaccount the functional information provided by cl-itics.
Clitics are unstressed pronouns that refer toan antecedent in the discourse.
In Spanish, cliticpronouns can only refer to the subject, the directobject, or the indirect object of the verb, and theycan in most cases be disambiguated taking into ac-count their agreement (in person, number and gen-der) with the verb.
When we find a clitic pronoun ina sentence, we know that an argument position is al-ready filled by it, and the rest of the constituents thatare candidates for the position are either discardedor moved to another position.
Sentence (2) showsan example of how the presence of clitic pronounsallows us to transform the patterns extracted.
Thesentence would normally match with the frame pat-tern [ PP(por)], but the presence of the clitic (whichhas the form le) allows us to deduce that the sen-tence contains an indirect object, realised in the sub-categorisation pattern with a prepositional phraseheaded by a in second position.
Therefore, we lookfor the following nominal phrase, la aparici ?on delcad?aver, to fill the slot of the direct object, that oth-erwise would have not been included in the pattern.
(2) Por la tarde, agentes del cuerpo nacionalde polic?
?a le comunicaron por tele?fono laaparicio?n del cada?ver.
?In the afternoon, agents of the national policeclitic IO reported by phone the apparition ofthe corpse.
?.The collection of pairs verb + pattern obtainedwith the method described in the last section needsto be filtered out, because we may have extractedconstituents that are in fact adjuncts, or elementsthat are not attached to the verb, or errors in theextraction process.
We filter out the spurious pat-terns with a Maximum Likelihood Estimate (MLE),a method proposed by (Korhonen, 2002b) for thistask.
MLE is calculated as the ratio of the frequencyof  	+  	 over the frequency of   .Pairs of verb+pattern that do not have a probabil-ity of co-occurring together higher than a certainthreshold are filtered out.
The threshold is deter-mined empirically using held-out data (20% of thetotal of the corpus), by choosing from a range of val-ues between 0.02 and 0.1 the value that yields betterresults against a held-out gold standard of 10 verbs.In our experiments, this method yields a thresholdvalue of 0.05.2.2 Experimental EvaluationWe evaluate the obtained subcategorisation framesin terms of precision and recall compared to a goldNo Prep.
Groups Preposition GroupsCorpus Prec Rec F Prec Rec FSmall 65 62 63 63 61 62Baseline 25 78 38 31 82 45Large 70 60 65 71 61 66Baseline 8 96 14 8 96 14Table 1: Results for the acquisition of subcategori-sation frames.standard.
The gold standard is manually constructedfor a sample of 41 verbs.
The verb sample is chosenrandomly from our data with the condition that bothfrequent and infrequent verbs are represented, andthat we have examples of all our subcategorisationframe types.
We perform experiments on two cor-pora of different sizes, expecting that the differencesin the results will show that a large amount of datadoes significantly improve the performance of anygiven system without any changes in the methodol-ogy.
After the extraction process, the small corpusconsists of 58493 pairs of verb+pattern, while thelarge corpus contains 1253188 pairs.1 Since we in-clude in our patterns the heads of the prepositionalphrases, the corpora contain a large number of pat-tern types (838 in the small corpora, and 2099 inthe large corpora).
We investigate grouping seman-tically equivalent prepositions together, in order toreduce the number of pattern types, and thereforeincrement the probabilities on the patterns.
Thepreposition groups are established manually.Table 1 shows the average results obtained on thetwo different corpora for the 41 test verbs.
The base-lines are established by considering all the framepatterns obtained in the extraction process as cor-rect frames.
The experiments on the large corpusgive better results than the ones on the small one,and grouping similar prepositions together is usefulonly on the large corpus.
This is probably due to thefact that the small corpus does not suffer from a toolarge number of frame types, and the effect of thegroupings cannot be noticed.
The F measure valueof 66% reported on the third line of table 1, ob-tained on the large corpus with preposition groups,compares favourably to the results reported on (Ko-rhonen, 2002b) for a similar experiment on Englishsubcategorization frames, in which an F measure of65.2 is achieved.1In all experiments, we post-process the data by eliminatingprepositional constituents in the second position of the patternthat are introduced with the preposition de, ?of?.
This is moti-vated by the observation that in 96.8% of the cases this prepo-sition is attached to the preceding constituent, and not to theverb.3 Clustering Verbs into ClassesWe use a bottom-up hierarchical clustering algo-rithm to group together 514 verbs into K classes.The algorithm starts by finding the similarities be-tween all the possible pairs of objects in the data ac-cording to a similarity measure S. After having es-tablished the distance between all the pairs, it linkstogether the closest pairs of objects by a linkagemethod L, forming a binary cluster.
The linkingprocess is repeated iteratively over the newly cre-ated clusters until all the objects are grouped intoone cluster.
K, S and L are parameters that can beset for the clustering.
For the similarity measureS, we choose the Euclidean distance.
For the link-age method L, we choose the Ward linkage method(Ward, 1963).
Our choice of the parameter settingsis motivated by the work of (Stevenson and Joanis,2003).
Applying a clustering method to the verbsin our data, we expect to find a natural division ofthe data that will be in accordance with the classi-fication of verbs that we have set as our target clas-sification.
We perform different experiments withdifferent values for K in order to test which of thedifferent granularities yields better results.3.1 The Target ClassificationIn order to be able to evaluate the clusters out-put by the algorithm, we need to establish a man-ual classification of sample verbs.
We assume themanual classification of Spanish verbs developedby (Va?zquez et al, 2000).
In their classification,verbs are organised on the basis of meaning com-ponents, diathesis alternations and event structure.They classify a large number of verbs into threemain classes (Trajectory, Change and Attitude) thatare further subdivided into a total of 31 subclasses.Their classification follows the same basic hypothe-ses as Levin?s, but the resulting classes differ insome important aspects.
For example, the Trajec-tory class groups together Levin?s Verbs of Motion(move), Verbs of Communication (tell) and verbs ofChange of Possession (give), among others.
Theirjustification for this grouping is that all the verbsin this class have a Trajectory meaning compo-nent, and that they all undergo the Underspecifica-tion alternation (in Levin?s terminology, the Loca-tive Preposition Drop and the Unspecified Objectalternations).
The size of the classes at the lowerlevel of the classification hierarchy varies from 2 to176.3.2 MaterialsThe input to the algorithm is a description of eachof the verbs in the form of a vector containing theprobabilities of their subcategorisation frames.
Weobtain the subcategorisation frames with the methoddescribed in the previous section that gave better re-sults: using the large corpus, and reducing the num-ber of frame types by merging individual preposi-tions into groups.
In order to reduce the numberof frame types still further, we only take into ac-count the ones that occur more than 10 times inthe corpus.
In this way, we have a set of 66 frametypes.
Moreover, for the purpose of the classifica-tion task, the subcategorisation frames are enhancedwith extra information that is intended to reflectproperties of the verbs that are relevant for the targetclassification.
The target classification is based onthree aspects of the verb properties: meaning com-ponents, diathesis alternations, and event structure,but the information provided by subcategorisationframes only reflects on the second of them.
Weexpect to provide some information on the mean-ing components participating in the action by takinginto account whether subjects and direct objects arerecognised by the partial parser as named entities.Then, the possible labels for these constituents are?no NE?, ?persons?, ?locations?, and ?institutions?.We introduce this new feature by splitting the proba-bility mass of each frame among the possible labels,according to their frequencies.
Now, we have a totalof 97 features for each verb of our sample.3.3 Clustering EvaluationEvaluating the results of a clustering experiment is acomplex task because ideally we would like the out-put to fulfil different goals.
One the one hand, theclusters obtained should reflect a good partition ofthe data, yielding consistent clusters.
On the otherhand, the partition of the data obtained should beas similar as possible to the manually constructedclassification, the gold standard.
We use the Silhou-ette measure (Kaufman and Rousseeuw, 1990) as anindication of the consistency of the obtained clus-ters, regardless of the division of the data in the goldstandard.
For each clustering experiment, we calcu-late the mean of the silhouette value of all the datapoints, in order to get an indication of the overallquality of the clusters created.
The main difficulty inevaluating unsupervised classification tasks againsta gold standard lies in the fact that the class labelsof the obtained clusters are unknown.
Therefore, theevaluation is done according to the pairs of objectsthat the two groups have in common.
(Schulte imWalde, 2003) reports that the evaluation method thatis most appropriate to the task of unsupervised verbclassification is the Adjusted Rand measure.
It givesa value of 1 if the two classifications agree com-No Named EntitiesTask Mean Sil Baseline Radj3-way 0.37 0 0.00115-way 0.37 0 0.04031-way 0.27 0 0.070Table 2: Clustering evaluation for the experimentwithout Named EntitiesNamed EntitiesTask Mean Sil Baseline Radj3-way 0.37 0 0.0115-way 0.31 0 0.0731-way 0.22 0 0.03Table 3: Clustering evaluation for the experimentwith Named Entitiespletely in which pairs of objects are clustered to-gether and which are not, while complete disagree-ment between two classifications yields a value of-1.3.4 Experimental ResultsWe perform various clustering experiments in or-der to test, on the one hand, the usefulness of ourenhanced subcategorisation frames.
On the otherhand, we intend to discover which is the natural par-tition of the data that best accommodates our targetclassification.
The target classification is a hierar-chy of three levels, each of them dividing the datainto 3, 15, or 31 levels.
For this reason, we ex-periment on 3, 15, and 31 desired output clusters,and evaluate them on each of the target classifica-tion levels, respectively.Table 2 shows the evaluation results of the clus-tering experiment that takes as input bare subcate-gorisation frames.
Table 3 shows the evaluation re-sults of the experiment that includes named entityrecognition in the features describing the verbs.
Inboth tables, each line reports the results of a clas-sification task.
The average Silhouette measure isshown in the second column.
We can observe thatthe best classification tasks in terms of the Silhou-ette measure are the 3-way and 15-way classifica-tions.
The baseline is calculated, for each task, asthe average value of the Adjusted Rand measure for100 random cluster assignations.
Although all thetasks perform better than the baseline, the increaseis so small that it is clear that some improvementshave to be done on the experiments.
Accordingto the Adjusted Rand measure, the clustering algo-rithm seems to perform better in the tasks with alarger number of classes.
On the other hand, the en-hanced features are useful on the 15-way and 3-wayclassifications, but they are harmful in the 31-wayclassification.
In spite of these results, a qualita-tive observation of the output clusters reveals thatthey are intuitively plausible, and that the evalua-tion is penalised by the fact that the target classesare of very different sizes.
On the other hand, ourdata takes into account syntactic information, whilethe target classification is not only based on syn-tax, but also on other aspects of the properties of theverbs.
These results compare poorly to the perfor-mance achieved by (Schulte im Walde, 2003), whoobtains an Adjusted Rand measure of 0.15 in a sim-ilar task, in which she classifies 168 German verbsinto 43 semantic verb classes.
Nevertheless, our re-sults are comparable to a subset of experiments re-ported in (Stevenson and Joanis, 2003), where theyperform similar clustering experiments on Englishverbs based on a general description of verbs, ob-taining average Adjusted Rand measures of 0.04and 0.07.4 Conclusions and Future WorkWe have presented a series of experiments that usean unsupervised learning method to classify Span-ish verbs into semantic classes based on subcate-gorisation information.
We apply well-known tech-niques that have been developed for the English lan-guage to Spanish, confirming that empirical meth-ods can be re-used through languages without sub-stantial changes in the methodology.
In the taskof acquiring subcategorisation frames, we achievestate of the art results.
On the contrary, the taskof inducing semantic classes from syntactic infor-mation using a clustering algorithm leaves room forimprovement.
The future work for this task goes ontwo directions.On the one hand, the theoretical basis of the man-ual verb classification suggests that, although thesyntactic behaviour of verbs is an important crite-ria for a semantic classification, other properties ofthe verbs should be taken into account.
Therefore,the description of verbs could be further enhancedwith features that reflect on meaning componentsand event structure.
The incorporation of name en-tity recognition in the experiments reported here isa first step in this direction, but it is probably atoo sparse feature in the data to make any signif-icant contributions.
The event structure of predi-cates could be statistically approximated from textby grasping the aspect of the verb.
The aspect ofthe verbs could, in turn, be approximated by devel-oping features that would consider the usage of cer-tain tenses, or the presence of certain types of ad-verbs that imply a restriction on the aspect of theverb.
Adverbs such as ?suddenly?, ?continuously?,?often?, or even adverbial sentences such as ?everyday?
give information on the event structure of pred-icates.
As they are a closed class of words, a typol-ogy of adverbs could be established to approximatethe event structure of the verb (Esteve Ferrer andMerlo, 2003).On the other hand, an observation of the verbclusters output by the algorithm suggests that theyare intuitively more plausible than what the evalua-tion measures indicate.
For the purposes of possi-ble applications, a hard clustering of verbs does notseem to be necessary, especially when even man-ually constructed classifications adopt arbitrary de-cisions and do not agree with each other: knowingwhich verbs are semantically similar to each other ina more ?fuzzy?
way might be even more useful.
Forthis reason, a new approach could be envisaged forthis task, in the direction of the work by (Weeds andWeir, 2003), by building rankings of similarity foreach verb.
For the purpose of evaluation, the goldstandard classification could also be organised in theform of similarity rankings, based on the distancebetween the verbs in the hierarchy.
Then, the rank-ings for each verb could be evaluated.
The two di-rections appointed here, enriching the verb descrip-tions with new features that grasp other propertiesof the verbs, and envisaging a similarity ranking ofverbs instead of a hard clustering, are the next stepsto be taken for this work.AcknowledgementsThe realisation of this work was possible thanks tothe funding of the Swiss FNRS project number 11-65328.01.ReferencesJordi Atserias, Josep Carmona, Irene Castello?n,Sergi Cervell, Montserrat Civit, Llu?
?s Ma`rquez,M.
Antonia Mart?
?, Llu?
?s Padro?, Roser Placer,Horacio Rodr?
?guez, Mariona Taule?, and JordiTurmo.
1998.
Morphosyntactic analysis andparsing of unrestricted spanish text.
In Proceed-ings of the First International Conference onLanguage Resources and Evaluation (LREC?98),pages 1267?1272, Granada/Spain.Michael Brent.
1993.
From grammar to lexicon:Unsupervised learning of lexical syntax.
Compu-tational Linguistics, 19(2):243?262.Bonnie Dorr.
1997.
Large-scale dictionary con-struction for foreign language tutoring and in-terlingual machine translation.
Machine Transla-tion, 12(4):1?55.Eva Esteve Ferrer and Paola Merlo.
2003.
Auto-matic classification of english verbs.
Technicalreport, Universite?
de Gene`ve.Leonard Kaufman and Peter J. Rousseeuw.
1990.Finding Groups in Data - An Introduction toCluster Analysis.
Probability and MathematicalStatistics.
Jonh Wiley and Sons, Inc., New York.Anna Korhonen.
2002a.
Semantically motivatedsubcategorization acquisition.
In Proceedings ofthe Workshop of the ACL Special Interest Groupon the Lexicon on Unsupervised Lexical Acquisi-tion, pages 51?58, Philadelphia,PA, July.Anna Korhonen.
2002b.
Subcategorisation Acqui-sition.
Ph.D. thesis, University of Cambridge.distributed as UCAM-CL-TR-530.Beth Levin.
1993.
English Verb Classes and Alter-nations.
University of Chicago Press, Chicago,IL.Christopher Manning.
1993.
Automatic acquisitionof a large subcategorization dictionary from cor-pora.
In Proceedings of the 31st Annual Meetingof the ACL, pages 235?242, Columbus/Ohio.Paola Merlo and Suzanne Stevenson.
2001.
Auto-matic verb classification based on statistical dis-tributions of argument structure.
ComputationalLinguistics, 27(3):373?408.Gerold Schneider.
2003.
A low-complexity, broadcoverage probabilistic dependency parser for en-glish.
In Proceedings of NAACL/HLT 2003 Stu-dent Session, pages 31?36, Edmonton/Canada.Sabine Schulte im Walde.
2003.
Experimentson the Automatic Induction of German Se-mantic Verb Classes.
Ph.D. thesis, Institutfur Maschinelle Sprachverarbeitung, UniversitatStuttgart.
Published as AIMS Report 9(2).Suzanne Stevenson and Eric Joanis.
2003.
Semi-supervised verb class discovery using noisy fea-tures.
In Proceedings of the Seventh Conferenceon Natural Language Learning (CoNLL-2003),page , Edmonton/Canada.Gloria Va?zquez, Ana Ferna?ndez, Irene Castello?n,and M. Antonia Mart??.
2000.
Clasificacio?n ver-bal: Alternancias de dia?tesis.
Quaderns de Sin-tagma.
Universitat de Lleida, 3.Joe H. Ward.
1963.
Hierarchical grouping to opti-mize an objective function.
Journal of the Amer-ican Statistical Association, 58:236?244.Julie Weeds and David Weir.
2003.
A generalframework for distributional similarity.
In Pro-ceedings of the Conference on Empirical Meth-ods in Natural Language Processing (EMNLP-2003), Sapporo/Japan.
