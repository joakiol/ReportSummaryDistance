Proceedings of NAACL HLT 2007, pages 172?179,Rochester, NY, April 2007. c?2007 Association for Computational LinguisticsGeneration by Inverting a Semantic Parser That UsesStatistical Machine TranslationYuk Wah Wong and Raymond J. MooneyDepartment of Computer SciencesThe University of Texas at Austin1 University Station C0500Austin, TX 78712-0233, USA{ywwong,mooney}@cs.utexas.eduAbstractThis paper explores the use of statisti-cal machine translation (SMT) methodsfor tactical natural language generation.We present results on using phrase-basedSMT for learning to map meaning repre-sentations to natural language.
Improvedresults are obtained by inverting a seman-tic parser that uses SMT methods to mapsentences into meaning representations.Finally, we show that hybridizing thesetwo approaches results in still more accu-rate generation systems.
Automatic andhuman evaluation of generated sentencesare presented across two domains and fourlanguages.1 IntroductionThis paper explores the use of statistical machinetranslation (SMT) methods in natural language gen-eration (NLG), specifically the task of mappingstatements in a formal meaning representation lan-guage (MRL) into a natural language (NL), i.e.
tacti-cal generation.
Given a corpus of NL sentences eachpaired with a formal meaning representation (MR),it is easy to use SMT to construct a tactical gener-ator, i.e.
a statistical model that translates MRL toNL.
However, there has been little, if any, researchon exploiting recent SMT methods for NLG.In this paper we present results on using a re-cent phrase-based SMT system, PHARAOH (Koehnet al, 2003), for NLG.1 Although moderately effec-1We also tried IBM Model 4/REWRITE (Germann, 2003), aword-based SMT system, but it gave much worse results.tive, the inability of PHARAOH to exploit the for-mal structure and grammar of the MRL limits its ac-curacy.
Unlike natural languages, MRLs typicallyhave a simple, formal syntax to support effective au-tomated processing and inference.
This MRL struc-ture can also be used to improve language genera-tion.Tactical generation can also be seen as the inverseof semantic parsing, the task of mapping NL sen-tences to MRs.
In this paper, we show how to ?in-vert?
a recent SMT-based semantic parser, WASP(Wong and Mooney, 2006), in order to produce amore effective generation system.
WASP exploitsthe formal syntax of the MRL by learning a trans-lator (based on a statistical synchronous context-free grammar) that maps an NL sentence to a lin-earized parse-tree of its MR rather than to a flat MRstring.
In addition to exploiting the formal MRLgrammar, our approach also allows the same learnedgrammar to be used for both parsing and genera-tion, an elegant property that has been widely ad-vocated (Kay, 1975; Jacobs, 1985; Shieber, 1988).We present experimental results in two domains pre-viously used to test WASP?s semantic parsing abil-ity: mapping NL queries to a formal database querylanguage, and mapping NL soccer coaching instruc-tions to a formal robot command language.
WASP?1is shown to produce a more accurate NL generatorthan PHARAOH.We also show how the idea of generating fromlinearized parse-trees rather than flat MRs, usedeffectively in WASP?1, can also be exploited inPHARAOH.
A version of PHARAOH that exploitsthis approach is experimentally shown to producemore accurate generators that are more competi-tive with WASP?1?s.
Finally, we also show how172((bowner our {4})(do our {6} (pos (left (half our)))))If our player 4 has the ball, then our player 6should stay in the left side of our half.
(a) CLANGanswer(state(traverse 1(riverid(?ohio?
))))What states does the Ohio run through?
(b) GEOQUERYFigure 1: Sample meaning representationsaspects of PHARAOH?s phrase-based model can beused to improve WASP?1, resulting in a hybrid sys-tem whose overall performance is the best.2 MRLs and Test DomainsIn this work, we consider input MRs with a hi-erarchical structure similar to Moore (2002).
Theonly restriction on the MRL is that it be definedby an available unambiguous context-free grammar(CFG), which is true for almost all computer lan-guages.
We also assume that the order in which MRpredicates appear is relevant, i.e.
the order can affectthe meaning of the MR.
Note that the order in whichpredicates appear need not be the same as the wordorder of the target NL, and therefore, the contentplanner need not know about the target NL grammar(Shieber, 1993).To ground our discussion, we consider two ap-plication domains which were originally used todemonstrate semantic parsing.
The first domain isROBOCUP.
In the ROBOCUP Coach Competition(www.robocup.org), teams of agents compete in asimulated soccer game and receive coach advicewritten in a formal language called CLANG (Chenet al, 2003).
The task is to build a system that trans-lates this formal advice into English.
Figure 1(a)shows a piece of sample advice.The second domain is GEOQUERY, where a func-tional, variable-free query language is used forquerying a small database on U.S. geography (Kateet al, 2005).
The task is to translate formal queriesinto NL.
Figure 1(b) shows a sample query.3 Generation using SMT MethodsIn this section, we show how SMT methods can beused to construct a tactical generator.
This is in con-trast to existing work that focuses on the use of NLGin interlingual MT (Whitelock, 1992), in which theroles of NLG and MT are switched.
We first con-sider using a phrase-based SMT system, PHARAOH,for NLG.
Then we show how to invert an SMT-basedsemantic parser, WASP, to produce a more effectivegeneration system.3.1 Generation using PHARAOHPHARAOH (Koehn et al, 2003) is an SMT systemthat uses phrases as basic translation units.
Dur-ing decoding, the source sentence is segmented intoa sequence of phrases.
These phrases are then re-ordered and translated into phrases in the target lan-guage, which are joined together to form the outputsentence.
Compared to earlier word-based methodssuch as IBM Models (Brown et al, 1993), phrase-based methods such as PHARAOH are much moreeffective in producing idiomatic translations, andare currently the best performing methods in SMT(Koehn and Monz, 2006).To use PHARAOH for NLG, we simply treat thesource MRL as an NL, so that phrases in the MRLare sequences of MR tokens.
Note that the grammat-icality of MRs is not an issue here, as they are givenas input.3.2 WASP: The Semantic Parsing AlgorithmBefore showing how generation can be performedby inverting a semantic parser, we present a briefoverview of WASP (Wong and Mooney, 2006), theSMT-based semantic parser on which this work isbased.To describe WASP, it is best to start with an ex-ample.
Consider the task of translating the Englishsentence in Figure 1(a) into CLANG.
To do this,we may first generate a parse tree of the input sen-tence.
The meaning of the sentence is then ob-tained by combining the meanings of the phrases.This process can be formalized using a synchronouscontext-free grammar (SCFG), originally developedas a grammar formalism that combines syntax anal-ysis and code generation in compilers (Aho and Ull-man, 1972).
It has been used in syntax-based SMTto model the translation of one NL to another (Chi-ang, 2005).
A derivation for a SCFG gives rise tomultiple isomorphic parse trees.
Figure 2 shows apartial parse of the sample sentence and its corre-173RULEIf CONDITIONTEAMourplayer UNUM4has the ball...(a) EnglishRULE( CONDITION(bowner TEAMour{ UNUM4})...)(b) CLANGFigure 2: Partial parse trees for the CLANG statement and its English gloss shown in Figure 1(a)sponding CLANG parse from which an MR is con-structed.
Note that the two parse trees are isomor-phic (ignoring terminals).Each SCFG rule consists of a non-terminal, X ,on the left-hand side (LHS), and a pair of strings,?
?, ?
?, on the right-hand side (RHS).
The non-terminals in ?
are a permutation of the non-terminalsin ?
(indices are used to show their correspondence).In WASP, ?
denotes an NL phrase, and X ?
?
isa production of the MRL grammar.
Below are theSCFG rules that generate the parses in Figure 2:RULE ?
?if CONDITION 1 , DIRECTIVE 2 .
,(CONDITION 1 DIRECTIVE 2 )?CONDITION ?
?TEAM 1 player UNUM 2 has theball , (bowner TEAM 1 {UNUM 2 })?TEAM ?
?our , our?UNUM ?
?4 , 4?All derivations start with a pair of co-indexed startsymbols of the MRL grammar, ?S 1 , S 1 ?, and eachstep involves the rewriting of a pair of co-indexednon-terminals (by ?
and ?, respectively).
Given aninput sentence, e, the task of semantic parsing is tofind a derivation that yields ?e, f?, so that f is an MRtranslation of e.Parsing with WASP requires a set of SCFG rules.These rules are learned using a word alignmentmodel, which finds an optimal mapping from wordsto MR predicates given a set of training sentencesand their correct MRs. Word alignment models havebeen widely used for lexical acquisition in SMT(Brown et al, 1993; Koehn et al, 2003).
To usea word alignment model in the semantic parsingscenario, we can treat the MRL simply as an NL,and MR tokens as words, but this often leads topoor results.
First, not all MR tokens carry spe-cific meanings.
For example, in CLANG, parenthe-ses and braces are delimiters that are semanticallyvacuous.
Such tokens can easily confuse the wordalignment model.
Second, MR tokens may exhibitpolysemy.
For example, the CLANG predicate pthas three meanings based on the types of argumentsit is given (Chen et al, 2003).
Judging from the pttoken alone, the word alignment model would not beable to identify its exact meaning.A simple, principled way to avoid these difficul-ties is to represent an MR using a list of productionsused to generate it.
This list is used in lieu of theMR in a word alignment.
Figure 3 shows an exam-ple.
Here the list of productions corresponds to thetop-down, left-most derivation of an MR. For eachMR there is a unique linearized parse-tree, sincethe MRL grammar is unambiguous.
Note that thestructure of the parse tree is preserved through lin-earization.
This allows us to extract SCFG rules in abottom-up manner, assuming the alignment is n-to-1(each word is linked to at most one production).
Ex-traction starts with productions whose RHS is all ter-minals, followed by those with non-terminals.
(De-tails can be found in Wong and Mooney (2006).
)The rules extracted from Figure 3 would be almostthe same as those used in Figure 2, except the one forbowner: CONDITION ?
?TEAM 1 player UNUM 2has (1) ball, (bowner TEAM 1 {UNUM 2 })?.
Thetoken (1) denotes a word gap of size 1, due to the un-aligned word the that comes between has and ball.It can be seen as a non-terminal that expands to atmost one word, allowing for some flexibility in pat-tern matching.In WASP, GIZA++ (Och and Ney, 2003) is usedto obtain the best alignments from the training ex-amples.
Then SCFG rules are extracted from thesealignments.
The resulting SCFG, however, can be174RULE ?
(CONDITION DIRECTIVE)TEAM ?
ourUNUM ?
4Ifourplayer4hastheballCONDITION ?
(bowner TEAM {UNUM})Figure 3: Partial word alignment for the CLANG statement and its English gloss shown in Figure 1(a)ambiguous.
Therefore, a maximum-entropy modelthat defines the conditional probability of deriva-tions (d) given an input sentence (e) is used for dis-ambiguation:Pr?
(d|e) =1Z?
(e)exp?i?ifi(d) (1)The feature functions, fi, are the number of timeseach rule is used in a derivation.
Z?
(e) is thenormalizing factor.
The model parameters, ?i, aretrained using L-BFGS (Nocedal, 1980) to maxi-mize the conditional log-likelihood of the trainingexamples (with a Gaussian prior).
The decodingtask is thus to find a derivation d?
that maximizesPr?
(d?|e), and the output MR translation, f?, is theyield of d?.
This can be done in cubic time with re-spect to the length of e using an Earley chart parser.3.3 Generation by Inverting WASPNow we show how to invert WASP to produceWASP?1, and use it for NLG.
We can use the samegrammar for both parsing and generation, a partic-ularly appealing aspect of using WASP.
Since anSCFG is fully symmetric with respect to both gen-erated strings, the same chart used for parsing canbe easily adapted for efficient generation (Shieber,1988; Kay, 1996).Given an input MR, f , WASP?1 finds a sentencee that maximizes Pr(e|f).
It is difficult to directlymodel Pr(e|f), however, because it has to assignlow probabilities to output sentences that are notgrammatical.
There is no such requirement for pars-ing, because the use of the MRL grammar ensuresthe grammaticality of all output MRs. For genera-tion, we need an NL grammar to ensure grammati-cality, but this is not available a priori.This motivates the noisy-channel model forWASP?1, where Pr(e|f) is divided into two smallercomponents:arg maxePr(e|f) = arg maxePr(e) Pr(f |e) (2)Pr(e) is the language model, and Pr(f |e) is theparsing model.
The generation task is to find a sen-tence e such that (1) e is a good sentence a priori,and (2) its meaning is the same as the input MR. Forthe language model, we use an n-grammodel, whichis remarkably useful in ranking candidate generatedsentences (Knight and Hatzivassiloglou, 1995; Ban-galore et al, 2000; Langkilde-Geary, 2002).
For theparsing model, we re-use the one from WASP (Equa-tion 1).
Hence computing (2) means maximizing thefollowing:maxePr(e) Pr(f |e)?
maxd?D(f)Pr(e(d)) Pr?
(d|e(d))= maxd?D(f)Pr(e(d)) ?
exp?i ?ifi(d)Z?
(e(d))(3)where D(f) is the set of derivations that are con-sistent with f , and e(d) is the output sentence thata derivation d yields.
Compared to most exist-ing work on generation, WASP?1 has the followingcharacteristics:1.
It does not require any lexical information inthe input MR, so lexical selection is an integralpart of the decoding algorithm.2.
Each predicate is translated to a phrase.
More-over, it need not be a contiguous phrase (con-sider the SCFG rule for bowner in Section 3.2).For decoding, we use an Earley chart generatorthat scans the input MR from left to right.
This im-plies that each chart item covers a certain substringof the input MR, not a subsequence in general.
It175requires the order in which MR predicates appearto be fixed, i.e.
the order determines the meaningof the MR.
Since the order need not be identical tothe word order of the target NL, there is no need forthe content planner to know the target NL grammar,which is learned from the training data.Overall, the noisy-channel model is a weightedSCFG, obtained by intersecting the NL side of theWASP SCFG with the n-gram language model.
Thechart generator is very similar to the chart parser, ex-cept for the following:1.
To facilitate the calculation of Pr(e(d)), chartitems now include a list of (n?1)-grams that encodethe context in which output NL phrases appear.
Thesize of the list is 2N + 2, where N is the number ofnon-terminals to be rewritten in the dotted rule.2.
Words are generated from word gaps throughspecial rules (g) ?
?
?, ?
?, where the word gap,(g), is treated as a non-terminal, and ?
is the NLstring that fills the gap (|?| ?
g).
The empty setsymbol indicates that the NL string does not carryany meaning.
There are similar constructs in Car-roll et al (1999) that generate function words.
Fur-thermore, to improve efficiency, our generator onlyconsiders gap fillers that have been observed duringtraining.3.
The normalizing factor in (3), Z?
(e(d)), is nota constant and varies across the output string, e(d).
(Note that Z?
(e) is fixed for parsing.)
This is un-fortunate because the calculation of Z?
(e(d)) is ex-pensive, and it is not easy to incorporate it into thechart generation algorithm.
Normalization is doneas follows.
First, compute the k-best candidate out-put strings based on the unnormalized version of (3),Pr(e(d)) ?
exp?i ?ifi(d).
Then re-rank the list bynormalizing the scores using Z?
(e(d)), which is ob-tained by running the inside-outside algorithm oneach output string.
This results in a decoding al-gorithm that is approximate?the best output stringmight not be in the k-best list?and takes cubic timewith respect to the length of each of the k candidateoutput strings (k = 100 in our experiments).Learning in WASP?1 involves two steps.
First, aback-off n-gram language model with Good-Turingdiscounting and no lexical classes2 is built from all2This is to ensure that the same language model is used inall systems that we tested.training sentences using the SRILM Toolkit (Stolcke,2002).
We use n = 2 since higher values seemed tocause overfitting in our domains.
Next, the parsingmodel is trained as described in Section 3.2.4 Improving the SMT-based GeneratorsThe SMT-based generation algorithms, PHARAOHand WASP?1, while reasonably effective, can besubstantially improved by borrowing ideas fromeach other.4.1 Improving the PHARAOH-based GeneratorA major weakness of PHARAOH as an NLG sys-tem is its inability to exploit the formal structure ofthe MRL.
Like WASP?1, the phrase extraction al-gorithm of PHARAOH is based on the output of aword alignment model such as GIZA++ (Koehn etal., 2003), which performs poorly when applied di-rectly to MRLs (Section 3.2).We can improve the PHARAOH-based generatorby supplying linearized parse-trees as input ratherthan flat MRs. As a result, the basic translation unitsare sequences of MRL productions, rather than se-quences of MR tokens.
This way PHARAOH canexploit the formal grammar of the MRL to producehigh-quality phrase pairs.
The same idea is used inWASP?1 to produce high-quality SCFG rules.
Wecall the resulting hybrid NLG system PHARAOH++.4.2 Improving the WASP-based GeneratorThere are several aspects of PHARAOH that can beused to improve WASP?1.
First, the probabilisticmodel of WASP?1 is less than ideal as it requiresan extra re-ranking step for normalization, which isexpensive and prone to over-pruning.
To remedy thissituation, we can borrow the probabilistic model ofPHARAOH, and define the parsing model as:Pr(d|e(d)) =?d?dw(r(d)) (4)which is the product of the weights of the rules usedin a derivation d. The rule weight, w(X ?
?
?, ??
),is in turn defined as:P (?|?
)?1P (?|?)?2Pw(?|?)?3Pw(?|?
)?4 exp(?|?|)?5where P (?|?)
and P (?|?)
are the relative frequen-cies of ?
and ?, and Pw(?|?)
and Pw(?|?)
are176the lexical weights (Koehn et al, 2003).
The wordpenalty, exp(?|?|), allows some control over theoutput sentence length.
Together with the languagemodel, the new formulation of Pr(e|f) is a log-linear model with ?i as parameters.
The advantageof this model is that maximization requires no nor-malization and can be done exactly and efficiently.The model parameters are trained using minimumerror-rate training (Och, 2003).Following the phrase extraction phase inPHARAOH, we eliminate word gaps by incorpo-rating unaligned words as part of the extractedNL phrases (Koehn et al, 2003).
The reason isthat while word gaps are useful in dealing withunknown phrases during semantic parsing, forgeneration, using known phrases generally leads tobetter fluency.
For the same reason, we also allowthe extraction of longer phrases that correspond tomultiple predicates (but no more than 5).We call the resulting hybrid system WASP?1++.It is similar to the syntax-based SMT system of Chi-ang (2005), which uses both SCFG and PHARAOH?sprobabilistic model.
The main difference is that weuse the MRL grammar to constrain rule extraction,so that significantly fewer rules are extracted, mak-ing it possible to do exact inference.5 ExperimentsWe evaluated all four SMT-based NLG systems in-troduced in this paper: PHARAOH, WASP?1, and thehybrid systems, PHARAOH++ and WASP?1++.We used the ROBOCUP and GEOQUERY corporain our experiments.
The ROBOCUP corpus consistsof 300 pieces of coach advice taken from the log filesof the 2003 ROBOCUP Coach Competition.
The ad-vice was written in CLANG and manually translatedto English (Kuhlmann et al, 2004).
The averageMR length is 29.47 tokens, or 12.82 nodes for lin-earized parse-trees.
The average sentence length is22.52.
The GEOQUERY corpus consists of 880 En-glish questions gathered from various sources.
Thequestions were manually translated to the functionalGEOQUERY language (Kate et al, 2005).
The av-erage MR length is 17.55 tokens, or 5.55 nodes forlinearized parse-trees.
The average sentence lengthis 7.57.Reference: If our player 2, 3, 7 or 5 has the balland the ball is close to our goal line ...PHARAOH++: If player 3 has the ball is in 2 5 theball is in the area near our goal line ...WASP?1++: If players 2, 3, 7 and 5 has the balland the ball is near our goal line ...Figure 4: Sample partial system output in theROBOCUP domainROBOCUP GEOQUERYBLEU NIST BLEU NISTPHARAOH 0.3247 5.0263 0.2070 3.1478WASP?1 0.4357 5.4486 0.4582 5.9900PHARAOH++ 0.4336 5.9185 0.5354 6.3637WASP?1++ 0.6022 6.8976 0.5370 6.4808Table 1: Results of automatic evaluation; bold typeindicates the best performing system (or systems)for a given domain-metric pair (p < 0.05)5.1 Automatic EvaluationWe performed 4 runs of 10-fold cross validation, andmeasured the performance of the learned generatorsusing the BLEU score (Papineni et al, 2002) and theNIST score (Doddington, 2002).
Both MT metricsmeasure the precision of a translation in terms of theproportion of n-grams that it shares with the refer-ence translations, with the NIST score focusing moreon n-grams that are less frequent and more informa-tive.
Both metrics have recently been used to eval-uate generators (Langkilde-Geary, 2002; Nakanishiet al, 2005; Belz and Reiter, 2006).All systems were able to generate sentences formore than 97% of the input.
Figure 4 shows somesample output of the systems.
Table 1 shows theautomatic evaluation results.
Paired t-tests wereused to measure statistical significance.
A fewobservations can be made.
First, WASP?1 pro-duced a more accurate generator than PHARAOH.Second, PHARAOH++ significantly outperformedPHARAOH, showing the importance of exploitingthe formal structure of the MRL.
Third, WASP?1++significantly outperformed WASP?1.
Most of thegain came from PHARAOH?s probabilistic model.Decoding was also 4?11 times faster, despite ex-act inference and a larger grammar due to extrac-tion of longer phrases.
Lastly, WASP?1++ signifi-cantly outperformed PHARAOH++ in the ROBOCUP177ROBOCUP GEOQUERYFlu.
Ade.
Flu.
Ade.PHARAOH++ 2.5 2.9 4.3 4.7WASP?1++ 3.6 4.0 4.1 4.7Table 2: Results of human evaluationdomain.
This is because WASP?1++ allows dis-contiguous NL phrases and PHARAOH++ does not.Such phrases are commonly used in ROBOCUPfor constructions like: players 2 , 3 , 7 and 5;26.96% of the phrases generated during testing werediscontiguous.
When faced with such predicates,PHARAOH++ would consistently omit some of thewords: e.g.
players 2 3 7 5, or not learn any phrasesfor those predicates at all.
On the other hand, only4.47% of the phrases generated during testing forGEOQUERY were discontiguous, so the advantage ofWASP?1++ over PHARAOH++ was not as obvious.Our BLEU scores are not as high as those re-ported in Langkilde-Geary (2002) and Nakanishi etal.
(2005), which are around 0.7?0.9.
However,their work involves the regeneration of automati-cally parsed text, and the MRs that they use, whichare essentially dependency parses, contain extensivelexical information of the target NL.5.2 Human EvaluationAutomatic evaluation is only an imperfect substitutefor human assessment.
While it is found that BLEUand NIST correlate quite well with human judgmentsin evaluating NLG systems (Belz and Reiter, 2006),it is best to support these figures with human evalu-ation, which we did on a small scale.
We recruited 4native speakers of English with no previous experi-ence with the ROBOCUP and GEOQUERY domains.Each subject was given the same 20 sentences foreach domain, randomly chosen from the test sets.For each sentence, the subjects were asked to judgethe output of PHARAOH++ and WASP?1++ in termsof fluency and adequacy.
They were presented withthe following definition, adapted from Koehn andMonz (2006):Score Fluency Adequacy5 Flawless English All meaning4 Good English Most meaning3 Non-native English Some meaningPHARAOH++ WASP?1++BLEU NIST BLEU NISTEnglish 0.5344 5.3289 0.6035 5.7133Spanish 0.6042 5.6321 0.6175 5.7293Japanese 0.6171 4.5357 0.6585 4.6648Turkish 0.4562 4.2220 0.4824 4.3283Table 3: Results of automatic evaluation on the mul-tilingual GEOQUERY data setScore Fluency Adequacy2 Disfluent English Little meaning1 Incomprehensible No meaningFor each generated sentence, we computed the av-erage of the 4 human judges?
scores.
No scorenormalization was performed.
Then we comparedthe two systems using a paired t-test.
Table 2shows that WASP?1++ produced better generatorsthan PHARAOH++ in the ROBOCUP domain, con-sistent with the results of automatic evaluation.5.3 Multilingual ExperimentsLastly, we describe our experiments on the mul-tilingual GEOQUERY data set.
The 250-exampledata set is a subset of the larger GEOQUERY cor-pus.
All English questions in this data set weremanually translated into Spanish, Japanese andTurkish, while the corresponding MRs remain un-changed.
Table 3 shows the results, which are sim-ilar to previous results on the larger GEOQUERYcorpus.
WASP?1++ outperformed PHARAOH++for some language-metric pairs, but otherwise per-formed comparably.6 Related WorkNumerous efforts have been made to unify the tasksof semantic parsing and tactical generation.
One ofthe earliest espousals of the notion of grammar re-versability can be found in Kay (1975).
Shieber(1988) further noted that not only a single gram-mar can be used for parsing and generation, but thesame language-processing architecture can be usedfor both tasks.
Kay (1996) identified parsing chartsas such an architecture, which led to the develop-ment of various chart generation algorithms: Car-roll et al (1999) for HPSG, Bangalore et al (2000)for LTAG, Moore (2002) for unification grammars,178White and Baldridge (2003) for CCG.
More re-cently, statistical chart generators have emerged, in-cluding White (2004) for CCG, Carroll and Oepen(2005) and Nakanishi et al (2005) for HPSG.
Manyof these systems, however, focus on the task of sur-face realization?inflecting and ordering words?which ignores the problem of lexical selection.
Incontrast, our SMT-based methods integrate lexicalselection and realization in an elegant frameworkand automatically learn all of their linguistic knowl-edge from an annotated corpus.7 ConclusionWe have presented four tactical generation systemsbased on various SMT-based methods.
In particular,the hybrid system produced by inverting the WASPsemantic parser shows the best overall results acrossdifferent application domains.AcknowledgmentsWe would like to thank Kevin Knight, JasonBaldridge, Razvan Bunescu, and the anonymous re-viewers for their valuable comments.
We also sin-cerely thank the four annotators who helped us eval-uate the SMT-based generators.
This research wassupported by DARPA under grant HR0011-04-1-0007 and a gift from Google Inc.ReferencesA.
V. Aho and J. D. Ullman.
1972.
The Theory of Parsing, Translation,and Compiling.
Prentice Hall, Englewood Cliffs, NJ.S.
Bangalore, O. Rambow, and S. Whittaker.
2000.
Evaluation metricsfor generation.
In Proc.
INLG-00, pages 1?8, Mitzpe Ramon, Israel,July.A.
Belz and E. Reiter.
2006.
Comparing automatic and human evalu-ation of NLG systems.
In Proc.
EACL-06, pages 313?320, Trento,Italy, April.P.
F. Brown, V. J. Della Pietra, S. A. Della Pietra, and R. L. Mercer.1993.
The mathematics of statistical machine translation: Parameterestimation.
Computational Linguistics, 19(2):263?312, June.J.
Carroll and S. Oepen.
2005.
High efficiency realization for a wide-coverage unification grammar.
In Proc.
IJCNLP-05, pages 165?176,Jeju Island, Korea, October.J.
Carroll, A. Copestake, D. Flickinger, and V. Poznan?ski.
1999.
Anefficient chart generator for (semi-)lexicalist grammars.
In Proc.EWNLG-99, pages 86?95, Toulouse, France.M.
Chen et al 2003.
Users manual: RoboCup soccer server man-ual for soccer server version 7.07 and later.
Available at http://sourceforge.net/projects/sserver/.D.
Chiang.
2005.
A hierarchical phrase-based model for statisticalmachine translation.
In Proc.
ACL-05, pages 263?270, Ann Arbor,MI, June.G.
Doddington.
2002.
Automatic evaluation of machine translationquality using n-gram co-occurrence statistics.
In Proc.
ARPA Work-shop on Human Language Technology, pages 128?132, San Diego,CA.U.
Germann.
2003.
Greedy decoding for statistical machine translationin almost linear time.
In Proc.
HLT/NAACL-03, Edmonton, Canada.P.
S. Jacobs.
1985.
PHRED: A generator for natural language inter-faces.
Computational Linguistics, 11(4):219?242.R.
J. Kate, Y. W. Wong, and R. J. Mooney.
2005.
Learning to transformnatural to formal languages.
In Proc.
AAAI-05, pages 1062?1068,Pittsburgh, PA, July.M.
Kay.
1975.
Syntactic processing and functional sentence per-spective.
In Theoretical Issues in Natural Language Processing?Supplement to the Proceedings, pages 12?15, Cambridge, MA,June.M.
Kay.
1996.
Chart generation.
In Proc.
ACL-96, pages 200?204, SanFrancisco, CA.K.
Knight and V. Hatzivassiloglou.
1995.
Two-level, many-paths gen-eration.
In Proc.
ACL-95, pages 252?260, Cambridge, MA.P.
Koehn and C. Monz.
2006.
Manual and automatic evaluation ofmachine translation between European languages.
In Proc.
SMT-06Workshop, pages 102?121, New York City, NY, June.P.
Koehn, F. J. Och, and D. Marcu.
2003.
Statistical phrase-basedtranslation.
In Proc.
HLT/NAACL-03, Edmonton, Canada.G.
Kuhlmann, P. Stone, R. J. Mooney, and J. W. Shavlik.
2004.
Guidinga reinforcement learner with natural language advice: Initial resultsin RoboCup soccer.
In Proc.
of the AAAI-04 Workshop on Supervi-sory Control of Learning and Adaptive Systems, San Jose, CA, July.I.
Langkilde-Geary.
2002.
An empirical verification of coverageand correctness for a general-purpose sentence generator.
In Proc.INLG-02, pages 17?24, Harriman, NY, July.R.
C. Moore.
2002.
A complete, efficient sentence-realization algo-rithm for unification grammar.
In Proc.
INLG-02, pages 41?48,Harriman, NY, July.H.
Nakanishi, Y. Miyao, and J. Tsujii.
2005.
Probabilistic models fordisambiguation of an HPSG-based chart generator.
In Proc.
IWPT-05, pages 93?102, Vancouver, Canada, October.J.
Nocedal.
1980.
Updating quasi-Newton matrices with limited stor-age.
Mathematics of Computation, 35(151):773?782, July.F.
J. Och and H. Ney.
2003.
A systematic comparison of various statis-tical alignment models.
Computational Linguistics, 29(1):19?51.F.
J. Och.
2003.
Minimum error rate training in statistical machinetranslation.
In Proc.
ACL-03, pages 160?167, Sapporo, Japan, July.K.
Papineni, S. Roukos, T. Ward, and W. J. Zhu.
2002.
BLEU: amethod for automatic evaluation of machine translation.
In Proc.ACL-02, pages 311?318, Philadelphia, PA, July.S.
M. Shieber.
1988.
A uniform architecture for parsing and generation.In Proc.
COLING-88, pages 614?619, Budapest, Hungary.S.
M. Shieber.
1993.
The problem of logical-form equivalence.
Com-putational Linguistics, 19(1):179?190.A.
Stolcke.
2002.
SRILM?an extensible language modeling toolkit.In Proc.
ICSLP-02, pages 901?904, Denver, CO.M.
White and J. Baldridge.
2003.
Adapting chart realization to CCG.In Proc.
EWNLG-03, Budapest, Hungary, April.M.
White.
2004.
Reining in CCG chart realization.
In Proc.
INLG-04,New Forest, UK, July.P.
Whitelock.
1992.
Shake-and-bake translation.
In Proc.
COLING-92,pages 784?791, Nantes, France.Y.
W. Wong and R. J. Mooney.
2006.
Learning for semantic parsingwith statistical machine translation.
In Proc.
HLT/NAACL-06, pages439?446, New York City, NY, June.179
