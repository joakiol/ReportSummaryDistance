Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 110?114,Athens, Greece, 30 March ?
31 March 2009. c?2009 Association for Computational LinguisticsStatistical Post Editing and Dictionary Extraction:Systran/Edinburgh submissions for ACL-WMT2009Loic Dugast*,** and Jean Senellart**SYSTRAN S.A.La Grande Arche1, Parvis de la De?fense92044 ParisLa De?fense CedexFrancePhilipp Koehn****School of InformaticsUniversity of Edinburgh10 Crichton Street,EdinburghUnited KingdomAbstractWe describe here the two Sys-tran/University of Edinburgh submissionsfor WMT2009.
They involve a statisticalpost-editing model with a particular han-dling of named entities (English to Frenchand German to English) and the extractionof phrasal rules (English to French).1 IntroductionPrevious results had shown a rather satisfying per-formance for hybrid systems such as the Statis-tical Phrase-based Post-Editing (SPE) (Simard etal., 2007) combination in comparison with purelyphrase-based statistical models, reaching simi-lar BLEU scores and often receiving better hu-man judgement (German to English at WMT2007)against the BLEU metric.
This last result wasin accordance with the previous acknowledgment(Callison-Burch et al, 2006) that systems of toodiffering structure could not be compared reliablywith BLEU.
We participated in the recent Work-shop on Machine Translation (WMT?09) in thelanguage pairs English to French and German toEnglish.
On the one hand we trained a Post-Editing system with an additional special treat-ment to avoid the loss of entities such as dates andnumbers.
On the other hand we trained an addi-tional English-to-French system (as a secondarysubmission) that made use of automatically ex-tracted linguistic entries.
In this paper, we willpresent both approaches.
The latter is part of on-going work motivated by the desire to both makeuse of corpus statistics and keep the advantage ofthe often (relative to automatic metrics?s scores)higher rank in human judgement given to rule-based systems on out-of-domain data, as seen onFigure 1: Translation with PBMT post-editingthe WMT 2008 results for both English to Frenchand German to English (Callison-Burch et al,2008).2 Statistical Post Editing systems2.1 BaselineThe basic setup is identical to the one describedin (Dugast et al, 2007).
A statistical translationmodel is trained between the rule-based transla-tion of the source-side and the target-side of theparallel corpus.
This is done separately for eachparallel corpus.
Language models are trained oneach target half of the parallel corpora and also onadditional in-domain corpora.
Figure 1 shows thetranslation process.Here are a few additional details which tend toimprove training and limit unwanted statistical ef-fects in translation:?
Named entities are replaced by special tokenson both sides.
By reducing vocabulary andcombined with the next item mentioned, thisshould help word alignment.
Moreover, en-tity translation is handled more reliably bythe rule-based engine.?
The intersection of both vocabularies (i.e.
vo-110cabularies of the rule-based output and thereference translation) is used to produce anadditional parallel corpus (whose target isidentical to source).
This was added to theparallel text to improve the word alignment.?
Rule-based output and reference translationsare lowercased before performing alignment,leaving the recasing job up to the rule-basedengine.?
Singleton phrase pairs are deleted from thephrase table to avoid overfitting.?
Phrase pairs non cohesive regarding entitiesare also discarded.
We make the hypothe-sis that entities are always passed to the tar-get language and all entities in the target lan-guage originate from the source language.This point is discussed in section 2.2.We will discuss some of these details further inthe upcoming sections.Due to time constraints, we did not use the GigaFrench-English Parallel corpus provided for theworkshop.
We only made use of the News Com-mentary and the Europarl corpora.
We used ad-ditional in-domain news corpora to train 5 gramslanguage models, according to the baseline rec-ommendations.
Weights for these separate modelswere tuned through the Mert algorithm providedin the Moses toolkit (Koehn et al, 2007), usingthe provided news tuning set.2.2 TrimmingIn a statistical translation model, trimming ofthe phrase table had been shown to be beneficial(Johnson et al, 2007).
For our post-editing model,we can afford to perform an even more aggressivetrimming of the phrase table, since the rule-basedsystem already provides us with a translation andwe only aim at correcting the most frequent er-rors.
Therefore, we suppress all unique phrasepairs before calculating the probabilities for the fi-nal phrase table.2.3 Avoiding the loss of entitiesDeleted and spurious content is a well knownproblem for statistical models (Chiang et al,2008).
Though we do not know of any study prov-ing it, it seems obvious that Named Entities thatwould be either deleted or added to the output outof nowhere is an especially problematic kind ofRule-Based French Reference Frenchent date etent date ent numeric etent numeric de golfe .
du golfe ent date .de?cennie ent numeric anset ent numeric .
.Table 1: Examples of problematic phrase pairserror for the translation quality.
The rule-basedtranslation engine benefits from an entity recogni-tion layer for numbers, dates and hours, addresses,company names and URIs.
We therefore ?trim?
(delete) from the extracted phrase pairs any itemthat would not translate all entities from the source(i.e.
the RBMT output) to the target or add spuri-ous entities which were not present in the sourceside of the phrase pair.
Table 1 illustrates the kindof phrase pairs that are excluded from the model.For example, the first phrase pair, when applied,would simply erase the date entity which was ex-pressed in the source sentence, which we of coursedo not want.3 Rule ExtractionThe baseline Systran rule-based system is moreor less a linguistic-oriented system that makesuse of a dependency analysis, general transferrules and dictionary entries, and finally a synthe-sis/reordering stage.
The dictionary entries havelong been the main entry point for customizationof the system.
Such lexical translation rules arefully linguistically coded dictionary entries, withthe following features attached: part-of-speech,inflection category, headword and possibly somesemantic tags.
Table 2 displays a sample ofmanually-entered entries.
These entries may bothmatch any inflected form of the source and gen-erate the appropriate (according to general agree-ment rules and depending on the source analysis)target inflection.Motivations for adding phrasal dictionary en-tries (compound words) are twofold: first, just asfor statistical translation models which went fromword-based to phrase-based models, it helps solvedisambiguation and non-literal translations.
Sec-ond, as the rule-based engine makes use of a syn-tactic analysis of a source sentence, adding un-ambiguous phrasal chunks as entries will reducethe overall syntactic ambiguity and lead to a bettersource analysis.111POS English French headword English headword FrenchNoun college level niveau d?e?tudes universitaires level niveauAdverb on bail sous caution on sousVerb badmouth me?dire de badmouth me?direTable 2: Example dictionary entriesFigure 2: Extraction pipeline: from parallel textsto bilingual dictionary3.1 Manual customization throughdictionary entriesThe Systran system provides a dictionary codingtool (Senellart et al, 2003).
This tool allows themanual task of coding entries to be partially au-tomated with the use of monolingual dictionariesand probabilistic context-free grammars, while al-lowing the user to fine-tune it by correcting the au-tomatic coding and/or add more features.
How-ever, this remains first of all a time-consumingtask.
Moreover, it is not easy for humans to selectthe best translation among a set of alternatives, letalone assign them probabilities.
Last but not least,the beneficial effect on translation is not guaran-teed (especially, the effect on the rule-based de-pendency analysis).3.2 Automatic extraction of dictionaryentriesThe problem consists of selecting relevant phrasepairs from a set, coding them linguistically and as-sign them probabilities.
The extraction setup asdepicted in figure 2) starts from a parallel cor-pus dataset.
The baseline procedure is followed(word alignment using GIZA++ and use of com-mon heuristics to extract phrase pairs (Koehn etal., 2007)) to extract phrase pairs.
At this stagethe ?phrases?
are plain word sequences, not nec-essarily linguistically motivated.
Some statisticalinformation is attached to each phrase pair: fre-quency of the pair and lexical weights in both di-rections.
Each unique phrase pair is then pro-cessed by our dictionary coding tool which triesto map both word sequences to a given category.If both sides are mapped to the same category, thephrase pair, now lemmatized, is retained as a bilin-gual entry.
Otherwise, the candidate is excluded.Given that a bilingual entry with a same lemmamay have various inflectional forms in corpus, wethen sum the lemma counts.
Finally, in the currentsetup, we only keep the most frequent translationfor each source.For our secondary submission for English-French, we extracted such entries from both theNews Commentary and the Europarl corpus.3.3 Validation of dictionary entriesThe coding procedure, when applied to phrasepairs extracted from the corpus instead of man-ually entered entries, may generate rules that donot lead to an improved translation.
Recall thatwe start from an existing system and only want tolearn additional rules to adapt to the domain of thebilingual corpus we have at our disposal.Now the problem consists of building the opti-mal subset from the set of candidate entries, ac-cording to a translation evaluation metric (here,BLEU).
Unlike the Mert procedure, we wouldlike to do more than assign global weights for thewhole set of translation rules, but instead make adecision for each individual phrasal rule.As an approximate response to this problem,we test each extracted entry individually, start-ing from the lower n-grams to the longer (source)chunks, following algorithm 1.
This results indictionaries of 5k and 170k entries for the NewsCommentary and the Europarl parallel corpora, re-spectively.112System BLEURBMT English-French 20.48RBMT+SPE English-French 21.90RBMT+Extracted dictionary English-French 20.82RBMT German-English 15.13RBMT+SPE German-English 17.50Table 3: Compared results of original RBMT system,post-editing and dictionary extraction: real-cased,untokenized NIST Bleu scores on the full newstest2009 set(%)System nc-test2007(newscommen-tary)test2007(eu-roparl)newstest2009(news)RBMT 24.88 22.75 20.48RBMT +Dictionary extracted from News Commentary 26.54 - 20.57RBMT +Dictionary extracted from Europarl - 25.55 -RBMT +Dictionary extracted from NC and Europarl, priority on NC 26.65 - 20.82Table 4: Results of dictionary extraction for English-French: real-cased, untokenized NIST Bleu scores(%)Algorithm 1 Dictionary Validation Algorithm1: n=12: for n=1 to Nmax do3: map all n-gram entries to parallel sentences4: translate training corpus with current dic-tionary5: for each entry do6: translate all relevant sentences with cur-rent dictionary, plus this entry7: compute BLEU scores without and withthe entry8: end for9: Select entries with better/worse sentencesratio above threshold10: add these entries to current dictionary11: end for4 ResultsBLEU scores of the dictionary extraction exper-iments for the English-French language pair andthree types of corpora are displayed in table 4.Table 3 shows results on the news test set.
Post-editing setups were tuned on the news tuning set.5 Conclusion and future workWe presented a few improvements to the Statisti-cal Post Editing setup.
They are part of an effortto better integrate a linguistic, rule-based systemand the statistical correcting layer also illustratedin (Ueffing et al, 2008).
Moreover, we presenteda dictionary extraction setup which resulted in animprovement of 2 to 3 BLEU points over the base-line rule-based system when in-domain,as can beseen in table 4.
This however improved transla-tion very little on the ?news?
domain which wasused for evaluation.
We think that is a differentissue, namely of domain adaptation.
In order topush further this rule-extraction approach and ac-cording to our previous work (Dugast et al, 2007)(Dugast et al, 2008), the most promising wouldprobably be the use of alternative meanings anda language model to decode the best translationin such a lattice.
Another path for improvementwould be to try and extract rules with more fea-113tures, such as constraints of lexical subcategoriza-tion as they already exist in the manually enteredentries.
Finally, we would like to try combiningthe dictionary extraction setup with a StatisticalPost-Editing layer to see if the latter supersedesthe former.AcknowledgementWe would like to thank the anonymous reviewersfor their comments and corrections.ReferencesC.
Callison-Burch, M. Osborne, and P. Koehn.
2006.Re-evaluating the role of bleu in machine translationresearch.
In In proceedings of EACL 2006.Chris Callison-Burch, Cameron Fordyce, PhilippKoehn, Christof Monz, and Josh Schroeder.
2008.Further meta-evaluation of machine translation.
InProceedings of the Third Workshop on Statisti-cal Machine Translation, pages 70?106, Columbus,Ohio, June.
Association for Computational Linguis-tics.David Chiang, Steve Deneefe, Yee S. Chan, andHwee T. Ng.
2008.
Decomposability of translationmetrics for improved evaluation and efficient algo-rithms.
In Proceedings of the 2008 Conference onEmpirical Methods in Natural Language Process-ing, pages 610?619, Honolulu, Hawaii, October.
As-sociation for Computational Linguistics.Lo?
?c Dugast, Jean Senellart, and Philipp Koehn.
2007.Statistical post-editing on SYSTRAN?s rule-basedtranslation system.
In Proceedings of the SecondWorkshop on Statistical Machine Translation, pages220?223, Prague, Czech Republic, June.
Associa-tion for Computational Linguistics.Lo?
?c Dugast, Jean Senellart, and Philipp Koehn.
2008.Can we relearn an rbmt system?
In Proceedings ofthe Third Workshop on Statistical Machine Transla-tion, Columbus, Ohio, U.S.A., June.
Association forComputational Linguistics.Howard Johnson, Joel Martin, George Foster, andRoland Kuhn.
2007.
Improving translation qual-ity by discarding most of the phrasetable.
In Pro-ceedings of the 2007 Joint Conference on EmpiricalMethods in Natural Language Processing and Com-putational Natural Language Learning (EMNLP-CoNLL), pages 967?975, Prague, Czech Republic,June.
Association for Computational Linguistics.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondrej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: Opensource toolkit for statistical machine translation.
InACL 2007, demonstration session.Jean Senellart, Jin Yang, and Anabel Rebollo.
2003.Technologie systran intuitive coding.
In in Proceed-ings of MT Summit IX.M.
Simard, C. Goutte, and P. Isabelle.
2007.
Statisti-cal phrase-based post-editing.
In proceedings of theNAACL-HLT.
2007.
NRC 49288.Nicola Ueffing, Jens Stephan, Evgeny Matusov, Lo?
?cDugast, George Foster, Roland Kuhn, Jean Senel-lart, and Jin Yang.
2008.
Tighter integration ofrule-based and statistical MT in serial system com-bination.
In Proceedings of the 22nd InternationalConference on Computational Linguistics (Coling2008), pages 913?920, Manchester, UK, August.Coling 2008 Organizing Committee.114
