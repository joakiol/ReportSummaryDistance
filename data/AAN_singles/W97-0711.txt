A Scalable Summarization System Using Robust NLPChinatsu  Aonet ,  Mary  E l len  Okurowsk i~ t, J ames  Gor l inskyt ,  B jo rnar  LarsenttSRA InternatlonM4300 Fair Lakes CourtFalrfax, VA 22033{aonec, gorhnsk, larsenb}@sra corn~Depaxtment of Defense9800 Savage RoadFort George G Meade, MD 20755-6000meokuro@afterhfe ncsc nnlAbst rac tWe describe a scalable summarization sys-tem which takes advantage ofrobust NLPtechnology such as corpus-based statlsh-cal NLP techmques, information extrac-tmn and readily available on-hne resourcesThe system attempts o compensate for thebottlenecks of traditional frequency-based,knowledge-based or discourse-based sum-manzatlon approaches by uhhzlng featuresderived by these robust techniques Pre-hrmnary evaluation results are reported,and the multi-dimensional summary vieweris described1 In t roduct ionSummarization research and system developmentcan be broadly characterized as frequency-based,knowledge-based or discourse-based These cate-gories correspond to a continuum of increasing un-derstanding of a text and increasing complextty intext processingEarliest attempts at summarization (Luhn, 1958,Edmundson, 1969, Rush, Salvador, and Zamora,1971) essentially rehed on lexlcal and locahonal m-formation within the text, 1 e, frequency of wordsor key terms, their proxnmty, and locatmn withinthe text More recent adaptations of tlns approachhave employed an automated method to combinethese types of feature sets through classificationtechniques (Kupmc, Pedersen, and Chen, 1995) O rhave drawn upon tradlhonal information retrievalindexing methods to incorporate knowledge of a textcorpus (Brandow, Mltze, and Rau, 1995) To a largeextent, these types of shallow approaches are igno-rant of dommn knowledge and the text macrostruc-ture They create summaries by extracting sentencesfrom the original documentKnowledge-based approaches generally depend onrich domain knowledge sources to interpret heconceptual structure of the text Systems likeTOPIC (Relmer and Hahn, 1988), SUSY (Fum,Gmda, and Tasso, 1985) or SCISORS (Ran, Ja-cobs, and Zermk, 1989) parse domaan specific textsand create conceptual representahons forthe gener-ation of text summarms These types of knowledge-ba.~d systems apply knowledge of the domain tocharacterize specific onceptual knowledge ofa textPalce (Pvace and Jones, 1993) provides a good ex-ample of the role of thts conceptual mformahon andthloff(Rlloff, 1995) gives a method for automahcallyidentifying relevant concepts lughly correlated witha category of interest Because these systems createa rich conceptual representation, there are multipleways m whlcha text summary may be created Forexample, SUMMONS (McKeown and Radev; 1995)generates a text summary from such a template r p-resentahon, whle (Maybury, 1995) describes mulh-pie methods for selecting events and presenting eventsummaries Knowledge-based approaches are usu-ally very knowledge-intensive and domvan-specificDiscourse-based approaches are grounded m theo-rms of text cohesion and coherence and vary conmd-erably m how much they push the lmnts of text un-derstanding and the complemty as well as automa-hon of that processing Spearheaded by the lackof cohesion and coherence m extracts produced byfrequency-based approaches, much of the work typi-fying discourse-based approaches focuses on lmgms-tic processing of the text to identify the best cohe-sive sentence candidates (Palce, 1990, Johnson et al,1993) or the best sentence candidates for represent-" mg the rhetorical structure of the text (Mnke et al?
1994) Both approaches revolve parsing the text andanalyzing dlscoarse relations to select sentences forextractmnFrequency-based approaches (Brandow, Mltze,and Rau, 1995) may incorporate heurmhcs to handlereadabilityrelated issues and knowledge-based ap-proaches ?
ystematically perform discourse process-mg m analyzing and condeusmg the text, but ma broad classificatmn schema It is the discourse-based approaches that tend to focus on the textmacrostructure and surface clues to that structureAt the far end of the continuum lies work by SparckJones (Jones, 1993, Jones, 1995) m describing a66!
!m,li\[iiliIiIia!IIiill1manual method for source texi~ representatlon basedon hngmstlc, dommn and communlcatlve reforma-tion From the NLP  technology point of wew, din-course theory LS the least understood among sub-fields of hnguistlcsOur work addresses challenges encountered inthese previous approaches by applying robust andproven NLP  techmques such as corpus-based sta-tmtlcal NLP,.
robust mforrmatlon extractlon, andreadlly-avmlable on-hne NLP  resources These tech-tuques and resources allow us to create a richer in-dexed source of Imgmstlc and domain knowledgethan other frequency approaches Our approachattempts to apprommate text dlscourse structurethrough these multlple layers of mformatlon, oh-tinned from automated methods m contrast tolabor-lntenslve, discourse-based approaches More-over, our planned training methodology will also al-low us to explmt thin productlve infrastructure mways whlch model human performance whde avoid-mg hand-crafting domain-dependent rules of theknowledge-based approaches Our ultlmate goal mto make our summarlzatlon system scalable andportable by learning summarization rules from easilyextractable text features2 System DescriptionOur summarization system DlmSum consmts ofthe Summarization Server and the SummarlzatzonChent The Server extracts features (the FeatureExtractor) from a document using various robustNLP techmques, described In Sectzon 2 1, and com-bines these features (the Feature Combiner) to base-hne multiple combinations of features, as describedm Section 2 2 Our work m progress to automatt-cally tram the Feature Combiner based upon userand apphcatlon eeds m presented in Section 2 2 2The Java-based Chent, which wdl be dmcnssed InSection 4, provides a graphical user interface (GUI)for the end user to cnstomlze the summamzatlonpreferences and see multiple views of generated sum-I nar les2.1 Ext ract ing  St lmmarizat ion FeaturesIn this section, we describe how we apply robustNLP technology to extract summarization featuresOur goal IS to add more mtelhgence to frequency-based approaches, to acqmre domain knowledge Ina more automated fashion, and to apprommate xtstructure by recogmzing sources of dmcourse cohe-sion and coherence2.1.1 Going Beyond a WordFrequency-based summarization systems typicallyuse a single word stnng as a umt for counting fre-quencies Whde such a method IS very robust, itignores the semantic ontent of words and their po-tential membership m multi-word phrases For ex-ample, zt does not dmtmgumh between "bill" m "BdlTable 1 Collocations with "chlps"{potato tortdla corn chocolate b~gle} chips{computer pentmm Intel macroprocessor memory} chips{wood oak plastlc} cchlpsbsrgmmng clupsblue clupsmr chipsClmton" and "bill" in "reform bill" This may intro-duce noise m frequency counting as the same strmgsare treated umformly no matter how the contextmay have dmamblguated the sense or regardless ofmembership in multl-word phrases For DlrnSum,we use term frequency based on tf*Idf (Salton andMcGdl, 1983, Brandow, Mitze, and Rau, 1995) toderive ssgnature words as one of the summarizationfeatures If single words were the sole basra of count-mg for our summarization application, nome wouldbe introduced both m term frequency and reversedocument frequencyHowever, recent advances in statmtlcal NLP andinformation extraction make it possible to utilize fea-tures which go beyond the single word level Ourapproach is to extract multi-word phrases automat-lcally with high accuracy and use them as the ba-sic unit in the summarization process, including fre-quency calculationFtrst, just as word association methods haveproven effective m lemcal analysis, eg (Church andHanks, 1990), we are exploring whether frequentlyoccurring Collocatlonal reformation can improveon simple word-based approaches We have pre-processed about 800 MB of LA tlmes/WastnngtonPost newspaper articles nsmg a POS tagger (Bnll,1993) and derived two-word noun collocations usingmutual information The.
result included, for exam-ple, varlons "chips" phrases as shown m Table 1The word "ch~ps" occurred 1143 times m this cor-pus, and the table shows that thin word m semanti-cally very amblguons In word associatmns, It canrefer to food, computer components, abstract con-cepts, etc By incorporating these conocatlons, wecan dlsamblguate dtfferent meamngs of "chips"Secondly, as the recent Message UnderstandingConference (MUC-6) showed (Adv, 1995), the accu-racy and robustness of name extraction has reacheda mature level, equahng the level of human perfor-mance m accuracy (lind-90%) and exceeding humanspeed by many thousands of times We employedSRA's NameTag TM (Krupka, 1995) to tag the afore-mentioned corpus with names of people, entztIes, andplaces, and derived a baseline database for tffIdfcalculation In the database, we not only treatedmulti-word names (e g,  "Ball Clinton") as single to-kens but also dmamblguated the semantic types ofnames so that, for instance, the company "Ford"67ts treated separately from President "Ford" Ourapproach is thus different from (Kupiec, Pedersen,and Chen, !995) where only capitalization reforma-tion was used to identify and group various types ofproper names2.1.2 Acquir ing Knowledge of  the  DomainIn knowledge-based summarization approaches,the biggest challenge ts to acquire enough domainknowledge to create conceptual representations foratext Though summarization from conceptual repre-sentation has many advantages (as discussed m Sec-tion 1), extracting such representations constrains asystem to domain dependency and is too knowledge-intensive for our approachInstead, we took an automatic and robust ap-proach where we acqmre some domain knowledgefrom a large corpus and incorporate that knowledgeas summarization features m the system We incor-porated corpus knowledge m three ways, that is, byusing a large corpus baseline to calculate'ldf valuesfor selecting signature words, by denying colloca-tions statistically from a large corpus, and by creat-ing a word association i dex derived from a large cor-pus (Jmg and Croft, 1994) With thin method, thesystem can automatically adapt to each dmtmct do-main, hke newspapers vs legal documents withoutmanually developing domain knowledge Domainknowledge is embraced in szgnature words, whichindicate key concepts of a given-document, in col-Iocat:on phrases, which provide richer key conceptsthan single-word key concepts (e g "appropriationsbill," "ommbus bill," "brady ball," "reconciliationbill," "crime bill," "stopgap bdl,", etc ), and in theirassoczated words, which are clusters of dommn re-lated terms (e g ,  "Bayer" and "aspirin," "ColumbiaRaver" and "gorge," "Dead Sea" and "scrolls")2. i .3 Recogniz ing sources  of  DiscourseCohes ion and  CoherencePast research (Pmce, 1990) has described the neg-ative impact on abstract quality of fathng to per-form some type of discourse processing Since din-course knowledge (e g ,  effective anaphora resolutionand text segmentation) cannot currently be auto-matlcally acquired easily wlth high accuracy and ro-bustness, heuristic techniques are often employed insummarization systems to suppress sentences withinterdependent cohesive markersHowever, there are several shallower but robustmethods we can employ now to acquire some dis-course knowledge Namely, we exploit the dmcoursefeatures of lexlcal items within a text by using namealiases, synonyms, and morphological variantsWithin a document, subsequent references to fullnames are often aliases Thus, linking name aliasesprovides ome indication as to which sentences areinterrelated, as shown belowThe I ns t i tu t iona l  Revo lu t ionaryParry ,  or PR I ,  capped sis landmark as-sembly to reform ,tself w,th a .Nourish ofpomp and prom,ses Among the mea-sures coming out of the assembly's fiercestpubhc debate, zn which party members roseup agaznst he,r leadership Saturday nlght,are new requsrements for future PR I  pres-,denttal cand, dates, quahficatwns that net-ther ~eddlo nor any of Mezzco's prevzousfour pres,dents would have metThe NameTag name extractxon tool discussed mthe previous ection performs hnkmg of name aliaseswithin a document such as "Albnght" to "MadelemeAlbnght," "U S"  to "Umted States," and "IBM" for"International Business Machine" We used tlus toolto link full names and.
their aliases o that term fre-quency can be more accurately reflected, x e ,  "IBM"and "International Business Machine" are countedas two occurrences of the same termAnother overt clue for chscourse cohesion and co-herence is synonymous words When a theme ofan article m developed throughout the text, synony-mous words often appear as variants m the text Inthe example below, forinstance, "pictures" and ~m-ages" are used interchangeablyA new medzcal imaging technzque maysomeday be able to detect lung cancer anddiseases of the bra:n earher than conven-twnal methods, according to doctors at theState Un:vers,ty of New York, Stony Brook,and Princeton Un:verszty If doctorswant to take pic tures  of the lungs, henoted, they have to use X-ray machines, ez-pos:ng thezr pat:ents to doses of radtatzon:n the process The new technlque usesan anesthetfc, tenon gas, instead of waterto create images of the bodyAlthough synonym sets have not  proven ef-fective in reformation retrieval for query expan-sion (Vorhees, 1994), we are using WordNet (Malletet al,  1990) to link synonymous words m an arti-cle In the IR task, a query term is expanded withIts synonyms without dlsambxguatmg the senses ofthe term Thus, semantically irrelevant query termsare added, and the system typically retrieves moreirrelevant documents, decreasing the precision Oursummarization approach, in contrast, attempts toexploit WordNet synonym sets of only signatureterms m a szngle document Our hypothesis m thatif a synonym of a signature term extsts m the article,the term has been dlsamblgnated by the context ofthe article and the "correct" synonym, not a syn-onym of the term in a different sense, m likely toco-occur in the same documentIn addition, morphological analysts allows us tolink morphological variants of the same word withina document Morphological variants are often usedto refer to the same concept hroughout a document,68!
!iIproviding discourse clues In the above example,"lma~ng" and "Images" are morphologically linkedLike synonyms, morphology or stemming has notproven to be useful for "lmprowng information re-trieval (Salton and Lesk, 1968, Harman,~1991)However, the recent work by (Church, 1995) showedthat effectiveness of morphology, or correlationsamong morphological variants within a document,vanes from word to word A word hke "hostage"has a large correlation with its variant Uhostages"while a word like "await" does not According to hisexperiments, good keywords like "hostage" and itsvariants are likely to be repeated more than chancewithin a document and highly correlate with variantforms Tins implies that important signature wordswe use for summarization are likely to appear In asingle document multiple times using their variantforms2.2 Combin ing  Sl~rnrnarlzatlon FeaturesThe DlmSum summarizer exploits our flexible def-inition of a signature word and sources of domainand duscourse knowledge m the texts through?
the creation of multiple basehne databases cor-responding to multiple definitions of signaturewords?
the application of the discourse features inmultiple-term frequency calculation methodsDifferent baseline databases can affect the inversedocument frequency (ldf).
values We have cre-ated multiple baseline databases based upon mul-tiple deflmtions of the signature words Signa-ture words are flexibly defined as collections of fea-tures Presently, we derive databases cousustmg of(a) terms alone, (b) terms plus multi-word names,(c) stemmed terms plus muti-words names, and(d) terms plus multi-word names and collocationsThe duscourse features, 1e ,  synonyms, morphologi-cal variants or name ahases, for s~gnature words, onthe other hand, can affect the term frequency (tf)values Using these discourse features boosts theterm frequency score within a text .when they are.
treated as var!ants of signature words Having mul-tiple baseline databases available makes it easy totest the contribution of each feature or combinationof features2.2.1 The  Feature  Combiner :  Cur rentIn order to select sentences for a summary, eachsentence in the document us scored using differentcombinations of signature word features and dis-course features Currently, every token m a docu-ment us assigned a score based on its tf*ldf valueThe token score us used, in turn, to calculate thescore of each sentence in the document More specif-ically, the score of a sentence is calculated as the av-erage of the scores of the tokens contained m thatsentence with the exception that certain types of69tokens can be ehmmated from the sentence as dis-cussed That m, the DlmSum system can Ignore anycombination of name types (1 e,  person, place, en-tity) from a ~ven document for sconng (cf Section 3for more details)After every sentence is assigned a score, the top ntnghest scoring sentences are chosen as a summaryof the content of the document Currently, the Dun-Sum system chooses the number of sentences equalto a power k (between zero and one) of the totalnumber of sentences Thus, the system can vary thelength of a summary accordmg to ~ For instance,if 0 5 is chosen as the power, and the document con-sists of 100 sentences, the output summary wouldcontain 10 sentences Thus scheme has an advantageover choosing a given percentage of document sizeas it yields more information for longer documentswhile keeping summary size manageable We usethe results of thus method as the baseline summaryperformance (; e,  without any training), and reportthem m Section 32.2.2 The  Feature  Combiner .
FutureAs our goal is to make our summarization systemtrainable to different user and application eeds, weare currently workmg on learning the best featurecombination method from a tralmng corpus auto-matically For training and evaluating our summa~nzatlon system, we had a user create extract sum-maries by selecting relevant sentences m articles Inorder to compare with the results of a trainable sum-manzer reported by (Kuplec, Pedersen, and Chen,1995), we first use Bayes' rules to learn the best scor-ing method Then, we will use an inductive learningalgorithm such as the decusion tree algorithm (Qum-lan, 1993) to learn summarization rules which candeal with feature dependencies across entences3 Eva luat ionMuch research as been devoted to assessing cor-respondence between human and machine abstractsbecause of the complexity of analyzing "ahoutness"as illustrated in (Hahn, 1990) As a result, most ofthe prehmmary evaluations of summarizatlon sys-terns have been developer-based A common aF-proach IS to compare correspondence b tween auto-matlc performance and human performance (Rath,Restock, and Savage, 1961, Edmundson, 1969, Ku-plec, Pedersen, and Chen, 1995) or summary accep~ability (Brandow, Mltze, and Ran, 1995) Othershave been task-based, comparing abstract and fulltext on~nals m terms of the browsing and searchtime (Mnke et al,  1994, Sumlta, Ono, and Ml-lke, 1993) or recall and precision m-document re-trieval (Brandow, Mltze, and Ran, 1995)Our evaluation methodology us two-prongedFirst, we evaluate the system by scoring for cor-respondence with human generated extracts (Secotlon 3 1) Second, m our future work we are col-laborating with the Umverslty of Massachusetts oevaluate retrieval effectiveness for system-generatedand human-generated summaries (Section 3 2)3.1 Developer -based Evaluat ionThe DlmSum development envtronment software in-corporates automatic sconng software to calculatesystem recall and precision for any user's training ortest data ThLs allows us to evaluate system perfor-mance for any user and for variatl0us m summarypreferencesWe performed an informal experiment in which 6users created summary extract versions of the sameset of 15 texts These versions varied considerablyamong users, winch supports our view that a sum-marlzation system should he trained for user pref-erence Then, we ran the DlmSum system overthese 15 texts using multiple feature combinations(l e ,  combmatlous among names, synonyms, andmorphologtcal variants), and scored against he sixversions of summary extracts Though correspon-dence between the DlmSum summaries and usersuminarles was low (ranging between 14% and 31%F-measures), clearly some feature sets were more ef-fective for some users than for others For example,the best feature c0mbmatlon for the best-case corre-spondence between the user and DlmSum (l e,  31%case) was the combination of name, synonym andmorphological mforinatlon On the other hand, thebest combination for the worst-case correspondencebetween the user and DlmSum (l e ,  14% case) wasthe combination of name and synonym reformationSome summary extracts, however, were not affectedby different combinations of featuresThe second step was to obtain a "bottom-hne"score for a singl e user We ran the DlmSum systemover a set of 86 texts using multiple feature combi-natlous The features were combined by taking anaverage Of tf*ldf, tf or ldf scores of each token ma-sentence No training was performed We vanedthe length of summaries (by changing/~ from 0 5 to1 0), use of different types Of names (l e ,  person,place, and entity), use of abases, and use of syn-onyms for different parts of speech (l e ,  adjective,adverb, noun, and verb)Table 2 shows the top three F-measure scores (1-3), and the score for using the simplest baseline (4)For the best summary (1), place names were usedwinle person and entity ~ames were recognized butremoved for sentence sconng Synonyms were alsoused The /c value was set to 0 65 (about 20-25%of a document as a summary) Use of aliases andsynonyms chdn't make much difference m the scores(2-3) However, they all scored shghtly ingher than?
the summary which &dn't use any of these features,i e ,  a summary which didn't use names, synonyms,or aliases (4)It Is interesting that using name tagging in a re-70verse way, 1 e , recogmzmg and then deleting personnames from ?
sentence scoring, made a slgmficantlypositive ffect on summarization The best summaryscore with the person name used m sentence scor-ing was 38 6% (5) The.reason why person namesmade negative contnbutlous to?the summary seems' to be because personal names were often mentionedas passing references (e g ,  names of spokespeople)m the corpus, but they had ingh ldf valuesFinally, m every feature combination, taking tf*ldfscores of each word outperformed the ldf-based cal-culation, and the latter m turn outperformed theif-based score calculationThese results further motivate us to apply auto-mated learning to combine summarization featuresThe fact that humans vary m summarization sug-gests that recall/preclmon evaluation.is not mean-mgful unless a summarization system Is trainableto a particular summary style Our current workis to identify through training what feature com-binations produce an optimal summary for a givenuser We anticipate that the summary performancewill improve with tralmng as DhmSum learns an-tomatlcally how or whether these, different mgna-.?
ture word definitions are contnbutmg to the sum-mary The current design does not incorporatepara~aph/sentence location reformation or genre-specific indicator phrases We are explonng if thesefeatures can be indirectly subsumed by the derivedfeatures we have already identifiedAlso, the cursory look at the summaries of Dim-Sum shows that the system-generated summary maybe prowdmg the same reformation as the summaryprovided by the user, but the sentences were chosendifferently ThE happens because the same reforma-tion can be conveyed by dnTerent sentences withinthe same document This motivates us to conduct amore task-oriented summarization evaluation, winchIs discussed below3.2 Task-based Evaluat ionAs a more task-oriented evaluation, we.
are col-laborating with the Umverslty of Massachusetts oevaluate retrieval etfectiveness for DlmSum system-generated .and human-generated xtracts for topicsfrom TREC-5 (Text REtrieval Conference-5) Wehave selected 30 topics, five assessed as difficult, fiveassessed as easy (Harman, 1996), and the remaining15 randomly The top 50 documents judged rele-vant by the INQUERY system m TRECC-5 for eachtopic have been identified For each document, twoextract versions are being manually created Oneextract m based on the topic description, wtule thesecond L9 generated independent ofthe topic descrip-tion In addition, the DlmSum system will automat-lcally.generate wo versions (query dependent andgeneric) for each of the texts With the TREC-5 fulltext results as a baseline, multiple lteratlous of theINQUEI~Y system wall test retrieval performance on!Ii1!II11!
!\[nt.AV , .
: .
....4 stony I~ .
, ,  ~.2 I~n~ton unwers~t~1 I S~ ?o~nmunlty coilllgeI star* umv~'s~ of ~w yak1 food and dr~p aclmmsmmon-~ Persoo- 8 sJbert, m~l l7 I I l~ ' t1 albor~, m~tChoII1 balamcro dlhp-\[1) p~i1 now yorkI~wa~t  Vm*c~0?0~ l~2S M28 </D0011~?S'L~.YID cut ,u \]m,,~.
sd.,~m--u~ x~ml .c~TC~.YID>?
cPORMA'T> ~ ~1 ~ T >c l~.AD~b - a1744 ~-?.~ 0491 </}I~A.OS~,cPREAMBL~>~-~ - a1744clffLDI1~> ~ ~m McMurme ~'L IN Ib .cCPY~RIGHT>:c) ~ Nem~#~.W~JOHT>?Iff.ADI.LNE>.~1~.
DOCtOa ~XZnm M~l t0 VkwL~ Maw (~ls &~L:TEXt'>q~:~ .
md dbmr, ses c~ ire b.Mu ea~4~.
,~ l  ccmm,~,m~ etb~ch~qm,,w~mmlms l~ ,m'mal~bmm~s m~ w~vm .,mwat~ ms bhaz :s~8~m'now~r   k l znm'~, '~* ' -m"m:dthe l Ip  &MDnm~ted~I  u~al m oaeMs~c,z~l~ iLw4 ram4 d ws~~ ~tSe'b~cli~ 9ec~ me su  s\]prr.~ds O~'o~lpm~,~ them~ve c~b w~r.h ~ m:b m a type ~ ~ calh~Di~Is ~bas~epotmwd w ~h~t~= m ~ Um ~.m md I=,p m~ m=~ thinFigure 1 Name Mode Summaryt,m,d ~ ~ b ~ o ~  VIw?
-~ I \ ]  m~word+ 8 albert, m~tchell4 s~ony brookG ~lnon.
.
.
.
d" 7r~7~ .
.
.
.
.
.
.
.
.
.5 irnlgmsI p~Jr lS4 lungs7 Mchn~w~14 extstlng12 rm~gIs2 a~iw~tim~2 semis2 ~rtm:e~on umvlrs~I hyplrDolaflzsS5 Conventional1 ~km~'O dshp31 nassau commumW ~o)hlge3 dlseesIS3 mIls| h~l(~lI mcmUrlrll?DOG~?Docm~ ~ .
s  raze ,c,~OCI0~ ?
?ST0\]tYZD cam-a\]p~.sd-qu-,~c, 'Q0a <~?~YID3.cFORMAT> ~ &DL </FO~.MAT>cS\[.UO> bc- - </SLUG>?IW, ADD.> - Lt744 07-25 04~J.
</HEADI\[~:Pr~AMBL)~.m-*  -a17~&tin, (ndy){A1r'/q,t Ncws $~r .d~ms)  A.QL~/P'REAMDLB>caYLINE:, By~ ' " -~</8YL~bccPYRZOlt'r)~Y JUOFrr>:~ADL IN Ib .&lYJt D~'s1 ,1~.~m i , j  tDYmv, .~ ,d=~J~,..&QLAumv--,'x-'~ ?
.
Jq  t .
.
..i m~,m,~,Fbs~ ~.ct~.m I\[ ' fhe~ed=u, ,  eAsat~mtmo~- e~,.e~l &t~l ~mapeh~~mem~mmn ~ ~du~uuda.~b~7 Butmmmswhm:~t  s m mthat  o .
,~m-~hm had al0t ~'uuMo mlmx~@Tbs~.m~v:d,.,..
cu~a,m.,rb'.
i  .
....
'~.~.," p~ ~, ,add~ma.~as .~ ~ddm~ Decme~meSm spreztstbn~Mmutth~Mood s~.am sod t~atb~ corer.me'me ~ arias d ~be hod7 su, rJ~, ~?
~ = ~w'mcSz 'enchmamm,W~c~.d~o~xthasthe~ ?
wrlmgr~U~SFigure 2 Keyword Mode Summary- ?71Table 2 Summary scores for different feature combinationsFeature Combination tf*ldf !
ldf I tfterm+place+synonym 41 5 32 3 20 9 (1)term+place+entity, - " 41 2 33 9 21 2 (2)term.termWplace+ahas+syn?nym 409399 323242104  /~l .term-l-person+place+entlty+ahas+synonym 386 321 225 (5)the human and machine generated extracts to com-pare retrieval effectiveness4 Mu l t i -d imens iona l  SummaryV iews  .The DlmSum Summarization Clientprovldes a sum-mary of a document in multiple dlmeuslons througha graphical user interface (GUI) to smt dflferentusers' needs In contrast o a static view of a doc-ument, the system brings the contributing hngnm-tie and other resources to the desktop and the userchooses the view he wants As shown m Flgnre 1,the GUI is divided mto the Lint Box on the left andthe Text Viewer on the rightWhen a user asks for a summary of a text, ex-tracted summary sentences are hlghhghted m theText Viewer The user can dynarmeally control apercentage of sentences to highlight for a summaryIn addition, the Client can automatically color-codetop keywords m different colors for different ypes(1 e,  person, entity, place and other) for quack andeasy browsingIn the Lint Box, the user can explore two differentsummary views of a text First, the user can choosethe "Name Mode," and all the names of people, en-tities, and places which were recognized by the nameextraction tool are sorted and displayed m the ListBox (el Figure 1) The user can also select a subsetof name types (e g,  only person and entity, but notplace) to d~play Aliases of a name are indented andhsted under their full namesIn the "Keyword Mode," the top keywords, or sig-nature words, (including names) axe dmplayed in theLast Box  Analogous to the name aliases, for eachkeyword its synonyms and morphological variants, ifexast, are indented and hsted below it (cf Figure 2)The user can choose the score threshold or percent-age to vary the number of keywords for displayIn both modes, the names and signature wordsin the List Box can be sorted alphabetically, byfrequency, or by the tf*ldf score Choking on  aterm in the Lint Box also causes the first occurrenceof the term to be hlghhghted in the Text ViewerFrom there, the user can use the FIRST, PREVIOUS,NEXT, or LAST button at the bottom of the GUI totrack the other occurrences ofthe term, including itsahases, synonyms, and morphological variants Thisprovides the user with a way to track themes of thetext lnteractively5 SummaryThe DlmSum summarization system leverages off.of the works of (Kuplec, Pedersen, and Chen,1995) and (Brandow, Mltze, .and Ran, 1995),and advances ummarmatlon technology by apply-nag corpus-based statistical NLP teehmques, robustinformation extraction, and readily avaalable on-hneresources Our prehxmnary experiments with com-bining different summarization features have beenreported, and our current effort to learn to com-bine these features to produce the best summarieshas been described The features derived by theserobust NLP techmques were also utihzed m present-mg multiple summary.vtews to the user m a novelwayReferencesAdvanced Research Projects Agency 1995 Proceed-:rigs of S:zth Message Understanding Conference(MUC-6) Morgan Kanfmann PubhshersBrandow, Ron, Karl Mltze, and Lisa Ran 1995Automatic ondensation f electromc pubhcatlousby sentence selection Information Processing and?
Management, 31, forthcoming.Bull, Eric 1993 A Comps-based Approach to Lan-guage Learning Ph D thesm, Umverslty of Penn-sylvaniaChurch, Kenneth and Patrick Hanks 1990 Word?
Aesoclatlon Norrns, Mutual Information, and Lex-icography Computational Lmgmstscs, 16(1)Church, Kenneth W 1995 One term or two 9 InProceedings of the 17th Annual International SI-GIR Conference on Research and Development InInformatzon Retrzeral, pages 310-318Edmundson, H P 1969 New methods m automaticabstracting Journal of the ACM, 16(2) 264-228Fum, Dando, Glovanm Gmda, and Carlo Tasso1985 Evalutatmg Importance A step towardstext surnmarlzatlon In I3CAI85, pages 840-844-IJCAi, AAAIHahn, Udo 1990 Topic parsing Accounting fortext macro structures m full-text analysm In for-72!i!IIIliIIIII!I1Iimat:on Processing and Management, 26(1)135-170Harman, Donna 1991 How effective is suttixang ~Journal of the Amerlcan Sot:cry for InformatwnSc:ence, 42(1) 7-15Harman, Donna 1996 Overview of the fifth textretrieval conference (tree-5) In TREC-5 Confer-ence ProceedingsJmg, Y and B Croft 1994 An Assoc:atwn The-saurns for Informatzon Retrseval Umass Techm-cal Report 94-I7 Center for Intelligent Informa-tion Retrieval, University of MassachusettsJohnson, F C, C D Prate, W J Black, and A PNeal 1993.
The apphcahon of hngumhc process-nag to automatic abstract generation Journal ofDocnmentatwn a d Tezt Management, 1(3) 215-241Jones; Karen Sparck 1993 What mtght be ina summary?
In Knorz, Krause, and Womser-Hacker, edttors, Informatwn Retrieval 'g3, pages9-26Jones, Karen Sparck 1995 Dmcourse modeling forautomahc surnmarms In E Hajlcova, M Cer-venka, O Leskn, and P Sgall, editors, Prague ~ :gmsttc Circle Papers, volume 1, pages 201-227Krupka, George 1995 SRA Descnphon of theSRA System as Used for MUC-6 In Proceed-rags of $:z'th Message Understanding Conference(MUC-~)Kuplec, Juhem, Jan Pedersen, and Francme Chert1995 A trmnable document summarizer In Pro-cee&ngs of the 18th Annual Internatwnai SIGIRConference on Research and Development :n In-formatwn Retrzeval, pages 68-73Luhn, H P 1958 The automatic reation of htera-ture abstracts In IBM J Research Development,volume 2, pages 159-165Maybury, Mark T 1995 Automated even sum-marxzatlon techmques In B Endres-Nlggemeyer,J Hobbs, and Karen Sparck Jones, editors,Summarizing Text for Intelhgent Commun:cat,on,pages 101-149McKeown, Kathleen and Dragomar Radev 1995Generating summaries of mulhple news articlesIn Proceedings of the 18th Annual Internat:onalSIGIR Conference on Research and Development:n In format:on, pages 74-78Make, Seljl, Etsuo Itho, Kenj10no, and KazuoSurmta 1994 A full text retrieval system witha dynannc abstract generation function In Pro-ceed:ngs of 17th Annual Internatwnal ACM S1-GIR Conference on Research and Development :nInformatwn Retrieval, pages 152-161Miller, George, Richard Beekwith, Chnshane Fell-" baum, Derek Gross, and Katherine Miller 199073Five papers on WordNet Technical Report CSLReport 43, Cogmhve Science Laboratory, Prince-ton Umverslty .Pmce, C 1990 Constructing hterature abstracts bycomputer Techmques and prospects Informa-::on Processing and Management , 26(1) 171-186Prate, C and P A Jones 1993 The ldenhficahon ofimportant concepts m lughly structured techmealpapers In Proceedings of the 16th Annual Inter-natwnal A CM SIGIR Conference of Research andDevelopment m Inforraatzon Retrieval, pages 69-78?
Qumlan, J Ross 1993 C4 5 Programs for Ma-chine Learmng Morgan Kaufmann PublmhersRath, G J ,  A Restock, and T R Savage 1961The formation of abstracts by the selechon of sen-tenees Amer:can Doeumentatwn, 12(2) 139-143Rau, Lma F ,  Paul S Jacobs, and Un Zermk 1989Information extraction and text surnmanzatlonumng hngmstlc knowledge acqmslhon Informa-:son Processing and Management, 25(4) 419-428Relmer, Ulrich and Udo Hahn 1988 Text conden-sahon as knowledge base ahstractmn In IEEE?
Conference on AI Apphcatwns, pages 338-344Rxlotf, Ellen 1995 A corpus-based approachto dommn-speclfic text surnmanzatlon InB Endres-Nlggemeyer, J Hobbs, and K SparekJones, e&tors, Summarizing TeE/or lntelhgentCommumcatwn, pages 69-84Rush, J E,  R Salvador, and A Zamora 1971Automatic abstracting and mdemng Produchonof m&eahve abstracts by.
application of contex-tual inference and syntactic riteria Journal ofthe American Sot:cry for Informat:on Sc:ence,22(4) 260-274Salton, G and M McGdl, editors 1983 AnIntroductzon to Modern Informatwn RetrievalMcGraw-HallSalton, Gerald and Mark Leak 1968 Computerevaluation of indexing and text processing Jour-nal of the ACM, 15(1) 8-36Sumxta, Kazuo, Kenjl Ono, and Seljt Make 1993Document structure extraction for mterachvedocument retrieval systems In Procee&ngs OfSIGDOC'93, pages 1301-310Vorhees, E 1994 Query expansion using lexacal-semamc relations In Proceedings of the 17thAnnual Internatwn.al ACM-SIGIR Conference onResearch and Development of Informatwn Re-trzeval, pages 61-69
