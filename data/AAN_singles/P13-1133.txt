Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1352?1362,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsLinking and Extending an Open Multilingual WordnetFrancis BondLinguistics and Multilingual StudiesNanyang Technological Universitybond@ieee.orgRyan FosterGreat Achievement Pressryan_foster@gapbks.comAbstractWe create an open multilingual wordnetwith large wordnets for over 26 languagesand smaller ones for 57 languages.
It ismade by combining wordnets with open li-cences, data from Wiktionary and the Uni-code Common Locale Data Repository.Overall there are over 2 million sensesfor over 100 thousand concepts, linkingover 1.4 million words in hundreds of lan-guages.1 IntroductionWe wish to create a lexicon covering as many lan-guages as possible, with as much useful informa-tion as possible.
Generally, language resources, tobe useful, must be both accessible (legal to use)and usable (of sufficient quality, size and with adocumented interface) (Ishida, 2006).
We addressboth of these concerns in this paper.One of the many attractions of the semantic net-work WordNet (Fellbaum, 1998), is that there arenumerous wordnets being built for different lan-guages.
There are, in addition, many projectsfor groups of languages: Euro WordNet (Vossen,1998), BalkaNet (Tufis?
et al, 2004), Asian Word-net (Charoenporn et al, 2008) and more.
Al-though there are over 60 languages for whichwordnets exist in some state of development (Fell-baum and Vossen, 2012, 316), less than half ofthese have released any data, and for those thathave, the data is often not freely accessible (Bondand Paik, 2012).
For those wordnets that are avail-able, they are of widely varying size and quality,both in terms of accuracy and richness.
Further,there is very little standardization in terms of for-mat, what information is included, or license.The goal of the research outlined in this paperis to make it possible for a researcher interested inworking on the lexical semantics of a language orlanguages to be able to access wordnets for thoselanguages with a minimum of legal and technicalbarriers.
In practice this means making it possibleto access multiple wordnets with a common inter-face.
We also use sources of semi-structured datathat have minimal legal restrictions to automati-cally extend existing freely available wordnets andto create additional wordnets which can be addedto our open wordnet grid.Previous studies have leveraged multiple word-nets and Wiktionary (Wikimedia, 2013) to extendexisting wordnets or create new ones (de Melo andWeikum, 2009; Hanoka and Sagot, 2012).
Thesestudies passed over the valuable sense groupingsof translations within Wiktionary and merely usedWiktionary as a source of translations that werenot disambiguated according to sense.
The presentstudy built and extended wordnets by directly link-ing Wiktionary senses to WordNet senses.Meyer and Gurevych (2011) demonstrated theability to automatically identify many matchingsenses in Wiktionary and WordNet based on thesimilarity of monolingual features.
Our studycombines monolingual features with the disam-biguating power of multiple languages.
In ad-dition to differences in linking methodology, ourproject gives special attention to ensuring the max-imum re-usability and accessibility of the data andsoftware released.Other large scale multilingual lexicons havebeen made by linking wordnet to Wikipedia(Wikipedia, 2013; de Melo and Weikum, 2010;Navigli and Ponzetto, 2012).
Our approach iscomplementary to these: in general Wikipedia hasmore entities than classes, while Wiktionary hasmore classes.In Section 2 we discuss linking freely availablewordnets to form a single multilingual semanticnetwork.
In Section 3 we extend the wordnets withdata from two sources.
We show the results inSection 4 and then discuss them and outline future1352work in Section 5.2 Linking Multiple WordnetsIn order to make the data from existing wordnetprojects more accessible, we have built a simpledatabase with information from those wordnetswith licenses that allow redistribution of the data.These wordnets, their licenses and recent activityare summarized in Table 1 (sizes for most of themare shown in Table 2).1Wordnet Project Lng Licence TypeAlbaneto als CC BY aArabic WordNet arb CC BY-SA sDanNet dan wordnet aPrinceton WordNetu eng wordnet aPersian Wordnet fas free to use uFinnWordNetu fin CC BY aWOLFu fra CeCILL-C sHebrew Wordneto heb wordnet sMultiWordNeto ita CC BY aJapanese Wordnetu jpn wordnet aMultilingual cat CC BY aCentral eus CC BY-NC-SA nRepositoryo,u glg CC BY aspa CC BY aWordnet Bahasau ind MIT azsm MIT aNorwegian Wordneto nno wordnet anob wordnet aplWordNeto,u pol wordnet aOpenWN-PTu por CC BY-SA sThai Wordnet tha wordnet ao Re-released under an open license in 2012u Updated in 2012Type: u Unrestricted; a Attribution; s Share-alike;n Non-commercialURL: http://casta-net.jp/~kuribayashi/multi/Table 1: Linked Open WordnetsThe first wordnet developed is the PrincetonWordNet (PWN: Fellbaum, 1998).
It is a largelexical database of English.
Open class words(nouns, verbs, adjectives and adverbs) are groupedinto concepts represented by sets of synonyms(synsets).
Synsets are linked by semantic relationssuch as hyponomy and meronomy.
PWN is re-leased under an open license (allowing one to use,copy, modify and distribute it so long as you prop-erly acknowledge the copyright).The majority of freely available wordnets takethe basic structure of the PWN and add new lem-mas (words) to the existing synsets: the extendmodel (Vossen, 2005).
For example, dogn:1 islinked to the lemmas chien in French, anjing inMalay, and so on.
It is widely realized that this1We have now added Mandarin Chinese.model is imperfect as different languages lexical-ize different concepts and link them in differentways (Fellbaum and Vossen, 2012).
Nevertheless,many projects have found that the overall structureof PWN serves as a useful scaffold.
The fact that,for example, a dogn:1 is an animaln:1 is languageindependent.In theory, such wordnets can easily be com-bined into a single resource by using the PWNsynsets as pivots.
All languages are linked throughthe English wordnet.
Because they are linked atthe synset level, the problem of ambiguity one getswhen linking bilingual dictionaries through a com-mon language is resolved: we are linking senses tosenses.In practice, linking a new language?s wordnetinto the grid could be problematic for three rea-sons.
The first problem was that the wordnets werelinked to various versions of the Princeton Word-Net.
In order to combine them into a single multi-lingual structure, we had to map to a common ver-sion.
The second problem was the incredible va-riety of formats that the wordnets are distributedin.
Almost every project uses a different format.Even different versions of the same project oftenhad slightly different formats.
The final problemwas legal: not all wordnets have been released un-der licenses that allow reuse.The first problem can largely be overcome us-ing the mapping scripts from Daude et al (2003).Mapping introduces some distortions, in particu-lar, when a synset is split, we chose to only mapthe translations to the most probable mapping, sosome new synsets will have no translations.The second problem we are currently solvingthrough brute force, writing a new script for ev-ery new project we add.
We make these scripts,along with the reformatted wordnets, freely avail-able for download.
Any problems or bugs foundwhen converting the wordnets have been reportedback to the original projects, with many of themfixed in newer releases.
We consider this feedbackto be an important part of our work: it means thatother researchers and users do not have to sufferfrom the same problems and it encourages projectsto release updates.The third, legal, problem is being solved byan ongoing campaign to encourage projects to(re-)release their data under open licenses.
SinceBond and Paik (2012) surveyed wordnet licensesin 2011, six projects have newly released data un-1353der open licenses and eight projects have updatedtheir data.Our combined wordnet includes English (Fell-baum, 1998); Albanian (Ruci, 2008); Arabic(Black et al, 2006); Chinese (Huang et al, 2010);Danish (Pedersen et al, 2009); Finnish (Linde?nand Carlson., 2010); French (Sagot and Fis?er,2008); Hebrew (Ordan and Wintner, 2007); In-donesian and Malaysian (Nurril Hirfana et al,2011); Italian (Pianta et al, 2002); Japanese(Isahara et al, 2008); Norwegian (Bokma?l andNynorsk: Lars Nygaard 2012, p.c.
); Persian (Mon-tazery and Faili, 2010); Portuguese (de Paivaand Rademaker, 2012); Polish (Piasecki et al,2009); Thai (Thoongsup et al, 2009) and Basque,Catalan, Galician and Spanish from the Multilin-gual Common Repository (Gonzalez-Agirre et al,2012).On our server, the wordnets are all in a sharedsqlite database using the schema produced bythe Japanese WordNet project (Isahara et al,2008).
The database is based on the logical struc-ture of the Princeton WordNet, with an additionallanguage attribute for lemmas, examples, defini-tions and senses.
It is a single open multilingualresource.
When we redistribute the data, eachproject?s data is made available separately, with acommon format, but separate licenses.The Scandinavian and Polish wordnets arebased on the merge approach, where indepen-dent language specific structures are built and thensome synsets linked to PWN.
Typically only asmall subset will be linked (due more to resourcelimitations than semantic incompatibility).2.1 Core ConceptsBoyd-Graber et al (2006) created a list of 5,000core word senses in Princeton WordNet whichrepresent approximately the 5,000 most frequentlyused word senses.2 We use this list to evaluate thecoverage of the wordnets: do they contain wordsfor the most common concepts?
As a very roughmeasure of useful coverage, we report the percent-age of synsets covered from this core list.
Becausethe list is based on English data, it is of course nota perfect measure for other languages and cultures.Note that some wordnet projects have deliberatelytargeted the core concepts, which of course booststheir coverage scores.2The original list is here from http://wordnetcode.princeton.edu/standoff-files/core-wordnet.txt;we converted it to wn30 synsets.2.2 License TypesThe licenses fall into four broad categories: (u)completely unrestricted, (a) attribution required,(s) share alike, and (n) non-commercial.
The firstcategory includes any work that is in the publicdomain or that the author has released without anyrestrictions.
The second category allows anyoneto use, adapt, improve, and redistribute the work aslong as one attributes the work in the manner spec-ified by the copyright holder (without suggestingan endorsement).
The WordNet, MIT, and CC BYlicenses are all in this category.
The third categoryallows anyone to adapt and improve the licensedwork and redistribute it, but the redistributed workmust be released under the same license.
The CCBY-SA, GPL, GFDL, and CeCILL-C licenses areof this type.
Because derivative works can onlybe redistributed under the same license, works li-censed under any two of these licenses cannotbe combined with each other and legally redis-tributed.
In general, a work formed from the com-bination of works in category (u) and (a) with awork in category (s) will be subject to the more re-strictive terms of the the share alike license.
How-ever, the GPL, GFDL and CeCILL-C are incom-patible with CC BY.3 The fourth type of licensefurther forbids the commercial use of a work.
TheCC BY-NC and the CC BY-NC-SA licenses are inthis category, they are also incompatible with li-censes in category (s).Releasing a work under the more restrictive li-censes in categories (s) and (n) above substantiallylimit and complicate the ability to extend and com-bine a work into other useful forms.
By maintain-ing a separation of databases released under in-compatible licenses, we avoid any possible legalproblems.
Due to license incompatibilities, it isimpossible to release a single database with all thewordnets, even though individually they are redis-tributable.
We can currently combine those withlicenses in groups (u) and (a) and the CC BY-SA wordnets (now everything except French andBasque).3 Extending with non-wordnet dataWe looked at two sources for automatically addingnew entries.
The Unicode Common Locale DataRepository (CLDR) has reliable information onlanguages, territories and dates.
Wiktionary is a3http://www.gnu.org/licenses/license-list.html\#ccby1354general purpose lexicon with much more informa-tion for many words.3.1 Unicode Common Locale DataRepository (CLDR)We added information on languages, territoriesand dates from the Unicode Common Locale DataRepository (CLDR).4 This is a collection of datamaintained by the Unicode Consortium to supportsoftware internationalization and localization withlocale information on formatting dates, numbers,currencies, times, and time zones, as well as helpfor choosing languages and countries by name.
Ithas this data for over 194 languages.
It is releasedunder an open license that allows redistributionwith proper attribution (Unicode, Inc., 2012).5We found data for 122 languages.
Most hadaround 550 senses (synsets and their lemmas): forexample, for Portuguese: Englishn:1 ingle?s.
Somehad only 40 or 50, such as Assamese, which onlyhas the week days, month names and a few lan-guage names.
The linked data was small enoughto check by hand.
When the original CLDR datais correct the data we generate should be correct.The idea of using such data is not new.
Quahet al (2001) for example, use Linux locale datato extend a proprietary English-Malay lexicon.de Melo and Weikum (2009) also use this data(and data from a variety of other sources) to buildan enhanced wordnet, in addition adding newsynsets for concepts that are not in not wordnet.However, when they released the data as LEXVO(data about languages: CC BY-SA) and UWN (theuniversal multilingual wordnet: CC BY-NC-SA),they added additional license restrictions whichcomplicate the reuse of the data and make it im-possible to integrate the data back into the originalwordnet project.3.2 WiktionarySearches for a publicly-available source of Wik-tionary in a preprocessed, machine-readable for-mat did not turn up any sources that were recentand publicly-available.6 Although there are sev-4http://cldr.unicode.org/5With the extra requirement that ?there is clear notice ineach modified Data File or in the Software as well as in thedocumentation associated with the Data File(s) or Softwarethat the data or software has been modified.
?6We later learned that McCrae et al (2012) made a releaseof Wiktionary in the lemon format (http://datahub.io/en/dataset/dbnary).
They did not, however, release thecode they used to parse Wiktionary.eral freely-available software programs that arecapable of parsing portions of the English Wik-tionary, none of the programs that were evaluatedappeared to extract the precise set of informationdesired for our task in an easy-to-use format.
Sothe authors decided to build a custom parser capa-ble of extracting the information needed for build-ing open wordnets.3.2.1 Wiktionary ParserSince each language edition of Wiktionary is for-matted in a somewhat unique way, parsers mustbe tailored to recognize the structure and format-ting of each edition on a case-by-case basis.
Theauthors created a parser tailored to the EnglishWiktionary, although it can be extended to handleother language versions as well.
We are releasingthis code under the MIT license.7The current version of the parser is capable ofextracting headwords, parts of speech, definitions,synonyms and translations from the XML Wik-tionary database dumps provided by the Wikime-dia Foundation.8 Within these large XML files,the main body of Wiktionary articles are stored ina Wikitext format, which is a semi-structured for-mat.
Although anyone can edit a Wiktionary pageand use any style of formatting they desire, thecommunity of users encourages adhering to estab-lished guidelines, which produces a format that isgenerally predictable.Within the English Wiktionary, synonyms andtranslations are both grouped into sense groupsthat correspond with definitions in the main sec-tion.
These sense groups are marked by a shorttext gloss (short gloss), which is usually an abbre-viated version of one of the full definitions (fulldefinition).
The parser makes no attempt to matchthese short glosses with the full definitions.
Datais simply extracted, cleaned, and then stored in arelational database or flat file.Translations proved to be easy to extract dueto the fairly consistent use of a specifically for-matted translation template.
These templates in-clude a language code derived from ISO standards,the translation, and optional additional informa-tion such as gender, transliteration, script, and al-ternate forms.
The parser extracts and retains allof this potentially valuable information.Examples of translation templates:7Available from the Open Multilingual Wordnet Page:http://casta-net.jp/~kuribayashi/multi/.8http://dumps.wikimedia.org/1355?
Finnish: {{t+|fi|sanakirja}}?
French: {{t+|fr|dictionnaire|m}}To enable later processing, it is necessary to tiesynonyms and translations to their correspondingshort gloss via a unique key.
Most parsers simplyuse an automatically generated surrogate key or akey based on the ordered position of data withina Wiktionary article.
Since Wiktionary is con-stantly changing, the side effect of this approachis that data extracted from a specific snapshot ofthe Wiktionary database can only be meaningfullyused in connection with other data extracted bythe same parser from the exact same snapshot.
Toovercome this, we use a unique key that can berecreated from the data itself, which we call thedefkey.
To generate this key, we concatenate thelanguage code, headword, part of speech, and theshort gloss and use the sha1 hash function (NIST,2012) to create a unique 40-character hexadecimalstring from the resulting text.These defkeys are time and technology indepen-dent, so they allow the ability for researchers toefficiently share and compare results.
Once a linkis established between this defkey and a particu-lar synset, translations added to Wiktionary at alater data can be automatically integrated into ourmultilingual wordnet.
Conversely, if a Wiktionarycontributor changes a short gloss, historical dataconnected to the old defkey is preserved while newdata imported at a later time will not be incorrectlylinked to an older definition.Another feature of our parser is a feedbackmode, which generates a report about poorly for-mated data that was encountered.
These automat-ically generated reports can be used to create aquality-enhancing feedback loop with Wiktionary.3.2.2 Linking SensesMeyer and Gurevych (2011) showed that auto-matic alignments between Wiktionary senses andPWN can be established with reasonable accuracyand recall by combining multiple text similarityscores to compare a bag of words based on severalpieces of information linked to a WordNet sensewith another bag of words obtained from a Wik-tionary entry.
In our study we evaluated the poten-tial for aligning senses based on common transla-tions in combination with monolingual similarityfeatures.In this study we used 20 of the wordnets de-scribed in Section 2,9 and the Wiktionary data ob-tained using the parser described in Section 3.2.1.Before searching for translation matches, we nor-malized the data to ensure the most accurate pos-sible overlap count.
First, article headwords wereincluded as English translations of Wiktionarysenses (along with synonyms).
Then differencesin language codes were rectified and translationscontaining symbolic characters or a mixture of ro-man and non-roman characters were marked to beignored, save a few exceptions.
This left approx-imately 1.4 million sense translations in 20 lan-guages in our wordnet grid, and nearly 1.3 millionWiktionary translations in over 1,000 languages.We then created a list of all possible align-ments where at least one translation of a wordnetsense matched a translation of a Wiktionary sense.This represented a small percentage of the possi-ble alignments, because definitions in Wiktionarythat do not contain any translations were ignoredin our study.
Of more than 500,000 English defini-tions in Wiktionary, only about 130,000 presentlyhave associated translations.
The resulting graphcontained over 700,000 possible sense alignments.We calculated a number of similarity scores, thefirst two based on similarity in the number of lem-mas, calculated using the Jaccard index:sime(sn,sk) =|E(sk)?E(sn)||E(sk)?E(sn)|(1)sima(sn,sk) =|L(sk)?L(sn)||L(sk)?L(sn)|(2)Where sk,sn are concepts in Wiktionary and word-net respectively,10 E(s) is the set of English lem-mas for sense s and L(s) is the set of lemmas in alllanguages.As an initial pruning, we kept only matcheswhere either: sima ?
0.7 or (sime ?
0.5 andsima ?
0.5) or, if (|L(sk) ?
L(sn)| > 5) then(sime ?
0.5 and sima ?
0.45).
After apply-ing these filters, approximately 220,000 alignmentcandidates remained.We reviewed a random sample of 551 alignmentcandidates.
Of these 136 were deemed correctlyaligned.
Another 48 we considered possibly closeenough to produce valid translations for wordnet.All others were marked as incorrect alignments.9We didn?t use Chinese or Polish, as the wordnets wereadded after we had started the evaluation.10Precisely, synsets in wordnet and senses in Wiktionary.1356This development dataset was used to tune re-fined similarity scores.simt(sn,sk) =|L(sk)?L(sn)|??
|L(sk)?L(sn)|(3)simd(sn,sk) = BoW(wndef)?BoW(wkdef)?BoW(wndef)??BoW(wkdef)?
(4)simc(sn,sk) = simt+?
simc (5)simt gives higher weight to concepts that linkthrough more lemmas, not just a higher proportionof lemmas.simd measures the similarity of the definitionsin the two resources, using a cosine similarityscore.
We initially used the WordNet gloss andexample sentence(s) for wndef and the short glossfrom Wiktionary for wkdef.
This improved the ac-curacy of the combined ranking score (simc), butsince many of the short glosses are only one ortwo words, the sparse input often produced a simdscore of zero even when the candidate alignmentwas correct.
To improve the accuracy of the simdcomponent, we also added in the long definitions.Short glosses were aligned with long definitionsusing a similar approach to McCrae et al (2012).First we search for a match where the short glosswas a substring of the full definition.
If that failedto produce a single possible alignment, we alignedthe short gloss with the full definition that pro-duced the greatest cosine similarity score.
Finally,where the short definition was blank and only along definition was present, we aligned the two.The results of this alignment were less than 90%accurate, so to offset the effects of this noise we in-cluded both the full definition and the short glossin wkdef.
For wndef we used the WordNet gloss,example sentence(s), and synonyms.
Even thoughthe linking of definitions within Wiktionary leftmuch to be desired, the increased amount of textimproved the accuracy of the definition based sim-ilarity component of our ranking score.Our combined ranking score (simc), based onboth overlapping translations and a monolinguallexical similarity score, was able to outperformranking based on either component in isolation.We expect that an improved alignment of shortglosses to full definitions together with more ac-curate measures of lexical similarity such as de-scribed by Meyer and Gurevych (2011) would fur-ther improve the accuracy of a combined rankingscore.
We employed our combined ranking scorefirst as a filter, where simc ?
?c.
The ranking scoreis then used to select the best match among com-peting alignments.
Alignments are based on thebelief that a definition within Wiktionary shouldonly map to a single WordNet synset (if any atall).
In theory, each WordNet synset should rep-resent a meaning distinguishable from all othersynsets.
Because Wiktionary is organized accord-ing to lemma first, and sense second, multiple def-initions in separate articles often map to the samesynset.
For example mortal ?A human; someonesusceptible to death?, individual ?A person con-sidered alone .
.
.
?, and person ?A single humanbeing; an individual?
all align with someonen:1(00007846-n).
However, two distinct definitionswithin the same Wiktionary entry should not mapto the same WordNet sense.
When there are mul-tiple possible alignments where only one can bevalid, simc is used to determine the best match.In addition to using the combined ranking scoreas a filter, we found that we could obtain a smalladditional increase in accuracy without reducingrecall by also requiring simt ?
?t or simd ?
?d .To determine ideal values for the weights andthresholds, we performed several grid searches.The parameters are interdependent and can pro-duce reasonable results at a variety of points.
Idealvalues also depend on whether we wish to maxi-mize accuracy or recall.
?
is set at 3.2 in order toachieve an ideal target threshold of ?t = 1.
We fi-nally chose values of ?
= 0.7 and ?c = 0.71 whichgave a reasonable balance between accuracy andrecall.4 Results and EvaluationWe give the data for the 26 wordnets with morethan 10,000 synsets in Table 2.
There are a further57 with more than 1,000; 133 with more than 100,200 with more than 10 and 645 with more than 1(although most of the very small languages appearto be simple errors in the language code enteredinto Wiktionary).
Individual totals are shown forsynsets and senses from the original wordnets, thedata extracted from Wiktionary, and the mergeddata of the wordnets, Wiktionary and CLDR.
Wedo not show the CLDR data in the table as it isso small, generally 500-600 synsets for the toplanguages.
Overall there are 2,040,805 senses for117,659 concepts, using over 1,400,000 words inover 1,000 languages.The smaller wordnets are not of much practi-cal use, but can still serve as the core of new1357Projects Wiktionary Merged (+CLDR)ISO Language Synsets Senses Core Synsets Senses Core Synsets Senses Coreeng English 117,659 206,978 100 35,400 49,951 75 117,661 213,538 100fin Finnish 116,763 189,227 100 21,516 31,154 65 116,830 199,435 100tha Thai 73,350 95,517 81 2,560 3,193 17 73,595 97,390 81fra French 59,091 102,671 92 20,449 27,150 63 61,258 109,643 95jpn Japanese 57,179 158,064 95 12,685 19,479 52 59,112 166,617 96ind Indonesian 52,006 142,488 99 2,390 2,810 17 52,154 143,755 99cat Catalan 45,826 70,622 81 8,626 10,251 36 48,007 74,806 84spa Spanish 38,512 57,764 76 18,281 25,310 60 47,737 74,848 86por Portuguese 41,810 68,285 79 12,331 16,178 53 43,870 74,151 84zsm Standard Malay 42,766 119,152 99 2,833 3,744 19 43,079 120,686 99ita Italian 34,728 60,561 83 14,605 18,710 53 38,938 68,827 87eus Basque 29,413 48,934 71 1,693 1,943 11 29,965 49,945 72pol Polish 14,008 21,001 30 10,888 13,431 46 20,975 30,943 55glg Galician 19,312 27,138 36 2,492 2,871 15 20,772 29,136 42fas Persian 17,759 30,461 41 4,229 5,443 26 20,766 35,318 55rus Russian 0 0 0 19,983 33,716 64 20,138 34,009 64deu German 0 0 0 19,675 29,616 64 19,857 29,884 64cmn Mandarin Chinese 4,913 8,069 28 12,130 19,079 49 15,490 27,113 60arb Standard Arabic 10,165 21,751 48 6,892 9,337 38 14,861 31,337 63nld Dutch 0 0 0 13,741 19,709 56 13,950 20,003 56ces Czech 0 0 0 12,802 15,493 54 13,030 15,813 54swe Swedish 0 0 0 12,000 16,226 51 12,221 16,512 51ell Modern Greek 0 0 0 10,308 13,071 44 10,549 13,472 44dan Danish 4,476 5,859 81 7,290 8,931 35 10,328 13,551 85nob Norwegian Bokma?l 4,455 5,586 79 7,262 9,170 35 10,322 13,612 83hun Hungarian 0 0 0 9,964 12,699 45 10,213 13,029 45Core shows the percentage coverage of the 5,000 core concepts.Table 2: Merged Wordnets (with more than 10,000 entries)projects.
The bigger wordnets show the data fromWiktionary (and to a lesser extent CLDR) havingonly a small increase in the number of senses.
Thebiggest change is for the medium size projects,such as Persian or Arabic, which end up withmuch better coverage of the most frequent coreconcepts.
Major languages such as German orRussian, which currently do not have open word-nets get good coverage as well.The size of the mapping table is the same as thenumber of English senses linked (49,951 senses).We evaluated a random sample of 160 alignmentsand found the accuracy to be 90% (Wiktionarysense maps to the best possible wordnet sense).We then evaluated samples of the wordnet cre-ated from Wiktionary for several languages.
Foreach language we choose 100 random senses, thenchecked them against existing wordnets.11 For allunmatched entries, we then had them checked bynative speakers.
The results are given in Table 3.The sense accuracy is higher than the mapping ac-curacy: in general, entries with more translationsare linked more accurately, thus raising the av-erage precision.
During the extraction and eval-11For Chinese we use the wordnet from Xu et al (2008),which is free for research but cannot be redistributed.
ForGerman we used Euro WordNet (Vossen, 1998).Language % Matched % GoodChinese?
46 97Serbo-Croation?,??
0 91Czech?
0 99English 89 92German?
19 85Indonesian 69 97Korean?
0 96Japanese 56 90Russian?
0 99Average 94.0Table 3: Precision of Wiktionary-based Wordnets?
Not used to build the mapping from wordnet to Wiktionary.??
We allow terms used in either Serbian or Croatian.uation, we noticed several language specific fea-tures: for example, Serbo-Croatian had a mixtureof Cyrillic and Latin entries.
For languages whereone script was clearly dominant, we kept only that,but really these decisions should be done for eachlanguage by a native speaker.We make the data available in two ways.
Thefirst is a set of downloads.
Each language has upto three files: the data from the wordnet project(if it exists), the data from the CLDR and the datafrom Wiktionary.
They are kept separate in order1358to keep the licenses as free as possible.
The sec-ond is as two on-line searches: one using only thedata from the projects, and one with all the datacombined.
The combination is done by simpleunion.12 We maintain this separation as we can-not guarantee the quality of the automatically ex-tracted data.
Because the raw data is there it is pos-sible to combine them in other ways.
The simplestructure is easy to manipulate, and there is codeto use this style of data with the popular tool kitNLTK (Bird et al, 2010).5 Discussion and Future WorkWe have created a large open wordnet of highquality (85%?99% measured on senses).
Twentysix languages have more than 10,000 conceptscovered, with 42?100% coverage of the most com-mon core concepts.
The data is easily download-able with minimal restrictions.
The overall ac-curacy is estimated at over 94%, as most of theoriginal wordnets are hand verified (and so shouldbe 100% accurate).
The high accuracy is largelythanks to the disambiguating power of the multi-ple translations, made possible by the many openwordnets we have access to.Because we link senses between wordnet andWiktionary and then use the translations of thesense, manually validating this mapping will im-prove the entries in multiple languages simultane-ously.
As the Wiktionary-wordnet algnment map-ping is linked to persistent keys it will remain use-ful even as the resources change.
Further, it can beused to identify and add missing senses to word-net: unmapped Wiktionary entries are candidatesfor new concepts.The Universal Wordnet (UWN: de Melo andWeikum, 2009) brings in data from even more re-sources, and combines them to make a larger re-source, choosing parameters with slightly lowerprecision (just under 90%).
It is further linked toWikipedia, adding many named entities.
We ex-pect that our work is complementary.
Becausewe use a different approach, it would be possi-ble to merge the two if the licenses allowed usto.
However, since the CC BY-SA and CC-BY-NC-SA licenses are mutually exclusive, the twoworks cannot be combined and rereleased unlessrelevant parties can relicense the works.
There isno easy way to improve UWN beyond checkingeach and every entry, which is expensive.
An ad-12http://casta-net.jp/~kuribayashi/multi/vantage of our approach, noted above, is that wecan validate the sense matches for English and theaccuracy percolates down to all the languages.Integrating data from the most recent versionof Wiktionary can be done simply and takes afew hours.
It is therefore feasible to update thedownloadable data regularly.
Improvements in ei-ther the wordnet projects or Wiktionary (or both)can also result in improved mappings.
We furtherhope to take advantage of ongoing initiatives in theglobal wordnet grid to add new concepts not in thePrinceton WordNet, so that we can expand beyondan English-centered world view.By making the data from multiple sources eas-ily available with minimal restrictions, we hopethat it will be easier to do research that exploitslexical semantics.
In particular, we make the dataeasily accessible to the original wordnet projects,some of whom have already started to merge itinto their own resources.
We cannot check theaccuracy of data in all languages, nor, for exam-ple, check that synsets have the most appropriatelemmas associated with them.
Many languageshave their own orthographic issues (for examplea choice of scripts, or the choice to include vow-els or not).
Our automatic extraction does not dealwith these issues at all.
This kind of language spe-cific quality control is best done by the individualwordnet projects.We also consider it important to keep feedingdata back to the individual wordnet projects, asmuch of the innovative research comes from them:the class/instance distinction from PWN; the dis-tinction between rigid and non-rigid synsets fromthe Kyoto Project; domain mappings from theMultiWordNet (Pianta et al, 2002); representingorthographic variation from the Japanese Wordnet(Kuroda et al, 2011); combining close languagesfrom the Wordnet Bahasa (Nurril Hirfana et al,2011); and so on.
For all of these reasons, wedo not consider automatic extraction from/linkingto Wiktionary a substitute for building languagesspecific wordnets.Further work that this data should allow us todo include: automatically producing a list of baddata found in Wiktionary that can be used by Wik-tionary editors to correct errors; and finding gapsin wordnet by identifying senses in Wiktionarythat have a large number of translations, but fail tohave any significant alignment with existing word-net synsets.1359We currently only link through the English Wik-tionary and its translations.
It should be possible toexpand the multilingual wordnet in the same wayusing Wiktionaries in other languages, which wewould expect to improve coverage.Finally, Wiktionary contains a lot of useful in-formation we are not currently using (informationon gender, transliterations, pronunciations, alter-native spellings and so forth).
We can also thinkof the aligned definitions as a paraphrase corpusfor English.We have devoted more space than is usual fora computational linguistics paper to issues of li-censing and sustainability.
This is deliberate: wefeel papers about lexical resources should be clearabout licensing, and that it should be consideredearly on when creating new resources.
There arestrong arguments that open data leads to better sci-ence (Pederson, 2008), and it has been shown thatopen resources are cited more (Bond and Paik,2012).
In addition, how to maintain resources overtime is a major unsolved problem.
We consider itimportant that our wordnet is not just large and ac-curate but also maintainable and as accessible aspossible.6 ConclusionsWe have created an open multilingual wordnetwith over 26 languages.
It is made by combiningwordnets with open licences, data from the Uni-code Common Locale Data Repository and Wik-tionary.
Overall there are over 2 million senses for117,659 concepts, using over 1.4 million words inhundreds of languages.AcknowledgmentsWe would like to thank the following for theirhelp with the evaluation: Le Tuan Anh, Frantis?ekKratochv?
?l, Kyonghee Paik, Zina Pozen, MelanieSiegel, Stefanie Stadler, Bilyana Shuman, LilingTan and Muhammad Zulhelmy bin Mohd Rosman.ReferencesStephen Bird, Ewan Klein, and Edward Loper.2010.
Nyumon Shizen Gengo Shori [In-troduction to Natural Language Processing].O?Reilly.
(translated by Hagiwara, Nakamuraand Mizuno).W.
Black, S. Elkateb, H. Rodriguez, M. Alkhalifa,P.
Vossen, A. Pease, M. Bertran, and C. Fell-baum.
2006.
The Arabic wordnet project.
InProceedings of LREC 2006.Francis Bond and Kyonghee Paik.
2012.
A surveyof wordnets and their licenses.
In Proceedingsof the 6th Global WordNet Conference (GWC2012).
Matsue.
64?71.Jordan Boyd-Graber, Christiane Fellbaum, DanielOsherson, and Robert Schapire.
2006.
Addingdense, weighted connections to WordNet.
InProceedings of the Third Global WordNet Meet-ing.
Jeju.Thatsanee Charoenporn, Virach Sornlerlam-vanich, Chumpol Mokarat, and Hitoshi Isahara.2008.
Semi-automatic compilation of AsianWordNet.
In 14th Annual Meeting of theAssociation for Natural Language Processing,pages 1041?1044.
Tokyo.Jordi Daude, Lluis Padro, and German Rigau.2003.
Validation and tuning of Wordnet map-ping techniques.
In Proceedings of the In-ternational Conference on Recent Advancesin Natural Language Processing (RANLP?03).Borovets, Bulgaria.Gerard de Melo and Gerhard Weikum.
2009.
To-wards a universal wordnet by learning fromcombined evidence.
In Proceedings of the 18thACM Conference on Information and Knowl-edge Management (CIKM 2009), pages 513?522.
ACM, New York, NY, USA.Gerard de Melo and Gerhard Weikum.
2010.
To-wards universal multilingual knowledge bases.In Pushpak Bhattacharyya, Christiane Fell-baum, and Piek Vossen, editors, Principles,Construction, and Applications of MultilingualWordnets.
Proceedings of the 5th Global Word-Net Conference (GWC 2010), pages 149?156.Narosa Publishing, New Delhi, India.Valeria de Paiva and Alexandre Rademaker.
2012.Revisiting a Brazilian wordnet.
In Proceedingsof the 6th Global WordNet Conference (GWC2012).
Matsue.Christiane Fellbaum and Piek Vossen.
2012.
Chal-lenges for a multilingual wordnet.
Lan-guage Resources and Evaluation, 46(2):313?326.
Doi=10.1007/s10579-012-9186-z.Christine Fellbaum, editor.
1998.
WordNet: AnElectronic Lexical Database.
MIT Press.Aitor Gonzalez-Agirre, Egoitz Laparra, and Ger-man Rigau.
2012.
Multilingual central repos-1360itory version 3.0: upgrading a very large lexi-cal knowledge base.
In Proceedings of the 6thGlobal WordNet Conference (GWC 2012).
Mat-sue.Vale?rie Hanoka and Beno?
?t Sagot.
2012.
Wordnetcreation and extension made simple: A multi-lingual lexicon-based approach using wiki re-sources.
In Proceedings of LREC 2012.
Istan-bul.Chu-Ren Huang, Shu-Kai Hsieh, Jia-Fei Hong,Yun-Zhu Chen, I-Li Su, Yong-Xiang Chen, andSheng-Wei Huang.
2010.
Chinese wordnet:Design and implementation of a cross-lingualknowledge processing infrastructure.
Journal ofChinese Information Processing, 24(2):14?23.
(in Chinese).Hitoshi Isahara, Francis Bond, Kiyotaka Uchi-moto, Masao Utiyama, and Kyoko Kanzaki.2008.
Development of the Japanese WordNet.In Sixth International conference on LanguageResources and Evaluation (LREC 2008).
Mar-rakech.Toru Ishida.
2006.
Language grid: Aninfrastructure for intercultural collaboration.In IEEE/IPSJ Symposium on Applicationsand the Internet (SAINT-06), pages 96?100.URL http://langrid.nict.go.jp/file/langrid20060211.pdf, (keynote address).Kow Kuroda, Takayuki Kuribayashi, FrancisBond, Kyoko Kanzaki, and Hitoshi Isahara.2011.
Orthographic variants and multilingualsense tagging with the Japanese WordNet.
In17th Annual Meeting of the Association for Nat-ural Language Processing, pages A4?1.
Toy-ohashi.Krister Linde?n and Lauri Carlson.
2010.Finnwordnet ?
wordnet pa?finska viao?versa?ttning.
LexicoNordica ?
NordicJournal of Lexicography, 17:119?140.
InSwedish with an English abstract.John McCrae, Philipp Cimiano, and ElenaMontiel-Ponsoda.
2012.
Integrating word-net and wiktionary with lemon.
In ChristianChiarcos, Sebastian Nordhoff, and SebastianHellman, editors, Linked Data in Linguistics.Springer.Christian M. Meyer and Iryna Gurevych.
2011.What psycholinguists know about chemistry:Aligning wiktionary and wordnet for increaseddomain coverage.
In Proceedings of the 5th In-ternational Joint Conference on Natural Lan-guage Processing (IJCNLP), pages 883?892.Nurril Hirfana Mohamed Noor, Suerya Sapuan,and Francis Bond.
2011.
Creating the openWordnet Bahasa.
In Proceedings of the 25th Pa-cific Asia Conference on Language, Informationand Computation (PACLIC 25), pages 258?267.Singapore.Mortaza Montazery and Heshaam Faili.
2010.
Au-tomatic Persian wordnet construction.
In 23rdInternational conference on computational lin-guistics, pages 846?850.Roberto Navigli and Simone Paolo Ponzetto.2012.
BabelNet: The automatic construction,evaluation and application of a wide-coveragemultilingual semantic network.
Artificial Intel-ligence, 193:217?250.NIST.
2012.
Secure hash standard (shs).
Fips pub180-4, National Institute of Standards and Tech-nology.Noam Ordan and Shuly Wintner.
2007.
He-brew wordnet: a test case of aligning lexicaldatabases across languages.
International Jour-nal of Translation, 19(1):39?58.B.S Pedersen, S. Nimb, J. Asmussen, N. S?rensen,L.
Trap-Jensen, and H. Lorentzen.
2009.
Dan-Net ?
the challenge of compiling a wordnetfor Danish by reusing a monolingual dictionary.Language Resources and Evaluation.Ted Pederson.
2008.
Empiricism is not a matterof faith.
Computational Linguistics, 34(3):465?470.Emanuele Pianta, Luisa Bentivogli, and ChristianGirardi.
2002.
Multiwordnet: Developing analigned multilingual database.
In In Proceed-ings of the First International Conference onGlobal WordNet, pages 293?302.
Mysore, In-dia.Maciej Piasecki, Stan Szpakowicz, and BartoszBroda.
2009.
A Wordnet from the Ground Up.Wroclaw University of Technology Press.
URLhttp://www.plwordnet.pwr.wroc.pl/main/content/files/publications/A_Wordnet_from_the_Ground_Up.pdf, (ISBN978-83-7493-476-3).Chiew Kin Quah, Francis Bond, and TakefumiYamazaki.
2001.
Design and constructionof a machine-tractable Malay-English lexicon.1361In Asialex 2001 Proceedings, pages 200?205.Seoul.Ervin Ruci.
2008.
On the current state of Al-banet and related applications.
Technical report,University of Vlora.
(http://fjalnet.com/technicalreportalbanet.pdf).Beno?
?t Sagot and Darja Fis?er.
2008.
Buildinga free French wordnet from multilingual re-sources.
In European Language Resources As-sociation (ELRA), editor, Proceedings of theSixth International Language Resources andEvaluation (LREC?08).
Marrakech, Morocco.Sareewan Thoongsup, Thatsanee Charoenporn,Kergrit Robkop, Tan Sinthurahat, ChumpolMokarat, Virach Sornlertlamvanich, and Hi-toshi Isahara.
2009.
Thai wordnet construction.In Proceedings of The 7th Workshop on AsianLanguage Resources (ALR7), Joint conferenceof the 47th Annual Meeting of the Associationfor Computational Linguistics (ACL) and the4th International Joint Conference on NaturalLanguage Processing (IJCNLP),.
Suntec, Sin-gapore.Dan Tufis?, Dan Cristea, and Sofia Stamou.
2004.BalkaNet: Aims, methods, results and perspec-tives.
a general overview.
Romanian Journal ofInformation Science and Technology, 7(1?2):9?34.Unicode, Inc. 2012.
Unicode, Inc. license agree-ment - data files and software.
http://www.unicode.org/copyright.html.Piek Vossen, editor.
1998.
Euro WordNet.
Kluwer.Piek Vossen.
2005.
Building wordnets.http://www.globalwordnet.org/gwa/BuildingWordnets.ppt.Wikimedia.
2013.
List of wiktionaries.http://meta.wikimedia.org/w/index.php?title=Wiktionary&oldid=4729333.
(accessed on 2013-02-14).Wikipedia.
2013.
Wikipedia ?
wikipedia,the free encyclopedia.
URL http://en.wikipedia.org/w/index.php?title=Wikipedia&oldid=552515903,[Online; accessed 30-April-2013].Renjie Xu, Zhiqiang Gao, Yuzhong Qu, andZhisheng Huang.
2008.
An integrated approachfor automatic construction of bilingual Chinese-English WordNet.
In 3rd Asian Semantic WebConference (ASWC 2008), pages 302?341.1362
