Latent Variable Models for Semantic Orientations of PhrasesHiroya TakamuraPrecision and Intelligence LaboratoryTokyo Institute of Technologytakamura@pi.titech.ac.jpTakashi InuiJapan Society of the Promotion of Sciencetinui@lr.pi.titech.ac.jpManabu OkumuraPrecision and Intelligence LaboratoryTokyo Institute of Technologyoku@pi.titech.ac.jpAbstractWe propose models for semantic orienta-tions of phrases as well as classificationmethods based on the models.
Althougheach phrase consists of multiple words, thesemantic orientation of the phrase is not amere sum of the orientations of the com-ponent words.
Some words can invert theorientation.
In order to capture the prop-erty of such phrases, we introduce latentvariables into the models.
Through exper-iments, we show that the proposed latentvariable models work well in the classifi-cation of semantic orientations of phrasesand achieved nearly 82% classification ac-curacy.1 IntroductionTechnology for affect analysis of texts has recentlygained attention in both academic and industrialareas.
It can be applied to, for example, a surveyof new products or a questionnaire analysis.
Au-tomatic sentiment analysis enables a fast and com-prehensive investigation.The most fundamental step for sentiment anal-ysis is to acquire the semantic orientations ofwords: desirable or undesirable (positive or neg-ative).
For example, the word ?beautiful?
is pos-itive, while the word ?dirty?
is negative.
Manyresearchers have developed several methods forthis purpose and obtained good results (Hatzi-vassiloglou and McKeown, 1997; Turney andLittman, 2003; Kamps et al, 2004; Takamuraet al, 2005; Kobayashi et al, 2001).
One ofthe next problems to be solved is to acquire se-mantic orientations of phrases, or multi-term ex-pressions.
No computational model for semanti-cally oriented phrases has been proposed so far al-though some researchers have used techniques de-veloped for single words.
The purpose of this pa-per is to propose computational models for phraseswith semantic orientations as well as classificationmethods based on the models.
Indeed the seman-tic orientations of phrases depend on context justas the semantic orientations of words do, but wewould like to obtain the most basic orientations ofphrases.
We believe that we can use the obtainedbasic orientations of phrases for affect analysis ofhigher linguistic units such as sentences and doc-uments.The semantic orientation of a phrase is not amere sum of its component words.
Semanticorientations can emerge out of combinations ofnon-oriented words.
For example, ?light laptop-computer?
is positively oriented although neither?light?
nor ?laptop-computer?
has a positive ori-entation.
Besides, some words can invert the ori-entation of a neighboring word, such as ?low?in ?low risk?, where the negative orientation of?risk?
is inverted to a ?positive?
by the adjective?low?.
This kind of non-compositional operationhas to be incorporated into the model.
We focuson ?noun+adjective?
in this paper, since this typeof phrase contains most of interesting propertiesof phrases, such as emergence or inversion of se-mantic orientations.In order to capture the properties of semanticorientations of phrases, we introduce latent vari-ables into the models, where one random variablecorresponds to nouns and another random vari-able corresponds to adjectives.
The words thatare similar in terms of semantic orientations, suchas ?risk?
and ?mortality?
(i.e., the positive ori-entation emerges when they are ?low?
), make acluster in these models.
Our method is language-201independent in the sense that it uses only cooccur-rence data of words and semantic orientations.2 Related WorkWe briefly explain related work from two view-points: the classification of word pairs and theidentification of semantic orientation.2.1 Classification of Word PairsTorisawa (2001) used a probabilistic model toidentify the appropriate case for a pair of wordsconstituting a noun and a verb with the case ofthe noun-verb pair unknown.
Their model is thesame as Probabilistic Latent Semantic Indexing(PLSI) (Hofmann, 2001), which is a generativeprobability model of two random variables.
Tori-sawa?s method is similar to ours in that a latentvariable model is used for word pairs.
How-ever, Torisawa?s objective is different from ours.In addition, we used not the original PLSI, butits expanded version, which is more suitable forthis task of semantic orientation classification ofphrases.Fujita et al (2004) addressed the task of the de-tection of incorrect case assignment in automat-ically paraphrased sentences.
They reduced thetask to a problem of classifying pairs of a verband a noun with a case into correct or incorrect.They first obtained a latent semantic space withPLSI and adopted the nearest-neighbors method,in which they used latent variables as features.
Fu-jita et al?s method is different from ours, and alsofrom Torisawa?s, in that a probabilistic model isused for feature extraction.2.2 Identification of Semantic OrientationsThe semantic orientation classification of wordshas been pursued by several researchers (Hatzi-vassiloglou and McKeown, 1997; Turney andLittman, 2003; Kamps et al, 2004; Takamura etal., 2005).
However, no computational model forsemantically oriented phrases has been proposedto date although research for a similar purpose hasbeen proposed.Some researchers used sequences of words asfeatures in document classification according tosemantic orientation.
Pang et al (2002) used bi-grams.
Matsumoto et al (2005) used sequentialpatterns and tree patterns.
Although such patternswere proved to be effective in document classi-fication, the semantic orientations of the patternsthemselves are not considered.Suzuki et al (2006) used the Expectation-Maximization algorithm and the naive bayes clas-sifier to incorporate the unlabeled data in the clas-sification of 3-term evaluative expressions.
Theyfocused on the utilization of context informationsuch as neighboring words and emoticons.
Tur-ney (2002) applied an internet-based technique tothe semantic orientation classification of phrases,which had originally been developed for word sen-timent classification.
In their method, the num-ber of hits returned by a search-engine, with aquery consisting of a phrase and a seed word (e.g.,?phrase NEAR good?)
is used to determine theorientation.
Baron and Hirst (2004) extracted col-locations with Xtract (Smadja, 1993) and classi-fied the collocations using the orientations of thewords in the neighboring sentences.
Their methodis similar to Turney?s in the sense that cooccur-rence with seed words is used.
The three methodsabove are based on context information.
In con-trast, our method exploits the internal structure ofthe semantic orientations of phrases.Inui (2004) introduced an attribute plus/minusfor each word and proposed several rules thatdetermine the semantic orientations of phraseson the basis of the plus/minus attribute val-ues and the positive/negative attribute values ofthe component words.
For example, a rule[negative+minus=positive] determines ?low (mi-nus) risk (negative)?
to be positive.
Wilson etal.
(2005) worked on phrase-level semantic orien-tations.
They introduced a polarity shifter, whichis almost equivalent to the plus/minus attributeabove.
They manually created the list of polarityshifters.
The method that we propose in this paperis an automatic version of Inui?s or Wilson et al?sidea, in the sense that the method automaticallycreates word clusters and their polarity shifters.3 Latent Variable Models for SemanticOrientations of PhrasesAs mentioned in the Introduction, the semanticorientation of a phrase is not a mere sum of itscomponent words.
If we know that ?low risk?
ispositive, and that ?risk?
and ?mortality?, in somesense, belong to the same semantic cluster, we caninfer that ?low mortality?
is also positive.
There-fore, we propose to use latent variable models toextract such latent semantic clusters and to real-ize an accurate classification of phrases (we focus202N ZANA CN ZA CN ZA CN ZA C(a) (b) (c) (d) (e)Figure 1: Graphical representations:(a) PLSI, (b) naive bayes, (c) 3-PLSI, (d) triangle, (e) U-shaped;Each node indicates a random variable.
Arrows indicate statistical dependency between variables.
N , A,Z and C respectively correspond to nouns, adjectives, latent clusters and semantic orientations.on two-term phrases in this paper).
The modelsadopted in this paper are also used for collabora-tive filtering by Hofmann (2004).With these models, the nouns (e.g., ?risk?
and?mortality?)
that become positive by reducingtheir degree or amount would make a cluster.
Onthe other hand, the adjectives or verbs (e.g., ?re-duce?
and ?decrease?)
that are related to reductionwould also make a cluster.Figure 1 shows graphical representations of sta-tistical dependencies of models with a latent vari-able.
N , A, Z and C respectively correspond tonouns, adjectives, latent clusters and semantic ori-entations.
Figure 1-(a) is the PLSI model, whichcannot be used in this task due to the absence ofa variable for semantic orientations.
Figure 1-(b)is the naive bayes model, in which nouns and ad-jectives are statistically independent of each othergiven the semantic orientation.
Figure 1-(c) is,what we call, the 3-PLSI model, which is the 3-observable variable version of the PLSI.
We callFigure 1-(d) the triangle model, since three of itsfour variables make a triangle.
We call Figure 1-(e) the U-shaped model.
In the triangle model andthe U-shaped model, adjectives directly influencesemantic orientations (rating categories) throughthe probability P (c|az).
While nouns and adjec-tives are associated with the same set of clusters Zin the 3-PLSI and the triangle models, only nounsare clustered in the U-shaped model.In the following, we construct a probabilitymodel for the semantic orientations of phrases us-ing each model of (b) to (e) in Figure 1.
We ex-plain in detail the triangle model and the U-shapedmodel, which we will propose to use for this task.3.1 Triangle ModelSuppose that a set D of tuples of noun n, adjectivea (predicate, generally) and the rating c is given :D = {(n1, a1, c1), ?
?
?
, (n|D|, a|D|, c|D|)}, (1)where c ?
{?1, 0, 1}, for example.
This can beeasily expanded to the case of c ?
{1, ?
?
?
, 5}.
Ourpurpose is to predict the rating c for unknown pairsof n and a.According to Figure 1-(d), the generative prob-ability of n, a, c, z is the following :P (nacz) = P (z|n)P (a|z)P (c|az)P (n).
(2)Remember that for the original PLSI model,P (naz) = P (z|n)P (a|z)P (n).We use the Expectation-Maximization (EM) al-gorithm (Dempster et al, 1977) to estimate the pa-rameters of the model.
According to the theory ofthe EM algorithm, we can increase the likelihoodof the model with latent variables by iteratively in-creasing the Q-function.
The Q-function (i.e., theexpected log-likelihood of the joint probability ofcomplete data with respect to the conditional pos-terior of the latent variable) is expressed as :Q(?)
=?nacfnac?zP?
(z|nac) log P (nazc|?
), (3)where ?
denotes the set of the new parameters.fnac denotes the frequency of a tuple n, a, c in thedata.
P?
represents the posterior computed usingthe current parameters.The E-step (expectation step) corresponds tosimple posterior computation :P?
(z|nac) = P (z|n)P (a|z)P (c|az)?z P (z|n)P (a|z)P (c|az).
(4)For derivation of update rules in the M-step (max-imization step), we use a simple Lagrange methodfor this optimization problem with constraints :?z, ?n P (n|z) = 1, ?z,?a P (a|z) = 1, and?a, z, ?c P (c|az) = 1.
We obtain the followingupdate rules :P (z|n) =?ac fnacP?
(z|nac)?ac fnac, (5)203P (y|z) =?nc fnacP?
(z|nac)?nac fnacP?
(z|nac), (6)P (c|az) =?n fnacP?
(z|nac)?nc fnacP?
(z|nac).
(7)These steps are iteratively computed until conver-gence.
If the difference of the values of Q-functionbefore and after an iteration becomes smaller thana threshold, we regard it as converged.For classification of an unknown pair n, a, wecompare the values ofP (c|na) =?z P (z|n)P (a|z)P (c|az)?cz P (z|n)P (a|z)P (c|az).
(8)Then the rating category c that maximize P (c|na)is selected.3.2 U-shaped ModelWe suppose that the conditional probability of cand z given n and a is expressed as :P (cz|na) = P (c|az)P (z|n).
(9)We compute parameters above using the EM al-gorithm with the Q-function :Q(?)
=?nacfnac?zP?
(z|nac) log P (cz|na, ?).
(10)We obtain the following update rules :E stepP?
(z|nac) = P (c|az)P (z|n)?z P (c|az)P (z|n), (11)M stepP (c|az) =?n fnacP?
(z|nac)?nc fnacP?
(z|nac), (12)P (z|n) =?ac fnacP?
(z|nac)?ac fnac.
(13)For classification, we use the formula :P (c|na) =?zP (c|az)P (z|n).
(14)3.3 Other Models for ComparisonWe will also test the 3-PLSI model correspondingto Figure 1-(c).In addition to the latent models, we test a base-line classifier, which uses the posterior probabil-ity :P (c|na) ?
P (n|c)P (a|c)P (c).
(15)This baseline model is equivalent to the 2-termnaive bayes classifier (Mitchell, 1997).
The graph-ical representation of the naive bayes model is (b)in Figure 1.
The parameters are estimated as :P (n|c) = 1 + fnc|N | + fc, (16)P (a|c) = 1 + fac|A| + fc, (17)where |N | and |A| are the numbers of the wordsfor n and a, respectively.Thus, we have four different models : naivebayes (baseline), 3-PLSI, triangle, and U-shaped.3.4 Discussions on the EM computation, theModels and the TaskIn the actual EM computation, we use the tem-pered EM (Hofmann, 2001) instead of the stan-dard EM explained above, because the temperedEM can avoid an inaccurate estimation of themodel caused by ?over-confidence?
in computingthe posterior probabilities.
The tempered EM canbe realized by a slight modification to the E-step,which results in a new E-step :P?
(z|nac) =(P (c|az)P (z|n))?
?z(P (c|az)P (z|n))?
, (18)for the U-shaped model, where ?
is a positivehyper-parameter, called the inverse temperature.The new E-steps for the other models are similarlyexpressed.Now we have two hyper-parameters : inversetemperature ?, and the number of possible val-ues M of latent variables.
We determine thevalues of these hyper-parameters by splitting thegiven training dataset into two datasets (the tempo-rary training dataset 90% and the held-out dataset10%), and by obtaining the classification accuracyfor the held-out dataset, which is yielded by theclassifier with the temporary training dataset.We should also note that Z (or any variable)should not have incoming arrows simultaneouslyfrom N and A, because the model with such ar-rows has P (z|na), which usually requires an ex-cessively large memory.To work with numerical scales of the ratingvariable (i.e., the difference between c = ?1 andc = 1 should be larger than that of c = ?1and c = 0), Hofmann (2004) used also a Gaus-sian distribution for P (c|az) in collaborative filter-ing.
However, we do not employ a Gaussian, be-cause in our dataset, the number of rating classes is204only 3, which is so small that a Gaussian distribu-tion cannot be a good approximation of the actualprobability density function.
We conducted pre-liminary experiments with the model with Gaus-sians, but failed to obtain good results.
For otherdatasets with more classes, Gaussians might be agood model for P (c|az).The task we address in this paper is somewhatsimilar to the trigram prediction task, in the sensethat both are classification tasks given two words.However, we should note the difference betweenthese two tasks.
In our task, the actual answergiven two specific words are fixed as illustratedby the fact ?high+salary?
is always positive, whilethe answer for the trigram prediction task is ran-domly distributed.
We are therefore interested inthe semantic orientations of unseen pairs of words,while the main purpose of the trigram predictionis accurately estimate the probability of (possiblyseen) word sequences.In the proposed models, only the words that ap-peared in the training dataset can be classified.
Anattempt to deal with the unseen words is an in-teresting task.
For example, we could extend ourmodels to semi-supervised models by regarding Cas a partially observable variable.
We could alsouse distributional similarity of words (e.g., basedon window-size cooccurrence) to find an observedword that is most similar to the given unseen word.However, such methods would not work for thesemantic orientation classification, because thosemethods are designed for simple cooccurrence andcannot distinguish ?survival-rate?
from ?infection-rate?.
In fact, the similarity-based method men-tioned above failed to work efficiently in our pre-liminary experiments.
To solve the problem of un-seen words, we would have to use other linguisticresources such as a thesaurus or a dictionary.4 Experiments4.1 Experimental SettingsWe extracted pairs of a noun (subject) and an ad-jective (predicate), from Mainichi newspaper ar-ticles (1995) written in Japanese, and annotatedthe pairs with semantic orientation tags : positive,neutral or negative.
We thus obtained the labeleddataset consisting of 12066 pair instances (7416different pairs).
The dataset contains 4459 neg-ative instances, 4252 neutral instances, and 3355positive instances.
The number of distinct nouns is4770 and the number of distinct adjectives is 384.To check the inter-annotator agreement betweentwo annotators, we calculated ?
statistics, whichwas 0.640.
This value is allowable, but not quitehigh.
However, positive-negative disagreement isobserved for only 0.7% of the data.
In other words,this statistics means that the task of extracting neu-tral examples, which has hardly been explored, isintrinsically difficult.We employ 10-fold cross-validation to obtainthe average value of the classification accuracy.We split the dataset such that there is no overlap-ping pair (i.e., any pair in the training dataset doesnot appear in the test dataset).If either of the two words in a pair in the testdataset does not appear in the training dataset, weexcluded the pair from the test dataset since theproblem of unknown words is not in the scope ofthis research.
Therefore, we evaluate the pairs thatare not in the training dataset, but whose compo-nent words appear in the training dataset.In addition to the original dataset, which we callthe standard dataset, we prepared another datasetin order to examine the power of the latent variablemodel.
The new dataset, which we call the harddataset, consists only of examples with 17 difficultadjectives such as ?high?, ?low?, ?large?, ?small?,?heavy?, and ?light?.
1 The semantic orientationsof pairs including these difficult words often shiftdepending on the noun they modify.
Thus, thehard dataset is a subset of the standard dataset.
Thesize of the hard dataset is 4787.
Please note thatthe hard dataset is used only as a test dataset.
Fortraining, we always use the standard dataset in ourexperiments.We performed experiments with all the valuesof ?
in {0.1, 0.2, ?
?
?
, 1.0} and with all the valuesof M in {10, 30, 50, 70, 100, 200, 300, 500}, andpredicted the best values of the hyper-parameterswith the held-out method in Section 3.4.4.2 ResultsThe classification accuracies of the four methodswith ?
and M predicted by the held-out methodare shown in Table 1.
Please note that the naivebayes method is irrelevant of ?
and M .
The tableshows that the triangle model and the U-shaped1The complete list of the 17 Japanese adjectives with theirEnglish counterparts are : takai (high), hikui (low), ookii(large), chiisai (small), omoi (heavy), karui (light), tsuyoi(strong), yowai (weak), ooi (many), sukunai (few/little), nai(no), sugoi (terrific), hageshii (terrific), hukai (deep), asai(shallow), nagai (long), mizikai (short).205Table 1: Accuracies with predicted ?
and Mstandard hardaccuracy ?
M accuracy ?
MNaive Bayes 73.40 ?
?
65.93 ?
?3-PLSI 67.02 0.73 91.7 60.51 0.80 87.4Triangle model 81.39 0.60 174.0 77.95 0.60 191.0U-shaped model 81.94 0.64 60.0 75.86 0.65 48.3model achieved high accuracies and outperformedthe naive bayes method.
This result suggests thatwe succeeded in capturing the internal structureof semantically oriented phrases by way of latentvariables.
The more complex structure of the tri-angle model resulted in the accuracy that is higherthan that of the U-shaped model.The performance of the 3-PLSI method is evenworse than the baseline method.
This result showsthat we should use a model in which adjectives candirectly influence the rating category.Figures 2, 3, 4 show cross-validated accuracyvalues for various values of ?, respectively yieldedby the 3-PLSI model, the triangle model and theU-shaped model with different numbers M of pos-sible states for the latent variable.
As the figuresshow, the classification performance is sensitive tothe value of ?.
M = 100 and M = 300 are mostlybetter than M = 10.
However, this is a tradeoffbetween classification performance and trainingtime, since large values of M demand heavy com-putation.
In that sense, the U-shaped model is use-ful in many practical situations, since it achieved agood accuracy even with a relatively small M .To observe the overall tendency of errors, weshow the contingency table of classification by theU-shaped model with the predicted values of hy-perparameters, in Table 2.
As this table shows,most of the errors are caused by the difficulty ofclassifying neutral examples.
Only 2.26% of theerrors are mix-ups of the positive orientation andthe negative orientation.We next investigate the causes of errors by ob-serving those mix-ups of the positive orientationand the negative orientation.One type of frequent errors is illustrated by thepair ?food (?s price) is high?, in which the word?price?
is omitted in the actual example 2.
As inthis expression, the attribute (price, in this case) ofan example is sometimes omitted or not correctly2This kind of ellipsis often occurs in Japanese.6264666870727476788082840.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1Accuracy(%)betaM=300M=100M=10Figure 2: 3-PLSI model with standard dataset6264666870727476788082840.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1Accuracy(%)betaM=300M=100M=10Figure 3: Triangle model with standard dataset6264666870727476788082840.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1Accuracy(%)betaM=300M=100M=10Figure 4: U-shaped model with standard dataset206Table 2: Contingency table of classification result by the U-shaped modelU-shaped modelpositive neutral negative sumpositive 1856 281 69 2206Gold standard neutral 202 2021 394 2617negative 102 321 2335 2758sum 2160 2623 2798 7581identified.
To tackle these examples, we will needmethods for correctly identifying attributes andobjects.
Some researchers are starting to work onthis problem (e.g., Popescu and Etzioni (2005)).We succeeded in addressing the data-sparsenessproblem by introducing a latent variable.
How-ever, this problem still causes some errors.
Pre-cise statistics cannot be obtained for infrequentwords.
This problem will be solved by incorporat-ing other resources such as thesaurus or a dictio-nary, or combining our method with other methodsusing external wider contexts (Suzuki et al, 2006;Turney, 2002; Baron and Hirst, 2004).4.3 Examples of Obtained ClustersNext, we qualitatively evaluate the proposed meth-ods.
For several clusters z, we extract the wordsthat occur more than twice in the whole datasetand are in top 50 according to P (z|n).
The modelused here as an example is the U-shaped model.The experimental settings are ?
= 0.6 and M =60.
Although some elements of clusters are com-posed of multiple words in English, the originalJapanese counterparts are single words.Cluster 1 trouble, objection, disease, complaint, anx-iety, anamnesis, relapseCluster 2 risk, mortality, infection rate, onset rateCluster 3 bond, opinion, love, meaning, longing, willCluster 4 vote, application, topic, supporterCluster 5 abuse, deterioration, shock, impact, burdenCluster 6 deterioration, discrimination, load, abuseCluster 7 relative importance, degree of influence,number, weight, sense of belonging, wave,reputationThese obtained clusters match our intuition.
Forexample, in cluster 2 are the nouns that are neg-ative when combined with ?high?, and positivewhen combined with ?low?.
In fact, the posteriorprobabilities of semantic orientations for cluster 2are as follows :P (negative|high, cluster 2) = 0.995,P (positive|low, cluster 2) = 0.973.With conventional clustering methods based onthe cooccurrence of two words, cluster 2 wouldinclude the words resulting in the opposite orien-tation, such as ?success rate?.
We succeeded inobtaining the clusters that are suitable for our task,by incorporating the new variable c for semanticorientation in the EM computation.5 ConclusionWe proposed models for phrases with semanticorientations as well as a classification methodbased on the models.
We introduced a latent vari-able into the models to capture the properties ofphrases.
Through experiments, we showed thatthe proposed latent variable models work wellin the classification of semantic orientations ofphrases and achieved nearly 82% classification ac-curacy.
We should also note that our method islanguage-independent although evaluation was ona Japanese dataset.We plan next to adopt a semi-supervised learn-ing method in order to correctly classify phraseswith infrequent words, as mentioned in Sec-tion 4.2.
We would also like to extend our methodto 3- or more term phrases.
We can also use theobtained latent variables as features for anotherclassifier, as Fujita et al (2004) used latent vari-ables of PLSI for the k-nearest neighbors method.One important and promising task would be theuse of semantic orientations of words for phraselevel classification.ReferencesFaye Baron and Graeme Hirst.
2004.
Collocationsas cues to semantic orientation.
In AAAI SpringSymposium on Exploring Attitude and Affect in Text:Theories and Applications.Arthur P. Dempster, Nan M. Laird, and Donald B. Ru-bin.
1977.
Maximum likelihood from incompletedata via the EM algorithm.
Journal of the Royal Sta-tistical Society Series B, 39(1):1?38.207Atsushi Fujita, Kentaro Inui, and Yuji Matsumoto.2004.
Detection of incorrect case assignments in au-tomatically generated paraphrases of Japanese sen-tences.
In Proceedings of the 1st International JointConference on Natural Language Processing (IJC-NLP), pages 14?21.Vasileios Hatzivassiloglou and Kathleen R. McKeown.1997.
Predicting the semantic orientation of ad-jectives.
In Proceedings of the Thirty-Fifth AnnualMeeting of the Association for Computational Lin-guistics and the Eighth Conference of the EuropeanChapter of the Association for Computational Lin-guistics, pages 174?181.Thomas Hofmann.
2001.
Unsupervised learningby probabilistic latent semantic analysis.
MachineLearning, 42:177?196.Thomas Hofmann.
2004.
Latent semantic models forcollaborative filtering.
ACM Transactions on Infor-mation Systems, 22:89?115.Takashi Inui.
2004.
Acquiring Causal Knowledge fromText Using Connective Markers.
Ph.D. thesis, Grad-uate School of Information Science, Nara Instituteof Science and Technology.Jaap Kamps, Maarten Marx, Robert J. Mokken, andMaarten de Rijke.
2004.
Using wordnet to measuresemantic orientation of adjectives.
In Proceedingsof the 4th International Conference on LanguageResources and Evaluation (LREC 2004), volume IV,pages 1115?1118.Nozomi Kobayashi, Takashi Inui, and Kentaro Inui.2001.
Dictionary-based acquisition of the lexicalknowledge for p/n analysis (in Japanese).
In Pro-ceedings of Japanese Society for Artificial Intelli-gence, SLUD-33, pages 45?50.Mainichi.
1995.
Mainichi Shimbun CD-ROM version.Shotaro Matsumoto, Hiroya Takamura, and ManabuOkumura.
2005.
Sentiment classification usingword sub-sequences and dependency sub-trees.
InProceedings of the 9th Pacific-Asia Conference onKnowledge Discovery and Data Mining (PAKDD-05), pages 301?310.Tom M. Mitchell.
1997.
Machine Learning.
McGrawHill.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
sentiment classification usingmachine learning techniques.
In Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing (EMNLP?02), pages 79?86.Ana-Maria Popescu and Oren Etzioni.
2005.
Ex-tracting product features and opinions from re-views.
In Proceedings of joint conference on Hu-man Language Technology / Conference on Em-pirical Methods in Natural Language Processing(HLT/EMNLP?05), pages 339?346.Frank Z. Smadja.
1993.
Retrieving collocationsfrom text: Xtract.
Computational Linguistics,,19(1):143?177.Yasuhiro Suzuki, Hiroya Takamura, and Manabu Oku-mura.
2006.
Application of semi-supervised learn-ing to evaluative expression classification.
In Pro-ceedings of the 7th International Conference on In-telligent Text Processing and Computational Lin-guistics (CICLing-06), pages 502?513.Hiroya Takamura, Takashi Inui, and Manabu Okumura.2005.
Extracting semantic orientations of words us-ing spin model.
In Proceedings 43rd Annual Meet-ing of the Association for Computational Linguistics(ACL?05), pages 133?140.Kentaro Torisawa.
2001.
An unsuperveised methodfor canonicalization of Japanese postpositions.
InProceedings of the 6th Natural Language Process-ing Pacific Rim Symposium (NLPRS 2001), pages211?218.Peter D. Turney and Michael L. Littman.
2003.
Mea-suring praise and criticism: Inference of semanticorientation from association.
ACM Transactions onInformation Systems, 21(4):315?346.Peter D. Turney.
2002.
Thumbs up or thumbs down?semantic orientation applied to unsupervised clas-sification of reviews.
In Proceedings 40th AnnualMeeting of the Association for Computational Lin-guistics (ACL?02), pages 417?424.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.2005.
Recognizing contextual polarity in phrase-level sentiment analysis.
In Proceedings of jointconference on Human Language Technology / Con-ference on Empirical Methods in Natural LanguageProcessing (HLT/EMNLP?05), pages 347?354.208
