BioNLP 2007: Biological, translational, and clinical language processing, pages 113?120,Prague, June 2007. c?2007 Association for Computational LinguisticsAutomatically Restructuring Practice Guidelines using the GEM DTDAmanda Bouffier                       Thierry PoibeauLaboratoire d?Informatique de Paris-NordUniversit?
Paris 13 and CNRS UMR 703099, av.
J.-B.
Cl?ment ?
F-93430 Villetaneusefirstname.lastname@lipn.univ-paris13.frAbstractThis paper describes a system capable ofsemi-automatically filling an XML templatefrom free texts in the clinical domain (prac-tice guidelines).
The XML template includessemantic information not explicitly encodedin the text (pairs of conditions and ac-tions/recommendations).
Therefore, there isa need to compute the exact scope of condi-tions over text sequences expressing the re-quired actions.
We present a system devel-oped for this task.
We show that it yieldsgood performance when applied to theanalysis of French practice guidelines.1 IntroductionDuring the past years, clinical practices have con-siderably evolved towards standardization and ef-fectiveness.
A major improvement is the develop-ment of practice guidelines (Brownson et al, 2003).However, even if widely distributed to hospitals,doctors and other medical staff, clinical practiceguidelines are not routinely fully exploited1.
Thereis now a general tendency to transfer these guide-lines to electronic devices (via an appropriate XMLformat).
This transfer is justified by the assumptionthat electronic documents are easier to browse thanpaper documents.However, migrating a collection of texts to XMLrequires a lot of re-engineering.
More precisely, itmeans analyzing the full set of textual documentsso that they can fit with strict templates, as requiredeither by XML schemas or DTD (document typedefinition).
Unfortunately, most of the time, the1 See (Kolata, 2004).
This newspaper article is a good exampleof the huge social impact of this research area.semantic blocks of information required by theXML model are not explicitly marked in the origi-nal text.
These blocks of information correspond todiscourse structures.This problem has thus renewed the interest forthe recognition and management of discourse struc-tures, especially for technical domains.
In thisstudy, we show how technical documents belong-ing to a certain domain (namely, clinical practiceguidelines) can be semi-automatically structuredusing NLP techniques.
Practice guidelines describebest practices with the aim of guiding decisions andcriteria in specific areas of healthcare, as definedby an authoritative examination of current evidence(evidence-based medicine, see Wikipedia orBrownson et al, 2003).The Guideline Elements Model (GEM) is anXML-based guideline document model that canstore and organize the heterogeneous informationcontained in practice guidelines (Schiffman, 2000).It is intended to facilitate translation of natural lan-guage guideline documents into a format that canbe processed by computers.
The main element ofGEM, knowledge component, contains the mostuseful information, especially sequences of condi-tions and recommendations.
Our aim is thus toformat these documents which have been writtenmanually without any precise model, according tothe GEM DTD (see annex A).The organization of the paper is as follows: first,we present the task and some previous approaches(section 2).
We then describe the different process-ing steps (section 3) and the implementation (sec-tion 4).
We finish with the presentation of someresults (section 5), before the conclusion (section 6).1132 Document Restructuring: the Case ofPractice GuidelinesAs we have previously seen, practice guidelines arenot routinely fully exploited.
One reason is thatthey are not easily accessible to doctors duringconsultation.
Moreover, it can be difficult for thedoctor to find relevant pieces of information fromthese guides, even if they are not very long.
Toovercome these problems, national health agenciestry to promote the electronic distribution of theseguidelines (so that a doctor could check recom-mendations directly from his computer).2.1 Previous WorkSeveral attempts have already been made to im-prove the use of practice guidelines: for exampleknowledge-based diagnostic aids can be derivedfrom them (e.g.
S?roussi et al, 2001).GEM is an intermediate document model, be-tween pure text (paper practice guidelines) andknowledge-based models like GLIF (Peleg et al,2000) or EON (Tu and Musen, 2001).
GEM is thusan elegant solution, independent from any theory orformalisms, but compliant with other frameworks.GEM Cutter (http://gem.med.yale.edu/) is atool aimed at aiding experts to fill the GEM DTDfrom texts.
However, this software is only an inter-face allowing the end-user to perform the taskthrough a time-consuming cut-and-paste process.The overall process described in Shiffman et al(2004) is also largely manual, even if it is an at-tempt to automate and regularize the translationprocess.The main problem in the automation of thetranslation process is to identify that a list of rec-ommendations expressed over several sentences isunder the scope of a specific condition (conditionsmay refer to a specific pathology, a specific kind ofpatients, temporal restrictions, etc.).
However, pre-vious approaches have been based on the analysisof isolated sentences.
They do not compute the ex-act scope of conditional sequences (Georg andJaulent, 2005): this part of the work still has to bedone by hand.Our automatic approach relies on work done inthe field of discourse processing.
As we have seenin the introduction, the most important sequencesof text to be tagged correspond to discourse struc-tures (conditions, actions ?).
Although most re-searchers agree that a better understanding of textstructure and text coherence could help extractknowledge, descriptive frameworks like the onedeveloped by Halliday and Hasan2 are poorly for-malized and difficult to apply in practice.Some recent works have proposed more opera-tional descriptions of discourse structures (P?ry-Woodley, 1998).
Several authors (Halliday andMatthiessen, 2004; Charolles, 2005) have investi-gated the use of non-lexical cues for discourseprocessing (e.g temporal adverbials like ?in 1999?
).These adverbials introduce situation frames in anarrative discourse, that is to say a ?period?
in thetext which is dependent from the adverbial.We show in this study that condition sequencesplay the same role in practice guidelines: theirscope may run over several dependent clauses(more precisely, over a set of several recommenda-tions).
Our plan is to automatically recognize theseusing surface cues and processing rules.2.2 Our ApproachOur aim is to semi-automatically fill a GEM tem-plate from existing guidelines: the algorithm isfully automatic but the result needs to be validatedby experts to yield adequate accuracy.
Our systemtries to compute the exact scope of conditional se-quences.
In this paper we apply it to the analysis ofseveral French practice guidelines.The main aim of the approach is to go from atextual document to a GEM based document, asshown on Figure 1 (see also annex A).
We focus onconditions (including temporal restrictions) andrecommendations since these elements are ofparamount importance for the task.
They are espe-cially difficult to deal with since they require toaccurately compute the scope of conditions.The example on figure 1 is complex since it con-tains several levels of overlapping conditions.
Weobserve a first opposition (Chez le sujet non immu-nod?prim?
/ chez le sujet immunod?prim??
Con-cerning the non-immuno-depressed patient / Con-cerning the immuno-depressed patient?)
but a sec-ond condition interferes in the scope of this firstlevel (En cas d?aspect normal de la muqueuse il?-ale?
If the ileal mucus seems normal?).
The taskinvolves recognizing these various levels of condi-tions in the text and explicitly representing themthrough the GEM DTD.2 See ?the text-forming component in the linguistic system?
inHalliday and Hasan (1976:23).114Figure 1.
From the text to GEMWhat is obtained in the end is a tree where theleaves are recommendations and the branchingnodes correspond to the constraints on conditions.2.3 DataWe analyzed 18 French practice guidelines pub-lished by French national health agency (ANAES,Agence Nationale d?Accr?ditation et d?Evaluationen Sant?
and AFSSAPS, Agence Francaise de S?-curit?
Sanitaire des Produits de Sant?)
between2000 and 2005.
These practice guidelines focus ondifferent pathologies (e.g.
diabetes, high bloodpressure, asthma etc.)
as well as with clinicalexamination processes (e.g.
digestive endoscopy).amination processes (e.g.
digestive endoscopy).The data are thus homogeneous, and is about 250pages long (150,000+ words).
Most of these prac-tice guidelines are publicly available at:http://www.anaes.fr or http://affsaps.sante.fr.
Similar documents have been published inEnglish and other languages; the GEM DTD islanguage independent.3 Processing StepsSegmenting a guideline to fill an XML template isa complex process involving several steps.
We de-scribe here in detail the most important steps(mainly the way the scope of conditional sequencesis computed), and will only give a brief overviewof the pre-processing stages.3.1 OverviewA manual study of several French practice guide-lines revealed a number of trends in the data.
Weobserved that there is a default structure in theseguidelines that may help segmenting the text accu-rately.
This default segmentation corresponds to ahighly conventionalized writing style used in thedocument (a norm).
For example, the location ofconditions is especially important: if a conditionoccurs at the opening of a sequence (a paragraph, asection?
), its scope is by default the entire follow-ing text sequence.
If the condition is included in thesequence (inside a sentence), its default scope isrestricted to the current sentence (Charolles, 2005for similar observations on different text types).This default segmentation can be revised if somelinguistic cues suggest another more accurate seg-mentation (violation of the norm).
We make use ofHalliday?s theory of text cohesion (Halliday andHasan, 1976).
According to this theory, some ?co-hesion cues?
suggest extending the default segmen-tation while some others suggest limiting the scopeof the conditional sequence (see section 3.4).3.2 Pre-processing (Cue Identification)The pre-processing stage concerns the analysis ofrelevant linguistic cues.
These cues vary in nature:they can be based either on the material structure orthe content of texts.
We chose to mainly focus ontask-independent knowledge so that the method isportable, as far as possible (we took inspirationfrom Halliday and Matthiessen?s introduction tofunctional grammar, 2004).
Some of these cues<recommandation><decision.variable>Chez le sujet non immunod?prim?</decsion.variable><decision.variable>en cas d'aspect macroscopique nor-mal de la muqueuse colique </decison.variable><action> des biopsies coliques nombreuses et ?tag?essont recommand?es (?)
</action><action>Les biopsies isol?es sont insuffisantes(..)</action><action>L?exploration de l?il?on terminal est ?gale-ment recommand?e</action></recommandation><recommandation><decision.variable>Chez le sujet non immunod?prim?</decsion.variable><decision.variable>en cas d'aspect macroscopique nor-mal de la muqueuse colique </decison.variable><decision.variable>En cas d'aspect normal de la mu-queuse il?ale</decision.variable><action>la r?alisation de biospsies n'est pas syst?ma-tique</action></recommandation><recommandation<decision.variable>Chez le sujet immunod?pri-m?</decision.variable><action> il est n?cessaire de r?aliser des biopsiessyst?matiques(?
)</action></recommandation>Chez le sujet non immunod?prim?, en cas d'as-pect macroscopique normal de la muqueuse co-lique, des biopsies coliques nombreuses et ?tag?essont recommand?es (?).
Les biopsies isol?es sontinsuffisantes (?
).L'exploration de l'il?on terminal est ?galement re-command?e (grade C).
En cas d'aspect normal dela muqueuse il?ale (?
), la r?alisation de biospsiesn'est pas syst?matique (accord professionnel).Chez le sujet immunod?prim?, il est n?cessaire der?aliser des biopsies syst?matiques (?
)115(especially connectors and lexical cues) can beautomatically captured by machine learning meth-ods.Material structure cues.
These features include therecognition of titles, section, enumerations andparagraphs.Morpho-syntactic cues.
Recommendations are notexpressed in the same way as conditions from amorpho-syntactic point of view.
We take the fol-lowing features into account:?
Part of speech tags.
For example recommand?should be a verb and not a noun, even if theform is ambiguous in French;?
Tense and mood of the verb.
Present and futuretenses are relevant, as well as imperative andconditional moods.
Imperative and future al-ways have an injunctive value in the texts.
In-junctive verbs (see lexical cues) lose their in-junctive property when used in a past tense.Anaphoric cues.
A basic and local analysis of ana-phoric elements is performed.
We especially fo-cused on expressions such as dans ce cas, dans lesN cas pr?c?dents (in this case, in the n precedingcases?)
which are very frequent in clinical docu-ments.
The recognition of such expressions isbased on a limited set of possible nouns that oc-curred in context, together with specific constraints(use of demonstrative pronouns, etc).Conjunctive cues (discourse connectors).
Condi-tions are mainly expressed through conjunctivecues.
The following forms are especially interest-ing: forms prototypically expressing conditions (si,en cas de, dans le cas o??
if, in case of?
); Formsexpressing the locations of some elements (chez, enpr?sence de... in presence of?
); Forms expressinga temporal frame (lorsque, au moment o?, avantde?
when, before?
)Lexical cues.
Recommendations are mainly ex-pressed through lexical cues.
We have observedforms prototypically expressing recommendations(recommander, prescrire, ?
recommend, pre-scribe), obligations (devoir, ?
shall) or options(pouvoir, ?
can).
Most of these forms are highlyambiguous but can be automatically acquired froman annotated corpus.
Some expressions from themedical domains can be automatically extractedusing a terminology extractor (we use Yatea, seesection 4, ?Implementation?
).3.3 Basic SegmentationA basic segment corresponds to a text sequenceexpressing either a condition or a recommendation.It is most of the time a sentence, or a propositioninside a sentence.Some of the features described in the previoussection may be highly ambiguous.
For this reasonbasic segmentation is rarely done according to asingle feature, but most of the time according to abundle of features acquired from a representativecorpus.
For example, if a text sequence contains aninjunctive verb with an infinitive form at the begin-ning of a sentence, the whole sequence is typed asaction.
The relevant sets of co-occurring featuresare automatically derived from a set of annotatedpractice guidelines, using the chi-square test to cal-culate the dissimilarity of distributions.After this step, the text is segmented into typedbasic sequences expressing either a recommenda-tion or a condition (the rest of the text is leftuntagged).3.4 Computing Frames and ScopesAs for quantifiers, a conditional element may havea scope (a frame) that extends over several basicsegments.
It has been shown by several authors(Halliday and Matthiessen, 2004; Charolles, 2005)working on different types of texts that conditionsdetached from the sentence have most of the time ascope beyond the current sentence whereas condi-tions included in a sentence (but not in the begin-ning of a sentence) have a scope which is limited tothe current sentence.
Accordingly we propose atwo-step strategy: 1) the default segmentation isdone, and 2) a revision process is used to correctthe main errors caused by the default segmentation(corresponding to the norm).Default SegmentationWe propose a strategy which makes use of the no-tion of default.
By default:1.
Scope of a heading goes up to the next head-ing;2.
Scope of an enumeration?s header covers allthe items of the enumeration ;3.
If a conditional sequence is detached (in thebeginning of a paragraph or a sentence), itsscope is the whole paragraph;4.
If the conditional sequence is included in asentence, its scope is equal to the currentsentence.116Cases 3 and 4 cover 50-80% of all the cases, de-pending on the practice guidelines used.
However,this default segmentation is revised and modifiedwhen a linguistic cue is a continuation mark withinthe text or when the default segmentation seems tocontradict some cohesion cue.Revising the Default SegmentationThere are two cases which require revising the de-fault segmentation: 1) when a cohesion mark indi-cates that the scope is larger than the default unit;2) when a rupture mark indicates that the scope issmaller.
We only have room for two examples,which, we hope, give a broad idea of this process.1) Anaphoric relations are strong cues of textcoherence: they usually indicate the continuation ofa frame after the end of its default boundaries.Figure 2.
The last sentence introduced by dans lesdeux cas is under the scope of the conditions intro-duced by lorsque3.In Figure 2, the expression dans les deux cas (inthe two cases?)
is an anaphoric mark referring tothe two previous utterances.
The scope of the con-ditional segment introduced by lorsque (that wouldnormally be limited to the sentence it appears in) isthus extended accordingly.2) Other discourse cues are strong indicatorsthat a frame must be closed before its defaultboundaries.
These cues may indicate some contras-tive, corrective or adversative information (cepen-dant, en revanche?
however).
Justifications cues(en effet, en fait ?
in effect) also pertain to thisclass since a justification is not part of the actionelement of the GEM DTD.Figure 3 is a typical example.
The linguistic cueen effet (in effect) closes the frame introduced by3 In figures 2 and 3, bold and grey background are used onlyfor sake of clarity; actual documents are made of text withoutany formatting.Figure 3.
The last sentence contains a justification cue(en effet) which limits the scope of the condition in thepreceding sentence.Chez les patients ayant initialement...(<1g/l) sincethis sequence should fill the explanation elementof the GEM DTD and is not an action element.4 ImplementationAccurate discourse processing requires a lot of in-formation ranging from lexical cues to complex co-occurrence of different features.
We chose to im-plement these in a classic blackboard architecture(Englemore and Morgan, 1988).
The advantages ofthis architecture for our problem are easy to grasp:each linguistic phenomenon can be treated as anindependent agent; inference rules can also becoded as specific agents, and a facilitator controlsthe overall process.Basic linguistic information is collected by a setof modules called ?linguistic experts?.
Each mod-ule is specialized in a specific phenomenon (textstructure recognition, part-of-speech tagging, termspotting, etc.).
The text structure and text format-ting elements are recognized using Perl scripts.Linguistic elements are encoded in local grammars,mainly implemented as finite-state transducers(Unitex 4 ).
Other linguistic features are obtainedusing publicly available software packages, e.g.
apart-of-speech tagger (Tree Tagger5) and a termextractor (Yatea6), etc.
Each linguist expert is en-capsulated and produces annotations that are storedin the database of facts, expressed in Prolog (wethus avoid the problem of overlapping XML tags,which are frequent at this stage).
These annotationsare indexed according to the textual clause theyappear in, but linear ordering of the text is not cru-4 http://www-igm.univ-mlv.fr/~unitex/5 http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/DecisionTreeTagger.html6 http://www-lipn.univ-paris13.fr/~hamon/YaTeAChez les patients ayant initialement une concentra-tion tr?s ?lev?e de LDL-cholest?rol, et notammentchez les patients ?
haut risque dont la cible th?ra-peutique est basse (<1g/l), le prescripteur doit garder?
l?esprit que la prescription de statine ?
fortes doses ouen association n?cessite une prise en compte au cas parcas du rapport b?n?fice/risque et ne doit jamais ?tre sys-t?matique.
En effet, les fortes doses de statines et lesbith?rapies n?ont pas fait l?objet ?
ce jour d?une ?valuationsuffisante dans ces situations.
(Prise en charge th?rapeutique du patient dyslipid?mique, 2005,p4)L?indication d?une insulinoth?rapie est recommand?elorsque l?HbA1c est > 8%, sur deux contr?les suc-cessifs sous l?association de sulfamides/metformine?
posologie optimale.
Elle est laiss?e ?
l?appr?ciation parle clinicien du rapport b?n?fices/inconv?nients del?insulinoth?rapie lorsque l?HbA1c est comprise entre6,6% et 8% sous la m?me association.
Dans les deuxcas, la di?t?tique aura au pr?alable ?t?
r?
?valu?e et unfacteur intercurrent de d?compensation aura ?t?
recher-ch?e (accord professionnel).Strat?gie de prise en charge du patient diab?tique de type 2 ?l?exclusion de la prise en charge des complications (2000)117cial for further processing steps since the systemmainly looks for co-occurrences of different cues.The resulting set of annotations constitutes the?working memory?
of the system.Another set of experts then combine the initialdisseminated knowledge to recognize basic seg-ments (section 3.3) and to compute scopes andframes (section 3.4).
These experts form the ?infer-ence engine?
which analyzes information stored inthe working memory and adds new knowledge tothe database.
Even when linear order is irrelevantfor the inference process new information is in-dexed with textual clauses, to enable the system toproduce the original text along with annotation.A facilitator helps to determine which experthas the most information needed to solve the prob-lem.
It is the facilitator that controls, for example,the application of default rules and the revision ofthe default segmentation.
It controls the chalk, me-diating among experts competing to write on theblackboard.
Finally, an XML output is producedfor the document, corresponding to a candidateGEM version of the document (no XML tags over-lap in the output since we produce an instance ofthe GEM DTD; all potential remaining conflictsmust have been solved by the supervisor).
Toachieve optimal accuracy this output is validatedand possibly modified by domain experts.5 EvaluationThe study is based on a corpus of 18 practiceguidelines in French (several hundreds of frames),with the aid of domain experts.
We evaluated theapproach on a subset of the corpus that has notbeen used for training.5.1 Evaluation CriteriaIn our evaluation, a sequence is considered correctif the semantics of the sequence is preserved.
Forexample Chez l?ob?se non diab?tique (accordprofessionnel) (In the case of an obese personwithout any diabetes (professional approval)),recognition is correct even if professional approvalis not stricto sensu part of the condition.
On theother hand, Chez l?ob?se (In the case of an obeseperson) is incorrect.
The same criteria are appliedfor recommendations.We evaluate the scope of condition sequences bymeasuring whether each recommendation is linkedwith the appropriate condition sequence or not.5.2 Manual Annotation and Inter-annotatorAgreementThe data is evaluated against practice guidelinesmanually annotated by two annotators: a domainexpert (a doctor) and a linguist.
In order to evaluateinter-annotator agreement, conditions and actionsare first extracted from the text.
The task of thehuman annotators is then to (manually) build a tree,where each action has to be linked with a condi-tion.
The output can be represented as a set of cou-ples (condition ?
actions).
In the end, we calculateaccuracy by comparing the outputs of the two an-notators (# of common couples).Inter-annotator agreement is high (157 nodes outof 162, i.e.
above .96 agreement).
This degree ofagreement is encouraging.
It differs from previousexperiments, usually done using more heterogene-ous data, for example, narrative texts.
Temporals(like ?in 1999?)
are known to open a frame butmost of the time this frame has no clear boundary.Practice guidelines should lead to actions by thedoctor and the scope of conditions needs to be clearin the text.In our experiment, inter-annotator agreement ishigh, especially considering that we required anagreement between an expert and non-expert.
Wethus make the simplified assumption that the scopeof conditions is expressed through linguistic cueswhich do not require, most of the time, domain-specific or expert knowledge.
Yet the very fewcases where the annotations were in disagreementwere clearly due to a lack of domain knowledge bythe non-expert.5.3 Evaluation of the Automatic Recognitionof Basic SequencesThe evaluation of basic segmentation gives the fol-lowing results for the condition and the recommen-dation sequences.
In the table, P is precision; R isrecall; P&R is the harmonic mean of precision andrecall  (P&R = (2*P*R) / (P+R), corresponding to aF-measure with a ?
factor equal to 1).Conditions:Without domainknowledgeWith domainknowledgeP 1 1R .83 .86P&R .91 .92118Recommendations:Without domainknowledgeWith domainknowledgeP 1 1R .94 .95P&R .97 .97Results are high for both conditions and recom-mendations.The benefit of domain knowledge is not evidentfrom overall results.
However, this information isuseful for the tagging of titles corresponding topathologies.
For example, the title Hypertensionart?rielle (high arterial blood pressure) is equiva-lent to a condition introduced by in case of?
It isthus important to recognize and tag it accurately,since further recommendations are under the scopeof this condition.
This cannot be done without do-main-specific knowledge.The number of titles differs significantly fromone practice guideline to another.
When the num-ber is high, the impact on the performance can bestrong.
Also, when several recommendations aredependent on the same condition, the system mayfail to recognize the whole set of recommendations.Finally, we observed that not all conditions andrecommendations have the same importance from amedical point of view ?
however, it is difficult toquantify this in the evaluation.5.4 Evaluation of the Automatic Recognitionof the Scope of ConditionsThe scope of conditions is recognized with accu-racy above .7 (we calculated this score using thesame method as for inter-annotator agreement, seesection 5.2).This result is encouraging, especially consider-ing the large number of parameters involved in dis-course processing.
In most of successful cases thescope of a condition is recognized by the defaultrule (default segmentation, see section 3.4).
How-ever, some important cases are solved due to thedetection of cohesion or boundary cue (especiallytitles).The system fails to recognize extended scopes(beyond the default boundary) when the cohesionmarks correspond to lexical items which are related(synonyms, hyponyms or hypernyms) or to com-plex anaphora structures (nominal anaphora; hypo-nyms and hypernyms can be considered as a spe-cial case of nominal anaphora).
Resolving theserarer complex cases would require ?deep?
domainknowledge which is difficult to implement usingstate-of-art techniques.6 ConclusionWe have presented in this paper a system capableof performing automatic segmentation of clinicalpractice guidelines.
Our aim was to automaticallyfill an XML DTD from textual input.
The system isable to process complex discourse structures and tocompute the scope of conditional segments span-ning several propositions or sentences.
We showthat inter-annotator agreement is high for this taskand that the system performs well compared toprevious systems.
Moreover, our system is the firstone capable of resolving the scope of conditionsover several recommendations.As we have seen, discourse processing is diffi-cult but fundamental for intelligent informationaccess.
We plan to apply our model to other lan-guages and other kinds of texts in the future.
Thetask requires at least adapting the linguistic com-ponents of our system (mainly the pre-processingstage).
More generally, the portability of discourse-based systems across languages is a challengingarea for the future.ReferencesR.C.
Brownson, E.A.
Baker, T.L.
Leet, K.N.
Gillespie.2003.
Evidence-based public health.
Oxford Univer-sity Press.
Oxford, UK.M.
Charolles.
2005.
?Framing adverbials and their rolein discourse cohesion: from connexion to forwardlabeling?.
Papers of the Symposium on theExploration and Modelling of Meaning (Sem?05),Biarritz.
France.R.
Englemore and T. Morgan.
1988.
Blackboard Sys-tems.
Addison-Wesley, USA.G.
Georg and M.-C. Jaulent.
2005.
?An Environment forDocument Engineering of Clinical Guidelines?.
Pro-ceedings of the American Medical Informatics Asso-ciation.
Washington DC.
USA.
pp.
276?280.M.A.K.
Halliday and R. Hasan.
1976.
Cohesion in Eng-lish.
Longman.
Harlow, UK.M.A.K.
Halliday and C. Matthiessen.
2004.
Introductionto functional grammar (3rd ed.).
Arnold.
London, UK.G.
Kolata.
2004.
?Program Coaxes Hospitals to SeeTreatments Under Their Noses?.
The New YorkTimes.
December 25, 2004.119M.
Peleg, A. Boxwala, O. Ogunyemi, Q. Zeng, S. Tu, R.Lacson, E. Bernstam, N. Ash, P. Mork, L. Ohno-Machado, E. Shortliffe and R. Greenes.
2000.?GLIF3: The Evolution of a Guideline Representa-tion Format?.
In Proceedings of the American Medi-cal Informatics Association.
pp.
645?649.M-P. P?ry-Woodley.
1998.
?Signalling in written text: acorpus-based approach?.
In M. Stede, L. Wanner &E. Hovy (Eds.
), Proceeding of te Coling ?98 Work-shop on Discourse Relations and Discourse Markers,pp.
79?85B.
S?roussi, J.  Bouaud, H.
Dr?au., H.
Falcoff., C. Riou.,M.
Joubert., G. Simon, A. Venot.
2001.
?ASTI :  AGuideline-based drug-ordering system for primarycare?.
In Proceedings MedInfo.
pp.
528?532.R.N.
Shiffman, B.T.
Karras, A. Agrawal, R. Chen, L.Marenco, S. Nath.
2000.
?GEM: A proposal for amore comprehensive guideline document model us-ing XML?.
Journal of the American Medical Infor-matics Assoc.
n?7(5).
pp.
488?498.R.N.
Shiffman, M. George, M.G.
Essaihi and E. Thorn-quist.
2004.
?Bridging the guideline implementationgap: a systematic, document-centered approach toguideline implementation?.
In Journal of the Ameri-can Medical Informatics Assoc.
n?11(5).
pp.
418?426.S.
Tu and M. Musen.
2001.
?Modeling data and knowl-edge in the EON Guideline Architecture?.
InMedinfo.
n?10(1).
pp.
280?284.Annex A. Screenshots of the systemFigure A1.
A practice guideline once analyzed by the system (Traitement m?dicamenteux du diab?te detype 2, AFSSAPS-HAS, nov. 2006)Figures A2 and A3.
The original text, an the XML GEM template instanciated from the text120
