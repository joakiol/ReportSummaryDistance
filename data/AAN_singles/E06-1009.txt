Information Presentation in Spoken Dialogue SystemsVera DembergInstitute for Natural Language Processing (IMS)University of StuttgartD-70174 StuttgartV.Demberg@gmx.deJohanna D. MooreSchool of InformaticsUniversity of EdinburghEdinburgh, EH8 9LW, GBJ.Moore@ed.ac.ukAbstractTo tackle the problem of presenting alarge number of options in spoken dia-logue systems, we identify compelling op-tions based on a model of user preferences,and present tradeoffs between alternativeoptions explicitly.
Multiple attractive op-tions are structured such that the user cangradually refine her request to find theoptimal tradeoff.
We show that our ap-proach presents complex tradeoffs under-standably, increases overall user satisfac-tion, and significantly improves the user?soverview of the available options.
More-over, our results suggest that presentingusers with a brief summary of the irrele-vant options increases users?
confidence inhaving heard about all relevant options.1 IntroductionThe goal of spoken dialogue systems (SDS) isto offer efficient and natural access to applica-tions and services, such as email and calendars,travel and entertainment booking, and product rec-ommendation.
In evaluating nine SDS in theDARPA Communicator domain (flight, hotel, andrental car hire), Walker et al (2001) found that (1)shorter task duration correlates with higher usersatisfaction, and (2) the information presentationphase of dialogues is the primary contributor todialogue duration.
During this phase, the typicalsystem enumerates the set of options that matchthe user?s constraints, as shown in Figure 1.
Theuser can then refine these options by offering newconstraints.
When the number of options to bepresented is large, this process can be painstaking,leading to reduced user satisfaction.
Moreover, asS: I found 28 round trips from Edinburgh to Brussels onOctober 31st and returning Edinburgh on November6th.
For option 1, I have an outbound flight with KLMdeparting at 7 am and arriving at 8:49 am non-stop.A return flight is with KLM departing at 10:30 am andarriving at 11:28 am with 1 stopover.
Ticket price is?165.
Please say ?next option?, or, ?flight details?, or,?I?ll take it?.U: Next optionS: For option 2, I have an outbound flight with KLM de-parting at 3:30 pm and arriving at 5:19 pm nonstop.A return flight is with KLM departing at 8:25 pm andarriving at 12:28 pm with 1 stopover.
Ticket price is?165 please say ?next option?, or, ?flight details?, or,?I?ll take it.
?U: Next optionS: .
.
.Figure 1: Typical Information Presentation Phaseof a Communicator DialogueWalker et al (2004) observe, having to access theset of available options sequentially makes it diffi-cult for the user to remember the various aspects ofmultiple options and to compare them in memory.Clearly, alternative strategies to sequential pre-sentation of information in SDS are needed.
Re-cently, two approaches have been proposed.
Inthe user-model (UM) based approach, the sys-tem identifies a small number of options that bestmatch the user?s preferences (Moore et al, 2004;Walker et al, 2004).
In the summarize and re-fine (SR) approach, the system structures the largenumber of options into a small number of clus-ters that share attributes.
The system summa-rizes the clusters based on their attributes and thenprompts the user to provide additional constraints(Polifroni et al, 2003; Chung, 2004).In this paper, we present an algorithm that com-bines the benefits of these two approaches in anapproach to information presentation that inte-grates user modelling with automated clustering.65Thus, the system provides detail only about thoseoptions that are of some relevance to the user,where relevance is determined by the user model.If there are multiple relevant options, a cluster-based tree structure orders these options to allowfor stepwise refinement.
The effectiveness of thetree structure, which directs the dialogue flow, isoptimized by taking the user?s preferences into ac-count.
Complex tradeoffs between alternative op-tions are presented explicitly to allow for a bet-ter overview and a more informed choice.
In ad-dition, we address the issue of giving the user agood overview of the option space, despite select-ing only the relevant options, by briefly accountingfor the remaining (irrelevant) options.In the remainder of this paper, we describe theprior approaches in more detail, and discuss theirlimitations (Section 2).
In section 3, we describeour approach, which integrates user preferenceswith automated clustering and summarization inan attempt to overcome the problems of the origi-nal approaches.
Section 4 presents our clusteringand content structuring algorithms and addressesissues in information presentation.
In Section 5,we describe an evaluation of our approach and dis-cuss its implications.2 Previous Work in InformationPresentation2.1 Tailoring to a User ModelPrevious work in natural language generationshowed how a multi-attribute decision-theoreticmodel of user preferences could be used to deter-mine the attributes that are most relevant to men-tion when generating recommendations tailored toa particular user (Carenini and Moore, 2001).
Inthe MATCH system, Walker et al (2004) appliedthis approach to information presentation in SDS,and extended it to generate summaries and com-parisons among options, thus showing how themodel can be used to determine which options tomention, as well as the attributes that the user willfind most relevant to choosing among them.
Eval-uation showed that tailoring recommendations andcomparisons to the user increases argument effec-tiveness and improves user satisfaction (Stent etal., 2002).MATCH included content planning algorithmsto determine what options and attributes to men-tion, but used a simple template based approachto realization.
In the FLIGHTS system, Mooreet al (2004) focussed on organizing and express-ing the descriptions of the selected options and at-tributes, in ways that are both easy to understandand memorable.
For example, Figure 2 shows adescription of options that is tailored to a user whoprefers flying business class, on direct flights, andon KLM, in that order.
In FLIGHTS, coherenceand naturalness of descriptions were increased byreasoning about information structure (Steedman,2000) to control intonation, using referring expres-sions that highlight attributes relevant to the user(e.g., ?the cheapest flight?
vs. ?a KLM flight?
),and signalling discourse relations (e.g., contrast)with appropriate intonational and discourse cues.S: You can fly business class on KLM, arriving at fourtwenty p.m., but you?d need to connect in London.
Thereis a direct flight on BMI, arriving at four ten p.m., but ithas no availability in business class.Figure 2: Tailored description by FLIGHTSThis prior work demonstrated that the usermodel-based approach can concisely present a rel-atively small number of options, pointing out theways in which those options satisfy user prefer-ences.
It is an appropriate strategy for SDS whenthere are a small number of options to present, ei-ther because the number of options is limited orbecause users can supply sufficient constraints towinnow down a large set before querying the data-base of options.However, there are several limitations to this ap-proach.
First, it does not scale up to presentinga large number of options.
When there are hun-dreds of options to consider (e.g., when choosingamong consumer products, hotels, or restaurants)there may be many options that are close in score.In addition, users may not be able to provide con-straints until they hear more information about thespace of options.
This brings up a second problemwith the UM-based approach, namely that it doesnot provide the user with an overview of the op-tion space, because options scoring below a speci-fied threshold are not mentioned.
This is related tothe third problem, which is that users might missout on options they would have chosen if they hadheard about them.
These last two problems mayreduce user confidence in the system, if users havethe perception that the system is not telling themabout all of the available options.
This may ulti-mately lead to a decrease in user satisfaction.662.2 Stepwise Refinement through Clusteringand SummarizationPolifroni et al (2003) developed an approach thatstructures large datasets for summarization andsuccessive refinement.
It supports the user in nar-rowing in on a suitable option by clustering theoptions in the database, summarizing the optionclusters and suggesting further constraints.
In thisapproach, the prompts presented to the user, andthe order in which they appear are determined atrun-time based on an algorithm that computes themost useful set of attributes, as dictated by the cur-rent data subset.
For large data sets, attributes thatpartition the data into the minimal number of clus-ters are chosen, so that a concise summary can bepresented to the user to refine, see Figure 3.M: What restaurants do you have?S: I have found 983 restaurants.
Most of them are locatedin Boston and Cambridge.
There are 32 choices for cui-sine.
I also have information about price range.M: Okay tell me about the ones in Boston.S: I have found 401 restaurants in Boston.
There are 29choices for cuisine.M: Do you have any that serve seafood?S: I have found 19 seafood restaurants.
They are predomi-nantly in Back Bay, the North End, South Boston and theSouth End.M: In the South End.S: I have found 3 restaurants.
Grill Fish on Columbus Av-enue, McCormick & Schmick?s on Columbus Avenue andJoseph?s on High Street.Figure 3: Dialogue between simulator (M) and Po-lifroni system (S)Polifroni et al?s approach was extended byChung (2004), who proposed a constraint relax-ation strategy for coping with queries that are toorestrictive to be satisfied by any option.
Qu andBeale (2003) had previously addressed the prob-lem of responding to user queries with severalconstraints and used linguistic cues to determinewhich constraints had to be relaxed.
Our discus-sion and evaluation of the SR approach is basedon Chung?s version.Although the SR approach provides a solutionto the problem of presenting information whenthere are large numbers of options in a way that issuitable for SDS, it has several limitations.
First,there may be long paths in the dialogue struc-ture.
Because the system does not know about theuser?s preferences, the option clusters may containmany irrelevant entities which must be filtered outsuccessively with each refinement step.
In addi-tion, the difficulty of summarizing options typi-cally increases with their number, because valuesare more likely to be very diverse, to the pointthat a summary about them gets uninformative (?Ifound flights on 9 airlines.?
).A second problem with the SR approach is thatexploration of tradeoffs is difficult when there isno optimal option.
If at least one option satis-fies all requirements, this option can be found effi-ciently with the SR strategy.
But the system doesnot point out alternative tradeoffs if no ?optimal?option exists.
For example, in the flight book-ing domain, suppose the user wants a flight that ischeap and direct, but there are only expensive di-rect and cheap indirect flights.
In the SR approach,as described by Polifroni, the user has to ask forcheap flights and direct flights separately and thushas to explore different refinement paths.Finally, the attribute that suggests the next userconstraint may be suboptimal.
The procedure forcomputing the attribute to use in suggesting thenext restriction to the user is based on the con-siderations for efficient summarization, that is, theattribute that will partition the data set into thesmallest number of clusters.
If the attribute thatis best for summarization is not of interest to thisparticular user, dialogue duration is unnecessarilyincreased, and the user may be less satisfied withthe system, as the results of our evaluation suggest(see section 5.2).3 Our ApproachOur work combines techniques from the UM andSR approaches.
We exploit information from auser model to reduce dialogue duration by (1) se-lecting all options that are relevant to the user,and (2) introducing a content structuring algorithmthat supports stepwise refinement based on theranking of attributes in the user model.
In thisway, we keep the benefits of user tailoring, whileextending the approach to handle presentation oflarge numbers of options in an order that reflectsuser preferences.
To address the problem of userconfidence, we also briefly summarize options thatthe user model determines to be irrelevant (seesection 4.3).
Thus, we give users an overview ofthe whole option space, and thereby reduce therisk of leaving out options the user may wish tochoose in a given situation.The integration of a user model with the cluster-ing and structuring also alleviates the three prob-lems we identified for the SR approach.
When a67user model is available, it enables the system todetermine which options and which attributes ofoptions are likely to be of interest to the particu-lar user.
The system can then identify compellingoptions, and delete irrelevant options from the re-finement structure, leading to shorter refinementpaths.
Furthermore, the user model allows thesystem to determine the tradeoffs among options.These tradeoffs can then be presented explicitly.The user model also allows the identification of theattribute that is most relevant at each stage in therefinement process.
Finally, the problem of sum-marizing a large number of diverse attribute valuescan be tackled by adapting the cluster criterion tothe user?s interest.In our approach, information presentation isdriven by the user model, the actual dialogue con-text and the available data.
We allow for an arbi-trarily large number of alternative options.
Theseare structured so that the user can narrow in on oneof them in successive steps.
For this purpose, astatic option tree is built.
Because the structure ofthe option tree takes the user model into account,it allows the system to ask the user to make themost relevant decisions first.
Moreover, the optiontree is pruned using an algorithm that takes advan-tage of the tree structure, to avoid wasting timeby suggesting irrelevant options to the user.
Thetradeoffs (e.g., cheap but indirect flights vs. directbut expensive flights) are presented to the user ex-plicitly, so that the user won?t have to ?guess?
ortry out paths to find out what tradeoffs exist.
Ourhypothesis was that explicit presentation of trade-offs would lead to a more informed choice and de-crease the risk that the user does not find the opti-mal option.4 ImplementationOur approach was implemented within a spokendialogue system for flight booking.
While the con-tent selection step is a new design, the content pre-sentation part of the system is an adaptation andextension of the work on generating natural sound-ing tailored descriptions reported in (Moore et al,2004).4.1 ClusteringThe clustering algorithm in our implementation isbased on that reported in (Polifroni et al, 2003).The algorithm can be applied to any numericallyordered dataset.
It sorts the data into bins thatroughly correspond to small, medium and largevalues in the following way.
The values of each at-tribute of the objects in the database (e.g., flights)are clustered using agglomerative group-averageclustering.
The algorithm begins by assigningeach unique attribute value to its own bin, and suc-cessively merging adjacent bins whenever the dif-ference between the means of the bins falls belowa varying threshold.
This continues until a stop-ping criterion (a target number of no more thanthree clusters in our current implementation) ismet.
The bins are then assigned predefined labels,e.g., cheap, average-price, expensivefor the price attribute.Clustering attribute values with the above algo-rithm allows for database-dependent labelling.
A?300 flight gets the label cheap if it is a flightfrom Edinburgh to Los Angeles (because mostother flights in the database are more costly) butexpensive if it is from Edinburgh to Stuttgart(for which there are a lot of cheaper flights in thedata base).
Clustering also allows the construc-tion of user valuation-sensitive clusters for cat-egorial values, such as the attribute airline:They are clustered to a group of preferred air-lines, dispreferred airlines and airlines theuser does not-care about.4.2 Building up a Tree StructureThe tree building algorithm works on the clustersproduced by the clustering algorithm instead of theoriginal values.
Options are arranged in a refine-ment tree structure, where the nodes of an optiontree correspond to sets of options.
The root ofthe tree contains all options and its children con-tain complementary subsets of these options.
Eachchild is homogeneous for a given attribute (e.g., ifthe parent set includes all direct flights, one childmight include all direct cheap flights whereas an-other child includes all direct expensive flights).Leaf-nodes correspond either to a single option orto a set of options with very similar values for allattributes.This tree structure determines the dialogue flow.To minimize the need to explore several branchesof the tree, the user is asked for the most essentialcriteria first, leaving less relevant criteria for laterin the dialogue.
Thus, the branching criterion forthe first level of the tree is the attribute that has thehighest weight according to the user model.
Forexample, Figure 5 shows an option tree structure68rank attributes1 fare class (preferred value: business)2 arrival time, # of legs, departure time, travel time6 airline (preferred value: KLM)7 price, layover airportFigure 4: Attribute ranking for business userFigure 5: Option tree for business userfor our ?business?
user model (Figure 4).The advantage of this ordering is that it mini-mizes the probability that the user needs to back-track.
If an irrelevant criterion had to be decidedon first, interesting tradeoffs would risk being scat-tered across the different branches of the tree.A special case occurs when an attribute is ho-mogeneous for all options in an option set.
Then aunary node is inserted regardless of its importance.This special case allows for more efficient summa-rization, e.g., ?There are no business class flightson KLM.?
In the example of Figure 5, the attributeairline is inserted far up in the tree despite itslow rank.The user is not forced to impose a to-tal ordering on the attributes but may specifythat two attributes, e.g., arrival-time andnumber-of-legs, are equally important to her.This partial ordering leads to several attributeshaving the same ranking.
For equally ranked at-tributes, we follow the approach taken by Polifroniet al (2003).
The algorithm selects the attributethat partitions the data into the smallest numberof sub-clusters.
For example, in the tree in Fig-ure 5, number-of-legs, which creates twosub-clusters for the data set (direct and indirect),comes before arrival-time, which splits theset of economy class flights into three subsets.The tree building algorithm introduces one ofthe main differences between our structuring andPolifroni?s refinement process.
Polifroni et al?ssystem chooses the attribute that partitions the datainto the smallest set of unique groups for sum-marization, whereas in our system, the algorithmtakes the ranking of attributes in the user modelinto account.4.3 Pruning the Tree StructureTo determine the relevance of options, we did notuse the notion of compellingness (as was done in(Moore et al, 2004; Carenini and Moore, 2001)),but instead defined the weaker criterion of ?dom-inance?.
Dominant options are those for whichthere is no other option in the data set that is betteron all attributes.
A dominated option is in all re-spects equal to or worse than some other option inthe relevant partition of the data base; it should notbe of interest for any rational user.
All dominantoptions represent some tradeoff, but depending onthe user?s interest, some of them are more interest-ing tradeoffs than others.Pruning dominated options is crucial to ourstructuring process.
The algorithm uses informa-tion from the user model to prune all but the dom-inant options.
Paths from the root to a given op-tion are thereby shortened considerably, leading toa smaller average number of turns in our systemcompared to Polifroni et al?s system.An important by-product of the pruning al-gorithm is the determination of attributes whichmake an option cluster compelling with respectto alternative clusters (e.g., for a cluster con-taining direct flights, as opposed to flights thatrequire a connection, the justification would be#-of-legs).
We call such an attribute the ?jus-tification?
for a cluster, as it justifies its existence,i.e., is the reason it is not pruned from the tree.
Jus-tifications are used by the generation algorithm topresent the tradeoffs between alternative optionsexplicitly.Additionally, the reasons why options havebeen pruned from the tree are registered and pro-vide information for the summarization of bad op-tions in order to give the user a better overview ofthe option space (e.g., ?All other flights are eitherindirect or arrive too late.?).
To keep summariesabout irrelevant options short, we back off to a de-fault statement ?or are undesirable in some otherway.?
if these options are very heterogeneous.694.4 Presenting Clusters4.4.1 Turn LengthIn a spoken dialogue system, it is important notto mention too many facts in one turn in order tokeep the memory load on the user manageable.Obviously, it is not possible to present all of theoptions and tradeoffs represented in the tree in asingle turn.
Therefore, it is necessary to split thetree into several smaller trees that can then be pre-sented over several turns.
In the current implemen-tation, a heuristic cut-off point (no deeper than twobranching nodes and their children, which corre-sponds to the nodes shown in Figure 5) is used.This procedure produces a small set of options topresent in a turn and includes the most relevant ad-vantages and disadvantages of an option.
The nextturn is determined by the user?s choice indicatingwhich of the options she would like to hear moreabout (for illustration see Figure 6).4.4.2 Identifying ClustersThe identification of an option set is based onits justification.
If an option is justified by severalattributes, only one of them is chosen for identi-fication.
If one of the justifications is a contex-tually salient attribute, this one is preferred, lead-ing to constructions like: ?.
.
.
you?d have to makea connection in Brussels.
If you want to fly di-rect,.
.
.
?).
Otherwise, the cluster is identified bythe highest ranked attribute e.g.,?There are fourflights with availability in business class.?.
If anoption cluster has no compelling homogeneous at-tribute, but only a common negative homogeneousattribute, this situation is acknowledged: e.g., ?Ifyou?re willing to travel economy / arrive later / ac-cept a longer travel time, .
.
.
?.4.4.3 Summarizing ClustersAfter the identification of a cluster, more in-formation is given about the cluster.
All positivehomogeneous attributes are mentioned and con-trasted against all average or negative attributes.An attribute that was used for identification ofan option is not mentioned again in the elabora-tion.
In opposition to a single flight, attributes mayhave different values for the entities within a set offlights.
In that case, these attribute values need tobe summarized.There are three main cases to be distinguished:1.
The continuous values for the attributesprice, arrival-time etc.
need to besummarized, as they may differ in their val-ues even if they are in the same cluster.
Oneway to summarize them is to use an ex-pression that reflects their value range, e.g.
?between x and y?.
Another solution is tomention only the evaluation value, leading tosentences like ?The two flights with shortesttravel time?
or ?The cheapest flights.?2.
For discrete-valued attributes with asmall number of possible values, e.g.,number-of-legs and fare-class,summarization is not an issue, because whenhomogeneous for a cluster, the attributevalues of its options are identical.3.
The third group are attributes with catego-rial values, e.g., ?airline?.
If there are nomore than three different values, we summa-rize using quantifications like ?none/all/bothof them?, as done in (Polifroni et al, 2003).If the values are more diverse, the user modelcomes back into play to produce a tailoredsummary based on user preferences (e.g., lik-ing KLM).
For example, we would generate?None are on KLM.
?, which takes into ac-count the user?s preference and is shorter thanmentioning all airlines the flights are on.An issue arising from summarization with nega-tion is that the negated value has to be salient, oth-erwise the utterance might be irritating.
For exam-ple, it would be better to say ?These flights are notdirect.?
in a neutral context, but ?You would notneed to connect in London Heathrow.?
if LondonHeathrow had already been mentioned.A sample dialogue produced by our system,when given the business user model (see Figure 4),is shown in Figure 6.5 EvaluationA within-participants laboratory experiment wasconducted in order to determine whether usermodel-based clustering leads to increased overalluser satisfaction, a better overview of the avail-able options, quicker accessibility to the optimaloption and higher confidence of having heard allrelevant options.
The experiment furthermore as-sessed whether the options were presented in away that users found understandable and recordedthe time users took to read a dialogue turn.70U: Hello.
I?d like to book a flight from Edinburgh to Brus-sels for tomorrow arriving at around 3pm.S: There are four flights with availability in business class.None are on KLM.
The only direct flight arrives at 5:30pm, which is later than you requested.
To arrive earlier,you?ll have to make a connection.If you?re willing to travel economy, there is a direct flighton BMI, arriving at 1:10 pm.
There?s also a KLM flightarriving at 1:50 pm, but it requires a connection in Am-sterdam.
All other economy flights take longer or arriveafter 4 pm.U: Can you tell me more about the business class flights thatarrive earlier?S: The two flights with shortest travel time are both onBritish Airways and cost 308 pounds.
The first takes 4hours and 20 minutes and arrives at 1:20 pm.
The othertakes 4 hours and 30 minutes and arrives at 3:30pm.There?s a cheaper flight on Lufthansa.
It arrives at3:10pm and costs just 270 pounds, but it takes 5 hoursand 35 minutes.
All other business class flights arrivevery early or too late.Figure 6: Example Dialogue with our System5.1 Experimental DesignEach of the 38 subjects who completed the exper-iment was presented with six dialogue pairs, thefirst of which was used for training and was thusnot included in the analysis.
Each dialogue pairconsisted of one dialogue between a user and oursystem and one dialogue between the same userand a system designed as described in (Polifroniet al, 2003; Chung, 2004) (cf.
Section 2.2).
Someof the dialogues with our system were constructedmanually based on the content selection and struc-turing step, because the generation component didnot cover all linguistic constructions needed.
Thedialogues with the Chung system were designedmanually, as this system is implemented for an-other domain.
The order of the dialogues in a pairwas randomized.
The dialogues were provided astranscripts.After reading each dialogue transcript, partici-pants were asked four questions about the system?sresponses.
They provided their answers using Lik-ert scales.1.
Did the system give the information in a way that waseasy to understand?1: very hard to understand7: very easy to understand2.
Did the system give you a good overview of the avail-able options?1: very poor overview7: very good overview3.
Do you think there may be flights that are better optionsfor X1 that the system did not tell X1 about?1X was instantiated by name of our example users.1: I think that is very possible7: I feel the system gave a good overview of all optionsthat are relevant for X1.4.
How quickly did the system allow X1 to find the opti-mal flight?1: slowly3: quicklyAfter reading each pair of dialogues, the partic-ipants were also asked the forced choice question:?Which of the two systems would you recommendto a friend??
to assess user satisfaction.5.2 ResultsA significant preference for our system was ob-served.
(In the diagrams, our system which com-bines user modelling and stepwise refinement iscalled UMSR, whereas the system based on Po-lifroni?s approach is called SR.) There were a totalof 190 forced choices in the experiment (38 par-ticipants * 5 dialogue pairs).
UMSR was preferred120 times (?
0.63%), whereas SR was preferredonly 70 times (?
0.37%).
This difference is highlysignificant (p < 0.001) using a two-tailed bino-mial test.
Thus, the null-hypothesis that both sys-tems are preferred equally often can be rejectedwith high confidence.The evaluation results for the Likert scale ques-tions confirmed our expectations.
The SR dia-logues received on average slightly higher scoresfor understandability (question 1), which can beexplained by the shorter length of the system turnsfor that system.
However, the difference is notstatistically significant (p = 0.97 using a two-tailed paired t-test).
The differences in resultsfor the other questions are all highly statisticallysignificant, especially for question 2, assessingthe quality of overview of the options given bythe system responses, and question 3, assessingthe confidence that all relevant options were men-tioned by the system.
Both were significant atp < 0.0001.
These results confirm our hypothe-sis that our strategy of presenting tradeoffs explic-itly and summarizing irrelevant options improvesusers?
overview of the option space and also in-creases their confidence in having heard about allrelevant options, and thus their confidence in thesystem.
The difference for question 4 (accessibil-ity of the optimal option) is also statistically sig-nificant (p < 0.001).
Quite surprisingly, subjectsreported that they felt they could access optionsmore quickly even though the dialogues were usu-ally longer.
The average scores (based on 190 val-71Figure 7: Results for all Questionsues) are shown in Figure 7.To get a feel for whether the content given byour system is too complex for oral presentationand requires participants to read system turns sev-eral times, we recorded reading times and corre-lated them to the number of characters in a systemturn.
We found a linear relation, which indicatesthat participants did not re-read passages and is apromising sign for the use of our strategy in SDS.6 Conclusions and Future WorkIn this paper, we have shown that information pre-sentation in SDS can be improved by an approachthat combines a user model with structuring ofoptions through clustering of attributes and suc-cessive refinement.
In particular, when presentedwith dialogues generated by a system that com-bines user modelling with successive refinement(UMSR) and one that uses refinement without ref-erence to a user model (SR), participants reportedthat the combined system provided them with abetter overview of the available options and thatthey felt more certain to have been presented withall relevant options.
Although the presentation ofcomplex tradeoffs usually requires relatively longsystem turns, participants were still able to copewith the amount of information presented.
Forsome dialogues, subjects even felt they could ac-cess relevant options more quickly despite longersystem turn length.In future work, we would like to extend the clus-tering algorithm to not use a fixed number of tar-get clusters but to depend on the number of naturalclusters the data falls into.
We would also like toextend it to be more sensitive to the user modelwhen forming clusters (e.g., to be more sensitiveat lower price levels for a user for whom price isvery important than for a user who does not careabout price).The explicit presentation of tradeoffs made bythe UMSR system in many cases leads to dialogueturns that are more complex than typical dialogueturns in the SR system.
Even though participantsdid not report that our system was harder to under-stand, it would be interesting to investigate howwell users can understand and remember informa-tion from the system when part of their concentra-tion is absorbed by another task, for example whenusing the system while driving a car.AcknowledgmentsWe would like to thank the anonymous review-ers for their comments.
The research is supportedby the TALK project (European Community ISTproject no.
507802), http://www.talk-project.org.The first author was supported by EvangelischesStudienwerk e.V.
Villigst.ReferencesG.
Carenini and J.D.
Moore.
2001.
An empirical study ofthe influence of user tailoring on evaluative argument ef-fectiveness.
In Proc.
of IJCAI 2001.G.
Chung.
2004.
Developing a flexible spoken dialog systemusing simulation.
In Proc.
of ACL ?04.V.
Demberg.
2005.
Information presentation in spoken di-alogue systems.
Master?s thesis, School of Informatics,University of Edinburgh.J.D.
Moore, M.E.
Foster, O.
Lemon, and M. White.
2004.Generating tailored, comparative descriptions in spokendialogue.
In Proc.
of the 17th International Florida Artifi-cial Intelligence Research Sociey Conference, AAAI Press.J.
Polifroni, G. Chung, and S. Seneff.
2003.
Towards au-tomatic generation of mixed-initiative dialogue systemsfrom web content.
In Proc.
of Eurospeech ?03, Geneva,Switzerland, pp.
193?196.Y.
Qu and S. Beale.
1999.
A constraint-based model forcooperative response generation in information dialogues.In AAAI/IAAI 1999 pp.
148?155.M.
Steedman 2000.
Information structure and the syntax-phonology interface.
In Linguistic Inquiry, 31(4): 649?689.A.
Stent, M.A.
Walker, S. Whittaker, and P. Maloor.
2002.User-tailored generation for spoken dialogue: an experi-ment.
In Proc.
of ICSLP-02.M.A.
Walker, S. Whittaker, A. Stent, P. Maloor, J.D.
Moore,M.
Johnston, and G. Vasireddy.
2004.
Generation andevaluation of user tailored responses in dialogue.
In Cog-nitive Science 28: 811-840.M.A.Walker, R. Passonneau, and J.E.
Boland.
2001.
Quanti-tative and qualitative evaluation of DARPA communicatorspoken dialogue systems.
In Proc of ACL-01.72
