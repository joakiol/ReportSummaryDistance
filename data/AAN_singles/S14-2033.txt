Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 208?212,Dublin, Ireland, August 23-24, 2014.Coooolll: A Deep Learning System for Twitter Sentiment Classification?Duyu Tang?, Furu Wei?, Bing Qin?, Ting Liu?, Ming Zhou?
?Research Center for Social Computing and Information RetrievalHarbin Institute of Technology, China?Microsoft Research, Beijing, China{dytang, qinb, tliu}@ir.hit.edu.cn{fuwei, mingzhou}@microsoft.comAbstractIn this paper, we develop a deep learn-ing system for message-level Twitter sen-timent classification.
Among the 45 sub-mitted systems including the SemEval2013 participants, our system (Coooolll)is ranked 2nd on the Twitter2014 test setof SemEval 2014 Task 9.
Coooolll isbuilt in a supervised learning frameworkby concatenating the sentiment-specificword embedding (SSWE) features withthe state-of-the-art hand-crafted features.We develop a neural network with hybridloss function1to learn SSWE, which en-codes the sentiment information of tweetsin the continuous representation of words.To obtain large-scale training corpora, wetrain SSWE from 10M tweets collected bypositive and negative emoticons, withoutany manual annotation.
Our system canbe easily re-implemented with the publiclyavailable sentiment-specific word embed-ding.1 IntroductionTwitter sentiment classification aims to classifythe sentiment polarity of a tweet as positive, nega-tive or neutral (Jiang et al., 2011; Hu et al., 2013;Dong et al., 2014).
The majority of existing ap-proaches follow Pang et al.
(2002) and employ ma-chine learning algorithms to build classifiers fromtweets with manually annotated sentiment polar-ity.
Under this direction, most studies focus on?This work was partly done when the first author wasvisiting Microsoft Research.1This is one of the three sentiment-specific word embed-ding learning algorithms proposed in Tang et al.
(2014).This work is licensed under a Creative Commons At-tribution 4.0 International Licence.
Page numbers and pro-ceedings footer are added by the organisers.
Licence details:http://creativecommons.org/licenses/by/4.0/designing effective features to obtain better clas-sification performance (Pang and Lee, 2008; Liu,2012; Feldman, 2013).
For example, Mohammadet al.
(2013) implement diverse sentiment lexiconsand a variety of hand-crafted features.
To leveragemassive tweets containing positive and negative e-moticons for automatically feature learning, Tanget al.
(2014) propose to learn sentiment-specificword embedding and Kalchbrenner et al.
(2014)model sentence representation with Dynamic Con-volutional Neural Network.In this paper, we develop a deep learning sys-tem for Twitter sentiment classification.
First-ly, we learn sentiment-specific word embedding(SSWE) (Tang et al., 2014), which encodes thesentiment information of text into the continuousrepresentation of words (Mikolov et al., 2013; Sunet al., 2014).
Afterwards, we concatenate the SS-WE features with the state-of-the-art hand-craftedfeatures (Mohammad et al., 2013), and build thesentiment classifier with the benchmark datasetfrom SemEval 2013 (Nakov et al., 2013).
Tolearn SSWE, we develop a tailored neural net-work, which incorporates the supervision fromsentiment polarity of tweets in the hybrid lossfunction.
We learn SSWE from tweets, lever-aging massive tweets with emoticons as distant-supervised corpora without any manual annota-tions.We evaluate the deep learning system on thetest set of Twitter Sentiment Analysis Track in Se-mEval 20142.
Our system (Coooolll) is ranked2nd on the Twitter2014 test set, along with theSemEval 2013 participants owning larger train-ing data than us.
The performance of only us-ing SSWE as features is comparable to the state-of-the-art hand-crafted features (detailed in Ta-ble 3), which verifies the effectiveness of thesentiment-specific word embedding.
We releasethe sentiment-specific word embedding learned2http://alt.qcri.org/semeval2014/task9/208TrainingDataLearningAlgorithmFeatureRepresentationSentimentClassifier12?.NN+1N+2?N+KSTATEFeatureSSWEFeatureall-capemoticon?
?.dimension 1dimension 2dimension NelongatedMassiveTweetsEmbeddingLearningFigure 1: Our deep learning system (Coooolll) forTwitter sentiment classification.from 10 million tweets, which can be easily usedto re-implement our system and adopted off-the-shell in other sentiment analysis tasks.2 A Deep Learning SystemIn this section, we present the details of our deeplearning system for Twitter sentiment classifica-tion.
As illustrated in Figure 1, Coooolll is a su-pervised learning method that builds the sentimen-t classifier from tweets with manually annotatedsentiment polarity.
In our system, the feature rep-resentation of tweet is composed of two parts, thesentiment-specific word embedding features (SS-WE features) and the state-of-the-art hand-craftedfeatures (STATE features).
In the following parts,we introduce the SSWE features and STATE fea-tures, respectively.2.1 SSWE FeaturesIn this part, we first describe the neural networkfor learning sentiment-specific word embedding.Then, we generate the SSWE features of a tweetfrom the embedding of words it contains.Our neural network is an extension of the tra-ditional C&W model (Collobert et al., 2011), asillustrated in Figure 2.
Unlike C&W model thatlearns word embedding by only modeling syntac-tic contexts of words, we develop SSWEu, whichcaptures the sentiment information of sentences aswell as the syntactic contexts of words.
Given anoriginal (or corrupted) ngram and the sentimentpolarity of a sentence as the input, SSWEupredict-s a two-dimensional vector for each input ngram.The two scalars (fu0, fu1) stand for language modelscore and sentiment score of the input ngram, re-so cooool :DsyntacticsentimentFigure 2: Our neural network (SSWEu) for learn-ing sentiment-specific word embedding.spectively.
The training objectives of SSWEuarethat (1) the original ngram should obtain a high-er language model score fu0(t) than the corruptedngram fu0(tr), and (2) the sentiment score of orig-inal ngram fu1(t) should be more consistent withthe gold polarity annotation of sentence than cor-rupted ngram fu1(tr).
The loss function of SSWEuis the linear combination of two hinge losses,lossu(t, tr) = ?
?
losscw(t, tr)+(1?
?)
?
lossus(t, tr)(1)where where t is the original ngram, tris the cor-rupted ngram which is generated from t with mid-dle word replaced by a randomly selected one,losscw(t, tr) is the syntactic loss as given in E-quation 2, lossus(t, tr) is the sentiment loss asdescribed in Equation 3.
The hyper-parameter ?weighs the two parts.losscw(t, tr) = max(0, 1?
fcw(t) + fcw(tr))(2)lossus(t, tr) = max(0, 1?
?s(t)fu1(t)+ ?s(t)fu1(tr) )(3)where ?s(t) is an indicator function reflecting thesentiment polarity of a sentence, whose value is 1if the sentiment polarity of tweet t is positive and-1 if t?s polarity is negative.
We train sentiment-specific word embedding from 10M tweets col-lected with positive and negative emoticons (Huet al., 2013).
The details of training phase are de-scribed in Tang et al.
(2014).After finish learning SSWE, we explore min,average and max convolutional layers (Collobertet al., 2011; Socher et al., 2011; Mitchell and Lap-ata, 2010), to obtain the tweet representation.
Theresult is the concatenation of vectors derived fromdifferent convolutional layers.2092.2 STATE FeaturesWe re-implement the state-of-the-art hand-craftedfeatures (Mohammad et al., 2013) for Twitter sen-timent classification.
The STATE features are de-scribed below.?
All-Caps.
The number of words with all char-acters in upper case.?
Emoticons.
We use the presence of positive(or negative) emoticons and whether the lastunit of a segmentation is emoticon3.?
Elongated Units.
The number of elongatedwords (with one character repeated more thantwo times), such as gooood.?
Sentiment Lexicon.
We utilize several senti-ment lexicons4to generate features.
We ex-plore the number of sentiment words, the s-core of last sentiment words, the total senti-ment score and the maximal sentiment scorefor each lexicon.?
Negation.
The number of individual nega-tions5within a tweet.?
Punctuation.
The number of contiguous se-quences of dot, question mark and exclama-tion mark.?
Cluster.
The presence of words from eachof the 1,000 clusters from the Twitter NLPtool (Gimpel et al., 2011).?
Ngrams.
The presence of word ngrams (1-4)and character ngrams (3-5).3 ExperimentsWe evaluate our deep learning system by applyingit for Twitter sentiment classification within a su-pervised learning framework.
We conduct exper-iments on both positive/negative/neutral and posi-tive/negative classification of tweets.3We use the positive and negative emoticons from Sen-tiStrength, available at http://sentistrength.wlv.ac.uk/.4HL (Hu and Liu, 2004), MPQA (Wilson et al., 2005), N-RC Emotion (Mohammad and Turney, 2013), NRC Hashtagand Sentiment140Lexicon (Mohammad et al., 2013).5http://sentiment.christopherpotts.net/lingstruc.html3.1 Dataset and SettingWe train the Twitter sentiment classifier on thebenchmark dataset in SemEval 2013 (Nakov etal., 2013).
The training and development sets werecompletely in full to task participants of SemEval2013.
However, we were unable to download al-l the training and development sets because sometweets were deleted or not available due to modi-fied authorization status.
The distribution of ourdataset is given in Table 1.
We train sentimen-t classifiers with LibLinear (Fan et al., 2008) onthe training set and dev set, and tune parameter?c,?wi of SVM on the test set of SemEval 2013.In both experiment settings, the evaluation met-ric is the macro-F1 of positive and negative class-es (Nakov et al., 2013).Positive Negative Neutral TotalTrain 2,642 994 3,436 7,072Dev 408 219 493 1,120Test 1,570 601 1,639 3,810Table 1: Statistics of our SemEval 2013 Twittersentiment classification dataset.The test sets of SemEval 2014 is directly pro-vided to the participants, which is composed offive parts.
The statistic of test sets in SemEval2014 is given in Table 2.Positive Negative Neutral TotalT1 427 304 411 1,142T2 492 394 1,207 2,093T3 1,572 601 1,640 3,813T4 982 202 669 1,939T5 33 40 13 86Table 2: Statistics of SemEval 2014 Twitter senti-ment classification test set.
T1 is LiveJournal2014,T2 is SMS2013, T3 is Twitter2013, T4 is Twit-ter2014, T5 is Twitter2014Sarcasm.3.2 Results and AnalysisThe experiment results of different methodson positive/negative/neutral and positive/negativeTwitter sentiment classification are listed in Ta-ble 3.
The meanings of T1?T5 in each column aredescribed in Table 2.
SSWE means the approachthat only utilizes the sentiment-specific word em-bedding as features for Twitter sentiment classi-fication.
In STATE, we only utilize the existingfeatures (Mohammad et al., 2013) for building the210MethodPositive/Negative/Neutral Positive/NegativeT1 T2 T3 T4 T5 T1 T2 T3 T4 T5SSWE 70.49 64.29 68.69 66.86 50.00 84.51 85.19 85.06 86.14 62.02Coooolll 72.90 67.68 70.40 70.14 46.66 86.46 85.32 86.01 87.61 56.55STATE 71.48 65.43 66.18 67.07 44.89 83.96 82.82 84.39 86.16 58.27W2V 55.19 52.98 52.33 50.58 49.63 68.87 71.89 74.50 71.52 61.60Top 74.84 70.28 72.12 70.96 58.16 - - - - - - - - - -Average 63.52 55.63 59.78 60.41 45.44 - - - - - - - - - -Table 3: Macro-F1 of positive and negative classes in positive/negative/neutral and positive/negativeTwitter sentiment classification on the test sets (T1-T5, detailed in Table 2) of SemEval 2014.
Theperformances of Coooolll on the Twitter-relevant test sets are bold.sentiment classifier.
In Coooolll, we use the con-catenation of SSWE features and STATE features.In W2V, we only use the word embedding learnedfrom word2vec6as features.
Top and Average arethe top and average performance of the 45 team-s of SemEval 2014, including the SemEval 2013participants who owns larger training data.On positive/negative/neutral classification oftweets as listed in Table 3 (left table), we findthat the learned sentiment-specific word embed-ding features (SSWE) performs comparable withthe state-of-the-art hand-crafted features (STATE),especially on the Twitter-relevant test sets (T3and T4)7.
After feature combination, Coooolllyields 4.22% and 3.07% improvement by macro-F1 on T3 and T4,which verifies the effective-ness of SSWE by learning discriminate featuresfrom massive data for Twitter sentiment classifi-cation.
From the 45 teams, Coooolll gets the Rank5/2/3/2 on T1-T4 respectively, along with the Se-mEval 2013 participants owning larger trainingdata.
We also comparing SSWE with the context-based word embedding (W2V), which don?t cap-ture the sentiment supervision of tweets.
We findthat W2V is not effective enough for Twitter sen-timent classification as there is a big gap betweenW2V and SSWE on T1-T4.
The reason is that W2Vdoes not capture the sentiment information of text,which is crucial for sentiment analysis tasks andeffectively leveraged for learning the sentiment-specific word embedding.We also conduct experiments on the posi-6We utilize the Skip-gram model.
The embedding istrained from the 10M tweets collected by positive and neg-ative emoticons, as same as the training data of SSWE.7The result of STATE on T3 is different from the resultsreported in Mohammad et al.
(2013) and Tang et al.
(2014)because we have different training data with the former anddifferent -wi of SVM with the latter.tive/negative classification of tweets.
The reasonis that the sentiment-specific word embedding islearned from the positive/negative supervision oftweets through emoticons, which is tailored forpositive/negative classification of tweets.
FromTable 3 (right table), we find that the performanceof positive/negative Twitter classification is con-sistent with the performance of 3-class classifica-tion.
SSWE performs comparable to STATE on T3and T4, and yields better performance (1.62% and1.45% improvements on T3 and T4, respectively)through feature combination.
SSWE outperform-s W2V by large margins (more than 10%) on T3and T4, which further verifies the effectiveness ofsentiment-specific word embedding.4 ConclusionWe develop a deep learning system (Coooolll) formessage-level Twitter sentiment classification inthis paper.
The feature representation of Cooool-ll is composed of two parts, a state-of-the-arthand-crafted features and the sentiment-specificword embedding (SSWE) features.
The SSWEis learned from 10M tweets collected by posi-tive and negative emoticons, without any manu-al annotation.
The effectiveness of Coooolll hasbeen verified in both positive/negative/neutral andpositive/negative classification of tweets.
Among45 systems of SemEval 2014 Task 9 subtask(b),Coooolll yields Rank 2 on the Twitter2014 test set,along with the SemEval 2013 participants owninglarger training data.AcknowledgmentsWe thank Li Dong for helpful discussions.
Thiswork was partly supported by National Natu-ral Science Foundation of China (No.61133012,No.61273321, No.61300113).211ReferencesRonan Collobert, Jason Weston, L?eon Bottou, MichaelKarlen, Koray Kavukcuoglu, and Pavel Kuksa.2011.
Natural language processing (almost) fromscratch.
Journal of Machine Learning Research,12:2493?2537.Li Dong, Furu Wei, Chuanqi Tan, Duyu Tang, MingZhou, and Ke Xu.
2014.
Adaptive recursive neuralnetwork for target-dependent twitter sentiment clas-sification.
In Proceedings of the 52nd Annual Meet-ing of the Association for Computational Linguistic-s, pages 49?54.Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin.
2008.
Liblinear: Alibrary for large linear classification.
The Journal ofMachine Learning Research, 9:1871?1874.Ronen Feldman.
2013.
Techniques and application-s for sentiment analysis.
Communications of theACM, 56(4):82?89.Kevin Gimpel, Nathan Schneider, Brendan O?Connor,Dipanjan Das, Daniel Mills, Jacob Eisenstein,Michael Heilman, Dani Yogatama, Jeffrey Flanigan,and Noah A. Smith.
2011.
Part-of-speech taggingfor twitter: Annotation, features, and experiments.In Proceedings of the Annual Meeting of the Associ-ation for Computational Linguistics, pages 42?47.Ming Hu and Bing Liu.
2004.
Mining and summa-rizing customer reviews.
In Proceedings of the tenthACM SIGKDDConference on Knowledge Discoveryand Data Mining, pages 168?177.Xia Hu, Jiliang Tang, Huiji Gao, and Huan Liu.2013.
Unsupervised sentiment analysis with emo-tional signals.
In Proceedings of the InternationalWorld Wide Web Conference, pages 607?618.Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, andTiejun Zhao.
2011.
Target-dependent twitter sen-timent classification.
The Proceeding of AnnualMeeting of the Association for Computational Lin-guistics, 1:151?160.Nal Kalchbrenner, Edward Grefenstette, and Phil Blun-som.
2014.
A convolutional neural network formodelling sentences.
In Proceedings of the 52ndAnnual Meeting of the Association for Computation-al Linguistics, pages 655?665.Bing Liu.
2012.
Sentiment analysis and opinion min-ing.
Synthesis Lectures on Human Language Tech-nologies, 5(1):1?167.Tomas Mikolov, Kai Chen, Greg Corrado, and Jef-frey Dean.
2013.
Efficient estimation of word rep-resentations in vector space.
arXiv preprint arX-iv:1301.3781.Jeff Mitchell and Mirella Lapata.
2010.
Compositionin distributional models of semantics.
Cognitive Sci-ence, 34(8):1388?1429.Saif M Mohammad and Peter D Turney.
2013.
Crowd-sourcing a word?emotion association lexicon.
Com-putational Intelligence, 29(3):436?465.Saif M Mohammad, Svetlana Kiritchenko, and Xiao-dan Zhu.
2013.
Nrc-canada: Building the state-of-the-art in sentiment analysis of tweets.
Proceedingsof the International Workshop on Semantic Evalua-tion, pages 321?327.Preslav Nakov, Sara Rosenthal, Zornitsa Kozareva,Veselin Stoyanov, Alan Ritter, and Theresa Wilson.2013.
Semeval-2013 task 2: Sentiment analysis intwitter.
In Proceedings of the International Work-shop on Semantic Evaluation, volume 13, pages312?320.Bo Pang and Lillian Lee.
2008.
Opinion mining andsentiment analysis.
Foundations and trends in infor-mation retrieval, 2(1-2):1?135.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
: sentiment classification usingmachine learning techniques.
In Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing, pages 79?86.Richard Socher, Eric H Huang, Jeffrey Pennington,Andrew Y Ng, and Christopher D Manning.
2011.Dynamic pooling and unfolding recursive autoen-coders for paraphrase detection.
The Conferenceon Neural Information Processing Systems, 24:801?809.Yaming Sun, Lei Lin, Duyu Tang, Nan Yang, ZhenzhouJi, and Xiaolong Wang.
2014.
Radical-enhancedchinese character embedding.
arXiv preprint arX-iv:1404.4714.Duyu Tang, Furu Wei, Nan Yang, Ming Zhou, TingLiu, and Bing Qin.
2014.
Learning sentiment-specific word embedding for twitter sentiment clas-sification.
In Proceedings of the 52nd Annual Meet-ing of the Association for Computational Linguistic-s, pages 1555?1565.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.2005.
Recognizing contextual polarity in phrase-level sentiment analysis.
In Proceedings of the Con-ference on Empirical Methods in Natural LanguageProcessing, pages 347?354.212
