A Co-occurrence Graph-based Approach forPersonal Name Alias Extraction from Anchor TextsDanushka Bollegala ?The University of Tokyo7-3-1, Hongo, Tokyo,113-8656, Japandanushka@mi.ci.i.u-tokyo.ac.jpYutaka MatsuoNational Institute of AdvancedIndustrial Science andTechnology1-18-13, Sotokanda, Tokyo,101-0021, Japany.matsuo@aist.go.jpMitsuru IshizukaThe University of Tokyo7-3-1, Hongo, Tokyo,113-8656, Japanishizuka@i.u-tokyo.ac.jpAbstractA person may have multiple name aliaseson the Web.
Identifying aliases of a nameis important for various tasks such as in-formation retrieval, sentiment analysis andname disambiguation.
We introduce the no-tion of a word co-occurrence graph to rep-resent the mutual relations between wordsthat appear in anchor texts.
Words in an-chor texts are represented as nodes in theco-occurrence graph and an edge is formedbetween nodes which link to the same url.For a given personal name, its neighboringnodes in the graph are considered as can-didates of its aliases.
We formalize aliasidentification as a problem of ranking nodesin this graph with respect to a given name.We integrate various ranking scores throughsupport vector machines to leverage a robustranking function and use it to extract aliasesfor a given name.
Experimental results on adataset of Japanese celebrities show that theproposed method outperforms all baselines,displaying a MRR score of 0.562.1 IntroductionSearching for information about people in the Web isone of the most common activities of Internet users.Around 30% of search engine queries include personnames (Guha and Garg, 2004).
However, an indi-vidual might have multiple nicknames or aliases on?Research Fellow of the Japan Society for the Promotion ofScience (JSPS)the Web.
For example, the famous Japanese majorleague baseball player Hideki Matsui is often calledas Godzilla in web contents.
Identifying aliases ofa name is important in various tasks such as infor-mation retrieval (Salton and McGill, 1986), senti-ment analysis (Turney, 2002) and name disambigua-tion (Bekkerman and McCallum, 2005).In information retrieval, to improve recall of aweb search on a person name, a search engine canautomatically expand the query using aliases of thename.
In our previous example, a user who searchesfor Hideki Matsui might also be interested in re-trieving documents in which Matsui is referred toas Godzilla.
People use different aliases when ex-pressing their opinions about an entity.
By aggre-gating texts written on an individual that use variousaliases, a sentiment analysis system can make an in-formed judgment on the sentiment.
Name disam-biguation focuses on identifying different individu-als with the same name.
For example, for the nameJim Clark, aside from the two most popular name-sakes - the formula-one racing champion and thefounder of Netscape - at least ten different people arelisted among the top 100 results returned by Googlefor the name.
Although namesakes have identicalnames, their nicknames usually differ.
Therefore, aname disambiguation algorithm can benefit from theknowledge related to name aliases.We propose an alias extraction method that ex-ploits anchor texts and the links indicated by theanchor texts.
Link structure has been studiedextensively in information retrieval and has beenfound to be useful in various tasks such as rank-ing of web pages, identification of hub-authority865sites, text categorization and social network extrac-tion (Chakrabarti, 2003).
Anchor texts pointing toan url provide useful semantic clues regarding theresource represented by the url.If the majority of inbound anchor texts of anurl contain a person name, then it is likely thatthe remainder of the anchor texts contain informa-tion about aliases of the name.
For example, animage of Hideki Matsui on a web page might belinked using the real name, Hideki Matsui, as wellas aliases Godzilla and Matsu Hide.
However, ex-tracting aliases from anchor texts is a challengingproblem due to the noise in both link structure andanchor texts.
For example, web pages of extremelydiverse topics link to yahoo.com using various an-chor texts.
Moreover, given the scale of the Web,broken links and incorrectly linked anchor texts areabundant.
Naive heuristics are insufficient to extractaliases from anchor texts.Our main contributions are summarized as fol-lows:?
We introduce word co-occurrence graphs torepresents words that appear in anchor textsand formalize the problem of alias extractionas a one of ranking nodes in the graph with re-spect to a given name.?
We define various ranking scores to evaluatethe appropriateness of a word as an alias of aname.
Moreover, the ranking scores are inte-grated using support vector machines to lever-age a robust alias detection method.2 Related WorkHokama and Kitagawa (2006) propose an alias ex-traction method that is specific to Japanese lan-guage.
For a given name p, they search for the query* koto p 1 and extract the words that match the aster-isk.
However, koto is highly ambiguous and extractslots of incorrect aliases.
Moreover, the method can-not extract aliases when a name and its aliases ap-pear in separate documents.Anchor texts and link structure have been em-ployed in synonym extraction (Chen et al, 2003)and translations extraction (Lu et al, 2004).
Chenet al (2003) propose the use of hyperlink structure1koto is written in hiragana and and means also known asHideki MatsuiGodzilla Matsu Hide???
?Yankees baseballsportsNew YorkFigure 1: Co-occurrence graph for Hideki Matsuiwithin a particular domain to generate a domain-specific thesaurus.
First, a set of high quality web-sites from a given domain is selected.
Second, sev-eral link analysis techniques are used to removenoisy links and the navigational structure of the web-site is converted into a content structure.
Third,pointwise mutual information is applied to identifyphrases within content structures to create a domainspecific thesaurus.
They evaluate the thesaurus in aquery expansion task.
Anchor texts written in differ-ent languages that point the same object have beenused in cross-language information retrieval (CLIR)to translate user queries.
Lu et al (2004) extend thisidea by associating anchor texts written using a piv-otal third language to find translations of queries.3 Method3.1 OutlineWe introduce word co-occurrence graph, an undi-rected graph, to represent words that appear in an-chor texts.
For each word that appears in the vocabu-lary of words in anchor texts, we create a node in thegraph.
Two words are considered as co-occurring iftwo anchor texts containing these words link to thesame url.
An edge is formed between two nodes ifthe words represented by those nodes co-occur.
Fig-ure 1 illustrates a portion of the co-occurrence graphin the proximity of Hideki Matsui as extracted bythis method from anchor texts.Representing words that appear in anchor textsas a graph enables us to capture the complex inter-relations between the words.
Words in inbound an-chor texts of an url contain important semantic clues866regarding the resource represented by the url.
Suchwords form a clique in the co-occurrence graph,indicating their close connectivity.
Moreover, co-occurrence graphs represent indirect relationshipsbetween words.
For example, in Figure 1 HidekiMatsui is connected to New York via Yankees.We model the problem of extracting aliases asa one of ranking nodes in the co-occurrence graphwith respect to a real name.
Usually, an individualhas just one or two aliases.
A name alias extractionalgorithm must identify the correct aliases among avast number of related terms for an individual.3.2 Word Co-occurrence GraphLet V be the vocabulary of words wi that appearin anchor texts.
The boolean function A(ai, wi) re-turns true if the anchor text ai contains the word wi.Moreover, let the boolean function L(ai, ui) to betrue if the anchor text ai points to url ui.
Then twowords wi, wj are defined to be co-occurring in a urlu, if A(ai, wi) ?
A(aj , wj) ?
L(ai, u) ?
L(aj , u) istrue for at least one pair of anchor texts (ai, aj).
Inother words, two words are said to co-occur in an urlif at least one inbound pair of anchor texts containsthe two words.
Moreover, we define the number ofco-occurrences of wi and wj to be the number ofdifferent urls they co-occur.We define word co-occurrence graph, G(V,E)(V is the set of nodes and E is the set of edges) as anundirected graph where each word wi in vocabularyV is represented by a node in the graph.
Becauseone-to-one mapping pertains between a word and anode, for simplicity we use wi to represent both theword and the corresponding node in the graph.
Anedge eij ?
E is created between two nodes wi, wj ifthey co-occur.
Given a personal name p, representedby a node p in the co-occurrence graph, our objec-tive is to identify the nodes that represent aliases ofp.
We rank the nodes in the graph with respect top such that more likely a node is an alias of p, thehigher the rank it is assigned.
According to our def-inition, a node that lies n hops away from p has ann-order co-occurrence with p. Considering the factthat a single web page might link to many pages withdiverse topics, higher order co-occurrences with p(i.e.
nodes that appear further from p) are unreliableas aliases of p. Consequently, we limit C(p), the setof candidate aliases of p, to nodes which are directlyTable 1: Contingency table for a candidate alias xx C(p)?
{x}p k n?
k nV ?
{p} K ?
k N ?
n?K + k N ?
nV K N ?K Nconnected to p in the graph.
In Figure 1 candidatesof Hideki Matsui fall inside the dotted ellipse.3.3 Ranking of CandidatesTo evaluate the strength of co-occurrence betweena candidate alias and the real name, for each candi-date alias x in C(p) we create a contingency tableas shown in Table 1.
In Table 1, the first row repre-sents candidates of p and the first column representsnodes in the graph.
Therein, k is the number of urlsin which p and x co-occur, K is the number of urlsin which at least one inbound anchor text containsthe candidate x, n is the number of urls in whichat least one inbound anchor text contains p and N isthe total number of urls in the crawl.
Next, we definevarious ranking scores based on Table 1.Simplest of all ranking scores is the link frequency(lf ).
We define link frequency of an candidate x asthe number of different urls in which x and p co-occur.
This is exactly the value of k in Table 1.Link frequency is biased towards highly frequentwords.
A word that has a high frequency in anchortexts can also report a high co-occurrence with p.tfidf measure which is popularly used in informationretrieval can be used to normalize this bias.
tfidf iscomputed from Table 1 as follows,tfidf(nj) = k log NK + 1 .From Table 1 we compute co-occurrence mea-sures; log likelihood ratio LLR (Dunning, 1993),chi-squared measure CS, point-wise mutual infor-mation PMI (Church and Hanks, 1991) and hypergeometric distribution HG (Hisamitsu and Niwa,2001).
Each of these measures is used to rank candi-date aliases of a given name.
Because of the limitedavailability of space, we omit the definitions of thesemeasures.Furthermore, we define popular set overlap mea-sures; cosine measure, overlap coefficient and Dicecoefficient from Table 1 as follows,867cosine(p, x) = k?n+?K ,overlap(p, x) = kmin(n,K) ,Dice(p, x) = 2kn+K .3.4 Hub weightingA frequently observed phenomenon on the Web isthat many web pages with diverse topics link to socalled hubs such as Google, Yahoo or Amazon.
Be-cause two anchor texts might link to a hub for en-tirely different reasons, co-occurrences coming fromhubs are prone to noise.
To overcome the adverse ef-fects of a hub h when computing the ranking scoresdescribed in section 3.3, we multiply the numberof co-occurrences of words linked to h by a factor?
(h, p) where,?
(h, p) = td?
1 .
(1)Here, t is the number of inbound anchor texts ofh that contain the real name p, d is the total num-ber of inbound anchor texts of h. If many anchortexts that link to h contain p (i.e., larger t value)then the reliability of h as a source of informationabout p increases.
On the other hand, if h has manyinbound links (i.e., larger d value) then it is likelyto be a noisy hub and gets discounted when mul-tiplied by ?
(<< 1).
Intuitively, Formula 1 boostshubs that are likely to be containing information re-garding p, while penalizing those that contain vari-ous other topics.3.5 TrainingIn section 3.3 we introduced 9 ranking scores toevaluate the appropriateness of a candidate alias fora given name.
Each of the scores is computedwith and without weighting for hubs, resulting in2?
9 = 18 ranking scores.
The ranking scores cap-ture different statistical properties of candidates; it isnot readily apparent which ranking scores best con-vey aliases of a name.
We use real world name-aliasdata to learn the proper combination of the rankingscores.We represent each candidate alias as a vector ofthe ranking scores.
Because we use the 18 rank-ing scores described above, each candidate is repre-sented by an 18-dimensional vector.
Given a set ofpersonal names and their aliases, we model the train-ing process as a preference learning task.
For eachname, we impose a binary preference constraint be-tween the correct alias and each candidate.For example, let us assume for a name wp weselected the four candidates a1, a2, a3, a4.
With-out loss of generality, let us further assume that a1and a2 are the correct aliases of p. Therefore, weform four partial preferences: a1 ?
a3, a1 ?
a4,a2 ?
a3 and a2 ?
a4.
Here, x ?
y denotesthe fact that x is preferred to y.
We use rankingSVMs (Joachims, 2002) to learn a ranking functionfrom preference constraints.
Ranking SVMs attemptto minimize the number of discordant pairs duringtraining, thereby improving average precision.
Thetrained SVM model is used to rank a set of candi-dates extracted for a name.
Then the highest rankingcandidate is selected as the alias of the name.4 ExperimentsWe crawled Japanese web sites and extracted anchortexts and urls linked by the anchor texts.
A website might use links for purely navigational purposes,which convey no semantic clue.
To remove naviga-tional links in our dataset, we prepare a list of wordsthat are commonly used in navigational menus, suchas top, last, next, previous, links, etc and removeanchor texts that contain those words.
In additionwe remove any links that point to pages within thesame site.
All urls with only one inbound anchor textare removed from the dataset.
After the above men-tioned processing, the dataset contains 24, 456, 871anchor texts pointing to 8, 023, 364 urls.
The aver-age number of inbound anchor texts per url is 3.05and its standard deviation is 54.02.
We tokenizeanchor texts using the Japanese morphological an-alyzer MeCab (Kudo et al, 2004) and select nounsas nodes in the co-occurrence graph.For training and evaluation purposes we manuallyassigned aliases for 441 Japanese celebrities.
Thename-alias dataset covers people from various fields868Table 2: Mean Reciprocal RankMethod MRR Method MRRSVM (RBF) 0.5625 lf 0.0839SVM (Linear) 0.5186 cosine 0.0761SVM (Quad) 0.4898 tfidf 0.0757SVM (Cubic) 0.4087 Dice 0.0751tfidf(h) 0.3957 overlap(h) 0.0750LLR(h) 0.3879 PMI(h) 0.0624cosine(h) 0.3701 LLR 0.0604lf(h) 0.3677 HG 0.0399HG(h) 0.3297 CS 0.0079Dice(h) 0.2905 PMI 0.0072CS(h) 0.1186 overlap 0.0056of cinema, sports, politics and mass-media.
The ma-jority of people in the dataset have only one aliasassigned.
For each real name in the dataset we ex-tract a set of candidates using the proposed method.We then sort the real names in the dataset accord-ing to the number of candidates extracted for them.We select the top 50 real names with the greatestnumber of candidate aliases for evaluation purposesbecause recognizing the correct alias from numerouscandidates is a more challenging task that enables usto perform a strict evaluation.
On average a name inour evaluation dataset has 6500 candidates, of whichonly one is correct.
The rest of the 391 (441 ?
50)names are used for training.We compare the proposed method (SVM) againstvarious baseline ranking scores using mean recip-rocal rank (MRR) (Baeza-Yates and Ribeiro-Neto,1999).
The MRR is defined as follows;MRR = 1nn?i=11Ri .
(2)Therein, Ri is the rank assigned to a correct alias andn is the total number of aliases.
The MRR is widelyused in information retrieval to evaluate the rank-ing of search results.
Formula 2 gives high MRR toranking scores which assign higher ranks to correctaliases.Our experimental results are summarized in Ta-ble 2.
The hub weighted versions of ranking scoresare denoted by (h).
We trained rank SVMs withlinear SVM (Linear), quadratic SVM (Quad), cubicSVM (Cubic) and radial basis functions (RBF) SVM(RBF) kernels.
As shown in Table 2, the proposedSVM-based method has the highest MRR valuesamong all methods compared.
The best results areobtained with the RBF kernel (SVM RBF).
In factfor 21 out of 50 names in our dataset, SVM (RBF)correctly ranks their aliases at the first rank.
Con-sidering the fact that each name has more than 6000candidate aliases, this is a marked improvement overthe baselines.
It is noteworthy in Table 2 that thehub-weighted versions of ranking scores outperformthe corresponding non-weighted version.
This jus-tifies the hub weighting method proposed in sec-tion 3.4.
The hub-weighted tfidf score (tfidf(h)) hasthe best MRR among the baseline ranking scores.For polynomial kernels, we observe a drop of preci-sion concomitant with the complexity of the kernel,which occurs as a result of over-fitting.Table 3 shows the top-three ranked aliases ex-tracted for Hideki Matsui by various methods.
En-glish translation of words are given within brackets.The correct alias, Godzilla, is ranked first by SVM(RBF).
Moreover, the correct alias is followed bythe last name Matsui and his team, New York Yan-kees.
In fact, tfidf(h), LLR(h) and lf(h) all have theexact ranking for the top three candidates.
Hide,which is an abbreviated form of Hideki, is rankedsecond by these measures.
However, none con-tains the alias Godzilla among the top three candi-dates.
The non-hub weighted measures tend to in-clude general terms such as Tokyo, Yomiuri (a pop-ular Japanese newspaper), Nikkei (a Japanese busi-ness newspaper), and Tokyo stock exchange.
A closeanalysis revealed that such general terms frequentlyco-occur with a name in hubs.
Without adjustingthe co-occurrences coming from hubs, such termsinvariably receive high ranking scores, as shown inTable 3.Incorrect tokenization of Japanese names is amain source of error.
Many aliases are out-of-dictionary (unknown) words, which are known toproduce incorrect tokenizations in Japanese mor-phological analyzers.
Moreover, a name and itsaliases can be written in various scripts: Hiragana,Katanaka, Kanji, Roman and even combinations ofmultiple scripts.
Some foreign names such as Davideven have orthographic variants in Japanese: da-bid-do or de-bid-do.
Failing to recognize the differ-ent ways in which a name can be written engenderswrong preference constraints during training.869Table 3: Top ranking candidate aliases for Hideki MatsuiMethod First Second ThirdSVM (RBF) (Godzilla) (Matsui) (Yankees)tfidf(h) (Matsui) (Hide) (Yankees)LLR(h) (Matsui) (Hide) (Yankees)cosine(h) (Matsui) (Yankees) (Hide)lf(h) (Matsui) (Hide) (Yankees)HG(h) (Matsui) (Yankees) (Hide)Dice(h) (Matsui) (Yankees) (Hide)CS(h) (Matsui) (Major league) (player)lf (Tokyo) (Yomiuri) (Nikkei)cosine (Yomiuri) (Tokyo stock exchange) (Matsui)tfidf (Yomiuri) (Tokyo) (Tokyo stock exchange)Dice (Yomiuri) (Tokyo stock exchange) (Matsui)overlap(h) (play) (Godzilla) (Steinbrenner)PMI(h) (play) (Godzilla) (Steinbrenner)LLR (Yomiuri) (Tokyo stock exchange) (jiji.com)HG (Yomiuri) (Tokyo stock exchange) (Matsui)CS (jiji.com) (Tokyo stock exchange) (Yomiuri)PMI (Komdatzien) (picture) (contents)overlap (Komdatzien) (picture) (contents)5 ConclusionWe proposed a method to extract aliases of a givenname using anchor texts and link structure.
We cre-ated a co-occurrence graph to represent words in an-chor texts and modeled the problem of alias extrac-tion as a one of ranking nodes in this graph with re-spect to a given name.
In future, we intend to applythe proposed method to extract aliases for other en-tity types such as products, organizations and loca-tions.ReferencesR.A.
Baeza-Yates and B.A.
Ribeiro-Neto.
1999.
ModernInformation Retrieval.
ACM Press / Addison-Wesley.R.
Bekkerman and A. McCallum.
2005.
Disambiguat-ing web appearances of people in a social network.
InProc.
of the World Wide Web Conference (WWW?
05),pages 463?470.S.
Chakrabarti.
2003.
Mining the Web: DiscoveringKnowledge from Hypertext Data.
Morgan Kaufmann.Z.
Chen, S. Liu, L. Wenyin, Ge.
Pu, and W. Ma.
2003.Building a web thesaurus from web link structure.In Proc.
of the 26th annual international ACM SI-GIR conference on Research and development in in-formaion retrieval, pages 48?55.K.
Church and P. Hanks.
1991.
Word association norms,mutual information and lexicography.
ComputationalLinguistics, 16:22?29.T.
Dunning.
1993.
Accurate methods for the statistics ofsurprise and coincidence.
Computational Linguistics,19:61?74.R.
Guha and A. Garg.
2004.
Disambiguating people insearch.
In Stanford University.T.
Hisamitsu and Y. Niwa.
2001.
Topic-word selectionbased on combinatorial probability.
In Proc.
of NL-PRS?01, pages 289?296.T.
Hokama and H. Kitagawa.
2006.
Extractingmnemonic names of people from the web.
In Proc.of 9th International Conference on Asian Digital Li-braries (ICADL?06), pages 121?130.T.
Joachims.
2002.
Optimizing search engines usingclickthrough data.
In Proc.
of the ACM conference onKnowledge Discovery and Data Minning (KDD).T.
Kudo, K. Yamamoto, and Y. Matsumoto.
2004.
Ap-plying conditional random fields to japanese morpho-logical analysis.
In Proc.
of EMNLP?04.W.
Lu, L. Chien, and H. Lee.
2004.
Anchor text miningfor translation of web queries: A transitive translationapproach.
ACM Transactions on Information Systems,22(2):242?269.G.
Salton and M.J. McGill.
1986.
Introduction to Mod-ern Information Retreival.
McGraw-Hill Inc., NewYork, NY.P.
Turney.
2002.
Thumbs up or thumbs down?
seman-tic orientation applied to unsupervised classification ofreviews.
In Proc.
of the ACL, pages 417?424.870
