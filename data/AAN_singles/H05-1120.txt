Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural LanguageProcessing (HLT/EMNLP), pages 955?962, Vancouver, October 2005. c?2005 Association for Computational LinguisticsLearning a Spelling Error Model from Search Query LogsFarooq AhmadDepartment of Electrical andComputer EngineeringUniversity of AlbertaEdmonton, Canadafarooq@ualberta.caGrzegorz KondrakDepartment of Computing ScienceUniversity of AlbertaEdmonton, Canadakondrak@cs.ualberta.caAbstractApplying the noisy channel model tosearch query spelling correction requiresan error model and a language model.Typically, the error model relies on aweighted string edit distance measure.The weights can be learned from pairsof misspelled words and their corrections.This paper investigates using the Expec-tation Maximization algorithm to learnedit distance weights directly from searchquery logs, without relying on a corpus ofpaired words.1 IntroductionThere are several sources of error in written lan-guage.
Typing errors can be divided into twogroups (Kucich, 1992): typographic errors and cog-nitive errors.
Typographic errors are the result ofmistyped keys and can be described in terms of key-board key proximity.
Cognitive errors on the otherhand, are caused by a misunderstanding of the cor-rect spelling of a word.
They include phonetic er-rors, in which similar sounding letter sequences aresubstituted for the correct sequence; and homonymerrors, in which a word is substituted for anotherword with the same pronunciation but a differentmeaning.
Spelling errors can also be grouped intoerrors that result in another valid word, such ashomonym errors, versus those errors that result ina non-word.
Generally non-word errors are easier todetect and correct.
In addition to its traditional usein word processing, spelling correction also has ap-plications in optical character recognition and hand-writing recognition.
Spelling errors in this contextare caused by inaccurate character recognition.Spelling correction is a well developed researchproblem in the field of computational linguistics.The first dictionary based approach to spelling cor-rection (Damerau, 1964) considers all words thatcan not be found in a dictionary as misspellings.
Thecorrect word is found by making a single edit op-eration (insertion, deletion, or substitution) on themisspelled word and re-checking the dictionary forthe inclusion of the altered version.
This methodworks well for correcting most typos, but often mis-spelled words are off by more than one character.A method of quantifying string-to-string distance isintroduced in (Wagner and Fischer, 1974), allowingthe consideration of multiple edit operations whendetermining candidate corrections.
Each edit op-eration is assigned a fixed cost.
Edit operations,though, can be more accurately modelled by consid-ering every possible insertion, deletion, and substitu-tion operation individually instead of having a fixedcost for each operation.
For example, the applica-tion of probabilistic models to spelling correction isexplored in (Kernighan, Church, and Gale, 1990),in which a confusion matrix describes the probabil-ity of each letter being substituted for another.
TheBayesian noisy channel model is used to determinethe the error probabilities, with the simplifying as-sumption that each word has at most one spellingerror.
In (Ristad and Yianilos, 1997), a probabilisticmodel of edit distance is learned from pairs of mis-spelled words and their corrections.
This extendsKernighan?s approach by allowing multiple edit op-erations rather than assuming a single edit.
Theprobability of edit operations is learned from a cor-pus of pairs of misspelled words and corrections.955Search query correction is an interesting branchof spelling correction.
Due to the wide variety ofsearch queries, dictionary based spelling correctionis not adequate for correcting search terms.
The con-cept of using query logs to aid in spelling correctionis explored in (Brill and Cucerzan, 2004).
It is notedthat using traditional Levenshtein distance as an er-ror model can lead to inappropriate corrections, so aweighted distance measure is used instead.This paper focuses on deriving a language modeland probabilistic error model directly from searchquery logs without requiring a corpus of misspelledwords paired with their corrections.
The task ofsearch query spelling correction is analyzed, andan implementation of the Expectation Maximization(EM) algorithm to learn an error model is described,with reference to similar approaches.
In Section 2,the make-up of search queries is analyzed in thecontext of spelling correction.
Section 3 details thenoisy channel model spelling correction frameworkand describes how the EM algorithm is applied tolearn an error model.
The learned error model is ex-plored in Section 4.
The derived model is tested inSection 5 by comparing its performance in the singleword spelling correction task to popular spell check-ing applications.
Finally, conclusions and directionsfor future work are presented in Section 6.2 Analysis of Search QueriesSearch queries present a difficult challenge for tradi-tional spelling correction algorithms.
As mentionedabove, dictionary-based approaches cannot be usedsince many search terms include words and namesthat are not well established in the language.
Fur-thermore, search queries typically consist of a fewkey words rather than grammatically correct sen-tences, making grammar-based approaches inappro-priate.
In addition, spelling errors are more com-mon in search queries than in regular written text,as approximately 10-15 % of search queries containa misspelling (Brill and Cucerzan, 2004).
The suit-ability of query logs as a corpus for spelling correc-tion is investigated in this section.The metaspy website1 displays search queriessubmitted to the popular metacrawler search enginein real time.
Over a period of five days in the last1www.metaspy.comFigure 1: Query Length Frequency Histogramweek of March 2005, 580,000 queries were ex-tracted from the site.
Several interesting observa-tions can be made from the analysis of the searchqueries.2.1 Query LengthOn average, each query consisted of approximately3 words.
Figure 1 shows the distribution of querylengths.As illustrated in Figure 1, over 80% of queriesinclude more than one search term.
Thus word n-gram probabilities provide useful statistical knowl-edge that can be exploited to improve spelling cor-rection.
Although word cooccurrences are not usedfor spelling correction in this paper, the possibilitiesfor n-gram analysis are explored in Section 3.2.
Thelonger queries (>5 terms) often contain quotations,song lyric excerpts or very specific product names.The frequency of words in written text has beenshown to follow Zipf?s law.
That is, if the words areordered in terms of frequency, the relationship be-tween frequency and rank can be approximated withthe following equation.F ?
Crm (1)where F is the frequency, r is rank, C is a constant,and m is an exponent close to 1.
In logarithmicform,log(F ) = log(C) ?
m ?
log(r) (2)The frequency and rank of search query tokensapproximately follow the same distribution, withsome deviation at the high and low ends.
Figure 2shows the frequency distribution for dictionary and956Figure 2: Token Frequency vs. Rank for Dictionary and Non-Dictionary Wordsnon-dictionary search query tokens.
The word listavailable on most Unix systems /usr/dict/words is acomprehensive list that contains 96,274 words, in-cluding names, plurals, verbs in several tenses, andcolloquialisms.
Following tokenization of the querylogs, the tokens were divided into dictionary andnon-dictionary words.
The frequency-rank relation-ship is similar for both types of words, except thatnearly all of the 100 most frequent query tokens aredictionary words.
The exponent m, the (negative)slope of the linear best fit lines shown in Figure 2,was determined to be 1.11 for dictionary words, and1.14 for non-dictionary words.
As in (Baeza-Yates,2005), the exponent is slightly higher than 1, partlydue to the less frequent use of function words suchas the in search queries relative to formal writing.Although the majority of search tokens can befound in a standard dictionary, a large proportion ofthe less common queries are not dictionary words.In fact, 73% of unique word types were not foundin the dictionary.
Taking token frequency into con-sideration, these non-dictionary tokens account forapproximately 20% of query search words, includ-ing correctly and incorrectly spelled words.
How-ever, the majority of the non-dictionary tokens arecorrectly spelled words, illustrating the unsuitabil-ity of traditional dictionary based spelling correctionfor search query correction.What are these non-dictionary words?
An anal-ysis of the top two hundred non-dictionary wordsin the query logs allows categorization into a fewmain groups.
The percentage of non-dictionarywords belonging to each category, and some exam-ples from each category are shown in Table 1.
Thefirst category, e-speak, includes words and abbre-Word Class Percent Examples1 E-speak &new words45% pics, html, multiplayer,clipart, mpeg, midi2 Companies& Products18% google, xbox, ebay,hotmail , playstation3 ProperNames16% (los) angeles, ratzinger,ilios, mallorca4 Medicalterms5% ERBS, mesothelioma,neuropsychological,alzheimers5 Misspellings 9% womens, realestate6 ForeignWords6% lettre, paraTable 1: Classes of Non-Dictionary Wordsviations that are commonly used online, but havenot crossed over into common language.
This cat-egory includes words such as pics, multiplayer, andclipart.
The second category is closely related tothe first, and includes company and product names,such as google, xbox, and hotmail.
Many of theseterms refer to online entities or computer games.Incorrectly spelled words are another main classof non-dictionary tokens.
Among the top 20 non-dictionary tokens are words with missing punctua-tion, such as womens and childrens, or with miss-ing spaces, such as realestate.
Names of peopleand locations are also common search queries, aswell as medical terminology.
Finally, foreign wordsmake up another class of words that are not foundin an (English) dictionary.
The 20 highest frequencynon-dictionary tokens from the extracted query logsare pics, html, multiplayer, googletestad, google,xbox, childrens, ebay, angeles, hotmail, womens,ERBS, clipart, playstation, ratzinger, Ilios, lettre,realestate, tech and mallorca.9573 Spelling Correction for Search QueriesThe spelling correction problem can be consideredin terms of the noisy channel model, which consid-ers the misspelled word v to be a corrupted versionof the correctly spelled word w.P (w|v) = P (v|w)P (w)P (v) (3)Finding the best candidate correction W involvesmaximizing the above probability.W = argmaxwP (v|w)P (w) (4)The denominator P (v) in Equation 3 is the samefor all w and can be eliminated from the calculation.P (v|w) models the errors that corrupt string w intostring v, and P (w) is the language model, or priorprobability, of word w.3.1 Error ModelGiven two strings v and w, P (v|w) is the probabilitythat v is transmitted given that the desired word isw.
One method of describing the noise model is toconsider P (v|w) to be proportional to the number ofedit operations required to transform w into v. ThisgivesP (v|w) ?
ED(v, w) (5)where ED(v, w) is the edit distance between v andw.The traditional edit distance calculation assigns afixed cost for each insertion, deletion, and substi-tution operation.
For example, each insertion anddeletion may be assigned a cost of 1, while substitu-tions are assigned a cost of 1.5.
The edit distancecalculation can be accomplished by dynamic pro-gramming.The error model can be improved if each edit op-eration is considered separately, rather than assign-ing a fixed cost to each operation.
For example, thesubstitution of the letter i for the letter e may bemuch more likely than k for e. Thus if a string S1differs from string S2 by one e ?
i substitution, itshould be considered more similar to S2 than a stringS3 that differs from S1 by an e ?
k substitution.Generating an accurate error model that consid-ers each edit operation individually requires learn-ing edit distance weights.
As described in (Ristadand Yianilos, 1997), character-to-character edit dis-tance costs ED(e) can be related to edit probabilityP (e) by means of the equation:ED(e) = ?
log[P (e)] (6)where e is an edit operation consisting of a sub-stitution of one alphanumeric character for another(c1 ?
c2), an insertion ( ?
c1), or a deletion(c1 ?
).Thus higher probability edits will have lower editdistances, and the string to string edit distance cal-culation proceeds in the same way as the tradi-tional calculation.
This convenient representationallows whole string-to-string edit probability to beexpressed in terms of the edit distance of the editsequence [e1...en]:P (w|v) = ?P (ei)= P (e1) ?
P (e2) ?
... ?
P (en) (7)Taking the log of both sides giveslog[P (w|v)] = log[P (e1)] + log[P (e2)]+ ... + log[P (en)] (8)Finally, by combining 6 and 8 we can relate theprobability of misspelling a string w as v to string-to-string edit distance.log[P (w|v)] = ?ED(w, v) (9)The edit probabilities can be estimated using theexpectation maximization (EM) algorithm as de-scribed in Section 3.3.3.2 Language ModelAlong with the error model, a language model isused to determine the most likely correction for ev-ery input query.
Often, spelling correction programsuse N-gram language models that use nearby wordsto help determine the most probable correction.
Forexample, it is noted in (Brill and Cucerzan, 2004)that employing a trigram language model can sub-stantially improve performance relative to a unigrammodel.
However, if search query logs are not verylarge, bigram or trigram data may be too sparse tobe helpful.
Nevertheless, a word unigram model canbe used for training the error model.
The unigram958model is determined by tokenizing the query logsand determining the frequency of each token.
Thelanguage model P (w) is the frequency of the wordC(w) divided by the total number of tokens N in thequery log:P (w) = C(w)N (10)Add-One smoothing is used to account for words notpresent in query logs.3.3 Determining Edit Probabilities withExpectation MaximizationThe EM algorithm is used to determine the parame-ters of the probability distribution for a given a set ofdata.
It can be considered to be a soft-clustering al-gorithm: given several data points, the task is to findthe cluster parameters which best represent the data.The EM algorithm is applied iteratively to each datapoint in a two-step process; the expectation step de-termines the degree to which data agrees with eachcluster/hypothesis, and the maximization step up-dates the parameters to reflect the inclusion of thenew data.Prior to running the EM algorithm, the edit dis-tance table is seeded with initial values.
The ini-tialization stage assigns high probability (low editdistance) to characters being typed correctly, anda lower probability for character substitutions.
Foreach character l, substitution distance is equally dis-tributed over all other characters and the deletionoperation (l ?
).
Specifically the initial prob-ability for a character match was set to 90%, andthe remaining 10% was equally distributed over theother 26 possible substitutions.
Essentially, the firstedit distance calculated in the EM algorithm will beequivalent to the fixed-weight Levenshtein distance.After this preprocessing stage, the edit probabilitymatrix is iteratively improved with the E-Step andM-Step described below.
The operation of the EMalgorithm is illustrated in Figure 3.For each query token, possible corrections areharvested from the query word list.
The entire wordlist is searched, and any word within a thresholdedit distance is considered as a candidate.
Since thequery logs can be quite large, determining the ex-act weighted edit distance between the input queryand each logged query is quite computationally ex-pensive.
Instead, the candidate queries are first nar-Figure 3: The EM processrowed down using a fast approximate string match-ing algorithm (Wu and Manber, 1990) to determineall candidates within k unweighted edit operations.Then, the candidate queries that are within a secondtighter threshold T, based on weighted edit distance,are kept.Candidates(v) = {wi|ED(wi, v) < T}Generally several words in the query logs willmeet the above criteria.
The threshold T is chosento ensure the inclusion of all reasonable corrections,while maintaining a manageable computation time.If T were infinite, every query log token would needto be considered, taking too much time.
On the otherhand, if T is too small, some corrections may not beconsidered.
In practice, K was set to 3 unweightededits, and T was set as a constant proportion of wordlength.The expectation of each candidate correction isthe probability that the word wi was desired giventhat the query was v:P (wi|v) =P (v|wi)P (wi)P (v) (11)where P (v|w) and P (w) are determined using theerror and language models described in Equations(9) and (10).If the value of T is set high enough, it can beassumed that the correct word w is within the setof candidates.
So, the sum of probabilities over allcandidates is normalized to P (v) in accordance withBayes Rule of Total Probability.P (v) = ?jP (v|wj)P (wj) (12)959Correction ErrorModel LanguageModel TotalProba-bilityNormal-izedequipment 0.0014 0.00078 1.1e-6 0.77equpment 0.64 5.0e-7 3.4e-7 0.23equpiment 0.0005 5.0e-7 1.0e-9 0.0005Table 2: Candidate Corrections for equpmentThis gives us the following formula for the expecta-tion valueP (wi|v) =P (v|wi)P (wi)?jP (v|wj)P (wj)(13)The E-step is used to generate candidate correc-tions for input query tokens.
For example, inputquery ?equpment?
returns the candidate correctionsand their probabilities shown in Table 2.Note that several incorrectly spelled words, in-cluding ?equpment?
itself, are given as candidatecorrections.
However, the language model derivedfrom the query logs assigns a low probability tothe incorrect candidates.
In the case of a correctlyspelled query, the most likely candidate correctionis the word itself.
However, occasionally there is acorrectly spelled but infrequent word within a smalledit distance of another more common word.
In thiscase, the language model will bias the correctionprobability in favor of an incorrect edit.
Neverthe-less, overall these cases do not seem to cause a sig-nificant impact on the error model except in the caseof plural nouns as discussed in Section 4.The maximization step updates the edit distanceprobabilities and edit distance table to reflect thequery considered in the E-Step.
For each can-didate correction, the required edits are added tothe edit frequency table, weighted by the proba-bility of the correction.
Then, the probability ofan edit for each character is normalized to 1 andthe edit probabilities are stored in a table.
Finally,Equation 6 is used to generate the edit probabil-ity table.
For example, for the input query ?equp-ment?
in response to the first candidate correction(equpment ?
equipment), the following substitu-tion frequencies will each be incremented by 0.77:e ?
e, q ?
q, u ?
u, i ?
, p ?
p,m ?
m, e ?e, n ?
n, t ?
t. The (i ? )
edit represents dele-tion of the letter i.Letter Subs Letter Subsa e qo n fkbb grnw o a eic ksm p nfrmd ds nk q glke ao i r sdmf btpj s mdng o ks t yirh rab u rioi aue v awcmj blhm w prgkk vots x gtmsl r is y ioajem nkvs z skmtTable 3: Most Common Substitutions4 The Learned Error ModelApproximately 580,000 queries were extracted fromthe metaspy site over a period of 5 days.
After gener-ating a language model by analyzing token frequen-cies, the EM algorithm was run on a subset of thequeries to find the edit probability matrix.After 15,000 iterations, several patterns can beobserved in the edit distance table.
The most com-mon edit operations are shown in Table 3.
As ex-pected, vowels are most commonly substituted forother vowels.
As can be seen in the table, vowel-to-vowel edits are more probable than vowel-to-consonant transitions.
The letter e is most com-monly mistyped as a, o, and i; the letter i is mostoften mistyped as a, u, and e. For the most part,vowel substitutions can be considered to be cogni-tive errors (except o ?
i may be a cognitive error ortypographic error).
The effect of keyboard key prox-imity is also evident; b is often typed as g; d as s; mas n; and so on.
Other errors seem to be a result ofphonetic similarity; c is misspelled as k and s; q as gand k; and v as w. In general, the edit probabilitiesroughly match those derived using a corpus of wordpairs in (Kernighan, Church, and Gale, 1990).The insertion probabilities for each letter areshown in Figure 4.
Equation 6 is used to convert theedit distances to probabilities.
Words in the pluralform cause problems for the algorithm, as is illus-trated by the high probability of s insertion in Fig-960Figure 4: Letter Insertion Probabilitiesure 4.
That is because high frequency query wordsoften appear in both singular and plural form.
Everytime the singular form is encountered, the plural isconsidered as a viable candidate correction, and thes insertion probability is increased.
Complementar-ily, every time the plural form is seen, the singularform is considered, increasing the s deletion proba-bility.
Indeed, as can be seen in Table 3, deletion isthe highest probability operation for the letter s.5 TestingTo test the accuracy of the error model, the well-known Unix based spelling correction programs Is-pell2 and Aspell3 spell checking programs were usedfor comparison.
Ispell generates candidate cor-rections by considering all words within 1 edit ofthe misspelled word.
Aspell uses the metaphonealgorithm (Philips, 1990), which divides Englishwords into phonetic segments, and generates al-ternate spellings by substituting similar soundingphones.
The test data set4 consists of 547 mis-spelled words paired with their best correction as de-termined by a human expert.Compound words wereremoved from the test set, leaving 508 misspellings.Several of the misspellings differ from the correctionby multiple edit operations.
Only the error modellearned by the EM algorithm on the search enginequeries was used; instead of using the probabilis-tic language model derived from the query logs andused for training, the word list in /usr/dict/words wasused, with equal probability assigned to each word.2International Ispell Version 3.1.20.http://www.lasr.cs.ucla.edu/geoff/ispell.html3Kevin Atkinson.
Aspell Version 0.29.http://aspell.sourceforge.net/4Kevin Atkinson.
http://aspell.net/test/SpellChecker ISPELL3.1.20 ASPELL0.29 EMBED GoogleTotalTokens508 508 508 508TotalFound272(53.5%)480(94.5%)402(79.1%)-Top 1(%)197(38.8%)302(59.5%)211(41.5%)291(57%)Top 5(%)260(51.2%)435(85.6%)331(65.2%)-Top 25(%)272(53.5%)478(94.1%)386(76.0%)-Table 4: Spelling Correction AccuracySince the test data is composed of single words ofvarying prevalence, a language model does not sig-nificantly aid correction.
In practice, the languagemodel would improve performance.Table 4 compares the performance of the As-pell and Ispell spell checkers with the Expecta-tion Maximization Based Edit Distance (EMBED)spelling correction system described in this paper.The percentages refer to the percentage of instancesin which the correct correction was within the topN suggestions given by the algorithm.
If only thetop recommended correction is considered, EMBEDfares better than Ispell, but worse than Aspell.
Forthe top 5 and 25 corrections, the rankings of the al-gorithms are the same.As Table 4 shows, in several cases the EMBED al-gorithm did not find the correction within the top 25suggestions.
Typically, the misspellings that couldnot be found had large edit distances from theircorrections.
For example, suggestions for the mis-spelling ?extions?
included ?actions?
and ?motions?but not the desired correction ?extensions?.
In gen-eral, by using a phonetic model to compress Englishwords, Aspell can find misspellings that have largeredit distances from their correction.
However, it re-lies on a language specific pronunciation model thatis manually derived.
EM based spelling correction,on the other hand, can be learned from a unlabeledcorpus and can be applied to other languages with-out modification.
Although the test data set wascomprised of misspelled dictionary words for thepurposes of comparison, the spelling correction sys-tem described here can handle a continuously evolv-ing vocabulary.
Also, the approach described herecan be used to train more general error models.961Comparison to online spelling suggestion systemssuch as provided by the Google search engine is dif-ficult since search results are returned for nearly ev-ery query on account of the large lexicon.
Conse-quently, many suggestions provided by Google arereasonable, but do not correspond to the golden stan-dard in the test data.
For example, ?cimplicity?
and?hallo?
are not considered misspellings since severalonline companies and products contain these terms,and ?verison?
is corrected to ?verizon?
rather than?version.?
While Google returns 291 corrections inagreement with the data set (57%), another 44 werejudged to be acceptable corrections, giving an accu-racy of 66%.
In addition, several of the apparentlymisspelled test strings are new words, proper names,or commonly accepted alternate spellings that arecommon on the web, so no suggestions were given.Taking these words into account would further im-prove the accuracy rating.6 Conclusions and Future WorkThe EM algorithm is able to learn an accurate errormodel without relying on a corpus of paired strings.The edit probabilities determined using the EM al-gorithm are similar to error models previously gen-erated using other approaches.
In addition, the gen-erated error model can be used to find the correctspelling of misspelled words as described in Section5.
However, there are several improvements thatcan be made to improve spelling error correction.One step is increasing the size of the corpus.
Whilethe corpus included nearly 580,000 queries, sev-eral thousand of those queries were correctly spelledwords without any misspelled versions in the corpus,or misspelled words without the correctly spelledversion available.
This results in the misidentifi-cation of candidate spelling corrections.
Anotherimprovement that can improve candidate correctionidentification is the use of better language models,as discussed in Section 3.2.
Since a large propor-tion of queries contain more than one word, wordn-gram statistics can be used to provide context sen-sitive spelling correction.
Finally, a large proportionof typos involve letter transpositions, and other oper-ations that can not be captured by a single-letter sub-stitution model.
In (Brill and Moore, 2000), a moregeneral model allowing generic string to string ed-its is used, allowing many-to-one and one-to-manycharacter substitution edits.
Pronunciation modelingin (Toutanova and Moore, 2002) further improvesspelling correction performance.AcknowledgmentsSupport for this work was provided by the Natu-ral Sciences and Engineering Research Council ofCanada.ReferencesBaeza-Yates, R. 2005.
Web Usage Mining in SearchEngines.
Chapter 14 in Web Mining: Applicationsand Techniques.
Ed.
Anthony Scime.
New York: IdeaGroup Publishing, 2005.
307-321.Brill, E. and Cucerzan, S. 2004.
Spelling correction as aniterative process that exploits the collective knowledgeof web users.
Proceedings of EMNLP 04.
293-300.Brill, E. and Moore, R. 2000.
An improved error modelfor noisy channel spelling correction.
Proceedings ofthe 38th Annual Meeting of the Association for Com-putational Linguistics.
286 - 293.Damerau, F. March 1964.
A technique for computerdetection and correction of spelling errors.
Communi-cations of the ACM.
7(3):171-176.Kernighan, M., Church, K., and Gale, W. 1990.
Aspelling correction program based on a noisy channelmodel.
Proceedings of COLING 1990.
205-210.Kucich, K. 1992.
Techniques for automatically cor-recting words in text.
ACM Computing Surveys.24(4):377-439.Philips, L. 1990.
Hanging on the metaphone.
ComputerLanguage Magazine.
7(12):39.Ristad, E. and Yianilos, P. 1997.
Learning string editdistance.
IEEE Transactions on Pattern Analysis andMachine Intelligence.
20(5):522-532.Toutanova, K. and Moore, R. 2002.
Pronunciation mod-eling for improved spelling correction.
Proceedings ofthe 40th Annual Meeting of the Association for Com-putational Linguistics.
144-151.Wagner, R. and Fischer, M. January 1974.
The string-to-string correction problem.
Journal of the ACM.21(1):168-173.Wu, S. and Manber, U.
1992.
Fast text searching allow-ing errors.
Communications of the ACM.
35(10):83-91962
