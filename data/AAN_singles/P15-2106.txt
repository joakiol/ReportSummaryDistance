Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 644?650,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsTowards a Contextual Pragmatic Model to Detect Irony in TweetsJihen KarouiIRIT, MIRACLToulouse University, Sfax Universitykaroui@irit.frFarah Benamara ZitouneIRIT, CNRSToulouse Universitybenamara@irit.frV?eronique MoriceauLIMSI-CNRSUniv.
Paris-Sudmoriceau@limsi.frNathalie Aussenac-GillesIRIT, CNRSNathalie.Aussenac-Gilles@irit.frLamia Hadrich BelguithMIRACLUniversity of Sfaxl.belguith@fsegs.rnu.tnAbstractThis paper proposes an approach to capturethe pragmatic context needed to infer irony intweets.
We aim to test the validity of two mainhypotheses: (1) the presence of negations, asan internal propriety of an utterance, can helpto detect the disparity between the literal andthe intended meaning of an utterance, (2) atweet containing an asserted fact of the formNot(P1) is ironic if and only if one can assessthe absurdity of P1.
Our first results are en-couraging and show that deriving a pragmaticcontextual model is feasible.1 MotivationIrony is a complex linguistic phenomenon widely stud-ied in philosophy and linguistics (Grice et al., 1975;Sperber and Wilson, 1981; Utsumi, 1996).
Despite the-ories differ on how to define irony, they all commonlyagree that it involves an incongruity between the literalmeaning of an utterance and what is expected about thespeaker and/or the environment.
For many researchers,irony overlaps with a variety of other figurative devicessuch as satire, parody, and sarcasm (Clark and Gerrig,1984; Gibbs, 2000).
In this paper, we use irony as anumbrella term that covers these devices focusing for thefirst time on the automatic detection of irony in Frenchtweets.According to (Grice et al., 1975; Searle, 1979; At-tardo, 2000), the search for a non-literal meaning startswhen the hearer realizes that the speaker?s utteranceis context-inappropriate, that is an utterance fails tomake sense against the context.
For example, the tweet:?Congratulation #lesbleus for your great match!?
isironic if the French soccer team has lost the match.
Ananalysis of a corpus of French tweets shows that thereare two ways to infer such a context: (a) rely exclu-sively on the lexical clues internal to the utterance, or(b) combine these clues with an additional pragmaticcontext external to the utterance.
In (a), the speaker in-tentionally creates an explicit juxtaposition of incom-patible actions or words that can either have oppositepolarities, or can be semantically unrelated, as in ?TheVoice is more important than Fukushima tonight?.
Ex-plicit opposition can also arise from an explicit posi-tive/negative contrast between a subjective propositionand a situation that describes an undesirable activity orstate.
For instance, in ?
I love when my phone turns thevolume down automatically?
the writer assumes thatevery one expects its cell phone to ring loud enoughto be heard.
In (b), irony is due to an implicit opposi-tion between a lexicalized proposition P describing anevent or state and a pragmatic context external to theutterance in which P is false or is not likely to happen.In other words, the writer asserts or affirms P whilehe intends to convey P?such that P?= Not(P ) orP?6= P .
The irony occurs because the writer believesthat his audience can detect the disparity between Pand P?on the basis of contextual knowledge or com-mon background shared with the writer.
For example,in ?#Hollande is really a good diplomat #Algeria.
?, thewriter critics the foreign policy of the French presidentHollande in Algeria, whereas in ?The #NSA wiretappeda whole country.
No worries for #Belgium: it is not awhole country.
?, the irony occurs because the fact inbold font is not true.Irony detection is quite a hot topic in the researchcommunity also due to its importance for efficientsentiment analysis (Ghosh et al., 2015).
Several ap-proaches have been proposed to detect irony castingthe problem into a binary classification task relyingon a variety of features.
Most of them are gleanedfrom the utterance internal context going from n-gramsmodels, stylistic (punctuation, emoticons, quotations,etc.
), to dictionary-based features (sentiment and af-fect dictionaries, slang languages, etc.).
These fea-tures have shown to be useful to learn whether a textspan is ironic/sarcastic or not (Burfoot and Baldwin,2009; Davidov et al., 2010; Tsur et al., 2010; Gonzalez-Ibanez et al., 2011; Reyes et al., 2013; Barbieri andSaggion, 2014).
However, many authors pointed outthe necessity of additional pragmatic features: (Ut-sumi, 2004) showed that opposition, rhetorical ques-tions and the politeness level are relevant.
(Burfootand Baldwin, 2009) focused on satire detection innewswire articles and introduced the notion of valid-ity which models absurdity by identifying a conjunc-644tion of named entities present in a given document andqueries the web for the conjunction of those entities.
(Gonzalez-Ibanez et al., 2011) exploited the commonground between speaker and hearer by looking if atweet is a reply to another tweet.
(Reyes et al., 2013)employed opposition in time (adverbs of time such asnow and suddenly) and context imbalance to estimatethe semantic similarity of concepts in a text to eachother.
(Barbieri and Saggion, 2014) captured the gapbetween rare and common words as well as the use ofcommon vs. rare synonyms.
Finally, (Buschmeier etal., 2014) measured the imbalance between the overallpolarity of words in a review and the star-rating.
Mostof these pragmatic features rely on linguistic aspects ofthe tweet by using only the text of the tweet.
We aimhere to go further by proposing a novel computationalmodel able to capture the ?outside of the utterance?context needed to infer irony in implicit oppositions.2 MethodologyAn analysis of a corpus of French ironic tweets ran-domly chosen from various topics shows that morethan 62.75% of tweets contain explicit negation mark-ers such as ?ne...pas?
(not) or negative polarity itemslike ?jamais?
(never) or ?personne?
(nobody).
Nega-tion seems thus to be an important clue in ironic state-ments, at least in French.
This rises the following hy-potheses: (H1) the presence of negations, as an internalpropriety of an utterance, can help to detect the dis-parity between the literal and the intended meaning ofan utterance, and (H2) a tweet containing an assertedfact of the form Not(P ) is ironic if and only if onecan prove P on the basis of some external commonknowledge to the utterance shared by the author andthe reader.To test the validity of the above hypotheses, we pro-pose a novel three-step model involving three succes-sive stages: (1) detect if a tweet is ironic or not relyingexclusively on the information internal to the tweet.
Weuse a supervised learning method relying on both stateof the art features whose efficiency has been empiri-cally proved and new groups of features.
(2) Test thisinternal context against the ?outside of the utterance?context.
We design an algorithm that takes the clas-sifier?s outputs and corrects the misclassified ironic in-stances of the formNot(P ) by looking forP in reliableexternal sources of information on the Web, such asWikipedia or online newspapers.
We experiment whenlabels are given by gold standard annotations and whenthey are predicted by the classifier.
(3) If the literalmeaning fails to make sense, i.e.
P is found, then thetweet is likely to convey a non-literal meaning.To this end, we collected a corpus of 6,742 Frenchtweets using the Tweeter API focusing on tweets rel-ative to a set of topics discussed in the media duringSpring 2014.
Our intuition behind choosing such top-ics is that a media-friendly topic is more likely to befound in external sources of information.
We chose184 topics split into 9 categories (politics, sport, etc.
).For each topic, we selected a set of keywords withand without hashtag: politics (e.g.
Sarkozy, Hollande,UMP), health (e.g.
cancer, flu), sport (e.g.
#Zlatan,#FIFAworldcup), social media (e.g.
#Facebook, Skype,MSN), artists (e.g.
Rihanna, Beyonc?e), TV shows (e.g.TheVoice, XFactor), countries or cities (e.g.
NorthKo-rea, Brasil), the Arab Spring (e.g.
Marzouki, BenAli) and some other generic topics (e.g.
pollution,racism).
Then we selected ironic tweets containing thetopic keywords, the #ironie or #sarcasme hashtag and anegation word as well as ironic tweets containing onlythe topic keywords with #ironie or #sarcasme hashtagbut no negation word.
Finally, we selected non ironictweets that contained either the topic keywords and anegation word, or only the topic keywords.
We re-moved duplicates, retweets and tweets containing pic-tures which would need to be interpreted to understandthe ironic content.
Irony hashtags (#ironie or #sar-casme) are removed from the tweets for the followingexperiments.
To guarantee that tweets with negationwords contain true negations, we automatically identi-fied negation usage of a given word using a French syn-tactic dependency parser1.
We then designed dedicatedrules to correct the parser?s decisions if necessary.
Atthe end, we got a total of 4,231 tweets with negationand 2,511 without negation, among them, 30.42% areironic with negation and 72.36% are non ironic withnegation.
At the end, we got a total of 4,231 tweets withnegation and 2,511 without negation: among them,30.42% are ironic with negation and 72.36% are nonironic with negation.
To capture the effect of nega-tion on our task, we split these tweets in three cor-pora: tweets with negation only (NegOnly), tweets withno negation (NoNeg), and a corpus that gathers all thetweets of the previous 2 corpora (All).
Table 1 showsthe repartition of tweets in our corpora.Corpus Ironic Non ironic TOTALNegOnly 470 3,761 4,231NoNeg 1,075 1,436 2,511All 1,545 5,197 6,742Table 1: Tweet repartition.3 Binary classifierWe experiment with SMO under the Weka toolkit withstandard parameters.
We also evaluated other learningalgorithms (naive bayes, decision trees, logistic regres-sion) but the results were not as good as those obtainedwith SMO.
We have built three classifiers, one for eachcorpus, namely CNeg, CNoNeg, and CAll.
Since thenumber of ironic instances in the first corpus is rela-tively small, we learnCNegwith 10-cross validation ona balanced subset of 940 tweets.
For the second and thelast classifiers, we used 80% of the corpus for training1We have used Malt as a syntactic parser.645and 20% for test, with an equal distribution betweenthe ironic (henceforth IR) and non ironic (henceforthNIR) instances2.
The results presented in this paperhave been obtained when training CNoNegon 1,720and testing on 430 tweets.
CAllhas been trained on2,472 tweets (1432 contain negation ?404 IR and 1028NIR) and tested on 618 tweets (360 contain negation ?66 IR and 294 NIR).
For each classifier, we representeach tweet with a vector composed of six groups of fea-tures.
Most of them are state of the art features, others,in italic font are new.Surface features include tweet length in words(Tsur et al., 2010), the presence or absence of punc-tuation marks (Gonzalez-Ibanez et al., 2011), wordsin capital letters (Reyes et al., 2013), interjections(Gonzalez-Ibanez et al., 2011), emoticons (Buschmeieret al., 2014), quotations (Tsur et al., 2010), slang words(Burfoot and Baldwin, 2009), opposition words such as?but?
and ?although?
(Utsumi, 2004), a sequence of ex-clamation or a sequence of question marks (Carvalho etal., 2009), a combination of both exclamation and ques-tion marks (Buschmeier et al., 2014) and finally, thepresence of discourse connectives that do not conveyopposition such as ?hence, therefore, as a result?
sincewe assume that non ironic tweets are likely to be moreverbose.
To implement these features, we rely on man-ually built French lexicons to deal with interjections,emoticons, slang language, and discourse connectives(Roze et al., 2012).Sentiment features consist of features that check forthe presence of positive/negative opinion words (Reyesand Rosso, 2012) and the number of positive and neg-ative opinion words (Barbieri and Saggion, 2014).
Weadd three new features: the presence of words that ex-press surprise or astonishment, and the presence andthe number of neutral opinions.
To get these featureswe use two lexicons: CASOAR, a French opinion lexi-con (Benamara et al., 2014) and EMOTAIX, a publiclyavailable French emotion and affect lexicon.Sentiment shifter features group checks if a giventweet contains an opinion word which is in the scope ofan intensifier adverb or a modality.Shifter features tests if a tweet contains an intensi-fier (Liebrecht et al., 2013), a negation word (Reyes etal., 2013), or reporting speech verbs.Opposition features are new and check for the pres-ence of specific lexico-syntactic patterns that verifywhether a tweet contains a sentiment opposition or anexplicit positive/negative contrast between a subjectiveproposition and an objective one.
These features havebeen partly inspired from (Riloff et al., 2013) whoproposed a bootstrapping algorithm to detect sarcas-tic tweets of the form [P+].
[P?obj] which correspondsto a contrast between positive sentiment and an ob-jective negative situation.
We extended this pattern to2For CNoNegand CAll, we also tested 10-cross valida-tion with a balanced distribution between the ironic and non-ironic instances but results were not conclusive.capture additional types of explicit oppositions.
Someof our patterns include: [Neg(P+)].
[P?+], [P?].[P?+],[Neg(P+)].
[P?obj], [P?obj].[P?].
We consider that anopinion expression is under the scope of a negation if itis separated by a maximum of two tokens.Finally, internal contextual deals with the pres-ence/absence of personal pronouns, topic keywords andnamed entities, as predicted by the parser?s outputs.For each classifier, we investigated how each groupof features contributes to the learning process.
Weapplied to each training set a feature selection algo-rithm (Chi2 and GainRatio), then trained the classifiersover all relevant features of each group3.
In all experi-ments, we used all surface features as baseline.
Table 2presents the result in terms of precision (P), recall (R),macro-averaged F-score (MAF) and accuracy (A).
Wecan see that CAllachieves better results.
An analysisof the best features combination for each classifier sug-gests four main conclusions: (1) surface features areprimordial for irony detection.
This is more salient forNoNeg.
(2) Negation is an important feature for ourtask.
However, having it alone is not enough to findironic instances.
Indeed, among the 76 misclassified in-stances inCAll, 60% contain negation clues (37 IR and9 NIR).
(3) When negation is concerned, oppositionfeatures are among the most productive.
(4) Explicitopinion words (i.e sentiment and sentiment shifter) arelikely to be used in tweets with no negation.
More im-portantly, these results empirically validate hypothesis(H1), i.e.
negation is a good clue to detect irony.Ironic (IR) Not ironic (NIR)P R F P R FCNeg88.9 56.0 68.7 67.9 93.3 78.5CNoNeg71.1 65.1 68.0 67.80 73.50 70.50CAll93.0 81.6 86.9 83.6 93.9 88.4Overall ResultsMAF ACNeg73.6 74.5CNoNeg69.2 69.3CAll87.6 87.7Table 2: Results for the best features combination.Error analysis shows that misclassification of ironicinstances is mainly due to four factors: presence of sim-iles (ironic comparison)4, absence of context within theutterance (most frequent case), humor and satire5, andwrong #ironie or #sarcasme tags.
The absence of con-text can manifest itself in several ways: (1) there isno pointer that helps to identify the main topic of thetweet, as in ?I?ve been missing her, damn!?.
Even if thetopic is present, it is often lexicalized in several col-lapsed words or funny hashtags (#baddays, #aprilfoll),3Results with all features are lower.4e.g.
?Benzema in the French team is like Sunday.
He isof no use.. :D?5e.g.
?I propose that we send Hollande instead of thespace probes on the next comet, it will save time and money;) #HUMOUR?646which are hard to automatically analyze.
(2) The ironyis about specific situations (Shelley, 2001).
(3) Falseassertions about hot topics, like in ?Don?t worry.
Sene-gal is the world champion soccer?.
(4) Oppositions thatinvolve a contradiction between two words that are se-mantically unrelated, a named entity and a given event(e.g.
?Tchad and ?democratic election?
), etc.
Case (4)is more frequent in the NoNeg corpus.Knowing that tweets with negation represent 62.75%of our corpus, and given that irony can focus on thenegation of a word or a proposition (Haverkate, 1990),we propose to improve the classification of these tweetsby identifying the absurdity of their content, follow-ing Attardo?s relevant inappropriateness model of irony(Attardo, 2000) in which a violation of contextual ap-propriateness signals ironical intent.4 Deriving the pragmatic contextThe proposed model included two parts: binary classi-fiers trained with tweet features, and an algorithm thatcorrects the outputs of the classifiers which are likelyto be misclassified.
These two phases can be appliedsuccessively or together.
In this latter case, the algo-rithm outputs are integrated into the classifiers and thecorrected instances are used in the training process ofthe binary classifier.
In this paper, we only present re-sults of the two phases applied successively because itachieved better results.Our approach is to query Google via its API to checkthe veracity of tweets with negation that have beenclassified as non ironic by the binary classifier in or-der to correct the misclassified tweets (if a tweet say-ing Not(P ) has been classified as non-ironic but P isfound online, then we assume that the opposite contentis checked so the tweet class is changed into ironic).Let WordsT be the set of words excluding stop wordsthat belong to a tweet t, and let kw be the topic key-word used to collect t. Let N ?WordsT be the set ofnegation words of t. The algorithm is as follows:1.
Segment t into a set of sentences S.2.
For each s ?
S such that ?neg ?
N and neg ?
s:2.1 Remove # and @ symbols, emoticons, and neg,then extract the set of tokens P ?
s that are on thescope of neg (in a distance of 2 tokens).2.2 Generate a query Q1= P ?
kw and submit it toGoogle which will return 20 results (title+snippet) orless.2.3 Among the returned results, keep only the reliableones (Wikipedia, online newspapers, web sites that donot contain ?blog?
or ?twitter?
in their URL).
Then,for each result, if the query keywords are found in thetitle or in the snippet, then t is considered as ironic.STOP.3.
Generate a second queryQ2= (WordsT?N)?kwand submit it again to Google and follow the procedurein 2.3.
If Q2is found, then t is considered as ironic.Otherwise, the class predicted by the classifier does notchange.Let us illustrate our algorithm with the topic Vallsand the tweet: #Valls has learnt that Sarkozy waswiretapped in newspapers.
Fortunately he is notthe interior minister.
The first step leads to twosentences s1(#Valls has learnt that Sarkozy waswiretapped in newspapers.)
and s2(Fortunatelyhe is not the interior minister).
From s2, we re-move the negation word ?not?, isolate the negationscope P = {interior, minister} and generatethe query Q1= {V alls interior minister}.The step 2.3 allows to retrieve the result:<Title>Manuel Valls - Wikipedia, the free encyclope-dia</Title><Snippet>... French politician.
For the Spanish com-poser, see Manuel Valls (composer).
.... Valls was ap-pointed Minister of the Interior in the Ayrault Cabinetin May 2012.</Snippet>.All query keywords were found in this snippet (in boldfont), we can then conclude that the tweet is ironic.We made several experiments to evaluate how thequery-based method improves tweet classification.
Forthis purpose, we have applied the method on both cor-pora All and Neg: ?
A first experiment evaluates themethod on tweets with negation classified as NIR butwhich are ironic according to gold annotations.
Thisexperiment represents an ideal case which we try toachieve or improve through other ones.
?
: A sec-ond experiment consists in applying the method on alltweets with negation that have been classified as NIRby the classifier, no matter if the predicted class is cor-rect or not.
Table 3 shows the results for both experi-ments.?
?NIR tweets for which: All Neg All NegQuery applied 37 207 327 644Results on Google 25 102 166 331Class changed into IR 5 35 69 178Classifier Accuracy 87.7 74.46 87.7 74.46Query-based Accuracy 88.51 78.19 78.15 62.98Table 3: Results for the query-based method.All scores for the query-based method are statis-tically significant compared to the classifier?s scores(p value < 0, 0001 when calculated with the McNe-mar?s test.).
An error analysis shows that 65% of tweetsthat are still misclassified with this method are tweetsfor which finding their content online is almost impos-sible because they are personal tweets or lack internalcontext.
A conclusion that can be drawn is that thismethod should not be applied on this type of tweets.For this purpose, we made the same experiments onlyon tweets with different combinations of relevant fea-tures.
The best results are obtained when the method isapplied only on NIR tweets with negation selected viathe internal context features, more precisely on tweetswhich do not contain a personal pronoun and whichcontain named entities: these results are coherent with647the fact that tweets containing personal pronouns andno named entity are likely to relate personal content im-possible to validate on the Web (e.g.
I?ve been missingher, damn!
#ironie).
Table 4 shows the results for theseexperiments.
All scores for the query-based method arealso statistically significant compared to the classifier?sscores.?
?NIR tweets for which: All Neg All NegQuery applied 0 18 40 18Results on Google - 12 17 12Class changed into IR - 4 7 4Classifier Accuracy 87.7 74.46 87.7 74.46Query-based Accuracy 87.7 74.89 86.57 74.89Table 4: Results when applied on ?non-personal?tweets.For experiment ?, on All, the method is not appliedbecause all misclassified tweets contain a personal pro-noun and no named entity.
The query-based methodoutperforms the classifier in all cases, except on Allwhere results on Google were found for only 42.5%of queries whereas more than 50% of queries foundresults in all other experiments (maximum is 66.6%in NegOnly).
Tweets for which no result is found aretweets with named entities but which do not relate anevent or a statement (e.g.
AHAHAHAHAHA!
NO RE-SPECT #Legorafi, where ?Legorafi?
is a satirical news-paper).
To evaluate the task difficulty, two annotatorswere also asked to label as ironic or not the 50 tweets(40+18) for which the method is applied.
The inter-annotator score (Cohen?s Kappa) between both anno-tators is only ?
= 0.41.
Among the 12 reclassifica-tions into IR, both annotators disagree with each otherfor 5 of them.
Even if this experiment is not strongenough to lead to a formal conclusion because of thesmall number of tweets, this tends to show that humanbeings would not do it better.It is interesting to note that even if internal contextfeatures were not relevant for automatic tweet classifi-cation, our results show that they are useful for classifi-cation improvement.
As shown by ?, the query-basedmethod is more effective when applied on misclassi-fied tweets.
We can then consider that using internalcontextual features (presence of personal pronouns andnamed entities) can be a way to automatically detecttweets that are likely to be misclassified.5 Discussion and conclusionsThis paper proposed a model to identify irony in im-plicit oppositions in French.
As far as we know, thisis the first work on irony detection in French on Twit-ter data.
Comparing to other languages, our resultsare very encouraging.
For example, sarcasm detectionachieved 30% precision in Dutch tweets (Liebrecht etal., 2013) while irony detection in English data resultedin 79% precision (Reyes et al., 2013).We treat French irony as an overall term that coversother figurative language devices such as sarcasm, hu-mor, etc.
This is a first step before moving to a morefine-grained automatic identification of figurative lan-guage in French.
For interesting discussions on the dis-tinction/similarity between irony and sarcasm hastags,see (Wang, 2013).One of the main contribution of this study is that theproposed model does not rely only on the lexical cluesof a tweet, but also on its pragmatic context.
Our in-tuition is that a tweet containing an asserted fact of theform Not(P1) is ironic if and only if one can prove P1on the basis of some external information.
This form oftweets is quite frequent in French (more than 62.75% ofour data contain explicit negation words), which sug-gests two hypotheses: (H1) negation can be a good in-dicator to detect irony, and (H2) external context canhelp to detect the absurdity of ironic content.To validate if negation helps, we built binary clas-sifiers using both state of the art features and newfeatures (explicit and implicit opposition, sentimentshifter, discourse connectives).
Overall accuracieswere good when the data contain both tweets withnegation and no negation but lower when tweets con-tain only negation or no negation at all.
Error anal-ysis show that major errors come from the presenceof implicit oppositions, particularly in CNegand CAll.These results empirically validate hypothesis (H1).Negation has been shown to be very helpful in manyNLP tasks, such as sentiment analysis (Wiegand et al.,2010).
It has also been used as a feature to detect irony(Reyes et al., 2013).
However, no one has empiricallymeasured how irony classification behaves in the pres-ence or absence of negation in the data.To test (H2), we proposed a query-based method thatcorrects the classifier?s outputs in order to retrieve falseassertions.
Our experiments show that the classificationafter applying Google searches in reliable web sites sig-nificantly improves the classifier accuracy when testedon CNeg.
In addition, we show that internal contextfeatures are useful to improve classification.
These re-sults empirically validate (H2).
However, even thoughthe algorithm improves the classifier performance, thenumber of queries is small which suggests that a muchlarger dataset is needed.
As for negation, querying ex-ternal source of information has been shown to givean improvement over the basic features for many NLPtasks (for example, in question-answering (Moldovanet al., 2002)).
However, as far as we know, this ap-proach has not been used for irony classification.This study is a first step towards improving irony de-tection relying on external context.
We plan to studyother ways to retrieve such a context like the conversa-tion thread.AcknowledgementsThis work was funded by the French National ResearchAgency (ASFALDA project ANR-12-CORD-023).648ReferencesSalvatore Attardo.
2000.
Irony as relevant inappropri-ateness.
Journal of pragmatics, 32(6):793?826.Francesco Barbieri and Horacio Saggion.
2014.
Mod-elling Irony in Twitter: Feature Analysis and Eval-uation.
In Proceedings of Language Resources andEvaluation Conference (LREC), pages 4258?4264.Farah Benamara, V?eronique Moriceau, andYvette Yannick Mathieu.
2014.
Fine-grainedsemantic categorization of opinion expressions forconsensus detection (Cat?egorisation s?emantiquefine des expressions d?opinion pour la d?etection deconsensus) [in French].
In TALN-RECITAL 2014Workshop DEFT 2014 : D?Efi Fouille de Textes(DEFT 2014 Workshop: Text Mining Challenge),pages 36?44, July.Clint Burfoot and Clint Baldwin.
2009.
Automaticsatire detection: Are you having a laugh?
In Pro-ceedings of the ACL-IJCNLP 2009 conference shortpapers, pages 161?164.
Association for Computa-tional Linguistics.Konstantin Buschmeier, Philipp Cimiano, and RomanKlinger.
2014.
An Impact Analysis of Features in aClassification Approach to Irony Detection in Prod-uct Reviews.
In Proceedings of the 5th Workshopon Computational Approaches to Subjectivity, Senti-ment and Social Media Analysis, pages 42?49.Paula Carvalho, Lu?
?s Sarmento, M?ario J Silva, andEug?enio De Oliveira.
2009.
Clues for detect-ing irony in user-generated contents: oh...!!
it?sso easy;-).
In Proceedings of the 1st internationalCIKM workshop on Topic-sentiment analysis formass opinion, pages 53?56.
ACM.Herbert H Clark and Richard J Gerrig.
1984.
On thepretense theory of irony.
Journal of ExperimentalPsychology: General, 113(1):121?126.Dmitry Davidov, Oren Tsur, and Ari Rappoport.
2010.Semi-supervised Recognition of Sarcastic Sentencesin Twitter and Amazon.
In Proceedings of the Four-teenth Conference on Computational Natural Lan-guage Learning, CoNLL ?10, pages 107?116.Aniruddha Ghosh, Guofu Li, Tony Veale, Paolo Rosso,Ekaterina Shutova, John Barnden, and AntonioReyes.
2015.
Semeval-2015 task 11: SentimentAnalysis of Figurative Language in Twitter.
In Proc.9th Int.
Workshop on Semantic Evaluation (SemEval2015), Co-located with NAACL, page 470478.
Asso-ciation for Computational Linguistics.Raymond W Gibbs.
2000.
Irony in talk among friends.Metaphor and symbol, 15(1-2):5?27.Roberto Gonzalez-Ibanez, Smaranda Muresan, andNina Wacholde.
2011.
Identifying sarcasm in Twit-ter: a closer look.
In Proceedings of the 49th An-nual Meeting of the Association for ComputationalLinguistics: Human Language Technologies: shortpapers-Volume 2, pages 581?586.
Association forComputational Linguistics.H Paul Grice, Peter Cole, and Jerry L Morgan.
1975.Syntax and semantics.
Logic and conversation,3:41?58.Henk Haverkate.
1990.
A speech act analysis of irony.Journal of Pragmatics, 14(1):77 ?
109.Christine Liebrecht, Florian Kunneman, andBosch Antal van den.
2013.
The perfect so-lution for detecting sarcasm in tweets# not.
InProceedings of the 4th Workshop on ComputationalApproaches to Subjectivity, Sentiment and SocialMedia Analysis, pages 29?37.
New Brunswick, NJ:ACL.Dan I Moldovan, Sanda M Harabagiu, Roxana Girju,Paul Morarescu, V Finley Lacatusu, Adrian Novis-chi, Adriana Badulescu, and Orest Bolohan.
2002.LCC Tools for Question Answering.
In TREC.Antonio Reyes and Paolo Rosso.
2012.
Making objec-tive decisions from subjective data: Detecting ironyin customer reviews.
Decision Support Systems,53(4):754?760.Antonio Reyes, Paolo Rosso, and Tony Veale.
2013.A multidimensional approach for detecting ironyin twitter.
Language resources and evaluation,47(1):239?268.Ellen Riloff, Ashequl Qadir, Prafulla Surve, Lalin-dra De Silva, Nathan Gilbert, and Ruihong Huang.2013.
Sarcasm as Contrast between a Positive Sen-timent and Negative Situation.
In EMNLP, pages704?714.Charlotte Roze, Laurence Danlos, and Philippe Muller.2012.
Lexconn: A French lexicon of discourse con-nectives.
Discours, Multidisciplinary Perspectiveson Signalling Text Organisation, 10:(on line).J.
Searle.
1979.
Expression and meaning: Studies inthe theory of speech acts.
Cambridge University.Cameron Shelley.
2001.
The bicoherence theory ofsituational irony.
Cognitive Science, 25(5):775?818.Dan Sperber and Deirdre Wilson.
1981.
Irony andthe use-mention distinction.
Radical pragmatics,49:295?318.Oren Tsur, Dmitry Davidov, and Ari Rappoport.
2010.ICWSM-A Great Catchy Name: Semi-SupervisedRecognition of Sarcastic Sentences in Online Prod-uct Reviews.
In ICWSM.Akira Utsumi.
1996.
A unified theory of irony andits computational formalization.
In Proceedings ofthe 16th conference on Computational linguistics-Volume 2, pages 962?967.
Association for Compu-tational Linguistics.Akira Utsumi.
2004.
Stylistic and contextual effectsin irony processing.
In Proceedings of the 26th An-nual Meeting of the Cognitive Science Society, pages1369?1374.649Po-Ya Angela Wang.
2013.
#Irony or #Sarcasm-AQuantitative and Qualitative Study Based on Twitter.Michael Wiegand, Alexandra Balahur, Benjamin Roth,Dietrich Klakow, and Andr?es Montoyo.
2010.
ASurvey on the Role of Negation in Sentiment Analy-sis.
In Proceedings of the Workshop on Negation andSpeculation in Natural Language Processing, pages60?68.
Association for Computational Linguistics.650
