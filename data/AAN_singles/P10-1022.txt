Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 207?215,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsRebanking CCGbank for improved NP interpretationMatthew Honnibal and James R. CurranSchool of Information TechnologiesUniversity of SydneyNSW 2006, Australia{mhonn,james}@it.usyd.edu.auJohan BosUniversity of GroningenThe Netherlandsbos@meaningfactory.comAbstractOnce released, treebanks tend to remainunchanged despite any shortcomings intheir depth of linguistic analysis or cover-age of specific phenomena.
Instead, sepa-rate resources are created to address suchproblems.
In this paper we show how toimprove the quality of a treebank, by in-tegrating resources and implementing im-proved analyses for specific constructions.We demonstrate this rebanking processby creating an updated version of CCG-bank that includes the predicate-argumentstructure of both verbs and nouns, base-NP brackets, verb-particle constructions,and restrictive and non-restrictive nominalmodifiers; and evaluate the impact of thesechanges on a statistical parser.1 IntroductionProgress in natural language processing relies ondirect comparison on shared data, discouragingimprovements to the evaluation data.
This meansthat we often spend years competing to reproducepartially incorrect annotations.
It also encouragesus to approach related problems as discrete tasks,when a new data set that adds deeper informationestablishes a new incompatible evaluation.Direct comparison has been central to progressin statistical parsing, but it has also caused prob-lems.
Treebanking is a difficult engineering task:coverage, cost, consistency and granularity are allcompeting concerns that must be balanced againsteach other when the annotation scheme is devel-oped.
The difficulty of the task means that weought to view treebanking as an ongoing processakin to grammar development, such as the manyyears of work on the ERG (Flickinger, 2000).This paper demonstrates how a treebank can berebanked to incorporate novel analyses and infor-mation from existing resources.
We chose to workon CCGbank (Hockenmaier and Steedman, 2007),a Combinatory Categorial Grammar (Steedman,2000) treebank acquired from the Penn Treebank(Marcus et al, 1993).
This work is equally ap-plicable to the corpora described by Miyao et al(2004), Shen et al (2008) or Cahill et al (2008).Our first changes integrate four previously sug-gested improvements to CCGbank.
We then de-scribe a novel CCG analysis of NP predicate-argument structure, which we implement usingNomBank (Meyers et al, 2004).
Our analysis al-lows the distinction between core and peripheralarguments to be represented for predicate nouns.With this distinction, an entailment recognitionsystem could recognise that Google?s acquisitionof YouTube entailed Google acquired YouTube, be-cause equivalent predicate-argument structures arebuilt for both.
Our analysis also recovers non-local dependencies mediated by nominal predi-cates; for instance, Google is the agent of acquirein Google?s decision to acquire YouTube.The rebanked corpus extends CCGbank with:1.
NP brackets from Vadas and Curran (2008);2.
Restored and normalised punctuation;3.
Propbank-derived verb subcategorisation;4.
Verb particle structure drawn from Propbank;5.
Restrictive and non-restrictive adnominals;6.
Reanalyses to promote better head-finding;7.
Nombank-derived noun subcategorisation.Together, these changes modify 30% of the la-belled dependencies in CCGbank, demonstratinghow multiple resources can be brought together ina single, richly annotated corpus.
We then trainand evaluate a parser for these changes, to investi-gate their impact on the accuracy of a state-of-the-art statistical CCG parser.2072 Background and motivationFormalisms like HPSG (Pollard and Sag, 1994),LFG (Kaplan and Bresnan, 1982), and CCG (Steed-man, 2000) are linguistically motivated in thesense that they attempt to explain and predictthe limited variation found in the grammars ofnatural languages.
They also attempt to spec-ify how grammars construct semantic representa-tions from surface strings, which is why they aresometimes referred to as deep grammars.
Anal-yses produced by these formalisms can be moredetailed than those produced by skeletal phrase-structure parsers, because they produce fully spec-ified predicate-argument structures.Unfortunately, statistical parsers do not take ad-vantage of this potential detail.
Statistical parsersinduce their grammars from corpora, and thecorpora for linguistically motivated formalismscurrently do not contain high quality predicate-argument annotation, because they were derivedfrom the Penn Treebank (PTB Marcus et al, 1993).Manually written grammars for these formalisms,such as the ERG HPSG grammar (Flickinger, 2000)and the XLE LFG grammar (Butt et al, 2006)produce far more detailed and linguistically cor-rect analyses than any English statistical parser,due to the comparatively coarse-grained annota-tion schemes of the corpora statistical parsers aretrained on.
While rule-based parsers use gram-mars that are carefully engineered (e.g.
Oepenet al, 2004), and can be updated to reflect the bestlinguistic analyses, statistical parsers have so farhad to take what they are given.What we suggest in this paper is that a tree-bank?s grammar need not last its lifetime.
For astart, there have been many annotations of the PTBthat add much of the extra information needed toproduce very high quality analyses for a linguis-tically motivated grammar.
There are also othertransformations which can be made with no addi-tional information.
That is, sometimes the existingtrees allow transformation rules to be written thatimprove the quality of the grammar.Linguistic theories are constantly changing,which means that there is a substantial lag betweenwhat we (think we) understand of grammar andthe annotations in our corpora.
The grammar en-gineering process we describe, which we dub re-banking, is intended to reduce this gap, tighteningthe feedback loop between formal and computa-tional linguistics.2.1 Combinatory Categorial GrammarCombinatory Categorial Grammar (CCG; Steed-man, 2000) is a lexicalised grammar, which meansthat all grammatical dependencies are specifiedin the lexical entries and that the production ofderivations is governed by a small set of rules.Lexical categories are either atomic (S , NP ,PP , N ), or a functor consisting of a result, direc-tional slash, and argument.
For instance, in mighthead a PP -typed constituent with one NP -typedargument, written as PP/NP .A category can have a functor as its result, sothat a word can have a complex valency structure.For instance, a verb phrase is represented by thecategory S\NP : it is a function from a leftwardNP (a subject) to a sentence.
A transitive verbrequires an object to become a verb phrase, pro-ducing the category (S\NP)/NP .A CCG grammar consists of a small number ofschematic rules, called combinators.
CCG extendsthe basic application rules of pure categorial gram-mar with (generalised) composition rules and typeraising.
The most common rules are:X /Y Y ?
X (>)Y X \Y ?
X (<)X /Y Y /Z ?
X /Z (>B)Y \Z X \Y ?
X \Z (<B)Y /Z X \Y ?
X /Z (<B?
)CCGbank (Hockenmaier and Steedman, 2007)extends this compact set of combinatory rules witha set of type-changing rules, designed to strike abetter balance between sparsity in the category setand ambiguity in the grammar.
We mark type-changing rules TC in our derivations.In wide-coverage descriptions, categories aregenerally modelled as typed-feature structures(Shieber, 1986), rather than atomic symbols.
Thisallows the grammar to include a notion of headed-ness, and to unify under-specified features.We occasionally must refer to these additionaldetails, for which we employ the following no-tation.
Features are annotated in square-brackets,e.g.
S [dcl ].
Head-finding indices are annotated oncategories in subscripts, e.g.
(NPy\NPy)/NPz .The index of the word the category is assigned tois left implicit.
We will sometimes also annotatederivations with the heads of categories as they arebeing built, to help the reader keep track of whatlexemes have been bound to which categories.2083 Combining CCGbank correctionsThere have been a few papers describing correc-tions to CCGbank.
We bring these corrections to-gether for the first time, before building on themwith our further changes.3.1 Compound noun bracketsCompound noun phrases can nest inside eachother, creating bracketing ambiguities:(1) (crude oil) prices(2) crude (oil prices)The structure of such compound noun phrasesis left underspecified in the Penn Treebank (PTB),because the annotation procedure involved stitch-ing together partial parses produced by the Fid-ditch parser (Hindle, 1983), which produced flatbrackets for these constructions.
The bracketingdecision was also a source of annotator disagree-ment (Bies et al, 1995).When Hockenmaier and Steedman (2002) wentto acquire a CCG treebank from the PTB, this poseda problem.
There is no equivalent way to leavethese structures under-specified in CCG, becausederivations must be binary branching.
They there-fore employed a simple heuristic: assume all suchstructures branch to the right.
Under this analysis,crude oil is not a constituent, producing an incor-rect analysis as in (1).Vadas and Curran (2007) addressed this bymanually annotating all of the ambiguous nounphrases in the PTB, and went on to use this infor-mation to correct 20,409 dependencies (1.95%) inCCGbank (Vadas and Curran, 2008).
Our changesbuild on this corrected corpus.3.2 Punctuation correctionsThe syntactic analysis of punctuation is noto-riously difficult, and punctuation is not alwaystreated consistently in the Penn Treebank (Bieset al, 1995).
Hockenmaier (2003) determinedthat quotation marks were particularly problem-atic, and therefore removed them from CCGbankaltogether.
We use the process described by Tseand Curran (2008) to restore the quotation marksand shift commas so that they always attach to theconstituent to their left.
This allows a grammarrule to be removed, preventing a great deal of spu-rious ambiguity and improving the speed of theC&C parser (Clark and Curran, 2007) by 37%.3.3 Verb predicate-argument correctionsSemantic role descriptions generally recognise adistinction between core arguments, whose rolecomes from a set specific to the predicate, and pe-ripheral arguments, who have a role drawn from asmall, generic set.
This distinction is representedin the surface syntax in CCG, because the categoryof a verb must specify its argument structure.
In(3) as a director is annotated as a complement; in(4) it is an adjunct:(3) HeNPjoined(S\NP)/PPas a directorPP(4) HeNPjoinedS\NPas a director(S\NP)\(S\NP)CCGbank contains noisy complement and ad-junct distinctions, because they were drawn fromPTB function labels which imperfectly representthe distinction.
In our previous work we usedPropbank (Palmer et al, 2005) to convert 1,543complements to adjuncts and 13,256 adjuncts tocomplements (Honnibal and Curran, 2007).
If aconstituent such as as a director received an ad-junct category, but was labelled as a core argu-ment in Propbank, we changed it to a comple-ment, using its head?s part-of-speech tag to inferits constituent type.
We performed the equivalenttransformation to ensure all peripheral argumentsof verbs were analysed as adjuncts.3.4 Verb-particle constructionsPropbank also offers reliable annotation of verb-particle constructions.
This was not available inthe PTB, so Hockenmaier and Steedman (2007)annotated all intransitive prepositions as adjuncts:(5) HeNPwokeS\NPup(S\NP)\(S\NP)We follow Constable and Curran (2009) in ex-ploiting the Propbank annotations to add verb-particle distinctions to CCGbank, by introducing anew atomic category PT for particles, and chang-ing their status from adjuncts to complements:(6) HeNPwoke(S\NP)/PTupPTThis analysis could be improved by adding extrahead-finding logic to the verbal category, to recog-nise the multi-word expression as the head.209Rome ?s gift of peace to EuropeNP (NP/(N /PP))\NP (N /PP)/PP)/PP PP/NP NP PP/NP NP< > >N /(N /PP) PP PP>(N /PP)/PP>N /PP>NPFigure 1: Deverbal noun predicate with agent, patient and beneficiary arguments.4 Noun predicate-argument structureMany common nouns in English can receiveoptional complements and adjuncts, realised byprepositional phrases, genitive determiners, com-pound nouns, relative clauses, and for some nouns,complementised clauses.
For example, deverbalnouns generally have argument structures similarto the verbs they are derived from:(7) Rome?s destruction of Carthage(8) Rome destroyed CarthageThe semantic roles of Rome and Carthage are thesame in (7) and (8), but the noun cannot case-mark them directly, so of and the genitive cliticare pressed into service.
The semantic role de-pends on both the predicate and subcategorisationframe:(9) Carthage?sp destructionPred.
(10) Rome?sa destructionPred.
of Carthagep(11) Rome?sa giftPred.
(12) Rome?sa giftPred.
of peacep to EuropebIn (9), the genitive introduces the patient, butwhen the patient is supplied by the PP, it insteadintroduces the agent.
The mapping differs for gift,where the genitive introduces the agent.Peripheral arguments, which supply genericallyavailable modifiers of time, place, cause, qualityetc, can be realised by pre- and post-modifiers:(13) The portrait in the Louvre(14) The fine portrait(15) The Louvre?s portraitsThese are distinct from core arguments becausetheir interpretation does not depend on the pred-icate.
The ambiguity can be seen in an NP such asThe nobleman?s portrait, where the genitive couldmark possession (peripheral), or it could introducethe patient (core).
The distinction between coreand peripheral arguments is particularly difficultfor compound nouns, as pre-modification is veryproductive in English.4.1 CCG analysisWe designed our analysis for transparency be-tween the syntax and the predicate-argumentstructure, by stipulating that all and only the corearguments should be syntactic arguments of thepredicate?s category.
This is fairly straightforwardfor arguments introduced by prepositions:destruction of CarthageN /PPy PPy/NPy NP>PPCarthage>NdestructionIn our analysis, the head of of Carthage isCarthage, as of is assumed to be a semanticallytransparent case-marker.
We apply this analysisto prepositional phrases that provide arguments toverbs as well ?
a departure from CCGbank.Prepositional phrases that introduce peripheralarguments are analysed as syntactic adjuncts:The war in 149 B.C.NPy/Ny N (Ny\Ny)/NPz NP>(Ny\Ny)in<Nwar>NPwarAdjunct prepositional phrases remain headed bythe preposition, as it is the preposition?s semanticsthat determines whether they function as temporal,causal, spatial etc.
arguments.
We follow Hocken-maier and Steedman (2007) in our analysis of gen-itives which realise peripheral arguments, such asthe literal possessive:Rome ?s aqueductsNP (NPy/Ny)\NPz N<(NPy/Ny)?s>NPaqueductsArguments introduced by possessives are a lit-tle trickier, because the genitive also functions asa determiner.
We achieve this by having the nounsubcategorise for the argument, which we typePP , and having the possessive subcategorise forthe unsaturated noun to ultimately produce an NP :210Google ?s decision to buy YouTubeNP (NPy/(Ny/PPz )y)\NPz (N /PPy)/(S [to]z\NPy)z (S [to]y\NPz )y/(S [b]y\NPz )y (S [b]\NPy)/NPz NP< >NPy/(Ny/PPGoogle)y S [b]\NPy>B >NPdecision/(S [to]y\NPGoogle)y S [to]buy\NPy>NPFigure 2: The coindexing on decision?s category allows the hard-to-reach agent of buy to be recovered.
A non-normal formderivation is shown so that instantiated variables can be seen.Carthage ?s destructionNP (NPy/(Ny/PPz )y)\NPz N /PPy<(NPy/(Ny/PPCarthage)y)?s>NPdestructionIn this analysis, we regard the genitive clitic as acase-marker that performs a movement operationroughly analogous to WH-extraction.
Its categoryis therefore similar to the one used in object ex-traction, (N \N )/(S/NP).
Figure 1 shows an ex-ample with multiple core arguments.This analysis allows recovery of verbal argu-ments of nominalised raising and control verbs, aconstruction which both Gildea and Hockenmaier(2003) and Boxwell and White (2008) identify as aproblem case when aligning Propbank and CCG-bank.
Our analysis accommodates this construc-tion effortlessly, as shown in Figure 2.
The cate-gory assigned to decision can coindex the missingNP argument of buy with its own PP argument.When that argument is supplied by the genitive,it is also supplied to the verb, buy, filling its de-pendency with its agent, Google.
This argumentwould be quite difficult to recover using a shallowsyntactic analysis, as the path would be quite long.There are 494 such verb arguments mediated bynominal predicates in Sections 02-21.These analyses allow us to draw comple-ment/adjunct distinctions for nominal predicates,so that the surface syntax takes us very close toa full predicate-argument analysis.
The only in-formation we are not specifying in the syntac-tic analysis are the role labels assigned to eachof the syntactic arguments.
We could go furtherand express these labels in the syntax, produc-ing categories like (N /PP{0}y)/PP{1}z and(N /PP{1}y)/PP{0}z , but we expect that thiswould cause sparse data problems given the lim-ited size of the corpus.
This experiment would bean interesting subject of future work.The only local core arguments that we do notannotate as syntactic complements are compoundnouns, such as decision makers.
We avoided thesearguments because of the productivity of noun-noun compounding in English, which makes theseargument structures very difficult to recover.We currently do not have an analysis that allowssupport verbs to supply noun arguments, so wedo not recover any of the long-range dependencystructures described by Meyers et al (2004).4.2 Implementation and statisticsOur analysis requires semantic role labels for eachargument of the nominal predicates in the PennTreebank ?
precisely what NomBank (Meyerset al, 2004) provides.
We can therefore draw ourdistinctions using the process described in our pre-vious work, Honnibal and Curran (2007).NomBank follows the same format as Prop-bank, so the procedure is exactly the same.
First,we align CCGbank and the Penn Treebank, andproduce a version of NomBank that refers to CCG-bank nodes.
We then assume that any preposi-tional phrase or genitive determiner annotated asa core argument in NomBank should be analysedas a complement, while peripheral arguments andadnominals that receive no semantic role label atall are analysed as adjuncts.We converted 34,345 adnominal prepositionalphrases to complements, leaving 18,919 as ad-juncts.
The most common preposition convertedwas of, which was labelled as a core argument99.1% of the 19,283 times it occurred as an ad-nominal.
The most common adjunct prepositionwas in, which realised a peripheral argument in59.1% of its 7,725 occurrences.The frequent prepositions were more skewed to-wards core arguments.
73% of the occurrences ofthe 5 most frequent prepositions (of, in, for, on andto) realised peripheral arguments, compared with53% for other prepositions.Core arguments were also more common thanperipheral arguments for possessives.
There are20,250 possessives in the corpus, of which 75%were converted to complements.
The percentagewas similar for both personal pronouns (such ashis) and genitive phrases (such as the boy?s).2115 Adding restrictivity distinctionsAdnominals can have either a restrictive or a non-restrictive (appositional) interpretation, determin-ing the potential reference of the noun phraseit modifies.
This ambiguity manifests itself inwhether prepositional phrases, relative clauses andother adnominals are analysed as modifiers ofeither N or NP, yielding a restrictive or non-restrictive interpretation respectively.In CCGbank, all adnominals attach to NPs,producing non-restrictive interpretations.
Wetherefore move restrictive adnominals to N nodes:All staff on casual contractsNP/N N (N \N )/NP N /N N>NTCNP>N \N<N>NPThis corrects the previous interpretation, whichstated that there were no permanent staff.5.1 Implementation and statisticsThe Wall Street Journal?s style guide mandatesthat this attachment ambiguity be managed bybracketing non-restrictive relatives with commas(Martin, 2002, p. 82), as in casual staff, who haveno health insurance, support it.
We thus use punc-tuation to make the attachment decision.All NP\NP modifiers that are not preceded bypunctuation were moved to the lowest N nodepossible and relabelled N \N .
We select the low-est (i.e.
closest to leaf) N node because some ad-jectives, such as present or former, require scopeover the qualified noun, making it safer to attachthe adnominal first.Some adnominals in CCGbank are created bythe S\NP ?
NP\NP unary type-changing rule,which transforms reduced relative clauses.
We in-troduce a S\NP ?
N \N in its place, and add abinary rule cued by punctuation to handle the rela-tively rare non-restrictive reduced relative clauses.The rebanked corpus contains 34,134 N \N re-strictive modifiers, and 9,784 non-restrictive mod-ifiers.
Most (61%) of the non-restrictive modifierswere relative clauses.6 Reanalysing partitive constructionsTrue partitive constructions consist of a quantifier(16), a cardinal (17) or demonstrative (18) appliedto an NP via of.
There are similar constructionsheaded by common nouns, as in (19):(16) Some of us(17) Four of our members(18) Those of us who smoke(19) A glass of wineWe regard the common noun partitives as headedby the initial noun, such as glass, because thisnoun usually controls the number agreement.
Wetherefore analyse these cases as nouns with prepo-sitional arguments.
In (19), glass would be as-signed the category N /PP .True partitive constructions are different, how-ever: they are always headed by the head of the NPsupplied by of.
The construction is quite common,because it provides a way to quantify or apply twodifferent determiners.Partitive constructions are not given specialtreatment in the PTB, and were analysed as nounphrases with a PP modifier in CCGbank:Four of our membersNP (NPy\NPy)/NPz NPy/Ny N>NPmembers>(NPy\NPy)of<NPFourThis analysis does not yield the correct seman-tics, and may even hurt parser performance, be-cause the head of the phrase is incorrectly as-signed.
We correct this with the following anal-ysis, which takes the head from the NP argumentof the PP:Four of our membersNPy/PPy PPy/NPy NPy/Ny N>NPmembers>PPmembers>NPmembersThe cardinal is given the category NP/PP ,in analogy with the standard determiner categorywhich is a function from a noun to a noun phrase(NP/N ).212Corpus L. DEPS U. DEPS CATS+NP brackets 97.2 97.7 98.5+Quotes 97.2 97.7 98.5+Propbank 93.0 94.9 96.7+Particles 92.5 94.8 96.2+Restrictivity 79.5 94.4 90.6+Part.
Gen. 76.1 90.1 90.4+NP Pred-Arg 70.6 83.3 84.8Table 1: Effect of the changes on CCGbank, by percentageof dependencies and categories left unchanged in Section 00.6.1 Implementation and StatisticsWe detect this construction by identifying NPspost-modified by an of PP.
The NP?s head musteither have the POS tag CD, or be one of the follow-ing words, determined through manual inspectionof Sections 02-21:all, another, average, both, each, another, any,anything, both, certain, each, either, enough, few,little, most, much, neither, nothing, other, part,plenty, several, some, something, that, those.Having identified the construction, we simply rela-bel the NP to NP/PP , and the NP\NP adnom-inal to PP .
We identified and reanalysed 3,010partitive genitives in CCGbank.7 Similarity to CCGbankTable 1 shows the percentage of labelled depen-dencies (L. Deps), unlabelled dependencies (U.Deps) and lexical categories (Cats) that remainedthe same after each set of changes.A labelled dependency is a 4-tuple consisting ofthe head, the argument, the lexical category of thehead, and the argument slot that the dependencyfills.
For instance, the subject fills slot 1 and theobject fills slot 2 on the transitive verb category(S\NP)/NP .
There are more changes to labelleddependencies than lexical categories because onelexical category change alters all of the dependen-cies headed by a predicate, as they all depend onits lexical category.
Unlabelled dependencies con-sist of only the head and argument.The biggest changes were those described inSections 4 and 5.
After the addition of nominalpredicate-argument structure, over 50% of the la-belled dependencies were changed.
Many of thesechanges involved changing an adjunct to a com-plement, which affects the unlabelled dependen-cies because the head and argument are inverted.8 Lexicon statisticsOur changes make the grammar sensitive to newdistinctions, which increases the number of lexi-cal categories required.
Table 2 shows the numberCorpus CATS Cats ?
10 CATS/WORDCCGbank 1286 425 8.6+NP brackets 1298 429 8.9+Quotes 1300 431 8.8+Propbank 1342 433 8.9+Particles 1405 458 9.1+Restrictivity 1447 471 9.3+Part.
Gen. 1455 474 9.5+NP Pred-Arg 1574 511 10.1Table 2: Effect of the changes on the size of the lexicon.of lexical categories (Cats), the number of lexicalcategories that occur at least 10 times in Sections02-21 (Cats?
10), and the average number of cat-egories available for assignment to each token inSection 00 (Cats/Word).
We followed Clark andCurran?s (2007) process to determine the set ofcategories a word could receive, which includesa part-of-speech back-off for infrequent words.The lexicon steadily grew with each set ofchanges, because each added information to thecorpus.
The addition of quotes only added two cat-egories (LQU and RQU ), and the addition of thequote tokens slightly decreased the average cate-gories per word.
The Propbank and verb-particlechanges both introduced rare categories for com-plicated, infrequent argument structures.The NP predicate-argument structure modifica-tions added the most information.
Head nounswere previously guaranteed the category N inCCGbank; possessive clitics always received thecategory (NP/N )\NP ; and possessive personalpronouns were always NP/N .
Our changes in-troduce new categories for these frequent tokens,which meant a substantial increase in the numberof possible categories per word.9 Parsing EvaluationSome of the changes we have made correct prob-lems that have caused the performance of a sta-tistical CCG parser to be over-estimated.
Otherchanges introduce new distinctions, which a parsermay or may not find difficult to reproduce.
To in-vestigate these issues, we trained and evaluated theC&C CCG parser on our rebanked corpora.The experiments were set up as follows.
Weused the highest scoring configuration describedby Clark and Curran (2007), the hybrid depen-dency model, using gold-standard POS tags.
Wefollowed Clark and Curran in excluding sentencesthat could not be parsed from the evaluation.
Allmodels obtained similar coverage, between 99.0and 99.3%.
The parser was evaluated using depen-213WSJ 00 WSJ 23Corpus LF UF CAT LF UF CATCCGbank 87.2 92.9 94.1 87.7 93.0 94.4+NP brackets 86.9 92.8 93.8 87.3 92.8 93.9+Quotes 86.8 92.7 93.9 87.1 92.6 94.0+Propbank 86.7 92.6 94.0 87.0 92.6 94.0+Particles 86.4 92.5 93.8 86.8 92.6 93.8All Rebanking 84.2 91.2 91.9 84.7 91.3 92.2Table 3: Parser evaluation on the rebanked corpora.Corpus Rebanked CCGbankLF UF LF UF+NP brackets 86.45 92.36 86.52 92.35+Quotes 86.57 92.40 86.52 92.35+Propbank 87.76 92.96 87.74 92.99+Particles 87.50 92.77 87.67 92.93All Rebanking 87.23 92.71 88.02 93.51Table 4: Comparison of parsers trained on CCGbank andthe rebanked corpora, using dependencies that occur in both.dencies generated from the gold-standard deriva-tions (Boxwell, p.c., 2010).Table 3 shows the accuracy of the parser on Sec-tions 00 and 23.
The parser scored slightly loweras the NP brackets, Quotes, Propbank and Parti-cles corrections were added.
This apparent declinein performance is at least partially an artefact ofthe evaluation.
CCGbank contains some depen-dencies that are trivial to recover, because Hock-enmaier and Steedman (2007) was forced to adopta strictly right-branching analysis for NP brackets.There was a larger drop in accuracy on thefully rebanked corpus, which included our anal-yses of restrictivity, partitive constructions andnoun predicate-argument structure.
This mightalso be explained by the evaluation, as the re-banked corpus includes much more fine-graineddistinctions.
The labelled dependencies evaluationis particularly sensitive to this, as a single categorychange affects multiple dependencies.
This can beseen in the smaller gap in category accuracy.We investigated whether the differences in per-formance were due to the different evaluation databy comparing the parsers?
performance against theoriginal parser on the dependencies they agreedupon, to allow direct comparison.
To do this, weextracted the CCGbank intersection of each cor-pus?s Section 00 dependencies.Table 4 compares the labelled and unlabelled re-call of the rebanked parsers we trained against theCCGbank parser on these intersections.
Note thateach row refers to a different intersection, so re-sults are not comparable between rows.
This com-parison shows that the declines in accuracy seen inTable 3 were largely confined to the corrected de-pendencies.
The parser?s performance remainedfairly stable on the dependencies left unchanged.The rebanked parser performed 0.8% worsethan the CCGbank parser on the intersection de-pendencies, suggesting that the fine-grained dis-tinctions we introduced did cause some sparse dataproblems.
However, we did not change any ofthe parser?s maximum entropy features or hyper-parameters, which are tuned for CCGbank.10 ConclusionResearch in natural language understanding isdriven by the datasets that we have available.
Themost cited computational linguistics work to dateis the Penn Treebank (Marcus et al, 1993)1.
Prop-bank (Palmer et al, 2005) has also been veryinfluential since its release, and NomBank hasbeen used for semantic dependency parsing in theCoNLL 2008 and 2009 shared tasks.This paper has described how these resourcescan be jointly exploited using a linguistically moti-vated theory of syntax and semantics.
The seman-tic annotations provided by Propbank and Nom-Bank allowed us to build a corpus that takes muchgreater advantage of the semantic transparencyof a deep grammar, using careful analyses andphenomenon-specific conversion rules.The major areas of CCGbank?s grammar left tobe improved are the analysis of comparatives, andthe analysis of named entities.
English compar-atives are diverse and difficult to analyse.
Eventhe XTAG grammar (Doran et al, 1994), whichdeals with the major constructions of English inenviable detail, does not offer a full analysis ofthese phenomena.
Named entities are also difficultto analyse, as many entity types obey their ownspecific grammars.
This is another example of aphenomenon that could be analysed much betterin CCGbank using an existing resource, the BBNnamed entity corpus.Our rebanking has substantially improvedCCGbank, by increasing the granularity and lin-guistic fidelity of its analyses.
We achieved thisby exploiting existing resources and crafting novelanalyses.
The process we have demonstrated canbe used to train a parser that returns dependenciesthat abstract away as much surface syntactic vari-ation as possible ?
including, now, even whetherthe predicate and arguments are expressed in anoun phrase or a full clause.1http://clair.si.umich.edu/clair/anthology/rankings.cgi214AcknowledgmentsJames Curran was supported by Australian Re-search Council Discovery grant DP1097291 andthe Capital Markets Cooperative Research Centre.The parsing evaluation for this paper wouldhave been much more difficult without the assis-tance of Stephen Boxwell, who helped generatethe gold-standard dependencies with his software.We are also grateful to the members of the CCGtechnicians mailing list for their help crafting theanalyses, particularly Michael White, Mark Steed-man and Dennis Mehay.ReferencesAnn Bies, Mark Ferguson, Karen Katz, and Robert MacIn-tyre.
1995.
Bracketing guidelines for Treebank II stylePenn Treebank project.
Technical report, MS-CIS-95-06,University of Pennsylvania, Philadelphia, PA, USA.Stephen Boxwell and Michael White.
2008.
Projecting prop-bank roles onto the CCGbank.
In Proceedings of theSixth International Language Resources and Evaluation(LREC?08), pages 3112?3117.
European Language Re-sources Association (ELRA), Marrakech, Morocco.Miriam Butt, Mary Dalrymple, and Tracy H. King, editors.2006.
Lexical Semantics in LFG.
CSLI Publications, Stan-ford, CA.Aoife Cahill, Michael Burke, Ruth O?Donovan, Stefan Rie-zler, Josef van Genabith, and Andy Way.
2008.
Wide-coverage deep statistical parsing using automatic depen-dency structure annotation.
Computational Linguistics,34(1):81?124.Stephen Clark and James R. Curran.
2007.
Wide-coverage ef-ficient statistical parsing with CCG and log-linear models.Computational Linguistics, 33(4):493?552.James Constable and James Curran.
2009.
Integrating verb-particle constructions into CCG parsing.
In Proceedings ofthe Australasian Language Technology Association Work-shop 2009, pages 114?118.
Sydney, Australia.Christy Doran, Dania Egedi, Beth Ann Hockey, B. Srinivas,and Martin Zaidel.
1994.
Xtag system: a wide coveragegrammar for english.
In Proceedings of the 15th confer-ence on Computational linguistics, pages 922?928.
ACL,Morristown, NJ, USA.Dan Flickinger.
2000.
On building a more efficient gram-mar by exploiting types.
Natural Language Engineering,6(1):15?28.Daniel Gildea and Julia Hockenmaier.
2003.
Identifying se-mantic roles using combinatory categorial grammar.
InProceedings of the 2003 conference on Empirical meth-ods in natural language processing, pages 57?64.
ACL,Morristown, NJ, USA.Donald Hindle.
1983.
User manual for fidditch, a determin-istic parser.
Technical Memorandum 7590-142, Naval Re-search Laboratory.Julia Hockenmaier.
2003.
Data and Models for StatisticalParsing with Combinatory Categorial Grammar.
Ph.D.thesis, University of Edinburgh, Edinburgh, UK.Julia Hockenmaier and Mark Steedman.
2002.
Acquiringcompact lexicalized grammars from a cleaner treebank.In Proceedings of the Third Conference on Language Re-sources and Evaluation Conference, pages 1974?1981.Las Palmas, Spain.Julia Hockenmaier and Mark Steedman.
2007.
CCGbank: acorpus of CCG derivations and dependency structures ex-tracted from the Penn Treebank.
Computational Linguis-tics, 33(3):355?396.Matthew Honnibal and James R. Curran.
2007.
Improving thecomplement/adjunct distinction in CCGBank.
In Proceed-ings of the Conference of the Pacific Association for Com-putational Linguistics, pages 210?217.
Melbourne, Aus-tralia.Ronald M. Kaplan and Joan Bresnan.
1982.
Lexical-Functional Grammar: A formal system for grammaticalrepresentation.
In Joan Bresnan, editor, The mental repre-sentation of grammatical relations, pages 173?281.
MITPress, Cambridge, MA, USA.Mitchell Marcus, Beatrice Santorini, and MaryMarcinkiewicz.
1993.
Building a large annotatedcorpus of English: The Penn Treebank.
ComputationalLinguistics, 19(2):313?330.Paul Martin.
2002.
The Wall Street Journal Guide to BusinessStyle and Usage.
Free Press, New York.Adam Meyers, Ruth Reeves, Catherine Macleod, RachelSzekely, Veronika Zielinska, Brian Young, and Ralph Gr-ishman.
2004.
The NomBank project: An interim report.In Frontiers in Corpus Annotation: Proceedings of theWorkshop, pages 24?31.
Boston, MA, USA.Yusuke Miyao, Takashi Ninomiya, and Jun?ichi Tsujii.
2004.Corpus-oriented grammar development for acquiring ahead-driven phrase structure grammar from the Penn Tree-bank.
In Proceedings of the First International Joint Con-ference on Natural Language Processing (IJCNLP-04),pages 684?693.
Hainan Island, China.Stepan Oepen, Daniel Flickenger, Kristina Toutanova, andChristopher D. Manning.
2004.
LinGO Redwoods.
a richand dynamic treebank for HPSG.
Research on Languageand Computation, 2(4):575?596.Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005.The proposition bank: An annotated corpus of semanticroles.
Computational Linguistics, 31(1):71?106.Carl Pollard and Ivan Sag.
1994.
Head-Driven Phrase Struc-ture Grammar.
The University of Chicago Press, Chicago.Libin Shen, Lucas Champollion, and Aravind K. Joshi.
2008.LTAG-spinal and the treebank: A new resource for incre-mental, dependency and semantic parsing.
Language Re-sources and Evaluation, 42(1):1?19.Stuart M. Shieber.
1986.
An Introduction to Unification-Based Approaches to Grammar, volume 4 of CSLI LectureNotes.
CSLI Publications, Stanford, CA.Mark Steedman.
2000.
The Syntactic Process.
The MITPress, Cambridge, MA, USA.Daniel Tse and James R. Curran.
2008.
Punctuation normali-sation for cleaner treebanks and parsers.
In Proceedings ofthe Australian Language Technology Workshop, volume 6,pages 151?159.
ALTW, Hobart, Australia.David Vadas and James Curran.
2007.
Adding noun phrasestructure to the Penn Treebank.
In Proceedings of the 45thAnnual Meeting of the Association of Computational Lin-guistics, pages 240?247.
ACL, Prague, Czech Republic.David Vadas and James R. Curran.
2008.
Parsing noun phrasestructure with CCG.
In Proceedings of the 46th AnnualMeeting of the Association for Computational Linguistics,pages 335?343.
ACL, Columbus, Ohio, USA.215
