Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1168?1178,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsA Rational Model of Eye Movement Control in ReadingKlinton Bicknell and Roger LevyDepartment of LinguisticsUniversity of California, San Diego9500 Gilman Dr, La Jolla, CA 92093-0108{kbicknell,rlevy}@ling.ucsd.eduAbstractA number of results in the study of real-time sentence comprehension have beenexplained by computational models as re-sulting from the rational use of probabilis-tic linguistic information.
Many times,these hypotheses have been tested in read-ing by linking predictions about relativeword difficulty to word-aggregated eyetracking measures such as go-past time.
Inthis paper, we extend these results by ask-ing to what extent reading is well-modeledas rational behavior at a finer level of anal-ysis, predicting not aggregate measures,but the duration and location of each fix-ation.
We present a new rational model ofeye movement control in reading, the cen-tral assumption of which is that eye move-ment decisions are made to obtain noisyvisual information as the reader performsBayesian inference on the identities of thewords in the sentence.
As a case study,we present two simulations demonstratingthat the model gives a rational explanationfor between-word regressions.1 IntroductionThe language processing tasks of reading, listen-ing, and even speaking are remarkably difficult.Good performance at each one requires integrat-ing a range of types of probabilistic informationand making incremental predictions on the ba-sis of noisy, incomplete input.
Despite these re-quirements, empirical work has shown that hu-mans perform very well (e.g., Tanenhaus, Spivey-Knowlton, Eberhard, & Sedivy, 1995).
Sophisti-cated models have been developed that explainmany of these effects using the tools of com-putational linguistics and large-scale corpora tomake normative predictions for optimal perfor-mance in these tasks (Genzel & Charniak, 2002,2003; Keller, 2004; Levy & Jaeger, 2007; Jaeger,2010).
To the extent that the behavior of thesemodels looks like human behavior, it suggests thathumans are making rational use of all the infor-mation available to them in language processing.In the domain of incremental language compre-hension, especially, there is a substantial amountof computational work suggesting that humans be-have rationally (e.g., Jurafsky, 1996; Narayanan &Jurafsky, 2001; Levy, 2008; Levy, Reali, & Grif-fiths, 2009).
Most of this work has taken as itstask predicting the difficulty of each word in a sen-tence, a major result being that a large componentof the difficulty of a word appears to be a functionof its probability in context (Hale, 2001; Smith &Levy, 2008).
Much of the empirical basis for thiswork comes from studying reading, where worddifficulty can be related to the amount of timethat a reader spends on a particular word.
To re-late these predictions about word difficulty to thedata obtained in eye tracking experiments, the eyemovement record has been summarized throughword aggregate measures, such as the average du-ration of the first fixation on a word, or the amountof time between when a word is first fixated andwhen the eyes move to its right (?go-past time?
).It is important to note that this notion of worddifficulty is an abstraction over the actual task ofreading, which is made up of more fine-graineddecisions about how long to leave the eyes intheir current position, and where to move themnext, producing the series of relatively stable pe-riods (fixations) and movements (saccades) thatcharacterize the eye tracking record.
While therehas been much empirical work on reading atthis fine-grained scale (see Rayner, 1998 for anoverview), and there are a number of successfulmodels (Reichle, Pollatsek, & Rayner, 2006; En-gbert, Nuthmann, Richter, & Kliegl, 2005), littleis known about the extent to which human read-ing behavior appears to be rational at this finer1168grained scale.
In this paper, we present a new ratio-nal model of eye movement control in reading, thecentral assumption of which is that eye movementdecisions are made to obtain noisy visual informa-tion, which the reader uses in Bayesian inferenceabout the form and structure of the sentence.
As acase study, we show that this model gives a ratio-nal explanation for between-word regressions.In Section 2, we briefly describe the leadingmodels of eye movements in reading, and in Sec-tion 3, we describe how these models account forbetween-word regressions and the intuition behindour model?s account of them.
Section 4 describesthe model and its implementation and Sections 5?6 describe two simulations we performed with themodel comparing behavioral policies that make re-gressions to those that do not.
In Simulation 1, weshow that specific regressive policies outperformspecific non-regressive policies, and in Simulation2, we use optimization to directly find optimalpolicies for three performance measures.
The re-sults show that the regressive policies outperformnon-regressive policies across a wide range of per-formance measures, demonstrating that our modelpredicts that making between-word regressions isa rational strategy for reading.2 Models of eye movements in readingThe two most successful models of eye move-ments in reading are E-Z Reader (Reichle, Pollat-sek, Fisher, & Rayner, 1998; Reichle et al, 2006)and SWIFT (Engbert, Longtin, & Kliegl, 2002;Engbert et al, 2005).
Both of these models charac-terize the problem of reading as one of word iden-tification.
In E-Z Reader, for example, the systemidentifies each word in the sentence serially, mov-ing attention to the next word in the sentence onlyafter processing the current word is complete, and(to slightly oversimplify), the eyes then follow theattentional shifts at some lag.
SWIFT works simi-larly, but with the main difference being that pro-cessing and attention are distributed over multiplewords, such that adjacent words can be identifiedin parallel.
While both of these models provide agood fit to eye tracking data from reading, neithermodel asks the higher level question of what a ra-tional solution to the problem would look like.The first model to ask this question, Mr. Chips(Legge, Klitz, & Tjan, 1997; Legge, Hooven,Klitz, Mansfield, & Tjan, 2002), predicts the op-timal sequence of saccade targets to read a textbased on a principle of minimizing the expectedentropy in the distribution over identities of thecurrent word.
Unfortunately, however, the Mr.Chips model simplifies the problem of reading ina number of ways: First, it uses a unigram modelas its language model, and thus fails to use anyinformation in the linguistic context to help withword identification.
Second, it only moves on tothe next word after unambiguous identification ofthe current word, whereas there is experimentalevidence that comprehenders maintain some un-certainty about the word identities.
In other work,we have extended the Mr. Chips model to removethese two limitations, and show that the result-ing model more closely matches human perfor-mance (Bicknell & Levy, 2010).
The larger prob-lem, however, is that each of these models usesan unrealistic model of visual input, which obtainsabsolute knowledge of the characters in its visualwindow.
Thus, there is no reason for the model tospend longer on one fixation than another, and themodel only makes predictions for where saccadesare targeted, and not how long fixations last.Reichle and Laurent (2006) presented a rationalmodel that overcame the limitations of Mr. Chipsto produce predictions for both fixation durationsand locations, focusing on the ways in which eyemovement behavior is an adaptive response to theparticular constraints of the task of reading.
Giventhis focus, Reichle and Laurent used a very simpleword identification function, for which the time re-quired to identify a word was a function only of itslength and the relative position of the eyes.
In thispaper, we present another rational model of eyemovement control in reading that, like Reichle andLaurent, makes predictions for fixation durationsand locations, but which focuses instead on thedynamics of word identification at the core of thetask of reading.
Specifically, our model identifiesthe words in a sentence by performing Bayesianinference combining noisy input from a realisticvisual model with a language model that takescontext into account.3 Explaining between-word regressionsIn this paper, we use our model to provide anovel explanation for between-word regressivesaccades.
In reading, about 10?15% of saccadesare regressive ?
movements from right-to-left (orto previous lines).
To understand how modelssuch as E-Z Reader or SWIFT account for re-1169gressive saccades to previous words, recall thatthe system identifies words in the sentence (gen-erally) left to right, and that identification of aword in these models takes a certain amount oftime and then is completed.
In such a setup, whyshould the eyes ever move backwards?
Three ma-jor answers have been put forward.
One possibil-ity given by E-Z Reader is as a response to over-shoot; i.e., the eyes move backwards to a previ-ous word because they accidentally landed fur-ther forward than intended due to motor error.Such an explanation could only account for smallbetween-word regressions, of about the magni-tude of motor error.
The most recent version,E-Z Reader 10 (Reichle, Warren, & McConnell,2009), has a new component that can producelonger between-word regressions.
Specifically, themodel includes a flag for postlexical integrationfailure, that ?
when triggered ?
will instruct themodel to produce a between-word regression tothe site of the failure.
That is, between-word re-gressions in E-Z Reader 10 can arise because ofpostlexical processes external to the model?s maintask of word identification.
A final explanation forbetween-word regressions, which arises as a resultof normal processes of word identification, comesfrom the SWIFT model.
In the SWIFT model, thereader can fail to identify a word but move pastit and continue reading.
In these cases, there isa chance that the eyes will at some point moveback to this unidentified word to identify it.
Fromthe present perspective, however, it is unclear howit could be rational to move past an unidentifiedword and decide to revisit it only much later.Here, we suggest a new explanation forbetween-word regressions that arises as a resultof word identification processes (unlike that ofE-Z Reader) and can be understood as rational(unlike that of SWIFT).
Whereas in SWIFT andE-Z Reader, word recognition is a process thattakes some amount of time and is then ?com-pleted?, some experimental evidence suggests thatword recognition may be best thought of as aprocess that is never ?completed?, as comprehen-ders appear to both maintain uncertainty about theidentity of previous input and to update that uncer-tainty as more information is gained about the restof the sentence (Connine, Blasko, & Hall, 1991;Levy, Bicknell, Slattery, & Rayner, 2009).
Thus, itis possible that later parts of a sentence can causea reader?s confidence in the identity of the previ-ous regions to fall.
In these cases, a rational way torespond might be to make a between-word regres-sive saccade to get more visual information aboutthe (now) low confidence previous region.To illustrate this idea, consider the case of a lan-guage composed of just two strings, AB and BA,and assume that the eyes can only get noisy in-formation about the identity of one character at atime.
After obtaining a little information about theidentity of the first character, the reader may bereasonably confident that its identity is A and moveon to obtaining visual input about the second char-acter.
If the first noisy input about the second char-acter also indicates that it is probably A, then thenormative probability that the first character is A(and thus a rational reader?s confidence in its iden-tity) will fall.
This simple example just illustratesthe point that if a reader is combining noisy vi-sual information with a language model, then con-fidence in previous regions will sometimes fall.There are two ways that a rational agent mightdeal with this problem.
The first option would beto reach a higher level of confidence in the iden-tity of each word before moving on to the right,i.e., slowing down reading left-to-right to preventhaving to make right-to-left regressions.
The sec-ond option is to read left-to-right relatively morequickly, and then make occasional right-to-left re-gressions in the cases where probability in pre-vious regions falls.
In this paper, we present twosimulations suggesting that when using a rationalmodel to read natural language, the best strate-gies for coping with the problem of confidenceabout previous regions dropping ?
for any trade-off between speed and accuracy ?
involve makingbetween-word regressions.
In the next section, wepresent the details of our model of reading and itsimplementation, and then we present our two sim-ulations in the sections following.4 Reading as Bayesian inferenceAt its core, the framework we are proposing is oneof reading as Bayesian inference.
Specifically, themodel begins reading with a prior distribution overpossible identities of a sentence given by its lan-guage model.
On the basis of that distribution, themodel decides whether or not to move its eyes (andif so where to move them to) and obtains noisyvisual input about the sentence at the eyes?
posi-tion.
That noisy visual input then gives the likeli-hood term in a Bayesian belief update, where the1170model?s prior distribution over the identity of thesentence given the language model is updated to aposterior distribution taking into account both thelanguage model and the visual input obtained thusfar.
On the basis of that new distribution, the modelagain selects an action and the cycle repeats.This framework is unique among models of eyemovement control in reading (except Mr. Chips)in having a fully explicit model of how visual in-put is used to discriminate word identity.
This ap-proach stands in sharp contrast to other models,which treat the time course of word identifica-tion as an exogenous function of other influenc-ing factors (such as word length, frequency, andpredictability).
The hope in our approach is thatthe influence of these key factors on the eye move-ment record will fall out as a natural consequenceof rational behavior itself.
For example, it is wellknown that the higher the conditional probabil-ity of a word given preceding material, the morerapidly that word is read (Boston, Hale, Kliegl,Patil, & Vasishth, 2008; Demberg & Keller, 2008;Ehrlich & Rayner, 1981; Smith & Levy, 2008).E-Z Reader and SWIFT incorporate this finding byspecifying a dependency on word predictability inthe exogenous function determining word process-ing time.
In our framework, in contrast, we wouldexpect such an effect to emerge as a byproduct ofBayesian inference: words with high prior proba-bility (conditional on preceding fixations) will re-quire less visual input to be reliably identified.An implemented model in this framework mustformalize a number of pieces of the reading prob-lem, including the possible actions available to thereader and their consequences, the nature of vi-sual input, a means of combining visual input withprior expectations about sentence form and struc-ture, and a control policy determining how themodel will choose actions on the basis of its poste-rior distribution over the identities of the sentence.In the remainder of this section, we present thesedetails of the formalization of the reading problemwe used for the simulations reported in this paper:actions (4.1), visual input (4.2), formalization ofthe Bayesian inference problem (4.3), control pol-icy (4.4), and finally, implementation of the modelusing weighted finite state automata (4.5).4.1 Formal problem of reading: ActionsFor our model, we assume a series of discretetimesteps, and on each time step, the model firstobtains visual input around the current locationof the eyes, and then chooses between three ac-tions: (a) continuing to fixate the currently fixatedposition, (b) initiating a saccade to a new posi-tion, or (c) stopping reading of the sentence.
Ifon the ith timestep, the model chooses option (a),the timestep advances to i + 1 and another sam-ple of visual input is obtained around the currentposition.
If the model chooses option (c), the read-ing immediately ends.
If a saccade is initiated (b),there is a lag of two timesteps, roughly represent-ing the time required to plan and execute a sac-cade, during which the model again obtains visualinput around the current position and then the eyesmove ?
with some motor error ?
toward the in-tended target ti, landing on position `i.
On the nexttime step, visual input is obtained around `i andanother decision is made.
The motor error for sac-cades follows the form of random error used by allmajor models of eye movements in reading: thelanding position `i is normally distributed aroundthe intended target ti with standard deviation givenby a linear function of the intended distance1`i ?
N(ti,(?0 +?1|ti?
`i?1|)2)(1)for some linear coefficients ?0 and ?1.
In the ex-periments reported in this paper, we follow theSWIFT model in using ?0 = 0.87,?1 = 0.084.4.2 Noisy visual inputAs stated earlier, the role of noisy visual input inour model is as the likelihood term in a Bayesianinference about sentence form and identity.
There-fore, if we denote the input obtained thus far froma sentence as I, all the information pertinent tothe reader?s inferences can be encapsulated in theform p(I|w) for possible sentences w. We assumethat the inputs deriving from each character posi-tion are conditionally independent given sentenceidentity, so that if w j denotes letter j of the sen-tence and I( j) denotes the component of visualinput associated with that letter, then we can de-compose p(I|w) as ?
j p(I( j)|w j).
For simplicity,we assume that each character is either a lowercaseletter or a space.
The visual input obtained froman individual fixation can thus be summarized asa vector of likelihoods p(I( j)|w j), as shown in1In the terminology of the literature, the model has onlyrandom motor error (variance), not systematic error (bias).Following Engbert and Kr?gel (2010), systematic error mayarise from Bayesian estimation of the best saccade distance.1171.
.
.
a s a c a*t s a t a t a t .
.
.??????????????ac...st...????????????????????????????00...00...1????????????????????????????00...00...1????????????????????????????00...00...1????????????????????????????00...00...1????????????????????????????00...00...1????????????????????????????00...00...1????????????????????????????00...00...1????????????????????????????.04.04....04.04...0????????????????????????????.04.04....04.04...0????????????????????????????.04.04....04.04...0????????????????????????????.08.02....04.03...0????????????????????????????.15.07....01.01...0????????????????????????????.02.25....03.01...0????????????????????????????.07.01....03.003...0????????????????????????????.05.01....002.05...0????????????????????????????.003.005....21.02...0????????????????????????????.04.01....03.07...0????????????????????????????.06.01....02.12...0????????????????????????????.05.05....07.05...0????????????????????????????.10.08....02.05...0?????????????
?Figure 1: Peripheral and foveal visual input in the model.
The asymmetric Gaussian curve indicatesdeclining perceptual acuity centered around the fixation point (marked by ?).
The vector underneath eachletter position denotes the likelihood p(I( j)|w j) for each possible letter w j, taken from a single inputsample with ?
= 1/?3 (see vector at the left edge of the figure for key, and Section 4.2).
In peripheralvision, the letter/whitespace distinction is veridical, but no information about letter identity is obtained.Note in this particular sample, input from the fixated character and the following one is rather inaccurate.Figure 1.
As in the real visual system, our vi-sual acuity function decreases with retinal eccen-tricity; we follow the SWIFT model in assumingthat the spatial distribution of visual processingrate follows an asymmetric Gaussian with ?L =2.41,?R = 3.74, which we discretize into process-ing rates for each character position.
If ?
denotes acharacter?s eccentricity in characters from the cen-ter of fixation, then the proportion of the total pro-cessing rate at that eccentricity ?
(?)
is given byintegrating the asymmetric Gaussian over a char-acter width centered on that position,?
(?)
=?
?+.5??.51Zexp(?x22?2)dx,?
={?L, x < 0?R, x?
0where the normalization constant Z is given byZ =?pi2(?L +?R).From this distribution, we derive two types of vi-sual input, peripheral input giving word boundaryinformation and foveal input giving informationabout letter identity.4.2.1 Peripheral visual inputIn our model, any eccentricity with a processingrate proportion ?
(?)
at least 0.5% of the rate pro-portion for the centrally fixated character (?
?
[?7,12]), yields peripheral visual input, definedas veridical word boundary information indicat-ing whether each character is a letter or a space.This roughly corresponds to empirical estimatesthat humans obtain useful information in readingfrom about 19 characters, more from the right offixation than the left (Rayner, 1998).
Hence in Fig-ure 1, for example, left-peripheral visual input canbe represented as veridical knowledge of the initialwhitespace (denoted ), and a uniform distributionover the 26 letters of English for the letter a.4.2.2 Foveal visual inputIn addition, for those eccentricities with a process-ing rate proportion ?
(?)
that is at least 1% of thetotal processing rate (?
?
[?5,8]) the model re-ceives foveal visual input, defined only for letters2to give noisy information about the letter?s iden-tity.
This threshold of 1% roughly corresponds toestimates that readers get information useful forletter identification from about 4 characters to theleft and 8 to the right of fixation (Rayner, 1998).In our model, each letter is equally confusablewith all others, following Norris (2006, 2009),but ignoring work on letter confusability (whichcould be added to future model revisions; Engel,Dougherty, & Jones, 1973; Geyer, 1977).
Visualinformation about each character is obtained bysampling.
Specifically, we represent each letter asa 26-dimensional vector, where a single elementis 1 and the other 25 are zeros, and given this rep-resentation, foveal input for a letter is given as asample from a 26-dimensional Gaussian with a2For white space, the model is already certain of the iden-tity because of peripheral input.1172mean equal to the letter?s true identity and a di-agonal covariance matrix ?(?)
= ?
(?)?1/2I.
It isrelatively straightforward to show that under theseconditions, if we take the processing rate to be theexpected change in log-odds of the true letter iden-tity relative to any other that a single sample bringsabout, then the rate equals ?
(?).
We scale the over-all processing rate by multiplying each rate by ?.For the experiments in this paper, we set ?
= 4.For each fixation, we sample independently fromthe appropriate distribution for each character po-sition and then compute the likelihood given eachpossible letter, as illustrated in the non-peripheralregion of Figure 1.4.3 Inference about sentence identityGiven the visual input and a language model, in-ferences about the identity of the sentence w canbe made by standard Bayesian inference, wherethe prior is given by the language model and thelikelihood is a function of the total visual input ob-tained from the first to the ith timestep I i1,p(w|I i1) =p(w)p(I i1|w)?w?(w?
)p(I i1|w?).
(2)If we let I( j) denote the input received about char-acter position j and let w j denote the jth characterin sentence identity w, then the likelihood can bebroken down by character position asp(I i1|w) =n?j=1p(I i1( j)|w j)where n is the final character about which there isany visual input.
Similarly, we can decompose thisinto the product of the likelihoods of each samplep(I i1|w) =n?j=1i?t=1p(It( j)|w j).
(3)If the eccentricity of the jth character on the tthtimestep ?
jt is outside of foveal input or the char-acter is a space, the inner term is 0 or 1.
If the sam-ple was from a letter in foveal input ?
jt ?
[?5,8], itis the probability of sampling It( j) from the mul-tivariate Gaussian N (w j,??(?
jt )).4.4 Control policyThe model uses a simple policy to decide betweenactions based on the marginal probability m of the(a) m = [.6, .7, .6, .4, .3, .6]: Keep fixating (3)(b) m = [.6, .4, .9, .4, .3, .6]: Move back (to 2)(c) m = [.6, .7, .9, .4, .3, .6]: Move forward (to 6)(d) m = [.6, .7, .9, .8, .7, .7]: Stop readingFigure 2: Values of m for a 6 character sentenceunder which a model fixating position 3 wouldtake each of its four actions, if ?
= .7 and ?
= .5.most likely character c in position j,m( j) = maxcp(wn = c|Ii1)= maxc ?w?
:w?n=cp(w?|I i1).
(4)Intuitively, a high value of m means that the modelis relatively confident about the character?s iden-tity, and a low value that it is relatively uncertain.Given the values of this statistic, our model de-cides between four possible actions, as illustratedin Figure 2.
If the value of this statistic for the cur-rent position of the eyes m(`i) is less than a pa-rameter ?
, the model chooses to continue fixatingthe current position (2a).
Otherwise, if the valueof m( j) is less than ?
for some leftward positionj < `i, the model initiates a saccade to the closestsuch position (2b).
If m( j)?
?
for all j < `i, thenthe model initiates a saccade to n characters pastthe closest position to the right j > `i for whichm( j)< ?
(2c).3 Finally, if no such positions existto the right, the model stops reading the sentence(2d).
Intuitively, then, the model reads by makinga rightward sweep to bring its confidence in eachcharacter up to ?
, but pauses to move left if confi-dence in a previous character falls below ?
.4.5 Implementation with wFSAsThis model can be efficiently and simply im-plemented using weighted finite-state automata(wFSAs; Mohri, 1997) as follows: First, we be-gin with a wFSA representation of the languagemodel, where each arc emits a single character (oris an epsilon-transition emitting nothing).
To per-form belief update given a new visual input, wecreate a new wFSA to represent the likelihood ofeach character from the sample.
Specifically, thiswFSA has only a single chain of states, where,e.g., the first and second state in the chain are con-nected by 27 (or fewer) arcs, which emit each of3The role of n is to ensure that the model does not cen-ter its visual field on the first uncertain character.
We did notattempt to optimize this parameter, but fixed n at 2.1173the possible characters for w1 along with their re-spective likelihoods given the visual input (as inthe inner term of Equation 3).
Next, these twowFSAs may simply be composed and then nor-malized, which completes the belief update, re-sulting in a new wFSA giving the posterior dis-tribution over sentences.
To calculate the statisticm, while it is possible to calculate it in closed formfrom such a wFSA relatively straightforwardly, forefficiency we use Monte Carlo estimation basedon samples from the wFSA.5 Simulation 1With the description of our model in place, wenext proceed to describe the first simulation inwhich we used the model to test the hypothesisthat making regressions is a rational way to copewith confidence in previous regions falling.
Be-cause there is in general no single rational trade-off between speed and accuracy, our hypothesisis that, for any given level of speed and accu-racy achieved by a non-regressive policy, there is afaster and more accurate policy that makes a fasterleft-to-right pass but occasionally does make re-gressions.
In the terms of our model?s policy pa-rameters ?
and ?
described above, non-regressivepolicies are exactly those with ?
= 0, and a pol-icy that is faster on the left-to-right pass but doesmake regressions is one with a lower value of ?but a non-zero ?
.
Thus, we tested the performanceof our model on the reading of a corpus of text typ-ical of that used in reading experiments at a rangeof reasonable non-regressive policies, as well as aset of regressive policies with lower ?
and posi-tive ?
.
Our prediction is that the former set willbe strictly dominated in terms of both speed andaccuracy by the latter.5.1 Methods5.1.1 Policy parametersWe test 4 non-regressive policies (i.e., those with?
= 0) with values of ?
?
{.90, .95, .97, .99}, andin addition, test regressive policies with a lowerrange of ?
?
{.85, .90, .95, .97} and ?
?
{.4, .7}.45.1.2 Language modelOur reader?s language model was an unsmoothedbigram model created using a vocabulary set con-4We tested all combinations of these values of ?
and ?except for [?,? ]
= [.97, .4], because we did not believe thata value of ?
so low in relation to ?
would be very differentfrom a non-regressive policy.sisting of the 500 most frequent words in theBritish National Corpus (BNC) as well as all thewords in our test corpus.
From this vocabulary, weconstructed a bigram model using the counts fromevery bigram in the BNC for which both wordswere in vocabulary (about 222,000 bigrams).5.1.3 wFSA implementationWe implemented our model with wFSAs usingthe OpenFST library (Allauzen, Riley, Schalk-wyk, Skut, & Mohri, 2007).
Specifically, weconstructed the model?s initial belief state (i.e.,the distribution over sentences given by its lan-guage model) by directly translating the bigrammodel into a wFSA in the log semiring.
Wethen composed this wFSA with a weighted finite-state transducer (wFST) breaking words downinto characters.
This was done in order to facili-tate simple composition with the visual likelihoodwFSA defined over characters.
In the Monte Carloestimation of m, we used 5000 samples from thewFSA.
Finally, to speed performance, we boundedthe wFSA to have exactly the number of char-acters present in the actual sentence and then re-normalized.5.1.4 Test corpusWe tested our model?s performance by simulatingreading of the Schilling corpus (Schilling, Rayner,& Chumbley, 1998).
To ensure that our resultsdid not depend on smoothing, we only tested themodel on sentences in which every bigram oc-curred in the BNC.
Unfortunately, only 8 of the 48sentences in the corpus met this criterion.
Thus,we made single-word changes to 25 more of thesentences (mostly changing proper names and rarenouns) to produce a total of 33 sentences to read,for which every bigram did occur in the BNC.5.2 Results and discussionFor each policy we tested, we measured the aver-age number of timesteps it took to read the sen-tences, as well as the average (natural) log prob-ability of the correct sentence identity under themodel?s beliefs after reading ended ?Accuracy?.The results are plotted in Figure 3.
As shown inthe graph, for each non-regressive policy (the cir-cles), there is a regressive policy that outperformsit, both in terms of average number of timestepstaken to read (further to the left) and the averagelog probability of the sentence identity (higher).Thus, for a range of policies, these results suggest1174TimestepsAccuracy?1.2?1.0?0.8?0.6ll ll50 55 60 65 70Betal non?regressive (beta=0)regressive (beta=0.4)regressive (beta=0.7)Figure 3: Mean number of timesteps taken to reada sentence and (natural) log probability of the trueidentity of the sentence ?Accuracy?
for a range ofvalues of ?
and ?
.
Values of ?
are not labeled,but increase with the number of timesteps for aconstant value of ?
.
For each non-regressive pol-icy (?
= 0), there is a policy with a lower ?
andhigher ?
that achieves better accuracy in less time.that making regressions when confidence aboutprevious regions falls is a rational reader strategy,in that it appears to lead to better performance,both in terms of speed and accuracy.6 Simulation 2In Simulation 2, we perform a more direct test ofthe idea that making regressions is a rational re-sponse to the problem of confidence falling aboutprevious regions using optimization techniques.Specifically, we search for optimal policy param-eter values (?,? )
for three different measures ofperformance, each representing a different trade-off between the importance of accuracy and speed.6.1 Methods6.1.1 Performance measuresWe examine performance measures interpolatingbetween speed and accuracy of the formL(1?
?
)?T ?
(5)where L is the log probability of the true identityof the sentence under the model?s beliefs at the endof reading, and T is the total number of timestepsbefore the model decided to stop reading.
Thus,each different performance measure is determinedby the weighting for time ?
.
We test three values of?
?
{.025, .1, .4}.
The first of these weights accu-racy highly, while the final one weights 1 timestepalmost as much as 1 unit of log probability.6.1.2 Optimization of policy parametersSearching directly for optimal values of ?
and ?for our stochastic reading model is difficult be-cause each evaluation of the model with a partic-ular set of parameters produces a different result.We use the PEGASUS method (Ng & Jordan, 2000)to transform this stochastic optimization probleminto a deterministic one on which we can use stan-dard optimization algorithms.5 Then, we evaluatethe model?s performance at each value of ?
and ?by reading the full test corpus and averaging per-formance.
We then simply use coordinate ascent(in logit space) to find the optimal values of ?
and?
for each performance measure.6.1.3 Language modelThe language model used in this simulation be-gins with the same vocabulary set as in Sim.
1,i.e., the 500 most frequent words in the BNC andevery word that occurs in our test corpus.
Becausethe search algorithm demands that we evaluate theperformance of our model at a number of param-eter values, however, it is too slow to optimize ?and ?
using the full language model that we usedfor Sim.
1.
Instead, we begin with the same set ofbigrams used in Sim.
1 ?
i.e., those that containtwo in-vocabulary words ?
and trim this set by re-moving rare bigrams that occur less than 200 timesin the BNC (except that we do not trim any bi-grams that occur in our test corpus).
This reducesour set of bigrams to about 19,000.6.1.4 wFSA implementationThe implementation was the same as in Sim.
1.6.1.5 Test corpusThe test corpus was the same as in Sim.
1.6.2 Results and discussionThe optimal values of ?
and ?
for each ?
?
{.025, .1, .4} are given in Table 1 along with themean values for L and T found at those parametervalues.
As the table shows, the optimization proce-dure successfully found values of ?
and ?
, whichgo up (slower reading) as ?
goes down (valuingaccuracy more than time).
In addition, we see thatthe average results of reading at these parametervalues are also as we would expect, with T and Lgoing up as ?
goes down.
As predicted, the optimal5Specifically, this involves fixing the random number gen-erator for each run to produce the same values, resulting inminimizing the variance in performance across evaluations.1175?
?
?
Timesteps Log probability.025 .90 .99 41.2 -0.02.1 .36 .80 25.8 -0.90.4 .18 .38 16.4 -4.59Table 1: Optimal values of ?
and ?
found for eachperformance measure ?
tested and mean perfor-mance at those values, measured in timesteps Tand (natural) log probability L.values of ?
found are non-zero across the range ofpolicies, which include policies that value speedover accuracy much more than in Sim.
1.
Thisprovides more evidence that whatever the partic-ular performance measure used, policies makingregressive saccades when confidence in previousregions falls perform better than those that do not.There is one interesting difference between theresults of this simulation and those of Sim.
1,which is that here, the optimal policies all have avalue of ?
> ?
.
That may at first seem surprising,since the model?s policy is to fixate a region un-til its confidence becomes greater than ?
and thenreturn if it falls below ?
.
It would seem, then, thatthe only reasonable values of ?
are those that arestrictly below ?
.
In fact, this is not the case be-cause of the two time step delay between the de-cision to move the eyes and the execution of thatsaccade.
Because of this delay, the model?s confi-dence when it leaves a region (relevant to ? )
willgenerally be higher than when it decided to leave(determined by ?).
In Simulation 2, because of thesmaller grammar that was used, the model?s confi-dence in a region?s identity rises more quickly andthis difference is exaggerated.7 ConclusionIn this paper, we presented a model that performsBayesian inference on the identity of a sentence,combining a language model with noisy informa-tion about letter identities from a realistic visualinput model.
On the basis of these inferences, ituses a simple policy to determine how long tocontinue fixating the current position and whereto fixate next, on the basis of information aboutwhere the model is uncertain about the sentence?sidentity.
As such, it constitutes a rational modelof eye movement control in reading, extending theinsights from previous results about rationality inlanguage comprehension.The results of two simulations using this modelsupport a novel explanation for between-word re-gressive saccades in reading: that they are used togather visual input about previous regions whenconfidence about them falls.
Simulation 1 showedthat a range of policies making regressions in thesecases outperforms a range of non-regressive poli-cies.
In Simulation 2, we directly searched for op-timal values for the policy parameters for three dif-ferent performance measures, representing differ-ent speed-accuracy trade-offs, and found that theoptimal policies in each case make substantial useof between-word regressions when confidence inprevious regions falls.
In addition to supportinga novel motivation for between-word regressions,these simulations demonstrate the possibility fortesting a range of questions that were impossi-ble with previous models of reading related to thegoals of a reader, such as how should reading be-havior change as accuracy is valued more.There are a number of obvious ways for themodel to move forward.
One natural next step isto make the model more realistic by using letterconfusability matrices.
In addition, the link to pre-vious work in sentence processing can be madetighter by incorporating syntax-based languagemodels.
It also remains to compare this model?spredictions to human data more broadly on stan-dard benchmark measures for models of read-ing.
The most important future development, how-ever, will be moving toward richer policy families,which enable more intelligent decisions about eyemovement control, based not just on simple confi-dence statistics calculated independently for eachcharacter position, but rather which utilize the richstructure of the model?s posterior beliefs about thesentence identity (and of language itself) to makemore informed decisions about the best time tomove the eyes and the best location to direct themnext.AcknowledgmentsThe authors thank Jeff Elman, Tom Griffiths,Andy Kehler, Keith Rayner, and Angela Yu foruseful discussion about this work.
This work bene-fited from feedback from the audiences at the 2010LSA and CUNY conferences.
The research waspartially supported by NIH Training Grant T32-DC000041 from the Center for Research in Lan-guage at UC San Diego to K.B., by a researchgrant from the UC San Diego Academic Senateto R.L., and by NSF grant 0953870 to R.L.1176ReferencesAllauzen, C., Riley, M., Schalkwyk, J., Skut, W.,& Mohri, M. (2007).
OpenFst: A general andefficient weighted finite-state transducer library.In Proceedings of the Ninth International Con-ference on Implementation and Application ofAutomata, (CIAA 2007) (Vol.
4783, p. 11-23).Springer.Bicknell, K., & Levy, R. (2010).
Rational eyemovements in reading combining uncertaintyabout previous words with contextual probabil-ity.
In Proceedings of the 32nd Annual Confer-ence of the Cognitive Science Society.
Austin,TX: Cognitive Science Society.Boston, M. F., Hale, J. T., Kliegl, R., Patil, U., &Vasishth, S. (2008).
Parsing costs as predic-tors of reading difficulty: An evaluation usingthe potsdam sentence corpus.
Journal of EyeMovement Research, 2(1), 1?12.Connine, C. M., Blasko, D. G., & Hall, M. (1991).Effects of subsequent sentence context in audi-tory word recognition: Temporal and linguisticconstraints.
Journal of Memory and Language,30, 234?250.Demberg, V., & Keller, F. (2008).
Data from eye-tracking corpora as evidence for theories of syn-tactic processing complexity.
Cognition, 109,193?210.Ehrlich, S. F., & Rayner, K. (1981).
Contextualeffects on word perception and eye movementsduring reading.
Journal of Verbal Learning andVerbal Behavior, 20, 641?655.Engbert, R., & Kr?gel, A.
(2010).
Readers useBayesian estimation for eye movement control.Psychological Science, 21, 366?371.Engbert, R., Longtin, A., & Kliegl, R. (2002).
Adynamical model of saccade generation in read-ing based on spatially distributed lexical pro-cessing.
Vision Research, 42, 621?636.Engbert, R., Nuthmann, A., Richter, E. M., &Kliegl, R. (2005).
SWIFT: A dynamical modelof saccade generation during reading.
Psycho-logical Review, 112, 777?813.Engel, G. R., Dougherty, W. G., & Jones, B. G.(1973).
Correlation and letter recognition.Canadian Journal of Psychology, 27, 317?326.Genzel, D., & Charniak, E. (2002, July).
Entropyrate constancy in text.
In Proceedings of the 40thannual meeting of the Association for Computa-tional Linguistics (pp.
199?206).
Philadelphia:Association for Computational Linguistics.Genzel, D., & Charniak, E. (2003).
Variation ofentropy and parse trees of sentences as a func-tion of the sentence number.
In M. Collins &M. Steedman (Eds.
), Proceedings of the 2003Conference on Empirical Methods in NaturalLanguage Processing (pp.
65?72).
Sapporo,Japan: Association for Computational Linguis-tics.Geyer, L. H. (1977).
Recognition and confusionof the lowercase alphabet.
Perception & Psy-chophysics, 22, 487?490.Hale, J.
(2001).
A probabilistic Earley parser asa psycholinguistic model.
In Proceedings of theSecond Meeting of the North American Chapterof the Association for Computational Linguistics(Vol.
2, pp.
159?166).
New Brunswick, NJ: As-sociation for Computational Linguistics.Jaeger, T. F. (2010).
Redundancy and re-duction: Speakers manage syntactic in-formation density.
Cognitive Psychology.doi:10.1016/j.cogpsych.2010.02.002.Jurafsky, D. (1996).
A probabilistic model oflexical and syntactic access and disambiguation.Cognitive Science, 20, 137?194.Keller, F. (2004).
The entropy rate principle asa predictor of processing effort: An evaluationagainst eye-tracking data.
In D. Lin & D.
Wu(Eds.
), Proceedings of the 2004 Conference onEmpirical Methods in Natural Language Pro-cessing (pp.
317?324).
Barcelona, Spain: As-sociation for Computational Linguistics.Legge, G. E., Hooven, T. A., Klitz, T. S., Mans-field, J. S., & Tjan, B. S. (2002).
Mr.Chips 2002: new insights from an ideal-observermodel of reading.
Vision Research, 42, 2219?2234.Legge, G. E., Klitz, T. S., & Tjan, B. S. (1997).Mr.
Chips: an Ideal-Observer model of reading.Psychological Review, 104, 524?553.Levy, R. (2008).
A noisy-channel model of ra-tional human sentence comprehension under un-certain input.
In Proceedings of the 2008 Con-ference on Empirical Methods in Natural Lan-guage Processing (pp.
234?243).
Honolulu,Hawaii: Association for Computational Linguis-tics.Levy, R., Bicknell, K., Slattery, T., & Rayner,K.
(2009).
Eye movement evidence that read-ers maintain and act on uncertainty about pastlinguistic input.
Proceedings of the NationalAcademy of Sciences, 106, 21086?21090.1177Levy, R., & Jaeger, T. F. (2007).
Speakers op-timize information density through syntactic re-duction.
In B. Sch?lkopf, J. Platt, & T.
Hoffman(Eds.
), Advances in Neural Information Pro-cessing Systems 19 (pp.
849?856).
Cambridge,MA: MIT Press.Levy, R., Reali, F., & Griffiths, T. L. (2009).Modeling the effects of memory on human on-line sentence processing with particle filters.
InD.
Koller, D. Schuurmans, Y. Bengio, & L. Bot-tou (Eds.
), Advances in Neural Information Pro-cessing Systems 21 (pp.
937?944).Mohri, M. (1997).
Finite-state transducers in lan-guage and speech processing.
ComputationalLinguistics, 23, 269?311.Narayanan, S., & Jurafsky, D. (2001).
A Bayesianmodel predicts human parse preference andreading time in sentence processing.
In T. Diet-terich, S. Becker, & Z. Ghahramani (Eds.
), Ad-vances in Neural Information Processing Sys-tems 14 (pp.
59?65).
Cambridge, MA: MITPress.Ng, A. Y., & Jordan, M. (2000).
PEGASUS:A policy search method for large MDPs andPOMDPs.
In Uncertainty in Artificial Intelli-gence, Proceedings of the Sixteenth Conference(pp.
406?415).Norris, D. (2006).
The Bayesian reader: Explain-ing word recognition as an optimal Bayesian de-cision process.
Psychological Review, 113, 327?357.Norris, D. (2009).
Putting it all together: A unifiedaccount of word recognition and reaction-timedistributions.
Psychological Review, 116, 207?219.Rayner, K. (1998).
Eye movements in reading andinformation processing: 20 years of research.Psychological Bulletin, 124, 372?422.Reichle, E. D., & Laurent, P. A.
(2006).
Usingreinforcement learning to understand the emer-gence of ?intelligent?
eye-movement behaviorduring reading.
Psychological Review, 113,390?408.Reichle, E. D., Pollatsek, A., Fisher, D. L., &Rayner, K. (1998).
Toward a model of eyemovement control in reading.
Psychological Re-view, 105, 125?157.Reichle, E. D., Pollatsek, A., & Rayner, K.(2006).
E-Z Reader: A cognitive-control, serial-attention model of eye-movement behavior dur-ing reading.
Cognitive Systems Research, 7, 4?22.Reichle, E. D., Warren, T., & McConnell, K.(2009).
Using E-Z Reader to model the ef-fects of higher level language processing on eyemovements during reading.
Psychonomic Bul-letin & Review, 16, 1?21.Schilling, H. E. H., Rayner, K., & Chumbley, J.
I.(1998).
Comparing naming, lexical decision,and eye fixation times: Word frequency effectsand individual differences.
Memory & Cogni-tion, 26, 1270?1281.Smith, N. J., & Levy, R. (2008).
Optimal process-ing times in reading: a formal model and empir-ical investigation.
In B. C. Love, K. McRae, &V. M. Sloutsky (Eds.
), Proceedings of the 30thAnnual Conference of the Cognitive Science So-ciety (pp.
595?600).
Austin, TX: Cognitive Sci-ence Society.Tanenhaus, M. K., Spivey-Knowlton, M. J., Eber-hard, K. M., & Sedivy, J. C. (1995).
Integrationof visual and linguistic information in spokenlanguage comprehension.
Science, 268, 1632?1634.1178
