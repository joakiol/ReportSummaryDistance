Proceedings of the Fifth Law Workshop (LAW V), pages 124?128,Portland, Oregon, 23-24 June 2011. c?2011 Association for Computational LinguisticsA Gold Standard Corpus of Early Modern GermanSilke Scheible, Richard J. Whitt, Martin Durrell and Paul BennettSchool of Languages, Linguistics, and CulturesUniversity of ManchesterSilke.Scheible, Richard.Whitt@manchester.ac.ukMartin.Durrell, Paul.Bennett@manchester.ac.ukAbstractThis paper describes an annotated gold stan-dard sample corpus of Early Modern Germancontaining over 50,000 tokens of text manu-ally annotated with POS tags, lemmas, andnormalised spelling variants.
The corpus isthe first resource of its kind for this variant ofGerman, and represents an ideal test bed forevaluating and adapting existing NLP tools onhistorical data.
We describe the corpus for-mat, annotation levels, and challenges, provid-ing an example of the requirements and needsof smaller humanities-based corpus projects.1 IntroductionThis paper describes work which is part of a largerproject whose goal is to develop a representative cor-pus of Early Modern German from 1650-1800.
TheGerManC corpus was born out of the need for a re-source to facilitate comparative studies of the devel-opment and standardisation of English and Germanin the 17th and 18th centuries.
One major goal isto annotate GerManC with linguistic information interms of POS tags, lemmas, and normalised spellingvariants.
However, due to the lexical, morpholog-ical, syntactic, and graphemic peculiarities charac-teristic of Early Modern German, automatic annota-tion of the texts poses a major challenge.
Most ex-isting NLP tools are tuned to perform well on mod-ern language data, but perform considerably worseon historical, non-standardised data (Rayson et al,2007).
This paper describes a gold standard sub-corpus of GerManC which has been manually anno-tated by two human annotators for POS tags, lem-mas, and normalised spelling variants.
The corpuswill be used to test and adapt modern NLP tools onhistorical data, and will be of interest to other currentcorpus-based projects in historical linguistics (Jur-ish, 2010; Fasshauer, 2011; Dipper, 2010).2 Corpus design2.1 GerManCIn order to enable corpus-linguistic investigations,the GerManC corpus aims to be representative onthree different levels.
First of all, the corpus includesa range of text types: four orally-oriented genres(dramas, newspapers, letters, and sermons), and fourprint-oriented ones (narrative prose, and humanities,scientific, and legal texts).
Secondly, in order to en-able historical developments to be traced, the pe-riod has been divided into three fifty year sections(1650-1700, 1700-1750, and 1750-1800).
The com-bination of historical and text-type coverage shouldenable research on the evolution of style in differ-ent genres (cf.
Biber and Finegan, 1989).
Finally,the corpus also aims to be representative with re-spect to region, including five broad dialect areas:North German, West Central, East Central, West Up-per (including Switzerland), and East Upper German(including Austria).
Per genre, period, and region,three extracts of around 2000 words are selected,yielding a corpus size of nearly a million words.
Thestructure of the GerManC corpus is summarised inTable 1.2.2 GerManC-GSIn order to facilitate a thorough linguistic inves-tigation of the data, the final version of the Ger-124Periods Regions Genres1650-1700 North Drama1700-1750 West Central Newspaper1750-1800 East Central LetterWest Upper SermonEast Upper NarrativeHumanitiesScientificLegalTable 1: Structure of the GerManC corpusManC corpus aims to provide the following linguis-tic annotations: 1.)
Normalised spelling variants;2.)
Lemmas; 3.)
POS tags.
However, due to thenon-standard nature of written Early Modern Ger-man, and the additional variation introduced by thethree variables of ?genre?, ?region?, and ?time?, au-tomatic annotation of the corpus poses a major chal-lenge.
In order to assess the suitability of existingNLP tools on historical data, and with a view toadapting them to improve their performance, a man-ually annotated gold standard subcorpus has beendeveloped, which aims to be as representative ofthe main corpus as possible (GerManC-GS).
To re-main manageable in terms of annotation times andcost, the subcorpus considers only two of the threecorpus variables, ?genre?
and ?time?, as they alonewere found to display as much if not more varia-tion than ?region?.
GerManC-GS thus only includestexts from the North German dialect region, withone sample file per genre and time period.
Table2 provides an overview of GerManC-GS, showingpublication year, file name, and number of tokens foreach genre/period combination.
It contains 57,845tokens in total, which have been manually annotatedas described in the following sections.2.3 Corpus formatAs transcription of historical texts needs to be verydetailed with regard to document structure, glossing,damaged or illegible passages, foreign language ma-terial and special characters such as diacritics andligatures, the raw input texts have been annotatedaccording to the guidelines of the Text EncodingInitiative (TEI)1 during manual transcription.
TheTEI have published a set of XML-based encodingconventions recommended for meta-textual markup1http://www.tei-c.orgto minimise inconsistencies across projects and tomaximise mutual usability and data interchange.The GerManC corpus has been marked up usingthe TEI P5 Lite tagset, which serves as standard formany humanities-based projects.
Only the most rel-evant tags have been selected to keep the documentstructure as straightforward as possible.
Figure 1shows structural annotation of a drama excerpt, in-cluding headers, stage directions, speakers, as wellas lines.Figure 1: TEI annotation of raw corpus3 Linguistic annotationGerManC-GS has been annotated with linguistic in-formation in terms of normalised word forms, lem-mas, and POS tags.
To reduce manual labour, asemi-automatic approach was chosen whose outputwas manually corrected by two trained annotators.The following paragraphs provide an overview ofthe annotation types and the main challenges en-countered during annotation.3.1 Tokenisation and sentence boundariesAs German orthography was not yet codified in theEarly Modern period, word boundaries were diffi-cult to determine at times.
Clitics and multi-wordtokens are particularly difficult issues: lack of stan-dardisation means that clitics can occur in variousdifferent forms, some of which are difficult to to-kenise (e.g.
wirstu instead of wirst du).
Multi-wordtokens, on the other hand, represent a problem as thesame expression may be sometimes treated as com-pound (e.g.
obgleich), but written separately at othertimes (ob gleich).
Our tokenisation scheme takes cl-itics into account, but does not yet deal with multi-word tokens.
This means that whitespace charactersusually act as token boundaries.125Genre P Year File name Tokens Genre P Year File name TokensDRAM1 1673 Leonilda 2933NARR1 1659 Herkules 23452 1749 AlteJungfer 2835 2 1706 SatyrischerRoman 23793 1767 Minna 3037 3 1790 AntonReiser 2551HUMA1 1667 Ratseburg 2563NEWS1 1666 Berlin1 11322 1737 Ko?nigstein 2308 2 1735 Berlin 22733 1772 Ursprung 2760 3 1786 Wolfenbuettel1 1506LEGA1 1673 BergOrdnung 2534SCIE1 1672 Prognosticis 23232 1707 Reglement 2467 2 1734 Barometer 24383 1757 Rostock 2414 3 1775 Chemie 2303LETT1 1672 Guericke 2473SERM1 1677 LeichSermon 25852 1748 Borchward 2557 2 1730 JubelFeste 25233 1798 Arndt 2314 3 1770 Gottesdienst 2292Total number of tokens 57,845Table 2: GerManC-GS designAnnotation of sentence boundaries is also affectedby the non-standard nature of the data.
Punctuationis not standardised in Early Modern German andvaries considerably across the corpus.
For example,the virgule symbol ?/?
was often used in place ofboth comma and full-stop, which proves problem-atic for sentence boundary detection.3.2 Normalising spelling variants andlemmatisationOne of the key challenges in working with histor-ical texts is the large amount of spelling variationthey contain.
As most existing NLP tools (such asPOS-taggers or parsers) are tuned to perform wellon modern language data, they are not usually ableto account for variable spelling, resulting in loweroverall performance (Rayson et al, 2007).
Like-wise, modern search engines do not take spellingvariation into account and are thus often unable toretrieve all occurrences of a given historical searchword.
Both issues have been addressed in previ-ous work through the task of spelling normalisa-tion.
Ernst-Gerlach and Fuhr (2006) and Pilz andLuther (2009) have created a tool that can gener-ate variant spellings for historical German to retrieverelevant instances of a given modern lemma, whileBaron and Rayson (2008) and Jurish (2010) haveimplemented tools which normalise spelling vari-ants in order to achieve better performance of NLPtools such as POS taggers (by running the tools onthe normalised input).
Our annotation of spellingvariants aims to compromise between these two ap-proaches by allowing for historically accurate lin-guistic searches, while also aiming to maximise theperformance of automatic annotation tools.
We treatthe task of normalising spelling variation as a typeof pre-lemmatisation, where each word token occur-ring in a text is labelled with a normalised head vari-ant.
As linguistic search requires a historically accu-rate treatment of spelling variation, our scheme has apreference for treating two seemingly similar tokensas separate items on historical grounds (e.g.
etwanvs.
etwa).
However, the scheme normalises variantsto a modernised form even where the given lexicalitem has since died out (e.g.
obsolete verbs endingin -iren are normalised to -ieren), in order to supportautomatic tools using morphological strategies suchas suffix probabilities (Schmid, 1994).Lemmatisation resolves the normalised variant toa base lexeme in modern form, using Duden2 pre-reform spelling.
With obsolete words, the leadingform in Grimm?s Deutsches Wo?rterbuch3 is taken.3.3 POS-TaggingWe introduce a modified version of the STTS tagset(Schiller et al, 1999), the STTS-EMG tagset, to ac-count for important differences between modern andEarly Modern German (EMG), and to facilitate moreaccurate searches.
The tagset merges two categories,as the criteria for distinguishing them are not appli-cable in EMG (1.
), and provides a number of ad-ditional ones to account for special EMG construc-tions (2. to 6.):2http://www.duden.de/3http://www.dwb.uni-trier.de/1261.
PIAT (merged with PIDAT): Indefinite deter-miner (occurring on its own, or in conjunctionwith another determiner), as in ?viele solcheBemerkungen?2.
NA: Adjectives used as nouns, as in ?derGesandte?3.
PAVREL: Pronominal adverb used as relative,as in ?die Puppe, damit sie spielt?4.
PTKREL: Indeclinable relative particle, as in?die Fa?lle, so aus Schwachheit entstehen?5.
PWAVREL: Interrogative adverb used asrelative, as in ?der Zaun, woru?ber sie springt?6.
PWREL: Interrogative pronoun used as rela-tive, as in ?etwas, was er sieht?Around 2.0% (1132) of all tokens in the corpushave been tagged with one of the above POS cate-gories, of which the merged PIAT class contains themajority (657 tokens).
The remaining 475 cases oc-cur as NA (291), or as one of the new relative mark-ers PWAVREL (69), PWREL (57), PTKREL (38),and PAVREL (20).4 Annotation procedure and agreementIn order to produce the gold standard annotations inGerManC-GS we used the GATE platform, whichfacilitates automatic as well as manual annotation(Cunningham et al 2002).
Initially, GATE?s Ger-man Language plugin4 was used to obtain word to-kens and sentence boundaries.
The output was man-ually inspected and corrected by one annotator, whomanually added a layer of normalised spelling vari-ants (NORM).
This annotation layer was then usedas input for the TreeTagger (Schmid, 1994), obtain-ing annotations in terms of lemmas (LEMMA) andPOS tags (POS).
All annotations (NORM, LEMMA,and POS) were subsequently corrected by two an-notators, and all disagreements were reconciled toproduce the gold standard.
Table 3 shows the over-all agreement for the three annotation types acrossGerManC-GS (measured in accuracy).The agreement values demonstrate that nor-malised word forms and lemmas are relatively easyto determine for the annotators, with 96.9% and95.5% agreement, respectively.
POS tags, on theother, represent more of a challenge with only 91.6%4http://gate.ac.uk/sale/tao/splitch15.htmlNORM LEMMA POSAgreed tokens(out of 57,845)56,052 55,217 52,959Accuracy (%) 96.9% 95.5% 91.6%Table 3: Inter-annotator agreementagreement between two annotators, which is consid-erably lower than the agreement level reported forannotating a corpus of modern German using STTS,at 98.6% (Brants, 2000a).
While a more detailedanalysis of the results remains to be carried out, aninitial study shows that POS agreement is lower inearlier texts (89.3% in Period P1) compared to laterones (93.1% in P3).
It is likely that a substantialamount of disagreements in the earlier texts are dueto the larger number of unfamiliar word forms andvariants on the one hand, and foreign word tokenson the other.
These represent a problem as from amodern view point it is not always easy to decidewhich words were ?foreign?
to a language and whichones ?native?.5 Future workThe gold standard corpus described in this paper willbe used to test and adapt modern NLP tools on EarlyModern German data.
Initial experiments focus onutilising the layer of normalised spelling variantsto improve tagger performance, and investigating towhat extent normalisation can be reliably automated(Jurish, 2010).
We further plan to retrain state-of-the-art POS taggers such as the TreeTagger and TnTTagger (Brants, 2000b) on our data.Finally, we plan to investigate how linguistic an-notations can be automatically integrated in the TEI-annotated version of the corpus to produce TEI-conformant output.
Currently, both structural andlinguistic annotations are merged in GATE stand-offXML format, which, as a consequence, is no longerTEI-conformant.
In the interest of interoperabilityand comparative studies between corpora we aim tocontribute towards the development of clearer proce-dures whereby structural and linguistic annotationsmight be merged (Scheible et al, 2010).127ReferencesAlistair Baron and Paul Rayson.
2008.
VARD 2: A toolfor dealing with spelling variation in historical cor-pora.
Proceedings of the Postgraduate Conference inCorpus Linguistics, Birmingham, UK.Douglas Biber and Edward Finegan.
1989.
Drift and theevolution of English style: a history of three genres.Language 65.
487-517.Torsten Brants.
2000a.
Inter-annotator agreement fora German newspaper corpus.
Second InternationalConference on Language Resources and Evaluation(LREC 2000), Athens, Greece.Torsten Brants.
2000b.
TnT ?
a statistical part-of-speechtagger.
Proceedings of the 6th Applied NLP Confer-ence, ANLP-2000, Seattle, WA.Hamish Cunningham, Diana Maynard, KalinaBontcheva, and Valentin Tablan.
2002.
GATE:A framework and graphical development environmentfor robust NLP tools and applications.
Proceedings ofthe 40th Anniversary Meeting of the Association forComputational Linguistics.Stefanie Dipper.
2010.
POS-Tagging of historical lan-guage data: First experiments in semantic approachesin Natural Language Processing.
Proceedings ofthe 10th Conference on Natural Language Processing(KONVENS-10).
Saarbru?cken, Germany.
117-121.Andrea Ernst-Gerlach and Norbert Fuhr.
2006.
Gen-erating search term variants for text collections withhistoric spellings.
Proceedings of the 28th EuropeanConference on Information Retrieval Research (ECIR2006), London, UK.Vera Fasshauer.
2011. http://www.indogermanistik.uni-jena.de/index.php?auswahl=184Accessed 30/03/2011.Bryan Jurish.
2010.
Comparing canonicalizations of his-torical German text.
Proceedings of the 11th Meetingof the ACL Special Interest Group on ComputationalMorphology and Phonology (SIGMORPHON), Upp-sala, Sweden.
72-77.Thomas Pilz and Wolfram Luther.
2009.
Automatedsupport for evidence retrieval in documents with non-standard orthography.
The Fruits of Empirical Lin-guistics.
Sam Featherston and Susanne Winkler (eds.
).211?228.Paul Rayson, Dawn Archer, Alistair Baron, JonathanCulpeper, and Nicholas Smith.
2007.
Tagging theBard: Evaluating the accuracy of a modern POS taggeron Early Modern English corpora.
Proceedings of theCorpus Linguistics Conference (CL2007), Universityof Birmingham, UK.Silke Scheible, Richard J. Whitt, Martin Durrell, and PaulBennett.
2010.
Annotating a Historical Corpus ofGerman: A Case Study.
Proceedings of the LREC2010Workshop on Language Resources and LanguageTechnology Standards, Valletta, Malta.Anne Schiller, Simone Teufel, Christine Sto?ckert, andChristine Thielen.
1999.
Guidelines fu?r das Taggingdeutscher Textcorpora mit STTS.
Technical Report.Institut fu?r maschinelle Sprachverarbeitung, Stuttgart.Helmut Schmid.
1994.
Probabilistic part-of-speech tag-ging using decision trees.
International Conferenceon NewMethods in Language Processing, Manchester,UK.
44?49.128
