Automatic Semantic Role Assignment for a Tree StructureJia-Ming YouInstitute of Information ScienceAcademia Sinicaswimming@hp.iis.sinica.edu.twKeh-Jiann ChenInstitute of Information ScienceAcademia SinicaKchen@iis.sinica.edu.twAbstractWe present an automatic semantic roles labelingsystem for structured trees of Chinese sentences.
Itadopts dependency decision making andexample-based approaches.
The training data andextracted examples are from the Sinica Treebank,which is a Chinese Treebank with semantic roleassigned for each constituent.
It used 74 abstractsemantic roles including thematic roles, such as?agent?
; ?theme?, ?instrument?, and secondary roles of?location?, ?time?, ?manner?
and roles for nominalmodifiers.
The design of role assignment algorithm isbased on the different decision features, such ashead-argument/modifier, case makers, sentencestructures etc.
It labels semantic roles of parsedsentences.
Therefore the practical performance of thesystem depends on a good parser which labels theright structures of sentences.
The system achieves92.71% accuracy in labeling the semantic roles forpre-structure- bracketed texts which is considerablyhigher than the simple method using probabilisticmodel of head-modifier relations.1.
IntroductionFor natural language understanding, the process offine-grain semantic role assignment is one of theprominent steps, which provides semantic relationsbetween constituents.
The sense and sense relationsbetween constituents are core meaning of a sentence.Conventionally there are two kinds of methodsfor role assignments, one is using only statisticalinformation (Gildea and Jurafsky, 2002) and theother is combining with grammar rules (Gildea andHockenmaier, 2003).
However using only grammarrules to assign semantic roles could lead to lowcoverage.
On the other hand, performance ofstatistical methods relies on significant dependentfeatures.
Data driven is a suitable strategy forsemantic roles assignments of general texts.
We usethe Sinica Treebank as information resource becauseof its various domains texts including politics,society, literature?etc and it is a Chinese Treebankwith semantic role assigned for each constituent(Chen etc., 2003).
It used 74 abstract semantic rolesincluding thematic roles, such as ?agent?
; ?theme?,?instrument?, and secondary roles of ?location?,?time?, ?manner?
and modifiers of nouns, such as?quantifier?, ?predication?, ?possessor?, etc.
Thedesign of role assignment algorithm is based onthe different decision features, such ashead-argument/modifier, case makers, sentencestructures etc.
It labels semantic roles of parsedsentences by example-based probabilistic models.1.1 Sinica TreebankThe Sinica Treebank has been developed andreleased to public since 2000 by ChineseKnowledge Information Processing (CKIP) groupat Academia Sinica.
The Sinica Treebank version2.0 contains 38944 structural trees and 240,979words in Chinese.
Each structural tree is annotatedwith words, part-of-speech of words, syntacticstructure brackets, and semantic roles.
Forconventional structural trees, only syntacticinformation was annotated.
However, it is veryimportant and yet difficult for Chinese to identifyword relations with purely syntactic constraints(Xia et al, 2000).
Thus, partial semanticinformation, i.e.
semantic role for each constituent,was annotated in Chinese structural trees.
Thegrammatical constraints are expressed in terms oflinear order of semantic roles and their syntacticand semantic restrictions.
Below is an examplesentence of the Sinica Treebank.Original sentence:?
?Ta??
?yao?
??
?ZhangSan??
?jian?
??qiu?
?He ask Zhang San to pick up the ball.Parsed tree:S(agent:NP(Head:Nhaa:??He?)|Head:VF2:??ask?|goal:NP(Head:Nba:??
?Zhang San?)|theme:VP(Head:VC2:??pick?|goal:NP(Head:Nab:?'?ball?
)))Figure 1: An example sentence of Sinica TreebankIn the Sinica Treebank, not only the semanticrelations of a verbal predicate but also themodifier head relations were marked.
There are 74different semantic roles, i.e.
the task of semanticrole assignment has to establish the semanticrelations among phrasal heads and theirarguments/modifiers within 74 different choices.The set of semantic roles used in the Sinica Treebankis listed in the appendix.2.
Example-based Probabilistic Models forAssigning Semantic RolesThe idea of example-based approaches is thatsemantic roles are preserved for the same eventframes.
For a target sentence, if we can find sameexamples in the training corpus, we can assign thesame semantic role for each constituent of the targetsentence as the examples.
However reoccurrence ofexact same surface structures for a sentence is veryrare, i.e.
the probability of finding same examplesentences in a corpus is very low.
In fact, byobserving structures of parsed trees, we find thatmost of semantic roles are uniquely determined bysemantic relations between phrasal heads and theirarguments/modifiers and semantic relations aredetermined by syntactic category, semantic class ofrelated words.
For example:Original sentence:??
?wo men?
?
?du?
??
?xi huan?
??
?hudie?
?We all like butterflies.Parsed tree:S(experiencer:NP(Head:Nhaa:???we?
)|quantity:Dab:?
?all?
|Head:VK1:??
?like?|goal:NP(Head:Nab:??
?butterflies?
))?Figure 2: The illustration of the parsed tree.In Figure2, ??
?like?
is the sentential head; ??
?we?
and ??
?butterflies?
are the arguments;?
?all?
is the modifier.
As a result, the semantic role?experiencer?
of ??
?we?
is deduced from therelation between ??
?we?
and??
?like?, sincethe event frame of??
?like?
has the two argumentsof experiencer and goal and the experiencer usuallytakes the subject position.
The semantic roles of ??
?butterflies?
and ?
?all?
are assigned by thesame way.
For the task of automatic roleassignment, once phrase boundaries and phrasalhead are known, the semantic relations will beresolved by looking for similarhead-argument/modifier pairs in training data.2.1  Example ExactionTo extract head-argument/modifier examplesfrom the Sinica Treebank is trivial, since phraseboundaries and semantic roles, including phrasalhead, are labeled.
The extracted examples arepairs of head word and target word.
The targetword is represented by the head of theargument/modifier, since the semantic relationsare established between the phrasal head and thehead of argument/modifier phrase.
An extractedword pair includes the following features.Target word:The head word of argument/modifier.Target POS:The part-of-speech of the target word.Target semantic role:Semantic role of the constituent contains thetarget word as phrasal head.Head word:The phrasal head.Head POS:The part-of-speech of the head word.Phrase type:The phrase which contains the head word andthe constituent containing target word.Position:Shows whether target word appears before orafter head word.The examples we extracted from Figure 2 arelisted below.Table 1: The three head-argument/modifier pairsextracted from Figure 2.SgoalNPexperiencerNPHeadVK1quantityDabHeadNhaaHeadNab?
?W e?all??like?
?Butterflies.Table 2: Coverage and accuracy of different features combinations2.2 Probabilistic Model for Semantic RoleAssignmentIt is possible that conflicting examples (orambiguous role assignments) occur in the trainingdata.
We like to assign the most probable roles.
Theprobability of each semantic role in a constituentwith different features combinations are estimatedfrom extract examples.position) pt,  t_pos, t,h_pos, h,(#position) pt,  t_pos,, t h_pos, h,(r, #) position pt,t_pos, t,h_pos, h, |r ()|(== PtconstituenrP1Due to the sparseness of the training data, it?s notpossible to have example feature combinationsmatched all input cases.
Therefore the similarexamples will be matched.
A back off process willbe carried out to reduce feature constraints duringthe example matching.
We will evaluateperformances for various features combinations tosee which features combinations are best suited forsemantic roles assignments.We choose four different feature combinations.Each has relatively high accuracy.
The fourclassifiers will be back off in sequence.
If none ofthe four classifiers is applicable, a baseline modelof assigning the most common semantic role oftarget word is applied.if # of (h,h_pos,t,t_pos,pt,position) > thresholdP(r|constituent)=P(r|h,h_pos,t,t_pos,pt,position)Elseif # of (h_pos,t,t_pos,pt,position) > thresholdP(r|constituent)=P(r|h_pos,t,t_pos,pt,position)Else1  r: semantic role; h: the head word;h_pos: part-of-speech of head word;t: the target word;t_pos: part-of-speech of target word;pt: the phrase type.if # of (h,h_pos,t_pos,pt,position) > thresholdP(r|constituent)=P(r|h,h_pos,t_pos,pt,position)Elseif # of (h_pos,t_pos,pt,position) > thresholdP(r|constituent)=P(r|h_pos,t_pos,pt,position)ElseBaseline model:P(r|constituent)=P(r| t, t_pos,pt)3.
ExperimentsWe adopt the Sinica Treebank as both trainingand testing data.
It contains about 40,000 parsedsentences.
We use 35,000 sentences as training dataand the rest 5,000 as testing data.
The table 2 showsthe coverage of each classifier, their accuracies, andperformance of each individual classifier withoutback off process.
The table 3 shows combinedperformance of the four classifiers after back offprocesses in sequence.
The baseline algorithm is thesimple unigram approach to assign the mostcommon role for the target word.
Because theaccuracy of the four classifiers is considerably high,instead of using linear probability combinations wewill rather use the most reliable classifier for eachdifferent features combination.Table 3: The accuracy of our backoff method andthe base line (the most common semantic roles)3.1 Error AnalysesAlthough the accuracy of back off model isrelatively high to the baseline model, it still hasquite a room for improvement.
After analyzed theerrors, we draw following conclusions.Method AccuracyBackoff 90.29%Baseline:  68.68%a) Semantic head vs. syntactic headA semantic role for a prepositional phrase (PP) ismainly determined by the syntactic head of PP, i.e.preposition, and the semantic head of PP, i.e.
thehead word of the DUMMY-argument of PP.
Forexample, in Figure 3, the two sentences are almostthe same, only the contents of PP are different.Obviously, the semantic roles of PP (?
?in?
???Indonesia?)
is location, and the semantic role of PP(?
?in?
??
?this year?)
is time.
Therefore thesemantic roles of the two PPs should be determinedonly within the scope of PP and not relevant tomatrix verb.SHeadVC31agentNPHeadNcaHeadP21HeadNcamannerDh??
?
??
??
?
?Taipei  speed-up  the  investments   in  Indonesia.DummyNPlocationPPSHeadVC31agentNPHeadNcaHeadP21HeadNcamannerDh??
?
??
??
?
?Taipei  speed-up   the  investments   this year.DummyNPtimePPFigure 3: Parsed trees of ??????????
?and ??????????
?b) Structure-dependent semantic roles assignmentsComplex structures are always the hardest part ofsemantic roles assignments.
For example, thesentences with passive voice are the typicalcomplex structures.
In Figure 4, the semantic roleof ??
?Butterflies?
is not solely determined bythe head verb ??
?attracted?
and itself.
Insteadwe should inspect the existence of passive voiceand then reverse the roles of subject and object.Figure 4: A parsed tree of passive sentence ?????????
?4 Refined ModelsChen & Huang (1996) had studied the task ofsemantic assignment during Chinese sentenceparsing.
They concluded that semantic roles aredetermined by the following 4 parameters.1.
Syntactic and semantic categories of the targetword,2.
Case markers, i.e.
prepositions andpostpositions3.
Phrasal head, and4.
Sub-categorization frame and its syntacticpatterns.Therefore head-modifier/argument examplesonly resolve most of semantic role assignments.Some of complex cases need other parameters todetermine their semantic roles.
For instance, theargument roles of Bei sentences (passive sentence)should be determined by all four parameters.The refined model contain two parts, one is therefinements of features data which provide moreprecisely information and the other is theimprovements of back off process to deal withspecial semantic roles assignments.4.1 Refinement of Features ExtractionsThe refinements of features extractions focus ontwo different cases, one is the features extractionsof case-marked structures, such as PP and GP(postpositional phrases), and the other is the generalsemantic class identifications of synonyms.The features of PP/GP include two differentSHeadVJ1goalNPHeadP02evaluationDbbHeadNabHeadNad??
?
?
??
?
?Butterflies   are   also   be   attracted   by   the voice.DummyNPthemePPfeature types: the internal and the external features.The internal features of phrases compose of phrasalhead and Dummy-head; the external features areheads (main verbs) of the target phrases.Figure 5: A parsed tree for demonstrating featuresextractions of PPTable 4: The internal/external relations of Figure 5.The semantic class identifications of synonymsare crucial for solving data sparseness problems.Some type of  words are very productive, such asnumbers, DM (determinative measurement), propernames.
They need to be classified into differentsemantic classes.
We use some tricks to classifythem into specific word classes.
For example welabel  1 ??
?one kilogram?, 2 ??
?twokilograms?
as their canonical form ???
?nkilograms?
; ???
?the first day?, ???
?thesecond day ?
as ???
?the nth days?
;  ??
?Zhang San?, ??
?Li Si?
as a personalname?etc.
With this method, we can increase thenumber of matched examples and resolve theproblem of occurrences of unknown words in alarge scale.4.2  Dependency Decisions and Refined Backoff ProcessesThe refined back off model aimed to solvesemantic roles assignments for certain specialstructures.
Using only head-modifier features couldresult into decision making with insufficientinformation.
As illustrated before, the semantic roleof ??
?butterflies?
in Figure 4 is ?agent?
observedfrom the head-argument feature.
But in fact thefeature of passive voice ?
?passive?
tells us thatthe subject role of ??
?butterflies?
should be thesemantic role ?goal?
instead of the usual role of?agent?.Therefore we enhanced our back off process byadding some dependency decisions.
Thedependency conditions include special grammarusage like passive form, quotation, topicalsentences?
etc.
In the refined back off process,first we have to detect which dependency conditionis happened and resolved it by using dependencyfeatures.
For example, if the feature word ??passive?
occurs in a sentence, we realize that thesubjective priority of semantic roles should bereversed.
For instance, ?goal?
will take subjectposition instead of ?agent?
(?goal?
appears before?agent?
).4.3 Experiment ResultsThe experiments were carried out for the refinedback off model with the same set of training dataand testing data as in the previous experiments.Table 5 shows that the refined back off model gains2.4 % accuracy rate than the original back offmodel.
However most of the improvement is due tothe refinements of features extractions andcanonical representation for certain classes of words.A few improvements were contributed to thedecision making on the cases of structuredependency.Method AccuracyRefined Backoff  92.71%Backoff 90.29%Baseline 68.68%Table 5: Role assignment accuracies of refinedbackoff, backoff, and baseline models.5  Conclusion and Future WorksSemantic roles are determined by the following 4parameters.1.
Syntactic and semantic categories of the targetword,2.
Case markers, i.e.
prepositions andpostpositions,3.
Phrasal head, and4.
Sub-categorization frame and its syntacticpatterns.SHeadVC31agentNPHeadNcaHeadP21HeadNcamannerDh??
?
??
??
?
?Taipei  speed-up  the  investments   in  Indonesia.DummyNPlocationPPWe present an automatic semantic roles labelingsystem.
It adopts dependency decision making andexample-based approaches, which makes decisionon the amount of parameters by observing theoccurrence of dependency features and to utilize theminimal amount of feature combinations to assignsemantic roles.
It labels semantic roles of parsedsentences.
Therefore the practical performance ofthe system depends on a good parser which labelsthe right structures of sentences.
The systemachieves 92.71% accuracy in labeling the semanticroles for pre-structure- bracketed texts which isconsiderably higher than the simple method usingprobabilistic model of head-modifier relations.In the future, we will consider fine-grain semanticrole assignment problems.
The current semanticroles assignment is focus on one sentence.
However,the occurrences of frame elements are not limited toa single sentence.
For instance, ?John bought thebooks from Mary?.
The semantic roles of ?John?and ?Mary?
are agent and theme respectively.According to Fillmore?s FrameNet, the frameelement assignment for the above sentence shouldbe ?John?
the buyer, ?Mary?
the seller, ?the books?the goods.
The precondition of buy-frame says thatthe seller should be the owner of the goods.Therefore after the sentence parsing and logicalreasoning, the following semantic relations shouldbe established.Event frame: Commerce-buyBuyer: JohnSeller: MaryGoods: booksAdditional frame: OwnBefore the buy eventOwner: MaryPossession: booksAfter the buy eventOwner: JohnPossession: booksThe semantic roles assignment is a process ofcrossing phrasal and sentential boundaries.
Somesemantic roles of an event might occur at left orright context.
Therefore we have to analyze therelation between two consecutive events.
Therelations include causal relation, temporal relation,resultant relation, etc.
How to resolve the aboveproblems will be our future studies.ReferencesChen, Keh-Jiann, Chu-Ren Huang.
1996.Information-based Case Grammar: AUnification-based Formalism for Parsing Chinese.Journal of Chinese Linguistics Monograph SeriesNo.
9.Chen, Keh-Jiann, Chu-Ren Huang, Feng-Yi Chen,Chi-Ching Luo,Ming-Chung Chang, Chao-Jan Chen,and Zhao-Ming Gao, 2003.
Sinica Treebank: DesignCriteria, Representational Issues andImplementation.
In Anne Abeille (Ed.)
TreebanksBuilding and Using Parsed Corpora.
Language andSpeech series.
Dordrecht:Kluwer, pp231-248.Chu-Ren Huang, Keh-Jiann Chen, and Benjamin K.T?sou Eds.
Readings in Chinese Natural LanguageProcessing.
23-45.
Berkeley: JCL.Daniel Gildea and Daniel Jurafsky.
2002.
AutomaticLabeling of Semantic Roles.
ComputationalLinguistics, 28(3):245-288Daniel Gildea and Julia Hockenmaier.
2003.
IdentifyingSemantic Roles Using Combinatory CategorialGrammar.
Conference on Empirical Methods inNatural Language Processing (EMNLP).Xia, Fei, 2000, The Part-of-Speech Tagging Guidelinesfor the Penn Chinese Treebank (3.0).
IRCS Report00-07.
Philadelphia, PA: University of Pennsylvania.Appendix:Figure 6: The detail classification of semantic roles in the Sinica Treebank
