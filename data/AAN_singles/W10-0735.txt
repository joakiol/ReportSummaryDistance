Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon?s Mechanical Turk, pages 217?221,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsError Driven Paraphrase Annotation using Mechanical TurkOlivia BuzekComputer Science and LinguisticsUniversity of MarylandCollege Park, MD 20742, USAolivia.buzek@gmail.comPhilip ResnikLinguistics and UMIACSUniversity of MarylandCollege Park, MD 20742, USAresnik@umd.eduBenjamin B. BedersonComputer Science and HCILUniversity of MarylandCollege Park, MD 20742, USAbederson@cs.umd.eduAbstractThe source text provided to a machine translationsystem is typically only one of many ways the inputsentence could have been expressed, and alternativeforms of expression can often produce a better trans-lation.
We introduce here error driven paraphras-ing of source sentences: instead of paraphrasing asource sentence exhaustively, we obtain paraphrasesfor only the parts that are predicted to be problematicfor the translation system.
We report on an AmazonMechanical Turk study that explores this idea, andestablishes via an oracle evaluation that it holds thepotential to substantially improve translation quality.1 IntroductionThe source text provided to a translation system is typ-ically only one of many ways the input sentence couldhave been expressed, and alternative forms of expressioncan often produce better translation.
This observation isfamiliar to most statistical MT researchers in the form ofpreprocessing choices ?
for example, one segmentationof a Chinese sentence might yield better translations thananother.1 Over the past several years, MT frameworkshave been developed that permit all the alternatives to beused as input, represented efficiently as a confusion net-work, lattice, or forest, rather than forcing selection ofa single input representation.
This has improved perfor-mance when applied to phenomena including segmenta-tion, morphological analysis, and more recently sourcelangage word order (Dyer, 2007; Dyer et al, 2008; Dyerand Resnik, to appear).We have begun to explore the application of the samekey idea beyond low-level processing phenomena suchas segmentation, instead looking at alternative expres-sions of meaning.
For example, consider translating The1Chinese is written without spaces, so most MT systems need tosegment the input into words as a preprocessing step.Democratic candidates stepped up their attacks duringthe debate.
The same basic meaning could have been ex-pressed in many different ways, e.g.:?
During the debate the Democratic candidatesstepped up their attacks.?
The Democratic contenders ratcheted up their at-tacks during the debate.?
The Democratic candidates attacked more aggres-sively during the debate.?
The candidates in the Democratic debate attackedmore vigorously.These examples illustrate lexical variation, as well as syn-tactic differences, e.g.
whether the attacking or the in-creasing serves as the main verb.
We hypothesize thatvariation of this kind holds a potential advantage fortranslation systems, namely that some variations may bemore easily translated than others depending on the train-ing data that was given to the system, and we can im-prove translation quality by allowing a system to take bestadvantage of the variations it knows about, at the sub-sentential level, just as the systems described above cantake advantage of alternative segmentations.Paraphrase lattices provide a way to make this hypoth-esis operational.
This idea is a variation on the uses ofparaphrase in translation introduced by Callison-Burchand explored by others, as well (Callison-Burch et al,2006; Madnani et al, 2007; Callison-Burch, 2008; Mar-ton et al, 2009).
These authors have shown that perfor-mance improvements can be gained by exploiting para-phrases using phrase pivoting.
We have investigated us-ing pivoting to create exhaustive paraphrase lattices, andwe have also investigated defining upper bounds by elic-iting human sub-sentential paraphrases using Mechani-cal Turk.
Unfortunately, in both cases, we have foundthe size of the paraphrase lattice prohibitive: there are217too many spans to paraphrase to make using Turk cost-effective, and automatically generated paraphrase latticesturn out to be too noisy to produce improved translations.A potential solution to this problem comes from a dif-ferent line of work we are pursuing, in which translationis viewed as a collaborative process involving people andmachines (Bederson et al, 2010).
Here, the idea is thatin translating from a source to a target language, source-and target-language speakers who are not bilingual cancollaborate to improve the quality of automatic transla-tion, via an iterative protocol involving translation, backtranslation, and the use of a very rich user interface.
Forexample, consider the following translation from Englishto French by an automatic MT system:?
Source: Polls indicate Brown, a state senator,and Coakley, Massachusetts?
Attorney General, arelocked in a virtual tie to fill the late Sen. TedKennedy?s Senate seat.?
System: Les sondages indiquent Brown,un se?nateur d?e?tat, et Coakley,Massachusetts?
Procureur ge?ne?ral, sont enferme?sdans une cravate virtuel a` remplir le regrette?se?nateur Ted Kennedy?s sie`ge au Se?nat.Someone with only a semester of college French (one ofthe authors) can look at this automatic translation, andsee that the underlined parts are probably wrong.
Chang-ing the source sentence to rephrase the underlined pieces(e.g.
changing Massachusetts?
Attorney General to theAttorney General of Massachusetts), we obtain a transla-tion that is still imperfect but is more acceptable:?
System: Les sondages indiquent que Brown, unse?nateur d?e?tat, et Coakley, le procureur ge?ne?raldu Massachusetts, sont enferme?s dans une cravatevirtuel pourvoir le sige au Se?nat de Sen. TedKennedy, qui est de?ce?de?
re?cemment.One could imagine (and, indeed, we are building) a vi-sual interface that allows a human participant on the tar-get side to communicate back to a source-side collabora-tor, in effect saying, ?These underlined pieces look likethey were translated poorly; can you rephrase the rele-vant parts of your sentence, and perhaps that will lead toa better translation?
?2Putting these ideas together ?
source paraphrase andidentification of difficult regions of input for translation?
we arrive at the idea of error driven paraphrasing ofsource sentences: instead of paraphrasing to introduce asmuch variation as possible everywhere in the sentence,we suggest that instead it makes sense to paraphrase only2Communicating which parts of the sentence are relevant across lan-guages is being done via projection across languages using word align-ments; cf.
(Hwa et al, 2001).the parts of a source sentence that are problematic for thetranslation system.
In Section 2 we give a first-pass algo-rithm for error driven paraphrasing, in Section 3 we de-scribe how this was realized using MTurk, and Sections 4and 5 provide an oracle evaluation, discussion, and con-clusions.2 Identifying source spans with errorsIn error driven paraphrasing, the key idea is to focus onsource spans that are likely to be problematic for trans-lation.
Although in principle one could use human feed-back from the target side to identify relevant spans, inthis paper we begin with an automatic approach, auto-matically identifying that are likely to be incorrect viaa novel algorithm.
Briefly, we automatically translatesource F to target E, then back-translate to produce F?
inthe source language.
We compare F and F?
using TERp(Snover et al, 2009), a form of string-edit distance thatidentifies various categories of differences between twosentences, and when at least two consecutive non-P (non-paraphrase) edits are found, we flag their smallest con-taining syntactic constituent.In more detail, we posit that areas of F?
where therewere many edits from F will correspond to areas in wherethe target translation did not match the English very well.Specifically, deletions (D), insertions (I), and shifts (S)are likely to represent errors, while matches (M) andparaphrases (P) probably represent a fairly accurate trans-lation.
Furthermore, we assume that while a single D, S,or I edit might be fairly meaningless, a string of at least 2of those types of edits is likely to represent a substantiveproblem in the translation.In order to identify reasonably meaningful paraphraseunits based on potential errors, we rely on a source lan-guage constituency parser.
Using the parse, we find thesmallest constituent of the sentence containing all of thetokens in a particular error string.
At times, these con-stituents can be quite large, even the entire sentence.
Toweed out these cases, we restrict constituent length to nomore than 7 tokens.For example, givenF The most recent probe to visit Jupiter was the Pluto-bound New Horizons spacecraft in late February 2007.E La investigacio?n ma?s reciente fue la visita de Ju?piter aPluto?n de la envolvente sonda New Horizons a fines defebrero de 2007.F?
The latest research visit Jupiter was the Pluto-bound NewHorizons spacecraft in late February 2007.spans in the the bolded phrase in F would be identified,based on the TERp alignment and smallest containingconstituent as shown in Figure 1.218NP PPNPFigure 1: TERp alignment of a source sentence and its back-translation in order to identify a problematic source span.3 Error driven paraphrasing on MTurkWe chose to use translation from English to Chinese inthis first foray into Mechanical Turk for error driven para-phrase.
This made sense for a number of reasons: first,because we expected to have a much easier time findingTurkers; second, because we could make use of a highquality English parser (in this case the Stanford parser);and, third, because it meant that we as researchers couldeasily read and judge the quality of Turkers?
paraphrases.To create an English-to-Chinese data set, we used theChinese-to-English data from the MT08 NIST machinetranslation evaluation.
We used English reference 0 asthe source sentence, and the original Chinese sentence asthe target.
We chose reference 0 because on inspectionthese references seemed most reflective of native Englishgrammar and usage.
The data set comprises 1357 sen-tence pairs.
Using the the above described algorithm toidentify possible problem areas in the translation, withthe Google Translate API providing both the translationand back-translation, we generated 1780 potential errorregions in 1006 of the sentences.
Then we created HITsboth to obtain paraphrases, and to validate the quality ofparaphrase responses.
Costs were $117.48 for obtainingmultiple paraphrases, and $44.06 for verification.3.1 Obtaining paraphrasesBased on the phrases marked as problematic by our algo-rithm, we created HITs asking for paraphrases within 5sentences, as illustrated in Figure 2.
Workers were given60 minutes to come up with a single paraphrase for eachof the five indicated problematic regions, for a reward of$0.10.
If a worker felt they could not come up with analternate phrasing for the marked phrase, they had theoption of marking an ?Unable to paraphrase?
checkbox.We assigned each task to 3 workers, resulting in 3 para-phrases for every marked phrase.
From the 1780 errors,we got 5340 responses.
Of these, 4821 contained actualparaphrase data, while the rest of the responses indicatedan inability to paraphrase, via the checkbox response.
Allparaphrases were passed on to the verification phase.3.2 Paraphrase VerificationIn the verification phase, we generated alternative fullsentences based on the 4821 paraphrases.
Workers wereshown an original sentence F and asked to compare it to atmost 5 alternatives, with a maximum of 20 comparisonsmade in a HIT.
(Recall that although F is the conven-tional notation for source sentences in machine transla-tion, in this study the F sentences are in English.)
Re-sponses were given in the form of radio buttons, mark-ing ?Yes?
for an alternate sentence if workers felt it wasgrammatical and accurately reflected the content of the219original sentence, or ?No?
if it did not meet both of thosecriteria.
Workers were given 30 minutes to make theirdecisions, for a reward of $0.05.
This task was also as-signed to 3 workers, resulting in 3 judgments for everyparaphrase.4 Evaluating ResultsUsing the paraphrase results from Mechanical Turk, weconstructed rephrased full sentences for every combina-tion of paraphrase alternatives.
For example, if a sentencehad 2 sub-spans paraphrased, and the two sub-spans had 2and 3 unique paraphrasings, respectively, we would con-struct 2 ?
3 = 6 alternative full sentences.
From the1780 predicted problematic phrases (within the 1006 au-tomatically identified sentences with possible translationerrors), we generated 14,934 rephrased sentences.
Eachrephrased English sentence was translated into a Chinesesentence, again via the Google Translate API.
We thenevaluated results for translation of the original sentences,and of all their paraphrase alternatives, via the TER met-ric, using the MT08 original Chinese sentence as thetarget-language reference translation.
The evaluation setincludes the 1000 sentence where at least one paraphrasewas provided.3Our evaluation takes the form of an oracle study: ifwe knew with perfect accuracy which variant of a sen-tence to translate, i.e.
among the original and all its para-phrases, based on knowledge of the reference translation,how well could we do?
An ?oracle?
telling us which vari-ant is best is not available in the real world, of course, butin situations like this one, oracle studies are often usedto establish the magnitude of the potential gain (Och etal., 2004).
In this case, the baseline is the average TERscore for the 1000 original sentences, 84.4.
If an ora-cle were permitted to choose which variant was the bestto translate, the average TER score would drop to 80.6.4Drilling down a bit further, we find that a better-translatedparaphrase sentence is available in 313 of the 1000 cases,or31.3%, and for those 313 cases, TER for the best para-phrase alternative improves on the TER for the originalsentence by 12.16 TER points.5 ConclusionsThis annotation effort has produced gold standard sub-sentential paraphrases and paraphrase quality ratings forspans in a large number of sentences, where the choiceof spans to paraphrase is specifically focused on regionsof the sentence that are difficult to translate.
In addi-3For the other 6 sentences, all problematic spans were marked ?Un-able to paraphrase?
by all 3 MTurkers.4TER measures errors, so lower is better.
A reduction in TER of 3.8for an MT evaluation dataset would be considered quite substantial; areduction of 1 point would typically be a publishable result.tion, we have performed an initial analysis, using human-generated paraphrases to provide an oracle evaluation ofhow much could be gained in translation by translatingparaphrases of problematic regions in the source sen-tence.
The results suggest if paraphrasing is automati-cally targeted to problematic source spans using a back-translation comparison, good paraphrases of the problem-atic spans could improve translation performance quitesubstantially.In future work, we will use a translation system sup-porting lattice input (Dyer et al, 2008), rather than theGoogle Translation API, in order to take advantage offully automatic error-driven paraphrasing, using pivot-based approaches (e.g.
(Callison-Burch et al, 2006)) tocomplete the automation of the error-driven paraphraseprocess.
We will also investigate the use of human ratherthan machine identification of likely translation prob-lems, in the context of collaborative translation (Beder-son et al, 2010).ReferencesBenjamin B. Bederson, Chang Hu, and Philip Resnik.
2010.
Trans-lation by iterative collaboration between monolingual users.
InGraphics Interface (GI) conference.Chris Callison-Burch, Philipp Koehn, and Miles Osborne.
2006.Improved statistical machine translation using paraphrases.
InRobert C. Moore, Jeff A. Bilmes, Jennifer Chu-Carroll, and MarkSanderson, editors, HLT-NAACL.
The Association for Computa-tional Linguistics.Chris Callison-Burch.
2008.
Syntactic constraints on paraphrases ex-tracted from parallel corpora.
In EMNLP, pages 196?205.
ACL.Chris Dyer and Philip Resnik.
to appear.
Forest translation.
InNAACL?10.C.
Dyer, S. Muresan, and P. Resnik.
2008.
Generalizing word latticetranslation.
In Proceedings of HLT-ACL, Columbus, OH.C.
Dyer.
2007.
Noisier channel translation: translation from morpho-logically complex languages.
In Proceedings of the Second Work-shop on Statistical Machine Translation, Prague, June.Rebecca Hwa, Philip Resnik, Amy Weinberg, and Okan Kolak.
2001.Evaluating translational correspondence using annotation projection.In ACL ?02: Proceedings of the 40th Annual Meeting on Associa-tion for Computational Linguistics, pages 392?399, Morristown, NJ,USA.
Association for Computational Linguistics.Nitin Madnani, Necip Fazil Ayan, Philip Resnik, and Bonnie Dorr.2007.
Using paraphrases for parameter tuning in statistical ma-chine translation.
In Proceedings of the Second Workshop on Statis-tical Machine Translation, pages 120?127, Prague, Czech Republic,June.
Association for Computational Linguistics.Yuval Marton, Chris Callison-Burch, and Philip Resnik.
2009.
Im-proved statistical machine translation using monolingually-derivedparaphrases.
In Proceedings of the 2009 Conference on EmpiricalMethods in Natural Language Processing, pages 381?390, Singa-pore, August.
Association for Computational Linguistics.Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur, Anoop Sarkar,Kenji Yamada, Alexander Fraser, Shankar Kumar, Libin Shen, DavidSmith, Katherine Eng, Viren Jain, Zhen Jin, and Dragomir R. Radev.2004.
A smorgasbord of features for statistical machine translation.In HLT-NAACL, pages 161?168.Matt Snover, Nitin Madnani, Bonnie Dorr, and Richard Schwartz.2009.
TER-Plus: Paraphrases, Semantic, and Alignment Enhance-ments to Translation Edit Rate.
Machine Translation.220Figure 2: HIT format 1: Obtaining sub-sentential paraphrases.
Note that as the MTurker types a paraphrase into the box,whatis typed appears immediately (character by character) in the full-sentence context under ?New sentence?, so that they can seeimmediately how the entire sentence looks with their paraphrase.the press trust of india quotedthe government minister for relief and rehabilitation kadamkadam, the governments relief and rehabilitation minister (2/3)the government minister concerned with relief and rehabiliation kadam (1/3)as revealing today that in the last week, the monsoon has started inall of indias states oneevery one of indias state, one (3/3)each of Indias states one (2/3)all states of india one (1/3)after another, and that the financial losses and casualties have been serious in all areas.
just in maharashtra, the state whichincludesmumbai, indias largest city,india?s largest city, mumbai (3/3)the largest city in India, Mumbai, (3/3)mumbai, the largest city of india, (3/3)the number of peopleknown to have diedwho died (3/3)identified to have died (2/3)known to have passed away (2/3)has now reached 358.Figure 3: Example of error-driven paraphrases produced via HIT format 1, above, for a single sentence.
The paraphrase spans(indented) are shown with the number of MTurkers, out of 3, who labeled that paraphrase in context as acceptable using a ?vali-dation?
HIT.221
