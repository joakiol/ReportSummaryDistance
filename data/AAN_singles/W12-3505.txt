Proceedings of the 1st Workshop on Speech and Multimodal Interaction in Assistive Environments, pages 28?33,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsReduction of Non-stationary Noise for a Robotic Living Assistant usingSparse Non-negative Matrix FactorizationBenjamin Cauchi 1, Stefan Goetze 1, Simon Doclo 1,21Fraunhofer Institute for Digital Media Technology (IDMT), Project groupHearing, Speech and Audio Technology (HSA), 26129 Oldenburg, Germany2University of Oldenburg, Signal Processing group, 26129 Oldenburg, Germany{benjamin.cauchi,s.goetze,simon.doclo}@idmt.fraunhofer.deAbstractDue to the demographic changes, support bymeans of assistive systems will become in-evitable for home care and in nursing homes.Robot systems are promising solutions buttheir value has to be acknowledged by the pa-tients and the care personnel.
Natural and in-tuitive human-machine interfaces are an es-sential feature to achieve acceptance of theusers.
Therefore, automatic speech recogni-tion (ASR) is a promising modality for suchassistive devices.
However, noises producedduring movement of robots can degrade theASR performances.
This work focuses onnoise reduction by a non-negative matrix fac-torization (NMF) approach to efficiently sup-press non stationary noise produced by thesensors of an assisting robot system.1 IntroductionThe amount of older people in today?s societies con-stantly grows due to demographic changes (Euro-pean Commision Staff, 2007).
Technical systemsbecome more and more common to support for rou-tine tasks of care givers or to assist older personsliving alone in their home environments (Alliance,2009).
Various technical assistive systems have beendeveloped recently (Lisetti et al, 2003), rangingfrom reminder systems (Boll et al, 2010; Goetzeet al, 2010) to assisting robots (Chew et al, 2010;Goetze et al, 2012).
If robot systems are supposedto navigate autonomously they usually rely on visionsensors (Aragon-Camarasa et al, 2010) or acous-tic sensors (Youssef et al, ).
Acoustic signals areusually picked up by microphones mounted on therobot.
In real-world scenarios not only the desiredsignal part is picked up by these microphones as pre-sented in Figure 1.spectrum speechNRFiltery[k]=s[k]+n[k]h[k]hats[k]0.5 1 1.5 201234-25-20-15-10-500.5 1 1.5 201234-25-20-15-10-500.5 1 1.5 201234-25-20-15-10-50n[k]0.5 1 1.5 201234-25-20-15-10-50frequencys[k]timefrequencyspectrum noisetime timetimefrequencyfrequencyspectrum mic spectrum outputspectrum outputspectrum outputspectrum outputspectrum outputtimetimetimetimey(k)=s(k)+n(k)h(k)( )^n(k)s(k)Figure 1: General denoising schemeThe desired signal part is usually superposed withdisturbing noise originating from the environment orthe robot system itself.
This disturbance has to beremoved from the microphone signal before it canbe further processed, e.g.
for navigation, positionestimation, acoustic event detection, speaker detec-tion or automatic speech recognition.
This contri-bution focuses on acoustic input for a robot systemand more specifically on the noise reduction pre-processing which is needed to clean up noisy soundsignals.Automatic speech recognition (Huang et al,2001; W?lfel et al, 2009) is a convenient way to in-teract with robot assistants since speech is the mostnatural form of communication.
However, to en-sure acceptance of speech recognition systems a suf-28ficiently high recognition rate has to be achieved(Pfister and T., 2008).
Today?s speech recognitionsystems succeed in achieving this recognition ratefor environments with low amount of noise and re-verberation.
Unfortunately, while moving, robotscan produce noise degrading the reliability of theASR.This work focuses on a specific application, sup-pressing the non stationary noise produced by theultra-sonic sensors of a robotic assistant while mov-ing.
Please note that although in theory ultrasonicsensors do not produce sound disturbances in the au-dible range, artefacts due to the fast activation anddeactivation of the sensors are present in the audiblerange and are clearly perceivable as a disturbance inthe picked up microphone signal as shown later inFigure 6.UltrasonicSensorsFigure 2: Lower part of the robot with ultrasonic sen-sors (Metralabs, 2010).Non-negative Matrix Factorization (NMF) is anapproach introduced by Lee & Seung (Lee and Se-ung, 2001) in which the data is described as theproduct of a set of basis and of a set of activation co-efficients both being non-negative.
We will apply theNMF approach to remove the disturbances causedby the ultrasonic sensors from the microphone inputsignal in the following.
NMF and its various exten-sions have been proven efficient in sources separa-tion (Cichocki et al, ; Virtanen, 2007), superviseddetection of acoustic events (Cotton and Ellis, 2011)or to wind noise reduction (Schmidt et al, ).
Asthe NMF algorithm can be fed with prior informa-tion about the content to identify, it is a handy wayto suppress the non stationary noise produced by thesensors of the considered robotic assistant.The remainder of this paper is organized as fol-lows: The general NMF algorithm is presented inSection 2 and the proposed denoising method isdescribed in Section 3.
An experiment using theTIMIT (Zue et al, 1990) speech corpus is presentedin Section 4 and finally the performances are eval-uated in terms of achieved signal enhancement inSection 5 before Section 6 concludes the paper.2 Sparse Non-negative MatrixFactorization2.1 NMF algorithmNMF is a low-rank approximation technique formultivariate data decomposition.
Given a real val-ued non-negative matrix V of size n?m and a pos-itive integer r < min(n,m), it aims to find a factor-ization of V into a n?
r real matrix W and a r ?mreal matrix H such that:V ?W ?H (1)The multivariate data to decompose is stacked intoV, whose columns represent the different observa-tions, and whose rows represent the different vari-ables.
In the case of information extraction from au-dio files, V could be the amplitude of the spectro-gram and therefore, W would be a basis of spectralfeatures when H would represent the levels of acti-vation of each of those features along time.
The rankr of the factorization corresponds to the number ofelements present in the dictionary W, and thereof, tothe number of rows within H.NMF is an iterative process that can be fed withinformation about the contents to extract.
As an il-lustration of this ability, an artificial spectrogram ofa mixture of two chords, C and D, has been created.Figure 3 shows the initialization of the NMF algo-rithm.
V is the spectrogram of the mixture in whichthe two chords contain only notes?fundamentals andoverlap each other.
The Algorithm is fed with thespectral content of the C chord.Figure 4 shows that during the iterative process,the elements of W corresponding to the C chordremain unchanged while the other elements of Whave been updated to fit the spectral content of theD chord.
The output time activations within H cor-29respond to the presence of both chords within thematrix V.Figure 3: Illustration of the initialization of the NMF al-gorithm.
The spectral content of the C chord is input intoW while the other element of dictionary and activationcoefficients in H are randomly initialized.Figure 4: Illustration of the output of the NMF algorithm.The spectral content of the D chord has been learnedwhile the updated H corresponds to the activations of thechords C and D along time.2.2 Sparseness ConstraintThe very definition of sparseness (or sparsity) is thata vector is sparse when most of its elements are zero.In its application to NMF, the addition of a sparse-ness constraint ?
permits to trade off between thefitness of the factorization and the sparseness of H.At each iteration, the process aims at reducing acost function C. In this paper, a generalized versionof the Kullback Leibler divergence is used as costfunction:D(V,WH) =????V?
logVW ?H?
V + W ?H????
(2)In 2 the multiplication ?
and the division areelement-wise.
The sparseness constraint results inthe new cost function:C(V,WH) = D(V,WH) + ?
?ijHij (3)The norm of each of the objects within W is fixed tounity.3 Supervised NMF denoising3.1 Method overviewThe method is supervised in the sense that it usesa noise dictionary Wn built from a recording of theknown noise to be reduced.
The noise spectrogram?n, i.e.
the short-term fourier transform (STFT), iscomputed using a hamming window of 32ms and a50% overlap.
The magnitude Vn of ?n is input tothe NMF algorithm with a sparseness constraint ?and an order rn, providing the noise dictionary of rnspectral vectors.
The spectrogram Vs of the noisyspeech is then input to the NMF algorithm alongwith Wn in order to obtain the denoised speech spec-trogram.3.2 Separation of the speech signalHsHnSpectrogramWnWsNoisy DenoisedSynthesisNMFFigure 5: Overview of the NMF based denoising.The denoising is summarized in Figure 5.
Thespectrum ?s of the noisy speech and its amplitudeVs are computed as in Section 3.1.
Vs is input tothe NMF algorithm along with Wn.
The order offactorization r is equal to rn + rs, rs being the num-ber of spectral vector used in the speech dictionaryWs.
Different sparseness constraint ?n and ?s can30be applied to the activation matrices Hn and Hs.Given V ?
Rn?m+ , r ?
N?
s.t.
r < min(n,m)minimize C(V,WH) w.r.t.W,H (4)subject to W ?
Rn?r+ , H ?
Rr?m+The update rules on W and H can be expressed asmultiplicative updates:Ws ?Ws ?VWsHs?HTs1?HTsH?
H?WT ?
VWHWT ?1(5)The NMF algorithm provides thereof Ws and Hs tobe used to approximate the spectrogram of the de-noised speech.
Therefore, ?
being the matrix prod-uct:V?s = Ws ?Hs V?n = Wn ?Hn?
?s = ?s ?
V?sV?s+V?n(6)The denoised speech signal is finally obtained byapplying ISTFT on the spectrogram S?s.
The inter-ested reader is referred to (O?Grady and Pearlmutter,2006) for a more detailed discussion of the neededderivations for Eqs.
(5)-(6).4 Experiment4.1 ContextThe robot platform Scitos A5 (Metralabs, 2012) canbe used as a robotic assistant for elderly care.
Itsbuilt-in microphones allow to interact with the robotusing if their signal is analysed by an ASR sys-tem.
However, while in motion, the robot uses ul-trasonic sensors (c.f.
Figure 2) to detect potentialobstacles.
Their constant activation and deactivationproduces artifacts that can sever the ASR reliability.The following experiment aims to evaluate the effi-ciency of the denoising method proposed in Section3 on speech signals corrupted by this specific sen-sors noise.
The Figure 6 examplarily presents thespectrogram of a corrupted speech signal.4.2 ProtocolThe noise produced by the sensors and the roomimpulse response (RIR) have been recorded in aquiet office room using the robot?s microphone.
Thetest data has been built from the test portion of theFrequency inHz80007000600050004000300020001000?30?25?20?15?10?50Time in sFrequency inHz0 1 2 3 4 580007000600050004000300020001000?30?25?20?15?10?50Figure 6: Spectrogram of a speech sentence from theTIMIT corpora: ?She had your dark suit in greasy washwater all year.
?, clean (top) and with added sensors noiseat SNR=10dB.TIMIT corpus (Zue et al, 1990).
The clean speechfiles have been built concatenating a silent period of0.5 seconds in their beginning, to allow for compari-son with methods relying on a voice activity detector(VAD), and convolving it with the measured RIR.From those prepared clean files, noisy corpora havebeen built by adding the recorded sensors noise witha SNR set to 10, 5, 0 and -5 dB.
In real scenarios, theSNR of the speech corrupted by the sensors noisevary between 5 and 10 dB depending on the loud-ness of the speaker and the distance between himand the robot.When applying the NMF algorithm the cost func-tion (3) has been used but no stop criterion has beenset and a fixed number of 25 iterations has beenrun.
Wn has been built by applying the NMF al-gorithm with rn = 64 and ?
= 0 to a 10 secondsnoise recording.
When applying the algorithm to thespeech samples denoising, r has been set to 128.
Adifferent sparseness constraint has been applied toHn and Hs with ?n = 0 and ?s = 0.2.As a reference, the noisy sound samples have as31well been processed using a state-of-the-art single-channel noise reduction scheme, i.e.
the decision-directed approach according to (Ephraim and Malah,1985) based on two different noise estimationschemes, i.e.
the minimum statistics approach (MS)as described in (Martin, 2001) and the minimummean square error (MMSE) approach accordingto (Gerkmann and Hendriks, 2011).5 ResultsThe achieved denoising is evaluated with the SNRof the denoised samples and with the noise reduc-tion (NR) as described in (Loizou, 2007).
For bothscores, the presented values are the mean of theachieved scores on all tested speech samples andthe standard deviation along the corpus.
The resultsare presented in Figure 7 for varying input SNR andspectrograms of a denoised speech sample using thethree methods is shown in Figure 8.
It appears thatthe NMF based method provides better results, bothin term of signal enhancement and of reliability.10 5 0 ?5?8?4048SNR of noisy signal in dBNRof denoisedsignal indB1216202428SNRof denoisedsignal indBNMFMMSEMS10 5 0 ?5?8?4048SNR of noisy signal in dBNRof denoisedsignal indB1216202428SNRof denoisedsignal indBNMFMMSEMSFigure 7: Mean and standard deviation of the achievedSNR and NR for the three tested methods and for differ-ent noise levels (SNR).Frequency inHz80007000600050004000300020001000?30?25?20?15?10?50Frequency inHz80007000600050004000300020001000?30?25?20?15?10?50Time in sFrequency inHz0 1 2 3 4 580007000600050004000300020001000?30?25?20?15?10?50Figure 8: Spectrogram of a denoised signal using thethree different methods, MS (top), MMSE (middle) andNMF.6 ConclusionA NMF based method to enhance speech signalwhen provided with spectral knowledge of the noisehas been presented.
This method has been applied tothe reduction of the non stationary noise producedby the sensors of a robotic assistant.
When testedon a corpus of speech signals, the proposed methodachieved better performances than well known VADbased denoising.Further works would include fine tuning of themethod, such as determining the optimal number ofiterations to obtain the best trade off between en-hancement and computing cost, as well as the use ofspectro temporal patches as elements of dictionary.327 AcknowledgementThis work was partially supported by the "Adapt-able Ambient Living Assistant" (ALIAS) project co-funded by the European Commission and the Fed-eral Ministry of Education and Research (BMBF).ReferencesThe European Ambient Assisted Living Innovation Al-liance.
2009.
Ambient Assisted Living Roadmap.VDI/VDE-IT AALIANCE Office.G.
Aragon-Camarasa, H. Fattah, and J. Paul Siebert.2010.
Towards a unified visual framework in a binoc-ular active robot vision system.
Robotics and Au-tonomous Systems, 58(3):276?286.S.
Boll, W. Heuten, E.M. Meyer, and M. , Meis.
2010.Development of a Multimodal Reminder System forOlder Persons in their Residential Home.
Informaticsfor Health and Social Care, SI Ageing & Technology,35(4).Selene Chew, Willie Tay, Danielle Smit, and ChristophBartneck.
2010.
Do social robots walk or roll?
InShuzhi Ge, Haizhou Li, John-John Cabibihan, andYeow Tan, editors, Social Robotics, volume 6414 ofLecture Notes in Computer Science, pages 355?361.Springer Berlin / Heidelberg.A.
Cichocki, R. Zdunek, and S. Amari.
New algorithmsfor non-negative matrix factorization in applicationsto blind source separation.
In Proc.
of Acoustics,Speech and Signal Processing, 2006.
ICASSP 2006.,volume 5, pages V?V, Toulouse, France.C.V.
Cotton and D.P.W.
Ellis.
2011.
Spectral vs. spectro-temporal features for acoustic event detection.
InProc.
of 2011 IEEE Workshop on Applications of Sig-nal Processing to Audio and Acoustics (WASPAA),pages 69 ?72, New Paltz, NY, USA, oct.Y.
Ephraim and D. Malah.
1985.
Speech enhancementusing a minimum mean-square error log-spectral am-plitude estimator.
IEEE Transactions on Acoustics,Speech and Signal Processing, 33(2):443?445.European Commision Staff.
2007.
Working Document.Europes Demografic Future: Facts and Figures.
Tech-nical report, Commission of the European Communi-ties.T.
Gerkmann and R.C.
Hendriks.
2011.
Noise power es-timation based on the probability of speech presence.In Proc.
of 2011 IEEE Workshop on Applications ofSignal Processing to Audio and Acoustics (WASPAA),pages 145?148, New Paltz, NY, USA.S.
Goetze, N. Moritz, J.E.
Appell, M. Meis, C. Bartsch,and J. Bitzer.
2010.
Acoustic user interfaces forambient-assisted living technologies.
Informatics forHealth and Social Care.S.
Goetze, S. Fischer, N. Moritz, J.E.
Appell, and F. Wall-hoff.
2012.
Multimodal human-machine interactionfor service robots in home-care environments.
Jeju,Republic of Korea.X.
Huang, A. Acero, H.W.
Hon, et al 2001.
Spokenlanguage processing, volume 15.
Prentice Hall PTRNew Jersey.D.D.
Lee and H.S.
Seung.
2001.
Algorithms for non-negative matrix factorization.
Advances in neural in-formation processing systems, 13.C.
Lisetti, F. Nasoz, C. LeRouge, O. Ozyer, and K. Al-varez.
2003.
Developing multimodal intelligent affec-tive interfaces for tele-home health care.
InternationalJournal of Human-Computer Studies, 59(1-2):245 ?255.
Applications of Affective Computing in Human-Computer Interaction.P.C.
Loizou.
2007.
Speech Enhancement: Theory andPractice.
CRC Press Inc., Boca Raton, USA.R.
Martin.
2001.
Noise power spectral density estima-tion based on optimal smoothing and minimum statis-tics.
IEEE Transactions on Speech and Audio Process-ing, 9(5):504?512.Metralabs.
2010.
Technical manual.Metralabs.
2012. http://www.metralabs.com.P.D.
O?Grady and B.A.
Pearlmutter.
2006.
Convolu-tive non-negative matrix factorisation with a sparse-ness constraint.
In Proc.
of the 2006 16th IEEE Sig-nal Processing Society Workshop on Machine Learn-ing for Signal Processing, Maynooth, Ireland.B.
Pfister and Kaufmann T. 2008.
Speech processingFundamentals and mthods for speech synthesis andspeech recognition (German original title: Sprachver-arbeitun Grundlagen und Methoden der Sprachsyn-these und Spracherkennung).
Springer, Berlin Heidel-berg.M.N.
Schmidt, J. Larsen, and F.T.
Hsiao.
Wind noise re-duction using non-negative sparse coding.
In Proc.
ofthe 2007 17th IEEE Signal Processing Society Work-shop on Machine Learning for Signal Processing,Thessaloniki, Greece.T.
Virtanen.
2007.
Monaural sound source separa-tion by nonnegative matrix factorization with tempo-ral continuity and sparseness criteria.
IEEE Trans-actions on Audio, Speech, and Language Processing,15(3):1066?1074.M.
W?lfel, J.W.
McDonough, and Inc Ebrary.
2009.
Dis-tant speech recognition.
Wiley Online Library.K.
Youssef, S. Argentieri, and J.L.
Zarader.
Binauralspeaker recognition for humanoid robots.
In Proc.
of2010 11th International Conference on Control Au-tomation Robotics & Vision (ICARCV), Singapore, Re-public of Singapore.V.
Zue, S. Seneff, and J.
Glass.
1990.
Speech databasedevelopment at MIT: TIMIT and beyond.
SpeechCommunication, 9(4):351?356.33
