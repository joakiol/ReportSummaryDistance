The F i t ted Parse:100% Parsing Capabi l iW in a Syntact ic  Grammar  o f  Engl ishKaren Jensen and George E. HeidornComputer  Sciences DepartmentIBM Thomas J. Watson Research CenterYorktown Heights, Hew York 10598AbstractA technique is described for performing fitted parsing.After the rules of a more conventional syntactic grammar areunable to produce a parse for an input string, this techniquecan be used to produce a reasonable approximate parse thatcan serve as input to the remaining stages of processing.
Thepaper describes how fitted parsing is done in the EP\ [STLEsystem and discusses how it can help in deal ing with manydifficult problems of natural anguage analysis.In t roduct ionThe EP ISTLE  project has as its long-range goal the ma-chine processing of natural language text in an office environ-ment.
Ultimately we intend to have software that will be ableto parse and understand ordinary prose documents  (such asthose that an off ice principal might expect his secretary tocope with), and will be able to generate at least a first draft  ofa business letter or memo.
Our  current goal is a system forcritiquing written material on points of grammar and style.Our  grammar is written in NLP (Heidorn 1972).
an aug-mented phrase structure language which is implemented inL ISP/370.
The EPISTLE grammar currently uses syntactic,but not semantic, information.
Access to an on-line standarddictionary with about 130.000 entries, including part-of-speechand some other syntactic information (such as transitivity ofverbs), makes the system's vocabulary essentially unlimited.We test and improve the grammar by regularly running it on adata base of 2254 sentences from 411 actual business letters.Most of these sentences are rather complicated; the longestcontains 63 words, and the average length is 19.2 words.Since the subset of English which is represented in busi-ness documents ,s very large, we need a very comprehensivegrammar and robust parser.
In the course of this work wehave developed some new techniques to help deal with therefractory nature of natural language syntax.
In this paper wediscuss one such technique: the fitted parse, which guaranteesthe production of a reasonable parse tree for any string, nomatter how unorthodox that string may be.
The parse which isproduced by fimng might not be perfect; but it will always bereasonable and useful, and will allow for later refinement bysemantic processing.There is a certain perception of parsing that leads to thedevelopment of techniques like this one: namely, that tryingto write a grammar to describe explicitly all and only the sen-fences of a natural  language is about as practical as trying tofind the Holy Grail.
Hot  only will the effort expended beHerculean, it will be doomed to failure.
Instead we take aheuristic approach and consider that a natural  language parsercan be divided into three parts:(a) a set of rules, called the core grammor, that preciselydefine the central, agreed-upon grammatica l  structuresof a language;(b) per ipheral  procedures that handle parsing ambiguity:when the core grammar produces more than one parse,these procedures decide which of the multiple parses isto be preferred;(c) peripheral procedures that handle parsing failure: whenthe core grammar  cannot  define an acceptable parse,these procedures assign some reasonable structure tO theinput.In EPISTLE, (a) the core grammar consists at present of a setof about 300 syntax rules; (b) ambiguity is resolved by using ametric that ranks alternative parses (Heidorn 1982): and (c)parse failure is handled by the fitting procedure described here.\[n using the terms core grammar and periphery we areconsciously echoing recent work in generative grammar,  but weare applying the terms in a somewhat different way.
Coregrammar,  in current linguistic theory, suggests the notion of aset of very general rules which define universal properties ofhuman language and effectively set limits on the types ofgrammars that any particular language may have; peripheryphenomena are those constructions which are peculiar to par-ticular languages and which require added rules beyond whatthe core grammar will provide (Lasnik and Freidin 1981 ) Ourcurrent work is not concerned with the meta-ruies of a Univer-sal Grammar.
But we have found that a distinction betweencore and periphery is useful even within a grammar of a panic-ular language ~ in this case, English.This paper first reviews parsing in EPISTLE,  and thendescribes the fitting procedure, followed by several examplesof its application.
Then the benefits of parse fitting and theresults of using it in our system are discussed, followed by itsrelation to other work.93Parsing in EPISTLEEPISTLE's parser is written in the NLP programminglanguage, which works with augmented phrase structure rulesand with attr ibute-value r cords, which are manipulated by therules.
When NLP is used to parse natural  language text, therecords describe constituents, and the rules put these constitu-ents together to form ever larger const ituent (or record) struc-tures.
Records conta in all the computat iona l  and l inguisticinformat ion associated with words,  with larger const i tuents,and with the parse formation.
At this time our grammar issentence-based; we do not, for instance, create record struc-tures to describe paragraphs.
Details of the EPISTLE systemand of its core grammar may be found in Miller et al, 1981,and Heidorn et al, 1982.A close examinat ion of parse trees produced by the coregrammar  will of ten reveal branch at tachments  that are notquite right: for example, semantical ly incongruous preposit ion-al phrase attachments .
In line with our pragmat ic  parsingphilosophy, our core grammar is designed to produce uniqueapprox imate parses.
(Recal l  that we current ly  have accessonly to syntact ic and morphological  information about constit-uents.)
In the cases where semantic or pragmatic informationis needed before a proper attachment can be made, rather thanproduce a confusion of multiple parses we force the grammarto try to assign a single parse.
This is usually done by forcingsome attachments to be made to the closest, or rightmost,available constituent.
This strategy only rarely impedes thetype of g rammar-check ing  and sty le-checking that we areworking on.
And we feel that a single parse with a consistentattachment scheme will yield much more easily to later seman-tic processing than would a large number of different struc-tures.The rules of the core grammar (CG)  produce single ap-proximate parses for the largest percentage of input text.
TheCG can always be improved and its coverage extended; workon improving the EPISTLE CG is continual.
But the coverageof a core grammar will never reach 100%.
Natural  language isan organic symbol system; it does not submit to cast- i roncontrol.
For  those strings that cannot  be fully parsed by rulesof the core grammar we use a heuristic best fit procedure thatproduces a reasonable parse structure.The Fitt ing ProcedureThe fitting procedure begins after the CG rules have beenapplied in a bottom-up, parallel fashion, but have failed toproduce an S node that covers the string.
At this point, as aby-product of bottom-up parsing, records are available forinspection that describe the various segments of the inputstring from many perspectives, according to the rules that havebeen applied.
The term fitting has to do with selecting andfitting these pieces of the analysis together in a reasonablefashion.The algorithm proceeds in two main stages: first, a headconstituent is chosen; next, remaining constituents are fitted in.In our current implementat ion,  candidates for the head aretested preferential ly as follows, from most to least desirable:(a) VPs with tense and subject;(b) VPs with tense but no subject:(c) segments other than VP:(d) untensed VPs.If more than one candidate is found in any category,  the onepreferred is the widest (covering most text).
If there is a tiefor widest, the leftmost of those is preferred.
\[f there is a tiefor leftmost, the one with the best value for the parse metric ischosen.
If there is still a tie (a very unlikely case),  an arbi-t rary choice is made.
(Note that we consider a VP to be anysegment of text that has a verb as its head element.
)The f itt ing process is complete if the head const i tuentcovers the entire input str ing (as would be the case if thestring contained just a noun phrase, for example,  "Salutat ionsand congratu lat ions") .
If the head const i tuent does not coverthe entire string, remaining const ituents are added on eitherside.
with the fol lowing order of preference:(a) segments other than VP;(b) untensed VPs:(c) tensed VPs.As with the choice of head.
the widest candidate is preferredat each step.
The fit moves outward  from the head.
bothleftward to the beginning of the string, and r ightward to theend.
until the entire input str ing has been fitted into a bestapproximate parse tree.
The overall  effect of the fitting proc-ess is to select the largest chunk  of sentence- l ike mater ia lwithin a text string and consider it to be central,  with left-overchunks of  text at tached in some reasonable manner.As a simple example, consider this text string which ap-peared in one of our EPfSTLE data base letters:"Example:  75 percent of $250.00 is $187.50.
"Because this string has a capital ized first word and a period atits end.
it is submitted to the core grammar  for considerat ionas a sentence.
But it is not a sentence, and so the CG will failto arrive at a completed parse.
However.
during processing.the CG will have assigned many structures to its many sub-strings.
Looking for a head const i tuent among these struc-tures, the fitting procedure will first seek VPs with tense andsubject.
Several are present:  "$250.00  is".
"percent  of$250.00 is", "$250.00  is $187.50" .
and so on.
The widest andleftmost of these VP const ituents is the one which covers thestring "75 percent of $250.00 is $187.50" ,  so it will be chosenas head.The fitting process then looks for addit ional const ituentsto the left, favoring ones other than VP.
\[t finds first thecolon, and then the word "Example"  In this ~tring the onlyconst ituent fol lowing the head is the final period, which is dulyadded.
The complete fitted parse is shown in Figure I.The form of parse tree used here shows the top-downstructure of the string from left to right, with the terminalnodes being the last item on each line.
At each level of thetree (in a vertical column),  the head element of a const ituent ismarked with an asterisk.
The other elements above and beloware pre- and post-modif iers.
The highest element of the treesshown here is F ITTED, rather than the more usual SENT.
(Itis important to remember that these parse diagrams are onlyshorthand representations for the NLP record structures, whichcontain an abundance of in format ion about  the str ing proc-essed.
)The tree of Figure I. which would be lost if we restrictedourselves to the precise rules of the core grammar,  is nowavailable for examination, for grammar and style checking, andultimately for semantic interpretation, It can take its place tnthe stream of cont inuous text and be analyzed for what it isa sentence fragment,  interpretable only by reference to othersentences in context.9L.F ITTEDI - - -NP  .
.
.
.
.
.
NOUN- - - - "Example"\[ ------'!
: ItI - - -VP"IIIIII - - - - - - l l  , It.
.
.
.
NP I  .
.
.
.
.
QUANT- - -NUM* .
.
.
.
.
.
"75"I .
.
.
.
.
NOUN*- - - "percent"I .
.
.
.
.
PP l  .
.
.
.
.
PREP  .
.
.
.
.
.
"o f "I .
.
.
.
.
MONEY,  .
.
.
.
.
.
$250.00".
.
.
.
VERBS-_ .
, , i s , ,.
.
.
.
NP  .
.
.
.
.
.
MONEY, - - "$187.50"Figm'e 1.
An example fitted parse tree.F ITTED I - - -NP"  I .
.
.
.
N91  .
.
.
.
.
A J9  .
.
.
.
.
AD J*  .
.
.
.
"Good"I I I .
.
.
.
.
NOUN' - - - "  luck"I I .
.
.
.
CONJ*  - - - "  and"I I .
.
.
.
NP  I .
.
.
.
.
A JP  .
.
.
.
.
AD J*  .
.
.
.
"good"I I .
.
.
.
.
NOUN*- - -  " se  11  ing"FIil,,,'e 2.
Fitted noun phrase (fragment).F ITTED I - - -VP*IIIIIIIIII - - - - - -"  t 11. .
.
.
AVP  I .
.
.
.
ADV"  .
.
.
.
"S  econd ly".
.
.
.
NP  I .
.
.
.
.
A JP  .
.
.
.
.
AD J  * .
.
.
.  "
the"I .
.
.
.
.
N9  .
.
.
.
.
.
NOUN*- - - "Annua l "l .
.
.
.
.
NP  .
.
.
.
.
.
NOUN*- - - "Commiss  ion"I .
.
.
.
.
NP  .
.
.
.
.
.
NOUN s - - - ' 'S ta tement ' 'I .
.
.
.
.
NOUN' - - - " to ta  I ".
.
.
.
VERB .
.
.
.  "
s  hou  id".
.
.
.
VERB.
- - - "be".
.
.
.
NP  .
.
.
.
.
.
MONEY* - - "  $ I a ,  682 .61  "i - - -AVP  .
.
.
.
.
ADV*  .
.
.
.
"not"I - - -NP  .
.
.
.
.
.
MONEY* - - "$  I ~ ,  682 .67"I - - - - - -"  ?
,rFit, urn 3.
Fitted sentence with ellipsis.Further ExamplesThe fitted parse approach can help to deal with manydifficult natural language problems, including fragments, diffi-cult cases of ellipsis, prol i feration of rules to handle singlephenomena, phenomena for which no rule seems adequate, andpunctuation horrors.
Each of these is discussed here withexamples.Fragments.
There are many of these in running text; theyare frequently NPs, as in Figure 2. and include common greet-ings.
farewells, and sentiments.
(N.b., all examples in thispaper are taken from the EPISTLE data base.
)Difficult cases of ellipsis.
In the sentence of Figure 3, whatwe really have at a semantic level is a conjunction of twopropositions which, if generated directly, would read: "TheAnnual Commission Statement total should be $14,682.61; theAnnual Commission Statement total should not beS\]4.682.67."
Deletion processes operating on the secondproposition are lawful (deletion of identical elements), butmassive.
It would be unwise to write a core grammar rule thatroutinely al lowed negadvized NPs to follow main clauses,because:(a) the proper analysis of this sentence would be obscured:some pieces - -  namely, the inferred concepts - -  aremissing from the second part of the surface sentence;(b) the linguistic general izat ion would be lost: any twoconjoined proposit ions can undergo deletion of identical(recoverable) elements.A fitted parse such as Figure 3 allows us to inspect the mainclause for syntactic and stylistic deviances, and at the sametime makes clear the breaking point between the two propost-tions and opens the door for a later semantic processing of theelided elements.Proliferation of rules to handle single phenomena.
Thereare some English constructions which, although they have afairly simple and unitary form, do not hold anything like aunitary ordering relation within clause boundaries.
The voca-tive is one of these:(a) Bit/.
I've been asked to clarify the enclosed letter.95F I TTE  D I - - -NP  .
.
.
.
.
.
NOUN * - - -  "B  i i i "- - - -  '* t "- - -VP*  I .
.
.
.
NP  .
.
.
.
.
.
PRON' - - - "  I "i .
.
.
.
VERB .
.
.
.  "
' ve"I .
.
.
.
VERB .
.
.
.
"been"I .
.
.
.
VERB, - - - "asked"I .
.
.
.
INFCL  i - - INFTO- - - "  to"I - -VERB*  .
.
.
.
.
c la r i fy"I - -NP  I .
.
.
.
.
A JP  .
.
.
.
.
AD J "  .
.
.
.  "
the"I .
.
.
.
.
A JP  .
.
.
.
.
VERB' - - - "  enc losed"I .
.
.
.
.
NOUN' - - - "  le t te r "Figure 4.
Fitted sentence with initial vocative.F ITTED - - -NP  I .
.
.
.
.
A JP  .
.
.
.
.
AD J*  .
.
.
.
"Good"i .
.
.
.
.
NOUN*- - - "  luck"- - -PP  l .
.
.
.
.
PREP  .
.
.
.  "
to"I .
.
.
.
.
NP  .
.
.
.
.
.
PRON*- - - "you"I .
.
.
.
.
CONJ* - - - "  and"I .
.
.
.
.
NP  .
.
.
.
.
.
PRON*- - -  "yours"- - -CONJ  .
.
.
.
"and"- - -VP*  \[ .
.
.
.
NP  .
.
.
.
.
.
PRON*- - - "  I "l .
.
.
.
VERB*- - - "w ish"l .
.
.
.
NP  .
.
.
.
.
.
PRON*- - -  "you"\[ .
.
.
.
NP  .
.
.
.
.
A JP  .
.
.
.
.
AD J*  .
.
.
.  "
the"l .
.
.
.
.
ADV .
.
.
.
.
"VERY"l .
.
.
.
.
AD J*  .
.
.
.
"best "i .
.
.
.
PP  .
.
.
.
.
PREP  .
.
.
.  "
in".
.
.
.
.
A JP  .
.
.
.
.
AD J*  .
.
.
.
"your".
.
.
.
.
A JP  .
.
.
.
.
AD J*  .
.
.
.  "
fu ture".
.
.
.
.
NOUN, - - - "  e f fo r ts "Figure 5.
Fitted conjunct ion of noun phrase with clause.
(b) I've been asked.
BilL to clarify the enclosed letter.
(c) I've been asked to clarify the enclosed letter.
Bill.\[n longer sentences there would be even more possible placesto insert the vocative, of course.Rules could be written that would explicitly allow theplacement of a proper name.
surrounded by commas,  at differ-ent positions in the sentence ~ a different rule for each posi-tion.
But this solution Lacks elegance, makes a simple phenom-enon seem complicated, and always runs the risk of overlook-mg yet one more position where some other writer might inserta vocative.
The parse fitting procedure provides an alternativethat preserves the integrity of the main clause and adds thevocative at a break in the structure, which is where it belongs.as shown in Figure 4.
Other  similar phenomena,  such as par-entheticaI expressions, can be handled in this same fashion.Phenomena for which no rule seems adequate.
The sen-tence "Good luck to you and yours and l wish you the verybest in your future efforts."
is.
on the face of it.
a conjunct ionof a noun phrase (or NP plus PP) with a finite verb phrase.Such construct ions are not usually considered to he fully gram-matical, and a core grammar which contained a rule describingthis construct ion ought probably to be called a faulty grammar.Nevertheless, ordinary English correspondence abounds withstrings of this sort.
and readers have no diff iculty construingthem.
The fitted parse for this sentence in Figure 5 presentsthe finite clause as its head and adds the remaining const itu-ents in a reasonable fashion.
From this structure later seman-tic processing could infer that "Good luck to you and yours"really means "1 express /send/w ish  good luck to you andyours"  - -  a special case of formalized, ritualized ellipsis.Punctuation horrors.
In any large sample of natural  lan-guage text, there will be many irregularit ies of punctuat ionwhich, although perfectly understandable to readers,  can com-pletely disable an explicit computat ional  grammar.
In businesstext these difficulties are frequent.
Some can he caught andcorrected by punctuat ion checkers and balancers.
But otherscannot,  sometimes because, for all their trickiness, they ~tre notreally wrong.
Yet few grammarians would care to dignify, bydescribing it with rules of the core grammar,  a text string like:"Opt ions:  A l - (T ransmi t ter  Clocked by Dataset)B3-(without the 605 Recall Unit) CS-(with ABCRing Indicator) D8- twi thout  Auto Answer) E I0 -(Auto Ring Selective).
"Our parse fitting procedure handles this example by building astring of NPs separated with punctuation marks, as shown inFigure 6.
This solution at least enables us to get a handle onthe contents of the string.96F ITTED I - - -NP  .
.
.
.
.
.
NOUN*  - - -  "Opt  ions"I ------" : "I - - -NP  .
.
.
.
.
.
NOUN*- - -  "A I  "I - - - - - -  " - -  1)I - - - "  ( "I - - -NP  I .
.
.
.
.
NP .
.
.
.
.
.
NOUN*- - - "  T ransmi  t ie r "I I .
.
.
.
.
NOUNe- - - "C locked"I - - -PP  I .
.
.
.
.
PREP  .
.
.
.
.  '
by"I I .
.
.
.
.
NOUN*- - - "Dataset"I - - - "  ) "I - - -NP  .
.
.
.
.
.
NOUNS- - - "BY 'I - - - - - -  ) )  " ' )I - - -PP*  I .
.
.
.  "
( "I .
.
.
.
PREP  .
.
.
.
"w i thout"I .
.
.
.
A JP  .
.
.
.
.
AD J*  .
.
.
.  "
the"I .
.
.
.
QUANT-  - -NUM ?
.
.
.
.
"6  0 5"I .
.
.
.
NP  .
.
.
.
.
.
NOUN*- - - "Reca l  i "I .
.
.
.
NOUN*- - - "Un i t "I .
.
.
.  ")
": - - -NP  .
.
.
.
.
.
NOUN*- - -  "C5"___ , I _ , !- - -PP  I .
.
.
.
.  "
( "I .
.
.
.
.
PREP  .
.
.
.
.
.
w i th"I .
.
.
.
.
NP  .
.
.
.
.
.
NOUN*- - -  "ABC"I .
.
.
.
.
NP  .
.
.
.
.
.
NOUN s - - -  "R ing ' 'I .
.
.
.
.
NOUN*- - - "  Ind icator "I .
.
.
.
.  ")
"- - -NP  .
.
.
.
.
.
NOUN' - - -  "D8"___ , , _ , ,- - -PP  I .
.
.
.
.  "
( "I .
.
.
.
.
PREP  .
.
.
.
"w?
thou , "I .
.
.
.
.
NP .
.
.
.
.
.
NOUN*- - -  "AUTO"I .
.
.
.
.
NOUN e .
.
.
.
.
Answer"I .
.
.
.
.  ")
"- - -NP  .
.
.
.
.
.
NOUN*- - - "E  10"___ , t  .- - -NP  I .
.
.
.
.  "
( "I .
.
.
.
.
NP  .
.
.
.
.
.
NOUN*- - - "Auto"I .
.
.
.
.
NP  .
.
.
.
.
.
NOUN*- - -  "R ing ' 'I .
.
.
.
.
NOUN*- - - "Se lec t ive"I .
.
.
.
.  ")
"------".
"~re a. Fitted list.Benef i t sThere are two main benefits to be gained from using thefitted parse approach.
First, it allows for syntactic processing- -  for our purposes, grammar and style checking - -  to proceedtn the absence of a perfect parse.
Second, it provides a prom-ising structure to submit to later semantic processing routines.And parenthetically, a fitted parse diagram is a great aid torule debugging.
The place where the first break occurs be-tween the head constituent and its pre- or post-modifiers usu-ally indicates fairly precisely where the core grammar failed.It should be emphasized that a fitting procedure cannot beused as a substitute for explicit ru les ,  and that it in no waylessens the importance of the core grammar.
There is a tightinteraction between the two components.
The success of thefitted parse depends on the accuracy and completeness of thecore rules; a fit is only as good as its grammar.ResultsIn December of 1981. the EPISTLE grammar, which atthat time consisted of about 250 grammar ules and did notinclude the fitted parsing technique, was run on the data baseof ?.254 sentences from business letters of various types, Theinput corpus was very raw: it had not been edited for spellingor other typing errors, nor had it been manipulated in any waythat might have made parsing easier.At that time the system failed to parse 832. or 36%, ofthe input sentences .
(It gave single parses for 41?%.
doubleparses for l i t ,  , and 3 or more parses for 12?'o.)
Then weadded the fitting procedure and also worked to improve thecore grammar.Concentrating only on those 832 sentences which in De-cember failed to parse, we ran the grammar again in July,1982, on a subset of 163 of them.
This time the number ofcore grammar ules was 300.
Where originally the CG couldparse none of these 163 sentences, this time it yielded parses(mostly single or double) for 109 of them.
The remaining 54were handled by the fitting procedure.Close analysis of the 54 fitted parses revealed that 14 ofthese sentences bypass the core grammar simply because ofmissing dictionary information: for example, the CG containsa rule to parse ditransitive VPs (indirect object-taking VPs.97with verbs like "give" or "send"), but that rule will not applyif the verb is not marked as ditransitive.
The EPISTLE dic-tionary will eventually have all ditransitive verbs marked prop-erly, but right now it does not.Removing those 14 sentences from consideration, we areleft with a residue of 40 strings, or about 25% of the 163sentences, which we expect always to handle by means of thefitted parse.
These strings include all of the problem typesmentioned above (fragments, ellipsis, etc.
), and the fittedparses produced were adequate for our purposes.
It is not yetclear how this 25% might extrapolate to business text at large,but it seems safe to say that there will always be a significantpercentage of natural business correspondence which we can-not expect o parse with the core grammar, but which respondsnicely to peripheral processing techniques like those of thefitted parse.
(A more recent run of the entire data base result-ed m 27% fitted parses.
)Related WorkAlthough we know of no approach quite like the onedescribed here, other related work has been done.
Most ofthis work suggests that unparsable or ill-formed input shouldbe handled by relaxation techniques, i.e., by relaxing restric-tions in the grammar ules in some principled way.
This isundoubtedly a useful strategy - -  one which EPISTLE makesuse of, in fact, in its rules for detecting rammatical errors(Heidorn et al 1982).
However.
it is questionable whethersuch a strategy can ultimately succeed in the face of the over-whelming (for all practical purposes, infinite) variety of ill-formedness with which we are faced when We set out to parsetruly unrestricted natural anguage input.
If all ili-formednessis rule-based (Weischedel and Sondheimer 1981, p. 3), it canonly be by some very loose definition of the term rule, such asthat which might apply to the fitting algorithm described here.Thus Weischedel and Black, 1980, suggest hree tech-niques for responding intelligently to unparsable inputs:(al using presuppositions to determine user assumptions;this course is not available to a syntactic grammar likeEPISTLE's;Ibl using relaxation techniques;(cJ supplying the user with information about the pointwhere the parse blocked; this would require an interac-tive environment, which would not be possible for everytype of natural language processing application.Kwasny and Sondheimer.
1981. are strongproponents ofrelaxation techniques, which they use to handle both cases ofclearly ungrammatical structures, such as co-occurrence viola-r~ons like subject/verb disagreement, and cases of perfectlyacceptable but difficult constructions (ellipsis and conjunc-tion).Weischedel and Sondheimer.
1982. describe an improvedellipsis processor.
No longer is ellipsis handled with relaxationtechniques, but by predicting transformatwns of previous pars-ing paths which would allow for the matching of fragmentswith plausible contexts.
This plan would be appropriate as anext step after the fitted parse, but it does not guarantee aparse for all elided inputs.Hayes and Mouradian, 1981. also use the relaxation me-thod.
They achieve flexibility in their parser by relaxing con-sistency constraints (grammatical restrictions, like Kwasny andSondheimer's co-occurrence violations) and also by relaxingordering constraints.
However.
they are working with arestricted-domain semantic system and their approach, as theyadmit, "does not embody a solution for flexible parsing ofnatural anguage in general" (p. 236).The work of WilLS is heavily semantic and therefore quitedifferent from EPISTLE, but his general philosophy meshesnicely with the philosophy of the fitted parse: "It is proper toprefer the normal...but i would be absurd...not to accept theabnormal if it is described" (WilLs 1975, p. 267).
WilLS"approach to machine translation which involves doing someamount of the translation on a phrase-by-phrase basis is rele-vant here.
too, With fitted parsing, it might be possible to getusable translations for strings that cannot be completely parsedwith the core grammar by translating each phrase of the fittedparse separately.AcknowledgementsWe would like to thank Lance Miller for his interest andencouragement i  this work, and Roy Byrd, Martin Chodorow,Robert Granville and John Sown for their comments on anearlier version of this paper.ReferencesHayes, P.J.
and G.V.
Mouradian.
1981.
"Flexible Parsing" inAm.
J.
Camp.
Ling.
7.4.
232-242.Heidorn, G.E.
1972.
"Natural Language Inputs to a Simula-tion Programming System."
Technical Report NPS-55HD72101A.
Monterey, Calf Naval Postgraduate School.Heidorn, G.E.
1982.
"Experience with an Easily ComputedMetric for Ranking Alternative Parses" in Proc.
20th Annu-al Meeting of the ACL.
Toronto, Canada, 82-84.Heidorn.
G.E., K. Jensen.
L.A. Miller.
R.J. Byrd, and M.S.Chodorow.
1982.
"The EPISTLE Text-Critiquing Sys-tem" in IBM gys, J.
21.3.
305-326.Kwasny, S.C. and N.K.
Sondheimer.
1981.
"Relaxation Tech-niques for Parsing iU-Formed Input" in Am.
J. Comp.
Ling.7.2.
99-108Lasnik, H. and R. Freidin.
1981.
"Core Grammar, CaseTheory.
and Markedness" in Proc.
1979 GLOW Conf.Pisa, Italy.Miller.
L.A., G.E.
Heidorn and K. Jensen.
1981.
"Text-Critiquing with the EPISTLE System: An Authors's Aid toBetter Syntax" in AFIPS Con/'.
Proc.. Vol.
50.
Arlington.Va., 649-655.Weischedel.
R.M.
and J.E.
Black.
1980.
"Responding Intelli-gently to Unparsable Inputs" in Am.
J. Comp.
Ling.
6.2.97-109.Weischedel, R.M.
and N.K.
Sondheimer.
1981.
"A Frame-work for Processing Ill-Formed Input."
Research Report.Univ.
of Delaware.Weischedel, R.M.
and N.K.
Sondheimer.
1982.
"An Im-proved Heuristic for Ellipsis Processing" in Proc.
20th An-nual Meeting of the ACL.
Toronto, Canada, 85-88.Wilks.
Yorick, 1975, "An Intelligent Analyzer and Under-stander of English" in Comm.
ACM 18.5.
264-274.98
