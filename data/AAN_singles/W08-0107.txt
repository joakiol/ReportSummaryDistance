Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue, pages 54?63,Columbus, June 2008. c?2008 Association for Computational LinguisticsDegrees of Grounding Based on Evidence of UnderstandingAntonio RoqueUSC Institute for Creative TechnologiesMarina del Rey, CA, USAroque@ict.usc.eduDavid TraumUSC Institute for Creative TechnologiesMarina del Rey, CA, USAtraum@ict.usc.eduAbstractWe introduce the Degrees of Groundingmodel, which defines the extent to which ma-terial being discussed in a dialogue has beengrounded.
This model has been developed andevaluated by a corpus analysis, and includes aset of types of evidence of understanding, a setof degrees of groundedness, a set of ground-ing criteria, and methods for identifying eachof these.
We describe how this model can beused for dialogue management.1 IntroductionDialogue system researchers are active in investi-gating ways of detecting and recovering from er-ror, including determining when to provide confir-mations or rejections, or how to handle cases ofcomplete non-understanding (Bohus and Rudnicky,2005a; Bohus and Rudnicky, 2005b; Skantze, 2005).Studying the strategies that humans use whenspeaking amongst themselves can be helpful (Swertset al, 2000; Paek, 2003; Litman et al, 2006).
Oneapproach to studying how humans manage errors ofunderstanding is to view conversation as a joint ac-tivity, in which grounding, or the process of addingmaterial to the common ground between speakers,plays a central role (Clark and Schaefer, 1989).From this perspective, conversations are highly co-ordinated efforts in which participants work togetherto ensure that knowledge is properly understood byall participants.
There is a wide variety of groundingbehavior that is determined by the communicationmedium, among other things (Clark and Brennan,1991).This approach is developed computationally byTraum, who presents a model of grounding whichadapts Clark and Schaefer?s contributions model tomake it usable in an online dialogue system (Traum,1994).
Other computational approaches to ground-ing use decision theory (Paek and Horvitz, 2000a)or focus on modeling belief (Bunt et al, 2007).Grounding models generally consider material tobe in one of three states: ungrounded, in the processof becoming sufficiently grounded, or sufficientlygrounded.
(An exception is (Paek and Horvitz,2000b), who use a continuous model of grounded-ness.)
We are developing a model of grounding thatis attentive to a larger set of types of evidence of un-derstanding than is typical, and use this to define amodel of Degrees of Grounding, which tracks theextent to which material has become a part of thecommon ground.This model includes a set of types of Evidence ofUnderstanding that describes the kinds of cues thatthe dialogue gives about the state of grounding.
Aset of Degrees of Groundedness describes the ex-tent to which material has achieved mutual beliefwhile being discussed.
A set of Grounding Crite-ria describes the degree to which material needs tobe grounded.
Finally, the model provides algorithmsto assist dialogue management.The next section describes the radio domainwhich we used to begin developing this model.
Thedialogues in this domain contain a large amount ofconfirmation behavior, which make it a good testbedfor the initial development of the model.
However,because these radio dialogues are highly structuredwe are not yet able to make strong claims about the54generality of this model.In following sections we describe the componentsof the model, annotation evaluations, and ongoingdevelopment of the model.2 DomainThe domain for this corpus analysis involves a radio-based military training application.
This corpus wasdeveloped while building the Radiobot-CFF system(Roque et al, 2006) in which soldiers are trainedto perform artillery strike requests over a simulatedradio in an immersive virtual environment.Calls for Fire (CFFs) are coordinated artillery at-tacks on an enemy.
Several teams work together toexecute a CFF.
A Forward Observer (FO) team lo-cates an enemy target and initiates the call.
The FOteam is made up of two or more soldiers, usuallywith one soldier dedicated to spotting the enemy andanother soldier dedicated to operating the radio.
TheFO radio operator communicates with the Fire Di-rection Center (FDC) team, which decides whetherto execute the attack, and if so, which of the avail-able fire assets to use.
An example CFF is given inthe Appendix.3 Evidence of UnderstandingAn influential description of evidence of understand-ing was presented in (Clark and Schaefer, 1989), asshown in Table 1.
This set of types of evidence wasdescribed as being ?graded roughly from weakest tostrongest?
and was part of the acceptance phase of atwo-phase grounding process.
(Clark and Brennan,1991) further develop Clark?s notion of evidence,describing ?the three most common forms of posi-tive evidence?
as being acknowledgments, initiationof the relevant next turn, and continued attention.The Degrees of Grounding model exchangesClark and Schaefer?s two-phase model for an ap-proach that tracks grounding acts in a way similarto (Traum, 1994).
Also, rather than concerning it-self with the strength of a given type of evidence, thecurrent model tracks the strength of material basedon its degree of groundedness, which is derived fromsequences of evidence as described in Section 4.Evidence in the Degrees of Grounding model istracked per Common Ground Unit (CGU) in an in-formation state, as in (Traum and Rickel, 2002).
AnEvidence DescriptionContinued Attention B shows he is continuing toattend and therefore remainssatisfied with As presentation.Initiation of RelevantNext ContributionB starts in on the next contri-bution that would be relevantat a level as high as the currentone.Acknowledgement B nods or says ?uh huh,??yeah,?
or the like.Demonstration B demonstrates all or part ofwhat he has understood A tomean.Display B displays verbatim all or partof As presentation.Table 1: (Clark and Schaefer, 1989)?s Evidence of Un-derstanding between speakers A and Bexample of such a CGU is given in Figure 1.
Ma-terial under discussion is disambiguated by severalidentifying components of the CGU: in this domainthis is the dialogue move, the parameter, the missionnumber, and the adjust number.
Note that parametervalue is not used as an identifying component; thisallows for reference to the material by participantswho may not yet agree on its value.information:dialogue move: target locationparameter: directionvalue: 5940mission number: to be determinedadjust number: 0evidence history:submit-G91, repeat_back-S19degree of groundedness: agreed-contentgrounding criteria met: trueFigure 1: Example Common Ground UnitThe remainder of this section describes the kindsof evidence of understanding found in the corpus.Section 6 describes inter-annotator agreement stud-ies that determine that humans can reliably identifythese types of evidence.3.1 SubmitA Submit type of evidence is provided when ma-terial is introduced into the common ground for thefirst time.
The Submit type of evidence is derivedfrom the Presentation phase of (Clark and Schaefer,1989).55An example of a Submit is given in line 1 of Table2: ?direction 6120?
is information that had not yetbeen mentioned and has no assumed values.Line ID Utterance Evidence1 G91 direction 6120 over Submit2 S19 direction 6120 out Repeat Back3 G91 correction direction6210 overResubmitTable 2: Example DialogueDialogue systems that do not specifically modelgrounding generally assume that material isgrounded when it is first Submitted unless there isevidence to the contrary.3.2 Repeat BackA Repeat Back type of evidence is provided whenmaterial that was Submitted by another dialogueparticipant is presented back to them, often as partof an explicit confirmation.The Repeat Back evidence is related to the ?Dis-play?
evidence of (Clark and Schaefer, 1989) anddescribed in Table 1, however here it is renamed toindicate that it pertains to verbal repetitions, ratherthan general displays which may be in other modal-ities, such as visual.
In fact, there is evidence thatgrounding behavior related to visual feedback is dif-ferent from that related to auditory feedback (Clarkand Brennan, 1991; Thompson and Gergle, 2008).An example is given in line 2 of Table 2: the?direction 6120?
information given in line 1 is Re-peated Back as part of a confirmation.3.3 ResubmitA Resubmit type of evidence is provided when ma-terial that has already been Submitted by a dialogueparticipant is presented again as part of a self- orother-correction.
This is an example of what (Clarkand Brennan, 1991) call negative evidence, whichindicate a lack of mutual belief.An example is shown in Table 2; the direction in-formation which was Submitted in turn 1 and Re-peated Back in turn 2 is Resubmitted in turn 3.In this domain, follow-up presentations of mate-rial were almost always corrections, usually of in-formation that has been repeated back by the otherparticipant, or based on new occurences in the vir-tual world (for example, the lifting of smoke thatwas previously obscuring a target.)
Due to the na-ture of the task, this corpus had few instances ofnon-correction follow-up behavior, where materialwas presented a second time for the purposes of fur-ther discussion.
Such follow-ups are an evidence ofunderstanding whose behavior is probably differentfrom that of the Resubmit type of evidence as de-scribed here, and will be examined in future work asdescribed in Section 7.3.4 AcknowledgeAn Acknowledge type of evidence is a general state-ment of agreement that does not specifically addressthe content of the material.
Acknowledges are iden-tified by semantic interpretation.
Acknowledges area part of (Clark and Schaefer, 1989)?s set of types ofevidence of understanding.Table 3 contains an example: in line 1 the speakerG91 Submits information about the target?s status,which is then Acknowledged by speaker S19 in turnline 2.Line ID Utterance Evidence1 G91 end of mission targetdestroyed overSubmit2 S19 roger AcknowledgeTable 3: Example of an Acknowledgment3.5 Request RepairA Request Repair type of evidence is a statementthat indicates that the speaker needs to have thematerial Resubmitted by the other participant.
Re-quest Repairs are identified by semantic interpreta-tion.
Request Repairs are another example of nega-tive evidence (Clark and Brennan, 1991).Table 4 gives an example: in line 1 G91 submitsa map grid coordinate, and in line 2 S19 asks thatthe other speaker ?say again?
that grid coordinate,which is a Request for Repair.Line ID Utterance Evidence1 G91 grid 5843948 Submit2 S19 say again grid over Request RepairTable 4: Example of a Request Repair563.6 Move OnA Move On type of evidence is provided when aparticipant decides to proceed to the next step of thetask at hand.
This requires that the given task havea set of well-defined steps, and that the step beingMoved On from needs to be grounded before thenext step can be discussed.
Move Ons are identifiedbased on a model of the task at hand.
Move Ons arerelated to (Clark and Schaefer, 1989)?s ?Initiation ofthe relevant next contribution,?
although Clark andSchaefer do not specify that ?next contributions?should be dependent on sufficiently grounding theprevious step.A Move On provides evidence because a cooper-ative dialogue participant would typically not moveon to the next step of the task under such condi-tions unless they felt that the previous step was suf-ficiently grounded.Table 5 shows an example of a Move On.
In line1, G91 indicates that the kind of artillery fire theywant is a ?fire for effect?
; this is Repeated Back inline 2.
G91 then Submits grid information relatedto the target location.
The task specification of Callsfor Fire indicates that fire requests should proceed inseveral steps: after a Warning Order is established, aTarget Location should be given, followed by a Tar-get Description.
By moving on to the step in whicha Target Location is provided, G91 tacitly indicatesthat the step in which a Warning Order is establishedhas been dealt with to their satisfaction.Line ID Utterance Evidence1 G91 fire for effect over Submit2 S19 fire for effect out Repeat Back3 G91 grid 45183658 Submit, MoveOnTable 5: Example of a Move OnLine ID Utterance Evidence1 S19 message to observerkilo 2 rounds AB0001overSubmit2 G91 mike tango oscar kilo2 rounds target numberAB0001 outRepeat Back3 S19 shot over SubmitTable 6: Example of a non-Move OnNot all typical sequences provide Move On ev-idence.
In the example in Table 6, in line 1 S91submits a ?message to observer?
indicating the kindof fire that is being delivered, which is followed inline 2 by a confirmation by G91.
S19 then proceedsto the next step of the task by indicating in line 3that the artillery has been fired.
Line 3, however, isnot a Move On because although it is typically thenext step in the task, providing that information isnot dependent on fully grounding the material beingdiscussed in line 2 - in fact, line 3 will be providedwhen the artillery has been fired, and not based onany other decision by S19.3.7 UseA Use type of evidence is provided when a partici-pant presents an utterance that indicates, through itssemantics, that a previous utterance was understood.Uses are related to (Clark and Schaefer, 1989)?s?Demonstration?.In the Radiobot-CFF corpus, most Uses arereplies to a request for information, such as in Ta-ble 7, where S19?s request for a target description inline 1 is answered with a target description, in line2.Line ID Utterance Evidence1 S19 s2 wants to know whatsthe target descriptionoverSubmit2 G91 zsu over Submit,UseTable 7: Example of a UseAnother example of Use is shown in Table 8, inwhich S19 is providing an intelligence report in line1 regarding an enemy target, and line 2 replies witha statement asking whether the target is a vehicle.The utterance in line 2 uses information provided inline 1.3.8 Lack of ResponseA Lack of Response type of evidence is providedwhen neither participant speaks for a given length oftime.
Identifying a Lack of Response type of evi-dence involves determining how much silence willbe significant for signalling understanding or lack ofunderstanding.57Line ID Utterance Evidence1 S19 again it should haverather large antennas af-fixed to it uh they arestill sending out signalsat the timeSubmit2 G91 this is some kind of Submit,vehicle over UseTable 8: Example of a UseIn the example shown in Table 9, G91 submitsan identifying utterance to see if S19 is available.After 12 seconds, G91 has heard nothing back; thisis negative evidence of grounding, so in line 3 G91resubmits the utterance.Line ID Utterance Evidence1 G91 S 1 9 this is G 9 1 Submit2 (12 seconds of silence) Lack ofResponse3 G91 S 1 9 this is G 9 1 ResubmitTable 9: Example of a Lack of ResponseA Lack of Response can also be an indication ofpositive grounding, as in Table 10.
In line 1, G91submits information about a target, which in line 2is repeated back.
Line 3 indicates a period of silence,in which neither speaker took the opportunity to re-quest a repair or otherwise indicate their disapprovalwith the state of the groundedness of the material.
Inthat sense, the silence of line 3 is positive evidenceof understanding.Line ID Utterance Evidence1 G91 b m p in the open over Submit2 S19 b m p in the open out RepeatBack3 (10 seconds of silence) Lack ofResponseTable 10: Example of a Lack of Response4 Degrees of GroundednessDegrees of groundedness are defined such that mate-rial has a given degree before and after any sequenceof evidence given.
For example, in Table 10 the tar-get description given in line 1 has a certain degreeDegreee Pattern/IdentifierUnknown not yet introducedMisunderstood (anything,Request Repair)Unacknowledged (Submit, Lack of Response)Accessible (Submit) or (anything,Resubmit)Agreed-Signal (Submit, Acknowledgment)Agreed-Signal+ (Submit, Acknowledgment, other)Agreed-Content (Submit, Repeat Back)Agreed-Content+ (Submit, Repeat Back, other)Assumed grounded by other meansTable 11: Degrees of Groundednessof groundedness before it is Submitted, another de-gree after it is Submitted, another degree after it isRepeated Back, and another degree after the Lack ofResponse.A key part of defining these degrees is to deter-mine which of these degrees is worth modeling.
Forexample, Table 3 shows a CGU further grounded bya single Acknowledgment.
In this domain, for thepurposes of determining grounding criteria and dia-logue management algorithms, it is not worth distin-guishing between the case in which it had been fol-lowed by one more Acknowledgment and the casein which it had been followed by two or more Ac-knowledgments.Table 11 shows the significant degrees identifiedduring the corpus study, as well as the definition oridentifying pattern of evidence.
These degrees areshown from Unknown, which is least grounded, toAssumed, which is grounded by other means, suchas written information given during a scenario brief-ing.
Most degrees are identified by patterns of evi-dence.
For example, a CGU is misunderstood if thelatest item of evidence provided is a Request Repair,and CGU is Unacknowledged if it is Submitted fol-lowed by a Lack of Response.The degree of groundedness is used to computehow much (if any) additional evidence is neededto reach the grounding criterion, or ?criterion suffi-cient for current purposes?
as defined by (Clark andSchaefer, 1989).
This computation can be used in di-alogue management to help select a next utterance.In this domain, information such as target num-bers have high grounding criteria, such as Agreed-Content+; they would need to be Repeated Back,and followed at least by a Lack of Response, giv-ing the other participant an opportunity to correct.58Other information might have a grounding crite-rion of Agreed-Signal, needing only an Acknowl-edgment to be grounded, as in Table 3.
Future workwill address the fact that grounding criteria are vari-able: for example, in noisy conditions where errorsare more probable, the grounding criteria may in-crease.5 Dialogue ManagementExploiting this model of grounding for dialoguemanagement involves several steps.
Evidence of un-derstanding must be identified given a semantic in-terpretation and the history of evidence provided sofar.
Given an utterance?s new evidence and a CGU?scurrent degree of groundedness, the CGU?s new de-gree of groundedness must be determined.Once a CGU?s current degree is determined, it canbe compared to its grounding criterion to determinewhether or not it has been sufficiently grounded, andif not, a new item of evidence may be suggested tohelp further ground the material.All of these can be put together in one algorithm,as shown in Figure 2.for each dialogue act parameter,identify the relevant CGUidentify evidence of understandingcompute the CGU?s degree of groundednessfor each CGU not sufficiently groundeddetermine evidence to be givencompute the CGU?s degree of groundednessif Lack of Response detectedcompute the CGU?s degree of groundednessFigure 2: Dialogue Management AlgorithmThe specifics of how this algorithm is integratedinto a system and how it influences task decisionswill vary based on the system being used.
To ex-plore the domain-independence of this model, weare currently integrating it into a dialogue managerin a domain unrelated to the CFF task.6 EvaluationThe validity of this model has been evaluated in sev-eral corpus tests to measure inter-annotator agree-ment in identifying evidence, to ensure that identify-ing evidence can reliably be done by an algorithm,to measure inter-annotator agreement in identifyingthe increase or decrease of the degree of grounded-ness, and to ensure that identifying the increase ordecrease of a degree of groundedness can reliablybe done by an algorithm.Human transcribers produced transcriptions ofseveral sessions between two sets of humans actingas Forward Observer and Fire Direction Center radiooperators in the training simulation.
A subset of thecorpus was used for close analysis: this subset wasmade up of 4 training sessions, composed of 17 firemissions, totaling 456 utterances; this provided a to-tal of 1222 possible indicators of evidence of under-standing made up of 886 dialogue move parametersand 336 period of silence.We automatically performed a dialogue act inter-pretation on the dialogue move parameters, whichwere then manually corrected.
We then manuallyannotated the evidence of understanding identifiedin each dialogue move parameter and period of si-lence.
An example of the data produced from thisprocess is given in the Appendix.6.1 Inter-Annotator Agreement - IdentifyingEvidenceAn inter-annotator agreement study was performedin which two annotators tagged a subset of the cor-pus (318 dialogue move parameters and 74 silences)to identify the evidence of understanding, given anutterance and dialogue act interpretation.
One anno-tator was the first author of this paper, and the otherwas a computer professional who had no previousexperience with the domain or with tagging data.Table 12 shows the results, broken down by theStandalone types of evidence, which could occurby themselves (Submit, Repeat Back, Resubmit,Acknowledge, and Request Repair), the Additionaltypes of evidence, which only occurred with othertypes of evidence (Move On and Use), and theSilence-Related Lack of Understanding type of ev-idence.
Each of these showed acceptable levels ofagreement, with the exception of the Kappa for theadditional evidence.
The low score on the additionalevidence is probably due to the fact that Move Onjudgments depend on a strong understanding of thedomain-specific task structure, as described in sec-tion 3.6; to a lesser extent Use judgments tend torely on an understanding of the scenario as well.59Evidence Type P(A) KappaStandalone 0.95 0.91Additional 0.87 0.53Silence-Related 0.92 0.84Table 12: Inter-Annotator Agreement - EvidenceEvidence Type P(A) KappaStandalone 0.88 0.81Additional 0.98 0.92Silence-Related 1.0 1.0Table 13: Algorithm Agreement - EvidenceThis highlights the fact that for most of the evidenceof understanding (all except for Move On and Use),agreement can be reached with a non-expert annota-tor.6.2 Algorithm Agreement - IdentifyingEvidenceThe results of the inter-annotator agreement testwere merged into the larger 1222-markable corpus,to create a consensus human-annotated corpus.
Thiswas used in the next test, to identify whether an al-gorithm can automatically identify evidence.We authored a set of rules to identify evidence ofunderstanding based on the order in which CGUswere introduced into the common ground, the iden-tity of the speaker who introduced them, and thesemantic interpretations.
The rules were then ap-plied to the 1222-markable corpus, and the resultingidentifications were then compared to the identifica-tions made by the human annotators.
The results areshown in Table 13.
The respectable agreement andkappa values indicate that it is possible for an algo-rithm to reliably identify evidence.6.3 Degree Increase/Decrease AgreementsFinally, we explored whether humans could reliablyagree on whether a given material?s groundednesshad increased or decreased after a given turn.We studied this because we are not here claimingthat humans explicitly model degrees of grounded-ness or perform a computation to compare a givenmaterial with something they had grounded pre-viously.
It is more likely that humans track evi-dence, determine whether material is more or lessgrounded than it was before, and check whether itAgreement Type P(A) KappaHuman-Human 0.97 0.94Human-Algorithm 0.87 0.73Table 14: Degree Increase/Decrease Agreementshas reached a grounding criterion.
A dialogue sys-tem need not be tied to human behavior to be effec-tive, so given these human behaviors, we are inter-ested in whether computer algorithms can be builtto produce useful results in terms of task completionand human-realistic behavior.
For this reason weevaluate the model of degrees of grounding based onhow human-realistic its ability to identify whether aCGU?s degree of groundedness has increased or de-creased, and in future work study whether a systemimplementation performs acceptably in terms of taskcompletion and managing human-realistic ground-ing behavior.To perform the test of whether degree increase ordecrease could be reliable detected, we annotated asubset of the corpus with a non-domain expert.
Fora set of CGUs, we tracked the sequence of evidencethat was provided to ground that CGU.
Before andafter each item of evidence, we asked the annota-tors to determine whether the CGU was more or lessgrounded than it was the turn before.We also developed a set of rules based on the defi-nition of the degrees of groundedness defined in sec-tion 4 to determine after each utterance whether aCGU?s degree of groundedness had increased or de-creased from the utterance before.
We then com-pared the results of that set of rules with human-consensus judgments about degree increase and de-crease.The results are shown in Table 14, indicating thathumans could reliably agree among themselves, anda rule-based algorithm could reliably agree with thehuman consensus judgments.7 Discussion and Future WorkIn this paper we describe the initial development ofthe Degrees of Grounding model, which tracks theextent to which material has been grounded in a di-alogue.
The Degrees of Grounding model containsa richer variety of evidence of understanding thanmost models of grounding, which allows us to de-60fine a full set of degrees of groundedness.We recognize that the initial domain, althoughrich in grounding behavior, is not typical of most hu-man conversation.
Besides the structured dialoguesand the domain-specific word use, the types of evi-dence of understanding presented in Section 3 doesnot cover all possible types of evidence.
For ex-ample, (Clark and Schaefer, 1989) describe ?contin-ued attention?
as another possibility, which was notavailable with the radio modality used in this study.Furthermore, it is a feature of this domain that Re-submit evidence generally indicates lack of under-standing; in general conversation, it is not true thatthe repeated mention of material indicates that it isnot understood, so a ?Follow-Up?
evidence is likely,as are variations of ?Use.
?To explore these questions, we are extendingwork to other domains, and are currently focusingon one in which virtual humans are used for a ques-tioning task.
Also, we plan to run evaluations in im-plemented systems, exploring performance in termsof task completion and believable human behavior.AcknowledgmentsThis work has been sponsored by the U.S. Army Re-search, Development, and Engineering Command(RDECOM).
Statements and opinions expressed donot necessarily reflect the position or the policy ofthe United States Government, and no official en-dorsement should be inferred.The authors would like to thank Kevin Knightand the anonymous reviewers for feedback about theevaluation.ReferencesDan Bohus and Alexander Rudnicky.
2005a.
Error han-dling in the RavenClaw dialog management architec-ture.
In Proceedings of HLT-EMNLP-2005.Dan Bohus and Alexander Rudnicky.
2005b.
Sorry,I didn?t catch that!
- an investigation of non-understanding errors and recovery strategies.
In Pro-ceedings of SIGdial-2005.
Lisbon, Portugal.Harry Bunt, Roser Morante, and Simon Keizer.
2007.
Anempirically based computational model of groundingin dialogue.
In Proceedings of the 8th SIGdial Work-shop on Discourse and Dialogue.Herbert H. Clark and Susan E. Brennan.
1991.
Ground-ing in communication.
In Perspectives on SociallyShared Cognition, pages 127?149.
APA Books.Herbert H Clark and Edward F Schaefer.
1989.
Con-tributing to discourse.
Cognitive Science, 13:259?294.Diane Litman, Julia Hirschberg, and Marc Swerts.
2006.Characterizing and predicting corrections in spokendialogue systems.
Computational linguistics, pages417?438.Tim Paek and Eric Horvitz.
2000a.
Conversation asaction under uncertainty.
In Proceedings of the 16thConference on Uncertainty in Artificial Intelligence(UAI), pages 455?464.Tim Paek and Eric Horvitz.
2000b.
Grounding criterion:Toward a formal theory of grounding.
Technical re-port, Microsoft Research, April.
Microsoft TechnicalReport, MSR-TR-2000-40.Tim Paek.
2003.
Toward a taxonomy of communica-tion errors.
In Proceedings of the ISCA Tutorial andResearch Workshop on Error Handling in Spoken Di-alogue Systems, pages 53?58, August 28-31.
Chateaud?Oex, Vaud, Switzerland.Antonio Roque, Anton Leuski, Vivek Rangarajan, Su-san Robinson, Ashish Vaswani, Shri Narayanan, andDavid Traum.
2006.
Radiobot-CFF: A spoken dia-logue system for military training.
In 9th InternationalConference on Spoken Language Processing (Inter-speech 2006 - ICSLP), September.Gabriel Skantze.
2005.
Galatea: a discourse modellersupporting concept-level error handling in spoken dia-logue systems.
In Proceedings of SigDial, pages 178?189).
Lisbon, Portugal.Marc Swerts, Diane Litman, and Julia Hirschberg.
2000.Corrections in spoken dialogue systems.
In Proceed-ings of the 6th International Conference of SpokenLanguage Processing (ICSLP-2000), October.Will Thompson and Darren Gergle.
2008.
Modelingsituated conversational agents as partially observablemarkov decision processes.
In Proceedings of Intelli-gent User Interfaces (IUI).David Traum and Jeff Rickel.
2002.
Embodied agentsfor multi-party dialogue in immersive virtual world.In Proceedings of the First International Joint Confer-ence on Autonomous Agents and Multi-agent Systems(AAMAS 2002), pages 766?773, July.David R. Traum.
1994.
A Computational Theory ofGrounding in Natural Language Conversation.
Ph.D.thesis, University of Rochester.61AppendixLine ID Utterance Semantic Interpretation Evidence:StandaloneEvidence:Additional1 G91 fire for effect over WO-MOF: fire for effect Submit2 S19 fire for effect out WO-MOF: fire for effect Repeat Back3 Silence: 0.7 secondsah roger ROGER Acknowledge4 G91 grid four five four two ah three sixthree eightTL-GR: 45423638 Submit Move On5 Silence: 2.3 seconds6 S19 grid four five four two three sixthree eight outTL-GR: 45423638 Repeat Back7 Silence: 0.7 secondsah roger ROGER Acknowledge8 G91 b r d m TD-TYPE: b r d m Submit Move Onin the open over TD-DESC: in the open Submit9 Silence: 1.3 seconds10 S19 b r d m TD-TYPE: b r d m Repeat Backin the open out TD-DESC: in the open Repeat Back11 Silence: 9.9 seconds Lack of Re-sponseComments:This dialogue is between G91 as a Forward Observer identifying a target, and S19 as a Fire DirectionCenter who will send the artillery fire when given the appropriate information.In line 1, G19?s utterance is interpreted as a Warning Order - Method of Fire (WO-MOF), describing thekind of artillery fire requested, whose value is ?fire for effect.?
This is the first mention of a WO-MOF forthis particular CFF, so it is identified as a Submit type of evidence related to a new CGU, which now has anAccessible degree of groundedness.In line 2, a WO-MOF is again given.
The WO-MOF is identified as referring to the CGU introducedin line 1, and a Repeat Back type of evidence is added to that CGU?s evidence history, which gives it anAgreed-Content degree of groundedness.In line 3 there follows a silence that is not long enough to be a Lack of Response.In line 4, G91 provides an Acknowledge type of evidence, and Moves On to the next task item: identifyingthe Target Location - Grid (TL-GR) of the CFF.
The Acknowledge and Move On, referring to the CGUcreated in line 1, raise that CGU?s degree of groundedness to its grounding criterion of Agreed-Content+, atwhich point it becomes grounded.
At the same time, the introduction of the TL-GR information creates anew CGU, whose degree is Accessible.In line 6 the TL-GR CGU is Repeated Back, thereby raising its degree of groundedness to Agreed-Content.In line 8 an Acknowledge is provided and a set of information related to the Target Description (TD-) isgiven, providing a Move On, thereby grounding the TL-GR CGU.
So by line 8, two CGUs (WO-MOF andTL-GR) have been added to the common ground, and two more CGUs (TD-TYPE and TD-DESC) haveAccessible degrees and are in the process of being grounded.In line 10 the TD CGUs are Repeated Back, raising their degree of groundedness to Agreed-Content.In line 11 the Lack of Response raises the TD CGUs to Agreed-Content+ thereby grounding them.
At thispoint there is enough information in the common ground for S19 to send the artillery fire.62Line ID Utterance Semantic Interpretation Evidence:StandaloneEvidence:Additionalmessage to observer kilo MTO-BAT: kilo Submit12 S19 two rounds MTO-NUM: two Submit Move Ontarget number alpha bravo zerozero one overTN: AB001 Submit13 Silence: 3.1 secondsa roger mike tango alpha ah alpha ROGER Acknowledge14 G91 target number alpha bravo zerozero zero oneTN: AB0001 Repeat Backa kilo MTO-BAT: kilo Repeat Backtwo rounds out MTO-NUM: two Repeat Back11 Silence: 11.4 seconds Lack of Re-sponse16 S19 shot SHOT Submitrounds complete over RC Submit17 Silence: 0.8 seconds18 G91 shot SHOT Repeat Backrounds complete out RC Repeat Back19 S19 splash over SPLASH Submit20 Silence: 1.5 seconds21 G91 splash out SPLASH Repeat Back22 Silence: 30.4 seconds Lack of Re-sponse...ah end of mission a target numberalpha bravo zero zero oneTN: AB001 Submit23 G91 one EOM-NUM: one Submitb r d m EOM-TYPE: b r d m Submitdestroyed over EOM-BDA: destroyed Submit24 S19 end of mission b r d des m d cor-rection b r d mEOM-TYPE: b r d m Repeat Backdestroyed out EOM-BDA: destroyed Repeat BackComments:In line 12, S19 provides information about the artillery fire that is going to be sent.
This includes thebattery that will be firing (MTO-BAT), the number of rounds to be fired (MTO-NUM) and the target numberthat will be used to refer to this particular fire mission from that point on (TN).In line 14, G91 Repeats Back the information presented in line 12 along with an Acknowledge.In line 16, S19 notifies that the mission has been fired; in line 18 this is confirmed.
Likewese, in line 19S19 notifies that the mission is about the land; in line 21 this is confirmed.Between lines 22 and 23 several turns have been removed for space reasons.
These turns were related to anadjustment of the artillery fire: after the initial bombardment, the Forward Observer requested that the sameartillery be fired 100 meters to the left of the original bombardment.
This was confirmed and delivered.In line 23, G91 sends a description of the amount of damage suffered by the target: the number of enemyaffected (EOM-NUM), the type of enemy (EOM-TYPE) and the extent of the damage (EOM-BDA).
Theseare Repeated Back by S19, thereby ending the CFF.
Note that S19 does not Repeat Back the EOM-NUM.
Inthis particular instance the number of enemies is implied by the EOM-TYPE being singular, but throughoutthe corpus EOMs are seen to have a low grounding criteria.63
