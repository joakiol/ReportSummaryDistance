Language Technology for Closely Related Languages and Language Variants (LT4CloseLang), pages 67?75,October 29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsProper Name Machine Translationfrom Japanese to Japanese Sign LanguageTaro Miyazaki, Naoto Kato, Seiki Inoue,Shuichi Umeda, Makiko Azuma, Nobuyuki HirumaNHK Science & Technology Research LaboratoriesTokyo, Japan{miyazaki.t-jw, katou.n-ga, inoue.s-li,umeda.s-hg, azuma.m-ia, hiruma.n-dy}@nhk.or.jpYuji NagashimaFaculty of Information,Kogakuin UniversityTokyo, japannagasima@cc.kogakuin.ac.jpAbstractThis paper describes machine transla-tion of proper names from Japanese toJapanese Sign Language (JSL).
?Propername transliteration?
is a kind of machinetranslation of proper names between spo-ken languages and involves character-to-character conversion based on pronunci-ation.
However, transliteration methodscannot be applied to Japanese-JSL ma-chine translation because proper namesin JSL are composed of words ratherthan characters.
Our method involvesnot only pronunciation-based translation,but also sense-based translation, becausekanji, which are ideograms that composemost Japanese proper names, are closelyrelated to JSL words.
These translationmethods are trained from parallel corpora.The sense-based translation part is trainedvia phrase alignment in sentence pairsin a Japanese and JSL corpus.
Thepronunciation-based translation part istrained from a Japanese proper name cor-pus and then post-processed with trans-formation rules.
We conducted a seriesof evaluation experiments and obtained75.3% of accuracy rate, increasing frombaseline method by 19.7 points.
We alsodeveloped a Japanese-JSL proper nametranslation system, in which the translatedproper names are visualized with CG ani-mations.1 IntroductionSign language is a visual language in which sen-tences are created using the fingers, hands, head,face, and lips.
For deaf people, sign language iseasier to understand than spoken language becauseit is their mother tongue.
To convey the meaningof sentences in spoken language to deaf people,the sentences need to be translated into sign lan-guage.To provide more information with sign lan-guage, we have been studying machine translationfrom Japanese to Japanese Sign Language (JSL).As shown in Figure 1, our translation system au-tomatically translates Japanese text into JSL com-puter graphics (CG) animations.
The system con-sists of two major processes: text translation andCG synthesis.
Text translation translates word se-quences in Japanese into word sequences in JSL.CG synthesis generates seamless motion transi-tions between each sign word motion by using amotion interpolation technique.
To improve themachine translation system, we have been tack-ling several problems with translating in JSL.
Inthis paper, we focus on the problem of propername translation, because proper names occur fre-quently in TV news programs and are hard totranslate with conventional methods.Proper name translation is one of the ma-jor topics of machine translation.
In particu-lar, there are many methods that work with spo-ken language, such as ?proper name translitera-tion,?
which means character-to-character conver-sion based on pronunciation (Knight et al., 1998;Goto et al., 2003; Virga et al., 2003; Li et al.,2004; Finch et al., 2010; Sudoh et al., 2013).However, transliteration methods cannot be ap-plied to Japanese-JSL proper name translation be-cause proper names in JSL are not composed ofcharacters but rather of sign words.
To translateproper names using sign words, sense-based trans-lation is required.
Sense-based translation trans-67Figure 1: Japanese-JSL translation system overviewlates kanji, which are ideograms that composemost Japanese proper names, into closely relatedJSL words.
Moreover, although several methodshave been proposed to translate sentences in signlanguage, there is as yet no method to translateproper names (Mass?o et al., 2010; San-Segundoet al., 2010; Morrissey, 2011; Stein et al., 2012;Mazzei, 2012; Lugaresi et al., 2013).This paper describes proper name translationfrom Japanese into JSL.
The method involvessense-based translation and pronunciation-basedtranslation.
Both conversions are based on astatistical machine translation framework.
Thesense-based translation is a sense-based character-wise translation learned from phrase pairs in aJapanese-JSL corpus.
The pronunciation-basedtranslation is a pronunciation-based character-wise translation learned from a Japanese propername corpus and is post-processed with transfor-mation rules.
We conducted a series of evaluationexperiments and obtained good results.
We alsodeveloped a proper name translation system fromJapanese to JSL, in which the translated propernames are visualized with CG-animations.2 Proper Names in JSL2.1 Types of proper name in JSLIn JSL, proper name representations are classifiedinto four types, as follows.Type 1: sense-based caseHere, each character in Japanese proper names istranslated into sign words in JSL.
Most charac-ters that make up Japanese proper names are kanji.Kanji are ideograms, i.e., each kanji representingconcept, so they can be translated into words withthe concepts in JSL.For example, in the Japanese place name ???(Kagawa),?
the kanji-characters ??
(aroma)?
and??
(river)?
are respectively translated into signwords ?AROMA1?
and ?RIVER.?
Accordingly,the translation of ???
(Kagawa)?
is ?AROMA/ RIVER?
in JSL.Type 2: Pronunciation-based caseHere, the pronunciations of the kanji are translit-erated into the Japanese kana alphabet.
The kanaare visualized by fingerspelling2.
The transliter-ation in this case is not a spelling-based transfor-mation from the source language because kanji arenot phonograms3.For example, in the Japanese personal name ????
(Motegi, written in kana as ?????
), the twokanji ???
and ???
are respectively transliteratedinto the kana ???
(mote)?
and ??
(gi).
?Each of the three kana, ??
(mo),?
??
(te)?
and??
(gi),?
is fingerspelled in JSL.Type 3: Mixed caseThis type includes Type 1 and Type 2.
Thatis, some of the characters in the proper namesare translated into sign words and the others aretransliterated into kana and then visualized by fin-gerspelling.
For example, regarding the Japaneseplace name ????
(Nagano, written in kana as ?????
), the kanji ???
is translated into the signword ?LONG?
and ???
is transliterated into thekana ??
(no).
?1The words in JSL are represented using capitalized En-glish words.
This notation method is called ?glosses?
in thesign language research community.2All of the kana can be visualized by fingerspelling inJSL.3For example, the character ???
is pronounced ?ki,?
?gi,??moku,?
?boku?
etc.
The decision as to which pronunciationshould be used is by context, meanings or idiom.68Table 1: Analysis of proper name typesPlace nameType 1 43%Type 2 3%Type 3 10%Type 4 44%Persons?
nameType 1 60%Type 2 14%Type 3 21%Type 4 21%Type 4: Idiomatic caseThese proper names are traditionally defined asfixed representations in JSL.2.2 Analysis of Proper Name Types inCorporaTo investigate the frequencies of these four typesin corpora, we analyzed a geographical dictionary(JFD, 2009) of place names and our corpus (men-tioned in section 4.2.1) of persons?
names.
Table1 shows the results of the analysis.Proper names of Types 1, 2 and 3 needed tobe translated, while those of Type 4 needed tobe registered in an idiomatic translation dictio-nary of proper names.
Furthermore, the propername translations of Type 1, 2 and 3 reduceto sense-based translations and/or pronunciation-based translations.Our translation method performs sense-basedtranslation and pronunciation-based translation onthe basis of statistical machine translation (SMT)methods.
The next section describes this method.3 Our translation method3.1 Sense-based translation3.1.1 Basic method (baseline)The sense-based translation uses SMT, and thetranslation probabilities (i.e.
a lexicon model inSMT) are trained on our news corpus consistingof sentence pairs in Japanese and JSL.
The basicmethod of training the lexicon model uses the cor-pus in a sentence-by-sentence manner (Figure 2-(a)).
It segments the sentences into characters inJapanese and into words in JSL.
Then, the modelis trained on the characters of the Japanese sen-tences and the words of the JSL sentences.
Re-garding Sentence 1 below, the method segments itinto Sentence 2 in Japanese and trains the model.Sentence 1JP ?????????????
(It will be fine from the morning in Kagawa)JSL AROMA / RIVER / MORNING /FROM / FINE / DREAMSentence 2JP ?/?/?/?/?/?/?/?/?/?/?/?/?
(It will be fine from the morning in Kagawa)JSL AROMA / RIVER / MORNING /FROM / FINE / DREAMWe took the basic method above to be the base-line method for the evaluations.3.1.2 Our methodOur method uses the corpus in a phrase-by-phrasemanner.
To use the phrase-segmented corpus,the method is composed of two steps.
The firststep aligns Japanese phrases to JSL phrases ineach of the sentence pairs in the corpus by us-ing many-to-many word alignment.
Using the re-sults of the alignment, each sentence pair is di-vided into phrase pairs.
The second step segmentsthe phrases into characters in Japanese and trainsthe sense-based translation part on the phrase pairs(Figure 2-(b)).Let us illustrate our method using Sentence 1.The first step is dividing a sentence into phrasepairs.
We use alignment pairs, the result ofthe many-to-many word alignment, as the phrasepairs.
The alignment pairs are combined intophrase pairs, as shown in Phrase 1 below.Phrase 1JP1 ??
/?
(in Kagawa)JSL1 AROMA / RIVERJP2 ?
/??
(from the morning)JSL2 MORNING / FROMJP3 ???
/???
/?
(it will be fine)JSL3 FINE / DREAMAlignment pairs that consist of many more orfewer sign words than Japanese words are dis-carded as alignment errors.
In this paper, weregard the alignment pair as the alignment errorwhen nsign> (NJP+ ?)
or (nsign+ ?)
< nJP.Here, nsignmeans the number of sign words in69Figure 2: Two ways of learning translation modelsthe alignment pair, and nJPmeans the number ofJapanese words in the alignment pair.
We chose ?to be 5, on the basis of preliminary experiment.The second step segments Phrase 1 into charac-ters in Japanese, as in Phrase 2 below.Phrase 2JP1 ?/?/?
(in Kagawa)JSL1 AROMA / RIVERJP2 ?/?/?
(from the morning)JSL2 MORNING / FROMJP3 ?/?/?/?/?/?/?
(It will be fine)JSL3 FINE / DREAMThen, as shown in Example 1, the sense-basedtranslation is trained on the corpus of phrase pairs.Example 1??
AROMA??
RIVER??
(null)...Our method can reduce the combinations ofalignments between Japanese characters and JSLwords, because it segments sentences into phrasesin which the number of words is less than that inthe sentences.
Therefore, it improves the align-ment accuracy.3.2 Pronunciation-based translationThe pronunciation-based translation is not translit-eration but translation, because kanji do not repre-sent their pronunciation.
Therefore, the translationprobabilities are also trained on a Japanese propername corpus as a lexicon model in the SMT train-ing step.
(a) (b)(c); katakana character; kanji characterFigure 3: Patterns that cannot be alignedUsing the trained lexicon model, a decoderaligns the kana with the kanji.
However, some ofthe kanji and kana are not aligned because of thesparse data problem.
Such non-aligned cases areas follows.Pattern (a) Aligned on neither the kanji nor thekana side (Fig.3-(a)).Pattern (b) Insertion occurred (Fig.3-(b)).Pattern (c) Deletion occurred (Fig.3-(c)).The kanji-to-kana alignment is generally many-to-many, but we restricted the alignment to one-to-many.To improve the result of these cases, we devisedtransformation rules that use the word?s context,as follows.Rule (a) Align all of the non-aligned kana withthe non-aligned kanji.Rule (b) Align the non-aligned kana to the kanjiwith the lower probability by comparing thetranslation probability of the left alignedkanji with the translation probability of theright aligned kanji.Rule (c) Align the non-aligned kanji to the kanawith the lower probability and un-align the70Figure 4: Japanese-JSL news corpusold aligned kanji with the lower one by com-paring the translation probability of the leftaligned kana with the translation probabilityof the rightaligned kana.Using these rules, our methods can align kanjito kana even if the kanji and/or kana are not inthe training data.
It has the advantage of robust-ness to the data sparse problem unlike conven-tional transliteration methods such as in (Finch etal., 2010; Knight et al., 1998).
There are many dif-ferent family names in Japan4, so these character-istics are important for translating Japanese propernames.Our method applies these rules to the non-aligned kanji and kana from the beginning char-acter in the sentences after the sense-based trans-lation.3.3 Combining sense-based andpronunciation-based translationIn our proper name translation, sense-based trans-lation is first applied to a Japanese proper nameand then pronunciation-based translation is ap-plied to the characters that were not converted intosign words.
Such characters occur in the followingcases.?
The character does not appear in the trainingdata of the sense-based translation.4There are over 300,000 family names in Japan(Power,2008).?
The character is translated into kana becausethe character is often translated into Kana inthe training data of sense-based translation.In these cases, our system translates the charac-ter into kana by using pronunciation-based trans-lation.4 Experiments and Results4.1 Experimental settingOur method uses GIZA++ and ?grow-diag-final-and?
(Och et al., 2003) as the model training andMoses (Koehn et al., 2007) as the decoding; it doesnot use a language model because word contextand reordering are useless in proper name transla-tion from Japanese to JSL.The training sets were our Japanese-JSLnews corpus (including 21,995 sentence pairs)for sense-based translation and a human-namecorpus (including 34,202 personal names) forpronunciation-based translation.
These corporaare described below.The test set consisted of persons?
names andplace names.
Regarding the persons?
names, thecandidates for the test set were first randomly sam-pled from a Japanese family name database5.
The100 sampled names were translated by three nativesigners and if two or three of the signers gave thesame translation, the sample was added to the test5http://www.douseidoumei.net/prof.html71Table 2: Results of evaluationPerson Place Total Type 1 Type 2 Type 3 Type 4# in the test set 96 82 178 123 16 32 7Baseline61 37 99 86 2 9 2(63.5%) (46.3%) (55.6%) (69.9%) (12.5%) (28.1%) (28.6%)Pialign75 41 118 97 3 15 3(78.1%) (51.3%) (66.3%) (78.9%) (18.8%) (46.9%) (42.9%)Proposed (sense-based)77 43 121 95 3 20 3(80.2%) (53.8%) (68.0%) (77.2%) (18.8%) (62.5%) (42.9%)Baseline 69 44 114 86 5 21 2+ pronunciation-based (71.9%) (55.0%) (64.0%) (69.9%) (31.3%) (65.6%) (28.6%)Pialign 74 47 123 97 5 18 3+ pronunciation-based (77.1%) (58.8%) (69.1%) (78.9%) (31.3%) (56.3%) (42.9%)Proposed (sense-based) 80 53 134 95 8 28 3+ pronunciation-based (83.3%) (66.3%) (75.3%) (77.2%) (0.50%) (87.5%) (42.9%)set.
This procedure produced a test set consistingof 96 names.
The test set for place names was pro-duced in the same way and amounted to 82 names.The total number of names used in our evaluationexperiments was thus 178.4.2 Training Corpora4.2.1 Japanese-JSL corpusWe have been building up a Japanese-JSL newscorpus to study Japanese-to-JSL machine transla-tion.
The corpus was collected from daily NHKSign Language News programs, which are broad-cast on NHK TV with Japanese narration and JSLsigns.The corpus consists of Japanese transcriptions,their JSL transcriptions, and their JSL movies.The Japanese transcriptions are transcribed by re-vising the speech recognition results of the newsprograms.
The transcriptions are carried out bychanging the sign gestures of the newscasters intosequences of JSL words.
The JSLmovies are man-ually extracted from the program by referring tothe time intervals of the transcribed JSL transcrip-tions.
The corpus currently includes about 22,000sentence pairs taken from broadcasts running fromApril 2009 to August 2010.
Our bilingual corpusis larger than other recent sign language corporabuilt in various sign language research projects(Bungeroth et al., 2006; Schembri, 2008; John-ston, 2009; Balvet et al., 2010; Matthes et al.,2012; Mesch et al., 2012).
Figure 4 shows an ex-ample of our corpus.4.2.2 Human Name CorpusThe human-name corpus was constructed by ex-tracting personal names written in both kanji andkana from the IPADIC dictionary6.4.3 Evaluation and DiscussionWe conducted a series of experiments to evaluateour method.
Table 2 shows the translation accura-cies for proper names.
The tested methods were asfollows.Baseline A simple baseline method (mentioned in3.1.1)Pialign The conventional character-based transla-tion method (Neubig et al., 2012)Proposed (sense-based) Our method for sense-based translation (described in 3.1.2)Pronunciation-based Our method forpronunciation-based translation (describedin 3.2)Our overall method is ?Proposed (sense-based) +pronunciation-based.?
The upper row of each cellin the table shows the number of the correct words,whereas the lower row of each cell is the accuracy.The table indicates that compared with the base-line, our method is higher in accuracy by 19.7points in total, 19.8 points on persons?
name, and19.6 points on place names.
It is higher in ac-curacy than the baseline for each type of trans-lation.
The sense-based translation is effectiveat the raising total translation accuracy, whereas6http://code.google.com/p/mecab/downloads72the pronunciation-based translation increases thetranslation accuracy Types 2 and 3.Each method had lower accuracy for placenames than for persons?
names.
The reasons areas follows.
One problem is that some of the char-acters in the place names are used only in placenames, and though they appear in the test set, theydo not appear in the training set.
This is the out-of-vocabulary problem, which is a major issue withthe corpus-based method.
To tackle this problem,we will make our corpus larger by using Japanese-JSL place name dictionary.
The other problemis that some of the place names have ambiguousJapanese-JSL translations.
In this regard, the rateof agreement of the signers making was lower forplace names (i.e.
82) than for personal names (i.e.96).The sense-based translation method is more ac-curate than pialign especially in translating type2 and 3.
This is because our discard process isable to delete infrequently used kanji in the corpusfrom the training data.
Infrequently used kanji areoften translated using their pronunciation becausenative signers cannot imagine the sign word thatwell represents the kanji.Some of the type 4 words that occurred fre-quently in the training data were translated withthe phrase-based method, however, the accuracywas low.
An idiomatic translation dictionary is re-quired for this purpose.A Japanese-JSL place name dictionary wouldalso improve the character-to-word conversion.For example, our method mistranslated the char-acter ??
(god)?
in a personal family name ???
(Kamiya)?
into ?KOBE (Kobe).?
The cause ofthis error is that our method trains the character-to-word conversion ??
(god)?KOBE(Kobe)?
fromPhrase 3.Phrase 3JP ??
(Kobe)JSL KOBEOur method would be able to avoid such a conver-sion error by deleting from the training set phrasepairs such as Phrase 3 that are registered in theplace dictionary.5 Proper Name Translation SystemUsing our translation method, we developed aproper name translation system from Japanese toFigure 5: Motion capture systemJSL.
This system visualizes the translated propernames as computer graphics (CG) animations.The CG animation is a high-quality 3D modelof human hands and fingers, and the model is con-trolled using motion-capture (MoCap) data.
Thedata is captured with an optical MoCap systemin which many markers are attached to fingersto pick up their movements precisely.
Figure5shows the MoCap system.
The CG-model hasabout 100 joints with three rotation angles.
TheCG-animation is rendered from scripts written inTVML (TM program Making Language7), whichis a scripting language developed by NHK to de-scribe full TV programs (Kaneko et al., 2010).Figure 6 shows an example of the Japanese-to-JSL proper name translation system.
When aproper name in Japanese is entered, a correspond-ing sign language animation is created and shownin the system.
The translation system will be usedin subjective evaluation of proper name transla-tions.6 ConclusionWe presented a Japanese-JSL proper name ma-chine translation method.
The method involvessense-based translation and pronunciation-basedtranslation, both of which are based on statisti-cal machine translation.
We conducted a series ofevaluation experiments and obtained 75.3% of ac-curacy, increasing from baseline method by 19.7points.We will incorporate our method of proper nametranslation from Japanese to JSL in our machinetranslation system.7http://www.nhk.or.jp/strl/tvml/english/player2/index.html73Figure 6: Japanese-JSL proper name translationsystemAcknowledgementsThe authors would like to express our deep grat-itude to Hirokazu Kosugi for implementing theexperimental system for translating sign word se-quences into sign language CG animations.
Theywould also like to express their gratitude to HidekiTanaka, Ichiro Yamada, Tadashi Kumano, IsaoGoto, and the anonymous reviewers for their valu-able comments and suggestions.ReferencesAntonio Balvet, Cyril Courtin, Dominique Boutet,Christian Cuxac, Ivani Fusellier-Souza, BrigitteGarcia, Marie-Th?er`ese L?Huillier and Marie-AnneSallandre.
2010.
The Creagest Project: a Digi-tized and Annotated Corpus for French Sign Lan-guage (LSF) and Natural Gestural Languages.
In-ternational Conference on Language Resources andEvaluation (LREC 2010): 469?475.Jan Bungeroth, Daniel Stein, Philippe Dreuw, MortezaZahedi and Hermann Ney.
2006.
A German SignLanguage corpus of the domain weather report.
In-ternational Conference on Language Resources andEvaluation (LREC 2006): 2000?2003.Andrew Finch, Keiji Yasuda, Hideo Okuma, EiichiroSumita and Satoshi Nakamura.
2011.
A BayesianModel of Transliteration and Its Human Evaluationwhen Integrated into a Machine Translation Sys-tem.
IEICE transactions on Information and Sys-tems: Vol.
E94?D, No.
10, pp.1889?1900.Isao Goto, Naoto Kato, Noriyoshi Uratani and Teru-masa Ehara.
2003.
Transliteration considering con-text information based on the maximum entropymethod.
The 9th Machine Translation Summit: 125?132.Japanese Federation of the Deaf (JFD).
2009.
Placenames map in Japanese Sign Language in Japan (inJapanese, ???????????)
Japanese Feder-ation of the Deaf Press.Trevor Johnston.
2009.
Creating a corpus of Auslanwithin an Australian national corpus.
Selected Pro-ceedings of the 2008 HCSNet Workshop on Design-ing the Australian National Corpus: Mustering Lan-guages.Hiroyuki Kaneko, Narichika Hamaguchi, MamoruDoke and Seiki Inoue.
2010.
Sign language anima-tion using TVML.
9th ACM SIGGRAPH Interna-tional Conference on Virtual-Reality Continuum andIts Applications in Industry (VRCAI 2010), ACM2010:289?292.Kevin Knight, Jonathan Graehl.
1998.
Machinetransliteration.
Computer Linguistics, 24: 599?612.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowen, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ond?rej Bojar, AlexandraConstantin and Evan Herbst.
2007.
Moses: Opensource toolkit for statistical machine translation.
An-nual meeting of the Association for ComputationalLinguistics (ACL 2007), demonstration session.Li Haizhou, Zhang Min, Su Jian.
2004 A joint source-channel model for machine transliteration.
Proceed-ings of the 42nd Annual Meeting on Association forComputational Linguistics (ACL ?04).
Article No.159.Camillo Lugaresi and Barbara Di Eugenio.
2013.Translating Italian connectives into Italian Sign Lan-guage.
Proceedings of the 51st Annual Meeting ofthe Association for Computational Linguistics (ACL2013), pp 270?280.
Sofia, Bulgaria, August.Guillem Mass?o and Toni Badia.
2010.
Dealingwith sign language morphemes in statistical machinetranslation.
4th workshop on the representation andprocessing of sign language: interactions betweencorpus and lexicon at LREC 2010: 154?157.Silke Matthes, Thomas Hanke, Anja Regan, JakobStorz, Satu Worseek, Eleni Efthimiou, Athanasia-Lida Dimou, Annelies Braffort, John Glauert andEva Safar.
2012.
Dicta-Sign ?
Building a multilin-gual sign language corpus.
5th workshop on the rep-resentation and processing of sign language: inter-actions between corpus and lexicon at LREC 2012:117?122.Alessandro Mazzei.
2012.
Sign language generationwith expert systems and ccg.
Proceedings of theSeventh International Natural Language GenerationConference (INLG ?12): 105?109.Johanna Mesch, Lars Wallin and Thomas Bj?orkstrand.2012.
Sign language resources in Swedes: dictio-nary and corpus.
5th workshop on the representa-tion and processing of sign language: interactions74between corpus and lexicon at LREC 2012: 127?130.Sara Morrissey.
2011.
Assessing three representationmethods for sign language machine translation andevaluation.
15th annual meeting of the EuropeanAssociation for Machine Translation (EAMT 2011):137?144.Graham Neubig, Taro Watanabe, Shinsuke Mori andTatsuya Kawahara.
2012.
Machine Translationwithout Words through Substring Alignment.
Pro-ceedings of the 50th Annual Meeting of the Asso-ciation for Computational Linguistics (ACL2012) :165?174.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational Linguistics,29: 19?51.John Power.
2008.
Japanese Names.
The Indexer,Volume 26, No 2, pp.
C4-2?C4-8.Rub?en San-Segundo, Ver?onica L?opez, Raquel Mart?
?n,David S?anchez, Adolfo Garc??a.
2010.
Language re-sources for Spanish ?
Spanish Sign Language (LSE)translation.
The 4th workshop on the representationand processing of sign languages: corpora and signlanguage technologies at LREC 2010: 208?211.Adam Schembri.
2008.
British Sign Language cor-pus project: open access archives and the observer?sparadox.
3rd workshop on the representation andprocessing of sign languages at LREC 2008.Daniel Stein, Christoph Schmidt and Hermann Ney.2012.
Analysis, preparation, and optimization ofstatistical sign language machine translation.
Ma-chine Translation 26: 325-357.Katsuhito Sudoh, Shinsuke Mori and Masaaki Na-gata.
2013.
Noise-aware Character Alignment forBootstrapping Statistical Machine Translation fromBilingual Corpora.
Proceedings of the 2013 Con-ference on Empirical Methods in Natural LanguageProcessing (EMNLP 2013): 204?209.Paola Virga, Senjeev Khudanpur.
2003.
Transliter-ation of proper names in cross-lingual informationretrieval.
MultiNER ?03 Proceeding of the ACL2003 workshop on multilingual and mixed-languagenamed entity recognition Volume 15, pp 57?64.75
