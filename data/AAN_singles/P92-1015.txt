Prosodic Aids to Syntactic and Semantic Analysis of Spoken EnglishChris Rowles and Xiuming HuangAI Systems SectionAustralia and Overseas Telecommunications CorporationTelecommunications Research LaboratoriesPO Box 249, Clayton, Victoria, 3168, AustraliaInternet: c.rowles@td.oz.auABSTRACTProsody can be useful in resolving certain lex-ical and structural ambiguities in spoken English.In this paper we present some results of employ-ing two types of prosodic information, namelypitch and pause, to assist syntactic and semanticanalysis during parsing.1.
INTRODUCTIONIn attempting to merge speech recognitionand natural anguage understanding to produce asystem capable of understanding spoken dia-logues, we are confronted with a range of prob-lems not found in text processing.Spoken language conversations are typicallymore terse, less grammatically correct, less well-structured and more ambiguous than text (Brown& Yule 1983).
Additionally, speech recognitionsystems that attempt o extract words fromspeech typically produce word insertion, deletionor substitution errors due to incorrect recognitionand segmentation.The motivation for our work is to combinespeech recognition and natural language under-standing (NLU) techniques to produce a systemwhich can, in some sense, understand the intentof a speaker in telephone-based, informationseeking dialogues.
As a result, we are interestedin NLU to improve the semantic recognition accu-racy of such a system, but since we do not haveexplicit utterance segmentation and structural in-formation, such as punctuation in text, we haveexplored the use of prosody.Intonation can be useful in understanding dia-logue structure (c.f.
Hirschberg & Pierrehumbert1986), but parsing can also be assisted.
(Briscoe& Boguraev 1984) suggests that if prosodic struc-ture could be derived for the noun compound Bo-ron epoxy rocket motor chambers, then theirparser LEXICAT could reduce the fourteen licit112morphosyntactic nterpretations to one correctanalysis without error (p. 262).
(Steedman 1990)explores taking advantage of intonational struc-ture in spoken sentence understanding in thecombinatory categorial grammar formalism.
(Bear & Price 1990) discusses integrating proso-dy and syntax in parsing spoken English, relativeduration of phonetic segments being the one as-pect of prosody examined.Compared with the efforts expended on syn-tactic/semantic disambiguation mechanisms,prosody is still an under-exploited area.
No workhas yet been carded out which treats prosody atthe same level as syntax, semantics, and prag-matics, even though evidence shows that proso-dy is as important as the other means in humanunderstanding of utterances (see, for example,experiments reported in (Price et a11989)).
(Scott& Cutler 1984) noticed that listeners can suc-cessfully identify the intended meaning of ambig-uous sentences even in the absence of adisambiguating context, and suggested thatspeakers can exploit acoustic features to high-light the distinction that is to be conveyed to thelistener (p. 450).Our current work incorporates certain prosod-ic information into the process of parsing, com-bining syntax, semantics, pragmatics andprosody for disambiguation 1 .
The context of thework is an electronic directory assistance system(Rowles et a11990).
In the following sections, anoverview of the system is first given (Section 2).Then the parser is described in Section 3.
Sec-tion 4 discusses how prosody can be employedin helping resolve ambiguity involved in process-1.
Another possible acoustic source to helpdisambiguation is =segmental phonology", the ap-plication of certain phonological assimilation andelision rules (Scott & Cutler 1984).
The currentwork makes no attempt at this aspect.ing fixed expressions, prepositional phrase at-tachment (PP attachment), and coordinateconstructions.
Section 5 shows the implementa-tion of the parser.2.
SYSTEM OVERVIEWOur work is aimed at the construction of aprototype system for the understanding of spo-ken requests to an electronic directory assis-tance service, such as finding the phone numberand address of a local business that offers partic-ular services.Our immediate work does not concentrate onspeech recognition (SR) or lexical access.
In-stead, we assume that a future speech recogni-tion system performs phoneme recognition anduses linguistic information during word recogni-tion.
Recognition is supplemented by a prosodicfeature extractor, which produces features syn-chronized to the word string output by the SR.The output of the recognizer is passed to asentence-level parser.
Here =sentence" reallymeans a conversational move, that is, a contigu-ous utterance of words constructed so as to con-vey a proposition.Parses of conversational moves are passedto a dialogue analyzer that segments the dia-logue into contextually-consistent sub-dialogues(i.e, exchanges) and interpret speaker requestsin terms of available system functions.
A dia-logue manager manages interaction with thespeaker and retrieves database information,3.
PROSODY EXTRACTIONAs the input to the parser is spoken language,it lacks the segmentation apparent in text.
Withina move, there is no punctuation to hint at internalgrammatical .structure.
In addition, as completesentences are frequently reduced to phrases, el-lipsis etc.
during a dialogue, the Parser cannotuse syntax alone for segmentation.Although intonation reflects deeper issues,such as a speakers' intended interpretation, itprovides the surface structure for spoken lan-guage.
Intonation is inherently supra-segmental,but it is also useful for segmentation purposeswhere other information is unavailable.
Thus, in-tonation can be used to provide initial segmenta-tion via a pre-processor for the parser.Although there are many prosodic featuresthat are potentially useful in the understanding ofspoken English, pitch and pause informationhave received the most attention due to ease ofmeasurement and their relative importance(Cruttenden 1986, pp 3 & 36).
Our efforts to dateuse only these two feature types.We extract pitch and pause information fromspeech using specifically designed hardwarewith some software post-processing.
The hard-ware performs frequency to amplitude transfor-mation and filtering to produce an approximatepitch contour with pauses.The post-processing samples the pitch con-tour, determines the pitch range and classifiesthe instantaneous pitch into high, medium andlow categories within that range.
This is similar tothat used in (Hirschberg & Pierrehumbert 1986).Pauses are classed as short (less than 250ms),long (between 250ms and 800ms) or extended(greater than 800ms).
These times were empiri-cally derived from spoken information seeking di-alogues conducted over a telephone to humanoperators.
Short pauses signify strong tum-hold-ing behaviour, long pauses signify weaker turn-holding behaviour and extended pauses signifyturn passing or exchange completion (Vonwiller1991).
These interpretations can vary with cer-tain pitch movements, however.
Unvoicedsounds are distinguished from pauses by subse-quent synchronisation of prosodic features withthe word stream by post-processing.A parser pre-processor then takes the SRword string, pitch markers and pauses, annotat-ing the word string with pitch markers (lowmarked as = ~ ", medium = - "and high = ^  ")  andpauses (short .
.
.
.
and long .
.
.
.
.
).
The markersare synchronised with words or syllables.
Thepre-processor uses the pitch and pause markersto segment the word string into intonationally-consistent groups, such as tone groups (bound-aries marked as = < = and "> ") and moves (//).
Atone group is a group of words whose intonation-al structure indicates that they form a majorstructural component of the speech, which iscommonly also a major syntactic grouping (Crut-tenden 1986, pp.
75 - 80).
Short conversationalmoves often correspond to tone groups, whilelonger moves may consist of several tonegroups.
With cue words for example, the cueforms its own tone group.113Pauses usually occur at points of low transi-tional probability and often mark phrase bound-aries (Cruttenden 1986).
In general, althoughpitch plays an important part, long pauses, indi-cate tone group and move boundaries, and shortpauses indicate tone group boundaries.
Ex-change boundary markers are dealt with in thedialogue manager (not covered here).
Pitchmovements indicate turn-holding behaviour, top-ic changes, move completion and informationcontrastiveness (Cooper & Sorensen 1977; Von-wilier 1991).The pre-processor also locates fixed expres-sions, so that during the parsing nondeterminismcan be reduced.
A problem here is that a clusterof words may be ambiguous in terms of whetherthey form a fixed expression or not.
"Look after",for example, means =take care of" in "Maryhelped John to look after his kid#', whereas"look" and "after" have separate meaning in "rlllook after you do so".
The pre-processor makesuse of tone group information to help resolve thefixed expression ambiguity.
A more detailed dis-cussion is given in section 5.2.4.
THE PARSEROnce the input is segmented, moves annotat-ed with prosody are input to the parser.
The pars-er deals with one move at a time.In general, the intonational structure of a sen-tence and its syntactic structure coincide (Crut-tenden 1986).
Thus, prosodic segmentationavoids having the Parser try to extract movesfrom unsegmented word strings based solely onsyntax.
It also reduces the computational com-plexity in comparing syntactic and prosodic wordgroupings.
There is a complication, however, inthat tone group boundaries and move bound-aries may not align exactly.
This is not frequent,and is not present in the material used here.
Into-nation is used to limit the range of syntactic pos-sibilities and the parser will align tone group andmove syntactic boundaries at a later stage.By integrating syntax and semantics, theParser is capable of resolving most of the ambig-uous structures it encounters in parsing writtenEnglish sentences, such as coordinate conjunc-tions, PP attachments, and lexical ambiguity(Huang 1988).
Migrating the Parser from writtento spoken English is our current focus.Moves input to the Parser are unlikely to bewell-formed sentences, as people do not alwaysspeak grammatically, or due to the SR's inabilityto accurately recognise the actual words spoken.The parser first assumes that the input move islexically correct and tries to obtain a parse for it,employing syntactic and semantic relaxationtechniques for handling ill-formed sentences(Huang 1988).
If no acceptable analysis is pro-duced, the parser asks the SR to provide thenext alternative word string.Exchanges between the parser and the SRare needed for handling situations where an ill-formed utterance gets further distorted by theSR.
In these cases other knowledge sourcessuch as pragmatics, dialogue analysis, and dia-logue management must be used to find themost likely interpretation for the input string.
Weuse pragmatics and knowledge of dialogue struc-ture to find the semantic links between separateconversational moves by either participant andresolve indirectness uch as pronouns, deicticexpressions and brief responses to the otherspeaker \[for more details, see (Rowles, 1989)\].By determining the dialogue purpose of utteranc-es and their domain context, it is then possible tocorrect some of the insertion and mis-recognisedword errors from the SR and determine the com-municative intent of the speaker.
The dialoguemanager queries the speaker if sentences can-not be analysed at the pragmatic stage.The output of the parser is a parse tree thatcontains syntactic, semantic and prosodic fea-tures.
Most ambiguity is removed in the parsetree, though some is left for later resolution, suchas definite and anaphoric references, whose res-olution normally requires inter-move inferences.The parser also detects cue words in its inputusing prosody.
Cue words, such as "now" in"Now, I want to...", are words whose meta-func-tion in determining the structure of dialoguesoverrides their semantic roles (Reichman1985).Cue words and phrases are prosodicallydistinct due to their high pitch and pause separa-tion from tone groups that convey most of thepropositional content (Hirschberg & Litman1987).
While relatively unimportant semantically,cue words are very important in dialogue analy-sis due to their ability to indicate segmentationand the linkage of the dialogue components.5.
PROSODY AND DISAMBIGUATIONDuring parsing prosodic information is usedto help disambiguate certain structures whichcannot be disambiguated syntactically/semanti-cally, or whose processing demands extra ef-forts, if no such prosodic information is available.In general, prosody includes pitch, loudness, du-ration (of words, morphemes and pauses) andrhythm.
While all of these are important cues, weare currently focussing on pitch and pauses asthese are easily extracted from the waveformand offer useful disambiguation during parsingand segmentation in dialogue analysis.
Subse-quent work will include the other features, andfurther refinement of the use of pitch and pause.At present, for example, we do not consider thelength of pauses internal to tone groups, al-though this may be significant.The prosodic markers are used by the parseras additional pre-conditions for grammaticalrules, discriminating between possible grammati-cal constructions via consistent intonationalstructures.5.1 HOMOGRAPHSEven when using prosody, homographs are aproblem for parsers, although a system recognis-ing words from phonemes can make the problema simpler.
The word sense of =bank" in "Johnwent to the bank" must be determined from se-mantics as the sense is not dependent upon vo-calisation, but the difference between thehomograph "content" in "contents of a book" and"happy and content' can be determined throughdiffering syllabic stress and resultant differentphonemes.
Thus, different homographs can bedetected during lexical access in the SR inde-pendently of the Parser.5.2 FIXED EXPRESSIONSAs is mentioned in subsection 4.1, when thepre-processor tries to locate fixed expressions, itmay face multiple choices.
Some fixed expres-sions are obligatory, i.e., they form single seman-tic units, for instance =look forward to" oftenmeans "expect o feel pleasure in (somethingabout to happen) ''2.
Some other strings may or2.
Longman Dictionary of Contemporary En-glish, 1978.may not form single sematic units, depending onthe context.
=Look after" and "win over" are twoexamples.
Without prosodic information, the pre-processor has to make a choice blindly, e.g.treating all potential fixed expressions as suchand on backtracking dissolve them into separatewords.
This adds to the nondeterminism of theparsing.
As prosodic information becomes avail-able, the nondeterminism is avoided.In the system's fixed expression lexicon, wehave entries such as "fix_e(\[gave, up\], gave_-up)".
The pre-processor contains a rule to the fol-lowing effect, which conjoins two (or more) wordsinto one fixed expression only when there is nopause following the first word:match_fix_e(\[FirstW, SecondWlRestW\], \[Fixe-dEIMoreW\]):-no_pause in between(FirstW, SecondW),fix_e(\[FirstW, SecondW\], FixedE),Match_fix_e(RestW, MoreW).This rule produces the following segment:-tions:(5.1a) <-He -gave> *<^up to ^ two hundreddollars> *<-to the ^ charity>**//(5.1b) <-He Agave ^ up> *<^two hundred dol-lars> *<-for damage compensation>**//.In (5.1a), gave and upto are treated as be-longing to two separate tone groups, whereas in(5.1 b) gave up is marked as one tone group.
Thepre-processor checking its fixed expression dic-tionary will therefore convert up to in (5.1 a) toup_to, and gave up in (5.1b) to gave_up.5.3 PP ATTACHMENT(Steedman 1990 & Cruttenden 1986) ob-served that intonational structure is strongly con-strained by meaning.
For example, an intonationimposing bracketings like the following is not al-lowed:(5.2) <Three cats> <in ten prefer corduroy>//Conversely, the actual contour detected forthe input can be significant in helping decide thesegmentation and resolving PP attachment.
Inthe following sentence, f.g.,(5.3) <1 would like> < information on her ar-rival> \[=on her arrival" attached to "information' 1115(5.4) <1 would like> <information> ** <on herarrival> \["on her arrival" attached to "like"\]the pause after "information" in (5.4), but not in(5.3), breaks the bracketed phrase in (5.3) intotwo separate tone groups with different attach-ments.In a clash between prosodic constraints andsyntactic/semantic constraints, the latter takesprecedence over the former.
For instance, in:(5.5) <1 would like> <information> ** <onsome panel beaters in my area>.although the intonation does not suggest attach-ment of the PP to "information", since the se-mantics constraints exclude attachment o "like"meaning "choose to have" ("On panel beaters \[asa location or time\] I like information" does notrate as a good interpretation), it is attached to "in-formation" anyway (which satisfies the syntactic/semantic constraints).5.4 COORDINATE CONSTRUCTIONSCoordinate constructions can be highly am-biguous, and are handled by rules such as:Np --> det(Det), adj(Adj),/* check if a pause follows the adjective */{check_pause (Flag)}, noun (Noun),{construct_np(Det, Adj, Noun, NP},conjunction(NP, Flag, FinalNP).In the conjunction rule, if two noun phrasesare joined, we check for any pauses to see if theadjective modifying the first noun should be cop-ied to allow it to modify the second noun.
Similar-ly, we check for a pause preceding theconjunction to decide if we should copy the postmodifier of the second noun to the first nounphrase.
For instance, the text-form phrase:(5.6) old men and women in glassescan produce three possible interpretations:\[old men (in glasses)\] and \[(old) women inglasses\] (5.6a)\[old men\] and \[women in glasses\] (5.6b)\[old men (in glasses)\] and \[women in glasses\](5.6c).l o0 ~..,,< (~) !Old men and women in glass - es(.,3P;*ch~,.,.t" s )  t< Old > <men and wmnen in glass- es>(Vl,)2o< Old-rr,,., e C.-.)
iinell > (and wollletl ill glass - es>P'~ I I I< Ohl men> <and women> <in glass- es>(1) neutraliulonailon(2) attachment of2 phrnses(3) i so la ted(4) atlaclmient ofI phrase onlyFigure 1.Figure1 shows some measured pitch con-tours for utterances of phrase (5.6) with an at-tempt by the speaker to provide theinterpretations (a) through (c).
Note that the con-tour is smoothed by the hardware pitch extrac-tion.
Pauses and unvoiced sounds aredistinguished in the software post-processor.In all waveforms "old" and "glasses" havehigh pitch.
In (5.6a), a short pause follows "old",indicating that "old" modifies "men and women inglasses" as a sub-phrase.
This is in contrast to(5.6b) where the short pause appears after"men" indicating "old men" as one conjunct and"women in glasses" as the other.
Notice also thatduration of "men" in (5.6b) is longer than in(5.6a).
In (5.6c) we have two major pauses, ashorter one after "men" and a longer one after"women".
Using this variation in pause locations,116the parser produces the correct interpretation(i.e.
the speaker's intended interpretation) forsentences (5.6a-c).6.
IMPLEMENTATIONProsodic information, currently the pitch con-tour and pauses, are extracted by hardware andsoftware.
The hardware detects pitch and paus-es from the speech waveform, while the softwaredetermines the duration of pauses, categorisespitch movements and synchronises these to thesequence of lexical tokens output from a hypo-thetical word recogniser.
The parser is written inthe Definite Clause Grammars formalism (Perei-ra et al 1980) and runs under BIMProlog on aSPARCstation 1.
The pitch and pause extractoras described here is also complete.To illustrate the function of the prosodic fea-ture extractor and the Parser pre-processor, thefollowing sentence was uttered and its pitch con-tour analysed:"yes i'd like information on some panel beaters"Prosodic feature extraction produced:** Ayes ** ^ i'd Alike * -information on some ^ panelbeaters **//The Parser pre-processor then segments theinput (in terms of moves and tone groups) for theParser, resulting in:**< Ayes> **//< ^ i'd Alike> * <-information on some^panel beaters> **//The actual output of the pre-processor is intwo parts, one an indexed string of lexical itemsplus prosodic information, the other a string oftone groups indicating their start and end points:\[** Ayes, 1\] \[**// ^i, 2\] \[would, 3\] \[Alike, 4\] \[* -infor-mation, 5\] \[on, 6\] \[some, 7\] \["panel_ beaters, 8\]\[**//, 9\]<1,1> <2, 4> < 5, 8> <9,9>We use a set of sentences 3, all beginningwith "Before the King~feature race~', but with dif-ferent intonation to provide different interpreta-tions, to illustrate how syntax, semantics and3.
Adapted from (Briscoe & Boguraev 1984).prosody(6.1)*horse>are used for disambiguation:<~ Before the -King ^ races>*<-his<is -usually ^ groomed>**//.
(6.2) <~Before the -King> *<-races his^horse> **<it's -usually ^ groomed>**//.
(6.3) <~Before the ^ feature ~races> *<-his^horse is -usually ^ groomed>**//.The syntactic ambiguity of "before" (preposi-tion in 6.3 and subordinate conjunction in 6.1 and6.2) is solved by semantic checking: "race" as averb requires an animate subject, which "theKing" satisfies, but not "the feature"; "race" as anoun can normally be modified by other nounssuch as "feature", but not "King '4.
However,when prosody information is not used the timeneeded for parsing the three sentences variestremendously, due to the top-down, depth-firstnature of the parser.
(6.3) took 2.05 seconds toparse, whereas (6.1) took 9.34 seconds, and(6.2), 41.78 seconds.
The explanation lies in thaton seeing the word "before" the parser made anassumption that it was a preposition (correct for6.3), and took the "wrong" path before backtrack-ing to find that it really was a conjunction (for 6.1and 6.2).
Changingthe order of rules would nothelp here: if the first assumption treats "before"as a conjunction, then parsing of (6.3) wouldhave been slowed down.We made one change to the grammar so thatit takes into account the pitch information accom-panying the word "races" to see if improvementcan be made.
The parser states that a noun-noun string can form a compound noun grouponly when the last noun has a low pitch.
That is,the feature ~races forms a legitimate nounphrase, while the King -races and the King '~rac-es do not.
This is in accordance with one of thebest known English stress rules, the "CompoundStress Rule" (Chomsky and Halle 1968), whichasserts that the first lexically stressed syllable ina constituent has the primary stress if the constit-uent is a compound construction forming an ad-jective, verb, or noun.4.
It is very difficult, though, to give a clear cutas to what kind of nouns can function as nounmodifiers.
King races may be a perfect noungroup in certain context.117We then added the pause information in theparser along similar lines.
The following is a sim-plified version of the VP grammar to illustrate theparsing mechanism:/* Noun phrase rule.
"Mods" can be a string of adjectives or nouns:major (races), feature (races), etc.
*/Np--> Det, Mods,HeadNoun./* Head noun is preferred to be low-pitched.
*/HeadNoun --> \[Noun\], {Iowpitched(Noun)}./* Verb phrase rule 1 .
*/Vp --> V_intr./* Verb phrase rule 2.
Some semantic check-ing is carded out after a transitive verb and anoun phrase is found.
*/Vp --> V_tr, Np, {match(V_tr, Np)}./* If a verb is found which might be used as in-transitive, check if there is a pause following it.
*/V_intr --> \[Verb\], {is_intransitive(Verb)\],Pause./* Otherwise see if the verb can be used astransitive.
*/V_tr--> \[Verb\], {is_transitive(Verb)}./* This succeeds if a pause is detected.
*/Pause --> \[pause\].The pause information following "races" insentences(6.1) and (6.2)thus helps the parser todecide if "races" is transitive or intransitive, againreducing nondeterminism.
The above rules spec-ify only the preferred patterns, not absolute con-straints.
If they cannot be satisfied, e.g.
whenthere is no pause detected after a verb which isintransitive, the string is accepted anyway.The parse times for sentences (6.1) to (6.3)with and without prosodic rules in the parser aregiven in the Table 6.1.Without Prosody With Prosody(6.1) 9.34 1.23(6.2) 41.78 8.69(6.3) 2.05 1.27Table 6.1 Parsing Times for the =races" sentence(in seconds).Table 6.2 shows how the parser performed onthe following sentences:(6.4) *1'11 look* ^ after the -boy ~comes**//(6.5) *He Agave* ^ up to ^ two *hundred dollarsto the -charity**//(6.6) ^ Now* -I want -some -information on*panel *beaters -in ~Clayton**//Without Prosody With Prosody(6.4) 6.59 1.19(6.5) 41.38 2.49(6.6) 2.15 2.55Table 6.2 Parsing Times for sentences (6.4) to(6.6) (in seconds).While (6.6) is slower with prosodic annotation,the parser correctly recognises "now" as a cueword rather than as an adverb.7.
DISCUSSIONWe have shown that by integrating prosodywith syntax and semantics in a natural languageparser we can improve parser performance.
Inspoken language, prosody is used to isolate sen-tences at the parser's input and again to deter-mine the syntactic structure of sentences byseeking structures that are intonationally andsyntactically consistent.The work described here is in progress.
Theprosodic features with which sentences havebeen annotated are the output of our feature ex-tractor, but synchronisation is by hand as we donot have a speech recognition system.
As shownby the =old men ..." example, the system is capa-ble of accurately producing correct interpreta-tions, but as yet, no formal experiments usingdata extracted from ordinary telephone conver-sations and human comparisons have been per-formed.
The aim has been to investigate thepotential for the use of prosody in parsers intend-ed for use in speech understanding systems.
(Bear & Price 1990) modified the grammarthey use to change all the rules of the form A ->B C to the form A -> B Link C, and add con-straints to the rules application in terms of thevalue of the =breaking indices" based on relativeduration of phonetic segments.
For instance therule VP -> V Link PP applies only when the valueof the link is either 0 or 1, indicating a close cou-pling of neighbouring words.
Duration is thus tak-118en into consideration in deciding the structure ofthe input.
In our work, pitch contour and pauseare used instead, achieving a similar result.The principle of preference semantics allowsthe straightforward integration of prosody intoparsing rules and a consistent representation ofprosody and syntax.
Such integration may havebeen more of a problem if the basic parsing ap-proach had been different.
Also relevant is thechoice of English, as the integration may not car-ry across to other languages.Future research aims at a more thoroughtreatment of prosody.
Research currently under-way, is also focussing on the use of prosody anddialogue knowledge for dialogue analysis andturn management.ACKNOWLEDGEMENTSThe permission of the Director, Research,AOTC to publish the above paper is hereby ac-knowledged.
The authors have benefited fromdiscussions with Robin King, Peter Sefton, JulieVonwiller and Christian Matthiessen, SydneyUniversity, and Muriel de Beler, Telecommunica-tion Research Laboratories, who are involved infurther work on this project.
The authors wouldalso like to thanks the anonymous reviewers forpositive comments on paper improvements.REFERENCESBear, J.
& Price, P. J.
(1990), Prosody, Syntaxand Parsing.
28th Annual Meeting of the Assoc.for Computational Linguistics (pp.
17-22).Briscoe, E.J.
& Boguraev, B.K.
(1984), Con-trol Structures and Theories of Interaction inSpeech Understanding Systems.
22th AnnualMeeting of the Assoc.
for Computational Linguis-tics (pp.
259-266)Brown, G., & Yule, G., (1983), DiscourseAnalysis, Cambridge University Press.Chomsky, N.& Halle, M. (1968), The SoundPattern of English, (New York: Harper and Row).Cooper, W.E.
& Sorensen, J.M., (1977), Fun-damental Frequency Contours at SyntacticBoundaries, Journal of the Acoustical Society ofAmerica, Vol.
62, No.
3, September.Cruttenden, A., (1986), Intonation, Cam-bridge University Press.Hirschberg, J.
& Litman, D., (1987), Now Let'sTalk About Now: Identifying Cue Phrases Intona-tionally, 25th Annual Meeting of the Assoc.
forComputational Linguistics.Hirschberg, J.
& Pierrehumbert, J., The Into-national Structure of Discourse, 24th AnnualMeeting of the Assoc.
for Computational Linguis-tics, 1986.Huang, X-M. (1988), Semantic Analysis inXTRA, An English - Chinese Machine TranslationSystem, Computers and Translation 3, No.2.
(pp.I 01-120)Pereira, F. & Warren, D. (1980), DefiniteClause Grammars for Language Analysis - ASurvey of the Formalism and A Comparison with?
Augmented Transition Networks.
Artificial Intelli-gence, 13:231-278.Price, P. J., Ostendorf, M. & Wightmen, C.W.
(1989), Prosody and Parsing.
DARPA Workshopon Speech and Natural Language, Cape Cod,October 1989 (pp.5-11).Reichman, R. (1985), Getting Computers toTalk Like You and Me, (Cambridge: MIT Press).Rowles, C.D.
(1989), Recognizing User Inten-tions from Natural anguage Expressions, FirstAustralia-Japan Joint Symposium on NaturalLanguage Processing, (pp.
157-I 66).Rowles, C.D., Huang, X., and Aumann, G.,(1990), Natural Language Understanding andSpeech Recognition: Exploring lhe Connections,Third Australian International Conference onSpeech Science and Technology, (pp.
374 - 382).Steedman, M. (1990),Structure and Intonationin Spoken Language Understanding.
28th AnnualMeeting of the Assoc.
for Computational Linguis-tics (pp.
9-I 6).Scott, D.R & Cutler, A.
(1984), SegmentalPhonology and the Perception of Syntactic Struc-ture, Journal of Verbal Learning and Verbal Be-havior23, (pp.
450-466).Vonwiller, J.
(1991),An Empirical Study ofSome Features of Intonation, Second Australia-Japan Natural Language Processing Sympo-sium, Japan, November, (pp 66-71 ).119
