Lexicalising Word Order Constraints forImplemented Linearisation GrammarYo SatoDepartment of Computer ScienceKing?s College Londonyo.sato@kcl.ac.ukAbstractThis paper presents a way in which a lex-icalised HPSG grammar can handle wordorder constraints in a computational pars-ing system, without invoking an additionallayer of representation for word order,such as Reape?s Word Order Domain.
Thekey proposal is to incorporate into lexi-cal heads the WOC (Word Order Con-straints) feature, which is used to constrainthe word order of its projection.
We alsooverview our parsing algorithm.1 IntroductionIt is a while since the linearisation technique wasintroduced into HPSG by Reape (1993; 1994) asa way to overcome the inadequacy of the con-ventional phrase structure rule based grammars inhandling ?freer?
word order of languages such asGerman and Japanese.
In parallel in computa-tional linguistics, it has long been proposed thatmore flexible parsing techniques may be requiredto adequately handle such languages, but hithertoa practical system using linearisation has eludedlarge-scale implementation.
There are at least twoobstacles: its higher computational cost accom-panied with non-CFG algorithms it requires, andthe difficulty to state word order information suc-cinctly in a grammar that works well with a non-CFG parsing engine.In a recent development, the ?cost?
issue hasbeen tackled by Daniels and Meurers (2004), whopropose to narrow down on search space while us-ing a non-CFG algorithm.
The underlying princi-ple is to give priority to the full generative capac-ity, let the parser overgenerate at default but re-strict generation for efficiency thereafter.
Whilesharing this principle, I will attempt to furtherstreamline the computation of linearisation, focus-ing mainly on the issue of grammar formalism.Specifically, I would like to show that the lex-icalisation of word order constraints is possiblewith some conservative modifications to the stan-dard HPSG (Pollard and Sag, 1987; Pollard andSag, 1994).
This will have the benefit of makingthe representation of linearisation grammar sim-pler and more parsing friendly than Reape?s influ-ential Word Order Domain theory.In what follows, after justifying the need fornon-CFG parsing and reviewing Reape?s theory, Iwill propose to introduce into HPSG the Word Or-der Constraint (WOC) feature for lexical heads.
Iwill then describe the parsing algorithm that refersto this feature to constrain the search for efficiency.1.1 Limitation of CFG ParsingOne of the main obstacles for CFG parsing isthe discontinuity in natural languages caused by?interleaving?
of elements from different phrases(Shieber, 1985).
Although there are well-knownsyntactic techniques to enhance CFG as in GPSG(Gazdar et al, 1985), there remain constructionsthat show ?genuine?
discontinuity of the kind thatcannot be properly dealt with by CFG.Such ?difficult?
discontinuity typically occurswhen it is combined with scrambling ?
anothersymptomatic phenomenon of free word order lan-guages ?
of a verb?s complements.
The follow-ing is an example from German, where scramblingand discontinuity co-occur in what is called ?inco-herent?
object control verb construction.
(1) Ich glaube, dass der Fritz dem FrankI believe Comp Fritz(Nom) Frank(Dat)das Buch zu lesen erlaubt.the book(Acc) to read allow?I think that Fritz allows Frank to read the book?23(1?)
Ich glaube, dass der Fritz [das Buch] dem Frank[zu lesen] erlaubtIch glaube, dass dem Frank [das Buch] der Fritz[zu lesen] erlaubtIch glaube, dass [das Buch] dem Frank der Fritz[zu lesen] erlaubt...Here (1) is in the ?canonical?
word order while theexamples in (1?)
are its scrambled variants.
Inthe traditional ?bi-clausal?
analysis according towhich the object control verb subcategorises fora zu-infinitival VP complement as well as nomi-nal complements, this embedded VP, das Buch zulesen, becomes discontinuous in the latter exam-ples (in square brackets).One CFG response is to use ?mono-clausal?analysis or argument composition(Hinrichs andNakazawa, 1990), according to which the higherverb and lower verb (in the above example er-lauben and zu lesen) are combined to form a sin-gle verbal complex, which in turn subcategorisesfor nominal complements (das Buch, der Fritz anddem Frank).
Under this treatment both the ver-bal complex and the sequence of complements arerendered continuous, rendering all the above ex-amples CFG-parseable.However, this does not quite save the CFGparseability, in the face of the fact that you couldextrapose the lower V + NP, as in the following.
(2) Ich glaube, dass der Fritz dem Frank [erlaubt], dasBuch [zu lesen].Now we have a discontinuity of ?verbal complex?instead of complements (the now discontinuousverbal complex is marked with square brackets).Thus either way, some discontinuity is inevitable.Such discontinuity is by no means a marginalphenomenon limited to German.
Parallel phenom-ena are observed in the object control verbs inKorean and Japanese ((Sato, 2004) for examples).These languages also show a variety of ?genuine?discontinuity of other sorts, which do not lenditself to a straightforward CFG parsing (Yatabe,1996).
The CFG-recalcitrant constructions exist inabundance, pointing to an acute need for non-CFGparsing.1.2 Reape?s Word Order DomainThe most influential proposal to accommodatesuch discontinuity/scrambling in HPSG is Reape?sWord Order Domain, or DOM, a feature that con-stitutes an additional layer separate from the dom-inance structure of phrases (Reape, 1993; Reape,1994).
DOM encodes the phonologically realised(?linearised?)
list of signs: the daughter signs of a???????????
?phraseDOM?1 ?
2 ?
3 ?...?
n?HD-DTR?
[phraseDOM 1UNIONED +]?NHD-DTRs?
[phraseDOM 2UNIONED +],[phraseDOM 3UNIONED +]...[phraseDOM nUNIONED +]????????????
?Figure 1: Word Order Domainphrase in the HD-DTR and NHD-DTRS featuresare linearly ordered as in Figure 1.The feature UNIONED in the daughters indi-cates whether discontinuity amongst their con-stituents is allowed.
Computationally, the positive(?+?)
value of the feature dictates (the DOMs of)the daughters to be sequence unioned (representedby the operator ?)
into the mother DOM: detailsapart, this operation essentially merges two lists ina way that allows interleaving of their elements.In Reape?s theory, LP constraints come froman entirely different source.
There is nothing asyet that blocks, for instance, the ungrammaticalzu lesen das Buch VP sequence.
The relevantconstraint, i.e.
COMPS?ZU-INF-V in German, isstated in the LP component of the theory.
Thuswith the interaction of the UNIONED feature andLP statements, the grammar rules out the unac-ceptable sequences while endorsing grammaticalones such as the examples in (1?
).One important aspect of Reape?s theory is thatDOM is a list of whole signs rather than of anypart of them such as PHON.
This is necessi-tated by the fact that in order to determine howDOM should be constructed, the daughters?
inter-nal structure need to be referred to, above all, theUNIONED feature.
In other words, the internalfeatures of the daughters must be accessible.While this is a powerful system that overcomesthe inadequacies of phrase-structure rules, somemay feel this is a rather heavy-handed way tosolve the problems.
Above all, much informationis repeated, as all the signs are effectively statedtwice, once in the phrase structure and again inDOM.
Also, the fact that discontinuity and lin-ear precedence are handled by two distinct mecha-nisms seems somewhat questionable, as these twofactors are computationally closely related.
Theseproperties are not entirely attractive features for acomputational grammar.242 Lexicalising Word Order Constraints2.1 OverviewOur theoretical goal is, in a nutshell, to achievewhat Reape does, namely handling discontinuityand linear precedence, in a simpler, more lexical-ist manner.
My central proposal consists in incor-porating the Word Order Constraint (WOC) fea-ture into the lexical heads, rather than positing anadditional tier for linearisation.
Some new sub-features will also be introduced.The value of the WOC feature is a set of word-order related constraints.
It may contain any re-lational constraint the grammar writer may wantwith the proviso of its formalisability, but for thecurrent proposal, I include two subfeatures ADJ(adjacency) and LP, both of which, being binaryrelations, are represented as a set of ordered pairs,the members of which must either be the head it-self or its sisters.
Figure 2 illustrates what suchfeature structure looks like with an English verbprovide, as in provide him with a book.We will discuss the new PHON subfeatures inthe next section ?
for now it would suffice to con-sider them to constitute the standard PHON list ?so let us focus on WOC here.
The WOC feature ofthis verb says, for its projection (VP), three con-straints have to be observed.
Firstly, the ADJ sub-feature says that the indirect object NP has to bein the adjacent position to the verb (?provide yes-terday him with a book?
is not allowed).
Secondly,the first two elements of the LP value encode ahead-initial constraint for English VPs, namelythat a head verb has to be preceded by its com-plements.
Lastly, the last pair in the same set saysthe indirect object must precede the with-PP (?pro-vide with a book him?
is not allowed).
Notice thatthis specification leaves room for some disconti-nuity, as there is no ADJ requirement between theindirect NP and with-PP.
Hence, provide him yes-terday with a book is allowed.The key idea here is that since the complementsof a lexical head are available in its COMPS fea-ture, it should be possible to state the relative lin-ear order which holds between the head and acomplement, as well as between complements, in-side the feature structure of the head.Admittedly word order would naturally be con-sidered to reside in a phrase, string of words.It might be argued, on the ground that a head?sCOMPS feature simply consists of the categoriesit selects for in exclusion of the PHON feature,that with this architecture one would inevitablyencounter the ?accessibility?
problem discussed inv?????????????????verbPHON??phon-wdCONSTITUENTS{provide}CONSTRAINTS{}?
?COMPS?np[npcase Acc],pp[pppform with]?WOC???
?wocADJ{?v , np?
}LP{?v , np?,?v , pp?,?np,pp?}????????????????????
?Figure 2: Example of lexical head with WOC fea-tureSection 1.2: in order to ensure the enforceabilityof word order constraints, an access must be se-cured to the values of the internal features includ-ing the PHON values.
However, this problem canbe overcome, as we will see, if due arrangementsare in place.The main benefit of this mechanism is that itpaves way to an entirely lexicon-based rule spec-ification, so that, on one hand, duplication of in-formation between lexical specification and phrasestructure rules can be reduced and on the other, awide variety of lexical properties can be flexiblyhandled.
If the word order constraints, which havebeen regarded as the bastion of rule-based gram-mars, is shown to be lexically handled, it is onesignificant step further to a fully lexicalist gram-mar.2.2 New Head-Argument SchemaWhat is crucial for this WOC-incorporated gram-mar is how the required word order constraintsstated in WOC are passed on and enforced in itsprojection.
I attempt to formalise this in the formof Head-Argument Schema, by modifying Head-Complement Schema of Pollard and Sag (1994).There are two key revisions: an enriched PHONfeature that contains word order constraints andpercolation of these constraints emanating fromthe WOC feature in the head.The revised Schema is shown in Figure 3.
Forsimplicity only the LP subfeature is dealt with,since the ADJ subfeature would work exactly thesame way.
The set notations attached underneathstates the restriction on the value of WOC, namelythat all the signs that appear in the constraintpairs must be ?relevant?, i.e.
must also appear asdaughters (included in ?DtrSet?, the set of the headdaughter and non-head daughters).
Naturally, theyalso cannot be the same signs (x6=y).Let me discuss some auxiliary modifications25???????????????????????????????????head-arg-phrasePHON?????phonCONSTITS?
{{ph},pa1,...,pai,...,paj,...pan}CONSTRTS | LP?{{...,?pai,paj?,...
}, ca1 ,..., cai ,... caj ,..., can}?????ARGS?
?HD-DTR hd??????????????????
?wordPHN[CONSTITS{ph}CONSTRS{}]ARGS args?a1?
?signPHN[CONSTITS pa1CONSTRS ca1]?
?,..., ai?
?signPHN[CONSTITS paiCONSTRS cai]??,...,aj?
?signPHN[CONSTITS pajCONSTRS caj]?
?,..., an[signPHN[CONSTITS panCONSTRS can]]?WOC | LP wocs{...,?ai , aj?,...}??????????????????
?NHD-DTRs args??????????????????????????????????
?where wocs ?
{?x,y?|x6=y, x,y?DtrSet}DtrSet = {hd}?
argsFigure 3: Head-Argument Schema with WOC featurefirst.
Firstly, we change the feature name fromCOMPS to ARGS because we assume a non-configurational flat structure, as is commonly thecase with linearisation grammar.
Another changeI propose is to make ARGS a list of underspeci-fied signs instead of SYNSEMs as standardly as-sumed (Pollard and Sag, 1994).
In fact, this is aposition taken in an older version of HPSG (Pol-lard and Sag, 1987) but rejected on the ground ofthe locality of subcategorisation.
The main reasonfor this reversal is to facilitate the ?accessibility?we discussed earlier.
As unification and percola-tion of the PHON information is involved in theSchema, it is much more straightforward to for-mulate with signs.
Though the change may notbe quite defensible solely on this ground,1 there isreason to leave the locality principle as an optionfor languages of which it holds rather than hard-wire it into the Schema, since some authors raisedoubt as for the universal applicability of the lo-cality principle e.g.
(Meurers, 1999).Turning to a more substantial modification, ournew PHON feature consists of two subfeatures,CONSTITUENTS (or CONSTITS) and CON-STRAINTS (or CONSTRS).
The former encodesthe set that comprises the phonology of words ofwhich the string consists.
Put simply, it is the un-1Another potential problem is cyclicity, since the sign-valued ARGS feature contains the WOC feature, which couldcontain the head itself.
This has to be fixed for the systemsthat do not allow cyclicity.ordered version of the standard PHON list.
TheCONSTRAINTS feature represents the concata-native constraints applicable to the string.
Thus,the PHON feature overall represents the legitimateword order patterns in an underspecified way, i.e.any of the possible string combinations that obeythe constraints.
Let me illustrate with a VP ex-ample, say, consisting of meet, often and Tom, forwhich we assume that the following word orderpatterns are acceptable,?meet, Tom, often?, ?often, meet, Tom?but not the followings:?meet, often, Tom?, ?Tom, often, meet?,?Tom, meet, often?, ?often, Tom, meet?.This situation can be captured by the followingfeature specification for PHON, which encodesany of the acceptable strings above in an under-specified way.????????PHON???????
?CONSTITS{often, Tom, meet}CONSTRS?????ADJ{?{meet},{Tom}?}LP{?{meet},{Tom}?}????????????????????
?The key point is that now the computation ofword order can be done based on the informationinside the PHON feature, though indeed the CON-STR values have to come from outside ?
the wordorder crucially depends on SYNSEM-related val-ues of the daughter signs.26Let us now go back to the Schema in Figure 3and see how to determine the CONSTR values toenter the PHON feature.
This is achieved by look-ing up the WOC constraints in the head (let?s callthis Step 1) and pushing the relevant constraintsinto the PHON feature of its mother, according tothe type of constraints (Step 2).For readability Figure 3 only states explicitlya special case ?
where one LP constraint holdsof two of the arguments ?
but the reader isasked to interpret ai and aj in the head daughter?sWOC|LP to represent any two signs chosen fromthe ?DTRS?
list (including the head, hd).
2 Thestructure sharing of ai and aj between WOC|LPand ARGS indicates that the LP constraint appliesto these two arguments in this order, i.e.
ai?aj.Thus through unification, it is determined whichconstraints apply to which pairs of daughter signsinside the head.
This corresponds to Step 1.Now, only for these WOC-applicable daughtersigns, the PHON|CONSTIITS values are paired upfor each constraint (in this case ?pai, paj?)
andpushed into the mother?s PHON|CONSTRS fea-ture.
This corresponds to Step 2.Notice also that the CONSTRAINTS subfeatureis cumulatively inherited.
All the non-head daugh-ters?
CONSTR values (ca1,...,can) ?
the word or-der constraints applicable to each of these daugh-ters ?
are also passed up, collecting effectivelyall the CONSTR values of its daughters and de-scendants.
This means the information concern-ing word order, as tied to particular string pairs, isnever lost and passed up all the way through.
Thusthe WOC constraints can be enforced at any pointwhere both members of the string pair in questionare instantiated.2.3 A Worked ExampleLet us now go through an example of applyingthe Schema, again with the German subordinateclause, das Buch der Fritz dem Frank zu lesen er-laubt (and other acceptable variants).
Our goal isto enforce the ADJ and LP constraints in a flexibleenough way, allowing the acceptable sequencessuch as those we saw in Section 1.2.1. whileblocking the constraint-violating instances.The instantiated Schema is shown in Figure 4.Let us start with a rather deeply embedded level,the embedded verb zu-lesen, marked v2, found in-side vp (the last and largest NHD-DTR) as its HD-2For the generality of the number of ARGS elements,which should be taken to be any number including zero, therecursive definition as detailed in (Richter and Sailer, 1995)can be adopted.DTR, which I suppose to be one lexical item forsimplicity.
This is one of the lexical heads fromwhich the WOC constraints emanate.
Find, inthis item?s WOC, a general LP constraint for zu-Infinitiv VPs, COMPS?V, namely np3?v2.
Thenthe PHON|CONSTITS values of these signs aresearched for and found in the daughters, namelypnp3 and pv2.
These values are paired up andpassed into the CONSTRS|LP value of its motherVP.
Notice also that into this value the NHD-DTRs?
CONSTR|LP values, in this case onlylpnp3 ({das}?
{Buch}), are also unioned, consti-tuting lpvp: we are here witnessing the cumula-tive inheritance of constraints explained earlier.Turn attention now to the percolation of ADJ sub-feature: no ADJ requirement is found betweendas Buch and zu-lesen (v2?s WOC|ADJ is empty),though ADJ is required one node below, betweendas and Buch (np3?s PHN|CONSTR|ADJ).
Thusno new ADJ pair is added to the mother VP?sPHON|CONSTR feature.Exactly the same process is repeated for theprojection of erlauben (v1), where its WOCagain contains only LP requirements.
With thePHON|CONSTITS values of the relevant signsfound and paired up ({Fritz,der}?
{erlaubt} and{Frank,dem}?
{erlaubt}), they are pushed into itsmother?s PHON|CONSTRS|LP value, which isalso unioned with the PHON|CONSTRS values ofthe NHD-DTRS.
Notice this time that there is noLP requirement between the zu-Infinitiv VP, dasBuch zu-lesen, and the higher verb, erlaubt.
Thisis intended to allow for extraposition.3The eventual effect of the cumulative constraintinheritance can be more clearly seen in the sub-AVM underneath, which shows the PHON part ofthe whole feature structure with its values instan-tiated.
After a succession of applications of theHead-Argument Schema, we now have a pool ofWOCs sufficient to block unwanted word orderpatterns while endorsing legitimate ones.
The rep-resentation of the PHON feature being underspec-ified, it corresponds to any of the appropriatelyconstrained order patterns.
der Fritz dem Frankzu lesen das Buch erlaubt would be ruled out bythe violation of the last LP constraint, der Fritz er-laubt dem Frank das Buch zu lesen by the second,and so on.The reader might be led to think, because of3The lack of this LP requirement also entails somemarginally acceptable instances, such as der Fritz dem Frankdas Buch erlaubt zu lesen, considered ungrammatical bymany.
These instances can be blocked, however, by intro-ducing more complex WOCs.
See Sato (forthcoming a).27??????????????????????????????????????????????????????????????????????????subordinate-clausePHON??
?CONSTITS pv1 ?
pnp1 ?
pnp2 ?
pvpCONSTRS[ADJ adnp1 ?
adnp2 ?
adnp3LP{?pnp1,pv1?,?pnp2,pv1?}?
lpnp1 ?
lpnp2 ?
lpvp]???ARGS?
?HD-DTR v1??????
?verbPHON | CONSTITS pv1{erlaubt}ARGS?np1,np2,vp?WOC[ADJ{}LP{?np1, v1?,?np2, v1?}]???????NHD-DTRs?np1???????????npPHON??????
?CONSTITS pnp1{Fritz, der}CONSTRS???
?ADJ adnp1{?{Fritz},{der}?
}LP lpnp1{?{der},{Fritz}?}??????????
?SYNSEM | ... | CASE Nom???????????,np2???????????npPHON??????
?CONSTITS pnp1{Frank, dem}CONSTRS???
?ADJ adnp2{?{Frank},{der}?
}LP lpnp2{?{der},{Frank}?}??????????
?SYNSEM | ... | CASE Dat???????????,vp???????????????????????????????????vpPHON??
?CONSTITS pvp : pv2 ?
pnp3CONSTRS[ADJ adnp3LP lpvp{?pnp3,pv2?}?
lpnp3]???ARGS?
?HD-DTR v2??????
?vPHON | CONSTITS pv2{zu-lesen}ARGS?np3?WOC[ADJ{}LP{?np3, v2?}]???????NHD-DTRS?np3???????????npPHON??????
?CONSTITS pnp3{Buch,das}CONSTRS???
?ADJ adnp3{?{Buch},{das}?
}LP lpnp3{?{das},{Buch}?}??????????
?SYNSEM | ... | CASE Acc?????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
?Instantiated PHON part of the above:PHON?????????
?CONSTITS{erlaubt, Fritz, der, Frank, dem, zu-lesen, Buch, das}CONSTRS???????ADJ{?{Fritz},{der}?,?{Frank},{dem}?,?{Buch},{das}?}LP??????{Fritz,der},{erlaubt}?,?{Frank,dem},{erlaubt}?,?{der},{Fritz}?,?{dem},{Frank}?,?{das},{Buch}?,?{Buch,das},{zu-lesen}??????????????????????
?Figure 4: An application of Head-Argument Schema28the monotonic inheritance of constraints, that theWOC compliance cannot be checked until thestage of final projection.
While this is generallytrue for freer word order languages consideringvarious scenarios such as bottom-up generation,one can conduct the WOC check immediately afterthe instantiation of relevant categories in parsing,the fact we can exploit in our implementation, aswe will now see.3 Constrained Free Word Order Parsing3.1 AlgorithmIn this section our parsing algorithm that workswith the lexicalised linearisation grammar out-lined above is briefly overviewed.4 It expands ontwo existing ideas: bitmasks for non-CFG parsingand dynamic constraint application.Bitmasks are used to indicate the positions ofa parsed words, wherever they have been found.Reape (1991) presents a non-CFG tabular parsingalgorithm using them, for ?permutation complete?language, which accepts all the permutations anddiscontinuous realisations of words.
To take foran example a simple English NP that comprisesthe, thick and book, this parser accepts not onlytheir 3!
permutations but discontinuous realisa-tions thereof in a longer string, such as [book, -,the, -, thick] (?-?
indicates the positions of con-stituents from other phrases).Clearly, the problem here is overgeneration and(in)efficiency.
In the current form the worst-case complexity will be exponential (O (n!
?2n), n =length of string).
In response, Daniels and Meur-ers (2004) propose to restrict search space dur-ing the parse with two additional bitmasks, pos-itive and negative masks, which encode the bitsthat must be and must not be occupied, respec-tively, based on what has been found thus far andthe relevant word order constraints.
For example,given the constraints that Det precedes Nom andDet must be adjacent to Nom and supposing theparser has found Det in the third position of a fiveword string like above, the negative mask [ x, x,the, -, -] is created, where x indicates the positionthat cannot be occupied by Nom, as well as thepositive mask [ * , das, *, -], where * indicates thepositions that must be occupied by Nom.
Thus,you can stop the parser from searching the posi-tions the categories yet to be found cannot occupy,or force it to search only the positions they have tooccupy.4For full details see Sato (forthcoming b).A remaining important job is to how to state theconstraints themselves in a grammar that workswith this architecture, and Daniels and Meurers?answer is a rather traditional one: stating them inphrase structure rules as LP attachments.
Theymodify HPSG rather extensively in a way simi-lar to GPSG, in what they call ?Generalised ID/LPGrammar?.
However, as we have been arguing,this is not an inevitable move.
It is possible to keepthe general contour of the standard HPSG largelyintact.The way our parser interacts with the grammaris fundamentally different.
We take full advan-tage of the information that now resides in lexi-cal heads.
Firstly, rules are dynamically generatedfrom the subcategorisation information (ARGSfeature) in the head.
Secondly, the constraintsare picked up from the WOC feature when lexicalheads are encountered and carried in edges, elimi-nating the need for positive/negative masks.
Whenan active edge is about to embrace the next cate-gory, these constraints are checked and enforced,limiting the search space thereby.After the lexicon lookup, the parser generatesrules from the found lexical head and forms lexi-cal edges.
It is also at this stage that the WOC ispicked up and pushed into the edge, along with therule generated:?Mum?
Hd-Dtr ?
Nhd1 Nhd2...Nhdn; WOCs?where WOCs is the set of ADJ and LP constraintspicked up, if any.
This edge now tries to find therest ?
non-head daughters.
The following is therepresentation of an edge when the parsing pro-ceeds to the stage where some non-head daughter,in this representation Dtri, has been parsed, andDtrj is to be searched for.?Mum?
Dtr1 Dtr2...Dtri?
Dtrj...Dtrn; WOCs?When Dtrj is found, the parser does not immedi-ately move the dot.
At this point the WOC com-pliance check with the relevant WOC constraint ?the one(s) involving Dtri and Dtrj ?
is conductedon these two daughters.
The compliance check isa simple list operation.
It picks the bitmasks ofthe two daughters in question and checks whetherthe occupied positions of one daughter precede/areadjacent to those of the other.The failure of this check would prevent the dotmove from taking place.
Thus, edges that violatethe word order constraints would not be created,thereby preventing wasteful search.
This is thesame feature as Daniels and Meurers?, and there-fore the efficiency in terms of the number of edgesis identical.
The main difference is that we use29the information inside the feature structure with-out having media like positive/negative masks.3.2 ImplementationI have implemented the algorithm in Prolog andcoded the HPSG feature structure in the way de-scribed using ProFIT (Erbach, 1995).
It is a head-corner, bottom-up chart parser, roughly based onGazdar and Mellish (1989).
The main modifi-cation consists of introducing bitmasks and theword order checking procedure described above.I created small grammars for Japanese and Ger-man and put them to the parser, to confirm thatlinearisation-heavy constructions such as objectcontrol construction can be successfully parsed,with the WOC constraints enforced.4 Future TasksWhat we have seen is an outline of my initial pro-posal and there are numerous tasks yet to be tack-led.
First of all, now that the constraints are writ-ten in individual lexical items, we are in need ofappropriate typing in terms of word order con-straints, in order to be able to state succinctly gen-eral constraints such as the head-final/initial con-straint.
In other words, it is crucial to devise anappropriate type hierarchy.Another potential problem concerns the gen-erality of our theoretical framework.
I have fo-cused on the Head-Argument structure in this pa-per, but if the present theory were to be of gen-eral use, non-argument constructions, such as theHead-Modifier structure, must be accounted for.Also, the cases where the head of a phrase is itselfa phrase may pose a challenge, if such a phrasalhead were to determine the word order of its pro-jection.
Since it is desirable for computationaltransparency not to use emergent constraints, I willattempt to get al the word order constraints ul-timately propagated and monotonically inheritedfrom the lexical level.
Though some word orderconstraints may turn out to have to be written intothe phrasal head directly, I am confident that themajority, if not all, of the constraints can be statedin the lexicon.
These issues are tackled in a sepa-rate paper (Sato, forthcoming a).In terms of efficiency, more study has to be re-quired to identify the exact complexity of my algo-rithm.
Also, with a view to using it for a practicalsystem, an evaluation of the efficiency on the ac-tual machine will be crucial.ReferencesM.
Daniels and D. Meurers.
2004.
GIDLP: A gram-mar format for linearization-based HPSG.
In Pro-ceedings of the HPSG04 Conference.G.
Erbach.
1995.
ProFIT: Prolog with features, in-heritance and templates.
Proceedings of the SeventhConference of the European Association for Compu-tational Linguistics.G.
Gazdar and C. Mellish.
1989.
Natural LanguageProcessing in Prolog.
Addison Wesley.G.
Gazdar, E. Klein, G. Pullum, and I.
Sag.
1985.
Gen-eralized Phrase Structure Grammar.
Harvard UP.E.
Hinrichs and T. Nakazawa.
1990.
Subcategorizationand VP structure in German.
In S. Hughes et al,editor, Proceedings of the Third Symposium on Ger-manic Linguistics.D.
Meurers.
1999.
Raising Spirits (and assigning themcase).
Groninger Arbeiten zur Germanistischen Lin-guistik, Groningen Univ.C.
Pollard and I.
Sag.
1987.
Information-Based Syntaxand Semantics.
CSLI.C.
Pollard and I.
Sag.
1994.
Head-Driven PhraseStructure Grammar.
CSLI.M.
Reape.
1991.
Parsing bounded discontinuousconstituents: Generalisation of some common algo-rithms.
DIANA Report, Edinburgh Univ.M.
Reape.
1993.
A Formal Theory of Word Order.Ph.D.
thesis, Edinburgh University.M.
Reape.
1994.
Domain union and word order vari-ation in German.
In J. Nerbonne et al, editor, Ger-man in Head-Driven Phrase Structure Grammar.F.
Richter and M. Sailer.
1995.
Remarks on lineariza-tion.
Magisterarbeit, T?bingen Univ.Y.
Sato.
2004.
Discontinuous constituency and non-CFG parsing.
http://www.dcs.kcl.ac.uk/pg/satoyo.Y.
Sato.
forthcoming a.
Two alternatives for lexicalistlinearisation grammar: Locality Principle revisited.Y.
Sato.
forthcoming b.
Constrained free word orderparsing for lexicalist grammar.S.
Shieber.
1985.
Evidence against the context free-ness of natural languages.
Linguistics and Philoso-phy, 8(3):333?43.S.
Yatabe.
1996.
Long-distance scrambling via partialcompaction.
In M. Koizumi et al, editor, FormalApproaches to Japanese Linguistics 2.
MIT Press,Cambridge, Mass.30
