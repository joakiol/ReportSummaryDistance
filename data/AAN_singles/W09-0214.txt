Proceedings of the EACL 2009 Workshop on GEMS: GEometical Models of Natural Language Semantics, pages 104?111,Athens, Greece, 31 March 2009. c?2009 Association for Computational LinguisticsSemantic Density Analysis:Comparing word meaning across time and phonetic spaceEyal SagiNorthwestern UniversityEvanston, Illinois, USAeyal@u.northwestern.eduStefan KaufmannNorthwestern UniversityEvanston, Illinois, USAkaufmann@northwestern.eduBrady ClarkNorthwestern UniversityEvanston, Illinois, USAbzack@northwestern.eduAbstractThis paper presents a new statistical methodfor detecting and tracking changes in wordmeaning, based on Latent Semantic Analysis.By comparing the density of semantic vectorclusters this method allows researchers tomake statistical inferences on questions suchas whether the meaning of a word changedacross time or if a phonetic cluster is asso-ciated with a specific meaning.
Possible appli-cations of this method are then illustrated intracing the semantic change of ?dog?, ?do?, and?deer?
in early English and examining andcomparing phonaesthemes.1 IntroductionThe increase in available computing power overthe last few decades has led to an explosion inthe application of statistical methods to the anal-ysis of texts.
Researchers have applied these me-thods to a wide range of tasks, from word-sensedisambiguation (Levin et al, 2006) to the sum-marization of texts (Marcu, 2003) and the auto-matic scoring of student essays (Riedel et al,2006).
However, some fields of linguistics thathave traditionally employed corpora as theirsource material, such as historical semantics,have yet to benefit from the application of thesestatistical methods.In this paper we demonstrate how an existingstatistical tool (Latent Semantic Analysis) can beadapted and used to automate and enhance someaspects of research in historical semantics andother fields whose focus is on the comparativeanalysis of word meanings within a corpus.
Ourmethod allows us to assess the semantic variationwithin the set of individual occurrences of a giv-en word type.
This variation is inversely relatedto a property of types that we call density ?
intui-tively, a tendency to occur in highly similar con-texts.
In terms of our LSA-based spatial semanticmodel, we calculate vectors representing the con-text of each occurrence of a given term, and es-timate the term?s cohesiveness as the densitywith which these token context vectors are?packed?
in space.2 The methodLatent Semantic Analysis (LSA) is a collectiveterm for a family of related methods, all of whichinvolve building numerical representations ofwords based on occurrence patterns in a trainingcorpus.
The basic underlying assumption is thatco-occurrence within the same contexts can beused as a stand-in measure of semantic related-ness (see Firth, 1957; Halliday and Hasan, 1976;Hoey, 1991, for early articulations of this idea).The success of the method in technical applica-tions such as information retrieval and its popu-larity as a research tool in psychology, education,linguistics and other disciplines suggest that thishypothesis holds up well for the purposes ofthose applications.The relevant notion of ?context?
varies.
Thefirst and still widely used implementation of theidea, developed in Information Retrieval andoriginally known as Latent Semantic Indexing(Deerwester et al, 1990), assembles a term-document matrix in which each vocabulary item(term) is associated with an n-dimensional vectorrecording its distribution over the n documents inthe corpus.
In contrast, the version we applied inthis work measures co-occurrence in a way thatis more independent of the characteristics of thedocuments in the training corpus, building in-104stead a term-term matrix associating vocabularyitems with vectors representing their frequencyof co-occurrence with each of a list of ?content-bearing?
words.
This approach originated withthe ?WordSpace?
paradigm developed bySch?tze (1996).
The software we used is a ver-sion of the ?Infomap?
package developed atStanford University and freely available (see alsoTakayama et al, 1999).
We describe it and thesteps we took in our experiments in some detailbelow.2.1 Word vectorsThe information encoded in the co-occurrencematrix, and thus ultimately the similarity meas-ure depends greatly on the genre and subjectmatter of the training corpus (Takayama et al,1999; Kaufmann, 2000).
In our case, we used theentire available corpus as our training corpus.The word types in the training corpus are rankedby frequency of occurrence, and the Infomapsystem automatically selects (i) a vocabulary ?for which vector representations are to be col-lected, and (ii) a set ?
of 1,000 ?content-bearing?words whose occurrence or non-occurrence istaken to be indicative of the subject matter of agiven passage of text.
Usually, these choices areguided by a stoplist of (mostly closed-class) lexi-cal items that are to be excluded, but because wewere interested in tracing changes in the meaningof lexical items we reduced this stoplist to a bareminimum.
To compensate, we increased thenumber of ?content-bearing?
words to 2,000.
Thevocabulary ?
consisted of the 40,000 most fre-quent non-stoplist words.
The set ?
of content-bearing words contained the 50th through 2,049thmost frequent non-stoplist words.
This methodmay seem rather blunt, but it has the advantageof not requiring any human intervention or ante-cedently given information about the domain.The cells in the resulting matrix of 40,000rows and 2,000 columns were filled with co-occurrence counts recording, for eachpair  ?, ?
?
?
?
?, the number of times a tokenof ?
occurred in the context of a token of ?
inthe corpus.1 The ?context?
of a token ??
in our1 Two details are glossed over here: First, the Infomap sys-tem weighs this raw count with a ??.
???
measure of thecolumn label c, calculated as follows: ??.
???
?
= ??
?
????
?
+ 1 ?
???
??
?
where ??
and ??
are the numberof occurrences of ?
and the number of documents in which?
occurs, respectively, and ?
is the total number of docu-ments.
Second, the number in each cell is replaced with itssquare root, in order to approximate a normal distribution ofcounts and attenuate the potentially distorting influence ofimplementation is the set of tokens in a fixed-width window from the 15th item preceding ?
?to the 15th item following it (less if a documentboundary intervenes).
The matrix was trans-formed by Singular Value Decomposition(SVD), whose implementation in the Infomapsystem relies on the SVDPACKC package(Berry, 1992; Berry et al, 1993).
The output wasa reduced 40,000 ?
100 matrix.
Thus each item?
?
?
is associated with a 100-dimensionalvector ?
.2.2 Context vectorsOnce the vector space is obtained from thetraining corpus, vectors can be calculated for anymulti-word unit of text (e.g.
paragraphs, queries,or documents), regardless of whether it occurs inthe original training corpus or not, as the normal-ized sum of the vectors associated with the wordsit contains.
In this way, for each occurrence of atarget word type under investigation, we calcu-lated a context vector from the 15 words preced-ing and the 15 words following that occurrence.Context vectors were first used in Word SenseDiscrimination by Sch?tze (1998).
Similarly tothat application, we assume that these ?second-order?
vectors encode the aggregate meaning, ortopic, of the segment they represent, and thus,following the reasoning behind LSA, areindicative of the meaning with which it is beingused on that particular occurrence.
Consequently,for each target word of interest, the contextvectors associated with its occurrences constitutethe data points.
The analysis is then a matter ofgrouping these data points according to somecriterion (e.g., the period in which the text waswritten) and conducting an appropriate statisticaltest.
In some cases it might also be possible touse regression or apply a clustering analysis.2.3 Semantic Density AnalysisConducting statistical tests comparing groups ofvectors is not trivial.
Fortunately, some questionscan be answered based on the similarity of vec-tors within each group rather than the vectorsthemselves.
The similarity between two vectors?
, ?
is measured as the cosine between them:2high base frequencies (cf.
Takayama, et al 1998; Widdows,2004).2 While the cosine measure is the accepted measure of simi-larity, the cosine function is non-linear and therefore prob-lematic for many statistical methods.
Several transforma-tions can be used to correct this (e.g., Fisher?s z).
In thispaper we will use the angle, in degrees, between the twovectors (i.e., ???
?1) because it is easily interpretable.105???
?
, ?
=?
?
??
?The average similarity of a group of vectors isindicative of its density ?
a dense group of highlysimilar vectors will have a high average cosine(and a correspondingly low average angle)whereas a sparse group of dissimilar vectors willhave an average cosine that approaches zero (anda correspondingly high average angle).3 Thussince a word that has a single, highly restrictedmeaning (e.g.
?palindrome?)
is likely to occur ina very restricted set of contexts, its context vec-tors are also likely to have a low average anglebetween them, compared to a word that is highlypolysemous or appears in a large variety of con-texts (e.g.
?bank?, ?do?).
From this observation, itfollows that it should be possible to compare thecohesiveness of groups of vectors in terms of theaverage pairwise similarity of the vectors ofwhich they are comprised.
Because the numberof such pairings tends to be prohibitively large(e.g., nearly 1,000,000 for a group of 1,000 vec-tors), it is useful to use only a sub-sample in anysingle analysis.
A Monte-Carlo analysis in whichn pair-wise similarity values are chosen at ran-dom from each group of vectors is therefore ap-propriate.4However, there is one final complication toconsider in the analysis.
The passage of time in-fluences not only the meaning of words, but alsostyles and variety of writing.
For example, textsin the 11th century were much less varied, on av-erage, than those written in the 15th century.5This will influence the calculation of contextvectors as those depend, in part, on the text theyare taken from.
Because the document as a wholeis represented by a vector that is the average ofall of its words, it is possible to predict that, if noother factors exist, two contexts are likely to berelated to one another to the same degree thattheir documents are.
Controlling for this effectcan therefore be achieved by subtracting from3Since the cosine ranges from -1 to +1, it is possible inprinciple to obtain negative average cosines.
In practice,however, the overwhelming majority of vocabulary itemshave a non-negative cosine with any given target word,hence the average cosine usually does not fall below zero.4It is important to note that the number of independentsamples in the analysis is determined not by the number ofsimilarity values compared but by the number of individualvectors used in the analysis.5 Tracking changes in the distribution of the documentvectors in a corpus over time might itself be of interest tosome researchers but is beyond the scope of the currentpaper.the angle between two context vectors the anglebetween the documents in which they appear.3 Applications to Research3.1 A Diachronic Investigation: SemanticChangeOne of the central questions of historical seman-tics is the following (Traugott, 1999):6Given the form-meaning pair ?
(lexeme) whatchanges did meaning ?
undergo?For example, the form as long as underwentthe change `equal in length?
> `equal in time?
>`provided that?.
Evidence for semantic changecomes from written records, cognates, and struc-tural analysis (Bloomfield, 1933).
Traditionalcategories of semantic change include (Traugott,2005: 2-4; Campbell, 2004:254-262; Forston,2003: 648-650):?
Broadening (generalization, extension,borrowing): A restricted meaning becomes lessrestricted (e.g.
Late Old English docga `a (spe-cific) powerful breed of dog?
> dog `any memberof the species Canis familiaris??
Narrowing (specialization, restriction): Arelatively general meaning becomes more specif-ic (e.g.
Old English deor `animal?
> deer)?
Pejoration (degeneration): A meaning be-comes more negative (e.g.
Old English s?lig`blessed, blissful?
> sely `happy, innocent, pitia-ble?
> silly `foolish, stupid?
)Semantic change results from the use of lan-guage in context, whether linguistic or extralin-guistic.
Later meanings of forms are connected toearlier ones, where all semantic change arises bypolysemy, i.e.
new meanings coexist with earlierones, typically in restricted contexts.
Sometimesnew meanings split off from earlier ones and areno longer considered variants by language users(e.g.
mistress `woman in a position of authority,head of household?
> `woman in a continuingextra-marital relationship with a man?
).Semantic change is often considered unsyste-matic (Hock and Joseph, 1996: 252).
However,recent work (Traugott and Dasher, 2002) sug-gests that there is, in fact, significant cross-linguistic regularity in semantic change.
For ex-6 This is the semasiological perspective on semantic change.Other perspectives include the onomasiological perspective(?Given the concept ?, what lexemes can it be expressedby??).
See Traugott 1999 for discussion.106ample, in the Invited Inferencing Model of Se-mantic Change proposed by Traugott and Dasher(2002) the main mechanism of semantic changeis argued to be the semanticization of conversa-tional implicatures, where conversational impli-catures are a component of speaker meaning thatarises from the interaction between what thespeaker says and rational principles of communi-cation (Grice, 1989 [1975]).
Conversational im-plicatures are suggested by an utterance but notentailed.
For example, the utterance Some stu-dents came to the party strongly suggests thatsome but not all students came to the party, eventhough the utterance would be true strictly speak-ing if all students came to the party.
According tothe Invited Inferencing Model, conversationalimplicatures become part of the semantic poly-semies of particular forms over time.Such changes in meaning should be evidentwhen examining the contexts in which the lex-eme of interest appears.
In other words, changesin the meaning of a type should translate to dif-ferences in the contexts in which its tokens areused.
For instance, semantic broadening resultsin a meaning that is less restricted and as a resultcan be used in a larger variety of contexts.
In asemantic space that encompasses the period ofsuch a change, this increase in variety can bemeasured as a decrease in vector density acrossthe time span of the corpus.
This decrease trans-lates into an increase in the average angle be-tween the context vectors for the word.
For in-stance, because the Old English word ?docga?applied to a specific breed of dog, we predictedthat earlier occurrences of the lexemes ?docga?and ?dog?, in a corpus of documents of the ap-propriate time period, will show less variety thanlater occurrences.An even more extreme case of semantic broa-dening is predicted to occur as part of the processof grammaticalization (Traugot and Dasher,2002) in which a content word becomes a func-tion word.
Because, as a general rule, a functionword can be used in a much larger variety ofcontexts than a content word, a word that under-went grammaticalization should appear in a sub-stantially larger variety of contexts than it didprior to becoming a function word.
One well stu-died case of grammaticalization is that of periph-rastic ?do?.
While in Old English ?do?
was usedas a verb with a causative and habitual sense(e.g.
?do you harm?
), later in English it took on afunctional role that is nearly devoid of meaning(e.g.
?do you know him??).
Because this changeoccurred in Middle English, we predicted thatearlier occurrences of ?do?
will show less varietythan later ones.In contrast with broadening, semantic narrow-ing results in a meaning that is more restricted,and is therefore applicable in fewer contexts thanbefore.
This decrease in variety results in an in-crease in vector density and can be directlymeasured as a decrease in the average angle be-tween the context vectors for the word.
As anexample, the Old English word ?deor?
denoted alarger group of living creatures than does theModern English word ?deer?.
We therefore pre-dicted that earlier occurrences of the lexemes?deor?
and ?deer?, in a corpus of the appropriatetime period, will show more variety than lateroccurrences.We tested our predictions using a corpus de-rived from the Helsinki corpus (Rissanen, 1994).The Helsinki corpus is comprised of texts span-ning the periods of Old English (prior to1150A.D.
), Middle English (1150-1500A.D.
),and Early Modern English (1500-1710A.D.
).Because spelling in Old English was highly vari-able, we decided to exclude that part of the cor-pus and focused our analysis on the Middle Eng-lish and Early Modern English periods.
The re-sulting corpus included 504 distinct documentstotaling approximately 1.1 million words.To test our predictions regarding semanticchange in the words ?dog?, ?do?, and ?deer?, wecollected all of the contexts in which they appearin our subset of the Helsinki corpus.
This re-sulted in 112 contexts for ?dog?, 4298 contextsfor ?do?, and 61 contexts for ?deer?.
Becausethere were relatively few occurrences of ?dog?Table 1 - Mean angle between context vectors for target words in different periods in the Helsinkicorpus (standard deviations are given in parenthesis)nUnknown composi-tion date(<1250)Early MiddleEnglish(1150-1350)Late MiddleEnglish(1350-1500)Early ModernEnglish(1500-1710)dog 112   15.47 (14.19) 24.73(10.43)do 4298  10.31(13.57) 13.02 (9.50) 24.54 (11.2)deer 61 38.72 (17.59) 20.6 (18.18)  20.5 (9.82)science 79   13.56 (13.33) 28.31 (12.24)107and ?deer?
in the corpus it was practical to com-pute the angles between all possible pairs of con-text vectors.
As a result, we elected to forgo theMonte-Carlo analysis for those two words in fa-vor of a full analysis.
The results of our analysisfor all three words are given in Table 1.
Theseresults were congruent with our prediction: Thedensity of the contexts decreases over time forboth ?dog?
(t(110) = 2.17, p < .05) and ?do?
(F(2,2997)=409.41, p < .01) while in the case of?deer?
there is an increase in the density of thecontexts over time (t(36) = 3.05, p < .01).Furthermore, our analysis corresponds withthe data collected by Elleg?rd (1953).
Elleg?rdtraced the grammaticalization of ?do?
by manual-ly examining changes in the proportions of itsvarious uses between 1400 and 1700.
His dataidentifies an overall shift in the pattern of usethat occurred mainly between 1475 and 1575.Our analysis identifies a similar shift in patternsbetween the time periods spanning 1350-1500and 1500-1570.
Figure 1 depicts an overlay ofboth datasets.
The relative scale of the two setswas set so that the proportions of ?do?
uses at1400 and 1700 (the beginning and end of El-leg?rd?s data, respectively) match the semanticdensity measured by our method at those times.Finally, our method can be used not only totest predictions based on established cases ofsemantic change, but also to identify new ones.For instance, in examining the contexts of theword ?science?
we can identify that it underwentsemantic broadening shortly after it first ap-peared in the 14th century (t(77) = 4.51, p < .01).A subsequent examination of the contexts inwhich the word appears indicated that this isprobably the result of a shift from a meaning re-lated to generalized knowledge (e.g., ?
?andlearn science of school?, John of Trevisa's Polyc-hronicon, 1387) to one that can also be used torefer to more specific disciplines (e.g., ?
?of theseven liberal sciences?, Simon Forman?s Diary,1602).Our long term goal with respect to this type ofanalysis is to use this method in a computer-based tool that can scan a diachronic corpus andautomatically identify probable cases of semanticchange within it.
Researchers can then use theseresults to focus on identifying the specifics ofsuch changes, as well as examine the overall pat-terns of change that exist in the corpus.
It is ourbelief that such a use will enable a more rigoroustesting and refinement of existing theories of se-mantic change.3.2 A Synchronic Investigation: Phonaes-themesIn addition to examining changes in meaningacross time, it is also possible to employ our me-thod to examine how the semantic space relatesto other possible partitioning of the lexemesrepresented by it.
For instance, while the rela-tionship between the phonetic representation andsemantic content is largely considered to be arbi-trary, there are some notable exceptions.
Oneinteresting case is that of phonaesthemes (Firth,1930), sub-morphemic units that have a predict-able effect on the meaning of the word as awhole.
In English, one of the more frequentlymentioned phonaesthemes is a word-initial gl-which is common in words related to the visualmodality (e.g., ?glance?, ?gleam?).
While therehave been some scholastic explorations of thesenon-morphological relationships between soundand meaning, they have not been thoroughly ex-plored by behavioral and computational research(with some notable exceptions; e.g.
Hutchins,1998; Bergen, 2004).
Recently, Otis and Sagi(2008) used the semantic density of the cluster ofwords sharing a phonaestheme as a measure of103050701020301200 1300 1400 1500 1600 1700%ofperiphrastic?do?
uses(Elleg?rd, 1953)MeanAnglebetweenvectors(currentstudy)YearCurrent Study Ellegard's dataFigure 1 ?
A comparison of the rise of periphrastic 'do' as measured by semantic density in our study andthe proportion of periphrastic 'do' uses by Elleg?rd (1953).108the strength of the relationship between the pho-netic cluster and its proposed meaning.Otis and Sagi used a corpus derived fromProject Gutenberg (http://www.gutenberg.org/)as the basis for their analysis.
Specifically, theyused the bulk of the English language literaryworks available through the project?s website.This resulted in a corpus of 4034 separate docu-ments consisting of over 290 million words.The bulk of the candidate phonaesthemes theytested were taken from the list used by Hutchins(1998), with the addition of two candidate pho-naesthemes (kn- and -ign).
Two letter combina-tions that were considered unlikely to be pho-naesthemes (br- and z-) were also included inorder to test the method?s capacity for discrimi-nating between phonaesthemes and non-phonaesthemes.
Overall Otis and Sagi (2008)examined 47 possible phonaesthemes.In cases where a phonetic cluster represents aphonaestheme, it intuitively follows that pairs ofwords sharing that phonetic cluster are morelikely to share some aspect of their meaning thanpairs of words chosen at random.
Otis and Sagitested whether this was true for any specific can-didate phonaestheme using a Monte-Carlo analy-sis.
First they identified all of the words in thecorpus sharing a conjectured phonaestheme7 andchose the most frequent representative wordform for each stem, resulting in a cluster of wordtypes representing each candidate phonaes-theme.8 Next they tested the statistical signific-ance of this relationship by running 100 t-testcomparisons.
Each of these tests compared therelationship of 50 pairs of words chosen at ran-dom from the conjectured cluster with 50 pairs ofwords chosen at random from a similarly sizedcluster, randomly generated from the entire cor-pus.
The number of times these t-tests resulted ina statistically significant difference (?
= .05) wasrecorded.
This analysis was repeated 3 times foreach conjectured phonaestheme and the medianvalue was used as the final result.To determine whether a conjectured phonaes-theme was statistically supported by their analy-sis Otis and Sagi compared the overall frequency7 It is important to note that due to the nature of a writtencorpus, the match was orthographical rather than phonetic.However, in most cases the two are highly congruent.8 Because, in this case, Otis and Sagi were not interested intemporal changes in meaning, they used the overall wordvectors rather than look at each context individually.
As aresult, each of the vectors used in the analysis is based onoccurrences in many different documents and there was noneed to control for the variability of the documents.of statistically significant t-tests with the binomi-al distribution for their ?
(.05).
After applying aBonferroni correction for performing 50 compar-isons, the threshold for statistical significance ofthe binomial test was for 14 t-tests out of 100 toturn out as significant, with a frequency of 13being marginally significant.
Therefore, if thesignificance frequency (#Sig below) of a candi-date phonaestheme was 15 or higher, that pho-naestheme was judged as being supported bystatistical evidence.
Significance frequencies of13 and 14 were considered as indicative of aphonaestheme for which there was only marginalstatistical support.Among Hutchins?
original list of 44 possiblephonaesthemes, 26 were found to be statisticallyreliable and 2 were marginally reliable.
Overallthe results were in line with the empirical datacollected by Hutchins.
By way of comparing thetwo datasets, #Sig and Hutchins?
average ratingmeasure were well correlated (r = .53).
Neitherof the unlikely phonaestheme candidates we ex-amined were statistically supported phonaes-themes (#Sigbr- = 6; #Sigz- = 5), whereas both ofour newly hypothesized phonaesthemes werestatistically supported (#Sigkn- = 28; #Sig-ign =23).
In addition to being able to use this measureas a decision criterion as to whether a specificphonetic cluster might be phonaesthemic, it canalso be used to compare the relative strength oftwo such clusters.
For instance, in the Gutenbergcorpus the phonaesthemic ending ?owl (e.g.,?growl?, ?howl?
; #Sig=97) was comprised of acluster of words that were more similar to oneanother than ?oop (e.g., ?hoop?, ?loop?
; #Sig=32).Such results can then be used to test the cogni-tive effects of phonaesthemes.
For instance, fol-lowing the comparison above, we might hypo-thesize that the word ?growl?
might be a bettersemantic prime for ?howl?
than the word ?hoop?is for the word ?loop?.
In contrast, because aword-initial br- is not phonaesthemic, the word?breeze?
is unlikely to be a semantic prime forthe word ?brick?.
In addition, it might be interest-ing to combine the diachronic analysis from theprevious section with the synchronic analysis inthis section to investigate questions such as whenand how phonaesthemes come to be part of alanguage and what factors might affect thestrength of a phonaestheme.4 DiscussionWhile the method presented in this paper isaimed towards quantifying semantic relation-109ships that were previously difficult to quantify, italso raises an interesting theoretical issue, name-ly the relationship between the statistically com-puted semantic space and the actual semanticcontent of words.
On the one hand, simulationsbased on Latent Semantic Analysis have beenshown to correlate with cognitive factors such asthe acquisition of vocabulary and the categoriza-tion of texts (cf.
Landauer & Dumais, 1997).
Onthe other hand, in reality speakers?
use of lan-guage relies on more than simple patterns ofword co-occurrence ?
For instance, we use syn-tactic structures and pragmatic reasoning to sup-plement the meaning of the individual lexemeswe come across (e.g., Fodor, 1995; Grice, 1989[1975]).
It is therefore likely that while LSA cap-tures some of the variability in meaning exhi-bited by words in context, it does not capture allof it.
Indeed, there is a growing body of methodsthat propose to integrate these two disparatesources of linguistic information (e.g., Pado andLapata, 2007; Widdows, 2003)Certainly, the results reported in this papersuggest that enough of the meaning of words andcontexts is captured to allow interesting infe-rences about semantic change and the relatednessof words to be drawn with a reasonable degree ofcertainty.
However, it is possible that some im-portant aspects of meaning are systematicallyignored by the analysis.
For instance, it remainsto be seen whether this method can distinguishbetween processes like pejoration and amerliora-tion as they require a fine grained distinction be-tween ?good?
and ?bad?
meanings.Regardless of any such limitations, it is clearthat important information about meaning can begathered through a systematic analysis of thecontexts in which words appear.
Furthermore,phenomena such as the existence of phonaes-themes and the success of LSA in predicting vo-cabulary acquisition rates, suggest that the acqui-sition of new vocabulary involves the gleaning ofthe meaning of words through their context.
Therole of context in semantic change is thereforelikely to be an active one ?
when a listener en-counters a word they are unfamiliar with they arelikely to use the context in which it appears, aswell as its phonetic composition, as clues to itsmeaning.
Furthermore, if a word is likewise en-countered in context in which it is unlikely, thisunexpected observation may induce the listenerto adjust their representation of both the contextand the word in order to increase the overall co-herence of the utterance or sentence.
As a result,it is possible that examining the contexts inwhich a word is used in different documents andtime periods might be useful not only as a toolfor examining the history of a semantic changebut also as an instrument for predicting its futureprogress.
Overall, this suggests a dynamic viewof the field of semantics ?
semantics as an ever-changing landscape of meaning.
In such a view,semantic change is the norm as the perceivedmeaning of words keeps shifting to accommo-date the contexts in which they are used.ReferencesBergen, B.
(2004).
The Psychological Reality ofPhonaesthemes.
Language, 80(2), 291-311.Berry, M. W. (1992) SVDPACK: A Fortran-77software library for the sparse singular valuedecomposition.
Tech.
Rep. CS-92-159, Knox-ville, TN: University of Tennessee.Berry, M. W., Do, T., O?Brien, G. Vijay, K. Va-radh an, S. (1993) SVDPACKC (Version 1.0)User?s Guide, Tech.
Rep. UT-CS-93-194,Knoxville, TN: University of Tennessee.Bloomfield, L. (1933).
Language.
New York,NY: Holt, Rinehart and Winston.Campbell, L. (2004) Historical linguistics: Anintroduction 2nd ed.
Cambridge, MA: The MITPress.Deerwester, S., Dumais, S. T., Furnas, G. W.,Landauer, T. K., and Harshman, R. (1990) In-dexing by Latent Semantic Analysis.
Journalof the American Society for InformationScience, 41, 391-407.Elleg?rd, A.
(1953) The Auxiliary Do: the Estab-lishment and Regulation of its Use in English.Gothenburg Studies in English, 2.
Stockholm:Almqvist and Wiksell.Firth, J.
(1930) Speech.
London: Oxford Univer-sity Press.Firth, J.
(1957) Papers in Linguistics, 1934-1951,Oxford University Press.Fodor, J. D. (1995) Comprehending sentencestructure.
In L. R. Gleitman and M.
Liberman,(Eds.
), Invitation to Cognitive Science, volume1.
MIT Press, Cambridge, MA.
209-246.Forston, B. W. (2003) An Approach to SemanticChange.
In B. D. Joseph and R. D.
Janda(Eds.
), The Handbook of Historical Linguis-tics.
Malden, MA: Blackwell Publishing.
648-666.110Grice, H. P. (1989) [1975].
Logic and Conversa-tion.
In Studies in the Way of Words.
Cam-bridge, MA: Harvard University Press.
22-40.Halliday, M. A. K., & Hasan, R. (1976) Cohe-sion in English.
London: Longman.Hock, H. H., and Joseph, B. D. (1996) LanguageHistory, Language Change, and Language Re-lationship: An Introduction to Historical andComparative Linguistics.
Berlin: Mouton deGruyter.Hoey, M. (1991) Patterns of Lexis in Text.
Lon-don: Oxford University Press.Hutchins, S. S. (1998).
The psychological reality,variability, and compositionality of Englishphonesthemes.
Dissertation Abstracts Interna-tional, 59(08), 4500B.
(University MicrofilmsNo.
AAT 9901857).Infomap [Computer Software].
(2007).http://infomap-nlp.sourceforge.net/ Stanford,CA.Kaufmann, S. (2000) Second-order cohesion.Computational Intelligence.
16, 511-524.Landauer, T. K., & Dumais, S. T. (1997).
A solu-tion to Plato's problem: The Latent SemanticAnalysis theory of the acquisition, induction,and representation of knowledge.
Psychologi-cal Review, 104, 211-240.Levin, E., Sharifi, M., & Ball, J.
(2006) Evalua-tion of utility of LSA for word sense discrimi-nation.
In Proceedings of the Human Lan-guage Technology Conference of the NAACL,Companion Volume: Short Papers, New YorkCity.
77-80.Marcu, D (2003) Automatic Abstracting, Encyc-lopedia of Library and Information Science,Drake, M. A., ed.
245-256.Otis K., & Sagi E. (2008) Phonaesthemes: ACorpora-based Analysis.
In B. C. Love, K.McRae, & V. M. Sloutsky (Eds.
), Proceedingsof the 30th Annual Conference of the CognitiveScience Society.
Austin, TX: CognitiveScience Society.Pado, S. & Lapata, M. (2007) Dependency-basedConstruction of Semantic Space Models.Computational Linguistics, 33, 161-199.Riedel E., Dexter S. L., Scharber C., Doering A.
(2006) Experimental Evidence on the Effec-tiveness of Automated Essay Scoring inTeacher Education Cases.
Journal of Educa-tional Computing Research, 35, 267-287.Rissanen, M. (1994) The Helsinki Corpus ofEnglish Texts.
In Kyt?, M., Rissanen, M. andWright S. (eds), Corpora Across the Centu-ries: Proceedings of the First InternationalColloquium on English Diachronic Corpora.Amsterdam: Rodopi.Sch?tze, H. (1996) Ambiguity in language learn-ing: computational and cognitive models.
CA:Stanford.Sch?tze, H. (1998) Automatic word sense dis-crimination.
Computational Linguistics24(1):97-124.Takayama, Y., Flournoy R., & Kaufmann, S.(1998) Information Mapping: Concept-BasedInformation Retrieval Based on WordAssociations.
CSLI Tech Report.
CA:Stanford.Takayama, Y., Flournoy, R., Kaufmann, S. &Peters, S. (1999).
Information retrieval basedon domain-specific word associations.
In Cer-cone, N. and Naruedomkul K.
(eds.
), Proceed-ings of the Pacific Association for Computa-tional Linguistics (PACLING?99), Waterloo,Canada.
155-161.Traugott, E. C. (1999) The Role of Pragmatics inSemantic Change.
In J. Verschueren (ed.
),Pragmatics in 1998:  Selected Papers from the6th International Pragmatics Conference, vol.II.
Antwerp: International Pragmatics Associa-tion.
93-102.Traugott, E. C. (2005) Semantic Change.
In En-cyclopedia of Language and Linguistics, 2nded., Brown K. ed.
Oxford: Elsevier.Traugott, E. C., and Dasher R. B.
(2002) Regu-larity in Semantic Change.
Cambridge: Cam-bridge University Press.Widdows, D. (2003) Unsupervised methods fordeveloping taxonomies by combining syntacticand statistical information.
In Proceedings ofthe joint Human Language Technology Confe-rence and Annual Meeting of the North Ameri-can Chapter of the Association for Computa-tional Linguistics.
Edmonton, Canada:Wiemer-Hastings.
197-204.Widdows, D. (2004) Geometry and Meaning.CSLI Publications, CA: Stanford.111
