Script Independent Word Spotting in Multilingual DocumentsAnurag Bhardwaj, Damien Jose and Venu GovindarajuCenter for Unified Biometrics and Sensors (CUBS)University at Buffalo, State University of New YorkAmherst, New York 14228{ab94,dsjose,govind}@cedar.buffalo.eduAbstractThis paper describes a method for script independentword spotting in multilingual handwritten and machineprinted documents.
The system accepts a query in theform of text from the user and returns a ranked list of wordimages from document image corpus based on similaritywith the query word.
The system is divided into two maincomponents.
The first component known as Indexer, per-forms indexing of all word images present in the documentimage corpus.
This is achieved by extracting MomentBased features from word images and storing them as in-dex.
A template is generated for keyword spotting whichstores the mapping of a keyword string to its correspond-ing word image which is used for generating query fea-ture vector.
The second component, Similarity Matcher,returns a ranked list of word images which are most sim-ilar to the query based on a cosine similarity metric.
Amanual Relevance feedback is applied based on Rocchio?sformula, which re-formulates the query vector to returnan improved ranked listing of word images.
The perfor-mance of the system is seen to be superior on printed textthan on handwritten text.
Experiments are reported ondocuments of three different languages: English, Hindiand Sanskrit.
For handwritten English, an average pre-cision of 67% was obtained for 30 query words.
For ma-chine printed Hindi, an average precision of 71% was ob-tained for 75 query words and for Sanskrit, an averageprecision of 87% with 100 queries was obtained.Figure 1: A Sample English Document - Spotted Queryword shown in the bounding box.1 IntroductionThe vast amount of information available in the form ofhandwritten and printed text in different languages posesa great challenge to the task of effective information ex-traction.
Research in this area has primarily focussed onOCR based solutions which are adequate for Roman Lan-guage (A sample English document is shown in Figure 1).However efficient solutions do not exist for scripts likeDevanagari.
One of the main reasons for this is lack ofgeneralisation.
OCR solutions tend to be specific to scripttype.
Ongoing research continues to scale these methodsto different types and font sizes.
Furthermore, non-Latinscripts exhibit complex character classes (like in the San-skrit document shown in Figure 2) and poor quality doc-uments are common.The notion of Word spotting [6] has been introducedas an alternative to OCR based solutions.
It can be de-fined as an information retrieval task that finds all oc-curences of a typed query word in a set of handwritten1Figure 2: A Sample Sanskrit Document - Spotted Queryword shown in the bounding box.or machine printed documents.
While spotting words inEnglish has been explored [3, 5, 4, 7, 11], generalisingthese approaches to multiple scripts is still an ongoing re-search task.
Harish et.al [1] describe a ?Gradient, Struc-tural, Concavity?
(GSC) based feature set for word spot-ting in multiple scripts.
However, they do not report theaverage precision rate for all queries in their experimen-tal results which makes it difficult to estimate the perfor-mance of their methodology.One important factor in finding a script independentsolution to word spotting is use of image based featureswhich are invariant to script type, image scale and trans-lations.
This paper proposes the use of moment basedfeatures for spotting word images in different scripts.We describe a moment-function based feature extractionscheme and use the standard vector space model to repre-sent the word images.
Similarity between the query fea-ture vector and the indexed feature set is computed usinga cosine similarity metric.
We also apply the Rocchio for-mula based Manual Relevance feedback to improve theranking of results obtained.
We evaluate the performanceof our system by conducting experiments on documentimages of three different scripts: English, Hindi and San-skrit.The organization of the rest of the paper is as fol-lows: Section 2 describes the previous work.
Section 3describes the theory of moment functions.
Section 4 de-scribes indexing word images and feature extraction.
Sec-tion 5 describes the Similarity Matching and RelevanceFeedback method applied to re-rank results.
Section 6describes the experiments and results.
Future work andconclusions are outlined in Section 7.2 Previous WorkSpotting words in English has recently received consider-able attention.
Manmatha et al [7], have proposed a com-bination of feature sets well suited for this application.For finding similarity between a query word image andthe document word image, Dynamic Time warping [8] iscommonly used.
Although the approach has been promis-ing with English handwritten documents, it does not gen-eralise well across scripts.
For eg., presence of Shirorekhain Devanagari script (an example shown in Figure 3) ren-ders most of the profile based features ineffective.
Also,DTW based approaches are slow.
Approaches which usea filter based feature set [2], are efficient with uniform fontsize and type but are not able to handle font variations andtranslations.Harish et al [1] use a Gradient, Structural and Concav-ity (GSC) feature set which measures the image character-istics at local, intermediate and large scales.
Features areextracted using a 4x8 sampling window to gather informa-tion locally.
Since character segmentation points are notperfectly located, local information about stroke orienta-tion and image gradient is not sufficient to characterizethe change in font scale and type.
Moreover, presence ofnoise in small regions of the word image lead to inconsis-tency in the overall feature extraction process.
The per-formance of their approach is presented in terms of per-centage of the number of times the correct match was re-turned, which does not capture the recall rate of system.For English word spotting, their results do not state thesize of the dataset and precision recall values have beenreported for only 4 query words.
For Sanskrit word spot-ting, the total number of query words is not mentionedwhich makes understanding of precision recall curve dif-ficult.
A comparison of their results against our proposedmethod is presented in section 6.3 Moment FunctionsMoments and functions of moments have been previouslyused to achieve an invariant representation of a two-dimensional image pattern [9].
Geometrical momentsFigure 3: A Sample Hindi Document - Spotted Querywords shown in the bounding box.
[9] have the desirable property of being invariant underthe image translation, scale and stretching and squeezingin either X or Y direction.
Mathematically, such affinetransformations are of the form of X?
= aX + b , andY ?
= cY + d [10].
Geometrical Moments (GM) oforder (p+ q) for a continuous image function f(x, y) aredefined as :Mpq =?
????
??
?xpyqf(x, y) dx dy (1)where p, q = 0, 1, 2, ...,?.
The above definition hasthe form of the projection of the function f(x, y) ontothe mononomial xpyq .
In our case, where the functionf(x, y) has only two possible values of 0 and 1, theequation 1 reduces to :Mpq =?X?Yxpyqf(x, y) (2)where X and Y represent x, y coordinates of the image.The center of gravity of the image has the coordinates :x?
= M10M00, y?
= M01M00, (3)If we refer to the center of gravity as origin, we obtain :M?pq =?X?Y(x?
x?
)p(y ?
y?
)qf(x, y) (4)These moments are also referred to as Central Momentsand can be expressed as a linear combination of Mjkand the moments of lower order.
The variances of themoment are defined as :?x =?M?20M00, ?y =?M?02M00, (5)4 6 8 10 12 14 160.70.720.740.760.780.80.820.840.86Moment OrderAvgPrec.Avg.
Precision Vs Moment OrderFigure 4: Average Precision curve Vs Moment Order fora Hindi Image Subset.They are used to normalise the coordinates by setting:x?
= (x?
x?
)?x, y?
= (y ?
y?
)?y, (6)Using the normalised values of coordinates as obtainedin equation 6 , the moment equation is as follows :mpq =?X?Y (x?)p(y?
)qf(x, y)M00(7)which is invariant under image translation and scale trans-formations.4 Feature Extraction and IndexingFeature extraction is preceeded by preprocessing of doc-uments prior to computing moment based functions.Firstly, the Horizontal Profile feature of the document im-age is used to segment into line images.
Thereafter, Ver-tical Profile features of each line image is used to extractindividual word images.
The word images are normalisedto equal height and width of 256 pixels.Using equation 7, moments up to the 7th order areextracted from the normalised word images.
A featurevector consisting of 30 moment values obtained is con-structed for each word image and stored in the main in-dex.
Experiments were conducted to determine the num-ber of orders up to which moments should be computed.As shown in Figure 4, average precision increases withthe rise in moment orders ( up to a threshold of 7 orders ),after which the precision rate falls.
This can be attributedto the nature of higher order Geometrical Moments whichare prone to adding noise in the feature set and thereby re-duce the overall precision after a certain threshold.
Afterthe index has been constructed using the moment features,we create a template which keeps the mapping between aword image and its corresponding text.
This template isused to generate a query word image corresponding to thequery text input by the user.
A similar feature extractionmechanism is performed on the query word image to ob-tain a query feature vector which is used to find the sim-ilarity between the query word image and all other wordimages present in the corpus.5 Similarity Matching and Rele-vance Feedback5.1 Cosine SimilarityA standard Vector Space Model is used represent thequery word and all the candidate words.
The index ismaintained in the form of a word-feature matrix, whereeach word image ?w occupies one row of the matrix andall columns in a single row correspond to the momentvalues computed for the given word image.When the user enters any query word, a lookup oper-ation is performed in the stored template to obtain thecorresponding normalised word image for the input text.Feature extraction is performed on the word image toconstruct the query feature vector?q.
A cosine similarityscore is computed for this query feature vector and all therows of the word-feature matrix.
The cosine similarity iscalculated as follows:SIM(q, w) =?q .
?w|?q | ?
| ?w |(8)All the words of the document corpus are then rankedaccording to the cosine similarity score.
The top choicereturned by the ranking mechanism represents the wordimage which is most similar to the input query word.5.2 Relevance FeedbackSince the word images present in the document corpusmay be of poor print quality and may contain noise, themoment features computed may not be effective in rank-ing relevant word images higher in the obtained result.Also the presence of higher order moments may leadto inconsistency in the overall ranking of word images.To overcome this limitation, we have implemented aRocchio?s formula based manual Relevance Feedbackmechanism.
This mechanism re-formulates the queryfeature vector by adjusting the values of the individualmoment orders present in the query vector.
The relevancefeedback mechanism assumes a user input after thepresentation of the initial results.
A user enters either a1 denoting a result to be relevant or 0 denoting a resultto be irrelevant.
The new query vector is computed asfollows:qnew = ?.qold +?|R| .i=R?i=1di ?
?|NR| .j=NR?j=1dj (9)where ?
, ?
and ?
are term re-weighting constants.
R de-notes a relevant result set and NR denotes a non-relevantresult set.
For this experiment, we chose ?
= 1 , ?
= 0.75and ?
= 0.25.6 Experiments and ResultsThe moment based features seem more robust in handlingdifferent image transformations compared to commonlyused feature sets for word spotting such as GSC features[1] and Gabor filter based features [2].
This can be ob-seerved in Figure 5.
The first row of the image corre-sponds to different types of transformations applied tonormal English handwritten word images ((a)) such aschanging the image scale as in (b) or (c).
The second rowcorresponds to linear ((f)) and scale transformation ((e)),when applied to the normal machine printed Hindi wordimage ((d)).
Even after undergoing such transformations,the cosine similarity score between the moment featuresextracted from all image pairs is still close to 1, which re-flects the strength of invariance of moment based featureswith respect to image transformations.
Table 1 shows thecosine similarity score between all pairs of English word(a) (b) (c)(d) (e) (f)Figure 5: Various forms of Image Transformations.
(a) &(d) Sample Word Image .
(b),(c) & (e) Scale Transforma-tion Examples (f) Linear Transformation Example .Table 1: Cosine Similarity Score for English TransformedWord Image Pairs.Word Image Pair (a) (b) (c)(a) 1 0.9867 0.9932(b) 0.9867 1 0.9467(c) 0.9932 0.9467 1images.
Table 2 shows the similarity score between allpairs of hindi word images.The data set for evaluating our methodology consistsof documents in three scripts, namely English, Hindi andSanskrit.
For English, we used publicly available IAMdb[13] handwritten word images and word images extractedfrom George Washington?s publicly available historicalmanuscripts [14].
The dataset for English consists of707 word images.
For Hindi, 763 word images were ex-tracted from publicly available Million Book Project doc-uments [12].
For Sanskrit, 693 word images were ex-tracted from 5 Sanskrit documents downloaded from theURL: http://sanskrit.gde.to/ .
For public testing and eval-uation, we have also made our dataset available at the lo-cation: http://cubs.buffalo.edu/ilt/dataset/.For evaluating the system performance, we use thecommonly used Average Precision Metric.
Precision forTable 2: Cosine Similarity Score for Hindi TransformedWord Image Pairs.Word Image Pair (d) (e) (f)(d) 1 0.9662 0.9312(e) 0.9662 1 0.9184(f) 0.9312 0.9184 11 2 3 4 5 6 7 80.20.30.40.50.60.70.80.91QueryAvgPrecisionAverage Precision Curve for few QueriesFigure 6: Average Precision curve for English Word Spot-ting.0 10 20 30 40 50 600.30.40.50.60.70.80.91QueriesAveragePrecisionAvg.
Precision for few QueriesFigure 7: Average Precision curve for Hindi Word Spot-ting.0 10 20 30 40 50 60 70 80 90 1000.20.30.40.50.60.70.80.91QueriesAveragePrecisionAvg Precision for few QueriesFigure 8: Average Precision curve for Sanskrit WordSpotting.each query image was calculated at every recall level,and then averaged over to give an Average Precision perquery.
Figure 6 shows the average precision values forsome query words in English.
Figure 7 shows the averageprecision values for query words in Hindi.
Figure 8 showsthe average precision values for query words in Sanskrit.The experimental results for all three scripts are sum-marised in Table 3.
The Average Precision rates as shownin the table have been averaged over 30 queries in En-glish, 75 queries in Hindi and 100 queries in Sanskrit.
Asshown here, the system works better for machine printedtext (71.18 and 87.88) as compared to handwritten (67.0).The best performance is seen with Sanskrit script (87.88),which has a variable length words allowing it to be morediscriminative in its feature analysis as compared to othertwo scripts.
Table 4 compares the performance of GSCbased word spotting as reported in [1] against our method-ology.
At 50% recall level, Moment based features per-form better than GSC based features for both handwrittenEnglish and machine printed Sanskrit documents.We also evaluate the performance of Gabor Featurebased word spotting method [2] on our dataset.
Featuresare extracted using an array of Gabor filters having a scalefrom 4 pixels to 6 pixels and 8 orientations.
Table 5 sum-marizes the performance of Gabor features based methodas opposed to our Moment based system.
As shown , Mo-Table 3: Average Precision rate for word spotting in all 3Scripts .Script Before RF After RFEnglish 66.30 69.20Hindi 71.18 74.34Sanskrit 87.88 92.33Table 4: Comparison of GSC and Moments based featuresat 50% recall level.Script GSC MomentsEnglish 60.0 71.6Sanskrit 90.0 94.3ment based features outperform Gabor based features interms of average precision rates obtained for all 3 scriptsused in the experiment.7 Summary and ConclusionIn this paper, we have proposed a framework for script in-dependent word spotting in document images.
We haveshown the effectiveness of using statistical Moment basedfeatures as opposed to some of the structural and profilebased features which may constrain the approach to fewscripts.
Another advantage of using moment based fea-tures is that they are image scale and translation invariantwhich makes them suitable for font independent featureanalysis.
In order to deal with the noise sensitivity of thehigher order moments, we use a manual relevance feed-back to improve the ranking of the relevant word images.We are currently working on extending our methodologyto larger data sets and incorporating more scripts in futureexperiments.Table 5: Comparison of Gabor filter based and MomentsFeatures.Script Gabor MomentsEnglish 56.15 66.30Hindi 67.25 71.18Sanskrit 79.10 87.88References[1] S. N. Srihari, H. Srinivasan, C. Huang and S. Shetty,?Spotting Words in Latin, Devanagari and ArabicScripts,?
Vivek: Indian Journal of Artificial Intelli-gence , 2006.
[2] Huaigu Cao, Venu Govindaraju, Template-Free WordSpotting in Low-Quality Manuscripts, the Sixth Inter-national Conference on Advances in Pattern Recogni-tion (ICAPR), Calcutta, India, 2007.
[3] S. Kuo and O. Agazzi, Keyword spotting in poorlyprinted documents using 2-d hidden markov models,in IEEE Trans.
Pattern Analysis and Machine Intelli-gence, 16, pp.
842848, 1994.
[4] M. Burl and P.Perona, Using hierarchical shape mod-els to spot keywords in cursive handwriting, in IEEE-CS Conference on Computer Vision and PatternRecognition, June 23-28, pp.
535540, 1998.
[5] A. Kolz, J. Alspector, M. Augusteijn, R. Carlson, andG.
V. Popescu, A line oriented approach to word spot-ting in hand written documents, in Pattern Analysisand Applications, 2(3), pp.
153168, 2000.
[6] R. Manmatha and W. B. Croft, ?Word spotting: In-dexing handwritten archives,??
In M. Maybury, editor,Intelligent Multimedia Information Retrieval Collec-tion , AAAI/MIT Press, Menlo Park, CA, 1997.
[7] T. Rath and R. Manmatha, .Features for word spot-ting in historical manuscripts,.
in Proc.
InternationalConference on Document Analysis and Recognition,pp.
218.222, 2003.
[8] T. Rath and R. Manmatha, .Word image matching us-ing dynamic time warping,.
in Proceeding of the Con-ference on Computer Vision and Pattern Recognition(CVPR), pp.
521.527, 2003.
[9] Teh C.-H. and Chin R.T., ?
?On Image Analysis bythe Methods of Moments,??
in IEEE Trans.
PatternAnalysis and Machine Intelligence, 10, No.
4 , pp.496513, 1988.
[10] Franz L. Alt , ?
?Digital Pattern Recognition by Mo-ments,??
in The Journal of the ACM , Vol.
9 , Issue 2, pp.
240-258 , 1962.
[11] Jeff L. Decurtins and Edward C. Chen ,??
Keywordspotting via word shape recognition ??
in Proc.
SPIEVol.
2422, p. 270-277, Document Recognition II, LucM.
Vincent; Henry S. Baird; Eds.
, vol.
2422 , pp.270-277, March 1995.
[12] Carnegie Mellon University - Million book project,URL: http://tera-3.ul.cs.cmu.edu/, 2007.
[13] IAM Database for Off-line Cursive Handwrit-ten Text, URL: http://www.iam.unibe.ch/ zim-merma/iamdb/iamdb.html .
[14] Word Image Dataset at CIIR - UMass, URL: http://ciir.cs.umass.edu/cgi-bin/downloads/downloads.cgi .
