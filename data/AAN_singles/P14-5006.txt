Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 31?36,Baltimore, Maryland USA, June 23-24, 2014.c?2014 Association for Computational LinguisticsDKPro Keyphrases: Flexible and Reusable Keyphrase ExtractionExperimentsNicolai Erbs?, Pedro Bispo Santos?, Iryna Gurevych?
?and Torsten Zesch???
UKP Lab, Technische Universit?at Darmstadt?
Information Center for Education, DIPF, Frankfurt?
Language Technology Lab, University of Duisburg-Essenhttp://www.ukp.tu-darmstadt.deAbstractDKPro Keyphrases is a keyphrase extrac-tion framework based on UIMA.
It offersa wide range of state-of-the-art keyphraseexperiments approaches.
At the sametime, it is a workbench for developing newextraction approaches and evaluating theirimpact.
DKPro Keyphrases is publiclyavailable under an open-source license.11 IntroductionKeyphrases are single words or phrases that pro-vide a summary of a text (Tucker and Whittaker,2009) and thus might improve searching (Song etal., 2006) in a large collection of texts.
As man-ual extraction of keyphrases is a tedious task, awide variety of keyphrase extraction approacheshas been proposed.
Only few of them are freelyavailable which makes it hard for researchers toreplicate previous results or use keyphrase extrac-tion in some other application, such as informa-tion retrieval (Manning et al., 2008), or questionanswering (Kwok et al., 2001).In this paper, we describe our keyphrase extrac-tion framework called DKPro Keyphrases.
It inte-grates a wide range of state-of-the-art approachesfor keyphrase extraction that can be directly usedwith limited knowledge of programming.
How-ever, for developers of new keyphrase extrac-tion approaches, DKPro Keyphrases also offers aprogramming framework for developing new ex-traction algorithms and for evaluation of result-ing effects.
DKPro Keyphrases is based on theUnstructured Information Management Architec-ture (Ferrucci and Lally, 2004), which provides arich source of libraries with preprocessing compo-nents.1http://code.google.com/p/dkpro-keyphrases/TextPreprocessingSelect keyphrasesFilter keyphrasesRank keyphrasesEvaluateResultsFigure 1: Architecture overview of DKProKeyphrases2 ArchitectureThe architecture of DKPro Keyphrases models thefive fundamental steps of keyphrase extraction:(i) Reading of input data and enriching it withstandard linguistic preprocessing, (ii) selectingphrases as keyphrase candidates based on the pre-processed text, (iii) filtering selected keyphrases,(iv) ranking remaining keyphrases, and (v) evalu-ating ranked keyphrases against a gold standard.This process is visualized in Figure 1.
In thissection, we will describe details of each step, in-cluding components already included in DKProKeyphrases.2.1 PreprocessingDKPro Keyphrases relies on UIMA-based pre-processing components developed in the natu-ral language processing framework DKPro Core(Gurevych et al., 2007; Eckart de Castilho andGurevych, 2009).
Thus, a wide range of linguis-tic preprocessing components are readily availablesuch as word segmentation, lemmatization, part-of-speech tagging, named entity recognition, syn-31tactic parsing, or co-reference resolution.2.2 Selecting KeyphrasesIn this step, DKPro Keyphrases selects all phrasesas keyphrases that match user-specified criteria.
Acriterium is typically a linguistic type, e.g.
tokens,or more sophisticated types such as noun phrases.The resulting list of keyphrases should cover allgold keyphrases and at the same time be as selec-tive as possible.
We use the following sentencewith the two gold keyphrases ?dog?
and ?old cat?as a step through example:A [dog] chases an [old cat] in my gar-den.Taking all uni- and bi-grams as keyphrases willeasily match both gold keyphrases, but it will alsoresult in many other less useful keyphrases like ?inmy?.In the given example, the keyphrase list consistsof nine tokens (lemmas, resp.)
but covers only onegold keyphrase (i.e.
?dog?).
Noun chunks andnamed entities are alternative keyphrases, limitingthe set of keyphrases further.
Experiments wherenoun chunks are selected as keyphrases performbest for this example.
Named entities are too re-strictive, but applicable for identifying relevant en-tities in a text.
This is useful for tasks that aretargeted towards entities, e.g.
for finding experts(D?orner et al., 2007) in a collection of domain-dependent texts.
The selection of a linguistic typeis not limited as preprocessing components mightintroduce further types.2.3 FilteringFiltering can be used together with over-generating selection approaches like taking all n-grams to decrease the number of keyphrases be-fore ranking.
One possible approach is basedon POS patterns.
For example, using the POSpatterns, Adjective-Noun, Adjective, andNoun limits the set of possible keyphrases to?dog?, ?old cat?, ?cat?, and ?garden?
in the pre-vious example.
This step can also been per-formed as part of the selection step, however,keeping it separated enables researchers to ap-ply filters to keyphrases of any linguistic type.DKPro Keyphrases provides the possibility to usecontrolled-vocabulary keyphrase extraction by fil-tering out all keyphrases which are not included ina keyphrase list.Developers of keyphrase extraction approachescan create their own filter simply by extendingfrom a base class and adding filter-specific code.Additionally, DKPro Keyphrases does not imposeworkflow-specific requirements, such as a fixednumber of filters.
This leaves room for keyphraseextraction experiments testing new or extended fil-ters.2.4 RankingIn this step, a ranker assigns a score to each re-maining keyphrase candidate.
DKPro Keyphrasescontains rankers based on the candidate position,frequency, tf-idf, TextRank (Mihalcea and Tarau,2004), and LexRank (Erkan and Radev, 2004).DKPro Keyphrases also contains a special ex-tension of tf-idf, called tf-idfweb, for which Googleweb1t (Brants and Franz, 2006) is used for obtain-ing approximate df counts.
In case of keyphraseextraction for a single document or for domain-independent keyphrase extraction, web1t providesreliable n-gram statistics without any domain-dependence.2.5 EvaluationDKPro Keyphrases ships with all the metricsthat have been traditionally used for evaluatingkeyphrase extraction.
Kim et al.
(2010) useprecision and recall for a different number ofkeyphrases (5, 10 and 15 keyphrases).
These met-rics are widely used for evaluation in informationretrieval.
Precision @5 is the ratio of true pos-itives in the set of extracted keyphrases when 5keyphrases are extracted.
Recall @5 is the ratio oftrue positives in the set of gold keyphrases when5 keyphrases are extracted.
Moreover, DKProKeyphrases evaluates with MAP and R-precision.MAP is the mean average precision of extractedkeyphrases from the highest scored keyphrase tothe total number of extracted keyphrases.
For eachposition in the rank, the precision at that positionwill be computed.
Summing up the precision ateach recall point and then taking its average willreturn the average precision for the text being eval-uated.
The mean average precision will be themean from the sum of each text?s average preci-sion from the dataset.
R-precision is the ratio oftrue positives in the set of extracted keyphrases,when the set is limited to the same size as the setof gold keyphrases (Zesch and Gurevych, 2009).323 Experimental frameworkIn this section, we show how researchers can per-form experiments covering many different config-urations for preprocessing, selection, and ranking.To facilitate the construction of experiments, theframework contains a module to make its archi-tecture compatible to the DKPro Lab framework(Eckart de Castilho and Gurevych, 2011), thus al-lowing to sweep through the parameter space ofconfigurations.
The parameter space is the combi-nation of all possible parameters, e.g.
one parame-ter with two possible values for preprocessing anda second parameter with two values for rankerslead to four possible combinations.
We refer to pa-rameter sweeping experiments when running theexperiment with all possible combinations.DKPro Keyphrases divides the experimentalsetup in three tasks.
Tasks are processing stepsdefined in the Lab framework, which ?
in case ofkeyphrase extraction ?
are based on the steps de-scribed in Section 2.
In the first task, the inputtext is fed into a pipeline and preprocessed.
In thesecond task, the keyphrases are selected and fil-tered.
In the third and final task they are rankedand evaluated.
The output of the first two tasks areserialized objects which can be processed furtherby the following task.
The output of the third taskis a report containing all configurations and resultsin terms of all evaluation metrics.The division into three tasks speeds up process-ing of the entire experiment.
Each task has mul-tiple configuration parameters which influence theforthcoming tasks.
Instead of running the prepro-cessing tasks for every single possible combina-tion, the intermediate objects are stored once andthen used for every possible configuration in thekeyphrase selection step.To illustrate the advantages of experimental set-tings in DKPro Keyphrases, we run the previouslyused example sentence through the entire parame-ter space.
Hence, tokens, lemmas, n-grams, nounchunks, and named entities will be combined withall filters and all rankers (not yet considering allpossible parameters).
This results in more than10,000 configurations.
Although the number ofconfigurations is high, the computation time islow2as not the entire pipeline needs to run thatoften.
This scales well for longer texts.The experimental framework runs all possible2Less than five minutes on a desktop computer with a 3.4GHz 8-core processor.combinations automatically and collects individ-ual results in a report, such as a spreadsheet ortext file.
This allows for comparing results of dif-ferent rankers, mitigating the influence of differ-ent preprocessing and filtering components.
Thisway, the optimal experimental configuration canbe found empirically.
It is a great improvementfor researchers because a variety of system con-figurations can be compared without the effort ofreimplementing the entire pipeline.Code example 1 shows the main method of anexample experiment, selecting all tokens as pos-sible keyphrases and ranking them with their tf-idf values.
Lines 1 to 34 show values for dimen-sions which span the parameter space.
A dimen-sion consists of an identifier, followed by one ormore values.
Lines 36 to 40 show the creation oftasks, and in lines 42 to 48 the tasks and a re-port are added to one batch task, which is thenexecuted.
Researchers can run multiple configu-rations by setting multiple values to a dimension.Line 25 shows an example of a dimension withtwo values (using the logarithm or unchanged textfrequency), in this case two configurations3for theranker based on tf-idf scores.Code example 1: Example experiment1 ParameterSpace params = newParameterSpace(2 Dimension.create("language", "en"),3 Dimension.create("frequencies","web1t"),4 Dimension.create("tfidfFeaturePath",Token.class"),56 Dimension.create("dataset",datasetPath),7 Dimension.create("goldSuffix", ".key"),89 //Selection10 Dimension.create("segmenter",OpenNlpSegmenter.class),11 Dimension.create("keyphraseFeaturePath",Token.class),1213 //PosSequence filter14 Dimension.create("runPosSequenceFilter",true),15 Dimension.create("posSequence",standard),1617 //Stopword filter18 Dimension.create("runStopwordFilter",true),19 Dimension.create("stopwordlists","stopwords.txt"),2021 // Ranking3DKPro Keyphrases provides ways to configure experi-ments using Groovy and JSON.3322 Dimension.create("rankerClass",TfidfRanking.class),2324 //TfIdf25 Dimension.create("weightingModeTf",NORMAL, LOG),26 Dimension.create("weightingModeIdf",LOG),27 Dimension.create("tfidfAggregate",MAX),2829 //Evaluator30 Dimension.create("evalMatchingType",MatchingType.Exact),31 Dimension.create("evalN", 50),32 Dimension.create("evalLowercase",true),33 Dimension.create("evalType",EvaluatorType.Lemma),34 );3536 Task preprocessingTask = newPreprocessingTask();37 Task filteringTask = newKeyphraseFilteringTask();38 candidateSelectionTask.addImport(preprocessingTask,PreprocessingTask.OUTPUT,KeyphraseFilteringTask.INPUT);39 Task keyphraseRankingTask = newKeyphraseRankingTask();40 keyphraseRankingTask.addImport(filteringTask,KeyphraseFilteringTask.OUTPUT,KeyphraseRankingTask.INPUT);4142 BatchTask batch = new BatchTask();43 batch.setParameterSpace(params);44 batch.addTask(preprocessingTask);45 batch.addTask(candidateSelectionTask);46 batch.addTask(keyphraseRankingTask);47 batch.addReport(KeyphraseExtractionReport.class);48 Lab.getInstance().run(batch);A use case for the experimental framework isthe evaluation of new preprocessing components.For example, keyphrase extraction should be eval-uated with Twitter data: One collects a datasetwith tweets and their corresponding keyphrases(possibly, the hash tags).
The standard preprocess-ing will most likely fail as non-canonical languagewill be hard to process (e.g.
hash tags or emoti-cons).The preprocessing components can be set as aparameter and compared directly without chang-ing the remaining parameters for filters andrankers.
This allows researchers to perform reli-able extrinsic evaluation of their components in akeyphrase extraction setting.Figure 2: Screenshot of web demo in DKProKeyphrases4 Visualization and wrappersTo foster analysis of keyphrase extraction ex-periments, we created a web-based visualizationframework with Spring4.
It allows for running off-the-shelf experiments and manually inspecting re-sults without the need to install any additional soft-ware.
Figure 2 shows a visualization of one pre-configured experiment.
The web demo is avail-able online.5Currently, a table overview of ex-tracted keyphrases is implemented, but develop-ers can change it to highlighting all keyphrases.The latter is recommend for a binary classificationof keyphrases.
This is the case, if a system onlyreturns keyphrases with a score above a certainthreshold.
The table in Figure 2 shows keyphraseswith the assigned scores, which can be sorted toget a ranking of keyphrases.
However, the visual-ization framework does not provide any evaluationcapabilities.To help new users of DKPro Keyphrases, it in-cludes a module with two demo experiments us-ing preconfigured parameter sets.
This is espe-cially useful for applying keyphrase extraction inother tasks, e.g.
text summarization (Goldstein et4http://projects.spring.io/spring-ws/5https://dkpro.ukp.informatik.tu-darmstadt.de/DKProWebDemo/livedemo/334al., 2000).
Both demo experiments are frequentlyused keyphrase extraction systems.
The first oneis based on TextRank (Mihalcea and Tarau, 2004)and the second one is based on the supervised sys-tem KEA (Witten et al., 1999).
Both configura-tions do not require any additional installation ofsoftware packages.This module offers setters to configure param-eters, e.g.
the size of co-occurrence windows incase of the TextRank extractor.5 Related workMost work on keyphrase extraction is not accom-panied with free and open software.
The toolslisted in this section allow users to combine differ-ent configurations with respect to preprocessing,keyphrase selection, filtering, and ranking.
In thefollowing, we give an overview of software toolsfor keyphrase extraction.KEA (Witten et al., 1999) provides a Java API,which offers automatic keyphrase extraction fromtexts.
They provide a supervised approach forkeyphrase extraction.
For each keyphrase, KEAcomputes frequency, position, and semantic relat-edness as features.
Thus, for using KEA, the userneeds to provide annotated training data.
KEAgenerates keyphrases from n-grams with lengthfrom 1 to 3 tokens.
A controlled vocabulary canbe used to filter keyphrases.
The configuration forkeyphrase selection and filtering is limited com-pared to DKPro Keyphrases, which offers capa-bilities for changing the entire preprocessing oradding filters.Maui (Medelyan et al., 2009) enhances KEAby allowing the computation of semantic related-ness of keyphrases.
It uses Wikipedia as a the-saurus and computes the keyphraseness of eachkeyphrase, which is the number of times a can-didate was used as keyphrase in the training data(Medelyan et al., 2009).Although Maui provides training data alongwith their software, this training data is highlydomain-specific.
A shortcoming of KEA andMaui is the lack of any evaluation capabilities orthe possibility to run parameter sweeping exper-iments.
DKPro Keyphrases provides evaluationtools for automatic testing of many parameter set-tings.Besides KEA and Mau, which are Java sys-tems, there are several modules in Python,e.g.
topia.termextract6, which offer capabili-ties for tokenization, part-of-speech tagging andkeyphrase extraction.
Keyphrase extraction fromtopia.termextract is based on noun phrases andranks them according to their frequencies.BibClassify7is a python module which auto-matically extracts keywords from a text based onthe occurrence of terms in a thesaurus.
The rankeris frequency-based like topia.termextract.
Bib-Classify and topia.termextract do not provide eval-uation capabilities or parameter sweeping experi-ments.Besides these software tools, there exist webservices for keyphrase extraction.
AlchemyAPI8offers a web service for keyword extraction.
Itmay return keyphrases encoded in various markuplanguages.
TerMine9offers a SOAP service forextracting keyphrases from documents and a webdemo.
The input must be a String and the extractedterms will be returned as a String.
Although webservices can be integrated easily due to their proto-col stacks, they are not extensible and replicabilitycannot be guaranteed over time.6 Conclusions and future workWe presented DKPro Keyphrases, a framework forflexible and reusable keyphrase extraction experi-ments.
This helps researchers to effectively de-velop new keyphrase extraction components with-out the need to re-implement state-of-the-art ap-proaches.The UIMA-based architecture of DKProKeyphrases allows users to easily evaluatekeyphrase extraction configurations.
Researcherscan integrate keyphrase extraction with differentexisting linguistic preprocessing components of-fered by the open-source community and evaluatethem in terms of all commonly used evaluationmetrics.As future work, we plan to wrap furtherthird-party libraries with keyphrase extraction ap-proaches in DKPro Keyphrases and to add a super-vised system using the unsupervised componentsas features.
We expect that a supervised system us-ing a large variety of features would improve thestate of the art in keyphrase extraction.6https://pypi.python.org/pypi/topia.termextract/7http://invenio-demo.cern.ch/help/admin/bibclassify-admin-guide8http://www.alchemyapi.com/api/keyword-extraction/9http://www.nactem.ac.uk/software/termine/35AcknowledgmentsThis work has been supported by the Volk-swagen Foundation as part of the Lichtenberg-Professorship Program under grant No.
I/82806,by the Klaus Tschira Foundation under project No.00.133.2008, and by the German Federal Min-istry of Education and Research (BMBF) withinthe context of the Software Campus project openwindow under grant No.
01IS12054.
The authorsassume responsibility for the content.
We thankRichard Eckart de Castilho and all contributors fortheir valuable collaboration and the we thank theanonymous reviewers for their helpful comments.ReferencesThorsten Brants and Alex Franz.
2006.
Web 1T 5-Gram Corpus Version 1.1.
Technical report, GoogleResearch.Christian D?orner, Volkmar Pipek, and Markus Won.2007.
Supporting Expertise Awareness: FindingOut What Others Know.
In Proceedings of the 2007Symposium on Computer Human Interaction for theManagement of Information Technology.Richard Eckart de Castilho and Iryna Gurevych.
2009.DKPro-UGD: A Flexible Data-Cleansing Approachto Processing User-Generated Discourse.
In Online-proceedings of the First French-speaking meetingaround the framework Apache UIMA.Richard Eckart de Castilho and Iryna Gurevych.
2011.A Lightweight Framework for Reproducible Param-eter Sweeping in Information Retrieval.
In Pro-ceedings of the 2011 Workshop on Data Infrastruc-tures for Supporting Information Retrieval Evalua-tion, pages 7?10.G?unes Erkan and Dragomir Radev.
2004.
LexRank:Graph-based Lexical Centrality as Salience in TextSummarization.
Journal of Artificial IntelligenceResearch, 22:457?479.David Ferrucci and Adam Lally.
2004.
UIMA: AnArchitectural Approach to Unstructured InformationProcessing in the Corporate Research Environment.Natural Language Engineering, 10(3-4):327?348.Jade Goldstein, Vibhu Mittal, Jaime Carbonell, andMark Kantrowitz.
2000.
Multi-Document Summa-rization By Sentence Extraction.
In Proceedings ofthe NAACL-ANLP 2000 Workshop: Automatic Sum-marization, pages 40?48.Iryna Gurevych, Max M?uhlh?auser, Christof M?uller,J?urgen Steimle, Markus Weimer, and Torsten Zesch.2007.
Darmstadt Knowledge Processing RepositoryBased on UIMA.
In Proceedings of the First Work-shop on Unstructured Information Management Ar-chitecture at Biannual Conference of the Society forComputational Linguistics and Language Technol-ogy.Su Nam Kim, Olena Medelyan, Min-Yen Kan, andTimothy Baldwin.
2010.
Semeval-2010 Task 5:Automatic Keyphrase Extraction from Scientific Ar-ticles.
In Proceedings of the 5th International Work-shop on Semantic Evaluation, pages 21?26.Cody Kwok, Oren Etzioni, and Daniel S. Weld.
2001.Scaling Question Answering to the Web.
ACMTransactions on Information Systems, 19(3):242?262.Christopher D Manning, Prabhakar Raghavan, andHinrich Sch?utze.
2008.
An Introduction to Infor-mation Retrieval.
Cambridge University Press Cam-bridge.Olena Medelyan, Eibe Frank, and Ian H Witten.2009.
Human-competitive Tagging using AutomaticKeyphrase Extraction.
In Proceedings of the 2009Conference on Empirical Methods in Natural Lan-guage Processing, pages 1318?1327.Rada Mihalcea and Paul Tarau.
2004.
TextRank:Bringing Order into Texts.
In Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing, pages 404?411.Min Song, Il Yeol Song, Robert B. Allen, and Zo-ran Obradovic.
2006.
Keyphrase Extraction-basedQuery Expansion in Digital Libraries.
In Proceed-ings of the 6th ACM/IEEE-CS Joint Conference onDigital Libraries, pages 202?209.Simon Tucker and Steve Whittaker.
2009.
Have A SayOver What You See: Evaluating Interactive Com-pression Techniques.
In Proceedings of the 2009International Conference on Intelligent User Inter-faces, pages 37?46.Ian H. Witten, Gordon W. Paynter, Eibe Frank,Carl Andrew Gutwin, and Craig G .
Nevill-Manning.
1999.
KEA: Practical AutomaticKeyphrase Extraction.
In Proceedings of the 4thACM Conference on Digital Libraries, pages 254?255.Torsten Zesch and Iryna Gurevych.
2009.
Approx-imate Matching for Evaluating Keyphrase Extrac-tion.
In Proceedings of the 7th International Confer-ence on Recent Advances in Natural Language Pro-cessing, pages 484?489.36
