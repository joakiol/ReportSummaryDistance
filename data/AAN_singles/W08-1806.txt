Coling 2008: Proceedings of the 2nd workshop on Information Retrieval for Question Answering (IR4QA), pages 42?49Manchester, UK.
August 2008Answer Validation by Information Distance CalculationFangtao Li, Xian Zhang, Xiaoyan ZhuState Key Laboratory on Intelligent Technology and SystemsTsinghua National Laboratory for Information Science and TechnologyDepartment of Computer Science and Technology, Tsinghua University, Beijing 100084, Chinazxy-dcs@mail.tsinghua.edu.cnAbstractIn this paper,an information distance basedapproach is proposed to perform answervalidation for question answering system.To validate an answer candidate, the ap-proach calculates the conditional informa-tion distance between the question focusand the candidate under certain conditionpattern set.
Heuristic methods are de-signed to extract question focus and gen-erate proper condition patterns from ques-tion.
General search engines are employedto estimate the Kolmogorov complexity,hence the information distance.
Experi-mental results show that our approach isstable and flexible, and outperforms tradi-tional tfidf methods.1 IntroductionQuestion answering(QA) system aims at findingexact answers to a natural language question.
Inorder to correctly answer a question, several com-ponents are implemented including question clas-sification, passage retrieval, answer candidatesgeneration, answer validation etc.
Answer Vali-dation is to decide whether the candidate answersare correct or not, or even to determine the accu-rate confidence score to them.
Most of QA systemsemploy answer validation as the last step to iden-tify the correct answer.
If this component fails, itis impossible to enable the question to be correctlyanswered.Automatic techniques for answer validation areof great interest among question answering re-c?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.search.
With automatic answer validation, thesystem will carry out different refinements of itssearching criteria to check the relevance of newcandidate answers.
In addition, since most ofQA systems rely on complex architectures and theevaluation of their performances requires a hugeamount of work, the automatic assessment of can-didates with respect to a given question will speedup both algorithm refinement and testing.Currently, answer validation is mainly viewedas a classification problem or ranking problem.Different models, such as Support Vector Ma-chine (Shen and Klakow, 2006) and Maximum En-tropy Model (Ittycheriah et al, 2001), are used tointegrate sophisticated linguistic features to deter-mine the correctness of candidates.
The answervalidation exercise (Penas et al , 2007) aims atdeveloping systems able to decide whether the an-swer is correct or not.
They formulate answer val-idation as a text entailment problem.
These ap-proaches are dependent on sophisticated linguis-tic analysis of syntactic and semantic relations be-tween question and candidates.
It is quite expen-sive to use deep analysis for automatic answer val-idation, especially in large scale data set.
Thus itis appropriate to find an alternative solution to thisproblem.
Here, we just consider the English an-swer validation task.This paper proposes a novel approach based oninformation retrieval on the Web.
The answer val-idation problem is reformulated as distance calcu-lation from an answer candidate to a question.
Thehypothesis is that, among all candidates, the cor-rect answer has the smallest distance from ques-tion.
We employ conditional normalized min dis-tance, which is based on Kolmogorov Complexitytheory (Li and Vitanyi, 1997), for this task.
Thedistance measures the relevance between question42focus and candidates conditioned on a surface pat-tern set.
For distance calculation, we first ex-tract the question focus, and then a hierarchicalpattern set is automatically constructed as condi-tion.
Since Kolmogrov Complexity can be approx-imated through frequency counts.
Two types ofsearch engine ?Google?
and ?Altavista?
are usedto approximate the distance.The paper is organized as follows: Section 2describes related work.
The fundamental Kol-mogorov Complexity theory is introduced in Sec-tion 3.
Section 4 presents our proposed answer val-idation method based on information retrieval.
InSection 5, we describe the experiments and discus-sions.
The paper is concluded in Section 6.2 Related WorkAnswer Validation is an emerging topic in Ques-tion Answering, where open domain systems areoften required to rank huge amounts of answercandidates.
This task can be viewed as a classi-fication problem or re-ranking problem.Early question answering systems focused onemploying surface text patterns (Subbotin andSubbotin, 2001) for answer validation.
Xu etal.
(2003) identified that pattern-based approachesgot bad performances due to poor system recall.Some researchers exploited machine learning tech-niques with rich syntactic or semantic features tomeasure the similarity between question and an-swer.
Ittycheriah et al (2001) used Maximum En-tropy model to combine rich features and automat-ically learn feature weights.
These features in-cluded query expansion features, focus features,named entity features, dependency relation fea-tures, pattern features et al Shen and Klakow(2006) presented three methods, including featurevector, string kernel and tree kernel, to representsurface text features and parse tree features in Sup-port Vector Machines.
Ko et al (2007) pro-posed a probabilistic graphical model to estimatethe probability of correctness for all candidate an-swers.
Four types of features were employed,including knowledge-based features, data-drivenfeatures, string distance feature and synonym fea-tures.Started in 2006, the annual Answer ValidationExercise (Penas et al , 2007) aims to develop sys-tems to decide if the answer to a question is corrector not.
The English answer validation task is refor-mulated as a Text Entailment problem.
The triplet,including question, answer and supporting text, isgiven.
The system determines if the supportingtext can entail the hypothesis, which is a reformu-lation from the question and answer.
All partici-pants used lexical processing, including lemmati-zation and part-of speech tagging.
Some systemsused first order logic representations, performedsemantic analysis and took the validation decisionwith a theorem proof.The above approaches should process deep syn-tactic and semantic analysis for either questions orcandidate answers.
The annotated linguistic re-source is hard to acquire for the supervised clas-sification problem.
Another alternative solutionfor answer validation is to exploit the redundancyof large scale data.
Eric et al (2007) devel-oped AskMSR question answering system.
Theyfocus on the Web as a gigantic data repositorywith tremendous redundancy that can be exploitedto extract the correct answer.
Lin (2007) im-plemented another Web-based question answeringsystem, named ARANEA, which is used approxi-mate tfidf method for answer validation.3 Preliminaries3.1 Kolmogorov complexityKolmogorov complexity , or algorithm entropy ,K(x) of a string x is the length of the shortest bi-nary program to compute x.
It defines randomnessof an individual string.
Kolmogorov complexityhas been widely accepted as an information theoryfor individual objects parallel to that of Shannon?sinformation theory which is defined on an ensem-ble of objects.
It has also found many applicationsin computer science such as average case analysisof algorithms (Li and Vitanyi, 1997).
For a uni-versal Turing machine U , the Kolmogorov com-plexity of a binary string x condition to anotherbinary string y, KU(x|y), is the length of the short-est (prefix-free) program for U that outputs x withinput y.
It has been proved that for different uni-versal Turing machine U?, for all x, yKU(x|y) = KU?
(x|y) + C,where the constant C depends only on U?.
Thus wesimply write KU(x|y) as K(x|y).
Define K(x) =K(x|?
), where ?
is the empty string.
For for-mal definitions and a comprehensive study of Kol-mogorov complexity, see (Li and Vitanyi, 1997).433.2 Information DistanceBased on the Kolmogovov complexity theory, in-formation distance (Bennett et al, 1998) is a uni-versal distance metric, which has been success-fully applied to many applications.
The informa-tion distance D(x, y) is defined as the length ofa shortest binary program which can compute xgiven y as well as compute y from x.
It has beenproved that , up to an additive logarithmic term,D(x, y) = max{K(x|y),K(y|x)}.
The normal-ized version of D(x, y), called the normalized in-formation distance(NID), is defined asdmax(x, y) =max{K(x|y),K(y|x)}max{K(x),K(y)}(1)Parallel to this, the min distance is proposed in(Zhang et al , 2007), defined asDmin(x, y) = min{K(x|y),K(y|x)}.
(2)And the normalized version isdmin(x, y) =min{K(x|y),K(y|x)}min{K(x),K(y)}.
(3)3.3 Conditional Information DistanceConditional information distance is defined asdmax(x, y|c) =max{K(x|y, c),K(y|x, c)}max{K(x|c),K(y|c)}, (4)dmin(x, y|c) =min{K(x|y, c),K(y|x, c)}min{K(x|c),K(y|c)}.
(5)where c is given in both x to y and y to x compu-tation.The information distance is proved to be uni-versal (Zhang et al , 2007), that is, if x and yare ?close?
under any distance measure, they are?close?
under the measure of information distance.However, it is not clear yet how to find out such?closeness?
in traditional information distance the-ory.
Now the conditional information distance pro-vides a possible solution.Figure 1 gives a more in-terpretable explanation: the condition c could mapthe original concepts x and y into different xcandyc, thus the variant ?closeness?
could be reflectedby the distance between xcand yc, as shown inFigure1.Figure 1: Conditional information distances under differentconditions c?sThe Kolmogorov complexity is non-computable, that is, to use the informationdistance measures, we must estimate the K(x)first.
There are traditionally two ways to dothis: (1) by compression (Li et al , 2001),and (2) by frequency counting based on codingtheorem (Cilibrasi and Vitanyi, 2007).
The secondapproach is implemented in this paper.4 Answer Validation with InformationDistanceGiven a question q and a candidate answer c, theanswer validation task can be considered as deter-mining the degree of relevance of c with respectto q.
The intuition of our approach is that the dis-tance between question and the correct answer issmaller than other candidates.
Take the question?What is the capital of the USA??
as an example,among all candidates, the correct answer ?Wash-ington?
is closest to the question under some dis-tance measure.
Thus the answer validation prob-lem is to determine a proper distance measure.Fortunately, it has been proved that the informa-tion distance (Bennett et al, 1998) is universal sothat the similarity between the question and the an-swer can surely be discovered using this measure.Direct calculation of the unconditional distanceis difficult and non-flexible.
We find it possibleand convenient to estimate the conditional infor-mation distance between question focus and theanswers, under certain context as the condition.
Asexplained previously, different conditions lead todifferent distance.
With the most proper conditionand the nearest distance, the best answer can beidentified out of previously determined candidates.The conditional normalized min distance is em-ployed for distance calculation, which is defined44Figure 2: Sample of conditional information distance calculation.as:dmin(x, y|c)=K(c(x,y))?max{K(c(x,?)),K(c(?,y))}min{K(c(x,?)),K(c(?,y))}?K(c(?,?
))where x represents the answer candidates, y isthe question focus, and c is condition pattern.
Thefunction c(x, y) will be described in the DistanceCalculation section.Figure 2 shows the procedure of distance cal-culation.
Given a question and a set of candidates,we calculate the min information distance betweenquestion focus and candidates conditioned on sur-face patterns.
Obviously, in order to calculate in-formation distance, there are three issues to be ad-dressed:1.
Question Focus Extraction: since the questionanswer distance is reformulated as the mea-sure between question focus and answer con-ditioned on the surface pattern, it is importantto extract some words or phrases as questionfocus.2.
Condition Pattern Generation: Obviously, thegeneration of the condition is the key part.We have built a well revised algorithm, inwhich proper conditions can be generatedfrom question sentence according to someheuristic rules.3.
Distance Calculation: after question focusand condition patterns are obtained, the laststep is calculating the conditional distance toestimate the relevance between question andanswer candidates.4.1 Question Focus ExtractionMost factoid questions refer to specific objects.
Aquestion is asked to learn some knowledge for thisobject from certain perspective.
In our approach,we take the key named entity or noun phrase, usu-ally as the subject or the main object of the ques-tion sentence as the reference object.
Take thequestion ?What city is Lake Washington by?
as ex-ample, the specific object is ?Lake Washington?.The question focus is identified using some heuris-tic rules as follows:1.
The question is processed by shallow parsing.All the noun phrases(NP) are extracted as NP set.2.
All the named entities(NE) in the question areextracted as NE set.3.
If only one same element is identified in bothNE and NP set, this element is considered as ques-tion focus.4.
If step 3 fails, but two elements from NE andNP set have overlap words, then choose the ele-ment with more words as question focus.5.
If step 3 and 4 fail, choose the candidate,which is nearest with verb phrase in dependencytree, as question focus.4.2 Condition Pattern GenerationA set of hierarchical patterns is automatically con-structed for conditional min distance calculation.4.2.1 Condition Pattern ConstructionSeveral operations are defined for patterns con-struction from the original question sentence.
Wedescribe pattern set construction with a sam-ple question ?What year was President Kennedykilled??:1.
With linguistic analysis, the question issplit into pieces of tokens.
These tokens in-45clude wh-word phrases, preposition phrases, nounphrases, verb phrases, key verb, etc.
The exam-ple question is split into ?What year?
(wh-wordphrase), ?was?
(key verb) ?President Kennedy?
(noun phrases), ?killed?
(verb phrase).2.
Replace the wh-word phrases with the candi-date placeholder ?c?.
Then the words ?What year?is replaced with placeholder ?c?.3.
Replace the question focus with the focusplaceholder ?f?, and add this pattern to the pat-tern set.
The example question focus is identifiedas ?President Kennedy?.
It is replaced with place-holder ?f?.
The first pattern ??c?
was ?f?
killed?
?is generated.4.
Voice Transformation: with morphologytechniques, verbs are expanded with all their tenseforms ( i.e.
present, past tense and past participle).The tokens?
order is adjusted to transform betweenactive voice and passive voice.
Both patterns areadded to the patterns set.
For sample question,the passive pattern is translated into active pattern,??c?
kill ?f??.5.
Preposition addition: for time and locationquestions, the preposition (i.e.
in, on and at) isadded before the candidate ?c?
; Then the pattern??c?
was ?f?
killed?
is reformulated as ?
(in |on)?c?
was ?f?
killed?.6.
Tokens shift: preposition phrase token couldbe shifted to the begin or the end of pattern, and?key verb?
must be shift before the ?verb phrase?.Then the pattern ?
(in |on) ?c?
was ?f?
killed?
canbe reformulated as ??f?
was killed (in |on) ?c??.7.
Definitional patterns: several heuristic pat-terns, as introduced at (Hildebrandt et al , 2004),are added into our final pattern sets, such as ??c?,?f?
?.By such heuristic rules, the original pattern set isobtained from question sentence.
The patterns areinitially enclosed in quotation marks, which meansexact matching.
However, by eliminating thesequotations, or reducing the scope that they cover,the matching is relaxed as words co-occurrence.The patterns are expanded into different strict-levelpatterns by adding or removing quotation marksfor each tokens or adjacent tokens combination.Several condition pattern samples are shown in Ta-ble 1Table 1: Sample condition patterns, ?
??
?
denotes exactmatch in web query.?
?
<f>(was | were) killed (in | on) <c>??
?
(in | on) <c>, <f>(was | were) killed??
?
(in | on) <c>?
& ?<f>(was | were) killed??
?
(in | on) <c>?
& ?<f>?
& ?
(was | were) killed??
in | on <c><f>(was | were) killedEach operation introduced above is given a pre-defined confidence coefficient(cc).
Then the con-fidence coefficient of a pattern is defined as themultiplication of cc for all performed operationsto generate this pattern.4.2.2 Condition Pattern RankingFrom the previous step, a set of condition pat-terns and corresponding confidence coefficient areobtained.
Let pidenotes the ith pattern in the pat-tern set, and cciis the confidence coefficient for theith pattern.
The confidence coefficient estimationin previous section contains much noise.
And thepatterns with similar confidence coefficient makelittle difference.
Therefore, the exact confidencecoefficient value is not directly used.
We clusterthe patterns into different priority groups.
Cjde-notes the pattern cluster with jth priority.
Here,the smaller j means higher priority.
The condi-tion patterns are ranked mainly based on confi-dence coefficient and the number of double quo-tation marks.
The following algorithm shows eachstep in detail:Table 2: patterns ranking algorithmInput patterns set C = {(pi, cci)}Algorithm(1) Initialize Cj= ?, j = 0(2) if C is empty, end this algorithm(3) Select (pmax, ccmax), where ccmax?cci, (pi, cci) ?
C(4) if Cjis empty, add ccmaxinto Cj, jump to(2)(5) select the minimum confidence coefficient(pmin, ccmin) from Cj, compare it with(pmax, ccmax).
if the number of doublequotes(??)
in pminis equal to the number inpmax, add pmaxinto Cj.
otherwise, j =j + 1, Cj= {pmax}.
(6) jump to (2) and repeat4.3 Distance CalculationConditional min distance dminis used to mea-sure the relevance between question and candidate.From section 3, dminis not computable, but ap-proximated by frequency counts based on the cod-ing theory:46dmin(x, y|c)=K(c(x,y))?max{K(c(x,?)),K(c(?,y))}min{K(c(x,?)),K(c(?,y))}?K(c(?,?
))=log f(c(x,y))?min{log f(c(x,?
)),log f(c(?,y))}max{log f(c(x,?
)),log f(c(?,y))}?log f(c(?,?
))The function c(x, ?)
means substituting ?c?
in cby answer candidate x and removing placeholder?f?
if any.
Similar definition applies to c(y, ?
),c(x, y).
For example, given pattern ??f?
was in-vented in ?c?
?, question focus ?the telegraph?
anda candidate ?1867?.
c(x, ?)
is ?was invented in1867?.
c(y, ?)
is ?the telegraph was invented?, andc(x, y) is ?the telegraph was invented in 1867?.The frequency counts f(x) are estimated as thenumber of returned pages by certain search en-gine with respect to x .
f(c(?, ?))
denote the to-tal pages indexed in search engine.
Two types ofsearch engines ?Google?
and ?Altavista?
are em-ployed.The patterns are selected in priority order to cal-culate the information distance for each candidate.5 Experiment and Discussion5.1 Experiment SetupData set: The standard QA test collection (Linand Katz, 2006) is employed in our experiments.
Itconsists of 109 factoid questions, covering severaldomains including history, geography, physics, bi-ology, economics, fashion knowledge, and etc.. 20candidates are prepared for each questions.
All an-swer candidates are first extracted by the imple-mented question answering system.
Then we re-view the candidate set for each question.
If the cor-rect answer is not in this set, it is manually addedinto the set.Performance Metric: The top 1 answer precisionand mean reciprocal rank (MRR) are used for per-formance evaluation.The top 1 answer means thecorrect answer ranks first with our distance calcu-lation method, and MRR =1n?
?i(1ranki), inwhich the1rankiis 1 if the correct answer occurs inthe first position; 0.5 if it firstly occurs in the sec-ond position; 0.33 for the third, 0.25 for the fourth,0.2 for the fifth and 0 if none of the first five an-swers is correct.The open source factoid QA system ARANEA(downloaded from Jimmy Lin?s website in 2005)is used for comparison, which implements an ap-proximate tfidf algorithm for candidate scoring.Both ARANEA and our proposed approaches usethe internet directly.
Google is used as the searchengine for ARENEA, and our conditional normal-ized min distance is calculated with Google andAltavista respectively.5.2 Experiment ResultsThe performances of our proposed approach andARANEA are shown in Table 3.
For top 1 an-swer precision, our conditional min distance cal-culation method through Google achieves 69.7%,and Altavista is 66.1%, which make 56.6%(69.7% v.s.42.2% ) and 50.0% (66.1% v.s 42.2%)improvement compared with ARENEA?s tfidfmethod.
Our proposed methods achieve 0.756 and0.772 compared with ARENEA?s 0.581 for MRRmeasure.Table 3: Performance comparison, where dmin(G) denotesthe distance calculation through ?Google?, dmin(A) through?Altavista?tfidf dmin(G) dmin(A)# of Top 1 46 72 69% of Top 1 42.2 69.7 66.1MRR 0.581 0.772 0.756Table 4 shows some correct answer validationexamples.
the Google Condition(GC) and the Al-tavista Condition(AC) columns are the employedcondition patterns for distance calculation.
Forquestion 1400, the conditional normalized googlemin distance calculates the distance between ques-tion focus ?the telegragh?
and all 20 answer can-didates.
The minimum distance score is achievedbetween ?the telegraph?
and ?1837?
with the con-dition pattern ??f?
was invented in ?c??.
There-fore, the candidate ?1837?
is validated as the cor-rect answer.
Meanwhile, the minimum value forconditional normalized altavista min distance isachieved on the same condition.These results demonstrate that the distance cal-culation method provides a feasible solution foranswer validation.In discussion section, we will study three ques-tions:1.
What is the role of search engine?2.
What is the role of condition pattern?3.
What is the role of question focus?47Table 4: Question Examples in conditional information calculation through Google and Altavista.
GC:Google Condition;AC:Altavista ConditionID Question GC AC Answer Question focus1400 When was the telegraphinvented??
?y was in-vented in ?s??
?y wasinvented in?x?1837 the telegraph1401 What is the democraticparty symbol??
?y is ?x?
?
?y is ?x?
the don-keythe democraticparty symbol1411 What Spanish explorerdiscovered the Missis-sippi River??
?x discov-ered ?y???x?
?dis-covered??
?y?Hernandode Sotothe MississippiRiver1412 Who is the governor ofColorado??
?y is ?x?
?
?y, ?x?
Gov.
BillRitterthe governor ofColorado1484 What college did AllenIverson attend??
?y attended?x???x?
?did?y?GeorgetownUniver-sityAllen Iverson at-tend5.3 Discussions5.3.1 Role of Search EngineThe rise of world-wide-web has enticed millionsof users to create billions of web pages.
The re-dundancy of web information is an important re-source for question answering.
Our KolmogorovComplexity based information distance is approx-imated with query frequency obtained by searchengine.
Two types of search engines ?Google?
and?Altavista?
are employed in this paper.
The num-ber of top 1 correct answer is 72 through ?Google?and 69 through ?Altavista?.
There is little differ-ence between two numbers, which shows that theinformation distance based on Kolmogorov Com-plexity is independent of special search engine.The performance didn?t vary much with the changeof search engine.
Actually, if the local data is ac-cumulated large enough, the information distancecan be approximated without the internet.
Thequality and size of data set affect the experimentperformance.5.3.2 Role of Condition PatternPattern set offers convenient and flexible condi-tion for information distance calculation.
In theexperiment, there are 61 questions correctly an-swered by both Google and Altavista.
46 ques-tions of them employ different patterns.
Consider-ing Question 1412, the condition pattern in Googleis ??c?
is ?f?
?, while in Altavista, it is ?
?f?, ?c?
?.However, the correct answer ?Gov.
Bill Ritter?
isidentified by both methods.
The information dis-tance is stable over specific condition patterns.5.3.3 Role of Question FocusQuestion focus is considered as the discrimina-tor for the question.
The distance between a ques-tion and a candidate is reformulated as the distancebetween question focus and candidate conditionedon a set of surface patterns.
The proposed ap-proach may not properly extract the question fo-cus, but the answers can be correctly identifiedwhen the condition pattern becomes loose enough.Take the question 1484 ?What college did AllenIverson attend??
as example, the verb ?attend?
istagged as ?noun?, then question focus is mistak-enly extracted as ?Allen Iverson attend?, instead ofthe correct ?Allen Iverson?.
The two conditionalinformation distance method still identify the cor-rect answer ?Georgetown University?.
Becausethey both employed the looser condition patterns???c??
??f???
and ???c??
did ??f??
?.Therefore, ourproposed distance answer validation methods arerobust to the question focus selection component.From the discussion above, it can be seen thatour algorithm is stable and robust, not dependingon the specific search engine, condition pattern,and question focus.6 ConclusionsWe have presented a novel approach for answervalidation based on information distance.
The an-swer validation task is reformulated as distancecalculation between question focus and candidateconditioned on a set of surface patterns.
The ex-periments show that our proposed answer valida-tion method makes a great improvement compared48with ARANEA?s tfidf method.
Furthermore, Theexperiments show that our approach is stable androbust, not depending on the specific search en-gine, condition pattern, and question focus.
In fu-ture work, we will try to calculate information dis-tance in the local constructed data set, and expandthis distance measure into other application fields.AcknowledgementThis work is supported by National Natural Sci-ence Foundation of China (60572084, 60621062),Hi-tech Research and Development Program ofChina (2006AA02Z321), National Basic ResearchProgram of China (2007CB311003).ReferencesAbraham Ittycheriah, Martin Franz, Wei-Jing Zhu, Ad-wait Ratnaparkhi, and Richard J.Mammone.
2001.Question answering using maximum entropy conm-ponents.
In Proceedings of the Second meeting ofthe North American Chapter of the Association forComputational Linguistics on Language tecnologies.Anselmo Penas, A. Rodrigo, F. Verdejo.
2007.Overview of the Answer Validation Exercise 2007.Working Notes for the CLEF 2007 Workshop.C.H.
Bennett, P. Gacs, M. Li, P. Vit?anyi, W. Zurek..1998.
Information Distance.
IEEE Trans.
Inform.Theory, 44:4, 1407?1423.Eric Brill and Susan Dumais and Michele Banko.
2002.An analysis of the AskMSR question-answering sys-tem.
EMNLP ?02: the ACL-02 conference on Em-pirical methods in natural language processing.Hildebrandt W., Katz B., and Lin J.
2004.
Answer-ing Definition Questions Using Multiple KnowledgeSources.
Proceedings of Human Language Technol-ogy Conference.
Boston, USA.Jeongwoo Ko, Luo Si, Eric Nyberg.
2007.
A Proba-bilistic Graphical Model for Joint Answer Rankingin Question Answering.
In Proceedings of the 30thannual international ACM SIGIR conference on Re-search and development in information retrieval.Jimmy Lin and Boris Katz.
2006.
Building a reusabletest collection for question answering.
J.
Am.
Soc.Inf.
Sci.
Technol..Jimmy Lin.
2007.
An Exploration of the Principles Un-derlying Redundancy-Based Factoid Question An-swering.
ACM Transactions on Information Sys-tems, 27(2):1-55.Jinxi Xu, Ana Licuanan and Ralph Weischedel.
2003.Trec 2003 qa at bbn: Answering definitional ques-tions.
In Proceedings of the 12th Text REtrievalConference, Gaithersburgh, MD, USA.Ming Li and Paul MB Vitanyi.
1997.
An Introduc-tion to Kolmogorov Complexity and Its Applications.Working Notes for the CLEF 2007 Workshop.M.
Li, J. Badger, X. Chen, S. Kwong, P. Kearney,H.
Zhang.. 2001.
An information-based sequencedistance and its application to whole mitochondrialgenome phylogeny.
Bioinformatics, 17:2.M.
Subbotin and S. Subbotin.
2001.
Patterns of Po-tential Answer Expressions as Clues to the Right An-swers.
In TREC-10 Notebook papers.
Gaithesburg,MD.R.
Cilibrasi, P.M.B.
Vit?anyi.
2007.
An Exploration ofthe Principles Underlying Redundancy-Based Fac-toid Question Answering.
EEE Trans.
Knowledgeand Data Engineering, 19:3, 370?383.Shen, Dan and Dietrich Klakow .
2006.
Exploring cor-relation of dependency relation paths for answer ex-traction.
In Proceedings of COLING-ACL, Sydney,Australia.Xian Zhang, Yu Hao, Xiaoyan Zhu, and Ming Li.
2007.Information Distance from a Question to an Answer.In Proceedings of the 13th ACM SIGKDD interna-tional conference on Knowledge discovery and datamining.49
