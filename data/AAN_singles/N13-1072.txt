Proceedings of NAACL-HLT 2013, pages 634?643,Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational LinguisticsAutomatic Generation of English RespellingsBradley Hauer and Grzegorz KondrakDepartment of Computing ScienceUniversity of AlbertaEdmonton, Alberta, Canada, T6G 2E8{bmhauer,gkondrak}@ualberta.caAbstractA respelling is an alternative spelling of aword in the same writing system, intended toclarify pronunciation.
We introduce the taskof automatic generation of a respelling fromthe word?s phonemic representation.
Our ap-proach combines machine learning with lin-guistic constraints and electronic resources.We evaluate our system both intrinsicallythrough a human judgment experiment, andextrinsically by passing its output to a letter-to-phoneme converter.
The results show thatthe respellings generated by our system arebetter on average than those found on the Web,and approach the quality of respellings de-signed by an expert.1 IntroductionRespellings are a widely employed method of con-veying the pronunciation of English and foreignwords, both in print and on the Web.
For example,Huatulco, the name of a Mexican resort, is respelledas ?wah-tool-koh?
in a travel guide (Noble, 2012).The advantage of using respellings lies in removingthe need for a separately defined phonetic transcrip-tion system.
Since they contain only the letters ofthe Latin alphabet, their phonetic interpretation re-lies exclusively on orthographic intuitions of read-ers.
For this reason, respellings are widely used intravel phrase books, medical compendia, and drugname pronunciation guides, among others.Despite their utility, good respellings are not easyto create.
Respellings found on the Web often con-tain errors or ambiguities.
For example, Henoch-Schoenlein purpura, a skin disease, is respelled bothas ?heh-nok shoon-line purr-puh-ruh?
and ?hen-awksher-line purr-purr-ah?.
Does ?heh?
rhyme with eh[e] or with Nineveh [@], or is it the same vowel asin hen [E]?
Clearly, if both respellings refer to thesame pronunciation, at least one of them must bewrong.
In addition, converting the pronunciation ofa foreign name to English phonemes is in itself anon-trivial task.In this paper, we focus on the task of generatingrespellings from the intended pronunciation given asa sequence of phonemes.
We develop a stand-alonesystem that combines linguistic knowledge and re-sources with machine learning models trained ondata mined from the Web and electronic dictionar-ies.
One of our ultimate objectives is to aid writ-ers by evaluating their respellings, improving them,or generating new candidates.
Accordingly, we en-deavour to maintain the generation and the evalua-tion stages as separate modules in our system.The evaluation of respellings is a challengingproblem.
Since English spelling conventions are no-toriously inconsistent, there is no algorithm for ac-curately predicting the pronunciation of an out-of-vocabulary word.
The current state-of-the-art letter-to-phoneme (L2P) converters are typically reportedwith 10-30% error rates on dictionary words (Bisaniand Ney, 2008).
On the other hand, human read-ers often disagree on the details of the pronunciationimplied by a respelling.
In this paper, we conducttwo kinds of evaluations: an automated verificationwith an independent L2P system, and an experimentwith human participants that pass judgments on dif-ferent respellings of the same word.
We interpretthe results as evidence that the output of our systemcompares favourably with typical respellings foundon the Web.6342 Definitions and ConventionsAlthough Chomsky and Halle (1968) characterizeEnglish orthography as close to optimal, Kominekand Black (2006) estimate that it is about 3 timesmore complex than German, and 40 times morecomplex than Spanish.
This is confirmed bylower accuracy of letter-to-phoneme systems on En-glish (Bisani and Ney, 2008).
A survey of Englishspelling (Carney, 1994) devotes 120 pages to de-scribe phoneme-to-letter correspondences, and lists226 letter-to-phoneme rules, almost all of which ad-mit exceptions.There is no consensus on how to best convey thepronunciation of an uncommon word in English.Most dictionaries employ either the InternationalPhonetic Alphabet (IPA), or their own transcriptionschemes that incorporate special symbols and dia-critics.
Unfortunately, many readers are unfamiliarwith phonetic transcription.
Instead, respellings areoften preferred by writers in the news and on theWeb.
In this section, we define the respelling task indetail.2.1 Form of RespellingsA respelling is a non-standard spelling of a word,that is intended to better convey its pronunciation.We assume that the pronunciation is defined as a se-quence of English phonemes, and that the respellingcontains only the 26 letters of the alphabet, withoptional hyphenation.
Some transcription schemescombine respellings with special symbols for repre-senting certain phonemes.
For example, an other-wise purely alphabetic Wikipedia scheme employsthe symbol @ for the vowel schwa.
In our opin-ion, such devices destroy the main advantage of re-spellings, which is their universality, without attain-ing the precision of a true phonetic transcription.
Infact, Fraser (1997) identifies the schwa symbol asthe cause of many pronunciation errors.In our system, we consistently use hyphens tosegment multi-syllable respellings.
Each syllable-size segment contains the representation of exactlyone vowel phoneme, so that the number of segmentsmatches the number of syllables.1 However, the hy-phenation need not correspond exactly to the actual1Henceforth, we refer to ?syllable-size segments?
simply as?syllables?.syllable breaks.
This approach has several advan-tages.
First, individual syllables are easier to pro-nounce than an entire unfamiliar word.
Second, hy-phens limit the context that affects the pronuncia-tion of a given letter (e.g.
th in Beethoven ?bayt-hoe-ven?).
Finally, hyphens indicate whether adja-cent vowel letters, such as oe in ?hoe?, represent onevowel phoneme or two.Some respellings explicitly indicate the stressedsyllable by expressing it in a different font.
This ispotentially helpful because unstressed vowels tendto be reduced, which changes their pronunciation.However, since the vowel reduction phenomenon isby no means universal, the readers may be unsurewhether to apply it to, e.g.
the final o in ?KWAT-ro?.
In this paper, we make no distinction betweenstressed and unstressed syllables; instead, we followthe principle that each syllable is to be pronouncedas if it was a separate word.
Nonetheless, it would bestraightforward to project the stress indicators ontothe appropriate syllables in the respellings generatedby our system.2.2 Quality of RespellingsThere is no clear-cut distinction between good andbad respellings.
The quality of a respelling is moreof a subjective opinion rather than a verifiable fact.We propose to evaluate it according to the follow-ing three criteria: ambiguity, correctness, and pref-erence.A respelling is ambiguous if it is perceived ascompatible with more than one pronunciation.
Be-cause most of the rules of English spelling have ex-ceptions, it is rarely possible to demonstrate thata respelling is completely unambiguous.
How-ever, some respellings are clearly more ambiguousthan others.
For example, the digraph ee almostalways represents the vowel [i], whereas the let-ter sequence ough can represent several differentphonemes.2 Respellings that contain highly ambigu-ous letter-phoneme mappings can be expected to beambiguous themselves.
Ambiguity is a property of arespelling itself, regardless of the intended pronun-ciation.A respelling is correct if it accurately conveys theintended pronunciation to the reader.
Unlike the am-2Compare bough, cough, dough, tough, lough, through.635biguity, correctness can be verified objectively fora particular reader, by comparing the intended pro-nunciation with the pronunciation inferred by thereader.
A respelling that is judged correct with re-spect to one pronunciation cannot be judged correctwith respect to a different pronunciation.
Never-theless, it is entirely possible that different readerswill derive different pronunciations from the samerespelling.A respelling can be classified as unambiguousand yet incorrect by a given reader, but it cannotbe judged as simultaneously ambiguous and cor-rect.
Indeed, an ambiguous respelling is compatiblewith at least two pronunciations, only one of whichcan be the intended pronunciation.
Therefore, fora given reader, unambiguity is a necessary but notsufficient condition for correctness.Given two unambiguous and correct respellings,a reader may prefer one over the other, perhaps be-cause of the ease of inferring the intended pronun-ciation.
For example, ?rode-ease-yew?
may be pre-ferred to ?roh-dee-zyoo?
because the former is en-tirely composed of actual English words with uniquepronunciation, whereas the latter contains an un-usual consonant cluster zy.
Preference is also ex-pressed implicitly if only one of the alternative re-spellings is judged as unambiguous (or correct),3 Related WorkFraser (1997) describes an experiment in which 15human subjects were asked to pronounce uncom-mon words after being shown a representation oftheir pronunciation.
The respellings designed by theauthor were much more effective for that purposethan either the IPA phonetic transcription or phone-mic respelling (Section 4.3).
However, the creationof respellings was described as labour-intensive, andat least one of them was found to be sub-optimal dur-ing the experiment.Williams and Jones (2008) propose respellings asa way of extending pronunciation lexicons by infor-mants who lack linguistic training.
Galescu (2009)reports that the addition of respellings of medicalterms from an on-line dictionary improves the ac-curacy of an L2P system.
The author identifies anautomatic pronunciation-to-respelling system as fu-ture work.Ghoshal et al(2009) extract a large number of re-spellings from the Web, and show that they can beexploited to improve the accuracy of the L2P con-version by supplementing the data in pronunciationdictionaries.
Can et al(2009) further analyze the ef-fect of using respellings on the accuracy of spoken-term detection (STD) systems.4 Direct MethodsIn this section, we discuss three direct methods ofgenerating respellings: manual design, dictionarylookup, and phonemic respelling.4.1 Manual DesignRespellings found on the Web and in news articlesare usually ad-hoc creations of the authors of thosetexts.
Respellings designed by different writers forthe same word are rarely identical.3 The quality ofWeb respellings vary.The respellings found in specialized lexicons aremore likely to be designed by experts, and are of-ten guided by a set of respelling rules.
Nevertheless,such respelling guides may also be ambiguous.4 Re-gardless of the source, since respellings are oftenused for names and foreign words, no lexicon canbe expected to provide a complete coverage.4.2 Dictionary LookupPronunciation dictionaries can be helpful in gener-ating respellings.
Assuming that we have a methodof dividing pronunciations into syllables, a completerespelling of an out-of-dictionary word can in somecases be automatically derived from the list of syl-lable pronunciations.
For example, hyphy can be re-spelled as ?high-fee?
by following such a procedure.If each of the syllables has a unique pronunciation,such respellings are arguably both unambiguous andcorrect.Unfortunately, only a subset of potential phone-mic syllables actually occur in a lexicon.
Consider-ing only the syllables of the CVC type (consonant-vowel-consonant), there are over ten thousand dis-tinct possibilities (e.g., [bEb], [bES], etc.
), of which3For example, the word capoeira is represented by 99 dif-ferent respellings in the corpus of Ghoshal et al(2009).4For an example of a confusing respelling guide see http://www.ama-assn.org/go/usan.636fewer than three thousand can be found in the Com-bilex pronunciation dictionary (Richmond et al2009).
While the dictionary lookup may produceattractive respellings, it is not sufficient for a stand-alone use.4.3 Phonemic RespellingA simple method that can produce a respelling forany word is to directly map each phoneme to a par-ticular letter or a letter sequence that is frequentlyused to represent that phoneme.
Phonemes such as[m], [d] and [f] are indeed closely associated with in-dividual letters.
This is not surprising since the Ro-man letters were originally created to represent sin-gle phonemes in Latin, and some of those phonemesalso exist in English.
However, many phonemes, es-pecially vowels, have no obvious orthographic rep-resentation.
One solution is to use digraphs such asee and aw, but a number of phonemes, such as [aU]as in loud, have no mappings that work in all con-texts.The principal weakness of a phonemic respellingis its inflexibility, which often results in counter-intuitive respellings.
For example, many readers arebaffled by respelling such as ?gee?
for ghee or ?john?for Joan.
Phonemic respelling tends to fail in caseswhere it generates a sequence of letters that is inher-ently ambiguous, or which pronunciation changesbecause of the context.
On the other hand, mappingssuch as uu for [U] and ahy for [aI], which never oc-cur in real English words, are difficult to interpretfor some readers.In this paper, we adopt a context-free phonemicrespelling scheme as the baseline, with the mappingsfrom the online dictionary Dictionary.com, whichdiffers from the system used in Wikipedia only ina few details.5 Candidate GenerationIn this section, we present our syllabification ap-proach, as well as two generation modules: a trainedphoneme-to-letter (P2L) model and a rule-based re-speller.5.1 SyllabificationOur respelling generation process is for the mostpart performed on the level of individual syllables.VOWEL ONSET LAX CODAnt *nd@n *b?
*d@nm *b?nTable 1: Examples of syllables that violate phonotacticconstraints.Correct syllabification is by itself a non-trivial prob-lem, but even if it was provided by an oracle, it mightnot correspond to the optimal segmentation of a re-spelling.
For example, the word trigonal [trIg@n@l]is usually syllabified as tri-go-nal, but a better seg-mentation for the purposes of respelling is trig-on-al.
We adopt an overgenerate-and-rank approach,whereby instead of committing to a specific wordsegmentation at the start of the process, we processmultiple syllabification alternatives in parallel, oneof which is ultimately selected at the respelling eval-uation stage.Ideally, syllabification should conform to thephonotactic constraints of English, so that the result-ing respellings are easy to pronounce.
The conso-nant sonority should be rising in onsets, and fallingin codas (Kenstowicz, 1994).
We verify that sylla-bles follow the sonority principle by following theformulation of Bartlett et al(2009).
The sonor-ity constraints are not tested at the boundaries ofthe word, which are independent of the syllabifica-tion choice.
We also incorporate another importantprinciple of English phonotactics that asserts thatlax vowels do not occur in open syllables (Rogers,2000).In our implementation, each candidate syllable istested with respect to the following sequence of fourviolable constraints, ordered from the strongest tothe weakest: (1) the syllable contains exactly onevowel phoneme; (2) the onset satisfies the sonorityprinciple; (3) if the nucleus contains a lax vowel (ex-cept @), the coda is non-empty; (4) the coda satis-fies the sonority principle.
For a syllabification to beaccepted, all its syllables must satisfy the four con-straints.
However, if this results in rejection of allpossible syllabifications, the constraints are gradu-ally relaxed starting from the weakest.637As an example, consider the word abandonment[@b?nd@nm@nt], which has 18 different syllabifica-tions satisfying the VOWEL constraint (Table 1).
8of the 18 satisfy the ONSET constraint as well, butonly two syllabifications satisfy all four constraints:[@b-?n-d@n-m@nt] and [@-b?n-d@n-m@nt].5.2 P2L GeneratorThe respelling problem can be viewed as a stringtransduction problem, with the transduction occur-ring between phonemes and letters.
As such, it is di-rectly related to the well-studied letter-to-phonemeconversion task.
The difference is that the lettersmay not conform to the standard orthography ofEnglish.
If we had a sufficiently large training setof pronunciation-respelling pairs, we could train amachine learning algorithm to directly generate re-spellings for any strings of English phonemes.
How-ever, such a training set is not readily available.
Therespellings in the corpus collected by Ghoshal et al(2009) are not easily matched to the phonetic tran-scriptions, and few of them can be found in elec-tronic pronunciation dictionaries.
In addition, thequality of Web respellings vary greatly.In place of a direct pronunciation-to-respellingmodel, we aim to model the orthographic intuitionsof readers by deriving a phoneme-to-letter (P2L)transduction model from an English pronunciationdictionary.
A possible criticism of such an approachis that our model may create ambiguous respellings,which abound in English orthography.
However, werely on a separate evaluation module to identify andfilter ambiguous respellings at a later stage.Our systems utilizes the DIRECTL+ program (Ji-ampojamarn et al 2008), which was originally de-signed for L2P conversion.
Since our basic unit isthe syllable, rather than the word, we train our P2Lmodel on a set of of 4215 pairs of monosyllabicwords and their pronunciations extracted from theCombilex dictionary.
We exclude syllables in multi-syllabic words from training because their pronunci-ation is often affected by context.
This is consistentwith our expectation that the reader will pronounceeach hyphen-delimited segment of the respelling asif it was an individual word.Since the P2L training data consists of a relativelysmall set of syllables, we ensure that the phoneme-letter alignment is highly accurate.
As a preprocess-ing step, we replace the letter x with ks, and we con-vert digraphs, such as ch and th, to single symbols.The alignment is performed by M2M-ALIGNER (Ji-ampojamarn et al 2007), under the restriction thateach phoneme is matched to either one or two lettersymbols.5.3 Context-Sensitive RespellerA hand-crafted context-sensitive respeller is in-tended to complement the trained P2L model de-scribed in the previous section.
It is similar to tothe phonemic respelling approach described in Sec-tion 4.3 in that it converts each phoneme to a lettersequence.
However, the mappings depend on adja-cent phonemes, as well as on the CV pattern of thecurrent syllable.
In addition, more than one map-ping for a phoneme can be proposed.
We designedthe mappings by analyzing their frequency and con-sistency in pronunciation dictionaries.The process of candidate generation involves es-tablishing the pattern of consonants in the input syl-lable.
The consonant mappings are the same as inthe baseline, except for [?]
and [T], while the vowelsyield up to three different letter sequences.
For ex-ample, [o] is mapped to oh as a default, but also to oif both onset and coda are empty, or to o followed bya consonant and a silent e if the coda is composed ofa single consonant.
So, given the syllable [tok] as in-put, the respeller produces two candidates: tohk andtoke.We make no claims about the completeness or op-timality of the mappings, but in our developmentexperiments we observed that the context-sensitiverespeller contributes to the robustness of our sys-tem, and in some cases produces more attractive re-spellings that the P2L model.6 Candidate SelectionWe aim at developing a stand-alone method for theassessment of respellings that could be applied re-gardless of their origin.
We consider two criteria:correctness, which is evaluated against the intendedpronunciation, and ambiguity, which is a property ofthe respelling itself.
As was the case in the genera-tion stage, the evaluation is performed at the level ofsyllables.6386.1 L2P Correctness FilterThe principal method of verifying the correctnessof a respelling involves the application of a letter-to-phoneme (L2P) model trained on the word-pronunciation pairs extracted from an English dic-tionary.
The generated pronunciation of each sylla-ble is compared against its intended pronunciation;if any of the syllables fail the test, the entire re-spelling is rejected.The L2P model is derived using the DIRECTL+system.
The main difference between the L2P modeldescribed in this section and the P2L model fromSection 5.2 is that the input and output data are re-versed.
However, the L2P model is not simply a mir-ror image of the P2L model.
Often the phonemicoutput of the composition of the two models is dif-ferent from the initial phonemic input; e.g., [ro] ?row?
[raU].
This is because the intermediate ortho-graphic string may be ambiguous.
Furthermore, theL2P model is also intended to test the correctness ofrespellings that were generated with other methods.Other differences between the two models per-tain to the preprocessing of the training data, andthe letter-to-phoneme alignment.
As with the P2Lmodel, the training data consists of a set of mono-syllabic words from the Combilex dictionary.
How-ever, in order to make our correctness filter moreconservative, we also remove all words that con-tain diacritics (e.g., cr?pe), non-English phonemes(e.g., avant), or silent consonants (e.g., limn).
Thealignment is restricted to matching each letter sym-bol to at most one phoneme, and is derived withthe ALINE phonetic aligner (Kondrak, 2000), whichhas been shown to outperform other 1-1 alignmentmethods (Jiampojamarn and Kondrak, 2010).6.2 Vowel CounterSyllables that contain multiple vowel groups may beconfusing to readers even if they correctly representthe intended pronunciation.
For example, readersmight be unsure whether takess represents one ortwo syllables.
A simple vowel counter is providedto filter out such syllables.
The vowel filter acceptsa syllable only if (a) it contains exactly one vowelgroup (e.g., moe), or (b) the second vowel groupconsists of a single e at the end of the syllable (e.g.,zake).6.3 SVM Ambiguity ClassifierThis module is designed to compute a score that re-flects the ambiguity of an orthographic syllable.
Theambiguity score of a respelling is defined as the av-erage of scores assigned to each of its syllables.
Thescore can then be used to select the best respellingfrom a number of candidates generated by our sys-tem, or to rate a respelling from another source.Since we have no explicit ambiguity annotationsfor respellings, we attempt instead to exploit ambi-guity judgments that are implicitly made when re-spellings are created by human authors.
We ap-proach ambiguity as a binary classification task.
Forany given syllable, we wish to determine whether itis ambiguous (a negative instance), or unambiguous(a positive instance).
Our assumption is that a sylla-ble will not be respelled unless it is necessary dueto ambiguity.
For each observed word-respellingpair, we take all syllables from the respelling as pos-itive instances, and all syllables in the original wordthat are not preserved in the respelling as negativeinstances.
For example, the pair consisting of theword cec-il-y respelled as ?sehs-il-ee?
provides threepositive instances: sehs, il and ee; and two negativeinstances: cec and y.We extracted word-respelling pairs from the Web-derived corpora of Ghoshal et al(2009).
The syl-lable breaks in the respellings were mapped ontothe original words using ALINE.
In order to im-prove the quality of the data, we applied a letter-to-phoneme model to both the original words andtheir respellings, and removed pairs with divergentpronunciations (computed as normalized edit dis-tance ?
0.8).
After the filtering, we were left aset of 25067 word-respelling pairs containing 78411training syllables, which yielded 47270 positive and31141 negative instances.For the classification task we utilize the SVM-light software package (Joachims, 1999).
Each in-stance is represented by a set of binary indicator fea-tures.
The features correspond to character n-grams(including syllable boundary markers) with the val-ues of n ranging from 1 to 5.
For example, the syl-lable -il- turns on the following features: i, l, -i, il,l-, -il, il-, -il-.
The model learns which n-grams arecharacteristic of ambiguous or unambiguous sylla-bles.
For example, it classifies both le and li as am-639biguous, and lee as unambiguous.
Apart from thebinary classification, the classifier also provides areal-valued score for each syllable.6.4 Lexical ReviserSince the use of familiar English letter sequencesmakes the respellings easier to interpret (Fraser,1997), we incorporate dictionary lookup (Section4.2) into our system.
When the pronunciation of asyllable happens to correspond to the pronunciationan actual dictionary word, the syllable may be re-spelled using that word.
This is done as the final stepin the generation process because dictionary wordsoften receive poor scores from the SVM classifier onthe account of their n-gram composition.
The lexi-cal reviser is restricted to optionally improving thetop-ranked word respelling candidate as determinedby the SVM classifier without altering its syllabifi-cation.
For example, the respelling ?surr-sin-uss?
ofcircinus is modified to ?sir-sin-us?.
If more than oneword can be used, we let the SVM classifier selectthe least ambiguous one.7 System OverviewOur respelling generation system is a multi-stageprocess.
The input is a sequence of phonemes rep-resenting the pronunciation of the word.
We start byidentifying acceptable syllabifications of phonemesas described in Section 5.1.
For each syllable, wetake up to five respelling candidates produced bythe P2L model (Section 5.2), and between one andthree candidates proposed by the context-sensitiverespeller (Section 5.3).
The next stage involves fil-tering the candidate respellings with the L2P model(Section 6.1), and the vowel counter (Section 6.2).If all candidates happen to be rejected, we retain thefirst output of the context-sensitive respeller as thedefault.
The candidate respellings are then scoredby the SVM model (Section 6.3).
At this point thesyllables are combined into word respellings, whichare ranked according to their syllable score average.Finally, the lexical reviser described in Section 6.4 isapplied to the top candidate in an attempt to furtherimprove the result.8 EvaluationIn this section, after describing our test sets, wepresent the results of two evaluation experiments:direct human judgment, and indirect validation withan L2P system.8.1 Test SetsOur two test sets were defined after the developmentof our system had been completed.
There is no over-lap between the test sets and any of our training sets.The first test set consists of 27 out of 30 words com-piled by Fraser (1997) ?
3 words from the origi-nal set were excluded because the corresponding re-spellings assume a non-rhotic variety of English.
Werefer to Fraser?s respellings as expert, and considerthem as the upper bound in terms of quality.The second test set of 231 words (henceforth re-ferred to as the Web set) was extracted from thecorpus of Ghoshal et al(2009) after performingadditional data clean-up described in Section 6.3.We identified a subset of words for which wecould find phonetic transcriptions composed of En-glish phonemes on Wikipedia.
In order to ensurethat the respellings and the corresponding transcrip-tions reflect the same pronunciation, we adapted theSoundex algorithm to apply to phonetic transcrip-tions, and retained only the respelling/transcriptionpairs that yielded identical Soundex codes.
We re-moved words that are found in the Combilex dic-tionary as those could be familiar to human judges.Since longer words are more challenging to respell,and more likely to exhibit variation in respellingsfrom different sources, we retained only words con-taining at least eight phonemes.8.2 Human JudgmentWe conducted an experiment with human evalua-tors using a specially developed graphical annota-tion program with synthesized word pronunciations.The evaluators were students enrolled in an intro-ductory linguistic course, who were not involved inour project.
13 out of 20 evaluators declared them-selves as native speakers of English.The evaluation process involves 40 randomly se-lected words: 10 from Fraser?s set, and 30 from theWeb set.
For each word, the program displays in arandom sequence three respellings, which are from640Source Web set Fraser?s setU U&C U U&CBaseline 43.0 25.5 41.0 20.0Web 68.0 32.6 ?Expert ?
72.0 46.0Our system 70.0 41.3 67.0 38.5Table 2: Human judgments on respellings in %: U -unambiguous; U&C - unambiguous & correct.the following sources: (1) the Baseline approach de-scribed in Section 4.3, (2) our system, and (3) ei-ther expert design (for Fraser?s set) or the Web (forthe Web set).
In order to reduce bias, the origi-nal spelling of the word is not shown.
Each re-spelling is judged separately with regards to ambi-guity, and those that are judged ambiguous are re-moved from further consideration.
Next, an audioclip synthesized from the phonemic sequence repre-senting the intended pronunciation is played throughheadphones.
For each of the remaining respellings,the evaluators decide whether it is correct with re-spect to the recorded pronunciation.
Finally, if morethan one respelling have been judged both unam-biguous and correct, the evaluators are asked to iden-tify the one that they prefer.The results of the experiment are shown in Ta-ble 2.
Our system significantly outperforms bothWeb respellings and the Baseline approach in termsof unambiguity and correctness.
In addition, the re-spellings produced by our system are more likely tobe preferred over the Web respellings, and more thantwice as likely to be preferred over the baseline re-spellings than vice versa.
The results on the smallFraser?s set are less conclusive, but suggest that interms of overall quality our system is much closer tothe upper bound than to the baseline.8.3 Automated AppraisalHuman evaluation is expensive and limited in termsof the number of variant respellings.
Moreover, hu-man judgements may be biased by previously seenrespellings or by the familiarity with the standardspelling of a word.
An automated evaluation is muchless constrained, and facilitates an ablation study todetermine the relative importance of various compo-nents of our system.Source Web set Fraser?s setWA PA WA PANo respelling 13.0 76.2 14.8 76.3Baseline 8.2 78.9 7.4 71.0Web 14.3 77.9 ?Expert ?
37.0 85.6Our system 58.0 93.0 70.4 95.6Table 4: Word accuracy (WA) and phoneme accuracy(PA) of eSpeak on respellings.Source Web setWA PAFull system 58.0 93.0w/o lexical reviser 57.6 93.1w/o context-sensitive respeller 56.7 92.8w/o P2L generator 51.9 92.1w/o L2P correctness filter 33.8 88.0w/o syllable breaks 20.8 83.9Table 5: Accuracy of eSpeak on respellings produced byvariants of our system.eSpeak is a publicly available speech synthesizer5that can also convert text into phonemic sequences.The letter-to-phoneme component for English uti-lizes about five thousand rules, and a dictionary ofabout three thousand words, names, and abbrevia-tions.
In our evaluation, we treat eSpeak as a ?blackbox?
which translates a respelling into its most likelypronunciation.
By determining if there is a matchbetween the output of eSpeak and the intended pro-nunciation, we directly test the correctness of the re-spelling, and indirectly also its ambiguity.The results of the automated evaluation are shownin Table 4.
The accuracy on the original orthogra-phy is low, which is unsurprising since the test setscontain mostly rare, unusually spelled words.
Nei-ther the baseline nor the Web respellings are sig-nificantly easier for eSpeak than the original words.On the other hand, respellings generated by our sys-tem make a massive difference, boosting phonemeaccuracy to well over 90% on both sets.
They arealso significantly more effective than the expert re-spellings.Table 5 shows the results of our system on the5http://espeak.sourceforge.net641No.
Spelling IPA Web/HF respelling Score System respelling Score1 Incirlik [in?irlik] injirlik 1/6 een-jeer-leek 4/62 Captopril [k?pt@prIl] kap-toh-pril 1/6 cap-tuh-prill 4/63 Coquitlam [kokwItl@m] ko-kwit-lam 1/6 koh-quit-lumb 4/64 Karolina [kArOlinA] karo-leena 4/6 car-awl-ee-nah 1/65 subluxation [s@bl@kseS@n] sub-luck-say-shun 3/5 suh-bluck-say-shun 1/56 swingle [swINg@l] swing-gl 0/5 swing-gull 2/57 cockatrice [kAk@traIs] kok-a-trice 0/7 cock-uh-trice 4/78 recalesce [rik@lEs] ree-ka-less 1/5 re-cull-ess 3/59 jongleur [ZANgl@r] jong-gler 7/9 zhahng-gler 0/910 ylang-ylang [il?Nil?N] ee-lang-ee-lang 5/5 eel-ang-eel-ang 1/5Table 3: Examples of respellings.Web set with various modules disabled, which pro-vides an estimate of their importance.
Neitherthe context-sensitive respeller nor dictionary lookupseem to contribute much to eSpeak?s performance.On the other hand, disabling the P2L generator pro-duces a significant drop in word accuracy, while re-moving the L2P correctness filter almost doubles thephoneme error rate.
Interestingly, removing syllablebreaks from the output of the full system has an evengreater negative impact.8.4 AnalysisEach of 20 evaluators judged 3 variant respellingsof 40 different words.
The average number of judg-ments per word was 7.4 for the 27 words in Fraser?sset, and 2.8 for the 212 words in the Web set (due torandom selection, 19 words from the Web set werenot judged).
Table 3 shows examples of respellingsthat were judged by at least five evaluators.
Thescore columns indicate the proportion of the evalu-ators that judged a particular respellings as unam-biguous and correct.
The baseline respellings arenot included as their scores were rarely higher thanthe scores of the other respellings for a given word.An interesting exception is palimpsest, for which thebaseline respelling is identical to the actual spellingof the word.Examples 1-5 in Table 3 come from the Web set,while examples 6-10 are from Fraser?s set.
Thelow scores of the first three Web respellings can beattributed to specific letter-to-phoneme mappings:[i]?i, [@]?oh, and [@]?a.
Each of the examples3-5 indicate the evaluators?
acceptance of a partic-ular respelling device: silent letters, multi-syllableunits, and dictionary words.
In examples 6-8, thesyllables immediately after the first hyphen in HelenFraser?s respellings seem to be problematic.
The ex-pert respelling of jongleur is considered correct eventhough the initial j suggests [?
], not [Z].
Finally,the last example demonstrates that the hyphenationchoice can result in very different judgments.9 ConclusionIn this paper, we introduced the task of automati-cally generating respellings from the given pronun-ciation.
We investigated the characteristics of goodrespellings, and discussed three direct methods oftheir creation.
We proposed a system that combinessupervised and unsupervised learning with phoneticand orthographic principles.
The evaluation experi-ment involving human participants indicates that therespellings produced by our system are better on av-erage than those found on the Web.
The automatedverification demonstrates that they are also mucheasier to interpret for a rule-based text-to-speechconverter.
In the future we plan to address the re-lated tasks of improving existing respellings, and as-sisting writers in creating respellings without directaccess to the phonemic representations.AcknowledgementsWe thank Aditya Bhargava and Clarke Chomyc fortheir contribution to the creation of data sets, andBen Tucker for advice on the complexities of the hu-man evaluation experiment.
This research was par-tially funded by the Natural Sciences and Engineer-ing Research Council of Canada.642ReferencesSusan Bartlett, Grzegorz Kondrak, and Colin Cherry.2009.
On the syllabification of phonemes.
In Proc.of HLT-NAACL, pages 308?316.Maximilian Bisani and Hermann Ney.
2008.
Joint-sequence models for grapheme-to-phoneme conver-sion.
Speech Communication, 50(5):434?451.Dog?an Can, Erica Cooper, Arnab Ghoshal, Martin Jan-sche, Sanjeev Khudanpur, Bhuvana Ramabhadran,Michael Riley, Murat Sara?lar, Abhinav Sethy, Mor-gan Ulinski, and Christopher White.
2009.
Web de-rived pronunciations for spoken term detection.
InProc.
of ACM SIGIR, pages 83?90.Edward Carney.
1994.
A Survey of English Spelling.Routledge.Noam Chomsky and Morris Halle.
1968.
The SoundPattern of English.
New York: Harper & Row.Helen Fraser.
1997.
Dictionary pronunciation guidesfor English.
International Journal of Lexicography,10(3):181?208.Lucian Galescu.
2009.
Extending pronunciation lexi-cons via non-phonemic respellings.
In Proc.
of HLT-NAACL: Short Papers, pages 129?132.Arnab Ghoshal, Martin Jansche, Sanjeev Khudanpur,Michael Riley, and Morgan Ulinski.
2009.
Web-derived pronunciations.
In Proc.
of ICASSP, pages4289?4292.Sittichai Jiampojamarn and Grzegorz Kondrak.
2010.Letter-phoneme alignment: An exploration.
In Proc.of ACL, pages 780?788.Sittichai Jiampojamarn, Grzegorz Kondrak, and TarekSherif.
2007.
Applying many-to-many alignmentsand hidden Markov models to letter-to-phoneme con-version.
In Proc.
of HLT-NAACL, pages 372?379.Sittichai Jiampojamarn, Colin Cherry, and GrzegorzKondrak.
2008.
Joint processing and discriminativetraining for letter-to-phoneme conversion.
In Proc.
ofACL, pages 905?913.Thorsten Joachims.
1999.
Making large-scale SVMlearning practical.
In B. Schalkopf, C. Burges, andA.
Smola, editors, Advances in Kernel Methods - Sup-port Vector Learning.
MIT Press.Michael Kenstowicz.
1994.
Phonology in GenerativeGrammar.
Blackwell.John Kominek and Alan W Black.
2006.
Learningpronunciation dictionaries: Language complexity andword selection strategies.
In Proc.
of HLT-NAACL,pages 232?239.Grzegorz Kondrak.
2000.
A new algorithm for the align-ment of phonetic sequences.
In Proc.
of NAACL, pages288?295.John Noble.
2012.
Mexico.
Lonely Planet, 13th edition.Korin Richmond, Robert Clark, and Sue Fitt.
2009.
Ro-bust LTS rules with the Combilex speech technologylexicon.
In Proc.
of Interspeech, pages 1295?1298.Henry Rogers.
2000.
The Sounds of Language.
Pearson.Briony Williams and Rhys James Jones.
2008.
Acquir-ing pronunciation data for a placenames lexicon in aless-resourced language.
In Proc.
of LREC.643
