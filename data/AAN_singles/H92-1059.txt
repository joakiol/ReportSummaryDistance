SESSION 9: NATURAL LANGUAGE PROCESSINGSKathleen McKeown, ChairDepartment of Computer ScienceColumbia UniversityNew York, N.Y. 10027Traditional approaches tointerpretation in natural languageprocessing typically fall into one of three classes: syntax-driven, semantics-driven, or frame/task based.
Syntax-driven approaches use a domain-independent grammar todrive the interpretation process and produce a global parseof the input, accounting for each word of the sentence.Semantics-driven approaches use knowledge about thecase frames of the verbs to drive the interpretation process.Early semantic parsers often ignored syntax altogether\[1, 2\] although more recent systems tend to integrate thetwo components whether primarily syntax or semanticsdriven (e.g., \[3\]).
Frame or task based parsers use infor-marion in the underlying domain to guide the parse.
Scriptbased parsers are one example of this class \[4\].
A morerecent example was presented at last year's DARPAWorkshop \[5\].
These systems use the underlying ATISdomain frame that must be built to form a database queryto guide the parse, relying on key words and templates toidentify information i the sentence that can fill slots of theframe.Any one of these approaches, however, has drawbacks forthe spoken language systems and large text understandingsystems being developed today.
These systems must berobust.
Spoken input is often ungrammatical and speakersuse words that are unknown to the system.
Text under-standing systems must be able to process large quantifiesof novel text which are likely to contain syntactically com-plex sentences, ungrammatical sentences, and unknownwords.
Given the large number of novel sentences thatboth types of systems encounter, extragranunaticality (i.e.,sentences that are grammatical but fall outside the scope ofthe system grammar) is also an issue.
While syntax-drivensystems have the advantage of domain independence andprovide useful information for further analysis, they areunable to handle ungrammatical sentences since they mustproduce a complete parse of the sentence.
Both semantics-driven and frame-based systems have the advantage ofbe-ing able to handle ungrammatical nd extragranunaticalsentences, but they break down on more complex sen-tences and are not easily transferrable tonew domains.
Allthree approaches fail when unknown words are encoun-tered.The first four papers in this session present three languageunderstanding systems that address these problems.
Theseare the MIT ATIS system ("A Relaxation Method for Un-derstanding Spontaneous Speech Utterances" by SeneffLthe BBN DELPHI system ("Fragment Processing in theDELPHI System" by Stallard and Bobrow and"Syntactic/Semantic Coupling in the BBN DELPHI Sys-tem" by Bobrow, Ingria, and Stallard.
These two paperswere combined into one presentation), and BBN PLUM("A New Approach to Text Understanding" by Weis-chedel, Ayuso, Boisen, Fox, and Ingria).
The first two ofthe systems are spoken language systems, while BBNPLUM is designed to extract dam from text.
All fourpapers include an evaluation of their methods.
The finalpaper in the session presents a new approach to evaluationthat does not involve testing through task application.The three systems take a remarkably similar approach todeveloping robust echniques involving integration of thetraditional pproaches ina single framework.
All three sys-tems are primarily syntax-driven, but have modified theirparsers to allow for the production of partial parses, orfragments.
BBN DELPHI extracts most likely partialparses from its chart, MIT ATIS allows for relaxation ofconstraints when a full parse cmmot be produce, and BBNPLUM uses a modified version of a Marcus determhfistieparser where constituents do not need to be attached to aparent node.
All three systems use frame or event basedknowledge to combine the fragments into a single inter-pretation.
BBN DELPHI and MIT ATIS both use theATIS frames or templates to guide this task.
BBN PLUMuses knowledge of common events in the domain.
Integra-tion of semantics (i.e., knowledge of verb case frames) andsyntax also plays a role in BBN DELPHI.
Semantics isused to reduce the application of plausible syntactic rulesby selecting only those rules that produce semantically ac-ceptable interpretations.
Case frames are also used to ruleout implausible fragments in both BBN DELPHI and BBNPLUM.
Finally, both BBN systems also integrateprobabilistic language models.
For example, statisticalmodels of the likelihood of each syntactic rule are used toselect he partial parses that are most likely.MIT ATIS and BBN DELPHI showed through analysis ofthe DARPA ATIS evaluation that robusqfallback parsingsubstantially improved their results.
BBN PLUM wasevaluated through two additional experiments in additionto the MUC-3 evaluation.
Their additional experimentsshowed that recall grows linearly with lexicon size, whileprecision remains flat.
These experiments support theirclaim that porting to a new domain can be achieved rela-tively easily.The final paper in this session ("Neal-Montgomery NLPSystem Evaluation Methodology" by Walter) presents avery controversial new approach to evaluation, as sub-sequent discussion showed.
Waiter's claim is that task-based evaluation methodologies are too man-power inten-sive, requiring excess expense mad thne when porting to anew domain.
Furthermore, due to inadequacies in both the297port and in the evaluation metrics, current evaluationmethodologies do not reveal an accurate picture of systempotential.
She reports on an evaluation methodologydeveloped by Neal and Montgomery that provides adescriptive profile of a system's linguistic capabilities.This methodology involves the development of ascorecard, in which each linguistic feature is defined.
Sys-tems are then scored against this list of features by ahuman evaluator who checks whether the system couldsuccesfully produce output when provided with a sentencecontaining a specific linguistic feature.
While Walter in-dicates that linguistic features can be syntactic, semantic,pragmatic, or lexical, it should be noted that most of thefeatures listed in the example scorecard in the paper aresyntactic (e.g., what-questions, what as determiner, what aspronoun, who-questions both with verb and with DO, etc.
).The final session discussion focused entirely on theproposed Neal-Montgomery Evaluation techniques, withmany pointing out flaws and inconsistencies in the ap-proach.
Several points seemed to emerge repeatedly.Many felt that the evaluation could be not be used forsystem comparison.
Systems work on different asks anddifferent domains.
Whether a particular linguisticphenomena can even be tested depends on whether it isused within that domain.
For example, Hobbs pointed outthat the SRI parser tested using this approach failed onimperatives, despite the fact that its parser had extensivecoverage of imperatives.
The problem was that imperativesentences were not used in the terrorist domain on whichthe system now works and therefore the evaluator couldnot think of an imperative sentence for the test.
The widemargin of disagreement among evaluators (20-100%) overwhether a given system could or could not handle a givenfeature was noted and this raised questions about he valueof the methodology.Many felt that evaluation of free-grained linguisticphenomena simply could not be done using a black boxevaluation.
When a sentence fails, it is not possible to tellwhat caused it.
People pointed out that failure could bedue to interaction between the linguistic feature beingtested and other linguistic features, to other linguistic fea-tures in the sentence, or to interaction between linguisticprocessing and task based processing (e.g., for some tasksit is not necessary to record possessives and thus from theoutput one cannot ell whether the system handles them).Moreover, success could be due to quirks and ad hocprocedures, thus raising the question of whether black boxmethodology tests anything at all about syntactic process-ing.
In contrast, people felt that the methodology could beuseful for glass box evaluation.
Developers could use thecheck list internally while constructing a parser for inter-mediate benchmarks.
The extensive nature of the list ofphenomena identified by Neal and Montgomery was citedas a positive aspect.
However, even so, people felt the listdoes not account for interactions between the linguisticfeatures listed.
Many noted that interaction between lin-guistic phenomena is probably the most difficult part ofparser development.
There were some who saw the needfor a more descriptive approach to evaluation and an ap-peal was made to involve those who know about evalua-tion to get involved in order that a good evaluation systemcould result.1.2.3.4.5.REFERENCESHendrix, G. G., "Human engineerhag for applied naturallanguage processing", Proceedings of the Fij~h Inter-national Joint Conference on Artificial Intelligence, Mor-gan Kaufmann, Los Altos, CA, 1977.Schank, R. C. and Riesbeck, C. K., Inside ComputerUnderstanding, Lawrence Erlbaum Associates, Hillsdale,New Jersey, 1981.Woods, W. A., "Cascaded ATN grammars", AmericanJournal of Computational Linguistics, Vol.
6, No.1, 1980.Schank R. C. and Abelson, R. P., Scripts, Plans, Goalsand Understanding, Lawrence Erlbaum Associates,Hillsdale, New Jersey, 1977.Jackson, E., Appelt, D., Bear, J., Moore, R., and Pod-lozny, A., "A Template Matcher for Robust NL Inter-pretation", Proceedings DARPA Speech and NaturalLanguage Workshop, Asilomar, Ca., 1991, pp.
190-194.298
