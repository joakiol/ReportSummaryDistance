Linear Context-Free Rewriting Systems and Deterministic Tree-WalkingTransducers*David J. WeirSchool of Cognitive and Computing SciencesUniversity of SussexFalmer, Brighton BN1 9QHdavidw @ cogs.
sussex, ac.
ukAbst rac tWe show that the class of string languages gener-ated by linear context-free r writing systems is equalto the class of output languages of deterministic tree-walking transducers.
From equivalences that have pre-viously been established we know that this class of lan-guages is also equal to the string languages generatedby context-free hypergraph grammars, multicompo-nent tree-adjoining grammars, and multiple context-free grammars and to the class of yields of images ofthe regular tree languages under finite-copying top-down tree transducers.In t roduct ionIn \[9\] a comparison was made of the generative capac-ity of a number of grammar formalisms.
Several werefound to share a number of characteristics (describedbelow) and the class of such formalisms was called lin-ear context-free r writing systems.
This paper showshow the class of string languages generated by linearcontext-free r writing systems relates to a number ofother systems that have been studied by formal lan-guage theorists.
In particular, we show that the classof string languages generated by linear context-freerewriting systems is equal to the class of output lan-guages of deterministic tree-walking transducers \[1\].A number of other equivalences have already beenestablished.
In \[10\] it was shown that linear context-free rewriting systems and multicomponent tree ad-joining grammars \[6\] generate the same string lan-guages.
The multiple context-free grammars of \[7\] areequivalent to linear context-free systems.
This follows*I would like to thank Joost Engelfriet for drawing myattention to context-free hypergraph grammars and theirrelationship to deterministic tree-walking automata.from the fact that multiple context-free grammars areexactly that subclass of the linear context-free r writ-ing systems in which the objects generated by thegrammar are tuples of strings.
The class of outputlanguages of deterministic tree-walking transducers iknown to be equal to the class of yields of images of theregular tree languages under finite-copying top-downtree transducers \[4\] and in \[3\] it was shown that it alsoequal to the string languages generated by context-freehypergraph grammars \[2, 5\].We therefore have a number of Characterizations ofthe same class of languages and results that have beenestablished for the class of languages associated withone system carry over to the others.
This is particu-larly fruitful in this case since the output languages ofdeterministic tree-walking transducers have been wellstudied (see \[4\]).In the remainder of the paper we describe linearcontext-free r writing systems and deterministic tree-walking transducers and outline the equivalence proof.We then describe context-free hypergraph grammarsand observe that they are a context-free r writing sys-tem.L inear  Context -F ree  Rewr i t ing  Sys temsLinear context-free rewriting systems arose from theobservation that a number of grammatical formalismsshare two properties.1.
Their derivation tree sets can be generated by acontext-free grammar.2.
Their composition operations are size-preserving,i.e., when two or more substructures are com-bined only a bounded amount of structure isadded or deleted.136Examples of formalisms that.
satisfy these condi-tions are head grammars \[8\], tree adjoining gram-mars \[6\], multicomponent tree adjoining grammars \[6\]and context-free hypergraph grammars.
It wasshown \[9\] that a system satisfying the above conditionsgenerates languages that are semilinear and can berecognized in polynomial time.
The definition of lin-ear context-free rewriting systems is deliberately notspecific about the kinds of structures being manipu-lated.
In the case of head grammars these are pairs ofstrings whereas tree adjoining grammars manipulatetrees and context-free hypergraph grammars manipu-late graphs.In \[9\] size-preserving operations are defined for ar-bitrary structures in terms of properties of the cor-responding functions over the terminal yield of thestructures involved.
The yield is taken to be a tupleof terminal strings.
We call the function associatedwith a composition operation the y ie ld  funct ion  ofthat operation.
The yield function of Of of a com-position operation f gives the yield of the structuref (c l , ldots,  cn) based on the yield of the structuresel, ?
?
.
,  am.Let ~ be an alphabet of terminal symbols, f is ann-ary l inear  regu lar  operat ion  over tuples of stringsin ~ if it can be defined with an equation of the formf((xl,1,.
.
.
,  xl,k,),.. .
,  (ran,l,..., xn,k,,)) ---- (t l , .
.
.
,tk)where each k i > O, n >_ 0 and each ti is a string ofvariables (x's) and symbols in ~ and where the equa-tion is regular (all the variables appearing on one sideappear on the other) and linear (the variables appearonly once on the left and right).For example, the operations of head grammars canbe define with the equations1:wrap( (X l ,  ~2), (Yl, Y2)) : (XlYl, Y2X2)concl((xl, x2) , (Yl, Y2)) = (xx, x2y, y2)C0n?2((,~1, X2) , (Yl, Y2)) = (2?IX2Yl, Y2)Thus, we havewrap( (ab, ca), (ac, bc) ) = (abac, bcca)concl( (ab, ca), (ac, bc) ) = (ab, caaebc)conc2( ab, ca), (ac, be)) = (abcaac, be)A genera l i zed  context - f ree  grammar  (gcfg) \[8\]is denoted G = (VN, S, F, P) where1These operations differ from (but are equivalent to)those used in \[8\]VN is a finite set of nonterminal symbols,S is a distinguished member of VN,F is a finite set of function symbols andP is a finite set of productions of the formA --+ f (A1 , .
.
.
,  A,)where n > 0, f C F, and A, A I , .
.
.
,Am C VN.With a grammatical formalism we associate an in-te rpretat ion  funct ion  m that maps symbols in Fonto the formalism's composition operations.
For ex-ample, in a typical head grammar the set F mightinclude { W, e l ,  C2} where re(W) = wrap, m(Cl )  =concl and re(C2) = conc2.A formalism is a l inear  context - f ree  rewr i t ingsys tem (lefts) if every grammar can be expressed asa gcfg and its interpretation function m maps sym-bols onto operations whose yield functions are linearregular operations.In order to simplify the remaining discussion we as-sume that m maps directly onto the yield functionsthemselves.The language L(G) generated by a gcfg G =(VN, S, F, P) with associated interpretation functionm is defined asL(G) =where* A =:=V re ( f )  Gi fA - -~f0  EP* A ~ m( / ) ( t l , .
.
.
, tn )Gi fA  --* f (A1 , .
.
.
,An)  E P andAi ~--~ ti (l < i < n).GWe denote the class of all languages generated bylefrs as LCFRL.Determin is t i c  Tree-Walk ing  Transduc-e rsA deterministic tree-walking transducer is an automa-ton whose inputs are derivation trees of some context-free grammar.
The automaton moves around the treestarting at the root.
At each point in the computation,depending on the label of the current node and thestate of the finite state control, the automaton moves137up, down or stays at the current node and outputs astring.
The computation ends when the machine triesto move to the parent of the root node.We denote a determin is t i c  t ree -wa lk ing  t rans-ducer  (dtwt) by M - (Q, G, A, 6, q0, F)  whereQ is a finite set of states,G = (VN, VT, S, P) is a context-free grammar withoute-rules,A is a finite set of output symbols,6 : Q ?
(VN U VT) ---+ Q ?
D ?
A* is the transitionfunction whereD = {stay, up} O {d(k) \[ k > 1 },q0 E Q is the initial state andF C_ Q is the set of final states.A configuration of M is a 4-tuple (q, 7, r/, w) whereq E Q is the current state, 7 is the derivation tree ofG under consideration, r/is a node in 7 or T (where 1"can be thought of as the parent of the root ofT), andw E A* is the output string produced up to that pointin the computation.
We have(q, 7, r/, w) \['-M (qt, "\[, r/,, WW/)if the label of r/ is X, ~f(q, X)  = (q', d, w') such thatwhen d = stay then T/' = r/, when d = d(i) then 7/' isthe ith child of r/( i f  it exists), and when d = up thenr/' is the parent of r/(T if r/is the root of 7).The output language OUT(M)  of M is the set ofstrings:{weA*I (q0,7, r/r, e) b~/ (q f, 7, T, w),ql E F and7 is a derivation tree of G with root r/r }where F-~ is the reflexive transitive closure of \['-M"We denote the class of all languages OUT(M) whereM is a dtwt as OUT(DTWT) .Consider the dtwtM = ({qo, ql,q2, q3},G,{a,b,c ,d},~f ,  qo,{q3})where G = ({S} ,{e} ,S ,{S-*A ,A -~A,A-*e})and the relevant component of 6 is defined as follows.6(q0, s) = (q0, d(1), e)6(q0, A) = (q0, d(1), a)6(ql, S) = (q2, d(1), e)6(q2, A) = (q2, d(1), c)6(q3, 5') -~ (q3, up, e)6(qo, e) = (ql, up, e)6(qz, A) = (qz, up, b)~f(q~, e) = (q3, up, e)6(q3, A) = (q3, up, d)It can be seen that OUT(M)  = { anbnc'~d '~In > 1 }.Equ iva lenceIn this section we outline a two part proof thatOUT(DTWT)  = LCFRL.OUT(DTWT)  C_ LCFRLConsider a dtwt M = (Q, E, G, A, 6, qo, F)  where G =(VN, VT, S, P).
For convenience we assume that M isa dtwt without stay moves (see Lemma 5.1 in \[3\] forproof that this can be done).Given a derivation tree of G, and a node r/ in thistree, we record the strings contributed to the outputbetween the first and last visit to nodes in the subtreerooted at r/.
These contributed terminal strings canbe viewed as a k tuple where k is the number of timesthat the transducer enters and then leaves the subtree.For each production X --* X1 .
.
.Xn in P and eachp E Q we callC((X,p, .)
-.+ (X1, e, 0 ) .
.
.
(Xn, ?, 0))C((A, p, .)
(XI, e, 0).
.
.
(Xn, e, 0)) simulates all sub-computations of M that start in state p at a nodelabelled X that has been expanded using the pro-duction X --* X1 .
.
.Xn .
The node labelled A maybe visited several times, but each time the machinemust be in a different state (otherwise, being deter-ministic, it would loop indefinitely).
The sequence ofvisits is recorded as a string of states.
The compo-nent of the rule that is underlined indicates which ofthe children or parent is currently being visited.
Thecall C((X, a, ?)
-~ (Xl, a l ,  i l ) .
.
.
(Xn, an, in)) is madewhen a computation is being simulated in which thenode labelled A has been visited \]a\[ times (\[a\[ de-notes the length of a) such that on the ith visit themachine was in the state indicated by the ith symbolin a. a l , .
.
.
,  an are used in a similar way to encodethe state of the machine during visits to each childnode.
?
is a string of terms that is used to encode theoutput produced between the first and last visit to thesubtree rooted at the node labelled A.
Ultimately, ithas the form .tl .
.
.
.
- tk .
where each ti encodes thecomposition of the ith component of the tuple.
Thenotation used for each ti is identical to that used inthe equations used to define lefts composition opera-tions given earlier, i.e., each ti is a string of outputsymbols and x's.
i l , .
.
.
, in  are used to encode thenumber of times that a given child has been visitedfrom above.
This gives the number of times the sub-tree rooted at that node has been visited and, hence,encodes which component of the tuple was completedmost recently.
Thus, for each j, 1 _< j _< n, the sim-ulation has moved from the parent to the j th  child ij138times.
This number is used to determine which com-ponent of the tuple derived from the j th node shouldcontribute to the parent's current component.
Whena move is made from the parent node to the j th childwe add the variable xj,/~+x to the term currently beingconstructed for the parent node.
In other words, thenext component of the parent output is the ij + l thcomponent of its j th  child.The callC((X, a, ?)
--*(X1, oq, ix)...  (Xj, aj, i j ) .
.
.
(Xn, an, in))sumulates the machine visiting the j th child of a nodeexpanded using the rule X --~ X1 .. .
Xn.From M the gcfg G' is constructed such that G' =(V~, 5", F, P') wherevk = {S '}u  {(X,a) lXeVNUVTandnon-repeating a e Q*}and the procedure C determines P'  and F where foreach production A -~ X1 .
.
.
Xn in P and each p E Qwe callC((A,p, .)
--* (Xx, c, 0) .
.
.
(X~,  e, 0))In addition, for each a E VT and each p E Q we callC((a, p, .))
-~C is defined as follows.Case 1.C((X, ap, ?)
---* (X1, oq, ix).. .
(Xn, an, in))Note that if n = 0 then X E VT, otherwise, X E VN.If 6(p, X) = (q, up, w) then(X, ap) --~ f ( (X l ,  ~1) , .
.
.
,  (Xn, otn)) E P'for a new function f E F where re(f) is defined byf((xl, .
.
.
,mix),.. .
,  (xl,.
: .
,  mi,)) '= (tl , .
.
.
,tk)where Cw.
= 41 " .
.
. "
tk'.
(note that when ij = 0 forsome j then (Xl , .
.
.
,  xij) will appear as e), in addition,for each p' in Q that does not appear in ap callC((X, o~pp', ew.)
---* (Xl, ~1, i1).
.
.
(Xn, O~n, in))Note that ?
has been placed after ew.
This indicatesthat we have finished with the current component ofthe tuple.Otherwise, if 6(p,X) = (q,d(j) ,w) and 1 _< j < nthen callc((x, ap, ?w=j,~j+x)(xt ,oq, i t ) .
.
.
(x j ,a jq ,# + 1)...(Xn,o~,~,i,O)Note that if Xj E VT then it is not possible for themachine to move down the tree any further.Case 2.c((x, ?)
- - .
(X1, (~1, i l ) .
.
.
(Xj, ajp, i j ) .
.
.
(Xn, an, in))If 6(p, Xj) = (q, up, w) then call(Xl, al, i l ) .
.
.
(Xj, ajp, i j ) .
.
.
(Xn, an, in))Note that ?
will end with xj,ii and the i jth compoentof the yield at As.
will end in w.Otherwise, if 6(p, Xj) = (q,d(k), w) then if Xj E VNfor each p' in Q and not in aiP callc((x ,  a, ?)
- - .
(Xl, ot\], i t ) .
.
.
(Xj, %pp', ij) .
.. (Xn, an, in))This simulates the next visit to this node (which mustbe from below) in the (guessed) state p'.In addition to the productions added by C, includein P~ the production S~ ---.
( S, qootq! )
for each qi E Fand a E Q* such that aootqi is non-repeating and/f(q, S) = (qI, up, w) for some w where q is the lastsymbol in q0a.A complete proof would establish that the followingequivalence holds.
(Aa) ~ (wt , .
.
.
,w , )if and only if there is a derivation tree 7 of G withroot ~?r labelled A such that a = a t .
.
.an  for somea l , .
.
.
, an  E Q+ and for each i (1 < i < n)7, 7, f,where ai = pia\[ = a\['qi for some c~, a~' E Q*.Consider the application of this construction to ex-ample the dtwt given earlier.
The grammar containsthe following productions (where productions contain-ing useless nonterminals have been omitted).
(S, qoqlq3) --~ A((A, qoqlq2q3))139where f l ( (X l j ,  Xl,2)) -- Xl,lX1,2(A, qoqlq2qa) --* f2((A, qoqlq2qa))=(A, qoqlq2q3) --~ f3((e, qoq2))where  =(e, qoq2) ~ f40where 140 = (e, e).By renaming nonterminal we get the four produc-tionsS --* f l (A )  A - .
f2(A)A ---* f3(e) e ---* f40LCFRL  C_ OUT(DTWT)Consider the gcfg G -- (VN, S, F, P)  and mapping mthat interprets the symbols in F.  Without loss of gen-erality we assume that no nonterminal appears morethan once on the right of a production and that foreach A E VN there is some rank(A) = k such thatonly k-tuples are derived from A.We define a dtwt M = (Q, ~, G ~, liT, 6, qo, F)  whereG ~ is a context-free grammar  that generates derivationtrees of G in the following way.
A derivation involvingthe use of a production zr will he represented by a treewhose root is labelled by zr = A --* f (A1 , .
.
.
,  Am) withn subtrees encoding the derivations from A1, .
.
.
,  An.The roots of these subtrees will be labelled by then productions used to rewrite the A1 , .
.
.
,An .
Letlhs(~r) = A and rhs(~r) = { A I , .
.
.
,  An }.The dtwt M walks around a derivation tree 7 ofG' in such a way that it outputs the yield of 7.
Eachsubtree of 7 rooted at a node ~/labelled by the produc-tion ~r will be visited on k = rank(lhsOr)) occasions byM.
During the ith visit to the subtree M will outputthe ith component of the tuple.
We therefore includein Q k states { 1 , .
.
.
, k}  that are used to keep trackof which tuple is being considered.
This will gener-ally involve visiting children of y as determined bythe equation used to define function used in 7r.
Addi-tional states in Q are used to keep track of these visitsas follows.
When the lth child of T/ has finished itsruth component, M will move back up to y in state(Az,m).
Since no nonterminal appears twice on theright of a production it is possible for M to determinethe value of l from At while at y.For each production ~r = A --* f (A1 , .
.
.
,An)  E Pwhere f is interpreted as the function defined by theequationf ( (xX ,1 , .
- .
,X l ,k l ) , .
- .
, (Xn j , .
.
- ,Xn ,k , ) )= ( t l , .
.
.
, tk )we include the following components in the definitionof 6.For each i (1 < i < k)?
if ti = wxl,m?, where w is a possibly empty ter-minal string then let6(i, ~) = (m, down(O, w)?
if ti = w (in which case it is t ime to move up thetree) let6(i, ~r) = (( lhs(Ir), i), up, w)For each B E rhs(~r) and each m, 1 <_ m <_ rank(B),let6((B, m), 7r) = (q, move, w)where (q, move, w) is determined as follows.
For someunique I we know that B is the lth nonterminal on theright-hand side of 7r.
There is a unique ti such thatti = ?lXZ,mw?2 where w is a possibly empty string ofterminals.Case 1 :?2  is emptyIn this case the ith component of the current node iscomplete.
Thus, q = ( lhs(r),  i) and move = up.Case 2 :?2 begins with the variable xv,m,In this case the machine M must find the m' th  compo-nent of the / ' th  child.
Thus, q = m' and move = d(l').It should be clear that the start state q0 should be1 and the set of final states F = { (S, rank(S))  }.A complete proof would involve verifying that thefollowing equivalence holds.
(Aa)  ~ (w l , .
.
.
,Wn)if and only if there is a derivation tree 7 of G' withroot ~r labelled 7r such that lhs(lr) = A and for each i(1 < i < n)(i, 7, ~/r, e) t-~4 ((A, i), 7, t, w~)We apply the construction to the grammar  pro-duced in the illustration of the first construction.First, we name the productions of the grammar7rl = S --~ f l (A )  ~r2 = A --* f2(A)140~3 = A ---* f3(e) 7r4 = e --* f40The construction gives a machine in which the func-tion 5 is defined as follows.di(1, rl) = (1, d(1), e)&(1, ~r2) = (1, d(1), a)5(2, ~2) = (2, d(1), e)5(1, 7rz) = (1, d(1), a)5(2, r3) = (2, d(1), c)5(1, ~r4) = ((e, 1), up, e)5(2, ~,) = fie, 2), up, ~)6((A, 1), r l )  = (2, d(1), e)6((A, 2), 7rl) : ((S, 1), up, e)6((A, 1), r~) = ((A, 1), up, b)5((A, 2), 7r2) = ((A, 2), up, d)5((e, 1), 7rz) = ((A, 1), up, b)5((e, 2), r3) = ((A, 2), up, d)The context-free grammar whose derivation treesare to be transduced has the following productions.
";l'l "~  71"2 7l'1 -"+ 7r3We denote a hypergraph as a five tuple H( V, E, ~, incident, label) whereV is a finite set of nodes,E is a finite set of edges,E is a finite set of edge labels,incident : E --* V* is the incidence function andlabel : E --+ ~ is the edge labelling functionFor example, in the above graphV = {vl ,v2,  vz, v4}, E = {el ,e2,e3},= { a, b, c}, incident(el) = (v2, vl, v4),i , ,c ide.
t (e2)  = (v4, vl) ,  incident(e3) = (v3),label(e,) = a, label(e2) - b and label(e3) -- c.A string can be encoded with a s t r ing  hyper -g raph  \[5\].
The string bcaab is encoded with the fol-lowing graph.71"2 ~ 71"2 71"2 ~ 71"3 71"3 ~ 7i'4Context -F ree  Hypergraph GrammarsIn this section we describe context-free hypergraphgramars since they are an example of a lcfrs involv-ing the manipulation of graphs, zThe class of stringlanguages generated by context-free hypergraph gram-mars is equal to OUT(DTWT)  \[3\] and the above resultshows that they are also equal to LCFRS.A directed hypergraph is similar to a standardgraph except hat its (hyper)edges need not simply gofrom one node to another but may be incident withany number of nodes.
If an edge is incident with nnodes then it is a n-edge.
The n nodes that are inci-dent to some edge are linearly ordered.
For example,in the figure below, dots denote nodes and labelledsquare boxes are edges.
The edge labelled a is a 3-edge, the edge labelled b is a 2-edge and the edgelabelled c is a 1-edge.
When the number of nodesincident o an edge exceeds 2, numbered tentacles areused to indicate the nodes that are incident to theedge.
The numbers associated with the tentacles com-ing from an edge indicate the linear order of the nodesthat are incident to that edge.
2-edges are shown inthe standard way and 1-edges can be used as a way ofassociating labels with nodes as shown.
@141b c a a bWe denote a context- f ree hypergraph gram-mar (cfhg) as four tuple G = (VN, VT, S, P)  whereVN is a finite nonterminal alphabet,VT is a finite terminal alphabet,S E VN is the initial nonterminal andP is a finite set of productions e -* H whereH = (V, E, VN O VT, incident, label)is a hypergraph ande E E is a nonterminal edge in H, i.e., label(e) E VN.Consider the application of a production e --* H to agraph H ~ at a node e p in H ~ with the same nonterminallabel as e. The resulting graph is obtained from H ~by replacing e ~ by the graph H with e removed fromit.
This involves merging of nodes.
In particular, theith node incident with e is merged with the ith nodeincident with e ~.
We require that all edges with thesame label have the same number of incident nodes.
Aderivation begins with a graph containing a single edgelabelled S and no edges.
A derivation is completedwhen there are no nonterminal nodes in the graph.The string language associated with a cfhg G is de-noted STR(G).
The class of languages generated byall cfhg is denoted STR(CFHG).Due to lack of space, rather than a complete formaldefinition of cfhg derivations, we present an illustra-tive example.
Consider the three productions hownbelow.
Note that the edge on the left-hand-side of theproduction is indicated with a double box.14aBelow we show the steps in a derivation of the stringaabbccdd involving these productions.
Note that theset of graphs derived corresponds to the string lan-guage { anbncnd n I n > 0 }.Dadab j ?
~tCdab 1Cda a?
b"~.
.~?Cd dIt is clear from their definition that cfhg satisfy theconditions for being a lcfrs given earlier.
As has beenobserved \[3\] it is possible to represent the set of deriva-tions of a given cfhg with a set of trees that can begenerated by a context-free grammar.
The composi-tion operation of cfhg in which a node is replaced bya graph is clearly size-preserving since it does not in-volve duplication or deletion of an unbounded numberof nodes or edges.Additional RemarksWe end by elaborating on the relationship betweenlcfrs, dtwt and cfhg in terms of the following complex-ity measures.?
The maximum of rank(A) nonterminals A of agcfg.
Let LCFRLk be the class of languages gen-erated by gcfg of some lcfrs whose nonterminalshave rank k or less, i.e., derive at most k tuples.?
The crossing number  of a dtwt M. This is themaximum number of times that it visits any givensubtree of an input tree.
Let OUT(DTWTk)be the class of languages output by dtwt whosecrossing number does not exceed k.?
The maximum number of tentacles of the nonter-minals of a cfhg.
Let STR(CFI-IGk) be the classof languages associated with cfhg whose nonter-minals have at most k tentacles.It has been shown (Theorem 6.1 in \[3\]) thatOUT(DTWTk) = STR(CFHGg.k) = STR(CFHG2k+I)It can be seen from the above constructions thatLCFRLk = OUT(DTWTk)= STR(CFHG2k)= STR(CFHG2k+I)References\[1\] A. V. Aho and J. D. Ullman.
Translations on acontext-free grammar.
Inf.
Control, 19:439-475,1971.\[2\] M. Bauderon and B. Courcelle.
Graph expres-sions and graph rewritings.
Math.
Syst.
Theory,20:83-127, 1987.\[3\] J. Engelfriet and L. Heyker.
The string generat-ing power of context-free hypergraph grammars.J.
Comput.
Syst.
Sci., 43:328-360, 1991.142\[4\] J. Engelfriet, G. Rozenburg, and G. Slutzki.
Treetransducers, I systems, and two-way machines.
JComput.
Syst.
Sci., 20:150-202, 1980.\[5\] A. Habel and H. Kreowski.
Some structural as-pects of hypergraph languages generated by hy-peredge replacement.
In STACS, 1987.\[6\] A. K. Joshi, L. S. Levy, and M. Takahashi.
Treeadjunct grammars.
J. Comput.
Syst.
Sci., 10(1),1975.\[7\] T. Kasami, H. Seki, and M. Fujii.
General-ized context-free grammars, multiple context-freegrammars and head grammars.
Technical report,Department of Information and Computer Sci-ence, Osaka University, Osaka, Japan, 1988.\[8\] C. Pollard.
Generalized Phrase Structure Gram-mars, Head Grammars and Natural Language.PhD thesis, Stanford University, 1984.\[9\] K. Vijay-Shanker, D. J. Weir, and A. K. Joshi.Characterizing structural descriptions producedby various grammatical formalisms.
In 25 th meet-ing Assoc.
Comput.
Ling., 1987.\[10\] D. J. Weir.
Characterizing Mildly Context-Sensitive Grammar Formalisms.
PhD thesis,University of Pennsylvania, Philadelphia, PA,1988.143
