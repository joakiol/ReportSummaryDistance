Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 1?10,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsLearning to Translate with Multiple ObjectivesKevin Duh?
Katsuhito Sudoh Xianchao Wu Hajime Tsukada Masaaki NagataNTT Communication Science Laboratories2-4 Hikari-dai, Seika-cho, Kyoto 619-0237, JAPANkevinduh@is.naist.jp, lastname.firstname@lab.ntt.co.jpAbstractWe introduce an approach to optimize a ma-chine translation (MT) system on multiplemetrics simultaneously.
Different metrics(e.g.
BLEU, TER) focus on different aspectsof translation quality; our multi-objective ap-proach leverages these diverse aspects to im-prove overall quality.Our approach is based on the theory of ParetoOptimality.
It is simple to implement on top ofexisting single-objective optimization meth-ods (e.g.
MERT, PRO) and outperforms adhoc alternatives based on linear-combinationof metrics.
We also discuss the issue of metrictunability and show that our Pareto approachis more effective in incorporating new metricsfrom MT evaluation for MT optimization.1 IntroductionWeight optimization is an important step in build-ing machine translation (MT) systems.
Discrimi-native optimization methods such as MERT (Och,2003), MIRA (Crammer et alHop-kins and May, 2011), and Downhill-Simplex (Nelderand Mead, 1965) have been influential in improvingMT systems in recent years.
These methods are ef-fective because they tune the system to maximize anautomatic evaluation metric such as BLEU, whichserve as surrogate objective for translation quality.However, we know that a single metric such asBLEU is not enough.
Ideally, we want to tune to-wards an automatic metric that has perfect corre-lation with human judgments of translation quality.?
*Now at Nara Institute of Science & Technology (NAIST)While many alternatives have been proposed, such aperfect evaluation metric remains elusive.As a result, many MT evaluation campaigns nowreport multiple evaluation metrics (Callison-Burchet al2010).
Different evaluation met-rics focus on different aspects of translation quality.For example, while BLEU (Papineni et alfocuses on word-based n-gram precision, METEOR(Lavie and Agarwal, 2007) allows for stem/synonymmatching and incorporates recall.
TER (Snoveret al arbitrary chunk movements,while permutation metrics like RIBES (Isozaki etal., 2010; Birch et ale deviation inword order.
Syntax (Owczarzak et al-mantics (Pado et alelp.
Arguably, allthese metrics correspond to our intuitions on what isa good translation.The current approach of optimizing MT towardsa single metric runs the risk of sacrificing other met-rics.
Can we really claim that a system is good ifit has high BLEU, but very low METEOR?
Simi-larly, is a high-METEOR low-BLEU system desir-able?
Our goal is to propose a multi-objective op-timization method that avoids ?overfitting to a sin-gle metric?.
We want to build a MT system thatdoes well with respect to many aspects of transla-tion quality.In general, we cannot expect to improve multi-ple metrics jointly if there are some inherent trade-offs.
We therefore need to define the notion of ParetoOptimality (Pareto, 1906), which characterizes thistradeoff in a rigorous way and distinguishes the setof equally good solutions.
We will describe ParetoOptimality in detail later, but roughly speaking, a1hypothesis is pareto-optimal if there exist no otherhypothesis better in all metrics.
The contribution ofthis paper is two-fold:?
We introduce PMO (Pareto-based Multi-objective Optimization), a general approach forlearning with multiple metrics.
Existing single-objective methods can be easily extended tomulti-objective using PMO.?
We show that PMO outperforms the alterna-tive (single-objective optimization of linearly-combined metrics) in multi-objective space,and especially obtains stronger results for met-rics that may be difficult to tune individually.In the following, we first explain the theory ofPareto Optimality (Section 2), and then use it tobuild up our proposed PMO approach (Section 3).Experiments on NIST Chinese-English and PubMedEnglish-Japanese translation using BLEU, TER, andRIBES are presented in Section 4.
We conclude bydiscussing related work (Section 5) and opportuni-ties/limitations (Section 6).2 Theory of Pareto Optimality2.1 Definitions and ConceptsThe idea of Pareto optimality comes originally fromeconomics (Pareto, 1906), where the goal is to char-acterize situations when a change in allocation ofgoods does not make anybody worse off.
Here, wewill explain it in terms of MT:Let h ?
L be a hypothesis from an N-best list L.We have a total of K different metrics Mk(h) forevaluating the quality of h. Without loss of gen-erality, we assume metric scores are bounded be-tween 0 and 1, with 1 being perfect.
Each hypoth-esis h can be mapped to a K-dimensional vectorM(h) = [M1(h);M2(h); ...;MK(h)].
For exam-ple, suppose K = 2, M1(h) computes the BLEUscore, and M2(h) gives the METEOR score of h.Figure 1 illustrates the set of vectors {M(h)} in a10-best list.For two hypotheses h1, h2, we write M(h1) >M(h2) if h1 is better than h2 in all metrics, andM(h1) ?
M(h2) if h1 is better than or equalto h2 in all metrics.
When M(h1) ?
M(h2) andMk(h1) > Mk(h2) for at least one metric k, we saythat h1 dominates h2 and write M(h1) .
M(h2).0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 100.10.20.30.40.50.60.70.80.91metric1metric2Figure 1: Illustration of Pareto Frontier.
Ten hypothesesare plotted by their scores in two metrics.
Hypothesesindicated by a circle (o) are pareto-optimal, while thoseindicated by a plus (+) are not.
The line shows the convexhull, which attains only a subset of pareto-optimal points.The triangle (4) is a point that is weakly pareto-optimalbut not pareto-optimal.Definition 1.
Pareto Optimal: A hypothesis h?
?L is pareto-optimal iff there does not exist anotherhypothesis h ?
L such that M(h) .
M(h?
).In Figure 1, the hypotheses indicated by circle(o) are pareto-optimal, while those with plus (+) arenot.
To visualize this, take for instance the pareto-optimal point (0.4,0.7).
There is no other point witheither (metric1 > 0.4 and metric2 ?
0.7), or (met-ric1 ?
0.4 and metric2 > 0.7).
On the other hand,the non-pareto point (0.6,0.4) is ?dominated?
by an-other point (0.7,0.6), because for metric1: 0.7 > 0.6and for metric2: 0.6 > 0.4.There is another definition of optimality, whichdisregards ties and may be easier to visualize:Definition 2.
Weakly Pareto Optimal: A hypothesish?
?
L is weakly pareto-optimal iff there is no otherhypothesis h ?
L such that M(h) > M(h?
).Weakly pareto-optimal points are a superset ofpareto-optimal points.
A hypothesis is weaklypareto-optimal if there is no other hypothesis thatimproves all the metrics; a hypothesis is pareto-optimal if there is no other hypothesis that improvesat least one metric without detriment to other met-rics.
In Figure 1, point (0.1,0.8) is weakly pareto-optimal but not pareto-optimal, because of the com-peting point (0.3,0.8).
Here we focus on pareto-optimality, but note our algorithms can be easily2modified for weakly pareto-optimality.
Finally, wecan introduce the key concept used in our proposedPMO approach:Definition 3.
Pareto Frontier: Given an N-best listL, the set of all pareto-optimal hypotheses h ?
L iscalled the Pareto Frontier.The Pareto Frontier has two desirable propertiesfrom the multi-objective optimization perspective:1.
Hypotheses on the Frontier are equivalentlygood in the Pareto sense.2.
For each hypothesis not on the Frontier, thereis always a better (pareto-optimal) hypothesis.This provides a principled approach to optimiza-tion: i.e.
optimizing towards points on the Frontierand away from those that are not, and giving no pref-erence to different pareto-optimal hypotheses.2.2 Reduction to Linear CombinationMulti-objective problems can be formulated as:arg maxw[M1(h);M2(h); .
.
.
;Mk(h)] (1)where h = Decode(w, f)Here, the MT system?s Decode function, parame-terized by weight vector w, takes in a foreign sen-tence f and returns a translated hypothesis h. Theargmax operates in vector space and our goal is tofind w leading to hypotheses on the Pareto Frontier.In the study of Pareto Optimality, one centralquestion is: To what extent can multi-objective prob-lems be solved by single-objective methods?
Equa-tion 1 can be reduced to a single-objective problemby scalarizing the vector [M1(h); .
.
.
;Mk(h)] witha linear combination:arg maxwK?k=1pkMk(h) (2)where h = Decode(w, f)Here, pk are positive real numbers indicating the rel-ative importance of each metric (without loss of gen-erality, assume?k pk = 1).
Are the solutions toEq.
2 also solutions to Eq.
1 (i.e.
pareto-optimal)and vice-versa?
The theory says:Theorem 1.
Sufficient Condition: If w?
is solutionto Eq.
2, then it is weakly pareto-optimal.
Further,if w?
is unique, then it is pareto-optimal.Theorem 2.
No Necessary Condition: There mayexist solutions to Eq.
1 that cannot be achieved byEq.
2, irregardless of any setting of {pk}.Theorem 1 is a positive result asserting that lin-ear combination can give pareto-optimal solutions.However, Theorem 2 states the limits: in partic-ular, Eq.
2 attains only pareto-optimal points thatare on the convex hull.
This is illustrated in Fig-ure 1: imagine sweeping all values of p1 = [0, 1]and p2 = 1?
p1 and recording the set of hypothesesthat maximizes?k pkMk(h).
For 0.6 < p1 ?
1 weget h = (0.9, 0.1), for p1 = 0.6 we get (0.7, 0.6),and for 0 < p1 < 0.6 we get (0.4, 0.8).
At nosetting of p1 do we attain h = (0.4, 0.7) whichis also pareto-optimal but not on the convex hull.1This may have ramifications for issues like metrictunability and local optima.
To summarize, linear-combination is reasonable but has limitations.
Ourproposed approach will instead directly solve Eq.
1.Pareto Optimality and multi-objective optimiza-tion is a deep field with active inquiry in engineer-ing, operations research, economics, etc.
For the in-terested reader, we recommend the survey by Mar-ler and Arora (2004) and books by (Sawaragi et al1985; Miettinen, 1998).3 Multi-objective Algorithms3.1 Computing the Pareto FrontierOur PMO approach will need to compute the ParetoFrontier for potentially large sets of points, so wefirst describe how this can be done efficiently.
Givena set of N vectors {M(h)} from an N-best list L,our goal is extract the subset that are pareto-optimal.Here we present an algorithm based on iterativefiltering, in our opinion the simplest algorithm tounderstand and implement.
The strategy is to loopthrough the list L, keeping track of any dominantpoints.
Given a dominant point, it is easy to filterout many points that are dominated by it.
After suc-cessive rounds, any remaining points that are not fil-1We note that scalarization by exponentiated-combination?k pkMk(h)q , for a suitable q > 0, does satisfy necessaryconditions for pareto optimality.
However the proper tuning of qis not known a priori.
See (Miettinen, 1998) for theorem proofs.3Algorithm 1 FindParetoFrontierInput: {M(h)}, h ?
LOutput: All pareto-optimal points of {M(h)}1: F = ?2: while L is not empty do3: h?
= shift(L)4: for each h in L do5: if (M(h?)
.
M(h)): remove h from L6: else if (M(h) .
M(h?
)): remove h from L; seth?
= h7: end for8: Add h?
to Frontier Set F9: for each h in L do10: if (M(h?)
.
M(h)): remove h from L11: end for12: end while13: Return Ftered are necessarily pareto-optimal.
Algorithm 1shows the pseudocode.
In line 3, we take a point h?and check if it is dominating or dominated in the for-loop (lines 4-8).
At least one pareto-optimal pointwill be found by line 8.
The second loop (lines 9-11)further filters the list for points that are dominated byh?
but iterated before h?
in the first for-loop.The outer while-loop stops exactly after P iter-ations, where P is the actual number of pareto-optimal points in L. Each inner loop costs O(KN)so the total complexity is O(PKN).
Since P ?
Nwith the actual value depending on the probabilitydistribution of {M(h)}, the worst-case run-time isO(KN2).
For a survey of various Pareto algorithms,refer to (Godfrey et allgorithm we de-scribed here is borrowed from the database literaturein what is known as skyline operators.23.2 PMO-PRO AlgorithmWe are now ready to present an algorithm for multi-objective optimization.
As we will see, it can be seenas a generalization of the pairwise ranking optimiza-tion (PRO) of (Hopkins and May, 2011), so we callit PMO-PRO.
PMO-PRO approach works by itera-tively decoding-and-optimizing on the devset, sim-2The inquisitive reader may wonder how is Pareto relatedto databases.
The motivation is to incorporate preferences intorelational queries(Bo?rzso?nyi et al = 2 metrics,they also present an alternative faster O(N logN) algorithm byfirst topologically sorting along the 2 dimensions.
All domi-nated points can be filtered by one-pass by comparing with themost-recent dominating point.ilar to many MT optimization methods.
The maindifference is that rather than trying to maximize asingle metric, we maximize the number of paretopoints, in order to expand the Pareto FrontierWe will explain PMO-PRO in terms of thepseudo-code shown in Algorithm 2.
For each sen-tence pair (f, e) in the devset, we first generate anN-best list L ?
{h} using the current weight vectorw (line 5).
In line 6, we evaluate each hypothesish with respect to the K metrics, giving a set of K-dimensional vectors {M(h)}.Lines 7-8 is the critical part: it gives a ?la-bel?
to each hypothesis, based on whether it isin the Pareto Frontier.
In particular, first we callFindParetoFrontier (Algorithm 1), which re-turns a set of pareto hypotheses; pareto-optimal hy-potheses will get label 1 while non-optimal hypothe-ses will get label 0.
This information is added tothe training set T (line 8), which is then optimizedby any conventional subroutine in line 10.
We willfollow PRO in using a pairwise classifier in line 10,which finds w?
that separates hypotheses with labels1 vs. 0.
In essence, this is the trick we employ todirectly optimize on the Pareto Frontier.
If we hadused BLEU scores rather than the {0, 1} labels inline 8, the entire PMO-PRO algorithm would revertto single-objective PRO.By definition, there is no single ?best?
resultfor multi-objective optimization, so we collect allweights and return the Pareto-optimal set.
In line 13we evaluate each weight w on K metrics across theentire corpus and call FindParetoFrontierin line 14.3 This choice highlights an interestingchange of philosophy: While setting {pk} in linear-combination forces the designer to make an a prioripreference among metrics prior to optimization, thePMO strategy is to optimize first agnostically anda posteriori let the designer choose among a set ofweights.
Arguably it is easier to choose among so-lutions based on their evaluation scores rather thandevising exact values for {pk}.3.3 DiscussionVariants: In practice we find that a slight modifi-cation of line 8 in Algorithm 2 leads to more sta-3Note this is the same FindParetoFrontier algorithm as usedin line 7.
Both operate on sets of points in K-dimensionalspace, induced from either weights {w} or hypotheses {h}.4Algorithm 2 Proposed PMO-PRO algorithmInput: Devset, max number of iterations IOutput: A set of (pareto-optimal) weight vectors1: Initialize w. LetW = ?.2: for i = 1 to I do3: Let T = ?.4: for each (f, e) in devset do5: {h} =DecodeNbest(w,f )6: {M(h)}=EvalMetricsOnSentence({h}, e)7: {f} =FindParetoFrontier({M(h)})8: foreach h ?
{h}:if h ?
{f}, set l=1, else l=0; Add (l, h) to T9: end for10: w?=OptimizationSubroutine(T , w)11: Add w?
toW; Set w = w?.12: end for13: M(w) =EvalMetricsOnCorpus(w,devset) ?w ?
W14: Return FindParetoFrontier({M(w)})ble results for PMO-PRO: for non-pareto hypothe-ses h /?
{f}, we set label l =?kMk(h)/K in-stead of l= 0, so the method not only learns to dis-criminate pareto vs. non-pareto but also also learnsto discriminate among competing non-pareto points.Also, like other MT works, in line 5 the N-best list isconcatenated to N-best lists from previous iterations,so {h} is a set with i ?N elements.General PMO Approach: The strategy we out-lined in Section 3.2 can be easily applied to otherMT optimization techniques.
For example, by re-placing the optimization subroutine (line 10, Algo-rithm 2) with a Powell search (Och, 2003), one canget PMO-MERT4.
Alternatively, by using the large-margin optimizer in (Chiang et alv-ing it into the for-each loop (lines 4-9), one canget an online algorithm such PMO-MIRA.
Virtuallyall MT optimization algorithms have a place wheremetric scores feedback into the optimization proce-dure; the idea of PMO is to replace these raw scoreswith labels derived from Pareto optimality.4 Experiments4.1 Evaluation MethodologyWe experiment with two datasets: (1) The PubMedtask is English-to-Japanese translation of scientific4A difference with traditional MERT is the necessity ofsentence-BLEU (Liang et ale 6.
We use sentence-BLEU for optimization but corpus-BLEU for evaluation here.abstracts.
As metrics we use BLEU and RIBES(which demonstrated good human correlation inthis language pair (Goto et alTheNIST task is Chinese-to-English translation withOpenMT08 training data and MT06 as devset.
Asmetrics we use BLEU and NTER.?
BLEU = BP ?
(?precn)1/4.
BP is brevitypenality.
precn is precision of n-gram matches.?
RIBES = (?
+ 1)/2 ?
prec1/41 , with Kendall?s?
computed by measuring permutation betweenmatching words in reference and hypothesis5.?
NTER=max(1?TER, 0), which normalizesTranslation Edit Rate6 so that NTER=1 is best.We compare two multi-objective approaches:1.
Linear-Combination of metrics (Eq.
2),optimized with PRO.
We search a rangeof combination settings: (p1, p2) ={(0, 1), (0.3, 0.7), (0.5, 0.5), (0.7, 0.3), (1, 0)}.Note (1, 0) reduces to standard single-metricoptimization of e.g.
BLEU.2.
Proposed Pareto approach (PMO-PRO).Evaluation of multi-objective problems can betricky because there is no single figure-of-merit.We thus adopted the following methodology: Werun both methods 5 times (i.e.
using the 5 differ-ent (p1, p2) setting each time) and I = 20 iterationseach.
For each method, this generates 5x20=100 re-sults, and we plot the Pareto Frontier of these pointsin a 2-dimensional metric space (e.g.
see Figure 2).A method is deemed better if its final Pareto Fron-tier curve is strictly dominating the other.
We reportdevset results here; testset trends are similar but notincluded due to space constraints.75from www.kecl.ntt.co.jp/icl/lirg/ribes6from www.umd.edu/?snover/tercom7An aside: For comparing optimization methods, we believedevset comparison is preferable to testset since data mismatchmay confound results.
If one worries about generalization, weadvocate to re-decode the devset with final weights and evaluateits 1-best output (which is done here).
This is preferable to sim-ply reporting the achieved scores on devset N-best (as done insome open-source scripts) since the learned weight may pickout good hypotheses in the N-best but perform poorly whenre-decoding the same devset.
The re-decode devset approachavoids being overly optimistic while accurately measuring op-timization performance.5Train Devset #Feat MetricsPubMed 0.2M 2k 14 BLEU, RIBESNIST 7M 1.6k 8 BLEU, NTERTable 1: Task characteristics: #sentences in Train/Dev, #of features, and metrics used.
Our MT models are trainedwith standard phrase-based Moses software (Koehn andothers, 2007), with IBM M4 alignments, 4gram SRILM,lexical ordering for PubMed and distance ordering for theNIST system.
The decoder generates 50-best lists eachiteration.
We use SVMRank (Joachims, 2006) as opti-mization subroutine for PRO, which efficiently handle allpairwise samples without the need for sampling.4.2 ResultsFigures 2 and 3 show the results for PubMed andNIST, respectively.
A method is better if its ParetoFrontier lies more towards the upper-right hand cor-ner of the graph.
Our observations are:1.
PMO-PRO generally outperforms Linear-Combination with any setting of (p1, p2).The Pareto Frontier of PMO-PRO dominatesthat of Linear-Combination.
This impliesPMO is effective in optimizing towards Paretohypotheses.2.
For both methods, trading-off between met-rics is necessary.
For example in PubMed,the designer would need to make a choice be-tween picking the best weight according toBLEU (BLEU=.265,RIBES=.665) vs. anotherweight with higher RIBES but poorer BLEU,e.g.
(.255,.675).
Nevertheless, both the PMOand Linear-Combination with various (p1, p2)samples this joint-objective space broadly.3.
Interestingly, a multi-objective approach cansometimes outperform a single-objective opti-mizer in its own metric.
In Figure 2, single-objective PRO focusing on optimizing RIBESonly achieves 0.68, but PMO-PRO using bothBLEU and RIBES outperforms with 0.685.The third observation relates to the issue of metrictunability (Liu et alund that RIBEScan be difficult to tune directly.
It is an extremelynon-smooth objective with many local optima?slightchanges in word ordering causes large changes inRIBES.
So the best way to improve RIBES is to0.2 0.21 0.22 0.23 0.24 0.25 0.26 0.270.6650.670.6750.680.6850.690.695bleuribesLinear CombinationPareto (PMO?PRO)Figure 2: PubMed Results.
The curve represents thePareto Frontier of all results collected after multiple runs.0.146 0.148 0.15 0.152 0.154 0.156 0.158 0.16 0.162 0.1640.6940.6950.6960.6970.6980.6990.70.7010.7020.7030.704bleunterLinear CombinationPareto (PMO?PRO)Figure 3: NIST Resultsnot to optimize it directly, but jointly with a moretunable metric BLEU.
The learning curve in Fig-ure 4 show that single-objective optimization ofRIBES quickly falls into local optimum (at iteration3) whereas PMO can zigzag and sacrifice RIBES inintermediate iterations (e.g.
iteration 2, 15) leadingto a stronger result ultimately.
The reason is thediversity of solutions provided by the Pareto Fron-tier.
This finding suggests that multi-objective ap-proaches may be preferred, especially when dealingwith new metrics that may be difficult to tune.4.3 Additional Analysis and DiscussionsWhat is the training time?
The Pareto approachdoes not add much overhead to PMO-PRO.
WhileFindParetoFrontier scales quadratically by size ofN-best list, Figure 5 shows that the runtime is triv-60 2 4 6 8 10 12 14 16 18 200.630.640.650.660.670.680.69iterationribesSingle?Objective RIBESPareto (PMO?PRO)Figure 4: Learning Curve on RIBES: comparing single-objective optimization and PMO.0 100 200 300 400 500 600 700 800 900 100000.050.10.150.20.250.30.35Set size |L|Runtime(seconds)Algorithm 1TopologicalSort (footnote 2)Figure 5: Avg.
runtime per sentence of FindParetoial (0.3 seconds for 1000-best).
Table 2 showsthe time usage breakdown in different iterations forPubMed.
We see it is mostly dominated by decod-ing time (constant per iteration at 40 minutes onsingle 3.33GHz processor).
At later iterations, Opttakes more time due to larger file I/O in SVMRank.Note Decode and Pareto can be ?embarrasingly par-allelized.
?Iter Time Decode Pareto Opt Misc.
(line 5) (line 7) (line 10) (line 6,8)1 47m 85% 1% 1% 13%10 62m 67% 6% 8% 19%20 91m 47% 15% 22% 16%Table 2: Training time usage in PMO-PRO (Algo 2).How many Pareto points?
The number of pareto0 2 4 6 8 10 12 14 16 185101520253035IterationsNumberof Pareto PointsNISTPubMedFigure 6: Average number of Pareto pointshypotheses gives a rough indication of the diversityof hypotheses that can be exploited by PMO.
Fig-ure 6 shows that this number increases gradually periteration.
This perhaps gives PMO-PRO more direc-tions for optimizing around potential local optimal.Nevertheless, we note that tens of Pareto points is farfew compared to the large size of N-best lists usedat later iterations of PMO-PRO.
This may explainwhy the differences between methods in Figure 3are not more substantial.
Theoretically, the num-ber will eventually level off as it gets increasinglyharder to generate new Pareto points in a crowdedspace (Bentley et alPractical recommendation: We present thePareto approach as a way to agnostically optimizemultiple metrics jointly.
However, in practice, onemay have intuitions about metric tradeoffs even ifone cannot specify {pk}.
For example, we mightbelieve that approximately 1-point BLEU degra-dation is acceptable only if RIBES improves byat least 3-points.
In this case, we recommendthe following trick: Set up a multi-objective prob-lem where one metric is BLEU and the other is3/4BLEU+1/4RIBES.
This encourages PMO to ex-plore the joint metric space but avoid solutions thatsacrifice too much BLEU, and should also outper-form Linear Combination that searches only on the(3/4,1/4) direction.5 Related WorkMulti-objective optimization for MT is a relativelynew area.
Linear-combination of BLEU/TER is7the most common technique (Zaidan, 2009), some-times achieving good results in evaluation cam-paigns (Dyer et alr as we known, theonly work that directly proposes a multi-objectivetechnique is (He and Way, 2009), which modifiesMERT to optimize a single metric subject to theconstraint that it does not degrade others.
Theseapproaches all require some setting of constraintstrength or combination weights {pk}.
Recent workin MT evaluation has examined combining metricsusing machine learning for better correlation withhuman judgments (Liu and Gildea, 2007; Albrechtand Hwa, 2007; Gimnez and Ma`rquez, 2008) andmay give insights for setting {pk}.
We view ourPareto-based approach as orthogonal to these efforts.The tunability of metrics is a problem that is gain-ing recognition (Liu et algood evalu-ation metric could not be used for tuning, it wouldbe a pity.
The Tunable Metrics task at WMT2011concluded that BLEU is still the easiest to tune(Callison-Burch et aler et alCer et al similar observations, in ad-dition citing WER being difficult and BLEU-TERbeing amenable.
One unsolved question is whethermetric tunability is a problem inherent to the metriconly, or depends also on the underlying optimizationalgorithm.
Our positive results with PMO suggestthat the choice of optimization algorithm can help.Multi-objective ideas are being explored in otherNLP areas.
(Spitkovsky et albe a tech-nique that alternates between hard and soft EM ob-jectives in order to achieve better local optimum ingrammar induction.
(Hall et aligatesjoint optimization of a supervised parsing objectiveand some extrinsic objectives based on downstreamapplications.
(Agarwal et alers us-ing multiple signals (of varying quality) from onlineusers to train recommendation models.
(Eisner andDaume?
III, 2011) trades off speed and accuracy ofa parser with reinforcement learning.
None of thetechniques in NLP use Pareto concepts, however.6 Opportunities and LimitationsWe introduce a new approach (PMO) for trainingMT systems on multiple metrics.
Leveraging thediverse perspectives of different evaluation metricshas the potential to improve overall quality.
Basedon Pareto Optimality, PMO is easy to implementand achieves better solutions compared to linear-combination baselines, for any setting of combi-nation weights.
Further we observe that multi-objective approaches can be helpful for optimiz-ing difficult-to-tune metrics; this is beneficial forquickly introducing new metrics developed in MTevaluation into MT optimization, especially whengood {pk} are not yet known.
We conclude by draw-ing attention to some limitations and opportunitiesraised by this work:Limitations: (1) The performance of PMO islimited by the size of the Pareto set.
Small N-bestlists lead to sparsely-sampled Pareto Frontiers, anda much better approach would be to enlarge the hy-pothesis space using lattices (Macherey et alHow to compute Pareto points directly from latticesis an interesting open research question.
(2) Thebinary distinction between pareto vs. non-paretopoints ignores the fact that 2nd-place non-paretopoints may also lead to good practical solutions.
Abetter approach may be to adopt a graded definitionof Pareto optimality as done in some multi-objectiveworks (Deb et al robust evaluationmethodology that enables significance testing formulti-objective problems is sorely needed.
This willmake it possible to compare multi-objective meth-ods on more than 2 metrics.
We also need to followup with human evaluation.Opportunities: (1) There is still much we donot understand about metric tunability; we can learnmuch by looking at joint metric-spaces and exam-ining how new metrics correlate with establishedones.
(2) Pareto is just one approach among manyin multi-objective optimization.
A wealth of meth-ods are available (Marler and Arora, 2004) and moreexperimentation in this space will definitely lead tonew insights.
(3) Finally, it would be interesting toexplore other creative uses of multiple-objectives inMT beyond multiple metrics.
For example: Can welearn to translate faster while sacrificing little on ac-curacy?
Can we learn to jointly optimize cascadedsystems, such as as speech translation or pivot trans-lation?
Life is full of multiple competing objectives.AcknowledgmentsWe thank the reviewers for insightful feedback.8ReferencesDeepak Agarwal, Bee-Chung Chen, Pradheep Elango,and Xuanhui Wang.
2011.
Click shaping to optimizemultiple objectives.
In Proceedings of the 17th ACMSIGKDD international conference on Knowledge dis-covery and data mining, KDD ?11, pages 132?140,New York, NY, USA.
ACM.J.
Albrecht and R. Hwa.
2007.
A re-examination of ma-chine learning approaches for sentence-level mt evalu-ation.
In ACL.J.
L. Bentley, H. T. Kung, M. Schkolnick, and C. D.Thompson.
1978.
On the average number of max-ima in a set of vectors and applications.
Journal of theAssociation for Computing Machinery (JACM), 25(4).Alexandra Birch, Phil Blunsom, and Miles Osborne.2010.
Metrics for MT evaluation: Evaluating reorder-ing.
Machine Translation, 24(1).S.
Bo?rzso?nyi, D. Kossmann, and K. Stocker.
2001.
Theskyline operator.
In Proceedings of the 17th Interna-tional Conference on Data Engineering (ICDE).Chris Callison-Burch, Philipp Koehn, Christof Monz,and Omar Zaidan.
2011.
Findings of the 2011 work-shop on statistical machine translation.
In Proceedingsof the Sixth Workshop on Statistical Machine Transla-tion, pages 22?64, Edinburgh, Scotland, July.
Associ-ation for Computational Linguistics.Daniel Cer, Christopher Manning, and Daniel Jurafsky.2010.
The best lexical metric for phrase-based statis-tical MT system optimization.
In NAACL HLT.David Chiang, Wei Wang, and Kevin Knight.
2009.11,001 new features for statistical machine translation.In NAACL.Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-Shwartz, and Yoram Singer.
2006.
Online passiveag-gressive algorithms.
Journal of Machine Learning Re-search, 7.Kalyanmoy Deb, Amrit Pratap, Sammer Agarwal, andT.
Meyarivan.
2002.
A fast and elitist multiobjectivegenetic algorithm: NSGA-II.
IEEE Transactions onEvolutionary Computation, 6(2).Chris Dyer, Hendra Setiawan, Yuval Marton, and PhilipResnik.
2009.
The university of maryland statisticalmachine translation system for the fourth workshop onmachine translation.
In Proc.
of the Fourth Workshopon Machine Translation.Jason Eisner and Hal Daume?
III.
2011.
Learning speed-accuracy tradeoffs in nondeterministic inference algo-rithms.
In COST: NIPS 2011 Workshop on Computa-tional Trade-offs in Statistical Learning.Jesu?s Gimnez and Llu?
?s Ma`rquez.
2008.
Heterogeneousautomatic mt evaluation through non-parametric met-ric combinations.
In ICJNLP.Parke Godfrey, Ryan Shipley, and Jarek Gyrz.
2007.
Al-gorithms and analyses for maximal vector computa-tion.
VLDB Journal, 16.Isao Goto, Bin Lu, Ka Po Chow, Eiichiro Sumita, andBenjamin K. Tsou.
2011.
Overview of the patent ma-chine translation task at the ntcir-9 workshop.
In Pro-ceedings of the NTCIR-9 Workshop Meeting.Keith Hall, Ryan McDonald, Jason Katz-Brown, andMichael Ringgaard.
2011.
Training dependencyparsers by jointly optimizing multiple objectives.In Proceedings of the 2011 Conference on Empiri-cal Methods in Natural Language Processing, pages1489?1499, Edinburgh, Scotland, UK., July.
Associa-tion for Computational Linguistics.Yifan He and Andy Way.
2009.
Improving the objec-tive function in minimum error rate training.
In MTSummit.Mark Hopkins and Jonathan May.
2011.
Tuning as rank-ing.
In Proceedings of the 2011 Conference on Empir-ical Methods in Natural Language Processing, pages1352?1362, Edinburgh, Scotland, UK., July.
Associa-tion for Computational Linguistics.H.
Isozaki, T. Hirao, K. Duh, K. Sudoh, and H. Tsukada.2010.
Automatic evaluation of translation quality fordistant language pairs.
In EMNLP.T.
Joachims.
2006.
Training linear SVMs in linear time.In KDD.P.
Koehn et alopen source toolkit forstatistical machine translation.
In ACL.A.
Lavie and A. Agarwal.
2007.
METEOR: An auto-matic metric for mt evaluation with high levels of cor-relation with human judgments.
In Workshop on Sta-tistical Machine Translation.P.
Liang, A. Bouchard-Cote, D. Klein, and B. Taskar.2006.
An end-to-end discriminative approach to ma-chine translation.
In ACL.Ding Liu and Daniel Gildea.
2007.
Source-language fea-tures and maximum correlation training for machinetranslation evaluation.
In NAACL.Chang Liu, Daniel Dahlmeier, and Hwee Tou Ng.
2011.Better evaluation metrics lead to better machine trans-lation.
In Proceedings of the Conference on EmpiricalMethods in Natural Language Processing.Wolfgang Macherey, Franz Och, Ignacio Thayer, andJakob Uszkoreit.
2008.
Lattice-based minimum er-ror rate training for statistical machine translation.
InEMNLP.R.
T. Marler and J. S. Arora.
2004.
Survey ofmulti-objective optimization methods for engineering.Structural and Multidisciplinary Optimization, 26.Arne Mauser, Sas?a Hasan, and Hermann Ney.
2008.Automatic evaluation measures for statistical machine9translation system optimization.
In International Con-ference on Language Resources and Evaluation, Mar-rakech, Morocco, May.Kaisa Miettinen.
1998.
Nonlinear Multiobjective Opti-mization.
Springer.J.A.
Nelder and R. Mead.
1965.
The downhill simplexmethod.
Computer Journal, 7(308).Franz Och.
2003.
Minimum error rate training in statis-tical machine translation.
In ACL.Karolina Owczarzak, Josef van Genabith, and Andy Way.2007.
Labelled dependencies in machine translationevaluation.
In Proceedings of the Second Workshopon Statistical Machine Translation.Sebastian Pado, Daniel Cer, Michel Galley, Dan Jurafsky,and Christopher D. Manning.
2009.
Measuring ma-chine translation quality as semantic equivalence: Ametric based on entailment features.
Machine Trans-lation, 23(2-3).Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: A method for automatic eval-uation of machine translation.
In ACL.Vilfredo Pareto.
1906.
Manuale di Economica Politica,(Translated into English by A.S. Schwier as Manual ofPolitical Economy, 1971).
Societa Editrice Libraria,Milan.Michael Paul.
2010.
Overview of the iwslt 2010 evalua-tion campaign.
In IWSLT.Yoshikazu Sawaragi, Hirotaka Nakayama, and TetsuzoTanino, editors.
1985.
Theory of Multiobjective Opti-mization.
Academic Press.M.
Snover, B. Dorr, R. Schwartz, L. Micciulla, andJ.
Makhoul.
2006.
A study of translation edit ratewith targeted human annotation.
In AMTA.Valentin I. Spitkovsky, Hiyan Alshawi, and Daniel Juraf-sky.
2011.
Lateen em: Unsupervised training withmultiple objectives, applied to dependency grammarinduction.
In Proceedings of the 2011 Conference onEmpirical Methods in Natural Language Processing,pages 1269?1280, Edinburgh, Scotland, UK., July.
As-sociation for Computational Linguistics.Omar Zaidan.
2009.
Z-MERT: A fully configurable opensource tool for minimum error rate training of machinetranslation systems.
In The Prague Bulletin of Mathe-matical Linguistics.10
