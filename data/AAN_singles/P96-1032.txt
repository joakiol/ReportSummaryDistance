Efficient Tabular LR ParsingMark- Jan  NederhofFacul ty  of ArtsUnivers i ty of GroningenP.O.
Box 7169700 AS GroningenThe Nether landsmarkj an@let, rug.
nlGiorgio SattaDipar t imento  di E let t ron ica ed Informat icaUniversit?
di Padovavia Gradenigo,  6 /A1-35131 PadovaItalysatt a@dei, unipd, itAbst ractWe give a new treatment of tabular LRparsing, which is an alternative to Tomita'sgeneralized LR algorithm.
The advantageis twofold.
Firstly, our treatment is con-ceptually more attractive because it usessimpler concepts, such as grammar trans-formations and standard tabulation tech-niques also know as chart parsing.
Second-ly, the static and dynamic complexity ofparsing, both in space and time, is signifi-cantly reduced.1 In t roduct ionThe efficiency of LR(k) parsing techniques (Sippuand Soisalon-Soininen, 1990) is very attractive fromthe perspective of natural language processing ap-plications.
This has stimulated the computationallinguistics community to develop extensions of thesetechniques to general context-free grammar parsing.The best-known example is generalized LR pars-ing, also known as Tomita's algorithm, described byTomita (1986) and further investigated by, for ex-ample, Tomita (1991) and Nederhof (1994a).
Des-pite appearances, the graph-structured stacks usedto describe Tomita's algorithm differ very little fromparse fables, or in other words, generalized LR pars-ing is one of the so called tabular parsing algorithms,among which also the CYK algorithm (Harrison,1978) and Earley's algorithm (Earley, 1970) can befound.
(Tabular parsing is also known as chart pars-ing.
)In this paper we investigate the extension of LRparsing to general context-free grammars from amore general viewpoint: tabular algorithms can of-ten be described by the composition of two construc-tions.
One example is given by Lang (1974) andBillot and Lang (1989): the construction of push-down automata from grammars and the simulationof these automata by means of tabulation yield dif-ferent abular algorithms for different such construc-tions.
Another example, on which our presentationis based, was first suggested by Leermakers (1989):a grammar is first transformed and then a standardtabular algorithm along with some filtering condi-tion is applied using the transformed grammar.
Inour case, the transformation and the subsequent ap-plication of the tabular algorithm result in a newform of tabular LR parsing.Our method is more efficient han Tomita's algo-rithm in two respects.
First,  reduce operations areimplemented in an efficient way, by splitting them in-to several, more primitive, operations (a similar ideahas been proposed by Kipps (1991) for Tomita's al-gorithm).
Second, several paths in the computationthat must be simulated separately by Tomita's algo-rithm are collapsed into a single computation path,using state minimization techniques.
Experimentson practical grammars have indicated that there isa significant gain in efficiency, with regard to bothspace and time requirements.Our grammar transformation produces a so calledcover for the input grammar, which together withthe filtering condition fully captures the specifica-tion of the method, abstracting away from algorith-mic details such as data structures and control flow.Since this cover can be easily precomputed, imple-menting our LR parser simply amounts to runningthe standard tabular algorithm.
This is very attrac-tive from an application-oriented perspective, sincemany actual systems for natural anguage processingare based on these kinds of parsing algorithm.The remainder of this paper is organized as fol-lows.
In Section 2 some preliminaries are discussed.We review the notion of LR automaton i  Section.3and introduce the notion of 2LR automaton i  Sec-tion 4.
Then we specify our tabular LR method inSection 5, and provide an analysis of the algorithmin Section 6.
Finally, some empirical results are giv-239en in Section 7, and further discussion of our methodis provided in Section 8.2 Def in i t ionsThroughout this paper we use standard formal lan-guage notation.
We assume that the reader is famil-iar with context-free grammar parsing theory (Har-rison, 1978).A context-free grammar (CFG) is a 4-tuple G =(S, N, P, S), where S and N are two finite disjointsets of terminal and nonterminal symbols, respec-tively, S E N is the start symbol, and P is a finiteset of rules.
Each rule has the form A ---* a withA E N and a E V*, where V denotes N U E. Thesize of G, written IG I, is defined as  E(A--*a)EP \[Aot I;by I a I we mean the length of a string of symbols a.We generally use symbols A ,B ,C , .
.
.
to rangeover N, symbols a, b, c , .
.
.
to range over S, symbolsX, Y, Z to range over V, symbols ~, 8, 7 , .
.
.
to rangeover V*, and symbols v, w, z , .
.
.
to range over S*.We write e to denote the empty string.A CFG is said to be in binary form if ~ E{e} U V t.J N 2 for all of its rules A --* c~.
(The binaryform does not limit the (weak) generative capaci-ty of context-free grammars (Harrison, 1978).)
FortechnicM reasons, we sometimes use the augment-ed grammar associated with G, defined as G t =(St ,  N t, pt ,  St), where St, t> and <1 are fresh sym-bols, S t = SU {t>,<l}, N t = NU {S t } andpt  = p U {S t ~ t>S<~}.A pushdown automaton (PDA) is a 5-tuple .4 =(Z, Q, T, qi,, q/in), where S,  Q and T are finite setsof input symbols, stack symbols and transitions, re-spectively; qin E Q is the initiM stack symbol andq/i, E Q is the finM stack symbol.
1 Each transitionhas the form 61 ~-~ 62, where 61,82 E Q*, 1 < 161 l,1 < 1621 < 2, and z = e or z = a.
We generally usesymbols q, r, s , .
.
.
to range over Q, and the symbol6 to range over Q*.Consider a fixed input string v E ~*.
A config-uration of the automaton is a pair (6, w) consistingof a stack 6 E Q* and the remaining input w, whichis a suffix of the input string v. The rightmost sym-bol of 6 represents the top of the stack.
The initialconfiguration has the form (qi~, v), where the stackis formed by the initial stack symbol.
The final con-figuration has the form (qi, q/i,, e), where the stackis formed by the final stack symbol stacked upon theinitial stack symbol.ZWe dispense with the notion of state, traditionallyincorporated in the definition of PDA.
This does notaffect the power of these devices, since states can beencoded within stack symbols and transitions.The application of a transition 81 ~-~ 82 is de-scribed as follows.
If the top-most symbols of thestack are 61, then these symbols may be replaced by62, provided that either z = e, or z = a and a is thefirst symbol of the remaining input.
Furthermore, ifz = a then a is removed from the remaining input.Formally, for a fixed PDA .4 we define the bina-ry relation t- on configurations as the least relationsatisfying (881, w) ~- (662, w) if there is a transition61 ~ 62, and (881, aw) t- (682, w) if there is a tran-sition 61 a 82.
The recognition of a certain input vis obtained if starting from the initial configurationfor that input we can reach the final configurationby repeated application of transitions, or, formally,if (qin, v) I"* (q~,, aria, e), where t-* denotes the re-flexive and transitive closure of b.By a computation of a PDA we mean a sequence(qi,,v) t- (61,wl) h .
.
.
t- (6n,wn), n > 0.
A PDA iscalled deterministic if for all possible configurationsat most one transition is applicable.
A PDA is saidto be in binary form if, for all transitions 61 ~L~ 62,we have 1611 < 2.3 L l : t  automataLet G = (S,  N, P, S) be a CFG.
We recall the no-tion of LR automaton, which is a particular kindof PDA.
We make use of the augmented grammarG t = (s t ,  N t, pt ,  S t) introduced in Section 2.Let !LR : {A ~ a ?
~ I (A --~ aft) E pt}.We introduce the function closure from 2 I~'R to 2 ILRand the function goto from 2 ILR ?
V to 2 l~rt.
Forany q C ILK, closure(q) is the smallest set such that(i) q c closure(q); and(ii) (B --~ c~ ?
Aft) e closure(q) and (A ~ 7) e pttogether imply (A --* ?
7) E closure(q).We then definegoto(q, X)  ={A ---* ~X ?
fl I (A --* a ?
Xfl) E closure(q)}.We construct a finite set T~Lp ~ as  the smallest collec-tion of sets satisfying the conditions:(i) {S t ~ t>.
S<~} E ~'~Ll=t; and(ii) for every q E ~T~LR and X E V, we havegoto(q, X) E 7~LR, provided goto(q, X)  ~ 0.Two elements from ~Lt~ deserve special attention:qm = {S t --+ t> * S<~}, and q/in, which is defined tobe the unique set in "~Ll:t containing (S t ~ t>S * <~);in other words, q/in = goto(q~n, S).240For A ?
N, an A-redex is a string qoqlq2"" "qm,m _> 0, of elements from T~Lrt, satisfying the follow-ing conditions:(i) (A ~ a .)
?
closure(q,,), for some a =X1X~.
?
?
?
Xm ; and(ii) goto(q~_l, Xk) = qk, for 1 < k < m.Note that in such an A-redex, (A --~ ?
X1Xg....  Xm)?
closure(qo), and (A ~ X1 .
.
.Xk  * Xk+z ' "Xm)E qk, for 0 < k < m.The LR automaton associated with G is now in-troduced.Definition 1 .ALR = (S, QLR, TLR, qin, q~n), whereQLR "-  ~'~LR, qin = {S t -'* t> ?
S<~}, qlin =goto(qin, S), and TLR contains:(i) q ~ q q', for every a ?
S and q, q~ ?
~LR suchthat q' = goto(q, a);(ii) q5 ~-L q q', for every A ?
N, A-redex q~, andq' ?
TiLa such that q~ = goto(q, A).Transitions in (i) above are called shift, transitionsin (ii) are called reduce.4 2LR AutomataThe automata .At, rt defined in the previous sectionare deterministic only for a subset of the CFGs,called the LR(0) grammars (Sippu and Soisalon-Soininen, 1990), and behave nondeterministical-ly in the general case.
When designing tabularmethods that simulate nondeterministic computa-tions of ~4LR, two main difficulties are encountered:?
A reduce transition in .ALrt is an elementary op-eration that removes from the stack a numberof elements bounded by the size of the underly-ing grammar.
Consequently, the time require-ment of tabular simulation of .AL~ computa-tions can be onerous, for reasons pointed outby Sheil (1976) and Kipps (1991).?
The set 7~Lrt can be exponential in the size ofthe grammar (Johnson, 1991).
If in such a casethe computations of.ALR touch upon each state,then time and space requirements of tabularsimulation are obviously onerous.The first issue above is solved here by re-casting .ALR in binary form.
This is doneby considering each reduce transition as a se-quence of "pop" operations which affect at mosttwo stack symbols at a time.
(See alsoLang (1974), Villemonte de la Clergerie (1993) andNederhof (1994a), and for LR parsing specificallygipps (1991) and Leermakers (19925).)
The follow-ing definition introduces this new kind of automaton.I !
Def in i t ion 2 A~R = (~, QLR' TLR., qin, q1~n), where q, LR ----- 7~LR U ILR, qin = {S t "* I> ?
S<2}, qJin =goto(qin, S) and TLR contains:(i) q ~ q q,, for every a ?
S and q, q' ?
7~Lrt suchthat q' = goto(q, a);(ii) q A. q (A --* a .
), for every q ?
TiLR and (A? )
?
closure(q);(iii) q (A --* aX  ?
,8) ~ (A ~ a ?
X,8), for everyq ?
~LR and (A ~ aX  .
,8) ?
q;(iv) q (A --* * c~) A, q q', for every q, q' ?
7~LR and(A ~ ~) ?
pt  such that q' = goto(q, A).Transitions in (i) above are again called shift, tran-sitions in (ii) are called initiate, those in (iii) arecalled gathering, and transitions in (iv) are calledgoto.
The role of a reduce step in .ALR is taken overin .A?K by an initiate step, a number of gatheringsteps, and a goto step.
Observe that these steps in-volve the new stack symbols (A --~ a ?
,8) ?
ILI~that are distinguishable from possible stack symbols{A .-* a ?
,8} ?
'/'~LR-We now turn to the second above-mentioned prob-lem, regarding the size of set 7dgR.
The problemis in part solved here as follows.
The number ofstates in 7~Lrt is considerably reduced by identify-ing two states if they become identical after itemsA --~ cr ?
fl from ILrt have been simplified to onlythe suffix of the right-hand side ,8.
This is rem-iniscent of techniques of state minimization for fi-nite automata (Booth, 1967), as they have been ap-plied before to LR parsing, e.g., by Pager (1970) andNederhof and Sarbo (1993).Let G t be the augmented grammar associatedwith a CFG G, and let I2LI~ -- {fl I (A ---, a,8) ept}.
We define variants of the closure and 9oto func-tions from the previous ection as follows.
For anyset q C I2Lt~, closurel(q) is the smallest collection ofsets such that(i) q C elosure'(q); and(ii) (Aft) e closure' (q) and (A ---* 7) ?
p t  togetherimply (7) ?
closure'(q).Also, we definegoto'(q, x )  = {,8 I (x,8) ~ closure'(q)}.We now construct a finite set T~2Lrt as the smallestset satisfying the conditions:241(i) {S<l} 6 7~2LR; and(ii) for every q 6 T~2LI:t and X ?
V, we havegoto'(q, X) ?
T~2LR, provided goto'(q, X) # @.As stack symbols, we take the elements from I2LRand a subset of elements from (V ?
~2Lrt):Q2LR = {(X,q) I 3q'\[goto'(q',X) = q\]} U I2LRIn a stack symbol of the form (X, q), the X servesto record the grammar symbol that has been recog-nized last, cf.
the symbols that formerly were foundimmediately before the dots.The 2LK automaton associated with G can nowbe introduced.Z T ' ' Def in i t ion  3 .A2LR ---~ ( , Q2LR, 2LR, qin, qfin),where Q LR is as defined above, = (C>,q~.
= (S, goto'({S.~}, S)), and T2LR contains:(i) (X,q) ~ (X,q) (a,q'), for every a ?
Z and(X, q), (a, q') ?
Q2Lrt such that q' = goto'(q, a);(ii) (X,q) ~+ (X,q)(e), for every (X,q) ?
Q2LRsuch that e ?
closure'(q);(iii) (Z,q)(~)  ~ (Zg),  for every (X,q) ?
Q2LRand 19 ?
q;(iv) (X,q) (o~) ~ (X,q) (A,q'), for every (X,q),(A,q') ?
Q2LR and (A ---~ c~) ?
pt  such thatq' = goto'(q, A).Note that in the case of a reduce/reduce conflictwith two grammar ules sharing some suffix in theright-hand side, the gathering steps of A2Lrt willtreat both rules simultaneously, until the parts ofthe right-hand sides are reached where the two rulesdiffer.
(See Leermakers (1992a) for a similar sharingof computation for common suffixes.
)An interesting fact is that the automaton .A2LR isvery similar to the automaton .ALR constructed fora grammar transformed by the transformation rtwogiven by Nederhof and Satta (1994).
25 The  a lgor i thmThis section presents a tabular LR parser, which isthe main result of this paper.
The parser is derivedfrom the 2LR automata introduced in the previoussection.
Following the general approach presentedby Leermakers (1989), we simulate computations of2For the earliest mention of this transformation, wehave encountered pointers to Schauerte (1973).
Regret-tably, we have as yet not been able to get hold of a copyof this paper.these devices using a tabular method, a grammartransformation a d a filtering function.We make use of a tabular parsing algorithm whichis basically an asynchronous version of the CYK al-gorithm, as presented by Harrison (1978), extendedto productions of the forms A ---* B and A ~and with a left-to-right filtering condition.
The al-gorithm uses a parse table consisting in a 0-indexedsquare array U.
The indices represent positions inthe input string.
We define Ui to be Uk<i Uk,i.Computation of the entries of U is moderated bya filtering process.
This process makes use of afunction pred from 2 N to 2 N, specific to a certaincontext-free grammar.
We have a certain nontermi-nal Ainit which is initially inserted in U0,0 in orderto start the recognition process.We are now ready to give a formal specification ofthe tabular algorithm.A lgor i thm 1 Let G = (~,N ,P ,S )  be a CFG inbinary form, let pred be a function from 2 N to 2 N,let Ai,,t be the distinguished element from N, andlet v = a la2 .
"'an 6 ~* be an input string.
Wecompute the least (n+ 1) x (n+ 1) table U such thatAinit 6 U0,0 and(i) A 6 Uj_ 1,jif (A ~ aj) 6 P, A 6 pred(Uj_l);(ii) A 6 Uj,jif (A --+ e) 6 P, A E pred(Uj);(iii) A 6 Ui,jif B 6 Ui,~, C 6 Uk,j, (A ---.
BC) 6 P, A 6pred(Ui);(iv) A 6 Uijif B 6 Uij, (A ~ B) 6 P, A 6 pred(UO.The string has been accepted when S 6 U0,,.We now specify a grammar transformation, basedon the definition of .A2LR.Def in i t ion 4 Let A2LR = (S, Q2LR, T2LR, ' qin,q~,)be the 2L1% automaton associated with a CFG G.The 2LR cover associated with G is the CFGC2I r (G) = ( Q2Lr , P2I rt, where the rules inP2LR are given by:(i) (a ,q ' )  --* a,for every (X, q) ~-~ (X, q) (a, q') E T2LR;(ii) (e) ~ ?,for every (X, q) ~-* (X, q) (e) 6 T2LR;(iii) (X~) ~ (X, q) (~),for every (X, q) (~) ~-* (X~) 6 T2LR;242(iv) (A,q') --, (a),for every (X, q) (or) ~-~ (X, q) (A, q') E T2La.Observe that there is a direct, one-to-one correspon-dence between transitions of.A2La and productionsof C2LR(G).The accompanying function pred is defined as fol-lows (q, q', q" range over the stack elements):pred(v) = {q I q'q" ~-~ q E T2La} U{q \] q' E r, q' ~*q'qET~La} U{q I q 'E r ,  q'q"~-~q'qET2La}.The above definition implies that only the tabularequivalents of the shift, initiate and goto transitionsare subject to actual filtering; the simulation of thegathering transitions does not depend on elementsin r.Finally, the distinguished nonterminal from thecover used to initialize the table is qin'l Thus westart with (t>, {S<l)) E U0,0.The 2LR cover introduces purious ambiguity:where some grammar G would allow a certain num-ber of parses to be found for a certain input, thegrammar C2Lrt(G) in general allows more parses.This problem is in part solved by the filtering func-tion pred.
The remaining spurious ambiguity isavoided by a particular way of constructing the parsetrees, described in what follows.After Algorithm 1 has recognized a given in-put, the set of all parse trees can be computed astree(q~n, O, n) where the function tree, which deter-mines sets of either parse trees or lists of parse treesfor entries in U, is recursively defined by:(i) tree((a, q'), i, j) is the set {a}.
This set containsa single parse tree Consisting of a single nodelabelled a.
(ii) tree(e, i, i) is the set {c}.
This set consists of anempty list of trees.
(iii) tree(Xl?,i,j) is the union of the sets T. k (x~),i,j,where i < k < j, (8) E Uk,j, and there is atleast one (X, q) E Ui,k and (X~) ---* (X, q) (8)in C2La(G), for some q.
For each such k, selectone such q.
We define 7:, ~ = {t .
t s  I t E ( X fl ), i, jtree((X,q),i,k) A ts E tree(fl, k, j)}.
Each t. tsis a list of trees, with head t and tail ts.
(iv) tree( A, q'), i, j) is the union of the setsT.
a where (~) E Uij is such that ( A,ql ),i, j  '(A, q') ---* (c~) in C2La(G).
We define T ~ - (a,q ' ) , i , j  - -{glue(A, ts) l ts E tree(c~,i,j)}.
The functionglue constructs a tree from a fresh root nodelabelled A and the trees in list ts as immediatesubtrees.We emphasize that in the third clause above, oneshould not consider more than one q for given k inorder to prevent spurious ambiguity.
(In fact, forfixed X, i, k and for different q such that (X, q) EUi,k, tvee((X, q),i, k) yields the exact same set oftrees.)
With this proviso, the degree of ambiguity,i.e.
the number of parses found by the algorithm forany input, is reduced to exactly that of the sourcegrammar.A practical implementation would construct heparse trees on-the-fly, attaching them to the tableentries, allowing packing and sharing of subtrees (cf.the literature on parse forests (Tomita, 1986; Ell-lot and Lang, 1989)).
Our algorithm actually onlyneeds one (packed) subtree for several (X, q) E Ui,kwith fixed X, i , k  but different q.
The resultingparse forests would then be optimally compact, con-trary to some other LR-based tabular algorithms, aspointed out by Rekers (1992), Nederhof (1993) andNederhof (1994b).6 Ana lys i s  o f  the  a lgor i thmIn this section, we investigate how the steps per-formed by Algorithm 1 (applied to the 2LR cover)relate to those performed by .A2LR, for the same in-put.We define a subrelation ~+ of t -+ as: (6, uw) ~+(66',w) if and only if (6, uw) = (6, z lz2".
'zmw) t-(88l,z2..-zmw) ~- ... ~ (68re,w) = (86',w), forsome m > 1, where I~kl > 0 for all k, 1 < k < m.Informally, we have (6, uw) ~+ (6~', w) if configura-tion (~8', w) can be reached from (6, uw) without hebottom-most part 8 of the intermediate stacks beingaffected by any of the transitions; furthermore, atleast one element is pushed on top of 6.The following characterization relates the automa-ton .A2Lrt and Algorithm 1 applied to the 2LR cover.Symbol q E Q~Lrt is eventually added to Uij if andonly if for some 6:(q;n,al.. .an) ~-* (di, a i+ l .
.
.an)  ~+ (~q, aj+l.. .an).In words, q is found in entry Ui,j if and only if, atinput position j, the automaton would push someelement q on top of some lower-part of the stackthat remains unaffected while the input from i to jis being read.The above characterization, whose proof is not re-ported here, is the justification for calling the result-ing algorithm tabular LR parsing.
In particular, fora grammar for which .A2Lrt is deterministic, i.e.
foran LR(0) grammar, the number of steps performed243by J42LR and the number of steps performed by theabove algorithm are exactly the same.
In the case ofgrammars which are not LR(0), the tabular LR algo-rithm is more efficient han for example a backtrackrealisation of -A2LR.For determining the order of the time complex-ity of our algorithm, we look at the most expen-sive step, which is the computation of an element(Xfl) E Ui,j from two elements (X, q) e Ui,k and(t3) E Uk,j, through (X, q) (fl) ,--% (Xfl) E T2LR.
Ina straightforward ealisation of the algorithm, thisstep can be applied O(IT2LRI" Iv 13) times (once foreach i, k, j  and each transition), each step taking aconstant amount of time.
We conclude that the timecomplexity of our algorithm is O(\[ T2LR\] ?
IV \[Z).As far as space requirements are concerned, eachset Ui,j or Ui contains at most I O2w.RI elements.
(One may assume an auxiliary table storing each Ui.
)This results in a space complexity O(I Q2LRI" Iv 12).The entries in the table represent single stack ele-ments, as opposed to pairs of stack elements follow-ing Lang (1974) and Leermakers (1989).
This hasbeen investigated before by Nederhof (1994a, p. 25)and Villemonte de la Clergerie (1993, p. 155).7 Empi r i ca l  resu l t sWe have performed some experiments with Algo-rithm 1 applied to ,A2L R and .A ~ for 4 practical LR,context-free grammars.
For ,4 ~ LR a cover was usedanalogous to the one in Definition 4; the filteringfunction remains the same.The first grammar generates a subset of the pro-gramming language ALGOL 68 (van Wijngaardenand others, 1975).
The second and third grammarsgenerate a fragment of Dutch, and are referred to asthe CORRie grammar (Vosse, 1994) and the Deltragrammar (Schoorl and Belder, 1990), respectively.These grammars were stripped of their argumentsin order to convert them into context-free grammars.The fourth grammar, eferred to as the Alvey gram-mar (Carroll, 1993), generates a fragment of Englishand was automatically generated from a unification-based grammar.The test sentences have been obtained by au-tomatic generation from the grammars, using theGrammar Workbench (Nederhof and Koster, 1992),which uses a random generator to select rules; there-fore these sentences do not necessarily represent in-put typical of the applications for which the gram-mars were written.
Table 1 summarizes the test ma-terial.Our implementation is merely a prototype, whichmeans that absolute duration of the parsing processG =(Z ,N ,P ,S )ALGOL 68 ~CORRieDeltraAlveyTable 1: The test material: the four grammars andsome of their dimensions, and the average length ofthe test sentences (20 sentences of various length foreach grammar).4 LR A2LRG space \] time space \] timeALGOL 68 327 375 234 343CORRie 7548 28028 5131 22414Deltra 11772 94824 6526 70333Alvey 599 1147 354 747Table 2: Dynamic requirements: average space andtime per sentence.is little indicative of the actual efficiency of moresophisticated implementations.
Therefore, our mea-surements have been restricted to implementation-independent quantities, viz.
the number of elementsstored in the parse table and the number of elemen-tary steps performed by the algorithm.
In a practicalimplementation, such quantities will strongly influ-ence the space and time complexity, although theydo not represent the only determining factors.
Fur-thermore, all optimizations of the time and spaceefficiency have been left out of consideration.Table 2 presents the costs of parsing the test sen-tences.
The first and third columns give the numberof entries stored in table U, the second and fourthcolumns give the number of elementary steps thatwere performed.An elementary step consists of the derivation of!
one element in QLR or Q2LR from one or two otherelements.
The elements that are used in the filter-ing process are counted individually.
We give anexample for the case of .A~R.
Suppose we derive anelement q~ E Ui,j from an element (A - .
?
c~) E Ui,j,warranted by two elements ql,q2 E Ui, ql ~ q2,through pred, in the presence of ql (A --* ?
c~)ql q' e T~.~ and q2 (A ---* ?
c~) ~-~ q2 q' E T~R.
Wethen count two parsing steps, one for ql and one forq2.Table 2 shows that there is a significant gain inspace and time efficiency when moving from ,4~a to244GALGOL 68CORRieDeltraAlvey.A !
LR\[T~LR\[ I \[Q\[a\[  \[T~R\[434 1 ,217  13,844600 1 ,741  22,129856 2,785 54,9323,712 8,784 1,862,492,A2LRIn2LRI \[ \[O2La\[ IT2Lrd109 724 12,387185 821 15,569260 1,089 37,510753 3,065 537,852Table 3: Static requirements.,A2LR.Apart from the dynamic osts of parsing, we havealso measured some quantities relevant o the con-struction and storage of the two types of tabular LRparser.
These data are given in Table 3.We see that the number of states is strongly re-duced with regard to traditional LR parsing.
In thecase of the Alvey grammar, moving from \[T~LR \[to\]T~2LR\[ amounts to a reduction to 20.3 %.
Whereastime- and space-efficient computation f T~LR for thisgrammar isa serious problem, computation ofT~2Lawill not be difficult on any modern computer.
Al-so significant is the reduction from \[T~R \[to \[T2LR\[,especially for the larger grammars.
These quanti-ties correlate with the amount of storage needed fornaive representation f the respective automata.8 DiscussionOur treatment oftabular LR parsing has two impor-tant advantages over the one by Tomita:* It is conceptually simpler, because we make useof simple concepts uch as a grammar trans-formation and the well-understood CYK al-gorithm, instead of a complicated mechanismworking on graph-structured stacks.?
Our algorithm requires fewer LR states.
Thisleads to faster parser generation, to smallerparsers, and to reduced time and space com-plexity of parsing itself.The conceptual simplicity of our formulation oftabular LR parsing allows comparison with othertabular parsing techniques, uch as Earley's algo-rithm (Earley, 1970) and tabular left-corner pars-ing (Nederhof, 1993), based on implementation-independent criteria.
This is in contrast o experi-ments reported before (e.g.
by Shann (1991)), whichtreated tabular LR parsing differently from the othertechniques.The reduced time and space complexities reportedin the previous ection pertain to the tabular eal-isation of two parsing techniques, expressed by theautomata A~, R and A2La.
The tabular ealisationof the former automata is very close to a variant ofTomita's algorithm by Kipps (1991).
The objectiveof our experiments was to show that the automata~4~La provide a better basis than .A~a for tabular LRparsing with regard to space and time complexity.Parsing algorithms that are not based on theLR technique have however been left out of con-sideration, and so were techniques for unificationgrammars and techniques incorporating finite-stateprocesses.
3Theoretical considerations (Leermakers, 1989;Schabes, 1991; Nederhof, 1994b) have suggested thatfor natural anguage parsing, LR-based techniquesmay not necessarily be superior to other parsingtechniques, although convincing empirical data tothis effect has never been shown.
This issue is dif-ficult to resolve because so much of the relative f-ficiency of the different parsing techniques dependson particular grammars and particular input, as wellas on particular implementations of the techniques.We hope the conceptual framework presented in thispaper may at least partly alleviate this problem.AcknowledgementsThe first author is supported by the Dutch Organiza-tion for Scientific Research (NWO), under grant 305-00-802.
Part of the present research was done whilethe second author was visiting the Center for Lan-guage and Speech Processing, Johns Hopkins Uni-versity, Baltimore, MD.We received kind help from John Carroll, JobHonig, Kees Koster, Theo Vosse and Hans deVreught in finding the grammars mentioned in thispaper.
Generous help with locating relevant litera-ture was provided by Anton Nijholt, Rockford Ross,and Arnd Ruflmann.3As remarked before by Nederhof (1993), the algo-rithms by Schabes (1991) and Leermakers (1989) are notreally related to LR parsing, although some notationused in these papers uggests otherwise.245ReferencesBillot, S. and B. Lang.
1989.
The structure ofshared forests in ambiguous parsing.
In 27th An-nual Meeting of the ACL, pages 143-151.Booth, T.L.
1967.
Sequential Machines and Au-tomata Theory.
Wiley, New York.Carroll, J.A.
1993.
Practical unification-based pars-ing of natural language.
Technical Report No.314, University of Cambridge, Computer Labora-tory, England.
PhD thesis.Earley, J.
1970.
An efficient context-free parsing al-gorithm.
Communications ofthe ACM, 13(2):94-102.Harrison, M.A.
1978.
Introduction to Formal Lan-guage Theory.
Addison-Wesley.Johnson, M. 1991.
The computational complexi-ty of GLR parsing.
In Tomita (1991), chapter 3,pages 35-42.Kipps, J.R. 1991.
GLR parsing in time O(n3).
InTomita (1991), chapter 4, pages 43-59.Lang, B.
1974.
Deterministic techniques for ef-ficient non-deterministic parsers.
In Automata,Languages and Programming, 2nd Colloquium,LNCS 14, pages 255-269, Saarbrficken.
Springer-Verlag.Leermakers, R. 1989.
How to cover a grammar.
In27th Annual Meeting of the ACL, pages 135-142.Leermakers, R. 1992a.
A recursive ascent Earleyparser.
Information Processing Letters, 41(2):87-91.Leermakers, R. 1992b.
Recursive ascent parsing:from Earley to Marcus.
Theoretical ComputerScience, 104:299-312.Nederhof, M.J. 1993.
Generalized left-corner pars-ing.
In Sixth Conference of the European Chapterof the ACL, pages 305-314.Nederhof, M.J. 1994a.
Linguistic Parsing and Pro-gram Transformations.
Ph.D. thesis, Universityof Nijmegen.Nederhof, M.J. 1994b.
An optimal tabular parsingalgorithm.
In 32nd Annual Meeting of the ACL,pages 117-124.Nederhof, M.J. and K. Koster.
1992.
A customizedgrammar workbench.
In J. Aarts, P. de Haan,and N. Oostdijk, editors, English Language Cor-pora: Design, Analysis and Exploitation, Papersfrom the thirteenth International Conference onEnglish Language Research on Computerized Cor-pora, pages 163-179, Nijmegen.
Rodopi.Nederhof, M.J. and J.J. Sarbo.
1993.
Increasingthe applicability of LR parsing.
In Third Interna-tional Workshop on Parsing Technologies, pages187-201.Nederhof, M.J. and G. Satta.
1994.
An extendedtheory of head-driven parsing.
In 32nd AnnualMeeting of the ACL, pages 210-217.Pager, D. 1970.
A solution to an open problem byKnuth.
Information and Control, 17:462-473.Rekers, J.
1992.
Parser Generation for InteractiveEnvironments.
Ph.D. thesis, University of Am-sterdam.Schabes, Y.
1991.
Polynomial time and space shift-reduce parsing of arbitrary context-free gram-mars.
In 29th Annual Meeting of the ACL, pages106-113.Schauerte, R. 1973.
Transformationen vonLR(k)-grammatiken.
Diplomarbeit, Universit~itGSttingen, Abteilung Informatik.Schoorl, J.J. and S. Belder.
1990.
Computation-al linguistics at Delft: A status report.
ReportWTM/TT 90-09, Delft University of Technology,Applied Linguistics Unit.Shann, P. 1991.
Experiments with GLR and chartparsing.
In Tomita (1991), chapter 2, pages 17-34.Sheil, B.A.
1976.
Observations on context-free pars-ing.
Statistical Methods in Linguistics, pages 71-109.Sippu, S. and E. Soisalon-Soininen.
1990.
Pars-ing Theory, Vol.
II: LR(k) and LL(k) Parsing.Springer-Verlag.Tomita, M. 1986.
Efficient Parsing for Natural Lan-guage.
Kluwer Academic Publishers.Tomita, M., editor.
1991.
Generalized LR Parsing.Kluwer Academic Publishers.van Wijngaarden, A. et at.
1975.
Revised report onthe algorithmic language ALGOL 68.
Acta Infor-matica, 5:1-236.Villemonte de la Clergerie, E. 1993.
AutomatesPiles et Programmation Dynamique -- DyALog:Une application h la Programmation en Logique.Ph.D.
thesis, Universit@ Paris VII.Vosse, T.G.
1994.
The Word Connection.
Ph.D.thesis, University of Leiden.246
