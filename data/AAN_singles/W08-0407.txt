Proceedings of the Second ACL Workshop on Syntax and Structure in Statistical Translation (SSST-2), pages 55?60,ACL-08: HLT, Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsExperiments in discriminating phrase-based translations on the basis ofsyntactic coupling featuresVassilina Nikoulina and Marc DymetmanXerox Research Centre EuropeGrenoble, France{nikoulina,dymetman}@xrce.xerox.comAbstractWe describe experiments on discriminatingEnglish to French phrase-based translationsthrough the use of syntactic ?coupling?
fea-tures.
Using a robust rule-based dependencyparser, we parse both the English source andthe French translation candidates from the n-best list returned by our phrase-based system;we compute for each candidate a number ofcoupling features, that is, values that dependon the amount of alignment between edges inthe source and target structures, and discrim-inatively train the weights of these couplingfeatures.
We compare different feature combi-nations.
Although the improvements in termsof automatic measures such as Bleu and Nistare inconclusive, an initial human assessmentof the results appears to show certain qualita-tive improvements.1 Introduction1.1 MotivationWhen we use the phrase-based SMT system MA-TRAX (Simard et al, 2005) to translate the sen-tence Our declaration of rights is the first of thismillenium from English to French, the result re-turned by the system is the erroneous translationNotre de?claration des droits de la premie`re est dece mille?naire, while somewhere down the n-best listof lesser-scored candidates we find a correct transla-tion: Notre de?claration des droits est la premie`re dece mille?naire.On closer inspection, the difference of scores be-tween the two candidates is the following.
In thesecond (correct) case, the phrase of rights was trans-lated into the phrase des droits, while in the first (in-correct) case, the phrase of was translated into thephrase de and the phrase rights into the phrase desdroits.
However, while the two bi-phrases of/de andrights/des droits independently make perfect sense,the sequence de des droits in French is not possi-ble, a situation which is easily detected by a stan-dard ngram language model; the language model hasthen a tendency to try to place the (in fact superflu-ous) de at a further place in the target (just beforela premie`re), where it is more acceptable to it.
Theoverall consequence is a translation that while for-mally possible from the viewpoint of a simple lan-guage model, is not an adequate representation ofthe meaning of the source.Now suppose that we parse both the source andthe two candidates with a dependency parser.
If wecompare the parses of the source and of the correcttranslation, we find a close (in the current exam-ple, very close) isomorphism between dependencyedges connecting pairs of aligned words (s1, s2) and(t1, t2), where si is aligned to ti: the presence ofan edge between s1 and s2 often implies that of anedge between t1 and t2.
This is less the case if wecompare the parses of the source and of the incor-rect translation; in this case, the word premie`re isnow linked to droits, while the word first was linkedto millenium.While this is of course just one example, it doeshelp to motivate the approach we have taken: wecompute different measures of association strengthbetween edges in the source and target dependencytrees, and use these measures as features for rerank-55ing the n-best candidates of a baseline phrase-basedsystem.
The hope is that by doing so, we will in-crease the adequacy of translations, and possibly tosome extent, their fluency (at least their ?seman-tic?
fluency, which is influenced by their adequacy,as opposed to their ?grammatical?
fluency, whichwould be better addressed by target-specific syntac-tic features than by coupling syntactic features).1.2 Related WorkThere is a growing body of work on the use of syntaxfor improving statistical machine translation, fromapproaches such as (Chiang, 2007) that use ?formalsyntax?, that is syntactic structures for the sourceand target that are discovered on the basis of a bilin-gual corpus, but without resort to an externally mo-tivated parser, to approaches such as (Yamada andKnight, 2001) and (Marcu et al, 2006) that use anexternal parser on the target only, or such as (Quirket al, 2005) on the source only, or such as (Cowan etal., 2006) that use external parsers both on the sourceand on the target.Our approach is in this last category, but is distin-guished from all the cited approaches by the fact thatit does not try to build a target structure (or string)directly, but rather by using a baseline phrase-basedsystem as a generator of candidates, and then select-ing between these candidates through a discrimina-tive procedure.
Some other researchers have taken asimilar line, for example (Hasan et al, 2006), whichonly uses a parser on the target, and attempts to im-prove the fluency of the translation produced, and es-pecially (Och et al, 2003) that reports experimentsusing a large number of syntactic features.
In oneof the experiments briefly reported, a dependencyparser is used both for the source and for the tar-get and a few features are introduced for countingthe number of edges that project from the sourceto the target.
This experiment, which as far as weknow was not followed up by deeper investigations,is very similar to what we do.
However we intro-duce and compare results for a wider variety of cou-pling features, taking into account different combi-nations involving normalization of the counts, sym-metrized features between the source and target, la-belled dependencies, and also consider several waysfor computing the word alignment on the basis ofwhich edge couplings are determined.2 The approach2.1 BackgroundMatrax.
The phrase-based SMT system Matrax(Simard et al, 2005), developed at Xerox, wasused in the experiments.
Matrax is based on afairly standard log-linear model, but one original as-pect of the system is the use of non-contiguous bi-phrases.
Most existing phrase-based models dependon phrases that are sequences of contiguous wordson either the source or the target side (e.g.
pren-dre feu / catch fire).
By contrast, Matrax considerspairs of non-contiguous phrases, such as ne ... plus /not ... anymore, where words in the source and tar-get phrases may be separated by gaps, to be filledat translation time by lexical material provided bysome other such pairs.
One motivation behind thisapproach is that, basically, the fact that the sourceexpression ne ... plus is a good predictor of not... anymore does not depend on the lexical materialappearing inside the source expression, an insightwhich is generally unexploitable by models basedon contiguous phrases.1XIP.
For parsing, we used the Xerox Incremen-tal Parser XIP (A?
?t-Mokhtar et al, 2002), which isa robust dependency parser developed at the XeroxResearch Centre Europe.
XIP is fast (around 2000words per second for English) and is well adapted toa situation, like the one we have here, were we needto parse on the order of a few hundred target candi-dates on the fly.
Also of interest to us is the fact thatXIP produces labelled dependencies, a feature thatwe use in some of our experiments.2.2 Decoding and TrainingCoupling features such as the ones we use requireaccess to the parses of candidate translations, andthese parses, at least for a parser such as XIP (andfor many similar parsers), can only be obtained oncethe complete candidate translation is known.
This iswhy it is difficult to introduce them internally in theMatrax stack-based decoder, which would require toprovide partial parses for prefixes of the target can-didates and also associated heuristics to estimate thesyntactic structure of completions of these prefixes.1The Hiero system (Chiang, 2007) is a well-known in-stance of a structure-oriented system that also has a notion ofgapped phrases, but contrary to Hiero, Matrax is based on non-hierarchical phrases.56Instead, we resort to a standard reranking approachin which we produce an n-best list of Matrax candi-date translations (with n = 100 in our experiments),and then rerank this list with a linear combinationof our parse-dependent features.
In order to trainthe feature weights, we use an averaged structuredperceptron approach a` la Collins, where we try tolearn weights such that the first candidate to emergeis equal to the ?oracle?
candidate, that is, the candi-date that is closest to the reference in terms of NISTscore.2.3 Coupling FeaturesOur general approach to computing coupling fea-tures between the dependency structure of the sourceand that of a candidate translation produced by Ma-trax is the following: we start by aligning the wordsbetween the source and the candidate translation, weparse both sides, and we count (possibly accordingto a weighting scheme) the number of configura-tions (?rectangles?)
that are of the following type:((s1, s12, s2), (t1, t12, t2)), where s12 is an edge be-tween s1 and s2, t12 is an edge between t1 and t2,s1 is aligned with t1 and s2 is aligned with t2.
Weimplemented several variants of this basic scheme.We start by describing different ?generic?
cou-pling functions derived from the basic scheme, as-suming that word alignments have been already de-termined, then we describe the option of taking intoaccount specific dependency labels when countingrectangles, and finally we describe two options forcomputing the word alignments.2.3.1 Generic featuresThe first measure of coupling is based on sim-ple, non-weighted, word alignments.
Here we sim-ply consider that a word of the source and a wordof the target are aligned or not aligned, without anyintermediary degree, and consider that a rectangleexists on the quadruple of words s1, s2, t1, t2 iff siis aligned to ti, s1 and s2 have a dependency linkbetween them (in whatever direction) and similarlyfor t1 and t2.
The first feature that we introduce,Coupling-Count, is simply the count of all such rect-angles between the source and the target.We note that the value of this feature tends to becorrelated with the size of the source and target de-pendency trees.
We therefore introduce some nor-malized variants of the feature:?
Coupling-Recall.
We compute the number ofsource edges for which there exists a projec-tion in the target.
More formally, the number ofedges between two words s1, s2 such that thereexist two words t1, t2 with si aligned to ti andsuch that t1, t2 have an edge between them.
Wethen divide this number by the total number ofedges in the source.?
Coupling-Precision.
We do the same thing thistime starting from the target.?
Coupling-F-measure.
In the case of perfectlyisomorphic dependency trees (a situation thatof course rarely occurs because of the linguis-tic divergences between languages), we wouldhave precision and recall both equal to 1.
In or-der to measure divergence from this ideal case,we introduce a feature that we call Coupling-F-measure, which is defined as the harmonicmean of the two previous features.One deficiency of the previous measures is thatthey rely a lot on ?hard?
word alignments, but do nottake into account the probability of aligning a sourceand a target word.
We introduce another featureCoupling-Lex that exploits lexical translation prob-abilities: each rectangle found between the sourceand target trees is weighted according to the prod-uct of the translation probabilities associated with(s1, t1) and (s2, t2).2.3.2 Label-specific featuresThe features previously defined do not take intoaccount the labels associated with edges in the de-pendency trees.
However, while rectangles of theform ((s1, subj, s2), (t1, subj, t2)) may be rather sys-tematic between such languages as English andFrench, other rectangles may be much less so, dueon the one hand to actual linguistic divergences be-tween the two languages, but also, as importantlyin practice, to different representational conventionsused by different grammar developers for the twolanguages.2In order to control this problem, we introduce acollection of Label-Specific-Coupling features, eachfor a specific pair of source label and target label.2Although the XIP formalism is shared between grammardevelopers of French and English, the grammars do sometimesfollow slightly different conventions.57The values of a label-specific feature are the num-ber of occurrences for this specific label pair.
Weuse only label pairs that have been observed to bealigned in the training corpus (that is, that partici-pate in observed rectangles).
In one version of thatapproach, we use all such pairs found in the corpus,in another version only the pairs above a certain fre-quency threshold in the corpus.2.3.3 Giza-based alignmentIn order to compute the features described above,a prerequisite is to be able to determine a word align-ment between the source and a candidate transla-tion.
Our first approach is to use GIZA++ to createthese alignments, by producing for a given sourceand a given candidate translation n-best alignmentlists in both directions and applying standard tech-niques of symmetrization to produce a bidirectionalalignment.2.3.4 Phrase-based alignmentAnother way to find word alignments is to use theinformation provided by our baseline system.
SinceMatrax is a phrase-based system, it has access tothe bi-phrases (aligned by definition) that are usedin order to generate a candidate translation.
How-ever note that if we use the bi-phrases directly weare not able to establish the alignments on a wordlevel (since Matrax does not provide any informa-tion about word alignments inside the bi-phrases),but only on a phrase level, and we need to adapt thecoupling features accordingly.To overcome this problem, we will transform thedependencies between words into dependencies be-tween phrases.
Thus, two phrases c1, c2 will have adependency edge between them if there exists a de-pendency edge between a word w1 ?
c1 and a wordw2 ?
c2.
Once this transformation is done bothfor the source and the target, we get dependencygraphs having phrases as nodes.
We also know thealignments between these phrases, implicit in the bi-phrases used by Matrax.
So, we can consider thephrases as super-words, and introduce coupling fea-tures of the same type as before, but operating on ahigher level (super-words) this time.3 Experiments3.1 DescriptionFor all our experiments we use the training, develop-ment and test sets provided for the English-FrenchNews Commentary corpus in WMT-08.
The num-ber of sentences in these sets are respectively 55039,1057 and 1064, and the average sentence length is 21words (English) and 24.5 words (French).We take Matrax as the baseline system.
With thissystem we generate 100-best lists of candidate trans-lations for all source sentences of the test set, wererank these candidates using our features, and weoutput the top candidate.
We present our results inTable 1, distinguished according to the actual com-bination of features used in each experiment.?
The Baseline entry in the table corresponds toMatrax results on the test set, without the useof any of the coupling features.?
We distinguish two sub-tables, according towhether Giza-based alignments or phrase-based alignments were used.?
The Generic keyword corresponds to the cou-pling features introduced in section 2.3.1, basedon rectangle counts, independent of the labelsof the edges.?
The Matrax keyword corresponds to using Ma-trax ?internal?
features as reranking features,along with the coupling features.
These Ma-trax features are pretty standard phrase-basedfeatures, apart from some features dealing ex-plicitly with gapped phrases, and are describedin detail in (Simard et al, 2005).?
The Labels and Frequent Labels keywords cor-responds to using label-specific features.
Inthe first case (Labels) we extracted all of thealigned label pairs (label pair associated with acoupling rectangle) found in a training set of1000 source sentences along with their 100-best Matrax translations (this set was chosento be different from the development set in or-der to avoid overfitting effects when rerank-ing on the development set); we then obtained2053 features of this kind.
In the second case58NIST BLEU - + DiffBaseline 6.4093 0.2034 0 0 0Giza-based alignmentsGeneric 6.3383 0.2043 15 17 2Generic, Matrax 6.3782 0.2083 4 18 14Labels 6.3483 0.1963 12 18 6Labels, Generic 6.3514 0.2010 3 18 15Labels, Generic, Matrax 6.4016 0.2075 3 20 17Frequent Labels 6.3815 0.2054 7 11 4Frequent Labels, Generic 6.3826 0.2044 6 18 12Frequent Labels, Generic, Matrax 6.4177 0.2100 2 16 14Phrase-based alignmentsGeneric 6.2869 0.1964 12 14 2Generic, Matrax 6.3972 0.2031 4 11 7Labels 6.3677 0.1995 16 15 -1Labels, Generic 6.3567 0.1977 8 15 7Labels, Generic, Matrax 6.4269 0.2049 4 17 13Frequent Labels 6.3701 0.1998 3 15 12Frequent Labels, Generic 6.3846 0.2013 7 16 9Frequent Labels, Generic, Matrax 6.4160 0.2049 4 16 12Giza Generic, Phrase Generic, Giza Labels, Matrax 6.4351 0.2060 7 22 15Table 1: Reranking results.
(Frequent Labels), we only kept the most fre-quently observed among these label pairs, re-taining only 137 such features.?
When several keywords appear on a line, weused the union of the corresponding features,and in the last line of the table, we show acombination involving at the same time somefeatures computed on the basis of Giza-basedalignments and of phrase-based alignments.?
Along with the NIST and BLEU scores of eachcombination3, we also conducted an informalmanual assessment of the quality of the resultsrelative to the Matrax baseline.
We took a ran-dom sample of 100 source sentences from thetest set and for each sentence, assessed whetherthe first candidate produced by reranking wasbetter, worse, or indistinguishable in terms ofquality relative to the baseline translation.
Wereport the number of improvements (+) and de-teriorations (-) among these 100 samples aswell as their difference.3These scores were computed on the basis of only one ref-erence.3.2 Discussion of the resultsWhile the overall results in terms of Bleu and Nistdo not show major improvements relative to thebaseline, there are several interesting observations tomake.
First of all, if we focus on feature combina-tions in which Matrax features are included (shownin italics in the table), we see that there is a gen-eral tendency for the results, both in terms of auto-matic and human evaluations, to be better than forthe same combination without the Matrax features;the explanation seems to be that if we do not use theMatrax features during reranking, but consider the100 candidates in the n-best list to be equally valu-able from the viewpoint of Matrax features, we loseessential information that cannot be recovered sim-ply by appeal to the syntactic coupling features.4If we now concentrate on the lines which do in-clude Matrax features and compare their results withthe baseline, we see a trend for these results to bebetter than the baseline, both in terms of automaticmeasures as (more strongly) in terms of human eval-4This is not very surprising and probably on the basis of thisobservation it would be useful in further experiments to intro-duce as an additional feature the log-linear score given by theMatrax baseline.59uation.
Taken individually, perhaps the improve-ments are not very clear, but collectively, a trenddoes seem to appear in favor of syntactic couplingfeatures generally, although we have not conductedformal statistical tests to validate this impression.
Amore detailed comparison between individual lines,inside the class of combinations that include Matraxfeatures, appears however difficult to make on thebasis of the current experiments.4 Conclusion and PerspectivesAlthough there is some consensus that the futureof statistical machine translation lies in the use ofstructural information, it is generally admitted thatit is currently difficult to significantly improve overphrase-base systems in this way, at least in terms ofautomatic evaluation measures.
Our results do notcontradict that impression, although they are moreencouraging in terms of preliminary human asses-ments than in terms of the automatic measures.The reranking approach to using syntactic fea-tures on top of a phrase-based system is attractivebecause on the one hand it is easier to implementthan a full new syntax-aware decoder, and on theother hand it guarantees at least as good perfor-mance as the baseline phrase-based system, if someprecautions are taken.
On the other hand, its mainlimitations concern the size of the n-best list of can-didates that is realistic in terms of decoding time.5At least two approaches seem promising in order toalleviate this problem: (1) find a way to capitalizeon the factorization of translation candidates in theinternal lattice used by the phrase-based decoder, inorder to produce factorized parses that would permitcomparison between more candidates than can beseen through a final n-best list; (2) allow the rerankerto perform local transformations of the n-best candi-dates, in the spirit of (Langlais et al, 2007), in orderto be able to explore a larger space of promising can-didates than is provided by the static list.Another interesting direction would be to learnthe feature weights by reranking towards anothertype of oracle than the one we used, which is de-fined as the closest candidate in the list in terms ofNIST score relative to the reference; instead it might5It should be noted however that we could increase this sizefrom 100 to 1000 without incurring too much penalty, given thespeed of the XIP parser we use.be worthwhile to use as an oracle the candidate inthe list which receives the best human assessmentin terms of fluency and adequacy, giving a betterchance to the syntactic features to show their worth;but this would probably also require that these sys-tems be mostly evaluated in terms of human assess-ment, a trend which is more and more noticeable inthe SMT community.ReferencesSalah A?
?t-Mokhtar, Jean-Pierre Chanod, and ClaudeRoux.
2002.
Robustness beyond shallowness: incre-mental deep parsing.
Natural Language Engineering,8(3):121?144.David Chiang.
2007.
Hierarchical phrase-based transla-tion.
Computational Linguistics, 33(2):201?228.Brooke Cowan, Ivona Kucerova, and Michael Collins.2006.
A discriminative model for tree-to-tree trans-lation.
In Proceedings EMNLP.Sas?a Hasan, Oliver Bender, and Hermann Ney.
2006.Reranking translation hypotheses using structuralproperties.
In Proceedings of the EACL Workshop onLearning Structured Information in Natural LanguageApplications.Philippe Langlais, Alexandre Patry, and Fabrizio Gotti.2007.
A greedy decoder for phrase-based statisticalmachine translation.
In Proceedings of the 11th Inter-national Conference on Theoretical and Methodolog-ical Issues in Machine Translation, pages 104?113,Skvde, Sweden, Sept.D.
Marcu, W. Wang, A. Echihabi, and K. Knight.2006.
SPMT: Statistical Machine Translation withSyntactified Target Language Phrases.
In ProceedingsEMNLP, pages 44?52.Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur,Anoop Sarkar, Kenji Yamada, Alex Fraser, ShankarKumar, Libin Shen, David Smith, Katherine Eng,Viren Jain, Zhen Jin, and Dragomir Radev.
2003.
Syn-tax for statistical machine translation: Final report ofjohn hopkins 2003 summer workshop.
Technical re-port, John Hopkins University.Chris Quirk, Arul Menezes, and Colin Cherry.
2005.
De-pendency treelet translation: Syntactically informedphrasal SMT.
In ACL05.Michel Simard, Nicola Cancedda, Bruno Cavestro,Marc Dymetman, E?ric Gaussier, Cyril Goutte,Kenji Yamada, Philippe Langlais, and Arne Mauser.2005.
Translating with non-contiguous phrases.
InHLT/EMNLP.Kenji Yamada and Kevin Knight.
2001.
A syntax-basedstatistical translation model.
In Proceedings ACL,pages 531?538.60
