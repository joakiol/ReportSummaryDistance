Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 851?861,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsLearning Knowledge Graphs for Question Answeringthrough Conversational DialogBen HixonUniversity of WashingtonComputer Science & EngineeringSeattle, WA, USAbhixon@cs.washington.eduPeter ClarkAllen Institute for AISeattle, WA, USApeterc@allenai.orgHannaneh HajishirziUniversity of WashingtonElectrical EngineeringSeattle, WA, USAhannaneh@washington.eduAbstractWe describe how a question-answering sys-tem can learn about its domain from conver-sational dialogs.
Our system learns to relateconcepts in science questions to propositionsin a fact corpus, stores new concepts and re-lations in a knowledge graph (KG), and usesthe graph to solve questions.
We are the firstto acquire knowledge for question-answeringfrom open, natural language dialogs without afixed ontology or domain model that predeter-mines what users can say.
Our relation-basedstrategies complete more successful dialogsthan a query expansion baseline, our task-driven relations are more effective for solvingscience questions than relations from generalknowledge sources, and our method is practi-cal enough to generalize to other domains.1 IntroductionOur goal is a question-answering (QA) system thatlearns about its domain from users in open, nat-ural language dialogs.
Dialog learning interfacesbuilt on top of existing QA systems can complementand refine knowledge acquired from other sources.Even large QA systems such as Watson (Ferrucciet al, 2010) that utilize heavy domain engineeringcould benefit from focused dialogs to dynamicallyimprove their knowledge.A successful QA system requires domain knowl-edge.
For example, 4th grade science questions aredifficult since they often exclude knowledge neces-sary to relate answers to known facts.
The questionin Figure 1 asks if an iron nail conducts electricity;S1: Here?s the question: Which object is the best conductor ofelectricity?
(A) a wax crayon (B) a plastic spoon (C) a rubbereraser (D) an iron nail.
I?m not sure of the answer.
What doyou think the answer is?U1: iron nailS2: Why do you think the answer is (D) an iron nail?U2: electricity goes through metalS3: I know ?metals are shiny and good conductors of electricityand heat,?
does that mean that the answer is (D) an iron nail?U3: yeahS4: Okay, great.
What?s the relationship between ?electricity?and ?iron?, if any?U4: iron conducts electricity because its metalS5: Okay, great, I get it!
The answer is (D) an iron nailFigure 1: Top: A successful real user dialog.
Open-ended prompts (S1&S2) encourage conversationalexplanations.
Focused prompts (S4) target particularrelations.
Bottom: Corresponding knowledge graphconsisting of relations between concepts.the system only knows that metal conducts electric-ity, and it needs to learn that iron is a metal in orderto answer the question with the relevant fact.Our dialog system, KNOWBOT, conducts dialogsabout science questions and learns how conceptsin each question relate to propositions in a corpusof science facts.
KNOWBOT presents its user witha question (line S1 in Figure 1), prompts them tochoose and explain their answer, and extracts rela-tions ?
any semantic relationship between two con-851cepts, such as metal to iron (line U4 in Figure 1) ?that increase its confidence in the user?s answer.Relation extraction systems such as NELL (Carl-son et al, 2010) use ontologies to predetermine validrelation types and arguments, then scan text to fillthe ontology with facts.
Open Information Extrac-tion (Etzioni et al, 2011) avoids fixed ontologieswith domain-independent linguistic features, distantsupervision, and redundancy, but requires web-scaletext and doesn?t improve with interaction.
LikeOpen IE, we extract relations without predeterminedtypes, but are the first to do so from dialog.KNOWBOT is an open dialog system, whichmeans a user utterance may progress the dialog taskeven if its underlying action is not explicitly rep-resented in a dialog model.
This lets KNOWBOTquickly bootstrap domain knowledge from userswithout significant engineering overhead.
Dialog-driven extraction produces effective relations with-out annotation, improves after each interaction, ac-quires relations useful on a particular task, and em-beds relations in a rich dialog context.Users successfully correct the system in approxi-mately 50% of dialogs even without a predetermineddialog model.
A baseline query expansion (Bast etal., 2007) strategy that bases decisions on the acqui-sition of new keywords instead of new relations re-sults in only a 5% success rate.
In comparison toparaphrase relations from general knowledge bases,relations acquired by our method are more effectiveas domain knowledge, demonstrating that we suc-cessfully learn from real users.Our contributions include:1.
The first end-to-end system to construct knowl-edge graphs for question-answering throughconversational dialog.2.
A generalizable method to represent the mean-ing of user utterances without a dialog modelwhen task progression can be computed as afunction of extracted relations.3.
A novel data set of real user dialogs in whichusers correct a QA system?s answer, togetherwith knowledge graphs representing the impor-tant concepts and relations in each question, la-beled with rich dialog features.2 Conversational extraction for QAOur QA task consists of 107 science questions fromthe 4th grade New York Regents exam (Clark et al,2014).1Each question has four possible answers.We convert each of the four question-answer pairsinto a true/false question-answer statement using asmall number of pattern-based transformation rules.Just as 4th graders read their textbooks for an-swers, we collect SCITEXT (Clark et al, 2014), acorpus of unlabeled true-false natural language sen-tences from science textbooks, study guides, andWikipedia Science.
Each question-answer statementis associated with a subset of true/false support sen-tences from SCITEXT based on positive word over-lap between the question-answer pair and the sup-port sentence.
The degree to which a SCITEXT sen-tence supports a question-answer pair is the sen-tence?s alignment score (section 2.3).Initially, the alignment score depends on keywordoverlap alone, but SCITEXT needs domain knowl-edge to answer our questions.
For example, the cor-rect question-answer statement to What form of en-ergy causes an ice cube to melt?
(A) mechanical(B) magnetic (C) sound (D) heat is Q(D), ?Heat is aform of energy and heat causes an ice cube to melt.
?To better align Q(D)to the SCITEXT sentence ?Asnowball melting in your hand is an example of heatenergy,?
we need to know that snowballs are madeof ice.
Figure 2 illustrates this example.To construct a knowledge base with which to useSCITEXT, we extract concepts (section 2.1) fromquestions and SCITEXT sentences, then use relations(section 2.2) between concepts to determine whichquestion-answer statementQiis most highly alignedwith a supporting SCITEXT sentence.2.1 ConceptsA concept keyword in a sentence or user utter-ance is any non-stopword of at least three char-acters.
Stopwords are domain-independent, low-information words such as ?the.
?A concept is a set of concept keywords with acommon root, e.g.
{melts, melted, melting} or{heat, heats, heated}.
We use the Porter algorithmfor stemming (Porter, 1997).
Question concepts ap-1Our dialogs, extractions, and tools are available atwww.cs.washington.edu/research/nlp/knowbot852pear in a question-answer statement, and supportconcepts appear in a SCITEXT support sentence.2.2 RelationsA relation is any pair of concepts that represents asemantic correspondence.
In general, relations canbe labeled with any feature that describes the corre-spondence, such as a particular type.
For example,the relation between Obama and Hawaii can be la-beled with the type born-in.A predetermined ontology is typically required tolabel relations with their type.
In this work we la-bel acquired relations with dialog-specific features.Our thesis is that user explanations intend to relateconcepts together, and the system?s task is to deter-mine the user?s intent.
For example, the user utter-ance U: it?s melting because of heatrelates the concepts represented by melt[ing] andheat, with the words because of appearing be-tween the two concept keywords.
We refer tobecause of as the relation?s intext.Relations can be intuitively arranged as a knowl-edge graph, which in this work is any graph whosenodes are concepts and whose edges are relationsbetween those concepts, in the spirit of semantic net-works such as ConceptNet (Havasi et al, 2007).2.3 Sentence alignmentWe calculate the alignment score ?
between the ithquestion-answer statement Qiand its jth supportingSCITEXT sentence Si,jas the normalized number ofrelations between their concepts,?
(Qi, Si,j) =?RQi,Si,j??CQi?
CSi,j?, (1)where CQiis the set of concepts in Qi, CSi,jis theset of concepts in Si,j, and ?RQi,Si,j?
is the numberof relations between CQiand CSi,j.Normalized relation count is a practical semanticsimilarity score that generalizes to different knowl-edge representations.
The dialog in Figure 2 alignsQ(D)with the SCITEXT fact S by learning from theuser that, for example, heat is related to melting.3 The KNOWBOT dialog systemKNOWBOT grows a knowledge graph of common-sense semantic relations in open, conversational dia-log.
Figure 2 traces the growth of a knowledge graphover a single dialog.
Section 3.1 details how knowl-edge is extracted from user explanations without adialog model.
Section 3.2 describes dialog strate-gies that elicit natural language explanations.KNOWBOT uses task progress to drive natural lan-guage understanding.
It assumes the user intendsto provide one or more novel relations, and usesthe constraints described in section 3.1.1 to disam-biguate noisy relations.
This way, KNOWBOT knowswhen the dialog progresses because its confidence inthe user?s chosen answer increases.3.1 Building knowledge graphs from dialogKNOWBOT builds KGs at three levels: per utter-ance, per dialog, and globally over all dialogs.
Anutterance-level knowledge graph (uKG) (Figure 2a)is a fully connected graph whose nodes are all con-cepts in an utterance.
After aggressive pruning (sec-tion 3.1.1), remaining edges update a dialog-levelknowledge graph (dKG) (Figure 2b; section 3.1.2).Upon dialog termination, the dKG updates theglobal knowledge graph (gKG), which stores rela-tions acquired from all dialogs (section 3.1.3).3.1.1 Utterance-level KGsKNOWBOT initially relates every pair of concepts inan utterance, then prunes them based on two con-straints: alignment and adjacency.Each user explanation is first converted into afully-connected utterance-level knowledge graph.This uKG is noisy because users don?t intendrelations between every pair of keywords intheir utterance.
For example, a typical utteranceU: freezes means it changes waterfrom a liquid to a solid mentions sixconcepts, freezing, meaning, change, water, liquid,solid, with(62)potential binary relations.
Not everyrelation is salient to the question.
To remove noisyrelations, edges in the uKG are aggressively prunedwith two simple, rational constraints:1.
Alignment.
An edge can only relate a questionconcept to a support concept.2.
Adjacency.
Edges can?t relate concepts whosekeywords are adjacent in the utterance.The intuition for the alignment constraint is that theuser intends each explanation to relate the question853(a) utterance-level knowledge graph (uKG)(b) dialog-level knowledge graph (dKG)(c) The dialog goal is to align Q and SFigure 2: Every pair of concepts in each user utterance is related then aggressively pruned.
(a) Utterance-levelknowledge graphs represent individual utterances.
Concepts (underlined, inset in nodes) are obtained by removingstopwords and stemming.
An edge that either doesn?t connect a question and support concept or else which connectsconcepts whose keywords in the user utterance have no intervening words (intexts) are pruned, indicated here withdashed lines.
(b) The four remaining relations are stored in a dialog-level dKG.to a known fact, and other relations in the utter-ance are unintentional.
For example, in the uKG forthe first utterance in Figure 2(a), the edge betweenmelt[ing] and heat is an alignment relation becausemelt[ing] is a concept in S and heat is a concept inQ.
But the edge between because and heat is pruned(dashed lines) since because is not a concept in S.Adjacency is a simple, practical syntactic fea-ture to reduce spurious relations.
Users typicallyput words or intexts between concepts they in-tend to relate.
The edge between melt[ing] andbecause is pruned since their keywords are ad-jacent in U1: it?s melting because ofheat, while U2 relates snow and ice with the intexthas the same behavior as the.We find these constraints effective in practice, butat this point other pruning constraints can be de-ployed.
A strength of our approach is that it wel-comes aggressive pruning: just as in human-humaninteraction, users who initially fail to communicatetheir intention can try again later in the dialog.3.1.2 Dialog-level KGsEach dialog focuses on a single question.
KNOW-BOT starts with an empty dialog-level knowledgegraph (dKG).
After each user turn, edges from thatturn?s uKG are added to the dKG, and KNOWBOTrescores each of the four answers according to equa-tion (1) where the set of relations RQi,Si,jis exactlythe set of edges in the dKG.
The dialog successfullyterminates when the user?s answer has the high-est alignment score, indicating the ?missing knowl-edge?
has been successfully provided by the user.3.1.3 The global knowledge graphThe global knowledge graph (gKG) includes everyrelation learned from every KNOWBOT dialog.Because we do not use a fixed ontology or com-prehensive dialog model, individual dialogs can re-sult in noisy relations even after aggressive prun-ing.
However, as KNOWBOT conducts more dialogsabout the same problem, relations that more oftenre-occur are more likely to be salient to the problem.In this work, KNOWBOT takes advantage of re-dundancy with a simple filter: it ignores singletonrelations originating in a single user utterance.
Wefind even this simple filter increases performance.As KNOWBOT accumulates more dialogs, frequencycan be incorporated in more sophisticated models.3.2 Dialog strategies for knowledge acquisitionWe?ve described how a user?s free text explana-tions are converted into knowledge graphs.
Eachuser explanation is uttered in response to a system854prompt.
A dialog system?s dialog manager choosesthe prompt to say next according to its dialog strat-egy, which maps each system state to an action.
Aneffective dialog strategy guides users to informativeexplanations that provide novel relations which letKNOWBOT successfully answer the question.We compare two different strategies.
A user-initiative strategy always asks open-ended questionsto prompt the user for new explanations, e.g.
lineS2 in Figure 1.
These prompts let users introducesalient concepts on their own.In contrast, a mixed-initiative strategy utilizes fo-cused prompts (line S4 in Figure 1) to introduce po-tentially related concepts.
KNOWBOT chooses whatpair of concepts to ask about based on how discrim-inative they are.
The most discriminative conceptsare the pair of question and support concepts that(1) don?t already have an edge between them, (2)satisfies the alignment constraint for the user?s an-swer, and (3) satisfies the alignment constraint forthe fewest alternative answers.
By proposing rela-tions that would lead to a swift completion of thedialog task, KNOWBOT shares the burden of knowl-edge acquisition with the user.Both dialog strategies are question-independent,but because we don?t use a comprehensive dialogmodel to represent the state space, we rely on handbuilt rules instead of optimizing with respect to areward function.
For example, KNOWBOT alwaysstarts by asking the user for their answer, and if anew support sentence is found will always immedi-ately present it to the user for confirmation.4 Evaluation of dialog strategiesOur first experiment compares mixed-initiative anduser-initiative strategies (section 3.2) to a baselineinteractive query expansion (section 4.1).
The pur-pose of this experiment is to investigate whetherusers can successfully complete our complex dialogtask even though we don?t use a trained semanticparser for natural language understanding.Dialogs were conducted through a web browser.Users were colleagues and interns at the Allen Insti-tute for Artificial Intelligence, and so were familiarwith the question-answering task but were not ex-pert annotators.
Users were invited to converse withthe system of their choice, and to move on to a newquestion if they felt the dialog was not progressing.Individual dialog sessions were anonymous.The system starts each dialog with an emptyknowledge graph, using only identity relations to se-lect its answer.
This default answer is correct on44 of the 107 questions, and an additional 10 ques-tions have no associated supporting sentence for thecorrect answer in SCITEXT.
We run dialogs for theremaining 53 questions, for which each answer can-didate has 80 supporting sentences in SCITEXT onaverage.
A successful dialog terminates when thesystem extracts enough novel relations from the userthat the correct answer has the highest alignmentscore with one of its supporting sentences.4.1 Baseline: Interactive query expansionTo evaluate whether task-driven relation extractionis an effective method for knowledge acquisition inthe absence of an explicit dialog model, we also im-plement a baseline dialog strategy based on interac-tive query expansion (IQE).
This baseline is similarto the recent knowledge acquisition dialog system ofRudnicky and Pappu (2014a; 2014b).In IQE, new knowledge is learned in the form ofnovel keywords that are appended to the question-answer statement.
For example, the dialog in Figure1 shows the user teaching KNOWBOT how metal re-lates to electricity.
KNOWBOT understands that theuser intends that relation because it drives the dia-log forward.
IQE, in contrast, treats the user ut-terance as an unstructured bag of keywords.
Theunrecognized word ?metal?
is added to the bag ofkeywords representing each of the four alternativeanswers to form four augmented queries, and newoverlap scores against sentences from SCITEXT arecomputed.
The dialog progresses whenever a newvocabulary word increases the score for the aug-mented query for the user?s chosen answer.The intuition behind query expansion is that userswill explain their answers with salient keywordsmissing from the original question sentence.
The ex-panded query will overlap with and uprank a supportsentence that contains the acquired keywords.4.2 Performance metricsTask completion is the proportion of dialogs thatend in agreement.
Higher task completion indicatesthat the dialog system is more successful in acquir-855ing enough knowledge by the end of the dialog tochange its answer from incorrect to correct.Dialog length is the number of system and userturns.
Shorter dialogs are more efficient.Acquisition rate is the number of edges in thedKG at the end of each dialog.
Acquisition rate mea-sures two contrasting system features:(1) how much new knowledge is acquired, and(2) how much explanatory effort users expend.From the perspective of raw knowledge acquisition,higher acquisition rate is better because each dialogadds more edges to the knowledge graph.
From theperspective of usability, lower acquisition rate is bet-ter provided it doesn?t negatively affect dialog suc-cess, because it indicates the user is able to success-fully correct the system?s answer with a fewer num-ber of explanatory relations.4.3 ResultsOur results (Table 1) show both strategies dramati-cally outperform the baseline and have comparablesuccess rate and dialog length to each other.
User-initiative strategies acquire more knowledge per di-alog but require more user effort.IQE U.I.
M.I.Total dialogs 35 27 57Task completion rate 5.7% 55.6% 49.1%Mean Dialog Length 14.1 10.6 10.9Mean acquisition Rate N/A 13.5 7.4Table 1: Comparison of knowledge acquisition strate-gies.
Interactive query expansion (IQE)?s poor task com-pletion indicates keywords can?t bridge the knowledgegap.
Relations are more successful.
User-initiative (U.I.
)and mixed-initiative (M.I.)
strategies have comparabletask completion and dialog length, but U.I.
extracts twicethe relations before getting the correct answer: moreknowledge acquired but at the cost of more explanatoryeffort.
User comments indicate M.I.
is more satisfying.We find that the baseline has a very low comple-tion rate of 5%, and longer dialog lengths of 14 turnson average.
Interactive query expansion is a poorknowledge acquisition dialog strategy for our task.In contrast, users were able to successfully correctour system using both strategies about 50% of thetime, even though no in-domain ontology guides ex-tractions and no comprehensive dialog model clas-sifies explanations.
The average dialog lengths andcompletion rate for User Initiative (U.I.)
and MixedInitiative (M.I.)
strategies was approximately thesame, so that choice of strategy had little impacton overall task success.
However, strategy has agreat effect on acquisition rate.
M.I.
cuts the knowl-edge acquisition rate nearly in half when comparedto U.I (7.4 novel relations per dialog to 13.5).
M.I.learns fewer new relations per dialog with compara-ble task success, which means each dialog succeedswith much less explanatory effort by the user butalso contributes less to the knowledge graph.User comments indicated that the mixed-initiativestrategy was the most enjoyable system to use.
Wefind that open-ended, user-initiative strategies canacquire more helpful relations in a single dialog butguided, mixed-initiative strategies may be more ap-propriate when usability is taken into account.
Be-cause our goal is lifelong interactive knowledge ac-quisition, the impact of a single dialog on the totalknowledge graph is less important than the individ-ual user effort required, and we conclude that themixed-initiative strategy is preferable.5 Evaluation of knowledge qualityExperiment 1 evaluated whether users could suc-cessfully complete our dialog task.
Next, we eval-uate whether the total output of our system, all rela-tions acquired during all 431 conducted dialogs, rep-resents useful domain knowledge on this task.
Weevaluate on questions for which dialogs have beenheld to investigate whether it?s possible to learn anydomain knowledge from natural language conversa-tion without a dialog model, irrespective of overfit-ting.
We then use cross-validation to test if knowl-edge transfers between questions.As described in section 2, our QA system de-composes each question/answer pair into a true/falsestatement and chooses as its answer the statementamong the four that has the best supporting sentencein a text corpus.
Equation (1) scores each question-answer statement by using domain relations to alignquestion concepts to support concepts.
The next sec-tion describes sources of domain relations.5.1 Sources of domain knowledgeWe compare relations from five sources:856IDENTITY: An edgeless knowledge graph.
Theonly relations are between identical concepts, equiv-alent to Jaccard overlap of concept keyword roots.WORDNET: Paraphrase relations from Wordnet.Wordnet (Fellbaum, 1998) is a lexical database ofsynonyms and hypernyms common in NLP tasks.For example, Snow et al(2006) use Wordnet astraining data for ontology induction.
To buildWORDNET, we draw an edge between every pairof Wordnet concepts (ws, wq) for which the Wu-Palmer Similarity (WUP) (Wu and Palmer, 1994)of the first sense in each concept?s synset exceeds0.9, the best-performing WUP threshold we found.Concepts in the Wordnet hierarchy have a higherWUP when they have a closer common ancestor.
If aknown fact is Heat energy causes snow to melt, but aquestion asks if ice melts, then Wordnet should pro-vide the missing knowledge that ice acts like snow.PPDB: Paraphrase relations from PPDB (Gan-itkevitch et al, 2013) are derived by aligning bilin-gual parallel texts.
PPDB is divided into subsetswhere the larger subsets have more paraphrases withless precision.
We tried all subsets and found thesmallest to give the best results, which we reporthere.
The largest performed the worst of all rela-tion sets we tested.
We use the lexical paraphrases,which relates unigrams.
Concepts are related whenat least one concept keyword for each are para-phrases in PPDB.
We obtained better performanceby stemming PPDB words: for example, if snowsand iced are paraphrases in PPDB then we also con-sidered snowing and icy to be in PPDB.KNOWBOT: Each question is answered using re-lations pooled from all dialogs about all questions.The goal in each dialog is to acquire knowledgehelpful to answer the question.
If KNOWBOT leadsto an increase in QA accuracy over IDENTITY, thenwe can successfully use open dialog with a human inthe loop to learn knowledge that solves a question.LEAVE-ONE-OUT: Each question is answeredonly with relations learned during dialogs for ev-ery other question.
While KNOWBOT uses re-lations learned from dialogs about the questionson those same questions, LEAVE-ONE-OUT testswhether knowledge generalizes to questions withoutdialogs.
Generalization is only possible when thereare at least two questions involving the same con-cepts.
Due to our small number of questions, in thebest case we expect only slight improvement.%correctIDENTITY 41%WORDNET 34%PPDB 39%KNOWBOT 57%LEAVE-ONE-OUT 45%Table 2: QA accuracy on the 107 questions with dif-ferent sources of domain knowledge.
IDENTITY: iden-tity relations only, e.g.
?heats?
to ?heating.?
WORD-NET: Wordnet-derived pseudo-synonyms, e.g.
?eagle?to ?owl.?
KNOWBOT: the full, unablated global KG.LEAVE-ONE-OUT: answers each question while ignoringrelations acquired during dialogs on that question.5.2 ResultsThe results of QA using the different domain knowl-edge is shown in Table 2.
IDENTITY achieves41% accuracy on this difficult reasoning task, show-ing that some questions are answerable by search-ing SCITEXT for supporting sentences with thesame concepts as in the question-answer statement.WORDNET works surprisingly poorly.
Examinationfound WORDNET?s relations to be of good quality,yet underperform IDENTITY.
PPDB performed bet-ter but still underperformed IDENTITY.
We con-clude that general paraphrase bases introduce toomuch noise to apply directly without manual cura-tion to our science domain, underscoring the needfor domain-specific knowledge acquisition.KNOWBOT achieves accuracy of 57%, a dramaticimprovement over both baselines.
Importantly, thisvalue does not test generalization to unseen ques-tions, since KNOWBOT has held dialogs on thesequestions.
However, it does show that our systemcan effectively learn about its domain: a poor dia-log extraction system will fail to extract any helpfulknowledge from users during a training dialog.
Thisis a significant result because it shows that we suc-cessfully acquire knowledge to solve many questionthrough conversational interaction without the over-head of a closed dialog model or fixed ontology.We also tested how well knowledge generalizeswith LEAVE-ONE-OUT.
Our question set is lesssuited to evaluate generalization because it coversa wide range of topics with little overlap between857questions.
We still found LEAVE-ONE-OUT to bethe second-best performer with accuracy of 45%, a10% relative improvement versus IDENTITY.
Re-dundancy is an effective noise reduction constraint:when LEAVE-ONE-OUT ignores redundancy and in-cludes singleton relations (those originating in a sin-gle dialog utterance), its accuracy reduces to 32%.6 Related workKnowledge acquisition in dialog has long been acentral goal of AI research.
Early dialog systemsacquired knowledge through ambitious interaction,but were brittle, required hand-defined dialog mod-els and did not scale.
Terry Winograd (1972) pre-sented the first dialog system that acquires knowl-edge about the block world.
TEIRESIAS (Davis,1977) refines inference rules from terse interactionwith experts.
CONVINCE (Kim and Pearl, 1987)and its prototypes (Leal and Pearl, 1977) learn de-cision structures through stylized but conversationaldialogs.
An interactive interface for CYC (Witbrocket al, 2003) learns from experts but don?t use naturallanguage.
Fern?andez et al(2011) argue the impor-tance of interactive language learning for conversa-tional agents.
Williams et al(2015) combine activelearning and dialog to efficiently label training datafor dialog act classifiers.Relatively little work integrates relation extrac-tion and dialog systems.
Attribute-value pairs fromrestaurant reviews can generate system prompts(Reschke et al, 2013), and single-turn exchangeswith search engines can populate a knowledge graph(Hakkani-Tur et al, 2014).
Dependency relationsextracted from individual dialog utterances by aparser also make effective features for dialog actclassification (Kl?uwer et al, 2010).The work closest to our own, Pappu and Rudnicky(2014a; 2014b), investigates knowledge acquisitionstrategies for academic events.
Their system asksits users open-ended questions in order to elicit in-formation about academic events of interest.
Theycompare strategies by how many new vocabularywords are acquired, so that the best strategy promptsthe user to mention the most OOV words.
In theirmost recent work (2014b), they group the acquiredresearcher names by their interests to form a bipar-tite graph, and use acquired keywords for query ex-pansion in a simple information retrieval task.
Ourpresent contribution builds on this general idea, butwe learn an unlimited number of relations and con-cepts from open dialogs, whereas they learn a smallnumber of relations belonging to a fixed ontologyfrom closed dialogs.
We also show the acquiredknowledge is objectively useful for QA.In closed dialog systems, the system?s dialogmodel explicitly represents the meaning of every po-tential user utterance.
Any utterance not representedby this comprehensive model is rejected and the userasked to rephrase.
Closed dialog systems work wellin practice.
For example, in the well-studied slot-filling or frame-filling model, users fill slots to con-strain their goal, and an NLU module decomposesuser utterances to known actions, slots, and val-ues.
A slot-filling system to find flights might mapthe utterance U: Show me a flight fromNashville to Seattle on Sunday to theaction find-flight and the filled slots origin =Nashville, destination = Seattle, and time = Sun-day.
However, for our domain, each distinct ques-tion warrants its own actions, slots, and values.
Sucha complex model would require abundant trainingdata or laboriously handcrafted interpretation rules.In contrast, an open dialog system can usefully in-terpret, learn from, and respond to user utteranceswithout a comprehensive dialog model.
Domain-independent dialog systems with the flexibility toaccept novel user utterances are a longstanding goalin dialog research (Polifroni et al, 2003).
Recentwork to address more open dialog includes boot-strapping a semantic parser from unlabeled dialogs(Artzi and Zettlemoyer, 2011), extracting poten-tial user goals and system responses from backenddatabases (Hixon and Passonneau, 2013), and in-ducing slots and slot-fillers from a corpus of human-human dialogs with the use of FrameNet (Chen etal., 2014).
These works focus on systems that learnabout their domain prior to any human-system dia-log.
Our system learns about its domain during thedialog.
While we rely on a limited number of tem-plates to generate system responses, unscripted userutterances can usefully progress the dialog.
This al-lows relation extraction from complex natural lan-guage utterances without a closed set of recognizedactions and known slot-value decompositions.8587 Discussion and Future WorkKNOWBOT acquires helpful, task-driven relationsfrom conversational dialogs in a difficult QA do-main.
A dialog is a success when it produces knowl-edge to solve the question.
Extractions increase QAaccuracy on questions for which dialogs have beenheld, indicating that knowledge acquisition dialogscan succeed without a closed dialog model by us-ing task progress and careful pruning to drive natu-ral language understanding.
Our method is generalenough to scale to any task in which alternative di-alog goals can be presented to a user and the sys-tem?s confidence in each alternative computed fromsemantic relations between concepts.Our focus is on facilitated knowledge acquisitionrather than question-answering, so we purposefullykeep inference simple.
The alignment score is a Jac-card overlap modified to use relations, which makesit fast and practical, but results in many ties whichwe score as incorrect, and also ignores word or-der.
For example, the bag-of-keywords is identicalfor contradicting answers ?changing from liquid tosolid?
and ?changing from solid to liquid.?
To makethis distinction, we could use an alignment score thatis sensitive to word order such as an edit distance.We could expand our simple pruning constraints totake more advantage of syntax, for example by us-ing dependency parsers optimized for conversationallanguage (Kong et al, 2014).The relational model for reasoning is both flexibleand powerful (Liu and Singh, 2004).
However, in asmall number of cases, relations that align knownfacts with question-answer statements are unlikelyto lead to the correct answer.
For example, our ques-tion set contains a single math problem, How longdoes it take for Earth to rotate on its axis seventimes?
(A) one day (B) one week (C) one month (D)one year.
The multiplication operation necessary toinfer the answer from the SCITEXT fact ?The Earthrotates, or spins, on its axis once every 24 hours?is not easily represented by our model and requiresother techniques (Hosseini et al, 2014).We observed only slight transfer of knowledge be-tween questions.
A larger question set with multiplequestions per topic will allow us to better evaluateknowledge transfer.
Our long-term goal is learn-ing through any conversational interaction in a com-pletely open domain, but because the fundamen-tal trick that enables model-free NLU is computingprogress towards an explicit dialog goal as a func-tion of possible extractions, our current method islimited to tasks with explicit goals.The simple redundancy filter we use effectivelydistinguishes salient from noisy relations, but couldbe improved with a model of relation frequency.We consider all acquired relations equally salient,but future work will examine how to rank relationsaliency.
We will also examine how dialog fea-tures can help distinguish between paraphrase, en-tailment, and negative relations.Our open system acquires relations from a widevariety of user explanations without the bottleneckof a hand-built dialog model, but the tradeoff is thatwe use relatively simple, templated system prompts.However, our collected corpus of real human-systemdialogs can be used to improve our system in fur-ther iterations.
For example, the knowledge graphswe produce are targeted, question-specific semanticnetworks, which could be used in lieu of FrameNetto induce domain-specific dialog models (Chen etal., 2014).
With a dialog model to represent thestate space, reinforcement learning could then beemployed to optimize our strategies.While most question-answering systems focus onfactoid questions, reasoning tasks such as ours re-quire different techniques.
Our method generalizesto other non-factoid QA tasks which could usefullyemploy relations, such as arithmetic word problems(Hosseini et al, 2014) and biology reading compre-hension questions (Berant et al, 2014).AcknowledgmentsThis research was conducted at the Allen Institutefor Artificial Intelligence.
We?d like to thank LukeZettlemoyer, Mark Yatskar, Rik Koncel-Kedziorski,Eric Gribkoff, Oren Etzioni and the anonymous re-viewers for helpful comments, and AI2 interns andcolleagues for their support and participation in theuser studies.
The first author was supported bythe National Science Foundation Graduate ResearchFellowship Program under Grant Number DGE-1256082.
The third author was supported by grantsfrom the Allen Institute for AI (66-9175) and theNSF (IIS-1352249).859ReferencesYoav Artzi and Luke Zettlemoyer.
2011.
Bootstrappingsemantic parsers from conversations.
In Proceedingsof the 2011 Conference on Empirical Methods in Natu-ral Language Processing, pages 421?432, Edinburgh,Scotland, UK., July.
Association for ComputationalLinguistics.Holger Bast, Debapriyo Majumdar, and Ingmar Weber.2007.
Efficient interactive query expansion with com-plete search.
In Proceedings of the Sixteenth ACMConference on Conference on Information and Knowl-edge Management, CIKM ?07, pages 857?860, NewYork, NY, USA.
ACM.Jonathan Berant, Vivek Srikumar, Pei-Chun Chen,Abby Vander Linden, Brittany Harding, Brad Huang,Peter Clark, and Christopher D. Manning.
2014.Modeling biological processes for reading comprehen-sion.
In Proceedings of EMNLP.Andrew Carlson, Justin Betteridge, Bryan Kisiel, BurrSettles, Estevam Hruschka, and Tom Mitchell.
2010.Toward an architecture for never-ending languagelearning.
In AAAI Conference on Artificial Intelli-gence.Yun-Nung Chen, William Yang Wang, and Alexander I.Rudnicky.
2014.
Leveraging frame semantics and dis-tributional semantics for unsupervised semantic slotinduction in spoken dialogue systems.
In 2014 IEEESpoken Language Technology Workshop (SLT 2014).Peter Clark, Niranjan Balasubramanian, Sumithra Bhak-thavatsalam, Kevin Humphreys, Jesse Kinkead,Ashish Sabharwal, and Oyvind Tajford.
2014.
Au-tomatic construction of inference-supporting knowl-edge bases.
In 4th Workshop on Automated Knowl-edge Base Construction (AKBC).Randall Davis.
1977.
Interactive transfer of expertise:Acquisition of new inference rules.
In Proceedings ofthe 5th International Joint Conference on Artificial In-telligence.
Cambridge, MA, August 1977, pages 321?328.Oren Etzioni, Anthony Fader, Janara Christensen,Stephen Soderland, and Mausam Mausam.
2011.Open information extraction: The second generation.In Proceedings of the Twenty-Second InternationalJoint Conference on Artificial Intelligence - VolumeVolume One, IJCAI?11, pages 3?10.
AAAI Press.Christiane Fellbaum.
1998.
WordNet: An ElectronicLexical Database.
Bradford Books.Raquel Fern?andez, Staffan Larsson, Robin Cooper,Jonathan Ginzburg, and David Schlangen.
2011.
Re-ciprocal learning via dialogue interaction: Challengesand prospects.
Proceedings of the IJCAI 2011 Work-shop on Agents Learning Interactively from HumanTeachers (ALIHT 2011).David Ferrucci, Eric Brown, Jennifer Chu-Carroll, JamesFan, David Gondek, Aditya A Kalyanpur, Adam Lally,J William Murdock, Eric Nyberg, John Prager, et al2010.
Building watson: An overview of the deepqaproject.
AI magazine, 31(3):59?79.Juri Ganitkevitch, Benjamin Van Durme, and ChrisCallison-Burch.
2013.
PPDB: The paraphrasedatabase.
In Proceedings of NAACL-HLT, pages 758?764, Atlanta, Georgia, June.
Association for Compu-tational Linguistics.Dilek Hakkani-Tur, Asli Celikyilmaz, Larry Heck,Gokhan Tur, and Geoff Zweig.
2014.
Probabilistic en-richment of knowledge graph entities for relation de-tection in conversational understanding.
In Proceed-ings of Interspeech.
ISCA - International Speech Com-munication Association, September.Catherine Havasi, Robert Speer, and Jason Alonso.
2007.Conceptnet 3: a flexible, multilingual semantic net-work for common sense knowledge.
In Recent Ad-vances in Natural Language Processing, Borovets,Bulgaria, September.Ben Hixon and Rebecca J. Passonneau.
2013.
Open di-alogue management for relational databases.
In Pro-ceedings of the 2013 Conference of the North Ameri-can Chapter of the Association for Computational Lin-guistics: Human Language Technologies, pages 1082?1091, Atlanta, Georgia, June.
Association for Compu-tational Linguistics.Javad Mohammad Hosseini, Hannaneh Hajishirzi, OrenEtzioni, and Nate Kushman.
2014.
Learning to solvearithmetic word problems with verb categorization.In Proceedings of the 2014 Conference on EmpiricalMethods in Natural Language Processing (EMNLP),pages 523?533.
Association for Computational Lin-guistics.Jin H. Kim and Judea Pearl.
1987.
Convince: A conver-sational inference consolidation engine.
IEEE Trans.Syst.
Man Cybern., 17(2):120?132, March.Tina Kl?uwer, Hans Uszkoreit, and Feiyu Xu.
2010.Using syntactic and semantic based relations for dia-logue act recognition.
In Proceedings of the 23rd In-ternational Conference on Computational Linguistics:Posters, COLING ?10, pages 570?578, Stroudsburg,PA, USA.Lingpeng Kong, Nathan Schneider, SwabhaSwayamdipta, Archna Bhatia, Chris Dyer, andA.
Noah Smith.
2014.
A dependency parser fortweets.
In Proceedings of the 2014 Conference onEmpirical Methods in Natural Language Process-ing (EMNLP), pages 1001?1012.
Association forComputational Linguistics.Antonio Leal and Judea Pearl.
1977.
An interactive pro-gram for conversational elicitation of decision struc-860tures.
IEEE Transactions on Systems, Man, and Cy-bernetics, 7(5):368?376.Hugo Liu and Push Singh.
2004.
Commonsense reason-ing in and over natural language.
In Proceedings of the8th International Conference on Knowledge-Based In-telligent Information and Engineering Systems (KES-2004.
Springer.Aasish Pappu and Alexander Rudnicky.
2014a.
Knowl-edge acquisition strategies for goal-oriented dialogsystems.
In Proceedings of the 15th Annual Meeting ofthe Special Interest Group on Discourse and Dialogue(SIGDIAL), pages 194?198, Philadelphia, PA, U.S.A.,June.Aasish Pappu and Alexander Rudnicky.
2014b.
Learningsituated knowledge bases through dialog.
In Proceed-ings of Interspeech, September.Joseph Polifroni, Grace Chung, and Stephanie Sen-eff.
2003.
Towards automatic generation of mixed-initiative dialog systems from web content.
In Eu-rospeech.M.
F. Porter.
1997.
Readings in information retrieval.chapter An Algorithm for Suffix Stripping, pages 313?316.
Morgan Kaufmann Publishers Inc., San Fran-cisco, CA, USA.Kevin Reschke, Adam Vogel, and Dan Jurafsky.
2013.Generating recommendation dialogs by extracting in-formation from user reviews.
In Proceedings of the51st Annual Meeting of the Association for Compu-tational Linguistics (Volume 2: Short Papers), pages499?504, Sofia, Bulgaria, August.
Association forComputational Linguistics.Rion Snow, Daniel Jurafsky, and Andrew Y Ng.
2006.Semantic taxonomy induction from heterogenous evi-dence.
In Proceedings of the 21st International Con-ference on Computational Linguistics and the 44thannual meeting of the Association for ComputationalLinguistics, pages 801?808.
Association for Computa-tional Linguistics.Jason D. Williams, Nobal B. Niraula, Pradeep Dasigi,Aparna Lakshmiratan, Carlos Garcia Jurado Suarez,Mouni Reddy, and Geoff Zweig.
2015.
Rapidly scal-ing dialog systems with interactive learning.
In 2015International Workshop Series on Spoken DialogueSystems Technology (IWSDS), January.T.
Winograd.
1972.
Understanding natural language.Academic Press.Michael Witbrock, David Baxter, Jon Curtis, DaveSchneider, Robert Kahlert, Pierluigi Miraglia, PeterWagner, Kathy Panton, Gavin Matthews, and AmandaVizedom.
2003.
An interactive dialogue system forknowledge acquisition in cyc.
In Proceedings of theIJCAI-2003 Workshop on Mixed-Initiative IntelligentSystems., pages 138?145.Zhibiao Wu and Martha Palmer.
1994.
Verbs semanticsand lexical selection.
In Proceedings of the 32Nd An-nual Meeting on Association for Computational Lin-guistics, ACL ?94, pages 133?138, Stroudsburg, PA,USA.
Association for Computational Linguistics.861
