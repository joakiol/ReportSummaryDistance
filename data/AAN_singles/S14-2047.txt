Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 289?293,Dublin, Ireland, August 23-24, 2014.FBK-TR: SVM for Semantic Relatedness and Corpus Patterns for RTENgoc Phuoc An VoFondazione Bruno KesslerUniversity of TrentoTrento, Italyngoc@fbk.euOctavian PopescuFondazione Bruno KesslerTrento, Italypopescu@fbk.euTommaso CaselliTrentoRISETrento, Italyt.caselli@trentorise.euAbstractThis paper reports the description andscores of our system, FBK-TR, whichparticipated at the SemEval 2014 task#1 "Evaluation of Compositional Distribu-tional Semantic Models on Full Sentencesthrough Semantic Relatedness and Entail-ment".
The system consists of two parts:one for computing semantic relatedness,based on SVM, and the other for identi-fying the entailment values on the basisof both semantic relatedness scores andentailment patterns based on verb-specificsemantic frames.
The system ranked 11thon both tasks with competitive results.1 IntroductionIn the Natural Language Processing community,meaning related tasks have gained an increasingpopularity.
These tasks focus, in general, on acouple of short pieces of text, like pair of sen-tences, and the systems are required to infer a cer-tain meaning relationship that exists between thesetexts.
Two of the most popular meaning relatedtasks are the identification of Semantic Text Sim-ilarity (STS) and Recognizing Textual Entailment(RTE).
The STS tasks require to identify the de-gree of similarity (or relatedness) that exists be-tween two text fragments (sentences, paragraphs,.
.
.
), where similarity is a broad concept and itsvalue is normally obtained by averaging the opin-ion of several annotators.
The RTE task requiresthe identification of a directional relation betweena pair of text fragments, namely a text (T) and ahypothesis (H).
The relation (T?
H) holds when-ever the truth of H follows from T.This work is licensed under a Creative Commons At-tribution 4.0 International Licence.
Page numbers and pro-ceedings footer are added by the organisers.
Licence details:http://creativecommons.org/licenses/by/4.0/At SemEval 2014, the Task #1 "Evaluationof Compositional Distributional Semantic Modelson Full Sentences through Semantic Relatednessand Entailment" (Marelli et al., 2014a) primarilyaimed at evaluating Compositional DistributionalSemantic Models (CDSMs) of meaning over twosubtasks, namely semantic relatedness and tex-tual entailment (ENTAILMENT, CONTRADIC-TION and NEUTRAL), over pairs of sentences(Marelli et al., 2014b).
Concerning the relatednesssubtask, the system outputs are evaluated againstgold standard ratings in two ways, using Pearsoncorrelation and Spearman?s rank correlation (rho).The Pearson correlation is used for evaluating andranking the participating systems.
Similarly, forthe textual entailment subtask, system outputs areevaluated against a gold standard rating with re-spect to accuracy.Our team, FBK-TR, participated in both sub-tasks with five different runs.
In this paper, wepresent a comprehensive description of our systemwhich obtained competitive results in both tasksand which is not based on CDSMs.
Our approachfor the relatedness task is based on machine learn-ing techniques to learn models from different lexi-cal and semantic features from the train corpus andthen to make prediction on the test corpus.
Par-ticularly, we used support vector machine (SVM)(Chang and Lin, 2011), regression model to solvethis subtask.
On the other hand, the textual en-tailment task uses a methodology mainly based oncorpus patterns automatically extracted from an-notated text corpora.The remainder of the paper is organized asfollows: Section 2 presents the SVM systemfor semantic relatedness.
Section 3 describesthe methodology used for extracting patterns andcomputing the textual entailment values.
Finally,Section 4 discusses about the evaluations and Sec-tion 5 presents conclusions and future work.289Figure 1: Schema of the system for computing entailment.2 System Overview for SemanticRelatedness SubtaskConcerning the Semantic Relatedness subtask ourSVM system is built on different linguistic fea-tures, ranging from relatedness at the lexical level(WordNet based measures, Wikipedia relatednessand Latent Semantic Analysis), to sentence level,including topic modeling based on Latent Dirich-let allocation (LDA) and string similarity (LongestCommon Substring).2.1 Lexical FeaturesAt the lexical level, we built a simple, yet effectiveSemantic Word Relatedness model, which con-sists of 3 components: WordNet similarity (basedon the Lin measure as implemented in Pedersenpackage WordNet:Similarity (Pedersen etal., 2004), Wikipedia relatedness (as provided bythe Wikipedia Miner package (Milne and Witten,2013)), and Latent Semantic Analysis (Landaueret al., 1998), with a model trained on the BritishNational Corpus (BNC)1and Wikipedia.
At thislevel of analysis, we concentrated only on thebest matched (lemma) pairs of content words, i.e.Noun-Noun, Verb-Verb, extracted from each sen-tence pair.
The content words have been automati-cally extracted by means of part-of-speech tagging(TreeTagger (Schmid, 1994)) and lemmatization.For words which are not present in WordNet,the relatedness score has been obtained by meansof the Levenshtein distance (Levenshtein, 1966).1http://www.natcorp.ox.ac.uk2.2 Topic ModelingWe have applied topic modeling based on LatentDirichlet allocation (LDA) (Blei et al., 2003) asimplemented in the MALLET package (McCal-lum, 2002).
The topic model was developed us-ing the BNC and Wikipedia (with the numbersof topics varying from 20 to 500 topics).
Fromthe proportion vectors (distribution of documentsover topics) of the given texts, we apply 3 differ-ent measures (Cosine similarity, Kullback-Leiblerand Jensen-Shannon divergences) to compute thedistances between each pair of sentences.2.3 String Similarity: Longest CommonSubstringAs for the string level, two given sentences areconsidered similar/related if they are overlap-ping/covering each other (e.g sentence 1 coversa part of sentence 2, or otherwise).
Hence, weconsidered the text overlapping between twogiven texts as a feature for our system.
Theextraction of the features at the string level wascomputed in two steps: first, we obtained LongestCommon Substring between two given sentences.After this, we also considered measuring thesimilarity for the parts before and after the LCSbetween two given texts, by means of the Linmeasure and the Levenshtein distance.3 System Overview for RTE SubtaskThe system for the identification of the entailmentvalues is illustrated in Figure 1.
Entailment values290are computed starting from a baseline (only EN-TAILMENT and NEUTRAL values) which relieson the output (i.e.
scores) of the semantic related-ness system.
After this step, two groups of entail-ment patterns are applied whether the surface formof a sentence pair is affirmative (i.e.
absence ofnegation words) or negative.
Each type of patternprovides in output an associated entailment valuewhich corresponds to the final value assigned bythe system.The entailment patterns are based on verb-specific semantic frames that include both syn-tactic and semantic information.
Hence, we haveexplicit access to the information that individualwords have and to the process of combining themin bigger units, namely phrases, which carry outmeanings.
The patterns have two properties: i.
)the senses of the words inside the pattern are sta-ble, they do not change whatever context is addedto the left, right or inside the phrase matching thepattern, and ii.)
the replacement of a word with an-other word belonging to a certain class changes thesenses of the words.
Patterns with these propertiesare called Sense Discriminative Patterns (SDPs).It has been noted (Popescu et al., 2011) that we canassociate to a phrase that is matched by an SDP aset of phrases for which an entailment relationshipis decidable showing that there is a direct relation-ship between SDPs and entailment .SDP patterns have been obtained from largeparsed corpora.
To maximize the accuracy of thecorpus we have chosen sentences containing atmaximum two finite verbs from BNC and Anno-tated English Gigaword.
We parsed this corpuswith the Stanford parser, discarding the sentencesfrom the Annotated English Gigaword which havea different parsing.
Each words is replaced withtheir possible SUMO attributes (Niles and Pease,2003).
Only the following Stanford dependen-cies are retained as valid [n, nsub]sbj, [d,i,p]obj,prep, [x,c]comp.
We considered only the most fre-quent occurrences of such patterns for each verb.To cluster into a single SDP pattern, all patternsthat are sense auto-determinative, we used theOntoNotes (Hovy et al., 2006) and CPA (Hanks,2008) lexica.
Inside each cluster, we searchedfor the most general hypernyms for each syntac-tic slot such that there are no common patternsbetween clusters (Popescu, 2013).
However, thepatterns thus obtained are not sufficient enoughfor the task.
Some expressions may be the para-phrasis a word in the context of an SDP.
To ex-tract this information, we considered all the pairsin training that are in an ENTAILMENT relation-ship, with a high relatedness score (4 to 5), and weextracted the parts that are different for each gram-matical slot.
In this way, we compiled a list ofquasi synonym phrases that can be replaced insidean SDP without affecting the replacement.
Thisis the only component that depends on the train-ing corpus.
Figure 2 describes the algorithm forcomputing entailment on the basis of the SDPs.The following subsections illustrate the identifi-cation of entailment relation for affirmative sen-tences and negated sentences.Figure 2: Algorithm for computing entailment.3.1 Entailment on Affirmative SentencesAffirmative sentences use three types of entail-ment patterns.
The switch baseline and hyponympatterns works in this way: If two sentences arematched by the same SDP, and the difference be-tween them is that the second one contains a hy-pernym on the same syntactic position, then thefirst one is entailed by the second (i.e.
ENTAIL-MENT).
If the two SDPs are such that the dif-ference between them is that the second containsa word which is not synonym, hypernym or hy-ponym on the same syntactic position, then there isno entailment between the two phrases (i.e.
NEU-TRAL).
The entailment direction is from the sen-tence that contains the hyponym toward the other291sentence.
The antonym patterns check if the twoSDPs are the same, with the only difference be-ing in the verb of the second sentence being anantonym of the verb in the first sentence (i.e.CONTRADICTION).3.2 Entailment on Negative SentencesAs for negated sentences, we distinguish betweenexistential negative phrases (i.e.
there is no orthere are no) and factual negative ones (presenceof a negative polarity word).
An assumption re-lated to each SDP is that it entails the existenceof any of the component of the pattern which canbe expressed by means of dedicated phrases.
ASDP of the kind "[Human] beat [Animal]", en-tails both phrases, namely there is a [Human] andthere is a [Animal].
We call this set of associ-ated existential phrases, Existential Assumptions(EAs).
This type of existential entailment obtainedthrough the usage of SDP has a direct consequencefor handling the ENTAILMENT, CONTRADIC-TION and NEUTRAL types of entailment whenone of the phrases is negated.
If the first phrasebelongs to the EA of the second one, then thefirst phrase is entailed by the second phrase; if thefirst phrase is an existential negation of a phrasebelonging to the EA set of the second phrase,meaning that it contains the string there is/are no,then the first one is a contradiction of the secondphrase; if neither the first phrase, nor its negationbelong to the EA set of the second phrase, then thetwo sentences are neutral with respect to the en-tailment.
The general rule described in 3.1 appliesto these types of phrases as well: replacing a wordon the same syntactic slot inside a phrase that ismatched by a SDP leads to a CONTRADICTIONtype of entailment, if the replacement is a hyper-nym of the original word.
Similarly, the approachcan be applied to factual negative phrases.
Thescope of negation is considered to be the extensionof the SDP and thus the negative set of EAs.4 Evaluation and RankingTable 1 illustrates the results for Pearson andSpearman correlations for the relatedness subtaskon the test set.
Table 2 reports the Accuracy valuesfor the entailment subtask on the test set.Concerning the relatedness results our systemsranked 11thout of 17 participating systems.
Bestscore of our system is reported in Table 1.
Oneof the main reason for the relatively low resultsTeam Pearson SpearmanECNU_run1 (ranked 1st) 0.82795 0.76892FBK-TR_run3 0.70892 0.64430Table 1: Results for semantic relatedness subtask.Team AccuracyIllinois-LH_run1 (ranked 1st) 84.575FBK-TR_run3 75.401?FBK-TR_baseline 64.080?FBK-TR_new 85.082Table 2: Results for entailment subtask.of the systems for this subtask concerns the factthat it is designed for a general-level of texts (i.e.compositionality is not taken into account).As for the entailment subtask, our systemranked 11thout of 18 participating systems.
Thesubmitted results of the system are illustrated inTable 2 and are compared against the best system,our baseline system (?FBK-TR_baseline) as de-scribed in Figure 1, and a new version of the par-ticipating system after fixing some bugs in the sub-mitted version due to the processing of the parser?soutput (?FBK-TR_new).
The new version of thesystem scores in the top provides a new state of theart result, with an improvement of 10 points withrespect to our submitted system.5 Conclusion and Future WorkThis paper reports the description of our system,FBK-TR, which implements a general SVM se-mantic relatedness system based on distributionalfeatures (LSA, LDA), knowledge-based relatedfeatures (WordNet and Wikipedia) and string over-lap (LCS).
On top of that, we added structural in-formation at both semantic and syntactic level byusing SDP patterns.
The system reached compet-itive results in both subtasks.
By correcting somebugs in the entailment scripts, we obtained an im-provement over our submitted systems as well asfor the best ranking system.
We plan to improveand extend the relatedness system by means ofcompositional methods.
Finally, the entailmentsystem can be improved by taking into accountadditional linguistic evidences, such as the alter-nation between indefinite and definite determiners,noun modifiers and semantically empty heads.292ReferencesDavid M Blei, Andrew Y Ng, and Michael I Jordan.2003.
Latent Dirichlet Allocation.
The Journal ofMachine Learning research, 3:993?1022.Chih-Chung Chang and Chih-Jen Lin.
2011.
LIB-SVM: A Library for Support Vector Machines.ACM Transactions on Intelligent Systems and Tech-nology (TIST), 2(3):27.Patrick Hanks.
2008.
Mapping meaning onto use: aPattern Dictionary of English Verbs.
In Proceedingsof the AACL 2008.Eduard Hovy, Mitchell Marcus, Martha Palmer,Lance Ramshaw, and Ralph Weischedel.
2006.OntoNotes: The 90% Solution.
In Proceedings ofthe human language technology conference of theNAACL, Companion Volume: Short Papers, pages57?60.Thomas K Landauer, Peter W Foltz, and Darrell La-ham.
1998.
An Introduction to Latent SemanticAnalysis.
Discourse processes, 25(2-3):259?284.Vladimir I Levenshtein.
1966.
Binary Codes Capa-ble of Correcting Deletions, Insertions and Rever-sals.
In Soviet Physics Doklady, volume 10, page707.M Marelli, L Bentivogli, M Baroni, R Bernardi,S Menini, and R Zamparelli.
2014a.
Semeval-2014Task 1: Evaluation of compositional distributionalsemantic models on full sentences through seman-tic relatedness and textual entailment.
In Proceed-ings of SemEval 2014: International Workshop onSemantic Evaluation, August 23-24, 2014, Dublin,Ireland.M Marelli, S Menini, M Baroni, L Bentivogli,R Bernardi, and R Zamparelli.
2014b.
A SICKcure for the evaluation of compositional distribu-tional semantic models.
In Proceedings of LREC2014, Reykjavik (Iceland): ELRA.Andrew Kachites McCallum.
2002.
MALLET: A Ma-chine Learning for Language Toolkit.David Milne and Ian H Witten.
2013.
An Open-Source Toolkit for Mining Wikipedia.
Artificial In-telligence, 194:222?239.Ian Niles and Adam Pease.
2003.
Mapping Word-Net to the SUMO Ontology.
In Proceedings of theIEEE International Knowledge Engineering Confer-ence, pages 23?26.Ted Pedersen, Patwardhan Siddharth, and MichelizziJason.
2004.
Wordnet::Similarity: Measuring theRelatedness of Concepts.
In Proceedings of theHLT-NAACL 2004.Octavian Popescu, Elena Cabrio, and BernardoMagnini.
2011.
Textual Entailment Using ChainClarifying Relationships.
In Proceedings of the IJ-CAI Workshop Learning by Reasoning and its Appli-cations in Intelligent Question-Answering.Octavian Popescu.
2013.
Learning Corpus PatternsUsing Finite State Automata.
In Proceedings of theICSC 2013.Helmut Schmid.
1994.
Probabilistic Part-of-SspeechTagging Using Decision Trees.
In Proceedings ofinternational conference on new methods in lan-guage processing, volume 12, pages 44?49.
Manch-ester, UK.293
