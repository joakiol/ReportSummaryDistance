High Efficiency Realization for aWide-Coverage Unification GrammarJohn Carroll1 and Stephan Oepen21 University of Sussex2 University of Oslo and Stanford UniversityAbstract.
We give a detailed account of an algorithm for efficient tactical gener-ation from underspecified logical-form semantics, using a wide-coverage gram-mar and a corpus of real-world target utterances.
Some earlier claims about chartrealization are critically reviewed and corrected in the light of a series of practicalexperiments.
As well as a set of algorithmic refinements, we present two noveltechniques: the integration of subsumption-based local ambiguity factoring, anda procedure to selectively unpack the generation forest according to a probabilitydistribution given by a conditional, discriminative model.1 IntroductionA number of wide-coverage precise bi-directional NL grammars have been developedover the past few years.
One example is the LinGO English Resource Grammar (ERG)[1], couched in the HPSG framework.
Other grammars of similar size and coverage alsoexist, notable examples using the LFG and the CCG formalisms [2,3].
These grammarsare used for generation from logical form input (also termed tactical generation or real-ization) in circumscribed domains, as part of applications such as spoken dialog systems[4] and machine translation [5].Grammars like the ERG are lexicalist, in that the majority of information is encodedin lexical entries (or lexical rules) as opposed to being represented in constructions (i.e.rules operating on phrases).
The semantic input to the generator for such grammars,often, is a bag of lexical predicates with semantic relationships captured by appropriateinstantiation of variables associated with predicates and their semantic roles.
For thesesorts of grammars and ?flat?
semantic inputs, lexically-driven approaches to realization?
such as Shake-and-Bake [6], bag generation from logical form [7], chart generation[8], and constraint-based generation [9] ?
are highly suitable.
Alternative approachesbased on semantic head-driven generation and more recent variants [10,11] would workless well for lexicalist grammars since these approaches assume a hierarchically struc-tured input logical form.Similarly to parsing with large scale grammars, realization can be computation-ally expensive.
In his presentation of chart generation, Kay [8] describes one sourceof potential inefficiency and proposes an approach for tackling it.
However, Kay doesnot report on a verification of his approach with an actual grammar.
Carroll et al [12] Dan Flickinger and Ann Copestake contributed a lot to the work described in this paper.
Wealso thank Berthold Crysmann, Jan Tore L?nning and Bob Moore for useful discussions.
Fund-ing is from the projects COGENT (UK EPSRC) and LOGON (Norwegian Research Council).R.
Dale et al (Eds.
): IJCNLP 2005, LNAI 3651, pp.
165?176, 2005.c?
Springer-Verlag Berlin Heidelberg 2005166 J. Carroll and S. Oepen?
h1,{ h1:proposition m(h2), h3: run v(e4, x5), h3:past(e4),h6: the q(x5, h7, h8), h9: athlete n(x5), h9: young a(x5), h9: polish a(x5) },{ h2 =q h3, h8 =q h9 } ?Fig.
1.
Simplified MRS for an utterance like the young Polish athlete ran (and variants).
Elementsfrom the bag of EPs are linked through both scopal and ?standard?
logical variables.present a practical evaluation of chart generation efficiency with a large-scale HPSGgrammar, and describe a different approach to the problem which becomes necessarywhen using a wide-coverage grammar.
White [3] identifies further inefficiencies, anddescribes and evaluates strategies for addressing them, albeit using what appears to bea somewhat task-specific rather than genuine wide-coverage grammar.
In this paper,we revisit this previous work and present new, improved algorithms for efficient chartgeneration; taken together these result in (i) practical performance that improves overa previous implementation by two orders of magnitude, and (ii) throughput that is nearlinear in the size of the input semantics.In Section 2, we give an overview of the grammar and the semantic formalismwe use, recap the basic chart generation procedure, and discuss the various sources ofpotential inefficiency in the basic approach.
We then describe the algorithmic improve-ments we have made to tackle these problems (Section 3), and conclude with the resultsof evaluating these improvements (Section 4).2 Background2.1 Minimal Recursion Semantics and the LinGO ERGMinimal Recursion Semantics (MRS) [13] is a popular member of a family of flat, un-derspecified, event-based (neo-Davidsonian) frameworks for computational semanticsthat have been in wide use since the mid-1990s.
MRS allows both underspecification ofscope relations and generalization over classes of predicates (e.g.
two-place temporalrelations corresponding to distinct lexical prepositions: English in May vs. on Monday,say), which renders it an attractive input representation for tactical generation.
While anin-depth introduction to MRS is beyond the scope of this paper, Figure 1 shows an ex-ample semantics that we will use in the following sections.
The truth-conditional core iscaptured as a flat multi-set (or ?bag?)
of elementary predications (EPs), combined withgeneralized quantifiers and designated handle variables to account for scopal relations.The bag of EPs is complemented by the handle of the top-scoping EP (h1 in our exam-ple) and a set of ?handle constraints?
recording restrictions on scope relations in termsof dominance relations.The LinGO ERG [1] is a general-purpose, open-source HPSG implementation withfairly comprehensive lexical and grammatical coverage over a variety of domains andgenres.
The grammar has been deployed for diverse NLP tasks, including machinetranslation of spoken and edited language, email auto response, consumer opinion track-ing (from newsgroup data), and some question answering work.1 The ERG uses MRS1 See http://www.delph-in.net/erg/ for background information on the ERG.High Efficiency Realization for a Wide-Coverage Unification Grammar 167as its meaning representation layer, and the grammar distribution includes treebankedversions of several reference corpora ?
providing disambiguated and hand-inspected?gold?
standard MRS formulae for each input utterance ?
of which we chose one of themore complex sets for our empirical investigations of realization performance using theERG (see Section 4 below).2.2 The Basic ProcedureBriefly, the basic chart generation procedure works as follows.
A preprocessing phaseindexes lexical entries, lexical rules and grammar rules by the semantics they contain.In order to find the lexical entries with which to initialize the chart, the input semanticsis checked against the indexed lexicon.
When a lexical entry is retrieved, the variablepositions in its relations are instantiated in one-to-one correspondence with the variablesin the input semantics (a process we term Skolemization, in loose analogy to the moregeneral technique in theorem proving; see Section 3.1 below).
For instance, for the MRSin Figure 1, the lookup process would retrieve one or more instantiated lexical entriesfor run containing h3: run v(e4, x5).
Lexical and morphological rules are applied to theinstantiated lexical entries.
If the lexical rules introduce relations, their application isonly allowed if these relations correspond to parts of the input semantics (h3:past(e4),say, in our example).
We treat a number of special cases (lexical items containing morethan one relation, grammar rules which introduce relations, and semantically vacuouslexical items) in the same way as Carroll et al [12].After initializing the chart (with inactive edges), active edges are created from in-active ones by instantiating the head daughter of a rule; the resulting edges are thencombined with other inactive edges.
Chart generation is very similar to chart parsing,but what an edge covers is defined in terms of semantics, rather than orthography.
Eachedge is associated with the set of relations it covers.
Before combining two edges acheck is made to ensure that edges do not overlap: i.e.
that they do not cover the samerelation(s).
The goal is to find all possible inactive edges covering the full input MRS.2.3 ComplexityThe worst-case time complexity of chart generation is exponential (even though chartparsing is polynomial).
The main reason for this is that in theory a grammar could allowany pair of edges to combine (subject to the restriction described above that the edgescover non-overlapping bags of EPs).
For an input semantics containing n EPs, andassuming each EP retrieves a single lexical item, there could in the worst case be O(2n)edges, each covering a different subset of the input semantics.
Although in the generalcase we cannot improve the complexity, we can make the processing steps involvedcheaper, for instance efficiently checking whether two edges are candidates for beingcombined (see Section 3.1 below).
We can also minimize the number of edges coveringeach subset of EPs by ?packing?
locally equivalent edges (Section 3.2).A particular, identifiable source of complexity is that, as Kay [8] notes, when a wordhas more than one intersective modifier an indefinite number of its modifiers may beapplied.
For instance, when generating from the MRS in Figure 1, edges correspondingto the partial realizations athlete, young athlete, Polish athlete, and young Polish athletewill all be constructed.
Even if a grammar constrains modifiers so there is only one valid168 J. Carroll and S. Oepenordering, or the generator is able to pack equivalent edges covering the same EPs, thenumber of edges built will still be 2n, because all possible complete and incompletephrases will be built.
Using the example MRS, ultimately useless edges such as theyoung athlete ran (omitting Polish) will be created.Kay proposes an approach to this problem in which edges are checked before theyare created to see if they would ?seal off?
access to a semantic index (x5 in this case) forwhich there is still an unincorporated modifier.
Although individual sets of modifiers stillresult in exponential numbers of edges, the exponentiality is prevented from propagatingfurther.
However, Carroll et al [12] argue that this check works only in limited circum-stances, since for example in (1) the grammar must allow the index for ran to be availableall the way up the tree to How, and simultaneously also make available the indexes fornewspapers, say, and athlete at appropriate points so these words could be modified2.
(1) How quickly did the newspapers say the athlete ran?Carroll et al describe an alternative technique which adjoins intersective modifiers intoedges in a second phase, after all possible edges that do not involve intersective modi-fication have been constructed by chart generation.
This overcomes the multiple indexproblem described above and reduces the worst-case complexity of intersective modi-fication in the chart generation phase to polynomial, but unfortunately the subsequentphase which attempts to adjoin sets of modifiers into partial realizations is still expo-nential.
We describe below (Section 3.3) a related technique which delays processing ofintersective modifiers by inserting them into the generation forest, taking advantage ofdynamic programming to reduce the complexity of the second phase.
We also presenta different approach which filters out edges based on accessibility of sets of seman-tic indices (Section 3.4), which covers a wider variety of cases than just intersectivemodification, and in practice is even more efficient.Exponential numbers of edges imply exponential numbers of realizations.
For anapplication task we would usually want only one (the most natural or fluent) realization,or a fixed small number of good realizations that the application could then itself selectfrom.
In Section 3.5 we present an efficient algorithm for selectively unpacking thegeneration forest to produce the n-best realizations according to a statistical model.3 Efficient Wide-Coverage Realization3.1 Relating Chart Edges and Semantic ComponentsOnce lexical lookup is complete and up until a final, post-generation comparison ofresults to the input MRS, the core phases of our generator exclusively operate on typedfeature structures (which are associated to chart edges).
For efficiency reasons, our algo-rithm avoids any complex operations on the original logical-form input MRS.
In orderto best guide the search from the input semantics, however, we employ two techniquesthat relate components of the logical form to corresponding sub-structures in the feature2 White [3] describes an approach to dealing with intersective modifiers which requires thegrammarian to write a collection of rules that ?chunk?
the input semantics into separate modi-fier groups which are processed separately; this involves extra manual work, and also appearsto suffer from the same multiple index problem.High Efficiency Realization for a Wide-Coverage Unification Grammar 169structure (FS) universe: (i) Skolemization of variables and (ii) indexing by EP cover-age.
Of these, only the latter we find commonly discussed in the literature, but we expectsome equivalent of making variables ground to be present in most implementations.As part of the process of looking up lexical items and grammar rules introducing se-mantics in order to initialize the generator chart, all FS correspondences to logical vari-ables from the input MRS are made ?ground?
by specializing the relevant sub-structurewith Skolem constants uniquely reflecting the underlying variable, for example addingconstraints like [SKOLEM ?x5?]
for all occurrences of x5 from our example MRS.Skolemization, thus, assumes that distinct variables from the input MRS, where supplied,cannot become co-referential during generation.
Enforcing variable identity at the FSlevel makes sure that composition (by means of FS unification) during rule applicationsis compatible to the input semantics.
In addition, it enables efficient pre-unification fil-tering (see ?quick-check?
below), and is a prerequisite for our index accessibility testdescribed in Section 3.4 below.In chart parsing, edges are stored into and retrieved from the chart data structureon the basis of their string start and end positions.
This ensures that the parser willonly retrieve pairs of chart edges that cover compatible segments of the input string (i.e.that are adjacent with respect to string position).
In chart generation, Kay [8] proposedindexing the chart on the basis of logical variables, where each variable denotes anindividual entity in the input semantics, and making the edge coverage compatibilitycheck a filter.
Edge coverage (with respect to the EPs in the input semantics) would beencoded as a bit vector, and for a pair of edges to be combined their corresponding bitvectors would have to be disjoint.We implement Kay?s edge coverage approach, using it not only when combiningactive and inactive edges, but also for two further tasks in our approach to realization:?
in the second phase of chart generation to determine which intersective modifier(s)can be adjoined into a partially incomplete subtree; and?
as part of the test for whether one edge subsumes another, for local ambiguityfactoring (see Section 3.2 below)3.In our testing with the LinGO ERG, many hundreds or thousands of edges may beproduced for non-trivial input semantics, but there are only a relatively small numberof logical variables.
Indexing edges on these variables involves bookkeeping that turnsout not to be worthwhile in practice; logical bit vector operations on edge coveragetake negligible time, and these serve to filter out the majority of edge combinationswith incompatible indices.
The remainder are filtered out efficiently before unificationis attempted by a check on which rules can dominate which others, and the quick-check,as developed for unification-based parsing [14].
For the quick-check, it turns out thatthe same set of feature paths that most frequently lead to unification failure in parsingalso work well in generation.3 We therefore have four operations on bit vectors representing EP coverage (C) in chart edges:?
concatenation of edges e1 and e2 ?
e3: C(e3) = OR(C(e1), C(e2));?
can edges e1 and e2 combine?
AND(C(e1), C(e2)) = 0;?
do edges e1 and e2 cover the same EPs?
C(e1) = C(e2);?
do edges e1, .
.
.
, en cover all input EPs?
NOT(OR(C(e1), .
.
.
, C(en)) = 0.170 J. Carroll and S. Oepen3.2 Local Ambiguity FactoringIn chart parsing with context free grammars, the parse forest (a compact representationof the full set of parses) can only be computed in polynomial time if sub-analyses dom-inated by the same non-terminal and covering the same segment of the input string are?packed?, or factored into a single unitary representation [15].
Similar benefits accruefor unification grammars without a context free backbone such as the LinGO ERG,if the category equality test is replaced by feature structure subsumption [16]4; also,feature structures representing the derivation history need to be restricted out when ap-plying a rule [17].
The technique can be applied to chart realization if the input span isexpressed as coverage of the input semantics.
For example, with the input of Figure 1,the two phrases in (2) below would have equivalent feature structures, and we pack theone found second into the one found first, which then acts as the representative edge forall subsequent processing.
(2) young Polish athlete | Polish young athleteWe have found that packing is crucial to efficiency: realization time is improved by morethan an order of magnitude for inputs with more than 500 realizations (see Section 4).Changing packing to operate with respect just to feature structure equality rather thansubsumption degrades throughput significantly, resulting in worse overall performancethan with packing disabled completely: in other words, equivalence-only packing failsto recoup the cost of the feature structure comparisons involved.A further technique we use is to postpone the creation of feature structures for activeedges until they are actually required for a unification operation, since many end up asdead ends.
Oepen and Carroll [18] do a similar thing in their ?hyper-active?
parsingstrategy, for the same reason.3.3 Delayed Modifier InsertionAs discussed in Section 2.3, Carroll et al [12] adjoin intersective modifiers into eachpartial tree extracted from the forest; their algorithm searches for partitions of modifierphrases to adjoin, and tries all combinations.
This process adds an exponential (in thenumber of modifiers) factor to the complexity of extracting each partial realization.This is obviously unsatisfactory, and in practice is slow for larger problems whenthere are many possible modifiers.
We have devised a better approach which delaysprocessing of intersective modifiers by inserting them into the generation forest at ap-propriate locations before the forest is unpacked.
By doing this, we take advantage ofthe dynamic programming-based procedure for unpacking the forest to reduce the com-plexity of the second phase.
The procedure is even more efficient if realizations areunpacked selectively (section 3.5).3.4 Index Accessibility FilteringKay?s original proposal for dealing efficiently with modifiers founders because morethan one semantic index may need to be accessible at any one time (leading to the4 Using subsumption-based packing means that the parse forest may represent some globallyinconsistent analyses, so these must be filtered out when the forest is unpacked.High Efficiency Realization for a Wide-Coverage Unification Grammar 171alternative solutions of modifier adjunction, and of chunking the input semantics ?
seeSections 2.3 and 3.3).However, it turns out that Kay?s proposal can form the basis of a more generallyapplicable approach to the problem.
We assume that we have available an operationcollect-semantic-vars() that traverses a feature structure and returns the set of semanticindices that it makes available5.
We store in each chart edge two sets: one of semanticvariables in the feature structure that are accessible (that is, they are present in thefeature structure and could potentially be picked by another edge when it is combinedwith this one), and a second set of inaccessible semantic variables (ones that were onceaccessible but no longer are).
Then,?
when an active edge is combined with an inactive edge, the accessible sets andinaccessible sets in the resulting edge are the union of the corresponding sets in theoriginal edges;?
when an inactive edge is created, its accessible set is computed to be the semanticindices available in its feature structure, and the variables that used to be accessiblebut are no longer in the accessible set are added to its inaccessible set, i.e.1 tmp ?
edge.accessible;2 edge.accessible ?
collect-semantic-vars(edge.fs)3 edge.inaccessible ?
(tmp \ edge.accessible) ?
edge.inaccessible?
immediately after creating an inactive edge, each EP in the input semantics thatthe edge does not (yet) cover is inspected, and if the EP?s index is in the edge?sinaccessible set then the edge is discarded (since there is no way in the future thatthe EP could be integrated with any extension of the edge?s semantics).A nice property of this new technique is that it applies more widely than to justintersective modification: for instance, if the input semantics were to indicate that aphrase should be negated, no edges would be created that extended that phrase withoutthe negation being present.
Section 4 shows this technique results in dramatic improve-ments in realization efficiency.3.5 Selective UnpackingThe selective unpacking procedure outlined in this section allows us to extract a smallset of n-best realizations from the generation forest at minimal cost.
The global rankorder is determined by a conditional Maximum Entropy (ME) model ?
essentially anadaptation of recent HPSG parse selection work to the realization ranking task [19].
Weuse a similar set of features to Toutanova and Manning [20], but our procedure dif-fers from theirs in that it applies the stochastic model before unpacking, in a guidedsearch through the generation forest.
Thus, we avoid enumerating all candidate realiza-tions.
Unlike Malouf and van Noord [21], on the other hand, we avoid an approximativebeam search during forest creation and guarantee to produce exactly the n-best realiza-tions (according to the ME model).
Further looking at related parse selection work, ourprocedure is probably most similar to those of Geman and Johnson [22] and Miyao and5 Implementing collect-semantic-vars() can be efficient: searching for Skolem constants through-out the full structure, it does a similar amount of computation as a single unification.172 J. Carroll and S. Oepen1 ?
?2 3?
?4 3?2 ?
?5 6?
?5 7?4 ?
?8 6?
?8 7?
?9 6?
?9 7?6 ??10?
?11?Fig.
2.
Sample generator forest and sub-node decompositions: ovals in the forest (on the left)indicate packing of edges under subsumption, i.e.
edges 4 , 7 , 9 , and 11 are not in the gen-erator chart proper.
During unpacking, there will be multiple ways of instantiating a chart edge,each obtained from cross-multiplying alternate daughter sequences locally.
The elements of thiscross-product we call decomposition, and they are pivotal points both for stochastic scoring anddynamic programming in selective unpacking.
The table on the right shows all non-leaf decom-positions for our example generator forest: given two ways of decomposing 6 , there will be threecandidate ways of instantiating 2 and six for 4 , respectively, for a total of nine full trees.Tsujii [23], but neither provide a detailed discussion of the dependencies between local-ity of ME features and the complexity of the read-out procedure from a packed forest.Two key notions in our selective unpacking procedure are the concepts of (i) decom-posing an edge locally into candidate ways of instantiating it and of (ii) nested contextsof ?horizontal?
search for ranked hypotheses (i.e.
uninstantiated edges) about candidatesubtrees.
See Figure 2 for examples of edge decomposition, but note that the ?depth?of each local cross-product needs to correspond to the maximum required context sizeof ME features; for ease of exposition, our examples assume a context size of no morethan depth one (but the algorithm straightforwardly generalizes to larger contexts).
Givenone decomposition ?
i.e.
a vector of candidate daughters to a token construction ?
therecan be multiple ways of instantiating each daughter: a parallel index vector ?i0 .
.
.
in?serves to keep track of ?vertical?
search among daughter hypotheses, where each index ijdenotes the i-th instantiation (hypothesis) of the daughter at position j.
Hypotheses areassociated with ME scores and ordered within each nested context by means of a localagenda (stored in the original representative edge, for convenience).
Given the additivenature of ME scores on complete derivations, it can be guaranteed that larger derivationsincluding an edge e as a sub-constituent on the fringe of their local context of optimiza-tion will use the best instantiation of e in their own best instantiation.
The second-bestlarger instantiation, in turn, will be obtained from moving to the second-best hypothesisfor one of the elements in the (right-hand side of the) decomposition.
Therefore, nestedlocal optimizations result in a top-down, exact n-best search through the generation for-est, and matching the ?depth?
of local decompositions to the maximum required MEfeature context effectively prevents exhaustive cross-multiplication of packed nodes.The main function hypothesize-edge() in Figure 3 controls both the ?horizontal?
and?vertical?
search, initializing the set of decompositions and pushing initial hypothe-ses onto the local agenda when called on an edge for the first time (lines 11 ?
17).Furthermore, the procedure retrieves the current next-best hypothesis from the agenda(line 18), generates new hypotheses by advancing daughter indices (while skipping overHigh Efficiency Realization for a Wide-Coverage Unification Grammar 1731 procedure selectively-unpack-edge(edge , n) ?2 results ?
?
?
; i ?
0;3 do4 hypothesis ?
hypothesize-edge(edge , i); i ?
i + 1;5 if (new ?
instantiate-hypothesis(hypothesis)) then6 n ?
n ?
1; results ?
results ?
?new?
;7 while (hypothesis and n ?
1)8 return results;9 procedure hypothesize-edge(edge , i) ?10 if (edge.hypotheses[i]) return edge.hypotheses[i];11 if (i = 0) then12 for each (decomposition in decompose-edge(edge)) do13 daughters ?
?
?
; indices ?
?
?14 for each (edge in decomposition.rhs) do15 daughters ?
daughters ?
?hypothesize-edge(edge, 0)?
;16 indices ?
indices ?
?0?
;17 new-hypothesis(edge, decomposition, daughters, indices);18 if (hypothesis ?
edge.agenda.pop()) then19 for each (indices in advance-indices(hypothesis.indices)) do20 if (indices ?
edge.indices) then continue21 daughters ?
?
?
;22 for each (edge in hypothesis.decomposition.rhs) each (i in indices) do23 daughter ?
hypothesize-edge(edge, i);24 if (not daughter) then25 daughters ?
?
?
; break26 daughters ?
daughters ?
?daughter?
;27 if (daughters) then new-hypothesis(edge, decomposition, daughters, indices)28 edge.hypotheses[i] ?
hypothesis;29 return hypothesis;30 procedure new-hypothesis(edge , decomposition , daughters , indices) ?31 hypothesis ?
new hypothesis(decomposition, daughters, indices);32 edge.agenda.insert(score-hypothesis(hypothesis), hypothesis);33 edge.indices ?
edge.indices ?
{indices};Fig.
3.
Selective unpacking procedure, enumerating the n best realizations for a top-level resultedge from the generation forest.
An auxiliary function decompose-edge() performs local cross-multiplication as shown in the examples in Figure 2.
Another utility function not shown in pseudo-code is advance-indices(), another ?driver?
routine searching for alternate instantiations of daughteredges, e.g.
advance-indices(?0 2 1?)
?
{?1 2 1?
?0 3 1?
?0 2 2?}.
Finally, instantiate-hypothesis() isthe function that actually builds result trees, replaying the unifications of constructions from thegrammar (as identified by chart edges) with the feature structures of daughter constituents.configurations seen earlier) and calling itself recursively for each new index (lines 19 ?27), and, finally, arranges for the resulting hypothesis to be cached for later invocationson the same edge and i values (line 28).
Note that we only invoke instantiate-hypothesis()on complete, top-level hypotheses, as the ME features of Toutanova and Manning [20]can actually be evaluated prior to building each full feature structure.
However, theprocedure could be adapted to perform instantiation of sub-hypotheses within each lo-cal search, should additional features require it.
For better efficiency, our instantiate-hypothesis() routine already uses dynamic programming for intermediate results.4 Evaluation and SummaryBelow we present an empirical evaluation of each of the refinements discussed in Sec-tions 3.2 through 3.5.
Using the LinGO ERG and its ?hike?
treebank ?
a 330-sentence174 J. Carroll and S. OepenTable 1.
Realization efficiency for various instantiations of our algorithm.
The table is brokendown by average ambiguity rates, the first two columns showing the number of items per aggre-gate and average string length.
Subsequent columns show relative cpu time of one- and two-phaserealization with or without packing and filtering, shown as a relative multiplier of the baselineperformance in the 1p+f+ column.
The rightmost column is for selective unpacking of up to 10trees from the forest produced by the baseline configuration, again as a factor of the baseline.
(Thequality of the selected trees depends on the statistical model and the degree of overgeneration inthe grammar, and is a completely separate issue which we do not address in this paper).items length 1p?f?
2p?f?
1p?f+ 1p+f?
2p+f?
1p+f+ n=10Aggregate  ?
?
?
?
?
?
s ?500 < trees 9 23.9 31.76 20.95 11.98 9.49 3.69 31.49 0.33100 < trees ?
500 22 17.4 53.95 36.80 3.80 8.70 4.66 5.61 0.4250 < trees ?
100 21 18.1 51.53 13.12 1.79 8.09 2.81 3.74 0.6210 < trees ?
50 80 14.6 35.50 18.55 1.82 6.38 3.67 1.77 0.890 ?
trees ?
10 185 10.5 9.62 6.83 1.19 6.86 3.62 0.58 0.95Overall 317 12.9 35.03 20.22 5.97 8.21 3.74 2.32 0.58Coverage 95% 97% 99% 99% 100% 100% 100%collection of instructional text taken from Norwegian tourism brochures ?
we bench-marked various generator configurations, starting from the ?gold?
standard MRS formularecorded for each utterance in the treebank.
At 12.8 words, average sentence length inthe original ?hike?
corpus is almost exactly what we see as the average length of allparaphrases obtained from the generator (see Table 1); from the available referencetreebanks for the ERG, ?hike?
appears to be among the more complex data sets.Table 1 summarizes relative generator efficiency for various configurations, wherewe use the best-performing exhaustive procedure 1p+f+ (one-phase generation withpacking and index accessibility filtering) as a baseline.
The configuration 1p?f?
(one-phase, no packing or filtering) corresponds to the basic procedure suggested by Kay [8],while 2p?f?
(two-phase processing of modifiers without packing and filtering) imple-ments the algorithm presented by Carroll et al [12].
Combining packing and filter-ing clearly outperforms both these earlier configurations, i.e.
giving an up to 50 timesspeed-up for inputs with large numbers of realizations.
Additional columns contrast thevarious techniques in isolation, thus allowing an assessment of the individual strengthsof our proposals.
On low- to medium-ambiguity items, for example, filtering gives riseto a bigger improvement than packing, but packing appears to flatten the curve more.Both with and without packing, filtering improves significantly over the Carroll et altwo-phase approach to intersective modifiers (i.e.
comparing columns 2p?f?
and 2p+f?to 1p?f+ and 1p+f+, respectively), thus confirming the increased generality of our solu-tion to the modification problem.
Finally, the benefits of packing and filtering combinemore than merely multiplicatively: compared to 1p?f?, just filtering gives a speed-up of5.9, and just packing a speed-up of 4.3.
At 25, the product of these factors is well belowthe overall reduction of 35 that we obtain from the combination of both techniques.While the rightmost column in Table 1 already indicates that 10-best selective un-packing further improves generator performance by close to a factor of two, Figure 4breaks down generation time with respect to forest creation vs. unpacking time.
Whenplotted against increasing input complexity (in terms of the ?size?
of the input MRS),forest creation appears to be a low-order polynomial (or better), whereas exhaustiveHigh Efficiency Realization for a Wide-Coverage Unification Grammar 1750 5 10 15 20 25 30 35Input Complexity (Number of EPs in MRS)02468101214s(generated by [incr tsdb()] at 15-apr-2005 (00:55 h))?
packed forest creation?
selective unpacking?
exhaustive unpackingFig.
4.
Break-down of generation times (in seconds) according to realization phases and inputcomplexity (approximated in the number of EPs in the original MRS used for generation).
Thethree curves are, from ?bottom?
to ?top?, the average time for constructing the packed generationforest, selective unpacking time (using n = 10), and exhaustive unpacking time.
Note that bothunpacking times are shown as increments on top of the forest creation time.unpacking (necessarily) results in an exponential explosion of generation time: withmore than 25 EPs, it clearly dominates total processing time.
Selective unpacking, incontrast, appears only mildly sensitive to input complexity and even on complex inputsadds no more than a minor cost to total generation time.
Thus, we obtain an over-all observed run-time performance of our wide-coverage generator that is bounded (atleast) polynomially.
Practical generation times using the LinGO ERG average below oraround one second for outputs of fifteen words in length, i.e.
time comparable to humanproduction.References1.
Flickinger, D.: On building a more efficient grammar by exploiting types.
Natural LanguageEngineering 6 (1) (2000) 15 ?
282.
Butt, M., Dyvik, H., King, T.H., Masuichi, H., Rohrer, C.: The Parallel Grammar project.In: Proceedings of the COLING Workshop on Grammar Engineering and Evaluation, Taipei,Taiwan (2002) 1 ?
73.
White, M.: Reining in CCG chart realization.
In: Proceedings of the 3rd International Con-ference on Natural Language Generation, Hampshire, UK (2004)4.
Moore, J., Foster, M.E., Lemon, O., White, M.: Generating tailored, comparative descriptionsin spoken dialogue.
In: Proceedings of the 17th International FLAIRS Conference, MiamiBeach, FL (2004)5.
Oepen, S., Dyvik, H., L?nning, J.T., Velldal, E., Beermann, D., Carroll, J., Flickinger, D.,Hellan, L., Johannessen, J.B., Meurer, P., Nordga?rd, T., Rose?n, V.: Som a?
kapp-ete medtrollet?
Towards MRS-based Norwegian ?
English Machine Translation.
In: Proceedingsof the 10th International Conference on Theoretical and Methodological Issues in MachineTranslation, Baltimore, MD (2004)6.
Whitelock, P.: Shake-and-bake translation.
In: Proceedings of the 14th International Confer-ence on Computational Linguistics, Nantes, France (1992) 610 ?
6167.
Phillips, J.: Generation of text from logical formulae.
Machine Translation 8 (1993) 209 ?235176 J. Carroll and S. Oepen8.
Kay, M.: Chart generation.
In: Proceedings of the 34th Meeting of the Association forComputational Linguistics, Santa Cruz, CA (1996) 200 ?
2049.
Gardent, C., Thater, S.: Generating with a grammar based on tree descriptions.
A constraint-based approach.
In: Proceedings of the 39th Meeting of the Association for ComputationalLinguistics, Toulouse, France (2001)10.
Shieber, S., van Noord, G., Pereira, F., Moore, R.: Semantic head-driven generation.
Com-putational Linguistics 16 (1990) 30 ?
4311.
Moore, R.: A complete, efficient sentence-realization algorithm for unification grammar.
In:Proceedings of the 2nd International Natural Language Generation Conference, Harriman,NY (2002) 41 ?
4812.
Carroll, J., Copestake, A., Flickinger, D., Poznanski, V.: An efficient chart generator for(semi-)lexicalist grammars.
In: Proceedings of the 7th European Workshop on Natural Lan-guage Generation, Toulouse, France (1999) 86 ?
9513.
Copestake, A., Flickinger, D., Sag, I., Pollard, C.: Minimal Recursion Semantics.
An intro-duction.
(1999)14.
Kiefer, B., Krieger, H.U., Carroll, J., Malouf, R.: A bag of useful techniques for efficient androbust parsing.
In: Proceedings of the 37th Meeting of the Association for ComputationalLinguistics, College Park, MD (1999) 473 ?
48015.
Billot, S., Lang, B.: The structure of shared forests in ambiguous parsing.
In: Proceedings ofthe 27th Meeting of the Association for Computational Linguistics, Vancouver, BC (1989)143 ?
15116.
Oepen, S., Carroll, J.: Ambiguity packing in constraint-based parsing.
Practical results.
In:Proceedings of the 1st Conference of the North American Chapter of the ACL, Seattle, WA(2000) 162 ?
16917.
Shieber, S.: Using restriction to extend parsing algorithms for complex feature-based for-malisms.
In: Proceedings of the 23rd Meeting of the Association for Computational Linguis-tics, Chicago, IL (1985) 145 ?
15218.
Oepen, S., Carroll, J.: Performance profiling for parser engineering.
Natural LanguageEngineering 6 (1) (2000) 81 ?
9719.
Velldall, E., Oepen, S., Flickinger, D.: Paraphrasing treebanks for stochastic realization rank-ing.
In: Proceedings of the 3rd Workshop on Treebanks and Linguistic Theories, Tu?bingen,Germany (2004)20.
Toutanova, K., Manning, C.: Feature selection for a rich HPSG grammar using decisiontrees.
In: Proceedings of the 6th Conference on Natural Language Learning, Taipei, Taiwan(2002)21.
Malouf, R., van Noord, G.: Wide coverage parsing with stochastic attribute value grammars.In: Proceedings of the IJCNLP workshop Beyond Shallow Analysis, Hainan, China (2004)22.
Geman, S., Johnson, M.: Dynamic programming for parsing and estimation of stochasticunification-based grammars.
In: Proceedings of the 40th Meeting of the Association forComputational Linguistics, Philadelphia, PA (2002)23.
Miyao, Y., Tsujii, J.: Maximum entropy estimation for feature forests.
In: Proceedings of theHuman Language Technology Conference, San Diego, CA (2002)
