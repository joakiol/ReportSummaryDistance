Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing, pages 189?192,Sydney, July 2006. c?2006 Association for Computational LinguisticsA Pragmatic Chinese Word Segmentation SystemWei Jiang, Yi Guan, Xiao-Long WangSchool of Computer Science and Technology, Harbin Institute of Technology,Heilongjiang Province, 150001, P.R.Chinajiangwei@insun.hit.edu.cnAbstractThis paper presents our work for partici-pation in the Third International ChineseWord Segmentation Bakeoff.
We applyseveral processing approaches accordingto the corresponding sub-tasks, which areexhibited in real natural language.
In oursystem, Trigram model with smoothingalgorithm is the core module in wordsegmentation, and Maximum Entropymodel is the basic model in Named En-tity Recognition task.
The experimentindicates that this system achieves F-measure 96.8% in MSRA open test in thethird SIGHAN-2006 bakeoff.1 IntroductionWord is a logical semantic and syntactic unit innatural language.
Unlike English, there is no de-limiter to mark word boundaries in Chinese lan-guage, so in most Chinese NLP tasks, word seg-mentation is a foundation task, which transformsChinese character string into word sequence.
It isprerequisite to POS tagger, parser or further ap-plications, such as Information Extraction, Ques-tion Answer system.Our system participated in the Third Interna-tional Chinese Word Segmentation Bakeoff,which held in 2006.
Compared with our systemin the last bakeoff (Jiang 2005A), the system inthe third bakeoff is adjusted intending to have abetter pragmatic performance.
This paper mainlyfocuses on describing two sub-tasks: (1) The ba-sic Word Segmentation; (2) Named entities rec-ognition.
We apply different approaches to solveabove two tasks, and all the modules are inte-grated into a pragmatic system (ELUS).2 System DescriptionAll the words in our system are categorized intofive types: Lexicon words (LW), Factoid words(FT), Morphologically derived words (MDW),Named entities (NE), and New words (NW).Figure 1 demonstrates our system structure.The input character sequence is converted intoone or several sentences, which is the basic deal-ing unit.
The ?Basic Segmentation?
is used toidentify the LW, FT, MDW words, and ?NamedEntity Recognition?
is used to detect NW words.We don?t adopt the New Word detection algo-rithm in our system in this bakeoff.
The ?Disam-biguation?
module performs to classify compli-cated ambiguous words, and all the above resultsare connected into the final result, which is de-noted by XML format.2.1 Trigram and Smoothing AlgorithmWe apply the trigram model to the word segmen-tation task (Jiang 2005A), and make use of Ab-solute Smoothing algorithm to overcome thesparse data problem.Trigram model is used to convert the sentenceinto a word sequence.
Let w = w1 w2 ?wn be aword sequence, then the most likely word se-quence w* in trigram is:?=?
?=niiiiwwwwwwPn 112 )|(maxarg*21 Lw                   (1)where let P(w0|w-2 w-1) be P(w0) and let P(w1|w-1w0) be P(w1|w0), and wi represents LW or a typeof FT or MDW.
In order to search the best seg-mentation way, all the word candidates are filledin the word lattice (Zhao 2005).
And the ViterbiBasicSegmentationDisambiguationSentenceNamed EntityRecognitionWordSequenceFactoid DetectLexicon WordsMorphologicalWordInputSequenceFigure 1 ELUS Segmenter and NER189algorithm is used to search the best word seg-mentation path.FT and MDW need to be detected when con-structing word lattice (detailed in section 2.2).The data structure of lexicon can affect the effi-ciency of word segmentation, so we representlexicon words as a set of TRIEs, which is a tree-like structure.
Words starting with the samecharacter are represented as a TRIE, where theroot represents the first Chinese character, andthe children of the root represent the secondcharacters, and so on (Gao 2004).When searching a word lattice, there is thezero-probability phenomenon, due to the sparsedata problem.
For instance, if there is no cooc-curence pair ???/?/???
(we eat bananas) inthe training corpus, then P(??|????)
= 0.According to formula (1), the probability of thewhole candidate path, which includes ???/?/???
is zero, as a result of the local zero prob-ability.
In order to overcome the sparse dataproblem, our system has applied Absolute Dis-counting Smoothing algorithm (Chen, 1999).|}0)(:{|)( 1 1111 >=?
?
+??
+?+ ii niii ni wwcwwN             (2)The notation N1+ is meant to evoke the numberof words that have one or more counts, and the ?is meant to evoke a free variable that is summedover.
The function ()c  represents the count ofone word or the cooccurence count of multi-words.
In this case, the smoothing probability?
+?+??
+?
?=iwiniiniiniiwcDwcwwp)(}0,)(max{)|(1111)|()1( 1 2?
+?
?+ i nii wwp?
(3)where,???????????=?
?
+?++??
)()(1 1 111 i niw i ni wNwcDi?
(4)Because we use trigram model, so the maxi-mum n may be 3.
A fixed discount D (0 ?D ?
1)can be set through the deleted estimation on thetraining data.
They arrive at the estimate2112nnnD +=                                              (5)where n1 and n2 are the total number of n-gramswith exactly one and two counts, respectively.After the basic segmentation, some compli-cated ambiguous segmentation can be furtherdisambiguated.
In trigram model, only the previ-ous two words are considered as context features,while in disambiguation processing, we can usethe Maximum Entropy model fused more fea-tures (Jiang 2005B) or rule based method.2.2 Factoid and Morphological wordsAll the Factoid words can be represented as regu-lar expressions.
So the detection of factoid wordscan be achieved by Finite State Automaton(FSA).In our system, the following categories of factoidwords can be detected, as shown in table 1.Table 1 Factoid word categoriesFT type Factoid word ExampleNumberInteger, real,percent  etc.2910, 46.12%, ??
?, ?????
?Date Date 2005?
5?
12?Time Time 8:00, ????
?English English word, How, are, youwww Website, IP addresshttp://www.hit.edu.cn192.168.140.133email Email elus@google.comphone Phone, fax 0451-86413322Deterministic FSA (DFA) is efficient becausea unique ?next state?
is determined, when givenan input symbol and the current state.
While it iscommon for a linguist to write rule, which can berepresented directly as a non-deterministic FSA(NFA), i.e.
which allows several ?next states?
tofollow a given input and state.Since every NFA has an equivalent DFA, webuild a FT rule compiler to convert all the FTgenerative rules into a DFA.
e.g.z ?< digit > -> [0..9];z < year > ::= < digit >{< digit >+}??
;z < integer > ::= {< digit >+};where ?->?
is a temporary generative rule, and?::=?
is a real generative rule.As for the morphological words, we erase thedealing module, because the word segmentationdefinition of our system adopts the PKU standard.3 Named Entity RecognitionWe adopt Maximum Entropy model to performthe Named Entity Recognition.
The extensiveevaluation on NER systems in recent years (suchas CoNLL-2002 and CoNLL-2003) indicates thebest statistical systems are typically achieved byusing a linear (or log-linear) classification algo-rithm, such as Maximum Entropy model, to-gether with a vast amount of carefully designedlinguistic features.
And this seems still true atpresent in terms of statistics based methods.Maximum Entropy model (ME) is definedover H?
T in segmentation disambiguation,where H is the set of possible contexts aroundtarget word that will be tagged, and T is the set ofallowable tags, such as B-PER, I-PER, B-LOC,I-LOC etc.
in our NER task.
Then the model?sconditional probability is defined as190?
?= Tt thpthphtp')',(),()|(                                (6)where ?==kjthfjjthp1),(),( ???
(7)where h is the current context and t is one of thepossible tags.The several typical kinds of features can beused in the NER system.
They usually includethe context feature, the entity feature, and thetotal resource or some additional resources.Table 2 shows the context feature templates.Table2 NER feature template1Type Feature TemplateOne order feature wi-2, wi-1, wi, wi+1, wi+2Two order feature wi-1:i, wi:i+1NER tag feature t i-1While, we only point out the local featuretemplate, some other feature templates, such aslong distance dependency templates, are alsohelpful to NER performance.
These trigger fea-tures can be collected by Average Mutual Infor-mation or Information Gain algorithm etc.Besides context features, entity features is an-other important factor, such as the suffix of Lo-cation or Organization.
The following 8 kinds ofdictionaries are usually useful (Zhao 2006):Table 3 NER resource dictionary2List Type Lexicon ExamplePlace lexicon ?
?, ?
?, ??
?Word listChinese surname ?, ?, ?, ?
?Prefix of PER ?, ?, ?Suffix of PLA ?, ?, ?, ?, ?
String listSuffix of ORG ?, ?
?, ?
?, ?Character for CPER ?,?, ?, ?, ?Character for FPER ?, ?, ?, ?, ?
Character listRare character ?, ?, ?In addition, some external resources may im-prove the NER performance too, e.g.
we collect alot of entities for Chinese Daily Newspaper in2000, and total some entity features.However, our system is based on Peking Uni-versity (PKU) word segmentation definition andPKU NER definition, so we only used the basicfeatures in table 2 in this bakeoff.
Another effectis the corpus: our system is training by the Chi-nese Peoples?
Daily Newspaper corpora in 1998,which conforms to PKU NER definition.
In thesection 4, we will give our system performancewith the basic features in Chinese Peoples?
DailyNewspaper corpora.1 wi ?
current word, wi-1 ?
previous word, ti ?
current tag.2 Partial translation: ??
BeiJing,??
New york;?
Zhang,?Wang; ?
Old;?
mountain,?
lake;?
bureau.4 Performance and analysis4.1 The Evaluation in Word SegmentationThe performance of our system in the third bake-off is presented in table 4 in terms of recall(R),precision(P) and F score in percentages.
Thescore software is standard and open by SIGHAN.Table 4 MSRA test in SIGHAN2006 (%)MSRA R P F OOV Roov RivClose 96.3 91.8 94.0 3.4 17.5 99.1Open 97.7 96.0 96.8 3.4 62.4 98.9Our system has good performance in terms ofRiv measure.
The Riv measure in close test and inopen test are 99.1% and 98.9% respectively.
Thisgood performance owes to class-based trigramwith the absolute smoothing and word disam-biguation algorithm.In our system, it is the following reasons thatthe open test has a better performance than theclose test:(1) Named Entity Recognition module isadded into the open test system.
And Named En-tities, including PER, LOC, ORG, occupy themost of the out-of-vocabulary words.
(2) The system of close test can only use thedictionary that is collected from the given train-ing corpus, while the system of open test can usea better dictionary, which includes the words thatexist in MSRA training corpus in SIGHAN2005.And we know, the dictionary is the one of impor-tant factors that affects the performance, becausethe LW candidates in the word lattice are gener-ated from the dictionary.As for the dictionary, we compare the two col-lections in SIGHAN2005 and SIGHAN2006, andevaluating in SIGHAN2005 MSRA close test.There are less training sentence in SIGHAN2006,as a result, there is at least 1.2% performancedecrease.
So this result indicates that the diction-ary can bring an important impact in our system.Table 5 gives our system performance in thesecond bakeoff.
We?ll make brief comparison.Table 5 MSRA test in SIGHAN 2005 (%)MSRA R P F OOV Roov RivClose 97.3 94.5 95.9 2.6 32.3 99.1Open 98.0 96.5 97.2 2.6 59.0 99.0Comparing table 4 with table 5, we find thatthe OOV is 3.4 in third bakeoff, which is higherthan the value in the last bakeoff.
Obviously, it isone of reasons that affect our performance.In addition, based on pragmatic consideration,our system has been made some simplifier, forinstance, we erase the new word detection algo-rithm and the is no morphological word detection.1914.2 Named Entity RecognitionIn MSRA NER open test, our NER system istraining in prior six-month corpora of ChinesePeoples?
Daily Newspaper in 1998, which wereannotated by Peking University.
Table 6 showsthe NER performance in the MSRA open test.Table 6 The NER performance in MSRA Open testMSRA NER Precision Recall  F ScorePER 93.68% 86.37% 89.87LOC 85.50% 59.67% 70.29ORG 75.87% 47.48% 58.41Overall 86.97% 65.56% 74.76As a result of insufficiency in preparing bake-off, our system is only trained in Chinese Peo-ples?
Daily Newspaper, in which the NER is de-fined according to PKU standard.
However, theNER definition of MSRA is different from thatof PKU, e.g, ??
?/LOC ??
?, ?
?/PER ?/PER???
in MSRA, are not entities in PKU.So the training corpus becomes a main handicapto decrease the performance of our system, and italso explains that there is much difference be-tween the recall rate and the precision in table 6.Table 7 gives the evaluation of our NER sys-tem in Chinese Peoples?
Daily Newspaper, train-ing in prior five-month corpora and testing in thesixth month corpus.
We also use the feature tem-plates in table 2, in order to make comparisonwith table 6.Table 7 The NER test in Chinese Peoples?
DailyMSRA NER Precision Recall  F ScoreCPN 93.56 90.96 92.24FPN 90.42 86.47 88.40LOC 91.94 90.52 91.22ORG 88.38 84.52 86.40Overall 91.35 88.85 90.08This experiment indicates that our system canhave a good performance, if the test corpus andthe training corpora conform to the condition ofindependent identically distributed attribution.4.3 Analysis and DiscussionSome points need to be further considered:(1) The dictionary can bring a big impact tothe performance, as the LW candidates comefrom the dictionary.
However a big dictionarycan be easily acquired in the real application.
(2) Due to our technical and insufficientlypreparing problem, we use the PKU NER defini-tion, however they seem not unified with theMSRA definition.
(3) Our NER system is a word-based model,and we have find out that the word segmentationwith two different dictionaries can bring a bigimpact to the NER performance.
(4) We erase the new word recognition algo-rithm in our system.
While, we should explorethe real annotated corpora, and add new worddetection algorithm, if it has positive effect.
e.g.???
??
(lotus prize) can be recognized as oneword by the conditional random fields model.5 ConclusionWe have briefly described our word segmenta-tion system and NER system.
We use word-based features in the whole processing.
Our sys-tem has a good performance in terms of Rivmeasure, so this means that the trigram modelwith the smoothing algorithm can deal with thebasic segmentation task well.
However, the resultin the bakeoff indicates that detecting out-of-vocabulary word seems to be a harder task thandealing with the segmentation-ambiguity task.The work in the future will concentrate on twosides: improving the NER performance and add-ing New Word Detection Algorithm.ReferencesHuaPing Zhang, Qun Liu etc.
2003.
Chinese LexicalAnalysis Using Hierarchical Hidden MarkovModel, Second SIGHAN workshop affiliated with4th ACL, Sapporo Japan, pp.63-70.Jianfeng Gao, Mu Li et al 2004.
Chinese Word Seg-mentation: A Pragmatic Approach.
MSR-TR-2004-123, November 2004.Peng Fuchun, Fangfang Feng and Andrew McCallum.Chinese segmentation and new word detection us-ing conditional random fields.
In:COLING 2004.Stanley F.Chen and J. Goodman.
1999.
An empiricalstudy of smoothing techniques for language model-ing.
Computer Speech and Language.
13:369-394.Wei Jiang, Jian Zhao et al 2005A.Chinese WordSegmentation based on Mixing Model.
4thSIGHAN Workshop.
pp.
180-182.Wei Jiang, Xiao-Long Wang, Yi Guan et al 2005B.applying rough sets in word segmentation disam-biguation based on maximum entropy model.
Jour-nal of Harbin Institute of Technology (New Series).13(1): 94-98.Zhao Jian.
2006.
Research on Conditional Probabilis-tic Model and Its Application in Chinese NamedEntity Recognition.
Ph.D. Thesis.
Harbin Instituteof Technology, China.Zhao Yan.
2005.
Research on Chinese MorphemeAnalysis Based on Statistic Language Model.
Ph.D.Thesis.
Harbin Institute of Technology, China.192
