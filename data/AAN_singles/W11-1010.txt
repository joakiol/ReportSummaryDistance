Proceedings of SSST-5, Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 88?97,ACL HLT 2011, Portland, Oregon, USA, June 2011. c?2011 Association for Computational LinguisticsImproving MT Word Alignment Using Aligned Multi-Stage ParsesAdam Meyers?, Michiko Kosaka?, Shasha Liao?
and Nianwen Xue??
New York University, ?Monmouth University, ?Brandeis UniversityAbstractWe use hand-coded rules and graph-alignedlogical dependencies to reorder English texttowards Chinese word order.
We obtain a1.5% higher F-score for Giza++ compared torunning with unprocessed text.
We describethis research and its implications for SMT.1 IntroductionSome statistical machine translation (SMT) systemsuse pattern-based rules acquired from linguisticallyprocessed bitexts.
They acquire these rules throughthe alignment of a parsed structure in one languagewith a raw string in the other language (Yamada andKnight, 2001; Shen et al, 2008) or the alignmentof source/target language parse trees (Zhang et al,2008; Cowan, 2008).
This paper shows that ma-chine translation (MT) can also benefit by aligning a?deeper?
level of analysis than parsed text, which in-cludes semantic role labeling, regularization of pas-sives and wh constructions, etc.
We create GLARFrepresentations (Meyers et al, 2009) for English andChinese sentences, in the form of directed acyclicgraphs.
We describe two graph-based techniquesfor reordering English sentences to be closer to thatof corresponding Chinese sentences.
One techniqueis based on manually created rules and the other isbased on an automatic alignment of GLARF repre-sentations of Chinese/English sentences.
After re-ordering, we align words of the reordered Englishwith the words of the Chinese, using the Giza++word aligner(Och and Ney, 2003).
For both tech-niques, the resulting alignment has a higher F-scorethan Giza++ on raw text (a 0.7% to 1.5% absoluteimprovement).
In principle, our reordered text canbe used to improve any Chinese/English SMT sys-tem for which Giza++ (or other word aligners) arepart of the processing pipeline.These experiments are a first step in usingGLARF-style analyses for MT, potentially improv-ing systems that already perform well with alignedtext lacking large gaps in surface alignment.
We hy-pothesize that SMT systems are most likely to ben-efit from deep analysis for structures where sourceand target language word order differs the most.
Wepropose using deep analysis to reorder such struc-tures in one language to more closely reflect theword order of the other language.
The text would bereordered at two stages in an SMT system: (1) priorto acquiring a translation model; and (2) either priorto translation (if source text is reordered) or aftertranslation (if target text is reordered).
Our systemmoves large constituents (e.g., noun post-modifiers)to bring English word order closer to that of parallelChinese sentences.
This improves word alignmentand is likely to improve SMT.For this work we use two English/Chinese bitextcorpora developed by the Linguistic Data Consor-tium (LDC): the Tides FBIS corpus and the GALEY1 Q4 Chinese/English Word-Alignment corpus.We used 2300 aligned sentences from FBIS for de-velopment purposes.
We divided the GALE corpusinto into a 3407 sentence development subcorpus(DEV) and a 1505 sentence test subcorpus (TEST).We used the LDC?s manual alignments of the FBIScorpus to score these data.882 Related Work in SMTFour papers stand out as closely related to thepresent study.
(Collins et al, 2005; Wang et al,2007) describe experiments which use manually cre-ated parse-tree-based rules to reorder one side ofa bitext: German/English in (Collins et al, 2005)and English/Chinese in (Wang et al, 2007).
Bothachieve BLEU score improvements for SMT: 25.2%to 26.8% for (Collins et al, 2005) and 28.52 to 30.86for (Wang et al, 2007).
(Wang et al, 2007) usesrules very similar to our own as they use the samelanguage pair, although they reorder the Chinese,whereas we reorder the English.
The most signifi-cant differences between our research and (Collinset al, 2005; Wang et al, 2007) are: (1) our manualrules benefit from a level of representation ?deeper?than a surface parse; and (2) In addition to the hand-coded rules, we also use automatic alignment-basedrules.
(Wu and Fung, 2009) uses PropBank role la-bels (Palmer et al, 2005) as the basis of a secondpass filter over an SMT system to improve the BLEUscore from 42.99 to 43.51.
The main similarity tothe current study is the use of a level of represen-tation that is ?deeper?
than a surface parse.
How-ever, our application of linguistic structure is morelike that of (Wang et al, 2007) and our ?deep?
levelconnects all predicates and arguments in the sen-tence, regardless of part of speech, rather than justconnecting verbs to their arguments.
(Bryl and vanGenabith, 2010) describes an open source LFG F-structure alignment tool with an algorithm similar toour previous work.
They evaluate their alignmentoutput on 20 manually-aligned German and EnglishF-structures.
They leave the impact of their work onMT to future research.In addition to these papers, there has also beensome work on rule-based reordering preprocessorsto word alignment based on shallower linguistic in-formation.
For example (Crego and Marin?o, 2006)reorders based on patterns of POS tags.
We hypoth-esize that this is similar to the above approaches inthat patterns of POS tags are likely to simulate pars-ing or chunking.3 Preparing the DataThe two stage parsers of previous decades (Hobbsand Grishman, 1976) generated a syntactic repre-sentation analogous to the (more accurate) outputof current treebank-based parsers (Charniak, 2001)and an additional second stage output that regular-ized constructions (passive, active, relative clauses)to representations similar to active clauses with nogaps, e.g., The book was read by Mary was given arepresentation similar to that of Mary read the book.Treating the active clause as canonical provides away to reduce variation in language and thus, mak-ing it easier to acquire and apply statistical informa-tion from corpora?there is more evidence for partic-ular statistical patterns when applications learn pat-terns and patterns more readily match data.Two-stage parsers were influenced by linguistictheories (Harris, 1968; Chomsky, 1957; Bresnan andKaplan, 1982) which distinguish a ?surface?
and a?deep?
level.
The deep level neutralizes differencesbetween ways to express the same meaning?a pas-sive like The cheese was eaten by rats was analyzedin terms of the active form Rats ate the cheese.
Cur-rently ?semantic parsing?
refers to a similar repre-sentation, e.g., (Wagner et al, 2007) or our ownGLARF (Meyers et al, 2009).
However, the term isalso used for semantic role labelers (Gildea and Ju-rafsky, 2002; Xue, 2008), systems which typicallylabel semantic relations between verbs and their ar-guments and rarely cover arguments of other partsof speech.
Second stage semantic parsers like ourown, connect all the tokens in the sentence.
Alignedtext processed in this way can (for example) repre-sent differences in English/Chinese noun modifierorder, including relative clauses.
In contrast, fewrole labelers handle noun modifiers and none han-dle relative clauses.
Below, we describe the GLARFframework and our system for generating GLARFrepresentations of English and Chinese sentences.For each language, we combine several types ofinformation which may include: named entity (NE)tagging, date/number regularization, recognition ofmulti-word expressions (the preposition with respectto, the noun hand me down and the verb ad lib),role labels for predicates of all parts of speech, regu-larizing passives and other constructions, error cor-rection, among other processes into a single typedfeature structure (TFS) representation.
This TFSis converted into a set of 25-tuples representingdependency-style relations between pairs of wordsin the sentence.
Three types of dependencies are89n1knowSBJ OBJn3ofn5 OBJSBJ OBJN?POSCOMPn4theQ?POSn2?
n3?n6?n1?I rulestennisn6n2Figure 1: Word-Aligned Logic1 Dependenciesrepresented: surface dependencies (close to the levelof the parser), logic1 dependencies (reflecting var-ious regularizations) and logic2 dependencies (re-flecting the output of a PropBanker, NomBankerand Penn Discourse Treebank transducer).
(Palmeret al, 2005; Xue and Palmer, 2003; Meyers et al,2004; Miltsakaki et al, 2004) The surface depen-dency graph is a tree; The logic1 dependency graphis an directed acyclic graph; and The logic2 depen-dency graph is a directed graph with cycles, cover-ing only a subset of the tokens in the sentence.
Forthese experiments, we focus on the logic1 relations,but will sometimes use the surface relations as well.Figure 1 is a simple dependency-based logic1 repre-sentation of I know the rules of tennis and its Chi-nese translation.
The edge labels name the relationsbetween heads and dependents, e.g., I is the SBJ ofknow and the dashed lines indicate word level corre-spondences.
Each node is labeled with both a wordand a unique node identifier (n1, n1?, etc.
)The English system achieves F-scores for logic1dependencies on parsed news text in the 80?90%range and the Chinese system achieves F-scores inthe 74?84% range, depending on the complexity ofthe text.
The English system has been created overthe course of about 9 years, and consequently ismore extensive than the Chinese system, which hasbeen created over the past 3 years.
The systems aredescribed in more detail in (Meyers et al, 2009).The GLARF representations are created in a se-ries of steps involving several processors.
The En-glish pipeline includes: (1) dividing text into sen-tences; (2) running the JET NE tagger (Ji and Gr-ishman, 2006); (3) running scripts that clean up data(to prevent parser crashes); (4) running a parser (cur-rently Charniak?s 2005 parser based on (Charniak,2001)); (5) running filters that: (a) correct com-mon parsing errors; (b) merge NE information withthe parse, resolving conflicts in constituent bound-aries by hand-coded rules; (c) regularize numbers,dates, times and holidays; (d) identify heads andlabel relations between constituents; (e) regularizetext grammatically (filling empty subjects, resolv-ing relative clause and Wh gaps, etc.
); (f) mark con-junction scope; (g) identify transparent constituents(e.g., recognizing, that A variety of different peo-ple has the semantic features of people (human), notthose of variety, the syntactic head of the phrase.
);among other aspects.
The Chinese pipeline is simi-lar, except that it includes the LDC word segmenterand a PropBanker (Xue, 2008).
Also, the regulariza-tion routines are not as completely developed, e.g.,relative clause gaps and passives are not handledyet.
The Chinese system currently uses the Berke-ley parser (Petrov and Klein, 2007).
Each of thesepipelines derives typed feature structure representa-tions, which are then converted into the 25 tuple rep-resentation of 3 types of dependencies between pairsof tokens: surface, logic1 and logic2.To insure that the logic1 graphs are acyclic, we as-sume that certain edges are surface only and that theresulting directed acyclic graphs can have multipleroots.
It turns out that the multiple rooted cases aremostly limited to a few constructions, the most com-mon being parenthetical clauses and relative clauses.A parenthetical clause takes the main clause as anargument.
For example, in The word ?potato?, heclaimed, is spelled with a final ?e?., the verb claimed,takes the entire main clause as an argument, we as-sume that he claimed is a dependent on the mainverb (is) spelled labeled PARENTHETICAL in oursurface dependency structure, but that the main verb(is) spelled is a dependent of the verb claimed inour logic1 structure, labeled COMPLEMENT.
Thusthe logic1 surface dependency structure have dis-tinct roots.
In a relative clause, such as the book thatI read?, we assume that the clause that I read is a de-pendent on the noun book in our surface dependencystructure with the label RELATIVE, but book is a de-pendent on the verb read in our logic1 dependencystructure, with the label OBJ.
This, means that ourlogic1 dependency graphs for sentences containingrelative clauses are multi-rooted.
One of the roots isthe same as the root of the surface tree and the otherroot is the root of the relative clause graph (a rela-90tive pronoun or a main verb).
Furthermore, there isa surface path connecting the relative clause root tothe rest of the graph.
Noncyclic graph traversal ispossible, provide that: (1) we use the surface path toenter the graph representing the relative clause ?
oth-erwise, the traversal would skip the relative clause;and (2) we halt the traversal if we reach this path asecond time ?
this avoids traversing down an end-less path.
The parenthetical and relative clause arerepresentative of the handful of cases in which naiverepresentations would introduce loops.
All cases ofwhich we are aware have the essential properties ofone of these two cases: (1) either introducing a dif-ferent single root of the clause; or (2) introducing anadditional root that can be bridged by a surface path.4 Manual Reordering RulesWe derived manual rules for making the EnglishWord Order more like the Chinese by manually in-specting the data.
We inspected the first 100-200sentences of the DEV corpus by first transliteratingthe Chinese into English ?
replaced each Chineseword with the aligned English counterpart.
Severalpatterns emerged which were easy to formalize intorules in the GLARF framework.
These patterns wereverified and sometimes generalized through discus-sions with native Chinese speakers and linguists.Our rules, similar to those of (Wang et al, 2007) areas follows (results are discussed in section 6): (1)Front a post-nominal PP headed by a preposition inthe list {of, in, with, about)}.
(2) Front post-nominalrelative clause that begins with that or does not haveany relative pronoun, such that the main predicate isnot a copula plus adjective construction.
(3) Frontpost-nominal relative clause that begins with that orhas no relative pronoun if the main predicate is acopula+adjective construction which is not negatedby a word from the set {no neither nor never notn?t}.
(4) Front post-nominal reduced relative in theform of a passive or adjectival phrase.
(5) Move ad-verbials more than and less than after numbers thatthey modify.
(6) Move PPs that post-modify adjec-tives to the position before the adjective.
(7) Movesubordinate conjunctions before and after to the endof the clause that they introduce.
(8) Move an ini-tial one-word-long title (Mr., Ms., Dr., President) tothe end of the name.
(9) Move temporal adverbials(adverb, PP, subordinate clause that is semanticallytemporal) to pre-verb position.5 Automatic Node Alignment and itsApplication for Word AlignmentIn this experiment, we automatically derive re-orderings of the English sentences from an align-ment between nodes in logic1 dependency graphsfor the English (source) and Chinese (target) sen-tences.
Source/Target designations are for conve-nience, since the direction of MT is irrelevant.We define an alignment as a partial function fromthe nodes in the source graph and the nodes in thetarget graph.
We, furthermore, assume that this map-ping is 1 to 1 for most node pairs, but can be n to 1(or 1 to n).
Furthermore, we allow some nodes, ineffect, to represent multiple tokens.
These are iden-tified as part of the GLARF analysis of a particularsentence string and reflect language-specific rules.Thus, for our purposes, a mapping between a sourceand target node, each representing a multi-word ex-pression is 1 to 1, rather than N to N.We identify the following types of multi-word ex-pressions for this purpose: (a) idiomatic expressionsfrom our monolingual lexicons, (b) dates, (c) times(d) numbers and (e) ACE (Grishman, 2000) NEs.Dates, holidays and times are regularized using ISO-TimeML, e.g., January 3, 1977 becomes 1977-03-01and numbers are converted to Arabic numbers.5.1 ALIGN-ALG1This work uses a modified version of ALIGN-ALG1, a graph alignment algorithm we previouslyused to align 1990s-style two-stage parser output forMT experiments.
ALIGN-ALG1 is an O(n2) algo-rithm, n is the maximum number of nodes in thesource and target graphs (Meyers et al, 1996; Mey-ers et al, 1998).
Given Source Tree T and TargetTree T ?, an alignment(T, T ?)
is a partial functionfrom nodes N in T to nodes N ?
in T ?.
An exhaus-tive search of possible alignments would consider allnon-intersecting combinations of the T ?T ?
pairs ofsource/target nodes ?
There are at most T !
such pair-ings where T >= T ?.1 However, ALIGN-ALG1 as-sumes that some of these pairings are unlikely, and1This ignores N to 1 matches, which we allow, although rel-atively rarely.91favors pairings that assume the structure of the treescorrespond more closely.
In particular, it is assumedthat ancestor nodes are more likely to match if mostof their descendant nodes match as well.ALIGN-ALG1 finds the highest scoring align-ment, where the score of an alignment is the sumof the scores of the node pairs in the partial func-tion.
The score for each node pair (n, n?)
partiallydepends on the scores of a mapping from the chil-dren of n to the children of n?.
While the processof calculating the scores is recursive, it can be madeefficient using dynamic programming.ALIGN-ALG1 assumes that we align r and r?,the roots of T and T ?.
Calculating the scores for rand r?, entails calculating the scores of pairs of theirchildren, and by extension all mappings from N toN ?
that obey the dominance preserving constraint:Given nodes n1 and n2 in N and nodes n?1 and n?2in N ?, where all 4 nodes are part of the alignment,it cannot be the case that: n1 dominates n2, butn?1 does not dominate n?2.
Here, dominates meansis an ancestor in the dependency graph.
ALIGN-ALG1 scores each pair of nodes using the formula:Score(n, n?)
= Lex(n, n?)
+ ChildV al(n, n?
),where Lex(n, n?)
is a score based on matching thewords labeling nodes n and n?, e.g., the score is 1 ifthe pair is found in a bilingual dictionary and 0 oth-erwise.
Given n has children c0, .
.
.
, ci and n?
haschildren c?0, .
.
.
, c?j , to calculate ChildVal: (1) Cre-ate Child-Matrix, a (i+ 1)?
(j + 1) matrix (2) Fillevery position (1 <= x <= i, 1 <= x?
<= j)with Score(x, x?)
(3) Fill every position (i+1, 1 <=x?
<= j) with Score(n, x?)
minus a penalty (e.g.,- .1) for collapsing an edge.
This treats n?
and x?as a single unit, matched to n.2 (4) Fill every po-sition (1 <= x <= i, j+1) with Score(x, n?)
mi-nus a penalty for collapsing an edge.
Thus n + x ispaired with n?.
(5) Set (i+1,j+1) to ??.
Collapsingboth source and target edges is not permitted.
(6) Forall sets of positions in the matrix such that no nodeor column is repeated, select the set with the high-est aggregate score.
The aggregate score is the nu-meric value of ChildV al(n, n?).
If (n,n?)
is part ofthe alignment that is ultimately chosen, this choiceof node pairs is also part of the alignment.
There2The slight penalty represents that collapsing edges compli-cate the analysis and is thus disfavored (Occam?s Razor).are at most max(i + 1, j + 1)!
possible pairings.Rather than calculating them all, a greedy heuristiccan reduce the calculation time with minimal effecton accuracy: the highest scoring cell in the matrix ischosen first, conflicting cells are eliminated, the nexthighest scoring cell is chosen, etc.Consider the example in Figure 1, assum-ing the dashed lines connect lexical matches(the function LEX returns 1 for these nodepairs).
Where n1 and n1?
are the roots,Score(n1, n1?)
= 1 + ChildV al(n1, n1?).
Cal-culating ChildV al(n1, n1?)
requires a recursivedescent down the pairs of nodes, until the bot-tom most pair is scored.
Score(n6, n6?)
= 1.Score(n5, n6?)
= 0 + .9 (derived by collaps-ing an edge and subtracting a penalty of .1).Score(n3, n3?)
= 1 + .9 = 1.9.
Score(n2, n2?)
=1.
ChildV al(n1, n1?)
= 1 + 1.9 = 2.9.
ThusScore(n1, n1?)
= 3.9.
The alignment includes:(n1, n1?
), (n2, n2?
), (n3, n3?
), (n5, n6?
), (n6, n6?
).The collapsing of edges helps recognize caseswhere multiple predicates form substructures, e.g.,take a walk, is angry, etc.
in one tree can map to sin-gle verbs in the other tree, allowing outgoing edgesfrom walk or angry to map to outgoing edges of thecorresponding verb, e.g., the agent and goal of Johnwalked to the store could map to the agent and goalof John took a walk to the store.In practice, ALIGN-ALG1 falls short because:(1) Our translation dictionary does not have suffi-cient coverage for the algorithm to perform well; (2)The assumption that the roots of both graphs shouldbe aligned is often false.
Parallel text often reflectsa dynamic, rather than a literal translation.
In onepair of aligned sentences in the FBIS corpus, theEnglish phrase the above mentioned requests cor-responds to: meaning these re-quests of Chen Shui-bian ?
Chen Shui-bian has nocounterpart in the English.
Parts of translations canbe omitted due to: (a) the discretion of the trans-lators, (b) the expected world knowledge of partic-ular language communities, (c) the cultural impor-tance of particular information, etc.
; (3) Violationsof the dominance-preserving constraint exist.
Themost common type that we have observed consistsof sequences of transparent nouns and of (e.g., se-ries of) in English corresponding to quantifiers in92Chinese ( ).
Thus the head of the English con-struction corresponds to the dependent of the Chi-nese construction and vice versa.5.2 Lexical ResourcesOur primary bilingual Chinese/English dictionary(LEX1) had insufficient coverage for ALIGN-ALG1to be effective.
LEX1 is a merger between:The LDC 2002 Chinese-English Dictionary andHowNet.
In addition, we manually added additionaltranslations of units of measure from English.
Wealso used NEDICT, a name translation dictionary (Jiet al, 2009) and AUTODICT, English/Chinese wordto word pairs with high similarity scores taken fromMT phase tables created as part of the (Zhang et al,2007) system.
The NEDICT was used both for pre-cise matches and partial matches (since, NEs canoften be synonymous with substrings of NEs).
Inaddition, we used some WordNet (Fellbaum, 1998)synonyms of English to expand the coverage of allthe dictionaries, allowing English words to matchChinese word translations of their synonyms.
Weallowed additional matches of function words thatserved similar functions in the two languages includ-ing: copulas, pronouns and determiners.Finally, we use a mutual information (MI) basedapproach to find further lexical information.
We runour alignment program over the corpus two times,the first time, we acquire statistical informationuseful for generating a MI-based score.
This scoreis used as a lexical score on the second pass foritems that do not match any of the dictionaries.
Onthe first pass, we tally the frequency of each pairof source/target words s and t, such that neithers, nor t are matched lexically to any other itemin the sentence.
We, furthermore, keep track ofthe number of times each word appears in thecorpus and the number of times each word appearedunaligned in the corpus.
We tally MI as follows:pair?frequency21+(source?word?frequency?target?word?frequency)One is added to the denominator as a variation onadd-one smoothing (Laplace, 1816), intended topenalize low frequency scores.
We calculate thisscore in two ways: (a) using the global frequenciesof the source and target words; and (b) using thefrequency these words were unaligned.
The largerof the two scores is the one that is actually use.Different lexicons are given different weights.Matches between words in the hand-coded transla-tion dictionary and NEDICT are given a score of1.0.
Matches in other dictionaries are allotted lowerscores to represent that these are based on automati-cally acquired information, which we assume is lessreliable than manually coded information.35.3 ALIGN-ALG2With ALIGN-ALG2, we partially address two lim-itations of ALIGN-ALG1: (1) the assumption thatthe roots of source and target graph are aligned;and (2) the dominance-preserving constraint.
Ba-sically, we assume that structural similarity is fa-vored, but not necessarily at the global level.
Thusit is likely that many subparts of corresponding treescorrespond closely, but not necessarily the highestnodes in the trees.We use ALIGN-ALG1 to align every possible pairof S source nodes and T target nodes.
Then we lookfor P , the highest scoring node pair of all SXTpairs.
P and all the pairs of descendants that areused to derive this score (the highest scoring pairsof children, grand children, etc.)
become the initialoutput.
Then we find all unmatched source and tar-get children, and look up the highest scoring pair ofthese nodes, and we repeat the process, adding theresulting node pairs to the output.
We continue torepeat this process until either all the nodes are in-cluded in the output or there is no remaining pairwith a score above a threshold score (we leave au-tomatic methods of tuning this score to future workand preliminarily have set this parameter to .3).
Thismeans that: 1) some parts of the graphs are left un-aligned (the alignment is a partial mapping); 2) thealignment is more resilient to misalignment causedby differences in graph structure, regardless of thereason; and 3) the alignment may be between pairof unconnected graphs, each containing subsets ofnodes and edges in the source and target graphs.While more complex than ALIGN-ALG1, ALIGN-ALG2 performs relatively quickly.
After one itera-tion using ALIGN-ALG1, scores are looked up, notrecalculated.3Current informal weights of .2 to .6 may be replaced withautomatically tuned weights (hill-climbing, etc.)
in future work.935.4 Treating Multiple Tokens as OneIn some cases, parsing and segmentation of textcan be corrected through minor modifications to ouralignment routine.
Similarly, we use bilingual lex-ical information to determine that certain other ad-jacent tokens should be treated as single words forpurposes of alignment.Given a language for which segmentation is acommon source of processing error (Chinese), if atoken is unaligned, we check to see whether subdi-viding the token into two sub-tokens would allowone or both of these sub-tokens to be alignable withunaligned tokens in the other language.
We iter-ate through the string one token at a time, tryingall partitions.
Given a source token ABC, consist-ing of segments A, B and C, we test the two pairs ofsubsequences {A, BC} and {AB, C}, to see whichof the two partitions (if any) could be aligned withunaligned target tokens and we compare the scoresof both, selecting the highest score.
Unless no par-tition yields further source/target matches, we thenchoose the highest scoring partition and add the re-sulting node pairings to our alignment.
In a similarway, if there are a pair of aligned names consistingof source tokens sj .
.
.
sk and target tokens tj .
.
.
tk,we look for adjacent unaligned source nodes (a se-quence of nodes ending in sj?1 or beginning withsk+1) and/or adjacent target language nodes, suchthat adding these nodes to the name sequence wouldproduce at least as high a lexical score.
The lexi-con can also be used to match two adjacent items tothe same word.
We use a similar routine that checksour lexicons for words that are adjacent to matchingwords.
This is particularly meaningful for the entriesautomatically acquired by means of MI, as our cur-rent method for acquiring MI would not distinguishbetween 1 to 1 and N to 1 cases.
Thus MI scoresfor adjacent items typically does mean that an N to1 match is appropriate.
For example, the Chineseword had high MI with every wordin the sequence (except and): ambassador extraor-dinary and plenipotentiary (example is from FBIS).This routine was able to cause our procedure to treatthis English sequence as a single token.5.5 Using Node Alignment for ReorderingGiven a node alignment, we can attempt to reorderthe source language so that words associated withaligned nodes reflect the order of the words label-ing the corresponding target nodes.
Specifically,we reorder our surface phrase structure-based repre-sentation of the source language (English) and thenprint out all the words yielded from the resultingreordered tree.
Reordering takes place in a bottomup fashion as follows: for each phrase P with chil-dren c0 .
.
.
cn, reorder the structure beneath the childnodes first.
Then build the new-constituent rightto left, one child at a time from cn .
.
.
c0.
Start-ing with an empty sequence, each item is put inits proper place among the constituents in the se-quence so far.
At each step, place some ci after somecj in ci+1 .
.
.
cn, such that cj align precedes ciand cj is after every ck in ci+1 .
.
.
cn such thatci align precedes ck.
If cj does not exist, ci isplaced at the beginning of the sequence so far.Definition of X align precedes Y , where X andY are nodes sharing the same parent: (1) Let pairsXbe the set of source/target pairs in the alignment suchthat some (leaf node) descendant of X is the sourcenode in the pair; (2) Let pairsY be the set of pairsin the alignment such that some descendant of Y isthe source node in the pair; (3) let Xtmax be the lasttarget member of a pair in pairsX , where the or-der is determined by the word order of the targetwords labeling the nodes; (4) let Ytmin be the firsttarget member of a pair in pairsY , where the orderis determined the same way; (5) let Xsmin be thefirst source member of a pair in pairsx, accordingto the source sentence word order; (6) let Ysmax bethe last source word in a pair in pairsY ordered thesame way.
(7) X align precedes Y if: Xtmax pre-cedes Ytmin and there is no source/target pair Q,Rin the alignment such that: (A) R precedes, Ytmin;(B) Xtmax precedes R; (C) Q either precedes Xsminor follows Ysmax; (D) If Q precedes Ysmax, then Rdoes not precede Ytmin.Essentially, the align precedes operator pro-vides a conservative way to order the source sub-trees S1 and S2 by their aligned target sub-tree coun-terparts T1 and T2.
The idea is that if T1 and T2are ordered in an opposite manner to S1 and S2,the source subtrees should trade places.
However,94System DEV TESTBASELINE 53.1% 49.9%MANUAL 54.0% 50.6%(p < .01) (not significant)ALIGN 53.5% 51.1%(p < .05) (p < .01)ALIGN+MI 53.8% 51.4%(p < .01) (p < .01)Table 1: F Scores for Reordering Rulesa source/target pair Bs, Bt can block this reorder-ing if doing so would upset the order of the movedconstituents relative to Bs and Bt e.g., if before themove, Bs precedes S2 and Bt precedes T2, but af-ter the move S2 would precede Bs.
This reorderingproceeds from right to left, halting after placing c0.6 ResultsThe results summarized in table 1, provide F-scores(the harmonic mean of precision and recall) of theword alignment resulting from running GIZA++with and without our reordering rules, using theLDC?s manually created word alignments for ourDEV and TEST corpora.4 Giza++ is run with En-glish as source and Chinese as target.
Our baselineis the result of running Giza++ on the raw text.
Thestatistical significance of differences from the base-line are provided in parentheses, next to each non-baseline score(rounded to 2 significant digits).
Wedivided both corpora into 20 parts and ran all ver-sions of the program on each section.
We comparedthe system output for each section against the base-line and used the sign test to calculate statistical sig-nificance.
All system output except one5 achievedat least p < .05 and most systems achieved signifi-cance well below p < .01.Informally, we observe that the rules reorderingcommon noun modifiers produce most of the total4We used F-scores, which (Fraser and Marcu, 2007) show tocorrelate well with improvements in BLEU.
We weighted pre-cision and recall evenly since we do not currently have BLEUscores for MT that use these alignments and therefore cannottune the weights.
Our results also showed improvements inalignment error rate (AER) (Och and Ney, 2000), which incor-porate the ?possible?
and ?sure?
portions of the manual align-ment into F-score, but do not seem to correlate well with BLEU.5When run on the test corpus, the manual system outper-formed the baseline system on only 13 out of 20 sections.improvement.
However, space limitations prevent adetailed exploration of these differences.
The resultsshow that for both DEV and TEST corpora, both re-ordering approaches improve F-scores of GIZA++over the baseline.
The manual rules (MANUAL)seem to suffer somewhat from overtraining on theDEV corpus, as they were designed based on DEVcorpus examples, whereas the alignment based ap-proaches (ALIGN and subsequent entries in the ta-ble) seem resilient to these effects.
The use of Mu-tual Information (ALIGN+MI) seems to further im-prove the F-score.The two approaches worked for many of the samephenomena, e.g., they fronted many of the samenoun post-modifiers.
The advantage of the hand-coded rules seems to be that they cover reorderingof words which we cannot align.
For example, arule that fronts post-nominal of phrases operates re-gardless of dictionary coverage.
Thus the rule-basedversion fronted the of phrase in the NP the govern-ment of the Guangxi Zhuangzu Autonomous Regionin our DEV corpus, due to the absolute applicationof the rule.
However, the alignment-based versiondid not front the PP because the name was not foundin NEDICT.
On the other hand, exceptions to thisrule were better handled by the alignment-based sys-tem.
For example, if series of aligns with the quan-tifier , the PP would be incorrectly frontedby the manual, but not the alignment-based system.Also, the alignment-based method can handle casesnot covered by our rules with minimal labor.
Thus,the automatic system, but not the manual-rule sys-tem fronted the locative PP in Guangxi to the po-sition between been and quite in the sentence: for-eign businessmen have been quite actively investingin Guangxi.
This is closer to the Chinese, but mayhave been difficult to predict with an automatic rulefor several reasons, e.g., it is not clear if all post-verbal locative phrases should front.We further analyzed the DEV ALIGN+MI run todetermine both how often nodes were combined to-gether by our algorithm to produce N to 1 align-ments and the number of reorderings undertaken.
Itturns out that out of the 59,032 pairs of nodes werealigned for 3076 sentence pairs:6 55,391 alignments6When sentences were misparsed in one language or theother they were not reordered by the program.95were 1 to 1 (93.8% of the total) , 3443 alignmentswere 2 to 1 (5.8% of the total) and 203 alignmentswere N to 1, where N is greater than 2 (0.3% of thetotal).
The reordering program moved 1597 singletokens; 2140 blocks 2 or 3 tokens long; 1203 blocksof 4 or 5 tokens; 610 blocks of 6 or 7 tokens, 419blocks of 8, 9 or 10 tokens, and 383 blocks of morethan 10 tokens.7 Concluding RemarksWe have demonstrated that deep level linguisticanalysis can be used to improve word alignment re-sults.
It is natural to consider whether or not thesereorderings are likely to improve MT results.
Boththe manual and alignment-based systems movedpost-nominal English modifiers to pre-nominal po-sition, to reflect Chinese word order ?
other move-ments were much less frequent.
In principle, theseselective reorderings may help SMT systems iden-tify phrases of English that correspond to phrases ofChinese, thus improving the quality of the phrase ta-bles, especially when large chunks are moved.
Wewould also expect that the precision of our system tobe more important than the recall, since our systemwould not yield an improvement if it produced toomuch noise.
Further experiments with current MTsystems are needed to assess whether this is actuallythe case.
We are considering such tests for future re-search, using the Moses SMT system (Koehn et al,2007).Our representation had several possible advan-tages over pure parse-based methods.
We used se-mantic features such as temporal, locative and trans-parent (whether a low-content words inherits its se-mantics) to help guide our alignment.
The regu-larized structure, also, helped identify long-distancedependency relationships.
We are also consider-ing several improvements for our alignment-basedrules: (1) using additional dictionary resources suchas CATVAR (Habash and Dorr, 2003), so that cross-part-of speech alignments can be more readily rec-ognized; (2) finding more optimal orderings forunaligned source language words.
For example,the alignment-based method reordered a bright stararising from China?s policy to a bright arising fromChina ?s policy star, separating bright from star,even though bright star function as a unit; (3) incor-porating and using multi-word bilingual dictionaryentries.
; (4) automatic methods for tuning parame-ters of our system that are currently hand-coded; (5)training MI on a much larger corpus; (6) investigat-ing possible ways to merge the manual-rules withthe alignment-based approach; and (7) performingsimilar experiments with English/Japanese bitexts.We would expect both parse-based approachesand our system to handle mismatches that coverlarge distances better than more shallow approachesto reordering, e.g., (Crego and Marin?o, 2006) in thesame way that a full-parse handles constituent struc-ture more completely than a chunker.
In addition,we would expect our approach to work best in lan-guages where there are large differences in word or-der, as these are exactly the cases that all predicate-argument structure is designed to handle well (theyreduce apparent variation in structure).
Towards thisend we are currently working on a Japanese/Englishsystem.
Obviously, the cost of developing GLARF(or similar) systems are high, require linguistic ex-pertise and may not be possible for resource-poorlanguages.
Nevertheless, we maintain that such sys-tems are useful for many purposes and are there-fore worth the cost.
The GLARF system for En-glish is available for download at http://nlp.cs.nyu.edu/meyers/GLARF.html.AcknowledgmentsThis work was supported by NSF Grant IIS-0534700 Structure Alignment-based MT.ReferencesJ.
Bresnan and R. M. Kaplan.
1982.
Syntactic Represen-tation: Lexical-Functional Grammar: A Formal The-ory for Grammatical Representation.
In J. Bresnan,editor, The Mental Representation of Grammatical Re-lations.
The MIT Press, Cambridge.A.
Bryl and J. van Genabith.
2010. f-align: An Open-Source Alignment Tool for LFG f-Structures.
In Pro-ceedings of AMTA 2010.E.
Charniak.
2001.
Immediate-head parsing for languagemodels.
In ACL 2001, pages 116?123.N.
Chomsky.
1957.
Syntactic Structures.
Mouton, TheHague.M.
Collins, P. Koehn, and I. Kucerova.
2005.
ClauseRestructuring for Statistical Machine Translation.
InACL 2005.96B.
A. Cowan.
2008.
A Tree-to-Tree Model for StatisticalMachine Translation.
Ph.D. thesis, MIT.J.
M. Crego and J.
B. Marin?o.
2006.
Integration of POS-tag-based source reordering into SMT decoding by anextended search graph.
In AMTA?06.C.
Fellbaum, editor.
1998.
WordNet: An Electronic Lex-ical Database.
The MIT Press, Cambridge.A.
Fraser and D. Marcu.
2007.
Measuring WordAlignment Quality for Statistical Machine Translation.Computational Linguistics, 33:293?303.D.
Gildea and D. Jurafsky.
2002.
Automatic Labeling ofSemantic Roles.
Computational Linguistics, 28:245?288.R.
Grishman.
2000.
Entity Annotation Guidelines.ftp://jaguar.ncsl.nist.gov/ace/phase1/edt phase1 v2.2.pdf.N.
Habash and B. Dorr.
2003.
CatVar: A Database ofCategorial Variations for English.
In Proceedings ofthe MT Summit, pages 471?474, New Orleans.Z.
Harris.
1968.
Mathematical Structures of Language.Wiley-Interscience, New York.J.
R. Hobbs and R. Grishman.
1976.
The AutomaticTransformational Analysis of English Sentences: AnImplementation.
International Journal of ComputerMathematics, 5:267?283.H.
Ji and R. Grishman.
2006.
Analysis and Repair ofName Tagger Errors.
In COLING/ACL 2006, Sydney,Australia.H.
Ji, R. Grishman, D. Freitag, M. Blume, J. Wang,S.
Khadivi, R. Zens, and H. Ney.
2009.
Name Transla-tion for Distillation.
In Global Autonomous LanguageExploitation.
Springer.P.
Koehn, H. Hoang, A. Birch, C. Callison-Burch,M.
Federico, N. Bertoldi, B. Cowan, W. Shen,C.
Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,and E. Herbst.
2007.
Moses: Open Source Toolkit forStatistical Machine Translation.
In ACL 2007 Demon-stration Session, Prague.P.
Laplace.
1816.
Essai philosophique sur les probabil-its.
Courcier Imprimeur, Paris.Adam Meyers, Roman Yangarber, and Ralph Grishman.1996.
Alignment of Shared Forests for Bilingual Cor-pora.
In Proceedings of Coling 1996: The 16th In-ternational Conference on Computational Linguistics,pages 460?465.Adam Meyers, Roman Yangarber, Ralph Grishman,Catherine Macleod, and Antonio Moreno-Sandoval.1998.
Deriving Transfer Rules from Dominance-Preserving Alignments.
In Proceedings of Coling-ACL98: The 17th International Conference on Com-putational Linguistics and the 36th Meeting of the As-sociation for Computational Linguistics.A.
Meyers, R. Reeves, C. Macleod, R. Szekely, V. Zielin-ska, B.
Young, and R. Grishman.
2004.
AnnotatingNoun Argument Structure for NomBank.
In Proceed-ings of LREC-2004, Lisbon, Portugal.A.
Meyers, M. Kosaka, N. Xue, H. Ji, A.
Sun, S. Liao,and W. Xu.
2009.
Automatic Recognition of Logi-cal Relations for English, Chinese and Japanese in theGLARF Framework.
In SEW-2009 at NAACL-HLT-2009.E.
Miltsakaki, A. Joshi, R. Prasad, and B. Webber.
2004.Annotating discourse connectives and their arguments.In A. Meyers, editor, NAACL/HLT 2004 Workshop:Frontiers in Corpus Annotation, pages 9?16, Boston,Massachusetts, USA, May 2 - May 7.
Association forComputational Linguistics.F.
J. Och and H. Ney.
2000.
Improved Statistical Align-ment Models.
In ACL 2000.F.
J. Och and H. Ney.
2003.
A systematic comparison ofvarious statistical alignment models.
ComputationalLinguistics, 29(1):19?51.M.
Palmer, D. Gildea, and P. Kingsbury.
2005.
TheProposition Bank: An annotated corpus of semanticroles.
Computational Linguistics, 31(1):71?106.S.
Petrov and D. Klein.
2007.
Improved Inference forUnlexicalized Parsing.
In HLT-NAACL 2007.L.
Shen, J. Xu, and R. Weischedel.
2008.
A New String-to-Dependency Machine Translation Algorithm with aTarget Dependency Language Model.
In ACL 2008.J.
Wagner, D. Seddah, J.
Foster, and J. van Genabith.2007.
C-Structures and F-Structures for the BritishNational Corpus.
In Proceedings of the Twelfth In-ternational Lexical Functional Grammar Conference,Stanford.
CSLI Publications.C.
Wang, M. Collins, and P. Koehn.
2007.
Chinese syn-tactic reordering for statistical machine translation.
InEMNLP-CoNLL 2007, pages 737?745.D.
Wu and P. Fung.
2009.
Semantic roles for smt: Ahybrid two-pass model.
In HLT-NAACL-2009, pages13?16, Boulder, Colorado, June.
Association for Com-putational Linguistics.N.
Xue and M. Palmer.
2003.
Annotating the Proposi-tions in the Penn Chinese Treebank.
In The Proceed-ings of the 2nd SIGHAN Workshop on Chinese Lan-guage Processing, Sapporo.N.
Xue.
2008.
Labeling Chinese Predicates with Seman-tic roles.
Computational Linguistics, 34:225?255.K.
Yamada and K. Knight.
2001.
A syntax-based statis-tical translation model.
In ACL, pages 523?530.Y.
Zhang, R. Zens, and H. Ney.
2007.
Chunk-LevelReordering of Source Language Sentences with Auto-matically Learned Rules for Statistical Machine Trans-lation.
In Proc.
of NAACL/HLT 2007.M.
Zhang, H. Jiang, A. Aw, H. Li, C. L. Tan, and S. Li.2008.
A Tree Sequence Alignment-based Tree-to-TreeTranslation Model.
In ACL 2008.97
