Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 381?390,Singapore, 6-7 August 2009.c?2009 ACL and AFNLPImproved Statistical Machine TranslationUsing Monolingually-Derived ParaphrasesYuval Marton,?Chris Callison-Burch,?and Philip Resnik?
?Department of Linguistics and the CLIP Labat the Institute for Advanced Computer Studies (UMIACS)University of Maryland College Park, MD 20742-7505, USA{ymarton,resnik}@umiacs.umd.edu?Computer Science Department, Johns Hopkins University3400 N. Charles Street (CSEB 226-B) Baltimore, MD 21218ccb@cs.jhu.eduAbstractUntranslated words still constitute a ma-jor problem for Statistical Machine Trans-lation (SMT), and current SMT systemsare limited by the quantity of paralleltraining texts.
Augmenting the trainingdata with paraphrases generated by pivot-ing through other languages alleviates thisproblem, especially for the so-called ?lowdensity?
languages.
But pivoting requiresadditional parallel texts.
We address thisproblem by deriving paraphrases monolin-gually, using distributional semantic simi-larity measures, thus providing access tolarger training resources, such as compa-rable and unrelated monolingual corpora.We present what is to our knowledge thefirst successful integration of a colloca-tional approach to untranslated words withan end-to-end, state of the art SMT sys-tem demonstrating significant translationimprovements in a low-resource setting.1 IntroductionPhrase-based systems, flat and hierarchical alike(Koehn et al, 2003; Koehn, 2004b; Koehn et al,2007; Chiang, 2005; Chiang, 2007), have achieveda much better translation coverage than word-based ones (Brown et al, 1993), but untranslatedwords remain a major problem in SMT.
For ex-ample, according to Callison-Burch et al (2006),a SMT system with a training corpus of 10,000words learned only 10% of the vocabulary; thesame system learned about 30% with a trainingcorpus of 100,000 words; and even with a largetraining corpus of nearly 10,000,000 words it onlyreached about 90% coverage of the source vocab-ulary.
Coverage of higher order n-gram levels iseven harder.
This problem plays a major part in re-ducing machine translation quality, as reflected byboth automatic measures such as BLEU (Papineniet al, 2002) and human judgment tests.
Improvingtranslation coverage accurately is therefore impor-tant for SMT systems.The first solution that might come to mind isto use larger parallel training corpora.
However,current state-of-the-art SMT systems cannot learnfrom non-aligned corpora, while sentence-alignedparallel corpora (bitexts) are a limited resource(See Section 2 for discussion of automatically-compiled bitexts).
Another direction might beto make use of non-parallel corpora for training.However, this requires developing techniques toextract alignments or translations from them, andin a sufficiently fast, memory-efficient, and scal-able manner.
One approach that can, in princi-ple, better exploit both alignments from bitextsand make use of non-parallel corpora is the dis-tributional collocational approach, e.g., as used byFung and Yee (1998) and Rapp (1999).
However,the systems described there are not easily scalable,and require pre-computation of a very large col-location counts matrix.
Related attempts proposegenerating bitexts from comparable and ?quasi-comparable?
bilingual texts by iteratively boot-strapping documents, sentences, and words (Fungand Cheung, 2004), or by using a maximumentropy classifier (Munteanu and Marcu, 2005).Alignment accuracy remains a challenge for them.Recent work has proposed augmenting thetraining data with paraphrases generated by pivot-ing through other languages (Callison-Burch et al,2006; Madnani et al, 2007).
This indeed allevi-ates the vocabulary coverage problem, especiallyfor the so-called ?low density?
languages.
How-ever, these approaches still require bitexts where381one side contains the original source language.The paradigm described in this paper involvesconstructing monolingual distributional profiles(DPs; a.k.a.
word association profiles, or co-occurrence vectors) of out-of-vocabulary wordsand phrases in the source language; then, gener-ating paraphrase candidates from phrases that co-occur in similar contexts, and assigning them sim-ilarity scores.
The highest ranking paraphrasesare used to augment the translation phrase table.The table augmentation idea is similar to Callison-Burch et al?s (Callison-Burch et al, 2006), butour proposed paradigm does not require using alimited resource such as parallel texts in orderto generate paraphrases.
Moreover, our proposedparadigm can, in principle, achieve large-scale ac-quisition of paraphrases with high semantic simi-larity.
However, using parallel training texts inpivoting techniques offers the potential advantageof implicit translational knowledge, in the formof sentence alignments, while our approach is un-guided in this respect.
Therefore, we conductedexperiments to find out how these relative advan-tages play out.
We present here, to our knowledgefor the first time, positive results of integrating dis-tributional monolingually-derived paraphrases inan end-to-end state-of-the-art SMT system.In the rest of this paper we discuss related workin Section 2, describe the distributional hypothesisand distributional profiles in Section 3, and presentthe monolingually-derived paraphrase generationsystem in Section 4.
We report our experimentsand results in Section 5, and conclude by dis-cussing the implications and future research direc-tions in Section 6.2 Related WorkThis is not the first to attempt to ameliorate theout-of-vocabulary (OOV) words problem in sta-tistical machine translation, and other natural lan-guage processing tasks.
This work is most closelyrelated to that of Callison-Burch et al (2006),who also translate source-side paraphrases of theOOV phrases.
There, paraphrases are generatedfrom bitexts of various language pairs, by ?pivot-ing?
: translating the OOV phrases to an additionallanguage (or languages) and back to the sourcelanguage.
The quality of these paraphrases is es-timated by marginalizing translation probabilitiesto and from the additional language side(s) e, asfollows: p(f2|f1) =?ep(e|f1)p(f2|e).
A ma-jor disadvantage of their approach is that it relieson the availability of parallel corpora in other lan-guages.
While this works for English and manyEuropean languages, it is far less likely to helpwhen translating from other source languages, forwhich bitexts are scarce or non-existent.
Also,the pivoting approach is inherently noisy (in boththe paraphrase candidates?
correct sense, and theirtranslational likelihood), and it is likely to farepoorly with out-of-domain translation.
One ad-vantage of the bitext-dependent pivoting approachis the use of the additional human knowledge thatis encapsulated in the parallel sentence alignment.However, we argue that the ability to use muchlarger resources for paraphrasing should trump thehuman knowledge advantage.More recently, Callison-Burch (2008) has im-proved performance of this pivoting technique byimposing syntactic constraints on the paraphrases.The limitation of such an approach is the relianceon a good parser (in addition to reliance on bi-texts), but a good parser is not available in alllanguages, especially not in resource-poor lan-guages.
Another approach using a pivoting tech-nique augments the human reference translationwith paraphrases, creating additional translation?references?
(Madnani et al, 2007).
Both ap-proaches have shown gains in BLEU score.Barzilay and McKeown (2001) extract para-phrases from a monolingual parallel corpus, con-taining multiple translations of the same source.In addition to the parallel corpus usage limitationsdescribed above, this technique is further limitedby the small size of such materials, which are evenscarcer than the resources in the pivoting case.Dolan et al (2004) explore generating para-phrases by edit-distance and headlines of time-and topic-clustered news articles; they do not ad-dress the OOV problem directly, as their focusis sentence-level paraphrases; although they usea standard SMT measure, alignment error rate(AER), they only report results of the alignmentquality, and not of an end-to-end SMT system.Much of the previous research largely focused onmorphological analysis in order to reduce typesparseness; Callison-Burch et al (2006) list someof the influential work in that direction.Work that relies on the distributional hypoth-esis using bilingual comparable corpora (with-out the need for bitexts), typically uses a seedlexicon for ?bridging?
source language phrases382with their target languages paraphrases (Fung andYee, 1998; Rapp, 1999; Diab and Finch, 2000).This approach is sometimes viewed as, or com-bined with, an information retrieval (IR) approach,and normalizes strength-of-association measures(see Section 3) with IR-related measures such asTF/IDF (Fung and Yee, 1998).
To date, reportedimplementations suffer from scalability issues, asthey pre-compute and hold in memory a huge col-location matrix; we know of no report of using thisapproach in an end-to-end SMT system.Another approach aiming to reduce OOV rateconcentrates on increasing parallel training setsize without using more dedicated human transla-tion (Resnik and Smith, 2003; Oard et al, 2003).3 Collocational ProfilesThe distributional hypothesis and distribu-tional profiles.
Natural language processing(NLP) applications that assume the distributionalhypothesis (Harris, 1940; Firth, 1957) typicallykeep track of word co-occurrences in distribu-tional profiles (a.k.a.
collocation vectors, or con-text vectors).
Each distributional profile DPu(for some word u) keeps counts of co-occurrenceof u with all words within a usually fixed dis-tance from each of its occurrences (a sliding win-dow) in some training corpus.
More advanced pro-files keep ?strength of association?
(SoA) infor-mation between u and each of the co-occurringwords, which is calculated from the counts of u,the counts of the other word, their co-occurrencecount, and the count of all words in the corpus(corpus size).
The information on the other wordswith respect to u is typically kept in a vector whosedimensions correspond to all words in the trainingcorpus.
This is described in Equation (1), whereV is the training corpus vocabulary:DPu= {< wi, SoA(u,wi) > |u,wi?
V }for all i s.t.
1 ?
i ?
|V |(1)Semantic similarity between words u and v canbe estimated by calculating the similarity (vectordistance) between their profiles.
Slightly more for-mally, the distributional hypothesis assumes thatif we had access to the hypothetical true (psycho-linguistic) semantic similarity function over wordpairs, semsim(u, v), then?u, v, w ?
V,[semsim(u, v) > semsim(u,w)] =?
[psim(DPu, DPv) > psim(DPu, DPw)],(2)where V is the language vocabulary, DPwordisthe distributional profile of word, and psim() isa 2-place vector similarity function (all furtherdescribed below).
Paraphrasing and other NLPapplications that are based on the distributionalhypothesis assume entailment in the reverse di-rection: the right-hand-side of Formula (2) (pro-file/vector similarity) entails the left-hand-side(semantic similarity).The sliding window and word association (SoA)measures.
Some researchers count positionalcollocations in a sliding window, i.e., the co-counts and SoA measures are calculated per rel-ative position (e.g., for some word/token u, po-sition 1 is the token immediately after u; posi-tion -2 is the token preceding the token that pre-cedes u) (Rapp, 1999); other researchers use non-positional (which we dub here flat) collocations,meaning, they count all token occurrences withinthe sliding window, regardless of their positionsin it relative to u (McDonald, 2000; Mohammadand Hirst, 2006).
We use here flat collocationsin a 6-token sliding window.
Beside simple co-occurrence counts within sliding windows, otherSoA measures include functions based on TF/IDF(Fung and Yee, 1998), mutual information (PMI)(Lin, 1998), conditional probabilities (Schuetzeand Pedersen, 1997), chi-square test, and the log-likelihood ratio (Dunning, 1993).Profile similarity measures.
A profile similar-ity function psim(DPu, DPv) is typically definedas a two-place function, taking vectors as argu-ments, each vector representing a distributionalprofile of some word u and v, respectively, andwhose cells contain the SoA of u (or v) with eachword (?collocate?)
in the known vocabulary.
Sim-ilarity can be (and have been) estimated in severalways, e.g., the cosine coefficient, the Jaccard co-efficient, the Dice coefficient, and the City-Blockmeasure.
The formula for the cosine function forsimilarity measure is given in Eq.
(3):383psim(DPu, DPv)= cos(DPu, DPv)=?wi?VSoA(u,wi)SoA(v, wi)??wi?VSoA(u,wi)2?
?wi?VSoA(v, wi)2(3)In principle, any SoA can be used with anyprofile similarity measure.
However, in practice,only some SoA/similarity measure combinationsdo well, and finding the best combination is stillmore art than science.
Some successful combina-tions are cosCP(Schuetze and Pedersen, 1997),LinPMI(Lin, 1998), CityLL(Rapp, 1999), andJensen?Shannon divergence of conditional prob-abilities (JSDCP).
We use here cosine of log-likelihood vectors (McDonald, 2000).Phrasal distributional profiles.
Word DPs canbe generalized to phrasal DPs, simply by count-ing words that co-occur within a sliding windowaround the target phrase?s occurrences (i.e., count-ing occurrences of words up to 6 words beforeor after the target phrase).
For example, whenbuilding a DP for the target phrase counting wordsin the previous sentence, then simply is in rela-tive position -2, and sliding is in relative posi-tion 5.
Searching for similar phrasal DPs posesan additional challenge over the word DP case(see Section 4), but there is no additional diffi-culty in building the phrasal profile itself as de-scribed above.
In preliminary experiments wefound no gain in using phrasal collocates (i.e.,count how many times a phrase of more than oneword co-occurs in a sliding window around the tar-get word/phrase).4 Searching and Scoring PhrasalParaphrasesThe system design is as follows: upon receiv-ing OOV phrase phr, build distributional profileDPphr.
Next, gather contexts: for each occur-rence of phr, keep surrounding (left and right)context L__R.
For each such context, gather para-phrase candidates X which occur between L andR in other locations in the training corpus, i.e.,all X such that LXR occur in the corpus.
Fi-nally, rank all candidates X , by building distribu-tional profile DPXand measuring profile similar-ity between DPXand DPphr, for each X .
Outputk-best candidates above a certain similarity scorethreshold.
The rest of this section describes thissystem in more detail.Build phrasal profile DPphr.
Build a profile ofall word collocates, as described in Section 3.
Usesliding window of size MaxPos = 6.
If phris very frequent (above some threshold of t oc-currences), uniformly sample only t occurrences,multiplying the gathered co-counts by factor ofcount(phr)/t.
We set t = 10000.Gather context.
The challenge in choosing therelevant context is this: if it is very short and/orvery frequent (e.g., ?the __ is?
), then it might notbe very informative, in the sense that many wordscan appear in that context (in this example, practi-cally any noun); however, if it is too long (too spe-cific), then it might not occur enough times else-where (or not at all) in the training corpus.
There-fore, to balance between these two extremes, weuse the following heuristics.
Start small: Startwith setting the left part of the context L to be asingle word/token to the left of phrase phr.
If itis stoplisted, append the next word to the left (nowhaving a bigram left context instead of a unigram),and repeat until the left context is not in the sto-plist.
Repeat similarly for R, the context to theright of phr.
Add the resulting L__R context toa context list.
We stoplist ?promiscuous?
words,i.e., those that have more than StoplistThresholdcollocates in the training corpus, using the aboveMaxPos parameter value.
We also stoplist bi-grams which occur more than t times and com-prise solely from stoplisted unigrams.Gather candidates.
For each gathered contextin the context list, gather all paraphrase candidatephrases X that connect left hand side context Lwith right hand side context R, i.e., gather all Xsuch that the sequence LXR occurs in the corpus.In practice, to keep search complexity low, limitX to be up to length MaxPhraseLen.
Also, tofurther speed up runtime, we uniformly sample thecontext occurrences.Rank candidates.
For each candidate X ,build distributional profile DPX, and evaluatepsim(DPphr, DPX).Output k-best candidates.
Output k-best para-phrase candidates for phrase phr, in descendingorder of similarity.
We set k = 20.
Filter out para-phrases with score less than minScore.3845 ExperimentWe examined the application of the system?s para-phrases to handling unknown phrases when trans-lating from English into Chinese (E2C) and fromSpanish into English (S2E).
For all baselines weused the phrase-based statistical machine transla-tion system Moses (Koehn et al, 2007), with thedefault model features, weighted in a log-linearframework (Och and Ney, 2002).
Feature weightswere set with minimum error rate training (Och,2003) on a development set using BLEU (Papineniet al, 2002) as the objective function.
Test re-sults were evaluated using BLEU and TER (Snoveret al, 2005).
The phrase translation probabili-ties were determined using maximum likelihoodestimation over phrases induced from word-levelalignments produced by performing Giza++ train-ing (Och and Ney, 2000) on both source and tar-get sides of the parallel training sets.
When thebaseline system encountered unknown words inthe test set, its behavior was simply to reproducethe foreign word in the translated output.The paraphrase-augmented systems were iden-tical to the corresponding baseline system, withthe exception of additional (paraphrase-based)translation rules, and additional feature(s).
Simi-larly to Callison-Burch et al (2006), we added thefollowing feature:h(e, f) =8>>><>>>:psim(DPf?, DPf) If phrase table entry (e, f)is generated from (e, f?
)using monolingually-derived paraphrases.1 Otherwise,(4)Note that it is possible to construct a new trans-lation rule from f to e via more than one pair ofsource-side phrase and its paraphrase; e.g., if f1is a paraphrase of f , and so is f2, and both f1, f2translate to the same e, then both lead to the con-struction of the new rule translating f to e, butwith potentially different feature scores.In order to eliminate this duplicity and lever-age over these alternate paths which can be usedto increase our confidence level in the new rule,we did the following: For each paraphrase fof some source-side phrases fi, with respec-tive similarity scores sim(fi, f), we calculatedan aggregate score asim with a ?quasi-online-updating?
method as follows: asimi= (1 ?asimi?1)sim(fi, f), where asim0= 0.
The ag-gregate score asim is updated in an ?online?
fash-ion with each pair fi, f as they are processed, butonly the final asimkscore is used, after all k pairshave been processed.
Simple arithmetics can showthat this method is insensitive to the order in whichthe paraphrases are processed.
We only augmentthe phrase table with a single rule from f to e,and in it are the feature values of the phrase fiforwhich the score sim(fi, f) was the highest.5.1 English-to-Chinese TranslationFor the English-Chinese (E2C) baseline system,we trained on the LCD Sinorama and FBIStests (LCD2005T10 and LCD2003E14), and seg-mented the Chinese side with the Stanford Seg-menter (Tseng et al, 2005).
After tokenizationand filtering, this bitext contained 231,586 lines(6.4M + 5.1M tokens).
We trained a trigram lan-guage model on the Chinese side.
We then split thebitext to 32 even slices, and constructed a reducedset of about 29,000 lines (sentences) by using onlyevery eighth slice.
The purpose of creating thissubset model was to simulate a resource-poor lan-guage.
See Table 1.Set # Tokens Source+TargetE2C 29K 0.8 + 0.6E2C Full 6.4 + 5.1bnc+apw 187S2E 10K 0.3 + 0.3S2E 20K 0.6 + 0.6S2E 80K 2.3 + 2.3wmt09 84wmt09+acquis 139wmt09+acquis+afp 402Table 1: Training set sizes (million tokens).For development, we used the Chinese-EnglishNIST MT 2005 evaluation set, taking one of theEnglish references as source, and the Chinesesource as a single reference translation.
We testedthe system using the English-Chinese NIST MTevaluation 2008 test set with its four referencetranslations.We augmented the E2C baseline models withparaphrases generated as described above, train-ing on the British National Corpus (BNC)v3 (Burnard, 2000) and the first 3 million linesof the English Gigaword v2 APW, totaling 187Mterms after tokenization, and number and punc-tuation removal.
We generated paraphrases forphrases up to six tokens in length, and used an ar-385bitrary similarity threshold of minScore = 0.3.We experimented with three variants: adding asingle additional feature for all paraphrases (1-6grams); using only paraphrases of unigrams(1grams); and adding two features, one only sen-sitive to unigrams, and the other only to the rest(1 + 2-6grams).
All features had the same de-sign as described in Section 5, each had an asso-ciated weight (as all other features), and all fea-ture weights in each system, including the base-line, were tuned using a separate minimum errorrate training for each system.Results are shown in Table 2.
For the E2C sys-tems, for which we had four reference translationsfor the test set, we used shortest reference length,and used the NIST-provided script to split the out-put words to Chinese characters before evaluation.Statistical significance for the BLEU results werecalculated using Koehn?s (Koehn, 2004) pair-wisebootstrapping test with 95% confidence interval.On the E2C 29,000-line subset, the augmentedsystem had a significant 1.7 BLEU points gain overits baseline.
On the full size model, results werenegative.
Note that our E2C full size baselineis reasonably strong: Its character-based BLEUscore is slightly higher than the JHU-UMD sys-tem that participated in the NIST 2008 MT evalua-tion (constrained training track), although we useda subset of that system?s training materials, anda smaller language model.
Results there rangedfrom 15.69 to 30.38 BLEU (ignoring a seemingoutlier of 3.93).5.2 Spanish-to-English TranslationIn order to to permit a more direct comparisonwith the pivoting technique, we also experimentedwith Spanish to English (S2E) translation, fol-lowing Callison-Burch et al (2006).
For base-line we used the Spanish and English sides ofthe Europarl multilingual parallel corpus (Koehn,2005), with the standard training, development,and test sets.
We created training subset modelsof 10,000, 20,000, and 80,000 aligned sentences,as described in Callison-Burch et al (2006).
Forbetter comparison with their pivoting system, weused the same 5-gram language model, develop-ment and test sets: For development, we used theEuroparl dev2006 Spanish and English sides, andfor testing we used the Europarl 2006 test set.We trained the Spanish paraphrase generationsystem on the Spanish corpora available fromdataset E2C model BLEU TER29k baseline 15.21 90.35429k 1grams 16.87*** 90.37029k 1-6grams 16.54*** 90.37629k 1 + 2-6grams 16.88*** 90.349Full baseline 22.17 90.398Full 1grams 21.64*** 90.459Full 1-6grams 21.75 90.421Full 1 + 2-6grams 21.39*** 90.433Table 2: E2C Results: character-based BLEU andTER scores.
All models have one additional fea-ture over baseline, except for the "1 + 2-6" mod-els that have one feature for unigrams and an-other feature for bigrams to 6-grams.
Paraphraseswith score < .3 were filtered out.
*** = sig-nificance test over baseline with p < 0.0001,using Koehn?s (2004) pair-wise bootstrap resam-pling test for BLEU with 95% confidence interval.Paraphrase ScoreSource: dealagreement 0.56accord 0.53talks 0.45contract 0.42peace deal 0.33merger 0.32agreement is 0.30Source: fallrise 0.87slip 0.82tumbled today 0.68fell today 0.67tumble 0.65fall tokyo ap stock prices fell 0.56are mixed 0.54Source: to provide any otherto give any 0.74to give further 0.70to provide any 0.68to give any other 0.62to provide further 0.61to provide other 0.53to reveal any 0.52to provide any further 0.48to disclose any 0.47to publicly discuss the 0.43Source: we have a situation thatuncontroversial question about our 0.66obviously with the developments this morning 0.65community staffing of community centres 0.64perhaps we are getting rather impatient 0.63er around the inner edge 0.60interested in going to the topics 0.60and that is the day that 0.60as a as a final point 0.59left which it may still have 0.56Table 3: English paraphrases from E2C 29K-bitext systems.386the EACL 2009 Fourth Workshop on StatisticalMachine Translation:1the Spanish side of theEuroparl-v4, news training 2008, and news com-mentary 2009.
We also re-trained adding the JRC-Acquis-v3 corpus2to the paraphrase training set,and then adding also the LDC Spanish Gigaword(LDC2006T12) and truncating the resulting cor-pus after the first 150M lines.
We lowercasedthese training sets, tokenized and removed punc-tuation marks and numbers, and this resulted intraining set sizes as detailed in Table 1.
We gen-erated paraphrases for phrases up to four tokensin length, and used two arbitrary similarity thresh-olds of minScore = 0.3 (as in the E2C experi-ments), and 0.6, for enforcing only higher preci-sion paraphrasing.We experimented with these variants: a singlefeature for all paraphrase (1-4grams); using onlyparaphrases of unigrams (1grams); and using twofeatures: one only sensitive to unigrams and bi-grams, and the other to the rest (1-2 + 3-4grams).Results are shown in Table 4.
We used BLEUover lowercased outputs to evaluate all S2E sys-tems, and Koehn?s significance test as above.On the S2E 10,000-line subset, both the 1gramsand 1-4grams models achieved significant gains of.4 BLEU points over the baseline.
We concludedfrom a manual evaluation of the 10,000-line mod-els that the two major weaknesses of the baselinesystem were (not surprisingly) number of untrans-lated (OOV) words / phrases, followed by numberof superfluous words / phrases.On the larger subset models, no system sig-nificantly outperformed the baseline.
Note thatour S2E baselines?
scores are higher than thoseof Callison-Burch et al (2006), since we evaluatelowercased outputs, instead of recased ones.6 Discussion and Future WorkWe have shown that monolingually-derived para-phrases, based on distributional semantic similar-ity measures over a source-language corpus, canimprove the performance of statistical machinetranslation (SMT) systems.
Our proposed methodhas the advantage of not relying on bitexts in orderto generate the paraphrases, and therefore givesaccess to large amounts of monolingual trainingdata, for which creating bitexts of equivalent sizeis generally unfeasible.
We haven?t trained our1http://www.statmt.org/wmt092http://wt.jrc.it/lt/Acquissystem on nearly as large a corpus as it can han-dle, and indeed we see this as a natural next step.Results support the assumption that a largermonolingual paraphrase training set yields bet-ter paraphrases: our S2E 1-4grams model per-formed significantly better than baseline when us-ing wmt09+aquis for paraphrasing, but when onlyusing wmt09, the model had a smaller advantagethat did not reach significance.
However, for theS2E 1grams model, there was a slight decrease inperformance when switching paraphrasing corpusfrom wmt09+aquis to wmt09+aquis+afp.
This ef-fect might be due to the genre or unbalanced con-tent of the additional corpus, or perhaps it is thecase that in this corpus size, paraphrases of higher-level ngrams benefitted from the additional textmuch more than paraphrases of unigrams did.
Thetwo rightmost columns in Table 5 show that al-though Spanish monolingual paraphrases for theunigram baile improve when using the larger cor-pus, (e.g., danza and un balie become the third andfourth top candidates, pushing much worse candi-dates far down the list), the two top paraphrasecandidates remained unchanged.
However, forthe 4gram a favor del informe, antonymous can-didates, which are bad and misleading for trans-lation, are pushed down from the top first andthird spots by synonymous, better candidates.
Ta-ble 3 contains additional examples of good andbad top paraphrase candidates, also in English.Paraphrases of phrases seem to be of lower qual-ity than those of unigrams, as can be seen at thebottom of the table.These results also show that our method is es-pecially useful in settings involving low-densitylanguages or special domains: The smaller sub-set models, emulating a resource-poor languagesituation, show higher gains than larger models(which are supersets of the smaller subset models),when augmented with paraphrases derived fromthe same paraphrase training set.
This was vali-dated in two very different language pairs: Englishto Chinese, and Spanish to English.
We believethat larger monolingual training sets for paraphras-ing can help languages with richer resources, andwe intend to explore this too.Although the gains in the Spanish-English sub-sets are somewhat smaller than the pivoting tech-nique reported in Callison-Burch et al (2006),e.g., .7 BLEU for the 10k subset, we take theseresults as a proof of concept that can yield better387bitext mono.corp.
features minScore BLEU TER10k (baseline) ?
?
23.78 62.38210k wmt09 1-4grams .6 23.8110k wmt09 1-2+3-4gr .6 23.92 62.20210k wmt09+aquis 1-4grams .6 24.13*** 61.73910k wmt09+aquis 1grams .6 24.11 61.97920k (baseline) ?
?
24.68 62.33320k wmt09+aquis 1-4grams .6 24.75 61.52880k (baseline) ?
?
27.89 57.97780k wmt09+aquis 1-4grams .6 27.82 57.90610k wmt09+aquis 1grams .3 24.11 61.97910k wmt09+aquis+afp 1grams .3 23.97 61.97420k wmt09+aquis+afp 1grams .3 24.77 61.27680k wmt09+aquis+afp 1grams .3 27.84*** 57.781Table 4: S2E Results: Lowercase BLEU and TER.
Paraphrases with score < minScore were filtered out.
*** = significance test over baseline with p < 0.0001, using Koehn?s (2004) pair-wise bootstrap test forBLEU with 95% confidence interval.pivot wmt09+acquis wmt09+acquis+afpSource: bailedanza el baile el bailebailar baile y baile ya de david palomar y la danzadans viejo como quien se acomoda una un baileempresa por juli?n estrada el tercero de teatrocoro al baile a la baloncesto el cineSource: a favor del informea favor de este informe en contra del informe favor del informefavor del informe a favor de este informe en contra del informeel informe en contra de este informe a favor de este informea favor a favor de la resoluci?n en contra de este informepor el informe a favor de esta resoluci?n en contra de la resoluci?nal informe a favor del informe del se?or a favor del informe del sr.su a favor del informe del sr. en contra del informe del sr.del informe en contra de la propuesta a favor del excelente informede este informe contra el informe a favor del informe deprezTable 5: Comparison of Spanish paraphrases: by pivoting, and by two monolingual corpora.
Orderedfrom best to worst score.system examplesource cuando escucho las distintas intervenciones , creo que quienes afirman que deber?amos analizarnuestras prioridades y limitar el n?mero de objetivos que queremos conseguir , est?n en lo cierto .reference when i listen to the various comments made , i find myself agreeing with those who recommendthat we take a look at our priorities and then limit the number of aims we want to achievebaseline escucho when the various speeches, i believe that those who afirman that we should ourenvironmental limitar priorities and the number of objectives we want to achieve, are in this way.pivoting (MW) when i can hear the various speeches , i believe that those people that we should look at ourpriorities and to limit the number of objectives we want to achieve , are in fact .wmt09+acquis escucho when the various speeches, i believe that those who claiming that we should environmental.1-4grams limitar our priorities and the number of objectives we want to achieve, are on the way.wmt09+acquis escucho when the various speeches, i believe that those who considered that we should our.1grams environmental priorities and reducing the number of objectives we want to achieve, are on the way.wmt09+acquis+afp escucho when the various speeches, i believe that those who say that we should our environmental.1grams priorities and reduce the number of objectives we want to achieve, are on the way.Table 6: S2E translation examples on 10k-bitext systems.
Some translation differences are in bold.388gains with larger monolingual training sets.
Pivot-ing techniques (translating back and forth) rely onlimited resources (bitexts), and are subject to shiftsin meaning due to their inherent double transla-tion step.
In contrast, large monolingual resourcesare relatively easy to collect, and our system in-volves only a single translation/paraphrasing stepper target phrase.
Table 5 also shows an exemplarcomparison with the pivoting paraphrases used inCallison-Burch et al (2006).
It seems that the piv-oting paraphrases might suffer more from havingfrequent function words as top candidates, whichmight be a by-product of their alignment ?promis-cuity?.
However, the top antonymous candidateproblem seems to mainly plague the monolin-gual distributional paraphrases (but improves withlarger corpora).
See also Table 6.The paraphrase quality remains an issue withthis method (as with all other paraphrasing meth-ods).
Some possible ways of improving it, be-sides using larger corpora, are: using syntactic in-formation (Callison-Burch, 2008), using semanticknowledge such as thesaurus or WordNet to per-form word sense disambiguation (WSD) (Resnik,1999; Mohammad and Hirst, 2006), improvingthe similarity measure, and refining the similaritythreshold.
We would like to explore ways of incor-porating syntactic knowledge that do not sacrificecoverage as much as in Callison-Burch (2008); in-corporating semantic knowledge to disambiguatephrasal senses; using context to help sense disam-biguation (Erk and Pad?, 2008); and optimizingthe similarity threshold for use in SMT, for exam-ple on a held-out dataset: too high a threshold re-duces coverage, while too low a threshold resultsin bad paraphrases and translation.The method presented here is quite general, andtherefore different similarity measures, includingother corpus-based ones, can be plugged in to gen-erate paraphrases.
We are looking into using DPswith word-sense disambiguation: Since it has beenshown that similarity is often judged by the se-mantic distance of the closest senses of the twotarget words (Mohammad and Hirst, 2006), andthat paraphrases generated this way are likely tobe of higher quality (Marton et al, 2009), henceit is also likely that the overall performance of anSMT system using them will also improve further.One potential advantage of using bitexts forparaphrase generation is the usage of implicit hu-man knowledge, i.e., sentence alignments.
Theconcern that not using this knowledge would turnout detrimental to the performance of SMT sys-tems augmented by paraphrases as described herewas largely put to rest, as our method improvedthe tested subset SMT systems?
quality.AcknowledgmentsMany thanks to Chris Dyer for his help withthe E2C set, and to Adam Lopez for his imple-mentation of pattern matching with Suffix Ar-ray.
This research was partially supported bythe GALE program of the Defense Advanced Re-search Projects Agency, Contract No.
HR0011-06-2-001 and NSF award 0838801, by the Euro-MatrixPlus project funded by the European Com-mission, and by the US National Science Foun-dation under grant IIS-0713448.
The views andfindings are the authors?
alone.ReferencesRegina Barzilay and Kathleen McKeown.
2001.
Ex-tracting paraphrases from a parallel corpus.
In Pro-ceedings of ACL-2001.P.F.
Brown, S.A.D.
Pietra, V.J.D.
Pietra, and R.L.
Mer-cer.
1993.
The mathematics of statistical machinetranslation.
Computational Linguistics, 19(2):263?313.Lou Burnard.
2000.
Reference Guide for the BritishNational Corpus.
Oxford University ComputingServices, Oxford, England, world edition edition.Chris Callison-Burch, Philipp Koehn, and Miles Os-borne.
2006.
Improved statistical machine trans-lation using paraphrases.
In Proceedings NAACL-2006.Chris Callison-Burch.
2008.
Syntactic constraints onparaphrases extracted from parallel corpora.
In Pro-ceedings of EMNLP 2008, Waikiki, Hawai?i.David Chiang.
2005.
A hierarchical phrase-basedmodel for statistical machine translation.
In Pro-ceedings of ACL-05, pages 263?270.David Chiang.
2007.
Hierarchical phrase-based trans-lation.
Computational Linguistics, 33(2):201?228.Mona Diab and Steve Finch.
2000.
A statistical word-level translation model for comparable corpora.
InProceedings of the Conference on Content-BasedMultimedia Information Access (RIAO).B.
Dolan, C. Quirk, and C. Brockett.
2004.
Unsu-pervised construction of large paraphrase corpora:exploiting massively parallel news sources.
In Pro-ceedings of the 20th International Conference onComputational Linguistics of the Association forComputational Linguistics, Geneva, Switzerland.T.
Dunning.
1993.
Accurate methods for the statisticsof surprise and coincidence.
Computational Lin-guistics, 19(1):61?74.389Katrin Erk and Sebastian Pad?.
2008.
A struc-tured vector space model for word meaning in con-text.
In Proceedings of the Conference on EmpiricalMethods in Natural Language Processing (EMNLP-2086), pages 897?906, Honolulu, HI.John R. Firth.
1957.
A synopsis of linguistic theory1930?U55.
Studies in Linguistic Analysis, (specialvolume of the Philological Society):1?32.
Distribu-tional Hypothesis.Pascale Fung and Percy Cheung.
2004.
Multi-level bootstrapping for extracting parallel sentencesfrom a quasi-comparable corpus.
In Proceedings ofthe 20th international conference on ComputationalLinguistics, page 1051, Geneva, Switzerland.
Asso-ciation for Computational Linguistics.Pascale Fung and Lo Yuen Yee.
1998.
An ir approachfor translating new words from nonparallel, com-parable texts.
In Proceedings of COLING-ACL98,pages 414?420, Montreal, Canada.Zellig S. Harris.
1940. Review of louis h. gray, foun-dations of language (new york: Macmillan, 1939).Language, 16(3):216?U231.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Pro-ceedings of HLT-NAACL, pages 127?133.Philipp Koehn, Hieu Hoang, Alexandra Birch,Chris Callison-Burch, Marcello Federico, NicolaBertoldi, Brooke Cowan, Wade Shen, ChristineMoran Richard Zens, Chris Dyer, Ondrej Bojar,Alexandra Constantin, and Evan Herbst.
2007.Moses: Open source toolkit for statistical machinetranslation.
In Annual Meeting of the Associationfor Computational Linguistics (ACL), demonstrationsession, Prague, Czech Republic.Philipp Koehn.
2004.
Statistical significance tests formachine translation evaluation.
In Proc.
EMNLP.Philipp Koehn.
2004b.
Pharaoh: A beam search de-coder for phrase-based statistical machine transla-tion models.
In Proceedings of AMTA.Philipp Koehn.
2005.
A parallel corpus for statisticalmachine translation.
In Proceedings of MT-Summit.Dekang Lin.
1998.
An information-theoretic defini-tion of similarity.
In Proceedings of the 15th In-ternational Conference on Machine Learning, pages296?304, San Francisco, CA.Nitin Madnani, Necip Fazil Ayan, Philip Resnik, andBonnie Dorr.
2007.
Using paraphrases for parame-ter tuning in statistical machine translation.
In Pro-ceedings of the ACL Workshop on Statistical Ma-chine Translation.Yuval Marton, Saif Mohammad, and Philip Resnik.2009.
Estimating semantic distance using soft se-mantic constraints in knowledge-source / corpus hy-brid models.
In Procedings of EMNLP, Singapore.S.
McDonald.
2000.
Environmental determinants oflexical processing effort.
Ph.D. thesis, University ofEdinburgh.Saif Mohammad and Graeme Hirst.
2006.
Distribu-tional measures of concept-distance: A task-orientedevaluation.
In Proceedings of the Conference onEmpirical Methods in Natural Language Processing(EMNLP-2006), Sydney, Australia.Dragos Stefan Munteanu and Daniel Marcu.
2005.
Im-proving machine translation performance by exploit-ing non-parallel corpora.
Computational Linguis-tics, 31(4):477?504.Doug Oard, David Doermann, Bonnie Dorr, DaqingHe, Phillip Resnik, William Byrne, Sanjeeve Khu-danpur, David Yarowsky, Anton Leuski, PhilippKoehn, and Kevin Knight.
2003.
Desperately seek-ing cebuano.
In Proceedings of HLT-NAACL.Franz Josef Och and Hermann Ney.
2000.
Improvedstatistical alignment models.
In Proceedings of the38th Annual Meeting of the ACL, pages 440?447.Franz Josef Och and Hermann Ney.
2002.
Discrimina-tive training and maximum entropy models for sta-tistical machine translation.
In Proceedings of ACL.Franz Josef Och.
2003.
Minimum error rate trainingin statistical machine translation.
In Proceedings ofthe 41st Annual Meeting of the ACL, pages 160?167.Kishore Papineni, Salim Roukos, Todd Ward, JohnHenderson, and Florence Reeder.
2002.
Corpus-based comprehensive and diagnostic MT evaluation:Initial Arabic, Chinese, French, and Spanish results.In Proceedings of the ACL Human Language Tech-nology Conference, pages 124?127, San Diego, CA.Reinhard Rapp.
1999.
Automatic identification ofword translations from unrelated english and germancorpora.
In Proceedings of the 37th Annual Confer-ence of the Association for Computational Linguis-tics., pages 519?525.Philip Resnik and Noah Smith.
2003.
The webas a parallel corpus.
Computational Linguistics,29(3):349?380.Philip Resnik.
1999.
Semantic similarity in a taxon-omy: An information-based measure and its appli-cation to problems of ambiguity in natural language.Journal of Artificial Intelligence Research (JAIR),11:95?130.Hinrich Schuetze and Jan O. Pedersen.
1997.
Acooccurrence-based thesaurus and two applicationsto information retreival.
Information Processingand Management, 33(3):307?U318.Matthew Snover, Bonnie J. Dorr, Richard Schwartz,John Makhoul, Linnea Micciulla, and RalphWeischedel.
2005.
A study of translation error ratewith targeted human annotation.
Technical ReportLAMP-TR-126, CS-TR-4755, UMIACS-TR-2005-58, University of Maryland, July, 2005.Huihsin Tseng, Pichuan Chang, Galen Andrew, DanielJurafsky, and Christopher Manning.
2005.
A con-ditional random field word segmenter.
In FourthSIGHAN Workshop on Chinese Language Process-ing.390
