Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 924?934,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsJapanese Zero Reference ResolutionConsidering Exophora and Author/Reader MentionsMasatsugu Hangyo Daisuke Kawahara Sadao KurohashiGraduate School of Informatics, Kyoto UniversityYoshida-honmachi, Sakyo-kuKyoto, 606-8501, Japan{hangyo,dk,kuro}@nlp.ist.i.kyoto-u.ac.jpAbstractIn Japanese, zero references often occur andmany of them are categorized into zero ex-ophora, in which a referent is not mentioned inthe document.
However, previous studies havefocused on only zero endophora, in whicha referent explicitly appears.
We present azero reference resolution model consideringzero exophora and author/reader of a docu-ment.
To deal with zero exophora, our modeladds pseudo entities corresponding to zeroexophora to candidate referents of zero pro-nouns.
In addition, we automatically detectmentions that refer to the author and reader ofa document by using lexico-syntactic patterns.We represent their particular behavior in a dis-course as a feature vector of a machine learn-ing model.
The experimental results demon-strate the effectiveness of our model for notonly zero exophora but also zero endophora.1 IntroductionZero reference resolution is the task of detecting andidentifying omitted arguments of a predicate.
Sincethe arguments are often omitted in Japanese, zeroreference resolution is essential in a wide range ofJapanese natural language processing (NLP) appli-cations such as information retrieval and machinetranslation.
(1) ????pasta-NOM???like??everyday(??)(?-NOM)(??)(?-ACC)????
?eat(Liking pasta, (?)
eats (?)
every day)For example, in example (1) , the accusative argu-ment of the predicate ??????
(eat) is omitted .1The omitted argument is called a zero pronoun.
Inthis example, the zero pronoun refers to ?????
(pasta).Zero reference resolution is divided into two sub-tasks: zero pronoun detection and referent identifi-cation.
Zero pronoun detection is the task that de-tects omitted zero pronouns from a document.
Inexample (1), this task detects that there are the zeropronouns in the accusative and nominative cases of??????
(eat) and there is no zero pronoun inthe dative case of ??????.
Referent identifica-tion is the task that identifies the referent of a zeropronoun.
In example (1), this task identifies that thereferent of the zero pronoun in the accusative case of??????
is ?????
(pasta).
These two subtasksare often resolved simultaneously and our proposedmodel is a unified model.Many previous studies (Imamura et al 2009;Sasano et al 2008; Sasano and Kurohashi, 2011)have treated only zero endophora, which is a phe-nomenon that a referent is mentioned in a document,such as ?????
(pasta) in example (1).
However,zero exophora, which is a phenomenon that a ref-erent does not appear in a document, often occurs inJapanese when a referent is an author or reader of adocument or an indefinite pronoun.
For example, inexample (1), the referent of the zero pronoun of thenominative case of ??????
(eat) is the author of1In this paper, we use the following abbreviations: NOM(nominative), ABL(ablative), ACC (accusative), DAT (dative),ALL (allative), GEN (genitive), CMI (comitative), CNJ (con-junction), INS(instrumental) and TOP (topic marker).924Zero pronoun Referent Examplein the documentZero endophora Exist Exist ???????????
(????)??????
(I like cafes and go (to a cafe) everyday.
)Zero exophora Exist Not exist???????
([reader]?)????????????
(I would like to explain the advantage (to [reader]).
)No zero reference Not exist Not exist?????????????
(??)?????
(You can have a relaxing time.
)*There is no dative case.Table 1: Examples of zero endophora, zero exophora and no zero reference.the document, but the author is not mentioned ex-plicitly.
(2) ???recently?????PC-INS???movie-ACC([unspecified:person]?)([unspecified:person]-NOM)???
?can see(Recently, (people) can see movies by a PC.
)Similarly, in example (2), the referent of the zeropronoun of the nominative case of ?????
(cansee) is an unspecified person.2Most previous studies have neglected zero ex-ophora, as though a zero pronoun does not exist ina sentence.
However, such a rough approximationhas impeded the zero reference resolution research.In Table 1, in ?zero exophora,?
the dative case ofthe predicate has the zero pronoun, but in ?no zeroreference,?
the dative case of the predicate does nothave a zero pronoun.
Treating them with no dis-tinction causes a decrease in accuracy of machinelearning-based zero pronoun detection due to a gapbetween the valency of a predicate and observed ar-guments of the predicate.
In this work, to deal withzero exophora explicitly, we provide pseudo entitiessuch as [author], [reader] and [unspecified:person]as candidate referents of zero pronouns.In the referent identification, selectional prefer-ences of a predicate (Sasano et al 2008; Sasano andKurohashi, 2011) and contextual information (Iidaet al 2006) have been widely used.
The author andreader (A/R) of a document have not been used forcontextual clues because the A/R rarely appear inthe discourse in corpora based on newspaper arti-cles, which are main targets of the previous studies.However, in other domain documents such as blog2In the following examples, omitted arguments are put inparentheses and exophoric referents are put in square brackets.articles and shopping sites, the A/R often appear inthe discourse.
The A/R tend to be omitted and thereare many clues for the referent identification aboutthe A/R such as honorific expressions and modal-ity expressions.
Therefore, it is important to dealwith the A/R of a document explicitly for the refer-ent identification.The A/R appear as not only the exophora but alsothe endophora.
(3) ?
author ?I-TOP???Kyoto-DAT(??)(I-NOM)???
?will go??????
?have thought(I have thought (I) will go to Kyoto.)???
reader ?you all-TOP???where-DAT????
?want to go(????
)(you all-NOM)(??)(I-DAT)???????
?let me know(Please let (me) know where do you want to go.
)In example (3), ???
(I), which is explicitly men-tioned in the document, is the author of the docu-ment and ?????
(you all) is the reader.
In this pa-per, we call these expressions, which refer to the au-thor and reader, author mention and reader men-tion.
We treat them explicitly to improve the per-formance of zero reference resolution.
Since theA/R are mentioned as various expressions besidespersonal pronouns in Japanese, it is difficult to de-tect the A/R mentions based merely on lexical in-formation.
In this work, we automatically detectthe A/R mentions by using a learning-to-rank al-gorithm(Herbrich et al 1998; Joachims, 2002) thatuses lexico-syntactic patterns as features.Once the A/R mentions can be detected, their in-formation is useful for the referent identification.925The A/R mentions have both a property of the dis-course element mentioned in a document and a prop-erty of the zero exophoric A/R.
In the first sentenceof example (3), it can be estimated that the referentof the zero pronoun of the nominative case of ?????
(will go) from a contextual clue that ???
(I) isthe topic of this sentence and a syntactic clues that ???
(I) depends on ????????
(have thought)over the predicate ?????
(will go).3 Such con-textual clues can be available only for the discourseentities that are mentioned explicitly.
On the otherhand, in the second sentence, since ?????????
(let me know) is a request form, it can be as-sumed that the referent of the zero pronoun of thenominative case is ???
(I), which is the author,and the one of the dative case is ????
(you all),which is the reader.
The clues such as request forms,honorific expressions and modality expressions areavailable for the author and reader.
In this work, torepresent such aspect of the A/R mentions, both theendophora and exophora features are given to them.In this paper, we propose a zero reference reso-lution model considering the zero exophora and theauthor/reader mentions, which resolves the zero ref-erence as a part of a predicate-argument structureanalysis.2 Related WorkSeveral approaches to Japanese zero reference reso-lution have been proposed.Iida et al(2006) proposed a zero reference resolu-tion model that uses the syntactic relations betweena zero pronoun and a candidate referent as a feature.They deal with zero exophora by judging that a zeropronoun does not have anaphoricity.
However, theinformation of zero pronoun existences is given andthus they did not address zero pronoun detection.Zero reference resolution has been tackled as apart of predicate-argument structure analysis.
Ima-mura et al(2009) proposed a predicate-argumentstructure analysis model based on a log-linear modelthat simultaneously conducts zero endophora resolu-tion.
They assumed a particular candidate referent,NULL, and when the analyzer selected this refer-ent, the analyzer outputs ?zero exophora or no zero3Since ???
(I) depends on ????????
(have thought),the relation between ???
(I) and ?????
(will go) is the zeroreference.pronoun,?
in which they are treated without distinc-tion.
Sasano et al(2008) proposed a probabilis-tic predicate-argument structure analysis model in-cluding zero endophora resolution by using wide-coverage case frames constructed from a web cor-pus.
Sasano and Kurohashi (2011) extended theSasano et al(2008)?s model by focusing on zero en-dophora.
Their model is based on a log-linear modelthat uses case frame information and the location ofa candidate referent as features.
In their work, zeroexophora is not treated and they assumed that a zeropronoun is absent when there is no referent in a doc-ument.For languages other than Japanese, zero pronounresolution methods have been proposed for Chinese,Portuguese, Spanish and other languages.
In Chi-nese, Kong and Zhou (2010) proposed tree-kernelbased models for three subtasks: zero pronoun de-tection, anaphoricity decision and referent selection.In Portuguese and Spanish, only a subject word isomitted and zero pronoun resolution has been tack-led as a part of coreference resolution.
Poesio etal.
(2010) and Rello et al(2012) detected omittedsubjects and made a decision whether the omittedsubject has anaphoricity or not as preprocessing ofcoreference resolution systems.3 Baseline ModelIn this section, we describe a baseline zero refer-ence resolution system.
In our model, the zero refer-ence resolution is conducted as a part of predicate-argument structure (PAS) analysis.
The PAS con-sists of a case frame and an alignment between caseslots and referents.
The case frames are constructedfor each meaning of a predicate.
Each case framedescribes surface cases that each predicate has (caseslot) and words that can fill each case slot (exam-ple).
In this study, the case frames are constructedfrom 6.9 billion Web sentences by using Kawaharaand Kurohashi (2006a)?s method.The baseline model does not treat zero exophoraas the previous studies.
The baseline model analyzesa document in the following procedure in the sameway as the previous study (Sasano and Kurohashi,2011).44For learning, the previous study used a log-linear model,but we use a learning-to-rank model.
In our preliminary exper-926 ???
?Kyoto station-DAT??stand????
?curry shop-NOM????like???
?the shop??often????
?go(I like a curry shop in Kyoto station and often go to the shop.)???Today-TOP???
?you all-DAT(?????
)(curry shop-ACC)?????
?will introduce(Today, I will introduce (the shop) to you.
)Discourse entities {???
(Kyoto station)}, {????
(curry shop),???
(the shop)}, {??
(today)},{???
(you all)} Candidate predicate-argument structures of ???????
in the baseline model [1-1] case frame:[????
(1)], { NOM:Null, ACC:Null, DAT:??
?, TIME:??
}[1-2] case frame:[????
(1)], { NOM:Null, ACC:???
?, DAT:??
?, TIME:??
}[1-3] case frame:[????
(1)], { NOM:??
?, ACC:???
?, DAT:??
?, TIME:??
}...[2-1] case frame:[????
(2)], { NOM:Null, ACC:Null, DAT:??
?, TIME:??
}[2-2] case frame:[????
(2)], { NOM:Null, ACC:???
?, DAT:??
?, TIME:??
}...  Figure 1: Examples of discourse entities and predicate-argument structures1.
Parse the input document and recognize namedentities.2.
Resolve coreferential relations and set dis-course entities.3.
Analyze the predicate-argument structure foreach predicate using the following steps:(a) Generate candidate predicate-argumentstructures.
(b) Calculate the score of each predicate-argument structure and select the one withthe highest score.We illustrate the details of the above procedure.First, we describe how to set the discourse entitiesin step 2.
In our model, we treat referents of a zeropronoun using a unit called discourse entity, whichis what mentions in a coreference chain are boundinto.
In Figure 1, we treat ??????
(curry shop)and ?????
(the shop), which are in a coreferencechain, as one discourse entity.
In Figure 1, the dis-course entity {???
?, ??? }
is selected forthe referent of the accusative case of the predicate ???????
(will introduce).Next, we illustrate the PAS analysis in step 3.
Instep 3a, possible combinations of the case frame(cf ) and the alignment (a) between case slots andiment of the baseline model, there is little difference betweenthe results of these methods.discourse entities are listed.
First, one case frame isselected from case frames for the predicate.
Next,overt arguments, which have dependency relationswith the predicate, are aligned to a case slot of thecase frame.
Finally, each of zero pronouns of re-maining case slots is assigned to a discourse entityor is not assigned to any discourse entities.
The caseslot whose zero pronoun is not assigned to any dis-course entities corresponds to the case that does nothave a zero pronoun.
In Figure 1, we show the ex-amples of candidate PASs.
In these examples, [????
(1)] and [????
(2)] are case frames corre-sponding to each meaning of ??????.
Referentsof each case slot are actually selected from discourseentities but are explained as a representative wordfor illustration.
?Null?
indicates that a case slot isnot assigned to any discourse entities.
Since align-ments between case slots and discourse entities ofthe PAS [1-2] and [2-2] are the same but their caseframes are different, we deal with them as discretePASs.
In this case, however, the results of zero ref-erence resolution are the same.We represent each PAS as a feature vector, whichis described in section 3.1, and calculate a score ofeach PAS with the learned weights.
Finally, the sys-tem outputs the PAS with the highest score.927Type Value DescriptionLog Probabilities that {words, categories and named entity types} of e is assigned to c of cfLog Generative probabilities of {words, categories and named entity types} of eLog PMIs between {words, categories and named entity types} of e and c of cfCase Log Max of PMIs between {words, categories and named entity types} of e and c of cfframe Log Probability that c of cf is assigned to any wordsLog Ratio of examples of c to ones of cfBinary c of cf is {adjacent and obligate} casePredicateBinary Modality types of pBinary Honorific expressions of pBinary Tenses of pBinary p is potential formBinary Modifier of p (predicate, noun and end of sentence)Binary p is {dynamic and stative} verbContextBinary Named entity types of eInteger Number of mentions about e in tInteger Number of mentions about e {before and after} p in tBinary e is mentioned with post position ???
in a target sentenceBinary Sentence distances between e and pBinary Location categories of e (Sasano and Kurohashi, 2011)Binary e is mentioned at head of a target sentenceBinary e is mentioned with post position {???
and ??? }
at head of a target sentenceBinary e is mentioned at head of the first sentenceBinary e is mentioned with post position ???
at head of the first sentenceBinary e is mentioned at end of the first sentenceBinary e is mentioned with copula at end of the first sentenceBinary e is mentioned with noun phrase stop at end of the first sentenceBinary Salience score of e is larger than 1 (Sasano and Kurohashi, 2011)other Binary c is assignedTable 2: The features of ?assigned(cf, c?
e, p, t)3.1 Feature Representation ofPredicate-Argument StructureWhen text t and target predicate p are given and PAS(cf, a) is chosen, we represent a feature vector of thePAS as ?
(cf, a, p, t).
?
(cf, a, p, t) consists of a fea-ture vector ?overt-PAS(cf, a, p, t) and feature vec-tors ?
(cf, c/e, p, t).
Where ?overt-PAS(cf, a, p, t)corresponds to alignment between case slots andovert (not omitted) arguments and ?
(cf, c/e, p, t)represents that a case slot c is assigned to a discourseentity e. If a case slot is assigned to an overt entity,?
(cf, c/e, p, t) is set to a zero vector.Each feature vector ?
(cf, c/e, p, t) consistsof ?A(cf, c/e, p, t) and ?NA(cf, c/Null, p, t).
?A(cf, c/e, p, t) becomes active when the caseslot c is assigned to the discourse entity e and?NA(cf, c/Null, p, t) becomes active when thecase slot c is not assigned to any discourse entities.For example, the PAS [1-2] in Figure 1 is repre-sented as:(?overt-PAS(????
(1), {NOM:Null,ACC:Null,NOM:???,TIME:??
}),0?A ,?NA(????
(1),NOM/Null),?A(????
(1),ACC/????
),0?NA ,0?A ,0?NA).
5In our feature representation, the second and thirdterms correspond to the nominative case, the forthand fifth ones correspond to the accusative and thesixth and seventh ones correspond to the dativecase.We present the details of ?overt-PAS(cf, a, p, t),?A(cf, c/e, p, t) and ?NA(cf, c/Null, p, t).
We usea score of the probabilistic PAS analysis (Kawaharaand Kurohashi, 2006b) to ?overt-PAS(cf, a, p, t).We list the features of ?A(cf, c/e, p, t) in Table 2and the features of ?NA(cf, c/Null, p, t) in Table5In the following example, p and t are sometimes omittedand 0?is 0 vector that has the same dimension as ?.928Type Value DescriptionCase frameLog Probability that c of cf isnot assignedLog Ratio of number of examplesof c to ones of cfBinary c of cf is{adjacent and obligate} caseTable 3: The features of ?NA(cf, c/Null, p, t)3.3.2 Weight LearningIn the previous section, we defined the feature vec-tor ?
(cf, a, p, t), which represents a PAS.
In thissection, we illustrate the learning method of theweight vector corresponding to the feature vector.The weight vector is learned by using a learning-to-rank algorithm.In a corpus, gold-standard alignments a?
are man-ually annotated but case frames are not annotated.Since the case frames are constructed for each mean-ing, some of them are unsuitable for a usage of aprdicate in a context.
If training data includes PASs(cf, a?)
whose cf is such case a frame as correctinstances, these are harmful for training.
Hence,we treat a case frame cf?
which is selected by aheuristic method as a correct case frame and remove(cf, a?)
which has other cf .In particular, we make ranking data for the learn-ing for each target predicate p in the following steps.1.
List possible PASs (cf, a) for predicate p.2.
Calculate a probabilistic zero reference resolu-tion score for each (cf, a?)
and define the onewith highest score as (cf?, a?).3.
Remove (cf, a?)
except (cf?, a?)
from thelearning instance.4.
Make ranking data that (cf?, a?)
has a higherrank than other (cf, a).In the above steps, we make ranking data for eachpredicate and use the ranking data collected from alltarget predicates as training data.4 CorpusIn this work, we use Diverse Document Leads Cor-pus (DDLC) (Hangyo et al 2012) for experiments.In DDLC, documents collected from the web areannotated with morpheme, syntax, named entity,coreference, PAS and A/R mention.
Morpheme,syntax, named entity, coreference and PAS are an-notated on the basis of Kyoto University Text Cor-pus (Kawahara et al 2002).
The PAS annotation in-cludes zero reference information and the exophorareferents are defined as five elements, [author],[reader], [US(unspecified):person], [US:matter] and[US:situation].
The A/R mentions are annotatedto head phrases of compound nouns when the A/Rmentions consist of compound nouns.
If the A/Ris mentioned by multiple expressions, only one ofthem is annotated with the A/R mention tag and allof these mentions are linked by a coreference chain.In other words, the A/R mentions are annotated todiscourse entities.
In the web site of an organiza-tion such as a company, the site administrator oftenwrites the document on behalf of the organization.In such a case, the organization is annotated as theauthor.5 Author/Reader Mention DetectionA/R mentions, which refer to A/R of a document,have different properties from other discourse enti-ties.
The A/R are mentioned as very various expres-sions such as personal pronouns, proper expressionsand role expressions.
(4) ??????Hello?????
?project team-GEN??
author ??
?am Umetsuji(Hello, I?m Umetsuji on the project team.
)(5) ???problem-NOM???exist???
author ?
?to moderator????????
?let me know(Please let me know if there are any problems.
)In example (4), the author is mentioned as ????
(Umetsuji), which is the name of the author, and inexample (5), the author is mentioned as ?????
(moderator), which expresses the status of the au-thor.
Likewise, the reader is sometimes mentionedas ?????
(customer) and others.
However, sincesuch expressions often refer to someone other thanthe A/R, whether an expression indicates the A/R ofa document depends on the context of the document.In English and other languages, the A/R mentionscan be detected from coreference information be-cause it can be assumed that the expression that has929a coreference relation with first or second personalpronoun is the A/R mention.
However, since theA/R tend to be omitted and personal pronouns arerarely used in Japanese, it is difficult to detect theA/R mentions from coreference information.
Be-cause of these reasons, it is difficult to detect whichdiscourse entity is the A/R mention from lexical in-formation of the entities.
In this study, the A/R men-tions are detected from lexico-syntactic (LS) pat-terns in the document.
We use a learning-to-rankalgorithm to detect A/R mentions by using the LSpatterns as features.5.1 Author/Reader Detection ModelWe use a learning-to-rank method for detecting A/Rmentions.
This method learns the ranking that en-tities of the A/R mentions have a higher rank thanother discourse entities.
Here, it is an importantpoint that there are no A/R mentions in some doc-uments.
The documents in which the A/R mentionsdo not appear are classified into two types.
The firsttype is a document that the A/R do not appear inthe discourse of the document such as newspaper ar-ticles and novels.
The second type is a documentthat the A/R appear in the discourse but all of theirmentions are omitted.
For example, in Figure 1, theauthor appears in the discourse (e.g.
the nominativeargument of ?like?)
but is not mentioned explicitly.We introduce two pseudo entities corresponding tothese types.
The first pseudo entity ?no A/R men-tion (discourse)?
represents the document that theA/R do not appear in the discourse.
It is consideredthat the document that the A/R do not appear havecharacteristics of writing style such that honorificexpressions and request expressions are rarely used.This pseudo entity is represented as a document vec-tor that consists of LS pattern features of the wholedocument, which reflect a writing style of a doc-ument.
The second pseudo entity ?no A/R men-tion (omitted)?
represents the document in which allmentions of the A/R are omitted and this pseudo en-tity is represented as 0 vector.
Since a decision scoreof this pseudo entity is allways 0, discourse entitieswhose score is lower than the score of this pseudoentity can be treated as a negative example in a bi-nary classification.When there are A/R mentions in a document, wemake ranking data where the discourse entity ofthe A/R mention has a higher rank than other dis-course entities and ?no A/R mention?
pseudo enti-ties.
When the A/R do not appear in the discourse,we make ranking data where ?no A/R mention (dis-course)?
has a higher rank than all discourse enti-ties and ?no A/R mention (omitted)?.
When the A/Rappear in the discourse but all mentions are omit-ted, we make ranking data where ?no A/R mention(omitted)?
has a higher rank than all discourse en-tities and ?no A/R mention (discourse)?.
We judgethat the A/R appear in the discourse if the A/R ap-pear as a referent of zero reference in gold-standardPASs and this judgment is used only in the trainingphase.
After making the ranking data for each doc-ument, all of the ranking data are merged and themerged data is fed into the learning-to-rank model.For the A/R mention detection, we calculate thescore of all discourse entities and the pseudo entitiesand select the discourse entity with the highest scoreto the A/R mention.
If any ?no A/R mention?
havethe highest score, we decide that there are no A/Rmentions in the document.5.2 Lexico-Syntactic PatternsFor each discourse entity, phrases of the discourseentity, its parent and their dependency relations areused to make LS patterns that represent the discourseentity.
When a discourse entity is mentioned multi-ple times, the phrases of all mentions are used tomake the LS patterns.
LS patterns of phrases aremade by generalizing these phrases on various lev-els (types).
LS patterns of dependencies are madefrom combining the LS patterns of phrases.Table 4 lists generalization types.
On the wordtype, we make a phrase LS pattern by generalizingeach content word and jointing them.
For example, aLS pattern of the phrase ?????
generalized on the<representative form> is ????.
The word+ typeis the same as word except all content words are gen-eralized on the <part of speech and conjugation>.For example, a LS pattern of the dependency rela-tion ?????????
generalized on the <namedentity> is ?NE:PERSON+??
verb:past?.
We alsouse the LS patterns of generalized individual mor-phemes.
On the phrase type, each phrase is gener-alized according to the information assigned to thephrase and all content words are generalized on the<part of speech and conjugation> if the information930Unit Type Example (original phrase)word<no generalization> ??
(??
)<original form> ???
(??
)<representative form> ??
(???
)<part of speech and conjugation> verb:past (???
)word+<category> Category:PERSON+?
(??
)<named entity> NE:PERSON+?
(???
)<first person pronoun> FirstPersonPronoun+?
(??
)<second person pronoun> SecondPersonPronoun+?
(????
)phrase<modality> modality:request (??????????
)<honorific expression> honorific:modest (??????
)<attached words> ????
(??????????
)Table 4: Generalization types of the LS patternsis not assigned to the phrase.For ?no A/R mention (discourse)?
instance, theabove features of all mentions, including verbs andadjectives, and their dependencies in the documentare gathered and used as the features representingthe instance.6 Zero Reference Resolution ConsideringExophora and Author/Reader MentionsIn this section, we describe the zero reference reso-lution system that considers the zero exophora andthe A/R mentions.
The proposed model resolveszero reference as a part of the PAS analysis basedon the baseline model.The proposed model analyzes the PASs in the fol-lowing steps:1.
Parse the input document and recognize namedentities.2.
Resolve coreferential relations and set dis-course entities.3.
Detect the A/R mentions of the document.4.
Set pseudo entities from the estimated A/Rmentions.5.
Analyze the PAS for each predicate using thesame procedure as the baseline model.The differences form baseline model are the estima-tion of the A/R mentions in step 3 and the setting ofpseudo entities in step 4.6.1 Pseudo Entities and Author/ReaderMentions for Zero ExophoraIn the baseline model, referents of zero pronounsare selected form discourse entities.
The proposedmodel adds pseudo entities([author], [reader],[US:person] (unspecified:person) and [US:others](unspecified:others)6) to deal with zero exophora.When the A/R mentions appear in a document,the A/R pseudo entities raise an issue.
The zero en-dophora are given priority to zero exophora.
In otherwords, the A/R mentions are selected to the referentsin preference to pseudo entities when there are A/Rmentions.
Therefore, when the system estimates thatA/R mentions appear, the A/R pseudo entities arenot created.In the PAS analysis, referents are selected fromdiscourse entities and the pseudo entities.
A zeroreference is the zero exophora when a case slot isassigned to pseudo entities.
Candidate PASs of ???????
in Figure 1 are shown in Figure 2.6.2 Feature Representation of PredicateArgument StructureIn the same way as the baseline model, theproposed model represents a PAS as a fea-ture vector that consists of the feature vector?overt-PAS(cf, a, p, t) and the feature vectors?
(cf, c/e, p, t).
The difference from the baselinemodel is a composition of ?A(cf, c/e, p, t).
In theproposed model, each ?A(cf, c/e) is composed ofvectors, ?discourse(cf, c/e), ?
[author ](cf, c/e),?
[reader ](cf, c/e), ?
[US :person](cf, c/e),?
[US :others](cf, c/e) and ?max(cf, c/e).
Theircontents and dimensions are the same and similar to?A(cf, c/e) of the baseline model the except for the6We merge [US:matter] and [US:situation] because of thesmall amount of [US:situation] in the corpus.931 [1-1] case frame:[????
(1)], { NOM:[author], ACC:Null, DAT:???
reader, TIME:??
}[1-2] case frame:[????
(1)], { NOM:[US:person], ACC:Null, DAT:???
reader, TIME:??
}[1-3] case frame:[????
(1)], { NOM:[author], ACC:???
?, DAT:???
reader, TIME:??
}[1-4] case frame:[????
(1)], { NOM:??
?, ACC:???
?, DAT:???
reader, TIME:??
}[1-5] case frame:[????
(1)], { NOM:[author], ACC:[US:others], DAT:???
reader, TIME:??
}...[2-1] case frame:[????
(2)], { NOM:[author], ACC:Null, DAT:???
reader, TIME:??
}[2-2] case frame:[????
(2)], { NOM:[US:person], ACC:Null, DAT:???
reader, TIME:??
}... Figure 2: Candidate predicate-argument structures of ???????
in the proposed modelExpressions Categoriesauthor ?
(I),??
(we),?
(I),?
(I), PERSON, ORGANIZATION??
(our company),??
(our company),??
(our shop)reader ???
(you),?
(customer),?
(you),??
(you all), PERSON???
(you all),?
(person),??
(people)US:person ?
(person),??
(people) PERSONUS:others ??
(thing)???
(situation) all categories exceptPERSON and ORGANIZATIONTable 5: Expressions and categories for pseudo entitiesaddition of a few features described in section 6.3.?discourse corresponds to the discourse entities,which are mentioned explicitly and becomes activewhen e is a discourse entity including the A/R men-tions.
?discourse is the same as ?A of the base-line model and the difference is explained in section6.3.
?
[author ] and ?
[reader ] become active when e is[author]/[reader] or the discourse entity correspond-ing to the A/R mention.
In particular, when e isthe discourse entity corresponding to the A/R men-tion, both ?discourse and ?
[author ]/?
[reader ] becomeactive.
This representation gives the A/R mentionsthe properties of the discourse entity and the A/R.?
[US :person] and ?
[US :others] become active when eis [US:person] and [US:others].Because ?
[author ], ?
[reader ], ?
[US :person] and?
[US :others] correspond to the pseudo entities, whichare not mentioned explicitly, we cannot use word in-formation such as expressions and categories.
Weassume that the pseudo entities have expressions andcategories shown in Table 5 and use these to cal-culate case frame features.
Finally, ?max consistsof the highest value of correspondent feature of theabove feature vectors.6.3 Author/Reader Mention ScoreWe add A/R mention score features to the featurevector ?A(cf, c/e, p, t) described in Table 2.
TheA/R mention scores are the discriminant functionscores of the A/R mention detection.
When e is theA/R mention, we set the A/R mention score to thefeature.7 Experiments7.1 Experimental SettingsWe used 1,000 documents from DDLC and per-formed 5-fold cross-validation.
1,440 zero en-dophora and 1,935 zero exophora are annotated inthese documents.
258 documens are annotated withauthor mentions and 105 documens are annotatedwith reader mentions.
We used gold-standard (man-ually annotated) morphemes, named entities, depen-dency structures and coreference relations to focuson the A/R detection and the zero reference resolu-tion.
We used SV M rank7 for the learning-to-rankmethod of the A/R detection and the PAS analysis.The categories of words are given by the morpho-logical analyzer JUMAN8.
Named entities and pred-icate features (e.g., honorific expressions, modality)7http://www.cs.cornell.edu/people/tj/svm light/svm rank.html8http://nlp.ist.i.kyoto-u.ac.jp/EN/index.php?JUMAN932System outputExist NoneCorrect WrongGold Exist 140 6 112-standard None - 38 704Table 6: Result of the author mention detectionSystem outputExist NoneCorrect WrongGold Exist 56 2 47-standard None - 23 872Table 7: Result of the reader mention detectionare given by the syntactic parser KNP.97.2 Results of Author/Reader MentionDetectionWe show the results of the author and reader men-tion detection in Table 6 and Table 7.
In these tables,?exist?
indicates numbers of documents in which theA/R mentions are manually annotated or our systemestimated that some discourse entities are A/R men-tions.
From these results, the A/R mentions includ-ing ?none?
can be predicted to accuracies of approx-imately 80%.
On the other hand, the recalls are notparticularly high: the recall of author is 140/258 andthe recall of reader is 56/105.
This is because thedocuments in which the A/R do not appear are morethan the ones in which the A/R appear and the sys-tem prefers to output ?no author/reader mention?
asthe result of training.7.3 Results of Zero Reference ResolutionWe show the results of zero reference resolutionin Table 8 and Table 9.
The difference betweenthe baseline and the proposed model is statisticallysignificant (p < 0.05) from the McNemar?s test.In Table 8, we evaluate only the zero endophorafor comparison to the baseline model, which dealswith only the zero endophora.
?Proposed model(estimate)?
shows the result of the proposed modelwhich estimated the A/R mentions and ?Proposedmodel (gold-standard)?
shows the result of the pro-posed model which is given the A/R mentions ofgold-standard from the corpus.From Table 8, considering the zero exophora and9http://nlp.ist.i.kyoto-u.ac.jp/EN/index.php?KNPRecall Precision F1Baseline 0.269 0.377 0.314Proposed model 0.282 0.448 0.346(estimate)Proposed model 0.388 0.522 0.445(gold-standard)Table 8: Results of zero endophora resolutionRecall Precision F1Baseline 0.115 0.377 0.176Proposed model 0.317 0.411 0.358(estimate)Proposed model 0.377 0.485 0.424(gold-standard)Table 9: Results of zero reference resolutionthe A/R mentions improves accuracy of zero en-dophora resolution as well as zero reference reso-lution including zero exophora.From Table 8 and Table 9, the proposed modelgiven the gold-standard A/R mentions achieves ex-traordinarily high accuracies.
This result indicatesthat improvement of the A/R mention detection im-proves the accuracy of zero reference resolution inthe proposed model.8 ConclusionThis paper presented a zero reference resolutionmodel considering exophora and author/reader men-tions.
In the experiments, our proposed modelachieves higher accuracy than the baseline model.As future work, we plan to improve the au-thor/reader detection model to improve the zero ref-erence resolution.ReferencesMasatsugu Hangyo, Daisuke Kawahara, and Sadao Kuro-hashi.
2012.
Building a diverse document leadscorpus annotated with semantic relations.
In Pro-ceedings of the 26th Pacific Asia Conference on Lan-guage, Information, and Computation, pages 535?544, Bali,Indonesia, November.
Faculty of ComputerScience, Universitas Indonesia.Ralf Herbrich, Thore Graepel, Peter Bollmann-Sdorra,and Klaus Obermayer.
1998.
Learning preference re-lations for information retrieval.
In ICML-98 Work-shop: text categorization and machine learning, pages80?84.Ryu Iida, Kentaro Inui, and Yuji Matsumoto.
2006.
Ex-ploiting syntactic patterns as clues in zero-anaphora933resolution.
In Proceedings of the 21st InternationalConference on Computational Linguistics and 44thAnnual Meeting of the Association for ComputationalLinguistics, pages 625?632, Sydney, Australia, July.Association for Computational Linguistics.Kenji Imamura, Kuniko Saito, and Tomoko Izumi.
2009.Discriminative approach to predicate-argument struc-ture analysis with zero-anaphora resolution.
In Pro-ceedings of the ACL-IJCNLP 2009 Conference ShortPapers, pages 85?88, Suntec, Singapore, August.
As-sociation for Computational Linguistics.Thorsten Joachims.
2002.
Optimizing search enginesusing clickthrough data.
In Proceedings of the eighthACM SIGKDD international conference on Knowl-edge discovery and data mining, pages 133?142.ACM.Daisuke Kawahara and Sadao Kurohashi.
2006a.Case frame compilation from the web using high-performance computing.
In Proceedings of the 5thInternational Conference on Language Resources andEvaluation, pages 1344?1347.Daisuke Kawahara and Sadao Kurohashi.
2006b.
Afully-lexicalized probabilistic model for japanese syn-tactic and case structure analysis.
In Proceedings ofthe Human Language Technology Conference of theNAACL, Main Conference, pages 176?183, New YorkCity, USA, June.
Association for Computational Lin-guistics.Daisuke Kawahara, Sadao Kurohashi, and Koiti Hasida.2002.
Construction of a japanese relevance-taggedcorpus.
In Proc.
of The Third International Confer-ence on Language Resources Evaluation, May.Fang Kong and Guodong Zhou.
2010.
A tree kernel-based unified framework for chinese zero anaphoraresolution.
In Proceedings of the 2010 Conference onEmpirical Methods in Natural Language Processing,pages 882?891, Cambridge, MA, October.
Associa-tion for Computational Linguistics.Massimo Poesio, Olga Uryupina, and Yannick Versley.2010.
Creating a coreference resolution system foritalian.
In Nicoletta Calzolari (Conference Chair),Khalid Choukri, Bente Maegaard, Joseph Mariani,Jan Odijk, Stelios Piperidis, Mike Rosner, and DanielTapias, editors, Proceedings of the Seventh conferenceon International Language Resources and Evaluation(LREC?10), Valletta, Malta, may.
European LanguageResources Association (ELRA).Luz Rello, Ricardo Baeza-Yates, and Ruslan Mitkov.2012.
Elliphant: Improved automatic detection of zerosubjects and impersonal constructions in spanish.
InProceedings of the 13th Conference of the EuropeanChapter of the Association for Computational Linguis-tics, pages 706?715.
Association for ComputationalLinguistics.Ryohei Sasano and Sadao Kurohashi.
2011.
A dis-criminative approach to japanese zero anaphora res-olution with large-scale lexicalized case frames.
InProceedings of 5th International Joint Conference onNatural Language Processing, pages 758?766, ChiangMai, Thailand, November.
Asian Federation of Natu-ral Language Processing.Ryohei Sasano, Daisuke Kawahara, and Sadao Kuro-hashi.
2008.
A fully-lexicalized probabilistic modelfor japanese zero anaphora resolution.
In Proceed-ings of the 22nd International Conference on Com-putational Linguistics (Coling 2008), pages 769?776,Manchester, UK, August.
Coling 2008 OrganizingCommittee.934
