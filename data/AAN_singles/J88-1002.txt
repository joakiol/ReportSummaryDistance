A COMMON PARSING SCHEME FOR LEFT- ANDRIGHT=BRANCHING LANGUAGESPaul T. SatoDepartment of Computer  ScienceNorth Central CollegeNapervi l le, I l l inois 60566This paper presents some results of an attempt to develop a common parsing scheme that workssystematically and realistically for typologically varied natural languages.
The scheme is bottom-up, andthe parser scans the input text from left to right.
However, unlike the standard LR(k) parser or Tomita'sextended LR(1) parser, the one presented in this paper is not a pushdown automaton based onshift-reduce transition that uses a parsing table.
Instead, it uses integrated data bases containinginformation about phrase patterns and parse tree nodes, retrieval of which is triggered by featurescontained in individual entries of the lexicon.
Using this information, the parser assembles a parse treeby attaching input words (and sometimes also partially assembled parse trees and tree fragments poppedfrom the stack) to empty nodes of the specified tree frame, until the entire parse tree is completed.
Thisscheme, which works effectively and realistically for both left-branching languages and right-branchinglanguages, is deterministic in that it does not use backtracking or parallel processing.
In this system,unlike in ATN or in LR(k), the grammatical sentences of a language are not determined by a set ofrewriting rules, but by a set of patterns in conjunction with procedures and the meta rules that governthe system's operation.This paper presents some results of an attempt todevelop a common parsing scheme that works system-atically and realistically for typologically varied naturallanguages.
When this project was started in 1982, thealgorithm based on augmented transition networks(ATNs) codified by Woods (1970, 1973) was not onlythe most commonly used approach to parsing naturallanguages in computer systems, but it was also theachievement of computational linguistics which wasmost influential to other branches of linguistics.
Forexample, researchers of psycholinguistics like Kaplan(1972) and Wanner and Maratsos (1978) used ATN-based parsers as simulation models of human languageprocessing.
Bresnan (1978) used an ATN model, amongothers, to test whether her version of transformationalgrammar was "realist ic".
Fodor's theory of "super-strategy" Fodor (1979) was also strongly influenced bythe standard ATN algorithm.
Indeed, as Berwick andWeinberg (1982) contend, parsing efficiency or compu-tational complexity by itself may not provide reliablecriteria for the evaluation of grammatical theories.
It isevident, however, that computers can be used as aneffective means of simulation in linguistics, as they haveproved to be in other branches of science.Nevertheless, as a simulation model of the humanfaculty of language processing, the standard ATNmechanism has an intrinsic drawback: unless some adhoc, unrealistic, and efficiency-robbing operations areadded, or unless one comes up with a radically differentgrammatical framework, it cannot be used to parseleft-branching languages like Japanese in which thebeginning of embedded clauses is not regularly marked.One may try to cope with this problem by developinga separate parsing algorithm for left-branching lan-guages, leaving the ATN formalism to specialize inright-branching languages like English.
However,  thissolution contradicts our intuition that the core of thehuman faculty of language processing is universal.Another possible alternative, an ATN-type parserwhich processes left-branching language's sentencesbackward from right to left, is also unrealistic.
Ifcomputational linguistics is to provide a simulationmodel for theoretical linguistics and psycholinguistics,it must develop an alternative parsing scheme which canCopyright 1988 by the Association for Computational Linguistics.
Permission to copy without fee all or part of this material isgranted providedthat the copies are not made for direct commercial dvantage and the CL reference and this copyright notice are included on the first page.
Tocopy otherwise, or to republish, requires afee and/or specific permission.0362-613X/88/010020-30503.0020 Computational Linguistics, Volume 14, Number I, Winter 1988Paul T. Sato A Common Parsing Scheme for Left- and Right-Branching Languageseffectively and realistically process both left-branchingand right-branching languages.
Even for purely practi-cal purposes, such a scheme is desirable because it willfacilitate the development of machine translation sys-tems which can handle languages with different ypo-logical characteristics.Some limitations of ATN-based parsers for handlingleft-branching languages are illustrated in section 1.
Therest of this paper describes and illustrates my alterna-tive parsing scheme called Pattern Oriented Parser(POP), which can be used for both left-branching andright-branching languages.
(POP is a descendant of itsearly prototype called Pattern-Stack Parser, which wasintroduced in Sato (1983a.))
A general outline of POP isgiven in section 2, and its operation is illustrated insection 3, using both English and Japanese xamples.Some characteristics of POP are highlighted in section4, after which brief concluding remarks are made insection 5.The present version of POP is a syntactic analyzer,and it does not take semantics into consideration.However, the system could be readily augmented withprocedures that build up semantic interpretations alongwith syntactic analysis.
One such model was presentedin Sato (1983b).1 LIMITATIONS OF ATN-BASED PARSERS1.1 CASE ASSIGNMENTOne of the greatest obstacles faced when attempting todevelop an ATN-based parser for a language like Japa-nese is the unpredictability caused by the relatively freeword order and by the left-branching subordinateclauses which have no beginning-of-clause marker.Indeed, Japanese word order is not completely free.For example, modifiers always precede the modified,and the verb complex (a verbal root plus one or moreordered suffixes marking tense, aspect, modality, voice,negativity, politeness level, question, etc.)
is alwaysplaced at the end of the sentence.
Moreover, almost allnouns and noun phrases occurring in Japanese sen-tences have one or more suffixes marking caserelationships.
1However, Japanese postnominal suffixes, by them-selves, do not always provide all the necessary infor-mation for case assignment.
For example, the directobject of a nonstative verb complex is marked by -o,while the direct object of a stative verb complex isusually marked by -ga, which also marks the subject.Compare the two sentences in (1).
(1) a. Mary-wa John-ga nagusame-ta.
'As for Mary,John consoled her.'
(-wa = TOPIC, nagusame-'console' <-STATIVE>),-ta = PAST)b. Mary-wa John-ga wakar-ta.
'As for Mary, sheunderstood John.'
(wakar- 'understand'< + STATIVE>)An ATN-based parser cannot positively identify thefunctions of the two noun phrases of these sentencesuntil it processes the verb complex at the end of thesentence.Examples like (2) also illustrate how little can bededuced from postnominal suffixes before the sentence-final verb complex is processed.
(2) a. Mary-ga hon-o kaw-ta.
'Mary bought a book.
'(kaw- 'buy')b. John-ga Mary-ni hon-o kaw-sase-ta.
'John madeMary buy a book.'
(-sase- = CAUSE)c. Mary-ga John-ni hon-o kaw-sase-rare-ta.
'Marywas made by John to buy a book.'
(-rare- =PASSIVE)The agent of the embedded sentence is marked by -ni in(2b), but by -ga in (2c).The relatively free word order of Japanese furthercomplicates the situation, as in the six sentences listedin (3) which are all grammatical nd all mean "Mary wasmade by John to buy a book", but each with differentnoun phrases given prominence.
(3) a. Mary-ga John-ni hon-o kaw-sase-rare-ta.
= (2c)b. Mary-ga hon-o John-ni kaw-sase-rare-ta.c.
John-ni Mary-ga hon-o kaw-sase-rare-ta.d.
John-ni hon-o Mary-ga kaw-sase-rare-ta.e.
Hon-o Mary-ga John-ni kaw-sase-rare-ta.f.
Hon-o John-ni Mary-ga kaw-sase-rare-ta.1.2 EMBEDDED SENTENCESEmbedded sentences in languages like Japanese posemore serious problems because they do not normallycarry any sign to mark their beginning.
As a result, thebeginning of a deeply embedded sentence can lookexactly like the beginning of a simple top-level sen-tence, as illustrated in (4).
(4) a. Mary-ga sotugyoo-si-ta.
'Mary was graduated(from school).'
(sotugyoo-si- 'be graduated')b. Mary-ga sotugyoo-si-ta kookoo-ga zensyoo-si-ta.
'The high school from which Mary was graduatedwas burnt down.'
(kookoo 'high school', zensyoo-si- 'be burnt down')c. Mary-ga sotugyoo-si-ta kookoo-ga zensyoo-si-tato iw-ru.
'It is reported that the high school fromwhich Mary was graduated was burnt down.
'(to = END-OF-QUOTE, iw- 'say', -ru = NON-PAST)d. Mary-ga sotugyoo-si-ta kookoo-ga zensyoo-si-tato iw-ru sirase-o uke-ta.
'(I/we/you/he/she/they)received news (which says) that the high schoolfrom which Mary was graduated was burntdown.'
(sirase 'news', uke- 'receive')e. Mary-ga sotugyoo-si-ta kookoo-ga zensyoo-si-tato iw-ru sirase-o uke-ta Cindy-ga nak-te i-ru.
'Cindy, who received news that the high schoolfrom which Mary was graduated was burnt down,is crying.'
(nak-te i- 'be crying, be weeping')Computational Linguistics, Volume 14, Number 1, Winter 1988 21Paul T. Sato A Common Parsing Scheme for Left- and Right-Branching LanguagesIn order to process sentences listed in (4), the NPnetwork of an ATN-based parser must be expanded byprefixing to it another state with two arcs leaving fromit: a PUSH SENTENCE arc that processes a relativeclause, and a JUMP arc that processes noun phrasesthat do not include a relative clause.However, as (4) illustrates, there is no systematicway to determine which of the two arcs leaving the firststate of this expanded NP network should be takenwhen the parser encounters the first word of the input.The parser cannot predict he correct path until it hascompleted processing the entire sentence or the entirerelative clause and has seen what followed it.
Becausethere is theoretically no limit to the number of levels ofrelative clause embedding, the number of combinationsof possible arcs to be traversed is theoretically infinite.2 OVERVIEW OF PATTERN ORIENTED PARSER (POP)This section presents a quick overview of PatternOriented Parser (POP), which I have developed inorderto cope with the kind of difficulties mentioned in theprevious ection.POP is a left-to-right, bottom-up arser consisting ofthree data bases, a push-down STACK, a buffer, aregister, and a set of LISP programs collectively calledhere the PROCESSOR that builds the parse tree of theinput sentence.
The relationship of these components isshown schematically in (5).
(5) Components of POP(Data bases) (Buffer, stack, and register)LEXICON.
, , INPUT BUFFERSNP~ROCESSOR~STACKPHP "LNP  REGISTERThe SNP (Sentence Pattern data base) contains a setof parse tree frames, each of which is associated withone class of verbs or verbal derivational suffixes andincludes information about he syntactic subcategoriza-tion of the members of that class and information aboutthe thematic roles of their arguments.
For example, theSNP entry for a class of English verbs which includesbuy and sell looks like (6).
(6) (s (* v)(AGNT (* NP <+HUMAN>)(PTNT (* NP <-HUMAN>))The PHP (Phrase Pattern data base) contains infor-mation about he internal structure of noun phrases andadverbial phrases and the procedures for building theparse trees of such phrases.
For example, (7) is anEnglish translation of the PHP entry for a Japanesenoun phrase which contains a relative clause.
2(7) If the CWS is an NP and the TOS is an S, thenconstruct the following noun phrase and push it tothe STACK:(NP (HEAD CWS)(MOD (rep_emn TOS CWS)))- CWS is the word or phrase on which the PROCES-SOR is currently working.- TOS is the word or phrase at the top of theSTACK.- (rep_emn TOS X) means "pop the TOS and attachX to its first matching empty node".- Each non-empty NP node is given a new indexnumber when it is constructed.Details of how (7) works will be illustrated in section 3.The push-down STACK of POP stores partially as-sembled parse trees and tree fragments, while LNP orthe "Last NP" REGISTER temporarily stores a copyof the noun phrase most recently attached to a node inthe sentence tree.
LNP is necessary to process a nounphrase with a modifier that follows the head noun (e.g.,English noun phrases which contain relative clauses).The present version of POP for Japanese does not usean LNP; however, it will prove useful when we try toprocess parenthetical phrases.
The INPUT BUFFERstores the input sentence.The three data bases of POP are stored on disk andcan be updated independently of each other and of thePROCESSOR, while the buffer, the stack and theregister are created by the PROCESSOR each time it isinvoked.The major program modules (functions) that consti-tute the PROCESSOR and their hierarchical callingpaths are presented in (8), where the parameters areenclosed in parentheses.
(8) Major Functions of the PROCESSORPARSE-SENTENCE (SENTENCE)IPARSE-WORD (WORD)I IASSEMBLE-NP (CWS) ASSEMBLE-SENTENCE (CWS SNA)CHECK-PHP (CWS) - called in different modules.where CWS = the word or the phrase which the PROC-ESSOR is currently working onSNA = address of a sentence pattern stored inthe SNPThe PROCESSOR is activated when its top-levelfunction, PARSE-SENTENCE, is called with the inputsentence as its parameter.
PARSE-SENTENCE thencreates the STACK, the INPUT BUFFER and theLNP-REGISTER in the memory, puts the input sen-tence into the INPUT BUFFER, and calls PARSE-WORD.
PARSE-WORD searches the LEXICON for anentry which matches the first word in the INPUTBUFFER and, when it is found, calls either ASSEM-BLE-NP or ASSEMBLE-SENTENCE, depending onthe word type of the entry it finds in the LEXICON,assembles a sub-tree, and pushes the result to theSTACK.
After that, PARSE-WORD removes the firstword from the INPUT BUFFER and repeats the same22 Computational Linguistics, Volume 14, Number 1, Winter 1988Paul T. Sato A Common Parsing Scheme for Left- and Right-Branching Languagesprocess with the next word.
In the course of assemblingsub-trees, ASSEMBLE-NP uses the PHP, and AS-SEMBLE-SENTENCE uses the SNP and the PHP astheir data bases.
This process continues until the IN-PUT BUFFER contains only the end-of-sentence mark(EOS), when PARSE-WORD returns control toPARSE-SENTENCE, which pops the assembled sen-tence from the STACK and sends it to the outputdevice, removes the stack, the buffer and the registerfrom memory, and exits successfully.As shown in section 3, POP assembles a parse treeprimarily by attaching terminal elements (copies oflexical entries) or tree fragments popped from theSTACK to the first matching empty node of the matrixtree.
All empty nodes of tree frames have an asterisk astheir first element, followed by various specificationsfor matching requirements: (* ga (NP <+HUMAN>))is an empty node for an NP which has a featurespecification <+HUMAN> and is flagged with ga. Tofind the first matching empty node, the PROCESSORconducts a depth-first search for "*"  followed by otherconditions, and when the first matching empty node isfound, it attaches the specified element o that nodeusing the LISP function UNION, thus preventing over-lapping elements from being duplicated in the resultantbranch.
After the attachment is completed, the asteriskis removed from the node.The use of the LNP REGISTER will be illustrated insubsection 3.3.3 OPERATION OF POPThis section illustrates the operation of POP more indetail.
Subsection 3.1 is a quick walk-through of theoverall operation using a simple yes~no-question iEnglish as an example, while subsection 3.2 illustrateshow POP handles the inherent problems of left-branching languages discussed in section 1, using theJapanese xamples presented in that section.
Then weturn our attention to English again in subsection 3.3 andillustrate POP's handling of English wh-questions andrelative clauses.3.1 SIMPLE ENGLISH EXAMPLEOur first example is (9).
(9) Did John buy a good book in Boston?When PARSE-SENTENCE calls PARSE-WORDand the latter finds did in the LEXICON, it makes acopy of the matching lexical entry, (V < +PAST>), andpushes it to the STACK.
The next word that PARSE-WORD finds in the INPUT BUFFER is John.
There-fore, PARSE-WORD searches the LEXICON and getsa copy of the entry that matches this word, ("John"),which is a noun.
3Whenever PARSE-WORD encounters a noun, itcalls ASSEMBLE-NP with a copy of the lexical entryas its argument.
ASSEMBLE-NP assembles a newComputational Linguistics, Volume 14, Number 1, Winter 1988noun phrase (NP1 "John"), and then it calls CHECK-PHP with the newly assembled NP1 as its argument.CHECK-PHP then examines the PHP data base, andreturns NIL to ASSEMBLE-NP because it finds nopattern that matches the string {<V, +PAST> NP}(i.e., the TOS followed by the CWS).
Because CHECK-PHP failed to find any matching entry of the PHP,ASSEMBLE-NP pushes NP1 to STACK without con-ducting any further assembling operation, and returnscontrol to PARSE-WORD.
The contents of the STACKat this time are shown in (10).
(10) ((NP1 "John")(<V, +PAST>))PARSE-WORD then removes John from the INPUTBUFFER, picks up buy there, searches the LEXICON,and gets a copy of a matching entry.
This is a verb.
Thelexical entry of every verb or verbal derivational suffixcontains an SNA (the SNP address of the sentencepattern associated with it).
Therefore, ASSEMBLE-SENTENCE retrieves a copy of the sentence patternfrom the address matching the verb's SNA and attachesthe verb's remaining lexical entry to its first empty Vnode (i.e., the first node whose CAR is "*"  and thesecond member is "V").
It then removes the "*"  fromthat node.
As mentioned in section 2, the SNP entry forthe class of verbs like buy and sell is (6).
Therefore, byattaching (V <"buy">)  to the V node of its copy,ASSEMBLE-SENTENCE constructs (11).
(11) (S (V <"buy">)(AGNT (* NP <+HUMAN>)(PTNT (* NP <-HUMAN>)))After (I1) is assembled, ASSEMBLE-SENTENCEpops the TOS, attaches it to the first empty nodematching its specifications and removes the asterisk atthe beginning of that node.
The result is (12).
(12) (S (V <"buy">)(AGNT (NP1 "John")(PTNT (* NP <-HUMAN>)))ASSEMBLE-SENTENCE pops TOS again.
Thistime, it is (<V, +PAST>).
ASSEMBLE-SENTENCEthen examines the PHP and finds two entries (13) and(14) whose conditions match the current state.
(13) If the element popped is a V and if it contains nofeature other than tense, number, and/or person,attach it to the V node of the S tree whichASSEMBLE-SENTENCE is currently building.
(14) If there is a tense feature in the element that ispopped immediately after the AGNT node (or theOBJ node if the tree has no AGNT node) isfilled, attach feature <Q> (i.e., "question") tothe main verb of the matrix S.ASSEMBLE-SENTENCE executes (13) and (14).
Theresult is (15).23Paul T. Sato A Common Parsing Scheme for Left- and Right-Branching Languages(15) (S (V <"buy" ,  +PAST, Q>)(AGNT (NP1 "John")(PTNT (* NP <-HUMAN>)))The STACK is now empty.
Therefore, ASSEMBLE-SENTENCE pushes (15) to the STACK and returnscontrol to PARSE-WORD.PARSE-WORD removes buy from the INPUTBUFFER, encounters the indefinite article a, gets acopy of the matching lexical entry (DET <-DEF>) fromthe LEXICON, and pushes it to the STACK.
The nextword that PARSE-WORD sees is good.
So a copy of itsmatching lexical entry (ADJ "good") is pushed to theSTACK and good is removed from the INPUTBUFFER.PARSE-WORD then finds .book in the INPUTBUFFER.
Because it is a noun, PARSE-WORD callsASSEMBLE-NP, which assembles a single-word NPand routinely calls CHECK-PHP.
This time, CHECK-PHP finds (16) in the PHP.
(16) If the CWS is an NP and if the TOS is an ADJ,assemble:(NP (HEAD CWS)(MOD (pop TOS)))At this time, the TOS is (ADJ "good").
Therefore,ASSEMBLE-NP pops it and assembles a new nounphrase in accordance with (16) and calls CHECK-PHPagain.
The new TOS is (DET <-DEF>) .
CHECK-PHPfinds (17) in the PHP which matches this situation.
(17) If the CWS is an NP and if the TOS is a DET,assemble:(NP (HEAD CWS)(pop TOS))ASSEMBLE-NP executes (17).
The result is (18).
(18) (NP4 (HEAD (NP3 (HEAD (NP2 "book"))(MOD(ADJ "good")))(DET <-DEF>))Because (18) is an NP, ASSEMBLE-NP calls CHECK-PHP again.
This time, the TOS is (15), which is an Stree.
CHECK-PHP finds a matching entry in the PHPagain, which is (19).
(19) If CWS = NP and TOS = S, pop the TOS andattach the CWS to its first matching empty node.What is involved here is the assembly of an S, which isoutside the domain of ASSEMBLE-NP's responsibility.Therefore, before popping the S from the STACK,ASSEMBLE-NP returns the symbol "AS"  to PARSE-WORD.
PARSE-WORD then calls ASSEMBLE-SEN-TENCE substituting (18) for the parameter CWS and"TOS" for the parameter SNA.
ASSEMBLE-SEN-TENCE then builds (20) in the manner explained ear-lier.
The STACK is now empty, and there is no match-24ing PHP entry.
Therefore, ASSEMBLE-SENTENCEpushes the newly assembled tree (20) to the STACK.
(20) (S (v <"buy", +PAST, Q>)(AGNT (NP1 "John")(PTNT (NP4 (HEAD (NP3 (HEAD (NP2 "book")(MOD (ADJ "good"))))(DET <-DEF>))))The next thing PARSE-WORD sees in the INPUTBUFFER is EOS (end-of-sentence symbol).
Therefore,it returns control to PARSE-SENTENCE, which pops(20) from the STACK, and sends it to the output device.Nothing is left in the STACK now.
Therefore, PARSE-SENTENCE removes the stack, the buffer and theregister from memory and exits successfully.3.2 JAPANESE EXAMPLESThis section illustrates how POP handles the problemsof Japanese sentences discussed in section 1.3.2.1 CASE MARKING IN SIMPLE SENTENCESThe first example in section 1 was (la), which isrepeated here in (21).
(21) Mary-wa John-ga nagusame-ta.
'As for Mary,John consoled her.
'(-wa = TOPIC, nagusame- 'console'<-STATIVE>),-ta = PAST)POP processes Japanese sentences in basically thesame way as it processes English sentences.
Therefore,when PARSE-SENTENCE calls PARSE-WORD andPARSE-WORD sees the first word, Mary-wa, PARSE-WORD retrieves from the LEXICON a copy of theentry which matches the stem of this word, and callsASSEMBLE-NP because Mary is a noun.
ASSEM-BLE-NP assembles (NP1 "Mary"),  and places its suffix-wa in front of the newly assembled NP as its flag.
ThenCHECK-PHP is called, but it returns NIL because theSTACK is still empty.
Therefore, ASSEMBLE-NPpushes (wa (NP1 "Mary")) to the STACK.
The secondword, John-ga, is processed in the same way, and (ga(NP2 "John")) is also pushed to the STACK.PARSE-WORD then encounters nagusame-ta ndidentifies it as the verb "console" with a past tensesuffix.
Therefore, PARSE-WORD retrieves a copy ofits SNP using the SNA included in the lexical entry, andattaches the lexical entry of nagusame-ta oits empty Vnode.
The result is (22).
(22) (S (V <"console",  +PAST>)(PTNT (* o (NP <+HUMAN>)))(AGNT (* ga (NP <+HUMAN>))))ASSEMBLE-SENTENCE then pops the TOS (ga (NP2"John")) and attaches it to the first matching emptynode, namely, the AGNT node.
The case flag ga, whichis no longer necessary, is removed.The next TOS is (wa (NPI "Mary")).
As mentionedin section 1, wa is a suffix that marks the sentence topic.However, there is no sentence pattern stored in theComputational Linguistics, Volume 14, Number 1, Winter 1988Paul T. Sato A Common Parsing Scheme for Left- and Right-Branching LanguagesSNP which includes a topic (TPIC) node.
Instead, it iscreated by the following instructions (23) retrieved fromthe PHP.
(23) If the TOS has the flag wa:a.
Create a TPIC node which is directly dominatedby the topmost S node and attach a "copy"(i.e., the category symbol and its index) of theTOS to this node.b.
Attach the TOS to the first matching emptynode.As is evident from (la, lb), the topic marker wa absorbsboth ga and o: i.e., the topicalized NP without any othercase flag can match both an NP node which is flaggedwith o and an NP node which is flagged with ga.Therefore, following (23b), (NP1 "Mary") is attachedto the first (and the only) empty node (PTNT) after (23a)is executed.
The result is (24), which is the correct parsetree of (21).
(24) (S (V <"console",  +PAST>)(PTNT (NP1 "Mary"))(AGNT (NP2 "John"))(TPIC (NP1)))'As for MarYi, John consoled MarYi.
'Example (lb) is processed in the same way, produc-ing the correct parse tree (25b), although both the PTNTnode and the AGNT node of the SNP pattern associatedwith the stative verb wakar- 'understand' are flagged byga, as shown in (25a).
(25) a. SNP pattern associated with wakar-"understand"(S (* V)(PTNT (* ga (NP))(AGNT (* ga (NP <+HUMAN>)))b. Parse tree of (2-1b) Mary-wa John-ga wakar-ta.
'As for Mary, she understood John.
'(S (V <"understand", +PAST>)(PTNT (NP2 "John"))(AGNT (NP1 "Mary"))(TPIC (NP1)))3.2.2 VERBAL DERIVATIONAL SUFFIX AND CASE MARKINGThe next set of examples is (2), repeated here as (26).
(26) a. Mary-ga hon-o kaw-ta.
'Mary bought a book.
'(kaw- 'buy')b. John-ga Mary-ni hon-o kaw-sase-ta.
'John madeMary buy a book.'
(-sase- = CAUSE)c. Mary-ga John-ni hon-o kaw-sase-rare-ta.
'Marywas made by John to buy a book.'
(-rare- =PASSIVE)The SNP pattern associated with kaw- 'buy' is (27).
(27) (S (* V)(PTNT (* o (NP)))(AGNT (* ga (NP <+HUMAN>))))Computational Linguistics, Volume 14, Number 1, Winter 1988Therefore, the parsing of (26a) to get (28) is straightfor-ward.
(28) (S (V <"buy" ,  +PAST>)(PTNT (NP2 "book"))(AGNT (NP1 "Mary")))The parsing of (26b) is a little more complex becauseit involves causative suffix -sase-, to which is associatedanother SNP pattern (29) (simplified here for the sake oflegibility).
(29) (S (V <CAUSE>)(PTNT (* or (ni (NP = AGNT of SR))(o (NP = OBJ or PTNT of Sk))))(AGNT (* ga (NP <+HUMAN>)))(ACTN (* Sk)))where ACTN = action, Sk = embedded S.When the PROCESSOR processing (26b) encountersthe verb kaw-sase-ta 'made to buy', it first retrieves (27)and attaches "buy" to its empty V node to construct thetree frame (30).
(30) (S (V <"buy">)(PTNT (* o (NP)))(AGNT (* ga (NP <+HUMAN>))))This tree is then incorporated into (29) to obtain thecomplex tree frame (31).
(There is a meta-rule thatremoves the case flag of a node in the embeddedsentence if the node is co-indexed with a node in thematrix sentence.
)(31) (S (V <CAUSE>)(PTNT (* ni (NP i <+HUMAN>)) )(AGNT (* ga (NP <+HUMAN>)))(ACTN (S (V <"buy">)(PTNT (* o (NP)))(AGNT (* NP i <+HUMAN>)))))By the time the PROCESSOR encounters the verbcomplex kaw-sase-ta 'caused to buy' and constructs thecomplex tree frame (31), all three noun phrases of thesentence have already been processed and stored in theSTACK, as shown in (32).
(32) ((o (NP3 "book"))(ni (NP2 "Mary"))(ga (NP1 "John")))Therefore, when the tree frame (31) is completed,ASSEMBLE-SENTENCE begins to pop elements fromthe STACK and to attach them to empty nodes of thetree.
First, (o (NP3 "book")) is popped.
The PTNTnode of the embedded sentence is the only empty nodethat matches it, so the popped NP is attached there.Next, (ni (NP2 "Mary")) is popped, which is attachedto the PTNT node of the matrix sentence and its copy isattached to the co-indexed AGNT node of the embed-ded sentence.
Finally, (ga (NP1 "John")) is popped and25Paul T. Sato A Common Parsing Scheme for Left- and Right-Branching Languagesattached to the AGNT node of the matrix sentence.
Theresult is (33), which is the correct parse tree of (26b).
(33) (S (V <CAUSE, +PAST>)(PTNT (NP2 "Mary"))(AGNT (NP1 "John"))(ACTN (S (V <"buy">)(PTNT (NP3 "book"))(AGNT (NP2)))))'John made Mary buy a book.
'Example (26c) is a passive of (26b) with passive suffix-rare-, with which is associated an SNP pattern (34)(simplified here for the sake of legibility).
(34) (S (V <PASSIVE>)(PTNT (ga (NP = OBJ or PTNT of Sk)))(AGNT (ni (NP = AGNT of Sk)))(ACTN (Sk)))Therefore, before beginning to pop elements from theSTACK, ASSEMBLE-SENTENCE constructs thecomplex tree frame (35) by incorporating (31) into (34).
(35) (S (V <PASSIVE, +PAST>)(PTNT (ga (NP i <+HUMAN>)))(AGNT (ni (NPj)))(ACTN (S (V <CAUSE>)(PTNT (NP i < +HUMAN>))(AGNT (NPj <+HUMAN>))(ACTN (S (V <"buy">)(PTNT (o (NP)))(AGNT (NP i<+HUMAN>)))))))At this stage, the contents of the STACK are the sameas (32).
So when they are popped and attached to thematching nodes according to the principle explainedabove, we obtain the correct parse tree (36).
(36) (S (V <PASSIVE, +PAST>)(PTNT (NP1 "Mary"))(AGNT (NP2 "John"))(ACTN (S (V <CAUSE>)(PTNT (NP1))(AGNT (NP2))(ACTN (S (V <"buy">)(PTNT (NP3 "book"))(AGNT (NP1)))))))'Mary was made by John to buy a book.
'3.2.3 RELATIVE CLAUSESAs mentioned in section 2, Japanese noun phrasescontaining a relative clause are processed by the PHPentry presented in (7), repeated here in (37).
(37) If the CWS is an NP and the TOS is an S, thenconstruct the following noun phrase and push itto the STACK:(NP (HEAD CWS)(MOD (rep_emn TOS CWS)))To illustrate how (37) works, we will trace the nounphrase (38), which is included in all sentences cited in(4b) through (4e).
(38) Mary-ga sotugyoo-si-ta kookoo-ga 'The highschool from which Mary was graduated'(sotugyoo-si- 'be graduated', -ta = PAST, kookoo'high school', -ga = case suffix)The SNP pattern associated with sotugyoo-si- s (39).
(39)(S (* V)(AGNT (* ga (NP <+HUMAN>)))(ABL (* o (NP <PLACE, DEF = "school">))))where ABL = ablative and DEF = default.Therefore, when the first two words of (38) are proc-essed, (40) is assembled and pushed to the STACK.
(4O)(S (V <"be graduated", +PAST>)(AGNT (NP1 "Mary"))(ABL (* o (NP <PLACE, DEF = "school">))))If the next item in the INPUT BUFFER were EOS (asin (4a)), the system pops (40) and, finding that theSTACK is now empty, attaches the default value"school" to the empty ABL node, and sends the resultto the output device.
However, what follows the verb in(38) is a noun.
Therefore, ASSEMBLE-NP assembles(ga (NP2 "high school")) and calls CHECK-PHP,which finds (37) because the CWS is the noun phrasejust assembled and the TOS is (40).In accordance with (37), (40) is popped from theSTACK, and a new noun phrase (41) is assembled andpushed to the STACK.
(41) (ga (NP3 (HEAD (NP2 "high school"))(MOD (S (V <"be graduated", +PAST>)(AGNT (NP1 "Mary"))(ABE (NP2))))))There is no backtracking involved here and, byrepeating the same process, POP can process nestedrelative clauses like those cited in (4) from left to right,without facing any combinatorial explosion.3.3 WH-QUESTION AND RELATIVE CLAUSE IN ENGLISHThe ATN strategy for parsing wh-questions and relativeclauses in English attracted special attention of manylinguists, including Bresnan (1978) and Fodor (1979),because it seemed to support he trace theory and thetheory of wh-movement transformation.
Therefore, wewill conclude the illustration of POP by explaining howit handles them.3.3.1 WH-QUESTIONSNo special mechanism is necessary for processing En-glish wh-questions like (42) by POP.
(42) a.
Who praised John?26 Computational Linguistics, Volume 14, Number 1, Winter 1988Paul T. Sato A Common Parsing Scheme for Left- and Right-Branching Languagesb.
Who did John praise?The SNP pattern associated with the verb praise is (43).
(43) (S (* V)(AGNT (* NP <+HUMAN>))(PTNT (* NP <+HUMAN>)))First, we will trace the parse of (42a).
The first word,who, is processed and the result, (NP1 <+HUMAN,WH, Q>), is pushed to the STACK before the PROC-ESSOR encounters praised and retrieves a copy of (43)from the SNP.
Then "praised" is attached to the emptyV node of the tree frame, and the TOS is popped andattached to the first matching empty node.
Since thatNP has the features <WH, Q>, and because theSTACK is now empty, thefeature <Q> is moved fromNP1 node to the V node.
The result is (44).
(44) (S (V <"praise", +PAST, Q>)(AGNT (NP1 <+HUMAN, WH>)(PTNT (* NP <+HUMAN>)))Then, John is processed in the normal way, and it isattached to the first (and the only) matching node(PTNT), following the ordinary procedure illustrated insection 3.1.
The result is the correct parse tree (45).
(45) (S (V <"praise", +PAST, Q>)(AGNT (NP1 <+HUMAN,  WH>)(PTNT (NP2 "John")))At first sight, parsing (42b) by POP may seem difficultbecause the object is placed before the subject in thissentence.
However, POP processes the sentence usingauxiliary did as a clue, just as humans do.
In the sameway as POP handled the first word of (42a), it processeswho in (42b) by assembling (NP1 <+HUMAN, WH,Q>) and pushing it to the STACK.
And in the same wayas it handled id in (9), POP assembles (V <+PAST>)and pushes it on top of NPI, after which it processesJohn and pushes (NP2 "John") to the STACK.The system then encounters praise and retrieves (43)from the SNP, pops (NP2 "John") from the STACK,and attaches it to the first matching empty node, whichis the AGNT node.
Next, (V <+PAST>) is popped,and it is attached to the V node in accordance with (13).Because (V <+PAST>) is an element hat is poppedimmediately after AGNT node is filled and because itcontains a tense feature, the feature <Q> is added tothis node in accordance with (14).
The result is (46).
(46) (S (V <"praise", +PAST, Q>)(AGNT (NP2 "John"))(PTNT (* NP <+HUMAN>)))The TOS is now (NP1 <+HUMAN,  WH, Q>), whichis popped and attached to the remaining matching node,and its feature <Q> is moved to the V node.
4The resultis the correct parse tree (47).
(47) (S (V <"praise", +PAST, Q>)(AGNT (NP2 "John"))(PTNT (NP1 <+HUMAN,  WH>)))3.3.2 RELATIVE CLAUSEAs an example of English sentences which includerelative clauses, we will examine (18).
(48) Joan loves the brilliant linguist who the studentsrespect.The first two words are processed and the partial tree(49) is constructed in the usual way, and it is pushed tothe STACK.
(49) (S (V <"love",  -PAST>)(AGNT (NPI "Joan"))(PTNT (* NP <+HUMAN>)))The next three words (the, brilliant, linguist) areprocessed in the ordinary way, and following the PHPinstructions cited in (16) and (17), they are assembledinto noun phrase (50) and attached to the empty PTNTnode of (4-41).
The result is (51), and NP4 is the contentof the LNP REGISTER:(50) (NP4 (HEAD (NP3 (HEAD (NP2 "linguist"))(MOD (ADJ "brilliant"))(DET <DEF>))))(51) (S (V <"love", -PAST>)(AGNT (NP1 "Joan"))(PTNT (NP4 (HEAD (NP3 (HEAD (NP2 "linguist"))(MOD (ADJ "brilliant"))(DET <DEF>)))))The next word (who) is read in.
Its lexical entry includesthe feature <WH>, and the TOS is (51).
Therefore,CHECK-PHP finds (52) which matches these condi-tions.
(52) If the CWS has a feature <WH> and if the TOSis an S, then(mark TOS)and (setq CWS (list (copyi MARKED)'<REL>))where - (mark TOS) marks the constituent of theTOS that is equal to the content of theLNP REGISTER- MARKED represents he constituent ofthe TOS thus marked- (copyi X) returns the category index ofX.When (52) is applied, the CWS becomes (53), which ispushed to the STACK.
(53) (NP4 <REL>)The next two words, the and students, are processed,and the result (54) is pushed to the STACK in accor-dance with (17).Computational Linguistics, Volume 14, Number 1, Winter 1988 27Paul T. Sato A Common Parsing Scheme for Left- and Right-Branching Languages(54) (NP6 (HEAD (NP5 "students"))(DET < +DEF>))The verb respect is encountered, the matching sentencepattern is retrieved, and the verb is attached to its Vnode.
The result is (55).
(55) (S (V <"respect" ,  -PAST>)(AGNT (* NP <+HUMAN>))(PTNT (* NP)))The TOS is popped and attached to the first matchingempty node.
The result is (56).
(56) (S (V <"respect" ,  -PAST>)(AGNT (NP6 (HEAD (NP5 "students"))(DET < +DEF>)))(PTNT (* NP)))The next TOS = (53) is popped and attached to theempty node of (56), hence (57).
(57) (S (V <"respect" ,  -PAST>)(AGNT (NP6 (HEAD (NP5 "students"))(DET < +DEF>)))(PTNT (NP4 <REL>)))CHECK-PHP is called again, which finds matchingentry (58).
(58) If the CWS contains <REL> and the TOScontains a marked NP, pop the TOS and replaceits marked NP with:(NP (HEAD MARKED)(MOD CWS))Then remove the mark from MARKED andremove feature <REL> from the CWS.Before (58) is applied, the CWS is (57) and the TOS is(51) of which NP4 is marked in accordance with (52).Following (58), therefore, the daughter of the PTNTnode of (51) is replaced by (59).
(59)(NP7 (HEAD (NP4 (HEAD (NP3 (HEAD (NP2 "linguist"))(MOD (ADJ "brilliant"))(DET <DEF>)))(MOD (S (V <"respect", -PAST>)(AGNT (NP6 (HEAD (NP5 "students"))(DET < +DEF>)))(PTNT (NP4)))))The result of this replacement is (60), and it is pushed tothe STACK.
(60)(S (V <"love", -PAST>)(AGNT (NPI "Joan"))(PTNT (NP7 (HEAD (NP4 (HEAD (NP3 (HEAD (NP2 "linguist"))(MOD (ADJ "brilliant"))(DET <DEF>)))(MOD (S (V <"respect", -PAST>)(AGNT (NP6 (HEAD (NP5 "students"))(DET <+DEF>)))(PTNT (NP4)))))))The next element found in the INPUT BUFFER isEOS (end-of-sentence).
So the PROCESSOR pops (60)and sends it to the output device.4 HIGHLIGHTS OF SOME CHARACTERISTICS OF POP4.1 VERBAL DERIVATIONAL SUFFIXES AND CASEASSIGNMENTAs illustrated in (2), the same postnominal suffixes markdifferent relations in Japanese, depending on the verbalderivational suffixes used in the verb complex.
Tradi-tional generative grammarians (like Kuno (1973)) triedto explain this by means of a series of transformationalrules such as agentive ni attachment, equi-NP deletion,Aux deletion, verb raising, subject marking, objectmarking, and ga/ni conversion, which were appliedcyclically.
This transformational approach is still widelypracticed by researchers of Japanese linguistics.
How-ever, as demonstrated bySato (1983b), this is unsuitablefor application to parsing because many of the transfor-mational rules involved here are non-reversible.A relatively recent approach to this problem is to usea set of rules like (61) which Kuroda (1976) callsCanonical Surface Structure Filters and Miyagawa(1980) calls Case Redundancy Rules.
(61) a.
\[NP ---\] ==> \[NP-ga ---\]b.
\[NP NP ---\] = => \[NP-ga NP-o ---\]c. \[NP NP NP ---\] = => \[NP-ga NP-ni NP-o ---\]These rules are invoked after applying all transforma-tional rules (Kuroda 1976) or all word formation rules(Miyagawa 1980), and they attach suffixes to nounphrases as specified in their output, without regard tothe functions of the phrases to which they are attached.The selection of case suffixes and the order of theirappearance in the surface structure are determinedsolely by the number of unmarked noun phrases in thesentence.
This approach would work well if Japanesespeakers always followed the "canonical word order".However, the so-called canonical word order is notalways followed.Contrary to the theories of Kuroda and Miyagawawhich treat Japanese case suffixes as if they wereuseless appendages which have no syntactic role, POPuses them as integral parts of the input data and, as aresult, it does not have to require the input sentences toconform to the "canonical word order".
As illustratedin subsection 3.2.2, POP first constructs an expandedsentence tree frame using the SNP patterns that matchthe SNA's of the derivational suffixes.
After this ex-panded frame is completed, arguments are popped fromthe STACK and attached to appropriate nodes in theusual manner.
Note that the flag specifications on thetree frame are automatically adjusted in course of itsexpansion, so no further adjustment resorting to the"canonical word order" or scrambling is necessary.28 Computational Linguistics, Volume 14, Number I, Winter 1988Paul T. Sato A Common Parsing Scheme for Left- and Right-Branching Languages4.2 EMBEDDED SENTENCESAs illustrated in subsection 3.2.3, POP handles Japa-nese complex sentences with relative clauses withoutfacing combinatorial explosion.
Especially noteworthyis the similarity in the PHP instructions to assemblenoun phrases with relative clause in Japanese (37) and inEnglish (58), which are paraphrased in (62).
(62) PHP entries for assembling NP with a relativeclausea.
For Japanese = (37):1.
Pop the TOS (which is a sentence with anempty NP node).2.
Attach a copy of the CWS (which is an NP)to the first matching empty node of thepopped sentence tree.3.
Assemble a new NP tree with the CWS asits HEAD and the sentence tree assembledin step 2 as its MOD(ifier).b.
For English = (58):1.
Pop the TOS (which is a sentence with amarked NP).2.
Assemble a new NP tree with the markedNP of the sentence popped in step I as itsHEAD and the CWS (which is a sentencetree containing an NP node co-indexed withthe marked NP according to (52)) as itsMOD.The only major difference between the two is that inJapanese (62a) the relative clause is in the STACK whenthe head NP is encountered, while in English (62b) thehead NP is a branch of an S tree in the STACK when therelative pronoun is encountered.
This difference is anatural consequence of the difference in word orderbetween the two languages (i.e., left-branching vs.right-branching).An important fact is that POP for Japanese does nothave to know in advance whether the sentence fragmentthat it is processing is a matrix sentence like (4a) or anembedded sentence like (4b) through (4e).4.3 COMPARISON WITH MARCUS'S PARSIFALThe reader may have wondered if there is any directrelationship between POP and Marcus's PARSIFALMarcus (1980): both are bottom-up arsers, where at-tachment can be made freely to any matching node inthe ACTIVE NODE STACK (Marcus) or the CWS(POP).
Therefore, a brief comparison of these twosystems may be in order.When I heard about Marcus's work for the first time,the development of POP was already well under way: itsbasic algorithm was already completed and coding hadalready started.
Therefore, the similarity between PAR-SIFAL and POP, if any, is only accidental.
Moreover,the basic philosophies of these two systems are differ-ent.
Marcus's goal was to build a "strictly determinis-tic" parser for natural anguage; mine was to build aparser that can handle not only right-branching sen-tences but also left-branching sentences naturally andwithout facing a combinatorial explosion.
POP does nothave any back-tracking or parallel parsing mechanism,but the lack of such mechanism was a consequence ofthe parser's algorithm and not an intended goal.In fact, the only significant similarity between PAR-SIFAL and POP is between the former's pattern/actionrules and the latter's PHP entries.
The latter can berewritten using the format of the former.
However, thesimilarity ends here.
PARSIFAL's rules are partiallyordered by a priority scheme; POP's PHP entries arenot ordered nor do they have priority over any otherentries in the PHP.
In PARSIFAL, a grammar uleactivates a packet by attaching it to the constituent atthe bottom of the ACTIVE NODE STACK, and thepacket of rules remains attached to the node even afterthe node is pushed up.
6 Such rules remain dormant untilthe node to which they are attached comes at thebottom of the ACTIVE NODE STACK again.
On theother hand, POP's PHP pattern does not remain withany node after a phrase tree (or an S tree) is assembledand pushed to the STACK.
A copy of PHP pattern isretrieved from the data base each time it becomesnecessary.
This strategy saves the memory space in theSTACK, although it requires a longer processing time.POP lacks one of PARSIFAL's most significantcharacteristics: the distinction between the ACTIVENODE STACK and the BUFFER.
POP also distin-guishes the place where trees are actually constructed(which I informally call here the "work space") and theplace where the results are stored (i.e., the STACK).However, the similarity again ends here.
POP's "workspace" is neither a stack nor a buffer, but a machine-dependent temporary memory space where the program(ASSEMBLE-NP, ASSEMBLE-SENTENCE, etc.)
re-trieves and manipulates partial trees popped from theSTACK or lexical entries copied from the LEXICON.Unlike PARSIFAL's ACTIVE NODE STACK, POP's"work space" cannot store any partially completed treewhich is not "active".
Such inactive partial trees arestored in the STACK.PARSIFAL's BUFFER is primarily a facility for"look-ahead".
Therefore, it contains unprocessed inputwords as well as phrase trees with no empty node.
Itcontains no phrase tree which has empty nodes, be-cause such trees are stored in the ACTIVE NODESTACK.
In contrast, the primary purpose of POP'sSTACK is to store tree fragments and tree frames.
It isnot a "look-ahead" facility and therefore does notcontain any unprocessed input word.
When POP'sPROCESSOR looks at an input word, it must process itimmediately.POP can process sentences like (4) without back-tracking or any look-ahead mechanism, while suchsentences would remain "garden path sentences" forMarcus's parser even with its limited look-ahead mech-anism.Computational Linguistics, Volume 14, Number 1, Winter 1988 29Paul T. Sato A Common Parsing Scheme for Left- and Right-Branching Languages5 CONCLUSIONPOP as presented in this paper is still in its evolvingstage, and it needs further ef inement.
For  example, wecould include in the common POP core such meta rulesas "at tach feature <ANIMATE> to AGNT node" .
Assuggested in section 1, we could also augment POP withprocedures to bui ld semantic  interpretat ions along withsyntactic analysis.
Such ref inements and improvementswill cont inue.However ,  the basic l inguistic theory under ly ing myscheme may not have to undergo a radical change in theprocess.
According to the theory under ly ing this work,it is not a set of patterns or rewrit ing rules that singlydetermines the grammatical  sentences of a language.Rather, it is the patterns (SNP) in conjunct ion withprocedures (PHP) and POP 's  meta rules that do so.
Intother words, this system points the way to a slightly/' different view of grammar competence than a basical lyChomskian one, in which one provides a competencegrammar that incorporates processing while leavingaside details of performance.REFERENCESBerwick, Robert C. and Weinberg, Amy S. 1982 Parsing Efficiency,Computational Complexity, and the Evaluation of GrammaticalTheories.
Linguistic Inquiry 13(2): 165-191.Bresnan, Joan W. 1978 A Realistic Transformational Grammar.
InHalle, Morris; Bresnan, Joan W.; and Miller, G. A., Eds.,Linguistic Theory and Psychological Reality.
MIT Press, Cam-bridge, Massachusetts: 1-59.Fillmore, Charles J.
1968 The Case for Case.
In Bach, E. and Harms,R.T., Eds., Universals in Linguistic Theory.
Holt, Rinehart andWinston, New York.Fodor, Janet D. 1979 Superstrategy.
In Cooper, William E. andWalker, Edward C.T., Eds., Sentence Processing: Psycholinguis-tic Studies Presented to Merrill Garrett.
Lawrence Erlbaum,Hillsdale, New Jersey: 249-279.Kaplan, Ronald M. 1972 Augme.nted Transition Networks as Psycho-logical Models of Sentence Comprehension.
Artificial Intelligence3:77-100.Kuno, Susumu.
1973 The Structure of the Japanese Language.
MITPress, Cambridge, Massachusetts.Kuroda, S-Y.
1976 A lecture given to graduate students and facultymembers of the Linguistics Department of the University ofMassachusetts atAmherst.Marcus, Mitchell P. 1980 A Theory of Syntactic Recognition forNatural Language.
MIT Press, Cambridge, Massachusetts.Miyagawa, Shigeru.
1980 Complex Verbs and the Lexicon.
CoyotePapers, Vol.
1.
University of Arizona, Tucson, Arizona.
(Orig-inally a Ph.D. dissertation, University of Arizona.
)Sato, Paul T. 1982 The Status of "Particles" and Its TypologicalImplications.
Papers in Japanese Linguistics 8:191-205.Sato, Paul T. 1983a On-line Parsing Strategies for English andJapanese.
A panel presentation at AAS Symposium on JapaneseLanguage on the Computer, in San Francisco, California.Sato, Paul T. 1983b Lexicalist vs. Tarnsformationalist Hypothesis onParsing Japanese Phrases with Complex Verbs.
Presented at theLinguistic Conference on East Asian Languages: Verb Phrases, inLos Angeles, California.
(Reprinted in Kim, Nam-Kil and Tiee,Henry H., Eds.
1985 Studies in East Asian Linguistics.
Depart-ment of East Asian Languages and Cultures, University of South-ern California, Los Angeles, California: 155-165.
)Tomita, Masaru.
1986 Efficient Parsing for Natural Language: A FastAlgorithm for Practical Systems.
Kluwer Academic Publishers,Boston, Massachusetts.Wanner, E. and Maratsos, M. 1978 An ATN Approach to Compre-hension.
In Halle, Morris; Bresnan, Joan W.; and Miller, G.A.,Eds., Linguistic Theory and Psychological Reality.
MIT Press,Cambridge, Massachusetts: 119-161.Woods, William A.
1970 Transition Network Grammar for NaturalLanguage Analysis.
Communications ofthe ACM 13:591-606.Woods, William A.
1973 An Experimental Parsing System for Tran-sition Networks.
In Rustin, R., Ed., Natural Language Process-ing.
Algorithmics Press, New York: I 11-154.NOTES1.
These postnominal suffixes are usually called "particles", but seeSato (1982).2.
For the sake of readability, I present all PHP entries cited in thispaper in their English translation.3.
"John" is an abbreviation of a bundle of features, <N,+PROPER, +HUMAN, +MALE, -PLURAL .
.
.
.
>.
For con-venience' sake, such feature bundles are often rendered in thispaper by an English word enclosed in quotation marks.4.
In fact, this <Q> attachment does not add another <Q> to the Vnode because there is already a <Q> there.
Note that POP'sattachment function uses UNION.5.
As mentioned insection 2, POP always keeps a copy of the mostrecently assembled NP in LNP REGISTER, or the "last (assem-bled) NP register", although I have not indicated this each time itoccurred.6.
Marcus (1980) uses the phrase "associate with" instead of"attach to" here.
PARSIFAL's ACTIVE NODE STACK growsdownward.30 Computational Linguistics, Volume 14, Number 1, Winter 1988
