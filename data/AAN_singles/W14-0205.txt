Proceedings of the of the EACL 2014 Workshop on Dialogue in Motion (DM), pages 33?37,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsA Natural Language Instructor for pedestrian navigation based ingeneration by selectionSantiago AvalosLIIS Group, FaMAFUniversidad Nacional de C?ordobaC?ordoba, Argentinasantiagoe.avalos@gmail.comLuciana BenottiLIIS Group, FaMAFUniversidad Nacional de C?ordobaC?ordoba, Argentinaluciana.benotti@gmail.comAbstractIn this paper we describe a method fordeveloping a virtual instructor for pedes-trian navigation based on real interactionsbetween a human instructor and a humanpedestrian.
A virtual instructor is an agentcapable of fulfilling the role of a humaninstructor, and its goal is to assist a pedes-trian in the accomplishment of differenttasks within the context of a real city.The instructor decides what to say usinga generation by selection algorithm, basedon a corpus of real interactions generatedwithin the world of interest.
The instructoris able to react to different requests by thepedestrian.
It is also aware of the pedes-trian position with a certain degree of un-certainty, and it can use different city land-marks to guide him.1 Introduction and previous workVirtual instructors are conversational agents thathelp a user perform a task.
These agents can beuseful for many purposes, such as language learn-ing (Nunan, 2004), training in simulated envi-ronments (Kim et al., 2009) and entertainment(Dignum, 2012; Jan et al., 2009).Navigation agents generate verbal route direc-tions for users to go from point A to point B ina given world.
The wide variety of techniques toaccomplish this task, range from giving completeroute directions (all route information in a singleinstruction), to full interactive dialogue systemswhich give incremental instructions based on theposition of the pedestrian.
Although it can recog-nize pre-established written requests, the instruc-tor presented in this work is not able to interpretutterances from the pedestrian, leaving it unable togenerate a full dialogue.
The instructor?s decisionsare based on the pedestrian actual task, his posi-tion in the world, and the previous behavior fromdifferent human instructors.
In order to guide auser while performing a task, an effective instruc-tor must know how to describe what needs to bedone in a way that accounts for the nuances ofthe virtual world and that is enough to engage thetrainee or gamer in the activity.There are two main approaches toward automat-ically producing instructions.
One is the selectionapproach, in which the task is to pick the appropri-ate output from a corpus of possible outputs.
Theother is the composition approach, in which theoutput is dynamically assembled using some com-position procedure, e.g.
grammar rules.The natural language generation algorithm usedin this work is a modified version of the generationby selection method described in (Benotti and De-nis, 2011).The advantages of generation by selection aremany: it affords the use of complex and human-like sentences, the system is not bound to use writ-ten instructions (it may easily use recorded audioclips, for example), and finally, no rule writing bya dialogue expert or manual annotations is needed.The disadvantage of generation by selection is thatthe resulting dialogue may not be fully coherent(Shawar and Atwell, 2003; Shawar and Atwell,2005; Gandhe and Traum, 2007).In previous work, the selection approach togeneration has been used in non task-orientedconversational agents such as negotiating agents(Gandhe and Traum, 2007), question answeringcharacters (Leuski et al., 2006) and virtual pa-tients (Kenny et al., 2007).
In the work pre-sented in this paper, the conversational agent istask-oriented.In Section 2 we introduce the framework usedin the interaction between the navigation agent andthe human pedestrians.
We discuss the creation ofthe human interaction corpus and the method fornatural language generation in Section 3; And inSection 4 we explain the evaluation methods and33the expected results.2 The GRUVE frameworkOne of the major problems in developing systemsthat generate navigation instructions for pedestri-ans is evaluating them with real users in the realworld.
This evaluations are expensive, time con-suming, and need to be carried out not just at theend of the project but also during the developmentcycle.Consequently, there is a need for a commonplatform to effectively compare the performancesof several verbal navigation systems developed bydifferent teams using a variety of techniques.The GIVE challenge developed a 3D virtual in-door environment for development and evaluationof indoor pedestrian navigation instruction sys-tems (Byron et al., 2007; Koller et al., 2007).In this framework, users walk through a buildingwith rooms and corridors, and interact with theworld by pressing buttons.
The user is guided bya navigation system that generates route instruc-tions.The GRUVE framework presented in (Ja-narthanam et al., 2012) is a web-based environ-ment containing a simulated real world in whichusers can simulate walking on the streets of realcities whilst interacting with different navigationsystems.
This system focus on providing a simu-lated environment where people can look at land-marks and navigate based on spatial and visual in-structions provided to them.
GRUVE also pro-vides a embedded navigation agent, the BuddySystem, which can be used to test the framework.Apart from the virtual environment in which theyare based an important difference between GIVEand GRUVE is that, in GRUVE, there is a cer-tain degree of uncertainty about the position of theuser.Figure 1: Snapshot of the GRUVE web-client.GRUVE presents navigation tasks in a game-world overlaid on top of the simulated real world.The main task consists of a treasure hunting simi-lar to the one presented in GIVE.
In our work, weuse a modified version of the original framework,in which the main task has been replaced by a setof navigation tasks.The web-client (see Figure 1) includes an inter-action panel that lets the user interact with his nav-igation system.
In addition to user location infor-mation, users can also interact with the navigationsystem using a fixed set or written utterances.
Theinteraction panel provided to the user consists of aGUI panel with buttons and drop-lists which canbe used to construct and send requests to the sys-tem in form of abstract semantic representations(dialogue actions).3 The virtual instructorThe virtual instructor is a natural language agentthat must help users reach a desired destinationwithin the virtual world.
Our method for devel-oping an instructor consists of two phases: an an-notation phase and a selection phase.
In Section3.1 we describe the annotation phase.
This is per-formed only once, when the instructor is created,and it consists of automatically generating a cor-pus formed by associations between each instruc-tion and the reaction to it.
In Section 3.2 we de-scribe how the utterance selection is performed ev-ery time the virtual instructor generates an instruc-tion.3.1 AnnotationAs described in (Benotti and Denis, 2011), the cor-pus consists in recorded interactions between twopeople in two different roles: the Direction Giver(DG), who has knowledge of how to perform thetask, and creates the instructions, and the Direc-tion Follower (DF), who travels through the envi-ronment following those instructions.The representation of the virtual world is givenby a graph of nodes, each one representing an in-tersection between two streets in the city.
GRUVEprovides a planner that can calculate the optimalpath from any starting point to a selected desti-nation (this plan consists in the list of nodes theuser must travel to reach the desired destination).As the DF user walks through the environment, hecannot change the world that surrounds him.
Thissimplifies the automatic annotation process, and34the logged atoms are:?
user position: latitude and longitude, indicat-ing position relative to the world.?
user orientation: angle between 0-360, indi-cating rotation of the point of view.In order to define the reaction associated to eachutterance, it is enough to consider the position towhich the user arrives after an instruction has beengiven, and before another one is requested.
Ninedestinations within the city of Edinburgh were se-lected to be the tasks to complete (the task is toarrive to each destination, from a common startingpoint, see Figure 2).
Each pair of DG and DF hadto complete all tasks and record their progress.Figure 2: The 9 selected tasks .For the creation of the corpus, a slightly mod-ified version of the GRUVE wizards-desk wasused.
This tool is connected to the GRUVE web-client, and allows a human user to act as DF, gen-erating instructions to assist the user in the com-pletion of the task and monitoring his progression.Each instruction generated by a DG was numberedin order, in relation to each task.
For example: ifthe fifth instruction given by the third DG, whileperforming the second task, was ?Go forward andcross the square?, then that instruction was num-bered as follows:5.3.2?
?Go forward and cross the square?.This notation was included to maintain the gener-ation order between instructions (as the tasks weregiven in an arbitrary specific order for each DG).With last-generated, we refer to the instructionsthat were generated in the last 3 runs of each DG.This notion is needed to evaluate the effect of theincreasing knowledge of the city (this metric is ex-plained in Section 4).As discussed in (Benotti and Denis, 2011) mis-interpreted instructions and corrections result inclearly inappropriate instruction-reaction associa-tions.
Since we want to avoid any manual anno-tation, but we also want to minimize the quantityof errors inside the corpus, we decided to createa first corpus in which the same person portraitsthe roles of DG and DF.
This allows us to elim-inate the ambiguity of the instruction interpreta-tion on the DF side, and eliminates correction in-structions (instructions that are of no use for guid-ance, but were made to correct a previous errorfrom the DG, or a wrong action from the DF).Later on, each instruction in this corpus was per-formed upon the virtual world by various othersusers, their reactions compared to the original re-action, and scored.
For each task, only the instruc-tions whose score exceeded an acceptance thresh-old remained in the final corpus.3.2 Instruction selectionThe instruction selection algorithm, displayed inAlgorithm 1 consists in finding in the corpus theset of candidate utterances C for the current taskplan P, which is the sequence of actions that needsto be executed in the current state of the virtualworld in order to complete the task.
We use theplanner included in GRUVE to create P. We de-fine:C = {U ?
Corpus | P starts with U.Reaction}In other words, an utterance U belongs to C if thefirst action of the current plan P exactly matchesthe reaction associated to the utterance U. When-ever the plan P changes, as a result of the actionsof the DF, we call the selection algorithm in orderto regenerate the set of candidate utterances C.Algorithm 1 Selection AlgorithmC ?
?action?
nextAction(currentObjective)for all Utterance U ?
Corpus doif action = U.Reaction thenC ?
C ?
Uend ifend forAll the utterances that pass this test are consid-ered paraphrases and hence suitable in the currentcontext.
Given a set of candidate paraphrases, onehas to consider two cases: the most frequent casewhen there are several candidates and the possiblecase when there is no candidate.35?
No candidate available: If no instruction isselected because the current plan cannot bematched with any existing reaction, a default,neutral, instruction ?go?
is uttered.?
Multiple candidates available: When multi-ple paraphrases are available, the agent mustselect one to transmit to the user.
In this case,the algorithm selects one from the set of thelast-generated instructions for the task (seeSection 3.1).4 Evaluation and expected resultsIs this section we present the metrics and evalua-tion process that will be performed to test the vir-tual instructor presented in Section 3, which wasgenerated using the dialogue model algorithm in-troduced in Section 3.2.4.1 Objective metricsThe objective metrics are summarized below:?
Task success: successful runs.?
Canceled: runs not finished.?
Lost: runs finished but failed.?
Time (sec): average for successful runs.?
Utterances: average per successful run.With this metrics, we will compare 3 systems:agents A, B and C.Agent A is the GRUVE buddy system, whichis provider by the GRUVE Challenge organizersas a baseline.
Agent B consists of our virtual in-structor, configured to select a random instructionwhen presented with multiple candidates (see Sec-tion 3.1).
Agent C is also our virtual instructor, butwhen presented with several candidates, C selectsa candidate who is also part of the last-generatedset.
As each task was completed in different or-der by each DG when the corpus was created, itis expected that in every set of candidates, themost late-generated instructions were created withgreater knowledge of the city.4.2 Subjective metricsThe subjective measures will be obtained from re-sponses to a questionnaire given to each user at theend of the evaluation, based partially on the GIVE-2 Challenge questionnaire (Koller et al., 2010).
Itask users to rate different statements about the sys-tem using a 0 to 10 scale.The questionnaire will include 19 subjectivemetrics presented below:Q1: The system used words and phrases thatwere easy to understand.Q2: I had to re-read instructions to understandwhat I needed to do.Q3: The system gave me useful feedback about myprogress.Q4: I was confused about what to do next.Q5: I was confused about which direction to goin.Q6: I had no difficulty with identifying the objectsthe system described for me.Q7: The system gave me a lot of unnecessaryInformation.Q8: The system gave me too much information allat once.Q9: The system immediately offered help when Iwas in trouble.Q10: The system sent instructions too late.Q11: The systems instructions were delivered tooearly.Q12: The systems instructions were clearlyworded.Q13: The systems instructions sounded robotic.Q14: The systems instructions were repetitive.Q15: I lost track of time while solving the overalltask.Q16: I enjoyed solving the overall task.Q17: Interacting with the system was reallyannoying.Q18: The system was very friendly.Q19: I felt I could trust the systems instructions.Metrics Q1 to Q12 assess the effectiveness andreliability of instructions, while metrics Q13 toQ19 are intended to assess the naturalness of theinstructions, as well as the immersion and engage-ment of the interaction.4.3 Expected resultsBased on the results obtained by (Benotti and De-nis, 2011) in the GIVE-2 Challenge, we expect agood rate of successful runs for the agent.
Further-more, the most interesting part of the evaluationresides in the comparison between agents B and C.We expect that the different selection methods ofthis agents, when presented with multiple instruc-tion candidates, can provide information about theform in which the level of knowledge of the vir-tual world or environment modifies the capacityof a Direction Giver to create correct, and useful,instructions.36ReferencesLuciana Benotti and Alexandre Denis.
2011.
Giv-ing instructions in virtual environments by corpusbased selection.
In Proceedings of the SIGDIAL2011 Conference, SIGDIAL ?11, pages 68?77.
As-sociation for Computational Linguistics.D.
Byron, A. Koller, J. Oberlander, L. Stoia, andK.
Striegnitz.
2007.
Generating instructions in vir-tual environments (give): A challenge and evalua-tion testbed for nlg.
In Proceedings of the Work-shop on Shared Tasks and Comparative Evaluationin Natural Language Generation.Frank Dignum.
2012.
Agents for games and simula-tions.
Autonomous Agents and Multi-Agent Systems,24(2):217?220, March.S.
Gandhe and D. Traum.
2007.
First steps towarddialogue modelling from an un-annotated human-human corpus.
In IJCAI Workshop on Knowledgeand Reasoning in Practical Dialogue Systemss.Dusan Jan, Antonio Roque, Anton Leuski, Jacki Morie,and David Traum.
2009.
A virtual tour guide forvirtual worlds.
In Proceedings of the 9th Interna-tional Conference on Intelligent Virtual Agents, IVA?09, pages 372?378, Berlin, Heidelberg.
Springer-Verlag.Srinivasan Janarthanam, Oliver Lemon, and XingkunLiu.
2012.
A web-based evaluation framework forspatial instruction-giving systems.
In Proceedingsof the ACL 2012 System Demonstrations, ACL ?12,pages 49?54.
Association for Computational Lin-guistics.Patrick Kenny, Thomas D. Parsons, Jonathan Gratch,Anton Leuski, and Albert A. Rizzo.
2007.
Vir-tual patients for clinical therapist skills training.
InProceedings of the 7th International Conference onIntelligent Virtual Agents, IVA ?07, pages 197?210,Berlin, Heidelberg.
Springer-Verlag.Julia M. Kim, Randall W. Hill, Jr., Paula J. Durlach,H.
Chad Lane, Eric Forbell, Mark Core, StacyMarsella, David Pynadath, and John Hart.
2009.
Bi-lat: A game-based environment for practicing nego-tiation in a cultural context.
Int.
J. Artif.
Intell.
Ed.,19(3):289?308, August.A.
Koller, J. Moore, B. Eugenio, J. Lester, L. Stoia,D.
Byron, J. Oberlander, and K. Striegnitz.
2007.Shared task proposal: Instruction giving in virtualworlds.
In In Workshop on Shared Tasks and Com-parative Evaluation in Natural Language Genera-tion.Alexander Koller, Kristina Striegnitz, Andrew Gargett,Donna Byron, Justine Cassell, Robert Dale, JohannaMoore, and Jon Oberlander.
2010.
Report on thesecond nlg challenge on generating instructions invirtual environments (give-2).
In Proceedings ofthe 6th International Natural Language GenerationConference, INLG ?10, pages 243?250.
Associationfor Computational Linguistics.Anton Leuski, Ronakkumar Patel, David Traum, andBrandon Kennedy.
2006.
Building effective ques-tion answering characters.
In Proceedings of the 7thSIGdial Workshop on Discourse and Dialogue, Sig-DIAL ?06, pages 18?27.
Association for Computa-tional Linguistics.David Nunan.
2004.
Task-based language teaching.University Press, Cambridge.B.A.
Shawar and E. Atwell.
2003.
Using dialoguecorpora to retrain a chatbot system.
In Proceedingsof the Corpus Linguistics Conference, pages 681?690.B.A.
Shawar and E. Atwell.
2005.
Using corporain machine-learning chatbot systems.
InternationalJournal of Corpus Linguistics, 10:489?516.37
