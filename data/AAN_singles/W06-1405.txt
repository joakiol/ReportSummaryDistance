Proceedings of the Fourth International Natural Language Generation Conference, pages 25?32,Sydney, July 2006. c?2006 Association for Computational LinguisticsIndividuality and Alignment in Generated DialoguesAmy Isard and Carsten Brockmann and Jon OberlanderSchool of Informatics, University of Edinburgh2 Buccleuch PlaceEdinburgh EH8 9LW, UK{Amy.Isard, Carsten.Brockmann, J.Oberlander}@ed.ac.ukAbstractIt would be useful to enable dialogueagents to project, through linguisticmeans, their individuality or personality.Equally, each member of a pair of agentsought to adjust its language (to a greater orlesser extent) to match that of its interlocu-tor.
We describe CRAG, which generatesdialogues between pairs of agents, who arelinguistically distinguishable, but able toalign.
CRAG-2 makes use of OPENCCGand an over-generation and ranking ap-proach, guided by a set of language mod-els covering both personality and align-ment.
We illustrate with examples of out-put, and briefly note results from user stud-ies with the earlier CRAG-1, indicatinghow CRAG-2 will be further evaluated.Related work is discussed, along with cur-rent limitations and future directions.1 IntroductionA computer agent should be individual.
Nassand collaborators find that users?
responsesto computer-agents are influenced by whetherthe agent?s linguistic personality matches?ormismatches?the personality of the user (Moonand Nass, 1996; Nass and Lee, 2000).
Similarly,characters in virtual environments should be dis-tinctive (Ball and Breese, 2000; Rist et al, 2003).But an aspect of personality is how well you adjustto other people (and their language use): align-ment.
Pickering and Garrod?s Interactive Align-ment Model suggests that people tend to automat-ically converge on lexical and syntactic choices,via a low-level mechanism of interpersonal prim-ing (Pickering and Garrod, 2004), and Brennanhas shown that people will align their language to-wards that of computer agents (Brennan, 1996).But it is an open issue as to whether some peo-ple are better ?aligners?
than others.
Conversely,alignment is only visible and interesting (amongcomputer agents) if they start out being individual.We therefore set out to simulate both individ-uality and alignment.
The paper briefly surveysthe evidence for linguistic personality, for inter-personal alignment, and for interaction betweenthem.
It then sketches the current version ofCRAG.
CRAG-2 makes use of OPENCCG andan over-generation and ranking approach, guidedby a set of language models for personality andalignment.
We illustrate the differing linguis-tic behaviours that it generates, and briefly notepromising results from user studies with the ear-lier CRAG-1 system, indicating how CRAG-2 willbe further evaluated.
Related work is discussed,along with possible directions for future work.2 Background2.1 Personality and LanguageCurrent work on personality traits is dominated byCosta and McCrae?s five-factor model (Costa andMcCrae, 1992).
The five factors, or dimensions,are: Extraversion; Neuroticism; Openness; Agree-ableness; and Conscientiousness (Matthews et al,2003).
It has been shown that scores on these di-mensions correlate with some aspects of languageuse (Scherer, 1979; Dewaele and Furnham, 1999).In studies of text, the focus has been on lexicalchoice, and Pennebaker and colleagues have anal-ysed relative frequencies of use of word-stems ina dictionary structured into semantic and syntac-tic categories (Pennebaker et al, 2001).
Amongstother results, they have shown that High Extraverts25use: more social process talk, positive emotionwords and inclusives; and fewer negations, ten-tative words, exclusives, causation words, nega-tive emotion words, and articles (Pennebaker andKing, 1999; Pennebaker et al, 2002).Computational linguistic exploitation of suchempirically-derived features has been limited.
Onthe one hand, in generation, there has been workon personality-based generation.
For instance, indeveloping embodied conversational agents, re-searchers have designed agents or teams of agentswith distinguishable linguistic personalities (Balland Breese, 2000; Rist et al, 2003; Piwek andvan Deemter, 2003; Gebhard, 2005).
However,the linguistic behaviour is usually informed byrules based on personality stereotypes, rather thanon language statistics themselves.
On the otherhand, in interpretation, more empirical work hasrecently been carried out, to enable text classifi-cation.
Argamon et al (2005) attempted to clas-sify authors as High or Low Extravert and Highor Low Neurotic, using Pennebaker and King?s(1999) data.
They report classification accuraciesof around 58% (with a 50% baseline).
Oberlanderand Nowson (2006) undertake a comparable task,using weblog data.
They report classification ac-curacies of roughly 85% (Neuroticism) and 94%(Extraversion), and comparable figures for Agree-ableness and Conscientiousness.
Such studies canprovide ordered lists of linguistic features whichare useful for distinguishing language producers,and we will return to this, below.2.2 Alignment and LanguagePeople converge with their interlocutors in linguis-tic choices at a number of levels (Pickering andGarrod, 2004).
The phenomena can be seen inboth social and cognitive terms.
On the social side,co-operative processes such as audience designare usually considered to be conscious, at least inpart (Bell, 1984).
But on the cognitive side, co-ordinative processes such as alignment are usu-ally considered to be largely automatic (Garrodand Doherty, 1994).
Alignment can be probedby psycholinguistic tests for interpersonal prim-ing, establishing the extent to which participantsare more likely to use a lexical item or syntac-tic construction after hearing their conversationalpartner use it.
Syntactic priming experiments in-volve constructions such as passives, and ditransi-tives (Pickering and Branigan, 1998).It is possible that some people are strongeraligners than others.
Gill et al (2004) probedsyntactic priming for passives, and investigatedwhether levels of Extraversion or Neuroticismwould affect the strength of priming effects.
Itwas found that Extraversion has no effect, but thatNeuroticism has a non-linear effect: both High andLow levels of Neuroticism led to weaker priming;Mid levels led to significantly stronger priming.Given this, if a generation system is going to simu-late alignment, it is probably worth designing it sothat it can simulate agents with differing propensi-ties to align.3 The CRAG System OverviewThe system described in the following sections(CRAG-2) is the successor to CRAG-1 which isdetailed in Isard et al (2005).
The system gener-ates a dialogue between two computer agents onthe subject of opinions about a film.
CRAG-2 usesthe OPENCCG parsing and generation framework(White, 2004; White, 2006).
The realiser com-ponent takes a logical form as input and outputsa list of candidate sentences ranked using one ormore language models.
In CRAG-2, we use theOPENCCG generator to massively over-generateparaphrases, and the combination of n-gram mod-els described in Section 4 to choose the best ut-terance according to a character?s personality andagenda, and the dialogue history.4 N-Grams: Personality and AlignmentModelling4.1 N-Gram Language ModelsThe basic assumption underlying CRAG-2 is thatpersonality, as well as alignment behaviour, canbe modelled by the combination of a variety of n-gram language models.Language models are trained on a corpus andsubsequently used to compute probability scoresof word sequences.
An n-gram language modelapproximates the probability of a word given itshistory of the preceding n?
1 words.
Accordingto the chain rule, probabilities are then combinedby multiplication.
Equation (1) shows a trigrammodel that takes into account two words of contextto predict the probability of a word sequence wn1:(1) P(wn1)?n?i=1P(wi|wi?1i?2)264.2 Avoiding the Length EffectBecause word probabilities are always less than 1and therefore each multiplication decreases the to-tal, if we use this standard model, longer sentenceswill always receive lower scores (this is known asthe length effect).
We therefore calculate the prob-ability of a sentence as the geometric mean of theprobability of each word in the sentence as shownin (2):(2) P(wn1)?n?i=1P(wi|wi?1i?2)1/n4.3 Linear Combination of Language ModelsOPENCCG supports the linear combination oflanguage models, where each model is assigned aweight.
For uniform interpolation of two languagemodels Pa and Pb, each receives equal weight:(3) P(wi|wi?1i?2) =Pa(wi|wi?1i?2)+Pb(wi|wi?1i?2)2In the more general case, the language modelsare assigned weights ?i, the sum of which has tobe 1:(4) P(wi|wi?1i?2) = ?1Pa(wi|wi?1i?2)+?2Pb(wi|wi?1i?2)For example, setting ?1 = 0.9 and ?2 = 0.1 assignsa high weight to the first language model.4.4 OPENCCG N-Gram RankingIn the OPENCCG framework, language modelscan be used to influence the chart-based realisationprocess.
The agenda of edges is re-sorted accord-ing to the score an edge receives with respect to alanguage model.
For CRAG-2, many paraphrasesare generated from a given logical form, and theyare then ranked in order of probability accordingto the combination of n-gram models appropriatefor the character and stage of the dialogue.5 CRAG-2 Personality and AlignmentModelsWe use the SRILM toolkit (Stolcke, 2002) to com-pute our language models.
All models (exceptfor the cache language model described in Sec-tion 5.4) are trigram models with backoff to bi-grams and unigrams.We have experimented with two strategies forcreating personality models.
Since we want tostudy the effects of alignment as well as person-ality, it is essential that the two characters in a di-alogue be distinct from one another, so that the ef-fects of alignment can be seen.
The first strategyinvolves using typical language for each personal-ity trait, and the second uses the language of oneindividual.
In both cases, the language models de-scribed in the following sections are combined asdescribed in Section 5.5.5.1 Building a PersonalityNowson (2006) performed a study on languageuse in weblogs.
The weblog authors were asked tocomplete personality questionnaires based on thefive-factor model (see Section 2.1).
All weblog au-thors scored High or Medium on the Openness di-mension, so we have no data for typical Low Openlanguage.We divided the data into High, Medium andLow for each personality dimension, and trainedlanguage models so that we would be able to as-sess the probability of a word sequence given apersonality type.
This means that each individualweblog is used 5 times, once for each dimension.For each personality dimension, the system sim-plifies a character?s personality setting x by assign-ing a value of High (x > 70), Medium (30 < x ?70) or Low (x ?
30).
The five models correspond-ing to the character?s assigned personality are uni-formly interpolated to give the final personalitymodel.
If the character has been given a low Open-ness score, since we do not have a model for thispersonality type, we simply interpolate the otherfour models.5.2 Borrowing a PersonalityOur second strategy was to train n-gram modelson language of the individuals from the CRAG-1corpus (Isard et al, 2005) and to use one of thesemodels for each character in the dialogue.5.3 Base Language ModelIn the case of building a personality, a base lan-guage model is obtained by combining a languagemodel computed from the corpus collected for theCRAG-1 system and a general language modelbased on data from the Switchboard corpus (Stol-cke et al, 2000).
The combined base model alonewould rank the utterances without any bias for per-sonality or alignment.
When we are borrowing apersonality, the base model is calculated from theSwitchboard corpus alone.275.4 Cache Language ModelWe simulate alignment by computing a cache lan-guage model based on the utterance that was gen-erated immediately before.
This dialogue historycache model is the uniform interpolation of word-and class-based n-gram models, where classes actas a backoff mechanism when there is no exactword match.
Classes group together lexical itemswith similar semantic properties, e.g.:?
good, bad: quality-adjective?
loved, hated: opinion-verbDetails of this approach can be found in Brock-mann et al (2005).5.5 Combining the Language ModelsThe system uses weights to combine all the mod-els described above.
First the base and person-ality models are interpolated to produce a base-personality model, and finally the cache model isintroduced to add alignment effects.6 Dialogue and Utterance Specifications6.1 Character SpecificationTwo computer characters are parameterised fortheir personality by specifying values (on a scalefrom 0 to 100) for the five dimensions: Extraver-sion (E), Neuroticism (N), Openness (O), Agree-ableness (A), and Conscientiousness (C).
Theiralignment behaviour is set to a value between 0(low propensity to align) and 1 (high propensityto align).
Also, each character receives an agendaof topics they wish to discuss, along with polari-ties (positive/negative) that indicate their opinionon the respective topic.6.2 Utterance DesignThe character with the higher Extraversion scorebegins the dialogue, and their first topic is se-lected.
Once an utterance has been generated, theother character is selected, and the system appliesthe algorithm shown in (5) to decide which topicshould come next.
This process continues untilthere are no topics left on the agenda of the cur-rent speaker.
(5) if (A < 46) or (C < 46) or(no.
of utts about this topic = 2)then take next topic from own agendaelse continue on same topicThe system creates a simple XML representa-tion of the character?s utterance, using the speci-fied topic and polarity.
An example using the topicmusic and polarity negative is shown in Figure 1.At this point the system also decides which dis-course connectives may be appropriate, based onthe previous topic and polarity.<utterance><utt topic="music" polarity="dislike"opp-polarity="like" so="no" right="no"also="no" well="yes" and="no" but="no"><pred adj="bad"/><opp-pred adj="good"/></utt></utterance>Figure 1: Simple Utterance Specification6.3 OPENCCG Logical FormsFollowing the method described in Foster andWhite (2004), the basic utterance specification istransformed, using stylesheets written in the XSLtransformation language, into an OPENCCG log-ical form.
We make use of the facility for defin-ing optional and alternative inputs and underspec-ified semantics to massively over-generate candi-date utterances.
A fragment of the logical formwhich results from the transformation of Figure 1is shown in Figure 2.
We also include some frag-ments of canned text from the CRAG corpus in ourOPENCCG lexicon.We also add optional interjections (i mean, youknow, sort of ) and conversational markers (right,but, and, well) where appropriate given the dis-course history.When the full logical form is processed by theOPENCCG system, the output consists of sen-tences of the types shown below:(I think) the music was bad.
(I think) the music was not (wasn?t)good.I did not (didn?t) like the music.I hated the music.One thing I did not (didn?t) like was themusic.One thing I hated was the music.The fragmentary logical form in Figure 2 wouldcreate all possible paraphrases from:(well) (you know) I (kind of) [liked/loved] the[music/score]By using synonyms (e.g., plot=story, com-edy=humour) and combining the sentence types28<node id="l1:opinion" pred="like" tense="past"><rel name="Speaker"><node id="p1:person" pred="pro1" num="sg"/></rel><rel name="Content"><node id="f1:cragtopic" pred="music"det="the" num="sg"/></rel><opt><rel name="Modifier"><node id="w1:adv" pred="well"/></rel><opt><opt><rel name="HasProp"><node id="a2:proposition" pred="kind-of"/></rel></opt><opt><rel name="Modifier"><node id="a1:adv" pred="you-know"/></rel></opt></node>Figure 2: Fragment of Logical FormStan: E:53 N:48 A:57 C:46 O:65agenda: film(neg), dialogue(neg),music(pos)other opinions: plot(neg), comedy(neg)Eddie: E:51 N:43 A:57 C:41 O:65agenda: plot(neg), comedy(neg),dialogue(neg)other opinions: music(pos), film(neg)Figure 3: Stan and Eddieand optional expressions, we create up to 3000possibilities per utterance, and the best candidateis chosen by the specific combination of n-grammodels appropriate for the given personality anddialogue history, as described in Section 4.Our OPENCCG lexicon is based on the coreEnglish lexicon included with the system and wehave added vocabulary appropriate to the moviedomain, and extended the range of grammaticalconstructions where necessary.7 Output and Evaluation7.1 OutputIn this section, we provide some example out-puts from the CRAG-2 system, using charactersbased on participants from our corpus (see Sec-tion 5.2).
Stan is higher on the Extraversion, Neu-roticism, and Conscientiousness scales than Ed-die.
The characters?
personalities and agendas aresummarised in Figure 3.We show three example dialogues between Stanand Eddie.
In the first (Figure 4) neither charac-ter aligns with the other at all, while in the sec-ond (Figure 5) Stan has a slight tendency towardsalignment and in the third (Figure 6) a more pro-nounced tendency.
In system terms, this meansthat in the first dialogue the cache model was givenweight 0, while in the second and third the cachemodel was given weights 0.05 and 0.1 respectivelyfor Stan?s utterances.
It can be seen that in thefirst dialogue, Eddie?s use of humour in utterance4 is followed by Stan?s comedy, and dialogue inutterance 6 is followed by script.
In the seconddialogue, Stan aligns his first lexical choice withEddie?s but not his second, while in the third di-alogue he aligns both.
The syntactic structures ofStan?s utterances in the second and third dialoguealso mirror Eddie?s progressively more closely.1.
Stan: I didn?t think much of the film you know.2.
Eddie: I mean I didn?t like kind of like the story.3.
Stan: Yeah there were so many little pathways that theydidn?t take you know.4.
Eddie: I mean I didn?t think the humour was really funny.5.
Stan: Yeah you know the comedy was a bit dull.6.
Eddie: I mean I didn?t like kind of like the dialogue.7.
Stan: I mean the script was a bit dull.Figure 4: Zero Alignment1.
Stan: I didn?t think much of the film you know.2.
Eddie: I mean I didn?t like kind of like the story.3.
Stan: Yeah there were so many little pathways that theydidn?t take you know.4.
Eddie: I mean I didn?t think the humour was really funny.5.
Stan: I mean the humour was a bit dull.6.
Eddie: I mean I didn?t like kind of like the dialogue.7.
Stan: I mean the script was a bit dull.Figure 5: Little Alignment from Stan1.
Stan: I didn?t think much of the film you know.2.
Eddie: I mean I didn?t like kind of like the story.3.
Stan: I mean the story was a bit dull.4.
Eddie: I mean I didn?t think the humour was really funny.5.
Stan: I mean the humour was a bit dull.6.
Eddie: I mean I didn?t like kind of like the dialogue.7.
Stan: I mean the dialogue was a bit dull.Figure 6: More Alignment from StanTo further illustrate the differences between thedialogues with and without alignment, we providesome utterance rankings.
We show candidatesfor the fifth utterance in each dialogue.
Table 1shows sentences from the example generated with-out alignment, corresponding to utterance 5 (Stan)291 .03317 Yeah you know the comedy was abit dull.3 .03210 Yeah you know the humour was a bitdull.6 .03083 Yeah to be honest I didn?t think thatthe comedy was very good either.15 .02938 I didn?t think much of the comedyeither.24 .02861 I thought that the comedy was a bitdull too you know.Table 1: Ranked Sentences with Zero Alignment1 .05384 I mean the humour was a bit dull.8 .05239 The humour wasn?t really funny youknow.15 .04748 I mean I didn?t think that the humourwas very good either.19 .04518 I didn?t think much of the humoureither you know.21 .04478 I thought the humour was a bit dulltoo you know.Table 2: Ranked Sentences with Little Alignmentfrom Stanfrom Figure 4.
We show the first five occurrencesof different sentence structures (see Section 6.3),with their rank and their geometric mean adjustedscores.Table 2 shows the the top five sentences fromthe fifth utterance from Figure 5 (little alignment),and Table 3 those from Figure 6 (more align-ment).
It can be seen that when more alignmentis present, the syntactic structure used by the pre-vious speaker rises higher in the rankings.7.2 EvaluationWe have not evaluated CRAG-2.
However, wehave evaluated CRAG-1.
The method was to gen-erate a set of dialogues, systematically contrastingcharacters with extreme settings for the personal-ity dimensions (High/Low Extraversion, Neuroti-cism, and Psychoticism1).1CRAG-1 used the simpler PEN three factor personalitymodel.1 .07081 I mean the humour was a bit dull.2 .06432 The humour wasn?t really funny youknow.15 .05516 I mean I didn?t think that the humourwas really funny either.27 .05000 I thought the humour was a bit dulltoo you know.36 .04884 I mean I didn?t think much of the hu-mour either.Table 3: Ranked Sentences with More Alignmentfrom StanHuman subjects were asked to fill in a question-naire to determine their personality.
They werethen given a selection of dialogues to read.
Aftereach dialogue, they were asked to rate their per-ception of the interaction and of the characters in-volved by assigning scores to a number of adjec-tives related to the personality dimensions.It was found that subjects could recognise dif-ferences in the Extraversion level of the language.Also, the personality setting of a character influ-enced the perception of its and its dialogue part-ner?s personality (Kahn, 2006).We plan a similar evaluation for CRAG-2 to beable to compare human raters?
impressions of di-alogues generated by the two systems.
We alsoplan to evaluate CRAG-2 internally by varying theweight given to the underlying language models,and observing the effects this has on the resultingranking of the generated utterances.8 Related WorkRelated work in NLG involves either personalityor alignment.
So far as we can tell, there is littlework on the latter.
Varges (2005) suggests that ?aword similarity-based ranker could align the gen-eration output (i.e.
the highest-ranked candidate)with previous utterances in the discourse context?,but there is no report yet on an implementation ofthis proposal.
A rather different approach is sug-gested by Bateman and Paris (2005), who discussinitial work on alignment, mediated by a processof register-recognition.
Regarding generation withpersonality, the most influential work is probablyHovy?s PAULINE system, which varies both con-tent selection and realisation according to an indi-vidual speaker?s goals and attitudes (Hovy, 1990).In her extremely useful survey of work on affective(particularly, emotional) natural language gener-ation, Belz (2003) notes that the complexity ofPAULINE?s rule system means that numerous ruleinteractions can lead to unpredictable side effects.In response, Paiva and Evans (2004) take a moreempirical line on style generation, which is closerto that pursued here.
Other relevant work includesLoyall and Bates (1997), who explicitly proposethat personality and emotion could be used ingeneration, but Belz observes that technical de-scriptions of Hap and the Oz project suggest thatthe proposals were not implemented.
Walker etal.
?s (1997) system produces linguistic behaviourwhich is much more varied than our current sys-30tem is capable of; but there, variation is driven bya model of social relations (based on Brown andLevinson), rather than on personality.
The NECAproject subsequently developed methods for gen-erating scripts for pairs of dialogue agents (Piwekand van Deemter, 2003), supported by the MIAUplatform (Rist et al, 2003).
The VIRTUALHU-MAN project is a logical successor to this work,and its ALMA platform provides an integrated ap-proach to affective generation, covering emotion,mood and personality (Gebhard, 2005).9 Conclusion and Next StepsOur current system takes a much coarser-grainedapproach to semantics and discourse goals thanthe recent projects described above, in order totake advantage of empirically-derived relationsbetween language and personality.
It should befeasible in principle to move to a more sophisti-cated semantics, but still retain the massive over-generation and ranking method.
However, tosupport more perceptible variation, we need toexploit much larger personality-corpus resourcesthan have been available up to now, and our cur-rent priority is to obtain a corpus at least an orderof magnitude larger than what is currently avail-able.
This interest in individual differences andwhat corpora can (and cannot) tell us about themis one we share with Reiter and colleagues (Reiterand Sripada, 2004).We also plan to integrate techniques fromCRAG-1 and CRAG-2, by passing the ranked out-put of CRAG-2 through further processing andranking stages.
Furthermore, we intend to inves-tigate longer-ranging alignment processes, takinginto account more than one previous utterance,with reduced weight by distance, to emulate mem-ory effects.With these enhancements, we will take furthersteps towards our goal of simulating both individu-ality and alignment in believable computer agents.10 AcknowledgementsThis research has been funded by Scottish Enter-prise through the Edinburgh-Stanford Link project?Critical Agent Dialogue?
(CRAG).
We wouldlike to thank Michael White and Scott Nowson fortheir assistance and our anonymous reviewers fortheir helpful comments.ReferencesShlomo Argamon, Sushant Dhawle, Moshe Koppel,and James W. Pennebaker.
2005.
Lexical predic-tors of personality type.
In Proceedings of the 2005Joint Annual Meeting of the Interface and the Clas-sification Society of North America.Gene Ball and Jack Breese.
2000.
Emotion and per-sonality in a conversational agent.
In J. Cassell,J.
Sullivan, S. Prevost, and E. Churchill, editors, Em-bodied Conversational Agents, pages 189?219.
MITPress, Cambridge, MA, USA.John A. Bateman and Ce?cile L. Paris.
2005.
Adap-tation to affective factors: architectural impacts fornatural language generation and dialogue.
In Pro-ceedings of the Workshop on Adapting the Interac-tion Style to Affective Factors at the 10th Interna-tional Conference on User Modeling (UM-05), Ed-inburgh, UK.Allan Bell.
1984.
Language style as audience design.Language in Society, 13(2):145?204.Anja Belz.
2003.
And now with feeling: Develop-ments in emotional language generation.
Techni-cal Report ITRI-03-21, Information Technology Re-search Institute, University of Brighton, Brighton.Susan E. Brennan.
1996.
Lexical entrainment in spon-taneous dialog.
In Proceedings of the 1996 Inter-national Symposium on Spoken Dialogue (ISSD-96),pages 41?44, Philadelphia, PA.Carsten Brockmann, Amy Isard, Jon Oberlander, andMichael White.
2005.
Modelling alignment for af-fective dialogue.
In Proceedings of the Workshop onAdapting the Interaction Style to Affective Factors atthe 10th International Conference on User Modeling(UM-05), Edinburgh, UK.Paul T. Costa and Robert R. McCrae, 1992.
Re-vised NEO Personality Inventory (NEO-PI-R) andNEO Five-Factor Inventory (NEO-FFI): Profes-sional Manual.
Odessa, FL: Psychological Assess-ment Resources.Jean-Marc Dewaele and Adrian Furnham.
1999.
Ex-traversion: The unloved variable in applied linguis-tic research.
Language Learning, 49:509?544.Mary Ellen Foster and Michael White.
2004.
Tech-niques for Text Planning with XSLT.
In Proc.
of the4th NLPXML Workshop.Simon Garrod and Gwyneth Doherty.
1994.
Conver-sation, co-ordination and convention: an empiricalinvestigation of how groups establish linguistic con-ventions.
Cognition, 53(3):181?215.Patrick Gebhard.
2005.
Alma: a layered model of af-fect.
In AAMAS ?05: Proceedings of the Fourth In-ternational Joint Conference on Autonomous Agentsand Multiagent Systems, pages 29?36, New York,NY, USA.
ACM Press.31Alastair J. Gill, Annabel J. Harrison, and Jon Ober-lander.
2004.
Interpersonality: Individual differ-ences and interpersonal priming.
In Proceedings ofthe 26th Annual Conference of the Cognitive ScienceSociety, pages 464?469.Eduard Hovy.
1990.
Pragmatics and natural languagegeneration.
Artificial Intelligence, 43.Amy Isard, Carsten Brockmann, and Jon Oberlander.2005.
Re-creating dialogues from a corpus.
InProceedings of the Workshop on Using Corpora forNatural Language Generation at Corpus Linguistics2005 (CL-05), pages 7?12, Birmingham, UK.Adam S. Kahn.
2006.
Master?s thesis, Stanford Uni-versity.A.
Bryan Loyall and Joseph Bates.
1997.
Personality-rich believable agents that use language.
In J. Lewisand B. Hayes-Roth, editors, Proceedings of the1st International Conference on Autonomous Agents(Agents?97).
ACM Press.Gerald Matthews, Ian J. Deary, and Martha C. White-man.
2003.
Personality Traits.
Cambridge Univer-sity Press, Cambridge, 2nd edition.Youngme Moon and Clifford Nass.
1996.
How ?real?are computer personalities?
Communication Re-search, 23:651?674.Clifford Nass and Kwan Min Lee.
2000.
Doescomputer-generated speech manifest personality?an experimental test of similarity-attraction.
InProceedings of CHI 2000, The Hague, Amsterdam,2000, pages 329?336.Scott Nowson.
2006.
The Language of Weblogs: Astudy of genre and individual differences.
Ph.D. the-sis, University of Edinburgh.Jon Oberlander and Scott Nowson.
2006.
Whosethumb is it anyway?
Classifying author personalityfrom weblog text.
In Proceedings of COLING/ACL-06: 44th Annual Meeting of the Association forComputational Linguistics and 21st InternationalConference on Computational Linguistics, Sydney.Daniel S. Paiva and Roger Evans.
2004.
A frameworkfor stylistically controlled generation.
In Proceed-ings of the 3rd International Conference on NaturalLanguage Generation, pages 120?129.James W. Pennebaker and Laura King.
1999.
Lin-guistic styles: Language use as an individual differ-ence.
Journal of Personality and Social Psychology,77:1296?1312.James W. Pennebaker, Martha E. Francis, and Roger J.Booth.
2001.
Linguistic Inquiry and Word Count2001.
Lawrence Erlbaum Associates, Mahwah, NJ.James W. Pennebaker, Matthias R. Mehl, and Kate G.Neiderhoffer.
2002.
Psychological aspects of nat-ural language use: Our words, our selves.
AnnualReview of Psychology, 54:547?577.Martin J. Pickering and Holly P. Branigan.
1998.
Therepresentation of verbs: Evidence from syntacticpriming in language production.
Journal of Mem-ory and Language, 39(4):633?651.Martin J. Pickering and Simon Garrod.
2004.
Towardsa mechanistic psychology of dialogue.
Behavioraland Brain Sciences, 27:169?225.Paul Piwek and Kees van Deemter.
2003.
Dialogue asdiscourse: Controlling global properties of scripteddialogue.
In Proceedings of the AAAI Spring Sym-posium on Natural Language Generation in Spokenand Written Dialogue.Ehud Reiter and Somayajulu Sripada.
2004.
Contex-tual influences on near-synonym choice.
In Pro-ceedings of the Third International Conference onNatural Language Generation, pages 161?170.Thomas Rist, Elisabeth Andre?, and Stephan Baldes.2003.
A flexible platform for building applicationswith life-like characters.
In IUI ?03: Proceedings ofthe 8th International Conference on Intelligent UserInterfaces, pages 158?165, New York, NY, USA.ACM Press.Klaus Scherer.
1979.
Personality markers in speech.In K. R. Scherer and H. Giles, editors, Social Mark-ers in Speech, pages 147?209.
Cambridge Univer-sity Press, Cambridge.Andreas Stolcke, Harry Bratt, John Butzberger, Hora-cio Franco, Venkata Ramana Rao Gadde, MadelainePlauche?, Colleen Richey, Elizabeth Shriberg, KemalSo?nmez, Fuliang Weng, and Jing Zheng.
2000.
TheSRI March 2000 Hub-5 conversational speech tran-scription system.
In Proceedings of the 2000 SpeechTranscription Workshop, College Park, MD.Andreas Stolcke.
2002.
SRILM ?
an extensible lan-guage modeling toolkit.
In Proceedings of the 7thInternational Conference on Spoken Language Pro-cessing (ICSLP-02), pages 901?904, Denver, CO.Sebastian Varges.
2005.
Spatial descriptions as refer-ring expressions in the MapTask domain.
In Pro-ceedings of the 10th European Workshop on NaturalLanguage Generation.Marilyn A. Walker, Janet E. Cahn, and Steve J. Whit-taker.
1997.
Improvising linguistic style: So-cial and affective bases for agent personality.
InJ.
Lewis and B. Hayes-Roth, editors, Proceedingsof the 1st International Conference on AutonomousAgents (Agents?97), pages 96?105.
ACM Press.Michael White.
2004.
Reining in CCG Chart Re-alization.
In Proceedings of the 3rd InternationalConference on Natural Language Generation, pages182?191.Michael White.
2006.
Efficient Realization of Coor-dinate Structures in Combinatory Categorial Gram-mar.
Research on Language & Computation, on-line first, March.32
