Proceedings of the Second Workshop on Statistical Machine Translation, pages 120?127,Prague, June 2007. c?2007 Association for Computational LinguisticsUsing Paraphrases for Parameter Tuning in Statistical Machine TranslationNitin Madnani, Necip Fazil Ayan, Philip Resnik & Bonnie J. DorrInstitute for Advanced Computer StudiesUniversity of MarylandCollege Park, MD, 20742{nmadnani,nfa,resnik,bonnie}@umiacs.umd.eduAbstractMost state-of-the-art statistical machinetranslation systems use log-linear models,which are defined in terms of hypothesis fea-tures and weights for those features.
It isstandard to tune the feature weights in or-der to maximize a translation quality met-ric, using held-out test sentences and theircorresponding reference translations.
How-ever, obtaining reference translations is ex-pensive.
In this paper, we introduce a newfull-sentence paraphrase technique, basedon English-to-English decoding with an MTsystem, and we demonstrate that the result-ing paraphrases can be used to drastically re-duce the number of human reference transla-tions needed for parameter tuning, without asignificant decrease in translation quality.1 IntroductionViewed at a very high level, statistical machinetranslation involves four phases: language and trans-lation model training, parameter tuning, decoding,and evaluation (Lopez, 2007; Koehn et al, 2003).Since their introduction in statistical MT by Och andNey (2002), log-linear models have been a standardway to combine sub-models in MT systems.
Typi-cally such a model takes the form?i?i?i(f?
, e?)
(1)where ?i are features of the hypothesis e and ?i areweights associated with those features.Selecting appropriate weights ?i is essentialin order to obtain good translation performance.Och (2003) introduced minimum error rate train-ing (MERT), a technique for optimizing log-linearmodel parameters relative to a measure of translationquality.
This has become much more standard thanoptimizing the conditional probability of the train-ing data given the model (i.e., a maximum likelihoodcriterion), as was common previously.
Och showedthat system performance is best when parameters areoptimized using the same objective function that willbe used for evaluation; BLEU (Papineni et al, 2002)remains common for both purposes and is often re-tained for parameter optimization even when alter-native evaluation measures are used, e.g., (Banerjeeand Lavie, 2005; Snover et al, 2006).Minimum error rate training?and more gener-ally, optimization of parameters relative to a trans-lation quality measure?relies on data sets in whichsource language sentences are paired with (sets of)reference translations.
It is widely agreed that, atleast for the widely used BLEU criterion, which isbased on n-gram overlap between hypotheses andreference translations, the criterion is most accu-rate when computed with as many distinct referencetranslations as possible.
Intuitively this makes sense:if there are alternative ways to phrase the meaningof the source sentence in the target language, thenthe translation quality criterion should take as manyof those variations into account as possible.
To dootherwise is to risk the possibility that the criterionmight judge good translations to be poor when theyfail to match the exact wording within the referencetranslations that have been provided.This reliance on multiple reference translationscreates a problem, because reference translations arelabor intensive and expensive to obtain.
A com-mon source of translated data for MT research is theLinguistic Data Consortium (LDC), where an elab-orate process is undertaken that involves translationagencies, detailed translation guidelines, and qual-ity control processes (Strassel et al, 2006).
Some120efforts have been made to develop alternative pro-cesses for eliciting translations, e.g., from users onthe Web (Oard, 2003) or from informants in low-density languages (Probst et al, 2002).
However,reference translations for parameter tuning and eval-uation remain a severe data bottleneck for such ap-proaches.Note, however, one crucial property of referencetranslations: they are paraphrases, i.e., multiple ex-pressions of the same meaning.
Automatic tech-niques exist for generating paraphrases.
Althoughone would clearly like to retain human transla-tions as the benchmark for evaluation of translation,might it be possible to usefully increase the numberof reference translations for tuning by using auto-matic paraphrase techniques?In this paper, we demonstrate that it is, in fact,possible to do so.
Section 2 briefly describes ourtranslation framework.
Section 3 lays out a noveltechnique for paraphrasing, designed with the ap-plication to parameter tuning in mind.
Section 4presents evaluation results using a state of the art sta-tistical MT system, demonstrating that half the hu-man reference translations in a standard 4-referencetuning set can be replaced with automatically gener-ated paraphrases, with no significant decrease in MTsystem performance.
In Section 5 we discuss relatedwork, and in Section 6 we summarize the results anddiscuss plans for future research.2 Translation FrameworkThe work described in this paper makes useof the Hiero statistical MT framework (Chiang,2007).
Hiero is formally based on a weighted syn-chronous context-free grammar (CFG), containingsynchronous rules of the formX ?
?e?, f?
, ?k1(f?
, e?, X)?
(2)where X is a symbol from the nonterminal alpha-bet, and e?
and f?
can contain both words (terminals)and variables (nonterminals) that serve as placehold-ers for other phrases.
In the context of statisticalMT, where phrase-based models are frequently used,these synchronous rules can be interpreted as pairsof hierarchical phrases.
The underlying strengthof a hierarchical phrase is that it allows for effec-tive learning of not only the lexical re-orderings, butphrasal re-orderings, as well.
Each ?
(e?, f?
, X) de-notes a feature function defined on the pair of hierar-chical phrases.1 Feature functions represent condi-tional and joint co-occurrence probabilities over thehierarchical paraphrase pair.The Hiero framework includes methods to learngrammars and feature values from unannotated par-allel corpora, without requiring syntactic annotationof the data.
Briefly, training a Hiero model proceedsas follows:?
GIZA++ (Och and Ney, 2000) is run on theparallel corpus in both directions, followed byan alignment refinement heuristic that yields amany-to-many alignment for each parallel sen-tence.?
Initial phrase pairs are identified following theprocedure typically employed in phrase basedsystems (Koehn et al, 2003; Och and Ney,2004).?
Grammar rules in the form of equation (2)are induced by ?subtracting?
out hierarchicalphrase pairs from these initial phrase pairs.?
Fractional counts are assigned to each pro-duced rule:c(X ?
?e?, f??)
=m?j=11njr(3)where m is the number of initial phrase pairsthat give rise to this grammar rule and njr isthe number of grammar rules produced by thejth initial phrase pair.?
Feature functions ?k1(f?
, e?, X) are calculatedfor each rule using the accumulated counts.Once training has taken place, minimum error ratetraining (Och, 2003) is used to tune the parameters?i.Finally, decoding in Hiero takes place using aCKY synchronous parser with beam search, aug-mented to permit efficient incorporation of languagemodel scores (Chiang, 2007).
Given a source lan-guage sentence f, the decoder parses the source lan-guage sentence using the grammar it has learned1Currently only one nonterminal symbol is used in Hieroproductions.121during training, with parser search guided by themodel; a target-language hypothesis is generatedsimultaneously via the synchronous rules, and theyield of that hypothesized analysis represents the hy-pothesized string e in the target language.3 Generating ParaphrasesAs discussed in Section 1, our goal is to make it pos-sible to accomplish the parameter-tuning phase us-ing fewer human reference translations.
We accom-plish this by beginning with a small set of humanreference translations for each sentence in the devel-opment set, and expanding that set by automaticallyparaphrasing each member of the set rather than byacquiring more human translations.Most previous work on paraphrase has focusedon high quality rather than coverage (Barzilay andLee, 2003; Quirk et al, 2004), but generating ar-tificial references for MT parameter tuning in oursetting has two unique properties compared to otherparaphrase applications.
First, we would like to ob-tain 100% coverage, in order to avoid modificationsto our minimum error rate training infrastructure.2Second, we prefer that paraphrases be as distinct aspossible from the original sentences, while retainingas much of the original meaning as possible.In order to satisfy these two properties, we ap-proach sentence-level paraphrase for English asa problem of English-to-English translation, con-structing the model using English-F translation, fora second language F , as a pivot.
Following Ban-nard and Callison-Burch (2005), we first identifyEnglish-to-F correspondences, then map from En-glish to English by following translation units fromEnglish to F and back.
Then, generalizing their ap-proach, we use those mappings to create a well de-fined English-to-English translation model.
The pa-rameters of this model are tuned using MERT, andthen the model is used in an the (unmodified) sta-tistical MT system, yielding sentence-level Englishparaphrases by means of decoding input Englishsentences.
The remainder of this section presentsthis process in detail.2Strictly speaking, this was not a requirement of the ap-proach, but rather a concession to practical considerations.3.1 Mapping and BackmappingWe employ the following strategy for the inductionof the required monolingual grammar.
First, we trainthe Hiero system in standard fashion on a bilingualEnglish-F training corpus.
Then, for each exist-ing production in the resulting Hiero grammar, wecreate multiple new English-to-English productionsby pivoting on the foreign hierarchical phrase in therule.
For example, assume that we have the follow-ing toy grammar for English-F , as produced by Hi-ero:X ?
?e?1, f?1?X ?
?e?3, f?1?X ?
?e?1, f?2?X ?
?e?2, f?2?X ?
?e?4, f?2?If we use the foreign phrase f?1 as a pivot andbackmap, we can extract the two English-to-Englishrules: X ?
?e?1, e?3?
and X ?
?e?3, e?1?.
Backmap-ping using both f?1 and f?2 produces the followingnew rules (ignoring duplicates and rules that mapany English phrase to itself):X ?
?e?1, e?2?X ?
?e?1, e?3?X ?
?e?1, e?4?X ?
?e?2, e?1?X ?
?e?2, e?4?3.2 Feature valuesEach rule production in a Hiero grammar isweighted by several feature values defined on therule themselves.
In order to perform accuratebackmapping, we must recompute these featurefunctions for the newly created English-to-Englishgrammar.
Rather than computing approximationsbased on feature values already existing in the bilin-gual Hiero grammar, we calculate these featuresin a more principled manner, by computing max-imum likelihood estimates directly from the frac-tional counts that Hiero accumulates in the penul-timate training step.We use the following features in our inducedEnglish-to-English grammar:33Hiero also uses lexical weights (Koehn et al, 2003) in both122?
The joint probability of the two English hierar-chical paraphrases, conditioned on the nonter-minal symbol, as defined by this formula:p(e?1, e?2|x) =c(X ?
?e?1, e?2?)?e?1?,e?2?
c(X ?
?e?1?, e?2??
)=c(X ?
?e?1, e?2?
)c(X)(4)where the numerator is the fractional count ofthe rule under consideration and the denomina-tor represents the marginal count over all theEnglish hierarchical phrase pairs.?
The conditionals p(e?1, x|e?2) and p(e?2, x|e?1)defined as follows:p(e?1, x|e?2) =c(X ?
?e?1, e?2?)?e?1?
c(X ?
?e?1?, e?2?
)(5)p(e?2, x|e?1) =c(X ?
?e?1, e?2?)?e?2?
c(X ?
?e?1, e?2??
)(6)Finally, for all induced rules, we calculate a wordpenalty exp(?T (e?2)), where T (e?2) just counts thenumber of terminal symbols in e?2.
This feature al-lows the model to learn whether it should produceshorter or longer paraphrases.In addition to the features above that are estimatedfrom the training data, we also use a trigram lan-guage model.
Since we are decoding to produceEnglish sentences, we can use the same languagemodel employed in a standard statistical MT setting.Calculating the proposed features is complicatedby the fact that we don?t actually have the countsfor English-to-English rules because there is noEnglish-to-English parallel corpus.
This is wherethe counts provided by Hiero come into the picture.We estimate the counts that we need as follows:c(X ?
?e?1, e?2?)
=?f?c(X ?
?e?1, f??
)c(X ?
?e?2, f??)
(7)An intuitive way to think about the formula aboveis by using an example at the corpus level.
As-sume that, in the given bilingual parallel corpus,there are m sentences in which the English phrasedirections as features but we don?t use them for our grammar.e?1 co-occurs with the foreign phrase f?
and n sen-tences in which the same foreign phrase f?
co-occurswith the English phrase e?2.
The problem can thenbe thought of as defining a function g(m,n) whichcomputes the number of sentences in a hypotheti-cal English-to-English parallel corpus wherein thephrases e?1 and e?1 co-occur.
For this paper, we de-fine g(m,n) to be the upper bound mn.Tables 1 and 2 show some examples of para-phrases generated by our system across a range ofparaphrase quality for two different pivot languages.3.3 Tuning Model ParametersAlthough the goal of the paraphrasing approachis to make it less data-intensive to tune log-linearmodel parameters for translation, our paraphrasingapproach, since it is based on an English-to-Englishlog-linear model, also requires its own parametertuning.
This, however, is straightforward: regard-less of how the paraphrasing model will be usedin statistical MT, e.g., irrespective of source lan-guage, it is possible to use any existing set of Englishparaphrases as the tuning set for English-to-Englishtranslation.
We used the 2002 NIST MT evaluationtest set reference translations.
For every item in theset, we randomly chose one sentence as the sourcesentence, and the remainder as the ?reference trans-lations?
for purposes of minimum error rate training.4 EvaluationHaving developed a paraphrasing approach based onEnglish-to-English translation, we evaluated its usein improving minimum error rate training for trans-lation from a second language into English.Generating paraphrases via English-to-Englishtranslation makes use of a parallel corpus, fromwhich a weighted synchronous grammar is automat-ically acquired.
Although nothing about our ap-proach requires that the paraphrase system?s trainingbitext be the same one used in the translation exper-iments (see Section 6), doing so is not precluded, ei-ther, and it is a particularly convenient choice whenthe paraphrasing is being done in support of MT.4The training bitext comprised of Chinese-English4The choice of the foreign language used as the pivot shouldnot really matter but it is worth exploring this using other lan-guage pairs as our bitext.123O: we must bear in mind the community as a whole .P: we must remember the wider community .O: thirdly , the implications of enlargement for the union ?s regional policy cannot be overlooked .P: finally , the impact of enlargement for eu regional policy cannot be ignored .O: how this works in practice will become clear when the authority has to act .P: how this operate in practice will emerge when the government has to play .O: this is an ill-advised policy .P: this is an unwelcome in europe .Table 1: Example paraphrases with French as the pivot language.
O = Original Sentence, P = Paraphrase.O: alcatel added that the company?s whole year earnings would be announced on february 4 .P: alcatel said that the company?s total annual revenues would be released on february 4 .O: he was now preparing a speech concerning the us policy for the upcoming world economic forum .P: he was now ready to talk with regard to the us policies for the forthcoming international economic forum .O: tibet has entered an excellent phase of political stability, ethnic unity and people living in peace .P: tibetans have come to cordial political stability, national unity and lived in harmony .O: its ocean and blue-sky scenery and the mediterranean climate make it world?s famous scenic spot .P: its harbour and blue-sky appearance and the border situation decided it world?s renowned tourist attraction .Table 2: Example paraphrases with Chinese as the pivot language.
O = Original Sentence, P = Paraphrase.Corpus # Sentences # WordsHK News 542540 11171933FBIS 240996 9121210Xinhua 54022 1497562News1 9916 314121Treebank 3963 125848Total 851437 22230674Table 3: Chinese-English corpora used as trainingbitext both for paraphrasing and for evaluation.parallel corpora containing 850, 000 sentence pairs ?approx.
22 million words (details shown in Table 3).As the source of development data for minimumerror rate training, we used the 919 source sen-tences and human reference translations from the2003 NIST Chinese-English MT evaluation exer-cise.
As raw material for experimentation, we gen-erated a paraphrase for each reference sentence via1-best decoding using the English-to-English trans-lation approach of Section 3.As our test data, we used the 1082 source sen-tences and human reference translations from the2005 NIST Chinese-English MT evaluation.Our core experiment involved three conditionswhere the only difference was the set of referencesfor the development set used for tuning featureweights.
For each condition, once the weights weretuned, they were used to decode the test set.
Notethat for all the conditions, the decoded test set wasalways scored against the same four high-quality hu-man reference translations included with the set.The three experimental conditions were designedaround the constraint that our development set con-tains a total of four human reference translations persentence, and therefore a maximum of four humanreferences with which to compute an upper bound:?
Baseline (2H): For each item in the devel-opment set, we randomly chose two of thefour human-constructed reference translationsas references for minimum error rate training.?
Expanded (2H + 2P): For each of the two hu-man references in the baseline tuning set, weautomatically generated a corresponding para-phrase using (1-best) English-to-English trans-lation, decoding using the model developed inSection 3.
This condition represents the criticalcase in which you have a limited number of hu-124man references (two, in this case) and augmentthem with artificially generated reference trans-lations.
This yields a set of four references forminimum error rate training (two human, twoparaphrased), which permits a direct compar-ison against the upper bound of four human-generated reference translations.?
Upper bound: 4H: We performed minimumerror rate training using the four human refer-ences from the development set.In addition to these core experimental conditions,we added a fourth condition to assess the effect onperformance when all four human reference trans-lations are used in expanding the reference set viaparaphrase:?
Expanded (4H + 4P): This is the same as Con-dition 2, but using all four human references.Note that since we have only four human referencesper item, this fourth condition does not permit com-parison with an upper bound of eight human refer-ences.Table 4 shows BLEU and TER scores on the testset for all four conditions.5 If only two human ref-erences were available (simulated by using only twoof the available four), expanding to four using para-phrases would yield a clear improvement.
Usingbootstrap resampling to compute confidence inter-vals (Koehn, 2004), we find that the improvement inBLEU score is statistically significant at p < .01.Equally interesting, expanding the number of ref-erence translations from two to four using para-phrases yields performance that approaches the up-per bound obtained by doing MERT using all fourhuman reference translations.
The difference inBLEU between conditions 2 and 3 is not significant.Finally, our fourth condition asks whether it ispossible to improve MT performance given thetypical four human reference translations used forMERT in most statistical MT systems, by adding aparaphrase to each one for a total eight referencesper translation.
There is indeed further improve-ment, although the difference in BLEU score doesnot reach significance.5We plan to include METEOR scores in future experiments.Condition References used BLEU TER1 2 H 30.43 59.822 2 H + 2 P 31.10 58.793 4 H 31.26 58.664 4 H + 4 P 31.68 58.24Table 4: BLEU and TER scores showing utility ofparaphrased reference translations.
H = human ref-erences, P = paraphrased references.We also evaluated our test set using TER (Snoveret al, 2006) and observed that the TER scores followthe same trend as the BLEU scores.
Specifically, theTER scores demonstrate that using paraphrases toartificially expand the reference set is better than us-ing only 2 human reference translations and as goodas using 4 human reference translations.65 Related WorkThe approach we have taken here arises from a typ-ical situation in NLP systems: the lack of sufficientdata to accurately estimate a model based on super-vised training data.
In a structured prediction prob-lem such as MT, we have an example input and asingle labeled, correct output.
However, this outputis chosen from a space in which the number of pos-sible outputs is exponential in the input size, and inwhich there are many good outputs in this space (al-though they are vastly outnumbered by the bad out-puts).
Various discriminative learning methods haveattempted to deal with the first of these issues, oftenby restricting the space of examples.
For instance,some max-margin methods restrict their computa-tions to a set of examples from a ?feasible set,?where they are expected to be maximally discrim-inative (Tillmann and Zhang, 2006).
The presentapproach deals with the second issue: in a learningproblem where the use of a single positive exampleis likely to be highly biased, how can we produce aset of positive examples that is more representativeof the space of correct outcomes?
Our method ex-ploits alternative sources of information to producenew positive examples that are, we hope, reasonablylikely to represent a consensus of good examples.Quite a bit of work has been done on paraphrase,6We anticipate doing significance tests for differences inTER in future work.125some clearly related to our technique, although ingeneral previous work has been focused on humanreadability rather than high coverage, noisy para-phrases for use downstream in an automatic process.At the sentence level, (Barzilay and Lee, 2003)employed an unsupervised learning approach tocluster sentences and extract lattice pairs fromcomparable monolingual corpora.
Their techniqueproduces a paraphrase only if the input sentencematches any of the extracted lattice pairs, leading toa bias strongly favoring quality over coverage.
Theywere able to generate paraphrases for 59 sentences(12%) out of a 484-sentence test set, generating noparaphrases at all for the remainder.Quirk et al (2004) also generate sentential para-phrases using a monolingual corpus.
They useIBM Model-1 scores as the only feature, and em-ploy a monotone decoder (i.e., one that cannot pro-duce phrase-level reordering).
This approach em-phasizes very simple ?substitutions of words andshort phrases,?
and, in fact, almost a third of theirbest sentential ?paraphrases?
are identical to the in-put sentence.A number of other approaches rely on parallelmonolingual data and, additionally, require pars-ing of the training sentences (Ibrahim et al, 2003;Pang et al, 2003).
Lin and Pantel (2001) use anon-parallel corpus and employ a dependency parserand computation of distributional similarity to learnparaphrases.There has also been recent work on using para-phrases to improve statistical machine translation.Callison-Burch et al (2006) extract phrase-levelparaphrases by mapping input phrases into a phrasetable and then mapping back to the source language.However, they do not generate paraphrases of entiresentences, but instead employ paraphrases to add en-tries to an existing phrase table solely for the pur-pose of increasing source-language coverage.Other work has incorporated paraphrases into MTevaluation: Russo-Lassner et al (2005) use a com-bination of paraphrase-based features to evaluatetranslation output; Zhou et al (2006) propose a newmetric that extends n-gram matching to include syn-onyms and paraphrases; and Lavie?s METEOR met-ric (Banerjee and Lavie, 2005) can be used with ad-ditional knowledge such as WordNet in order to sup-port inexact lexical matches.6 Conclusions and Future WorkWe introduced an automatic paraphrasing techniquebased on English-to-English translation of full sen-tences using a statistical MT system, and demon-strated that, using this technique, it is possible tocut in half the usual number of reference transla-tions used for minimum error rate training with nosignificant loss in translation quality.
Our methodenables the generation of paraphrases for thousandsof sentences in a very short amount of time (muchshorter than creating other low-cost human refer-ences).
This might prove beneficial for various dis-criminative training methods (Tillmann and Zhang,2006).This has important implications for data acquisi-tion strategies For example, it suggests that ratherthan obtaining four reference translations per sen-tence for development sets, it may be more worth-while to obtain fewer translations for a wider rangeof sentences, e.g., expanding into new topics andgenres.
In addition, this approach can significantlyincrease the utility of datasets which include only asingle reference translation.A number of future research directions are pos-sible.
First, since we have already demonstratedthat noisy paraphrases can nonetheless add value,it would be straightforward to explore the quan-tity/quality tradeoff by expanding the MERT refer-ence translations with n-best paraphrases for n > 1.We also plan to conduct an intrinsic evaluation ofthe quality of paraphrases that our technique gener-ates.
It is important to note that a different tradeoffratio may lead to even better results, e.g, using onlythe paraphrased references when they pass somegoodness threshold, as used in Ueffing?s (2006) self-training MT approach.We have also observed that named entities areusually paraphrased incorrectly if there is a genremismatch between the training and the test data.
TheHiero decoder allows spans of source text to be an-notated with inline translations using XML.
We planto identify and annotate named entities in the En-glish source so that they are left unchanged.Also, since the languageF for English-F pivotingis arbitrary, we plan to investigate using English-to-English grammars created using multiple English-Fgrammars based on different languages, both indi-126vidually and in combination, in order to improveparaphrase quality.We also plan to explore a wider range ofparaphrase-creation techniques, ranging from sim-ple word substitutions (e.g., based on WordNet) tousing the pivot technique with other translations sys-tems.7 AcknowledgmentsWe are indebted to David Chiang, Adam Lopezand Smaranda Muresan for insights and comments.This work has been supported under the GALE pro-gram of the Defense Advaned Research ProjectsAgency, Contract No.
HR0011-06-2-001.
Any opin-ions, findings, conclusions or recommendations ex-pressed in this paper are those of the authors and donot necessarily reflect the view of DARPA.ReferencesS.
Banerjee and A. Lavie.
2005.
Meteor: An auto-matic metric for mt evaluation with improved correla-tion with human judgments.
In Proceedings of Work-shop on Intrinsic and Extrinsic Evaluation Measuresfor MT and/or Summarization at ACL.Colin Bannard and Chris Callison-Burch.
2005.
Para-phrasing with bilingual parallel corpora.
In Proceed-ings of ACL.Regina Barzilay and Lillian Lee.
2003.
Learning toparaphrase: An unsupervised approach using multiple-sequence alignment.
In Proceedings of HLT-NAACL.Chris Callison-Burch, Philipp Koehn, and Miles Os-borne.
2006.
Improved statistical machine translationusing paraphrases.
In Proceedings of HLT-NAACL.David Chiang.
2007.
Hierarchical phrase-based transla-tion.
Computational Linguistics, 33(2).A.
Ibrahim, B. Katz, and J. Lin.
2003.
Extracting struc-tural paraphrases from aligned monolingual corpora.In Proceedings the Second International Workshop onParaphrasing (ACL 2003).Philipp Koehn, Franz Och, and Daniel Marcu.
2003.Statistical phrase-based translation.
In Proceedings ofHLT-NAACL.Philipp Koehn.
2004.
Statistical significance tests formachine translation evaluation.
In Proceedings ofEMNLP.Dekang Lin and Patrick Pantel.
2001.
DIRT - discov-ery of inference rules from text.
In Proceedings ofACM SIGKDD Conference on Knowledge Discoveryand Data Mining.A.
Lopez.
2007.
A survey of statistical machine transla-tion.
Technical Report 2006-47, University of Mary-land, College Park.D.
W. Oard.
2003.
The surprise langauge exercises.ACM Transactions on Asian Language InformationProcessing, 2(3).Franz J. Och and Hermann Ney.
2000.
Improved statisti-cal alignment models.
In Proceedings of ACL.Franz J. Och and Hermann Ney.
2002.
Discriminativetraining and maximum entropy models for statisticalmachine translation.
In Proceedings of ACL.Franz Och and Hermann Ney.
2004.
The alignment tem-plate approach to statistical machine translation.
Com-putational Linguistics, 30(4).Franz Josef Och.
2003.
Minimum error rate training instatistical machine translation.
In Proceedings of ACL.Bo Pang, Kevin Knight, and Daniel Marcu.
2003.Syntax-based alignment of multiple translations: Ex-tracting paraphrases and generating new sentences.
InProceedings of HLT/NAACL.K.
Papineni, S. Roukos, T. Ward, and W.-J.
Zhu.
2002.Bleu: a method for automatic evaluation of machinetranslation.
In Proceedings of ACL.K.
Probst, L. Levin, E. Peterson, A. Lavie, and J. Car-bonell.
2002.
Mt for minority languages usingelicitation-based learning of syntactic transfer rules.Machine Translation, 17(4).Chris Quirk, Chris Brockett, and William Dolan.
2004.Monolingual machine translation for paraphrase gen-eration.
In Proceedings of EMNLP 2004.Grazia Russo-Lassner, Jimmy Lin, and Philip Resnik.2005.
A paraphrase-based approach to machine trans-lation evaluation.
Technical Report UMIACS-TR-2005-57, University of Maryland, College Park.M.
Snover, B. Dorr, R. Schwartz, L. Micciulla, andJ.
Makhoul.
2006.
A study of translation edit rate withtargeted human annotation.
In Proceedings of AMTA.S.
Strassel, C. Cieri, A. Cole, D. DiPersio, M. Liberman,X.
Ma, M. Maamouri, and K. Maeda.
2006.
Inte-grated linguistic resources for language exploitationtechnologies.
In Proceedings of LREC.Christoph Tillmann and Tong Zhang.
2006.
A discrimi-native global training algorithm for statistical MT.
InProceedings of ACL.Nicola Ueffing.
2006.
Using monolingual source-language data to improve MT performance.
In Pro-ceedings of IWSLT.L.
Zhou, C.-Y.
Lin, D. Muntenau, and E. Hovy.
2006.ParaEval: Using paraphrases to evaluate summariesautomatically.
In Proceedings of HLT-NAACL.127
