Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 433?443,Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational LinguisticsTimeline Generation through Evolutionary Trans-Temporal SummarizationRui Yan?, Liang Kong?
, Congrui Huang?, Xiaojun Wan?, Xiaoming Li\, Yan Zhang??
?School of Electronics Engineering and Computer Science, Peking University, China?Institute of Computer Science and Technology, Peking University, China\State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, China{r.yan,kongliang,hcr,lxm}@pku.edu.cn,wanxiaojun@icst.pku.edu.cn,zhy@cis.pku.edu.cnAbstractWe investigate an important and challeng-ing problem in summary generation, i.e.,Evolutionary Trans-Temporal Summarization(ETTS), which generates news timelines frommassive data on the Internet.
ETTS greatlyfacilitates fast news browsing and knowl-edge comprehension, and hence is a neces-sity.
Given the collection of time-stamped webdocuments related to the evolving news, ETTSaims to return news evolution along the time-line, consisting of individual but correlatedsummaries on each date.
Existing summariza-tion algorithms fail to utilize trans-temporalcharacteristics among these component sum-maries.
We propose to model trans-temporalcorrelations among component summaries fortimelines, using inter-date and intra-date sen-tence dependencies, and present a novel com-bination.
We develop experimental systems tocompare 5 rival algorithms on 6 instinctivelydifferent datasets which amount to 10251 doc-uments.
Evaluation results in ROUGE metricsindicate the effectiveness of the proposed ap-proach based on trans-temporal information.1 IntroductionAlong with the rapid growth of the World WideWeb, document floods spread throughout the Inter-net.
Given a large document collection related toa news subject (for example, BP Oil Spill), readersget lost in the sea of articles, feeling confused andpowerless.
General search engines can rank these?Corresponding author.news webpages by relevance to a user specified as-pect, i.e., a query such as ?first relief effort for BPOil Spill?, but search engines are not quite capableof ranking documents given the whole news subjectwithout particular aspects.
Faced with thousands ofnews documents, people usually have a myriad of in-terest aspects about the beginning, the developmentor the latest situation.
However, traditional infor-mation retrieval techniques can only rank webpagesaccording to their understanding of relevance, whichis obviously insufficient (Jin et al, 2010).Even if the ranked documents could be in a satis-fying order to help users understand news evolution,readers prefer to monitor the evolutionary trajecto-ries by simply browsing rather than navigate everydocument in the overwhelming collection.
Summa-rization is an ideal solution to provide an abbrevi-ated, informative reorganization for faster and bet-ter representation of news documents.
Particularly,a timeline (see Table 1) can summarize evolutionarynews as a series of individual but correlated com-ponent summaries (items in Table 1) and offer anoption to understand the big picture of evolution.With unique characteristics, summarizing time-lines is significantly different from traditional sum-marization methods which are awkward in such sce-narios.
We first study a manual timeline of BP OilSpill in Mexico Gulf in Table 1 from Reuters News1to understand why timelines generation is observ-ably different from traditional summarization.
Notraditional method has considered to partition corpusinto subsets by timestamps for trans-temporal cor-relations.
However, we discover two unique trans-1http://www.reuters.com433Table 1: Part of human generated timeline about BP OilSpill in 2010 from Reuters News website.April 22, 2010The Deepwater Horizon rig, valued at more than $560 million,sinks and a five mile long (8 km) oil slick is seen.April 25, 2010The Coast Guard approves a plan to have remote underwater vehi-cles activate a blowout preventer and stop leak.
Efforts to activatethe blowout preventer fail.April 28, 2010The Coast Guard says the flow of oil is 5,000 barrels per day (bpd)(210,000 gallons/795,000 litres) ?
five times greater than first esti-mated.
A controlled burn is held on the giant oil slick.April 29, 2010U.S.
President Barack Obama pledges ?every single available re-source,?
including the U.S. military, to contain the spreading spill.Obama also says BP is responsible for the cleanup.
Louisiana de-clares state of emergency due to the threat to the state?s naturalresources.April 30, 2010An Obama aide says no drilling will be allowed in new areas, as thepresident had recently proposed, until the cause of the DeepwaterHorizon accident is known.temporal characteristics of component summariesfrom the handcrafted timeline.
Individuality.
Thecomponent summaries are summarized locally: thecomponent item on date t is constituted by sentenceswith timestamp t. Correlativeness.
The compo-nent summaries are correlative across dates, basedon the global collection.
To the best of our knowl-edge, no traditional method has examined the rela-tionships among these timeline items.Although it is profitable, summarizing timelinefaces with new challenges:?
The first challenge for timeline generation isto deliver important contents and avoid informationoverlaps among component summaries under thetrans-temporal scenario based on global/local sourcecollection.
Component items are individual but notcompletely isolated due to the dynamic evolution.?
As we have individuality and correlativenessto evaluate the qualities of component summaries,both locally and globally, the second challenge is toformulate the combination task into a balanced op-timization problem to generate the timelines whichsatisfy both standards with maximum utilities.We introduce a novel approach for the web min-ing problem Evolutionary Trans-Temporal Summa-rization (ETTS).
Taking a collection relevant to anews subject as input, the system automatically out-puts a timeline with items of component summarieswhich represent evolutionary trajectories on specificdates.
We classify sentence relationships as inter-date and intra-date dependencies.
Particularly, theinter-date dependency calculation includes temporaldecays to project sentences from all dates onto thesame time horizon (Figure 1 (a)).
Based on intra-/inter-date sentence dependencies, we then modelaffinity and diversity to compute the saliency scoreof each sentence and merge local and global rank-ings into one unified ranking framework.
Finally weselect top ranked sentences.
We build an experimen-tal system on 6 real datasets to verify the effective-ness of our methods compared with other 4 rivals.2 Related WorkMulti-document summarization (MDS) aims to pro-duce a summary delivering the majority of informa-tion content from a set of documents and has drawnmuch attention in recent years.
Conferences such asACL, SIGIR, EMNLP, etc., have advanced the tech-nology and produced several experimental systems.Generally speaking, MDS methods can be eitherextractive or abstractive summarization.
Abstractivesummarization (e.g.
NewsBlaster2) usually needsinformation fusion, sentence compression and refor-mulation.
We focus on extraction-based methods,which usually involve assigning saliency scores tosome units (e.g.
sentences, paragraphs) of the docu-ments and extracting the units with highest scores.To date, various extraction-based methods havebeen proposed for generic multi-document summa-rization.
The centroid-based method MEAD (Radevet al, 2004) is an implementation of the centroid-based method that scores sentences based on fea-tures such as cluster centroids, position, and TF.IDF,etc.
NeATS (Lin and Hovy, 2002) adds new featuressuch as topic signature and term clustering to selectimportant content, and use MMR (Goldstein et al,1999) to remove redundancy.Graph-based ranking methods have been pro-posed to rank sentences/passages based on ?votes?or ?recommendations?
between each other.
Tex-tRank (Mihalcea and Tarau, 2005) and LexPageR-ank (Erkan and Radev, 2004) use algorithms similarto PageRank and HITS to compute sentence impor-tance.
Wan et al have improved the graph-ranking2http://www1.cs.columbia.edu/nlp/newsblaster/434algorithm by differentiating intra-document andinter-document links between sentences (2007b),and have proposed a manifold-ranking method toutilize sentence-to-sentence and sentence-to-topicrelationships (Wan et al, 2007a).ETTS seems to be related to a very recent task of?update summarization?
started in DUC 2007 andcontinuing with TAC.
However, update summariza-tion only dealt with a single update and we make anovel contribution with multi-step evolutionary up-dates.
Further related work includes similar timelinesystems proposed by (Swan and Allan, 2000) us-ing named entities, by (Allan et al, 2001) measuredin usefulness and novelty, and by (Chieu and Lee,2004) measured in interest and burstiness.
We haveproposed a timeline algorithm named ?Evolution-ary Timeline Summarization (ETS)?
in (Yan et al,2011b) but the refining process based on generatedcomponent summaries is time consuming.
We aimto seek for more efficient summarizing approach.To the best of our knowledge, neither update sum-marization nor traditional systems have consideredthe relationship among ?component summaries?, orhave utilized trans-temporal properties.
ETTS ap-proach can also naturally and simultaneously takeinto account global/local summarization with biasedinformation richness and information novelty, andcombine both summarization in optimization.3 Trans-temporal SummarizationWe conduct trans-temporal summarization based onthe global biased graph using inter-date dependencyand local biased graph using intra-date dependency.Each graph is the complementary graph to the other.3.1 Global Biased SummarizationThe intuition for global biased summarization is thatthe selected summary should be correlative with sen-tences from neighboring dates, especially with thoseinformative ones.
To generate the component sum-mary on date t, we project all sentences in the collec-tion onto the time horizon of t to construct a globalaffinity graph, using temporal decaying kernels.3.1.1 Temporal Proximity Based ProjectionClearly, a major technical challenge in ETTS ishow to define the temporal biased projection func-tion ?
(?t), where ?t is the distance between theFigure 1: Construct global/local biased graphs.
Solid cir-cles denote intra-date sentences on the pending date t anddash ones represent inter-date sentences from other dates.Figure 2: Proximity-based kernel functions, where ?=10.pending date t and neighboring date t?, i.e., ?t =|t?
?
t|.
As in (Lv and Zhai, 2009), we present 5representative kernel functions: Gaussian, Triangle,Cosine, Circle, and Window, shown in Figure 2.
Dif-ferent kernels lead to different projections.1.
Gaussian kernel?
(?t) = exp[?
?t22?2 ]2.
Triangle kernel?
(?t) ={1?
?t?
if ?t ?
?0 otherwise3.
Cosine (Hamming) kernel?
(?t) ={12 [1 + cos(?t?pi? )]
if ?t ?
?0 otherwise4.
Circle kernel?
(?t) ={?1?
(?t?
)2 if ?t ?
?0 otherwise4355.
Window kernel?
(?t) ={1 if ?t ?
?0 otherwiseAll kernels have one parameter ?
to tune, whichcontrols the spread of kernel curves, i.e., it restrictsthe projection scope of each sentence.
In general,the optimal setting of ?
may vary according to thenews set because sentences presumably would havewider semantic scope in certain news subjects, thusrequiring a higher value of ?
and vice versa.3.1.2 Modeling Global AffinityGiven the sentence collectionC partitioned by thetimestamp set T , C = {C1, C2, .
.
.
, C |T |}, we ob-tain Ct = {sti|1 ?
i ?
|Ct|} where si is a sentencewith the timestamp t = tsi .
When we generate com-ponent summary on t, we project all sentences ontotime horizon t. After projection, all sentences areweighted by their influence on t. We use an affinitymatrix M t with the entry of the inter-date transitionprobability on date t. The sum of each row equals to1.
Note that for the global biased matrix, we mea-sure the affinity between local sentences from t andglobal sentences from other dates.
Therefore, intra-date transition probability between sentences withthe timestamp t is set to 0 for local summarization.M ti,j is the transition probability of si to sj basedon the perspective of date t, i.e., p(si ?
sj |t):p(si ?
sj |t) ={ f(si?sj |t)?|C| f(si?sk|t)if ?
f 6= 00 if tsi = tsj = t(1)f(si ?
sj |t) is defined as the temporal weightedcosine similarity between two sentences:f(si ?
sj |t) =?w?si?sjpi(w, si|t) ?
pi(w, sj |t) (2)where the weight pi associated with term w is calcu-lated with the temporal weighted tf.isf formula:pi(w, s|t) =?|t?
ts| ?
tf(w, s)(1 + log( |C|Nw ))?
?|s|(tf(w, s)(1 + log(|C|Nw )))2.
(3)where ts is the timestamp of sentence s, andtf(w, s) is the term frequency of w in s. ts can beany date from T .
|C| is the sentences set size andNw is the number of sentences containing term w.We let p(si ?
si|t)=0 to avoid self transition.Note that although f(.)
is a symmetric function,p(si ?
sj |t) is usually not equal to p(sj ?
si|t),depending on the degrees of nodes si and sj .Now we establish the affinity matrix M ti,j and byusing the general form of PageRank, we obtain:~?
= ?M?1~?+ 1?
?|C| ~e (4)where ~?
is the selective probability of all sentencenodes and ~e is a column vector with all elementsequaling to 1. ?
is the damping factor set as 0.85.Usually the convergence of the iteration algorithm isachieved when difference between the scores com-puted at two successive iterations for any sentencesfalls below a given threshold (0.0001 in this study).3.1.3 Modeling DiversityDiversity is to reflect both biased informationrichness and sentence novelty, which aims to reduceinformation redundancy.
However, using standardPageRank of Equation (4) will not result in diver-sity.
The aggregational effect of PageRank assignshigh salient scores to closely connected node com-munities (Figure 3 (b)).
A greedy vertex selectionalgorithm may achieve diversity by iteratively se-lecting the most prestigious vertex and then penal-izing the vertices ?covered?
by the already selectedones, such as Maximum Marginal Relevance and itsapplications in Wan et al (2007b; 2007a).
Most re-cently diversity rank DivRank is another solutionto diversity penalization in (Mei et al, 2010).We incorporate DivRank in our general rankingframework, which creates a dynamicM during eachiteration, rather than a static one.
After z times ofiteration, the matrix M becomes:M (z) = ?M (z?1) ?
~?
(z?1) + 1?
?|C| ~e (5)Equation (5) raises the probability for nodes withhigher centrality and nodes already having highweights are likely to ?absorb?
the weights of itsneighbors directly, and the weights of neighbors?neighbors indirectly.
The process is to iteratively ad-just matrix M according to ~?
and then to update ~?according to the changed M .
As iteration increases436there emerges a rich-gets-richer phenomenon (Fig-ure 3 (c) and (d)).
By incorporating DivRank, weobtain rank r?i and the global biased ranking scoreGi for sentence si from date t to summarize Ct.3.2 Local Biased SummarizationNaturally, the component summary for date t shouldbe informative within Ct.
Given the sentence col-lection Ct = {sti|1 ?
i ?
|Ct|}, we build an affin-ity matrix for Figure 1 (b), with the entry of intra-date transition probability calculated from standardcosine similarity.
We incorporate DivRank withinlocal summarization and we obtain the local biasedrank and ranking score for si, denoted as r?i and Li.3.3 Optimization of Global/Local CombinationWe do not directly add the global biased rankingscore and local biased ranking score, as many previ-ous works did (Wan et al, 2007b; Wan et al, 2007a),because even the same ranking score gap may indi-cate different rank gaps in two ranking lists.Given subset Ct, let R = {ri}(i = 1,. .
.
,|Ct|), riis the final ranking of si to estimate, optimize thefollowing objective cost function O(R),O(R) =?|Ct|?i=1Gi?ri?i?
r?iGi?2+ ?|Ct|?i=1Li?ri?i?
r?iLi?2(6)where Gi is the global biased ranking score while Liis the local biased ranking score.
?i is expected tobe the merged ranking score, namely sentence im-portance, which will be defined later.
Among thetwo components in the objective function, the firstcomponent means that the refined rank should notdeviate too much from the global biased rank.
Weuse ?
ri?i ?r?iGi ?2 instead of ?ri?
r?i ?2 in order to dis-tinguish the differences between sentences from thesame rank gap.
The second component is similar byrefining rank from local biased summarization.Our goal is to find R = R?
to minimize the costfunction, i.e.,R?
= argmin{O(R)}.
R?
is the finalrank merged by our algorithm.
To minimize O(R),we compute its first-order partial derivatives.
?O(R)?ri= 2?
?i( Gi?iri ?
r?i ) +2?
?i(Li?iri ?
r?i ) (7)Let ?O(R)?ri = 0, we getr?i =?
?ir?i + ?
?ir?i?Gi + ?Li(8)Two special cases are that if (1) ?
= 0, ?
6= 0:we obtain ri = ?ir?i /Li, indicating we only use thelocal ranking score.
(2) ?
6= 0, ?
= 0, indicating weignore local ranking score and only consider globalbiased summarization using inter-date dependency.There can be many ways to calculate the sen-tence importance ?i.
Here we define ?i as theweighted combination of itself with ranking scoresfrom global biased and local biased summarization:?
(z)i =?Gi + ?Li + ??
(z?1)i?+ ?
+ ?
.
(9)To save one parameter we let ?+?+?
= 1.
In the z-th iteration, r(z)i is dependent on ?
(z?1)i and ?
(z)i isindirectly dependent on r(z)i via ?
(z?1)i .
?
(0)i = 0.We iteratively approximate final ?i for the ultimaterank listR?.
The expectation of stable ?i is obtainedwhen ?
(z)i = ?
(z?1)i .
Final ?i is expected to satisfy?i = ?Gi + ?Li + ?
?i:?i =?Gi + ?Li1?
?
=?Gi + ?Li?+ ?
(10)Final ?i is dependent only on original global/localbiased ranking scores.
Equation (8) becomes moreconcise with no ?
or ?
: r?
is a weighted combina-tion of global and local ranks by ??
(?
6= 0, ?
6= 0):r?i =?
?+ ?
r?i +?
?+ ?
r?i= 11 + ?/?r?i +11 + ?/?
r?i(11)4 Experiments and Evaluation4.1 DatasetsThere is no existing standard test set for ETTS meth-ods.
We randomly choose 6 news subjects withspecial coverage and handcrafted timelines by ed-itors from 10 selected news websites: these 6 testsets consist of news datasets and golden standards toevaluate our proposed framework empirically, whichamount to 10251 news articles.
As shown in Ta-ble 2, three of the sources are in UK, one of them437(a) An illustrative network.
(a) PageRank on t. (b) DivRank on t (c) DivRank on t?Figure 3: An illustration of diverse ranking in a toy graph (a).
Comparing (b) from general PageRank with (c),(d) fromDivRank, we find a better diversity by selecting {1,9} in (c) rather than {1,3} in (b).
Moreover, (c) and (d) reflecttemporal biased processes on t {1,9} in (c) and t?
{2,12} in (d).is in China and the rest are in the US.
We choosethese sites because many of them provide timelinesedited by professional editors, which serve as refer-ence summaries.
The news belongs to different cate-gories of Rule of Interpretation (ROI) (Kumaran andAllan, 2004).
More detailed statistics are in Table 3.Table 2: News sources of 6 datasetsNews Sources Nation News Sources NationBBC UK Fox News USXinhua China MSNBC USCNN US Guardian UKABC US New York Times USReuters UK Washington Post USTable 3: Detailed basic information of 6 datasets.News Subjects #size #docs #stamps #RT AL1.Influenza A 115026 2557 331 5 832.Financial Crisis 176435 2894 427 2 1183.BP Oil Spill 63021 1468 135 6 764.Haiti Earthquake 12073 247 83 2 325.Jackson Death 37819 925 168 3 646.Obama Presidency 79761 2160 349 5 92size: the whole sentence counts; #stamps: the number of timestamps;Note average size of subsets is calculated as: avg.size=#size/#stamps;RT: reference timelines; AL: avg.
length of RT measured in sentences.4.2 Experimental System Setups?
Preprocessing.
As ETTS faces with much largercorpus compared with traditional MDS, we applyfurther data preprocessing besides stemming andstop-word removal.
We extract text snippets repre-senting atomic ?events?
from all documents with atoolkit provided by Yan et al (2010; 2011a), bywhich we attempt to assign more fine-grained andaccurate timestamps for every sentence within thetext snippets.
After the snippet extraction procedure,we filter the corpora by discarding non-event texts.?
Compression Rate and Date Selection.
Afterpreprocessing, we obtain numerous snippets withfine-grained timestamps, and then decompose theminto temporally tagged sentences as the global col-lection C. We partition C according to timestampsof sentences, i.e., C = C1 ?
C2 ?
?
?
?
?
C |T |.Each component summary is generated from its cor-responding sub-collection.
The sizes of componentsummaries are not necessarily equal, and moreover,not all dates may be represented, so date selectionis also important.
We apply a simple mechanismthat users specify the overall compression rate ?, andwe extract more sentences for important dates whilefewer sentences for others.
The importance of datesis measured by the burstiness, which indicates prob-able significant occurrences (Chieu and Lee, 2004).The compression rate on ti is set as ?i = |Ci||C| .4.3 Evaluation MetricsThe ROUGE measure is widely used for evaluation(Lin and Hovy, 2003): the DUC contests usually of-ficially employ ROUGE for automatic summariza-tion evaluation.
In ROUGE evaluation, the summa-rization quality is measured by counting the num-ber of overlapping units, such as N-gram, word se-quences, and word pairs between the candidate time-lines CT and the reference timelines RT .
There areseveral kinds of ROUGE metrics, of which the mostimportant one is ROUGE-N with 3 sub-metrics:1 ROUGE-N-R is an N-gram recall metric:ROUGE-N-R =?I?RT?N-gram?ICountmatch(N-gram)?I?RT?N-gram?ICount (N-gram)4382 ROUGE-N-P is an N-gram precision metric:ROUGE-N-P =?I?CT?N-gram?ICountmatch(N-gram)?I?CT?N-gram?ICount (N-gram)3 ROUGE-N-F is an N-gram F1 metric:ROUGE-N-F = 2?
ROUGE-N-P?
ROUGE-N-RROUGE-N-P + ROUGE-N-RI denotes a timeline.
N in these metrics stands forthe length of N-gram and N-gram?RT denotes theN-grams in reference timelines while N-gram?CTdenotes the N-grams in the candidate timeline.Countmatch(N-gram) is the maximum number of N-gram in the candidate timeline and in the set of ref-erence timelines.
Count(N-gram) is the number of N-grams in reference timelines or candidate timelines.According to (Lin and Hovy, 2003), among allsub-metrics, unigram-based ROUGE (ROUGE-1)has been shown to agree with human judgment mostand bigram-based ROUGE (ROUGE-2) fits summa-rization well.
We report three ROUGE F-measurescores: ROUGE-1, ROUGE-2, and ROUGE-W,where ROUGE-W is based on the weighted longestcommon subsequence.
The weight W is set to be1.2 in our experiments by ROUGE package (version1.55).
Intuitively, the higher the ROUGE scores, thesimilar the two summaries are.4.4 Algorithms for ComparisonWe implement the following widely used sum-marization algorithms as baseline systems.
Theyare designed for traditional summarization withouttrans-temporal dimension.
The first intuitive way togenerate timelines by these methods is via a globalsummarization on collection C and then distribu-tion of selected sentences to their source dates.
Theother one is via an equal summarization on all localsub-collections.
For baselines, we average both in-tuitions as their performance scores.
For fairness weconduct the same preprocessing for all baselines.Random: The method selects sentences ran-domly for each document collection.Centroid: The method applies MEAD algorithm(Radev et al, 2004) to extract sentences accordingto the following three parameters: centroid value,positional value, and first-sentence overlap.GMDS: The graph-based MDS proposed by(Wan and Yang, 2008) first constructs a sentenceconnectivity graph based on cosine similarity andthen selects important sentences based on the con-cept of eigenvector centrality.Chieu: (Chieu and Lee, 2004) present a simi-lar timeline system with different goals and frame-works, utilizing interest and burstiness ranking butneglecting trans-temporal news evolution.ETTS: ETTS is an algorithm with optimizedcombination of global/local biased summarization.RefTL: As we have used multiple human time-lines as references, we not only provide ROUGEevaluations of the competing systems but also of thehuman timelines against each other, which providesa good indicator as to the upper bound ROUGEscore that any system could achieve.4.5 Overall Performance ComparisonWe use a cross validation manner among 6 datasets,i.e., train parameters on one subject set and exam-ine the performance on the others.
After 6 training-testing processes, we take the average F-score per-formance in terms of ROUGE-1, ROUGE-2, andROUGE-W on all sets.
The overall results are shownin Figure 4 and details are listed in Tables 4?6.Figure 4: Overall performance on 6 datasets.From the results, we have following observations:?
Random has the worst performance as expected.?
The results of Centroid are better than those ofRandom, mainly because the Centroid method takes439Table 4: Overall performance comparison on InfluenzaA (ROI?
category: Science) and Financial Crisis (ROIcategory: Finance).
?=0.4, kernel=Gaussian, ?=60.1.
Influenza A 2.
Financial CrisisSystems R-1 R-2 R-W R-1 R-2 R-WRefTL 0.491 0.114 0.161 0.458 0.112 0.159Random 0.257 0.039 0.081 0.230 0.030 0.071Centroid 0.331 0.050 0.114 0.305 0.041 0.108GMDS 0.364 0.062 0.130 0.327 0.054 0.110Chieu 0.350 0.059 0.128 0.325 0.052 0.109ETTS 0.375 0.071 0.132 0.339 0.058 0.112Table 5: Overall performance comparison on BP Oil(ROI category: Accidents) and Haiti Quake (ROI cate-gory: Disasters).
?=0.4, kernel=Gaussian, ?=30.3.
BP Oil 4.
Haiti QuakeSystems R-1 R-2 R-W R-1 R-2 R-WRefTL 0.517 0.135 0.183 0.528 0.139 0.187Random 0.262 0.041 0.096 0.266 0.043 0.093Centroid 0.369 0.062 0.128 0.362 0.060 0.129GMDS 0.389 0.084 0.139 0.380 0.106 0.137Chieu 0.384 0.083 0.139 0.383 0.110 0.138ETTS 0.441 0.107 0.158 0.436 0.111 0.145Table 6: Overall performance comparison on JacksonDeath (ROI category: Legal Cases) and Obama Presi-dency (ROI category: Politics).
?=0.4, kernel=Gaussian,?=30.5.
Jackson Death 6.
Obama PresidencySystems R-1 R-2 R-W R-1 R-2 R-WRefTL 0.482 0.113 0.161 0.495 0.115 0.163Random 0.232 0.033 0.080 0.254 0.039 0.084Centroid 0.320 0.051 0.109 0.325 0.053 0.111GMDS 0.341 0.059 0.127 0.359 0.061 0.129Chieu 0.344 0.059 0.128 0.346 0.060 0.125ETTS 0.358 0.061 0.130 0.369 0.074 0.133?ROI: news categorization defined by Linguistic Data Consortium.into account positional value and first-sentence over-lap, which facilitate main aspects summarization.?
The GMDS system outperforms centroid-basedsummarization methods.
This is due to the fact thatPageRank-based framework ranks the sentence us-ing eigenvector centrality which implicitly accountsfor information subsumption among all sentences.Traditional MDS only consider sentence selectionfrom either the global or the local scope, and hencebias occurs.
Mis-selected sentences result in a lowrecall.
Generally the performance of global priorityintuition (i.e.
only global summarization and thendistribution to temporal subsets) is better than localpriority methods (only local summarization).
Proba-ble bias is enlarged by searching for worthy sentencein single dates.
However, precision drops due to ex-cessive choice of global timeline-worthy sentences.Figure 5: ?/?
: global/local combination.Figure 6: ?
on long topics (?1 year).Figure 7: ?
on short topics (<1 year).?
In general, the result of Chieu is better thanCentroid but unexpectedly, worse than GMDS.
Thereason may be that Chieu does not capture suffi-cient timeline attributes.
The ?interest?
modeled440in the algorithms actually performs flat clustering-based summarization which is proved to be less use-ful (Wang and Li, 2010).
GMDS utilizes sentencelinkage, and partly captures ?correlativeness?.?
ETTS under our proposed framework outper-forms baselines, indicating that the properties weuse for timeline generation are beneficial.
We alsoadd a direct comparison between ETTS and ETS(Yan et al, 2011b).
We notice that both balancedalgorithms achieve comparable performance (0.386v.s.
0.412: a gap of 0.026 in terms of ROUGE-1), but ETTS is much faster than ETS.
It is under-standable that ETS refines timelines based on neigh-boring component summaries iteratively while forETTS neighboring information is incorporated intemporal projection and hence there is no such pro-cedure.
Furthermore, ETS has 8 free parameters totune while ETTS has only 2 parameters.
In otherwords, ETTS is more simple to control.?
The performance on intensive focused newswithin short time range (|last timestamp?first times-tamp |<1 year) is better than on long lasting news.Having proved the effectiveness of our proposedmethods, we carry the next move to identity howglobal?local combination ratio ?/?
and projectionkernels take effects to enhance the quality of a sum-mary in parameter tuning.4.6 Parameter TuningEach time we tune one parameter while others arefixed.
To identify how global and local biased sum-marization combine, we provide experiments on theperformance of varying ?/?
in Figure 5.
Results in-dicate that a balance between global and local biasedsummarization is essential for timeline generationbecause the performance is best when ??
?
[10, 100]and outperforms global and local summarization inisolation, i.e., when ?=0 or ?
= 0 in Figure 5.
Inter-estingly, we conclude an opposite observation com-pared with ETS.
Different approaches might lead todifferent optimum of global/local combination.Another key parameter ?
measures the temporalprojection influence from global collection to localcollection and hence the size of neighboring sen-tence set.
6 datasets are classified into two groups.Subject 1, 2, 6 are grouped as long news with a timespan of more than one year and the others are shortnews.
The effect of ?
varies on long news sets andshort news sets.
In Figure 6 ?
is best around 60 andin Figure 7 it is best at about 20?40, indicating longnews has relatively wider semantic scope.We then examine the effect of different projectionkernels.
Generally, Gaussian kernel outperformsothers and window kernel is the worst, probably be-cause Gaussian kernel provides the best smoothingeffect with no arbitrary cutoffs.
Window kernel failsto distinguish different weights of neighboring setsby temporal proximity, so its performance is as ex-pected.
Other 3 kernels are comparable.4.7 Sample Output and Case StudySample output is presented in Table 7 and it sharesmajor information similarity with the human time-line in Table 1.
Besides, we notice that a dynamic?i is reasonable.
Important burstiness is worthy ofmore attention.
Fewer sentences are selected on thedates when nothing new occurs.Interesting Findings.
We notice that humans havebiases to generate timelines for they have (1) pref-erence on local occurrences and (2) different writ-ing styles.
For instance, news outlets from UnitedStates tend to summarize reactions by US govern-ment while UK websites tend to summarize Britishaffairs.
Some editors favor statistical reports whileothers prefer narrative style, and some timelineshave detailed explanations while others are ex-tremely concise with no more than two sentences foreach entry.
Our system-generated timelines have alarge variance among all golden standards.
Proba-bly a new evaluation metric should be introduced tomeasure the quality of human generated timelinesto mitigate the corresponding biases.
A third in-teresting observation is that subjects have differentvolume patterns, e.g., H1N1 has a slow start and abursty evolution and BP Oil has a bursty start and aquick decay.
Obama is different in nature becausethe report volume is temporally stable and scattered.5 ConclusionWe present a novel solution for the importantweb mining problem, Evolutionary Trans-TemporalSummarization (ETTS), which generates trajectorytimelines for news subjects from massive data.
Weformally formulate ETTS as a combination of globaland local summarization, incorporating affinity and441Table 7: Selected part of timeline generated by ETTS for BP Oil.April 20, 2010s1: An explosion on the Deepwater Horizon offshore oil drilling rig inthe Gulf of Mexico, around 40 miles south east of Louisiana, causingseveral kills and injuries.s2: The rig was drilling in about 5,000ft (1,525m) of water, pushingthe boundaries of deepwater drilling technology.s3: The rig is owned and operated by Transocean, a company hired byBP to carry out the drilling work.s4: Deepwater Horizon oil rig fire leaves 11 missing.April 22, 2010s1: The US Coast Guard estimates that the rig is leaking oil at the rateof up to 8,000 barrels a day.s2: The Deepwater Horizon sinks to the bottom of the Gulf after burn-ing for 36 hours, raising concerns of a catastrophic oil spill.s3: Deepwater Horizon rig sinks in 5,000ft of water.April 23, 2010s1: The US coast guard suspends the search for missing workers, whoare all presumed dead.s2: The Coast Guard says it had no indication that oil was leaking fromthe well 5,000ft below the surface of the Gulf.s3: Underwater robots try to shut valves on the blowout preventer tostop the leak, but BP abandons that failed effort two weeks later.s4: The US Coast Guard estimates that the rig is leaking oil at the rateof up to 8,000 barrels a day.s5: Deepwater Horizon clean-up workers fight to prevent disaster.April 24, 2010s1: Oil is found to be leaking from the well.April 26, 2010s1: BP?s shares fall 2% amid fears that the cost of cleanup and legalclaims will hit the London-based company hard.s2: Roughly 15,000 gallons of dispersants and 21,000ft of containmentboom are placed at the spill site.April 27, 2010s1: BP reports a rise in profits, due in large part to oil price increases,as shares rise again.s2: The US departments of interior and homeland security announceplans for a joint investigation of the explosion and fire.s3: Minerals Management Service (MMS) approves a plan for two re-lief wells.s4: BP chairman Tony Hayward says the company will take full re-sponsibility for the spill, paying for legitimate claims and cleanup cost.April 28, 2010s1: The coast guard says the flow of oil is 5,000bpd, five times greaterthan first estimated, after a third leak is discovered.s2: BP?s attempts to repair a hydraulic leak on the blowout preventervalve are unsuccessful.s3: BP reports that its first-quarter profits more than double to ?3.65billion following a rise in oil prices.s4: Controlled burns begin on the giant oil slick.diversity into a unified ranking framework.
We im-plement a system under such framework for ex-periments on real web datasets to compare all ap-proaches.
Through our experiment we notice thatthe combination plays an important role in timelinegeneration, and global optimization weights slightlyhigher (?/?
?
[10, 100]), but auxiliary local infor-mation does help to enhance performance in ETTS.AcknowledgmentsThis work was partially supported by NSFC withGrant No.61073082, 60933004, 70903008 and61073081, and Xiaojun Wan was supported byNSFC with Grant No.60873155 and Beijing NovaProgram (2008B03).ReferencesJames Allan, Rahul Gupta, and Vikas Khandelwal.
2001.Temporal summaries of new topics.
In Proceedings ofthe 24th annual international ACM SIGIR conferenceon Research and development in information retrieval,SIGIR ?01, pages 10?18.Hai Leong Chieu and Yoong Keok Lee.
2004.
Querybased event extraction along a timeline.
In Proceed-ings of the 27th annual international ACM SIGIR con-ference on Research and development in informationretrieval, SIGIR ?04, pages 425?432.G.
Erkan and D.R.
Radev.
2004.
Lexpagerank: Prestigein multi-document text summarization.
In Proceed-ings of EMNLP, volume 4.Jade Goldstein, Mark Kantrowitz, Vibhu Mittal, andJaime Carbonell.
1999.
Summarizing text documents:sentence selection and evaluation metrics.
In Proceed-ings of the 22nd annual international ACM SIGIR con-ference on Research and development in informationretrieval, pages 121?128.Xin Jin, Scott Spangler, Rui Ma, and Jiawei Han.
2010.Topic initiator detection on the world wide web.
InProceedings of the 19th international conference onWWW?10, pages 481?490.Giridhar Kumaran and James Allan.
2004.
Text clas-sification and named entities for new event detection.In Proceedings of the 27th annual international ACMSIGIR?04, pages 297?304.Chin-Yew Lin and Eduard Hovy.
2002.
From singleto multi-document summarization: a prototype systemand its evaluation.
In Proceedings of the 40th An-nual Meeting on Association for Computational Lin-guistics, ACL ?02, pages 457?464.Chin-Yew Lin and Eduard Hovy.
2003.
Automatic evalu-ation of summaries using n-gram co-occurrence statis-tics.
In Proceedings of the Human Language Technol-ogy Conference of the NAACL?03, pages 71?78.442Yuanhua Lv and ChengXiang Zhai.
2009.
Positional lan-guage models for information retrieval.
In Proceed-ings of the 32nd international ACM SIGIR conferenceon Research and development in information retrieval,SIGIR ?09, pages 299?306.Qiaozhu Mei, Jian Guo, and Dragomir Radev.
2010.
Di-vrank: the interplay of prestige and diversity in infor-mation networks.
In Proceedings of the 16th ACMSIGKDD?10, pages 1009?1018.R.
Mihalcea and P. Tarau.
2005.
A language indepen-dent algorithm for single and multiple document sum-marization.
In Proceedings of IJCNLP, volume 5.D.R.
Radev, H. Jing, and M. Sty.
2004.
Centroid-basedsummarization of multiple documents.
InformationProcessing and Management, 40(6):919?938.Russell Swan and James Allan.
2000.
Automatic genera-tion of overview timelines.
In Proceedings of the 23rdannual international ACM SIGIR?00, pages 49?56.Xiaojun Wan and Jianwu Yang.
2008.
Multi-documentsummarization using cluster-based link analysis.
InProceedings of the 31st annual international ACM SI-GIR conference on Research and development in in-formation retrieval, SIGIR ?08, pages 299?306.X.
Wan, J. Yang, and J. Xiao.
2007a.
Manifold-rankingbased topic-focused multi-document summarization.In Proceedings of IJCAI, volume 7, pages 2903?2908.X.
Wan, J. Yang, and J. Xiao.
2007b.
Single documentsummarization with document expansion.
In Proceed-ings of the 22nd AAAI?07, pages 931?936.Dingding Wang and Tao Li.
2010.
Document updatesummarization using incremental hierarchical cluster-ing.
In Proceedings of the 19th ACM internationalconference on Information and knowledge manage-ment, CIKM ?10, pages 279?288.Rui Yan, Yu Li, Yan Zhang, and Xiaoming Li.
2010.Event recognition from news webpages through latentingredients extraction.
In Information Retrieval Tech-nology - 6th Asia Information Retrieval Societies Con-ference, AIRS 2010, pages 490?501.Rui Yan, Liang Kong, Yu Li, Yan Zhang, and XiaomingLi.
2011a.
A fine-grained digestion of news webpagesthrough event snippet extraction.
In Proceedings ofthe 20th international conference companion on worldwide web, WWW ?11, pages 157?158.Rui Yan, Xiaojun Wan, Jahna Otterbacher, Liang Kong,Xiaoming Li, and Yan Zhang.
2011b.
Evolution-ary timeline summarization: a balanced optimizationframework via iterative substitution.
In Proceedings ofthe 34th annual international ACM SIGIR conferenceon Research and development in information retrieval,SIGIR ?11.443
