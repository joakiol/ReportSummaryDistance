HELPFUL ANSWERS TO MODAL AND tlYPOTHETICAL QUESTIONSAmre De Roeck, Richard Ball, Keilh Brown, Chris Fox, Marjolein Groefsema, Nadhn Obeid, Ray TurnerUniversity of EssexEnglandemaih derce@uk.ac.essex (janet)1.0 ABSTRACT,This paper describes a computational pragmatic model which isgeared towards providing helpful answers to modal and hypothet-ical questions.
The work brings together elements from fonnal.semantic theories on modality m~d question answering, defines awkler, pragmatically flavoured, notion of answerhood based onnon-monotonic inference aod develops a notion of context, with-in which aspects of more cognitively oriented theories, such asRelevance Theory, can be accommodated.
The model has beeninlplemented.
The research was fundexl by ESRC grant numberR000231279.Keywords:Semantics, Pragmatics2.0 INTRODUCTION.Answers people give to questions have two basic properties:they may vary dependitig on the situation a question is asked in,and, especially if the answer is negative, they aim to be "helpful".The context-sensistivity of answering seems obvious and in noneed of further demonstration.
What precisely constitutes "help-fidness" is harder to pin down.
Modal and hypothetical questionsoffer an interesting mea for investigating "helpfulness".
SupposeA and B are going to a party and are discussing how they mighttravel.
Suppose A asks B Cat, youdrive.?
B is correct but perverseto respond ~ if he knows how to drive, has a valid licence buthas no car, or if he has a car but he has lent it to someone.
A morehelpful answer might be No.
because 1 haven't got a car.
Notehere that there is a range of "correct" answers, some of which areYe___~s: for instance Yes, I hww how to drive, Yes, !
lutve a licence,even Yes, I have a car', and some of which are N._oo, as in No, I ha-ven't got a car" tonight.
The range includes No, but !
cat, ask tOborrow my wife's car, or even Yes, i l l  .can get mF car back whichestablishes a link with hypothetical questions.
Note also that, foreach of these "correct" aqswers, we can imagine contexts inwhich they would be "helpful".Little is known ahout the nature of questions and their relation-ship to appropriate answers, or about how ,such answers can becomputed given some information about what the answererknows.
Some theories, mainly emerging from the Men*ague tra-dition (see Groeneudijk and Stockhof 119841), attempt to define"sema,tic" answerhood (see section 2.2), but fall short whentackling the pragmatic aspect of helpful answers.
Other theorieslSperber & Wilso, 19861 offer interesting pragmatic insights buttheir formulation does not allow for a straightforward hnplemen-ration.
Furthermore, the problem of answering modal and hypo-thetical questions is a compounded one which touches on a hostof issues including quantification, intensionality, partiality, beliefrevision, propositional ttitudes, etc.Our research aimed to draw up a formally specified and compu-rationally feasible pragmatic theory which could accommodateformal semantic views on answerhood as well as intuitive in-sights into "helpfulness" and its dependence on context (such asoffered by Relevaoce Theory \[Sperber and Wilson 19861).
Fur-thennore, the model is rigourously constrained as it must be test-ed by an implementation ver some knowledge base representingwhat an agent knows.This paper is intended as an overview of the computationalmodel.
As such it (Ices not provide an in-depth account of all as-pects of the investigation; in particular, it does not attempt to givea formal account of a basic theory of pragmatics, which is avail,able elsewhere \[Ball et al19901.
Rather, we sketch the back-ground to the problems involved in providing helpful answers tOmodal and hypothetical questions as a review of the relevant liter-ature aml its perceived shortcomings.
We will then proceed tooutline the intuitions behind our approach to a model of pragmat.ics aod its in~plementation, a d explain how it accommodateshelpful answers to modal and hypothetical questions.
An exam-ple is presented.3.0 IIELPFULNESS, MEDALS AND QUESTIONSThough tile problem of helpfully answering modal questionstouches on many issues, four particular points need to be ad,dressed.3.1 Modality.When looking at the example set out in the introduction, thequestion arises whether the range of "correct" answers to someextent corresponds to ambiguity (ability/possibility) residing inthe ,nodal can.
Indeed, a large proportion of the literature on mo-dality concerns the view that medals are polysemous, dependingon the kind and degree of modality they express (epistemic, deon.tic, etc.)
\[Palmer 1979, 1986; Quirk et at.
19851.
Usually, at-tempts are made to identify modal "primitives" (ability,permission, etc) and 1o analyse modal constructs as ambiguousover several "literal" meanings involving these primitives.
Invari-ably, polysemie reduetionist approaches to modal constructs runinto problems: given any classification of core types of modality,it is often hnpossible to determine which reading is involved inany particular example \[Coates 1983 versus Walton 1988\].Kratzer \[19771 lakes another view.
She presents a unified anal,ysis of modality which includes the treatment of conditionals(and hence hypotheticals).
Medals are unarubiguous and modalconstructs are analysed as tri-partite structures lsee also Partee1988, Heinz 1982\], comprising a ,nodal operator, a conversationalbackground, and a proposition.
For example, ill \[Kratzer 1977\]the modal mu..y?
in the following sentences:(at All Maori children must learn the names of theiraucestol~.
(b) The ancestors of the Maoris must have arrivedfrom Tahiti.
(c) If you must sneeze, at least use yourhandkerchief.
(d) When Kahukura-uui (lied, the people ofKahungunu said: Rakaipaka must be our chief.is traditionally analysed as (at 'deontic' must indicating duty, (b)'epistemic' must referring to a piece of knowledge or informa-tion, (c) 'dispositional' must, referring to people's dispositions(e.g.
they cannot help sneezing), and (d) 'preferential' must refer-ring to preferences and wishes.
Kratzer points out that classifica-tions of medals drawn in the polysemy paradigms neveradequately cover the data and that new examples are easily foundto demonstrate the need for ever more refined categories of modalmeaning.Kratzer wishes to propose a treatment that brings out the com-mon factor in all uses of mu~?
(and of other medals) and suggeststhat the burden of differentiation is to be placed on a variation in- 257  -context.
As such, tile meaning of (a)-(d) entertains a relationshipwith the meaning of (a')-(d') resl~ectively:(a) In view of what their tribal duties are, all Maorichildren lust learn the names of their ancestors.
(b) In view of what is known, the ancestors of theMaoris must have arrived from Talfiti.
(c) If, in view of what your dispositions are, you mustsneeze, at least use your handkerchief.
(d) When Kahukura-nui died, the people ofKahungutm said: In view of what is good for us,Rakaip',dr, a must 1~ our chief.and she defines the sematic interpretation underlying mt~al con-structs as a tripartite structure (applied to (b)):Sentence: Operator: Must in view ofFirst Argumeut: What is knownSecond Argument: The ancestors of the Maori havearrived fi'om Tahiti.The modal is an operator which takes a context and a proposition.The Intth conditions for t/!
?~st, interpreted as necessity, dictate thatthe modal construct is true if the proposition (the second argument)logically follows from the context (the first argument).
A similarapproach to can (possibility) unpacks its truth conditions as true ifthe context (the first argument) is logically compatible:(i.e, doesnot induce a contradiction) with the prgposition (the second argu-ment).
Kratzer works within the classical possible world tradition.Conversational backgrounds, modelled' as sets of propositions, areusually itoplicit and linked to tile utterance situation, though it isnot clear by what n~echanisru.
: :Kratzer 119831 proceeds to distinguish between different kinds ofconversational backgrounds, depending on the infornlation theycontain.
She does however experience difficulties when trying toidentify different context classes.
Indeed, it is as difficult to isolatedifferent conversational backgrounds as it is to pinpoint ile variousmeanings a modal might have.3.2 Quest ions attd AnswersIt is also necessary to present a coherent perspective on questions~md answers.
Groenendijk and Stockhof \[19841 compile an over-view of various treatnaents of questions that populate tile field andinvestigate desiderata for a semantic tlteory.
They arguethat inter-rogatives are entitled to a meaning of their own (and should not beviewed as, say, hidden imperatives) but that their treatment mustshow some equivalence with that of indirect questions.
The mean-ing of a question is to be related inextricahly with its answerhoodconditions.
Groenendijk and Stockhof work in the possible worldtradition and they cast the interpretation f a.qnestion as'a functionwhich, for every index, returns its tree answer.
Conskler the fol-lowing example.
The semantics givet~ to a question Does Peterwalk?
is a partition of the set of possible worhls into .two: thoseworlds where Peter walks, and those ~orlds where Peter does notwalk.
Both Peter walks and Peter does not walk are possible se-mantic answers to the question.
Each possible world belongs to oneor the other of these partitions, so each possible world offers onlyone true answer to the question.
This analysis caters for entailmentbetween questions (question Q entails question R if all true answersto Q are also true answers to R) and thus explains entailment be-tween coordinated questions.
Groenendijk mad Stockhof elaboratethe basic treatment of yes/no questions; wh-questions are reducedto this basic type.
They also provide an interpretation for constitu-ent answers.
They assume that modal questions will be analysed atsome other pragmatic level.The work described constitutes tile :most extensive treatuzent ofthe semantics of questions aml answers to date.
llowcver, in ourview, it cannot be directly incorporated in a pragmatic!model, fortwo reasons.
First of all, the semantic model assumes completenessof infonnation, and complete nmtual awareness of speakers' beliefstates (but then, wily ask questions of one another?).
They do at-tempt o build, from this, an account of how to reason with par-tial knowledge but, as they work in a traditional extensionalfrmnework, this results in clashes with the semantic theory.
(Inshort, what a person knows is a set of possible worlds, namelyall those possible worlds that are consistent with his/her beliefs.The semantics of questions is given as a partition over all possi-ble worlds, in an extensional framework - where intensions arederived from extensions - this means that if a person entertainspartial beliefs, he/she cannot know the meaning of a question.
)Secondly, there may be more than one true answer to a question,and all should be captured by Groenendijk and Stockhof's theo-ry.
But how are these answers defined, even computed, from thequestion7 And, as illustrated in the example given in the intro.duction, even if we know how to generate such answers, how dowe define a helpful answer?3.3 Helpfu lnessIt is not easy to give a definition of a "helpful" answer off thecuff.
Formal sere.antic theories have little to say on this issue,though some cognitively oriented frameworks have developeduseful views.Relevance Theory {Sperber and Wilson 1986\] has given an ac-count of context-sensitivity in cormnunication.
It postulates thatwhen people understand, they attempt to maximise relevance -i.e.
tbey pick the context against which the relevance of an utter-ance is greatest.
Relevance, thus, is quantifiable and defined bymeans of extent conditions: an assumption is relevant in a con.text to the extent hat its effects in this co,ltext are large and theeffort to process \[t is smaU.it should be clear from the onset hat the specification of Rele-vance Theory i snot  precise enough to be implemented as itstands.
There are, however, three principles which axe interest-ing for our purpc~/e.
(i) The most relevant context for interpret-ing a question is that a Ye__a-answer is desired.
This helps towardsexplaining why helpful answers are given at all, and why theyoccur typically with negative answezs.
(ii) The selection of  rele-vant contexts is eml~died in the human cognitive machineryand ensures that, an utterance receives only one interpretation(and not many from which a particular one is selected).
Indeed,as shown in the introduction, there may be more than one trueanswer to a question but only one appropriate one, which mustbe characterized..(iii) The theory specifies that all contextual ef-fects are explained against the background of assumptionswhich a person may hold and postulates mechanisms by meansof which relevant contexts can be pinned down starting from sit-uational information and the utterance itself.3.4 ContextThe necessity to give a more precise definition of context be-comes obvious from the previous sections.
Questions can onlybe answered in context, medals seem to receive different inter-pretations according to varying contexts, and any cognitivelyappealing notion of "helpfulness" or "relevance" is stated interms of contexts.
Al l  this ties in with current work in formal se-mantics which explores tri-partite structures (tying in contextwith propositional content of utterances) as a basic mechanismfor semantic interpretation Il leim 1982, Partee 19881.
However,though current formal semantic theory is steadily increasing theworkload of context, its precise nature remains vague.
It is notenough to furnish fonnal semantic interpretations "relative" tosome context: a satisfactory approach to a formal but cognitive-ly attractive characterization f  "helpful" answers eems to war,rant a closer look at the content of conversational backgrounds,their relation to ihe utterance and its situation, and an apprecia-tion of whether they can be computed.The insights offered by Relevance Theory may be compatiblewith fonnal (and computational) semantic theories, and offer apractical starting point when trying to pin down a fuller notion- 258  -of context.
In order to investigate this, we need to define our intui-tions in an implementable fr,'unework.
Please note that it is not ourintention to attempt a foml.
'disation or an implementation f Rele-vance Theory, but merely to define an experimental franlework ca-pable of handling contexts in order to derive helpful answers tomodal and hypothetical questions, alheit exploiting insights frontRelevance Tlleory if possible.4.0 TOWARDS A Ti lEORY OF PRAGMATICSIt is our intuition that, when people communicate, they know dif-ferent hings, or there woulkl be no point in communicating.
Thus itseems that any realistic inodei of communication must allow forpartiality in what agents know.
Since agents retain inferential capa-bilities, we assume their beliefs are consistent.
As a consequence,.our model represents agents as partial, consistent sets of proposi-tions.
The notion of proposition deployed is takon straight fromProperty Theory ITumer 1987, Chierchia el al 1989, see also Ram-say 19901, a weak first order theory with fine grained intensionali-ty.Questions are not themselves propositions; they are not associat-ed with truth values.
They do, however, entertain a relationshipwith propositions.
In our view, a simple yes/no question embodiesa proposition whose truth value is notknown to the agent askingthe question.
An answer to the question is any proposition which, ifadded to the agent's beliefs, will force truth or falsity of the propo-sition embodied in the question.
This view on answerhood is muchlooser than the one adopted by Groenendijk and Stockhof in that itallows answers other than true semantic answers.
Indeed, any an-swer will do as long as it allows all agent o conclude to the true se-inantic answer.
Thus, a question Does Peter walk?
may beanswered by Peter sleeps in this framework (and not just by eitherof Peter walks or Peter does not walk) as long as that informationallows the agent o conclude that Peter walks or that Peter does notwal.k.
This constrains the agent's reasoning capacity which nmstnow deal with partial information.
It also means that agents' beliefsmust he subject o revision.In order to reflect hese intuitions in our theory, we extended thelanguage of Property Theory with a predicate which holds of ques-tions, and an operator which, given a proposition, will yield a ques-tion.
An axiomatisation governs conjunction of questions.
Arelation of answerhood is defined which holds between a questionand its answer (a proposition).
The behaviour of this relation isgiven through axiomatisation f a proof theory.We adopt a view on inodality parallel to Kratzer's: our workinghypothesis states that modals are not ambiguous and that any dif-ference in interpretation resides in contextual diversity.
We do not,however, try to classify contexts; a hopeless task which is no differ-ent to attempting toclassify modal mnbiguity.
~a.n and must corre-spond to the inodal operators of passibility and necessity.
Modalconstructs are analysed in terins of these operators, a context attd aproposition.
A context is a collection of propositions, which is acohsistent subset of the agent's total beliefs.
Necessity is true if thenegatiotl of the proposition causes a contradiction i the context;possibility is true if the proposition can be accolmnodated withinthe context without giving rise to a contradiction (i.e.
the contextcan he updated with the proposition).Questions, whether they are simple or modal, are equally analy-sed as tri-partite structures COlnprising an operator, a context and aproposition.
For simple yes/no questions file operator is the Ques-tionTruth predicate (which can he safely stated in Property Theo-ry).
For modal questions, tile operator is tile Question counterpartof the appropriate modal operator.
As with Groenendijk and Stock-hof, wh-questions are reduced to yes/no questions.
It should followfrom tile above that Groenendijk and Stockhof's results carry overinto this model, as the notion of semantic answedtood is preserved(though in an extended franlework).Following Kratzer, conditionals are treated like modals but timcontext is ulxlated with the antecedent.
We are not, however,treating connterfactuals at this stage (i.e.
we only treat caseswhere the context can be uixlated with the antecedent and wber?no contradictions occur as a result).fu defining "helpfulness", we take the view of Relevance The-ory that a positive answer to the proposition embedded in timquestion is desirable.
As such, yes-answers become uninterest,ing as they are already nmximally helpful.
No-answers, on theother hand, where the proposition cannot be accommodated bythe context, can be helpful if they indicate why the propositionis inconlpatible with a state of affairs, or how the state of altairsmight change so that it can be updated with the proposition.
Inthe theory, this information is available frum the logic underpin-ning the answerhood relation relativised to a context.
However,this furnishes us with a semantics only.
To arrive at some viewof how this may interact with pragmatics, the content of con-texts must be fleshed out.Intuition tells us that only one helpful answer is furnished percontext.
Following Kratzer, and Relevance Theory, we assumethat the burden of being helpful and relevant rests with thenlechanism which defines the context for an utterance given asituation.
Many factors may contribute to this mechanism and itseems reasonable that knowledge of the physical circumstances(i.e.
speakers, time, location, etc.)
should play a role.
The utter,ance itself must also contribute.
As the literature offers no de,tailed information on how io model tim relationship betweencontext and utterance, we have developed an implementation fa context machine which, initially, derived context from lexicalinformation.
This hnplementation was changed and refined inorder to attempt to determine xperhnenlally what the require-merits for a "context machine" Inay be.5.0 TI lE IMPLEMENTATION5.1 The Overali FrameworkThe implementation f the overall framework consists of aparser, a knowledge base, a context machine and a theoremprover.
The knowledge base, a consistent collection of proposi.lions, is set up to represent the beliefs of an agent who is to an-swer questions.
For convenience of computation, the items in itare cast as sorted property-theoretic expressions (a sortal hierar-chy can he achieved without sorting quantified variables - sort-ing and closing the world with respect to individuals merely hasthe effect of rendering the ilnplementation f the first order lan-guage decidable), Each knowledge base item is tagged withkeys linking the information it contains with words in the lexi-COll.The parser, a bi-directional chart parser \[Steel and De Reeck19871 augmented with feature structures, works from an essemdally context free rule base where semantic translation rules ar cpair~!
up with tim syntactic statement.
The semantic representa-tion delivered by the parser is an expression i  Property Theorycapturing the structural aspects of question's meaning.This Property-Tbeoretic expression is passed to the context,machine.
It yields, from the Property-Theoretic expression, a tri-partite structure comprising an operator, a context and a proposi-tion derived from the question.
The role of the context machineis to extract from the knowledge base that information which isrelevant o finding a helpful answer to the question.The proposition delivered by the context machine is given inthe language of the logic K-T IOheid 1990\].
K-T is a proposi-tional, non-monotonic logic which employs Kleene's strongthree-valued colmectives, aqd which is extended with two mod-al operators (the language can he propositional s the knowl-edge base is sorted and closed).
The semantics of the logic ar?~expressed in terms of states of partial information which allowan agent o he uncertain about the truth or falsity of his knowl-- 259  -edge, and where possible, to make assumptions on the basis ofwhat is not known to be false.
The infereoce rules of K-T are givenin the Appemlix.The propositional content of the input question is set against asuitable subset of the agent's knowledge, i.e.
the context.
The theo-rem prover then attempts to prove in the system K-T that the prop-ositional content of the input question follows from the context.This it might achieve monotonically; or non-monotonically withthe aid of assumptions, it is the record left in the wake of the proofprocess in each case, which we interpret in order to provide a help-ful answer.5.2 The Theorem Prover.The theorem prover is a three valued, modal analogue of a seman-tic tableau theorem prover \[Beth 1962; Jeffrey 19671.
This methodperfonns a case-wise analysis of all models in which the premises(read context) might be true while contradicting the conclusion(read propositional conteqt of the inpu\[ question), if no such mod-els are found to exist, the theorem is proven.
We employ this meth-od because it allows a user absolute access to every stage of theproof process.
We then exploit this access in order to find a helpfulanswer.
If a proof succeeds monotonically, the agent's answer issunply Yes.
If it succeeds by means of one or more assumptions,the answer is of the fonn Yes, if .... where the body of tile/f-clauseis the infonnation that was assulned.
Where a proof fails, we havethe task of detennining the reason why it failad - i.e.
which as-sumptions shouhl be made to yield a y._e.~-answer.
The proof processconstructs a tree of which the branches represeot individual mod-els.
These models are closely or distantly related to one =mother ac-cording to how much of the proof tree they have in conunon.
Afailed proof has one or more models which are consistent, a,ldtherefore counterexamples to our intended inference.
We are ableto compare these consistent models with closely related inconsis-tent ones.
We can theo identify the contradiction which is in somesense missing.
- i.e.
we point to the particular premise or premiseswhich are too weak to support he inference.
A helpful answer inthis case takes the form No, unless ... and the body of the unless-clause is composed of the strengthening required in a premise orpremises o that the counterexampleswould no longer arise.
Thismethod remains constant regardless Of the actual content of thecontext.
Note that a single answer is always yielded and that theborden of assuring that its content is "helpful" rests entirely on thecontext machine.5.3 The Context Machine.Different inlplemeotations of the context selection mechanismhave been attempted.
Originally.
it 6perat.ed by intersecting thatpart of the knowledge base which concerns the individuals and re-lations mentioned in the utterance.
In this sense, it relied exclusive-ly on lexical information as the process operated by selectingpropositions associated with lexicai items reflected as objects in theknowledge base.
It used closure on the sortal hierarchy to achievethis.
This approach is compatible with Relevance Theory as it canbe argued that Encyclopedic IOiowledge can be thus implemented.A side effect is lexical dismnbiguation - different readings of aword are associated with different clusters of information; onlycompatible infonnation will survive the intersection.This version was tested on a knowledge base modelling a build-ing site, containing information about, buildings, workers, materialsand time tables.
The domain proved too complex to allow for anyconclusions to be drawn: the diversity of objects whose behaviourneeded modelling (including some beyond tile current state of theart - e.g.. mass vs count objects, plurals, time and teose, etc.)
wasprohibitive.
Two other domains were tackled as a consequence:marital relationships and law, and the simple situation of what ittakes to drive a car.Eveo against simple domains, it became clear that mere relia~lceon keying lexical infonnatiou would not be sufficient.
The searchspace remahled large and insufficiently focussed as it includedpropositions which never contributed to deriving an answer, anda closer interaction between context machine and proof processshould be postulated.
It seems that tile context selection mecha-nism must have a model of inference.
An attempt at such amechanism was developed.The cootext machine Mark II extracts from the knowledgebase any information which enable the truth of the propositionassociated with tile question to be derived.
Any implication inthe knowledge base with that proposition as a consequent is se-lected to form part of the context and all rules and assertionswhich enable the truth of the antecedent of the hnplication to bederived axe also included.
Any other rules, which cannot im-pinge upon the truth of the goal clause, are omitted as they are'irrelevant' o the proof.
In a sense, this selection process antici-pates the structure of the proof itself.
In the full system, the in-stantiation of quantified variables in sentences extracted fromthe knowledge base, is restricted to those individuals mentionedin the question, or relevant o those assertions made about indi-viduals mentioned in the question.
This is implemented usingthe sortal hierarchy.
The examples given in Section 5 are de-rived using this version over a very restricted omain.Though the results were more satisfactory, the contexts de-rived in complex domains are still large.
Though all informationselected plays a part in the overall proof, the search space is uni-fonn for each proof branch.
It became clear that a full interac.tioo between the structure of the proof and context selectionnmst be achieved.
A third version of the context machine at-tempted to derive contexts local to particular steps in the proofprocess.
Though incomplete, the experience gained in the at,tmnpt convinced us that the selection of 'relevant' contextual in-formation is dynamic, hffonnation pertaining to particular stepsin the derivation of all aqswer should be local to that step anddiffereot 'relevant' contexts hould be made accessible as thederivatiou progresses.6.0 AN EXAMPLEThis sectioo elaborates an exanlple to illustrate (i) the basictheorem prover and (ii) the behaviour of context machines.
Tosinlplify the examples, we consider the case where there is onlyone individual, Anne.
The set up coocerus finding a helpful an-swer to Cm~ Antic drive?
First we present a successful proof,working from an optimal context which yields that Anne can in-deed drive.
The rules to tile theorem prover (K-T IObeid 1988\])are given in the Appendix.
Notice that premises are theorems ofthe logic and so any premise of form ~ is logically equivalent to~M - 7t.III M -dr ive(a)  goal 131 iicenced(a) premise121 ownscar(a) premise \[41 skilltodrive(a) premise151 ownscar(a) & liceoced(a) & skilltodrive(a) -> drive(a)premise171 ~M - drive(a) Line 5 - contradiction 171 /11161 -M  (ownscar(a) & liceoced(a) & skilltodrive(a))t81 ~M ownscar(a) Line 6 - contradiction \[81 121191 ~M (licenced(a) & skilltodrive(a))\[101 -M iicenced(a) Line 9 - contradiction \[101 \[31\[ 11J ~M skilltodrive(a) 0 141The theorem prover eports that the inference KB I- drive(a) isproven by refutation.
This we know because ach path is incon-sistent.
The inference was proven monotonically (there was noneed for assumptions) and required no sub-proof.
The answerhere is Ye___ss: Anne can drive because she has a lieence, she ownsa ear and she has tile required skills.In the second example, the premise that Anne has a licence isremoved.
The proof fails to show monotonically that Anne eaqdrive.
"llae system therefore ,sets out to assume that Anne mighthave a licence and thus attempts to fill the gap in the agent's in-- 260  -fonnatiou.
Rule: R3 (see Appendix) allows us to infer M g for anyg if we ca,mot prove ~ n.i l \]  M ~ drive(a) goal|21 owuscar(a) premise 141 skilltodrive(a) premise\[4\] ownscar(a) & licenced(a) & skilltodrive(a) -> drive(a)premise\[61 ~M ~ drive(a) Line 4 ?
contradiction \[6\] \[1\]\[5\] -M (ownscar(a) & licenced(a) & skilltodrive(a))171 ~M ownscar(a) Line 5 - contradiction \[7\] \[2\]\[ 81 ~M (licenced(a) & skiUtodrive(a))191 -M skillt<~drive(a) Line 8 - contradiction \[9\] 131\[ 101 -M licenced(a)In this case, if we can assume the premise M licenced(a) success-fully, we can prove tile original assertion monotonically.
In thiscontext here are no fonnulae which might affect he truth of M li-cenced(a) so our proof succeeds trivially.
The answer here is Yes, i\[Anne has a licence.
In the next exmnple, we add explicitly thatAnne does not have a licence.
We assume that this infomlation isknown and does not need a sub-proof.\[ 1 \] M - drive(a) goal I31 ~M licenced(a) premise\[21 ownscar(a) premise \[4 !
skilltodrive(a) premise151 ownscar(a) & iicenced(a) & skilltodrive(a) -> drive(a)premise17\] ~M - drive(a) Line 5 - contradiction 171 i l \ ]\[61 ~M (ownscar(a) & iicenced(a) & skilltodrive(a))181 ~M ownscar(a) Line 6 - contradiction \[8\] 12\]\[9\] ~M (licenced(a) & skilltodrive(a))110\] ~M skilltodrive(a) Line 9 - contradiction llO\] \[41\[ 11 \] ~M licenced(a)Again, the proof fails monotonically as in the second example.An attempt o hold an assumption that Anne has a licence will,IIowever, fail as it will contradict the premise \[3\] which states thatsuch an assumption is false.
The answer in this case is No, becauseAntle doe~ not Ilave a licenfe.The procedure for dealing with hypotheticals i  similar but thecontext is updated with the antecedent before the proof of the con-sequent is carried out.
Counterfactuals, which would require totalrevision of the knowledge base, are not treated.We can use these examples to illustrate the problems faced withselecting the appropriate contexts to yield helpful answers.
Theearliest version of the context machine would have selected all in-fonnation associated with domain objects directly related to thewords in the sentence (Anne and driving), and all information asso-ciated with the sortal hierarchy involving those objects.
The unionof all these propositions produced a context hat was not adequate:only some properties of Anne will affect hdr driving, and not allknowledge about vehicles will contribute to finding an answer towhether Anne can drive.
Itatersection f clusters of information ob-tained by closure on tile hierarchy has tile side effect of achievinglexical disambiguation, but, in complex domains, it excluded somerelevant facts from the context, whilst still including propositionswhich could never play a role in the proof.
A more title grained ap-proach was needed.In tile second hnplementation, the context machine selected onlythose propositions which could lead to a goal.
Any implication inthe knowledge base with the goal as a consequetlt is extracted, asare all assertions that contribute to establishing the troth of any ofits antecedents (recursively).
The proof is established against hiscontext as a whole.
Whilst significantly reducing the size of the m-suiting context as well as focussing its content on what the proofmight turn out to be, them are problems with this approach.
Imag-ine the situation where Anne has the skill to drive, she owns a car,but she does not have a iicencc because she has to pay her fines.She did not pay her fines because she has no money.
All this infor-mation would be extracted as a total context for answering thequestion Cat: At#ne drive?\[11 M - drive(a) goal \[3\] skilltodrive(a) premise\[2\] owuscar(a) premise \[4\] ~M hasmoney(a) premise\[5\] hasmoney(a) -> payfmes(a) premise\[6\] payfmes(a) -> licenced(a) premise\[7\] ownscar(a) & licenced(a) & skilltodrive(a) -> drive(a)premise\[8l --M ~ drive(a) l.J'ne 7 - contradiction \[8\] il1\[9\] ~M (ownscar(a) & licenced(a) & skilltodrive(a))\[101 -M ownscar(a) Line 9 - contradiction \[10\] \[2\]\[ 11 \] -M (licenced(a) & skilitodrive(a))\[12\] ~M skilltodrive(a) Linell - contradiction \[12\] 13\]\[13\] ~M licenced(a)\[14\] licenced(a) Line 6 - Contradiction \[14\] \[13\]\[15\] ~M payfines(a)\[ 16\] payfines(a) Line 5 - Contradiction \[16\] [15\]\[17\] -M hasmoney(a)The proof to \[13\] mimicks that of exmnple 2 above, but now,an attempt to establish whether Anne has a licence requires asub-proof.
The proof fails to close on the assumption that Annehas money.
It cannot be inferred non-monotonically that Annehas money (because of \[4\]).
The answer in this case is No.
be,cause Anna has ,no money.
Some explanation is due here.Though tile answer offered in the last example is "correct", andthem might he situations in which it is helpful, it is intuitivelyarguable that an answer No, because Anne ha~ no licence ismore helpful.
The point is that this version of the context ms,chine does not cater for the possibility of giving this latter an-swer under any conditions.
From this we conclude that a closetinteraction between context machine and proof structure is nec-essary.
A helpful answer should not be confined to the ultimatereasons why the reply is No: die answer should depend uponsome measure of "closeness" in contexts.
Contrary to the as-sumptions we made at the start of this project our conclusionslead us to postulate that such a view is indeed necessary to pro.vide a fine grained notion of helpfulness.We have no treatment of mutual beliefs so far (but Davies\[19901 is compatible and promising).
We need to extend the log-ic so it can reason with varying domains if we are to exploit fulltile intensionality provided by the Property Theory.
We havestarted work on a treatment of time and tense in this framework.7.0 CONCLUSIONSWe have developed a semantic theory of questions using Prop,erty Theory.
We have investigated (i)pragmatic answerhood and(it) modality using an experimental computational framework.We believe that the insights gained from the work have bee 0valuable: they cohtribute towards our understanding of the re-qukements for a fonnally specified and computationally tracta-ble theory of pragmatics which is capable of incorporatingiusights from cognitively oriented theories.
Furthermore, the ex-periment has pointed out that some of the intuitions underlyingRelevance Theory are accurate and useful, especially with re-spect to context refining strategies necessary for characterisinghelpful answers.8.0 REFERENCESBall, R. E.K.
BrOwn, A.N.
De Roeck, C.J.
Fox, M. Groefsema,N.
Obeid and R. Turner 0990) Helpful Answex ~ to Medal andHvoothetical Questions: Final Report, Cognitive Science Cen.tfe Memo, University of EssexBeth, E.W.
(1962) Formal Methods.
Dordrecht, ReidelChierchia, O., B. Partee and R. Tumer (1989) Pro verties.
Tv~sand Meaning, Dordrecht, Kluwer Academic PublishersCoates, J.
(1983) The Semantics of tile Modal Auxil.iaries, Lon-don, Croom HelmDavies, N. (1990) 'A First Order Logic of Truth, Knowledgeand Belief', Proceedings of ECAI 1990- 261  -Groefsema, M., C.J.
Fox and N. Obeid (1991) 'Can, May, Mustand Should: A division of Labour', Paperaccepted at the LAGB,Somerville College, Oxford.Groenendijk, J. and M. Stockhof 41984) Studies on the Semanticsof Questions and the Pragmatics of Answers, PhD.
Dissertation,University of AmsterdamHe*m, 1.
(1982) The Semantics of Definite and h~definite NounPhrases, PhD Dissertation, University of Massachussetts, Am-herst (Mass.
)Jeffrey, R.C.
(1967) Fonnal Logic, its Scope and Lhnits, London,McGraw-HillKratzer, A.
0977) 'What 'must' aod 'can' must and can mean',Linguistics and Philosophy, Vol 1-3 : 337-355Ksatzer, A.
(1981) 'The Notional Category of Modality', in Eilan-eyer and Rieser (eds) Words, Worlds and C0ntex.tS, Berlin, Walterde GruyterObeid, N. (1988) 'A Propositional Logic for Reasoning aboutReal-Time Situations', in IASTED h~temational Conference, LosAzlgeles, California.Obeid, N. (i 990) Partial Models Basis for Non-monotonic Reason-in~, Research Note CSM-140, Department of Computer Science,University of EssexPalmer, F.R.
41979) Morality and tl3e English Modals, London,Long=nanPalmer, F.R.
(1986) Mood and Morality, Cambridge, CambridgeUniversity PressQuirk, Q. et al41985) A Comprehensive Gr~munar of the EnglishLanguage.
London, LongmanRamsay, A.
(1990) The Logical Structure of English, London, Pit-man PublishingSpetber, D. and D. Wilson (1986) Relevance: Conmmnication andCognition, Oxford, Basil BlackwellSteel, S. and A.N.
De Roeck (1987) 'Bi-Directional Chart Parsing',in Hallam mid Mcllish (eds) Advances in ,M., London, John WileyTurner, R. (1987) 'A Theory of Properties', Jo~rual of Symbolic~--~-gLq, Vol 52, No 2 : 455-472Turner, R. (1990), Truth and Modality for Knowledge Representa-tin___n, Pitman & MIT Press, London.Walton, A.
(1988), The Pragnmtics of English Modal Verbs, PhD.Dissertation, University of London.APPENDIXKleene-Turner's (K-T) System \[Obeid 1988\]Complete infonnation is hard to obtain, even in the mostmanageablc situations: in most cases, a reasoner does not knoweverything that is pertinent to the investigation athand, There arepropositions whose troth status cannot be decided.
However, mostof the classically based non-monotonic formalisms eem to resortto adding intermediary troth values between troth and falsity.
This,in fact, is one of the basic anti most imporlant features whichdistinguishes three-valued logics from the classical one.
Such adifference is reflected semantically by partial models (partiallystates of information) for thrce-valned logics as opposed topossible words (complete status of knowledge) for classicallogic.
In this section, we shall develop the logic K-T.In K-T a proposition is either accepted as true, accepted as falseor not known at all.
The basic language LK.
T which we shall useis a propositional logic.
Starting with primitive propositions T(tmc), F (false), p,q,r .... more complicated ones are fonned via clo-Sure under negation ~, conjunction &, disjunction V, implication --->and epistcmic possibility M. That is, if A and B are well-formedformulae then so are ~A, A&B, AVB, A --> B and MA.
Let N hethe dual of M, i.e.
NA=~M.
~, --~, & and V are Kieene's tong con-nectives.
Given A, MA is false if A is false, otherwise MA is true.~, & and M may be taken as primitives.
V and --> may he definedin terms of & ,and ~ as follows:Definition I.
A V B= ~(-A & ~B)Definition 2 (A --~ B) = ~A V BLet A <- -> B stand for (A --.)
B) & (B ---) A).
Note that Kleen-e's strong implication --~ is not truth functional, i.e.
A --) B isundefined if both A and B are undefined.
We also define a tmth-fucntional implication D as follows:DeJinition 2.3.
(A D B) = M(~A & B) V ~A V B .
=3 is trothfunctional in the sense that the truth value of A D B is true ifboth A and B have the same troth value.
Let A = B stand for(AD B)& (B ~ A).Definition 2.4.
A model structure for LK.
T is K = <B, R, g>where B is non-empty set, R is a binary relation on B and g is atruth assigmnent function g for atomic wffs.
The interpreta-tion of R may be thought of as "epistemic possible" extensionbetween states.
Given b, bl are members of B, we shall write bR bl to mean that the state bl is an "epistemic possible" exten-sion of the state b.We employ the notation K I= g A (resp.
K =1 g A) to mean thatA is accepted as true (resp.
false) in K with respect o g. Forconvenience, reference to g will be omitted except when a con-fusion may arise.
Let A, B he wits; then the truth I= and the fal-sity =1 notions are recurs*rely defined as follows:Definition 2.5.
(i) K,b I= T(ii) K,b I= p iff g(b,p) = tree for p atomic(iii) K,b I= A & B iff K,bl= A and K,b I= B(iv) K,b I= ~A iff K,b =1 A(v) K,bl= MAiff(-\]  bl e B) (bRb l  and K, bl  I#~A)(i') K,b =1 F(ii') K,b I---p iffg(b.p) = false for p atomic(iii') K,b =1 A & B iff K,B =1 A or K,b =1 B(iv') K,b ---I ~A iff K,b I= A(v') K ,b=lMAi f f (Vb le  B) (if b R bl then K,bl l= ~A)The logic K-T is the smallest set of LK.
T which is closed underthe following axiom schemas and inference rules.
We shallwrite I- K-T A to mean that A is a "theorem" of K-T.Axiom Schemas:(al) A D (13 =3 A&B) (aS) ~~A = A(a2) A D (B --> A) (a6) - (A & B) == (~A V -B)(a3) A&B:~AIA&BDB (aT) A -eMA(a4) A --~ B) D |(B --~ C) D (A --~ C)\]Inference Rules:Modus ponens (Mp) for ~ together with (R 1), (R2) and (R3).
(RI) From ~ A V B infer -MA V B(R2) From A =3 B infer MA --~ MB(R3) .
.
.
.
.
.I- MA- 262  -
