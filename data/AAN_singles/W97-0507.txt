IUs ing  NLP  in the  des ign  of a conversat ion  aid for non-speak ingch i ld renPortia FileSchool of InformaticsUniversity of Abertay DundeeBell Street, Dundee DD1 1HGScotland, UKp.
fi le~tay, ac.ukLeona ElderSchool of Social and Health SciencesUniversity of Abertay DundeeBell Street, Dundee DD1 1HGScotland, UKi.
elder@ray, ac.
ukAbstractIt is difficult to develop an effectivecomputer-based aid to enable childrenwhose speech is hard to understand to par-ticipate in social conversations.
Such chil-dren require a relatively simple device thatwill enable them to select and produce suit-able content for a conversation i real time.We are investigating how an analysis ofchildren's language can be used in the de-sign of such a device.
In particular, we be-lieve that an analysis of the pragmatics ofchildren's conversations will provide a ba-sis for predicting from a corpus of plausi-ble utterances those utterances that will bemost useful for a particular child.
Suchan analysis may also be useful for subse-quently predicting and locating which ofthese pre-loaded utterances i likely to berequired next during a particular conver-sation.
In addition, we are interested inusing computer-based training for the aid.Given that all of the child's speech will beproduced through the computer-based aid,it may be possible to provide intelligent in-teractive training.1 IntroductionChildren who cannot speak tend to be socially iso-lated from their peers.
We are currently developinga computer-based device, called PICTALK, to sup-port their casual conversation and hence their so-cial development.
Because the system is intendedfor children, we need careful control of the cognitivedemands made on the system's users.
We wish toinvestigate how the methods developed in NLP re-search can be used to improve the effectiveness ofPICTALK in supporting the conversations of theseusers without increasing its complexity.The PICTALK system (File et al, 1995a); (Fileet al, 1995b) is intended to support he casual con-versation of people who can neither 4ad nor speak.It is based on the TALK system (Todman, Aim, andElder, 1994a) for people who can read but who arenot able to speak.
With PICTALK, pictures andlabels are used to indicate the content of utterancesthat the user can choose to speak (using a speechsynthesiser).
Content utterances are stored withinan organisational framework (provided for the user)that is designed to enable their prompt retrieval in'real-time' conversations.
The content available toa PICTALK user is very limited for two reasons.First, each PICTALK screen has few items or 'but-tons' available because ach picture takes up quite abit of space.
Further, the number of screens that canbe accessed by a user using the organisational frame-work is restricted by the need to limit the complexityof the system to that suitable for someone who is ei-ther very young or who has learning difficulties.
Itis important to use any methods we can, e.g.
predic-tive methods, that will reduce the cognitive load onthe user or that will allow the user effective accessto a larger set of utterances.The content of informal conversational exchangeis often subordinate to its social aspects.
Therefore,our emphasis on casual conversation leads us to focusmore on supporting those social aspects of conversa-tion rather than on the delivery of information.
Ourprincipal goal is to allow the system's users and theirconversational partners, working together, to havepleasant social interactions.
To achieve this goal,we are examining the pragmatic structures of chil-dren's successful unaided conversations and wouldlike to use the relationships between these structuresto predict content.432 The  pragmat ics  o f  ch i ld ren 'sconversat ionsMcTear (McTear, 1985) has examined the pragmat-ics of children's conversations.
The main pragmaticstructures he notes are: greetings, initiations, at-tention getting, attention directing, conversation re-pair e.g.
repeating an utterance or requesting or re-sponding to a need for clarification, and use of dis-course connectors for topic shift or to continue theconversation after repair and to signal turntaking.
'Ihrntaking exchanges can be to initiate, respond,follow-up or conduct a simultaneous response withinitiation (e.g.
"Is it in the cupboard" in response to"where is it?").
Even young children use verbal andnon-verbal means to accomplish these activities aswell as changes in prosody and variations in polite-ness depending on the partner.
We are interestedin investigating ways in which we can assist childrenin carrying out these activities by using predictionwithin PICTALK's organisation structure to reducethe complexity of the process required for finding thenext appropriate utterance.3 P ICTALK fo r  Ch i ld renPICTALK has many features that support he aboveactivities.
These include the use of pre-loaded text, amenu controlled organisational structure that mod-els conversation flow and additional items specifi-cally designed to keep the flow of conversation going.There may be a potential for NLP to contribute tothe enhancement of these and other aspects of thePICTALK system.3.1 The  role of  p re - loaded ut terances  inP ICTALKThe PICTALK system allows the user to pre-loadpotential conversation fragments that may be usefulin some future conversational interaction.
The sub-stantive content of these fragments may be inputwith a particular interaction and a specific conver-Sational partner in mind or it may be more generalfor use with any of a number of potential partners.This pre-loading process may be very slow but it canbe carried out whenever the user has time to do itand under circumstances when there will certainlybe much less time pressure than during actual con-versation.
The intention is that the user will be ableto access these pre-loaded utterances quickly duringthe conversation.
Such rapid access is likely to bevery important in social conversation.
Experiencewith the TALK system (Todman and Lewins, 1996)suggests that the rate of conversation has a strongpositive relationship with the ratings of satisfactionmade both by a TALK user and by her conversationpartners.Pre-loaded utterances currently have to be con-structed by someone other than the PICTALK userEach of these utterances needs to be considered verycarefully for several reasons.
First, PICTALK holdsvery few (typically two dozen) utterances.
As al-ready mentioned, this is partly because few picturescan be accommodated on a fixed size of computerscreen.
Additionally, it is important hat the cog-nitive demands made of PICTALK be limited and,therefore, the number of possible decisions that arerequired in order to select utterances must also belimited.
Finally, PICTALK users are likely to havedifficulty deciding how to make the conversation flowwhen the utterance they would like to use is notavailable.3.2 Selecting pre-loaded utterancesIt is generally considered highly desirable to allowpeople with disabilities to be as independent as pos-sible.
In this context, it would be desirable to allowPICTALK users to take more control over the con-tent of their social interactions.
Though at presentutterances are developed and pre-loaded by some-one other than the PICTALK user, the PICTALKsystem has a facility to allow the end user to  se-lect from a database of those available utterancesand their associated pictures.
Because the associa-tion between picture and utterances i  imprecise, theuser will need to experiment with the available itemsto see what speech is associated with each availablepicture before deciding whether to load an item intotheir PICTALK system.
It would be helpful to offerfirst the items that are most likely to be appropri-ate.
A wide range of conversation attributes couldbe used to predict the most appropriate utterance,e.g.
the anticipated conversation partner, phrases e-lected for similar conversation partners, content re-lated to the last phrase selected.
Even a fairly smalldatabase of additional items with individually se-lected and stored attributes could offer benefits tothese users.3.3 Supporting variations in conversationalstyleAt present it may be possible to support some varia-tions in conversational style as a function of who theconversational partner is (e.g.
peer, teacher).
Thesimple solution is to address this problem when ut-terances are constructed for the user with a particu-lar conversation partner in mind or when utterancesare selected uring a conversation.
For example, inPICTALK variations in style can be expressed in the44Ifour utterances that are available to open a conver-sation (e.g.
hiya; howdy; hello ) and the four otherutterances that are available to close a conversation(see you later; goodbye; see ya ).
It may be possibleto provide more general support for variation in styleeither by picking up the cue to style from the openingutterance selected and then using the correspondingvariation of each subsequent u terance selected or byoffering suitable prediction when the user selects ma-terial from a database of utterances in preparationfor an interaction with a particular class of conversa-tion partner e.g.
polite style for adult, more informalstyle for classmate.3.4 Accessing material through theorganisational structureMost of the utterances available to the PICTALKuser are organised in a shallow menu structure.There is a hello menu button to give access togreeting utterances, a goodbye menu button to giveaccess to closing utterances and most of the re-maining content is accessed through a set of 3 in-tersecting perspectives, namely, person with 2 val-ues: me and you; tense with 2 values: past andpresent/future and affect with two values: happyand sad.
By selecting one each of these three per-spectives, the user gets access to pre-loaded contentappropriate to that combined perspective e.g.
con-tent on something I like doing (me/present/happy).These perspectives are designed to support theflow of conversation and require only one buttonpress to move from phrases about what I disliked(me/past/sad) to phrases about what you disliked(you/past/sad) or from phrases about what I liked(me/past/happy) to phrases about what I would like(me/present/happy).
With similar features, TALKhas been shown to support its users in initiating con-versation topics and in turn-taking in the Question-Answer format (Todman et al, 1994b).
Unfortu-nately, our experience with PICTALK users uggeststhat this menu structure is very difficult for them tounderstand.
It may, however, be possible to sup-port the PICTALK user by predicting and suggest-ing suitable utterances during a conversation.From McTear's (McTear, 1985) work, it seemsplausible that children may be able to recognise asuitable utterance (identified by its associated pic-ture) as appropriate if it were suggested, even if theyare unable to recall and locate it.
Though it wouldbe difficult to implement, a modestly effective pre-diction system could reduce the cognitive load on thePICTALK user.
Such a prediction system may beeasier for children than for adults.
Some theorists,notably, of course, Piaget (Piaget, 1959), have sug-gested that children are more egocentric than adultsin all aspects of social relationships including con-versations, by which it is usually taken to mean thatthey respond less to the listener's perspective.
Whilelater work has suggested that the level of egocen-trism which is in general exhibited by young childrenmay not be as great as suggested by Piaget e.g.
(Sel-man, 1980) nevertheless the ability to make this typeof social adaptation is not fully developed for someyears and therefore children may be less responsiveto their partners (McTear, 1985).
This may havethe fortuitous consequence that the child's next ut-terance depends more on the child's last utterance,which is known by the system, rather than on thepartner's last utterance, which is not known.3.5 Keeping the conversation flowingPICTALK provides a few other utterances that areoutside of the menu structure and are always avail-able.
The utterances are intended to support hegoal of maintaining conversational flow when a suit-able specific response to something a partner says isnot available and fulfil general pragmatic functionssuch as initiation to get attention, e.g.
"Hey!
", re-pair when something has gone wrong, e.g.
"OOPS"or "What?"
or "I don't have anything to say to that"and discourse connection to signal a topic shift, e.g.
"Now, right".
Utterances can also be available sup-port the speaking conversation partner.
In using theTALK system, we have found that keeping the part-ner informed in some way is reassuring and helpful.They need to know, for instance, that a longer thanusual silence is not signalling the termination of theinteraction and this can be achieved through the in-clusion of such utterances as "hang on.
I need tofind what I want to say".
It may be that some ofthese may be automated.
For example, it might bepossible for the PICTALK system to recognise thatits user is searching for something to say when con:secutive menu presses are made or even to recognisethat a topic shift is being initiated when the utter-ance just selected iffers greatly in semantic ontentfrom the previous utterance.3.6 TrainingChildren who have no speech or whose speech isso impaired that they cannot be readily understoodmay not have had opportunities to develop a famil-iarity with the structure and pragmatics ofconversa-tional interactions or the skills required to maintainthem.
They also need considerable training to usethe PICTALK system effectively.
Therefore, we aredeveloping a training system to help such childrendevelop their conversation skills with PICTALK.
In45the training system, the computer, using one speechsynthesised voice, converses with the child, using an-other speech synthesised voice.
At present the scriptfor the computer is entirely pre-programmed.
Itmight be possible to introduce intelligence into thescript to allow the computer to respond appropri-ately to a wider range of user's contributions.
Sucha system should make it easier to retain the child'sinterest during the rather long training period.
Be-cause each of the child's responses i known to thesystem and is predictably limited to those availablein PICTALK, it might be possible for the computerto converse fairly naturally with the child.4 Cur rent  researchAt present we are carrying out a preliminary inves-tigation of the use of NLP to support the use ofPICTALK by children working in structured settingsto achieve the following:?
Analyse the pragmatic features of children'sconversation i  a particular setting e.g.
a struc-tured news setting.?
Analyse the variability in the features used bydifferent children in the setting and eventuallyby the same children in different settings.
Tryto associate different conversational styles withdifferent utterances for later use in predictingwhich utterances will be appropriate.?
Use these analyses to develop a corpus of plau-sible utterances together with an indication ofwhich features are likely to be most helpful forchildren with different conversational styles orin different conversational settings.?
Use the utterance f atures to predict which ut-terances will be useful in the chosen setting andto help individual children to select utterancesfrom the corpus to include in PICTALK for usein the setting.?
Use the analysis to see if there is any scope forthe prediction or automatic insertion of utter-ances during a conversation.?
Use artificial intelligence to script PICTALKtraining conversations.Portia File, John Todman, Norman Aim, Leona El-der, and Hilary Smith.
1995b.
Adapting a Con-versation Aid for Non-Speaking People (TALK) tothe Needs of Non- Reading, Non-Speaking People(PICTALK).
In Proceedings European Conferenceon the Advancement of Rehabilitation Technology,pages 158-160.Michael McTear.
1985.
Children's Conversations.Blackwell, Oxford, England.Jean Piaget.
1959.
The Language and Thought ofthe Child, 3rd edition.
Routledge, London, Eng-land.R.L.
Selman.
1980.
The Growth of InterpersonalUnderstanding, Academic Press, New York.John Todman, Norman Aim, and Leona Elder.1994a.
Computer-aided conversation: a prototypesystem for non-speaking people with physical dis-abilities.
Applied Psycholinguistics, 15:45-73.John Todman, Leona Elder, Norman Aim, and Por-tia File.
1994b.
Sequential Dependencies inComputer-Aided Conversation.
Journal of Prag-matics, 21:141-169.John Todman, Elizabeth Lewins, Portia File, Nor-man Alm, and Leona Elder.
1995.
Use of a Com-munication Aid (TALK) by a Non-speaking Per-son with Cerebral Palsy, Communication Matters,9:18-25.John Todman and Elizabeth Lewins.
1996.
Use ofan AAC system for casual conversation.
In Pro-ceedings 7th Biennial Conference of the Interna-tional Society for Augmentative and AlternativeCommunication, pages 167-168.Re ferencesPortia File, John Todman, Norman Alm, Leona El-der, and Hilary Smith.
1995a.
PICTALK; A con-versation aid for nonspeaking, nonreading people.Journal of Rehabilitation Sciences, 8:47.46
