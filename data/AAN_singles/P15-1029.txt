Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing, pages 292?301,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsSimple Learning and Compositional Application of PerceptuallyGrounded Word Meanings for Incremental Reference ResolutionCasey KenningtonCITEC, Bielefeld UniversityUniversit?atsstra?e 2533615 Bielefeld, Germanyckennington@cit-ec.uni-bielefeld.deDavid SchlangenCITEC, Bielefeld UniversityUniversit?atsstra?e 2533615 Bielefeld, Germanydavid.schlangen@uni-bielefeld.deAbstractAn elementary way of using language isto refer to objects.
Often, these objectsare physically present in the shared envi-ronment and reference is done via men-tion of perceivable properties of the ob-jects.
This is a type of language use that ismodelled well neither by logical semanticsnor by distributional semantics, the formerfocusing on inferential relations betweenexpressed propositions, the latter on simi-larity relations between words or phrases.We present an account of word and phrasemeaning that is perceptually grounded,trainable, compositional, and ?dialogue-plausible?
in that it computes meaningsword-by-word.
We show that the approachperforms well (with an accuracy of 65%on a 1-out-of-32 reference resolution task)on direct descriptions and target/landmarkdescriptions, even when trained with lessthan 800 training examples and automati-cally transcribed utterances.1 IntroductionThe most basic, fundamental site of language useis co-located dialogue (Fillmore, 1975; Clark,1996) and referring to objects, as in Example (1),is a common occurrence in such a co-located set-ting.
(1) The green book on the left next to the mug.Logical semantics (Montague, 1973; Gamut,1991; Partee et al, 1993) has little to say aboutthis process ?
its focus is on the construction ofsyntactically manipulable objects that model infer-ential relations; here, e.g.
the inference that thereare (at least) two objects.
Vector space approachesto distributional semantics (Turney and Pantel,2010) similarly focuses on something else, namelysemantic similarity relations between words orphrases (e.g.
finding closeness for ?coloured tomeon the right of the cup?).
Neither approach by it-self says anything about processing; typically, theassumption in applications is that fully presentedphrases are being processed.Lacking in these approaches is a notion ofgrounding of symbols in features of the world(Harnad, 1990).1In this paper, we present an ac-count of word and phrase meaning that is (a) per-ceptually grounded in that it provides a link be-tween words and (computer) vision features of realimages, (b) trainable, as that link is learned fromexamples of language use, (c) compositional inthat the meaning of phrases is a function of thatof its parts and composition is driven by structuralanalysis, and (d) ?dialogue-plausible?
in that itcomputes meanings incrementally, word-by-wordand can work with noisy input from an automaticspeech recogniser (ASR).
We show that the ap-proach performs well (with an accuracy of 65%on a reference resolution task out of 32 objects) ondirect descriptions as well as target/landmark de-scriptions, even when trained with little data (lessthan 800 training examples).In the following section we will give a back-ground on reference resolution, followed by a de-scription of our model.
We will then describe thedata we used and explain our evaluations.
We fin-ish by giving results, providing some additionalanalysis, and discussion.2 Background: Reference ResolutionReference resolution (RR) is the task of resolvingreferring expressions (REs; as in Example (1)) toa referent, the entity to which they are intended torefer.
Following Kennington et al (2015a), thiscan be formalised as a function frrthat, given arepresentation U of the RE and a representationW1But see discussion below of recent extensions of theseapproaches taking this into account.292of the (relevant aspects of the) world, returns I?,the identifier of one the objects in the world that isthe referent of the RE.
A number of recent papershave used stochastic models for frrwhere, givenW andU , a distribution over a specified set of can-didate entities in W is obtained and the probabil-ity assigned to each entity represents the strengthof belief that it is the referent.
The referent is thenthe argmax:I?= argmaxIP (I|U,W ) (1)Recently, generative approaches, including ourown, have been presented (Funakoshi et al, 2012;Kennington et al, 2013; Kennington et al, 2014;Kennington et al, 2015b; Engonopoulos et al,2013) which model U as words or ngrams andthe world W as a set of objects in a virtual gameboard, represented as a set properties or concepts(in some cases, extra-linguistic or discourse as-pects were also modelled in W , such as deixis).In Matuszek et al (2014), W was represented as adistribution over properties of tangible objects andU was a Combinatory Categorical Grammar parse.In all of these approaches, the objects are distinctand represented via symbolically specified prop-erties, such as colour and shape.
The set of prop-erties is either read directly from the world if itis virtual, or computed (i.e., discretised) from thereal world objects.In this paper, we learn a mapping from W toU directly, without mediating symbolic properties;such a mapping is a kind of perceptual ground-ing of meaning between W and U .
Situated RRis a convenient setting for learning perceptually-grounded meaning, as objects that are referred toare physically present, are described by the RE,and have visual features that can be computation-ally extracted and represented.Further comparison to related work will be dis-cussed in Section 5.3 Modelling Reference to Visible ObjectsOverview As a representative of the kind ofmodel explained above with formula (1), we wantour model to compute a probability distributionover candidate objects, given a RE (or rather, pos-sibly just a prefix of it).
We break this task downinto components: The basis of our model is amodel of word meaning as a function from per-ceptual features of a given object to a judgementabout how well a word and that object ?fit to-gether?.
(See Section 5 for discussion of prior usesof this ?words as classifiers?-approach.)
This can(loosely) be seen as corresponding to the inten-sion of a word, which for example in Montague?sapproach is similarly modelled as a function, butfrom possible worlds to extensions (Gamut, 1991).We model two different types of words / wordmeanings: those picking out properties of singleobjects (e.g., ?green?
in ?the green book?
), follow-ing Kennington et al (2015a), and those pickingout relations of two objects (e.g., ?next to?
in (1)),going beyond Kennington et al (2015a).
Theseword meanings are learned from instances of lan-guage use.The second component then is the applicationof these word meanings in the context of an actualreference and within a phrase.
This applicationgives the desired result of a probability distribu-tion over candidate objects, where the probabilityexpresses the strength of belief in the object fallingin the extension of the expression.
Here we modeltwo different types of composition, of what we callsimple references and relational references.
Theseapplications are strictly compositional in the sensethat the meanings of the more complex construc-tions are a function of those of their parts.Word Meanings The first type of word (orrather, word meaning) we model picks out a sin-gle object via its visual properties.
(At least, thisis what we use here; any type of feature could beused.)
To model this, we train for each word wfrom our corpus of REs a binary logistic regressionclassifier that takes a representation of a candidateobject via visual features (x) and returns a proba-bility pwfor it being a good fit to the word (wherew is the weight vector that is learned and ?
is thelogistic function):pw(x) = ?
(w?x+ b) (2)Formalising the correspondence mentionedabove, the intension of a word can in this approachthen be seen as the classifier itself, a function froma representation of an object to a probability:[[w]]obj= ?x.pw(x) (3)(Where [[w]] denotes the meaning of w, and x isof the type of feature given by fobj, the functioncomputing a feature representation for a given ob-ject.
)293We train these classifiers using a corpus of REs(further described in Section 4), coupled with rep-resentations of the scenes in which they were usedand an annotation of the referent of that scene.
Thesetting was restricted to reference to single ob-jects.
To get positive training examples, we paireach word of a RE with the features of the refer-ent.
To get negative training examples, we pair theword with features of (randomly picked) other ob-jects present in the same scene, but not referred toby it.
This selection of negative examples makesthe assumption that the words from the RE applyonly to the referent.
This is wrong as a strict rule,as other objects could have similar visual featuresas the referent; for this to work, however, this hasto be the case only more often than it is not.The second type of word that we model ex-presses a relation between objects.
Its meaning istrained in a similar fashion, except that it is pre-sented a vector of features of a pair of objects,such as their euclidean distance, vertical and hor-izontal differences, and binary features denotinghigher than/lower than and left/right relationships.Application and Composition The model justdescribed gives us a prediction for a pair of wordand object (or pair of objects).
What we wanted,however, is a distribution over all candidate ob-jects in a given utterance situation, and not only forindividual words, but for (incrementally growing)REs.
Again as mentioned above, we model twotypes of application and composition.
First, whatwe call ?simple references?
?which roughly cor-responds to simple NPs?that refer only by men-tioning properties of the referent (e.g.
?the redcross on the left?).
To get a distribution for a sin-gle word, we apply the word classifier (the inten-sion) to all candidate objects and normalise; thiscan then be seen as the extension of the word in agiven (here, visual) discourse universe W , whichprovides the candidate objects (xiis the featurevector for object i, normalize() vectorized nor-malisation, and I a random variable ranging overthe candidates):[[w]]Wobj=normalize(([[w]]obj(x1), .
.
.
, [[w]]obj(xk))) =normalize((pw(x1), .
.
.
, pw(xk))) = P (I|w) (4)In effect, this combines the individual classifiersinto something like a multi-class logistic regres-sion / maximum entropy model?but, nota bene,only for application.
The training regime did notneed to make any assumptions about the numberof objects present, as it trained classifiers for a 2-class problem (how well does this given object fitto the word?).
The multi-class nature is also indi-cated in Figure 1, which shows multiple applica-tions of the logistic regression network for a word,and a normalisation layer on top. (w|x1 + b)  (w|x2 + b)  (w|x3 + b)x1 x2 x3Figure 1: Representation as network with normalisationlayer.To compose the evidence from individual wordsw1, .
.
.
, wkinto a prediction for a ?simple?
RE[srw1, .
.
.
, wk] (where the bracketing indicates thestructural assumption that the words belong toone, possibly incomplete, ?simple reference?
), weaverage the contributions of its constituent words.The averaging function avg() over distributionsthen is the contribution of the construction ?sim-ple reference (phrase)?, sr, and the meaning of thewhole phrase is the application of the meaning ofthe construction to the meaning of the words:[[[srw1, .
.
.
, wk]]]W= [[sr]]W[[w1, .
.
.
, wk]]W=avg([[w1]]W, .
.
.
, [[wk]]W) (5)where avg() is defined asavg([[w1]]W, [[w2]]W) = Pavg(I|w1, w2)with Pavg(I = i|w1, w2) =12(P (I = i|w1) + P (I = i|w2)) for i ?
I (6)The averaging function is inherently incre-mental, in the sense that avg(a, b, c) =avg(avg(a, b), c) and hence it can be extended ?onthe right?.
This represents an incremental modelwhere new information from the current incrementis added to what is already known, resulting in anintersective way of composing the meaning of thephrase.
This cannot account for all constructions(such as negation or generally quantification), ofcourse; we leave exploring other constructions thatcould occur even in our ?simple references?
to fu-ture work.294Relational references such as in Exam-ple (1) from the introduction have a morecomplex structure, being a relation between a(simple) reference to a landmark and a (sim-ple) reference to a target.
This structure isindicated abstractly in the following ?parse?
:[rel[srw1, .
.
.
, wk][rr1, .
.
.
, rn][srw?1, .
.
.
, w?m]],where the w are the target words, r the relationalexpression words, and w?the landmark words.As mentioned above, the relational expressionsimilarly is treated as a classifier (in fact, techni-cally we contract expressions such as ?to the leftof?
into a single token and learn one classifier forit), but expressing a judgement for pairs of objects.It can be applied to a specific scene with a set ofcandidate objects (and hence, candidate pairs) in asimilar way by applying the classifier to all pairsand normalising, resulting in a distribution overpairs:[[r]]W= P (R1, R2|r) (7)We expect the meaning of the phrase to be afunction of the meaning of the constituent parts(the simple references, the relation expression, andthe construction), that is:[[[rel[srw1, .
.
.
, wk][rr][srw?1, .
.
.
, w?m]]]] =[[rel]]([[sr]][[w1.
.
.
wk]], [[r]], [[sr]][[w?1.
.
.
w?m]]) (8)(dropping the indicator for concrete application,Won [[ ]], for reasons of space and readability).What is the contribution of the relational con-struction, [[rel]]?
Intuitively, what we want toexpress here is that the belief in an object be-ing the intended referent should combine the ev-idence from the simple reference to the land-mark object (e.g., ?the mug?
in (1)), from thesimple (but presumably deficient) reference tothe target object (?the green book on the left?
),and that for the relation between them (?nextto?).
Instead of averaging (that is, combiningadditively), as for sr, we combine this evidencemultiplicatively here: If the target constituentcontributes P (It|w1, .
.
.
, wk), the landmark con-stituent P (Il|w?1, .
.
.
, w?m), and the relation ex-pression P (R1, R2|r), with Il, It, R1and R2allhaving the same domain, the set of all candidateobjects, then the combination isP (R1|w1, .
.
.
, wk, r, w?1, .
.
.
, w?m) =?R2?Il?ItP (R1, R2|r) ?
P (Il|w?1, .
.
.
, w?m)?P (It|w1, .
.
.
, wk) ?
P (R1|It) ?
P (R2|Il) (9)The last two factors force identity on the elementsof the pair and target and landmark, respectively(they are not learnt, but rather set to be 0 unlessthe values ofR and I are equal), and so effectivelyreduce the summations so that all pairs need to beevaluated only once.
The contribution of the con-struction then is this multiplication of the contri-butions of the parts, together with the factors en-forcing that the pairs being evaluated by the rela-tion expression consist of the objects evaluated bytarget and landmark expression, respectively.In the following section, we will explain thedata we collected and used to evaluate our model,the evaluation procedure, and the results.4 ExperimentsFigure 2: Example episode for phase-2 where the target isoutlined in green (solid arrow added here for presentation),the landmark outlined in blue (dashed arrow).Data We evaluated our model using data we col-lected in a Wizard-of-Oz setting (that is, a hu-man/computer interaction setting where parts ofthe functionality of the computer system were pro-vided by a human experimentor).
Participantswere seated in front of a table with 36 Pen-tomino puzzle pieces that were randomly placedwith some space between them, as shown inFigure 2.
Above the table was a camera thatrecorded a video feed of the objects, processedusing OpenCV (Pulli et al, 2012) to segment theobjects (see below for details); of those, one (orone pair) was chosen randomly by the experimentsoftware.
The video image was presented to theparticipant on a display placed behind the table,but with the randomly selected piece (or pair ofpieces) indicated by an overlay).The task of the participant was to refer to thatobject using only speech, as if identifying it for afriend sitting next to the participant.
The wizard295(experimentor) had an identical screen depictingthe scene but not the selected object.
The wiz-ard listened to the participant?s RE and clicked onthe object she thought was being referred on herscreen.
If it was the target object, a tone soundedand a new object was randomly chosen.
This con-stituted a single episode.
If a wrong object wasclicked, a different tone sounded, the episode wasflagged, and a new episode began.
At varied in-tervals, the participant was instructed to ?shuffle?the board between episodes by moving around thepieces.The first half of the allotted time constitutedphase-1.
After phase-1 was complete, instructionsfor phase-2 were explained: the screen showed thetarget and also a landmark object, outlined in blue,near the target (again, see Figure 2).
The partici-pant was to refer to the target using the landmark.
(In the instructions, the concepts of landmark andtarget were explained in general terms.)
All otherinstructions remained the same as phase-1.
Thetarget?s identifier, which was always known be-forehand, was always recorded.
For phase-2, thelandmark?s identifier was also recorded.Nine participants (6 female, 3 male; avg.
ageof 22) took part in the study; the language ofthe study was German.
Phase-1 for one partici-pant and phase-2 for another participant were notused due to misunderstanding and a technical diffi-culty.
This produced a corpus of 870 non-flaggedepisodes in total.
Even though each episode had36 objects in the scene, all objects were not alwaysrecognised by the computer vision processing.
Onaverage, 32 objects were recognized.To obtain transcriptions, we used Google WebSpeech (with a word error rate of 0.65, as deter-mined by comparing to a hand transcribed sample)This resulted in 1587 distinct words, with 15.53words on average per episode.
The objects werenot manipulated in any way during an episode, sothe episode was guaranteed to remain static duringa RE and a single image is sufficient to representthe layout of one episode?s scene.
Each scene wasprocessed using computer vision techniques to ob-tain low-level features for each (detected) object inthe scene which were used for the word classifiers.We annotated each episode?s RE with a simpletagging scheme that segmented the RE into wordsthat directly referred to the target, words that di-rectly referred to the landmark (or multiple land-marks, in some cases) and the relation words.
Forcertain word types, additional information aboutthe word was included in the tag if it describedcolour, shape, or spatial placement (denoted con-tributing REs in the evaluations below).
The direc-tion of certain relation words was normalised (e.g.,left-of should always denote a landmark-target re-lation).
This represents a minimal amount of ?syn-tactic?
information needed for the application ofthe classifiers and the composition of the phrasemeanings.
We leave applying a syntactic parser tofuture work.
An example RE in the original Ger-man (as recognised by the ASR), English gloss,and tags for each word is given in (2).
(2) a. grauer stein ?uber dem gr?unen m unten linksb.
gray block above the green m bottom leftc.
tc ts r l lc ls tf tfTo obtain visual features of each object, we usedthe same simple computer-vision pipeline of ob-ject segmentation and contour reconstruction asused by Kennington et al (2015a), providing uswith RGB representations for the colour and fea-tures such as skewness, number of edges etc.
forthe shapes.Procedure We break down our data as follows:episodes where the target was referred directlyvia a ?simple reference?
construction (DD; 410episodes) and episodes where a target was referredvia a landmark relation (RD; 460 episodes).
Wealso test with either knowledge about structure(simple or relational reference) provided (ST) ornot (WO, for ?words-only?).
All results shown arefrom 10-fold cross validations averaged over 10runs; where for evaluations labelled RD the train-ing data always includes all of DD plus 9 folds ofRD, testing on RD.
The sets address the followingquestions:?
how well does the sr model work on its ownwith just words?
?
DD.WO?
how well does the sr model work when itknows about REs?
?
DD.ST?
how well does the sr model work when itknows about REs, but not about relations?
?RD.ST (sr)?
how well does the model learn relation wordsafter it has learned about sr?
RD.ST (r)?
how well does the rr model work (togetherwith the sr)?
RD.ST with DD.ST (rr)Words were stemmed using the NLTK (Loperand Bird, 2002) Snowball Stemmer, reducing the296vocabulary size to 1306.
Due to sparsity, for rela-tion words with a token count of less than 4 (foundby ranging over values in a held-out set) relationalfeatures were piped into an UNK relation, whichwas used for unseen relations during evaluation(we assume the UNK relation would learn a gen-eral notion of ?nearness?).
For the individual wordclassifiers, we always paired one negative examplewith one positive example.For this evaluation, word classifiers for sr weregiven the following features: RGB values, HSVvalues, x and y coordinates of the centroids, eu-clidean distance of centroid from the center, andnumber of edges.
The relation classifiers receivedinformation relating two objects, namely the eu-clidean distance between them, the vertical andhorizontal distances, and two binary features thatdenoted if the landmark was higher than/lowerthan or left/right of the target.00.10.20.30.40.50.60.70.8DD.
?WO DD.
?ST RD.
?ST(sr) RD.
?ST(sr+r) RD.
?ST(rr)0.7590.680.6080.680.56mean reciprocal rank0?%10?%20?%30?%40?%50?%60?%70?%DD.
?WO DD.
?ST RD.
?ST(sr) RD.
?ST(sr+r) RD.
?ST(rr)65.3?%55?%42?%54?%40.9?%accuracyFigure 3: Results of our evaluation.Metrics for Evaluation To give a picture of theoverall performance of the model, we report accu-racy (how often was the argmax the gold target)and mean reciprocal rank (MRR) of the gold tar-get in the distribution over all the objects (like ac-curacy, higher MRR values are better; values rangebetween 0 and 1).
The use of MRR is motivated bythe assumption that in general, a good rank for thecorrect object is desirable, even if it doesn?t reachthe first position, as when integrated in a dialoguesystem this information might still be useful to for-mulate clarification questions.Results Figure 3 shows the results.
(Randombaseline of 1/32 or 3% not shown in plot.)
DD.WOshows how well the sr model performs using thewhole utterances and not just the REs.
(Note thatall evaluations are on noisy ASR transcriptions.
)DD.ST adds structure by only considering wordsthat are part of the actual RE, improving the re-sults further.
The remaining sets evaluate the con-tributions of the rr model.
RD.ST (sr) does thisindirectly, by including the target and landmarksimple references, but not the model for the rela-tions; the task here is to resolve target and land-mark SRs as they are.
This provides the baselinefor the next two evaluations, which include the re-lation model.
In RD.ST (sr+r), the model learnsSRs from DD data and only relations from RD.
Theperformance is substantially better than the base-line without the relation model.
Performance isbest finally for RD.ST (rr), where the landmarkand target SRs in the training portion of RD alsocontribute to the word models.The mean reciprocal rank scores follow a sim-ilar pattern and show that even though the targetobject was not the argmax of the distribution, onaverage it was high in the distribution.
For all eval-uations, the average standard deviation across the10 runs was very small (0.01), meaning the modelwas fairly stable, despite the possibility of one runhaving randomly chosen more discriminating neg-ative examples.
Our conclusion from these exper-iments is that despite the small amount of trainingdata and noise from ASR as well as the scene, themodel is robust and yields respectable results.0 2 4 6 8 10 12 1450510152025Figure 5: Incremental results: average rank improves overtimeIncremental Results Figure 5 shows how ourrr model processes incrementally, by giving theaverage rank of the (gold) target at each incrementfor the REs with the most common length in ourdata (13 words, of which there were 64 examples).A system that works incrementally would have amonotonically decreasing average rank as the ut-terance unfolds.
The overall trend as shown in that297100 200 300 400 500 6001002003004000.10.20.30.40.50.60.70.80.90 50 100 150 200 2500.00.20.40.60.81.0100 200 300 400 500 6001002003004000.00.10.20.30.40.50.60.70.80.9Figure 4: Each plot represents how well selected words fit assumptions about their lexical semantics: the leftmost plot ecke(corner) yields higher probabilities as objects are closer to the corner; the middle plot gr?un (green) yields higher probabilitieswhen the colour spectrum values are nearer to green; the rightmost plot ?uber (above) yields higher probabilities when targetsare nearer to a landmark set in the middle.Figure is as expected.
There is a slight increasebetween 6-7, though very small (a difference of0.09).
Overall, these results seem to show that ourmodel indeed works intersectively and ?zooms in?on the intended referent.4.1 Further AnalysisAnalysis of Selected Words We analysed sev-eral individual word classifiers to determine howwell their predictions match assumptions abouttheir lexical semantics.
For example, for the spa-tial word Ecke (corner), we would expect its clas-sifier to return high probabilities if features relatedto an object?s position (e.g., x and y coordinates,distance from the center) are near corners of thescene.
The leftmost plot in Figure 4 shows thatthis is indeed the case; by holding all non-positionfeatures constant and ranging over all points onthe screen, we can see that the classifier gives highprobabilities around the edges, particularly in thefour corners, and very low probabilities in the mid-dle region.
Similarly for the colour word gr?un,the centre plot in Figure 4 (overlaid with a colourspectrum) shows high probabilities are given whenpresented with the colour green, as expected.
Sim-ilarly, for the relational word ?uber (above), bytreating the center point as the landmark and rang-ing over all other points on the plot for the target,the ?uber classifier gives high probabilities whendirectly above the center point, with linear nega-tive growth as the distance from the landmark in-creases.Note that we selected the type of feature to varyhere for presentation; all classifiers get the full fea-ture set and learn automatically to ?ignore?
the ir-relevant features (e.g., that for gr?un does not re-spond to variations in positional features).
Theydo this wuite well, but we noticed some ?blurring?,due to not all combinations of colours and shapebeing represented in the objects in the training set.Analysis of Incremental Processing Figure 6finally shows the interpretation of the RE in Ex-ample (2) in the scene from Figure 2.
The toprow depicts the distribution over objects (true tar-get shown in red) after the relation word unten(bottom) is uttered; the second row that for land-mark objects, after the landmark description be-gins (dem gr?unen m / the green m).
The third row(target objects), ceases to change after the rela-tional word is uttered, but continues again as ad-ditional target words are uttered (unten links / bot-tom left).
While the true target is ranked highlyalready on the basis of the target SR alone, it isonly when the relational information is added (toprow) that it becomes argmax.Discussion We did not explore how well ourmodel could handle generalised quantifiers, suchas all (e.g., all the red objects) or a specific num-ber of objects (e.g., the two green Ts).
We specu-late that one could see as the contribution of wordssuch as all or two a change to how the distributionis evaluated (?return the n top candidates?).
Ourmodel also doesn?t yet directly handle more de-scriptive REs like the cross in the top-right corneron the left, as left is learned as a global term, ornegation (the cross that?s not red).
We leave ex-ploring such constructions to future work.5 Related WorkKelleher et al (2005) approached RR us-ing perceptually-grounded models, focusing onsaliency and discourse context.
In Gorniak andRoy (2004), descriptions of objects were used tolearn a perceptually-grounded meaning with focuson spatial terms such as on the left.
Steels andBelpaeme (2005) used neural networks to connectlanguage with colour terms by interacting with hu-mans.
Larsson (2013) is closest in spirit to whatwe are attempting here; he provides a detailed298grauer stein ?ber dem gr?nen m unten linksFigure 6: A depiction of the model working incrementally for the RE in Example (2): the distribution over objects for relationis row 1, landmark is row 2, target is row 3.formal semantics for similarly descriptive terms,where parts of the semantics are modelled by aperceptual classifier.
These approaches had lim-ited lexicons (where we attempt to model all wordsin our corpus), and do not process incrementally,which we do here.Recent efforts in multimodal distributional se-mantics have also looked at modelling word mean-ing based on visual context.
Originally, vectorspace distributional semantics focused words inthe context of other words (Turney and Pantel,2010); recent multimodal approaches also con-sider low-level features from images.
Bruni etal.
(2012) and Bruni et al (2014) for examplemodel word meaning by word and visual con-text; each modality is represented by a vector,fused by concatenation.
Socher et al (2014)and Kiros et al (2014) present approaches wherewords/phrases and images are mapped into thesame high-dimensional space.
While these ap-proaches similarly provide a link between wordsand images, they are typically tailored towardsa different setting (the words being descriptionsof the whole image, and not utterance intendedto perform a function within a visual situation).We leave more detailed exploration of similaritiesand differences to future work and only note fornow that our approach, relying on much simplerclassifiers (log-linear, basically), works with muchsmaller data sets and additionally seem to pro-vide an easier interface to more traditional waysof composition (see Section 3 above).The issue of semantic compositionality is alsoactively discussed in the distributional semanticsliterature (see, e.g., (Mitchell and Lapata, 2010;Erk, 2013; Lewis and Steedman, 2013; Papernoet al, 2014)), investigating how to combine vec-tors.
This could be seen as composition on thelevel of intensions (if one sees distributional rep-resentations as intensions, as is variously hintedat, e.g.
Erk (2013)).
In our approach, compositionis done on the extensional level (by interpolatingdistributions over candidate objects).We do not see our approach as being in op-position to these attempts.
Rather, we envisiona system of semantics that combines traditionalsymbolic expressions (on which inferences canbe modelled via syntactic calculi) with distributedrepresentations (which model conceptual knowl-edge / semantic networks, as well as encyclopedicknowledge) and with our action-based (namely,identification in the environment via perceptualinformation) semantics.
This line of approachis connected to a number of recent works (e.g.,(Erk, 2013; Lewis and Steedman, 2013; Larsson,2013)); for now, exploring its ramifications is leftfor future work.6 ConclusionIn this paper, we presented a model of referenceresolution that learns a perceptually-groundedmeaning of words, including relational words.
Themodel is simple, compositional, and robust despitelow amounts of training data and noisy modalities.Our model is not without limitations; it so far onlyhandles definite descriptions, yet there are otherways to refer to real-world objects, such as via pro-nouns and deixis.
A unified model that can handleall of these, similar in spirit perhaps to Funakoshiet al (2012), but with perceptual groundings, isleft for future work.
Our approach could also ben-efit from improved object segmentation and repre-299sentation.Our next steps with this model is to handle com-positional structures without relying on our closedtag set (e.g., using a syntactic parser).
We alsoplan to test our model in a natural, interactive dia-logue system.Acknowledgements We want to thank the anonymousreviewers for their comments.
We also want to thank Spy-ros Kousidis for helping with data collection, Livia Dia forhelp with the computer vision processing, and Julian Houghfor fruitful discussions on semantics, though we can?t blamethem for any problems of the work that may remain.
This re-search/work was supported by the Cluster of Excellence Cog-nitive Interaction Technology ?CITEC?
(EXC 277) at Biele-feld University, which is funded by the German ResearchFoundation (DFG).ReferencesElia Bruni, Gemma Boleda, Marco Baroni, and Nam-Khanh Tran.
2012.
Distributional semantics in tech-nicolor.
In Proceedings of the 50th Annual Meet-ing of the Association for Computational Linguis-tics, volume 1, pages 136?145.Elia Bruni, Nam Khanh Tran, and Marco Baroni.
2014.Multimodal distributional semantics.
Journal of Ar-tificial Intelligence Research, 49:1?47.Herbert H Clark.
1996.
Using Language, volume 23.Cambridge University Press.Nikos Engonopoulos, Martin Villalba, Ivan Titov, andAlexander Koller.
2013.
Predicting the resolu-tion of referring expressions from user behavior.
InProceedings of EMLNP, pages 1354?1359, Seattle,Washington, USA.
Association for ComputationalLinguistics.Katrin Erk.
2013.
Towards a semantics for distri-butional representations.
In Proceedings of IWCS,pages 1?11, Potsdam, Germany.Charles J Fillmore.
1975.
Pragmatics and the descrip-tion of discourse.
Radical pragmatics, pages 143?166.Kotaro Funakoshi, Mikio Nakano, Takenobu Toku-naga, and Ryu Iida.
2012.
A Unified Probabilis-tic Approach to Referring Expressions.
In Proceed-ings of SIGDial, pages 237?246, Seoul, South Ko-rea, July.
Association for Computational Linguistics.L T F Gamut.
1991.
Logic, Language and Meaning:Intensional Logic and Logical Grammar, volume 2.Chicago University Press, Chicago.Peter Gorniak and Deb Roy.
2004.
Grounded semanticcomposition for visual scenes.
Journal of ArtificialIntelligence Research, 21:429?470.Stevan Harnad.
1990.
The Symbol Grounding Prob-lem.
Physica D, 42:335?346.John Kelleher, Fintan Costello, and Jofsef Van Gen-abith.
2005.
Dynamically structuring, updatingand interrelating representations of visual and lin-guistic discourse context.
Artificial Intelligence,167(1?2):62?102.Casey Kennington, Spyros Kousidis, and DavidSchlangen.
2013.
Interpreting Situated DialogueUtterances: an Update Model that Uses Speech,Gaze, and Gesture Information.
In Proceedings ofSIGdial.Casey Kennington, Spyros Kousidis, and DavidSchlangen.
2014.
Situated Incremental Natu-ral Language Understanding using a Multimodal,Linguistically-driven Update Model.
In Proceed-ings of CoLing.Casey Kennington, Livia Dia, and David Schlangen.2015a.
A Discriminative Model for Perceptually-Grounded Incremental Reference Resolution.
InProceedings of IWCS.
Association for Computa-tional Linguistics.Casey Kennington, Ryu Iida, Takenobu Tokunaga, andDavid Schlangen.
2015b.
Incrementally Track-ing Reference in Human/Human Dialogue UsingLinguistic and Extra-Linguistic Information.
InNAACL, Denver, U.S.A. Association for Computa-tional Linguistics.Ryan Kiros, Ruslan Salakhutdinov, and Richard SZemel.
2014.
Unifying Visual-Semantic Embed-dings with Multimodal Neural Language Models.In Proceedings of NIPS 2014 Deep Learning Work-shop, pages 1?13.Staffan Larsson.
2013.
Formal semantics for percep-tual classification.
Journal of Logic and Computa-tion.Mike Lewis and Mark Steedman.
2013.
CombinedDistributional and Logical Semantics.
Transactionsof the ACL, 1:179?192.Edward Loper and Steven Bird.
2002.
NLTK: The nat-ural language toolkit.
In Proceedings of the ACL-02Workshop on Effective tools and methodologies forteaching natural language processing and computa-tional linguistics-Volume 1, pages 63?70.
Associa-tion for Computational Linguistics.Cynthia Matuszek, Liefeng Bo, Luke Zettlemoyer, andDieter Fox.
2014.
Learning from Unscripted Deic-tic Gesture and Language for Human-Robot Interac-tions.
In AAAI.
AAAI Press.Jeff Mitchell and Mirella Lapata.
2010.
Compositionin distributional models of semantics.
Cognitive sci-ence, 34(8):1388?1429, November.300Richard Montague.
1973.
The Proper Treatment ofQuantifikation in Ordinary English.
In J Hintikka,J Moravcsik, and P Suppes, editors, Approaches toNatural Language: Proceedings of the 1970 Stan-ford Workshop on Grammar and Semantics, pages221?242, Dordrecht.
Reidel.Denis Paperno, Nghia The Pham, and Marco Baroni.2014.
A practical and linguistically-motivated ap-proach to compositional distributional semantics.
InProceedings of ACL, pages 90?99.Barbara H Partee, Alice ter Meuelen, and Robert EWall.
1993.
Mathematical Methods in Linguistics.Kluwer Academic Publishers, Dordrecht.Kari Pulli, Anatoly Baksheev, Kirill Kornyakov, andVictor Eruhimov.
2012.
Real-time computer vi-sion with OpenCV.
Communications of the ACM,55(6):61?69.Richard Socher, Andrej Karpathy, Quoc V Le, Christo-pher D Manning, and Andrew Y Ng.
2014.Grounded Compositional Semantics for Finding andDescribing Images with Sentences.
Transactionsof the Association for Computational Linguistics(TACL), 2:207?218.Luc Steels and Tony Belpaeme.
2005.
Coordinatingperceptually grounded categories through language:a case study for colour.
The Behavioral and brainsciences, 28(4):469?489; discussion 489?529.Peter D Turney and Patrick Pantel.
2010.
From Fre-quency to Meaning: Vector Space Models of Seman-tics.
Artificial Intelligence, 37(1):141?188.301
