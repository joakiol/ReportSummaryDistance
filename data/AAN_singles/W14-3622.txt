Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 160?164,October 25, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsThe Columbia System in the QALB-2014 Shared Taskon Arabic Error CorrectionAlla Rozovskaya Nizar Habash?Ramy Eskander Noura Farra Wael SalloumCenter for Computational Learning Systems, Columbia University?New York University Abu Dhabi{alla,ramy,noura,wael}@ccls.columbia.edu?nizar.habash@nyu.eduAbstractThe QALB-2014 shared task focuses oncorrecting errors in texts written in Mod-ern Standard Arabic.
In this paper, wedescribe the Columbia University entry inthe shared task.
Our system consists ofseveral components that rely on machine-learning techniques and linguistic knowl-edge.
We submitted three versions of thesystem: these share several core elementsbut each version also includes additionalcomponents.
We describe our underlyingapproach and the special aspects of the dif-ferent versions of our submission.
Oursystem ranked first out of nine participat-ing teams.1 IntroductionThe topic of text correction has seen a lot of in-terest in the past several years, with a focus oncorrecting grammatical errors made by learners ofEnglish as a Second Language (ESL).
The twomost recent CoNLL shared tasks were devoted togrammatical error correction for non-native writ-ers (Ng et al., 2013; Ng et al., 2014).The QALB-2014 shared task (Mohit et al.,2014) is the first competition that addresses theproblem of text correction in Modern StandardArabic (MSA) texts.
The competition makesuse of the recently developed QALB corpus (Za-ghouani et al., 2014).
The shared task covers alltypes of mistakes that occur in the data.Our system consists of statistical models, lin-guistic resources, and rule-based modules that ad-dress different types of errors.We briefly discuss the task in Section 2.
Sec-tion 3 gives an overview of the Columbia systemand describes the system components.
In Sec-tion 4, we evaluate the complete system on the de-velopment data and show the results obtained ontest.
Section 5 concludes.2 Task DescriptionThe QALB-2014 shared task addresses the prob-lem of correcting errors in texts written in ModernStandard Arabic (MSA).
The task organizers re-leased training, development, and test data.
Allof the data comes from online commentaries writ-ten to Aljazeera articles.1The training data con-tains 1.2 million words; the development and thetest data contain about 50,000 words each.
Thedata was annotated and corrected by native Arabicspeakers.
For more detail on the QALB corpus, werefer the reader to Zaghouani et al.
(2014).
The re-sults in the subsequent sections are reported on thedevelopment set.It should be noted that in the annotation process,the annotators did not assign error categories butonly specified an appropriate correction.
In spiteof this, it is possible, to isolate certain error typesautomatically, by using the corrections in coordi-nation with the input words.
The first type con-cerns punctuation errors.
Errors involving punc-tuation account for about 39% of all errors in thedata.
In addition to punctuation mistakes, anothervery common source of errors refers to subopti-mal spelling for two groups of letters ?
Alif (andits Hamzated versions) and Ya (and its undotted orAlif Maqsura versions).
For more detail on thisand other Arabic phenomena, we refer the readerto Habash (2010; Buckwalter (2007; El Kholy andHabash (2012).
Mistakes associated with Alif and1http://www.aljazeera.net/160Component SystemCLMB-1 CLMB-2 CLMB-3MADAMIRAMLENa?
?ve BayesGSECMLE-unigramPunctuationDialectalPatternsTable 1: The three versions of the Columbia sys-tem and their components.Ya spelling constitute almost 30% of all errors.3 System OverviewThe Columbia University system consists of sev-eral components designed to address differenttypes of errors.
We submitted three versions of thesystem.
We refer to these as CLMB-1, CLMB-2,and CLMB-3.
Table 1 lists all of the componentsand indicates which components are included ineach version.
The components are applied in theorder shown in the table.
Below we describe eachcomponent in more detail.3.1 MADAMIRA CorrectorMADAMIRA (Pasha et al., 2014) is a tooldesigned for morphological analysis and dis-ambiguation of Modern Standard Arabic.MADAMIRA performs morphological analysisin context.
This is a knowledge-rich resourcethat requires a morphological analyzer and alarge corpus where every word is marked withits morphological features.
The task organizersprovided the shared task data pre-processedwith MADAMIRA, including all of the featuresgenerated by the tool for every word.
In additionto the morphological analysis and contextualmorphological disambiguation, MADAMIRAalso performs Alif and Ya spelling correctionfor the phenomena associated with these lettersdiscussed in Section 2.
The corrected form wasincluded among the features and can be usedfor correcting the input.
We use the correctionsproposed by MADAMIRA and apply them to thedata.
As we show in Section 4, while the formproposed by MADAMIRA may not necessarilybe correct, MADAMIRA performs at a very highprecision.
MADAMIRA corrector is used in theCLMB-1 and CLMB-2 systems.3.2 Maximum Likelihood ModelThe Maximum Likelihood Estimator (MLE) is asupervised component that is trained on the train-ing data of the shared task.
Given the annotatedtraining data, a map is defined that specifies for ev-ery word n-gram in the source text the most likelyn-gram corresponding to it in the target text.
TheMLE model considers source n-grams of lengthsbetween 1 to 3; the MLE-unigram model that ispart of the CLMB-3 version only considers n-grams of length 1.The MLE approach performs well on errors thathave been observed in the training data and canbe unambiguously corrected without using the sur-rounding context, i.e.
do not have many alternativecorrections.
Consequently, MLE fails on wordsthat have many possible corrections, as well aswords not seen in training.3.3 Na?
?ve Bayes for Unseen WordsThe Na?
?ve Bayes component addresses errors forwords that were not seen in training.
The systemuses the approach proposed in Rozovskaya andRoth (2011) that proved to be successful for cor-recting errors made by English as a Second Lan-guage learners.
The model operates at the wordlevel and targets word replacement errors that in-volve single tokens.
Candidate corrections aregenerated using a character confusion table that isbased on the training data.
The model is a Na?
?veBayes classifier trained on the Arabic Gigawordcorpus (Parker et al., 2011) with word n-gram fea-tures in the 4-word window around the word to becorrected.
The Na?
?ve Bayes component is used inthe CLMB-1 system.3.4 The GSEC ModelThe CLMB-3 system implements a GeneralizedCharacter-Level Error Correction model (GSEC)proposed in Farra et al.
(2014).
GSEC is a super-vised model that operates at the character level.Because of this, the source and the target side ofthe training data need to be aligned at the charac-ter level.
We use the alignment tool Sclite (Fiscus,1998).
The alignment maps each source charac-ter to itself, a different character, a pair of char-acters, or an empty string.
For the shared task,punctuation corrections are ignored since punctu-ation errors are handled by the punctuation correc-tor described in the following section.
It should161also be noted that the model was not trained toinsert missing characters.
The model is a multi-class SVM classifier (Kudo, 2005) that makes useof character-level features using a window of fourcharacters that may occur within the word bound-aries as well as in the surrounding context.
Dueto a long training time, GSEC was trained on aquarter of the training data.
The system is post-processed with a unigram word-level maximum-likelihood model described in Section 3.2.
Formore detail on the GSEC approach, we refer thereader to Farra et al.
(2014).3.5 Punctuation CorrectorThe shared task data contains a large number ofpunctuation mistakes.
Punctuation errors, such asmissing periods and commas, account for about30% of all errors in the data.
Most of these errorsinvolve incorrectly omitting a punctuation symbol.Our punctuation corrector is a statistical modelthat inserts periods and commas.
The system isa decision tree model trained on the shared tasktraining data using WEKA (Hall et al., 2009).
Forpunctuation insertion, every space that is not fol-lowed or preceded by a punctuation mark is con-sidered.To generate features, we use a window of sizethree around the target space.
The features are de-fined as follows:?
The part-of-speech of the previous word?
The existence of a conjunctive or connectiveproclitic in the following word; that is a ?w?or ?f?
proclitic that is either a conjunction, asub-conjunction or a connective particleThe part-of-speech and proclitic information isobtained by running MADAMIRA on the text.We also ran experiments where the model istrained with a complete list of features producedby MADAMIRA; that is part-of-speech, gender,number, person, aspect, voice, case, mood, state,proclitics and enclitics.
This was done for two pre-ceding words and two following words.
However,this model did not perform as well as the one de-scribed above, which we used in the final system.Note that the punctuation model predicts pres-ence or absence of a punctuation mark in a spe-cific location and is applied to the source datafrom which all punctuation marks have been re-moved.
However, when we apply our punctuationmodel in the correction pipeline, we find that itis always better to keep the already existing peri-ods and commas in the input text instead of over-writing them with the model prediction.
In otherwords, we only attempt to add missing punctua-tion.3.6 Dialectal Usage CorrectorEven though the shared task data is written inMSA, MSA is not a native language for Arabicspeakers.
Typically, an Arabic speaker has a nativeproficiency in one of the many Arabic dialects andlearns to write and read MSA in a formal setting.For this reason, even in MSA texts produced bynative Arabic speakers, one typically finds wordsand linguistic features specific to the writer?s na-tive dialect that are not found in the standard lan-guage.To address such errors, we use Elissa (Salloumand Habash, 2012), which is Dialectal to StandardArabic Machine Translation System.
Elissa usesa rule-based approach that relies on the existenceof a dialectal morphological analyzer (Salloumand Habash, 2011), a list of hand-written trans-fer rules, and dialectal-to-standard Arabic lexi-cons.
Elissa uses different dialect identificationtechniques to select dialectal words and phrases(dialectal multi-word expressions) that need to behandled.
Then equivalent MSA paraphrases of theselected words/phrases are generated and an MSAlattice for each input sentence is constructed.
Theparaphrases within the lattice are then ranked us-ing language models and the n-best sentences areextracted from lattice.
We use 5-gram languagemodels trained using SRILM (Stolcke, 2002) onabout 200 million untokenized, Alif /Ya normal-ized words extracted from Arabic GigaWord.
Thiscomponent is employed in the CLMB-2 system.3.7 Pattern-Based CorrectorWe created a set of rules that account for verycommon phenomena involving incorrectly split ormerged tokens.
The MADAMIRA corrector de-scribed above does not handle splits and merges;however, some of the cases are handled in theMLE method.
Note that the MLE method is re-strictive since it does not correct words not seenin training, while the pattern-based corrector ismore general.
The rules were created throughanalysis of samples of the QALB Shared Task162training data.
Some of the rules use regular ex-pressions, while others make use of the rule-based Standard Arabic Morphological Analyzer(SAMA) (Maamouri et al., 2010), the same out-of-context analyzer used inside of MADAMIRA.Rules for splitting words?
All digits are separated from words.?
A space is added after all word medial Ta-Marbuta characters.?
A space is added after the very common?ElY?
?at/about/on?
preposition if it is at-tached to the following word.?
If a word has a morphological analysis thatincludes ?lmA?
(as negation particle, relativepronoun or pseudo verb), ?hA?
(a demonstra-tive pronoun), or ?Ebd?
and ?>bw?
in propernouns, a space is inserted after those parts ofthe analysis.?
If a word has no morphological analysis, butstarts with a set of commonly mis-attachedwords, and the rest of the word has an anal-ysis, the word is split after the mis-attachedword sequence.Rules for merging words?
All lone occurrences of the conjunction w?and?
are attached to the following word.?
All sequences of the punctuation marks (., ?,!)
that occur between two and six times aremerged: e.g !
!
!
?
!!
!.4 Experimental ResultsIn Section 3, we described the individual sys-tem components that address different types oferrors.
In this section, we show how the sys-tem improves when each component is added intothe system.
System output is scored with theM2 scorer (Dahlmeier and Ng, 2012), the officialscorer of the shared task.Table 2 reports performance results of each ver-sion of the Columbia system on the developmentdata.
Table 3 shows the performance results for thebest-performing system, CLMB-1, as each systemcomponent is added.System P R F1CLMB-1 72.22 62.79 67.18CLMB-2 69.49 61.72 65.38CLMB-3 69.71 59.42 64.15Table 2: Performance of the Columbia systemson the development data.System P R F1MADAMIRA 83.33 32.94 47.21+ MLE 86.52 42.52 57.02+ NB 85.80 43.27 57.53+ Punc.
73.66 59.51 65.83+ Patterns 72.22 62.79 67.18Table 3: Performance of the CLMB-1 system onthe development data and the contribution ofits components.System P R F1CLMB-1 73.34 63.23 67.91CLMB-2 70.86 62.21 66.25CLMB-3 71.45 60.00 65.22Table 4: Performance of the Columbia systemson the test data.Finally, Table 4 reports results obtained on thetest data.
These results are comparable to the per-formance observed on the development data.
Inparticular, CLMB-1 achieves the highest score.5 ConclusionWe have described the Columbia University sys-tem that participated in the first shared taskon grammatical error correction for Arabic andranked first out of nine participating teams.
Wehave presented three versions of the system; all ofthese incorporate several components that targetdifferent types of mistakes, which we presentedand evaluated in this paper.AcknowledgmentsThis material is based on research funded by grantNPRP-4-1058-1-168 from the Qatar National Re-search Fund (a member of the Qatar Foundation).The statements made herein are solely the respon-sibility of the authors.
Nizar Habash performedmost of his contribution to this paper while he wasat the Center for Computational Learning Systemsat Columbia University.163ReferencesT.
Buckwalter.
2007.
Issues in Arabic MorphologicalAnalysis.
In A. van den Bosch and A. Soudi, editors,Arabic Computational Morphology: Knowledge-based and Empirical Methods.
Springer.D.
Dahlmeier and H. T. Ng.
2012.
Better evaluationfor grammatical error correction.
In Proceedings ofNAACL.A.
El Kholy and N. Habash.
2012.
Orthographic andmorphological processing for English?Arabic sta-tistical machine translation.
Machine Translation,26(1-2).N.
Farra, N. Tomeh, A. Rozovskaya, and N. Habash.2014.
Generalized character-level spelling error cor-rection.
In Proceedings of ACL.J.
Fiscus.
1998.
Sclite scoring package ver-sion 1.5.
US National Institute of StandardTechnology (NIST), URL http://www.
itl.
nist.gov/iaui/894.01/tools.N.
Y. Habash.
2010.
Introduction to Arabic naturallanguage processing.
Synthesis Lectures on HumanLanguage Technologies 3.1.M.
Hall, F. Eibe, G. Holmes, B. Pfahringer, P. Reute-mann, and I. H. Witten.
2009.
The WEKA datamining software: an update.
SIGKDD Explorations,11(1):10?18.T.
Kudo.
2005.
YamCha: Yet another multipurposechunk annotator.
http://chasen.org/ taku/software/.M.
Maamouri, D. Graff, B. Bouziri, S. Krouna, A. Bies,and S. Kulick.
2010.
LDC Standard Arabic Mor-phological Analyzer (SAMA) Version 3.1.
LinguisticData Consortium.B.
Mohit, A. Rozovskaya, N. Habash, W. Zaghouani,and O. Obeid.
2014.
The first QALB shared task onautomatic text correction for Arabic.
In Proceedingsof EMNLP Workshop on Arabic Natural LanguageProcessing.H.
T. Ng, S. M. Wu, Y. Wu, Ch.
Hadiwinoto, andJ.
Tetreault.
2013.
The CoNLL-2013 shared taskon grammatical error correction.
In Proceedings ofCoNLL: Shared Task.H.
T. Ng, S. M. Wu, T. Briscoe, C. Hadiwinoto, R. H.Susanto, and C. Bryant.
2014.
The CoNLL-2014shared task on grammatical error correction.
In Pro-ceedings of CoNLL: Shared Task.R.
Parker, D. Graff, K. Chen, J. Kong, and K. Maeda.2011.
Arabic Gigaword Fifth Edition.
LinguisticData Consortium.A.
Pasha, M. Al-Badrashiny, A. E. Kholy, R. Eskan-der, M. Diab, N. Habash, M. Pooleery, O. Rambow,and R. Roth.
2014.
MADAMIRA: A fast, compre-hensive tool for morphological analysis and disam-biguation of arabic.
In Proceedings of LREC.A.
Rozovskaya and D. Roth.
2011.
Algorithm selec-tion and model adaptation for ESL correction tasks.In Proceedings of ACL.W.
Salloum and N. Habash.
2011.
Dialectal to stan-dard arabic paraphrasing to improve arabic-englishstatistical machine translation.
In Proceedings ofthe First Workshop on Algorithms and Resources forModelling of Dialects and Language Varieties.W.
Salloum and N. Habash.
2012.
Elissa: A dialectalto standard arabic machine translation system.
InProceedings of COLING (Demos).A.
Stolcke.
2002.
Srilm-an extensible language mod-eling toolkit.
In Proceedings of International Con-ference on Spoken Language Processing.W.
Zaghouani, B. Mohit, N. Habash, O. Obeid,N.
Tomeh, A. Rozovskaya, N. Farra, S. Alkuhlani,and K. Oflazer.
2014.
Large scale arabic error anno-tation: Guidelines and framework.
In Proceedingsof the Ninth International Conference on LanguageResources and Evaluation (LREC?14).164
