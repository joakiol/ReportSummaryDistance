Proceedings of the ACL-HLT 2011 System Demonstrations, pages 7?13,Portland, Oregon, USA, 21 June 2011. c?2011 Association for Computational LinguisticsThe ACL Anthology SearchbenchUlrich Scha?fer Bernd Kiefer Christian Spurk Jo?rg Steffen Rui WangLanguage Technology LabGerman Research Center for Artificial Intelligence (DFKI)D-66123 Saarbru?cken, Germany{ulrich.schaefer,kiefer,cspurk,steffen,wang.rui}@dfki.dehttp://www.dfki.de/ltAbstractWe describe a novel application for structuredsearch in scientific digital libraries.
The ACLAnthology Searchbench is meant to become apublicly available research tool to query thecontent of the ACL Anthology.
The applica-tion provides search in both its bibliographicmetadata and semantically analyzed full tex-tual content.
By combining these two features,very efficient and focused queries are possi-ble.
At the same time, the application servesas a showcase for the recent progress in nat-ural language processing (NLP) research andlanguage technology.
The system currentlyindexes the textual content of 7,500 anthol-ogy papers from 2002?2009 with predicate-argument-like semantic structures.
It alsoprovides useful search filters based on bib-liographic metadata.
It will be extended toprovide the full anthology content and en-hanced functionality based on further NLPtechniques.1 Introduction and MotivationScientists in all disciplines nowadays are faced witha flood of new publications every day.
In addi-tion, more and more publications from the past be-come digitally available and thus even increase theamount.
Finding relevant information and avoidingduplication of work have become urgent issues to beaddressed by the scientific community.The organization and preservation of scientificknowledge in scientific publications, vulgo text doc-uments, thwarts these efforts.
From a viewpoint ofa computer scientist, scientific papers are just ?un-structured information?.
At least in our own sci-entific community, Computational Linguistics, it isgenerally assumed that NLP could help to supportsearch in such document collections.The ACL Anthology1 is a comprehensive elec-tronic collection of scientific papers in our own field(Bird et al, 2008).
It is updated regularly withnew publications, but also older papers have beenscanned and are made available electronically.We have implemented the ACL AnthologySearchbench2 for two reasons: Our first aim is toprovide a more targeted search facility in this col-lection than standard web search on the anthologywebsite.
In this sense, the Searchbench is meant tobecome a service to our own community.Our second motivation is to use the developedsystem as a showcase for the progress that has beenmade over the last years in precision-oriented deeplinguistic parsing in terms of both efficiency andcoverage, specifically in the context of the DELPH-IN community3.
Our system also uses further NLPtechniques such as unsupervised term extraction,named entity recognition and part-of-speech (PoS)tagging.By automatically precomputing normalized se-mantic representations (predicate-argument struc-ture) of each sentence in the anthology, the searchspace is structured and allows to find equivalent orrelated predicates even if they are expressed differ-1http://www.aclweb.org/anthology2http://aclasb.dfki.de3http://www.delph-in.net ?
DELPH-IN stands forDEep Linguistic Processing with HPSG INitiative.7ently, e.g.
in passive constructions, using synonyms,etc.
By storing the semantic sentence structure alongwith the original text in a structured full-text searchengine, it can be guaranteed that recall cannot fallbehind the baseline of a fulltext search.In addition, the Searchbench also provides de-tailed bibliographic metadata for filtering as well asautosuggest texts for input fields computed from thecorpus ?
two further key features one can expectfrom such systems today, nevertheless very impor-tant for efficient search in digital libraries.We describe the offline preprocessing and deepparsing approach in Section 2.
Section 3 concen-trates on the generation of the semantic search in-dex.
In Section 4, we describe the search interface.We conclude in Section 5 and present an outlook tofuture extensions.2 Parsing the ACL AnthologyThe basis of the search index for the ACL Anthol-ogy are its original PDF documents, currently 8,200from the years 2002 through 2009.
To overcomequality problems in text extraction from PDF, weuse a commercial PDF extractor based on OCR tech-niques.
This approach guarantees uniform and high-quality textual representations even from older pa-pers in the anthology (before 2000) which mostlywere scanned from printed paper versions.The general idea of the semantics-oriented ac-cess to scholarly paper content is to parse each sen-tence they contain with the open-source HPSG (Pol-lard and Sag, 1994) grammar for English (ERG;Flickinger (2002)) and then distill and index seman-tically structured representations for search.To make the deep parser robust, it is embeddedin a NLP workflow.
The coverage (percentage offull deeply parsed sentences) on the anthology cor-pus could be increased from 65 % to now morethan 85 % through careful combination of severalrobustness techniques; for example: (1) chart prun-ing, directed search during parsing to increase per-formance, and also coverage for longer sentences(Cramer and Zhang, 2010); (2) chart mapping, anovel method for integrating preprocessing informa-tion in exactly the way the deep grammar expectsit (Adolphs et al, 2008); (3) new version of theERG with better handling of open word classes; (4)more fine-grained named entity recognition, includ-ing recognition of citation patterns; (5) new, bettersuited parse ranking model (WeScience; Flickingeret al (2010)).
Because of limited space, we will fo-cus on (1) and (2) below.
A more detailed descrip-tion and further results are available in (Scha?fer andKiefer, 2011).Except for a small part of the named entity recog-nition components (citations, some terminology)and the parse ranking model, there are no furtheradaptations to genre or domain of the text corpus.This implies that the NLP workflow could be easilyand modularly adapted to other (scientific or non-scientific) domains?mainly thanks to the genericand comprehensive language modelling in the ERG.The NLP preprocessing component workflow isimplemented using the Heart of Gold NLP mid-dleware architecture (Scha?fer, 2006).
It startswith sentence boundary detection (SBR) and regu-lar expression-based tokenization using its built-incomponent JTok, followed by the trigram-based PoStagger TnT (Brants, 2000) trained on the Penn Tree-bank (Marcus et al, 1993) and the named entity rec-ognizer SProUT (Droz?dz?yn?ski et al, 2004).2.1 Precise Preprocessing Integration withChart MappingTagger output is combined with information fromthe named entity recognizer, e.g.
delivering hypo-thetical information on citation expressions.
Thecombined result is delivered as input to the deepparser PET (Callmeier, 2000) running the ERG.Here, citations, for example, can be treated as eitherpersons, locations or appositions.Concerning punctuation, the ERG can make useof information on opening and closing quotationmarks.
Such information is often not explicit in theinput text, e.g.
when, as in our setup, gained throughOCR which does not distinguish between ?
and ?
or ?and ?.
However, a tokenizer can often guess (recon-struct) leftness and rightness correctly.
This infor-mation, passed to the deep parser via chart mapping,helps it to disambiguate.2.2 Increased Processing Speed and Coveragethrough Chart PruningIn addition to a well-established discriminative max-imum entropy model for post-analysis parse selec-8tion, we use an additional generative model as de-scribed in Cramer and Zhang (2010) to restrict thesearch space during parsing.
This restriction in-creases efficiency, but also coverage, because theparse time was restricted to at most 60 CPU secondson a standard PC, and more sentences could now beparsed within these bounds.
A 4 GB limit for mainmemory consumption was far beyond what was everneeded.
We saw a small but negligible decrease inparsing accuracy, 5.4 % best parses were not founddue to the pruning of important chart edges.Ninomiya et al (2006) did a very thorough com-parison of different performance optimization strate-gies, and among those also a local pruning strategysimilar to the one used here.
There is an importantdifference between the systems, in that theirs workson a reduced context-free backbone first and recon-structs the results with the full grammar, while PETuses the HPSG grammar directly, with subsumptionpacking and partial unpacking to achieve a similareffect as the packed chart of a context-free parser.010203040506070800  20  40  60  80  100sentences x 1000mean parse time (CPU s)sentence length ?
?Figure 1: Distribution of sentence length and mean parsetimes for mild pruningIn total, we parsed 1,537,801 sentences, of which57,832 (3.8 %) could not be parsed because of lexi-con errors.
Most of them were caused by OCR ar-tifacts resulting in unexpected punctuation charactercombinations.
These can be identified and will bedeleted in the future.Figure 1 displays the average parse time of pro-cessing with a mild chart pruning setting, togetherwith the mean quadratic error.
In addition, it con-tains the distribution of input sentences over sen-tence length.
Obviously, the vast majority of sen-tences has a length of at most 60 words4.
The parsetimes only grow mildly due to the many optimiza-tion techniques in the original system, and also thenew chart pruning method.
The sentence length dis-tribution has been integrated into Figure 1 to showthat the predominant part of our real-world corpuscan be processed using this information-rich methodwith very low parse times (overall average parsetime < 2 s per sentence).The large amount of short inputs is at first surpris-ing, even more so that most of these inputs can notbe parsed.
Most of these inputs are non-sentencessuch as headings, enumerations, footnotes, table cellcontent.
There are several alternatives to deal withsuch input, one to identify and handle them in a pre-processing step, another to use a special root con-dition in the deep analysis component that is ableto combine phrases with well-defined properties forinputs where no spanning result could be found.We employed the second method, which has theadvantage that it handles a larger range of phenom-ena in a homogeneous way.
Figure 2 shows thechange in percentage of unparsed and timed out in-puts for the mild pruning method with and withoutthe root condition combining fragments.01020304050607080901000  20  40  60  80  100strictstrict timeoutstrict+fragmentsstrict+fragments timeoutsentence length ?
?Figure 2: Unparsed and timed out sentences with andwithout fragment combinationFigure 2 shows that this changes the curve for un-parsed sentences towards more expected character-istics and removes the uncommonly high percent-age of short sentences for which no parse can becomputed.
Together with the parses for fragmented4It has to be pointed out that extremely long sentences alsomay be non-sentences resulting from PDF extraction errors,missing punctuation etc.
No manual correction took place.9Figure 3: Multiple semantic tuples may be generated for a sentenceinput, we get a recall (sentences with at least oneparse) over the whole corpus of 85.9 % (1,321,336sentences), without a significant change for any ofthe other measures, and with potential for further im-provement.3 Semantic Tuple Extraction with DMRSIn contrast to shallow parsers, the ERG not onlyhandles detailed syntactic analyses of phrases, com-pounds, coordination, negation and other linguisticphenomena that are important for extracting seman-tic relations, but also generates a formal semanticrepresentation of the meaning of the input sentencein the Minimal Recursion Semantics (MRS) repre-sentation format (Copestake et al, 2005).
It consistsof elementary predications for each word and largerconstituents, connected via argument positions andvariables, from which predicate-argument structurecan be extracted.MRS representations resulting from deep parsingare still relatively close to linguistic structures andcontain more detailed information than a user wouldlike to query and search for.
Therefore, an additionalextraction and abstraction step is performed beforestoring semantic structures in the search index.Firstly, MRS is converted to DMRS (Copes-take, 2009), a dependency-style version of MRSthat eases extraction of predicate-argument struc-ture using the implementation in LKB (Copestake,2002).
The representation format we devised for thesearch index we call semantic tuples, in fact quintu-ples <subject, predicate, first object, second object,adjuncts>; example in Figure 3.
The basic extrac-tion algorithm consists of the following three steps:(1) calculate the closure for each elementary pred-ication based on the EQ (variable equivalence) re-lation, and group the predicates and entities in eachclosure respectively; (2) extract the relations of thegroups, which results in a graph as a whole; (3) re-cursively traverse the graph, form one semantic tu-ple for each predicate, and fill in the correspondinginformation under its scope, i.e.
subject, object, etc.In the example shown in Figure 3, entity groupslike ?our systems?, ?the baseline?, and ?good perfor-mance on the SRL task?, as well as predicate groups?beating?
and ?achieved?
are formed at the first step.In the second step, the graph structure is extracted,i.e., the relation between the groups.
Finally, twosemantic tuples are filled in with both the predicatesand the corresponding information.
Notice that themodifier(s) of the entity belong to the same entitygroup, but the modifier(s) of the predicate will beput into the Adjuncts slot.
Similarly, the coordina-tion of the entities will be put into one entity group,while the coordination of predicates will form mul-tiple semantic tuples.Since we are extracting predicate-argument struc-ture, syntactic variations such as passive construc-tions and relative clauses will be all ?normalized?into the same form.
Consequently, ?the book whichI read?, ?I read the book?, and ?the book was readby me?
will form the exact same semantic tuple <I,read, the book, N/A, N/A>.
The resulting tuplestructures along with their associated text are storedin an Apache Solr/Lucene5 server which receivesqueries from the Searchbench user interface.4 Searchbench User InterfaceThe Searchbench user interface (UI) is a web appli-cation running in every modern, JavaScript-enabledweb browser.
As can be seen in Figure 4, the UIis divided into three parts: (1) a sidebar on the left(Filters View), where different filters can be set thatconstrain the list of found documents; (2) a list offound documents matching the currently set filtersin the upper right part of the UI (Results View); (3)5http://lucene.apache.org/solr10Figure 4: Searchbench user interface with different filters set and currently looking at the debug menu for a sentence.the Document View in the lower right part of the UIwith different views of the current document.A focus in the design of the UI has been to al-low the user to very quickly browse the papers of theACL Anthology and then to find small sets of rele-vant documents based on metadata and content.
Thisis mainly achieved by these techniques: (i) changesin the collection of filters automatically update theResults View; (ii) metadata and searchable contentfrom both the Results View and the Document Viewcan easily be used with a single click as new filters;(iii) filters can easily be removed with a single click;(iv) manually entering filter items is assisted by sen-sible autosuggestions computed from the corpus; (v)accidental filter changes can easily be corrected bygoing back in the browser history.The following kinds of filters are supported:Statements (filter by semantic statements, i.e., theactual content of sentences, see Section 4.1), Key-words (filter by simple keywords with a full-textsearch), Topics (filter by topics of the articles thatwere extracted with an extended approach of the un-supervised term extractor of Frantzi et al (1998)),Publication (filter by publication title/event), Au-thors (filter by author names), Year (filter by pub-lication year), Affiliations (filter by affiliation or-ganizations), Affiliation Sites (filter by affiliationcities and countries)6.
Found papers always matchall currently set filters.
For each filter type multi-ple different filter items can be set; one could searchfor papers written jointly by people from differentresearch institutes on a certain topic, for example.Matches of the statements filter and the keywordsfilter are highlighted in document snippets for eachpaper in the Results View and in the currently se-lected paper of the Document View.Besides a header displaying the metadata of thecurrently selected paper (including the automaticallyextracted topics on the right), the Document Viewprovides three subviews of the selected paper: (1)the Document Content View is a raw list of the sen-tences of the paper and provides different kinds ofinteraction with these sentences; (2) the PDF Viewshows the original PDF version of the paper; (3) theCitations View provides citation information includ-6Affiliations have been added using the ACL AnthologyNetwork data (Radev et al, 2009).11ing link to the ACL Anthology Network (Radev etal., 2009).Figure 4 shows the search result for a query com-bining a statement (?obtain improvements?
), a topic?dependency parsing?
and the publication year 2008.As can be seen in the Results View, six papersmatch these filters; sentences with semantically sim-ilar predicates and passive voice are found, too.4.1 Semantic SearchThe main feature which distinguishes the ACL An-thology Searchbench from other search applicationsfor scientific papers is the semantic search in papercontent.
This enables the search for (semantic) state-ments in the paper content as opposed to searchingfor keywords in the plain text.
Our use of the term?statement?
is loosely along the lines of the sameterm used in logic.
Very simple sentences oftenbear a single statement only, while more complexsentences (especially when having multiple clauses)contain multiple statements.
Each of the semantictuples extracted from the papers of the ACL Anthol-ogy (cf.
Section 3) corresponds to a statement.The Statements filter is responsible for the seman-tic search.
Statements used in filters may be under-specified, e.g., one may search for statements with acertain semantic subject but with arbitrary semanticpredicates and objects.
There are two ways in whicha new statement filter can be set: (1) entering a state-ment manually; (2) clicking a sentence in the Doc-ument Content View and choosing the statements ofthis sentence that shall be set as new statement fil-ters (cf.
Figure 5), i.e.
it is possible to formulate andrefine queries ?by example?.Figure 5: Dialog for choosing statements to be used asnew filters (for sentence ?Our systems achieved good per-formance on the SRL task, easily beating the baseline.?
).Throughout the user interface, no distinction ismade between the different kinds of semantic ob-jects and adjuncts so as to make it easy also fornon-linguists to use the search and to be more ro-bust against bad analyses of the parser.
Therefore,the different semantic parts of a statement are high-lighted in three different colors only, depending onwhether a part is the semantic subject, the semanticpredicate or anything else (object/adjunct).In order to disengage even further from the con-crete wording and make the semantic search evenmore ?meaning-based?, we additionally search forsynonyms of the semantic predicates in statementfilters.
These synonyms have been computed as anintersection of the most frequent verbs (semanticpredicates) in the anthology corpus with WordNetsynsets (Fellbaum, 1998), the main reason being re-duction of the number of meanings irrelevant for thedomain.
This relatively simple approach could ofcourse be improved, e.g.
by active learning fromuser clicks in search results etc.5 Summary and OutlookWe have described the ACL Anthology Search-bench, a novel search application for scientific dig-ital libraries.
The system is fully implemented andindexes 7,500 papers of the 8,200 parsed ones.
Forthe other 700, bibliographic metadata was missing.These and the remaining 10,000 papers are currentlybeing processed and will be added to the search in-dex.
The goal of the Searchbench is both to serveas a showcase for benefits and improvement of NLPfor text search and at the same time provide a use-ful tool for researchers in Computational Linguis-tics.
We believe that the tool by now already sup-ports targeted search in a large collection of digitalresearch papers better than standard web search en-gines.
An evaluation comparing Searchbench queryresults with web search is in progress.Optionally, the Searchbench runs in a linguisticdebug mode providing NLP output a typical userwould not need.
These analyses are accessible froma context menu on each sentence (cf.
Figure 4).
Botha tabular view of the semantic tuples of a sentence(cf.
Figure 3) and different kinds of information re-lated to the parsing of the sentence (including theMRS and a parse tree) can be displayed.Future work, for which we are urgently seek-ing funding, could include integration of further12NLP-based features such as coreference resolutionor question answering, as well as citation classifi-cation and graphical navigation along the ideas inScha?fer and Kasterka (2010).AcknowledgmentsWe are indebted to Peter Adolphs, Bart Cramer, DanFlickinger, Stephan Oepen, Yi Zhang for their sup-port with ERG and PET extensions such as chartmapping and chart pruning.
Melanie Reiplinger,Benjamin Weitz and Leonie Gro?n helped with pre-processing.
We also thank the anonymous review-ers for their encouraging comments.
The work de-scribed in this paper has been carried out in thecontext of the project TAKE (Technologies for Ad-vanced Knowledge Extraction), funded under con-tract 01IW08003 by the German Federal Ministryof Education and Research, and in the context of theworld-wide DELPH-IN consortium.ReferencesPeter Adolphs, Stephan Oepen, Ulrich Callmeier,Berthold Crysmann, Daniel Flickinger, and BerndKiefer.
2008.
Some fine points of hybrid natural lan-guage parsing.
In Proceedings of LREC-2008, pages1380?1387, Marrakesh, Morocco.Steven Bird, Robert Dale, Bonnie Dorr, Bryan Gibson,Mark Joseph, Min-Yen Kan, Dongwon Lee, BrettPowley, Dragomir Radev, and Yee Fan Tan.
2008.
TheACL anthology reference corpus: A reference datasetfor bibliographic research.
In Proceedings of LREC-2008, pages 1755?1759, Marrakesh, Morocco.Torsten Brants.
2000.
TnT ?
a statistical part-of-speechtagger.
In Proc.
of ANLP, pages 224?231, Seattle, WA.Ulrich Callmeier.
2000.
PET ?
A platform for experi-mentation with efficient HPSG processing techniques.Natural Language Engineering, 6(1):99?108.Ann Copestake, Dan Flickinger, Ivan A.
Sag, and CarlPollard.
2005.
Minimal recursion semantics: an in-troduction.
Research on Language and Computation,3(2?3):281?332.Ann Copestake.
2002.
Implementing Typed FeatureStructure Grammars.
CSLI publications, Stanford.Ann Copestake.
2009.
Slacker semantics: why superfi-ciality, dependency and avoidance of commitment canbe the right way to go.
In Proc.
of EACL, pages 1?9.Bart Cramer and Yi Zhang.
2010.
Constraining robustconstructions for broad-coverage parsing with preci-sion grammars.
In Proceedings of COLING-2010,pages 223?231, Beijing, China.Witold Droz?dz?yn?ski, Hans-Ulrich Krieger, Jakub Pisko-rski, Ulrich Scha?fer, and Feiyu Xu.
2004.
Shallowprocessing with unification and typed feature struc-tures ?
foundations and applications.
Ku?nstliche In-telligenz, 2004(1):17?23.Christiane Fellbaum, editor.
1998.
WordNet, An Elec-tronic Lexical Database.
MIT Press.Dan Flickinger, Stephan Oepen, and Gisle Ytrest?l.2010.
WikiWoods: Syntacto-semantic annotation forEnglish Wikipedia.
In Proceedings of LREC-2010,pages 1665?1671.Dan Flickinger.
2002.
On building a more efficientgrammar by exploiting types.
In Dan Flickinger,Stephan Oepen, Hans Uszkoreit, and Jun?ichi Tsujii,editors, Collaborative Language Engineering.
A CaseStudy in Efficient Grammar-based Processing, pages1?17.
CSLI Publications, Stanford, CA.Katerina T. Frantzi, Sophia Ananiadou, and Jun?ichi Tsu-jii.
1998.
The C-value/NC-value method of automaticrecognition for multi-word terms.
In Proceedings ofECDL, pages 585?604.Mitchell P. Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1993.
Building a large annotated cor-pus of English.
The Penn Treebank.
ComputationalLinguistics, 19:313?330.Takashi Ninomiya, Yoshimasa Tsuruoka, Yusuke Miyao,Kenjiro Taura, and Jun?ichi Tsujii.
2006.
Fast andscalable HPSG parsing.
Traitement automatique deslangues (TAL), 46(2).Carl Pollard and Ivan A.
Sag.
1994.
Head-Driven PhraseStructure Grammar.
Studies in Contemporary Lin-guistics.
University of Chicago Press, Chicago.Dragomir R. Radev, Pradeep Muthukrishnan, and Va-hed Qazvinian.
2009.
The ACL anthology networkcorpus.
In Proceedings of the ACL-2009 Workshopon Natural Language Processing and Information Re-trieval for Digital Libraries, Singapore.Ulrich Scha?fer and Uwe Kasterka.
2010.
Scientificauthoring support: A tool to navigate in typed cita-tion graphs.
In Proceedings of the NAACL-HLT 2010Workshop on Computational Linguistics and Writing,pages 7?14, Los Angeles, CA.Ulrich Scha?fer and Bernd Kiefer.
2011.
Advances indeep parsing of scholarly paper content.
In RaffaellaBernardi, Sally Chambers, Bjo?rn Gottfried, Fre?de?riqueSegond, and Ilya Zaihrayeu, editors, Advanced Lan-guage Technologies for Digital Libraries, LNCS HotTopics Series.
Springer.
to appear.Ulrich Scha?fer.
2006.
Middleware for creating andcombining multi-dimensional NLP markup.
In Pro-ceedings of the EACL-2006 Workshop on Multi-dimensional Markup in Natural Language Processing,pages 81?84, Trento, Italy.13
