Proceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue, pages 302?305,Queen Mary University of London, September 2009. c?2009 Association for Computational LinguisticsTELIDA: A Package for Manipulation and Visualization ofTimed Linguistic DataTitus von der Malsburg, Timo Baumann, David SchlangenDepartment of LinguisticsUniversity of Potsdam, Germany{malsburg|timo|das}@ling.uni-potsdam.deAbstractWe present a toolkit for manipulating andvisualising time-aligned linguistic datasuch as dialogue transcripts or languageprocessing data.
The package comple-ments existing editing tools by allowingfor conversion between their formats, in-formation extraction from the raw files,and by adding sophisticated, and easily ex-tended methods for visualising the dynam-ics of dialogue processing.
To illustratethe versatility of the package, we describeits use in three different projects at our site.1 IntroductionManual inspection and visualization of raw data isoften an important first step in the analysis of lin-guistic data, be that transcripts of conversations orrecords of the performance of processing modules.Dialogue data or speech processing data in gen-eral are typically temporally aligned, which posesadditional challenges for handling and visualiza-tion.
A number of tools are available for work-ing with timed data, each with different focus:as a small selection, Praat (Boersma, 2001) andWavesurfer (Sjo?lander and Beskow, 2000) excel atacoustic analysis and are helpful for transcriptionwork, Anvil (Kipp, 2001) helps with the analysisof video material, Exmaralda (Schmidt, 2004) of-fers a suite of specialized tools for discourse anal-ysis.We developed TELIDA (TimEd LInguisticDAta) to complement the strengths of these tools.TELIDA comprises (a) a suite of Perl mod-ules that offer flexible data structures for stor-ing timed data; tools for converting data in otherformats to and from this format; a command-line based interface for querying such data, en-abling for example statistical analysis outside ofthe original creators of transcriptions or annota-tions; and (b) a lightweight but powerful visual-ization tool, TEDview, that has certain unique fea-tures, as will be described in Section 2.3.
TEL-IDA is available for download from http://www.ling.uni-potsdam.de/~timo/code/telida/.2 Overview of TELIDA2.1 Data StructuresLike the tools mentioned above, we handle timeddata as discrete labels which span a certain timeand contain some data.
To give an example, in aword-aligned transcription of a recording, a singleword would correspond to one label.
Sequencesof (non-overlapping) labels are collected into whatwe call alignments.
In our example of the word-aligned transcription, all words from one speakermight be collected in one alignment.This so far is a conceptualization that is com-mon to many tools.
In Praat for example, ouralignments would be called a tier.
TELIDA adds afurther, novel, abstraction, by treating alignmentsas belief states that can have a time (namely thatof their formation) as well.
Concretely, an incre-mental ASR may hypothesize a certain way of an-alyzing a stretch of sound at one point, but at alater point might slighlty adapt this analysis; in ourconceptualization, this would be two alignmentsthat model the same original data, each with a timestamp.
For other applications, timed belief statesmay contain other information, e.g.
new states ofparse constructions or dialogue manager informa-tion states.
We also allow to store several of suchalignment sequences (= successive belief states) inparallel, to represent n-best lists.302Figure 1: TEDview Showing Annotated Dialogue DataA document finally can consist of collectionsof such alignments that reference the same time-line, but model different aspects of the base-data.For example, we may want to store informationabout turns, how they decompose into words, andinto phonemes; or, for dual-channel dialogue, haveseparate alignments for the different speakers.2.2 Data Manipulation ToolsIn order to process timed linguistic data, we im-plemented a Perl library and command-line tools,TGtool and INtool for non-incremental and incre-mental data respectively.
They facilitate handling(showing, merging, editing, .
.
. )
and processing(search-and-replace, hypothesis filtering, .
.
. )
ofdata and interface to TEDview for interactive vi-sualization.2.3 TEDviewTEDview is the visualization component of TEL-IDA.
It organizes the different sources of informa-tion (i.e., alignments or alignment sequences) inhorizontal tracks.
Similar as in many of the above-mentioned tools, time progresses from left to rightin those tracks.
The content of tracks consists ofevents that are displayed as bars if they have a tem-poral extent or as diamonds otherwise.
TEDviewuses a player metaphor and therefore has a cursorthat marks the current time and a play-mode thatcan be used to replay recorded sequences of events(in real-time or sped-up / slowed-down).
Unlike inother tools, TEDview has a steady cursor (the redline in the Figures) across which events flow, andthis cursor can be moved, e.g.
to give a configura-tion where no future events are shown.Information encapsulated by events is displayedin two different ways:a) Labels are represented as bars, with the la-bel information shown as text.
(Figure 1 shows aconfiguration with only labels.
)b) Events without duration are displayed as di-amonds at the appropriate time (all other Figures).Such events can carry a ?payload?
; depending onits type, different display methods are chosen:?
If the payload is an alignment, it is displayedon the same track, as a sequence of labels.?
In all other cases TEDview determines thedata type of the information and selects an appro-priate plug-in for displaying it in a separate inspec-tor window.
These data types can be syntax trees,probability distributions, etc.To avoid visual clutter, only the informationcontained in the diamonds that most recentlypassed the cursor are displayed.
In this way, TED-view can elegantly visualize the dynamics of in-formation state development.Events can be fed to TEDview either from a file,in a use case where pre-recorded material is re-played for analysis, or online, via a network con-nection, in use cases where processing compo-nents are monitored or profiled in real-time.
Theformat used to encode events and their encapsu-303Figure 2: TEDview showing different filteringstrategies for incremental ASR: Diamonds corre-spond to edits of the hypothesis.lated information is a simple and generic XMLformat (which the data manipulation tools can cre-ate out of other formats, if necessary), i.e.
the for-mat does not make any assumptions as to what theevents represent.
For this reason TEDview can beused to visualize almost any type of discrete tem-poral data.
Intervals can be adorned with displayinformation, for example to encode further infor-mation via colouring.
Plug-ins for special data-types can be written in the programming languagePython with its powerful library of extension mod-ules; this enabled us to implement an inspector forsyntax trees in only 20 lines of code.3 Use CasesTo illustrate the versatility of the tool, we now de-scribe how we use it in several projects at our site.
(Technical manuals can be downloaded from thepage listed above.
)3.1 Analysis of Dialogue DataIn the DEAWU project (see e.g.
(Schlangen andFerna?ndez, 2007)), we used the package to main-tain transcriptions made in Praat and annotationsmade in MMAX2 (Mu?ller and Strube, 2006), andto visualize these together in a time-aligned view.As Figure 1 shows, we made heavy use of thepossibility of encoding information via colour.
Inthe example, there is one track (mac, for mouseactivity) where a numerical value (how much themouse travels in a certain time frame) is visual-ized through the colouring of the interval.
In othertracks other information is encoded through colouras well.
We found this to be of much use in the?getting to know the data?
phase of the analysis ofour experiment.
We have also used the tool andthe data in teaching about dialogue structure.Figure 3: TEDview showing 5-best incrementalASR hypotheses.3.2 Analysis of SDS PerformanceIn another project, we use TELIDA to analyze andvisualize the incremental output of several mod-ules of a spoken dialogue system we are currentlydeveloping.In incremental speech recognition, what is con-sidered the best hypothesis frequently changes asmore speech comes in.
We used TEDview to an-alyze these changes and to develop filtering meth-ods to reduce the jitter and to reduce edits of theASR?s incremental hypothesis (Baumann et al,2009a).
Figure 2 shows incremental hypothesesand different settings of two filtering strategies.When evaluating the utility of using n-best ASRhypotheses, we used TEDview to visualize thebest hypotheses (Baumann et al, 2009b).
An in-teresting result we got from this analysis is thattypically the best hypothesis seems to be more sta-ble than lower-ranked hypotheses, as can be seenin Figure 3.We also evaluated the behaviour of our in-cremental reference resolution module, whichoutputs distributions over possible referents(Schlangen et al, 2009).
We implemented a TED-view plug-in to show distributions in bar-charts, ascan be seen in Figure 4.3.3 Analysis of Cognitive ModelsIn another project, we use TEDview to visualizethe output of an ACT-R (Anderson et al, 2004)simulation of human sentence parsing developedby (Patil et al, 2009).
This model producespredictions of parsing costs based on working-memory load which in turn are used to predicteye tracking measures in reading.
Figure 5 showsan example where the German sentence ?Den Tongab der Ku?nstler seinem Gehilfen?
(the artist givesthe clay to his assistant) is being parsed, taking304Figure 4: TEDview showing the output of our in-cremental reference resolution module.
Distribu-tions are shown with a bar-chart plug-in.about 3 seconds of simulated time.
The items inthe channel labeled ?Memory?
indicate retrievalsof items from memory, the items in the channel la-beled ?Parse?
indicate that the parser produced anew hypothesis, and the inspector window on theright shows the latest of these hypotheses accord-ing to cursor time.
The grey bars finally in theremaining channels show the activity of the pro-duction rules.
Such visualizations help to quicklygrasp the behaviour of a model, and so greatly aiddevelopment and debugging.4 ConclusionsWe presented TELIDA, a package for the manip-ulation and visualization of temporally aligned(linguistic) data.
The package enables convenienthandling of dynamic data, especially from incre-mental processing, but more generally from allkinds of belief update.
We believe that it can beof use to anyone who is interested in exploringcomplex state changes over time, be that indialogue annotations or in system performanceprofiles.Acknowledgments This work was funded bya grant from DFG in the Emmy Noether Pro-gramme.ReferencesJ.R.
Anderson, D. Bothell, M.D.
Byrne, S. Douglass,C.
Lebiere, and Y. Qin.
2004.
An integrated theory ofthe mind.
Psychological Review, 111(4):1036?1060.Timo Baumann, Michaela Atterer, and David Schlangen.2009a.
Assessing and Improving the Performance ofSpeech Recognition for Incremental Systems.
In Proceed-ings of NAACL-HLT 2009, Boulder, USA.Figure 5: TEDview visualizing the dynamics ofan ACT-R simulation, including the current parse-tree.Timo Baumann, Okko Bu?, Michaela Atterer, and DavidSchlangen.
2009b.
Evaluating the Potential Utility ofASR N-Best Lists for Incremental Spoken Dialogue Sys-tems.
In Proceedings of Interspeech 2009, Brighton, UK.Paul Boersma.
2001.
Praat, a system for doing phonetics bycomputer.
Glot International, 5(9?10):341?345.Michael Kipp.
2001.
Anvil - a generic annotation tool formultimodal dialogue.
In Proceedings of the 7th Euro-pean Conference on Speech Communication and Technol-ogy (Eurospeech), pages 1367?1370, Aalborg, Denmark.Christoph Mu?ller and Michael Strube.
2006.
Multi-level an-notation of linguistic data with MMAX2.
In Corpus Tech-nology and Language Pedagogy: New Resources, NewTools, New Methods, pages 197?214.
Peter Lang.Umesh Patil, Marisa Ferrara Boston, John T. Hale, ShravanVasishth, and Reinhold Kliegl.
2009.
The interaction ofsurprisal and working memory cost during reading.
InProc.
of the CUNY sentence processing conference, Davis,USA.David Schlangen and Raquel Ferna?ndez.
2007.
Speakingthrough a noisy channel - experiments on inducing clarifi-cation behaviour in human-human dialogue.
In Proceed-ings of Interspeech 2007, Antwerp, Belgium.David Schlangen, Timo Baumann, and Michaela Atterer.2009.
Incremental Reference Resolution: The Task, Met-rics for Evaluation, and a Bayesian Filtering Model that isSensitive to Disfluencies.
In Proc.
of SigDial 2009, Lon-don, UK.Thomas Schmidt.
2004.
Transcribing and annotating spokenlanguage with exmaralda.
In Proceedings of the LREC-Workshop on XML based richly annotated corpora, Lis-bon 2004, Paris.
ELRA.
EN.K.
Sjo?lander and J. Beskow.
2000.
Wavesurfer?an opensource speech tool.
In Sixth International Conference onSpoken Language Processing, Beijing, China.
ISCA.305
