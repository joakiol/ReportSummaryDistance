Proceedings of the EACL 2012 Joint Workshop of LINGVIS & UNCLH, pages 54?62,Avignon, France, April 23 - 24 2012. c?2012 Association for Computational LinguisticsLanguage comparison through sparse multilingual word alignmentThomas MayerResearch UnitQuantitative Language ComparisonLMU Munichthommy.mayer@googlemail.comMichael CysouwResearch CenterDeutscher SprachatlasPhilipp University of Marburgcysouw@uni-marburg.deAbstractIn this paper, we propose a novel approachto compare languages on the basis of par-allel texts.
Instead of using word lists orabstract grammatical characteristics to infer(phylogenetic) relationships, we use mul-tilingual alignments of words in sentencesto establish measures of language similar-ity.
To this end, we introduce a new methodto quickly infer a multilingual alignment ofwords, using the co-occurrence of words ina massively parallel text (MPT) to simulta-neously align a large number of languages.The idea is that a simultaneous multilin-gual alignment yields a more adequate clus-tering of words across different languagesthan the successive analysis of bilingualalignments.
Since the method is computa-tionally demanding for a larger number oflanguages, we reformulate the problem us-ing sparse matrix calculations.
The useful-ness of the approach is tested on an MPTthat has been extracted from pamphlets ofthe Jehova?s Witnesses.
Our preliminaryexperiments show that this approach cansupplement both the historical and the ty-pological comparison of languages.1 IntroductionThe application of quantitative methods in histor-ical linguistics has attracted a lot of attention inrecent years (cf.
Steiner et al (2011) for a sur-vey).
Many ideas have been adapted from evolu-tionary biology and bioinformatics, where similarproblems occur with respect to the genealogicalgrouping of species and the multiple alignmentof strings/sequences.
One of the main differencesbetween those areas and attempts to uncover lan-guage history is the limited amount of suitabledata that can serve as the basis for language com-parison.
A widely used resource are Swadesh listsor similar collections of translational equivalentsin the form of word lists.
Likewise, phylogeneticmethods have been applied using structural char-acteristics (e.g., Dunn et al (2005)).
In this paper,we propose yet another data source, namely par-allel texts.Many analogies have been drawn between theevolution of species and languages (see, for in-stance, Pagel (2009) for such a comparison).
Oneof the central problems is to establish what is theequivalent of the gene in the reproduction of lan-guages.
Like in evolutionary biology, where genesequences in organisms are compared to inferphylogenetic trees, a comparison of the ?genes?of language would be most appropriate for a quan-titative analysis of languages.
Yet, Swadesh-like wordlists or structural characteristics do notneatly fit into this scheme as they are most likelynot the basis on which languages are replicated.After all, language is passed on as the expressionof propositions, i.e.
sentences, which usually con-sists of more than single words.
Hence, follow-ing Croft (2000), we assume that the basic unit ofreplication is a linguistic structure embodied in aconcrete utterance.According to this view, strings of DNA in bio-logical evolution correspond to utterances in lan-guage evolution.
Accordingly, genes (i.e., thefunctional elements of a string of DNA) corre-spond to linguistic structures occurring in thoseutterances.
Linguistic replicators (the ?genes?
oflanguage) are thus structures in the context of anutterance.
Such replicators are not only the wordsas parts of the sentence but also constructions toexpress a complex semantic structure, or phonetic54realizations of a phoneme, to give just a few ex-amples.In this paper, we want to propose an approachthat we consider to be a first step in the direc-tion of using the structure of utterances as thebasic unit for the comparison of languages.
Forthis purpose, a multilingual alignment of words inparallel sentences (as the equivalent of utterancesin parallel texts) is computed, similar to multi-species alignments of DNA sequences.1 Thesealignments are clusters of words from differentlanguages in the parallel translations of the samesentence.2The remainder of the paper is organized as fol-lows.
First, we quickly review the position of ourapproach in relation to the large body of work onparallel text analysis (Section 2).
Then we de-scribe the method for the multilingual alignmentof words (Section 3).
Since the number of lan-guages and sentences that have to be analyzed re-quire a lot of computationally expensive calcula-tions of co-occurrence counts, the whole analysisis reformulated into manipulations of sparse ma-trices.
The various steps are presented in detailto give a better overview of the calculations thatare needed to infer the similarities.
Subsequently,we give a short description of the material that weused in order to test our method (Section 4).
InSection 5 we report on some of the experimentsthat we carried out, followed by a discussion ofthe results and their implications.
Finally, we con-clude with directions for future work in this area.2 Word AlignmentAlignment of words using parallel texts has beenwidely applied in the field of statistical ma-chine translation (cf.
Koehn (2010)).
Alignmentmethods have largely been employed for bitexts,i.e., parallel texts of two languages (Tiedemann,2011).
In a multilingual context, the same meth-ods could in principle be used for each pair of lan-guages in the sample.
One of the goals of this pa-1The choice of translational equivalents in the form ofsentences rather than words accounts for the fact that somewords cannot be translated accurately between some lan-guages whereas most sentences can.2In practice, we simply use wordforms as separated byspaces or punctuation instead of any more linguistically sen-sible notion of ?word?.
For better performance, more detailedlanguage-specific analysis is necessary, like morpheme sep-aration, or the recognition of multi-word expressions andphrase structures.per, however, is to investigate what can be gainedwhen including additional languages in the align-ment process at the same time and not iterativelylooking for correspondences in pairs of languages(see Simard (1999), Simard (2000) for a similarapproach).There are basically two approaches to comput-ing word alignments as discussed in the literature(cf.
Och and Ney (2003)): (i) statistical alignmentmodels and (ii) heuristic models.
The former havetraditionally been used for the training of parame-ters in statistical machine translation and are char-acterized by their high complexity, which makesthem difficult to implement and tune.
The latterare considerably simpler and thus easier to im-plement as they only require a function for theassociation of words, which is computed fromtheir co-occurrence counts.
A wide variety of co-occurrence measures have been employed in theliterature.
We decided to use a heuristic methodfor the first steps reported on here, but plan to inte-grate statistical alignment models for future work.Using a global co-occurrence measure, we pur-sue an approach in which the words are comparedfor each sentence individually, but for all lan-guages at the same time.
That is, a co-occurrencematrix is created for each sentence, containing allthe words of all languages that occur in the cor-responding translational equivalents for that sen-tence.
This matrix then serves as the input fora partitioning algorithm whose results are inter-preted as a partial alignment of the sentence.
Inmost cases, the resulting alignments do not in-clude words from all languages.
Only those wordsthat are close translational equivalents occur inalignments.
This behavior, while not optimalfor machine translation, is highly useful for lan-guage comparison because differences betweenlanguages are implicitly marked as such by split-ting different structures into separate alignments.The languages are then compared on the basisof having words in the same clusters with otherlanguages.
The more word forms they share in thesame clusters, the more similar the languages areconsidered to be.3 The form of the words them-selves is thereby of no importance.
What counts3A related approach is discussed in Wa?lchli (2011).
Thebiggest difference to the present approach is that Wa?lchlionly compares languages pairwise.
In addition, he makes useof a global glossing method and not an alignment of wordswithin the same parallel sentence.55is their frequency of co-occurrence in alignmentsacross languages.
This is in stark contrast tomethods which focus on the form of words withsimilar meanings (e.g., using Swadesh lists) in or-der to compute some kind of language similar-ity.
One major disadvantage of the present ap-proach for a comparison of languages from a his-torical perspective is the fact that such similaritiesalso could be a consequence of language contact.This is a side effect that is shared by the wordlist approach, in which loanwords have a simi-lar effect on the results.
It has to be seen howstrongly this influences the final results in orderto assess whether our current approach is usefulfor the quantitative analysis of genealogical relat-edness.3 MethodWe start from a massively parallel text, which weconsider as an n?m matrix consisting of n differ-ent parallel sentences S = {S1, S2, S3, ..., Sn} inm different languages L = {L1, L2, L3, ..., Lm}.This data-matrix is called SL (?sentences ?
lan-guages?).
We assume here that the parallel sen-tences are short enough so that most words occuronly once per sentence.
Because of this assump-tion we can ignore the problem of decoding thecorrect alignment of multiple occurring words, aproblem we leave to be tackled in future research.We also ignore the complications of language-specific chunking and simply take spaces andpunctuation marks to provide a word-based sep-aration of the sentences into parts.
In future re-search we are planning to include the (language-specific) recognition of bound morphemes, multi-word expressions and phrase structures to allowfor more precise cross-language alignment.Based on these assumptions, we decompose theSL matrix into two sparse matrices WS (?words?
sentences?)
and WL (?words ?
languages?
)based on all words w that occur across all lan-guages in the parallel texts.
We define them asfollows.
First, WSij = 1 when word wi oc-curs in sentence Sj , and is 0 elsewhere.
Second,WLij = 1 when word wi is a word of languageLj , and is 0 elsewhere.
The product WST ?WLthen results in a matrix of the same size as SL,listing in each cell the number of different wordsin each sentence.
Instead of the current approachof using WS only for marking the occurrence ofa word in a sentence (i.e., a ?bag of words?
ap-proach), it is also possible to include the order ofwords in the sentences by defining WSij = kwhen word wi occurs in position k in sentenceSj .
We will not use this extension in this paper.The matrix WS will be used to compute co-occurrence statistics of all pairs of words, bothwithin and across languages.
Basically, we defineO (?observed co-occurrences?)
and E (?expectedco-occurrences?)
as:O = WS ?WSTE = WS ?1SSn?WSTEij thereby gives the expected number of sen-tences where wi and wj occur in the correspond-ing translational equivalents, on the assumptionthat words from different languages are statisti-cally independent of each other and occur at ran-dom in the translational equivalents.
Note thatthe symbol ?1ab?
in our matrix multiplicationsrefers to a matrix of size a ?
b consisting ofonly 1?s.
Widespread co-occurrence measures arepointwise mutual information, which under thesedefinitions simply is logE?
logO, or the cosinesimilarity, which would be O?n?E.
However, weassume that the co-occurrence of words followa poisson process (Quasthoff and Wolff, 2002),which leads us to define the co-occurrence matrixWW (?words ?
words?)
using a poisson distri-bution as:WW = ?
log[EO exp(?E)O!
]= E+ logO!
?O logEThis WW matrix represents a similarity ma-trix of words based on their co-occurrence intranslational equivalents for the respective lan-guage pair.
Using the alignment clustering thatis based on the WW matrices for each sentence,we then decompose the words-by-sentences ma-trix WS into two sparse matrices WA (?words?alignments?)
and AS (?alignments ?
sentences?
)such that WS = WA ?AS.
This decompositionis the basic innovation of the current paper.The idea is to compute concrete alignmentsfrom the statistical alignments in WW for eachsentence separately, but for all languages at thesame time.
For each sentence Si we take thesubset of the similarity matrix WW only includ-ing those words that occur in the column WSi,56i.e., only those words that occur in sentence Si.We then perform a partitioning on this subset ofthe similarity matrix WW.
In this paper we usethe affinity propagation clustering approach fromFrey and Dueck (2007) to identify the clusters, butthis is mainly a practical choice and other meth-ods could be used here as well.
The reason forthis choice is that this clustering does not requirea pre-defined number of clusters, but establishesthe optimal number of clusters together with theclustering itself.4 In addition, it yields an exem-plar for each cluster, which is the most typicalmember of the cluster.
This enables an inspec-tion of intermediate results of what the clustersactually contain.
The resulting clustering for eachsentence identifies groups of words that are sim-ilar to each other, which represent words that areto be aligned across languages.
Note that we donot force such clusters to include words from alllanguages, nor do we force any restrictions on thenumber of words per language in each cluster.5In practice, most alignments only include wordsfrom a small number of the languages included.To give a concrete example for the clusteringresults, consider the English sentence given below(no.
93 in our corpus, see next section) togetherwith its translational equivalents in German, Bul-garian, Spanish, Maltese and Ewe (without punc-tuation and capitalization).i.
who will rule with jesus (English, en)ii.
wer wird mit jesus regieren (German, de)iii.
ko$i we upravlva s isus (Bulgarian, bl)iv.
quie?nes gobernara?n con jesu?s (Spanish, es)v. min se jah?kem ma g?esu` (Maltese, mt)vi.
amekawoe a?u fia kple yesu (Ewe, ew)These six languages are only a subset of the50 languages that served as input for the matrixWW where all words that occur in the respectivesentence for all 50 languages are listed togetherwith their co-occurrence significance.
When re-stricting the output of the clustering to thosewords that occur in the six languages given above,4Instead of a prespecified number of clusters, affinitypropagation in fact takes a real number as input for each datapoint where data points with larger values are more likely tobe chosen as exemplars.
If no input preference is given foreach data point, as we did in our experiments, exemplar pref-erences are initialized as the median of non infinity values inthe input matrix.5Again, this takes into account that some words cannotbe translated accurately between some languages.however, the following clustering result is ob-tained:1. isusbl jesusen fiaew yesuew g?esu`mt jesu?sesjesusde2.
ko$ibl whoen minmt werde3.
regierende4.
upravlvabl a?uew jah?kemmt gobernara?nes5.
amekawoeew quie?neses6.
webl willen semtwirdde7.
sbl withen cones mitde8.
kpleew9.
mamt10.
ruleenFirst note that the algorithm does not requireall languages to be given in the same script.
Bul-garian isus is grouped together with its transla-tional equivalents in cluster 1 even though it doesnot share any grapheme with them.
Rather, wordsfrom different languages end up in the same clus-ter if they behave similarly across languages interms of their co-occurrence frequency.
Further,note that the ?question word?
clusters 2 and 5 dif-fer in their behavior as will be discussed in moredetail in Section 5.2.
Also note that the English?rule?
and German ?regieren?
are not included inthe cluster 4 with similar translations in the otherlanguages.
This turns out to be a side effect of thevery low frequency of these words in the currentcorpus.In the following, we will refer to these clustersof words as alignments (many-to-many mappingsbetween words) within the same sentence acrosslanguages.
For instance, sentences i., iii.
and v.above would have the following alignment, whereindices mark those words that are aligned by thealignment clusters (1.-10.)
above:who2 will6 rule10 with7 jesus1min2 se6 jah?kem4 ma7 g?esu`1ko$i2 we6 upravlva4 s7 isus1All alignment-clusters from all sentences aresummarized as columns in the sparse matrixWA,defined as WAij = 1 when word wi is part ofalignment Aj , and is 0 elsewhere.6 We also estab-lish the ?book-keeping?
matrix AS to keep track6For instance, the alignment in 2. above contains the fourwords {ko$i, who, min, wer}, which are thus marked with 1whereas all other words have 0 in this column of the WAmatrix.57of which alignment belongs to which sentence,defined as ASij = 1 when the alignment Ai oc-curs in sentence Sj , and as 0 elsewhere.
Thealignment matrix WA is the basic informationto be used for language comparison.
For exam-ple, the product WA ?WAT represents a sparseversion of the words ?
words similarity matrixWW.A more interesting usage of WA is to derivea similarity between the alignments AA.
We de-fine both a sparse version of AA, based on thenumber of words that co-occur in a pair of align-ments, and a statistical version of AA, based onthe average similarity between the words in thetwo alignments:AAsparse = WAT ?WAAAstatistical =WAT ?WW ?WAWAT ?
1WW ?WAThe AA matrices will be used to select suit-able alignments from the parallel texts to be usedfor language comparison.
Basically, the statisticalAA will be used to identify similar alignmentswithin a single sentence and the sparse AA willbe used to identify similar alignments across dif-ferent sentences.
Using a suitable selection ofalignments (we here use the notation A?
for a se-lection of alignments7), a similarity between lan-guages LL can be defined as:LL = LA?
?
LA?Tby defining LA?
(?languages ?
alignments?)
asthe number of words per language that occur ineach selected alignment:LA?
= WLT ?WA?The similarity between two languages LL is thenbasically defined as the number of times wordsare attested in the selected alignments for bothlanguages.
It thus gives an overview of howstructurally similar two languages are, where lan-guages are considered to have a more similarstructure the more words they share in the align-ment clusters.7Note that the prime in this case does not stand for thetranspose of a matrix, as it is sometimes used.4 DataParallel corpora have received a lot of attentionsince the advent of statistical machine translation(Brown et al, 1988) where they serve as trainingmaterial for the underlying alignment models.
Forthis reason, the last two decades have seen an in-creasing interest in the collection of parallel cor-pora for a number of language pairs (Hansard8),also including text corpora which contain textsin three or more languages (OPUS9, Europarl10,Multext-East11).
Yet there are only few resourceswhich comprise texts for which translations areavailable into many different languages.
Suchtexts are here referred to as ?massively paralleltexts?
(MPT; cf.
Cysouw and Wa?lchli (2007)).The most well-known MPT is the Bible, whichhas a long tradition in being used as the basisfor language comparison.
Apart from that, otherreligious texts are also available online and canbe used as MPTs.
One of them is a collectionof pamphlets of the Jehova?s Witnesses, some ofwhich are available for over 250 languages.In order to test our methods on a variety oflanguages, we collected a number of pamphletsfrom the Watchtower website http://www.watchtower.org) together with their trans-lational equivalents for 146 languages in total.The texts needed some preprocessing to removeHTML markup, and they were aligned with re-spect to the paragraphs according to the HTMLmarkup.
We extracted all paragraphs which con-sisted of only one sentence in the English ver-sion and contained exactly one English questionword (how, who, where, what, why, whom, whose,when, which) and a question mark at the end.From these we manually excluded all sentenceswhere the ?question word?
is used with a differ-ent function (e.g., where who is a relative pronounrather than a question word).
In the end we wereleft with 252 questions in the English version andthe corresponding sentences in the 145 other lan-guages.
Note that an English interrogative sen-tence is not necessarily translated as a questionin each other language (e.g., the English questionwhat is the truth about God?
is simply translatedinto German as die Wahrheit u?ber Gott ?the truth8http://www.isi.edu/natural-language/download/hansard/9http://opus.lingfil.uu.se10http://www.statmt.org/europarl/11http://nl.ijs.si/ME/58about God?).
However, such translations appearto be exceptions.5 Experiments5.1 Global comparison of Indo-EuropeanAs a first step to show that our method yieldspromising results we ran the method for the 27Indo-European languages in our sample in orderto see what kind of global language similarityarises when using the present approach.
In ourprocedure, each sentence is separated into variousmultilingual alignments.
Because the structuresof languages are different, not each alignment willspan across all languages.
Most alignments willbe ?sparse?, i.e., they will only include words froma subset of all languages included.
In total, weobtained 6, 660 alignments (i.e., 26.4 alignmentsper sentence on average), with each alignment in-cluding on average 9.36 words.
The number ofalignments per sentence turns out to be linearlyrelated to the average number of words per sen-tence, as shown in Fig.
1.
A linear interpolationresults in a slope of 2.85, i.e., there are about threetimes as many alignments per sentence as the av-erage number of words.
We expect that this slopedepends on the number of languages that are in-cluded in the analysis: the more languages, thesteeper the slope.5 10 151020304050average sentence length in wordsnumber of alignments persentenceFigure 1: Linear relation between the average numberof words per sentence and number of alignments persentenceWe use the LL matrix as the similarity matrixfor languages including all 6, 660 alignments.
Foreach language pair this matrix contains the num-ber of times words from both languages are at-tested in the same alignment.
This similarity ma-trix is converted into a distance matrix by sub-tracting the similarity value from the highest valuethat occurs in the matrix:LLdist = max(LL)?
LLThis distance matrixLLdist is transformed intoa NeighborNet visualization for an inspection ofthe structures that are latent in the distance ma-trix.
The NeighborNet in Fig.
2 reveals an ap-proximate grouping of languages according to themajor language families, the Germanic family onthe right, the Romance family on the top and theSlavic family at the bottom.
Note that the soleCeltic language in our sample, Welsh, is includedinside the Germanic languages, closest to English.This might be caused by horizontal influence fromEnglish on Welsh.
Further, the only Baltic lan-guage in our sample, Lithuanian, is grouped withthe Slavic languages (which is phylogeneticallyexpected behavior in line with Gray and Atkin-son (2003)), though note that it is grouped par-ticularly close to Russian and Polish, which sug-gests more recent horizontal transfer.
Interest-ingly, the separate languages Albanian and Greekroughly group together with two languages fromthe other families: Romanian (Romance) and Bul-garian (Slavic).
This result is not in line with theirphylogenetic relatedness but rather reflects a con-tact situation in which all four languages are partof the Balkan Sprachbund.Although the NeighborNet visualization ex-hibits certain outcomes that do not correspond tothe attested genealogical relationship of the lan-guages, the method still fares pretty well basedon a visual inspection of the resulting Neighbor-Net.
In the divergent cases, the groupings can beexplained by the fact that the languages are in-fluenced by the surrounding languages (as is mostclear for the Balkan languages) through direct lan-guage contact.
As mentioned before, a similarproblem also exists when using word lists to in-fer phylogenetic trees when loanwords introducenoise into the calculations and thus lead to a closerrelationship of languages than is genealogicallytenable.
However, in the case of our alignments59AfrikaansEnglishWelshGermanIcelandicLithuanianPolishRussianUkrainianCzechSlovakSlovenianCroatianSerbianAlbanianGreekBulgarianRomanianPortugueseSpanishCatalanFrenchItalian DanishNorwegianSwedishDutch1000000.0Figure 2: NeighborNet (created with SplitsTree, Huson and Bryant (2006)) of all Indo-European languages inthe samplethe influence of language contact is not related toloanwords but to the borrowing of similar con-structions or structural features.
In the Balkancase, linguists have noted over one hundred suchshared structural features, among them the lossof the infinitive, syncretism of dative and geni-tive case and postposed articles (cf.
Joseph (1992)and references therein).
These features are partic-ularly prone to lead to a higher similarity in ourapproach where the alignment of words withinsentences is sensitive to the fact that certain wordforms are identical or different even though theexact form of the word is not relevant.5.2 Typology of PERSON interrogativesA second experiment we conducted involved acloser study of just a few questions in the data athand to obtain a better impression of the resultsof the alignment procedure.
For this experiment,we took the same 252 questions for a worldwidesample of 50 languages.
After running the wholeprocedure, we selected just the six sentences inthe sample that were formulated in English with awho interrogative, i.e., questions as to the personwho did something.
The English sentences are thefollowing:I Who will be resurrected?II Who will rule with Jesus?III Who created all living things?IV Who are god?s true worshipers on earth to-day?V Who is Jesus Christ?VI Who is Michael the Archangel?We expected to be able to find all translationsof English who in the alignments.
Interestingly,this is not what happened.
The six alignments thatcomprised the English who only included wordsin 23 to 30 other languages in the sample, so weare clearly not finding all translations of who.
Byusing a clustering on AAstatistical we were ableto find seven more alignments that appear to behighly similar to the six alignments including En-glish who.
Together, these 13 alignments includedwords for almost all languages in the six sentences(on average 47.7 words for each sentence).
Wecomputed a language similarity LL only on thebasis of these 13 alignments, which represents atypology of the structure of PERSON interrog-atives.
This typology clearly separates into two60clusters of languages, two ?types?
so to speak, ascan be seen in Fig.
3.Investigating the reason for these two types, itturns out that the languages in the right cluster ofFig.
3 consistently separate the six sentences intotwo groups.
The first, second, and fourth sen-tence are differently marked than the third, fifthand sixth sentence.
For example, Finnish usesketka?
vs. kuka and Spanish quie?nes vs. quie?n.These are both oppositions in number, suggestingthat all languages in the right cluster of Fig.
3 dis-tinguish between a singular and a plural form ofwho.
Interpreting the meaning of the English sen-tences quoted above, this distinction makes com-plete sense.
The Ewe form amekawoe in examplevi.
(see Section 3) contains the plural marker -wo,which distinguishes it from the singular form andindeed correctly clusters together with quie?nes inthe alignment cluster 5.This example shows that it is possible to useparallel texts to derive a typology of languages fora highly specific characteristic.6 Conclusion and Future WorkOne major problem with using our approach forphylogentic reconstruction is the influence of lan-guage contact.
Traits of the languages which arenot inherited from a common proto-language butare transmitted through contact situations lead tonoise in the similarity matrix which does not re-flect a genealogical signal.
However, other meth-ods also suffer from the shortcoming that lan-guage contact cannot be automatically subtractedfrom the comparison of languages without man-ual input (such as manually created cognate lists).With translational equivalents, a further problemfor the present approach is the influence of trans-lationese on the results.
If one version in a lan-guage is a direct translation of another language,the structural similarity might get a higher scoredue to the fact that constructions will be literallytranslated which otherwise would be expresseddifferently in that language.The experiments that have been presented inthis paper are only a first step.
However, we firmlybelieve that a multilingual alignment of words ismore appropriate for a large-scale comparison oflanguages than an iterative bilingual alignment.Yet so far we do not have the appropriate evalu-ation method to prove this.
We therefore plan toinclude a validation scheme in order to test howmuch can be gained from the simultaneous analy-sis of more than two languages.
Apart from this,we intend to improve the alignment method itselfby integrating techniques from statistical align-ment models, like adding morpheme separation orphrase structures into the analysis.Another central problem for the further devel-opment of this method is the selection of align-ments for the language comparison.
As our sec-ond experiment showed, just starting from a se-lection of English words will not automaticallygenerate the corresponding words in the other lan-guages.
It is possible to use the AA matrices tosearch for further similar alignments, but this pro-cedure is not yet formalized enough to automati-cally produce language classification for selectedlinguistic domains (like for the PERSON interrog-atives in our experiment).
When this step is betterunderstood, we will be able to automatically gen-erate typological parameters for a large numberof the world?s languages, and thus easily producemore data on which to base future language com-parison.AcknowledgementsThis work has been funded by the DFG project?Algorithmic corpus-based approaches to typo-logical comparison?.
We are grateful to fouranonymous reviewers for their valuable com-ments and suggestions.ReferencesPeter F. Brown, John Cocke, Stephen A. Della-Pietra,Vincent J. Della-Pietra, Frederick Jelinek, Robert L.Mercer, and Paul S. Roossin.
1988.
A statisticalapproach to language translation.
In Proceedingsof the 12th International Conference on Computa-tional Linguistics (COLING-88), pages 71?76.William Croft.
2000.
Explaining Language Change:An Evolutionary Approach.
Harlow: Longman.Michael Cysouw and Bernhard Wa?lchli.
2007.
Paral-lel texts: using translational equivalents in linguis-tic typology.
Sprachtypologie und Universalien-forschung STUF, 60(2):95?99.Michael Dunn, Angela Terrill, Ger Reesink, R. A. Fo-ley, and Steve C. Levinson.
2005.
Structural phylo-genetics and the reconstruction of ancient languagehistory.
Science, 309(5743):2072?5, 9.Brendan J. Frey and Delbert Dueck.
2007.
Clusteringby passing messages between data points.
Science,315:972?976.61AlbanianRarotonganMalteseMalagasyLithuanianIlokoCroatianChichewaBulgarianGermanPonapeanPapiamento(Aruba)Papiamento(Cura?ao)DutchNiueanMiskitoIndonesianItalianKiribatiFrenchEnglishDanishHaitianCreoleCatalanAfrikaansAtesoFijianTuvaluanSwedishGunaHungarianQuechua (Ancash)KwanyamaTumbukaChin(Hakha)TswanaSpanishNdongaNyanekaGreekFinnishEweDangmeChitongaShonaBicolXitshwaAcholiLugandaSepedi1015202530Cluster Dendrogramhclust (*, "complete")as.dist(max(LL) - LL)HeightFigure 3: Hierarchical cluster using Ward?s minimum variance method (created with R, R Development CoreTeam (2010)) depicting a typology of languages according to the structure of their PERSON interrogativesRussell D. Gray and Quentin D. Atkinson.
2003.Language-tree divergence times support the Ana-tolian theory of Indo-European origin.
Nature,426:435?439.Daniel H. Huson and David Bryant.
2006.
Applica-tion of phylogenetic networks in evolutionary stud-ies.
Molecular Biology and Evolution, 23(2):254?267.Brian D. Joseph.
1992.
The Balkan languages.
InWilliam Bright, editor, International Encyclopediaof Linguistics, pages 153?155.
Oxford: Oxford Uni-versity Press.Philipp Koehn.
2010.
Statistical Machine Translation.Cambridge University Press.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational Linguistics, 29(1):19?51.Mark Pagel.
2009.
Human language as a culturallytransmitted replicator.
Nature Reviews Genetics,10:405?415.Uwe Quasthoff and Christian Wolff.
2002.
Thepoisson collocation measure and its applications.In Proceedings of the 2nd International Workshopon Computational Approaches to Collocations, Vi-enna, Austria.R Development Core Team, 2010.
R: A languageand environment for statistical computing.
Wien:R Foundation for Statistical Computing.Michel Simard.
1999.
Text-translation alignment:Three languages are better than two.
In Proceed-ings of EMNLP/VLC-99, pages 2?11.Michel Simard.
2000.
Text-translation alignment:Aligning three or more versions of a text.
In JeanVe?ronis, editor, Parallel Text Processing: Align-ment and Use of Translation Corpora, pages 49?67.Dordrecht: Kluwer Academic Publishers.Lydia Steiner, Peter F. Stadler, and Michael Cysouw.2011.
A pipeline for computational historicallinguistics.
Language Dynamics and Change,1(1):89?127.Jo?rg Tiedemann.
2011.
Bitext Alignment.
Morgan &Claypool Publishers.Bernhard Wa?lchli.
2011.
Quantifying inner form: Astudy in morphosemantics.
Arbeitspapiere.
Bern:Institut fu?r Sprachwissenschaft.62
