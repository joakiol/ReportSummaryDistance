Software Re-Use  and Evolut ion in Text Generat ion Appl icat ions $Karen  Kuk ich*  and Rebecca  Passonneau *t and Kath leen  McKeown t andDragomir  Radev  t and Vas i le ios  Hatz ivass i log lou  t and Hongyan J ing  t*Bellcore445 South StreetMorr istown, NJ 07960, USA{kukich, beck}@bellcore, comtDepar tment  of Computer  Science450 Computer  Science Bui ldingCo lumbia  UniversityNew York, NY 10027, USA{becky, kathy, radev, vh, hjing}Ocs, columbia, eduAbst rac t  1 In t roduct ionA practical goal for natural anguage textgeneration research is to converge on a sep-aration of functions into modules that canbe independently re-used.
This paper ad-dresses i sues related to software re-use andevolution in text generation systems.
Wedescribe the benefits we obtained by adapt-ing and generalizing the generation mod-ules and techniques we used for the succes-sive development of three distinct ext gen-eration applications, PLANDoc, FLOW-Doc, and ZEDDoc.
We suggest that de-sign principles uch as the use of a com-mon, modular pipeline architecture, a con-sistent and general data representation for-*nat, and domain-independent algorithmsfor generation subtasks, together with com-ponent re-use and adaptation, facilitateboth application development and researchin the field.
In our experience, these princi-ples led to significant reductions in develop-ment time for successive applications, fromthree years to one year to six months, re-spectively.
They also enabled us to isolatedomain-specific knowledge and devise re-usable, domain-independent algorithms forgeneration tasks such as ontological gener-alization and discourse structuring.tThe authors wish to acknowledge Jacques Ftobin,James Shaw, Jong Lira, and Larry Lefkowitz, who alsoplayed essential roles in the design and development ofPLANDoc and FLOWDOC.Recent technological dvances, such as the wide-spread use of the World Wide Web and ready accessto a multitude of extensive large-scale databases,have created novel opportunities for practical textgeneration applications.
At the same time, to takefull advantage of these opportunities, text genera-tion systems must be easily adaptable to new do-mains, changing data formats, and distinct underly-ing ontologies.One crucial factor contributing to the generaliza-tion and subsequent practical and commercial via-bility of text generation systems is the adaptationand re-use of text generation modules and the de-velopment of re-usable tools and techniques.
Inthis paper, we focus on the lessons learned dur-ing the successive development of three text gen-eration systems at Bellcore: PLANDoc (McKeownet al, 1994) summarizes execution traces of an ex-pert system for telephone network capacity expan-sion analysis; FLOwDoc (Passonneau et al, 1996)provides ummaries of the most important eventsin flow diagrams constructed uring business re-engineering; and ZEDDoc (Passonnean et al, 1997)produces ummaries of activity for a user-specifiedset of advertisements within a user-specified time pe-riod from logs of WWW page hits.We built FLowDoc and ZEDDoc by adaptingcomponents of the PLANDoc system.
The trans-fer of the original PLANDoc modules to new do-mains led to the replacement of some hard-codedrules and ontological knowledge with more general,domain-independent components.
This encapsula-tion, or "plug-and-play" feature, enabled the trans-fer of many of FLowDoc's modules to ZEDDoc13with minimal alterations.
As a result, developmenttime was significantly reduced --  from three yearsfor PLANDoc to one year for FLOwDoc to sixmonths for ZEDDoc.In the remainder of the paper, we provide back-ground information on the three systems and thenpresent and discuss four design principles that facili-tate the development of text generation systems andtheir portability to new domains and applications:?
A common, stable pipeline architecture thatsubdivides generation tasks (e.g., sentence plan-ning or lexical choice) into separate modules.?
A consistent and general data representationthat allows easy interfacing between generationmodules and between the text generator andexternal sources (e.g., relational databases).
* Domain-independent methods for performingeach generation subtask, that avoid hard-codedknowledge and rely instead on external, plug-and-play knowledge bases.?
Component re-use and adaptability from eachapplication to the next, with the aim of improv-ing generality and achieving the data indepen-dence goal described previously.2 BackgroundPLANDoc (McKeown et al, 1994), the first ma-jor text generation system developed at Bellcore, isan enhancement to Bellcore's LEIS-PLAN TM net-work planning product.
Human engineers use LEIS-PLAN to do network capacity expansion studies,during which they explore alternative scenarios toarrive at an optimal configuration ofequipment thatmeets demands for new services while minimizingcosts.
PLANDoc produces textual summaries ofthe scenarios explored by engineers.
It transformslengthy execution traces into human-readable sum-maries by making heavy use of conjunction, ellip-sis, and paraphrasing.
It also allows engineers tointersperse their own comments and justificationswhile using the tool.
PLANDoc is currently inwidespread use throughout the Southwestern BellCorporation and has been requested by at least twoother regional Bell companies.
As an example, Fig-ure 1 shows a fragment of the input to PLANDocfor a particular study, PLANDoc's representationof the same information in canonical form, and theresulting enerated sentence.FLowDoc (Passonneau et al, 1996) takes as in-put flow diagrams representing the structure and op-erations of a business unit, either as it is currentlyRUNID fiberall FIBER6119/93 act yesBFA 1301 2 1995FA 1201 2 1995FA 1401 2 1995FA 1501 2 1995ANF C0 1103 2 1995 48ANF 1201 1301 2 1995 24ANF 1401 1501 2 1995 24END 856.0 670.2(a) Fragment of LEIS-PLAN's executiontrace~br a particular plan.
( (cat domain_message)(admin ((msg-num 19)(runid FIBERALL)(prev-runid ALLDLC)(status act)(saved yes) ) )(class refinement)(ref-type FIBER)(action ACTIVATION)(csa-site 1301)(date ((year 1995) (quarter 2))))(b) PLANDoc 's  representation of (a) incanonical form.RUN-ID FIBERALL demanded that PLANactivate fiber for CSAs 1201, 1301,1401 and 1501 in 1998 Q2.
(c) Sentence generated by PLANDocfrom the data in (b) and three othersimilar messages.Figure h Sample Input, Canonical Representation,and Output of PLANDoc.operating or after a proposed re-organization.
LikePLANDoc, it interfaces with another tool devel-oped at Bellcore, SHowBIz, which maintains thegraphical representation a d allows the explorationof possible alternatives by the re-engineering con-sultant.
The diagrams resulting from re-engineeringanalysis are quite complex, with numerous nodes an-notated with a large number of attributes.
FLOW-DOC identifies the core components, participants,and actions of each flow diagram and produces ashort textual summary.
Figure 2 shows an exampleinput flow diagram, the representation f a samplenode in that diagram as presented to FLowDoc bySHOwBIz, FLOWDOC's description of the same in-14AM~OdI~ Cora I~llr l lnce Ml~l l l ldlo~eotAmt(a) Input flow diagram.
(make-flownode 26 'thought-task: node-posit ion 32899435: who ' SME: does_what "review": to_whom_or_what' dr aft _do cument _in_MS_Wor d_f ormat )(b) Input representation f a sample node.
( (cat domain_msg)(msg_id 14)(msg-class salient-task)(workf low_id 000931)(activity-class thought_activity)(does_what review)(to_whom_or_what ms_word_doc)(count 3) )(c) FLowDoc's canonical representation ofthe information in (b), aggregated withinformation from two other similar nodes.The most frequent tasks in this workflow are those of creating,reviewing aIld saving documents.
(d) Generated sentence from the canonical message in (c) and from similarmessages corresponding to other frequent asks in the input diagram.Figure 2: Sample Input Flow Diagram, Input Description of a Single Node, Canonical Representation f aSet of Nodes after Aggregation, and Corresponding Generated Sentence for FLowDoc.15select host, count(host)from zeddoc_viewwhere (date_time between '01-JAN-95 ' and '31-DEC-96')(a) Fragment of SQL  query automatically generated by ZEDDoc 'sdatabase query subsystem.HOST COUNT(HOST)santos.doc.ic.ac.uk 12896ed78a.extern.ucsd.edu 7thor.dai.ed.ac.uk 7hvlassar.port.net 6vip-b.enel.ucalgary.ca 4baugi.ifi.uio.no 3pm2-O5.sundial.net 3194.80.129.254 2abest206.abest.com 2. .
.
(b) Part of the database output for thequery in (a).
((msg-class user-domain)(santos.doc.ic.ac.uk 12.0)(896edZ8a.extern.ucsd.edu 7.0)(thor.dai.ed.ac.uk 7.0)(hvlassar.port.net 6.0)(vip-b.enel.ucalgary.ca 4.0)(baugi.ifi.uio.no 3.0)(pm2-05.stmdial.net 3.0)(other 2.0)(abest206.abest.com 2.0).
.
.
)(c) ZEDDoc 's  canonical representationof the information in (b).For the ads of interest, the most frequent Internet user domains were EuropeanInternet domains at 28 percent and U.8.
network domains at 23 percent.
(d) One of the sentences generated by ZEDDoc  from the full informationabout network hosts, which is partially shown in (c).Figure 3: Automatically Generated SQL Query, Partial Database Output, Corresponding Canonical Repre-sentation, and one of the Corresponding Sentences Produced by ZEDDoc .formation aggregated over several similar nodes inthe diagram, and the sentence generated to expressthis information.ZEDDoc  summarizes the underlying ZED appli-cation's WWW activity.
ZED manages a databaseof advertisement images to satisfy Web advertisingcontracts.
1 It selects ads to display in predefinedslots in a manner that optimizes the satisfaction ofthe advertising contracts.
Whenever ZED displaysa Web page, it determines what ads to display andcreates database ntries for each displayed ad.
ZED-Doc  integrates a browser, the summary generator,and ZED's Oracle TM database of WWW transac-tions in a client-server a chitecture.
By accessing thetransaction database, ZEDDoc  can produce shortsummaries of ad activity within a user-specified timeframe for a user-specified set of ads.
Summaries con-tain, for example, demographic generalizations per-l Zed has evolved into a product, the Adapt/XAdvertiser TM .raining to potentially large numbers of hits.
An ex-ample of ZEDDoc 's  input, internal representation,and output is shown in Figure 3.3 A Common Arch i tec tureWhile PLANDoc ,  FLOwDoc,  and ZEDDoC allshare a common foundation, they embody distinctlydifferent ext generation applications.
However, weaimed during the design of both FLOWDOC andZEDDoc  to utilize as much of PLANDoc 's  archi-tecture as possible, often adapting and generalizingmodules that were originally written with only thePLANDoc  system in mind.All three systems employ a modular pipeline ar-chitecture.
A pipeline architecture is one that sepa-rates the functions involved in text generation, suchas content planning, discourse organization, lexical-ization, and syntactic realization, into distinct mod-ules that operate in sequence.
Modular pipeline ar-chitectures have a long history of use in text gen-16eration systems (Kukich, 1983a; McKeown, 1985;McDonald and Pustejovsky, 1986; Reiter, 1994), al-though recent work argues for the need for interac-tion between modules (Danlos, 1987; Rubinoff, 1992;McKeown et al, 1993).
The most powerful argu-ment for using pipeline architectures is the poten-tial benefit of re-using individual modules for subse-quent applications.
However, with the exception ofsurface realization modules uch as FUF/SURGE(Elhadad, 1992; Robin, 1994), actual code re-use hasbeen minimal due to the lack of agreement about heorder and grouping of subprocesses into modules.In PLANDoc, FLowDoc, and ZEDDoc, weutilize the following main modules, in the orderlisted below:?
Message Generator:  The message generatortranscribes the raw data from LEIS-PLAN ex-ecution traces, SHowBIz, or ZED transactionlogs into instances of message classes.
We re-fer to simple collections of (possibly nested)attribute-value pairs pertaining to a single eventas messages.
Message classes are domain-specific (e.g., there are 30 of them in PLAN-Doc, 13 in FLowDoc, and 6 in ZEDDoc),but they all share the same representation asthe basic content unit.
In all three systems, gen-eralization must occur at this level in order tocreate semantically concise messages from rela-tively large amounts of input data.?
Ontologizer: In PLANDoc, a pipelined onto-iogizer enriches messages with domain-specificknowledge that is not explicitly present in theinput.
\[n FLOWDoC and ZEDDoc, semanticenrichment is done at various tages by consult-ing external ontologies.?
Discourse Organizer: The discourse orga-nizer performs all the remaining functions priorto lexicalization and surface generation 2.
Threesub-modules apply general discourse coherenceconstraints at the levels of discourse, sentence,and sentence constituent.
The first module per-forms aggregation and text linearization opera-tions using an ontology of rhetorical predicatesderived from Hobbs (1985) and Polanyi (1988).Linear order and prominence of the subcon-stituents are then determined, followed by con-straints on subconstituents that affect lexicalchoice (e.g., centering and informational con-straints, as in (Passonneau, 1996)).2|n previous work we referred to this module as theSentence Planner (Passonneau et al, 1996).Lexicalizer: The lexicalizer maps message at-tributes into thematic/case roles, and choosesappropriate content (open-class) words for tilevalues of these attributes.Surface Generator: This module maps the-matic roles into syntactic roles and builds syn-tactic constituents, chooses function (closed-class) words, ensures grammatical greement,and linearizes to produce the final surface sen-tence.Our message generator modules are largelydomain-specific, and we have made major changes tothem while porting them to new applications.
Evenso, their ontological generalization technique, whichproduces emantically concise descriptions from fre-quency data, is domain-independent.
Our finalsurface generation module is completely domain-independent; it employs the FUF/SURGE (E1-hadad, 1991; Robin, 1994) text generation tools,and was re-used in all three systems with virtuallyno modifications.
Modules near the middle of thepipeline provide the most interesting examples ofcode that can be re-used if it is general enough andrelies on plug-and-play knowledge bases rather thanhard-coded ata.
We return to this issue of codere-use and of the evolution of our modules to ac-commodate it in Section 5.4 A Common Representat ionAll three systems employ a consistent, standardizedattribute-value data format that persists from eachmodule to the next.
Examples of this internal dataformat were shown in Figures 1-3.
This fbrmatis used for representing and processing conceptual-semantic, lexical-semantic, syntactic, and other lin-guistic information.
Its persistent use facilitatesinter-module communication and module indepen-dence, hence re-usability.
Furthermore, it does notrestrict he kinds of information that can be repre-sented, and it is common to many non-NLP com-putational systems and languages (e.g., relationaldatabases), thus making it easier for text generationsystems to interface with existing applications.The input to each of our three systems came fromvery different sources, some closer than others toattribute-value message format.
PLANDoc's inputcame from n-tuple records representing program ex-ecution traces, so it required a filter to transform itinto messages.
FLOwDOC'S input came from ASCIIrepresentations of nodes and links in work flow di-agrams which were already essentially in attribute-value format.
ZEDDoc's input, representing Web17activity data, had been stored in an Oracle TM rela-tional database by its application, so it too requiredlittle transformation.5 Arch i tec tura l  Evo lu t ionAs discussed earlier, a practical goal for text gen-eration research is to converge on a separation offunctions into modules that can be independentlyre-used.
Towards this goal, we have generalized andrefined our architecture with each successive appli-cation.
In fact, we significantly adapted our PLAN-DOC architecture for use in FLOwDOC, but we wereable to re-use the FLowDoc  architecture and muchof its code in ZEDDoc .
Figure 4 contrasts the ar-chitecture of PLANDoc  with those of FLOwDocand ZEDDoc .
(a) Overall architecture for PLANDoc .
(b) Overall architecture for FLOwDoc and ZEDDoc .Figure 4: Contrasting the Architecture of the ThreeText Generation Systems.The obvious architectural change from PLAN-Doc  to FLowDoc  (and ZEDDoc)  is the extrac-tion of ontological knowledge from the process-ing pipeline.
Ontological knowledge is necessarilydomain-specific, so this modification allowed us toimplement significantly more general Message Gen-eration and Discourse Organization modules anda somewhat more general Lexicalizati6n module.These more general modules rely on external knowl-edge bases to supply the domain-specific informationthat was previously embedded in the code.
Thus, wecan replace the external knowledge base when mov-ing to a new domain or application without havingto modify the module itself.
One of our future re-search goals is to further extract domain-specific lex-ical knowledge and further generalize the lexicalizermodule (.ling et al, 1997).What is not so obvious from Figure 4 are the con-sistencies and shifts in function among the modules.In fact, the functions of the Lexicalization and Sur-face Generation modules remained constant acrossall three systems.
But the functions of the firstthree modules hifted significantly from PLANDocto FLOwDOC.
In particular, the function of messageaggregation lay exclusively in the Discourse Organi-zation module in PLANDoc  (Shaw, 1995), whereasaggregation functions are executed in both the Mes-sage Generation and Discourse Organization mod-ules in FLOWDOC.Because the development of domain-independent,plug-and-play ontology modules is one of the majorfeatures that affected these shifts in function, andbecause such modules greatly increase the portabil-ity of the system, we devote the next section to amore detailed description of the function of ontolog-ical generalization.6 Ontological GeneralizationOntological generalization refers to the problem ofcomposing, with the help of an ontology, a concisedescription for a multi-set of concepts.
For example,FLOWDOC's output sentence shown in Figure 2The most frequent tasks in thisworkflow are those of creating,reviewing and saving documents.concisely describes a multi-set of ten specific tasknodes in the flow diagram by locating superclassconcepts in the ontology that encompass the specificpredicates and objects of the task nodes.
Our aimis to compose a description that is concise withoutsacrificing much in accuracy.While PLANDoc  made extensive use of conjunc-tion, ellipsis, and paraphrasing to produce a con-cise summary, ontological relations were not heavilyused.
For FLowDoc  we implemented a more gen-eral, domain-independent solution.
We were ableto re-use this module with minor modifications inZEDDoc ,  after replacing the ontological knowledgebase.Our ontological generalization algorithm works asfollows.
Given a set Co = {01,02,... ,ON} of ob-jects of a given predicate-class and an associatedlist (c l ,c2, .
.
.
,CN) of their occurrence counts, wecompute an optimal set of concept generalizations{G1, G2,... ,GM} such that each generalization re-places a subset of Co while maintaining a reasonabletrade-off between the accuracy, specificity, and ver-bosity of the resulting description.We consider as candidate concept generalizationsthe actual members of Co and all the concepts inthe domain ontology that subsume one or more ofthem.
Each such candidate concept generalization18is evaluated on its suitability to replace a given sub-set of Co using a weighted sum formula, trading-offalong two antagonistic dimensions:?
Coverage,  measuring how many of the objectsin the subset (proportionally weighted accord-ing to their occurrence counts ci) are actuallysubsumed by the candidate generalization.?
Speci f ic i ty,  defined as the average semanticdistance between each element of the subset andthe candidate generalization.The semantic distance currently used is simply thenumber of levels between each object and the gen-eralization in the domain ontology.
It could be eas-ily changed to an information-based distance, e.g.,along the lines of the metrics proposed in (Resnik,1995), who measures emantic distance between twoconcepts as a function of the lexical probabilities oftheir c.ommon superclasses.To compute the optimal set of generalizations, thealgorithm starts by generating all possible partitionsof the given set of objects 3, then locates the bestsingle-term description for each subset in the par-tition by applying the procedure outlined above toeach candidate generalization, and finally combinesthe single-term description scores in one number.The final score is adjusted by two additional penal-ties:?
A verbosity penalty, penalizing descriptionswith more than one generalization (exponen-tially more as the number of terms in the de-scription increases).?
A heterogeneity penalty, for descriptions thatare locally optimal but significantly lower in theontology (more specific) than the global speci-ficity level.The global specificity level indicates the appropri-ate overall level of detail.
It is computed by ap-plying the above ontological generalization proce-dure to the collection of all the objects appearingin the input graph, across all actions.
It implementsthe idea of "basic level" descriptions from (Rosch,1978) for the application domain modeled by thework flow.
For example, while processing a flow di-agram which covers documents of many types, ouralgorithm will have a bias in favor of the generic term"Document" rather the too-specific term "Draft doc-ument in SGML format"; a trade-off between the~With some performance-imposed constraints, incethe number of possible partitions grows exponentiallywith the number of objects and the number of subsetsin the partition.heterogeneity penalty and other components of thedescription score occurs if the latter term looks lo-cally optimal.The same generalization method for sets of(concept, occurrence count) pairs was applied inZEDDoc ,  but instead of actions or graph compo-nents, the concepts were Internet addresses or ZEDpage types.
ZED requires emantic types to be as-signed to WWW pages and ads to help determinewhich ads from its database can be inserted in pre-defined ad slots.
When a ZEDDOc user requests asummary of activity pertaining to a particular setof ads for a given time period, the raw data con-sists in part of frequency lists indicating how manyusers from a given Internet node saw the relevantads and how many of the displayed pages corre-sponded to particular semantic types.
One minorchange for ZEDDoc  was the replacement of prede-fined absolute frequency thresholds for determiningthe salience of items with relative ones.To summarize the Internet domain or page typedata, ZEDDoc  relies on plug-and-play ontologies.Specialization subtrees rooted at certain concepts,e.g., the Internet domain, can be replaced so longas at least one lexicalization is provided for everyconcept.
Our ontology for the Internet domain com-bined world knowledge with the implicit hierarchicalstructure of domain names.
For example, throughhand analysis of WWW logs we created a geograph-ical categorization of university nodes, on the as-sumption that such demographic nformation is im-portant o advertisers.7 Component Re-Use RevisitedThe major theme throughout his paper has beenhow we re-used components from our original Plan-Doc system to implement the subsequent FLOwDOcand ZEDDoc  systems, significantly cutting devel-opment ime.
In this section, we summarize our ex-periences regarding code re-use.?
The message generator offers limited possibil-ities for reuse becanse it directly interfaces toan application-specific external source.
Limitedcode sharing w~ possible however, because ofour choice of a common representation formatfor all three systems.?
As noted briefly in Section 3, the FLowDocarchitecture had distinct modules pertaining tothe three levels of discourse, sentence, and sen-tence constituent.
Retaining this more generalarchitecture in ZEDDoc  proved useful withrespect to one additional required functional-ity, namely the ability to produce plain text or19HTML output.
The three levels of discourse or-ganization were exploited in ZEDDoc primar-ily to distinguish between HTML commandsthat pertain to the overall layout (e.g., para-graph divisions) versus those that pertain tosentence-internal features (e.g., fonts).?
At the lexicalization level, we achieved onlypartial generalization of the lexicalizer's code.Given the state of the art in natural lan-glmge generation, the lexicon remains neces-sarily domain-specific.
However, we are ex-ploring ways to remove domain-specific lexicalknowledge from the system pipeline, as we didwith domain-specific ontological and discourseknowledge.We are building a large-scale general lexicon forgeneration, which provides yntactic arid partialsemantic knowledge and can be used to selectthe generated sentence structure and possibleparaphrases (Jing et al, 1997).
By using thisgeneral lexicon together with a smaller domain-specific lexicon or with information extractedfrom a corpus from the application domain, weexpect o significantly simplify the developmentof the lexicalization module, improving its reli-ability and portability.?
At the final surface generation level, we tookadvantage of prior progress in component s an-dardization and used FUF (Functional Unifica-tion Formalism) and its corresponding extensiveEnglish surface grammar SURGE.
As a result,the surface generation module was ported un-changed to the other systems.8 Conc lus ionBy teasing apart some of PLANDoc's  modulesand partially re-configuring others, we were able toport our text generation system to two completelynew domains, those of flow chart and WWW ac-tivity summarization.
In the process, ~ve deviseddomain-independent message aggregation and dis-course restructuring modules for FLowDoc thatwe re-used intact for ZEDDoc.
Indeed, we be-lieve that our ontological generalization algorithm(i.e., message aggregation guided by quantitativeformulas over plug-and-play ontologies) is generallydomain-independent.
We are exploring ways to in-troduce probability estimates in our weighting func-tions for message aggregation, linking the static on-tology with corpus-observable variations in conceptuse and coverage.Re-usable tools and techniques can provide lever-age for building practical text generation applica-tions.
They can also facilitate research leading to in-creasingly more general and more useful tools.
Thishas been our experience in implementing tile threetext generation systems covered in this paper whichare all based on a common architecture, a com-mon representation format, and a common, evolvingfoundation of text generation tools.At least three other factors that are critical topractical and commercial success should be men-tioned though we cannot discuss them here.
Twoof them, i) extensive user-needs analysis and feed-back and ii) target corpus compilation and analy-sis, are highly correlated with the relative successof each of our systems.
These two factors are dis-cussed in more detail in previous papers (Kukich etal., 1994; Kukich, 1983b).
A third, undocumentedfactor, the rigorous pre-release t sting of the systemunder conditions imilar to its deployment environ-ment, played a critical role in PLANDoc's  success.AcknowledgmentResearch on these projects at Columbia Universitywas supported by grants from Bellcore.Re ferencesLaurence Danlos.
1987.
The Linguistic Basis ofText Gene~ntion.
Studies in Natural LanguageProcessing.
Cambridge University Press, Cam-bridge, England.Michael Elhadad.
1991.
FUF user manual - -  ver-sion 5.0.
Technical Report CUCS-038-91, Depart-ment of Computer Science, Columbia University.Michael Elhadad.
1992.
Using Argumentation toControl Lexical Choice: A Functional Unification-Based Approach.
Ph.D. thesis, Department ofComputer Science, Columbia University.Jerry Hobbs.
1985.
On the coherence and structureof discourse.
Technical Report CSLI-85-37, Cen-ter for the Study of Language and Information,Stanford University.Hongyan Jing, Kathleen McKeown, and RebeccaPassonneau.
1997.
Building a rich large-scalelexical base for generation.
Technical ReportCUCS-016-97, Department of Computer Science,Columbia University.Karen Kukich, Kathleen McKeown, James Shaw,Jacques Robin, Jong Lim, Neal Morgan, and Jim20Phillips.
\[994.
User needs analysis and de-sign methodology for an automated ocumenta-tion generator.
In Antonio Zampolli, NicolettaCalzolari, and Martha Palmer, editors, CurrentIssues in Computational Linguistics: In Honourof Don Walker, pages 109-115.
Kluwer AcademicPress, Boston, Massachussets.Koran Kukich.
1983a.
Design and implementationof a knowledge-based text generator.
In Proceed-in.qs of the 21st Annual Meeting of the Associ-ation for Computational Linguistics, pages 145-150, Cambridge, Massachusetts, June.Karen Kukich.
1983b.
Knowledge-Based ReportGeneration: A Knowledge Engineering Approachto Natural Language Report Generation.
Ph.D.thesis, University of Pittsburgh.Da~d McDonald and James Pustejovsky.
1986.Description-directed natural anguage generation.In Proceedings of the 9th International Joint Con-ference on Artifieal Intelligence, pages 799-805,Los Angeles, California.Kathleen McKeown, Jacques Robin~ and MichaelTanenblatt.
1993.
Tailoring lexical choice to theuser's vocabulary in multimedia explanation gen-eration.
In Proceedings of the 31st Annual Meet-ing of the Association for Computational Linguis-tics, pages 226-234, Columbus, Ohio, June.Kathleen McKeown, Karen Kukich, and JamesShaw.
1994.
Practical issues in automatic docu-mentation generation.
In Proceedings of the 1994Applied Natural Langua9e Processing Conference,pages 7-14, Stuttgart, Germany, October.Kathleen McKeown.
1985.
The need for text gen-eration.
Technical Report CUCS-173-85, Depart-ment of" Computer Science, Columbia University.Rebecca Passonneau, Karen Kukich, Jacques Robin,Vasileios Hatzivassiloglou, Larry Lefkowitz, andHongyan Jing.
1996.
Generating summaries ofwork flow diagrams.
In Proceedings of the Interna-tional Conference on Natural Language Processingand Industrial Applications, pages 204-210, NewBrunswick, Canada, June.
University of Moncton.Rebecca Passonneau, Karen Kukich, Kathleen McK-eown, Dragomir Radev, and Hongyan Jing.
1997.Summarizing web traffic: A portability exercise.Technical Report CUCS-009-97, Department ofComputer Science, Columbia University.Rebecca Passonneau.
1.996.
Using centering to re-lax Gricean informational constraints on discourseanaphoric noun phrases.
Language and Speech,39(2-3):229-265, April-September.
Special dou-ble issue on Discourse and Syntax, edited by JudyDelin and Jon Oberlander.Livya Polanyi.
1988.
A formal model of discoursestructure.
Journal of Pragmaties, 12:601-638.Ehud Reiter.
1994.
Has a consensus NL generationarchitecture appeared, and is it psycholing,~listi-caily plausible?
In Proceedings of the 1994 Inter-national Natural Language Generation Workshop,pages 163-170, Kennebunkport, Maine.Philip Resnik.
1995.
Using information con-tent to evaluate semantic similarity in a taxon-omy.
In Proceedings of the Fourteenth Interna-tional Joint Conference on Artificial Intelligence(IJCAI-95), volume 1, pages 448-453, Montr6al,Quebec, Canada, August.
Morgan Kaufmann, SanMateo, California.Jacques Robin.
1994.
Revision-Based Generation ofNatural Language Summaries Providing HistoricalBackground: Corpus-Based Analysis, Design, Im-plementation, and Evaluation.
Ph.D. thesis, De-partment of Computer Science, Columbia Univer-sity.
Also Technical Report CU-CS-034-94.Eleanor Rosch.
1978.
Principles of categorization.In Eleanor Roschand and Barbara B. Lloyd, edi-tors, Cognition and Categorization, pages 27-48.Lawrence Erlbaum Associates, Hillsdale, New Jer-sey.Robert Rubinoff.
1992.
A cooperative modelof strategy and tactics in generation.
InRobert Dale, Eduard Hovy, Dietmar RSesner, andOliviera Stock, editors, Aspects of Automated Nat-ural Language Generation.
Springer Verlag.
Pre-sented at the 6th International Workshop on Nat-ural Language Generation, Trento, Italy.James Shaw.
1995.
Conciseness through aggrega-tion in text generation.
In Proceedings of the 33rdAnnual Meeting of the Association for Computa-tional Linguistics (Student Session), pages 329-331, June.2122
