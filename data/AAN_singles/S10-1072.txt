Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 325?328,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsKUL: Recognition and Normalization of Temporal ExpressionsOleksandr Kolomiyets, Marie-Francine MoensDepartment of Computer ScienceKatholieke Universiteit Leuven{oleksandr.kolomiyets, sien.moens}@cs.kuleuven.beAbstractIn this paper we describe a system for therecognition and normalization of temporalexpressions (Task 13: TempEval-2, TaskA).
The recognition task is approached asa classification problem of sentence con-stituents and the normalization is imple-mented in a rule-based manner.
One of thesystem features is extending positive an-notations in the corpus by semanticallysimilar words automatically obtained froma large unannotated textual corpus.
Thebest results obtained by the system are0.85 and 0.84 for precision and recall re-spectively for recognition of temporal ex-pressions; the accuracy values of 0.91 and0.55 were obtained for the feature valuesTYPE and VAL respectively.1 IntroductionRecognition of temporal expressions1 is a task ofproper identification of phrases with temporalsemantics in running text.
After several evalua-tion campaigns targeted at temporal processingof text, such as MUC, ACE TERN and TempEv-al-1 (Verhagen et al, 2007), the recognition andnormalization task has been again newly reintro-duced in TempEval-2 (Pustejovsky & Verhagen,2009).
The task is defined as follows: determinethe extent of the time expressions; in addition,determine the value of the features TYPE for thetype of the temporal expression and its temporalvalue VAL.
In this paper we describe the KULsystem that has participated in this task.1Temporal expressions are sometimes referenced as timeexpressions and timexes.Architecturally, the system employs a pipe-lined information processing chain and imple-ments a number of machine learning classifiersfor extracting the necessary information for thetemporal value estimation.
The normalizationstep employs a number of hand-crafted vocabula-ries for tagging single elements of a temporalexpression and a rule-based system for estimat-ing the temporal value.
The performance of thesystem obtained the values of 0.85 and 0.84 forprecision and recall respectively for the recogni-tion of temporal expressions.
The accuracy forthe type and value is 0.91 and 0.55 respectively.The remainder of the paper is organized asfollows: Section 2 reports on the architecture ofthe system with single modules and describestheirs functions.
Section 3 presents the resultsand error analysis; the conclusions are providedin Section 4.2 System ArchitectureThe system is implemented in Java and follows apipelined method for information processing.Regarding the problems it solves, it can be splitin two sub-systems: recognition and normaliza-tion.2.1 Recognition of Temporal ExpressionsThis sub-system is employed for finding tempor-al expressions in the text.
It takes a sentence asinput and looks for temporal expressions in it.Pre-processing: At this step the input text un-dergoes syntactic analysis.
Sentence detection,tokenization, part-of-speech tagging and parsingare applied2.Candidate selection: Since only certain lexi-cal categories can be temporal expressions andthey are defined in the TIDES standard (Ferro et2For preprocessing we use the OpenNLP package(http://opennlp.sourceforge.net).325al., 2003), in our implementation we consider thefollowing chunk-phrases as candidates for tem-poral expressions: nouns (week, day), propernames (Tuesday, May), noun phrases (last Tues-day), adjectives (current), adjective phrases (thencurrent), adverbs (currently), adverbial phrases(a year ago), and numbers (2000).
As input ittakes the sentences with provided syntactic in-formation and marks phrases in the parse treebelonging to the above types for temporal ex-pressions.Annotation alignment: If the system is usedfor training classifiers, all the candidates in asentence are examined against the available an-notations.
The candidates, whose parse and anno-tation extents aligned, are taken as positive ex-amples and the rest is considered as negative.Feature Design: To produce a feature-vectorwe use most valuable features extracted forphrase-candidate.
After a number of experimentsthe following features were selected:?
Last token in the phrase, most probabletoken to be a temporal trigger;?
Lemma of the last phrasal token;?
Part-of-speech of the last phrasal token;?
Character pattern of the last phrasal to-ken as introduced in (Ahn et al, 2007);?
Neighbor POS?s.
The concatenated part-of-speech tags of the last phrasal tokenand its preceding token;?
Character pattern of the entire phrase;?
Phrase surface.
A concatenated string ofsub-parse  types for the phrase;?
A Boolean feature indicating nestedcomplex phrasal parses, such as nounverb, adverbial, adjective or preposition-al phrase;?
Depth of the phrase.
The number of thenested sub-parses to the deepest pre-terminal sub-parse.All the features are considered as Boolean.Classification: Once the classifiers are trainedthey can be used for recognition of temporal ex-pressions on test sentences.
A preprocessed sen-tence is taken as input and starting from itsparse-tree root the candidate-phrases are classi-fied.
The most probable class will be assigned tothe candidate under consideration.
Once thephrase is classified as temporal expression nofurther classification of nested phrases is per-formed, since no embedded timexes are allowedin the corpus.
After a series of experiments withdifferent machine learning techniques on thetraining data the maximum entropy classifier waschosen.Extending positive instances: Sparseness ofannotated corpora is the biggest challenge forany supervised machine learning technique.
Toovercome this problem we hypothesize thatknowledge of semantic similar words could befound by associating words that do not occur inthe training set to similar words that did occur inthe training set.
Furthermore, we would like tolearn these similarities automatically in order tobe as much as possible independent of know-ledge sources that might not be available for alllanguages or domains.
For example, there is inTimeBank a temporal expression ?last summer?with the temporal trigger summer, but there is noannotation of temporal expressions built aroundthe temporal trigger winter, and this means thatno temporal expression with the trigger wintercan be recognized.
Something similar usuallyhappens to any annotated corpus and we want tofind a way how to find other temporal expres-sions outside the available data, which can beused for training.
On the other hand, we want toavoid a na?ve selection of words as, for example,from a gazetteer with temporal triggers, whichmay contradict with grammatical rules and thelexical context of a timex in text, e.g.
:on Tuesday said....But grammatically wrong by na?ve replacementfrom a gazetteer:?
on week said*??
on day said*??
on month said* ?In order to find these words, which are legiti-mate at a certain position in a certain context weuse the latent word language model (LWLM)(Deschacht & Moens, 2009) with a Hidden Mar-kov Model approach for estimating the latentword parameters.Complementary, we use WordNet (Miller,1995) as a source that can provide a most com-plete set of words similar to the given one.
Oneshould note that the use of WordNet is notstraight-forward.
Due to the polysemy, the wordsense disambiguation (WSD) problem has to besolved.
Our system uses latent words obtained bythe LWLM and chooses the synset with the high-326est overlap between WordNet synonyms andcoordinate terms, and the latent words.
The over-lap value is calculated as the sum of LWLMprobabilities for matching words.Having these two sets of synonyms and after aseries of preliminary tests we found the setting,at which the system produces the highest resultsand submitted several runs with different strate-gies:?
Baseline (no expansion) (KUL Run 1)?
3 LWLM words with highest probabili-ties (KUL Run 2)?
3 WordNet coordinate terms; WSD issolved by means of LWLM3 (KUL Run3)For each available annotation in the corpus apositive instance is generated.
After that, the to-ken at the most probable position for a temporaltrigger is replaced by a synonym from the syn-onym set found to the available token.2.2 Normalization of Temporal ExpressionsNormalization of temporal expressions is aprocess of estimating standardized temporal val-ues and types.
For example, the temporal expres-sion ?summer 1990?
has to be resolved to itsvalue of 1990-SU and the type of DATE.
Incontrast, for the expression ?last year?
the valuecannot be estimated directly, rather it gets a mod-ified value of another time expression.Due to a large variance of expressions denot-ing the same date and vagueness in language,rule-based systems have been proven to performbetter than machine-learning ones for the norma-lization task.
The current implementation followsa rule-based approach and takes a pre-processeddocument with recognized temporal expressions(as it is described in Section 2.1) and estimates astandardized ISO-based date/time value.
In thefollowing sections we provide implementationdetails of the system.Before the temporal value is estimated, weemploy a classifier, which uses the same featuresets and classify the temporal expression amongtype classes DATE, TIME, DURATION andSET.Labeling: Labeling text is a process of provid-ing tags to tokens of chunk-phrases from a de-3Preliminary experiments, when the most common sense inWordNet is chosen for increasing the number of positiveexamples, showed a low performance level and thus has notbeen proposed for evaluations.fined set of tags.
We carefully examined availa-ble annotated temporal expressions and annota-tion standards to determine categories of wordsparticipating in temporal expressions.
The fol-lowing set of categories with labels based on se-mantics of temporally relevant information andsimple syntax was defined: ordinal numbers(first, 30th etc.
), cardinal numbers (one, two, 10etc.
), month names (Jan., January etc.
), weekday names (Mo., Monday etc.
), season names(summer, winter etc.
), parts of day (morning,afternoon etc.
), temporal directions (ago, later,earlier etc.
), quantifiers (several, few etc.
), mod-ifiers (recent, last etc.
), approximators (almost,nearly etc.
), temporal co-references (time, periodetc.
), fixed single token timexes (tomorrow, to-day etc.
), holidays (Christmas, Easter etc.)
andtemporal units (days, months, years etc.).
Alsofine-grained categories are introduced: day num-ber, month number and year number.
For eachcategory we manually construct a vocabulary, inwhich each entry specifies a value of a temporalfield or a final date/time value, or a method withparameters to apply.As input, the normalization takes a recognizedtemporal expression and its properties, such asthe temporal type and the discourse type4.
Duringlabeling each token in a temporal expression istagged with one or multiple labels correspondingto the categories defined above.
For each of thecategories a custom detector is implemented.
Thedetector declares the method to run and the ex-pected type of the result.
The rules that imple-ment the logics for the detector are inheritedfrom an abstract class for this specific detector,so that if a new rule needs to be implemented itsrealization is limited to the development of oneclass, all the rest the detector does automatically.Besides, the order, in which detectors have to berun, can be specified (as for example, in case offine-grained detectors).
As output, the moduleprovides labels of the categories to the tokens inthe temporal expression.
If there is no entry inthe vocabulary for a token, its part-of-speech tagis used as the label.Value estimation: Value estimation isimplemented in the way of aggregating thevalues defined for entries in the vocabularyand/or executing instructions or methodsspecified.
Also a set of predefined resolution4Since in TempEval-2 the reference to the timex with re-spect to which the value estimated is given, the normaliza-tion module considers all timexes as deictic.327rules is provided and can be extended with newimplementations of resolution strategies.For resolution of complex relative temporalexpressions, the value for which cannot be esti-mated directly, we need to rely on additional in-formation found at the recognition step.
This in-cludes the semantic type of the timex, discoursetype and contextual temporal information(speech or document creation time, or previouslymentioned timexes).
Let?s consider the followingtemporal expression as an example: 10 days ago.In this example the temporal expression receivesa modified value of another timex, namely thevalue of the document creation time.
The tem-poral expression is recognized and classified as adate (SEM TYPE: DATE), which refers toanother timex (DISCOURSE TYPE: DEIC-TIC).
It takes the value of the referenced timexand modifies it with respect to the number (10),magnitude (days) and temporal direction (ago).Thus, the final value is calculated by subtractinga number of days for the value of the referencedtimex.3 Results and Error AnalysisIn the Table 1 the results of the best-performingruns are presented.Table 1.
Results of different runs of the system.As we can see the best results were obtainedby extending available annotations with maxi-mum 3 additional instances, which are extractedas coordinate terms in WordNet, whereas theWSD problem was solved as the greatest overlapbetween coordinate terms and latent words ob-tained by the LWLM.Most of the errors at the recognition step werecaused by misaligned parses and annotations.For normalization we acknowledge the signi-ficance of estimating a proper temporal valuewith a correct link to the temporal expressionwith its value.
In the TempEval-2 training datathe links to the temporal expressions indicatinghow the value is calculated were not provided,and thus, the use of machine learning tools fortraining and automatic disambiguation was notpossible.
We choose a fixed strategy and all rela-tive temporal expressions were resolved withrespect to the document creation time, whichcaused errors with wrong temporal values and alow performance level.4 ConclusionsFor TempEval-2 we proposed a system for therecognition and normalization of temporal ex-pressions.
Multiple runs were submitted, amongwhich the best results were obtained with auto-matically expanded positive instances by wordsderived as coordinate terms from WordNet forwhich the proper sense was found as the greatestoverlap between coordinate terms and latentwords found by the LWLM.AcknowledgementsThis work has been funded by the Flemish gov-ernment as a part of the project AMASS++(Grant: IWT-60051) and by Space ApplicationsServices NV as part of the ITEA2 project LIN-DO (ITEA2-06011, IWT-70043).ReferencesAhn, D., van Rantwijk, J., and de Rijke, M. 2007.
ACascaded Machine Learning Approach to Interpret-ing Temporal Expressions.
In Proceedings ofNAACL-HLT 2007.Deschacht, K., and Moens M.-F. 2009.
Using the La-tent Words Language Model for Semi-SupervisedSemantic Role Labeling.
In Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing.Ferro, L., Gerber, L., Mani, I., Sundheim, B., andWilson, G. 2003.
TIDES 2003 Standard for theAnnotation of Temporal Expressions.Miller, G. A.
1995.
WordNet: A Lexical Database forEnglish.
Communications of the ACM, 38(11): 39-41.Pustejovsky, J. and Verhagen, M. 2009.
SemEval-2010 Task 13: Evaluating Events, Time Expres-sions, and Temporal Relations (TempEval-2).
InProceedings of the Workshop on Semantic Evalua-tions: Recent Achievements and Future Directions.Verhagen, M., Gaizauskas, R.,  Schilder, F., Hepple,M.,  and Pustejovsky, J.
2007.
Semeval-2007 Task15: Tempeval Temporal Relation Identification.
InSemEval-2007: 4th International Workshop onSemantic Evaluations.Run Recognition NormalizationP R F1 TYPE Acc.VALAcc.1 0.78 0.82 0.8 0.91 0.552 0.75 0.85 0.797 0.91 0.513 0.85 0.84 0.845 0.91 0.55328
