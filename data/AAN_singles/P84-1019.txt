COMPUTER SIMULATION OF SPONTANEOUS SPEECH PRODUCTIONBengt SigurdDept of Linguistics and PhoneticsHelgonabacken 12, S-223 62 Lund, SWEDENABSTRACTThis paper pinpoints some of the problemsfaced when a computer text production model(COMMENTATOR) is to produce spontaneous speech, inparticular the problem of chunking the utterancesin order to get natural prosodic units.
The paperproposes a buffer model which allows the accumula-tion and delay of phonetic material until a chunkof the desired size has been built up.
Severalphonetic studies have suggested a similar tempo-rary storage in order to explain intonation slopes,rythmical patterns, speech errors and speech dis-orders.
Small-scale simulations of the whole ver-balization process from perception and thought tosounds, hesitation behaviour, pausing, speecherrors, sound changes and speech disorders are pre-sented.1.
IntroductionSeveral text production models implement-ed on computers are able to print grammatical sen-tences and coherent text (see e.g.
contributions inAll~n, 1983, Mann & Matthiessen, 1982).
There is,however, to my knowledge no such verbal productionsystem with spoken output, simulating spontaneousspeech, except the experimental version ofCommentator to be described.The task to design a speech productionsystem cannot be solved just by attaching a speechsynthesis device to the output instead of a printer.The whole production model has to be reconsideredif the system is to produce natural sound and pro-sody, in particular if the system is to have somepsychological reality by simulating the hesitationpauses, and speech errors so common in spontaneousspeech.This paper discusses some of the prob-lems in the light of the computer model of verbalproduction presented ?n Sigurd (1982), Fornell(1983).
For experimental purposes a simple speechsynthesis device (VOTRAX) has been used.The Problem of producing naturallysounding utterances is also met in text-to-speechsystems (see e.g.
Carlson & Granstr~m, 1978).
Suchsystems, however, take printed text as input andturn it into a phonetic representation, eventuallysound.
Because of the differences between spellingand sound such systems have to face special prob-lems, e.g.
to derive single sounds from the lettercombinations t__hh, ng, sh, ch in such words as the,thing, shy, change.2.
Co,~entator as a speech productionsystemThe general outline of Con~entator ispresented in fig.
I.
The input to this model isperceptual data or equivalent values, e.g.
infor-mation about persons and objects on a screen.
Theseprimary perceptual facts constitute the basis forvarious calculations in order to derive secondaryfacts and draw concluslons about movements and re-lations such as distances, directions, right/left,over/under, front/back, closeness, goals and in-tentions of the persons involved etc.
TheCommentator produces comments consisting of gram-matical sentences making up coherent and well-formed text (although often soon boring).
Sometypical comments on a marine scene are: THE SUB-79MARINE IS TO THE SOUTH OF THE PORT.
IT IS APPROACH-ING THE PORT, BUT IT IS NOT CLOSE TO IT.
THEDESTROYER IS APPROACHING THE PORT TOO.
The orig-inal version commented onthe  movements of thetwo persons ADAM and EVE in front of a gate.A question menu, different for differentsituations, suggests topics leading to proposi-tions which are considered appropriate under thecircumstances and their truth values are testedagainst the primary and secondary facts of theworld known to the system (the simulated scene).If a proposition is found to be true, it is ac-cepted as a protosentence and verbalized by var-ious lexical, syntactic, referential and texualsubroutines.
If, e.g., the proposition CLOSE(SUBMARINE, PORT) is verified after measuring thedistance between the submarine and the port, thelexical subroutines try to find out how closeness,the submarine and the port should be expressed inthe language (Swedish and English printing andspeaking versions have been implemented).The referential subroutines determinewhether pronouns could be used instead of properor other nouns and textual procedures investigatewhether connectives such as but, however, too,either and perhaps contrastive stress should beinserted.Dialogue (interactive) versions of theCommentator have also been developed, but it isdifficult to simulate dialogue behaviour.
Aperson taking part in a dialogue must also masterturntaking, questioning, answering, and back-channelling (indicating, listening, evaluation).Expert systems, and even operative systems, simu--late dialogue behaviour, but as everyone knows,who has worked with computers, the computer dia-logue often breaks down and it is poor and cer-tainly not as smooth as human dialogue.The Commentator can deliver words oneat a time whose meaning, syntactic and textualfunctions are well-defined through the verbal-ization processes.
For the printing version ofCo~nentator these words are characterized bywhatever markers are needed.Lines Component10- 35 Primary infor-mation100- Secondary infor-140 mation152- i 183 Focus and topicplanning expert210- 232 Verificationexpert500 Sentence struc-ture(syntax) expert600- Reference expert800 (subroutine)700- Lexical expert(dictionary)expertTask Result (sample)I Get values of Localizationprimary dimen- coordinatessionsDerive values Distances, right-of complex left, under-overdimensionsDetermine objects Choice of sub-in focus (refe- ject, object andrents) and topics instructions toaccording to menu test abstract pred-icates with theseTest whether the Positive or nega-conditions for tive protosentencesthe use of the and instructions forabstract predl- how to proceedcares are met inthe situation donthe screen)Order the abstract Sentence struc-sentence constltu- ture with furtherents (subject, pre- instructionsdicate, object);basic prosodyDetermine  whether Pronouns, properpronouns, proper nouns, indefinitenouns, or other or definlteNPsexpressions couldbe usedTranslate (substi- Surface phrases,tute} abstract wordspredicates, etc.Insert conjunc- Sentenc~withtlons, connective words such as ock-adverbs; prosodic s~ (too}, dock - -features -~owever} - -Pronounce or print Uttered orthe assembled printed sentencestructure (text)Figure I.
Components of the text production modelunderlying Commentator3.
A Simple speech synthesis deviceThe experimental system presented in thispaper uses a Votrax speech synthesis unit (for apresentation see Giarcia, 1982).
Although it isa very simple system designed to enable computersto deliver spoken output such as numbers, shortinstructions etc, it has some experimental poten-tials.
It forces the researcher to take a stand ona number of interesting issues and make theoriesabout speech production more concrete.
The Votraxis an inexpensive and unsophisticated synthesisdevice and it is not our hope to achieve perfectpronunciation using this circuit, of course.
Thecircuit, rather, provides a simple way of doingresearch in the field of speech production.Votrax (which is in fact based on a cir-cuit named SC-01 sold under several trade names)80offers a choice of some 60 (American) Englishsounds (allophones) and 4 pitch levels.
A soundmust be transcribed by its numerical code and apitch level, represented by one of the figures0,1,2,3.
The pitch figures correspond roughly tothe male levels 65,90,110,130 Hz.
Votrax offersno way of changing the amplitude or the duration.Votrax is designed for (American) Englishand if used for other languages it will, of course,add an English flavour.
It can, however, be usedat least to produce intelligible words for severalother languages.
Of course, some sounds may belacking, e.g.
Swedish ~ and \[ and some sounds maybe slightly different, as e.g.
Swedish sh-, ch-,r_-, and ~-sounds.Most Swedish words can be pronouncedintelligibly by the Votrax.
The pitch levels havebeen found to be sufficient for the production ofthe Swedish word tones: accent I (acute) as inand-en (the duck) and accent 2 (grave) as in ande-(the spirit).
Accent I can be rendered by thepitch sequence 20 and accent 2 by the sequence 22on the stressed syllable (the beginning) of thewords.
Stressed syllables have to include at leastone 2.Words are transcribed in the Votrax al-phabet by series of numbers for the sounds andtheir pitch levels.
The Swedish word hSger (right)may be given by the series 27,2,58,0,28,0,35,0,43,0, where 27,58,28,35,43 are the sounds corre-sponding to h,~:,g,e,r, respectively and the fig-ures 2,0 etc after each sound are the pitch levelsof each sound.
The word h~ger sounds Americanbecause of the ~, which sounds like the (retroflex)vowels in bird.The pronunciation (execution) of thewords is handled by instructions in a computerprogram, which transmits the information to thesound generators and the filters simulating thehuman vocal apparatus.4.
Some problems to handle4.1.
Pauses and prosodic units in speechThe spoken text produced by human beings isnormally divided by pauses into units of severalwords (prosodic units).
There is no generallyaccepted theory explaining the location and dura-tion of the pauses and the intonation and stresspatterns in the prosodic units.
Many observationshave, however, been made, see e.g.
Dechert &Raupach (1980).The printing version of Con=nentator col-lects all letters and spaces into a string beforethey are printed.
A speaking version trying tosimulate at least some of the production processescannot, of course, produce words one at a timewith pauses corresponding to the word spaces, norproduce all the words of a sentence as one proso-dic unit.
A speaking version must be able to pro-duce prosodic units including 3-5 words (cfSvartvik (1982)) and lasting 1-2 seconds (seeJSnsson, Mandersson & Sigurd (1983)).
How thisshould be achieved may be called the chunkingproblem.
It has been noted that the chunks ofspontaneous speech are generally shorter than intext read aloud.The text chunks have internal intonationand stress patterns often described as superim-posed on the words.
Deriving these internal proso-dic patterns may be called the intra-chunk problem.We may also talk about the inter-chunk problemhaving to do with the relations e.g.
in pitch,between succesive chunks.As human beings need to breathe theyhave to pause in order to inhale at certain inter-vals.
The need for air is generally satisfiedwithout conscious actions.
We estimate that chunksof I-2 seconds and inhalation pauses of about 0.5seconds allow convenient breathing.
Clearly,breathing allows great variation.
Everybody hasmet persons who try to extend the speech chunksand minimize the pauses in order to say as muchas possible, or to hold the floor.It has also been observed that pausesoften occur where there is a major syntactic break(corresponding to a deep cut in the syntactictree), and that, except for soTcalled hesitationpauses, pauses rarely occur between two wordswhich belong closely together (corresponding to a81shallow cut in the syntactic tree).
There is,however, no support for a simple theory thatpauses are introduced between the main constitu-ents of the sentence and that their duration is afunction of the depthof the cuts in the syntactictree.
The conclusion to draw seems rather to bethat chunk cuts are avoided between words whichbelong closely together.
Syntactic structure doesnot govern chunking, but puts constraints on it.Click experiments which show that the click iserroneously located at major syntactic cuts ratherthan between words which are syntactically coherentseem to point in the same direction.
As an illus-tration of syntactic closeness we mention thecombination of a verb and a following reflexivepronoun as in Adam n~rmar+sig Eva.
("Adam ap-proaches Eva").
Cutting between n~rmar and si~would be most unnatural.Lexical search, syntactic and textualplanning are often mentioned as the reasons forpauses, so-called hesitation pauses, filled orunfilled.
In the speech production model envisagedin this paper sounds are generally stored in abuffer where they are given the proper intona-tional contours and stress patterns.
The pronun-ciation is therefore generally delayed.
Hesitationpauses seem, however, to be direct (on-line) re-flexes of searching or planning processes and atsuch moments there is no delay.
Whatever has beenaccumulated in the articulation or executionbuffer is pronounced and the system is waitingfor the next word.
While waiting (idling),somehuman beings are silent, others prolong the lastsounds of the previous word or produce sounds,such as ah, eh, or repeat part of the previousutterence.
(This can also be simulated byCommentator.)
Hesitation pauses may occur anywhere,but they seem to be more frequent before lexicalwords than function words.By using buffers chunking may be madeaccording to various principles.
If a sentencetermination (full stop) is entered in the execu-tion buffer, whatever has been accumulated in thebuffer may be pronounced setting the pitch of thefinal part at low.
If the number of segments inthe chunk being accumulated in the buffer doesnot exceed a certain limit a new word is onlystored after the others in the execution buffer.The duration of a sound in Votrax is 0.1 secondon the average.
If the limit is set at 15 thesystem will deliver chunks about 1.5 seconds,which is a common length of speech chunks.
Thesystem may also accumulate words in such a waythat each chunk normally includes at least onestressed word, or one syntactic constituent (ifthese features are marked in the representation).The system may be made to avoid cutting wherethere is a tight syntactic link, as e.g.
betweena head word and enclitic morphemes.
The lengthof the chunk can be varied in order to simulatedifferent speech styles, individuals or speechdisorders.4.2.
Prosodic patterns within utterance chunksA system producing spontaneous speechmust give the proper prosodic patterns to all thechunks the text has been divided into.
Except fora few studies, e.g.
Svartvik (1982) most prosodicstudies concern well-formed grammatical sentencespronounced in isolation.
While waiting for furtherinformation and more sophisticated synthesisdevices it is interesting to do experiments tofind out how natural the result is.Only @itch, not intensity, is availablein Votrax, but pitch may be used to signal stresstoo.
Unstressed words may be assigned pitch levelI or 0, stressed words 2 or higher on at leastone segment.
Words may be assumed to be inherentlystressed or unstressed.
In the restricted Swedishvocabulary of Commentator the following illustratelexically stressed words: Adam, v~nster (left),n~ra (close), ocks~ (too).
The following wordsare lexically unstressed in the experiments: han(he), den (it), i (in), och (and), men (but), ~r(is).
Inherently unstressed words may becomestressed, e.g.
by contrast assigned during theverbalization process.The final sounds of prosodic units areoften prolonged, a fact which can be simulatedby doubling some chunk-final sounds, but the82Votrax is not sophisticated enough to handle thesephonetic subtleties.
Nor can it take into accountthe fact that the duration of sounds seem to varywith the length of the speech chunk.The rising pitch observed in chunks whichare not sentence final (signalling incompleteness)can be implemented by raising the pitch of thefinal sounds of such chunks.
It has also been ob-served that words (syllables) within a prosodicunit seem to be placed on a slope of intonation(grid).
The decrement to the pitch of each soundcaused by such a slope can be calculated knowingthe place of the sound and the length of thechunk.
But so far, the resulting prosody, as isthe case of text-to-speech systems, cannot be saidto be natural.4.3.
Speech errors and sound changeSpeech errors may be classed as lexical,grammatical or phonetic.
Some lexical errors canbe explained (and simulated) as mistakes in pick-ing up a lexical item.
Instead of picking uphbge~ (right) the word v~nster (left), a semi-antonym, stored on an adjacent address, is sentto the buffer.
Grammatical mistakes may be simu-lated by mixing up the contents of memories stor-ing the constituents during the process of verbal-ization.Phonetic errors can be explaned (andsimulated) if we assume buffers where the phoneticmaterial is stored and mistakes in handling thesebuffers.
The representation in Votrax is not,however, sophisticated enough for this purpose assound features and syllable constituents oftenmust be specified.
If a person says pb~er omporten instead of h~ger om porten (to the rightof the gate) he has picked up the initial conso-nantal element of the following stressed syllabletoo early.Most explanations of speech errors assumean unconscious or a conscious monitoring of thecontents of the buffers used during the speechproduction process.
This monitoring (which in someways can be simulated by computer) may result inchanges in order to adjust the contents of thebuffers, e.g.
to a certain norm or a fashion.Similar monitoring is seen in word processingsystems which apply automatic spelling correction.But there are several places in Commentator wheresound changes may be simulated.REFERENCESAll~n, S. (ed) 1983.
Text processing.
Nobelsymposium.
Stockholm: Almqvist & WiksellCarlson, R. & B. Granstrbm.
1978.
Experimentaltext-to-speech system for the handicapped.JASA 64, p 163Ciarcia, S. 1982.
Build the Microvox Text-to-speechsynthesizer.
Byte 1982:0ctDechert, H.W.
& M. Raupach (eds) 1980.
Temporalvariables in speech.
The Hague: MoutonFornell, J.
1983.
Commentator, ett mikrodator-baserat forskningsredskap fDr lingvister.Praktisk Lingvistik 8Jbnsson, K-G, B. Mandersson & B. Sigurd.
1983.A microcomputer pausemeter for linguists.
In:Working Papers 24.
Lund.
Department oflinguisticsMann, W.C. 5 C. Matthiessen.
1982.
Nigel: asystemic grammar for text generation.
In-formation sciences institute.
USC.
Marina delRay.
ISI/RR-83-I05Sigurd, B.
1982.
Text representation in a textproduction model.
In: All~n (1982)Sigurd, B.
1983.
Commentator: A computer model ofverbal production.
Linguistics 20-9/10 (toappear)Svartvik, J.
1982.
The segmentation of impromptuspeech.
In Enkvist, N-E (ed).
Impromptu speech:Symposium.
Abo: Abo akademi83
