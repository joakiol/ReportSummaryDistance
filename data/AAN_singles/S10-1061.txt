Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 272?275,Uppsala, Sweden, 15-16 July 2010.c?2010 Association for Computational LinguisticsMARS: A Specialized RTE System for Parser EvaluationRui Wang?Yi Zhang???
Department of Computational Linguistics, Saarland University?
LT-Lab, German Research Center for Artificial IntelligenceIm Stadtwald, 66123 Saarbr?ucken, Germany{rwang,yzhang}@coli.uni-sb.deAbstractThis paper describes our participationin the the SemEval-2010 Task #12,Parser Evaluation using Textual Entail-ment.
Our system incorporated two depen-dency parsers, one semantic role labeler,and a deep parser based on hand-craftedgrammars.
The shortest path algorithmis applied on the graph representation ofthe parser outputs.
Then, different typesof features are extracted and the entail-ment recognition is casted into a machine-learning-based classification task.
Thebest setting of the system achieves 66.78%of accuracy, which ranks the 3rd place.1 IntroductionThe SemEval-2010 Task #12, Parser Evaluationusing Textual Entailment (PETE) (Yuret et al,2010), is an interesting task connecting two areasof research, parsing and recognizing textual entail-ment (RTE) (Dagan et al, 2005).
The former isusually concerned with syntactic analysis in spe-cific linguistic frameworks, while the latter is be-lieved to involve more semantic aspects of the hu-man languages.
However, no clear-cut boundarycan be drawn between syntax and semantics forboth tasks.
In recent years, the parsing commu-nity has been reaching beyond what was usuallyaccepted as syntactic structures.
Many deep lin-guistic frameworks allow the construction of se-mantic representations in parallel to the syntacticstructure.
Meanwhile, data-driven shallow seman-tic parsers (or semantic role labelers) are anotherpopular type of extension to enrich the informationin the parser outputs.Although entailment is described as a semanticrelation, RTE, in practice, covers linguistic phe-nomena at various levels, from surface text to themeaning, even to the context and discourse.
Oneproposal of solving the problem is to deal with dif-ferent cases of entailment using different special-ized RTE modules (Wang and Neumann, 2009).Then, the PETE data can be naturally classifiedinto the syntactic and shallow semantic categories.By participating in this shared task, we aim toinvestigate whether different parsing outputs leadsto different RTE accuracy, and on the contrary,whether the ?application?-based evaluation pro-vides insights to the parser comparison.
Further,we investigate if strict grammaticality checkingwith a linguistic grammar is helpful in this task.2 System DescriptionThe workflow of the system is shown in Figure1 and the details of the three components will beelaborated on in the following sections.2.1 PreprocessingIn this paper, we generally refer all the linguisticanalyses on the text as preprocessing.
The outputof this procedure is a graph representation, whichapproximates the meaning of the input text.
In par-ticular, after tokenization and POS tagging, we diddependency parsing and semantic role labeling.
Inaddition, HPSG parsing is a filter for ungrammat-ical hypotheses.Tokenization and POS Tagging We use thePenn Treebank style tokenization throughout thevarious processing stages.
TnT, an HMM-basedPOS tagger trained with Wall Street Journal sec-tions of the PTB, was used to automatically pre-dict the part-of-speech of each token in the textsand hypotheses.Dependency Parsing For obtaining the syntac-tic dependencies, we use two dependency parsers,MSTParser (McDonald et al, 2005) and Malt-Parser (Nivre et al, 2007).
MSTParser is a graph-based dependency parser where the best parsetree is acquired by searching for a spanning tree272Dependency PathExtractionFeature-based ClassificationPreprocessingHPSGParsingDependencyParsingSemanticRoleLabelingTHDependencyTripleExtractionPathExtractionFeatureExtractionSVM-basedClassificationYes/NoNoFigure 1: Workflow of the Systemwhich maximize the score on an either partially orfully connected dependency graph.
MaltParser isa transition-based incremental dependency parser,which is language-independent and data-driven.
Itcontains a deterministic algorithm, which can beviewed as a variant of the basic shift-reduce al-gorithm.
Both parsers can achieve state-of-the-artperformance and Figure 2 shows the resulting syn-tactic dependency trees of the following T-H pair,ID: 2036; Entailment: YEST: Devotees of the market question the value ofthe work national service would perform.H: Value is questioned.Semantic Role Labeling The statistical depen-dency parsers provide shallow syntactic analysesof the entailment pairs through the limited vocab-ulary of the dependency relations.
In our case, theCoNLL shared task dataset from 2008 were usedto train the statistical dependency parsing mod-els.
While such dependencies capture interestingsyntactic relations, when compared to the parsingsystems with deeper representations, the containedinformation is not as detailed.
To compensate forthis, we used a shallow semantic parser to predictthe semantic role relations in the T and H of en-tailment pairs.
The shallow semantic parser wasalso trained with CoNLL 2008 shared task dataset,with semantic roles extracted from the Propbankand Nombank annotations (Zhang et al, 2008).Figure 3 shows the resulting semantic dependencygraphs of the T-H pair.HPSG Parsing We employ the English Re-source Grammar (Flickinger, 2000), a hand-written linguistic grammar in the framework ofHPSG, and the PET HPSG parser (Callmeier,2001) to check the grammaticality of each hy-pothesis sentence.
As the hypotheses in thisPETE shared task were automatically generated,some ungrammatical hypotheses occur in non-entailment pairs.
the grammaticality checking al-lows us to quickly identify these instances.2.2 Dependency Path ExtractionAccording to the task definition, we need to ver-ify whether those dependency relations in H alsoappear in T. We firstly find out all the impor-tant dependency triples in H, like <word, depen-dency relation, word>, excluding those havingstop words.
The extracted syntactic dependencytriples of the example T-H pair would be none,since the only content words ?value?
and ?ques-tioned?
have no direct syntactic dependency in-between (Figure 2).
The extracted semantic de-pendency triples would be <?questioned?, ?A1?,?value?> (Figure 3).After that, we use the word pairs contained inthe extracted dependency triples as anchors to findout the corresponding dependency relations in T.Notice that it is not necessarily that we can al-ways find a direct dependency relation in T be-tween the same word pair, so we need to traversethe dependency tree or graph to find the depen-dency paths.
In general, we treat all the depen-dency trees and graphs as undirected graphs withloops, but keep records for the directions of theedges we traverse.
For the following three repre-sentations, we apply slightly different algorithmsto find the dependency path between two words,Syntactic Dependency Tree We simply traversethe tree and find the corresponding depen-dency path connecting the two words;Semantic Dependency Graph We apply Dijk-stra?s algorithm (Dijkstra, 1959) to find theshortest path between the two words;Joint Dependency Graph We assign differentweights to syntactic and semantic dependen-cies and apply Dijkstra?s algorithm to find theshortest path (with the lowest cost)1.2.3 Feature-based ClassificationBased on the meaning representation we have dis-cussed above (Section 2.1 and Section 2.2), we ex-1In practice, we simply give semantic dependencies 0.5cost and syntactic dependencies 1.0 cost, to show the prefer-ences on the former when both exist.273T:H:Figure 2: Syntactic dependency of the example T-H pair by MaltParser.T:H:Figure 3: Semantic dependency of the example T-H pair by MaltParser and our SRL system.tract features for the machine-learning-based clas-sifier.
First of all, we should check whether thereare dependency triples extracted from H, other-wise for our system, there is no meaning repre-sentation for that sentence.
Then we also need tocheck whether the same words can be found in Tas well.
Only if the corresponding dependencypaths are successfully located in T, we could ex-tract the following features.The direction of each dependency relation orpath could be interesting.
The direction of theH-path is clear, so we only need to check thedirection of the T-path.
In practice, we simplyuse a boolean value to represent whether T-pathcontains dependency relations with different di-rections.
For instance, in Figure 3, if we extractthe path from ?market?
to ?value?, the directionsof the dependency relations contained in the pathwould be?
and?, one of which would be incon-sistent with the dependency relation in H.Notice that all the dependency paths from Hhave length 12, but the lengths of the dependencypaths from T are varied.
If the latter length is also1, we can simply compare the two dependency re-lations; otherwise, we compare each of the depen-2The length of one dependency path is defined as the num-ber of dependency relations contained in the path.dency relation contained the T-path with H-pathone by one3.
By comparison, we mainly focus ontwo values, the category of the dependency rela-tion (e.g.
syntactic dependency vs. semantic de-pendency) and the content of the dependency rela-tion (e.g.
A1 vs. AM-LOC).We also incorporate the string value of the de-pendency relation pair and make it boolean ac-cording to whether it occurs or not.
Table 1 showsthe feature types we extract from each T-H pair.3 ExperimentsAs we mentioned in the preprocessing section(Section 2.1), we utilize the open source depen-dency parsers, MSTParser4and MaltParser5, ourown semantic role labeler (Zhang et al, 2008), andthe PET HPSG parser6.
For the shortest path algo-rithm, we use the jGraphT package7; and for themachine learning toolkit, we use the UniverSVM3Enlightened by Wang and Neumann (2007), we ex-clude some dependency relations like ?CONJ?, ?COORD?,?APPO?, etc., heuristically, since in most of the cases, theywill not change the relationship between the two words atboth ends of the path.4http://sourceforge.net/projects/mstparser/5http://maltparser.org/6http://heartofgold.dfki.de/PET.html7http://jgrapht.sourceforge.net/274HNull?TNull?DirMulti?DepSame?RelSim?RelSame?RelPairJoint + + + + + + + +No Sem + + + + +No Syn + + + + + + +Table 1: Feature types of different settings of thesystem.
H Null?
means whether H has dependencies;T Null?
means whether T has the corresponding paths (us-ing the same word pairs found in H); Dir is whether the di-rection of the path T the same as H; Multi?
adds a prefix,m , to the Rel Pair features, if the T-path is longer than onedependency relation; Dep Same?
checks whether the two de-pendency types are the same, i.e.
syntactic and semantic de-pendencies; Rel Sim?
only occurs when two semantic depen-dencies are compared, meaning whether they have the sameprefixes, e.g.
C-, AM-, etc.
; Rel Same?
checks whether thetwo dependency relations are the same; and Rel Pair simpleconcatenates the two relation labels together.
Notice that, thefirst seven feature types all contain boolean values, and for thelast one, we make it boolean as well, by observing whetherthat pair of dependency labels appear or not.package8.
We test different dependency graphsand feature sets as mentioned before (Table 1), andthe results are shown in Table 2.MSTParser+SRL MaltParser+SRLJoint No Sem No Syn Joint No Sem No Syn+GC 0.52490.5116 0.50500.66780.5282 0.6346(-1.3%) (-2.0%) (-14.0%) (-3.3%)-GC 0.5216 0.5050 0.4950 0.6545 0.5282 0.6179Table 2: Experiment results of our system withdifferent settings.First of all, in almost all the cases, the grammat-icality checking based on HPSG parsing is help-ful, if we compare each pair of results at the tworows, +GC and -GC.
In all cases, the joint graphrepresentation achieves better results.
This in-dicates that features extracted from both syntac-tic dependency and shallow semantic dependencyare useful for the entailment recognition.
For theMaltParser case, the semantic features show greatimportance.
Notice that the performance of thewhole system does not necessarily reflect the per-formance of the parser itself, since it also dependson our entailment modules.
In all, the best settingof our system ranks the 3rd place in the evaluation.4 ConclusionIn this paper, we present our system used in thePETE task, which consists of preprocessing, de-pendency path extraction, and feature-based clas-sification.
We use MSTParser and MaltParser as8http://www.kyb.mpg.de/bs/people/fabee/universvm.htmldependency parsers, our SRL system as a shallowsemantic parser, and a deep parser based on hand-crafted grammars for grammaticality checking.The entailment recognition is done by an SVM-based classifier using features extracted from thegraph representation of the parser outputs.
Basedon the results, we tentatively conclude that boththe syntactic and the shallow semantic features areuseful.
A detailed error analysis would be our on-going work in the near future.AcknowledgmentThe authors thank the PIRE PhD scholarship andthe German Excellence Cluster of MMCI for thesupport of the work.ReferencesUlrich Callmeier.
2001.
Efficient parsing with large-scaleunification grammars.
Master?s thesis, Universit?at desSaarlandes, Saarbr?ucken, Germany.Ido Dagan, Oren Glickman, and Bernardo Magnini.
2005.The pascal recognising textual entailment challenge.
InQui?nonero-Candela et al, editor, MLCW 2005, volumeLNAI Volume 3944, pages 177?190.
Springer-Verlag.E.
W. Dijkstra.
1959.
A note on two problems in connexionwith graphs.
Numerische Mathematik, 1:269?271.Dan Flickinger.
2000.
On building a more efficient gram-mar by exploiting types.
Natural Language Engineering,6(1):15?28.Ryan McDonald, Fernando Pereira, Kiril Ribarov, and JanHajic.
2005.
Non-Projective Dependency Parsing us-ing Spanning Tree Algorithms.
In Proceedings of HLT-EMNLP 2005, pages 523?530, Vancouver, Canada.Joakim Nivre, Jens Nilsson, Johan Hall, Atanas Chanev,G?ulsen Eryigit, Sandra K?ubler, Svetoslav Marinov, andErwin Marsi.
2007.
Maltparser: A language-independentsystem for data-driven dependency parsing.
Natural Lan-guage Engineering, 13(1):1?41.Rui Wang and G?unter Neumann.
2007.
Recognizing textualentailment using a subsequence kernel method.
In Pro-ceedings of AAAI-07, Vancouver, Canada, July.Rui Wang and G?unter Neumann.
2009.
An accuracy-oriented divide-and-conquer strategy for recognizing tex-tual entailment.
In Proceedings of TAC 2008, Gaithers-burg, Maryland, USA.Deniz Yuret, Ayd?n Han, and Zehra Turgut.
2010.
Semeval-2010 task 12: Parser evaluation using textual entailments.In Proceedings of the SemEval-2010 Evaluation Exerciseson Semantic Evaluation.Yi Zhang, Rui Wang, and Hans Uszkoreit.
2008.
Hybridlearning of dependency structures from heterogeneous lin-guistic resources.
In Proceedings of the Twelfth Con-ference on Computational Natural Language Learning(CoNLL 2008), pages 198?202, Manchester, UK.275
