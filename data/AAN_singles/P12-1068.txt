Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 647?656,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsCrosslingual Induction of Semantic RolesIvan Titov Alexandre KlementievSaarland UniversitySaarbru?cken, Germany{titov|aklement}@mmci.uni-saarland.deAbstractWe argue that multilingual parallel data pro-vides a valuable source of indirect supervisionfor induction of shallow semantic representa-tions.
Specifically, we consider unsupervisedinduction of semantic roles from sentences an-notated with automatically-predicted syntacticdependency representations and use a state-of-the-art generative Bayesian non-parametricmodel.
At inference time, instead of onlyseeking the model which explains the mono-lingual data available for each language, weregularize the objective by introducing a softconstraint penalizing for disagreement in ar-gument labeling on aligned sentences.
Wepropose a simple approximate learning algo-rithm for our set-up which results in efficientinference.
When applied to German-Englishparallel data, our method obtains a substantialimprovement over a model trained without us-ing the agreement signal, when both are testedon non-parallel sentences.1 IntroductionLearning in the context of multiple languages simul-taneously has been shown to be beneficial to a num-ber of NLP tasks from morphological analysis tosyntactic parsing (Kuhn, 2004; Snyder and Barzilay,2010; McDonald et al, 2011).
The goal of this workis to show that parallel data is useful in unsupervisedinduction of shallow semantic representations.Semantic role labeling (SRL) (Gildea and Juraf-sky, 2002) involves predicting predicate argumentstructure, i.e.
both the identification of argumentsand their assignment to underlying semantic roles.For example, in the following sentences:(a) [A0Peter] blamed [A1Mary] [A2for planning a theft].
(b) [A0Peter] blamed [A2planning a theft] [A1on Mary].
(c) [A1Mary] was blamed [A2for planning a theft] [A0byPeter]the arguments ?Peter?, ?Mary?, and ?planning a theft?of the predicate ?blame?
take the agent (A0), patient(A1) and reason (A2) roles, respectively.
In thiswork, we focus on predicting argument roles.SRL representations have many potential appli-cations in NLP and have recently been shownto benefit question answering (Shen and Lapata,2007; Kaisser and Webber, 2007), textual entailment(Sammons et al, 2009), machine translation (Wuand Fung, 2009; Liu and Gildea, 2010; Wu et al,2011; Gao and Vogel, 2011), and dialogue systems(Basili et al, 2009; van der Plas et al, 2011), amongothers.
Though syntactic representations are oftenpredictive of semantic roles (Levin, 1993), the inter-face between syntactic and semantic representationsis far from trivial.
Lack of simple deterministic rulesfor mapping syntax to shallow semantics motivatesthe use of statistical methods.Most of the current statistical approaches to SRLare supervised, requiring large quantities of humanannotated data to estimate model parameters.
How-ever, such resources are expensive to create and onlyavailable for a small number of languages and do-mains.
Moreover, when moved to a new domain,performance of these models tends to degrade sub-stantially (Pradhan et al, 2008).
Sparsity of anno-tated data motivates the need to look to alternative647resources.
In this work, we make use of unsuper-vised data along with parallel texts and learn to in-duce semantic structures in two languages simulta-neously.
As does most of the recent work on unsu-pervised SRL, we assume that our data is annotatedwith automatically-predicted syntactic dependencyparses and aim to induce a model of linking betweensyntax and semantics in an unsupervised way.We expect that both linguistic relatedness andvariability can serve to improve semantic parses inindividual languages: while the former can pro-vide additional evidence, the latter can serve to re-duce uncertainty in ambiguous cases.
For example,in our sentences (a) and (b) representing so-calledblame alternation (Levin, 1993), the same informa-tion is conveyed in two different ways and a success-ful model of semantic role labeling needs to learnthe corresponding linkings from the data.
Induc-ing them solely based on monolingual data, thoughpossible, may be tricky as selectional preferencesof the roles are not particularly restrictive; similarrestrictions for patient and agent roles may furthercomplicate the process.
However, both sentences(a) and (b) are likely to be translated in Germanas ?
[A0Peter] beschuldigte [A1Mary] [A2einen Dieb-stahl zu planen]?.
Maximizing agreement betweenthe roles predicted for both languages would pro-vide a strong signal for inducing the proper linkingsin our examples.In this work, we begin with a state-of-the-artmonolingual unsupervised Bayesian model (Titovand Klementiev, 2012) and focus on improving itsperformance in the crosslingual setting.
It inducesa linking between syntax and semantics, encoded asa clustering of syntactic signatures of predicate ar-guments.
The clustering implicitly defines the set ofpermissible alternations.
For predicates present inboth sides of a bitext, we guide models in both lan-guages to prefer clusterings which maximize agree-ment between predicate argument structures pre-dicted for each aligned predicate pair.
We experi-mentally show the effectiveness of the crosslinguallearning on the English-German language pair.Our model admits efficient inference: the estima-tion time on CoNLL 2009 data (Hajic?
et al, 2009)and Europarl v.6 bitext (Koehn, 2005) does not ex-ceed 5 hours on a single processor and the infer-ence algorithm is highly parallelizable, reducing in-ference time down to less than half an hour on mul-tiple processors.
This suggests that the models scaleto much larger corpora, which is an important prop-erty for a successful unsupervised learning method,as unlabeled data is abundant.In summary, our contributions are as follows.?
This work is the first to consider the crosslin-gual setting for unsupervised SRL.?
We propose a form of agreement penalty andshow its efficacy on English-German languagepair when used in conjunction with a state-of-the-art non-parametric Bayesian model.?
We demonstrate that efficient approximate in-ference is feasible in the multilingual setting.The rest of the paper is organized as follows.
Sec-tion 2 begins with a definition of the crosslingualsemantic role induction task we address in this pa-per.
In Section 3, we describe the base monolingualmodel, and in Section 4 we propose an extension forthe crosslingual setting.
In Section 5, we describeour inference procedure.
Section 6 provides bothevaluation and analysis.
Finally, additional relatedwork is presented in Section 7.2 Problem DefinitionAs we mentioned in the introduction, in this workwe focus on the labeling stage of semantic role la-beling.
Identification, though an important prob-lem, can be tackled with heuristics (Lang and Lap-ata, 2011a; Grenager and Manning, 2006; de Marn-effe et al, 2006) or potentially by using a supervisedclassifier trained on a small amount of data.Instead of assuming the availability of role an-notated data, we rely only on automatically gener-ated syntactic dependency graphs in both languages.While we cannot expect that syntactic structure cantrivially map to a semantic representation1, we canmake use of syntactic cues.
In the labeling stage,semantic roles are represented by clusters of ar-guments, and labeling a particular argument corre-sponds to deciding on its role cluster.
However, in-stead of dealing with argument occurrences directly,1Although it provides a strong baseline which is difficult tobeat (Grenager and Manning, 2006; Lang and Lapata, 2010;Lang and Lapata, 2011a).648we represent them as predicate-specific syntacticsignatures, and refer to them as argument keys.
Thisrepresentation aids our models in inducing high pu-rity clusters (of argument keys) while reducing theirgranularity.
We follow (Lang and Lapata, 2011a)and use the following syntactic features for Englishto form the argument key representation:?
Active or passive verb voice (ACT/PASS).?
Arg.
position relative to predicate (LEFT/RIGHT).?
Syntactic relation to its governor.?
Preposition used for argument realization.In the example sentences in Section 1, the argu-ment keys for candidate arguments Peter for sen-tences (a) and (c) would be ACT:LEFT:SBJ andPASS:RIGHT:LGS->by,2 respectively.
While aim-ing to increase the purity of argument key clusters,this particular representation will not always pro-duce a good match: e.g.
planning a theft in sen-tence (b) will have the same key as Mary in sen-tence (a).
Increasing the expressiveness of the ar-gument key representation by using features of thesyntactic frame would enable us to distinguish thatpair of arguments.
However, we keep this particularrepresentation, in part to compare with the previouswork.
In German, we do not include the relative po-sition features, because they are not very informativedue to variability in word order.In sum, we treat the unsupervised semantic rolelabeling task as clustering of argument keys.
Thus,argument occurrences in the corpus whose keys areclustered together are assigned the same semanticrole.
The objective of this work is to improve ar-gument key clusterings by inducing them simulta-neously in two languages.3 Monolingual ModelIn this section we describe one of the Bayesian mod-els for semantic role induction proposed in (Titovand Klementiev, 2012).
Before describing ourmethod, we briefly introduce the central compo-nents of the model: the Chinese Restaurant Pro-cesses (CRPs) and Dirichlet Processes (DPs) (Fer-guson, 1973; Pitman, 2002).
For more details werefer the reader to (Teh, 2007).2LGS denotes a logical subject in a passive construction(Surdeanu et al, 2008).3.1 Chinese Restaurant ProcessesCRPs define probability distributions over partitionsof a set of objects.
An intuitive metaphor for de-scribing CRPs is assignment of tables to restaurantcustomers.
Assume a restaurant with a sequence oftables, and customers who walk into the restaurantone at a time and choose a table to join.
The firstcustomer to enter is assigned the first table.
Sup-pose that when a client number i enters the restau-rant, i ?
1 customers are sitting at each of the k ?
(1, .
.
.
,K) tables occupied so far.
The new cus-tomer is then either seated at one of the K tableswith probability Nki?1+?
, where Nk is the number ofcustomers already sitting at table k, or assigned to anew table with the probability ?i?1+?
, ?
> 0.If we continue and assume that for each table ev-ery customer at a table orders the same meal, withthe meal for the table chosen from an arbitrary basedistributionH , then all ordered meals will constitutea sample from the Dirichlet Process DP (?,H).An important property of the non-parametric pro-cesses is that a model designer does not need to spec-ify the number of tables (i.e.
clusters) a-priori as itis induced automatically on the basis of the data andalso depending on the choice of the concentrationparameter ?.
This property is crucial for our task,as the intended number of roles cannot possibly bespecified for every predicate.3.2 The Generative StoryIn Section 2 we defined our task as clustering of ar-gument keys, where each cluster corresponds to asemantic role.
If an argument key k is assigned to arole r (k ?
r), all of its occurrences are labeled r.The Bayesian model encodes two common as-sumptions about semantic roles.
First, it enforces theselectional restriction assumption: namely it stip-ulates that the distribution over potential argumentfillers is sparse for every role, implying that ?peaky?distributions of arguments for each role r are pre-ferred to flat distributions.
Second, each role nor-mally appears at most once per predicate occur-rence.
The inference algorithm will search for aclustering which meets the above requirements tothe maximal extent.The model associates two distributions with eachpredicate: one governs the selection of argument649fillers for each semantic role, and the other mod-els (and penalizes) duplicate occurrence of roles.Each predicate occurrence is generated indepen-dently given these distributions.
Let us describe themodel by first defining how the set of model param-eters and an argument key clustering are drawn, andthen explaining the generation of individual predi-cate and argument instances.
The generative story isformally presented in Figure 1.For each predicate p, we start by generating a par-tition of argument keys Bp with each subset r ?Bp representing a single semantic role.
The parti-tions are drawn from CRP(?)
independently for eachpredicate.
The crucial part of the model is the set ofselectional preference parameters ?p,r, the distribu-tions of arguments x for each role r of predicate p.We represent arguments by lemmas of their syntac-tic heads.3The preference for sparseness of the distributions?p,r is encoded by drawing them from the DP priorDP (?,H(A)) with a small concentration parameter?, the base probability distribution H(A) is just thenormalized frequencies of arguments in the corpus.The geometric distribution ?p,r is used to model thenumber of times a role r appears with a given predi-cate occurrence.
The decision whether to generate atleast one role r is drawn from the uniform Bernoullidistribution.
If 0 is drawn then the semantic role isnot realized for the given occurrence, otherwise thenumber of additional roles r is drawn from the ge-ometric distribution Geom(?p,r).
The Beta priorsover ?
can indicate the preference towards generat-ing at most one argument for each role.Now, when parameters and argument key clus-terings are chosen, we can summarize the remain-der of the generative story as follows.
We begin byindependently drawing occurrences for each predi-cate.
For each predicate role we independently de-cide on the number of role occurrences.
Then eachof the arguments is generated (see GenArgument)by choosing an argument key kp,r uniformly fromthe set of argument keys assigned to the cluster r,and finally choosing its filler xp,r, where the filler isthe lemma of the syntactic head of the argument.3For prepositional phrases, the head noun of the object nounphrase is taken as it encodes crucial lexical information.
How-ever, the preposition is not ignored but rather encoded in thecorresponding argument key, as explained in Section 2.Clustering of argument keys:for each predicate p = 1, 2, .
.
.
:Bp ?
CRP (?)
[partition of arg keys]Parameters:for each predicate p = 1, 2, .
.
.
:for each role r ?
Bp:?p,r ?
DP (?,H(A)) [distrib of arg fillers]?p,r ?
Beta(?0, ?1) [geom distr for dup roles]Data generation:for each predicate p = 1, 2, .
.
.
:for each occurrence s of p:for every role r ?
Bp:if [n ?
Unif(0, 1)] = 1: [role appears at least once]GenArgument(p, r) [draw one arg]while [n ?
?p,r] = 1: [continue generation]GenArgument(p, r) [draw more args]GenArgument(p, r):kp,r ?
Unif(1, .
.
.
, |r|) [draw arg key]xp,r ?
?p,r [draw arg filler]Figure 1: The generative story for predicate-argumentstructure.4 Multilingual ExtensionAs we argued in Section 1, our goal is to penalizefor disagreement in semantic structures predicted foreach language on parallel data.
In doing so, as inmuch of previous work on unsupervised induction oflinguistic structures, we rely on automatically pro-duced word alignments.
In Section 6, we describehow we use word alignment to decide if two argu-ments are aligned; for now, we assume that (noisy)argument alignments are given.Intuitively, when two arguments are aligned inparallel data, we expect them to be labeled with thesame semantic role in both languages.
This corre-spondence is simpler than the one expected in mul-tilingual induction of syntax and morphology wheresystematic but unknown relation between structuresin two language is normally assumed (e.g., (Snyderet al, 2008)).
A straightforward implementation ofthis idea would require us to maintain one-to-onemapping between semantic roles across languages.Instead of assuming this correspondence, we penal-ize for the lack of isomorphism between the sets ofroles in aligned predicates with the penalty depen-dent on the degree of violation.
This softer approach650is more appropriate in our setting, as individual ar-gument keys do not always deterministically map togold standard roles4 and strict penalization wouldresult in the propagation of the corresponding over-coarse clusters to the other language.
Empirically,we observed this phenomenon on the held-out setwith the increase of the penalty weight.Encoding preference for the isomorphism directlyin the generative story is problematic: sparse Dirich-let priors can be used in a fairly trivial way to encodesparsity of the mapping in one direction or anotherbut not in both.
Instead, we formalize this preferencewith a penalty term similar to the expectation criteriain KL-divergence form introduced in McCallum etal.
(2007).
Specifically, we augment the joint proba-bility with a penalty term computed on parallel data:?p(1), p(2)(?
?
(1)?r(1)?Bp(1)fr(1) argmaxr(2)?Bp(2)log P?
(r(2)|r(1))??
(2)?r(2)?Bp(2)fr(2) argmaxr(1)?Bp(1)log P?
(r(1)|r(2))),where P?
(r(l)|r(l?))
is the proportion of times the roler(l?)
of predicate p(l?)
in language l?
is aligned to therole r(l) of predicate p(l) in language l, and fr(l) isthe total number of times the role is aligned, ?
(l) is anon-negative constant.
The rationale for introducingthe individual weighting fr(l) is two-fold.
First, theproportions P?
(r(l)|r(l?))
are more ?reliable?
whencomputed from larger counts.
Second, more fre-quent roles should have higher penalty as they com-pete with the joint probability term, the likelihoodpart of which scales linearly with role counts.Space restrictions prevent us from discussing theclose relation between this penalty formulation andthe existing work on injecting prior and side infor-mation in learning objectives in the form of con-straints (McCallum et al, 2007; Ganchev et al,2010; Chang et al, 2007).In order to support efficient and parallelizable in-ference, we simplify the above penalty by consider-ing only disjoint pairs of predicates, instead of sum-ming over all pairs p(1) and p(2).
When choosing4The average purity for argument keys with automatic argu-ment identification and using predicted syntactic trees, beforeany clustering, is approximately 90.2% on English and 87.8%on German.the pairs, we aim to cover the maximal number ofalignment counts so as to preserve as much informa-tion from parallel corpora as possible.
This objectivecorresponds to the classic maximum weighted bipar-tite matching problem with the weight for each edgep(1) and p(2) equal to the number of times the twopredicates were aligned in parallel data.
We use thestandard polynomial algorithm (the Hungarian algo-rithm, (Kuhn, 1955)) to find an optimal solution.5 InferenceAn inference algorithm for an unsupervised modelshould be efficient enough to handle vast amountsof unlabeled data, as it can easily be obtained and islikely to improve results.
We use a simple approx-imate inference algorithm based on greedy search.We start by discussing search for the maximum a-posteriori clustering of argument keys in the mono-lingual set-up and then discuss how it can be ex-tended to accommodate the role alignment penalty.5.1 Monolingual SettingIn the model, a linking between syntax and seman-tics is induced independently for each predicate.Nevertheless, searching for a MAP clustering canbe expensive: even a move involving a single ar-gument key implies some computations for all itsoccurrences in the corpus.
Instead of more com-plex MAP search algorithms (see, e.g., (Daume III,2007)), we use a greedy procedure where we startwith each argument key assigned to an individualcluster, and then iteratively try to merge clusters.Each move involves (1) choosing an argument keyand (2) deciding on a cluster to reassign it to.
This isdone by considering all clusters (including creatinga new one) and choosing the most probable one.Instead of choosing argument keys randomly atthe first stage, we order them by corpus frequency.This ordering is beneficial as getting clustering rightfor frequent argument keys is more important andthe corresponding decisions should be made earlier.5We used a single iteration in our experiments, as wehave not noticed any benefit from using multiple it-erations.5This has been explored before for shallow semantic rep-resentations (Lang and Lapata, 2011a; Titov and Klementiev,2011).6515.2 Incorporating the Alignment PenaltyInference in the monolingual setting is done inde-pendently for each predicate, as the model factor-izes over the predicates.
The role alignment penaltyintroduces interdependencies between the objectivesfor each bilingual predicate pair chosen by the as-signment algorithm as discussed in Section 4.
Foreach pair of predicates, we search for clusteringsto maximize the sum of the log-probability and thenegated penalty term.At first glance it may seem that the alignmentpenalty can be easily integrated into the greedy MAPsearch algorithm: instead of considering individualargument keys, one could use pairs of argument keysand decide on their assignment to clusters jointly.However, given that there is no isomorphic mappingbetween argument keys across languages, this solu-tion is unlikely to be satisfactory.6 Instead, we usean approximate inference procedure similar in spiritto annotation projection techniques.For each predicate, we first induce semantic rolesindependently for the first language, as describedin Section 5.1, and then use the same algorithm forthe second language but take the penalty term intoaccount.
Then we repeat the process in the reversedirection.
Among these two solutions, we choosethe one which yields the higher objective value.
Inthis way, we begin with producing a clustering forthe side which is easier to cluster and provides moreclues for the other side.76 Empirical EvaluationWe begin by describing the data and evaluation met-rics we use before discussing results.6.1 DataWe run our main experiments on the English-German section of Europarl v6 parallel corpus6We also considered a variation of this idea where a pair ofargument keys is chosen randomly proportional to their align-ment frequency and multiple iterations are repeated.
Despitebeing significantly slower than our method, it did not provideany improvement in accuracy.7In preliminary experiments, we studied an even simpler in-ference method where the projection direction was fixed for allpredicates.
Though this approach did outperform the monolin-gual model, the results were substantially worse than achievedwith our method.
(Koehn, 2005) and the CoNLL 2009 distributionsof the Penn Treebank WSJ corpus (Marcus et al,1993) for English and the SALSA corpus (Burchardtet al, 2006) for German.
As standard for unsuper-vised SRL, we use the entire CoNLL training setsfor evaluation, and use held-out sets for model se-lection and parameter tuning.Syntactic annotation.
Although the CoNLL 2009dataset aleady has predicted dependency structures,we could not reproduce them so that we could usethe same parser to annotate Europarl.
We chose toreannotate it, since using different parsing modelsfor both datasets would be undesirable.
We usedMaltParser (Nivre et al, 2007) for English and thesyntactic component of the LTH system (Johanssonand Nugues, 2008) for German.Predicate and argument identification.
We select allnon-auxiliary verbs as predicates.
For English, weidentify their arguments using a heuristic proposedin (Lang and Lapata, 2011a).
It is comprised of alist of 8 rules, which use nonlexicalized propertiesof syntactic paths between a predicate and a candi-date argument to iteratively discard non-argumentsfrom the list of all words in a sentence.
For Ger-man, we use the LTH argument identification classi-fier.
Accuracy of argument identification on CoNLL2009 using predicted syntactic analyses was 80.7%and 86.5% for English and German, respectively.Argument alignment.
We use GIZA++ (Och andNey, 2003) to produce word alignments in Europarl:we ran it in both directions and kept the intersec-tion of the induced word alignments.
For every ar-gument identified in the previous stage, we chose aset of words consisting of the argument?s syntactichead and, for prepositional phrases, the head nounof the object noun phrase.
We mark arguments intwo languages as aligned if there is any word align-ment between the corresponding sets and if they arearguments of aligned predicates.6.2 Evaluation MetricsWe use the standard purity (PU) and collocation(CO) metrics as well as their harmonic mean (F1) tomeasure the quality of the resulting clusters.
Puritymeasures the degree to which each cluster containsarguments sharing the same gold role:652PU =1N?imaxj|Gj ?
Ci|where Ci is the set of arguments in the i-th inducedcluster, Gj is the set of arguments in the jth goldcluster, and N is the total number of arguments.Collocation evaluates the degree to which argumentswith the same gold roles are assigned to a singlecluster:CO =1N?jmaxi|Gj ?
Ci|We compute the aggregate PU, CO, and F1 scoresover all predicates in the same way as (Lang and La-pata, 2011a) by weighting the scores of each pred-icate by the number of its argument occurrences.Since our goal is to evaluate the clustering algo-rithms, we do not include incorrectly identified ar-guments when computing these metrics.6.3 Parameters and Set-upOur models are robust to parameter settings; the pa-rameters were tuned (to an order of magnitude) tooptimize the F1 score on the held-out developmentset and were as follows.
Parameters governing du-plicate role generation, ?(?
)0 and ?(?
)1 , and penaltyweights ?(?)
were set to be the same for both lan-guages, and are 100, 1.e-3 and 10, respectively.
Theconcentration parameters were set as follows: forEnglish, they were set to ?
(1) = 1.e-3, ?
(1) = 1.e-3,and, for German, they were ?
(2) = 0.1, ?
(2) = 1.Domains of Europarl (parliamentary proceedings)and German/English CoNLL data (newswire) aresubstantially different.
Since the influence of do-main shift is not the focus of work, we try to min-imize its effect by computing the likelihood part ofthe objective on CoNLL data alone.
This also makesour setting more comparable to prior work.86.4 ResultsBase monolingual model.
We begin by evaluat-ing our base monolingual model MonoBayes aloneagainst the current best approaches to unsupervisedsemantic role induction.
Since we do not have ac-cess to the systems, we compare on the marginallydifferent English CoNLL 2008 (Surdeanu et al,8Preliminary experiments on the entire dataset show a slightdegradation in performance.PU CO F1LLogistic 79.5 76.5 78.0GraphPart 88.6 70.7 78.6SplitMerge 88.7 73.0 80.1MonoBayes 88.1 77.1 82.2SyntF 81.6 77.5 79.5Table 1: Argument clustering performance with goldargument identification and gold syntactic parses onCoNLL 2008 shared-task dataset.
Bold-face is used tohighlight the best F1 scores.2008) shared task dataset used in their experiments.We report the results using gold argument identifi-cation and gold syntactic parses in order to focusthe evaluation on the argument labeling stage and tominimize the noise due to automatic syntactic anno-tations.
The methods are Latent Logistic classifica-tion (Lang and Lapata, 2010), Split-Merge cluster-ing (Lang and Lapata, 2011a), and Graph Partition-ing (Lang and Lapata, 2011b) (labeled LLogistic,SplitMerge, and GraphPart, respectively) achievingthe current best unsupervised SRL results in this set-ting.
Additionally, we compute the syntactic func-tion baseline (SyntF), which simply clusters predi-cate arguments according to the dependency relationto their head.
Following (Lang and Lapata, 2010),we allocate a cluster for each of 20 most frequentrelations in the CoNLL dataset and one cluster forall other relations.
Our model substantially outper-forms other models (see Table 1).Multilingual extensions.
Next, we improve ourmodel performance using agreement as an addi-tional supervision signal during training (see Sec-tion 4).
We compare the performance of indi-vidual English and German models induced sepa-rately (MonoBayes) with the jointly induced mod-els (MultiBayes) as well as the syntactic baseline,see Table 2.9 While we see little improvementin F1 for English, the German system improvesby 1.8%.
For German, the crosslingual learningalso results in 1.5% improvement over the syntac-tic baseline, which is considered difficult to outper-form (Grenager and Manning, 2006; Lang and Lap-ata, 2010).
Note that recent unsupervised SRL meth-9Note that the scores are computed on correctly identified ar-guments only, and tend to be higher in these experiments prob-ably because the complex arguments get discarded by the argu-ment identifier.653English GermanPU CO F1 PU CO F1MonoBayes 87.5 80.1 83.6 86.8 75.7 80.9MultiBayes 86.8 80.7 83.7 85.0 80.6 82.7SyntF 81.5 79.4 80.4 83.1 79.3 81.2Table 2: Results on CoNLL 2009 with automatic argu-ment identification and automatic syntactic parses.ods do not always improve on it, see Table 1.The relatively low expressivity and limited purityof our argument keys (see discussion in Section 4)are likely to limit potential improvements when us-ing them in crosslingual learning.
The natural nextstep would be to consider crosslingual learning witha more expressive model of the syntactic frame andsyntax-semantics linking.7 Related WorkUnsupervised learning in crosslingual setting hasbeen an active area of research in recent years.
How-ever, most of this research has focused on induc-tion of syntactic structures (Kuhn, 2004; Snyderet al, 2009) or morphologic analysis (Snyder andBarzilay, 2008) and we are not aware of any pre-vious work on induction of semantic representa-tions in the crosslingual setting.
Learning of se-mantic representations in the context of monolin-gual weakly-parallel data was studied in Titov andKozhevnikov (2010) but their setting was semi-supervised and they experimented only on a re-stricted domain.Most of the SRL research has focused on thesupervised setting, however, lack of annotated re-sources for most languages and insufficient cover-age provided by the existing resources motivatesthe need for using unlabeled data or other formsof weak supervision.
This includes methods basedon graph alignment between labeled and unlabeleddata (Fu?rstenau and Lapata, 2009), using unlabeleddata to improve lexical generalization (Deschachtand Moens, 2009), and projection of annotationacross languages (Pado and Lapata, 2009; van derPlas et al, 2011).
Semi-supervised and weakly-supervised techniques have also been explored forother types of semantic representations but thesestudies again have mostly focused on restricted do-mains (Kate and Mooney, 2007; Liang et al, 2009;Goldwasser et al, 2011; Liang et al, 2011).Early unsupervised approaches to the SRL taskinclude (Swier and Stevenson, 2004), where theVerbNet verb lexicon was used to guide unsuper-vised learning, and a generative model of Grenagerand Manning (2006) which exploits linguistic priorson syntactic-semantic interface.More recently, the role induction problem hasbeen studied in Lang and Lapata (2010) where ithas been reformulated as a problem of detecting al-ternations and mapping non-standard linkings to thecanonical ones.
Later, Lang and Lapata (2011a) pro-posed an algorithmic approach to clustering argu-ment signatures which achieves higher accuracy andoutperforms the syntactic baseline.
In Lang and La-pata (2011b), the role induction problem is formu-lated as a graph partitioning problem: each vertex inthe graph corresponds to a predicate occurrence andedges represent lexical and syntactic similarities be-tween the occurrences.
Unsupervised induction ofsemantics has also been studied in Poon and Domin-gos (2009) and Titov and Klementiev (2011) but theinduced representations are not entirely compatiblewith the PropBank-style annotations and they havebeen evaluated only on a question answering taskfor the biomedical domain.
Also, a related task ofunsupervised argument identification has been con-sidered in Abend et al (2009).8 ConclusionsThis work adds unsupervised semantic role labelingto the list of NLP tasks benefiting from the crosslin-gual induction setting.
We show that an agreementsignal extracted from parallel data provides indi-rect supervision capable of substantially improvinga state-of-the-art model for semantic role induction.Although in this work we focused primarily onimproving performance for each individual lan-guage, cross-lingual semantic representation couldbe extracted by a simple post-processing step.
Infuture work, we would like to model cross-lingualsemantics explicitly.AcknowledgementsThe work was supported by the MMCI Cluster of Excel-lence and a Google research award.
The authors thankMikhail Kozhevnikov, Alexis Palmer, Manfred Pinkal,Caroline Sporleder and the anonymous reviewers for theirsuggestions.654ReferencesOmri Abend, Roi Reichart, and Ari Rappoport.
2009.Unsupervised argument identification for semanticrole labeling.
In ACL-IJCNLP.Roberto Basili, Diego De Cao, Danilo Croce, Bonaven-tura Coppola, and Alessandro Moschitti.
2009.
Cross-language frame semantics transfer in bilingual cor-pora.
In CICLING.A.
Burchardt, K. Erk, A. Frank, A. Kowalski, S. Pado,and M. Pinkal.
2006.
The SALSA corpus: a germancorpus resource for lexical semantics.
In LREC.Ming-Wei Chang, Lev Ratinov, and Dan Roth.2007.
Guiding semi-supervision with constraint-driven learning.
In ACL.Hal Daume III.
2007.
Fast search for dirichlet processmixture models.
In AISTATS.Marie-Catherine de Marneffe, Bill MacCartney, andChristopher D. Manning.
2006.
Generating typeddependency parses from phrase structure parses.
InLREC 2006.Koen Deschacht and Marie-Francine Moens.
2009.Semi-supervised semantic role labeling using the La-tent Words Language Model.
In EMNLP.Thomas S. Ferguson.
1973.
A Bayesian analysis ofsome nonparametric problems.
The Annals of Statis-tics, 1(2):209?230.Hagen Fu?rstenau and Mirella Lapata.
2009.
Graph align-ment for semi-supervised semantic role labeling.
InEMNLP.Kuzman Ganchev, Joao Graca, Jennifer Gillenwater, andBen Taskar.
2010.
Posterior regularization for struc-tured latent variable models.
Journal of MachineLearning Research (JMLR), 11:2001?2049.Qin Gao and Stephan Vogel.
2011.
Corpus expansion forstatistical machine translation with semantic role labelsubstitution rules.
In ACL:HLT.Daniel Gildea and Daniel Jurafsky.
2002.
Automatic la-belling of semantic roles.
Computational Linguistics,28(3):245?288.Dan Goldwasser, Roi Reichart, James Clarke, and DanRoth.
2011.
Confidence driven unsupervised semanticparsing.
In ACL.Trond Grenager and Christoph Manning.
2006.
Un-supervised discovery of a statistical verb lexicon.
InEMNLP.Jan Hajic?, Massimiliano Ciaramita, Richard Johans-son, Daisuke Kawahara, Maria Anto`nia Mart?
?, Llu?
?sMa`rquez, Adam Meyers, Joakim Nivre, SebastianPado?, Jan S?te?pa?nek, Pavel Stran?a?k, Mihai Surdeanu,Nianwen Xue, and Yi Zhang.
2009.
The conll-2009shared task: Syntactic and semantic dependencies inmultiple languages.
In CoNLL 2009: Shared Task.Richard Johansson and Pierre Nugues.
2008.Dependency-based semantic role labeling of Prop-Bank.
In EMNLP.Michael Kaisser and Bonnie Webber.
2007.
Questionanswering based on semantic roles.
In ACL Workshopon Deep Linguistic Processing.Rohit J. Kate and Raymond J. Mooney.
2007.
Learninglanguage semantics from ambigous supervision.
InAAAI.Philipp Koehn.
2005.
Europarl: A parallel corpus forstatistical machine translation.
In Proceedings of theMT Summit.Harold W. Kuhn.
1955.
The hungarian method for theassignment problem.
Naval Research Logistics Quar-terly, 2:83?97.Jonas Kuhn.
2004.
Experiments in parallel-text basedgrammar induction.
In ACL.Joel Lang and Mirella Lapata.
2010.
Unsupervised in-duction of semantic roles.
In ACL.Joel Lang and Mirella Lapata.
2011a.
Unsupervised se-mantic role induction via split-merge clustering.
InACL.Joel Lang and Mirella Lapata.
2011b.
Unsupervisedsemantic role induction with graph partitioning.
InEMNLP.Beth Levin.
1993.
English Verb Classes and Alter-nations: A Preliminary Investigation.
University ofChicago Press.Percy Liang, Michael I. Jordan, and Dan Klein.
2009.Learning semantic correspondences with less supervi-sion.
In ACL-IJCNLP.Percy Liang, Michael Jordan, and Dan Klein.
2011.Learning dependency-based compositional semantics.In ACL: HLT.Ding Liu and Daniel Gildea.
2010.
Semantic role fea-tures for machine translation.
In Coling.Mitchell P. Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1993.
Building a large annotated cor-pus of English: The Penn Treebank.
ComputationalLinguistics, 19(2):313?330.Andrew McCallum, Gideon Mann, and Gregory Druck.2007.
Generalized expectation criteria.
Techni-cal Report TR 2007-60, University of Massachusetts,Amherst, MA.Ryan McDonald, Slav Petrov, and Keith Hall.
2011.Multi-source transfer of delexicalized dependencyparsers.
In EMNLP.J.
Nivre, J.
Hall, S. Ku?bler, R. McDonald, J. Nils-son, S. Riedel, and D. Yuret.
2007.
The CoNLL2007 shared task on dependency parsing.
In EMNLP-CoNLL.Franz Josef Och and Hermann Ney.
2003.
A system-atic comparison of various statistical alignment mod-els.
Computational Linguistics, 29:19?51.655Sebastian Pado and Mirella Lapata.
2009.
Cross-lingualannotation projection for semantic roles.
Journal ofArtificial Intelligence Research, 36:307?340.Jim Pitman.
2002.
Poisson-Dirichlet and GEM invari-ant distributions for split-and-merge transformationsof an interval partition.
Combinatorics, Probabilityand Computing, 11:501?514.Hoifung Poon and Pedro Domingos.
2009.
Unsuper-vised semantic parsing.
In EMNLP.Sameer Pradhan, Wayne Ward, and James H. Martin.2008.
Towards robust semantic role labeling.
Com-putational Linguistics, 34:289?310.M.
Sammons, V. Vydiswaran, T. Vieira, N. Johri,M.
Chang, D. Goldwasser, V. Srikumar, G. Kundu,Y.
Tu, K. Small, J.
Rule, Q.
Do, and D. Roth.
2009.Relation alignment for textual entailment recognition.In Text Analysis Conference (TAC).Dan Shen and Mirella Lapata.
2007.
Using semanticroles to improve question answering.
In EMNLP.Benjamin Snyder and Regina Barzilay.
2008.
Unsuper-vised multilingual learning for morphological segmen-tation.
In ACL.Benjamin Snyder and Regina Barzilay.
2010.
Climbingthe tower of Babel: Unsupervised multilingual learn-ing.
In ICML.Benjamin Snyder, Tahira Naseem, Jacob Eisenstein, andRegina Barzilay.
2008.
Unsupervised multilinguallearning for POS tagging.
In EMNLP.Benjamin Snyder, Tahira Naseem, and Regina Barzilay.2009.
Unsupervised multilingual grammar induction.In ACL.Mihai Surdeanu, Adam Meyers Richard Johansson, Llu?
?sMa`rquez, and Joakim Nivre.
2008.
The CoNLL-2008shared task on joint parsing of syntactic and semanticdependencies.
In CoNLL 2008: Shared Task.Richard Swier and Suzanne Stevenson.
2004.
Unsuper-vised semantic role labelling.
In EMNLP.Yee Whye Teh.
2007.
Dirichlet process.
Encyclopediaof Machine Learning.Ivan Titov and Alexandre Klementiev.
2011.
A Bayesianmodel for unsupervised semantic parsing.
In ACL.Ivan Titov and Alexandre Klementiev.
2012.
A Bayesianapproach to unsupervised semantic role induction.
InEACL.Ivan Titov and Mikhail Kozhevnikov.
2010.
Bootstrap-ping semantic analyzers from non-contradictory texts.In ACL.Lonneke van der Plas, Paola Merlo, and James Hender-son.
2011.
Scaling up automatic cross-lingual seman-tic role annotation.
In ACL.Dekai Wu and Pascale Fung.
2009.
Semantic roles forSMT: A hybrid two-pass model.
In NAACL.Dekai Wu, Marianna Apidianaki, Marine Carpuat, andLucia Specia, editors.
2011.
Proc.
of Fifth Work-shop on Syntax, Semantics and Structure in StatisticalTranslation.
ACL.656
