Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on SemanticEvaluation (SemEval 2013), pages 684?688, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational LinguisticsUColorado SOM: Extraction of Drug-Drug Interactions from BioMedicalText using Knowledge-rich and Knowledge-poor FeaturesNegacy D. Hailu Lawrence E. Hunter K. Bretonnel Cohennegacy.hailu@ucdenver.edu larry.hunter@ucdenver.edu kevin.cohen@gmail.comUniversity of Colorado, Anschutz Medical CampusAbstractIn this paper, we present our approach toSemEval-2013 Task 9.2.
It is a feature richclassification using LIBSVM for Drug-DrugInteractions detection in the BioMedical do-main.
The features are extracted consideringmorphosyntactic, lexical and semantic con-cepts.
Tools like openDMAP and TEES areused to extract semantic concepts from thecorpus.
The best F-score that we got for Drug-Drug Interaction (DDI) detection is 50% and61% and the best F-score for DDI detectionand classification is 34% and 48% for test anddevelopment data respectively.Keywords: text mining, event extraction, ma-chine learning, feature extraction.1 IntroductionOur approach to the Semeval 2013 drug-drug in-teraction task explored the potential for integrat-ing knowledge-based approaches with supervisedmachine learning.
In practice, most supervisedmachine learning systems are actually hybrids ofmachine learning and some knowledge-based ap-proach.
However, the integration between the twois typically quite loose, with the knowledge-basedapproach being realized either as heuristic pre-processing or post-processing of the results.
Thework reported here is an attempt to make a tightercoupling between knowledge-based methods andmachine learning.
In particular, we took the ap-proach of using knowledge-based methods for fea-ture extraction.2 MethodologyIn this challenge we approach the Drug-Drug inter-action task 9.2 as a binary classification problem.
Apair of drugs is interacting if there is some kind ofinfluence between the two.
Our approach for Drug-Drug interaction extraction 2013 mainly makes useof domain specific morphosyntactic, lexical and se-mantic features between paired drugs.We applied Machine Learning classification tech-niques in order to determine whether a pair of drugswithin a biomedical text is interacting or not.
For atraining set of labeled instances(Xi, yi)= 1, 2, ..., lwhere Xi ?
Rn and y ?
{1,?1}l, the support vectormachines (SVMs) optimization problem is definedas(Boser et al 1992) (Cortes and Vapnik , 1995):??
= argmax?,w,b(12W TW + Cl?i=1?i)(1)such that yi(W T?
(Xi) + b)> 1?
?i,?i ?
0.2.1 MaterialsThe corpus is provided from two data sources.
Thereare 572 documents describing drug-drug interac-tions from the DrugBank database and 142 abstractson the subject of drug-drug interactions from Med-Line (Isabel et.al., 2011).
We prepared datasetsfor the entire corpus.
Each instance in the datasetis a set of paired drugs.
In our dataset, there are27787 instances.
93.57% of them are from Drug-bank database and the remaining are from MedLineabstracts.
DDI shared task 2013 is not only interac-tion detection but the challenge also includes detec-684tion of the type of interaction.
In our approach, wetreated each interaction type as one class.2.2 MethodsLIBSVM is a library for support vector machines (LIBSVM, 2011).
We used this tool for classify-ing the dataset.
Basically, the problem is a multi-class classification problem.
We applied the conceptof one-vs-all multi-class classification technique tohandle the multiple classes.2.3 Feature ExtractionThe features that we extracted for this challenge canbe categorized into three types:2.3.1 Morphosyntactic Features?
Distance feature: this is distance betweenpaired drugs in number of words.
The intuitionhere is that the closer two drugs are, the morechance that they might be interacting.
Sincethis feature takes word count as its value, thetext is split within white space when countingnumber of words.
Punctuation marks are notconsidered when counting words.?
Part-Of-Speech tags: we chose the GENIAdependency parser for parsing the corpus fortwo reasons.?
Dependency parser related features: we con-struct the dependency tree using the GENIAdependency parser.
Two features are extractedfrom the tree:?
Presence of interaction word in the pathfrom the target drug node to the root ofthe tree.?
Distance from one target drug name toanother one in the tree.2.3.2 Lexical Features?
Bigrams: a sequence of bigrams is ex-tracted for input text.2.3.3 Semantic Features?
Interaction words: we collected the top100 words that indicate drug-drug inter-action.
The presence of these words isone feature for our system.
The words arechecked before and after each target drug.Such words include: increase, decrease,inhibit, interaction, reduce, affect.?
Presence of preposition within targetdrugs: the text within the target drugs istested to see if it has preposition or not.
Ifthe text has a preposition, the value is 1otherwise it will have zero value.?
Presence of other drugs within targetdrugs: firstly, we collect all drug namesinto a list.
The text within the target drugsis searched for the drug names and thevalue for this feature will have the num-ber of hits.?
Concept from OpenDMAP:OpenDMAP is an ontology-driven,rule-based concept analysis and infor-mation extraction system (Hunter et.al.,2008).
We used openDMAP to extractdrug-drug interaction concepts from theDDI2013 corpus.
We extracted patternbased features using OpenDMAP only ifOpenDMAP recognizes target drugs.3 Dataset PreparationThe challenge provided datasets from Drug-Bank database and MedLine abstracts.
We splitthe dataset into 20% development data and 80%training data.
Table1 shows the percentage ofpositive instances in the dataset.DDI interaction 14.47%Interaction type effect 6.07%Interaction type advise 2.97%Interaction type mechanism 4.75%Interaction type int 0.68%Table 1: positive instances for the different class typesThe data is not balanced, as shown in table 1.We penalized the negative classes during train-ing in order to balance the data.In section 4 we present results for three runs.Run1 includes the basic features which are de-scribed in section 2.3.
In Run2 we included fea-ture values made available by TEES ( Bjo?rne685et.al., 2011).
In addition to the features in thefirst two runs, in Run3 the list of interactionwords were considered individually as features.In this run, weight penalty and different opti-mized LIBSVM parameters were considered.4 ResultsTable 2 shows the results for DDI detectiononly, for both development and test data.
Thebest F1 score is 50% for test data and 61% fordevelopment data.Runs1 2 3test dataprecision 0.37 0.38 0.4recall 0.73 0.75 0.64F1 0.49 0.5 0.49development dataprecision 0.28 0.82 0.62recall 0.78 0.46 0.59F1 0.41 0.59 0.61Table 2: Partial Evaluation: only detection of DDITable 3 shows results for DDI detection andclassification.
The best F1 score is 34% for testdata and 48% for development data.Runs1 2 3test dataprecision 0.16 0.25 0.27recall 0.32 0.5 0.44F1 0.21 0.33 0.34development dataprecision 0.13 0.59 0.49recall 0.37 0.33 0.46F1 0.2 0.42 0.48Table 3: Detection and classification of DDIAnd finally, the scores for the individual DDItype for the best run are shown in table 4.
Ap-parently, Run3 outperforms in all the scores ascan be seen in tables 2 through 4.Run3precision recall F1test datamechanism 0.39 0.29 0.33effect 0.21 0.63 0.31advise 0.45 0.39 0.42int 0.4 0.28 0.334development datamechanism 0.5 0.29 0.37effect 0.44 0.61 0.51advise 0.72 0.46 0.56int 0.08 0.1 0.09Table 4: Best scores for DDI type, Run35 DiscussionGenerally speaking, the performance of oursystem is better for DDI detection regardless oftheir types compared to classifying what kindof DDI they are.Among the three runs that we submitted for thechallenge, Run3 outperforms in all the scoresas can be seen in tables 2 through 4 for the fol-lowing reasons:?
weight penalty techniques are applied inRun3?
optimal cost and gamma parameters areselected while training for Run3?
Bag of interaction words are consideredas individual features.
This specially in-creases scores for detecting the individualDDI types.The best F-score that we got for DDI detec-tion is 61% for development data and 50% fortest data as shown in Table 2.
The reason whyscores are better for DDI detection is that ourapproach is feature rich DDI detection and webelieve that our features mainly target detect-ing DDIs.
A further addition of features thatdistinguishes the DDI types will hopefully im-prove the scores for DDI classification.
On theother hand, it has been observed that scores arelower for test data compared to developmentdata.
And the reason for this is due to opti-mization parameters that we heuristically choseduring training are possibly favoring to devel-opment data than to test data.
Another possiblereason could be overfitting.As shown in section 4, the knowledge-basedlexical features produced our best run.
The se-mantic parser made a smaller contribution toperformance, almost certainly because of lowcoverage- - -historically, in past shared taskson information extraction, its behavior has beencharacterized by very high precision but low re-call.5.1 Error AnalysisTable 5 shows false positive predictions col-lected from the results for Run3.
In FP-1, thesystem predicts detecting the first pair (etan-ercept and anakinra) correctly and then clas-sifying as type effect but it failed to deter-mine whether etanercept is interacting with686interleukin-1 antagonist.
A close examina-tion of this sentence shows that the last twodrugs are separated by parentheses and in factthe last drug is a further explanation of thesecond one.
The system couldn?t distinguishthis concept ?
rather it is treating all the threedrugs separately and both pairs i.e.
(etanercept,anakinra) and (etanercept, interleukin-1 antag-onist) are predicted the same.
This is happeningdue the syntactic nature of the text.
One possi-ble way to avoid such confusion is to expandthe sentence.
In other words, we believe initialdata clean up might improve the performanceof the system.
Avoiding punctuation markssuch as parenthesis for this case and other de-limiters and representing them in words if pos-sible might improve the performance of theclassifier.It is also observed that there is poor predictionfor pairs of drugs that have negation.
The twoexamples, i.e.
FP-2 and FP-3 in table 5 arewrongly predicted because there is no featurethat handles negation in the system.FP-1 Concurrent administration of etanercept(another TNF -blocking agent) and anakinra(an interleukin-1 antagonist) has been as-sociated with an increased risk of serious in-fections, and increased risk of neutropeniaand no additional benefit compared to thesem edicinal products alone.FP-2 When used in external subcutaneous infu-sion pumps for insulin, NovoLog should notbe mixed with any other insulins or diluent.FP-3 With the exception of albuterol, there areno formal studies fully evaluating the in-teraction effects of ATROVENT InhalationAerosol and these drugs with respect to ef-fectiveness.Table 5: False positive samples.
In this table false positive DDIs are in bold font.False negative predictions have a negative ef-fect on the recall evaluation parameter.
In ta-ble 6 we show false negative predictions andtheir possible analysis for the developmentdata.
A close analysis of FN-1 and FN-2 showsthat both sentences have a comma between thepaired drugs.
From a linguistic point of view,the punctuation mark comma can be used toseparate interdependent clauses.
Represent-ing this dependency as a feature might help toavoid false negatives.
FN-3 are a bit differ-ent and it apprears that there is much knowl-edge that can be extracted from the given textwhich is in number format.
Currently, the fea-tures that we have don?t extract informationwritten in numbers.
Also, the list of interac-tion words doesn?t include words like admin-istered, administration though words like co-administration, coadministered are included.A further development of the list of interactionwords will avoid such false predictions.FN-1 Anticholinergic agents: Although iprat-ropium bromide is minimally absorbed intothe systemic circulation, there is some poten-tial for an additive interaction with concomi-tantly used anticholinergic medications.FN-2 Lymphocytopenia has been reported in pa-tients receiving CAMPTOSAR, and it ispossible that the administration of dexam-ethasone as antiemetic prophylaxis mayhave enhanced the likelihood of this effect.FN-3 Betaseron administration to three cancer pa-tients over a dose range of 0.025 mg to2.2 mg led to a dose-dependent inhibitionof antipyrine elimination.14 The effect ofalternate-day administration of 0.25 mg ofBetaseron on drug metabolism in MS pa-tients is unknown.Table 6: False negative samples.
In this table false negative DDIs are in bold format.6 ConclusionOur approach to Extraction of Drug-Drug In-teractions from BioMedical Texts task 9.2 is afeature rich SVM classification.
The perfor-mance on detecting Drug-Drug interactions isencouraging but it is a bit lower when it comesto further classfying the type of the interaction.As described in section 5.1, addition of fea-tures such as negation will reduce false posi-tive prediction and this will increase precisionscore.
Further development of the list of inter-action words is also a important task to handlethe different forms of words that could indicatean interaction type.
We have also observed thatpattern-based semantic features are not well ex-tracted in our system.687ReferencesSegura-Bedmar, I., Mart?
?nez, P, Herrero-Zazo, M.SemEval-2013 Task 9: Extraction of Drug-DrugInteractions from Biomedical Texts.
In Proceed-ings of the 7th International Workshop on SemanticEvaluation (SemEval 2013)Chang, Chih-Chung and Lin, Chih-Jen 2011.
LIB-SVM: A library for support vector machines, vol-ume 2.
Software available at http://www.csie.ntu.edu.tw/?cjlin/libsvmHunter, L, Z Lu, J Firby, WA Baumgartner, Jr., HLJohnson, PV Ogren, KB Cohen.
.
OpenDMAP: Anopen-source, ontology-driven concept analysis en-gine, with applications to capturing knowledge re-garding protein transport, protein interactions andcell-type-specific gene expression.
BMC Bioinfor-matics 2008, 9:78.Jari Bjo?rne, Filip Ginter, Juho Heimonen, AnttiAirola, Tapio Pahikkala and Tapio Salakoski.2011.
TEES: Event Extraction Software.
Softwareavailable at http://jbjorne.github.com/TEES/Isabel Segura-Bedmar, Paloma Mart?
?nez, Cesar dePablo-sachnez Using a shallow linguistic kernel fordrug-drug interaction Extraction.
2011.
Journal ofBiomedical Informatics, 44(5):789-804..Boser, Bernhard E. and Guyon, Isabelle M. andVapnik, Vladimir N. A training algorithm for opti-mal margin classifiers.
Proceedings of the fifth an-nual workshop on Computational learning theory.C.
Cortes and V. Vapnik.
Support-vector network.Machine Learning, 20:273-297Isabel Segura-Bedmar, Paloma Mart?
?nez, andDaniel Sa?nchez-Cisneros The 1st DDIExtraction-2011 challenge task: Extraction of Drug-Drug In-teractions from biomedical texts Proceedings of the1st Challenge task on Drug-Drug Interaction Ex-tractionPhilippe Thomas, Mariana Neves, Illes Solt,Domonkos Tikk, and Ulf Leser.
Relation Extractionfor Drug-Drug Interactions using Ensemble Learn-ing Proceedings of the 1st Challenge task on Drug-Drug Interaction ExtractionMd.
Faisal Mahbub Chowdhury, Asma BenAbacha, Alberto Lavelli, and Pierre Zweigenbau.Two Different Machine Learning Techniques forDrug-drug Interaction Extraction Proceedings ofthe 1st Challenge task on Drug-Drug InteractionExtractionMd.
Faisal Mahbub Chowdhury, and AlbertoLavelli.
Drug-drug Interaction Extraction UsingComposite Kernels Proceedings of the 1st Chal-lenge task on Drug-Drug Interaction ExtractionJari Bjo?rne, Antti Airola, Tapio Pahikkala, andTapio Salakoski Drug-Drug Interaction Extractionwith RLS and SVM Classiffers Proceedings of the1st Challenge task on Drug-Drug Interaction Ex-tractionJAnne-Lyse Minard, Anne-Laure Ligozat, BrigitteGrau, and Lamia Makour Feature selection forDrug-Drug Interaction detection using machine-learning based approaches Proceedings of the 1stChallenge task on Drug-Drug Interaction Extrac-tionSandra Garcia-Blasco, Santiago M. Mola-Velasco,Roxana Danger, and Paolo Rosso Automatic Drug-Drug Interaction Detection: A Machine LearningApproach With Maximal Frequent Sequence Ex-traction Proceedings of the 1st Challenge task onDrug-Drug Interaction ExtractionJacinto Mata Va?zquez, Ramo?n Santano, DanielBlanco, Marcos Lucero, and Manuel J.
Man?a Lo?pezA machine learning approach to extract drugdruginteractions in an unbalanced cataset Proceedingsof the 1st Challenge task on Drug-Drug InteractionExtractionStefania Rubrichi, Matteo Gabetta, RiccardoBellazzi, Cristiana Larizza, and Silvana QuagliniDrug-Drug Interactions Discovery Based on CRFsSVMs and Rule-Based Methods Proceedings ofthe 1st Challenge task on Drug-Drug InteractionExtractionMan Lan, Jiang Zhao, Kezun Zhang, Honglei Shi,and Jingli Cai An experimental exploration of drug-drug interaction extraction from biomedical textsProceedings of the 1st Challenge task on Drug-Drug Interaction ExtractionShreyas Karnik, Abhinita Subhadarshini, ZhipingWang, Luis Rocha and Lang Li Extraction of drug-drug interactions using all paths graph kernel Pro-ceedings of the 1st Challenge task on Drug-DrugInteraction Extraction688
