Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1128?1137,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsCross-Lingual Latent Topic ExtractionDuo ZhangUniversity of Illinois atUrbana-Champaigndzhang22@cs.uiuc.eduQiaozhu MeiUniversity of Michiganqmei@umich.eduChengXiang ZhaiUniversity of Illinois atUrbana-Champaignczhai@cs.uiuc.eduAbstractProbabilistic latent topic models have re-cently enjoyed much success in extractingand analyzing latent topics in text in an un-supervised way.
One common deficiencyof existing topic models, though, is thatthey would not work well for extractingcross-lingual latent topics simply becausewords in different languages generally donot co-occur with each other.
In this paper,we propose a way to incorporate a bilin-gual dictionary into a probabilistic topicmodel so that we can apply topic models toextract shared latent topics in text data ofdifferent languages.
Specifically, we pro-pose a new topic model called Probabilis-tic Cross-Lingual Latent Semantic Anal-ysis (PCLSA) which extends the Proba-bilistic Latent Semantic Analysis (PLSA)model by regularizing its likelihood func-tion with soft constraints defined based ona bilingual dictionary.
Both qualitative andquantitative experimental results show thatthe PCLSA model can effectively extractcross-lingual latent topics from multilin-gual text data.1 IntroductionAs a robust unsupervised way to perform shallowlatent semantic analysis of topics in text, prob-abilistic topic models (Hofmann, 1999a; Blei etal., 2003b) have recently attracted much atten-tion.
The common idea behind these models is thefollowing.
A topic is represented by a multino-mial word distribution so that words characteriz-ing a topic generally have higher probabilities thanother words.
We can then hypothesize the exis-tence of multiple topics in text and define a gener-ative model based on the hypothesized topics.
Byfitting the model to text data, we can obtain an es-timate of all the word distributions correspondingto the latent topics as well as the topic distributionsin text.
Intuitively, the learned word distributionscapture clusters of words that co-occur with eachother probabilistically.Although many topic models have been pro-posed and shown to be useful (see Section 2 formore detailed discussion of related work), mostof them share a common deficiency: they are de-signed to work only for mono-lingual text data andwould not work well for extracting cross-linguallatent topics, i.e.
topics shared in text data intwo different natural languages.
The deficiencycomes from the fact that all these models rely onco-occurrences of words forming a topical cluster,but words in different language generally do notco-occur with each other.
Thus with the existingmodels, we can only extract topics from text ineach language, but cannot extract common topicsshared in multiple languages.In this paper, we propose a novel topic model,called Probabilistic Cross-Lingual Latent Seman-tic Analysis (PCLSA) model, which can be used tomine shared latent topics from unaligned text datain different languages.
PCLSA extends the Proba-bilistic Latent Semantic Analysis (PLSA) modelby regularizing its likelihood function with softconstraints defined based on a bilingual dictio-nary.
The dictionary-based constraints are key tobridge the gap of different languages and wouldforce the captured co-occurrences of words ineach language by PCLSA to be ?synchronized?so that related words in the two languages wouldhave similar probabilities.
PCLSA can be esti-mated efficiently using the General Expectation-Maximization (GEM) algorithm.
As a topic ex-traction algorithm, PCLSA would take a pair ofunaligned document sets in different languagesand a bilingual dictionary as input, and output aset of aligned word distributions in both languagesthat can characterize the shared topics in the twolanguages.
In addition, it also outputs a topic cov-1128erage distribution for each language to indicate therelative coverage of different shared topics in eachlanguage.To the best of our knowledge, no previous workhas attempted to solve this topic extraction prob-lem and generate the same output.
The closestexisting work to ours is the MuTo model pro-posed in (Boyd-Graber and Blei, 2009) and theJointLDA model published recently in (Jagarala-mudi and Daume?
III, 2010).
Both used a bilingualdictionary to bridge the language gap in a topicmodel.
However, the goals of their work are dif-ferent from ours in that their models mainly focuson mining cross-lingual topics of matching wordpairs and discovering the correspondence at thevocabulary level.
Therefore, the topics extractedusing their model cannot indicate how a commontopic is covered differently in the two languages,because the words in each word pair share thesame probability in a common topic.
Our work fo-cuses on discovering correspondence at the topiclevel.
In our model, since we only add a soft con-straint on word pairs in the dictionary, their prob-abilities in common topics are generally different,naturally capturing which shows the different vari-ations of a common topic in different languages.We use a cross-lingual news data set and a re-view data set to evaluate PCLSA.
We also proposea ?cross-collection?
likelihood measure to quanti-tatively evaluate the quality of mined topics.
Ex-perimental results show that the PCLSA modelcan effectively extract cross-lingual latent topicsfrom multilingual text data, and it outperforms abaseline approach using the standard PLSA on textdata in each language.2 Related WorkMany topic models have been proposed, and thetwo basic models are the Probabilistic Latent Se-mantic Analysis (PLSA) model (Hofmann, 1999a)and the Latent Dirichlet Allocation (LDA) model(Blei et al, 2003b).
They and their extensionshave been successfully applied to many prob-lems, including hierarchical topic extraction (Hof-mann, 1999b; Blei et al, 2003a; Li and McCal-lum, 2006), author-topic modeling (Steyvers et al,2004), contextual topic analysis (Mei and Zhai,2006), dynamic and correlated topic models (Bleiand Lafferty, 2005; Blei and Lafferty, 2006), andopinion analysis (Mei et al, 2007; Branavan et al,2008).
Our work is an extension of PLSA by in-corporating the knowledge of a bilingual dictio-nary as soft constraints.
Such an extension is sim-ilar to the extension of PLSA for incorporating so-cial network analysis (Mei et al, 2008a) but ourconstraint is different.Some previous work on multilingual topic mod-els assume documents in multiple languages arealigned either at the document level, sentence levelor by time stamps (Mimno et al, 2009; Zhao andXing, 2006; Kim and Khudanpur, 2004; Ni et al,2009; Wang et al, 2007).
However, in many ap-plications, we need to mine topics from unalignedtext corpus.
For example, mining topics fromsearch results in different languages can facilitatesummarization of multilingual search results.Besides all the multilingual topic modelingwork discussed above, comparable corpora havealso been studied extensively (e.g.
(Fung, 1995;Franz et al, 1998; Masuichi et al, 2000; Sadatet al, 2003; Gliozzo and Strapparava, 2006)), butmost previous work aims at acquiring word trans-lation knowledge or cross-lingual text categoriza-tion from comparable corpora.
Our work differsfrom this line of previous work in that our goal isto discover shared latent topics from multi-lingualtext data that are weakly comparable (e.g.
the datadoes not have to be aligned by time).3 Problem FormulationIn general, the problem of cross-lingual topic ex-traction can be defined as to extract a set of com-mon cross-lingual latent topics covered in text col-lections in different natural languages.
A cross-lingual latent topic will be represented as a multi-nomial word distribution over the words in allthe languages, i.e.
a multilingual word distri-bution.
For example, given two collections ofnews articles in English and Chinese, respectively,we would like to extract common topics simul-taneously from the two collections.
A discov-ered common topic, such as the terrorist attackon September 11, 2001, would be characterizedby a word distribution that would assign relativelyhigh probabilities to words related to this event inboth English and Chinese (e.g.
?terror?, ?attack?,?afghanistan?, ?taliban?, and their translations inChinese).As a computational problem, our input is amulti-lingual text corpus, and output is a set ofcross-lingual latent topics.
We now define thisproblem more formally.1129Definition 1 (Multi-Lingual Corpus) A multi-lingual corpus C is a set of text collections{C1, C2, .
.
.
, Cs}, where Ci = {di1, di2, .
.
.
, diMi}is a collection of documents in language Li withvocabulary Vi = {wi1, wi2, .
.
.
, wiNi}.
Here, Mi isthe total number of documents in Ci, Ni is the to-tal number of words in Vi, and dij is a document incollection Ci.Following the common assumption of bag-of-words representation, we represent document dijwith a bag of words {wij1 , wij2 , .
.
.
, wijd}, and usec(wik, dij) to denote the count of word wik in docu-ment dij .Definition 2 (Cross-Lingual Topic): A cross-lingual topic ?
is a semantically coherent multi-nomial distribution over all the words in the vo-cabularies of languages L1, ..., Ls.
That is, p(w|?
)would give the probability of a word w which canbe in any of the s languages under consideration.
?is semantically coherent if it assigns high probabil-ities to words that are semantically related either inthe same language or across different languages.Clearly, we have?si=1?w?Vi p(w|?)
= 1 for anycross-lingual topic ?.Definition 3 (Cross-Lingual Topic Extrac-tion) Given a multi-lingual corpus C, the task ofcross-lingual topic extraction is to model and ex-tract k major cross-lingual topics {?1, ?2, .
.
.
, ?k}from C, where ?i is a cross-lingual topic, and k isa user specified parameter.The extracted cross-lingual topics can be di-rectly used as a summary of the common con-tent of the multi-lingual data set.
Note that oncea cross-lingual topic is extracted, we can eas-ily obtain its representation in each language Liby ?splitting?
the cross-lingual topic into multi-ple word distributions in different languages.
For-mally, the word distribution of a cross-lingualtopic ?
in language Li is given by pi(wi|?)
=p(wi|?)?w?Vip(w|?)
.These aligned language-specific word distribu-tions can directly review the variations of topicsin different languages.
They can also be used toanalyze the difference of the coverage of the sametopic in different languages.
Moreover, they arealso useful for retrieving relevant articles or pas-sages in each language and aligning them to thesame common topic, thus essentially also allow-ing us to integrate and align articles in multiplelanguages.4 Probabilistic Cross-Lingual LatentSemantic AnalysisIn this section, we present our probabilistic cross-lingual latent semantic analysis (PCLSA) modeland discuss how it can be used to extract cross-lingual topics from multi-lingual text data.The main reason why existing topic modelscan?t be used for cross-lingual topic extraction isbecause they cannot cross the language barrier.Intuitively, in order to cross the language barrierand extract a common topic shared in articles indifferent languages, we must rely on some kindof linguistic knowledge.
Our PCLSA model as-sumes the availability of bi-lingual dictionaries forat least some language pairs, which are generallyavailable for major language pairs.
Specifically,for text data in languages L1, ..., Ls, if we rep-resent each language as a node in a graph andconnect those language pairs for which we have abilingual dictionary, the minimum requirement isthat the whole graph is connected.
Thus, as a min-imum, we will need s?
1 distinct bilingual dictio-naries.
This is so that we can potentially cross allthe language barriers.Our key idea is to ?synchronize?
the extractionof monolingual ?component topics?
of a cross-lingual topic from individual languages by forcinga cross-lingual topic word distribution to assignsimilar probabilities to words that are potentialtranslations according to a Li-Lj bilingual dictio-nary.
We achieve this by adding such preferencesformally to the likelihood function of a probabilis-tic topic model as ?soft constraints?
so that whenwe estimate the model, we would try to not onlyfit the text data well (which is necessary to extractcoherent component topics from each language),but also satisfy our specified preferences (whichwould ensure the extracted component topics indifferent languages are semantically related).
Be-low we present how we implement this idea inmore detail.A bilingual dictionary for languages Li and Ljgenerally would give us a many-to-many map-ping between the vocabularies of the two lan-guages.
With such a mapping, we can constructa bipartite graph Gij = (Vij , Eij) between thetwo languages where if one word can be poten-tially translated into another word, the two wordswould be connected with an edge.
An edge canbe weighted based on the probability of the cor-responding translation.
An example graph for1130Chinese-English dictionary is shown in Figure 1.Figure 1: A Dictionary based Word GraphWith multiple bilingual dictionaries, we canmerge the graphs to generate a multi-partite graphG = (V,E).
Based on this graph, the PCLSAmodel extends the standard PLSA by adding aconstraint to the likelihood function to ?smooth?the word distributions of topics in PLSA on themulti-partite graph so that we would encourage thewords that are connected in the graph (i.e.
pos-sible translations of each other) to be given simi-lar probabilities by every cross-lingual topic.
Thuswhen a cross-lingual topic picks up words that co-occur in mono-lingual text, it would prefer pick-ing up word pairs whose translations in other lan-guages also co-occur with each other, giving us acoherent multilingual word distribution that char-acterizes well the content of text in different lan-guages.Specifically, let ?
= {?j} (j = 1, ..., k) be a setof k cross-lingual topic models to be discoveredfrom a multilingual text data set with s languagessuch that p(w|?i) is the probability of word w ac-cording to the topic model ?i.If we are to use the regular PLSA to model ourdata, we would have the following log-likelihoodand we usually use a maximum likelihood estima-tor to estimate parameters and discover topics.L(C) =s?i=1?d?Ci?wc(w, d) logk?j=1p(?j |d)p(w|?j)Our main extension is to add to L(C) a cross-lingual constraint term R(C) to incorporate theknowledge of bilingual dictionaries.
R(C) is de-fined asR(C) = 12??u,v?
?Ew(u, v)k?j=1(p(wu|?j)Deg(u) ?p(wv|?j)Deg(v) )2where w(u, v) is the weight on the edge betweenu and v in the multi-partite graph G = (V,E),which in our experiments is set to 1, and Deg(u)is the degree of word u, i.e.
the sum of the weightsof all the edges ending with u.Intuitively, R(C) measures the difference be-tween p(wu|?j) and p(wv|?j) for each pair (u, v)in a bilingual dictionary; the more they differ, thelarger R(C) would be.
So it can be regarded asa ?loss function?
to help us assess how well the?component word distributions?
in multiple lan-guages are correlated semantically.
Clearly, wewould like the extracted topics to have a smallR(C).
We choose this specific form of loss func-tion because it would make it convenient to solvethe optimization problem of maximizing the cor-responding regularized maximum likelihood (Meiet al, 2008b).
The normalization with Deg(u)and Deg(v) can be regarded as a way to compen-sate for the potential ambiguity of u and v in theirtranslations.Putting L(C) and R(C) together, we wouldlike to maximize the following objective functionwhich is a regularized log-likelihood:O(C, G) = (1 ?
?)L(C)?
?R(C) (1)where ?
?
(0, 1) is a parameter to balance thelikelihood and the regularizer.
When ?
= 0, werecover the standard PLSA.Specifically, we will search for a set of valuesfor all our parameters that can maximize the ob-jective function defined above.
Our parametersinclude all the cross-lingual topics and the cov-erage distributions of the topics in all documents,which we denote by ?
= {p(w|?j), p(?j |d)}d,w,jwhere j = 1, ..., k, w varies over the entire vo-cabularies of all the languages , d varies overall the documents in our collection.
This opti-mization problem can be solved using a General-ized Expectation-Maximization (GEM) algorithmas described in (Mei et al, 2008a).Specifically, in the E-step of the algorithm, thedistribution of hidden variables is computed usingEq.
2.z(w, d, j) = p(?j |d)p(w|?j)?j?
p(?j?
|d)p(w|?j?
)(2)Then in the M-step, we need to maximize thecomplete data likelihood Q(?;?n):Q(?
;?n) = (1?
?)L?(C)?
?R(C)1131whereL?
(C) =?d?wc(w, d)?jz(w, d, j) log p(?j |d)p(w|?j), (3)with the constraints that?j p(?j |d) = 1 and?w p(w|?j) = 1.There is a closed form solution if we only wantto maximize the L?
(C) part:p(n+1)(?j |d) =?w c(w, d)z(w, d, j)?w?j?
c(w, d)z(w, d, j?
)p(n+1)(w|?j) =?d c(w, d)z(w, d, j)?d?
?w c(w?, d)z(w?, d, j)(4)However, there is no closed form solution in theM-step for the whole objective function.
Fortu-nately, according to GEM we do not need to findthe local maximum of Q(?
;?n) in every M-step,and we only need to find a new value ?n+1 to im-prove the complete data likelihood, i.e.
to makesure Q(?n+1; ?n) ?
Q(?n; ?n).
So our methodis to first maximize the L?
(C) part using Eq.
4 andthen use Eq.
5 to gradually increase the R(C) part.p(t+1)(wu|?j) = (1?
?
)p(t)(wu|?j) (5)+ ???u,v?
?Ew(u, v)Deg(v)p(t)(wv|?j)Here, parameter ?
is the length of each smooth-ing step.
Obviously, after each smoothing step,the sum of the probabilities of all the words in onetopic is still equal to 1.
We smooth the parametersuntil we cannot get a better parameter set ?n+1.Then, we continue to the next E-step.
If there isno ?n+1 s.t.
Q(?n+1; ?n) ?
Q(?n; ?n), thenwe consider ?n to be the local maximum point ofthe objective function Eq.
1.5 Experiment Design5.1 Data SetThe data set we used in our experiment is collectedfrom news articles of Xinhua English and Chi-nese newswires.
The whole data set is quite big,containing around 40,000 articles in Chinese and35,000 articles in English.
For different purpose ofour experiments, we randomly selected differentnumber of documents from the whole corpus, andwe will describe the concrete statistics in each ex-periment.
To process the Chinese corpus, we usea simple segmenter1 to split the data into Chinesephrases.
Both Chinese and English stopwords areremoved from our data.The dictionary file we used for our PCLSAmodel is from mandarintools.com2.
For each Chi-nese phrase, if it has several English meanings, weadd an edge between it and each of its Englishtranslation.
If one English translation is an En-glish phrase, we add an edge between the Chinesephrase and each English word in the phrase.5.2 Baseline MethodAs a baseline method, we can apply the standardPLSA (Hofmann, 1999a) directly to the multi-lingual corpus.
Since PLSA takes advantage ofthe word co-occurrences in the document level tofind semantic topics, directly using it for a multi-lingual corpus will result in finding topics mainlyreflecting a single language (because words in dif-ferent languages would not co-occur in the samedocument in general).
That is, the discovered top-ics are mostly monolingual.
These monolingualtopics can then be aligned based on a bilingual dic-tionary to suggest a possible cross-lingual topic.6 Experimental Results6.1 Qualitative ComparisonTo qualitatively compare PCLSAwith the baselinemethod, we compare the word distributions of top-ics extracted by them.
The data set we used in thisexperiment is selected from the Xinhua News dataduring the period from Jun.
8th, 2001 to Jun.
15th,2001.
There are totally 1799 English articles and1485 Chinese articles in the data set.
The num-ber of topics to be extracted is set to 10 for bothmethods.Table 1 shows the experimental results.
Tomake it easier to understand, we add an Englishtranslation to each Chinese phrase in our results.The first ten rows show sample topics of the mod-eling results of traditional PLSA model.
We cansee that it only contains mono-language topics,i.e.
the topics are either in Chinese or in En-glish.
The next ten rows are the results fromour PCLSA model.
Compared with the base-line method, PCLSA can not only find coherenttopics from the cross-lingual corpus, but it canalso show the content about one topic from bothtwo language corpora.
For example, in ?Topic 2?1http://www.mandarintools.com/segmenter.html2http://www.mandarintools.com/cedict.html1132Table 2: Synthetic Data Set from Xinhua NewsEnglish Shrine Olympic Championship90 101 70Chinese CPC Anniversary Afghan War Championship95 206 72which is about ?Israel?
and ?Palestinian?, the Chi-nese corpus mentions a lot about ?Arafat?
who isthe leader of ?Palestinian?, while the English cor-pus discusses more on topics such as ?cease fire?and ?women?.
Similarly, in ?Topic 9?, the topicis related to Philippine, the Chinese corpus men-tions some environmental situation in Philippine,while the English corpus mentions a lot about?Abu Sayyaf?.6.2 Discovering Common TopicsTo demonstrate the ability of PCLSA for findingcommon topics in cross-lingual corpus, we usesome event names, e.g.
?Shrine?
and ?Olympic?,as queries and randomly select a certain number ofdocuments from the whole corpus, which are re-lated to the queries.
The number of documents foreach query in the synthetic data set is shown in Ta-ble 2.
In either the English corpus or the Chinesecorpus, we select a smaller number of documentsabout topic ?Championship?
combined with theother two topics in the same corpus.
In this way,when we want to extract two topics from either En-glish or Chinese corpus, the ?Championship?
topicmay not be easy to extract, because the other twotopics have more documents in the corpus.
How-ever, when we use PCLSA to extract four topicsfrom the two corpora together, we expect that thetopic ?Championship?
will be found, because nowthe sum of English and Chinese documents relatedto ?Championship?
is larger than other topics.
Theexperimental result is shown in Table 3.
The firsttwo columns are the two topics extracted from En-gish corpus, the third and the forth columns aretwo topics from Chinese corpus, and the other fourcolumns are the results from cross-lingual cor-pus.
We can see that in either the Chinese sub-collection or the English sub-collection, the topic?Championship?
is not extracted as a significanttopic.
But, as expected, the topic ?Championship?is extracted from the cross-lingual corpus, whilethe topic ?Olympic?
and topic ?Shrine?
are mergedtogether.
This demonstrate that PCLSA is capableof extracting common topics from a cross-lingualcorpus.6.3 Quantitative EvaluationWe also quantitatively evaluate how well ourPCLSA model can discover common topicsamong corpus in different languages.
We pro-pose a ?cross-collection?
likelihood measure forthis purpose.
The basic idea is: suppose we gotk cross-lingual topics from the whole corpus, thenfor each topic, we split the topic into two sepa-rate set of topics, English topics and Chinese top-ics, using the splitting formula described before,i.e.
pi(wi|?)
= p(wi|?)?w?Vip(w|?)
.
Then, we use theword distribution of the Chinese topics (translatingthe words into English) to fit the English Corpusand use the word distribution of the English top-ics (translating the words into Chinese) to fit theChinese Corpus.
If the topics mined are commontopics in the whole corpus, then such a ?cross-collection?
likelihood should be larger than thosetopics which are not commonly shared by the En-glish and the Chinese corpus.
To calculate thelikelihood of fitness, we use the folding-in methodproposed in (Hofmann, 2001).
To translate topicsfrom one language to another, e.g.
Chinese to En-glish, we look up the bilingual dictionary and doword-to-word translation.
If one Chinese word hasseveral English translations, we simply distributeits probability mass equally to each English trans-lation.For comparison, we use the standard PLSAmodel as the baseline.
Basically, suppose PLSAmined k semantic topics in the Chinese corpus andk semantic topics in the English corpus.
Then, wealso use the ?cross-collection?
likelihood measureto see how well those k semantic Chinese topics fitthe English corpus and those k semantic Englishtopics fit the Chinese corpus.We totally collect three data sets to compare theperformance.
For the first data set, (English 1,Chinese 1), both the Chinese and English corpusare chosen from the Xinhua News Data duringthe period from 2001.06.08 to 2001.06.15, whichhas 1799 English articles and 1485 Chinese ar-ticles.
For the second data set, (English 2, Chi-nese 2), the Chinese corpus Chinese 2 is the sameas Chinese 1, but the English corpus is chosenfrom 2001.06.14 to 2001.06.19 which has 1547documents.
For the third data set, (English 3, Chi-nese 3), the Chinese corpus is the same as in dataset one, but the English corpus is chosen from2001.10.02 to 2001.10.07 which contains 1530documents.
In other words, in the first data set,1133Table 1: Qualitative EvaluationTopic 0 Topic 1 Topic 2 Topic 3 Topic 4 Topic 5 Topic 6 Topic 7 Topic 8 Topic 9j(party) +"(crime) ?C(athlete) ?
(palestine) \*(collaboration) s?
(education) israel bt dollar china?
?j(communist) @(agriculture) 	(champion) ????
(palestine) ?0(shanghai) E(ball) palestinian beat percent cooperate??
(revolution) @?
(travel) ?)?
(championship) 1??
(israel) ?
(relation) ??
(league) eu final million shanghaij?
(party member) Qs(heathendom) ?
(base) *?
(cease fire) ?
)(bilateral) E(soccer) police championship index develop??
(central) ??
(public security) ?
?E(badminton) ?\)(UN) ?4(trade) I?
(minute) report play stock beije?B(ism) w(name) ?
(sports) ??
(mid east) :(president) ??
(team member) secure champion point particulate?\(cadre) ?
(case) ??
(final) ?
?(lebanon) )(country) s(teacher) kill win share matter?
?
(chairman mao) ?(law enforcement) E(women) j??
(macedon) ?P(friendly) ?B?
(school) europe olympic close sco??
(chinese communist) =(city) 6?
(chess) ?B(conflict) ??
(meet) E?
(team) egypt game 0 invests(leader) ?(penalize) H?
(fitness) ??
(talk) [?
(russia)  (grade A) treaty cup billion project?
)(bilateral) ??
(league) israel cooperate ?C(athlete) party eu invest 0 ??
(absorb)\*(collaboration) w(name) 1??
(israel) sco particulate j(party) khatami =?
(investment) dollar ???
(talk) E(ball) bt develop 	 communist ireland 7?
(billion) percent ?Y?
e(abu)?P(friendly) ??
(shenhua) palestinian country athlete revolution ?}(ireland) s?
(education) index ??
(palestine) ??
(host) ceasefire president champion ?B(-ism) elect ??(environ.
protect.)
million (?
(particle)country A ?n(arafat) apec ii ?
(antiwar) vote ??
(money) stock philippine?\)(UN) ball women shanghai 6?
(chess) 3?
(comrade) presidential ?B?
(school) billion abus|(leader) ?y(jinde) jerusalem africa competition ??
(revolution) cpc market point ?
(base)bilateral ?(season) mideast meet contestant j?
(party) iran s(teacher) 7(billion) ?state E?
(player) lebanon T?
(zemin jiang) v(gymnastics) ideology referendum business share ?
(object)Table 3: Effectiveness of Extracting Common TopicsEnglish 1 English 2 Chinese 1 Chinese 2 Cross 1 Cross 2 Cross 3 Cross 4japan olympic ?
?j(CPC) ?
?F(afghan) koizumi ??
(taliban) swim ?|(worker)shrine ioc ?
(championship) ?
(taliban) yasukuni /(military) ?
(championship) partyvisit beije -(world) ??
(taliban) ioc city ?y(free style) ??
(three)koizumi game ?.
(thought) /(military) japan refugee !y(diving) j.?
(marx)yasukuni july ?X(theory) K?
(attack) olympic side ?)?
(championship) communistwar bid j.?
(marx) ?(US army) beije ?(US army) ???
(semi final) marxaugust swim ?y(swim) [(laden) shrine q(bomb) competition theoryasia vote ?)?
(championship) \?
(army) visit 	Y(kabul) ?y(swim) Oj(found party)criminal championship j(party) q(bomb) ???
(olympic) 8?
(attack) ?9(record) ?
?j(CPC)ii committee Oj(found party) 	Y(kabul) ???.(olympic)?
(refugee) [??
(xuejuan luo) revolutionthe English corpus and Chinese corpus are com-parable with each other, because they cover simi-lar events during the same period.
In the seconddata set, the English and Chinese corpora sharesome common topics during the overlap period.The third data is the most tough one since the twocorpora are from different periods.
The purpose ofusing these three different data sets for evaluationis to test how well PCLSA can mine common top-ics from either a data set where the English corpusand the Chinese corpus are comparable or a dataset where the English corpus and the Chinese cor-pus rarely share common topics.The experimental results are shown in Table 4.Each row shows the ?cross-collection?
likelihoodof using the ?cross-collection?
topics to fit the dataset named in the first column.
For example, inthe first row, the values are the ?cross-collection?likelihood of using Chinese topics found by differ-ent methods from the first data set to fit English 1.The last collum shows howmuch improvement wegot from PCLSA compared with PLSA.
From theresults, we can see that in all the data sets, ourPCLSA has higher ?cross-collection?
likelihoodvalue, which means it can find better common top-ics compared to the baseline method.
Notice thatthe Chinese corpora are the same in all three datasets.
The results show that both PCLSA and PLSAget lower ?cross-collection?
likelihood for fittingthe Chinese corpora when the data set becomes?tougher?, i.e.
less topic overlapping, but the im-Table 4: Quantitative Evaluation of CommonTopic Finding (?cross-collection?
log-likelihood)PCLSA PLSA Rel.
Imprv.English 1 -2.86294E+06 -3.03176E+06 5.6%Chinese 1 -4.69989E+06 -4.85369E+06 3.2%English 2 -2.48174E+06 -2.60805E+06 4.8%Chinese 2 -4.73218E+06 -4.88906E+06 3.2%English 3 -2.44714E+06 -2.60540E+06 6.1%Chinese 3 -4.79639E+06 -4.94273E+06 3.0%provement of PCLSA over PLSA does not dropmuch.
On the other hand, the improvement ofPCLSA over PLSA on the three English corporadoes not show any correlation with the difficultyof the data set.6.4 Extracting from Multi-Language CorpusIn the previous experiments, we have shown thecapability and effectiveness of the PCLSA modelin latent topic extraction from two language cor-pora.
In fact, the proposed model is general andcapable of extracting latent topics from multi-language corpus.
For example, if we have dic-tionaries among multiple languages, we can con-struct a multi-partite graph based on the corre-spondence between those vocabularies, and thensmooth the PCLSA model with this graph.To show the effectiveness of PCLSA in min-ing multiple language corpus, we first construct asimulated data set based on 1115 reviews of threebrands of laptops, namely IBM (303), Apple(468)and DELL(344).
To simulate a three language cor-1134Table 5: Effectiveness of Latent Topic Extraction from Multi-Language CorpusTopic 0 Topic 1 Topic 2 Topic 3 Topic 4 Topic 5 Topic 6 Topic 7cd(apple) battery(dell) mouse(dell) print(apple) port(ibm) laptop(ibm) os(apple) port(dell)port(apple) drive(dell) button(dell) resolution(dell) card(ibm) t20(ibm) run(apple) 2(dell)drive(apple) 8200(dell) touchpad(dell) burn(apple) modem(ibm) thinkpad(ibm) 1(apple) usb(dell)airport(apple) inspiron(dell) pad(dell) normal(dell) display(ibm) battery(ibm) ram(apple) 1(dell)firewire(apple) system(dell) keyboard(dell) image(dell) built(ibm) notebook(ibm) mac(apple) 0(dell)dvd(apple) hour(dell) point(dell) digital(apple) swap(ibm) ibm(ibm) battery(apple) slot(dell)usb(apple) sound(dell) stick(dell) organize(apple) easy(ibm) 3(ibm) hour(apple) firewire(dell)rw(apple) dell(dell) rest(dell) cds(apple) connector(ibm) feel(ibm) 12(apple) display(dell)card(apple) service(dell) touch(dell) latch(apple) feature(ibm) hour(ibm) operate(apple) standard(dell)mouse(apple) life(dell) erase(dell) advertise(dell) cd(ibm) high(ibm) word(apple) fast(dell)osx(apple) applework(apple) port(dell) battery(dell) lightest(ibm) uxga(dell) light(ibm) battery(apple)memory(dell) file(apple) port(apple) battery(ibm) quality(dell) ultrasharp(dell) ultrabay(ibm) point(dell)special(dell) bounce(apple) port(ibm) battery(apple) year(ibm) display(dell) connector(ibm) touchpad(dell)crucial(dell) quit(apple) firewire(apple) geforce4(dell) hassle(ibm) organize(apple) dvd(ibm) button(dell)memory(apple) word(apple) imac(apple) 100mhz(apple) bania(dell) learn(apple) nice(ibm) hour(apple)memory(ibm) file(ibm) firewire(dell) 440(dell) 800mhz(apple) logo(apple) modem(ibm) battery(ibm)netscape(apple) file(dell) firewire(ibm) bus(apple) trackpad(apple) postscript(apple) connector(dell) battery(dell)reseller(apple) microsoft(apple) jack(apple) 8200(dell) cover(ibm) ll(apple) light(apple) fan(dell)10(dell) ms(apple) playback(dell) 8100(dell) workmanship(dell) sxga(dell) light(dell) erase(dell)special(apple) excel(apple) jack(dell) chipset(dell) section(apple) warm(apple) floppy(ibm) point(apple)2000(ibm) ram(apple) port(dell) itune(apple) uxga(dell) port(apple) pentium(dell) drive(ibm)window(ibm) ram(ibm) port(apple) applework(apple) screen(dell) port(ibm) processor(dell) drive(dell)2000(apple) ram(dell) port(ibm) imovie(apple) screen(ibm) port(dell) p4(dell) drive(apple)2000(dell) screen(apple) 2(dell) import(apple) screen(apple) usb(apple) power(dell) hard(ibm)window(apple) 1(apple) 2(apple) battery(apple) ultrasharp(dell) plug(apple) pentium(apple) osx(apple)window(dell) screen(ibm) 2(ibm) iphoto(apple) 1600x1200(dell) cord(apple) pentium(ibm) hard(dell)portege(ibm) screen(dell) speak(dell) battery(ibm) display(dell) usb(ibm) keyboard(dell) hard(apple)option(ibm) 1(ibm) toshiba(dell) battery(dell) display(apple) usb(dell) processor(ibm) card(ibm)hassle(ibm) 1(dell) speak(ibm) hour(apple) display(ibm) firewire(apple) processor(apple) dvd(ibm)device(ibm) maco(apple) toshiba(ibm) hour(ibm) view(dell) plug(ibm) power(apple) card(dell)pus, we use an ?IBM?
word, an ?Apple?
word, anda ?Dell?
word to replace an English word in theircorpus.
For example, we use ?IBM10?, ?Apple10?,?Dell10?
to replace the word ?CD?
whenever it ap-pears in an IBM?s, Apple?s, or Dell?s review.
Af-ter the replacement, the reviews about IBM, Ap-ple, and Dell will not share vocabularies with eachother.
On the other hand, for any three createdwords which represent the same English word, weadd three edges among them, and therefore weget a simulated dictionary graph for our PCLSAmodel.The experimental result is shown in Table 5, inwhich we try to extract 8 topics from the cross-lingual corpus.
The first ten rows show the re-sult of our PCLSA model, in which we set a verysmall value to the weight parameter ?
for the reg-ularizer part.
This can be used as an approxima-tion of the result from the traditional PLSA modelon this three language corpus.
We can see thatthe extracted topics are mainly written in mono-language.
As we set the value of parameter ?larger, the extracted topics become multi-lingual,which is shown in the next ten rows.
From thisresult, we can see the difference between the re-views of different brands about the similar topic.In addition, if we set the ?
even larger, we willget topics that are mostly made of the same wordsfrom the three different brands, which means theextracted topics are very smooth on the dictionarygraph now.7 ConclusionIn this paper, we study the problem of cross-lingual latent topic extraction where the task is toextract a set of common latent topics from multi-lingual text data.
We propose a novel probabilistictopic model (i.e.
the Probabilistic Cross-LingualLatent Semantic Analysis (PCLSA) model) thatcan incorporate translation knowledge in bilingualdictionaries as a regularizer to constrain the pa-rameter estimation so that the learned topic modelswould be synchronized in multiple languages.
Weevaluated the model using several data sets.
Theexperimental results show that PCLSA is effec-tive in extracting common latent topics from mul-tilingual text data, and it outperforms the baselinemethod which uses the standard PLSA to fit eachmonolingual text data set.Our work opens up some interesting future re-search directions to further explore.
First, inthis paper, we have only experimented with uni-form weighting of edge in the bilingual graph.It should be very interesting to explore how toassign weights to the edges and study whetherweighted graphs can further improve performance.Second, it would also be interesting to furtherextend PCLSA to accommodate discovering top-ics in each language that aren?t well-aligned withother languages.8 AcknowledgmentsWe sincerely thank the anonymous reviewers fortheir comprehensive and constructive comments.The work was supported in part by NASA grant1135NNX08AC35A, by the National Science Foun-dation under Grant Numbers IIS-0713581, IIS-0713571, and CNS-0834709, and by a Sloan Re-search Fellowship.ReferencesDavid Blei and John Lafferty.
2005.
Correlated topicmodels.
In NIPS ?05: Advances in Neural Informa-tion Processing Systems 18.David M. Blei and John D. Lafferty.
2006.
Dynamictopic models.
In Proceedings of the 23rd interna-tional conference on Machine learning, pages 113?120.D.
Blei, T. Griffiths, M. Jordan, and J. Tenenbaum.2003a.
Hierarchical topic models and the nestedchinese restaurant process.
In Neural InformationProcessing Systems (NIPS) 16.D.
Blei, A. Ng, and M. Jordan.
2003b.
Latent Dirichletallocation.
Journal of Machine Learning Research,3:993?1022.J.
Boyd-Graber and D. Blei.
2009.
Multilingual topicmodels for unaligned text.
In Uncertainty in Artifi-cial Intelligence.S.
R. K. Branavan, Harr Chen, Jacob Eisenstein, andRegina Barzilay.
2008.
Learning document-levelsemantic properties from free-text annotations.
InProceedings of ACL 2008.Martin Franz, J. Scott McCarley, and Salim Roukos.1998.
Ad hoc and multilingual information retrievalat IBM.
In Text REtrieval Conference, pages 104?115.Pascale Fung.
1995.
A pattern matching methodfor finding noun and proper noun translations fromnoisy parallel corpora.
In Proceedings of ACL 1995,pages 236?243.Alfio Gliozzo and Carlo Strapparava.
2006.
Exploit-ing comparable corpora and bilingual dictionariesfor cross-language text categorization.
In ACL-44:Proceedings of the 21st International Conferenceon Computational Linguistics and the 44th annualmeeting of the Association for Computational Lin-guistics, pages 553?560, Morristown, NJ, USA.
As-sociation for Computational Linguistics.T.
Hofmann.
1999a.
Probabilistic latent semantic anal-ysis.
In Proceedings of UAI 1999, pages 289?296.Thomas Hofmann.
1999b.
The cluster-abstractionmodel: Unsupervised learning of topic hierarchiesfrom text data.
In IJCAI?
99, pages 682?687.Thomas Hofmann.
2001.
Unsupervised learning byprobabilistic latent semantic analysis.
Mach.
Learn.,42(1-2):177?196.Jagadeesh Jagaralamudi and Hal Daume?
III.
2010.
Ex-tracting multilingual topics from unaligned corpora.In Proceedings of the European Conference on In-formation Retrieval (ECIR), Milton Keynes, UnitedKingdom.Woosung Kim and Sanjeev Khudanpur.
2004.
Lex-ical triggers and latent semantic analysis for cross-lingual language model adaptation.
ACM Trans-actions on Asian Language Information Processing(TALIP), 3(2):94?112.Wei Li and Andrew McCallum.
2006.
Pachinko allo-cation: Dag-structured mixture models of topic cor-relations.
In ICML ?06: Proceedings of the 23rd in-ternational conference on Machine learning, pages577?584.H.
Masuichi, R. Flournoy, S. Kaufmann, and S. Peters.2000.
A bootstrapping method for extracting bilin-gual text pairs.
In Proc.
18th COLINC, pages 1066?1070.Qiaozhu Mei and ChengXiang Zhai.
2006.
A mixturemodel for contextual text mining.
In Proceedings ofKDD ?06, pages 649?655.Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su,and ChengXiang Zhai.
2007.
Topic sentiment mix-ture: Modeling facets and opinions in weblogs.
InProceedings of WWW ?07.Qiaozhu Mei, Deng Cai, Duo Zhang, and ChengXiangZhai.
2008a.
Topic modeling with network regular-ization.
In WWW, pages 101?110.Qiaozhu Mei, Duo Zhang, and ChengXiang Zhai.2008b.
A general optimization framework forsmoothing language models on graph structures.
InSIGIR ?08: Proceedings of the 31st annual interna-tional ACM SIGIR conference on Research and de-velopment in information retrieval, pages 611?618,New York, NY, USA.
ACM.David Mimno, Hanna M. Wallach, Jason Naradowsky,David A. Smith, and Andrew Mccallum.
2009.Polylingual topic models.
In Proceedings of the2009 Conference on Empirical Methods in NaturalLanguage Processing, pages 880?889, Singapore,August.
Association for Computational Linguistics.Xiaochuan Ni, Jian-Tao Sun, Jian Hu, and Zheng Chen.2009.
Mining multilingual topics from wikipedia.In WWW ?09: Proceedings of the 18th internationalconference on World wide web, pages 1155?1156,New York, NY, USA.
ACM.F.
Sadat, M. Yoshikawa, and S. Uemura.
2003.
Bilin-gual terminology acquisition from comparable cor-pora and phrasal translation to cross-language infor-mation retrieval.
In ACL ?03: Proceedings of the41st Annual Meeting on Association for Computa-tional Linguistics, pages 141?144.1136Mark Steyvers, Padhraic Smyth, Michal Rosen-Zvi,and Thomas Griffiths.
2004.
Probabilistic author-topic models for information discovery.
In Proceed-ings of KDD?04, pages 306?315.Xuanhui Wang, ChengXiang Zhai, Xiao Hu, andRichard Sproat.
2007.
Mining correlated burstytopic patterns from coordinated text streams.
InKDD ?07: Proceedings of the 13th ACM SIGKDDinternational conference on Knowledge discoveryand data mining, pages 784?793, New York, NY,USA.
ACM.Bing Zhao and Eric P. Xing.
2006.
Bitam: Bilingualtopic admixture models for word alignment.
In InProceedings of the 44th Annual Meeting of the As-sociation for Computational Linguistics.1137
