First Joint Conference on Lexical and Computational Semantics (*SEM), pages 80?84,Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational LinguisticsTowards a Flexible Semantics:Colour Terms in Collaborative Reference TasksBert BaumgaertnerUniversity of California, Davisbbaum@ucdavis.eduRaquel Ferna?ndezUniversity of Amsterdamraquel.fernandez@uva.nlMatthew StoneRutgers Universitymatthew.stone@rutgers.eduAbstractWe report ongoing work on the developmentof agents that can implicitly coordinate withtheir partners in referential tasks, taking as acase study colour terms.
We describe algo-rithms for generation and resolution of colourdescriptions and report results of experimentson how humans use colour terms for referencein production and comprehension.1 IntroductionSpeakers do not always share identical semantic rep-resentations nor identical lexicons.
For instance, asubject may refer to a shape as a diamond whileanother subject may call that same shape a square(which just happens to be tilted sidewise); or some-one may refer to a particular colour with ?light pink?while a different speaker may refer to it as ?salmon?.Regardless of these differences, which seem com-mon place, speakers in dialogue are able to com-municate successfully most of the time.
Success-ful communication exploits interlocutors?
abilities tonegotiate referring expressions interactively throughgrounding (Clark and Wilkes-Gibbs, 1986; Clarkand Schaefer, 1989), but in many cases interlocutorscan already make a good guess at their partners?
in-tentions by relaxing the interpretation of their utter-ances and looking for the referent that best matchesthis looser interpretation.
We are interested in mod-elling this second kind of behaviour computation-ally, to get a better understanding of it and to con-tribute to the development of dialogue systems thatare able to better coordinate with their human part-ners.In this paper we focus on collaborative referen-tial tasks (akin to the classic matching tasks intro-duced by Krauss and Weinheimer (1966) and Clarkand Wilkes-Gibbs (1986)) and take as a case studycolour terms.
Our focus here is not on the explicitjoint negotiation of effective terms, but rather on thedeployment of flexible semantic representations thatcan adapt to the constraints imposed by the contextand to the dialogue partner?s language use.We start by describing our algorithms for genera-tion and resolution of colour descriptions in the nextsection.
In sections 3 and 4, we present results ofexperiments that investigate how humans use colourterms for reference in production and comprehen-sion.
Section 5 compares our model against the ex-perimental data we have collected so far and dis-cusses some directions for future work.
We end witha short conclusion in section 6.2 Reference to Colours: Our ModelOur view of how colour terms are used in referentialtasks follows the basic tenets of Gricean pragmat-ics (Grice, 1975) and collaborative reference theo-ries (Clark and Wilkes-Gibbs, 1986), according towhich speakers and addressees tend to maximize thesuccess of their joint task while minimizing costs.In the domain of colour terms, we take this tomean that speakers tend use a basic colour term (e.g.,?red?
or ?blue?)
whenever this is enough to iden-tify the target object and resort to an alternative,more specific or complex term (e.g., ?bordeaux?
or?navy blue?)
in other contexts where the basic termis deemed insufficient.
Non-basic terms can be con-sidered more costly because they are less frequentand thus more difficult to retrieve.Similar ideas are at the core of models for thegeneration of referring expressions that build on theseminal work of Dale and Reiter (1995).
These ap-80proaches, however, rely on a lexicon or databasewhere the properties of potential target objects areassociated with specific, predefined terms.1 Our aimis to develop dialogue agents that employ more flex-ible semantic representations, allowing them to (a)refer to target colours with different terms in differ-ent contexts, and (b) resolve the reference of colourterms produced by the dialogue partner by pickingup targets that are not rigidly linked to the term inthe agent?s lexicon.2.1 AlgorithmsData.
To develop the generation and resolution al-gorithms of our agent, we used a publicly avail-able database of RGB codes and colour terms gen-erated from a colour naming survey created by Ran-dall Monroe (author of the webcomic xkcd.com)and taken by around two hundred thousand par-ticipants.2 This database contains a total of 954colour terms (corresponding to the colour termsmost frequently used by the participants) paired witha unique RGB code corresponding to the location inthe RGB colour space which was most frequentlynamed with the colour term in question.We use this database as the default lexicon of ouragent.
Amongst the colour terms in the lexicon,we distinguish between basic and non-basic colours.We selected the following as our basic colours: red,purple, pink, magenta, brown, orange, yellow, green,teal, blue, and grey.
This selection takes into accountthe high frequency of these terms in English and is inline with the literature on basic colour terms (Berlinand Kay, 1967; Berlin and Kay, 1991).Resolution Algorithm.
ALIN (ALgorithm for IN-terpretation) is given as input a scene of colouredsquares and a colour term.
Its output is the square ittakes to be the intended target, generated as follows.Assuming the input term is in the lexicon, ALINcompares every colour in the scene to the RGB valueof the input (the anchor).
ALIN considers a colourc the intended target if, (a) c is nearest the anchorwithin a certain distance threshold, and (b) for anyother colour c?
in the scene within the given distance1See, however, van Deemter (2006) for an attempt to dealwith vague properties such as size within this framework.2For further details visit http://blog.xkcd.com/2010/05/03/color-survey-results/.Figure 1: Two scenes with the brown square (top left inboth scenes) as the target; no competitors (left scene) andone potential competitor (right scene).threshold of the anchor, c?
is far enough away fromboth the anchor and c. We say more about distancethresholds below.Generation Algorithm.
Unless there are competi-tors (colours relatively close to the target), GENA(GENeration Algorithm) is disposed to output a ba-sic colour term if the target is acceptably close to abasic colour (if not, it selects the default term asso-ciated with the RGB code in the lexicon).
In casethere are competitor colours in the scene, if the tar-get is a basic colour, GENA will attempt to select anon-basic colour term closest to the target but stillfurther away from the competitor(s).
If the target isnot a basic colour, GENA simply selects the defaultterm in the lexicon.Measuring Colour Distance.
We treat coloursin our model as points in a conceptual space(Ga?rdenfors, 2000; Ja?ger, 2009).
As a first approx-imation, we measure colour proximity in terms ofEuclidean distances between RGB values.3 Threevariables were used to set the thresholds required byALIN and GENA: i) bc is the maximum range tosearch for basic colours; ii) min is the minimum dis-tance required between two colours to be consideredminimally different; and iii) max is the maximumrange of allowable search for alternative colours.
Weconducted two pilot studies to establish reasonablevalues for these variables, which we then set as: bc= 100; min = 25; max = 75.43 Experimental MethodologyWe conducted two small experiments to collect dataabout how speakers and addressees use colour termsin referential tasks.3We recognize Euclidean distances between RGB values as-sumes colour space is uniform, which is not the case in humanvision (Wyszecki and Stiles, 2000).
See section 5.4RGB codes scaled at 0?255.81brownchocolatebrowndarkbrownearthy brownpoop brownsameas mudbasic colour w/o competitors0.00.10.20.30.40.50.60.7blueberry brownchocolatebrowncolour of muddarkbrownbasic colour with competitors0.00.10.20.30.40.50.60.7darkpinkdustyrose magenta mauve pink red roserosepink salmonsalmon pinknon-basic colour w/o competitors0.00.10.20.30.40.5bright pinkdull light fuchsiadull salmon pinkdustyroselightmauvelightpink lightredlightsalmonlightish pinkmagenta mauvemedium pinkorangish pinkpastel pink pink red rose rosepink salmonsalmon pinkterracottanon-basic colour with competitors0.00.10.20.30.40.5Figure 2: Sample of results from ExpA, for a basic and a non-basic colour.Materials & Setup.
We created 12 differentscenes, each consisting of four solid colouredsquares, one of them the target (see Figure 1 forsample scenes).
Scenes were designed to take intoaccount two parameters: basic and non-basic targetcolours, and without or with a competitor ?
a colourat a distance threshold from the target.5 The targetbasic colours used were ?brown?
and ?magenta?
andthe non-basic ones, ?rose?
and ?sea blue?.6 Each tar-get colour appeared at least in one scene where therewere no competitors.We run a generation experiment (ExpA) and a res-olution experiment (ExpB).
In ExpA, participantswere shown our 12 scenes and were asked to referto the target with a colour term that would allow apotential addressee to identify it in the current con-text, but without reference to the other colours inthe scene (to avoid comparatives such as ?the bluersquare?).
In ExpB, participants were shown a sceneand a colour term and were asked to pick up the in-tended referent.
The colour terms used in this sec-ond experiment were selected from those producedin ExpA ?
29 scene-term pairs in total.
Each sceneappeared at least twice, once with a term with highoccurrence frequency in ExpA, and once or twicewith one or two terms that had been produced withlow frequency.
To minimize chances that subjectsrecognize the same scene more than once, we ro-tated and dispersed them evenly throughout.5Any colour within a Euclidean distance of 125 from thetarget was considered a competitor.6Compositional phrases may introduce more sophisticatedeffects.
However, the data on which our lexicon is based ab-stracted away from such details, treating them as simples.Participants.
A total of 36 native-English partici-pants took part in the experiments: 19 in ExpA and17 in ExpB.
Subjects for both experiments includedundergraduate students, graduates students, and uni-versity faculty.
Both experiments were run online.4 Experimental ResultsExpA Generation.
ExpA revealed there is highvariability in the terms produced to refer to a sin-gle colour.
As expected, variability of terms gener-ated for non-basic colours was higher than for ba-sic colours.
For non-basic colours, variability ofterms in scenes with competitors was higher.
Fig-ure 2 shows the different terms produced for a basiccolour (?brown?)
and a non-basic colour (?rose?)
inscenes without and with competitors, together withthe proportional frequency of each term.For the brown square target in a scene with-out competitors, the basic-colour term ?brown?
wasused with high frequency (72% of the time) whileany other terms were used 1 or 2 times only.
Inscenes with competitors, ?dark brown?
had high-est frequency with ?brown?
almost as much (43%vs.
40%).
For the rose square target in a scene with-out competitors, there was also one term that stoodout as the most frequent, ?pink?, although its fre-quency (30%) is substantially lower to that of thebasic-colour ?brown?.
In scenes with competitorsthere is an explosion in variation, with ?pink?
stillstanding out but only with a proportional frequencyof 21%.Overall, ExpA showed that speakers attempt toadapt their colour descriptions to the context and that82there is high variability in the terms they choose todo this.ExpB: Resolution.
ExpB showed that referenceresolution is almost always successful despite thevariation in colour terms observed in ExpA.
For thebasic colours in scenes with no competitors, partici-pants successfully identified the targets in all cases,while in scenes with competitors they did so 98%of the time.
This was the case for both terms withproportionally high and low frequency.For the non-basic colours in scenes with no com-petitors, the success rate in identifying the targetwas again 100% for both high and low frequencyterms.
For scenes with competitors, there were dif-ferences depending on the frequency of the termsused: for high frequency terms there were once moreno resolution errors, while the resolution successrate dropped to 78% where we used terms with lowproportional frequency scores.
A summary of theseresults is shown in Table 1, together with the successrate of our resolution algorithm ALIN.Basic Colours Non-basic Colourshigh freq.
low freq.
high freq.
low freq.nc c nc c nc c nc cExpB 1 0.98 1 0.98 1 1 1 0.78ALIN 1 0.71 1 0.71 0.5 1 0.75 0.71Table 1: Resolution success rate by human participantsand ALIN in scenes without and with competitors (nc/c).5 DiscussionThe data we collected allows us to make informa-tive comparisons between humans and our model incollaborative reference tasks.
Although we do notbelieve the data is sufficient for an evaluation, thecomparison illuminates how the model can be re-fined and the setup required for a proper evaluation.Regarding resolution, we note that an algorithmthat rigidly associates colours and terms would havesuccessfully resolved only 4 of the 29 cases, 3 ofwhich were basic colours with no distractors ?
a7.25% success rate.
In our scenarios with four po-tential targets, a random algorithm would have anaverage success rate of 25%.
ALIN is closer to ourhuman data (see Table 1), though anomalies exist.One problem is the lack of compositional semanticsin our current model.
ALIN failed to resolve com-plex phrases like ?dull salmon pink?
and ?deep grayblue?, which were terms produced by humans fornon-basic colours with competitors, simply becausethe terms were not in the agent?s lexicon.
Otheranomalies seem to be consequences of taking Eu-clidean distances over RGB values, which may betoo crude.
In the future, our intent is to convert RGBvalues to Lab values and then use Delta-E values tomeasure distances.
First, however, we need a moresophisticated analysis of the thresholds that we usedfor ALIN and GENA.As for generation, given the amount of variationobserved in the terms produced by our subjects, it isnot clear how human performance ought to be com-pared to GENA?s.
For instance, in scenes with com-petitors, GENA produced ?reddish brown?
for thebasic colour ?brown?
and ?coral?
for the non-basiccolour ?rose?.
These did not appear in our human-generated data but still seem to our lights reasonabledescriptions.
GENA also produced ?gray?
to refer to?rose?
in a different scene, which seems less appro-priate and may be due to our current way of calcu-lating colour distances and setting up the thresholds.We believe that instead of comparing GENA?soutput to human output, it makes more sense to eval-uate GENA by testing how well humans can resolveterms produced by it.
We intend to carry out thisevaluation in the future.6 ConclusionsWe have focused on the specific case of colourswhere speakers differ in the referring expressionsthey generate, but addressees are nevertheless ableto relax the interpretations of the expressions in or-der to coordinate.
We believe this implicit adapt-ability is part of our semantic representation morebroadly.
The case of colour provides us with a start-ing point for studying and modelling computation-ally this flexibility we possess.AcknowledgementsThis work has been partially supported by grant632.002.001 from the Netherlands Organisation forScientic Research (NWO) and by grant IIS-1017811from the National Science Foundation (NSF).83ReferencesBrent Berlin and Paul Kay.
1967.
Universality and evo-lution of basic color terms.
Laboratory for Language-Behavior Research.Brent Berlin and Paul Kay.
1991.
Basic color terms:Their universality and evolution.
Univ of CaliforniaPr.Herbert H. Clark and Edward F. Schaefer.
1989.
Con-tributing to discourse.
Cognitive Science, 13(2):259?294.Herbert H. Clark and Donna Wilkes-Gibbs.
1986.
Refer-ring as a collaborative process.
Cognition, 22:1?39.Robert Dale and Ehud Reiter.
1995.
Computational in-terpretations of the Gricean Maxims in the Generationof Referring Expressions.
Cognitive Science, 18:233?266.Peter Ga?rdenfors.
2000.
Conceptual Spaces.
MIT Press,Cambridge.Paul Grice.
1975.
Logic and conversation.
In D. David-son and G. Harman, editors, The Logic of Grammar,pages 64?75.
Dickenson, Encino, California.Gerhard Ja?ger.
2009.
Natural color categories are convexsets.
In Logic, Language and Meaning: 17th Amster-dam Colloquium, Amsterdam, The Netherlands, De-cember 16-18, 2009, Revised Selected Papers, pages11?20.
Springer.Robert Krauss and Sidney Weinheimer.
1966.
Concur-rent feedback, confirmation, and the encoding of refer-ents in verbal communication.
Journal of Personalityand Social Psychology, 4(3):343?346.Kees van Deemter.
2006.
Generating referring expres-sions that involve gradable properties.
ComputationalLingustics, 32(2):195?222.Gu?nter Wyszecki and Walter S. Stiles.
2000.
Color sci-ence: concepts and methods, quantitative data andformulae.
Wiley Classics Library.84
