Language Identification With Confidence LimitsDav id  E lwor thyCanon Research Centre Europe1 Occam CourtOccam RoadSurrey Research ParkGui\]idford GU2 5YJUnited Kingdomdahe~cre, canon, co. ukAbst rac tA statistical classification algorithm and its ap-plication to language identification from noisyinput are described.
The main innovation is tocompute confidence limits on the classification,so that the algorithm terminates when enoughevidence to make a clear decision has beenmade, and so avoiding problems with categoriesthat have similar characteristics.
A second ap-plication, to genre identification, is briefly ex-amined.
The results show that some of theproblems of other language identification tech-niques can be avoided, and illustrate a more im-portant point: that a statistical language pro-cess can be used to provide feedback about itsown success rate.1 In t roduct ionLanguage identification is an example of a gen-eral class of problems in which we want to as-sign an input data stream to one of several cat-egories as quickly and accurately as possible.
Itcan be solved using many techniques, includingknowledge-poor statistical approaches.
Typi-cally, the distribution of n-grams of charactersor other objects is used to form a model.
Acomparison of the input against the model de-termines the language which matches best.
Ver-sions of this simple technique can be found inDunning (1994) and Cavnar and Trenkle (1994),while an interesting practical implementation isdescribed by Adams and Resnik (1997).A variant of the problem is considered bySibun and Spitz (1994), and Sibun and Rey-nar (1996), who look at it from the point ofview of Optical Character Recognition (OCR).Here, the language model for the OCR systemcannot be selected until the language has beenidentified.
They therefore work with so-calledshape tokens, which give a very approximate en-coding of the characters' hapes on the printedpage without needing full-scale OCR.
For exam-ple, all upper case letters are treated as beingone character shape, all characters with a de-scender are another, and so on.
Sequences ofcharacter shape codes separated by white spaceare assembled into word shape tokens.
Sibunand Spitz then determine the language on thebasis of linear discriminant analysis (LDA) overword shape tokens, while Sibun and Reynar ex-plore the use of entropy relative to training datafor character shape unigrams, bigrams and tri-grams.
Both techniques are capable of over90% accuracy for most languages.
However, theLDA-based technique tends to perform signifi-cantly worse for languages which are similar toone another, such as the Norse languages.
Rela-tive entropy performs better, but still has somenoticeable rror clusters, such as confusion be-tween Croatian, Serbian and Slovenian.What these techniques lack is a measure ofwhen enough information has been accumulatedto distinguish one language from another reli-ably: they examine all of the input data andthen make the decision.
Here we will look at adifferent approach which attempts to overcomethis by maintaining a measure of the total ev-idence accumulated for each language and howmuch confidence there is in the measure.
Tooutline the approach:1.
The input is processed one (word shape)token at a time.
For each language, we de-termine the probability that the token isin that language, expressed as a 95% con-fidence range.2.
The values for each word are accumulatedinto an overall score with a confidencerange for the input to date, and comparedboth to an absolute threshold, and with94.each other.
Thus, to select a language, werequire not only that it has a high score(probability, roughly), but also that it issignificantly better scoring than any other.If the process fails to make a decision on thedata that is available, the subset of the lan-guages which have exceeded the absolutethreshold can be output, so that even if afinal decision has not been made, the likelypossibilities have been narrowed own.We look at this procedure in more detail below,with particular emphasis on how the underlyingstatistical model provides confidence intervals.An evaluation of the technique on data similarto that used by Sibun and Reynar follows I.2 The  Ident i f i ca t ion  A lgor i thmThe essential idea behind the identification al-gorithm is to accumulate the probability of thelanguage given the input tokens for each lan-guage, treating each token as an independentevent.
To obtain the probability of a languagel given a token t, p(llt), we use Bayes' rule:p(l\[t) = p(tl l)p(l)p(t)where p(t\[l) is the probability of the token if thelanguage is known, p(t) is the a pr/or/probabil-ity of the token, and p(l) is the a priori probabil-ity of the language.
We will assume that p(l) isconstant (all languages are equi-probable) anddrop it from the computation; in the tests, wewill use the same amount of training data foreach language.
The other two terms are esti-mated from training data, using the proceduredescribed in section 2.2.2.1 The  language mode l  and thea lgor i thmThe input to the algorithm consists of a streamof tokens, such as word shape tokens (as in Si-bun and Spitz, or Sibun and Reynar) or wordsthemselves.
The model for each language con-tains the probability of each known token giventhe language, expressed as three values: the ba-sic probability, and the lower and ulSper limitsISome ideas related to the use of confidence limitscan also be found in Dagan et al (1991), applied in adifferent area.95of a range containing this probability for a spe-cific level of confidence.
We will denote these bypB(tll), pL(tll), pH(tll), for base, low and highvalues.
The probability that a token which hasnever been seen before is in a language is alsopresent in the model of the language.
In ad-dition, there is a language independent model,containing the p(t) values.
No confidence rangeis used for them, although this would be a sim-ple extension of the technique.The algorithm proceeds by processing tokens,building up evidence about each language inthree accumulators.
The accumulators rep-resent the overall probability of the languagegiven the entire stream of tokens to date, againas base, low and high values, denoted as(1),aL(1), all(l).
They are set to zero at the startof processing, and the logarithms of the proba-bilities are added to them as each token is pro-cessed.
By taking logarithms of probabilities,we are in effect measuring the amount of evi-dence for each language, expressed as informa-tion content.
From a practical point of view,using logarithms also helps keep all the valuesin a reasonable range and so avoids numericalunderflow.After processing each token, two tests are ap-plied.
Firstly, we examine the base accumulatorfor the language which has the highest accumu-lated total, and test whether it is greater than afixed threshold, called the activation threshold.If it is, then we conclude that enough informa-tion has been accumulated to try to make a de-cision.
The low value for this language a(l) isthen compared against he high value aff(l') forthe next best language l', and if aL(l) exceedsaH(l') language l is output and the algorithmhalts.
Otherwise, the process continues withthe next token, until the best choice languageis a clear "winner" over any other.Finally, if we reach the end of the input datawithout a decision being made, several optionsare possible, depending on the needs of the ap-plication.
We can simply output the languagewith the highest base score, even if the secondtest is not satisfied.
Alternatively, we can out-put the highest scoring language, and all otherlanguages whose high probability is greater thanthe low probability of this language.2.2 Tra in ing  the  mode lThe model is trained using a collection of cor-pora for which the correct language is known.For a given language I and token t, let f ( t ,  l) bethe count of the token in that language and .f(l)be the total count of all tokens in that language.f ( t )  is the count of the token t across all the \]lan-guages, and F the count of all tokens across alllanguages.
The probability of the token occur-ring in the language p(tll ) is then calculated byassuming that the probabilities follow a bino-mial distribution.
The idea here is that tokenoccurrences are binary "events" which are eitherthe given token t or are not.
For large f ( t ,  l), theunderlying probability can be calculated by us-ing the normal approximation to the binomial,giving the base probabilityps(t l l  ) = ff(t,t)f ( t )The standard eviation of this quantity isa(t, 1) = ~/f( l )ps(t l l ) (1 - ps(t l l ) )The low and high probabilities are found bytaking a given number of standard deviationsd from the base probability.pL(tll ) = f ( t ,  l) - da(t, l).f(t)pu(tll) = f(t ,  l) + da(t, l)f ( l )In the evaluation below, d was set to 2, giving95% confidence limits.For lower values of f ( t ,  l), the calculation ofthe low and high probabilities can be made moreexact, by substituting them for the base prob-ability in the calculation of the standard evia-tion, givingpL(tll ) = f ( t ,  l) - d~/f( l)pt.
(t l l)(1 - pL(tll'))'f ( l )pu(t l l )  = f ( t ,  l) + dx/ f ( l )pu(t l l ) (1  - pu(t l l ) )f ( l )Approximating 1 -  pL(tll) and 1 -pu( t l l )  to lon the grounds that the probabilities are small,and solving the equations gives(~fd 2 + 4f ( t , l )  - d) 2pL(tll) =4f(l)pu(tl l)  = (x /~ + 4f(t ,  l) + d) 24f(/)The calculation requires marginally more com-putational effort than the first case, and in prac-tice we use it for all but very large values off ( t , l ) ,  where the approximation of 1 -pL ( t l l  )and 1 -pu( t l l  ) to 1 would break down.For very small values of f ( t , l ) ,  say lessthan 10, the normal approximation is not goodenough, and we calculate the probabilities byreference to the binomial equatibn for the prob-ability of rn (=y(t; l)) successes in n (= f ( l ) )trials:p(rn) = Prn(1 - P)n--rnn!m!
(n -- rn)!p is the underlying probability of the distribu-tion, and this is what we are after.
By choos-ing values for p(rn) and solving to find p wecan obtain a given confidence range.
To ob-tain a 95% interval, p(m) is set to 0.025, 0.5and 0.975, yielding pt,(tll), ps(t l l ) ,  and pu(t l l ) ,respectively.
In fact, this is not exactly howthe probability ranges for low frequency itemsshould be calculated: instead the cumulativeprobability density function should be calcu-lated and the range estimated from it s .
For thepresent purposes, the low frequency items donot make much of a contribution to the overallsuccess rate, and so the approximation is unim-portant.
However, if similar techniques were ap-plied to problems with sparser data, then theprocedure here would have to be revised.Finally, we need a probability for tokenswhich were not seen in the ti'aining data, calledthe zero probability, for which we set m = 0 inthe above equation givingp(0l/) = 1 -It is not clear what it means to have a confidencemeasure here, and so we use a single value forbase, low and high probabilities, obtained bysetting p(m) to 0.95.Similar calculations using f ( t )  in place off ( t , l )  and F in place of f ( l )  give the a prioritoken probabilities p(t).
As already noted, base,low and high value could have been calculatedin this case, but as a minor simplification, weuse only the base probability.~Thanks to one of the referees for pointing this out.9693 Eva luat ionTo evaluate the technique, a test was run usingsimilar data to Sibun and Reynar.
Corpora foreighteen languages from the European CorpusInitiative CDROM 1 were extracted and splitinto non-overlapping files, one containing 2000tokens 3, one containing 200 tokens, and 25 fileseach of 1, 5, 10 and 20 tokens.
The 2000 and200 token files were used as training data, andthe remainder for test data.
Wherever possiblethe texts were taken from newspaper corpora,and failing that from novels or literature.
Theidentification algorithm was run on each test fileand the results placed in one of four categories:?
Definitive, correct decision made.?
No decision made by the end of the input,but highest scoring language was correct.?
No decision, highest scoring language in-correct.?
Definitive, incorrect decision made.The sum of the first two figures divided by thetotal number of tests gives a measure of accu-racy; the sum of the first and last divided by thetotal gives a measure of decisiveness, expressedas the proportion of the time a definitive deci-sion was made.
The tests were executed usingword shape tokens on the same coding schemeas Sibun and Reynar, and using the words asthey appeared in the corpus.
No adjustmentswere made for punctuation, case, etc.
Vari-ous activation thresholds were tried: raising thethreshold increases accuracy by requiring moreinformation before a decision is made, but re-duces decisiveness.
With shapes and 2000 to-kens of training data, at a threshold of 14 ormore, all the 20 token files gave 100% accu-racy.
For words themselves, the threshold wasset to 22.
The results of these tests appear intable 1.
The figures for the activation thresholdwere determined by experimenting on the data.An interesting area for further work would be toput this aspect of the procedure on a soundertheoretical basis, perhaps by using the a prioriprobabilities of the individual anguages.3Sibun and Spitz, and Sibun and Reynar, presenttheir results in terms of lines of input, with 1-5 linescorresponding roughly to a sentence, and 10-20 lines toa paragraph.
Estimating a line a.s 10 words, we are there-fore working with significantly smaller data sets.The accuracy figures are generally similar toor better than those of Sibun and Reynar.
Thecorresponding figures for 200 tokens of trainingdata appear in table 2, for the token identifica-tion task only.One of the strengths of the algorithm is thatit makes a decision as soon as one can be madereliably.
Table 3 shows the average number oftokens which have to be read before a decisioncan be made, for the cases where the decisionwas correct and incorrect, and for both casestogether.
Again, the results are for word shapetokens, and for words alone.
The figures showthat convergence usually happens within about10 words, with a long tailing off to the results.The longest ime to convergence was 153 shapetokens.A manual inspection of one run (2000 linesof training data, tokens, threshold=14) showsthat errors are somtimes clustered, althoughquite weakly.
For example, Serbian, Croatianand Slovenian show several confusions betweenthem, as in Sibun and Reynar's results.
Thereare two observations to be made here.
Firstly,there are about as many other errors betweenthese language and languages which are unre-lated to them, such as Italian, German and Nor-wegian, and so the errors may be due to poorquality data rather than a lack of discrimina-tion in the algorithm.
For example, Croatianis incorrectly recognised as Serbian 3 times andas Slovenian once, while the languages whichare misrecognised as Croatian are German andNorwegian (once each).
Secondly, even wherethere are errors, the range of possibilities hasbeen substantially reduced, so that a more pow-erful process (such as full-scale OCR followedby identification on words rather than shape to-kens, or a raising of the threshold and addingmore data) could be brought in to finish thejob off.
That is, the confidence limits have pro-vided a benefit in reducing the search space.The confusion matrix for this case appears inan appendix.3.1 Broader  app l icab i l i tyAlthough the algorithm was developed with lan-guage identification i  mind, it is interesting toexplore other classification problems with it.
Asimple and rather crude experiment in "genre"identification was carried out, using the Browncorpus.
Each section of the corpus (labelled A,97Test and Accuracy (%) Decisiveness (%)threshold Tokens of tesl~ data Tokens of test dataTokens (0)Tokens (10)Tokens (14)Words (0)Words (10)Words (22)171.692.994.278.495.896.95 10 2072.7 69.6 72.098.4 98.4 98.299.6 99.1 10080.4  77.1 78.797.6197.1 98.099.8 99.8 100Al l71.497.098.278.797.199.11 5 10 20 All88.0 99.3 100 99.8 96.866.0 98.9 99.6 99.8 91.149.8 98.9 99.6 99.8 87.097.3 100 100 100 99.376.9 99.8 100 99.8 94.129.3 98.9 99.8 99.8 81.9Table 1: Performance with 2000 tokens of training dataThreshold0510Accuracy (~7o)Tokens of test data1 5 10 20 Al l63.3 72.4 48.9 ,17.1 57.982.2 88.9 75.6 75.8 80.686.0 94.0 88.0 87.6 ,88 .9Decisiveness (%)Tokens of test data1 5 10 20 Al l72.2 89.6 96.7 96.2 88.758.0 86.4 93.3 93.8 82.945.6 85.1 91.1 92.4 78.6Table 2: Performance with 200 tokens of training data (word shape tokens only)B, C ... R in the original) was taken as a genre,and files of similar distribution to the previousexperiment were extracted.
Because this is amore unconstrained problem, the training setand tests sets were about 10 times the size ofthe language identification task.
A 20000 wordfile was used as training data, and the remain-ing files as test data.
Accuracy and decisive-ness results appear in table 4.
Beyond the ac-tivation threshold of 12, there is no significantimprovement in accuracy.
The technique seemsto give good accuracy when there is sufficientinput (100 words or more), but at the cost ofvery low decisiveness.
Excluding a fixed list ofcommon words such as function words mightincrease the decisiveness.
These results shouldbe taken with a pinch of salt, as the notion ofgenre is not very well-defined, and it is not clearthat sections of the Brown corpus really repre-sent coherent categories, but they may providea starting point for further investigation.3.2 On dec is ivenessDecisiveness represents the degree to which aunique decision has been made with a high de-gree of confidence.
In cases where no unique de-cision has been made, the range of possibilitieswill often have been reduced: a category is onlystill possible at any stage if its high accumula-tor value is greater than the low accumulatorvalue of the best rated category.
To illustratethis, the number of categories which are stillpossible when all the input was exhausted wasexamined.
The results appear in tables 5 and6, for the tests of language identification fromword shape tokens with an activation thresholdof 14 and a training set of 2000 tokens, and forgenre identification with a threshold of 12 and atraining set of 20000 tokens.
Results are shownfor the cases of a correct decision, an incorrectone, and all cases.
The average number ofpossibilities remaining is 1.3 out of 18 for thelanguage identification test, and 9.7 out of 15for the genre test, showing that we are generallynear to convergence in the former case, but haveonly achieved a small reduction in the possibil-ities in the latter, in keeping with the generallylow decisiveness.3.3 A fu r ther  compar i sonThe classification algorithm described abovewas originally developed in response to Sibunand Spitz's work.
There is another approachto language identification, which has a certain98Threshold0101422Shape tokensCorrect Incorrect3.22 1.237.33 4.559.35 6.50All2.657.289.33WordsCorrect i Incorrect1.81 1.075.31 3.8810.6 8.00All1.665.2810.6Table 3: Average number of tokens read before convergenceThreshold010121047.750.950.9Accuracy (%)Words of test data50 100 200 All76.0 83.7 80.8 72.186.9 96.8 99.5 83.586.9 96.8 99.7 83.6Decisiveness (%)Words of test data10 50 100 200 All36.3 38.7 39.5 42.9 39.32.13 15.5 16.5 18.1 13.11.07 14.1 114.9 16.0 11.5Table 4: Performance on genre identificationLanguagesremainingi23456789101112131718Number of testsCorrect i Incorrect1560 6128 737 918 25 15 12 02 01 03 01 02 02 01 07 0All1566135462066221312217Table 5: Categories remaining at end of in-put (language identification from word shapetokens)--Genresremaining123456789101112131415Number of testsCorrect Incorrect173 022 031 145 334 465 873 483 384 389 284 0128 1131 0175 1253 0All17322324838737786879184129131176253Table 6: Categories remaining at end of input(genre identification)amount in common with ours, described in apatent by Martino and Paulsen (1996).
Theirapproach is to build tables of the most frequentwords in each language, and assign them a nor-malised score, based on the frequency of occur-rence of the word in one language compared tothe total across all the languages.
Only themost frequent words for each language are used.The algorithm works by accumulating scores,until a preset number of words has been reador a minimum score has been reached.
Theyalso apply the technique to genre identification.Since there is a clear similarity, it is perhaps99worth highlighting the differences.
In terms ofthe algorithm, the most important difference isthat no confidence measures are included.
Thecomplexities of splitting the data into differentfrequency bands for calculating probabilities arethus avoided, but no test analogous to overlap-ping confidence intervals can be applied.
Mar-tino and Paulsen say they obtain a high degreeof confidence in the decision after about 100words, without saying what the actual successrate is; we can compare this with around 10words (or tokens) for convergence here.4 Conc lus ionsWe have examined a simple technique for clas-sifying a stream of input tokens in which con-fidence measures are used to determine when acorrect decision can be made.
The results intable 1 show that there is a tradeoff betweenaccuracy and the degree to which the algorithmselects a single language.
Not surprisingly, theamount of training data also affects the per-formance, with 2000 tokens being adequate foraccuracy close to 100%, and convergence typi-cally being reached in the first 10 tokens.
Ona more unconstrained problem, such as genreidentification from words alone, the algorithmperforms less well in both accuracy and deci-siveness even with significantly more trainingdata, and is probably not adequate xcept as apreprocessor to some more knowledge intensivetechnique.In a sense, language identification is not avery interesting problem.
As we have noted,there are plenty of techniques which work well,each with its own characteristics and suitabilityfor different application areas.
What is perhapsmore important is the way the statistical infor-mation has been used here.
When we take astatistical or data-led approach to NLP, thereare two things which can help us trust thatthe technique is accurate.
The first is a be-lief that the statistical technique is an adequatemodel of the underlying process which "gener-ates" the data, using theoretical considerationsor some external source of knowledge to informthis belief.
The second is quantitative valua-tion on test data which has been characterisedby an outside source (for example, in the case ofpart of speech tagging, a corpus which has beenmanually annotated, or at least automaticallytagged and manually corrected).
The problemwith quantitative valuation is that we do notknow whether it will generalise, so that if wetrain on one data set, we have only the theo-retical model to reassure that the same modelwill work on a different data set.
The idea Ihave been presenting here is to get the statisti-cal process itself to provide feedback about it-self, through the use of confidence limits whichare themselves based in the statistical model.
Indoing so, we hope to avoid presenting a resultfor which we lack adequate vidence.AcknowledgementThanks to Robert Keiller of Canon ResearchCentre Europe for his advice on computing ac-curate statistics.Re ferencesGary Adams and Philip Resnik 1997.
A Lan-guage Identification Application Built on theJava Client/Server Platform.
In Proceedingsoff the Workshop 'From Research to Commer-cial Applications: Making NLP TechnologyWork in Practice', ACL/EACL, Madrid.William B. Cavnar and John M. Trenkle 1994.N-Gram Based Text Categorization.
In Pro-ceedings off the Third Annual Symposiumon Document Analysis and Information Re-trieval, pages 161-169, Las Vegas, Nevada.I.
Dagan, A. Itai and U. Schwall 1991.
TwoLanguages are Better Than One.
In Proceed-ings of the 29th Annual Meeting of the Asso-ciation for Computational Linguistics, pages130-137.Ted Dunning 1994.
Statistical Identification ofLanguage.
Computing Research LaboratoryMemo MCCS 940-273, New Mexico StateUniversity.Michael J. Martino and Robert C. Paulsen, Jr.1996.
Language Identification Process UsingCoded Language Words.
US Patent Number5548507 (Issued 1996-08-20).Penelope Sibun and A. Lawrence Spitz.
1994.Language Determination: Natural LanguageProcessing from Scanned Document Images.In Proceedings of the 4th Conference on Ap-plied Natural Language Processing, pages 15-21, Stuttgart, Germany.
Association for Com-putational Linguistics.100Penelope Sibun and Jeffrey C. Reynar.
1996.Language Determination: Examining the Is-sues.
In Proceedings of the 5th Annual Sym-posium on Document Analysis and Informa-tion Retrieval, pages 125-135, Lass Vegas,Nevada.Append ixConfusion matrix for the case of 2000 lines oftraining data, token, threshold=14.
An entryin this matrix means that the language on thehorizontal axis was classified as being in the lan-guage on the vertical axis in the indicated num-ber of test samples.
(alb = Albanian, cro = Croatian, dan = Dan-ish, dut = Dutch, eng = English, est = Esto-nian, fre = French, ger = German, ira -- Italian,lat = Latin, lit = Lithuanian, real = Malay, nor= Norwegian, por = Portugese, set = Serbian,slo = Slovenian, spa = Spanish, tur = Turk-ish.
Some of the languages are in a Romanisedform.
)albcrodandutengestfregeriralatlitrealnorporserslospatura c d d e e f g i 11 r a u n s r e t ab o n t g t e r a t1009610010099 293121199111297 1979998m n p s s s ta o o e 1 p uI r r r o a r10098 198100 1989799101
