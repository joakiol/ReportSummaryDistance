Towards Multimodal Spoken Language Corpora:TransTool and SyncToolJoakim Nivre Jens Allwood Jenny Holm Dario Lopez-K~tenKristina Tullgren Elisabeth Ahls6n Leif Gr6nqvist Sylvana SofkovaE-mail:G6teborg UniversityDepartment ofLinguisticsf i r s tname,  las tname@l ing ,  gu.
seAbstractThis paper argues for the usefulness of multimodal spoken language corpora andspecifies components of a platform for the creation, maintenance and exploitationof such corpora.
Two of the components, which have already been implementedas prototypes, are described in more detail: TransTool and SyncTool.
TransToolis a transcription editor meant o facilitate and partially automate the task of a hu-man transcriber, while SyncTool is a tool for aligning the resulting transcriptionswith a digitized audio and video recording in order to allow synchronized pres-entation of different representations (e.g., text, audio, video, acoustic analysis).Finally, a brief comparison is made between these tools and other programs de-veloped for similar purposes.1.
In t roduct ionThe availability of adequate tools for the crea-tion, maintenance and use of multimodal spo-ken language corpora is an important instru-mental goal for spoken language research,whether this research is motivated primarilyby the desire to gain a better understanding ofthe mechanisms of spoken communication rby the wish to develop practical applicationssuch as multimodal interfaces for human-machine interaction.Multimodal dialog systems will be a fea-ture of many future applications, e.g., infor-mation systems.
They will also be a feature ofmany VR systems and tutoring systems.
Thebasic source of inspiration for dialog systemsis ordinary human face-to-face communica-tion involving both speech and gestures.However, our understanding of human com-munication as a multimodal phenomenon isstill very insufficient.
Thus, there is a needfor tools which will enable us to gain a betterunderstanding of the relations between prop-erties of human face-to-face communication,such as gestures, intonation, words and11grammar, and of how the utterances andgestures of different speakers are coordinatedwith each other.In this paper, we report on a long-termproject o develop a platform for multimodalspoken language corpora.
More specifically,we describe two modules of such a platform,which both exist in prototype implementa-tions.
The first of these modules, which iscalled TransTool, is a transcription editorwhich assists a human transcriber in produc-ing transcriptions in accordance with a givenstandard and partially automates some of thetasks involved, e.g., in the marking of over-lapping speech.The second one, SyncTool, is a tool foraligning transcriptions with the correspondingdigitized audio and video recordings in orderto allow synchronized isplay of differentrepresentations.
Again, this is meant o pro-vide support for a human analyst rather thanto provide a completely automated process,although the latter would of course be prefer-able in the long run.Before we turn to a detailed escription ofTransTool and SyncTool, however, we willtry to set the stage by presenting the platformfor multimodal spoken language corpora ofwhich these tools are meant o be part.2.
BackgroundEven though face-to-face spoken interactionis one of the most basic forms of humancommunication, many aspects of it are stillnot well understood.
To some extent, thislack of knowledge is due to a lack of gooddata as well as adequate tools for presentingand analysing the data.
In order to study spo-ken communication efficiently, we need notonly recordings of naturally occurring spokencommunication and transcriptions of theserecordings, but also tools for presenting andanalysing these transcriptions and recordingsin a flexible and efficient manner.The picture is further complicated by thefact that face-to-face spoken communicationis multimodal, involving gestures as well asspeech, which means that video recordingsare usually required.
But this also means thattranscriptions must be synchronized and dis-played together not only with an acoustic sig-nal but also in conjunction with visual data ongestures, etc., which tends to magnify thetechnical difficulties involved.Putting together a multimodal spoken lan-guage corpus is a very labor intensive task.First of all, manual transcription is laboriousand time-consuming in itself, and even moreso if the multimodal aspects of spoken com-munication are taken into consideration.
Tothis we have to add the work needed to insurethat transcriptions and recordings are properlyaligned, so that they can be displayed andanalysed in a synchronized fashion.In order to improve the situation, we needto develop adequate tools for the creation,maintenance and exploitation of multimodalspoken language corpora.
Wherever possible,the aim should be to automate the processing,but for many of the tasks involved we willprobably have to be content with providingcomputer support for manual work, supportwhich either speeds up the process, or re-duces the error rate, or indeed both.The Department ofLinguistics at G6teborgUniversity has been involved in the empiricalstudy of face-to-face spoken communicationsince the late 1970s.
This has resulted in acorpus of transcribed spoken Swedish, whichcontains a wide variety of different activitytypes and which currently contains about onemillion word tokens (cf.
Allwood 1998).Over the years, a fairly detailed transcrip-tion standard has been developed, the mostimportant features of which are the following(cf.
Nivre 1998).?
A transcription consists of a header,containing background informationsuch as type of activity, participants,date of recording, duration, transcriber,etc., and a body, containing the tran-scription proper.?
The transcription body consists ofspeech lhws, containing the transcribedspeech of dialog participants (each lineintroduced by a speaker initial); com-ment lhws, containing comments per-taining to phenomena in speech lines(see below); section lhws, indicatingboundaries between subactivities ortopics; and time lines, containing in-formation about he amount of timeelapsed from the start of the activity.?
Words are transcribed using standardorthography modified to capture spokenlanguage variants and reductions (e.g.,the Swedish first person pronoun 'jag'is transcribed 'ja' or 'jag' according tothe actual pronunciation).?
Spoken language variants are indexedfor disambiguation to the level of stan-dard orthography (e.g., the Swedishfirst person pronoun is transcribed 'ja 1'to distinguish it from the affirmativeparticle 'ja0' \[yes\]).?
Overlapping speech is marked bymeans of indexed square brackets(where the same index on differentpairs of brackets indicate simultaneity).?
Comments are made by enclosing thecommented part of an utterance in(possibly indexed) angle brackets andputting the actual comment in matchingbrackets on a separate comment line.An elaborate system of standardizedcomments, including comments for thecoding of gestures, allows automaticparsing of comment information.12A short extract from a transcription, exempli-fying most of the features discussed above,can be found in Figure 1.Producing transcriptions in accordancewith this standard is a very time-consumingtask without adequate tools.
It can also be anerror-prone task, mostly because it involves alot of numerical indexing (of words, com-ments, overlaps, etc.).
This is the reason thatwe have thought it necessary to develop acomputer tool to assist the manual transcriberin this process and partially automate some ofthe tasks involved (cf.
section 3).However, although transcriptions of thiskind constitute a useful form of data for thestudy of spoken language, they are neverthe-less insufficient in themselves and need to besupplemented with the actual sound and videorecordings.
Moreover, transcriptions and re-cordings need to be aligned so that analystscan view them together and do various typesof coding and analysis based both on the re-cording and the transcription.In order to satisfy these needs, we believethat several tools are needed.
Hence, we haveembarked on the project of building a plat-form for multimodal spoken language cor-pora, consisting of a set of integrated toolsfor the creation, maintenance and use of suchcorpora.
The planned tools of the platform arethe following:?
A tool for digitizing audiovisual corpusdata (recordings).?
A tool for producing and checkingstandardized transcriptions(TransTool).?
A tool for semi-automatic alignment ofaudio/video and transcribed text(SyncTool).?
A multimodal corpus presentation tool,allowing simultaneous and synchro-nized display of transcriptions andaudio/video recordings.?
A transcription coding tool, includingdisplay of transcriptions in differentformats, with optional use of synchro-nized audio/video display.?
An analysis tool for processing infor-mation from the coding tool (and fromthe corpus itself).If possible, all tools should be implementedin a platform-independent way and preferablyallow access via the Internet.Before we go on to describe the two toolsrelating directly to transcription - - TransTooland SyncTool - -  it might be worth address-ing the question of why we have chosen todevelop our own tools instead of using ex-isting ones.
The simple answer is that wehave not so far been able to find any tools thatprovide the right kind of functionality in theright kind of environment.
First of all, thereis no abundance of software in this domain.Secondly, many of the programs that do existare developed for a specific purpose or a spe-cific standard, which makes them hard to usein other contexts.
Finally, most of the pro-grams are available only on one or two soft-ware platforms, which may or may not be aproblem depending on whether this happensto coincide with the platforms that you areworking with yourself.However, although we have not so farbeen able to reuse existing tools, it is clearlyimportant to be open to developments withinthe area.
In section 5, we will therefore makesome brief comparisons between our toolsand similar programs developed by others.Hopefully, this can contribute to a better un-derstanding of the similarities and differencesbetween different approaches and pave theway for cooperation i the future.$A: ja0 de0 e0 <14 \[4 havsstr6mmarnaandra f~rh~l landen d~r borta@ <14 gesture: B nods >$B: \[4 m0 \]4\]4 som g6r >14 att de0 e0Figure 1.
Transcription extract\[Translation f A's utterance: 'yes it is because of the seacurrents that there are other conditions over there'.\]133.
TransToolTransTool is a computer tool for transcribingspoken language in accordance with the stan-dard developed within the research programSemantics and Spoken Language at G/SteborgUniversity, Department of Linguistics, anddescribed in Nivre (1998) (cf.
section 2).The current implementation f TransToolis done in Tcl/Tk (Tool Command Language/Toolkit) and runs (at least) in Unix, Macin-tosh and Windows environments.
The latestversion of the program can be downloadedfrom http://www.ling.gu.se/gmslc/.TransTool is equipped with File-, Edit-and Format menus which operate in much thesame way as in word processing programs(Figure 2).In addition, TransTool contains three specialmenus for the transcription of spoken lan-guage: the Add menu, the Comment menu,and the Tools menu.The Add menu (Figure 3) contains com-mands for starting a new utterance (New ut-terance), for inserting time codes (Time code)and section boundaries (Section), and formarking inaudible speech (Inaudible speech).All of these commands help speed up thetranscription process while at the same timeminimizing the risk for typing errors and en-suring conformance with the transcriptionstandard.Figure 3.
The Add menuFigure 2, The File, Edit and Format menusThe Add menu also contains a command formarking overlapping speech (Overlap), whichautomatically inserts and keeps track of thenumerical indices used to indicate which por-tions of speech overlap with each other (cf.Figure 1).The final command in the Add menu is thecommand for adding a header to the tran-scription (Header).
This command invokes aset of standardized forms, where the user hasto fill in all the relevant information about therecorded activity, such as time and place ofrecording, type of activity, participants, tran-scriber, etc.
involved in this particular con-versation and appnopdate initials for them,transcriber, etc.
The forms used to composethe header can be seen in Figures 4 and 5,while the resulting header can be seen in Fig-ure 6.The second special menu is the Commentsmenu (Figure 7), where the user can selectthe whole range of standardized commentsprovided by the transcription standard.
Thecomments are displayed in sub-menus, orted14by category, which may be ripped off andplaced as separate windows on the screen.When using this menu, the user first selectsthe portion of speech that he wants to make acomment about, and then selects the appro-priate type of comment from one of the sub-menus.
The comments are automatically in-dexed.The final menu of interest is the Toolsmenu (Figure 8), which mainly containscommands for indexing.
In addition to theindexing of comments and overlap (seeabove), which may need to be updated, thetranscription also requires ambiguous spokenlanguage variants (such as the pronunciation'ja' of the Swedish first person pronoun'jag') to be disambiguated by numerical indi-ces.
This is done through the command MSOindices (where MSO stands for ModifiedStandard Orthography), which automaticallyidentifies all word forms that need to be in-dexed and prompts the user for disambigua-tion.Figure 4.
Header form (1)Figure 5.
Header form (2)15Figure 6.
Specified headerFigure 7.
The Comments menuFigure 8.
The Tools menu164.
SyncToo lSyncTool is an application developed forsynchronizing transcriptions with digitizedaudio/video recordings.
SyncTool is meant obe a synchronizing and viewing tool, allow-ing the researcher to set time codes in appro-priate places in the transcriptions, and to viewthe transcription and play the recording with-out having to manually locate the specificpassage in the recording.SyncTool is still in early development,with a limited but working prototype, down-loadable from http://www.ling.gu.se/gmslc/.Development is done with cross platformcompatibility in mind targeting the Macintosh,Windows and Unix platforms.
The prototypehas been implemented using a combination ofAppleScript and Tcl/Tk on the Macintoshplatform; we are currently moving to pureTcl/Tk and have started a re-implementationin Java.SyncTool presupposes the following data:?
A transcription conforming to the tran-scription standard (cf.
section 2).?
A media file of some kind, containingthe corresponding audio and/or videorecording in digitized form.The user interface is quite straightforward.The user is presented with three windows(Figure 9):?
The Transcript Score & Time LineWindow presents the transcription imusical score format along with a timeline extracted from the media and mediacontrol buttons (bottom window inFigure 9).?
The Media Window (currently an exter-nal tool) displays the audio/video re-cording, allowing the user to swiftlymove back and forth in the recording(top right window in Figure 9).?
The Full Transcript Window displaysthe transcription i original format.All of these windows, except he Full Tran-script Window are available in the prototypewe have running.
In the final version, whileplaying an audio or video sequence, the tran-scription will be scrolled and a visual cue willbe shown to indicate which part of the tran-scription is currently on display.
Media con-trois, such as Play, Stop, etc.
will be avail-able, as well as controls for setting the vol-ume, playback speed, stepping back and forthin the recording and looping sequences.The Speaker Pane inside the TranscriptScore & Time Line Window is where thetranscription is presented to the user in thespecial score format used by SyncTool(Figure 10).
The score format is a convenientway of displaying an ongoing dialog involv-ing several speakers.Each speaker is assigned a 'channel' ortrack, and the utterances that s/he producesare segmented by means of transcriptionpoints.
Transcription points correspond tospeaker changes and the start and end ofoverlaps.
The transcription points used tosegement the utterances in the Speaker Paneare derived automatically from the underlyingtranscription.
When a transcription is dis-played in musical score format, transcriptionpoints span all the speaker channels in theSpeaker Pane and are numbered, as can beseen in Figure 11.The Time Line Pane inside the TranscriptScore & Timeline Window allows the user tospecify where in the timeline of the recordingeach of the transcription points occur.
Time ismeasured in minutes, seconds and frames forvideo with audio, and minutes, seconds andmilliseconds for audio only recordings.A slider for each transcription point sets itstime in the recording (as shown by the labelbeneath it), and can be moved back and forththrough the timeline.
Transcription point slid-ers cannot go outside their boundaries, e.g.,it is not possible for transcription point 2 tomove to the left of transcription point 1, or tothe right of transcription point 3, and so on.In Figure 13 the correspondence b tweenthe transcription points in the Speaker Paneand in the Timeline Pane is highlighted witharrows.Initial placement of sliders is very roughlycalculated with a simple algorithm, whichdistributes the sliders along the timeline moreor less according to the length of the utter-ance.
Note that we are not doing any kind ofsound signal analysis; the algorithm is basedon length of the text appearing in the tran-script.
The result is, as could be expected, notvery good, but it helps somewhat and savessome time; we are working on improving the17| \ [ \ ]  :.....::..+.:.:.:::.....::.~......:..+.......::.:.......
:: :~'.i.
:;:::.
~.'.:.':::;~..~:.:~...~.....~:.
:..~---- WOO i kort,l~4~5:.i:.:.:~'.:~;::.;~::~::i.~.:~:i.
:::;:::~ 7.:~:::~.+.!~:~.~.~;~::~.~.:.::~.~:.;~:.~.:~:~.~.:~.
:~:.~:.~:...........~:~ ;.
.
; .
:: .
.
::: .:..
.
:  \[\] II1~ I I II I  -~1|I+ .
.
.
.
)dl.a Pig901- /k .e+ + $~I0 h$l..tQ41,11 0 a41o r io  10111 40 f61"lt'l I l l  l ip l 111 oi0 /~ii.i fal ,~.
~ N0 ib l  lJIlII 2 ~ dl 5 $I!, ,,++++~ ++ +,++ +,+++++,+++~+++0~++ ++,+++++++~ ~, III I m,, +.
.~ ,,,:+ ~ ~,~+~+.+~+++++~++++++++++ + + ~++++++ ++ :.
+ ++++ ~  4 , ~: ++ ~+++ ?~ ~,+ +  ~,~+++ + ~ +++++~++++++~+ +~+    ++ + +++ + ~ ++++++ :IIml ..............  m ++::: ++~: ++++++m++ :  ~+ :~++++:: ++~ ~ + ++++++:++~++~+~:+++:m+ + ~+ +.
+~++. '
~+ ......... ++~++~+ ++++++++++ + + ~.
m+~ +  - - + + ~ ~ z : : - ~  +~-~ i i  + ++ ................... + ... ..................................................................................... +++~'++~+~ .
.
..... + + .
.
.
.
.
?
+:+:..:.:.::+;+.
:::~:::+:+:::+ .~:+::.
: :::~:+~:~+:::~:::~ ~:++::`~`` ++::~:~+:~::~m:+m::~+~+~+:++~:m~:+~:mm:+++++~m~+:++++~+~+~+~:~+~++~+~5+::~+:m+~++++++~:~+:+:++~:+~`~++:+~+++~:~+~:~::+~ ~;::+.:;.:!
,+1  ~ ll~| ?
~ lllpm+I Ii, .~o .+ ....... + ............. .++~ .
.
.
.
.
.
z .
.
.
.
.
.
.
.
.
.
.
.
.
_ .
.
.
.
.
.
.
+ .
.
.
.
.
.
.
+ + \]i I ?, ,+ ............. , .
.
.
.
.
.
.
.
.
.
.
.
.
+ .... ...... ...... .............. ............ ......... ........ + ................. ++.
,I IF igure  9.
Overv iew o f  the  SyncToo l  user  in ter face\ [ \ ]  - -==-+VamkOrt .mS5 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
- - - -=  \ [ \ ]  \ [ \ ]? )
du riggar /lkameranl an sSO i: IL~nge / eO deO riO sore eO f6rst \[el er | j:I 2 3 4 5m,,  +.~,++;+~+++:~++H----i ++;a++~+i+++++~+~+ ++ J+ +  :: +i:++!++ii+ i +++ !
:+++++:+++ + ~ +i+++++  + .
+: i ++~:+ i!
: +:  +++   + + ++ ++++++   ++ .
.
:: +++++:+F igure  10.
Speaker  Pane, t ranscr ipt ion in score format: I Ikameron ~nI 2o.F igure  11 .
Channe ls  in  the  Speaker  Pane;  th ree  speakers :  c ,  i and  j1BFigure 12.
Timeline Pane, with transcription point slidersFigure 13.
Timeline Pane, with transcription point slidersII I l,i~ ii~;ii~i~;~ ~ ~:~/:.:~;...:~:;...".
:i!~i~i:i~?~iiii:;Figure 14.
Go to transcription pointalgorithm, possibly using words per secondmeasures and/or involving simple sound sig-nal analysis.To go to a specific transcription point, theuser enters it in the 'Go to transcription point'edit field (Figure 14).
Both the Speaker Paneand the Timeline Pane then scroll to the tran-scription point in question.Double clicking on a slider plays the re-cording from that ranscription point.
To stopplayback, the user presses the space key onthe keyboard.
The prototype also implementsprimitive playback controls, currently onlyStart and Stop.
These will be enhanced in up-coming versxons.The Media Window is currently imple-mented as an external application, The MediaViewer.
It has no user interface apart from themedia controllers, and its only purpose is toallow other applications to communicate withit and programmatically tell it to open mediafiles, start/stop layback, provide data on themovie, etc.
It uses QuickTime and all the me-dia formats that QuickTime supports (i.e.MPEG, QuickTime movies, AIFF, WAV,etc.
), and it provides full motion playback of19MPEG-1 movies with appropriate computerhardware.The Media Viewer is available as a sepa-rate Macintosh application.
Note however thatwe are in the process of implementing thefunctionality of The Media Viewer into Sync-Tool as plug-in module, which we hope willgive us better control of how media files areused in SyncTool.Planned, but currently missing features in-clude the possibility to visualize sound wavesalong the Time Line Pane, which will let us-ers more easily position the transcriptionpoint sliders.
We are also considering the in-clusion of spectrograms, etc.
Furthermore,we need to implement the real-time visual cueindicating which part of the transcription isbeing played back.
This will be much easierto achieve when the Media Viewer function-ality is built into SyncTool.
Another featurethat is going to be implemented is the possi-bility to add and delete transcription points, aswell as separate tracks for different kinds ofsynchronisations (gestures, etc).In its current state, SyncTool is not onlty asynchronising tool, it is also a viewer of syn-chronized transcriptions.
The tool presentsaudio, video and text simultaneously.
Theuser can select parts of the transcription textand have the corresponding audio or videosequence played back with a minimum of ef-fort.
With this use in mind, the possibility tocorrect errors found in the transcription, suchas incorrectly marked overlaps, will be a veryuseful feature too.
The prototype has alreadyshown its usefulness in this area, highlightingthe usability of the score format.
These errorsare quite hard to discover using the traditionalfull view of a transcription.
Therefore, it ispossible that TransTool and SyncTool will bemerged in the future.
Ultimately, our goal isto provide a set of integrated tools for tran-scription, synchronization/alignment, coding,annotation and presentation.5.
Some Compar i sonsIn this section, we will compare our tools tosome other programs that help align text andrecordings.
The tools considered are:?
SoundWalker (by Jack Du Bois)\[http://humanitas.ucsb.edu/depts/linguistics/research/csae/soundwalker/walk.html\]?
SoundWriter (by Jack Du Bois)\[http://humanitas.ucsb.eduldepts/linguistics/lab/transcriptions.html\]?
SyncWriter (by med-i-bit)\[http://www.med.i.bit/Software/syncWRITER/info.english.html\]SoundWalker/VoiceWalker/MediaWalkerlets you view recordings in 'auto-pilot' mode;we quote from the on-line manual: 'The mostdistinctive feature in SoundWalker for con-trolling the playback of recorded speech iscalled the Walk.
The Walk function plays therecording in manageable chunks so that thetranscriber can concentrate on transcribing, asit automatically Walks through the recordingone Step at a time.
It plays a brief sound biteconsisting of the first four seconds of the re-cording (one Step), and repeats this portionof sound several times to allow the user totranscribe it.
Then it steps forward slightly,beginning the second Step about one secondafter the first.
It plays this new four-secondchunk of sound several times, and thenmoves on to the third Step.
Because ach newStep overlaps partially with the previous one,the transcriber always has enough familiarcontext o know where s/he is in the record-ing.
And because the Walk is entirely auto-matic, it leaves the user's hands free to tran-scribe using his/her preferred word processorin a separate window.'
The user interface ofSoundWalker is depicted in Figure 16.S oundWalke!
,' ~ I~Figure 16.
The SoundWalker/MediaWalker user interface20Compared to our tools, SoundWalker pro-vides a subset of the functionality that weplan to provide in SyncTool, albeit in a morerefined and elegant way, which we have notachieved yet.
The main focus of Sound-Walker is to support he manual transcriptionprocess and as such that functionality shouldbe provided in Transtool.As was mentioned above, we are alreadyplanning to integrate TransTool and SyncToolThe development of The Media Viewer into aplug-in module for inclusion in Transtool isone step towards that goal.
SoundWalkeruses Word as its text processor, somethingthat we cannot do.
When transcribing spokenlanguage we use our own Modified StandardOrthography (MSO), which lets us transcribespeech as it is actually pronounced.
MSOthen uses an indexing system to map betweenStandard Orthography and MSO.
This in-dexing feature, along with automated overlaphandling, is managed by TransTool.Turning from SoundWalker to Sound-Writer, we first note that: 'SoundWriter in-corporates the features of SoundWalker 1.1as well as the ability to align transcripts withsound files.
Basically, this program assignsstarting and ending SMPTE time codes toeach intonation unit.'
(From download page.
)SoundWriter provides more or less the ba-sic functionality we want to have in SyncTooland in addition allows the user to partially editthe transcription.
The alignment tool ofSoundWriter is very nice, and we do not haveanything like it in SyncTool or The MediaViewer today.
Something that is particularlyhelpful is the 'guessing' function in Sound-Writer.
Even if it is not a guessing functionper se (you specify the number of words persecond, and then it 'guesses' where the nextturn is) it clearly speeds up the alignment oftranscription and recording......................................................................
I .................
I .......................................................................................................................................................................................  :i ixilFigure 17.
The SoundWriter user interface21There are also differences, however.
:\['hemost important one is in the transcriptionstandard used.
From the information that ,=anbe gathered from the web site, it seems daatthis standard only covers a small subset of thephenomena taken into account by our stan-dard.
Another difference is the musical scoreformat used in SyncTool but not in Sound-Writer.
Moreover, SoundWfiter does notsupport the use of video recordings in thesame way as SyncTool does.
Finally,SoundWriter is not platform independent butonly exists for Windows computers.The third program, SyncWriter, handlestexts with simultaneous passages (tracks orchannels) and works with the notion of a mu-sical score format in a way similar to Sync-Tool.
Figure 18 shows a screenshot of theSyncWriter user interface layout.SyncWfiter does what we need to do; itsynchronizes text with a QuickTime movie.There is a Tape window (the topmost win-dow in Figure 18) that contains all the texttracks, the movie track(s) and whatever extratracks one deems necessary.
It is possible toattach a movie to the movie track.
A thumb-nail of the movie is then displayed in thetrack..~ " : :~!
::~:::: ; ~::: : :  "Neue $W-Vers ion!"
(Tape)  :: i:: .
:: : :  : : .
::: : :: : ....?
V " VW ~  - Endlich ist.sie da..
Die syncWRITER-Version.2.0.- Jetztlmm ) :00 :(L~ .32 V'ideo (Thumbnai lViewMan WomanThe camera.is sdJ uated so.that.on1 g.the.wo man,with.t he.package.ia.i n"Neue sW-Vers io .
!Present~Uon of the newQuickTime-re~d~/s,a ncWRITER: i !
!
!
: ; : ; : sWMov ie  (Mavie&/!,il i l}!iii;:;:;i Z~:: ::!
; :Figure 18.
The SyncWriter user interfaceIEFigure 19.
Synctabs22One of the drawbacks with SyncWriter isthat you have to synchronize all of the tracksseparately, as there is no hierarchy of tracksor of synctabs.
This can be very time-consuming if you have a lot of speakers.Moreover, there is no time line, you attach amovie to a movie track.
And the system withmovie thumbnails i not very elegant.So, even if SyncWriter contains ome ofthe features that we want TransTool andSyncTool to have, it is not quite adequate forour needs.
Finally, it is again platform spe-cific (Macintosh).SyncWriter:http://www.med.i.bit/Software/syncWRITER/in fo.english .
trnl6.
Conc lus ionIn this paper, we have argued for the useful-ness of an integrated platform for multimodalspoken language corpora, and we have pre-sented two simple tools that have been devel-oped as components of such a framework.Although these tools are still far from consti-tuting a full-fledged platform for multimodalspoken language corpora, with synchronizeddisplay of transcriptions and audio/video re-cordings, as well as tools for annotation andpresentation, they nevertheless represent thefirst steps towards such a platform and havealready proven useful in their own right.
Wealso believe that the experience gained fromthe development of these tools will be valu-able in future work towards a more ambitiousand useful toolbox.Re ferencesAllwood, J.
(1998) Some Frequency-BasedDifferences between Spoken and WrittenSwedish.
To appear in Proceedings of theXVIth Scandinavian Conference of Lin-guistics, Turku, November 1996.Nivre, J.
(1998) Transcription Standard.Version 5.2.
Technical Report.
G6teborgUniversity: Department of Linguistics.SoundWalker:http://humanitas.ucsb.edu/depts/linguistics/research/csae/soundwalkedwalk.htmlSoundWriter:http://humanitas.ucsb.edu/depts/linguistics/lab/transcriptions.html23
