Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics?System Demonstrations, pages 1?6,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsPOLYGLOT: Multilingual Semantic Role Labeling with Unified LabelsAlan Akbik Yunyao LiIBM ResearchAlmaden Research Center650 Harry Road, San Jose, CA 95120, USA{akbika,yunyaoli}@us.ibm.comAbstractSemantic role labeling (SRL) identifies thepredicate-argument structure in text withsemantic labels.
It plays a key role in un-derstanding natural language.
In this pa-per, we present POLYGLOT, a multilingualsemantic role labeling system capable ofsemantically parsing sentences in 9 differ-ent languages from 4 different languagegroups.
The core of POLYGLOT are SRLmodels for individual languages trainedwith automatically generated PropositionBanks (Akbik et al, 2015).
The key fea-ture of the system is that it treats thesemantic labels of the English Proposi-tion Bank as ?universal semantic labels?
:Given a sentence in any of the supportedlanguages, POLYGLOT applies the corre-sponding SRL and predicts English Prop-Bank frame and role annotation.
The re-sults are then visualized to facilitate theunderstanding of multilingual SRL withthis unified semantic representation.1 IntroductionSemantic role labeling (SRL) is the task of la-beling predicate-argument structure in sentenceswith shallow semantic information.
One promi-nent labeling scheme for the English language isthe Proposition Bank (Palmer et al, 2005) whichannotates predicates with frame labels and argu-ments with role labels.
Role labels roughly con-form to simple questions (who, what, when, where,how much, with whom) with regards to the predi-cate.
SRL is important for understanding naturallanguage; it has been found useful for many ap-plications such as information extraction (Fader etal., 2011) and question answering (Shen and Lap-ata, 2007; Maqsud et al, 2014).Figure 1: Example of POLYGLOT predicting English Prop-Bank labels for a simple German sentence: The verb ?kaufen?is correctly identified to evoke the BUY.01 frame, while ?ich?
(I) is recognized as the buyer, ?ein neues Auto?
(a new car)as the thing bought, and ?dir?
(for you) as the benefactive.Not surprisingly, enabling SRL for languagesother than English has received increasing atten-tion.
One relevant key effort is to create Proposi-tion Bank-style resources for different languages,such as Chinese (Xue and Palmer, 2005) andHindi (Bhatt et al, 2009).
However, the conven-tional approach of manually generating such re-sources is costly in terms of time and experts re-quired, hindering the expansion of SRL to new tar-get languages.An alternative approach is annotation projec-tion (Pad?o and Lapata, 2009; Van der Plas etal., 2011) that utilizes parallel corpora to trans-fer predicted SRL labels from English sentencesonto sentences in a target language.
It has showngreat promise in automatically generating such re-sources for arbitrary target languages.
In previ-ous work, we presented an approach based on fil-tered projection and bootstrapped learning to auto-generate Proposition Bank-style resources for 7languages, namely Arabic, Chinese, French, Ger-man, Hindi, Russian and Spanish (Akbik et al,2015).Unified semantic labels across all languages.One key difference between auto-generatedPropBanks and manually created ones is that theformer use English Proposition Bank labels for1Figure 2: Side by side view of English, Chinese and Spanish sentences parsed in POLYGLOT?s Web UI.
English PropBankframe and role labels are predicted for all languages: All example sentences evoke the BUY.01 frame and have constituentsaccordingly labeled with roles such as the buyer, the thing bought, the price paid and the benefactive.all target languages, while the latter use language-specific labels.
As such, the auto-generated Prop-Banks allow us to train an SRL system to consumetext in various languages and make predictions ina shared semantic label set, namely English Prop-Bank labels.
Refer to Figures 1 and 2 for examplesof how our system predicts frame and role labelsfrom the English Proposition Bank for sentencesin German, English, Chinese and Spanish.Similar to how Stanford dependencies are onebasis of universal dependencies (De Marneffe etal., 2014; Nivre, 2015), we believe that EnglishPropBank labels have the potential to eventu-ally become a basis of ?universal?
shallow se-mantic labels.
Such a unified representation ofshallow semantics, we argue, may facilitate ap-plications such as multilingual information ex-traction and question answering, much in thesame way that universal dependencies facilitatetasks such as crosslingual learning and the devel-opment and evaluation of multilingual syntacticparsers (Nivre, 2015).
The key questions, how-ever, are (1) to what degree English PropBankframe and role labels are appropriate for differenttarget languages; and (2) how far this approach canhandle language-specific phenomena or semanticconcepts.Contributions.
To facilitate the discussions ofthe above questions, we present POLYGLOT, anSRL system trained on auto-generated PropBanksfor 8 languages plus English, namely Arabic, Chi-nese, French, German, Hindi, Japanese, Russianand Spanish.
Given a sentence in one of these9 languages, the system applies the correspond-ing SRL and visualizes the shallow semantic parsewith predicted English PropBank labels.
POLY-GLOT allows us to illustrate our envisioned ap-proach of parsing different languages into a sharedshallow semantic abstraction based on the EnglishProposition Bank.
It also enables researchers toexperiment with the tool to understand the breadthof shallow semantic concepts currently covered,and to discuss limitations and the potential of suchan approach for downstream applications.2 System OverviewFigure 3 depicts the overall architecture of POLY-GLOT.
First, we automatically generate labeledtraining data for each target language with anno-tation projection (Akbik et al, 2015) (Figure 3Step 1).
We use the labeled data to train for eachlanguage an SRL system (Figure 3 Step 2) thatpredicts English PropBank frame and role labels.Both the creation of the training data and the train-ing of the SRL instances are one-time processes.POLYGLOT provides a Web-based GUI to al-low users to interact with the SRL systems (Fig-ure 3 Step 3).
Given a natural language sentence,depending on the language of the input sentence,POLYGLOT selects the appropriate SRL instanceand displays on the GUI the semantic parse, aswell as syntactic information.Figure 3: System overview2Yesterday,  Diego  bought  his girlfriend  some flowers A1A0 buy.01A0 buy.01Ayer,  Diego  compr?
flores  para su noviaA4AM-TMPAM-TMP A4A1Figure 4: Annotation projection for a word-aligned English-Spanish sentence pair.In the next sections, we briefly describe the cre-ation of the labeled data and the training of theSRL systems, followed by a tour of the Web UI.3 Auto-Generation of Labeled DataWe followed an annotation projection approachto automatically generate the labeled data for dif-ferent languages.
This approach takes as input aword-aligned parallel corpus of English sentencesand their translations in a target language (TL).
Asemantic role labeler then predicts labels for theEnglish sentences.
In a projection step, these la-bels are transferred along word alignments ontothe target language sentences.
The underlying the-ory is that translated sentence pairs share a de-gree of semantic similarity, making such projec-tion possible (Pad?o and Lapata, 2009).Figure 4 illustrates an example of annotationprojection: Using an SRL system trained with theEnglish Proposition Bank, the English sentence islabeled with the appropriate frame (BUY.01) androle labels: ?Diego?
as the buyer (A0 in PropBankannotation), ?some flowers?
as the thing bought(A1) and ?his girlfriend?
as the benefactive (A4).In addition, ?yesterday?
is labeled AM-TMP, sig-nifying a temporal context of this frame.
Theselabels are then projected onto the aligned Spanishwords.
For instance, ?compr?o?
is word-aligned to?bought?
and thus labeled as BUY.01.
The pro-jection produces a Spanish sentence labeled withEnglish PropBank labels; such data can in turn beused to train an SRL system for Spanish.State-of-the-art.
Direct annotation projection of-ten introduces errors, mostly due to non-literaltranslations (Akbik et al, 2015).
Previous workdefined lexical and syntactic constraints to in-crease projection quality, such as filters to al-low only verbs to be labeled as frames (Van derPlas et al, 2011), heuristics that ensure that onlyheads of syntactic constituents are labeled as ar-guments (Pad?o and Lapata, 2009) and the use ofverb translation dictionaries to guide frame map-pings.
In (Akbik et al, 2015), we additionallyproposed a process of filtered projection and boot-strapped learning, and successfully created Propo-sition Banks for 7 target languages.
We found thequality of the generated PropBanks to be moderateto high, depending on the target language.
Table 1shows estimated precision, recall and F1-score foreach language with two evaluation methods.
Par-tial evaluation counts correctly labeled incompleteconstituents as true positives while exact evalua-tion only counts correctly labeled complete con-stituents as true positives.
For more details we re-fer the reader to (Akbik et al, 2015) .4 Semantic Role LabelingUsing the auto-generated labeled data, wetrain the semantic role labeler of the MATEtoolkit (Bj?orkelund et al, 2009), which achievedstate-of-the-art semantic F1-score in the multilin-gual semantic role labeling task of the CoNLL-2009 shared task (Haji?c et al, 2009).
The parser isimplemented as a sequence of local logistic regres-sion classifiers for the four steps of predicate iden-tification, predicate classification, argument iden-tification and argument classification.
In addition,it implements a global reranker to rerank sets oflocal predictions.
It uses a standard feature set oflexical and syntactic features.Preprocessing.
Before SRL, we execute apipeline of NLP tools to extract the required lex-ical, morphological and syntactic features.
To fa-cilitate reproducability of the presented work, weuse publicly available open source tools and pre-PREDICATE ARGUMENTLANG.
Match P R F1 P R F1 Agr ?Arabicpart.
0.97 0.89 0.93 0.86 0.69 0.77 0.92 0.87exact 0.97 0.89 0.93 0.67 0.63 0.65 0.85 0.77Chinesepart.
0.97 0.88 0.92 0.93 0.83 0.88 0.95 0.91exact 0.97 0.88 0.92 0.83 0.81 0.82 0.92 0.86Frenchpart.
0.95 0.92 0.94 0.92 0.76 0.83 0.97 0.95exact 0.95 0.92 0.94 0.86 0.74 0.8 0.95 0.91Germanpart.
0.96 0.92 0.94 0.95 0.73 0.83 0.95 0.91exact 0.96 0.92 0.94 0.91 0.73 0.81 0.92 0.86Hindipart.
0.91 0.68 0.78 0.93 0.66 0.77 0.94 0.88exact 0.91 0.68 0.78 0.58 0.54 0.56 0.81 0.69Russianpart.
0.96 0.94 0.95 0.91 0.68 0.78 0.97 0.94exact 0.96 0.94 0.95 0.79 0.65 0.72 0.93 0.89Spanishpart.
0.96 0.93 0.95 0.85 0.74 0.79 0.91 0.85exact 0.96 0.93 0.95 0.75 0.72 0.74 0.85 0.77Table 1: Estimated precision and recall over seven languagesfrom our previous evaluation (Akbik et al, 2015).3LANGUAGE NLP PREPROCESSING PARALLEL DATA SETS #SENTENCESArabic STANFORDCORENLP, KHOJASTEMMER, STANFORDPARSER UN, OpenSubtitles 24,5MChinese STANFORDCORENLP, MATEPARSER UN, OpenSubtitles 12,2MEnglish CLEARNLP n/a n/aFrench STANFORDCORENLP, MATETRANSITIONPARSER UN, OpenSubtitles 36MGerman STANFORDCORENLP, MATETRANSITIONPARSER Europarl, OpenSubtitles 14,1MHindi TNTTAGGER, MALTPARSER Hindencorp 54KJapanese JJST Tatoeba, OpenSubtitles 1,7MRussian TREETAGGER, MALTPARSER UN, OpenSubtitles 22,7MSpanish STANFORDCORENLP, MATEPARSER UN, OpenSubtitles 52,4MTable 2: NLP tools and source of parallel data used for each language.
Since English is the source language for annotationprojection, no parallel data was required to train SRL.NLP tools: STANFORDCORENLP: (Manning et al, 2014) , TNTTAGGER: (Brants, 2000), TREETAGGER: (Schmid, 1994), KHOJASTEMMER: (Khoja and Garside,1999), STANFORDPARSER: (Green and Manning, 2010), STANFORDCORENLP: (Choi and McCallum, 2013), MATEPARSER: (Bohnet, 2010), JJST: proprietarysystem, MATETRANSITIONPARSER: (Bohnet and Nivre, 2012), MALTPARSER: (Nivre et al, 2006).trained models where available.
A breakdown ofthe preprocessing tools used for each language isgiven in Table 2.Data sets.
In order to generate trainingdata for POLYGLOT, we used the followingsources of parallel data: The UN corpus ofofficial United Nations documents (Rafalovitchet al, 2009), the Europarl corpus of Euro-pean parliament proceedings (Koehn, 2005), theOpenSubtitles corpus of movie subtitles (Lisonand Tiedemann, 2016), the Hindencorp corpusautomatically gathered from web sources (Bojaret al, 2014) and the Tatoeba corpus of languagelearning examples1.
The data sets were obtainedfrom the OPUS project (Tiedemann, 2012) andword aligned using the Berkeley Aligner2.
Table 2lists the data sets used for each language and thecombined number of available parallel sentences.5 POLYGLOT User InterfaceThe Web-based GUI of POLYGLOT allows users toenter sentences in one of 9 languages and requesta shallow semantic analysis.
Figure 5 presents ascreenshot of the GUI.
Users begin by entering asentence in the text field and clicking on the ?parsesentence?
button.
As indicated in Figure 3, it isthen passed to a language-specific NLP pipelinebased on the associated language that is detectedautomatically by default or specified by the user.The pipeline tokenizes and lemmatizes the sen-tence, performs morphological analysis, depen-dency parsing and semantic role labeling.Output.
The syntactic and semantic parsing re-sults are displayed below the input field, follow-ing the design of (Bj?orkelund et al, 2010): Thetopmost result table is the semantic analysis, pre-1http://tatoeba.org/eng/2https://code.google.com/archive/p/berkeleyaligner/sented as a grid in which each row correspondsto one identified semantic frame.
The grid high-lights sentence constituents labeled with roles andincludes role descriptions for better interpretabil-ity of the parsing results.Below the results of the semantic analysis theGUI shows two more detailed views of the pars-ing results.
The first visualizes the dependencyparse tree generated using WHATSWRONGWITH-MYNLP3, while the second (omitted in Fig-ure 5 in the interest of space) displays the fullsyntactic-semantic parse in CoNLL format, in-cluding morphological information and other fea-tures not present in the dependency tree visualiza-tion.
These two views may be helpful to users thatwish to identify possible sources of SRL errors.For instance, a common error class stem from er-rors in dependency parsing, causing incorrect con-stituents to be labeled as arguments.Example sentence.
Figure 5 illustrates the re-sult visualization of the tool.
A user enters a sen-tence ?Hier, je voulais acheter une baguette, maisje n?avais pas assez d?argent?
(engl.
?Yesterday Iwanted to buy a baguette but I didn?t have enoughmoney?)
into the text field.
As indicated in thetop left corner, this sentence is auto-detected to beFrench.The results of semantic analysis is displayed be-low the input field.
The first column in the gridindicates that three frames have been identified:WANT.01, BUY.01 and HAVE.03.
The second rowin the grid corresponds to the WANT.01 frame,which identifies ?je?
(engl.
?I?)
as the wanter and?acheter une baguette?
(engl.
?buy a baguette?)
asthe thing wanted.
The arguments are color-codedby PropBank argument type for better readability.For instance, in the PropBank annotation scheme,3https://code.google.com/archive/p/whatswrong/4Figure 5: POLYGLOT?s Web UI with a French example sentence.the agents of the three frames in the example (thewanter, the buyer and the owner) are all annotatedwith the same role (A0).
They are thus highlightedin the same yellow color in the visualization.
Thisallows a user to quickly gauge whether the seman-tic analysis of the sentence is correct4.6 Demonstration and OutlookWe present POLYGLOT as a hands-on demo whereusers can enter sentences and request shallow se-mantic analyses.
We also plan to make it publiclyaccessible in the future.
We are currently workingon improving the annotation projection approachto generate higher quality data by experimentingwith further constraints, language-specific heuris-tics and improved frame mappings.
We are par-ticularly interested in how far English Proposi-tion Bank labels are suitable for arbitrary targetlanguages and may serve as basis of a ?universalsemantic role labeling?
framework: we are qual-itatively analysing auto-generated PropBanks incomparison to manual efforts; meanwhile, we areevaluating POLYGLOT in downstream applicationssuch as multilingual IE.
Through the presentationof POLYGLOT, we hope to engage the researchcommunity in this discussion.4The example sentence in Figure 5 contains one error:The word ?hier?
(engl.
?yesterday?)
should be labeled AM-TMP instead of AM-DIS.
All other labels are correct.ReferencesAlan Akbik, Laura Chiticariu, Marina Danilevsky,Yunyao Li, Shivakumar Vaithyanathan, and HuaiyuZhu.
2015.
Generating high quality propositionbanks for multilingual semantic role labeling.
InACL 2015, 53rd Annual Meeting of the Associationfor Computational Linguistics Beijing, China, pageto appear.Rajesh Bhatt, Bhuvana Narasimhan, Martha Palmer,Owen Rambow, Dipti Misra Sharma, and Fei Xia.2009.
A multi-representational and multi-layeredtreebank for hindi/urdu.
In Proceedings of the ThirdLinguistic Annotation Workshop, pages 186?189.Association for Computational Linguistics.Anders Bj?orkelund, Love Hafdell, and Pierre Nugues.2009.
Multilingual semantic role labeling.
In Pro-ceedings of the Thirteenth CoNLL: Shared Task,pages 43?48, Boulder, Colorado, June.
Associationfor Computational Linguistics.Anders Bj?orkelund, Bernd Bohnet, Love Hafdell, andPierre Nugues.
2010.
A high-performance syntac-tic and semantic dependency parser.
In Proceedingsof the 23rd International Conference on Computa-tional Linguistics: Demonstrations, pages 33?36.Association for Computational Linguistics.Bernd Bohnet and Joakim Nivre.
2012.
A transition-based system for joint part-of-speech tagging and la-beled non-projective dependency parsing.
In Pro-ceedings of the 2012 EMNLP-CoNLL, pages 1455?1465.
Association for Computational Linguistics.Bernd Bohnet.
2010.
Very high accuracy and fast de-pendency parsing is not a contradiction.
In Proceed-ings of the 23rd COLING, pages 89?97.
Associationfor Computational Linguistics.5Ond?rej Bojar, Vojt?ech Diatka, Pavel Rychl`y, PavelStra?n?ak, V?
?t Suchomel, Ale?s Tamchyna, Daniel Ze-man, et al 2014.
Hindencorp?hindi-english andhindi-only corpus for machine translation.
In Pro-ceedings of the Ninth LREC.Thorsten Brants.
2000.
Tnt: a statistical part-of-speech tagger.
In Proceedings of the sixth confer-ence on Applied natural language processing, pages224?231.
Association for Computational Linguis-tics.Jinho D. Choi and Andrew McCallum.
2013.Transition-based dependency parsing with selec-tional branching.
In Proceedings of the 51st AnnualMeeting of the Association for Computational Lin-guistics.Marie-Catherine De Marneffe, Timothy Dozat, Na-talia Silveira, Katri Haverinen, Filip Ginter, JoakimNivre, and Christopher D Manning.
2014.
Univer-sal stanford dependencies: A cross-linguistic typol-ogy.
In LREC, volume 14, pages 4585?4592.Anthony Fader, Stephen Soderland, and Oren Etzioni.2011.
Identifying relations for open information ex-traction.
In Proceedings of the Conference on Em-pirical Methods in Natural Language Processing,pages 1535?1545.
Association for ComputationalLinguistics.Spence Green and Christopher D Manning.
2010.
Bet-ter arabic parsing: Baselines, evaluations, and anal-ysis.
In Proceedings of the 23rd COLING, pages394?402.
Association for Computational Linguis-tics.Jan Haji?c, Massimiliano Ciaramita, Richard Johans-son, Daisuke Kawahara, Maria Ant`onia Mart?
?, Llu?
?sM`arquez, Adam Meyers, Joakim Nivre, SebastianPad?o, Jan?St?ep?anek, et al 2009.
The conll-2009shared task: Syntactic and semantic dependenciesin multiple languages.
In Proceedings of the Thir-teenth CoNLL: Shared Task, pages 1?18.
Associa-tion for Computational Linguistics.Shereen Khoja and Roger Garside.
1999.
Stemmingarabic text.
Lancaster, UK, Computing Department,Lancaster University.Philipp Koehn.
2005.
Europarl: A parallel corpus forstatistical machine translation.
In MT summit, vol-ume 5, pages 79?86.Pierre Lison and J?org Tiedemann.
2016.
Opensub-titles2016: Extracting large parallel corpora frommovie and tv subtitles.Christopher D. Manning, Mihai Surdeanu, John Bauer,Jenny Finkel, Steven J. Bethard, and David Mc-Closky.
2014.
The Stanford CoreNLP natural lan-guage processing toolkit.
In Association for Compu-tational Linguistics (ACL) System Demonstrations,pages 55?60.Umar Maqsud, Sebastian Arnold, Michael H?ulfenhaus,and Alan Akbik.
2014.
Nerdle: Topic-specific ques-tion answering using wikia seeds.
In COLING (De-mos), pages 81?85.Joakim Nivre, Johan Hall, and Jens Nilsson.
2006.Maltparser: A data-driven parser-generator for de-pendency parsing.
In Proceedings of LREC, vol-ume 6, pages 2216?2219.Joakim Nivre.
2015.
Towards a universal grammarfor natural language processing.
In ComputationalLinguistics and Intelligent Text Processing, pages 3?16.
Springer.Sebastian Pad?o and Mirella Lapata.
2009.
Cross-lingual annotation projection for semantic roles.Journal of Artificial Intelligence Research,36(1):307?340.Martha Palmer, Daniel Gildea, and Paul Kingsbury.2005.
The proposition bank: An annotated cor-pus of semantic roles.
Computational linguistics,31(1):71?106.Alexandre Rafalovitch, Robert Dale, et al 2009.United nations general assembly resolutions: A six-language parallel corpus.
In Proceedings of the MTSummit, volume 12, pages 292?299.Helmut Schmid.
1994.
Probabilistic part-of-speechtagging using decision trees.
In Proceedings of theinternational conference on new methods in lan-guage processing, volume 12, pages 44?49.
Cite-seer.Dan Shen and Mirella Lapata.
2007.
Using semanticroles to improve question answering.
In EMNLP-CoNLL, pages 12?21.J?org Tiedemann.
2012.
Parallel data, tools and inter-faces in opus.
In Proceedings of LREC, MAY 21-27,2012, Istanbul, Turkey, pages 2214?2218.Lonneke Van der Plas, Paola Merlo, and James Hen-derson.
2011.
Scaling up automatic cross-lingualsemantic role annotation.
In Proceedings of the 49thAnnual Meeting of the Association for Computa-tional Linguistics: Human Language Technologies:short papers-Volume 2, pages 299?304.
Associationfor Computational Linguistics.Nianwen Xue and Martha Palmer.
2005.
Automaticsemantic role labeling for chinese verbs.
In IJCAI,volume 5, pages 1160?1165.
Citeseer.6
