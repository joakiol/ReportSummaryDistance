Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 26?34,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsEmotions Evoked by Common Words and Phrases:Using Mechanical Turk to Create an Emotion LexiconSaif M. Mohammad and Peter D. TurneyInstitute for Information Technology,National Research Council Canada.Ottawa, Ontario, Canada, K1A 0R6{saif.mohammad,peter.turney}@nrc-cnrc.gc.caAbstractEven though considerable attention has beengiven to semantic orientation of words and thecreation of large polarity lexicons, researchin emotion analysis has had to rely on lim-ited and small emotion lexicons.
In this pa-per, we show how we create a high-quality,moderate-sized emotion lexicon using Me-chanical Turk.
In addition to questions aboutemotions evoked by terms, we show how theinclusion of a word choice question can dis-courage malicious data entry, help identify in-stances where the annotator may not be famil-iar with the target term (allowing us to rejectsuch annotations), and help obtain annotationsat sense level (rather than at word level).
Weperform an extensive analysis of the annota-tions to better understand the distribution ofemotions evoked by terms of different parts ofspeech.
We identify which emotions tend to beevoked simultaneously by the same term andshow that certain emotions indeed go hand inhand.1 IntroductionWhen analyzing text, automatically detecting emo-tions such as joy, sadness, fear, anger, and surprise isuseful for a number of purposes, including identify-ing blogs that express specific emotions towards thetopic of interest, identifying what emotion a news-paper headline is trying to evoke, and devising auto-matic dialogue systems that respond appropriately todifferent emotional states of the user.
Often differentemotions are expressed through different words.
Forexample, delightful and yummy indicate the emo-tion of joy, gloomy and cry are indicative of sadness,shout and boiling are indicative of anger, and so on.Therefore an emotion lexicon?a list of emotionsand words that are indicative of each emotion?islikely to be useful in identifying emotions in text.Words may evoke different emotions in differentcontexts, and the emotion evoked by a phrase or asentence is not simply the sum of emotions conveyedby the words in it, but the emotion lexicon will be auseful component for any sophisticated emotion de-tecting algorithm.
The lexicon will also be useful forevaluating automatic methods that identify the emo-tions evoked by a word.
Such algorithms may thenbe used to automatically generate emotion lexiconsin languages where no such lexicons exist.
As ofnow, high-quality high-coverage emotion lexiconsdo not exist for any language, although there are afew limited-coverage lexicons for a handful of lan-guages, for example, the WordNet Affect Lexicon(WAL) (Strapparava and Valitutti, 2004) for six ba-sic emotions and the General Inquirer (GI) (Stone etal., 1966), which categorizes words into a number ofcategories, including positive and negative semanticorientation.Amazon has an online service called Mechani-cal Turk that can be used to obtain a large amountof human annotation in an efficient and inexpensivemanner (Snow et al, 2008; Callison-Burch, 2009).1However, one must define the task carefully to ob-tain annotations of high quality.
Several checks mustbe placed to ensure that random and erroneous anno-tations are discouraged, rejected, and re-annotated.In this paper, we show how we compiled amoderate-sized English emotion lexicon by manual1https://www.mturk.com/mturk/welcome26annotation through Amazon?s Mechanical Turk ser-vice.
This dataset, which we will call EmoLex, ismany times as large as the only other known emo-tion lexicon, WordNet Affect Lexicon.
More impor-tantly, the terms in this lexicon are carefully chosento include some of the most frequent nouns, verbs,adjectives, and adverbs.
Beyond unigrams, it hasa large number of commonly used bigrams.
Wealso include some words from the General Inquirerand some from WordNet Affect Lexicon, to allowcomparison of annotations between the various re-sources.We perform an extensive analysis of the annota-tions to answer several questions that have not beenproperly addressed so far.
For instance, how hard isit for humans to annotate words with the emotionsthey evoke?
What percentage of commonly usedterms, in each part of speech, evoke an emotion?
Areemotions more commonly evoked by nouns, verbs,adjectives, or adverbs?
Is there a correlation be-tween the semantic orientation of a word and theemotion it evokes?
Which emotions tend to go to-gether; that is, which emotions are evoked simulta-neously by the same term?
This work is intendedto be a pilot study before we create a much largeremotion lexicon with tens of thousands of terms.We focus on the emotions of joy, sadness, anger,fear, trust, disgust, surprise, and anticipation?argued by many to be the basic and prototypicalemotions (Plutchik, 1980).
Complex emotions canbe viewed as combinations of these basic emotions.2 Related workWordNet Affect Lexicon (Strapparava and Valitutti,2004) has a few hundred words annotated with theemotions they evoke.2 It was created by manuallyidentifying the emotions of a few seed words andthen marking all their WordNet synonyms as havingthe same emotion.
The General Inquirer (Stone etal., 1966) has 11,788 words labeled with 182 cat-egories of word tags, including positive and nega-tive semantic orientation.3 It also has certain otheraffect categories, such as pleasure, arousal, feeling,and pain but these have not been exploited to a sig-nificant degree by the natural language processing2http://wndomains.fbk.eu/wnaffect.html3http://www.wjh.harvard.edu/?inquirercommunity.Work in emotion detection can be roughly classi-fied into that which looks for specific emotion denot-ing words (Elliott, 1992), that which determines ten-dency of terms to co-occur with seed words whoseemotions are known (Read, 2004), that which useshand-coded rules (Neviarouskaya et al, 2009), andthat which uses machine learning and a number ofemotion features, including emotion denoting words(Alm et al, 2005).Much of this recent work focuses on six emo-tions studied by Ekman (1992).
These emotions?joy, sadness, anger, fear, disgust, and surprise?
area subset of the eight proposed in Plutchik (1980).We focus on the Plutchik emotions because the emo-tions can be naturally paired into opposites?joy?sadness, anger?fear, trust?disgust, and anticipation?surprise.
Natural symmetry apart, we believe thatprior work on automatically computing word?pairantonymy (Lin et al, 2003; Mohammad et al, 2008;Lobanova et al, 2010) can now be leveraged in au-tomatic emotion detection.3 Emotion annotationIn the subsections below we present the challengesin obtaining high-quality emotion annotation, howwe address those challenges, how we select the tar-get terms, and the questionnaire we created for theannotators.3.1 Key challengesWords used in different senses can evoke differentemotions.
For example, the word shout evokes adifferent emotion when used in the context of ad-monishment, than when used in ?Give me a shout ifyou need any help.?
Getting human annotations onword senses is made complicated by decisions aboutwhich sense-inventory to use and what level of gran-ularity the senses must have.
On the one hand, wedo not want to choose a fine-grained sense-inventorybecause then the number of word?sense combina-tions will become too large and difficult to easilydistinguish, and on the other hand we do not wantto work only at the word level because when usedin different senses a word may evoke different emo-tions.Yet another challenge is how best to convey a27word sense to the annotator.
Long definitions willtake time to read and limit the number of annotationswe can obtain for the same amount of resources.Further, we do not want to bias the annotator to-wards an emotion through the definition.
We wantthe users to annotate a word only if they are alreadyfamiliar with it and know its meanings.
And lastly,we must ensure that malicious and erroneous anno-tations are rejected.3.2 Our solutionIn order to overcome the challenges describedabove, before asking the annotators questions aboutwhat emotions are evoked by a target term, we firstpresent them with a word choice problem pertainingto the target.
They are provided with four differentwords and asked which word is closest in meaningto the target.
This single question serves many pur-poses.
Through this question we convey the wordsense for which annotations are to be provided, with-out actually providing annotators with long defini-tions.
If an annotator is not familiar with the targetword and still attempts to answer questions pertain-ing to the target, or is randomly clicking options inour questionnaire, then there is a 75% chance thatthey will get the answer to this question wrong, andwe can discard all responses pertaining to this targetterm by the annotator (that is, we discard answers tothe emotion questions provided by the annotator forthis target term).We generated these word choice problems auto-matically using the Macquarie Thesaurus (Bernard,1986).
Published thesauri, such as Roget?s and Mac-quarie, divide the vocabulary into about a thou-sand categories, which may be interpreted as coarsesenses.
If a word has more than one sense, then itcan be found in more than one thesaurus category.Each category also has a head word which best cap-tures the meaning of the category.Most of the target terms chosen for annotation arerestricted to those that are listed in exactly one the-saurus category.
The word choice question for atarget term is automatically generated by selectingthe following four alternatives (choices): the headword of the thesaurus category pertaining to the tar-get term (the correct answer); and three other headwords of randomly selected categories (the distrac-tors).
The four alternatives are presented to the an-notator in random order.Only a small number of the words in the WordNetAffect Lexicon are listed in exactly one thesauruscategory (have one sense), and so we included tar-get terms that occurred in two thesaurus categoriesas well.
For these questions, we listed head wordsfrom both the senses (categories) as two of the alter-natives (probability of a random choice being cor-rect is 50%).
Depending on the alternative chosen,we can thus determine the sense for which the sub-sequent emotion responses are provided by the an-notator.3.3 Target termsIn order to generate an emotion lexicon, we firstidentify a list of words and phrases for which wewant human annotations.
We chose the MacquarieThesaurus as our source pool for unigrams and bi-grams.
Any other published dictionary would haveworked well too.
However, apart from over 57,000commonly used English word types, the MacquarieThesaurus also has entries for more than 40,000commonly used phrases.
From this list of unigramsand bigrams we chose those that occur frequently inthe Google n-gram corpus (Brants and Franz, 2006).Specifically we chose the 200 most frequent n-gramsin the following categories: noun unigrams, nounbigrams, verb unigrams, verb bigrams, adverb un-igrams, adverb bigrams, adjective unigrams, adjec-tive bigrams, words in the General Inquirer that aremarked as having a negative semantic orientation,words in General Inquirer that are marked as hav-ing a positive semantic orientation.
When selectingthese sets, we ignored terms that occurred in morethan one Macquarie Thesaurus category.
Lastly, wechose all words from each of the six emotion cat-egories in the WordNet Affect Lexicon that had atmost two senses in the thesaurus (occurred in atmost two thesaurus categories).
The first and sec-ond column of Table 1 list the various sets of tar-get terms as well as the number of terms in each setfor which annotations were requested.
EmoLexUnistands for all the unigrams taken from the thesaurus.EmoLexBi refers to all the bigrams.
EmoLexGIare all the words taken from the General Inquirer.EmoLexWAL are all the words taken from the Word-Net Affect Lexicon.283.4 Mechanical Turk HITsAn entity submitting a task to Mechanical Turk iscalled the requester.
A requester first breaks thetask into small independently solvable units calledHITs (Human Intelligence Tasks) and uploadsthem on the Mechanical Turk website.
The requesterspecifies the compensation that will be paid for solv-ing each HIT.
The people who provide responses tothese HITs are called Turkers.
The requester alsospecifies the number of different Turkers that areto annotate each HIT.
The annotation provided bya Turker for a HIT is called an assignment.We created Mechanical Turk HITs for each of theterms specified in Table 1.
Each HIT has a set ofquestions, all of which are to be answered by thesame person.
We requested five different assign-ments for each HIT (each HIT is to be annotatedby five different Turkers).
Different HITS may beattempted by different Turkers, and a Turker mayattempt as many HITs as they wish.
Below is anexample HIT for the target word ?startle?.Title: Emotions evoked by wordsReward per HIT: $0.04Directions: Return HIT if you are not familiarwith the prompt word.Prompt word: startle1.
Which word is closest in meaning (mostrelated) to startle??
automobile?
shake?
honesty?
entertain2.
How positive (good, praising) is the wordstartle??
startle is not positive?
startle is weakly positive?
startle is moderately positive?
startle is strongly positive3.
How negative (bad, criticizing) is the wordstartle??
startle is not negative?
startle is weakly negative?
startle is moderately negative?
startle is strongly negative4.
How much does the word startle evoke orproduce the emotion joy (for example, happyand fun may strongly evoke joy)?# of terms Annotns.EmoLex Initial Master per wordEmoLexUni:adjectives 200 196 4.7adverbs 200 192 4.7nouns 200 187 4.6verbs 200 197 4.7EmoLexBi:adjectives 200 182 4.7adverbs 187 171 4.7nouns 200 193 4.7verbs 200 186 4.7EmoLexGI:negatives in GI 200 196 4.7positives in GI 200 194 4.8EmoLexWAL:anger terms in WAL 107 84 4.8disgust terms in WAL 25 25 4.8fear terms in WAL 58 58 4.8joy terms in WAL 109 92 4.8sadness terms in WAL 86 73 4.7surprise terms in WAL 39 38 4.7Union 2176 2081 4.75Table 1: Break down of target terms into various cate-gories.
Initial refers to terms chosen for annotation.
Mas-ter refers to terms for which three or more valid assign-ments were obtained using Mechanical Turk.?
startle does not evoke joy?
startle weakly evokes joy?
startle moderately evokes joy?
startle strongly evokes joy[Questions 5 to 11 are similar to 4, except thatjoy is replaced with one of the other sevenemotions: sadness (failure and heart-break);fear (horror and scary); anger (rage and shout-ing); trust (faith and integrity); disgust (grossand cruelty); surprise (startle and sudden); an-ticipation (expect and eager).
]Before going live, the survey was approved by theethics committee at the National Research CouncilCanada.4 Annotation analysisThe first set of emotion annotations on MechanicalTurk were completed in about nine days.
The Turk-ers spent a minute on average to answer the ques-tions in a HIT.
This resulted in an hourly pay ofslightly more than $2.29Once the assignments were collected, we used au-tomatic scripts to validate the annotations.
Some as-signments were discarded because they failed cer-tain tests (described below).
A subset of the dis-carded assignments were officially rejected (theTurkers were not paid for these assignments) be-cause instructions were not followed.
About 500 ofthe 10,880 assignments (2,176 ?
5) included at leastone unanswered question.
These assignments werediscarded and rejected.
More than 85% of the re-maining assignments had the correct answer for theword choice question.
This was a welcome resultshowing that, largely, the annotations were done ina responsible manner.
We discarded all assignmentsthat had the wrong answer for the word choice ques-tion.
If an annotator obtained an overall score thatis less than 66.67% on the word choice questions(that is, got more than one out of three wrong), thenwe assumed that, contrary to instructions, HITs forwords not familiar to the annotator were attempted.We discarded and rejected all assignments by suchannotators (not just the assignments for which theygot the word choice question wrong).HITs pertaining to all the discarded assignmentswere uploaded for a second time on MechanicalTurk and the validation process was repeated.
Af-ter the second round, we had three or more valid as-signments for 2081 of the 2176 target terms.
We willrefer to this set of assignments as the master set.
Wecreate the emotion lexicon from this master set con-taining 9892 assignments from about 1000 Turkerswho attempted 1 to 450 assignments each.
About100 of them provided 20 or more assignments each(more than 7000 assignments in all).
The master sethas, on average, about 4.75 assignments for each ofthe 2081 target terms.
(See Table 1 for more details.
)4.1 Emotions evoked by wordsThe different emotion annotations for a target termwere consolidated by determining the majorityclass of emotion intensities.
For a given term?emotion pair, the majority class is that intensity levelthat is chosen most often by the Turkers to representthe degree of emotion evoked by the word.
Ties arebroken by choosing the stronger intensity level.
Ta-ble 2 lists the percent of 2081 target terms assigneda majority class of no, weak, moderate, and strongemotion.
For example, it tells us that 7.6% of the tar-IntensityEmotion no weak moderate stronganger 78.8 9.4 6.2 5.4anticipation 71.4 13.6 9.4 5.3disgust 82.6 8.8 4.9 3.5fear 76.5 11.3 7.3 4.7joy 72.6 9.6 10.0 7.6sadness 76.0 12.4 5.8 5.6surprise 84.8 7.9 4.1 3.0trust 73.3 12.0 9.8 4.7micro average 77.0 10.6 7.2 5.0any emotion 17.9 23.4 28.3 30.1Table 2: Percent of 2081 terms assigned a majority classof no, weak, moderate, and strong emotion.Emotion % of termsanger 15.4anticipation 20.9disgust 11.0fear 14.5joy 21.9sadness 14.4surprise 9.8trust 20.6micro average 16.1any emotion 67.9Table 3: Percent of 2081 target terms that are evocative.get terms strongly evoke joy.
The table also presentsan average of the numbers in each column (micro av-erage).
Observe that the percentages for individualemotions do not vary greatly from the average.
Thelast row lists the percent of target terms that evokesome emotion (any of the eight) at the various in-tensity levels.
We calculated this using the intensitylevel of the strongest emotion expressed by each tar-get.
Observe that 30.1% of the target terms stronglyevoke at least one of the eight basic emotions.Even though we asked Turkers to annotate emo-tions at four levels of intensity, practical NLP appli-cations often require only two levels?evoking par-ticular emotion (evocative) or not (non-evocative).For each target term?emotion pair, we convert thefour-level annotations into two-level annotations byplacing all no- and weak-intensity assignments inthe non-evocative bin, all moderate- and strong-intensity assignments in the evocative bin, and thenchoosing the bin with the majority assignments.
Ta-ble 3 gives percent of target terms considered to be30EmoLex anger anticipation disgust fear joy sadness surprise trust anyEmoLexUni:adjectives 12 21 8 11 30 13 10 19 72adverbs 12 16 7 8 21 6 11 25 65nouns 4 21 2 9 16 3 3 21 47verbs 12 21 7 11 15 12 11 17 56EmoLexBi:adjectives 12 24 8 10 26 14 7 18 64adverbs 3 26 1 5 15 4 8 25 54nouns 9 30 6 12 15 6 2 24 56verbs 8 34 2 5 29 6 9 28 67EmoLexGI:negatives in GI 45 5 34 35 1 37 11 2 78positives in GI 0 23 0 0 48 0 6 47 77EmoLexWAL:anger terms in WAL 90 2 54 41 0 32 2 0 91disgust terms in WAL 40 4 92 36 0 20 8 0 96fear terms in WAL 25 17 31 79 0 36 34 0 87joy terms in WAL 3 32 3 1 89 1 18 38 95sadness terms in WAL 17 0 9 15 0 93 1 1 94surprise terms in WAL 7 23 0 21 52 10 76 7 86Table 4: Percent of terms, in each target set, that are evocative.
Highest individual emotion scores for EmoLexWAL areshown bold.
Observe that WAL fear terms are marked most as fear evocative, joy terms as joy evocative, and so on.evocative.
The last row in the table gives the per-centage of terms evocative of some emotion (any ofthe eight).
Table 4 shows how many terms in eachcategory are evocative of the different emotions.4.1.1 Analysis and discussionTable 4 shows that a sizable percent of nouns, verbs,adjectives, and adverbs are evocative.
Adverbs andadjectives are some of the most emotion inspiringterms and this is not surprising considering that theyare used to qualify a noun or a verb.
Anticipation,trust, and joy come through as the most commonemotions evoked by terms of all four parts of speech.The EmoLexWAL rows are particularly interest-ing because they serve to determine how muchthe Turker annotations match annotations in theWordnet Affect Lexicon (WAL).
The most commonTurker-determined emotion for each of these rows ismarked in bold.
Observe that WAL anger terms aremostly marked as anger evocative, joy terms as joyevocative, and so on.
The EmoLexWAL rows alsoindicate which emotions get confused for which, orwhich emotions tend to be evoked simultaneouslyby a term.
Observe that anger terms tend also to beevocative of disgust.
Similarly, fear and sadness gotogether, as do joy, trust, and anticipation.The EmoLexGI rows rightly show that wordsmarked as negative in the General Inquirer, mostlyevoke negative emotions (anger, fear, disgust, andsadness).
Observe that the percentages for trust andjoy are much lower.
On the other hand, positivewords evoke anticipation, joy, and trust.4.1.2 AgreementIn order to analyze how often the annotators agreedwith each other, for each term?emotion pair, we cal-culated the percentage of times the majority classhas size 5 (all Turkers agree), size 4 (all but oneagree), size 3, and size 2.
Observe that for more than50% of the terms, at least four annotators agree witheach other.
Table 5 presents these agreement values.Since many NLP systems may rely only on two in-tensity values (evocative or non-evocative), we alsocalculate agreement at that level (Table 6).
Observethat for more than 50% of the terms, all five annota-tors agree with each other, and for more than 80%of the terms, at least four annotators agree.
Thisshows a high degree of agreement on emotion anno-tations despite no real control over the educationalbackground and qualifications of the annotators.31Majority class sizeEmotion two three four fiveanger 13.1 25.6 27.4 33.7anticipation 31.6 35.2 20.7 12.3disgust 14.0 21.6 29.0 35.1fear 15.0 29.9 28.6 26.2joy 17.6 26.4 23.0 32.7sadness 14.2 24.6 28.1 32.8surprise 17.0 29.3 32.3 21.2trust 22.4 27.8 22.4 27.2micro average 18.1 27.6 26.4 27.7Table 5: Agreement at four intensity levels for emotion(no, weak, moderate, and strong): Percent of 2081 termsfor which the majority class size was 2, 3, 4, and 5.Majority class sizeEmotion three four fiveanger 15.0 25.9 58.9anticipation 32.3 33.7 33.8disgust 12.8 24.6 62.4fear 14.9 25.6 59.4joy 18.4 27.0 54.5sadness 13.6 22.0 64.2surprise 17.5 31.4 50.9trust 23.9 29.3 46.6micro average 18.6 27.4 53.8Table 6: Agreement at two intensity levels for emotion(evocative and non-evocative): Percent of 2081 terms forwhich the majority class size was 3, 4, and 5.4.2 Semantic orientation of wordsWe consolidate the semantic orientation (polarity)annotations in a manner identical to the process foremotion annotations.
Table 7 lists the percent of2081 target terms assigned a majority class of no,weak, moderate, and strong semantic orientation.For example, it tells us that 16% of the target termsare strongly negative.
The last row in the table liststhe percent of target terms that have some semanticorientation (positive or negative) at the various in-tensity levels.
Observe that 35% of the target termsare strongly evaluative (positively or negatively).Just as in the case for emotions, practical NLP ap-plications often require only two levels of seman-tic orientation?having particular semantic orienta-tion or not (evaluative) or not (non-evaluative).
Foreach target term?emotion pair, we convert the four-level semantic orientation annotations into two-levelones, just as we did for the emotions.
Table 8 givesIntensityPolarity no weak moderate strongnegative 60.8 10.8 12.3 16.0positive 48.3 11.7 20.7 19.0micro average 54.6 11.3 16.5 17.5any polarity 14.7 17.4 32.7 35.0Table 7: Percent of 2081 terms assigned a majority classof no, weak, moderate, and strong polarity.Polarity % of termsnegative 31.3positive 45.5micro average 38.4any polarity 76.1Table 8: Percent of 2081 target terms that are evaluative.percent of target terms considered to be evaluative.The last row in the table gives the percentage ofterms evaluative with respect to some semantic ori-entation (positive or negative).
Table 9 shows howmany terms in each category are positively and neg-atively evaluative.4.2.1 Analysis and discussionObserve in Table 9 that, across the board, a sizablenumber of terms are evaluative with respect to somesemantic orientation.
Interestingly unigram nounshave a markedly lower proportion of negative terms,and a much higher proportion of positive terms.
Itmay be argued that the default semantic orientationof noun concepts is positive, and that usually it takesa negative adjective to make the phrase negative.The EmoLexGI rows in the two tables show thatwords marked as having a negative semantic orien-tation in the General Inquirer are mostly marked asnegative by the Turkers.
And similarly, the positivesin GI are annotated as positive.
Again, this is con-firmation that the quality of annotation obtained ishigh.
The EmoLexWAL rows show that anger, dis-gust, fear, and sadness terms tend not to have a posi-tive semantic orientation and are mostly negative.
Incontrast, and expectedly, the joy terms are positive.The surprise terms are more than twice as likely tobe positive than negative.4.2.2 AgreementIn order to analyze how often the annotators agreedwith each other, for each term?emotion pair, we cal-32EmoLex negative positive anyEmoLexUni:adjectives 33 55 87adverbs 29 54 82nouns 6 44 51verbs 22 41 62EmoLexBi:adjectives 30 48 78adverbs 10 52 61nouns 13 49 61verbs 12 57 68EmoLexGI:negatives in GI 90 2 92positives in GI 2 91 91EmoLexWAL:anger terms in WAL 96 0 96disgust terms in WAL 96 0 96fear terms in WAL 87 3 89joy terms in WAL 4 92 96sadness terms in WAL 90 1 91surprise terms in WAL 23 57 81Table 9: Percent of terms, in each target set, that are eval-uative.
The highest individual polarity EmoLexGI rowscores are shown bold.
Observe that the positive GI termsare marked mostly as positively evaluative and the nega-tive terms are marked mostly as negatively evaluative.culated the percentage of times the majority classhas size 5 (all Turkers agree), size 4 (all but oneagree), size 3, and size 2.
Table 10 presents theseagreement values.
Observe that for more than 50%of the terms, at least four annotators agree with eachother.
Table 11 gives agreement values at the two-intensity level.
Observe that for more than 50% ofthe terms, all five annotators agree with each other,and for more than 80% of the terms, at least fourannotators agree.5 ConclusionsWe showed how Mechanical Turk can be used tocreate a high-quality, moderate-sized, emotion lex-icon for a very small cost (less than US$500).
No-tably, we used automatically generated word choicequestions to detect and reject erroneous annotationsand to reject all annotations by unqualified Turkersand those who indulge in malicious data entry.
Wecompared a subset of our lexicon with existing goldstandard data to show that the annotations obtainedare indeed of high quality.
A detailed analysis of theMajority class sizePolarity two three four fivenegative 11.8 28.7 29.4 29.8positive 21.2 30.7 19.0 28.8micro average 16.5 29.7 24.2 29.3Table 10: Agreement at four intensity levels for polarity(no, weak, moderate, and strong): Percent of 2081 termsfor which the majority class size was 2, 3, 4, and 5.Majority class sizePolarity three four fivenegative 11.8 21.2 66.9positive 23.1 26.3 50.5micro average 17.5 23.8 58.7Table 11: Agreement at two intensity levels for polarity(evaluative and non-evaluative): Percent of 2081 termsfor which the majority class size was 3, 4, and 5.lexicon revealed insights into how prevalent emotionbearing terms are among common unigrams and bi-grams.
We also identified which emotions tend to beevoked simultaneously by the same term.
The lexi-con is available for free download.4Since this pilot experiment with about 2000 targetterms was successful, we will now obtain emotionannotations for tens of thousands of English terms.We will use the emotion lexicon to identify emo-tional tone of larger units of text, such as newspaperheadlines and blog posts.
We will also use it to eval-uate automatically generated lexicons, such as thepolarity lexicons by Turney and Littman (2003) andMohammad et al (2009).
We will explore the vari-ance in emotion evoked by near-synonyms, and alsohow common it is for words with many meanings toevoke different emotions in different senses.AcknowledgmentsThis research was funded by the National researchCouncil Canada (NRC).
Thanks to Diana Inkpenand Diman Ghazi for early discussions on emotion.Thanks to Joel Martin for encouragement and sup-port.
Thanks to Norm Vinson and the Ethics Com-mittee at NRC for examining, guiding, and approv-ing the survey.
And last but not least, thanks to themore than 1000 anonymous people who answeredthe emotion survey with diligence and care.4http://www.purl.org/net/emolex33ReferencesCecilia Ovesdotter Alm, Dan Roth, and Richard Sproat.2005.
Emotions from text: Machine learning fortext-based emotion prediction.
In Proceedings of theJoint Conference on Human Language Technology/ Empirical Methods in Natural Language Process-ing (HLT/EMNLP-2005), pages 579?586, Vancouver,Canada.J.R.L.
Bernard, editor.
1986.
The Macquarie Thesaurus.Macquarie Library, Sydney, Australia.Thorsten Brants and Alex Franz.
2006.
Web 1t 5-gramversion 1.
Linguistic Data Consortium.Chris Callison-Burch.
2009.
Fast, cheap and cre-ative: Evaluating translation quality using amazon?smechanical turk.
In Proceedings of the Conference onEmpirical Methods in Natural Language Processing(EMNLP-2009), pages 286?295, Singapore.Paul Ekman.
1992.
An argument for basic emotions.Cognition and Emotion, 6(3):169?200.Clark Elliott.
1992.
The affective reasoner: A processmodel of emotions in a multi-agent system.
Ph.D. the-sis, Institute for the Learning Sciences, NorthwesternUniversity.Dekang Lin, Shaojun Zhao, Lijuan Qin, and Ming Zhou.2003.
Identifying synonyms among distributionallysimilar words.
In Proceedings of the 18th Inter-national Joint Conference on Artificial Intelligence(IJCAI-03), pages 1492?1493, Acapulco, Mexico.A.
Lobanova, T. van der Kleij, and J. Spenader.
2010.Defining antonymy: A corpus-based study of oppo-sites by lexico-syntactic patterns.
International Jour-nal of Lexicography (in press), 23:19?53.Saif Mohammad, Bonnie Dorr, and Codie Dunn.
2008.Computing word-pair antonymy.
In Proceedings ofthe Conference on Empirical Methods in Natural Lan-guage Processing (EMNLP-2008), pages 982?991,Waikiki, Hawaii.Saif Mohammad, Cody Dunne, and Bonnie Dorr.
2009.Generating high-coverage semantic orientation lexi-cons from overtly marked words and a thesaurus.
InProceedings of Empirical Methods in Natural Lan-guage Processing (EMNLP-2009), pages 599?608,Singapore.Alena Neviarouskaya, Helmut Prendinger, and MitsuruIshizuka.
2009.
Compositionality principle in recog-nition of fine-grained emotions from text.
In Proceed-ings of the Proceedings of the Third International Con-ference on Weblogs and Social Media (ICWSM-09),pages 278?281, San Jose, California.R Plutchik.
1980.
A general psychoevolutionary theoryof emotion.
Emotion: Theory, research, and experi-ence, 1(3):3?33.Jonathon Read.
2004.
Recognising affect in text usingpointwise-mutual information.
Ph.D. thesis, Depart-ment of Informatics, University of Sussex.Rion Snow, Brendan O?Connor, Daniel Jurafsky, and An-drew Ng.
2008.
Cheap and fast - but is it good?
Evalu-ating nonexpert annotations for natural language tasks.In Proceedings of the Conference on Empirical Meth-ods in Natural Language Processing (EMNLP-2008),pages 254?263, Waikiki, Hawaii.Philip Stone, Dexter C. Dunphy, Marshall S. Smith,Daniel M. Ogilvie, and associates.
1966.
The GeneralInquirer: A Computer Approach to Content Analysis.The MIT Press.Carlo Strapparava and Alessandro Valitutti.
2004.Wordnet-Affect: An affective extension of WordNet.In Proceedings of the 4th International Conferenceon Language Resources and Evaluation (LREC-2004),pages 1083?1086, Lisbon, Portugal.Peter Turney and Michael Littman.
2003.
Measuringpraise and criticism: Inference of semantic orientationfrom association.
ACM Transactions on InformationSystems (TOIS), 21(4):315?346.34
