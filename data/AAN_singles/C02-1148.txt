Investigating the Relationship between Word SegmentationPerformance and Retrieval Performance in Chinese IRFuchun Peng and Xiangji Huang and Dale Schuurmans and Nick CerconeSchool of Computer Science, University of Waterloo200 University Ave. West, Waterloo, Ontario, Canada, N2L 3G1{f3peng, jhuang, dale, ncercone}@uwaterloo.caAbstractIt is commonly believed that word segmentation ac-curacy is monotonically related to retrieval perfor-mance in Chinese information retrieval.
In this pa-per we show that, for Chinese, the relationship be-tween segmentation and retrieval performance is infact nonmonotonic; that is, at around 70% wordsegmentation accuracy an over-segmentation phe-nomenon begins to occur which leads to a reductionin information retrieval performance.
We demon-strate this effect by presenting an empirical inves-tigation of information retrieval on Chinese TRECdata, using a wide variety of word segmentation al-gorithms with word segmentation accuracies rangingfrom 44% to 95%.
It appears that the main reasonfor the drop in retrieval performance is that correctcompounds and collocations are preserved by accu-rate segmenters, while they are broken up by lessaccurate (but reasonable) segmenters, to a surpris-ing advantage.
This suggests that words themselvesmight be too broad a notion to conveniently capturethe general semantic meaning of Chinese text.1 IntroductionAutomated processing of written languages suchas Chinese involves an inherent word segmentationproblem that is not present in western languages likeEnglish.
Unlike English, Chinese words are not ex-plicitly delimited by whitespace, and therefore toperform automated text processing tasks (such asinformation retrieval) one normally has to first seg-ment the text collection.
Typically this involves seg-menting the text into individual words.
Althoughthe text segmentation problem in Chinese has beenheavily investigated recently (Brent and Tao, 2001;Chang, 1997; Ge et al, 1999; Hockenmaier andBrew, 1998; Jin, 1992; Peng and Schuurmans, 2001;Sproat and Shih, 1990; Teahan et al 2001) mostresearch has focused on the problem of segmentingcharacter strings into individual words, rather thanuseful constituents.
However, we have found thatfocusing exclusively on words may not lead to themost effective segmentation from the perspective ofbroad semantic analysis (Peng et al 2002).In this paper we will focus on a simple form of se-mantic text processing: information retrieval (IR).Although information retrieval does not require adeep semantic analysis, to perform effective retrievalone still has to accurately capture the main topic ofdiscourse and relate this to a given query.
In the con-text of Chinese, information retrieval is complicatedby the fact that the words in the source text (andperhaps even the query) are not separated by whites-pace.
This creates a significant amount of additionalambiguity in interpreting sentences and identifyingthe underlying topic of discourse.There are two standard approaches to informationretrieval in Chinese text: character based and wordbased.
It is usually thought that word based ap-proaches should be superior, even though characterbased methods are simpler and more commonly used(Huang and Robertson, 2000).
However, there hasbeen recent interest in the word based approach, mo-tivated by recent advances in automatic segmenta-tion of Chinese text (Nie et al 1996; Wu and Tseng,1993).
A common presumption is that word segmen-tation accuracy should monotonically influence sub-sequent retrieval performance (Palmer and Burger,1997).
Consequently, many researchers have focusedon producing accurate word segmenters for Chinesetext indexing (Teahan et al 2001; Brent and Tao,2001).
However, we have recently observed that lowaccuracy word segmenters often yield superior re-trieval performance (Peng et al 2002).
This obser-vation was initially a surprise, and motivated us toconduct a more thorough study of the phenomenonto uncover the reason for the performance decrease.The relationship between Chinese word segmenta-tion accuracy and information retrieval performancehas recently been investigated in the literature.
Fooand Li (2001) have conducted a series of experimentswhich suggests that the word segmentation approachdoes indeed have effect on IR performance.
Specif-ically, they observe that the recognition of words oflength two or more can produce better retrieval per-formance, and the existence of ambiguous words re-sulting from the word segmentation process can de-crease retrieval performance.
Similarly, Palmer andBurger (1997) observe that accurate segmentationtends to improve retrieval performance.
All of thisprevious research has indicated that there is indeedsome sort of correlation between word segmentationperformance and retrieval performance.
However,the nature of this correlation is not well understood,and previous research uniformly suggests that thisrelationship is monotonic.One reason why the relationship between seg-mentation and retrieval performance has not beenwell understood is that previous investigators havenot considered using a variety of Chinese word seg-menters which exhibit a wide range of segmenta-tion accuracies, from low to high.
In this paper,we employ three families of Chinese word segmenta-tion algorithms from the recent literature.
The firsttechnique we employed was the standard maximummatching dictionary based approach.
The remainingtwo algorithms were selected because they can bothbe altered by simple parameter settings to obtaindifferent word segmentation accuracies.
Specifically,the second Chinese word segmenter we investigatedwas the minimum description length algorithm ofTeahan et al (2001), and the third was the EMbased technique of Peng and Schuurmans (2001).Overall, these segmenters demonstrate word identi-fication accuracies ranging from 44% to 95% on thePH corpus (Brent and Tao, 2001; Hockenmaier andBrew, 1998; Teahan et al 2001).Below we first describe the segmentation algo-rithms we used, and then discuss the informationretrieval environment considered (in Sections 2 and3 respectively).
Section 4 then reports on the out-come of our experiments on Chinese TREC data,and in Section 5 we attempt to determine the reasonfor the over-segmentation phenomenon witnessed.2 Word Segmentation AlgorithmsChinese word segmentation has been extensively re-searched.
However, in Chinese information retrievalthe most common tokenziation methods are stillthe simple character based approach and dictionary-based word segmentation.
In the character basedapproach sentences are tokenized simply by takingeach character to be a basic unit.
In the dictionarybased approach, on the other hand, one pre-defines alexicon containing a large number of words and thenuses heuristic methods such as maximum matchingto segment sentences.
Below we experiment withthese standard methods, but in addition employ tworecently proposed segmentation algorithms that al-low some control of how accurately words are seg-mented.
The details of these algorithms can befound in the given references.
For the sake of com-pleteness we briefly describe the basic approacheshere.2.1 Dictionary based word segmentationThe dictionary based approach is the most popu-lar Chinese word segmentation method.
The idea isto use a hand built dictionary of words, compoundwords, and phrases to index the text.
In our experi-ments we used the longest forward match method inwhich text is scanned sequentially and the longestmatching word from the dictionary is taken at eachsuccessive location.
The longest matched strings arethen taken as indexing tokens and shorter tokenswithin the longest matched strings are discarded.
Inour experiments we used two different dictionaries.The first is the Chinese dictionary used by Gey etal.
(1997), which includes 137,659 entries.
The sec-ond is the Chinese dictionary used by Beaulieu et al(1997), which contains 69,353 words and phrases.2.2 Compression based word segmentationThe PPM word segmentation algorithm of Teahan etal.
(2001) is based on the text compression methodof Cleary and Witten (1984).
PPM learns an n-gramlanguage model by supervised training on a given setof hand segmented Chinese text.
To segment a newsentence, PPM seeks the segmentation which givesthe best compression using the learned model.
Thishas been proven to be a highly accurate segmenter(Teahan et al 2001).
Its quality is affected both bythe amount of training data and by the order of then-gram model.
By controlling the amount of train-ing data and the order of language model we cancontrol the resulting word segmentation accuracy.2.3 EM based word segmentationThe ?self-supervised?
segmenter of Peng and Schu-urmans (2001) is an unsupervised technique basedon a variant of the EM algorithm.
This methodlearns a hidden Markov model of Chinese words, andthen segments sentences using the Viterbi algorithm(Rabiner, 1989).
It uses a heuristic technique toreduce the size of the learned lexicon and preventthe acquisition of erroneous word agglomerations.Although the segmentation accuracy of this unsu-pervised method is not as high as the supervisedPPM algorithm, it nevertheless obtains reasonableperformance and provides a fundamentally differentsegmentation scheme from PPM.
The segmentationperformance of this technique can be controlled byvarying the number of training iterations and by ap-plying different lexicon pruning techniques.3 Information Retrieval MethodWe conducted our information retrieval experimentsusing the OKAPI system (Huang and Robertson,2000; Robertson et al, 1994).
In an attempt to en-sure that the phenomena we observe are not specificto a particular retrieval technique, we experimentedwith a parameterized term weighting scheme whichallowed us to control the quality of retrieval per-formance.
We considered a refined term weightingscheme based on the the standard term weightingfunctionw0 = logN ?
n+ 0.5n+ 0.5 (1)where N is the number of indexed documents in thecollection, and n is the number of documents con-taining a specific term (Spark Jones, 1979).
Manyresearchers have shown that augmenting this basicfunction to take into account document length, aswell as within-document and within-query frequen-cies, can be highly beneficial in English text retrieval(Beaulieu et al, 1997).
For example, one standardaugmentation is to usew1 = w0 ?
(c1 + 1) ?
tfK + tf ?
(c2 + 1 ) ?
qtfc2 + qtf (2)whereK = c1 ?(1?
c3 + c3 dlavdl)Here tf is within-document term frequency, qtf iswithin-query term frequency, dl is the length ofthe document, avdl is the average document length,and c1, c2, c3 are tuning constants that depend onthe database, the nature of the queries, and areempirically determined.
However, to truly achievestate-of-the-art retrieval performance, and also toallow for the quality of retrieval to be manipulated,we further augmented this standard term weightingscheme with an extra correction termw2 = w1 ?
kd ?
y (3)This correction allows us to more accurately accountfor the length of the document.
Here ?
indicatesthat the component is added only once per docu-ment, rather than for each term, andy =????????
?ln( dlavdl ) + ln(c4) if dl ?
rel avdl(ln( rel avdlavdl ) + ln(c4)) (1?
dl?rel avdlc5?avdl?rel avdl)if dl > rel avdlwhere rel avdl is the average relevant documentlength calculated from previous queries based on thesame collection of documents.
Overall, this termweighting formula has five tuning constants, c1 toc5, which are all set from previous research on En-glish text retrieval and some initial experiments onChinese text retrieval.
In our experiments, the val-ues of the five arbitrary constants c1, c2, c3, c4 andc5 were set to 2.0, 5.0, 0.75, 3 and 26 respectively.The key constant is the quantity kd, which is thenew tuning constant that we manipulate to controlthe influence of correction factor, and hence controlthe retrieval quality.
By setting kd to different val-ues, we have different term weighting methods in ourexperiments.
In our experiments, we tested kd setto values of 0, 6, 8, 10, 15, 20, 50.4 ExperimentsWe conducted a series of experiments in word basedChinese information retrieval, where we varied boththe word segmentation method and the informationretrieval method.
We experimented with word seg-mentation techniques of varying accuracy, and infor-mation retrieval methods with varying performance.In almost every case, we witness a nonmonotonicrelationship between word segmentation accuracyand retrieval performance, robustly across retrievalmethods.
Before describing the experimental resultsin detail however, we first have to describe the per-formance measures used in the experiments.4.1 Measuring segmentation performanceWe evaluated segmentation performance on theMandarin Chinese corpus, PH, due to Guo Jin.
Thiscorpus contains one million words of segmented Chi-nese text from newspaper stories of the Xinhua newsagency of the People?s Republic of China publishedbetween January 1990 and March 1991.To make the definitions precise, first define theoriginal segmented test corpus to be S. We thencollapse all the whitespace between words to makea second unsegmented corpus U , and then use thesegmenter to recover an estimate S?
of the originalsegmented corpus.
We measure the segmentationperformance by precision, recall, and F-measure ondetecting correct words.
Here, a word is consideredto be correctly recovered if and only if (Palmer andBurger, 1997)1. a boundary is correctly placed in front of thefirst character of the word2.
a boundary is correctly placed at the end of thelast character of the word3.
and there is no boundary between the first andlast character of the word.Let N1 denote the number of words in S, let N2 de-note the number of words in the estimated segmen-tation S?, and let N3 denote the number of wordscorrectly recovered.
Then the precision, recall andF measures are definedprecision: p = N3N2recall: r = N3N1F-measure: F = 2?p?rp+rIn this paper, we only report the performance inF-measure, which is a comprehensive measure thatcombines precision and the recall.4.2 Measuring retrieval performanceWe used the TREC relevance judgments for eachtopic that came from the human assessors of theNational Institute of Standards and Technology(NIST).
Our statistical evaluation was done bymeans of the TREC evaluation program.
The mea-sures we report are Average Precision: average pre-cision over all 11 recall points (0.0, 0.1, 0.2,..., 1.0);and R Precision: precision after the number of doc-uments retrieved is equal to the number of knownrelevant documents for a query.
Detailed descrip-tions of these measures can be found in (Voorheesand Harman, 1998).4.3 Data setsWe used the information retrieval test collectionsfrom TREC-5 and TREC-6 (Voorhees and Harman,1998).
(Note that the document collection used inthe TREC-6 Chinese track was identical to the oneused in TREC-5, however the topic queries differ.
)This collection of Chinese text consists of 164,768documents and 139,801 articles selected from thePeople?s Daily newspaper, and 24,988 articles se-lected from the Xinhua newswire.
The original arti-cles are tagged in SGML, and the Chinese charactersin these articles are encoded using the GB (Guo-Biao) coding scheme.
Here 0 bytes is the minimumfile size, 294,056 bytes is the maximum size, and 891bytes is the average file size.To provide test queries for our experiments, weconsidered the 54 Chinese topics provided as partof the TREC-5 and TREC-6 evaluations (28 forTREC-5 and 26 for TREC-6).Finally, for the two learning-based segmentationalgorithms, we used two separate training corporabut a common test corpus to evaluate segmentationaccuracy.
For the PPM segmenter we used 72% ofthe PH corpus as training data.
For the the self-supervised segmenter we used 10M of data from thedata set used in (Ge et al, 1999), which contains oneyear of People?s Daily news service stories.
We usedthe entire PH collection as the test corpus (whichgives an unfair advantage to the supervised methodPPM which is trained on most of the same data).4.4 Segmentation accuracy controlBy using the forward maximum matching segmen-tation strategy with the two dictionaries, Berkeleyand City, we obtain the segmentation performanceof 71% and 85% respectively.
For the PPM algo-rithm, by controlling the order of the n-gram lan-guage model used (specifically, order 2 and order3) we obtain segmenters that achieve 90% and 95%word recognition accuracy respectively.
Finally, forthe self-supervised learning technique, by controllingthe number of EM iterations and altering the lexi-con pruning strategy we obtain word segmentationaccuracies of 44%, 49%, 53%, 56%, 59%, 70%, 75%,and 77%.
Thus, overall we obtain 12 different seg-menters that achieve segmentation performances of44%, 49%, 53%, 56%, 59%, 70%, 71%, 75%, 77%,85%, 90%, and 95%.4.5 Experimental resultsNow, given the 12 different segmenters, we con-ducted extensive experiments on the TREC datasets using different information retrieval methods(achieved by tuning the kd constant in the termweighting function described in Section 3).Table 1 shows the average precision and R-precision results obtained on the TREC-5 andTREC-6 queries when basing retrieval on word seg-mentations at 12 different accuracies, for a singleretrieval method, kd = 10.
To illustrate the resultsgraphically, we re-plot this data in Figure 1, in whichthe x-axis is the segmentation performance and they-axis is the retrieval performance.seg.
accuracy TREC-5 TREC-644% 0.2231/0.2843 0.3424/0.393049% 0.2647/0.3259 0.3848/0.420153% 0.2999/0.3376 0.4492/0.480156% 0.3056/0.3462 0.4473/0.472759% 0.3097/0.3533 0.4740/0.496070% 0.3721/0.3988 0.5044/0.507271% 0.3656/0.4088 0.5133/0.511675% 0.3652/0.4000 0.4987/0.509777% 0.3661/0.4027 0.4968/0.497385% 0.3488/0.3898 0.5049/0.504790% 0.3213/0.3663 0.4983/0.500895% 0.3189/0.3669 0.4867/0.4933Table 1: Average precision and R-precision resultson TREC queries when kd = 10.0.4 0.6 0.8 10.20.250.30.350.40.45 Relation of segmentation performance and retrieval performance on TREC5 (kd=10)P?precisionR?precision0.4 0.6 0.8 10.20.30.40.50.6 Relation of segmentation performance and retrieval performance on TREC6 (kd=10)P?precisionR?precisionFigure 1: Retrieval F-measure (y-axis) versus seg-mentation accuracy (x-axis) for kd = 10.Clearly these curves demonstrate a nonmonotonicrelationship between retrieval performance (on theboth P-precision and the R-precision) and segmen-tation accuracy.
In fact, the curves show a clearuni-modal shape, where for segmentation accura-cies 44% to 70% the retrieval performance increasessteadily, but then plateaus for segmentation accu-racies between 70% and 77%, and finally decreasesslightly when the segmentation performance increaseto 85%,90% and 95%.This phenomenon is robustly observed as wealter the retrieval method by setting kd =0, 6, 8, 15, 20, 50, as shown in Figures 2 to 7 respec-tively.To give a more detailed picture of the results, Fig-ures 8 and 9 we illustrate the full precision-recallcurves for kd = 10 at each of the 12 segmentationaccuracies, for TREC-5 and TREC-6 queries respec-tively.
In these figures, the 44%, 49% segmentationsare marked with stars, the 53%, 56%, 59% segmen-tations are marked with circles, the 70%, 71%, 75%,77% segmentations are marked with diamonds, the85% segmentation is marked with hexagrams, andthe 90% and 95% segmentations are marked withtriangles.
We can see that the curves with the dia-monds are above the others, while the curves withstars are at the lowest positions.0.4 0.6 0.8 10.10.150.20.250.30.350.4 Relation of segmentation performance and retrieval performance on TREC5 (kd=0)P?precisionR?precision0.4 0.6 0.8 10.20.30.40.5 Relation of segmentation performance and retrieval performance on TREC6 (kd=0)P?precisionR?precisionFigure 2: Results for kd = 0.5 DiscussionThe observations were surprising to us at first, al-though they suggest that there is an interesting phe-nomenon at work.
To attempt to identify the under-lying cause, we break the explanation into two parts:one for the first part of the curves where retrievalperformance increases with increasing segmentationaccuracy, and a second effect for the region whereretrieval performance plateaus and eventually de-creases with increasing segmentation accuracy.The first part of these performance curves seemseasy to explain.
At low segmentation accuracies thesegmented tokens do not correspond to meaningful0.4 0.6 0.8 10.20.250.30.350.40.45 Relation of segmentation performance and retrieval performance on TREC5 (kd=6)P?precisionR?precision0.4 0.6 0.8 10.20.30.40.50.6 Relation of segmentation performance and retrieval performance on TREC6 (kd=6)P?precisionR?precisionFigure 3: Results for kd = 6.0.4 0.6 0.8 10.20.250.30.350.40.45 Relation of segmentation performance and retrieval performance on TREC5 (kd=8)P?precisionR?precision0.4 0.6 0.8 10.20.30.40.50.6 Relation of segmentation performance and retrieval performance on TREC6 (kd=8)P?precisionR?precisionFigure 4: Results for kd = 8.linguistic terms, such as words, which hampers re-trieval performance because the term weighting pro-cedure is comparing arbitrary tokens to the query.However, as segmentation accuracy improves, the to-kens behave more like true words and the retrievalengine begins to behave more conventionally.However, after a point, when the second regimeis reached, retrieval performance no longer increaseswith improved segmentation accuracy, and eventu-ally begins to decrease.
One possible explanationfor this which we have found is that a weak wordsegmenter accidentally breaks compound words intosmaller constituents, and this, surprisingly yields abeneficial effect for Chinese information retrieval.For example, one of the test queries, Topic 34,is about the impact of droughts in various parts ofChina.
Retrieval based on the EM-70% segmenterretrieved 84 of 95 relevant documents in the col-lection, whereas retrieval based on the PPM-95%segmenter retrieved only 52 relevant documents.
Infact, only 2 relevant documents were missed by EM-70% but retrieved by PPM-95%, whereas 34 docu-0.4 0.6 0.8 10.20.250.30.350.40.45 Relation of segmentation performance and retrieval performance on TREC5 (kd=15)P?precisionR?precision0.4 0.6 0.8 10.20.30.40.50.6 Relation of segmentation performance and retrieval performance on TREC6 (kd=15)P?precisionR?precisionFigure 5: Results for kd = 15.0.4 0.6 0.8 10.20.250.30.350.40.45 Relation of segmentation performance and retrieval performance on TREC5 (kd=20)P?precisionR?precision0.4 0.6 0.8 10.20.30.40.50.6 Relation of segmentation performance and retrieval performance on TREC6 (kd==20)P?precisionR?precisionFigure 6: Results for kd = 20.ments retrieved by EM-70% and not by PPM-95%.In investigating this phenomenon, one finds that theperformance drop appears to be due to the inherentnature of written Chinese.
That is, in written Chi-nese many words can often legally be representedtheir subparts.
For example, @*?
(agricultureplants) is sometimes represented as*?(plants).
Sofor example in Topic 34, the PPM-95% segmentercorrectly segments B?
as B?
(drought disas-ter) and @*?
correctly as @*?
(agricultureplants), whereas the EM-70% segmenter incorrectlysegments B?
as B(drought) and ?
(disaster), andincorrectly segments @*?
as @(agriculture) and*?(plants).
However, by inspecting the relevantdocuments for Topic 34, we find that there are manyChinese character strings in these documents thatare closely related to the correctly segmented wordB?
(drought disaster).
These alternative words areB?B??IB?
?B?fiB?BK etc.
Forexample, in the relevant document ?pd9105-832?,which is ranked 60th by EM-70% and 823rd byPPM-95%, the correctly segmented word B?
does0.4 0.6 0.8 10.10.150.20.250.30.350.4 Relation of segmentation performance and retrieval performance on TREC5 (kd=50)P?precisionR?precision0.4 0.6 0.8 10.20.30.40.5 Relation of segmentation performance and retrieval performance on TREC6 (kd=50)P?precisionR?precisionFigure 7: Results for kd = 50.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 100.10.20.30.40.50.60.70.80.9RecallP?PrecisionOverview of the TREC5 results 44%49%53%56%59%70%71%75%77%85%90%95%Figure 8: TREC5 precision-recall comprehensiveview at kd = 10not appear at all.
Consequently, the correct seg-mentation for B?
by PPM-95% leads to a muchweaker match than the incorrect segmentation ofEM-70%.
Here EM-70% segments B?
into B and?
, which is not regarded as a correct segmentation.However, there are many matches between the topicand relevant documents which contain onlyB.
Thissame phenomenon happens with the query word @*?
since many documents only contain the frag-ment *?
instead of @*?, and these documentsare all missed by PPM-95% but captured by EM-70%.Although straightforward, these observations sug-gest a different trajectory for future research on Chi-nese information retrieval.
Instead of focusing onachieving accurate word segmentation, we shouldpay more attention to issues such as keyword weight-ing (Huang and Robertson, 2000) and query key-word extraction (Chien et al 1997).
Also, we findthat the weak unsupervised segmentation method0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 100.10.20.30.40.50.60.70.80.91 Overview of the TREC?6 resultsRecallP?Precision44%49%53%56%59%70%71%75%77%85%90%95%Figure 9: TREC6 precision-recall comprehensiveview at kd = 10based yields better Chinese retrieval performancethan the other approaches, which suggests a promis-ing new avenue to apply machine learning techniquesto IR (Sparck Jones, 1991).
Of course, despite theseresults we expect highly accurate word segmenta-tion to still play an important role in other Chineseinformation processing tasks such as information ex-traction and machine translation.
This suggests thatsome different evaluation standards for Chinese wordsegmentation should be given to different NLP ap-plications.6 AcknowledgmentsResearch supported by Bell University Labs, MI-TACS and NSERC.
We sincerely thank Dr. WilliamTeahan for supplying us the PPM segmenters.ReferencesBeaulieu, M. and Gatford, M. and Huang, X. andRobertson, S. and Walker, S. and Williams, P.1997.
Okapi at TREC-5.
In Proceedings TREC-5.Brent, M. and Tao, X.
2001, Chinese Text Segmen-tation With MBDP-1: Making the Most of Train-ing Corpora.
In Proceedings ACL-2001.Buckley, C., Singhal, A., and Mitra, M. 1997.
Us-ing query zoning and correlation within SMART:TREC-5.
In Proceedings TREC-5.Chang, J.-S. and Su, K.-Y.
1997, An UnsupervisedIterative Method for Chinese New Lexicon Extrac-tion, In Int J Comp Ling & Chinese Lang Proc.Chen, A. and He, J. and Xu, L. and Gey, F. andMeggs, J.
1997.
Chinese Text Retrieval WithoutUsing a Dictionary.
In Proceedings SIGIR-97.Chien L. and Huang, T. and Chien, M. 1997 InProceedings SIGIR-97.Cleary, J. and Witten, I.
1984.
Data compressionusing adaptive coding and partial string matching.In IEEE Trans Communications, 32(4): 396-402.Foo, S. and Li, H. 2001 Chinese Word SegmentationAccuracy and Its Effects on Information Retrieval.In TEXT Technology.Ge, X., Pratt, W. and Smyth, P. 1999.
Discover-ing Chinese Words from Unsegmented Text.
InProceedings SIGIR-99.Gey, F., Chen, A., He, J., Xu, L. and Meggs, J.1997 Term Importance, Boolean Conjunct Train-ning Negative Terms, and Foreign Language Re-trieval: Probabilistic Algorithms at TREC-5.
InProceedings TREC-5.Hockenmaier, J. and Brew C. 1998.
Error drivensegmentation of Chinese.
In Comm.
COLIPS,8(1): 69-84.Huang, X. and Robertson, S. 2000.
A probabilisticapproach to Chinese information retrieval: theoryand experiments.
In Proceedings BCS-IRSG 2000.Jin, W. 1992, Chinese Segmentation and its Disam-biguation, Tech report, New Mexico State Univ.Nie, J., Brisebois, M. and Ren, X.
1996.
On Chinesetext retrieval.
In Proceedings SIGIR-96.Palmer, D. and Burger, J.
1997.
Chinese Word Seg-mentation and Information Retrieval.
In AAAISymp Cross-Language Text and Speech Retrieval.Peng, F., Huang, X., Schuurmans, D., Cercone, N.,and Robertson, S. 2002.
Using Self-supervisedWord Segmentation in Chinese Information Re-trieval.
In Proceedings SIGIR-02.Peng, F. and Schuurmans, D. 2001.
Self-supervisedChinese Word Segmentation.
In Proceedings IDA-01, LNCS 2189.Rabiner, L. 1989.
A Tutorial on Hidden MarkovModels and Selected Applications in SpeechRecognition.
In Proceedings of IEEE, 77(2).Robertson, S. and Walker, S. 1994.
Some SimpleEffective Approximations to the 2-Poisson Modelfor Probabilistic Weighted Retrieval.
SIGIR-94.Sparck Jones, K. 1991 The Role of Artificial In-telligence in Information Retrieval J. Amer.
Soc.Info.
Sci., 42(8): 558-565.Sparck Jones, K. 1979.
Search Relevance Weight-ing Given Little Relevance Information.
In J. ofDocumentation, 35(1).Sproat, R. and Shih, C. 1990.
A Statistical Methodfor Finding Word Boundaries in Chinese Text, InComp Proc of Chinese and Oriental Lang, 4.Teahan, W. J. and Wen, Y. and McNab, R. andWitten I. H. 2001 A Compression-based Algo-rithm for Chinese Word Segmentation.
In Com-put.
Ling., 26(3):375-393.Voorhees, E. and Harman, D. 1998.
Overview ofthe Sixth Text REtrieval Conference (TREC-6),In Proceedings TREC-6.Wu, Z. and Tseng, G. 1993.
Chinese Text Segmen-tation for Text Retrieval: Achievements and Prob-lems.
In J. Amer.
Soc.
Info.
Sci., 44(9): 532-542.
