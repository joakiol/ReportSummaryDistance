Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 193?198,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsDocent: A Document-Level Decoder forPhrase-Based Statistical Machine TranslationChristian Hardmeier Sara Stymne J?rg Tiedemann Joakim NivreUppsala UniversityDepartment of Linguistics and PhilologyBox 635, 751 26 Uppsala, Swedenfirstname.lastname@lingfil.uu.seAbstractWe describe Docent, an open-source de-coder for statistical machine translationthat breaks with the usual sentence-by-sentence paradigm and translates completedocuments as units.
By taking transla-tion to the document level, our decodercan handle feature models with arbitrarydiscourse-wide dependencies and consti-tutes an essential infrastructure compon-ent in the quest for discourse-aware SMTmodels.1 MotivationMost of the research on statistical machine trans-lation (SMT) that was conducted during the last20 years treated every text as a ?bag of sentences?and disregarded all relations between elements indifferent sentences.
Systematic research into ex-plicitly discourse-related problems has only begunvery recently in the SMT community (Hardmeier,2012) with work on topics such as pronominalanaphora (Le Nagard and Koehn, 2010; Hard-meier and Federico, 2010; Guillou, 2012), verbtense (Gong et al 2012) and discourse connect-ives (Meyer et al 2012).One of the problems that hamper the develop-ment of cross-sentence models for SMT is the factthat the assumption of sentence independence isat the heart of the dynamic programming (DP)beam search algorithm most commonly used fordecoding in phrase-based SMT systems (Koehn etal., 2003).
For integrating cross-sentence featuresinto the decoding process, researchers had to adoptstrategies like two-pass decoding (Le Nagard andKoehn, 2010).
We have previously proposed analgorithm for document-level phrase-based SMTdecoding (Hardmeier et al 2012).
Our decodingalgorithm is based on local search instead of dy-namic programming and permits the integration ofdocument-level models with unrestricted depend-encies, so that a model score can be conditioned onarbitrary elements occurring anywhere in the inputdocument or in the translation that is being gen-erated.
In this paper, we present an open-sourceimplementation of this search algorithm.
The de-coder is written in C++ and follows an object-oriented design that makes it easy to extend it withnew feature models, new search operations or dif-ferent types of local search algorithms.
The codeis released under the GNU General Public Licenseand published on Github1 to make it easy for otherresearchers to use it in their own experiments.2 Document-Level Decoding with LocalSearchOur decoder is based on the phrase-based SMTmodel described by Koehn et al(2003) and im-plemented, for example, in the popular Mosesdecoder (Koehn et al 2007).
Translation isperformed by splitting the input sentence intoa number of contiguous word sequences, calledphrases, which are translated into the target lan-guage through a phrase dictionary lookup and op-tionally reordered.
The choice between differenttranslations of an ambiguous source phrase and theordering of the target phrases are guided by a scor-ing function that combines a set of scores takenfrom the phrase table with scores from other mod-els such as an n-gram language model.
The actualtranslation process is realised as a search for thehighest-scoring translation in the space of all thepossible translations that could be generated giventhe models.The decoding approach that is implemented inDocent was first proposed by Hardmeier et al(2012) and is based on local search.
This meansthat it has a state corresponding to a complete, ifpossibly bad, translation of a document at every1https://github.com/chardmeier/docent/wiki193stage of the search progress.
Search proceeds bymaking small changes to the current search state inorder to transform it gradually into a better trans-lation.
This differs from the DP algorithm used inother decoders, which starts with an empty trans-lation and expands it bit by bit.
It is similar toprevious work on phrase-based SMT decoding byLanglais et al(2007), but enables the creation ofdocument-level models, which was not addressedby earlier approaches.Docent currently implements two search al-gorithms that are different generalisations of thehill climbing local search algorithm by Hardmeieret al(2012).
The original hill climbing algorithmstarts with an initial state and generates possiblesuccessor states by randomly applying simple ele-mentary operations to the state.
After each op-eration, the new state is scored and accepted ifits score is better than that of the previous state,else rejected.
Search terminates when the decodercannot find an acceptable successor state after acertain number of attempts, or when a maximumnumber of steps is reached.Simulated annealing is a stochastic variant ofhill climbing that always accepts moves towardsbetter states, but can also accept moves towardslower-scoring states with a certain probability thatdepends on a temperature parameter in order toescape local maxima.
Local beam search gener-alises hill climbing in a different way by keepinga beam of a fixed number of multiple states at anytime and randomly picking a state from the beamto modify at each move.
The original hill climb-ing procedure can be recovered as a special caseof either one of these search algorithms, by call-ing simulated annealing with a fixed temperatureof 0 or local beam search with a beam size of 1.Initial states for the search process can be gen-erated either by selecting a random segmentationwith random translations from the phrase table inmonotonic order, or by running DP beam searchwith sentence-local models as a first pass.
Forthe second option, which generally yields bettersearch results, Docent is linked with the Mosesdecoder and makes direct calls to the DP beamsearch algorithm implemented by Moses.
In addi-tion to these state initialisation procedures, Docentcan save a search state to a disk file which can beloaded again in a subsequent decoding pass.
Thissaves time especially when running repeated ex-periments from the same starting point obtainedby DP search.In order to explore the complete search spaceof phrase-based SMT, the search operations in alocal search decoder must be able to change thephrase translations, the order of the output phrasesand the segmentation of the source sentence intophrases.
The three operations used by Hardmeieret al(2012), change-phrase-translation, reseg-ment and swap-phrases, jointly meet this require-ment and are all implemented in Docent.
Addi-tionally, Docent features three extra operations, allof which affect the target word order: The move-phrases operation moves a phrase to another loca-tion in the sentence.
Unlike swap-phrases, it doesnot require that another phrase be moved in theopposite direction at the same time.
A pair ofoperations called permute-phrases and linearise-phrases can reorder a sequence of phrases into ran-dom order and back into the order correspondingto the source language.Since the search algorithm in Docent isstochastic, repeated runs of the decoder will gen-erally produce different output.
However, the vari-ance of the output is usually small, especiallywhen initialising with a DP search pass, and ittends to be lower than the variance introducedby feature weight tuning (Hardmeier et al 2012;Stymne et al 2013a).3 Available Feature ModelsIn its current version, Docent implements a selec-tion of sentence-local feature models that makesit possible to build a baseline system with a con-figuration comparable to that of a typical Mosesbaseline system.
The published source codealso includes prototype implementations of a fewdocument-level models.
These models should beconsidered work in progress and serve as a demon-stration of the cross-sentence modelling capabilit-ies of the decoder.
They have not yet reached astate of maturity that would make them suitablefor production use.The sentence-level models provided by Docentinclude the phrase table, n-gram language modelsimplemented with the KenLM toolkit (Heafield,2011), an unlexicalised distortion cost model withgeometric decay (Koehn et al 2003) and a wordpenalty cost.
All of these features are designedto be compatible with the corresponding featuresin Moses.
From among the typical set of baselinefeatures in Moses, we have not implemented the194lexicalised distortion model, but this model couldeasily be added if required.
Docent uses the samebinary file format for phrase tables as Moses, sothe same training apparatus can be used.DP-based SMT decoders have a parametercalled distortion limit that limits the difference inword order between the input and the MT out-put.
In DP search, this is formally considered tobe a parameter of the search algorithm because itaffects the algorithmic complexity of the searchby controlling how many translation options mustbe considered at each hypothesis expansion.
Thestochastic search algorithm in Docent does not re-quire this limitation, but it can still be useful be-cause the standard models of SMT do not modellong-distance reordering well.
Docent thereforeincludes a separate indicator feature to indicatea violated distortion limit.
In conjunction with avery large weight, this feature can effectively en-sure that the distortion limit is enforced.
In con-trast with the distortion limit parameter of a DP de-coder, the weight of our distortion limit feature canpotentially be tuned to permit occasional distor-tion limit violations when they contribute to bettertranslations.The document-level models included in Docentinclude a length parity model, a semantic lan-guage model as well as a collection of document-level readability models.
The length parity modelis a proof-of-concept model that ensures that allsentences in a document have either consistentlyodd or consistently even length.
It serves mostly asa template to demonstrate how a simple document-level model can be implemented in the decoder.The semantic language model was originally pro-posed by Hardmeier et al(2012) to improve lex-ical cohesion in a document.
It is a cross-sentencemodel over sequences of content words that arescored based on their similarity in a word vectorspace.
The readability models serve to improvethe readability of the translation by encouragingthe selection of easier and more consistent targetwords.
They are described and demonstrated inmore detail in section 5.Docent can read input files both in the NIST-XML format commonly used to encode docu-ments in MT shared tasks such as NIST or WMTand in the more elaborate MMAX format (M?llerand Strube, 2003).
The MMAX format makesit possible to include a wide range of discourse-level corpus annotations such as coreference links.These annotations can then be accessed by thefeature models.
To allow for additional target-language information such as morphological fea-tures of target words, Docent can handle simpleword-level annotations that are encoded in thephrase table in the same way as target languagefactors in Moses.In order to optimise feature weights we haveadapted the Moses tuning infrastructure to Do-cent.
In this way we can take advantage of all itsfeatures, for instance using different optimisationalgorithms such as MERT (Och, 2003) or PRO(Hopkins and May, 2011), and selective tuning ofa subset of features.
Since document features onlygive meaningful scores on the document level andnot on the sentence level, we naturally performoptimisation on document level, which typicallymeans that we need more data than for the op-timisation of sentence-based decoding.
The res-ults we obtain are relatively stable and competit-ive with sentence-level optimisation of the samemodels (Stymne et al 2013a).4 Implementing Feature ModelsEfficientlyWhile translating a document, the local search de-coder attempts to make a great number of moves.For each move, a score must be computed andtested against the acceptance criterion.
An over-whelming majority of the proposed moves will berejected.
In order to achieve reasonably fast de-coding times, efficient scoring is paramount.
Re-computing the scores of the whole document atevery step would be far too slow for the decoderto be useful.
Fortunately, score computation canbe sped up in two ways.
Knowledge about howthe state to be scored was generated from its pre-decessor helps to limit recomputations to a min-imum, and by adopting a two-step scoring proced-ure that just computes the scores that can be calcu-lated with little effort at first, we need to computethe complete score only if the new state has somechance of being accepted.The scores of SMT feature models can usu-ally be decomposed in some way over parts ofthe document.
The traditional models borrowedfrom sentence-based decoding are necessarily de-composable at the sentence level, and in practice,all common models are designed to meet the con-straints of DP beam search, which ensures thatthey can in fact be decomposed over even smal-195ler sequences of just a few words.
For genuinedocument-level features, this is not the case, buteven these models can often be decomposed insome way, for instance over paragraphs, anaphoriclinks or lexical chains.
To take advantage of thisfact, feature models in Docent always have accessto the previous state and its score and to a list ofthe state modifications that transform the previousstate into the next.
The scores of the new state arecalculated by identifying the parts of a documentthat are affected by the modifications, subtract-ing the old scores of this part from the previousscore and adding the new scores.
This approachto scoring makes feature model implementationa bit more complicated than in DP search, but itgives the feature models full control over how theydecompose a document while still permitting effi-cient decoding.A feature model class in Docent implementsthree methods.
The initDocument method is calledonce per document when decoding starts.
Itstraightforwardly computes the model score forthe entire document from scratch.
When a stateis modified, the decoder first invokes the estim-ateScoreUpdate method.
Rather than calculatingthe new score exactly, this method is only requiredto return an upper bound that reflects the max-imum score that could possibly be achieved by thisstate.
The search algorithm then checks this upperbound against the acceptance criterion.
Only if theupper bound meets the criterion does it call theupdateScore method to calculate the exact score,which is then checked against the acceptance cri-terion again.The motivation for this two-step procedure isthat some models can compute an upper bound ap-proximation much more efficiently than an exactscore.
For any model whose score is a log probab-ility, a value of 0 is a loose upper bound that canbe returned instantly, but in many cases, we can domuch better.
In the case of the n-gram languagemodel, for instance, a more accurate upper boundcan be computed cheaply by subtracting from theold score all log-probabilities of n-grams that areaffected by the state modifications without addingthe scores of the n-grams replacing them in thenew state.
This approximation can be calculatedwithout doing any language model lookups at all.On the other hand, some models like the distor-tion cost or the word penalty are very cheap tocompute, so that the estimateScoreUpdate methodcan simply return the precise score as a tight up-per bound.
If a state gets rejected because of alow score on one of the cheap models, this meanswe will never have to compute the more expensivefeature scores at all.5 Readability: A Case StudyAs a case study we report initial results on howdocument-wide features can be used in Docent inorder to improve the readability of texts by encour-aging simple and consistent terminology (Stymneet al 2013b).
This work is a first step towardsachieving joint SMT and text simplification, withthe final goal of adapting MT to user groups suchas people with reading disabilities.Lexical consistency modelling for SMT hasbeen attempted before.
The suggested approacheshave been limited by the use of sentence-leveldecoders, however, and had to resort to proced-ures like post processing (Carpuat, 2009), multipledecoding runs with frozen counts from previousruns (Ture et al 2012), or cache-based models(Tiedemann, 2010).
In Docent, however, we al-ways have access to a full document translation,which makes it straightforward to include featuresdirectly into the decoder.We implemented four features on the documentlevel.
The first two features are type token ra-tio (TTR) and a reformulation of it, OVIX, whichis less sensitive to text length.
These ratios havebeen related to the ?idea density?
of a text (M?h-lenbock and Kokkinakis, 2009).
We also wantedto encourage consistent translations of words, forwhich we used the Q-value (Del?ger et al 2006),which has been proposed to measure term qual-ity.
We applied it on word level (QW) and phraselevel (QP).
These features need access to the fulltarget document, which we have in Docent.
In ad-dition, we included two sentence-level count fea-tures for long words that have been used to meas-ure the readability of Swedish texts (M?hlenbockand Kokkinakis, 2009).We tested our features on English?Swedishtranslation using the Europarl corpus.
For train-ing we used 1,488,322 sentences.
As test data, weextracted 20 documents with a total of 690 sen-tences.
We used the standard set of baseline fea-tures: 5-gram language model, translation modelwith 5 weights, a word penalty and a distortionpenalty.196Baseline Readability features Commentde ?rade ledam?terna (the honourableMembers)ledam?terna (the members) / ni(you)+ Removal of non-essential wordsp?
ett s?dant s?tt att (in such a waythat)s?
att (so that) + Simplified expressiongemenskapslagstiftningen (thecommunity legislation)gemenskapens lagstiftning (thecommunity?s legislation)+ Shorter words by changing longcompound to genitive constructionV?rldshandelsorganisationen (WorldTrade Organisation)WTO (WTO) ?
Changing long compound toEnglish-based abbreviationhandlingsplanen (the action plan) planen (the plan) ?
Removal of important word?gnat s?rskild uppm?rksamhet ?t (paidparticular attention to)s?rskilt uppm?rksam p?
(particular attentive on)?
Bad grammar because of changedpart of speech and missing verbTable 2: Example translation snippets with commentsFeature BLEU OVIX LIXBaseline 0.243 56.88 51.17TTR 0.243 55.25 51.04OVIX 0.243 54.65 51.00QW 0.242 57.16 51.16QP 0.243 57.07 51.06All 0.235 47.80 49.29Table 1: Results for adding single lexical consist-ency features to DocentTo evaluate our system we used the BLEU score(Papineni et al 2002) together with a set of read-ability metrics, since readability is what we hopedto improve by adding consistency features.
Herewe used OVIX to confirm a direct impact on con-sistency, and LIX (Bj?rnsson, 1968), which is acommon readability measure for Swedish.
Unfor-tunately we do not have access to simplified trans-lated text, so we calculate the MT metrics against astandard reference, which means that simple textswill likely have worse scores than complicatedtexts closer to the reference translation.We tuned the standard features using Moses andMERT, and then added each lexical consistencyfeature with a small weight, using a grid search ap-proach to find values with a small impact.
The res-ults are shown in Table 1.
As can be seen, for in-dividual features the translation quality was main-tained, with small improvements in LIX, and inOVIX for the TTR and OVIX features.
For thecombination we lost a little bit on translation qual-ity, but there was a larger effect on the readabilitymetrics.
When we used larger weights, there wasa bigger impact on the readability metrics, with afurther decrease on MT quality.We also investigated what types of changes thereadability features could lead to.
Table 2 shows asample of translations where the baseline is com-pared to systems with readability features.
Thereare both cases where the readability features helpand cases where they are problematic.
Overall,these examples show that our simple features canhelp achieve some interesting simplifications.There is still much work to do on how to takebest advantage of the possibilities in Docent in or-der to achieve readable texts.
This attempt showsthe feasibility of the approach.
We plan to ex-tend this work for instance by better feature op-timisation, by integrating part-of-speech tags intoour features in order to focus on terms rather thancommon words, and by using simplified texts forevaluation and tuning.6 ConclusionsIn this paper, we have presented Docent, an open-source document-level decoder for phrase-basedSMT released under the GNU General Public Li-cense.
Docent is the first decoder that permits theinclusion of feature models with unrestricted de-pendencies between arbitrary parts of the output,even crossing sentence boundaries.
A number ofresearch groups have recently started to investig-ate the interplay between SMT and discourse-levelphenomena such as pronominal anaphora, verbtense selection and the generation of discourseconnectives.
We expect that the availability of adocument-level decoder will make it substantiallyeasier to leverage discourse information in SMTand make SMT models explore new ground bey-ond the next sentence boundary.ReferencesCarl-Hugo Bj?rnsson.
1968.
L?sbarhet.
Liber, Stock-holm.Marine Carpuat.
2009.
One translation per discourse.In Proceedings of the Workshop on Semantic Evalu-ations: Recent Achievements and Future Directions(SEW-2009), pages 19?27, Boulder, Colorado.197Louise Del?ger, Magnus Merkel, and Pierre Zweigen-baum.
2006.
Enriching medical terminologies: anapproach based on aligned corpora.
In InternationalCongress of the European Federation for MedicalInformatics, pages 747?752, Maastricht, The Neth-erlands.Zhengxian Gong, Min Zhang, Chew Lim Tan, andGuodong Zhou.
2012.
N-gram-based tense modelsfor statistical machine translation.
In Proceedingsof the 2012 Joint Conference on Empirical Meth-ods in Natural Language Processing and Computa-tional Natural Language Learning, pages 276?285,Jeju Island, Korea.Liane Guillou.
2012.
Improving pronoun translationfor statistical machine translation.
In Proceedings ofthe Student Research Workshop at the 13th Confer-ence of the European Chapter of the Association forComputational Linguistics, pages 1?10, Avignon,France.Christian Hardmeier and Marcello Federico.
2010.Modelling pronominal anaphora in statistical ma-chine translation.
In Proceedings of the seventh In-ternational Workshop on Spoken Language Transla-tion (IWSLT), pages 283?289, Paris, France.Christian Hardmeier, Joakim Nivre, and J?rgTiedemann.
2012.
Document-wide decodingfor phrase-based statistical machine translation.In Proceedings of the 2012 Joint Conference onEmpirical Methods in Natural Language Processingand Computational Natural Language Learning,pages 1179?1190, Jeju Island, Korea.Christian Hardmeier.
2012.
Discourse in statisticalmachine translation: A survey and a case study.
Dis-cours, 11.Kenneth Heafield.
2011.
KenLM: faster and smallerlanguage model queries.
In Proceedings of the SixthWorkshop on Statistical Machine Translation, pages187?197, Edinburgh, Scotland.Mark Hopkins and Jonathan May.
2011.
Tuning asranking.
In Proceedings of the 2011 Conferenceon Empirical Methods in Natural Language Pro-cessing, pages 1352?1362, Edinburgh, Scotland.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Pro-ceedings of the 2003 conference of the North Amer-ican chapter of the Association for ComputationalLinguistics on Human Language Technology, pages48?54, Edmonton.Philipp Koehn, Hieu Hoang, Alexandra Birch, et al2007.
Moses: open source toolkit for Statistical Ma-chine Translation.
In Annual meeting of the Associ-ation for Computational Linguistics: Demonstrationsession, pages 177?180, Prague, Czech Republic.Philippe Langlais, Alexandre Patry, and Fabrizio Gotti.2007.
A greedy decoder for phrase-based statist-ical machine translation.
In TMI-2007: Proceedingsof the 11th International Conference on Theoreticaland Methodological Issues in Machine Translation,pages 104?113, Sk?vde, Sweden.Ronan Le Nagard and Philipp Koehn.
2010.
Aidingpronoun translation with co-reference resolution.
InProceedings of the Joint Fifth Workshop on Statist-ical Machine Translation and MetricsMATR, pages252?261, Uppsala, Sweden.Thomas Meyer, Andrei Popescu-Belis, Najeh Hajlaoui,and Andrea Gesmundo.
2012.
Machine translationof labeled discourse connectives.
In Proceedings ofthe Tenth Biennial Conference of the Association forMachine Translation in the Americas (AMTA), SanDiego, California, USA.Katarina M?hlenbock and Sofie Johansson Kokkinakis.2009.
LIX 68 revisited ?
an extended readability.
InProceedings of the Corpus Linguistics Conference,Liverpool, UK.Christoph M?ller and Michael Strube.
2003.
Multi-level annotation in MMAX.
In Proceedings of theFourth SIGdial Workshop on Discourse and Dia-logue, pages 198?207, Sapporo, Japan.Franz Josef Och.
2003.
Minimum error rate training instatistical machine translation.
In Proceedings of the42nd Annual Meeting of the Association for Com-putational Linguistics, pages 160?167, Sapporo, Ja-pan.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: A method for automaticevaluation of machine translation.
In Proceedings ofthe 40th Annual Meeting of the Association for Com-putational Linguistics, pages 311?318, Philadelphia,Pennsylvania, USA.Sara Stymne, Christian Hardmeier, J?rg Tiedemann,and Joakim Nivre.
2013a.
Feature weight optim-ization for discourse-level SMT.
In Proceedings ofthe Workshop on Discourse in Machine Translation(DiscoMT), Sofia, Bulgaria.Sara Stymne, J?rg Tiedemann, Christian Hardmeier,and Joakim Nivre.
2013b.
Statistical machine trans-lation with readability constraints.
In Proceedings ofthe 19th Nordic Conference of Computational Lin-guistics (NODALIDA 2013), pages 375?386, Oslo,Norway.J?rg Tiedemann.
2010.
Context adaptation in stat-istical machine translation using models with ex-ponentially decaying cache.
In Proceedings of theACL 2010 Workshop on Domain Adaptation for Nat-ural Language Processing (DANLP), pages 8?15,Uppsala, Sweden.Ferhan Ture, Douglas W. Oard, and Philip Resnik.2012.
Encouraging consistent translation choices.In Proceedings of the 2012 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics: Human Language Technologies,pages 417?426, Montr?al, Canada.198
