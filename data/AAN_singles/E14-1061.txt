Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 579?587,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsHow to Produce Unseen Teddy Bears:Improved Morphological Processing of Compounds in SMTFabienne Cap, Alexander FraserCIS, University of Munich{cap|fraser}@cis.uni-muenchen.deMarion WellerIMS, University of Stuttgartwellermn@ims.uni-stuttgart.deAoife CahillEducational Testing Serviceacahill@ets.orgAbstractCompounding in morphologically richlanguages is a highly productive processwhich often causes SMT approaches tofail because of unseen words.
We presentan approach for translation into a com-pounding language that splits compoundsinto simple words for training and, dueto an underspecified representation, allowsfor free merging of simple words intocompounds after translation.
In contrast toprevious approaches, we use features pro-jected from the source language to predictcompound mergings.
We integrate our ap-proach into end-to-end SMT and show thatmany compounds matching the referencetranslation are produced which did not ap-pear in the training data.
Additional man-ual evaluations support the usefulness ofgeneralizing compound formation in SMT.1 IntroductionProductive processes like compounding or inflec-tion are problematic for traditional phrase-basedstatistical machine translation (SMT) approaches,because words can only be translated as they haveoccurred in the parallel training data.
As paral-lel training data is limited, it is desirable to ex-tract as much information from it as possible.
Wepresent an approach for compound processing inSMT, translating from English to German, thatsplits compounds prior to training (in order to ac-cess the individual words which together form thecompound) and recombines them after translation.While compound splitting is a well-studied task,compound merging has not received as much at-tention in the past.
We start from Stymne and Can-cedda (2011), who used sequence models to pre-dict compound merging and Fraser et al.
(2012)who, in addition, generalise over German inflec-tion.
Our new contributions are: (i) We projectfeatures from the source language to support com-pound merging predictions.
As the source lan-guage input is fluent, these features are more re-liable than features derived from target languageSMT output.
(ii) We reduce compound parts toan underspecified representation which allows formaximal generalisation.
(iii) We present a detailedmanual evaluation methodology which shows thatwe obtain improved compound translations.We evaluated compound processing both onheld-out split data and in end-to-end SMT.
Weshow that using source language features increasesthe accuracy of compound generation.
Moreover,we find more correct compounds than the base-lines, and a considerable number of these com-pounds are unseen in the training data.
This islargely due to the underspecified representation weare using.
Finally, we show that our approach im-proves upon the previous work.We discuss compound processing in SMT inSection 2, and summarise related work in Sec-tion 3.
In Section 4 we present our method forsplitting compounds and reducing the componentwords to an underspecified representation.
Themerging to obtain German compounds is the sub-ject of Section 5.
We evaluate the accuracy ofcompound prediction on held-out data in Section 6and in end-to-end SMT experiments in Section 7.We conclude in Section 8.2 Dealing with Compounds in SMTIn German, two (or more) single words (usuallynouns or adjectives) are combined to form acompound which is considered a semantic unit.The rightmost part is referred to as the head whileall other parts are called modifiers.
EXAMPLE (1)lists different ways of joining simple words intocompounds: mostly, no modification is required(A) or a filler letter is introduced (B).
More rarely,a letter is deleted (C), or transformed (D).579WerkzeugHandelObstKistefruitboxtradingtool HandelswerkzeugObstkisteWerkzeugkisteObsthandel fruittradingtoolboxKisteWerkzeugObstHandelsplitting trainingsplitting trainingtesting re?combinationtesting re?combinationFigure 1: Compound processing in SMT allows the synthesis of compounds unseen in the training data.EXAMPLE (1)(A) Haus+Boot = Hausboot (?house boat?
)(B) Ort+s+Zeit = Ortszeit (?local time?
)(C) Kirche-e+Turm = Kirchturm (?church tower?
)(D) Kriterium+Liste = Kriterienliste (?criteria list?
)German compounds are highly productive,1andtraditional SMT approaches often fail in the faceof such productivity.
Therefore, special process-ing of compounds is required for translation intoGerman, as many compounds will not (e.g.
Haus-boot, ?house boat?)
or only rarely have been seenin the training data.2In contrast, most compoundsconsist of two (or more) simple words that occurmore frequently in the data than the compound asa whole (e.g.
Haus (7,975) and Boot (162)) and of-ten, these compound parts can be translated 1-to-1 into simple English words.
Figure 1 illustratesthe basic idea of compound processing in SMT:imagine, ?Werkzeug?
(?tool?)
occurred only as amodifier of e.g.
?Kiste?
(?box?)
in the trainingdata, but the test set contains ?tool?
as a simpleword or as the head of a compound.
Splitting com-pounds prior to translation model training enablesbetter access to the component translations and al-lows for a high degree of generalisation.
At test-ing time, the English text is translated into the splitGerman representation, and only afterwards, somesequences of simple words are (re-)combined into(possibly unseen) compounds where appropriate.This merging of compounds is much more chal-lenging than the splitting, as it has to be appliedto disfluent MT output: i.e., compound parts maynot occur in the correct word order and even if theydo, not all sequences of German words that couldform a compound should be merged.3 Related WorkCompound processing for translation into a com-pounding language includes both compound split-1Most newly appearing words in German are compounds.2~30% of the word types and ~77% of the compoundtypes we identified in our training data occurred ?
3 times.ting and merging, we thus report on previous ap-proaches for both of these tasks.In the past, there have been numerous attemptsto split compounds, all improving translation qual-ity when translating from a compounding to a non-compounding language.
Several compound split-ting approaches make use of substring corpus fre-quencies in order to find the optimal split points ofa compound (e.g.
Koehn and Knight (2003), whoallowed only ?(e)s?
as filler letters).
Stymne et al.
(2008) use Koehn and Knight?s technique, includea larger list of possible modifier transformationsand apply POS restrictions on the substrings, whileFritzinger and Fraser (2010) use a morphologicalanalyser to find only linguistically motivated sub-strings.
In contrast, Dyer (2010) presents a lattice-based approach to encode different segmentationsof words (instead of finding the one-best split).More recently, Macherey et al.
(2011) presenteda language-independent unsupervised approach inwhich filler letters and a list of words not to be split(e.g., named entities) are learned using phrase ta-bles and Levenshtein distance.In contrast to splitting, the merging of com-pounds has received much less attention in thepast.
An early approach by Popovi?c et al.
(2006)recombines compounds using a list of compoundsand their parts.
It thus never creates invalid Ger-man compounds, but on the other hand it is limitedto the coverage of the list.
Moreover, in some con-texts a merging in the list may still be wrong, cf.EXAMPLE (3) in Section 5 below.
The approachof Stymne (2009) makes use of a factored model,with a special POS-markup for compound mod-ifiers, derived from the POS of the whole com-pound.
This markup enables sound mergings ofcompound parts after translation if the POS of thecandidate modifier (X-Part) matches the POS ofthe candidate compound head (X): Inflations|N-Part + Rate|N = Inflationsrate|N (?inflation rate?
).In Stymne and Cancedda (2011) the factored ap-580Gas|Traum      8.34Gastraum        3.74Gast|Raum    8.594) Disambiguation.........Amerikanische Medien ...Tim Baumeister besiegt ...Der Gastraum des ...0) Original Text...(S(NP(ADJA Amerikanische) (NN Medien)...))...(S(NP(PN(NE Tim)(NE Baumeister))(VV besiegt)...))...(S(NP(ART Der) (NN Gastraum) (ART des)...))1) Bitpar Parsed Text> amerikanische> Gastraum> BaumeisterBau<NN>Meister<+NN>Baumeister<+NPROP>Gast<NN>Raum<+NN>Gas<NN>Traum<+NN>amerikanisch<+ADJ>3) SMOR Analysisamerikanische Medien ...ADJA NNNETim Baumeister besiegt ...NE VVARTNNARTder Gastraum des ............2) True CasingFigure 2: Compound splitting pipeline 1) The original text is parsed with BITPAR to get unambiguous POS tags,2) The original text is then true-cased using the most frequent casing for each word and BITPAR tags are added,3) All words are analysed with SMOR, analyses are filtered using BITPAR tags (only bold-faced analyses are kept),4) If several splitting options remain, the geometric mean of the word (part) frequencies is used to disambiguate them.proach was extended to make use of a CRF se-quence labeller (Lafferty et al., 2001) in orderto find reasonable merging points.
Besides thewords and their POS, many different target lan-guage frequency features were defined to train theCRF.
This approach can even produce new com-pounds unseen in the training data, provided thatthe modifiers occurred in modifier position of acompound and heads occurred as heads or even assimple words with the same inflectional endings.However, as former compound modifiers were leftwith their filler letters (cf.
?Inflations?
), they cannot be generalised to compound heads or simplewords, nor can inflectional variants of compoundheads or simple words be created (e.g.
if ?Rate?had only been observed in nominative form in thetraining data, the genitive ?Raten?
could not beproduced).
The underspecified representation weare using allows for maximal generalisation overword parts independent of their position of oc-currence or inflectional realisations.
Moreover,their experiments were limited to predicting com-pounds on held-out data; no results were reportedfor using their approach in translation.
In Fraseret al.
(2012) we re-implemented the approach ofStymne and Cancedda (2011), combined it withinflection prediction and applied it to a transla-tion task.
However, compound merging was re-stricted to a list of compounds and parts.
Ourpresent work facilitates more independent com-bination.
Toutanova et al.
(2008) and Weller etal.
(2013) used source language features for targetlanguage inflection, but to our knowledge, none ofthese works applied source language features forcompound merging.4 Step 1: Underspecified RepresentationIn order to enhance translation model accuracy,it is reasonable to have similar degrees of mor-phological richness between source and target lan-guage.
We thus reduce the German target lan-guage training data to an underspecified represen-tation: we split compounds, and lemmatise allwords (except verbs).
All occurrences of simplewords, former compound modifiers or heads havethe same representation and can thus be freelymerged into ?old?
and ?new?
compounds aftertranslation, cf.
Figure 1 above.
So that we can laterpredict the merging of simple words into com-pounds and the inflection of the words, we storeall of the morphological information stripped fromthe underspecified representation.Note that erroneous over-splitting might makethe correct merging of compounds difficult3(or even impossible), due to the number ofcorrect decisions required.
For example, itrequires only 1 correct prediction to recom-bine ?Niederschlag|Menge?
into ?Niederschlags-menge?
(?amount of precipitation?)
but 3 forthe wrong split into ?nie|der|Schlag|Menge?(?never|the|hit|amount?).
We use the compoundsplitter of Fritzinger and Fraser (2010), who haveshown that using a rule-based morphological anal-yser (SMOR, Schmid et al.
(2004)) drastically re-duced the number of erroneous splits when com-pared to the frequency-based approach of Koehnand Knight (2003).
However, we adapted it towork on tokens: some words can, depending ontheir context, either be interpreted as named enti-ties or common nouns, e.g., ?Dinkelacker?
(a Ger-man beer brand or ?spelt|field?
).4We parsed thetraining data and use the parser?s decisions to iden-tify proper names, see ?Baumeister?
in Figure 2.After splitting, we use SMOR to reduce words tolemmas, keeping morphological features like gen-der or number, and stripping features like case, asillustrated for ??Olexporteure?
(?oil exporters?
):3In contrast, they may not hurt translation quality in theother direction, where phrase-based SMT is likely to learnthe split words as a phrase and thus recover from that error.4Note that Macherey et al.
(2011) blocked splitting ofwords which can be used as named entities, independent ofcontext, which is less general than our solution.581No.
Feature Description ExampleExperimentSC T TR1SC surface form of the word string: Arbeit<+NN><Fem><Sg> X X2SC main part of speech of the word (from the parser) string: +NN X X3SC word occurs in a bigram with the next word frequency: 0 X X4SC word combined to a compound with the next word frequency: 10,000 X X X5SC word occurs in modifier position of a compound frequency: 100,000 X X6SC word occurs in a head position of a compound frequency: 10,000 X X7SC word occurs in modifier position vs. simplex string: P>W (P= 5SC, W= 100,000) X8SC word occurs in head position vs. simplex string: S<W (S= 6SC, W= 100,000) X7SC+ word occurs in modifier position vs. simplex ratio: 10 (10**ceil(log10(5SC/W))) X X8SC+ word occurs in head position vs. simplex ratio: 1 (10**ceil(log10(6SC/W))) X X9N different head types the word can combine with number: 10,000 X XTable 1: Target language CRF features for compound merging.
SC = features taken from Stymne and Cancedda(2011), SC+ = improved versions, N = new feature.
Experiments: SC = re-implementation of Stymne and Cancedda (2011),T= use full Target feature set, TR = use Target features, but only a Reduced set.EXAMPLE (2)?l<+NN><Neut><Sg> Exporteur<+NN> <Masc><Pl>?l<NN>Exporteur<+NN><Masc><Nom><Pl>compoundheadmodifierWhile the former compound head (?Exporteure?
)automatically inherits all morphological featuresof the compound as a whole, the features of themodifier need to be derived from SMOR in an ad-ditional step.
We need to ensure that the repre-sentation of the modifier is identical to the sameword when it occurs independently in order to ob-tain full generalisation over compound parts.5 Step 2: Compound MergingAfter translation from English into the underspec-ified German representation, post-processing is re-quired to transform the output back into fluent,morphologically fully specified German.
First,compounds need to be merged where appropriate,e.g., ?Hausboote?
(?house boats?
):Haus<+NN><Neut><Sg> + Boot<+NN><Neut><Pl>?
Haus<NN>Boot<+NN><Neut><Pl> (merged)and second, all words need to be inflected:Haus<NN>Boot<+NN><Neut><Acc><Pl>?
Hausbooten (inflected)5.1 Target Language FeaturesTo decide which words should be combined, wefollow Stymne and Cancedda (2011) who usedCRFs for this task.
The features we derived fromthe target language to train CRF models are listedin Table 1.
We adapted features No.
1-8 fromStymne and Cancedda (2011).
Then, we modi-fied two features (7+8) and created a new featureindicating the productivity of a modifier (9N).5.2 Projecting Source Language FeaturesWe also use new features derived from the Englishsource language input, which is coherent and flu-ent.
This makes features derived from it more reli-able than the target language features derived fromdisfluent SMT output.
Moreover, source languagefeatures might support or block merging decisionsin unclear cases, i.e., where target language fre-quencies are not helpful, either because they arevery low or they have roughly equal frequency dis-tributions when occurring in a compound (as mod-ifier or head) vs. as a simple word.In Table 2, we list three types of features:1.
Syntactic features: different English nounphrase patterns that are aligned to Germancompound candidate words (cf.
10E-13E)2.
The POS tag of the English word (cf.
14E)3.
Alignment features, derived from wordalignments (cf.
15E-18E)The examples given in Table 2 (10E-13E) showthat English compounds often have 1-to-1 corre-spondences to the parts of a German compound.Knowing that two consecutive German simplewords are aligned to two English words of thesame noun phrase is a strong indicator that theGerman words should be merged:EXAMPLE (3)should be merged:ein erh?ohtes verkehrs aufkommen sorgt f?ur chaos?an increased traffic volume causes chaos?(S...
(NP(DT An)(VN increased)(NN traffic)(NN volume))..)))should not be merged:f?ur die finanzierung des verkehrs aufkommen?pay for the financing of transport?
(VP(V pay)(PP(IN for)(NP(NP(DT the)(NN financing))(PP(IN of)(NP(NN transport)..))In the compound reading of ?verkehr + aufkom-men?, the English parse structure indicates thatthe words aligned to ?verkehr?
(?traffic?)
and582No.
Feature Description Type10Eword and next word are aligned from a noun phrase in the English source sentence:(NP(NN traffic)(NN accident))?
Verkehr (?traffic?)
+ Unfall (?accident?
)true/false11Eword and next word are aligned from a gerund construction in the English source sentence:(NP(VBG developing)(NNS nations))?
Entwicklung (?development?)
+ L?ander (?countries?
)true/false12Eword and next word are aligned from a genitive construction in the English source sentence:(NP(NP(DT the)(NN end))(PP(IN of)(NP(DT the)(NN year))?
Jahr (?year?)
+ Ende(?end?
)true/false13Eword and next word are aligned from an adjective noun construction in the English source sentence:(NP (ADJ protective)(NNS measures))?
Schutz (?protection?)
+ Ma?nahmen (?measures?
)true/false14E print the POS of the corresponding aligned English word string15Eword and next word are aligned 1-to-1 from the same word in the English source sentence, e.g.,beef??Rind(?cow?)Fleisch(?meat?
)true/false16E like 15E, but the English word contains a dash, e.g., Nobel ?
Prize??Nobel(?Nobel?)Preis(?prize?
)true/false17E like 15E, but also considering 1-to-n and n-to-1 links true/false18E like 16E, but also considering 1-to-n and n-to-1 links true/falseTable 2: List of new source language CRF features for compound merging.?aufkommen?
(?volume?
), are both nouns andpart of one common noun phrase, which is a strongindicator that the two words should be mergedin German.
In contrast, the syntactic relation-ship between ?pay?
(aligned to ?aufkommen?
)and ?transport?
(aligned to ?verkehr?)
is more dis-tant5: merging is not indicated.We also use the POS of the English words tolearn (un)usual combinations of POS, indepen-dent of their exact syntactic structure (14E).
Re-consider EXAMPLE (3): NN+NN is a more com-mon POS pair for compounds than V+NN.Finally, the alignment features (15E-18E) pro-mote the merging into compounds whose align-ments indicate that they should not have been splitin the first place (e.g., Rindfleisch, 15E).5.3 Compound Generation and InflectionSo far, we reported on how to decide which sim-ple words are to be merged into compounds, butnot how to recombine them.
Recall from EXAM-PLE (1) that the modifier of a compound some-times needs to be transformed, before it can becombined with the head word (or next modifier),e.g., ?Ort?+?Zeit?
= ?Ortszeit?
(?local time?
).We use SMOR to generate compounds from acombination of simple words.
This allows us tocreate compounds with modifiers that never oc-curred as such in the training data.
Imagine that?Ort?
occurred only as compound head or as asingle word in the training data.
Using SMOR, weare still able to create the correct form of the mod-ifier, including the required filler letter: ?Orts?.This ability distinguishes our approach from pre-5Note that ?f?ur etwas aufkommen?
(lit.
?for sth.
arise?,idiom.
: ?to pay for sth.?)
is an idiomatic expression.vious approaches: Stymne and Cancedda (2011)do not reduce modifiers to their base forms6(theycan only create new compounds when the modifieroccurred as such in the training data) and Fraser etal.
(2012) use a list for merging.Finally, we use the system described in Fraseret al.
(2012) to inflect the entire text.6 Accuracy of Compound PredictionWe trained CRF models on the parallel trainingdata (~40 million words)7of the EACL 2009workshop on statistical machine translation8us-ing different feature (sub)sets, cf.
the ?Exper-iment?
column in Table 1 above.
We exam-ined the reliability of the CRF compound predic-tion models by applying them to held-out data:1. split the German wmt2009 tuning data set2.
remember compound split points3.
predict merging with CRF models4.
combine predicted words into compounds5.
calculate f-scores on how properly thecompounds were mergedTable 3 lists the CRF models we trained, togetherwith their compound merging accuracies on held-out data.
It can be seen that using more features(SC?T?ST) is favourable in terms of precisionand overall accuracy and the positive impact of us-ing source language features is clearer when onlyreduced feature sets are used (TR vs. STR).However, these accuracies only somewhat cor-relate with SMT performance: while being trainedand tested on clean, fluent German language, the6They account for modifier transformations by using char-acter n-gram features (cf.EXAMPLE (1)).7However, target language feature frequencies are derivedfrom the monolingual training data, ~146 million words.8http://www.statmt.org/wmt09583exp to be all correct wrong wrong not mergingprecision recall f-scoremerged merged merged merged merged wrongSC 1,047 997 921 73 121 3 92.38% 88.13% 90.21%T 1,047 979 916 59 128 4 93.56% 87.40% 90.38%ST 1,047 976 917 55 126 4 93.95% 87.58% 90.66%TR 1,047 893 836 52 204 5 93.62% 80.00% 86.27%STR 1,047 930 866 58 172 6 93.12% 82.95% 87.74%Table 3: Compound production accuracies of CRF models on held-out data: SC: re-implementation of Stymneand Cancedda (2011); T: all target language features, including a new one (cf.
Table 1); ST = all Source and Target languagefeatures; TR: only a reduced set of target language features; STR: TR, plus all source language features given in Table 2.exp BLEU SCORES #compounds foundmert.log BLEU RTS all ref new new*RAW 14.88 14.25 1.0054 646 175 n.a.
n.a.UNSPLIT 15.86 14.74 0.9964 661 185 n.a.
n.a.SC 15.44 14.45 0.9870 882 241 47 8T 15.56 14.32 0.9634 845 251 47 8ST 15.33 14.51 0.9760 820 248 46 9TR 15.24 14.26 0.9710 753 234 44 5STR 15.37 14.61 0.9884 758 239 43 7#compounds in reference text: 1,105 1,105 396 193Table 4: SMT results.
Tuning scores (mert.log) are on merged but uninflected data (except RAW).RTS: length ratio; all: #compounds produced; ref: reference matches; new: unknown to parallel data; new*: unknown totarget language data.
bold face indicates statistical significance wrt.
the RAW baseline, SC, T and TR.models will later be applied to disfluent SMT out-put and might thus lead to different results there.Stymne and Cancedda (2011) dealt with this bynoisifying the CRF training data: they translatedthe whole data set using an SMT system that wastrained on the same data set.
This way, the train-ing data was less fluent than in its original format,but still of higher quality than SMT output of un-seen data.
In contrast, we left the training data asit was, but strongly reduced the feature set for CRFmodel training (e.g., no more use of surface wordsand POS tags, cf.
TR and STR in Table 3) instead.7 Translation PerformanceWe integrated our compound processing pipelineinto an end-to-end SMT system.
Models weretrained with the default settings of the Moses SMTtoolkit, v1.0 (Koehn et al., 2007) using the datafrom the EACL 2009 workshop on statistical ma-chine translation.
All compound processing sys-tems are trained and tuned identically, except us-ing different CRF models for compound predic-tion.
All training data was split and reducedto the underspecified representation described inSection 4.
We used KenLM (Heafield, 2011) withSRILM (Stolcke, 2002) to train a 5-gram languagemodel based on all available target language train-ing data.
For tuning, we used batch-mira with ?-safe-hope?
(Cherry and Foster, 2012) and ran itseparately for every experiment.
We integrated theCRF-based merging of compounds into each itera-tion of tuning and scored each output with respectto an unsplit and lemmatised version of the tuningreference.
Testing consists of:1. translation into the split, underspecifiedGerman representation2.
compound merging using CRF modelsto predict recombination points3.
inflection of all words7.1 SMT ResultsWe use 1,025 sentences for tuning and 1,026 sen-tences for testing.
The results are given in Table 4.We calculate BLEU scores (Papineni et al., 2002)and compare our systems to a RAW baseline (builtfollowing the instructions of the shared task) and abaseline very similar to Fraser et al.
(2012), usinga lemmatised representation of words for decod-ing, re-inflecting them after translation, but with-out compound processing (UNSPLIT).
Table 4shows that only UNSPLIT and STR (source lan-guage and a reduced set of target language fea-tures) are significantly9improving over the RAWbaseline.
They also significantly outperform allother systems, except ST (full source and targetlanguage feature set).
The difference between STR(14.61) and the UNSPLIT baseline (14.74) is notstatistically significant.9We used pair-wise bootstrap resampling with sample size1000 and p-value 0.05, from: http://www.ark.cs.cmu.edu/MT584group ID example reference english UNSPLIT STRlexically 1a: perfect match Inflationsrate Inflationsrate inflation rate 185 239matches 1b: inflection wrong Rohstoffpreisen Rohstoffpreise raw material prices 40 44the 2a: merging wrong Anwaltsbewegung Anw?altebewegung lawyers movement 5 9reference 2b: no merging Polizei Chef Polizeichef police chief 101 54correct 3a: compound Zentralbanken Notenbank central banks 92 171translation 3b: no compound pflanzliche?Ole Speise?ol vegetable oils 345 291wrong 4a: compound Haushaltsdefizite Staatshaushalts state budget 12 42translation 4b: no compound Ansporn Linien Nebenlinien spur lines 325 255Total number of compounds in reference text: 1,105 1,105Table 5: Groups for detailed manual compound evaluation and results for UNSPLIT and STR.reference English source UNSPLIT baseline STRTeddyb?aren teddy bear 4bTeddy tragen1aTeddyb?aren(Teddy, to bear) (teddy bear)Emissionsreduktion emissions reduction 3bEmissionen Reduzierung3aEmissionsverringerung(emissions, reducing) (emission decrease)Geldstrafe fine 4bsch?onen3aBu?geld(fine/nice) (monetary fine)Tischtennis table tennis 2bTisch Tennis4aSpieltischtennis(table, tennis) (play table tennis)Kreditkartenmarkt credit-card market 2bKreditkarte Markt4aKreditmarkt(credit-card, market) (credit market)Rotationstempo rotation rate 2bTempo Rotation4aTemporotation(rate, rotation) (rate rotation)Table 6: Examples of the detailed manual compound analysis for UNSPLIT and STR.Compound processing leads to improvements atthe level of unigrams and as BLEU is dominatedby four-gram precision and length penalty, it doesnot adequately reflect compound related improve-ments.
We thus calculated the number of com-pounds matching the reference for each experi-ment and verified whether these were known tothe training data.
The numbers in Table 4 showthat all compound processing systems outperformboth baselines in terms of finding more exact refer-ence matches and also more compounds unknownto the training data.
Note that STR finds less ref-erence matches than e.g.
T or ST, but it also pro-duces less compounds overall, i.e.
it is more pre-cise when producing compounds.However, as compounds that are correctly com-bined but poorly inflected are not counted, this isonly a lower bound on true compounding perfor-mance.
We thus performed two additional manualevaluations and show that the quality of the com-pounds (Section 7.2), and the human perception oftranslation quality is improving (Section 7.3).7.2 Detailed Evaluation of CompoundsThis evaluation focuses on how compounds in thethe reference text have been translated.10We:10In another evaluation, we investigated the 519 com-pounds that our system produced but which did not matchthe reference: 367 were correct translations of the English,1.
manually identify compounds in Germanreference text (1,105 found)2. manually perform word alignment of thesecompounds to the English source text3.
project these English counterparts of com-pounds in the reference text to the decodedtext using the ??print-alignment-info?
flag4.
manually annotate the resulting tuples, us-ing the categories given in Table 5The results are given in the two rightmost columnsof Table 5: besides a higher number of referencematches (cf.
row 1a), STR overall produces morecompounds than the UNSPLIT baseline, cf.
rows2a, 3a and 4a.
Indirectly, this can also be seen fromthe low numbers of STR in category 2b), wherethe UNSPLIT baseline produces much more (101vs.
54) translations that lexically match the refer-ence without being a compound.
While the 171compounds of STR of category 3a) show that oursystem produces many compounds that are correcttranslations of the English, even though not match-ing the reference (and thus not credited by BLEU),the compounds of categories 2a) and 4a) containexamples where we either fail to reproduce thecorrect compound or over-generate compounds.We give some examples in Table 6: for ?teddybear?, the correct German word ?Teddyb?aren?
is87 contained erroneous lexemes and 65 were over-mergings.585missing in the parallel training data and insteadof ?B?ar?
(?bear?
), the baseline selected ?tragen?
(?to bear?).
Extracting all words containing thesubstring ?b?ar?
(?bear?)
from the original paralleltraining data and from its underspecified splitversion demonstrates that our approach is ableto access all occurrences of the word.
This leadsto higher frequency counts and thus enhancesthe probabilities for correct translations.
We cangeneralise over 18 different word types containing?bear?
(e.g.
?polar bears?, ?brown bears?, ?bearskin?, ?bear fur?)
to obtain only 2:occurrences in raw training data: B?ar (19), B?aren(26), B?arendienst (42), B?arenfarmen (1), B?arenfell (2),B?arengalle(1), B?arenhaut (1), B?arenmarkt (1), Braunb?ar(1), Braunb?aren (3), Braunb?arengebiete (1), Braunb?ar-Population (1), Eisb?aren(18), Eisb?arenpopulation (2),Eisb?arenpopulationen (1), Schwarzb?ar (1), Schwarzb?aren (1)?b?ar?
occurring in underspecified split data:B?ar<+NN><Masc><Sg> (94)B?ar<+NN><Masc><Pl> (29)?Emissionsverringerung?
(cf.
Table 6) is a typ-ical example of group 3a): a correctly translatedcompound that does not lexically match the ref-erence, but which is semantically very similar tothe reference.
The same applies for ?Bu?geld?,a synonym of ?Geldstrafe?, for which the UN-SPLIT baseline selected ?sch?onen?
(?fine, nice?)instead.
Consider also the wrong compound pro-ductions, e.g.
?Tischtennis?
is combined withthe verb ?spielen?
(?to play?)
into ?Spieltischten-nis?.
In contrast, ?Kreditmarkt?
dropped the mid-dle part ?Karte?
(?card?
), and in the case of ?Tem-porotation?, the head and modifier of the com-pound are switched.7.3 Human perception of translation qualityWe presented sentences of the UNSPLIT baselineand of STR in random order to two native speak-ers of German and asked them to rank the sen-tences according to preference.
In order to pre-vent them from being biased towards compound-bearing sentences, we asked them to select sen-tences based on their native intuition, without re-vealing our focus on compound processing.Sentences were selected based on source lan-guage sentence length: 10-15 words (178 sen-tences), of which either the reference or oursystem had to contain a compound (95 sen-tences).
After removing duplicates, we ended upwith 84 sentences to be annotated in two subse-(a) Fluency: without reference sentence?
= 0.3631person 1STR UNSPLIT equalperson2STR 24 6 7 37UNSPLIT 5 16 9 30equal 6 2 9 1735 24 25 84(b) Adequacy: with reference sentence?
= 0.4948person 1STR UNSPLIT equalperson2STR 23 4 5 32UNSPLIT 4 21 7 32equal 5 3 12 2032 28 24 84Table 7: Human perception of translation quality.quent passes: first, without being given the refer-ence sentence (approximating fluency), then, withthe reference sentence (approximating adequacy).The results are given in Table 7.
Both annotatorspreferred more sentences of our system overall,but the difference is clearer for the fluency task.8 ConclusionCompounds require special attention in SMT, es-pecially when translating into a compounding lan-guage.
Compared with the baselines, all of our ex-periments that included compound processing pro-duced not only many more compounds matchingthe reference exactly, but also many compoundsthat did not occur in the training data.
Takinga closer look, we found that some of these newcompounds could only be produced due to the un-derspecified representation we are using, which al-lows us to generalise over occurrences of simplewords, compound modifiers and heads.
Moreover,we demonstrated that features derived from thesource language are a valuable source of informa-tion for compound prediction: experiments weresignificantly better compared with contrastive ex-periments without these features.
Additional man-ual evaluations showed that compound processingleads to improved translations where the improve-ment is not captured by BLEU.AcknowledgementsThis work was supported by Deutsche For-schungsgemeinschaft grants Models of Mor-phosyntax for Statistical Machine Translation(Phase 2) and Distributional Approaches to Se-mantic Relatedness.
We thank the anonymous re-viewers for their comments and the annotators.586ReferencesColin Cherry and George Foster.
2012.
Batch Tun-ing Strategies for Statistical Machine Translation.
InHLT-NAACL?12: Proceedings of the Human Lan-guage Technology Conference of the North Ameri-can Chapter of the Association for ComputationalLinguistics, volume 12, pages 34?35.
Associationfor Computational Linguistics.Chris Dyer.
2010.
A Formal Model of Ambiguity andits Applications in Machine Translation.
Phd disser-tation, University of Maryland, USA.Alexander Fraser, Marion Weller, Aoife Cahill, and Fa-bienne Cap.
2012.
Modeling Inflection and WordFormation in SMT.
In EACL?12: Proceedings of the13th Conference of the European Chapter of the As-sociation for Computational Linguistics, pages 664?674.
Association for Computational Linguistics.Fabienne Fritzinger and Alexander Fraser.
2010.
Howto Avoid Burning Ducks: Combining LinguisticAnalysis and Corpus Statistics for German Com-pound Processing.
In Proceedings of the Fifth Work-shop on Statistical Machine Translation, pages 224?234.
Association for Computational Linguistics.Kenneth Heafield.
2011.
KenLM: Faster and SmallerLanguage Model Queries.
In Proceedings of theSixth Workshop on Statistical Machine Translation,Edinburgh, UK, July.
Association for ComputationalLinguistics.Philipp Koehn and Kevin Knight.
2003.
EmpiricalMethods for Compound Splitting.
In EACL ?03:Proceedings of the 10th Conference of the EuropeanChapter of the Association for Computational Lin-guistics, pages 187?193, Morristown, NJ, USA.
As-sociation for Computational Linguistics.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondrej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: OpenSource Toolkit for Statistical Machine Translation.In ACL?07: Proceedings of the 45th Annual Meet-ing of the Association for Computational Linguis-tics, Demonstration Session, pages 177?180.
Asso-ciation for Computational Linguistics.John Lafferty, Andrew McCallum, and FernandoPereira.
2001.
Conditional Random Fields: Prob-abilistic Models for Segmenting and Labeling Se-quence Data.
In ICML?01: Proceedings of the 18thInternational Conference on Machine Learning.Klaus Macherey, Andrew M. Dai, David Talbot,Ashok C. Popat, and Franz Och.
2011.
Language-independent Compound Splitting with Morpholog-ical Operations.
In ACL ?11: Proceedings of the49th annual meeting of the Association for Compu-tational Linguistics, pages 1395?1404.
Associationfor Computational Linguistics.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: A Method for AutomaticEvaluation of Machine Translation.
In ACL?02:Proceedings of the 40th Annual Meeting of the As-sociation for Computational Linguistics, pages 311?318.
Association for Computational Linguistics.Maja Popovi?c, Daniel Stein, and Hermann Ney.
2006.Statistical Machine Translation of German Com-pound Words.
In FinTAL?06: Proceedings of the5th International Conference on Natural LanguageProcessing, pages 616?624.
Springer Verlag.Helmut Schmid, Arne Fitschen, and Ulrich Heid.2004.
SMOR: A German Computational Morphol-ogy Covering Derivation, Composition and Inflec-tion.
In LREC ?04: Proceedings of the 4th Confer-ence on Language Resources and Evaluation, pages1263?1266.Andreas Stolcke.
2002.
SRILM ?
an Extensible Lan-guage Modelling Toolkit.
In ICSLN?02: Proceed-ings of the international conference on spoken lan-guage processing, pages 901?904.Sara Stymne and Nicola Cancedda.
2011.
ProductiveGeneration of Compound Words in Statistical Ma-chine Translation.
In EMNLP?11: Proceedings ofthe 6th Workshop on Statistical Machine Transla-tion and Metrics MATR of the conference on Em-pirical Methods in Natural Language Processing,pages 250?260.
Association for Computational Lin-guistics.Sara Stymne, Maria Holmqvist, and Lars Ahrenberg.2008.
Effects of Morphological Analysis in Transla-tion between German and English.
In ACL?08: Pro-ceedings of the 3rd workshop on statistical machinetranslation of the 46th annual meeting of the Associ-ation for Compuational Linguistics, pages 135?138.Association for Computational Linguistics,.Sara Stymne.
2009.
A Comparison of Merging Strate-gies for Translation of German Compounds.
InEACL ?09: Proceedings of the Student ResearchWorkshop of the 12th conference of the EuropeanChapter of the Association for Computational Lin-guistics, pages 61?69.
Association for Computa-tional Linguistics.Kristina Toutanova, Hisami Suzuki, and Achim Ruopp.2008.
Applying Morphology Generation Models toMachine Translation.
In ACL?08: Proceedings ofthe 46th Annual Meeting of the Association for Com-putational Linguistics: Human Language Technolo-gies, pages 514?522.
Association for ComputationalLinguistics.Marion Weller, Alexander Fraser, and SabineSchulte im Walde.
2013.
Using Subcatego-rization Knowledge to Improve Case Prediction forTranslation to German.
In ACL?13: Proceedingsof the 51st Annual Meeting of the Associationfor Computational Linguistics, pages 593?603.Association for Computational Linguistics.587
