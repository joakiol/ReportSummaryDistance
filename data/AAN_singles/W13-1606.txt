Proceedings of the 4th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 38?45,Atlanta, Georgia, 14 June 2013. c?2013 Association for Computational LinguisticsUsing PU-Learning to Detect Deceptive Opinion SpamDonato Herna?ndez Fusilier1,2Rafael Guzma?n CabreraDivisio?n de Ingenier?
?asCampus Irapuato-Salamanca.1Universidad de GuanajuatoMexico.
{donato,guzmanc}@ugto.mxManuel Montes-y-Go?mezLaboratorio de Tecnolog?
?asdel Lenguaje.Instituto Nacional deAstrof?
?sica, O?ptica y Electro?nica.Mexico.mmontesg@inaoep.mxPaolo RossoNatural LanguageEngineering Lab., ELiRF.2Universitat Polite`cnica deVale`nciaSpain.prosso@dsic.upv.esAbstractNowadays a large number of opinion reviewsare posted on the Web.
Such reviews are a veryimportant source of information for customersand companies.
The former rely more thanever on online reviews to make their purchasedecisions and the latter to respond promptlyto their clients?
expectations.
Due to the eco-nomic importance of these reviews there is agrowing trend to incorporate spam on suchsites, and, as a consequence, to develop meth-ods for opinion spam detection.
In this paperwe focus on the detection of deceptive opin-ion spam, which consists of fictitious opinionsthat have been deliberately written to soundauthentic, in order to deceive the consumers.In particular we propose a method based onthe PU-learning approach which learns onlyfrom a few positive examples and a set of un-labeled data.
Evaluation results in a corpus ofhotel reviews demonstrate the appropriatenessof the proposed method for real applicationssince it reached a f-measure of 0.84 in the de-tection of deceptive opinions using only 100positive examples for training.1 IntroductionThe Web is the greatest repository of digital infor-mation and communication platform ever invented.People around the world widely use it to interactwith each other as well as to express opinions andfeelings on different issues and topics.
With the in-creasing availability of online review sites and blogs,costumers rely more than ever on online reviewsto make their purchase decisions and businessesto respond promptly to their clients?
expectations.It is not surprising that opinion mining technolo-gies have been witnessed a great interest in recentyears (Zhou et al 2008; Mihalcea and Strapparava,2009).
Research in this field has been mainly ori-ented to problems such as opinion extraction (Liu B.,2012) and polarity classification (Reyes and Rosso.,2012).
However, because of the current trend aboutthe growing number of online reviews that are fakeor paid by companies to promote their products ordamage the reputation of competitors, the automaticdetection of opinion spam has emerged as a highlyrelevant research topic (Jindal et al 2010; Jindaland Liu, 2008; Lau et al 2011; Wu et al 2010;Ott et al 2011; Sihong et al 2012).Detecting opinion spam is a very challengingproblem since opinions expressed in the Web aretypically short texts, written by unknown people us-ing different styles and for different purposes.
Opin-ion spam has many forms, e.g., fake reviews, fakecomments, fake blogs, fake social network postingsand deceptive texts.
Opinion spam reviews may bedetected by methods that seek for duplicate reviews(Jindal and Liu, 2008), however, this kind of opinionspam only represents a small percentage of the opin-ions from review sites.
In this paper we focus ona potentially more insidious type of opinion spam,namely, deceptive opinion spam, which consists offictitious opinions that have been deliberately writ-ten to sound authentic, in order to deceive the con-sumers.The detection of deceptive opinion spam has beentraditionally solved by means of supervised textclassification techniques (Ott et al 2011).
These38techniques have demonstrated to be very robustif they are trained using large sets of labeled in-stances from both classes, deceptive opinions (pos-itive instances) and truthful opinions (negative ex-amples).
Nevertheless, in real application scenariosit is very difficult to construct such large training setsand, moreover, it is almost impossible to determinethe authenticity of the opinions (Mukherjee et al2011).
In order to meet this restriction we proposea method that learns only from a few positive exam-ples and a set of unlabeled data.
In particular, wepropose applying the PU-Learning approach (Liu etal., 2002; Liu et al 2003) to detect deceptive opin-ion spam.The evaluation of the proposed method was car-ried out using a corpus of hotel reviews under dif-ferent training conditions.
The results are encourag-ing; they show the appropriateness of the proposedmethod for being used in real opinion spam detec-tion applications.
It reached a f-measure of 0.84 inthe detection of deceptive opinions using only 100positive examples, greatly outperforming the effec-tiveness of the traditional supervised approach andthe one-class SVM model.The rest of the paper is organized as follows.
Sec-tion 2 presents some related works in the field ofopinion spam detection.
Section 3 describes ouradaptation of the PU-Learning approach to the taskof opinion spam detection.
Section 4 presents theexperimental results and discusses its advantagesand disadvantages.
Finally, Section 5 indicates thecontributions of the paper and provides some futurework directions.2 Related WorkThe detection of spam in the Web has been mainlyapproached as a binary classification problem (spamvs.
non-spam).
It has been traditionally studied inthe context of e-mail (Drucker et al 2002), and webpages (Gyongyi et al 2004; Ntoulas et al 2006).The detection of opinion spam, i.e., the identifica-tion of fake reviews that try to deliberately misleadhuman readers, is just another face of the same prob-lem (Lau et al 2011).
Nevertheless, the construc-tion of automatic detection methods for this taskis more complex than for the others since manu-ally gathering labeled reviews ?particularly truthfulopinions?
is very hard, if not impossible (Mukher-jee et al 2011).One of the first works regarding the detection ofopinion spam reviews was proposed by (Jindal andLiu, 2008).
He proposed detecting opinion spam byidentifying duplicate content.
Although this methodshowed good precision in a review data set fromAmazon1, it has the disadvantage of under detect-ing original fake reviews.
It is well known thatspammers modify or paraphrase their own reviewsto avoid being detected by automatic tools.In (Wu et al 2010), the authors present a methodto detect hotels which are more likely to be involvedin spamming.
They proposed a number of criteriathat might be indicative of suspicious reviews andevaluated alternative methods for integrating thesecriteria to produce a suspiciousness ranking.
Theircriteria mainly derive from characteristics of the net-work of reviewers and also from the impact and rat-ings of reviews.
It is worth mentioning that they didnot take advantage of reviews?
content for their anal-ysis.Ott et al(2011) constructed a classifier to dis-tinguish between deceptive and truthful reviews.
Inorder to train their classifier they considered certaintypes of near duplicates reviews as positive (decep-tive) training data and the rest as the negative (truth-ful) training data.
The review spam detection wasdone using different stylistic, syntactical and lexicalfeatures as well as using SVM as base classifier.In a recent work, Sihong et al(2012) demon-strated that a high correlation between the increasein the volume of (singleton) reviews and a sharp in-crease or decrease in the ratings is a clear signal thatthe rating is manipulated by possible spam reviews.Supported by this observation they proposed a spamdetection method based on time series pattern dis-covery.The method proposed in this paper is similar toOtt?s et almethod in the sense that it also aimsto automatically identify deceptive and truthful re-views.
However, theirs shows a key problem: itdepends on the availability of labeled negative in-stances which are difficult to obtain, and that causestraditional text classification techniques to be inef-fective for real application scenarios.
In contrast,1http://www.Amazon.com39our method is specially suited for this applicationsince it builds accurate two-class classifiers withonly positive and unlabeled examples, but not neg-ative examples.
In particular we propose using thePU-Learning approach (Liu et al 2002; Liu et al2003) for opinion spam detection.
To the best ofour knowledge this is the first time that this tech-nique, or any one-class classification approach, hasbeen applied to this task.
In (Ferretti et al 2012)PU-learning was successfully used in the task ofWikipedia flaw detection2.3 PU-Learning for opinion spam detectionPU-learning is a partially supervised classificationtechnique.
It is described as a two-step strategywhich addresses the problem of building a two-classclassifier with only positive and unlabeled examples(Liu et al 2002; Liu et al 2003; Zhang and Zuo,2009).
Broadly speaking this strategy consists oftwo main steps: i) to identify a set of reliable nega-tive instances from the unlabeled set, and ii) to ap-ply a learning algorithm on the refined training setto build a two-class classifier.Figure 1 shows our adaptation of the PU-learningapproach for the task of opinion spam detection.
Theproposed method is an iterative process with twosteps.
In the first step the whole unlabeled set isconsidered as the negative class.
Then, we train aclassifier using this set in conjunction with the setof positive examples.
In the second step, this classi-fier is used to classify (automatically label) the un-labeled set.
The instances from the unlabeled setclassified as positive are eliminated; the rest of themare considered as the reliable negative instances forthe next iteration.
This iterative process is repeateduntil a stop criterion is reached.
Finally, the latestbuilt classifier is returned as the final classifier.In order to clarify the construction of the opinionspam classifier, Algorithm 1 presents the formal de-scription of the proposed method.
In this algorithmP is the set of positive instances and Ui representsthe unlabeled set at iteration i; U1 is the originalunlabeled set.
Ci is used to represent the classifierthat was built at iteration i, and Wi indicates theset of unlabeled instances classified as positiveby the classifier Ci.
These instances have to be2http://www.webis.de/research/events/pan-12removed from the training set for the next iteration.Therefore, the negative class for next iteration isdefined as Ui ?Wi.
Line 4 of the algorithm showsthe stop criterion that we used in our experiments,|Wi| <= |Wi?1|.
The idea of this criterion isto allow a continue but gradual reduction of thenegative instances.1: i?
12: |W0| ?
|U1|3: |W1| ?
|U1|4: while |Wi| <= |Wi?1| do5: Ci ?
Generate Classifier(P,Ui)6: ULi ?
Ci(Ui)7: Wi ?
Extract Positives(ULi )8: Ui+1 ?
Ui ?Wi9: i?
i + 110: Return Classifier CiAlgorithm 1: PU-Learning for opinion spam detec-tion4 Evaluation4.1 DatasetsThe evaluation of the proposed method was carriedout using a dataset of reviews assembled by Ottet al(2011).
This corpus contains 800 opinions,400 deceptive and 400 truthful opinions.
Theseopinions are about the 20 most popular Chicagohotels; deceptive opinions were generated usingthe Amazon Mechanical Turk (AMT)3, whereas?possible?
truthful opinions were mined froma total of 6,977 reviews on TripAdvisor4.
Thefollowing paragraphs show two opinions takenfrom (Ott et al 2011).
These examples are veryinteresting since they show the great complexity ofthe automatically ?and even manually?
detection ofdeceptive opinions.
Both opinions are very similarand just minor details can help distinguishing onefrom the other.
For example, in his research Ottet al(2011) found that deceptive reviews used thewords ?experience?, ?my husband?, ?I?, ?feel?,?business?, and ?vacation?
more than genuine ones.3http://www.mturk.com4http://www.tripadvisor.com40Figure 1: Classifier construction with PU-Learning approach.Example of a truthful opinionWe stay at Hilton for 4 nights last march.
It was a pleasantstay.
We got a large room with 2 double beds and 2 bathrooms,The TV was Ok, a 27?
CRT Flat Screen.
The concierge wasvery friendly when we need.
The room was very cleaned whenwe arrived, we ordered some pizzas from room service and thepizza was ok also.
The main Hall is beautiful.
The breakfastis charged, 20 dollars, kinda expensive.
The internet access(WiFi) is charged, 13 dollars/day.
Pros: Low rate price, hugerooms, close to attractions at Loop, close to metro station.Cons: Expensive breakfast, Internet access charged.
Tip: Whenleaving the building, always use the Michigan Ave exit.
It?s agreat view.Example of a deceptive opinionMy husband and I stayed for two nights at the HiltonChicago, and enjoyed every minute of it!
The bedrooms areimmaculate, and the linens are very soft.
We also appreciatedthe free WiFi, as we could stay in touch with friends whilestaying in Chicago.
The bathroom was quite spacious, and Iloved the smell of the shampoo they provided-not like mosthotel shampoos.
Their service was amazing, and we absolutelyloved the beautiful indoor pool.
I would recommend stayinghere to anyone.In order to simulated real scenarios to test ourmethod we assembled several different sub-corporafrom Ott?s et al(2011) dataset.
First we randomlyselected 80 deceptive opinions and 80 truthful opin-ions to build a fixed test set.
The remaining 640opinions were used to build six training sets of dif-ferent sizes and distributions.
They contain 20, 40,60, 80, 100 and 120 positive instances (deceptiveopinions) respectively.
In all cases we used a set of520 unlabeled instances containing a distribution of320 truthful opinions and 200 deceptive opinions.4.2 Evaluation MeasureThe evaluation of the effectiveness of the pro-posed method was carried out by means of thef-measure.
This measure is a linear combination ofthe precision and recall values.
We computed thismeasure for both classes, deceptive and ?possible?truthful opinions, nevertheless, the performance onthe deceptive opinions is the only measure of realrelevance.
The f-measure for each opinion categoryOi is defined as follows:f ?measure(Oi) =2 ?
recall(Oi) ?
precision(Oi)recall(Oi) + precision(Oi)(1)recall(Oi) =number of correct predictions of Oinumber of opinions of Oi(2)41precision(Oi) =number of correct predictions of Oinumber of predictions as Oi(3)4.3 ResultsTables 1 and 2 show the results from all the ex-periments we carried out.
It is important to no-tice that we used Na?
?ve Bayes and SVM classifiersas learning algorithms in our PU-learning method.These learning algorithms as well as the one-classimplementation of SVM were also used to generatedbaseline results.
In all the experiments we used thedefault implementations of these algorithms in theWeka experimental platform (Hall et al 2009).In order to make easy the analysis and discussionof the results we divided them in three groups: base-line results, one-class classification results, and PU-learning results.
The following paragraphs describethese results.Baseline results: The baseline results were ob-tained by training the NB and SVM classifiers us-ing the unlabeled dataset as the negative class.
Thisis a common approach to build binary classifiers inlack of negative instances.
It also corresponds tothe results of the first iteration of the proposed PU-learning based method.
The rows named as ?BASENB?
and ?BASE SVM?
show these results.
They re-sults clearly indicate the complexity of the task andthe inadequacy of the traditional classification ap-proach.
The best f-measure in the deceptive opinionclass (0.68) was obtained by the NB classifier whenusing 120 positive opinions for training.
For thecases considering less number of training instancesthis approach generated very poor results.
In addi-tion we can also noticed that NB outperformed SVMin all cases.One-class classification results: These resultscorrespond to the application of the one-class SVMlearning algorithm (Manevitz et al 2002), whichis a very robust approach for this kind of problems.This algorithm only uses the positive examples tobuild the classifier and does not take advantage ofthe available unlabeled instances.
Its results areshown in the rows named as ?ONE CLASS?
; theseresults are very interesting since clearly show thatthis approach is very robust when there are onlysome examples of deceptive opinions (please referto Table 1).
On the contrary, it is also clear that thisapproach was outperformed by others, especially byour PU-learning based method, when more trainingdata was available.PU-Learning results: Rows labeled as ?PU-LEANB?
and ?PU-LEA SVM?
show the results of theproposed method when the NB and SVM clas-sifiers were used as base classifiers respectively.These results indicate that: i) the application of PU-learning improved baseline results in most of thecases, except when using 20 and 40 positive traininginstances; ii) PU-Learning results clearly outper-formed the results from the one-class classifier whenthere were used more than 60 deceptive opinions fortraining; iii) results from ?PU-LEA NB?
were usu-ally better than results from ?PU-LEA SVM?.
It isalso important to notice that both methods quicklyconverged, requiring less than seven iterations for allcases.
In particular, ?PU-LEA NB?
took more iter-ations than ?PU-LEA SVM?, leading to greater re-ductions of the unlabeled sets, and, consequently, toa better identification of the subsets of reliable neg-ative instances.Finally, Figure 2 presents a summary of thebest results obtained by each of the methods in alldatasets.
From this figure it is clear the advantage ofthe one-class SVM classifier when having only someexamples of deceptive opinions for training, but alsoit is evident the advantage of the proposed methodover the rest when having a considerable quantityof deceptive opinions for training.
It is important toemphasize that the best result obtained by the pro-posed method (a F-meausre of 0.837 in the deceptiveopinion class) is a very important results since it iscomparable to the best result (0.89) reported for thiscollection/task, but when using 400 positive and 400negative instances for training.
Moreover, this resultis also far better than the best human result obtainedin this dataset, which, according to (Ott et al 2011)it is around 60% of accuracy.5 Conclusions and future workIn this paper we proposed a novel method for detect-ing deceptive opinion spam.
This method adapts thePU-learning approach to this task.
In contrast to tra-ditional approaches that require large sets of labeledinstances from both classes, deceptive and truthful42Original Approach Truthful Deceptive Itera- FinalTraining Set P R F P R F tion Training SetONE CLASS 0.500 0.688 0.579 0.500 0.313 0.38520-D BASE NB 0.506 1.000 0.672 1.000 0.025 0.049PU-LEA NB 0.506 1.000 0.672 1.000 0.025 0.049 5 20-D/493- U520-U BASE SVM 0.500 1.000 0.667 0.000 0.000 0.000PU-LEA SVM 0.500 1.000 0.667 0.000 0.000 0.000 4 20-D/518-UONE CLASS 0.520 0.650 0.578 0.533 0.400 0.45740-D BASE NB 0.517 0.975 0.675 0.778 0.088 0.157PU-LEA NB 0.517 0.975 0.675 0.778 0.088 0.157 4 40-D/479-U520-U BASE SVM 0.519 1.000 0.684 1.000 0.075 0.140PU-LEA SVM 0.516 0.988 0.678 0.857 0.075 0.138 3 40-D/483-UONE CLASS 0.500 0.500 0.500 0.500 0.500 0.50060-D BASE NB 0.569 0.975 0.719 0.913 0.263 0.408PU-LEA NB 0.574 0.975 0.722 0.917 0.275 0.423 3 60-D/449-U520-U BASE SVM 0.510 0.938 0.661 0.615 0.100 0.172PU-LEA SVM 0.517 0.950 0.670 0.692 0.113 0.194 3 60-D/450-UTable 1: Comparison of the performance of different classifiers when using 20, 40 and 60 examples of deceptiveopinions for training; in this table D refers to deceptive opinions and U to unlabeled opinions.Original Approach Truthful Deceptive Itera- FinalTraining Set P R F P R F tion Training SetONE CLASS 0.494 0.525 0.509 0.493 0.463 0.47880-D BASE NB 0.611 0.963 0.748 0.912 0.388 0.544PU-LEA NB 0.615 0.938 0.743 0.868 0.413 0.559 6 80-D/267-U520-D BASE SVM 0.543 0.938 0.688 0.773 0.213 0.333PU-LEA SVM 0.561 0.925 0.698 0.786 0.275 0.407 3 80-D/426-UONE CLASS 0.482 0.513 0.497 0.480 0.450 0.465100-D BASE NB 0.623 0.950 0.752 0.895 0.425 0.576PU-LEA NB 0.882 0.750 0.811 0.783 0.900 0.837 7 100-D/140-U520-U BASE SVM 0.540 0.938 0.685 0.762 0.200 0.317PU-LEA SVM 0.608 0.913 0.730 0.825 0.413 0.550 4 100-D/325-UONE CLASS 0.494 0.525 0.509 0.493 0.463 0.478120-D BASE NB 0.679 0.950 0.792 0.917 0.550 0.687PU-LEA NB 0.708 0.850 0.773 0.789 0.781 0.780 5 120-D/203-U520-U BASE SVM 0.581 0.938 0.718 0.839 0.325 0.468PU-LEA SVM 0.615 0.738 0.670 0.672 0.538 0.597 6 120-D/169-UTable 2: Comparison of the performance of different classifiers when using 80, 100 and 120 examples of deceptiveopinions for training; in this table D refers to deceptive opinions and U to unlabeled opinions.43Figure 2: Summary of best F-measure results.opinions, to build accurate classifiers, the proposedmethod only uses a small set of deceptive opinionexamples and a set of unlabeled opinions.
This char-acteristic represents a great advantage of our methodover previous approaches since in real applicationscenarios it is very difficult to construct such largetraining sets and, moreover, it is almost impossibleto determine the authenticity or truthfulness of theopinions.The evaluation of the method in a set of hotel re-views indicated that the proposed method is very ap-propriate for the task of opinion spam detection.
Itachieved a F-meausre of 0.837 in the classificationof deceptive opinions using only 100 positive exam-ples and a bunch of unlabeled instances for training.This result is very relevant since it is comparable toprevious results obtained by highly supervised meth-ods in similar evaluation conditions.Another important contribution of this work wasthe evaluation of a one-class classifier in this task.For the experimental results we can conclude thatthe usage of a one-class SVM classifier is very ad-equate for cases when there are only very few ex-amples of deceptive opinions for training.
In ad-dition we could observe that this approach and theproposed method based on PU-learning are comple-mentary.
The one-class SVM classifier obtained thebest results using less than 50 positive training ex-amples, whereas the proposed method achieved thebest results for the cases having more training exam-ples.As future work we plan to integrate the PU-learning and self-training approaches.
Our idea isthat iteratively adding some of the unlabeled in-stances into the original positive set may further im-prove the classification accuracy.
We also plan todefine and evaluate different stop criteria, and to ap-ply this method in other related tasks such as emailspam detection or phishing url detection.AcknowledgmentsThis work is the result of the collaboration in theframework of the WIQEI IRSES project (GrantNo.
269180) within the FP 7 Marie Curie.
Thework of the last author was in the framework theDIANA-APPLICATIONS-Finding Hidden Knowl-edge in Texts: Applications (TIN2012-38603-C02-01) project, and the VLC/CAMPUS Microcluster onMultimodal Interaction in Intelligent Systems.ReferencesH.
Drucker, D. Wu and V.N.
Vapnik.
2002.
Supportvector machines for spam categorization.
Neural Net-works, IEEE Transactions on, 10(5), pages 1048-1054.Edgardo Ferretti, Donato Herna?ndez Fusilier, RafaelGuzma?n-Cabrera, Manuel Montes-y-Go?mez, MarceloErrecalde and Paolo Rosso.
2012.
On the Use of PULearning for Quality Flaw Prediction in Wikipedia.CLEF 2012 Evaluation Labs and Workshop, On lineWorking Notes, Rome, Italy, page 101.Z.
Gyongyi, H. Garcia-Molina and J. Pedersen.
2004.Combating web spam with trust rank.
In Proceedingsof the Thirtieth international conference on Very largedata bases-Volume 30, pages 576-587.
VLDB Endow-ment.Hall Mark, Frank Eibe, Holmes Geoffrey, PfahringerBernhard, Reutemann Peter and Witten Ian H. 2009.The WEKA data mining software: an update.SIGKDD Explor.
Newsl., pages 10-18.
ACM.N.
Jindal and B. Liu.
2008.
Opinion spam and analysis.In Proceedings of the international conference on Websearch and web data mining, pages 219-230.
ACM.N.
Jindal, B. Liu.
and E. P. Lim.
2010.
Finding unusualreview patterns using unexpected rules.
In CIKM,pages 219-230.
ACM.Raymond Y. K. Lau, S. Y. Liao, Ron Chi-Wai Kwok, Kai-quan Xu, Yunqing Xia and Yuefeng Li.
2011.
Textmining and probabilistic modeling for online reviewspam detection.
In Proceedings of the international44conference on Web search and web data mining, Vol-ume 2 Issue 4,Article 25. pages 1-30.
ACM.E.P.
Lim, V.A.
Nguyen, N. Jindal, B. Liu, and H.W.Lauw.
2010.
Detecting product review spammers us-ing rating behaviors.
In CIKM,pages 939-948.
ACM.B.
Liu, Y. Dai, X.L.
Li, W.S.
Lee and Philip Y.
2002.Partially Supervised Classification of Text DocumentsProceedings of the Nineteenth International Confer-ence on Machine Learning (ICML-2002), Sydney,July 2002, pages 387-394.B.
Liu, Y. Dai, X.L.
Li, W.S.
Lee and Philip Y.
2003.Building Text Classifiers Using Positive and Un-labeled Examples ICDM-03, Melbourne, Florida,November 2003, pages 19-22.B.
Liu.
2012.
Sentiment Analysis and Opinion Mining.Synthesis Lecture on Human Language TechnologiesMorgan & Claypool PublishersManevitz, Larry M. and Yousef, Malik 2002.
One-classsvms for document classification.
J. Mach.
Learn.Res.,January 2002, pages 139-154.
JMLR.org.R.
Mihalcea and C. Strapparava.
2009.
The lie detector:Explorations in the automatic recognition of deceptivelanguage.
In Proceedings of the ACL-IJCNLP 2009Conference Short Papers, pages 309-312.
Associationfor Computational Linguistics.Mukherjee Arjun, Liu Bing, Wang Junhui, Glance Na-talie and Jindal Nitin.
2011.
Detecting group reviewspam.
Proceedings of the 20th international confer-ence companion on World wide web, pages 93-94.ACM.A.
Ntoulas, M. Najork, M. Manasse and D. Fetterly.2006.
Detecting spam web pages through contentanalysis.
Transactions on Management InformationSystems (TMIS), pages 83-92.
ACM.Ott M., Choi Y., Cardie C. and Hancock J.T.
2011.
Find-ing deceptive opinion spam by any stretch of the imag-ination.
In Proceedings of the 49th Annual Meet-ing of the Association for Computational Linguis-tics: Human Language Technologies, Portland, Ore-gon, USA, Association for Computational Linguistics(2011), pages 309-319.Reyes A. and Rosso P. 2012.
Making Objective Deci-sions from Subjective Data: Detecting Irony in Cus-tomers Reviews.
In Journal on Decision Support Sys-tems, vol.
53, issue 4 (Special Issue on ComputationalApproaches to Subjectivity and Sentiment Analysis),pages 754-760.
DOI: 10.1016/j.dss.2012.05.027Sihong Xie, Guan Wang, Shuyang Lin and Philip S. Yu.2012.
Review spam detection via time series patterndiscovery.
Proceedings of the 21st international con-ference companion on World Wide Web, pages 635-636.
ACM.G.
Wu, D. Greene and P. Cunningham.
2010.
Mergingmultiple criteria to identify suspicious reviews.
Rec-Sys10, pages 241-244.
ACM.Bangzuo Zhang and Wanli Zuo.
2009.
Reliable NegativeExtracting Based on KNN for Learning from Positiveand Unlabeled Examples Journal of Computers, Vol.4 No.
1., January, 2009, pages 94-101.L.
Zhou, Y. Sh and D. Zhang.
2008.
A Statistical Lan-guage Modeling Approach to Online Deception De-tection.
IEEE Transactions on Knowledge and DataEngineering, 20(8), pages 1077-1081.45
