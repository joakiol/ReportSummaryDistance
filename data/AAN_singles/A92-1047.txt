Lexical Processing in the CLARE SystemDav id  M.  Carter*SRI  In ternat iona lCambr idge  Computer  Sc ience Research  Cent re23 Mi l lers YardCambr idge  CB2 1RQ,  U .K .1 In t roduct ionIn many language processing systems, uncertainty in theboundaries of linguistic units means that data are rep-resented not as a well-defined sequence of units but as alattice of possibilities.
This is often the case in speechrecognition, syntactic parsing and Japanese kana-kanjiconversion.
In contrast, however, it is often assumedthat, for languages written with interword spaces, it issufficient o prepare an input character stream for pars-ing by grouping it deterministically into a sequence ofwords, punctuation symbols and perhaps other items.But for typed input, spaces do not necessarily corre-spond to boundaries between lexical items, because of er-rors and other, linguistic, phenomena.
This means thata lattice representation, ot a simple sequence, should beused throughout front end (pre-parsing) analysis.
TheCLARE system under development at SRI Cambridgeuses such a representation, allowing it to deal straight-forwardly with combinations or multiple occurrences ofphenomena that would be difficult or impossible to pro-cess correctly under a sequence representation.
This pa-per concentrates on CLARE's ability to deal with typingand spelling errors, which are especially common in in-teractive use, for which CLARE is designed.The word identity and word boundary ambiguities en-countered in the interpretation of errorful input oftenrequire the application of syntactic and semantic knowl-edge on a phrasal or even sentential scale.
Such knowl-edge may be applied as soon as the problem is encoun-tered; however, this brings major problems with it, suchas the need for adequate lookahead, and the difficultiesof engineering large systems where the processing levelsare tightly coupled.
To avoid such problems, CLAREadopts a staged architecture, in which indeterminacyis preserved until the knowledge needed to resolve it isready to be applied.
An appropriate representation is ofcourse the key to doing this efficiently.
*CLARE is being developed as part of a collaborativeproject involving SRI International, British Aerospace, BPResearch, British Telecom, Cambridge University, the UKDefence Research Agency, and the UK Department of Tradeand Industry.2 Spaces  and Word  Boundar iesIn general, typing errors are not just a matter of oneintended input token being miskeyed as another one.Spaces between tokens may be deleted or inserted.
Mul-tiple errors, involving both spaces and other characters,may be combined in the same intended or actual token.A reliable spelling corrector must allow for all these pos-sibilities.However, even in the absence of "noise" of this kind,spaces do not always correspond to lexical item bound-aries, at least if lexical items are defined in a way that ismost convenient for grammatical purposes.
For example,"special" forms such as telephone numbers or e-mail ad-dresses, which are common in many domains, may con-tain spaces.
In CLARE, these are analysed using regularexpressions, which may include space characters.The complexities of punctuation are another sourceof uncertainty: many punctuation symbols have severaluses, not all of which necessarily lead to the same wayof segmenting the input.
For example, periods may in-dicate either the end of a sentence or an abbreviation,and slashes may be simple word-internal characters orfunction lexically as disjunctions.CLARE's architecture and formalism allow for allthese possibilities, and, as an extension, also permitmultiple-token phrases, such as idioms, to be defined asequivalent o other tokens or token sequences.
This fa-cility is especially useful when CLARE is being tailoredfor use in a particular domain, since it allows people notexpert in linguistics or the CLARE grammar to extendgrammatical coverage in simple and approximate, butoften practically important, ways.3 CLARE 's  P rocess ing  StagesThe CLARE system is intended to provide language pro-cessing capabilities (both analysis and generation) andsome reasoning facilities for a range of possible applica-tions.
English sentences are mapped, via a number ofstages, into logical representations of their literal mean-ings, from which reasoning can proceed.
Stages arelinked by well-defined representations.
The key interme-diate representation is that of quasi logical form (QLF),a version of first order logic augmented with constructsfor phenomena such as anaphora nd quantification thatcan only be resolved by reference to context.
The unifica-259tion of declarative linguistic data is the basic processingoperation.In the analysis direction, CLARE's front end process-ing stages are as follows.
A sentence is divided into asequence of clusters separated by white space.
Eachcluster is then divided into one or more tokens: words(possibly inflected), punctuation characters, and otheritems.
Tokenization is nondeterministic, and so a lat-tice is used at this and subsequent stages.
Next, eachtoken is analysed as a sequence of one or more segments.For normal exical items, these segments are morphemes.The lexicon proper is first accessed at this stage.
Variousstrategies for error recovery (including but not limited tospell ing/typing correction) are then attempted on tokensfor which no segmentation could be found.
After this,edges without segmentations are deleted; if no completepath remains, sentence processing is abandoned.
Fur-ther edges, possibly spanning non-adjacent vertices, areadded to the lattice by the phrasal equivalence mecha-nism mentioned above.
Finally, morphological, syntacticand semantic stages apply to produce one or more quasilogical forms (QLFs).
These are checked for adherenceto sortal (selectional) restrictions, and, possibly with thehelp of user intervention, one is selected for further pro-cessing.4 Segmentat ion  and  Spe l l ing  Cor rect ionEnglish inflectional morphology is sufficiently simple toallow CLARE to use a fairly simple affix-stripping ap-proach to token segmentation.
One major advantage ofthis is that spelling correction can be interleaved irectlywith it.
Root forms in the lexicon are represented in adiscrimination et for efficient access.
When the spellingcorrector is called to suggest possible corrections for aword, the number of simple errors (of deletion, inser-tion, substitution and transposition) to assume is given.NormM segmentation is just the special case of this withthe number of errors set to zero.
The mechanism non-deterministically removes affixes from each end of theword, postulating errors if appropriate, and then looksup the resulting string in the discrimination et, againconsidering the possibility of error.Interleaving correction with segmentation promotesefficiency in the following way.
As in most other correc-tors, only up to two simple errors are considered alonga given search path.
Therefore, either the affix-strippingphase or the lookup phase is fairly quick and producesa fairly small number of results, and so the two do notcombine to slow processing down.
Another beneficialconsequence of the interleaving is that no special treat-ment is required for the otherwise awkward case whereerrors overlap morpheme boundaries; thus desigend iscorrected to designed as easily as deisgned or designdeare.If one or more possible corrections to a token arefound, they are preserved as alternatives for disambigua-tion at the later syntactic or semantic stages.
The latticerepresentation allows nmltiple-word corrections (involv-ing both the insertion and the deletion of spaces) to bepreserved along with single-word ones.
The choice is onlyfinally made when a sortally coherent QLF is selected.5 An  Eva luat ionTo assess the usefulness of syntactico-semantic con-straints in CLARE's spelling correction, the following ex-periment was carried out.
Five hundred sentences fallingwithin CLARE's current lexical and grammatical cover-age were taken at random from the LOB corpus.
Al-though CLARE's core lexicon is fairly small (1600 rootforms), it consists of the more frequent words in the lan-guage, which tend to be fairly short and therefore havemany candidate corrections if misspelled.
The sentenceswere passed, character by character, through a channelwhich transmitted a character without alteration withprobability 0.99, and with probability 0.01 introducedone of the four kinds of simple error.
This process pro-duced a total of 102 sentences that differed from theiroriginals.
The average length was 6.46 words, and therewere 123 corrupted tokens in all.The corrupted sentence set was then processed byCLARE with only the spelling correction recoverymethod in force and with no user intervention.
Up totwo simple errors were considered per token.
No domain-specific or context-dependent knowledge was used.Of the 123 corrupted tokens, ten were corrupted intoother known words, and so no correction was attempted.Parsing failed in nine of these cases; in the tenth, thecorrupted word made as much sense as the original outof discourse context.
In three further cases, the originaltoken was not among the corrections uggested.
Thecorrections for two other tokens were not used becausea corruption into a known word elsewhere in the samesentence caused parsing to fail.Only one correction (the right one) was suggested for59 of the remaining 108 tokens.
Multiple-token cor-rection, involving the manipulation of space characters,took place in 24 of these cases.This left 49 tokens for which more than one correctionwas suggested, requiring syntactic and semantic process-ing for further disambiguation.
The average number ofcorrections uggested for these 49 was 4.57.
However,only an average of 1.69 candidates (including, because ofthe way the corpus was selected, all the right ones) ap-peared  in QLFs satisfying selectional restrictions; thusover 80% of the wrong candidates were rejected.
Treat-ing all candidates as equally likely in the absence of fre-quency information, syntactic and semantic processingreduced the average ntropy from 1.92 to 0.54, removing72% of the uncertainty.
Comparisons of parsing timesshowed that a lattice could be parsed many times fasterthan separate alternative strings when the problem to-ken is towards the end of the sentence and/or has severalsyntactically plausible candidate corrections.The corpus on which the experiment was carried outconsisted only of sentences of which CLARE could parsethe uncorrupted versions.
However, the figures presentedhere give grounds to believe that false positives - a wrong"correction" causing a spurious parse of an unparsableoriginal - should be rare.
If the replacement of one wordby another only rarely maps one sentence inside cover-age to another, then a corresponding replacement on asentence outside coverage should yield something withincoverage ven more rarely.260
