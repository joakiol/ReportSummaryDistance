Multiword Expression Filtering for Building Knowledge MapsShailaja VenkatsubramanyanSan Jose State UniversityDepartment of MISOne Washington SquareSan Jose, California, 95192-0244USAshailaja@acm.orgJose Perez-CarballoCalifornia State University, Los AngelesDept.
of Information Systems5151 State University DriveLos Angeles, CA 90032USAperez-carballo@acm.orgAbstractThis paper describes an algorithm thatcan be used to improve the quality ofmultiword expressions extracted fromdocuments.
We measure multiword ex-pression quality by the ?usefulness?
of amultiword expression in helping ontolo-gists build knowledge maps that allowusers to search a large document corpus.Our stopword based algorithm takes n-grams extracted from documents, andcleans them up to make them more suit-able for building knowledge maps.
Run-ning our algorithm on large corpora ofdocuments has shown that it helps to in-crease the percentage of useful termsfrom 40% to 70% ?
with an eight-foldimprovement observed in some cases.1 IntroductionMany real world applications require extractionof word sequences or multiword expressionsfrom text.
Examples of such applications in-clude, among others, creation of search engineindexes, knowledge discovery, data mining, ma-chine translation, summarization and term sug-gestion for either knowledge engineering orquery refinement by end users of a search sys-tem.The application of interest to the authors of thispaper was that of building knowledge maps thathelp bridge the gap between searchers and docu-ments.
A knowledge map for a particular domainis a collection of concepts, relationships betweenthese concepts as well as evidence associated toeach concept.
A domain concept represents anabstraction that can be generalized frominstances in the domain.
It can be a person, athing, or an event.
An example of a concept inthe operating system domain is ?installationguidelines?.
Relationships between concepts canbe either generalization or specialization (such as?is a?)
as well as different types of association(such as "part-of").
The evidence associated to aconcept is a set of single or multiword terms suchthat if any of those terms are found in a docu-ment, then it is likely that the document refers tothat concept.The task we were trying to support was to iden-tify multiword expressions in a corpus of docu-ments belonging to a domain that can helpontologists identify the important concepts in thedomain as well as their evidence.Our research was focused on domains where thecorpus of documents representing the domaincontains a high degree of technical content.
Thereason for this is that such documents are servedon many company web sites to help providetechnical support for both employees and cus-tomers.Our research assumes that a term1  is ?useful?when it meets all of the following conditions ?
(1) it makes sense in context of the domain, (2) itrepresents an action, some tangible or intangibleobject, name of a product, or a troubleshootingphrase, and (3) it would be chosen by an ontolo-gist to be incorporated to their knowledge map.Some examples of multiword expressions thatmay be considered useful for building knowledgemaps about technical content are ?how to1 In common parlance, the words ?term?
and ?expres-sion?
are generally used interchangeably.
In this pa-per, a term refers to a expression with one or morewords.Second ACL Workshop on Multiword Expressions: Integrating Processing, July 2004, pp.
40-47uninstall the program?, ?Simple Mail TransferProtocol?, and ?cannot reboot the computer?.Some expressions may not seem useful at firstglance but may make sense to an ontologist fa-miliar with that domain.
For instance, the occur-rence of the number ?error 37582?
may be anerror code, and hence evidence of a particularkind of problem.
Similarly, expressions such as?after rebooting the system?
may not seem usefulbut may be good evidence of concepts related toproblem identification.
Examples of expressionsthat may be acceptable for some purposes, butnot for building knowledge maps are ?this soft-ware was implemented by?
and ?and reboot thesystem to?.
These expressions however can be-come useful after undergoing some processing ormanipulation by humans.We extracted n-grams from documents using analgorithm proposed by Tseng [1998], andcleaned them up iteratively using a stopword-based algorithm in order to make them more use-ful for building knowledge maps.
Tseng?s algo-rithm is based on the assumption that documentsconcentrating on a topic tend to mention a set ofwords in a specific sequence repeatedly.
In otherwords, repeated multiword expressions are ex-tracted since they will make good evidence can-didates.Our experience with Tseng?s algorithm was thatit extracts many useful multiword expressions.But, it also extracts multiword expressions thatare repeated frequently in the documents but arenot useful when viewed independently of thesentences from where they originated.
This maynot matter for some applications, but puts a lot ofburden on librarians or ontologists who want touse those multiword expressions to build knowl-edge maps.
Examples of such expressions are?software was?, ?computer crashed after?, ?in-stalled in order to?, and so on.
Such expressionshave to undergo further manipulation or process-ing by ontologists in order for them to be useful.A good weighting algorithm may eliminate someof these expressions in some cases.
However,our experience has shown that in a sufficientlylarge and homogenous set of documents, occur-rence of all of these variations is so high thatmany of them meet the threshold requirements toqualify as eligible multiword expressions.
Set-ting higher frequency thresholds may be a solu-tion to this problem, but that may result inelimination of other useful multiword expres-sions.One of the steps usually undertaken is to elimi-nate not so useful single word terms extractedfrom documents.
For instance, the word ?the?
isnot considered to be useful for most purposes.
Ifa user were to submit a query such as ?the cat?,returning documents that contain ?cat?
would bemore useful than looking for documents that con-tain both ?the?
and ?cat.?
Terms such as ?a?,?an?, ?the?
and so on are referred to as ?stop-words?
or ?noise words?
or ?skipwords?, andthese are usually ignored by search engines whenthey occur by themselves when building indexes.There are many common stopword lists useful invarious contexts.Statistical and quantitative techniques using fre-quency or mutual information scores for multi-word expressions as well as syntactic techniquesusing phrase trees have been used to extractmultiword expressions from text.
[Choueka1988, Dias 1999, Lessard 1991, Hamza 2003,Merkel 1994, Paynter 2000]  According to Diaset.
al.
[1999], many multiword units identifiedusing statistical methods can not be considered asterms although it may be useful to identify them.Examples cited by the authors include terms suchas ?be notified?
and ?valid for?.
Less com-monly found in literature is work done to ?clean?or ?filter?
the extracted multiword expressions tomake them suitable for certain purposes.
An ex-ample of implementation of a filter is found inwork done by Merkel et al in their FRASSE sys-tem [Merkel 2000] where they defined wordsthat should be stripped at the beginning and atthe end of multiword expressions as well as re-quirements on what kinds of characters should beregarded as pairs (quotation marks, parentheses,etc).
The reason for identifying characters thatshould be regarded in pairs is to make sure thatmultiword expressions that are retained after fil-tering do not have only one parenthesis characteror quotation mark.
Their filter was implementedwith the use of entropy thresholds and stopwordsfor the Swedish language.
Another example of aproposed filter is found in work by Dias et.
al.
[1999] in which the authors suggest using a filterthat removed stopwords where they occurredeither at the beginning or at the end of multiwordexpressions.
Our work uses a standard stopwordlist used by systems that suggest terms to ontolo-gists and end users, and part of speech informa-tion to achieve the same goal.
The part of speechinformation ensures that we treat beginning andend of multilword expressions differently.Our contribution has been to extend Tseng?s al-gorithm using stopwords and a part of speechbased algorithm to reduce the occurrence of ex-pressions that need further processing by ontolo-gists.
Our goal was to increase the proportion ofexpressions extracted that don?t have to undergoany more manual processing by ontologists tomake them useful.
This is very useful in situa-tions such as term suggestion where users can besaved the time and effort involved in goingthrough long lists of terms many of which maynot be useful, or may have to be manipulated insome way to make them useful.
Running ouralgorithm on large corpora of documents hasshown that it helps to increase the percentage ofuseful terms from 40% (+-10) to 70% (+-10).
Inother words, the improvement is at least 20% andcould be high as 160%.The rest of this paper is organized as follows ?Section 2 describes our algorithm for extractionof frequently occurring n-grams, and convertingthem to useful multiword expressions.
Sections3 and 4 describe the results of evaluating our al-gorithm on large corpora of documents and con-clude the paper.2 Term Extraction and Filtering Algo-rithmsResearchers have extracted keywords by a sim-ple recognition of fixed patterns that occur fre-quently in the text.
[Choueka 1988, Tseng 1998]We adopted Tseng?s algorithm which identifiesfrequently repeated N-grams because of its effi-ciency.We begin by describing Tseng?s algorithm andthen discuss our modifications to extract usefulmultiword expressions.2.1 Tseng?s AlgorithmThis algorithm consists of three major steps.
Thefirst step requires only linear-time complexity forconverting the input text into a list.
The secondstep repeats merging tests until no elements re-mained to be merged.
The third step involvesfiltering out noisy terms using a stop list.Table 1: Tseng?s algorithm [Tseng 1998]1.
Convert the input text into a LIST of overlapping2-grams (or 2-words, see an example below).2.
WHILE LIST is not empty2.1.
Set MergeList to empty.2.2.
Push a special token to the end of LISTas a sentinel.2.3.
FOR each pair of adjacent elements KIand K2 in LIST,IF Kl and K2 are mergeable and both oftheir occurring  frequency are greater than a thresholdTHENMerge KI and K2 into K and push K intoMergeList.Accumulate the occurring frequency ofK.ELSEIF the occurring frequency of KI isgreater than a threshold and KI did not merge withthe element before it in LISTPush KI into the FinalList.ENDIFENDFORENDWHILE2.4.
Set LIST to MergeList.3.
Filter out noisy terms in FinalList and sort the re-sult according to some criteria.2.2 Iterative Term Filtering AlgorithmWe used Tseng?s algorithm to select a set of mul-tiword expressions.
Then, we applied an algo-rithm based on stopwords and part of speechinformation to filter out the less useful wordsfrom the beginning and end of multiword expres-sions in order to help identify and construct use-ful multiword expressions.
Our algorithmdeletes words from the beginning and end of themultiword expression until one of the followingconditions are satisfied: (1) the result is a oneword term that is not a stopword, or (2) thewords at the beginning and end of the multiwordexpression are deemed acceptable by our algo-rithm or (3) all words in the expression are de-leted.Our technique uses the stopword list that is usedby step 3 of Tseng?s algorithm along with rulesregarding which of those stopwords are accept-able if found at the beginning and at the end ofthe extracted n-grams.
Stopword lists may begenerated by analyzing a corpus of documents,and identifying the most frequently occurringwords across the corpus.
Many pre-compiledlists are also available, and generally the practicehas been to adopt a pre-compiled list and tweak itto meet a specific purpose.The number of entries in stopword lists can rangefrom approximately 50 to 5000 words.
[?Onix?online stopword lists, ?freeWAIS-sf?, ?SeattleCity Clerk Information Services Database?,?RDS?]
The stopword lists that are used for termsuggestion tend to be longer or more aggressivethan those used for building standard search en-gine indexes.
The stopword list used by the termsuggestion system that we used for our experi-mentation contained around 600 words.
Fast-NPE, a noun phrase extractor, uses a stopwordlist with more than 3500 words [Bennett, 1999].One would find words such as ?can?, ?cannot?,should?, ?approximately?, and so on a stopwordlist for term suggestion even though they maynot be present in other stopword lists.
The rea-son for this is that such words are not useful bythemselves to end users or to ontologists who aretrying to understand the content of documents.But, these words may be useful when found atthe beginning or end of multiword expressions.Our algorithm assumes the use of a stopword listgenerally used by implementers building termsuggestion systems.
Our part of speech basedheuristics determine which of those stopwordswould be considered acceptable at the beginningor end of multiword expressions.2.3 Stopword AnalysisIn order to gain an initial insight into what kindsof words are acceptable at the beginning and endof multiword expressions, we built lists of ac-ceptable multiword expressions based on filter-ing performed by a team of experiencedontologists on a sample set of multiword expres-sions extracted from hundreds of thousands ofdocuments.
Studying words in the multiwordexpressions that were discarded or retained gaveus clues about what words are acceptable at thebeginning and end of multiword expressions.This helped us identify patterns that could thenbe incorporated into a more general algorithm.Most of the time, stopwords were not usefulwhen they were at the beginning or end of mul-tiword expressions.
Some good examples ofstopwords that are not useful at the beginning orend or a multiword expression are coordinatingconjunctions such as ?and?, ?or?, and so on.However, there are exceptions to this rule.
Theexceptions are described in sections 2.3.1 and2.3.2.2.3.1.
Stopwords Acceptable at the Begin-ning of Multiword ExpressionsWe studied words retained and discarded by on-tologists at the beginning of multiword expres-sions.
As expected, many times, these werewords that were in the stopword lists.
But, therewere cases where some stopwords were not dis-carded.
These helped us identify cases or pat-terns that went into the creation of our algorithm.Those cases are presented below:Prepositions ?
Words such as ?under?,?over?, ?after?, and so on.
An example ofan expression that has a preposition at thebeginning, and is a useful expression is?after installing the operating system?.Using the standard stopwords list to elimi-nate words from the beginning of multi-word expressions would have resulted inthat expression being reduced to ?install-ing the operating system?.
The meaningof ?after installing the operating system?
isquite different from ?installing the operat-ing system?.
The content of documentscontaining the expression ?after installingthe operating system?
may be quite differ-ent from documents containing just theexpression ?installing the operating sys-tem?.
?After installing the operating sys-tem?
may be indicative of a documentabout problems users may run into afterinstallation.
Just ?installing the operatingsystem?
may be indicative of documentsabout how to install an operating system.The goal here is not to determine whetherone multiword expression is really differ-ent from another, but to provide the on-tologist with all possible information tomake those judgment calls.Auxiliary verbs ?
Words such as ?can?,?cannot?, ?will?, ?won?t?, ?was?, ?has?,?been?
are examples of auxiliary or help-ing verbs.
For example, the expression?can uninstall the program?
is quite differ-ent from ?cannot uninstall the program?.Since ?can?
is both a noun as well as anauxiliary verb, it is usually not on moststopword lists.
But, ?cannot?
is some-times found in some stopword lists.Adverbs - Words such as ?slowly?, ?insuffi-ciently?, ?fast?, ?late?, early?, etc.
may befound in stopword lists used for term sug-gestion since these words do not carrymuch meaning by themselves.
But, theyare useful when found at the beginning ofmultiword expressions.
Examples of suchexpressions include ?early binding?
and?late binding?.Adjectives ?
Adjectives such as ?slow?,?fast?, ?empty?, ?full?, and intermittent?are useful when found in the beginning ofmultiword expressions.
Examples include?slow CPU?, ?intermittent failures?, etc.
"All," "any," "each," "few," "many," "no-body," "none," "one," "several," and"some," are some examples of indefiniteadjectives.
Multiword expressions suchas ?several users?, and ?all CDROMdrives?
may convey more meaning thanjust ?users?
and ?CDROM drives?.Interrogative pronouns ?
?How?, ?why?,?when?, and so on are not useful by them-selves, but are very useful when found atthe beginning of multiword expressions.Examples of such expressions include ?
?how to install an anti-virus package?,?when to look for updates?, and ?how do Ifix my computer?.Correlative conjunctions ?
?Both the com-puters?, and ?either freezing or crashing?are examples of expressions that beginwith correlative conjunctions.
?Both?
and?either?
are very likely to be found instopword lists used for term suggestion,but they add meaning to multiword ex-pressions.2.3.2.
Stopwords Acceptable at the End ofMultiword ExpressionsSimilarly we studied words retained and dis-carded by ontologists at the end of multiwordexpressions.
As expected, many times, thesewere words that were in the stopword lists.
But,there were cases where some stopwords were notdiscarded.
Those cases are presented below:Numbers ?
Numbers are generally found onmost stopword lists.
0, 1, 2, and so onrarely make sense by themselves, espe-cially in the context of term suggestion.However, when they are found at the endof the multiword expressions in the digitform (0, 1, 2, and so on) rather than in theword form (one, two, three, and so on),they can be useful.
Examples of suchcases are usually product names with theirversion numbers ?
?Microsoft Word ver-sion 3.0?, ?Windows 3.1?, and so on.Closing parentheses ?
Closing parenthesesusually indicates the presence of openingparentheses within the multiword expres-sion.
Therefore, retaining the closingparentheses is a good idea.
Examples ofsuch expressions are ?Manufacturing (UKdivision)?, ?Transmission Control Proto-col (TCP)?, and so on.
A nice side effectof this heuristic is the ability for the usersto learn about acronyms in the domain.Adverbs ?
Words such as ?slowly?,?quickly?, ?immediately?, and so on areuseful at the end of multiword expres-sions.
Examples of these include ?com-puter shuts down slowly?, and ?uninstallthe program immediately?.Table 2 describes Tseng?s algorithm modifiedusing our term filtering algorithmTable 2: Modified Term Filtering Algorithm1.
Convert the input text into a LIST of overlapping2-grams (or 2-words, see an example below).2.
WHILE LIST is not empty2.1.
Set MergeList to empty.2.2.
Push a special token to the end of LISTas a sentinel.2.3.
FOR each pair of adjacent elements KIand K2 in LIST,IF Kl and K2 are mergeable and both oftheir occurring  frequency are greater than a thresholdTHENMerge KI and K2 into K and push K intoMergeList.Accumulate the occurring frequency ofK.ELSEIF the occurring frequency of KI isgreater than a threshold and KI did not merge withthe element before it in LISTPush KI into the FinalList.ENDIFENDFORENDWHILE2.4.
Set LIST to MergeList.3.
Filter out noisy terms in FinalList and sort the re-sult according to some criteria.4.
FOR each expression FL on the FinalList,4.1 IF the first word in FL is a stopword andis not: a preposition, an auxiliary verb, an adverb, anadjective, an interrogative pronoun, or a correlativeconjunctionsTHENDelete that wordENDIF4.2 IF the last word in FL is a stopword andis not: an adverb, a closing parenthesis, or a number,THENDelete that wordENDIFUNTIL (the words at the beginning and end of FL arenot on the stopword list OR FL is a one word termthat is a not a stopword or all the words in the expres-sion are deleted by this algorithm)5.
Push FL into FilteredList.This algorithm can be implemented using either aprogram that does part of speech tagging or aprogram that looks up a thesaurus.
Our imple-mentation used a list of stopwords that are ac-ceptable at the beginning of the expression, andanother list of stopwords that are acceptable atthe end of the expression.3 EvaluationWe implemented this algorithm using Java, andran it on more than 20 corpora of documentsdealing with technology topics.
The size of thecorpora ranged from 4000 documents to 500,000documents.
The average size of the corpora wasaround 5-6 MB.
The topics discussed include,among others, computer networking, instructionson how to install and use application software,troubleshooting software problems, and so on.Program inputs include documents, and a stop-words list.Benefits of applying our algorithm to filter ex-pressions include:Term list size reduction - The result of ap-plying our algorithm to filter expressionsextracted from documents is a reduction innumber of terms by at least 30%-40%.This translated to an order-of-magnitudereduction in time and effort on the part ofontologists and other users.
Without thealgorithm, ontologists may have had tostudy the list manually to eliminate mean-ingless expressions and manipulate otherterms to turn them into useful expressions.Examples of such reduction include:Expressions such as ?Windows 98 operat-ing system?, ?Windows 98 operatingsystem was?, ?the Windows 98 operat-ing system?, and ?Windows 98 operat-ing system is?
are reduced to?Windows 98 operating system?.Expressions such as ?the screen flickers?,and ?screen flickers and?
would be re-duced to just ?screen flickers?.Expressions such as ?and is a?
and ?is not?and ?and etc.?
are eliminated from thelist.
The individual words in these ex-pressions are in the stop words list, butordinarily a multiword expression suchas ?is not?
would make it past the stopwords filter since it contains more thanone word in it.The reduction in the number of termstranslated to a reduction in the numberof person-weeks required to create aknowledge map using the terms.
Wenoticed a savings in the number of per-son-weeks that ranged from 50% toclose to 90%.
In one particular in-stance, using our algorithm reduced thetime required to create a knowledgemap based on extracted n-grams from 4person-weeks to about 0.5 person/weeksHigher precision - There is a greater prob-ability that the terms that remain after fil-tering are useful terms.
In other words,the remaining terms are more likely to beconsidered useful by users.
Our experi-ence has shown that the percentage of use-ful terms prior to filtering ranged from30% to 50%.
Post filtering, the percentageof useful terms ranged from 60% to 80%.In other words, running our algorithm onlarge corpora of documents has shown thatit helps to increase the percentage of use-ful terms from 40% (?10%) to 70%(?10%) ?
with an eight-fold improvementobserved in some cases.Domain independence - Pattern extractionfrom documents involves extracting bothdomain specific and domain independentterms.
Domain specific terms are thosethat represent the core knowledge in thedomain.
For example, terms such as ?dy-namic host control protocol?
and?TCP/IP?
can be considered to be domainspecific terms in the computer networkingdomain.
On the other hand, terms such as?document author?
are not domain spe-cific.
The technique described in this pa-per aids in filtering both domain specificand domain independent terms extractedfrom documents.
This ensures domainportability.
The tests conducted have beenprimarily with documents containing tech-nology topics.
However, this algorithmworked well with documents related toelectronic commerce as well.The algorithm is, of course, not foolproof, andthere are instances where expressions that oughtto be modified are not, and expressions are modi-fied more than necessary.
For instance, the ex-pression ?software was?
will be correctlyreduced to ?software?
since ?was?
is an auxiliaryverb.
The multiword expression ?computercrashed after?
will be reduced to ?computercrashed?
since ?after?
is a prepositon, but ?in-stalled in order to?
will be reduced to ?installedin order?.
?Installed in order?
is not a useful ex-pression, but it is one of the expressions that arenot processed correctly by our algorithm.
On thewhole, however, our finding is that applying thisalgorithm results in a significant savings of timeand effort to extract useful multiword expres-sions from documents.4 Conclusion and Future WorkWe believe that our approach can help tremen-dously with the task of filtering expressions ex-tracted automatically from documents.
Theresult of applying our approach will be automaticextraction of more useful expressions, and reduc-tion of burden on users who are presented withthose expressions.Future work includes using more sophisticatedstatistics such as IDF other than just frequency ofoccurrence of terms to eliminate more terms be-fore they are processed by the multiword termfiltering algorithm.
Our initial approach was todo something fast and simple that has a signifi-cant impact.
Our plan is to evaluate various sta-tistical approaches in order to select one that canproduce better multiword expressions that canthen be fed into the term filtering algorithm.
Anapproach that we experimented with was runningthe algorithm on just the titles and abstracts oflarger documents.
We noticed that this approachworked well for extracting concepts for buildingknowledge maps.
However, it needs to undergofurther testing.
Besides, testing this algorithm ondocuments from other domains such as medical,pharmaceutical and financial domains, and usingsyntactic and semantic information to build?positive filters?
that identify well formed pat-terns, instead of stripping away ill-formed pat-terns are other issues worth researching.ReferencesBennett Nuala A., He Qin, Chang, Conrad T. K., andSchatz, Bruce R.  Concept Extraction in the Inter-space Prototype, UIUCDCS-R-99-2095, April1999Choueka, Y.
(1988) ?Looking for needles in a hay-stack?.
In RIAO 88, User-oriented Content-basedText and Image Handling, Volume 1, 609-623,1988.Dias, G, Vintar, Pereira Lopes, G.; Guillore, S.Normalising the IJS-ELAN Slovene-EnglishParallel Corpus for the Extraction of MultilingualTerminology.
In: Monachesi, P.
(ed.)
Proceedingsof the CLIN '99 (Computational Linguistics in theNetherlands).freeWAIS-sf stopword list at http://www-fog.bio.unipd.it/waishelp/stoplist.htmlHamza, H., Mahdy, A. Fayad, M. E. and Cline, M.Extracting Domain-Specific and Domain-NeutralPatterns Using Software Stability Concepts, OOIS2003, Geneva, Switzerland, September 2003Lessard, G., Hamm, Jean-Jacques.
(1991) Computer-Aided Analysis of Repeated Structures: the Case ofStendhal's Armance.
ACH/ALLC 91, Tempe.Merkel, Magnus & Andersson, Mikael (2000).Knowledge-lite extraction of multiword units withlanguage filters and entropy thresholds.
In Proceed-ings of RIAO'2000, Coll?ge de France, Paris,France, April 12-14, 2000, Volume 1, pp.
737-746.Merkel, Magnus, Nilsson, Bernt & Ahrenberg, Lars(1994).
A Phrase-Retrieval System Based on Re-currence.
In Proceedings from the Second AnnualWorkshop on Very Large Corpora.
Kyoto.Onix Text Retrieval Toolkit stopword list #1 athttp://www.lextek.com/manuals/onix/stopwords1.htmlOnix Text Retrieval Toolkit stopword list #2 athttp://www.lextek.com/manuals/onix/stopwords2.htmlPaynter, Gordon W., Witten, Ian H., Cunningham,Sally Jo, Buchanan, George.
Scalable browsing forlarge collections: a case study.
June 2000.
Pro-ceedings of the fifth ACM conference on Digitallibraries.RDS Business Reference Suite stopword list athttp://rdsweb2.rdsinc.com/help/stopword_list.htmlSeattle City Clerk's Office Information ServicesDatabase Stopword List athttp://clerk.ci.seattle.wa.us/~public/stop.htmTseng, Yuen-Hsien.
August 1998   Multilingualkeyword extraction for term suggestion.
Proceed-ings of the 21st annual international ACM SIGIRconference on Research and development in infor-mation retrieval
