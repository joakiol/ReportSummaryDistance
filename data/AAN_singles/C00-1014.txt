Reusing an ontology to generate numeral classifiersFrancis Bond*NTT Communication Science Laboratories2-4 Hikari-dai, Kyoto 619-0237, JAPANbond@cs lab .kec l  .n t t .
co .
jpKyonghee PaikCenter for the Study of Language and InformationStanford University, CA 94305-2150, USAkpa ik@usa ,  netAbstractIn this paper, we present a solution to the prob-lem of generating Japanese nmneral classifiers us-ing semantic lasses from an ontology.
Most nounsmust take a numeral classifier when they are quan-tiffed in languages uch as Chinese, Japanese, Ko-rean, Malay and Thai.
In order to select an appro-priate classifier, we propose an algorithm which as-sociates classifiers with semantic lasses and usesinheritance to list only those classifiers which haveto be listed.
It generates sortal classifiers with au ac-curacy of 81%.
We reuse the ontology provided byGoi-Taikei - -  a Japanese lexicon, and show that itis a reasonable choice for this task, requiring infor-mation to be entered for less than 6% of individualnouns .1 IntroductionIn this paper we consider two questions.
The th'st is:how to generate numeral classifiers uch as piece in2 pieces qfl)aper?
To do this we use a semantic hier-archy originally developed for a different ask.
Thesecond is: how far can such a hierarchy be reused?In English, uncountable nouns cannot be directlymodified by numerals, instead the noun nmst beembedded in a noun phrase headed by a classi-tier.
Knowing when to do this is a language Sl0e-cific property.
For example, French deux renseigne-merit must be translated as two pieces of informationin English.
\] Iu many languages, including mostSouth-East Asian lauguages, Chinese, Japanese andKorean, the majority of nouns are uncountable andnmst be quantified by numeral classifier combina-tions.
These languages typically have many differ-ent classifiers.
There has been some work on theanalysis of numeral classifiers in natural languageprocessing, particularly for Japanese (Asahioka etal., 1990; Kamei and Muraki, 1995; Bond et al,* Visiting CSLI, Stanford University (1999-2000).I Numeral-classilier combinations are shown in bold, thenoun phrases they quantify are underlined.1996; Bond et al, 1998; Yokoyama and Ochiai,1999), but very little on their generation.
We couldonly find one paper on generating classifiers in Thai(Sornlertlamvanich et al, 1994).
One immediateapplication fox the generation of classifiers is ma-chine translation, and we shall take examples flomthere, but it is in fact needed fox" the generationof any quantified noun phrase with an uncountablehead noun.The second question we address is: how far canan ontology be reused for a difl%rent task to the oneit was originally designed fox.
There are severallarge ontologies now in use (WordNet (Fellb~mm,1998); Goi-Taikei (lkehara et al, 1997); Mikrokos-rues (Nirenburg, 1989)) and it is impractical to re-build one fox" every application.
Howevel, there isno guarantee that an ontology built fox one task willbe useful for another.The paper is structured as follows.
In Section 2,we discuss tile properties of numeral classifiers inmore detail and suggest an ilnproved algorithm fox"generating them.
Seclion 3 introduces the ontologywe have chosen, the Goi-Taikei ontology (ikehara ctal., 1997).
Then we show how to use the ontology togenerate classifiers in Section 4.
Finally, we discusshow well it performs in Section 5.2 Generating Numeral ClassifiersIn this section we introduce the properties of nu-meral classifiers, focusing on Japanese, then givean algorithm to generate classiliers.
Japanesc waschosen because of tile wealth of published ata onJapanese classifiers and the availability of a largelexicon with semantic lasses marked.2.1 What are Numeral ClassifiersJapanese is a language where most nouns can notbe directly modified by numerals, instead, nounsare modified by a numeral-classifier combinatiou asshown in (1).22~Vc use lhe fo l low ing  abbrev ia t ions :  NOM : nominat ive ;ACC = accusat ive ;  AI)N = adnomina l ;  CI.
= c lass i l ier ;  ARGSTR90(l) 2-tsfH10 denshimC~ru2-(:L-ADN emai\[2 pieces of emai\]2 emailsIn Japanese, numeral classifiers arc a subclass o\[nouns.
The main properly dislinguishillg them fromt)rolotypical nouns is thai lhey cannot sland alone.Typically they postiix to numerals, forming a quan-tilter l)hrase.
Japanese also allows them to combinewith the quantifier st7 "some" or tile interrogativenani "what" (2).
We will call all such Colnbinationsot' a numeral/quantifier/interrogative with a numeralclassifier a numeral-classitier combination.
(2) a.
2-hiki"2 animals" (Numeral)b. sO-hiki "solne animals" (Quantilier)c. nan-biki "how Illauy mfimals" (inlcr-rogali ve)Classiliers have different l)rOl)erlies del)ending ontheir use.
There are live ulajor types: serial whichclassify the kind o1: tile noun phrase tile}, (.\]uan-lily (such as -/all "piece"); evenl which arc usedto quantify events (such as -kai " l i l l lC" ) ;  me i l s l l -ral which ~lre used to measure lhc U.IIIOtlllt Of  SOl l leproperty (such its senchi "-cm"), group which referto a collection of melnbers (such as -inure gloup ),and taxononfic which force (he noun phrase to beinlerpreted as a generic kind (such as -.vim "kind").We propose the l:ollowing basic struclurc for sor-tal classiliers (3).
The lexical slructtlre we adopt isan extension ot' Pustejovsky's (1995) generative l x-icon, with tile addition of an explicit quantilicationrelationship (Bond and Paik, 1997).\[ \[AR(;I x : numera l+ARGSTR (3) / LD-ARG1 y:,,la.,.qlicrLOUANT Cluant:5- f 5.es (x,  y)There are two variables in the argument strut-lure: the numeral, quantifier or interrogative (repre-sented by numera2+) ,  and the noun phrase beingclassilied.
Because the noun phrase being classiliedcan be omitted in context, it is a default argun-lent,one which participales in tile logical expressions inthe qualia, but is not necessarily expressed syntacti-cally.= argunle l l l  s lructurc;  AR(; = argument ;  \[)-AR(; = default  m-gu-menl ,  QUANT = quant i l icat ion.Serial classiliers differ from each other in tile re-strictions they place on the quantilied variable 7V.For example tile classilier -nin adds tile restrictiony :human.
That is, it can only be used to classifyhuman referents.Japanese has two number systems: a Sine-Japanese one based on Chinese for example, ichi"Olle",lli "\[wo",s(lll "lhree", etc., and ~tll alternativenalive-Jal)anesc ystem, for example, hitotsu "one"fitlalsu "two",milsu "three", etc.
In Japanese tile lla-live system only exists for the numbers from oneto ten.
Most classitiers combine with the Chineselorms, howevm; different classiliers select Sine-Japanese for some numerals, for example, ni-hiki"two-el", and most classifiers undergo some formof sound change (such as -hiki to -biki in (2)).Wc will not bc concerned wilh these morllhologicalchanges, we refer interested reMers to Backhouse(1993, I 1 g-122) for more discussion.Numeral classiliers characteristically premodifythe noun phrases they quantify, linked by an adhere-inal case marker, as in (4); or appear 't\]oating' asadverbial phrases, lypically to before the verb: (5).The choice between pre-nominal and lloming quan-lifters is hu'gcly driven by discourse related consid-erations (1)owning, 1996).
In this paper we concen-lrale on (he semantic ontribution of the quantiliers,and ignore tile discourse ffects.
(4) 2-isii-no tegami-o yonda2-CI.-AI)N letter-A{:c readI read two letters(5) tcgami-o 2-tsii yondaletter-ACC 2<:L readI read two lettersQuantilier phrases can also function as nounl)hrascs on their own, with anaphoric or deictic ref-erence, when what is being quantilied is recover-able from the context.
For example (7) is accept-able if the letters have already been referred to, orarc clearly visible.
(6) \[some background with letters salient\](7) 2-tsfi-o yonda (Japanese)2-CI,-ACC read1 read two lettersIn the pre-nonlinal construction tile relation be-tween ihe target noun phrase and quantilier isexplicit.
For muneral-classilier combinations the91quantification can be of the object denoted by thenoun phrase itself as in (8); or of a sub-part of it asin (9) (see Bond and Pai l  (1997) for a fuller discus-sion).
(8) 3-tsfi-no tegami3-CL-ADN letter3 letters(9) 3-mai-no tegami3-CL-ADN lettera 3 page letter2.2 An Algorithm to Generate NumeralClassifiersThe only published algorithm to generate classifiersis that of Sornlertlamvanich et al (1994).
Theypropose to generate classifiers in Thai as follows:First create a lexicon with default classifiers listedfor as many nouns as possible.
This was done byautomatically extracting noun classifier pairs froma sense-tagged corpus, and taking the classifier thatappeared most often with each sense of a noun.
3Then, the most fiequent classifier is listed for eachsemantic lass.
Generation is then simple: if a nounhas a default classifier in the lexicon, then use it,otherwise use the default classifier associated withits semantic lass.Unfortunately, no detailed results were given asto the size of the concept hierarchy, the number ofnodes in it or the number of nouns for which clas-sifiers were found.
As the generation procedurewas not ilnplemented, there was no overall accuracygiven for the system.As a default, Sornlertlamvanich et al's algorithmis useful.
However, it does not cover several ex-ceptional cases, so we have refined it further.
Theextended algorithm is shown in Figure 1.Firstly, we have made explicit what to do whena noun is a member of more than one semanticclass or of no semantic lass.
In the lexicon weused, nouns are, on average, inembers of 2 seman-tic classes.
Howevm; the semantic lasses are or-dered so that the most typical use comes first.
Forexample, usagi "rabbit" is marked as both animaland meat, with animal coming first (Fignre 3).In this case, we would take the classifier associated3111 fact, Thai also has a great many group classiliers, muchlike heM, flock and pack in English.
Therefore ach noun hastWO classifiers, a sortal classifier and a group classifier listed.Japanese does not, so we will not discuss the generation ofgroup classiliers here.with the first semantic lass.
However, in the case ofusagi it is not counted with the default classifier foranimals -hiki, but with that for birds -wa, this mustbe listed as an exception.Secondly, we have added a method for generatingclassifiers that quantify coordinate noun phrases.These commonly appear in appositive noun phrasessuch as ABC-to XYC-no 2-sha "the two companies,ABC and XYZ".1.
For a simple noun phrase(a) If the head noun has a default classifier inthe lexicon:use the noun's default classifier(b) Else if it exists, use the defimlt classifierof the head noun's first listed semanticclass (the class's default classifier)(c) Else use the residual classifier -tsu2.
For a coordinate noun phrasegenerate the classifier for each noun phraseuse the most frequent classifierFigure 1: Algorithm to generate numeral classifiersIn addition, we investigate to what degree wecould use inheritance to remove redundancy fromthe lexicon, ff a noun's default classifier is the sameas the default classifier for its semantic lass, thenthere is no need to list it in the lexicon.
This makesthe lexicon smaller and it is easier to add new en-tries.
Any display of the lexical item (such as formaintenance or if the lexicon is used as a humanaid), should automatically generate the classifierfrom the semantic lass.
Alternatively (and equiv-alently), in a lexicon with multiple inheritance anddefaults, the class's default classifier can be addedas a defeasible constraint on all lnembers of the se-mantic class.3 The  Go i -Ta ike i  Onto logyWe used tim ontology provided by Goi-Taikei - -  AJapanese Lexicon (Ikehara et al, 1997).
We chooseit because of its rich ontology, its extensive use inmany other NLP applications, its wide coverage ofJapanese, and tile fact that it is being extended toother numeral classifier languages, such as Malay.The ontology has several hierarchies of concepts:92with both is-a and has-a rehttionshil)s. 2,710 se-mantic classes (12-level t'ee structure) for commonnouns, 200 chtsses (9-level tree structure) for propernouns and 108 classes for predicates.
We show thetop three levels of the common norm ontology inFigure 2.
Words can be assigned to semantic lassesanywhere in the hierarchy.
Not all semantic lasseshave words assigned to them.The semantic classes are used in the Jalmneseword semantic dictionary to classify nouns, verbsand adjectives.
The dictionary inchtdes 100,000common nouns, 70,000 technical terms, 200,000proper nouns and 30,000 other words: 400,000words in all.
The semantic lasses al'e also used asselectional restrictions on the arguments o1' predi-cates in a separate predicate dictionary, with around17,000 entries.Figure 3 shows an example of one record of theJapanese semantic word dictionary, with the addi-tion of the new I)I{FAU1\]I" CLASSIFIFA{ lield (under-lined for elnphasis).Each record has an index form, pronunciation,a canonical form, part-of-speech and semanticclasses.
Each word can have up to five commoniloun classes and ten proper noun chtsses, hi thecase of usagi "rabbit", there are two common nounclasses and no proper noun classes.4 Maplfing Classiliers to the Onto logyIn this section we investigate how l'ar the seman-tic classes can be used to predict default classiticrsfor nouns.
Because most sortal classifiers selectfor some kind of semantic lass, we thought thatnouns grouped together under the same senmnticclass should share the same classifier.We associated classifiers with semantic classesby hand.
This took around two weeks.
We foundthat, while some classes were covered by a singleclassifier, around 20% required more than one.
Forexample, 1056:song is counted only by -kyoku"tune", and 989 :waker  veh icZe  by only by -seki "ship", but the class \[961:weapon\] had menl-bet's counted by -hen "long thin", -chO "knife", -.fitri"swords", -ki "machines" and more.We show the most flequeut numeral classifiers inTable 1.
We ended up with 47 classifiers used assemantic lasses' default classifiers.
This is in linewith the fact that most speakers of Japanese knowand use between 30 and 80 sortal classifiers (l)own-ing, 1996).
Of course, we expect o add more clas-sifters at the noun level.801 semantic lasses turned out not to have clas-siliers.
This included chtsses with no words associ-ated with them, and those that only contained nounswith referents o abstract we considered them to beuncountable, such as greed, lethargy, etc.We used the default chtssifiers assigned to the se-mantic classes to generate defeasible del'aults for thenoun entries in the common and technical term dic-tionaries (172,506 words in all).
We did this in orderto look at the distribution of classifiers over words inthe lexicon.
In the actual generation this would bedone dynamically, after the semantic lasses havebeen disambiguated.
The distributions of classifierswere similar to those of the semantic lasses, al-though there was a higher proportion counted withthe residual classilier -tsu, and the classifier for ma-chines -ekti.
This may be an artifact of the 70,000word technical term dictionary.
As further esearch,wc would like to calculate the distribution of classi-\[iers in some text, althottgh we expect it to dependgreatly on the genre.The mapping we created is not complete becausesome of the semantic lasses have nouns which donot share the same classifiers.
We have to add lnorespecific defaults at the noun level.
As well as morespecific sortal classifiers, there are cases where agroup classifier may be more appropriate.
For ex-ample, among the nouns counted with -~zi~ there areentries such as couple, twins and so on which areoften counted with -kumi "pair".In addition, the choice o1' classilier can depend onfactors other than just semantic lass, for example,hire "people" can be counted by either -nin or -mei,the only difference being that -mei is more polite.it was difficult to assign default classifiers tothe semantic lasses that referred to events.
Thesechtsses mainly include deverbal nouns (e.g.
konomi"liking") and nominal verbs (e.g., benkyO "study").These can stand for both the action or the result ofthe action: e.g.
kenkyl7 "a study/research".
In thesecases, every application we considered would dis-tinguish between event and sortal classification inthe input, so it was only necessary to choose a clas-sifier for the result of the action.5 Evaluation and Discuss ionThe algorithm was tested oil a 3700 sentence tna-claine translation test set of Japanese with Englishtranslatious, although we only used the JapaneseJ~The test set is available at www.kec l .n t t .
co .
jp /i c l /mtg / resources .931 : noun2 : concrete3 : 388 : 533 :agent  p lace  ob jec ti000 : abst rac t1001 : 1235 : 2422 :abst rac t  th ing  event  re la t ionFigure 2: Top three levels of the Goi-Taikei Common Noun Ontology;'CCo;'H-INDEX FORMPRONUNCIATIONCANONICAL FORMPAP.T OF SPEECH\])IEFAULT CLASSIFIERSEMANTIC CLASSESey +)-:~ (usagi)"5 ~ -~"/usagi/~, (usagi)noun~g~ (-wa)COMMON NOUN 537:beast  \]843 meat /egg\ ]Figure 3: Japanese Lexical Entry for rabbit "usagi"We only considered sentences with a noun phrasemodified by a sortal classifier.
Noun phrases modi-lied by group classifiers, such as -soku "pair" werenot evaluated, as we reasoned that the presence ofsuch a classifier would be marked in the input to thegenerator.
We also did not consider the anaphoricuse of numeral classifiers.
Although there wereninny anaphoric examples, resolving them requiresrobust anaphor esolution, which is a separate prob-lem.
We estimate that we would achieve the sameaccuracy with the anaphoric examples if their ref-erents were known, unfortunately the test set didnot always include the full context, so we could notidentify the referents and test this.
A typical exam-ple of anaphoric use is (10).
(1o) shukka-ga ruiseki-de 500-hon-woshipment-NOM cumulative 500-CL-ACCtoppa-shitaroachedCumulative shipments reached 500 ?bar-rels/rolls/logs/...In total, there were 90 noun phrases modified by asortal classilier.
Our test of the algoritlml was doneby hand, as we have no Japanese generator.
We as-sumed as input only the fact that a classifier wasrequired, and the semantic lasses of the head noungiven in the lexicon.
Using only the default classi-tiers predicted by the senmntic lass, we were ableto generate 73 (81%) correctly.
A classifier was onlyjudged to be correct if it was exactly the stone asthat in the original test set.
This was ahnost doublethe base line of generating the most common clas-sifter (-nin) for all noun phrases, which would haveachieved 41%.
The results, with a breakdown of theerrors, are summarized in Table 2.In this small sample, 6 out of 90 (6.7%) of nounphrases needed to have tim default classifier markedfor the nouu.
In fact, there were only 4 differentnouns, as two were repeated.
We therefore stinmtethat fewer than 6% of nouns will need to have theirown default classifier marked.
Had the default clas-sifier for these nouns been marked in the lexicon,our accuracy would have been 88%, the maxinmmachievable for our method.94CI.ASSIFIER P, eferents class|lied Semantic Class (2,710) Noun (172,506)No.
% Example No.
%None Uncountable referents 794 29.3 3 : agent  34,548 20.0-kai (IN) events 703 25.9 1699 :v i s i t  35,050 20.3-tsu (O) abstract/general objects 565 20.9 2 : concrete  52,921 30.1-nin (J,,) person 298 11.0 5 :person 8,545 4.9-ko ({\])iI) concrete objecls 124 4.6 854 : ed ib le  f ru i t  14,380 8.3-hen (J?)
long thin objecls 52 1.9 673 : t ree  3,775 2.1-mai (~)  fiat objecls 32 1.2 7 70 : paper  2,807 1.6-teki (}l',;~J) liquid 21 0.8 652 : tear  1,219 0.7-dai (?i't) lnechanic itclnS/furniture 18 0.7 9 62 : mach inery  5,087 2.9-hiki (l;ri) animals 12 0.6 537 :beast  1,361 0.8Other 38 classifiers 91 3.4 12,813 7.4Table 1 : Japanese Numeral Classiliers and associated Semantic ClassesP, esult % No.Correctly generated 81% 73Incorrectly generated 19% 17Total 100% 90Breakdown o1' En'orsNoun needs default classilier - -  6Target not in lexicon, bad entry 4()ther errors 7Table 2: P, esults of atplying the algorilhmLooking at it from allolher point of view, theGoi-Taikei ontology, although initially designed i'or.lapanese analysis, was also useftfl for generatingJapanese numeral chtssifiers.
We consider that itwould be equally useful for the same task with Ko-l'can, or even lhe tmrelaled language Mahty.We generated the residual classilier -tsu for nounsnot in the lexicon, this proved to be a bad choicelbr three unknown words.
If we had a me(hod o1:deducing senlanlic chtsses for tlnknown words wccouM have used it to predict the classiiicr moresuccessfully.
1;or example, kikan-l&vhika "insti-tutional investor ''5 was not in the dictionary, andso we used the senmntic class for lOshika "in-vestor", which was 175 : investor ,  a sub-typeof 5 :person .
Had kikan-toshika "institutionalinvestor" been marked as a subtype of company,or if we had deduced the semantic lass from themodifier, then we would have been able to gener-5hmlitufional illvcStOl'S are \[inancial institutions tha!
investsavin~,s of individuals and non-lina.ncial companies in the fi-nancial nmrkets.ate tho correct classifior -sha.
In ono case, wc feltlho default ordering of the semantic lasses shouldhave been reversed: 673: t ree  was listed before854 : ed ib le  f ru i t  for ringo "apple".The remaining errors were moro problematic.There was one cxamplc, 80,O00-nin-amari-no.vl,#nlei "about 80,000 signatures", wlfich could beueated as rel:ercnt tlansfof: shomei "signature"was being counted wilh the classifier for people.Another l)ossiblc analysis is that the classilier isthe head of a referential noun phrase with deic-tic/almphoric reference, equivalent to the si,qnaluJwsoJ'ahold SO, 000 people.
A COUlJe were quile literaryin slylc: for example lOnen-no loshi "10 years (Lit:10 years of years)", where the loshi "year" lmrt isredundant, and would not normally be used.
in twoof the errors the residual classilier was used insteadof (he more specific default.
Shhnoio (1997) prc~dicls flint this will happen in expressions where lheamot ln l  is being emphasized more than what is be-ing counted.
Intuitively, lifts applied in both cases,but we were ul\]able to identify any features we couldexploit 1o make this judgment autolnatically.A more adwmced semantic analysis may be ablelo dynamically delermine the appropriate semanticclass for cases of rel'ercnt transfer, unknown words,or words whose semantic lass can be restricted bycontext Our algorithm, which ideally generates theclassifier from this dynamically determined seman-tic class allows us to generate the correct classilierin context, whereas using a default listed for a noundoes not.
This was our original mot|wit|on 1'oi" gen-erating chtssitiers 1?o111 seman(ic lasses, rather thanusing a classifier lis(ed wilh each noun as Sornlert-95lamvanich et al (1994) do.In this paper we have concentrated on solvingthe problem of generating appropriate Japanese nu-meral classifiers using an ontology.
11\] future work,we would like to investigate in more detail the con-ditions under which a classifier needs to be gener-ate&6 ConclusionIn this paper, we presented an algorithm to generateJapanese numeral classifiers.
It was shown to selectthe correct sortal classifier 81% of the time.
The al-gorithm uses the ontology provided by Goi-Taikei,a Japanese lexicon, and shows how accurately se-mantic lasses can predict numeral classifiers for thenouns they subsume.
We also show how we canimprove the accuracy and efficiency ftmher throughsolving other natural language processing problems,in particular, referent ransfer, anaphor esolutionand word sense disambiguation.AcknowledgmentsThe authors thank Kentaro Ogura, Timothy Bald-win, Virach Sornlertlamvanich and the anonymousreviewers for their helpful comments.ReferencesYoshimi Asahioka, Hideki Hirakawa, and Shin-yaAmano.
1990.
Semantic lassification and ananalyzing system of Japanese numerical expres-sions.
1PSJ SIG Notes 90-NL-78, 90(64):129-136, July.
(in Japanese).A.
E. Backhouse.
1993.
The Japatwse Language:An h~troduction.
Oxford University Press.Francis Bond and Kyonghee Paik.
1997.
Classify-ing correspondence in Japanese and Korean.
In3rd Pacific Association for Computational Lin-guistics Conference: PACLING-97, pages 58-67.Meisei University, Tokyo, Japan.Francis Bond, Kentaro Ogura, and Satom Ikehara.1996.
Classifiers in Japanese-to-English machinetranslation.
In 16th International Coqference onComputational Linguistics: COLING-96, pages125-130, Copenhagen, August.
(h t tp : / /xxx.
lanl.
gov/abs/cmp- ig/9608014).Francis Bond, Daniela Kurz, and Satoshi Shirai.1998.
Anchoring floating quantifiers in Japanese-to-English machine translation.
In 36th AnmtalMeeting of the Association .for ComputationalLinguistics and 17th hzternational Conferenceon Computational Linguistics: COLING/ACL-98, pages 152-159, Montreal, Canada.Pamela Downing.
1996.
Nunwral Class(tier Sys-tems, the case of Japanese.
Jolm Benjamins, Am-sterdam.Christine Fellbamn, editor.
1998.
WordNet: AnElectronic Lexical Database.
MIT Press.Satoru Ikehara, Masahiro Miyazaki, Satoshi Shirai,Akio Yokoo, Hiromi Nakaiwa, Kentaro Ogura,Yoshifumi Ooyama, and Yoshihiko Hayashi.1997.
Goi-Taikei - -  A Japanese Lexicon..Iwanami Shoten, Tokyo.
5 volumes/CDROM.Shin-ichiro Kamei and Kazunori Muraki.
1995.
Ananalysis of NP-like quantifiers in Japanese.
InFirst Natural l_zmguage Processing Pactific RimSymposium: NLPRS-95, volume 1, pages 163-167.Sergei Nirenburg.
1989.
KBMT-89 - -  aknowledge-based MT proiect at CarnegieMellon University.
pages 141-147, Aug. 16-18.James Pusteiovsky.
1995.
The Generative Lexicon.MIT Press.Mitsuaki Shimojo.
1997.
The role of the generalcategory in the maintenance of numeral classi-fier systems: The case of tsu and ko in Japanese.Linguistics, 35(4).
(h t tp  : / / i f rm.
g locom.ac.
jp/doc/sOl.
001 .html).Virach Sornlertlamvanich, Wantanee Pantachat,and Surapant Meknavin.
1994.
Classifierassignment by corpus-based approach.
In15th International Conference on Computa-tional Linguistics: COLING-94, pages 556-561, August.
(h t tp : / /xxx .
lan l .gov /abs/cmp- ig/9411027).Shoichi Yokoyalna and Takeru Ochiai.
1999.Aimai-na sfiry6shi-o fukumu meishiku-nokaisekih6 \[a method for analysing noun phraseswith ambiguous quantifiers.\].
In 5th AlmualMeeting of the Association for Natural LzmguageProcessing, pages 550-553.
The Association forNatural Language Processing.
(in Japanese).,+a:~--:~,5o NNT ' JZNN,~N~,  q~NN, t37%, 6 %~cr)~l~l ,~Uc  r) b'~Jb~'\[~l~%-5:96
