Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 635?643,Beijing, August 2010Sentiment Classification and Polarity ShiftingShoushan Li??
Sophia Yat Mei Lee?
Ying Chen?
Chu-Ren Huang?
Guodong Zhou?
?Department of CBSThe Hong Kong Polytechnic University{shoushan.li, sophiaym,chenying3176, churenhuang}@gmail.com?Natural Language Processing LabSchool of Computer Science andTechnologySoochow Universitygdzhou@suda.edu.cnAbstractPolarity shifting marked by variouslinguistic structures has been a challengeto automatic sentiment classification.
Inthis paper, we propose a machine learningapproach to incorporate polarity shiftinginformation into a document-levelsentiment classification system.
First, afeature selection method is adopted toautomatically generate the training datafor a binary classifier on polarity shiftingdetection of sentences.
Then, by using theobtained binary classifier, each documentin the original polarity classificationtraining data is split into two partitions,polarity-shifted and polarity-unshifted,which are used to train two baseclassifiers respectively for furtherclassifier combination.
The experimentalresults across four different domainsdemonstrate the effectiveness of ourapproach.1 IntroductionSentiment classification is a special task of textclassification whose objective is to classify a textaccording to the sentimental polarities ofopinions it contains (Pang et al, 2002), e.g.,favorable or unfavorable, positive or negative.This task has received considerable interests inthe computational linguistic community due to itspotential applications.In the literature, machine learning approacheshave dominated the research in sentimentclassification and achieved the state-of-the-artperformance (e.g., Kennedy and Inkpen, 2006;Pang et al, 2002).
In a typical machine learningapproach, a document (text) is modeled as abag-of-words, i.e.
a set of content words withoutany word order or syntactic relation information.In other words, the underlying assumption is thatthe sentimental orientation of the whole textdepends on the sum of the sentimental polaritiesof content words.
Although this assumption isreasonable and has led to initial success, it islinguistically unsound since many functionwords and constructions can shift thesentimental polarities of a text.
For example, inthe sentence ?The chair is not comfortable?, thepolarity of the word ?comfortable?
is positivewhile the polarity of the whole sentence isreversed because of the negation word ?not?.Therefore, the overall sentiment of a document isnot necessarily the sum of the content parts(Turney, 2002).
This phenomenon is one mainreason why machine learning approaches failunder some circumstances.As a typical case of polarity shifting, negationhas been paid close attention and widely studiedin the literature (Na et al, 2004; Wilson et al,2009; Kennedy and Inkpen, 2006).
Generally,there are two steps to incorporate negationinformation into a system: negation detectionand negation classification.
For negationdetection, some negation trigger words, such as?no?, ?not?, and ?never?, are usually applied torecognize negation phrases or sentences.
As fornegation classification, one way to importnegation information is to directly reverse thepolarity of the words which contain negationtrigger words as far as term-counting approachesare considered (Kennedy and Inkpen, 2006).
Analternative way is to add some negation features(e.g., negation bigrams or negation phrases) into635machine learning approaches (Na et al, 2004).Such approaches have achieved certain success.There are, however, some shortcomings withcurrent approaches in incorporating negationinformation.
In terms of negation detection,firstly, the negation trigger word dictionary iseither manually constructed or relies on existingresources.
This leads to certain limitationsconcerning the quality and coverage of thedictionary.
Secondly, it is difficult to adaptnegation detection to other languages due to itslanguage dependence nature of negationconstructions and words.
Thirdly, apart fromnegation, many other phenomena, e.g., contrasttransition with trigger words like ?but?,?however?, and ?nevertheless?, can shift thesentimental polarity of a phrase or sentence.Therefore, considering negation alone isinadequate to deal with the polarity shiftingproblem, especially for document-levelsentiment classification.In terms of negation classification, although itis easy for term-counting approaches to integratenegation information, they rarely outperform amachine learning baseline (Kennedy and Inkpen,2006).
Even for machine learning approaches,although negation information is sometimeseffective for local cases (e.g., not good), it failson long-distance cases (e.g., I don?t think it isgood).In this paper, we first propose a featureselection method to automatically generate alarge scale polarity shifting training data forpolarity shifting detection of sentences.
Then, aclassifier combination method is presented forincorporating polarity shifting information.Compared with previous ones, our approachhighlights the following advantages?First of all,we apply a binary classifier to detect polarityshifting rather than merely relying on triggerwords or phrases.
This enables our approach tohandle different kinds of polarity shiftingphenomena.
More importantly, a featureselection method is presented to automaticallygenerate the labeled training data for polarityshifting detection of sentences.The remainder of this paper is organized asfollows.
Section 2 introduces the related work ofsentiment classification.
Section 3 presents ourapproach in details.
Experimental results arepresented and analyzed in Section 4.
Finally,Section 5 draws the conclusion and outlines thefuture work.2 Related WorkGenerally, sentiment classification can beperformed at four different levels: word level(Wiebe, 2000), phrase level (Wilson et al, 2009),sentence level (Kim and Hovy, 2004; Liu et al,2005), and document level (Turney, 2002; Panget al, 2002; Pang and Lee, 2004; Riloff et al,2006).
This paper focuses on document-levelsentiment classification.In the literature, there are mainly two kinds ofapproaches on document-level sentimentclassification: term-counting approaches(lexicon-based) and machine learningapproaches (corpus-based).
Term-countingapproaches usually involve deriving a sentimentmeasure by calculating the total number ofnegative and positive terms (Turney, 2002; Kimand Hovy, 2004; Kennedy and Inkpen, 2006).Machine learning approaches recast thesentiment classification problem as a statisticalclassification task (Pang and Lee, 2004).Compared to term-counting approaches,machine learning approaches usually achievemuch better performance (Pang et al, 2002;Kennedy and Inkpen, 2006), and have beenadopted to more complicated scenarios, such asdomain adaptation (Blitzer et al, 2007),multi-domain learning (Li and Zong, 2008) andsemi-supervised learning (Wan, 2009; Dasguptaand Ng, 2009) for sentiment classification.Polarity shifting plays a crucial role inphrase-level, sentence-level, and document-levelsentiment classification.
However, most ofprevious studies merely focus on negationshifting (polarity shifting caused by the negationstructure).
As one pioneer research on sentimentclassification, Pang et al (2002) propose amachine learning approach to tackle negationshifting by adding the tag ?not?
to every wordbetween a negation trigger word/phrase (e.g., not,isn't, didn't, etc.)
and the first punctuation markfollowing the negation trigger word/phrase.
Totheir disappointment, considering negationshifting has a negligible effect and even slightlyharms the overall performance.
Kennedy andInkpen (2006) explore negation shifting byincorporating negation bigrams as additionalfeatures into machine learning approaches.
The636experimental results show that consideringsentiment shifting greatly improves theperformance of term-counting approaches butonly slightly improves the performance ofmachine learning approaches.
Other studies suchas Na et al (2004), Ding et al (2008), and Wilsonet al (2009) also explore negation shifting andachieve some improvements1.
Nonetheless, as faras machine learning approaches are concerned,the improvement is rather insignificant (normallyless than 1%).
More recently, Ikeda et al (2008)first propose a machine learning approach todetect polarity shifting for sentence-levelsentiment classification, based on amanually-constructed dictionary containingthousands of positive and negative sentimentalwords, and then adopt a term-counting approachto incorporate polarity shifting information.3 Sentiment Classification with PolarityShifting DetectionFigure 1: General framework of our approachThe motivation of our approach is to improve theperformance of sentiment classification by robusttreatment of sentiment polarity shifting betweensentences.
With the help of a binary classifier, thesentences in a document are divided into twoparts: sentences which contain polarity shiftingstructures and sentences without any polarityshifting structure.
Figure 1 illustrates the generalframework of our approach.
Note that thisframework is a general one, that is, differentpolarity shifting detection methods can be appliedto differentiate polarity-shifted sentences fromthose polarity-unshifted sentences and different1Note that Ding et al (2006) also consider but-clause, anotherimportant structure for sentiment shifting.
Wilson et al (2009) useconjunctive and dependency relations among polarity words.polarity classification methods can be adopted toincorporate sentiment shifting information.
Forclarification, the training data used for polarityshifting detection and polarity classification arereferred to as the polarity shifting training dataand the polarity classification training data,respectively.3.1 Polarity Shifting DetectionIn this paper, polarity shifting means that thepolarity of a sentence is different from thepolarity expressed by the sum of the contentwords in the sentence.
For example, in thesentence ?I am not disappointed?, the negationstructure makes the polarity of the word'disappointed' different from that of the wholesentence (negative vs. positive).
Apart from thenegation structure, many other linguisticstructures allow polarity shifting, such ascontrast transition, modals, andpre-suppositional items (Polanyi and Zaenen,2006).
We refer these structures as polarityshifting structures.One of the great challenges in building apolarity shifting detector lies on the lack ofrelevant training data since manually creating alarge scale corpus of polarity shifting sentencesis time-consuming and labor-intensive.
Ikeda etal.
(2008) propose an automatic way forcollecting the polarity shifting training databased on a manually-constructed large-scaledictionary.
Instead, we adopt a feature selectionmethod to build a large scale training corpus ofpolarity shifting sentences, given only thealready available document-level polarityclassification training data.
With the help of thefeature selection method, the top-ranked wordfeatures with strong sentimental polarityorientation, e.g., ?great?, ?love?, ?worst?
are firstchosen as the polarity trigger words.
Then, thosesentences with the top-ranked polarity triggerwords in both categories of positive and negativedocuments are selected.
Finally, those candidatesentences taking opposite-polarity compared tothe containing trigger word are deemed aspolarity-shifted.The basic idea of automatically generating thepolarity shifting training data is based on theassumption that the real polarity of a word orphrase is decided by the major polarity categorywhere the word or phrase appears more often.
Asa result, the sentences in thePolarity ShiftingDetectorDocumentsPolarity-shiftedSentencesPolarity-unshiftedSentencesPolarity Classifier Positive/Negative637frequently-occurring category would be seen aspolarity-unshifted while the sentences in theinfrequently-occurring category would be seenas polarity-shifted.In the literature, various feature selectionmethods, such as Mutual Information (MI),Information Gain (IG) and Bi-Normal Separation(BNS) (Yang and Pedersen, 1997; Forman 2003),have been employed to cope with the problem ofthe high-dimensional feature space which isnormal in sentiment classification.In this paper, we employ the theoreticalframework, proposed by Li et al (2009),including two basic measurements, i.e.
frequencymeasurement and ratio measurement, where thefirst measures, the document frequency of a termin one category, and the second measures, theratio between the document frequency in onecategory and other categories.
In particular, anovel method called Weighed Frequency andOdds (WFO) is proposed to incorporate bothbasic measurements:1( | )( , ) ( | ) {max(0, log )}( | )ii iiP t cWFO t c P t cP t c?
?
?=where ( | )iP t c  denotes the probability that adocument x contains the term t with thecondition that x belongs to category ic ;( | )iP t c  denotes the probability that a documentx contains the term t with the condition that xdoes not belong to category ic .
The left part ofthe formula ( | )iP t c  implies the first basicmeasurement and the right partlog( ( | ) / ( | ))i iP t c P t c  implies the second one.The parameter ?
0 1??
??
?is thus to tune theweight between the two basic measurements.Especially, when ?
equals 0, the WFO methodfades to the MI method which fully prefers thesecond basic measurement.Figure 2 illustrates our algorithm forautomatically generating the polarity shiftingtraining data where 1c and 2c denote the twosentimental orientation categories, i.e.
negativeand positive.
Step A segments a document intosentences with punctuations.
Besides, twospecial words, ?but?
and ?and?, are used tofurther segment some contrast transitionstructures and compound sentences.
Step Bemploys the WFO method to rank all featuresincluding the words.
Step D extracts thosepolarity-shifted and polarity-unshifted sentencescontaining top it ?
where maxN denotes theupper-limit number of sentences in eachcategory of the polarity shifting training data and#(x) denotes the total number of the elements inx.
Apart from that, the first word in the followingsentence is also included to capture a commonkind of long-distance polarity shifting structure:contrast transition.
Thus, important trigger wordslike ?however?
and ?but?
may be considered.Finally, Step E guarantees the balance betweenthe two categories of the polarity shiftingtraining data.Given the polarity shifting training data, weapply SVM classification algorithm to train apolarity-shifting detector with word unigramfeatures.Input:The polarity classification training data: the negativesentimental document set1cD and the positive sentimentaldocument set2cD .Output:The polarity shifting training data: thepolarity-unshifted sentence set unshiftS  and the polarity-shifted sentence setshiftS .Procedure:A.
Segment documents1cD  and2cD  to singlesentences1cS  and2cS .B.
Apply feature selection on the polarity classificationtraining data and get the ranked features,1( ,..., ,..., )top top i top Nt t t?
?
?C.
shiftS  = {}, unshiftS  = {}D. For  top it ?
in  1( ,..., ,..., )top top i top Nt t t?
?
?
:D1) if #( shiftS )> maxN : breakD2) Collect all sentences1,top i cS?and2,top i cS?which contain  top it ?
from  1cS  and  2cSrespectivelyD3)  if #(1,top i cS?
)>#(2,top i cS?
):put2,top i cS?into  shiftSput1,top i cS?into  unshiftSelse:put1,top i cS?into  shiftSput2,top i cS?into  unshiftSE.
Randomly selectmaxN sentences from unshiftS as theoutput ofunshiftSFigure 2: The algorithm for automaticallygenerating the polarity shifting training data6383.2 Polarity Classification with ClassifierCombinationAfter polarity shifting detection, each documentin the polarity classification training data isdivided into two parts, one containingpolarity-shifted sentences and the othercontaining polarity-unshifted sentences, whichare used to form the polarity-shifted training dataand the polarity-unshifted training data.
In thisway, two different polarity classifiers, If  and2f , can be trained on the polarity-shiftedtraining data and the polarity-unshifted trainingdata respectively.
Along with classifier 3f ,trained on all original polarity classificationtraining data, we now have three base classifiersin hand for possible classifier combination via amultiple classifier system.The key issue in constructing a multipleclassifier system (MCS) is to find a suitable wayto combine the outputs of the base classifiers.
InMCS literature, various methods are availablefor combining the outputs, such as fixed rulesincluding the voting rule, the product rule andthe sum rule (Kittler et al, 1998) and trainedrules including the weighted sum rule (Fumeraand Roli, 2005) and the meta-learningapproaches (Vilalta and Drissi, 2002).
In thisstudy, we employ the product rule, a popularfixed rule, and stacking (D?eroski and ?enko,2004), a well-known trained rule, to combine theoutputs.Formally, each base classifier provides somekind of confidence measurements, e.g., posteriorprobabilities of the test sample belonging to eachclass.
Formally, each base classifier( 1,2,3)lf l =  assigns a test sample (denoted aslx ) a posterior probability vector ( )lP x:1 2( ) ( | ), ( | ))tl l lP x p c x p c x= (where 1( | )lp c x  denotes the probability that the-thl base classifier considers the samplebelonging 1c .The product rule combines the base classifiersby multiplying the posterior possibilities andusing the multiplied possibility for decision, i.e.31arg max ( | )j i li lassign y c when j p c x=?
= ?Stacking belongs to well-knownmeta-learning (Vilalta and Drissi, 2002).
Thekey idea behind meta-learning is to train ameta-classifier with input attributes that are theoutputs of the base classifiers.
Hence,meta-learning usually needs some developmentdata for generating the meta-training data.
Let'x  denote a feature vector of a sample from thedevelopment data.
The output of the -thl baseclassifier lf on this sample is the probabilitydistribution over the category set 1 2{ , }c c , i.e.1 2( ' ) ( ( | ' ), ( | ' ))l l l lP x p c x p c x=A meta-classifier can be trained using thedevelopment data with the meta-level featurevector 2 3metax R ?
?1 2 3( ( ' ), ( ' ), ( ' ))meta l l lx P x P x P x= = ==  Stacking is a specific meta-learning rule, inwhich a leave-one-out or a cross-validationprocedure on the training data is applied togenerate the meta-training data instead of usingextra development data.
In our experiments, weperform stacking with 10-fold cross-validation togenerate the meta-training data.4 Experimentation4.1 Experimental SettingThe experiments are carried out on productreviews from four domains: books, DVDs,electronics, and kitchen appliances (Blitzer et al,2007)2.
Each domain contains 1000 positive and1000 negative reviews.For sentiment classification, all classifiersincluding the polarity shifting detector, threebase classifiers and the meta-classifier instacking are trained by SVM using theSVM-light tool 3  with Logistic Regressionmethod for probability measuring (Platt, 1999).In all the experiments, each dataset israndomly and evenly split into two subsets: 50%documents as the training data and the remaining50% as the test data.
The features include wordunigrams and bigrams with Boolean weights.4.2 Experimental Results on PolarityShifting DataTo better understand the polarity shiftingphenomena in document-level sentimentclassification, we randomly investigate 2002This data set is collected by Blitzer et al (2007):http://www.seas.upenn.edu/~mdredze/datasets/sentiment/3It is available at: http://svmlight.joachims.org/639polarity-shifted sentences, together with theircontexts (i.e.
the sentences before and after it),automatically generated by the WFO ( 0?
= )feature selection method.
We find that nearlyhalf of the automatically generated polarity-shifted sentences are actually polarity-unshiftedsentences or difficult to decide.
That is to say,the polarity shifting training data is noisy tosome extent.
One main reason is that someautomatically selected trigger words do notreally contain sentiment information, e.g., ?hear?,?information?
etc.
Another reason is that somereversed opinion is given in a review withoutany explicit polarity shifting structures.To gain more insights, we manually checked100 sentences which are explicitlypolarity-shifted and can also be judged byhuman according to their contexts.
Table 1presents some typical structures causing polarityshifting.
It shows that the most common polarityshifting type is Explicit Negation (37%), usuallyexpressed by trigger words such as ?not?, ?no?, or?without?, e.g., in the sentence ?I am not happywith this flashcard at all?.
Another common typeof polarity shifting is Contrast Transition (20%),expressed by trigger words such as ?however?,e.g., in the sentence ?It is large and stylish,however, I cannot recommend it because of thelid?.
Other less common yet productive polarityshifting types include Exception and Until.Exception structure is usually expressed by thetrigger phrase ?the only?
to indicate the one andonly advantage of the product, e.g., in thesentence ?The only thing that I like about it isthat bamboo is a renewable resource?.
Untilstructure is often expressed by the trigger word?until?
to show the reversed polarity, e.g.
in thesentence ?This unit was a great addition until theprobe went bad after only a few months?.Polarity ShiftingStructuresTriggerWords/PhrasesDistribution(%)Explicit Negation not, no, without 37Contrast Transition but, however,unfortunately20Implicit Negation avoid, hardly,  7False Impression look, seem 6Likelihood probably, perhaps 5Counter-factual should, would 5Exception the only 5Until until 3Table 1: Statistics on various polarity shiftingstructures4.3 Experimental Results on PolarityClassificationFor comparison, several classifiers with differentclassification methods are developed.1) Baseline classifier, which applies SVM withall unigrams and bigrams.
Note that it alsoserves as a base classifier in the followingcombined classifiers.2) Base classifier 1, a base classifier for theclassifier combination method.
It works on thepolarity-unshifted data.3) Base classifier 2, another base classifier forthe classifier combination method.
It works onthe polarity-shifted data.4) Negation classifier, which applies SVM withall unigrams and bigrams plus negation bigrams.It is a natural extension of the baseline classifierwith the consideration of negation bigrams.
Inthis study, the negation bigrams are collectedusing some negation trigger words, such as ?not?and ?never?.
If a negation trigger word is foundin a sentence, each word in the sentence isattached with the word ?_not?
to form a negationbigram.5) Product classifier, which combines thebaseline classifier, the base classifier 1 and thebase classifier 2 using the product rule.6) Stacking classifier, a combined classifiersimilar to the Product classifier.
It uses thestacking classifier combination method insteadof the product rule.Please note that we do not compare our approachwith the one as proposed in Ikeda et al (2008)due to the absence of a manually-collectedsentiment dictionary.
Besides, it is well knownthat a combination strategy itself is capable ofimproving the classification performance.
Tojustify whether the improvement is due to thecombination strategy or our polarity shiftingdetection or both, we first randomly split thetraining data into two portions and train two baseclassifiers on each portion, then apply thestacking method to combine them along with thebaseline classifier.
The corresponding results areshown as ?Random+Stacking?
in Table 2.
Finally,in our experiments, t-test is performed toevaluate the significance of the performanceimprovement between two systems employingdifferent methods (Yang and Liu, 1999).640Domain Baseline BaseClassifier1BaseClassifier2NegationClassifierRandom+StackingShifting+ProductShifting+StackingBook 0.755 0.756 0.670 0.759 0.764 0.772 0.785DVD 0.750 0.743 0.667 0.748 0.759 0.768 0.770Electronic 0.779 0.786 0.711 0.785 0.789 0.820 0.830Kitchen 0.818 0.814 0.683 0.826 0.835 0.840 0.849Table 2: Performance comparison of different classifiers with equally-splitting between training and test dataPerformance comparison of differentclassifiersTable 2 shows the accuracy results of differentmethods using 2000 polarity shifted sentencesand 2000 polarity-unshifted sentences to train thepolarity shifting detector (Nmax=2000).
Comparedto the baseline classifier, it shows that: 1) Thebase classifier 1, which only uses thepolarity-unshifted sentences as the training data,achieves similar performance.
2)  The baseclassifier 2 achieves much lower performancedue to much fewer sentences involved.
3)Including negation bigrams usually allowsinsignificant improvements (p-value>0.1), whichis consistent with most of previous works (Panget al, 2002; Kennedy and Inkpen, 2006).
4) Boththe product and stacking classifiers with polarityshifting detection significantly improve theperformance (p-value<0.05).
Compared to theproduct rule, the stacking classifier is preferable,probably due to the performance unbalanceamong the individual classifiers, e.g., theperformance of the base classifier 2 is muchlower than the other two.
Although stacking withtwo randomly generated base classifiers, i.e.
?Random + Stacking?, also consistentlyoutperforms the baseline classifier, theimprovements are much lower than what hasbeen achieved by our approach.
This suggeststhat both the classifier combination strategy andpolarity shifting detection contribute to theoverall performance improvement.Effect of WFO feature selection methodFigure 3 presents the accuracy curve of thestacking classifier when using different Lambda( ? )
values in the WFO feature selection method.It shows that those feature selection methodswhich prefer frequency information, e.g., MI andBNS, are better in automatically generating thepolarity shifting training data.
This is reasonablesince high frequency terms, e.g., ?is?, ?it?, ?a?,etc., tend to obey our assumption that the realpolarity of one top term should belong to thepolarity category where the term appearsfrequently.Performance of the Stacking Classifier0.720.740.760.780.80.820.840.86Lambda=0 0.25 0.5 0.75 1AccuracyBook DVD Electronic KitchenFigure 3: Performance of the stacking classifier usingWFO with different Lambda ( ? )
valuesPerformance of the Stacking Classifier0.720.740.760.780.80.820.840.86200 500 1000 1500 2000 3000 4000 6000 8000AccuracyBook DVD Electronic KitchenFigure 4: Performance of the stacking classifier overdifferent sizes of the polarity shifting training data(with Nmax sentences in each category)Effect of a classifier over different sizes of thepolarity shifting training dataAnother factor which might influence theoverall performance is the size of the polarityshifting training data.
Figure 4 presents theoverall performance on different numbers of thepolarity shifting sentences when using thestacking classifier.
It shows that 1000 to 4000sentences are enough for the performanceimprovement.
When the number is too large, thenoisy training data may harm polarity shiftingdetection.
When the number is too small, it is notenough for the automatically generated polarityshifting training data to capture various polarityshifting structures.64130% 40% 50% 60% 70% 80% 90% 100%0.60.650.70.750.8Domain: BookThe traning data sizesAccuracyBaseline BaseClassifier 1 BaseClassifier 2 Stacking30% 40% 50% 60% 70% 80% 90% 100%0.60.650.70.750.8Domain: DVDThe traning data sizesAccuracy30% 40% 50% 60% 70% 80% 90% 100%0.650.70.750.80.850.9Domain: ElectronicThe traning data sizesAccuracy30% 40% 50% 60% 70% 80% 90% 100%0.650.70.750.80.850.9Domain: KitchenThe traning data sizesAccuracyFigure 5: Performance of different classifiers over different sizes of the polarity classification training dataEffect of different classifiers over differentsizes of the polarity classification training dataFigure 5 shows the classification results ofdifferent classifiers with varying sizes of thepolarity classification training data.
It shows thatour approach is able to improve the overallperformance robustly.
We also notice the bigdifference between the performance of thebaseline classifier and that of the base classifier1 when using 30% training data in Book domainand 90% training data in DVD domain.
Detailedexploration of the polarity shifting sentences inthe training data shows that this difference ismainly attributed to the poor performance of thepolarity shifting detector.
Even so, the stackingclassifier guarantees no worse performance thanthe baseline classifier.5 Conclusion and Future WorkIn this paper, we propose a novel approach toincorporate polarity shifting information intodocument-level sentiment classification.
In ourapproach, we first propose amachine-learning-based classifier to detectpolarity shifting and then apply two classifiercombination methods to perform polarityclassification.
Particularly, the polarity shiftingtraining data is automatically generated througha feature selection method.
As shown in ourexperimental results, our approach is able toconsistently improve the overall performanceacross different domains and training data sizes,although the automatically generated polarityshifting training data is prone to noise.Furthermore, we conclude that those featureselection methods, which prefer frequencyinformation, e.g., MI and BNS, are good choicesfor generating the polarity shifting training data.In our future work, we will explore betterways in generating less-noisy polarity shiftingtraining data.
In addition, since our approach islanguage-independent, it is readily applicable tosentiment classification tasks in other languages.For availability of the automatically generatedpolarity shifting training data, please contact thefirst author (for research purpose only).AcknowledgmentsThis research work has been partially supportedby Start-up Grant for Newly AppointedProfessors, No.
1-BBZM in the Hong KongPolytechnic University and two NSFC grants,No.
60873150 and No.
90920004.
We also thankthe three anonymous reviewers for their helpfulcomments.642ReferencesBlitzer J., M. Dredze, and F. Pereira.
2007.Biographies, Bollywood, Boom-boxes andBlenders: Domain Adaptation for SentimentClassification.
In Proceedings of ACL-07.Dasgupta S. and V. Ng.
2009.
Mine the Easy andClassify the Hard: Experiments with AutomaticSentiment Classification.
In Proceedings ofACL-IJCNLP-09.Ding X., B. Liu, and P. Yu.
2008.
A HolisticLexicon-based Approach to Opinion Mining.
InProceedings of the International Conference onWeb Search and Web Data Mining, WSDM-08.D?eroski S. and B.
?enko.
2004.
Is CombiningClassifiers with Stacking Better than Selecting theBest One?
Machine Learning, vol.54(3),pp.255-273, 2004.Forman G. 2003.
An Extensive Empirical Study ofFeature Selection Metrics for Text Classification.The Journal of Machine Learning Research, 3(1),pp.1289-1305.Fumera G. and F. Roli.
2005.
A Theoretical andExperimental Analysis of Linear Combiners forMultiple Classifier Systems.
IEEE Trans.
PAMI,vol.27, pp.942?956, 2005Ikeda D., H. Takamura, L. Ratinov, and M. Okumura.2008.
Learning to Shift the Polarity of Words forSentiment Classification.
In Proceedings ofIJCNLP-08.Kennedy, A. and D. Inkpen.
2006.
SentimentClassification of Movie Reviews using ContextualValence Shifters.
Computational Intelligence,vol.22(2), pp.110-125, 2006.Kim S. and E. Hovy.
2004.
Determining theSentiment of Opinions.
In Proceedings ofCOLING-04.Kittler J., M. Hatef, R. Duin, and J. Matas.
1998.
OnCombining Classifiers.
IEEE Trans.
PAMI, vol.20,pp.226-239, 1998Li S., R. Xia, C. Zong, and C. Huang.
2009.
AFramework of Feature Selection Methods for TextCategorization.
In Proceedings ofACL-IJCNLP-09.Li S. and C. Zong.
2008.
Multi-domain SentimentClassification.
In Proceedings of ACL-08: HLT,short paper.Liu B., M. Hu, and J. Cheng.
2005.
Opinion Observer:Analyzing and Comparing Opinions on the Web.In Proceedings of WWW-05.Na J., H. Sui, C. Khoo, S. Chan, and Y. Zhou.
2004.Effectiveness of Simple Linguistic Processing inAutomatic Sentiment Classification of ProductReviews.
In Conference of the InternationalSociety for Knowledge Organization (ISKO-04).Pang B. and L. Lee.
2004.
A Sentimental Education:Sentiment Analysis using SubjectivitySummarization based on Minimum Cuts.
InProceedings of ACL-04.Pang B., L. Lee, and S. Vaithyanathan.
2002.
Thumbsup?
Sentiment Classification using MachineLearning Techniques.
In Proceedings ofEMNLP-02.Platt J.
1999.
Probabilistic Outputs for SupportVector Machines and Comparisons to RegularizedLikelihood Methods.
In: A. Smola, P. Bartlett, B.Schoelkopf and D. Schuurmans (Eds.
): Advancesin Large Margin Classiers.
MIT Press, Cambridge,61?74.Polanyi L. and A. Zaenen.
2006.
Contextual ValenceShifters.
Computing attitude and affect in text:Theory and application.
Springer Verlag.Riloff E., S. Patwardhan, and J. Wiebe.
2006.
FeatureSubsumption for Opinion Analysis.
InProceedings of EMNLP-06.Turney P. 2002.
Thumbs Up or Thumbs Down?Semantic Orientation Applied to UnsupervisedClassification of Reviews.
In Proceedings ofACL-02.Vilalta R. and Y. Drissi.
2002.
A Perspective Viewand Survey of Meta-learning.
ArtificialIntelligence Review, 18(2), pp.
77?95.Wan X.
2009.
Co-Training for Cross-LingualSentiment Classification.
In Proceedings ofACL-IJCNLP-09.Wiebe J.
2000.
Learning Subjective Adjectives fromCorpora.
In Proceedings of AAAI-2000.Wilson T., J. Wiebe, and P. Hoffmann.
2009.Recognizing Contextual Polarity: An Explorationof Features for Phrase-Level Sentiment Analysis.Computational Linguistics, vol.35(3), pp.399-433,2009.Yang Y. and X. Liu, X.
1999.
A Re-Examination ofText Categorization methods.
In Proceedings ofSIGIR-99.Yang Y. and J. Pedersen.
1997.
A Comparative Studyon Feature Selection in Text Categorization.
InProceedings of ICML-97.643
