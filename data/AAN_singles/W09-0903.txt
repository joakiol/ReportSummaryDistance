Proceedings of the EACL 2009 Workshop on Cognitive Aspects of Computational Language Acquisition, pages 18?25,Athens, Greece, 31 March 2009. c?2009 Association for Computational LinguisticsWhat?s in a Message?Stergos D. Afantenos and Nicolas HernandezLINA, (UMR CNRS 6241)Universit?
de Nantes, Francestergos.afantenos@univ-nantes.frnicolas.hernandez@univ-nantes.frAbstractIn this paper we present the first step in a largerseries of experiments for the induction of pred-icate/argument structures.
The structures thatwe are inducing are very similar to the con-ceptual structures that are used in Frame Se-mantics (such as FrameNet).
Those structuresare called messages and they were previouslyused in the context of a multi-document sum-marization system of evolving events.
The se-ries of experiments that we are proposing areessentially composed from two stages.
In thefirst stage we are trying to extract a represen-tative vocabulary of words.
This vocabularyis later used in the second stage, during whichwe apply to it various clustering approaches inorder to identify the clusters of predicates andarguments?or frames and semantic roles, touse the jargon of Frame Semantics.
This paperpresents in detail and evaluates the first stage.1 IntroductionTake a sentence, any sentence for that matter; step backfor a while and try to perceive that sentence in its mostabstract form.
What you will notice is that once youtry to abstract away sentences, several regularities be-tween them will start to emerge.
To start with, there isalmost always an action that is performed.1 Then, thereis most of the times an agent that is performing this ac-tion and a patient or a benefactor that is receiving thisaction, and it could be the case that this action is per-formed with the aid of a certain instrument.
In otherwords, within a sentence?and in respect to its action-denoting word, or predicate in linguistic terms?therewill be several entities that are associated with the pred-icate, playing each time a specific semantic role.The notion of semantic roles can be traced back toFillmore?s (1976) theory of Frame Semantics.
Accord-ing to this theory then, a frame is a conceptual structurewhich tries to describe a stereotypical situation, eventor object along with its participants and props.
Eachframe takes a name (e.g.
COMMERCIAL TRANSAC-TION) and contains a list of Lexical Units (LUs) which1In linguistic terms, an action-denoting word is alsoknown as a predicate.actually evoke this frame.
An LU is nothing else thana specific word or a specific meaning of a word in thecase of polysemous words.
To continue the previousexample, some LUs that evoke the frame of COMMER-CIAL TRANSACTION could be the verbs buy, sell,etc.
Finally, the frames contain several frame elementsor semantic roles which actually denote the abstractconceptual entities that are involved with the particu-lar frame.Research in semantic roles can be distinguished intotwo major branches.
The first branch of research con-sists in defining an ontology of semantic roles, theframes in which the semantic roles are found as well asdefining the LUs that evoke those frames.
The secondbranch of research, on the other hand, stipulates theexistence of a set of frames, including semantic rolesand LUs; its goal then, is the creation of an algorithmthat given such a set of frames containing the semanticroles, will be able to label the appropriate portions ofa sentence with the corresponding semantic roles.
Thissecond branch of research is known as semantic rolelabeling.Most of the research concerning the definition of thesemantic roles has been carried out by linguists who aremanually examining a certain amount of frames beforefinally defining the semantic roles and the frames thatcontain those semantic roles.
Two such projects thatare widely known are the FrameNet (Baker et al, 1998;Ruppenhofer et al, 2006) and PropBank/NomBank 2(Palmer et al, 2005; Meyers et al, 2004).
Due to thefact that the aforementioned projects are accompaniedby a large amount of annotated data, computer scien-tists have started creating algorithms, mostly based onstatistics (Gildea and Jurafsky, 2002; Xue, 2008) in or-der to automatically label the semantic roles in a sen-tence.
Those algorithms take as input the frame that2We would like to note here that although the two ap-proaches (FrameNet and PropBank/NomBank) share manycommon elements, they have several differences as well.Two major differences, for example, are the fact that theLinguistic Units (FrameNet) are referred to as Relations(PropBank/NomBank), and that for the definition of the se-mantic roles in the case of PropBank/NomBank there is noreference ontology.
A detailed analysis of the differences be-tween FrameNet and PropBank/NomBank would be out ofthe scope of this paper.18contains the roles as well as the predicate3 of the sen-tence.Despite the fact that during the last years we haveseen an increasing interest concerning semantic rolelabeling,4 we have not seen many advancements con-cerning the issue of automatically inducing semanticroles from raw textual corpora.
Such a process of in-duction would involve, firstly the identification of thewords that would serve as predicates and secondly thecreation of the appropriate clusters of word sequences,within the limits of a sentence, that behave similarlyin relation to the given predicates.
Although thoseclusters of word sequences could not actually be saidto serve in themselves as the semantic roles,5 theycan nevertheless be viewed as containing characteris-tic word sequences of specific semantic roles.
The lastpoint has the implication that if one is looking for ahuman intuitive naming of the semantic role that is im-plied by the cluster then one should look elsewhere.This is actually reminiscent of the approach that is car-ried out by PropBank/NomBank in which each seman-tic role is labeled as Arg1 through Arg5 with the se-mantics given aside in a human readable natural lan-guage sentence.Our goal in this paper is to contribute to the researchproblem of frame induction, that is of the creation offrames, including their associated semantic roles, givenas input only a set of textual documents.
More specifi-cally we propose a general methodology to accomplishthis task, and we test its first stage which includes theuse of corpus statistics for the creation of a subset ofwords, from the initial universe of initial words that arepresent in the corpus.
This subset will later be usedfor the identification of the predicates as well as thesemantic roles.
Knowing that the problem of frame in-duction is very difficult in the general case, we limitourselves to a specific genre and domain trying to ex-ploit the characteristics that exist in that domain.
Thedomain that we have chosen is that of the terroristic in-cidents which involve hostages.
Nevertheless, the samemethodology could be applied to other domains.The rest of the paper is structured as follows.
In sec-tion 2 we describe the data on which we have appliedour methodology, which itself is described in detail insection 3.
Section 4 describes the actual experimentsthat we have performed and the results obtained, whilea discussion of those results follows in section 5.
Fi-nally, section 6 contains a description of the relatedwork while we present our future work and conclusionsin section 7.3In the case of FrameNet the predicate corresponds to a?Linguistic Unit?, while in the case of PropBank/NomBankit corresponds to what is named ?Relation?.4Cf, for example, the August 2008 issue of the journalComputational Linguistics (34:2).5At least as the notion of semantic roles is proposed andused by FrameNet.2 The Annotated DataThe annotated data that we have used in order toperform our experiments come from a previous workon automatic multi-document summarization of eventsthat evolve through time (Afantenos et al, 2008; Afan-tenos et al, 2005; Afantenos et al, 2004).
The method-ology that is followed is based on the identification ofsimilarities and differences?between documents thatdescribe the evolution of an event?synchronically aswell as diachronically.
In order to do so, the notion ofSynchronic and Diachronic cross document Relations(SDRs),6 was introduced.
SDRs connect not the doc-uments themselves but some semantic structures thatwere called messages.
The connection of the messageswith the SDRs resulted in the creation of a semanticgraph that was then fed to a Natural Language Gener-ation (NLG) system in order to produce the final sum-mary.
Although the notion of messages was originallyinspired by the notion of messages as used in the area ofNLG, for example during the stage of Content Determi-nation as described in (Reiter and Dale, 1997), and ingeneral they do follow the spirit of the initial definitionby Reiter & Dale, in the following section we wouldlike to make it clear what the notion of messages rep-resents for us.
In the rest of the paper, when we refer tothe notion of messages, it will be in the context of thediscussion that follows.2.1 MessagesThe intuition behind messages, is the fact that duringthe evolution of an event we have several activities thattake place and each activity is further decomposed intoa series of actions.
Messages were created in order tocapture this abstract notion of actions.
Of course, ac-tions usually implicate several entities.
In this case, en-tities were represented with the aid of a domain ontol-ogy.
Thus, in more formal terms a message m can bedefined as follows:m = message_type (arg1, .
.
.
, argn)where argi ?
Topic Ontology, i ?
{1, .
.
.
, n}In order to give a simple example, let us take for in-stance the case of the hijacking of an airplane by ter-rorists.
In such a case, we are interested in knowingif the airplane has arrived to its destination, or even toanother place.
This action can be captured by a mes-sage of type arrive whose arguments can be the en-tity that arrives (the airplane in our case, or a vehicle,in general) and the location that it arrives.
The specifi-cations of such a message can be expressed as follows:6Although a full analysis of the notion of Synchronic andDiachronic Relations is out of the scope of this paper, wewould like simply to mention that the premises on whichthose relations are defined are similar to the ones which gov-ern the notion of Rhetorical Structure Relations in RhetoricalStructure Theory (RST) (Taboada and Mann, 2006), with thedifference that in the case of SDRs the relations hold acrossdocuments, while in the case of RSTs the relation hold insidea document.19arrive (what, place)what : Vehicleplace : LocationThe concepts Vehicle and Location belong to theontology of the topic; the concept Airplane is a sub-concept of the Vehicle.
A sentence that might in-stantiate this message is the following:The Boeing 747 arrived at the airport ofStanstend.The above sentence instantiates the following message:arrive ("Boeing 747", "airport ofStanstend")The domain which was chosen was that of terroris-tic incidents that involve hostages.
An empirical study,by three people, of 163 journalistic articles?written inGreek?that fell in the above category, resulted in thedefinition of 48 different message types that representthe most important information in the domain.
At thispoint we would like to stress that what we mean by?most important information?
is the information thatone would normally expect to see in a typical summaryof such kinds of events.
Some of the messages thathave been created are shown in Table 1; figure 1 pro-vides full specifications for two messages.free explodekill kidnapenter arrestnegotiate encircleescape_from block_the_waygive_deadlineTable 1: Some of the message types defined.negotiate (who, with_whom, about)who : Personwith_whom : Personabout : Activityfree (who, whom, from)who : Personwhom : Personfrom : Place ?
VehicleFigure 1: An example of message specificationsAlthough in an abstract way the notion of messages,as presented in this paper approaches the notion offrame semantics?after all, both messages and framesemantics are concerned with ?who did what, to whom,when, where and how?
?it is our hope that our ap-proach could ultimately be used for the problem offrame induction.
Nevertheless, the two structures haveseveral points in which they differ.
In the followingsection we would like to clarify those points in whichthe two differ.2.2 How Messages differ from Frame SemanticsAs it might have been evident until now, the notionsof messages and frame semantics are quite similar, atleast from an abstract point of view.
In practical termsthough, the two notions exhibit several differences.To start with, the notion of messages has been useduntil now only in the context of automatic text summa-rization of multiple documents.
Thus, the aim of mes-sages is to capture the essential information that onewould expect to see in a typical summary of this do-main.7 In contrast, semantic roles and the frames inwhich they exist do not have this limitation.Another differentiating characteristic of frame se-mantics and messages is the fact that semantic roles al-ways get instantiated within the boundaries of the sen-tence in which the predicate exists.
By contrast, in mes-sages although in the vast majority of the cases there isa one-to-one mapping from sentences to messages, insome of the cases the arguments of a message, whichcorrespond to the semantic roles, are found in neigh-boring sentences.
The overwhelming majority of thosecases (which in any case were but a few) concern re-ferring expressions.
Due to the nature of the machinelearning experiments that were performed, the actualentities were annotated as arguments of the messages,instead of the referring expressions that might exist inthe sentence in which the message?s predicate resided.A final difference that exists between messages andframe semantics is the fact that messages were meantto exist within a certain domain, while the definition ofsemantic roles is usually independent of a domain.83 The Approach FollowedA schematic representation of our approach is shownin Figure 2.
As it can be seen from this figure, our ap-proach comprises two stages.
The first stage concernsthe creation of a lexicon which will contain as most aspossible?and, of course, as accurately as possible?candidates that are characteristic either of the predi-cates (message types) or of the semantic roles (argu-ments of the messages).
This stage can be thought ofas a filtering stage.
The second stage involves the useof unsupervised clustering techniques in order to createthe final clusters of words that are characteristic eitherof the predicates or of the semantic roles that are asso-7In this sense then, the notion of messages is reminiscentof Schank & Abelson?s (1977) notion of scripts, with the dif-ference that messages are not meant to exist inside a struc-ture similar to Schank & Abelson?s ?scenario?.
We wouldlike also to note that the notion of messages shares certainsimilarities with the notion of templates of Information Ex-traction, as those structures are used in conferences such asMUC.
Incidentally, it is not by chance that the ?M?
in MUCstands for Message (Understanding Conference).8We would like to note at this point that this does not ex-clude of course the fact that the notion of messages could beused in a more general, domain independent way.
Neverthe-less, the notion of messages has for the moment been appliedin two specific domains (Afantenos et al, 2008).20ciated with those predicates.
The focus of this paper ison the first stage.As we have said, our aim in this paper is the useof statistical measures in order to extract from a givencorpus a set of words that are most characteristic ofthe messages that exist in this corpus.
In the contextof this paper, a word will be considered as being char-acteristic of a message if this word is employed in asentence that has been annotated with that message.
Ifa particular word does not appear in any message an-notated sentence, then this word will not be consideredas being characteristic of this message.
In more formalterms then, we can define our task as follows.
If by Uwe designate the set of all the words that exist in ourcorpus, then we are looking for a setM such that:M?
U ?w ?M?
m appears at least oncein a message instance (1)In order to extract the set M we have employed thefollowing four statistical measures:Collection Frequency: The set that results from theunion of the n% most frequent words that appearin the corpus.Document Frequency: The set that results from theunion of the n% most frequent words of each doc-ument in the corpus.tf.idf: For each word in the corpus we calculate itstf.idf .
Then we create a set which is the union ofwords with the highest n% tf.idf score in eachdocument.Inter-document Frequency: A word has inter-docu-ment frequency n if it appears in at least n docu-ments in the corpus.
The set with inter-documentfrequency n is the set that results from the unionof all the words that have inter-document fre-quency n.As we have previously said in this paper, our goal isthe exploitation of the characteristic vocabulary thatexists in a specific genre and domain in order to ulti-mately achieve our goal of message induction, some-thing which justifies the use of the above statisticalmeasures.
The first three measures are known to beused in context of Information retrieval to capture top-ical informations.
The latter measure has been pro-posed by (Hernandez and Grau, 2003) in order to ex-tract rhetorical indicator phrases from a genre depen-dant corpus.In order to calculate the aforementioned statistics,and create the appropriate set of words, we ignored allthe stop-words.
In addition we worked only with theverbs and nouns.
The intuition behind this decision liesin the fact that the created set will later be used for theidentification of the predicates and the induction of thesemantic roles.
As Gildea & Jurafsky (2002)?amongothers?have mentioned, predicates, or action denot-ing words, are mostly represented by verbs or nouns.9Thus, in this series of experiments we are mostly focus-ing in the extraction of a set of words that approachesthe set that is obtained by the union of all the verbs andnouns found in the annotated sentences.4 Experiments and ResultsThe corpus that we have consists of 163 journalisticarticles which describe the evolution of five differentterroristic incidents that involved hostages.
The cor-pus was initially used in the context of training a multi-document summarization system.
Out of the 3,027 sen-tences that the corpus contains, about one third (1,017sentences) were annotated with the 48 message typesthat were mentioned in section 2.1.Number of Documents: 163Number of Token: 71,888Number of Sentences: 3,027Annotated Sentences (messages): 1,017Distinct Verbs and Nouns in the Corpus: 7,185Distinct Verbs and Nouns in the Messages: 2,426Table 2: Corpus Statistics.The corpus contained 7,185 distinct verbs and nouns,which actually constitute the U of the formula (1)above.
Out of those 7,185 distinct verbs and nouns2,426 appear in the sentences that have been annotatedwith the messages.
Our goal was to create this set thatapproached as much as possible to the set of 2,426 dis-tinct verbs and nouns that are found in the messages.Using the four different statistical measures pre-sented in the previous section, we tried to reconstructthat set.
In order to understand how the statistical mea-sures behaved, we varied for each one of them the valueof the threshold used.
For each statistical measure used,the threshold represents something different.
For theCollection Frequency measure the threshold representsthe n% most frequent words that appear in the cor-pus.
For the Document Frequency it represents the n%most frequent words that appear in each document sep-arately.
For tf.idf it represents the words with the high-est n% tf.idf score in each document.
Finally for theInter-document Frequency the threshold represents theverbs and nouns that appear in at least n documents.Since for the first three measures the threshold repre-sents a percentage, we varied it from 1 to 100 in orderto study how this measure behaves.
For the case ofthe Inter-document Frequency, we varied the thresholdfrom 1 to 73 which represents the maximum number ofdocuments in which a word appeared.In order to measure the performance of the statisticalmeasures employed, we used four different evaluationmeasures, often employed in the information retrieval9In some rare cases predicates can be represented by ad-jectives as well.21Lexicon Extraction(initial predicate filtering) Unsupervised ClusteringClusters of predicates and semantic rolesFigure 2: Two different stages in the process of predicate clusteringfield.
Those measures are the Precision, Recall, F-measure and Fallout.
Precision represents the percent-age of the correctly obtained verbs and nouns over thetotal number of obtained verbs and nouns.
Recall rep-resents the percentage of the obtained verbs and nounsover the target set of verbs and nouns.
The F-measureis the harmonic mean of Precision and Recall.
Finally,fallout represents the number of verbs and nouns thatwere wrongly classified by the statistical measures asbelonging to a message, over the total number of verbsand nouns that do not belong to a message.
In an idealsituation one expects a very high precision and recall(and by consequence F-measure) and a very low Fall-out.The obtained graphs that combine the evaluation re-sults for the four statistical measures presented in sec-tion 3 are shown in Figures 3 through 6.
A first remarkthat we can make in respect to those graphs is that con-cerning the collection frequency, document frequencyand tf.idf measures, for small threshold numbers wehave more or less high precision values while the recalland fallout values are low.
This implies that for smallerthreshold values the obtained sets are rather small, inrelation toM (and by consequence to U as well).
Asthe threshold increases we have the opposite situation,that is the precision falls while the recall and the fall-out increases, implying that we get much bigger sets ofverbs and nouns.In terms of absolute numbers now, the best F-measure is given by the Collection Frequency measurewith a threshold value of 46%.
In other words, thebest results?in terms of F-measure?is given by theunion of the 46% most frequent verbs and nouns thatappear in the corpus.
For this threshold the Precisionis 54.14%, the Recall is 72.18% and the F-measure is61,87%.
This high F-measure though comes at a cer-tain cost since the Fallout is at 31.16%.
This impliesthat although we get a rather satisfying score in termsof precision and recall, the number of false positivesthat we get is rather high in relation to our universe.As we have earlier said, a motivating factor of this pa-per is the automatic induction of the structures that wehave called messages; the extracted lexicon of verbsand messages will later be used by an unsupervisedclustering algorithm in order to create the classes ofwords which will correspond to the message types.
Forthis reason, although we prefer to have an F-measure ashigh as possible, we also want to have a fallout measureas low as possible, so that the number of false positiveswill not perturb the clustering algorithm.If, on the other hand, we examine the relation be-tween the F-measure and Fallout, we notice that for theInter-document Frequency with a threshold value of 4we obtain a Precision of 71.60%, a recall of 43.86%and an F-measure of 54.40%.
Most importantly thoughwe get a fallout measure of 8.86% which implies thatthe percentage of wrongly classified verbs and nounscompose a small percentage of the total universe ofverbs and nouns.
This combination of high F-measureand very low Fallout is very important for later stagesduring the process of message induction.5 DiscussionAs we have claimed in the introduction of this paper,although we have applied our series of experiments ina single domain, that of terroristic incidents which in-volve hostages, we believe that the proposed procedurecan be viewed as a ?general?
one.
In the section wewould like to clarify what exactly we mean by thisstatement.In order to proceed, we would like to suggest thatone can view two different kinds of generalization forthe proposed procedure:1.
The proposed procedure is a general one in thesense that it can be applied in a large corpus of het-erogeneous documents incorporating various do-mains and genres, in order to yield ?general?, i.e.domain-independent, frames that can later be usedfor any kind of domain.2.
The proposed procedure is a general one in thesense that it can be used in any kind of domainwithout any modifications.
In contrast with thefirst point, in this case the documents to whichthe proposed procedure will be applied ought tobe homogeneous and rather representative of thedomain.
The induced frames will not be generalones, but instead will be domain dependent ones.22L e x i c LLLeLxLi LcoLoeoxoi oceLeeexei ecnLnenxni ncxLxexxxi xc L  e  x  i  c iL ie ix ii ic ELEeExEi EccLcecxci cctrttaotrttantrttatrttaEtrttaLttrttaLotrtta(lpdfgf)UspduvvCmpug?lpCuvv)?
?Figure 3: Collection Frequency statisticsL e x i c LLLeLxLi LcoLoeoxoi oceLeeexei ecnLnenxni ncxLxexxxi xc L  e  x  i  c iL ie ix ii ic ELEeExEi EccLcecxci cctrttaotrttantrttatrttaEtrttaLttrttaLotrtta(lpdfgf)UspduvvCmpug?lpCuvv)?
?Figure 4: Document Frequency statisticsGiven the above two definitions of generality, wecould say that the procedure proposed in this paperfalls rather in the second category than in the firstone.
Ignoring for the moment the second stage of theprocedure?clustering of word sequences characteris-tic of specific semantic roles?and focusing on the ac-tual work described in this paper, that is the use ofstatistical methods for the identification of candidatepredicates, it becomes clear that the use of an hetero-geneous, non-balanced corpus is prone to skewing theresults.
By consequence, we believe that the proposedprocedure is general in the sense that we can use it forany kind of domain which is described by an homoge-neous corpus of documents.6 Related WorkTeufel and Moens (2002) and Saggion and Lapalme(2002) have shown that templates based on domainconcepts and relations descriptions can be used for thetask of automatic text summarization.
The drawbackof their work is that they rely on manual acquisitionof lexical resources and semantic classes?
definition.Consequently, they do not avoid the time-consumingtask of elaborating linguistic resources.
It is actuallyfor this kind of reason?that is, the laborious manualwork?that automatic induction of various structures isa recurrent theme in different research areas of NaturalLanguage Processing.An example of an inductive Information Extractionalgorithm is the one presented by Fabio Ciravegna(2001).
The algorithm is called (LP)2.
The goal of thealgorithm is to induce several symbolic rules given asinput previous SGML tagged information by the user.The induced rules will later be applied in new texts inorder to tag it with the appropriate SGML tags.
Theinduced rules by (LP)2 fall into two distinct categories.In the first we have a bottom up procedure which gen-eralizes the tag instances found in the training corpuswhich uses shallow NLP knowledge.
A second set ofrules is also created which have a corrective character;that is, the application of this second set of rules aimsat correcting several of the mistakes that are performedby the first set of rules.On the other hand several researchers have pioneeredthe automatic acquisition of lexical and semantic re-sources (such as verb classes).
Some approaches arebased on Harris?s (1951) distribution hypothesis: syn-tactic structures with high occurrences can be used foridentifying word clusters with common contexts (Linand Pantel, 2001).
Some others perform analysis fromsemantic networks (Green et al, 2004).
Poibeau andDutoit (2002) showed that both can be used in a com-plementary way.Currently, our approach follows the first trend.Based on Hernandez and Grau (2003; 2004)?s proposal,we aim at explicitly using corpus characteristics such asits genre and domain features to reduce the quantity ofconsidered data.
In this paper we have explored variousstatistical measures which could be used as a filter forimproving results obtained by the previous mentionedworks.23L e x i c LLLeLxLi LcoLoeoxoi oceLeeexei ecnLnenxni ncxLxexxxi xc  L  e  x  i  c iL ie ix ii ic ELEeExEi EccLcecxci cctrttaotrttantrttatrttaEtrttaLttrttaLotrtta(lpdfgf)UspduvvCm?pug?lpCuvv)?
?Figure 5: Tf.idf statisticsL ex i c on  ELtLLLeLxLiLcLoLnL LEeteLeeexeieceoene eExtxLxexxxixcxoxnx xEit iLieixii icioini iEctcLcecxcicccocnc cEotoLoeoxoiocooono oEntnLnenxtrttaetrttaitrttaotrttatrttaLttrttaLetrtta(lpdfgf)UspduvvCmpug?lpCuvv)?
?Figure 6: Inter-document frequency statistics7 Conclusions and Future WorkIn this paper we have presented a statistical approachfor the extraction of a lexicon which contains the verbsand nouns that can be considered as candidates for useas predicates for the induction of predicate/argumentstructures that we call messages.
Actually, the researchpresented here can be considered as the first step in atwo-stages approach.
The next step involves the useof clustering algorithms on the extracted lexicon whichwill provide the final clusters that will contain the pred-icates and arguments for the messages.
This processis itself part of a larger process for the induction ofpredicate/argument structures.
Apart from messages,such structures could as well be the structures that areassociated with frame semantics, that is the framesand their associated semantic roles.
Despite the greatresemblances that messages and frames have, one oftheir great differences is the fact that messages werefirstly introduced in the context of automatic multi-document summarization.
By consequence they aremeant to capture the most important information in adomain.
Frames and semantic roles on the other hand,do not have this restriction and thus are more general.Nonetheless, it is our hope that the current researchcould ultimately be useful for the induction of frame se-mantics.
In fact it is in our plans for the immediate fu-ture work to apply the same procedure in FrameNet an-notated data10 in order to extract a vocabulary of verbs10See http://framenet.icsi.berkeley.edu/index.php?option=com_wrapper&Itemid=84and nouns which will be characteristic of the differentLinguistic Units (LUs) for the frames of FrameNet.The proposed statistical measures are meant to be afirst step towards a fully automated process of mes-sage induction.
The immediate next step in the pro-cess involves the application of various unsupervisedclustering techniques on the obtained lexicon in orderto create the 48 different classes each one of whichwill represent a distinct vocabulary for the 48 differ-ent message types.
We are currently experimentingwith several algorithms such K-means, Expectation-Minimization (EM), Cobweb and Farthest First.
In ad-dition to those clustering algorithms, we are also exam-ining the use of various lexical association measuressuch as Mutual Information, Dice coefficient, ?2, etc.Although this approach will provide us with clusters ofpredicates and candidate arguments, still the problemof linking the predicates with their arguments remains.Undoubtedly, the use of more linguistically orientedtechniques, such as syntactic analysis, is inevitable.
Weare currently experimenting with the use of a shallowparser (chunker) in order to identify the chunks thatbehave similarly in respect to a given cluster of pred-icates.Concerning the evaluation of our approach, the high-est F-measure score (61,87%) was given by the Col-lection Frequency statistical measure with a thresholdvalue of 46%.
This high F-measure though came at thecost of a high Fallout score (31.16%).
Since the ex-tracted lexicon will later be used as an input to a clus-tering algorithm, we would like to minimize as much as24possible the false positives.
By consequence we haveopted in using the Inter-document Frequency measurewhich presents an F-measure of 54.40% and a muchmore limited Fallout of 8.86%.AcknowledgmentsThe authors would like to thank Konstantina Liontou andMaria Salapata for their help on the annotation of the mes-sages, as well as the anonymous reviewers for their insightfuland constructive comments.ReferencesStergos D. Afantenos, Irene Doura, Eleni Kapel-lou, and Vangelis Karkaletsis.
2004.
Exploit-ing cross-document relations for multi-documentevolving summarization.
In G. A. Vouros andT.
Panayiotopoulos, editors, Methods and Applica-tions of Artificial Intelligence: Third Hellenic Con-ference on AI, SETN 2004, volume 3025 of LectureNotes in Computer Science, pages 410?419, Samos,Greece, May.
Springer-Verlag Heidelberg.Stergos D. Afantenos, Konstantina Liontou, MariaSalapata, and Vangelis Karkaletsis.
2005.
An in-troduction to the summarization of evolving events:Linear and non-linear evolution.
In BernadetteSharp, editor, Proceedings of the 2nd InternationalWorkshop on Natural Language Understanding andCognitive Science, NLUCS 2005, pages 91?99, Ma-iami, Florida, USA, May.
INSTICC Press.Stergos D. Afantenos, Vangelis Karkaletsis, Panagio-tis Stamatopoulos, and Constantin Halatsis.
2008.Using synchronic and diachronic relations for sum-marizing multiple documents describing evolvingevents.
Journal of Intelligent Information Systems,30(3):183?226, June.Collin F. Baker, Charles J. Fillmore, and John B. Lowe.1998.
The berkeley framenet project.
In Proceed-ings of the COLING-ACL, Montreal, Canada.Fabio Ciravegna.
2001.
Adaptive information extrac-tion from text by rule induction and generalisation.In 17th International Joint Conference on ArtificialIntelligence (IJCAI 2001), pages 1251?1256, Seat-tle, USA, August.C.
J. Fillmore.
1976.
Frame semantics and the na-ture of language.
Annals of the New York Academyof Sciences: Conference on the Origin and Develop-ment of Language and Speech, 280:20?32.Daniel Gildea and Daniel Jurafsky.
2002.
Automaticlabeling of semantic roles.
Computational Linguis-tics, 28(3):245?288.Rebecca Green, Bonnie J. Dorr, and Philip Resnik.2004.
Inducing frame semantic verb classes fromwordnet and ldoce.
In Proceedings of the 42ndMeeting of the Association for Computational Lin-guistics (ACL?04), Main Volume, pages 375?382,Barcelona, Spain, July.Zelig Harris.
1951.
Structural Linguistics.
Universityof Chicago Press.Nicolas Hernandez and Brigitte Grau.
2003.
Auto-matic extraction of meta-descriptors for text descrip-tion.
In International Conference on Recent Ad-vances In Natural Language Processing (RANLP),Borovets, Bulgaria, 10-12 September.Nicolas Hernandez.
2004.
D?tection et DescriptionAutomatique de Structures de Texte.
Ph.D. thesis,Universit?
de Paris-Sud XI.Dekang Lin and Patrick Pantel.
2001.
Induction ofsemantic classes from natural language text.
In Pro-ceedings of ACM Conference on Knowledge Discov-ery and Data Mining (KDD-01), pages 317?322, SanFrancisco, CA.Adam Meyers, Ruth Reeves, Catherine Macleod,Rachel Szekely, Veronika Zielinska, Brian Young,and Ralph Grishman.
2004.
The nombank project:An interim report.
In Adam Meyers, editor, HLT-NAACL 2004 Workshop: Frontiers in Corpus Anno-tation, pages 24?31, Boston, Massachusetts, USA,May.
Association for Computational Linguistics.Martha Palmer, Daniel Gildea, and Paul Kingsbury.2005.
The proposition bank: An annotated cor-pus of semantic roles.
Computational Linguistics,31(1):71?106.Thierry Poibeau and Dominique Dutoit.
2002.
In-ferring knowledge from a large semantic network.In Proceeding of the Semantic networks workshop,during the Computational Linguistics Conference(COLING 2002), Taipei, Taiwan.Ehud Reiter and Robert Dale.
1997.
Building appliednatural language generation systems.
Natural Lan-guage Engineering, 3(1):57?87.Josef Ruppenhofer, Michael Ellsworth, Miriam R. L.Petruck, Christopher R. Johnson, and Jan Schef-fczyk.
2006.
Framenet ii: Extended theory andpractice.
Unpublished manuscript; accessible athttp://framenet.icsi.berkeley.edu.Horacio Saggion and Guy Lapalme.
2002.
Generat-ing indicative-informative summaries with sumum.Computational Linguistics, 28(4):497?526.Roger C. Schank and Robert P. Abelson.
1977.
Scripts,Plans, Goals and Understanding: an Inquiry intoHuman Knowledge Structures.
L. Erlbaum, Hills-dale, NJ.Maite Taboada and William C. Mann.
2006.
Rhetor-ical structure theory: Looking back and movingahead.
Discourse Studies, 8(3):423?459, June.Simone Teufel and Marc Moens.
2002.
Summariz-ing scientific articles: Experiments with relevanceand rhetorical status.
Computational Linguistics,28:409?445.Nianwen Xue.
2008.
Labeling chinese predicateswith semantic roles.
Computational Linguistics,34(2):225?255, June.25
