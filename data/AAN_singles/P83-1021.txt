PARSING AS DEDUCTION lFernando C. N. PereiraDavid H. D. WarrenArtificial Intelligence CenterSRI International333 Ravenswood Ave., Menlo Park CA 04025Abst rac tBy exploring the relationship between parsing anddeduction, a new and more general view of chart parsingis obtained, which encompasses parsing for grammarformalisms based on unification, and is the basis of theEarley Deduction proof procedure for definite clauses.The efficiency of this approach for an interesting class ofgrammars is discussed.1.
In t roduct ionThe aim of this paper is to explore the relationshipbetween parsing and deduction.
The basic notion, whichgoes back to Kowaiski (Kowalski, 1980} and Colmerauer{Colmeraucr, 1978), h'zs seen a very efficient, if limited,realization in tile use of the logic programming languageProlog for parsing {Colmerauer, 1978; Pereira andWarren, 1980).
The connection between parsing anddeduction was developed further in the design of theEariey Deduction proof procedure (Warren, 1975), whichwill also be discussed at length here.Investigation of the connection between parsing anddeduction yields several important benefits:?
A theoretically clean mechanism to connect parsingwith the inference needed for semanticinterpretation.llandling of gaps and unbounded ependencies "onthe fly" without adding special mechanisms to theparser.
:\ reinterprecation and generalization of chartparsing that abstracts from unessential data-structure details.
* Techniques that are applicable to parsing in relatedformalisms not directly based on logic.IThis work wa~ partially supported by the Defense AdvancedResearch Projects Agency under Contract N00039-80-C-0575 withthe Naval Electronic Systems Command.
The views and conclusionscontained in this article are those of the authors and should not beinterpreted as representative of the official policies, either expressedor imp{led, of the Defense Advanced Research Projects Agency or theUnited Slates Government.?
Elucidation of parsing complexity issues for relatedformalisms, in particular lexieal-functional grammar(LFG).Our study of these topics is still far from complete;therefore, besides offering some initial results, we shalldiscuss various outstanding questions.The connection between parsing and deduction is basedon the axiomatization of context-free grammars indefinite clauses, a particularly simple subset of first-order logic (Kowalski, 1080; van Emden and Kowalski,1976).
This axiomatization allows us to identify context-free parsing algorithms with proof procedures for arestricted class of definite clauses, those derived fromcontext-free rules.
This identification can then begeneralized to inc{ude larger classes of definite clauses towhich the same algorithms can be applied, with simplemodifications.
Those larger classes of definite clauses canbe seen as grammar formalisms in which the atomicgrammar symbols of context-free grammars have beenreplaced by complex symbols that are matched byunification (Robinson, 1965; Colmerauer, 1978; Pereir3and Warren, 1980}.
The simplest of these formalisms isdefinite-clause grammars (DCG) (Pereira and Warren,1980).There is a close relationship between DCGs ~nd other~,rammar formalisms based on unification, such asUnification Grammar {UG) (Kay, 1070), LFG, PATR-2{Shieber.
1083) and the more recent versions of GPSG(Gazdar and Pullum, 1082).The parsing a{gorithms we are concerned with areonline algorithms, in the sense that they apply theconstraints pecified by the augmentation of a rule a~soon as the rule is applied.
In contrast, an olTline parsingalgorithm will consist of two phases: a context-freeparsing algorithm followed by application of theconstraints to all the resulting analyses.The pap('r is organized as follows.
Section 2 gives anoverview of the concepts of definite clause logic, definiteclause grammars, definite clause proof procedures, andchart parsing, Section 3 discusses the connection betweeDCGs and LFG.
Section 4 describes the EarleyDeduction definite-clause proof procedure.
Section 5 thenbrings out the connection between Earley Deduction andchart parsing, and shows the added generality brought inby the proof procedure approach.
Section 6 outlines someoi the problems of implementing Earley Deduction andsimilar parsing procedure~.
Finally, Section 7 discussesquestions of computational complexity and decidability.?372.
Bas ic  Not ions2.1.
Def in i te  ClausesA def in i te  c lause has the formP:Q~&... &Q..to be read as "P  is true if Q1 and ... and Qa are true".
Ifn --~ 0, the clause is a un i t  clause and is written simply asP.P and QI .
.
.
.
.
Qn are literals.
P is the pos i t ive  literalor head of the clause; Ql .
.
.
.
, Qn are the negativeliterals, forming the body  of the clause.
Literals have theforn~ pit I ..... tk), where p is the pred icate  of arity k andthe t i the arguments.
The arguments are terms.
Aterm may be: a var iab le  {variable names start withcapital letters); a constant ;  a compound termJ~tl,.. .
,t m) where f is a functor of arit$ m and the t i areterms.
All the variables in a clause are implicitlyuniversally quantified.A set of definite clauses forms a program,  and theclauses in a program are called input  clauses.
Aprogram defines the relations denoted by the predicatesappearing in the heads of clauses.
When using a definite-clause proof procedure, such as Prolog (Roussel.
1975), agoal s ta tementrequests the proof procedure to find provable instances ofP.2.2.
Definite Clause GrammarsAny context-free rulei ' ~ o r  1 .
.
.
O ncan be translated into a definite clausexlSo.S~) : %/S0,Sl)  & .., & %(S~.
l .S . )
.The variables S i are the s t r ing  arguments ,  representingpositions m the input string.
For example, the context-freerule "S ~ NP VP" is translated into "s(S0,S2)np{,qO.Sl} k" vp(S1,S2)," which can be paraphrased as"'there is an S from SO to $2 in the input string if there isan NP from SO to S1 and a V'P from S1 to 82.
"Given the translation of a context-free grammar G withstart symbol S into a set of definite clauses G" withcorresponding predicate s, to say that a string w is in thegrammar's language is equivalent to saying that the startgoal  S{po,pj is a consequence of G" U W, where Po and prepresent the left and right endpoints of u,, and W is a setof unit clauses that represents w.It is easy to generalize the above notions to defineDCGs.
DCG nonterminals have arguments in the sameway that predicates do.
A DCG nonterminal with uarguments is translated into a predicate of n+2arguments, the last two of which are the string points, asin the translation of context-free rules into definiteclauses.
The context-free grammar obtained from a DCGby dropping all nonterminal arguments is the context -free ske le ton  of the DCG.2.3.
Dedu.ction in Definite ClausesThe fundamental inference rule for definite clauses isthe following reso lu t ion  rule: From the clausesB ?= A l ?
: ... & A m .
(l)C:  D 1 & ,.. & D i & ... & D n. (2}when B and D i are unifiable by substitution a, infera f t  =D 1 & ... Di.
1 &A t & ... &Am &,D i+ 1 ... & Dn.
~ (3}Clause (3) is a der ived  clause, the resoivent of {1) and(2).The proof procedure of Prolog is just a particularembedding of the resolution rule in a search procedure, inwhich a goal clause like (2) is successively rewritten bythe res,qution rule using clauses from the program (1).The Prolog proof procedure can be implemented veryefficiently, but it has the same theoretical problems of thetop-d?.wn backtrack parsing algorithms after which it ismotif?led.
These problems do not preclude its use forcreating uniquely efficient parsers for suitably constructedgrammars (Warren and Pereira, 1983: Pereira, 1982), butthe broader questions of the relation between parsing anddeduction and of the derivation of online parsingalgorithms for unification formalisms require that we lookat a more generally applicable class of proof procedures.2.4.
Char t  Pars ing  and the Ear ley  Algor i thmChart parsing is a general framework for constructingparsing algorithms for context-free grammars and relatedformalisms.
The Earley context-free parsing algorithm,although independently developed, can be seen as aparticular case ,)f chart parsing.
We will give here justthe basic terminolog-y of chart parsing and of the Earteyalgorithm.
Full accounts can be found in the articles byKay (Kay.
l.qS0} and Earley/Earley,  1970).The state of a chart parser is represented by the chart .which is a directed graph.
The nodes of the chartrepresent positions in the string being analyzed.
Eachodge in Ihe chart is either act ive  or passive.
Both typesof edges are labeled.
A passive edge with label ,V linksnode r to node .~ if the string between r and s h,~ beenanalyzed as a phr,'tse of type N. Initially, the only edgesare passive edges that link consecutive nodes and arelabeh,d with Ihe words of the input string (see Figure I}.Active edges represent partially applied grammar rules.In the siml)le~.t case, active edges are labeled by dot tedrules.
A dolled rule is a grammar ule with a dot insertedsome~vhcre on its right-hand sideX- - -  % ... ~i-I ?
~i - ' "  % {4)An edge with this label links node r to node s if thesentential form ~!
... o%1 is an analysis of the input stringbetween r and s. An active edge that links a node to138itself is called empty  and acts like a top-down prediction.Chart-parsing procedures tart with a chart containingthe passive edges for the input string.
New edges areadded in two distinct ways.
First, an active edge from r tos labeled with a dotted rule {4) combines with a passiveedge from s to t with label a i to produce a new edge fromr to t, which will be a passive edge with label X if a i isthe last symbol in the right-hand side of the dotted rule;otherwise it will be an active edge with the dot advancedover cr i.
Second, the parsing strategy must place into thechart, at appropriate points, new empty active edges thatwill be used to combine existing passive edges.
The exactmethod used determines whether the parsing method isseen as top-down, bottom*up, or a combination of thetwo.The Earley parsing algorithm can be seen as a specialcase of chart parsing in which new empty active edges areintroduced top-down and, for all k, the edge combinationsinvolving only the first k nodes are done before anycombinations that involve later nodes.
This particularstrategy allows certain simplifications to be made in thegeneral algorithm.3.
DCGs  and  LFGWe would like to make a few informal observations atthis point, to clarify the relationship between DCGs andother unification grammar formalisms - -  LFG inparticular.
A more detailed discussion would take usbeyond the intended scope of this paper.The diffl,rcnt nolational conventions of DCGs and LFGmake the two formalisms less similar on the surface thanthe), actually are from the computational point of view.The object~ that appear ,as arguments in DCG rules aretree fragments every node of which has a number ofchildren predetermined by the functor that labels thenode.
Explicit variables mark unspecified parts of thetree.
In contrast, the functional structure nodes that areimplicitly mentioned in LFG equations do not have apred(,fined number of children, and unspecified parts areeither omitted or defined implicitly through equations.As a first approximation, a DCG rule such ass(s(Subj,Obj)) ~ np(Subj) vp(Obj} (5)might correspond to the LFG ruleS - -  KP vP  (6)I sub j= i I obj----- tThe DCG rule can be read as "an s with structurei i/ \Subj Objis an np with structure Subj followed by a vp withstructure Obj."
The LFG rule can be read as "an S is anNP  followed by a V'P, where the value of the subjattribute of the S is the functional structure of the NPand the value of the attribute obj of the S is thefunctional structure of the VP."
For those familiar withthe details of the mapping from functional descriptions tofunctional structures in LFG, DCG variables are just"placeholder" symbols (Bresnan and Kaplan, 1982).As we noted above, an apparent difference betweenLFG and DCGs is that LFG functional structure nodes,unlike DCG function symbols, do not have a definitenumber of children.
Although we mu~t leave to aseparate paper the details of the application to LFG ofthe unification algorithms from theorem proving, we willnote here that the formal properties of logical and LFG orUG unification are similar, and there are adaptations toLFG and UG of the algorithms and data structures usedin the logical case.4.
Ear ley  Deduct ionThe Earley Deduction proof procedure schema is namedafter Earley's context-free parsing algorithm (Earley,1970), on which it is based Earley Deduction providesfor definite clauses the same kind of mixed top-downbottom-up mechanism that the Earley parsing algorithmprovides for context-free grammars.Earley Deduction operates on two sets of definite clausescalled the program and the state.
The program is justthe set of input  clauses and remains fixed.
The stateconsists of a set of derived clauses, where each nonunit.
:Iause has one of its negative literals selected; the state iscontinually being added to.
Whenever  a nonunit clause isadded to the state, one of its negative literals is selected.Initially tile state contains just the goal statement (withone of its negative \[iterals selected}.There are two inference rules, called ins tant ia t ion  andreduct ion,  which can map the current state into a newone by adding a new derived clause.
For an instantiationstep, there is some clause in the current state whoseselected literal unifies with the positive literal of a,onun i t  clause C in the program.
In this case, thederived clause is a\[C\], where cr is a most general unifier(\[~obinson, 1965} of the two literals concerned.
Theselected literal is said to ins tant ia te  C to a\[C\].For a reduction step, there is some clause C in thecurrent state whose selected literal unifies with a unitclause from either the program or the current state.
Inthis case, tile derived clause is siC' l ,  where a is a mostgeneral unifier of the two Iiterals concerned, and C" is Cminus its selected literal.
Thus, the deriydd clause is justthe res,)lvent of C with the unit clause and the latter issaid to reduce C to a(C" I.Before a derived clause is added to the state, a check ismade to see whether the derived clause is subsumed byany clause already in the state.
\[f the derived clause issubsumed, it is not added to the state, and that inferencestep is said to be blocked.In the examples that follow, we assume that the selectedliteral in a derived clause is always the leftmost literal inthe body.
This choice is not optimal (Kowalski, 1980),but it is sufficient for our purposes.For example, given the program139cl.X:,Z) = c(X,Y) & c(Y,Z).
(7)c(1,2).
(8)c(O.,3).
(g)and goal statementass(Z) ~ c(l,Z).
(10)here is a sequence of clauses derived by Early Deductionass(Z) = c(t.Z), goal.
statement (11)c(I,Z) = c(I,$) It c(Y,Z).
(11) ?nstantlates (7) (12)ass(2).
(8) reduces (II) (13)c(1,Z) = c(2,Z).
(8) reduces (12) (14)c(2,Z) = c(2.T) & c(Y,Z).
(14) instantlatee (7) (15)c(1.3).
(9) reduces (14) (15)arts(3), (16) reduces (11) (17)c(2,Z) ~ c(3,Z).
(9) reduces (15) (18)c(3,Z) = c(3.T) It c(Y,Z).
(18) inst~nC?aCes (7) (19)At this point, all further steps are blocked, so thecomputation terminates.Earley Deduction generalizes Earley parsing in a directand natural way.
\[nstantiation is analogous to the"predictor" operation of Earley's algorithm, whilereduction corresponds to the "scanner" and "completer"operations.
The "scanner" operation amounts toreduction with an input unit clause representing aterminal symbol occurrence, while the "completer"operation amounts  to reduction with a derived unit clauserepresenting a nonterminal symbol  occurrence.5.
Char t  Pars ing  and  Ear ley  Deduct ionChart parsing {Kay, I980) and other tabular parsingalgorithms (Aho and Ullman, 1972; Graham et al, I980)are usually presented in terms of certain (abstract) datastructures that keep a record of the alternatives beingexplored by the parser.
Looking at parsing procedures asproof procedures has the following advantages: (i)unification, ~aps and unbounded dependencies areautomatically handled: (ii} parsing strategies becomepossible that cannot be formulated in chart parsing.The chart represents completed nonterminals {passiveedges) and partially applied rules {active edges).
From thestandpoint of Earley Deduction, both represent derivedclauses that have been proved in the course of an attemptto deduce a goal statement whose meaning is that a stringbelongs to the language generated by the grammar.
Anactive edge corresponds to a nonunit clause, a passiveedge to a unit clause.
Nowhere  in this definition is theremention of i.he "endpoints" of the edges.
The  endpointscorrespond to certain literal arguments, and are of noconcern to the (abstract) proof procedure.
Endpoints arejust a convenient way  of indexing derived clauses in animplementalion to reduce the number  of nonproductive(nonunifying) attempts at applying the reduction rule.We shall give now an example of the application ofEarley Deduction to parsing, corresponding to the chartof Figure I.The  CFGS - ,  NP VPNP --- Det NDet ~ NP GenDet ---* ArtDet ---, AV'P --.
V NPcorresponds to the following definite-clause program:s(S0,S) = np(S0,Sl) & vp(SI,S).
{20)np(S0,S) ~ det{S0,Sl) & n(S1,S).
(21)det(S0,S} = np(S0,Sl) & gen(SI,S).
(22}det(S0,S) ~ art(S0,S).
(23)det(S,S).
(24)vp{S0,S) = v(SO,~l) & np(Sl,S}.
(25)The lexical categories of the sentenceoAg ath~ 1 's2h usband3hit4 Ulrich s (26)can be represented by the unit clausesn(0,11.
(97}gen(l,2).
(28)n(2,3).
(29},.(3..t).
(301n{.ts).
131)Thus.
the t~k of determining whether (26) is a sentencecan be represented by the goal statementans ~ s(0.5).
(32)If the sentence is in the language, the unit clause ass  willbe derived in the course of an Eariey Deduction proof.S.ch a pro(_)f could proceed as follows:?
ns = s(0,5), goal statement (33)s(0,5) = np(O,Sl) ?
vp(Sl,5).
(33) instantiates (20) (34)np(O,S) = det(O, Sl) I n(SI,S).
(34) inst,&nt,?a, tes (21) (35)det(O.S) = np(O.5t) It gen(SI.S).
(35) ?nstanr, i~tes (22) (35)det(O.S) = crt(0,S).
(35) inst~ntiates (23) (37)np(0.S) ~ n(O.5)'.
(24) reduces (35) (38)up(0.1).
(27) reduces (38) (39)s(0"~5~ = ':p(I_,5) (39) reduces (34) (40)vp(i.5) ~ v(I,SI) ~ np(Sl,5).
(40) instant, in.tee (25) (41)der,(0,S) *=-gen(1.S).
(39) reduces (36) (42)det(0.2) (28) reduces (42) (43)np(O-S)" ~ n(2.S) (43) reduces (35) (44)np(O.3).
.
(29) reduces (44) (45)s(O,5) = vp(3,5).
(45) reduces (34) (46)det(O,3) = gen(3.S).
(45) reduces (35) (47)vp(3.5) ~ v(3.$I) It np(SI,5).
(46) instanti~tes (25)" (48)vp(3_,5) ~ np(4.5).
(30) reduces (48) (49)ap(4,5) = det(4,St) ~t n($1,5),(49) inst~ntiates (21) (50)det(4.S) = np(4,Sl) It gen(Sl,S).
(50) instantiatss (22) (51)det(4,S) ~ ~rt(4.S).
(50) instantiates (23) (52)np(4.S) = det(4_~Sl) It n(SI,S),(51) inet&ntiLtes (21) (53)up(4,5) = n(4,5).
(24) reduces (50) (54)np(4.S) = n(4.S) (24) reduces (53) (55)up(4_-,5).
- (31) reduces (54) (56)vp(3.5) (56) reduces (49) (57)det'~4~'S) = gen(5,S).
(56) reduces (51) (58)s(0,5) .
(67) reduces (46) (59)an?
.
-  (69) reduce?
(33) (60)Note how subsumption is used to curtail the left recursionof rules (21) and (22), by stopping extraneousinstantiation steps from the derived clauses (35) and (36).As we have seen in the example of the previous section,this mechanism is a general one, capable of handlingcomplex grammar symbols within certain constraints thatwill be discussed later.The Earley Deduction derivation given abovecorresponds directly to the chart in Figure 1.In general, chart parsing cannot support strategies thatwould create active edges by reducing the symbols in theright-hand side of a rule in any arbitrary order.
This isbecause an active edge must correspond to a contiguoussequence of analyzed symbols.
Definite clause proofprocedures do not have this limitation.
For example, it isvery simple t.o define a strategy, "head word nar?,ng -(NlgCord, 19801, which would use the" reduction rule toinfernp(SO,S) = deqS0,2) & rel{3,S}.37 40 49 51 5844 48 63vpF igure  1: ( 'hart vs. Earley Deduction ProofEach arc in tile chart is labeled with the number of aclause in the proof.
In each clause that, corresponds to achart arc, two literal arguments correspond to the twoendpoints of the arc.
These arguments have beenunderlined in the derivation.
Notice how the endpointarguments are tile two string arguments in the head forunit clauses {passive edges) but, in the case of nonunitclauses (passive dges), are the first string argument in thehead and the first in the leftmost literal in the body.As we noted before, our view of parsing as deductionmakes it possible to derive general parsing mechanisms foraugmented phraso-structure grammars with gaps andunbounded dependencies.
It is difficult (especially in thecase of pure bottom-up parsing strategies} to augmentchart parser~ to handle gaps and dependencies(Thompson, 1981}.
However, if gaps and dependenciesare specified by extra predicate arguments in the clausesthat correspond to the rules, the general proof procedureswill handle those phenomena without further change.This is the technique used in DCGs and is the basis of thespecialized extra.position grammar formalism (Pereira,t081).The increased generality of our approach in the area ofparsing strategy stems from the fact that chart parsingstrategies correspond to specialized proof procedures fordefinite clauses with string arguments.
In other words, theorigin of these proof procedures means that stringarguments are treated differently from other arguments,as they correspond to the chart nodes.from the clausesnp(S0,S} '-- det(SO,Sl} & n(SI,S2) & rel(S2,S).\[NP --- Det N Rei\]n(2,3).\[There is an N between points 2 and 3 in the input\]This example shows that the class of parsing strategiesallowed in the deductive approach is broader than what isp,,ssible in the chart parsing approach.
It remains to beshown which of those strategies will have practicalimportance as well.6.
Imp lement ing  Ear ley  Deduct ionTo implement Earley Deduction with an efficiencycomparable, say.
to Prolog, presents some challengingproblems.
The main issues are?
t low to represent he derived clauses, especially thesubstitutions involved.?
ttow to avoid the very heavy computational cost ofsubsunlption.?
How to recognize when derived clauses are no longer2This particular strategy could be implemented ia a chart parser,by changing the rules for combining edges but the generalitydemonstrated here would be lost.ihlneeded and space can be recovered.There are two basic methods for representing derivedclauses in resolution systems: the more direct copy ingmethod, in which substitutions are applied explicitly; thes t ructure -shae lng  method of Bayer and Moore, whichavoids copying by representing derived clauses implicitlywith the aid of variable binding environments.
Apromising strategy for Earley Deduction might be to usecopying for derived unit clauses, structure sharing forother derived clauses.
When copying, care should betaken not to copy variable-free subterms, but to copy justpointers to those subterrns instead.It is very costly to implement subsumption in its fullgenerality.
To keep the cost within reasonable bounds, itwill be essential to index the derived clauses on at leastthe predicate symbols they contain - -  and probably also.on symbols in certain key argument positions.
Asimpfification of full subsumption checking that wouldappear adequate to block most redundant steps is to keeptrack of selected literals that have been used exhaustivelyto generate instantiation steps.
If another selected literalis an instance of one that has been exhaustively explored,there is no need to consider using it as a candidate forinstantiation steps, Subsuvnption would then be onlyapplied to derived unit clauses.A major efficiency problem with Earley deduction isthat it is difficult to recognize situations in which derivedclauses are no longer needed and space can be reclaimed.There is a marked contrast with purely top-down proofprocedures, such as Prolog, to which highly effective~pace recovery techniques can be applied relatively easily.The Eartey algorithm pursues all possible parses inparallel, indexed by string position.
In principle, thispermits space to be recovered, as parsing progresses, bydeleting information relating to earlier string positions, l'tamy be possible to generalize this technique to EarleyDeduction.
by recognizing, either automatically ormanually, certain special properties of the input clauses.7.
Dec idab i l i ty  and  Computat iona lComplex i tyIt is not at.
all obvious that grammar formalisms basedon unification can be parsed within reasonable bounds oftime and space.
\[n fact, unrestricted DCGs have Turingmachine power, and LFG, although decidable, seemscapable of encoding exponentially hard problems.llowever, we need not give up our interest in thecomplexity analysis of unification-based parsing.
Whetherfor interesting subclasses of, grammars or specific~rammars of interest, it is still important to determinehow efficient parsing can be.
A basic step in that directionis to estimale the cost added by unification to theoperation of combining {reducing or expanding) anontcrmin.~l in a derivation with a nonterminal in agrammar ule.Because definite clauses are only semidecidable, generalproof procedures may not terminate for some sets ofdefinite clauses.
However, the specialized proofprocedures we have derived from parsing algorithms arestable:  if a set of definite clauses G is the translation of acontext-free grammar, the procedure will alwaysterminate (in success or failure) when to proving any startgoal for G. More interesting in this context is the notionof s t rong  s tab i l i ty ,  which depends on the followingnotion of off'line parsab i l i ty .
A DCG is offline-parsableif its context-free skeleton is not infinitely ambiguous.Using different terminology, Bresnan and Kaplan(Bresnan and Kaplan, 1982) have shown that the parsingproblem for LFG is decidable because LFGs are offlineparsable.
This result can be adapted easily to DCGs,showing that the parsing problem for offline-parsableDCGs is decidable.
Strong stability can now be defined: aparsing algorithm is strongly stable if it always terminatesfor offline-parsab\[e grammars.
For example, a direct DCGversion of the Earley parsing algorithm is stable but notstrongly so.In the following complexity arguments, we restrictourselves to offline-parsable grammars.
This is areasonable restriction for two reasons: (i) since generalDCGs have Turing machine power, there is no usefulnotion of computational complexity for the parser on itsown; (ii) (.here are good reasons to believe thatlinguistically relevant grammars must be offliae-parsable{Bresnan and Kaplaa, 1982).In estimating the added complexity of doing onlineunification, we start from the fact that the length of anyderivation of a terminal string in a finitely ambiguouscontext-free grammar is linearly bounded by the length ofthe termin:fi string.
The proof of this fact is omitted forlack of spa~.e, but can be found elsewhere (Pereira andWarren, 1.q83).General definite-clause proof procedures need to accessttle values of variables {bindings} in derived clauses.
Thestrueture-sh:lring method of representation makes thelime to access a variable binding at worst linear in thelength of 1he derivation.
Furthermore, the number ofvariables to be looked up in a derivation step is at worstlinear in the size of tile derivation.
Finally, the time (andspace) to finish a derivation step, once all the relevantbindings are known, does not depend on the size of thederivation.
Therefore, using this method for parsingoffline-parsable grammars makes the time complexity ofeach step at worst oIn 2) in the length of the input.Some simplifications are possible that improve that timebound.
First, it, is possible to use a va lue ar rayrcpresenta~i(m of hinding~ (Bayer and Moore.
1972} whileexploring any given derivation path.
reducing to aconstant he variable lookup time at the cost of having tosave and restore o(n} variable bindings from the valuearray each time the parsing procedure moves to explore adifferent derivation path.
Secondly, the unification costcan be mode independent of the derivation length, if wefor~o the occurs  check that prevents a variable frombeing bound to a term containing it.
Finally, thecombination of structure sharing and copying suggested inthe last section eliminates the overhead of switching to adifferent derivation path in the value array method at thecost of a uniform o(log n) time to look up or create avariabl, binding in a balanced binary tree.When adding a new edge to the chart, a chart parser142must verify that no edge with the same label between thesame nodes is already present.
In general DCG parsing(and therefore in online parsing with any unification-based formalism}, we cannot check for the "same label"(same lemma), because lemmas in general will containvariables.
\Ve must instead check for subsumption of thenew lemma by some old lemma.
The obvioussubsumption checking mechanism has an o(n 3) worst casecost, but the improved binding representations describedabove, together with the other special techniquesmentioned in the previous section, can be used to reducethis cost in practice.We do not yet have a full complexity comparisonbetween online and offline parsing, but it is easy toenvisage situations in which the number of edges createdby an online algorithm is much smaller than that for thecorresponding offline algorithm, whereas the cost ofapplying the unification constraints is the same for bothalgorithms.8.
Conc lus ionWe have outlined an approach to the problems ofparsing unification-based grammar formalisms that buildson the relationship between parsing and definite-clausededuction.Several theoretical and practical problems remain.Among these are the question of recognizing derivedclauses that are no longer useful in Earley-style parsing,the design of restricted formalisms with a polynomialbound on the number of distinct derived clauses, andindependent characterizations of the classes of offline-parsable grammars and languages.AcknowledgmentsWe would like to thank Barbara Grosz and StanRosenschein for their comments on earlier versions of thispaper.Re ferences.\.
V. Aho and .I.
D Ullman, The Theory o/Parsing,Translation and Compiling (Prentice-flail,Englewood Cliffs, New Jersey, 1972).R.
S. Boyer and J S. Moore, "The Sharing of Structurein Theorem-Proving Programs," in MachineIntelligence 7, B. Meltzer and D. Michie, eds.,pp.
101-116 (.John Wiley & Sons, New York, NewYork.
1.q72}..1.
Bresnan and R. Kaplan.
"Lexical-FunctionalGrammar: A Formal System for GrammaticalRepresentation," in The Mental Representation fGrammatical Relations, J. Bresnan, ed.,pp.
173-281 (NflT Press, Cambridge, Massachusetts,1982).A.
Colmerauer, "Metamorphosis Grammars," in NaturalLanguage Communication with Computers, L. Bole,ed.
(Springer-Verlag, Berlin, 1978).
First appeared as'Les Grammaires de Metamorphose', Grouped'Intelligence Artifieielle, Universitd de Marseille 17,November 1975.J.
Earley, "An Efficient Context-Free ParsingAlgorithm," Communications of the ACM, Vol.
13,No.
2, pp.
94-102 (February 1970).G.
Gazdar and G. Pullum, Generalized Phrase SlructureGrammar: A Theoretical Synopsis (IndianaUniversity Linguistics Club, Bloomington, Indiana,1982).S.
L. Graham, M. A. Harrison and W. L. Ruzzo, "AnImproved Context-Free Recognizer," ACMTransactions on Programming Languages andSystems, Vol.
2, No.
3, pp.
415-462 (July 1980).NI.
Kay, "Functional Grammar," Prec.
of the FifthAnnual A\[celing of the Berkeley Linguistic Society,pp.
142-158.
Berkeley Linguistic Society, Berkeley,California (February 17-19 19791 .M.
Kay, "Algorithm Schemata nd Data Structures inSyntactic Processing," Technical Report , X~EROXPale Alto Research Center, Pale Alto, California(1980).
A version will appear in the proceedings ofthe Nobel Symposium on Text Processing,(h,t henburg, 1980.R.
A. Kowalski.
Logic for Problem Solving (NorthHolland.
New York, New York, 1980}.M.
C. Mc('ord, "Slot Grammars," American Journal ofComputational Linguistics, Vol.
6.
No.
1. pp.2",,5-2Sli (Januar.v-March 1980).F.
C N. Pereira.
"Extraposition Grammars," AmericanJournal of Computational Linguistics, Vol.
7, No.
4.pp.
243-256 (October-December 1981).F.
C. N. Pereira.
Logic for Natural Language Analysis.Ph.D.
thesis.
University of Edinburgh.
Scotland.1982.F.
C'.
N. Pereira and D. H. D. Warren.
"Definite ClauseGrammars for Language Analysis - a Survey of theFormalism and a Comparison with AugmentedTransition Networks," Artificial Intelligence, Vot.13.
pp.
231-278 (19801.F.
C. N. Pereira and D. H. D. Warren, "Parsing a.sDeduction," Forthcoming technical note , ArtificialIntelligence Center, SRI International , Menlo Park,California { 1983).143J.
A. Robinson, "A Machine-Oriented Logic Based on theResolution Principle," Journal of the AGM, Vol.
12,pp.
23-44 (January 1965).P.
Roussel, "Prolog : Manuel de Rdf6rence etUtilisation," Technical Report, Groupe d'IntelligenceArtificielle, Universitd d'AJx-Marse.ille II, Marseille,France {1975).S.
Shieber, Personal communication, 1983.H.
Thompson, "Chart Parsing and Rule Schemata inGPSG," Proc.
of the 19th Annual Meeting of theAssociation for Computational Linguistics,pp.
167-172, Association for ComputationalLinguistics, Stanford University, Stanford, California(June 29-July 1 1981).M.
H. van Emden and R. A. Kowalski, "The Semanticsof Predicate Logic as a Programming Language,"Journal of the AC~V\[, Vol.
23, No.
4, pp.73.3-742 \[October 19781.D.
H. D. Warren.
Earley Deduction.
Unpublished note,1975.D H. D. Warren and F. C. N. Pereira, An EfficientEasily Adaptable System for Interpreting NaturalLangu.~e Queries.
To appear in the AmericanJournal of Computational Linguistics., 1983.144
