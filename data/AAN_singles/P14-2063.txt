Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 383?389,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsBuilding Sentiment Lexicons for All Major LanguagesYanqing ChenComputer Science Dept.Stony Brook UniversityStony Brook, NY 11794cyanqing@cs.stonybrook.eduSteven SkienaComputer Science Dept.Stony Brook UniversityStony Brook, NY 11794skiena@cs.stonybrook.eduAbstractSentiment analysis in a multilingualworld remains a challenging problem, be-cause developing language-specific senti-ment lexicons is an extremely resource-intensive process.
Such lexicons remain ascarce resource for most languages.In this paper, we address this lexicon gapby building high-quality sentiment lexi-cons for 136 major languages.
We in-tegrate a variety of linguistic resourcesto produce an immense knowledge graph.By appropriately propagating from seedwords, we construct sentiment lexicons foreach component language of our graph.Our lexicons have a polarity agreementof 95.7% with published lexicons, whileachieving an overall coverage of 45.2%.We demonstrate the performance of ourlexicons in an extrinsic analysis of 2,000distinct historical figures?
Wikipedia ar-ticles on 30 languages.
Despite cul-tural difference and the intended neutralityof Wikipedia articles, our lexicons showan average sentiment correlation of 0.28across all language pairs.1 IntroductionSentiment analysis of English texts has become alarge and active research area, with many commer-cial applications, but the barrier of language limitsthe ability to assess the sentiment of most of theworld?s population.Although several well-regarded sentiment lexi-cons are available in English (Esuli and Sebastiani,2006; Liu, 2010), the same is not true for mostof the world?s languages.
Indeed, our literaturesearch identified only 12 publicly available sen-timent lexicons for only 5 non-English languages(Chinese mandarin, German, Arabic, Japanese andItalian).
No doubt we missed some, but it is clearthat these resources are not widely available formost important languages.In this paper, we strive to produce a comprehen-sive set of sentiment lexicons for the worlds?
majorlanguages.
We make the following contributions:?
New Sentiment Analysis Resources ?
We havegenerated sentiment lexicons for 136 majorlanguages via graph propagation which arenow publicly available1.
We validate our ownwork through other publicly available, humanannotated sentiment lexicons.
Indeed, ourlexicons have polarity agreement of 95.7%with these published lexicons, plus an over-all coverage of 45.2%.?
Large-Scale Language Knowledge GraphAnalysis ?
We have created a massive com-prehensive knowledge graph of 7 million vo-cabulary words from 136 languages with over131 million semantic inter-language links,which proves valuable when doing alignmentbetween definitions in different languages.?
Extrinsic Evaluation ?
We elucidate the sen-timent consistency of entities reported in dif-ferent language editions of Wikipedia usingour propagated lexicons.
In particular, wepick 30 languages and compute sentimentscores for 2,000 distinct historical figures.Each language pair exhibits a Spearman sen-timent correlation of at least 0.14, with an av-erage correlation of 0.28 over all pairs.The rest of this paper is organized as follows.We review related work in Section 2.
In Section3, we describe our resource processing and de-sign decisions.
Section 4 discusses graph propaga-tion methods to identify sentiment polarity acrosslanguages.
Section 5 evaluates our results against1https://sites.google.com/site/datascienceslab/projects/383each available human-annotated lexicon.
Finally,in Section 6 we present our extrinsic evaluationof sentiment consistency in Wikipedia prior to ourconclusions.2 Related WorkSentiment analysis is an important area of NLPwith a large and growing literature.
Excellent sur-veys of the field include (Liu, 2013; Pang and Lee,2008), establishing that rich online resources havegreatly expanded opportunities for opinion min-ing and sentiment analysis.
Godbole et al (2007)build up an English lexicon-based sentiment anal-ysis system to evaluate the general reputation ofentities.
Taboada et al (2011) present a more so-phisticated model by considering patterns, includ-ing negation and repetition using adjusted weights.Liu (2010) introduces an efficient method, at thestate of the art, for doing sentiment analysis andsubjectivity in English.Researchers have investigated topic or domaindependent approaches to identify opinions.
Jijk-oun et al (2010) focus on generating topic spe-cific sentiment lexicons.
Li et al (2010) extractsentiment with global and local topic dependency.Gindl et al (2010) perform sentiment analysis ac-cording to cross-domain contextualization and Pakand Paroubek (2010) focus on Twitter, doing re-search on colloquial format of English.Work has been done to generalize sentimentanalysis to other languages.
Denecke (2008) per-forms multilingual sentiment analysis using Sen-tiWordNet.
Mihalcea et al (2007) learn multi-lingual subjectivity via cross-lingual projections.Abbasi et al (2008) extract specific language fea-tures of Arabic which requires language-specificknowledge.
G?
?nsc?a et al (2011) work on bettersentiment analysis system in Romanian.The ready availability of machine translation toand from English has prompted efforts to employtranslation for sentiment analysis (Bautin et al,2008).
Banea et al (2008) demonstrate that ma-chine translation can perform quite well when ex-tending the subjectivity analysis to multi-lingualenvironment, which makes it inspiring to replicatetheir work on lexicon-based sentiment analysis.Machine learning approaches to sentiment anal-ysis are attractive, because of the promise of re-duced manual processing.
Boiy and Moens (2009)conduct machine learning sentiment analysis us-ing multilingual web texts.
Deep learning ap-proaches draft off of distributed word embeddingwhich offer concise features reflecting the seman-tics of the underlying vocabulary.
Turian et al(2010) create powerful word embedding by train-ing on real and corrupted phrases, optimizing forthe replaceability of words.
Zou et al (2013) com-bine machine translation and word representationto generate bilingual language resources.
Socheret al (2012) demonstrates a powerful approach toEnglish sentiment using word embedding, whichcan easily be extended to other languages by train-ing on appropriate text corpora.3 Knowledge Graph ConstructionIn this section we will describe how we leverageoff a variety of NLP resources to construct the se-mantic connection graph we will use to propagatesentiment lexicons.Figure 1: Illustration of our knowledge graph,showing links between words and edge represen-tation to preserve source identity.
For each edgebetween corresponding words, a 5-bit integer willrecord the existence of 5 possible semantic links.The Polyglot project (Al-Rfou et al, 2013)identified the 100,000 most frequently used wordsin each language?s Wikipedia.
Drawing a can-didate lexicon from Wikipedia has some down-sides (e.g.
limited use of informal words), but isrepresentative and convenient over a large num-ber of languages.
In particular, we collect totalof 7,741,544 high-frequency words from 136 lan-guages to serve as vertices in our graph.We seek to identify as many semantic linksacross languages as possible to connect our net-work, and so integrated several resources:?
Wiktionary ?
This growing resource has en-384tries for 171 languages, edited by peoplewith sufficient background knowledge.
Wik-tionary provides about 19.7% of the totallinks covering 382,754 vertices in our graph.?
Machine Translation - We script the Googletranslation API to get even more semanticlinks.
In particular we ask for translations ofeach word in our English vocabulary to 57languages with available translators as wellas going from each known vocabulary wordin other languages to English.
In total, ma-chine translation provides 53.2% of the to-tal links and establishes connections between3.5 million vertices.?
Transliteration Links ?
Natural flow bringswords across languages with little morpho-logical change.
Closely related languagepairs (i.e.
Russian and Ukrainian) share manycharacters/words in common.
Though not al-ways true, words with same spelling usuallyhave similar meanings so this can improvethe coverage of semantic links.
Translitera-tion provides 22.1% of the total links in ourexperiment.?
WordNet ?
Finally, we gather synonyms andantonyms of English words from WordNet,which prove particularly useful in propagat-ing sentiment across languages.
In total wecollect over 100,000 pairs of synonyms andantonyms and created 5.0% of the total links.Links do not always agree in a bidirectionalmanner, particularly for multi-sense words, thusall links in our network are unidirectional.
Figure1 illustrates how we encode links from differentresources in an integer edge value.4 Graph PropagationSentiment propagation starts from English senti-ment lexicons.
Through semantic links in ourknowledge graph, words are able to extend theirsentiment polarities to adjacent neighbors.
Weexperimented with both graph propagation algo-rithm (Velikovich et al, 2010) and label propaga-tion algorithm (Zhu and Ghahramani, 2002; Raoand Ravichandran, 2009).
The primary differ-ence between is that label propagation takes multi-ple paths between two vertices into consideration,while graph propagation utilizes only the best pathbetween word pairs.We report results from using Liu?s lexicons(Liu, 2010) as seed words.
Liu?s lexicons con-tain 2006 positive words and 4783 negative words.Of these, 1422 positive words and 2956 negativewords (roughly 64.5%) appear among the 100,000English vertices in our graph.Dataset Propagation Acc CovArabicLabel 0.93 0.45Graph 0.94 0.46GermanLabel 0.97 0.31Graph 0.97 0.32EnglishLabel 0.92 0.55Graph 0.90 0.69ItalianLabel 0.73 0.29Graph 0.72 0.32JapaneseLabel 0.57 0.12Graph 0.56 0.15Chinese-1Label 0.95 0.62Graph 0.94 0.65Chinese-2Label 0.97 0.70Graph 0.97 0.72Table 1: Graph propagation vs label propagation.Acc represents the ratio of identical polarity be-tween our analysis and the published lexicons.Cov reflects what faction of our lexicons overlapwith published lexicons.Our knowledge network is comprised of linksfrom a heterogeneous collection of sources, of dif-ferent coverage and reliability.
For the task of de-ciding sentiment polarity of words, only antonymlinks are negative.
An edge gains zero weightif both negative and positive links exist.
Edgeshaving multiple positive links will be credited thehighest weight among all these links.
We con-ducted a grid search on the weight of each type oflinks to maximize the best overall accuracy on ourtest data of published non-English sentiment lexi-cons.
To avoid potential overfitting problems, gridsearch starts from SentiWordNet English lexicons(Esuli and Sebastiani, 2006) instead of Liu?s.5 Lexicon EvaluationWe collected all available published sentiment lex-icons from non-English languages to serve as stan-dard for our evaluation, including Arabic, Italian,German and Chinese.
Coupled with English senti-ment lexicons provides in total seven different testcases to experiment against, specifically:385Language ?lexicon?
+/- Ratio Language ?lexicon?
+/- Ratio Language ?lexicon?
+/- RatioAfrikaans 2299 0.40 Albanian 2076 0.41 Amharic 46 0.63Arabic 2794 0.41 Aragonese 97 0.47 Armenian 1657 0.43Assamese 493 0.49 Azerbaijani 1979 0.41 Bashkir 19 0.63Basque 1979 0.40 Belarusian 1526 0.43 Bengali 2393 0.42Bosnian 2020 0.42 Breton 184 0.42 Bulgarian 2847 0.40Burmese 461 0.48 Catalan 3204 0.37 Cebuano 56 0.54Chechen 26 0.65 Chinese 3828 0.34 Chuvash 17 0.76Croatian 2208 0.40 Czech 2599 0.41 Danish 3340 0.38Divehi 67 0.67 Dutch 3976 0.38 English 4376 0.32Esperanto 2604 0.40 Estonian 2105 0.41 Faroese 123 0.43Finnish 3295 0.40 French 4653 0.35 Frisian 224 0.43Gaelic 345 0.50 Galician 2714 0.37 German 3974 0.38Georgian 2202 0.40 Greek 2703 0.39 Gujarati 2145 0.44Haitian 472 0.44 Hebrew 2533 0.36 Hindi 3640 0.39Hungarian 3522 0.38 Icelandic 1770 0.40 Ido 183 0.49Interlingua 326 0.50 Indonesian 2900 0.37 Italian 4491 0.36Irish 1073 0.45 Japanese 1017 0.39 Javanese 168 0.51Kazakh 81 0.65 Kannada 2173 0.42 Kirghiz 246 0.49Khmer 956 0.49 Korean 2118 0.42 Kurdish 145 0.48Latin 2033 0.46 Latvian 1938 0.42 Limburgish 93 0.46Lithuanian 2190 0.41 Luxembourg 224 0.52 Macedonian 2965 0.39Malagasy 48 0.54 Malayalam 393 0.50 Malay 2934 0.39Maltese 863 0.50 Marathi 1825 0.48 Manx 90 0.51Mongolian 130 0.52 Nepali 504 0.49 Norwegian 3089 0.37Nynorsk 1894 0.39 Occitan 429 0.40 Oriya 360 0.51Ossetic 12 0.67 Panjabi 79 0.63 Pashto 198 0.50Persian 2477 0.39 Polish 3533 0.39 Portuguese 3953 0.35Quechua 47 0.55 Romansh 116 0.48 Romanian 3329 0.39Russian 2914 0.43 Sanskrit 178 0.59 Sami 24 0.71Serbian 2034 0.41 Sinhala 1122 0.43 Slovak 2428 0.43Slovene 2244 0.42 Spanish 4275 0.36 Sundanese 476 0.50Swahili 1314 0.42 Swedish 3722 0.39 Tamil 2057 0.40Tagalog 1858 0.44 Tajik 97 0.62 Tatar 76 0.50Telugu 2523 0.41 Thai 1279 0.51 Tibetan 24 0.63Turkmen 78 0.56 Turkish 2500 0.39 Uighur 18 0.44Ukrainian 2827 0.41 Urdu 1347 0.39 Uzbek 111 0.57Vietnamese 1016 0.38 Volapuk 43 0.70 Walloon 193 0.32Welsh 1647 0.42 Yiddish 395 0.43 Yoruba 276 0.50Table 2: Sentiment lexicon statistics.
We tag 10 languages having most/least sentiment words withblue/green color and 10 languages having highest/lowest ratio of positive words with orange/purple color.?
Arabic: (Abdul-Mageed et al, 2011).?
German: (Remus et al, 2010).?
English: (Esuli and Sebastiani, 2006).?
Italian: (Basile and Nissim, 2013).?
Japanese: (Kaji and Kitsuregawa, 2007).?
Chinese-1, Chinese-2: (He et al, 2010).We present the accuracy and coverage achievedby two propagation model in Table 1.
Both mod-els achieve similar accuracy while slightly morewords in graph propagation can be verified viapublished lexicons.
Performance is not good onJapanese because of mismatching between ourdictionary and the test data.Table 2 reveals that very sparse sentiment lex-icons resulted for a small but notable fraction ofthe languages we analyzed.
In particular, only 20languages yielded lexicons of less than 100 words.Without exception, they all have very small avail-able definitions in Wikitionary.
By contrast, 48languages had lexicons with over 2,000 words, an-other 16 with between 1,000 and 2,000: clearlylarge enough to perform a meaningful analysis.6 Extrinsic Evaluation: Consistency ofWikipedia SentimentWe consider evaluating our lexicons on the con-sistency of Wikipedia pages about a particular in-dividual person among various languages.
Asour candidate entities for analysis, we use theWikipedia pages of 2,000 most significant peo-ple as measured in the recent book Who?s Bigger?
(Skiena and Ward, 2013).
The sentiment polar-ity of a page is simply computed by subtracting386Type Person Z-score distributionGoodLeonardo da VinciSteven SpielbergBadAdolf HitlerOsama bin LadenTable 3: Z-score distribution examples.
We label 10 languages with their language code and other usingtick marks on the x-axis.the number of negative words from that of posi-tive words, divided by the sum of both.The differing ratio of positive and negative po-larity terms in Table 2 means that sentiment cannotbe directly compared across languages.
For moreconsistent evaluation we compute the z-score ofeach entity against the distribution of all its lan-guage?s entities.We use the Spearman correlation coefficient tomeasure the consistence of sentiment distributionacross all entities with pages in a particular lan-guage pair.
Figure 2 shows the results for 30 lan-guages with largest propagated sentiment lexiconsize.
All pairs of language exhibit positive corre-lation (and hence generally stable and consistentsentiment), with an average correlation of 0.28.Finally, Table 3 illustrates sentiment consis-tency over all 136 languages (represented by bluetick marks), with the first 10 languages in Figure 2granted labels.
Respected artists like Steven Spiel-berg and Leonardo da Vinci show as consistentlypositive sentiment as notorious figures like Osamabin Laden and Adolf Hitler are negative.7 ConclusionsOur knowledge graph propagation is generally ef-fective at producing useful sentiment lexicons.
In-terestingly, the ratio of positive sentiment wordsis strongly connected with number of sentimentwords ?
it is noteworthy that English has thesmallest ratio of positive lexicon terms.
TheFigure 2: Heatmap of sentiment correlation be-tween 30 languages.phenomenon possibly shows that many negativewords reflecting cultural nuances do not translatewel.
We believe that this ratio can be consid-ered as quality measurement of the propagation.Similar approaches can be extended to other NLPtasks using different semantic links, specific dic-tionary and special seed words.
Future work willrevolve around learning modifiers, negation terms,and various entity/sentiment attribution.AcknowledgmentsThis research was partially supported by NSFGrants DBI-1060572 and IIS-1017181, and aGoogle Faculty Research Award.387ReferencesAhmed Abbasi, Hsinchun Chen, and Arab Salem.2008.
Sentiment analysis in multiple languages:Feature selection for opinion classification in webforums.
ACM Transactions on Information Systems(TOIS), 26(3):12.Muhammad Abdul-Mageed, Mona T Diab, and Mo-hammed Korayem.
2011.
Subjectivity and senti-ment analysis of modern standard arabic.
In ACL(Short Papers), pages 587?591.Rami Al-Rfou, Bryan Perozzi, and Steven Skiena.2013.
Polyglot: Distributed word represen-tations for multilingual nlp.
arXiv preprintarXiv:1307.1662.Carmen Banea, Rada Mihalcea, Janyce Wiebe, andSamer Hassan.
2008.
Multilingual subjectivityanalysis using machine translation.
In Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing, pages 127?135.
Associationfor Computational Linguistics.Valerio Basile and Malvina Nissim.
2013.
Sentimentanalysis on italian tweets.
WASSA 2013, page 100.M.
Bautin, L. Vijayarenu, and S. Skiena.
2008.
In-ternational sentiment analysis for news and blogs.Second Int.
Conf.
on Weblogs and Social Media(ICWSM 2008).Erik Boiy and Marie-Francine Moens.
2009.
Amachine learning approach to sentiment analysisin multilingual web texts.
Information retrieval,12(5):526?558.Kerstin Denecke.
2008.
Using sentiwordnet for mul-tilingual sentiment analysis.
In Data EngineeringWorkshop, 2008.
ICDEW 2008.
IEEE 24th Interna-tional Conference on, pages 507?512.
IEEE.Andrea Esuli and Fabrizio Sebastiani.
2006.
Senti-wordnet: A publicly available lexical resource foropinion mining.
In Proceedings of LREC, volume 6,pages 417?422.Stefan Gindl, Albert Weichselbraun, and Arno Scharl.2010.
Cross-domain contextualisation of sentimentlexicons.
19th European Conference on ArtificialIntelligence (ECAI).Alexandru-Lucian G?
?nsc?a, Emanuela Boros?, AdrianIftene, Diana Trandab?At?, Mihai Toader, MariusCor?
?ci, Cenel-Augusto Perez, and Dan Cristea.2011.
Sentimatrix: multilingual sentiment analy-sis service.
In Proceedings of the 2nd Workshopon Computational Approaches to Subjectivity andSentiment Analysis, pages 189?195.
Association forComputational Linguistics.Namrata Godbole, Manja Srinivasaiah, and StevenSkiena.
2007.
Large-scale sentiment analysis fornews and blogs.
ICWSM, 7.Yulan He, Harith Alani, and Deyu Zhou.
2010.
Ex-ploring english lexicon knowledge for chinese senti-ment analysis.
CIPS-SIGHAN Joint Conference onChinese Language Processing.Valentin Jijkoun, Maarten de Rijke, and WouterWeerkamp.
2010.
Generating focused topic-specific sentiment lexicons.
In Proceedings of the48th Annual Meeting of the Association for Compu-tational Linguistics, pages 585?594.
Association forComputational Linguistics.Nobuhiro Kaji and Masaru Kitsuregawa.
2007.
Build-ing lexicon for sentiment analysis from massive col-lection of html documents.
In EMNLP-CoNLL,pages 1075?1083.Fangtao Li, Minlie Huang, and Xiaoyan Zhu.
2010.Sentiment analysis with global topics and local de-pendency.
In AAAI.Bing Liu.
2010.
Sentiment analysis and subjectivity.Handbook of natural language processing, 2:568.Bing Liu.
2013.
Sentiment Analysis and Opinion Min-ing.
Morgan and Claypool.Rada Mihalcea, Carmen Banea, and Janyce Wiebe.2007.
Learning multilingual subjective lan-guage via cross-lingual projections.
In AN-NUAL MEETING-ASSOCIATION FOR COMPU-TATIONAL LINGUISTICS, volume 45, page 976.Alexander Pak and Patrick Paroubek.
2010.
Twitter asa corpus for sentiment analysis and opinion mining.In LREC.Bo Pang and Lillian Lee.
2008.
Opinion mining andsentiment analysis.
Foundations and trends in infor-mation retrieval, 2(1-2):1?135.Delip Rao and Deepak Ravichandran.
2009.
Semi-supervised polarity lexicon induction.
In Proceed-ings of the 12th Conference of the European Chap-ter of the Association for Computational Linguistics,pages 675?682.
Association for Computational Lin-guistics.Robert Remus, Uwe Quasthoff, and Gerhard Heyer.2010.
Sentiws-a publicly available german-language resource for sentiment analysis.
In LREC.Steven Skiena and Charles Ward.
2013. Who?s Big-ger?
: Where Historical Figures Really Rank.
Cam-bridge University Press.Richard Socher, Brody Huval, Christopher D. Man-ning, and Andrew Y. Ng.
2012.
Semantic com-positionality through recursive matrix-vector spaces.In Proceedings of the 2012 Conference on Em-pirical Methods in Natural Language Processing(EMNLP).Maite Taboada, Julian Brooke, Milan Tofiloski, Kim-berly Voll, and Manfred Stede.
2011.
Lexicon-based methods for sentiment analysis.
Computa-tional linguistics, 37(2):267?307.388Joseph Turian, Lev Ratinov, and Yoshua Bengio.
2010.Word representations: a simple and general methodfor semi-supervised learning.
In Proceedings of the48th Annual Meeting of the Association for Compu-tational Linguistics, pages 384?394.
Association forComputational Linguistics.Leonid Velikovich, Sasha Blair-Goldensohn, KerryHannan, and Ryan McDonald.
2010.
The viabilityof web-derived polarity lexicons.
In Human Lan-guage Technologies: The 2010 Annual Conferenceof the North American Chapter of the Associationfor Computational Linguistics, pages 777?785.
As-sociation for Computational Linguistics.Xiaojin Zhu and Zoubin Ghahramani.
2002.
Learningfrom labeled and unlabeled data with label propa-gation.
Technical report, Technical Report CMU-CALD-02-107, Carnegie Mellon University.Will Y Zou, Richard Socher, Daniel Cer, and Christo-pher D Manning.
2013.
Bilingual word embeddingsfor phrase-based machine translation.
In Proceed-ings of the 2013 Conference on Empirical Methodsin Natural Language Processing, pages 1393?1398.389
