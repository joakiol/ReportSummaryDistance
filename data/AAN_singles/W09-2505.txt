Proceedings of the 2009 Workshop on Applied Textual Inference, ACL-IJCNLP 2009, pages 36?43,Suntec, Singapore, 6 August 2009.c?2009 ACL and AFNLPOptimizing Textual Entailment Recognition Using Particle SwarmOptimizationYashar MehdadUniversity of Trento and FBK - IrstTrento, Italymehdad@fbk.euBernardo MagniniFBK - IrstTrento, Italymagnini@fbk.euAbstractThis paper introduces a new method to im-prove tree edit distance approach to tex-tual entailment recognition, using particleswarm optimization.
Currently, one of themain constraints of recognizing textual en-tailment using tree edit distance is to tunethe cost of edit operations, which is a dif-ficult and challenging task in dealing withthe entailment problem and datasets.
Wetried to estimate the cost of edit operationsin tree edit distance algorithm automati-cally, in order to improve the results fortextual entailment.
Automatically estimat-ing the optimal values of the cost opera-tions over all RTE development datasets,we proved a significant enhancement inaccuracy obtained on the test sets.1 IntroductionOne of the main aspects of natural languages is toexpress the same meaning in many possible ways,which directly increase the language variabilityand emerges the complex structure in dealing withhuman languages.
Almost all computational lin-guistics tasks such as Information Retrieval (IR),Question Answering (QA), Information Extrac-tion (IE), text summarization and Machine Trans-lation (MT) have to cope with this notion.
TextualEntailment Recognition was proposed by (Daganand Glickman, 2004), as a generic task in order toconquer the problem of lexical, syntactic and se-mantic variabilities in languages.Textual Entailment can be explained as an as-sociation between a coherent text (T) and a lan-guage expression, called hypothesis (H) such thatentailment function for the pair T-H returns thetrue value when the meaning of H can be inferredfrom the meaning of T and false, otherwise.Amongst the approaches to the problem of tex-tual entailment, some methods utilize the no-tion of distance between the pair of T and H asthe main feature which separates the entailmentclasses (positive and negative).
One of the suc-cessful algorithms implemented Tree Edit Dis-tance (TED), based on the syntactic features thatare represented in the structured parse tree of eachstring (Kouylekov and Magnini, 2005).
In thismethod the distance is computed as the cost ofthe edit operations (insertion, deletion and substi-tution) that transform the text T into the hypothesisH.
Each edit operation has an associated cost andthe entailment score is calculated such that the setof operations would lead to the minimum cost.Generally, the initial cost is assigned to eachedit operation empirically, or based on the ex-pert knowledge and experience.
These methodsemerge a critical problem when the domain, fieldor application is new and the level of expertise andempirical knowledge is very limited.
In dealingwith textual entailment, (Kouylekov and Magnini,2006) tried to experiment different cost valuesbased on various linguistics knowledge and prob-abilistics estimations.
For instance, they definedthe substitution cost as a function of similaritybetween two nodes, or, for insertion cost, theyemployed Inverse Document Frequency (IDF) ofthe inserted node.
However, the results could notproven to be optimal.Other approaches towards estimating the costof operations in TED tried to learn a generic ordiscriminative probabilistic model (Bernard et al,2008; Neuhaus and Bunke, 2004) from the data,without concerning the optimal value of each op-eration.
One of the drawbacks of those approachesis that the cost values of edit operations are hiddenbehind the probabilistic model.
Additionally, thecost can not be weighted or varied according tothe tree context and node location (Bernard et al,2008).In order to overcome these drawbacks, we areproposing a stochastic method based on Particle36Swarm Optimization (PSO), to estimate the costof each edit operation for textual entailment prob-lem.
Implementing PSO, we try to learn the op-timal cost for each operation in order to improvethe prior textual entailment model.
In this paper,the goal is to automatically estimate the best possi-ble operation costs on the development set.
A fur-ther advantage of such method, besides automaticlearning of the operation costs, is being able to in-vestigate the cost values to better understand howTED approaches the data in textual entailment.The rest of the paper is organized as follows:After describing the TED approach to textual en-tailment in the next section, PSO optimization al-gorithm and our method in applying it to the prob-lem are explained in sections 4 and 5.
Then wepresent our experimental setup as well as the re-sults, in detail.
Finally, in the conclusion, the mainadvantages of our approach are reviewed and fur-ther developments are proposed accordingly.2 Tree Edit Distance and TextualEntailmentOne of the approaches to textual entailment isbased on the Tree Edit Distance (TED) betweenT and H. The tree edit distance measure is a simi-larity metric for rooted ordered trees.
This metricwas initiated by (Tai, 1979) as a generalization ofthe string edit distance problem and was improvedby (Zhang and Shasha, 1989) and (Klein, 1998).The distance is computed as the cost of editingoperations (i.e.
insertion, deletion and substitu-tion), which are required to transform the text Tinto the hypothesis H, while each edit operation ontwo text fragments A and B (denoted as A ?
B)has an associated cost (denoted as ?
(A ?
B)).
Intextual entailment context, the edit operations aredefined in the following way based on the depen-dency parse tree of T and H:?
Insertion (?
?
A): insert a node A fromthe dependency tree of H into the depen-dency tree of T. When a node is inserted itis attached to the dependency relation of thesource label.?
Deletion (A ?
?
): delete a node A fromthe dependency tree of T. When A is deletedall its children are attached to the parent ofA.
It is not required to explicitly delete thechildren of A, as they are going to be eitherdeleted or substituted in a following step.?
Substitution (A ?
B): change the label ofa node A in the source tree into a label of anode B of the target tree.
In the case of substi-tution, the relation attached to the substitutednode is changed with the relation of the newnode.According to (Zhang and Shasha, 1989), the min-imum cost mappings of all the descendants ofeach node has to be computed before the nodeis encountered, so the least-cost mapping can beselected right away.
To accomplish this the al-gorithm keeps track of the keyroots of the tree,which are defined as a set that contains the rootof the tree plus all nodes which have a left sibling.This problem can be easily solved using recursivemethods (Selkow, 1977), or as it was suggested in(Zhang and Shasha, 1989) by dynamic program-ming.
(Zhang and Shasha, 1989) defined the rel-evant subproblems of tree T as the prefixes of allspecial subforests rooted in the keyroots.
This ap-proach computes the TED (?)
by the followingequations:?
(FT, ?)
=?(FT?
rFT, ?)
+ ?(rFT?
?)
(1)?
(?, FH) =?
(?, FH?
rFH) + ?(?
?
rFH) (2)?
(FT, FH) =min????????????????(FT?
rFT, FH) + ?(rFT?
?)?
(FT, FH?
rFH) + ?(?
?
rFH)?
(FT(rFT), FH(rFH))+?(FT?
T (rFT), FH?H(rFH))+?(rFT?
rFH)(3)where FTand FHare forests of T and H , whilerFTand rFHare the rightmost roots of the treesin FTand FHrespectively.
?
is an empty forest.Moreover, FT(rFT) and FH(rFH) are the forestsrooted in rFTand rFHrespectively.Estimating ?
as the bottom line of the compu-tation is directly related to the cost of each oper-ation.
Moreover, the cost of edit operations cansimply change the way that a tree is transformedto another.
As Figure 11shows (Demaine et al,2007), there could exist more than one edit scriptfor transforming each tree to another.
Based on the1The example adapted from (Demaine et al, 2007)37Figure 1: Two possible edit scripts to transform one tree to another.main definition of this approach, TED is the costof minimum cost edit script between two trees.The entailment score for a pair is calculated onthe minimal set of edit operations that transformthe dependency parse tree of T into H. An entail-ment relation is assigned to a T-H pair where theoverall cost of the transformations is below a cer-tain threshold.
The threshold, which correspondsto tree edit distace, is empirically estimated overthe dataset.
This method was implemented by(Kouylekov and Magnini, 2005), based on the al-gorithm by (Zhang and Shasha, 1989).In this method, a cost value is assigned to eachoperation initially, and the distance is computedbased on the initial cost values.
Considering thatthe distance can vary in different datasets, con-verging to an optimal set of values for operationsis almost empirically impossible.
In the follow-ing sections, we propose a method for estimat-ing the optimum set of values for operation costsin TED algorithm dealing with textual entailmentproblem.
Our method is built on adapting PSOoptimization approach as a search process to auto-mate the procedure of the cost estimation.3 Particle Swarm OptimizationPSO is a stochastic optimization technique whichwas introduced based on the social behaviour ofbird flocking and fish schooling (Eberhart et al,2001).
It is one of the population-based searchmethods which takes advantage of the concept ofsocial sharing of information.
The main struc-ture of this algorithm is not very different fromother evolutionary techniques such as Genetic Al-gorithms (GA); however, the easy implementationand less complexity of PSO, as two main charac-teristics, are good motivations to apply this opti-mization approach in many areas.In this algorithm each particle can learn fromthe experience of other particles in the same pop-ulation (called swarm).
In other words, each parti-cle in the iterative search process, would adjust itsflying velocity as well as position not only basedon its own acquaintance, but also other particles?flying experience in the swarm.
This algorithm hasfound efficient in solving a number of engineeringproblems.
In the following, we briefly explain themain concepts of PSO.To be concise, for each particle at each itera-tion, the position Xi(Equation 4) and velocity Vi(Equation 5) is updated.
Xbiis the best positionof the particle during its past routes and Xgiisthe best global position over all routes travelled bythe particles of the swarm.
r1and r2are randomvariables drawn from a uniform distribution in therange [0,1], while c1and c2are two accelerationconstants regulating the relative velocities with re-spect to the best local and global positions.
Theweight ?
is used as a tradeoff between the globaland local best positions and its value is usuallyselected slightly less than 1 for better global ex-ploration (Melgani and Bazi, 2008).
The optimalposition is computed based on the fitness func-tion defined in association with the related prob-lem.
Both position and velocity are updated dur-ing the iterations until convergence is reached oriterations attain the maximum number defined bythe user.
This search process returns the best fit-ness function over the particles, which is definedas the optimized solution.Xi= Xi+ Vi(4)Vi= ?Vi+ c1r1(Xbi?Xi)+ c2r2(Xgi?Xi) (5)Algorithm 1 shows a simple pseudo code ofhow this optimization algorithm works.
In the restof the paper, we describe our method to integratethis algorithm with TED.38Algorithm 1 PSO algorithmfor all particles doInitialize particleend forwhile Convergence or maximum iterationdofor all particles doCalculate fitness functionif fitness function value > XbithenXbi?
fitness function valueend ifend forchoose the best particle amongst all in Xgifor all particles docalculate Viupdate Xiend forend whilereturn best particle4 Automatic Cost EstimationOne of the challenges in applying TED for rec-ognizing textual entailment is estimating the costof each edit operation which transforms the text Tinto the hypothesis H in an entailment pair.
Sincethe cost of edit operations can directly affect thedistance, which is the main criteria to measure theentailment, it is not trivial to estimate the cost ofeach operation.
Moreover, considering that imply-ing different costs for edit operations can affect theresults in different data sets and approaches, it mo-tivates the idea of optimizing the cost values.4.1 PSO SetupOne of the most important steps in applying PSOis to define a fitness function which could lead theswarm to the optimized particles based on the ap-plication and data.
The choice of this functionis very crucial, since PSO evaluates the qualityof each candidate particle for driving the solutionspace to optimization, on the basis of the fitnessfunction.
Moreover, this function should possiblyimprove the textual entailment recognition model.In order to attain these goals, we tried to definetwo main fitness functions as follows.1.
Bhattacharyya Distance: This measure wasproposed by (Bhattacharyya, 1943) as a sta-tistical measure to determine the similarityor distance between two discrete probabil-ity distributions.
In binary classification, thismethod is widely used to measure the dis-tance between two different classes.
In thestudies by (Fukunaga, 1990), Bhattacharyyadistance was occluded to be one of the mosteffective measure specifically for estimatingthe separability of two classes.
Figure 2shows the intuition behind this measure.Figure 2: Bhattacharyya distance between twoclasses with similar variances.Bhattacharyya distance is calculated based onthe covariance (?)
and mean (?)
of each dis-tribution based on its simplest formulation inEquation 6 (Reyes-Aldasoro and Bhalerao,2006).
Maximizing the distance betweenthe classes would result a better separabilitywhich aims to a better classification results.Furthermore, estimating the costs using thisfunction would indirectly improve the perfor-mance specially in classification problems.
Itcould be stated that, maximizing the Bhat-tacharyya distance would increase the separa-bility of two entailment classes which resultin a better performance.BD(c1, c2) =14ln{14(?2c1?2c2+?2c2?2c1+ 2)}+14{(?c1?
?c2)2?2c1+ ?2c2} (6)2.
Accuracy: Accuracy or any performancemeasure obtained from a TED based system,can define a good fitness function in optimiz-ing the cost values.
Since maximizing theaccuracy would directly increase the perfor-mance of the system or enhance the modelto solve the problem, this measure is a pos-sible choice to adapt in order to achieve ouraim.
In this method, trying to maximize thefitness function will compute the best modelbased on the optimal cost values in the parti-cle space of PSO algorithm.In other words, by defining the accuracy ob-tained from 10 fold cross-validation over the39development set, as the fitness function, wecould estimate the optimized cost of the editoperations.
Maximizing the accuracy gainedin this way, would lead to find the set of editoperation costs which directly increases ouraccuracy, and consequently guides us to themain goal of optimization.In the following section, the procedure of esti-mating the optimal costs are described in detail.4.2 Integrating TED with PSO for TextualEntailment ProblemThe procedure describing the proposed system tooptimize and estimate the cost of edit operationsin TED applying PSO algorithm is as follows.a) InitializationStep 1) Generate a random swarm of particles(in a simple case each particle is de-fined by the cost of three operations).Step 2) For each position of the particle fromthe swarm, obtain the fitness functionvalue (Bhattacharyya distance or accu-racy) over the training data.Step 3) Set the best position of each particlewith its initial position (Xbi).b) SearchStep 4) Detect the best global position (Xgi)in the swarm based on maximum valueof the fitness function over all exploredroutes.Step 5) Update the velocity of each particle(Vi).Step 6) Update the position of each particle(Xi).
In this step, by defining theboundaries, we could stop the particleto exit the allowed search space.Step 7) For each candidate particle calculatethe fitness function (Bhattacharyyadistance or accuracy).Step 8) Update the best position of each parti-cle if the current position has a largervalue.c) ConvergenceStep 9) Run till the maximum number of iter-ation (in our case set to 10) is reachedor start the search process.d) ResultsStep 10) Return the best fitness function valueand the best particle.
In this step theoptimum costs are returned.Following the steps above, in contrary to de-termine the entailment relation applying tree editdistance, the operation costs can be automaticallyestimated and optimized.
In this process, both fit-ness functions could be easily compared and thecost values leading to the better model would beselected.
In the following section, the experimen-tal procedure for obtaining the optimal costs byexploiting the PSO approach to TE is described.5 Experimental DesignIn our experiments we show an increase in the per-formance of TED based approach to textual en-tailment, by optimizing the cost of edit operations.In the following subsections, the framework anddataset of our experiments are elaborated.5.1 Dataset DescriptionOur experiments were conducted on the basisof the Recognizing Textual Entailment (RTE)datasets2, which were developed under PASCALRTE challenge.
Each RTE dataset includes its owndevelopment and test set, however, RTE-4 was re-leased only as a test set and the data from RTE-1to RTE-3 were used as development set.
More de-tails about the RTE datasets are illustrated in Table5.1.Number of pairsDevelopment TestDatasets YES NO YES NORTE-1 283 284 400 400RTE-2 400 400 400 400RTE-3 412 388 410 390RTE-4 ?
?
500 500Table 1: RTE-1 to RTE-4 datasets.5.2 Experimental FrameworkIn our experiments, in order to deal with TEDapproach to textual entailment, we used EDITS3package (Edit Distance Textual Entailment Suite)2http://www.pascal-network.org/Challenges/RTE1-43The EDITS system has been supported by the EU-funded project QALL-ME (FP6 IST-033860).
Available athttp://edits.fbk.eu/40(Magnini et al, 2009).
This system is an opensource software based on edit distance algorithms,and computes the T-H distance as the cost of theedit operations (i.e.
insertion, deletion and substi-tution) that are necessary to transform T into H.By defining the edit distance algorithm and a costscheme (assigning a cost to the edit operations),this package is able to learn a TED threshold, overa set of string pairs, to decide if the entailment ex-ists in a pair.In addition, we partially exploit the JSwarm-PSO4(Cingolani, 2005) package, with some adap-tations, as an implementation of PSO algorithm.Each pair in the datasets is converted to two syn-tactic dependency parse trees using the Stanfordstatistical parser5, developed in the Stanford uni-versity NLP group by (Klein and Manning, 2003).Figure 3: Five main steps of the experimentalframework.In order to take advantage of PSO optimizationapproach, we integrated EDITS and JSwarm-PSOto provide a flexible framework for the experi-ments (Figure 5.3).
In this way, we applied thedefined fitness functions in the integrated system.The Bhattacharyya distance between two classes(YES and NO), in each experiment, could be com-puted based on the TED score of each pair in thedataset.
Moreover, the accuracy, by default, iscomputed by EDITS over the training set basedon 10-fold cross-validation.5.3 Experimental SchemeWe conducted six different experiments in two setson each RTE dataset.
The costs were estimated onthe training set and the results obtained based onthe estimated costs over the test set.
In the first4http://jswarm-pso.sourceforge.net/5http://nlp.stanford.edu/software/lex-parser.shtmlset of experiments, we set a simple cost schemebased on three operations.
Implementing this costscheme, we expect to optimize the cost of eachedit operation without considering that the opera-tion costs may vary based on different character-istics of a node, such as size, location or content.The results were obtained considering three dif-ferent settings: 1) the random cost assignment; 2)assigning the cost based on the human expertiseknowledge and intuition (called Intuitive), and 3)automatic estimated and optimized cost for eachoperation.
In the second case, we used the samescheme which was used in EDITS by its develop-ers (Magnini et al, 2009).In the second set of experiments, we tried tocompose an advanced cost scheme with morefine-grained operations to assign a weight to theedit operations based on the characteristics of thenodes.
For example if a node is in the list of stop-words, the deletion cost is set to zero.
Otherwise,the cost of deletion would be equal to the numberof words in H multiplied by word?s length (num-ber of characters).
Similarly, the cost of insertinga word w in H is set to 0 if w is a stop word,and to the number of words in T multiplied bywords length otherwise.
The cost of substitutingtwo words is the Levenshtein distance (i.e.
the editdistance calculated at the level of characters) be-tween their lemmas, multiplied by the number ofwords in T, plus number of words in H. By this in-tuition, we tried to optimize nine specialized costsfor edit operations (i.e.
each particle is defined by9 parameters to be optimized).
We conducted theexperiments using all three cases mentioned in thesimple cost scheme.In each experiment, we applied both fitnessfunctions in the optimization; however, at the finalphase, the costs which led to the maximum resultswere chosen as the estimated operation costs.
Inorder to save breath and time, we set the numberof iterations to 10, in addition, the weight ?
wasset to 0.95 for better global exploration (Melganiand Bazi, 2008).6 ResultsOur results are summarized in Table 2.
We showthe accuracy gained by a distance-based (word-overlap) baseline for textual entailment (Mehdadand Magnini, 2009) to be compared with the re-sults achieved by the random, intuitive and op-timized cost schemes using EDITS system.
For41Data setModel RTE-4 RTE-3 RTE-2 RTE-1SimpleRandom 49.6 53.62 50.37 50.5Intuitive 51.3 59.6 56.5 49.8Optimized 56.5 61.62 58 58.12AdvancedRandom 53.60 52.0 54.62 53.5Intuitive 57.6 59.37 57.75 55.5Optimized 59.5 62.4 59.87 58.62Baseline 55.2 60.9 54.8 51.4RTE-4 Challenge 57.0Table 2: Comparison of accuracy on all RTE datasets based on optimized and unoptimized cost schemes.the better comparison, we also present the resultsof the EDITS system in RTE-4 challenge using acombination of different distances as features forclassification (Cabrio et al, 2008).In the first experiment, we estimated the cost ofeach operation using the simple cost scheme.
Ta-ble 2 shows that in all datasets, accuracy improvedup to 9% by optimizing the cost of each edit opera-tion.
Results prove that the optimized cost schemeenhances the quality of the system performance,even more than the cost scheme used by experts(Intuitive cost scheme) (Magnini et al, 2009).Furthermore, in the second set of experiments,using the fine-grained and weighted cost schemefor edit operations we could achieve the highest re-sults in accuracy.
The chart in Figure 4, illustaresthat all optimized results outperform the word-overlap baseline for textual entailment as well asthe accuracy obtained in RTE-4 challenge usingcombination of different distances as features forclassification (Cabrio et al, 2008).By exploring the estimated optimal cost of eachoperation, another interesting point was discov-ered.
The estimated cost of deletion in the firstset of experiments was 0, which means that delet-ing a node from the dependency tree of T does noteffect the quality of results.
This proves that bysetting different cost schemes, we could exploreeven some linguistics phenomena which exists inthe entailment dataset.
Studying the dataset fromthis point of view might be interesting to find somehidden information which can not be explored eas-ily.In addition, the optimized model can reflectmore consistency and stability (from 58 to 62 inaccuracy) than other models, while in unoptimizedmodels the result varies more, on different datasets(from 50 in RTE-1 to 59 in RTE-3).
Moreover, webelieve that by changing some parameters such asmaximum number of iterations, or by defining abetter cost scheme, there could be still a room forimprovement.Figure 4: Accuracy obtained by different experi-mental setups.7 ConclusionIn this paper, we proposed a novel approach for es-timating the cost of edit operations for the tree editdistance approach to textual entailment.
With thiswork we illustrated another step forward in im-proving the foundation of working with distance-based algorithms for textual entailment.
The ex-perimental results confirm our working hypothe-sis that by improving the results in applying treeedit distance for textual entailment, besides out-performing the distance-based baseline for recog-42nizing textual entailment.We believe that for further development, ex-tending the cost scheme to find weighted andspecialized cost operations to deal with differentcases, can lead to more interesting results.
Besidesthat, exploring and studying the estimated cost ofoperations, could be interesting from a linguisticspoint of view.AcknowledgmentsBesides my special thanks to Farid Melganifor his helpful ideas, I acknowledge MilenKouylekov for his academic and technical sup-ports.
This work has been partially sup-ported by the three-year project LiveMemories(http://www.livememories.org/), funded by theProvincia Autonoma di Trento.ReferencesMarc Bernard, Laurent Boyer, Amaury Habrard, andMarc Sebban.
2008.
Learning probabilistic modelsof tree edit distance.
Pattern Recogn., 41(8):2611?2629.A.
Bhattacharyya.
1943.
On a measure of diver-gence between two statistical populations defined byprobability distributions.
Bull.
Calcutta Math.
Soc.,35:99109.Elena Cabrio, Milen Kouylekovand, and BernardoMagnini.
2008.
Combining specialized entailmentengines for rte-4.
In Proceedings of TAC08, 4thPASCAL Challenges Workshop on Recognising Tex-tual Entailment.Pablo Cingolani.
2005.
Jswarm-pso: Particle swarmoptimization package.
Available at http://jswarm-pso.sourceforge.net/.Ido Dagan and Oren Glickman.
2004.
Probabilis-tic textual entailment: Generic applied modeling oflanguage variability.
In Proceedings of the PAS-CAL Workshop of Learning Methods for Text Under-standing and Mining.E.
Demaine, S. Mozes, B. Rossman, and O. Weimann.2007.
An optimal decomposition algorithm for treeedit distance.
In Proceedings of the 34th Inter-national Colloquium on Automata, Languages andProgramming (ICALP), pages 146?157.Russell C. Eberhart, Yuhui Shi, and James Kennedy.2001.
Swarm Intelligence.
The Morgan KaufmannSeries in Artificial Intelligence.
Morgan Kaufmann.Keinosuke Fukunaga.
1990.
Introduction to statisti-cal pattern recognition (2nd ed.).
Academic PressProfessional, Inc., San Diego, CA, USA.Dan Klein and Christopher D. Manning.
2003.
Fastexact inference with a factored model for naturallanguage parsing.
In Advances in Neural Informa-tion Processing Systems 15, pages 3?10, Cambridge,MA.
MIT Press.Philip N. Klein.
1998.
Computing the edit-distancebetween unrooted ordered trees.
In ESA ?98: Pro-ceedings of the 6th Annual European Symposium onAlgorithms, pages 91?102, London, UK.
Springer-Verlag.Milen Kouylekov and Bernardo Magnini.
2005.
Rec-ognizing textual entailment with tree edit distancealgorithms.
In PASCAL Challenges on RTE, pages17?20.Milen Kouylekov and Bernardo Magnini.
2006.
Treeedit distance for recognizing textual entailment: Es-timating the cost of insertion.
In PASCAL RTE-2Challenge.Bernardo Magnini, Milen Kouylekov, and ElenaCabrio.
2009.
Edits - edit distance tex-tual entailment suite user manual.
Available athttp://edits.fbk.eu/.Yashar Mehdad and Bernardo Magnini.
2009.
A wordoverlap baseline for the recognizing textual entail-ment task.
Available at http://edits.fbk.eu/.Farid Melgani and Yakoub Bazi.
2008.
Classi-fication of electrocardiogram signals with supportvector machines and particle swarm optimization.IEEE Transactions on Information Technology inBiomedicine, 12(5):667?677.Michel Neuhaus and Horst Bunke.
2004.
A proba-bilistic approach to learning costs for graph edit dis-tance.
In ICPR ?04, pages 389?393, Washington,DC, USA.
IEEE Computer Society.C.
C. Reyes-Aldasoro and A. Bhalerao.
2006.
Thebhattacharyya space for feature selection and its ap-plication to texture segmentation.
Pattern Recogn.,39(5):812?826.Stanley M. Selkow.
1977.
The tree-to-tree editingproblem.
Inf.
Process.
Lett., 6(6):184?186.Kuo-Chung Tai.
1979.
The tree-to-tree correctionproblem.
J. ACM, 26(3):422?433.K.
Zhang and D. Shasha.
1989.
Simple fast algorithmsfor the editing distance between trees and relatedproblems.
SIAM J.
Comput., 18(6):1245?1262.43
