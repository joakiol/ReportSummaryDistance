Proceedings of the 12th European Workshop on Natural Language Generation, pages 191?194,Athens, Greece, 30 ?
31 March 2009. c?2009 Association for Computational LinguisticsA Probabilistic Model of Referring Expressions for Complex ObjectsKotaro Funakoshi?
Philipp Spanger?
?Honda Research Institute Japan Co., Ltd.Saitama, Japanfunakoshi@jp.honda-ri.comnakano@jp.honda-ri.comMikio Nakano?
Takenobu Tokunaga?
?Tokyo Institute of TechnologyTokyo, Japanphilipp@cl.cs.titech.ac.jptake@cl.cs.titech.ac.jpAbstractThis paper presents a probabilistic modelboth for generation and understanding ofreferring expressions.
This model intro-duces the concept of parts of objects, mod-elling the necessity to deal with the char-acteristics of separate parts of an object inthe referring process.
This was ignored orimplicit in previous literature.
Integratingthis concept into a probabilistic formula-tion, the model captures human character-istics of visual perception and some typeof pragmatic implicature in referring ex-pressions.
Developing this kind of modelis critical to deal with more complex do-mains in the future.
As a first step in ourresearch, we validate the model with theTUNA corpus to show that it includes con-ventional domain modeling as a subset.1 IntroductionGeneration of referring expressions has been stud-ied for the last two decades.
The basic orientationof this research was pursuing an algorithm thatgenerates a minimal description which uniquelyidentifies a target object from distractors.
Thusthe research was oriented and limited by two con-straints: minimality and uniqueness.The constraint on minimality has, however,been relaxed due to the computational complexityof generation, the perceived naturalness of redun-dant expressions, and the easiness of understand-ing them (e.g., (Dale and Reiter, 1995; Spanger etal., 2008)).
On the other hand, the other constraintof uniqueness has not been paid much attentionto.
One major aim of our research is to relax thisconstraint on uniqueness because of the reason ex-plained below.The fundamental goal of our research is to dealwith multipartite objects, which have constituentswith different attribute values.
Typical domain set-tings in previous literature use uniform objects likethe table A shown in Figure 1.
However, real lifeis not so simple.
Multipartite objects such as ta-bles B and C can be found easily.
Therefore thispaper introduces the concept of parts of objects todeal with more complex domains containing suchobjects.
Hereby the constraint on uniqueness be-comes problematic because people easily generateand understand logically ambiguous expressionsin such domains.For example, people often use an expressionsuch as ?the table with red corners?
to identifytable B. Logically speaking, this expression isequally applicable both to A and to B, that is, vio-lating the constraint on uniqueness.
And yet peo-ple seem to have no problem identifying the in-tended target correctly and have little reluctance touse such an expression (Evidence is presented inSection 3).
We think that this reflects some type ofpragmatic implicature arising from human charac-teristics of visual perception and that is importantboth for understanding human-produced expres-sions and for generating human-friendly expres-sions in a real environment.
This paper proposes amodel of referring expressions both for generationand understanding.
Our model uses probabilitiesto solve ambiguity under the relaxed constraint onuniqueness while considering human perception.No adequate data is currently available in or-der to provide a comprehensive evaluation of ourmodel.
As a first step in our research, we validatethe model with the TUNA corpus to show that itincludes conventional domain modeling.Figure 1: An example scene1912 Related workHoracek (2005) proposes to introduce probabili-ties to overcome uncertainties due to discrepan-cies in knowledge and cognition between subjects.While our model shares the same awareness of is-sues with Horacek?s work, our focus is on ratherdifferent issues (i.e., handling multipartite objectsand relaxing the constraint on uniqueness).
Inaddition, Horacek?s work is concerned only withgeneration while our model is available both forgeneration and understanding.
Roy (2002) alsoproposes a probabilistic model for generation butpresupposes uniform objects.Horacek (2006) deals with references for struc-tured objects such as documents.
Although it con-siders parts of objects, the motivation and focus ofthe work are on quite different aspects from ours.3 Evidence against logical uniquenessWe conducted two psycholinguistic experimentsusing the visual stimulus shown in Figure 1.In the first experiment, thirteen Japanese sub-jects were presented with an expression ?kado noakai tukue (the table with red corners)?
and askedto choose a table from the three in the figure.Twelve out of the thirteen chose table B. Sevenout of the twelve subjects answered that the givenexpression was not ambiguous.In the second experiment, thirteen differentJapanese subjects were asked to make a descrip-tion for table B without using positional relations.Ten out of the thirteen made expressions seman-tically equivalent to the expression used in thefirst experiment.
Only three subjects made log-ically discriminative expressions such as ?asi toyotu kado dake akai tukue (the table whose fourcorners and leg only are red).
?These results show that people easily gener-ate/understand logically ambiguous expressions.4 Proposed modelWe define pi = {p1, p2, .
.
.
, pk} as the set of kparts of objects (classes of sub-parts) that appearsin a domain.
Here p1 is special and always meansthe whole of an object.
In a furniture domain, p1means a piece of furniture regardless of the kindof the object (chair, table, whatever).
pi(i 6= 1)means a sub-part class such as leg.
Note that pi isdefined not for each object but for a domain.
Thus,objects may have no part corresponding to pi (e.g.,some chairs have no leg.
).A referring expression e is represented as a setof n pairs of an attribute value expression eaj and apart expression epj modified by eaj ase = {(ep1, ea1), (ep2, ea2), .
.
.
, (epn, ean)}.
(1)For example, an expression ?the white table witha red leg?
is represented as{(?table?, ?white?
), (?leg?, ?red?
)}.Given a set of objects ?
and a referring ex-pression e, the probability with which the expres-sion e refers to an object o ?
?
is denoted asPr(O = o|E = e,?
= ?).
If we seek to providea more realistic model, we can model a probabilis-tic distribution even for ?.
In this paper, however,we assume that ?
is fixed to ?
and it is shared byinterlocutors exactly.
Thus, hereafter, Pr(o|e) isequal to Pr(o|e, ?
).Following the definition (1), we estimatePr(o|e) as follows:Pr(o|e) ?
N?iPr(o|epi , eai ).
(2)Here, N is a normalization coefficient.
Accordingto Bayes?
rule,Pr(o|epi , eai ) =Pr(o)Pr(epi , eai |o)Pr(epi , eai ).
(3)Therefore,Pr(o|e) ?
N?iPr(o)Pr(epi , eai |o)Pr(epi , eai ).
(4)We decompose Pr(epi , eai |o) as?u?vPr(epi |pu, o)Pr(eai |av, o)Pr(pu, av|o)(5)where pu is one of parts of objects that could beexpressed with epi , and av is one of attribute val-ues1 that could be expressed with eai .
Under thesimplifying assumption that epi and eai are not am-biguous and are single possible expressions fora part of objects and an attribute value indepen-dently of objects 2,Pr(o|e) ?
N?iPr(o)Pr(pi, ai|o)Pr(pi, ai)(6)?
N?iPr(o|pi, ai) (7)1Each attribute value belongs to an attribute ?, a set ofattribute values.
E.g., ?color = {red, white, .
.
.
}.2That is, we ignore lexical selection matters in this paper,although our model is potentially able to handle those mattersincluding training from corpora.192Pr(o|p, a) concerns attribute selection in gen-eration of referring expressions.
Most attributeselection algorithms presented in past work arebased on set operations over multiple attributeswith discrete (i.e., symbolized) values such as col-ors (red, brown, white, etc) to find a uniquely dis-tinguishing description.
The simplest estimationof Pr(o|p, a) following this conventional Booleandomain modeling isPr(o|p, a) ?{|?
?|?1 (p in o has a)0 (p in o does not have a) (8)where ??
is the subset of ?, each member of whichhas attribute value a in its part of p.As Horacek (2005) pointed out, however, thisstandard approach is problematic in a real envi-ronment because many physical attributes are non-discrete and the symbolization of these continuousattributes have uncertainties.
For example, evenif two objects are blue, one can be more blueishthan the other.
Some subjects may say it?s bluebut others may say it?s purple.
Moreover, thereis the problem of logical ambiguity pointed outin Section 1.
That is, even if an attribute itselfis equally applicable to several objects in a logi-cal sense, other available information (such as vi-sual context) might influence the interpretation ofa given referring expression.Such phenomena could be captured by estimat-ing Pr(o|p, a) asPr(o|p, a) ?
Pr(a|p, o)Pr(p|o)Pr(o)Pr(p, a).
(9)Pr(a|p, o) represents the relevance of attributevalue a to part p in object o. Pr(p|o) representsthe salience of part p in object o.
The underlyingidea to deal with the problem of logical ambiguityis ?If some part of an object is mentioned, it shouldbe more salient than other parts.?
This is relatedto Grice?s maxims in a different way from mat-ters discussed in (Dale and Reiter, 1995).
Pr(p|o)could be computed in some manner by using thesaliency map (Itti et al, 1998).
Pr(o) is the priorprobability that object o is chosen.
If potentialfunctions (such as used in (Tokunaga et al, 2005))are used for computing Pr(o), we can naturallyrank objects, which are equally relevant to a givenreferring expression, according to distances frominterlocutors.5 Algorithms5.1 UnderstandingUnderstanding a referring expression e is identify-ing the target object o?
from a set of objects ?.
Thisis formulated in a straightforward way aso?
= argmaxo??Pr(o|e).
(10)5.2 GenerationGeneration of a referring expression is choosingthe best appropriate expression e?
to discriminate agiven object o?
from a set of distractors.
A simpleformulation ise?
= argmaxe??Pr(e)Pr(o?|e).
(11)?
is a pre-generated set of candidate expressionsfor o?.
This paper does not explain how to generatea set of candidates.Pr(e) is the generation probability of an ex-pression e independent of objects.
This probabil-ity can be learned from a corpus.
In the evaluationdescribed in Section 6, we estimate Pr(e) asPr(e) ?
Pr(|e|)?iPr(?i).
(12)Here, Pr(|e|) is the distribution of expressionlength in terms of numbers of attributes used.Pr(?)
is the selection probability of a specific at-tribute ?
(SP (a) in (Spanger et al, 2008)).6 Preliminary evaluationAs mentioned above, no adequate corpus is cur-rently available in order to provide an initial vali-dation of our model which we present in this pa-per.
In this section, we validate our model us-ing the TUNA corpus (the ?Participant?s Pack?available for download as part of the GenerationChallenge 2009) to show that it includes tradi-tional domain modeling.
We use the training-part of the corpus for training our model and thedevelopment-part for evaluation.We note that we here assume a homogeneousdistribution of the probability Pr(o|p, a), i.e., weare applying formula (8) here in order to calculatethis probability.
We first implemented our proba-bilistic model for the area of understanding.
Thismeans our algorithm took as input the user?s selec-tion of attribute?value pairs in the description andcalculated the most likely target object.
This was193Table 1: Initial evaluation of proposed model forgeneration in TUNA-domainFurniture PeopleTotal cases 80 68Mean Dice-score 0.78 0.66carried out for both the furniture and people do-mains.
Overall, outside of exceptional cases (e.g.,human error), our algorithm was able to distin-guish the target object for all human descriptions(precision of 100%).
This means it covers all thecases the original approach dealt with.We then implemented our model for the case ofgeneration.
We measured the similarity of the out-put of our algorithm with the human-produced setsby using the Dice-coefficient (see (Belz and Gatt,2007)).
We evaluated this both for the Furnitureand People domain.
The results are summarizedin Table 1.Our focus was here to fundamentally show howour model includes traditional modelling as a sub-set, without much focus or effort on tuning in orderto achieve a maximum Dice-score.
However, wenote that the Dice-score of our algorithm was com-parable to the top 5-7 systems in the 2007 GRE-Challenge (see (Belz and Gatt, 2007)) and thusproduced a relatively good result.
This shows howour algorithm ?
providing a model of the referringprocess in a more complex domain ?
is applica-ble as well to the very simple TUNA-domain as aspecial case.7 DiscussionIn past work, parts of objects were ignored or im-plicit.
In case of the TUNA corpus, while the Fur-niture domain ignores parts of objects, the Peopledomain contained parts of objects such as hair,glasses, beard, etc.
However, they were implic-itly modeled by combining a pair of a part and itsattribute as an attribute such as hairColor.
Onemajor advantage of our model is that, by explicitlymodelling parts of objects, it can handle the prob-lem of logical ambiguity that is newly reported inthis paper.
Although it might be possible to han-dle the problem by extending previously proposedalgorithms in some ways, our formulation wouldbe clearer.
Moreover, our model is directly avail-able both for generation and understanding.
Re-ferring expressions using attributes (such as dis-cussed in this paper) and those using discoursecontexts (such as ?it?)
are separately approachedin past work.
Our model possibly handles both ofthem in a unified manner with a small extension.This paper ignored relations between objects.We, however, think that it is not difficult to preparealgorithms handling relations using our model.Generation using our model is performed in agenerate-and-test manner.
Therefore computa-tional complexity is a matter of concern.
However,that could be controlled by limiting the numbersof attributes and parts under consideration accord-ing to relevance and salience, because our model isunder the relaxed constraint of uniqueness unlikeprevious work.As future work, we have to gather data to eval-uate our model and to statistically train lexical se-lection in a new domain containing multipartiteobjects.ReferencesAnja Belz and Albert Gatt.
2007.
The attribute selec-tion for GRE challenge: Overview and evaluationresults.
In Proc.
the MT Summit XI Workshop UsingCorpora for Natural Language Generation: Lan-guage Generation and Machine Translation (UC-NLG+MT), pages 75?83.Robert Dale and Ehud Reiter.
1995.
Computationalinterpretations of the Gricean maxims in the gener-ation of referring expressions.
Cognitive Science,18:233?263.Helmut Horacek.
2005.
Generating referential de-scriptions under conditions of uncertainty.
In Proc.ENLG 05.Helmut Horacek.
2006.
Generating references to partsof recursively structured objects.
In Proc.
ACL 06.L Itti, C. Koch, and E. Niebur.
1998.
A model ofsaliency-based visual attention for rapid scene anal-ysis.
IEEE Transactions on Pattern Analysis andMachine Intelligence, 20(11):1254?1259.Deb Roy.
2002.
Learning visually-grounded wordsand syntax for a scene description task.
ComputerSpeech and Language, 16(3).Philipp Spanger, Takehiro Kurosawa, and TakenobuTokunaga.
2008.
On ?redundancy?
in selectingattributes for generating referring expressions.
InProc.
COLING 08.Takenobu Tokunaga, Tomonori Koyama, and SuguruSaito.
2005.
Meaning of Japanese spatial nouns.In Proc.
the Second ACL-SIGSEM Workshop on TheLinguistic Dimensions of Prepositions and their Usein Computational Linguistics Formalisms and Appli-cations, pages 93 ?
100.194
