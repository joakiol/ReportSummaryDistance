Proceedings of the 2014 Workshop on Biomedical Natural Language Processing (BioNLP 2014), pages 118?127,Baltimore, Maryland USA, June 26-27 2014.c?2014 Association for Computational LinguisticsTowards Gene Recognition from Rare andAmbiguous Abbreviations using a Filtering ApproachMatthias Hartung?, Roman Klinger?, Matthias Zwick?and Philipp Cimiano?
?Semantic Computing GroupCognitive Interaction Technology ?Center of Excellence (CIT-EC)Bielefeld University33615 Bielefeld, Germany{mhartung,rklinger,cimiano}@cit-ec.uni-bielefeld.de?Research NetworkingBoehringer Ingelheim Pharma GmbHBirkendorfer Str.
6588397 Biberach, Germanymatthias.zwick@boehringer-ingelheim.comAbstractRetrieving information about highly am-biguous gene/protein homonyms is a chal-lenge, in particular where their non-proteinmeanings are more frequent than their pro-tein meaning (e. g., SAH or HF).
Due totheir limited coverage in common bench-marking data sets, the performance of exist-ing gene/protein recognition tools on theseproblematic cases is hard to assess.We uniformly sample a corpus of eight am-biguous gene/protein abbreviations fromMEDLINEr and provide manual annota-tions for each mention of these abbrevia-tions.1Based on this resource, we showthat available gene recognition tools suchas conditional random fields (CRF) trainedon BioCreative 2 NER data or GNAT tendto underperform on this phenomenon.We propose to extend existing gene recog-nition approaches by combining a CRFand a support vector machine.
In a cross-entity evaluation and without taking anyentity-specific information into account,our model achieves a gain of 6 pointsF1-Measure over our best baseline whichchecks for the occurrence of a long formof the abbreviation and more than 9 pointsover all existing tools investigated.1 IntroductionIn pharmaceutical research, a common task is togather all relevant information about a gene, e. g.,from published articles or abstracts.
The task of rec-ognizing the mentions of genes or proteins can beunderstood as the classification problem to decide1The annotated corpus is available for future research athttp://dx.doi.org/10.4119/unibi/2673424.whether the entity of interest denotes a gene/proteinor something else.
For highly ambiguous shortnames, this task can be particularly challenging.Consider, for instance, the gene acyl-CoA syn-thetase medium-chain family member 3 which hassynonyms protein SA homolog or SA hypertension-associated homolog, among others, with abbrevia-tions ACSM3, and SAH.2Standard thesaurus-basedsearch engines would retrieve results where SAHdenotes the gene/protein of interest, but also oc-currences in which it denotes other proteins (e. g.,ATX1 antioxidant protein 1 homolog3) or entitiesfrom semantic classes other than genes/proteins(e. g., the symptom sub-arachnoid hemorrhage).For an abbreviation such as SAH, the use as de-noting a symptom or another semantic class dif-ferent from genes/proteins is more frequent by afactor of 70 compared to protein-denoting men-tions according to our corpus analysis, such thatthe retrieval precision for acyl-CoA synthetase bythe occurrence of the synonym SAH is only about0.01, which is totally unacceptable for practicalapplications.In this paper, we discuss the specific challengeof recognizing such highly ambiguous abbrevia-tions.
We consider eight entities and show thatcommon corpora for gene/protein recognition areof limited value for their investigation.
The abbre-viations we consider are SAH, MOX, PLS, CLU,CLI, HF, AHR and COPD (cf.
Table 1).
Basedon a sample from MEDLINE4, we show that thesenames do actually occur in biomedical text, butare underrepresented in corpora typically used forbenchmarking and developing gene/protein recog-nition approaches.2http://www.ncbi.nlm.nih.gov/gene/62963http://www.ncbi.nlm.nih.gov/gene/4434514http://www.nlm.nih.gov/pubs/factsheets/medline.html118Synonym Other names Other meaning EntrezGene IDSAH acyl-CoA synthetase medium-chain familymember 3; ACSM3subarachnoid hemorrhage;S-Adenosyl-L-homocysteine hydrolase6296MOX monooxygenase, DBH-like 1 moxifloxacin; methylparaoxon 26002PLS POLARIS partial least squares; primary lateral sclerosis 3770598CLU clusterin; CLI covalent linkage unit 1191CLI clusterin; CLU clindamycin 1191HF complement factor H; CFH high frequency; heart failure; Hartree-Fock 3075AHR aryl hydrocarbon receptor; bHLHe76 airway hyperreactivity 196COPD archain 1; ARCN1; coatomer proteincomplex, subunit deltaChronic Obstructive Pulmonary Disease 22819; 372Table 1: The eight synonyms for genes/proteins which are subject of analysis in this paper and their longnames together with frequent other meanings.We propose a machine learning-based filteringapproach to detect whether a mention in questionactually denotes a gene/protein or not and showthat for the eight highly ambiguous abbreviationsthat we consider, the performance of our approachin terms of F1measure is higher than for a state-of-the-art tagger based on conditional random fields(CRF), a freely available dictionary-based approachand an abbreviation resolver.
We evaluate differ-ent parameters and their impact in our filteringapproach and discuss the results.
Note that thisapproach does not take any information about thespecific abbreviation into account and can thereforebe expected to generalize to names not consideredin our corpus.The main contributions of this paper are:(i) We consider the problem of recognizinghighly ambiguous abbreviations that fre-quently do not denote proteins as a task thathas so far attracted only limited attention.
(ii) We show that the recognition of such ambigu-ous mentions is important as their string rep-resentation is frequent in collections such asMEDLINE.
(iii) We show, however, that this set of ambiguousnames is underrepresented in corpora com-monly used for system design and develop-ment.
Such corpora do not provide a suffi-cient data basis for studying the phenomenonor for training systems that appropriately han-dle such ambiguous abbreviation.
We con-tribute a manually annotated corpus of 2174occurrences of ambiguous abbreviations.
(iv) We propose a filtering method for classifyingambiguous abbreviations as denoting a pro-tein or not.
We show that this method has apositive impact on the overall performance ofnamed entity recognition systems.2 Related WorkThe task of gene/protein recognition consists inthe classification of terms as actually denoting agene/protein or not.
The task is typically eithertackled by using machine learning or dictionary-based approaches.
Machine learning approachesrely on appropriate features describing the localcontext of the term to be classified and induce amodel to perform the classification from trainingdata.
Conditional random fields have shown toyield very good results on the task (Klinger et al.,2007; Leaman and Gonzalez, 2008; Kuo et al.,2007; Settles, 2005).Dictionary-based approaches rely on an explicitdictionary of gene/protein names that are matchedin text.
Such systems are common in practice dueto the low overhead required to adapt and maintainthe system, essentially only requiring to extend thedictionary.
Examples of commercial systems areProMiner (Fluck et al., 2007) or I2E (Bandy et al.,2009); a popular free system is made available byHakenberg et al.
(2011).Such dictionary-based systems typically incorpo-rate rules for filtering false positives.
For instance,in ProMiner (Hanisch et al., 2003), ambiguous syn-onyms are only accepted based on external dictio-naries and matches in the context.
Abbreviationsare only accepted if a long form matches all parts ofthe abbreviation in the context (following Schwartzand Hearst (2003)).
Similarly, Hakenberg et al.
(2008) discuss global disambiguation on the doc-ument level, such that all mentions of a string inone abstract are uniformly accepted as denoting anentity or not.A slightly different approach is taken by the web-service GeneE5(Schuemie et al., 2010): Entering aquery as a gene/protein in the search field generates5http://biosemantics.org/geneE119MEDLINE BioCreative2 GENIAProtein # Tokens % tagged # Tokens % of genes # Tokens % of genesSAH 30019 6.1 % 2 0 % 0MOX 16007 13.1 % 0 0PLS 11918 25.9 % 0 0CLU 1077 29.1 % 0 0CLI 1957 4.8 % 4 0 % 0HF 42563 7.9 % 8 62.5 % 4 0 %AHR 21525 75.7 % 12 91.7 % 0COPD 44125 0.6 % 6 0 % 0Table 2: Coverage of ambiguous abbreviations in MEDLINE, BioCreative2 and GENIA corpora.
Thepercentage of tokens tagged as a gene/protein in MEDLINE (% tagged) is determined with a conditionalrandom field in the configuration described by Klinger et al.
(2007), but without dictionary-based featuresto foster the usage of contextual features).
The percentages of genes/proteins (% of genes) in BC2 andGENIA are based on the annotations in these corpora.a query to e. g. PubMedr6with the goal to limitthe number of false positives.Previous to the common application of CRFs,other machine learning methods have been popu-lar as well for the task of entity recognition.
Forinstance, Mitsumori et al.
(2005) and Bickel et al.
(2004) use a support vector machine (SVM) withpart-of-speech information and dictionary-basedfeatures, amongst others.
Zhou et al.
(2005) use anensemble of different classifiers for recognition.In contrast to this application of a classifierto solve the recognition task entirely, other ap-proaches (including the one in this paper) aim atfiltering specifically ambiguous entities from a pre-viously defined set of challenging terms.
For in-stance, Al-mubaid (2006) utilize a word-based clas-sifier and a mutual information-based feature selec-tion to achieve a highly discriminating list of termswhich is applied for filtering candidates.Similarly to our approach, Tsuruoka and Tsujii(2003) use a classifier, in their case a na?
?ve Bayesapproach, to learn which entities to filter fromthe candidates generated by a dictionary-based ap-proach.
They use word based features in the con-text including the candidate itself.
Therefore, theapproach is focused on specific entities.Gaudan et al.
(2005) use an SVM and a dictio-nary of long forms of abbreviations to assign thema specific meaning, taking contextual informationinto account.
However, their machine learning ap-proach is trained on each possible sense of an ab-breviation.
In contrast, our approach consists indeciding if a term is used as a protein or not.
Fur-ther, we do not train to detect specific, previouslygiven senses.6http://www.ncbi.nlm.nih.gov/pubmed/Xu et al.
(2007) apply text similarity measures todecide about specific meanings of mentions.
Theyfocus on the disambiguation between different en-tities.
A corpus for word sense disambiguation isautomatically built based on MeSH annotations byJimeno-Yepes et al.
(2011).
Okazaki et al.
(2010)build a sense inventory by automatically applyingpatterns on MEDLINE and use this in a logisticregression approach.Approaches are typically evaluated on freelyavailable resources like the BioCreative Gene Men-tion Task Corpus, to which we refer as BC2 (Smithet al., 2008), or the GENIA Corpus (Kim et al.,2003).
When it comes to identifying particular pro-teins by linking the protein in question to someprotein in an external database ?
a task we donot address in this paper ?
the BioCreative GeneNormalization Task Corpus is a common resource(Morgan et al., 2008).In contrast to these previous approaches, ourmethod is not tailored to a particular set of entitiesor meanings, as the training methodology abstractsfrom specific entities.
The model, in fact, knowsnothing about the abbreviations to be classified anddoes not use their surface form as a feature, suchthat it can be applied to any unseen gene/proteinterm.
This leads to a simpler model that is applica-ble to a wide range of gene/protein term candidates.Our cross-entity evaluation regime clearly corrobo-rates this.3 DataWe focus on eight ambiguous abbreviations ofgene/protein names.
As shown in Table 2, thesehomonyms occur relatively frequently in MEDLINEbut are underrepresented in the BioCreative 2 entity120Protein Pos.
Inst.
Neg.
Inst.
TotalSAH 5 349 354MOX 62 221 283PLS 1 206 207CLU 235 30 265CLI 11 211 222HF 2 353 355AHR 53 80 133COPD 0 250 250Table 3: Number of instances per protein in theannotated data set and their positive/negative distri-butionrecognition data set and the GENIA corpus whichare both commonly used for developing and evalu-ating gene recognition approaches.
We compileda corpus from MEDLINE by randomly sampling100 abstracts for each of the eight abbreviations (81for MOX) such that each abstract contains at leastone mention of the respective abbreviation.
Oneof the authors manually annotated the mentionsof the eight abbreviations under consideration tobe a gene/protein entity or not.
These annotationswere validated by another author.
Both annotatorsdisagreed in only 2% of the cases.
The numbersof annotations, including their distribution overpositive and negative instances, are summarizedin Table 3.
The corpus is made publicly availableat http://dx.doi.org/10.4119/unibi/2673424 (Hartung and Zwick, 2014).In order to alleviate the imbalance of positiveand negative examples in the data, additional pos-itive examples have been gathered by manuallysearching PubMed7.
At this point, special attentionhas been paid to extract only instances denoting thecorrect gene/protein corresponding to the full longname, as we are interested in assessing the impactof examples of a particularly high quality.
Thisprocess yields 69 additional instances for AHR(distributed over 11 abstracts), 7 instances (3 ab-stracts) for HF, 14 instances (2 abstracts) for PLSand 15 instances (7 abstracts) for SAH.
For theother gene/proteins in our dataset, no additionalpositive instances of this kind could be retrievedusing PubMed.
In the following, this process willbe referred to as manual instance generation.
Thisadditional data is used for training only.7http://www.ncbi.nlm.nih.gov/pubmed4 Gene Recognition by FilteringWe frame gene/protein recognition from ambigu-ous abbreviations as a filtering task in which a setof candidate tokens is classified into entities andnon-entities.
In this paper, we assume the candi-dates to be generated by a simple dictionary-basedapproach taking into account all tokens that matchthe abbreviation under consideration.4.1 Filtering StrategiesWe consider the following filtering approaches:?
SVM classifies the occurring terms based on abinary support vector machine.?
CRF classifies the occurring terms based ona conditional random field (configured as de-scribed by Klinger et al.
(2007)) trained on theconcatenation of BC2 data and our newly gen-erated corpus.
This setting thus correspondsto state-of-the-art performance on the task.?
CRF?SVM considers the candidate an entityif both the standard CRF and the SVM fromthe previous steps yield a positive prediction.?
HRCRF?SVM is the same as the previousstep, but the output of the CRF is optimizedtowards high recall by joining the recognitionof entities of the five most likely Viterbi paths.?
CRF?SVM is similar to the first setting, butthe output of the CRF is taken into account asa feature in the SVM.4.2 Features for ClassificationOur classifier uses local contextual and global fea-tures.
Local features focus on the immediate con-text of an instance, whereas global features encodeabstract-level information.
Throughout the follow-ing discussion, tidenotes a token at position i thatcorresponds to a particular abbreviation to be classi-fied in an abstract A.
Note that we blind the actualrepresentation of the entity to be able to generalizeto all genes/proteins, not being limited to the onescontained in our corpus.4.2.1 Local InformationThe feature templates context-left and context-rightcollect the tokens immediately surrounding an ab-breviation in a window of size 6 (left) and 4 (right)in a bag-of-words-like feature generation.
Addi-tionally, the two tokens from the immediate contexton each side are combined into bigrams.The template abbreviation generates features iftioccurs in brackets.
It takes into account the min-imal Levenshtein distance (ld, Levenshtein (1966))121between all long forms L of the abbreviation (asretrieved from EntrezGene) in comparison to eachstring on the left of ti(up to a length of seven,denoted by tk:ias the concatenation of tokenstk, .
.
.
, ti).
Therefore, the similarity value sim(ti)taken into account is given bysim(ti) = maxl?L;k?
[1:7]1?ld(tk:i?1, l)max(|ti|, |l|),where the denominator is a normalization term.The features used are generated by cumulative bin-ning of sim(ti).The feature taggerlocaltakes the prediction of theCRF for tiinto account.
Note that this feature isonly used in the CRF?SVM setting.4.2.2 Global InformationThe feature template unigrams considers each wordin A as a feature.
There is no normalization orfrequency weighting.
Stopwords are ignored8.
Oc-currences of the same string as tiare blinded.The feature taggerglobalcollects all tokens in Aother than tithat are tagged as an entity by the CRF.In addition, the cardinality of these entities in A istaken into account by cumulative binning.The feature long form holds if one of the longforms previously defined to correspond with the ab-breviation occurs in the text (in arbitrary position).Besides using all features, we perform a greedysearch for the best feature set by wrapping the bestmodel configuration.
A detailed discussion of thefeature selection process follows in Section 5.3.4.2.3 Feature PropagationInspired by the ?one sense per discourse?
heuristiccommonly adopted in word sense disambiguation(Gale et al., 1992), we apply two feature combi-nation strategies.
In the following, n denotes thenumber of occurrences of the abbreviation in anabstract.In the setting propagationall, n ?
1 identicallinked instances are added for each occurrence.Each new instance consists of the disjunction ofthe feature vectors of all occurrences.
Based onthe intuition that the first mention of an abbrevia-tion might carry particularly valuable information,propagationfirstintroduces one additional linked in-stance for each occurrence, in which the featurevector is joined with the first occurrence.8Using the stopword list at http://www.ncbi.nlm.nih.gov/books/NBK3827/table/pubmedhelp.T43/, last accessed on March 25, 2014Setting P R F1SVM 0.81 0.45 0.58CRF?SVM 0.99 0.26 0.41HRCRF?SVM 0.95 0.27 0.42CRF?SVM 0.83 0.49 0.62CRF?SVM+FS 0.97 0.74 0.84GNAT 0.73 0.45 0.56CRF 0.55 0.43 0.48AcroTagger 0.92 0.63 0.75Long form 0.98 0.65 0.78lex 0.18 1.00 0.32Table 4: Overall micro-averaged results over eightgenes/proteins.
For comparison, we show the re-sults of a default run of GNAT (Hakenberg et al.,2011), a CRF trained on BC2 data (Klinger et al.,2007), AcroTagger (Gaudan et al., 2005), and asimple approach of accepting every token of therespective string as a gene/protein entity (lex).
Fea-ture selection is denoted with +FS.In both settings, all original and linked instancesare used for training, while during testing, originalinstances are classified by majority voting on theirlinked instances.
For propagationall, this results inclassifying each occurrence identically.5 Experimental Evaluation5.1 Experimental SettingWe perform a cross-entity evaluation, in which wetrain the support vector machine (SVM) on the ab-stracts of 7 genes/proteins from our corpus and teston the abstracts for the remaining entities, i. e., themodel is evaluated only on tokens representing en-tities which have never been seen labeled duringtraining.
The CRFs are trained analogously withthe difference that the respective set used for train-ing is augmented with the BioCreative 2 Trainingdata.
The average numbers of precision, recall andF1measure are reported.As a baseline, we report the results of a simplelexicon-based approach assuming that all tokensdenote an entity in all their occurrences (lex).
In ad-dition, the baseline of accepting an abbreviation asgene/protein if the long form occurs in the same ab-stract is reported (Long form).
Moreover, we com-pare our results with the publicly available toolkitGNAT (Hakenberg et al., 2011)9and the CRF ap-9The gene normalization functionality of GNAT is nottaken into account here.
We acknowledge that this comparison122proach as described in Section 4.
In addition, wetake into account the AcroTagger10that resolvesabbreviations to their most likely long form whichwe manually map to denoting a gene/protein or not.5.2 Results5.2.1 Overall resultsIn Table 4, we summarize the results of the recogni-tion strategies introduced in Section 4.
The lexicalbaseline clearly proves that a simple approach with-out any filtering is not practical.
GNAT adapts wellto ambiguous short names and turns out as a com-petitive baseline, achieving an average precision of0.73.
In contrast, the filtering capacity of a stan-dard CRF is, at best, mediocre.
The long formbaseline is very competitive with an F1measure of0.78 and a close-to-perfect precision.
The results ofAcroTagger are similar to this long form baseline.We observe that the SVM outperforms the CRFin terms of precision and recall (by 10 percentagepoints in F1).
Despite not being fully satisfactoryeither, these results indicate that global featureswhich are not implemented in the CRF are of im-portance.
This is confirmed by the CRF?SVMsetting, where CRF and SVM are stacked: This fil-tering procedure achieves the best precision acrossall models and baselines, whereas the recall is stilllimited.
Despite being designed for exactly thispurpose, the HRCRF?SVM combination can onlymarginally alleviate this problem, and only at theexpense of a drop in precision.The best trade-off between precision and recallis offered by the CRF?SVM combination.
Thissetting is not only superior to all other variants ofcombining a CRF with an SVM, but outperformsGNAT by 6 points in F1score, while being inferiorto the long form baseline.
However, performingfeature selection on this best model using a wrapperapproach (CRF?SVM+FS) leads to the overallbest result of F1= 0.84, outperforming all otherapproaches and all baselines.5.2.2 Individual resultsTable 5 summarizes the performance of all filter-ing strategies broken down into individual entities.Best results are achieved for AHR, MOX and CLU.COPD forms a special case as no examples for themight be seen as slightly inappropriate as the focus of GNATis different.10ftp://ftp.ebi.ac.uk/pub/software/textmining/abbreviation_resolution/, ac-cessed April 23, 2014occurrence as a gene/protein are in the data; how-ever the results show that the system can handlesuch a special distribution.SVM and CRF are mostly outperformed by acombination of both strategies (except for CLI andHF), which shows that local and global featuresare highly complementary in general.
Complemen-tary cases generally favor the CRF?SVM strategy,except for PLS, where stacking is more effective.In SAH, the pure CRF model is superior to allcombinations of CRF and SVM.
Apparently, theglobal information as contributed by the SVM isless effective than local contextual features as avail-able to the CRF in these cases.
In SAH and CLI,moreover, the best performance is obtained by theAcroTagger.5.2.3 Impact of instance generationAll results reported in Tables 4 and 5 refer to con-figurations in which additional training instanceshave been created by manual instance generation.The impact of this method is analyzed in Table 6.The first column reports the performance of ourmodels on the randomly sampled training data.
Inorder to obtain the results in the second column,manual instance generation has been applied.The results show that all our recognition mod-els generally benefit from additional informationthat helps to overcome the skewed class distribu-tion of the training data.
Despite their relativelysmall quantity and uneven distribution across thegene/protein classes, including additional exter-nal instances yields a strong boost in all mod-els.
The largest difference is observed in SVM(?F1= +0.2) and CRF?SVM (?F1= +0.16).Importantly, these improvements include both pre-cision and recall.5.3 Feature SelectionThe best feature set (cf.
CRF?SVM+FS in Ta-ble 4) is determined by a greedy search using awrapper approach on the best model configurationCRF?SVM.
The results are depicted in Table 7.In each iteration, the table shows the best featureset detected in the previous iteration and the resultsfor each individual feature when being added tothis set.
In each step, the best individual featureis kept for the next iteration.
The feature analysisstarts from the long form feature as strong base-line.
The added features are, in that order, context,taggerglobal, and propagationall.Overall, feature selection yields a considerable123AHR CLI CLU COPDSetting P R F1P R F1P R F1P R F1SVM 1.00 0.72 0.84 0.30 0.27 0.29 1.00 0.41 0.58 0.00 1.00 0.00CRF?SVM 1.00 0.70 0.82 0.00 0.00 0.00 1.00 0.15 0.26 1.00 1.00 1.00HRCRF?SVM 1.00 0.70 0.82 1.00 0.00 0.00 1.00 0.16 0.28 1.00 1.00 1.00CRF?SVM 0.96 0.83 0.89 0.30 0.27 0.29 1.00 0.40 0.57 0.00 1.00 0.00CRF?SVM+FS 0.93 0.98 0.95 0.50 0.09 0.15 0.99 0.84 0.91 1.00 1.00 1.00GNAT 0.74 0.66 0.70 1.00 0.18 0.31 0.97 0.52 0.68 1.00 1.00 1.00CRF 0.52 0.98 0.68 0.00 0.00 0.00 1.00 0.20 0.33 0.00 1.00 0.00AcroTagger 1.00 0.60 0.75 1.00 0.82 0.90 1.00 0.00 0.00 1.00 1.00 1.00Long form 1.00 0.96 0.98 1.00 0.09 0.17 0.99 0.80 0.88 1.00 1.00 1.00lex 0.40 1.00 0.57 0.05 1.00 0.09 0.89 1.00 0.94 0.00 1.00 0.00HF MOX PLS SAHSetting P R F1P R F1P R F1P R F1SVM 0.25 1.00 0.40 0.87 0.44 0.58 0.14 1.00 0.25 0.00 0.00 0.00CRF?SVM 1.00 0.00 0.00 1.00 0.39 0.56 1.00 1.00 1.00 1.00 0.00 0.00HRCRF?SVM 1.00 0.00 0.00 1.00 0.39 0.56 0.20 1.00 0.33 1.00 0.00 0.00CRF?SVM 0.25 1.00 0.40 0.91 0.63 0.74 0.50 1.00 0.67 1.00 0.00 0.00CRF?SVM+FS 1.00 0.00 0.00 1.00 0.37 0.54 0.00 0.00 0.00 1.00 0.00 0.00GNAT 1.00 0.00 0.00 0.38 0.08 0.14 0.00 0.00 0.00 0.00 0.00 0.0CRF 0.00 0.00 0.00 0.43 0.90 0.59 0.14 1.00 0.25 1.00 0.50 0.67AcroTagger 0.33 1.00 0.50 1.00 0.00 0.00 1.00 0.00 0.00 1.00 0.60 0.75Long form 1.00 0.00 0.00 1.00 0.00 0.00 0.00 0.00 0.00 1.00 0.00 0.00lex 0.01 1.00 0.02 0.22 1.00 0.36 0.00 1.00 0.01 0.01 1.00 0.03Table 5: Results for the eight genes/proteins and results for our different recognition schemes.randomly sampled +instance generationP R F1?P ?R ?F1SVM 0.73 0.25 0.38 +0.08 +0.20 +0.20CRF?SVM 1.00 0.17 0.29 -0.01 +0.09 +0.13HRCRF?SVM 0.97 0.18 0.30 -0.02 +0.09 +0.12CRF?SVM 0.79 0.32 0.46 +0.05 +0.17 +0.16CRF?SVM+FS 0.99 0.60 0.75 -0.02 +0.14 +0.09Table 6: Impact of increasing the randomly sampled training set by adding manually curated additionalpositive instances (+instance generation), measured in terms of the increase in precision, recall and F1(?P, ?R, ?F1).boost in recall, while precision remains almost con-stant.
Surprisingly, the unigrams feature has a par-ticularly strong negative impact on overall perfor-mance.While the global information contributed by theCRF turns out very valuable, accounting for mostof the improvement in recall, local tagger informa-tion is widely superseded by other features.
Like-wise, the abbreviation feature does not provide anyadded value to the model beyond what is knownfrom the long form feature.Comparing the different feature propagationstrategies, we observe that propagationalloutper-forms propagationfirst.5.4 DiscussionOur experiments show that the phenomena inves-tigated pose a challenge to all gene recognitionparadigms currently available in the literature, i. e.,dictionary-based, machine-learning-based (e. g. us-ing a CRF), and classification-based filtering.Our results indicate that stacking different meth-ods suffers from a low recall in early steps of theworkflow.
Instead, a greedy approach that consid-ers all occurrences of an abbreviation as input toa filtering approach yields the best performance.Incorporating information from a CRF as featuresinto a SVM outperforms all baselines at very highlevels of precision; however, the recall still leavesroom for improvement.124Iter.
Feature Set P R F1?F11 long form 0.98 0.65 0.78+propagation1st0.98 0.65 0.78 +0.00+propagationall0.98 0.65 0.78 +0.00+taggerlocal0.72 0.81 0.76 -0.02+taggerglobal0.55 0.79 0.65 -0.13+context 0.98 0.67 0.79 +0.01+abbreviation 0.98 0.65 0.78 +0.00+unigrams 0.71 0.43 0.53 -0.252 long form+context 0.98 0.67 0.79+propagation1st0.98 0.67 0.79 +0.00+propagationall0.96 0.70 0.81 +0.02+taggerlocal0.98 0.70 0.82 +0.03+taggerglobal0.97 0.72 0.83 +0.04+abbreviation 0.98 0.67 0.80 +0.01+unigrams 0.77 0.39 0.52 -0.273 long form+context+taggerglobal0.97 0.72 0.83+propagation1st0.97 0.71 0.82 -0.01+propagationall0.97 0.74 0.84 +0.01+taggerlocal0.97 0.72 0.82 -0.01+abbreviation 0.97 0.72 0.82 -0.01+unigrams 0.77 0.44 0.56 -0.274 long form+context+taggerglobal+propagationall0.97 0.74 0.84+taggerlocal0.90 0.66 0.76 -0.08+abbreviation 0.97 0.74 0.84 -0.00+unigrams 0.80 0.49 0.61 -0.23Table 7: Greedy search for best feature combina-tion in CRF?SVM (incl.
additional positives).In a feature selection study, we were able to showa largely positive overall impact of features thatextend local contextual information as commonlyapplied by state-of-the-art CRF approaches.
Thisranges from larger context windows for collectingcontextual information over abstract-level featuresto feature propagation strategies.
However, featureselection is not equally effective in all individualclasses (cf.
Table 5).The benefits due to feature propagation indi-cate that several instances of the same abbreviationin one abstract should not be considered indepen-dently of one another, although we could not verifythe intuition that the first mention of an abbrevia-tion introduces particularly valuable informationfor classification.Overall, our results seem encouraging as the ma-chinery and the features used are in general suc-cessful in determining whether an abbreviation ac-tually denotes a gene/protein or not.
The best pre-cision/recall balance is obtained by adding CRFinformation as features into the classifier.As we have shown in the cross-entity experi-ment setting, the system is capable of generalizingto other unseen entities.
For a productive system,we assume our workflow to be applied to specificabbreviations such that the performance on otherentities (and therefore on other corpora) is not sub-stantially influenced.6 Conclusions and OutlookThe work reported in this paper was motivated fromthe practical need for an effective filtering methodfor recognizing genes/proteins from highly ambigu-ous abbreviations.
To the best of our knowledge,this is the first approach to tackle gene/proteinrecognition from ambiguous abbreviations in asystematic manner without being specific for theparticular instances of ambiguous gene/proteinhomonyms considered.The proposed method has been proven to allowfor an improvement in recognition performancewhen added to an existing NER workflow.
Despitebeing restricted to eight entities so far, our approachhas been evaluated in a strict cross-entity manner,which suggests sufficient generalization power tobe extended to other genes as well.In future work, we plan to extend the data setto prove the generalizability on a larger scale andon an independent test set.
Furthermore, an inclu-sion of the features presented in this paper into theCRF will be evaluated.
Moreover, assessing theimpact of the global features that turned out benefi-cial in this paper on other gene/protein inventoriesseems an interesting path to explore.
Finally, wewill investigate the prospects of our approach in anactual black-box evaluation setting for informationretrieval.AcknowledgementsRoman Klinger has been funded by the ?It?sOWL?
project (?Intelligent Technical SystemsOstwestfalen-Lippe?, http://www.its-owl.de/), a leading-edge cluster of the German Min-istry of Education and Research.
We thank J?orgHakenberg and Philippe Thomas for their supportin performing the baseline results with GNAT.
Ad-ditionally, we thank the reviewers of this paper fortheir very helpful comments.125ReferencesHisham Al-mubaid.
2006.
Biomedical term disam-biguation: An application to gene-protein name dis-ambiguation.
In In IEEE Proceedings of ITNG06.Judith Bandy, David Milward, and Sarah McQuay.2009.
Mining protein-protein interactions from pub-lished literature using linguamatics i2e.
MethodsMol Biol, 563:3?13.Steffen Bickel, Ulf Brefeld, Lukas Faulstich, J?org Hak-enberg, Ulf Leser, Conrad Plake, and Tobias Schef-fer.
2004.
A support vector machine classifier forgene name recognition.
In In Proceedings of theEMBO Workshop: A Critical Assessment of TextMining Methods in Molecular Biology.Juliane Fluck, Heinz Theodor Mevissen, Marius Os-ter, and Martin Hofmann-Apitius.
2007.
ProMiner:Recognition of Human Gene and Protein Namesusing regularly updated Dictionaries.
In Proceed-ings of the Second BioCreative Challenge Evalua-tion Workshop, pages 149?151, Madrid, Spain.William A. Gale, Kenneth W. Church, and DavidYarowsky.
1992.
One sense per discourse.
In Pro-ceedings of the Workshop on Speech and NaturalLanguage, pages 233?237, Stroudsburg, PA, USA.Association for Computational Linguistics.Sylvain Gaudan, Harald Kirsch, and Dietrich Rebholz-Schuhmann.
2005.
Resolving abbreviations to theirsenses in medline.
Bioinformatics, 21(18):3658?3664.J?org Hakenberg, Conrad Plake, Robert Leaman,Michael Schroeder, and Graciela Gonzalez.
2008.Inter-species normalization of gene mentions withGNAT.
Bioinformatics, 24(16):i126?i132, Aug.J?org Hakenberg, Martin Gerner, Maximilian Haeus-sler, Ills Solt, Conrad Plake, Michael Schroeder,Graciela Gonzalez, Goran Nenadic, and Casey M.Bergman.
2011.
The GNAT library for local andremote gene mention normalization.
Bioinformatics,27(19):2769?2771, Oct.Daniel Hanisch, Juliane Fluck, Heinz-Theodor Mevis-sen, and Ralf Zimmer.
2003.
Playing biology?sname game: identifying protein names in scientifictext.
Pac Symp Biocomput, pages 403?414.Matthias Hartung and Matthias Zwick.
2014.
A cor-pus for the development of gene/protein recognitionfrom rare and ambiguous abbreviations.
BielefeldUniversity.
doi:10.4119/unibi/2673424.Antonio J Jimeno-Yepes, Bridget T McInnes, andAlan R Aronson.
2011.
Exploiting mesh indexingin medline to generate a data set for word sense dis-ambiguation.
BMC bioinformatics, 12(1):223.J-D. Kim, T. Ohta, Y. Tateisi, and J. Tsujii.
2003.
Ge-nia corpus?semantically annotated corpus for bio-textmining.
Bioinformatics, 19 Suppl 1:i180?i182.Roman Klinger, Christoph M. Friedrich, Juliane Fluck,and Martin Hofmann-Apitius.
2007.
NamedEntity Recognition with Combinations of Condi-tional Random Fields.
In Proceedings of the Sec-ond BioCreative Challenge Evaluation Workshop,Madrid, Spain, April.Cheng-Ju Kuo, Yu-Ming Chang, Han-Shen Huang,Kuan-Ting Lin, Bo-Hou Yang, Yu-Shi Lin, Chun-Nan Hsu, and I-Fang Chung.
2007.
Rich featureset, unication of bidirectional parsing and dictionaryfiltering for high f-score gene mention tagging.
InProceedings of the Second BioCreative ChallengeEvaluation Workshop, Madrid, Spain, April.Robert Leaman and Graciela Gonzalez.
2008.
Ban-ner: An executable survey of advances in biomed-ical named entity recognition.
In Russ B. Altman,A.
Keith Dunker, Lawrence Hunter, Tiffany Murray,and Teri E. Klein, editors, Pacific Symposium on Bio-computing, pages 652?663.
World Scientific.Vladimir I. Levenshtein.
1966.
Binary codes capableof correcting deletions, insertions, and reversals.
So-viet Physics Doklady, 10:707?710.Tomohiro Mitsumori, Sevrani Fation, Masaki Mu-rata, Kouichi Doi, and Hirohumi Doi.
2005.Gene/protein name recognition based on supportvector machine using dictionary as features.
BMCBioinformatics, 6 Suppl 1:S8.Alexander A. Morgan, Zhiyong Lu, Xinglong Wang,Aaron M. Cohen, Juliane Fluck, Patrick Ruch, AnnaDivoli, Katrin Fundel, Robert Leaman, Jrg Haken-berg, Chengjie Sun, Heng-hui Liu, Rafael Torres,Michael Krauthammer, William W. Lau, HongfangLiu, Chun-Nan Hsu, Martijn Schuemie, K BretonnelCohen, and Lynette Hirschman.
2008.
Overview ofbiocreative ii gene normalization.
Genome Biol, 9Suppl 2:S3.Naoaki Okazaki, Sophia Ananiadou, and Jun?ichi Tsu-jii.
2010.
Building a high-quality sense inventoryfor improved abbreviation disambiguation.
Bioinfor-matics, 26(9):1246?1253, May.Martijn J. Schuemie, Ning Kang, Maarten L. Hekkel-man, and Jan A. Kors.
2010.
Genee: gene and pro-tein query expansion with disambiguation.
Bioinfor-matics, 26(1):147?148, Jan.Ariel S. Schwartz and Marti A. Hearst.
2003.
A simplealgorithm for identifying abbreviation definitions inbiomedical text.
Pac Symp Biocomput, pages 451?462.Burr Settles.
2005.
Abner: an open source tool for au-tomatically tagging genes, proteins and other entitynames in text.
Bioinformatics, 21(14):3191?3192,Jul.Larry Smith, Lorraine K. Tanabe, Rie Johnson nee J.Ando, Cheng-Ju J. Kuo, I-Fang F. Chung, Chun-Nan N. Hsu, Yu-Shi S. Lin, Roman Klinger,126Christoph M. Friedrich, Kuzman Ganchev, Man-abu Torii, Hongfang Liu, Barry Haddow, Craig A.Struble, Richard J. Povinelli, Andreas Vlachos,William A. Baumgartner, Lawrence Hunter, BobCarpenter, Richard Tzong-Han T. Tsai, Hong-Jie J.Dai, Feng Liu, Yifei Chen, Chengjie Sun, Sophia Ka-trenko, Pieter Adriaans, Christian Blaschke, RafaelTorres, Mariana Neves, Preslav Nakov, Anna Divoli,Manuel Ma?na L?opez, Jacinto Mata, and W. JohnWilbur.
2008.
Overview of BioCreative II genemention recognition.
Genome biology, 9 Suppl2(Suppl 2):S2+.Yoshimasa Tsuruoka and Jun?ichi Tsujii.
2003.
Boost-ing precision and recall of dictionary-based pro-tein name recognition.
In Proceedings of the ACL2003 Workshop on Natural Language Processing inBiomedicine, pages 41?48, Sapporo, Japan, July.
As-sociation for Computational Linguistics.Hua Xu, Jung-Wei Fan, George Hripcsak, Eneida AMendonc?a, Marianthi Markatou, and Carol Fried-man.
2007.
Gene symbol disambiguation us-ing knowledge-based profiles.
Bioinformatics,23(8):1015?1022.GuoDong Zhou, Dan Shen, Jie Zhang, Jian Su, andSoonHeng Tan.
2005.
Recognition of protein/genenames from text using an ensemble of classifiers.BMC Bioinformatics, 6 Suppl 1:S7.127
