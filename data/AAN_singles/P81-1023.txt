A View of Pars ingRonald M. KaplanXerox Pale Alto Research CenterThe questions before this panel presuppose a distinction between parsing andinterpretation.
There are two other simple and obvious distinctions that Ithink are necessary for a reasonable discussion of the issues.
First, we mustclearly distinguish between the static specification of a process and itsdynamic execution.
Second, we must clearly distinguish two purposes that anatural language processing system might serve: one legitimate goal of asystem is to perform some practical ~sk efficiently and well.
while a secondgoal is to assist in developing a scientific understanding of the cognitiveoperations that underlie human language processing.
1 will refer to pa~rsprimarily oriented towards the former goal as Practical Parsers (PP) and referto the others as Performance Model Parsers (PMP).
With these distinctionsin mind.
let me now turn to the questions at hand.1.
The  Computat iona l  Perspect ive.From a computadonal point of view.
there are obvious reasons fordistinguishing parsing from interpretation.
Parsing is the process wherebylinearly ordered scquences of character strings annotated with informationfound in a stored lexicon are transduced into labelled hierarchical structures.Interpretation maps such structures either into structures with differentformal properties, such as logical formulas, or into sequences of actions to beperformed on a logical model or database.
On the face of it, unless weignore the obvious formal differences between string--to--structure andstructure--to--structure mappings, parsing is thus formally and conceptuallydistinct from interpretation.
The specifications of thc two processesnecessarily mention different kinds of operations that are sensitive todifferent- features of the input and express quite different generalizationsabout the correspondences betwecn form and meaning.As far as I can see.
these are simply factual assertions about which therecan be little or no debate.
Beyond this level, however, there are a number ofcontroversial issues.
Even though parsing and interpretation operations arerecognizably distinct, they can be combined in a variety of ways to constructa natural language understanding system.
For example, the staticspecification of a s~stem could freely intermix parsing and interpretationoperations, so that there is no part of the program text that is clearlyidentifiable as the parser or interpreter, and perhaps no part that can even bethought of as more pa~er-like or interpreter-like than any other.
Althoughthe microscopic operations fall into two classes, there is no notion in such asystem of separate parsing and interpretation components at a macroscopicte~cl.
.Macroscopiealty.
it might be argued` a ,~yslcm specified in this waydoes not embody a parsmg/interprcmtitm distinctmn.On the other hand.
we can imagine a system whose static specification iscarefully divided into two parts, one that only specifies parsing operationsand expresses parsing generalizations and one that involves onlyinterpretation specifications.
And there arc clearly untold numbers of systemconfigurations that fall somewhere between these extremes.I take it to be uncontrovcrsial that.
other things being equal, ahomogenized system is less preferable on both practical and scientificgrounds to one that naturally decomposes.
Practically.
such a system iseasier to build and maintain, since the parts can be designed, developed, andunderstood to a certain extent in isolation, perhaps even by people workingindependently.
Scientifically.
a decomposable system is much more likely toprovide insight into the process of natural anguage omprehe~ion, whetherby machines or people.
The reasons for this can be found in Simon's classicessay on the Architecture of Complexity.
and in other places as well.The debate arises from the contention that there are important "otherthings" that cannot be made equal, given a completely decomposed staticspecification.
In particular, it is suggested that parsing and interpretationoperations must be partially or totally interleaved uring the execuuon of acomprehension process.
For practical systems, arguments are advanced thata "habitable" system, one that human clients fecl comfortable using, must beable to interpret inputs before enough information is available for a completesyntactic structure or when the syntactic information that is available doesnot lead to a consistent parse.
It is also argued that interpretation must beperformed in the middle of parsing in the interests of reasonable efficiency:the interpreter can reject sub-constituents that are semantically orpragmatically unacceptable and thereby permit early truncation of long pathsof syntactic omputation.
From the performance model perspective, it issuggested that humans eem able to make syntactic, semantic, and pragmaticdecisions in parallel, and the ability to simulate this capability is thus acondition of adequacy for any psycholinguistic model.All these arguments favor a system where the operations of parsing andinterpretation are interleaved uring dynamic execution, and perhaps evenexecuted on parallel hardware (or wetware, from the PMP perspective), Ifparsing and interpretation are run-time indistinguishable, it is claimed, thenparsing and interpretation must be part and parcel of the same monolithicprocess.Of course, whether or not there is dynamic fusit)n of parsing andinterpetation is an empirical question which might be answered ifferentlyfor practical systems than for perlbrmance models, and might even beanswered ifferently ior different practical implementations.
Depending onthe relative computational efficiency of parsing versus interpretationoperations, dynamic intcrlc:ning might increase or decrease ovendl systemefli:'ctivcness.
For example, in our work t.n the I.UNAR system /Woods.Kaolan.
& Nash-Webbcr.
1q72), we fl)tmd it more ellicient o detbr semanticprt~.cssmg until after a complete, well-l~.,nncd parse had been discovered.The consistency checks embedded in the grammar could rule outsyntactically unacceptable structures much more quickly than our particularinterpretation component was able to do.
More recendy.
Martin.
Church.and Ramesh (1981) have claimed that overall efficiency is greatest if allsyntactic analyses are computed in breadth-fi~t fashion before any semanticoperations are executed.
These results might be taken to indicate that theparticular semantic components were poorly conceived and implemented,with little bearing on systems where interpretation is done "properly" (orparsing is done improperly).
But they do make the point that a practicaldecision on the dynamic fusion of parsing and interpretation cannot be madea priori, without a detailed study of the many other factors that can influencea system's computational resource demands.Whatever conclusion we arrive at from practical considerations, there isno reason to believe that it will carry over to performance modelling.
Thehuman language faculty is an evolutiol, try compromise between therequirements hat language be easy to learn, easy to produce, and easy tocomprehend.
Because of this.
our cognitive mechanisms for comprehensionmay exhibit acceptable but not optimal efficiency, and we would thereforeexpect a successful PMP to operate with psychologically appropriateinefficiencies.
Thus.
for performance modelling, the question can beanswered only by finding eases where the various hypotheses make cruciallydistinct predictions concerning human capabilities, errors, or profiles ofcognitive load.
and then testing these predictions in a careful series ofpsycholinguisttc experiments.
It is often debated, usually by non-linguists,whether the recta-linguistic intuitions that form the empirical foundation formuch of current linguistic theory are reliable indicators of the naUvespeaker's underlying competence.
When it comes to questions about internalprocessing as opposed to structural relations, the psychological literature hasdemonstrated many times that intuitions are deserving of even much lesstrust.
Thus, though we may have strong beliefs to the effect that parsing andinterpretation are psychologically inseparable, our theoretical commitmentsshould rather be based on a solid experimental footing.
At this point intime.
the experimental evidence is mixed: semantic and syntactic processesare interleaved on-line in many situations, but there is also evidence thatthese processes have a separate, relatively non-interacting run-time coup .103However, no matter how the question of.
dynamic fusion is ultimatelyresolved, it should bc clear t, ha\[ dynamic interleaving or parallelism carriesno implicauon of" static homogeneity.
A system whose run-rune behavior hasno distinguishable components may neverthelc~ have a totally dccompo~dstatic description.
Given this possibilty, and given me evident scientificadvantages that a dccornposed static spccifgation aflords.
I have adopted inmy own rescareh on these matters the strong working hypothesis that astatically deeomposahle sys~n co~ be constructed to provide the necessaryefficiencics for practical purposes and ycL perhaps with minor modirr.ationsand l'twther ~ipulations.
Still supp(~n signilicant explanauons of.p~ycholingmstic phenomena.In short, I maintain the position that the "true" comprehension systemwill also meet our pre-theorctic notions of.
scientific elegance and "beauty'.This hypothesis, that truth and beauty are highly correlated in this domain, isperhaps implausible, but it presents a challenge for theory andimplementation that has held my interest and fascination for many years.2.
The Linguistic Perspective.While k is certainly Irue that our tools (computers and formal grammars)have shoged our views of" what human languages and human languagepreceding may be like, it seems a little bit strange to think that our viewshave been warped by those tools.
Warping suggcsts, that there is rome other,more accurate view that we would have comc m either without mathematicalor computational tools or with a set of formal tools with a substantiallydifferent character.
There is no way in principle to exclude such apossibility, but it could hc tatar we have the tools wc have because theyharmonize with the capabilities of the human mind for scientificunderstanding.
That is.
athough substantially different ools might be bettersuited to the phenomena under investigation, the results cleaved with \[hosetools might not be humanly appreciable.
"\]'he views that have emerged fromusing our present ools might be far off the mark, but they might be the onlyviews \[hat we are c~hle  OCPerhaps a more interesting statement can be made if the question isinterpreted as posing a conflict between the views that we as computationallinguists have come to.
guided by our present practical and formalunderstanding of what constitutes a reasonable computation, and the viewsthat \[henretical linguisXs, philosophers, and others imilarly unconstrained byconcrete computation, might hold.
Historically.
computational Brammm~have represented a mixture of intuitions about the significant gntcturalgeneralizations of language and intuitions about what can be p ~efT~:ientiy, given a pani-'ular implementation that the grammar writer had inthe back of his or her mind.This is certainly \[rue of my own work on some of the catty ATNgrammars.
Along with many others, I felt an often unconscious pressure tomove forward along ?
given computational path as long as possible beforethrowing my gramnmtical fate to the purser's general nondeterntioLs~ c oicemechanisms, even though \[his usually meant hat feaster contents had to bemanipulated in linguistically unjustified ways.
For example, the standardATN account of" passive sentcnces used register operations to ?voidbacktracking that would re.analyze the NP that was initially parsed as anactive subject.
However.
in so doing, the grammar confused the notions ofsurfare and deep suh)eets, and lost the ability to express gcnendizationsconcerning, for examplc, passive tag questions.In hindsighL I con~der that my early views were "warped" by both theATN formalism, with its powerful register operations, and my understandingof the particular top-down, leright underlying pa~ing algorithm.
As \[developed the more sophisticated model of parsing embodied in my GeneralSyntactic Processor, l realized that \[here was a systematic, non-fpamrr~*_~*~Jway at" holding on to funcXionally mis-assigned constituent structures.
Freedfrom worrying about exponential constituent su'ucture nondetermism, itbecame possible to restrict and simplify \[he ATN's register oparaUons and,ultimately, to give them a non-proceduraL algebraic interpretation.
Theresult is a new grammatical formalism, Lexical-Functiona\] Grammar CKaplan& Bresnan, in press), a forrnalisan that admits a wider class of eff?ientcomputational implementations than the ATN formalism just becat~ shegrammar itself" makes fewer computational commi~nen~ Moreover, it is a104formalism that provides for the natural statement of" many languageparticular and universal gencralizations, h also seems to bc a formalism d'mtfatal/tales cooperaoon between linguists and computational linguists, despitethe.~" diffcnng theoretical and me\[hodologeaI bmses.Just as we have been warped by our computational mechanisms,linguists have been warped by their formal tools, particularly ther~ansformational formalism.
The convergence represented by Lexical-Functional Grammar is heartening in that it suggests hat imperfect tools andunderstanding can and will evolve into better tools and deeper insights.3.
The Interactions.As indicated ?hove, I think computational grammars have been influenced bythe algorithms that we expect o appb them with.
While difficult w weedout, that influence is not a thcoretica\] or practical oeces~ty.
By reducing andeliminaong the computational commitments of Our grammaocal forn~ism, aswe have done with Lexical-Functional Grammar, it is possible to devise avariety or different parsing schemes.
By comparing and coou'asUng theirbehavior with different grammars and sentences, we can begin to develop adeeper understanding of \[he way compulationa\] resources depend onproperties of grammars, smngs, and algorithms.
This unders~nding isessenUal both to practic~ implementations and also to psycholinguisticmodelling.
Furthermore, if a formalism allows grammars to be written as anabstract characterization of string--structure correspondences, the Jp~nunm"should be indifferent as to recognition or generation.
We should be ?hie toimplement fcasible generators as well as parsers, and again, shed light on theinterdependencies of grammars and grammaucal prrx:cssmg,.
Lc( me conclude with a few comments about the psychol,ogeaI validityor grammars and parsing algorithms.
To the extent that a grammar cor~j.lymodels a native speaker's lingtusuc ompelcnce, or, less tend~Uously, the setof meta-linguistic judgments he is able to make.
then ti'mt srammar has acertain psyehok~gical "validity'.
h becomes much more interepang, however,if" it can ?l~.J be cmpeddcd in a psychologeally accurate motel of speakingand comprehending, h.~ all cumpct?,nce grammars will mcc~ \[his additionalrequL,~ment, but I have the optLmis~c belief that such a grammar will~ y  be found.It is also possible to find psychological validation for a parsing algorithmin the ?bsence of a particular Ipmnn~.
One could in principle adduceevidence to \[he effect that \[he architecture of \[he parser, the structuring of itsmemory and operations, corresponds point by point to well-e,.,.,.,.,.,.,.,.,~mhl~hedcognitive mectmnisms.
As ?
research strategy for ?fraying at a psychologicallyvalid model of comprehension, it is much more reasonable to developlinguisr.ically justified 8rammars and computationaUy motivated pmT, ingalgorithms in a collaborative ffort.
A model with such independentlymotivated yet mutually compatible knowledBe and process components ismuch more likely to resuh in an explanatory account of \[he mechanismsunderlying human linguisl~ abilil~=.ReferencesKaplan, R. & Bres.oan, J. Lexical-functional grammar:.
A fen'hal system forgrammatical representation" In J. Bresnan ted.
), The me;m~lrepvecentalion of ~mmal~.ol rela,on~ Cambridse: M IT  Press.
inprem.Martin.
W~ Church, K.. & P, ame~, P. Paper presented to the Symposiumon Modelling Human Parsing Strategies, Unive~ty of Texas at Austin,~z.Woods.
W. Kaplan, R. & Nash-Wehber.
B.
The Lunar sr/ences nalum/language information .Wslem.
Cmnbridsc: Belt "Ikranek and Newnlan`Report 2378, 1972.
