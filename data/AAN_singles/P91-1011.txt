EFF IC IENT INCREMENTAL PROCESSING WITH CATEGORIAL  GRAMMARAbst ractSome problems are discussed that arise for incremental pro-cessing using certain flezible categorial grammars, which in-volve either undesirable parsing properties or failure to allowcombinations useful to incrementality.
We suggest a new cal-culus which, though 'designed' in relation to categorial inter-pretatious of some notions of dependency grammar, seems toprovide a degree of flexibility that  is highly appropriate for in-cremental interpretation.
We demonstrate how this grammarmay be used for efficient incremental parsing, by employingnormalisation techniques.I n t roduct ionA range of categorial grammars (CGs) have beenproposed which allow considerable flexibility in theassignment of syntactic structure, a characteristicwhich provides for categorial treatments of extrac-tion (Ades & Steedman, 1982) and non-constituentcoordination (Steedman, 1985; Dowty, 1988), andthat is claimed to allow for incremental processingof natural anguage (Steedman, 1989).
It is this lat-ter possibility that is the focus of this paper.Such 'flexible' CGs (FCGs) typically allow thatgrammatical sentences may be given (amongst oth-ers) analyses which are either fully or primarily left-branching.
These analyses have the property of des-ignating many of the initial substrings of sentencesas interpretable constituents, providing for a style ofprocessing in which the interpretation of a sentenceis generated 'on-line' as the sentence is presented.It has been argued that incremental interpretationmay provide for efficient language processing - -  byboth humans and machines - -  in allowing early fil-tering of thematically or referentially implausiblereadings.
The view that human sentence processingis 'incremental' is supported by both introspectiveand experimental evidence.In this paper, we discuss FCG approaches andsome problems that arise for using them as a ba-sis for incremental processing.
Then, we propose agrammar that avoids these problems, and demon-strate how it may be used for efficient incrementalprocessing.Mark  Hepp leUniversity of Cambridge Computer Laboratory,New Museums Site, Pembroke St, Cambridge, UK.e-mail  : mrhQuk, a?.
cam.
?iF lex ib le  Categor ia l  GrammarsCGs consist of two components: (i) a categorial lex-icon, which assigns to each word at least one syn-tactic type (plus associated meaning), (ii) a calculuswhich determines the set of admitted type combina-tions and transitions.
The set of types (T) is definedrecursively in terms of a set of basic types (To) anda set of operators (\ and/ ,  for standard bidirectionalCG), as the smallest set such that (i) To C T, (ii)if x,y E T, then x\y, x/y E T. 1 Intuitively, lexi-cal types specify subcategorisation requirements ofwords, and requirements on constituent order.
Themost basic (non-flexible) CGs provide only rules ofapplication for combining types, shown in (1).
Weadopt a scheme for specifying the semantics of com-bination rules where the rule name identifies a func-tion that applies to the meanings of the input typesin their left-to-right order to give the meaning ofthe result expression.
(1) f: X/Y + Y =~ X (where f= AaAb.
(ab))b: Y + X\Y =~ X (where b = AaAb.
(ba))The Lambek calculusWe begin by briefly considering the (product-free)Lambek calculus (LC - Lambek, 1958).
Various for-mulations of the LC are possible (although we shallnot present one here due to space limitations).
2The LC is complete with respect o an intuitivelysensible interpretation ofthe slash connectives wherebythe type x/y (resp.
x\y) may be assigned to anystring z which when left-concatenated (resp.
right-concatenated) with any string y of type y yieldsa string x.y (resp.
y.x) of type x.
The LC canbe seen to provide the limit for what are possible1 We use a categorial notat ion in which x /y  and x\y  areboth  functions from y into x, and adopt a convention ofleft association, so that,  e.g.
( ( s \np) /pp) /np  may be writ-ten s \np /pp /np .2See Lambek (1958) and Moortgat (1989) for a sequentformulation of the LC.
See Morrill, Leslie, Hepple & Barry(1990), and Barry, Hepple, Leslie & Morrill (1991) for a natu-ral deduction formulation.
Zielonka (1981) provides a LC for-mulation in terms of (recursively defined) reduction schema.Various extensions of the LC are currently under investiga-tion, although we shall not have space to discuss them here.See Hepple (1990), Morrill (1990) and Moortgat (1990b).79type combinations - -  the other calculi which weconsider admit only a subset of the Lambek typecombinations, sThe flexibility of the LC is such that, for any com-bination xl , .
.
,x,  ==~ x0, a fully left-branching deriva-tion is always possible (i.e.
combining xl and x2,then combining the result with x3, and so on).
How-ever, the properties of the LC make it useless forpractical incremental processing.
Under the LC,there is always an infinite number of result typesfor any combination, and we can only in practice ad-dress the possibility of combining some types to givea known result type.
Even if we were to allow onlyS as the overall result of a parse, this would not tellus the intermediate target types for binary combi-nations made in incrementally accepting a sentence,so that such an analysis cannot in practice be made.Comblnatory  Categor |a l  GrRmmarCombinatory Categorial Grammars (CCGs - Steed-man, 1987; Szabolcsi, 1987) are formulated by addinga number of type combination and transition schemesto the basic rules of application.
We can formulate asimple version of CCG with the rules of type raisingand composition shown in (2).
This CCG allowsthe combinations (3a,b), as shown by the proofs(4a,b).
(2) T: x ::~ y / (y \x )  (where T - AxAf.
(fz))B: x/y + y/z =:~ x/z(where B =(3) a. np:z, s \np /np : f  =~ s/np:Ay.fyzb.
vp/s: f ,  np:z =~ vp/(s\np):Ag.f(gz)(4) (a) np s\np/np (b) vp/s npT Ts/(s\np) \]3 s/(s\nP)Bs/np vp/(s\np)The derived rule (3a) allows a subject NP to com-bine with a transitive verb before the verb has com-bined with its object.
In (3b), a sentence m-bedding verb is composed with a raised subject NP.Note that it is not clear for this latter case that thecombination would usefully contribute to incremen-tal processing, i.e.
in the resulting semantic expres-sion, the meanings of the types combined are not di-rectly related to each other, but rather a hypothet-ical function mediates between the two.
Hence, any3In some frameworks, the use of non-Lambek-valid rulessuch as disharmonic omposition (e.g.
x/y + y\z ::~ x\z)has been suggested.
We shall not consider such rules in thispaper.requirements hat the verb may have on the seman-tic properties of its argument (i.e.
the clause) couldnot be exploited at this stage to rule out the re-sulting expression as semantically implausible.
Wedefine as contentful only those combinations whichdirectly relate the meanings of the expressions com-bined, without depending on the mediation of hy-pothetical functions.Note that this calculus (like other versions of CCG)fails to admit some combinations, which are allowedby the LC, that are contentful in this sense - -  forexample, (5).
Note that although the seman-tics for the result expression in (5) is complex,the meanings of the two types combined are still di-rectly related - -  the lambda abstractions effectivelyjust fulfil the role of swapping the argument orderof the subordinate functor.
(5) x / (y \z ) : f ,  y/w\z:g ~ x/w:Av.f(Aw.gwv)Other problems arise for using CCG as a basisfor incremental processing.
Firstly, the free use oftype-raising rules presents problems, i.e.
since therule can always apply to its own output.
In practice,however, CCG grammars typically use type specificraising rules (e.g.
np =~ s/(s\np)) ,  thereby avoidingthis problem.
Note that this restriction on type-raising also excludes various possibilities for flexiblecombination (e.g.
so that not all combinations oftheform y, x \y /z  =~ x/z are allowed, as would be thecase with unrestricted type-raising).Some problems for efficient processing of CCGsarise from what has been termed 'spurious ambigu-ity' or 'derivational equivalence', i.e.
the existenceof multiple distinct proofs which assign the samereading for some combination of types.
For exam-ple, the proofs (6a,b) assign the same reading forthe combination.
Since search for proofs must beexhaustive to ensure that all distinct readings for acombination are found, effort will be wasted con-structing proofs which a. .
.
.~ ~he same meaning,considerably reducing the elficiency of processing.Hepple & Morrill (1989) suggest a solution to thisproblem that involves specifying a notion of nor-mal form (NF) for CCG proofs, and ensuring thatthe parser returns only NF proofs.
4 However, theirmethod has a number of limitations.
(i) They con-sidered a 'toy grammar'  involving only the CCGrules stated above.
For a grammar involving fur-ther combination rules, normalisation would needto be completely reworked, and it remains to beshown that this task can be successfully done.
(ii)4Normalisation has also been suggested to deal with theproblem of spurious ambiguity as it arises for the LC.
SeeK6nig (1989), Hepple (1990) and Moortgat (1990).80The NF proofs of this system are right-branching- -  again, it remains to be shown that a NF can bedefined which favours left-branching (or even pri-marily left-branching) proofs.
(6) (a) x/y y/z - (b) x/y y/zf By x /zf fx xMeta-Categor ia l  GrammarIn Meta-Categorial Grammar (MCG - Morrill, 1988)combination rules are recursively defined from theapplication rules (f and b) using the metarnles (7)and (8).
The metarules tate that given a ruleof the form shown to the left of ==~ with name ~,a further ule is allowed of the form shown to theright, with name given by applying t t  or L to ?
asindicated.
For example, applying It  to backwardapplication gives the rule (9), which allows com-bination of subject and transitive verb, as T andB do for CCG.
Note, however, that this calculusdoes not allow any 'non-contentful' combinations- -  all rules are recursively defined on the applica-tion rules which require a proper functional relationbetween the types combined.
However, this calcu-lus also fails to allow some contentful combinations,such as the case x/(y\z), y/w\z =:~ x/w mentionedabove in (5).
Like CCG, MCG suffers from spuriousambiguity, although this problem can be dealt withvia normalisation (Morrill, 1988; Hepple & Morrill,1989).
(7) ?
:x+y:~z  =:~ R?
:x+y/w=C,z /w(where R = ~g,~a~b,~c.ga(bc))(8) ?
:x+y=~z ==~ L?
:x \w+y:C ,z \w(where L = ag a bae g(ac)b)(9) Rb: y + x\y/z =~ x/zThe  Dependency  Ca lcu lusIn this section, we will suggest anew calculus which,we will argue, is well suited to the task of incremen-tal processing.
We begin, however, with some dis-cussion of the notions of head and dependent, andtheir relevance to CG.The dependency grammar (DG) tradition takesas fundamental the notions of head, dependent andthe head-dependent relationship; where a head is,loosely, an element on which other elements depend.An analogy is often drawn between CG and DGbased on equating categorial functors with heads,whereby a functor x/yl../yn (ignoring directional-ity, for the moment) is taken to correspond to a headrequiring dependents Yl..Yn, although there are sev-eral obvious differences between the two approaches.Firstly, a categorial functor specifies an orderingover its 'dependents' (function-argument order, thatis, rather than constituent order) where no such or-dering is identified by  a DG head.
Secondly, thearguments of a categorial functor are necessarilyphrasal, whereas by the standard view in DG, thedependents of a head are taken to be words (whichmay themselves be heads of other head/dependentcomplexes).
Thirdly, categorial functors may spec-ify arguments which have complex types, which, bythe analogy, might be descr ibed  as a head being ableto make stipulations about the dependency require-ments of its dependent and also to 'absorb' thosedependency requirements.
5 For example, a typex/(y\z) seeks an argument which is a "y needing adependent z" under the head/functor analogy.
Oncombining with such a type, the requirement "needa dependent z" is gone.
Contrast his with the useof, say, composition (i.e.
x/y, y/z =~ x/z), where atype x/y simply needs a dependent y, and wherecomposition allows the functor to combine with itsdependent y while the latter still requires a depen-dent z, and where that requirement is inherited ontothe result of the combination and can be satisfiedlater on.Barry & Pickering (B&P, 1990) explore the viewof dependency that arises in CG when the functor-argument relationship is taken as analogous to thetraditional head-dependent relationship.
A problemarises in employing this analogy with FCGs, sinceFCGs permit certain type transformations that un-dermine the head-dependent relations that are im-plicit in lexical type assignments.
An obvious exam-ple is the type-raising transformation x =~ y/(y\x),which directly reverses the direction of the head-dependent relationship between a functor and itsargument.
B&P identify a subset of LC combina-tions as dependency preserving (DP), i.e.
those com-binations which preserve the head-dependent rela-tions implicit in the types combined, and call con-stituents which have DP analyses dependency con-stituents.
B&P argue for the significance of thisnotion of constituency in relation to the treatmentof coordination and the comparative difficulty ob-served for (human) processing of nested and non-5Clearly, a CG where argument  ypes were required to bebasic would be a closer ana logue of  DG in not  allowing a'head'  to make such s t ipu lat ions  about  its dependents .
Sucha sys tem could be enforced by adopt ing  a more restr icteddefinit ion of the  set of types (T) as the  smal lest  set such that(i) To C T, (ii) if x E T and  y E To, then x\y ,  x /y  E T (c.f.the definit ion given earl ier).81nested constructionsfi B&P suggest a means foridentifying the DP subset of LC transformationsand combinations in terms of the lambda expres-sions that assign their semantics.
Specifically, acombination is DP iff the lambda expression speci-fying its semantics does not involve abstraction overa variable that fulfils the role of functor within theexpression (c.f.
the semantics of type raising in (2))ffWe will adopt a different approach to B&P foraddressing dependency constituency, which involvesspecifying a calculus that allows all and only the DPcombinations (as opposed to a criterion identifyinga subset of LC combinations as DP).
Consider againthe combination x/ (y\z) ,  y /w\z  =~ x/w, not admit-ted by either the CCG or MCG stated above.
Thiscombination would be admitted by the MCG (andalso the CCG) if we added the following (Lambek-valid) associativity axioms, as illustrated in (11).
(10) a: x \y /z=~x/z \ya: x /y \z=~x\z /y(where a = ~f~a\]b.fba)( I I)  x/(y\z) y/w\z~ ay\, /wRfx/wWe take it as self-evident that the unary trans-formations pecified by these two axioms are DP,since function-argument order is a notion extrane-ous to dependency; the functors x \y /z  and x /z \yhave the same dependency requirements, i.e.
depen-dents y and z. s For the same reason, such reorderingof arguments hould also be possible for functionsthat occur as subtypes within larger types, as in(12a,b).
The operation of the associativity rulescan be 'generalised' in this fashion by including theunary metarules (13), 9 which recursively defineeSee Baxry (forthcoming) for extensive discussion of de-pendency and CG, and Pickering (1991) for the relevance ofdependency to human sentence processing.7B&P suggest a second criterion in terms of the form ofproofs which, for the natural deduction formulation of theLC that B&P use, is equivalent to the criterion in termsof laznbda expressions (given that a variant of the Curry-Howard correspondence between implicational deductionsand lambda expressions obtains).s Clearly, the reversal of two co-directional rguments (i.e.x /y /z  =~ x/z/y)  would also be DP for this reason, but is notLC-valld (since it would not preserve linear order require-ments).
For a unidirectional CG system (i.e.
a system with asingle connective/,  that did not specify linear order require-ments), free reversal of axguments would be appropriate.
Wesuggest hat a unidirectional variant of the calculus to beproposed might be the best system for pure reasoning about'categorial dependency', aside from linearity considerations.9These unary metarules have been used elsewhere as partof the LC formulation of Zielonka (1981).new unary rules from tile associat, ivit.)
axioms.
(12) a. a \b /c /d  ~ a/ckb/db.
x / (a \b /c )  ~ x/Ca/c\b)(13) a.
?
: x=~y ==~ V?
: x/z : :~y/z?
: x=~y ==~ V?
: x\z =~y\z(where V =  f a b.f(ab))b. ?
:x=~y ==~ Z?
: z /y=~z/x?
: x==~y ~ Z?
: z \y=~ z\x(where Z =(14) x / (a \b /c ) : f~  x/(a/c\b):~v./O~a~b.vba)Clearly, the rules {V,Z,a} allow only DP unarytransformations.
However, we make the strongerclaim that these rules specify the limit of DP unarytransformations.
The rules allow that the givenfunctional structure of a type be 'shuffled' upto thelimit of preserving linear order requirements.
Butthe only alternative to such 'shuffling' would seemto be that some of the given type structure be re-moved or further type structure be added, which, bythe assumption that functional structure xpressesdependency relations, cannot be DP.We propose the system {L,R,V,Z,a,f ,b} as a cal-culus allowing all and only the DP combinations andtransformations of types, with a 'division of labour'as follows: (i) the rules f and b, allowing the estab-lishment of direct head-dependent relations, (ii) thesubsystem {V,Z,a}, allowing DP transformation oftypes upto the limit of preserving linear order, and(iii) the rules t t  and L, which provide for the inher-itance of 'dependency requirements' onto the resultof a combination.
We call this calculus the depen-dency calculus (DC) (of which we identify two sub-systems: (i) the binary calculus B : {L,R,f,b}, (ii)the unary calculus U : {V,Z,a}).
Note that B&P'scriterion and the DC do not agree on what are DPcombinations in all cases.
For example, the seman-tics for the type transformation i (14) involves ab-straction over a variable that occurs as a functor.Hence this transformation is not DP under B&P'scriterion, although it is admitted by the DC.
Webelieve that the DC is correct in admitting this andthe other additional combinations that it allows.There is clearly a close relation between DP typecombination and the notion of contentful combi-nation discussed earlier.
The 'dependency require-ments' stated by any lexical type will constitute thesum of the 'thematically contentful' relationshipsinto which it may enter.
In allowing all DP com-binations (subject to the limit of preserving linearorder requirements), the DC ensures that lexieally82originating dependency structure is both preservedand also exploited in full.
Consequently, the DC iswell suited to incremental processing.
Note, how-ever, that there is some extent of divergence be-tween the DC and the (admittedly vague) criterionof 'contentful' combination defined earlier.
Con-sider the LC-valid combination in (15), which isnot admitted by the DC.
This combination wouldappear to be 'contentful' since no hypothetical se-mantic functor intervenes between land  g (althoughg has undergone a change in its relationship to itsown argument which depends on such a hypothet-ical functor).
However, we do not expect that theexclusion of such combinations will substraet signif-icantly from genuinely useful incrementality in pars-ing actual grammars.
(15) x/(y/z):/, x:l(X .g(Xh.hv))Parsing and the Dependency CalculusBinary combinations allowed by the DC are all ofthe form (16) (where the vertical dots abbrevi-ate unary transformations, and ?
is some binaryrule).
The obvious naive approach to finding possi-ble combinations of two types x and y under the DCinvolves earching through the possible unary trans-forms of x and y, then trying each possible pairingof them with the binary rules of B, and then deriv-ing the set of unary transforms for the result of anysuccessful combination.At first sight, the efficiency of processing usingthis calculus seems to be in doubt.
Firstly, thesearch space to be addressed in checking for possiblecombinations of two types is considerably greaterthan for CCG or MCG.
Also, the DC will suffer spu-rious ambiguity in a fashion directly comparable toCCG and MCG (obviously, for the latter case, sincethe above MCG is a subsystem of the DC).
For ex-ample, the combination x/y, y/z, z ::~ x has bothleft and right branching derivations.However, a further equivalence problem arises dueto the interderivability of types under the unarysubsystem U.
For any unary transformation x :=~ y,the converse y :~ x is always possible, and the se-mantics of these transformations are always inverses.
(This obviously holds for a, and can be shown tohold for more complex transformations by a simpleinduction.)
Consequently, if parsing assigns distincttypes x and y to some substring that are merelyvariants under the unary calculus, this will engen-der redundancy, since anything that can be provenwith x can equivalently be proven with y.
(16) x yX 0ZNormalisation and the Dependency  CalculusThese efficiency problems for parsing with the DCcan be seen to result from equivalence amongst termsoccurring at a number of levels within the system.Our solution to this problem involves pecifying nor-mal forms (NFs) for terms - -  to act as privilegedmembers of their equivalence class - -  at three differ-ent levels of the system: (i) types, (ii) binary com-binations, (iii) proofs.
The resulting system allowsfor efficient categorial parsing which is incrementalup to the limit allowed by the DC.A standard way of specifying NFs is based onthe method of reduction, and involves defining acontraction relation (I>1) between terms, which isstated as a number of contraction rules of the formX !>1 Y (where X is termed a redez and Y its con-tractum).
Each contraction rule allows that a termcontaining a redex may be transformed into a termwhere that occurrence is replaced by its contractum.A term is said to be in NF if and only if it containsno redexes.
The contraction relation generates a re-duction relation (1>) such that X reduces to Y (X I>Y) iff Y is obtained from X by a finite series (pos-sibly zero) of contractions.
A term Y is a NF of Xiff Y is a NF and X 1> Y.
The contraction relationalso generates an equivalence relation which is suchthat X = Y iff Y can be obtained from X by a se-quence of zero or more steps, each of which is eithera contraction or reverse contraction.Interderivability of types under U can be seen asgiving a notion of equivalence for types.
The con-traction rule (17) defines a NF for types.
Sincecontraction rules apply to any redex subformula oc-curring within some overall term, this rule's do-main of application is as broad as that of the as-sociativity axioms in the unary calculus given thegeneralising effects of the unary metarules.
Hence,the notion of equivalence generated by rule (16) isthe same as that defined by interderivability un-der U.
It is straightforward to show that the reduc-tion relation defined by (16) exhibits two impor-tant properties: (i) strong normalisation 1?, with the1?To prove s t rong normal i sat ion  it is sufficient to give ametr ic  which ass igns each te rm a f inite non-negat ive integerscore, and  under  which every contract ion  reduces the scorefor a te rm by a posit ive integer  amount .
The  following metr icsuffices: (a) X ~ = 1 if X is atomic,  (b) (X /Y)  t = X ~ + Y~,(c) (X \Y ) '  = 2(X'  + Y ' ) .83consequence that every type has a NF, and (ii) theChurch-Rosser property, from which it follows thatNFs are unique.
In (18), a constructive notionof NF is specified.
It is easily shown that this con-structive definition identifies the same types to beNFs as the reduetive definition.
11(17) x/y\,.
~1 x\z/y(18) x\yl.-Yi/Yi+l..Ynwhere n _~ 0, x is a basic type and each yj(1 < j < n) is in turn of this general form.
(19) ?
: x /u t , .u ,  + y =~ z ==~L(n)?
: x \w/u l .
.U,  + y =~ z\w(where L(n) ---- A#AaAbAc.#(Ava..vn.avl..vnc)b)We next consider normalisation for binary com-binations.
For this purpose, we require a modifiedversion of the binary calculus, called W, having therules {L(n),R,f ,b}),  where L(n) is a 'generalised'variant of the metarule L, shown in (19) (where thenotation X/Ul..Un is schematic for a function seek-ing n forward directional arguments, e.g.
so that forn = 3 we have x/ux..un = X/Ul/U~/Us).
Note thatthe case L(0) is equivalent to L.We will show that for every binary combinationX + Y =~ Z under the DC, there is a correspond-ing combination X' + Y~ =* Z' under W, where X ~,Y' and Z' are the NFs of X, Y and Z.
To demon-strate this, it is sufficient to show that for everycombination under B, there is a corresponding Wcombination of the NFs of the types (i.e.
since forbinary combinations under the DC, of the form in(16), the types occurring at the top and bottom ofany sequence of unary transformations will have thesame NF).The  following contraction rules define a NF  forcombinations under B ~ (which includes the combi-nations of B as a subset -- provided that each useof L is relabelled as L(0)):(20) IF w l>t w' THENa.
f: w/y + y :=~ w 1>1 f: w'/y + y =~ w'b.
f: y /w + w ::~ y I>t f: y /w'  + w' =~ yc.
b: y+w\y=~w E>lb: y+w~\y=~w'd.
b: w + y \w :=~ y !>1 b: w' + ykw' :=~ ye.
L(i)?
: x\w/ul .
.Ui  + y =~ z\w I>1L(i)?
: xkw'/ul .
.u/ + y =~ zkw tf.
Re:  x + y /w =~ z/w t>lRe:  x + y/w' ::~ z/w'laThis NF is based on an arbitrary bias in the restruc-turing of types, i.e.
ordering backward irectional rgumentsafter forward irectional rguments.
The opposite bias (i.e.forward arguments after backward arguments) could as wellhave been chosen.
(21) L( i )R?
: x\w/ul .
.u i  + y /v  =~ z/v \w t>lRL( i )?
:  x \w/ul .
.u i  + y/v  ::~ zkw/v(22) L(o)f: x /w\v  + w ~ x\v  \[:>1f: x \v/w + w =~ x\v(23) L(i)f: xkw/ul..Ui + ui =*" x /u l .
.u i - t \w  t>lf: x\w/ul..ul + ui ~ x\w/ul..u;_~for i > O.
(24) b: ~.
+ x/y\~, ~ x /y  ~1Rb:  z + x \z /y  =~ x /y(25) L(i)?
: X/V\W/Ul..U i + y ~ Z\W E> 1L( i+I )?
:  x \w/v /u l .
.u i  + y ==~ z\w(26) IF ?
: x+y==~z 1>1 ?
': x '+y ' :=~z 'THEN R?
:x+y/w:=~z/w I>lRe': x' + y'/w =~ z'/w(27) IF  ?
: X/Ul..Ui + y :=~ z I>t?~: x' /ul ' .
.u l  ~ + y' =~ z'THEN L(i)~b: x \w/u l .
.u i  + y =~ z I>1L(i)?
': x ' \w/u l ' .
.u i '  + y' ~ z'These rules also transform the types involved intotheir NFs.
In the cases in (20), a contraction ismade without affecting the identity of the particularrule used to combine the types.
In (21-25), thetransformations made on types requires that somechange be made to the rule used to combine them.The rules (26) and (27) recursively define newcontractions in terms of the basic ones.This reduction system can be shown to exhibitstrong normalisation, and it is straightforward toar-gue that each combination must have a unique NF.This definition of NF accords with the constructivedefinition (28).
(Note that the notation R n rep-resents a sequence of n Rs, which are to be brack-eted right-associatively with the following rule, e.g.so that R~f = (R(Rf)) ,  and that i takes the samevalue for each L(i) in the sequence L(i)"L)(28) ?
:x+y~zwhere x, y, z are NF types, and ?
is (Rnf)or (RnL(i)mb), for n, m > 0.Each proof of some combination xl,.
.
,xn =~ x0under the DC can be seen to consist of a number ofbinary 'subtrees', each of the form (16).
If we sub-stitute each binary subtree with its NF combinationin W, this gives a proof of Xlt,..,x~ ' =~ x0 t (whereeach xl ~ is the NF ofxi) .
Hence, for every DC proof,there is a corresponding proof of the combination ofthe NFs of the same types under B'.Even if we consider only proofs involving NF com-binations in W, we observe spurious ambiguity ofthe kind familiar from CCG and MCG.
Again, wecan deal with this problem by defining NFs for such84proofs.
Since we are interested in incremental pro-cessing, our method for identifying NF proofs isbased on favouring left-branching structures.Let us consider the patterns of functional depen-dency that are possible amongst sequences of threetypes.
These are shown in (29).
12 Of these cases,some (i.e.
(a) and (f)) can only be derived witha left-branching proof under B' (or the DC), andothers (i.e.
(b) and (e)) can only be derived witha right-branching proof.
Combinations of the pat-terns (c),(d) and (g) commonly allow both right andleft-branching derivations (though not in all cases).
(29) (a) ~ (h) (x y z x y z(c) (d)x y z x y z(e) , (f) ?x y z x y z(g)x y z(30) (R"f) :  x /y  + y /u l .
.un  ~ x /u l .
.u .
(31) (R"L(/)mb):x\wl..wm/ul..u, + y\(xlul..n,)lvl..v.=~ y\wl..wm/vl..v,~NF binary combinations of the pattern in (28) takethe two more specific forms in (30) and (31).Knowing this, we can easily sketch out the schematicform of the three element combinations correspond-ing to (29c,d,g) which have equivalent left andright branching proofs, as shown in Figure 1.We can define a NF for proofs under B I (that useonly NF combinations) by stating three contractionrules, one for each of the three cases in Figure 1,where each rule rewrites the right branching three-leaf subproof as the equivalent left branching sub-proof.
This will identify the optimally left branch-ing member of each equivalence class of proofs as itsNF exemplar.
Again, it is easily shown that reduc-tion under these rules exhibits strong normalisationand the Church-Rosser property, so that every proofmust have a unique normal form.
However, it is notso easy to prove the stronger claim that there is onlya single NF proof that assigns each distinct read-ing for any combination.
13 We shall not attempt12Note that  various other conceivable patterns  of depen-dency do not need to be considered here since they do notcorrespond to  any Lambek-val id combination.~3 Thls holds if the contract ion relat ion generates an equiv-to demonstrate this property, although we believethat it holds.
We can identify the redexes of thesethree contraction rules purely in terms of the rulesused to combine types, i.e.
without needing to ex-amine the schematic form of the types, since therules themselves identify the relevant structure ofthe types.
In fact, the right-branching subproofs forcases (29c,g) collapse to the single schematic redex(32), and that for (29d) simplifies to the schematicredex (33).
(Note that the notation ?~ is used torepresent any (NF) rule which is recursively definedon a second rule ~r, e.g.
so that ~rb is any NF ruledefined on b.
)(32) x y zltm fw where n ~_ mv(33) x y z'~b(L(i}b) w where n ~ 1Ir bVLet us consider the use of this system for pars-ing.
In seeking combinations of some sequence oftypes, we first begin by transforming the types intotheir NFs.
14 Then, we can search for proofs usingonly the NF binary combinations.
Any proof thatis found to contain a proof redexes is discontinued,so that only NF proofs are returned, avoiding theproblems of spurious ambiguity.
Any result typesassigned by such proofs stand as NF exemplars forthe set of non-NF types that could be derived fromthe original input types under the DC.
We may wantto know if some input types can combine to give aspecific result type x.
This will be the case if theparser returns the NF of x.Regarding incremental processing, we have seenthat the DC is well-suited to this task in terms of al-lowing combinations that may usefully contribute toa knowledge of the semantic relations amongst hephrases combined, and that the NF proofs we havedefined (and which the parser will construct) areoptimally left-branching to the limit set by the cal-culus.
Hence, in left-to-right analysis of sentences,the parser will be able to combine the presentedmaterial to the maximal extent that doing so use-fully contributes to incremental interpretation andthe filtering of semantically implausible analyses.alence relat ion that  equates any two proofs iff these assignextenslonal ly equivalent readings.14The complexity of this t ransformat ion is constant in thecomplexity of the type.85C~.
(2s~):(a) x/y y/wa..w. W,/Vl..Vm gnfx/wa ..w,.R'nfx/wa ..wn-I/vl..vmC~ (2Sd):(~) w,\q~..qk/u,..us(b) x/y y/wl .
.wn Wn/Vl..vm.I%mfy/wl ..Wn--1/Vl .-vmRm+n_l fx/wl..w,-a/va..v,,(b) w,\~..qk/ua..ujy\wl..Wn--l \(wn/ul..Uj)/vl..vi x\(y/vl..Vi)/tl..tmRmL(1)nby\wl ..wn-a\q,..qk/v, ..vlx\wa ..wn-i \ql .
.~lt l  ..tinCase (28g):(a) y\wl ..wj/ul ..ui x\(y/ul  ..ui)/Vl ..Vm vm/ql--qn R'nL(i)~bX\Wl..Wj/Va..Vm Rnfx\wl..w~//vl..Vm-i/ql..qn(b) y\wl ..wj/ul ..ui x\(y/ul..ui)/vl ..vm vm/ql ..qn\]Ln fx\(ylul..Ui)/vz..vm-l/ql..qnam+n_ 1 L(i)JbX\Wl..Wn-l\(wn/ul..uj)/tl..tmRmg(j)kbx\wl ..w,-a \qu ..qk/ta..t,,y\wl .
.w,- I  \(wn/ul ..uj)/vl ..ViRiL.j.kb_() x\(y/vl  ..vi)/tl ..tinx\wa..w~l,,l..v,,,-, lo~..qnRmL(1) k4n-I bFigure 1: Equivalent left and right-branching three-leaf subproofsReferencesAdes, A.E.
and Steedman, M.J. 1982.
'On the order ofwords.'
Linguistics and Philosophy, 4.Barry, G. \]orthcoming:1991.
Ph.D. dissertation, Centre forCognitive Science, University of Edinburgh.Barry, G., Hepple, M., Leslie, N. and Morrill, G. 1991.
'Prooffigures and structural operators for categorial grammar'.
InEA CL-5, Berlin.Barry, G. and Morrill, G. 1990.
(Eds).
Studies in CategorlalGrammar.
Edinburgh Working Papers in Cognitive Sci-ence, Volume 5.
Centre for Cognitive Science, Universityof Edinburgh.Barry, G. and Piekering, M. 1990.
'Dependency and Con-stituency in Categorial Grammar.'
In Barry, G. and Mor-rill, G. 1990.Dowty, D. 1988.
'Type raising, function composition, andnon-constituent conjunction.'
In Oehrle, R., Bach, E. andWheeler, D. (Eds), Categorial Grammars and Natural Lan-guage Structures, D. Reidel, Dordrecht.Hepple, M. 1990.
'Normal form theorem proving for the Lam-bek calculus.'
In Karlgren, H. (Ed), Proe.
o\] COLING1990.Hepple, M. 1990.
The Grammar and Processing of Orderand Dependency: A Categorial Approach.
Ph.D. disser-tation, Centre for Cognitive Science, University of Edin-burgh.Hepple, M. and Morrill, G. 1989.
'Parsing and derivationalequivalence.'
In EACL-J, UMIST, Manchester.KSnig, E. 1989, 'Parsing as natural deduction.'
In Proc.
o\]A CL-$5, Vancouver.Lambek, J.
1958.
'The mathematics of sentence structure.
'American Mathematical Monthly 65.Moortgat, M. 1989.
Categorial Investigations: Logical andLinguistic Aspects o\] the Lambek Calculus, Foris, Dordrecht.Moortgat, M. 1990.
'Unambiguous proof representations forthe Lambek calculus.'
In Proe.
o\] 7th Amsterdam Collo-quium, University of Amsterdam.Moortgat, M. 1990.
'The logic of discontinuous type con-structors.'
In Proc.
of the Symposium on DiscontinuousConstituency, Institute for Language Technology and In-formation, University of Tllburg.Morrill, G. 1988, Extraction and Coordination in PhraseStructure Grammar and Categorial Grammar.
Ph.D. dis-sertation, Centre for Cognitive Science, University of Ed-inbturgh.Morrill, G. 1990.
'Grammar and Logical Types.'
In Proc.7th Amsterdam Colloquium, University of Amsterdam.
Anextended version appears in Barry, G. and Morrill, G. 1990.Morrill, G., Leslie, N., Hepp\]e, M. and Barry, G. 1990.
'Cat-egorial deductions and structural operations.'
In Barry, G.and Morrill, G. 1990.Piekering, M. 1991.
Processing Dependencies.
Ph.D. disser-tation, Centre for Cognitive Science, University of Edin-burgh.Steedrnan, Mark.
1985.
'Dependency and Coordination inthe Grammar of Dutch and English.'
Language, 61:3.Steedman, Mark.
1987.
'Combinatory Grammars and Para-sitic Gaps.'
NLLT, 5:3.Steedman, M.J. 1989.
'Gramnaar, interpretation a d process-ing from the lexicon.'
In Marslen-Wilson, W. (Ed), LexicalRepresentation and Process, MIT Press, Cambridge, MA.Szabolcsi, A.
1987 'On Combinatory Categorial grammar.
'In Proc.
o.f the Symposium on Logic and Language, Debre-cen, Akad6miai Kiad6, Budapest.Zielonka, W. 1981.
'AxiomatizabilityofAjdukiewicz-LambekCalculus by Means of Cancellation Schemes.'
Zeitschr.
\].math.
Logik und Grundlagen d. Math.
27.86
