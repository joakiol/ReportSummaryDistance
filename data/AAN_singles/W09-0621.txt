Proceedings of the 12th European Workshop on Natural Language Generation, pages 122?125,Athens, Greece, 30 ?
31 March 2009. c?2009 Association for Computational LinguisticsClustering and Matching Headlines for Automatic Paraphrase AcquisitionSander Wubben, Antal van den Bosch, Emiel Krahmer, Erwin MarsiTilburg centre for Creative ComputingTilburg UniversityThe Netherlands{s.wubben,antal.vdnbosch,e.j.krahmer,e.c.marsi}@uvt.nlAbstractFor developing a data-driven text rewritingalgorithm for paraphrasing, it is essentialto have a monolingual corpus of alignedparaphrased sentences.
News article head-lines are a rich source of paraphrases; theytend to describe the same event in vari-ous different ways, and can easily be ob-tained from the web.
We compare twomethods of aligning headlines to constructsuch an aligned corpus of paraphrases, onebased on clustering, and the other on pair-wise similarity-based matching.
We showthat the latter performs best on the task ofaligning paraphrastic headlines.1 IntroductionIn recent years, text-to-text generation has re-ceived increasing attention in the field of Nat-ural Language Generation (NLG).
In contrastto traditional concept-to-text systems, text-to-textgeneration systems convert source text to targettext, where typically the source and target textshare the same meaning to some extent.
Ap-plications of text-to-text generation include sum-marization (Knight and Marcu, 2002), question-answering (Lin and Pantel, 2001), and machinetranslation.For text-to-text generation it is important toknow which words and phrases are semanticallyclose or exchangable in which contexts.
Whilethere are various resources available that capturesuch knowledge at the word level (e.g., synsetknowledge in WordNet), this kind of informationis much harder to get by at the phrase level.
There-fore, paraphrase acquisition can be considered animportant technology for producing resources fortext-to-text generation.
Paraphrase generation hasalready proven to be valuable for Question An-swering (Lin and Pantel, 2001; Riezler et al,2007), Machine Translation (Callison-Burch et al,2006) and the evaluation thereof (Russo-Lassneret al, 2006; Kauchak and Barzilay, 2006; Zhou etal., 2006), but also for text simplification and ex-planation.In the study described in this paper, we makean effort to collect Dutch paraphrases from newsarticle headlines in an unsupervised way to beused in future paraphrase generation.
News ar-ticle headlines are abundant on the web, andare already grouped by news aggregators such asGoogle News.
These services collect multiple arti-cles covering the same event.
Crawling such newsaggregators is an effective way of collecting re-lated articles which can straightforwardly be usedfor the acquisition of paraphrases (Dolan et al,2004; Nelken and Shieber, 2006).
We use thismethod to collect a large amount of aligned para-phrases in an automatic fashion.2 MethodWe aim to build a high-quality paraphrase corpus.Considering the fact that this corpus will be the ba-sic resource of a paraphrase generation system, weneed it to be as free of errors as possible, becauseerrors will propagate throughout the system.
Thisimplies that we focus on obtaining a high precisionin the paraphrases collection process.
Where pre-vious work has focused on aligning news-items atthe paragraph and sentence level (Barzilay and El-hadad, 2003), we choose to focus on aligning theheadlines of news articles.
We think this approachwill enable us to harvest reliable training materialfor paraphrase generation quickly and efficiently,without having to worry too much about the prob-lems that arise when trying to align complete newsarticles.For the development of our system we usedata which was obtained in the DAESO-project.This project is an ongoing effort to build a Par-allel Monolingual Treebank for Dutch (Marsi122Placenta sandwich?
No, urban legend!Tom wants to make movie with KatieKate?s dad not happy with Tom CruiseCruise and Holmes sign for eighteen millionEighteen million for Tom and KatieNewest mission Tom Cruise not very convincingLatest mission Tom Cruise succeeds less wellTom Cruise barely succeeds with MI:3Tom Cruise: How weird is he?How weird is Tom Cruise really?Tom Cruise leaves familyTom Cruise escapes changing diapersTable 1: Part of a sample headline cluster, withsub-clustersand Krahmer, 2007) and will be made availablethrough the Dutch HLT Agency.
Part of the datain the DAESO-corpus consists of headline clusterscrawled from Google News Netherlands in the pe-riod April?August 2006.
For each news article,the headline and the first 150 characters of the ar-ticle were stored.
Roughly 13,000 clusters wereretrieved.
Table 1 shows part of a (translated) clus-ter.
It is clear that although clusters deal roughlywith one subject, the headlines can represent quitea different perspective on the content of the arti-cle.
To obtain only paraphrase pairs, the clustersneed to be more coherent.
To that end 865 clus-ters were manually subdivided into sub-clusters ofheadlines that show clear semantic overlap.
Sub-clustering is no trivial task, however.
Some sen-tences are very clearly paraphrases, but considerfor instance the last two sentences in the example.They do paraphrase each other to some extent, buttheir relation can only be understood properly withworld knowledge.
Also, there are numerous head-lines that can not be sub-clustered, such as the firstthree headlines shown in the example.We use these annotated clusters as developmentand test data in developing a method to automat-ically obtain paraphrase pairs from headline clus-ters.
We divide the annotated headline clusters in adevelopment set of 40 clusters, while the remain-der is used as test data.
The headlines are stemmedusing the porter stemmer for Dutch (Kraaij andPohlmann, 1994).Instead of a word overlap measure as used byBarzilay and Elhadad (2003), we use a modifiedTF ?IDF word score as was suggested by Nelkenand Shieber (2006).
Each sentence is viewed as adocument, and each original cluster as a collectionof documents.
For each stemmed word i in sen-tence j, TFi,j is a binary variable indicating if theword occurs in the sentence or not.
The TF ?IDFscore is then:TF.IDFi = TFi,j ?
log|D||{dj : ti ?
dj}||D| is the total number of sentences in the clus-ter and |{dj : ti ?
dj}| is the number of sen-tences that contain the term ti.
These scores areused in a vector space representation.
The similar-ity between headlines can be calculated by usinga similarity function on the headline vectors, suchas cosine similarity.2.1 ClusteringOur first approach is to use a clustering algorithmto cluster similar headlines.
The original GoogleNews headline clusters are reclustered into finergrained sub-clusters.
We use the k-means imple-mentation in the CLUTO1 software package.
Thek-means algorithm is an algorithm that assignsk centers to represent the clustering of n points(k < n) in a vector space.
The total intra-clustervariances is minimized by the functionV =k?i=1?xj?Si(xj ?
?i)2where ?i is the centroid of all the points xj ?
Si.The PK1 cluster-stopping algorithm as pro-posed by Pedersen and Kulkarni (2006) is used tofind the optimal k for each sub-cluster:PK1(k) =Cr(k)?mean(Cr[1...?K])std(Cr[1...?K])Here, Cr is a criterion function, which mea-sures the ratio of withincluster similarity to be-tweencluster similarity.
As soon as PK1(k) ex-ceeds a threshold, k?1 is selected as the optimumnumber of clusters.To find the optimal threshold value for cluster-stopping, optimization is performed on the devel-opment data.
Our optimization function is an F -score:F?
=(1 + ?2) ?
(precision ?
recall)(?2 ?
precision + recall)1http://glaros.dtc.umn.edu/gkhome/views/cluto/123We evaluate the number of aligments between pos-sible paraphrases.
For instance, in a cluster of foursentences,(42)= 6 alignments can be made.
Inour case, precision is the number of alignmentsretrieved from the clusters which are relevant, di-vided by the total number of retrieved alignments.Recall is the number of relevant retrieved alig-ments divided by the total number of relevantalignments.We use an F?-score with a ?
of 0.25 as wefavour precision over recall.
We do not want to op-timize on precision alone, because we still want toretrieve a fair amount of paraphrases and not onlythe ones that are very similar.
Through optimiza-tion on our development set, we find an optimalthreshold for the PK1 algorithm thpk1 = 1.
Foreach original cluster, k-means clustering is thenperformed using the k found by the cluster stop-ping function.
In each newly obtained cluster allheadlines can be aligned to each other.2.2 Pairwise similarityOur second approach is to calculate the similaritybetween pairs of headlines directly.
If the similar-ity exceeds a certain threshold, the pair is acceptedas a paraphrase pair.
If it is below the thresh-old, it is rejected.
However, as Barzilay and El-hadad (2003) have pointed out, sentence mappingin this way is only effective to a certain extent.Beyond that point, context is needed.
With thisin mind, we adopt two thresholds and the Cosinesimilarity function to calculate the similarity be-tween two sentences:cos(?)
=V 1 ?
V 2?V 1?
?V 2?where V 1 and V 2 are the vectors of the two sen-tences being compared.
If the similarity is higherthan the upper threshold, it is accepted.
If it islower than the lower theshold, it is rejected.
Inthe remaining case of a similarity between the twothresholds, similarity is calculated over the con-texts of the two headlines, namely the text snippetthat was retrieved with the headline.
If this simi-larity exceeds the upper threshold, it is accepted.Threshold values as found by optimizing on thedevelopment data using again an F0.25-score, areThlower = 0.2 and Thupper = 0.5.
An optionalfinal step is to add alignments that are implied byprevious alignments.
For instance, if headlineA ispaired with headline B, and headline B is alignedto headline C, headline A can be aligned to C asType Precision Recallk-means clustering 0.91 0.43clusters onlyk-means clustering 0.66 0.44all headlinespairwise similarity 0.93 0.39clusters onlypairwise similarity 0.76 0.41all headlinesTable 2: Precision and Recall for both methodsPlaystation 3 more expensive thancompetitorPlaystation 3 will become moreexpensive than Xbox 360Sony postpones Blu-Ray moviesSony postpones coming of blu-ray dvdsPrices Playstation 3 known: from 499 eurosE3 2006: Playstation 3 from 499 eurosSony PS3 with Blu-Ray for sale fromNovember 11thPS3 available in Europe fromNovember 17thTable 3: Examples of correct (above) and incorrect(below) alignmentswell.
We do not add these alignments, because inparticular in large clusters when one wrong align-ment is made, this process chains together a largeamount of incorrect alignments.3 ResultsThe 825 clusters in the test set contain 1,751 sub-clusters in total.
In these sub-clusters, there are6,685 clustered headlines.
Another 3,123 head-lines remain unclustered.
Table 2 displays theparaphrase detection precision and recall of ourtwo approaches.
It is clear that k-means cluster-ing performs well when all unclustered headlinesare artificially ignored.
In the more realistic casewhen there are also items that cannot be clustered,the pairwise calculation of similarity with a backoff strategy of using context performs better whenwe aim for higher precision.
Some examples ofcorrect and incorrect alignments are given in Ta-ble 3.1244 DiscussionUsing headlines of news articles clustered byGoogle News, and finding good paraphraseswithin these clusters is an effective route for ob-taining pairs of paraphrased sentences with rea-sonable precision.
We have shown that a cosinesimilarity function comparing headlines and us-ing a back off strategy to compare context can beused to extract paraphrase pairs at a precision of0.76.
Although we could aim for a higher preci-sion by assigning higher values to the thresholds,we still want some recall and variation in our para-phrases.
Of course the coverage of our method isstill somewhat limited: only paraphrases that havesome words in common will be extracted.
Thisis not a bad thing: we are particularly interestedin extracting paraphrase patterns at the constituentlevel.
These alignments can be made with existingalignment tools such as the GIZA++ toolkit.We measure the performance of our approachesby comparing to human annotation of sub-clusterings.
The human task in itself is hard.
Forinstance, is we look at the incorrect examples inTable 3, the difficulty of distinguishing betweenparaphrases and non-paraphrases is apparent.
Infuture research we would like to investigate thetask of judging paraphrases.
The next step wewould like to take towards automatic paraphrasegeneration, is to identify the differences betweenparaphrases at the constituent level.
This task hasin fact been performed by human annotators in theDAESO-project.
A logical next step would be tolearn to align the different constituents on our ex-tracted paraphrases in an unsupervised way.AcknowledgementsThanks are due to the Netherlands Organizationfor Scientific Research (NWO) and to the DutchHLT Stevin programme.
Thanks also to WauterBosma for originally mining the headlines fromGoogle News.
For more information on DAESO,please visit daeso.uvt.nl.ReferencesRegina Barzilay and Noemie Elhadad.
2003.
Sentencealignment for monolingual comparable corpora.
InProceedings of the 2003 conference on Empiricalmethods in natural language processing, pages 25?32.Chris Callison-Burch, Philipp Koehn, and Miles Os-borne.
2006.
Improved statistical machine transla-tion using paraphrases.
In Proceedings of the mainconference on Human Language Technology Con-ference of the North American Chapter of the Asso-ciation of Computational Linguistics, pages 17?24.Bill Dolan, Chris Quirk, and Chris Brockett.
2004.Unsupervised construction of large paraphrase cor-pora: exploiting massively parallel news sources.
InCOLING ?04: Proceedings of the 20th internationalconference on Computational Linguistics, page 350.David Kauchak and Regina Barzilay.
2006.
Para-phrasing for automatic evaluation.
In Proceedingsof the Human Language Technology Conference ofthe NAACL, Main Conference, pages 455?462, June.Kevin Knight and Daniel Marcu.
2002.
Summa-rization beyond sentence extraction: a probabilis-tic approach to sentence compression.
Artif.
Intell.,139(1):91?107.Wessel Kraaij and Rene Pohlmann.
1994.
Portersstemming algorithm for dutch.
In Informatieweten-schap 1994: Wetenschappelijke bijdragen aan dederde STINFON Conferentie, pages 167?180.Dekang Lin and Patrick Pantel.
2001.
Dirt: Discov-ery of inference rules from text.
In KDD ?01: Pro-ceedings of the seventh ACM SIGKDD internationalconference on Knowledge discovery and data min-ing, pages 323?328.Erwin Marsi and Emiel Krahmer.
2007.
Annotatinga parallel monolingual treebank with semantic sim-ilarity relations.
In he Sixth International Workshopon Treebanks and Linguistic Theories (TLT?07).Rani Nelken and Stuart M. Shieber.
2006.
Towards ro-bust context-sensitive sentence alignment for mono-lingual corpora.
In Proceedings of the 11th Confer-ence of the European Chapter of the Association forComputational Linguistics (EACL-06), 3?7 April.Ted Pedersen and Anagha Kulkarni.
2006.
Automaticcluster stopping with criterion functions and the gapstatistic.
In Proceedings of the 2006 Conferenceof the North American Chapter of the Associationfor Computational Linguistics on Human LanguageTechnology, pages 276?279.Stefan Riezler, Alexander Vasserman, IoannisTsochantaridis, Vibhu O. Mittal, and Yi Liu.
2007.Statistical machine translation for query expansionin answer retrieval.
In ACL.Grazia Russo-Lassner, Jimmy Lin, and Philip Resnik.2006.
A paraphrase-based approach to machinetranslation evaluation.
Technical report, Universityof Maryland, College Park.Liang Zhou, Chin-Yew Lin, and Eduard Hovy.
2006.Re-evaluating machine translation results with para-phrase support.
In Proceedings of the 2006 Con-ference on Empirical Methods in Natural LanguageProcessing, pages 77?84, July.125
