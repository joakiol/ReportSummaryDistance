Proceedings of the 2th Workshop of Natural Language Processing for Improving Textual Accessibility (NLP4ITA), pages 1?10,Atlanta, Georgia, 14 June 2013. c?2013 Association for Computational LinguisticsA User Study: Technology to Increase Teachers?
Linguistic Awarenessto Improve Instructional Language Supportfor English Language LearnersJill Burstein, John Sabatini, Jane Shore, Brad Moulder, and Jennifer LentiniEducational Testing Service666 Rosedale Road, Princeton, New Jersey 08541{jburstein, jsabatini, jshore, bmoulder, jlentini}@ets.orgAbstractThis paper discusses user study outcomes withteachers who used Language MuseSM a web-based teacher professional development (TPD)application designed to enhance teachers?
lin-guistic awareness, and support teachers in thedevelopment of language-based instructionalscaffolding (support) for their English languagelearners (ELL).
System development wasgrounded in literature that supports the notionthat instruction incorporating language supportfor ELLs can improve their accessibility tocontent-area classroom texts ?in terms of ac-cess to content, and improvement of languageskills.
Measurement outcomes of user pilotingwith teachers in a TPD setting indicated thatapplication use increased teachers' linguisticknowledge and awareness, and their ability todevelop appropriate language-based instructionfor ELLs.
Instruction developed during the pi-lot was informed by the application?s linguisticanalysis feedback, provided by natural lan-guage processing capabilities in LanguageMuse.1 IntroductionStatistics show that between 1997 and 2009 thenumber of ELLs enrolled in U.S. public schoolshas increased by 51% (National Clearinghouse forLanguage Acquisition, 2011).
ELLs who havelower literacy skills, and who are reading belowgrade level may be mainstreamed into regular con-tent-area classrooms, and may not receive supple-mental English language instruction.Unfortunately, K-12 content-area teachers1 are lesslikely to be trained to adapt their instructional ap-proaches to accommodate the diverse cultural andlinguistic backgrounds of students with varyinglevels of English proficiency (Adger, Snow, &Christian, 2002; Calder?n, August, Slavin, Cheun,Dur?n, & Madden, 2005; Rivera, Moughamian,Lesaux, & Francis, 2008; Walqui & Heritage,2012).
This situation motivated the developmentof Language MuseSM, a web-based application de-signed to offer teacher professional development(TPD) for content-area teachers to support theirunderstanding of potential sources of linguisticunfamiliarity that may obscure text content forELLs, and their ability to develop relevant lan-guage-based instructional scaffolding.
We rea-soned that prerequisite to effectively planning orimplementing instructional supports for ELLs,teachers first needed to be able to recognize poten-tial sources of linguistic difficulty.
Further, teach-ers might need training about the specificlinguistic structures that might be unfamiliar tolearners, and which might lead to learners?
inac-cessibility to core content in text.The motivation for Language Muse, thus, grewfrom the need to provide teachers with trainingabout linguistic features in texts that may be un-familiar to learners.
In complement to trainingvideos and reading resources, Language Musecontains a module that provides automated andexplicit linguistic feedback for texts, and is intend-1 These are Kindergarten-12th grade teachers of subject areas,including math, science, social studies, and English languagearts.1ed to support teachers in the development of les-son plans with language-based instructional activi-ties and assessments to support reading andcontent comprehension of texts.
The linguisticfeedback module uses various natural languageprocessing methods to provide feedback at the vo-cabulary, phrasal, sentential, and discourse levels.Another motivation of application was efficiency.Even with a strong linguistic awareness, manualidentification of linguistic features would be avery time-consuming process.Outcomes from pre-post teacher assessmentsdelivered through user piloting with teachers indi-cated that teachers who used Language Museshowed gains in linguistic knowledge.
Outcomesalso indicated that Language Muse use supportedteachers in the ability to develop appropriate lan-guage-based instruction for ELLs, informed by theapplication?s linguistic analysis feedback.2 Related WorkIn a brief literature review, we address the lan-guage demands for ELLs in reading content-areatexts, and the need for relevant teacher training forcontent-area teachers (Section 2.1).
We also dis-cuss NLP-related applications that support the lin-guistic analysis of texts -- typically in the contextof developing readability measures -- which con-tinues to be a prominent area of research; otherresearch supports student tools allowing directinteraction with language forms (Section 2.2).2.1 Language Demands on ELLs, andTeacher TrainingLanguage Demands on ELLs.
The English Lan-guage Arts Common Core State Standards2(Standards) (NGA Center & CCSSO, 2010) hasnow been adopted by 46 states and is a trend-setterin U.S. education.
The Standards emphasize theneed for all learners (including ELLs3) to readprogressively more complex texts across multiplegenres in the content areas, preparing learners forcollege and careers.
To accomplish this, learnersmust have familiarity with numerous linguisticfeatures related to vocabulary, English language2 http://www.corestandards.org/3 For details and about Standards and ELLs, see:http://ell.stanford.edu/.structures, and a variety of text structures (dis-course).In terms of vocabulary demands, research re-ports on investigations of academic vocabularyand the Tier word system (Beck, McKeown, &Kucan, 2008; Calder?n, 2007).
Specifically, Tier 1words are those used in everyday conversation;Tier 2 words are general academic words; and Tier3 words are found in specific domains (Beck et al2008; Coleman & Pimental, 2011a).
All three Ti-ers are necessary to academic content learning.Key content-area terms in any text would includethe vocabulary that students are expected to learnregardless of the Tier.
However, there are manyother vocabulary terms in the same text that mayor may not be key content, but may still pose diffi-culties for an ELL reader.
For instance, the phrase?rock star?
is a figurative term whose meaning isnot obvious from knowing the various meaningsof ?rock?
or ?star?.
A deficit in morphologicalawareness can be a source of reading comprehen-sion difficulties among native speakers of English,(Berninger, Abbott, Nagy, & Carlisle, 2009; Nagy,Berninger, & Abbot, 2006), but even more soamong ELLs (Carlo, August, McLaughlin, Snow,Dressler, Lippmann, & White, 2004; Kieffer &Lesaux, 2008).
Teaching morphological structurehas been shown to be effective with ELLs(Lesaux, Kieffer, Faller, & Kelley, 2010; Proctor,Dalton, Uccelli, Biancarosa, Snow, & Neugebauer,2011).
Native language support can also aid stu-dents in learning text-based content (Francis, Au-gust, Goldenberg, & Shanahan, 2004).Specifically, lessons that incorporate cognates(e.g., individual (English) and individuo (Spanish))have been found to be effective in expanding Eng-lish vocabulary development and aiding in com-prehension (August, 2003; Proctor, Dalton, &Grisham, 2007).
Polysemous words can contributeto overall text difficulty.
Papamihiel, Lake & Rice(2005) specifically discuss difficulties of content-specific, polysemous words, where the morecommon meaning may lead to a misconceptionwhen using that meaning to infer the more specificcontent meaning (e.g., prime in prime numbers).Unfamiliar cultural references (e.g., He?s a mem-ber of the Senate.
), when reading an unfamiliarlanguage to learn unfamiliar content, imposes atriple cognitive load for ELLs (Goldenberg, 2008).With regard to sentence-level demands, long,multi-clause sentences can present frustrating2complexities.
Readers need to analyze sentenceclauses to understand and encode key informationin working memory as they build a coherent men-tal model of the meaning of a text (Kintsch, 1998).Different subject areas often have sentential andphrasal structures that are unique to that subject,resulting in comprehension breakdowns, e.g., thenoun phrases in math texts ?a number which canbe divided by itself ??
(Schleppegrell, 2007;Schleppegrell & de Oliveira, 2006).Regarding discourse structure demands, con-tent-area texts may represent varying discourserelationships.
Discourse relations such as, com-pare-contrast, cause-effect can all be intermingledwithin a single passage (Goldman & Rakestraw,2000; Meyer, 2003).
Teachers need to learn howto identify discourse-level information and devel-op scaffolding to support students?
ability to navi-gate discourse elements in texts.
Students may alsobe challenged in keeping track of and resolvingreferential (anaphoric) relationships.
Pronomialreference can be a challenge for ELLs in textswith multiple characters or agents (Kral, 2004).An equal challenge concerns the resolution of ref-erential relations among nouns, phrases, or ideas -a common occurrence in expository texts- whetherthe category of reference is pronominal, synony-my, paraphrase, or determiner, e.g., this, that, orthose (Pretorius, 2005).
Also critical to learningnew content is understanding connector wordsfunctions (e.g., because, therefore) for buildingtext cohesion (Goldman & Murray, 1992;Graesser, McNamara, & Louwerse, 2003).Teacher Training.
Teachers need to become lin-guistically aware of aspects of the English lan-guage that present potential obstacles to contentaccess for ELLs.
Yet, teachers often lack trainingin the identification of features of English that maychallenge diverse groups of ELLs (Adger et al2002; Calder?n et al 2005; Rivera et al 2008;Walqui & Heritage, 2012), and in the implementa-tion of strategies to help ELLs academic languageand vocabulary acquisition (Flinspach, Scott, Mil-ler, Samway, & Vevea, 2008).
Further, the num-ber of teachers trained in effective instructionalstrategies to meet the range of needs of ELLs hasnot increased consistently with the rate of the ELLpopulation (G?ndara, Maxwell-Jolly, & Driscoll,2005; Green, Foote, Walker & Shuman, 2010).Studies suggest that teachers with specializedtraining have a positive impact on student perfor-mance (Darling-Hammond, 2000; Peske & Hay-cock, 2006).2.2 Text Accessibility and NLPConsiderable research in NLP and textaccessibility has focussed on linguistic propertiesof text that render a text relatively more or lessaccessible (comprehensible).
This research streamhas often fed into applications offering readabilitymeasures ?
specifically, measures that predict thegrade level, or grade range of a text (e.g.,elementary, middle or high-school).
Foundationalresearch in this area examined the effect ofmorphological and syntactic text properties.
Flesch(1948) reported that text features such as syllablecounts of words, and sentence length werepredictors of text difficulty.
Newer research inthis area has included increasingly more NLP-based investigations (Collins-Thompson & Callan,2004; Schwarm & Ostendorf, 2005; Miltsakaki,2009).
Some research examines text quality interms of discourse coherence of  well-formed texts(Barzilay & Lapata, 2008; Pitler & Nenkova,2008; Graesser, McNamara, & Kulikowich,2011).Human evaluation of text complexity in curricu-lum materials development (i.e., adaptation andscaffolding of reading texts, and the creation ofactivities and assessments) is a time-consuming,and typically intuitive process.
Determining textcomplexity is also not a clear and objective meas-ure.
For example, what is complex for a nativeEnglish speaker reading on grade level may varyfrom what is complex (or unfamiliar) for an ELLreading below grade level.
This area of researchcontinues to grow as is evidenced by NLP sharedtasks (Mihalcea, Sinha & McCarthy, 2010), in theresearch and educational measurement communi-ties (Burstein, Sabatini, and Shore, in press; Nel-son, Perfetti, Liben & Liben, 2012).The REAP system uses statistical languagemodeling to assign readability measures to Webdocuments (Collins-Thompson & Callan, 2004).This system is used in college-level ESL class-rooms for higher level ESL students.
It is designedto support automatic selection and delivery of ap-propriate and authentic texts to students in an in-structional setting (Heilman, Zhao, Pino, &Eskenazi, 2008).
Teacher users can set a numberof constraints (e.g., reading level, text length, and3target vocabulary) to direct the text search.
Thesystem then automatically performs the text selec-tion.
The system also has tools that allow Englishlearners to work with the text, including dictionarydefinition access and vocabulary practice exercis-es.
In pilot studies with high-intermediate learnersin a university setting, a post-test showed promis-ing learning outcomes (Heilman et al2008).WERTi (Working with English Real Texts in-teractively) (Meurers et al 2010) is an innovativeComputer-Assisted Language Learning (CALL)tool that allows learners to interact directly withNLP outputs related to specific linguistic forms.
Inthe context of a standard search environment,learners can select texts from the web.
NLP meth-ods are applied to identify linguistic forms that areoften problematic for ELLs, including, use of de-terminers and prepositions, wh-question formation,and phrasal verbs in the texts.
Meurers et alpointout that this CALL method is intended to drawlearners?
attention to specific properties of a lan-guage (Rutherford and Sharwood Smith , 1985).ELLs?
direct interaction with different linguisticforms could support them in language skills de-velopment, and content accessibility.To our knowledge, Language Muse is uniquefrom other NLP applications in that it is designedas a teacher professional development (TPD) ap-plication intended to enhance teachers?
linguisticawareness, and as a result, aid teachers in the de-velopment of language-based scaffolding to sup-port learners?
content accessibility, and languageskills development.
Key text complexity driverscannot be communicated to teachers through nu-merical aggregate readability measures which ap-pear to be the predominant approach to analysis oftext difficulty described in the literature.
Lan-guage Muse fills a critical TPD gap.
The appli-cation is an innovative resource designed to helpteachers understand the specific linguistic featuresthat may contribute to text difficulty and ELLs?inaccessibility to text content; linguistic feedbackfeatures in SYSTEM are grounded in the literatureabout ELL language demands (Section 2.1).3 Language MuseLanguage Muse is a web-based application forenhancing teachers?
linguistic awareness and sup-porting the development of language-based in-struction for ELLs.
It uses NLP methods toprovide explicit linguistic feedback that is ground-ed in the literature discussing ELL language de-mands and needs (Section 2.1).We will discuss (a) the system?s specific lessonplanning components, and (b) a text explorationtool that provides automated linguistic feedback.The lesson planning component has three mod-ules that support the creation of lesson plans, andrelated activities and assessments.
To create a les-son plan, teachers complete a lesson plan template(provided by the system) with five sections com-monly found in lesson plans: (a) standards andobjectives, (b) formative and summative assess-ments, (c) engaging student interest/connecting tostudent background  knowledge, (d) modeling andguided practice, and (e) independent practice.Teachers use system functionality to link specifictexts to a lesson plan.
Texts have typically beenanalyzed, first, using the feedback tool.
Feedbackis then used to inform lesson plan development.Activities and assessments may also be created fora specific lesson plan and will also be linked to theplan.
Teachers are instructed to use linguisticfeedback from the tool to develop language-focused activities and assessments that can be usedto    support the language objectives proposed inthe lesson plan.
The Text Explorer & Adapter(TEA-Tool) feedback module uses NLP methodsfor automatic summarization (Marcu, 1999); Eng-lish-to-Spanish machine translation (SDL n.d.);and, linguistic feedback.
A text4, or a webpagewith the relevant text is uploaded, or accessed,respectively, into the TEA-Tool module.
Thesummarization capability may be used to reducethe amount of text that learners are exposed to re-duce cognitive load.
The machine translation ca-pability can be used to offer native languagesupport to learners with little English proficiency.The primary focus in this section, however, willcenter around the linguistic feedback that supportsthe core goal of building teachers?
awareness ofspecific linguistic features in texts.
The linguisticfeedback includes specific information about vo-cabulary, phrasal and sentence complexity, anddiscourse relations.
For vocabulary5, categories offeedback include: academic words, cognates, col-locations and figurative words and terms, cultural4 Microsoft Word, PDF, and Plain text files may be used.5 For academic words, cognates, cultural references, andhomonyms, customized word lists are used.
No NLP is usedin these cases.4references, morphological analysis, homonyms(e.g., their, there, and they?re), key content words,and similes6.
For phrasal and sentential complexi-ty, complex verb and noun phrases, sentences withone or more dependent clauses, and passive sen-tences.
For discourse, cause-effect, compare-contrast, evidence and details, opinion, persuasion,and summary relations.The remainder of this section describes featuresin the TEA-Tool module that use NLP to generatelinguistic feedback.
Providing individual evalua-tion descriptions for each NLP feature is beyondthe scope of this paper7, intended to focus on userstudy outcomes associated with Language Museuse (Section 4).The specific vocabulary (lexical) features thatuse NLP methods or resources include these op-tions8: basic and challenge synonyms, complex andirregular word forms, variant word forms, andmultiple word expressions.
As discussed earlier,unfamiliar vocabulary is recognized as a big con-tributor to text inaccessibility.
The Basic Synonymand Challenge Synonym features support the vo-cabulary comprehension and vocabulary buildingaspects, respectively.
To generate the greatestbreadth of synonyms, the tool uses a distributionalthesaurus (Lin, 1998), WordNet (Miller, 1995) anda paraphrase generation tool (Dorr and Madnani,to appear).
Previous research has evaluated usingthese combined resources with relevant constraintsto prevent too many false positives (Burstein andPedersen, 2010).
An additional slider feature al-lows users to adjust the number of words forwhich the tool will return synonyms for existingwords in the text.
Outputs are based on word fre-quency.
Frequencies are determined using a stand-ard frequency index (Breland, Jones, and Jenkins,1994).
If users want synonyms for a larger numberof words across a broader frequency range thatincludes lower (more rare words) and higher(more common words) frequency words, then theymove the slider further to the right.
To retrievesynonyms for fewer and rarer words, the slider ismoved to the left.
For all words in the text that arewithin the range of word frequencies at the partic-ular point on the slider, the tool returns synonyms.If users select Basic Synonyms, the tool returns all6 This new feature was not available during the pilot study.7 For details, see Burstein, Sabatini, Shore, Moulder,Holtzman & Pedersen (2012).8 These reflect the feature names in TEA-Tool.words with equivalent or higher frequencies thanthe word in the text.
In theory, these words shouldbe more common words that support basic com-prehension.
If users select Challenge Synonyms,then the tool returns all words with equivalent orlower frequencies than the word in the text.
In thiscase, the teacher might want to work on vocabu-lary building skills to help the learner with newvocabulary.
If the user  selects both the Basic Syn-onyms and Challenge Synonyms features, then thetool will output the  full list of basic (more famil-iar), and challenge (less familiar) synonyms forwords in the text.
The teacher can use these syno-nyms to modify the text directly, or to developinstructional activities to support word learning.The Complex and Irregular Word Forms and Var-iant Word Forms feature offers feedback related tomorphological form.
A morphological analyzeroriginally evaluated for an automated short-answerscoring system (Leacock & Chodorow, 2003) isused.
This analyzer handles derivational and in-flectional morphology.
Feedback can be used forinstructional scaffolding that includes discussionand activities related to morphological structure isan effective method to build ELLs?
vocabulary.There are two features that identify words withmorphological complexity, specifically, wordswith prefixes or suffixes: (1) Complex and Irregu-lar Word Forms and (2) Variant Word Forms.
For(1), the morphological analyzer identifies wordsthat are morphologically complex.
A rollover isavailable for these words.
Users can place theircursor over the highlighted word, and the wordstem is shown (e.g., lost ?
stem: lose).
For (2), thesystem underlines words with the same stem thathave different parts of speech, such as poles andpolar.
Teachers can build instruction related to thiskind of morphological variation and teach studentsabout variation and relationships to parts ofspeech.Multiple word expressions (MWE) may includeidioms (e.g., body and soul), phrasal verbs (e.g.,reach into), and MWEs that are not necessarilyidiomatic, but typically appear together (colloca-tions) to express a single meaningful concept (e.g.,heart disease).
All of these MWE types may beunfamiliar terms to ELLs, and so they may inter-fere with content comprehension.
Teachers can getfeedback identifying MWEs to design relevantscaffolding for a text.
To identify MWEs, two re-sources are used.
The WordNet 3.0 compounds5list of approximately 65,000 collocational terms isused in combination with a collocation tool thatwas designed to identify collocations in test-takeressays (Futagi, Deane, Chodorow, & Tetreault,2008).
Some terms in the WordNet list are com-plementary to what is found by the collocationtool.
We have found that both outputs are useful.Futagi et als collocation tool identifies colloca-tions in a text that occur in seven syntactic struc-tures that are the most common structures forcollocations in English based on The BBI Combi-natory Dictionary of English (Benson, Benson, &Ilson, 1997).
For instance, these include Noun ofNoun (e.g., swarm of bees), and Adjective + Noun(e.g., strong tea), and Noun + Noun (e.g., housearrest).
See Futagi et al(2008) for further details.Complex phrasal or sentential features can in-troduce potential difficulty in a text.
A rule-basedNLP module is used to identify all of these fea-tures using a shallow parser that had been previ-ously evaluated for prepositional phrase and nounphrase detection (Leacock & Chodorow, 2003).The module to identify passive sentence construc-tion had been previously evaluated for commercialuse (Burstein, Chodorow, & Leacock, 2004).
Thefollowing feedback features can be selected: LongPrepositional Phrases, which identifies sequencesof two or more consecutive prepositional phrases(e.g., He moved the dishes from the table to thesink in the kitchen.
); Complex Noun Phrases,which shows noun compounds composed of twoor more nouns (e.g., emergency managementagency) and noun phrases (e.g., shark-infested wa-ters); Passives, which indicate passive sentenceconstructions (e.g., The book was bought by theboy.
); 1+Clauses, which highlights sentences withat least one dependent clause (e.g., The newspaperindicated that there are no weather advisories.
);and Complex Verbs, which identifies verbs withmultiple verbal constituents (e.g., would havegone, will be leaving, had not eaten).With regard to discourse transition features,discourse-relevant cue words and terms arehighlighted when the following discourse transi-tions features are identified, including: Evidence& Details, Compare-Contrast, Summary, Opinion,Persuasion, and Cause-Effect.
A discourse ana-lyzer previously evaluated for a commercial auto-mated scoring application is used (Burstein,Kukich, Wolff, Lu, Chodorow, Braden-Harder, &Harris, 1998).
The system identifies cue words andphrases in text that are being used as specific dis-course (or rhetorical) contexts.
For instance, ?be-cause?
is typically associated with a cause-effectrelation.
However, some words need to appear in aspecific syntactic construction to function as a dis-course term.
For instance, the word first functionsas an adjective modifier and not a discourse termin a phrase, e.g., ?the first piece of cake.?
Whenfirst is sentence-initial, as in, ?First, she sliced apiece of cake,?
then it is more likely to be used asa discourse marker, indicating a sequence ofevents.4 TPD PilotWe report on Language Muse use as it was inte-grated into a Stanford University TPD program forin-service9  teachers.
The site agreed to integratethe application into their coursework to supportcoursework instruction, and instructional goals.This section describes a pilot study and outcomeswith in-service teachers enrolled in the program.4.1 Study Design4.1.1 Site DescriptionStanford University?s courses are offered entirelyonline to teachers as part of a professional devel-opment program that awards the California StateCross-Cultural Language and Academic Devel-opment (CLAD) certificate through its CaliforniaTeachers of English Learners (CTEL) certificationprocess.
By state law, all California teachers ofELLs must obtain a CLAD/CTEL or equivalentcertification.4.1.2 Teacher ParticipantsResponses to a background survey administered toteachers indicated a range of teaching experiencefrom less than a year of teaching experience to asmuch as 37 years of teaching experience.
Teach-ers taught across a broad range of content areas,including Art, Computers, Health, Language Arts,Math, Music, Physical Education, Science, andSocial Studies, and grade levels from Kindergartenthrough 12th grade.9 This refers to teachers who have teaching credentials, andcan be employed as a classroom teachers.64.1.3 Pilot Instructional Activities10,After responding to the background survey, andthe two pre-tests (Section 4.1.4), teachers com-pleted the following TPD activities before movingon to post-tests (Section 4.1.4.)
First, teachers readan article written by a teacher training expert onthe team.
The article describes best practices fordeveloping language-based scaffolding for ELLs.The article also offers strategy descriptions as tohow to use Language Muse to complete the lessonplan assignment (Section 4.1.4), in particular.Teachers then viewed three instructional videosthat provided instruction about how to use the tool.Videos were created by a research team member,and included additional instruction about scaffold-ing strategies.
Finally, teachers completed twopractice activities with Language Muse whichgave them an opportunity to use the different toolmodules (TEA-Tool and lesson planning) beforedeveloping the final lesson plan assignment.4.1.4 Measurement Instruments11Teachers completed two surveys, one pre-survey,responding to questions about their professionalbackground and school context, and a second post-survey responding to questions related to percep-tions about Language Muse use.
To evaluateteacher knowledge gains, pre- and post-test in-struments were developed by the project team, andincluded: (a) a multiple-choice (MC) test thatevaluated teachers?
knowledge of linguistic struc-tures at the Vocabulary, Sentence, and Discourselevels, and (b) a constructed- response12 (CR) test tmeasured teachers?
ability to identify linguisticfeatures in a text13 that were likely to interfere withcontent comprehension,  and to suggest language-based instructional scaffolding to support compre-hension.
The pretests were administered prior toexposure to Language Muse (through the instruc-tional activities (Section 4.1.3)), and the posttest10 Instructional activities are available on the Language Musehomepage.
Teachers save all of their work in Language Museso it can be viewed by course instructors and the researchteam, and accessed by users.11 For measurement instruments details, see Burstein et al(2012).12 Constructed-response tasks require extended written re-sponses.13 An 300-word, 8th grade Social Studies text about U.S. colo-nization was used.after exposure.
The same test was administered atpre- and post-.14 The CR task was scored by twohuman raters on a 6-point scale (0 to 5, where5=highest quality response).
Inter-rater reliabili-ties15 were 0.72 for Vocabulary; 0.75 for Sentenc-es; and 0.71 for Discourse CR items.
At post-testonly, teachers developed a lesson plan using thelesson planning and TEA-Tool16 modules in Lan-guage Muse.
This occurred after teachers hadcompleted the instructional activities included aspart of Language Muse integration in the Stanfordprogram.
Lesson plans were evaluated by two hu-man raters using two distinct rubrics: a) quality ofLanguage Skill objectives or b) ELL-specific Skillsobjectives, i.e., unique challenges to ELLs such as,idioms or cultural references.
Inter-rater reliabili-ties were 0.61 and 0.71 respectively.
In addition,raters reviewed the linguistic feedback featuresthat teachers had used to explore the lesson plantext, using TEA-Tool.
The raters then examinedthe lesson plan and recorded the number of fea-tures explored that ended up informing the lessonplan.
Inter-rater reliabilities were 0.69.4.2 Study ResultsPre-Posttests, MC and CR.
Analyses were con-ducted for 107 teacher participants for pre- andpost-MC; 103 pre- and post-CR17.
Paired-samplest-test showed statistically significant (p=0.02) in-crease in the MC Discourse score from pre-test (M=13.71, SD =2.22) to post- (M=14.20, SD =2.35;(p=0.02) increase in CR Vocabulary pre (M=2.79,SD=0.88) to post- (M=2.99, SD=0.86); in the CRSentences score (p=0.02) from pre- (M=1.51,SD=1.23) to post- (M=1.91, SD=1.24); in the CRTotal score (p=0.00) pre- (M=5.96, SD=2.35) topost- (M=6.76, SD=2.08).
There were no statisti-cally significant increases in the MC Vocabulary,Sentences, and Total scores, nor CR Discourse.Lesson Plans.
Of the 112 teachers who com-pleted the Lesson Plan assignment, a significant14 There was a lapse of approximately 8 weeks between thepre- and the post-test.15 Inter-rater reliabilities in this study reflect Pearson correla-tions.16 The TEA-Tool module is used to explore the linguisticfeatures in the text; feedback features are then used to informlesson plan development with regard to the creation of lan-guage-based scaffolding.17 Analyses are reported only for participants who respondedto the pre- and post-.7correlation of 0.205 was found between the Lan-guage Skills Score and the number of feedbackfeatures used to inform the lesson plan.5 Discussion and ConclusionsThis paper discusses how Language Muse, anNLP-driven TPD application, supported K-12teachers in understanding linguistic features in textthat may be obstacles to content understandingduring reading.
Through the development ofteachers?
linguistic awareness, our original hy-pothesis was that teachers would become moreknowledgeable about linguistic structures, and inturn, this would support them in the practice ofcreating lesson plans with greater coverage of textlanguage and language objectives that would facil-itate students?
text and content understanding.Study outcomes indicated that the teacher pro-fessional development package can be successful-ly implemented in the context of in-service, post-secondary course work.
Through a study with aTPD program at Stanford University, results of thepre-post assessments administered in the studyindicated at statistically-significant levels thatteachers did improve their linguistic knowledgeabout vocabulary, sentences relations, and dis-course relations, and that they also demonstratedand increased ability to offer language-based scaf-folding strategies as evidenced by an gains pre-post total score on the CR.
In the context of lessonplan development, as a secondary post-test evalua-tion, teachers who productively used the linguisticfeedback to inform their lesson plans designedhigher-quality plans (i.e., addressed language ob-jectives that target development of new languageskills), than those who did not.The Language Muse TPD package is now beingevaluated with nine middle-school teachers withhigh populations of ELLs in California, New Jer-sey, and Texas.
After completion of the TPD,teachers will develop lesson units using LanguageMuse, and administer the lessons in their class-rooms.
Pre- and post-tests will be administered tostudents to evaluate the effectiveness of the lessonplans vis-?-vis language-based instruction.AcknowledgmentsResearch presented in this paper was supported bythe Institute of Education Science, U.S. Depart-ment of Education, Award No.
R305A100105.Any opinions, findings, and conclusions or rec-ommendations are those of the authors and do notnecessarily reflect the IES?s views.
We are grate-ful to Steven Holtzman and Jennifer Minsky forstatistical analysis support.
We would like to thankDr.
Kenji Hakuta for supporting this work throughhis TPD program at Stanford University.ReferencesAdger, C. T., Snow, C., & Christian D. (2002).
Whatteachers need to know about language.
Washington,DC: Center for Applied Linguistics.August, D. (2003).
Supporting the development of Eng-lish literacy in English language learners: Key issuesand promising practices (Report No.
61).
Baltimore,MD: Johns  Hopkins University Center for Re-search on the Education of Students Placed at Risk.Barzilay, Regina and Mirella Lapata (2008).
?ModelingLocal Coherence: An Entity-Based Approach.?
Com-putational Linguistics, 43(1): 1-34.Beck, I. L., McKeown, M. G., & Kucan, L. (2008).Creating robust vocabulary: Frequently asked ques-tions and extended examples.
New York, NY: Guil-ford Press.Benson, M., Benson, E., & Ilson, R.
(Eds.).
(1997).The BBI Combinatory Dictionary of English: AGuide to Word Combinations.
Amsterdam & Phila-delphia: John Benjamins Publishing Company.Berninger, V., Abbot, R., Nagy, W., & Carlisle, J.(2009).
Growth in phonological, orthographic, andmorphological awareness in grades 1-6.
Journal ofPsycholinguistic Research, 39, 141-163.Breland, H.  Jones, R., and  Jenkins, L (1994).
The col-lege board vocabulary study.
Technical Report Col-legeBurstein, J., Sabatini, J., & Shore, J.
(in press).
InRuslan Mitkov (Ed.
), Developing NLP Applicationsfor Educational Problem Spaces, Oxford Handbookof Computational Linguistics.
New York: OxfordUniversity Press.Burstein, J., Shore, J., Sabatini, J., Moulder, B.,Holtzman, S., & Pedersen, T. (2012).
The LanguageMuse system: Linguistically focused instructional au-thoring ETS RR-12-21.
Princeton, NJ: ETS.Burstein, J., and Pedersen, T. (2010).
Towards Improv-ing Synonym Options in a Text Modification Appli-cation.
University of Minnesota SupercomputingInstitute Research Report Series, UMSI 2010/165,November 2010.Burstein, J., Chodorow, M., and Leacock, C. (2004).Automated Essay Evaluation: The Criterion OnlineService, AI Magazine, 25(3), 27-36.Burstein, J., Kukich, K., Wolff, S., Lu, C.,  Chodorow,8M., Braden-Harder, L., and Harris, M. D.  (1998).Automated Scoring Using A Hybrid Feature Identifi-cation Technique.
In the Proceedings of the AnnualMeeting of the Association of Computational Lin-guistics, August, 1998.
Montreal, Canada.Calder?n, M. (2007).
Teaching reading to English lan-guage learners, grades 6-12: A framework for im-proving achievement in the content areas.
ThousandOaks, CA: Corwin Press.Calder?n, M., August, D., Slavin, R., Cheung, A.,Dur?n, D., & Madden, N. (2005).
Bringing words tolife in classrooms with English language learners.
InA.
Hiebert & M. Kamil (Eds.
), Research and devel-opment on vocabulary.
Mahwah, NJ: Lawrence Erl-baum Associates.Carlo, M. S., August, D., McLaughlin, B., Snow, C. E.,Dressler, C., Lippman, D. N., & White, C. E. (2004).Closing the gap: Addressing the vocabulary needs ofEnglish language learners in bilingual and main-stream classrooms.
Reading Research Quarterly, 39,188-215.Coleman, D., & Pimentel, S. (2011a).
Publishers?
crite-ria for the Common Core State Standards in EnglishLanguage Arts and Literacy, grades 3-12.
Washing-ton, DC: National Governors Association Center forBest Practices and Council of Chief State School Of-ficers.Collins-Thompson, Kevyn and Jamie Callan (2004).
?ALanguage Modeling Approach to Predicting ReadingDifficulty.?
In Proceedings of the Human LanguageTechnology Conference of the North American Chap-ter of the Association for Computational Linguistics.Boston, MA: Association for Computational Linguis-tics, 193-200.Darling-Hammond, L. (2000).
Teacher quality and stu-dent achievement: A review of state policy evidence.Education Policy Analysis Archives, 8.Flesch, R.. (1948).
A new readability yardstick.Journal of Applied Psychology, 32, 221-233.Flinspach, S. L., Scott, J.
A., Samway, K. D., & Miller,T.
(2008, March).
Developing cognate awareness toenhance literacy: Importante y necesario.
Paper pre-sented at the Annual Meeting of the American Edu-cational Research Association, New York, NY..Francis, D., August, D. Goldenberg, C., & Shanahan, T.(2004).
Developing literacy skills in English lan-guage learners: Key issues and promising practices.Retrieved June 11, 2007, from:www.cal.org/natl-lit-panel/reports/Executive_Summary.pdfFutagi, Y., Deane, P., Chodorow, M., & Tetreault, J.(2008).
A Computational Approach to Detecting Col-location Errors in the Writing of Non-native Speakersof English, Computer Assisted Language Learning,Vol.
21, pp.
353?367.G?ndara, P., Maxwell-Jolly, J., & Driscoll, A.
(2005).Listening to teachers of English language learners: Asurvey of California teachers?
challenges, experienc-es, and professional development needs.
Sacramento,CA: The Regents of the University of California.
Re-trieved fromhttp://www.cftl.org/documents/2005/listeningforweb.pdf.Goldenberg, C. (2008).
Teaching English languagelearners: What the research does?and does not?say.
American Educator, 32, 8-21.Goldman, S. R., & Rakestraw Jr., J.
A.
(2000).
Struc-tural aspects of constructing meaning from text.
InM.
L. Kamil, P. B. Mosenthal, P. D. Pearson, & R.Barr (Eds.
), Handbook of reading research (Vol.
III,pp.
311-335).
Mahwah, NJ: Lawrence Erlbaum As-sociates.Graesser, Arthur C., Danielle S. McNamara, and JonnaM.
Kulikowich (2011).
?Coh-Metrix: Providing Mul-tilevel Analyses of Text Characteristics.?
EducationalResearcher, 40(5): 223-234.Green, C., Foote, M., Walker, C., & Shuman, C.(2010).
From questions to answers: Education facultymembers learn about English learners.
In S. Szabo,M.
B. Sampson, M. M. Foote, & F. Falk-Ross (Eds.
),Mentoring literacy professionals: Continuing thespirit of CRA/ALER after 50 years (pp.
113-125).Commerce, TX: Texas A&M University Press.Heilman, Michael, Lee Zhao, Juan Pinto, and MaxineEskenazi (2008).
?Retrieval of Reading Materials forVocabulary and Reading Practice.?
In Proceedings ofthe Third Workshop on Innovative Use of NLP forBuilding Educational Applications.
Columbus, OH:Association for Computational Linguistics, 80-88.Kieffer, M. J.
& Lesaux, N. K. (2008).
The role of deri-vational morphology in the reading comprehension ofSpanish-speaking English language learners.
Readingand Writing, 21, 783-804.Kintsch, W. (1998).
Comprehension: A paradigm forcomprehension.
Cambridge, UK: Cambridge Univer-sity Press.Leacock, C.  & Chodorow, M.  (2003).
C-rater: Scoringof Short-Answer Questions.
Computers and the Hu-manities, Vol.
37, pp.
389?405.Lesaux, N. K., Kieffer, M. J., Faller, S. E., & Kelley, J.G.
(2010).
The effectiveness and ease of implementa-tion of an academic vocabulary intervention for lin-guistically diverse students in urban middle schools.Reading Research Quarterly, 45, 196-228.Lin, Dekang (1998).
?Automatic Retrieval and Cluster-ing of Similar Words.?
In ?Proceedings of the 17thInternational Conference on Computational Linguis-tics and the 36th Annual Meeting of the Associationfor Computational Linguistics.
Montreal, Canada:768-774.Madnani, Nitin and Bonnie J. Dorr (in press).
?Generat-ing Targeted Paraphrases for Improved Translation.
?9ACM Transactions on Intelligent Language Musesand Technology: Special Issue on Paraphrasing.Marcu, Daniel (1999).
?Discourse Trees Are Good In-dicators of Importance in Text.
In Advances in Auto-matic Text Summarization, eds.
Inderjeet Mani andMark T. Maybury.
Cambridge, MA: MIT Press, 123-136.Meurers, W. Detmar, Ramon Ziai, Luiz Amaral, Adri-ane Boyd, Aleksandar Dimitrov, Vanessa Metcalf,and Niels Ott (2010).
?Enhancing Authentic WebPages for Language Learners.?
In Proceedings of theNAACL HLT 2010 Fifth International Workshop onInnovative Use of NLP for Building Educational Ap-plications, eds.
Joel Tetreault, Jill Burstein, andClaudia Leacock.
Los Angeles, CA: Association forComputational Linguistics, 10-18.Meyer, B. J. F. (2003).
Text coherence and readability.Topics in Language Disorders, 23, 204-221.Mihalcea, Rada, Ravi Sinha, and Diana McCarthy(2010).
?SemEval-2010 Task 2: Cross-Lingual Lexi-cal Substitution.?
In Proceedings of SemEval-2010:Fifth International Workshop on Semantic Evalua-tions.
Uppsala, Sweden: Association for Computa-tional Linguistics, 9-14.Miller, George A.
(1990).
?An On-line Lexical Data-base.?
International Journal of Lexicography 3(4):235-312.Miltsakaki, Eleni (2009).
?Matching Readers?
Prefer-ences and Reading Skills with Appropriate WebTexts.?
In Proceedings of the European Associationfor Computational Linguistics.
Athens, Greece: As-sociation for Computational Linguistics, 49-52.Nagy, W., Beringer, V., & Abbott, R. (2006).
Contribu-tions of morphology beyond phonology to literacyoutcomes of upper elementary and middle schoolstudents.
Journal of Educational Psychology, 98,134-147.National Clearinghouse for English Language Acquisi-tion (2011).
The growing numbers of English learnerstudents.
Washington, DC: Author.
Retrieved fromhttp://www.ncela.gwu.edu/files/uploads/9/growingLEP_0809.pdf.National Governors Association Center for Best Prac-tices and Council of Chief State School Officers(2010).
Common Core State Standards for Englishlanguage Arts & Literacy in History/Social Studies,Science, and Technical Subjects.
Appendix A: Re-search supporting key elements of the Standards.Washington, DC: Author.Nelson, Jessica, Charles Perfetti, David Liben, andMeredith Liben (2012).
Measures of Text Difficulty:Testing Their Predictive Value for Grade Levels andStudent Performance.
Washington, DC: The Councilof Chief State School Officers.
Retrieved fromhttp://www.ccsso.org/Documents/2012/Measures%20ofText%20Difficulty_final.2012.pdf.Pappamihiel, N. E., Lake, V., & Rice, D. (2005).Adapting a Social Studies lesson to include Englishlanguage learners.
Social Studies and the YoungLearner, 17, 4-7.Peske, H. G., & Haycock, K. (2006).
Teaching inequal-ity: How poor and minority students areshortchanged on teacher quality.
Washington, DC:The Education Trust.
Retrieved fromhttp://www.edtrust.org/sites/edtrust.org/files/publications/files/TQReportJune2006.pdf.Pitler, Emily  and Ani Nenkova (2008).
?RevisitingReadability: A Unified Framework for PredictingText Quality.?
In Proceedings of the 2008 Confer-ence on Empirical Methods in Natural LanguageProcessing.
Honolulu, HI: Association for Computa-tional Linguistics, 186-195.Proctor, C. P., Dalton, D., Uccelli, P., Biancarosa, G.,Mo, E., Snow, C. E., & Neugebauer, S. (2011).
Im-proving comprehension online (ICON): Effects ofdeep vocabulary instruction with bilingual and mono-lingual fifth graders.
Reading and Writing: An Inter-disciplinary Journal, 24, 517-544.Proctor, C. P., Dalton, B., & Grisham, D. (2007).
Scaf-folding English language learners and strugglingreaders in a multimedia hypertext environment withembedded strategy instruction and vocabulary sup-port.
Journal of Literacy Research, 39, 71-93.Rivera, M. O., Moughamian, A. C., Lesaux, N. K., &Francis, D. J.
(2008).
Language and reading inter-ventions for English language learners and Englishlanguage learners with disabilities.
Portsmouth, NJ:Research Corporation, Center on Instruction.Rutherford William E. and Michael Sharwood Smith(1985).
?Consciousness-Raising and UniversalGrammar.?
Applied Linguistics 6(3): 274-282.Schwarm, Sarah E.  and Mari Ostendorf (2005).
?Read-ing Level Assessment Using Support Vector Ma-chines and Statistical Language Models.?
InProceedings of the Annual Meeting of the Associationfor Computational Linguistics.
Ann Arbor, MI: As-sociation for Computational Linguistics, 523-530.Schleppegrell, M. J.
(2007).
The linguistic challengesof mathematics teaching and learning: A research re-view.
Reading and Writing Quarterly, 23, 139-159.Schleppegrell, M. J., & de Oliveira, L. C. (2006).
Anintegrated language and content approach for historyteachers.
Journal of English for Academic Purposes,5, 254-268.SDL.
(n.d.).
Automated translation.
Retrieved fromhttp://www.sdl.com/en/languagetechnology/products/automated-translation/Walqui, A., & Heritage, M. (2012, January).
Instructionfor diverse groups of ELLs.
Paper presented at theUnderstanding Language Conference, Stanford, CA.10
