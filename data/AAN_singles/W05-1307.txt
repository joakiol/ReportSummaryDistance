Proceedings of the ACL-ISMB Workshop on Linking Biological Literature, Ontologies and Databases: MiningBiological Semantics, pages 46?53, Detroit, June 2005. c?2005 Association for Computational LinguisticsUsing Biomedical Literature Mining to Consolidate the Set of KnownHuman Protein?Protein InteractionsArun Ramani, Edward MarcotteInstitute for Cellular and Molecular BiologyUniversity of Texas at Austin1 University Station A4800Austin, TX 78712arun@icmb.utexas.edumarcotte@icmb.utexas.eduRazvan Bunescu, Raymond MooneyDepartment of Computer SciencesUniversity of Texas at Austin1 University Station C0500Austin, TX 78712razvan@cs.utexas.edumooney@cs.utexas.eduAbstractThis paper presents the results of a large-scale effort to construct a comprehensivedatabase of known human protein inter-actions by combining and linking knowninteractions from existing databases andthen adding to them by automatically min-ing additional interactions from 750,000Medline abstracts.
The end result is anetwork of 31,609 interactions amongst7,748 proteins.
The text mining sys-tem first identifies protein names in thetext using a trained Conditional RandomField (CRF) and then identifies interac-tions through a filtered co-citation anal-ysis.
We also report two new strategiesfor mining interactions, either by findingexplicit statements of interactions in thetext using learned pattern-based rules ora Support-Vector Machine using a stringkernel.
Using information in existing on-tologies, the automatically extracted datais shown to be of equivalent accuracy tomanually curated data sets.1 IntroductionProteins are often considered in terms of their net-works of interactions, a view that has spurred con-siderable effort in mapping large-scale protein in-teraction networks.
Thus far, the most completeprotein networks are measured for yeast and de-rive from the synthesis of varied large scale experi-mental interaction data and in-silico interaction pre-dictions (summarized in (von Mering et al, 2002;Lee et al, 2004; Jansen et al, 2003)).
Unlike thecase of yeast, only minimal progress has been madewith respect to the human proteome.
While somemoderate-scale interaction maps have been created,such as for the purified TNFa/NFKB protein com-plex (Bouwmeester et al, 2004) and the proteins in-volved in the human Smad signaling pathway (Col-land et al, 2004), the bulk of known human pro-tein interaction data derives from individual, small-scale experiments reported in Medline.
Many ofthese interactions have been collected in the Reac-tome (Joshi-Tope et al, 2005), BIND (Bader et al,2003), DIP (Xenarios et al, 2002), and HPRD (Periet al, 2004) databases, with Reactome contributing11,000 interactions that have been manually enteredfrom articles focusing on interactions in core cellularpathways, and HPRD contributing a set of 12,000interactions recovered by manual curation of Med-line articles using teams of readers.
Additional inter-actions have been transferred from other organismsbased on orthology (Lehner and Fraser, 2004).A comparison of these existing interaction datasets is enlightening.
Although the interactions fromthese data sets are in principle derived from the samesource (Medline), the sets are quite disjoint (Fig-ure 1) implying either that the sets are biased fordifferent classes of interactions, or that the actualnumber of interactions in Medline is quite large.We suspect both reasons.
It is clear that each dataset has a different explicit focus (Reactome towardscore cellular machinery, HPRD towards disease-linked genes, and DIP and BIND more randomly46distributed).
Due to these biases, it is likely thatmany interactions from Medline are still excludedfrom these data sets.
The maximal overlap betweeninteraction data sets is seen for BIND: 25% of theseinteractions are also in HPRD or Reactome; only 1%of Reactome interactions are in HPRD or BIND.Figure 1: Overlap diagram for known datasets.Medline now has records from more than 4,800journals accounting for around 15 million articles.These citations contain thousands of experimentallyrecorded protein interactions, and even a cursory in-vestigation of Medline reveals human protein inter-actions not present in the current databases.
How-ever, retrieving these data manually is made diffi-cult by the large number of articles, all lacking for-mal structure.
Automated extraction of informa-tion would be preferable, and therefore, mining datafrom Medline abstracts is a growing field (Jenssenet al, 2001; Rzhetsky et al, 2004; Liu and Wong,2003; Hirschman et al, 2002).In this paper, we describe a framework forautomatic extraction of protein interactions frombiomedical literature.
We focus in particular on thedifficult and important problem of identifying inter-actions concerning human proteins.
We describe asystem for first accurately identifying the names ofhuman proteins in the documents, then on identify-ing pairs of interacting human proteins, and demon-strate that the extracted protein interactions are com-parable to those extracted manually.
In the pro-cess, we consolidate the existing set of publically-available human protein interactions into a networkof 31,609 interactions between 7,748 proteins.2 Assembling existing protein interactiondataWe previously gathered the existing human proteininteraction data sets ((Ramani et al, 2005); sum-marized in Table 1), representing the current sta-tus of the publically-available human interactome.This required unification of the interactions undera shared naming and annotation convention.
Forthis purpose, we mapped each interacting proteinto LocusLink (now EntrezGene) identification num-bers and retained only unique interactions (i.e., fortwo proteins A and B, we retain only A?B or B?A,not both).
We have chosen to omit self-interactions,A?A or B?B, for technical reasons, as their qual-ity cannot be assessed on the functional benchmarkthat we describe in Section 3.
In most cases, a smallloss of proteins occurred in the conversion betweenthe different gene identifiers (e.g., converting fromthe NCBI ?gi?
codes in BIND to LocusLink iden-tifiers).
In the case of Human Protein ReferenceDatabase (HPRD), this processing resulted in a sig-nificant reduction in the number of interactions from12,013 total interactions to 6,054 unique, non-selfinteractions, largely due to the fact that HPRD oftenrecords both A-B and B-A interactions, as well as alarge number of self interactions, and indexes genesby their common names rather than conventionaldatabase entries, often resulting in multiple entriesfor different synonyms.
An additional 9,283 (or60,000 at lower confidence) interactions are avail-able from orthologous transfer of interactions fromlarge-scale screens in other organisms (orthology-core and orthology-all) (Lehner and Fraser, 2004).3 Two benchmark tests of accuracy forinteraction dataTo measure the relative accuracy of each protein in-teraction data set, we established two benchmarksof interaction accuracy, one based on shared proteinfunction and the other based on previously knowninteractions.
First, we constructed a benchmark inwhich we tested the extent to which interaction part-ners in a data set shared annotation, a measure previ-ously shown to correlate with the accuracy of func-tional genomics data sets (von Mering et al, 2002;Lee et al, 2004; Lehner and Fraser, 2004).
Weused the functional annotations listed in the KEGG47Dataset Version Total Is (Ps) Self (A-A) Is (Ps) Unique (A-B) Is (Ps)Reactome 08/03/04 12,497 (6,257) 160 (160) 12,336 (807)BIND 08/03/04 6,212 (5,412) 549 (549) 5,663 (4,762)HPRD* 04/12/04 12,013 (4,122) 3,028 (3,028) 6,054 (2,747)Orthology (all) 03/31/04 71,497 (6,257) 373 (373) 71,124 (6,228)Orthology (core) 03/31/04 11,488 (3,918) 206 (206) 11,282 (3,863)Table 1: Is = Interactions, Ps = Proteins.
(Kanehisa et al, 2004) and Gene Ontology (Ash-burner et al, 2000) annotation databases.
Thesedatabases provide specific pathway and biologicalprocess annotations for approximately 7,500 humangenes, assigning human genes into 155 KEGG path-ways (at the lowest level of KEGG) and 1,356 GOpathways (at level 8 of the GO biological processannotation).
KEGG and GO annotations were com-bined into a single composite functional annotationset, which was then split into independent testingand training sets by randomly assigning annotatedgenes into the two categories (3,800 and 3,815 anno-tated genes respectively).
For the second benchmarkbased on known physical interactions, we assembledthe human protein interactions from Reactome andBIND, a set of 11,425 interactions between 1,710proteins.
Each benchmark therefore consists of aset of binary relations between proteins, either basedon proteins sharing annotation or physically inter-acting.
Generally speaking, we expect more accu-rate protein interaction data sets to be more enrichedin these protein pairs.
More specifically, we expecttrue physical interactions to score highly on bothtests, while non-physical or indirect associations,such as genetic associations, should score highly onthe functional, but not physical interaction, test.For both benchmarks, the scoring scheme formeasuring interaction set accuracy is in the form ofa log odds ratio of gene pairs either sharing anno-tations or physically interacting.
To evaluate a dataset, we calculate a log likelihood ratio (LLR) as:LLR = lnP (DjI)P (Dj:I)= lnP (IjD)P (:I)P (:IjD)P (I)(1)where P (DjI) and P (Dj:I) are the probabilityof observing the data D conditioned on the genessharing benchmark associations (I) and not sharingbenchmark associations (:I).
In its expanded form(obtained by applying Bayes theorem), P (IjD) andP (:IjD) are estimated using the frequencies of in-teractions observed in the given data set D betweenannotated genes sharing benchmark associations andnot sharing associations, respectively, while the pri-ors P (I) and P (:I) are estimated based on the to-tal frequencies of all benchmark genes sharing thesame associations and not sharing associations, re-spectively.
A score of zero indicates interaction part-ners in the data set being tested are no more likelythan random to belong to the same pathway or to in-teract; higher scores indicate a more accurate dataset.Among the literature-derived interactions (Reac-tome, BIND, HPRD), a total of 17,098 unique in-teractions occur in the public data sets.
Testing theexisting protein interaction data on the functionalbenchmark reveals that Reactome has the highestaccuracy (LLR = 3.8), followed by BIND (LLR =2.9), HPRD (LLR = 2.1), core orthology-inferred in-teractions (LLR = 2.1) and the non-core orthology-inferred interaction (LLR = 1.1).
The two mostaccurate data sets, Reactome and BIND, form thebasis of the protein interaction?based benchmark.Testing the remaining data sets on this benchmark(i.e., for their consistency with these accurate pro-tein interaction data sets) reveals a similar ranking inthe remaining data.
Core orthology-inferred interac-tions are the most accurate (LLR = 5.0), followed byHPRD (LLR = 3.7) and non-core orthology inferredinteractions (LLR = 3.7).4 Framework for Mining Protein?ProteinInteractionsThe extraction of interacting proteins from Medlineabstracts proceeds in two separate steps:1.
First, we automatically identify protein names48using a CRF system trained on a set of 750abstracts manually annotated for proteins (seeSection 5 for details).2.
Based on the output of the CRF tagger, we fil-ter out less confident extractions and then try todetect which pairs of the remaining extractedprotein names are interaction pairs.For the second step, we investigate two generalmethods: Use co-citation analysis to score each pair ofproteins based on the assumption that proteinsco-occurring in a large number of abstracts tendto be interacting proteins.
Out of the resultingprotein pairs we keep only those that co-occurin abstracts likely to discuss interactions, basedon a Naive Bayes classifier (see Section 6 fordetails). Given that we already have a set of 230 Med-line abstracts manually tagged for both proteinsand interactions, we can use it to train an inter-action extractor.
In Section 7 we discuss twodifferent methods for learning this interactionextractor.5 A CRF Tagger for Protein NamesThe task of identifying protein names is made diffi-cult by the fact that unlike other organisms, such asyeast or E. coli, the human genes have no standard-ized naming convention, and thus present one of thehardest sets of gene/protein names to extract.
Forexample, human proteins may be named with typ-ical English words, such as ?light?, ?map?, ?com-plement?, and ?Sonic Hedgehog?.
It is thereforenecessary that an information extraction algorithmbe specifically trained to extract gene and proteinnames accurately.We have previously described (Bunescu et al,2005) effective protein and gene name tagging us-ing a Maximum Entropy based algorithm.
Condi-tional Random Fields (CRF) (Lafferty et al, 2001)are new types of probabilistic models that preserveall the advantages of Maximum Entropy models andat the same time avoid the label bias problem by al-lowing a sequence of tagging decisions to competeagainst each other in a global probabilistic model.In both training and testing the CRF protein-nametagger, the corresponding Medline abstracts wereprocessed as follows.
Text was tokenized usingwhite-space as delimiters and treating all punctua-tion marks as separate tokens.
The text was seg-mented into sentences, and part-of-speech tags wereassigned to each token using Brill?s tagger (Brill,1995).
For each token in each sentence, a vector ofbinary features was generated using the feature tem-plates employed by the Maximum Entropy approachdescribed in (Bunescu et al, 2005).
Generally, thesefeatures make use of the words occurring before andafter the current position in the text, their POS tagsand capitalization patterns.
Each feature occurringin the training data is associated with a parameter inthe CRF model.
We used the CRF implementationfrom (McCallum, 2002).
To train the CRF?s parame-ters, we used 750 Medline abstracts manually anno-tated for protein names (Bunescu et al, 2005).
Wethen used the trained system to tag protein and genenames in the entire set of 753,459 Medline abstractsciting the word ?human?.In Figure 2 we compare the performance of theCRF tagger with that of the Maximum Entropy tag-ger from (Bunescu et al, 2005), using the sameset of features, by doing 10-fold cross-validation onYapex ?
a smaller dataset of 200 manually annotatedabstracts (Franzen et al, 2002).
Each model assignsto each extracted protein name a normalized confi-dence value.
The precision?recall curves from Fig-ure 2 are obtained by varying a threshold on the min-imum accepted confidence.
We also plot the preci-sion and recall obtained by simply matching textualphrases against entries from a protein dictionary.50607080901000  20  40  60  80  100Precision(%)Recall (%)CRFMaxEntDictFigure 2: Protein Tagging Performance.49The dictionary of human protein names wasassembled from the LocusLink and Swissprotdatabases by manually curating the gene namesand synonyms (87,723 synonyms between 18,879unique gene names) to remove genes that were re-ferred to as ?hypothetical?
or ?probable?
and also toomit entries that referred to more than one proteinidentifier.6 Co-citation Analysis and BayesianClassificationIn order to establish which interactions occurredbetween the proteins identified in the Medline ab-stracts, we used a 2-step strategy: measure co-citation of protein names, then enrich these pairs forphysical interactions using a Bayesian filter.
First,we counted the number of abstracts citing a pair ofproteins, and then calculated the probability of co-citation under a random model based on the hyper-geometric distribution (Lee et al, 2004; Jenssen etal., 2001) as:P (kjN;m; n) =nkN   nm  kNm (2)where N equals the total number of abstracts, n ofwhich cite the first protein, m cite the second pro-tein, and k cite both.Empirically, we find the co-citation probabilityhas a hyperbolic relationship with the accuracy onthe functional annotation benchmark from Section 3,with protein pairs co?cited with low random proba-bility scoring high on the benchmark.With a threshold on the estimated extraction con-fidence of 80% (as computed by the CRF model)in the protein name identification, close to 15,000interactions are extracted with the co-citation ap-proach that score comparable or better on the func-tional benchmark than the manually extracted inter-actions from HPRD, which serves to establish a min-imal threshold for our mined interactions.However, it is clear that proteins are co-cited formany reasons other than physical interactions.
Wetherefore tried to enrich specifically for physical in-teractions by applying a secondary filter.
We applieda Bayesian classifier (Marcotte et al, 2001) to mea-sure the likelihood of the abstracts citing the pro-tein pairs to discuss physical protein?protein inter-actions.
The classifier scores each of the co-citingabstracts according to the usage frequency of dis-criminating words relevant to physical protein inter-actions.
For a co-cited protein pair, we calculatedthe average score of co-citing Medline abstracts andused this to re-rank the top-scoring 15,000 co-citedprotein pairs.Interactions extracted by co-citation and filteredusing the Bayesian estimator compare favorablywith the other interaction data sets on the functionalannotation benchmark (Figure 3).
Testing the accu-racy of these extracted protein pairs on the physi-cal interaction benchmark (Figure 4) reveals that theco-cited proteins scored high by this classifier areindeed strongly enriched for physical interactions.0.511.522.533.540  10000  20000  30000  40000  50000  60000  70000LLRscore, functional benchmark# of interactions recoveredCo-citation, Bayes filterBINDReactomeHPRDOrthology (core)Orthology (core)Figure 3: Accuracy, functional benchmark22.533.544.555.560  10000  20000  30000  40000  50000  60000  70000LLRscore, physicalbenchmark# of interactions recoveredCo-citation, Bayes filterHPRDOrthology (core)Orthology (core)Figure 4: Accuracy, physical benchmarkKeeping all the interactions that score better thanHPRD, our co-citation / Bayesian classifier analy-sis yields 6,580 interactions between 3,737 proteins.By combining these interactions with the 26,280 in-teractions from the other sources, we obtained a fi-50nal set of 31,609 interactions between 7,748 humanproteins.7 Learning Interaction ExtractorsIn (Bunescu et al, 2005) we described a dataset of230 Medline abstracts manually annotated for pro-teins and their interactions.
This can be used as atraining dataset for a method that learns interactionextractors.
Such a method simply classifies a sen-tence containing two protein names as positive ornegative, where positive means that the sentence as-serts an interaction between the two proteins.
How-ever a sentence in the training data may contain morethan two proteins and more than one pair of inter-acting proteins.
In order to extract the interactingpairs, we replicate the sentences having n proteins(n  2) into Cn2sentences such that each one hasexactly two of the proteins tagged, with the rest ofthe protein tags omitted.
If the tagged proteins in-teract, then the replicated sentence is added to theset of positive sentences, otherwise it is added to theset of negative sentences.
During testing, a sentencehaving n proteins (n  2) is again replicated intoCn2sentences in a similar way.7.1 Extraction using Longest CommonSubsequences (ELCS)Blaschke et al (Blaschke and Valencia, 2001;Blaschke and Valencia, 2002) manually developedrules for extracting interacting proteins.
Each oftheir rules (or frames) is a sequence of words (orPOS tags) and two protein-name tokens.
Betweenevery two adjacent words is a number indicatingthe maximum number of intervening words allowedwhen matching the rule to a sentence.
In (Bunescuet al, 2005) we described a new method ELCS (Ex-traction using Longest Common Subsequences) thatautomatically learns such rules.
ELCS?
rule repre-sentation is similar to that in (Blaschke and Valen-cia, 2001; Blaschke and Valencia, 2002), except thatit currently does not use POS tags, but allows dis-junctions of words.
Figure 5 shows an example of arule learned by ELCS.
Words in square brackets sep-arated by ?j?
indicate disjunctive lexical constraints,i.e.
one of the given words must match the sen-tence at that position.
The numbers in parenthesesbetween adjacent constraints indicate the maximumnumber of unconstrained words allowed between thetwo (called a word gap).
The protein names are de-noted here with PROT.
A sentence matches the ruleif and only if it satisfies the word constraints in thegiven order and respects the respective word gaps.- (7) interaction (0) [between j of] (5) PROT (9) PROT (17) .Figure 5: Sample extraction rule learned by ELCS.7.2 Extraction using a Relation Kernel (ERK)Both Blaschke and ELCS do interaction extractionbased on a limited set of matching rules, where a ruleis simply a sparse (gappy) subsequence of words (orPOS tags) anchored on the two protein-name tokens.Therefore, the two methods share a common limita-tion: either through manual selection (Blaschke), oras a result of the greedy learning procedure (ELCS),they end up using only a subset of all possible an-chored sparse subsequences.
Ideally, we would wantto use all such anchored sparse subsequences as fea-tures, with weights reflecting their relative accuracy.However explicitly creating for each sentence a vec-tor with a position for each such feature is infeasi-ble, due to the high dimensionality of the featurespace.
Here we can exploit an idea used before instring kernels (Lodhi et al, 2002): computing thedot-product between two such vectors amounts tocalculating the number of common anchored sub-sequences between the two sentences.
This can bedone very efficiently by modifying the dynamic pro-gramming algorithm from (Lodhi et al, 2002) to ac-count only for anchored subsequences i.e.
sparsesubsequences which contain the two protein-nametokens.
Besides restricting the word subsequencesto be anchored on the two protein tokens, we canfurther prune down the feature space by utilizing thefollowing property of natural language statements:whenever a sentence asserts a relationship betweentwo entity mentions, it generally does this using oneof the following three patterns: [FI] Fore?Inter: words before and between thetwo entity mentions are simultaneously used toexpress the relationship.
Examples: ?interac-tion of hP1i with hP2i?, ?activation of hP1i byhP2i?.51 [I] Inter: only words between the two entitymentions are essential for asserting the rela-tionship.
Examples: ?hP1i interacts with hP2i?,?hP1i is activated by hP2i?. [IA] Inter?After: words between and after thetwo entity mentions are simultaneously usedto express the relationship.
Examples: hP1i ?hP2i complex?, ?hP1i and hP2i interact?.Another useful observation is that all these pat-terns use at most 4 words to express the relationship(not counting the two entities).
Consequently, whencomputing the relation kernel, we restrict the count-ing of common anchored subsequences only to thosehaving one of the three types described above, with amaximum word-length of 4.
This type of feature se-lection leads not only to a faster kernel computation,but also to less overfitting, which results in increasedaccuracy (we omit showing here comparative resultssupporting this claim, due to lack of space).We used this kernel in conjunction with SupportVector Machines (Vapnik, 1998) learning in or-der to find a decision hyperplane that best separatesthe positive examples from negative examples.
Wemodified the libsvm package for SVM learning byplugging in the kernel described above.7.3 Preliminary experimental resultsWe compare the following three systems on the taskof retrieving protein interactions from the dataset of230 Medline abstracts (assuming gold standard pro-teins): [Manual]: We report the performance of therule-based system of (Blaschke and Valencia,2001; Blaschke and Valencia, 2002). [ELCS]: We report the 10-fold cross-validatedresults from (Bunescu et al, 2005) as aprecision-recall graph. [ERK]: Based on the same splits as thoseused by ELCS, we compute the correspondingprecision-recall graph.The results, summarized in Figure 6, show thatthe relation kernel outperforms both ELCS and themanually written rules.
In future work, we intendto analyze the complete Medline with ERK and in-tegrate the extracted interactions into a larger com-posite set.01020304050607080901000  10  20  30  40  50  60  70  80  90  100Precision(%)Recall (%)ERKManualELCSFigure 6: PR curves for interaction extractors.8 ConclusionThrough a combination of automatic text mining andconsolidation of existing databases, we have con-structed a large database of known human proteininteractions containing 31,609 interactions amongst7,748 proteins.
By mining 753,459 human-relatedabstracts from Medline with a combination of aCRF-based protein tagger, co-citation analysis, andautomatic text classification, we extracted a set of6,580 interactions between 3,737 proteins.
By uti-lizing information in existing knowledge bases, thisautomatically extracted data was found to have anaccuracy comparable to manually developed datasets.
More details on our interaction database havebeen published in the biological literature (Ramaniet al, 2005) and it is available on the web athttp://bioinformatics.icmb.utexas.edu/idserve.
Weare currently exploring improvements to thisdatabase by more accurately identifying assertionsof interactions in the text using an SVM that exploitsa relational string kernel.9 AcknowledgementsThis work was supported by grants from the N.S.F.
(IIS-0325116, EIA-0219061), N.I.H.
(GM06779-01), Welch (F1515), and a Packard Fellowship(E.M.M.).52ReferencesM.
Ashburner, C. A.
Ball, J.
A. Blake, D. Botstein, H. Butler,J.
M. Cherry, A. P. Davis, K. Dolinski, S. S. Dwight, and J. T.et al Eppig.
2000.
Gene ontology: tool for the unificationof biology.
the gene ontology consortium.
Nature Genetics,25(1):25?29.G.
D. Bader, D. Betel, and C. W. Hogue.
2003.
Bind: thebiomolecular interaction network database.
Nucleic AcidsResearch, 31(1):248?250.C.
Blaschke and A. Valencia.
2001.
Can bibliographic pointersfor known biological data be found automatically?
proteininteractions as a case study.
Comparative and FunctionalGenomics, 2:196?206.C.
Blaschke and A. Valencia.
2002.
The frame-based moduleof the Suiseki information extraction system.
IEEE Intelli-gent Systems, 17:14?20.T.
Bouwmeester, A. Bauch, H. Ruffner, P. O. Angrand,G.
Bergamini, K. Croughton, C. Cruciat, D. Eberhard,J.
Gagneur, S. Ghidelli, and et al 2004.
A physical andfunctional map of the human tnf-alpha/nf-kappa b signaltransduction pathway.
Nature Cell Biology, 6(2):97?105.Eric Brill.
1995.
Transformation-based error-driven learningand natural language processing: A case study in part-of-speech tagging.
Computational Linguistics, 21(4):543?565.Razvan Bunescu, Ruifang Ge, Rohit J. Kate, Edward M.Marcotte, Raymond J. Mooney, Arun Kumar Ramani, andYuk Wah Wong.
2005.
Comparative experiments on learn-ing information extractors for proteins and their interactions.Artificial Intelligence in Medicine (special issue on Sum-marization and Information Extraction from Medical Doc-uments), 33(2):139?155.F.
Colland, X. Jacq, V. Trouplin, C. Mougin, C. Groizeleau,A.
Hamburger, A. Meil, J. Wojcik, P. Legrain, and J. M.Gauthier.
2004.
Functional proteomics mapping of a humansignaling pathway.
Genome Research, 14(7):1324?1332.K.
Franzen, G. Eriksson, F. Olsson, L. Asker, P. Liden, andJ.
Coster.
2002.
Protein names and how to find them.
Inter-national Journal of Medical Informatics, 67(1-3):49?61.L.
Hirschman, J. C. Park, J. Tsujii, L. Wong, and C. H. Wu.2002.
Accomplishments and challenges in literature datamining for biology.
Bioinformatics, 18(12):1553?1561.R.
Jansen, H. Yu, D. Greenbaum, Y. Kluger, N. J. Krogan,S.
Chung, A. Emili, M. Snyder, J. F. Greenblatt, and M. Ger-stein.
2003.
A bayesian networks approach for predict-ing protein-protein interactions from genomic data.
Science,302(5644):449?453.T.
K. Jenssen, A. Laegreid, J. Komorowski, and E. Hovig.
2001.A literature network of human genes for high-throughputanalysis of gene expression.
Nature Genetics, 28(1):21?28.G.
Joshi-Tope, M. Gillespie, I. Vastrik, P. D?Eustachio,E.
Schmidt, B. de Bono, B. Jassal, G. R. Gopinath, G. R.Wu, L. Matthews, and et al 2005.
Reactome: a knowl-edgebase of biological pathways.
Nucleic Acids Research,33 Database Issue:D428?432.M.
Kanehisa, S. Goto, S. Kawashima, Y. Okuno, and M. Hat-tori.
2004.
The kegg resource for deciphering the genome.Nucleic Acids Research, 32 Database issue:D277?280.John Lafferty, Andrew McCallum, and Fernando Pereira.
2001.Conditional random fields: Probabilistic models for seg-menting and labeling sequence data.
In Proceedings of18th International Conference on Machine Learning (ICML-2001), pages 282?289, Williamstown, MA.I.
Lee, S. V. Date, A. T. Adai, and E. M. Marcotte.
2004.
Aprobabilistic functional network of yeast genes.
Science,306(5701):1555?1558.B.
Lehner and A. G. Fraser.
2004.
A first-draft human protein-interaction map.
Genome Biology, 5(9):R63.H.
Liu and L. Wong.
2003.
Data mining tools for biological se-quences.
Journal of Bioinformatics and Computational Bi-ology, 1(1):139?167.Huma Lodhi, Craig Saunders, John Shawe-Taylor, Nello Cris-tianini, and Chris Watkins.
2002.
Text classification us-ing string kernels.
Journal of Machine Learning Research,2:419?444.E.
M. Marcotte, I. Xenarios, and D. Eisenberg.
2001.
Min-ing literature for protein-protein interactions.
Bioinformat-ics, 17(4):359?363.Andrew Kachites McCallum.
2002.
Mallet: A machine learn-ing for language toolkit.
http://mallet.cs.umass.edu.S.
Peri, J. D. Navarro, T. Z. Kristiansen, R. Amanchy, V. Suren-dranath, B. Muthusamy, T. K. Gandhi, K. N. Chandrika,N.
Deshpande, S. Suresh, and et al 2004.
Human proteinreference database as a discovery resource for proteomics.Nucleic Acids Research, 32 Database issue:D497?501.A.
K. Ramani, R. C. Bunescu, R. J. Mooney, and E. M. Mar-cotte.
2005.
Consolidating the set of know human protein-protein interactions in preparation for large-scale mapping ofthe human interactome.
Genome Biology, 6(5):r40.A.
Rzhetsky, I. Iossifov, T. Koike, M. Krauthammer, P. Kra,M.
Morris, H. Yu, P. A. Duboue, W. Weng, W. J. Wilbur,V.
Hatzivassiloglou, and C. Friedman.
2004.
Geneways: asystem for extracting, analyzing, visualizing, and integratingmolecular pathway data.
Journal of Biomedical Informatics,37(1):43?53.Vladimir N. Vapnik.
1998.
Statistical Learning Theory.
JohnWiley & Sons.C.
von Mering, R. Krause, B. Snel, M. Cornell, S. G. Oliver,S.
Fields, and P. Bork.
2002.
Comparative assessment oflarge-scale data sets of protein-protein interactions.
Nature,417(6887):399?403.I.
Xenarios, L. Salwinski, X. J. Duan, P. Higney, S. M. Kim, andD.
Eisenberg.
2002.
Dip, the database of interacting pro-teins: a research tool for studying cellular networks of pro-tein interactions.
Nucleic Acids Research, 30(1):303?305.53
