Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 1054?1062,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsExploring Deterministic Constraints: From a Constrained English POSTagger to an Efficient ILP Solution to Chinese Word SegmentationQiuye Zhao Mitch MarcusDept.
of Computer & Information ScienceUniversity of Pennsylvaniaqiuye, mitch@cis.upenn.eduAbstractWe show for both English POS tagging andChinese word segmentation that with properrepresentation, large number of deterministicconstraints can be learned from training exam-ples, and these are useful in constraining prob-abilistic inference.
For tagging, learned con-straints are directly used to constrain Viterbidecoding.
For segmentation, character-basedtagging constraints can be learned with thesame templates.
However, they are better ap-plied to a word-based model, thus an integerlinear programming (ILP) formulation is pro-posed.
For both problems, the correspondingconstrained solutions have advantages in bothefficiency and accuracy.1 introductionIn recent work, interesting results are reported forapplications of integer linear programming (ILP)such as semantic role labeling (SRL) (Roth and Yih,2005), dependency parsing (Martins et al, 2009)and so on.
In an ILP formulation, ?non-local?
de-terministic constraints on output structures can benaturally incorporated, such as ?a verb cannot taketwo subject arguments?
for SRL, and the projectiv-ity constraint for dependency parsing.
In contrastto probabilistic constraints that are estimated fromtraining examples, this type of constraint is usuallyhand-written reflecting one?s linguistic knowledge.Dynamic programming techniques based onMarkov assumptions, such as Viterbi decoding, can-not handle those ?non-local?
constraints as discussedabove.
However, it is possible to constrain Viterbidecoding by ?local?
constraints, e.g.
?assign label tto word w?
for POS tagging.
This type of constraintmay come from human input solicited in interactiveinference procedure (Kristjansson et al, 2004).In this work, we explore deterministic constraintsfor two fundamental NLP problems, English POStagging and Chinese word segmentation.
We showby experiments that, with proper representation,large number of deterministic constraints can belearned automatically from training data, which canthen be used to constrain probabilistic inference.For POS tagging, the learned constraints are di-rectly used to constrain Viterbi decoding.
The cor-responding constrained tagger is 10 times faster thansearching in a raw space pruned with beam-width 5.Tagging accuracy is moderately improved as well.For Chinese word segmentation (CWS), whichcan be formulated as character tagging, analogousconstraints can be learned with the same templatesas English POS tagging.
High-quality constraintscan be learned with respect to a special tagset, how-ever, with this tagset, the best segmentation accuracyis hard to achieve.
Therefore, these character-basedconstraints are not directly used for determining pre-dictions as in English POS tagging.
We propose anILP formulation of the CWS problem.
By adopt-ing this ILP formulation, segmentation F-measureis increased from 0.968 to 0.974, as compared toViterbi decoding with the same feature set.
More-over, the learned constraints can be applied to reducethe number of possible words over a character se-quence, i.e.
to reduce the number of variables to set.This reduction of problem size immediately speedsup an ILP solver by more than 100 times.10542 English POS tagging2.1 Explore deterministic constraintsSuppose that, following (Chomsky, 1970), we dis-tinguish major lexical categories (Noun, Verb, Ad-jective and Preposition) by two binary features:+|?
N and +|?
V. Let (+N, ?V)=Noun, (?N,+V)=Verb, (+N, +V)=Adjective, and (?N,?V)=preposition.
A word occurring in between apreceding word the and a following word of alwaysbears the feature +N.
On the other hand, considerthe annotation guideline of English Treebank (Mar-cus et al, 1993) instead.
Part-of-speech (POS) tagsare used to categorize words, for example, the POStag VBG tags verbal gerunds, NNS tags nominal plu-rals, DT tags determiners and so on.
Following thisPOS representation, there are as many as 10 possi-ble POS tags that may occur in between the?of, asestimated from the WSJ corpus of Penn Treebank.2.1.1 Templates of deterministic constraintsTo explore determinacy in the distribution of POStags in Penn Treebank, we need to consider thata POS tag marks the basic syntactic category of aword as well as its morphological inflection.
A con-straint that may determine the POS category shouldreflect both the context and the morphological fea-ture of the corresponding word.The practical difficulty in representing such de-terministic constraints is that we do not have a per-fect mechanism to analyze morphological featuresof a word.
Endings or prefixes of English words donot deterministically mark their morphological in-flections.
We propose to compute the morph featureof a word as the set of all of its possible tags, i.e.all tag types that are assigned to the word in trainingdata.
Furthermore, we approximate unknown wordsin testing data by rare words in training data.
Fora word that occurs less than 5 times in the trainingcorpus, we compute its morph feature as its last twocharacters, which is also conjoined with binary fea-tures indicating whether the rare word contains dig-its, hyphens or upper-case characters respectively.See examples of morph features in Table 1.We consider bigram and trigram templates forgenerating potentially deterministic constraints.
Letwi denote the ith word relative to the current wordw0; and mi denote the morph feature of wi.
A(frequent) (set of possible tags of the word)w0=trades m0={NNS, VBZ}(rare) (the last two characters...)w0=time-shares m0={-es, HYPHEN}Table 1: Morph features of frequent words and rare wordsas computed from the WSJ Corpus of Penn Treebank.bi- w?1w0, w0w1, m?1w0, w0m1-gram w?1m0, m0w1, m?1m0, m0m1tri- w?1w0w1, m?1w0w1, w?1m0w1, m?1m0w1-gram w?1w0m1, m?1w0m1, w?1m0m1, m?1m0m1Table 2: The templates for generating potentially deter-ministic constraints of English POS tagging.bigram constraint includes one contextual word(w?1|w1) or the corresponding morph feature; anda trigram constraint includes both contextual wordsor their morph features.
Each constraint is also con-joined with w0 or m0, as described in Table 2.2.1.2 Learning of deterministic constraintsIn the above section, we explore templates forpotentially deterministic constraints that may deter-mine POS category.
With respect to a training cor-pus, if a constraint C relative to w0 ?always?
assignsa certain POS category t?
to w0 in its context, i.e.count(C?t0=t?
)count(C) > thr, and this constraint occursmore than a cutoff number, we consider it as a de-terministic constraint.
The threshold thr is a realnumber just under 1.0 and the cutoff number is em-pirically set to 5 in our experiments.2.1.3 Decoding of deterministic constraintsBy the above definition, the constraint of w?1 =the,m0 = {NNS, VBZ} andw1 = of is determinis-tic.
It determines the POS category of w0 to be NNS.There are at least two ways of decoding these con-straints during POS tagging.
Take the word tradesfor example, whose morph feature is {NNS, VBZ}.One alternative is that as long as trades occurs be-tween the-of, it is tagged with NNS.
The second al-ternative is that the tag decision is made only if alldeterministic constraints relative to this occurrenceof trades agree on the same tag.
Both ways of de-coding are purely rule-based and involve no proba-bilistic inference.
In favor of a higher precision, weadopt the latter one in our experiments.1055raw input O(nT 2) n = 23The complex financing plan in the S&L bailout law includes...constrained input O(m1T + m2T 2) m1 = 2,m2 = 1The/DT complex/?
financing/?
plan/NN in/INthe/DT S&L/?
bailout/NN law/NN includes/VBZ ...Table 3: Comparison of raw input and constrained input.2.2 Search in a constrained spaceFollowing most previous work, we consider POStagging as a sequence classification problem and de-compose the overall sequence score over the linearstructure, i.e.
t?
= argmaxt?tagGEN(w)n?i=1score(ti) wherefunction tagGEN maps input sentence w = w1...wnto the set of all tag sequences that are of length n.If a POS tagger takes raw input only, i.e.
for everyword, the number of possible tags is a constant T ,the space of tagGEN is as large as Tn.
On the otherhand, if we decode deterministic constraints first be-fore a probabilistic search, i.e.
for some words, thenumber of possible tags is reduced to 1, the searchspace is reduced to Tm, where m is the number of(unconstrained) words that are not subject to any de-terministic constraints.Viterbi algorithm is widely used for tagging, andruns in O(nT 2) when searching in an unconstrainedspace.
On the other hand, consider searching in aconstrained space.
Suppose that among the m un-constrained words, m1 of them follow a word thathas been tagged by deterministic constraints andm2 (=m-m1) of them follow another unconstrainedword.
Viterbi decoder runs in O(m1T + m2T 2)while searching in such a constrained space.
Theexample in Table 3 shows raw and constrained inputwith respect to a typical input sentence.Lookahead featuresThe score of tag predictions are usually computedin a high-dimensional feature space.
We adopt thebasic feature set used in (Ratnaparkhi, 1996) and(Collins, 2002).
Moreover, when deterministic con-straints have applied to contextual words of w0, itis also possible to include some lookahead featuretemplates, such as:t0&t1, t0&t1&t2, and t?1&t0&t1where ti represents the tag of the ith word relativeto the current word w0.
As discussed in (Shen etal., 2007), categorical information of neighbouringwords on both sides of w0 help resolve POS ambi-guity of w0.
In (Shen et al, 2007), lookahead fea-tures may be available for use during decoding sincesearching is bidirectional instead of left-to-right asin Viterbi decoding.
In this work, deterministic con-straints are decoded before the application of prob-abilistic models, therefore lookahead features aremade available during Viterbi decoding.3 Chinese Word Segmentation (CWS)3.1 Word segmentation as character taggingConsidering the ambiguity problem that a Chinesecharacter may appear in any relative position in aword and the out-of-vocabulary (OOV) problem thatit is impossible to observe all words in training data,CWS is widely formulated as a character taggingproblem (Xue, 2003).
A character-based CWS de-coder is to find the highest scoring tag sequence t?over the input character sequence c, i.e.t?
= argmaxt?tagGEN(c)n?i=1score(ti) .This is the same formulation as POS tagging.
TheViterbi algorithm is also widely used for decoding.The tag of each character represents its relativeposition in a word.
Two popular tagsets include 1)IB: where B tags the beginning of a word and Iall other positions; and 2) BMES: where B, M and Erepresent the beginning, middle and end of a multi-character word respectively, and S tags a single-character word.
For example, after decoding withBMES, 4 consecutive characters associated with thetag sequence BMME compose a word.
However, afterdecoding with IB, characters associated with BIIImay compose a word if the following tag is B or onlyform part of a word if the following tag is I. Eventhough character tagging accuracy is higher withtagset IB, tagset BMES is more popular in use sincebetter performance of the original problem CWS canbe achieved by this tagset.Character-based feature templatesWe adopt the ?non-lexical-target?
feature tem-plates in (Jiang et al, 2008a).
Let ci denote the ithcharacter relative to the current character c0 and t01056denote the tag assigned to c0.
The following tem-plates are used:ci&t0 (i=-2...2), cici+1&t0 (i=-2...1) and c?1c1&t0.Character-based deterministic constraintsWe can use the same templates as described inTable 2 to generate potentially deterministic con-straints for CWS character tagging, except that thereare no morph features computed for Chinese char-acters.
As we will show with experimental resultsin Section 5.2, useful deterministic constraints forCWS can be learned with tagset IB but not withtagset BMES.
It is interesting but not surprising to no-tice, again, that the determinacy of a problem is sen-sitive to its representation.
Since it is hard to achievethe best segmentations with tagset IB, we proposean indirect way to use these constraints in the fol-lowing section, instead of applying these constraintsas straightforwardly as in English POS tagging.3.2 Word-based word segmentationA word-based CWS decoder finds the highest scor-ing segmentation sequence w?
that is composed bythe input character sequence c, i.e.w?
= argmaxw?segGEN(c)|w|?i=1score(wi) .where function segGEN maps character sequence cto the set of all possible segmentations of c. Forexample, w = (c1..cl1)...(cn?lk+1...cn) represents asegmentation of k words and the lengths of the firstand last word are l1 and lk respectively.In early work, rule-based models find words oneby one based on heuristics such as forward maxi-mum match (Sproat et al, 1996).
Exact search ispossible with a Viterbi-style algorithm, but beam-search decoding is more popular as used in (Zhangand Clark, 2007) and (Jiang et al, 2008a).We propose an Integer Linear Programming (ILP)formulation of word segmentation, which is nat-urally viewed as a word-based model for CWS.Character-based deterministic constraints, as dis-cussed in Section 3.1, can be easily applied.3.3 ILP formulation of CWSGiven a character sequence c=c1...cn, there are s(=n(n+1)/2) possible words that are contiguous sub-sets of c, i.e.
w1, ..., ws ?
c. Our goal is to findTable 4: Comparison of raw input and constrained input.an optimal solution x = x1...xs that maximizess?i=1score(wi) ?
xi, subject to(1)?i:c?wixi = 1, ?c ?
c;(2) xi ?
{0, 1}, 1 ?
i ?
sThe boolean value of xi, as guaranteed by constraint(2), indicates whether wi is selected in the segmen-tation solution or not.
Constraint (1) requires ev-ery character to be included in exactly one selectedword, thus guarantees a proper segmentation of thewhole sequence.
This resembles the ILP formula-tion of the set cover problem, though the first con-straint is different.
Take n = 2 for example, i.e.c = c1c2, the set of possible words is {c1, c2, c1c2},i.e.
s = |x| = 3.
There are only two possible so-lutions subject to constraints (1) and (2), x = 110giving an output set {c1, c2}, or x = 001 giving anoutput set {c1c2}.The efficiency of solving this problem depends onthe number of possible words (contiguous subsets)over a character sequence, i.e.
the number of vari-ables in x.
So as to reduce |x|, we apply determin-istic constraints predicting IB tags first, which arelearned as described in Section 3.1.
Possible wordsare generated with respect to the partially taggedcharacter sequence.
A character tagged with B al-ways occurs at the beginning of a possible word.
Ta-ble 4 illustrates the constrained and raw input withrespect to a typical character sequence.3.4 Character- and word-based featuresAs studied in previous work, word-based featuretemplates usually include the word itself, sub-wordscontained in the word, contextual characters/wordsand so on.
It has been shown that combining theuse of character- and word-based features helps im-prove performance.
However, in the character tag-ging formulation, word-based features are non-local.1057To incorporate these non-local features and make thesearch tractable, various efforts have been made.
Forexample, Jiang et al (2008a) combine different lev-els of knowledge in an outside linear model of a two-layer cascaded model; Jiang et al (2008b) uses theforest re-ranking technique (Huang, 2008); and in(Kruengkrai et al, 2009), only known words in vo-cabulary are included in the hybrid lattice consistingof both character- and word-level nodes.We propose to incorporate character-based fea-tures in word-based models.
Consider a character-based feature function ?
(c, t, c) that maps acharacter-tag pair to a high-dimensional featurespace, with respect to an input character sequencec.
For a possible word over c of length l , wi =ci0 ...ci0+l?1, tag each character cij in this word witha character-based tag tij .
Character-based featuresof wi can be computed as {?
(cij , tij , c)|0 ?
j < l}.The first row of Table 5 illustrates character-basedfeatures of a word of length 3, which is tagged withtagset BMES.
From this view, the character-basedfeature templates defined in Section 3.1 are naturallyused in a word-based model.When character-based features are incorporatedinto word-based CWS models, some word-basedfeatures are no longer of interest, such as the start-ing character of a word, sub-words contained inthe word, contextual characters and so on.
Weconsider word counting features as a complemen-tary to character-based features, following the ideaof using web-scale features in previous work, e.g.
(Bansal and Klein, 2011).
For a possible word w, letcount(w) return the count of times that w occurs asa legal word in training data.
The word count num-ber is further processed following (Bansal and Klein,2011), wc(w) = floor(log(count(w)) ?
5)/5.
Inaddition to wc(wi), we also use corresponding wordcount features of possible words that are composedof the boundary and contextual characters ofwi.
Thespecific word-based feature templates are illustratedin the second row of Table 5.4 TrainingWe use the following linear model for scoring pre-dictions: score(y)=?T?
(x, y), where ?
(y) is a high-dimensional binary feature representation of y overinput x and ?
contains weights of these features.
Forcharacter-?
(ci0 , B, c), ?
(ci1 , M, c), ?
(ci2 , E, c)-basedword-wc(ci0ci1ci2), wc(clci0), wc(ci2cr)-basedTable 5: Character- and word-based features of a possi-ble wordwi over the input character sequence c. Supposethatwi = ci0ci1ci2 , and its preceding and following char-acters are cl and cr respectively.parameter estimation of ?, we use the averaged per-ceptron as described in (Collins, 2002).
This train-ing algorithm relies on the choice of decoding algo-rithm.
When we experiment with different decoders,by default, the parameter weights in use are trainedwith the corresponding decoding algorithm.Especially, for experiments with lookahead fea-tures of English POS tagging, we prepare trainingdata with the stacked learning technique, in order toalleviate overfitting.
More specifically, we divide thetraining data into k folds, and tag each fold with thedeterministic model learned over the other k-1 folds.The predicted tags of all folds are then merged intothe gold training data and used (only) as lookaheadfeatures.
Sun (2011) uses this technique to mergedifferent levels of predictors for word segmentation.5 Experiments5.1 Data setWe run experiments on English POS tagging on theWSJ corpus in the Penn Treebank.
Following mostprevious work, e.g.
(Collins, 2002) and (Shen et al,2007), we divide this corpus into training set (sec-tions 0-18), development set (sections 19-21) andthe final test set (sections 22-24).We run experiments on Chinese word segmenta-tion on the Penn Chinese Treebank 5.0.
Following(Jiang et al, 2008a), we divide this corpus into train-ing set (chapters 1-260), development set (chapters271-300) and the final test set (chapters 301-325).5.2 Deterministic constraintsExperiments in this section are carried out on the de-velopment set.
The cutoff number and threshold asdefined in 2.1.2, are fixed as 5 and 0.99 respectively.1058precision recall F1bigram 0.993 0.841 0.911trigram 0.996 0.608 0.755bi+trigram 0.992 0.857 0.920Table 6: POS tagging with deterministic constraints.The maximum in each column is bold.m0={VBN, VBZ} & m1={JJ, VBD, VBN} ?
VBNw0=also & m1={VBD, VBN} ?
RBm0=?es & m?1={IN, RB, RP} ?
NNSw0=last & w?1= the?
JJTable 7: Deterministic constraints for POS tagging.Deterministic constraints for POS taggingFor English POS tagging, we evaluate the deter-ministic constraints generated by the templates de-scribed in Section 2.1.1.
Since these deterministicconstraints are only applied to words that occur ina constrained context, we report F-measure as theaccuracy measure.
Precision p is defined as the per-centage of correct predictions out of all predictions,and recall r is defined as the percentage of gold pre-dictions that are correctly predicted.
F-measure F1is computed by 2pr/(p+ r).As shown in Table 6, deterministic constraintslearned with both bigram and trigram templates areall very accurate in predicting POS tags of wordsin their context.
Constraints generated by bigramtemplate alone can already cover 84.1% of the inputwords with a high precision of 0.993.
By adding theconstraints generated by trigram template, recall isincreased to 0.857 with little loss in precision.
Sincethese deterministic constraints are applied before thedecoding of probabilistic models, reliably high pre-cision of their predictions is crucial.There are 114589 bigram deterministic con-straints and 130647 trigram constraints learned fromthe training data.
We show a couple of examples ofbigram deterministic constraints in Table 7.
As de-fined in Section 2.2, we use the set of all possiblePOS tags for a word, e.g.
{VBN, VBZ}, as its morphfeature if the word is frequent (occurring more than5 times in training data).
For a rare word, the last twocharacters are used as its morph feature, e.g.
?es.
Aconstraint is composed of w?1, w0 and w1, as wellas the morph features m?1, m0 and m1.
For ex-tagset precision recall F1BMES 0.989 0.566 0.720IB 0.996 0.686 0.812Table 8: Character tagging with deterministic constraints.ample, the first constraint in Table 7 determines thetag VBN of w0.
A deterministic constraint is awareof neither the likelihood of each possible tag or therelative rank of their likelihoods.Deterministic constraints for character taggingFor the character tagging formulation of Chineseword segmentation, we discussed two tagsets IB andBMES in Section 3.1.
With respect to either tagset,we use both bigram and trigram templates to gen-erate deterministic constraints for the correspondingtagging problem.
These constraints are also evalu-ated by F-measure as defined above.
As shown inTable 8, when tagset IB is used for character tag-ging, high precision predictions can be made by thedeterministic constraints that are learned with re-spect to this tagset.
However, when tagset BMES isused, the learned constraints don?t always make reli-able predictions, and the overall precision is not highenough to constrain a probabilistic model.
There-fore, we will only use the deterministic constraintsthat predict IB tags in following CWS experiments.5.3 English POS taggingFor English POS tagging, as well as the CWS prob-lem that will be discussed in the next section, we usethe development set to choose training iterations (=5), set beam width etc.
The following experimentsare done on the final test set.As introduced in Section 2.2, we adopt a verycompact feature set used in (Ratnaparkhi, 1996)1.While searching in a constrained space, we can alsoextend this feature set with some basic lookaheadfeatures as defined in Section 2.2.
This replicatesthe feature set B used in (Shen et al, 2007).In this work, our main interest in the POS tag-ging problem is on its efficiency.
A well-knowntechnique to speed up Viterbi decoding is to con-duct beam search.
Based on experiments carried out1Our implementation of this feature set is basically the sameas the version used in (Collins, 2002).1059Ratnaparkhi (1996)?s featureBeam=1 Beam=5raw 96.46%/3?
97.16/1?constrained 96.80%/14?
97.20/10?Feature B in (Shen et al, 2007)(Shen et al, 2007) 97.15% (Beam=3)constrained 97.03%/11?
97.20/8?Table 9: POS tagging accuracy and speed.
The maximumin each column is bold.
The baseline for speed in all casesis the unconstrained tagger using (Ratnaparkhi, 1996)?sfeature and conducting a beam (=5) search.on the development set, we set beam-width of ourbaseline model as 5.
Our baseline model, whichuses Ratnaparkhi (1996)?s feature set and conductsa beam (=5) search in the unconstrained space,achieves a tagging accuracy of 97.16%.
Taggingaccuracy is measured by the percentage of correctpredictions out of all gold predictions.
We considerthe speed of our baseline model as 1?, and compareother taggers with this one.
The speed of a POS tag-ger is measured by the number of input words pro-cessed per second.As shown in Table 9, when the beam-width is re-duced from 5 to 1, the tagger (beam=1) is 3 timesfaster but tagging accuracy is badly hurt.
In contrast,when searching in a constrained space rather thanthe raw space, the constrained tagger (beam=5) is 10times fast as the baseline and the tagging accuracyis even moderately improved, increasing to 97.20%.When we evaluate the speed of a constrained tag-ger, the time of decoding deterministic constraintsis included.
These constraints make more accuratepredictions than probabilistic models, thus besidesimproving the overall tagging speed as we expect,tagging accuracy also improves by a little.In Viterbi decoding, all possible transitions be-tween two neighbour states are evaluated, so the ad-dition of locally lookahead features may have NOimpact on performance.
When beam-width is set to5, tagging accuracy is not improved by the use ofFeature B in (Shen et al, 2007); and because thesize of the feature model grows, efficiency is hurt.On the other hand, when lookahead features areused, Viterbi-style decoding is less affected by thereduction of beam-width.
As compared to the con-strained greedy tagger using Ratnaparkhi (1996)?sfeature set, with the additional use of three locallylookahead feature templates, tagging accuracy is in-creased from 96.80% to 97.02%.When no further data is used other than trainingdata, the bidirectional tagger described in (Shen etal., 2007) achives an accuracy of 97.33%, using amuch richer feature set (E) than feature set B, theone we compare with here.
As noted above, theaddition of three feature templates already has anotable negative impact on efficiency, thus the useof feature set E will hurt tagging efficiency muchworse.
Rich feature sets are also widely used inother work that pursue state-of-art tagging accuracy,e.g.
(Toutanova et al, 2003).
In this work, we fo-cus on the most compact feature sets, since taggingefficiency is our main consideration in our work onPOS taging.
The proposed constrained taggers asdescribed above can achieve near state-of-art POStagging accuracy in a much more efficient manner.5.4 Chinese word segmentationLike other tagging problems, Viterbi-style decodingis widely used for character tagging for CWS.
Wetransform tagged character sequences to word seg-mentations first, and then evaluate word segmenta-tions by F-measure, as defined in Section 5.2.We proposed an ILP formulation of the CWSproblem in Section 3.3, where we present a word-based model.
In Section 3.4, we describe a way ofmapping words to a character-based feature space.From this view, the highest scoring tagging sequenceis computed subject to structural constraints, givingus an inference alternative to Viterbi decoding.
Forexample, recall the example of input character se-quence c = c1c2 discussed in Section 3.3.
The twopossible ILP solutions give two possible segmenta-tions {c1, c2} and {c1c2}, thus there are 2 tag se-quences evaluated by ILP, BB and BI.
On the otherhand, there are 4 tag sequences evaluated by Viterbidecoding: BI, BB, IB and II.With the same feature templates as described inSection 3.1, we now compare these two decodingmethods.
Tagset BMES is used for character taggingas well as for mapping words to character-based fea-ture space.
We use the same Viterbi decoder as im-plemented for English POS tagging and use a non-commercial ILP solver included in GNU Linear Pro-1060precision recall F-measureViterbi 0.971 0.966 0.968ILP 0.970 0.977 0.974(Jiang et al, 2008a), POS- 0.971(Jiang et al, 2008a), POS+ 0.973Table 10: F-measure on Chinese word segmentation.Only character-based features are used.
POS-/+: percep-tron trained without/with POS.gramming Kit (GLPK), version 4.3.
2 As shownin Table 10, optimal solutions returned by an ILPsolver are more accurate than optimal solutions re-turned by a Viterbi decoder.
The F-measure is im-proved by a relative error reduction of 18.8%, from0.968 to 0.974.
These results are compared to thecore perceptron trained without POS in (Jiang et al,2008a).
They only report results with ?lexical-target?features, a richer feature set than the one we usehere.
As shown in Table 10, we achieve higher per-formance even with more compact features.Joint inference of CWS and Chinese POS taggingis popularly studied in recent work, e.g.
(Ng andLow, 2004), (Jiang et al, 2008a), and (Kruengkrai etal., 2009).
It has been shown that better performancecan be achieved with joint inference, e.g.
F-measure0.978 by the cascaded model in (Jiang et al, 2008a).We focus on the task of word segmentation only inthis work and show that a comparable F-measure isachievable in a much more efficient manner.
Sun(2011) uses the stacked learning technique to mergedifferent levels of predictors, obtaining a combinedsystem that beats individual ones.Word-based features can be easily incorporated,since the ILP formulation is more naturally viewedas a word-based model.
We extend character-basedfeatures with the word count features as describedin Section 3.4.
Currently, we only use word countscomputed from training data, i.e.
still a closed test.The addition of these features makes a moderate im-provement on the F-measure, from 0.974 to 0.975.As discussed in Section 3.3, if we are able todetermine that some characters always start newwords, the number of possible words is reduced,i.e.
the number of variables in an ILP solution isreduced.
As shown in Table 11, when character se-2http://www.gnu.org/software/glpkF-measure avg.
|x| #char per sec.raw 0.974 1290.4 113 (1?
)constrained 0.974 83.75 12190 (107?
)Table 11: ILP problem size and segmentation speed.quences are partially tagged by deterministic con-straints, the number of possible words per sentence,i.e.
avg.
|x|, is reduced from 1290.4 to 83.7.
This re-duction of ILP problem size has a very important im-pact on the efficiency.
As shown in Table 11, whentaking constrained input, the segmentation speed isincreased by 107 times over taking raw input, from113 characters per second to 12,190 characters persecond on a dual-core 3.0HZ CPU.Deterministic constraints predicting IB tags areonly used here for constraining possible words.They are very accurate as shown in Section 5.2.
Fewgold predictions are missed from the constrained setof possible words.
As shown in Table 11, F-measureis not affected by applying these constraints, whilethe efficiency is significantly improved.6 Conclusion and future workWe have shown by experiments that large number ofdeterministic constraints can be learned from train-ing examples, as long as the proper representation isused.
These deterministic constraints are very use-ful in constraining probabilistic search, for example,they may be directly used for determining predic-tions as in English POS tagging, or used for reduc-ing the number of variables in an ILP solution as inChinese word segmentation.
The most notable ad-vantage in using these constraints is the increased ef-ficiency.
The two applications are both well-studied;there isn?t much space for improving accuracy.
Evenso, we have shown that as tested with the same fea-ture set for CWS, the proposed ILP formulation sig-nificantly improves the F-measure as compared toViterbi decoding.These two simple applications suggest that it isof interest to explore data-driven deterministic con-straints learnt from training examples.
There aremore interesting ways in applying these constraints,which we are going to study in future work.1061ReferencesM.
Bansal and D. Klein.
2011.
Web-scale features forfull-scale parsing.
In Proceedings of the 49th AnnualMeeting of the Association for Computational Linguis-tics: Human Language Technologies - Volume 1, pages693?702.Noam Chomsky.
1970.
Remarks on nominalization.In R Jacobs and P Rosenbaum, editors, Readings inEnglish Transformational Grammar, pages 184?221.Ginn.Michael Collins.
2002.
Discriminative training meth-ods for hidden markov models: theory and experi-ments with perceptron algorithms.
In Proceedings ofthe ACL-02 conference on Empirical methods in natu-ral language processing, EMNLP ?02, pages 1?8.L.
Huang.
2008.
Forest reranking: Discriminative pars-ing with non-local features.
In In Proceedings of the46th Annual Meeting of the Association for Computa-tional Linguistics.W.
Jiang, L. Huang, Q. Liu, and Y. Lu?.
2008a.
A cas-caded linear model for joint chinese word segmenta-tion and part-of-speech tagging.
In In Proceedings ofthe 46th Annual Meeting of the Association for Com-putational Linguistics.W.
Jiang, H. Mi, and Q. Liu.
2008b.
Word lattice rerank-ing for chinese word segmentation and part-of-speechtagging.
In Proceedings of the 22nd InternationalConference on Computational Linguistics - Volume 1,COLING ?08, pages 385?392.T.
Kristjansson, A. Culotta, and P. Viola.
2004.
Inter-active information extraction with constrained condi-tional random fields.
In In AAAI, pages 412?418.C.
Kruengkrai, K. Uchimoto, J. Kazama, Y. Wang,K.
Torisawa, and H. Isahara.
2009.
An error-drivenword-character hybrid model for joint chinese wordsegmentation and pos tagging.
In Proceedings of theJoint Conference of the 47th Annual Meeting of theACL and the 4th International Joint Conference onNatural Language Processing of the AFNLP, ACL ?09,pages 513?521.Mitch Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1993.
Building a large annotated cor-pus of english: The penn treebank.
Computational lin-guistics, 19(2):313?330.A.
F. T. Martins, N. A. Smith, and E. P. Xing.
2009.Concise integer linear programming formulations fordependency parsing.
In Proceedings of the Joint Con-ference of the 47th Annual Meeting of the ACL andthe 4th International Joint Conference on Natural Lan-guage Processing of the AFNLP (ACL-IJCNLP), pages342?350, Singapore.H.
T. Ng and J. K. Low.
2004.
Chinese partof-speechtagging: One-at-a-time or all-at-once?
word-based orcharacter-based?
In In Proceedings of the 2004 Con-ference on Empirical Methods in Natural LanguageProcessing (EMNLP), page 277C284.A.
Ratnaparkhi.
1996.
A maximum entropy model forpart-of-speech tagging.
In In Proceedings of the Em-pirical Methods in Natural Language Processing Con-ference (EMNLP).S.
Ravi and K. Knight.
2009.
Minimized models forunsupervised part-of-speech tagging.
In Proc.
ACL.D.
Roth and W. Yih.
2005.
Integer linear programminginference for conditional random fields.
In In Pro-ceedings of the International Conference on MachineLearning (ICML), pages 737?744.L.
Shen, G. Satta, and A. K. Joshi.
2007.
Guided learn-ing for bidirectional sequence classification.
In Pro-ceedings of the 45th Annual Meeting of the Associationfor Computational Linguistics.R.
Sproat, W. Gale, C. Shih, and N. Chang.
1996.A stochastic finite-state word-segmentation algorithmfor chinese.
Comput.
Linguist., 22(3):377?404.W.
Sun.
2011.
A stacked sub-word model for joint chi-nese word segmentation and part-of-speech tagging.In Proceedings of the ACL-HLT 2011.K.
Toutanova, D. Klein, C. Manning, and Y. Singer.2003.
Feature-rich part-of-speech tagging with acyclic dependency network.
In NAACL-2003.N.
Xue.
2003.
Chinese word segmentation as charactertagging.
International Journal of Computational Lin-guistics and Chinese Language Processing, 9(1):29?48.Y.
Zhang and S. Clark.
2007.
Chinese Segmentation witha Word-Based Perceptron Algorithm.
In Proceedingsof the 45th Annual Meeting of the Association of Com-putational Linguistics, pages 840?847.1062
