Proceedings of the 12th Conference of the European Chapter of the ACL, pages 33?41,Athens, Greece, 30 March ?
3 April 2009. c?2009 Association for Computational LinguisticsPersonalizing PageRank for Word Sense DisambiguationEneko Agirre and Aitor SoroaIXA NLP GroupUniversity of the Basque CountryDonostia, Basque Contry{e.agirre,a.soroa}@ehu.esAbstractIn this paper we propose a new graph-based method that uses the knowledge ina LKB (based on WordNet) in order toperform unsupervised Word Sense Disam-biguation.
Our algorithm uses the fullgraph of the LKB efficiently, performingbetter than previous approaches in Englishall-words datasets.
We also show that thealgorithm can be easily ported to other lan-guages with good results, with the only re-quirement of having a wordnet.
In addi-tion, we make an analysis of the perfor-mance of the algorithm, showing that it isefficient and that it could be tuned to befaster.1 IntroductionWord Sense Disambiguation (WSD) is a keyenabling-technology that automatically choosesthe intended sense of a word in context.
Super-vised WSD systems are the best performing inpublic evaluations (Palmer et al, 2001; Snyderand Palmer, 2004; Pradhan et al, 2007) but theyneed large amounts of hand-tagged data, which istypically very expensive to build.
Given the rela-tively small amount of training data available, cur-rent state-of-the-art systems only beat the simplemost frequent sense (MFS) baseline1 by a smallmargin.
As an alternative to supervised systems,knowledge-based WSD systems exploit the infor-mation present in a lexical knowledge base (LKB)to perform WSD, without using any further corpusevidence.1This baseline consists of tagging all occurrences in thetest data with the sense of the word that occurs more often inthe training dataTraditional knowledge-based WSD systems as-sign a sense to an ambiguous word by comparingeach of its senses with those of the surroundingcontext.
Typically, some semantic similarity met-ric is used for calculating the relatedness amongsenses (Lesk, 1986; McCarthy et al, 2004).
Oneof the major drawbacks of these approaches stemsfrom the fact that senses are compared in a pair-wise fashion and thus the number of computa-tions can grow exponentially with the number ofwords.
Although alternatives like simulated an-nealing (Cowie et al, 1992) and conceptual den-sity (Agirre and Rigau, 1996) were tried, most ofpast knowledge based WSD was done in a subop-timal word-by-word process, i.e., disambiguatingwords one at a time.Recently, graph-based methods for knowledge-based WSD have gained much attention in theNLP community (Sinha and Mihalcea, 2007; Nav-igli and Lapata, 2007; Mihalcea, 2005; Agirreand Soroa, 2008).
These methods use well-knowngraph-based techniques to find and exploit thestructural properties of the graph underlying a par-ticular LKB.
Because the graph is analyzed as awhole, these techniques have the remarkable prop-erty of being able to find globally optimal solu-tions, given the relations between entities.
Graph-based WSD methods are particularly suited fordisambiguating word sequences, and they man-age to exploit the interrelations among the sensesin the given context.
In this sense, they providea principled solution to the exponential explosionproblem, with excellent performance.Graph-based WSD is performed over a graphcomposed by senses (nodes) and relations betweenpairs of senses (edges).
The relations may be ofseveral types (lexico-semantic, coocurrence rela-tions, etc.)
and may have some weight attached to33them.
The disambiguation is typically performedby applying a ranking algorithm over the graph,and then assigning the concepts with highest rankto the corresponding words.
Given the compu-tational cost of using large graphs like WordNet,many researchers use smaller subgraphs built on-line for each target context.In this paper we present a novel graph-basedWSD algorithm which uses the full graph ofWordNet efficiently, performing significantly bet-ter that previously published approaches in En-glish all-words datasets.
We also show that thealgorithm can be easily ported to other languageswith good results, with the only requirement ofhaving a wordnet.
The algorithm is publicly avail-able2 and can be applied easily to sense invento-ries and knowledge bases different from WordNet.Our analysis shows that our algorithm is efficientcompared to previously proposed alternatives, andthat a good choice of WordNet versions and rela-tions is fundamental for good performance.The paper is structured as follows.
We first de-scribe the PageRank and Personalized PageRankalgorithms.
Section 3 introduces the graph basedmethods used for WSD.
Section 4 shows the ex-perimental setting and the main results, and Sec-tion 5 compares our methods with related exper-iments on graph-based WSD systems.
Section 6shows the results of the method when applied toa Spanish dataset.
Section 7 analyzes the perfor-mance of the algorithm.
Finally, we draw someconclusions in Section 8.2 PageRank and Personalized PageRankThe celebrated PageRank algorithm (Brin andPage, 1998) is a method for ranking the verticesin a graph according to their relative structuralimportance.
The main idea of PageRank is thatwhenever a link from vi to vj exists in a graph, avote from node i to node j is produced, and hencethe rank of node j increases.
Besides, the strengthof the vote from i to j also depends on the rankof node i: the more important node i is, the morestrength its votes will have.
Alternatively, PageR-ank can also be viewed as the result of a randomwalk process, where the final rank of node i rep-resents the probability of a random walk over thegraph ending on node i, at a sufficiently large time.Let G be a graph with N vertices v1, .
.
.
, vNand di be the outdegree of node i; let M be a2http://ixa2.si.ehu.es/ukbN?N transition probability matrix, where Mji =1diif a link from i to j exists, and zero otherwise.Then, the calculation of the PageRank vector Prover G is equivalent to resolving Equation (1).Pr = cMPr + (1 ?
c)v (1)In the equation, v is a N ?
1 vector whose ele-ments are 1N and c is the so called damping factor,a scalar value between 0 and 1.
The first term ofthe sum on the equation models the voting schemedescribed in the beginning of the section.
The sec-ond term represents, loosely speaking, the proba-bility of a surfer randomly jumping to any node,e.g.
without following any paths on the graph.The damping factor, usually set in the [0.85..0.95]range, models the way in which these two termsare combined at each step.The second term on Eq.
(1) can also be seen asa smoothing factor that makes any graph fulfill theproperty of being aperiodic and irreducible, andthus guarantees that PageRank calculation con-verges to a unique stationary distribution.In the traditional PageRank formulation the vec-tor v is a stochastic normalized vector whose ele-ment values are all 1N , thus assigning equal proba-bilities to all nodes in the graph in case of randomjumps.
However, as pointed out by (Haveliwala,2002), the vector v can be non-uniform and assignstronger probabilities to certain kinds of nodes, ef-fectively biasing the resulting PageRank vector toprefer these nodes.
For example, if we concen-trate all the probability mass on a unique node i,all random jumps on the walk will return to i andthus its rank will be high; moreover, the high rankof i will make all the nodes in its vicinity also re-ceive a high rank.
Thus, the importance of node igiven by the initial distribution of v spreads alongthe graph on successive iterations of the algorithm.In this paper, we will use traditional PageRankto refer to the case when a uniform v vector is usedin Eq.
(1); and whenever a modified v is used, wewill call it Personalized PageRank.
The next sec-tion shows how we define a modified v.PageRank is actually calculated by applying aniterative algorithm which computes Eq.
(1) suc-cessively until convergence below a given thresh-old is achieved, or, more typically, until a fixednumber of iterations are executed.Regarding PageRank implementation details,we chose a damping value of 0.85 and finish thecalculation after 30 iterations.
We did not try other34damping factors.
Some preliminary experimentswith higher iteration counts showed that althoughsometimes the node ranks varied, the relative orderamong particular word synsets remained stable af-ter the initial iterations (cf.
Section 7 for furtherdetails).
Note that, in order to discard the effectof dangling nodes (i.e.
nodes without outlinks) weslightly modified Eq.
(1).
For the sake of brevitywe omit the details, which the interested readercan check in (Langville and Meyer, 2003).3 Using PageRank for WSDIn this section we present the application ofPageRank to WSD.
If we were to apply the tra-ditional PageRank over the whole WordNet wewould get a context-independent ranking of wordsenses, which is not what we want.
Given an inputpiece of text (typically one sentence, or a small setof contiguous sentences), we want to disambiguateall open-class words in the input taken the rest ascontext.
In this framework, we need to rank thesenses of the target words according to the otherwords in the context.
Theare two main alternativesto achieve this:?
To create a subgraph of WordNet which con-nects the senses of the words in the input text,and then apply traditional PageRank over thesubgraph.?
To use Personalized PageRank, initializing vwith the senses of the words in the input textThe first method has been explored in the lit-erature (cf.
Section 5), and we also presented avariant in (Agirre and Soroa, 2008) but the secondmethod is novel in WSD.
In both cases, the algo-rithms return a list of ranked senses for each targetword in the context.
We will see each of them inturn, but first we will present some notation and apreliminary step.3.1 Preliminary stepA LKB is formed by a set of concepts and relationsamong them, and a dictionary, i.e., a list of words(typically, word lemmas) each of them linked toat least one concept of the LKB.
Given any suchLKB, we build an undirected graph G = (V, E)where nodes represent LKB concepts (vi), andeach relation between concepts vi and vj is rep-resented by an undirected edge ei,j .In our experiments we have tried our algorithmsusing three different LKBs:?
MCR16 + Xwn: The Multilingual CentralRepository (Atserias et al, 2004b) is a lexicalknowledge base built within the MEANINGproject3.
This LKB comprises the originalWordNet 1.6 synsets and relations, plus somerelations from other WordNet versions auto-matically mapped4 into version 1.6: WordNet2.0 relations and eXtended WordNet relations(Mihalcea and Moldovan, 2001) (gold, silverand normal relations).
The resulting graphhas 99, 632 vertices and 637, 290 relations.?
WNet17 + Xwn: WordNet 1.7 synset andrelations and eXtended WordNet relations.The graph has 109, 359 vertices and 620, 396edges?
WNet30 + gloss: WordNet 3.0 synset andrelations, including manually disambiguatedglosses .
The graph has 117, 522 vertices and525, 356 relations.Given an input text, we extract the list Wi i =1 .
.
.m of content words (i.e.
nouns, verbs, ad-jectives and adverbs) which have an entry in thedictionary, and thus can be related to LKB con-cepts.
Let Concepts i = {v1, .
.
.
, vim} be theim associated concepts of word Wi in the LKBgraph.
Note that monosemous words will be re-lated to just one concept, whereas polysemouswords may be attached to several.
As a resultof the disambiguation process, every concept inConcepts i, i = 1, .
.
.
, m receives a score.
Then,for each target word to be disambiguated, we justchoose its associated concept in G with maximalscore.In our experiments we build a context of at least20 content words for each sentence to be disam-biguated, taking the sentences immediately beforeand after it in the case that the original sentencewas too short.3.2 Traditional PageRank over Subgraph(Spr)We follow the algorithm presented in (Agirre andSoroa, 2008), which we explain here for complete-ness.
The main idea of the subgraph method is toextract the subgraph of GKB whose vertices andrelations are particularly relevant for a given input3http://nipadio.lsi.upc.es/nlp/meaning4We use the freely available WordNet mappings fromhttp://www.lsi.upc.es/?nlp/tools/download-map.php35context.
Such a subgraph is called a ?disambigua-tion subgraph?
GD, and it is built in the followingway.
For each word Wi in the input context andeach concept vi ?
Concepts i, a standard breath-first search (BFS) over GKB is performed, start-ing at node vi.
Each run of the BFS calculates theminimum distance paths between vi and the rest ofconcepts of GKB .
In particular, we are interestedin the minimum distance paths between vi and theconcepts associated to the rest of the words in thecontext, vj ?
?j 6=i Conceptsj .
Let mdpvi be theset of these shortest paths.This BFS computation is repeated for everyconcept of every word in the input context, stor-ing mdpvi accordingly.
At the end, we obtain aset of minimum length paths each of them hav-ing a different concept as a source.
The disam-biguation graph GD is then just the union of thevertices and edges of the shortest paths, GD =?mi=1{mdpvj/vj ?
Concepts i}.The disambiguation graph GD is thus a sub-graph of the original GKB graph obtained by com-puting the shortest paths between the concepts ofthe words co-occurring in the context.
Thus, wehypothesize that it captures the most relevant con-cepts and relations in the knowledge base for theparticular input context.Once the GD graph is built, we compute the tra-ditional PageRank algorithm over it.
The intuitionbehind this step is that the vertices representingthe correct concepts will be more relevant in GDthan the rest of the possible concepts of the contextwords, which should have less relations on averageand be more isolated.As usual, the disambiguation step is performedby assigning to each word Wi the associated con-cept in Concepts i which has maximum rank.
Incase of ties we assign all the concepts with maxi-mum rank.
Note that the standard evaluation scriptprovided in the Senseval competitions treats mul-tiple senses as if one was chosen at random, i.e.for evaluation purposes our method is equivalentto breaking ties at random.3.3 Personalized PageRank (Ppr andPpr w2w)As mentioned before, personalized PageRank al-lows us to use the full LKB.
We first insert thecontext words into the graph G as nodes, and linkthem with directed edges to their respective con-cepts.
Then, we compute the personalized PageR-ank of the graph G by concentrating the initialprobability mass uniformly over the newly intro-duced word nodes.
As the words are linked tothe concepts by directed edges, they act as sourcenodes injecting mass into the concepts they are as-sociated with, which thus become relevant nodes,and spread their mass over the LKB graph.
There-fore, the resulting personalized PageRank vectorcan be seen as a measure of the structural rele-vance of LKB concepts in the presence of the inputcontext.One problem with Personalized PageRank isthat if one of the target words has two senseswhich are related by semantic relations, thosesenses reinforce each other, and could thusdampen the effect of the other senses in the con-text.
With this observation in mind we deviseda variant (dubbed Ppr w2w), where we build thegraph for each target word in the context: for eachtarget word Wi, we concentrate the initial proba-bility mass in the senses of the words surroundingWi, but not in the senses of the target word itself,so that context words increase its relative impor-tance in the graph.
The main idea of this approachis to avoid biasing the initial score of concepts as-sociated to target word Wi, and let the surround-ing words decide which concept associated to Wihas more relevance.
Contrary to the other two ap-proaches, Ppr w2w does not disambiguate all tar-get words of the context in a single run, whichmakes it less efficient (cf.
Section 7).4 Evaluation framework and resultsIn this paper we will use two datasets for com-paring graph-based WSD methods, namely, theSenseval-2 (S2AW) and Senseval-3 (S3AW) allwords datasets (Snyder and Palmer, 2004; Palmeret al, 2001), which are both labeled with WordNet1.7 tags.
We did not use the Semeval dataset, forthe sake of comparing our results to related work,none of which used Semeval data.
Table 1 showsthe results as recall of the graph-based WSD sys-tem over these datasets on the different LKBs.
Wedetail overall results, as well as results per PoS,and the confidence interval for the overall results.The interval was computed using bootstrap resam-pling with 95% confidence.The table shows that Ppr w2w is consistentlythe best method in both datasets and for all LKBs.Ppr and Spr obtain comparable results, which isremarkable, given the simplicity of the Ppr algo-36Senseval-2 All Words datasetLKB Method All N V Adj.
Adv.
Conf.
intervalMCR16 + Xwn Ppr 51.1 64.9 38.1 57.4 47.5 [49.3, 52.6]MCR16 + Xwn Ppr w2w 53.3 64.5 38.6 58.3 48.1 [52.0, 55.0]MCR16 + Xwn Spr 52.7 64.8 35.3 56.8 50.2 [51.3, 54.4]WNet17 + Xwn Ppr 56.8 71.1 33.4 55.9 67.1 [55.0, 58.7]WNet17 + Xwn Ppr w2w 58.6 70.4 38.9 58.3 70.1 [56.7, 60.3]WNet17 + Xwn Spr 56.7 66.8 37.7 57.6 70.8 [55.0, 58.2]WNet30 + gloss Ppr 53.5 70.0 28.6 53.9 55.1 [51.8, 55.2]WNet30 + gloss Ppr w2w 55.8 71.9 34.4 53.8 57.5 [54.1, 57.8]WNet30 + gloss Spr 54.8 68.9 35.1 55.2 56.5 [53.2, 56.3]MFS 60.1 71.2 39.0 61.1 75.4 [58.6, 61.9]SMUaw 68.6 78.0 52.9 69.9 81.7Senseval-3 All Words datasetLKB Method All N V Adj.
Adv.MCR16 + Xwn Ppr 54.3 60.9 45.4 56.5 92.9 [52.3, 56.1]MCR16 + Xwn Ppr w2w 55.8 63.2 46.2 57.5 92.9 [53.7, 57.7]MCR16 + Xwn Static 53.7 59.5 45.0 57.8 92.9 [51.8, 55.7]WNet17 + Xwn Ppr 56.1 62.6 46.0 60.8 92.9 [54.0, 58.1]WNet17 + Xwn Ppr w2w 57.4 64.1 46.9 62.6 92.9 [55.5, 59.3]WNet17 + Xwn Spr 56.20 61.6 47.3 61.8 92.9 [54.8, 58.2]WNet30 + gloss Ppr 48.5 52.2 41.5 54.2 78.6 [46.7, 50.6]WNet30 + gloss Ppr w2w 51.6 59.0 40.2 57.2 78.6 [49.9, 53.3]WNet30 + gloss Spr 45.4 54.1 31.4 52.5 78.6 [43.7, 47.4]MFS 62.3 69.3 53.6 63.7 92.9 [60.2, 64.0]GAMBL 65.2 70.8 59.3 65.3 100Table 1: Results (as recall) on Senseval-2 and Senseval-3 all words tasks.
We also include the MFSbaseline and the best results of supervised systems at competition time (SMUaw,GAMBL).rithm, compared to the more elaborate algorithmto construct the graph.
The differences betweenmethods are not statistically significant, which is acommon problem on this relatively small datasets(Snyder and Palmer, 2004; Palmer et al, 2001).Regarding LKBs, the best results are obtainedusing WordNet 1.7 and eXtended WordNet.
Herethe differences are in many cases significant.These results are surprising, as we would ex-pect that the manually disambiguated gloss re-lations from WordNet 3.0 would lead to bet-ter results, compared to the automatically disam-biguated gloss relations from the eXtended Word-Net (linked to version 1.7).
The lower perfor-mance of WNet30+gloss can be due to the factthat the Senseval all words data set is tagged usingWordNet 1.7 synsets.
When using a different LKBfor WSD, a mapping to WordNet 1.7 is required.Although the mapping is cited as having a correct-ness on the high 90s (Daude et al, 2000), it couldhave introduced sufficient noise to counteract thebenefits of the hand-disambiguated glosses.Table 1 also shows the most frequent sense(MFS), as well as the best supervised sys-tems (Snyder and Palmer, 2004; Palmer etal., 2001) that participated in each competition(SMUaw and GAMBL, respectively).
The MFS isa baseline for supervised systems, but it is consid-ered a difficult competitor for unsupervised sys-tems, which rarely come close to it.
In this casethe MFS baseline was computed using previouslyavailabel training data like SemCor.
Our best re-sults are close to the MFS in both Senseval-2 andSenseval-3 datasets.
The results for the supervisedsystem are given for reference, and we can see thatthe gap is relatively small, specially for Senseval-3.5 Comparison to Related workIn this section we will briefly describe somegraph-based methods for knowledge-based WSD.The methods here presented cope with the prob-lem of sequence-labeling, i.e., they disambiguateall the words coocurring in a sequence (typically,all content words of a sentence).
All the meth-ods rely on the information represented on someLKB, which typically is some version of Word-Net, sometimes enriched with proprietary rela-tions.
The results on our datasets, when available,are shown in Table 2.
The table also shows theperformance of supervised systems.The TexRank algorithm (Mihalcea, 2005) forWSD creates a complete weighted graph (e.g.
agraph where every pair of distinct vertices is con-nected by a weighted edge) formed by the synsetsof the words in the input context.
The weight37Senseval-2 All Words datasetSystem All N V Adj.
Adv.Mih05 54.2 57.5 36.5 56.7 70.9Sihna07 56.4 65.6 32.3 61.4 60.2Tsatsa07 49.2 ?
?
?
?Spr 56.6 66.7 37.5 57.6 70.8Ppr 56.8 71.1 33.4 55.9 67.1Ppr w2w 58.6 70.4 38.9 58.3 70.1MFS 60.1 71.2 39.0 61.1 75.4Senseval-3 All Words datasetSystem All N V Adj.
Adv.Mih05 52.2 - - - -Sihna07 52.4 60.5 40.6 54.1 100.0Nav07 - 61.9 36.1 62.8 -Spr 56.2 61.6 47.3 61.8 92.9Ppr 56.1 62.6 46.0 60.8 92.9Ppr w2w 57.4 64.1 46.9 62.6 92.9MFS 62.3 69.3 53.6 63.7 92.9Nav05 60.4 - - - -Table 2: Comparison with related work.
Note thatNav05 uses the MFS.of the links joining two synsets is calculated byexecuting Lesk?s algorithm (Lesk, 1986) betweenthem, i.e., by calculating the overlap between thewords in the glosses of the correspongind senses.Once the complete graph is built, the PageRank al-gorithm is executed over it and words are assignedto the most relevant synset.
In this sense, PageR-ank is used an alternative to simulated annealingto find the optimal pairwise combinations.
Themethod was evaluated on the Senseval-3 dataset,as shown in row Mih05 on Table 2.
(Sinha and Mihalcea, 2007) extends their pre-vious work by using a collection of semantic sim-ilarity measures when assigning a weight to thelinks across synsets.
They also compare differ-ent graph-based centrality algorithms to rank thevertices of the complete graph.
They use differ-ent similarity metrics for different POS types anda voting scheme among the centrality algorithmranks.
Here, the Senseval-3 corpus was used asa development data set, and we can thus see thoseresults as the upper-bound of their method.We can see in Table 2 that the methods pre-sented in this paper clearly outperform both Mih05and Sin07.
This result suggests that analyzing theLKB structure as a whole is preferable than com-puting pairwise similarity measures over synsets.The results of various in-house made experimentsreplicating (Mihalcea, 2005) also confirm this ob-servation.
Note also that our methods are simplerthan the combination strategy used in (Sinha andMihalcea, 2007), and that we did not perform anyparameter tuning as they did.In (Navigli and Velardi, 2005) the authors de-velop a knowledge-based WSD method based onlexical chains called structural semantic intercon-nections (SSI).
Although the system was first de-signed to find the meaning of the words in Word-Net glosses, the authors also apply the method forlabeling text sequences.
Given a text sequence,SSI first identifies monosemous words and assignsthe corresponding synset to them.
Then, it iter-atively disambiguates the rest of terms by select-ing the senses that get the strongest interconnec-tion with the synsets selected so far.
The inter-connection is calculated by searching for paths onthe LKB, constrained by some hand-made rules ofpossible semantic patterns.
The method was eval-uated on the Senseval-3 dataset, as shown in rowNav05 on Table 2.
Note that the method labelsan instance with the most frequent sense of theword if the algorithm produces no output for thatinstance, which makes comparison to our systemunfair, specially given the fact that the MFS per-forms better than SSI.
In fact it is not possible toseparate the effect of SSI from that of the MFS.For this reason we place this method close to theMFS baseline in Table 2.In (Navigli and Lapata, 2007), the authors per-form a two-stage process for WSD.
Given an inputcontext, the method first explores the whole LKBin order to find a subgraph which is particularlyrelevant for the words of the context.
Then, theystudy different graph-based centrality algorithmsfor deciding the relevance of the nodes on the sub-graph.
As a result, every word of the context isattached to the highest ranking concept among itspossible senses.
The Spr method is very similarto (Navigli and Lapata, 2007), the main differ-ence lying on the initial method for extracting thecontext subgraph.
Whereas (Navigli and Lapata,2007) apply a depth-first search algorithm over theLKB graph ?and restrict the depth of the subtreeto a value of 3?, Spr relies on shortest paths be-tween word synsets.
Navigli and Lapata don?t re-port overall results and therefore, we can?t directlycompare our results with theirs.
However, we cansee that on a PoS-basis evaluation our results areconsistently better for nouns and verbs (especiallythe Ppr w2w method) and rather similar for adjec-tives.
(Tsatsaronis et al, 2007) is another example ofa two-stage process, the first one consisting onfinding a relevant subgraph by performing a BFS38Spanish Semeval07LKB Method Acc.Spanish Wnet + Xnet?
Ppr 78.4Spanish Wnet + Xnet?
Ppr w2w 79.3?
MFS 84.6?
Supervised 85.10Table 3: Results (accuracy) on Spanish Semeval07dataset, including MFS and the best supervisedsystem in the competition.search over the LKB.
The authors apply a spread-ing activation algorithm over the subgraph fornode ranking.
Edges of the subgraph are weightedaccording to its type, following a tf.idf like ap-proach.
The results show that our methods clearlyoutperform Tsatsa07.
The fact that the Spr methodworks better suggests that the traditional PageR-ank algorithm is a superior method for ranking thesubgraph nodes.As stated before, all methods presented hereuse some LKB for performing WSD.
(Mihalcea,2005) and (Sinha and Mihalcea, 2007) use Word-Net relations as a knowledge source, but neitherof them specify which particular version did theyuse.
(Tsatsaronis et al, 2007) uses WordNet 1.7enriched with eXtended WordNet relations, justas we do.
Both (Navigli and Velardi, 2005; Nav-igli and Lapata, 2007) use WordNet 2.0 as the un-derlying LKB, albeit enriched with several newrelations, which are manually created.
Unfor-tunately, those manual relations are not publiclyavailable, so we can?t directly compare their re-sults with the rest of the methods.
In (Agirre andSoroa, 2008) we experiment with different LKBsformed by combining relations of different MCRversions along with relations extracted from Sem-Cor, which we call supervised and unsupervisedrelations, respectively.
The unsupervised relationsthat yielded bests results are also used in this paper(c.f Section 3.1).6 Experiments on SpanishOur WSD algorithm can be applied over non-english texts, provided that a LKB for this partic-ular language exists.
We have tested the graph-algorithms proposed in this paper on a Spanishdataset, using the Spanish WordNet as knowledgesource (Atserias et al, 2004a).We used the Semeval-2007 Task 09 dataset asevaluation gold standard (Ma`rquez et al, 2007).The dataset contains examples of the 150 mostfrequent nouns in the CESS-ECE corpus, manu-Method TimePpr 26m46Spr 119m7Ppr w2w 164m4Table 4: Elapsed time (in minutes) of the algo-rithms when applied to the Senseval-2 dataset.ally annotated with Spanish WordNet synsets.
Itis split into a train and test part, and has an ?allwords?
shape i.e.
input consists on sentences,each one having at least one occurrence of a tar-get noun.
We ran the experiment over the test part(792 instances), and used the train part for cal-culating the MFS baseline.
We used the Span-ish WordNet as LKB, enriched with eXtendedWordNet relations.
It contains 105, 501 nodes and623, 316 relations.
The results in Table 3 are con-sistent with those for English, with our algorithmapproaching MFS performance.
Note that for thisdataset the supervised algorithm could barely im-prove over the MFS, suggesting that for this par-ticular dataset MFS is particularly strong.7 Performance analysisTable 4 shows the time spent by the different al-gorithms when applied to the Senseval-2 all wordsdataset, using the WNet17 + Xwn as LKB.
Thedataset consists on 2473 word instances appear-ing on 476 different sentences.
The experimentswere done on a computer with four 2.66 Ghz pro-cessors and 16 Gb memory.
The table shows thatthe time elapsed by the algorithms varies between30 minutes for the Ppr method (which thus dis-ambiguates circa 82 instances per minute) to al-most 3 hours spent by the Ppr w2w method (circa15 instances per minute).
The Spr method liesin between, requiring 2 hours for completing thetask, but its overall performance is well below thePageRank based Ppr w2w method.
Note that thealgorithm is coded in C++ for greater efficiency,and uses the Boost Graph Library.Regarding PageRank calculation, we have trieddifferent numbers of iterations, and analyze therate of convergence of the algorithm.
Figure 1 de-picts the performance of the Ppr w2w method fordifferent iterations of the algorithm.
As before, thealgorithm is applied over the MCR17 + Xwn LKB,and evaluated on the Senseval-2 all words dataset.The algorithm converges very quickly: one sole it-eration suffices for achieving a relatively high per-395757.257.457.657.85858.258.458.60 5 10 15 20 25 30RecallIterationsRate of convergence3333 33 3 3Figure 1: Rate of convergence of PageRank algo-rithm over the MCR17 + Xwn LKB.formance, and 20 iterations are enough for achiev-ing convergence.
The figure shows that, depend-ing on the LKB complexity, the user can tune thealgorithm and lower the number of iterations, thusconsiderably reducing the time required for disam-biguation.8 ConclusionsIn this paper we propose a new graph-basedmethod that uses the knowledge in a LKB (basedon WordNet) in order to perform unsupervisedWord Sense Disambuation.
Our algorithm uses thefull graph of the LKB efficiently, performing bet-ter than previous approaches in English all-wordsdatasets.
We also show that the algorithm can beeasily ported to other languages with good results,with the only requirement of having a wordnet.Both for Spanish and English the algorithm attainsperformances close to the MFS.The algorithm is publicly available5 and can beapplied easily to sense inventories and knowledgebases different from WordNet.
Our analysis showsthat our algorithm is efficient compared to previ-ously proposed alternatives, and that a good choiceof WordNet versions and relations is fundamentalfor good performance.AcknowledgmentsThis work has been partially funded by the EU Commission(project KYOTO ICT-2007-211423) and Spanish ResearchDepartment (project KNOW TIN2006-15049-C03-01).ReferencesE.
Agirre and G. Rigau.
1996.
Word sense disam-biguation using conceptual density.
In In Proceed-ings of the 16th International Conference on Com-putational Linguistics, pages 16?22.5http://ixa2.si.ehu.es/ukbE.
Agirre and A. Soroa.
2008.
Using the multilin-gual central repository for graph-based word sensedisambiguation.
In Proceedings of LREC ?08, Mar-rakesh, Morocco.J.
Atserias, G. Rigau, and L. Villarejo.
2004a.
Span-ish wordnet 1.6: Porting the spanish wordnet acrossprinceton versions.
In In Proceedings of LREC ?04.J.
Atserias, L. Villarejo, G. Rigau, E. Agirre, J. Carroll,B.
Magnini, and P. Vossen.
2004b.
The meaningmultilingual central repository.
In In Proceedings ofGWC, Brno, Czech Republic.S.
Brin and L. Page.
1998.
The anatomy of a large-scale hypertextual web search engine.
ComputerNetworks and ISDN Systems, 30(1-7).J.
Cowie, J. Guthrie, and L. Guthrie.
1992.
Lexicaldisambiguation using simulated annealing.
In HLT?91: Proceedings of the workshop on Speech andNatural Language, pages 238?242, Morristown, NJ,USA.J.
Daude, L. Padro, and G. Rigau.
2000.
MappingWordNets using structural information.
In Proceed-ings of ACL?2000, Hong Kong.T.
H. Haveliwala.
2002.
Topic-sensitive pagerank.
InWWW ?02: Proceedings of the 11th internationalconference on World Wide Web, pages 517?526,New York, NY, USA.
ACM.A.
N. Langville and C. D. Meyer.
2003.
Deeper insidepagerank.
Internet Mathematics, 1(3):335?380.M.
Lesk.
1986.
Automatic sense disambiguation us-ing machine readable dictionaries: how to tell a pinecone from an ice cream cone.
In SIGDOC ?86: Pro-ceedings of the 5th annual international conferenceon Systems documentation, pages 24?26, New York,NY, USA.
ACM.L.
Ma`rquez, L. Villarejo, M. A.
Mart?
?, and M. Taule?.2007.
Semeval-2007 task 09: Multilevel semanticannotation of catalan and spanish.
In Proceedingsof SemEval-2007, pages 42?47, Prague, Czech Re-public, June.D.
McCarthy, R. Koeling, J. Weeds, and J. Carroll.2004.
Finding predominant word senses in untaggedtext.
In ACL ?04: Proceedings of the 42nd AnnualMeeting on Association for Computational Linguis-tics, page 279, Morristown, NJ, USA.
Associationfor Computational Linguistics.R.
Mihalcea and D. I. Moldovan.
2001. eXtendedWordNet: Progress report.
In in Proceedings ofNAACL Workshop on WordNet and Other LexicalResources, pages 95?100.R.
Mihalcea.
2005.
Unsupervised large-vocabularyword sense disambiguation with graph-based algo-rithms for sequence data labeling.
In Proceedings ofHLT05, Morristown, NJ, USA.40R.
Navigli and M. Lapata.
2007.
Graph connectivitymeasures for unsupervised word sense disambigua-tion.
In IJCAI.R.
Navigli and P. Velardi.
2005.
Structural seman-tic interconnections: A knowledge-based approachto word sense disambiguation.
IEEE Trans.
PatternAnal.
Mach.
Intell., 27(7):1075?1086.M.
Palmer, C. Fellbaum, S. Cotton, L. Delfs, and H.T.Dang.
2001.
English tasks: All-words and verblexical sample.
In Proc.
of SENSEVAL-2: SecondInternational Workshop on Evaluating Word SenseDisambiguation Systems, Tolouse, France, July.S.
Pradhan, E. Loper, D. Dligach, and M.Palmer.
2007.Semeval-2007 task-17: English lexical sample srland all words.
In Proceedings of SemEval-2007,pages 87?92, Prague, Czech Republic, June.R.
Sinha and R. Mihalcea.
2007.
Unsupervised graph-based word sense disambiguation using measuresof word semantic similarity.
In Proceedings of theIEEE International Conference on Semantic Com-puting (ICSC 2007), Irvine, CA, USA.B.
Snyder and M. Palmer.
2004.
The English all-wordstask.
In ACL 2004 Senseval-3 Workshop, Barcelona,Spain, July.G.
Tsatsaronis, M. Vazirgiannis, and I. Androutsopou-los.
2007.
Word sense disambiguation with spread-ing activation networks generated from thesauri.
InIJCAI.41
