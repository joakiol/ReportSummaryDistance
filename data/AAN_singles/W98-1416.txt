ATTENTION DURING ARGUMENT GENERATION ANDPRESENTATION*Ingrid Zukerman, Richard McConachy & Kevin B. KorbSchool of  Computer  Science and Software Engineer ingMonash UniversityClayton, Victoria 3168, AUSTRAL IAemail: {ingrid,ricky, korb} @csse.monash.edu.auAbstractWe describe the operation of our argumentation system, and discuss its use of attentional focusduring both content planning and argument presentation.
During content planning, attentional focusguides an abductive process used to build-up arguments.
This process is applied to a model of a user's?
beliefs and a normative model.
During argument presentation, attentional focus supports the generationof enthymematic arguments.1 IntroductionIn this paper, we describe the operation of our argument-generation system, NAG (Nice Argument Gener-ator).
We consider its content planning and argument presentation processes, and discuss the attentionalmechanism used in both of these processes.Given a goal proposition, NAG's objective is to generate a nice argument for it, by which we meanone which achieves a balance between what is normatively justifiable and what persuades the interlocutor.To this end, NAG consults a normative model, which contains our best understanding of the domain ofdiscourse, and a model of the user's beliefs.
The main modules of the system are shown in Figure 1.The Strategist drives the argumentation process.
During argument generation, it activates a generation-analysis cycle as follows (Section 3).
First, it invokes the Attentional Mechanism (Section 4) to activatesalient propositions, which are used to construct an initial Argument Graph for an argument, or to extend analready existing Argument Graph.
(An Argument Graph is a network with nodes that represent propositions,and links that represent the inferences that connect these propositions.)
The Strategist then calls the Gener-ator to continue the argument building process (Section 5).
The Generator in turn fleshes out the ArgumentGraph by activating Reasoning Agents, which consult several sources of information, and incorporating theinferences and propositions returned by these agents into the Argument Graph.
This Argument Graph?
isreturned to the Strategist, which passes it to the Analyzer in order to evaluate its niceness and check forreasoning flaws (Section 6).
If the Analyzer indicates that the argument is not nice enough, i.e., there is notsufficient belief in the?goal in the user or the normative model, then the Strategist re-activates the Generatorin order to find further support for the premises in the argument, and so on.- The generation-analysis cyclecontinues until a sufficiently nice Argument Graph is generated.
This graph is then passed to the Argu-ment Presenter, which selects an argumentation strategy and determines propositions to be removed fromthe argument, aiming to produce asimpler, enthymematic argument.
After each removal, the Presenter acti-vates the Analyzer to check whether theargument is still nice and the Attentional Mechanism to determinewhether the argument can still be followed by the user.Thus, the Attentional Mechanism is used in two different stages of the argumentation process.
Duringargument generation, it focuses the argument construction process on concepts which are related to the"This research was supported in part by Australian Research Council grant A49531227.148IIIIIIil~4i iII!IArgument :r~a~ffnaa~:l I Argument \[Generator" A~ents "l \[ Analyzer I .
.
.
.
.
.
.
.
.
.
I Argument I _ _ _ I ArgumentArgument~,,~~ProG?i~ons A ~ a l y ~ g u m ~  alysisGoal _ I Argument IPresentation Argument Graph l Argument I ArgumentProposition "\[ Strategist ~ .
.
.
.
.
.
.
.
.
.
.
~ 1  Presenter t ~ USERi " - ,q  At tent iona l  ~ i .User Argument/Inquiry/Goal PropositionFigure 1: System Architecturegoal, avoiding some distractions.
During argument presentation, the Attentional Mechanism supports thegeneration of enthymematic arguments.2 Related ResearchCharniak and Goldman (1993) describe a Bayesian plan recognition system that uses marker passing as amethod for focusing attention on a manageable portion of the space of all possible plans.
This is analo-gous to the way in which NAG uses spreading activation to focus on a small portion of the available dataduring the content planning process.
Walker (1996) points out the effect of attentional focus on discoursecomprehension.
This effect is taken into consideration by NAG during argument presentation.The approach of "interpretation asabduction" used in \[Hobbs et al, 1993\].aims to recover the premisesand inferential links which lead to an argument's conclusion.
This is similar to NAG's argument analysis.The most important difference between NAG and the work by Hobbs et al, in addition to NAG being asystem that reasons under uncertainty, is that NAG performs both analysis and generation.
A generativesystem based on the work of Hobbs et al is described in \[Thomason et aL, 1996\].
This system deals withwhat can be readily inferred, and so deleted, during communication, but the generated iscourse does notargue in favour of a proposition.
Mehl (1994) describes a system which can turn an existing fully explicitargument into an enthymematic one, but it cannot generate an argument from constituent propositions.
Thesystem described in \[Horacek, 1997\] generates its own arguments and presents them enthymematically.However, neither process models explicitly a user's attentional state.Like NAG, the systems described in \[Reed and Long, 1997, Huang and Fiedler, 1997\] consider focus ofattention during argument presentation.
NAG differs from these systems in that NAG also uses attentionalfocus to guide the content planning process.
In addition, Reed and Long consider attention in order to gener-ate additional information that makes a concept salient, and Huang and Fiedler use a limited implementationof attentional focus to select which step in a proof should be mentioned next.
In Contrast, NAG uses atten-tional focus during argument presentation to convert a fully explicit argument into an enthymematic one.Finally, Fehrer and Horacek (1997) take advantage of mathematical properties to structure certain types ofmathematical proofs.
They model a user's inferential ability by means of specialized substitution rules, butoffer no mechanism (such as attention in NAG) to limit the number of applications of their rules.3 The Generation-Analysis CycleNAG receives the following inputs: (1) a proposition to be argued for, (2) an initial argument context, and(3) two target ranges of degrees of belief to be achieved (one each for the normative model and the usermodel).
The argument context is composed of salient propositions and concepts appearing in the discussion149preceding the argument or in the current Argument Graph.
The initial argument context, contexto, is com-posed of salient propositions and concepts mentioned in the preamble to the argumen t plus the argument'sgoal.
The degrees of belief to be achieved are expressed as ranges of probabilities, e.g., \[0.5, 0.6\], in order tobe able to represent a variety of goals, e.g., inducing indifference or assent.
Two target ranges are requiredsince the degree of belief to be reached by the user may differ from that reached by the system.When constructing an argument, NAG relies on two collections of information: a normative ?modelcomposed of different types of Knowledge Bases (KBs), and a user model also composed of different typesof KBs, which represent the user's presumed beliefs and inferences.
A KB represents information in asingle format, e.g., semantic network (SN), Bayesian etwork (BN), rule-based system, or database.
TheKBs in the normative and user models are consulted by specialist Reasoning Agents which are activatedwhen trying to fill gaps in a partial argument (Section 5).
The KBs in the user model are consulted to makean argument persuasive for the target audience, while the normative KBs are consulted so that the generatedargument isnormatively correct.
This distinction between the normative correctness and the persuasivenessof an argument enables the system to control the extent o which it will sacrifice normative correctness inorder to be persuasive.
During argument generation, relevant material from several KBs may need to becombined into a common representation.
We have chosen BNs for this purpose because of ?their abilityto represent normatively correct reasoning ?under uncertainty, and because simple alterations of the normalBayesian propagation rules allow us to model various human cognitive phenomena \[Korb et al, 1997\].
?The content planning process produces an Argument Graph which starts from admissible premises andends in the goal proposition.
Admissible premises are normatively acceptable propositions that are believedby NAG and are either believed the user (sufficiently for the argument to work) or assented to by the user.The resultant Argument Graph is then passed to the Presenter.
The argument generation process is imple-mented by the following algorithm, which is executed by the Strategist.Generation-Analysis Algorithm1.
i +-- 0.2.
Clamp nodes in the current context, contexti, and perform spreading activation.
This yields an Argu=ment Graph containing: the clamped nodes, the activated nodes (whose activation exceeds a thresh-old), and the links connecting these nodes.
(Section 4)3.
Identify new subgoals in the current Argument Graph.
These are nodes which have not been previ-ously passed to the Reasoning Agents, and have a path to the goal in the Argument Graph or a highlevel of activation (higher than a subgoaling threshold).4.
Pass the argument subgoals identified in Step 3 to the Generator, which adds the new informationreturned by its Reasoning Agents to the current Argument Graph.
(Section 5)5.
Pass the Argument Graph generated in Step 4 to the Analyzer for evaluation.
(Section 6)6.
If the Analyzer eports that the current Argument Graph is sufficiently nice, then pass the ArgumentGraph to the Presenter.
Otherwise, continue.
(Section 7)7. i+- i+ l .8. contexti +-- contexti_l + new nodes connected to the goal during cycle i-1 +highly activated nodes that are not connected to the goal.9.
Go to Step 2.4 Simulating AttentionNAG uses a hierarchical semantic network built on top of BNs in both the user and normative models to cap-ture connections between the items mentioned in the discourse (Figure 2 illustrates a three-level semantic-Bayesian etwork).
The semantic network portion (upper levels of the pyramid) and the BN portion (baseof the pyramid) are used by NAG to simulate attentional focus in each model.150Iii.IiIIIIHigher level/1~ ~ .,concepts likeI Lower level / / I V , ,  .
~,concepts like / / ~ , /~arge  ammaJ'dinosaur' J ~ SemanticSemantic ~ ~ 7 ~ - ~ - - - ~  2rid layer1st layer - ~ -  o^ - ~ BayesianProposition, e.g., \[widespread iridium deposited 65 mil yrs BC\]Figure 2: Semantic and Bayesian NetworksThe Attentional Mechanism receives as input a context consisting of a set of salient objects.
For contentplanning, the initial context consists of the goal proposition and salient concepts and propositions mentionedin the preamble of the argument; as the content planning process progresses, the context is extended withconcepts and propositions included in the argument.
For argument presentation, the context initially containsthe propositions of the first sub-argument to be presented under a particular presentation strategy, and moveson to different propositions as the presentation of the argument pro~esses (Section 7).We use activation with decay \[Anderson, 1983\], spreading from the current context, to model the focusof attention.
All items in the semantic-Bayesian networks which achieve a threshold activation level duringthe spreading activation process are brought into the current span of attention.
This process passes activationthrough the pyramidal semantic-Bayesian networks, each node being activated to the degree implied by theactivation levels of its neighbours, the strength of association to those neighbours, and its immediately prioractivation level (vitiated by a time-decay factor).
The spreading activation process ceases when an activationcycle fails to activate any new node.
By these means we have a direct implementation f attention whichwe use to identify portions of the pyramidal semantic-Bayesian networks that are strongly related to theargument being built or presented.During content planning, spreading activation is applied to both the semantic-Bayesian pyramid in theuser model and that in the normative model.
This supports the retrieval of information that is semanticallyconnected, and hence likely to be useful for building an argument, from each of the models.
Further,the items in the initial context and in subsequent, extended contexts are clamped, since they are used forreasoning, and their level of activation should not fade as the system reasons about he argument.
In contrast,during argument presentation, spreading activation is performed only in the semantic-Bayesian pyramid inthe user model, and salient information items are not clamped.
This is because we are trying to anticipatethe effect of the information being presented on the addressee, and information presented earlier will fadefrom the addressee's focus of attention \[Walker, 1996\].The Attentional Mechanism offers the following advantages.
During content planning, i t  allows NAGto restrict its search to information semantically or evidentially connected with the propositions already infocus, and it enables NAG to analyze its arguments with respect to just these propositions (Section 6).
Duringargument presentation, it supports the generation of enthymematic arguments by assessing the omission ofpropositions that are in the addressee's span of attention (as a result of the presentation fother propositions).5 Argument ExtensionThe Generator activates the Reasoning Agents to collect information relevant to each of the subgoals in thecurrent Argument Graph (these subgoals were identified in Step 3 of the Generation-Analysis algorithm).The Reasoning Agents determine the relevance of a piece of information to a goal proposition by applying a151I~V5I ~'~in~is:; :exposure,/%I r?ptihrs :haveNn ~2expl~oc throws l widespread~r~.
in to~ :1 i. .
i~,,m.atmosphere :J , is ~o=teaI[ ~ , ~  :strike forms :N~IIN~(a) Initial Argument GraphN7materialobscures suni g herbivorous N~ animals startN5I large ankna~suffer .from: exposure,:NsI reptile s hav(Nlo N. l ~2 ~3I shocked quartz -j----j debHs into 1he ~ , iridium " ~ ~ ~ .
_ ~ ' ~J is deposited I J alto?sphere I I isdep osited I |~- -~>~I ~  I " a.ro~:.. 11  giant crater is II ~ ~ ' ~ t  st~ke forms??
I - 'q  discovered in the Ii ~ f f 3  l J g~anterater ] t Gulf of Mexico ]?
(b) Argumen t Graph after one cycleFigure 3: Argument Graphs for the Asteroid Example during Content Planningprocedure that is appropriate for the KB under consideration.
For instance, if the goal proposition matchesthe consequent of a rule in a rule-based system, the Reasoning Agent for rule-based systems selects thisrule.
The relationships found by the Reasoning Agents represent inferences.
The strength of each inferenceis represented bymeans of conditional probabilities which reflect he degree of belief in the consequent ofan inference given full belief in its antecedents.ExampleThroughout this paper, we consider the generation of an argument for the goal proposition "A large iridium-rich asteroid struck Earth about 65-million-yearsBC;' preceded by the preamble "Approximately 65-million-years BC the dinosaurs, large reptiles that dominated the Earth for many millions of years, became xtinct".Initially, the goal proposition and the preamble activate any propositions containing two or more of theitalicized concepts, i.e., nodes Nr, N13 and N15 (the goal node) in Figure 3(a) (shown in dark grey boxes).After clamping the nodes that correspond to this discourse context and performing spreading activation,additional nodes become activated in the semantic and Bayesian etworks.
All the nodes whose activation?
level exceeds a threshold are added to the Argument Graph.
In this example, this yields the nodes shown in?
light grey boxes in Figure 3(a).
The links between the nodes in Figure 3(a) were obtained from the BN, butthe activation of these nodes involved spreading activation through both the BN and the SN.Since none of the nodes in the current Argument Graph (Figure 3(a)) have been passed to the ReasoningAgents, the following nodes are passed to these agents (through the Generator): those in the subgraphcontaining the goal node (Nil, N15 and N16), plus the two clamped (highly active) nodes in the graphfragments not connected tothe goal node (N6 and Nz3).
The information returned by the Reasoning Agents,which is either causally?
or evidentially connected to the nodes passed to the Generator, is then incorporatedinto the Argument Graph (Figure 3(b)).
Some of the nodes found by these agents have already been activatedthrough spreading activation (shown in light grey in Figures 3(a) and 3(b)), while others are new to theArgument Graph (shown in white in Figure 3(b)).
In addition, the Reasoning Agents added a new linkbetween the previously activated nodes Nlz --~ N12.152!I1II11I1I1IIIIIIII .NI N~~-mo-s~-'pI-a:l--i_.~l.
herbivorousspecies die ' I animals starve kL___-~ .
.
.
.
, - -[-:_ - .
: " - -  - - I  I. large animals :.Il".~lrlt7 DecorIP-.S ~ I : - '~ ; ' : ' -~  " "i:~'t.
.
.
.
.
.
.
.
.
.
~\ I .. :~1I ma,e o,I.
?2:::d~sease~attac: ~all d/,,osa,,~siNio N. | NI2 ~[ .,des~'ead I _ lexp'osion throwsI I widespread .
~shocked quartz ~ debris nto the I '~  iridiumis deposited I I atmosphere I I is deposited,'v'i4 i N/, l N16 N/,,~o,..~ ~.,.
,,,,,.o,; I ~ ~ ~ 1  I asteroid strike I I giant crater is I; o~ s!~o~ked , I~-~k '~ stake forms I-~'-Idiscovered inthe I, n ' I .
giant crater ] I Gulf of Mexico I Qt28~2 I~ ~OtJ,- : "  .
.
.
.
.
.
.
~ l(a) Argument Graph passed to the PresenterI , most plant 1i' specie~ die t i. .
.
.
~ .
.
.
.
.
iNz * N6i .
i Earth becomesL____ I .
.
.
.
.
\ : / .:...,,-.
.
...............,,v7 i ',, N,8N.
I N3rd ~'?si?nthr?ws]ebris into the .~ :latmosphere !~.:1N.
~ N~6 87t ~ ~  I: ::asteroid ' / I  giant crater is I~ ~  :sb:ike forms:: I--D'I discovered in the I~ , ~ ~  ......
I:::glant ctater :: 11  G.,, o, Mexico I(b) Argument Graph after pruningFigure 4: Argument Graphs for the Asteroid Example during Presentation6 Argument AnalysisThe process of computing the anticipated belief in a goal proposition as a result of presenting an argumentstarts with the belief in the premises of the Argument Graph and ends with a new degree of belief in thegoal proposition.
The Analyzer computes the new belief in a proposition by combining the previous beliefin it with the result of applying the inferences which precede this proposition i  the Argument Graph.
Thisbelief computation process is performed by applying Bayesian propagation procedures tothe Bayesian sub-network corresponding tothe current Argument Graph in the user model and separately to the subnetworkcorresponding to the current Argument Graph in the normative model.After propagation, the Analyzer eturns the following measures for an argument: its normative strength,which is its effect on the belief in the goal proposition i  the normative model, and its effectiveness, whichis its effect on the user's belief in the goal proposition (estimated according to the user model).
Of course,an argument's effectiveness may be quite different from its normative strength.
When anticipating an argu-ment's effect upon a user, NAG takes into account hree cognitive rrors that humans frequently succumbto: belief bias, overconfidence and the base rate fallacy [Korb et aL, 1997].If the normative strength or effectiveness of the Argument Graph is insufficient, another cycle of theGeneration-Analysis algorithm is executed, gathering further support for propositions which have a pathto the goal or have a high activation level (Step 3 of the Generation-Analysis algorithm).
In this manner,NAG combines goal-based content planning with t e associative inspection of highly active nodes.
Afterintegrating the new sub-arguments into the Argument Graph (Step 4), the now enlarged Argument Graph isagain sent to the Analyzer (Step 5).
Hence, by completing additional focusing-generation-analysis c cles,Argument Graphs that are initially unsatisfactory are often improved.Example - ContinuedThe argument that can be built at this stage consists of nodes NT, N10-N13 and N15-N17.
However, onlyN13 is admissible among the potential premise nodes.
Thus, the anticipated belief in the goal node in boththe normative and the user model falls short of the desired ranges.
This is reported by the Analyzer to theStrategist.
Nodes NT, Nlo-N12, N16 and N17 are now added to the context (which initially included N6,153N13 and N15), and the next cycle of the Generation-Analysis algorithm starts.
This process continues untilthe Analyzer eports that the belief in the goa !
proposition is inside the target ranges in both the user andthe normative model.
In this example, this happens after two additional generation-analysis cycles, whichactivate nodes N1, N4 and N14 among others (in dashed boxes in Figure 4(a)).7 Argument PresentationAfter a successful Argument Graph has been built, the argument must be structured for presentation to theuser.
This involves electing an argumentation strategy and pruning unnecessary propositions.
These arepropositions that lend little support o the belief in the goal or support he goal beyond what is required(removed by probabilistic pruning), and also intermediate propositions which will be in the addressee'sfocus of attention as a result of information presented earlier, and hence may be omitted (removed bysemantic suppression).
After pruning, the Analyzer (Section 6) is invoked to check whether the belief inthe goal proposition in the now smaller Argument Graph is still within the target ranges; the AttentionalMechanism (Section 4) is invoked to check whether the propositions in the argument are still in focus whenthey are needed.
The following greedy algorithm implements his process.Presentation Algorithm1.
Determine an argumentation strategy.
(Section 7.1)2.
Traverse the Argument Graph according to the strategy selected in Step 1, invoking the AttentionalMechanism to determine the activation level of intermediate propositions.
(Section 7.2)3.
Alternate between probabilistic pruning and semantic suppression until time runs out or until no prun-ing has been successful in the last N consecutive iterations.
(Section 7.3)At present, the resulting argument is in the form of propositions interleaved with causal or eviden-tial relations.?
A graphical interface which allows users to build and receive arguments in an annotatednetwork form (similar to that Shown in Figure 4(b)) is in preparation.
We are also considering the appli-cation of microplanning operators for generating paraphrases and aggregations, such as those described in\[Huang and Fiedler, 1997\], prior to rendering an argument in English.7.1 Determining an Argumentation StrategyThe argumentation strategy determines the order of presentation of the propositions.
Two basic argumen-tation strategies are premise-to-goal and goal-to-premise.
A premise-to-goal argument simply starts at thepremises, goes on to support intermediate propositions, and eventually reaches the goal.
Two types of goal-to-premise arguments are hypothetical, which assume the goal and go from it to the premises (which are suf-ficiently believed), and reductio ad absurdum, which start from the negation of the goal and reach a contra-diction.
NAG selects an argument presentation strategy by examining separately the impact of each individ-ual line of reasoning contributing to the belief in the goal in the Argument Graph \[McConachy etal., 1998\].7.2 Traversing the Argument ?GraphEach argumentation strategy ields a traversal order for the Argument Graph.
The premise-to-goal strategyis implemented bymeans of a post-order t aversal modified by policies which select he order of presentationof sub-arguments.
We consider two policies for presenting sub-arguments for any conclusion inside theArgument Graph: collective and individual-sequential.
In the collective policy, all the current immediateantecedents of a conclusion, i.e., those that remain after pruning (Section 7.3), are mentioned immediatelyprior to mentioning this conclusion.
For examPle, this policy yields the following argument for node E inthe Argument Graph in Figure 5(a): "A is evidence for B, which together with D strongly supports E. ''11The phrases that convey the causal and evidential relations inthe arguments depend on the numerical values in the conditionalprobability ?matrices inthe normative BN, the types of the links and the direction of the argument compared to that of the links.154II!!!IIIIII!IiII!
!w-"A ~ N6~ Nf~..A ~B.~... B--"~-D...~.
A?~ )N4~ N7~ NII"~ NI5c-."
H N6~-- N~ ~,f .
N ,~(a) (b) (c)Figure 5: Sample Argument GraphsThis policy is used when all the antecedents provide similar levels of support for the consequent orwhenthe antecedents are not conditionally independent.
Since the collective policy requires all antecedents tobe mentioned prior to stating the consequent, intermediate conclusions drawn earlier in the argument arementioned again prior to their actual usage.
For example, in the following argument, which corresponds tothe Argument Graph in Figure 5(b), proposition D is repeated prior to its use in arguing H: "A, B and Ccause D. E causes F which in turn causes G. G and D cause H." In the individual-sequential policy, theeffect of one antecedent on the consequent is mentioned first followed by the effect of the other antecedents,e.g., "A is evidence for B, which strongly supports E. D also supports E." ?This policy is used when oneantecedent is conditionally independent from the others, and provides alevel of support that is quite differentfrom that provided by the others.
If an antecedent is selected according to the individual-sequential po icy,the policy selection considerations are again applied to the remaining antecedents.When the collective policy is applied, the sub-arguments are ordered according to the largest-subgraph-first heuristic, which is designed to reduce the number of intermediate conclusions that fade from the focusof attention (due to decay in their activation).
This heuristic states that among several sub-arguments forthe same consequent, the longer sub-arguments, i.e., those containing the largest number of propositions,should be presented before the shorter ones.7.2.1 Activation Levels in the Argument GraphAfter determining a traversal Order for the Argument Graph, the activation level of each proposition iscalculated based on the activation spread from the propositions which NAG has planned to mention so far(taking into account a time decay factor).
As each proposition is "mentioned", activation spreads from it ina pattern which depends on the level of activation of its neighbours and the strength of its association withits neighbours (Section 4).
2 For instance, when a highly connected node is activated, it in turn activates alarge number of nodes, but the activation spread to each node is relatively small, leading to a quick decay inthe activation process.
This process forms a small but densely populated "bubble of attention" around theactivated node \[Taylor, 1998\].
In contrast, when a node with a few connections i  activated, the activationspread to each neighbouring node is stronger, hence the process takes longer to decay, yielding a larger butmore sparsely populated bubble of attention.
Such larger bubbles normally encompass several reasoningsteps in the Argument Graph, thereby enabling NAG to remove intermediate conclusions (Section 7.3).7.3 Pruning the Argument GraphThe Presenter interleaves probabilistic pruning with semantic suppression.
It starts with probabilistic prun-ing, which iteratively removes from the Argument Graph premises that have a relatively small contributionto the belief in their consequents, and also removes entire lines of reasoning which provide more supportfor the goal than what is Strictly necessary in order to achieve abelief within the target ranges.
After eachremoval, the Analyzer is called to check whether the belief in the goal proposition is still within the targetranges.
In addition, affected subgraphs in the Argument Graph are reordered according to the policies men-tioned in Section 7.2 (reordering isnecessary if their relative sizes have changed as a result of the removal of2Nothing is actually mentioned at this stage.
However.
in order to anticipate the effect of an argument, NAG pretends thatpropositions have actually been mentioned.
?155propositions), and the Attentional Mechanism is called to determine whether the remaining propositions stillhave sufficient activation for the addressee tobe able to follow the resulting argument.
Probabilistic pruningfails when the Analyzer eports that the anticipated belief in the goal is outside a target range or when thelevel of activation of a proposition falls below a certain threshold.
In this case, the last removed proposi-tion is reinstated, and semantic suppression is activated.
This process iteratively omits from the ArgumentGraph intermediate conclusions whose level of activation was already high before they were "mentioned",so long as the probabilities of the links from their antecedent totheir consequent are sufficiently strong.
Therationale for this omission is that propositions which are readily inferred, because they have a high level ofactivation and the user attributes them a very high probability on the basis of a simple inference from justmentioned premises, will continue to contribute much of their support o the conclusions that follow them.For instance, if the bubble of attention around node E in the Argument Graph in Figure 5(b) includes nodesF and G, then node F may be omitted, yielding an argument such as "A, B and C cause D. E leads toG, which together with D causes H".
Semantic pruning fails when the level of activation of any requiredsubsequent proposition falls below a threshold.
In this case, the last removed proposition is reinstated, prob-abilistic pruning is reactivated, and the interleaved pruning continues.
These pruning processes continueuntil time runs out Or until both pruning methods have failed several consecutive times.
3Example - ContinuedAfter traversing the Argument Graph according to the premise-to-goal strategy, pruning is performed.
Prob-abilistic pruning removes node N9 in Figure 4(a) as its probability is very low, and hence so is its effect on itsconsequent N6.
The branch containing nodes Nlo and NI4 is removed espite the high probability of thesenodes, because after their omission the probability of the goal proposition is still withinthe target ranges.The branch containing Ns and N6 is removed for the same reason (without removing node N6, since it isstill connected toother nodes in the Argument Graph).
Probabilistic pruning fails after this step, so semanticsuppression is attempted, which removes nodes N2 ~ N3 and N12.
Both types of pruning fail after this step,yielding the Argument Graph in Figure 4(b).
The expanded tree which represents he final ordering of thisArgument Graph appears in Figure 5(c).
The post-order t aversal of this tree yields an argument which maybe roughly paraphrased asfollows.Dinosaurs became xtinct about 65 million years ago.
This could have been caused in part by mostplant species dying.
This could also have been caused in part by reptiles having trouble breeding.This and mostplant species dying was likely caused by the Earth becoming much cooler, which couldhave been caused by material obscuringthe Sun.Many 65 million-year-old iridium deposits (which were found) and material obscuring the Sun couldhave been caused by an explosion throwing debris into the atmosphere.A giant crater which was discovered in the Gulf of Mexico was likely caused by an asteroid strikeforming a giant crater.
This and the explosion debris in the atmosphere were likely caused by a largeiridium-rich asteroid striking Earth 65 million years BC.8 ConclusionNAG uses items in the user's focus of attention to guide a series of generation-analysis cycles which resultin the generation of an Argument Graph that is both normatively acceptable and persuasive.
Attentionalfocus also supports the generation of enthymematic arguments.NAG was written in Common Lisp.
It was tested on five sample scenarios with KBs containing up to200 propositions.
The simulation of attention Via spreading activation generally led to a significant speed-up in content planning times, with little effect on the generated arguments \[Zukerman et al, 1998\].
Contentplanning times slowed down when extremely slow decay factors and low activation thresholds were used3An alternative approach t Ocombining probabilistic pruning and semantic suppression is described in \[McConachy et aL, 1998\].156IIIIII,I:l!!
!i|i1iIi,IIiand when extremely fast decay factors and high activation thresholds were used.
The former incorporatedinto the Argument Graph nodes that were only marginally related to the goal, while the latter incorporatedtoo few nodes, resulting in essentially a goal-based search for an argument.We conducted a preliminary Web-based evaluation of NAG's content planning component.
This evalua-tion consisted of giving respondents pre-test questions regarding certain propositions in an asteroid argumentsimilar to that discussed in this paper, and then presenting them with hand-generated renditions of an aster-oid argument which took into account he responses to these questions.
A post-test was used to determinethe effect of the argument.
This test showed a clear tendency among the respondents toshift belief towardsthe targets as a result of NAG's argument.
A more rigorous evaluation of the content planning componentand an evaluation of the argument presentation component will be performed in the next months.References\[Anderson, 1983\] Anderson, J. R. (1983).
The Architecture of Cognition.
Harvard University Press, Cambridge,Massachusetts.\[Charniak and Goldman, 1993\] Charniak, E. and Goldman, R. P. (1993).
A Bayesian model of plan recognition.Artificial Intelligence, 64(1):50-56.\[Fehrer and Horacek, 1997\] Fehrer, D. and Horacek, H. (1997).
Exploiting the addressee's inferential capabilitiesin presenting mathematical proofs.
In IJCAI97- Proceedings of the Fifteenth International Joint Conference onArtificial Intelligence, pages 959-964, Nagoya, Japan.\[Hobbs et al, 1993\] Hobbs, J. R., Stickel, M. E., Appelt, D. E., and Martin, P. (1993).
Interpretation as abduction.Artificial Intelligence, 63(1-2):69-142.\[Horacek, 1997\] Horacek, H. (1997).
A model for adapting explanations tothe user's likely inferences.
User Model-ing and User-Adapted Interaction, 7(1): 1-55.\[Huang and Fiedler, 1997\] Huang, X. and Fiedler, A.
(1997).
Proof verbalization.as n application of NLG.
InHCAI97 - Proceedings of the Fifteenth International Joint Conference on Artificial Intelligence, pages?
965-970,Nagoya, Japan.\[Korb et al, 1997\] Korb, K. B., McConachy, R., and Zukerman, I.
(1997).?
A cognitive model of argumentation.In Proceedings of the Nineteenth Annual Conference of the Cognitive Science Society, pages 400--405, Stanford,Califomia.\[McConachy et al, 1998\] McConachy, R., Korb, K. B., and Zukerman, I.
(1998).
Deciding what not to say: Anattentional-probabilistic approach to argument presentation.
InProceedings of the Twentieth Annual Conference ofthe Cognitive Science Society, Madison, Wisconsin.\[Mehl, 1994\] Mehl, S. (1994).
Forward inferences in text generation.
?
In ECAI94 - Proceedings of the EleventhEuropean Conference on Artificial Intelligence, pages 525-529, Amsterdam, The Netherlands.\[Reed and Long, 1997\] Reed, C. and Long, D. (1997).
Content ordering in the generation of persuasive discourse.
InIJCAI97- Proceedings of the Fifteenth International Joint Conference on Artificial Intelligence, pages 1022-1027,Nagoya, Japan.\[Taylor, 1998\] Taylor, J.
(1998).
Constructing the relational mind.
Psyche, 4. http://psyche.cs.monash.edu.au/v4.\[Thomason et al, 1996\] Thomason, R. H., Hobbs, J. R., and Moore, J. D. (1996).
Communicative goals.
In Pro-ceedings of ECAI-96 Workshop - Gaps and Bridges: New Directions hi Planning and NLG, pages 7-12, Budapest,Hungary.\[Walker, 1996\] Walker, M. A.
(1996).
The effect of resource limits and task complexity on collaborative planning indialogue.
Artificial Intelligence, 85:181-243.\[Zukerman et al, !998\] Zukerman, I. McConachy, R., and Korb, K. B.
(1998).
Bayesian reasoning in an abductivemechanism for argument generation and analysis.
In AAAI98 - Proceedings of the Fifteenth National Conferenceon Artificial Intelligence, Madison, Wisconsin.157
