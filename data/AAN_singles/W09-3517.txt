Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 80?83,Suntec, Singapore, 7 August 2009. c?2009 ACL and AFNLPEnglish to Hindi Machine Transliteration System at NEWS 2009Amitava Das, Asif Ekbal, Tapabrata Mandal and Sivaji BandyopadhyayComputer Science and Engineering DepartmentJadavpur University, Kolkata-700032, Indiaamitava.research@gmail.com, asif.ekbal@gmail.com, ta-pabratamondal@gmail.com, sivaji_cse_ju@yahoo.comAbstractThis paper reports about our work in theNEWS 2009 Machine Transliteration SharedTask held as part of ACL-IJCNLP 2009.
Wesubmitted one standard run and two non-standard runs for English to Hindi translitera-tion.
The modified joint source-channel modelhas been used along with a number of alterna-tives.
The system has been trained on theNEWS 2009 Machine Transliteration SharedTask datasets.
For standard run, the systemdemonstrated an accuracy of 0.471 and themean F-Score of 0.861.
The non-standard runsyielded the accuracy and mean F-scores of0.389 and 0.831 respectively in the first oneand 0.384 and 0.828 respectively in the secondone.
The non-standard runs resulted in sub-stantially worse performance than the standardrun.
The reasons for this are the ranking algo-rithm used for the output and the types of to-kens present in the test set.1 IntroductionTechnical terms and named entities (NEs) consti-tute the bulk of the Out Of Vocabulary (OOV)words.
Named entities are usually not found inbilingual dictionaries and are very generative innature.
Proper identification, classification andtranslation of Named entities (NEs) are very im-portant in many Natural Language Processing(NLP) applications.
Translation of NEs involvesboth translation and transliteration.
Translitera-tion is the method of translating into another lan-guage by expressing the original foreign wordusing characters of the target language preserv-ing the pronunciation in their source language.Thus, the central problem in transliteration ispredicting the pronunciation of the original word.Transliteration between two languages that usethe same set of alphabets is trivial: the word isleft as it is.
However, for languages those usedifferent alphabet sets the names must be transli-terated or rendered in the target language alpha-bets.
Transliteration of NEs is necessary in manyapplications, such as machine translation, corpusalignment, cross-language Information Retrieval,information extraction and automatic lexiconacquisition.
In the literature, a number of transli-teration algorithms are available involving Eng-lish (Li et al, 2004; Vigra and Khudanpur, 2003;Goto et al, 2003), European languages (Marinoet al, 2005) and some of the Asian languages,namely Chinese (Li et al, 2004; Vigra and Khu-danpur, 2003), Japanese (Goto et al, 2003;Knight and Graehl, 1998), Korean (Jung et al,2000) and Arabic (Al-Onaizan and Knight,2002a; Al-Onaizan and Knight, 2002c).
Recent-ly, some works have been initiated involvingIndian languages (Ekbal et al, 2006; Ekbal et al,2007; Surana and Singh, 2008).2 Machine Transliteration SystemsThree transliteration models have been used thatcan generate the Hindi transliteration from anEnglish named entity (NE).
An English NE isdivided into Transliteration Units (TUs) withpatterns C*V*, where C represents a consonantand V represents a vowel.
The Hindi NE is di-vided into TUs with patterns C+M?, where Crepresents a consonant or a vowel or a conjunctand M represents the vowel modifier or matra.The TUs are the lexical units for machine transli-teration.
The system considers the English andHindi contextual information in the form of col-located TUs simultaneously to calculate the plau-sibility of transliteration from each English TUto various Hindi candidate TUs and chooses theone with maximum probability.
This is equiva-lent to choosing the most appropriate sense of aword in the source language to identify its repre-sentation in the target language.
The systemlearns the mappings automatically from the bi-lingual NEWS training set being guided by lin-80guistic features/knowledge.
The system consid-ers the linguistic knowledge in the form of con-juncts and/or diphthongs in English and theirpossible transliteration in Hindi.
The output ofthe mapping process is a decision-list classifierwith collocated TUs in the source language andtheir equivalent TUs in collocation in the targetlanguage along with the probability of each deci-sion obtained from the training set.
Linguisticknowledge is used in order to make the numberof TUs in both the source and target sides equal.A Direct example base has been maintained thatcontains the bilingual training examples that donot result in the equal number of TUs in both thesource and target sides during alignment.
TheDirect example base is checked first during ma-chine transliteration of the input English word.
Ifno match is obtained, the system uses direct or-thographic mapping by identifying the equivalentHindi TU for each English TU in the input andthen placing the Hindi TUs in order.
The transli-teration models are described below in which Sand T denotes the source and the target wordsrespectively:?
Model AThis is essentially the joint source-channel model(Hazhiou et al, 2004) where the previous TUswith reference to the current TUs in both thesource (s) and the target sides (t) are consideredas the context.11( | ) ( , | , )k kkKP S T P s t s t?== < > < >?
( ) arg max { ( ) ( | )}S T S P T P S TT?
= ??
Model BThis is basically the trigram model where theprevious and the next source TUs are consideredas the context.1, 11( | ) ( , | )k k kkKP S T P s t s s?
+== < >?
( ) arg max { ( ) ( | )}S T S P T P S TT?
= ??
Model CIn this model, the previous and the next TUs inthe source and the previous target TU areconsidered as the context.
This is the  improvedmodified joint source-channel model.1, 11( | ) ( , | , )k k kkKP S T P s t s t s?
+== < > < >?
( ) arg max { ( ) ( | )}S T S P T P S TT?
= ?For NE transliteration, P(T), i.e., theprobability of transliteration in the targetlanguage, is calculated from a English-Hindibilingual database of approximately 961,890English person names, collected from the web1.If, T is not found in the dictionary, then a verysmall value is assigned to P(T).
These modelshave been desribed in details in Ekbal et al(2007).?
Post-ProcessingDepending upon the nature of errors involved inthe results, we have devised a set of translitera-tion rules.
A few rules have been devised to pro-duce more spelling variations.
Some examplesare given below.Spelling variation rulesBadlapur ???????
| ??????
?Shree | Shri ?3 Experimental ResultsWe have trained our transliteration models usingthe English-Hindi datasets obtained from theNEWS 2009 Machine Transliteration SharedTask (Li et al, 2009).
A brief statistics of thedatasets are presented in Table 1.
Out of 9975English-Hindi parallel examples in the trainingset, 4009 are multi-words.
During training, wehave split these multi-words into collections ofsingle word transliterations.
It was observed thatthe number of tokens in the source and targetsides mismatched in 22 multi-words and thesecases were not considered further.
Following aresome examples:Paris Charles de Gaulle ????????
?
?? ?
????
?South Arlington Church ofChrist ????
??
?
?In the training set, some multi-words were partlytranslated and not transliterated.
Such exampleswere dropped from the training set.
Finally, thetraining set consists of 15905 single word Eng-lish-Hindi parallel examples.1http://www.eci.gov.in/DevForum/Fullname.asp81Set Number of examplesTraining 9975Development 974Test 1000Table 1.
Statistics of DatasetThe output of the modified joint source-channel model is given more priority during out-put ranking followed by the trigram and the jointsource-channel model.
During testing, the Directexample base is searched first to find the transli-teration.
Experimental results on the develop-ment set yielded the accuracy of 0.442 and meanF-score of 0.829.
Depending upon the nature oferrors involved in the results, we have devised aset of transliteration rules.
The use of these trans-literation rules increased the accuracy and meanF-score values up to 0.489 and 0.881 respective-ly.The system has been evaluated for the test setand the detailed reports are available in Li et al(2009).
There are 88.88% unknown examples inthe test set.
We submitted one standard run inwhich the outputs are provided for the modifiedjoint source-channel model (Model C), trigrammodel (Model B) and joint source-channel model(Model A).
The same ranking procedure (i.e.,Model C, Model B and Model A) has been fol-lowed as that of the development set.
The outputof each transliteration model has been post-processed with the set of transliteration rules.
Foreach word, three different outputs are provided ina ranked order.
If the outputs of any two modelsare same for any word then only two outputs areprovided for that particular word.
Post-processing rules generate more number of possi-ble transliteration output.
Evaluation results ofthe standard run are shown in Table 2.Parameters AccuracyAccuracy in top-1 0.471Mean F-score 0.861Mean Reciprocal Rank(MRR)0.519Mean Average Preci-sion (MAP)ref0.463MAP10 0.162MAPsys 0.383Table 2.
Results of the standard runThe results of the two non-standard runs arepresented in Table 3 and Table 4 respectively.Parameters AccuracyAccuracy in top-1 0.389Mean F-score 0.831Mean Reciprocal Rank(MRR)0.487Mean Average Preci-sion (MAP)ref0.385MAP10 0.16MAPsys 0.328Table 3.
Results of the non-standard run 1Parameters AccuracyAccuracy in top-1 0.384Mean F-score 0.823Mean Reciprocal Rank(MRR)0.485Mean Average Precision(MAP)ref0.380MAP10 0.16MAPsys 0.325Table 4.
Results of the non-standard run2In both the non-standard runs, we have usedan English-Hindi bilingual database of approx-imately 961, 890 examples that have been col-lected from the web2.
This database contains the(frequency) of the corresponding English-Hindiname pair.
Along with the outputs of three mod-els, the output obtained from this bilingual data-base has been also provided for each Englishword.
In the first non-standard run, only the mostfrequent transliteration has been considered.
But,in the second non-standard run all the possibletransliteration have been considered.
It is to benoted that in these two non-standard runs, thetransliterations obtained from the bilingual data-base have been kept first in the ranking.
Resultsof the tables show quite similar performance inboth the runs.
But the non-standard runs resultedin substantially worse performance than the stan-dard run.
The reasons for this are the rankingalgorithm used for the output and the types oftokens present in the test set.
The additional da-2http://www.eci.gov.in/DevForum/Fullname.asp82taset used for the non-standard runs is mainlycensus data consisting of only Indian personnames.
The NEWS 2009 Machine TransliterationShared Task training set is well distributed withforeign names (Ex.
Sweden, Warren), commonnouns (Mahfuz, Darshanaa) and a few nonnamed entities.
Hence the training set for thenon-standard runs was biased towards the Indianperson name transliteration pattern.
Additionaltraining set was quite larger (961, 890) than theshared task training set (9,975).
Actually outputsof non-standard runs have more alternative trans-literation outputs than the standard set.
Thatmeans non-standard sets are superset of standardset.
Our observation is that the ranking algorithmused for the output and biased training are themain reasons for the worse performance of thenon-standard runs.4 ConclusionThis paper reports about our works as part of theNEWS 2009 Machine Transliteration SharedTask.
We have used the modified joint source-channel model along with two other alternativesto generate the Hindi transliteration from an Eng-lish word (to generate more spelling variations ofHindi names).
We have also devised some post-processing rules to remove the errors.
Duringstandard run, we have obtained the word accura-cy of 0.471 and mean F-score of 0.831.
In non-standard rune, we have used a bilingual databaseobtained from the web.
The non-standard runsyielded the word accuracy and mean F-scorevalues of 0.389 and 0.831 respectively in the firstrun and 0.384 and 0.823 respectively in thesecond run.ReferencesAl-Onaizan, Y. and Knight, K. 2002a.
NamedEntity Translation: Extended Abstract.
InProceedings of the Human Language Tech-nology Conference, 122?
124.Al-Onaizan, Y. and Knight, K. 2002b.
Translat-ing Named Entities using Monolingual andBilingual Resources.
In Proceedings of the40th Annual Meeting of the ACL, 400?408,USA.Ekbal, A. Naskar, S. and Bandyopadhyay, S.2007.
Named Entity Transliteration.
Interna-tional Journal of Computer Processing ofOriental Languages (IJCPOL), Volume(20:4), 289-310, World Scientific PublishingCompany, Singapore.Ekbal, A., Naskar, S. and Bandyopadhyay, S.2006.
A Modified Joint Source ChannelModel for Transliteration.
In Proceedings ofthe COLING-ACL 2006, 191-198, Australia.Goto, I., Kato, N., Uratani, N. and Ehara, T.2003.
Transliteration Considering ContextInformation based on the Maximum EntropyMethod.
In Proceeding of the MT-SummitIX, 125?132, New Orleans, USA.Jung, Sung Young , Sung Lim Hong and EunokPaek.
2000.
An English to Korean Translite-ration Model of Extended Markov Window.In Proceedings of International Conferenceon Computational Linguistics (COLING2000), 383-389.Knight, K. and Graehl, J.
1998.
Machine Transli-teration, Computational Linguistics, Volume(24:4), 599?612.Kumaran, A. and Tobias Kellner.
2007.
A gener-ic framework for machine transliteration.
InProc.
of the 30th SIGIR.Li, Haizhou, A Kumaran, Min Zhang and Vla-dimir Pervouchine.
2009.
Whitepaper ofNEWS 2009 Machine Transliteration SharedTask.
In Proceedings of ACL-IJCNLP 2009Named Entities Workshop (NEWS 2009), Sin-gapore.Li, Haizhou, A Kumaran, Vladimir Pervouchineand Min Zhang.
2009.
Report on NEWS 2009Machine Transliteration Shared Task.
In Pro-ceedings of ACL-IJCNLP 2009  amed EntitiesWorkshop (NEWS 2009), Singapore.Li, Haizhou, Min Zhang and Su Jian.
2004.
AJoint Source-Channel Model for MachineTransliteration.
In Proceedings of the 42ndAnnual Meeting of the ACL, 159-166.
Spain.Marino, J.
B., R. Banchs, J. M. Crego, A. deGispert, P. Lambert, J.
A. Fonollosa and M.Ruiz.
2005.
Bilingual n-gram StatisticalMachine Translation.
In Proceedings of theMT-Summit X, 275?282.Surana, Harshit, and Singh, Anil Kumar.
2008.
AMore Discerning and Adaptable MultilingualTransliteration Mechanism for Indian Lan-guages.
In Proceedings of the 3rd Interna-tional Joint Conference on Natural Lan-guage Processing (IJCNLP-08), 64-71, In-dia.Vigra, Paola and Khudanpur, S. 2003.
Translite-ration of Proper Names in Cross-Lingual In-formation Retrieval.
In Proceedings of theACL 2003 Workshop on Multilingual andMixed-Language Named Entity Recognition,57?60.83
