Coling 2010: Poster Volume, pages 1229?1237,Beijing, August 2010Learning Web Query Patterns for Imitating Wikipedia ArticlesShohei Tanaka?tanaka@mi.ci.i.u-tokyo.ac.jpNaokaki Okazaki?okazaki@is.s.u-tokyo.ac.jpMitsuru Ishizuka?ishizuka@i.u-tokyo.ac.jp?Graduate School of InformationScience and TechnologyUniversity of Tokyo?Interfaculty Initiative inInformation StudiesUniversity of TokyoAbstractThis paper presents a novel method for ac-quiring a set of query patterns to retrievedocuments containing important informa-tion about an entity.
Given an existingWikipedia category that contains the tar-get entity, we extract and select a smallset of query patterns by presuming thatformulating search queries with these pat-terns optimizes the overall precision andcoverage of the returned Web informa-tion.
We model this optimization prob-lem as a weighted maximum satisfiabil-ity (weighted Max-SAT) problem.
Theexperimental results demonstrate that theproposed method outperforms other meth-ods based on statistical measures such asfrequency and point-wise mutual informa-tion (PMI), which are widely used in rela-tion extraction.1 IntroductionWikipedia1 is useful for obtaining comprehensiveinformation of entities and concepts.
However,even with 3.3 million English articles, Wikipediadoes not necessarily include articles about an en-tity and concept of interest to a user.
The ultimategoal of this study is to generate articles about anentity of a specified category from the Web by us-ing Wikipedia articles in the same entity categoryas exemplars.This study follows previous work of theother authors on query-biased/focused summa-rization (Tombros and Sanderson, 1998; Berger1http://en.wikipedia.org/and Mittal, 2000) for modeling the target articlegeneration process.
In that model, when a user in-puts an entity of interest, Web pages are retrievedthat describe the entity by issuing queries to aninformation retrieval system.
Using the retrievedpages as an information source, an article (sum-mary) can be produced specialized for the targetentity.
From the application point of view, the arti-cle should include the concepts that best describethe target entity.
In addition, articles concerningthe entities of a category should cover conceptsthat are typical of the category.
For example, anarticle about an actor is expected to mention hisnationality, date of birth, movie credits, awards,etc.A great number of researchers have ad-dressed the problem of query-focused summariza-tion (Carbonell and Goldstein, 1998; White etal., 2003; Dang, 2005; Daume?
and Marcu, 2006;Varadarajan and Hristidis, 2006; Fuentes et al,2007; Gupta et al, 2007; Wang et al, 2007; Ka-nungo et al, 2009).
However, these studies as-sume that a document collection is provided forthe summarization systems.
In other words, col-lecting source documents that include importantconcepts for the target entity is not in the scopeof these studies.
For example, queries such as?
(actor) was born in,?
?
(actor) born on,?
?(actor)plays,?
and ?
(actor) won?
may be more suitablethan the simple query ?(actor)?
for obtaining con-cepts concerning the actor.Source documents can be collected by a simi-lar idea in relation extraction, which extracts en-tities having specific relations with the target en-tity (Hearst, 1992; Brin, 1999; Agichtein and Gra-vano, 2000; Turney, 2001; Pantel and Pennac-1229chiotti, 2006; Blohm et al, 2007).
These stud-ies typically use statistical measures, such as fre-quency and point-wise mutual information (PMI),to assess the scores of the query patterns.
How-ever, these studies cannot eliminate the redun-dancy of concepts retrieved by a query set becausethey are designed to extract entities for each rela-tion independently.
For example, the query ?
(ac-tor) born on?
would not be necessary if the query?
(actor) was born in?
could gather documents re-ferring to both the actor?s nationality and date ofbirth.In this paper, we propose a novel method foracquiring a set of high-quality query patterns thatcan gather source documents referring to impor-tant concepts about a specified entity.
Given acategory in which the entity is expected to be in-cluded, we use existing Wikipedia articles in thiscategory to extract query patterns so that, whenused together with the entity, they can retrieve im-portant concepts related to the entity.
We thenselect a small subset of query patterns that max-imize the coverage and precision of the query re-sult by modeling the query selection task as aweighted maximum satisfiability (weighted Max-SAT) problem.2 Proposed methodFirst, let us define the terminology used in thispaper.
An entity is a topic for which we need toobtain an article (summary).
Note that this defi-nition is different from that used in other studies(e.g., named entity recognition).
A concept is anoun phrase that has a specific relation to an en-tity.
A query pattern is a lexical pattern that con-tains a slot filled by an entity.
Used with an entity,a query pattern instantiates a query that collectsrelated concepts.
For example, ?X was born in?
isa query pattern in which X is a slot.
When replac-ing X with an entity (e.g., ?Dustin Hoffman?
), thequery pattern instantiates a query that may returnthe birthplace.The goal of this study is, for a given entitycategory (e.g., American actor), to acquire a setof query patterns (template) for collecting relatedconcepts from the Web.
We learn the template byusing Wikipedia articles of the category as super-vision data.
The method consists of three steps.1.
Triplet extraction identifies, for eachWikipedia article, entity mentions, concepts,and phrases that form a bridge between theentity mentions and concepts.
In the contextof learning query patterns from Wikipedia,we assume that a Wikipedia article is writ-ten for an entity.
By identifying entity men-tions and concepts in the article, we ob-tain bridging phrases between entity men-tions and concepts as candidates for querypatterns.2.
Pattern assessment verifies whether eachcandidate query pattern can actually retrieveconcepts from the Web.
This step issuesqueries of the form ?
(entity) (pattern)?
to aninformation retrieval system, analyzes the re-trieved Web pages, and examines whethereach concept is found in the same sentenceas the query expressions.3.
Pattern selection obtains a template bychoosing a small subset of patterns such thatthe retrieved Web pages contain as manykinds of concepts as possible.
We also elimi-nate query patterns that can retrieve descrip-tions other than concepts.
We formalize thisstep as a weighted Max-SAT problem.2.1 Triplet extractionWe first analyze Wikipedia articles to extracttriplets of entities, query patterns, and concepts.Because a Wikipedia article usually describes asingle entity, we identify the entity from the ti-tle of the article.
We then search for occurrencesof the entity in the body of the article.
How-ever, we might need to resolve coreference expres-sions because the entity might be described by anumber of surface variations.
For example, theWikipedia article titled ?Dustin Hoffman?
mightrefer to the entity using ?he?
and ?Hoffman?
aswell as ?Dustin Hoffman?
; the entity ?MicrosoftCorporation?
might be described by ?Microsoft?and ?the company?
in the article.In general, coreference resolution is a non-trivial NLP task.
Fortunately, Wikipedia articlesare written for target entities.
Therefore, we re-place the occurrences of the following expressionsin the body with the entity name:1230 Hoffman was born in [Los Angeles], [California], thesecond and youngest son of Lillian and Harry Hoffman,a [Russian]-born father who worked as a prop supervi-sor/set decorator at [Columbia Pictures] before becom-ing a furniture salesman.
Hoffman is from a [Jewish]family, although he did not have a religious upbring-ing.
He graduated from [Los Angeles High School] in1955.
He enrolled at [Santa Monica College] with theintention of studying medicine but left after a year tojoin the [Pasadena Playhouse]. Figure 1: A snippet of a Wikipedia article about?Dustin Hoffman.?1.
Any token (split by spaces) that appears inthe title of the article.2.
The phrase that appears the most frequentlywith the four anaphoric expressions ?he,??she,?
?they,?
and ?the noun.
?The first rule deals with anaphoric expressioncaused by an ellipsis, e.g., ?Dustin Hoffman?
isreferred to by ?Dustin?
and ?Hoffman.?
Thesecond rule resolves the coreference expressionscaused by pronouns and definite noun phrases.After detecting the entity mentions, we identifythe concepts concerning the entity in the article.In this study, we employ WikiLink texts (anchortexts linked with other Wikipedia articles) that co-occur with the entity mentions in the same sen-tences.
Finally, we identify a candidate of a querypattern as a phrase that satisfies the following con-ditions:1.
It consists of alphanumeric letters and hy-phens only.2.
Its length is no longer than 6 tokens.3.
It appears between an entity mention and aconcept in a sentence.Figure 1 shows a snippet of the Wikipedia articleabout ?Dustin Hoffman.?
The underlined expres-sions are identified as entity mentions; the text insquare brackets represents a WikiLink text.
Be-cause all WikiLink texts appear in sentences withthe entity mentions, we identify all expressionswith square brackets as concepts.
Italic texts arecandidates of the query patterns.Finally, we extract triplets of the form?Ek,Pi,C j?
from the Wikipedia article, whereTable 1: Triplets extracted from Figure 1.Entity Query pattern conceptDustin Hoffman was born in Los AngelesDustin Hoffman was born in CaliforniaDustin Hoffman was born in RussianDustin Hoffman was born in Columbia PicturesDustin Hoffman is from a JewishDustin Hoffman graduated from Los Angeles High SchoolDustin Hoffman enrolled at Santa Monica CollegeDustin Hoffman enrolled at Pasadena PlayhouseEk (k ?
{1, ...,L}) denotes the entity, Pi (i ?
{1, ...,M}) denotes a query pattern, and C j ( j ?
{1, ...,N}) denotes a concept.
For each conceptC jfound in the Wikipedia article, we build a tripletby setting Ek as the entity of the article and Pjas the query pattern that precedes the concept C j.Repeating this process for L Wikipedia articles inthe same category, we obtain triplets withM querypatterns and N concepts.Table 1 shows the eight triplets obtained fromFigure 1.
Here, it might not be clear whetherthe indefinite article a is necessary in the patternis from a.
Although we do not address this is-sue directly in this paper, we determine the pop-ularity and usefulness of the pattern by analyzingWikipedia articles in the same category.
Similarly,some concepts (e.g., Russian) are not so impor-tant for the entity.
It may be better to filter out theconcept, but we expect that errors in concept iden-tification are negligible when selecting the querypatterns.2.2 Pattern assessmentIn this step, we verify whether each pattern Pi canactually retrieve concepts of the entities from theWeb.
More specifically, for every combination ofan entity mention Ek and a pattern Pi, we issue aquery ?Ek Pi?
(e.g., ?Dustin Hoffman graduatedfrom?)
to Yahoo!
Search BOSS2.
We downloadthe top 10 Web pages retrieved by each query andexamine whether any of the concepts, C j, appearin the same sentence as the query phrase.
To de-scribe the capability of the patterns for retrievingconcepts, we introduce an m?n matrix called R,Ri j ={1 (pattern Pi can retrieve concept C j)0 (otherwise) .2http://developer.yahoo.com/search/boss/1231DVDthe Newsblogswon the Academy Awardwas born inCaliforniaLos Angeles1 9 3 7Dustin Hoffmangraduated fromgrew up ininL.A.
High SchoolFigure 2: Patterns ?
collected concepts graph.Figure 2 illustrates a bipartite graph betweenthe patterns and concepts with R as the biadja-cency matrix.
Here, nodes with dotted lines areexpressions other than concepts but are retrievedby the patterns.
For example, the pattern ?in?
canretrieve four concepts Academy Award, Califor-nia, Los Angeles, and 1937, but it also retrievesnon-concepts such as DVD, the News, and blogs.In other words, this pattern can retrieve sentenceswith a number of concepts, but it also gathers un-necessary sentences.
Thus, we define the errorrate of pattern Pi?i = 1?
(# sentences with concepts)(# total sentences retrieved by Pi) .2.3 Pattern selectionBased on the pattern assessment in Section 2.2,this step chooses a small set of query patterns asthe template.
Let w1, ...,wm denote m Boolean (0?1 integer) variables, each of which (wi) indicateswhether the corresponding query pattern Pi is se-lected (1) or unselected (0).
Choosing a subset ofquery patterns is equivalent to assigning Booleanvalues to the variables w1, ...,wm.
The number ofselected patterns is ?mi=1wi.Given an assignment of variables w1, ...,wm forthe query patterns, we can examine whether theconcept C j is retrieved from the patterns by usingthe logical sum,c j = w1R1 j ?w2R2 j ?
...?wmRmj =m?i=1wiRi j.Here, c j is a Boolean (0?1) variable indicating thatconcept C j is retrieved (1) or not retrieved (0) bythe template.
In Figure 2, if either the ?in?
or ?wasborn in?
pattern is selected, we can retrieve theconcept ?1937?
from the Web search.To choose a set of query patterns, we maxi-mize the number of concept coverages ?nj=1 c j aswell as minimize the number of patterns selected?mi=1wi and the total of the error rates of the se-lected patterns?mi=1 ?iwi.
This is achieved by solv-ing the following problem.Problem 1.Maximizen?j=1c j ?
?m?i=1wi ?
?m?i=1?iwi,subject to: c1 =m?i=1wiRi1...cn =m?i=1wiRin,wi ?
{0,1}.Here, ?
and ?
are the parameters for control-ling the preference of a smaller number of patterns(?)
and the preference of accurate patterns (?
).To solve this problem, we rewrite it as aweighted maximize satisfiability (weighted Max-SAT) problem.Problem 2.Maximizen+m?k=1?kxkSubject to: x1 =m?i=1wiRi1 (?1 = 1)... (...)xn =m?i=1wiRin (?n = 1)xn+1 = ?w1 (?n+1 = ?+??1)...
(...)xn+m = ?wm (?n+m = ?+?
?m)wi ?
{0,1}Instead of subtracting the penalty terms fromthe objective value, we give bonus weights (?
+?
?i) if the pattern Pi is not selected.
This isachieved by introducing additional clauses xn+1,..., xn+m that are satisfied by ?w1, ..., ?wm, respec-tively.
Therefore, the optimization process triesto find a compromise between selecting patterns(clauses x1, ..., xn) and rejecting patterns (clausesxn+1, ..., xn+m).
Although the complexity of theweighted Max-SAT problem is NP-hard, we useMiniMaxSAT (Heras et al, 2008) to solve theproblem.12323 EvaluationTo verify the performance of the proposedmethod, we compare the precision, coverage,and F?-score of the information retrieval processby using the template obtained by the proposedmethod with that by three other baseline methods.3.1 Experimental Settings3.1.1 DataWe use articles of five categories in Wikipediaas the data for evaluation: American actors, Ge-netic disorders, American tennis players, Soft-ware companies, and Operas.
Among these cat-egories, the first two (American actors, Geneticdisorders) have been commonly used as evalua-tion data in previous research on text summariza-tion (Sauper and Barzilay, 2009).
The other three(American tennis players, Software companies,Operas) are categories about three distinct topics(sport, business, entertainment).Table 2 shows in-formation about these categories.We divide the article set of a given category intosix subsets.
We use one subset as the developmentset for tuning the parameters ?
and ?
in the pro-posed method.
The remaining five subsets are thetraining set and the test set, which are used for the5-fold cross-validation.
We create the template byusing the training set and evaluate it with the testset.
For evaluation of the baseline methods, weuse only the training set and the test set.3.1.2 BaselinesRandom SelectionThe baseline ?Random Selection?
randomly se-lects 10 query patterns from the candidate querypatterns as the template for the category.FrequencyIn this baseline method, we sort the query patternsfor each category in the order of frequency of oc-currences in the category.
We then select the top10 frequent query patterns as the template for thecategory.PMI-WebThe baseline PMI-Web chooses the query patternsthat are the most ?reliable.?
Following KnowIt-Now (Cafarella et al, 2005) and Espresso (Pan-tel and Pennacchiotti, 2006), the ?reliability?
of aTable 2: The five categories used for evaluation.Category #Articles #Patterns #ConceptsAmerican actors 1864 2951 10495American tennis players 444 1039 2826Software companies 1890 1992 5087Genetic disorders 657 1087 2400Operas 1425 2125 6365Figure 3: Relation between coverage and querypattern frequency.pattern is defined by using the strength of the as-sociation of the pattern with the entities and con-cepts co-occurring with the pattern.
In KnowIt-Now and Espresso, PMI (point-wise mutual infor-mation) is used to measure the strength of this as-sociation.
PMI is estimated with the Web searchhit counts as follows:pmi(Ek,Pi,C j)?
hit(Ek,Pi,C j)hit(Ek,Pi) ?hit(C j) ,where hit(EkPi), hit(C j) are the Web search hitcounts for the query ?Ek, Pi,?
?C j?
(Ek,Pi,C j is en-tity, pattern, concept), and hit(Ek,Pi,C j) is the hitcount for the query ?Ek Pi?
and ?C j.?
The relia-bility score of the query pattern is defined as thefollowing formula:Score(Pi) = 1|S| ?
(Ek,C j)?S pmi(Ek,Pi,C j),where S is the set of pairs of entity Ek and conceptC j co-occurring with the pattern Pi in a sentence.The method PMI-Web chooses the top 10 patternsthat have the highest reliability scores.3.1.3 ExperimentsWe use each method to generate a template andretrieve information of the entities by using the1233query patterns in the template.
We remove thequery patterns occurring only once in each cat-egory from the candidate patterns because thesepatterns may be too entity-specific or noisy.Figure 3 shows the coverage of the concept re-trieval process when we use the top N frequentlyappearing patterns in the candidate pattern set.
Weobserve that the coverage does not reach 100%even if we use all the query patterns.
This is be-cause some concepts cannot be retrieved by anyquery pattern.
Moreover, we consider a Wikilinkas a concept, even though some Wikilink texts donot actually represent a concept.We use query patterns that occur no less than3 times (for American actors, American ten-nis players, Software companies, and Operas) ortwice (for Genetic disorders) in the correspond-ing Wikipedia articles so that the query patternsreach 95% of the upper bound of the coverage.This small subset comprises the final candidatepatterns.
For the candidate patterns, we use theproposed method (solving the weighted Max-SATproblem) and the three baselines described aboveto choose N query patterns.The precision, coverage and quasi F-score (F?-score) of the information retrieval process by eachtemplate are defined as follows:precision = freq(Ek,Pi,Cj)freq(Ek,Pi) ,coverage =CcollectedCtotal ,F ?
= 2 ?precision ?
coverageprecision+ coverage ,where freq(Ek,Pi) is the frequency of the phrase?Ek Pi?
in the retrieved documents, freq(Ek,Pi,C j)is the frequency of co-occurrence of the phrase?Ek Pi?
and ?C j?
in the sentences.
Ctotal is the to-tal number of distinct concepts in the data set, andCcollected is the number of distinct concepts whichcan be collected by the template.3.2 ResultTable 5 shows the average of the precision, cover-age and F?
scores of the five categories when wechoose 10 query patterns (N=10).
The proposedmethod obtains the highest score of all methods.Moreover, the proposed method outperforms thebaselines not only for the average of all categories,but also for each category.
This result indicatesTable 5: Performance of the templates producedby the proposed method and the three baselines(N=10).Method Precision Coverage F?
scoreRandom 16.56 11.40 13.19Frequency 21.43 29.29 24.40PMI-Web 22.55 22.08 21.42Proposed 27.34 30.77 27.95Figure 4: Number of query patterns (N) in tem-plate and F?
score in American tennis players.that the proposed method is able to choose querypatterns that precisely and comprehensively col-lect the target concepts.Table 3 shows some example templates pro-duced by the proposed method.
In this table, thenumber in the parentheses next to a pattern is thefrequency rank of the pattern.
We observe that theproposed method generates templates with twotypes of query patterns: generic patterns and spe-cific patterns.
Generic patterns such as ?is a?and ?is an?
are patterns that can appear in everycategory.
These patterns cover various kinds ofconcepts (high coverage), but may retrieve sen-tences that do not describe any concept (low pre-cision).
Specific patterns, such as ?has a star onthe?
and ?was nominated for a,?
can retrieve con-cepts that have specific relations with the entity.Therefore, queries with specific patterns retrievea small number of concepts with high precision.The proposed method chooses query patterns inboth of these types to achieve both high precisionand high coverage.
Therefore, it is able to retrieve1234Table 3: Templates generated by the proposed method (N=10): (n) is the frequency rank.Category TemplateAmerican actors ?is an?
(1), ?was an?
(2), ?was a?
(7), ?graduated from?
(9), ?died of?
(18), ?has a star on the?
(24),?was nominated for a?
(28), ?was married to?
(47), ?was born on?
(56), ?has appeared in?
(92)American tennis players ?defeated?
(3), ?beat?
(5), ?is a former?
(12), ?is an?
(16), ?graduated from?
(17),?reached the?
(18), ?played?
(24), ?of?
(30), ?was?
(38), ?won?Software companies ?is a?
(1), ?acquired?
(3), ?is?
(9), ?is headquartered in?
(11), ?was founded by?
(15),?has offices in?
(22), ?was?
(29), ?include?
(36), ?introduced?
(41), ?is an international?
(41)Genetic disorders ?is a?
(1), ?is an?
(2), ?has an autosomal recessive pattern of?
(3),?has an autosomal dominant pattern of?
(9), ?is named after?
(11), ?is a form of?
(13),?is caused by?
(16), ?include?
(18), ?appears to be inherited in an?
(41), ?is considered an?
(41)Operas ?is an?
(1), ?is a?
(2), ?is an opera by?
(17), ?was?
(18), ?is a comic?
(20), ?premiered at the?
(25),?was first performed at?
(31), ?is the second?
(38), ?opera?
(46), ?libretto by?
(62)Table 4: Templates generated by different methods for the Opera category (N= 10).Method Template Pre.
Cov.
F?Random ?was an,?
?of the complete operas of the,?
?was on,?
?was commissioned by,?
15.79 8.12 10.73?by,?
?is,?
?popular,?
?for the,?
?New York,?
?the same name by?Frequency ?is an,?
?is a,?
?the,?
?by,?
?of the,?
?in,?
?and,?
?of,?
?was a,?
?a?
16.83 27.12 20.77PMI-Web ?was created by,?
?is a three act,?
?premiered at the,?
?was an,?
?is an,?
30.25 18.29 22.80?is an opera composed by,?
?is a Hindi language,?
?premiered on?
?was commissioned by,?
?was first performed at the,?Proposed ?is an,?
?is a,?
?is an opera by,?
?was,?
?is a comic,?
?premiered at the,?
31.18 27.28 29.10?was first performed at,?
?is the second,?
?opera,?
?libretto by?various types of concepts.
This implies that themethod achieves high coverage even for conceptsthat cannot be retrieved by generic patterns.The baseline Frequency obtains the secondhighest F?-score.
It achieves high coverage butlow precision.
This is because this methodchooses high-frequency patterns that can appearwith every concept.
Therefore, it is able to retrieveconcepts with high coverage.
However, these pat-terns do not retrieve specific information concern-ing a concept.
Moreover, some high-frequencypatterns, such as ?the ?
and ?by,?
lead to sentencesthat do not describe any concept.Table 4 shows the patterns generated for the cat-egoryOpera by each method.
We can observe thatthe method Frequency chooses very generic pat-terns, such as ?is a,?
?and,?
and ?the,?
which arenot specific to Opera.In contrast, the method PMI-Web achieves highprecision but low coverage.
This is becausethis method chooses highly reliable patterns (e.g.,?was commissioned by?
), which are strongly as-sociated with a specific kind of concept.
How-ever, these patterns cannot retrieve a broad rangeof concepts related to the target entity.
This ex-plains why the method cannot achieve high cover-age.Figure 4 shows the F?
scores when we vary thenumber of selected query patterns (N) for the cat-egory American tennis players.
We observe thatthe templates generated by the proposed methodachieve the highest F?-score at every value of N.The maximum F?-score is 24.7, which is achievedwhen N is 30.
Moreover, the proposed method re-quires only five query patterns to achieve the F?-score of 21.4.
Therefore, the proposed methodachieves a high F?-score by using only a smallnumber of patterns.
This implies that the methodachieves high performance in a short query pro-cessing time.4 Related WorkMany studies have addressed the problem of pat-tern extraction from Wikipedia (or other large cor-pora).
Filatova et al (2006) presented an approachfor automatically extracting important word pat-terns from a large corpus.
They analyzed the BBCcorpus to extract word patterns containing verbsthat are supposed to be important for a specificdomain.
Biadsy et al (2008) described a sys-tem for producing biographies for a given targetname.
They used Wikipedia to learn the docu-ment structures of a biography.
Ye et al (2009)1235explored a method for generating a series of sum-maries of various lengths by using informationfrom Wikipedia.Sauper and Barzilay (2009) proposed an ap-proach for creating a summary of many chunksof text that are related to an entity and retrievedfrom the Web.
They used Wikipedia not onlyfor producing the template, but also for improv-ing the summaries.
Although the target of theirwork is very close to that of our study, the focus ofeach study is different.
They address the methodfor selecting appropriate sentences for summa-rization, whereas we consider the method for se-lecting query patterns that can generate a compre-hensive summary of an entity.Various studies have addressed Web pagesummarization and query-focused summarization,from search result summarization (Kanungo et al,2009) to query biased summarization (Wang et al,2007).
Furthermore, Fujii and Ishikawa (2004)presented a method to automatically compile en-cyclopedic knowledge from the Web.Similar to relation extraction, the proposedmethod retrieves information concerning an entityby using query patterns.
This is because querypatterns for relation extraction are also appro-priate in sentence extraction for multi-documentsummarization (Hachey, 2009).
However, the re-lation extraction task primarily obtains query pat-terns that retrieve instances of a specific relation.This is different from the goal of this study, whichis obtaining a set of patterns that are able to re-trieve a large range of topics related to an entity.5 ConclusionWe present a novel method to acquire a set ofquery patterns for retrieving documents that con-tain important information regarding an entity.Especially, we concentrate on the method for se-lecting query patterns that are able to compre-hensively and precisely retrieve important con-cepts concerning an entity.
The experimental re-sults demonstrate that the proposed method out-performs methods based on statistical measuressuch as frequency and point-wise mutual infor-mation (PMI), which are widely used in relationextraction.Currently, we use the text between an entityand a WikiLink as a candidate for a query pat-tern.
In the future, we plan to use the text betweentwo noun phrases as query patterns to increase thenumber of candidates for the pattern selection pro-cess.
Moreover, we intend to build a text summa-rization application based on the proposed methodto confirm that the selected pattern set is able togenerate a comprehensive summary for an entity.ReferencesAgichtein, Eugene and Luis Gravano.
2000.
Snow-ball: Extracting relations from large plain-text col-lections.
In Proc.
of the fifth ACM conference onDigital libraries, pages 85?94.Berger, Adam and Vibhu O. Mittal.
2000.
Query-relevant summarization using FAQs.
In Proc.
of the38th Annual Meeting on Association for Computa-tional Linguistics, pages 294?301.Biadsy, Fadi, Julia Hirschberg, and Elena Filatova.2008.
An unsupervised approach to biography pro-duction using Wikipedia.
In Proc.
of the 46thAnnual Meeting of the Association for Computa-tional Linguistics on Human Language Technolo-gies, pages 807?815.Blohm, Sebastian, Philipp Cimiano, and Egon Stemle.2007.
Harvesting relations from theWeb: quantifiy-ing the impact of filtering functions.
In Proc.
of the22nd national conference on Artificial intelligence,pages 1316?1321.Brin, Sergey.
1999.
Extracting patterns and relationsfrom the World Wide Web.
Selected papers fromthe International Workshop on The World Wide Weband Databases, pages 172?183.Cafarella, Michael J., Doug Downey, Stephen Soder-land, and Oren Etzioni.
2005.
KnowItNow: Fast,scalable information extraction from the Web.
InProc.
of the conference on Human Language Tech-nology and Empirical Methods in Natural LanguageProcessing, pages 563?570.Carbonell, Jaime and Jade Goldstein.
1998.
The useof MMR, diversity-based reranking for reorderingdocuments and producing summaries.
In Proc.
ofthe 21st annual international ACM SIGIR confer-ence on Research and development in informationretrieval, pages 335?336.Dang, Hoa Trang.
2005.
Overview of DUC 2005.
InDocument Understanding Conference (DUC) 2005.Daume?, III, Hal and Daniel Marcu.
2006.
Bayesianquery-focused summarization.
In Proc.
of the 21st1236International Conference on Computational Lin-guistics and the 44th annual meeting of the Associa-tion for Computational Linguistics, pages 305?312.Filatova, Elena, Vasileios Hatzivassiloglou, and Kath-leen McKeown.
2006.
Automatic creation of do-main templates.
In Proc.
of the 21st InternationalConference on Computational Linguistics and the44th annual meeting of the Association for Compu-tational Linguistics, pages 207?214.Fuentes, Maria, Enrique Alfonseca, and HoracioRodr??guez.
2007.
Support vector machines forquery-focused summarization trained and evaluatedon pyramid data.
In Proc.
of the 45th Annual Meet-ing of the ACL on Interactive Poster and Demon-stration Sessions, pages 57?60.Fujii, Atsushi and Tetsuya Ishikawa.
2004.
Summa-rizing encyclopedic term descriptions on the Web.In Proc.
of the 20th international conference onComputational Linguistics, pages 645?651.Gupta, Surabhi, Ani Nenkova, and Dan Jurafsky.2007.
Measuring importance and query relevancein topic-focused multi-document summarization.
InProc.
of the 45th Annual Meeting of the ACL on In-teractive Poster and Demonstration Sessions, pages193?196.Hachey, Ben.
2009.
Multi-document summarisationusing generic relation extraction.
In Proc.
of the2009 Conference on Empirical Methods in NaturalLanguage Processing, pages 420?429.Hearst, Marti A.
1992.
Automatic acquisition ofhyponyms from large text corpora.
In Proc.
ofthe 14th conference on Computational linguistics,pages 539?545.Heras, Federico, Javier Larrosa, and Albert Oliveras.2008.
MiniMaxSat: An efficient weighted Max-SAT solver.
Journal of Artificial Intelligence Re-search, 31:1?32.Kanungo, Tapas, Nadia Ghamrawi, Ki Yuen Kim, andLawrence Wai.
2009.
Web search result summa-rization: Title selection algorithms and user satis-faction.
In Proceeding of the 18th ACM conferenceon Information and knowledge management, pages1581?1584.Pantel, Patrick and Marco Pennacchiotti.
2006.Espresso: Leveraging generic patterns for automat-ically harvesting semantic relations.
In Proc.
of the21st International Conference on ComputationalLinguistics and the 44th annual meeting of the Asso-ciation for Computational Linguistics, pages 113?120.Sauper, Christina and Regina Barzilay.
2009.
Auto-matically generating Wikipedia articles: a structure-aware approach.
In Proc.
of the Joint Conference ofthe 47th Annual Meeting of the ACL and the 4th In-ternational Joint Conference on Natural LanguageProcessing of the AFNLP, pages 208?216.Tombros, Anastasios and Mark Sanderson.
1998.
Ad-vantages of query biased summaries in informationretrieval.
In Proc.
of the 21st annual internationalACM SIGIR conference on Research and develop-ment in information retrieval, pages 2?10.Turney, Peter D. 2001.
Mining the Web for synonyms:PMI-IR versus LSA on TOEFL.
In Proc.
of the 12thEuropean Conference on Machine Learning, pages491?502.Varadarajan, Ramakrishna and Vagelis Hristidis.2006.
A system for query-specific document sum-marization.
In Proc.
of the 15th ACM internationalconference on Information and knowledge manage-ment, pages 622?631.Wang, Changhu, Feng Jing, Lei Zhang, and Hong-Jiang Zhang.
2007.
Learning query-biased Webpage summarization.
In Proc.
of the sixteenth ACMconference on information and knowledge manage-ment, pages 555?562.White, Ryen W., Joemon M. Jose, and Ian Ruthven.2003.
A task-oriented study on the influencing ef-fects of query-biased summarisation in Web search-ing.
Information Processing and Management,39(5):707?733.Ye, Shiren, Tat-Seng Chua, and Jie Lu.
2009.
Sum-marizing definition from Wikipedia.
In Proc.
of theJoint Conference of the 47th Annual Meeting of theACL and the 4th International Joint Conference onNatural Language Processing of the AFNLP: Vol-ume 1, pages 199?207.1237
