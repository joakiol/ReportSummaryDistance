Proceedings of NAACL-HLT 2015, pages 106?110,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsWriteAhead2: Mining Lexical Grammar Patterns for Assisted WritingJim ChangDepartment of Computer Science,National Tsing Hua University101, Kuangfu Road,Hsinchu, 300, Taiwanjim.chang.nthu@gmail.comJason S. ChangDepartment of Computer Science,National Tsing Hua University101, Kuangfu Road,Hsinchu, 300, Taiwanjason.jschang@gmail.comAbstractThis paper describes WriteAhead2, an inter-active writing environment that provides lex-ical and grammatical suggestions for sec-ond language learners, and helps them writefluently and avoid common writing errors.The method involves learning phrase tem-plates from dictionary examples, and extract-ing grammar patterns with example phrasesfrom an academic corpus.
At run-time, as theuser types word after word, the actions trig-ger a list after list of suggestions.
Each suc-cessive list contains grammar patterns and ex-amples, most relevant to the half-baked sen-tence.
WriteAhead2 facilitates steady, timely,and spot-on interactions between learner writ-ers and relevant information for effective as-sisted writing.
Preliminary experiments showthat WriteAhead2 has the potential to inducebetter writing and improve writing skills.1 IntroductionMore and more non-native speakers are writingin English as a second language for global com-munication, especially in academia.
Unavoidably,these L2 writers encounter many problems: inform and content, in grammar, style, and discourse.Much work has been done on developing computer-assisted language reference tools to improve L2learners?
writing skills.
Furthermore, many re-searchers have worked on providing corrective feed-back and grades, by automatically detecting and cor-recting grammatical errors in learner writings.Computer assisted language learning (CALL)systems typically help the users before and afterwriting.
For example, NetSpeak (www.netspeak.org) uses Google Web 1T Corpus to retrieve com-mon phrases relevant to a user query, while MarkingMate (www.readingandwritingtools.com) ac-cepts an user essay and offers a grade with correc-tive feedback.
However, learner writers sorely needconcrete writing suggestions, right in the context ofwriting.
Learners could be more effectively assisted,if CALL tools provide such suggestions as learnerswrite away.Consider an online writer who is composing asentence starting with ?We propose a method ...?The best way the system can help is probably notjust dictionary-lookup, but rather in-page sugges-tions tailor-made for this very context of continuingthe unfinished sentence.
Furthermore, fixed-lengthngrams such as (1) method for automatic evalua-tion and (2) method for determining the is not goodenough, or general enough, for all writers address-ing diverse issues.Appropriate suggestions should contains general,long grammar patterns such as: (1) method for do-ing something: method for finding a solution (2)method for something: method for grammatical er-ror detection.
Intuitively, by extracting and display-ing such patterns and examples, distilled from a verylarge corpus, we can guide the user towards writingfluently, and free of grammatical errors.We present a new system, WriteAhead2, thatproactively provides just-in-time writing sugges-tions to assist student writers, while they typeaway.
WriteAhead2 is a continuation of the workof WriteAhead (Liou, Yang, Chang 2012).
ExampleWriteAhead2 suggestions for ?We propose a method106Figure 1: Example WriteAhead2 session....?
are shown in Figure 1.
WriteAhead2 has deter-mined the best patterns and examples extracted fromthe underlying corpus.
WriteAhead2 learns thesepatterns and examples automatically during trainingby analyzing annotated dictionary examples and au-tomatically tagged sentences in a corpus.
As will bedescribed in Section 4, we used the information oncollocation and syntax (ICS) for example sentencesfrom online Macmillan English Dictionary, as wellas in the Citeseer x corpus, to develop WriteAhead2.At run-time, WriteAhead2 activate itself as theuser types in yet another word (e.g., ?method?
in theprefix ?We propose a method ...?).
WriteAhead2 thenretrieves patterns related to the last word.
WriteA-head2 goes one step further and re-ranks the sug-gestions, in an attempt to move most relevant sug-gestions to the top.
WriteAhead2 can be accessed athttp://writeahead.nlpweb.org.In our prototype, WriteAhead2 returns the sug-gestions to the user directly (see Figure 1); alterna-tively, the suggestions returned by WriteAhead2 canbe used as input to an automatic grammar checker oran essay rater.2 Related WorkUsing dictionaries for language learning has a longand honorable history.
However, Sinclair (1991)pointed out dictionaries are limited by their narrowfocus on meaning, lack in pragmatics, and insuffi-cient genre/discipline-specific information.
There-fore, Sinclair advocated corpus linguistics, corpus-based lexicography, and using a concordance in lan-guage teaching.In the area of corpus-based language learning,Weber (2001) illustrated how combining learnerwriting and a concordance helped law students inwriting better legal essays.
Sun (2007) proposeda web-based Scholarly Writing Template (SWT)system for graduate students based on a small,manually-annotated corpus.
In contrast, we focuson grammar, the most problematic area for learners.In the area of automated essay rating, Crite-rion (Burstein, Chodorow and Leacock, 2003) usesstatistical models to evaluate student writing andprovides corrective feedback.
Criterion has beenused for rating 4 to 12th graders?
writings, andTOFEL/GRE composition tests.
Criterion handlesessay writing, while WriteAhead2 concentrates onhelping learner with the genre of research articles.Autocompletion has been widely used in manylanguage production tasks (e.g., search query andtranslation).
Examples include Google Suggest andTransType, which pioneered the interactive user in-terface for statistical machine translation (Langlais,Foster and Lapalme, 2002).In contrast to the previous research in developingcomputer assisted writing environment, we presenta system that automatically learns grammar patternsand examples from an academic written corpus, withthe goal of providing relevant, in-context sugges-tions.3 MethodOften, it is not sufficient to use dictionaries or lexi-cal autocompletion to assist learner in writing.
Un-fortunately, very few Language tools offer compre-107????????????????????????
?Procedure ExtractPatterns(Sent, Keywords, Corpus)(1) Learning phrase templates for grammar patterns of con-tent words (Section 3.1.1)(2) Extracting patterns for all keywords in the given corpusbased on phrase templates (Section 3.1.2)(3) Extracting exemplary instances for all patterns of all key-words (Section 3.1.3)????????????????????????
?Figure 2: Outline of the pattern extraction processhensive writing suggestions during writing.
In thissection, we address such a problem.
Given a corpusin a specific genre/domain (e.g., Citeseer x), and anunfinished sentence, we intend to assist the user byretrieving and displaying a set of suggestions basedon the corpus.
For this, we extract grammar patternswith exemplary instances from the corpus.
We de-scribe the stages of our solution to this problem inthe subsections that followed.3.1 Extracting Grammar PatternsWe attempt to extract characteristic grammar pat-terns for keywords in a given corpus to provide writ-ing suggestions, for L2 learners in an online writingsession.
The set of keywords (as will be describedin Section 4) include the words academic writers usemost frequently for rhetoric purposes, including stat-ing a topic, hypothesizing, contrasting, exemplify-ing, explaining, evaluating and other functions.
Ourextraction process is shown in Figure 2.3.1.1 Learning Templates of Grammar PatternsIn the first stage of the extraction process (Step (1) inFigure 2), we generate a set of phrase templates foridentifying grammar patterns.
For example, a dictio-nary example with ICS?have difficulty/problem(in) doing something: Six months after the acci-dent, he still has difficulty walking, implies that thispattern (i.e.
have difficulty in doing something)can realize in a phrase sequences, ?VP NP prep.
VPNP?.
With such a template, we can identify poten-tial patterns for verbs and nouns (e.g., differ or diffi-culty).
We expand the parentheticals (e.g., (in)) andalternatives (e.g., difficulty/problem) in ICS, andkeep only the most frequent templates.
Finally, eachof these templates is converted into a regular expres-sion for a RegExp chunk parser.3.1.2 Extracting Patterns In the second stageof the extraction process (Step (2) in Figure 2), weidentify instances of potential pattern for all key-words.
These instance are generated for each taggedand chunked sentence in the given corpus and foreach chunk templates obtained in the previous stage.We adopt the MapReduce framework to extractcharacteristic patterns.
In Step (1) of the Map pro-cedure, we perform part of speech and base phrasetagging on the sentences.
We then find all patterninstances anchoring at a keyword and matching tem-plates obtained in the first stage.
Note that matchingis done on the sequence of BIO phrase labels (denot-ing Beginning, Inside, and Outside of base NP, VP,PP, and ADJP).
Then from each matched instance,we extract a tuple of keyword, POS, grammar pat-tern, collocates (of the keyword), and ngram (wordsequence) in Steps (4a) through (4c).
Finally, weemit all tuples extracted from the tagged sentence(Step (5)).The Reduce procedure receives a batch of hashedand locally sorted tuples, grouped by the head wordand POS.
In Step (1) of the Reduce procedure, wefurther group the tuples by pattern.
Then we countthe number of tuples of each pattern (in Step (2)) aswell as within-group average and standard deviation(in Step (3)).
Finally, With these statistics, we filterand identify patterns more frequent than average byK standard deviation, K = 1 (in Step (4)), followingSmadja (1993).3.1.3 Extracting Exemplary Phrases In the thirdand final stage of extraction, we generate exemplaryphrases for all patterns of all keywords of interest.The procedure is essentially the same as the Reduceprocedure in the second stage (Section 3.1.2).3.2 Retrieving and Ranking SuggestionsOnce the patterns and examples are automaticallyextracted for each keyword in the given corpus, theyare stored as suggestions for the last word the usertypes in.
WriteAhead2 constantly probes and getsthe last written word from the writing area.
With thelast word as a query, WriteAhead2 retrieves patternsand examples, and re-ranks the results to move themost relevant information toward the top.Currently, we re-rank patterns by using wordoverlap between the last written sentence and the re-trieved examples.
When there is no word overlap,we fall back to frequency-based ranking.
An exam-108????????????????????
?Procedure Map(Sent, AKL, Template)(1) TaggedSent = TagAndChunkParse(Sent)For each Word ?
AKL at position i in TaggedSent(2) Match = RegExpChunkParse(TaggedSent, Template, i)If Match is found(3) ChunkedPhr = CutChunk(TaggedSent, i, Match)(4a) Pat = ExtractPattern(ChunkedPhr)(4b) Col = ExtractCollocation(ChunkedPhr)(4c) Ng = ExtractNgram(ChunkedPhr)(5) Emit Tuple = (Word, Pat, Col, Ng)Procedure Reduce(Tuples for a word)(1) Pats, PatTuples = GroupTuplesByPat(Tuple)(2) Pats, Counts = Counter(Pats, PatTuples)(3) Avg, STD = CalStatatics(Pats, Counts)For each Pat, Count pair in (Pats, Counts)If Count > Avg + K ?
STD(4) Emit Tuple = (Word, Pat, PatTuples)?????????????????????Fig.
3.
Outline of the process used to extract CPs.ple session is shown in Figure 1.4 Experiments and ResultsFor training, we used a collection of approxi-mately 3,000 examples for 700 headwords obtainedfrom online Macmillan English Dictionary (Rundel2007), to develop the templates of patterns.
Theheadwords include nouns, verbs, adjectives, and ad-verbs.
We then proceeded to generate writing sug-gestions from the Citeseer x corpus.
First, we usedTsujii POS Tagger (Tsuruoka and Tsujii 2005) togenerate tagged sentences.
We applied the proposedmethod to generate suggestions for each of the 700content keywords in Academic Keyword List.4.1 Technical ArchitectureWriteAhead2 was implemented in Python and FlaskWeb framework.
We stored the suggestions in JSONformat using PostgreSQL for faster access.
WriteA-head2 server obtains client input from a popularbrowser (Safari, Chrome, or Firefox) dynamicallywith AJAX techniques.
For uninterrupted serviceand ease of scaling up, we chose to host WriteA-head2 on Heroku, a cloud-platform-as-a-service(PaaS) site.Table 1: Human evaluation of WriteAhead2Suggestion Count Percent Recall1st suggestion 141 .53 .432nd suggestion 50 .19 .153rd suggestion 38 .14 .12Top 3 suggestions 229 .85 .70Not in Top 3 38 ?
.12No suggestions 62 ?
.19Not applicable 71 ?
?4.2 Evaluating WriteAhead2To evaluate the performance of WriteAhead2, werandomly sampled sentences from conference pa-pers.
For simplicity, we tested if our system canprovide proper grammar patterns for the first nounor verb in theses sentence.
We randomly selected400 sentences from ACL-2014 long papers.
Foreach sentence, we pasted the sentence prefix up tothe the first (noun or verb) keyword to the input boxof WriteAhead2.
The reason for targeting verbs andnouns is that they are considered as exhibiting reg-ularity in local syntax (Hunston and Francis 2000)and common source of learners?
writing errors (DeCock, Gilquin, Granger, Lefer, Paquot, and Ricketts2007).
Finally, we manually determined the appro-priateness of suggestions for continuing part of thesentence based on the precision of the Top-3 sugges-tions.
For example, we took a sentence:There is some prior work on the related task of hi-erarchical clustering, or grouping together of se-mantically related words ...and identified the first noun or verb (e.g., work) asthe anchor, and run WriteAhead2 on the prefix end-ing at the anchor (e.g, ?There is some prior work?
).The Top 3 suggestions displayed by WriteAhead2were than examined by a human judge to evaluatefor correctness in predicting what follow the prefix.For instance, if the first suggestion is:work on something of something 1332: VoiSe is designedto work on a symbolic representation of a music scoreThen the judge would determine it is a correct pre-diction of work on the related task of hierarchicalclustering and record that the first suggestion is cor-rect.
Evaluation of WriteAhead2 showed a Top 1precision rate of 53% and recall rate of 70% whenconsidering the Top 3 suggestions.1095 Demo ScriptIn this demo, we will present a new writing assis-tance system, WriteAhead2, which makes it easy toobtain writing tips as you type away.
WriteAhead2does two things really well.
First, it examines theunfinished sentence you just typed in and then auto-matically gives you tips in the form of grammar pat-terns (accompanied with examples similar to thosefound in a good dictionary ) for continuing yoursentence.
Second, WriteAhead2 automatically rankssuggestions relevant to your writing, so you spendless time looking at tips, and focus more on writingyour piece.You might type in This paper presents a methodand are not sure about how to continue.
You will in-stantly receive tips on grammar as well as content asshown in Figure 1.
At a quick glance, you might finda relevant pattern, method for doing somethingwith examples such as This paper presents/describesa method for generating solutions.
That could tipyou off as to change the sentence into This paperpresents a method, thus getting rid of tense and arti-cle errors, and help you continue to write somethinglike method for extracting information.Using WriteAhead2 this way, you could at oncespeed up writing and avoid making common writingerrors.
This writing and tip-taking process repeatsuntil you finish writing a sentence.
And as you startwriting a new, the process starts all over again.Most autocompletion systems such as GoogleSuggest and TransType offer word-level sugges-tions, while WriteAhead2 organizes, summarizes,and ranks suggestions, so you can, at a glance, graspcomplex linguistic information and make quick de-cision.
Our philosophy is that it is important to showinformation from general to specific to reduce thecognitive load, so while minding the form, you canstill focus on the content of writing.6 ConclusionMany avenues exist for future research and improve-ment of WriteAhead2.
For example, corpora for dif-ferent language levels, genres (e.g., emails, news)could be used to make the suggestions more rele-vant to users with diverse proficiency levels and in-terests.
NLP, IR, and machine learning techniquescould be used to provide more relevant ranking, topin-point grammatical errors, or to generate finer-grained semantic patterns (e.g., assist someone insomething or attend activity/institution) Addition-ally, an interesting direction is identifying grammarpatterns using a CRF sequence labeller.
Yet anotherdirection of research would be to extract and dis-play backward-looking suggestions to complementthe current forward-looking suggestions.In summary, in an attempt to assist learner writers,we have proposed a method for providing writingsuggestion as a user is typewriting.
The method in-volves extracting, retrieving, and ranking grammarpatterns and examples.
We have implemented andevaluated the proposed method as applied to a schol-arly corpus with promising results.ReferencesJill Burstein, Martin Chodorow, and Claudia Leacock.2003.
Criterion: Online Essay Evaluation?An Appli-cation for Automated Evaluation of Student Essays.
InProceedings of the Fifteenth Annual Conference on In-novative Applications of Artificial Intelligence.
Aca-pulco, Mexico.Cornelia Caragea, Jian Wu, Alina Ciobanu, KyleWilliams, Juan Fernndez-Ramrez, Hung-Hsuan Chen,Zhaohui Wu, and Lee Giles.
CiteSeer x: A Schol-arly Big Dataset.
Advances in Information Retrieval.Springer International Publishing, 2014.
311-322.Sylvie De Cock, Gatanelle Gilquin, Sylviane Granger,Marie-Aude Lefer, Magali Paquot, and Suzanne Rick-etts.
2007.
Improve Your Writing Skills.
In Rundell(2007).Philippe Langlais, George Foster, and Guy Lapalme.2000.
TransType: A Computer-Aided Translation Typ-ing System.
In Workshop on Embedded MachineTranslation Systems.Hien-Chin Liou, PingChe.
Yang, and Jason S. Chang.Language supports for journal abstract writing acrossdisciplines.
Journal of Computer Assisted Learning28.4 (2012): 322-335.Michael Rundell (Ed.).
2007.
Macmillan English Dic-tionary for Advanced Learners.
Oxford, Macmillan,2002.John Sinclair.
1991.
Corpus, Concordance, Collocation.Oxford University Press, Hong Kong.Yu-Chih Sun.
2007.
Learner Perceptions of a Concor-dancing Tool for Academic Writing.
Computer As-sisted Language Learning 20, 323343.Jean-Jacques Weber.
2001.
A Concordance- and Genre-informed Approach to ESP Essay Editing.
ELT Jour-nal 55, 1420.110
