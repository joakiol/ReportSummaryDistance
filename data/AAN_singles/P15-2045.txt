Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 273?278,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsImproving distant supervision using inference learningRoland Roller1, Eneko Agirre2, Aitor Soroa2and Mark Stevenson11Department of Computer Science, University of Sheffieldroland.roller,mark.stevenson@sheffield.ac.uk2IXA NLP group, University of the Basque Countrye.agirre,a.soroa@ehu.eusAbstractDistant supervision is a widely applied ap-proach to automatic training of relationextraction systems and has the advantagethat it can generate large amounts of la-belled data with minimal effort.
How-ever, this data may contain errors andconsequently systems trained using dis-tant supervision tend not to perform aswell as those based on manually labelleddata.
This work proposes a novel methodfor detecting potential false negative train-ing examples using a knowledge inferencemethod.
Results show that our approachimproves the performance of relation ex-traction systems trained using distantly su-pervised data.1 IntroductionDistantly supervised relation extraction relies onautomatically labelled data generated using infor-mation from a knowledge base.
A sentence isannotated as a positive example if it contains apair of entities that are related in the knowledgebase.
Negative training data is often generated us-ing a closed world assumption: pairs of entities notlisted in the knowledge base are assumed to be un-related and sentences containing them consideredto be negative training examples.
However this as-sumption is violated when the knowledge base isincomplete which can lead to sentences containinginstances of relations being wrongly annotated asnegative examples.We propose a method to improve the quality ofdistantly supervised data by identifying possiblewrongly annotated negative instances.
Our pro-posed method includes a version of the Path Rank-ing Algorithm (PRA) (Lao and Cohen, 2010; Laoet al, 2011) which infers relation paths by com-bining random walks though a knowledge base.We use this knowledge inference to detect possi-ble false negatives (or at least entity pairs closelyconnected to a target relation) in automatically la-belled training data and show that their removalcan improve relation extraction performance.2 Related WorkDistant supervision is widely used to train relationextraction systems with Freebase and Wikipediacommonly being used as knowledge bases, e.g.
(Mintz et al, 2009; Riedel et al, 2010; Krauseet al, 2012; Zhang et al, 2013; Min et al, 2013;Ritter et al, 2013).
The main advantage is itsability to automatically generate large amounts oftraining data automatically.
On the other hand,this automatically labelled data is noisy and usu-ally generates lower performance than approachestrained using manually labelled data.
A range offiltering approaches have been applied to addressthis problem including multi-class SVM (Nguyenand Moschitti, 2011) and Multi-Instance learn-ing methods (Riedel et al, 2010; Surdeanu et al,2012).
These approaches take into account the factthat entities might occur in different relations atthe same time and may not necessarily express thetarget relation.
Other approaches focus directly onthe noise in the data.
For instance Takamatsu et al(2012) use a generative model to predict incorrectdata while Intxaurrondo et al (2013) use a rangeof heuristics including PMI to remove noise.
Au-genstein et al (2014) apply techniques to detecthighly ambiguous entity pairs and discard themfrom their labelled training set.This work proposes a novel approach to theproblem by applying an inference learning methodto identify potential false negatives in distantly la-belled data.
Our method makes use of a modi-fied version of PRA to learn relation paths from aknowledge base and uses this information to iden-tify false negatives.2733 Data and MethodsWe chose to apply our approach to relation ex-traction tasks from the biomedical domain sincethis has proved to be an important problem withinthese documents (Jensen et al, 2006; Hahn et al,2012; Cohen and Hunter, 2013; Roller and Steven-son, 2014).
In addition, the first application of dis-tant supervision was to biomedical journal articles(Craven and Kumlien, 1999).
In addition, the mostwidely used knowledge source in this domain, theUMLS Metathesaurus (Bodenreider, 2004), is anideal resource to apply inference learning given itsrich structure.We develop classifiers to identify relationsfound in two subsets of UMLS: the National DrugFile-Reference Terminology (ND-FRT) and theNational Cancer Institute Thesaurus (NCI).
A cor-pus of approximately 1,000,000 publications isused to create the distantly supervised trainingdata.
The corpus contains abstracts published be-tween 1990 and 2001 annotated with UMLS con-cepts using MetaMap (Aronson and Lang, 2010).3.1 Distantly labelled dataDistant supervision is carried out for a targetUMLS relation by identifying instance pairs andusing them to create a set of positive instancepairs.
Any pairs which also occur as an instancepair of another UMLS relation are removed fromthis set.
A set of negative instance pairs is thencreated by forming new combinations that do notoccur within the positive instance pairs.
Sentencescontaining a positive or negative instance pair arethen extracted to generate positive and negativetraining examples for the relation.
These candi-date sentences are then stemmed (Porter, 1997)and PoS tagged (Charniak and Johnson, 2005).The sets of positive and negative training exam-ples are then filtered to remove sentences that meetany of the following criteria: contain the samepositive pair more than once; contain both a posi-tive and negative pair; more than 5 words betweenthe two elements of the instance pair; contain verycommon instance pairs.3.2 PRA-ReductionPRA (Lao and Cohen, 2010; Lao et al, 2011)is an algorithm that infers new relation instancesfrom knowledge bases.
By considering a knowl-edge base as a graph, where nodes are connectedthrough typed relations, it performs random walksover it and finds bounded-length relation paths thatconnect graph nodes.
These paths are used asfeatures in a logistic regression model, which ismeant to predict new relations in the graph.
Al-though initially conceived as an algorithm to dis-cover new links in the knowledge base, PRA canalso be used to learn relevant relation paths forany given relation.
For instance, if x and y arerelated via sibling relation, the model trained byPRA would learn that the relation path parent(x,a)?
parent(a,y)1is highly relevant, as siblings sharethe same parents.Knowledge graphs were extracted from the ND-FRT and NCI vocabularies generating approxi-mately 200, 000 related instance pairs for ND-FRT and 400, 000 for NCI.
PRA is then run onboth graphs in order to learn paths for each tar-get relation.
Table 1 shows examples of the pathsPRA generated for the relation biological-process-involves-gene-product together with their weights.We only make use of relation paths with positiveweights generated by PRA.path weightgene-encodes-gene-product(x,a) ?
gene-plays-role-in-process(a,y)10.53isa(x,a) ?
biological-process-involves-gene-product(a,y)6.17isa(x,a) ?
biological-process-involves-gene-product(a,y)2.80gene-encodes-gene-product(x,a) ?
gene-plays-role-in-process(a,b) ?
isa(b,y)-0.06Table 1: Example PRA-induced paths and weightsfor the NCI relation biological-process-involves-gene-product.The paths induced by PRA are used to iden-tify potential false negatives in the negative train-ing examples (Section 3.1).
Each negative trainingexample is examined to check whether the entitypair is related in UMLS by following any of therelation paths extracted by PRA for the relevanttarget relation.
Examples containing related en-tity pairs are assumed to be false negatives, sincethe relation can be inferred from the knowledgebase, and removed from the set of negatives train-ing examples.
For instance, using the path in thetop row of Table 1, sentences containing the enti-ties x and y would be removed if the path gene-encodes-gene-product(x,a) ?
gene-plays-role-in-process(a,y) could be identified within UMLS.1An underline (?
?)
prefix represents the inverse of a rela-tion while ?
represents path composition.2743.3 EvaluationRelation Extraction system: The MultiR system(Hoffmann et al, 2010) with features described bySurdeanu et al (2011) was used for the experi-ments.Datasets: Three datasets were created to trainMultiR and evaluate performance.
The first (Un-filtered) uses the data obtained using distant su-pervision (Section 3.1) without removing any ex-amples identified by PRA.
The overall ratio ofpositive to negative sentences in this dataset was1:5.1.
However, this changes to 1:2.3 after remov-ing examples identified by PRA.
Consequently thebias in the distantly supervised data was adjustedto 1:2 to increase comparability across configura-tions.
Reducing bias was also found to increase re-lation extraction performance, producing a strongbaseline.
The PRA-reduced dataset is created byapplying PRA reduction (Section 3.2) to the Un-filtered dataset to remove a portion of the nega-tive training examples.
Removing these examplesproduces a dataset that is smaller than Unfilteredand with a different bias.
Changing the bias ofthe training data can influence the classification re-sults.
Consequently the Random-reduced datasetwas created by removing randomly selected nega-tive examples from Unfiltered to produce a datasetwith the same size and bias as PRA-reduced.
TheRandom-reduced dataset is used to show that ran-domly removing negative instances leads to lowerresults than removing those suggested by PRA.Evaluation: Two approaches were used to eval-uate performance.The Held-out datasets consist of the Unfiltered,PRA-reduced and Random-reduced data sets.
Theset of entity pairs obtained from the knowledgebase is split into four parts and a process similarto 4-fold cross validation applied.
In each fold theautomatically labelled sentences obtained from thepairs in 3 of the quarters are used as training dataand sentences obtained from the remaining quarterused for testing.The Manually labelled dataset contains 400examples of the relation may-prevent and 400 ofmay-treat which were manually labelled by twoannotators who were medical experts.
Both rela-tions are taken from the ND-FRT subset of UMLS.Each annotator was asked to label every sentenceand then re-examine cases where there was dis-agreement.
This process lead to inter-annotatoragreement of 95.5% for may-treat and 97.3% formay-prevent.
The annotated data set is publiclyavailable2.
Any sentences in the training data con-taining an entity pair that occurs within the man-ually labelled dataset are removed.
Although thisdataset is smaller than the held-out dataset, its an-notations are more reliable and it is therefore likelyto be a more accurate indicator of performance ac-curacy.
This dataset is more balanced than theheld-out data with a ratio of 1:1.3 for may-treatand 1:1.8 for may-prevent.Evaluation metric: Our experiments use en-tity level evaluation since this is the most appropri-ate approach to determine suitability for databasepopulation.
Precision and recall are computedbased on the proportion of entity pairs identified.For the held-out data the set of correct entity pairsare those which occur in sentences labeled as pos-itive examples of the relation and which are alsolisted as being related in UMLS.
For the manuallylabelled data it is simply the set of entity pairs thatoccur in positive examples of the relation.4 Results4.1 Held-out dataTable 2 shows the results obtained using the held-out data.
Overall results, averaged across all re-lations with maximum recall, are shown in the topportion of the table and indicate that applying PRAimproves performance.
Although the highest pre-cision is obtained using the Unfiltered classifier,the PRA-reduced classifier leads to the best recalland F1.
Performance of the Random-reduced clas-sifier indicates that the improvement is not simplydue to a change in the bias in the data but that theexamples it contains lead to an improved model.The lower part of Table 2 shows results for eachrelation.
The PRA-reduced classifier produces thebest results for the majority of relations and alwaysincreases recall compared to Unfiltered.It is perhaps surprising that removing false neg-atives from the training data leads to an increasein recall, rather than precision.
False negativescause the classifier to generate an overly restrictivemodel of the relation and to predict positive ex-amples of a relation as negative.
Removing themleads to a less constrained model and higher recall.There are two relations where there is also an in-crease in precision (contraindicating-class-of andmechanism-of-action-of ) and these are also theones for which the fewest training examples are2https://sites.google.com/site/umlscorpus/home275Unfiltered Random-reduced PRA-reducedPrec.
Rec.
F1 Prec.
Rec.
F1 Prec.
Rec.
F1Overall 62.30 51.82 56.58 44.49 74.26 55.64 56.85 77.10 65.44NCI relationsbiological process involves gene product 89.61 43.18 57.86 65.67 78.79 71.38 70.63 84.85 76.97disease has normal cell origin 60.20 83.86 69.95 43.2 95.21 58.85 42.80 91.88 57.91gene product has associated anatomy 41.65 64.04 49.96 29.22 74.63 41.81 37.94 65.28 47.82gene product has biochemical function 86.43 72.00 78.33 60.66 91.57 72.90 70.58 95.80 81.17process involves gene 78.92 50.71 61.54 51.38 80.64 62.73 68.16 87.34 76.47ND-FRT relationscontraindicating class of 40.00 20.83 26.14 28.48 72.50 39.58 41.30 82.50 54.33may prevent 27.48 14.69 18.87 20.61 44.79 27.94 38.11 35.63 36.64may treat 48.66 39.63 43.14 39.57 50.00 43.84 50.88 57.93 54.11mechanism of action of 47.15 40.63 43.12 40.25 59.38 47.62 52.85 59.38 55.82Table 2: Evaluation using held-out dataUnfiltered Random-reduced PRA-reducedrelation Prec.
Rec.
F1 Prec.
Rec.
F1 Prec.
Rec.
F1may prevent 54.17 21.67 30.95 53.57 25.00 34.09 39.66 38.33 38.98may treat 40.00 47.48 43.42 43.21 50.36 46.51 41.05 67.63 51.09Table 3: Evaluation using manually labelled data0.40.50.60.70.80.910  0.2  0.4  0.6  0.8  1PrecisionRecallunfilteredPRA-reducedRandom-reducedFigure 1: Precision/Recall Curve for Held-out dataavailable.
The classifier has access to such a lim-ited amount of data for these relations that remov-ing the false negatives identified by PRA allows itto learn a more accurate model.Figure 1 presents a precision/recall curve com-puted using MultiR?s output probabilities.
Resultsfor the PRA-reduced and the Random-reducedclassifiers show that reducing the amount of nega-tive training data increases recall.
However, usingPRA-reduced generally leads to higher precision,indicating that PRA is able to identify suitable in-stances for removal from the training set.
The Un-filtered classifier produces good results but preci-sion and recall are lower than PRA-reduced.4.2 Manually labelledTable 3 shows results of evaluation on the morereliable manually labelled data set.
The best over-all performance is once again obtained using thePRA-reduced classifier.
There is an increase in re-call for both relations and a slight increase in pre-cision for may treat.
Performance of the Random-reduced classifier also improves due to an increas-ing recall but remains below PRA-reduced.
Per-formance of the Random-reduced classifier is alsobetter than Unfiltered, with the overall improve-ment largely resulting from increased recall, butbelow PRA-reduced.
These results confirm that re-moving examples identified by PRA improves thequality of training data.Further analysis indicated that the PRA-reducedclassifier produces the fewest false negatives in itspredictions on the manually annotated dataset.
Itincorrectly labels 82 entity pairs (45 may-treat, 37may-prevent) as negative while Unfiltered predicts120 (73, 47) and Random-reduced 114 (69, 45).This supports our initial hypothesis that remov-ing potential false negatives from training data im-proves classifier predictions.5 Conclusions and Future WorkThis paper proposes a novel approach to identify-ing incorrectly labelled instances generated usingdistant supervision.
Our method applies an infer-ence learning method to detect and discard pos-sible false negatives from the training data.
Weshow that our method improves performance fora range of relations in the biomedical domain bymaking use of information from UMLS.In future we would like to explore alternative276methods for selecting PRA relation paths to iden-tify false negatives.
Furthermore we would liketo examine the PRA-reduced data in more detail.We would like to find which kind of entity pairsare detected by our proposed method and whetherthe reduced data can also be used to extend thepositive training data.
We would also like to ap-ply the approach to other domains and alternativeknowledge bases.
Finally it would be interestingto compare our approach to other state of the art re-lation extraction systems for distant supervision orbiased-SVM approaches such as Liu et al (2003).AcknowledgementsThe authors are grateful to the Engineeringand Physical Sciences Research Council forsupporting the work described in this paper(EP/J008427/1).ReferencesA.
Aronson and F. Lang.
2010.
An overview ofMetaMap: historical perspective and recent ad-vances.
Journal of the American Medical Associ-ation, 17(3):229?236.Isabelle Augenstein, Diana Maynard, and FabioCiravegna.
2014.
Relation extraction from the webusing distant supervision.
In Proceedings of the19th International Conference on Knowledge Engi-neering and Knowledge Management (EKAW 2014),Link?oping, Sweden, November.Olivier Bodenreider.
2004.
The unified medical lan-guage system (umls): integrating biomedical termi-nology.
Nucleic acids research, 32(suppl 1):D267?D270.Eugene Charniak and Mark Johnson.
2005.
Coarse-to-fine n-best parsing and maxent discriminativereranking.
In Proceedings of the 43rd Annual Meet-ing on Association for Computational Linguistics,ACL ?05, pages 173?180, Stroudsburg, PA, USA.Association for Computational Linguistics.K Bretonnel Cohen and Lawrence E Hunter.
2013.Text mining for translational bioinformatics.
PLoScomputational biology, 9(4):e1003044.Mark Craven and Johan Kumlien.
1999.
Constructingbiological knowledge bases by extracting informa-tion from text sources.
In In Proceedings of the Sev-enth International Conference on Intelligent Systemsfor Molecular Biology (ISMB), pages 77?86.
AAAIPress.Udo Hahn, K Bretonnel Cohen, Yael Garten, andNigam H Shah.
2012.
Mining the pharmacoge-nomics literaturea survey of the state of the art.Briefings in bioinformatics, 13(4):460?494.Raphael Hoffmann, Congle Zhang, and Daniel S.Weld.
2010.
Learning 5000 relational extractors.
InProceedings of the 48th Annual Meeting of the As-sociation for Computational Linguistics, ACL ?10,pages 286?295, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Ander Intxaurrondo, Mihai Surdeanu, Oier Lopezde Lacalle, and Eneko Agirre.
2013.
Remov-ing noisy mentions for distant supervision.
Proce-samiento del Lenguaje Natural, 51:41?48.Lars Juhl Jensen, Jasmin Saric, and Peer Bork.
2006.Literature mining for the biologist: from informa-tion retrieval to biological discovery.
Nature reviewsgenetics, 7(2):119?129.Sebastian Krause, Hong Li, Hans Uszkoreit, and FeiyuXu.
2012.
Large-scale learning of relation-extraction rules with distant supervision from theweb.
In Proceedings of the 11th InternationalConference on The Semantic Web - Volume PartI, ISWC?12, pages 263?278, Berlin, Heidelberg.Springer-Verlag.Ni Lao and William W. Cohen.
2010.
Relational re-trieval using a combination of path-constrained ran-dom walks.
Mach.
Learn., 81(1):53?67, October.Ni Lao, Tom Mitchell, and William W. Cohen.
2011.Random walk inference and learning in a large scaleknowledge base.
In Proceedings of the 2011 Con-ference on Empirical Methods in Natural LanguageProcessing, pages 529?539, Edinburgh, Scotland,UK., July.
Association for Computational Linguis-tics.Bing Liu, Yang Dai, Xiaoli Li, Wee Sun Lee, andPhilip S. Yu.
2003.
Building text classifiers usingpositive and unlabeled examples.
In Intl.
Conf.
onData Mining, pages 179?188.Bonan Min, Ralph Grishman, Li Wan, Chang Wang,and David Gondek.
2013.
Distant supervision forrelation extraction with an incomplete knowledgebase.
In Proceedings of the 2013 Conference ofthe North American Chapter of the Association forComputational Linguistics: Human Language Tech-nologies, pages 777?782, Atlanta, Georgia, June.Association for Computational Linguistics.Mike Mintz, Steven Bills, Rion Snow, and Dan Ju-rafsky.
2009.
Distant supervision for relation ex-traction without labeled data.
In Proceedings of theJoint Conference of the 47th Annual Meeting of theACL and the 4th International Joint Conference onNatural Language Processing of the AFNLP: Vol-ume 2 - Volume 2, ACL ?09, pages 1003?1011,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Truc-Vien T. Nguyen and Alessandro Moschitti.
2011.End-to-end relation extraction using distant super-vision from external semantic repositories.
In Pro-ceedings of the 49th Annual Meeting of the Associ-ation for Computational Linguistics: Human Lan-guage Technologies: short papers - Volume 2, HLT277?11, pages 277?282, Stroudsburg, PA, USA.
Associ-ation for Computational Linguistics.M.
F. Porter.
1997.
Readings in information retrieval.chapter An Algorithm for Suffix Stripping, pages313?316.
Morgan Kaufmann Publishers Inc., SanFrancisco, CA, USA.Sebastian Riedel, Limin Yao, and Andrew McCallum.2010.
Modeling relations and their mentions with-out labeled text.
In Proceedings of the EuropeanConference on Machine Learning and KnowledgeDiscovery in Databases (ECML PKDD ?10).Alan Ritter, Luke Zettlemoyer, Oren Etzioni, et al2013.
Modeling missing data in distant supervisionfor information extraction.
Transactions of the As-sociation for Computational Linguistics, 1:367?378.Roland Roller and Mark Stevenson.
2014.
Self-supervised relation extraction using umls.
In Pro-ceedings of the Conference and Labs of the Evalua-tion Forum 2014, Sheffield, England.Mihai Surdeanu, David McClosky, Mason Smith, An-drey Gusev, and Christopher Manning.
2011.
Cus-tomizing an information extraction system to a newdomain.
In Proceedings of the ACL 2011 Work-shop on Relational Models of Semantics, pages 2?10, Portland, Oregon, USA, June.
Association forComputational Linguistics.Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati,and Christopher D. Manning.
2012.
Multi-instancemulti-label learning for relation extraction.
In Pro-ceedings of the 2012 Joint Conference on EmpiricalMethods in Natural Language Processing and Com-putational Natural Language Learning, EMNLP-CoNLL ?12, pages 455?465, Stroudsburg, PA, USA.Association for Computational Linguistics.Shingo Takamatsu, Issei Sato, and Hiroshi Nakagawa.2012.
Reducing wrong labels in distant supervi-sion for relation extraction.
In Proceedings of the50th Annual Meeting of the Association for Compu-tational Linguistics: Long Papers - Volume 1, ACL?12, pages 721?729, Stroudsburg, PA, USA.
Associ-ation for Computational Linguistics.Xingxing Zhang, Jianwen Zhang, Junyu Zeng, JunYan, Zheng Chen, and Zhifang Sui.
2013.
Towardsaccurate distant supervision for relational facts ex-traction.
In Proceedings of the 51st Annual Meet-ing of the Association for Computational Linguis-tics (Volume 2: Short Papers), pages 810?815, Sofia,Bulgaria, August.
Association for ComputationalLinguistics.278
