What are the points?
What are the stances?Decanting for question-driven retrieval and executive summarizationJean-Fran?ois DelannoyUniversity of OttawaOttawa, Ontario, K1N 6N5Canadadelannoy@site.uottawa.caAbstractDecanter illustrates a heuristicapproach to extraction for informationretrieval and question answering.Generic information aboutargumentative text is found andstored, easing user-focused, question-driven access to the core information.The emphasis is placed on theargumentative dimension, to addressin particular three types of questions:?What are the points?
?, ?Based onwhat??
?What are the comments?
?.The areas of application of thisapproach include: question-answering,information retrieval, summarization,critical thinking and assistance tospeed reading.11.11.2IntroductionDecanter is a prototype to detect and displayhigh-level information from argumentative text.The game is one of situating andcontextualizing.Queries and RequestsInformation requests can be classified by typesof questions, bearing for example on: descriptiveknowledge (?tell me about Pakistan?
),narratives/updates (?what happened in CampDavid??
), know-how (?how can I replace the inkcartridge on my XYZ printer??
), evaluation oradvice (?Is Netscape 6 stable??
; ?Should I installNetscape 6??
).One can take them on face value or not.
Inexplicitly argumentative, and in loaded topics(like politics) it is in the interest of the user tohave elements of context in the cognitivemodeling he/she is doing of the text contents.Paying due attention to argumentationcontributes in two ways:- by giving contexts to answers, helpingqualify them for credibility- By answering to questions aboutopinions and stances: whatLevels of Answering: on topic, onquestion, with justifications (andreferences), with a stanceLevel zero is answering on topic.
This has beenthe only concern of ?classical IR?
(and still,word-sense disambiguation is not quite thereyet?
).Level one of question-answering is then toanswer to the point semantically orpragmatically (depending of what kind ofinformation need there is, relevance is of adifferent nature: in a nutshell, answering apractical question can require action-orientedinformation, but answers a la AskJeeves talkingof travel agents when one just wants the distancefrom Paris to London are waylaid).
As I stressheavily in my IR course (Delannoy 2001c)answers, and summaries alike, have to addressrelations, not just concepts.
Answers should notjust be ?about?
the keywords, but give the rightkind of information: the height, the name, thecolour, the description rather than the price, etc.
(in many cases, a wholesale description may bejudged satisfactory, but the user incurs a post-filtering overhead).There is another dimension, though: context, ina broad sense.
Context includes: who gives theanswer; on what medium; what it the answerbased on in terms of auctorial or demonstration;is it convincing for other reasons.
A valuableanswer is one given with good ?
reason: theanswer should be rational, i.e.
plausible,checkable, supported by authority of sourceand/or good demonstration.
There is here anidea of critical thinking.Critical thinking (Toulmin 84, Little et al 89,Mendenhall 90; Aristotle?s Organon) is thestudy of formal argumentation, and of what canbe accepted reasonably in not-so-formalargumentation (what dose of induction; whatauctoritas).
This is often met with derision byvarious brands of relativism in and outsideacademia, although people of this suasion tooplay the argumentation game: they offerelements of proof; they rarely fling totally non-logical-looking rhetoric.
But bottom lines thereare, and, in the apt words of the title of Little etal.
1989, good reasoning matters!How to track it then?
The next section is aboutthe ?decanting?
done by our prototype; Section3 is about retrieving what has been decanted, viaquestioning.233.1DecantingThe input consists of one or several texts, by oneor several authors and possibly mentioningseveral ?actors?
(who are also often ?utterers?,but ).The general workflow is the following.1.
segment2.
extract entities, in particular the actors3.
detect utterances4.
analyze them argumentatively in asimple way: links of claims-evidence,evidence-evidence (contribute, contrast)5. infer underlying goals and values (e.g.prioritizing equity over efficiency;immediate goals vs stability)6. detect polarity: for, against7.
link authors to utterances (who saidwhat), and to points of view (what arethe stances)Topics are registered in a knowledge base (e.g.economics, war, elections) and issues (mostefficient course of action, objectivemeasurement of income or turnover, objectivityof declarations by public figures, etc.).
It isconsidered to implement a module of semi-automatic acquisition: the user, prompted withlists of potential entries, would select and editthem for incorporation into the knowledge base.The output comes in multiple forms, as selectedby the user:- list of entities- main structure of the claims- quotes- marked-up text (entities, reasoning)- table of points and stances (and theirholders) on the issues at hand.- extractive summary based on claims ratherthan evidence) and, classically, position,importance cues and keyword density(Delannoy et al 98).RepresentationKeysThree keys give viewing angles on theinformation: actors, topics, and issues,correspond to basic factual questions a readermay have (Table 1).key attributes questionAnactorutters quotes  What did X say?has stances onissuesWhat does X thinkon I, i.e.
is s/he foror against?and stances oncourses of actionWhat does Xadvocate/propose/support?has previsions What does X thinkWill happen?prioritizes/foregrounds somevalues overothersWhat are(allegedly) X'sforemost values?atopicinvolves issues What are theissues?involves coursesof actionWhat are thepossible coursesof action?anissueinvolves actorssituated pro andcontraWhat are thecomments?Table 1.
Keys, attributes, and related questions3.23.344.14.24.3Background knowledgeSome knowledge is pre-encoded or reused fromprevious processing, and some is built duringthe analysis.For repeated analysis of texts on the same topic,the knowledge built can of course be reused.- list of topics and issues, and thecorresponding heuristics used todetermine which are expected to berelevant to a given text- list text types, and associated heuristics- values: e.g.
equity, egalitarianism, vitalminimum/income, safety, ethnic identity,personal freedom, access to information,democracyKnowledge built with theprocessing:- actors in the input text; other entities- quotes in the text; their association withactors- claims- evidence- association of actors with claims, evidenceProcessingThe general working is the following.Situate and segment the text- guess text topic, from keywords situatingknow topics; this is done easily- segment the text into clauses (the variousclauses of the same utterance are thenlinked)Extract elements- extract entities, in particular the actors- detect utterancesAssign relations:- articulate utterance components (mainrelations: evidence-of, support, contrast)- assign entity-to-utterance relations (whosaid what, textually)- polarities (who is for/contra what;including the author of the document)- infer underlying goals and values (e.g.identifying, if possible, whether an authorprioritizes equity over efficiency;immediate goals vs stability)- link authors to utterances (who said what),and to points of view (what are thestances).The program uses a small knowledge baseabout the known topics (e.g.
economics, war,elections) and issues (most efficient course ofaction, objective measurement of income orturnover, objectivity of declarations by publicfigures, etc.
).The processing uses heuristic rules and pattern-matching to recognize syntactic-semanticpatterns, e.g.
:- entities regular expressions- cues to topic- syntactic patterns of direct and reportspeech, to assign quotes- cues to polarity- argumentation operators.It is being considered to implement a module ofsemi-automatic acquisition: the user, promptedwith lists of potential entries, would select andedit them for incorporation into the knowledgebase.4.45Querying/QuestioningVarious questions can be asked and answeredusing the structures produced, and especially:- What?
-> What are the points made?- Why so?
->  What are the justifications?- What are the points of view or comments?
(including of the authors themselves)Example 1: Results of Decanting(actual example)From a simple input:Ehud Barak, the Israeli president, said "wewant peace".He added: "This is our main goal.
""We want peace too", OLP Leader Arafatanswered.Arafat added that Barak said that Israelmay pull out of Gaza.Because Barak and Arafat have differentstandpoints, the peace process is fragile,even though they both want a peacefulresolution.we derive the following structures.ACTORS AND QUOTESContext1ref: textname="text1", utterer="John Doe", date="19990101"{Barak [assert]: "we want peace"Barak [assert]: "this is our main goal"Arafat [assert] "we want peace too".Context2 { utterer="Arafat"Barak [assert] "Israel may pull out of Gaza"}The peace process will take time [cause_from]Barak and Arafat have different standpoints.The peace process will take time[detract] Barakand Arafat want a peaceful resolution.
}NB The utterer of the last assertions is theauthor of the input text.
If we process multipletexts, we have to indicate it explicitly (authornameSTANCESpeace [pro] Barakpeace [pro] ArafatPREDICTIONSJohn Doe [predict] the peace process will taketimeAs of the submission of this article, theprototype detects the quotes but not the stancesand contexts (which functionalities are underdevelopment).6 Example 2: ?What Are theComments??
(manual study)This example is to indicate the kind ofcomparative output targeted (but notimplemented as yet), and the series of linguisticand modeling difficulties involved in producingit.
It is based on an excerpt from a BBC bulletinboard linked, at the time, from news.bbc.co.uk,called ?BBC Talking point?, athttp://newsvote.bbc.co.uk/hi/english/talking_point.The case in point was the desirable attitudetowards the participation of J?rg Haider?sFreedom Party (FP?)
in Austria in agovernmental coalition in February 2000.Notes on the table- ID: numbering, for convenience- No d-author (author of the page or article) ismentioned, as all the texts in this exampleare from the same page.- Author: author of the comment;identification if free (may be a pseudonym)- Statement:  original statement- Marked up statement: statement afterinsertion of argumentation tags- Summary, manual: freely rephrased (there isalso a summary from the BBC editor, whichwe do not mention here)- Arguments: main justifications, rephrased- Orientation:: here, by convention, pro means?for?
Haider?s mandate and againstsanctions; NOT necessarily in favour ofHaider and his party.id Author Statement Summary,manualArguments Orient.Notes1 Nico C. K.,AustriaThe EU is neitherjustified nor allowedto isolate Austria.Austria is, after all, afull member in goodstanding of the EU andits new governmenthas not actuallycommitted any actscontrary to EUprinciples.
If the EUstarts policing itsmembers over theoutcome of duedemocratic process,who will police the EUwhen it gets out ofhand?Sanctions arenot justifiable,as Austria is alegitimatemember andhas donenothingwrong..- sanctions are notjustified nor legal- Austria is a member ofthe EU in good standing- no devious acts- Austria is master athome- counterfactual: if EUat large becomesdevious, who willcontrol it?p Pb: the core point maybeless noteworthy or quote-worthy than a justificationof it.2 Jason H.,USAI do not believe theEU and America areover reacting.
I thinkthey see the Haiderphenomenon as a"virus" that mightinfect other moreimportant parts ofEurope if it does notreact strongly now to"quarantine" it.Haider is like avirus.
Yes,isolate Austriavirus epidemicsmetaphorp The author, implicitly,adopts the advice ofquarantining the(metaphorical) virus orvirus-bearer.3 Ron, USA The E.U.
is over-reacting.
There are twobasic ideas Brusselsdoes not get, freedomand liberty.
If this"political censorship"is carried out, let usremember it camefrom the left and notthe right.
The EU isdoomed if thesesanctions are carriedout.
Brussels shouldlet the people decidefor once.Freedom atnational levelhasprecedence.This amounts topolitical censorship.- Decisions should notcome from outside orabove.p Positively loaded terms:freedom, liberty.
(In fact,rather redundant; andsemantically pliable).Negatively loaded:political censorship;curiously, appears quoted.Paradox, from implicitknowledge that the left isnormally more principledabout liberty than theright.Implicit: The EUadministration is often notheeding much other levelsof decision.7 Jaya N.,IndiaI think the EU hasreacted responsiblyand followed throughon its earlierstatements.
When onecountry acts in such away as to promoteleaders with outrightprejudice, the rest ofthe Nations must do allin their power tosubdue further action.The EU isright, and hasbeen actingconsistently,because this isa clear case ofprejudice.Austria (or the FP?)
isprejudicedc Loaded: ?outrightprejudice.
?Reasoning from general(?when one country?)
toparticular.Rem: fails to distinguishbetween prejudice in theFP?
?s policy andsupposed prejudice of thecountry as such or inmajority.788.18.28.38.4Evaluation / CommentaryThis is prototype work, but several originalfunctionalities are already giving results:- characterizing the topic, based ondiscriminating keywords ?
i.e.
the systemmakes good guesses among a dozen topicsincluding economics/finance, economicpolicy, conflict, social/labour relations,culture, electoral politics?- from the topic, predicting typical issues onwhich stances articulate: for example foreconomic policy, one may expect stancesabout deregulation, globalization, interestrates, etc.- extracting quotes in direct speech gives60% good results; on indirect speech, thisgoes down to about 40%.- stance assignment works at about 50%success (good positives).Entity-extraction is not particularly original, likefinding entities, classifying them, detectingnaming equivalences for the entities.Related workPhilosophy and Critical ThinkingBooks on critical thinking (Little et al 89,Mendenhall 90) use representations of argumentstructures (e.g.
as diagrams) but give no hint ashow to automate it, i.e to go from text to model.Linguistics and NLPWhile research in linguistics has addressedseveral brands of ?discourse analysis?
asdialogue pragmatics and the search forunderlying ?ideology?
or values, there is little ingeneral linguistics about the study ofargumentation proper.Simone Teufel (1999) performs ?argumentativezoning?
on research papers, finding types ofpassages like: aim, background, own research,continuation.
The result is a colour-codeddisplay of the input, based on an XML markup.Bayes and ngrams are used to perform thisclassication task.
(Interestingly, she finds goodagreement between manual annotators, vsvarious research in summarization failing todetect ?golden standard?
summaries.)
This isargumentation in a rather specialized (scientificresearch in AI, i.e., largely, innovation inproblem-solving) and shallow (no collation ofthe points themselves; one-level) sense.
Incontrast, Decanter is designed to deliver arepresentation of conclusions and justifications,from several uttererers in parallel or in a nestedfashion if applicable.Some work on summarization, in particular byDaniel Marcu  (Marcu 97) has looked at the"rhetoric" dimension of text, based on RST(Mann&Thompson 88).
It produces a detailedand high-quality tree representing thearticulation of the text, but it is qualitatively ahybrid: it does not separate argumentation frommere description or narration.
The detailed userstudy and modeling done in (Endres-Nieggemeyer 97) gives little place toargumentation tracking in the summarizationprocess.
(Barker et al 94) process rules and exampleslegal text to produce a semantic output then fedto a machine learning system doinggeneralization and abstraction.
Yet it does notconsider contexts of utterance.Information retrievalInformation has focused even less onargumentation.
As indicated above, answeringon-topic is useful, but often the user is in factlooking for information which answers aquestion, which is situated, and which mayinvolve opinions.
We know of no work inargumentation-based IR ?
all the overhead ofhigh-level filtering of argument being left to theuser.Knowledge Representation andautomated reasoningSome authors in computational linguistics haveapproached contexts.
Ballim & Wilks doknowledge representation with nested contextswith Fauconnier?s mental spaces.
Moulin usesconceptual graphs to represent spatio-temporalcontexts from text.
(Recently, a student projectin his department has addressed argumentation,it seems, but information is scarce).
Recently, acontributor to the CG list, L. Misek-Falkoff,asked for tools to represent nested contexts intort/defamation; there were some answerspointing to tools, but not to tools capable ofdoing this.Various studies of reasoning, on the legaldomain like (Bench-Capon 97) or more generallike (Zukerman et al 99), representsophisticated reasoning, without performingextraction from text.
(Delannoy 99) proposed an XML mark-upscheme for argumentation as such, the ideabeing to flag it inside the text besides producinga separate representation.
Decanter is designedto do both.99.19.29.31011Future workFurther work is intended to address a variety ofrobustness and scope issues, including referenceresolution (neglected in IR) and the detection oflexicalized irony in the expression of stances.More Manual AnalysisI am currently working on digesting severalargumentative corpora on- issues of drug legalization (in Delannoy2001b)- Colombia (Plan Colombia, conflict,violence)- the Digital Divide (i.e.
low access to theInternet by segments of Canadian or worldpopulation).Reference resolutionThis is another neglected topic in IR.
Evenmedium-quality reference resolution wouldenhance performance in IR, including in ourapproach.Indirect argumentation and ironyIndirect argumentation, especially ironyIrony is an ingredient of rhetoric and can be ofuse in tracking stance on topics, stances on otheractors, and also style of course.
In another study(Delannoy 2001b) I observe the alternating useof irony and indignation.
Besides the directinterest as a study rhetoric, it shows the varianceof one factor of enunciation the socio-psychological attitude, while the doxastic-epistemic attitude stays aligned (the stance).From an IR point of view, one could try todifferentiate ironic from non-ironic passages;also to normalize them into a ?just the stance?form ?
a desalination device of sorts!ConclusionIR and NLP should pay due attention toquestion-focused information of course, but toother textual elements participating in the valueof the returns, both 1) when it gives a usefulcharacterization of the usability of the answer ?as plausible, corroborated, demonstrated, novel,etc.
2) to begin to answer questions neveraddressed in IR and CL but definitely pervasivein user needs, either easily phrasable, in thestyle: ?Is Netscape a good tool?
?, ?Is itadvisable to buy Microsoft stock soon?
?, or as amore underlying information goal: ?So, what isLe Monde saying about the new developmentsof Plan Colombia and about the politicalreactions??.
This second type can be useful bothto interested layme and to professionals ofinformation and politics.Moreover, a matrix presentation as in example 2can be quite useful and reusable.
That is, to beeven more useful, argumentation analysis shouldintegrate information retrieval + analysis +aggregation.In a Baconian vein: The information retrieverand questioner has to use Invention (IRtechniques) and Judgment (critical thinking) totap into Memory (writing, library science) andTradition (corpus of knowledge, opinions).Decanter opens the way to the necessarycontribution of Judgment in Invention.ReferencesAristotle.
Organon.Ballim A & Wilks.
1991: Artificial Believers,Lawrence Erlbaum AssociatesK.
Barker, JF Delannoy, S. Matwin, S.Szpakowic.
1994: "From text to Horn clauses",Proceedings of the Canadian Conference onArtificial Intelligence (AI/GI/CV '94), Banff,Alberta, Canada, March 1994, pp.
9-16Bench-Capon, T.J.M.
1997.
Argument inArtificial Intelligence and Law ArtificialIntelligence and Law, Vol 5 No 4., 1997, pp249-61.Delannoy JF.
1999.
"Argumentation Mark-Up: A Proposal", Workshop "TowardsStandards and Tools for Discourse Tagging",Conference of the Association forComputational Linguistics (ACL'99), U.Maryland, College Park, MD, June 22, 1999Delannoy JF.
2001b.
"Arguing about drugs",OSSA 2001 (conference of the Ontario Societyfor the Study of Argumentation), Windsor,Ontario, May 2001Delannoy JF.
1200c.
course material forCSI4107, Information Retrieval and theInternet, University of Ottawa:http://www.site.uottawa.ca/~delannoy/csi4107Endres-Nieggemeyer, Brigitte.
1997.Summarizing Information, Springer, 1997Fauconnier, G. 1985.
Mental Spaces:Aspects of meaning construction in naturallanguage.
MIT Press, Cambridge, MA.Little J, Groarke L,Tindale C. 1989.
Goodreasoning matters!, McClelland&StewartMann, W. & Thompson, S.
1988.?Rhetorical structure theory: Towards afunctional theory of text organization?, Text8(3), 241-281Marcu, Daniel.
1997.
The RhetoricalParsing, Summarization, and Generation ofNatural Language Texts, Ph.D. Dissertation, UToronto, 1997Mendenhall V. 1990.
Une introduction ?l'analyse du discours argumentatif.
Presses del'Universit?
d'Ottawa, 1990Teufeul, S.  1999.
Argumentative Zoning.Information Extraction from ArgumentativeText.
Ph.D. Thesis, U. Edimburg, 1999Toulmin S, Riek R, Janik A.
1984.
AnIntroduction to Reasoning, MacMillanZukerman, I., McConachy, R., Korb, K. andPickett, D. 1999.
Exploratory Interaction with aBayesian Argumentation System.
IJCAI99Proceedings (16th International JointConference on Artificial Intelligence), pp.
1294-1299, Stockholm, Sweden, Morgan KaufmannPublishers
