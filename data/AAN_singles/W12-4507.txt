Proceedings of the Joint Conference on EMNLP and CoNLL: Shared Task, pages 76?82,Jeju Island, Korea, July 13, 2012. c?2012 Association for Computational LinguisticsA Mixed Deterministic Model for Coreference ResolutionBo Yuan1, Qingcai Chen, Yang Xiang, Xiaolong Wang2Liping Ge, Zengjian Liu, Meng Liao, Xianbo SiIntelligent Computing Research Center, Key Laboratory of Network Oriented IntelligentComputation, Computer Science and technology Department, Harbin Institute of TechnologyShenzhen graduate School, Shenzhen, Guangdong, 518055, China{yuanbo.hitsz1, windseedxy, qingcai.chen, geliping123,autobotsonearth, dream2009gd, sixianbo}@gmail.comwangxl@insun.hit.edu.cn2AbstractThis paper presents a mixed deterministicmodel for coreference resolution in theCoNLL-2012 shared task.
We separate thetwo main stages of our model, mentiondetection and coreference resolution, intoseveral sub-tasks which are solved bymachine learning method anddeterministic rules based on multi-filters,such as lexical, syntactic, semantic, genderand number information.
We participate inthe closed track for English and Chinese,and also submit an open result for Chineseusing tools to generate the required features.Finally, we reach the average F1 scores58.68, 60.69 and 61.02 on the Englishclosed task, Chinese closed and open tasks.1 IntroductionThe coreference resolution task is a complicatedand challenging issue of natural languageprocessing.
Although many sub-problems, such asnoun phrase to noun phrase and pronouns to nounphrase, are contained in this issue, it is interestingthat humans do not get too confused when theydetermine whether two mentions refer to the sameentity.
We also believe that automatic systemsshould copy the human behavior (Kai-Wei et al,2011).
In our understanding, the basis for humanmaking judgment on different sub-problems isdifferent and limited.
Although there are somecomplicated and ambiguous cases in this task, andwe are not able to cover all the prior knowledge ofhuman mind, which plays a vital role in hissolution, the mixed deterministic model weconstructed can solve a big part of this task.
Wepresent a mixed deterministic model forcoreference resolution in the CoNLL-2012 sharedtask (Sameer et al, 2011).Different methods such as Relaxation labeling(Emili et al, 2011), Best-Link (Kai-Wei et al,2011), Entropy Guided Transformation Learning(Cicero et al, 2011) and deterministic models(Heeyoung et al, 2011), were attempted in theCoNLL-2011 shared task (Sameer et al, 2011).The system performance reported by the taskshows that a big part of this task has been solvedbut some sub-problems need more exploration.We also participate in the Chinese closed andopen tracks.
However, the lack of linguisticannotations makes it more difficult to build adeterministic model.
Basic solutions such as HobbsAlgorithm and Center Theory have been listed in(Wang et al, 2002; Jun et al, 2007).
The recentresearch on Chinese contains non-anaphorsdetection using a composite kernel (Kong Fang, etal., 2012(a)) and a tree kernel method to anaphoraresolution of pronouns (Kong Fang et al, 2012(b)).We accept the thought of Stanford (Karthik et al,2010; Heeyoung et al, 2011).
In Stanford systemthe coreference resolution task is divided intoseveral problems and each problem is solved byrule based methods.
For English we did someresearch on mention detection which uses DecisionTree to decide whether the mention ?it?
shouldrefer to some other mention.
For Chinese wesubmit closed and open result.
The lack of gender,76number and name entities make it more difficultfor the Chinese closed task and we try to extractinformation from the training data to help enhancethe performance.
For the open task, we use somedictionaries such as appellation dictionary, genderdictionary, geographical name dictionary andtemporal word dictionary (Bo et al, 2009), andsome tools such as conversion of pinyin-to-character and LTP which is a Chinese parser thatcan generate the features such as Part-of-Speech,Parse bit, Named Entities (Liu et al, 2011) togenerate the similar information.We describe the system architecture in section 2.Section 3 illustrates the mention detection process.Section 4 describes the core process of coreferenceresolution.
In section 5, we show the results anddiscussion of several experiments.
Finally, we givethe conclusion of our work in section 6.2 System ArchitectureOur system mainly contains mention detection andcoreference resolution.
Recall is the determiningfactor in mention detection stage.
The reason isthat if some mention is missed in this stage, thecoreference resolution part will miss the chainswhich contain this mention.
Yet some mentionsstill need to be distinguished because in some casesthey refer to no entity.
For example ?it?, in thesentence ?it + be + weather/ time?, ?it?
should referto no entity.
But the ?it?
in the phrase ?give it tome?
might refer to some entity.
The coreferenceresolution module of our system follows the ideaof Stanford.
In the English task we did some moreexploration on mention detection, pronouncoreference and partial match of noun phrases.
TheChinese task is more complicated and becausegender, number and name entities are not provided,the feature generation from the training data has tobe added before the coreference resolution process.Some Chinese idiomatic usages are also consideredin this stage.3 Mention detectionAll the NPs, pronouns and the phrases which areindexed as named entities are selected ascandidates.
NPs are extracted from the parse tree.Yet some mentions do not refer to any entity insome cases.
In our system we attempt todistinguish these mentions in this stage.
The reasonis that the deterministic rules in coreferenceresolution part are not complete to distinguishthese mentions.
The methods below can also beadded to the coreference resolution part as a pre-processing.
For the conveniences of system design,we finish this work in this stage.For English, the pronoun ?it?
and NPs ?this, that,those and these?
need to be distinguished.
We take?it?
as an example to illustrate the process.
First weuse regular expressions to select ?it?, which refersto no entity, such as ?it + be + weather/ time?, ?ithappened that?
and ?it makes (made) sense that?.Second we use Decision Tree (C4.5) to classify thetwo kinds of ?it?
based on the training data.
Thefeatures contain the Part-of-Speech, Parse bit,Predicate Arguments of ?it?, the word before andafter ?it?.
The number of total ?it?
is 9697 and 4043of them have an entity to refer to in the trainingdata.Category Precision Recall Fno entity referedentity refered0.5760.7470.5960.7310.5860.739total 0.682 0.679 0.68Table 1: Results of ?it?
classification using C4.5Table 1 shows the classification result of ?it?
inthe development data v4.
The number of total ?it?is 1401 and 809 of them have an entity to refer to.The result is not perfect but can help enhance theperformance of coreference resolution.
However,the results of ?this, that, those and these?
are notacceptable and we skip over these words.
We didnot do any process on ?verb?
mention detection andcoreference resolution.In addition, we divide mentions into groups inwhich they are nested in position.
And formentions which have the same head word in onegroup, only the mentions with the longest spanshould be left (for the English task and a set ofChinese articles).
For some Chinese articles ofwhich names contain ?chtb?, both in the trainingdata and the development data, the nest ispermitted based on the statistic results.For Chinese we also attempt to train a model forpronouns ???
(you) and ???(that).
However, theresults are not acceptable either since the featureswe select are not enough for the classifier.After the mentions have been extracted, therelated features of each mention are also extracted.We transform the ?conll?
document into mention77document.
Each mention has basic features such asposition, part-of-speech, parse tree, head word,speaker, Arguments, and the gender and number ofhead word.
The head word feature is veryimportant and regular expression can almostaccomplish the process but not perfectly.
Firstly,we extract the key NPs of a mention based onparse feature.
Then the regular expressions are toextract the head word.
For example, the mention:(NP (DNP (LCP (NP (NP (NR ??))
(NP (NN ??
)))(LC ?))
(DEG ?))
(NP (NR ??))
(NP (NN ??)))
(NP(DNP (LCP (NP (NP (NR ??))
(NP (NN ??)))
(LC ?
))(DEG ?))
(NP (NR ??))
(NP (NN ??
)))The key NPs of this mention is:(NP (NR ??))
(NP (NN ??))
.The head word ofthis mention is: NN ?
?However, there are still some cases that need tobe discussed.
For example, the head word of ?theleader of people?
should be ?leader?, while the headword of ?the city of Beijing?
should be ?city?
and?Beijing?
for the mentions of ?the city?
and?Beijing?
both have the same meaning with ?thecity of Beijing?.
Finally, we only found the wordsof ?city?
and ?country?
should be processed.4 Coreference resolutionThe deterministic rules are the core methods tosolve the coreference resolution task.
All thementions in the same part can be seen as a list.
Thementions which refer to the same entity will beclustered based on the deterministic rules.
After allthe clusters have generated, the merge programwill merge the clusters into chains based on theposition information.
The mentions in one chaincannot be reduplicative in position.
Basically thenested mentions are not allowed.The process contains two parts NP-NP and NP-pronoun.
Each part has several sub-problems to bediscussed.
First, the same process of English taskand Chinese task will be illustrated.
Then thedifferent parts will be discussed separately.4.1 NP-NPExact match: the condition of exact match is thetwo NP mentions which have no other largerparent mentions in position are coreferential if theyare exactly the same.
The stop words such as ?a?,?the?, ?this?
and ?that?
have been removed.Partial match: there are two conditions forpartial match which are the two mentions have thesame head word and one of them is a part of theother in form simultaneously.Alias and abbreviation: some mentions havealias or abbreviation.
For example the mentions?USA?
and ?America?
should refer to the mention?the United States?.Similar match:  there are three forms of thismatch.
The first one is all the modifiers of two NPsare same and the head words are similar based onWordNet1 which is provided for the English closedtask.
We only use the English synonym sets of theWordNet to solve the first form.
The second one isthe head words are same and the modifiers are notconflicted.
The third form is that the head wordsand modifiers are all different.
The result of similarmatch may be reduplicative with that of exactmatch and partial match.
This would be eliminatedby the merge process.4.2 Pronoun - NPThere are seven categories of pronoun to NP in oursystem.
For English second person, it is difficult todistinguish the plural form from singular form andwe put them in one deterministic rule.
For eachkind of pronouns shown below, the first cluster isthe English form and the second cluster is theChinese form.First Person (singular) = {'I', 'my', 'me', 'mine','myself'}{???
}Second Person= {'you', 'your', 'yours', 'yourself','yourselves'}{????
????
}Third Person (male) = {'he', 'him', 'his','himself'}{???
}Third Person (female) = {'she', 'her', 'hers','herself'}{???
}Third Person (object) = {'it', 'its', 'itself'}{???
}First Person (plural) = {'we', 'us', 'our', 'ours','ourselves'}{????
}Third Person (plural) = {'they', 'them', 'their','theirs', 'themselves'}{?????
?????????
}In the Chinese task the possessive form ofpronoun is not considered.
For example, themention ???
?
?
(our) is a DNP in the parsefeature and it contains two words ????
and ??
?.We only selected the NP ???
?as a mention.
Thereflexive pronouns are composed by two wordswhich are the pronoun itself and the word ???
?.1 http://wordnet.princeton.edu/78For example, the mention ??
???
(myself) isprocessed as ???
(I or me).Gender, number and distance between pronounand NP are the most important features for this part(Shane et al, 2006).
We only allow pronoun tofind NPs at first.
We find out the first mention ofwhich all the features are satisfied ahead of thepronoun.
If there is no matching mention, searchbackward from the pronoun.
For the first personand second person, we merged all the pronounswith the same form and the same speaker.
If thecontext is a conversation of two speakers, thesecond person of a speaker should refer to the firstperson of the other speaker.
The scene of multi-speakers conversation is too difficult to be solved.In the Chinese task there are some otherpronouns.
The pronoun ????
(both sides) shouldrefer to a plural mention which contain ???
(and)in the middle.
The pronoun ??
?
has similarmeaning of third person and refers to the largestNP mention before it.
The pronouns ??
?(this),??
?
(that), ???
?
(here), ???
?
(there) are notprocessed for we did not find a good solution.However in some cases the provided gender andnumber are not correct or missing and we had tolabel these mentions based on the appellationwords of the training data.
For example, if theappellation word of a person is ?Mr.?
or ?sir?, thegender should be male.4.3 Chinese closed taskFor the Chinese closed task NE, the gender andnumber are not provided.
We used regular patternsto generate these features from the training data.In the NE (named entities) feature ?PERSON?
isa very important category because most pronounswill refer to the person entity.
To extract?PERSON?, we build a PERSON dictionary whichcontains all the PERSON mentions in training data,such as ????(Mr.)
and ????(Professor).
If thesame mention appears in the test data, we believe itis a person entity.
However, the PERSONdictionary cannot cover all the PERSON mentions.The appellation words are extracted before or afterthe person entity.
When some appellation wordappears in the test data, the NP mention before orafter the appellation word should be a person entity,if they compose a larger NP mention.The Gender feature was generated at the sametime of the ?PERSON?
generation.
We separate the?PERSON?
dictionary and appellation dictionaryinto male cluster and female cluster by thepronouns in the same chain.The generation of number feature is a littlecomplicated.
Since the Chinese word does not haveplural form, the numerals and the quantifiers of themention are the main basis to extract the numberfeature.
We extract the numerals and thequantifiers from the training data and built regularexpressions for determine the number feature of amention in test data.
Other determinative rules fornumber feature extraction are shown below:If the word ???
appears in a mention tail, thismention is plural.
For example ????
(student) issingular and ?????
(students) is plural.If the word ???
(and) appears in the middle of amention A, and the two parts separated by ???
aresub-mentions of A,  mention A should be plural.Other words which have the similar meaning of??
?, such as ??
?, ???
and ??
?, are considered.The time and date coreference resolution is alsoconsidered.
The NP mentions which containtemporal words are processed separately sincethese categories of name entity are not provided.These temporal words are also extracted fromtraining data.
Since the head words of thesementions are themselves, the two time or datementions are coreferential if they are the same orone must be a part of the other?s tail.
For example??????
(this September) and ????
(September)which are not nested should be coreferential.4.4 Chinese open taskFor the Chinese open task we use several tools togenerate features we need.NE generation: LTP is a Chinese parser that cangenerate the features such as Part-of-Speech, Parsebit, Named Entities (Liu et al, 2011).
We only useLTP for the NE generation.
However, the NElabels of LTP are different with that provided bythe gold training data and need to be transformed.The difference of word segmentation between LTPand the provided data also made some errors.
Atlast we find the NE feature from LTP does notperform well and it will be discussed in section 5.The conversion of pinyin-to-character is alsoused in the Chinese open task.
The speakerprovided in the training data is given in pinyinform.
The speaker might be the ?PERSON?mention in the context.
When we determine the79pronoun coreference, we need to know whether thespeaker and the ?PERSON?
mention are same.Other tools used in open task contain appellationdictionary, gender dictionary, geographical namedictionary and temporal word dictionary (Bo et al,2009).
These dictionaries are more complete thanthose used in the closed task, although theenhancements are also limited.5 Results and DiscussionTable 2 to table 4 show the results of Englishcoreference resolution on the gold and autodevelopment and the test data.
The results of theauto development data and the test data are closeand lower than that of the gold data.
Since thedeterministic rules can not cover all the cases,there is still an improvement if we could make thedeterministic rules more complete.Measure R  P F1Mention detectionMUCB377.765.169.271.862.970.974.66470.1CEAF(E)(CEAF(E)+MUC+B3)/346.4 48.9 47.660.6Table 2: Results of the English gold developmentdataMeasure R  P F1Mention detectionMUCB372.462.366.771.562.871.8726269.1CEAF(E)(CEAF(E)+MUC+B3)/346.4 44.9 45.658.9Table 3: Results of the English auto developmentdataMeasure R P F1Mention detectionMUCB373.262.166.271.96370.572.536368.3CEAF(E)CEAF(M)BLANC(CEAF(E)+MUC+B3)/345.757.372.144.757.376.945.257.374.258.68Table 4: Results of English test dataThe results of the closed Chinese performanceon the gold and auto development and the test dataare shown in table 5 to table 7.
The performance ofthe auto development data and the test data hasabout 4% decline to that of the gold developmenton F1 of coreference resolution.
It means theChinese results are also partly affected by the parsefeature.
In fact we attempted to revise the parsefeature of the auto development data using regularexpressions.
Yet the complicacy and unacceptableresults made us abandon that.Measure R  P F1Mention detectionMUCB382.371.676.769.864.374.275.567.775.4CEAF(E)(CEAF(E)+MUC+B3)/349 56.5 52.565.2Table 5: Closed results of the Chinese golddevelopment dataMeasure R P  F1Mention detectionMUCB374.263.673.1666073.57061.773.3CEAF(E)(CEAF(E)+MUC+B3)/347.3 50.6 48.961.3Table 6: Closed results of the Chinese autodevelopment dataMeasure R P F1Mention detectionMUCB372.862.473.164.158.472.768.1560.372.9CEAF(E)CEAF(M)BLANC(CEAF(E)+MUC+B3)/347.159.673.750.759.678.248.859.675.860.69Table 7: Closed results of the Chinese test dataThe results of the open Chinese performance onthe gold and auto development and the test data areshown in table 8 to table 10.
The performance issimilar with that of the closed task.
However, theimprovement between F1 of the open task and F1of the closed task is limited.
We also get the F1 ofthe closed and open test results using gold parserwhich are 66.46 and 66.38.
The open result is even80lower.
This can be explained.
The performanceenhanced by the dictionaries we used for the opentask are limited because the open dictionariesinformation which appears in the test data is notmuch more than that of the closed dictionarieswhich generated from the training data, althoughthe total information of the former is much larger.The named entities generated by LTP have someerrors such as person identification errors and willcaused coreferential errors in Pronoun-NP stage.For the time we did not use LTP well and someother open tools such as Wikipedia and BaiduBaike should be applied in the open task.Measure R P F1Mention detectionMUCB382.472.377.769.363.873.375.367.875.4CEAF(E)(CEAF(E)+MUC+B3)/348.3 56.8 52.265.1Table 8: Open results of the Chinese golddevelopment dataMeasure R  P F1Mention detectionMUCB375.164.974.265.759.972.670.162.373.4CEAF(E)(CEAF(E)+MUC+B3)/346.7 51.5 4961.6Table 9: Open results of the Chinese autodevelopment dataMeasure R P F1Mention detectionMUCB373.763.7746458.572.268.496173.1CEAF(E)CEAF(M)BLANC(CEAF(E)+MUC+B3)/360.146.874.360.151.57860.1497661.02Table 10: Open results of the Chinese test dataThe results of the gold-mention-boundaries andgold-mentions data of the English and Chineseclosed task are shown in table 11 and 12.
Althoughthe mention detection stage is optimized by thegold-mention-boundaries and gold-mentions dataand the final performance is enhanced, there is stillspace to enhance in the coreference resolutionstage.
The recall of mention detection of gold-mentions is 99.8.
This problem will be explored inour future work.Data R P F1Mention detection(A)gold-mention-boundariesMention detection(B)gold-mentions75.78070.810073.259.5088.9169.88Table 11: Results of the English closed gold-mention-boundaries and gold-mentions data, (A) isthe mention detection score of the gold-mention-boundaries and (B) is the score of the gold-mentions.Data R P F1Mention detection(A)gold-mention-boundariesMention detection(B)gold-mentions82.981.766.999.874.0264.4289.8576.05Table 12: Results of the Chinese closed gold-mention-boundaries and gold-mentions data6 ConclusionIn this paper we described a mixed deterministicmodel for coreference resolution of English andChinese.
We start the mention detection fromextracting candidates based on the parse feature.The pre-processing which contains static rules anddecision tree is applied to remove the defectivecandidates.
In the coreference resolution stage thetask is divided into several sub-problems and foreach sub-problem the deterministic rules areconstructed based on limited features.
For theChinese closed task we use regular patterns togenerate named entities, gender and number fromthe training data.
Several tools and dictionaries areapplied for the Chinese open task.
The result is notas good as we supposed since the feature errorscaused by these tools also made the coreferentialerrors.However, a deeper error analysis is needed inthe construction of deterministic rules.
The featureof the predicate arguments is not used well.Although the open performance of the Chinesetask is not good, we still believe that complete andaccurate prior knowledge can help solve the task.81AcknowledgementThis work is supported in part by the NationalNatural Science Foundation of China (No.61173075 and 60973076), ZTE Foundation andScience and Technology Program of Shenzhen.ReferencesBo Yuan, Qingcai Chen, Xiaolong Wang, Liwei Han.2009.
Extracting Event Temporal Information basedon Web.
2009 Second International Symposium onKnowledge Acquisition and Modeling, pages.346-350Cicero Nogueira dos Santos, Davi Lopes Carvalho.2011.
Rule and Tree Ensembles for UnrestrictedCoreference Resolution.
Proceedings of the 15thConference on Computational Natural LanguageLearning: Shared Task, pages 51?55.Emili Sapena, Llu?
?s Padr?o and Jordi Turmo.
2011.RelaxCor Participation in CoNLL Shared Task onCoreference Resolution.
Proceedings of the 15thConference on Computational Natural LanguageLearning: Shared Task, pages 35?39.Heeyoung Lee, Yves Peirsman, Angel Chang,Nathanael Chambers, Mihai Surdeanu, Dan Jurafsky.2011.
Stanford?s Multi-Pass Sieve CoreferenceResolution System at the CoNLL-2011 Shared Task.Proceedings of the 15th Conference onComputational Natural Language Learning: SharedTask, pages 28?34, Portland, Oregon.Liu Ting, Che Wanxiang, Li Zhenghua.
2011.
LanguageTechnology Platform.
Journal of ChineseInformation Processing.
25(6): 53-62Jun Lang, Bing Qin, Ting Liu, Sheng Li.
2007.
Intra-document Coreference Resolution: The state of theart.
Journal of Chinese Language and Computing.
17(4):227-253Kai-Wei Chang Rajhans Samdani.
2011.
InferenceProtocols for Coreference Resolution.
Proceedings ofthe 15th Conference on Computational NaturalLanguage Learning: Shared Task, pages 40?44,Portland, Oregon.Karthik Raghunathan, Heeyoung Lee, SudarshanRangarajan, Nathanael Chambers, Mihai Surdeanu,Dan Jurafsky, Christopher Manning.
2010.
A Multi-Pass Sieve for Coreference Resolution.
In EMNLP.Kong Fang, Zhu Qiaoming and Zhou Guodong.
2012(a).Anaphoricity determination for coreferenceresolution in English and Chinese languages.Computer Research and Development (Chinese).Kong Fang and Zhou Guodong.
2012(b).
Tree kernel-based pronoun resolution in English and Chineselanguages.
Journal of Software (Chinese).
Accepted:23(8).Sameer Pradhan, Lance Ramshaw, Mitchell Marcus,Martha Palmer, Ralph Weischedel and NianwenXue.2011.
CoNLL-2011 Shared Task: ModelingUnrestricted Coreference in OntoNotes.
Proceedingsof the Fifteenth Conference on ComputationalNatural Language Learning (CoNLL 2011).
Portland,OR.Sameer Pradhan and Alessandro Moschitti and NianwenXue and Olga Uryupina and Yuchen Zhang.
2012.CoNLL-2012 Shared Task: Modeling MultilingualUnrestricted Coreference in OntoNotes.
Proceedingsof the Sixteenth Conference on ComputationalNatural Language Learning (CoNLL 2012).
Jeju,Korea.Shane Bergsma and Dekang Lin.
2006.
BootstrappingPath-Based Pronoun Resolution Proceedings of the21st International Conference on ComputationalLinguistics and 44th Annual Meeting of the ACL,pages 33?40, SydneyWang Houfeng.
2002.
Survey: Computational Modelsand Technologies in Anaphora Resolution.
Journal ofChinese Information Processing.
16(6): 9-17.82
