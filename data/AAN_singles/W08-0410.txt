Proceedings of the Second ACL Workshop on Syntax and Structure in Statistical Translation (SSST-2), pages 78?86,ACL-08: HLT, Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsInductive Detection of Language Features via Clustering Minimal Pairs:Toward Feature-Rich Grammars in Machine TranslationJonathan H. Clark, Robert Frederking, Lori LevinLanguage Technologies InstituteCarnegie Mellon UniversityPittsburgh, PA 15213, USA{jhclark,ref,lsl}@cs.cmu.eduAbstractSyntax-based Machine Translation systemshave recently become a focus of researchwith much hope that they will outperformtraditional Phrase-Based Statistical MachineTranslation (PBSMT).
Toward this goal, wepresent a method for analyzing the mor-phosyntactic content of language from anElicitation Corpus such as the one included inthe LDC?s upcoming LCTL language packs.The presented method discovers a mappingbetween morphemes and linguistically rele-vant features.
By providing this tool thatcan augment structure-based MT models withthese rich features, we believe the discrimina-tive power of current models can be improved.We conclude by outlining how the resultingoutput can then be used in inducing a mor-phosyntactically feature-rich grammar for AV-ENUE, a modern syntax-based MT system.1 IntroductionRecent trends in Machine Translation have begunmoving toward the incorporation of syntax andstructure in translation models in hopes of gainingbetter translation quality.
In fact, some structure-based systems have already shown that they can out-perform phrase-based SMT systems (Chiang, 2005).Still, even the best-performing data-driven systemshave not fully explored the depth of such linguisticfeatures as morphosyntax.Certainly, many have brought linguistically moti-vated features into their models in the past.
Huangand Knight (2006) explored relabeling of non-terminal symbols to embed more information di-rectly into the backbone of the grammar.
Bonneau-Maynard et al (2007) argue that incorporation ofmorphosyntax in the form of a part of speech (POS)language model can improve translation.
Whilethese approaches do make use of various linguis-tic features, we have only begun to scratch the sur-face of what actually occurs in the languages of theworld.
We wish to address such issues as case mark-ing, subject-verb agreement, and numeral-classifieragreement by providing models with informationabout which morphemes correspond to which gram-matical meanings.2 Task OverviewFeature Detection is the process of determining froma corpus annotated with feature structures (Figure 2)which feature values (Figure 1) have a distinct rep-resentation in a target language in terms of mor-phemes (Figure 3).
By leveraging knowledge fromthe field of language typology, we know what typesof phenomena are possible across languages and,thus, which features to include in our feature speci-fication.But not every language will display each of thesephenomena.
Our goal is to determine which fea-ture values (e.g.
singular, dual, plural) have a dis-tinct encoding in a given target language.
Vieweddifferently, we can ask which feature values can beclustered by similarity.
For instance, in Chinese, wewould expect singular, plural and dual to be mem-bers of the same cluster (since they are typically notexplicitly expressed), while for Arabic we shouldplace each of these into separate clusters to indicatethey are each grammaticalized differently.
Similarly,78Feature Name Feature Value Commentnp-gen m ,f, n Biological Gendernp-def +, - Definitenessnp-num sg, dl, pl Numberc-ten past, pres, fut Tensenp-function act, und Actor and undergoer participant rolesc-function main, rel Main and relative clause rolesFigure 1: An example feature specification.ID Source Language Target Language Lexical Cluster Feature Structures1 He loves her.
El ama a ella.
`1 ((act (np-gen m) (np-num sg) (np-def +))(und (np-gen f) (np-num sg) (np-def +)) (c-ten pres))s2 She loves her.
Ella ama a ella.
`1 ((act (np-gen f) (np-num sg) (np-def +))(und (np-gen f) (np-num sg) (np-def +)) (c-ten pres))s3 He loved her.
El *ama a ella.
`1 ((act (np-gen m) (np-num sg) (np-def +))(und (np-gen f) (np-num sg) (np-def +)) (c-ten past))s4 The boy eats.
El nin?o come.
`2 ((act (np-gen m) (np-num sg) (np-def +)) (c-ten pres))s5 The girl eats.
La nin?a come.
`2 ((act (np-gen f) (np-num sg) (np-def +)) (c-ten pres))s6 A girl eats.
Una nin?a come.
`2 ((act (np-gen f) (np-num sg) (np-def -)) (c-ten pres))s7 The girls eat.
Las nin?as comen.
`2 ((act (np-gen f) (np-num pl) (np-def +)) (c-ten pres))s8 The girls eat.
Las nin?as comen.
`2 ((act (np-gen f) (np-num dl) (np-def +)) (c-ten pres))s9 Girls eat.
Unas nin?as comen.
`2 ((act (np-gen f) (np-num pl) (np-def -)) (c-ten pres))Figure 2: An example of sentences that might be found in an elicitation corpus.
Notice that each sentence differs fromsome other sentence in the corpus by exactly one feature value.
This enables us to see how the written form of thelanguage changes (or does not change) when the grammatical meaning changes.English would have two clusters for the feature num-ber: (singular) and (dual, plural).
Further, we wouldlike to determine which morphemes express each ofthese values (or value clusters).
For example, En-glish expresses negation with the morphemes no andnot, whereas questions are expressed by reorderingof the auxiliary verb or the addition of a wh-word.Though many modern corpora contain feature-annotated utterances, these corpora are often notsuitable for feature detection.
For this purpose, weuse an Elicitation Corpus (see Figure 2), a corpusthat has been carefully constructed to provide a largenumber of minimal pairs of sentences such as Hesings and She sings so that only a single feature (e.g.gender) differs between the two sentences.
Also, no-tice that the feature structures are sometimes moredetailed than the source language sentence.
For ex-ample, English does not express dual number, butwe might want to include this feature in our Elicita-tion Corpus (especially for a language such as Ara-bic).
For these cases, we include a context field forthe translator with an instruction such as ?Translatethis sentence as if there are two girls.
?In the past, we proposed deductive (rule-based)methods for feature detection (Clark et al, 2008).In this paper, we propose the use of inductive fea-ture detection, which operates directly on the featureset that the corpus has been annotated with, remov-ing the need for manually written rules.
We defineinductive feature detection as a recall-oriented tasksince its output is intended to be analyzed by a Mor-phosyntactic Lexicon Generator, which will addressthe issue of precision.
This, in turn, allows us to in-form a rule learner about which language featurescan be clustered and handled by a single set of rulesand which must be given special attention.
How-ever, due to the complexity of this component, de-scribing it is beyond the scope of this paper.
We alsonote that future work will include the integration of amorphology analysis system such as ParaMor (Mon-son et al, 2007) to extract and annotate the valuablemorphosyntactic information of inflected languages.An example of this processing pipeline is given inFigure 4.79Feature Value Candidate Morphemesnp-gen m el, nin?onp-gen f ella, nin?anp-gen n *unobserved*np-def + el, la, lasnp-def - una, unasnp-num sg el, ella, la, una, come, nin?o, nin?anp-num dl-pl las, unas, comen, nin?asc-ten past-pres ?c-ten fut *unobserved*Figure 3: An example of the output of our system for the above corpus: a list of feature-morpheme pairings.ElicitationCorpusInductiveFeatureDetectionMorphosyntacticLexiconGeneratorUnsupervisedMorphologyInductionGrammarRuleLearnerDecoderFigure 4: An outline of the steps from an input Elicitation Corpus to the application of a morphosyntactically featurerich grammar in a MT decoder.
This paper discusses the highlighted inductive feature detection component.
Note thatthis is just one possible configuration for integrating inductive feature detection into system training.3 The Need to Observe Real DataOne might argue that such information could be ob-tained from a grammatical sketch of a language.However, these sketches often focus on the ?inter-esting?
features of a language, rather than those thatare most important for machine translation.
Fur-ther, not all grammatical functions are encoded inthe elements that most grammatical sketches focuson.
According to Construction Grammar, such in-formation is also commonly found in constructions(Kay, 2002).
For example, future tense is not gram-maticalized in Japanese according to most referencesources, yet it may be expressed with a constructionsuch as watashi wa gakoo ni iku yode desu (lit.
?Ihave a plan to go to school.?)
for I will go to school.Feature detection informs us of such constructional-ized encodings of language features for use in im-proving machine translation models.Recognizing the need for this type of data, theLDC has included our Elicitation Corpus in theirLess Commonly Taught Languages (LCTL) lan-guage packs (Simpson et al, 2008).
Already, theselanguage packs have been translated into Thai, Ben-gali, Urdu, Hungarian, Punjabi, Tamil, and Yoruba.With structured elicitation corpora already beingproduced on a wide scale, there exists plenty of datathat can be exploited via feature detection.
Some ofthese language packs have already been released foruse in MT competitions and they will start being re-leased to the general research community this yearthrough LDC?s catalog.4 Applications4.1 Induction of Feature-Rich GrammarsGiven these outputs, a synchronous grammar in-duction system can then use these feature-annotatedmorphemes and the knowledge of which features areexpressed to create a feature rich grammar.
Considerthe example in Figure 5, which shows Urdu subject-verb agreement taking place while being separatedby 12 words.
Traditional n-gram Language Mod-els (LM?s) would not be able to detect any disagree-ments more than n words away, which is the nor-mal case for a trigram LM.
Even most syntax-basedsystems would not be able to detect this problemwithout using a huge number of non-terminals, eachmarked for all possible agreements.
A syntax-basedsystem might be able to check this sort of agree-80ek talb alm arshad jo mchhlyoN ke liye pani maiN aata phink raha tha .
.
.a.SG student named Irshad who fish for water in flour throw PROG.SG.M be.PAST.SG.M?A student named Irshad who was throwing flour in the water for the fish .
.
.
?Figure 5: A glossed example from parallel text in LDC?s Urdu-English LCTL language pack showing subject-verbagreement being separated by 12 words.ment if it produced a target-side dependency tree asin Ding and Palmer (2005).
However, we are notaware of any systems that attempt this.
Therefore,the correct hypotheses, which have correct agree-ment, will likely be produces as hypotheses of tra-ditional beam-search MT systems, but their featuresmight not be able to discern the correct hypothe-sis, allowing it to fall below the 1-best or out of thebeam entirely.
By constructing a feature-rich gram-mar in a framework that allows unification-basedfeature constraints such as AVENUE (Carbonell etal., 2002), we can prune these bad hypotheses lack-ing agreement from the search space.Returning to the example of subject-verb agree-ment, consider the following Urdu sentences takenfrom the Urdu-English Elicitation Corpus in LDC?sLCTL language pack:Danish ne Amna ko sza diDanish ERG Amna DAT punish give.PERF?Danish punished Amna.
?Danish Amna ko sza dita haiDanish Amna DAT punish give.HAB be.PRES?Danish punishes Amna.
?These examples show the split-ergativity of Urduin which the ergative marker ne is used only forthe subject of transitive, perfect aspect verbs.
Inparticular, since these sentences have the perfectaspect marked on the light verb di, a closed-classword (Poornima and Koenig, 2008), feature detec-tion will allow the induction of a grammar that per-colates a feature up from the VP containing di in-dicating that its aspect is perfect.
Likewise, the NPcontaining Danish ne will percolate a feature up in-dicating that the use of ne requires perfect aspect.If, during translation, a hypothesis is proposed thatdoes not meet either of these conditions, unificationwill fail and the hypothesis will be pruned 1.Certainly, unification-based grammars are not the1If the reader is not familiar with Unification Grammars, werecommend Kaplan (1995)only way in which this rich source of linguistic infor-mation could be used to augment a structure-basedtranslation system.
One could also imagine a systemin which the feature annotations are simply used toimprove the discriminative power of a model.
Forexample, factored translation models (Koehn andHoang, 2007) retain the simplicity of phrase-basedSMT while adding the ability to incorporate addi-tional features.
Similarly, there exists a continuumof degrees to which this linguistic information canbe used in current syntax-based MT systems.
Asmodern systems move toward integrating many fea-tures (Liang et al, 2006), resources such as this willbecome increasingly important in improving trans-lation quality.5 System DescriptionIn the following sections, we will describe the pro-cess of inductive feature detection by way of a run-ning example.5.1 Feature SpecificationThe first input to our system is a feature specification(Figure 1).
The feature specification used for this ex-periment was written by an expert in language typol-ogy and is stored in a human-readable XML format.It is intended to cover a large number of phenom-ena that are possible in the languages of the world.Note that features beginning with np- are partici-pant (noun) features while features beginning withc- are clause features.
The feature specification al-lows us to know which values are unobserved duringelicitation (that is, no sentence having that featurevalue was given to the bilingual person to translate).This is the case for the first four features and theirvalues in Figure 1.
The last two function featuresand their values tell us what possible roles partici-pants and clauses can take in sentences.815.2 Elicitation CorpusAs outlined in Section 3, feature detection uses anElicitation Corpus (see Figure 2), a corpus that hasbeen carefully constructed to provide a large num-ber of minimal pairs of sentences such as He singsand She sings so that only a single feature (e.g.
gen-der) differs between the two sentences (Levin et al,2006; Alvarez et al, 2006).
If two features had var-ied at once (e.g.
It sang) or lexical choice varied(e.g.
She reads), then making assertions about whichfeatures the language does and does not express be-comes much more difficult.Notice that each input sentence has been taggedwith an identifier for a lexical cluster as a pre-processing step.
Specifying lexical clusters ensuresthat we don?t compare sentences with different con-tent just because their feature structures match.
Forexample, we would not want to compare Dog bitesman and Man bites dog nor The student snoredand The professor snored.
Note that bag-of-wordsmatching is insufficient for this purpose.Though any feature-annotated corpus can be usedin feature detection, the amount of useful informa-tion extracted from the corpus is directly dependenton how many minimal pairs can be formed from thecorpus.
For instance, one might consider using amorphologically annotated corpus or even an auto-matically parsed corpus in place of the elicitationcorpus.
Even though these resources are likely tosuffer from having very sparse minimal pairs due totheir uncontrolled usage of vocabulary, they mightstill contain some amount of useful information.However, since we seek both to apply these methodsto language for which there are currently no man-ually annotated corpora and to investigate featuresthat existing parsers generally cannot identify (e.g.generic nouns and evidentiality), we will not men-tion these types of resources any further.5.3 Minimal Pair ClusteringMinimal pair clustering is the process of groupingall possible sets of minimal pairs, those pairs of sen-tences that have exactly one difference between theirfeature structures.
We use wildcard feature struc-tures to represent each minimal pair cluster.
We de-fine a wildcard feature as any feature whose valueis *, which denotes that the value matches another *rather than its original feature value.
Similarly, wedefine the feature context of the wildcard feature bethe enclosing participant and clause type for a np-feature or the enclosing clause for a c- type fea-ture.
Then, for each sentence s in the corpus, wesubstitute a wildcard feature for each of the values vin its feature structure, and we append s to the listof sentences associated with this wildcard featurestructure.
A sample of some of the minimal pairsfor our running example are shown in Figure 6.Here, we show minimal pairs for just one wild-card, though multiple wildcards may be created ifone wishes to examine how features interact withone another.
This could be useful in cases such asHindi where the perfective verb aspect interacts withthe past verb tense and the actor NP function to addthe case marker ne (for split ergativity of Urdu, seeSection 4.1).
That said, a downstream componentsuch as a Morphosyntactic Lexicon Generator wouldperhaps be better suited for the analysis of feature in-teractions.
Also, note that the feature context is notused when there is only one wildcard feature.
Thefeature context becomes useful when multiple wild-cards are added in that it may also act as a wildcardfeature.The next step is to organize the example sentencesinto a table that helps us decide which examples canbe compared and stores information that will informour comparison.
Briefly, any two sentences belong-ing to the same minimal pair cluster and lexical clus-ter will eventually get compared.
As specified in Al-gorithm 1, we create a table like that in Figure 7.Having collected this information, we are now readyto begin clustering feature values.Algorithm 1 Organize()Require: Minimal pairs, lexical clusters, and thefeature specification.Ensure: A table T of comparable examples.for all pair m ?
minimalPairs dofor all sentence s ?
m dof?
wildcardFeature(s, m)v?
featureValue(s, f)c?
featureContext(m)`?
lexCluster(s)T[f,m, c, `, v]?
T[f,m, c, `, v]?
sreturn T82ID Set Members Feature Feature Context Feature Structurem1 {s1, s2} np-gen ((act)) ((act (np-gen *) (np-num sg) (np-def +))(und (np-gen f) (np-num sg) (np-def +)) (c-ten pres))m2 {s1, s3} np-ten () ((act (np-gen m) (np-num sg) (np-def +))(und (np-gen f) (np-num sg) (np-def +)) (c-ten *))m3 {s4, s5, s7, s8} np-gen ((act)) ((act (np-gen *) (np-num sg) (np-def +)) (c-ten pres))m4 {s5, s7, s8} np-num ((act)) ((act (np-gen f) (np-num *) (np-def +)) (c-ten pres))m5 {s6, s9} np-num ((act)) ((act (np-gen f) (np-num *) (np-def -)) (c-ten pres))m6 {s5, s6} np-def ((act)) ((act (np-gen f) (np-num sg) (np-def *)) (c-ten pres))m7 {s7, s9} np-def ((act)) ((act (np-gen f) (np-num pl) (np-def *)) (c-ten pres))Figure 6: An example subset of minimal pairs that can be formed from the corpus in Figure 2.Feature Min.
Pair Feat.
Context Lex.
Cluster Feat.
Value.
Sentencenp-gen m1 ((act)) `1 m s1np-gen m1 ((act)) `1 f s2np-ten m2 () `1 pres s1np-ten m2 () `1 past s3np-num m4 ((act)) `2 sg s5np-num m4 ((act)) `2 pl s7np-num m4 ((act)) `2 dl s8np-num m5 ((act)) `2 sg s6np-num m5 ((act)) `2 pl s9Figure 7: An example subset of the organized items that can be formed from the minimal pairs in Figure 6.
Each itemthat has a matching minimal pair ID, feature context, and lexical cluster ID can be compared during feature detection.5.4 Feature Value ClusteringDuring the process of feature value clustering, wecollapse feature values that do not have a distinctencoding in the target language into a single group.This is helpful both as information to componentsusing the output of inductive feature detection andlater as a method of reducing data sparseness whencreating morpheme-feature pairings.
We representthe relationship between the examples we have gath-ered for each feature as a feature expression graph.We define a feature expression graph (FEG) for afeature f to be a graph on |v| vertices where v isthe number of possible values of f (though for mostnon-trivial cases, it is more conveniently representedas a triangular matrix).Each vertex of the FEG corresponds to a featurevalue (e.g.
singular, dual) while each arc containsthe list of examples that are comparable accordingto the table from the previous step.
The examples ateach arc are organized into those that had the sametarget language string, indicating that the feature val-ues are not distinctly expressed, and those that hada different target language string, indicating that thechange in grammatical meaning represented in thefeature structure has a distinct encoding in the tar-get language.
Algorithm 2 more formally specifiesthe creation of a FEG.
The FEG?s for our runningexample are shown in Figure 8.
From these statis-tics generated from these graphs, we then estimatethe maximum likelihood probability of each featurevalue pair being distinctly encoded as shown in Fig-ure 9.The interpretation of these probabilities might notbe obvious.
They estimate the likelihood of a lan-guage encoding a feature given that the meaning ofthat feature is intended to be conveyed.
These proba-bilities should not be interpreted as a traditional like-lihood of encountering a given lexical item.Finally, we cluster by randomly selecting a start-ing vertex for a new cluster and adding vertices tothat cluster, following arcs out from the cluster thathave a weight lower than some threshold ?.
Whenno more arcs may be followed, a new start vertex isselected and another cluster is formed.
This is re-peated until all feature values have been assigned toa cluster.
For our running example, we use ?
= 0.6,83fmn{(s1, s2, NEQ), (s4, s5, NEQ),(s4, s7, NEQ), (s4, s8, NEQ)}np-gen{} {}plsdl{(s5,s7, NEQ), (s6, s9, NEQ)}{(s5, s8, NEQ)}{(s7, s8, EQ)}np-num-+{(s5, s6, NEQ),(s7, s9, NEQ))}np-defprespastfut{(s1, s2, NEQ)}c-ten{} {}Figure 8: An example subset of the Feature Expression Graphs that are formed from the minimal pairs in Figure 7.fmn| arcs[m,f] with (sm,sf,x,NEQ) || arcs[m,f] || arcs[m,n] with (sm,sn,x,NEQ) || arcs[m,n] || arcs[f,n] with (sf,sn,x,NEQ) || arcs[f,n] |Figure 9: An example of how probabilities are estimated for each feature value pair in a Feature Expression Graph forthe feature np-gender.Algorithm 2 Collecting statistics for each FEG.Require: The table T from the previous step.Ensure: A complete graph as an arc list with theobserved similarities and differences for each fea-ture value.for all si, sj ?
T s.t.
(mi, ci, `i) = (mj , cj , `j)do(vi, vj)?
(featureValue(si), featureValue(sj))if tgt(si) = tgt(sj) thenarcs[vi, vj ]?
arcs[vi, vj ] ?
(si, sj ,m,EQ)elsearcs[vi, vj ]?
arcs[vi, vj ] ?
(si, sj ,m,NEQ)return arcswhich results in the following clusters being formed:np-gen: m, fnp-num: s, pl/dlnp-def: +, -c-ten: past, pres5.5 Morpheme-Feature PairingFinally, using the information from above aboutwhich values should be examined as a group andwhich sentence pairs exemplify an orthographic dif-ference, we examine each pair of target languagesentences to determine which words changed to re-flect the change in grammatical meaning.
This pro-cess is outlined in Algorithm 3.
The general idea isthat for each arc going out of a feature value vertexwe examine all of the target language sentence pairsthat expressed a difference.
We then take the wordsthat were in the vocabulary of the target sentencefor the current feature value, but not in the sentenceit was being compared to and add them to the listof words that could be used to express this featurevalue (Figure 3).6 Evaluation and ResultsWe evaluated the output of feature detection withone wildcard feature as applied to the ElicitationCorpus from the LDC?s Urdu-English LCTL lan-guage pack.
Threshold parameters were set to smallvalues (?
= 0.05).
Note that an increase in precisionmight be possible by tuning this value; however, asstated, we are most concerned with recall.An initial attempt was made to create a gold stan-dard against which recall could be directly calcu-lated.
However, the construction of this gold stan-dard was both noisier and more time consumingthan expected.
That is, even though the task isbased on how a linguistic field worker might col-84Algorithm 3 Determine which morphemes are as-sociated with which feature values.Require: List of clusters C and list of FEGs FEnsure: A list of morphemes associated with eachfeature valuefor all feature ?
F dofor all vertex ?
feature dofor all arc ?
vertex dofor all (s1, s2,m,NEQ) ?
arc dov1 ?
featureValue(s1,m)v2 ?
featureValue(s2,m)if v1 6= v then (s1, v1)?
(s2, v2)w1 ?
vocabulary(s1)w2 ?
vocabulary(s2)?
?W1 ?W2for all w ?
freq dofreq[w]++for all w ?
freq dop = freq[w] / ?w freq[w]if p ?
??
thenmorphemes[v]?
morphemes[v]?
wreturn morphemeslect data, it was more difficult for a human thananticipated.
Therefore, we instead produced a listof hypothesized morpheme-feature pairs and had ahuman trained in linguistics who was also bilingualin Hindi/Urdu-English mark each pair as ?Correct,??Incorrect,?
or ?Ambiguous.?
The results of thisevaluation are summarized in Figure 10.
The readermay be surprised by how many incorrect hypothe-ses were generated, given the controlled nature ofthe Elicitation Corpus.
However, there are two im-portant factors to consider.
First, features can in-teract in complex and often unexpected ways.
Forinstance, in English, the only feature difference inminimal pair Cats yawned and A cat yawned is thenumber of the actor.
However, this causes an in-teraction with definiteness that would cause the pre-sented algorithms to associate a with the number ofnouns even though it is canonically associated withdefiniteness.
Second, the bilingual people translat-ing the Elicitation Corpus are prone to make errors.Though a fair number of incorrect hypotheseswere produced, the number of correct hypothesesis encouraging.
We also note that the words be-ing identified are largely function words and multi-Judgment Morpheme-Feature PairingsCorrect 68Ambiguous 29Incorrect 109TOTAL 206Figure 10: The results of feature detection.
Being arecall-oriented approach, inductive feature detection isgeared toward overproduction of morpheme-feature pair-ings as shown in the number of ambiguous and incorrectpairings.morpheme tokens from which closed-class func-tional morphemes will be extracted.
One mightthink the counts extracted seem low when comparedto the typical MT vocabulary size, but these functionwords that we extract cover a much larger probabil-ity mass of the language than content words.We are confident that the Morphosyntactic Lex-icon Generator designed to operate directly down-stream from this process will be sufficiently discrim-inant to use these morpheme-feature pairings to cre-ate a high precision lexicon.
However, since thiscomponent is, in itself, highly complex, its specificsare beyond the scope of this paper and so we leave itto be discussed in future work.7 ConclusionWe have presented a method for inductive featuredetection of an annotated corpus, which determineswhich feature values have a distinct representationin a target language and what morphemes can beused to express these grammatical meanings.
Thismethod exploits the unique properties of an Elici-tation Corpus, a resource which is becoming widelyavailable from the LDC.
Finally, we have argued thatthe output of feature detection is useful for exploit-ing these linguistic features via a feature-rich gram-mar for a machine translation system.AcknowledgmentsWe would like to thank our colleagues Alon Lavie,Vamshi Ambati, Abhaya Agarwal, and Alok Par-likar for their insights.
Thanks to Keisuke Kamatakifor the Japanese example and to Shakthi Poornimafor her help with the Urdu examples.
This work wassupported by US NSF Grant Number 0713-292.85ReferencesAlison Alvarez, Lori Levin, Robert Frederking, SimonFung, Donna Gates, and Jeff Good.
2006.
The MILEcorpus for less commonly taught languages.
In HLT-NAACL, New York, New York, June.H.
Bonneau-Maynard, A. Allauzen, D. De?chelotte, andH.
Schwenk.
2007.
Combining morphosyntactic en-riched representation with n-best reranking in statis-tical translation.
In Proceedings of the Workshop onStructure and Syntax in Statistical Translation (SSST)at NAACL-HLT.Jaime Carbonell, Kathrina Probst, Erik Peterson, Chris-tian Monson, Alon Lavie, Ralf Brown, and Lori Levin.2002.
Automatic rule learning for resource limitedMT.
In Association for Machine Translation in theAmericas (AMTA), October.David Chiang.
2005.
A hierarchical phrase-based modelfor statistical machine translation.
In Association forComputational Linguistics (ACL).Jonathan H. Clark, Robert Frederking, and Lori Levin.2008.
Toward active learning in corpus creation: Au-tomatic discovery of language features during elicita-tion.
In Proceedings of the Language Resources andEvaluation Conference (LREC).Yuan Ding and Martha Palmer.
2005.
Machine trans-lation using probabilistic synchronous dependency in-sertion grammars.
In Proceedings of the 43rd Meetingof the Association for Computational Linguistics ACL.Bryant Huang and Kevin Knight.
2006.
Relabeling syn-tax trees to improve syntax-based machine translationquality.
In Proceedings of (NAACL-HLT).Ronald Kaplan.
1995.
The formal architecture of lexi-cal functional grammar.
In Mary Dalrymple, RonaldKaplan, J. Maxwell, and A. Zaenen, editors, FormalIssues in Lexical Functional Grammar.
CSLI Publica-tions.Paul Kay.
2002.
An informal sketch of a formal archi-tecture for construction grammar.
In Grammars.Phillipp Koehn and Hieu Hoang.
2007.
Factored trans-lation models.
In Empirical Methods in Natural Lan-guage Processing (EMNLP).Lori Levin, Jeff Good, Alison Alvarez, and Robert Fred-erking.
2006.
Parallel reverse treebanks for the dis-covery of morpho-syntactic markings.
In Proceedingsof Treebanks and Linguistic Theory, Prague.Percy Liang, Alexandre Bouchard-Cote, Dan Klein, andBen Taskar.
2006.
An end-to-end discriminative ap-proach to machine translation.
In Proceedings of the44th Annual Meeting of the Association for Computa-tional Linguistics, Sydney.Christian Monson, Jaime Carbonell, Alon Lavie, and LoriLevin.
2007.
Paramor: Minimally supervised induc-tion of paradigm structure and morphological analysis.In Proceedings of the 9th ACL SIGMORPH.Shakthi Poornima and Jean-Pierre Koenig.
2008.
Re-verse complex predicates in Hindi.
In Proceedings ofthe 24th Northwest Linguistic Conference.Heather Simpson, Christopher Cieri, Kazuaki Maeda,Kathryn Baker, and Boyan Onyshkevych.
2008.
Hu-man language technology resources for less commonlytaught languages: Lessons learned toward creation ofbasic language resources.
In Proceedings of the LREC2008 Workshop on Collaboration: interoperability be-tween people in the creation of language resources forless-resourced langauges.86
