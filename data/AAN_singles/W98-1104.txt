Using Suffix Arrays to Compute Term Frequencyand Document Frequency for All Substrings in a CorpusMikio YamamotoUniversity of Tsukuba1-1-1 Tennodai,Tsukuba 305-8573, JAPANmyama@is.tsukuba.ac.jpKenneth W. ChurchAT&T Labs - Research180 Park AvenueFlorham Park, NJ 07932, U.S.Akwc @research.att.comAbstractMutual Information (MI) and similarmeasures are often used in corpus-basedlinguistics to find interesting ngrams.
MIlooks for bigrams whose term frequency (~ islarger than chance.
Residual InverseDocument Frequency (RIDF) is similar, but itlooks for ngrams whose document frequency(df) is larger than chance.
Previous studieshave tended to focus on relatively shortngrams, typically bigrams and trigrams.
Inthis paper, we will show that this approachcan be extended to arbitrarily long ngrams.Using suffix arrays, we were able to computetf, df and RIDF for all ngrams in two largecorpora, an English corpus of 50 millionwords of Wall Street Journal news articles anda Japanese corpus of 216 million characters ofMainichi Shimbun ews articles.1 MI  and RIDFMutual Information (MI), l(x;y), compares theprobability of observing word x and word ytogether (the joint probabil ity) with theprobabilities of observing x and y independently(chance).l(x;y) = log (P(x,y) / e(x)e(y)MI has been used to identify a variety ofinteresting linguistic phenomena, ranging fromsemantic relations of the doctor/nurse type tolexico-syntactic co-occurrence preferences of thesave/from type (Church and Hanks, 1990).Church and Gale (1995) proposed Residual28Inverse Document Frequency (RIDF), thedifference between the observed IDF and whatwould be expected under a Poisson model for arandom word or phrase with comparablefrequency.
RIDF is a variant of IDF, a standardmethod for weighting keywords in InformationRetrieval (IR).
Let D be the number of documents,tf be the term frequency (what we call '~frequency"in our field) and dfbe the document frequency (thenumber of documents which contain the word orphrase at least once).
RIDF is defined as:Residual IDF ~ observed IDF - predicted IDF= -log(df/D) +log(1-exp(- 8))= -log(df/D) +log(1-exp(-tf/D)).RIDF is, in certain sense, like MI; both are the logof the ratio between an empirical observation anda chance-based estimate.
Words or phrases withhigh RIDF or MI have distributions that cannot beattributed to chance.
However, the two measureslook for different kinds of deviations from chance.MI tends to pick out general vocabulary, the kindof words one would expect o find in a dictionary,whereas RIDF tends to pick out good keywords,the kind of words one would not expect o find ina dictionary.
This distinction is not surprisinggiven the history of the two measures; MI, as it iscurrently used in our field, came fromlexicography whereas RIDF came fromInformation Retrieval.In addition, it is natural to compute RIDFfor all substrings.
This is generally not done forMI, though there are many ways that MI could begeneralized to apply to longer ngrams.
In the nextsection, we will show an algorithm based on suffixarrays for computing tf, df and RIDF for allsubstrings in a corpus in O(NlogN) time.In section 3, we will compute RIDF's for allsubstrings in a corpus and compare and contrastMI and RIDF experimentally for phrases in aEnglish corpus and words/phrases in a Japanesecorpus.
We won't try to argue that one measure isbetter than the other; rather we prefer to view thetwo measures as mutually complementary.2 Comput ing  tf  and df  for all substrings2.1 Suffix arraysA suffix array is a data structure designed to makeit convenient to compute term frequencies for allsubstrings in a corpus.
Figure 1 shows an exampleof a suffix array for a corpus of N=6 words.
Asuffix array, s, is an array of all N suffixes,pointers to substrings that start at position i andcontinue to the end of the corpus, sortedalphabetically.
The following very simple Cfunction, suffixarray, takes a corpus as input andreturns a suffix array.int suffix_compare(char **a, char **b){return strcmp(*a, *b); }/ *  The input is a string, terminated with a null * /char **suffix_array(char *corpus){int i, N = strten(corpus);char **result=(char **)rnalloc(N*sizeof(char *));/ *  initialize result\[i\] with the ith suffix * /for(i=0; i < N; i++) result\[il = corpus + i;ClSOr't(result, N, sizeof(char *), suffix_compare);return result; }Nagao and Mori (1994) describe thisprocedure, and report that it works well on theircorpus, and that it requires O(NlogN)time,assuming that the sort step requires O(NlogN)comparisons, and that each comparison requires0(1) time.
We tried this procedure on our twocorpora, and it worked well for the Japanese one,but unfortunately, it can go quadratic for a corpuswith long repeated substfings, where strcmp takesO(N) time rather than 0(1) time.
For our Englishcorpus, after 50 hours of cpu time, we gave up andturned to Doug Mcllroy's implementation( http : //cm.
bell-labs, corrJcm/cs/ who/doug/ssort, c)of Manber and Myers' (1993) algorithm, whichtook only 2 hours.
For a corpus that would29otherwise go quadratic, the Manber and Myers'algorithm is well worth the effort, but otherwise,the procedure described above is simpler, andoften a bit faster.As mentioned above, suffix arrays weredesigned to make it easy to compute termfrequencies (~.
If you want the term frequency of"to be," you can do a binary search to find the firstand last position in the suffix array that start withthis phrase, i and j, and then tfl"to be") =j-i+l.
Inthis case, i=5 and j=6, and consequently, tfl"tobe")=6-5+1=2.
Similarly, tfl"be")= 2-1+1 = 2, and~"to")=6-5+1=2.
This straightforward method ofcomputing tf requires O(logN) string comparisons,though as before, each string comparison couldtake O(N) time.
There are more sophisticatedalgorithms that take O(logN) time, even forcorpora with long repeated substrings.A closely related concept is lcp (longestcommon prefix).
Lcp is a vector of length N,where lcp\[i\] indicates the length of the commonprefix between the ith suffix and the/+/st suffix inthe suffix array.
Manber and Myers (1993) showedhow to compute the lcp vector in O(NlogN) time,even for corpora with long repeated substrings,though for many corpora, the complicationsrequired to avoid quadratic behavior areunnecessary.Corpus: "to be or not to be"s\[i\]s\[z\]s\[3\]s\[4\]s\[s\]s\[s\]1 2 3 4Alphabet: \[to, be, or, not}... lcp-Ior not to be Inot to be Ior not toto beto be orbe\]not to be\]00020Lcp's are denoted by bold vertical lines as well as the Icp table.Figure 1: An example of a Suffix Array with lcp's2.2 Classes of substr ingsThus far we have seen how to compute tf for asingle ngram, but how do we compute tfand dfforall ngrams?
There are N(N+I)/2 substrings in atext of size N. If every substring has a different fand df, the counting algorithm would require atleast quadratic time and space.
Fortunately manysubstrings have the same tf and the same df.
Wewill cluster the N(N+I)/2 substrings into at most2N-1 classes and compute tf  and df over theclasses.
There will be at most N distinct values ofRIDF.Let <i,j> be an interval on the suffix array:{s\[i\], s\[i+l\] ..... s\[j\]}.
We call the interval LCP-delimited if the lcp's are larger inside the intervalthan at its boundary:min(lcp\[i\], lcp\[i+ l\] ..... lcp\[j-1\])> max(lcp\[i-1\], Icp\[l\]) (1)In Figure 1, for example, the interval <5,6> isLCP-delimited, and as a result, 0fCto") = tf("to be")= 2, and dfCto")=dfCto be").The interval <5,6> is associated with a classof substrings: "to" and "to be."
Classes will turnout to be important because all of the substrings ina class have the same tf(property l) and the samedf (property 2).
In addition, we will show thatclasses partition the set of substrings (property 3)so that we can compute tf and df on the classes,rather than substrings.
Doing so is much moreefficient because there many fewer classes thansubstfings (property 4).Classes of substrings are defined to be the(not necessarily least) common prefixes in aninterval.
In Figure 1, for example, both "to" and"to be" are common prefixes throughout heinterval <5,6>.
That is, every suffix in the interval<5,6> starts with "to," and every suffix also startswith "to be".
More formally, we defineclass(<ij>) as: {s\[i\]ml LBL<rn_<SIL}, where s\[i\]rnis a substring (the first m characters of s\[i\]),LBL(longest boundary lcp) is the fight hand of (1)and SIL (shortest interior Icp) is the left hand side"of (1).
In Figure 1, for example, SIL(<5,6>) =min(lcp\[5\]) = 2, LBL(<5,6>) = max(lcp\[4\], lcp\[6\])=0, and class(<5,6>) = {s\[5\]m I 0<m_<2} = {"to","to be"}.Figure 2 shows six LCP-delimited intervalsand the LBL and SIL of <2,4>.
For <2,4>, thebounding lcp's are lcp\[1 \] = 2 and lcp\[4\]=3(LBL=3), and the interior lcp's are lcp\[2\]=4 andlcp\[3\]=6 (SIL=4).
The interval <2,4> is LCP-delimited, because L B L<SIL.
Class(<2,4>)={s\[2\]m13<m~<4} = {aacc}.
The interval <3,3> is*) SIL(<i,i>) is defined to be infinity, and consequently,all intervals <i,i> are LCP-delimited, forall i.30Doc-id(..,.
382 s\[1\]~84987 stZ\]\6892 s\[3\]- -382  s\[4\]2566 s\[5\]s\[6\]1 2 3 4 5 6 7 .
.
.a a lb  b c c d...a aLc old d e .
.
.4,: :  .
.
.
.
.Bounding Icps, LBL, SIL, Intedor Icps of <2, 4>Vertical ines denote lcps.
Gray area denotes endpointsof substrings in class(<2,4>).LCP-delimited Classinterval<2,4> {aacc}<3,4> {aacce, aaccee}<1,1> {aab, aabb, aabbc, ...}<2,2> {aaccd, aaccdd, ...}<3,3> {aacceef, ...}<4,4> {aacceeg, ...}LBL SIL tf2 4 33 6 22 infinity 14 infinity 16 infinity \]6 infinity 1Figure 2: Examples of intervals and classesLCP-delimited because SIL is infinite and LBL=6.The interval <2,3> is not LCP-delimited becauseSIL is 4 and LBL is 6 (LBL>SIL).By construction, the suffixes within theinterval <i,j> all start with the substrings inclass( <i,j> ), and no suffixes outside this intervalstart with these substfings.
As a result, if sl and s2are two substfings in class(<ij>) thenProperty 1: tflsJ) = tfls2) =j- i+l?
andProperty 2: dr(s1) = df(s2).The calculation of dfis more complicated than tf,and will be discussed in section 2.4.It is not uncommon for an LCP-delimitedinterval to be nested within another.
In Figure 2,for example, the in~rval <3,4> is nested within<2,4>.
The computation of df in section 2.4 willtake advantage of a very convenient nestingproperty.
Given two LCP-delimited intervals,either one is nested within the other (e.g., <2,4>and <3,4>), or one precedes the other (e.g., <2,2>and <3,4>), but they cannot overlap.
Thus, forexample, the intervals <1,3> and <2,4> cannotboth be LCP-delimited because they overlap.Because of this nesting property, it is possible toexpress the dfof an interval recursively in terms ofits constituents or subintervals.As mentioned aboye, we will use thefollowing partitioning property so that we cancompute tfand dfon the classes rather than on thesubstrings.Property 3: the classes partition the set ofall substrings in a text.There are two parts to this argument: everysubstfing belongs to at most one class (property3a), and every substring belongs to at least oneclass (property 3b).Demonstration of property 3a (proof bycontradiction): Suppose there is a substfing, s, thatis a member of two classes: class(<ij>) andclass(<u,v>).
There are three possibilities: oneinterval precedes the other, they are propertynested or they overlap.
The only interesting case isthe nesting case.
Suppose without loss ofgenerality that <u,v> is nested within <i j> as inFigure 3.
Because <u,v> is LCP-delimited, theremust be a bounding lcp of <u,v> that is smallerthan any lcp within <u,v>.
This bounding Icp mustbe within <i j>, and as a result, class(<ij>) andclass(<u,v>) must be disjoint.
Therefore, s cannotbe in both classes.t Suffix Array / SIL of <i,j>$\[i\]1 I 1 Is\[.\]/ ^ I , II / I Is\[v\]/ I ,fl I sb\] , .<.
.
j" l?h~s is an interior lcp of <i,j>and the LBL of <u, v>.Figure 3: An example of nested intervalsDemonstration ofproperty 3b (constructiveargument): Let s be an arbitrary substring in thecorpus.
There will be at least one suffix in thesuffix array that starts with s. Let i be the firstsuch suffix and let j be the last such suffix.
Byconstruction, the interval <i j>  is LCP-delimited(LBL(<ij>) < Isl and S1L(<ij>) >_ Isl), and s is anelement of class(<ij>).Finally, as mentioned above, computingover classes is much more efficient thancomputing over the substfings themselves becausethere are many fewer classes (at most 2N-l) thansubstrings (N(N+I)/2).31Property 4: There are N classes with tf=land at most N-1 classes with ~'> 1.The first clause is relatively straightforward.There are N intervals <i,i>.
These are all and onlythe intervals with tf=l.
By construction, theseintervals are LCP-delimited.To argue the second clause, we will makeuse of a uniqueness property: an LCP-delimitedinterval <ij> can be uniquely determined by itsS1L and a representative element k (i.~.k<j).Suppose there were two distinct intervals, <id>and <u,v>, with the same SIL,  SIL(<ij>)=SIL(<u,v>), and the same representative, i.~.k<j andu_<k<v.
Since they share a common representative,k, the two intervals must overlap.
But since theyare distinct, there must be a distinguishingelement, d, that is in one but not the other.
One ofthese distinguishing elements, d, would have to bea bounding lcp in one and an interior lcp in theother.
But then the two intervals couldn't both beLCP-delimited.Given this uniqueness property, we candetermine the N-1 upper bound on the number ofLCP-delimited intervals by considering the N-1elements in the Icp vector.
Each of these elements,lcp\[k\], has the opportunity to become the SIL of anLCP-delimited interval <i j> with a representativek.
Thus there could be as many as N-1 LCP-delimited intervals (though there could be fewer ifsome of the opportunities don't work out).Moreover, there couldn't be any more intervalswith 0f>l, because if there were one, its SIL shouldhave been in the lcp vector.
(Note that this lcpcounting argument excludes intervals with t~-Idiscussed above, because their SILs need not be inthe lcp vector.
)From property 4, it follows that there are atmost N distinct values of RIDF.
The N intervals<i,i> have just one RIDF value since 0~-'-df=l forthese intervals.
The other N-1 intervals could haveanother N-1 RIDF values.In summary, the four properties takencollectively make it practical to compute tf, df andRIDF over a relatively small number of classes; itwould have been prohibitively expensive tocompute these quantities directly over theN(N+ 1)/2 substrings.2.3 Calculat ing classes using Suffix Ar rayThis section will describe a single pass procedurefor Computing classes.
Since LCP-delimitedintervals obey a convenient nesting property, theprocedure is based on a push-down stack.
Theprocedure outputs 4-tuples, <s\[i\],LBL,SIL,~>, onefor each LCP-delimited interval.
The stackelements are pairs (x,y), where x is an index,typically the left edge of a candidate LCP-delimited interval, and y is the SIL of thiscandidate interval.
Typically, y=lcp\[x\], though notalways, as we will see in Figure 5.The algorithm sweeps over the suffixes insuffix array s\[1..N\] and their lcp\[1..N\] (lcp\[N\]=O)successively.
While Icp's of suffixes aremonotonically increasing, indexes and lcp's of thesuffixes are pushed into a stack.
When it finds thei-th suffix whose lcp\[i\] is less than the lcp on thetop of the stack, the index and Icp on the top arepopped off the stack.
Popping is repeated until thelcp on the top becomes less than the lcp\[i\].A stack element popped out generates aclass.
Suppose that a stack element composed ofan index i and lcp\[i\] is popped out by lcp\[1\].
Lcp\[i\]is used as the SIL.
The LBL is the Icp on the nexttop element in the stack or lcp\[j\].
If the next topIcp will be popped out by lcp\[j\], then the algorithmuses the next top lop as the LBL, else it uses thelcp\[j\].
Tf is the offset between the indexes i and j,that is, j-i+1.Figure 4 shows the detailed algorithm forCreate and clear stack.Push (-1, -1) (dummy).Repeat i = 1 .
.
.
.
.
N dotop (index1, Icpl).if Icp\[i\] > Icpl thenpush (i, Icp\[i\]).elsewhile Icp\[i\] _< Icpl dopop(index1, Icpl)top (index2, Icp2)if Icp\[i\] _< Icp2 thenoutput <s\[index 1\], Icp2, Icpl, i-index1 +1 >elseoutput <s\[indexl\], Icp\[i\], Icpl, i-index1+1>push (indext, Icp\[i\])Icpl = Icp2.Figure 4: An algorithm for computing all classes32computing all classes with tf > 1.
If classes with tf= 1 are needed, we can easily add the line tooutput hose into the algorithm.
The expressions,push(x,y) and pop(x,y), operate on the stack in theobvious way, but note that x and y are inputs forpush and outputs for pop.
The expression, top(x,y),is equivalent to pop(x,y) followed by push(x,y); itreads the top of the stack without changing thestack pointer.As mentioned above, the stack elements aretypically pairs (x,y) where y=lcp\[x\], but notalways.
Pairs are typically pushed onto the stackby line 6, push(i ,  Icp\[i\]), and consequently,y=lcp\[x\], in many cases, but some pairs are pushedon by line 15.
Figure 5 (a) shows the typical casewith the suffix array in Figure 2.
At this point,i=3 and the stack contains 4 pairs, a dummyelement (-1, -1), followed by three pairs generatedby line 6: (1, Icp\[l\]), (2, lcp\[2\]), (3, lcp\[3\]).
Incontrast, Figure 5 (b) shows an atypical case.
Inbetween snapshot (a) and snapshot (b), two LCP-delimited intervals were generated, <s\[3\], 4 6, 2>and <s\[2\], 3 4, 3>, and then the pair (2, 3) waspushed onto the stack by line 15, push(indexl,lcp\[i\]), to capture the fact that there is a candidateLCP-delimited interval starting at indexl=2,spanning past the representative element i=4, withan SIL of lcp\[i=4\].index lcp Note!
(3, 6)\]\]Poppedilout ('2, 3) (2, 4)\[-  s\[4\].
, 2) (1, 2) (1(-1,-1) I dummy (-1,-1)II \] ushod(a) end of processing s\[3\] (b) end of processing s\[4\]Figure 5: Snapshots of the stack2.4 Computing df for all classesThis section will extend the algorithm in Figure 4to include the calculation of dr. Straightforwardlycomputing dfindependently for each class wouldrequire at least quadratic time, because theprogram must check document id's for allsubstfings (N at most) in all classes (N-I at most).Instead of this, we will take advantage of thenesting property of intervals.
The df for oneinterval can be computed recursively in terms ofits constituents (nested subintervals), avoidingunnecessary ecomputation.The stack elements in Figure 5 is augmentedwith two additional counters: (1) a df counter forsumming the dfs over the nested subintervals and(2) a duplication counter for adjusting forovercounting documents that are referenced inmultiple subintervals.
The df for an interval issimply the difference of these two counters, that is,the sum of the dfs of the subintervals, minus theduplication.
A C code implementation can befound athttp://www.milab.is.tsukuba.ac.jp/-myama/oedf/tfdf c.The df counters are re lat ivelystraightforward to implement.
The crux of theproblem is the adjustment for duplication.
Theadjustment makes use of a document link table, asillustrated in Figure 6.
The left two columnsindicate that suffixes \[101\], s\[104\] and s\[107\] areSuffix Document Document id link (index)s\[101\] 382 - ~ 66 js\[102\] 84987 ~172 ~silO31 -- 6892 21s\[104l 382 - 01s\[105\] 2566 / 112~)s\[106\] -- 6892 03s\[107\] 382 - ~ , - I04  ' , /stl08\] l -  84987 .. \ [102  "~-.,,~.,Figure 6: An example of document link tables\[i\]sbqs\[k ~.s\[tSuffix Arraycharacters ( uffix).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
., Idf-df-counter \] hh h,,tdf-counter IAdf-counterl I6-"----... _ ;,11;,I I ; ,  4 df-cou.te,T----IL_ II.
.
.
.
.
.
.
.
.
.
.
.
.
.
I,odup-counter I-~ Indocument links ~.~ Intervalendpoints of substrings in the class of the intervalFigure 7: Dfrelations among an intervaland its constituents33all in document 382, and that several other suffixesare also in the same documents.
The third columnlinks together suffixes that are in the samedocument.
Note, for example, that there is apointer from suffix 104 to 101, indicating thats\[104\] and s\[101\] are in the same document.
Thesuffixes in one of these linked lists are kept sortedby their order in the suffix array.
When thealgorithm is processing s\[t\], the algorithm searchesthe stack to find the suffix, s\[k\], with the largest ksuch k_<i and s\[i\] and s\[k\] are in the samedocument.
This search can be performed inO(logN) time.Figure 7 shows the LCP-delimited intervalsin a suffix array and four suffixes included in thesame document.
I1has four immediate constituentsof intervals.
S\[j\] is included in the same documentof s\[i\].
Count for the document of s\[j\] will beduplicated at computing df of 11.
At the point ofprocessing sO'\], the algorithm will incrementduplication-counter of I!
to cancel dfcount of sO'\].As the same way, df count of s\[k\] has to canceledat computing df of 11.Figure 8 shows a snapshot of the stack afterprocessing s\[4\] in Figure 2.
Each stack element isa 4-tuple of the index of suffix array, lcp, df-counter and duplication-counter, (i, lcp, df dc).Figure 2 shows s\[1\] and s\[4\] are in the samedocument.
Looking up the document link table,the algorithm knows s\[1\] is the nearest suffixwhich is in the same document of s\[4\].
Theduplication-counter of the element of s\[1\] isincremented.
The duplication of counting s\[1\] ands\[4\] for the class generated by s\[1\] will be avoidedusing this duplication-counter.At some processing point, the algorithmuses only a part of the document link table.
Itduplicationlcp counter(2, 3, 3,0)\[(1, 2, 1,1)I ( -1 , -1 , - , - )Figure 8: A snapshot ofthe stack in dfcomputingNearest Doc-id index.
.
?382 4o H6892 3?
, ?84987 2Figure 9: Nearest indexesof documentsneeds only the nearest index on the link, but notthe whole of the link.
So we can compress the linktable to dynamic one in which an entry of eachdocument holds the nearest index.
Figure 9 showsthe nearest index+ table of document afterprocessing s\[4\].The final algorithm to calculate all classeswith tfand dftakes O(NlogN) time and O(N) spacein the worst case.3 Experimental  results3.1 RIDF and MI for English and JapaneseWe computed all RIDF's for all substrings of twocorpora, Wall Street Journal of ACL/DCI inEnglish (about 50M words and 113k articles) andMainichi News Paper 1991-1995 (CD-MainichiShimbun 91-95) in Japanese (about 216Mcharacters and 436k articles), using the algorithmin the previous ection.
In English, we tokenizedthe text into words, delimited by white .space,whereas in Japanese we tokenized the text intocharacters (usually 2-bytes) because Japanese texthas no word delimiter such as white space.It took a few hours to compute all RIDF'susing the suffix array.
It takes much longer tocompute the suffix array than to compute tfand df.We ignored substrings with tf< 10 to avoid noise,resulting in about 1.6M English phrases (#classes= 1.4M) and about 15M substrings of Japanesewords/phrases (#classes = 10M).MI of the longest substring of each class wasalso computed by the following formula., p(xyz)MI(xyz) = xog p(xy)p(z I y)Where xyz is a phrase or string, x and Z are aword or a character and y is a sub-phrase or sub-string.3.2 Little correlation between RIDF and MIWe are interested in comparing and contrastingRIDF and MI.
Figure 10 (a) plots RIDF vs MI forphrases in WSJ (length > 1), showing little, if any,correlation between RIDF and MI.
Figure 10 (b)also plots RIDF vs MI but this time the corpus is inJapanese and the words were manually selected bythe newspaper to be keywords.
Both Figures I0(a) and 10 (b) suggest hat RIDF and MI are34largely independent.
There are many substringswith a large RIDF value and a small MI, and viceversa .MI is very different from RIDF.
Both pickout interesting phrases, but phrases with large MIare interesting in different ways from phrases withlarge RIDF.
Consider the phrases in Table 1,which all contain the word "having."
Thesephrases have large MI values and small RIDFvalues.
A lexicographer such as Patrick Hanks,who works on dictionaries for learners, might beinterested in these phrases because these kinds ofcollocations tend to be difficult for non-nativespeakers of the language.
On the other hand, thesekinds of collocations are not very good keywords.Table 2 is a random sample of phrasescontaining the substring/Mr/, sorted by RIDF.
Theones at the top of the list tend to be betterkeywords than the ones further down.Table 3.A and 3.B show a few phrasesstarting with/the/, sorted by MI (Table 3.A) andsorted by RIDF (Table 3.B).
Most of the phrasesare interesting in one way or another, but those atthe top of Table 3.A tend to be somewhat.+  + ?
!$ ?
o  ?+ .
?
: .
'.~- : .-?
,.:'~Mi~-.t....'...
?
, .~ l l t~ .~z :L= :o MI lo 20(a) English phraseso"l~-lo o MI lo(b) Japanese stringsFigure 10: Scatter plot of RIDF and MIi,-Table520Table 1: phrases with 'having'ff df RIDF MI Phrase18 18 -0.0001 10.4564 admits to having14 14 -0.0001 9.7154 admit to having25 23 0.1201 8.8551 diagnosed as having20 20 -0.0001 7.4444 suspected of having301 293 0.0369 7.2870 without having15 13 0.2064 6.9419 denies having59 59 -0.0004 6.7612 avoid having18 18 -0.0001 5.9760 without ever having12 12 -0.0001 5.9157 Besides having26 26 -0.0002 5.7678 denied havingTable 2: phrases with 'Mr'tf df RIDF MT Phraseii 3 1.8744 0.6486 .
Mr. Hinz18 5 1.8479 6.5583 Mr. Bradbury51 16 1.6721 6.6880 Mr. Roemer67 25 1.4218 6.7856 Mr. Melamed54 27 0.9997 5.7704 Mr. Burnett16 9 0.8300 5.8364 Mrs. BrownIi 8 0.4594 1.0931 Mr. Eiszner said53 40 0.4057 0.2855 Mr. Johnson .21 16 0.3922 0.1997 Mr. Nichols said .13 i0 0.3784 0.4197 .
Mr. Shulman176 138 0.3498 0.4580 Mr. Bush has13 ii 0.2409 1.5295 to Mr. Trump's13 Ii 0.2409 -0.9301 Mr.
Bowman ,35 32 0.1291 1.1673 wrote Mr.12 ii 0.1255 1.7330 M r. Lee to22 21 0.0670 1.4293 facing Mr.ii ii -0.0001 0.7004 Mr. Poehl also13 13 -0.0001 1.4061 inadequate . "
Mr.16 16 -0.0001 1.5771 The 41-year-old Mr.19 19 -0.0001 0.4738 14 .
Mr.26 26 -0.0002 0.0126 in November .
Mr.27 27 -0.0002 -0.0112 " For his part , Mr.38 38 -0.0002 1.3589 .
AMR ,39 39 -0.0002 -0.3260 for instance , Mr.tf dfTable 3.A: Worse KeywordsRIDF MI Phraseii ii -0.0001 11.0968 the up side73 66 0.1450 9.3222 the will of16 16 -0.0001 8.5967 the sell side17 16 0.0874 8.5250 the Stock Exchange of16 15 0.0930 8.4617 the buy side20 20 -0.0001 8.4322 the down side55 54 0.0261 8.3287 the will to14 14 -0.0001 8.1208 the saying goes15 15 -0.0001 7.5643 the going getstf dfTable 3.B: Better KeywordsRIDF MI Phrase37 3 3.6243 2.2561 the joint commission66 8 3.0440 3.5640 the SSC55 7 2.9737 2.0317 the Delaware &37 5 2.8873 3.6492 the NHS22 3 2.8743 3.3670 the kibbutz22 3 2.8743 4.1142 the NSA's29 4 2.8578 4.1502 the DeBartolos36 5 2.8478 2.3061 the Basic Law21 3 2.8072 2.2983 the national outputTable 3.C: Concordance of the phrase "the Basic Law"The first col. is the token id and the last col. is the doc id (position of the start word in the corpus)2229521: line in the drafting of2229902: s policy as expressed in9746758: he U.S. Constitution and11824764: any changes must follow33007637: sts a tentative draft of33007720: the relationship between33007729: onstitution .
Originally33007945: wer of interpretation of33007975: tation of a provision of33008031: interpret provisions of33008045: ration of a provision of33008115: etation of an article of33008205: nland representatives of33008398: e : Mainland drafters of33008488: pret al the articles of33008506: y and power to interpret33008521: pret those provisions of33008545: r the tentative draft of33008690: d of being guaranteed by33008712: uncilor , is a member of39020313: sts a tentative draft of39020396: the relationship between39020405:39020621:39020651:39020707:39020721:39020791:39020881:39021074:39021164:39021182:39021197:39021221:39021366:39021388:onstitution .
Originallywet of interpretation oftation of a provision ofinterpret provisions oftation of a provision ofetation of an article ofnland representatives ofe : Mainland drafters ofpret al the articles ofy and power to interpretpret those provisions ofr the tentative draft ofd of being guaranteed byuncilor , is a member ofthe Basicthe Basicthe Basicthe Basicthe Basicthe Basicthe Basicthe Basicthe Basicthe Basicthe Basicthe Basicthe Basicthe Basicthe Basicthe Basicthe Basicthe Basicthe Basicthe Basicthe Basicthe Basicthe Basicthe Basicthe Basicthe Basicthe Basicthe Basicthe Basicthe Basicthe Basicthe Basicthe Basicthe Basicthe Basicthe BasicLaw that will determine how Hon 2228648Law -- as Gov.
Wilson's debut s 2228648Law of the Federal Republic of 9746014Law , Hong Kong's miniconstitut 11824269Law , and although this may be 33007425Law and the Chinese Constitutio 33007425Law was to deal with this topic 33007425Law shall be vested in the NPC 33007425Law , the courts of the HKSAR { 33007425Law .
If a case involves the in 33007425Law concerning defense , foreig 33007425Law regarding " defense , forei 33007425Law Drafting Committee fear tha 33007425Law simply do not appreciate th 33007425Law .
While recognizing that th 33007425Law , it should irrevocably del 33007425Law within the scope of Hong Ko 33007425Law , I cannot help but conclud 33007425Law , are being redefined out o 33007425Law Drafting Committee .
<EOA> 33007425Law , and although this may be 39020101Law and the Chinese Constitutio 39020101Law was to deal with this topic 39020101Law shall be vested in the NPC 39020101Law , the courts of the HKSAR { 39020101Law .
If a case involves the in 39020101Law concerning defense , foreig 39020101Law regarding " defense , forei 39020101Law Drafting Committee fear tha 39020101Law simply do not appreciate th 39020101Law .
While recognizing that th 39020101Law , it should irrevocably del 39020101Law within the scope of Hong Ko 39020101Law , I cannot help but conclud 39020101Law , are being redefined out o 39020101Law Drafting Committee .
<EOA> 3902010135tf df  RIDF MITable 4: Phrases with prepositionsPhrase with 'for' tf df RIDF14 1415 1512 12i0 512 413 1323 21I0 2i0 919 16-0.0001 14.5587-0.0001 14.4294-0.0001 14.11230.9999 13.75141.5849 13.7514-0.0001 13.68030.1311 13.66762,3219 13.40090.1519 13.35910.2478 12.9440tf df  RIDF MIfeedlots for fattening ii 5 1.1374error for subgroups II i0 0.1374Voice for Food 13 12 0.1154Quest for Value 16 16 -0.0001Friends for Education 12 12 -0.0001Commissioner for Refugee~ 12 12 -0.0001meteorologist for Weathe\] 22 18 0.2894Just for Men ii ii -0.0001Witness for Peace 17 12 0.5024priced for reoffering 22 20 0.1374Phrase with'by' tf df  RIDFIi ii13 1313 1315 1516 1661 5917 1712 12ii ii20 20-0,0001 12.8665-0.0001 12.5731-0,0001 12.4577-0,0001 12.4349-0.0001 11.82760,0477 11.5281-0,0001 11.4577-0.0001 11.3059-0.0001 10.8176-0.0001 10.6641piece by piece ii i0 0.1374guilt by association 12 5 1.2630step by step 16 16 -0.0001bit by bit 14 13 0.1068engineer by training 10 9 0.1519side by side ii II -0.0001each by Korea's i0 9 0.1519hermaed in by I0 8 0.3219dictated by formula 12 12 -0.000170%-owned by Exxon 16 4 1.9999Table 5: Examples of keywordswith interesting RIDF and MIRIDF MI Substrings Features~E(native last name)SUN (company name) High Low z,J-~'(foreign name)10% 10% ~Z~ b(brush)V 7 7 - -  (sofa)~< \]'fl,~ (huge)Low High '~l~J (passive)I,~ 19 (determination)10% 10% /~j J (nat ive full name)~ii~l~'(native fullname)Kanji characterEnglish characterKatakana characterHiragana characterLoan word, KatakanaGeneral vocabularyGeneral vocab., KanjiGeneral vocabularyKanji characterKanji characteridiomatic (in the WSJ domain) whereas those atthe top of Table 3.B tend to pick out specificstories or events in the news.
For example, thephrase, "the Basic Law," selects for stories aboutthe British handover of Hong Kong to China, asillustrated in Table 3.C.Table 4 shows a number of phrases withhigh M!
containing common prepositions.
Thehigh MI indicates an interesting association, butagain most of them are not good keywords, thoughthere are a few exceptions uch as "Just for Men,"a well-known brand name.RIDF and MI for Japanese substrings tend tobe similar.
Substrings with both high RIDF and MItend to be good keywords such as ~ (merger),(stock certificate), ~ ,~ (dictionary), J~l~ (wireless)36MI Phrase with 'on'14.3393 Terrorist on Trial13.1068 War on Poverty12.6849 Institute on Drug12.5599 dead on arrival11.5885 from on high11.5694 knocking on doors11.3317 warnings on cigarette11.2137 Subcon~ittee on Oversight11.1847 Group on Health11.1421 free on bailMI Phrase with 'o f16.7880 Joan of Arc16.2177 Ports of Call16.0725 Articles of Confederation16.0604 writ of mandamus15.8551 Oil of Olay15.8365 shortness of breath15.6210 Archbishop of Canterbur15.3454 Secret of My15.2030 Lukman of Nigeria15.1600 Days of Rageand so on.
Substrings with both low RIDF and MItend to be poor keywords such as "~" ~q~(current regular-season game) and meaninglessfragments such as *& ,_.~" (??).
Table 5 showsexamples where MI and RIDF point in oppositedirections (rectangles in Figure 10 (b)).
Wordswith low RIDF and high MI tend to be generalvocabulary (often written in Kanji characters).
Incontrast, words with high RIDF and low MI tend?
to be domain specific words such as loan words(often written in Katakana characters).
MI is highfor words in general vocabulary (words found indictionary) and RIDF is high for good keywordsfor IR.3.3 Word extractionSproat and Shih (1990) found MI to be useful forword extraction in Chinese.
We performed thefollowing experiment o see if both MI and RIDFare useful for word extraction in Japanese.We extracted four random samples of 100substrings each.
The four samples cover all fourcombinations of high and low RIDF and high andlow MI, where high is defined to be in the topdecile and low is defined to be in the bottomdecile.
Then we manually scored each samplesubstring using our own judgment as a good (thesubstring is a word) or bad the substring is not aword) or gray (the judge is not sure).
The resultsare presented in Table 6, which shows thatTable 6: RIDF and MI are complementaryI M I  M IAll MI !
(high 10%) (low 10%)All RIDF --- 20-44% 2-11%RIDF (high 10%) 29-51% 38-55% 11-35%RIDF(low 10%) 3-18% 4-13% 0-8%Each cell is computed over a sample of 100examples.
The smaller values are counts of 'good'words and the larger values, 'not bad' words ('good'and 'gray' words).
Good or 'not bad' word ratio ofpairs of characters with high MI is 51-76%.substrings with high scores in both dimensions aremore likely to be words than substrings that scorehigh in just one dimension.
Conversely, substringswith low scores in both dimensions are veryunlikely to be words.3.4 Case study: NamesWe also compared RIDF and MI for people'snames.
We made a list of people's names fromcorpora using simple heuristics.
A phrase orsubstring is accepted as a person's name if Englishphrase starts with the title 'Mr.'
'Ms.'
or 'Dr.'
and isfollowed by a series of capitalized words.
ForJapanese, we selected phrases in the keyword listending with 'L~:' (-shi), which is roughly theequivalent of the English titles 'Mr.'
and 'Ms.
'Figure 11 plots RIDF and MI for names inEnglish (a) and Japanese (b) with t f  _> 10,respectively?
Figure 11 (a) shows that MI has amore limited range than RIDF, suggesting thatRIDF may be more effective with names than MI.The English name 'Mr.
From' is a particularlyL?% ?-, .
: .r" lr  r .qp ?
?
?? "'"
"?
:",: i ' : .""
1"" " " " .1 5 ?
: .
'~~, :I1 : " "" "" ~ .
-~1~, .
'~ ' : .
I0 4 MI 8 12 -8 -4 MI4 8 12(a) English names (b) Japanese namesFigure 11: MI and RIDF of people's names37interesting case, since both 'Mr.'
and 'From' is astop word.
In this case, the RIDF was large and theMI was not.The Japanese names in Figure 11 (b) splitnaturally at RIDF = 0.5.
Japanese names withRIDF below 0.5 are different from names after 0.5.The group whose RIDF is under 0.5 included firstname and full name (first and last name) at rate of90% and another group whose RIDF is up to 0.5included only lastname at rate of 90%.
The reasonof this separation is that full name (and first nameas a substring of full name) appears once in thebeginning of the document, but last name isrepeated as a reference in the article.
Recall thatRIDF tends to give higher value to substringswhich appear many times in a few documents.
Insummary, RIDF can discriminate difference ofsome words which cannot be done by MI.5 Conclus ionWe showed that RIDF is efficiently and naturallyscalable to long phrases or substrings.
RIDF for allsubstrings in a corpus can be computed using thealgorithm which computes tfs and dfs  for allsubstrings based on Suffix Array.
It remains anopen question how to do this for MI.
We foundthat RIDF is useful for finding good keywords,word extraction and so on.
The combination of MIand RIDF is better than either by itself.
R IDF islike MI, but different?ReferencesChurch, K. and P. Hanks (1990)Word associationnorms, mutual information, and lexicography?Computational Linguistics, 16:1, pp.
22 - 29.Church, K. and W. Gale (1995) Poisson mixtures.Natural Language Engineering, 1:2, pp.
163 - 190.Manber, U. and G. Myers (1993) Suffix array: A newmethod for on-line string searches.
SIAM Journalon Computing, 22:5, pp.
935 - 948.http://glimpse.cs.arizona, edu/udi.htmlNagao, M. and S. Mori (1994) A new method of n-gramstatistics for large number of n and automaticextraction of words and phrases from large text dataof Japanese, Coling-94, pp.611-615.Sproat, R and C. Shih (1990) A statistical method forfinding word boundaries in Chinese text.
ComputerProcessing of Chinese and Oriental Languages,Vol.4, pp.
336 - 351.
