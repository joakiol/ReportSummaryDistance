Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-X),pages 236?240, New York City, June 2006. c?2006 Association for Computational LinguisticsMaximum Spanning Tree Algorithm for Non-projective LabeledDependency ParsingNobuyuki ShimizuDept.
of Computer ScienceState University of New York at AlbanyAlbany, NY, 12222, USAshimizu@cs.albany.eduAbstractFollowing (McDonald et al, 2005), wepresent an application of a maximumspanning tree algorithm for a directedgraph to non-projective labeled depen-dency parsing.
Using a variant of thevoted perceptron (Collins, 2002; Collinsand Roark, 2004; Crammer and Singer,2003), we discriminatively trained ourparser in an on-line fashion.
After just oneepoch of training, we were generally ableto attain average results in the CoNLL2006 Shared Task.1 IntroductionRecently, we have seen dependency parsing growmore popular.
It is not rare to see dependency re-lations used as features, in tasks such as relation ex-traction (Bunescu and Mooney, 2005) and machinetranslation (Ding and Palmer, 2005).
Although En-glish dependency relations are mostly projective, inother languages with more flexible word order, suchas Czech, non-projective dependencies are more fre-quent.
There are generally two methods for learn-ing non-projective dependencies.
You could map anon-projective dependency tree to a projective one,learn and predict the tree, then bring it back to thenon-projective dependency tree (Nivre and Nilsson,2005).
Non-projective dependency parsing can alsobe represented as search for a maximum spanningtree in a directed graph, and this technique has beenshown to perform well in Czech (McDonald et al,2005).
In this paper, we investigate the effective-ness of (McDonald et al, 2005) in the various lan-guages given by the CoNLL 2006 shared task fornon-projective labeled dependency parsing.The paper is structured as follows: in section 2and 3, we review the decoding and learning aspectsof (McDonald et al, 2005), and in section 4, we de-scribe the extension of the algorithm and the featuresneeded for the CoNLL 2006 shared task.2 Non-Projective Dependency Parsing2.1 Dependency StructureLet us define x to be a generic sequence of input to-kens together with their POS tags and other morpho-logical features, and y to be a generic dependencystructure, that is, a set of edges for x.
We use theterminology in (Taskar et al, 2004) for a genericstructured output prediction, and define a part.A part represents an edge together with its label.A part is a tuple ?DEPREL, i, j?
where i is the startpoint of the edge, j is the end point, and DEPREL isthe label of the edge.
The token at i is the head ofthe token at j.Table 1 shows our formulation of building a non-projective dependency tree as a prediction problem.The task is to predict y, the set of parts (column 3,Table 1), given x, the input tokens and their features(column 1 and 2, Table 1).In this paper we use the common method of fac-toring the score of the dependency structure as thesum of the scores of all the parts.A dependency structure is characterized by itsfeatures, and for each feature, we have a correspond-236Token POS Edge PartJohn NN ?SUBJ, 2, 1?saw VBD ?PRED, 0, 2?a DT ?DET, 4, 3?dog NN ?OBJ, 2, 4?yesterday RB ?ADJU, 2, 5?which WDT ?MODWH, 7, 6?was VBD ?MODPRED, 4, 7?a DT ?DET, 10, 8?Yorkshire NN ?MODN, 10, 9?Terrier NN ?OBJ, 7, 10?.
.
?., 10, 11?Table 1: Example Partsing weight.
The score of a dependency structureis the sum of these weights.
Now, the dependencystructures are factored by the parts, so that each fea-ture is some type of a specialization of a part.
Eachpart in a dependency structure maps to several fea-tures.
If we sum up the weights for these features,we have the score for the part, and if we sum up thescores of the parts, we have the score for the depen-dency structure.For example, let us say we would like to find thescore of the part ?OBJ, 2, 4?.
This is the edge goingto the 4th token ?dog?
in Table 1.
Suppose there aretwo features for this part.?
There is an edge labeled with ?OBJ?
that pointsto the right.
( = DEPREL, dir(i, j) )?
There is an edge labeled with ?OBJ?
starting atthe token ?saw?
which points to the right.
( =DEPREL, dir(i, j), wordi )If a statement is never true during the training, theweight for it will be 0.
Otherwise there will be apositive weight value.
The score will be the sum ofall the weights of the features given by the part.In the upcoming section, we explain a decodingalgorithm for the dependency structures, and laterwe give a method for learning the weight vector usedin the decoding.2.2 Maximum Spanning Tree AlgorithmAs in (McDonald et al, 2005), the decoding algo-rithm we used is the Chu-Liu-Edmonds (CLE) al-gorithm (Chu and Liu, 1965; Edmonds, 1967) forfinding the Maximum Spanning Tree in a directedgraph.
The following is a nice summary by (Mc-Donald et al, 2005).Informally, the algorithm has each vertexin the graph greedily select the incomingedge with highest weight.Note that the edge is coming from the parent to thechild.
This means that given a child node wordj , weare finding the parent, or the head wordi such thatthe edge (i, j) has the highest weight among all i,i 6= j.If a tree results, then this must be the max-imum spanning tree.
If not, there must bea cycle.
The procedure identifies a cycleand contracts it into a single vertex andrecalculates edge weights going into andout of the cycle.
It can be shown that amaximum spanning tree on the contractedgraph is equivalent to a maximum span-ning tree in the original graph (Leonidas,2003).
Hence the algorithm can recur-sively call itself on the new graph.3 Online LearningAgain following (McDonald et al, 2005), we haveused the single best MIRA (Crammer and Singer,2003), which is a variant of the voted perceptron(Collins, 2002; Collins and Roark, 2004) for struc-tured prediction.
In short, the update is executedwhen the decoder fails to predict the correct parse,and we compare the correct parse yt and the incor-rect parse y?
suggested by the decoding algorithm.The weights of the features in y?
will be lowered, andthe weights of the features in yt will be increased ac-cordingly.4 ExperimentsOur experiments were conducted on CoNLL-Xshared task, with various datasets (Hajic?
et al, 2004;Simov et al, 2005; Simov and Osenova, 2003; Chenet al, 2003; Bo?hmova?
et al, 2003; Kromann, 2003;van der Beek et al, 2002; Brants et al, 2002;Kawata and Bartels, 2000; Afonso et al, 2002;Dz?eroski et al, 2006; Civit Torruella and Mart??
An-ton?
?n, 2002; Nilsson et al, 2005; Oflazer et al,2003; Atalay et al, 2003) .4.1 Dependency RelationThe CLE algorithm works on a directed graph withunlabeled edges.
Since the CoNLL-X shared task237Given a part ?DEPREL, i, j?DEPREL, dir(i, j)DEPREL, dir(i, j), wordiDEPREL, dir(i, j), posiDEPREL, dir(i, j), wordjDEPREL, dir(i, j), posjDEPREL, dir(i, j), wordi, posiDEPREL, dir(i, j), wordj , posjDEPREL, dir(i, j), wordi?1DEPREL, dir(i, j), posi?1DEPREL, dir(i, j), wordi?1, posi?1DEPREL, dir(i, j), wordj?1DEPREL, dir(i, j), posj?1DEPREL, dir(i, j), wordj?1, posj?1DEPREL, dir(i, j), wordi+1DEPREL, dir(i, j), posi+1DEPREL, dir(i, j), wordi+1, posi+1DEPREL, dir(i, j), wordj+1DEPREL, dir(i, j), posj+1DEPREL, dir(i, j), wordj+1, posj+1DEPREL, dir(i, j), posi?2DEPREL, dir(i, j), posi+2DEPREL, dir(i, j), distance = |j ?
i|additional featuresDEPREL, dir(i, j), wordi, wordjDEPREL, dir(i, j), posi+1, posi, posi+1DEPREL, dir(i, j), posi+1, wordi, posi+1DEPREL, dir(i, j), wordi, posi, posjDEPREL, dir(i, j), posi, wordj , posjTable 2: Binary Features for Each Partrequires the labeling of edges, as a preprocessingstage, we created a directed complete graph with-out multi-edges, that is, given two distinct nodes iand j, exactly two edges exist between them, onefrom i to j, and the other from j to i.
There is noself-pointing edge.
Then we labeled each edge withthe highest scoring dependency relation.
This com-plete graph was given to the CLE algorithm and theedge labels were never altered in the course of find-ing the maximum spanning tree.
The result is thenon-projective dependency tree with labeled edges.4.2 FeaturesThe features we used to score each part (edge)?DEPREL, i, j?
are shown in Table 2.
The index iis the position of the parent and j is that of the child.wordj = the word token at the position j.posj = the coarse part-of-speech at j.dir(i, j) = R if i < j, and L otherwise.No other features were used beyond the combina-tions of the CPOS tag and the word token in Table 2.We have evaluated our parser on Arabic, Danish,Slovene, Spanish, Turkish and Swedish, and usedthe ?additional features?
listed in Table 2 for all lan-guages except for Danish and Swedish.
The reasonfor this is simply that the model with the additionalfeatures did not fit in the 4 GB of memory used inthe training.Although we could do batch learning by runningthe online algorithm multiple times, we run the on-line algorithm just once.
The hardware used is anIntel Pentinum D at 3.0 Ghz with 4 GB of memory,and the software was written in C++.
The trainingtime required was Arabic 204 min, Slovene 87 min,Spanish 413 min, Swedish 1192 min, Turkish 410min, Danish 381 min.5 ResultsThe results are shown in Table 3.
Although our fea-ture set is very simple, the results were around theaverages.
We will do error analysis of three notablelanguages: Arabic, Swedish and Turkish.5.1 ArabicOf 4990 words in the test set, 800 are prepositions.The prepositions are the most frequently found to-kens after nouns in this set.
On the other hand,our head attachment error was 44% for prepositions.Given the relatively large number of prepositionsfound in the test set, it is important to get the prepo-sition attachment right to achieve a higher mark inthis language.
The obvious solution is to have a fea-ture that connects the head of a preposition to thechild of the preposition.
However, such a featureeffects the edge based factoring and the decoding al-gorithm, and we will be forced to modify the MSTalgorithm in some ways.5.2 SwedishDue to the memory constraint on the computer, wedid not use the additional features for Swedish andour feature heavily relied on the CPOS tag.
At thesame time, we have noticed that relatively higherperformance of our parser compared to the averagecoincides with the bigger tag set for CPOS for thiscorpus.
This suggests that we should be using morefine grained POS in other languages.5.3 TurkishThe difficulty with parsing Turkish stems from thelarge unlabeled attachment error rate on the nouns238Language LAS AV SDArabic 62.83% 59.92% 6.53Danish 75.81% 78.31% 5.45Slovene 64.57% 65.61% 6.78Spanish 73.17% 73.52% 8.41Swedish 79.49% 76.44% 6.46Turkish 54.23% 55.95% 7.71Language UAS AV SDArabic 74.27% 73.48% 4.94Danish 81.72% 84.52% 4.29Slovene 74.88% 76.53% 4.67Spanish 77.58% 77.76% 7.81Swedish 86.62% 84.21% 5.45Turkish 68.77% 69.35% 5.51Table 3: Labeled and Unlabeled Attachment Score(39%).
Since the nouns are the most frequently oc-curring words in the test set (2209 out of 5021 to-tal), this seems to make Turkish the most challeng-ing language for any system in the shared task.
Onthe average, there are 1.8 or so verbs per sentence,and nouns have a difficult time attaching to the cor-rect verb or postposition.
This, we think, indicatesthat there are morphological features or word order-ing features that we really need in order to disam-biguate them.6 Future WorkAs well as making use of fine-grained POS tags andother morphological features, given the error analy-sis on Arabic, we would like to add features that aredependent on two or more edges.6.1 Bottom-Up Non-Projective ParsingIn order to incorporate features which depend onother edges, we propose Bottom-Up Non-ProjectiveParsing.
It is often the case that dependency rela-tions can be ordered by how close one relation is tothe root of dependency tree.
For example, the de-pendency relation between a determiner and a nounshould be decided before that between a prepositionand a noun, and that of a verb and a preposition, andso on.
We can use this information to do bottom-upparsing.Suppose all words have a POS tag assigned tothem, and every edge labeled with a dependency re-lation is attached to a specific POS tag at the endpoint.
Also assume that there is an ordering of POStags such that the edge going to the POS tag needsbe decided before other edges.
For example, (1) de-terminer, (2) noun, (3) preposition, (4) verb wouldbe one such ordering.
We propose the following al-gorithm:?
Assume we have tokens as nodes in a graph and no edgesare present at first.
For example, we have tokens ?I?,?ate?, ?with?, ?a?, ?spoon?, and no edges between them.?
Take the POS tag that needs to be decided next.
Find alledges that go to each token labeled with this POS tag,and put them in the graph.
For example, if the POS isnoun, put edges from ?ate?
to ?I?, from ?ate?
to ?spoon?,from ?with?
to ?I?, from ?with?
to ?spoon?, from ?I?
to?spoon?, and from ?spoon?
to ?I?.?
Run the CLE algorithm on this graph.
This selects thehighest incoming edge to each token with the POS tag weare looking at, and remove cycles if any are present.?
Take the resulting forests and for each edge, bring the in-formation on the child node to the parent node.
For ex-ample, if this time POS was noun, and there is an edge toa preposition ?with?
from a noun ?spoon?, then ?spoon?is absorbed by ?with?.
Note that since no remaining de-pendency relation will attach to ?spoon?, we can safelyignore ?spoon?
from now on.?
Go back and repeat until no POS is remaining and wehave a dependency tree.
Now in the next round, whendeciding the score of the edge from ?ate?
to ?with?, wecan use the all information at the token ?with?, including?spoon?.7 ConclusionWe have extended non-projective unlabeled de-pendency parsing (McDonald et al, 2005) to avery simple non-projective labeled dependency andshowed that the parser performs reasonably wellwith small number of features and just one itera-tion of training.
Based on the analysis of the Ara-bic parsing results, we have proposed a bottom-up non-projective labeled dependency parsing algo-rithm that allows us to use features dependent onmore than one edge, with very little disadvantagecompared to the original algorithm.ReferencesA.
Abeille?, editor.
2003.
Treebanks: Building and Us-ing Parsed Corpora, volume 20 of Text, Speech andLanguage Technology.
Kluwer Academic Publishers,Dordrecht.S.
Afonso, E. Bick, R. Haber, and D. Santos.
2002.
?Flo-resta sinta?(c)tica?
: a treebank for Portuguese.
In Proc.of the Third Intern.
Conf.
on Language Resources andEvaluation (LREC), pages 1698?1703.239N.
B. Atalay, K. Oflazer, and B.
Say.
2003.
The annota-tion process in the Turkish treebank.
In Proc.
of the 4thIntern.
Workshop on Linguistically Interpreteted Cor-pora (LINC).A.
Bo?hmova?, J.
Hajic?, E.
Hajic?ova?, and B. Hladka?.
2003.The PDT: a 3-level annotation scenario.
In Abeille?
(Abeille?, 2003), chapter 7.S.
Brants, S. Dipper, S. Hansen, W. Lezius, and G. Smith.2002.
The TIGER treebank.
In Proc.
of theFirst Workshop on Treebanks and Linguistic Theories(TLT).R.
Bunescu and R. Mooney.
2005.
A shortest path de-pendency kernel for relation extraction.
In Proc.
ofthe Joint Conf.
on Human Language Technology andEmpirical Methods in Natural Language Processing(HLT/EMNLP).K.
Chen, C. Luo, M. Chang, F. Chen, C. Chen, C. Huang,and Z. Gao.
2003.
Sinica treebank: Design criteria,representational issues and implementation.
In Abeille?
(Abeille?, 2003), chapter 13, pages 231?248.Y.J.
Chu and T.H.
Liu.
1965.
On the shortest arbores-cence of a directed graph.
In Science Sinica, page14:13961400.M.
Civit Torruella and Ma A.
Mart??
Anton??n.
2002.
De-sign principles for a Spanish treebank.
In Proc.
of theFirst Workshop on Treebanks and Linguistic Theories(TLT).M.
Collins and B. Roark.
2004.
Incremental parsing withthe perceptron algorithm.
In Proc.
of the 42rd AnnualMeeting of the ACL.M.
Collins.
2002.
Discriminative training methods forhidden markov models: Theory and experiments withperceptron algorithms.
In Proc.
of Empirical Methodsin Natural Language Processing (EMNLP).K.
Crammer and Y.
Singer.
2003.
Ultraconservative on-line algorithms for multiclass problems.
In JMLR.Y.
Ding and M. Palmer.
2005.
Machine translation usingprobabilistic synchronous dependency insertion gram-mars.
In Proc.
of the 43rd Annual Meeting of the ACL.S.
Dz?eroski, T. Erjavec, N. Ledinek, P. Pajas,Z.
?Zabokrtsky, and A.
?Zele.
2006.
Towards a Slovenedependency treebank.
In Proc.
of the Fifth Intern.Conf.
on Language Resources and Evaluation (LREC).J.
Edmonds.
1967.
Optimum branchings.
In Journal ofResearch of the National Bureau of Standards, page71B:233240.J.
Hajic?, O.
Smrz?, P. Zema?nek, J.
?Snaidauf, and E. Bes?ka.2004.
Prague Arabic dependency treebank: Develop-ment in data and tools.
In Proc.
of the NEMLAR In-tern.
Conf.
on Arabic Language Resources and Tools,pages 110?117.Y.
Kawata and J. Bartels.
2000.
Stylebook for theJapanese treebank in VERBMOBIL.
Verbmobil-Report 240, Seminar fu?r Sprachwissenschaft, Univer-sita?t Tu?bingen.M.
T. Kromann.
2003.
The Danish dependency treebankand the underlying linguistic theory.
In Proc.
of theSecond Workshop on Treebanks and Linguistic Theo-ries (TLT).G.
Leonidas.
2003.
Arborescence optimization problemssolvable by edmonds algorithm.
In Theoretical Com-puter Science, page 301:427 437.R.
McDonald, F. Pereira, K. Ribarov, and J. Hajic?.
2005.Non-projective dependency parsing using spanningtree algorithms.
In Proc.
of the Joint Conf.
on Hu-man Language Technology and Empirical Methods inNatural Language Processing (HLT/EMNLP).J.
Nilsson, J.
Hall, and J. Nivre.
2005.
MAMBA meetsTIGER: Reconstructing a Swedish treebank from an-tiquity.
In Proc.
of the NODALIDA Special Session onTreebanks.J.
Nivre and J. Nilsson.
2005.
Pseudo-projective depen-dency parsing.
In Proc.
of the 43rd Annual Meeting ofthe ACL.K.
Oflazer, B.
Say, D. Zeynep Hakkani-Tu?r, and G. Tu?r.2003.
Building a Turkish treebank.
In Abeille?
(Abeille?, 2003), chapter 15.K.
Simov and P. Osenova.
2003.
Practical annotationscheme for an HPSG treebank of Bulgarian.
In Proc.of the 4th Intern.
Workshop on Linguistically Inter-preteted Corpora (LINC), pages 17?24.K.
Simov, P. Osenova, A. Simov, and M. Kouylekov.2005.
Design and implementation of the BulgarianHPSG-based treebank.
In Journal of Research on Lan-guage and Computation ?
Special Issue, pages 495?522.
Kluwer Academic Publishers.B.
Taskar, D. Klein, M. Collins, D. Koller, and C. Man-ning.
2004.
Max-margin parsing.
In Proc.
ofEmpirical Methods in Natural Language Processing(EMNLP).L.
van der Beek, G. Bouma, R. Malouf, and G. van No-ord.
2002.
The Alpino dependency treebank.
In Com-putational Linguistics in the Netherlands (CLIN).240
