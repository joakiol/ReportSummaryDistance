Proceedings of the 2010 Workshop on Domain Adaptation for Natural Language Processing, ACL 2010, pages 53?59,Uppsala, Sweden, 15 July 2010. c?2010 Association for Computational LinguisticsFrustratingly Easy Semi-Supervised Domain AdaptationHal Daume?
IIISchool Of ComputingUniversity of Utahhal@cs.utah.eduAbhishek KumarSchool Of ComputingUniversity of Utahabhik@cs.utah.eduAvishek SahaSchool Of ComputingUniversity of Utahavishek@cs.utah.eduAbstractIn this work, we propose a semi-supervised extension to a well-knownsupervised domain adaptation approach(EA) (Daume?
III, 2007).
Our proposedapproach (EA++) builds on the notionof augmented space (introduced in EA)and harnesses unlabeled data in target do-main to ameliorate the transfer of infor-mation from source to target.
This semi-supervised approach to domain adaptationis extremely simple to implement, and canbe applied as a pre-processing step to anysupervised learner.
Experimental resultson sequential labeling tasks demonstratethe efficacy of the proposed method.1 IntroductionA domain adaptation approach for sequential la-beling tasks in NLP was proposed in (Daume?III, 2007).
The proposed approach, termedEASYADAPT (EA), augments the source domainfeature space using features from labeled data intarget domain.
EA is simple, easy to extend andimplement as a preprocessing step and most im-portantly is agnostic of the underlying classifier.However, EA requires labeled data in the targetand hence applies to fully supervised (labeled datain source and target) domain adaptation settingsonly.
In this paper, we propose a semi-supervised1(labeled data in source, and both labeled and un-labeled data in target) approach to leverage unla-beled data for EASYADAPT (which we call EA++)and empirically demonstrate its superior perfor-mance over EA as well as few other existing ap-proaches.1We refer, labeled data in source and only unlabeled datain target, as the unsupervised domain adaptation setting.There exists prior work on supervised domainadaptation (or multi-task learning) that can be re-lated to EASYADAPT.
An algorithm for multi-task learning using shared parameters was pro-posed (Evgeniou and Pontil, 2004) for multi-taskregularization where each task parameter was rep-resented as sum of a mean parameter (that stayssame for all tasks) and its deviation from thismean.
SVM was used as the base classifierand the algorithm was formulated in the standardSVM dual optimization setting.
Subsequently,this framework (Evgeniou and Pontil, 2004) wasextended (Dredze et al, 2010) to online multi-domain setting.
Prior work on semi-supervisedapproaches to domain adaptation also exists in lit-erature.
Extraction of specific features from theavailable dataset was proposed (Arnold and Co-hen, 2008; Blitzer et al, 2006) to facilitate thetask of domain adaptation.
Co-adaptation (Tur,2009), a combination of co-training and domainadaptation, can also be considered as a semi-supervised approach to domain adaptation.
Asemi-supervised EM algorithm for domain adap-tation was proposed in (Dai et al, 2007).
Sim-ilar to graph based semi-supervised approaches,a label propagation method was proposed (Xinget al, 2007) to facilitate domain adaptation.
Therecently proposed Domain Adaptation Machine(DAM) (Duan et al, 2009) is a semi-supervisedextension of SVMs for domain adaptation andpresents extensive empirical results.
However, inalmost all of the above cases, the proposed meth-ods either use specifics of the datasets or are cus-tomized for some particular base classifier andhence it is not clear how the proposed methodscan be extended to other existing classifiers.EA, on the other hand, is remarkably general inthe sense that it can be used as a pre-processing53step in conjunction with any base classifier.
How-ever, one of the prime limitations of EA is its inca-pability to leverage unlabeled data.
Given its sim-plicity and generality, it would be interesting toextend EA to semi-supervised settings.
In this pa-per we propose EA++, a co-regularization basedsemi-supervised extension to EA.
We present ourapproach and results for a single pair of sourceand target domain.
However, we note that EA++can also be extended to multiple source settings.If we have k sources and a single target domainthen we can introduce a co-regularizer for eachsource-target pair.
Due to space constraints, wedefer details to a full version.2 Background2.1 Problem Setup and NotationsLet X ?
Rd denote the instance space and Y= {?1,+1} denote the label space.
We have a setof source labeled examples Ls(?
Ds(x, y)) anda set of target labeled examples Lt(?
Dt(x, y)),where |Ls| = ls ?
|Lt| = lt. We also have targetunlabeled data denoted by Ut(?
Dt(x)), where|Ut| = ut.
Our goal is to learn a hypothesis h :X 7?
Y having low expected error with respect tothe target domain.
In this paper, we consider lin-ear hypotheses only.
However, the proposed tech-niques extend to non-linear hypotheses, as men-tioned in (Daume?
III, 2007).
Source and targetempirical errors for hypothesis h are denoted by?
?s(h, fs) and ?
?t(h, ft) respectively, where fs andft are source and target labeling functions.
Sim-ilarly, the corresponding expected errors are de-noted by ?s(h, fs) and ?t(h, ft).
Shorthand no-tions of ?
?s, ?
?t, ?s and ?t have also been used.2.2 EasyAdapt (EA)In this section, we give a brief overview ofEASYADAPT proposed in (Daume?
III, 2007).
Letus denote Rd as the original space.
EA operatesin an augmented space denoted by X?
?
R3d (for asingle pair of source and target domain).
For k do-mains, the augmented space blows up to R(k+1)d.The augmented feature maps ?s,?t : X 7?
X?
forsource and target domains are defined as,?s(x) = ?x, x, 0?
?t(x) = ?x, 0, x?
(2.1)where x and 0 are vectors in Rd, and 0 de-notes a zero vector of dimension d. The first d-dimensional segment corresponds to commonalitybetween source and target, second d-dimensionalsegment corresponds to the source domain whilethe last segment corresponds to the target domain.Source and target domain features are transformedusing these feature maps and the augmented fea-ture space so constructed is passed onto the un-derlying supervised classifier.
One of the most ap-pealing properties of EASYADAPT is that it is ag-nostic of the underlying supervised classifier be-ing used to learn in the augmented space.
Al-most any standard supervised learning approachfor linear classifiers (for e.g., SVMs, perceptrons)can be used to learn a linear hypothesis h?
?
R3din the augmented space.
As mentioned earlier,this work considers linear hypotheses only and thethe proposed techniques can be extended (Daume?III, 2007) to non-linear hypotheses.
Let us denoteh?
= ?hc, hs, ht?, where each of hc, hs, ht is ofdimension d and represent the common, source-specific and target-specific components of h?, re-spectively.
During prediction on target data, theincoming target feature x is transformed to obtain?t(x) and h?
is applied on this transformed fea-ture.
This is equivalent to applying (hc + ht) onx.A good intuitive insight into why this simplealgorithm works so well in practice and outper-forms most state-of-the-art algorithms is givenin (Daume?
III, 2007).
Briefly, it can be thought tobe simultaneously training two hypotheses: ws =(hc +hs) for source domain and wt = (hc +gt)for target domain.
The commonality between thedomains is represented by hc whereas the sourceand target domain specific information is capturedby hs and ht, respectively.
This technique canbe easily extended to a multi-domain scenario bymaking more copies of the original feature space((K +1) copies in case of K domains).
A kernel-ized version of the algorithm has also been pre-sented in (Daume?
III, 2007).3 Using Unlabeled dataAs discussed in the previous section, theEASYADAPT algorithm is attractive because itperforms very well empirically and can be used inconjunction with any underlying supervised clas-54sifier.
One drawback of EASYADAPT is that itdoes not make use of unlabeled target data whichis generally available in large quantity in mostpractical problems.
In this section, we propose asemi-supervised extension of this algorithm whilemaintaining the desirable classifier-agnostic prop-erty.3.1 MotivationIn multi-view approach for semi-supervised learn-ing algorithms (Sindhwani et al, 2005), differenthypotheses are learned in different views.
There-after, unlabeled data is utilized to co-regularizethese learned hypotheses by making them agreeon unlabeled samples.
In domain adaptation, thesource and target data come from two differentdistributions.
However, if the source and tar-get domains are reasonably close to each other,we can employ a similar form of regularizationusing unlabeled data.
A similar co-regularizerbased approach for unlabeled data was previouslyshown (Duan et al, 2009) to give improved empir-ical results for domain adaptation task.
However,their technique applies for the particular base clas-sifier they consider and hence does not extend toEASYADAPT.3.2 EA++: EASYADAPT with unlabeled dataIn our proposed semi-supervised extension toEASYADAPT, the source and target hypothesis aremade to agree on unlabeled data.
We refer tothis algorithm as EA++.
Recall that EASYADAPTlearns a linear hypothesis h?
?
R3d in the aug-mented space.
The hypothesis h?
contains com-mon, source and target sub-hypotheses and is ex-pressed as h?
= ?hc, hs, ht?.
In original space(ref.
section 2.2), this is equivalent to learning asource specific hypothesis ws = (hc + hs) and atarget specific hypothesis wt = (hc + ht).In EA++, we want source hypothesis ws andtarget hypothesis wt to agree on unlabeled data.For some unlabeled target sample xi ?
Ut ?
Rd,EA++ would implicitly want to make the predic-tions of wt and wt on xi to agree.
Formally, itaims to achieve the following condition:ws ?
xi ?
wt ?
xi??
(hc + hs) ?
xi ?
(hc + ht) ?
xi??
(hs ?
ht) ?
xi ?
0??
?hc, hs, ht?
?
?0, xi, ?xi?
?
0.
(3.1)We define another feature map ?u : X 7?
X?
forunlabeled data as below:?u(x) = ?0, x, ?x?.
(3.2)Every unlabeled sample is transformed using themap ?u(.).
The augmented feature space that re-sults from the application of three feature maps,namely, ?s : X 7?
X?,?t : X 7?
X?,?u : X 7?X?
, on source labeled samples, target labeled sam-pled and target unlabeled samples is summarizedin Figure 1.As shown in Eq.
3.1, during the training phase,EA++ assigns a predicted value close to 0 for eachunlabeled sample.
However, it is worth notingthat, during the test phase, EA++ predicts labelsfrom two classes: +1 and ?1.
This warrantsfurther exposition of the implementation specificswhich is deferred until the next subsection.EA++EA00d d d                                                                                                                                                                                                                                                                                                                                             0LsLsLt LtUt ?UtlsltutFigure 1: Diagrammatic representation of featureaugmentation in EA and EA++Algorithm 1 presents the EA++ approach in de-tail.3.3 ImplementationIn this section, we present implementation specificdetails of EA++.
We consider SVM as our basesupervised learner (LEARN in Algorithm 1).However, these details hold for other supervised55Algorithm 1 EA++Input: Ls; Lt; Ut; LEARN : supervised clas-sifierOutput: h?
: classifier learned in augmentedspace/* initialize augmented training set */1: P := {}/* construct augmented training set */2: ?
(x, y) ?
Ls, P := P ?
{?s(x), y}3: ?
(x, y) ?
Lt, P := P ?
{?t(x), y}4: ?x ?
Ut, P := P ?
{?u(x), 0}/* output learned classifier */5: h?
= LEARN (P )classifiers too.
In the dual form of SVM optimiza-tion function, the labels are multiplied with the in-ner product of features.
This can make the un-labeled samples redundant since we want their la-bels to be 0 according to Eq.
3.1.
To avoid this, wecreate as many copies of ?u(x) as there are labelsand assign each label to one copy.
For the case ofbinary classification, we create two copies of ev-ery augmented unlabeled sample, and assign +1label to one copy and ?1 to the other.
The learnerattempts to balance the loss of the two copies, andtries to make the prediction on unlabeled sampleequal to 0.
Figure 2 shows the curves of the hingeloss for class +1, class ?1 and their sum.
The ef-fective loss for each unlabeled sample is similar tothe sum of losses for +1 and ?1 classes (shown inFigure 2c).4 ExperimentsIn this section, we demonstrate the empirical per-formance of EA augmented with unlabeled data.4.1 SetupWe follow the same experimental setup usedin (Daume?
III, 2007) and perform two sequencelabelling tasks (a) named-entity-recognition(NER), and (b) part-of-speech-tagging (POS )onthe following datasets:PubMed-POS: Introduced by (Blitzer et al,2006), this dataset consists of two domains.The WSJ portion of the Penn Treebankserves as the source domain and the PubMedabstracts serve as the target domain.
TheLossLossLoss(a)(b)(c)Figure 2: Loss functions for class +1, class ?1and unlabeled samples.task is to perform part-of-speech tagging onunlabeled PubMed abstracts with a classifiertrained on labeled WSJ and PubMed data.Treebank-Brown.
Treebank-Chunk data consistsof the following domains: the standard WSJdomain (the same data as for CoNLL 2000),the ATIS switchboard domain and the Browncorpus.
The Brown corpus consists of datacombined from six subdomains.
Treebank-Chunk is a shallow parsing task based onthe data from the Penn Treebank.
Treebank-Brown is identical to the Treebank-Chunktask, However, in Treebank-Brown we con-sider all of the Brown corpus to be a singledomain.Table 1 presents a summary of the datasetsused.
All datasets use roughly the same featureset which are lexical information (words, stems,capitalization, prefixes and suffixes), membershipon gazetteers, etc.
We use an averaged perceptronclassifier from the Megam framework (implemen-tation due to (Daume?
III, 2004)) for all the afore-mentioned tasks.
The training sample size variesfrom 1k to 16k.
In all cases, the amount of unla-beled target data was equal to the total amount oflabeled source and target data.56Task Dom #Tr #De #Te #FtPubMed src 950,028 - - 571kPOS tgt 11,264 1,987 14,554 39kwsj 191,209 29,455 38,440 94kswbd3 45,282 5,596 41,840 55kbr-cf 58,201 8,307 7,607 144kTree br-cg 67,429 9,444 6,897 149kbank- br-ck 51,379 6,061 9,451 121kChunk br-cl 47,382 5,101 5,880 95kbr-cm 11,696 1,324 1,594 51kbr-cn 56,057 6,751 7,847 115kbr-cp 55,318 7,477 5,977 112kbr-cr 16,742 2,522 2,712 65kTable 1: Summary of Datasets.
The columns de-note task, domain, size of training, developmentand test data sets, and the number of unique fea-tures in the training data.4.2 ResultsWe compare the empirical performance ofEA++ with a few other baselines, namely, (a)SOURCEONLY (classifier trained on source la-beled samples), (b) TARGETONLY-FULL (classi-fier trained on the same number of target labeledsamples as the number of source labeled samplesin SOURCEONLY), (c) TARGETONLY (classifiertrained on small amount of target labeled sam-ples, roughly one-tenth of the amount of source la-beled samples in SOURCEONLY), (d) ALL (clas-sifier trained on combined labeled samples ofSOURCEONLY and TARGETONLY), (e) EA (clas-sifier trained in augmented feature space on thesame input training set as ALL), (f) EA++ (clas-sifier trained in augmented feature space on thesame input training set as EA and an equal amountof unlabeled target data).
All these approacheswere tested on the entire amount of available tar-get test data.Figure 3 presents the learning curves for(a) SOURCEONLY, (b) TARGETONLY-FULL, (c)TARGETONLY, (d) ALL, (e) EA, and (f) EA++(EA with unlabeled data).
The x-axis repre-sents the number of training samples on whichthe predictor has been trained.
At this point,we note that the number of training samplesvary depending on the particular approach beingused.
For SOURCEONLY, TARGETONLY-FULLand TARGETONLY, it is just the correspondingnumber of labeled source or target samples, re-spectively.
For ALL and EA, it is the summa-tion of labeled source and target samples.
For0.10.20.30.40.54000 8000 12000 16000errorratenumber of samplesSrcOnlyTgtOnly-FullTgtOnlyAllEAEA++(a)0.10.20.30.40.54000 8000 12000 16000errorratenumber of samplesSrcOnlyTgtOnly-FullTgtOnlyAllEAEA++(b)Figure 3: Test accuracy of (a) PubMed-POS and(b) Treebank-Brown for, SOURCEONLY, TARGE-TONLY-FULL, TARGETONLY, ALL, EA andEA++.EA++, the x-value plotted denotes the amount ofunlabeled target data used (in addition to an equalamount of source+target labeled data, as in ALLor EA).
We plot this number for EA++, just tocompare its improvement over EA when using anadditional (and equal) amount of unlabeled targetdata.
This accounts for the different x values plot-ted for the different curves.
In all cases, the y-axisdenotes the error rate.As can be seen in Figure 3(a), EA++ performsbetter than the normal EA (which uses labeleddata only).
The labeled and unlabeled case starttogether but with increase in number of samplestheir gap increases with the unlabeled case result-ing in much lower error as compared to the labeledcase.
Similar trends were observed in other datasets as can be seen in Figure 3(b).
We also notethat EA performs poorly for some cases, as was57shown (Daume?
III, 2007) earlier.5 SummaryIn this paper, we have proposed a semi-supervisedextension to an existing domain adaptation tech-nique (EA).
Our approach EA++, leverages theunlabeled data to improve the performance of EA.Empirical results demonstrate improved accuracyfor sequential labeling tasks performed on stan-dardized datasets.
The previously proposed EAcould be applied exclusively to fully superviseddomain adaptation problems only.
However, withthe current extension, EA++ applies to both fullysupervised and semi-supervised domain adapta-tion problems.6 Future WorkIn both EA and EA++, we use features fromsource and target space to construct an augmentedfeature space.
In other words, we are sharing fea-tures across source and target labeled data.
Weterm such algorithms as Feature Sharing Algo-rithms.
Feature sharing algorithms are effectivefor domain adaptation because they are simple,easy to implement as a preprocessing step and out-perform many existing state-of-the-art techniques(shown previously for domain adaptation (Daume?III, 2007)).
However, despite their simplicity andempirical success, it is not theoretically apparentwhy these algorithms perform so well.
Prior workprovides some intuitions but is mostly empiricaland a formal theoretical analysis to justify FSAs(for domain adaptation) is clearly missing.
Priorwork (Maurer, 2006) analyzes the multi-task reg-ularization approach (Evgeniou and Pontil, 2004)(which is related to EA) but they consider a cumu-lative loss in multi-task (or multi-domain) setting.This does not apply to domain adaptation settingwhere we are mainly interested in loss in the targetdomain only.Theoretically analyzing the superior perfor-mance of EA and EA++ and providing gener-alization guarantees is an interesting line of fu-ture work.
One approach would be to modelthe feature sharing approach in terms of co-regularization; an idea that originated in thecontext of multiview learning and for whichsome theoretical analysis has already been done(Rosenberg and Bartlett, 2007; Sindhwani andRosenberg, 2008).
Additionally, the afore-mentioned techniques, namely, SOURCEONLY,TARGETONLY, ALL have been empirically com-pared to EA and EA++.
It would be interest-ing to formally frame these approaches and seewhether their empirical performance can be justi-fied within a theoretical framework.ReferencesAndrew Arnold and William W. Cohen.
2008.
Intra-document structural frequency features for semi-supervised domain adaptation.
In CIKM?08, pages1291?1300, Napa Valley, California, USA.John Blitzer, Ryan Mcdonald, and Fernando Pereira.2006.
Domain adaptation with structural correspon-dence learning.
In EMNLP?06, pages 120?128,Sydney, Australia.Wenyuan Dai, Gui-Rong Xue, Qiang Yang, and YongYu.
2007.
Transferring Naive Bayes classifiersfor text classification.
In AAAI?07, pages 540?545,Vancouver, B.C.Hal Daume?
III.
2004.
Notes on CG and LM-BFGSoptimization of logistic regression.
August.Hal Daume?
III.
2007.
Frustratingly easy domain adap-tation.
In ACL?07, pages 256?263, Prague, CzechRepublic.Mark Dredze, Alex Kulesza, and Koby Crammer.2010.
Multi-domain learning by confidence-weighted parameter combination.
Machine Learn-ing, 79.Lixin Duan, Ivor W. Tsang, Dong Xu, and Tat-SengChua.
2009.
Domain adaptation from multiplesources via auxiliary classifiers.
In ICML?09, pages289?296, Montreal, Quebec.Theodoros Evgeniou and Massimiliano Pontil.
2004.Regularized multitask learning.
In KDD?04, pages109?117, Seattle, WA, USA.Andreas Maurer.
2006.
The Rademacher complexityof linear transformation classes.
In COLT?06, pages65?78, Pittsburgh, Pennsylvania.D.
S. Rosenberg and P. L. Bartlett.
2007.
TheRademacher complexity of co-regularized kernelclasses.
In AISTATS?07, San Juan, Puerto Rico.Vikas Sindhwani and David S. Rosenberg.
2008.An RKHS for multi-view learning and manifoldco-regularization.
In ICML?08, pages 976?983,Helsinki, Finland.58Vikas Sindhwani, Partha Niyogi, and Mikhail Belkin.2005.
A co-regularization approach to semi-supervised learning with multiple views.
In ICMLWorkshop on Learning with Multiple Views, pages824?831, Bonn, Germany.Gokhan Tur.
2009.
Co-adaptation: Adaptiveco-training for semi-supervised learning.
InICASSP?09, pages 3721?3724, Taipei, Taiwan.Dikan Xing, Wenyuan Dai, Gui-Rong Xue, and YongYu.
2007.
Bridged refinement for transfer learning.In PKDD?07, pages 324?335, Warsaw, Poland.59
