Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 208?215,New York, June 2006. c?2006 Association for Computational LinguisticsLearning to Detect Conversation Focus of Threaded DiscussionsDonghui Feng        Erin Shaw        Jihie Kim        Eduard HovyInformation Sciences InstituteUniversity of Southern CaliforniaMarina del Rey, CA, 90292{donghui, shaw, jihie, hovy}@isi.eduAbstractIn this paper we present a novel feature-enriched approach that learns to detect theconversation focus of threaded discus-sions by combining NLP analysis and IRtechniques.
Using the graph-based algo-rithm HITS, we integrate different fea-tures such as lexical similarity, postertrustworthiness, and speech act analysis ofhuman conversations with feature-oriented link generation functions.
It isthe first quantitative study to analyze hu-man conversation focus in the context ofonline discussions that takes into accountheterogeneous sources of evidence.
Ex-perimental results using a threaded dis-cussion corpus from an undergraduateclass show that it achieves significant per-formance improvements compared withthe baseline system.1 IntroductionThreaded discussion is popular in virtual cybercommunities and has applications in areas such ascustomer support, community development, inter-active reporting (blogging) and education.
Discus-sion threads can be considered a special case ofhuman conversation, and since we have huge re-positories of such discussion, automatic and/orsemi-automatic analysis would greatly improve thenavigation and processing of the information.A discussion thread consists of a set of messagesarranged in chronological order.
One of the mainchallenges in the Question Answering domain ishow to extract the most informative or importantmessage in the sequence for the purpose of answer-ing the initial question, which we refer to as theconversation focus in this paper.
For example,people may repeatedly discuss similar questions ina discussion forum and so it is highly desirable todetect previous conversation focuses in order toautomatically answer queries (Feng et al, 2006).Human conversation focus is a hard NLP (Natu-ral Language Processing) problem in general be-cause people may frequently switch topics in a realconversation.
The threaded discussions make theproblem manageable because people typically fo-cus on a limited set of issues within a thread of adiscussion.
Current IR (Information Retrieval)techniques are based on keyword similarity meas-ures and do not consider some features that areimportant for analyzing threaded discussions.
As aresult, a typical IR system may return a ranked listof messages based on keyword queries even if,within the context of a discussion, this may not beuseful or correct.Threaded discussion is a special case of humanconversation, where people may express theirideas, elaborate arguments, and answer others?questions; many of these aspects are unexplored bytraditional IR techniques.
First, messages inthreaded discussions are not a flat document set,which is a common assumption for most IR sys-tems.
Due to the flexibility and special characteris-tics involved in human conversations, messageswithin a thread are not necessarily of equal impor-tance.
The real relationships may differ from theanalysis based on keyword similarity measures,e.g., if a 2nd message ?corrects?
a 1st one, the 2ndmessage is probably more important than the 1st.IR systems may give different results.
Second,messages posted by different users may have dif-ferent degrees of correctness and trustworthiness,which we refer to as poster trustworthiness in thispaper.
For instance, a domain expert is likely to bemore reliable than a layman on the domain topic.208In this paper we present a novel feature-enrichedapproach that learns to detect conversation focus ofthreaded discussions by combining NLP analysisand IR techniques.
Using the graph-based algo-rithm HITS (Hyperlink Induced Topic Search,Kleinberg, 1999), we conduct discussion analysistaking into account different features, such as lexi-cal similarity, poster trustworthiness, and speechact relations in human conversations.
We generatea weighted threaded discussion graph by applyingfeature-oriented link generation functions.
All thefeatures are quantified and integrated as part of theweight of graph edges.
In this way, both quantita-tive features and qualitative features are combinedto analyze human conversations, specifically in theformat of online discussions.To date, it is the first quantitative study to ana-lyze human conversation that focuses on threadeddiscussions by taking into account heterogeneousevidence from different sources.
The study de-scribed here addresses the problem of conversationfocus, especially for extracting the best answer to aparticular question, in the context of an online dis-cussion board used by students in an undergraduatecomputer science course.
Different features arestudied and compared when applying our approachto discussion analysis.
Experimental results showthat performance improvements are significantcompared with the baseline system.The remainder of this paper is organized as fol-lows: We discuss related work in Section 2.
Sec-tion 3 presents thread representation and theweighted HITS algorithm.
Section 4 details fea-ture-oriented link generation functions.
Compara-tive experimental results and analysis are given inSection 5.
We discuss future work in Section 6.2 Related WorkHuman conversation refers to situations where twoor more participants freely alternate in speaking(Levinson, 1983).
What makes threaded discus-sions unique is that users participate asynchro-nously and in writing.
We model humanconversation as a set of messages in a threadeddiscussion using a graph-based algorithm.Graph-based algorithms are widely applied inlink analysis and for web searching in the IR com-munity.
Two of the most prominent algorithms arePage-Rank (Brin and Page, 1998) and the HITSalgorithm (Kleinberg, 1999).
Although they wereinitially proposed for analyzing web pages, theyproved useful for investigating and ranking struc-tured objects.
Inspired by the idea of graph basedalgorithms to collectively rank and select the bestcandidate, research efforts in the natural languagecommunity have applied graph-based approacheson keyword selection (Mihalcea and Tarau, 2004),text summarization (Erkan and Radev, 2004; Mi-halcea, 2004), word sense disambiguation (Mihal-cea et al, 2004; Mihalcea, 2005), sentimentanalysis (Pang and Lee, 2004), and sentence re-trieval for question answering (Otterbacher et al,2005).
However, until now there has not been anypublished work on its application to human con-versation analysis specifically in the format ofthreaded discussions.
In this paper, we focus onusing HITS to detect conversation focus ofthreaded discussions.Rhetorical Structure Theory (Mann and Thom-son, 1988) based discourse processing has attractedmuch attention with successful applications in sen-tence compression and summarization.
Most of thecurrent work on discourse processing focuses onsentence-level text organization (Soricut andMarcu, 2003) or the intermediate step (Sporlederand Lapata, 2005).
Analyzing and utilizing dis-course information at a higher level, e.g., at theparagraph level, still remains a challenge to thenatural language community.
In our work, we util-ize the discourse information at a message level.Zhou and Hovy (2005) proposed summarizingthreaded discussions in a similar fashion to multi-document summarization; but then their work doesnot take into account the relative importance ofdifferent messages in a thread.
Marom and Zuker-man (2005) generated help-desk responses usingclustering techniques, but their corpus is composedof only two-party, two-turn, conversation pairs,which precludes the need to determine relative im-portance as in a multi-ply conversation.In our previous work (Feng et al, 2006), we im-plemented a discussion-bot to automatically an-swer student queries in a threaded discussion butextract potential answers (the most informativemessage) using a rule-based traverse algorithm thatis not optimal for selecting a best answer; thus, theresult may contain redundant or incorrect informa-tion.
We argue that pragmatic knowledge likespeech acts is important in conversation focusanalysis.
However, estimated speech act labelingbetween messages is not sufficient for detecting209human conversation focus without consideringother features like author information.
Carvalhoand Cohen (2005) describe a dependency-networkbased collective classification method to classifyemail speech acts.
Our work on conversation focusdetection can be viewed as an immediate step fol-lowing automatic speech act labeling on discussionthreads using similar collective classification ap-proaches.We next discuss our approach to detect conver-sation focus using the graph-based algorithm HITSby taking into account heterogeneous features.3 Conversation Focus DetectionIn threaded discussions, people participate in aconversation by posting messages.
Our goal is tobe able to detect which message in a thread con-tains the most important information, i.e., the focusof the conversation.
Unlike traditional IR systems,which return a ranked list of messages from a flatdocument set, our task must take into accountcharacteristics of threaded discussions.First, messages play certain roles and are relatedto each other by a conversation context.
Second,messages written by different authors may vary invalue.
Finally, since postings occur in parallel, byvarious people, message threads are not necessarilycoherent so the lexical similarity among the mes-sages should be analyzed.
To detect the focus ofconversation, we integrate a pragmatics study ofconversational speech acts, an analysis of messagevalues based on poster trustworthiness and ananalysis of lexical similarity.
The subsystems thatdetermine these three sources of evidence comprisethe features of our feature-based system.Because each discussion thread is naturally rep-resented by a directed graph, where each messageis represented by a node in the graph, we can applya graph-based algorithm to integrate these sourcesand detect the focus of conversation.3.1 Thread RepresentationA discussion thread consists of a set of messagesposted in chronological order.
Suppose that eachmessage is represented by mi, i =1,2,?, n. Thenthe entire thread is a directed graph that can be rep-resented by G= (V, E), where V is the set of nodes(messages), V= {mi,i=1,...,n}, and E is the set ofdirected edges.
In our approach, the set V is auto-matically constructed as each message joins in thediscussion.
E is a subset of VxV.
We will discussthe feature-oriented link generation functions thatconstruct the set E in Section 4.We make use of speech act relations in generat-ing the links.
Once a speech act relation is identi-fied between two messages, links will be generatedusing generation functions described in next sec-tion.
When mi is a message node in the threadgraph, VmF i ?
)( represents the set of nodes thatnode mi points to (i.e., children of mi), andVmB i ?
)( represents the set of nodes that point tomi (i.e., parents of mi).3.2 Graph-Based Ranking Algorithm: HITSGraph-based algorithms can rank a set of objects ina collective way and the affect between each paircan be propagated into the whole graph iteratively.Here, we use a weighted HITS (Kleinberg, 1999)algorithm to conduct message ranking.Kleinberg (1999) initially proposed the graph-based algorithm HITS for ranking a set of webpages.
Here, we adjust the algorithm for the task ofranking a set of messages in a threaded discussion.In this algorithm, each message in the graph can berepresented by two identity scores, hub score andauthority score.
The hub score represents the qual-ity of the message as a pointer to valuable or usefulmessages (or resources, in general).
The authorityscore measures the quality of the message as a re-source itself.
The weighted iterative updating com-putations are shown in Equations 1 and 2.
?
?+ =)(1 )(*)(ij mFmjrijir mauthoritywmhub           (1)?
?+ =)(1 )(*)(ij mBmjrjiir mhubwmauthority           (2)where r and r+1 are the numbers of iterations.The number of iterations required for HITS toconverge depends on the initialization value foreach message node and the complexity of thegraph.
Graph links can be induced with extraknowledge (e.g.
Kurland and Lee, 2005).
To helpintegrate our heterogeneous sources of evidencewith our graph-based HITS algorithm, we intro-duce link generation functions for each of the threefeatures, (gi, i=1, 2, 3), to add links between mes-sages.4 Feature-Oriented Link Generation210Conversation structures have received a lot of at-tention in the linguistic research community (Lev-inson, 1983).
In order to integrate conversationalfeatures into our computational model, we mustconvert a qualitative analysis into quantitativescores.
For conversation analysis, we adopted thetheory of Speech Acts proposed by (Austin, 1962;Searle, 1969) and defined a set of speech acts (SAs)that relate every pair of messages in the corpus.Though a pair of messages may only be labeledwith one speech act, a message can have multipleSAs with other messages.We group speech acts by function into threecategories, as shown in Figure 1.
Messages mayinvolve a request (REQ), provide information(INF), or fall into the category of interpersonal(INTP) relationship.
Categories can be further di-vided into several single speech acts.Figure 1.
Categories of Message Speech Act.The SA set for our corpus is given in Table 1.
Aspeech act may a represent a positive, negative orneutral response to a previous message dependingon its attitude and recommendation.
We classifyeach speech act as a direction as POSITIVE (+),NEGATIVE (?)
or NEUTRAL, referred to as SADirection, as shown in the right column of Table 1.The features we wish to include in our approachare lexical similarity between messages, postertrustworthiness, and speech act labels betweenmessage pairs in our discussion corpus.The feature-oriented link generation is con-ducted in two steps.
First, our approach examinesin turn all the speech act relations in each threadand generates two types of links based on lexicalsimilarity and SA strength scores.
Second, the sys-tem iterates over all the message nodes and assignseach node a self-pointing link associated with itsposter trustworthiness score.
The three features areintegrated into the thread graph accordingly by thefeature-oriented link generation functions.
Multiplelinks with the same start and end points are com-bined into one.SpeechAct Name Description Dir.ACK Acknowl-edgeConfirm oracknowledge +CANS Complex AnswerGive answer requiring afull description of pro-cedures, reasons, etc.COMM Command Command or            announceCOMP Compli-mentPraise an argument orsuggestion +CORR Correct Correct a wrong answer or solution ?CRT Criticize Criticize an argument ?DESC Describe Describe a fact or    situationELAB Elaborate Elaborate on a previous argument or questionOBJ Object Object to an argument or suggestion ?QUES Question Ask question about a specific problemSANS Simple AnswerAnswer with a shortphrase or few words(e.g.
factoid, yes/no)SUG Suggest Give advice or suggest a solutionSUP Support Support an argument or suggestion +Table 1.
Types of message speech acts in corpus.4.1 Lexical SimilarityDiscussions are constructed as people expressideas, opinions, and thoughts, so that the text itselfcontains information about what is being dis-cussed.
Lexical similarity is an important measurefor distinguishing relationships between messagepairs.
In our approach, we do not compute the lexi-cal similarity of any arbitrary pair of messages,instead, we consider only message pairs that arepresent in the speech act set.
The cosine similaritybetween each message pair is computed using theTF*IDF technique (Salton, 1989).Messages with similar words are more likely tobe semantically-related.
This information is repre-sented by term frequency (TF).
However, thoseInform:INFInterpersonal:INTPCOMMQUESSpeechAct Request:REQACKCOMPCRTOBJSUPCANSCORRDESCELABSANSSUG211with more general terms may be unintentionallybiased when only TF is considered so InverseDocument Frequency (IDF) is introduced to miti-gate the bias.
The lexical similarity score can becalculated using their cosine similarity.
),(cos_ jil mmsimW =                      (3)For a given a speech act, SAij(mi?mj), connect-ing message mi and mj, the link generation functiong1 is defined as follows:)()(1lijij WarcSAg =                          (4)The new generated link is added to the threadgraph connecting message node mi and mj with aweight of Wl.4.2 Poster TrustworthinessMessages posted by different people may have dif-ferent degrees of trustworthiness.
For example,students who contributed to our corpus did notseem to provide messages of equal value.
To de-termine the trustworthiness of a person, we studiedthe responses to their messages throughout the en-tire corpus.
We used the percentage of POSITIVEresponses to a person?s messages to measure thatperson?s trustworthiness.
In our case, POSITIVEresponses, which are defined above, included SUP,COMP, and ACK.
In addition, if a person?s mes-sage closed a discussion, we rated it POSITIVE.Suppose the poster is represented by kperson ,the poster score, pW , is a weight calculated by))(())(_()(kkkppersonfeedbackcountpersonfeedbackpositivecountpersonW =(5)For a given single speech act, SAij(mi?mj), theposter score indicates the importance of messagemi by itself and the generation function is given by)()(2piiij WarcSAg =                               (6)The generated link is self-pointing, and containsthe strength of the poster information.4.3 Speech Act AnalysisWe compute the strength of each speech act in agenerative way, based on the author and trustwor-thiness of the author.
The strength of a speech actis a weighted average over all authors.
)()()()()( kPpersonpersons personWSAcountSAcountdirsignSAWkk?= (7)where the sign function of direction is defined withEquation 8.???
?=Otherwise     1NEGATIVE isdir  if     1)(dirsign                      (8)All SA scores are computed using Equation 7and projected to [0, 1].
For a given speech act,SAij(mi?mj), the generation function will generatea weighted link in the thread graph as expressed inEquation 9.????
?=Otherwise      )(NEUTRAL is  if      )()(3 sijijsiiij WarcSAWarcSAg     (9)The SA scores represent the strength of the rela-tionship between the messages.
Depending on thedirection of the SA, the generated link will eithergo from message mi to mj or from message mi to mi(i.e., to itself).
If the SA is NEUTRAL, the link willpoint to itself and the score is a recommendation toitself.
Otherwise, the link connects two differentmessages and represents the recommendation de-gree of the parent to the child message.5 Experiments5.1 Experimental SetupWe tested our conversation-focus detection ap-proach using a corpus of threaded discussions fromthree semesters of a USC undergraduate course incomputer science.
The corpus includes a total of640 threads consisting of 2214 messages, where athread is defined as an exchange containing at leasttwo messages.Length of thread Number of threads3 1394 745 476 307 138 11Table 2.
Thread length distribution.From the complete corpus, we selected onlythreads with lengths of greater than two and lessthan nine (messages).
Discussion threads withlengths of only two would bias the random guessof our baseline system, while discussion threadswith lengths greater than eight make up only 3.7%of the total number of threads (640), and are theleast coherent of the threads due to topic-switchingand off-topic remarks.
Thus, our evaluation corpusincluded 314 threads, consisting of 1307 messages,with an average thread length of 4.16 messages per212thread.
Table 2 gives the distribution of the lengthsof the threads.The input of our system requires the identifica-tion of speech act relations between messages.
Col-lective classification approaches, similar to thedependency-network based approach that Carvalhoand Cohen (2005) used to classify email speechacts, might also be applied to discussion threads.However, as the paper is about investigating howan SA analysis, along with other features, canbenefit conversation focus detection, so as to avoiderror propagation from speech act labeling to sub-sequent processing, we used manually-annotatedSA relationships for our analysis.Code Frequency Percentage (%)ACK 53 3.96CANS 224 16.73COMM 8 0.6COMP 7 0.52CORR 20 1.49CRT 23 1.72DESC 71 5.3ELAB 105 7.84OBJ 21 1.57QUES 450 33.61SANS 23 1.72SUG 264 19.72SUP 70 5.23Table 3.
Frequency of speech acts.The corpus contains 1339 speech acts.
Table 3gives the frequencies and percentages of speechacts found in the data set.
Each SA generates fea-ture-oriented weighted links in the threaded graphaccordingly as discussed previously.Number of bestanswersNumber of threads1 2502 563 54 3Table 4.
Gold standard length distribution.We then read each thread and choose the mes-sage that contained the best answer to the initialquery as the gold standard.
If there are multiplebest-answer messages, all of them will be rankedas best, i.e., chosen for the top position.
For exam-ple, different authors may have provided sugges-tions that were each correct for a specifiedsituation.
Table 4 gives the statistics of the num-bers of correct messages of our gold standard.We experimented with further segmenting themessages so as to narrow down the best-answertext, under the assumption that long messagesprobably include some less-than-useful informa-tion.
We applied TextTiling (Hearst, 1994) to seg-ment the messages, which is the technique used byZhou and Hovy (2005) to summarize discussions.For our corpus, though, the ratio of segments tomessages was only 1.03, which indicates that ourmessages are relatively short and coherent, and thatsegmenting them would not provide additionalbenefits.5.2 Baseline SystemTo compare the effectiveness of our approach withdifferent features, we designed a baseline systemthat uses a random guess approach.
Given a dis-cussion thread, the baseline system randomly se-lects the most important message.
The result wasevaluated against the gold standard.
The perform-ance comparisons of the baseline system and otherfeature-induced approaches are presented next.5.3 Result Analysis and DiscussionWe conducted extensive experiments to investigatethe performance of our approach with differentcombinations of features.
As we discussed in Sec-tion 4.2, each poster acquires a trustworthinessscore based on their behavior via an analysis of thewhole corpus.
Table 5 is a sample list of someposters with their poster id, the total number ofresponses (to their messages), the total number ofpositive responses, and their poster scores pW .PosterIDTotalResponsePositiveResponsepW193 1 1 193 20 18 0.938 15 12 0.880 8 6 0.7547 253 182 0.71922 3 2 0.66744 9 6 0.66791 6 4 0.667147 12 8 0.66732 10 6 0.6190 9 5 0.55697 20 11 0.5512 2 1 0.5Table 5.
Sample poster scores.213Based on the poster scores, we computed thestrength score of each SA with Equation 7 and pro-jected them to [0, 1].
Table 6 shows the strengthscores for all of the SAs.
Each SA has a differentstrength score and those in the NEGATIVE cate-gory have smaller ones (weaker recommendation).SA )(SAWs  SA )(SAWsCANS 0.8134 COMM 0.6534DESC 0.7166 ELAB 0.7202SANS 0.8281 SUG 0.8032QUES 0.6230ACK 0.6844 COMP 0.8081SUP 0.8057CORR 0.2543 CRT 0.1339OBJ 0.2405Table 6.
SA strength scores.We tested the graph-based HITS algorithm withdifferent feature combinations and set the error rateto be 0.0001 to get the algorithm to converge.
Inour experiments, we computed the precision scoreand the MRR (Mean Reciprocal Rank) score(Voorhees, 2001) of the most informative messagechosen (the first, if there was more than one).
Ta-ble 7 shows the performance scores for the systemwith different feature combinations.
The perform-ance of the baseline system is shown at the top.The HITS algorithm assigns both a hub scoreand an authority score to each message node, re-sulting in two sets of results.
Scores in the HITS_AUTHORITY rows of Table 7 represent the re-sults using authority scores, while HITS_HUBrows represent the results using hub scores.Due to the limitation of thread length, the lowerbound of the MRR score is 0.263.
As shown in thetable, a random guess baseline system can get aprecision of 27.71% and a MRR score of 0.539.When we consider only lexical similarity, theresult is not so good, which supports the notionthat in human conversation context is often moreimportant than text at a surface level.
When weconsider poster and lexical score together, the per-formance improves.
As expected, the best per-formances use speech act analysis.
More featuresdo not always improve the performance, for exam-ple, the lexical feature will sometimes decreaseperformance.
Our best performance produced aprecision score of 70.38% and an MRR score of0.825, which is a significant improvement over thebaseline?s precision score of 27.71% and its MRRscore of 0.539.Algorithm  &FeaturesCorrect(out of 314)Precision(%) MRRBaseline 87 27.71 0.539Lexical 65 20.70 0.524Poster 90 28.66 0.569SA 215 68.47 0.819Lexical +Poster 91 28.98 0.565Lexical +SA 194 61.78 0.765Poster +SA 221 70.38 0.825 HITS_AUTHORITYLexical +Poster +SA212 67.52 0.793Lexical 153 48.73 0.682Poster 79 25.16 0.527SA 195 62.10 0.771Lexical +Poster 158 50.32 0.693Lexical +SA 177 56.37 0.724Poster +SA 207 65.92 0.793HITS_HUBLexical +Poster +SA196 62.42 0.762Table 7.
System Performance Comparison.Another widely-used graph algorithm in IR isPageRank (Brin and Page, 1998).
It is used to in-vestigate the connections between hyperlinks inweb page retrieval.
PageRank uses a ?randomwalk?
model of a web surfer?s behavior.
The surferbegins from a random node mi and at each stepeither follows a hyperlink with the probability of d,or jumps to a random node with the probability of(1-d).
A weighted PageRank algorithm is used tomodel weighted relationships of a set of objects.The iterative updating expression is?
??
?+ +?=)()(1 )(*)1()(ijjkmBmjrmFmjkjiir mPRwwddmPR  (10)where r and r+1 are the numbers of iterations.We also tested this algorithm in our situation,but the best performance had a precision score ofonly 47.45% and an MRR score of 0.669.
It maybe that PageRank?s definition and modeling ap-proach does not fit our situation as well as theHITS approach.
In HITS, the authority and hub-214based approach is better suited to human conversa-tion analysis than PageRank, which only considersthe contributions from backward links of eachnode in the graph.6 Conclusions and Future WorkWe have presented a novel feature-enriched ap-proach for detecting conversation focus of threadeddiscussions for the purpose of answering studentqueries.
Using feature-oriented link generation anda graph-based algorithm, we derived a unifiedframework that integrates heterogeneous sourcesof evidence.
We explored the use of speech actanalysis, lexical similarity and poster trustworthi-ness to analyze discussions.From the perspective of question answering, thisis the first attempt to automatically answer com-plex and contextual discussion queries beyond fac-toid or definition questions.
To fully automatediscussion analysis, we must integrate automaticSA labeling together with our conversation focusdetection approach.
An automatic system will helpusers navigate threaded archives and researchersanalyze human discussion.Supervised learning is another approach to de-tecting conversation focus that might be explored.The tradeoff and balance between system perform-ance and human cost for different learning algo-rithms is of great interest.
We are also exploringthe application of graph-based algorithms to otherstructured-objects ranking problems in NLP so asto improve system performance while relievinghuman costs.AcknowledgementsThe work was supported in part by DARPA grant DOI-NBC Contract No.
NBCHC050051, Learning by Read-ing, and in part by a grant from the Lord CorporationFoundation to the USC Distance Education Network.The authors want to thank Deepak Ravichandran, FengPan, and Rahul Bhagat for their helpful suggestionswith the manuscript.
We would also like to thank theHLT-NAACL reviewers for their valuable comments.ReferencesAustin, J.
1962.
How to do things with words.
Cam-bridge, Massachusetts: Harvard Univ.
Press.Brin, S. and Page, L. 1998.
The anatomy of a large-scale hypertextual web search engine.
ComputerNetworks and ISDN Systems, 30(1-7):107--117.Carvalho, V.R.
and Cohen, W.W. 2005.
On the collec-tive classification of email speech acts.
In Proceed-ings of SIGIR-2005, pp.
345-352.Erkan, G. and Radev, D. 2004.
Lexrank: graph-basedcentrality as salience in text summarization.
Journalof Artificial Intelligence Research (JAIR).Feng, D., Shaw, E., Kim, J., and Hovy, E.H. 2006.
Anintelligent discussion-bot for answering student que-ries in threaded discussions.
In Proceedings of Intel-ligent User Interface (IUI-2006), pp.
171-177.Hearst, M.A.
1994.
Multi-paragraph segmentation ofexpository text.
In Proceedings of ACL-1994.Kleinberg, J.
1999.
Authoritative sources in a hyper-linked environment.
Journal of the ACM, 46(5).Kurland, O. and Lee L. 2005.
PageRank without hyper-links: Structural re-ranking using links induced bylanguage models.
In Proceedings of SIGIR-2005.Levinson, S. 1983.
Pragmatics.
Cambridge Univ.
Press.Mann, W.C. and Thompson, S.A. 1988.
Rhetoricalstructure theory: towards a functional theory of textorganization.
Text, 8 (3), pp.
243-281.Marom, Y. and Zukerman, I.
2005.
Corpus-based gen-eration of easy help-desk responses.
Technical Re-port, Monash University.
Available at:http://www.csse.monash.edu.au/publications/2005/tr-2005-166-full.pdf.Mihalcea, R. 2004.
Graph-based ranking algorithms forsentence extraction, applied to text summarization.
InCompanion Volume to ACL-2004.Mihalcea, R. 2005. unsupervised large-vocabulary wordsense disambiguation with graph-based algorithmsfor sequence data labeling.
In HLT/EMNLP 2005.Mihalcea, R. and Tarau, P. 2004.
TextRank: bringingorder into texts.
In Proceedings of EMNLP 2004.Mihalcea, R., Tarau, P. and Figa, E. 2004.
PageRank onsemantic networks, with application to word sensedisambiguation.
In Proceedings of COLING 2004.Otterbacher, J., Erkan, G., and  Radev, D. 2005.
Usingrandom walks for question-focused sentence re-trieval.
In Proceedings of HLT/EMNLP 2005.Pang, B. and Lee, L. 2004.
A sentimental education:sentiment analysis using subjectivity summarizationbased on minimum cuts.
In ACL-2004.Salton, G. 1989.
Automatic Text Processing, The Trans-formation, Analysis, and Retrieval of Information byComputer.
Addison-Wesley, Reading, MA, 1989.Searle, J.
1969.
Speech Acts.
Cambridge: CambridgeUniv.
Press.Soricut, R. and Marcu, D. 2003.
Sentence level dis-course parsing using syntactic and lexical informa-tion.
In Proceedings of HLT/NAACL-2003.Sporleder, C. and Lapata, M. 2005.
Discourse chunkingand its application to sentence compression.
In Pro-ceedings of HLT/EMNLP 2005.Voorhees, E.M. 2001.
Overview of the TREC 2001question answering track.
In TREC 2001.Zhou, L. and Hovy, E.H. 2005.
Digesting virtual ?geek?culture: the summarization of technical internet re-lay chats.
In Proceedings of ACL 2005.215
