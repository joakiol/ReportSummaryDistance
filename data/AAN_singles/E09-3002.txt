Proceedings of the EACL 2009 Student Research Workshop, pages 10?18,Athens, Greece, 2 April 2009. c?2009 Association for Computational LinguisticsA Memory-Based Approach to the Treatment of Serial Verb Constructionin Combinatory Categorial GrammarPrachya Boonkwan???
School of Informatics ?
National ElectronicsUniversity of Edinburgh and Computer Technology Center10 Crichton Street 112 Phahon Yothin Rd.Edinburgh EH8 9AB, UK Pathumthani 12120, ThailandEmail: p.boonkwan@sms.ed.ac.ukAbstractCCG, one of the most prominent grammarframeworks, efficiently deals with deletionunder coordination in natural languages.However, when we expand our attentionto more analytic languages whose degreeof pro-dropping is more free, CCG?s de-composition rule for dealing with gappingbecomes incapable of parsing some pat-terns of intra-sentential ellipses in serialverb construction.
Moreover, the decom-position rule might also lead us to over-generation problem.
In this paper thecomposition rule is replaced by the useof memory mechanism, calledCCG-MM.Fillers can be memorized and gaps can beinduced from an input sentence in func-tional application rules, while fillers andgaps are associated in coordination and se-rialization.
Multimodal slashes, which al-low or ban memory operations, are utilizedfor ease of resource management.
As aresult, CCG-MM is more powerful thancanonical CCG, but its generative powercan be bounded by partially linear indexedgrammar.1 IntroductionCombinatory Categorial Grammar (CCG, Steed-man (2000)) is a prominent categorial grammarframework.
Having a strong degree of lexical-ism (Baldridge and Kruijff, 2003), its grammarsare encoded in terms of lexicons; that is, each lex-icon is assigned with syntactic categories whichdictate the syntactic derivation.
One of its strik-ing features is the combinatory operations that al-low coordination of incomplete constituents.
CCGis nearly context-free yet powerful enough fornatural languages as it, as well as TAG, LIG,and HG, exhibits the lowest generative power inthe mildly context-sensitive grammar class (Vijay-Shanker and Weir, 1994).CCG accounts for gapping in natural languagesas a major issue.
Its combinatory operations re-solve deletion under coordination, such as right-node raising (SV&SVO) and gapping (SVO&SO).In case of gapping, a specialized rule called de-composition is used to handle with forward gap-ping (Steedman, 1990) by extracting the filler re-quired by a gap from a complete constituent.However, serial verb construction is a challeng-ing topic in CCG when we expand our attentionto more analytic languages, such as Chinese andThai, whose degree of pro-dropping is more free.In this paper, I explain how we can deal withserial verb construction with CCG by incorpo-rating memory mechanism and how we can re-strict the generative power of the resulted hy-brid.
The integrated memory mechanism is mo-tivated by anaphoric resolution mechanism in Cat-egorial Type Logic (Hendriks, 1995; Moortgat,1997), Type Logical Grammar (Morrill, 1994;Ja?ger, 1997; Ja?ger, 2001; Oehrle, 2007), and CCG(Jacobson, 1999), and gap resolution in Memory-Inductive Categorial Grammar (Boonkwan andSupnithi, 2008), as it is designed for associatingfillers and gaps found in an input sentence.
Theo-retically, I discuss how this hybrid efficiently helpsus deal with serial verb construction and how farthe generative power grows after incorporating thememory mechanism.Outline: I introduce CCG in ?2, and then mo-tivate the need of memory mechanism in dealingwith serial verb construction in CCG in ?3.
I de-scribe the hybrid model of CCG and the filler-gapmemory in ?4.
I then discuss the margin of gener-ative power introduced by the memory mechanismin ?5.
Finally, I conclude this paper in ?6.102 Combinatory Categorial GrammarCCG is a lexicalized grammar; i.e.
a grammar isencoded in terms of lexicons assigned with oneor more syntactic categories.
The syntactic cat-egories may be atomic elements or curried func-tions specifying linear directions in which theyseek their arguments.
A word is assigned with asyntactic category by the turnstile operator `.
Forexample, a simplified English CCG is given below.
(1) John ` np sandwiches ` npeats ` s\np/npThe categories X\Y (and X/Y) denotes that X seeksthe argument Y from the left (right) side.Combinatory rules are used to combine wordsforming a derivation of a sentence.
For basiccombination, forward (>) and backward (<) func-tional applications, defined in (2), are used.
(2) X/Y Y ?
X [>]Y X\Y ?
X [<]We can derive the sentence John eats sandwichesby the rules and the grammar in (1) as illustratedin (3).
CCG is semantic-transparent; i.e.
a logicalform can be built compositionally in parallel withsyntactic derivation.
However, semantic interpre-tation is suppressed in this paper.
(3) John eats sandwichesnp s\np/np nps\npsFor coordination of two constituents, the coor-dination rules are used.
There are two types ofcoordination rules regarding their directions: for-ward coordination (> &) and backward coordina-tion (< &), defined in (4).
(4) & X ?
[X]& [> &]X [X]& ?
X [< &]By the coordination rules, we can derive the sen-tence John eats sandwiches and drinks coke in (5).
(5) John eats sandwiches and drinks cokenp s\np/np np & s\np/np np> >s\np s\np>&[s\np]&<&s\np<sBeyond functional application and coordina-tion, CCG also makes use of rules motivated bycombinators in combinatory logics: functionalcomposition (B), type raising (T), and substitution(S), namely.
Classified by directions, the func-tional composition and type raising rules are de-scribed in (6) and (7), respectively.
(6) X/Y Y/Z ?
X/Z [> B]Y\Z X\Y ?
X\Z [< B](7) X ?
Y/(Y\X) [> T]X ?
Y\(Y/X) [< T]These rules permit associativity in derivation re-sulting in that coordination of incomplete con-stituents with similar types is possible.
For ex-ample, we can derive the sentence John likes butMary dislikes sandwiches in (8).
(8) John likes but Mary dislikes sandwichesnp s\np/np & np s\np/np np>T >Ts/(s\np) s/(s\np)>B >Bs/np s/np>&[s/np]&<&s/np>sCCG also allows functional composition withpermutation called disharmonic functional com-position to handle constituent movement such asheavy NP shift and dative shift in English.
Theserules are defined in (9).
(9) X/Y Y\Z ?
X\Z [> B?
]Y/Z X\Y ?
X/Z [< B?
]By disharmonic functional composition rules,we can derive the sentence I wrote briefly a longstory of Sinbad as (10).
(10) I wrote briefly a long story of Sinbadnp s\np/np s\np\(s\np) np>B?s\np/np>np<sTo handle the gapping coordination SVO&SO,the decomposition rule was proposed as a separatemechanism from CCG (Steedman, 1990).
It de-composes a complete constituent into two parts forbeing coordinated with the other incomplete con-stituent.
The decomposition rule is defined as fol-lows.
(11) X ?
Y X\Y [D]where Y and X\Ymust be seen earlier in the deriva-tion.
The decomposition rule allows us to de-rive the sentence John eats sandwiches, and Mary,noodles as (12).
Steedman (1990) stated that En-glish is forward gapping because gapping always11takes place at the right conjunct.
(12) John eats sandwiches and Mary noodlesnp s\np/np np & np np> >T <Ts\np s/VP VP\(VP/np)< >B?s s\(VP/np)D >&VP/np s\(VP/np) [s\(VP/np)]&<&s\(VP/np)<swhere VP = s\np.A multimodal version of CCG (Baldridge,2002; Baldridge and Kruijff, 2003) restricts gener-ative power for a particular language by annotatingmodalities to the slashes to allow or ban specificcombinatory operations.
Due to the page limita-tion, the multimodal CCG is not discussed here.3 Dealing with Serial Verb ConstructionCCG deals with deletion under coordination byseveral combinatory rules: functional composi-tion, type raising, disharmonic functional compo-sition, and decomposition rule.
This enables CCGto handle a number of coordination patterns suchas SVO&VO, SV&SVO, and SVO&SO.
However,the decomposition rule cannot solve some patternsof SVC in analytic languages such as Chinese andThai in which pro-dropping is prevalent.The notion serial verb construction (SVC) inthis paper means a sequence of verbs or verbphrases concatenated without connectives in a sin-gle clause which expresses simultaneous or con-secutive events.
Each of the verbs is marked or un-derstood to have the same grammatical categories(such as tense, aspect, and modality), and sharesat least one argument, i.e.
a grammatical subject.As each verb is tensed, SVC is considered as coor-dination with implicit connective rather than sub-ordination in which either infinitivization or sub-clause marker is made use.
Motivated by Li andThompson (1981)?s generalized form of ChineseSVC, the form of Chinese and Thai SVC is gener-alized in (13).
(13) (Subj)V1(Obj1)V2(Obj2) .
.
.Vn(Objn)The subject Subj and any objects Obji of the verbVi can be dropped.
If the subject or one of the ob-jects is not dropped, it will be understood as lin-early shared through the sequence.
Duplication ofobjects in SVC is however questionable as it dete-riorates the compactness of utterance.In order to deal with SVC in CCG, I consideredit syntactically similar to coordination where theconnective is implicit.
The serialization rule (?
)was initially defined by imitating the forward co-ordination rule in (14).
(14) X ?
[X]& [?
]This rule allows us to derive by CCG some typesof SVC in Chinese and Thai as exemplified in (15)and (16), respectively.
(15) wo?Izhe?foldzh??paperzuo`makey?
?onegeCLhe?zibox?I fold paper to make a box.?
(16) khaoher:phurryVNrunkha:mcrossth anonroad?He hurriedly runs across the road.
?One can derive the sentence (15) by consideringzhe?
?fold?
and zuo` ?make?
as s\np/np and ap-plying the serialization rule in (14).
In (16), thederivation can be done by assigning r:p ?hurry?and VN ?run?
as s\np, and kha:m ?cross?
ass\np/np.Since Chinese and Thai are pro-drop languages,they allow some arguments of the verbs to be pro-dropped, particularly in SVC.
For example, let usconsider the following Thai sentence.
(17) kla:Klap	ajgoDIRt	a:mfollowV1ha:seekV2n	ajinraj;POicane-fieldtc	@:findV3l	a:jLaaytc aFUTd	@:nwalkV4tc a:kleaveV5p	ajgoDIRLit: ?Kla goes out, he follows Laay (his cow), heseeks it in the cane field, and he finds that it willwalk away.
?Sem: ?Kla goes out to seek Laay in the cane fieldand he finds that it is about to walk away.
?The sentence in (17) are split into two SVCs: theseries of V1 to V3 and the series of V4 to V5, be-cause they do not share their tenses.
The direc-tional verb p	aj ?go?
performs as an adverb identi-fying the outward direction of the action.Syntactically speaking, there are two possibleanalyses of this sentence.
First, we can considerthe SVC V4 to V5 as a complement of the SVCV1 to V3.
Pro-drops occur at the object positionsof the verbs V1, V2, and V3.
On the other hand,we can also consider the SVC V1 to V3 and theSVC V4 to V5 as adjoining construction (Muan-suwan, 2002) which indicates resultative events inThai (Thepkanjana, 1986) as exemplified in (18).
(18) p t Pitit	:hitN	u:snaket okfallna:mwater?Piti hits a snake and it falls into the water.
?12In this case, the pro-drop occurs at the subject po-sition of the SVC V4 to V5, and can thereforebe treated as object control (Muansuwan, 2002).However, the sentence in (17) does not show resul-tative events.
I then assume that the first analysisis correct and will follow it throughout this paper.We have consequently reached the question thatthe verb tc	@: ?find?
should exhibit object controlby taking two arguments for the object and theVP complementary, or it should take the entiresentence as an argument.
To explicate the prolif-eration of arguments in SVC, we prefer the firstchoice to the second one; i.e.
the verb tc	@: ?find?
ispreferably assigned as s\np/(s\np)/np.
In (17),the object l	a:j ?Laay?
is dropped from the verbs V1and V2 but appears as one of V3?s arguments.Let us take a closer look on the CCG analysisof (17).
It is useful to focus on the SVCs of theverbs V1-V2 and V3.
It is shown below that thedecomposition rule fails to parse the tested sen-tence through its application illustrated in (19).
(19) Kla go follow seek find Laay FUT walkin cane-field leave gonp s\np/np s\np/(s\np)/np np s\np>s\np/(s\np)>s\npD?
?
?
?
?The verbs V1 and V2 are transitive and assignedas s\np/np, while V4 and V5 are intransitive andassigned as s\np.
From the case (19), it followsthat the decomposition rule cannot capture somepatterns of intra-sentential ellipses in languageswhose degree of pro-dropping is more free.
Bothtypes of intra-sentential ellipses which are preva-lent in SVC of analytic languages should be cap-tured for the sake of applicability.The use of decomposition rule in analytic lan-guages is not appealing for two main reasons.First, the decomposition rule does not support cer-tain patterns of intra-sentential ellipses which areprevalent in analytic languages.
As exemplifiedin (19), the decomposition rule fails to parse theThai SVC whose object of the left conjunct is pro-dropped, since the right conjunct cannot be de-composed by (11).
To tackle a broader coverage ofintra-sentential ellipses, the grammar should relyon not only decomposition but also a supplementmemory mechanism.
Second, the decompositionrule allows arbitrary decomposition which leads toover-generation.
From their definitions the vari-able Y can be arbitrarily substituted by any syn-tactic categories resulting in ungrammatical sen-tences generated.
For example we can derive theungrammatical sentence *Mary eats noodles andquickly by means of the decomposition rule in(20).
(20) * Mary eats noodles and quicklynp s\np/np np & s\np\(s\np)> >&s\np [s\np\(s\np)]&Ds\np s\np\(s\np)<&s\np\(s\np)<s\np<sThe issues of handling ellipses in SVC andovergeneration of the decomposition rule can beresolved by replacing the decomposition rule witha memory mechanism that associates fillers totheir gaps.
The memory mechanism also makesgrammar rules more manageable because it ismore straightforward to identify particular syn-tactic categories allowed or banned from pro-dropping.
I will show how the memory mecha-nism improves the CCG?s coverage of serial verbconstruction in the next section.4 CCG with Memory Mechanism(CCG-MM)As I have elaborated in the last section, CCGneeds a memory mechanism (1) to resolve intra-sentential ellipses in serial verb construction of an-alytic languages, and (2) to improve resource man-agement for over-generation avoidance.
To do so,such memory mechanism has to extend the gener-ative power of the decomposition rule and improvethe ease of resource management in parallel.The memory mechanism used in this paper ismotivated by a wide range of previous work fromcomputer science to symbolic logics.
The notionof memory mechanism in natural language pars-ing can be traced back to HOLD registers in ATN(Woods, 1970) in which fillers (antecedents) areheld in registers for being filled to gaps foundin the rest of the input sentence.
These regis-ters are too powerful since they enable ATN torecognize the full class of context-sensitive gram-mars.
In Type Logical Grammar (TLG) (Morrill,1994; Ja?ger, 1997; Ja?ger, 2001; Oehrle, 2007),Gentzen?s sequent calculus was incorporated withvariable quantification to resolve pro-forms andVP ellipses to their antecedents.
The variablequantification in TLG is comparable to the useof memory in storing antecedents and anaphora.13In Categorial Type Logic (CTL) (Hendriks, 1995;Moortgat, 1997), gap induction was incorporated.Syntactic categories were modified with modal-ities which permit or prohibit gap induction inderivation.
However, logical reasoning obtainedfrom TLG and CTL are an NP-complete prob-lem.
In CCG, Jacobson (1999) attempted to ex-plicitly denote non-local anaphoric requirementwhereby she introduced the anaphoric slash (|) andthe anaphoric connective (Z) to connect anaphorsto their antecedents.
However, this frameworkdoes not support anaphora whose argument isnot its antecedent, such as possessive adjectives.Recently, a filler-gap memory mechanism wasagain introduced to Categorial Grammar, calledMemory-Inductive Categorial Grammar (MICG)(Boonkwan and Supnithi, 2008).
Fillers and gaps,encoded as memory modalities, are modified tosyntactic categories, and they are associated by thegap-resolution connective when coordination andserialization take place.
Though their frameworkis successful in resolving a wide variety of gap-ping, its generative power falls between LIG andIndexed Grammar, theoretically too powerful fornatural languages.The memory mechanism introduced in this pa-per deals with fillers and gaps in SVC.
It is similarto anaphoric resolution in ATN, Jacobson?s model,TLG, and CTL.
However, it also has prominentdistinction from them: The anaphoric mechanismsmentioned earlier are dealing with unbounded de-pendency or even inter-sentential ellipses, whilethe memory mechanism in this paper is dealingonly with intra-sentential bounded dependency inSVC as generalized in (13).
Moreover, choices offiller-gap association can be pruned out by the useof combinatory directionality because the word or-der of analytic languages is fixed.
It is notice-able that we can simply determine the grammat-ical function (subject or object) of arbitrary np?sin (13) from the directionality (the subject on theleft and the object on the right).
With these rea-sons, I therefore adapted the notions of MICG?smemory modalities and gap-resolution connective(Boonkwan and Supnithi, 2008) for the backboneof the memory mechanism.In CCG with Memory Mechanism (CCG-MM),syntactic categories are modalized with memorymodalities.
For each functional application, asyntactic category can be stored, or memorized,into the filler storage and the resulted category ismodalized with the filler 2.
A syntactic categorycan also be induced as a gap in a unary deriva-tion called induction and the resulted category ismodalized with the gap 3.There are two constraint parameters in eachmodality: the combinatory directionality d ?
{<,>} and the syntactic category c, resulting in thefiller and the gap denoted in the forms 2dc and 3dc ,respectively.
For example, the syntactic category2<np3>nps has a filler of type np on the left side anda gap of type np on the right side.The filler 2dc and the gap 3dc of the same di-rectionality and syntactic categories are said to besymmetric under the gap-resolution connective ?
;that is, they are matched and canceled in the gapresolution process.
Apart from MICG, I restrictthe associative power of ?
to match only a fillerand a gap, not between two gaps, so that the gener-ative power can be preserved linear.
This topic willbe discussed in ?5.
Given two strings of modali-ties m1 and m2, the gap-resolution connective ?is defined in (21).
(21) 2dcm1 ?3dcm2 ?
m1 ?m23dcm1 ?
2dcm2 ?
m1 ?m2?
 ?
The notation  denotes an empty string.
It meansthat a syntactic category modalized with an emptymodality string is simply unmodalized; that is, anymodalized syntactic categories X are equivalent tothe unmodalized ones X.Since the syntactic categories are modalized bya modality string, all combinatory operations incanonical CCG must preserve the modalities af-ter each derivation step.
However, there are twoconditions to be satisfied:Condition A: At least one operands of functionalapplication must be unmodalized.Condition B: Both operands of functional com-position, disharmonic functional composi-tion, and type raising must be unmodalized.Both conditions are introduced to preserve thegenerative power of CCG.
This topic will be dis-cussed in ?5.As adopted from MICG, there are two memoryoperations: memorization and induction.Memorization: a filler modality is pushed tothe top of the memory when an functional appli-cation rule is applied, where the filler?s syntacticcategory must be unmodalized.
Let m be a modal-14ity string, the memorization operation is defined in(22).
(22) X/Y mY ?
2<X/YmX [> MF ]mX/Y Y ?
2>Y mX [> MA]Y mX\Y ?
2<Y mX [< MA]mY X\Y ?
2>X\YmX [< MF ]Induction: a gap modality is pushed to the topof the memory when a gap of such type is inducedat either side of the syntactic category.
Let m be amodality string, the induction operation is definedin (23).
(23) mX/Y ?
3>Y mX [> IA]mY ?
3<X/YmX [> IF ]mX\Y ?
3<Y mX [< IA]mY ?
3>X\YmX [< IF ]Because the use of memory mechanism eluci-dates fillers and gaps hidden in the derivation, wecan then replace the decomposition rule of thecanonical CCG with the gap resolution process ofMICG.
Fillers and gaps are associated in the co-ordination and serialization by the gap-resolutionconnective ?.
For any given m1,m2, if m1 ?
m2exists then always m1 ?
m2 ?
.
Given twomodality strings m1 and m2 such that m1 ?
m2exists, the coordination rule (?)
and serializationrule (?)
are redefined on ?
in (24).
(24) m1X & m2X ?
X [?
]m1X m2X ?
X [?
]At present, the memory mechanism was devel-oped in Prolog for the sake of unification mecha-nism.
Each induction rule is nondeterministicallyapplied and variables are sometimes left uninstan-tiated.
For example, the sentence in (12) can beparsed as illustrated in (25).
(25) John eats sandwiches and Mary noodlesnp s\np/np np & np np>MF >IF2<s\np/nps\np 3<X1/npX1< <2<s\np/nps 3<X2\np/npX2?sLet us consider the derivation in the right conjunct.The gap induction is first applied on np resultingin 3<X1/npX1, where X1 is an uninstantiated vari-able.
Then the backward application is applied, sothat X1 is unified with X2\np.
Finally, the leftand the right conjuncts are coordinated yieldingthat X2 is unified with s and X1 with s\np.
Forconvenience of type-setting, let us suppose that wecan always choose the right type in each inductionstep and suppress the unification process.Table 1: Slash modalities for memory operations.- Left + Left- Right ?
/+ Right .
?Once we instantiate X1 and X2, the derivationobtained in (25) is quite more straightforward thanthe derivation in (12).
The filler eats is intro-duced on the left conjunct, while the gap of types\np/np is induced on the right conjunct.
The co-ordination operation associates the filler and thegap resulting in a complete derivation.A significant feature of the memory mechanismis that it handles all kinds of intra-sentential el-lipses in SVC.
This is because the coordinationand serialization rules allow pro-dropping in ei-ther the left or the right conjunct.
For example, theintra-sentential ellipses pattern in Thai SVC illus-trated in (19) can be derived as illustrated in (26).
(26) Kla go follow seek find Laay FUT walkin cane-field leave gonp s\np/np s\np/(s\np)/np np s\np>IA >MA3>nps\np 2>nps\np/(s\np)>2>nps\np?s\np<sBy replacing the decomposition rule with thememory mechanism, CCG accepts all patterns ofpro-dropping in SVC.
It should also be noted thatthe derivation in (20) is per se prohibited by thecoordination rule.Similar to canonical CCG, CCG-MM is alsoresource-sensitive; that is, each combinatory op-eration is allowed or prohibited with respect to theresource we have (Baldridge and Kruijff, 2003).Baldridge (2002) showed that we can obtain acleaner resource management in canonical CCGby the use of modalized slashes to control combi-natory behavior.
His multimodal schema of slashpermissions can also be applied to the memorymechanism in much the same way.
I assume thatthere are four modes of memory operations ac-cording to direction and allowance of memory op-erations as in Table 1.The modes can be organized into the type hier-archy shown in Figure 1.
The slash modality ?,the most limited mode, does not allow any mem-ory operations on both sides.
The slash modalities/ and .
allow memorization and induction on the15????????/???????
?.?Figure 1: Hierarchy of slash modalities for mem-ory operations.left and right sides, respectively.
Finally, the slashmodality ?
allows memorization and induction onboth sides.
In order to distinguish the memory op-eration?s slash modalities from Baldridge?s slashmodalities, I annotate the first as a superscriptand the second as a subscript of the slashes.
Forexample, the syntactic category s\/?np denotesthat s\np allows permutation in crossed functionalcomposition (?)
and memory operations on theleft side (/).
As with Baldridge?s multimodalframework, the slash modality ?
can be omittedfrom writing.
By defining the slash modalities, itfollows that the memory operations can be definedin (27).
(27) mX/.Y Y ?
2>Y mX [> MF ]X//Y mY ?
2<X//YmX [> MA]Y mX\/Y ?
2<Y mX [< MA]mY X\.Y ?
2>X\.YmX [< MF ]mX/.Y ?
3>Y mX [> IA]mY ?
3<X//YmX [> IF ]mX\/Y ?
3<Y mX [< IA]mY ?
3>X\.YmX [< IF ]When incorporating with the memory mech-anism and the slash modalities, CCG becomesflexible enough to handle all patterns of intra-sentential ellipses in SVC which are prevalent inanalytic languages, and to manage its lexical re-source.
I will now show that CCG-MM extendsthe generative power of the canonical CCG.5 Generative PowerIn this section, we will informally discuss the mar-gin of generative power introduced by the memorymechanism.
Since Vijay-Shanker (1994) showedthat CCG and Linear Indexed Grammar (LIG)(Gazdar, 1988) are weakly equivalent; i.e.
theygenerate the same sets of strings, we will firstcompare the CCG-MM with the LIG.
As will beshown, its generative power is beyond LIG; wewill find the closest upper bound in order to locateit in the Chomsky?s hierarchy.We will follow the equivalent proof of Vijay-Shanker and Weir (1994) to investigate the gen-erative power of CCG-MM.
Let us first assumethat we are going to construct an LIG G =(VN , VT , VS , S, P ) that subsumes CCG-MM.
Toconstruct G, let us define each of its component asfollows.VN is a finite set of syntactic categories,VT is a finite set of terminals,VS is a finite set of stack symbols having the form2dc , 3dc , /c, or \c,S ?
VN is the start symbol, andP is a finite set of productions, having the formA[] ?
aA[?
?
l] ?
A1[] .
.
.
Ai[?
?
l?]
.
.
.
An[]where each Ak ?
VN , d ?
{<,>}, c ?
VN ,l, l?
?
VS , and a ?
VT ?
{}.The notation for stacks uses [?
?
l] to denote an ar-bitrary stack whose top symbol is l. The linearityof LIG comes from the fact that in each produc-tion there is only one daughter that share the stackfeatures with its mother.
Let us also define ?(?
)as the homomorphic function that converts eachmodality in a modality string ?
into its symmetriccounterpart, i.e.
a filler 2dc into a gap3dc , and viceversa.
The stack in this LIG is used for storing(1) tailing slashes of a syntactic category for har-monic/disharmonic functional composition rules,and (2) modalities of a syntactic category for gapresolution.We start out by transforming the lexical item.For every lexical item of the formw ` Xwhere X isa syntactic category, add the following productionto P :(28) X[] ?
wWe add two unary rules for converting betweentailing slashes and stack values.
For every syntac-tic category X and Y1, .
.
.
, Yn, the following rulesare added.
(29) X|1Y1 .
.
.
|nYn[??]
?
X[?
?
|1Y1 .
.
.
|nYn]X[?
?
|1Y1 .
.
.
|nYn] ?
X|1Y1 .
.
.
|nYn[??
]where the top of ??
must be a filler or a gap, or??
must be empty.
This constraint preserves theordering of combinatory operations.We then transform the functional applicationrules into LIG productions.
From Condition A,we can generalize the functional application rulesin (2) as follows.16(30) mX/Y Y ?
mXX/Y mY ?
mXmY X\Y ?
mXY mX\Y ?
mXwhere m is a modality string.
Condition A pre-serves the linearity of the generative power in thatit prevents the functional application rules from in-volving the two stacks of the daughters at once.We can convert the rules in (30) into the followingproductions.
(31) X[??]
?
X[?
?
/Y] Y[]X[??]
?
X[/Y] Y[??]X[??]
?
Y[??]
X[\Y]X[??]
?
Y[] X[?
?
\Y]We can generalize the harmonic and dishar-monic, forward and backward composition rulesin (6) and (9) as follows.
(32) X/Y Y|1Z1 .
.
.
|nZn ?
X|1Z1 .
.
.
|nZnY|1Z1 .
.
.
|nZn X\Y ?
X|1Z1 .
.
.
|nZnwhere each |i ?
{\, /}.
By Condition B, we ob-tain that all operands are unmodalized so that wecan treat only tailing slashes.
That is, ConditionB prevents us from processing both tailing slashesand memory modalities at once where the linear-ity of the rules is deteriorated.
We can thereforeconvert these rules into the following productions.
(33) X[??]
?
X[/Y] Y[??]X[??]
?
Y[??]
X[\Y]The memorization and induction rules de-scribed in (27) are transformed into the followingproductions.
(34) X[?
?
2<X/Y] ?
X[/Y] Y[??]X[?
?
2>Y ] ?
X[?
?
/Y] Y[]X[?
?
2<Y ] ?
Y[] X[?
?
\Y]X[?
?
2>X\Y] ?
Y[??]
X[\Y]X[?
?3>Y ] ?
X[?
?
/Y]X[?
?3<X/Y] ?
Y[??]X[?
?3<Y ] ?
X[?
?
\Y]X[?
?3>X\Y] ?
Y[??
]However, it is important to take into account thecoordination and serialization rules, because theyinvolve two stacks which have similar stack val-ues if we convert one of them into the symmetricform with ?.
Those rules can be transformed asfollows.
(35) X[] ?
X[??]
&[] X[?(??
)]X[] ?
X[??]
X[?(??
)]It is obvious that the rules in (35) are not LIG pro-duction; that is, CCG-MM cannot be generated byany LIGs; or more precisely, CCG-MM is prop-erly more powerful than CCG.
We therefore haveto find an upper bound of its generative power.Though CCG-MM is more powerful than CCGand LIG, the rules in (35) reveal a significant prop-erty of Partially Linear Indexed Grammar (PLIG)(Keller and Weir, 1995), an extension of LIGwhose productions are allowed to have two ormore daughters sharing stack features with eachother but these stacks are not shared with theirmother as shown in (36).
(36) A[] ?
A1[] .
.
.
Ai[??]
.
.
.
Aj [??]
.
.
.
An[]Whereby restricting the power of the gap-resolution connective, the two stacks of the daugh-ters are shared but not with their mother.
An in-teresting trait of PLIG is that it can generate thelanguage {wk|w is in a regular language and k ?N}.
This is similar to the pattern of SVC in whicha series of verb phrase can be reduplicated.To conclude this section, CCG-MM is morepowerful than LIG but less powerful than PLIG.From (Keller and Weir, 1995), we can position theCCG-MM in the Chomsky?s hierarchy as follows:CFG < CCG = TAG = HG = LIG < CCG-MM ?
PLIG?
LCFRS < CSG.6 Conclusion and Future WorkI have presented an approach to treating serialverb construction in analytic languages by incor-porating CCG with a memory mechanism.
In thememory mechanism, fillers and gaps are storedas modalities that modalize a syntactic category.The fillers and the gaps are then associated in thecoordination and the serialization rules.
This re-sults in a more flexible way of dealing with intra-sentential ellipses in SVC than the decompositionrule in canonical CCG.
Theoretically speaking, theproposed memory mechanism increases the gen-erative power of CCG into the class of partiallylinear indexed grammars.Future research remains as follows.
First, I willinvestigate constraints that reduce the search spaceof parsing caused by gap induction.
Second, I willapply the memory mechanism in solving discon-tinuous gaps.
Third, I will then extend this frame-work to free word-ordered languages.
Fourth andfinally, the future direction of this research is todevelop a wide-coverage parser in which statisticsis also made use to predict memory operations oc-curing in derivation.17ReferencesJason Baldridge and Geert-Jan M. Kruijff.
2003.
Mul-timodal combinatory categorial grammar.
In Pro-ceedings of the 10th Conference of the EuropeanChapter of the ACL 2003, pages 211?218, Budapest,Hungary.Jason Baldridge.
2002.
Lexically Specified Deriva-tional Control in Combinatory Categorial Gram-mar.
Ph.D. thesis, University of Edinburgh.Prachya Boonkwan and Thepchai Supnithi.
2008.Memory-inductive categorial grammar: An ap-proach to gap resolution in analytic-language trans-lation.
In Proceedings of The Third InternationalJoint Conference on Natural Language Processing,volume 1, pages 80?87, Hyderabad, India, January.Gerald Gazdar.
1988.
Applicability of indexedgrammars to natural languages.
In U. Reyle andC.
Rohrer, editors, Natural Language Parsing andLinguistic Theories, pages 69?94.
Reidel, Dor-drecht.Petra Hendriks.
1995.
Ellipsis and multimodal catego-rial type logic.
In Proceedings of Formal GrammarConference, pages 107?122.
Barcelona, Spain.Pauline Jacobson.
1999.
Towards a variable-free se-mantics.
Linguistics and Philosophy, 22:117?184,October.Gerhard Ja?ger.
1997.
Anaphora and ellipsis in type-logical grammar.
In Proceedings of the 11th Amster-dam Colloquium, pages 175?180, Amsterdam, theNetherland.
ILLC, Universiteit van Amsterdam.Gerhard Ja?ger.
2001.
Anaphora and quantificationin categorial grammar.
In Lecture Notes in Com-puter Science; Selected papers from the 3rd Interna-tional Conference, on logical aspects of Computa-tional Linguistics, volume 2014/2001, pages 70?89.Bill Keller and David Weir.
1995.
A tractable exten-sion of linear indexed grammars.
In In Proceedingsof the 7th European Chapter of ACL Conference.Charles N. Li and Sandra A. Thompson.
1981.
Man-darin Chinese: A Functional Reference Grammar.Berkeley: University of California Press.Michael Moortgat.
1997.
Categorial type logics.
Invan Benthem and ter Meulen, editors, Handbook ofLogic and Language, chapter 2, pages 163?170.
El-sevier/MIT Press.Glyn Morrill.
1994.
Type logical grammar.
In Catego-rial Logic of Signs.
Kluwer, Dordrecht.Nuttanart Muansuwan.
2002.
Verb Complexes in Thai.Ph.D.
thesis, University at Buffalo, The State Uni-versity of New York.Richard T. Oehrle, 2007.
Non-Transformational Syn-tax: A Guide to Current Models, chapter Multi-modal Type Logical Grammar.
Oxford: Blackwell.Mark Steedman.
1990.
Gapping as constituent coordi-nation.
Linguistics and Philosophy, 13:207?263.Mark Steedman.
2000.
The Syntactic Process.
TheMIT Press, Cambridge, Massachusetts.Kingkarn Thepkanjana.
1986.
Serial Verb Construc-tions in Thai.
Ph.D. thesis, University of Michigan.K.
Vijay-Shanker and David J. Weir.
1994.
The equiv-alence of four extensions of context-free grammars.Mathematical Systems Theory, 27(6):511?546.William A.
Woods.
1970.
Transition network gram-mars for natural language analysis.
Communica-tions of the ACM, 13(10):591?606, October.18
