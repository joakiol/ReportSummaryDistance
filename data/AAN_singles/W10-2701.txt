Proceedings of the 2010 Workshop on Companionable Dialogue Systems, ACL 2010, pages 1?6,Uppsala, Sweden, 15 July 2010. c?2010 Association for Computational LinguisticsEpisodic Memory for Companion DialogueGregor SieberOFAIVienna, Austriagregor.sieber@ofai.atBrigitte KrennOFAIVienna, Austriabrigitte.krenn@ofai.atAbstractWe present an episodic memory compo-nent for enhancing the dialogue of artifi-cial companions with the capability to re-fer to, take up and comment on past in-teractions with the user, and to take intoaccount in the dialogue long-term userpreferences and interests.
The proposedepisodic memory is based on RDF repre-sentations of the agent?s experiences andis linked to the agent?s semantic memorycontaining the agent?s knowledge base ofontological data and information about theuser?s interests.1 IntroductionRecently, research on artificial companions hascome more and more in focus.
They are artifi-cial agents (virtual or robotic) that are intendedto support the human user in aspects of everydaylife.
They may range from virtual agents that as-sist their users in accessing information from theInternet in accordance with the users?
interests,preferences and needs (Skowron et al, 2008), upto assistive robots in home environments that sup-port elderly in mastering their life at home (Graf etal., 2009).
In the long run when developing com-panions, the goal is to model and implement arti-ficial ?caring developing helpers?
(Sloman, 2007)that learn and develop over time to be of long-termbenefit for the user.In order to come closer to the vision of artifi-cial companions a number of research issues needto be addressed such as: action-perception andlearning capabilities suitable to function with im-perfect sensors in dynamically changing environ-ments which can only be partially modelled; thedevelopment of affect sensing capabilities that ex-tend over the detection of basic emotions such asjoy, anger, fear, disgust etc.
(Ekman, 1992); usermodels that account for and adapt to the users?interests, preferences, affective states, needs andhandicaps; approaches to multimodal dialoguethat allow the agent?s mental models and mem-ories to be connected to its expressive behaviour(Castellano et al, 2008), and where natural lan-guage dialogue is semantically grounded (Benyonand Mival, 2008).
Companions need to be awareof their own history and past interactions with theirindividual users, so that the single user can believethat her/his companion knows ?what it is talkingabout?.
This is particularly important for creatingacceptable long?term interactions.To account for this kind of requirements, wepropose a communication component for com-panions where autobiographic episodic memory,semantic memory and dialogue are closely con-nected.
In our approach, input analysis is per-formed using information extraction techniques,that yield RDF triples describing the content of auser utterance in terms of the knowledge base (se-mantic memory) of the companion, and an utter-ance class describing the type of message (greet-ing, question, agreement, rejection, etc.).
Shortterm memory holds the current user utterance anda set of pointers to currently important and thusactivated parts of the companion?s knowledge.
Wedistinguish two parts of the long term memory: Se-mantic memory is composed of a knowledge basecontaining ontological data and a user model en-coding e.g.
elements of the ontology which theuser is especially interested in.
Episodic memoryis based on RDF representations of the agent?s ex-periences.
It contains utterances of the user andthe companion, and representations of the com-panion?s actions and their evaluation (for the caseswhere it is known).
The dialogue manager con-sists of a set of parallel, independent componentsfor the different queries on the episodic mem-ory described below and answer retrieval from theknowledge base.
Which component is finally used1is decided by a scoring mechanism in connectionwith a rule set.In the remainder of this contribution, we willconcentrate on the interplay between episodicmemory and dialogue.
In particular, we describehow the episodic memory is represented (sec.
2),how episodes are retrieved (sec.
3), and how nat-ural language output is generated from memorycontent (sec.
4).2 Episodic Memory RepresentationAn episodic memory component for companiondialogue needs to provide adequate knowledgerepresentation in connection with the cognitivemodel and the tasks of the agent.
RDF-based1 datastores are widely used for representing domainknowledge as well as common sense knowledge(e.g.
the Open Mind Common Sense Database2,or ConceptNet3).
Accordingly, we have developedan episodic memory component for artificial com-panions that stores episodes as RDF graphs.
Sinceboth memory, domain and common sense knowl-edge bases are composed of RDF triples, they areinteroperable and can be easily extended.
We usea Sesame4 repository for hosting the data stores.Episode encoding is automatic, since all userinput and its analysis is immediately transferredfrom short-term memory to episodic memory.Thus the agent is able to recall the same data froman episode that was available at the time of the ex-perience.For episode retrieval, a similarity matching al-gorithm is required that can find memories basedon similarity of the individuals and relations in-volved.
Thus, our retrieval mechanism neithertreats the RDF data as symbols in a similarity vec-tor ?
such as for a nearest?neighbour search ?, noras a graph matching problem, which often is tooslow for retrieval.
Both of these approaches donot take advantage of the RDF encoding of thedata, and as a consequence do not allow class orsuperclass information of individuals to be usedfor matching.Our approach is to query the RDF reposito-ries using a query language such as SeRQL andSPARQL.
While these query languages do not al-low a direct search for a similar graph, a set of1http://www.w3.org/RDF/2http://commons.media.mit.edu/en/3http://conceptnet.media.mit.edu/4http://www.openrdf.org/queries can be generated from a target episodemaking use of the full range of features of RDFand the query language.
The episode most similarto the input episode is then selected from the resultset by applying a heuristic.2.1 EpisodesIn our system, there are several types of episodeswhich share a set of basic parameters, each rep-resenting the different events and actions in theworld of the agent.The different sub-types of episodes are RDFsubclasses of the basic episode concept and con-tain specialised parameters applicable to the typeof action.Basic properties stored with each episode are:a) creation time of the episode and b) an episodeID property which is used to trace back or forwardthrough the episodes in (reverse) order of creation,to find the outcome and evaluation following anepisode retrieved from memory.
This is necessary,because triples in RDF are stored as graphs and notdatabase entries like in a relational database whichcould easily be ordered by a primary key.Action episodes are a subclass of episodesthat represent the actions the agent is capable of.These are:Answer from domain knowledge the agent mapsthe user?s question to a SeRQL query and evalu-ates the query against its domain knowledge base.Find similar interactions represents deliberateremembering, i.e.
actively searching for similarsituations.Pattern search allows the agent to check for aset of patterns in the behaviour of the user andits episodic memory which can be exploited fordialogue.Retrieve context is employed by the agent whenno other actions can be applied because parts ofthe utterance are missing.
The companion thensearches its memories to retrieve relevant contextof the dialogue.Send message to the user, which can eithercommunicate the results of a query, memoriesof the agent, statements based on results frompattern search, or details about the situation of theagent, which includes reporting errors.Input episodes store textual user input.
Theycontain the analysis of the user input which is anRDF description of the entities, classes and prop-2erties of the domain ontology contained in the ut-terance.
For example, the question ?When wasCharlie Parker born??
is classified as utteranceclass WH-Question, and its analysis is an RDFtriple with the ontology individual of class Artistrepresenting Charlie Parker, the property birth-Date, and a variable as the object since it is thisvalue the user wants to know.Evaluation episodes can be either positive ornegative.
They are crucial for the agent to be ableto learn from its past actions.
If an evaluation isavailable, the agent can decide based on its mem-ories whether a past solution should be repeated ornot.
Not all episodes have an evaluation.
Evalua-tion values can either come from direct user feed-back or internal feedback such as empty query re-sults or failure to retrieve a query result.In order to be able to find the right associationsand memories, the agent also needs to have an in-ternal notion of relative time that can be related tointeractions with the user.
As noted e.g.
by Bromand Lukavsky?
(2009) humans commonly do notuse exact times, but instead refer to fuzzy cate-gories.
Thus, our (application specific) time modelof the companion allows to differentiate betweenfour coarse times of day ?
morning, noon, after-noon, evening.
For events that are further in thepast, the model contains the categories of: today,yesterday, this week, this month, this year, lastyear.2.2 Episode DynamicsDue to available computing hardware and scalabletriple stores, the episodic memory component istechnically able to store a large amount of memo-ries.
But when the episode base grows too big, itbecomes increasingly difficult to retrieve episodeswithin an acceptable time limit due to the grow-ing number of search and comparison operationsrequired.
Thus the companion needs a mechanismof reducing the number of episodes in the mem-ory.
Generally, there are two approaches to this:episode blending and forgetting.Episode blending refers to a mechanism thatgroups similar experiences into one episode.
Lessimportant parameters of the memories are lost, andthe similarities strengthened.
This would mean theagent can remember what happened, and that ithappened more than once, but the exact situationsare lost.
Episode blending is an interesting aspectof episodic memory that will be pursued in our fu-ture work.Forgetting refers to the deletion of episodes.Ideally, the episodes with least utility to the com-panion should be deleted.
Nuxoll (2007) providesa list of possible approaches regarding forgetting:1) remove the oldest memory first, 2) remove theleast activated memory, 3) remove the most redun-dant memory, 4) memory decay.Approach 1) does not take the importance ofepisodes into account and may result in losing im-portant information.
Approaches 2) and 4) bothdepend on assigning activation values to episodes,and delete those with the least activation.
The ideaof 3) is to locate two memories that are very simi-lar to each other and remove one of them.Our initial strategy is to assign a time-stamp oflast retrieval to each episode, since we currentlydo not use activation values.
Episode removal canthen be regularly performed by issuing a SeRQLdelete statement for all episodes whose retrievaldate is older than a certain time, depending on thegrowth rate of the memory.Note that the removal process described abovestill bears the risk of losing important memories ofsituations that are very rarely encountered.
For ourdialogue application scenario, this risk might notseem too critical, yet it might be e.g.
for an agentin an artificial life environment where seldomlyoccurring enemies need to be recognised.
A pos-sible remedy would be the connection of episodicmemory with a model of emotion.
This would al-low the emotional intensity of a situation to be afactor in episode retrieval and deletion.3 Retrieval of Episodic MemoriesOne of the important aspects of any episodic mem-ory component is to retrieve the right memories.Since our episodic memory is realised usingRDF, a set of SeRQL queries is used for episoderetrieval.
Queries are processed in parallel.
Theconstruction of these queries depends on the typeof episode represented by the input situation.The following section describes our model fordeliberate retrieval for dialogue situations.
Thismeans that the companion actively chooses tosearch its memory for episodes of relevance.The current situation is characterised by a set offeatures, expressed in RDF data, that are extractedfrom short term memory: 1) the description of theuser utterance in terms of domain data, 2) the cur-rent time, 3) a list of entities in the user utterance3that are among the user?s preferred entities, if any.A query is issued representing the input situa-tion.
This means, we search the memory to see ifthe exact same situation has been encountered pre-viously.
Alternatively, queries using combinationsand subsets of the instance set and the set of rela-tions present in the user utterance are issued.
Forinstance, given a popular music gossipping sce-nario, if the user asks a question about MichaelJackson, Janet Jackson, and Tina Turner, the agentsearches its memory for previous episodes involv-ing the named artists and relations or subsets ofthose, in order to connect to and take up previousdiscussions.
Moreover, the structure of the domaindata is used for generating a query containing theclasses of the individuals in the utterance.
For ex-ample, an agent that has talked about the birth-day of any guitar player before, could relate a userquestion about the birthday of Joe Satriani to theprevious experience by knowing that he is a guitarplayer too, and use this knowledge in the ongoingdialogue.Queries related to classes can be iterated by fol-lowing up the superclass hierarchy until a resultis found.
The iteration stops either when there isno further superclass, or when the property underdiscussion is not a property of the superclass anymore.
For example, talking about the birthday ofan Artist, the companion looks for episodes aboutbirthdays involving its superclass Person, but notepisodes with its superclass Entity, since the classEntity has no birthday property.The most similar episode is selected fromthe result set by a heuristic which ranks thoseepisodes higher that resemble the input episodemore closely, so for example an episode that con-tains the same entities and the same properties asthe input episode is ranked higher than an episodethat contains a matching entity with a differentproperty, and so on.These content?driven retrieval strategies can beused to support the selection of the next dialoguemove, taking into account available evaluations ofsimilar past episodes.
Additionally to the content?driven mechanism of remembering, the compan-ion can also search its memories for recency- andpreference-driven patterns that can be used for dia-logue, such as the following examples.
In contrastto the mechanisms mentioned above, these opera-tions are automatically performed without requir-ing the agent?s initiative.Has the same question been discussed recently,or ever before?
The companion can make a com-ment to the user about this ?
either noting as triviathat the question has been asked a year ago, or re-acting annoyed if the user asks the same questionfor the fifth time within ten minutes.Is there a property in a user utterance that isamong the user?s interests?
Has this property beenasked for in the last 15 interactions?
For exam-ple, the user is very interested in the birth placesof artists.
The companion can use this informationin the following ways: a) for the next artist underdiscussion, automatically provide the birth placeto the user; b) the companion can comment on thefact that the property is part of the user interests;c) the companion can ask the user whether shewould like to know the birthplace of a randomlyselected artist from her preference list (the com-panion would select an artist whose birth place hasnot been inquired in the recent past, by checkingagainst its memories).In the last 15 interactions that related to a cer-tain property, is there a strong tendency (currently,more than 66%) towards one specific value of thatproperty?
The companion can then search for sim-ilar cases among the data, and check whether thereis another artist ?
maybe even among the user?spreferred artists ?
that shares this birth place.Additionally, this type of information is storedin the user model and leads to automatic retrievalof episodes where appropriate.
Continuing the ex-ample of the birth place from above: a day afterbeing asked about artists born in New York, thecompanion might notice while talking about thealbums recorded by Billy Joel that he was alsoborn in New York, and communicate it to the user.Building upon the user preferences stored in theuser model, the remembering process additionallycontains queries related to the most prevalent pref-erences of the user model.
This is similar to find-ing strengthened links in a connectionist model.For example, if one of the currently high-rankeduser preferences is asking for information aboutartists born in New York, a query is automaticallygenerated from the user model to look for this in-formation connected to the individuals in the inputgraph.4 Output GenerationSince our companion ?thinks?
in RDF statements,it requires mechanisms to communicate their con-4tent to the user.
We distinguish two classes ofRDF statements from which to generate natural-language output.
The first class is RDF datathat describes content from the domain ontologies,e.g, that Duke Ellington was born in Washington,DC.
The second class are statements that describea certain type of communicative intent, such astelling the user that she just asked the same ques-tion as five minutes ago.Our approach for the second case is that oftemplate?based generation, where each commu-nicative intent from the ontology corresponds toa different template.
The templates are describedusing the Velocity5 template language, and canthus be extended separately from the programcode, while still offering the possibility to makeuse of memory contents for filling slots in the tem-plates.The first case is handled by directly generatinga sentence structure from the subject ?
predicate?
object structure of the RDF graph.
Triples aresorted by subject; subjects that also appear as ob-jects are inserted as relative clauses.
Statementsthat share the same subject are connected by coor-dination or relative clauses, depending on the typeof relation, and so forth.
The input may containnegation markers, which are realised as negativepolarity items.The surface string of predicates is generated byusing a set of templates and morphological pro-cessing (e.g.
pluralisation).
For subjects and ob-jects, a query on the knowledge base is performedto retrieve an adequate natural language represen-tation.
For example, while the name of a personis in the name property of the Person class, thename of a music album is contained in the prop-erty albumTitle.
A mapping for each class to sucha property is stored in an annotation file.5 Related WorkCatizone et al (2008) use an extended version ofGATE?s ANNIE subsystem, combined with a setof gazetteers, to identify relationships in the in-put to their Senior Companion system.
The fo-cus of the Senior Companion is to use the dataextracted from the user utterances to collect in-formation about the user?s life.
While our inputanalysis system is similar, it uses regular expres-sion patterns over annotations for the matching ofrelations between, and properties of, individuals5http://velocity.apache.org/and classes.
In terms of functionality, our systemfocuses on being able to answer user requests andprovide continued dialogue by taking into accountthe previous interactions with the user.Episodic memory has first been distinguishedfrom other memory types by Tulving (1972).
Im-plementations have for example been used in arti-ficial life agents (Nuxoll, 2007; Ho et al, 2003), instorytelling agents (Ho et al, 2007; Ho and Daut-enhahn, 2008), and for non-player characters ingames (Brom et al, 2007; Brom and Lukavsky?,2009).
Since our memory component is realised asan RDF graph, nearest?neighbour search as in thememory model proposed by Nuxoll (2007) doesnot directly apply.Brom and Lukavsky?
(2009) summarise impor-tant aspects of episodic memory and propose amore detailed concept of time categories thanours.
In contrast to their work, our memory is notconcerned with remembering locations, but withfinding items relevant for current dialogue in theepisodic memory of the agent, and thus stores dif-ferent data.Both the adaptive mind agent by Krenn et al(2009) and Gossip Galore (Xu et al, 2009) de-scribe companion systems able to answer ques-tions on domain data.
Both agents only have lim-ited knowledge of their own past and do not useit for dialogue.
Thus they cannot ground dialoguein their own experiences, and are unable to lever-age knowledge about user preferences for provid-ing more interesting dialogue.Cavazza et al (2008) describe a companion sys-tem for helping users plan a healthier lifestyle.
Di-alogue can be driven by the companion or by theuser, but revolves around agreeing upon a daily ex-ercise plan or negotiating re-planning in case ofplan failure.
Our system aims at a more open kindof dialogue which does not revolve around a planmodel.
Instead, the user is able to ask differentkinds of questions on all the domain data available,which leaves the companion in a situation wheremuch less expectations can be made towards thenext user utterance.6 ConclusionWe have presented a model of a companion thatuses an RDF?based episodic memory componentfor enhancing dialogue with the user and ground-ing domain knowledge in interaction experiencesinterconnected with the agent?s knowledge base.5The full implementation of the model is currentlywork in progress.Retrieval of episodes is accomplished by usinga set of competing SeRQL queries.
Our modelshows how the contents of past interactions andtheir relation to current dialogue can be employedby a companion for selecting the next dialoguemove and generating dialogue content.AcknowledgementsThe work presented is supported by the AustrianMinistry for Transport, Innovation and Technol-ogy (BMVIT) under the programme ?FEMtechWomen in Research and Technology?
grant nr.821855, project C4U.
The Austrian Research In-stitute for Artificial Intelligence (OFAI) is sup-ported by the Austrian ministries BMVIT andBMWF.ReferencesDavid Benyon and Oli Mival.
2008.
Scenariosfor companions.
In Austrian Artificial IntelligenceWorkshop, September.Cyril Brom and Jir??
Lukavsky?.
2009.
Towards Vir-tual Characters with a Full Episodic Memory II: TheEpisodic Memory Strikes Back.
In Proc.
EmpathicAgents, AAMAS workshop, pages 1?9.Cyril Brom, Kla?ra Peskova?, and Jir??
Lukavsky?.
2007.Towards characters with a full episodic memory.In Catherine Pelachaud, Jean-Claude Martin, Elis-abeth Andre?, Ge?rard Chollet, Kostas Karpouzis, andDanielle Pele?, editors, IVA, volume 4722 of Lec-ture Notes in Computer Science, pages 360?361.Springer.G.
Castellano, R. Aylett, K. Dautenhahn, A. Paiva,P.
W. McOwan, and S. Ho.
2008.
Long-Term Af-fect Sensitive and Socially Interactive Companions.In Proceedings of the 4th International Workshop onHuman-Computer Conversation.Roberta Catizone, Alexiei Dingli, Hugo Pinto, andYorick Wilks.
2008.
Information extraction toolsand methods for understanding dialogue in a com-panion.
In Proceedings of the Sixth InternationalLanguage Resources and Evaluation (LREC?08).Marc Cavazza, Cameron Smith, Daniel Charlton,Li Zhang, Markku Turunen, and Jaakko Hakulinen.2008.
A ?companion?
ECA with planning and activ-ity modelling.
In AAMAS ?08: Proceedings of the7th international joint conference on Autonomousagents and multiagent systems, pages 1281?1284.Paul Ekman.
1992.
An argument for basic emotions.Cognition and Emotion, 6:169?200.Birgit Graf, Ulrich Reiser, Martin Ha?gele, KathrinMauz, and Peter Klein.
2009.
Robotic home as-sistant care-o-bot 3 - product vision and innovationplatform.
In IEEE / Robotics and Automation Soci-ety: IEEE Workshop on Advanced Robotics and itsSocial Impacts - ARSO 2009, pages 139?144, NewYork, NY, USA.
Piscataway.Wan Ching Ho and Kerstin Dautenhahn.
2008.
To-wards a narrative mind: The creation of coherentlife stories for believable virtual agents.
In IVA ?08:Proceedings of the 8th international conference onIntelligent Virtual Agents, pages 59?72, Berlin, Hei-delberg.
Springer.Wan Ching Ho, Kerstin Dautenhahn, and Chrysto-pher L. Nehaniv.
2003.
Comparing different con-trol architectures for autobiographic agents in staticvirtual environments.
In Thomas Rist, Ruth Aylett,Daniel Ballin, and Jeff Rickel, editors, IVA, volume2792 of Lecture Notes in Computer Science, pages182?191.
Springer.Wan Ching Ho, Joa?o Dias, Rui Figueiredo, and AnaPaiva.
2007.
Agents that remember can tell sto-ries: integrating autobiographic memory into emo-tional agents.
In Edmund H. Durfee, Makoto Yokoo,Michael N. Huhns, and Onn Shehory, editors, AA-MAS, page 10.
IFAAMAS.Brigitte Krenn, Marcin Skowron, Gregor Sieber, ErichGstrein, and Jo?rg Irran.
2009.
Adaptive mindagent.
In IVA ?09: Proceedings of the 9th Inter-national Conference on Intelligent Virtual Agents,pages 519?520, Berlin, Heidelberg.
Springer.Andrew Nuxoll.
2007.
Enhancing Intelligent Agentswith Episodic Memory.
Ph.D. thesis, Univ.
ofMichigan, Ann Arbor.Marcin Skowron, Jo?rg Irran, and Brigitte Krenn.
2008.Computational framework for and the realization ofcognitive agents providing intelligent assistance ca-pabilities.
In 18th European Conference on Ar-tificial Intelligence, Cognitive Robotics Workshop,pages 88?96.Aaron Sloman.
2007.
Requirements for Digital Com-panions It?s harder than you think.
In Position Paperfor Workshop on Artificial Companions in Society:Perspectives on the Present and Future.
Oxford In-ternet Institute.Endel Tulving.
1972.
Episodic and semantic memory.In E. Tulving and W. Donaldson, editors, Organi-zation of Memory, pages 381?403.
Academic Press,New York.Feiyu Xu, Peter Adolphs, Hans Uszkoreit, XiwenCheng, and Hong Li.
2009.
Gossip galore: Aconversational web agent for collecting and sharingpop trivia.
In Joaquim Filipe, Ana L. N. Fred, andBernadette Sharp, editors, ICAART, pages 115?122.INSTICC Press.6
