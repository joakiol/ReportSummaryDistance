Proceedings of the EACL 2014 Workshop on Type Theory and Natural Language Semantics (TTNLS), pages 1?9,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsTypes and Records for PredicationAarne RantaDepartment of Computer Science and Engineering, University of Gothenburgaarne@chalmers.seAbstractThis paper studies the use of recordsand dependent types in GF (GrammaticalFramework) to build a grammar for pred-ication with an unlimited number of sub-categories, also covering extraction andcoordination.
The grammar is imple-mented for Chinese, English, Finnish, andSwedish, sharing the maximum of codeto identify similarities and differences be-tween the languages.
Equipped with aprobabilistic model and a large lexicon,the grammar has also been tested in wide-coverage machine translation.
The firstevaluations show improvements in parsingspeed, coverage, and robustness in com-parison to earlier GF grammars.
The studyconfirms that dependent types, records,and functors are useful in both engineer-ing and theoretical perspectives.1 IntroductionPredication is the basic level of syntax.
In logic, itmeans building atomic formulas by predicates.
Inlinguistics, it means building sentences by verbs.Categorial grammars (Bar-Hillel, 1953; Lambek,1958) adapt logical predication to natural lan-guage.
Thus for instance transitive verbs are cat-egorized as (n\s/n), which is the logical typen?
n?
s with the information that one argumentcomes before the verb and the other one after.
Butmost approaches to syntax and semantics, includ-ing (Montague, 1974), introduce predicate cate-gories as primitives rather than as function types.Thus transitive verbs are a category of its own, re-lated to logic via a semantic rule.
This gives moreexpressive power, as it permits predicates with dif-ferent syntactic properties and variable word order(e.g.
inversion in questions).
A drawback is thata grammar may need a large number of categoriesand rules.
In GPSG (Gazdar et al., 1985), and laterin HPSG (Pollard and Sag, 1994), this is solvedby introducing a feature called subcat for verbs.Verbs taking different arguments differ in the sub-cat feature but share otherwise the characteristic ofbeing verbs.In this paper, we will study the syntax and se-mantics of predication in GF, Grammatical Frame-work (Ranta, 2011).
We will generalize both oversubcategories (as in GPSG and HPSG), and overlanguages (as customary in GF).
We use depen-dent types to control the application of verbs tolegitimate arguments, and records to control theplacement of arguments in sentences.
The recordstructure is inspired by the topological model ofsyntax in (Diderichsen, 1962).The approach is designed to apply to all lan-guages in the GF Resource Grammar Library(RGL, (Ranta, 2009)), factoring out their typolog-ical differences in a modular way.
We have testedthe grammar with four languages from three fam-ilies: Chinese, English, Finnish, and Swedish.
Asthe implementation reuses old RGL code for allparts but predication, it can be ported to new lan-guages with just a few pages of new GF code.
Wehave also tested it in wide coverage tasks, with aprobabilistic tree model and a lexicon of 60,000lemmas.We will start with an introduction to the abstrac-tion mechanisms of GF and conclude with a sum-mary of some recent research.
Section 2 placesGF on the map of grammar formalisms.
Section 3works out an example showing how abstract syn-tax can be shared between languages.
Section 4shows how parts of concrete syntax can be sharedas well.
Section 5 gives the full picture of predi-cation with dependent types and records, also ad-dressing extraction, coordination, and semantics.Section 6 gives preliminary evaluation.
Section 7concludes.12 GF: an executive summaryGF belongs to a subfamily of categorial grammarsinspired by (Curry, 1961).
These grammars makea distinction between tectogrammar, which spec-ifies the syntactic structures (tree-like representa-tions), and phenogrammar, which relates thesestructures to linear representations, such as se-quences of characters, words, or phonemes.
Otherformalisms in this family include ACG (de Groote,2001) and Lambda grammars (Muskens, 2001).GF inherits its name from LF, Logical Frame-works, which are type theories used for defin-ing logics (Harper et al., 1993).
GF builds onthe LF called ALF, Another Logical Framework(Magnusson, 1994), which implements Martin-L?of?s higher-level type theory (first introducedin the preface of (Martin-L?of, 1984); see Chap-ter 8 of (Ranta, 1994) for more details).
BeforeGF was introduced as an independent formalismin 1998, GF-like applications were built as plug-ins to ALF (Ranta, 1997).
The idea was that theLF defines the tectogrammar, and the plug-in de-fines the phenogrammar.
The intended applicationwas natural language interfaces to formal proofsystems, in the style of (Coscoy et al., 1995).GF was born via two additions to the naturallanguage interface idea.
The first one was multi-linguality: one and the same tectogrammar canbe given multiple phenogrammars.
The secondaddition was parsing: the phenogrammar, whichwas initially just linearization (generating stringsfrom type theoretical formulas), was reversed torules that parse natural language into type theory.The result was a method for translation, whichcombines parsing the source language with lin-earization into the target language.
This idea wasindeed suggested in (Curry, 1961), and appliedbefore GF in the Rosetta project (Landsbergen,1982), which used Montague?s analysis trees astectogrammar.GF can be seen as a formalization and gener-alization of Montague grammar.
Formalization,because it introduces a formal notation for thelinearization rules that in Montague?s work wereexpressed informally.
Generalization, because ofmultilinguality and also because the type systemfor analysis trees has dependent types.Following the terminology of programming lan-guage theory, the tectogrammar is in GF calledthe abstract syntax whereas the phenogrammar iscalled the concrete syntax.
As in compilers andlogical frameworks, the abstract syntax encodesthe structure relevant for semantics, whereas theconcrete syntax defines ?syntactic sugar?.The resulting system turned out to be equiv-alent to parallel multiple context-free gram-mars (Seki et al., 1991) and therefore parsablein polynomial time (Ljungl?of, 2004).
Compre-hensive grammars have been written for 29 lan-guages, and later work has optimized GF pars-ing and also added probabilistic disambiguationand robustness, resulting in state-of-the-art perfor-mance in wide-coverage deep parsing (Angelov,2011; Angelov and Ljungl?of, 2014).3 Example: subject-verb-objectsentencesLet us start with an important special case of predi-cation: the subject-verb-object structure.
The sim-plest possible rule isfun PredTV : NP -> TV -> NP -> Sthat is, a function that takes a subject NP, a tran-sitive verb TV, and an object NP, and returns asentence S. This function builds abstract syntaxtrees.
Concrete syntax defines linearization rules,which convert trees into strings.
The above rulecan give rise to different word orders, such as SVO(as in English), SOV (as in Hindi), and VSO (as inArabic):lin PredTV s v o = s ++ v ++ olin PredTV s v o = s ++ o ++ vlin PredTV s v o = v ++ s ++ owhere ++ means concatenation.The above rule builds a sentence in one step.A more flexible approach is to do it in two steps:complementation, forming a VP (verb phrase)from the verb and the object, and predicationproper that provides the subject.
The abstract syn-tax isfun Compl : TV -> NP -> VPfun Pred : NP -> VP -> SThese functions are easy to linearize for the SVOand SOV orders:lin Compl v o = v ++ o -- SVOlin Compl v o = o ++ v -- SOVlin Pred s vp = s ++ vp -- bothwhere -- marks a comment.
However, the VSOorder cannot be obtained in this way, because thetwo parts of the VP are separated by the subject.The solution is to generalize linearization fromstrings to records.
Complementation can then re-turn a record that has the verb and the object asseparate fields.
Then we can also generate VSO:2lin Compl v o = {verb = v ; obj = o}lin Pred s vp = vp.verb ++ s ++ vp.objThe dot (.)
means projection, picking the valueof a field in a record.Records enable the abstract syntax to abstractaway not only from word order, but also fromwhether a language uses discontinuous con-stituents.
VP in VSO languages is one example.Once we enable discontinuous constituents, theyturn out useful almost everywhere, as they enableus to delay the decision about linear order.
It canthen be varied even inside a single language, if itdepends on syntactic context (as e.g.
in German;cf.
(M?uller, 2004) for a survey).The next thing to abstract away from is inflec-tion and agreement.
Given the lexiconfun We, She : NPfun Love : TVwe can build the abstract syntax treePred We (Compl Love She)to represent we love her.
If we swap the subjectand the object, we getPred She (Compl Love We)for she loves us.
Now, these two sentences arebuilt from the same abstract syntax objects, butno single word is shared between them!
This isbecause the noun phrases inflect for case and theverb agrees to the subject.In contrast to English, Chinese just reorders thewords:women ai ta - ?we love her?ta ai women - ?she loves us?Thus the above rules for SVO languages work asthey are for Chinese.
But in English, we must in-clude case and agreement as features in the con-crete syntax.
Thus the linearization of an NP isa record that includes a table producing the caseforms, and agreement as an inherent feature:lin She = {s = table {Nom => "she" ;Acc => "her"} ;a = {n = Sg ; p = P3} ;}The agreement feature (field a) is itself a record,with a number and a gender.
In other languages,case and agreement can of course have differentsets of values.Verbs likewise include tables that inflect themfor different agreement features:lin Love = {s = table {{n = Sg ; p = P3} => "loves" ;_ => "love"}}We can now define English linearization:lin Compl v o ={s = table {a => v.s !
a ++ o.s !
Acc}}lin Pred s vp ={s = s.s !
Nom ++ vp.s !
np.a}using the same type of records for VP as for TV,and a one-string record for S. The Compl rulepasses the agreement feature to the verb of the VP,and selects the Acc form of the object (with !
de-noting selection from a table).
The Pred rule se-lects the Nom form of the subject, and attaches tothis the VP form selected for np.a, i.e.
the agree-ment feature of the subject.4 Generalized concrete syntaxTo see the full power of GF, we now take a lookat its type and module system.
Figure 1 shows acomplete set of grammar modules implementingtransitive verb predication for Finnish and Chinesewith a maximum of shared code.The first module in Figure 1 is the abstract syn-tax Pred, where the fun rules are preceded bya set of cat rules defining the categories of thegrammar, i.e.
the basic types.
Pred defines fivecategories: S, Cl, NP, VP, and TV.
S is the top-level category of sentences, whereas Cl (clause) isthe intermediate category of predications, whichcan be used as sentences in many ways?here, asdeclaratives and as questions.The concrete syntax has corresponding lincatrules, which equip each category with a lineariza-tion type, i.e.
the type of the values returnedwhen linearizing trees of that category.
The mod-ule PredFunctor in Figure 1 contains four suchrules.
In lincat NP, the type Case => Str isthe type of tables that produce a string as a func-tion of a case, and Agr is the type of agreementfeatures.When a GF grammar is compiled, each lin ruleis type checked with respect to the lincats of thecategories involved, to guarantee that, for everyfun f : C1?
???
?Cn?Cwe havelin f : C?1?
???
?C?n?C?3abstract Pred = {cat S ; Cl ; NP ; VP ; TV ;fun Compl : TV -> NP -> VP ; fun Pred : TV -> NP -> Cl ;fun Decl : Cl -> S ; fun Quest : Cl -> S ;}incomplete concrete PredFunctor of Pred = open PredInterface in {lincat S = {s : Str} ; lincat Cl = {subj,verb,obj : Str} ;lincat NP = {s : Case => Str ; a : Agr} ;lincat VP = {verb : Agr => Str ; obj : Str} ; lincat TV = {s : Agr => Str} ;lin Compl tv np = {verb = tv.s ; obj = np.s !
objCase} ;lin Pred np vp = {subj = np.s !subjCase ; verb = vp.verb !
np.a ; obj = vp.obj} ;lin Decl cl = {s = decl cl.subj cl.verb cl.obj} ;lin Quest cl = {s = quest cl.subj cl.verb cl.obj} ;}interface PredInterface = {oper Case, Agr : PType ;oper subjCase, objCase : Case ;oper decl, quest : Str -> Str -> Str -> Str ;}instance PredInstanceFin of PredInterface = { concrete PredFin of Pred =oper Case = -- Nom | Acc | ... ; PredFunctor withoper Agr = {n : Number ; p : Person} ; (PredInterface =oper subjCase = Nom ; objCase = Acc ; PredInstanceFin) ;oper decl s v o = s ++ v ++ o ;oper quest s v o = v ++ "&+ ko" ++ s ++ o ;}instance PredInstanceChi of PredInterface = { concrete PredChi of Pred =oper Case, Agr = {} ; PredFunctor withoper subjCase, objCase = <> ; (PredInterface =oper decl s v o = s ++ v ++ o ; PredInstanceChi) ;oper quest s v o = s ++ v ++ o ++ "ma" ;}Figure 1: Functorized grammar for transitive verb predication.where A?is the linearization type of A.
Thus lin-earization is a homomorphism.
It is actuallyan instance of denotational semantics, where thelincats are the domains of possible denota-tions.Much of the strength of GF comes from us-ing different linearization types for different lan-guages.
Thus English needs case and agreement,Finnish needs many more cases (in the full gram-mar), Chinese needs mostly only strings, and soon.
However, it is both useful and illuminating tounify the types.
The way to do this is by the useof functors, also known as a parametrized mod-ules.PredFunctor in Figure 1 is an example; func-tors are marked with the keyword incomplete.
Afunctor depends on an interface, which declaresa set of parameters (PredInterface in Figure1).
A concrete module is produced by givingan instance to the interface (PredInstanceFinand PredInstanceChi).The rules in PredFunctor in Figure 1 are de-signed to work for both languages, by varying thedefinitions of the constants in PredInterface.And more languages can be added to use it.
Con-sider for example the definition of NP.
The expe-rience from the RGL shows that, if a languagehas case and agreement, its NPs inflect for caseand have inherent agreement.
The limiting caseof Chinese can be treated by using the unit type({} i.e.
the record type with no fields) for bothfeatures.
This would not be so elegant for Chinesealone, but makes sense in the code sharing context.Discontinuity now appears as another usefulgeneralization.
With the lincat definition inPredFunctor, we can share the Compl rule in allof the languages discussed so far.
In clauses (Cl),we continue on similar lines: we keep the subject,the verb, and the object on separate fields.
Noticethat verb in Cl is a plain string, since the value ofAgr gets fixed when the subject is added.The final sentence word order is created as thelast step, when converting Cl into S. As Cl is dis-continuous, it can be linearized in different orders.In Figure 1, this is used in Finnish for generat-ing the SVO order in declaratives and VSO onquestions (with an intervening question particle koglued to the verb).
It also supports the other word4orders of Finnish (Karttunen and Kay, 1985).By using an abstract syntax in combination withunordered records, parameters, and functors forthe concrete syntax, we follow a kind of a ?prin-ciples and parameters?
approach to language vari-ation (Chomsky, 1981).
The actual parameter setfor the whole RGL is of course larger than the oneshown here.Mathematically, it is possible to treat all differ-ences in concrete syntax by parameters, simply bydeclaring a new parameter for every lincat andlin rule!
But this is both vacuous as a theory andan unnecessary detour in practice.
It is more il-luminating to keep the functor simple and the setof parameters small.
If the functor does not workfor a new language, it usually makes more sense tooverride it than to grow the parameter list, and GFprovides a mechanism for this.
Opposite to ?prin-ciples and parameters?, this is ?a model in whichlanguage-particular rules take over the work of pa-rameter settings?
(Newmeyer, 2004).
A combina-tion of the two models enables language compari-son by measuring the amount of overrides.5 The full predication systemSo far we have only dealt with one kind of verbs,TV.
But we need more: intransitive, ditransitive,sentence-complement, etc.
The general verb cate-gory is a dependent type, which varies over argu-ment type lists:cat V (x : Args)The list x : Args corresponds to the subcat fea-ture in GPSG and HPSG.
Verb phrases and clauseshave the same dependencies.
Syntactically, aphrase depending on x : Args has ?holes?
forevery argument in the list x. Semantically, it is afunction over the denotations of its arguments (seeSection 5.3 below).5.1 The codeFigure 2 shows the essentials of the resultinggrammar, and we will now explain this code.
Thefull code is available at the GF web site.1.
Argument lists and dependent categories.The argument of a verb can be an adjectival phrase(AP, become old), a clause (Cl, say that we go), acommon noun (CN, become a president), a nounphrase (NP, love her), a question (QCl, wonderwho goes), or a verb phrase (VP, want to go).
Thedefinition allows an arbitrary list of arguments.For example, NP+QCl is used in verbs such as ask(someone whether something).What about PP (prepositional phrase) comple-ments?
The best approach in a multilingual set-ting is to treat them as NP complements with des-ignated cases.
Thus in Figure 2.5, the lineariza-tion type of VP has fields of type complCase.This covers cases and prepositions, often in com-bination.
For instance, the German verb lieben(?love?)
takes a plain accusative argument, fol-gen (?love?)
a plain dative, and warten (?wait?
)the preposition auf with the accusative.
From theabstract syntax point of view, all of them are NP-complement verbs.
Cases and prepositions, andthereby transitivity, are defined in concrete syntax.The category Cl, clause, is the discontinuousstructure of sentences before word order is deter-mined.
Its instance Cl (c np O) corresponds tothe slash categories S/NP and S/PP in GPSG.Similarly, VP (c np O) corresponds to VP/NPand VP/PP, Adv (c np O) to Adv/NP (preposi-tions), and so on.2.
Initial formation of verb phases.
A VP isformed from a V by fixing its tense and polarity.In the resulting VP, the verb depends only on theagreement features of the expected subject.
Thecomplement case comes from the verb?s lexicalentry, but the other fields?such as the objects?are left empty.
This makes the VP usable in bothcomplementation and slash operations (where thesubject is added before some complement).VPs can also be formed from adverbials, ad-jectival phrases, and common nouns, by adding acopula.
Thus was in results from applying UseAdvto the preposition (i.e.
Adv/NP) in, and expands toa VP with ComplNP (was in France) and to a slashclause with PredVP (she was in).3.
Complementation, VP slash formation, re-flexivization.
The Compl functions in Figure 2.3provide each verb phrase with its ?first?
comple-ment.
The Slash functions provide the ?last?complement, leaving a ?gap?
in the middle.
Forinstance, SlashCl provides the slash clause usedin the question whom did you tell that we sleep.The Refl rules fill argument places with reflexivepronouns.4.
NP-VP predication, slash termination, andadverbial modification.
PredVP is the basic NP-VP predication rule.
With x = c np O, it be-comes the rule that combines NP with VP/NP toform S/NP.
SlashTerm is the GPSG ?slash termi-51.
Argument lists and some dependent categoriescat Arg ; Args -- arguments and argument listsfun ap, cl, cn, np, qcl, vp : Arg -- AP, Cl, CN, NP, QCl, VP argumentfun O : Args -- no argumentsfun c : Arg -> Args -> Args -- one more argumentcat V (x : Args) -- verb in the lexiconcat VP (x : Args) -- verb phrasecat Cl (x : Args) -- clausecat AP (x : Args) -- adjectival phrasecat CN (x : Args) -- common noun phrasecat Adv (x : Args) -- adverbial phrase2.
Initial formation of verb phasesfun UseV : (x : Args) -> Temp -> Pol -> V x -> VP x -- loved (X)fun UseAP : (x : Args) -> Temp -> Pol -> AP x -> VP x -- was married to (X)fun UseCN : (x : Args) -> Temp -> Pol -> CN x -> VP x -- was a son of (X)fun UseAdv : (x : Args) -> Temp -> Pol -> Adv x -> VP x -- was in (X)3.
Complementation, VP slash formation, reflexivizationfun ComplNP : (x : Args) -> VP (c np x) -> NP -> VP x -- love herfun ComplCl : (x : Args) -> VP (c cl x) -> Cl x -> VP x -- say that we gofun SlashNP : (x : Args) -> VP (c np (c np x)) -> NP -> VP (c np x) -- show (X) to himfun SlashCl : (x : Args) -> VP (c np (c cl x)) -> Cl x -> VP (c np x) -- tell (X) that..fun ReflVP : (x : Args) -> VP (c np x) -> VP x -- love herselffun ReflVP2 : (x : Args) -> VP (c np (c np x)) -> VP (c np x) -- show (X) to herself4.
NP-VP predication, slash termination, and adverbial modificationfun PredVP : (x : Args) -> NP -> VP x -> Cl x -- she loves (X)fun SlashTerm : (x : Args) -> Cl (c np x) -> NP -> Cl x -- she loves + X5.
The functorial linearization type of VPlincat VP = {verb : Agr => Str * Str * Str ; -- finite: would,have,goneinf : VVType => Str ; -- infinitive: (not) (to) goimp : ImpType => Str ; -- imperative: goc1 : ComplCase ; -- case of first complementc2 : ComplCase ; -- case of second complementvvtype : VVType ; -- type of VP complementadj : Agr => Str ; -- adjective complementobj1 : Agr => Str ; -- first complementobj2 : Agr => Str ; -- second complementobjagr : {a : Agr ; objCtr : Bool} ; -- agreement used in object controladv1 : Str ; -- pre-verb adverbadv2 : Str ; -- post-verb adverbext : Str ; -- extraposed element e.g.
that-clause}6.
Some functorial linearization ruleslin ComplNP x vp np = vp ** {obj1 = \\a => appComplCase vp.c1 np}lin ComplCl x vp cl = vp ** {ext = that_Compl ++ declSubordCl cl}lin SlashNP2 x vp np = vp ** {obj2 = \\a => appComplCase vp.c2 np}lin SlashCl x vp cl = vp ** {ext = that_Compl ++ declSubordCl cl}7.
Some interface parametersoper Agr, ComplCase : PType -- agreement, complement caseoper appComplCase : ComplCase -> NP -> Str -- apply complement case to NPoper declSubordCl : Cl -> Str -- subordinate question word orderFigure 2: Dependent types, records, and parameters for predication.6nation?
rule.5.
The functorial linearization type of VP.This record type contains the string-valued fieldsthat can appear in different orders, as well as theinherent features that are needed when comple-ments are added.
The corresponding record for Clhas similar fields with constant strings, plus a sub-ject field.6.
Some functorial linearization rules.
Theverb-phrase expanding rules typically work withrecord updates, where the old VP is left un-changed except for a few fields that get new val-ues.
GF uses the symbol ** for record updates.Notice that ComplCl and SlashCl have exactlythe same linearization rules; the difference comesfrom the argument list x in the abstract syntax.7.
Some interface parameters.
The codein Figure 2.5 and 2.6 is shared by different lan-guages, but it depends on an interface that declaresparameters, some of which are shown here.5.2 More constructionsExtraction.
The formation of questions and rel-atives is straighforward.
Sentential (yes/no) ques-tions, formed by QuestCl in Figure 3.1, don?t inmany languages need any changes in the clause,but just a different ordering in final linearization.Wh questions typically put one interrogative (IP)in the focus, which may be in the beginning of thesentence even though the corresponding argumentplace in declaratives is later.
The focus field inQCl is used for this purpose.
It carries a Booleanfeature saying whether the field is occupied.
If itsvalue is True, the next IP is put into the ?normal?argument place, as in who loves whom.Coordination.
The VP conjunction rules inFigure 3.2 take care of both intransitive VPs (shewalks and runs) and of verb phrases with argu-ments (she loves and hates us).
Similarly, Cl con-juction covers both complete sentences and slashclauses (she loves and we hate him).
Some VPcoordination instances may be ungrammatical, inparticular with inverted word orders.
Thus she istired and wants to sleep works as a declarative,but the question is not so good: ?is she tired andwants to sleep.
Preventing this would need a muchmore complex rules.
Since the goal of our gram-mar is not to define grammaticality (as in formallanguage theory), but to analyse and translate ex-isting texts, we opted for a simple system in thiscase (but did not need to do so elsewhere).5.3 SemanticsThe abstract syntax has straightforward denota-tional semantics: each type in the Args list of acategory adds an argument to the type of denota-tions.
For instance, the basic VP denotation type isEnt -> Prop, and the type for an arbitrary sub-category of VP x is(x : Args) -> Den x (Ent -> Prop)where Den is a type family defined recursivelyover Args,Den : Args -> Type -> TypeDen O t = tDen (c np xs) t = Ent -> Den xs tDen (c cl xs) t = Prop -> Den xs tand so on for all values of Arg.
The second ar-gument t varies over the basic denotation types ofVP, AP, Adv, and CN.Montague-style semantics is readily availablefor all rules operating on these categories.
As alogical framework, GF has the expressive powerneeded for defining semantics (Ranta, 2004).
Thetypes can moreover be extended to express selec-tional restrictions, where verb arguments are re-stricted to domains of individuals.
Here is a typesystem that adds a domain argument to NP andVP:cat NP (d : Dom)cat VP (d : Dom)(x : Args)fun PredVP : (d : Dom) -> (x : Args)-> NP d -> VP d x -> Cl xThe predication rule checks that the NP and theVP have the same domain.6 EvaluationCoverage.
The dependent type system for verbs,verb phrases, and clauses is a generalization ofthe old Resource Grammar Library (Ranta, 2009),which has a set of hard-wired verb subcategoriesand a handful of slash categories.
While it cov-ers ?all usual cases?, many logically possible onesare missing.
Some such cases even appear in thePenn treebank (Marcus et al., 1993), requiring ex-tra rules in the GF interpretation of the treebank(Angelov, 2011).
An example is a function of typeV (c np (c vp O)) ->VPC (c np O) -> VP (c np O)which is used 12 times, for example in This is de-signed to get the wagons in a circle and defendthe smoking franchise.
It has been easy to writeconversion rules showing that the old coverage ispreserved.
But it remains future work to see whatnew cases are covered by the increased generality.71.
Extraction.cat QCl (x : Args) -- question clausecat IP -- interrogative phrasefun QuestCl : (x : Args) -> Cl x -> QCl x -- does she love himfun QuestVP : (x : Args) -> IP -> VP x -> QCl x -- who loves himfun QuestSlash : (x : Args) -> IP -> QCl (c np x) -> QCl x -- whom does she lovelincat QCl = Cl ** {focus : {s : Str ; isOcc : Bool}} -- focal IP, whether occupied2.
Coordination.cat VPC (x : Args) -- VP conjunctioncat ClC (x : Args) -- Clause conjunctionfun StartVPC : (x : Args) -> Conj -> VP x -> VP x -> VPC x -- love or hatefun ContVPC : (x : Args) -> VP x -> VPC x -> VPC x -- admire, love or hatefun UseVPC : (x : Args) -> VPC x -> VP x -- [use VPC as VP]fun StartClC : (x : Args) -> Conj -> Cl x -> Cl x -> ClC x -- he sells and I buyfun ContClC : (x : Args) -> Cl x -> ClC x -> ClC x -- you steal, he sells and I buyfun UseClC : (x : Args) -> ClC x -> Cl x -- [use ClC as Cl]Figure 3: Extraction and coordination.Multilinguality.
How universal are the con-crete syntax functor and interface?
In the stan-dard RGL, functorization has only been attemptedfor families of closely related languages, with Ro-mance languages sharing 75% of syntax code andScandinavian languages 85% (Ranta, 2009).
Thenew predication grammar shares code across alllanguages.
The figure to compare is the percent-age of shared code (abstract syntax + functor + in-terface) of the total code written for a particularlanguage (shared + language-specific).
This per-centage is 70 for Chinese, 64 for English, 61 forFinnish, and 76 for Swedish, when calculated aslines of code.
The total amount of shared code is760 lines.
One example of overrides is negationand questions in English, which are complicatedby the need of auxiliaries for some verbs (go) butnot for others (be).
This explains why Swedishshares more of the common code than English.Performance.
Dependent types are not inte-grated in current GF parsers, but checked by post-processing.
This implies a loss of speed, be-cause many trees are constructed just to be thrownaway.
But when we specialized dependent typesand rules to nondependent instances needed by thelexicon (using them as metarules in the sense ofGPSG), parsing became several times faster thanwith the old grammar.
An analysis remains to do,but one hypothesis is that the speed-up is due tofixing tense and polarity earlier than in the oldRGL: when starting to build VPs, as opposed towhen using clauses in full sentences.
Dependenttypes made it easy to test this refactoring, sincethey reduced the number of rules that had to bewritten.Robustness.
Robustness in GF parsing isachieved by introducing metavariables (?ques-tion marks?)
when tree nodes cannot be con-structed by the grammar (Angelov, 2011).
Thesubtrees under a metavariable node are linearizedseparately, just like a sequence of chunks.
Intranslation, this leads to decrease in quality, be-cause dependencies between chunks are not de-tected.
The early application of tense and polarityis an improvement, as it makes verb chunks con-tain information that was previously detected onlyif the parser managed to build a whole sentence.7 ConclusionWe have shown a GF grammar for predication al-lowing an unlimited variation of argument lists: anabstract syntax with a concise definition using de-pendent types, a concrete syntax using a functorand records, and a straightforward denotational se-mantics.
The grammar has been tested with fourlanguages and shown promising results in speedand robustness, also in large-scale processing.
Amore general conclusion is that dependent types,records, and functors are powerful tools both forcomputational grammar engineering and for thetheoretical study of languages.Acknowledgements.
I am grateful to KrasimirAngelov and Robin Cooper for comments, andto Swedish Research Council for support undergrant nr.
2012-5746 (Reliable Multilingual Dig-ital Communication).8ReferencesK.
Angelov and P. Ljungl?of.
2014.
Fast statistical pars-ing with parallel multiple context-free grammars.
InProceedings of EACL-2014, Gothenburg.K.
Angelov.
2011.
The Mechanics of the GrammaticalFramework.
Ph.D. thesis, Chalmers University ofTechnology.Y.
Bar-Hillel.
1953.
A quasi-arithmetical notation forsyntactic description.
Language, 29:27?58.N.
Chomsky.
1981.
Lectures on Government andBinding.
Mouton de Gruyter.Y.
Coscoy, G. Kahn, and L. Thery.
1995.
Extract-ing text from proofs.
In M. Dezani-Ciancaglini andG.
Plotkin, editors, Proc.
Second Int.
Conf.
on TypedLambda Calculi and Applications, volume 902 ofLNCS, pages 109?123.H.
B. Curry.
1961.
Some logical aspects of grammat-ical structure.
In Roman Jakobson, editor, Structureof Language and its Mathematical Aspects: Pro-ceedings of the Twelfth Symposium in Applied Math-ematics, pages 56?68.
American Mathematical So-ciety.Ph.
de Groote.
2001.
Towards Abstract CategorialGrammars.
In Association for Computational Lin-guistics, 39th Annual Meeting and 10th Conferenceof the European Chapter, Toulouse, France, pages148?155.P.
Diderichsen.
1962.
Element?r dansk grammatik.Gyldendal, K?benhavn.G.
Gazdar, E. Klein, G. Pullum, and I.
Sag.
1985.
Gen-eralized Phrase Structure Grammar.
Basil Black-well, Oxford.R.
Harper, F. Honsell, and G. Plotkin.
1993.
A Frame-work for Defining Logics.
JACM, 40(1):143?184.L.
Karttunen and M. Kay.
1985.
Parsing in a freeword order language.
In D. Dowty, L. Karttunen,and A. Zwicky, editors, Natural Language Pars-ing, Psychological, Computational, and TheoreticalPerspectives, pages 279?306.
Cambridge UniversityPress.J.
Lambek.
1958.
The mathematics of sentence struc-ture.
AmericanMathematical Monthly, 65:154?170.J.
Landsbergen.
1982.
Machine translation basedon logically isomorphic Montague grammars.
InCOLING-1982.P.
Ljungl?of.
2004.
The Expressivity and Com-plexity of Grammatical Framework.
Ph.D.thesis, Dept.
of Computing Science, ChalmersUniversity of Technology and Gothenburg Uni-versity.
http://www.cs.chalmers.se/~peb/pubs/p04-PhD-thesis.pdf.L.
Magnusson.
1994.
The Implementation of ALF - aProof Editor based on Martin-L?of?s MonomorphicType Theory with Explicit Substitution.
Ph.D. thesis,Department of Computing Science, Chalmers Uni-versity of Technology and University of G?oteborg.M.
P. Marcus, B. Santorini, and M. A. Marcinkiewicz.1993.
Building a Large Annotated Corpus of En-glish: The Penn Treebank.
Computational Linguis-tics, 19(2):313?330.P.
Martin-L?of.
1984.
Intuitionistic Type Theory.
Bib-liopolis, Napoli.R.
Montague.
1974.
Formal Philosophy.
Yale Univer-sity Press, New Haven.
Collected papers edited byRichmond Thomason.S.
M?uller.
2004.
Continuous or Discontinuous Con-stituents?
A Comparison between Syntactic Analy-ses for Constituent Order and Their Processing Sys-tems.
Research on Language and Computation,2(2):209?257.R.
Muskens.
2001.
Lambda Grammars and theSyntax-Semantics Interface.
In R. van Rooy andM.
Stokhof, editors, Proceedings of the ThirteenthAmsterdam Colloquium, pages 150?155, Amster-dam.
http://let.uvt.nl/general/people/rmuskens/pubs/amscoll.pdf.F.
J. Newmeyer.
2004.
Against a parameter-settingapproach to language variation.
Linguistic VariationYearbook, 4:181?234.C.
Pollard and I.
Sag.
1994.
Head-Driven PhraseStructure Grammar.
University of Chicago Press.A.
Ranta.
1994.
Type Theoretical Grammar.
OxfordUniversity Press.A.
Ranta.
1997.
Structures grammaticales dans lefranc?ais math?ematique.
Math?ematiques, informa-tique et Sciences Humaines, 138/139:5?56/5?36.A.
Ranta.
2004.
Computational Semantics in TypeTheory.
Mathematics and Social Sciences, 165:31?57.A.
Ranta.
2009.
The GF Resource GrammarLibrary.
Linguistics in Language Technology,2.
http://elanguage.net/journals/index.php/lilt/article/viewFile/214/158.A.
Ranta.
2011.
Grammatical Framework: Program-ming with Multilingual Grammars.
CSLI Publica-tions, Stanford.H.
Seki, T. Matsumura, M. Fujii, and T. Kasami.
1991.On multiple context-free grammars.
TheoreticalComputer Science, 88:191?229.9
