Proceedings of the 2nd Workshop on Building and Using Comparable Corpora, ACL-IJCNLP 2009, pages 46?54,Suntec, Singapore, 6 August 2009. c?2009 ACL and AFNLPExploiting Comparable Corpora with TER and TERpSadaf Abdul-Rauf and Holger SchwenkLIUM, University of Le Mans, FRANCESadaf.Abdul-Rauf@lium.univ-lemans.frAbstractIn this paper we present an extension of asuccessful simple and effective method forextracting parallel sentences from com-parable corpora and we apply it to anArabic/English NIST system.
We exper-iment with a new TERp filter, along withWER and TER filters.
We also report acomparison of our approach with that of(Munteanu and Marcu, 2005) using ex-actly the same corpora and show perfor-mance gain by using much lesser data.Our approach employs an SMT systembuilt from small amounts of parallel textsto translate the source side of the non-parallel corpus.
The target side texts areused, along with other corpora, in the lan-guage model of this SMT system.
We thenuse information retrieval techniques andsimple filters to create parallel data froma comparable news corpora.
We evaluatethe quality of the extracted data by show-ing that it significantly improves the per-formance of an SMT systems.1 IntroductionParallel corpora, a requisite resource for StatisticalMachine Translation (SMT) as well as many othernatural language processing applications, remaina sparse resource due to the huge expense (humanas well as monetary) required for their creation.A parallel corpus, also called bitext, consists inbilingual texts aligned at the sentence level.
SMTsystems use parallel texts as training material andmonolingual corpora for target language model-ing.
Though enough monolingual data is availablefor most language pairs, it is the parallel corpusthat is a sparse resource.The performance of an SMT system heavilydepends on the parallel corpus used for train-ing.
Generally, more bitexts lead to better perfor-mance.
The existing resources of parallel corporacover a few language pairs and mostly come fromone domain (proceedings of the Canadian or Eu-ropean Parliament, or of the United Nations).
Thelanguage jargon used in such corpora is not verywell suited for everyday life translations or transla-tions of some other domain, thus a dire need arisesfor more parallel corpora well suited for everydaylife and domain adapted translations.One option to increase this scarce resourcecould be to produce more human translations, butthis is a very expensive option, in terms of bothtime and money.
Crowd sourcing could be an-other option, but this has its own costs and thusis not very practical for all cases.
The worldwide web can also be crawled for potential ?par-allel sentences?, but most of the found bilingualtexts are not direct translations of each other andnot very easy to align.
In recent works less ex-pensive but very productive methods of creatingsuch sentence aligned bilingual corpora were pro-posed.
These are based on generating ?parallel?texts from already available ?almost parallel?
or?not much parallel?
texts.
The term ?comparablecorpus?
is often used to define such texts.A comparable corpus is a collection of textscomposed independently in the respective lan-guages and combined on the basis of similarity ofcontent (Yang and Li, 2003).
The raw material forcomparable documents is often easy to obtain butthe alignment of individual documents is a chal-lenging task (Oard, 1997).
Potential sources ofcomparable corpora are multilingual news report-ing agencies like AFP, Xinhua, Al-Jazeera, BBCetc, or multilingual encyclopedias like Wikipedia,Encarta etc.
Such comparable corpora are widelyavailable from LDC, in particular the Gigawordcorpora, or over the WEB for many languagesand domains, e.g.
Wikipedia.
They often containmany sentences that are reasonable translations of46each other.
Reliable identification of these pairswould enable the automatic creation of large anddiverse parallel corpora.The ease of availability of these comparablecorpora and the potential for parallel corpus aswell as dictionary creation has sparked an interestin trying to make maximum use of these compa-rable resources, some of these works include dic-tionary learning and identifying word translations(Rapp, 1995), named entity recognition (Sproatet al, 2006), word sense disambiguation (Kaji,2003), improving SMT performance using ex-tracted parallel sentences (Munteanu and Marcu,2005), (Rauf and Schwenk, 2009).
There has beenconsiderable amount of work on bilingual compa-rable corpora to learn word translations as wellas discovering parallel sentences.
Yang and Lee(2003) use an approach based on dynamic pro-gramming to identify potential parallel sentencesin title pairs.
Longest common sub sequence, editoperations and match-based score functions aresubsequently used to determine confidence scores.Resnik and Smith (2003) propose their STRANDweb-mining based system and show that their ap-proach is able to find large numbers of similar doc-ument pairs.Works aimed at discovering parallel sentencesinclude (Utiyama and Isahara, 2003), who usecross-language information retrieval techniquesand dynamic programming to extract sentencesfrom an English-Japanese comparable corpus.They identify similar article pairs, and then, treat-ing these pairs as parallel texts, align their sen-tences on a sentence pair similarity score and useDP to find the least-cost alignment over the doc-ument pair.
Fung and Cheung (2004) approachthe problem by using a cosine similarity measureto match foreign and English documents.
Theywork on ?very non-parallel corpora?.
They thengenerate all possible sentence pairs and select thebest ones based on a threshold on cosine simi-larity scores.
Using the extracted sentences theylearn a dictionary and iterate over with more sen-tence pairs.
Recent work by Munteanu and Marcu(2005) uses a bilingual lexicon to translate someof the words of the source sentence.
These trans-lations are then used to query the database to findmatching translations using information retrieval(IR) techniques.
Candidate sentences are deter-mined based on word overlap and the decisionwhether a sentence pair is parallel or not is per-formed by a maximum entropy classifier trainedon parallel sentences.
Bootstrapping is used andthe size of the learned bilingual dictionary is in-creased over iterations to get better results.Our technique is similar to that of (Munteanuand Marcu, 2005) but we bypass the need of thebilingual dictionary by using proper SMT transla-tions and instead of a maximum entropy classifierwe use simple measures like the word error rate(WER) and the translation edit rate (TER) to de-cide whether sentences are parallel or not.
Wealso report an extension of our work (Rauf andSchwenk, 2009) by experimenting with an addi-tional filter TERp, and building a named entitynoun dictionary using the unknown words fromthe SMT (section 5.2).
TERp has been tried en-couraged by the outperformance of TER in ourprevious study on French-English.
We have ap-plied our technique on a different language pairArabic-English, versus French-English that we re-ported the technique earlier on.
Our use of fullSMT sentences, gives us an added advantage ofbeing able to detect one of the major errors ofthese approaches, also identified by (Munteanuand Marcu, 2005), i.e, the cases where the initialsentences are identical but the retrieved sentencehas a tail of extra words at sentence end.
We dis-cuss this problem as detailed in section 5.1.We apply our technique to create a parallel cor-pus for the Arabic/English language pair.
Weshow that we achieve significant improvementsin the BLEU score by adding our extracted cor-pus to the already available human-translated cor-pora.
We also perform a comparison of the dataextracted by our approach and that by (Munteanuand Marcu, 2005) and report the results in Sec-tion 5.3.This paper is organized as follows.
In the nextsection we first describe the baseline SMT systemtrained on human-provided translations only.
Wethen proceed by explaining our parallel sentenceselection scheme and the post-processing.
Sec-tion 5 summarizes our experimental results andthe paper concludes with a discussion and perspec-tives of this work.2 Task DescriptionIn this paper, we consider the translation fromArabic into English, under the same conditions asthe official NIST 2008 evaluation.
The used bi-47texts include various news wire translations1 aswell as some texts from the GALE project.2 Wealso added the 2002 to 2005 test data to the paral-lel training data (using all reference translations).This corresponds to a total of about 8M Arabicwords.
Our baseline system is trained on these bi-texts only.We use the 2006 NIST test data as developmentdata and the official NIST 2008 test data as in-ternal test set.
All case sensitive BLEU scoresare calculated with the NIST scoring tool with re-spect to four reference translations.
Both data setsinclude texts from news wires as well as news-groups.LDC provides large collections of monolingualdata, namely the LDC Arabic and English Giga-word corpora.
There are two text sources that doexist in Arabic and English: the AFP and XIN col-lection.
It is likely that each corpora contains sen-tences which are translations of the other.
We aimto extract those.
We have used the XIN corpusfor all of our reported results and the collectionof the AFP and XIN for comparison with ISI.
Ta-ble 1 summarizes the characteristics of the corporaused.
Note that the English part is much largerthan the Arabic one (we found the same to be thecase for French-English AFP comparable corporathat we used in our previous study).
The numberof words are given after tokenization.Source Arabic EnglishAFP 138M 527MXIN 51M 140MTable 1: Characteristics of the available compara-ble Gigaword corpora for the Arabic-English task(number of words).3 Baseline SMT systemThe goal of statistical machine translation (SMT)is to produce a target sentence e from a source sen-tence f .
It is today common practice to use phrasesas translation units (Koehn et al, 2003; Och andNey, 2003) and a log linear framework in orderto introduce several models explaining the transla-tion process:e?
= argmax p(e|f)1LDC2003T07, 2004E72, T17, T18, 2005E46 and2006E25.2LDC2005E83, 2006E24, E34, E85 and E92.= argmaxe{exp(?i?ihi(e, f))} (1)The feature functions hi are the system modelsand the ?i weights are typically optimized to max-imize a scoring function on a development set(Och and Ney, 2002).
In our system fourteenfeatures functions were used, namely phrase andlexical translation probabilities in both directions,seven features for the lexicalized distortion model,a word and a phrase penalty and a target languagemodel (LM).The system is based on the Moses SMT toolkit(Koehn et al, 2007) and constructed as follows.First, Giza++ is used to perform word alignmentsin both directions.
Second, phrases and lexical re-orderings are extracted using the default settingsof the Moses SMT toolkit.
The target 4-gramback-off language model is trained on the Englishpart of all bitexts as well as the whole English Gi-gaword corpus.4 System ArchitectureThe general architecture of our parallel sentenceextraction system is shown in figure 1.
Startingfrom comparable corpora for the two languages,Arabic and English, we first translate Arabic toEnglish using an SMT system as described in theabove sections.
These translated texts are thenused to perform information retrieval from theEnglish corpus, followed by simple metrics likeWER, TER or TERp to filter out good sentencepairs and eventually generate a parallel corpus.We show that a parallel corpus obtained using thistechnique helps considerably to improve an SMTsystem.4.1 System for Extracting Parallel Sentencesfrom Comparable CorporaWe start by translating the Arabic XIN and AFPtexts to English using the SMT systems discussedin section 2.
In our experiments we consideredonly the most recent texts (2001-2006, 1.7M sen-tences; about 65.M Arabic words for XIN ).
Forour experiments on effect on SMT quality we useonly the XIN corpus.
We use the combinationof AFP and XIN for comparison of sentences ex-tracted by our approach with that of (Munteanuand Marcu, 2005).
These translations are thentreated as queries for the IR process.
The designof our sentence extraction process is based on theheuristic that considering the corpus at hand, we48ENSMTused as queries per day articles candidate sentence pairs parallel sentences+?5 day articlesfrom English GigawordEnglishtranslationstailremovalsentences withextra words at ends+parallelnumber / tablecomparison      lengthremovingArabiccomparablecorpusARWER/TER/TERpFigure 1: Architecture of the parallel sentence extraction system.can safely say that a news item reported on day Xin the Arabic corpus will be most probably foundin the day X-5 and day X+5 time period.
We ex-perimented with several window sizes and foundthe window size of is to be the most accurate interms of time and the quality of the retrieved sen-tences.
(Munteanu and Marcu, 2005) have alsoworked with a ?5 day window.Using the ID and date information for each sen-tence of both corpora, we first collect all sentencesfrom the SMT translations corresponding to thesame day (query sentences) and then the corre-sponding articles from the English Gigaword cor-pus (search space for IR).
These day-specific filesare then used for information retrieval using a ro-bust information retrieval system.
The Lemur IRtoolkit (Ogilvie and Callan, 2001) was used forsentence extraction.The information retrieval step is the most timeconsuming task in the whole system.
The timetaken depends upon various factors like size of theindex to search in, length of the query sentenceetc.
To give a time estimate, using a ?5 day win-dow required 9 seconds per query vs 15 secondsper query when a ?7 day window was used.
Weplaced a limit of approximately 90 words on thequeries and the indexed sentences.
This choicewas motivated by the fact that the word alignmenttoolkit Giza++ does not process longer sentences.A Krovetz stemmer was used while building theindex as provided by the toolkit.
English stopwords, i.e.
frequently used words, such as ?a?
or?the?, are normally not indexed because they areso common that they are not useful to query on.The stop word list provided by the IR Group ofUniversity of Glasgow3 was used.The resources required by our system are min-imal : translations of one side of the comparablecorpus.
It has already been demonstrated in (Raufand Schwenk, 2009) that when using translationsas queries, the quality of the initial SMT is nota factor for better sentence retrieval and that anSMT system trained on small amounts of human-translated data can ?retrieve?
potentially good par-allel sentences.4.2 Candidate Sentence Pair SelectionThe information retrieval process gives us the po-tential parallel sentences per query sentence, thedecision of their being parallel or not needs to bemade about them.
At this stage we choose thebest scoring sentence as determined by the toolkitand pass the sentence pair through further filters.Gale and Church (1993) based their align programon the fact that longer sentences in one languagetend to be translated into longer sentences in theother language, and that shorter sentences tend tobe translated into shorter sentences.
We initiallyused the same logic in our selection of the candi-date sentence pairs.
However our observation wasthat the filters that we use, WER, TER and TERpimplicitly place a penalty when the length differ-3http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words49ence between two sentences is too large.
Thus us-ing this inherent property, we did not apply anyexplicit sentence length filtering.The candidate sentences pairs are then judgedbased on simple filters.
Our choice of filtersin accordance to the task in consideration werethe WER (Levenshtein distance), Translation EditRate (TER) and the relatively new Translation EditRate plus (TERp).
WER measures the numberof operations required to transform one sentenceinto the other (insertions, deletions and substitu-tions).
A zero WER would mean the two sen-tences are identical, subsequently lower WER sen-tence pairs would be sharing most of the commonwords.
However two correct translations may dif-fer in the order in which the words appear, some-thing that WER is incapable of taking into ac-count.
This shortcoming is addressed by TERwhich allows block movements of words and thustakes into account the reorderings of words andphrases in translation (Snover et al, 2006).
TERpis an extension of Translation Edit Rate and wasone of the top performing metrics at the NISTMetric MATR workshop 4.
It had the highest ab-solute correlation, as measured by the Pearson cor-relation coefficient, with human judgments in 9of the 45 test conditions.
TERp tries to addressthe weaknesses of TER through the use of para-phrases, morphological stemming, and synonyms,as well as edit costs that are optimized to corre-late better with various types of human judgments(Snover et al, 2009).
The TER filter allows shiftsif the two strings (the word sequence in the trans-lated and the IR retrieved sentence) match exactly,however TERp allows shifts if the words beingshifted are exactly the same, are synonyms, stemsor paraphrases of each other, or any such combi-nation.
This allows better sentence comparisonby incorporation of sort of linguistic informationabout words.5 Experimental evaluationOur main goal was to be able to create an addi-tional parallel corpus to improve machine transla-tion quality, especially for the domains where wehave less or no parallel data available.
In this sec-tion we report the results of adding these extractedparallel sentences to the already available human-translated parallel sentences.4http://www.itl.nist.gov/iad/mig//tests/metricsmatr/2008/#words BLEUBitexts Arabic Eval06 Eval08Baseline 5.8M 42.64 39.35+WER-10 5.8M 42.73 39.70+WER-40 7.2M 43.34 40.59+WER-60 14.5M 43.95 41.20+WER-70 20.4M 43.58 41.18+TER-30 6.5M 43.41 40.08+TER-50 12.5M 43.90 41.45+TER-60 17.3M 44.30 41.73+TER-75 24.1M 43.79 41.21+TERp-10 5.8M 42.69 39.80+TERp-40 10.2M 43.89 41.44+TERp-60 20.8M 43.94 41.25+TERp-80 27.7M 43.90 41.58Table 2: Summary of BLEU scores for the bestsystems selected based on various thresholds ofWER, TER and TERp filtersWe conducted a range of experiments by addingour extracted corpus to various combinations ofalready available human-translated parallel cor-pora.
For our experiments on effect on SMT qual-ity we use only the XIN extracted corpus.
Weexperimented with WER, TER and TERp as fil-ters to select the best scoring sentences.
Table 2shows some of the scores obtained based on BLEUscores on the Dev and test data as a function ofthe size of the added extracted corpus.
The nameof the bitext indicates the filter threshold used, forexample, TER-50 means sentences selected basedon TER filter threshold of 50.
Generally, sen-tences selected based on TER filter showed bet-ter BLEU scores on NIST06 than their WER andTERp counter parts up to almost 21M words.
Alsofor the same filter threshold TERp selected longersentences, followed by TER and then WER, thisfact is evident from table 2, where for the fil-ter threshold of 60, TERp and TER select 20.8Mand 17.3 words respectively, whereas WER selects14.5M words.Figure 2 shows the trend obtained in functionof the number of words added.
These experimentswere performed by adding our extracted sentencesto only 5.8M words of human-provided transla-tions.
Our best results are obtained when 11.5Mof our extracted parallel sentences based on TERfilter are added to 5.8M of News wire and gale par-allel corpora.
We gain an improvement of 1.66BLEU points on NIST06 and 2.38 BLEU points5041.54242.54343.54444.5455  10  15  20  25  30BLEUscoreonnist06Arabic words for training [M]baselineTERTERpWER38.53939.54040.54141.5425  10  15  20  25  30BLscoreonnist08Arabic words for training [M]baselineTERTERpWERFigure 2: BLEU scores on the NIST06 (Dev,top) and NIST08 (test, bottom) data using anWER,TER or TERp filter as a function of the num-ber of extracted Arabic words added.on NIST08 (TER-60 in table 2 ).An interesting thing to notice in figure 2 is thatno filter was able to clearly outperform the others,which is contradictory to our experiments with theFrench-English language pair (Rauf and Schwenk,2009), where the TER filter clearly outperformedthe WER filter.
WER is worse than TER but lessevident here than for our previous experiments forthe French-English language pair.
This perfor-mance gain by using the TER filter for French-English was our main motivation for trying TERp.We expected TERp to get better results comparedto WER and TER, but TER filter seems the betterone among the three filters.
Note that all condi-tions in all the experiments were identical.
Thisgives a strong hint of language pair dependency,making the decision of suitability of a particularfilter dependent on the language pair in considera-tion.5.1 Sentence tail removalTwo main classes of errors are known when ex-tracting parallel sentences from comparable cor-pora: firstly, cases where the two sentences sharemany common words but actually convey differ-ent meaning, and secondly, cases where the twosentences are (exactly) parallel except at sentenceends where one sentence has more informationthan the other.
This second case of errors canbe detected using WER as we have the advan-tage of having both the sentences in English.
Wedetected the extra insertions at the end of the IRresult sentence and removed them.
Some exam-ples of such sentences along with tails detectedand removed are shown in figure 3.
Since thisgives significant improvement in the SMT scoreswe used it for all our extracted sentences (Raufand Schwenk, 2009).
However, similar to our ob-servations in the last section, the tails were muchshorter as compared to our previous experimentswith French-English, also most of the tails in thisArabic-English data were of type as shown in lastline figure 3.
This is a factor dependent on re-porting agency and its scheme for reporting, i.e,whether it reports an event independently in eachlanguage or uses the translation from one languageto the other .5.2 Dictionary CreationIn our translations, we keep the unknown words asthey are, i.e.
in Arabic (normally a flag is used sothat Moses skips them).
This enables us to build adictionary.
Consider the case with translation withone unknown word in Arabic, if all the other wordsaround align well with the English sentence thatwe found with IR, we could conclude the trans-lation of the unknown Arabic word, see figure 3line 5.
We were able to make a dictionary us-ing this scheme which was comprised mostly ofproper nouns often not found in Arabic-Englishdictionaries.
Our proper noun dictionary com-prises of about 244K words, some sample wordsare shown in figure 4.
Adding the proper nounsfound by this technique to the initial SMT sys-tem should help improve translations for new sen-tences, as these words were before unknown to thesystem.
However, the impact of addition of thesewords on translation quality is to be evaluated atthe moment.51Arabic:                           !
"855 #!"$% &' ()%% *!& .Query: Thousands of officials began counting the votes registered in tens of thousands of electronic machines in 855towns and cities across the country at 8 a.m.Result: Thousands of officials began counting the votes registered in tens of thousands of electronic machines in 855towns and cities across the country at 8 a.m. thursday.Arabic:               &+)* *, - %.
/(& 0&1$ " ,(2" * 3&1* 4 .Query: 5was referring to the current stalemate between his government and the Liberation Tigers of TamilEelam .Result: Wickremesinghe was referring to the current stalemate between his government and the Liberation Tigers ofTamil Eelam ( LTTE )   REBELS .Arabic:                %6 /17!.
 1#(" &1,87" 9: 4 !7" ;<2= " 2>4?  .Query: Bono adopted this position after some legislators asked the government to rethink the Spanish military presencein Afghanistan .Result: Bono adopted this attitude after some legislators asked the government to reconsider the Spanish militarypresence in Afghanistan .
( SPAIN-AFGHANISTAN ) .Figure 3: Some examples of an Arabic source sentence, the SMT translation used as query and thepotential parallel sentence as determined by information retrieval.
Bold parts are the extra tails at the endof the sentences which we automatically removed.Figure 4: Examples of some words found by ourdictionary building technique.5.3 Comparison with previous workLDC provides extracted parallel texts extractedwith the algorithm published by (Munteanu andMarcu, 2005).
This corpus contains 1.1M sen-tence pairs (about 35M words) which were auto-matically extracted and aligned from the mono-lingual Arabic and English Gigaword corpora, aconfidence score being provided for each sentencepair.
We also applied our approach on data pro-vided by LDC, but on a different subset.
Since wehad used the recent data sets our corpora were tillyear 2006, whereas ISI?s data were till year 2004.We filtered our data according to the time intervalof their data (date information was provided foreach sentence pair) and used them to compare thetwo data sets.
Both AFP and XIN were used inthese comparison experiments since the availableISI?s data was comprised of these two collections.To perform the comparison, we have, firstly,the ISI parallel sentences and secondly the paral-lel sentences extracted by using our approach us-ing the same time frame and comparable corporaas ISI.
We used our sentences as filtered by theTER filter and added them to the already avail-able 5.8M of human-translated (as done in previ-ous experiments).
The result is shown graphicallyin figure 5.
Adding the ISI parallel data to the5.8M baseline parallel corpus (total 27.5M words)yielded a BLEU score of 43.59 on NIST06 Devset and 41.84 BLEU points on NIST08 test set.Whereas we were able to achieve a BLEU score of43.88 on NIST06 Dev and 41.35 on NIST08 testset (using a total of 16.1M words), which amountsto an increase of 0.29 BLEU points on the NIST06Dev set.
Note that this gain is achieved by usinga total of only 10.3M of our extracted words ascompared to 21.7M of ISI corpus to get their bestresult.
However we were not able to improve asmuch on the NIST08 test corpus.The trend in BLEU score in figure 5 clearly524242.54343.54444.55  10  15  20  25  30BLEUscoreonnist06Arabic words for training [M]OurISI39.54040.54141.54242.55  10  15  20  25  30BLEUscoreonnist08Arabic words for training [M]OurISIFigure 5: BLEU scores on the NIST06 andNIST08 data using the ISI parallel corpus and ourcomparative extracted bitexts in function of num-ber of extracted Arabic words added.shows that our sentence selection scheme selectsgood sentences, and is capable of achieving thesame scores but with much less sentences.
Thisis because in the scheme of ISI, the confidencescores provided are based on the IR and maximumentropy classifier scoring scheme, whereas our fil-ters score the sentences based on linguistic sen-tence similarity, allowing us to retrieve the goodsentence pairs from the bad ones.
Once informa-tion retrieval is done, which is the most time con-suming task in both the techniques, our approachis better able to sort out the good IR extractedsentences as is evident from the results obtained.Moreover our scheme does not require any com-plex operations, just simple filters which are welladapted to the problem at hand.6 Conclusion and discussionSentence-aligned bilingual texts are a crucial re-source to build SMT systems.
For some languagepairs bilingual corpora just do not exist, the ex-isting corpora are too small to build a good SMTsystem or they are not of the same genre or do-main.
This need for parallel corpora, has made theresearchers employ new techniques and methodsin an attempt to reduce the dire need of this cru-cial resource of the SMT systems.
Our study alsocontributes in this regard by employing an SMTitself and information retrieval techniques to pro-duce additional parallel corpora from easily avail-able comparable corpora.We use translations of the source language com-parable corpus to find the corresponding paral-lel sentences from the target language compa-rable corpus.
We only used a limited amountof human-provided bilingual resources.
Startingwith small amounts of sentence aligned bilingualdata large amounts of monolingual data are trans-lated.
These translations are then employed to findthe corresponding matching sentences in the tar-get side corpus, using information retrieval meth-ods.
Simple filters are used to determine whetherthe retrieved sentences are parallel or not.
Byadding these retrieved parallel sentences to al-ready available human translated parallel corporawe were able to improve the BLEU score on thetest set(NIST08) by 2.38 points for the Arabic-English language pair.Contrary to the previous approaches as in(Munteanu and Marcu, 2005) which used smallamounts of in-domain parallel corpus as an initialresource, our system exploits the target languageside of the comparable corpus to attain the samegoal, thus the comparable corpus itself helps tobetter extract possible parallel sentences.
We havealso presented a comparison with their approachand found our bitexts to achieve nice improve-ments using much less words.
The LDC com-parable corpora were used in this paper, but thesame approach can be extended to extract parallelsentences from huge amounts of corpora availableon the web by identifying comparable articles us-ing techniques such as (Yang and Li, 2003) and(Resnik and Y, 2003).We have successfully ap-plied our approach to French-English and Arabic-English language pairs.
As this study stronglyhinted towards language pair dependancy on thechoice of the filter to use to select better sentences,we intend to investigate this trend in detail.53ReferencesPascale Fung and Percy Cheung.
2004.
Mining very-non-parallel corpora: Parallel sentence and lexiconextraction via bootstrapping and em.
In DekangLin and Dekai Wu, editors, EMNLP, pages 57?63,Barcelona, Spain, July.
Association for Computa-tional Linguistics.William A. Gale and Kenneth W. Church.
1993.
Aprogram for aligning sentences in bilingual corpora.Computational Linguistics, 19(1):75?102.Hiroyuki Kaji.
2003.
Word sense acquisition frombilingual comparable corpora.
In NAACL ?03: Pro-ceedings of the 2003 Conference of the North Amer-ican Chapter of the Association for ComputationalLinguistics on Human Language Technology, pages32?39, Morristown, NJ, USA.
Association for Com-putational Linguistics.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrased-based machine translation.In HLT/NACL, pages 127?133.Philipp Koehn et al 2007.
Moses: Open source toolkitfor statistical machine translation.
In ACL, demon-stration session.Dragos Stefan Munteanu and Daniel Marcu.
2005.
Im-proving machine translation performance by exploit-ing non-parallel corpora.
Computational Linguis-tics, 31(4):477?504.Douglas W. Oard.
1997.
Alternative approaches forcross-language text retrieval.
In In AAAI Sympo-sium on Cross-Language Text and Speech Retrieval.American Association for Artificial Intelligence.Franz Josef Och and Hermann Ney.
2002.
Discrimina-tive training and maximum entropy models for sta-tistical machine translation.
In ACL, pages 295?302.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignementmodels.
Computational Linguistics, 29(1):19?51.Paul Ogilvie and Jamie Callan.
2001.
Experimentsusing the Lemur toolkit.
In In Proceedings of theTenth Text Retrieval Conference (TREC-10), pages103?108.Reinhard Rapp.
1995.
Identifying word translations innon-parallel texts.
In Proceedings of the 33rd an-nual meeting on Association for Computational Lin-guistics, pages 320?322, Morristown, NJ, USA.
As-sociation for Computational Linguistics.Sadaf Abdul Rauf and Holger Schwenk.
2009.
On theuse of comparable corpora to improve SMT perfor-mance.
In EACL, pages 16?23.Philip Resnik and Noah A. Smith Y.
2003.
The webas a parallel corpus.
Computational Linguistics,29:349?380.Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-nea Micciulla, and John Makhoul.
2006.
A study oftranslation edit rate with targeted human annotation.In ACL.Matthew Snover, Bonnie Dorr, and Richard Schwartz.2008.
Language and translation model adaptationusing comparable corpora.
In Proceedings of the2008 Conference on Empirical Methods in Nat-ural Language Processing, pages 857?866, Hon-olulu, Hawaii, October.
Association for Computa-tional Linguistics.Matthew Snover, Nitin Madnani, Bonnie Dorr, andRichard Schwartz.
2009.
Fluency, adequacy, orHTER?
Exploring different human judgments witha tunable MT metric.
In Proceedings of the FourthWorkshop on Statistical Machine Translation, pages259?268, Athens, Greece, March.
Association forComputational Linguistics.Richard Sproat, Tao Tao, and ChengXiang Zhai.
2006.Named entity transliteration with comparable cor-pora.
In ACL-44: Proceedings of the 21st Interna-tional Conference on Computational Linguistics andthe 44th annual meeting of the Association for Com-putational Linguistics, pages 73?80, Morristown,NJ, USA.
Association for Computational Linguis-tics.Masao Utiyama and Hitoshi Isahara.
2003.
Reliablemeasures for aligning Japanese-English news arti-cles and sentences.
In Erhard Hinrichs and DanRoth, editors, ACL, pages 72?79.Christopher C. Yang and Kar Wing Li.
2003.
Auto-matic construction of English/Chinese parallel cor-pora.
J.
Am.
Soc.
Inf.
Sci.
Technol., 54(8):730?742.54
