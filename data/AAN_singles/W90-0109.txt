Abstract Linguistic Resources for Text PlanningMar ie  W.  MeteerBBN Systems & Technologies Corporation10 Moulton StreetCambridge, Massachusetts 02138MMETEER@BBN.COMAbstractIn this paper, I define the notion of an abstractlinguistic resource which reifies as a term for use bythe text planner just those combinations of concretelinguistic resources (the words, morphologicalmarkings, syntactic structures, etc.
that actuallyappear in a stream of text) that are expressible.
Ipresent a representational level, the Text Structure,which is defined in these abstract linguistic termsand which mediates and constrains the commitmentsof a text planner to ensure that the utterance beingplanned will be expressible in language.1.
IntroductionNatural language generation is the deliberate productionof text to meet the communicative goals of someunderlying application program.
It consists of thefollowing major activities: (1) determining whatinformation is to be communicated, (2) imposing asuitable order on the elements of this informationconsistent with the constituent structure of language andexpressing the relative salience and newness of theelements, and (3) determining what wording and syntacticconstructions touse.
The first two of these activitiesare generally considered "text planning" and its output isthe "plan".
The third activity is "realization" andgenerally handles all of the linguistic decision making.While it is recognized that his division is problematic(Hovy, et al 1988), nearly all generation systems todaymake this division.
One of the chief accomplishmentsof my work has been to bridge the gap between thesetwo activities through the introduction of a newrepresentational level that simplifies both theirresponsibilities.
It both provides the choices available tothe text planner to allow it to take advantage of theexpressiveness of natural anguage and, through thatcontrol of the choices, prevents it from composing anutterance that is not expressible in the language.Most state of the art text planning systems follow acommon design (see for example McKeown 1985, Derr& McKeown 1984, Paris 1987, or Hovy 1988).
Theystart from a set of propositions, each typically verb-basedand able to be realized independently as a simplesentence.
Then they organize the propositions into acoherent discourse by combining them according to thedictates of predefined "schemas" representing plausiblediscourse relationships.
Subsequent choices of concretesurface resources 1 are all local to the propositions andnot sensitive to the schemas or other context, except forthe discourse-level connectives used in combining thepropositions into complex sentences and occasionally ashallow discourse history governing the use of pronouns.In these approaches to natural language generationthere is a gap between the plan, which is usuallyrepresented in the terms of the application program, andthe resources used by the realization component tocarryout that plan, which are the concrete words, syntax,morphemes, etc.
The gap occurs because the textplanner selects units from the application program andorganizes them without simultaneously considering whatlinguistic resources are available for expressing them.These systems thus have no principled way of ensuringthat heir message isexpressible in language.Of course, they do successfully produce texts: theyensure their plans are expressible by accepting limits totheir expressive competence, .g.
each atomic unit in theplan is required to be a proposition, and thus can alwaysbe realized as a clause.
Each unit can be independentlytranslated into language using the linguistic realizationcomponent since there are few restrictions on theconnection between clauses.
Clauses can be connectedwith coordinate or subordinate conjunctions (e.g.
"and","because") or simply made into separate sentences.However, this kind of approach does not takeadvantage of the full expressive power of language, inwhich units can be much more tightly composed.
Inorder to exercise the full expressiveness of language, textplanning needs to address the internal composition ofclauses and not just their organization into largerstructures.
Clauses in actual texts reflect a combinationof multiple atomic units.
Systems that ignore this andbegin with units that are inevitably realized as kernelclauses (e.g.
Mann & Moore 1981, Derr & McKeown1984, Hovy 1988) have two major deficiencies: (1) theyare presuming underlying programs have units of thissize that may be simply selected for inclusion in themessage and then realized intact, and (2) they are under-utilizing the power of natural language, which can usecomplex noun phrases, nominalizations, adverbialphrases, and other adjuncts to pack information frommultiple units into one clause.1 The surface linguistic resources arc all the syntacticstructures, words, and grammatical features ofthe languageavailable to the speaker.62Moreover, the process of composing multiple unitsinto one clause is a much more complex problem thansimply ordering propositions in a text plan.
Whatcompositions are possible depends on what linguisticresources are available to realize the units involved.
Forexample, an Army battalion that has been assigned adefensive mission can be said to be "defending", but ifwe say that a battalion that has been assigned anoffensive mission is "offending" we mean somethingvery different.
There is no comparable r source availableto fit that textual niche and either a different, morecomplex resource must be used or the whole text changed(e.g.
"attack".
Furthermore, different types of resourceshave different constraints on their composition: one can"make an important decision", but one cannot "decideimportantly".In this paper, I address the problem of how we canconstrain the actions of a text planner to ensure that itwill never compose an utterance that cannot be realizedand can still make use of the full expressive power oflanguage.
To do this, I introduce the notion of anabstract linguistic resource which groups together as thereified terms to be used by the planner just thosecombinations of concrete linguistic resources that areexpressible.
I have defined a level of representation interms of these abstract resources, the Text Structure,which is used by the text planner to state its "plan".This intermediate l vel of representation bridges the"generation gap" between the representation f the worldin the application program and the linguistic resourcesprovided by the language.The terms and expressions in the Text Structure areabstractions over the concrete resources of language.They provide the text planner with terms that define thepossible combinations of features that express thesemantic ategories available in the language, such asevent, process, or instance-of-a-kind.
By providing thetext planner with a set of semantic categories, rather thanletting it freely choose from the individual inguisticfeatures that define the categories, the planner isprevented from choosing a combination of features thatis not realizable.
These abstractions in Text Structurefurther constrain the composition of the utterance bydefining what kinds of constituents can be extended andhow the semantic categories can compose.In this paper, I define the notion of an abstractlinguistic resource for text planning by looking at (1)what are the concrete resources that he language providesand what are their abstract properties, and (2) which ofthose properties are appropriate to a text planner tryingto compose an utterance from an application program.
Ithen show a preliminary set of abstractions which is usedin the text planner of the Spokesman generation system.This set was arrived at by both applying research resultsfrom linguistics and lexical semantics and empirically byconnecting the generation system to an applicationprogram and producing text.
The long range challengeof this work will be the continued evelopment andrefinement of this vocabulary of abstract linguistic termsto cover the full expressive power of natural anguageand determining the compositional constraints whichwill maintain the expressibility criteria.2.
L ingu is t i c  ResourcesIn this section, I address the question of what thelinguistic resources are and what abstractions we can andshould make over them.
I begin by looking at theconcrete resources, that is, those that actually appear in astream of text.
I then look at what various complexes ofthese resources express taken as a group.
In Section 2.3,I look more generally at how work in linguistics canhelp develop amore complete vocabulary of abstractions.2.1  The concrete resources of languageThe concrete linguistic resources are all the syntacticstructures, words, and grammatical features available tothe speaker of the language.
We can divide linguisticresources into two general classes:?
The lexical resources: These are what are oftencalled the open class words (the nouns, verbs, andadjectives), and they carry most of the content.?
The grarnrnatical resources: These include the closedclass words, morphological markings, and phrasestructure.In what follows we ground the notion of concreteresources by looking closely at one fairly simplesentence:Karen likes watching movies.This sentence has lexical resources, uch as "Karen" and"watch", and morphological resources, such as "-ing",the gerund marker on the verb "watch" which emphasizesthe process aspect of the action, and "-s", the pluralmarker on the noun "movie".
The phrase structure isalso a concrete resource, which expresses how theconstituents group together and certain kinds of relationsbetween them; in this example, the phrase structure tellsus that "movies" are what is watched, that "watchingmovies" is what is liked, and that "Karen" is the one thatlikes watching movies.What is not there also expresses information.
The factthat there is no determiner Ca" or "the") with "movies"indicates that it is not a particular set of movies beingreferred to (as in "the movies") but a general sample ofmovies.
Note that it is not just the lack of thedeterminer that provides this information, but thefeatures of the whole constituent the particular noun is inand the fact that it is plural: if the noun phrase weresingular, then there would have to be a determiner before"movie" (*"Karen likes watching movie").
For othernouns in head position, the lack of a determiner canmean other things.
For example, there is also nodeterminer in the first noun phrase in the sentenceCKaren"); however, in this case, since the head is aproper noun, it does refer to a unique individual.
If adeterminer is used with a proper noun, it has a more63general meaning of "an entity with that name" (as in"All the Karens I had ever met had dark hair and then Imet a Karen with red hair").We will term this kind of composition, where thesame resource means different things in differentcontexts, "non-linear" composition; this is in contrast to"linear" composition, where each resource contributes anidentifiable part of the whole and what it contributes inot context dependent.
The identification of whichgrammatical resources non-linearly co-occur andgrouping those sets into single/tbstract resources is apowerful method of constraining the text planner to keepits choices only those that are expressible in language, aswe shall see in the next section where we developabstraction resources for the sets of concrete resourcesthat appear in the example.2.2 Abstract ions over  concrete resourcesAllowing a generation system to select concreteresources directly, as is done in virtually all othergeneration systems, makes available many more degreesof freedom than the language actually permits.
As wesaw in the previous section, some combinations ofconcrete resources occur in language, while others donot.
Furthermore, we saw that the combination of thelexical resource in the head of a constituent and thegrammatical resources in the constituent as a whole cancombine non-linearly, so that the choice of the lexicaland grammatical resources cannot be made independentlyof each other.In this section, we look at how we can abstract overcombinations of concrete resources by treating aparticular set as a whole and naming it, rather thantreating the resources as a set of independent features thathappen to have appeared together.
The vocabulary ofabstractions we derive then becomes the terms in whichthe text planner makes its decisions.
It is incapable ofselecting a set of resources that is not expressiblebecause it is not allowed to choose them independently.For example, the two noun phrase constituents in ourexample CKaren" and "movies"), express two differentperspectives on the entities they refer to.
"Karen" isexpressed with the perspective NAMED-INDIVIDUAL and"movies" is expressed as a "SAMPLE-OF-A-KIND".2 Wecan think of these perspectives as semant iccategor ies ;  "semantic" because they representsomething about the meaning of a constituent, not justits form, e.g.
"Karen" is referring to a person as a uniqueindividual with a name, in contrast to referring to her asan anonymous individual (e.g.
"a woman").
A surfaceconstituent can then be abstractly represented in the Text2 "Sample" intended to mean "indefinite set"; the choice ofnames for categories i meant to be evocative of what heymean, while staying away from terms that have specialmeanings in other theories.
Within Text Structure, these termsonly need to be consistent.
The names themselves do no work,except to help the observer understand the system.Structure for the purposes of the text planner as thecombination of a lexical item and a semantic ategory.Figure 1 shows the "abstract" resources for the twonoun phrases of our example and the other constituentsof our sentence: Karen Likes watching movies.
3The upward arrows begin at the surface constituentbeing abstracted over and point to the boxes showingabstract resources: the lexical item in italics andsemantic ategory following it.
This tree of boxes is anexample of the Text Structure intermediate level ofrepresentation.
We will return to how to develop acomplete set of semantic ategories in the next section.In addition to abstracting over combinations ofconcrete resources by only representing the semantic typeof a constituent, we can also represent the structural(syntactic) relations between the constituents.
In Figure1 the concrete relations of subject, direct object, etc.
arerepresented abstractly as arguments and marked with asemantic relation.
4In this example, we have identified three kinds ofinformation that are essential to an abstractrepresentation of the concrete resources languageprovides:?
the constituency,?
the semantic ategory of the constituent, and?
the structural relations among the constituents.In the next section we look at some of the motivationsfor these abstractions, and in Section 3, show how theycan be used for text planning.3 The notation of the phrase structure in the diagram is thenotation used in the linguistic component Mumble-86.
Whileit is slightly unconventional in that it explicitly represents hepath that wiU be followed in traversing the structure, it is inother espects fairly standard in its terminology.
I use it heresince it is the notation I work with and because it lends aconcreteness and reality to the diagrams ince this is thestructure the linguistic omponent will actually build whengenerating this sentence.4 The semantic relations hown here, "agent" and "patient", arecapturing internally consistent relations.
They are notattempting to carry the kind of weight and meaning as, say, theterms in theta-theory.64L/ke::State~.
I ~Gu1/mNT I 11 \  i Agc~ENT i.
~?\[F\]~oy!
5g~t.
I I ~ I Arg-relation: Patient II I II I ~u~ \[\[ J/ I "?'/~S'a?e~?
:":t'~ _  Karen \[VERB\] ~ \[COMPLEMENT\]likes VP\[VERB\] ~ \[D-OBJEwatch/.g .~,,.,~\[NP-hq~movi,Figure 12.3 Developing a set of abstractionsThe development of the full vocabulary of particularabstract resources is an ongoing process.
Themotivation for determining the abstractions comes fromanalysis of the language and what is expressible.
A greatdeal of work has already been done in linguistics that cancontribute to defining the vocabulary of abstractions.
Inthis section, I look at the work of four linguists inparticular who have influenced my development of thecurrent set of semantic ategories: Jackendoff, Talmy,Pustejovsky, and Grimshaw.
While their work is verydifferent in character, all explore regularities in languageusing a more semantic than syntactic vocabulary.The notion of a semantic ategory used here wasinitially influenced by the work of Jackendoff (1983)who makes the following claim about he relationshipbetween language structure and meaning:Each contentful major syntactic constituent of asentence maps into a conceptual constituent in themeaning of the sentence.
5Included in his vocabulary of conceptual categories areThing, Path, Action, Event, and Place.Abstractions over concrete resourcesHowever, while Jackendoffs categories are useful inthat they span the entire language (since they areprojections from the syntactic ategories), they are notdiscriminatory enough to capture the constraintsnecessary toensure xpressibility.
For example, two ofthe semantic ategories in the example above, NAMED-INDIVIDUAL and SAMPLE-OF-A-KIND, are subsumed bythe same category in JackendoWs set, OBJECT.Similarly, his category EVENT has finer distinctionsavailable in the actual resources: a finite verb (onewhich expresses tense) with its arguments expresseswhat I call an EVENT (Peter decided to go to the beach),whereas anonfinite verb can express ageneric ACTIVITY(to decide to go to the beach).
Nominalizations make theevent or activity into an OBJECT and different forms ofnominalizations can pick out different aspects of theevent, such as the PROCESS (Deciding to go to thebeach took Peter all morning) or the RESULT (Thedecision to go to the beach caused controversy).Figure 2 shows a partial hierarchy of semanticcategories that reflects these distinctions.5 Jackendoff, 1983, p. 76.EV\]Time-Anchored-Event /C"Transition-Event StateProcess-Event~NTObjectResult-ObjectActivityProcess-ActivityFigure 2 Partial hierarchyIn using these finer semantic categories in theplanning vocabulary for generation, we are making astronger claim than JackendoWs, namely that thesecategories define what combinations of surface resourcesare possible in the language.
For example, anACTIVITY cannot have a tense marker, since bydefinition it is not grounded in time.
The categoriesalso serve to constrain how constituents are composed.For example, if we choose the EVENT perspective ( .g.Michael decided to go to the beach), we can add anadjunct of type MANNER to it (Michael quicklydecided to go to the beach) but we cannot add an adjunctof type PROPERTY (*Michael important(ly) decidedto go to the beach) 6.
However, if we choose anOBJECT perspective (Michael made a decision), thePROPERTY adjunct oan be added (Michael made animportant decision ).
Both perspectives are available,and the text planner's choice must be consistent withthe kinds of adjunctions it intends to make.Research in lexical semantics has contributed a greatdeal to defining these finer grained semantic ategories.Talmy's (1987) extensive cross language researchresulted in a set of categories for the notions expressedgrammatically in a language.
Pustejovsky's (1989)Event Semantic Structure makes a three way distinctionof event types (state, process, transition) which bothcaptures the effects of nonlinear composition ofresources and provides constraints on the compositionof these types with other resources.
Grirnshaw'sanalysis of nominals (1988) contributed to thedefinition of object types which convey particularperspectives on events, such as result and process.3.
Using Abstract Resources for TextPlanningIn order to plan complex utterances and ensure they areexpressible in language, i.e.
can be successfully realizedas grammatical utterances, the text planning process6 Following the general convention i  linguistics, we use a"*" to mark ungrammatical sentences, and a "?"
to markquestionable ones.Proc~s-ObjectEvent-Activityof semantic categoriesmust know (1) what realizations are available to anelement, that is, what resources are available for it, (2)the constraints on the composition of the resources, and(3) what has been committed to so far in the utterancethat may constrain the choice of resource.
The first twopoints are addressed by the the use of abstract linguisticresources discussed in the previous ection.
The third isaddressed by the ongoing Text Structure representationof the utterance being planned, which is also in abstractlinguistic terms.
In this section, I describe the TextStructure and how it mediates and constrains the textplanning process.3.1 Text Structure 7Text Structure is a tree in which each node represents aconstituent in the utterance being planned.
Figure 3shows an example of the Text Structure representationfor the utterance: "Karen likes watching movies onSundays".Text Structure represents he following information:Constituency: The nodes in the Text Structure treereflect the constituency of the utterance.
Aconstituent may range in size from a paragraph to asingle word.Structural  relat ions among constituents: Eachnode is marked with its structural relation to itsparent (the top label) and to its children (thebottom label on nodes with children).
Structuralrelations indicate where the tree can be expanded:composite nodes may be incrementally extendedwhereas a head/argument structure is built in asingle action by the planner, reflecting theatomicity of predicate/argument structure.7 Note that I will not attempt aformal definition.
I agreewith the text linguist Beaugrande that "Formalism should notbe undertaken too early.
Unwieldy constructs borrowed frommathematics and logic are out of place in domains where thebasic concepts are still highly approximative.
Such constructsgive a false sense of security of having explained what has infact only been rewritten i  a formal anguage."
Beaugrande &Dressier, 1981, p.14.66/ARGUMENTArg-relation: AgentKaren ::Named- individualMATRIXL/ke::StateHEADARGUMENTArg-relation: PatientactivityCOMPOSITEf rollMATRIXWatch ::ActivityHEAD/iI ARGUMENTArg-relation: Patientmov/e ::Sample-of-a-kindi iFigure 3 Text Structure for "Karen likesSemantic category the constituent expresses:The labels in the center of the node (in bold) showthe lexical head (when applicable, in italics) and thesemantic category the constituent expresses.3.2 Using the Text Structure for TextPlanningThe abstract linguistic terms of our planning vocabularycan provide constraints on the composition of themessage to ensure that it will continue to be expressibleas we add more information.
For example, the semanticcategory of a constituent can constrain the kind ofinformation that can be composed into that constituent.Consider the earlier example contrasting "decide" and"make a decision", where in order to add an adjunct oftype PROPERTY, the RESULT perspective of theEVENT must be explicit in the utterance, as shown inFigure 4.In summary, the Text Structure can constrain thefollowing types of decisions within the text planner:?
where additional information may be added (e.g.structure can only he added at leaves and nodes oftype COMPOSITE; furthermore, in an incrementalpipeline architecture such as this, information canonly be added ahead of the point of speech)?
what functions and positions are available for theelements being added in (e.g.
matrix or adjunc0?
what form the added element must be in (e.g.
anobject of type property can be added to a thing butnot to an event)ADJUNCTon ::temporal-relationHEAD\ARGUMENT Isunday ::sample-of-a-kindwatching movies on Sundays"The Text Structure representation is used in the textplanner of my SPOKESMAN generation system (Meteer1989).
It serves as an intermediate r presentationbetween a variety of application programs and thelinguistic realization component Mumble-86(McDonald 1984, Meteer, et.al 1987).
Portions of theoutputs for three of these applications are shown below.THE MAIN STREET SIMULATION PROGRAM(ABRE'rr, ET AL 1989)Karen 10:49 AM: Karen is at International-conglomerate, which is at 1375 Main Street.
Herskills are managing and cooking.
Karen likeswatching movies.
She watched "The LadyVanishes" on Sunday.SEMI-AUTOMATED FORCES (SAF) PROJECT 8C/1 TB is to the east and its mission is to attackObjective GAMMA from ES646905 to ES758911at 141423 Apr.
All TB is to the south.
B/1 TBand HHC/2 are to the east.AIRLAND BATrLE MANAGEMENT PROJECT 9Conduct covering force operations along avenues Band C to defeat he lead regiments of the firsttactical echelon in the CFA in assigned sector.8 SAF is part of DARPA's SIMNET project, contractnumber MDA972-89-0600.9 Sponsorship of ALBM is by the Defense Advanced ResearchProjects Agency, the US Army Ballistic Research Laboratory,and the US Army Center for Communications, contractnumber DAAA15-87-C-0006.67I COMPLEX-EVENTCOMPOSITE/DECIDE=EVENT HEAD / \MICHAEL: :INDIVIDUALII ADJUNCTIMPORTANT: :PROPERTY"Michael decided ..."COMPLEX-EVENT ICOMPOSITE/I MATRIXMAKE::EVENT HEAD /ARGUMENTMICHEAL::INDIVIDUALI MATRIXDECISION::OBJECT\ARGUMENT \]DECISION::RESULTCOMPOSITEIMPORTANT=PROPERTY"Michael made an important decision"Figure 44.
Contrasting ApproachesThe greatest difference between other approaches to NLGand ours is that they work directly in terms of concreteresources rather than introducing an abstract intermediatelevel as I have proposed here.
Approaches fall into twoclasses: (1) those that use a two component architecturein which a text planner chooses and organizes theinformation to be expressed and passes it to a separatelinguistic component that chooses the concrete resourcesto express the plan (e.g.
McKeown 1985, Paris 1987, orHovy 1988); and (2) those that use a single componentwhich does the planning of the text directly in terms ofthe concrete resources (e.g.
Nirenburg et al 1989,Danlos 1987).The limitation of the two component architecture isthat the text planner is not working in linguistic terms,and so it cannot be sure that the plan it builds isexpressible, i.e.
can have a successful realization.
Mostsuch systems avoid this problem by limiting theexpressiveness of the system overall.
The plannerbegins with a set of propositions, each verb-based andable to be realized independently asa simple sentence.
Itthen organizes the propositions into a coherent discourseby combining them according to predefined "schemas"representing plausible discourse relationships.Subsequent choices of linguistic resources are all local tothe propositions and not sensitive to the schemas orother context, except for the discourse-level connectivesused in combining the propositions and occasionally adiscourse history governing the use of pronouns.However, clauses in actual texts by people reflect acombination of multiple atomic units.
Systems thatignore this and begin with units that are inevitablyrealized as kernel clauses under-utilize the expressivepower of natural language, which can use complex nounphrases, nominalizations, adverbial phrases, and otheradjuncts to pack information from multiple units intoone clause.The second approach, using single componentarchitecture, recognizes the limitation of separating text68planning from the choice of linguistic resources, andremoves this division, letting the text plannermanipulate concrete resources directly.
However, thisincrease in complexity for the text planner hasrepercussions for the complexity of the architectureoverall.
For example, Nirenburg uses a blackboardarchitecture that must backtrack when the text plannerhas chosen incompatible concrete r sources.5.
ConclusionI have argued that an intermediate level of representationis needed within the text planner in which to composethe utterance and that this representation should be inabstract linguistic terms.
Making the vocabulary inwhich the text planner makes its decisions be anabstraction over the concrete resources of the languagesimplifies the decision making in the compositionprocess, since the text planner need not deal with theparticular grammatical details of the language.Furthermore, since the abstract vocabulary captures alland only those combinations of resources that occur inthe language and since its terms constrain thecomposition with other terms, the representation servesto ensure that the decisions that the text planner makeswhen composing the utterance will not have to beretracted, that is, that the utterance the text plannercomposes will be expressible in language.I have shown how a preliminary planning vocabularycan be developed by approaching the problem from twosides: (1) using research in linguistics and text analysisto determine a set of abstractions over concrete linguisticresources and (2) using these terms in a text plannergenerating text from a real application to empirically testthe usefulness of this set for generating.
The long rangchallenge of this work will be continuing thisbidirectional development and testing process to define anintermediate representation that both covers theexpressiveness of natural anguage and ensures theexpressibility ofthe generator's text plan.ReferencesBeaugrande Robert de, & Wolfgang Dressier (1981)Introduction to Text Linguistics.
Longman.
London,England.Abrett, Glen, Mark Burstein, & Stephen Deutsch (1989)Tarl: Tactical Action Representation Language, anenvironment for building goal directed knowledgebased simulation.
BBN Technical Report No.
7062.June 1989.Danlos, Laurence (1987) The Linguistic Basis of TextGeneration, Cambridge University Press, Cambridge,England.Derr & McKeown (1984) "Using Focus to GenerateComplex and Simple Sentences", Proceedings ofColing-84, Stanford University, July 2-6 1984. p.319-326.Gfimshaw, Jane (1988) "On the Representation f TwoKinds of Noun" Presented at Theoretical Issues inComputation and Lexical Semantics Workshop,Brandeis University, April 1988.Hovy, Eduard (1988) "Planning Coherent MultisentenfialParagraphs" In Proceedings of the 26th AnnualMeeting of the Association for ComputationalLinguistics, Buffalo, New York, June 7-10, 1988, p.163-169.Jackendoff, Ray (1983) Semantics and Cognition, MITPress, Cambridge, Massachusetts.McDonald, David D. (1984) "Description DirectedControl", Computers and Mathematics 9(1) Reprintedin Grosz, et al (eds.)
Readings in Natural LanguageProcessing, Morgan Kaufman Publishers, California,1986, pp.519-538.McDonald, David D. & Marie Meteer "Adapting TreeAdjoining Grammar to Generation", submitted to 5thInternational Workshop on Natural LanguageGeneration.McKeown, Kathleen (1985) Text Generation, CambridgeUniversity Press, Cambridge, England.Meteer, Marie W. (1990) The Generation Gap: Theproblem of expressibility in text planning.
Ph.D.thesis, Computer and Information SciencesDepartment, University of Massachusetts, Amherst,Massachusetts.
February 1990.Meteer, Marie W. (1989) The SPOKESMAN NaturalLanguage Generation System, BBN Technical Report7090.Meteer, Marie W., David D. McDonald, Scott Anderson,David Forster, Linda Gay, Alison Huettner, PenelopeSibun (1987) Mumble-86: Design andImplementation, UMass Technical Report 87-87, 173pgs.Nirenburg, Sergei, Victor Lessor, & Eric Nyberg (1989)"Controlling a Language Generation Planner",Proceedings of lJCAI-89, Detroit, Michigan.Paris, Cecile L. (1987) The Use of Explicit UserModels in Text Generation: Tailoring to a User'sLevel of Expertise, PhD Thesis, Columbia University,Department ofComputer Science.Pustejovsky, James (1989) "The Generative Lexicon",submitted to Computational Linguistics.Talmy, Leonard (1987) "The Relation of Grammar toCognition" (ed) B. Rudzka-Ostyn, Topics in CognitiveLinguistics, John Benjamins.69
