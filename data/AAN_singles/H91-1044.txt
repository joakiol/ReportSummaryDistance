Parsing the Voyager Domain  Using PearlDavid M. Magerman and Mitchell P. MarcusCIS DepartmentUniversity of PennsylvaniaPhiladelphia, PA 19104ABSTRACTThis paper* describes a .al, ural language p~rsi.g algorithm &)r un-resu'icl,ed I,ext which uses a probabilhq-hased scoring funct,iow I,o se-le(:l, I,he "besC: parse of ~/ sent,enos acc:ording t,c~ a given gra0nunar.The parser~ "Pearl~ ix a i,hne-asynciironous t)ol,l,orn-u 1) chart, parser withEarley-l,ype I,Ol)-dowil t)redic:l,ion which pursues I,he }6gtmsl,-s(:ori.g t,he-ory in I,he (:|larl,, where I,he set)re of a IJmory represe.l,s I,|le exl,e.l, I,oW|lic:|l L}le ~:on|,exl, ()~ I,|le seutl,euic:e predic:l;s I,}lat, int,erprel,at,ion.
Thisparser {lifters front previous au,eUnl)l,s el, sto(:}la.st,i(: parsers in I,|lal, it, .sesa richer h)rm of condii,ional probabilil, ies |)a.~ed on conl,exl, l,o predict,likelihood.
Pearl Mso provides a framework for in(:orporat,ing the resuh,sof previo.s work in part,-of-st)eeeh assig.tnenl,) InlkutowIi word u||od-els, and olJher l)rol)abilist,ic models (ff linguistfic feauJres im,o o.e pars-i .g U)t)\], inl,erleaving I,}lese I,e(:imiques |.stead of usi.g I, he I,ra~lil,iona\]pipeline archil,eci, ure.
In I, esl~ perh~ruvled on I,|ie Voyager (lirecl,io.-finding domain, "Pearl has been s.ccessful el, resolvi.g parl,-of-speechaunifiguhq, del,ermiufing cal,egories for umknow, words, and selecl,ingcorrecl, parses firsl, using a very loosely fil, l,lng covering rammar.
~INTRODUCTIONAll natural language grammars are ambiguous.
Even tightlyfitting natural language grammars are ambiguous in some ways.Loosely fitting grammars, which are necessary for handhng thevariability and complexity of unrestricted text and speech, areworse.
The standard technique for dealing with this ambiguity,prtming grammars by hand, is painful, time-consuming, and usu-ally arbitrary.
The solution which many people have proposed isto use stochastic models to train statistical grammars automati-cally from a large corpus.Attempts in applying statistical techniques to natural lan-guage parsing have exhibited varying degrees of success.
Thesesuccessful and unsuccessful attempts have suggested to us that:?
Stochastic techniques combined with traditional hnguistictheories can (and indeed must) provide a solution to thenatural language understanding problem.
*This work was partially supportcd by DARPA grant No.
Nt1014-85-K0018, ONR contract No.
Ntltltl14-89-O~0171 by DARPA and AIrOSR jointlyttndcr grant No.
AFOSR-90-Ut166, and by ARO grant No.
DAAL 03-89-Ctlt131PRL SpccJal thanks to Carl Wcir and Lynettc Hirschman at Unisys for thcirvalucd input, guidancc and support.2Thc grammar uscd for o~tr cxpcrimcnts i  the string grammar used inU nisys: P U NDIT natural languagc undcrstanding systcm.?
In order for stochastic techniques to be ett~ctive, they mustbe applied with restraint (poor estimates of context axeworse than none\[6|).?
Interactive, interlea~'ed architectures axe preferable to pipelinearchitectures in NLU systems, because they use more of theavailable information in the decision-malting process.We have constructed a stochastic parser, "Pearl, which is basedon these ideas.The development of the Pearl  parser is an ettbrt to combinethe statistical models developed recently into a single tool whichincorporates all of these models into the decision-making compo-nent of a. parser.
While we hax'e only attempted to incorporate afew simple statistical models into this parser, Peaxl is structuredin a way which allows any number of syntactic, semantic, andother knowledge sources to contribute to parsing decisions.
'l'hecurrent implementation f Pear l  uses Church's part-of-speech as-signment r igram model, a simple probabilistic unknown wordmodel, and a conditional probability model for grammar rulesbased on part-of-speech trigrams and parent rules.By combining multiple knowledge sources and using a chart-parsing framework, Pearl  attempts to handle a number of difficultproblems.
Pear l  has the capability to parse word lattices, anability which is useful in recognizing idioms in text processing, aswell as in speech processing.
The parser uses probabilistic trainingfrom a corpus to disambiguate between grammatically acceptablestructures, such as determining prepositional phrase attachmentand conjunction scope.
Finally, Pear l  ms|mains  a well-formedsubs|r ing table within its chart to allow for partial parse retrieval.Partial parses are useful both for error-message neration and forprocessing ungrammatical or incomplete sentences.For preliminary tests of Pear l 's  capabilities, we are using theVoyager direction-finding domain, a spoken-language system de-veloped at MiT.
3 We have selected this domain for a numberof reasons.
First, it exhibits the attachment regularities whichwe are trying to capture with the context-sensitive probabilitymodel.
Also, since both MIT and Unisys have developed parsersand grammars for this domain, there are existing parsers withwhich we can compare 7Pearl.
Finally, pear l ' s  dependence ona parsed corpus to train its models and to der i~  its grammar3Spccial thanks to Victor Zuc at MIT for thc use of thc speech data fromMIT:s Voyagcr system.231required that we use a domain for which a parsed corpus ex-isted.
A corpus of 1100 parsed sentences was generated by theUnisys' I-'I.tNDIT Language Understanding System.
These parsetrees were evaluated to be semantically correct by PUNDIT'S se-mant ics  component, although no hand-verification f this corpuswas performed.
PUNDIT'S parser uses a string grammar with manycomphcated, hand-generated restrictions.
The goal of the exper-iments we performed was to reproduce (or improve upon) theparsing accuracy of PUNDIT USing jUSt the context-free backboneof the PIINDIT grammar, without the hand-generated restrictionsand, equally important, without the benefit of semantic analysis.In a. test on 40 Voyager sentences excluded from the trainingmaterial, Pearl  has shown promising results in handling part-of-speech assignment, prepositional phrase attachment, and un-known word categorization.
Pearl correctly parsed 35 out of 40or 87.5% of these sentences, where a correc~ parse is defined tomean one which would produce a correct response from the Voy-ager system.
We will describe the details of this experiment later.In this paper, we will first explain our contribution to thestochastic models which axe used in Pearl: a context-free gram-mar with context-sensitive conditional probabilities.
Then, wewill describe the purser's architecture and the parsing algorithm.Finally, we will gi~m the results of experiments we performed usingPearl which explore its capabilities.USING STAT IST ICS  TO PARSERecent work involving context-~ee and context-sensitive prob-abilistic grammars provide httle hope for the success of processingunrestricted text using probabilistic techniques.
Works by Chi-trao and Grishman\[3\] and by Sharman, Jehnek, and Mercer\[Illexhibit accuracy rates lower than 50% using supervised training.Supervised training for probabilistic CFGs requires parsed cor-pora., which is very costly in time and maa-power\[2\].In our investigations, we have made two observations whichattempt o explain the lack-luster performance of statistical pars-ing techniques:?
Simple probabilistic CFGs provide generalinformation abouthow likely a construct is going to appear anywhere in a sam-ple of a language.
This average likehhood is often a poorestimate of probability.?
Parsing algorithms which accumulate probabilities of parsetheories by simply multiplying them over-penalize infre-quent constructs.Pearl avoids the first pitfall by using a context-sensitive condi-tional probabihty CFG, where context of a theory is determinedby the theories which predicted it and the part-of-speech se-quences in the input sentence. '
lb address the second issue, Pearlscores each theory by using the geometric mean of the contextualconditional probabilities of all of the theories which have con-tributed to that theory.
This is equivalent to using the sum ofthe logs of these probabilities.CFG wi th  context -sens i t ive  cond i t iona l  p robab i l i t iesIn a very large parsed corpus of English text, one finds thatthe most frequently occurring noun phrase structure in the textis a noun phrase containing a determiner followed by a noun.Simple probabilistic CFGs dictate that, given this information,"determiner noun" should be the most likely interpretation of anoun phrase.Now, consider only those noun phrases which occur as subjectsof a sentence.
In a given corpus, yon might find that, pronounsoccur just as frequently as "determiner nolm"s in the subjectposition.
This type ~fff information can ea~ily be captured byconditional probabilities.Finally, assume that the sentence begins with a pronoun fol-lowed by a verb.
In this case, it, is quite clear that, while yoncan probably concoct a sentence which fits this description anddoes not have a pronoun for a subject, the first theory which yonshould pursue is one which makes this hypothesis.The context-sensitive conditional probabilities which "Pearluses take into account he immediate parent of a theory 4 and thepart-of-speech trigram centered at the beginning of the theory.For example, consider the sentence:My first love was named 'Pearl.
(no subliminal propaganda intended)A theory which tries to interpret "love" as a verb will be scoredbased on the part-of-speech trigram "adjective verb verb" and theparent heory, probably "S --+ NP VP."
A theory which interprets"love" as a noun will be scored based on the trigram "adjectivenoun verb."
Although lexical probabilities favor "love" as a verb,the conditional probabilities will heavily favor "love" a.~ a nounin this context.
'5Us ing  the  Geometr i c  Mean of  Theory  ScoresAccording to probability theory, the likelihood of two inde-pcndcnl, events occurring at, the same time is the product of theirindividual probabilities.
Previous statistical parsing techniquesapply this definition to the cooceurrence of two theories in a parse,and claim that the likelihood of the two theories being correct isthe product of the probabilities of the two theories.This application of probability theory ignores two vital obser-vations about the domain of statistical parsing:?
Two constructs occurring in the same sentence are not, nec-essarily independent (and frequently are not).
If the inde-pendence assumption is violated, then the product of in-dividual probabilities has no meaning with respect to thejoint probability of two event, s.?
Since statistical parsing suffers from sparse data, probabilityestimates of low frequency events will usually be inaccurateestimates.
Extreme underestimates of the likelihood of lowfrequency events will produce misleading joint probabilityestimates.4Tl,e parent of a theory is defined as a theory with a CF rule which containsthe left-hand side of the theory.
For instance, if ~S ~ NP VP" and "NP --*det o" are two grammar rules, the .first rule can be a parent of the secoud~sittce the left-hand side of the second "NP" occurs in the right-hand side ofthe frst rule.5In fact, the part-of-speedt tagging model wlddt is also used in "Pearl willheavily favor "love" as a noun.
We ignore this behavior to demonstrate hebenefits of the trlgram conditioning.232From these observations, we have determined that estimatingjoint probabilities of theories using individual probabilities i toodifficnlt with the available data.
We have fonnd that the geo-metric mean of these probability estimates provides an accurateassessment of a theory's viability.The  Actua l  Theory  Scor ing  Funct ionIn a departnre from standard practice, and perhaps againstbetter judgment,we will include a precise description of the the-ory scoring fimction used by Pearl.
This scoring fimction tries tosolve some of the problen~ noted in previous attempts at proba-bilistic parsing\[3\]\[11\]:?
Theory scores hould not depend on the length of the stringwhich the theory spans.?
Sparse data.
(zero=frequency events) and even zero=probabilityevents do occur, and shonld not resnlt in zero scoring the-ories.?
Theory scores hould not discriminate against unlikely con=structs when the context predicts them.In this discnssion, a theory is defined to be a partial or com-plete syntactic interpretation f a word string, or, simply, a parsetree.
The raw score of a theory, 0, is calculated by taking theproduct of the conditional probability of that theory's CFG rulegiven the context, where context is a part-of-speech trigram cen-tered at the beginning of the theory and a parent heory's rule,and the score of the contextnal trigram:SCram(0) = .p(rulcol(poPtP2),  ru lcparent)Sc(poplp2)Here, the score of a trigram is the prodnct of the mutna\] in-formation of the part-of-speech trigram, 6 P0PlP2, and the lexicalprobability of the word at the location of Pi being assigned thatpart-of-speech Pi .7 In the case of ambiguity (part-of-speech am-bignity or multiple parent heories), the maximnm valne of thisproduct is used.
The score of a partial theory or a complete the-ory is the geometric mean of the raw scores of all of the theorieswhich are contained in that theory.Theory Length Independence This scoring fimction, althoughheuristic in derivation, provides a method for evaluating the valueof a theory, regardle~ of its length.
When a rule is first, predicted(Earley-style), its score is just its raw score, which represents howmnch the context predicts it.
However, when the parse processhypothesizes interpretations of the sentence which reinforce thistheory, the geometric mean of all of the raw scores of the rule'ssnbtree is nsed, representing the overall ikelihood of the theorygiven the context of the sentence.Low-freqnency Events Although some statistical natural lan-gnage applications employ backing-off estimation techniqnes\[10\]\[5\]to handle low-frequency events, 'Pearl uses a very simple estima-tion technique, reluctantly attributed to Church\[6\].
This tech-niqne estimates the probability of an event by adding 0.5 to ev-6The mutual information of a part-of-speech trigrnm, poPlP2, is definedto be ..pry ~w') .
where x is any part-of-sr)eech.
See \[4\] for further "M( pilxp~)'P( ~t ) )ex planation.7The trigram scoring \[traction actually used by the parser is somewhatmore complicated than this.ery frequency count.
8 Low-scoring theories will  be predicted bythe Earley-style parser.
And, if no other hypothesis suggested,these theories will be pursued.
If a high scoring theory advancesa theory with a very low raw score, the resulting theory's corewill be the geometric mean of all of the raw scores of theoriescontained in thkt theory, and thus will be much higher than thelow-scoring theory's core.Example of Scoring Fnnction As an example of how the conditional-probability-based scoring fimction handles ambiguity, considerthe sentenceFruit flies like a banana.in the domain of insect studies.
Lexica.I probabilities should indi-cate that the word "flies" is more likely to be a plural noun thana tensed verb.
This information is incorporated in the trigramscores.
However, when the interpretationS -+.
NPVPis proposed, two possible NPs will be parsed,NP --~ noun (frnit)andNP ~ noun nmm (fruit file.6).Since this sentence is syntactically a.mbiglmns, if the first hypoth-esis is tested first, the parser will interpret his sentence incor-rectly.However, this will not happen in this domain.
Since "fruitflies" is a conmmn idiom in insect studies, the score of its tri-gram, noun noun verb, will be much greater than the score of thetrigram, noun verb verb.
Thus, not only will the lexical proba-bility of the word "flies\]verb" e lower than that, of "f l ies/norm,"but also the raw score of "NP  ~ noun (fruit)" will be lower thanthat, of "NP  ~ norm noun (fruit flies)," because of the differentialbetween the trigram scores.So, "NP --~ noun noun" will be used first to advance the "S. NP VP" rnle.
Further, even if the parser advances both NPhypotheses, the "S ~ NP .
VP" rnle using "NP --~ noun noun"will have a higher score than the "S ~ NP .
VP" rule using "NP---~ 111011I'I .~INTERLEAVED ARCHITECTURE INPEARLThe interleaved architecture implemented in .pearl providesmany advantages over the traditional pipeline architecture, butit also introduces certain risks.
Decisions about word and part-of-speech ambiguity can be delayed nntil syntactic processing canSWe are not deliberately avoiding using all probability estimation tech-niques, only those backLItg-O~ teclLttiqu.eS wltich thse itLdel.
)endence ?~ssump-~ons that frequently provide misleading information when applied to naturallanguage.233disarnbignate hem.
And, using the appropriate score combina-/,ion fimctions, the scoring of ambiguous choices can direct theparser towards the most likely interpretation efficiently.However, with these delayed decisions comes a. vastly enlargedsearch space.
The effectiveness of the parser depends on a major-ity of the theories having very low scores barred on either unlikelysyntactic struct~Jres or low scoring input (such as low scores froma speech recognizer or low lexical probability).
In experiments wehave performed, this has been the case.The  Pars ing  A lgor i thmPearl is an agenda~ba~sed time-asynchronous bottom-up chartparser with Earley-type top-down prediction.
The significant dif-ference between T~earl and non-probabilistic bottom-up parsersis that instead of completely generating all grammatical inter-pretations of a word string, ~earl uses an agenda to order theincomplete theories in its chart to determine which theory to ad-vance next.
The agenda is sorted by the value of the theoryscoring fimction described above.
Instead of expanding all the-ories in the chart, Pearl pl~rsnes the highest-scoring incompletetheories in the chart, advancing up to N theories at each pass.However, T~earl parses without pruning.
Although it is only ad-vancing N incomplete theories at each pass, it retains the lowerscoring theories in its agenda.
If the higher scoring theories donot generate viable alternatives, the lower scoring theories maybe used on snbseqnent passes.The parsing algorithm begins with an input word lattice, whichdescribes the input sentence and includes possible idiom bypotheseand may include alternative word hypotheses.
"q Lexical rules for/.he input word lattice are inserted into the parser's chart,.
UsingEarley-type prediction, a sentence (S) is predicted at the begin-ning of the input, and all of the theories which are predicted bythat initial sentence are inserted into the chart.
These incompletetheories are scored according to the context-sensitive conditionalprobabilities and the trigrarn part-of-speech model.
The incom-plete theories are tested in order by score, until N theories areadvanced, m The resulting advanced theories are scored and pre-dicted for, and the new incomplete predicted theories are scoredand added to the chart.
This process continues until an completeparse tree is determined, or nnt~il the parser decides, heuristically,that it should not continue.
The heuristics we used for deter-mining that no parse can be found for an input are based onthe highest, scoring incomplete theory inn the chart, the number ofpasses the parser hans made, and the size of the chart.Pear l ' s  Capab i l i t iesBesides using statistical methods to guide the parser throughthe parsing search space, "Pearl also performs other fimctions0 Usi*tg alternative word hypotheses without incorporating a speech recog-tfition model would not necessarily produce ttsefftd results.
Given two unam-bigttous norms at the same position in the sentence, "Pearl has no informationwith wlfich to disambiguate these words, and will invariably select hefirst oneentered into the chart.
The capability to process a alternate word hypothe-ses is inchtded to suggezt the future implementation ffa speedt recognitionmodal i, +Pearl.J%Ve believe that N depends on the perplexity off the grammar used, but forthe string grammar used for ottr experiments we itsed N=3.
For the pttrp(ysesoff training, we sttgg?~l, that a higher N shottld be used in order to generatemore  parses.which are crncial to robustly processing unrestricted natliral lan-guage text and speech.Handling Unknown Words Pearl uses a very simple proba-bilistic unknown word model to hypothesize categories for un-known words.
When a word is fonnd which is unknown to thesystem's lexicon, the word is a.ssumed to be any one of the opencla~ss categories.
The lexical probability given a category is theprobability of that category occurring in the training corpns.Idiom Processing and Lattice Parsing Since the parsing searchspace can be simplified by recognizing idion~s, Pearl allows theinpnt string to inch~de idiorrrs that.
span more than one word inthe sentence.
This is accomplished by viewing the input sentenceas a word lattice instead of a word string.
Since idioo~s tend tobe nnambignous with respect o part-of-speech, they are gener-ally favored over processing the individual words that make upthe idiom, since the scores of rules containing the words will tendto be lens than 1, while a syntactically appropriate~ unambiguousidiom will have a score of close to 1.The ability to parse a sentence with mnltiple word hypothe-ses and word boundary hypotheses makes Pearl very nsefifi inthe domain of spoken language processing.
By delaying decisionsabout word selection but maintaining scoring information froma speech recognizer, the parser can use grammatical informationin word selection without slowing the speech recognition process.Because of Pearl 's interleaved architecture, one conld ea.sily in-corporate scoring information from a speech recognizer into theset of scoring fl\]nctions used in the parser.
'Pearl could also pro-vide feedback to the speech recognizer abont the grarnmaticalityof fragment hypotheses to glfide the recognizer's search.Partial Parses The main advantage of chart-barred parsingover other parsing algorithms is that a chart-based parser canrecognize well-formed substrings within the input string in thecourse of pursuing a complete parse.
Pearl takes fi,ll advantageof this characteristic.
Once Pearl is given the input sentence, itawaits instructions as to what type of parse should be attemptedfor this input.
A standard parser automatically attempts to pro-dace a sentence (S) spanning the entire inplJt string.
However, ifthis fails, the semantic interpreter might be able to derive somemeaning from the sentence if given non-overlapping noun, verb,and prepositional phrases.
If a sentence fails to parse, requestsfor partial parses of the input string can be made by specifyinga range which the parse tree should cover and the category (NP,VP, etc.).
These requests, however, must be initiated by an in-telligent semantics processor which can manipulate these partialparses.Trainability One of the major advantages of the probabilis-tic parsers is trainability.
The conditional probabilities used byPearl are estimated by using frequencies from a large corpus ofparsed sentences.
The parsed sentences must be parsed using thegrammar formalism which the Pearl will use.Assuming the grammar is not recnrsive in an unconstrainedway, the parser can be trained in an unsupervised mode.
Thisis accomplished by running the parser without the scoring flmc-tions, and generating many parse trees for each sentence.
Previ-ous work H has demonstrated that the correct information fromnThis is art unpublished result, reportedly due to Fujisaki at IBM Japan.234these parse trees will be reinforced, while the incorrect substruc-ture will not.
Multiple passes of re-training using frequency datafrom the previous pass should creme the frequency tables to con-verge to a stable state.
This hypothesis has not yet been tested, t2An alternative to completely unsupervised training is to takea parsed corpus for any domain of the same language using thesame grammar, and use the frequency data from that corpus asthe initial training material for the new corpus.
This approachshould serve only to minimize the number of nnsupervised passesrequired for the frequency data to converge.PARSING THE VOYAGEI~ DOMAINIn order to test Pearl 's capabilities, we performed some simpletests to determine if its performance is at least consistent with thepremises upon which it is bmsed.
The test sentences used for thisevaluation are not from the training dataon which the parser wastrained.
Using Pearl 's context-free grammar, which is equivalentto the context-free backbone of PUNDIT'S grammar, these testsentences produced an average of 64 parses per sentence , withsome sentences producing over 100 parses.Overa l l  Pars ing  AccuracyThe 40 test sentences were parsed by "Pearl and the highestscoring parse fbr each sentence was compared to the correct parseproduced by PUNDIT.
Of these 40 sentences, "Pearl produced parsetrees fbr 38 of them, and 35 of these parse trees were equivalentto the correct parse produced by PUNDIT, fbr an overall accu-racy rate of 88%.
Although precise accuracy statistics are notavailable ibr PUNDIT, this result is believed to be comparable toPUNDIT's perfbrmance.
However, the result is achieved withoutthe painfully hand-crafted restriction grammar associated withPUNDIT'S parser.Many of the test sentences were not difficult to parse fbr ex-isting parsers, but most had some grammatical ambiguity whichwould produce multiple parses.
In fkct, on 2 of the 3 sentenceswhich were incorrectly parsed, "Pearl produced the correct parseas well, but the correct parse did not have the highest score.
Andboth of these sentences would have been correctly processed if'semantic filtering were used on the top three parses.Of the two sentences which did not parse, one used passivevoice, which only occurred in one sentence in the training corpus.While the other sentence,How can I got  from care sushi to CambridgeCity Hospital by walkingdid not produce a parse for the entire word string, it could be pro-cessed using "Pearl's partial parsing capability.
By accessing thechart produced by the failed parse attempt, the parser can finda parsed sentence containing the first eleven words, and a prepo-sitional phrase containing the final two words.
This infbrmationcould be used to interpret he sentence properly.12In fact, for certain grammars, the frequency tables may not converge atall, or they may converge to zero, with the grammar generating no parses forthe entire corpus.
This is a worst-ease scenario which we do not anticipatehappening.Unknown Word  Par t -o f - speech  Ass ignmentTo determine how "Pearl handles unknown words, we randomlyselected five words f~om the test sentences, \[, know, ~cc, dcscriSc,removed their entries f~om the lexicon, and stalion, and tried toparse the 40 sample sentences using the simple unknown wordmodel previously described) ~In this test, the pronoun, /, was assigned the correct part-of:speech 9 of 10 times it occurred in the test sentences.
The nouns,~ee and station, were correctly tagged 4 of 5 times.
And the verbs,know and describc, were correctly tagged 3 of 3 times.
While thisCategory Accuracypronoun 90%noun 80%verb 100%overall 89%F ig , r  e 1: Performance on Unknown Words in Test Sentencesaccuracy is expected for unknown words in isolation, based on theaccuracy of' the part-of:speech tagging model, the perfbrmance isexpected to degrade for sequences of" unknown words.P repos i t iona l  Phrase  At tachmentAccurately determining prepositional phrase attachment ingeneral is a difficult and well-documented problem.
However,based on experience with several different domains, we have ibundprepositional phrase attachment tobe a domain-specific phenomenonfor which training can be very helpful.
For instance, in thedirection-finding domain, from and to prepositional phrases gen-erally attach to the preceding verb and not to any noun phrase.This tendency is captured in the training process for "Pearl andis used to guide the parser to the more likely attachment with re-spect to the domain.
This does not mean that "Pearl will get thecorrect parse when the less likely attachment is correct; in fact,"Pearl will invariably get this case wrong.
However, based on thepremise that this is the less likely attachment, his will producemore correct analyses than incorrect.
And, using a more sophis-ticated statistical model which uses more contextual infbrmation,this perfbrmance can likely be improved.
"Pearl's perfbrmance on prepositional phrase attachment wasvery high (54/55 or 98.2% correct).
The reason the accuracy rateis so high is that the direction-finding domain is very consistentin its use of individual prepositions.
The accuracy rate is notexpected to be as high in less consistent domains, although weexpect it to be significantly higher than chance.Search  Space  Reduct ionOne claim of "Pearl, and of probabilistic parsers in general, isthat probabilities can help guide a parser through the immensesearch space produced by ambiguous grammars.
Since, withoutprobabilisties, the test sentences produced an average of 64 parsesper sentence, "Pearl unquestionably has reduced the space of possi-bilities by only producing 3 parses per sentence while maintainingnThe unknown word model used in this test was augmented to includedosed class categories as well as open class, since the words removed fromthe lexicon may have included (in fact did include) dosed dass words.235Figure 2:PrepositionPrep.
, Accuracyfrom ' 92%to \[ 100%on 100%Overall\[ 98.2%Accuracy Rate for Prepositional Phrm~e Attachment, byhigh accuracy.
However, it is interesting to see how "Pearl's cor-ing function performs against previously proposed scoring func-tions.
The four scoring :\['unctions compared include a simple prob-abilistic CFG, where each context-fl'ee rule is assigned a fixed like-lihood based on training, a CFG using probabilistic onditioningon the parent rule only, which is similar to the scoring f'unctionused by Chitrao and Grishman\[3\], and two versions of the CFGwith CSP model, one using the geometric mean of raw theoryscores and the other using the product of" these raw scores.
UsingTechnique Edges AccuracyP-CFG j 929 35%CFG with Parent Cond.
883 50%CFG with CSP 210 ~ 88%Prod.
of Scores 657 60%Figure 3: Search Space Reduction and Accuracy for 1,bur ProbabilisticModelsa simple probabilistic CFG model, the parser produced a muchlower accuracy rate (35%).
The parentM conditioning broughtthis rate up to 50%, and the trigram conditioning brought thislevel up to 88%.
The search space for CFG with CSP was 4 to 5times lower than the simple probabilistic CFG.FUTURE WORKThe "Pearl parser takes advantage of domain-dependent i for-mation to select the most appropriate interpretation of an input.However, the statistical measure used to disambiguate these in-terpretations is sensitive to certain attributes of' the grammaticalibrmalism used, as well as to the part-of-speech categories used tolabel lexical entries.
All of the experiments perfbrmed on "Pearlthus far have been using one grammar, one part-of-speech tagset, and one domain (because of availability constraints).
Futureexperiments are planned to e~xluate "Pearl's perfbrmance on dif-ferent domains, as well as on a general corpus of English, and ondifferent grammars, including a grammar derived fl'om a manuallyparsed corpus.Specifically, we plan to retrain "Pearl on a corpus of terrorist-related messages fl'om the Message Understanding Conference(MUC).
Using this material, we will attempt two very differ-ent experiments.
The first experiment will be similar to theone performed on the Voyager data.
Using a corpus of correctlyparsed MUC sentences fl'om SRI's Tacitus system, we will derivea context-f~ee grammar and extract raining statistics ibr "Pearl'smodels.
Since the MUC sentences exhibit many more difficul-ties than Voyager, including 50 word sentences, punctuation, nosentence markers, and typographical errors, we expect "Pearl torequire significant re-engineering to handle this experiment.
'The second experiment on the MUC corpus involves extract-ing a grammar and training statistics from a hand-parsed corpus.When the University of" Pennsylvania's Treebank project\[2\] makesa hand-parsed version of the MUG training material a~ilable tothe DARPA community, we will extract a context-f~ee grammarfrom these parse trees, and retrain ~earl on this material.
Thisexperiment is even more interesting because, if successful, it willshow that ~Oearl provides an alternative to the hand-pruning ofgrammars to cover specific domains.
If a hand-parsed corpuscan provide a covering rammar which can be used to accuratelyparse a particular domain, porting natural anguage applicationsto new domains will be greatly facilitated.CONCLUSIONThe probabilistic parser which we have described provides aplatibrm for exploiting the useful ini:brmation made available bystatistical models in a manner which is consistent with existinggrammar fbrmalisms and parser designs.
"Pearl can be trained touse any context-f~ee grammar, accompanied by the appropriatetraining material.
And, the parsing algorithm is very similar to astandard bottom-up algorithm, with the exception of using theoryscores to order the search.In experiments on the Voyager direction-finding domain, ~earl,using only a context-i~ee grammar and statistical models, per-fbrmed at least as well as PUNDIT'S parser, which includes hand-generated restrictions.
In the ihture, we hope to demonstratesimilar peribrmance on more difficult domains and using manu-ally parsed corpora.REFERENCES\[1\] Ayuso, D., Bobrow, R., et.
el.
1990.
Towards Understanding Textwith a Very Large Vocabulary.
In Proceedings of the June 1990DA'RPA Speech and NatorM Language xA'orkshop.
Hidden Valley,Pennsylvania.\[2\] 13rill, E., Magerman, D., Marcus, M., and Santorini, D. 1990.
De-ducing Lingnistic Structure from the Statistics of Large Corpora.In Proceedings ofthe June 1990 DARPA Speech and Natural Lan-guagn Workshop.
Hidden Valley, Pennsylvania.\[3\] Chitrao, M. and Grishman, R. 1990.
Statistical Parsing of Mes-sages.
In Proceedings ofthe June 1990 DARPA Speech and NMurMLangamgs %Vorkshop.
Hidden VMley, Pennsylvania.\[4\] Church, K. 1988. h Stoeha.qtic Parts Program and Noun Phra.,~eParser for Unrestricted Text.
In Proceedings of the Second Con-ference on Applied NaturM Language Proce~qing.
Austin, Texas.\[5\] Church, K. and Gale, W. 1990.
Enhanced Good-Tnring and Cat-CM: Two New Methods for Estimating Probabilities of EnglishBigrams.
Comlmlen %Speech and Lauguaye.\[6\] Gale, W. A. and Church, K. 1990.
Poor Estimates of Context areWorse than None.
In Proceedings ofthe June 1990 DA RPA Speechand NaturM Language Workshop.
Hidden Valley, Pennsylvania.\[7\] Hindle, D. 1988.
Acquiring a Noun Classification from Predicate-Argument Structures.
Bell Laboratories.\[8\] Hindle, D. and Rooth, M. 1990.
StructnrM Ambiguity and Lexical"Relations.
In Proceedings of the June 1990 DAKPA Speech andNatural Language Workshop.
Hidden Valley, Pennsylvania.\[9\] Jelinek, F. 1985.
Self-organizing Language Modeling for Speech"Recognition.
Il3M Report.\[10\] Katz, S. M. 1987.
Estimation of Probabilitie.q from Sparse Data forthe Language Model Component of a Speech Recognizer.
?EEE7"~nnsaclions ou Acouslics, Speech, aud Signal Plvee.ssing, I/)H.ASSP-35, No.
3.\[11\] Sh~.rman, R. A., Jelinek, 1,'., and Mercer, R. 1990.
In Proceedingsof the June 1990 DARPA Speech and NatnrM Language Workshop.Hidden Valley, Pennsylvania.236
