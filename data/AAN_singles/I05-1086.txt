R. Dale et al (Eds.
): IJCNLP 2005, LNAI 3651, pp.
993 ?
1003, 2005.?
Springer-Verlag Berlin Heidelberg 2005A Case-Based Reasoning Approachfor Speech Corpus GenerationYandong Fan and Elizabeth KendallSchool of Network Computing, Faculty of IT, Monash University, Australiayandong.fan@infotech.monash.edu.auKendall@infotech.monash.edu.auAbstract.
Corpus-based stochastic language models have achieved significantsuccess in speech recognition, but construction of a corpus pertaining to aspecific application is a difficult task.
This paper introduces a Case-BasedReasoning system to generate natural language corpora.
In comparison totraditional natural language generation approaches, this system overcomes theinflexibility of template-based methods while avoiding the linguisticsophistication of rule-based packages.
The evaluation of the system indicatesour approach is effective in generating users?
specifications or queries as 98%of the generated sentences are grammatically correct.
The study result alsoshows that the language model derived from the generated corpus cansignificantly outperform a general language model or a dictation grammar.1   IntroductionStochastic language models have achieved significant success in speech recognitionsince the last decade [1, 2].
The main underlying technique in stochastic approaches isthe use of corpora.
The successful utilization of corpora has been proven by manyresearchers [3,4,5].
However, construction of a corpus pertaining to a specificapplication is a difficult task, given that there is no pre-knowledge on how usersmight communicate with the application before the deployment of a system.
Research[6] has been conducted to explore the effectiveness of Web-based text corpusgeneration.
Although the proliferation of eText has made the collection of textualmaterial easier than ever, Thompson [7] argues that actually locating eTextappropriate to your needs can be quite difficult.
Moreover, in the context ofconversational systems, the suitability of corpora purely collected from the Internet iscontroversial due to the difference of written text and spoken language.Although generally there is a lack of spoken material pertaining to a newapplication, ample transcriptions do exist in some well-established domains, such asthe Air Traffic Information System (ATIS) domain.
User modeling has been studiedfor long and conversations between users and agents of spoken language systemshave been recorded and accumulated for decades in these domains.
In our project, weseek to develop a speech-enabled mobile commerce application, which we called theMCCS (Mobile Car City system).
The system allows a mobile-phone user to specifypreferences or initiate queries by speech at the beginning of the conversation.
Then all994 Y.
Fan and E. Kendallcar models conforming to the preferences or queries are retrieved to guide the user infinding specific car models that meet his/her needs.
Through carefully examining thespoken transcriptions from the ATIS domain, we believe that user specifications orqueries in the MCCS system should share significant similarity in sentence syntacticstructure with their counterparts in the ATIS domain.
Motivated by this assumption,we believe that the MCCS system can learn a set of sample sentences from the ATISdomain, which can then be used as the knowledge base for case-based reasoning(CBR) to generate a speech corpus pertaining to the MCCS domain.NLG (Natural Language Generation) research has been dominated by twoapproaches in the past three decades: template-based and rule-based [8, 9].
Someclaim that template-based approaches are not flexible enough while others criticizethe sophistication of linguistic grammars implemented in rule-based approaches [8].A new strand in the arena is learning-based NLG, in which the objective is to learnthe mapping from semantics to surface realization through sample sentences.Research [10, 11, 12] suggests that learning-based approaches can balance theinflexibility of template-based methods and the linguistic sophistication of rule-basedNLG packages when developing domain-specific generation systems.In this paper, we explore an incremental learning approach for speech corpusgeneration.
Firstly, a set of sample sentences pertaining to user specifications orqueries in the MCCS application are learnt from the ATIS domain.
Secondly, a CBRsystem is built to generate a corpus based on those sample sentences.
Finally, an n-gram language model is derived from the corpus by learning the statistical distributionof tokens.
The paper is structured as follows.
Section 2 introduces the generalstructure of the corpus generation system.
Detailed implementation of the system isdescribed through Section 3-5.
Section 6 presents the evaluation results of thegenerated corpus.
Related work is discussed in Section 7.
We conclude the study andbriefly discuss potential future work in Section 8.2   System OverviewOur aim is to develop a case-based, domain-specific generation system that cansignificantly reduce complexity in comparison to rule-based solutions.
Case-basedreasoning (CBR) systems have long been applied for problem solving in many areas,such as classification, diagnosis, configuration and design, and planning, but onlyrecently has it attracted significant attention from researchers in NLG.
Like any otherCBR system, a CBR-based NLG system has to include the following components:?
Sample sentence set (Case Base)?
Schema for sentence structure, includes semantic and syntactic (KnowledgeRepresentation)?
Similarity measurement (Acceptance Function)?
Sentence generation (Case Retrieval and adaptation algorithms)Figure 1 represents the overall structure of our CBR-based corpus generationsystem.
The system implements a pipeline architecture consisting of three stages.Firstly, an initial sample sentence set is created manually to integrate an ATISsentence base (ASB) and a MCCS phrasal base (MPB).
The ASB is a collection ofA Case-Based Reasoning Approach for Speech Corpus Generation 995sentences from a well-established corpus in the ATIS domain.
The MPB collectsphrases in describing car model features, which are abstracted from carmanufacturers?
websites and marketing brochures.
Through careful analysis on thesentences in the ASB and the phrases in the MPB, sample sentences for user queriesor specifications pertaining to the MCCS system can be created to form a casesentence base (CSB).
The examples (2.1)-(2.3) show an ATIS sentence from theASB, a MCCS phrase from the MPB, and a sample sentence from the CSB,respectively.I prefer [PluralObject flights] [ServiceFeature serve lunch] (2.1)[SingularObject A car] with [NumOfDoorFeature four doors] (2.2)I prefer cars with four doors.
(2.3)Secondly, these sample sentences in the CSB are annotated to abstract semanticstructure and corresponding syntactic structure, which become the case representationfor instance learning.
Finally, based on the understanding of the characteristics of userqueries and specifications, a new input that represents a unique semantic meaningpasses through the CBR system.
The similarity between the input and a case iscalculated and examined.
If the distance is within the predefined threshold, adaptationis conducted to generate a new syntactic structure for the semantic input.
Thisprocedure is continuously performed until all possible inputs are enumerated.
Theresultant corpus is then ready for creating an n-gram language model.Fig.
1.
Main procedures of the CBR-based corpus generation system3   Sample Sentence SetWe collect utterances pertaining to user preference specifications or queries from theATIS domain.
The utterances are classified into four categories [13] according to theirsentence acts.
The followings are examples for each category:Sample Sentence Creation?
Build up the sample sentence setCase Sentence Annotation?
Implement the schema for representing the semantic and syntacticstructure of sample sentencesCorpus Generation?
Retrieve cases from the set?
Calculate the distance between a new input and a case?
Perform adaptation to generate new sentences996 Y.
Fan and E. KendallDeclarative: I prefer a [TimeFeature morning] [SingularObject flight].
(3.1)Imperative: Show me the [PriceFeature cheapest] [SingularObject flight].
(3.2)Yes-no-question: Can you give me some information for [Carrier United]?
(3.3)Wh-question: What [PluralObject flights] [ServeFeature serve breakfast]and [HaveFeature have stops]?
(3.4)Each sentence in the ASB has been annotated by assigning conceptual categories[14] to domain concepts reflecting semantic meanings.
Such simple annotations canhelp us create sample sentences in the MCCS domain by substituting or adjoiningoperations.
The examples (3.5)-(3.8) show the corresponding cases in the CSB rootedfrom (3.1)-(3.4).
There are in total 114 cases in the CSB.Declarative: I prefer a white car.
(3.5)Imperative: Show me the cheapest sedan.
(3.6)Yes-no-question: Can you give me some information for Honda?
(3.7)Wh-question: What cars can seat more than 5 passengers and have 4 doors?
(3.8)4   Case Sentence AnnotationIn our corpus generation system, we implement an annotation scheme for samplesentences in the CSB.
Each sample sentence is annotated in two plies.
The first ply isthe semantic structure representing the domain concept relationships.
The syntacticstructure is abstracted in the second ply to reflect surface realization.QueryObject   CAT_Color  CAT_NumOfDoorCAT_NumOfCylinder  CAT_Make  CAT_BodyStyleCAT_Transmission  CAT_DriveWheelNUM_MadeYearStartValue NUM_MadeYearEndValueNUM_EngineLiterStartValue NUM_EngineLiterEndValueNUM_PriceStartValue  NUM_PriceEndValueNUM_NumOfPassengerStartValue NUM_NumOfPassengerEndValueNote: CAT means categorical feature while NUM means numeric featureFig.
2.
Conceptual category setWe utilize a set of conceptual categories to abstract conceptual meanings in ourapplication domain (Figure 2).
The benefit of introducing conceptual categories is thateach concept in a case sentence can be instantiated with different values to satisfyword coverage.
The semantic ply indicates the sentence act and the number type(singular or plural) of the query object.
It also catches the relations between thoseconceptual categories involved in the annotated sentence.
For instance, the semanticply of Example (3.8) can be described in a Query Language [15] as:A Case-Based Reasoning Approach for Speech Corpus Generation 997{x|x.Act=?wh-question?
?
x.QueryObject=?car?
?
x.ObjectType=?Plural?
?car.NumOfDoor=?four?
?
car.NumOfPassenger.StartValue=5 }  (4.1)The syntactic ply analyzes the syntactic structure of the sentence, which is theformalism for surface realization.
The structure of the formalism is adapted from thesystemic functional grammar [16], which consists of three layers: clause, phrase andtoken.
Figure 3 represents the syntactic structure of the example (3.8).<SynStructure type=?ComplexClause?><SynClause localID=?c1?><SynPhrase type=?Simple?
fc=?CannedText?
value=?What?
/><SynPhrase type=?Simple?
fc=?ObjectThing?
ref=?Head?
value=?VALUE?
/><SynPhrase type=?Simple?
fc=?Predicate?
value=?can seat?
/><SynPhrase type=?Complex?
fc=?NUMFeature?
ref=?NumOfPassenger?><SynToken type=?Simple?
fc=?CannedText?
value=?more than?
/><SynToken type=?Simple?
fc=?Feature?
value=?StartValue?
/><SynToken type=?Simple?
fc=?Quantifier?
value=?passengers?
/></SynPhrase><SynPhrase type=?Simple?
fc=?PredicateConj?
value=?and?
/><SynPhrase type=?Simple?
fc=?Predicate?
value=?have?
/><SynPhrase type=?Complex?
fc=?CATFeature?
ref=?NumOfDoor?
/><SynToken type=?Simple?
fc=?Feature?
value=?VALUE?
/><SynToken type=?Simple?
fc=?Quantifier?
value=?doors?
/></SynPhrase></SynClause></SynStructure>Fig.
3.
The syntactic structure of Example (3.8) in XML5   Corpus GenerationThe general principles for creating a corpus are semantic coverage, syntacticcoverage, prosodic coverage and word coverage [11].
As the target outcome of oursystem is a sentence corpus for language modeling, prosodic coverage is not ourfocus.?
Semantic coverage: the corpus should cover domain concepts and relationships ascompletely as possible;?
Syntactic Coverage: the corpus should reflect many rich syntactic variations, asfound in natural language;?
Word Coverage: the corpus should cover as many words as possible in thevocabulary.In this Section, we demonstrate how these three principles have been considered andsatisfied during the corpus generation.
Although case sentences marked with domain-specific conceptual categories can be used directly for surface natural languagegeneration, as was suggested in [17], it is only capable of handling certaincircumstances, such as simple applications (as the NLG1 in [17]) or under theassumption that the corpus is large enough for statistical analysis (as the NLG2 andNLG3 in [17]).
In our project, we seek to create a corpus based on a sample sentenceset with a limited size.
Therefore, a CBR approach with adaptability is more998 Y.
Fan and E. Kendallappropriate [11].
An input to the sentence generator is a semantic structure representedin an AVM (attribute value matrix) form, including a sentence act, the query object andits features.
Figure 4 shows a typical example of inputs.Act:  declarativeObject:   head: carnumber: singularFeature:color: rednum_of_door: 4body_style: sedanFig.
4.
An example input showing the semantic meaning of a user?s specification: ?I wouldprefer a red sedan with four doors?In order to satisfy the semantic coverage, we explore all possible combinations offeatures related to the car object.
We made a decision to include only thosecombinations with less than 5 features so that the generated sentence can be kept in areasonable length.
In terms of syntactic coverage, we consider all sentence acts toexpress a feature combination.
In addition, the variations of syntax in describing anumeric feature are explored.
The examples (5.1)-(5.4) show four types of phraseswith different foci to specify the price of a car.
The word coverage is achievedthrough enumerating all possible values of each feature.a price no less than [PriceStartValue 15,000] dollars (5.1)a price no more than [PriceEndValue 30,000] dollars (5.2)a price from [PriceStartValue 15,000] to [PriceEndValue 30,000] dollars (5.3)a price around [PriceStartValue=PriceEndValue 20,000] dollars (5.4)The generation of sentences is performed according to a procedural algorithm.
Thealgorithm consists of four procedures:?
Distance measuring: An input is compared with the semantic representation of aninstance in the CSB.
Candidates above the threshold are selected for furtherprocessing.?
Feature categorizing: Through examining the difference between the feature set ofthe input and that of the case, features are categorized into four groups:OldFeatures, AdjustFeatures, OtioseFeatures and NewFeatures.
Old features arethose shared by the input and the case.
Adjust features are those numeric featuresbelonging to both but with different focuses.
Features in the case but not in theinput are called otiose features, and new features are those that appeared in theinput but not in the case.A Case-Based Reasoning Approach for Speech Corpus Generation 999Sentence Generation AlgorithmInput: The semantic structure of a new sentence: I ;An instance of cases retrieved from the sentence base: C;Output: a generated sentence if it?s successful; otherwise null.1.
If (I.act == C.act) then proceed to 2;2.
If ( isCompatible (I.object, C.object)) then proceed to 3;3.
Calculate Dis (I, C);Denote I (F) as the input, where F={F1,F2,..Fn} represents the feature setof the input.Denote C (A) as the case, where A={A1,A2,?Am} represents the featureset of the case.Denote k as the number of features ?
F?
A.If we define:?
if fi ?Cd (fi, C)  =?
if fi ?
C?
if ai ?Fd (ai, F)  =?
if ai ?
Fthen Dis (I, C) =?
d (fi, C)  + ?
d (ai, F) = 2?k + (n-k) ?
+ (m-k) ?The distance function (metric) should satisfy the following conditions:(1) 0 ?
Dis (I,C) ?
1;(2) if n=m=k then Dis (I,C)=0;(3) if k=0 then Dis (I, C) =1;(4) ?
> ?
> 0, given that insertion is a more difficult operationthan deletion;Thus ?=0;1/(m+n) <?
< 1/n;and  ?
= (1-n?
)/m .Choose ?
= 1/(n+1) then Dis (I, C) = (n-k)*(1/(n+1)) + (m-k)*(1/(n+1))/m4.
If (Dis(I,C) <0.5) then proceed to 5;5.
For each feature fi?
{oldFeatures||adjustFeatures}=F?A, perform value substitutionor adjustment operation;For each feature fj?
{otioseFeatures}=(F?A)?F, perform deletion operation;For each feature fk?
{newFeatures}=(F?A)?A , perform insertion operation.6.
Surface realize the sentence according to the adaptive syntactic structure.Fig.
5.
Sentence generation algorithm1000 Y.
Fan and E. Kendall?
Case adapting: For each type of features, different adaptations to the case areperformed to generate a syntactic structure corresponding to the semantic structureof the input.?
Surface realizing: A sentence is generated according to the adapted syntacticstructure.Figure 5 depicts the details of the sentence generation algorithm.6   EvaluationThe evaluation is done at two levels.
Firstly, the generated sentences are scored byhuman evaluators using three ratings: no grammatical error, minor grammatical errorand major grammatical error.
The ratios generally represent the quality of sentencegeneration.
Secondly, the generated corpus is divided into two sets: a training set anda test set.
We use the training set to build an n-gram language model.
The languagemodel is applied to a speech recognition engine to test recognition effectiveness.
Thesentences from the test set are used for this testing.
We measure the word error rate toverify the acceptability of the language model.Table 1.
Testing results of language modelsTesting Engine LanguageModelIOSNsolPercentcorrectAccuracySphinx 4,  Nospeaker trainingOur DomainSpecificModel84 16 154 1024 83.4% 75.2%Sphinx 4,No speakertrainingWSJ5KModel(Vocabularysize: 5,000)82 10 568 1024 43.6% 34.6%Sphinx 4,No speakertrainingHUB4 Model(Vocabularysize: 64,000) 56 28 704 1024 28.5% 23.1%Dragon NaturallySpeakingPreferred(version 3.52),Speaker trainingDictationGrammar99 26 327 1024 65.5% 55.9%I: Number of inserted symbols  O: Number of omitted symbolsS: Number of substituted symbols  Nsol : Total Number of symbols for testingTwo hundred sentences are randomly selected from the generated corpus forgrammatical evaluation.
Of these sentences, 196 sentences are grammatically correct.Three sentences have major grammatical errors and one has minor error.
Theeffectiveness of the system in generating user specifications and queries is supportedA Case-Based Reasoning Approach for Speech Corpus Generation 1001by the high percentage of correctness.
We then follow the methods introduced in [1]to test the performance of the language model derived from the corpus.
We utilize theSphinx 4 Recognition Engine [18] without speaker training to test our language modeland two general models.
A further test is conducted to compare our model with thedictation grammar used in the Dragon Naturally Speaking Preferred (version 3.52)Engine with speaker training.
Table 1 details the test results, which suggest thelanguage model specific to the MCCS can significantly outperform a generallanguage model or a dictation grammar.7   Related WorkGenerating natural language through learning is a relatively new endeavor.
Trainablemethods for surface NLG are introduced in [17] to learn the mapping betweensemantic meaning and syntactic structure so that sophisticated grammars can beavoided.
The implicative assumption of trainable systems is the existence of a largecorpus.
In our project, we can only create a sample sentence set of a limited size,which is not appropriate for training.
Our CBR approach differs from trainablemethods in that instances in the case base are used for adaptation to generate newsentences directly, instead of for calculating statistical distribution.
[10, 12] introducean approach for instance-based natural language generation.
However, instead ofadapting instances to generate sentences, instances are just used to compare withsentences generated by a rule-based system for choosing the final output.
Noadaptation is performed during the generation procedure.
[11] presents a surfacenatural language generator in the real estate domain that employs a case-basedparadigm.
Its adaptation-guided retrieval makes it ultimately similar to our system.However, our approach differs from it in two respects.
Firstly, we employ aquantitative distance measurement for acceptance function.
Compared with thequalitative cost-analysis method used in [11], our method provides a numeric valuefor similarity comparison, which we believe is more straightforward.
Secondly, thesyntactic structure of cases in our system is represented in systemic functionalformalism while graphical tree structure is utilized in [11] to represent the syntactic,lexical, prosodic and acoustic realizations.
Our method is simpler and less prone togrammatical error in generating structured sentences.8   ConclusionsThis paper presents a CBR system to generate a speech corpus for the MCCSapplication.
In comparison to traditional NLG approaches, this system overcomes theinflexibility of template-based methods while avoiding the linguistic sophistication ofrule-based packages.
Our research indicates that CBR learning techniques can performeffectively in generating structured sentences.
This approach is particularly useful ifthe size of the sample sentence set is relatively small.
The study results also suggestthat a language model pertaining to a specific application is a necessity as generalmodels or dictation grammar cannot satisfy the requirements for recognition accuracy.1002 Y.
Fan and E. KendallThis study is part of research to incorporate natural language understandingcapacity into a framework to develop speech-enabled mobile commerce applications.We only explore natural language models for understanding user specifications orqueries at the beginning of a conversation in the context of mobile commerce.
Afterthat, users would be guided by a system-directed dialogue to continue their search fordesired products.
When a user shows interest in a particular product and selects tolisten to the detailed description of the product, the system will play a pre-recordedaudio file.
We believe speech for product description can be generated through CBR-based NLG system in a similar manner.
A NLG method can provide much moreflexibility in generating product descriptions in comparison to pre-recorded audiofiles.
In future work, the CBR approach introduced in this paper should be able to beextended for product description generation.AcknowledgementsThe authors would like to thank Benny Nasution and Adrian Ryan for examining thesample sentences, grammatically evaluating the generated sentences and testing theperformance of different language models.References1.
Becchetti, C. and Ricotti, L.P. (1999): Speech Recognition: Theory and C++Implementation, John Wiley & Sons.2.
Somers, H. (2000): Empirical Approaches to Natural Language Processing, in Handbookof Natural Language Processing (Eds., Dale, R. et al), pp.377-384.
New York, MarcelDekker.3.
Jurafsky, D. et al (1994): The Berkeley Restaurant Project.
In Proceedings of ICSLP-94,Yokohama, Japan, pp.2139-2142.4.
Lesher, G.W.
et al (1999): Effects of ngram order and training text size on wordprediction, In Proc.
of the RESNA?99 Annual Conference, Arlington, VA. pp.52-54.5.
Rudnicky, A.I.
et al (2000): Task and Domain Specific Modeling in the Carnegie MellonCommunicator System, in ICSLP2000, Beijing, China.6.
Lesher, G.W.
and Sanelli, C. (2000): A Web-Based System for Autonomous Text CorpusGeneration, In Proceedings of ISSAAC 2000, Washington DC, U.S.A.7.
Thompson, H.S.
(2000): Corpus Creation for Data-Intensive Linguistics.
In Handbook ofNatural Language Processing (Eds, Dale R. et al), pp.385-401.
New York, Marcel Dekker.8.
Reiter, E. (1995): NLG vs. Templates, In Proceedings of the 5th European Workshop onNatural Language Generation, Leiden, the Netherlands.9.
Oh, A.H. and Rudnicky, A.
(2000): Stochastic Language Generation for Spoken DialogueSystems, In Proceedings of the ANLP/NAACL Workshop on Conversational Systems,May 2000, pp.27-32.10.
Varges, S. and Mellish, C. (2001): Instance-based Natural Language Generation, InProceedings of the 2nd Meeting of the North America Chapter of the Association forComputational Linguistics (NAACL-2001), Pittsburgh, PA, June 2001.11.
Pan, S. and Weng, W. (2002): Designing a speech corpus for instance-based spokenlanguage generation.
In Proceedings of INLG2002, New York, U.S.A.A Case-Based Reasoning Approach for Speech Corpus Generation 100312.
Varges, S. (2003): Instance-based Natural Language Generation, PhD thesis, Institute forCommunicating and Collaborative Systems, School of Informatics, University ofEdinburgh.13.
Jurafsky, D. and Martin, J.H.
(2000): Speech and Language Processing: An Introduction toNatural Language Processing, Computational Linguistics, and Speech Recognition,Prentice Hall.pp.332-334.14.
Sun, J. et al (2000): A Robust Speech Understanding System Using Conceptual RelationalGrammar, In Proceedings of ICSLP?2000, Oct 2000, Beijing, China.15.
Minock, M.J. (2003): A Phrasal Generator for Describing Relational Database Queries, InProceedings of the 9th European Association of Computational Linguistics workshop onNatural Language Generation, Apr 2003, Budapest, Hungary.16.
Halliday, M.A.K.
and Matthiessen, M.I.M.
(2004) An Introduction to FunctionalGrammar, 3rd Edition, ARNOLD.17.
Ratnaparkhi, A.
(2000): Trainable Methods for Surface Natural Language Generation, Inproceedings of the ANLP/NAACL?00, Seattle, WA.
pp.194-201.18.
The CMU Sphinx Group Open Source Speech Recognition Engines.
Retrieved Dec 12,2004.
From http://cmusphinx.sourceforge.net/html/cmusphinx.php
