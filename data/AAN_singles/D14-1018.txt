Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 159?164,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsAsymmetric Features of Human Generated TranslationSauleh EetemadiMichigan State University, East Lansing, MIMicrosoft Research, Redmond, WAsaulehe@microsoft.comKristina ToutanovaMicrosoft ResearchRedmond, WAkristout@microsoft.comAbstractDistinct properties of translated text havebeen the subject of research in linguisticsfor many year (Baker, 1993).
In recentyears computational methods have beendeveloped to empirically verify the lin-guistic theories about translated text (Ba-roni and Bernardini, 2006).
While manycharacteristics of translated text are moreapparent in comparison to the originaltext, most of the prior research has fo-cused on monolingual features of trans-lated and original text.
The contributionof this work is introducing bilingual fea-tures that are capable of explaining dif-ferences in translation direction using lo-calized linguistic phenomena at the phraseor sentence level, rather than using mono-lingual statistics at the document level.We show that these bilingual features out-perform the monolingual features used inprior work (Kurokawa et al., 2009) for thetask of classifying translation direction.1 IntroductionIt has been known for many years in linguis-tics that translated text has distinct patterns com-pared to original or authored text (Baker, 1993).The term ?Translationese?
is often used to referto the characteristics of translated text.
Patternsof Translationese can be categorized as follows(Volansky et al., 2013):1.
Simplification: The process of translation isoften coupled with a simplification process atseveral levels.
For example, there tends to beless lexical variety in translated text and rarewords are often avoided.2.
Explicitation: Translators often have to bemore explicit in their translations due to lackof the cultural context that speakers of thesource language have.
Another manifesta-tion of this pattern is making arguments moreexplicit which can be observed in the heavyuse of cohesive markers like ?therefore?
and?moreover?
in translated text (Koppel andOrdan, 2011).3.
Normalization: Translated text often con-tains more formal and repeating language.4.
Interference: A translator is likely to pro-duce a translation that is structurally andgrammatically closer to the source text ortheir native language.In Figure 1 the size of a word in the ?Translated?section is proportional to the difference betweenthe frequency of the word in original and in thetranslated text (Fellows, 2013).
For example, it isapparent that the word ?the?
is over-representedin translated English as noted by other research(Volansky et al., 2013).
In addition, cohesivemarkers are clearly more common in translatedtext.In the past few years there has been work on ma-chine learning techniques for identifying Trans-lationese.
Standard machine learning algorithmslike SVMs (Baroni and Bernardini, 2006) andBayesian Logistic Regression (Koppel and Ordan,2011) have been employed to train classifiers forone of the following tasks:i.
Given a chunk of text in a specific language,classify it as ?Original?
or ?Translated?.ii.
Given a chunk of translated text, predict thesource language of the translation.iii.
Given a text chunk pair and their languages,predict the direction of translation.There are two stated motivations for the tasksabove: first, empirical validation of linguistic the-ories about Translationese (Volansky et al., 2013),and second, improving statistical machine trans-lation by leveraging the knowledge of the trans-lation direction in training and test data (Lember-159Figure 1: EuroParl Word Cloud Data Visualiza-tion (Translated vs Original)1sky et al., 2012a; Lembersky et al., 2013; Lember-sky et al., 2012b).
Few parallel corpora includ-ing a customized version of EuroParl (Islam andMehler, 2012) and a processed version of Hansard(Kurokawa et al., 2009) are labeled for translatedversus original text.
Using these limited resources,it has been shown that taking the translation direc-tion into account when training a statistical ma-chine translation system can improve translationquality (Lembersky et al., 2013).
However, im-proving statistical machine translation using trans-lation direction information has been limited byseveral factors.1.
Limited Labeled Data: The amount of la-beled data is limited by language and domainand therefore by itself is not enough to makea significant improvement in statistical ma-chine translation.2.
Cross-Domain Scalability: Current meth-ods of Translationese detection do not scaleacross different corpora.
For example, aclassifier trained on EuroParl corpus (Koehn,2005) had in-domain accuracy of 92.7% butout-of-domain accuracy of 64.8% (Koppeland Ordan, 2011).3.
Text Chunk Size: The reported high accu-racy of Translationese detection is based onrelatively large (approximately 1500 tokens)text chunks (Koppel and Ordan, 2011).
Whensimilar tasks are performed at the sentence1This word cloud was created using the word-cloud and tm R packages (Fellows, 2013) fromEuroParl parallel data annotated for translation di-rection (Islam and Mehler, 2012) obtained fromhttp://www.hucompute.org/ressourcen/corpora/56.level the accuracy drops by 15 percentagepoints or more (Kurokawa et al., 2009).
Fig-ure 2 shows how detection accuracy dropswith the reduction of the input text chunksize.
Since parallel data are often availableat the sentence level or small chunks of text,existing detection methods aren?t suitable forthis type of data.Figure 2: Effects of Chunk Size on TranslationeseDetection Accuracy2Motivated by these limitations, in this work wefocus on improving sentence-level classificationaccuracy by using non-domain-specific bilingualfeatures at the sentence level.
In addition to im-proving accuracy, these fine-grained features maybe better able to confirm existing theories or dis-cover new linguistic phenomena that occur in thetranslation process.
We use a fast linear classi-fier trained with online learning, Vowpal Wabbit(Langford et al., 2007).
The Hansard French-English dataset (Kurokawa et al., 2009) is used fortraining and test data in all experiments.2 Related WorkWhile distinct patterns of Translationese havebeen studied widely in the past, the work of Ba-roni and Bernardini (2006) is the first to intro-duce a computational method for detecting Trans-lationese with high accuracy.
Prior work hasshown in-domain accuracy can be very high atthe chunk-level if fully lexicalized features areused (Volansky et al., 2013), but then the phenom-ena learned are clearly not generalizable acrossdomains.
For example, in Figure 1, it can beobserved that content words like ?commission?,?council?
or ?union?
can be used effectively forclassification while they do not capture any gen-eral linguistic phenomena and are unlikely to scale2This is a reproduction of the results of Koppel and Or-dan (2011) using function word frequencies as features for alogistic regression classifier.
Based on the description of howtext chunks were created, the results of the paper (92.7% ac-curacy) are based on text chunk sizes of approximately 1500tokens.160Figure 3: POS Tagged Aligned Sentence Pairsto other corpora.
This is also confirmed by anaverage human performance of 72.7% precisionwith 82.1% recall on a similar task where the testsubjects were not familiar with the domain andwere not able to use domain-specific lexical fea-tures (Baroni and Bernardini, 2006).
A more gen-eral feature set still with high in-domain accuracyis POS tags with lexicalization of function words(Baroni and Bernardini, 2006; Kurokawa et al.,2009).
We build on this feature set and explorebilingual features.The only work to consider features of the twoparallel chunks (one original, one translated) is thework of Kurokawa et al.
(2009).
They simply usedthe union of the n-gram mixed-POS3features ofthe two sides; these are monolingual features ofthe original and translated text and do not look attranslation phenomena directly.
Their work is alsothe only work to look at sentence level detectionaccuracy and report 15 percentage points drop inaccuracy when going from chunk level to sentencelevel classification.3 Bilingual Features for TranslationDirection ClassificationWe are interested in learning common localizedlinguistic phenomena that occur during the trans-lation process when translating in one directionbut not the other.3.1 POS Tag MTUsMinimal translation units (MTUs) for a sentencepair are defined as pairs of source and target wordsets that satisfy the following conditions (Quirkand Menezes, 2006).1.
No alignment links between distinct MTUs.2.
MTUs are not decomposable into smallerMTUs without violating the previous rule.We use POS tags to capture linguistic struc-tures and MTUs to map linguistic structures of3Only replacing content words with their POS tags whileleaving function words as is.the two languages.
To obtain POS MTUs froma parallel corpus, first, the parallel corpus is wordaligned.
Next, the source and target side of thecorpus are tagged independently.
Finally, wordsare replaced with their corresponding POS tagin word-aligned sentence pairs.
MTUs were ex-tracted from the POS tagged word-aligned sen-tence pairs from left to right and listed in sourceorder.
Unigram, bi-gram, and higher order n-gram features were built over this sequence ofPOS MTUs.
For example, for the sentence pairin Figure 3, the following POS MTUs will be ex-tracted: VBZ?D, PRP?
(N,V), RB?ADV,JJ?N, .
?PUNC.3.2 DistortionIn addition to the mapping of linguistic structures,another interesting phenomenon is the reorderingof linguistic structures during translation.
One hy-pothesis is that when translating from a fixed-orderto a free-order language, the order of the target willbe very influenced by the source (almost mono-tone translation), but when translating into a fixedorder language, more re-ordering is required toensure grammaticality of the target.
To capturethis pattern we add distortion to POS Tag MTUfeatures.
We experiment with absolute distortion(word position difference between source and tar-get of a link) as well as HMM distortion (wordposition difference between the target of a link andthe target of the previous link).
We bin the distor-tions into three bins: ?= 0?, ?> 0?
and ?< 0?, toreduce sparsity.4 Experimental SetupFor the translation direction detection task ex-plained in section 1, we use a fast linear classi-fier trained with online learning, Vowpal Wabbit(Langford et al., 2007).
Training data and classi-fication features are explained in section 4.1 and4.2.161Figure 4: Sentence level translation direction detection precision using different features with n-gramlengths of 1 through 5.4.1 DataFor this task we require a parallel corpus with sen-tence pairs available in both directions (sentencesauthored in language A and then translated to lan-guage B and vice versa).
While the customizedversion of EuroParl (Islam and Mehler, 2012) con-tains sentence pairs for many language pairs, noneof the language pairs have sentence pairs availablein both directions (e.g., it does contain sentencesauthored in English and translated into French butnot vice versa).
The Canadian Hansard corpuson the other hand fits the requirement as it has742,408 sentence pairs translated from French toEnglish and 2,203,504 sentences pairs that weretranslated from English to French (Kurokawa etal., 2009).
We use the Hansard data for trainingclassifiers.
For training the HMM word alignmentmodel used to define features, we use a larger setof ten billion words of parallel text from the WMTEnglish-French corpus.4.2 Preprocessing and Feature ExtractionWe used a language filter4, deduplication filter5and length ratio filter to clean the data.
After fil-tering we were left with 1,890,603 English-Frenchsentence pairs and 640,117 French-English sen-tence pairs.
The Stanford POS tagger (Toutanovaand Manning, 2000) was used to tag the Englishand the French sides of the corpus.
The HMMalignment model (Vogel et al., 1996) trained on4A character n-gram language model is used to detect thelanguage of source and target side text and filter them out ifthey do not match their annotated language.5Duplicate sentences pairs are filtered out.WMT data was used to word-align the Hansardcorpus while replacing words with their corre-sponding POS tags.
Due to differences in wordbreaking between the POS tagger tool and ourword alignment tool there were some mismatches.For simplicity we dropped the entire sentence pairwhenever a token mismatch occurred.
This left uswith 401,569 POS tag aligned sentence pairs in theFrench to English direction and 1,184,702 pairs inthe other direction.
We chose to create a balanceddataset and reduced the number of English-Frenchsentences to 401,679 with 20,000 sentence pairsheld out for testing in each direction.5 ResultsThe results of our experiments on the translationdirection detection task are listed in Table 4.
Wewould like to point out several results from thetable.
First, when using only unigram features,the highest accuracy is achieved by the ?POS-MTU + HMM Distortion?
feature, which usesPOS minimal translation units together with dis-tortion.
The highest accuracy overall if obtainedby a ?POS-MTU?
trigram model, showing the ad-vantage of bilingual features over prior work us-ing only a union of monolingual features (repro-duced by the ?English-POS + French-POS?
con-figuration).
While higher order features generallyshow better in-domain accuracy, the advantage oflow-order bilingual features might be even higherin cross-domain classification.6For description of English POS tags see (Marcus et al.,1993) and (Abeill?e et al., 2003) for French162POS MTU (E?F) FE# EF# Example1 NNPS?
(N,C) 336 12 quebecers(NNPS)?
qu?eb?ecoises(N) et(C) des qu?eb?ecois2 IN?
(CL,V) 69 1027 a few days ago(IN)?
il y(CL) a(V) quelques3 PRP?
(N,V) 18 663 he(PRP) is?
le d?eput?e(N) `a(V)4 (NNP,POS)?A 155 28 quebec(NNP) ?s(POS) history?
histoire qu?eb?ecoises(A)5 (FW,FW)?ADV 7 195 pro(FW) bono(FW) work?
b?en?evolement(ADV) travailler6 (RB,MD)?V 2 112 money alone(RB) could(MD) solve?
argent suffirait(V) `a r?esoudreTable 1: POS MTU features with highest weight.
FE# indicates the number of times this feature ap-peared when translating from French to English.66 AnalysisAn interesting aspect of this work is that it is ableto extract features that can be linguistically inter-preted.
Although linguistic analysis of these fea-tures is outside the scope of this work, we listPOS MTU features with highest positive or neg-ative weights in Table 1.
Although the top feature,NNPS?
(N,C)7, in this context is originatingfrom a common phrase used by French speakingmembers of the Canadian Parliament, qu?eb?ecoiseset des qu?eb?ecois, it does highlight an underlyinglinguistic phenomenon that is not specific to theCanadian Parliament.
When translating a pluralnoun from English to French it is likely that onlythe masculine form of the noun appears, while ifit was authored in French with both forms of thenouns, a single plural noun would appear in En-glish as English doesn?t have masculine and femi-nine forms of the word.
A more complete form ofthis feature would have been NNPS?
(N,C,N),but since word alignment models, in general, dis-courage one-to-many alignments, the extractedMTU only covers the first noun and conjunction.7 Conclusion and Future WorkIn this work we introduce new features for transla-tion direction detection that leverage word align-ment, source POS and target POS in the formof POS MTUs.
POS MTUs are a powerful toolfor capturing linguistic interactions between lan-guages during the translation process.
Since POSMTUs are not lexical features they are more likelyto scale across corpora and domains compared tolexicalized features.
Although most of the highweight POS MTU features used in classification(Table 1) are not corpus specific, unfortunately,due to lack of training data in multiple domains,experiments were not run to validate this claim.In future work, we intend to obtain training data7NNPS: Plural Noun, N: Noun, C:Conjunctionfrom multiple domains that enables us to verifycross-domain scalability of POS-MTUs.
In addi-tion, observing linguistic phenomena that occur inone translation direction but not the other can bevery informative in improving statistical machinetranslation quality.
Another future direction forthis work is leveraging sentence level translationdirection detection to improve statistical machinetranslation output quality.
Finally, further investi-gation of the linguistic interpretation of individualfeature that are most discriminating between op-posite translation directions can lead to discoveryof new linguistic phenomena that occur during thetranslation process.AcknowledgementThe authors would like to thank Lee Schwartz foranalyzing classification features and providing lin-guistic insight for them.
We would like to also ac-knowledge the thoughtful comments and detailedfeedback of the reviewers which helped us im-prove the paper.ReferencesAnne Abeill?e, Lionel Cl?ement, and Franc?ois Tou-ssenel.
2003.
Building a treebank for french.
InAnne Abeill?e, editor, Treebanks, volume 20 of Text,Speech and Language Technology, pages 165?187.Springer Netherlands.Mona Baker.
1993.
Corpus linguistics and transla-tion studies: Implications and applications.
Text andtechnology: in honour of John Sinclair, 233:250.Marco Baroni and Silvia Bernardini.
2006.
A newapproach to the study of translationese: Machine-learning the difference between original and trans-lated text.
Literary and Linguistic Computing,21(3):259?274.Ian Fellows, 2013. wordcloud: Word Clouds.
R pack-age version 2.4.163Zahurul Islam and Alexander Mehler.
2012.
Cus-tomization of the europarl corpus for translationstudies.
In LREC, page 2505?2510.Philipp Koehn.
2005.
Europarl: A Parallel Corpusfor Statistical Machine Translation.
In ConferenceProceedings: the tenth Machine Translation Sum-mit, pages 79?86, Phuket, Thailand.
AAMT, AAMT.Moshe Koppel and Noam Ordan.
2011.
Translationeseand its dialects.
In Proceedings of the 49th An-nual Meeting of the Association for ComputationalLinguistics: Human Language Technologies-Volume1, page 1318?1326.
Association for ComputationalLinguistics.David Kurokawa, Cyril Goutte, and Pierre Isabelle.2009.
Automatic detection of translated text andits impact on machine translation.
Proceedings.
MTSummit XII, The twelfth Machine Translation Sum-mit International Association for Machine Transla-tion hosted by the Association for Machine Transla-tion in the Americas.J Langford, L Li, and A Strehl, 2007.
Vowpal wabbitonline learning project.Gennadi Lembersky, Noam Ordan, and Shuly Wint-ner.
2012a.
Adapting translation models to trans-lationese improves SMT.
In Proceedings of the 13thConference of the European Chapter of the Associ-ation for Computational Linguistics, page 255?265.Association for Computational Linguistics.Gennadi Lembersky, Noam Ordan, and Shuly Wint-ner.
2012b.
Language models for machine trans-lation: Original vs. translated texts.
ComputationalLinguistics, 38(4):799?825.Gennadi Lembersky, Noam Ordan, and Shuly Wintner.2013.
Improving statistical machine translation byadapting translation models to translationese.Mitchell P. Marcus, Mary Ann Marcinkiewicz, andBeatrice Santorini.
1993.
Building a large anno-tated corpus of english: The penn treebank.
Com-put.
Linguist., 19(2):313?330, June.Chris Quirk and Arul Menezes.
2006.
Do we needphrases?
: Challenging the conventional wisdom instatistical machine translation.
In Proceedings ofthe Main Conference on Human Language Technol-ogy Conference of the North American Chapter ofthe Association of Computational Linguistics, HLT-NAACL ?06, pages 9?16, Stroudsburg, PA, USA.Association for Computational Linguistics.Kristina Toutanova and Christopher D. Manning.2000.
Enriching the knowledge sources used in amaximum entropy part-of-speech tagger.
In Pro-ceedings of the 2000 Joint SIGDAT Conference onEmpirical Methods in Natural Language Process-ing and Very Large Corpora: Held in Conjunctionwith the 38th Annual Meeting of the Associationfor Computational Linguistics - Volume 13, EMNLP?00, pages 63?70, Stroudsburg, PA, USA.
Associa-tion for Computational Linguistics.Stephan Vogel, Hermann Ney, and Christoph Tillmann.1996.
Hmm-based word alignment in statisticaltranslation.
In Proceedings of the 16th conferenceon Computational linguistics-Volume 2, pages 836?841.
Association for Computational Linguistics.Vered Volansky, Noam Ordan, and Shuly Wintner.2013.
On the features of translationese.
Literaryand Linguistic Computing, page fqt031.164
