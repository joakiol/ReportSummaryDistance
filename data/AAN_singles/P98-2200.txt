Similarity metrics for aligning children's articulation data1.
BackgroundThis paper concerns the implementation andtesting of similarity metrics for the alignment ofphonetic segments in transcriptions of children's(mis)articulations with the adult model.
This hasan obvious application in the development ofsoftware to assist speech and language cliniciansto assess clients and to plan therapy.
This paperwill give some of the background to this generalproblem, but will focus on the computationaland linguistic aspect of the alignment problem.1.1.
Articulation testingIt is well known that a child's acquisition ofphonology is gradual, and can be chartedaccording to the appearance of phoneticdistinctions (e.g.
stops vs. fricatives), the dis-appearance of childish mispronunciations,especially due to assimilation (\[909\] for dog),and the ability to articulate particular phoneticconfigurations (e.g.
consonant clusters).Whether screening whole populations ofchildren, or assessing individual referrals, thearticulation test is an important ool for thespeech clinician.A child's articulatory development is usuallydescribed with reference to an adult model, andin terms of deviations from it: a number ofphonological "processes" can be identified, andtheir significance with respect to thechronological age of the child assessed.
Oftenprocesses interact, e.g.
when spoon ispronounced \[mun\] we have consonant-clusterreduction and assimilation.The problem for this paper is to align thesegments in the transcription of the child'sarticulation with the target model pronunci-ation.
The task is complicated by the need toidentify cases of "metathesis", where thecorresponding sounds have been reordered (e.g.remember -+ \[mtremb~\]) and "merges", a specialcase of consonant-cluster reduction where theHarold L. SOMERSCentre for Computational LinguisticsUMIST, PO Box 88,Manchester M60 1QD, Englandharo ld@cc l ,  umist ,  ac.
ukresulting segment has some of the features ofboth elements in the original cluster (e.g.
sleep\[tip\]).It would be appropriate here to review thesoftware currently available to speech clinicians,but lack of space prevents us from doing so (seeSomers, forthcoming).
Suffice it to say thatsoftware does exist, but is mainly forgrammatical and lexical analysis.
Of the tinynumber of programs which specifically addressthe problem of articulation testing, none, as faras one can tell, involve automatic alignment ofthe data.1.2.
Segment alignmentIn a recent paper, Covington (1996) describedan algorithm for aligning historical cognates.The present author was struck by the possibilityof using this technique for the child-languageapplication, a task for which a somewhat similaralgorithm had been developed some years ago(Somers 1978, 1979).
In both algorithms, thephonetic segments are interpreted as bundles ofphonetic features, and the algorithms include asimple similarity metric for comparing thesegments pairwise.
The algorithms differsomewhat in the way the search space isreduced, but the results are quite comparable(Somers, forthcoming).Coincidentally, a recent article by Connolly(1997) has suggested a number of ways ofquantifying the similarity or difference betweentwo individual phones, on the basis of per-ceptual and articulatory differences.
Connolly'smetric is also feature-based, but differs from theothers mentioned in its complexity.
In particular,the features can be differentially weighted forsalience, and, additionally, not all the featuresare simple Booleans.
In the second part of hisarticle, Connolly introduces a distance measurefor comparing sequences of phones, based onthe Levenshtein distance well-known in the1227spell-checking, speech-processing and corpus-alignment literatures (inter alia).
Again, thismetric can be weighted, to allow substitutions tobe valued differentially (on the basis of theindividual phone distance measure as describedin the first part), and to deal with merges andmetathesis.Although his methods are clearly com-putational in nature, Connolly reports (personalcommunication) that he has not yet implementedthem.
In this paper, we describe a simple imple-mentation and adaptation of Connolly's metrics,and a brief critical evaluation of their per-formance on some child language data (both realand artificial).2.
The alignment algorithmsWe have implemented three versions of analignment algorithm, utilising different segmentsimilarity measures, but the same sequencemeasure.2.1.
Coding the inputBefore we consider the algorithms themselves,however, it is appropriate to mention briefly theissue of transcription.
On the one hand,children's articulations can include a muchwider variety of phones than those which arefound in the target system; in addition, certainsecondary phonetic features may be particularlyimportant in the description of the child'sarticulation (e.g.
spreading, laryngealization).
Sothe transcriptions need to be "narrow".
On theother hand, speech clinicians nevertheless tendto use a "contrastive" transcription, essentiallyphonemic except where the child's articulationdiffers from the target: so normal allophonicvariation will not necessarily be reflected in thetranscription.
Any program that is to be used forthe analysis of articulation data will need anappropriate coding scheme which allows anarrow transcription in a fairly transparentnotation.
Some software offers phonetictranscription schemes based on the ASCIIcharacter set (e.g.
Perry 1995).
Alternatively, itseems quite feasible to allow the transcriptionsto be input using a standard word-processor anda phonetic font, and to interpret he symbolsaccordingly.
For a commercial implementationit would be better to follow the standardproposed by the IPA (Esling & Gaylord 1993),which has been approved by the ISO, andincluded in the Unicode definitions.2.2.
Internal representationRepresenting the phonetic segments as bundlesof features is an obvious technique, and onewhich is widely adopted.
In the algorithmreported in Somers (1979) - -  henceforth CAT- -  phones are represented as bundles of binaryarticulatory features.
Some primary features alsoserve as secondary features where appropriate(e.g.
dark 'l' is marked as VEL(ar)), but there arealso explicit secondary features, e.g.ASP(iration).Connolly (1997) suggests two alternativefeature representations.
The first is based onperceptual features, which, he claims, are moresignificant han articulatory features "from thepoint of view of communicative dysfunction"(p.276).
On the other hand, he admits that usingperceptual features can be problematic, unless"we are prepared to accept a relatively unrefinedquantification method" (p.277).
Connolly rejectsa number of perceptual feature schemes forconsonants in favour of one proposed by Line(1987), which identifies two perceptual featuresor axes, "friction strength" (FS) and "pitch" (P),and divides the consonant phones into sixgroups, differentiated by their score on each ofthese axes, as shown in Figure 1.Henceforth we will refer to this scheme as"FS/P".
In fact, there are a number of drawbacksand shortcomings in Connolly's scheme for ourpurposes, notably the absence of many non-English phones (all non-pulmonics, uvulars,retroflexes, trills and taps), and there is noindication how to handle secondary featurestypically needed to transcribe children'sarticulations accurately.
We have tried to rectifythe first shortcoming in our implementation, butit is not obvious how to deal with the second.Connoily's alternative feature representationis based on artieulatory features, adapted fromLadefoged's (1971) system, though unlike thefeatures used in the CAT scheme, some ofthe features are not binary.
Figure 2 shows thefeature scheme for consonants, which we haveadapted slightly, in detail.
We will refer to this1228Figure 1.
Perceptual feature-based representation (FS/P) of consonants from Connolly (1997:2792I)Group Friction-strength Pitch Members1 0.0 0.0 bilabial plosives; labial and alveolar nasals2 0.0 0.4 glottal obstruents; central and lateral approximants;palatal and velar nasals3 0.4 0.3 alveolar plosives; labial and dental fricatives; voicelessnasals4 0.5 0.8 velar and palatal obstruents5 0.8 0.9 palato-alveolar nd lateral fricatives6 1.0 1.0 alveolar fricatives and affricatesFigure 2.
Articulatory feature scheme (Lad) for consonants, adapted from Connolly (1997:28299.
(a) non-binary features with explanations ofthe values:glottalic: I (ejective), 0.5 (pulmonic), 0 (implosive)voice: 1 (glottal stop), 0.8 (laryngealized), 0.6 (voiced), 0.2 (murmur), 0 (voiceless)place (i.e.
passive articulator): 1(labial), 0.9 (dental), 0.85 (alveolar), 0.8 (post-alveolar), 0.75 (pre-palatal), 0.7 (palatal), 0.6 (velar), 0.5 (uvular), 0.3 (pharyngeal), 0 (glottal)constrictor: 1(labial), 0.9 (dental), 0.85 (apical), 0.75 (laminal), 0.6 (dorsal), 0.3 (radical), 0 (glottal)stop: 1 (stop), 0.95 (affricate), 0.9 (fricative), 0 (approximant)length: 1 (long), 0.5 (half-long)(b) binary features:velaric (for clicks), aspirated, nasal, lateral, trill, tap, retroflex, rounded, syllabic, unreleased, groovedscheme as "Lad".
Again, some features orfeature values needed to be added, notably avalue of "stop" for affricates.Let us now consider the similarity metricsbased on these three schemes.2.3.
Similarity metrics for individualphonesThe similarity (or distance) metric is the key tothe alignment algorithm.
In the case of CAT, thedistance measure is quite simply a count of thebinary features for which the polarity differs.
Sofor example, when comparing the articulation\[d\] with a target of \[st\], the Is\] and \[d\] differ interms of three features (VOICE, STOP and FRIC)while \[t\] and \[d\] differ in only one (VOICE): so\[d\] is more similar to \[t\] than to \[s\].In FS/P, the two features are weighted toreflect he greater importance of FS over P, theformer being valued double the latter.
Tocalculate the similarity of two phones we add thedifference in their FS scores to half thedifference in their P scores.
If the two phonesare in the same group, the score is set at 0.05(unless they are identical, in which case it is 0).Thus, to take our \[st\]-~\[d\] example again, since\[s\] is in group 6, and \[t\] and \[d\] both in group 3,\[t\]-\[d\] scores 0.05, \[s\]-\[d\] 0.95.The similarity metric based on the Ladscheme is simpler, in that all the features areequally weighted.
The Lad score is the simplysum of the score differences for all the features.For our example of \[st\]-~\[d\], the \[t\]-\[d\]difference is only in one feature, "voice", withvalues 0 and 0.6 respectively, while the \[s\]-\[d\]difference has the 0.6 voice difference plus adifference of 0.1 in the "stop" feature (\[d\] scoresl, \[s\] scores 0.9).All three metrics agree that \[d\] is moresimilar to \[t\] than to \[s\], as we might hope andexpect.
As we will see below, the differentfeature schemes do not always give the sameresult however.2.4.
Sequence comparisonConnolly's proposed algorithm for aligningsequences of phones is based on the Levenshteindistance.
He calls it a "weighted" Levenshteindistance, because the algorithm would have totake into account he similarity scores betweenindividual segments when deciding in cases ofcombined substitution and deletion (e.g.
our \[st\]--4 \[d\] example) which segment o mark as1229inserted or deleted.
Connolly suggests (p.291)that substitutions hould always be preferredover insertions and deletions, and thisassumption was also built into the algorithm weoriginally developed in Somers (1979).However, this does not always give the correctsolution: for example, if the sequence \[skr\] (e.g.in scrape) was realised as \[J'sk\], we would preferthe alignment in (la) with one insertion and onedeletion, to that in (lb) with only substitutions.
(1 )a .
- s  k r b. s k rJ ' sk -  J ' skThe algorithm would also have to be adjusted toallow for metathesis, though Connolly suggeststhat merges do not present a special problembecause they can always be treated as asubstitution plus an omission (p.292) - -  againwe disagree with this approach and willillustrate the problem below.For these reasons we have not used aLevenshtein distance algorithm for our newimplementation of the alignment task.
Asdescribed in Somers (forthcoming), the originalalignment algorithm in CAT relied on a singlepredetermined anchor point, and thenexhaustively compared all possible alignmentseither side of the anchor, though only when thenumber of segments differed.We now prefer a more general recursivealgorithm in which we identify in the twostrings a suitable anchor, then split the stringsaround the two anchor points, and repeat theprocess with each half string until one (or both)is (are) reduced to the empty string.
Thealgorithm is given in Figure 3.
Step 2 is the keyto the algorithm, and is primed to look first foridentical phones, else vowels, else the phonesare compared pairwise exhaustively.
If there is achoice of"best match", we prefer values of i andj that are similar, and near the middle of thestring.
Although the algorithm is looking for thebest match, it is also looking for possiblemerges, which will be identified when there isno single best match.2.5.
Identifying metathesisIt is difficult to incorporate a test formetathesis directly into the above algorithm, andit is better to make a second pass looking for thisFigure 3.
The alignment algorithm.Let X and Y be the strings to be aligned, oflength m and n, where each X\[i\], Y\[j\], l<i<m,1 <j<_<_<_<_~, is a bundle of features.1.
If X=\[\] and Y=\[\], then stop; else if X=\[\](Y=\[\]) then mark all segments in Y (X) as"inserted" ("omitted") and stop; elsecontinue.2.
Find the best matching X\[i\] and Y\[/\], andmark these as "aligned".3.
Take the substring X\[1\]..X\[i-1\] and thesubstring Y\[I\]..Y\[j-1\] and repeat from step1; and similarly with the substringsX\[i+ 1\]..X\[m\], and Y\[j+ l\]..Y\[n\].phenomenon explicitly.
For our purposes it isreasonable to focus on consonants.
Metathesiscan occur either with contiguous phones, e.g.\[desk\] ~ \[deks\], or with phones either side of avowel, e.g.
\[ehfant\] ~ \[efflont\].
In addition, oneor both of the phones may have undergone someother phonological processes, e.g.
\[ehfont\]\[epIlant\], where the \[f\] and \[1\] have beenexchanged, but the \[f\] realised as a \[p\].The algorithm described above will analysemetatheses in one of two ways, depending onvarious other factors.
One analysis will simplyalign the phones with each other.
To recognisethis as a case of metathesis, we need to see if thecrossing alignment gives a better score.
Theother analysis will align one or other of theidentical phones, and mark the others asomitted/inserted.
The second pass looks out forboth these situations.3.
EvaluationIn this section we consider how the algorithmdeals with some data, both real and simulated.We want (a) to see if the algorithm as describedgets alignments hat correspond to the alignmentfavoured by a human; and (b) to compare thedifferent feature systems that have beenproposed.For many of the examples we have used,there is no problem, and nothing to choosebetween the systems.
These are cases of simpleomission (e.g.
spoon~\[pun\]), insertion (Everton\[eVatAnt\]), substitution (feather ~ \[buya\]), and1230\[eVOtAnt\]), substitution (feather -~ \[beyo\]), andvarious combinations of those processes(Christmas-~\[gixmox\], aeroplane~\[wejabein\]).Cases of inserted vowels (e.g.
spoon-+\[supun\])were analysed correctly when the inserted vowelwas different from the main vowel.
So forexample chimney ~ \[tJ'unml\] caused difficulty,with the alignment (2a) preferred over (2b).(2)a.
t J ' imn t - -  b. t J ' xm-ntt J 'xm- In I  tSxm xnlDifferences between the feature systemsshow up when the alignment combinessubstitutions and omissions, and the "bestmatch" comes into play.
Vocalisation ofsyllabics (e.g.
bottle \[bDt.~\] -~ \[bt)?uw\]) causedproblems, with the syllabic \[~\] aligning with \[u\]in the CAT system, \[7\] in FS/P, and \[w\] in Lad.In other cases where the systems gavedifferent results, the FS/P system most oftengave inappropriate alignments.
For example,monkey \[rnA0ki\] ~ \[mAn?i\] was correctly alignedas in (3a) by the other two systems, but as (3b)with FS/P.
(3) a. m ArJ ki  b. mA-0k imAn?
i  mAn ?--iFor teeth \[ti0\]-~\[?isx\], FS/P aligned the Ix\] withthe \[0\] while the other systems got the morelikely \[0\]-~\[s\] alignment.
Similarly, the Lad andCAT systems labelled the \[a\] as omitted inbridge \[baId3\]~\[gLx\], while FS/P aligned it with\[g\].When identifying merges on the other hand,only CAT had any success, in sleep \[s\[ip\]~\[tip\](but not when the \[1\] is not marked as voiceless).In analysing \[fl\]~\[b\], CAT suggests a merge,FS/P marks the If\] as omitted, Lad the \[1\].
Inprinciple, the FS/P system offers most scope foridentifying merges, as it only recognises ixdifferent classes of consonant phone, While theLad system is too fine-grained: indeed, we wereunable to find (or simulate) any plausible casewhich Lad would analyse as a merge.Against that it should also be noted that suchanalyses cannot be carried out totally inisolation.
For example, compare the case where\[~\] is only used when \[sl\] is expected to the onewhere Is\] is generally realised as \[t\]: we mightwant to analyse only the former case as a merge,the latter as a substitution plus omission.
Itshould be remembered that the alignment task isonly the first step of the analysis of the child'sphonetic system.4.
ConclusionBecause of its poor performance with manyalignments, we must reject the FS/P system.This is not a great surprise: a feature systembased on perceptual differences seemsintuitively questionable for an articulationanalysis task.
There does not seem much tochoose between Lad and CAT, though the formergives a more subtle scoring system, which mightbe useful for screening children.
On the otherhand, it never identifies merges, even in highlyplausible cases, so the system using simplerbinary articulatory features may be the bestsolution.Whichever system is used, it seems that anacceptable l vel of success can be achieved withthe algorithm described here, and it could formthe basis of software for the automatic analysisof children's articulation data.5.
ReferencesConnolly, John H. (1997) Quantifying target-realization differences.
Clinical Linguistics &Phonetics 11:267-298.Covington, Michael A.
(1996) An algorithm to alignwords for historical comparison.
ComputationalLinguistics 22:481--496.Esling, John H. & Harry Gaylord (1993) Computercodes for phonetic symbols.
Journal of theInternational Phonetic Association 23:83-97.Ladefoged, P. (1971) Preliminaries to LinguisticPhonetics.
Chicago: University of Chicago Press.Line, Pippa (1987) An Investigation of AuditoryDistance.
M.Phil.
dissertation, De MontfortUniversity, Leicester.Perry, Cecyle K. (1995) Review of PhonologicalDeviation Analysis by Computer (PDAC).
ChildLanguage Teaching and Therapy 11:331-340.Somers, H.L.
(1978) Computerised ArticulationTesting.
M.A.
thesis, Manchester University.Somers, H.L.
(1979) Using the computer to analysearticulation test data.
British Journal of Disordersof Communication 14:231-240.Somers, H.L.
(forthcoming) Aligning phoneticsegments for children's articulation assessment.
Toappear in Computational Linguistics.1231Similarity metrics for aligningchildren's articulation dataAn important step in the automatic analysis ofchild-language articulation data is to align thetranscriptions of children's (mis)articulationswith adult models.
The problems underlyingthis task are discussed and a number ofalgorithms are presented and compared.
Theseare based on various similarity or distancemeasures for individual phonetic segments,considering perceptual and articulatoryfeatures, which may be weighted to reflectsalience, and on sequence comparison.0")I~'~'I$, 7,/l,':f'J ~Ao"9~i l ' I~t i !
i~Di~f  ,AcknowledgementsThanks to Joe Somers for providing some of theexample data; and to Marie-Jo Proulx and AyakoMatsuo who helped with the abstracts.Une comparaison de quelquesmesures de ressemblance pourl'analyse comparative destranscriptions d'articulationinfantileEn ce qui concerne l'analyse des transcriptionsd'articulation infantile, il est tr~s importantd'identifier les correspondences entre lesarticulations de l'enfant, parfois fausses, et celles del'adulte per~ues en tant que module.
Nous d6crivonsI'automatisation de cene t~che, et pr6sentonsquelques algorithmes dont nous faisons unecomparaison 6valuative.
Les algorithmes e basentsur certaines mesures de ressemblance (ou distance)phon6tique entre les segments individuels quiconsid~rent les traits perceptuels et articulatoires,ceux qui peuvent porter des poids scion leursaillance.
I1 s'agit aussi d'une comparaison des6quences.Les erreurs d'articulation sont parfois de simplessubstitutions d'un son par un autre, ou des insertionsou omissions, qui sont faciles h analyser.
Lesprobl~mes d6coulent surtout des "m6tath6ses" (parex.
dl~phant s'exprime \[efela'\]), surtout o/l il y a aussiune substitution (par ex.
\[epela-\] pour dl~phant), etdes "fusions" (par ex.
crayon \[kRejS\] ---> \[xejS\]) o/l leIx\] rassemble 6galement au \[k\] et au \[R\].Les trois mesures de ressemblance utilisent lestraits phon6tiques: un syst6me de simples traitsarticulatoires binaires (TAB) 61abor6 par le presentauteur; un syst~me de traits perceptuels ("force defriction" et "ton" FF/T) 61abor~ par Connolly(1997); et un syst+me de traits articulatoires non-binaires bas6 sur Ladefoged (1971).
Pour beaucoupd'exemples, les trois syst~mes ont trouv~ la m~mesolution.
L~t ot~ ils different, le syst~me FF/T estmoins performant.
Entre les deux autres, le syst6mele plus simple (TAB) semble aussi ~tre le plusrobuste.
Pour la comparaison des s6quences, un seulalgorithme st pr6sent6.
I1 fonctionne tr~s bien, saufquand il s'agit d'une voyelle identique ins6r6e (parex.
\[kR~j~ ~ \[k~Rej3-'\]).Parmi les logiciels commercialis~s destines auxorthophonistes actuellement disponibles, aucun necomprend 'analyse automatique des articulations,celle-ci ~tant consid~r~e "trop difficile".
Le pr6senttravail sugg&e qu'un tel logiciel est au contraire toutfait concevable.1232
