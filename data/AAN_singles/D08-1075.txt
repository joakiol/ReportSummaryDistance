Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 715?724,Honolulu, October 2008. c?2008 Association for Computational LinguisticsLearning the Scope of Negation in Biomedical TextsRoser Morante?, Anthony Liekens?, Walter Daelemans?CNTS - Language Technology Group?, Applied Molecular Genomics Group?University of AntwerpPrinsstraat 13, B-2000 Antwerpen, Belgium{Roser.Morante,Anthony.Liekens,Walter.Daelemans}@ua.ac.beAbstractIn this paper we present a machine learningsystem that finds the scope of negation inbiomedical texts.
The system consists of twomemory-based engines, one that decides if thetokens in a sentence are negation signals, andanother that finds the full scope of these nega-tion signals.
Our approach to negation detec-tion differs in two main aspects from existingresearch on negation.
First, we focus on find-ing the scope of negation signals, instead ofdetermining whether a term is negated or not.Second, we apply supervised machine learn-ing techniques, whereas most existing systemsapply rule-based algorithms.
As far as weknow, this way of approaching the negationscope finding task is novel.1 IntroductionIn this paper we present a machine learning systemthat finds the scope of negation in biomedical texts.The system consists of two classifiers, one that de-cides if the tokens in a sentence are negation sig-nals (i.e., words indicating negation), and anotherthat finds the full scope of these negation signals.Finding the scope of a negation signal means deter-mining at sentence level which words in the sentenceare affected by the negation.
Our approach differs intwo main aspects from existing research.
First, wefocus on finding the scope of negation signals, in-stead of determining whether a term is negated ornot.
Second, we apply supervised machine learn-ing techniques, whereas most existing systems applyrule-based algorithms.Predicting the scope of negation is important ininformation extraction from text for obvious rea-sons; instead of simply flagging the sentences con-taining negation as not suited for extraction (whichis currently the best that can be done), correct se-mantic relations can be extracted when the scope ofnegation is known, providing a better recall.Not being able to recognize negation can alsohinder automated indexing systems (Mutalik et al,2001; Rokach et al, 2008).
As Mutalik et al (2001)put it, ?to increase the utility of concept indexing ofmedical documents, it is necessary to record whetherthe concept has been negated or not?.
They highlightthe need to detect negations in examples like ?no ev-idence of fracture?, so that an information retrievalsystem does not return irrelevant reports.Szarvas et al (2008) report that 13.45% of thesentences in the abstracts section of the BioScopecorpus and 13.76% of the sentences in the full paperssection contain negations.
A system that does notdeal with negation would treat these cases as falsepositives.The goals of this research are to model the scopefinding task as a classification task similar to the se-mantic role labeling task, and to test the performanceof a memory?based system that finds the scope ofnegation signals.
Memory-based language process-ing (Daelemans and van den Bosch, 2005) is basedon the idea that NLP problems can be solved byreuse of solved examples of the problem in mem-ory, applying similarity-based reasoning on theseexamples in order to solve new problems.
As lan-guage processing tasks typically involve many sub-regularities and (pockets of) exceptions, it has been715argued that lazy learning is at an advantage in solv-ing these highly disjunctive learning problems com-pared to eager learning, as the latter eliminates notonly noise but also potentially useful exceptions(Daelemans et al, 1999).
Memory-based algorithmshave been successfully applied in language process-ing to a wide range of linguistic tasks, from phonol-ogy to semantic analysis, such as semantic role la-beling (Morante et al, 2008).The paper is organised as follows.
In Section 2,we summarise related work.
In Section 3, we de-scribe the corpus with which the system has beentrained.
In Section 4, we introduce the task to beperformed by the system, which is described in Sec-tion 5.
The results are presented and discussed inSection 6.
Finally, Section 7 puts forward some con-clusions.2 Related workNegation has been a neglected area in open-domainnatural language processing.
Most research has beenperformed in the biomedical domain and has fo-cused on detecting if a medical term is negated ornot, whereas in this paper we focus on detecting thefull scope of negation signals.Chapman et al (2001) developed NegEx, a reg-ular expression based algorithm for determiningwhether a finding or disease mentioned within nar-rative medical reports is present or absent.
The re-ported results are 94.51 precision and 77.84 recall.Mutalik et al (2001) developed Negfinder, a rule-based system that recognises negated patterns inmedical documents.
It consists of two tools: a lexi-cal scanner called lexer that uses regular expressionsto generate a finite state machine, and a parser.
Thereported results are 95.70 recall and 91.80 precision.Sanchez-Graillet and Poesio (2007) present ananalysis of negated interactions in biological textsand a heuristics-based system that extracts such in-formation.
They treat all types of negation: (i) Af-fixal negation, which is expressed by an affix.
(ii)Noun phrase or emphatic negation, expressed syn-tactically by using a negative determiner (e.g.
no,nothing).
(iii) Inherent negation, expressed by wordswith an inherently negative meaning (e.g.
absent).
(iv) Negation with explicit negative particles (e.g.no, not).
The texts are 50 journal articles.
The pre-liminary results reported range from 54.32 F-scoreto 76.68, depending on the method applied.Elkin et al (2005) describe a rule-based systemthat assigns to concepts a level of certainty as part ofthe generation of a dyadic parse tree in two phases:First a preprocessor breaks each sentence into textand operators.
Then, a rule based system is used todecide if a concept has been positively, negatively,or uncertainly asserted.
The system achieves 97.20recall and 98.80 precision.The systems mentioned above are essentiallybased on lexical information.
Huang andLowe (2007) propose a classification scheme ofnegations based on syntactic categories and patternsin order to locate negated concepts, regardless oftheir distance from the negation signal.
Their hybridsystem that combines regular expression matchingwith grammatical parsing achieves 92.60 recall and99.80 precision.Additionally, Boytcheva et al (2005) incorporatethe treatment of negation in a system, MEHR, thatextracts from electronic health records all the in-formation required to generate automatically patientchronicles.
According to the authors ?the nega-tion treatment module inserts markers in the text fornegated phrases and determines scope of negation byusing negation rules?.
However, in the paper thereis no description of the rules that are used and it isnot explained how the results presented for negationrecognition (57% of negations correctly recognised)are evaluated.The above-mentioned research applies rule-basedalgorithms to negation finding.
Machine learningtechniques have been used in some cases.
Averbuchet al (2004) developed an algorithm that uses infor-mation gain to learn negative context patterns.Golding and Chapman (2003) experiment withmachine learning techniques to distinguish whethera medical observation is negated by the word not.Their corpus contains 207 selected sentences fromhospital reports, in which a negation appears.
Theyuse Naive Bayes and Decision Trees and achieve amaximum of 90 F-score.
According to the authors,their main finding is that ?when negation of a UMLSterm is triggered with the negation phrase not, if theterm is preceded by the then do not negate?.Goryachev et al (2006) compare the perfor-mance of four different methods of negation de-716tection, two regular expression-based methods andtwo classification-based methods trained on 1745discharge reports.
They show that the regularexpression-based methods have better agreementwith humans and better accuracy than the classifica-tion methods.
Like in most of the mentioned work,the task consists in determining if a medical term isnegated.Rokach et al (2008) present a new pattern-basedalgorithm for identifying context in free-text med-ical narratives.The originality of the algorithm liesin that it automatically learns patterns similar to themanually written patterns for negation detection.Apart from work on determining whether a term isnegated or not, we are not aware of research that hasfocused on learning the full scope of negation sig-nals inside or outside biomedical natural languageprocessing.
The research presented in this paper pro-vides a new approach to the treatment of negationscope in natural language processing.3 CorpusThe corpus used is a part of the BioScope cor-pus (Szarvas et al, 2008)1, a freely available re-source that consists of medical and biological texts.Every sentence is annotated with information aboutnegation and speculation that indicates the bound-aries of the scope and the keywords, as shown in (1).
(1) PMA treatment, and <xcope id=?X1.4.1?><cuetype=?negation?
ref=?X1.4.1?>not<cue> retinoicacid treatment of the U937 cells</xcope> acts ininducing NF-KB expression in the nuclei.A first characteristic of the annotation of scope inthe BioScope corpus is that all sentences that assertthe non-existence or uncertainty of something areannotated, in contrast to other corpora where onlysentences of interest in the domain are annotated.A second characteristic is that the annotation is ex-tended to the biggest syntactic unit possible so thatscopes have the maximal length.
In (2) below, nega-tion signal no scopes over primary impairment ofglucocorticoid metabolism instead of scoping onlyover primary.
(2) There is [no] primary impairment of glucocorticoidmetabolism in the asthmatics.1Web page: www.inf.u-szeged.hu/rgai/bioscope.The part used in our experiments are the biologi-cal paper abstracts from the GENIA corpus (Collieret al, 1999).
This part consists of 11,872 sentencesin 1,273 abstracts.
We automatically discarded fivesentences due to annotation errors.
The total num-ber of words used is 313,222, 1,739 of which arenegation signals that belong to the different typesdescribed in (Sanchez-Graillet and Poesio, 2007).We processed the texts with the GENIA tag-ger (Tsuruoka and Tsujii, 2005; Tsuruoka et al,2005), a bidirectional inference based tagger that an-alyzes English sentences and outputs the base forms,part-of-speech tags, chunk tags, and named entitytags in a tab-separated format2.
Additionally, weconverted the annotation about scope of negationinto a token-per-token representation.Table 1 shows an example sentence of the corpusthat results from converting and processing the Bio-Scope representation.
Following the standard for-mat of the CoNLL Shared Task 2006 (Buchholz andMarsi, 2006), sentences are separated by a blank lineand fields are separated by a single tab character.
Asentence consists of tokens, each one starting on anew line.
A token consists of the following 10 fields:1.
ABSTRACT ID: number of the GENIA ab-stract.2.
SENTENCE ID: sentence counter starting at 1for each new abstract.3.
TOKEN ID: token counter, starting at 1 foreach new sentence.4.
FORM: word form or punctuation symbol.5.
LEMMA: lemma of word form.6.
POS TAG: Penn Treebank part-of-speech tagsdescribed in (Santorini, 1990).7.
CHUNK TAG: IOB (Inside, Outside, Begin)tags produced by the GENIA tagger that indi-cate if a token is inside a certain chunk, outside,or at the beginning.8.
NE TAG: IOB named entity tags produced bythe GENIA tagger that indicate if a token is in-2The accuracy of the tagger might be inflated due to the factthat it was trained on the GENIA corpus.717ABSTR SNT TOK FORM LEMMA POS CHUNK NE NEG NEG SCOPEID ID ID TAG TAG TAG SGN10415075 07 1 NF-kappa NF-kappa NN B-NP B-protein I-NEG O-NEG10415075 07 2 B B NN I-NP I-protein I-NEG O-NEG10415075 07 3 binding binding NN I-NP O I-NEG O-NEG10415075 07 4 activity activity NN I-NP O I-NEG O-NEG10415075 07 5 was be VBD B-VP O I-NEG O-NEG10415075 07 6 absent absent JJ B-ADJP O NEG I-NEG O-NEG10415075 07 7 in in IN B-PP O I-NEG O-NEG10415075 07 8 several several JJ B-NP O I-NEG O-NEG10415075 07 9 SLE SLE NN I-NP O I-NEG O-NEG10415075 07 10 patients patient NNS I-NP O I-NEG O-NEG10415075 07 11 who who WP B-NP O I-NEG O-NEG10415075 07 12 were be VBD B-VP O I-NEG O-NEG10415075 07 13 not not RB I-VP O NEG I-NEG I-NEG10415075 07 14 receiving receive VBG I-VP O I-NEG I-NEG10415075 07 15 any any DT B-NP O I-NEG I-NEG10415075 07 16 medication medication NN I-NP O I-NEG I-NEG10415075 07 17 , , , O O I-NEG I-NEG10415075 07 18 including include VBG B-PP O I-NEG I-NEG10415075 07 19 corticosteroidscorticosteroid NNS B-NP O I-NEG I-NEG10415075 07 20 .
.
.
O O O-NEG O-NEGTable 1: Example sentence of the BioScope corpus converted into columns format.side a certain named entity, outside, or at thebeginning.9.
NEG SIGNAL: tokens that are negation signalsare marked as NEG.
Negation signals in theBioScope corpus are not always single words,like the signal could not.
After the tagging pro-cess the signal cannot becomes also multiwordbecause the tagger splits it in two words.
Inthese cases we assign the NEG mark to not.10.
NEG SCOPE: IO tags that indicate if a tokenis inside the negation scope (I-NEG), or out-side (O-NEG).
These tags have been obtainedby converting the xml files of BioScope.
Eachtoken can have one or more NEG SCOPE tags,depending on the number of negation signals inthe sentence.4 Task descriptionWe approach the scope finding task as a classifica-tion task that consists of classifying the tokens ofa sentence as being a negation signal or not, andas being inside or outside the scope of the negationsignal(s).
This happens as many times as there arenegation signals in the sentence.
Our conception ofthe task is inspired by Ramshaw and Marcus?
rep-resentation of text chunking as a tagging problem(Ramshaw and Marcus, 1995) .The information that can be used to train the sys-tem appears in columns 1 to 8 of Table 1.
The infor-mation to be predicted by the system is contained incolumns 9 and 10.As far as we know, approaching the negationscope finding task as a token per token classifica-tion task is novel, whereas at the same time it con-forms to the well established standards of the re-cent CoNLL Shared Tasks3 on dependency parsing(Buchholz and Marsi, 2006; Nivre et al, 2007) andsemantic role labeling (Surdeanu et al, 2008).
Bysetting up the task in this way we show that the nega-tion scope finding task can be modelled in a waysimilar to semantic role labeling, and by conform-ing to existing standards we show that learning thescope of negation can be integrated in a joint learn-ing task with dependency parsing and semantic rolelabeling.3Web page of CoNLL:http://www.ifarm.nl/signll/conll/.7185 System descriptionIn order to solve the task, we apply supervised ma-chine learning techniques.
We build a memory-based scope finder, that tackles the task in twophases.
In the first phase a classifier predicts if a to-ken is a negation signal, and in the second phase an-other classifier predicts if a token is inside the scopeof each of the negation signals.
Additionally, theoutput of the second classifier is postprocessed withan algorithm that converts non-consecutive blocks ofscope into consecutive, as explained in Section 5.3.As for the first and second phases, we use amemory?based classifier as implemented in TiMBL(version 6.1.2) (Daelemans et al, 2007), a super-vised inductive algorithm for learning classificationtasks based on the k-nearest neighbor classificationrule (Cover and Hart, 1967).
Similarity is defined bycomputing (weighted) overlap of the feature valuesof a test instance and training instances.
The metriccombines a per-feature value distance metric (Costand Salzberg, 1993) with gain ratio (Quinlan, 1993)based global feature weights that account for relativedifferences in discriminative power of the features.5.1 Negation signal findingIn this phase, a classifier predicts whether a token isa negation signal or not.
The memory-based classi-fier was parameterised by using overlap as the sim-ilarity metric, gain ratio for feature weighting, andusing 7 k-nearest neighbors.
All neighbors haveequal weight when voting for a class.
The instancesrepresent all tokens in the corpus and they have thefollowing features:?
Of the token: Form, lemma, part of speech, andchunk IOB tag.?
Of the token context: Form, POS, and IOB tagof the three previous and three next tokens.5.2 Scope findingIn the first step of this phase, a classifier predictswhether a token is in the scope of each of the nega-tion signals of a sentence.
A pair of a negation signaland a token from the sentence represents an instance.This means that all tokens in a sentence are pairedwith all negation signals that occur in the sentence.For example, token NF-kappa in Table 1 will be rep-resented in two instances as shown in (3).
An in-stance represents the pair [NF?KAPPA, absent] andanother one represents the pair [NF?KAPPA, not].
(3) NF-kappa absent [features] I-NEGNF-kappa not [features] O-NEGNegation signals are those that have been classi-fied as such in the previous phase.
Only sentencesthat have negation signals are selected for this phase.The memory?based algorithm was parameterisedin this case by using overlap as the similarity metric,gain ratio for feature weighting, using 7 k-nearestneighbors, and weighting the class vote of neighborsas a function of their inverse linear distance.The features of the scope finding classifier are:?
Of the negation signal: Form, POS, chunk IOBtag, type of chunk (NP, VP, ...), and form, POS,chunk IOB tag, type of chunk, and named en-tity of the 3 previous and 3 next tokens.?
Of the paired token: form, POS, chunk IOBtag, type of chunk, named entity, and form,POS, chunk IOB tag, type of chunk, and namedentity type of the 3 previous and 3 next tokens.?
Of the tokens between the negation signal andthe token in focus: Chain of POS types, dis-tance in number of tokens, and chain of chunkIOB tags.?
Others: A binary feature indicating whether thetoken and the negation signal are in the samechunk, and location of the token relative to thenegation signal (pre, post, same).5.3 Post-processingNegation signals in the BioScope corpus alwayshave one consecutive block of scope tokens, includ-ing the signal token itself.
However, the scope find-ing classifier can make predictions that result in non-consecutive blocks of scope tokens: we observedthat 54% of scope blocks predicted by the sys-tem given gold standard negation signals are non?consecutive.
This is why in the second step of thescope finding phase, we apply a post-processing al-gorithm in order to increase the number of fully cor-rect scopes.
A scope is fully correct if all tokens in a719sentence have been assigned their correct class labelfor a given negation signal.
Post-processing ensuresthat the resulting scope is one consecutive block oftokens.In the BioScope corpus negation signals are insideof their scope.
The post-processing algorithm thatwe apply first checks if the negation signal is in itsscope.
If the signal is out, the algorithm overwritesthe predicted scope in order to include the signal inits scope.Given the position of the signal in the sentence,the algorithm locates the starting and ending tokensof the consecutive block of predicted scope tokensthat surrounds the signal.
Other blocks of predictedscope tokens may have been predicted outside of thisblock, but they are separated from the current block,which contains the signal, by tokens that have beenpredicted not to be in the scope of the negation, as inFigure 1.ksignalmlFigure 1: Non-consecutive blocks of scope tokens.
Fora signal, two blocks of k = 6 and m = 3 tokens arepredicted to be the scope of the signal token, but they areseparated by l = 2 tokens that are predicted to be out ofscope.The post-processing algorithm decides whetherthe detached blocks should be connected as one con-secutive block of scope tokens, or whether the de-tached block of scope tokens should be discardedfrom the scope.
Dependent on this decision, ei-ther the classification of the separated blocks, or theseparating non-scope tokens are considered noisy,and their classification is updated to produce oneconsecutive block of scope tokens for each signal.This check is performed iteratively for all detachedblocks of scope tokens.As in Figure 1, consider a sentence where thenegation signal is in one block K of predicted scopeof length k tokens and another block M of m con-secutive tokens that is predicted as scope but is sep-arated from the latter scope block by l out-of-scopetokens.If non-consecutive blocks are near each other, i.e.,if l is sufficiently small in comparison with k andm, then the intermediate tokens that have been pre-dicted out of scope could be considered as noise andconverted into scope tokens.
In contrast, if there aretoo many intermediate tokens that separate the twoblocks of scope tokens, then the additional block ofscope is probably wrongly classified.Following this logic, if l < ?
(k + m), with aspecifically chosen ?, the intermediate out-of-scopetokens are re-classified as scope tokens, and theseparated blocks are connected to form one biggerblock containing the negation signal.
Otherwise,the loose block of scope is re-classified to be out ofscope.
When the main scope is extended, and moreblocks are found that are separated from the mainscope block, the algorithm reiterates this procedureuntil one consecutive block of scope tokens has beenfound.Our implementation first looks for separatedblocks from right to left, and then from left to right.Dependent on whether blocks need to be added be-fore or after the main scope block, we have observedin preliminary tests that ?
= 0.2 for extending themain scope block from right to left, and ?
= 0.3 forextending the block from left to right into the sen-tence provide the best results.
Algorithm 1 detailsthe above procedure in pseudo code.Algorithm 1 Post-processingK ?
scope block that contains signalwhile M ?
nearest separated scope block doL?
non-scope block between K and Mif |L| < ?
(|K|+ |M |) theninclude L in scopeelseexclude M from scopeend ifK ?
scope block that contains signalend while6 ResultsThe results have been obtained by performing 10-fold cross validation experiments.
The evaluationis made using the precision and recall measures(Van Rijsbergen, 1979), and their harmonic mean,F-Measure.
We calculate micro F1.720In the negation finding task, a negation token iscorrectly classified if it has been assigned a NEGclass.
In the scope finding task, a token is correctlyclassified if all the IO tag(s) that it has been assignedare correct.
This means that when there is more thanone negation signal in the sentence, the token has tobe correctly assigned an IO tag for as many negationsignals as there are.
For example, token NF-kappafrom Table 1 reproduced in (4) will not be correctif it is assigned classes I-NEG I-NEG or O-NEG I-NEG.
(4) 10415075 07 1 NF-kappa NF-kappa NN B-NPB-protein I-NEG O-NEGAdditionally, we evaluated the percentage of fullycorrect scopes (PCS).6.1 Negation signal findingWe calculate two baselines for negation signal find-ing.
Baseline 1 (B1) is calculated by assigning theNEG class to all the tokens that had no or not aslemma, which account for 72.80% of the negationsignals.
The F1 of the baseline is 80.66.
Baseline2 (B2) is calculated by assigning the NEG class toall the tokens that had no, not, lack, neither, unable,without, fail, absence, or nor as lemma.
These lem-mas account for 85.85 % of the negation signals.Baseline Total Prec.
Recall F1B1 1739 90.42 72.80 80.66B2 1739 89.77 93.38 91.54Table 2: Baselines of the negation finding system.Table 3 shows the overall results of the negationsignal finding system and the results per negationsignal.
With F1 94.40, it outperforms Baseline 2by 2.86 points.
Precision and recall are very simi-lar.
Scores show a clear unbalance between differentnegation signals.
Those with the lowest frequenciesget lower scores than those with the highest frequen-cies.
Probably, this could be avoided by training thesystem with a bigger corpus.However, a bigger corpus would not help solve allthe errors because some of them are caused by in-consistency in the annotation.
For example, absenceis annotated as a negation signal in 57 cases, whereasin 22 cases it is not annotated as such, although in allcases it is used as a negation signal.
Example 5 (a)Neg signals Total Prec.
Recall F1lack (v) 55 100.00 100.00 100.00neither (con) 34 100.00 100.00 100.00lack (n) 33 100.00 100.00 100.00unable 30 100.00 100.00 100.00neither (det) 8 100.00 100.00 100.00no (adv) 5 100.00 100.00 100.00without 83 100.00 98.79 99.39nor 44 100.00 100.00 98.89rather 19 95.00 100.00 97.43not 1057 96.15 96.97 96.56no (det) 204 95.63 96.56 96.09none 7 85.71 85.71 85.71fail 57 79.36 87.71 83.33miss 2 66.66 100.00 80.00absence 57 67.64 80.70 73.60failure 8 45.54 62.50 52.63could 6 66.66 33.33 44.44absent 13 42.85 23.07 30.00with 6 0.00 0.00 0.00either 2 0.00 0.00 0.00instead 2 0.00 0.00 0.00never 2 0.00 0.00 0.00impossible 1 0.00 0.00 0.00lacking 1 0.00 0.00 0.00loss 1 0.00 0.00 0.00negative 1 0.00 0.00 0.00or 1 0.00 0.00 0.00Overall 1739 94.21 94.59 94.40Table 3: F scores of the negation finding classifier.shows one of the 22 cases of absence that has notbeen annotated, and Example 5 (b) shows one of the57 cases of absence annotated as a negation signal.Also fail is not annotated as a negation signal in 13cases where it should.
(5) (a) Retroviral induction of TIMP-1 not onlyresulted in cell survival but also in continued DNAsynthesis for up to 5 d in the absence of serum,while controls underwent apoptosis.
(b) A significant proportion of transcripts appear toterminate prematurely in the <xcope id= X654.8.1><cue type= negation ref= X654.8.1 > absence</cue> of transactivators </xcope>.Other negation signals are arbitrarily annotated.Failure is annotated as a negation signal in 8 caseswhere it is followed by a preposition, like in Exam-ple 6 (a), and it is not annotated as such in 26 cases,like Example 6 (b), where it is modified by an adjec-tive.721(6) (a) ... the <xcope id= X970.8.2><cue type=negation ref= X970.8.2>failure</cue> of eTh1cells to produce IL-4 in response to an antigen</xcope> is due, at least partially, to a <xcope id=X970.8.1>< cue type= negation ref= X970.8.1>failure</cue> to induce high-level transcriptionof the IL-4 gene by NFAT </xcope></xcope>.
(b) Positive-pressure mechanical ventilationsupports gas exchange in patients with respiratoryfailure but is also responsible for significant lunginjury.The errors in detecting with as a negation signalare caused by the fact that it is embedded in the ex-pression with the exception of, which occurs 6 timesin contrast with the 5265 occurrences of with.
Couldappears as a negation signal because the tagger doesnot assign to it the lemma can, but could, causingthe wrong assignment of the tag NEG to not, insteadof could when the negation cue in BioScope is couldnot.6.2 Scope findingWe provide the results of the classifier and the re-sults of applying the postprocessing algorithm to theoutput of the classifier.Table 4 shows results for two versions of thescope finding classifier, one based on gold standardnegation signals (GS NEG), and another (PR NEG)based on negation signals predicted by the classifierdescribed in the previous section.Prec.
Recall F1 PCSGS NEG 86.03 85.53 85.78 39.39PR NEG 79.83 77.42 78.60 36.31Table 4: Results of the scope finding classifier with gold-standard (GS NEG) and with predicted negation signals(PR NEG).The F1 of PR NEG is 7.18 points lower than theF1 of GS NEG, which is an expected effect due tothe performance of classifier that finds negation sig-nals.
Precision and recall of GS NEG are very bal-anced, whereas PR NEG has a lower recall than pre-cision.
These measures are the result of a token pertoken evaluation, which does not guarantee that thecomplete sequence of scope is correct.
This is re-flected in the low percentage of fully correct scopesof both versions of the classifier.In Table 5, we present the results of the system af-ter applying the postprocessing algorithm.
The mostremarkable result is the 29.60 and 21.58 error reduc-tion in the percentage of fully correct scopes of GSNEG and PR NEG respectively, which shows thatthe algorithm is efficient.
Also interesting is the in-crease in F1 of GS NEG and PR NEG.Prec.
Recall F1 PCSGS NEG 88.63 88.17 88.40 57.33PR NEG 80.70 81.29 80.99 50.05Table 5: Results of the system with gold-standard (GSNEG) and with predicted negation signals (PR NEG) af-ter applying the postprocessing algorithm.Table 6 shows detailed results of the system basedon predicted negation signals after applying thepostprocessing algorithm.
Classes O-NEG and I-NEG are among the most frequent and get highscores.
Classes composed only of O-NEG tags areeasier to predict.Scope tags Total Prec.
Recall F1O-NEG 29590 86.78 84.75 85.75O-NEG O-NEG O-NEG 46 100.00 63.04 77.33I-NEG 12990 73.41 80.72 76.89O-NEG O-NEG 2848 84.11 68.43 75.46I-NEG I-NEG O-NEG 69 62.92 81.15 70.88I-NEG I-NEG 684 57.30 65.93 61.31I-NEG O-NEG O-NEG 20 50.00 75.00 60.00O-NEG I-NEG 791 72.13 50.06 59.10I-NEG O-NEG 992 45.32 67.94 54.37O-NEG I-NEG I-NEG 39 100.00 20.51 34.04I-NEG I-NEG I-NEG 22 26.66 36.36 30.76O-NEG O-NEG I-NEG 14 0.00 0.00 0.00Overall 48105 80.70 81.29 80.99Table 6: F scores of the system per scope class after ap-plying the postprocessing algorithm.Table 7 shows information about the percentageof correct scopes per negation signal after applyingthe algorithm to PR-NEG.
A clear example of anincorrect prediction is the occurrence of box in thelist.
The signal with the highest percentage of PCSis without, followed by no (determiner), rather andnot, which are above 50%.
It would be interesting toinvestigate how the syntactic properties of the nega-tion signals are related to the percentage of correctscopes, and how does the algorithm perform depend-ing on the type of signal.722Neg signals Total Correct PCSwithout 82 56 68.29no (det) 206 133 64.56rather 20 11 55.00not 1066 556 52.15neither (det) 8 4 50.00none 7 3 42.85neither (conj) 34 16 47.05no (adv) 5 2 40.00fail 63 23 36.50missing 3 1 33.33absence 68 22 32.35lack (v.) 54 17 31.48absent 7 2 28.57lack (n.) 33 9 27.27nor 43 11 25.58unable 30 8 26.66failure 11 0 0.00could 3 0 0.00negative 1 0 0.00never 1 0 0.00box 1 0 0.00Overall 1746 874 50.05Table 7: Information about Percentage of Correct Scopes(PCS) per negation signal in PR-NEG.7 ConclusionsGiven the fact that a significant portion of biomed-ical text is negated, recognising negated instancesis important in NLP applications.
In this paper wehave presented a machine learning system that findsthe scope of negation in biomedical texts.
The sys-tem consists of two memory-based classifiers, onethat decides if the tokens in a sentence are negationsignals, and another that finds the full scope of thenegation signals.The first classifier achieves 94.40 F1, and the sec-ond 80.99.
However, the evaluation in terms of cor-rect scopes shows the weakness of the system.
Thisis why a postprocessing algorithm is applied.
Thealgorithm achieves an error reduction of 21.58, with50.05 % of fully correct scopes in the system basedon predicted negation signals.These results suggest that unsupervised machinelearning algorithms are suited for tackling the task,as it was expected from results obtained in othernatural language processing tasks.
However, resultsalso suggest that there is room for improvement.
Afirst improvement would consist in predicting thescope chunk per chunk instead of token per token,because most negation scope boundaries coincidewith boundaries of chunks.We have highlighted the fact that our approachto negation detection focuses on finding the scopeof negation signals, instead of determining whethera term is negated or not, and on applying super-vised machine learning techniques.
As far as weknow, this approach is novel.
Unfortunately, thereare no previous comparable approaches to measurethe quality of our results.Additionally, we have shown that negation find-ing can be modelled as a classification task in a waysimilar to other linguistic tasks like semantic role la-beling.
In our model, tokens of a sentence are clas-sified as being a negation signal or not, and as beinginside or outside the scope of the negation signal(s).This representation would allow to integrate the taskwith other semantic tasks and exploring the interac-tion between different types of knowledge in a jointlearning setting.Further research is possible in several directions.In the first place, other machine learning algorithmscould be integrated in the system in order to opti-mise performance.
Secondly, the system should betested in different types of biomedical texts, like fullpapers or medical reports to check its robustness.Finally, the postprocessing algorithm could be im-proved by using more sophisticated sequence classi-fication techniques (Dietterich, 2002) .AcknowledgmentsOur work was made possible through financial sup-port from the University of Antwerp (GOA projectBIOGRAPH).
We are thankful to three anonymousreviewers for their valuable comments and sugges-tions.ReferencesM.
Averbuch, T. Karson, B. Ben-Ami, O. Maimon, andL.
Rokach.
2004.
Context-sensitive medical informa-tion retrieval.
In Proc.
of the 11th World Congresson Medical Informatics (MEDINFO-2004), pages 1?8, San Francisco, CA.
IOS Press.723S.
Boytcheva, A. Strupchanska, E. Paskaleva, andD.
Tcharaktchiev.
2005.
Some aspects of negationprocessing in electronic health records.
In Proc.
ofInternational Workshop Language and Speech Infras-tructure for Information Access in the Balkan Coun-tries, pages 1?8, Borovets, Bulgaria.S.
Buchholz and E. Marsi.
2006.
CoNLL-X shared taskon multilingual dependency parsing.
In Proc.
of the XCoNLL Shared Task, New York.
SIGNLL.W.
W. Chapman, W. Bridewell, P. Hanbury, G. F. Cooper,and B.G.
Buchanan.
2001.
A simple algorithm foridentifying negated findings and diseases in dischargesummaries.
J Biomed Inform, 34:301?310.N.
Collier, H.S.
Park, N. Ogata, Y. Tateisi, C. Nobata,T.
Sekimizu, H. Imai, and J. Tsujii.
1999.
The GE-NIA project: corpus-based knowledge acquisition andinformation extraction from genome research papers.In Proceedings of EACL-99.S.
Cost and S. Salzberg.
1993.
A weighted nearest neigh-bour algorithm for learning with symbolic features.Machine learning, 10:57?78.T.
M. Cover and P. E. Hart.
1967.
Nearest neighborpattern classification.
Institute of Electrical and Elec-tronics Engineers Transactions on Information The-ory, 13:21?27.W.
Daelemans and A. van den Bosch.
2005.
Memory-based language processing.
Cambridge UniversityPress, Cambridge, UK.W.
Daelemans, A.
Van den Bosch, and J. Zavrel.
1999.Forgetting exceptions is harmful in language learning.Machine Learning, Special issue on Natural LanguageLearning, 34:11?41.W.
Daelemans, J. Zavrel, K. Van der Sloot, and A. Vanden Bosch.
2007.
TiMBL: Tilburg memory basedlearner, version 6.1, reference guide.
Technical ReportSeries 07-07, ILK, Tilburg, The Netherlands.T.
G. Dietterich.
2002.
Machine learning for sequentialdata: A review.
In Lecture Notes in Computer Science2396, pages 15?30, London.
Springer Verlag.P.
L. Elkin, S. H. Brown, B.
A. Bauer, C.S.
Husser,W.
Carruth, L.R.
Bergstrom, and D. L. Wahner-Roedler.
2005.
A controlled trial of automated classi-fication of negation from clinical notes.
BMC MedicalInformatics and Decision Making, 5(13).l.
M. Goldin and W.W. Chapman.
2003.
Learning todetect negation with ?Not?
in medical texts.
In Pro-ceedings of ACM-SIGIR 2003.S.
Goryachev, M. Sordo, Q.T.
Zeng, and L. Ngo.
2006.Implementation and evaluation of four different meth-ods of negation detection.
Technical report, DSG.Y.
Huang and H.J.
Lowe.
2007.
A novel hybrid approachto automated negation detection in clinical radiologyreports.
J Am Med Inform Assoc, 14(3):304?311.R.
Morante, W. Daelemans, and V. Van Asch.
2008.
Acombined memory-based semantic role labeler of en-glish.
In Proc.
of the CoNLL 2008, pages 208?212,Manchester, UK.A.G.
Mutalik, A. Deshpande, and P.M. Nadkarni.
2001.Use of general-purpose negation detection to augmentconcept indexing of medical documents.
a quantita-tive study using the UMLS.
J Am Med Inform Assoc,8(6):598?609.J.
Nivre, J.
Hall, S. Ku?bler, R. McDonald, J. Nilsson,S.
Riedel, and D. Yuret.
2007.
The CoNLL-2007shared task on dependency parsing.
In Proc.
of theCoNLL Shared Task Session of EMNLP-CoNLL 2007,pages 915?932, Prague.J.R.
Quinlan.
1993.
C4.5: Programs for Machine Learn-ing.
Morgan Kaufmann, San Mateo, CA.L.
Ramshaw and M. Marcus.
1995.
Text chunking usingtransformation-based learning.
In Proc.
of ACL ThirdWorkshop on Very Large Corpora, pages 82?94, Cam-bridge, MA.
ACL.L.
Rokach, R.Romano, and O. Maimon.
2008.
Negationrecognition in medical narrative reports.
InformationRetrieval Online.O.
Sanchez-Graillet and M. Poesio.
2007.
Negation ofprotein-protein interactions: analysis and extraction.Bioinformatics, 23(13):424?432.B.
Santorini.
1990.
Part-of-speech tagging guidelinesfor the penn treebank project.
Technical report MS-CIS-90-47, Department of Computer and InformationScience, University of Pennsylvania.M.
Surdeanu, R. Johansson, A. Meyers, Ll.
Ma`rquez,and J. Nivre.
2008.
The CoNLL-2008 shared task onjoint parsing of syntactic and semantic dependencies.In Proc.
of CoNLL 2008, pages 159?177, Manchester,UK.G.
Szarvas, V. Vincze, R. Farkas, and J. Csirik.
2008.The BioScope corpus: annotation for negation, uncer-tainty and their scopein biomedical texts.
In Proc.
ofBioNLP 2008, pages 38?45, Columbus, Ohio, USA.ACL.Y.
Tsuruoka and J. Tsujii.
2005.
Bidirectional in-ference with the easiest-first strategy for tagging se-quence data.
In Proc.
of HLT/EMNLP 2005, pages467?474.Y.
Tsuruoka, Y. Tateishi, J. Kim, T. Ohta, J. McNaught,S.
Ananiadou, and J. Tsujii, 2005.
Advances in Infor-matics - 10th Panhellenic Conference on Informatics,volume 3746 of Lecture Notes in Computer Science,chapter Part-of-Speech Tagger for Biomedical Text,Advances in Informatics, pages 382?392.
Springer,Berlin/Heidelberg.C.J.
Van Rijsbergen.
1979.
Information Retrieval.
But-terworths, London.724
