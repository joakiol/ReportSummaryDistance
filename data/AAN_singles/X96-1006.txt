THE MESSAGE UNDERSTANDING CONFERENCESBeth M. SundheimNaval Command, Control, and Ocean Surveillance Center RDT&E Division (NRaD)53140 Gatchell Road, San Diego, CA 92152-7420sundheim@ nosc.milThe latest in a series of natural languageprocessing system evaluations was concluded inOctober 1995 and was the topic of the SixthMessage Understanding Conference (MUC-6) inNovember, co-chaired by Ralph Grishman (NYU)and Beth Sundheim (NRaD).
Participants wereinvited to enter their systems in as many as fourdifferent task-oriented evaluations.
The NamedEntity and Coreference tasks entailed StandardGeneralized Markup Language (SGML) annotationof texts and were being conducted for the first time.The other two tasks, Template Element andScenario Template, were information extractiontasks that followed on from previous MUCevaluations.
All except he Scenario Template taskare defined independently of any particular domain.The evolution and design of the MUC-6evaluation are described in the conferenceproceedings \[1\].
A basic characterization of thechallenge presented by each task is as follows:?
Named Ent i ty  (NE) -- Insert SGMLtags into the text to mark each string thatrepresents a person, organization, or locationname, or a date or time stamp, or a currency orpercentage figure.?
Coreference (CO) -- Insert SGML tagsinto the text to link strings that representcoreferring noun phrases.?
Template Element (TE) -- Extractbasic information related to organization andperson entities, drawing evidence ffromanywhere in the text.?
Scenario Template (ST) -- Drawingevidence from anywhere in the text, extractprespecified event information, and relate theevent information to the particularorganization and person entities involved inthe event.later, with results due by the end of the week.Sixteen sites participated in the evaluation; 15systems were evaluated for the NE task, 7 for CO,11 for TE, and 9 for ST. 1The variety of tasks that were designed forMUC-6 reflects the interests of both participants andsponsors in assessing and furthering research thatcan satisfy some urgent ext processing needs in thevery near term and can lead to solutions to morechallenging text understanding problems in thelonger term.
The hard work carried out by theplanning committee over nearly two years led toextremely interesting and useful evaluation results.oIdentification of names, which constitutes alarge portion of the NE task and a critical portion ofthe TE task, has proven to be largely a solvedproblem.
The majority of systems evaluated on NEhad recall and precision over 90%; the highest-scoring system had a recall of 96% and a precisionof 97%, which was judged to be comparable tohuman performance on the task.oRecognition of alternative ways ofidentifying an entity constitutes a large portion ofthe CO task and another critical portion of the TEtask; it has been shown to represent only a modestchallenge when the referents are names or pronouns.All but two of the TE systems posted combinedrecall-precision (F-measure) scores in the 70-80%range; four of the systems were able to achieverecall in the 70-80% range while maintainingprecision in the 80-90% range.
The top-scoringsystem had 75% recall, 86% precision.
Five of theseven CO systems were in the 51%-63% recallrange and 62%-72% precision range.Testing was conducted using Wall StreetJournal texts provided by the Linguistic DataConsortium.
The test set for the two informationextraction tasks consisted of 100 articles.
A subsetof 30 articles was selected for use as the test set forthe two SGML annotation tasks.
The evaluationbegan with the distribution of the scenariodefinition and training data at the beginning ofSeptember.
The test data was distributed four weeks1 The participating sites were BBN Systems andTechnology, University of Durham (UK), Knight-Ridder Information, Lockheed-Martin, University ofManitoba (Canada), University of Massachusetts(Amherst), The MITRE Corp., New Mexico StateUniversity Computing Research Laboratory, New YorkUniversity, University of Pennsylvania, SAIC(McLean), University of Sheffield (UK), SystemsResearch and Applications, SRI International, SterlingSoftware, and Wayne State University.$5oThe ST task concerned changes in corporateexecutive management personnel; the extractedinformation i cludes answers to the basic questionsof "Who is creating or filling what vacancy at whatorganization?".
The mix of challenges that the taskrepresents -- extraction of domain-specific events andrelations along with the pertinent entities (templateelements) -- yielded levels of performance that aresimilar to those achieved in previous MUCs (40%-50% recall, 60%-70% precision), but with a muchshorter time required for porting.
The highest STperformance overall was 47% recall and 70%precision.Table 1.96.4295.6694.925 96 9795 9693 9694.00 10 92 9693.65 10 94 9393.33 11 92 9592.88 10 94 9292.74 12 92 9392.61 12 89 9691.20 13 91 9190.84 14 91 9189.06 18 84 9488.19 19 86 9085.82 20 85 8785.73 23 80 9284.95 22 82 89Summary NE scores on primary metrics for the top 16 (out of 20) systems tested, in order ofdecreasing F-Measure (P&R)1009080706050403020O Q ?10 20 30 40 50 60 70 80 90Reca l lFigure 1.
Overall recall and precision on the CO task10036I(X)90806O5O4O3020I0?
?
o4?
el0  21) 31) 40 50 60 70 80 90RecallFigure 2.
Overall recall and precision on the TE task1(~(11009O807O6Oi,?4O311100 ,0tb10 20 ~ ~ 50 6O 70 ~ 9O 1~RecallFigure 3.
Overall information extraction recall and precision on the ST taskMUC-7 will be held in 1997, withGovernment coordination led by Elaine Marsh of theNaval Research Laboratory.
Ms. Marsh is currentlySection Head for the Intelligent MultimodalMultimedia (IM4) Section at the Navy Center forArtificial Intelligence.
There she has conductedbasic and exploratory research in natural languageunderstanding and multimodal interactive systems.Prior to joining the Naval Research Laboratory, Ms.Marsh was employed as a research scientist on theLinguistic String Project at New York University.She holds M.A.
degrees from the University ofWisconsin-Madison and New York University andhas completed additional graduate courses at NewYork University.REFERENCES\[ 1 \] Proceedings of the Sixth Message UnderstandingConference (MUC-6), November, 1995, San Mateo:Morgan Kaufmann.37
