Coling 2010: Poster Volume, pages 1104?1112,Beijing, August 2010Sentiment Translation through Multi-Edge GraphsChristian Scheible, Florian Laws, Lukas Michelbacher, and Hinrich Schu?tzeInstitute for Natural Language ProcessingUniversity of Stuttgart{scheibcn, lawsfn, michells}@ims.uni-stuttgart.deAbstractSentiment analysis systems can benefitfrom the translation of sentiment informa-tion.
We present a novel, graph-based ap-proach using SimRank, a well-establishedgraph-theoretic algorithm, to transfer sen-timent information from a source lan-guage to a target language.
We evaluatethis method in comparison with semanticorientation using pointwise mutual infor-mation (SO-PMI), an established unsuper-vised method for learning the sentiment ofphrases.1 IntroductionSentiment analysis is an important topic in com-putational linguistics that is of theoretical interestbut is also useful in many practical applications.Usually, two aspects are of importance in senti-ment analysis.
The first is the detection of sub-jectivity, i.e., whether a text or an expression ismeant to express sentiment at all; the second is thedetermination of sentiment orientation, i.e., whatsentiment is to be expressed in a structure that isconsidered subjective.Work on sentiment analysis most often cov-ers resources or analysis methods in a single lan-guage, usually English.
However, the transferof sentiment analysis between languages can beadvantageous by making use of resources for asource language to improve the analysis of the tar-get language.This paper presents an approach to the transferof sentiment information between two languagesthat does not rely on resources with limited avail-ability like parallel corpora.
It is built around Sim-Rank, a graph similarity algorithm that has suc-cessfully been applied to the acquisition of bilin-gual lexicons (Laws et al, 2010) and semanticsimilarity (Michelbacher et al, 2010).
It useslinguistic relations extracted from two monolin-gual corpora to determine the similarity of wordsin different languages.
One of the main benefitsof our method is its ability to handle sparse dataabout the relations between the languages well(i.e., a small seed lexicon).
Further, we experi-ment with combining multiple types of linguisticrelations for graph-based translation.
Our exper-iments are carried out using English as a sourcelanguage and German as a target language.
Weevaluate our method using a hand-annotated set ofGerman adjectives which we intend to publish.In the following section, related work is dis-cussed.
Section 3.1 gives an introduction to Sim-Rank and its application to lexicon induction,while section 3.2 reviews SO-PMI (Turney, 2002),an unsupervised baseline method for the genera-tion of sentiment lexicons.
In section 4, we defineour sentiment transfer method which we apply inexperiments in section 5.2 Related WorkMihalcea et al (2007) propose two methods fortranslating sentiment lexicons.
The first methodsimply uses bilingual dictionaries to translate anEnglish sentiment lexicon.
A sentence-based clas-sifier built with this list achieved high precision,but low recall on a small Romanian test set.
Thesecond method is based on parallel corpora.
Thesource language in the corpus is annotated withsentiment information, and the information is thenprojected to the target language.
Problems arisedue to mistranslations.Banea et al (2008) use machine translation formultilingual sentiment analysis.
Given a corpusannotated with sentiment information in one lan-guage, machine translation is used to produce anannotated corpus in the target language, by pre-serving the annotations.
The original annotations1104can be produced either manually or automatically.Wan (2009) constructs a multilingual classi-fier using co-training.
In co-training, one classi-fier produces additional training data for a secondclassifier.
In this case, an English classifier assistsin training a Chinese classifier.The induction of a sentiment lexicon is the sub-ject of early work by Hatzivassiloglou and McK-eown (1997).
They construct graphs from coordi-nation data from large corpora based on the intu-ition that adjectives with the same sentiment ori-entation are likely to be coordinated.
For example,fresh and delicious is more likely than rotten anddelicious.
They then apply a graph clustering al-gorithm to find groups of adjectives with the sameorientation.
Finally, they assign the same label toall adjectives that belong to the same cluster.Corpus work and bilingual dictionaries arepromising resources for translating sentiment.
Incontrast to previous approaches, the work pre-sented in this paper uses corpora that are not an-notated with sentiment.Turney (2002) suggests a corpus-based extrac-tion method based on his pointwise mutual infor-mation (PMI) synonymy measure.
He assumesthat the sentiment orientation of a phrase can bedetermined by comparing its pointwise mutual in-formation with a positive (excellent) and a nega-tive phrase (poor).
An introduction to this methodis given in Section 3.2.3 Background3.1 Lexicon Induction via SimRankWe use the extension of the SimRank (Jeh andWidom, 2002) node similarity algorithm proposedby Dorow et al (2009).
Given two graphs A andB, the similarity between two nodes a in A and bin B is computed in each iteration as:S(a, b) = c|NA(a)||NB(b)|?k?NA(a),l?NB(b)S(k, l).NX(x) is the neighborhood of node x in graphX .
To compute similarities between two graphs,some initial links between these graphs have to begiven, called seed links.
These form the recursionbasis which sets S(a, b) = 1 if there is a seedlink between a and b.
At the beginning of eachiteration, all known equivalences between nodesare reset to 1.Multi-Edge Extraction (MEE).
MEE is an ex-tension of SimRank that, in each iteration, com-putes the average node-node similarity of severaldifferent SimRank matrices.
In our case, we usetwo different SimRank matrices, one for coordi-nations and one for adjective modification.
See(Dorow et al, 2009) for details.
We also usedthe node degree normalization function h(n) =?n ?
?maxk(|N(k)|) (where n is the node de-gree, and N(k) the degree of node k) to decreasethe harmful effect of high-degree nodes on finalsimilarity values.
See (Laws et al, 2010) for de-tails.3.2 SO-PMISemantic orientation using pointwise mutual in-formation (SO-PMI) (Turney, 2002) is an algo-rithm for the unsupervised learning of semanticorientation of words or phrases.
A word has pos-itive (resp.
negative) orientation if it is associ-ated with positive (resp.
negative) terms morefrequently than with negative (resp.
positive)terms.
Association of terms is measured usingtheir pointwise mutual information (PMI) whichis defined for two words w1 and w2 as follows:PMI(w1, w2) = log( p(w1, w2)p(w1)p(w2))Using PMI, Turney defines SO-PMI for a wordw asSO-PMI(w) =log?p?P hits(word NEAR p)?
?n?N hits(n)?n?N hits(word NEAR n)?
?p?P hits(p)hits is a function that returns the number of hitsin a search engine given the query.
P is a set ofknown positive words, N a set of known negativewords, and NEAR an operator of a search enginethat returns documents in which the operands oc-cur within a close range of each other.11054 Sentiment TranslationUnsupervised methods like SO-PMI are suitableto acquire basic sentiment information in a lan-guage.
However, since hand-annotated resourcesfor sentiment analysis exist in other languages,it seems plausible to use automatic translation ofsentiment information to leverage these resources.In order to translate sentiment, we will use multi-ple sources of information that we represent in aMEE graph as given in Section 3.1.In our first experiments (Scheible, 2010), coor-dinated adjectives were used as the sole trainingsource.
Two adjectives are coordinated if they arelinked with a conjunction like and or but.
Theintuition behind using coordinations ?
based onwork by Hatzivassiloglou and McKeown (1997)and Widdows and Dorow (2002) ?
was that wordswhich are coordinated share properties.
In partic-ular, coordinated adjectives usually express sim-ilar sentiments even though there are exceptions(e.g., ?The movie was both good and bad?
).In this paper, we focus on using multiple edgetypes for sentiment translation.
In particular, thegraph we will use contains two types of relations,coordinations and adjective-noun modification.
Inthe sentence ?The movie was enjoyable and fun?,enjoyable and fun are coordinated.
In This is anenjoyable movie, the adjective enjoyable modifiesthe noun movie.We selected these two relation types for tworeasons.
First, the two types provide clues forsentiment analysis.
Coordination information isan established source for sentiment similarity (e.g.Hatzivassiloglou and McKeown (1997)) whileadjective-noun relations provide a different typeof information on sentiment.
For example, nounswith positive associations (vacation) tend to occurwith positive adjectives and nouns with negativeassociations (pain) tend to occur with negative ad-jectives.
Second, we have successfully used thesetwo types for a similar acquisition task, the acqui-sition of word-to-word translation pairs (Laws etal., 2010).In the resulting graph, adjectives and nouns arerepresented as nodes, each containing a word andits part of speech, and relations are represented aslinks which are distinguished by their edge types.Two graphs, one in the source language and one inthe target language, are needed to translate wordsbetween those languages.
Figure 1 shows an ex-ample for such a setup.
Black links in this graphare coordinations, grey links are seed relations.In order to calculate sentiment for all nodes inthe target language, we apply the SimRank algo-rithm to the graphs which gives us similarities be-tween all nodes in the source graph and all nodesin the target graph.
Using the similarity S(ns, nt)between a node ns in the source language graphS and a node nt in the target language graph T ,the sentiment score (sent(nt)) is the similarity-weighted average of all sentiment scores in thetarget language:sent(nt) =?ns?Ssimnorm(ns, nt) sent(ns)We assume that sentiment scores in the sourcelanguage are expressed on a numeric scale.
Thenormalized similarity simnorm is defined assimnorm(ns, nt) = S(ns, nt)?ns?S S(ns, nt).The normalization assures that all resulting sen-timent values are within [?1, 1], with ?1 beingthe most negative sentiment and 1 the most posi-tive.5 Experiments5.1 Data AcquisitionFor our experiments, we needed coordination datato build weighted graphs and a bilingual lexi-con to define seed relations between those graphs.Coordinations were extracted from the Englishand German versions of Wikipedia1 by applyingpattern-based search using the Corpus Query Pro-cessor (CQP) (Christ et al, 1999).
We annotatedboth corpora with parts of speech using the TreeTagger (Schmid, 1994).
A total of 477,291 En-glish coordinations and 112,738 German coordi-nations were collected.
A sample of this data isgiven in Figure 2.
We restrict these experimentsto the use of and/und since other coordinations1http://www.wikipedia.org/ (01/19/2009)1106affordabledeliciousnutritiousjuicytastyhealthylovelyschmackhaftgesundstrangefrischwertvollnahrhaft angesehenertragreichFigure 1: A German and an English graph with coordinated adjectives including seed linksaffordabledeliciousdiversepopularnutritiousinexpensiveoriginalvariedmelodiousrarestrangejuicytastyexotic healthytemptinglovelyhearty fragrantdangerousbeautifulcharming authenticFigure 2: English sample coordinations (adjectives)1107behave differently and might even express dissim-ilarity (e.g.
Was the weather good or bad?
).The seed lexicon was constructed from thedict.cc dictionary2.
While the complete dictionarycontains 30,551 adjective pairs, we reduced thenumber of pairs used in the experiments to 1,576.To produce a smaller seed lexicon which stillmakes sense from a semantic point of view, weused the General Service List (GSL) (West, 1953)which contains about 2000 words the author con-sidered central to the English language.
Morespecifically, a revised list was used3.SO-PMI needs a larger amount of training data.Since Wikipedia does not satisfy this need, wecollected additional coordination data from theweb using search result counts from Google.
InTurney?s original paper, he uses the NEAR oper-ator, which returns documents that contain twosearch terms that are within a certain distance ofeach other, to collect collocations.
Unfortunately,Google does not support this operator, so instead,we searched for coordinations using the queries+ "w and s" and+ "w und s"for English and German, respectively.
We addedthe quotes and the + operator to make sure thatboth spelling correction and synonym replace-ments were disabled.The original experiments were made for En-glish, so we had to construct our own set ofseed words.
For German, we chose gut (good),nett (nice), richtig (right), scho?n (beautiful), or-dentlich (neat), angenehm (pleasant), aufrichtig(honest), gewissenhaft (faithful), and hervorra-gend (excellent) as positive seed words, andschlecht (bad), teuer (expensive), falsch (wrong),bo?se (evil), feindlich (hostile), verhasst (invidi-ous), widerlich (disgusting), fehlerhaft (faulty),and mangelhaft (flawed) as negative ones.5.2 Sentiment LexiconFor our experiments, we used two different polar-ity lexicons.
The lexicon of Wilson et al (2005)contains sentiment annotations for 8,221 words2http://www.dict.cc3http://jbauman.com/aboutgsl.htmlannotation valuepositive 1.0weakpos 0.5neutral 0.0weakneg ?0.5negative ?1.0Table 1: Assigned values for Wilson et al setwhich are tagged as positive, neutral, or nega-tive.
A few words are tagged as weakneg, imply-ing weak negativity.
These categorial annotationsare mapped to the range [-1,1] using the assign-ment scheme given in Table 1.5.3 Human RatingsIn order to manually annotate a test set, wechose 200 German adjectives that occurred in theWikipedia corpus and that were part of a coor-dination.
From these words, we removed thosewhich we deemed uncommon, too complicated,or which were mislabeled as adjectives by the tag-ger.
The test set contained 150 adjectives of whichseven were excluded after annotators discardedthem.We asked 9 native speakers of German to anno-tate the adjectives.
Possible annotations were verypositive, slightly positive, neutral, slightly nega-tive, or very negative.
These categories are thesame as the ones used in the training data.In order to capture the general sentiment, i.e.,sentiment that is not related to a specific context,the judges were asked to stay objective and notlet their personal opinions influence the annota-tion.
However, some words with strong politicalimplications were annotated by some judges asnon-neutral which led to disagreement beyond theusual level.
Nuklear (nuclear) is an example forsuch a word.
We measured the agreement of thejudges with Kendall?s coefficient of concordance(W ) with tie correction (Legendre, 2005), yield-ing W = 0.674 with a high level of significance(p < .001); thus, inter-annotator agreement washigh (Landis and Koch, 1977).5.4 Experimental SetupGiven the relations extracted from Wikipedia, webuilt a German and an English graph by setting1108Method rMEE 0.63MEE-GSL 0.47SR 0.63SR-GSL 0.48SO-PMI 0.58Table 2: Correlation with human ratingsthe weight of each link to the log-likelihood ra-tio of the two words it connects according to thecorpus frequencies.
There are two properties ofthe graph transfer algorithm that we intend to in-vestigate.
First, we are interested in the merits ofapplying multi edge extraction (MEE) for senti-ment transfer.
Second, we are interested in howthe transfer quality changes when the seed lexi-con is reduced in size.
This way, a sparse datasituation is simulated where large dictionaries areunavailable.
Having these two properties in mind,four possible setups are evaluated: (i) using thefull seed lexicon with all 30,551 entries, but usingonly coordination data (SR), (ii) reducing the seedlexicon to 1,576 entries from the General ServiceList (SR-GSL), (iii) applying MEE by adding ad-jective modification data (MEE), and (iv) usingMEE with a reduced seed lexicon (MEE-GSL).SimRank was run for 6 iterations in all experi-ments.
All experiments use the weight functionh as described above.
We show that this functionimproves similarities and thus lexicon inductionin Laws et al (2010).Correlation.
First, we will examine the correla-tion between the automatic methods (SO-PMI andthe aforementioned SimRank variations) and thegold standard as done by Turney in his evaluation.For this purpose, the human ratings are mappedto float values following Table 1 and the aver-age rating over all judges for each word is used.The correlation coefficients r are given in Table 2.Judging from these results, the ordering of SR andMEE matches the human ratings better than SO-PMI, however it decreases when using any of theGSL variations instead which can be attributed tousing less data.Classification.
The correct identification of theclasses positive, neutral, and negative is more im-portant than the correct assignment of values ona scale since the rank ordering is debatable ?
thisbecomes apparent when measuring the agreementof human annotators.
Since the assignments madeby the human judges are not unanimous in mostcases, the averages are distributed across the in-terval [-1,1]; this means that the borders betweenthe three distinct categories are not clear.
Sincethere is no standard evaluation for this particu-lar problem, we need to devise a way to makethe range of the neutral category dynamic.
In or-der to find possible borders, we first assume thatsentiment is distributed symmetrically around 0.We then define a threshold x which assumes thevalues x ?
{ i20 |0 ?
i ?
20}, covering the in-terval [0,0.5].
Since 0.5 is slightly positive, wedo not believe that values above it are plausible.Then, each word w is positive if its human ratingscoreh(w) ?
x, negative if scoreh(w) ?
?x, andneutral if ?x < scoreh(w) < x.
The result ofthis process is a gold standard for the three cate-gories for each of the values for x.
The percentilesof the sizes of those categories are mapped to thevalues produced by the automatic methods.
Forexample, if x = 0.35 means that the top 21% ofall adjectives are in the positive class, the top 21%of all adjectives as assigned by SO-PMI and theSimRank varieties are positive as well.The size of the neutral category increases thelarger x becomes.
Thus, high values for x areunlikely to produce a correct partitioning of thedata.
Since slightly positive was defined as 0.5,we expect the highest plausible value for x to bebelow that.
The size of the neutral category foreach value of x is given in Table 3.
(Recall thatthe total size of the set is 143.
)We can then compute the assignment accu-racy on the positive, neutral, and negative classes,as well macro- and micro-averages over theseclasses.5.5 Results and DiscussionFigures 3 and 4 show the macro- and micro-averaged accuracies over the positive, negative,and neutral class for each automatic method, re-spectively.
Overall, the SimRank variations per-form better for x in the interval [0, 0.3].
In partic-ular, MEE has a slightly higher accuracy than SR,1109x 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50# neutral 0 13 35 46 56 64 74 82 92 99 99Table 3: Size of neutral category given xword (translation) humans SO MEE MEE-GSL SR SR-GSLchemisch (chemical) 0.00 -20.20 0.185 0.185 0.186 0.184auferstanden (resurrected) 0.39 -10.96 -0.075 -0.577 -0.057 -0.493intelligent (intelligent) 0.94 46.59 0.915 0.939 0.834 0.876versiert (skilled) 0.67 -5.26 0.953 0.447 0.902 0.404mean -0.04 -9.58 0.003 0.146 0.010 0.142median 0.00 -15.60 0.110 0.157 0.114 0.157Table 4: Example adjectives including translation, and their scores00.20.40.60.810  0.1  0.2  0.3  0.4  0.5AccuracyxSO-PMI (macro)MEE (macro)MEE-GSL (macro)SR (macro)SR-GSL (macro)Figure 3: Macro-averaged Accuracy00.20.40.60.810  0.1  0.2  0.3  0.4  0.5AccuracyxSO-PMI (micro)MEE (micro)MEE-GSL (micro)SR (micro)SR-GSL (micro)Figure 4: Micro-averaged Accuracy1110however, not significantly.Table 4 shows selected example words withtheir scores.
These values can be understood bet-ter together with the means and medians of therespective methods which are given in the table aswell.
These values give us an idea of where wemight expect the neutral point of a particular dis-tribution of polarities.Chemisch (chemical) is misclassified by SO-PMI since it occurs in negative contexts on theweb.
SimRank in turn was able to recognizethat most words similar to chemisch are neutral,the most similar one being its literal translation,chemical.
Auferstanden (resurrected) is an exam-ple for misclassification by SimRank which hap-pens because the word is usually coordinated withwords that have negative sentiment, e.g.
gestor-ben (deceased) and gekreuzigt (crucified).
Thisproblem could not be fixed by including adjective-noun modification data since the coordinationsproduced high log-likelihood values which lead todead being the most similar word to auferstanden.Intelligent receives a score close to neutral withthe original (coordination-only) training method,which could be corrected by applying MEE sim-ply because the ordering of similar words changesthrough the new weighting method.
Nouns modi-fied by intelligent include Leben (life) and Wesen(being) whose translations are modified by pos-itive adjectives.
Many words, such as versiert(skilled) are classified more accurately due to thenew weighting method when compared to our pre-vious experiments (Scheible, 2010) where it re-ceived a SimRank polarity of only 0.224.The inclusion of adjective modifications doesnot improve the classification results as often aswe had hoped.
For some cases (cf.
intelligentmentioned above), the scores do improve, but theoverall impact is limited.6 Conclusion and OutlookWe were able to show that sentiment translationwith SimRank is able to classify adjectives moreaccurately than SO-PMI, an unsupervised base-line method.
We demonstrated that SO-PMI isoutperformed by SimRank when choosing a rea-sonable region of neutral adjectives.
In addition,we showed that the improvements of SimRanklead to better accuracy in sentiment translation insome cases.
In future work, we will apply a senti-ment lexicon generated with SimRank in a senti-ment classification task for reviews.The algorithms we compared are different intheir purpose of application.
While SO-PMI isapplicable when large corpora are available for alanguage, it fails when used in a sparse-data situ-ation, as noted by Turney (2002).
We showed thatdespite reducing the seed lexicon for SimRank toa small fraction of its original size, it still performsbetter than SO-PMI.Currently, our experiments are limited by thechoice of using adjectives for our test set.
Whilethe examination of adjectives is highly importantfor sentiment analysis (as shown by Pang et al(2002) who were able to achieve high accuracyeven when using only adjectives), the applicationof our algorithms to a broader set of linguisticunits is an important goal for future work.Acknowledgments.
We are grateful toDeutsche Forschungsgemeinschaft for fund-ing this research as part of the WordGraphproject.ReferencesBanea, Carmen, Rada Mihalcea, Janyce Wiebe, andSamer Hassan.
2008.
Multilingual subjectivityanalysis using machine translation.
In EmpiricalMethods in Natural Language Processing, pages127?135.Christ, O., B.M.
Schulze, A. Hofmann, and E. Koenig.1999.
The IMS Corpus Workbench: Corpus QueryProcessor (CQP): User?s Manual.
University ofStuttgart, March, 8:1999.Dorow, Beate, Florian Laws, Lukas Michelbacher,Christian Scheible, and Jason Utt.
2009.
A graph-theoretic algorithm for automatic extension of trans-lation lexicons.
In Workshop on Geometrical Mod-els of Natural Language Semantics, pages 91?95.Hatzivassiloglou, Vasileios and Kathleen R. McKe-own.
1997.
Predicting the semantic orientation ofadjectives.
In Proceedings of the 35th Annual Meet-ing of the Association for Computational Linguis-tics, pages 174?181.Jeh, Glen and Jennifer Widom.
2002.
Simrank: Ameasure of structural-context similarity.
In Pro-ceedings of the Eighth ACM SIGKDD Interna-1111tional Conference on Knowledge Discovery andData Mining, pages 538?543.Landis, J.R. and G.G.
Koch.
1977.
The measurementof observer agreement for categorical data.
Biomet-rics, 33(1):159?174.Laws, Florian, Lukas Michelbacher, Beate Dorow,Christian Scheible, Ulrich Heid, and HinrichSchu?tze.
2010.
A linguistically grounded graphmodel for bilingual lexicon extraction.
In Proceed-ings of the 23nd International Conference on Com-putational Linguistics.Legendre, P. 2005.
Species associations: the Kendallcoefficient of concordance revisited.
Journal ofAgricultural Biological and Environment Statistics,10(2):226?245.Michelbacher, Lukas, Florian Laws, Beate Dorow, Ul-rich Heid, and Hinrich Schu?tze.
2010.
Buildinga cross-lingual relatedness thesaurus using a graphsimilarity measure.
In Proceedings of the SeventhConference on International Language Resourcesand Evaluation.Mihalcea, Rada, Carmen Banea, and Janyce Wiebe.2007.
Learning multilingual subjective languagevia cross-lingual projections.
In Proceedings of the45th Annual Meeting of the Association of Compu-tational Linguistics, pages 976?983.Pang, Bo, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
Sentiment classification usingmachine learning techniques.
In Proceedings of the2002 Conference on Empirical Methods in NaturalLanguage Processing, pages 79?86.Scheible, Christian.
2010.
Sentiment translationthrough lexicon induction.
In Proceedings of theACL 2010 Student Research Workshop, Uppsala,Sweden.
Association for Computational Linguis-tics.Schmid, Helmut.
1994.
Probabilistic part-of-speechtagging using decision trees.
In Proceedings of theInternational Conference on New Methods in Lan-guage Processing.Turney, Peter.
2002.
Thumbs up or thumbs down?semantic orientation applied to unsupervised classi-fication of reviews.
In Proceedings of 40th AnnualMeeting of the Association for Computational Lin-guistics, pages 417?424.Wan, Xiaojun.
2009.
Co-training for cross-lingualsentiment classification.
In Proceedings of the JointConference of the 47th Annual Meeting of the ACLand the 4th International Joint Conference on Natu-ral Language Processing of the AFNLP, pages 235?243, Suntec, Singapore, August.
Association forComputational Linguistics.West, Michael.
1953.
A general service list of englishwords.Widdows, Dominic and Beate Dorow.
2002.
A graphmodel for unsupervised lexical acquisition.
InCOL-ING.Wilson, Theresa, Janyce Wiebe, and Paul Hoffmann.2005.
Recognizing contextual polarity in phrase-level sentiment analysis.
In Proceedings of HumanLanguage Technology Conference and Conferenceon Empirical Methods in Natural Language Pro-cessing, pages 347?354, October.1112
