Proceedings of EACL '99Resolving Discourse Deictic Anaphora in DialoguesMir iam Eckert  & Michael StrubeInstitute for Research in Cognit ive Sc ienceUniversity of  Pennsylvania3401 Walnut Street, Suite 400APhiladelphia, PA 19104, USA{miriame, strube}@linc, cis.
upenn, eduAbstractMost existing anaphora resolution algo-rithms are designed to account only foranaphors with NP-antecedents.
This paperdescribes an algorithm for the resolution ofdiscourse deictic anaphors, which constitutea large percentage ofanaphors in spoken di-alogues.
The success of the resolution isdependent on the classification of all pro-nouns and demonstratives into individual,discourse deictic and vague anaphora.
Fi-nally, the empirical results of the applicationof the algorithm to a corpus of spoken dia-logues are presented.1 IntroductionMost anaphora resolution algorithms are designed todeal with the co-indexing relation between anaphorsand NP-antecedents.
In the spoken language corpuswe examined - the Switchboard corpus of telephoneconversations (LDC, 1993) - this type of link onlyaccounts for 45.1% of all anaphoric references.
An-other 22.6% are anaphors whose referents are not in-dividual, concrete ntities but events, facts and propo-sitions, e.g.,(1) B.7:A.8:\[We never know what they're thinking\]/.Thati's right.
\[I don't trust hem\]j,maybe I guess itj's because of whathappened over there with their ownpeople, how they threw them out ofpower.
(sw3241)Whilst there have been attempts to classify abstractobjects and the rules governing anaphoric reference tothem (Webber, 1991; Asher, 1993; Dahl and Hellman,1995), there have been no exhaustive, mpirical stud-ies using actual resolution algorithms.
These have sofar only been applied to written corpora.
However,the high frequency of abstract object anaphora in dia-logues means that any attempt to resolve anaphors inspoken language cannot succeed without aking thisinto account.Summarised below are some issues specific toanaphora resolution in spoken dialogues (see alsoByron and Stent (1998) who mention some of theseproblems in their account of the Centering model(Grosz et al, 1995)).Center of attention in multi-party discourse.
Inspontaneous speech it is possible that the participantsof a dialogue may not be focussing on the same entityat a given point in the discourse.Utterances with no discourse entities.
E.g., Uh-huh; yeah; right.
Byron and Stent (1998) andWalker (1998) assign no importance tosuch utterancesin their models.
We assume that hese also can be usedto acknowledge a preceding utterance.Abandoned or partial utterances.
Speakers may in-terrupt each other or make speech repairs, e.g.,(2) Uh, our son/has this kind of, you know, he/'s,well hei started out going Stephen F Austin(sw3117)Self-corrected speech cannot be ignored as can beseen by the fact that the entity referred to by the NPour son is subsequently referred to by a pronoun andmust therefore have entered the discourse model.Determination of utterance boundaries.
Mostanaphor resolution algorithms rely on a syntactic def-inition of utterance which cannot be provided by spo-ken dialogue as there is no punctuation tomark com-plete sentences.These issues are dealt with by our method of segment-ing dialogues into dialogue acts with specified dis-course functions.
In addition, our approach presentsa simple classification of individual and abstract ob-ject anaphors and uses separate algorithms for eachclass.
We build on the recall rate of state-of-the-artpronoun resolution algorithms but we achieve a farhigher precision than would be achieved by applyingthese to spoken language because the classification of37Proceedings of EACL '99anaphors prevents the algorithm from co-indexing dis-course deictic anaphora with individual antecedents.Section 2 gives definitions and frequency of occur-rence of the different anaphor types.
Section 3 de-scribes the segmentation f the dialogues into dialogueacts and the influence of these on the entities in thediscourse model.
Section 4 presents the method weuse for resolving anaphors and the corresponding al-gorithm.
In Section 5, we report on the corpus anno-tation and the evaluation of the algorithm.2 Anaphor Types in DialoguesIn the dialogues examined, only 45.1% of the anaphorsare individual anaphors, i.e., anaphors with NP-antecedents (IPro, IDem), e.g.,(3) Boeing ought to hire himi and give him/ ajunkyardj .
.
.
.
and see if hei could build aSeven Forty-Seven out of itj.
(sw2102)22.6% of the anaphors are discourse deictic, i.e.co-specify with non-NP constituents such as VPs, sen-tences, strings of sentences (DDPro, DDDem; cf.Webber (1991)).
The phenomenon of discourse de-ictic anaphora in written texts has been shown to bestrongly dependent on discourse structure.
As can alsobe seen in the examples below, anaphoric reference isrestricted to elements adjacent o the utterance con-taining the anaphor, i.e., those on the right frontierof the discourse structure tree (Webber, 1991; Asher,1993):(4) A.46: \[The government don't tell youeverything.\]iB.47: I knowit/(sw3241)(5) Now why didn't she \[take him over there withher\]i?
No, she didn't do thati.
(sw4877)The existence of abstract object anaphora showsthat aside from individual entities, the discourse modelmay also contain complex, higher-order ntities.
Oneof the differences between individual and discoursedeictic anaphora is that whereas a concrete NP an-tecedent usually only refers to the individual it de-scribes, a sentence may simultaneously denote aneventuality, a concept, a proposition and a fact.Instead of assuming that all levels of abstract ob-jects are introduced to the discourse model by the sen-tence that makes them available, it has been suggestedthat anaphoric discourse deictic reference involves ref-erent coercion (Webber, 1991; Asher, 1993; Dahl andHellman, 1995).
This assumption is further justifiedby the fact that discourse deictic reference, as opposedto individual anaphoric reference, is often established38by demonstratives rather than pronouns.
In theoriesrelating cognitive status and choice of NP-form (cf.Gundel et al (1993)), pronouns are only available forthe most salient entities, whereas demonstratives canbe used to shift the focus of attention to a different en-tity.A further 19.1% of anaphors are Inferrable-Evoked Pronouns (IEPro) and constitute a particulartype of plural pronoun which indirectly co-specifieswith a singular antecedent.
This group includes exis-tential, generic and corporate 3rd person plural pro-nouns (Jaeggli, 1986; Belletti and Rizzi, 1988).
(6) I think the Soviet Union knows what we haveand knows that we're pretty serious and if theyever tried to do anything, we would, we wouldbe on the offensive.
(sw3241)In (6), the NP Soviet Union can be associated withinferrables uch as the population or the government.These can subsequently be referred to by pronounswithout having been explicitly mentioned themselves.In some cases of IEPro's there is no associated NP, asin the following example, where the speaker is refer-ring to the organisers of the Switchboard calls:(7) this is the first call I 've done \[...\] and, I didn'trealize that they ha-, were going to reachout to people from \[...\] all over the country.
(sw2041)13.2% of the anaphors are vague (VagPro, Vag-Dem), in the sense that they refer to the general topicof conversation and, as opposed to discourse deic-tic anaphors, do not have a specific clause as an an-tecedent, e.g.,(8) B.29: I mean, the baby is like seventeenmonths and she just screams.A.30: Uh-huh.B.31 : Well even if she knows that they'refixing to get ready to go over there.They're not even there yet -A.32: Uh-huh.B.33: -you  know.A.34: Yeah.
It's hard.Non-referring pronouns, or expletives, were notmarked.
These include subjects of weather verbs,those in raising verb constructions or those occurringin sentences with extraposed sentential subjects or ob-jects, e.g.,(9) It's hard to realize, that there are places thatare just so, uh, bare on the shelves as there.
(sw2403)This group also contains the various ubcategorisedexpletives (Postal and Pullum, 1988), defined as beingnon-referring pronouns in argument positions, e.g.,Proceedings of EACL '99(10) Uh, they don't need somebody else coming inand saying, you know, okay we're going to bewith them and we're going to zap it to you.
(sw2403)(11) When it comes to trucks, though, I wouldprobably think to go American.
(sw2326)They differ from referring anaphors in that theycannot be questioned (e.g., *When what comes totrucks ?
).3 Synchronising UnitsThe domain which contains potential antecedents inot given in syntactic terms in spoken dialogue.
Hencewe define this domain in pragmatic terms.
We assumethat discourse ntities enter the joint discourse modeland are available for subsequent reference when com-mon ground between the discourse participants i es-tablished.
Our model builds on the observation thatcertain dialogue acts - in particular acknowledgments- signal that common ground is achieved.
Our as-sumptions are based on Clark's (1989) theory of con-tributions (cf.
also Traum (1994)).Each dialogue is divided into short, clearly de-fined dialogue acts - Initiations I and Acknowledg-ments A - based on the top of the hierarchy givenin Carletta et al (1997).
Each sentence and each con-joined clause counts as a separate I, even if they arepart of the same turn.
A's do not convey semantic on-tent but have a pragmatic function (e.g., backchannel).In addition there are utterances which function as anA but also have semantic ontent - these are labelledas A/I.A single I is paired with an A and they jointly forma Synchronising Unit (SU).
In longer turns, each mainclause functions as a separate unit along with its sub-ordinate clauses.
Single I 's constitute SU's by them-selves and do not require explicit acknowledgment.The assumption is that by letting the speaker continue,the hearer implicitly acknowledges the utterance.
It isonly in the context of turn-taking that I's and A's arepaired up.Our model is based on the observation that com-mon ground has an influence on attentional state.
Weassume that only entities in a complete SU are en-tered into the common ground and remain in the S-list for the duration of a further SU.
If one speaker's Iis not acknowledged by the other participant i cannotbe included in an SU.
In this case the discourse nti-ties mentioned in the unacknowledged I are added tothe S-List but are immediately deleted again when thesubsequent I clearly shows that they are not part of thecommon ground.Figure 1 below, taken from the Trains-corpus(speakers  and u) illustrates that a missing acknowl-39edgment prevents the discourse model from contain-ing discourse ntities from the unacknowledged turn.SUi I s: so there- the five boxcars of oranges<sil> + that are at- +S-List: \[5 boxcars of oranges\]SUj A/I u: +at <sil> +atComingS-List: \[5 boxcars of oranges, Coming\]A s: urn- I u: okay the orange warehouse <sil> urnI + have to +S-List: \[Coming, orange warehouse\]SUk I S: yOU need + you need to get five <sil>five boxcars of oranges thereS-List: \[Coming, 5 boxcars of oranges\]A u: uhSOt I no they're are already waiting for methere(d92a-4.3)Figure 1: Unacknowledged TurnsSpeaker u's second turn is an I which is not fol-lowed by an A.
This means that the entity referred toin that utterance (orange warehouse) is immediatelyremoved from the joint discourse model.
Thus therein the final two turns co-specifies with Coming andnot the most recent orange warehouse.4 How to Resolve Discourse DeicticAnaphoraWe now turn to our method of anaphora reso-lution, which extends the algorithm presented inStrube (1998), in order to be able to account fordiscourse deictic anaphora as well as individualanaphora.4.1 Anaphor-anteeedent Compatibi l i tyAs indicated in Section 2, information provided bythe subcategorisation frame of the anaphor's predicatecan be used to determine the type of the referent.
Inthe algorithm, we make use of the notion of anaphor-antecedent Compatibility to distinguish between dis-course deictic and individual reference.
Certain pred-icates (notably verbs of propositional ttitude) requireone of their arguments o have a referent whose mean-ing is correlated with sentences, e.g., is true, assume(referred to as SC-bias verbs in Garnsey et al (1997)and elsewhere).
Pronouns in these positions rarelyhave concrete individual NP-antecedents and are gen-erally only compatible with discourse deictic refer-ents.
Other argument positions are preferentially as-sociated with concrete individuals (e.g., objects of eat,smell) (DO-bias verbs).
A summary of these predicatetypes is provided in Figure 2, where l-incompatibleProceedings of EACL '99I-Incompatible (*I)Equating constructions where a pronominal referentis equated with an abstract object, e.g., x is makingit easy, x is a suggestion.Copula constructions whose adjectives can only beapplied to abstract entities, e.g., x is true, x is false,x is correct, x is right, x isn't right.?
Arguments of verbs describing propositional atti-tude which only take S'-complements, e.g., assume.?
Object of do.?
Predicate or anaphoric referent is a "reason", e.g., xis because I like her, x is why he ' s late.A-Incompatible (*A)Equating constructions where a pronominal referentis equated with a concrete individual referent, e.g., xis a car.Copula constructions whose adjectives can only beapplied to concrete ntities, e.g., x is expensive, x istasty, x is loud.Arguments of verbs describing physical con-tact/stimulation, which cannot be used metaphori-cally, e.g., break x, smash x, eat x, drink x, smell xbut NOT *see xFigure 2: I-Incompatibility and A-Incompatibilitymeans preferentially associated with abstract objectsand A-incompatible means preferentially associatedwith individual objects 1.
Anaphors which are argu-ment positions of the first type are classified as dis-course deictic (DDPro; DDDem), those in argumentpositions of the second type are classified as individ-ual anaphora (IPro; IDem).It is clear that predicate information alone is not suf-ficient for this purpose as there is a large group ofverbs which allow both individual and discourse de-ictic referents (e.g., objects of see, know) (EQ-biasverbs).
In these cases the preference is determined byNP-form of the anaphor (pronoun vs. demonstrative).4.2 Types of Abstract AntecedentsWe follow Asher (1993) in assuming that the predicateof a discourse deictic anaphor determines the type ofabstract object.
An anaphor in the object position ofthe verb do, for example, can only have a VP (event-concept) antecedent (eg John \[sang\].
Bill did thattoo.
), whereas an anaphor in the subject position ofthe predicate is true requires a full S (proposition) (eg\[John sang\].
That 's  true.).
This verbal subcategorisa-tion information is used to determine which part of thepreceding I is required to form the correct referent.Following Webber and others, we assume that anabstract object is only introduced to the discoursemodel by the anaphor itself.
In addition to the S-List(Strube, 1998), which contains the referents of NPsavailable for anaphoric reference, our model includes~These are preferences and not strict rules because somel-Incompatible contexts are compatible with NPs denotingabstract objects, e.g., The story/It is true.
and NPs whichare used to stand elliptically for an event or state, e.g., Hiscar/It is the reason why he's late.
This shows that predicatecompatibility must ultimately be defined in semantic termsand not just rely on syntactic strings (NP vs. S).40an A-List for abstract objects.
This is only filled if dis-course deictic pronouns or demonstratives occur andits contents remain only for one I, which is necessaryfor multiple discourse deictic reference to the same en-tity.The following context ranking describes the order inwhich the parts of the linguistic context are accessed:1.
A-List (containing abstract objects previously re-ferred to anaphorically).2.
Within same I: Clause to the left of the clausecontaining the anaphor.3.
Within previous I: Rightmost main clause (andsubordinated clauses to its right).4.
Within previous rs :  Rightmost complete sen-tence (if previous I is incomplete sentence).Figure 3: Context Ranking4.3 The AlgorithmThe algorithm consists of two branches, one for theresolution of pronouns, the other for the resolution ofdemonstratives.
Both of them call the functions re-solveDD and resolvelnd, which resolve discourse de-ictic anaphora nd individual anaphora, respectively.If a pronoun is encountered (Figure 4, below), thefunctions resolveDD or resolvelnd (described below)are evaluated, depending on whether the pronoun is I-incompatible (1) or A-incompatible (2).
In the case ofsuccess the pronouns are classified as DDPro or lPro,respectively.
In the case of failure, the pronouns areclassified as VagPro.
If the pronoun is neither I- norA-incompatible (i.e., the pronoun is ambiguous in thisrespect), the classification is only dependent on theProceedings of EACL '991.
if (PRO is I-incompatible)then if resolveDD(PRO)then classify as DDProelse classify as VagPro2.
else if (PRO is A-incompatible)then if resolvelnd(PRO)then classify as IProelse classify as VagPro3.
else if resolvelnd(PRO)then classify as IPro4.
else if resolveDD(PRO)then classify as DDProelse classify as VagProFigure 4: Pronoun Resolution Algorithm1.
if (DEM is I-incompatible)then if resolveDD(DEM)then classify as DDDemelse classify as VagDem2.
else if (DEM is A-incompatible)then if resolveInd(DEM)then classify as IDemelse classify as VagDem3.
else if resolveDD(DEM)then classify as DDDem4.
else if resolvelnd(DEM)then classify as IDemelse classify as VagDemFigure 5: Demonstrative Resolution Algorithmsuccess of the resolution.
The function resolvelnd isevaluated first (3) because of the observed preferencefor individual antecedents for pronouns,.
If success-ful, the pronoun is classified as IPro, if unsuccessful,the function resolveDD attempts to resolve the pro-noun (4).
If this, in turn, is successful, the pronoun isclassified as DDPro, if it is unsuccessful it is classi-fied as VagPro, indicating that the pronoun cannot beresolved using the linguistic context.The procedure is similar in the case of demonstra-fives (Figure 5, below).
The only difference being thatthe antecedent of a demonstrative is preferentially anabstract object.
The order of (3) and (4) is thereforereversed.We now turn to the function resolveDD (Figure 6,below) (assuming that resolvelnd resolves individualanaphora nd returns true or false depending on itssuccess).
In step (1) the function resolveDD examinesall elements of the context ranking (Figure 3) until thefunction co-index succeeds, which evaluates whetherthe element is of the right type.
Then the functionresolveDD returns true.
If the pronoun is an argu-ment of "do", the function co-index is tried on the VPof the current element of the context ranking (2).
Ifsuccessful, the VP-referent is added to the A-List andthe function returns true.
In (3), co-index evaluateswhether the pronoun and the current element of thecontext ranking are compatible.
In the case of a posi-tive result, the element is added to the A-List and trueis returned.
If all elements of the context ranking areresolveDD(PRO) :=1.
foreach element of context ranking do2.
if (PRO is argument of do)then if (co-index PRO with VP of element)then add VP to A-List; return true3.
else if (co-index PRO with element)then add element to A-List; return true4.
return false.Figure 6: resolveDD41checked without success, resolveDD returns false (4).Example 12 illustrates the algorithm:(12) B.8: I mean, if went and policed, just likeyou say, every country when they hadsquabbles,A.9: Well,but we've done it before,B.10: Oh,I know we have.A.
11 : and it has not been successful.
(sw2403)When the pronoun "it" in A.9 is encountered,the algorithm determines the pronoun to be I-incompatible (Step 1 in Figure 4), as it is the objectargument of the verb do.
The function resolveDD isevaluated.
The A-List is empty, so the highest rankedelement in the context ranking is the last complete sen-tence in B.8.
The pronoun is an argument of "do",therefore gets co-indexed with the VP-referent of thesentence in B.8.
The VP is added to the A-List, thefunction returns true and the pronoun is classified asDDPro by the algorithm.When the next pronoun is encountered, the A-List is empty again because of the intervening sen-tence (I) in B.10.
The pronoun is neither I- norA-incompatible, therefore the algorithm evaluates re-solvelnd (step 3).
This fails, since there are no indi-vidual antecedents available in B.
10 and the algorithmevaluates resolveDD in the step (4).
The first elementin the context ranking is the main clause in A.
11 whichis co-indexed with the pronoun.
The clause-referentis added to the A-List, the function returns true andthe algorithm classifies the pronoun as DDPro.
In thiscase, the classification is correct but not the resolution,since the pronoun should co-specify with the pronounin A.9.5 Empi r i ca l  Eva luat ionIn order to test the hypotheses made in the previoussections we performed an empirical evaluation on nat-Proceedings ofEACL '99urally occurring dialogues.
First, the corpus was an-notated for all relevant features, i.e., division of turnsinto dialogue act units, classification of dialogue acts(I, A), marking of noun phrases, classification of thevarious types of anaphors introduced in Section 2, andannotating coreference between anaphors and individ-ual/abstract discourse ntities.
The last step providedthe key for the test of the algorithm described in Sec-tion 4.3.5.1 AnnotationOur data consisted of five randomly selected dia-logues from the Switchboard corpus of spoken tele-phone conversations (LDC, 1993).
Two dialogues(SW2041, SW4877) were used to train the two annota-tors (the authors), and three further dialogues for test-ing (SW2403, SW3117, SW3241).
The training dia-logues were used for improving the annotation manualand for clarifying the annotation i  borderline cases.After each step the annotations were compared us-ing the ~ statistic as reliability measure for all classifi-cation tasks (Carletta, 1996).
A t~ of 0.68 < ~ < 0.80allows tentative conclusions while ~ > 0.80 indicatesreliability between the annotators.
In the following ta-bles, the rows on above the horizontal line show howoften a particular class was actually marked as such byboth annotators.
In the rows below the line, N showsthe total number of markables, while Z gives the num-ber of agreements between the annotations.
PA is per-cent agreement between the annotators, PE expectedagreement by chance.
Finally, ~ is computed by theformula PA - PE /1  - PE .Dialogue Acts.
First, turns were segmented into di-alogue act units.
We turned the segmentation task intoa classification task by using boundaries between di-alogue acts as one class and non-boundaries a  theother (see Passonneau and Litman (1997) for a simi-lar practice).
In Table l, Non-Bound.
and Bound.
givethe number of non-boundaries and boundaries actu-ally marked by the annotators, N is the total numberof possible boundary sites, while Z gives the numberof agreements between the annotations.SW2403 SW3117 SW3241 ENon-Bound.
3372 3332 1717 8421Bound.
454 452 241 1147NZPAPE1913 1892 9791877 1866 9620.9812 0.9863 0.98260.7908 0.7896 0.78410.9100 0.9347 0.9200Table I : Dialogue Act Units478447050.98350.78900.9217Table 2 shows the results of the comparison be-tween the annotations with respect o the classification42of the dialogue act units into Initiations (I), Acknowl-edgements (A), Acknowledgement/Initiations (A/I),and no dialogue act (No).
For this test we used onlythese dialogue act units which the annotators agreedabout.
PA was 92.6%, ~ = 0.87 again indicating thatit is possible to annotate these classes reliably.IAMINoNZPAPESW2403 SW3117 SW3241230 211 10898 120 6838 41 160 8 8183 190 100167 181 900.9126 0.9526 0.90000.4774 0.4201 0.41520.8327 0.9183 0.8290E54928695164734380.92600.42730.8708Table 2: Dialogue Act LabelsIndividual and Abstract Object Anaphora.
Table32 shows the reliability scores for the classificationof pronouns in the classes IPro, DDPro, VagPro, andIEProclassification of demonstratives in the classesIDem, DDDem, ~ and VagDem.
The e-values arearound .8, indicating that annotators were able to clas-sify the pronouns reliably.IProDDProVagProIEProNZPAPESW2403 SW3117 SW3241120 148 533 5 931 20 2624 20 86104 97 6383 90 580.7980 0.9278 0.92060.3935 0.6039 0.51510.6670 0.8170 0.836327347771302642310.87500.35710.8055Table 3: Classification of PronounsSW2403 SW3117 SW3241 EIDem 9 19 2 30DDDem 45 34 28 107VagDem 5 3 6 14NZPAPE30 28 1827 26 160.9000 0.9286 0.88880.5919 0.4866 0.63580.7550 0.8609 0.694976690.90780.54300.7985Table 4: Classification of DemonstrativesCo-Indexation of Abstract Object Anaphora.
Theabstract object anaphora were manually co-indexed2No.
for each class is the actual no.
marked by both an-notators.
N is the total number of markables, Z is total num-ber of agreements between annotators, PE is the expectedagreement by chance.Proceedings of EACL '99with their antecedents.
For this task we cannot pro-vide reliability scores using n because it is not a clas-sification task.
It is much more difficult than theprevious ones, as the problem consists of identifyingthe correct beginning and end of the string which co-specifies with the anaphor.
We used only the abstractanaphors whose classification both annotators agreedupon.
The annotators then marked the antecedents andco-indexed them with the anaphors.
The results werecompared and the annotators agreed upon a reconciledversion of the data.
Annotator accuracy was then mea-sured against the reconciled version.
Accuracy rangedfrom 85,7% (Annotator A) to 94,3% (Annotator B).SW2403 SW3117 SW3241AAgreem.
31 15 14 60No Agreem.
7 2 1 10BAgreem.No Agreem.35 16 153 1 0664Table 5: Agreement about Antecedents of DiscourseDeictic Anaphora gainst Key5.2 Evaluation of the AlgorithmWe used the reconciled version of the annotation askey for the abstract anaphora resolution algorithm.
Ta-ble 6 shows the results of the evaluation.
Precision is63.6% and Recall 70%.Res.
Corr.Res.
OverallRes.
KeyPrecisionRecallSW2403 SW3117 SW324125 I1 13 4938 19 20 7738 17 15 700.658 0.579 0.65 0.6360.658 0.647 0.867 0.7Table 6: Results of the Discourse Deictic AnaphoraAlgorithmThe low value for precision indicates that the classi-fication did not perform very well.
Of the 28 anaphorsresolved incorrectly, only 11 were classified correctly.One of the most common errors in classification was,that an anaphor annotated as vague (VagPro, VagDem)was classified by the algorithm as discourse deictic(DDPro, DDDem).
Classification is dependent on res-olution, so since the context almost always provides anantecedent for a discourse deictic anaphor, it is possi-ble to classify and resolve avague anaphor incorrectly,as in Example 13:(13) A: \[I don't know\]/ , I think it/ really dependsa lot on the child.
(sw3117)6 Comparison to Related WorkBoth Webber(1991) and Asher (1993) describe thephenomenon of abstract object anaphora nd presentrestrictions on the set of potential antecedents.
Theydo not, however, concern themselves with the problemof how to classify a certain pronoun or demonstrativeas individual or abstract.
Also, as they do not givepreferences on the set of potential candidates, theirapproaches are not intended as attempts to resolve ab-stract object anaphora.Concerning anaphora resolution in dialogues, onlylittle research as been carried out in this area to ourknowledge.
LuperFoy (1992) does not present a cor-pus study, meaning that statistics about he distributionof individual and abstract object anaphora or aboutthe success rate of her approach are not available.Byron and Stent (1998) present extensions of the cen-tering model (Grosz et al, 1995) for spoken dialogueand identify several problems with the model.
Wehave chosen Strube's (1998) model for the resolutionof individual anaphora s basis because it avoids theproblems encountered by Byron & Stent, who also donot present data on the resolution of pronouns in dia-logues and do not mention abstract object anaphora.Dagan and Itai (1991) describe a corpus-based ap-proach to the resolution of pronouns, which is evalu-ated for the neuter pronoun "it".
Again, abstract ob-ject anaphora are not mentioned.7 Conclusions and Future WorkIn this paper we presented a method for resolving ab-stract object anaphora in spoken language.
We con-sider our approach to be a first step towards the un-constrained resolution of anaphora in dialogue.The results of our method show that the recall isfairly high while the precision is relatively low.
Thisindicates that the anaphor classification requires im-provement, in particular the notion of Compatibility.Lists of verb biases for sentential and NP comple-ments, as described in psycholinguistic studies (e.g.Garnsey et al (1997)), could be used to classify verbs.Currently exisiting lists only account for a small num-ber of verbs but there may be the possibility of addingstatistical information from large corpora of spokendialogue.Furthermore, the algorithm currently ignores ab-stract NPs (e.g., story, exercising) when looking forantecedents for anaphors with 1-incompatible predi-cates.
We are considering determining the feature ab-stract for all NPs in order to identify those which canact as antecedents in such contexts.Information such as this could be used by the algo-rithm to prevent the anaphor classification from beingdependent on anaphor resolution.43Proceedings of EACL '99Acknowledgments.
We would like to thank DonnaByron and Amanda Stent for discussing the central is-sues contained in this paper.
We are grateful to au-diences at AT&T Labs-Research, the University ofDelaware, IBM Research and the participants ofEllenPrince's Discourse Analysis Seminar for the criticalfeedback they provided.
Thanks also to Jonathan De-Cristofaro and Kathleen E McCoy who discussed theempirical issues.
Both authors are funded by post-doctoral fellowship awards from IRCS.ReferencesNicholas Asher.
1993.
Reference to Abstract Objects.Kluwer, Dordrecht.Adriana Belletti and Luigi Rizzi.
1988.
Psych verbsand theta theory.
Natural Language and LinguisticTheory, 6:291-352.Donna Byron and Amanda Stent.
1998.
A prelim-inary model of centering in dialog.
In Proceed-ings of the 17 th International Conference on Com-putational Linguistics and 36 th Annual Meetingof the Association for Computational Linguistics,Montrral, Qurbec, Canada, 10-14 August 1998,pages 1475-1477.Jean Carletta, Amy Isard, Stephen Isard, JacquelineKowtko, Gwyneth Doherty-Sneddon, a d Anne An-derson.
1997.
The reliability of a dialogue struc-ture coding scheme.
Computational Linguistics,23(1):13-31.Jean Carletta.
1996.
Assessing agreement on classi-fication tasks: The kappa statistic.
ComputationalLinguistics, 22(2):249-254.Herbert H. Clark and Edward F. Schaefer.
1989.
Con-tributing to discourse.
Cognitive Science, 13:259-294.Ido Dagan and Alon Itai.
1991.
A statistical filter forresolving pronoun references.
In Y.A.
Feldman andA.
Bruckstein, editors, Artificial Intelligence andComputer Vision, pages 125-135.
Elsevier, Amster-dam.t3sten Dahl and Christina Hellman.
1995.
What hap-pens when we use an anaphor.
In Presentation atthe XVth Scandinavian Conference of LinguisticsOslo, Norway.Susan Garnsey, Neal Pearlmutter, Elizabeth Myers,and Melanie Lotocky.
1997.
Contributions of verbbias and plausibility to the comprehension f tem-porarily ambiguous sentences.
Journal of Memoryand Language, 37:58-93.Barbara J. Grosz, Aravind K. Joshi, and Scott Wein-stein.
1995.
Centering: A framework for modelingthe local coherence of discourse.
ComputationalLinguistics, 21 (2):203-225.44Jeanette K. Gundel, Nancy Hedberg, and RonZacharski.
1993.
Cognitive status and the formof referring expressions in discourse.
Language,69:274-307.Osvaldo Jaeggli.
1986.
Arbitrary plural pronominals.Natural Language and Linguistic Theory, 4:43-76.LDC.
1993.
Switchboard.
Linguistic Data Con-sortium.
University of Pennsylvania, Philadelphia,Penn.Susann LuperFoy.
1992.
The representation f mul-timodal user interface dialogues using discoursepegs.
In Proceedings of the 30 th Annual Meetingof the Association for Computational Linguistics,Newark, Del., 28 June - 2 July 1992, pages 22-31.Rebecca Passonneau and Diane Litman.
1997.Discourse segmentation by human and automatedmeans.
Computational Linguistics, 23(1): 103-139.Paul Postal and Geoffrey Pullum.
1988.
Expletivenoun phrases in subcategorized positions.
Linguis-tic Inquiry, 19:635-670.Michael Strube.
1998.
Never look back: An alter-native to centering.
In Proceedings of the 17 th In-ternational Conference on Computational Linguis-tics and 36 th Annual Meeting of the Associationfor Computational Linguistics, Montrfal, Qurbec,Canada, 10-14 August 1998, pages 1251-1257.David R. Traum.
1994.
A Computational The-ory of Grounding in Natural Language Conversa-tion.
Ph:D. thesis, Department of Computer Sci-ence, University of Rochester.Marilyn A. Walker.
1998.
Centering, anaphora res-olution, and discourse structure.
In M.A.
Walker,A.K.
Joshi, and E.E Prince, editors, Centering The-ory in Discourse, pages 401-435.
Oxford Univer-sity Press, Oxford, U.K.Bonnie L. Webber.
1991.
Structure and ostensionin the interpretation f discourse deixis.
Languageand Cognitive Processes, 6(2): 107-135.
