Proceedings of the NAACL HLT 2010 Workshop on Speech and Language Processing for Assistive Technologies, pages 28?36,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsScanning methods and language modeling for binary switch typingBrian Roark?, Jacques de Villiers?, Christopher Gibbons?
and Melanie Fried-Oken?
?Center for Spoken Language Understanding ?Child Development & Rehabilitation CenterOregon Health & Science University{roark,jacques}@cslu.ogi.edu {gibbons,mfo}@ohsu.eduAbstractWe present preliminary experiments of abinary-switch, static-grid typing interfacemaking use of varying language model contri-butions.
Our motivation is to quantify the de-gree to which language models can make thesimplest scanning interfaces ?
such as show-ing one symbol at a time rather than a scan-ning a grid ?
competitive in terms of typingspeed.
We present a grid scanning methodmaking use of optimal Huffman binary codes,and demonstrate the impact of higher orderlanguage models on its performance.
We alsoinvestigate the scanning methods of highlight-ing just one cell in a grid at any given timeor showing one symbol at a time without agrid, and show that they yield commensurateperformance when using higher order n-grammodels, mainly due to lower error rate and alower rate of missed targets.1 IntroductionAugmentative and Alternative Communication(AAC) is a well-defined subfield of assistive tech-nology, focused on methods that assist individualsfor whom conventional spoken or written communi-cation approaches are difficult or impossible.
Thosewho cannot make use of standard keyboards for textentry have a number of alternative text entry meth-ods that permit typing.
One of the most common ofthese alternative text entry methods is the use of abinary switch ?
triggered by button-press, eye-blinkor even through event related potentials (ERP) suchas the P300 detected in EEG signals ?
that allowsthe individual to make a selection based on somemethod for scanning through alternatives (Lesher etal., 1998).
Typing speed is a challenge, yet criticallyimportant for usability.
One common approach isrow/column scanning on a matrix of characters,symbols or images (a ?spelling grid?
), which allowsthe user of a binary yes/no switch to select the rowand column of a target symbol, by simply indicating?yes?
(pressing a button or blinking an eye) when therow or column of the target symbol is highlighted.Figure 1 shows the 6?6 spelling grid used for theP300 Speller (Farwell and Donchin, 1988).For any given scanning method, the use of a bi-nary switch to select from among a set of options(letter, symbols, or images) amounts to the assign-ment of binary codes to each symbol.
For example,the standard row/column scanning algorithm worksby scanning each row until a selection is made, thenscanning each column until a selection is made, andreturning the symbol at the selected row and column.This can be formalized as follows:1 for i = 1 to (# of rows) do2 HIGHLIGHTROW(i)3 if YESSWITCH4 for j = 1 to (# of columns) do5 HIGHLIGHTCOLUMN(j)6 if YESSWITCH7 return (i, j)8 return (i, 0)9 return (0, 0)where the function YESSWITCH returns true if thebutton is pressed (or whatever switch event counts asa ?yes?
response) within the parameterized latency.If the function returns (0, 0) then nothing has beenselected, requiring rescanning.
If the function re-turns (i, 0) for i > 0, then row i has been selected,but columns must be rescanned.
Under this scanningmethod, the binary code for the letter ?J?
in the ma-trix in Figure 1 is 010001; the letter ?T?
is 000101.The length of the binary code for a symbol is re-MGA FEC_97653 4Y 1ZXWUTSRQONHBLKIV8PJ2DFigure 1: Spelling grid such as that used for the P300speller (Farwell and Donchin, 1988).
?
?
denotes space.28lated to the time required to type it.
In the ma-trix in Figure 1, the space character is in the bot-tom right-hand corner, yielding the maximum binarycode length for that grid size (12), despite that, intypical written English we would expect the spacecharacter to be used about 20% of the time.
A moreefficient strategy would be to place the space charac-ter in the upper left-hand corner of the grid, leadingto the much shorter binary code ?11?.Ordering symbols in a fixed grid so that frequentsymbols are located in the upper left-hand corner isone method for making use of a statistical model ofthe language so that likely symbols receive the short-est codes.
Such a language model, however, doesnot take into account what has already been typed,but rather assigns its code identically in all contexts.In this paper we examine alternative fixed-grid scan-ning methods that do take into account context in thelanguage models used to establish codes, i.e., thecodes in these methods vary in different contexts,so that high probability symbols receive the short-est codes and hence require the fewest keystrokes.We show that n-gram language models can providea large improvement in typing speed.Before presenting our methods and experimentalresults, we next provide further background on alter-native text entry methods, language modeling, andbinary coding based on language models.2 Preliminaries and background2.1 Alternative text entryOf the ways in which AAC typing interfaces differ,perhaps most relevant to the current paper is whetherthe symbol positions are fixed or can move dynam-ically, because such dynamic layouts facilitate in-tegration of richer language models.
For example,if we re-calculate character probabilities after eachtyped character, then we could re-arrange the char-acters in the grid so that the most likely are placedin the upper left-hand corner for row/column scan-ning.
Conventional wisdom, however, is that thecognitive overhead of processing a different grid ar-rangement after every character would slow downtyping more than the speedup due to the improvedbinary coding (Baletsa et al, 1976; Lesher et al,1998).
The GazeTalk system (Hansen et al, 2003),which presents the user with a 3?4 grid and captureswhich cell the user?s gaze fixates upon, is an instanceof a dynamically changing grid.
The cell layoutsare configurable, but typically one cell contains a setof likely word completions; others are allocated tospace and backspace; and around half of the cells areallocated to the most likely single character contin-uation of the input string, based on language modelpredictions.
Hansen et al (2003) report that usersproduced more words per minute with a static key-board than with the predictive grid interface, illus-trating the impact of the cognitive overhead that goesalong with this sort of scanning.The likely word completions in the GazeTalk sys-tem illustrates another common way in which lan-guage modeling is integrated into AAC typing sys-tems.
Much of the language modeling researchwithin the context of AAC has been for word com-pletion/prediction for keystroke reduction (Darraghet al, 1990; Li and Hirst, 2005; Trost et al, 2005;Trnka et al, 2006; Trnka et al, 2007; Wandmacherand Antoine, 2007).
The typical scenario for this isallocating a region of the interface to contain a set ofsuggested words that complete what the user has be-gun typing.
The expectation is to derive a keystrokesavings when the user selects one of the alternativesrather than typing the rest of the letters.
The cogni-tive load of monitoring a list of possible completionshas made the claim that this speeds typing contro-versial (Anson et al, 2004); yet some results haveshown this to speed typing under certain conditions(Trnka et al, 2007).One innovative language-model-driven AAC typ-ing interface is Dasher (Ward et al, 2002), whichuses language models and arithmetic coding topresent alternative letter targets on the screen withsize relative to their likelihood given the history.Users can type by continuous motion, such as eyegaze or mouse cursor movement, targeting their cur-sor at the intended letter and moving the cursorfrom left-to-right through the interface, while itsmovements are tracked.
This is an extremely effec-tive typing interface alternative to keyboards, pro-vided the user has sufficient motor control to per-form the required systematic visual scanning.
Themost severely impaired users, such as those withlocked-in syndrome (LIS), have lost the voluntarymotor control sufficient for such an interface.Relying on extensive visual scanning, such as thatrequired in dynamically reconfiguring spelling gridsor Dasher, or requiring complex gestural feedbackfrom the user renders a typing interface difficult orimpossible to use for those with the most severe im-pairments.
Indeed, even spelling grids like the P300speller can be taxing as an interface for users.
Re-cent attempts to use the P300 speller as a typinginterface for locked-in individuals with ALS found291 A?
V  initialize A as symbol set V2 k ?
1  initialize bit position k to 13 while |A| > 1 do4 P ?
{a ?
A : a[k] = 1}5 Q?
{a ?
A : a[k] = 0}6 Highlight symbols in P7 if selected then A?
P8 else A?
Q9 k ?
k + 110 return a ?
A  Only 1 element in AFigure 2: Algorithm for binary code symbol selectionthat the number of items in the grid caused prob-lems for these patients, because of difficulty orient-ing attention to specific locations in the spelling grid(Sellers et al, 2003).
This is another illustration ofthe need to reduce the cognitive overhead of such in-terfaces.
Yet the success of classification of ERP ina simpler task for this population indicates that theP300 is a binary response mechanism of utility forthis task (Sellers and Donchin, 2006).Simpler interactions via brain-computer inter-faces (BCI) hold much promise for effective textcommunication.
Yet these simple interfaces have yetto take full advantage of language models to ease orspeed typing.
In this paper we will make use of astatic grid, or a single letter linear scanning inter-face, yet scan in a way that allows for the use ofcontextual language model probabilities when con-structing the binary code for each symbol.2.2 Binary codes for typing interfacesRow/column scanning, as outlined in the previoussection, is not the only means by which the spellinggrid in Figure 1 can be used as a binary responsetyping interface.
Rather than highlighting full rowsor full columns, arbitrary subsets of letters could behighlighted, and letter selection again driven by abinary response mechanism.
An algorithm to do thisis as follows.
Assign a unique binary code to eachsymbol in the symbol set V (letters in this case).
Foreach symbol a ?
V , there are |a| bits in the coderepresenting the letter.
Let a[k] be the kth bit of thecode for symbol a.
We will assume that no symbol?sbinary code is a prefix of another symbol?s binarycode.
Given such an assignment of binary codes tothe symbol set V , the algorithm in Figure 2 can beused to select the target symbol in a spelling grid.One key question in this paper is how to producesuch a binary code, which is how language modelscan be included in scanning.
Figure 3 shows twodifferent binary trees, which yield different binarycodes for six letters in a simple, artificial example.Huffman:1011 01 0 100000feacb d0011101110110Linear:101c01db1fea000000000100010011 001010Letter: a b c d e fProbability: 0.15 0.25 0.18 0.2 0.12 0.1Huffman bits: 3 2 3 2 3 3Linear bits: 4 1 3 2 5 5Figure 3: Two binary trees for encoding letters based onletter probabilities: (1) Huffman coding; and (2) Linearcoding via a right-branching tree (right-linear).
Expectedbits are 2.55 for Huffman and 2.89 for linear coding.Huffman coding (Huffman, 1952) builds a binarytree that minimizes the expected number of bits ac-cording to the provided distribution.
There is a lin-ear complexity algorithm for building this tree givena list of items sorted by descending probability.Another type of binary code, which we will call alinear code, provides a lot of flexibility in the kind ofinterface that it allows, relative to the other methodsmentioned above.
In this binary code, each itera-tion of the WHILE loop in the Figure 2 algorithmwould have a set P on line 4 with exactly one mem-ber.
With such a code, the spelling grid in Figure1 would highlight exactly one letter at a time forselection.
Alternately, symbols could be presentedone at a time with no grid, which we call rapid serialvisual presentation (RSVP, see Fig.7).
Linear cod-ing builds a simple right-linear tree (seen in Figure3) that preserves the sorted order of the set, puttinghigher probability symbols closer to the root of thetree, thus obtaining shorter binary codes.
Linearcoding can never produce codes with fewer expectedbits than Huffman coding, though the linear codemay reach the minimum under certain conditions.The simplicity of an interface that presents a sin-gle letter at a time may reduce user fatigue, and evenmake typing feasible for users that cannot maintainfocus on a spelling grid.
Additionally, single symbolauditory presentation would be possible, for visuallyimpaired individuals, something that is not straight-forwardly feasible with the sets of symbols that mustbe presented when using Huffman codes.2.3 Language modeling for typing interfacesThe current task is very similar to word predictionwork discussed in Section 2.1, except that the pre-30diction interface is the only means by which textis input, rather than a separate window with com-pletions being provided.
In principle, the symbolsthat are being predicted (hence typed) can be froma vocabulary that includes multiple symbol stringssuch as words.
However, a key requirement in acomposition-based typing interface is an open vo-cabulary ?
the user should be able to type any word,whether or not it is in some fixed vocabulary.
In-cluded in such a mechanism is the ability to repair:delete symbols and re-type new ones.
In contrast,a word prediction component must be accompaniedby some additional mechanism in place for typingwords not in the vocabulary.
The current problem isto use symbol prediction for that core typing inter-face, and this paper will focus on predicting singleASCII and control characters, rather than multiplecharacter strings.
The task is actually very similarto the well known Shannon game (Shannon, 1950),where text is guessed one character at a time.Character prediction is done in the Dasher andGazeTalk interfaces, as discussed in an earlier sec-tion.
There is also a letter prediction component tothe Sibyl/Sibylle interfaces (Schadle, 2004; Wand-macher et al, 2008), alongside a separate word pre-diction component.
Interestingly, the letter predic-tion component of Sibylle (Sibyletter) involves a lin-ear scan of the letters, one at a time in order of proba-bility (as determined by a 5-gram character languagemodel), rather than a row/column scanning of theP300 speller.
This approach was based on user feed-back that the row/column scanning was a much moretiring interface than the linear scan interface (Wand-macher et al, 2008), which is consistent with theresults previously discussed on the difficulty of ALSindividuals with the P300 speller interface.Language modeling for a typing interface task ofthis sort is very different from other common lan-guage modeling tasks.
This is because, at each sym-bol in the string, the already typed prefix string isgiven ?
there is no ambiguity in the prefix string,modulo subsequent repairs.
In contrast, in speechrecognition, machine translation, optical characterrecognition or T9 style text input, the actual pre-fix string is not known; rather, there is a distribu-tion over possible prefix strings, and a global in-ference procedure is required to find the best stringas a whole.
For typing, once the symbol has beenproduced and not repaired, the model predicting thenext symbol is given the true context.
This has sev-eral important ramifications for language modeling,including the availability of supervised adaptationdata and the fact that the models trained with rel-ative frequency estimation are both generative anddiscriminative.
See Roark (2009) for extensive dis-cussion of these issues.
Here we will consider n-gram language models of various orders, estimatedvia smoothed relative frequency estimation (see ?3.1).
The principal novelty in the current approachis the principled incorporation of error probabilitiesinto the binary coding approaches, and the experi-mental demonstration of how linear coding for gridsor RSVP interfaces compare to Huffman coding androw/column scanning for grids.3 Methods3.1 Character-based language modelsFor this paper, we use character n-gram models.Carpenter (2005) has an extensive comparison oflarge scale character-based language models, andwe adopt smoothing methods from that paper.
Itpresents a version of Witten-Bell smoothing (Wit-ten and Bell, 1991) with an optimized hyperparam-eter K, which is shown to be as effective as Kneser-Ney smoothing (Kneser and Ney, 1995) for higherorder n-grams.
We refer readers to that paper for de-tails on this standard n-gram language modeling ap-proach.
For the experimental results presented here,we trained unigram and 8-gram models from the NYTimes portion of the English Gigaword corpus.We performed extensive normalization of thiscorpus, detailed in Roark (2009).
We de-casedthe resulting corpus and selected sentences thatonly included characters that would appear inour 6?6 spelling grid.
Those characters are:the 26 letters of the English alphabet, the spacecharacter, a delete symbol, comma, period, doubleand single quote, dash, dollar sign, colon andsemi-colon.
We used a 42 million character subsetof this corpus for training the model.
Finally, weappended to this corpus approximately 112 thou-sand words from the CMU Pronouncing Dictionary(www.speech.cs.cmu.edu/cgi-bin/cmudict),which also contained only the symbols from thegrid.
For hyper-parameter settings, we used a 100kcharacter development set.
Our best performinghyper-parameter for the Witten-Bell smoothing wasK = 15, which is comparable to optimal settingsfound by Carpenter (2005) for 12-grams.3.2 Binary codesGiven what has been typed so far, we can use a char-acter n-gram language model to assign probabilities31Figure 4: Row/column scanning interface.to all next symbols in the symbol set V .
After sort-ing the set in order of decreasing probability, we canuse these probabilities to build binary coding treesfor the set.
Hence the binary code assigned to eachsymbol in the symbol set differs depending on whathas been typed before.
For Huffman coding, weused the algorithm from Perelmouter and Birbaumer(2000) that accounts for any probability of error infollowing a branch of the tree, and builds the optimalcoding tree even when there is non-zero probabilityof taking a branch in error.
Either linear or Huffmancodes can be built from the language model proba-bilities, and can then be used for a typing interface,using the algorithm presented in Figure 2.3.3 Scanning systemsFor these experiments, we developed an interfacefor controlled testing of typing performance undera range of scanning methods.
These include: (i)row/column scanning, both auto scan (button pressselects) and step scan (lack of button press selects);(ii) Scanning with a Huffman code, either derivedfrom a unigram language model, or from an 8-gramlanguage model; and (iii) Scanning with a linearcode, either on the 6?6 grid, or using RSVP, whichshows one symbol at a time.
Each trial involved giv-ing subjects a target phrase with instructions to typethe phrase exactly as displayed.
All errors in typingwere required to be corrected by deleting (via?)
theincorrect symbol and re-typing the correct symbol.Figure 4 shows our typing interface when config-ured for row/column scanning.
At the top of theapplication window is the target string to be typedby the subject (?we run the risk of failure?).
Belowthat is the buffer displaying what has already beentyped (?we run t?).
Spaces between words must alsobe typed ?
they are represented by the underscorecharacter in the upper left-hand corner of the grid.Spaces are treated like any other symbol in our lan-guage model ?
they must be typed, thus they are pre-Figure 5: Error in row/column scanning interface.dicted along with the other symbols.
Figure 5 showshow the display updates when an incorrect characteris typed.
The errors are highlighted in red, followedby the backarrow symbol to remind users to delete.If a row has not been selected after a pass over allrows, scanning begins again at the top.
After rowselection, column scanning commences; if a columnis not selected after three passes from left-to-rightover the columns, then row scanning re-commencesat the following row.
Hence, even if a wrong row isselected, the correct symbol can still be typed.Note that the spelling grid has been sorted in uni-gram frequency order, so that the most frequent sym-bols are in the upper left-hand corner.
This same gridis used in all grid scanning conditions, and provideslanguage modeling benefit to row/column scanning.Figure 6 shows our typing interface when config-ured for what we term Huffman scanning.
In thisscanning mode, the highlighted subset is dictated bythe Huffman code, and is not necessarily contiguous.Not requiring contiguity of highlighted symbols al-lows the coding to vary with the context, thus allow-ing use of an n-gram language model.
As far as weknow, this is the first time that contiguity of high-lighting is relaxed in a scanning interface to accom-modate Huffman coding.
Baljko and Tam (2006)used Huffman coding for a grid scanning interface,but using a unigram model and the grid layout wasselected to ensure that highlighted regions would al-ways be contiguous, thus precluding n-grammodels.In our Huffman scanning approach, when the se-lected set includes just one character, it is typed.
Aswith row/column scanning, when the wrong charac-ter is typed, the backarrow symbol must be chosento delete it.
If an error is made in selection that doesnot result in a typed character ?
i.e., if the incorrectlyselected set has more than one member ?
then weneed some mechanism for allowing the target sym-bol to still be selected, much as we have a mecha-32Figure 6: Huffman scanning interface.nism in row/column scanning for recovering if thewrong row is selected.
Section 3.4 details our novelmethod for recalculating the binary codes based onan error rate parameter.
At no point in typing is anycharacter ruled out from being selected.The grids shown in Figures 4-6 can be straightfor-wardly used with linear coding as well, by simplyhighlighting one cell at a time in descending proba-bility order.
Additionally, linear coding can be usedwith an RSVP interface, shown in Figure 7, whichdisplays one character at a time.Each interface needs a scan rate, specifying howlong to wait for a button press before advancing.
Thescan rate for each condition was set for each individ-ual during a training/calibration session (see ?4.1).3.4 Errors in Huffman and Linear scanningIn this section we briefly detail how we account forthe probability of error in scanning with Huffmanand linear codes.
The scanning interface takes a pa-rameter p, which is the probability that, when a se-lection is made, it is correct.
Thus 1?p is the proba-bility of an error.
Recall that if a selection leads to asingle symbol, then that symbol is typed.
Otherwise,if a selection leads to a set with more than one sym-bol, then all symbol probabilities (even those not inthe selected set) are updated based on the error prob-ability and scanning continues.
If a non-target (in-correct) symbol is selected, the delete (backarrow)symbol must be chosen to correct the error, afterwhich the typing interface returns to the previousposition.
Three key questions must be answered insuch an approach: (1) how are symbol probabilitiesupdated after a keystroke, to reflect the probabilityof error?
(2) how is the probability of backarrow es-timated?
and (3) when the typing interface returnsto the previous position, where does it pick up thescanning?
Here we answer all three questions.Consider the Huffman coding tree in Figure 3.
Ifthe left-branch (?1?)
is selected by the user, the prob-ability that it was intended is p versus an error withFigure 7: RSVP scanning interface.probability 1?p.
If the original probability of a sym-bol is q, then the updated probability of the symbolis pq if it starts with a ?1?
and (1?p)q if it starts witha ?0?.
After updating the scores and re-normalizingover the whole set, we can build a new binary cod-ing tree.
The user then selects a branch at the rootof the new tree.
A symbol is finally selected whenthe user selects a branch leading to a single symbol.The same approach is used with a linear coding tree.The probability of requiring the delete (backar-row) character can be calculated directly from theprobability of keystroke error ?
in fact, the probabil-ity of backarrow is exactly the probability of error1?p.
To understand why this is the case, considerthat a non-target (incorrect) symbol can be chosenaccording to the approach in the previous paragraphonly with a final keystroke error.
Any keystrokeerror that does not select a single symbol does noteliminate the target symbol, it merely re-adjusts thetarget symbol?s probability along with all other sym-bols.
Hence, no matter how many keystrokes havebeen made, the probability that a selected symbolwas not the target symbol is simply the probabilitythat the last keystroke was in error, i.e., 1?p.Finally, if backarrow is selected, the previous po-sition is revisited, and the probabilities are reset asthough no prior selection had been made.4 Empirical results4.1 Subjects and scan rate calibrationWe recruited 10 native English speakers between theages of 24 and 48 years, who had not used our typ-ing interface, are not users of scanning interfacesfor typing, and have typical motor function.
Eachsubject participated in two sessions, one for trainingand calibration of scan rates; and another for testing.We use the phrase set from MacKenzie and Souko-reff (2003) to evaluate typing performance.
Of the500 phrases in that set, 20 were randomly set asidefor testing, the other 480 available during trainingand calibration phases.
Five of the 20 evaluation33strings were used in this study.
We used an AblenetJellybean R?
button as the binary switch.
For thesetrials, to estimate error rates in modeling, we fixedp = 0.95, i.e., 5% error rate.The scan rate for row/column scanning is typi-cally different than for Huffman or linear scanning,since row/column scanning methods allow for an-ticipation: one can tell from the current highlight-ing whether the desired row or column will be high-lighted next.
For the Huffman and linear scanningapproaches that we are investigating, that is not thecase: any cell can be highlighted (or symbol dis-played) at any time, even multiple times in a row.Hence the scan rate for these methods depends moreon reaction time than row/column scanning, whereanticipation allows for faster rates.The scan rate also differs between the tworow/column scanning approaches (auto scan andstep scan), due to the differences in control neededto advance scanning with a button press versus se-lecting with a button press.
We thus ran scan ratecalibration under three conditions: row/column stepscan; row/column auto scan; and Huffman scan-ning, using a unigram language model.
The Huff-man scanning scan rate was then used for all of theHuffman and linear scanning approaches.Calibration involved two stages for each of thethree approaches, and the first stage of all three iscompleted before running the second stage, thus fa-miliarizing subjects with all interfaces prior to finalcalibration.
The first stage of calibration starts withslow scan rate (1200 ms dwell time), then speeds upthe scan rate by reducing dwell time by 200 ms whena target string is successfully typed.
Success heremeans that the string is correctly typed with less than10% error rate.
The subject gets three tries to type astring successfully at a given scan rate, after whichthey are judged to not be able to complete the taskat that rate.
In the first stage, this stops the stage forthat method and the dwell time is recorded.
In thesecond stage, calibration starts at a dwell time 500ms higher than where the subject failed in the firststage, and the dwell time decreases by 100 ms in-crements when target strings are successfully typed.When subjects cannot complete the task at a dwelltime, the dwell time then increases at 50 ms incre-ments until they can successfully type a target string.Table 1 shows the mean (and std) scan rates (dwelltime) for each condition.
Step scanning generallyhad a slower scan rate than auto scanning, and Huff-man scanning (unsurprisingly) was slowest.4.2 Testing stage and resultsIn the testing stage of the protocol, there weresix conditions: (1) row/column step scan; (2)row/column auto scan; (3) Huffman scanning withcodes derived from the unigram language model; (4)Huffman scanning with codes derived from the 8-gram language model; (5) Linear scanning on the6?6 spelling grid with codes derived from the 8-gram language model; and (6) RSVP single letterpresentation with codes derived from the 8-gramlanguage model.
The ordering of the conditions foreach subject was randomized.
In each condition, in-structions were given (identical to instructions dur-ing calibration phase), and the subjects typed prac-tice phrases until they successfully reached error ratecriterion performance (10% error rate or lower), atwhich point they were given the test phrases to type.Recall that the task is to type the stimulus phraseexactly as presented, hence the task is not com-plete until the phrase has been correctly typed.
Toavoid non-termination scenarios ?
e.g., the subjectdoes not recognize that an error has occurred, whatthe error is, or simply cannot recover from cascad-ing errors ?
the trial is stopped if the total errorsin typing the target phrase reach 20, and the sub-ject is presented with the same target phrase to typeagain from the beginning, i.e., the example is re-set.
Only 2 subjects in the experiment had a phrasereset in this way (just one phrase each), both inrow/column scanning conditions.
Of course, thetime and keystrokes spent typing prior to reset areincluded in the statistics of the condition.Table 1 shows the mean (and std) of several mea-sures for the 10 subjects.
Speed is reported in char-acters per minute.
Bits per character representsthe number of keypress and non-keypress (timeout)events that were used to type the symbol.
Note thatbits per character does not correlate perfectly withspeed, since a non-keypress bit due to a timeouttakes the full dwell time, while the time for a key-press event may be less than that full time.
For anygiven symbol the bits may involve making an error,followed by deleting the erroneous symbol and re-typing the correct symbol.
Alternately, the subjectmay scan pass the target symbol, but still return totype it correctly, resulting in extra keystrokes, i.e., alonger binary code than optimal.
In addition to themean and standard deviation of bits per character,we present the optimal could be achieved with eachmethod.
Finally we characterize the errors that aremade by subjects by the error rate, which is the num-34Scan rate (ms) Speed (cpm) Bits per character Error rate Long code rateScanning condition mean (std) mean (std) mean (std) opt.
mean (std) mean (std)row/column step scan 425 (116) 20.7 (3.6) 8.5 (2.6) 4.5 6.3 (5.1) 29.9 (19.0)auto scan 310 (70) 19.1 (2.2) 8.4 (1.2) 4.5 5.4 (2.8) 33.8 (11.5)Huffman unigram 475 (68) 12.5 (2.3) 8.4 (1.9) 4.4 4.4 (2.2) 39.2 (13.5)8-gram 475 (68) 23.4 (3.7) 4.3 (1.1) 2.6 4.1 (2.2) 19.3 (14.2)Linear grid 8-gram 475 (68) 23.2 (2.1) 4.2 (0.7) 3.4 2.4 (1.5) 5.0 (4.1)RSVP 8-gram 475 (68) 20.3 (5.1) 6.1 (2.6) 3.4 7.7 (5.4) 5.2 (4.0)Table 1: Typing results for 10 users on 5 test strings (total 31 words, 145 characters) under six conditions.ber of incorrect symbols typed divided by the totalsymbols typed.
The long code rate is the percent-age of correctly typed symbols for which a longerthan optimal code was used to type the symbol, bymaking an erroneous selection that does not result intyping the wrong symbol.We also included a short survey, using a Likertscale for responses, and mean scores are shown inTable 2 for four questions: 1) I was fatigued by theend of the trial; 2) I was stressed by the end of thetrial; 3) I liked this trial; and 4) I was frustrated bythis trial.
The responses showed a consistent prefer-ence for Huffman and linear grid conditions with an8-gram language model over the other conditions.Survey Row/Column Huffman LinearQuestion step auto 1-grm 8-grm grid RSVPFatigued 3.2 2.4 3.6 2.0 2.4 2.8Stressed 2.7 2.4 2.7 1.5 1.8 2.6Liked it 2.2 3.3 2.3 4.2 3.8 3.2Frustrated 3.2 1.7 3.1 1.7 1.7 2.3Table 2: Mean Likert scores to survey questions(5 = strongly agree; 1 = strongly disagree)4.3 Discussion of resultsWhile this is a preliminary study of just 10 sub-jects, several things stand out from the results.
First,comparing the three methods using just unigram fre-quencies to inform scanning (row/column and Huff-man unigram), we can see that Huffman unigramscanning is significantly slower than the other two,mainly due to a slower scan rate with no real im-provement in bits per character (real or optimal).
Allthree methods have a high rate of longer than opti-mal codes, leading to nearly double the bits per char-acter that would optimally be required.Next, with the use of the 8-gram language modelin Huffman scanning, both the optimal bits per char-acter and the difference between real and optimal arereduced, leading to nearly double the speed.
Inter-estingly, use of the linear code on the grid leads tofewer bits per character than Huffman scanning, de-spite nearly 1 bit increase in optimal bits per charac-ter, due to a decrease in error rate and a very largedecrease in long code rate.
We speculate that this isbecause highlighting a single cell at a time draws theeye to that cell, making visual scanning easier.Finally, despite using the same model, RSVP isfound to be slightly slower than the Huffman 8-gram or Linear grid conditions, though commensu-rate with the row/column scanning, mainly due to anincrease in error rate.
Monitoring a single cell, rec-ognizing symbol identity and pressing the switch isapparently somewhat harder than finding the symbolon a grid and waiting for the cell to light up.5 Summary and future directionsWe have presented methods for including languagemodeling in simple scanning interfaces for typing,and evaluated performance of novice subjects withtypical motor control.
We found that language mod-eling can make a very large difference in the us-ability of the Huffman scanning condition.
We alsofound that, despite losing bits to optimal Huffmancoding, linear coding leads to commensurate typ-ing speed versus Huffman coding presumably dueto lower cognitive overhead of scanning and thusfewer mistakes.
Finally, we found that RSVP wassomewhat slower than grid scanning with the samelanguage model and code.This research is part of a program to make thesimplest scanning approaches as efficient as possi-ble, so as to facilitate the use of binary switches forindividuals with the most severe impairments, in-cluding ERP for locked-in subjects.
While our sub-jects in this study have shown slightly better perfor-mance using a grid versus RSVP, these individualshave no problem with visual scanning or fixationon relatively small cells in the grid.
It is encourag-ing that subjects can achieve nearly the same perfor-mance with an interface that simply displays an op-tion and requests a yes or a no.
We intend to run thisstudy with subjects with impairment, and are incor-porating the interfaces with an ERP detection systemfor use as a brain-computer interface.35AcknowledgmentsThis research was supported in part by NIH Grant#1R01DC009834-01 and NSF Grant #IIS-0447214.Any opinions, findings, conclusions or recommen-dations expressed in this publication are those of theauthors and do not necessarily reflect the views ofthe NSF or NIH.ReferencesD.
Anson, P. Moist, M. Przywars, H. Wells, H. Saylor,and H. Maxime.
2004.
The effects of word com-pletion and word prediction on typing rates using on-screen keyboards.
Assistive Technology, 18(2):146?154.G.
Baletsa, R. Foulds, and W. Crochetiere.
1976.
Designparameters of an intelligent communication device.
InProceedings of the 29th Annual Conference on Engi-neering in Medicine and Biology, page 371.M.
Baljko and A. Tam.
2006.
Indirect text entry usingone or two keys.
In Proceedings of the Eigth Inter-national ACM Conference on Assistive Technologies(ASSETS), pages 18?25.B.
Carpenter.
2005.
Scaling high-order character lan-guage models to gigabytes.
In Proceedings of the ACLWorkshop on Software, pages 86?99.J.J.
Darragh, I.H.
Witten, and M.L.
James.
1990.
Thereactive keyboard: A predictive typing aid.
Computer,23(11):41?49.L.A.
Farwell and E. Donchin.
1988.
Talking off thetop of your head: toward a mental prosthesis utiliz-ing event-related brain potentials.
Electroenceph Clin.Neurophysiol., 70:510?523.J.P.
Hansen, A.S. Johansen, D.W. Hansen, K. Itoh, andS.
Mashino.
2003.
Language technology in a pre-dictive, restricted on-screen keyboard with ambiguouslayout for severely disabled people.
In Proceedings ofEACL Workshop on Language Modeling for Text EntryMethods.D.A.
Huffman.
1952.
A method for the construction ofminimum redundancy codes.
In Proceedings of theIRE, volume 40(9), pages 1098?1101.R.
Kneser and H. Ney.
1995.
Improved backing-off form-gram language modeling.
In Proceedings of theIEEE International Conference on Acoustics, Speech,and Signal Processing (ICASSP), pages 181?184.G.W.
Lesher, B.J.
Moulton, and D.J.
Higginbotham.1998.
Techniques for augmenting scanning commu-nication.
Augmentative and Alternative Communica-tion, 14:81?101.J.
Li and G. Hirst.
2005.
Semantic knowledge in wordcompletion.
In Proceedings of the 7th InternationalACM Conference on Computers and Accessibility.I.S.
MacKenzie and R.W.
Soukoreff.
2003.
Phrase setsfor evaluating text entry techniques.
In Proceedings ofthe ACM Conference on Human Factors in ComputingSystems (CHI), pages 754?755.J.
Perelmouter and N. Birbaumer.
2000.
A binaryspelling interface with random errors.
IEEE Transac-tions on Rehabilitation Engineering, 8(2):227?232.B.
Roark.
2009.
Open vocabulary language modelingfor binary response typing interfaces.
TechnicalReport #CSLU-09-001, Center for Spoken LanguageProcessing, Oregon Health & Science University.cslu.ogi.edu/publications/ps/roark09.pdf.I.
Schadle.
2004.
Sibyl: AAC system using NLP tech-niques.
In Proceedings of the 9th International Con-ference on Computers Helping People with Specialneeds (ICCHP), pages 1109?1015.E.W.
Sellers and E. Donchin.
2006.
A p300-based brain-computer interface: initial tests by als patients.
Clini-cal Neuropsysiology, 117:538?548.E.W.
Sellers, G. Schalk, and E. Donchin.
2003.
Thep300 as a typing tool: tests of brain-computer interfacewith an als patient.
Psychophysiology, 40:77.C.E.
Shannon.
1950.
Prediction and entropy of printedEnglish.
Bell System Technical Journal, 30:50?64.K.
Trnka, D. Yarrington, K.F.
McCoy, and C. Pennington.2006.
Topic modeling in fringe word prediction forAAC.
In Proceedings of the International Conferenceon Intelligent User Interfaces, pages 276?278.K.
Trnka, D. Yarrington, J. McCaw, K.F.
McCoy, andC.
Pennington.
2007.
The effects of word predic-tion on communication rate for AAC.
In Proceed-ings of HLT-NAACL; Companion Volume, Short Pa-pers, pages 173?176.H.
Trost, J. Matiasek, and M. Baroni.
2005.
The lan-guage component of the FASTY text prediction sys-tem.
Applied Artificial Intelligence, 19(8):743?781.T.
Wandmacher and J.Y.
Antoine.
2007.
Methods to in-tegrate a language model with semantic informationfor a word prediction component.
In Proceedings ofthe Conference on Empirical Methods in Natural Lan-guage Processing (EMNLP), pages 506?513.T.
Wandmacher, J.Y.
Antoine, F. Poirier, and J.P. De-parte.
2008.
Sibylle, an assistive communication sys-tem adapting to the context and its user.
ACM Transac-tions on Accessible Computing (TACCESS), 1(1):6:1?30.D.J.
Ward, A.F.
Blackwell, and D.J.C.
MacKay.
2002.DASHER ?
a data entry interface using continuousgestures and language models.
Human-Computer In-teraction, 17(2-3):199?228.I.H.
Witten and T.C.
Bell.
1991.
The zero-frequencyproblem: Estimating the probabilities of novel eventsin adaptive text compression.
IEEE Transactions onInformation Theory, 37(4):1085?1094.36
