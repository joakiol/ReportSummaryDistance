Processing Self Corrections in a speech to speech systemJ S rg  Sp i lker ,  Mar t in  K la rner ,  G f in ther  G6rzUniversity of Er langen-Nuremberg - Computer  Science Institute,IMMD 8 - Artificial Intell igence,Am Weichselgarten 9, 91058 Er langen-  Tennenlohe, Germany{ spilker, klarner, goerz}~immd8, inf ormat ik.
uni-erlangen, deAbstractSpeech repairs occur often in spontaneous spo-ken dialogues.
The ability to detect and cor-rect those repairs is necessary for any spokenlanguage system.
We present a framework todetect and correct speech repairs where all tel-evant levels of information, i.e., acoustics, lexis,syntax and semantics can be integrated.
Thebasic idea is to reduce the search space for re-pairs as soon as possible by cascading filtersthat involve more and more features.
At first anacoustic module generates hypotheses about theexistence of a repair.
Second a stochastic modelsuggests a correction for every hypothesis.
Wellscored corrections are inserted as new paths inthe word lattice.
Finally a lattice parser decideson accepting the repair.1 I n t roduct ionSpontaneous peech is disfluent.
In contrastto read speech the sentences aren't perfectlyplanned before they are uttered.
Speakers of-ten modify their plans while they speak.
Thisresults in pauses, word repetitions or changes,word fragments and restarts.
Current mlto-rustic speech understanding systems performvery well in small domains with restrictedspeech but have great difficulties to deal withsuch disfluencies.
A system that copes withthese self corrections (=repairs) must recognizethe spoken words and identify the repair to getthe intended meaning of an utterance.
To char-acterize a repair it is commonly segmented intothe following four parts (el.
fig.i):?
reparandum: the "wrong" part of the ut-terance?
interruption point (IP): marker at the endof the reparandum?
editing term: special phrases, which indi-cate a repair like "well", "I mean" or filledpauses such as "uhln '~, "uh"?
reparans: the correction of the reparandumon Thursday lcannot ?
no Ican meet "ah afteronc// \ - / ""Rct)arandmn Interruption- Editing Rcparanspoint TermFigure 1: Example of a self repairOnly if reparandum and editing term areknown, the utterance can be analyzed in theright way.
It remains an open question whetherthe two terms should be deleted before a seman-tic analysis as suggested sometimes in the liter-ature 1.
If both terms are marked it is a straight-forward preprocessing step to delete reparan-dum and editing term.
In the Verbmobil 2 cor-pus, a corpus dealing with appointment schedul-ing a.nd tr~vel planning, nearly 21% of all turnscontain at least one repair.
As a consequence aspeech understanding system thai; cannot han-dle repairs will lose perforlnance on these turns.Even if repairs are defined by syntactic andsemantic well-formedness (Levelt, 1983) we ob-serve that most of them are local phenomena..At this point we have to differentiate betweenrestarts and other repairs a (modification re-pairs).
Modification repairs have a strong corre-spondence between reparandum and reparans,1In most cases a reparaudum could be deleted with-out any loss of information.
But, for exmnple, if it in-troduces an object which is referred to later, a deletionis not appropriate.>l?his work is part of the VERBMOBIL  project andwas funded by the German Federal Ministry for Researchand Technology (BMBF) in the framework of the Verb-mobil Project under Grant BMBF 01 IV 701 V0.
Theresponsibility for the contents of this study lies with theauthors.SOften a third kind of repair is defined: "abridgedrepairs".
These repairs consist solely of an editing termand are not repairs in our sense.1116whereas restarts a.re less structured.
In our be-lieve there is no nted for a. complete syntacticam@sis to detect ~md correct most modificationrepairs.
Thus, in wh~tt follows, we will concen-tra.te on this ldnd of repa.ir.There are two major arguments to processrepairs before t)arsing.
Primarily spontaneousspeech is not always syntactically well-formedeven in the absence of sell' corrections.
Sec-ond (Meta-) rules increase the pa.rsers' searchspace.
This is perhaps acceptable for transliter-ated speech but not for speech recognizers out-put like l~ttices because they represent millionsof possible spoken utterances.
\[n addition, sys-tems whk;h a.re not based on a. deep syntacticand semantic amdysis e .g .
statistical dialogact prediction -- require a repa.ir processing stepto resolve contr~dictions like the one in tit.
1.We propose all algorithm for word latticesth,~t divides repa.ir detection a.nd correction inthree steps (of.
fig.
2) l"irst, ~r trigger indi-cates potential 1Ps.
Second, a sl;ochasl, ic modeltries to lind an appropria.te repair h)r each IP byguessing 1,he mosl; l)robable segmentation, qbaccomplish this, repair processing is seen as astatistical machine translation problem wherethe repa.randum is a transl~tion of the reparans.For every repair found, a pa.th representing thespcaker.'
intended word sequence is insertedinto the la.ttice.
In the last step, a lattice parserselects the best pa.th.tlll 'llllll'Sday I ?iIIlllt)l IlO \[ CIIII lllCel "ah tiller t)llCgpeec\] l  I't'cOgtllZCiwllnl Io Slly ICOll i i1  ilOll +l'htusday 1 C;lllllOI lit) \] t'311 IIIL'L~I 'liIh alter  111112loca l  word  based  scope  dc lec t io l l  o f  lattice ed i t ing  1o represent  res t l l tl{cl)ttl' i l l/dtll l l \ ]~.c\])alans !f1 ?-ilJ\]?
wll iii \[o say icoll ill , iion  "\[\]lttlSdlly t'lllllK~l t'atI1 litter I / "lib ' ' tll'\[Cl "t t)llC t Jse lec l ion  by1 l ingu is t i c  a l la lys l ss011 "l'htll'gday \]C/Ill nlcel "till :tiler olleFigure 2: An architecture for repa.ir processing2 Repa i r  qh ' iggersBecause it is impossible for;t  rea.l time speechsystem to check for every word whether it canbe part of a repair, we use triggers which indi-cate the potential existence of a repa.ir.
Thesetriggers nlllst be immediately detectable for ev-ery word in the lattice.
Currently we art usingtwo different ldnd of triggers4:\]..Acoustic/prosodic cuts: Spe~kers mark the117 in many cases by prosodic signals like1)auses, hesitations, etc.
A prosodic classi-tier 5 determines for every word the proba-bi l i ty of  an IP following.
If it is above a cer-t~dn l;hreshold, the trigger becomes active.For a detailed description of the acousticaspects ee (Batliner eL al., 1998).Word Dagments are a very strong repairindicator.
Unfortunately, no speech recog-nizer is able to detect word fl:agmtnts todate.
But there are some interesting ap-proaches to detect words which are not inthe recognizers vocabulary (Klakow et al,1999).
A word fi'agment is normally an un-known word and we hope that it can btdistinguished from unfra.gmented unknownwords by the prosodic classifier.
So, cur-rently this is a hypol;hetical trigger.
Wewill elaborate on it in the evaluation sec-tion (cf.
sect.
5) to show the impact of thistrigger.If a trigger is active, a. sea, rch for an acceptablesegmentation into rel)arandum , editing terma.nd reparans is initia.ted.3 Scope Detect ionAs mentioned in the introduction reDfir seg-mentation is based mainly on a stochastic trans-la.tion modtl, l~el'ore we explain it in detail wegive a short introduction to statistical machinetranslation ?.
The fundalnentaJ idea.
is the as-sumption that a given sentence S in a sourcelanguage (e.g.
English) can be translated in any^sentence 5/' in a l;~rgel; I,~nguage (e.g.
German).To every pair (5', ~/') a probability is assignedwhich reflects the likelihood that a tra.nsl~torwho sees S will produce \]' as the translation.The sta.tistical machine translation problem is4 Other triggers cal, be added as well.
(Stolcke ct al.,1999) for example integrate prosodic cues and an ex-tended language model in a speech recognizer to detectIPs.SThe classifier is developed by tile speech group ofthe IMM1) 5.
Special thanks to Anton Batliner, RichardIluber and Volker Warnke.~A more detailed introduction is given by (Brown el,al., 1990)I 117formul;~ted as:5~' = argmaXTI ' (T lS )This is reformulated by Bayes' law for a bettersearch space reduction, but we are only inter-ested in the conditional probability P(TIS ).
Forfurther processing steps we have to introducethe concept of alignment (Brown et al, 1990).Let S be the word sequence S1, S 2 .
.
.
.
5,l ~ SIand T = ~,T2.
.
.Tm ~ 77\] ~.
We can link aword in T to a word in S. This reflects theassumption that the word in T is translatedfrom the word in S. \]?or example, if S is "OnThursday" and T is "Am l)onnerstag" "Am"can be linked to "On" but also to "Thursday".If each word in T is linked to exactly one wordin ,S' these links can be described by a vectora~ '~ = a l .
.
.
a,~ with ai E O...l. If the word 51~.is linked to Si then aj = i.
If it is not connectedto any word in S then aj = 0.
Such a vectoris called an alignment a. P(T\],5,) can now beexpressed by'(TIS) = al,5,) (2)a is alignmentWithout any further assumptions we can inferthe tbllowing:) 1 * ( -45) ,H \])(ajl(t'{-l' r j - l '  ?'"'
'5,) ~J--' Tii-', m, ,5,) (3)Now we return to self corrections.
How can thisframework help to detect the segments of a re-pair?
Assulne we have a lattice l)~th where thereparandn.
(m)) a,d the reparans( S) aregiven, then (RS, \]{D) can be seen as a. transla-tion pair and P(RD\]R,5,) can be expressed ex-actly the same way as in equation (2).
Hencewe have a method to score (ITS, P~D) pairs.. Butthe triggers only indicate the interruption point,not the complete segmentation.
Let us firstlook at editing terms.
We assume them to bea closed list of short phrases.
Thus if an entryof the editing term list; is found after an 1P, thecorresponding words are skipped.
Any subse-quence of words befbre/after the IP conld be thereparanduln/reparans.
Because turns ca.n h~wean arbitrary length it is impossible to computeP(I-~D\]IL5,) for every (RS, H.D) pair.
Bug thisis not necessary at all, if repairs are consideredas local phenomena.
We restrict our search to awindow of four words before and after the IP.
Acorpus analysis showed that 98% of all repairsare within this window.
Now we only have tocompute probabilities for 42 difl'erent pairs.
Ifthe probability of a (RS, RD) pair is above acertain threshold, the segmentation is acceptedas a repair.3.1 Parameter  Est imationThe conditional probabilities in equation (3)cannot be estimated reliably fi'om any corpusof realistic size, because there are too many p~>rameters.
For example both P in the productdepend on the complete reparans R,5,.
There-fore we simplify the probabilities by assumingthat m depends only on l, a.i only on j ,m andl and finally RDj on 1L5,,.j.
So equation (3) be-comesP(Z D, siZeS) :\]-I (4)j=lThese probabilffies can be directly trained fi'orna nlannally annotated corl)ns , where all repairsare labeled with begin, end, liP and editing termand for each l'eparandnnl the words are linkedto the corresponding words in the respectivereparalls.
All distributions are smoothed by asimple back-off method (Katz, 1987) to avoidzero probabilities with the exception that theword replacement probability P(I~I)jIILS,j) issmoothed in a more sophisticated way.3.2 SmoothingEven it" we reduce the number of parameters forthe word replacement probability by the sim-plifications mentioned above there are a lot ofparameters left.
With a vocabulary size of 2500words, 25002 paralneters have to be estimatedfor P(I~DjllL5,~j).
The corpus 7 contains 3200repairs fi'om which we extra.ct about 5000 wordlinks.
So most of the possible word links neveroccur in the corpus.
Some of theln are morelikely to occur in a repair than others.
For ex-ample, the replacement of "Thursday" by "\]M-clay'" is supposed to be more likely than by "eat'ing", even if both replacements are not in thetraining corpus.
Of course, this is related to7~110006urns with ~240000 words1118the fact that a, repair is a syntactic and/or se-mantic anomaly.
We make nse of it by a.ddingtwo additional knowledge sources to our model.Minimal syntactic information is given by part-o f  speech (POS) tags and POS sequences, se-mmltic information is given by semantic wordclasses.
Ilence the input is not merely a se-quence of words but a sequence of triples.
Eachtriple has three slots (word, POS tag, seman-tic class).
In the next section we will describehow we ol)tain these two information pieces \[brevery word in the lattice.
With this additionalinforma.tion, P(RDjI1LS',~ j) probability could 1)esmoothed by linea.r interpolation of word, POSand semantic la.ss replacement \])robabilities.=n,, l '(Word( l .Dj )ll4r o.rd( n,S'..j) )+/3 ,+with a '+\ [3+7=1.l'Vord(IM):i ) is the not~tion tbr 1;11(: selector ofthe word slot of the triple a,t position j .4 Integration with LatticeProcessingWe ca, ll llOW del ;e( ; t  a ,nd cor rec t  a, repa,ir, given asentence a.nnotated with I)()S tag;s an(I seman-1;ic classes, l~tll, how ca.n we ('onsl;rucl, such a.sequence, from a wor(l la.tl;ic(<?
Integrating thentodel in a lattice algoril;h m requires three steps:?
mapping the word la?tice to a. tag lattice?
triggering IPs and extra.cting the possiblerel)ar;md um/reparans l):~irs?
intr<)ducing new paths to represent tileplausible repa.ransThe tag lattice constrnction is adapted from(Samuelsson, 11997).
For every word edge andevery denoted POS tag a corresponding tagedge is crea,ted and tim resulting prol)abilityis determined.
\[I' a tag edge already exists,tile probabilities of both edges are merged.The original words are stored together withtheir unique semantic lass in a associated list.Paths through the tag graph a.re scored by aIX)S-trigram.
If a trigger is active, all pathsthrough the word before tim ll' need to be testedwhether an acceptable rel)air segmentation ex-ists.
Since the scope model takes at most \['ourwords for reparandum a.nd rel)a.ra.ns in accountit is sufficient to expand only partial paths.l);ach of these partial paths is then processed bythe scope model.
To reduce the se~rch space,paths with a low score can be pruned.Repair processing is integrated into the Verb-mobil system as a. filter process between speechrecognition a.nd syntactic analysis.
This en-forces a rep~fir representation that ca.n be into-grated into a lattice.
It is not possible to lna.rkonly the words with some additional informa-tion, because a rel)air is a phenomenon that (le-pends on a path.
Imagine that the system hasdetected ~ repair on ~ certain path in the bttticeand marked all words by their top,fir function.Then a search process (e.g.
the parser) selects adifferent D~th which shares only the words of therepa.randum.
But these words are no reparan-dum for this path.
A solution is to introduce anew path in the.
lattice where reI)arandum a.ndediting terms a.re deleted.
As we said betbre, wedo not want l;o delete these segments, so theyare stored in a special slot of 1;11o first word ofthe reparans.
The original path can now 1)e re-construct if necessary.To ensure that these new I)aths are coml)~>ra.ble to other paths we score the reparandumthe same wa.y the l)arser does, and add the re-suiting wdue to the \[irst wor(l of the reparaits.As a result, l>oth the original path a.nd the.
onewil,h the repair get the sa.me score excel)t oneword tra.nsition.
The (proba.bly bad) transitionin l, he original path from the last word o\[" therei)arandtnn to the first word of 1;he repa.rans isrel)laeed by a.
(proba.bly goo(t) transition Fromthe repa.ran(hnn~s onset to the rel>arans.
\Vetake the lattice in fig.
2 to give an example.The SCOl)e mo(M has ma.rked " l  ca.nnot" as thereparandum, "no" as an editing term, and "lca.n" as the rel)arans.
We sum tip the acousticscores of "1", "can" and "no".
Then we add themaximnm language model scores for the tra.n-sition to "1", to "can" given "I", and to "no"given 'T' and "can".
This score is ~(I(le(1 as anoffset to the acoustic score of the second "1".5 Resu l ts  and  Fur ther  WorkDue to the different trigger situations we per-formed two tests: One where we use onlyacoustic triggers and ~mother where the exis-tence of a perfect word fr~gment detector is as-sume(1.
The input were unsegmented translit-era.ted utterance to exclude intluences a word1 1 19recognizer.
We restrict the processing time ona SUN/ULTI{A 300MIIZ to 10 seconds.
Theparser was simulated by a word trigram.
Train-ing and testing were done on two separatedparts of the German part of the Verbmobil cor-pus (12558 turns training / 1737 turns test).Detection Correct scopeRecall Precision Recall PrecisionTest 1 49% 70% 47 % 70%Test 2 71% 85% 62% 83%A direct comparison to other groups is ratherdifficult due to very different corpora, eval-uation conditions and goals.
(Nakatani andHirschberg, 1.993) suggest a acoustic/prosodicdetector to identify IPs but don't discuss theproblem of finding the correct segmentation idepth.
Also their results are obtained on acorpus where every utterance contains at leastone repair.
(Shriberg, 1994) also addresses theacoustic aspects of repairs.
Parsing approacheslike in (Bear et al, 1992; Itindle, 1983; Core andSchubert, 1999) must be proved to work withlattices rather than transliterated text.
An al-gorithm which is inherently capable of latticeprocessing is prot)osed by Heeman (Hem-nan,1997).
He redefines the word recognition prob-lem to identify the best sequence of words, cor-responding POS tags and special rel)air tags.He reports a recall rate of 81% and a precisionof 83% for detection and 78%/80% tbr correc-tion.
The test settings are nearly the same astest 2.
Unibrtunately, nothing is said about theprocessing time of his module.We have presented an approach to score po-tential reparandum/reparans pairs with a rela-tive simple scope model.
Our results show thatrepair processing with statistical methods andwithout deep syntactic knowledge is a promis-ing approach at least for modification repairs.Within this fi'alnework more sophisticated scopemodels can be evaluated.
A system integrationas a filter process is described.
Mapping theword lattice to a POS tag lattice is not optimal,because word inlbrmation is lost in the searchtbr partial paths.
We plan to implement a com-bined combined POS/word tagger.ReferencesA.
Batliner, R. Kompe, A. Kiettling, M. Mast,H.
Niemann, and F,.
NSth.
1998.
M =syntax + prosody: A syntactic-prosodic la-belling schema for large spontaneous speechdatabases.
Epeech Communication, 25:193-222.J.
Bear, J. Dowding, and E. Shriberg.
1992.Integrating multiple knowledge sources \["ordetection and correction of repairs ill hu-man computer dialogs.
In Proc.
ACL, pages56-63, University of Delaware, Newark,Delaware.P.
F. Brown, J. Cocke, S. A. Della Pietra, V. J.Della Pietr~, F. Jelinek, J. D. Lafferty, R. L.Mercer, and P. S. Roossin.
1990.
A sta.tisti-cal approach to machine translation.
Compu-tational Linguistics, 16(2):79-85, June.M.
G. Core and K. Schubert.
1999.
Speech re-pairs: A parsing perspective.
Satellite meet-ing ICPIIS 99.P.
A. I-Iceman.
1997.
Speech Repairs, Into-nation Boundaries and Discourse Markers:Modeling Epeakcrs' Utterances in ,5'pokcn Di-alog.
Ph.l).
thesis, University of Rochester.D.
Hindle.
1983.
Deterministic parsing of syn-tactic nontluencies.
In Proc.
ACL, MIT,Cambridge, Massachusetts.S.
M. Katz.
1987.
Estimation of probabilitiesfrom sparse data for tile language model con>ponent of a speech recognizer.
7)'ansactionon Acoustics, ,5'pcech and ,5'ignal 1)rocessing,ASSl'-35, March.ill).
Klakow, G Rose, and X. Aubert.
1999.OOV-Detection in Large Vocabulary Sys-tem Using Automatically Defined Word-Fragments as Fillers.
In EUR.OSPEECII '99,volume 1, pages 4:9-52, Budapest.W.
Levelt.
1983.
Monitoring and self-repair inspeech.
Cognition, 14:41-104.C.
Naka.tani and a. tlirschberg.
1993.
A speech-tirst model for repair detection and correc-tion.
In P,vc.
ACL, Ohio State University,Cohmbus, Ohio.C.
Samuelsson.
1997.
A left-to-right tagger forword graphs.
In Proc.
of the 5th Inter'nationalworkshop on Parsing technologies, pages 171-178, Bosten, Massachusetts.E.
E. Shriberg.
1994.
Preliminaries to a Theoryof Epeech Disflucncics.
Ph.D. thesis, Univer-sity of California.A.
Stolcke, E. Shriberg, D. Hakkani-Tur, andG.
Tur.
1999.
Modeling the prosody of hid-den events for improved word recognition.
InEUROS'PEECII '99, volume 1, pages 307-310, Budapest.1120
