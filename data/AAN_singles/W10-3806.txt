Proceedings of SSST-4, Fourth Workshop on Syntax and Structure in Statistical Translation, pages 43?51,COLING 2010, Beijing, August 2010.Seeding Statistical Machine Translation with Translation MemoryOutput through Tree-Based Structural AlignmentVentsislav Zhechev Josef van GenabithEuroMatrixPlus, CNGLSchool of Computing, Dublin City UniversityEuroMatrixPlus, CNGLSchool of Computing, Dublin City Universitycontact@VentsislavZhechev.eu josef@computing.dcu.ieAbstractWith the steadily increasing demand forhigh-quality translation, the localisationindustry is constantly searching for tech-nologies that would increase translatorthroughput, with the current focus on theuse of high-quality Statistical MachineTranslation (SMT) as a supplement to theestablished Translation Memory (TM)technology.
In this paper we present anovel modular approach that utilisesstate-of-the-art sub-tree alignment to pickout pre-translated segments from a TMmatch and seed with them an SMT sys-tem to produce a final translation.
Weshow that the presented system can out-perform pure SMT when a good TMmatch is found.
It can also be used in aComputer-Aided Translation (CAT) envi-ronment to present almost perfect transla-tions to the human user with markuphighlighting the segments of the transla-tion that need to be checked manually forcorrectness.1.
IntroductionAs the world becomes increasingly intercon-nected, the major trend is to try to deliver ideasand products to the widest audience possible.This requires the localisation of products for asmany countries and cultures as possible, withtranslation being one of the main parts of the lo-calisation process.
Because of this, the amount ofdata that needs professional high-quality transla-tion is continuing to increase well beyond thecapacity of the world?s human translators.Thus, current efforts in the localisation indus-try are mostly directed at the reduction of theamount of data that needs to be translated fromscratch by hand.
Such efforts mainly include theuse of Translation Memory (TM) systems, whereearlier translations are stored in a database andoffered as suggestions when new data needs tobe translated.
As TM systems were originallylimited to providing translations only for (al-most) exact matches of the new data, the integra-tion of Machine Translation (MT) techniques isseen as the only feasible development that hasthe potential to significantly reduce the amountof manual translation required.At the same time, the use of SMT is frownedupon by the users of CAT tools as they still donot trust the quality of the SMT output.
There aretwo main reasons for that.
First, currently there isno reliable way to automatically ascertain thequality of SMT-generated translations, so that theuser could at a glance make a judgement as to theamount of effort that might be needed to post-edit the suggested translation (Simard and Isa-belle, 2009).
Not having such automatic qualitymetrics also has the side effect of it being impos-sible for a Translation-Services Provider (TSP)company to reliably determine in advance theincrease in translator productivity due to the useof MT and to adjust their resources-allocationand cost models correspondingly.The second major problem for users is that SMT-generated translations are as a rule only obtainedfor cases where the TM system could not producea good-enough translation (cf.
Heyn, 1996).
Giventhat the SMT system used is usually trained onlyon the data available in the TM, expectedly it alsohas few examples from which to construct thetranslation, thus producing low quality output.43In this paper, we combine a TM, SMT and anautomatic Sub-Tree Alignment (STA) backendsin a single integrated tool.
When a new sentencethat needs to be translated is supplied, first aFuzzy-Match Score (FMS ?
see Section 2.2) isobtained from the TM backend, together with thesuggested matching sentence and its translation.For sentences that receive a reasonably highFMS, the STA backend is used to find the corre-spondences between the input sentence and theTM-suggested translation, marking up the partsof the input that are correctly translated by theTM.
The SMT backend is then employed to ob-tain the final translation from the marked-up in-put sentence.
In this way we expect to achieve abetter result compared to using pure SMT.In Section 2, we present the technical detailsof the design of our system, together with moti-vation for the particular design choices.
Section 3details the experimental setup and the data setused for the evaluation results in Section 4.
Wepresent improvements that we plan to investigatein further work in Section 5, and provide con-cluding remarks in Section 6.2.
System FrameworkWe present a system that uses a TM-match topre-translate parts of the input sentence andguide an SMT system to the generation of ahigher-quality translation.2.1.
Related ApproachesWe are not aware of any published researchwhere TM output is used to improve the per-formance of an SMT system in a manner similarto the system presented in this paper.Most closely related to our approach are thesystems by Bi?ici and Dymetman (2008) andSimard and Isabelle (2009), where the authorsuse the TM output to extract new phrase pairsthat supplement the SMT phrase table.
Such anapproach, however, does not guarantee that theSMT system will select the TM-motivatedphrases even if a heavy bias is applied to them.Another related system is presented in (Smithand Clark, 2009).
Here the authors use a syntax-based EBMT system to pre-translate and mark-up parts of the input sentence and then supplythis marked-up input to an SMT system.
Thisdiffers to our system in two ways.
First, Smithand Clark use EMBT techniques to obtain partialtranslations of the input from the complete ex-ample base, while we are only looking at the bestTM match for the given input.
Second, the authorsuse dependency structures for EMBT matching,while we employ phrase-based structures.2.2.
Translation Memory BackendAlthough the intention is to use a full-scale TMsystem as the translation memory backend, tohave complete control over the process for thisinitial research we decided to build a simple pro-totype TM backend ourselves.We employ a database setup using the Post-greSQL v.8.4.31relational database management(RDBM) system.
The segment pairs from a givenTM are stored in this database and assignedunique IDs for further reference.
When a newsentence is supplied for translation, the databaseis searched for (near) matches, using an FMSbased on normalised character-level Levenshteinedit distance (Levenshtein, 1965).Thus for each input sentence, from the data-base we obtain the matching segment with thehighest FMS, its translation and the score itself.2.3.
Sub-Tree Alignment BackendThe system presented in this paper uses phrase-based sub-tree structural alignment (Zhechev,2010) to discover parts of the input sentence thatcorrespond to parts of the suggested translationextracted from the TM database.
We chose thisparticular tool, because it can produce alignedphrase-based-tree pairs from unannotated (i.e.unparsed) data.
It can also function fully auto-matically without the need for any training data.The only auxiliary requirement it has is for aprobabilistic dictionary for the languages that arebeing aligned.
As described later in this section,in our case this is obtained automatically from theTM data during the training of the SMT backend.The matching between the input sentence andthe TM-suggested translation is done in a three-step process.
First, the plain TM match and its1http://www.postgresql.org/44translation are aligned, which produces a sub-tree-aligned phrase-based tree pair with all non-terminal nodes labelled ?X?
(cf.
Zhechev, 2010).As we are only interested in the relations be-tween the lexical spans of the non-terminalnodes, we can safely ignore their labels.
We callthis first step of our algorithm bilingual alignment.In the second step, called monolingual align-ment, the phrase-based tree-annotated version ofthe TM match is aligned to the unannotated inputsentence.
The reuse of the tree structure for theTM match allows us to use it in the third step asan intermediary to establish the available sub-tree alignments between the input sentence andthe translation suggested from the TM.During this final alignment, we identifymatched and mismatched portions of the inputsentence and their possible translations in theTM suggestion and, thus, this step is calledmatching.
Additionally, the sub-tree alignmentsimplicitly provide us with reordering informa-tion, telling us where the portions of the inputsentence that we translate should be positioned inthe final translation.The alignment process is exemplified in Figure 1.The tree marked ?I?
corresponds to the input sen-tence, the one marked ?M?
to the TM match andthe one marked ?T?
to the TM translation.
Due tospace constraints, we only display the node IDnumbers of the non-terminal nodes in the phrase-structure trees??
?in reality all nodes carry thelabel ?X?.
These IDs are used to identify the sub-sentential alignment links.
The lexical items cor-responding to the leaves of the trees are pre-sented in the table below the graph.The alignment process can be visually repre-sented as starting at a linked node in the I treeand following the link to the M tree.
Then, ifavailable, we follow the link to the T tree andthis leads us to the T-tree node corresponding tothe I-tree node we started from.
In Figure 1, thisresults in the I?T alignments I1?T18, I2?T2, I3?T1, I4?T32 and I6?T34.
The first three links arematches, because the lexical items covered bythe I nodes correspond exactly to the lexicalitems covered by their M node counterparts.Such alignments provide us with direct TMtranslations for our input.
The last two links inthe group are mismatched, because there is nolexical correspondence between the I and Mnodes (node I4  corresponds to the phrase senderemail, while the linked node M10  corresponds tosender ?s email).
Such alignments can only beused to infer reordering information.
In particularin this case, we can infer that the target word or-der for the input sentence is address emailsender, which produces the translation adresse?lectronique de l?
exp?diteur.151310 46 31 253634 81 322 24 718 63 4 5641 23TIMIinputMmatchTtrans-lation1 2 3sender email address1 2 3 4 5sender ?s email address .1 2 3 4 5 6 7 8adresse?lectro-niquede l?exp?-diteurdumes-sage.Figure 1.
Example of sub-tree alignment betweenan input sentence, TM match and TM translationWe decided to use sub-tree-based alignment,rather than plain word alignment (e.g.
GIZA++ ?Och and Ney, 2003), due to a number of factors.First, sub-tree-based alignment provides muchbetter handling of long-distance reorderings,while word?
and phrase-based alignment modelsalways have a fixed limit on reordering distancethat tends to be relatively low to allow efficientcomputation.The alignments produced by a sub-tree align-ment model are also precision-oriented, ratherthan recall-oriented (cf.
Tinsley, 2010).
This isimportant in our case, where we want to onlyextract those parts of the translation suggested bythe TM for which we are most certain that theyare good translations.45As stated earlier, the only resource necessaryfor the operation of this system is a probabilisticbilingual dictionary covering the data that needsto be aligned.
For the bilingual alignment step,such a bilingual dictionary is produced as a by-product of the training of the SMT backend andtherefore available.
For the monolingual align-ment step, the required probabilistic dictionary isgenerated by simply listing each unique tokenseen in the source-language data in the TM astranslating only as itself with probability 1.2.4.
Statistical Machine Translation BackendOnce the matching  step is completed, we haveidentified and marked-up the parts of the inputsentence for which translations will be extractedfrom the TM suggestions, as well as the partsthat need to be translated from scratch.
Thelengths of the non-translated segments vary de-pending on the FMS, but are in general relativelyshort (one to three tokens).The further processing of the input relies on aspecific feature of the SMT backend we use,namely the Moses system (Koehn et al, 2007).We decided to use this particular system as it isthe most widely adopted open-source SMT sys-tem, both for academic and commercial pur-poses.
In this approach, we annotate the seg-ments of the input sentence for which transla-tions have been found from the TM suggestionusing XML tags with the translation correspond-ing to each segment given as an attribute to theencapsulating XML tag, similarly to the systemdescribed in (Smith and Clark, 2009).
The SMTbackend is supplied with marked-up input in theform of a string consisting of the concatenationof the XML-enclosed translated segments andthe plain non-translated segments in the target-language word order, as established by thealignment process.
The SMT backend is in-structed to translate this input, while keeping thetranslations supplied via the XML annotation.This allows the SMT backend to produce transla-tions informed by and conforming to actual ex-amples from the TM, which should result in im-provements in translation quality.2.5.
Auxilliary ToolsIt must be noted that in general the SMT backendsees the data it needs to translate in the target-language word order (e.g.
it is asked to translatean English sentence that has French word order).This, however, does not correspond to the datafound in the TM, which we use for deriving theSMT models.
Because of this discrepancy, wedeveloped a pre-processing tool that goes overthe TM data performing bilingual alignment andoutputting reordered versions of the sentences itprocesses by using the information implicitlyencoded in the sub-tree alignments.
In this waywe obtain the necessary reordered data to train atranslation model where the source language al-ready has the target-language word order.
In oursystem we than use this model??
?together withthe proper-word-order model??
?for translation.One specific aspect of real-world TM data thatwe need to deal with is that they often containmeta-tag annotations of various sorts.
Namely,annotation tags specific to the file format used forstoring the TM data, XML tags annotating partsof the text as appearing in Graphical User Inter-face (GUI) elements, formatting tags specific tothe file format the TM data was originally takenfrom, e.g.
RTF, OpenDoc, etc.
Letting any MTsystem try to deal with these tags in a probabilis-tic manner can easily result in ill-formed, mis-translated and/or out-of-order meta-tags in thetranslation.This motivates the implementation of a rudi-mentary handling of meta-tags in the system pre-sented in this paper, in particular handling theXML tags found in the TM data we work with,as described in Section 3.
The tool we developedfor this purpose simply builds a map of allunique XML tags per language and replacesthem in the data with short placeholders that aredesigned in such a way that they would not inter-fere with the rest of the TM data.2A special casethat the tool has to take care of is when an XMLtag contains an attribute whose value needs to betranslated.
In such situations, we decided to notperform any processing, but rather leave theXML tag as is, so that all text may be translatedas needed.
A complete treatment of meta-tags,however, is beyond the scope of the current paper.2In the current implementation, the XML tags are replaced with the string ?<tag_id>?, where <tag_id> is a unique nu-meric identifier for the XML tag that is being replaced.46We also had to build a dedicated tokeniser/de-tokeniser pair to handle real world TM data con-taining meta-tags, e-mail addresses, file paths,etc., as described in Section 3.
Both tools areimplemented as a cascade of regular expressionsubstitutions in Perl.Finally, we use a tool to extract the textualdata from the TM.
That is, we strip all tags spe-cific to the format in which the TM is stored, asthey can in general be recreated and thus do notneed to be present during translation.
In our par-ticular case the TM is stored in the XML-basedTMX format.32.6.
Complete WorkflowBesides the components described above, wealso performed two further transformations onthe data.
First, we lowercase the TM data beforeusing it to train the SMT backend models.
Thisalso means that the alignment steps from Section2.3 are performed on lowercased data, as the bi-lingual dictionary used there is obtained duringthe SMT training process.4Additionally, the SMT and sub-tree alignmentsystems that we use cannot handle certain char-acters, which we need to mask in the data.
Forthe SMT backend, this includes ?|?, ?<?
and ?>?and for the sub-tree aligner, ?(?
and ?)?.
The rea-son these characters cannot be handled is that theSMT system uses ?|?
internally to separate datafields in the trained models and ?<?
and ?>?
can-not be handled whilst using XML tags to anno-tate pre-translated portions of the input.
The sub-tree aligner uses ?(?
and ?)?
to represent thephrase-based tree structures it generates and thepresence of these characters in the data may cre-ate ambiguity when parsing the tree structures.All these characters are masked by substitutingin high-Unicode counterparts, namely ??
?, ???,??
?, ???
and ???.
Visually, there is a very slightdistinction and this is intentionally so to simplifydebugging.
However, the fact that the charactercodes are different alleviates the problems dis-cussed above.
Of course, in the final output, themasking is reversed and the translation containsthe regular versions of the characters.Extract Textual Datafrom TMX FormatTMX DataMeta-Tag HandlingTokenisation andMasking of SpecialCharactersStartLowercasingGeneration of ProbabilisticDictionary forMonolingual AlignmentLanguage-ModelTraining andBinarisationAutomaticWord-AlignmentSMT ModelTraining andBinarisationLanguage ModelsProbabilistic Dictionaryfor MonolingualAlignmentProbabilistic Dictionaryfor Bilingual AlignmentSMT Model withNormal Word OrderGeneration ofBilingual ParallelTreebankBilingual ParallelTreebankTMDatabaseReorder Source-Language DataNormalWord OrderReordered Source-Language DataAutomaticWord-AlignmentSMT ModelTraining andBinarisationSMT Model withTarget Word OrderStopTargetWordOrderSub-Tree AlignmentInput DataMeta-TagSubstitution MapsFigure 2.
Pre-Processing WorkflowThe complete pre-processing workflow is pre-sented in Figure 2, where the rectangles with ver-tical bars represent the use of open-source tools,while the plain rectangles represent tools devel-oped by the authors of this paper.First, the textual data is extracted from theoriginal TM format, producing one plain-text filefor each language side.
These data can either bepre-loaded in a PostgreSQL database at this time,or during the first run of the translation system.Next, the meta-tag-handling tool is used togenerate the substitution tables for the source andtarget languages, as well as new files for eachlanguage with the tags substituted by the corre-sponding identifiers (cf.
Section 2.5).
These filesare then tokenised, lowercased and all conflictingcharacters are masked, as described above.The pre-processed files are then used to pro-duce a file containing pairs of sentences in theinput format of the sub-tree aligner, as well as togenerate the probabilistic dictionary required for3http://www.lisa.org/fileadmin/standards/tmx1.4/tmx.htm4Currently, we do not use a recaser tool and the translations produced are always in lowercase.
This component, however,will be added in a future version of the system.47the monolingual alignment and to train the SMTmodel on the data in the proper word order.
TheSMT training produces the necessary bilingualdictionary for use by the sub-tree aligner, whichis run to obtain a parallel-treebank version of theTM data.
The parallel treebank is then used toretrieve bilingual alignments for the TM data,rather than generate them on the fly during trans-lation.
This is an important design decision, asthe complexity of the alignment algorithm is highfor plain-text alignment (cf.
Zhechev, 2010).Once we have generated the bilingual paralleltreebank, we run the reordering tool, which gen-erates a new plain-text file for the source lan-guage, where the sentences are modified to con-form to the target-language word order, as im-plied by the data in the parallel treebank.
This isthen matched with the proper-order target-language file to train the SMT backend for theactual use in the translation process.SMT Model withNormal Word OrderSMT Backend(normal word order)SMT Backend(both word orders)TMDatabaseFind TM Match withHighest FMSMeta-Tag Handling,Tokenisation andMasking of SpecialCharacters for I, M, TBilingual ParallelTreebankExtract BilingualAlignment for M, TGenerate Mono-lingual Alignmentfor M, IOutput T(tm)Perform AlignmentMatchingxml ApproachOutputTranslation(xml)SMT Model withTarget Word OrderOutputTranslation(direct)FMS >= 50Probabilistic Dictionaryfor MonolingualAlignmentRead InputSentenceMeta-Tag Handling,Detokenisation andUnmasking of SpecialCharacters for OutputyesnoLanguage ModelsMeta-TagSubstitution MapsFigure 3.
Translation WorkflowOnce all the necessary files have been gener-ated and all pre-processing steps have been com-pleted, the system is ready for use for translation.The translation workflow is shown in Figure 3,?I?, ?M?
and ?T?
having the same meanings as inFigure 1.
Here, the first step after an input sen-tence has been read in is to find the TM matchwith the highest FMS.
This is done using theoriginal plain non-pre-processed data to simulatereal-life operation with a proper TM backend.After the best TM match and its translation areextracted from the TM, they??
?together with theinput sentence??
?are pre-processed by tokenisa-tion, lowercasing, meta-tag and special-charactersubstitution.
Next, the corresponding tree pair isextracted from the bilingual parallel treebank toestablish the tree structure for the TM source-language match.
This tree structure is then usedto perform the monolingual alignment, whichallows us to perform the matching step next.
Af-ter the matching is complete, we generate a finaltranslation as described in Section 2.4.
Finally,the translations are de-tokenised and the XMLtags and special characters are unmasked.3.
Experimental SetupWe use real-life TM data from an industrial part-ner.
The TM was generated during the translationof RTF-formatted customer support documenta-tion.
The data is in TMX format and originallycontains 108 ?
967 English?French translationsegments, out of which 14 segments either havean empty language side or have an extreme dis-crepancy in the number of tokens for each lan-guage side and were therefore discarded.A particular real-life trait of the data is thepresence of a large number of XML tags.
Run-ning the tag-mapping tool described in Section2.6, we gathered 2?049 distinct tags for the Eng-lish side of the data and 2 ?653 for the Frenchside.
Still, there were certain XML tags that in-cluded a label argument whose value was trans-lated from one language to the other.
These XMLtags were left intact so that our system couldhandle the translation correctly.The TM data also contain a large number offile paths, e-mail addresses, URLs and others,which makes bespoke tokenisation of the datanecessary.
Our tokenisation tool ensures thatnone of these elements are tokenised, keeps RTFformatting sequences non-tokenised and properlyhandles non-masked XML tags, minimising theirfragmentation.As translation segments rarely occur more thanonce in a TM, we observe a high number of uniquetokens (measured after pre-processing)??
?41?379for English and 49 ?
971 for French??
?out of48108 ?953 segment pairs.
The average sentencelength is 13.2 for English and 15.0 for French.For evaluation, we use a data set of 4977 Eng-lish?French segments from the domain of theTM.
The sentences in the test set are significantlyshorter on average, compared to the TM??
?9.2tokens for English and 10.9 for French.It must be noted that we used SMT modelswith maximum phrase length of 3 tokens, ratherthan the standard 5 tokens, and for decoding weused a 3-gram language model.
This results inmuch smaller models than the ones usually usedin mainstream SMT applications.
(The standardfor some tools goes as far as 7-token phase-length limit and 7-gram language models)4.
Evaluation ResultsFor the evaluation of our system, we used anumber of widely accepted automatic metrics,namely BLEU (Papineni et al, 2002), METEOR(Banerjee and Lavie, 2005), TER (Snover et al,2006) and inverse F-Score based on token-levelprecision and recall.We setup our system to only fully process in-put sentences for which a TM match with anFMS over 50% was found, although all sen-tences were translated directly using the SMTbackend to check the overall pure SMT perform-ance.
The TM-suggested translations were alsooutput for all input sentences.The results of the evaluation are given in Fig-ure 4, where the tm and direct scores are alsogiven for the FMS range [0%; 50%)?
{100%}.Across all metrics we see a uniform drop in thequality of TM-suggested translations, which iswhat we expected, given that these translationscontain one or more wrong words.
We believethat the relatively high scores recorded for theTM-suggested translations at the high end of theFMS scale are a result of the otherwise perfectword order and lexical choice.
For n-gram-match-based metrics like the ones we used such aresult is expected and predictable.
Although theinverse F-score results show the potential of oursetup to translate the outstanding tokens in a90%?100% TM match, it appears that the SMTsystem produces word order that does not corre-spond to the reference translation and because ofthis receives lower scores on the other metrics.The unexpected drop in scores for perfect TMmatches is due to discrepancies between the ref-erence translations in our test set and the transla-tions stored in the TM.
We believe that this issueFigure 4.
Evaluation results for English-to-French translation, broken down by FMS range0?50/1963 50?60/779 60?70/621 70?80/537 80?90/537 90?100/375 100/1650,10,20,30,40,50,60,70,8FMS Range/SegmentsBLEUtmdirectxml0?50/1963 50?60/779 60?70/621 70?80/537 80?90/537 90?100/375 100/1650,30,40,50,60,70,80,9FMS Range/SegmentsMETEORxmldirecttm0?50/1963 50?60/779 60?70/621 70?80/537 80?90/537 90?100/375 100/1650,10,20,30,40,50,60,70,80,9FMS Range/SegmentsTERxmldirecttm0?50/1963 50?60/779 60?70/621 70?80/537 80?90/537 90?100/375 100/1650,20,30,40,50,60,7FMS Range/SegmentsInverse F-Scoretmdirectxml49affects all FMS ranges, albeit to a lower extentfor non-perfect matches.
Unfortunately, the exactimpact cannot be ascertained without humanevaluation.We observe a significant drop-off in translationquality for the direct output below FMS 50%.This suggests that sentences with such low FMSshould be translated either by a human translatorfrom scratch, or by an SMT system trained ondifferent/more data.Our system (i.e.
the xml setup) clearly outper-forms the direct SMT translation for FMS be-tween 80 and 100 and has comparable perform-ance between FMS 70 and 80.
Below FMS 70,the SMT backend has the best performance.
Al-though these results are positive, we still need toinvestigate why our system has poor perform-ance at lower FMS ranges.
Theoretically, itshould outperform the SMT backend across allranges, as its output is generated by supplyingthe SMT backend with good pre-translated frag-ments.
The Inverse F-Score graph suggest thatthis is due to worse lexical choice, but only man-ual evaluation can provide us with clues for solv-ing the issue.The discrepancy in the results in the Inverse F-Score graph with the other metrics suggest thatthe biggest problem for our system is producingoutput in the expected word-order.5.
Future WorkThere are a number of possible directions forimprovement that can be explored.As mentioned earlier, we plan to integrate oursystem with a full-featured open-source or com-mercial TM product that will supply the TMmatches and translations.
We expect this to im-prove our results, as the quality of the TM matcheswill better correspond to the reported FMS.Such an integration will also be the first neces-sary step to perform a user study evaluating theeffect of the use of our system on post-editingspeeds.
We expect the findings of such a study toshow a significant increase of throughput thatwill significantly reduce the costs of translationfor large-scale projects.It would be interesting to also conduct a userstudy where our system is used to additionallymark up the segments that need to be edited inthe final SMT translation.
We expect this to pro-vide additional speedup to the post-editing proc-ess.
Such a study will require tight integrationbetween our system and a CAT tool and themodular design we presented will facilitate thissignificantly.The proposed treatment of meta-tags is cur-rently very rudimentary and may be extendedwith additional features and to handle additionaltypes of tags.
The design of our system currentlyallows the meta-tag-handling tool to be devel-oped independently, thus giving the user thechoice of using a different meta-tag tool for eachtype of data they work with.In addition, the reordering tool needs to bedeveloped further, with emphasis on properlyhandling situations where the appropriate posi-tion of an input-sentence segment cannot be re-liably established.
In general, further research isneeded into the reordering errors introduced bythe SMT system into otherwise good translations.6.
ConclusionsIn this paper, we presented a novel modular ap-proach to the utilisation of Translation Memorydata to improve the quality of Statistical MachineTranslation.The system we developed uses precise sub-tree-based alignments to reliably determine andmark up correspondences between an input sen-tence and a TM-suggested translation, which en-sures the utilisation of the high-quality transla-tion data stored in the TM database.
An SMTbackend then translates the marked-up input sen-tence to produce a final translation with im-proved quality.Our evaluation shows that the system pre-sented in this paper significantly improves thequality of SMT output when using TM matcheswith FMS above 80 and produces results on parwith the pure SMT output for SMT between 70and 80.
TM matches with FMS under 70 seem toprovide insufficient reordering information andtoo few matches to improve on the SMT output.Still, further investigation is needed to properlydiagnose the drop in quality for FMS below 70.We expect further improvements to the reor-dering functionality of our system to result inhigher-quality output even for lower FMS ranges.50AcknowledgementsThis research is funded under the 7thFrameworkProgramme of the European Commission withinthe EuroMatrixPlus project (grant ?
231720).The data used for evaluation was generously pro-vided by Symantec Ireland.ReferencesBanerjee, Satanjeev and Alon Lavie.
2005.
METEOR:An Automatic Metric for MT Evaluation withImproved Correlation with Human Judgements.In Proceedings of the Workshop on Intrinsic andExtrinsic Evaluation Measures for MT and/orSummarization at the 43rd Annual Meeting of theAssociation for Computational Linguistics(ACL ?05), pp.
65?72.
Ann Arbor, MI.Bi?ici, Ergun and Marc Dymetman.
2008.
DynamicTranslation Memory: Using Statistical MachineTranslation to improve Translation Memory FuzzyMatches.
In Proceedings of the 9th InternationalConference on Intelligent Text Processing andComputational Linguistics (CICLing??08),ed.
Alexander F. Gelbukh, pp.
454?465.
Vol.
4919of Lecture Notes in Computer Science.
Haifa,Israel: Springer Verlag.Heyn, Matthias.
1996.
Integrating MachineTranslation into Translation Memory Systems.In Proceedings of the EAMT Machine TranslationWorkshop, TKE?
?96, pp.
113?126.
Vienna, Austria.Koehn, Philipp, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, NicolaBertoldi, Brooke Cowan, Wade Shen, ChristineMoran, Richard Zens, Chris Dyer, Ond?ej Bojar,Alexandra Constantin and Evan Herbst.
2007.Moses: Open Source Toolkit for StatisticalMachine Translation.
In Proceedings of the Demoand Poster Sessions of the 45th Annual Meeting ofthe Association for Computational Linguistics(ACL ?07), pp.
177?180.
Prague, Czech Republic.Levenshtein, Vladimir I.
1965.
????????
????
?????????????
????????
?, ???????
?
?????????????????
(Binary Codes Capable of CorrectingDeletions, Insertions, and Reversals).
???????????????
????
???
?, 163 (4): 845?848.
[reprinted in: Soviet Physics Doklady, 10: 707?710.
].Och, Franz Josef and Hermann Ney.
2003.A Systematic Comparison of Various StatisticalAlignment Models.
Computational Linguistics,29 (1): 19?51.Papineni, Kishore, Salim Roukos, Todd Ward andWei-Jing Zhu.
2002.
BLEU: A Method forAutomatic Evaluation of Machine Translation.In Proceedings of the 40th Annual Meeting of theAssociation of Computational Linguistics(ACL?
?02), pp.
311?318.
Philadelphia, PA.Simard, Michel and Pierre Isabelle.
2009.
Phrase-based Machine Translation in a Computer-assistedTranslation Environment.
In The Twelfth MachineTranslation Summit (MT Summit XII), pp.
120?127.Ottawa, ON, Canada.Smith, James and Stephen Clark.
2009.
EBMT forSMT: A New EBMT?SMT Hybrid.
In Proceedingsof the 3rd International Workshop on Example-Based Machine Translation (EBMT??09),eds.
Mikel L. Forcada and Andy Way, pp.
3?10.Dublin, Ireland.Snover, Matthew, Bonnie J. Dorr, Richard Schwartz,Linnea Micciulla and John Makhoul.
2006.A Study of Translation Edit Rate with TargetedHuman Annotation.
In Proceedings of the7th Conference of the Association for MachineTranslation in the Americas (AMTA??06),pp.
223?231.
Cambridge, MA.Tinsley, John.
2010.
Resourcing Machine Translationwith Parallel Treebanks.
School of Computing,Dublin City Univercity: PhD Thesis.
Dublin, Ireland.Zhechev, Ventsislav.
2010.
Automatic Generation ofParallel Treebanks.
An Efficient UnsupervisedSystem: Lambert Academic Publishing.51
