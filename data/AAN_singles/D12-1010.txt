Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational NaturalLanguage Learning, pages 105?115, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational LinguisticsAn Entity-Topic Model for Entity LinkingXianpei Han        Le SunInstitute of Software, Chinese Academy of SciencesHaiDian District, Beijing, China.
{xianpei, sunle}@nfs.iscas.ac.cnAbstractEntity Linking (EL) has receivedconsiderable attention in recent years.Given many name mentions in a document,the goal of EL is to predict their referententities in a knowledge base.
Traditionally,there have been two distinct directions ofEL research: one focusing on the effects ofmention?s context compatibility, assumingthat ?the referent entity of a mention isreflected by its context?
; the other dealingwith the effects of document?s topiccoherence, assuming that ?a mention?sreferent entity should be coherent with thedocument?s main topics?.
In this paper, wepropose a generative model ?
called entity-topic model, to effectively join the abovetwo complementary directions together.
Byjointly modeling and exploiting the contextcompatibility, the topic coherence and thecorrelation between them, our model canaccurately link all mentions in a documentusing both the local information (includingthe words and the mentions in a document)and the global knowledge (including thetopic knowledge, the entity contextknowledge and the entity name knowledge).Experimental results demonstrate theeffectiveness of the proposed model.1 IntroductionEntity Linking (EL) has received considerableresearch attention in recent years (McNamee &Dang, 2009; Ji et al2010).
Given many namementions in a document, the goal of EL is topredict their referent entities in a given knowledgebase (KB), such as the Wikipedia1.
For example, as1 www.wikipedia.orgshown in Figure 1, an EL system should identifythe referent entities of the three mentions WWDC,Apple and Lion correspondingly are the entitiesApple Worldwide Developers Conference, AppleInc.
and Mac OS X Lion in KB.
The EL problemappears in many different guises throughout theareas of natural language processing, informationretrieval and text mining.
For instance, in manyapplications we need to collect all appearances of aspecific entity in different documents, EL is aneffective way to resolve such an informationintegration problem.
Furthermore, EL can bridgethe mentions in documents with the semanticinformation in knowledge bases (e.g., Wikipediaand Freebase 2 ), thus can provide a solidfoundation for knowledge-rich methods.Figure 1.
A Demo of Entity LinkingUnfortunately, the accurate EL is often hinderedby the name ambiguity problem, i.e., a name mayrefer to different entities in different contexts.
Forexample, the name Apple may refer to more than20 entities in Wikipedia, such as Apple Inc., Apple(band) and Apple Bank.
Traditionally, there havebeen two distinct directions in EL to resolve thename ambiguity problem: one focusing on theeffects of mention?s context compatibility and theother dealing with the effects of document?s topiccoherence.
EL methods based on context2 www.freebase.comAt the WWDCconference,Appleintroduces itsnew operatingsystem release -Lion.Document Knowledge BaseApple Inc.MAC OS X LionSteve JobsiPhoneApple WorldwideDevelopersConferenceCalifornia105compatibility assume that ?the referent entity of amention is reflected by its context?
(Mihalcea &Cosomai, 2007; Zhang et al2010; Zheng et al2010; Han & Sun, 2011; Kataria et al2011; Sen2012).
For example, the context compatibilitybased methods will identify the referent entity ofthe mention Lion in Figure 1 is the entity Mac OSX Lion, since this entity is more compatible with itscontext words operating system and release thanother candidates such as Lion(big cats) orLion(band).
EL methods based on topic coherenceassume that ?a mention?s referent entity should becoherent with document?s main topics?
(Medelyanet al2008; Milne & Witten, 2008; Kulkarni et al2009; Han et al2011).
For example, the topiccoherence based methods will link the mentionApple in Figure 1 to the entity Apple Inc., since itis more coherent with the document?s topic MACOS X Lion Release than other referent candidatessuch as Apple (band) or Apple Bank.In recent years, both of the above two ELdirections have shown their effectiveness to someextent, and obviously they are complementary toeach other.
Therefore we believe that bring theabove two directions together will enhance the ELperformance.
Traditionally, the above twodirections are usually be brought together using ahybrid method (Zhang and Sim, 2011; Ratinov etal., 2011; Han et al2011), i.e., the contextcompatibility and the topic coherence are firstseparately modeled, then their EL evidence arecombined through an additional model.
Forexample, Zhang and Sim (2011) first models thecontext compatibility as a context similarity andthe topic coherence as a similarity between theunderlying topics of documents and KB entries,then these two similarities are combined throughan additional SVM classifier for the final ELdecision.The main drawback of these hybrid methods,however, is that they model the contextcompatibility and the topic coherence separately,which makes it difficult to capture the mutualreinforcement effect between the above twodirections.
That is, the topic coherence and thecontext compatibility are highly correlated andtheir evidence can be used to reinforce each otherin EL decisions.
For example, in Figure 1, if thecontext compatibility gives a high likelihood themention Apple refers to the entity Apple Inc., thenthis likelihood will give more evidence for thisdocument?s topic is about MAC OS X Lion, and itin turn will reinforce the topic coherence betweenthe entity MAC OS X Lion and the document.
Inreverse, once we known the topic of this documentis about MAC OS X Lion, the context compatibilitybetween the mention Apple and the entity AppleInc.
can be improved as the importance of thecontext words operating system and release will beincreased using the topic knowledge.
In this way,we believe that modeling the above two directionsjointly, rather than separately, will further improvethe EL performance by capturing the mutualreinforcement effect between the contextcompatibility and the topic coherence.In this paper, we propose a method to jointlymodel and exploit the context compatibility, thetopic coherence and the correlation between themfor better EL performance.
Specifically, wepropose a generative probabilistic model ?
calledentity-topic model, which can uniformly model thetext compatibility and the topic coherence as thestatistical dependencies between the mentions, thewords, the underlying entities and the underlyingtopics of a document by assuming that eachdocument is generated according to the followingtwo assumptions:1) Topic coherence assumption: All entitiesin a document should be centered around the maintopics of the document.
For example, the entityApple Inc. tends to occur in documents about IT,but the entity Apple Bank  will more likely to occurin documents about bank or investment.2) Context compatibility assumption: Thecontext words of a mention should be centered onits referent entity.
For example, the wordscomputer, phone and music tends to occur in thecontext of the entity Apple Inc., meanwhile thewords loan, invest and deposit will more likely tooccur in the context of the entity Apple Bank.In this way, the entity-topic model uniformlymodels the context compatibility, the topiccoherence and the correlation between them as thedependencies between the observed information(the mentions and the words) in a document andthe hidden information we want to know (theunderlying topics and entities) through the globalknowledge (including the topic knowledge, theentity name knowledge and the entity contextknowledge).
And the EL problem can now bedecomposed into the following two inference tasks:1061) Predicting the underlying topics and theunderlying entities of a document based on theobserved information and the global knowledge.We call such a task the prediction task;2) Estimating the global knowledge from data.Notice that the topic knowledge, the entityname knowledge and the entity contextknowledge are all not previously given, thus weneed to estimate them from data.
We call such atask the knowledge discovery task.Because the accurate inference of the above twotasks is intractable in our entity-topic model, thispaper also develops an approximate inferencealgorithm ?
the Gibbs sampling algorithm to solvethem.Contributions.
The main contributions of thispaper are summarized below:y We propose a generative probabilisticmodel, the entity-topic model, which can jointlymodel and exploit the context compatibility, thetopic coherence and the correlation between themfor better EL performance;y We develop a Gibbs sampling algorithm tosolve the two inference tasks of our model: 1)Discovering the global knowledge from data; and 2)Collectively making accurate EL decisions.This paper is organized as follows.
Section 2describes the proposed entity-topic model.
Section3 demonstrates the Gibbs sampling algorithm.
Theexperimental results are presented and discussed inSection 4.
The related work is reviewed in Section5.
Finally we conclude this paper in Section 6.2 The Entity-Topic Model for EntityLinkingIn this section, we describe the proposed entity-topic model.
In following we first demonstrate howto capture the context compatibility, the topiccoherence and the correlation between them in thedocument generative process, then we incorporatethe global knowledge generation into our modelfor knowledge estimation from data.2.1 Document Generative ProcessAs shown in Section 1, we jointly model thecontext compatibility and the topic coherence asthe statistical dependencies in the entity-topicmodel by assuming that all documents aregenerated in a topical coherent and contextcompatible way.
In following we describe thedocument generative process.In our model, each document d is assumedcomposed of two types of information, i.e., thementions and the words.
Formally, we represent adocument as:A document is a collection of M mentions andN words, denoted as d = {m1, ?, mM; w1, ?,wN}, with mi the ith mention and wj the jth word.For example, the document in Figure 1 isrepresented as d = {WWDC, Apple, Lion;   at, the,conference, ?
}, where WWDC, Apple, Lion arethe three mentions and the other are the words.To generate a document, our model relies onthree types of global knowledge, including:y Topic Knowledge ?
(The entitydistribution of topics): In our model, all entities ina document are generated based on its underlyingtopics, with each topic is a group of semanticallyrelated entities.
Statistically, we model each topicas a multinomial distribution of entities, with theprobability indicating the likelihood an entity to beextracted from this topic.
For example, we mayhave a topic ?Apple Inc:= {Steve Jobs0.12, iPhone0.07,iPod0.08, ?
}, indicating the likelihood of the entitySteve Jobs be extracted from this topic is 0.12, etc.y Entity Name Knowledge ?
(The namedistribution of entities): In our model, all namementions are generated using the name knowledgeof its referent entity.
Specifically, we model thename knowledge of an entity as a multinomialdistribution of its names, with the probabilityindicating the likelihood this entity is mentionedby the name.
For example, the name knowledge ofthe entity Apple Inc. may be ?Apple Inc: = {Apple0.51,Apple Computer Inc.0.10, Apple Inc.0.07, ?
}, indicatingthat the entity Apple Inc. is mentioned by the nameApple with probability 0.51, etc.y Entity Context Knowledge ?
(The contextword distribution of entities): In our model, allcontext words of an entity?s mention are generatedusing its context knowledge.
Concretely, we modelthe context knowledge of an entity as amultinomial distribution of words, with theprobability indicating the likelihood a wordappearing in this entity?s context.
For example, wemay have ?Apple Inc:= {phone0.07, computer0.10, IT0.06,phone0.002, ?
}, indicating that the word computerappearing in the context of the entity Apple Inc.with probability 0.1, etc.107Figure 2.
The document generative process, withDir(:), Mult(:) and Unif(:) correspondinglyDirichlet, Multinomial and Uniform distributionGiven the entity list E = {e1, e2, ?, eE} in theknowledge base, the word list V = {w1, w2, ?, wv},the entity name list K = {n1, n2, ?, nK} and theglobal knowledge described in above, thegeneration process of a document collection(corpus) D = {d1, d2, ?, dD} is shown in Figure 2.To demonstrate the generation process, we alsodemonstrate how the document in Figure 1 can begenerated using our model in following steps:Step 1: The model generates the topicdistribution of the document as ?d = {Apple Inc.0.45,Operating System(OS)0.55};Step 2: For the three mentions in the document:i.
According to the topic distribution  ?d, themodel generates their topic assignments asz1=Apple Inc., z2 = Apple Inc., z3 = OS;ii.
According to the topic knowledge ?Apple Inc. ,?OS  and the topic assignments z1, z2, z3, the modelgenerates their entity assignments as e1 = AppleWorldwide Developers Conference, e2 = Apple Inc.,e3 = Mac OS X Lion;iii.
According to the name knowledge of theentities Apple Worldwide Developers Conference,Apple Inc. and Mac OS X Lion, our modelgenerates the three mentions as m1=WWDC, m2 =Apple, m3 = Lion;Step 3: For all words in the document:i.
According to the referent entity set indocument ed = {Apple Worldwide DevelopersConference, Apple Inc., Mac OS X Lion}, themodel generates the target entity they describes asa3=Apple Worldwide Developers Conference anda4=Apple Inc.;ii.
According to their target entity and thecontext knowledge of these entities, the modelgenerates the context words in the document.
Forexample, according to the context knowledge ofthe entities Apple Worldwide DevelopersConference, the model generates its context wordw3 =conference, and according to the contextknowledge of the entity Apple Inc., the modelgenerates its context word w4 = introduces.Through the above generative process, we cansee that all entities in a document are extractedfrom the document?s underlying topics, ensuringthe topic coherence; and all words in a documentare extracted from the context word distributionsof its referent entities, resulting in the contextcompatibility.
Furthermore, the generation oftopics, entities, mentions and words are highlycorrelated, thus our model can capture thecorrelation between the topic coherence and thecontext compatibility.2.2 Global Knowledge Generative ProcessThe entity-topic model relies on three types ofglobal knowledge (including the topic knowledge,the entity name knowledge and the entity contextknowledge) to generate a document.
Unfortunately,all three types of global knowledge are unknownand thus need to be estimated from data.
In thispaper we estimate the global knowledge throughBayesian inference by also incorporating theknowledge generation process into our model.Specifically, given the topic number T, the entitynumber E, the name number K and the wordnumber V, the entity-topic model generates theglobal knowledge as follows:1) ?j?
?
Dir(?
)For each topic z, our model samples its entitydistribution ?z from an E-dimensional Dirichletdistribution with hyperparameter ?.2) ?j?
?
Dir(?
)For each entity e, our model samples its namedistribution ?e from a K-dimensional Dirichletdistribution with hyperparameter ?.3) ?j?
?
Dir(?
)Given the topic knowledge ?
, the entity nameknowledge ?
and the entity context knowledge ?:1.
For each doc d in D, sample its topic distribution?d ?
Dir(?);2.
For each of the Md mentions mi in doc d:a) Sample a topic assignment zi ?
Mult(?d);b) Sample an entity assignment ei ?
Mult(?zi);c) Sample a mention mi ?
Mult(?ei);3.
For each of the Nd words wi in doc d:a) Sample a target entity it describes from d?sreferent entities ai ?
Unif(em1 ; em2 ;?
?
?
; emd);b) Sample a describing word using ai?s contextword distribution wi ?
Mult(?ai).108For each entity e, our model samples its contextword distribution ?e  from a V-dimensionalDirichlet distribution with hyperparameter ?.Finally, the full entity-topic model is shown inFigure 3 using the plate representation.?
?Figure 3.
The plate representation of the entity-topic model2.3 The Probability of a CorpusUsing the entity-topic model, the probability ofgenerating a corpus D={d1, d2, ?, dD} givenhyperparameters ?, ?, ?
and ?
can be expressed as:P (D;?
; ?
; ?
; ?)
=YdP (md;wd;?
; ?
; ?
; ?
)=YdXedP (edj?
; ?
)P (mdjed; ?
)P (wdjed; ?
)=Z?P (?j?
)Z?P (?j?
)YdXedP (mdjed; ?
)?Z?P (?j?
)XadP (adjed)P (wdjad; ?
)?Z?P (?j?
)P (edj?
; ?)d?d?d?d?
(2:1)where md  and ed  correspondingly the set ofmentions and their entity assignments in documentd, wd and ad correspondingly the set of words andtheir entity assignments in document d.3 Inference using Gibbs SamplingIn this section, we describe how to resolve theentity linking problem using the entity-topic model.Overall, there were two inference tasks for EL:1) The prediction task.
Given a document d,predicting its entity assignments (ed for mentionsand ad  for words) and topic assignments ( zd ).Notice that here the EL decisions are just theprediction of per-mention entity assignments (ed).2) The knowledge discovery task.
Given acorpus D={d1, d2, ?, dD}, estimating the globalknowledge (including the entity distribution oftopics ?, the name distribution ?
and the contextword distribution ?
of entities) from data.Unfortunately, due to the heaven correlationbetween topics, entities, mentions and words (thecorrelation is also demonstrated in Eq.
(2.1), wherethe integral is intractable due to the couplingbetween ?
, ?, ?
and ?
), the accurate inference ofthe above two tasks is intractable.
For this reason,we propose an approximate inference algorithm ?the Gibbs sampling algorithm for the entity-topicmodel by extending the well-known Gibbssampling algorithm for LDA (Griffiths & Steyvers,2004).
In Gibbs sampling, we first construct theposterior distribution P (z; e;ajD) , then thisposterior distribution is used to: 1) estimate ?, ?, ?and ?
; and 2) predict the entities and the topics ofall documents in D. Specifically, we first derive thejoint posterior distribution from Eq.
(2.1) as:P (z; e; ajD) / P (z)P (ejz)P (mje)P (aje)P (wja)whereP (z) = (?(T?)?(?
)T )DDYd=1Qt ?(?
+CDTdt )?(T?
+ CDTd?
)(3.1)is the probability of the joint topic assignment z toall mentions m in corpus D, andP (ejz) = (?(E?)?(?
)E )TTYt=1Qe ?(?
+ CTEte )?(E?
+ CTEt?
)(3.2)is the conditional probability of the joint entityassignments e to all mentions m in corpus D givenall topic assignments z, andP (mje) = (?(K?)?(?
)K )EEYe=1Qm ?(?
+ CEMem )?(K?
+ CEMe?
)(3.3)is the conditional probability of all mentions mgiven all per-mention entity assignments e, andP (aje) =DYd=1Ye?ed?CDEdeCDEd?
?CDAde              (3.4)is the conditional probability of the joint entityassignments a to all words w in corpus D given allper-mention entity assignments e, and109P (wja) = (?
(V ?)?(?
)V )EEYe=1Qw ?(?
+ CEWew )?
(V ?
+ CEWe?
)(3.5)is the conditional probability of all words w givenall per-word entity assignments a .
In all aboveformulas, ?
(:) is the Gamma function, CDTdt  is thetimes topic t has been assigned for all mentions indocument d, CDTd?
=Pt CDTdt  is the topic numberin document d, and CTEte , CEMem ,CDEde , CDAde , CEWewhave similar explanation.Based on the above joint probability, weconstruct a Markov chain that converges to theposterior distribution P (z; e;ajD) and then drawsamples from this Markov chain for inference.
Forentity-topic model, each state in the Markov chainis an assignment (including topic assignment to amention, entity assignment to a mention and entityassignment to a word).
In Gibbs sampling, allassignments are sequentially sampled conditionedon all the current other assignments.
So here weonly need to derive the following three fullyconditional assignment distributions:1) P (zi = tjz?i; e;a;D): the topic assignmentdistribution to a mention given the currentother topic assignments z?i , the currententity assignments e and a;2) P (ei = ejz; e?i;a;D) : the entityassignment distribution to a mention giventhe current entity assignments of all othermentions e?i, the current topic assignmentsz  and the current entity assignments ofcontext words a;3) P (ai = ejz; e; a?i;D) : the entityassignment distribution to a context wordgiven the current entity assignments of allother context words a?i, the current topicassignments  z  and the current entityassignments e of mentions.Using the Formula 3.1-3.5, we can derive theabove three conditional distributions as (where miis contained in doc d):P (zi = tjz?i;e;a;D) /CDT(?i)dt + ?CDT(?i)d?
+ T?
?CTE(?i)te + ?CTE(?i)t?
+E?where the topic assignment to a mention isdetermined by the probability this topic appearingin doc d (the 1st term) and the probability thereferent entity appearing in this topic (the 2nd term);P (ei = ejz; e?i;a;D) /CTE(?i)te + ?CTE(?i)t?
+E?
?CEM(?i)em + ?CEM(?i)e?
+K??
?CDE(?i)de + 1CDE(?i)de?CDAdewhere the entity assignment to a mention isdetermined by the probability this entity extractedfrom the assigned topic (the 1st term), theprobability this entity is referred by the name m(the 2nd term) and the contextual words describingthis entity in doc d (the 3rd term);P (ai = ejz; e;a?i;D) /CDEdeCDEd?
?CEW(?i)ew + ?CEW(?i)e?
+ V ?where the entity assignment to a word isdetermined by the number of times this entity hasbeen assigned to mentions in doc d (the 1st term)and the probability the word appearing in thecontext of this entity (the 2nd term).Finally, using the above three conditionaldistributions, we iteratively update all assignmentsof corpus D until coverage, then the globalknowledge is estimated using the final assignments,and the final entity assignments are used as thereferents of their corresponding mentions.Inference on Unseen Documents.
Whenunseen documents are given, we predict its entitiesand topics using the incremental Gibbs samplingalgorithm described in (Kataria et al2011), i.e.,we iteratively update the entity assignments andthe topic assignments of an unseen document asthe same as the above inference process, but withthe previously learned global knowledge fixed.Hyperparameter setting.
One still problemhere is the setting of the hyperparameters ?, ?, ?and ?.
For ?
and ?
, this paper empirically set thevalue of them to ?
= 50=T  and ?
= 0:1  as inGriffiths & Steyvers(2004).
For ?, we notice thatK?
is the number of pseudo names added to eachentity, when ?
= 0  our model only mentions anentity using its previously used names.
Observedthat an entity typically has a fixed set of names, weset ?
to a small value by setting K?
= 1:0.
For ?,we notice that V ?
is the number of pseudo wordsadded to each entity, playing the role of smoothingits context word distribution.
As there is typically arelatively loose correlation between an entity andits context words, we set ?
to a relatively largevalue by fixing the total smoothing words added toeach entity, a typical value is V ?
= 2000.1104 ExperimentsIn this section, we evaluate our method andcompare it with the traditional EL methods.
Wefirst explain the experimental settings in Section4.1-4.4, then discuss the results in Section 4.5.4.1 Knowledge BaseIn our experiments, we use the Jan. 30, 2010English version of Wikipedia as the knowledgebase, which contains over 3 million entities.
Noticethat we also take the general concepts in Wikipedia(such as Apple, Video, Computer, etc.)
as entities,so the entity in this paper may not strictly followits definition.4.2 Data SetsThere are two standard data sets for EL: IITB3 andTAC 2009 EL data set (McNamee & Dang, 2009),where IITB focuses on aggressive recall EL andTAC 2009 focuses on EL on salient mentions.
Dueto the collective nature of our method, we mainlyused the IITB as the primary data set as the sameas Kulkarni et al009) and Han et al011).
Butwe also give the EL accuracies on the TAC 2009 inSect.
4.5.4 as auxiliary results.Overall, the IITB data set contains 107 webdocuments.
For each document, the namementions?
referent entities in Wikipedia aremanually annotated to be as exhaustive as possible.In total, 17,200 name mentions are annotated, with161 name mentions per document on average.
Inour experiments, we use only the name mentionswhose referent entities are contained in Wikipedia.4.3 Evaluation CriteriaThis paper adopted the same performance metricsused in the Kulkarni et al2009), which includesRecall, Precision and F1.
Let M* be the goldenstandard set of the EL results (each EL result is apair (m, e), with m the mention and e its referententity), M be the set of EL results outputted by anEL system, then these metrics are computed as:Precision = jM\M?jjMjRecall = jM\M?jjM?jwhere two EL results are considered equal if andonly if both their mentions and referent entities areequal.
As the same as Kulkarni et al009),3 http://www.cse.iitb.ac.in/~soumen/doc/QCQ/Precision and Recall are averaged acrossdocuments and overall F1 is used as the primaryperformance metric by computing from averagePrecision and Recall.4.4 BaselinesWe compare our method with five baselines whichare described as follows:Wikify!.
This is a context compatibility basedEL method using vector space model (Mihalcea &Csomai, 2007).
Wikify!
computes the contextcompatibility using the word overlap between themention?s context and the entity?s Wikipedia entry.EM-Model.
This is a statistical contextcompatibility based EL method described in Han& Sun(2011), which computes the compatibility byintegrating the evidence from the entity popularity,the entity name knowledge and the context worddistribution of entities.M&W.
This is a relational topic coherence basedEL method described in Milne & Witten(2008).M&W measures an entity?s topic coherence to adocument as its average semantic relatedness to theunambiguous entities in the document.CSAW.
This is an EL method which combinescontext compatibility and topic coherence using ahybrid method (Kulkarni et al2009), wherecontext compatibility and topic coherence are firstseparated modeled as context similarity and thesum of all pair-wise semantic relatedness betweenthe entities in the document, then the entities whichcan maximize the weighted sum of the contextcompatibility and the topic coherence are identifiedas the referent entities of the document.EL-Graph.
This is a graph based hybrid ELmethod described in Han et al2011), which firstmodels the context compatibility as text similarityand the topic coherence of an entity as its nodeimportance in a referent graph which captures allmention-entity and entity-entity relations in adocument, then a random walk algorithm is used tocollectively find all referent entities of a document.Except for CSAW and EL-Graph, all otherbaselines are designed only to link the salient namementions (i.e., key phrases) in a document.
In ourexperiment, in order to compare the ELperformances on also the non-salient namementions, we push these systems?
recall byreducing their respective importance thresholds oflinked mentions.1114.5 Experimental Results4.5.1 Overall PerformanceWe compared our method with all the above fivebaselines.
For our method, we estimate the globalknowledge using all the articles in the Jan. 30,2010 English version of Wikipedia, and totallythere were 3,083,158 articles.
For each article, thementions within it are detected using the methodsdescribed in Medelyan et al008) and all terms inan article are used as context words, so a term mayboth be a mention and a context word.
The topicnumber of our model is T = 300  (will beempirically set in Sect 4.5.2).
To train the entity-topic model, we run 500  iterations of our Gibbssampling algorithm to converge.
The training timeof our model is nearly one week on our serverusing 20 GB RAM and one core of 3.2 GHz CPU.Since the training can be done offline, we believethat the training time is not critical to the real-world usage as the online inference on newdocument is very quick.
Using the above settings,the overall results are shown in Table 1.Precision Recall F1Wikify!
0.55 0.28 0.37EM-Model 0.82 0.48 0.61M&W 0.80 0.38 0.52CSAW 0.65 0.73 0.69EL-Graph 0.69 0.76 0.73Our Method 0.81 0.80 0.80Table 1.
The overall results on IITB data setFrom the overall results in Table 1, we can see that:1) By jointly modeling and exploiting thecontext compatibility and the topic coherence, ourmethod can achieve competitive performance: ?1compared with the context compatibility baselinesWikify!
and EM-Model, our methodcorrespondingly gets 43% and 19% F1improvement; ?2  compared with the topiccoherence baselines M&W, our method achieves28% F1 improvement; ?
compared with thehybrid baselines CSAW and EL-Graph, our methodcorrespondingly achieves 11% and 7% F1improvement.2) Compared with the context compatibilityonly and the topic coherence only methods, themain advantage of our method is that, rather thanonly achieved high entity linking precision onsalient mentions, it can also effectively link thenon-salient mentions in a document: this isdemonstrated in our method?s significant Recallimprovement: a 32~52% Recall improvement overbaselines Wikify!, EM-Model and M&W.
Webelieve this is because a document usually containslittle evidence for EL decisions on non-salientmentions, so with either only context compatibilityor only topic coherence the evidence is not enoughfor EL decisions on these non-salient mentions,and bring these two directions together is criticalfor the accurate EL on these mentions.3) Compared with the hybrid methods, themain advantage of our method is the improvementof EL precision (a 11~16% improvement overbaselines CSAW and EL-Graph), we believe this isbecause: ?1 Our method can further capture themutual reinforcement effect between the contextcompatibility and the topic coherence; ?2 Thetraditional hybrid methods usually determine thetopic coherence of an entity to a document usingall entities in the document, in comparison ourmethod uses only the entities in the same topic, webelieve this is more reasonable for EL decisions.4.5.2 Parameter TuningOne still parameter of our method is the topicnumber T. An appropriate T will distribute entitiesinto well-organized topics, in turn it will capturethe co-occurrence information of entities.
Figure 4plots the F1 at different T values.
We can see thatthe F1 is not very sensitive to the topic number andwith T = 300  our method achieves its best F1performance.0 200 400 600 800 10000.7700.7750.7800.7850.7900.7950.800F1TFigure 4.
The F1 vs. the topic number T4.5.3 Detailed AnalysisIn this section we analyze why and how ourmethod works well in detail.
Generally, we believethe main advantages of our method are:1) The effects of topic knowledge.
One mainadvantage of our model is that the topic knowledge112can provide a document-specific entity prior for EL.Concretely, using the topic knowledge and thetopic distribution of documents, the prior for anentity appearing in a document d is highly relatedto the document?s topics:P (ejd) =Pz P (zjd)P (ejz)This prior is obviously more reasonable than the?information less prior?
(i.e., all entities have equalprior) or ?a global entity popularity prior?
(Han &Sun, 2011).
To demonstrate, Table 2-3 show the 3topics where the Apple Inc. and the fruit Applehave the largest generation probability P(e|z) fromthese topics.
We can see that the topic knowledgecan provide a reasonable prior for entitiesappearing in a document: the Apple Inc. has a largeprior in documents about Computer, Video andSoftware, and the fruit Apple has a large prior indocuments about Wine, Food and Plant.Topic(Computer) Topic(Video) Topic(Software)ComputerCPUHardwarePersonal computerVideoMobile phoneMass mediaMusicComputer softwareMicrosoft WindowsLinuxWeb browserComputer memory Television Operating systemTable 2.
The 3 topics where the Apple Inc. has thelargest P(e|z)Topic(Wine) Topic(Food) Topic(Plant)WineGrapeVineyardWineryFoodRestaurantMeatCheesePlantFlowerLeafTreeApple Vegetable FruitTable 3.
The 3 topics where the fruit Apple has thelargest P(e|z)2) The effects of a fine-tuned context model.The second advantage of our model is that itprovides a statistical framework for fine-tuning thecontext model from data.
To demonstrate such aneffect, Table 4 compares the EL performance of?
the entity-topic model with no context model isused (No Context), i.e., we determine the referententity of a mention by deleting the 3rd term of theformula P (ei = ejz;e?i;a;D) in Section 3; ?
withthe context model estimated using the entity?sWikipedia page (Article Content), ?
with thecontext model estimated using the 50 wordwindow of all its mentions in Wikipedia (MentionContext) and; ?
with the context model in theoriginal entity-topic model (Entity-Topic Model).From Table 4 we can see that a fine-tuned contextmodel will result in a 2~7% F1 improvement.Context Model F1No Context 0.73Article ContentMention ContextEntity-Topic Model0.750.780.80Table 4.
The F1 using different context models3) The effects of joint model.
The thirdadvantage of our model is that it jointly model thecontext compatibility and the topic coherence,which bring two benefits: ?
the mutualreinforcement between the two directions can becaptured in our model; ?
the context compatibilityand the topic coherence are uniformly modeled andjointly estimated, which makes the model moreaccurate for EL.4.5.4 EL Accuracies on TAC 2009 datasetWe also compare our method with the top 5 ELsystems in TAC 2009 and the two state-of-the-artsystems (EM-Model and EL-Graph) on TAC 2009data set in Figure 5 (For EL-Graph and our method,a NIL threshold is used to detect whether thereferent entity is contained in the knowledge base,if the knowledge base not contains the referententity, we assign the mention to a NIL entity).From Figure 5, we can see that our method iscompetitive: 1) Our method can achieve a 3.4%accuracy improvement over the best system inTAC 2009; 2) Our method, EM-Model and EL-Graph get very close accuracies (0.854, 0.86 and0.838 correspondingly), we believe this is because:?1  The mentions to be linked in TAC data set aremostly salient mentions; ?2  The influence of theNIL referent entity problem, i.e., the referent entityis not contained in the given knowledge base: Mostreferent entities (67.5%) on TAC 2009 are NILentity and our method has no special handling onthis problem, rather than other methods such as theEM-Model, which affects the overall performanceof our method.0.720.740.760.780.80.820.840.860.88Figure 5.
The EL accuracies on TAC 2009 dataset1135 Related WorkIn this section, we briefly review the related workof EL.
Traditionally, the context compatibilitybased methods link a mention to the entity whichhas the largest compatibility with it.
Cucerzan(2007) modeled the compatibility as the cosinesimilarity between the vector space representationof mention?s context and of entity?s Wikipediaentry.
Mihalcea & Csomai (2007), Bunescu &Pasca (2006), Fader et al2009), Gottipati etal.
(2011) and Zhang et al011) extended thevector space model with more information such asthe entity category and the acronym expansion, etc.Han & Sun (2011) proposed a generative modelwhich computes the compatibility using theevidences from entity?s popularity, namedistribution and context word distribution.
Katariaet al011) and Sen (2012) used a latent topicmodel to learn the context model of entities.
Zhenget al2010), Dredze et al2010), Zhang et al(2010), Zhou et al2010) and Ji & Chen(2011)employed the ranking techniques to further takerelations between candidate entities into account.On the other side, the topic coherence basedmethods link a mention to the entity which aremost coherent to the document containing it.Medelyan et al2008) measured the topiccoherence of an entity to a document as theweighted average of its relatedness to theunambiguous entities in the document.
Milne andWitten (2008) extended Medelyan et al2008)?scoherence by incorporating commonness andcontext quality.
Bhattacharya and Getoor (2006)modeled the topic coherence as the likelihood anentity is generated from the latent topics of adocument.
Sen (2012) modeled the topic coherenceas the groups of co-occurring entities.
Kulkarni etal.
(2009) modeled the topic coherence as the sumof all pair-wise relatedness between the referententities of a document.
Han et al011) andHoffart et al011) modeled the topic coherence ofan entity as its node importance in a graph whichcaptures all mention-entity and entity-entityrelations in a document.6 Conclusions and Future WorkThis paper proposes a generative model, the entity-topic model, for entity linking.
By uniformlymodeling context compatibility, topic coherenceand the correlation between them as statisticaldependencies, our model provides an effective wayto jointly exploit them for better EL performance.In this paper, the entity-topic model can onlylink mentions to the previously given entities in aknowledge base.
For future work, we want toovercome this limit by incorporating an entitydiscovery ability into our model, so that it can alsodiscover and learn the knowledge of previouslyunseen entities from a corpus for linking namementions to these entities.AcknowledgmentsThe work is supported by the National NaturalScience Foundation of China under Grants no.90920010 and 61100152.
Moreover, we sincerelythank the reviewers for their valuable comments.ReferencesAdafre, S. F. & de Rijke, M. 2005.
Discovering missinglinks in Wikipedia.
In: Proceedings of the 3rdinternational workshop on Link discovery.Bhattacharya, I. and L. Getoor.
2006.
A latent dirichletmodel for unsupervised entity resolution.
In:Proceedings of SIAM International Conference onData Mining.Blei, D. M. and A. Y. Ng, et al2003).
Latent dirichletallocation.
In: The Journal of Machine LearningResearch 3: 993--1022.Bunescu, R. & Pasca, M. 2006.
Using encyclopedicknowledge for named entity disambiguation.
In:Proceedings of EACL, vol.
6.Brown,  P., Pietra, S. D.,  Pietra, V. D., and Mercer, R.1993.
The mathematics of statistical machinetranslation: parameter estimation.
ComputationalLinguistics, 19(2), 263-31.Chen, S. F. & Goodman, J.
1999.
An empirical study ofsmoothing techniques for language modeling.
InComputer Speech and Language, London; Orlando:Academic Press, c1986-, pp.
359-394.Cucerzan, S. 2007.
Large-scale named entitydisambiguation based on Wikipedia data.
In:Proceedings of EMNLP-CoNLL, pp.
708-716.De Beaugrande, R. A. and W. U. Dressler.
1981.Introduction to text linguistics, Chapter V, LongmanLondon.Dredze, M., McNamee, P., Rao, D., Gerber, A.
& Finin,T.
2010.
Entity Disambiguation for Knowledge BasePopulation.
In: Proceedings of the 23rd InternationalConference on Computational Linguistics.114Fader, A., Soderland, S., Etzioni, O.
& Center, T. 2009.Scaling Wikipedia-based named entitydisambiguation to arbitrary web text.
In: Proceedingsof  Wiki-AI Workshop at IJCAI, vol.
9.Gottipati, S., Jiang, J.
2011.
Linking Entities to aKnowledge Base with Query Expansion.
In:Proceedings of EMNLP.Griffiths, T. L. and M. Steyvers.
2004.
Findingscientific topics.
In: Proceedings of the NationalAcademy of Sciences of the United States ofAmerica.Han, X., Sun, L. and Zhao J.
2011.
Collective EntityLinking in Web Text: A Graph-Based Method.
In:Proceedings of 34th Annual ACM SIGIR Conference.Han, X. and Sun, L. 2011.
A Generative Entity-MentionModel for Linking Entities with Knowledge Base.
In:Proceedings of ACL-HLT.Hoffart, J., Yosef, M. A., et al011.
RobustDisambiguation of Named Entities in Text.
In:Proceedings of EMNLP.Jelinek, Frederick and Robert L. Mercer.
1980.Interpolated estimation of Markov source parametersfrom sparse data.
In: Proceedings of the Workshopon Pattern Recognition in Practice.Kataria, S. S., Kumar, K. S. and Rastogi, R. 2011.
EntityDisambiguation with Hierarchical Topic Models.
In:Proceedings of KDD.Kulkarni, S., Singh, A., Ramakrishnan, G. &Chakrabarti, S. 2009.
Collective annotation ofWikipedia entities in web text.
In: Proceedings of the15th ACM SIGKDD international conference onKnowledge discovery and data mining, pp.
457-466.Li, X., Morie, P. & Roth, D. 2004.
Identification andtracing of ambiguous names: Discriminative andgenerative approaches.
In: Proceedings of theNational Conference on Artificial Intelligence, pp.419-424.McNamee, P. & Dang, H. T. 2009.
Overview of theTAC 2009 Knowledge Base Population Track.
In:Proceeding of Text Analysis Conference.Ji, H., et al010.
Overview of the TAC 2010 knowledgebase population track.
In: Proceedings of TextAnalysis Conference.Ji, H. and Chen, Z.
2011.
Collaborative Ranking: ACase Study on Entity Linking.
In: Proceedings ofEMNLP.Milne, D. & Witten, I. H. 2008.
Learning to link withWikipedia.
In: Proceedings of the 17th ACMconference on Conference on information andknowledge management.Milne, D., et al2006.
Mining Domain-SpecificThesauri from Wikipedia: A case study.
In Proc.
ofIEEE/WIC/ACM WI.Medelyan, O., Witten, I. H. & Milne, D. 2008.
Topicindexing with Wikipedia.
In: Proceedings of theAAAI WikiAI workshop.Mihalcea, R. & Csomai, A.
2007.
Wikify!
: linkingdocuments to encyclopedic knowledge.
In:Proceedings of the sixteenth ACM conference onConference on information and knowledgemanagement, pp.
233-242.Pedersen, T., Purandare, A.
& Kulkarni, A.
2005.
Namediscrimination by clustering similar contexts.Computational Linguistics and Intelligent TextProcessing, pp.
226-237.Ratinov, L. and D. Roth, et al011.
Local and GlobalAlgorithms for Disambiguation to Wikipedia.
In:Proceedings of ACL.Sen, P. 2012.
Collective context-aware topic models forentity disambiguation.
In Proceedings of WWW '12,New York, NY, USA, ACM.Zhang, W., Su, J., Tan, Chew Lim & Wang, W. T. 2010.Entity Linking Leveraging Automatically GeneratedAnnotation.
In: Proceedings of the 23rd InternationalConference on Computational Linguistics (Coling2010).Zheng, Z., Li, F., Huang, M. & Zhu, X.
2010.
Learningto Link Entities with Knowledge Base.
In: TheProceedings of the Annual Conference of the NorthAmerican Chapter of the ACL.Zhou, Y., Nie, L., Rouhani-Kalleh, O., Vasile, F. &Gaffney, S. 2010.
Resolving Surface Forms toWikipedia Topics.
In: Proceedings of the 23rdInternational Conference on ComputationalLinguistics (Coling 2010),  pp.
1335-1343.Zhang, W. and Sim, Y. C., et al2011.
Entity Linkingwith Effective Acronym Expansion, InstanceSelection and Topic Modeling?.
In: Proceedings ofIJCAI.115
