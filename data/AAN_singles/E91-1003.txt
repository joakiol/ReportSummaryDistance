DESIGNING ILLUSTRATED TEXTS:HOW LANGUAGE PRODUCTION IS INFLUENCED BYGRAPHICS GENERATIONWolfgang Wahlster, Elisabeth Andr6, Winfried Graf, Thomas RistGerman Research Center for Artificial IntelligenceStuhlsatzenhausweg 3, 6600 Saarbrficken 11, GermanyE-mail: {wahlster, andre, graf, rist)@dfki.uni-sb.deABSTRACTMultimodal interfaces combining, e.g., naturallanguage and graphics take advantage of both theindividual strength of each communication mode andthe fact that several modes can be employed inparallel, e.g., in the text-picture combinations ofillustrated ocuments.
It is an important goal of thisresearch not simply to merge the verbalizationresults of a natural language generator and thevisualization results of a knowledge-based graphicsgenerator, but to carefully coordinate graphics andtext in such a way that they complement each other.We describe the architecture of the knowledge-basedpresentation system WIP* which guarantees a designprocess with a large degree of freedom that can beused to tailor the presentation to suit the specificcontext.
In WIP, decisions of the language generatormay influence graphics generation and graphicalconstraints may sometimes force decisions in thelanguage production process, In this paper, we focuson the influence of graphical constraints on textgeneration.
In particular, we describe the generationof cross-modal references, the revision of text due tographical constraints and the clarification of graphicsthrough text.particular combination of communication modes, theautomatic generation of multimodal presentations isone of the tasks of such presentation systems.
Thetask of the knowledge-based presentation systemWIP is the generation of a variety of multimodaldocuments from an input consisting of a formaldescription of the communicative intent of a plannedpresentation.
The generation process is controlled bya set of generation parameters uch as targetaudience, presentation objective, resourcelimitations, and target language.One of the basic principles underlying the WIPproject is that the various constituents of amultimodal presentation should be generated from acommon representation.
This raises the question ofhow to divide a given communicative goal intosubgoals to be realized by the various mode-specificgenerators, o that they complement each other.
Toaddress this problem, we have to explorecomputational models of the cognitive decisionprocesses coping with questions such as what shouldgo into text, what should go into graphics, andwhich kinds of links between the verbal and non-verbal fragments are necessary.1 INTRODUCTIONWith increases in the amount and sophisticationof information that must be communicated to theusers of complex technical systems comes acorresponding need to find new ways to present thatinformation flexibly and efficiently.
Intelligentpresentation systems are important building blocksof the next generation of user interfaces, as theytranslate from the narrow output channels providedby most of the current application systems intohigh-bandwidth communications tailored to theindividual user.
Since in many situationsinformation is only presented efficiently through a*The WlP project is supported by the GermanMinistry of Research and Technology under grantITW8901 8.
We would like to thank Doug Appelt,Steven Feiner and Ed Hovy for stimulating discussionsabout multimodal information presentation., , ,  , i , , , , ,i .I:: Uf t  i ihe  ild::iili:?
::: :i:::::;:i!i!i:i:.
:!:k..
:;~To fill thewatercontalner , ,~- - - : :  ::::.
::.~: : .::::!
::::, :: : :.
:i;:reniove the cover,:: ": '.
:Fig.
l: Example InstructionIn the project WIP, we try to generate on the flyillustrated texts that are customized for the intendedtarget audience and situation, flexibly presentinginformation whose content, in contrast tohypermedia systems, cannot be fully anticipated.
Thecurrent testbed for WIP is the generation ofinstructions for the use of an espresso-machine.
It isa rare instruction manual that does not contain-8 -illustrations.
WIP's 2D display of 3D graphics ofmachine parts help the addressee of the synthesizedmultimodal presentation to develop a 3D mentalmodel of the object that he can constantly matchwith his visual perceptions of the real machine infront of him.
Fig.
1 shows a typical text-picturesequence which may be used to instruct a user infilling the watercontainer of an espresso-machine.Currently, the technical knowledge to bepresented by WIP is encoded in a hybrid knowledgerepresentation language of the KL-ONE familyincluding a terminological and assertionalcomponent (see Nebel 90).
In addition to thispropositional representation, which includes therelevant information about the structure, function,behavior, and use of the espresso-machine, WIP hasaccess to an analogical representation of thegeometry of the machine in the form of a wireframemodel.The automatic design of multimodalpresentations has only recently received significantattention in artificial intelligence research (cf.
theprojects SAGE (Roth et al 89), COMET (Feiner &McKeown 89), FN/ANDD (Marks & Reiter 90) andWlP (Wahlster et al 89)).
The WIP and COMETprojects share a strong research interest in thecoordination of text and graphics.
They differ fromsystems uch as SAGE and FN/ANDD in that theydeal with physical objects (espresso-machine, radiovs.
charts, diagrams) that the user can access directly.For example, in the WIP project we assume that theuser is looking at a real espresso-machine and usesthe presentations generated by WlP to understand theoperation of the machine.
In spite of manysimilarities, there are major differences betweenCOMET and WIP, e.g., in the systems' architecture.While during one of the final processing steps ofCOMET the layout component combines text andgraphics fragments produced by mode-specificgenerators, in WIP a layou\[ manager can interactwith a presentation planner before text and graphicsare generated, so that layout considerations mayinfluence the early stages of the planning process andconstrain the mode-specific generators.2 THE ARCHITECTURE OF WIPThe architecture of the WIP system guarantees adesign process with a large degree of freedom thatcan be used to tailor the presentation to suit thespecific context.
During the design process apresentation planner and a layout manager orchestratethe mode-specific generators and the documenthistory handler (see Fig.
2) provides informationabout intermediate r sults of the presentation designthat is exploited in order to prevent disconcerting orincoherent output.
This means that decisions of thelanguage generator may influence graphicsgeneration and that graphical constraints maysometimes force decisions in the languageproduction process.
In this paper, we focus on theinfluence of graphical constraints on text generation(see Wahlster et al 91 for a discussion of the inverseinfluence).::i:!
!~;: : text i: p: Fig.
2: The Architecture of the WIP SystemFig.
2 shows a sketch of WIP's currentarchitecture used for the generation of illustrateddocuments.
Note that WIP includes two parallelprocessing cascades for the incremental generation oftext and graphics.
In WIP, the design of amultimodal document is viewed as a non-monotonicprocess that includes various revisions ofpreliminary results, massive replanning or planrepairs, and many negotiations between thecorresponding design and realization components inorder to achieve a fine-grained and optimal divisionof work between the selected presentation modes.2.i THE PRESENTATION PLANNERThe presentation planner is responsible forcontents and mode selection.
A basic assumptionbehind the presentation planner is that not only thegeneration of text, but also the generation ofmultimodal documents can be considered as asequence of communicative acts which aim toachieve certain goals (cf.
Andr6 & Rist 90a).
For thesynthesis of illustrated texts, we have designedpresentation strategies that refer to both text andpicture production.
To represent the strategies, wefollow the approach proposed by Moore andcolleagues (cf.
Moore & Paris 89) to operationalizeRST-thcory (cf.
Mann & Thompson 88) for textplanning.The strategies are represented by a name, aheader, an effect, a set of applicability conditions anda specification of main and subsidiary acts.
Whereasthe header of a strategy indicates whichcommunicative function the corresponding documentpart is to fill, its effect refers to an intentional goal.The applicability conditions pecify when a strategymay be used and put restrictions on the variables tobe instantiated.
The main and subsidiary acts form-9 -the kernel of the strategies.
E.g., the strategy belowcan be used to enable the identification of an objectshown in a picture (for further details see Andr6 &Rist 90b).
Whereas graphics is to be used to carryout the main act, the mode for the subsidiary acts isopen.Name:Enable-ldentlficatlon-by-BackgroundHeader:(Provlde-Background P A ?x ?px ?plc GRAPHICS)Effect:(BMB P A (Identifiable A ?x ?px ?pie))Applicability Conditions:(AND (Bel P (Perceptually-Accesslble A ?X))(Bel P (Part-of ?x ?z)))Main Acts:(Depict P A (Background ?z) ?pz ?pie)Subsidiary Acts:(Achieve P (BMB P A (Identifiable A ?z ?pz ?pie)) ?mode)For the automatic generation of illustrateddocuments, the presentation strategies are treated asoperators of a planning system.
During the planningprocess, presentation strategies are selected andinstantiated according to the presentation task.
Afterthe selection of a strategy, the main and subsidiaryacts are carried out unless the correspondingpresentation goals are already satisfied.
Elementaryacts, such as DeVJ.ct or A~sere, are performed bythe text and graphics generators.2.2 THE LAYOUT MANAGERThe main task of the layout manager is toconvey certain semantic and pragmatic relationsspecified by the planner by the arrangement ofgraphic and text fragments received from the mode-specific generators, i.e., to determine the size of theboxes and the exact coordinates for positioning themon the document page.
We use a grid-based approachas an ordering system for efficiently designingfunctional (i.e., uniform, coherent and consistent)layouts (cf.
Mtiller-Brockmann 81).A central problem for automatic layout is therepresentation of design-relevant knowledge.Constraint networks eem to be a natural formalismto declaratively incorporate aesthetic knowledge intothe layout process, e.g., perceptual criteriaconcerning the organization of boxes as sequentialordering, alignment, grouping, symmetry orsimilarity.
Layout constraints can be classified assemantic, geometric, topological, and temporal.Semantic constraints essentially correspond tocoherence relations, such as sequence and contrast,and can be easily reflected through specific designconstraints.
A powerful way of expressing suchknowledge is to organize the constraintshierarchically by assigning a preference scale to theconstraint network (cf.
Borning et al 89).
Wedistinguish obligatory, optional and defaultconstraints.
The latter state default values, thatremain fixed unless the corresponding constraint isremoved by a stronger one.
Since there areconstraints that have only local effects, theincremental constraint solver must be able to changethe constraint hierarchy dynamically (for furtherdetails ee Graf 90).2.3 THE TEXT GENERATORWIP's text generator is based on the formalismof tree adjoining grammars (TAGs).
In particular,lexicalized TAGs with unification are used for theincremental verbalization of logical forms producedby the presentation planner (cf.
Harbusch 90 andSchauder 91).
The grammar is divided into an LD(linear dominance) and an LP (linear precedence) partso that the piecewise construction of syntacticconstituents i separated from their linearizationaccording to word order rules (Flakier & Neumann89).The text generator uses a TAG parser in a localanticipation feedback loop (see Jameson & Wahlster82).
: The generator and parser form a bidirectionalsystem, i.e., both processes are based on the sameTAG.
By parsing a planned utterance, the generatormakes sure that it does not contain unintendedstructural ambiguities.Since the TAG-based generator is used indesigning illustrated ocuments, it has to generatenot only complete sentences, but also sentencefragments such as NPs, PPs, or VPs, e.g., for figurecaptions, section headings, picture annotations, oritemized lists.
Given that capability and theincrementality of the generation process, it becomespossible to interleave generation with parsing inorder to check for ambiguities as soon as possible.Currently, we are exploring different domains oflocality for such feedback loops and trying to relatethem to resource limitations specified in WIP'sgeneration parameters.
One parameter of thegeneration process in the current implementation isthe number of adjoinings allowed in a sentence.
Thisparameter can be used by the presentation planner tocontrol the syntactic omplexity of the generatedutterances and sentence length.
If the number ofallowed adjoinings is small, a logical form that canbe Verbalized as a single complex sentence may leadto a sequence of simple sentences.
The leewaycreated by this parameter can be exploited for modecoordination.
For example, constraints set up by thegraphics generator or layout manager can forcedelimitation of sentences, ince in a good design,picture breaks hould correspond to sentence breaks,and vice versa (see McKeown & Feiner 90).2,4  THE GRAPHICS GENERATORWhen generating illustrations of physical objectsWIP does not rely on previously authored picture- 10 -fragments or predefined icons stored in theknowledge base.
Rather, we start from a hybridobject representation which includes a wireframemodel for each object.
Although these wireframemodels, along with a specification of physicalattributes such as surface color or transparency formthe basic input of the graphics generator, the designof illustrations i  regarded as a knowledge-intensiveprocess that exploits various knowledge sources toachieve a given presentation goal efficiently.
E.g.,when a picture of an object is requested, we have todetermine an appropriate perspective in a context-sensitive way (cf.
Rist&Andr6 90).
In our approach,we distinguish between three basic types of graphicaltechniques.
First, there are techniques tocreate andmanipulate a 3D object configuration that serves asthe subject of the picture.
E.g., we have developed atechnique to spatially separate the parts of an objectin order to construct an exploded view.
Second, wecan choose among several techniques which map the3D subject onto its depiction.
E.g., we can constructeither a schematic line drawing or a more realisticlooking picture using rendering techniques.
The thirdkind of technique operates on the picture level.
E.g.,an object depiction may be annotated with a label, orpicture parts may be colored in order to emphasizethem.
The task of the graphics designer is then toselect and combine these graphical techniquesaccording to the presentation goal.
The result is a so-called design plan which can be transformed intoexecutable instructions of the graphics realizationcomponent.
This component relies on the 3Dgraphics package S-Geometry and the 2D graphicssoftware of the Symbolics window system.3 THE GENERATION OF CROSS-MODAL REFERENCESIn a multimodal presentation, cross-modalexpressions establish referential relationships ofrepresentations i  one modality to representations ianother modality.The use of cross-modal deictic expressions suchas (a) - (b) is essential for the efficient coordinationof text and graphics in illustrated ocuments:(a) The left knob in the figure on the right is theon~off switch.Co) The black square in Fig.
14 shows thewaterconlainer.In sentence (a) a spatial description is used torefer to a knob shown in a synthetic picture of theespresso-machine.
Note that the multimodalreferential act is only successful if the addressee isable to identify the intended knob of the realespresso-machine.
It is clear that he visualization ofthe knob in the illustration cannot be used as anon/off switch, but only the physical object identifiedas the result of a two-level reference process, i.e., thecross-modal expression i  the text refers to a specificpart of the illustration which in turn refers to a real-word object 1.Another subtlety illustrated by example (a) is theuseiof different frames of reference for the two spatialrelations used in the cross-modal expression.
Thedefinite desedpfionfigure onthe right is based on acomponent generating absolute spatial descriptionsfor:geometric objects displayed inside rectangularframes.
In our example, the whole page designed byWIP's layout manager constitutes the frame ofreference.
One of the basic ideas behind thiscomponent is that such 'absolute' descriptions can bemapped on relative spatial predicates developed forthe VITRA system (see Herzog et al 90) throughthe use of a virtual reference object in the center ofthe frame (for more details ee Wazinski 91).
Thismeans that the description of the location of thefigure showing the on/off switch mentioned insentence (a) is based on the literal r ighe-of (figure-A, center (page-l)) p~u~d by W~'slocalization component.The definite description the left knob is based onthe use of the region denoted byfigure on the rightas a frame of reference for another call of thelocalization component producing the literal a~fe-of~(knobl, knob2) as an appropriate spatialdescription.
Note that all these descriptions arehighly dependent on the viewing specificationchosen by the graphics design component.
Thatmeans that changes in the illustrations during arevision process must automatically be madeavailable to the text design component.Fig.
3: The middle knob in A is the left knob in: the close-up rojection BLet's assume that the presentation planner hasselected the relevant information for a particularpresentation goal.
This may cause the graphicsdesigner to choose a close-up rojection of the topl ln the WIP system there exists yet anotherc0referentiality relation, namely between an individualcQnstant, say knob- l ,  representing the particularknob in the knowledge r presentation la guage and anobject in the wireframe model of the machinecontaining a description of the geometry of that knob.11-part of the espresso-machine with a narrow field ofview focusing on specific objects and eliminatingunnecessary details from the graphics as shown inFig.
B (see Fig.
3).
If the graphics designer choosesa wide field of view (see Fig.
A in Fig.
3) foranother presentation goal, knobZ Can no longer bedescribed as the left knob since the "real-world'spatial ocation of another knob (e.g., ~aobo), whichwas not shown in the close-up projection, is nowused to produce the adequate sPatial description theleft knob for ~aob0.
Considering the row of threeknobs in Fig.
A, knobZ is now described as themiddle knob.Note that the layout manager also needs tobacktrack from time to time:.
This may result indifferent placement of the figure A, e.g., at thebottom of the page.
This means that in the extreme,the cross-modal expression, the left knob in thefigure on the right will be changed into the middleknob in the figure at the bottom.Due to various presentational constraints, thegraphics design component cannot always show thewireframe object in a general position providing asmuch geometric information about the object aspossible.
For example, when a cube is viewed alongthe normal to a face it projects to a square, sO that aloss of generality results (see Karp & Feiner 90).
Inexample (b) the definite description the black squareuses shape information extracted from the projectionchosen by the graphics designer that is stored in thedocument history handler.
It is obvious that even aslight change in the viewpoint for the graphics canresult in a presentation situation where the blackcube has to be used as a referential expression i steadof black square.
Note that the colour attribute blackused in these descriptions may conflict with theaddressee's visual perception of the real espresso-machine.The difference between referring to attributes inthe model and perceptual properties of the real-worldobject becomes more obvious in cases where thespecific features of the display medium are used tohighlight intended objects (e.g., blinking or inversevideo) or when metagraphical objects are chosen asreference points (e.g., an arrow pointing to theintended object in the illustration).
It is clear that adefinite description like the blinking square or thesquare that is highlighted by the bold arrow cannotbe generated before the corresponding decisions aboutillustration techniques are finalized by the graphicsdesigner.The text planning component of a mul'timodalpresentation system such as WlP must be able togenerate such cross-modal expressions not only forfigure captions, but also for coherent ext-picturecombinations.4 THE REVISION OF TEXT DUE TOGRAPHICAL CONSTRAINTSFrequently, the author of a document facesformal restrictions; e.g., when document parts mustnot exceed a specific page size or column width.Such formatting constraints may influence thestructure and contents of the document.
A decisivequestion is, at which stage of the generation processsuch constraints hould be evaluated.
Somerestrictions, uch as page size, are known a priori,while others (e.g., that an illustration should beplaced on the page where it is fast discussed) ariseduring the generation process.
In the WIP system=the problem is aggravated since restrictions canresult from the processing of at least two generators(for text and graphics) working in parallel.
A mode-specific generator is not able to anticipate allsituations in which formatting problems mightoccur.
Thus in WIP, the generators are launched toproduce a ftrst version of their planned output whichmay be revised if necessary.
We illustrate thisrevision process by showing the coordination ofWIP's components when object depictions areannotated with text strings.Suppose the planner has decided to introduce theessential parts of the espresso-machine byclassifying them.
E.g., it wants the addressee toidentify a switch which allows one to choosebetween two operating modes: producing espresso rproducing steam.
In the knowledge base= such aswitch may be represented asshown in Fig.
4.t i, l !
t .
.
.
.
.
./ I  , Z , - - -g .
- - .
- - .
; -  , ...,,,..5 ~_ I tV //~"?
"=''?~-,' ras~lt :Fig.
4: Part of the Terminological Knowledge BaseSince it is assumed that the discourse objects arevisually accessible to the addressee, it is reasonableto refer to them by means of graphics, to describethem verbally and to show the connection betweenthe depictions and the verbal descriptions.
Ininstruction manuals this is usually accomplished by- 12 -various annotation techniques.
In the current WlPsystem, we have implemented three annotationtechniques: annotating by placing the text stringinside an object projection, close to it, or by usingarrows starting at the text string and pointing to theintended object.
Which annotation technique appliesdepends on syntactic riteria, (e.g., formattingrestrictions) as well as semantic riteria to avoidconfusion.
E.g., the same annotation technique is tobe used for all instances of the same basic concept(cL Bum et al 91).on/off ~witch--~elector switctw~tercont~inerFig.
5: Annotations after Text RevisionsSuppose that in our example, the text generatoris asked to find a lexical realization for the conceptEM selector switch and comes up with thedescription selector switch for coffee and steam.When trying to annotate the switch with this textstring, the graphics generator finds out that none ofthe available annotation techniques apply.
Placingthe string close to the corresponding depiction causesambiguities.
The string also cannot be placed insidethe projection of the object without occluding otherparts of the picture.
For the same reason,annotations with arrows faU.
Therefore, the textgenerator is asked to produce a shorter formulation.Unfortunately, it is not able to do so withoutreducing the contents.
Thus, the presentation planneris informed that the required task cannot beaccomplished.
The presentation planner then tries toreduce the contents by omitting attributes or byselecting more general concepts from thesubsumption hierarchy encoded in terms of theterminological logic.
Since m selector switch isa compound escription which inherits informationfrom the concepts witch and ~ selector (seeFig.
4), the planner has to decide which componentof the contents pecification should be reduced.Because the concept switch contains lessdiscriminating information than the conceptselector and the concept switch is at leastpartially inferrable from the picture, the planner firsttries to reduce the component .witch by replacing itby physica l  object.
Thus, the text generator hasto find a sufficiently short definite descriptioncontaining the components physical object andEM selector.
Since this fails, the planner has topropose another reduction.
It now tries to reduce thecomponent EM selector by omitting thecoffee/steam ode.
The text generator then tries toconstruct a NP combining the concepts .witch andselector.
This time it succeeds and the annotationstring can be placed.
Fig.
5 is a hardcopy producedby WIP showing the rendered espresso-machine afterthe required annotations have been carried out.5 THE CLARIFICATION OF GRAPHICSTHROUGH TEXTIn the example above, the first version of adefinite description produced by the text generatorhad to be shortened ue to constraints resulting frompicture design.
However, there are also situations inwhich clarification information has to be addedthrough text because the graphics generator on itsown is not able to convey the information to becommunicated.Let's suppose the graphics designer is requestedto show the location of fitting-I with respect othe espresso-machine-1.
The graphics designertries to design a picture that includes objects that canbe identified as f i t t ing-1 and espresso-machine-1.
To convey the location of ~.tt ing-1 the picturemust provide essential information which enablesthe addressee to reconstruct the initial 3D objectconfiguration (i.e., information concerning thetopology, metric and orientation).
To ensure that headdressee is able to identify the intended object, thegraphics designer tries to present the object from astandard perspective, i.e., an object dependentperspective that satisfies tandard presentation goals,such as showing the object's functionality, top-bottom orientation, oraccessibility (see also Rist &Andr6 90).
In the case of a part-whole relationship,we assume that the location of the part with respectto the whole can be inferred from a picture if thewhole is shown under a perspective such that boththe part and further constituents of the whole arevisible.
In our example, f i t t ing-1 only becomesvisible and identifiable as a part of the espresso-machine when showing the machine from the back.But this means that the espresso-machine must bepresented from a non-standard perspective and thuswe cannot assume that its depiction can be identifiedwithout further clarification.Whenever the graphics designer discoversconflicting presentation goals that cannot be solvedby using an alternative t chnique, the presentationplanner must be informed about currently solved andunsolvable goals.
In the example, the presentationplanner has to ensure that the espresso-machine sidentifiable.
Since we assume that an addressee isable to identify an object's depiction if he knowsfrom which perspective the object is shown, theconflict can be resolved by informing the addressee-13-that the espresso-machine s depicted from the back.This means that the text generator has to produce acomment such as This figure shows the fitting onthe back of the machine, which clarifies thegraphics.CONCLUSIONIn this paper, we introduced the architecure oftheknowledge-based presentation system WIP, whichincludes two parallel processing cascades for theincremental generation of text and graphics.
Weshowed that in WIP the design of a multimodaidocument is viewed as a non-monotonic process thatincludes various revisions of preliminary results,massive replanning or plan repairs, and manynegotiations between the corresponding design andrealization components in order to achieve a fine-grained and optimal devision of work between theselected presentation modes.
We described how theplan-based approach to presentation design can beexploited so that graphics generation i fluences theproduction of text.
In particular, we showed howWlP can generate cross-modal references, revise textdue to graphical constraints and clarify graphicsthrough text.REFERENCES\[Andr6 & Rist 90a\] Elisabeth Andr~ and Thomas Rist.Towards a Plan-Based Synthesis of IllustratedDocuments.
In: 9th ECAI, 25-30, 1990.\[Andrd & Rist 90b\] Elisabeth Andr~ and Thomas Rlst.Generating Illustrated Documents: A Plan-BasedApproach.
In: InfoJapan 90, Vol.
2, 163-170.
1990.\[Borning et al 89\] Alan Borning, Bjorn Freeman-Benson ,  and Molly Wi l son .
ConstraintHierarchies.
Technical Report, Department ofComputer Science and Engineering, University ofWashington, 1989.\[Butz et al 91\] Andreas Butz, Bernd Hermann.
DanielKudenko, and Defter Zlmmermann.
ANNA: EinSystem zur Annotation und Analyse automatiseherzeugter Bilder.
Memo, DFKI, Saarbrflcken, 1991.\[Feiner & McKeown 89\] Steven Feiner and KathleenMcKeown.
Coordinating Text and Graphics inExplanation Generation.
In: DARPA Speech andNatural Language Workshop, 1989.\[Finider & Neumann 89\] Wolfgang Flnkler and GtlnterNeumann.
POPEL-HOW: A Distributed ParallelModel for Incremental Natural Language Productionwith Feedback.
In: llth IJCAI, 1518-1523, 1989.\[Graf 90\] Winfried Graf .
Spezielle Aspekte desautomatischen Layout-Designs bei der koordiniertenGenerierung von multimodalen Dokumenten.
GI-Workshop "Multimediale lektronische Dokumente",1990.\[Harbuach 90\] Karin Harbusch.
Constraining TreeAdjoining Grammars by Unification.
13th COLING,167-172, 1990.\[Herzog et al 90\] Gerd Herzog, Elisabeth Andre, andThomas R is t .
Sprache und Raum:Natllrlichspraclflicher Zugang zu visuellen Daten.
In:Christian Freksa and Christopher Habel (eds.
).Reprlisentation und Verarbeitung ritumlichenWissens.
IFB 245, 207-220, Berlin: Springer-Verlag, 1990.\[Jameson & Wahlster 82\] Anthony Jameson andWolfgang Wahlster.
User Modelling in AnaphoraGeneration: Ellipsis and Defmite Description.
In: 5thECAI, 222-227, 1982\[Karp & Feiner 90\] Peter Karp and Steven Felner.Issues in the Automated Generation of AnimatedPresentations.
In: Graphics Interface '90, 39-48,1990.\[Mann & Thompson 88\] William Mann and SandraThompson.
Rhetorical Structure Theory: Towards aFunctional Theory of Text Organization.
In: TEXT, 8(3), 1988.\[Marks &Reiter 90\] Joseph Marks and Ehnd Reiter.Avoiding Unwanted Conversational Implicatures inText and Graphics.
In: 8th AAAI, 450-455, 1990.\[McKeown & Feiner 90\] Kathleen McKeown andSteven Feiner.
Interactive Multimedia Explanationfor Equipment Maintenance and Repair.
In: DARPASpeech and Natural Language Workshop, 42-47,1990.\[Moore & Pads 89\] Johanna Moore and C(~cile Paris.Planning Text for Advisory Dialogues.
In: 27th ACL,1989.\[Mtlller-Brockmann 81\] Josef Mfi l ler-Brockmann.Grid Systems in Graphic Design.
Stuttgart: Hatje,1981.\[Nebel 90\] Bernhard Nebel.
Reasoning and Revisionin Hybrid Representation Systems.
Lecture Notes inAI, Vol.
422, Berlin: Springer-Verlag, 1990.\[Rist & Andr~ 90, ~ Thomas Rlst and Elisabeth Andre.Wissensbasierte Perspektivenwahl for die auto-matische Erzeugung yon 3D-Objektdarstellungen.
In:Klaus Kansy and Peter Wil3kirchen (eds.).
Graphikund KI.
IFB 239?
Berlin: Springer-Verlag, 48-57,1990.\[Roth et aL 89\] Steven Roth, Joe Mattls, and XavierMesnard .
Graphics and Natural Language asComponents of Automatic Explanation.
In: JosephSullivan and Sherman Tyler (eds.).
Architectures forIntelligent Interfaces: Elements and Prototypes.Reading, MA: Addison-Wesley.
1989.\[Sehauder 90\] Anne Schauder .
Inkrementellesyntaktische Generierung natttrlicher Sprache mitTree Adjoining Grammars.
MS thesis, ComputerScience, University of Saarbrflcken, 1990.\[Wahlster et at.
89\] Wolfgang Wahlster, ElisabethAndre, Matthias Hecking, and Thomas Rlst.
WIP:Knowledge-based Presentation of Information.Report WIP-1, DFKI, Saarbrflcken, 1989.\[Wahlster et al 91\] Wolfgang Wahister, ElisabethAndre, Som Bandyopadhyay, Winfried Graf, andThomas Rlst.
WIP: The Coordinated Generation ofMuliimodal Presentations from a CommonRepresentation.
In: Oliviero Stock, John Slack,Andrew Ortony (eds.).
Computational Theories ofCommunication and their Applications.
Berlin:Springer-Verlag, 1991.\[Wazinski 91\] Peter Waz|nski.
Objektlokalisation igraphischen Darstellungen.
MS thesis, ComputerScience, University of SaarbrOcken, forthcoming.- 14 -
