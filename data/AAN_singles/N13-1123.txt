Proceedings of NAACL-HLT 2013, pages 1031?1040,Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational LinguisticsA Latent Variable Model for Viewpoint Discovery fromThreaded Forum PostsMinghui QiuSchool of Information SystemsSingapore Management UniversitySingaporeminghui.qiu.2010@smu.edu.sgJing JiangSchool of Information SystemsSingapore Management UniversitySingaporejingjiang@smu.edu.sgAbstractThreaded discussion forums provide an im-portant social media platform.
Its rich usergenerated content has served as an importantsource of public feedback.
To automaticallydiscover the viewpoints or stances on hot is-sues from forum threads is an important anduseful task.
In this paper, we propose a novellatent variable model for viewpoint discov-ery from threaded forum posts.
Our model isa principled generative latent variable modelwhich captures three important factors: view-point specific topic preference, user identityand user interactions.
Evaluation results showthat our model clearly outperforms a numberof baseline models in terms of both clusteringposts based on viewpoints and clustering userswith different viewpoints.1 IntroductionThreaded discussion forums provide an importantsocial media platform that allows netizens to expresstheir opinions, to ask for advice, and to form on-line communities.
In particular, responses to majorsociopolitical events and issues can often be foundin discussion forums, which serve as an impor-tant source of public feedback.
In such discussionthreads, we often observe heated debates over a con-troversial issue, with different sides defending theirviewpoints with different arguments.
For example,after the presidential debate between Barack Obamaand Mitt Romney, there were heated discussions inonline forums like CreateDebate1 where some peo-ple expressed their support for Obama while some1http://www.createdebate.com/others have their opposition to him.
For a user whois not closely following an event or issue, instead ofgoing through all the existing posts in a long thread,she may want to quickly get an overview of the ma-jor viewpoints and arguments given by the differentsides.
For policy makers who want to obtain pub-lic feedback on social issues from social media, it isalso desirable to automatically summarize the view-points on an issue from relevant threads.
In this pa-per, we study the problem of modeling and discov-ering different viewpoints in forum threads.Recently there has been some work on findingcontrastive viewpoints from text.
The model pro-posed by Paul et al(2010) assumes viewpoints andtopics are orthogonal dimensions.
Another modelproposed by Fang et al(2012) assumes that docu-ments are already grouped by viewpoints and it fo-cus on identifying contrastive viewpoint words un-der the same topic.
However, these existing stud-ies are not based on interdependent documents likethreaded forum posts.
As a result, at least two im-portant characteristics of threaded forum data are notconsidered in these models.
(1) User identity: Theuser or publisher of each forum post is known, anda user may publish several posts in the same thread.Since the same user?s opinion on an issue usually re-mains unchanged, posts published by the same userare likely to contain the same viewpoint.
(2) Userinteractions.
A thread is like a conversation, whereusers not only directly comment on the issue underdiscussion but also comment on each other?s posts.Users having different viewpoints may express theirdisagreement or even attack each other while usershaving the same viewpoint often support each other.1031The interaction expressions in forum posts may helpus infer the relation between two users and subse-quently infer the viewpoints of the correspondingposts.In this paper, we propose a novel latent variablemodel for viewpoint discovery from threaded forumposts.
Our model is based on the following obser-vations: First, posts with different viewpoints tendto focus on different topics.
To illustrate this point,we first apply the Latent Dirichlet Allocation (LDA)model (Blei et al 2003) on a thread about ?willyou vote Obama?
and obtain a set of topics.
Thisthread comes from a data set that has each user?sviewpoint annotated.
Using the ground truth view-point labels, we group all posts published by userswith viewpoint 1 (or viewpoint 2) and compute thetopic proportions.
The two topic distributions areshown in Figure 1.
We can see that indeed the twoviewpoints each have some dominating topics.
Oursecond observations is that the same user tends tohold the same viewpoint.
In our model, we use auser-level viewpoint distribution to capture this ob-servation, and the experiments show that it worksbetter than assuming a global viewpoint distribution.Third, users with the same viewpoint are likely tohave positive interactions while users with differentviewpoints tend to have negative interactions.
Usinga sentiment lexicon, we can first predict the polarityof interaction expressions.
We then propose a novelway to incorporate this information into the latentvariable model.
In summary, we capture the threeobservations above in a principled generative latentvariable model.
We present the details of our modelin Section 3.Figure 1: Topic distributions of two viewpoints for thethread ?will you vote Obama??
The dotted line is theaverage topic probability.We use two tasks to evaluate our model.
In thefirst task, we evaluate how well posts with differ-ent viewpoints are separated.
In the second task, weevaluate how well our model is able to group userswith different viewpoints.
For both tasks, we com-pare our model with an existing model as well asa few degenerate versions of our model.
The re-sults show that our model can clearly outperform thebaselines in terms of three evaluation metrics.
Theexperiments are presented in Section 5.The contributions of our work are threefold: (1)We identify the importance of using user interac-tions to help infer viewpoints in forum posts.
(2) Wepropose a principled latent variable model to jointlymodel topics, viewpoints and user interactions.
(3)We empirically verify the validity of the three as-sumptions in our model using real data sets.2 Related WorkThere are a few different lines of work that are re-lated to our work.
For discovering different view-points from general text, Paul et al(2010) used themodel proposed by Paul and Girju (2010) to jointlymodel topics and viewpoints.
They assume thesetwo concepts are orthogonal and they do not con-sider user identity.
In comparison, our model hasthe notion of topics and viewpoints, but we explicitlymodel the dependency of topics on viewpoints, i.e.we assume each viewpoint has a topic distribution.We also consider author identities as an importantfactor of our model.
Fang et al(2012) proposed amodel that also combines topics and viewpoints.
Butthey assume that documents are already grouped byviewpoints, which is not the case for forum posts.Therefore, their model cannot be directly applied toforum posts.There has also been some work on finding view-points from social media.
Somasundaran and Wiebe(2010) studied how to identify stances in online de-bates.
They used a supervised approach for classi-fying stances in ideological debates.
In comparison,our model is an unsupervised method.
The same au-thors proposed an unsupervised method which relieson associations of aspects with topics indicative ofstances mined from the Web for the task (Somasun-daran and Wiebe, 2009).
In contrast, our model isalso an unsupervised one but we do not rely on anyexternal knowledge.Part of our work is related to detecting agree-ment/disagreement from text.
For this task, nor-1032mally supervised methods are used (Galley et al2004; Abbott et al 2011), which require sufficientlabeled training data.
In our work, since we dealwith different languages, we use a lexicon-basedapproach that does not need training data.
Re-cently, Mukherjee and Liu (2012) proposed an un-supervised model to extract different types of ex-pressions including agreement/disagreement expres-sions.
However, our focus is not to detect agree-ment/disagreement expressions but to model theinterplay between agreement/disagreement expres-sions and viewpoints.
The work by Mukherjee andLiu (2012) can potentially be combined with ourmodel.Another line of related work is subgroup detec-tion, which aims to separate users holding differentviewpoints.
This problem has recently been stud-ied by Abu-Jbara and Radev (2012), Dasigi et al(2012), Abu-Jbara et al(2012) and Hassan et al(2012), where a clustering based approach is used.Lu et al(2012) studied both textual content andsocial interactions to find opposing network fromonline forums.
In our experiments we show thatour model can also be used for subgroup detection,but meanwhile we also directly identify viewpoints,which is not the goal of existing work on subgroupfinding or opposing network extraction.3 Model3.1 MotivationBefore we formally present our latent variablemodel for viewpoint discovery, let us first look at theassumptions we would like to capture in the model.Viewpoint-based topic distribution: The first as-sumption we have is that different viewpoints tendto touch upon different topics.
This is because tosupport a viewpoint, users need to provide evidenceand arguments, and for different viewpoints the ar-guments are likely different.
To capture this assump-tion, in our model, we let each viewpoint have itsown distribution of topics.
Given the viewpoint ofa post, the hidden topic of each word in the post ischosen according to the corresponding topic distri-bution associated with that viewpoint.User identify: The second assumption we haveis that the same user tends to talk from the sameviewpoint, although there are also users who do notclearly have a viewpoint.
In our model, we assumethat there is a user-level viewpoint distribution.
Foreach post by a user, its viewpoint is drawn from thecorresponding viewpoint distribution.User interaction: An important difference betweenthreaded forum posts and regular document collec-tions such as news articles is that posts in the samethread form a tree structure via the ?reply-to?
re-lations.
Many reply posts start with an expressionthat comments on a previous post or directly ad-dresses another user.
These interaction expressionsmay carry positive or negative sentiment, indicatingan agreement or a disagreement.
For example, Ta-ble 1 shows the interaction expressions from a fewsample posts with words such as ?correct,?
?agree,?and ?delusional,?
implying the polarity of the inter-action expressions.
The polarity of these interactionexpressions can help us infer whether two posts ortwo users hold the same viewpoint or not.
In ourmodel, we assume that the polarity of each interac-tion expression can be detected.
Details of how weperform this detection are in Section 3.4.Post+You are correct.
Obama got into office w/ everything ?
?
?I agree with your post Dan.
Obama is so ?
?
?
?Most of your post is delusional, especially the part ?
?
?Are you freaking nutz?
Palin is a BIMBO!Table 1: Sample posts with positive (+) and negative(?
)interactions.While the way to capture the first two assump-tions discussed above is fairly standard, modelinguser interactions is something new.
In our model,we assume that the polarity of an interaction expres-sion is generated based on the viewpoint of the cur-rent post and the viewpoint of post(s) that the currentpost replies to.
The intuition is that if the viewpointsare the same, we are more likely to see a positive in-teraction whereas if the viewpoints are different weare more likely to see a negative interaction.3.2 Model descriptionWe use the following notation to represent our data.We consider a set of forum posts published by U dif-ferent users on the same event or issue, where useru (1 ?
u ?
U ) has published Nu posts.
Let wu,n,l(1 ?
l ?
Lu,n ) denote the l-th word in the n-thpost by user u, where Lu,n is the number of words1033in the n-th post by user u. wu,n,l is represented byan index between 1 and V where V is the vocabu-lary size.
Furthermore, we assume that some of theposts have user interaction expressions, where thepolarity of the expression is known.
Without loss ofgenerality, let su,n ?
{0, 1} denote the polarity ofthe interaction expression of the n-th post by useru.
In addition, for each post that has an interactionexpression, we assume we also know the previouspost(s) it replies to.
(In the case when the currentpost replies to a user, we assume all that user?s ex-isting posts are being replied to.)
We refer to theseposts as the parent posts of the current post.We assume that there are T topics where eachtopic is essentially a word distribution, denoted as?t.
We also assume that there are Y different view-points expressed in the collection of posts.
For mostcontroversial issues, Y can be set to 2.
Each view-point y has a topic distribution ?y over the T top-ics.
While these T topics are meant to capture thetopical differences between viewpoints, since theseviewpoints are all about the same issue, there arealso some words commonly used by different view-points.
We therefore introduce a background topic?B to capture these words.
Finally, each user u hasa distribution over the Y viewpoints, denoted as ?u.Figure 2: Plate notation of the Joint Viewpoint-TopicModel with User Interaction (JVTM-UI).
The dotted cir-cle for Y means the variables represented by Y are notnew variables but a subset of the y variables.Figure 2 shows the plate notation of the completemodel.
We assume the following generation processin our model.
When user u generates her n-th post,she first samples a viewpoint from ?u.
Let this view-point be represented by a hidden variable yu,n.
Forthe l-th word in this post, she first samples an in-dicator variable xu,n,l from a Bernoulli distributionparameterized by pi.
If xu,n,l = 0, then she drawswu,n,l from ?B .
Otherwise, she first samples a topic,denoted as zu,n,l, according to ?yu,n , and then drawswu,n,l from ?zu,n,l .Furthermore, if this post is a reply to a previouspost or another user, she may first comment on theparent post(s).
The polarity of the interaction ex-pression in the post is dependent on the viewpointyu,n and the viewpoints of the previous post(s).
Letus use Yu,n to denote the set of y variables associ-ated with the parent posts of the current post.
Theuser draws su,n according to following distribution:p(su,n = 1|yu,n,Yu,n, ?)
=?y?
?Yu,nI(yu,n == y?)
+ ?|Yu,n|+ 2?,p(su,n = 0|yu,n,Yu,n, ?)
= 1?
p(su,n = 1|yu,n,Yu,n, ?
), (1)where I(?)
is 1 if the statement inside is true and 0otherwise, and ?
> 0 is a smoothing parameter.Finally, we assume that ?B , ?t, ?u, ?y and pi allhave some uniform Dirichlet priors.3.3 InferenceWe use collapsed Gibbs sampling to estimate themodel parameters.
In the initialization stage ofGibbs sampling, for a reply post to a recipient, weinitialize its corresponding reply polarity s accord-ing to all the labeled polarity of interaction words.Specifically, if the majority of labeled interactionwords are positive, we set s = 1, otherwise we sets = 0.Let Y denote the set of all y variables, andY?
(u,n) denote Y excluding yu,n.
Similar notationis used for the other variables.
We sample yu,n usingthe following formula.p(yu,n = k|Y?
(u,n),Z,S,X, ?, ?, ?
)?p(yu,n = k,Y?(u,n)|?)p(Y?(u,n)|?
)?p(Z|yu,n = k,Y?
(u,n),X, ?)p(Z?(u,n)|Y?(u,n),X?
(u,n), ?
)?p(S|yu,n = k,Y?
(u,n), ?
)=Cku,?n + ?C(?
)u,?n + Y ??
?Tt=1?Ctu,n?1a=0 (Ctk,?
(u,n) + ?
+ a)?C(?
)u,n?1b=0 (C(?)k,?
(u,n) + T?
+ b)?p(S|yu,n = k,Y?
(u,n), ?).
(2)Here all Cs are counters.
Cku,?n is the number oftimes we observe the viewpoint k from u?s posts,excluding the n-th post, based on Y?(u,n).
Ctu,n is1034the number of times we observe topic t from useru?s n-th post, based on Zu,n.
And Ctk,?
(u,n) is thenumber of times we observe topic t associated withviewpoint k, excluding user u?s n-th post.
Note thatwe need X to know which words are assigned tothe background topic so we can exclude them forCtu,n and Ctk,?(u,n).
C(?
)u,?n is the number of times weobserve any viewpoint from u?s posts, excluding then-th post.
C(?
)u,n and C(?)k,?
(u,n) are defined similarly.The last term is further expanded as follows:p(S|yu,n = k,Y?
(u,n), ?)
= p(su,n|yu,n = k,Yu,n, ?)?p(S?
(u,n)|yu,n = k,Y?
(u,n), ?).
(3)Here p(su,n|yu,n = k,Yu,n, ?)
is computed ac-cording to Eqn.
(1).
For the latter term, we need toconsider posts which reply to user u?s n-th post be-cause the value of yu,n affects these posts.p(S?
(u,n)|yu,n = k,Y?
(u,n), ?)??(u?,n?):yu,n?Yu?,n?p(su?,n?
|yu?,n?
,Yu?,n?
, ?).
(4)Next, we show how we jointly sample xu,n,land zu,n,l.
We jointly sample them because whenxu,n,l = 0, zu,n,l does not need a value.
We have thefollowing formulas:p(xu,n,l = 1, zu,n,l = t|X?(u,n,l),Z?
(u,n,l),Y,W, ?, ?, ?, ?B)?C1?
(u,n,l) + ?C(?)?
(u,n,l)+ 2??Ctyu,n,l,?
(u,n,l)+ ?C(?)yu,n,l,?
(u,n,l)+ T??Cwu,n,lt,?
(u,n,l)+ ?C(?)t,?
(u,n,l)+ V ?, (5)p(xu,n,l = 0|X?(u,n,l),Z?
(u,n,l),Y,W, ?, ?, ?, ?B)?C0?
(u,n,l) + ?C(?)?
(u,n,l)+ 2??Cwu,n,lB,?
(u,n,l)+ ?BC(?)B,?
(u,n,l)+ V ?B.
(6)Here again the Cs are counters defined in similarways as before.
For example, C1?
(u,n,l) is the num-ber of times we observe 1 assigned to an x variable,excluding xu,n,l.3.4 Interaction polarity predictionThe problem of detecting agreement and disagree-ment from forum posts is relatively new.
One pos-sible solution is to use supervised learning, whichrequires training data (Galley et al 2004; Abbott etal., 2011; Andreas et al 2012).
However, trainingdata are also likely domain and language dependent,which makes them hard for re-use.
For our task, wetake a simpler approach and use a sentiment lexicontogether with some heuristics to predict the polar-ity of interaction expressions.
Specifically, we firstidentify interaction sentences following the strate-gies from Hassan et al(2012).
We assume sentencescontaining mentions of the recipient of a post are in-teraction sentences.
Next, we consider words withina text window of 8 words surrounding these men-tions.
We then use a subjectivity lexicon to labelthese words.
To form an English lexicon, we com-bine three popular lexicons: the sentiment lexiconused by Hu and Liu (2004), Multi-Perspective Ques-tion Answering Subjectivity Lexicon by Wilson etal.
(2005) and SentiWordNet by Baccianella et al(2010).
Since we also work with a Chinese data set,to form the Chinese sentiment lexicon, we use opin-ion words from HowNet2 and NTUSD by Ku et al(2007).
To predict the polarity of an interaction ex-pression, we simply check whether there are morepositive sentiment words or more negative sentimentwords in the expression, and label the interaction ex-pression accordingly.We would like to stress that since this interactionclassification step is independent of the latent vari-able model, we can always apply a more accuratemethod, but this is not the focus of this work.4 Models for ComparisonIn our experiments, we compare our model,Joint Viewpoint-Topic Model with User Interaction(JVTM-UI), with the following baseline models.JVTM: The model is shown in Figure 3(a), a variantof JVTM-UI that does not consider user interaction.Through comparison with it, we can check the effectof modeling user interactions.JVTM-G: We consider JVTM-G in Figure 3(b), avariant of JVTM which assumes a global viewpointdistribution.
Comparison with it allows us to checkthe usefulness of user identity in the task.UIM: The third model we consider is a User Interac-tion Model (UIM) in Figure 3(c), where we rely ononly the users?
interactions to infer the viewpoints.We use it to check how well viewpoints can be dis-covered from only user interaction expressions.2http://www.keenage.com/html/e_index.html1035Figure 3: (a) JVTM: Joint Viewpoint-Topic Model.
(b) JVTM-G: JVTM with a global viewpoint distribution.
(c)UIM: User-Interaction Model.TAM: The last model we consider is the one by Paulet al(2010).
As TAM is applied at document collec-tions, we first concatenate all the posts by the sameuser into a pseudo document and then apply TAM.5 Experiments and AnalysisIn this section, we evaluate our model with a set ofbaseline models using two data sets.Name Issue #Posts #UsersEDS1 Vote for Obama 2599 197EDS2 Arizona Immigration Law 738 59EDS3 Tax Cuts 276 26CDS1 Tencent and Qihoo dispute 30137 2507CDS2 Fang Zhouzi questions Han Han 76934 1769CDS3 Liu Xiang in London Olympics 29486 2774Table 2: Some statistics of the data set.5.1 Data Sets and Experimental SettingsWe focus our work on finding users?
viewpoints ona controversial issue, where we assume that thereare two contradictory viewpoints.
We use two datasets on controversial issues.
The first data set comesfrom Abu-Jbara et al(2012) and Hassan et al(2012).
This data set originally was used for findingsubgroups of users, so the annotations were done atuser level, i.e.
for each user there is a label indicat-ing which subgroup he/she belongs to.
We use thetop-3 mostly discussed threads with two subgroupsfor our study.In reality, controversial issues are often discussedacross threads.
We thus constructed another largedata set which contains more than one thread foreach issue.
We chose three hot issues from one ofthe most popular Chinese online forums ?
TianYaClub3.
The three issues are ?Fang Zhouzi questionsHan Han?4, ?Tencent and Qihoo dispute?5, and ?LiuXiang in London Olympics?6.
All these issues trig-gered heated discussions on the forum and we foundthat most of the users were divided into two differentgroups.We crawled the data set using the TianYa API7.The API allows users to issue queries and get threadsmost related to the queries.
For each issue, we usedentities involved in the event as queries and obtained750 threads for each query.
We then extracted all theposts in the threads.
As there are users who postedirrelevant posts in the forum, we then filtered outthose users who did not mention the entities or hadfewer than 4 posts.We refer to the first set of data in English as EDS1,EDS2 and EDS3, and the second set of data in Chi-nese as CDS1, CDS2 and CDS3.
Some statistics ofthe resulting data set are shown in Table 2.For all the models, we set Y = 2.
We set T = 10for the English data sets and T = 40 for the Chinesedata sets.
We run 400 iterations of Gibbs samplingas burn-in iterations and then take 100 samples witha gap of 5 to obtain our final results.
We empiricallyset ?
= 0.01, ?B = 0.1, ?
= 10 and ?
= 0.1 for ourmodel on all the data sets.
?
and ?
are set throughgrid search where they take values in {0.01, 0.001}.For each data set, we choose the best setting for eachmodel and report the corresponding results.3http://en.wikipedia.org/wiki/Tianya_Club4http://en.wikipedia.org/wiki/Fang_Zhouzi5http://en.wikipedia.org/wiki/360_v._Tencent6http://en.wikipedia.org/wiki/Liu_Xiang7http://open.tianya.cn/index.php10365.2 Identification of viewpointsWe first evaluate the models on the task of identi-fying viewpoints.
For fair comparison, each modelwill output a viewpoint label for each post.
ForJVTM-UI, JVTM, JVTM-G and UIM, after we learnthe model, each post will directly have a viewpointassignment.
For TAM we cannot directly get eachpost?s viewpoint as the model assumes a document-level viewpoint distribution.
To estimate each post?sviewpoint in this model, we use viewpoint assign-ment at the word level learnt from the model.
Thenfor each post, we label its viewpoint as the viewpointthat has the majority count in the post.Ideally, we would like to manually label all theposts to obtain the ground truth for evaluation.
Sincethere are too many posts, we only labeled a sampleof them.
For each issue, we randomly selected 150posts to label their viewpoints.
For each post, weasked two different annotators to label its viewpoint.We made sure that the annotators understand the is-sue and the two major viewpoints before they anno-tated the posts.
Specifically, as the Chinese data setsare about some controversial issues around the enti-ties involved, we then defined two major viewpointsas support and not support the entity who initiatedthe event.
The entities of data set CDS1, CDS2 andCDS3 are Fang Zhouzi, Tencent and Liu Xiang re-spectively.
For each given post, the annotators wereasked to judge whether the post has expressed view-points and if so, what is its corresponding view-point.
We measure the agreement score using Co-hen?s kappa coefficient.
The lowest agreement scorefor an issue is 0.61 in the data set, showing goodagreement.
We then used the set of posts that werelabeled with the same viewpoint by the two annota-tors as our evaluation data for all the models.Since our task is essentially a clustering problem,we use purity and entropy to measure the perfor-mance (Manning et al 2008).
Furthermore, we alsouse accuracy where we choose the better alignmentof clusters with ground truth class labels and com-pute the percentage of posts that are ?classified?
cor-rectly.
For purity and accuracy, the higher the mea-sure is the better the performance.
For entropy, thelower the measure is the better the performance.We give an overview of the all the averaged modelresults on the data sets in Figure 4.
We observed that0.40.60.81.0Purity Entropy AccuracyJVTM-GTAMJVTMUIMJVTM-UIFigure 4: Averaged results of the models in identificationof viewpoints.UIM performs relatively better than other methodsexcept our model.
This shows user interactions areimportant features to identify post viewpoints.
Over-all, our model has a better performance as it is withhigher purity and accuracy, and lower entropy.JVTM-UI UIM JVTM TAM JVTM-GEDS1P 0.77 0.74 0.64 0.65 0.63E 0.72 0.76 0.90 0.92 0.94A 0.77 0.74 0.61 0.60 0.57EDS2P 0.82 0.78 0.68 0.65 0.64E 0.69 0.73 0.79 0.86 0.90A 0.81 0.78 0.68 0.68 0.65EDS3P 0.79 0.73 0.65 0.64 0.62E 0.67 0.79 0.88 0.89 0.87A 0.79 0.73 0.65 0.64 0.62CDS1P 0.87 0.83 0.83 0.82 0.82E 0.61 0.64 0.65 0.66 0.64A 0.60 0.58 0.59 0.58 0.57CDS2P 0.71 0.65 0.61 0.63 0.60E 0.80 0.85 0.92 0.95 0.96A 0.71 0.65 0.61 0.61 0.59CDS3P 0.78 0.78 0.78 0.78 0.78E 0.73 0.75 0.70 0.72 0.73A 0.67 0.59 0.67 0.66 0.63Table 3: Results on viewpoint identification on the alldata sets.Table 3 shows the detailed results on the datasets.
We perform the 2-tailed paired t-test as usedby Abu-Jbara et al(2012) on the results.
All the re-sult differences are at 10% significance level if notwith further clarification.
First, JVTM has a betterperformance over JVTM-G, which shows it is im-portant to consider user identity in the task.
Sec-ond, JVTM and TAM have similar performance on1037EDS1 and CDS2, but JVTM has a relatively bet-ter performance on EDS2, EDS3, CDS1 and CDS3.This shows it is helpful to consider each viewpoint?stopic preference.
Although as studied by Paul etal.
(2010), by only using unigram features, TAMmay not be able to cluster viewpoints accurately,our study shows that the results can be improvedwhen adding each viewpoint?s topic focus.
Third,UIM has relatively better performance than the othermodels, which demonstrates that user interactionsalone can do a decent job in inferring viewpoints.
Fi-nally, our proposed model has the best performanceacross the board in terms of all three evaluation met-rics.
Note that, our proposed model significantlyoutperforms other methods at 5% significance levelexcept at 10% significance level over JVTM model.This shows by jointly modeling topics, viewpointsand user interactions, our model can better identifyposts with different viewpoints.5.3 Identification of user groupsWe also use another task to evaluate our model.The task here is finding each user?s viewpoint andsubsequently grouping users by their viewpoints.This task has been studied by Abu-Jbara and Radev(2012), Dasigi et al(2012), Abu-Jbara et al(2012)and Hassan et al(2012).
For the English data set,the user-level group labels are provided by the orig-inal data set.
For the Chinese data set, we randomlyselected 150 users for each issue and manually la-beled them according to their viewpoints as reflectedby their posts.
If a user?s posts do not clearly suggesta viewpoint, we label her as neutral.
Again we askedtwo human judges to do annotation.
The agreementscores are above 0.70 for all issues, showing sub-stantial agreement.
This score is higher than view-point identification, which suggests that it is easierto judge a user?s viewpoint than a single post?s view-point.
We use the set of users who have got the samelabels by the two human judges for our experiments.Similarly we compute purity, entropy and accuracyto evaluate the clustering results.Figure 5 shows the averaged results of all themodels.
Similar to previous experiment, our modelhas a better performance compared to the competingmodels.The results on the each data set are shown in Ta-ble 4.
The tables show that similar trends can be0.40.60.81.0Purity Entropy AccuracyJVTM-GTAMJVTMUIMJVTM-UIFigure 5: Averaged results of the models in identificationof user groups.JVTM-UI UIM JVTM TAM JVTM-GEDS1P 0.67 0.67 0.67 0.67 0.67E 0.85 0.88 0.89 0.89 0.91A 0.63 0.59 0.58 0.59 0.57EDS2P 0.77 0.77 0.77 0.77 0.77E 0.72 0.76 0.74 0.75 0.76A 0.62 0.59 0.60 0.58 0.59EDS3P 0.68 0.63 0.61 0.61 0.58E 0.90 0.92 0.95 0.96 0.97A 0.68 0.63 0.61 0.58 0.57CDS1P 0.64 0.60 0.61 0.61 0.60E 0.91 0.97 0.96 0.96 0.97A 0.61 0.55 0.55 0.56 0.53CDS2P 0.69 0.69 0.69 0.69 0.69E 0.83 0.89 0.85 0.89 0.89A 0.62 0.57 0.56 0.58 0.54CDS3P 0.67 0.63 0.64 0.60 0.60E 0.89 0.91 0.92 0.93 0.96A 0.64 0.62 0.60 0.56 0.54Table 4: Results on identification of user groups on theall the data sets.observed for the task of user group identification.We also perform the 2-tailed paired t-test on the re-sults.
We find our model significantly outperformsother models in terms of accuracy at 5% significancelevel, and purity and entropy at 10% significancelevel.
Overall speaking, our joint model performedthe best among all the models for this task for allthree metrics.
This shows that it is important to con-sider the topical preference of individual viewpoint,user?s identify as well as the interactions betweenusers.1038Figure 6: The user interaction network in a discussionthread about ?will you vote obama.?
Green (left) andwhite (right) nodes represent users with two differentviewpoints.
Red (thin) and blue(thick) edges representnegative and positive interactions.5.4 User interaction networkTo gain some direct insight into our results, we showthe user interaction network from one thread in Fig-ure 6.
Here each node denotes a user, and its colordenotes the predicted viewpoint of that user.
A linkbetween a pair of users means these users have in-teractions and the interaction types have a dominantpolarity.
The polarities of these links are predictedusing the interaction expressions and a sentimentlexicon, whereas the viewpoints of different usersare learned by JVTM-UI, making use of the inter-action polarities.
The figure shows that clearly thereare mostly positive interactions between users withthe same viewpoint and mostly negative interactionsbetween users with different viewpoints.
Note that,our method to identify user interaction polarity isrule-based.
As this step serves as a preprocessingstep for our latent variable model, we can alwaysuse a more accurate method to improve the perfor-mances.6 ConclusionIn this work, we proposed a novel latent variablemodel for viewpoint discovery from threaded forumposts.
Our model is based on the three important fac-tors: viewpoint specific topic preference, user iden-tity and user interactions.
Our proposed model cap-tures these observations in a principled way.
In par-ticular, to incorporate the user interaction informa-tion, we proposed a novel generative process.
Em-pirical evaluation on the real forum data sets showedthat our model could cluster both posts and userswith different viewpoints more accurately than thebaseline models we consider.
To the best of ourknowledge, our work is the first to incorporate userinteraction polarity into a generative model to dis-cover viewpoints.In this work, we only considered unigrams.
Assome previous work has shown, more complex lexi-cal units such as n-grams (Mukherjee and Liu, 2012)and dependency triplets (Paul et al 2010) may im-prove the performance of topic models.
We will con-sider these strategies in our future work.
Currentlywe use a simple heuristic-based classifier to predictinteraction polarity.
In our further work, we planto consider more accurate methods using deeper lin-guistic analysis.
We did not study how to summarizethe discovered viewpoints in this work, which is alsosomething we will look into in our future work.AcknowledgmentsWe thank the reviewers for their valuable commentson this work.
We also thank Shuang Xia for his helpon processing and labeling the data sets.ReferencesRob Abbott, Marilyn Walker, Pranav Anand, Jean E.Fox Tree, Robeson Bowmani, and Joseph King.
2011.How can you say such things?!?
: Recognizing dis-agreement in informal political argument.
In Proceed-ings of the Workshop on Language in Social Media(LSM 2011), pages 2?11.Amjad Abu-Jbara and Dragomir R. Radev.
2012.
Sub-group detector: A system for detecting subgroups inonline discussions.
In ACL (System Demonstrations),pages 133?138.Amjad Abu-Jbara, Pradeep Dasigi, Mona Diab, andDragomir R. Radev.
2012.
Subgroup detection inideological discussions.
In Proceedings of ACL 2012,pages 399?409.Jacob Andreas, Sara Rosenthal, and Kathleen McKe-own.
2012.
Annotating agreement and disagreementin threaded discussion.
In Proceedings of LREC?12.Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-tiani.
2010.
Sentiwordnet 3.0: An enhanced lexicalresource for sentiment analysis and opinion mining.
InLREC.David M. Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent dirichlet alcation.
J. Mach.
Learn.Res., 3:993?1022.Pradeep Dasigi, Weiwei Guo, and Mona T. Diab.
2012.Genre independent subgroup detection in online dis-cussion threads: A study of implicit attitude using1039textual latent semantics.
In Proceedings of the 50thAnnual Meeting of the Association for ComputationalLinguistics, pages 65?69.Yi Fang, Luo Si, Naveen Somasundaram, and ZhengtaoYu.
2012.
Mining contrastive opinions on politicaltexts using cross-perspective topic model.
In WSDM,pages 63?72.Michel Galley, Kathleen McKeown, Julia Hirschberg,and Elizabeth Shriberg.
2004.
Identifying agreementand disagreement in conversational speech: Use ofbayesian networks to model pragmatic dependencies.In Proceedings of ACL?04, Main Volume, pages 669?676.Ahmed Hassan, Amjad Abu-Jbara, and Dragomir Radev.2012.
Detecting subgroups in online discussions bymodeling positive and negative relations among par-ticipants.
In Proceedings of the 2012 EMNLP, pages59?70.Minqing Hu and Bing Liu.
2004.
Mining and summariz-ing customer reviews.
In Proceedings of the 10th ACMSIGKDD international conference on Knowledge dis-covery and data mining, pages 168?177.Lun-wei Ku, Yong-sheng Lo, and Hsin-hsi Chen.
2007.Using polarity scores of words for sentence-level opin-ion extraction.
In Proc.
of the NTCIR-6 WorkshopMeeting, pages 316?322.Yue Lu, Hongning Wang, ChengXiang Zhai, and DanRoth.
2012.
Unsupervised discovery of opposingopinion networks from forum discussions.
In Pro-ceedings of the 21st ACM international conference onInformation and knowledge management, CIKM ?12,pages 1642?1646, New York, NY, USA.
ACM.Christopher D. Manning, Prabhakar Raghavan, and Hin-rich Schtze.
2008.
Introduction to Information Re-trieval.
Cambridge University Press, July.Arjun Mukherjee and Bing Liu.
2012.
Modeling reviewcomments.
In Proceedings of the 50th Annual Meet-ing of the Association for Computational Linguistics,pages 320?329.Michael J. Paul and Roxana Girju.
2010.
A two-dimensional topic-aspect model for discovering multi-faceted topics.
In AAAI.Michael J. Paul, ChengXiang Zhai, and Roxana Girju.2010.
Summarizing contrastive viewpoints in opin-ionated text.
In EMNLP, pages 66?76.Swapna Somasundaran and Janyce Wiebe.
2009.
Rec-ognizing stances in online debates.
In Proceedingsof the Joint Conference of the 47th Annual Meetingof the ACL and the 4th International Joint Conferenceon Natural Language Processing of the AFNLP, pages226?234.Swapna Somasundaran and Janyce Wiebe.
2010.
Recog-nizing stances in ideological on-line debates.
In Pro-ceedings of the NAACL HLT 2010 Workshop on Com-putational Approaches to Analysis and Generation ofEmotion in Text, pages 116?124.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.2005.
Recognizing contextual polarity in phrase-levelsentiment analysis.
In HLT/EMNLP.1040
