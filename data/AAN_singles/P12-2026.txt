Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 130?134,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsLearning to Find Translations and Transliterations on the WebJoseph Z. Chang Jason S. Chang Jyh-Shing Roger JangDepartment of Computer Science, Department of Computer Science, Department of Computer Science,National Tsing Hua University National Tsing Hua University National Tsing Hua University101, Kuangfu Road,Hsinchu, 300, Taiwan101, Kuangfu Road,Hsinchu, 300, Taiwan101, Kuangfu Road,Hsinchu, 300, Taiwanjoseph.nthu.tw@gmail.com jschang@cs.nthu.edu.tw jang@cs.nthu.edu.twAbstractIn this paper, we present a new methodfor learning to finding translations andtransliterations on the Web for a giventerm.
The approach involves using a smallset of terms and translations to obtainmixed-code snippets from a search engine,and automatically annotating the snippetswith tags and features for training aconditional random field model.
At run-time, the model is used to extractingtranslation candidates for a given term.Preliminary experiments and evaluationshow our method cleanly combiningvarious features, resulting in a system thatoutperforms previous work.1 IntroductionThe phrase translation problem is critical tomachine translation, cross-lingual informationretrieval, and multilingual terminology (Bian andChen 2000, Kupiec 1993).
Such systems typicallyuse a parallel corpus.
However, the out ofvocabulary problem (OOV) is hard to overcomeeven with a very large training corpus due to theZipf nature of word distribution, and ever growingnew terminology and named entities.
Luckily,there are an abundant of webpages consistingmixed-code text, typically written in one languagebut interspersed with some sentential or phrasaltranslations in another language.
By retrieving andidentifying such translation counterparts on theWeb, we can cope with the OOV problem.Consider the technical term named-entityrecognition.
The best places to find the Chinesetranslations for named-entity recognition areprobably not some parallel corpus or dictionary,but rather mixed-code webpages.
The followingexample is a snippet returned by the Bing searchengine for the query, named entity recognition:...
??????????????
(Natural LanguageParsing)?????
(Question Classification)?????
(Named Entity Recognition)??
...This snippet contains three technical terms inChinese (i.e., ??????
zhiran yuyan poxi,????
wenti fenlei, ????
zhuanmingbianshi), followed by source terms in brackets(respectively, Natural Language Parsing, QuestionClassification, and Named Entity Recognition).Quoh (2006) points out that submitting the sourceterm and partial translation to a search engine is agood strategy used by many translators.Unfortunately, the user still has to sift throughsnippets to find the translations.
For a givenEnglish term, such translations can be extracted bycasting the problem as a sequence labeling task forclassifying the Chinese characters in the snippetsas either translation or non-translation.
Previouswork has pointed out that such translations usuallyexhibit characteristics related to word translation,word transliteration, surface patterns, andproximity to the occurrences of the original phrase(Nagata et.
al 2001 and Wu et.
al 2005).130Thus, we also associate features to each Chinesetoken (characters or words) to reflect the likelihoodof the token being part of the translation.
Wedescribe how to train a CRF model for identifyingtranslations in more details in Section 3.At run-time, the system accepts a given phrase(e.g., named-entity recognition), and then query asearch engine for webpages in the target  language(e.g., Chinese) using the advance search function.Subsequently, we retrieve mixed-code snippets andidentify the translations of the given term.
Thesystem can potentially be used to assist translatorsto find the most common translation for a giventerm, or to supplement a bilingual terminologybank (e.g., adding multilingual titles to existingWikipedia); alternatively, they can be used asadditional training data for a machine translationsystem, as described in Lin et al (2008).2 Related WorkPhrase translation and transliteration is importantfor cross-language tasks.
For example, Knight andGraehl (1998) describe and evaluate a multi-stagemachine translation method for back transliteratingEnglish names into Japanese, while Bian and Chen(2000) describe cross-language information accessto multilingual collections on the Internet.Recently, researchers have begun to exploitmixed code webpages for word and phrasetranslation.
Nagata et al (2001) present a systemfor finding English translations for a givenJapanese technical term using Japanese-Englishsnippets returned by a search engine.
Kwok et al(2005) focus on named entity transliteration andimplemented a cross-language name finder.
Wu etal.
(2005) proposed a method to learn surfacepatterns to find translations in mixed code snippets.Some researchers exploited the hyperlinks inWebpage to find translations.
Lu, et al (2004)propose a method for mining translations of webqueries from anchor texts.
Cheng, et al(2004)propose a similar method for translating unknownqueries with web corpora for cross-languageinformation retrieval.
Gravano (2006) also proposesimilar methods using anchor texts.In a study more closely related to our work, Linet al (2008) proposed a method that performsword alignment between translations and phraseswithin parentheses in crawled webpages.
They useheuristics to align words and translations, while weToken TR TL Distance Label?
0 0 14 O62 0 0 13 O 62th ?
0 0 12 O?
3 0 11 BEmmy ?
3 0 10 IAward ?
0 5 9 I?
0 0 8 Oawarding ?
0 0 7 O?
0 0 6 Oceremony ?
0 0 5 O?
0 0 4 O(           0 0 3 O the         0 0 2 O62th       0 0 1 OEmmy 0 0 0 EAward 0 0 0 E)        0 0 -1 OFigure 1.
Example training data.use a learning based approach to find translations.In contrast to previous work described above,we exploit surface patterns differently as a softconstraint, while requiring minimal humanintervention to prepare the training data.3 MethodTo find translations for a given term on the Web, apromising approach is automatically learning toextract phrasal translations or transliterations ofphrase based on machine learning, or morespecifically the conditional random fields (CRF)model.We focus on the issue of finding translations inmixed code snippets returned by a search engine.The translations are identified, tallied, ranked, andreturned as the output of the system.3.1 Preparing Data for CRF ClassifierWe make use a small set of term and translationpairs as seed data to retrieve and annotate mixed-code snippets from a search engine.
Features aregenerated based on other external knowledgesources as will be described in Section 3.1.2 and3.1.3.
An example data generated with given termEmmy Award with features and translation/non-translation labels is shown in Figure 1 using thecommon BIO notation.3.1.1 Retrieving and tagging snippets.
We use alist of randomly selected source and target terms asseed data (e.g., Wikipedia English titles and their131Chinese counterpart using the language links).
Weuse the English terms (e.g., Emmy Awards) toquery a search engine with the target webpagelanguage set to the target language (e.g., Chinese),biasing the search engine to return Chinesewebpages interspersed with some English phrases.We then automatically label each Chinesecharacter of the returned snippets, with B, I, Oindicating respectively beginning, inside, andoutside of translations.
In Figure 1, the translation???
(ai mei jiang) are labeled as B I I, while allother Chinese characters are labeled as O.   Anadditional tag of E is used to indicate theoccurrences of the given term (e.g., Emmy Awardsin Figure 1).3.1.2 Generating translation feature.
Wegenerate translation features using externalbilingual resources.
The ?2 score proposed by Galeand Church (1991) is used to measure thecorrelations between English and Chinese tokens:where e is an English word and f is a Chinesecharacter.
The scores are calculated by countingco-occurrence of Chinese characters and Englishwords in bilingual dictionaries or termbanks,where P(e, f) represents the probability of the co-occurrence of English word e and Chinesecharacter f, and P(e, ?f) represents the probabilitythe co-occurrence of e and any Chinese charactersexcluding  f.We used the publicly available English-ChineseBilingual WordNet and NICT terminology bank togenerate translation features in ourimplementation.
The bilingual WordNet has99,642 synset entries, with a total of some 270,000translation pairs, mainly common nouns.
TheNICT database has over 1.1 million bilingual termsin 72 categories, covering a wide variety ofdifferent fields.3.1.3 Generating transliteration feature.
Sincemany terms are transliterated, it is important toinclude transliteration feature.
We first use a list ofname transliterated pairs, then use Expectation-Maximization (EM) algorithm to align Englishsyllables Romanized Chinese characters.
Finally,we use the alignment information to generatetransliteration feature for a Chinese token withrespect to English words in the query.We extract person or location entries inWikipedia as name transliterated pairs to generatetransliteration features in our implementation.
Thiscan be achieved by examining the Wikipediacategories for each entry.
A total of some 15,000bilingual names of persons and 24,000 bilingualplace names were obtained and forced aligned toobtain transliteration relationships.3.1.4 Generating distance feature.
In the finalstage of preparing training data, we add thedistance, i.e.
number of words, between a Chinesetoken feature and the English term in question,aimed at exploiting the fact that translations tend tooccur near the source term, as noted in Nagata etal.
(2001) and Wu et al (2005).Finally, we use the data labeled with translationtags and three kinds feature values to train a CRFmodel.3.2 Run-Time Translation ExtractionWith the trained CRF model, we then attempt tofind translations for a given phrase.
The systembegins by submitting the given phrase as query to asearch engine to retrieve snippets, and generatefeatures for each tokens in the same way as done inthe training phase.
We then use the trained modelto tag the snippets, and extract translationcandidates by identifying consecutive Chinesetokens labeled as B and I.Finally, we compute the frequency of all thecandidates identified in all snippets, and output theone with the highest frequency.4 Experiments and EvaluationWe extracted the Wikipedia titles of English andChinese articles connected through language linksfor training and testing.
We obtained a total of155,310 article pairs, from which we thenrandomly selected 13,150 and 2,181 titles as seedsto obtain the training and test data.
Since we areusing Wikipedia bilingual titles as the goldstandard, we exclude any snippets from thewikipedia.org domain, so that we are not usingWikipedia article content in both training andtesting stage.
The test set contains 745,734snippets or 9,158,141 tokens (Chinese character orEnglish word).
The reference answer appeared atotal of 48,938 times or 180,932 tokens (2%), andan average of 22.4 redundant answer instances perinput.132System Coverage Exact match Top5 exact matchFull (En-Ch) 80.4% 43.0% 56.4%-TL 83.9% 27.5% 40.2%-TR 81.2% 37.4% 50.3%-TL-TR 83.2% 21.1% 32.8%LIN En-Ch 59.6% 27.9% not reportedLIN Ch-En 70.8% 36.4% not reportedLCD (En-Ch) 10.8% 4.8% N/ANICT (En-Ch) 24.2% 32.1% N/ATable 1.
Automatic evaluation results of  8 experiments:(1) Full system (2-4)  -TL,  -TR, -TL-TR : Full systemdeprecating TL, TR, and TL+TL features (5,6) LIN En-Ch and En-Ch : the results in Lin et al (2008) (6) LDC:LDC E-C dictionary (7) NICT : NICT term bank.English Wiki Chinese Wiki Extracted Ev.Pope Celestine IV  ??????
??????
AFujian  ???
??
AWaste  ??
??
ACollateral  ????
??
BLudwig Erhard  ????????
???
POsman I  ?????
???
PBubble sort  ????
??
PThe Love Suicidesat Sonezaki?????
????
EAmmonium  ?
????
ETable 2.
Cases failing the exact match test.Result Count PercentageA+B: correct 53 55.8%P: partially corr.
30 31.6%E: incorrect 8 8.4%N: no results 4 4.2%total 95 100%Table 3.
Manual evaluation of unlink titles.To compare our method with previous work, weused a similar evaluation procedure as described inLin et al (2008).
We ran the system and producedthe translations for these 2,181 test data, andautomatically evaluate the results using the metricsof coverage, i.e.
when system was able to producetranslation candidates, and exact match precision.This precision rate is an under-estimations, sincea term may have many alternative translations thatdoes not match exactly with one single referencetranslation.
To give a more accurate estimate ofreal precision, we resorted to manual evaluation ona small part of the 2,181 English phrases and asmall set of English Wikipedia titles without aChinese language link.4.1 Automatic EvaluationIn this section, we describe the evaluation based onEnglish-Chinese titles extracted from Wikipedia asthe gold standard.
Our system produce the top-1translations by ranking candidates by frequencyand output the most frequent translations.
Table 1shows the results we have obtained as compared tothe results of Lin et al (2008).Table 1 shows the evaluation results of 8experiments.
The results indicate that usingexternal knowledge to generate feature improvessystem performance significantly.
By addingtranslation feature (TL) or transliteration feature(TR) to the system with no external knowledgefeatures (-TL-TR) improves exact match precisionby about 6% and 16% respectively.
Because manyWikipedia titles are named entities, transliterationfeature is the most important.
Overall, the systemwith full features perform the best, findingreasonably correct translations for 8 out of 10phrases.4.2 Manual EvaluationEvaluation based on exact match against a singlereference answer leads to under-estimation,because an English phrase is often translated intoseveral Chinese counterparts.
Therefore, we askeda human judge to examine and mark the outputs ofour full system.
The judge was instructed to markeach output as A: correct translation alternative, B:correct translation but with a difference sense fromthe reference, P: partially correct translation, andE: incorrect translation.Table 2 shows some translations generated bythe full system that does not match the singlereference translation.
Half of the translations arecorrect translations (A and B), while a third arepartially correct translation (P).
Notice that it is acommon practice to translate only the surname of aforeign person.
Therefore, some partial translationsmay still be considered as correct (B).To Evaluate titles without a language link, wesampled a list of 95 terms from the unlinkedportion of Wikipedia using the criteria: (1) with afrequency count of over 2,000 in Google Web 1T.
(2) containing at least three English words.
(3) nota proper name.
Table 3 shows the evaluation133results.
Interestingly, our system provides correcttranslations for over 50% of the cases, and at leastpartially correct almost 90% of the cases.5 Conclusion and Future workWe have presented a new method for findingtranslations on the Web for a given term.
In ourapproach, we use a small set of terms andtranslations as seeds to obtain and to tag mixed-code snippets returned by a search engine, in orderto train a CRF model for sequence labels.
ThisCRF model is then used to tag the returnedsnippets for a given query term to extractiontranslation candidates, which are then ranked andreturned as output.
Preliminary experiments andevaluations show our learning-based methodcleanly combining various features, producingquality translations and transliterations.Many avenues exist for future research andimprovement.
For example, existing queryexpansion methods could be implemented toretrieve more webpages containing translations.Additionally, an interesting direction to explore isto identify phrase types and train type-specificCRF model.
In addition, natural languageprocessing techniques such as word stemming andword lemmatization could be attempted.ReferencesG.
W. Bian, H. H. Chen.
Cross-language informationaccess to multilingual collections on the internet.2000.
Journal of American Society for InformationScience  & Technology (JASIST), Special Issue onDigital Libraries, 51(3), pp.281-296, 2000.Y.
Cao and H. Li.
Base Noun Phrase Translation UsingWeb Data and the EM Algorithm.
2002.
InProceedings of the 19th International Conference onComputational Linguistics (COLING?02), pp.127-133, 2002.P.
J. Cheng, J. W. Teng, R. C. Chen, J. H. Wang, W. H.Lu, and L. F. Chien.
Translating unknown querieswith web corpora for cross-language informationretrieval.
In Proceedings of the 27th ACMInternational Conference on Research andDevelopment in Information Retrieval, pp.146-153,2004.F.
Huang, S. Vogel, and A. Waibel.
Automaticextraction of named entity translingual equivalencebased on multi-feature cost minimization.
InProceeding of the 41st ACL, Workshop onMultilingual and Mixed-Language Named EntityRecognition, Sapporo, 2003.K.
Knight, J. Graehl.
Machine Transliteration.
1998.Computational Linguistics 24(4), pp.599-612, 1998.P.
Koehn, K. Knight.
2003.
Feature-Rich StatisticalTranslation of Noun Phrases.
In Proceedings of the41st Annual Meeting on Association forComputational Linguistics, pp.
311-318, 2003.J.
Kupiec.
1993.
An Algorithm for Finding Noun PhraseCorrespondences in Bilingual Corpora.
InProceedings of the 31st Annual Meeting of theAssociation for Computational Linguistics, pp.
17-22, 1993.KL Kwok, P Deng, N Dinstl, HL Sun, W Xu, P Peng,and Doyon, J.
2005.
CHINET: a Chinese name findersystem for document triage.
In Proceedings of 2005D.
Lin, S. Zhao, B.V. Durme, and M. Pa?ca.
2008.Mining Parenthetical Translation from the Web byWord Alignment, In Proceedings of ACL 2008, pp.994-1002, 2008.Y.
Li, G. Grefenstette.
2005.
Translating ChineseRomanized name into Chinese idiographic charactersvia corpus and web validation.
In Proceedings ofCORIA 2005, pp.
323-338, 2005.M.
Nagata, T. Saito, and K. Suzuki.
Using the Web as abilingual dictionary.
2001.
In Proceedings of 39th.ACL Workshop on Data-Driven Methods in MachineTranslation, pp.
95-102, 2001.Y.
Qu, and G. Grefenstette.
2004.
Finding IdeographicRepresentations of Japanese Names Written in LatinScript via Language Identification and CorpusValidation.
In Proceedings of the 42nd AnnualMeeting of the Association for ComputationalLinguistics, pp.183-190, 2004.CK Quah.
2006.
Translation and Technology, PalgraveTextbooks in Translation and Interpretation, PalgraveMacMillan.R Sproat and C Shih.
Statistical Method for FindingWord Boundaries in Chinese Text, ComputerProcessing of Chinese and Oriental languages.
1990.J.
C. Wu, T. Lin and J. S. Chang.
Learning Source-Target Surface Patterns for Web-based TerminologyTranslation.
In Proceeding of the ACL 2005 onInteractive poster and demonstration sessions(ACLdemo '05).
2005.Y Zhang, F Huang, S Vogel.
2005.
Mining translationsof OOV terms from the web through cross-lingualquery expansion.
In Proceedings of the 28th AnnualInternational ACM SIGIR, pp.669-670, 2005.134
