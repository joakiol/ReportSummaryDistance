Modular MT with a learned bilingual dictionary: rapid deploymentof a new language pairJessie Pinkham Martine SmetsMicrosoft ResearchOne Microsoft WayRedmond, WA 98052{jessiep martines}@microsoft.comAbstractThe MT system described in this papercombines hand-built analysis and generationcomponents with automatically learnedexample-based transfer patterns.
Up to now,the transfer component used a traditionalbilingual dictionary to seed the transferpattern learning process and to providefallback translations at runtime.
This paperdescribes an improvement to the system bywhich the bilingual dictionary used for thesepurposes is instead learned automaticallyfrom aligned bilingual corpora, making thesystem?s transfer knowledge entirelyderivable from corpora.
We show that thissystem with a fully automated transferprocess performs better than the systemwith a hand-crafted bilingual dictionary.More importantly, this has enabled us tocreate in less than one day a new languagepair, French-Spanish, which, for a technicaldomain, surpasses the quality bar of thecommercial system chosen for comparison.1 IntroductionThe phrase ?MT in a day?
is strongly associatedwith research in statistical MT.
In this paper wedemonstrate that ?MT in a day?
is possible witha non-statistical MT system provided that thetransfer component is learned from alignedbilingual corpora (bi-texts), and does not rely onany large hand-crafted bilingual resource.
Wepropose instead to use a bilingual dictionarylearned only from the same bi-texts.
Section 4.2describes the creation of the new language pair,French-Spanish, and gives evaluation results.Section 4.1 examines the impact of the learneddictionary on our existing French-Englishsystem.2 Previous workCommercial systems and other large-scalesystems have traditionally relied heavily on theknowledge encoded in their bilingualdictionaries.
Gerber & Yang (1997) clearlystate that Systran?s translation capabilities aredependent on ?large, carefully encoded, high-quality dictionaries?.
With the advent of bi-texts, efforts to derive bilingual lexicons haveled to substantial research (Melamed 1996,Moore 2001 for discussion), including resourcesfor semi-automatic creation of bilingual lexicasuch as SABLE (Melamed 1997), used forinstance in Palmer et al (1998).
Statistical MTsystems have relied on bi-texts to automaticallycreate word-alignments; in many statistical MTsystems however, the authors state that use of aconventional bilingual dictionary enhances theperformance of the system (Al-Onaizan et al1999, Koehn & Knight 2001).
We find then,that in spite of the movement to create bilingualdictionaries automatically, there is still a heavyreliance on hand-crafted and hand-editedresources.
We found no full-scale MT systemthat relied only on learned bilingual dictionariesand certainly none that was found better inperformance for doing so.Rapid deployment of a new language pairhas been one of the strong features of statisticalMT systems.
For example, ?MT in a day?
was astated goal of the workshop on statistical MT(Al-Onaizan et al 1999).
The system deployedwas of low quality, in part because of the smallsize of the corpus used, and the difficulty of thelanguage pair chosen (Chinese to English).
Wehave chosen French-Spanish, because we areconstrained by the availability of well-developed analysis and generation componentsin our experiment.
Those, needless to say, werenot created in one day, nor were the large sizemonolingual dictionaries that they rely on.
Butgiven the assumption that these modules areavailable and of good quality, we demonstratethat training the transfer dictionary1 andexample base on bi-texts is sufficient to create anew language pair which is of comparablequality to others based on the same sourcelanguage.
This, to our knowledge, has not beendone before in the context of a large hybrid MTsystem3 System overviewThe MT system discussed here uses a sourcelanguage broad coverage analyzer, a large multi-purpose source language dictionary, anapplication-independent natural languagegeneration component which can access a fullmonolingual dictionary for the target language,and a transfer component.
The transfercomponent, described in detail in Menezes(2001), consists of high-quality transfer patternsautomatically acquired from sentence-alignedbilingual corpora.The innovation of this work is the use of anunedited, automatically created dictionary whichcontains translation pairs and parts of speech,without any use of a broad domain, generalpurpose hand-crafted dictionary resource.
Thearchitecture of the MT system as describedelsewhere (Richardson et al 2001) used both atraditional bilingual dictionary and anautomatically derived word-association file attraining time, but it used only the traditionalbilingual dictionary at runtime.
We refer to thisbelow as the HanC system, because it uses aHand-crafted Dictionary2.
We changed this sothat a learned dictionary consisting of word-associations (Moore 2001) with parts of speechand a function word only bilingual dictionary(prepositions, conjunctions and pronouns)replaces the previous combination both attraining and at runtime3.
We refer to this as the1 In both French-English and French-Spanish, we usea hand-crafted bilingual function word dictionary ofabout 500 entries.
It includes conjunctions,prepositions and pronouns; see section 4.1.4.2 The dictionaries are automatically converted fromelectronic dictionaries acquired from publishers, andare updated by hand over time.3 The same statistical techniques identify certainmulti-word terms for parsing and transfer.
ThisLeaD system (Learned Dictionary).
Wedemonstrate that this change improves sentencesthat differ between both systems, and show thatwe can now adapt quickly to new language pairswith excellent results.Analysis of the consequences of removingthe standard hand-crafted bilingual dictionaryfrom the system (and having no dictionary as afallback at all) are provided in Pinkham &Smets (2002).
It proved important to have adictionary containing parts of speech to use as afallback, motivating the work described here.4 ExperimentsWe conducted two experiments.
In the first one,we compared the performance of the HanC(Hand-Crafted dictionary) MT system to theperformance of our LeaD (Learned Dictionary)system.
The French-English system is trainedon 200,000 sentences in the computer domain,and tested on unseen sentences from the samedomain.In the second experiment, we created a newlanguage pair, French-Spanish, in less than 8hours.
The French-Spanish system was trainedon 220,000 sentences from the same computerdomain, and also tested on unseen computerdomain data.4.1 French-English translationwith a learned bilingualdictionary4.1.1 Comparing HanC to LeaDIn this first experiment, we compare theperformance of the HanC system and the LeaDsystem for French-English versus the samecompetitor.Translations produced by the two versions ofour system differ in 30% of the cases.
Out ofthe 2000 sentences in our test set, only 595 weretranslated differently.
In about half of thesecases, there was an overt difference in the wordchosen as a fallback translation at runtime.
Inthe other half, the translation example-basepatterns were different.learned dictionary stays constant during the French-English experiments.We evaluated 400 of the 595 ?diff?
sentencesmentioned.
A complete description of theevaluation method is given in Richardson(2001), and repeated in Appendix A. Evaluationfor each version of the system was conductedagainst the competitor system, which we use asa benchmark of quality.
Our current benchmarkfor French-English is Systran4, which usesrelevant dictionaries available but has not beenotherwise customized to the domain in any way.Scores Signif.
SizeHanC system(diffs only)-.1777 +/-.087 > .999 400LeaD system(diffs only)-.0735 +/-.182 .97 400French-EnglishHanC system+.2626 +/- .103 > .999 400French-EnglishLeaD system+.2804 +/-.115 > .999 400Table 1: LeaD vs. HanC for FEWe also evaluated a set of 400 sentencestaken randomly from the 2000 test sentence set.They were translated with both the HanC systemand the LeaD system, and evaluated against thesame competitor, Systran.4.1.2 ResultsThe random test has a score representative ofthe quality of the system (December 2001system), and is significantly better than thecompetitor given the score of +0.2804 (0 meansthe systems are the same, -1 the competitor isbetter, 1 the competitor is worse).
See Table 1.Sentences whose translations differ betweenthe HanC and LeaD versions of our system areless well translated overall.
Throughexamination of the data, we have found thatreliance on the fallback translation at runtimetends to indicate a failure to learn or applytransfer patterns from the example-base, both ofwhich are often due to faulty analysis of thesource sentence.
There are also cases where4 Systran was chosen on the basis of its ranking asthe best FE system in the IDC report (Flanagan &McClure, 2000)translations are not learned because of sparsedata, but these tend to be rare in our technicalcorpus.More importantly, we see that the LeaDversion of the system has a significantly higherscore than the HanC version (p=0.002 in a one-tailed t-test).
Replacing the conventionalbilingual dictionary with the learned bilingualdictionary combined with the small functionword dictionary has led to significantimprovement in quality when measured on?diff?
sentences, i.e.
cases where all thesentences are different.
However, when we take400 random sentences, the difference betweenthe two versions only affects 30% of thesentences (133 or thereabouts) and thereforedoes not result in a significant difference(p=0.13 in a one tailed t-test).4.1.3 Translation examplesIn this section, we give examples of translationwith both versions of our system, and comparedto Systran.
The LeaD version of our systemuses the correct translation of ?casiers?, in thisspecific context, while both our HanC version ofthe system and Systran use terms inappropriatefor this domain.
By using a learned dictionary,the LeaD system is better suited to the domain.Source Le finisseur est trait?
comme troiscasiers individuels,Reference The Finisher is addressed as threeindividual binsLeaD The finisher is processed like threeindividual bins.HanC The finisher is processed like threeindividual pigeonholes.Systran The finisher is treated like threeindividual racks,4.1.4 Creation of the learned bilingualdictionaryThe learned dictionary with parts of speech wascreated by the same method (Moore, 2001) asthe previously used word-association file, withthe exception that parts of speech wereappended to lemmas in the first step of theprocess.
We are easily able to modify the inputthis way, because we use the output of theanalysis of the training data to create the file thatis the input to the word alignment process.Appending the part of speech disambiguateshomographs such as ?use?, causing them to betreated as separate entities in the word-association process:use^^Verbuse^^NounThe word-association process assigns scoresto each pair of words.
We have established athreshold below which the pairs are discarded.Here are the top word pairs in the learneddictionary for this domain:utiliser^^Verb use^^Verbfichier^^Noun file^^Nounserveur^^Noun server^^NounBecause the input to the learning process isderived from Logical Forms (the output of ouranalysis systems), and because this format nolonger includes lemmas for function words,there are no function words in the learneddictionaries.
This is the primary reason why wecomplemented the learned dictionary with afunction word dictionary.
See the future worksection for ideas on learning the function wordsas well.Both the French-English and the French-Spanish were arbitrarily cut off at the samethreshold, and were not edited in any way,resulting in a file with 24,000 translation pairsfor French-English and 28,000 translation pairsfor French-Spanish.
The dictionary for functionwords contains about 500 word pairs.
Thetraditional French-English dictionary hadapproximately 40,000 entries.4.2 French-Spanish4.2.1 Creating French-SpanishOur group currently has both a French-Englishsystem and an English-Spanish system.
Inchoosing the new language pair to develop, wewere constrained by the availability of goodquality analysis and generation systems.
This isa limiting factor, but will become less so oncewe have more generation modules available foruse5, as we currently have seven fully developedanalysis modules.
We were fortunate to have220,000 aligned sentences for French-Spanishfrom the technical domain (manuals, help files),5 Members of our group (Corston-Oliver et al) aredeveloping an automatic generation component.This could speed up the development of generationmodules, giving us a potential of 42 differentlanguage-pairs trainable on bi-texts.which enabled the construction of the learnedbilingual dictionaries, and the automaticcreation of the transfer pattern example base.For reasons explained above, our firstlearned dictionary made no attempt to learnfunction word translations.
We needed,therefore, to complement the learned French-Spanish dictionary with a French-Spanishfunction word bilingual dictionary, which wasbootstrapped from our French-English andEnglish-Spanish bilingual dictionaries.
All thetranslations for prepositions, conjunctions andpronouns were created using both of these, andhand-edited by a lexicographer bilingual inFrench and Spanish.The creation process, including the hand-editing work, took less than 8 hours.4.2.2 ResultsThe test was conducted on 250 test sentencesfrom the same technical domain as the trainingcorpus, using the methodology described inAppendix A.
All test data is distinct fromtraining data and unseen by developers.
TheSail Labs French-Spanish system is thebenchmark used as comparison.
The technicaldomain dictionary on the website was applied tothe Sail Labs translation, but it was nototherwise customized to the domain.The Sail Labs translation included bracketsaround unfound words, which were thought tointerfere with the raters?
ability to compare thesentences; the brackets were removed for theevaluation.Condition Scores Signif SizeFS LeaD +.2278+/- .117> .999 250French-English +.2804+/- .114> .999 400Table 2: French Spanish resultsAs seen in Table 2, where the French-Spanish system is ranked at +0.228, it issignificantly better than the Sail Labs French-Spanish system in this technical domain.
Thescore is very similar to the French-English scoreas measured against Systran (+.2804).
Sincethese are being compared against differentcompetitors, we also wanted to measure theirabsolute quality.
On a scale of 1 to 4, where 4 isthe best, we found that both Systran and SailLabs were comparable in quality, and that oursystem scored slightly higher in both cases, butnot significantly so, if one considers theconfidence measures (Table 3).
The details ofthe scoring for absolute evaluations are given inAppendix B.
As a brief illustration, the LeaDFrench-English translation in 4.1.3 has a scoreof 3, while the LeaD French-Spanish translationin 4.2.3 received a score of 2.5.Absolute scoreFS LeaD 2.676 +/- .329 250FS Sail Labs 2.444 +/- .339 250French-English 2.321 +/- .21 400FE Systran 2.259 +/- .291 250Table 3: Absolute scores FS and FE4.2.3 Translation Example for French-SpanishThis section gives examples of translation fromFrench into Spanish.
The LeaD translation hasthe correct translation for domain specific termssuch as ?hardware?
and ?casilla deverificaci?n?, while Sails Labs translation doesnot in spite of the use of a domain bilingualdictionary.Source Si la case ?
cocher Supprimer de ceprofil mat?riel est activ?e, lep?riph?rique est supprim?
du profilmat?riel.Reference Si la casilla de verificaci?n Quitar esteperfil de hardware est?
activada, se haquitado el dispositivo del perfil dehardware.LeaD Si se activa la casilla de verificaci?nEliminar de este perfil de hardware, eldispositivo se quita del perfil dehardware.Sails Labs Si la coloca a marcar Suprimir de esteperfil material es activada, el perif?ricose suprime del perfil material.5 Future WorkWe are planning to experiment with loweringthe threshold for the cutoff of information in thelearned bilingual dictionary, in an attempt toinclude more word pairs (some words remainuntranslated).To further validate the Learned Dictionaryapproach, we are experimenting with otherdomains.
One might assume, for instance, thatas the domain becomes broader, learneddictionaries would be less effective due tosparse data.
We have preliminary experimentson Hansard French-English data which indicatethat this is not the case.6 ConclusionWe have demonstrated that we can replace thetraditional bilingual dictionary with acombination of a small bilingual function worddictionary and a bilingual dictionary learnedfrom bi-texts.
This removes the reliance onacquired or hand-built bilingual dictionaries,which can be expensive and time-consuming tocreate.
One can estimate that for any newdomain application, this could save as much as1-2 person years of customization.
This alsoremoves a major obstacle to quick deploymentof a new language pair.We believe that high-quality linguisticanalysis is a necessary ingredient for successfulMT.
In our system, it has enabled automation ofthe transfer component, both in the learning ofthe bilingual dictionary and in the creation ofexample-based patterns.Appendix A: Relative Evaluation MethodFor each version of the system to be tested,seven evaluators were asked to evaluate thesame set of blind test sentences.
For eachsentence, raters were presented with a referencesentence, the original English sentence fromwhich the human French translation wasderived.
In order to maintain consistency amongraters who may have different levels of fluencyin the source language, raters were not shownthe original French sentence.
Raters were alsoshown two machine translations, one from thesystem with the component being tested, andone from the comparison system (Systran forFrench-English, Sails Lab for French-Spanish).Because the order of the two machinetranslation sentences was randomized on eachsentence, evaluators could not determine whichsentence was from which system.
The order ofpresentation of sentences was also randomizedfor each rater in order to eliminate any orderingeffect.The raters were asked to make a three-waychoice.
For each sentence, the raters were todetermine which of the two automaticallytranslated sentences was the better translation ofthe (unseen) source sentence, assuming that thereference sentence was a perfect translation,with the option of choosing ?neither?
if thedifferences were negligible.
Raters wereinstructed to use their best judgment about therelative importance of fluency/style andaccuracy/content preservation.
We chose to usethis simple three-way scale in order to avoidmaking any a priori judgments about the relativejudgments of quality.
The three-way scale alsoallowed sentences to be rated on the same scale,regardless of whether the differences betweenoutput from system 1 and system 2 weresubstantial or relatively small; and regardless ofwhether either version of the system producedan adequate translation.The scoring system was similarly simple;each judgment by a rater was represented as 1(sentence from our system judged better), 0(neither sentence judged better), or -1 (sentencefrom Systran or Sails Labs judged better).
Thescore for each version of the system was themean of the scores of all sentences for all raters.The significance of the scores was calculated intwo ways.
First, we determined the range aroundthe mean which we could report with 95%confidence (i.e.
a confidence interval at .95),taking into account both variations in thesentences and variations across the raters'judgments.
In order to determine the effects ofeach stage of development on the overall qualityof the system, we calculated the significance ofthe difference in the scores across the differentversions of the system to determine whether thedifference between them was statisticallymeaningful.
We used a one-tailed t-test, sinceour a priori hypothesis was that the system withmore development would show improvement(that is, a statistically meaningful change inquality with respect to the competitor).Appendix B: Absolute EvaluationMethodAt the same time as the relative evaluations aremade, all the raters enter scores from 1 to 4reflecting the absolute quality of the translation,as compared to the reference translation given.The grading is done according to theseguidelines:1 unacceptable:Absolutely not comprehensible and/or littleor no information transferred accurately2 possibly acceptable:Possibly comprehensible (given enough contextand/or time to work it out); some informationtransferred accurately3 acceptable:Not perfect (stylistically or grammatically odd),but definitely comprehensible, AND withaccurate transfer of all important information4 ideal:Not necessarily a perfect translation, butgrammatically correct, and with all informationaccurately transferredReferencesAl-Onaizan, Y & Curin, J.
& Jahr, M. & KnightK.
& Lafferty, J.
& Melamed, D. & Och, F-J,& Purdy, D. & Smith, N. A.
& Yarowsky, D.(1999).
Statistical Machine Translation: FinalReport, Johns Hopkins University 1999Summer Workshop on LanguageEngineering, Center for Speech and LanguageProcessing, Baltimore, MD.Corston-Oliver, S., M. Gamon, E. Ringger, R.Moore.
2002.
An overview of Amalgam: Amachine-learned generation module.
Toappear in Proceedings of the InternationalNatural Language Generation Conference.New York, USAFlanagan, M and McClure, S. (2000) MachineTranslation Engines: An Evaluation of OutputQuality, IDC publication 22722.Gerber, L. & Yang,J.
(1997) Systran MTDictionary Development in the Proceedingsof the MT Summit V, San Diego.Koehn, P. & Knight, K. (2001) KnowledgeSources for Word-Level Translation Models,Proceedings of the conference on EmpiricalMethods in Natural Language Processing(EMNLP)Melamed, D. (1998).
Empirical Methods for MTLexicon Construction, in L. Gerber and D.Farwell, Eds., Machine Translation and theInformation Soup, Springer-Verlag.Melamed, D. (1997).
A Scalable Architecturefor Bilingual Lexicography, Dept.
ofComputer and Information Science TechnicalReport #MS-CIS-91-01.Melamed, D. (1996).
Automatic Construction ofClean Broad-Coverage Translation Lexicons,Proceeding of the 2nd Conference of theAssociation for Machine Translation in theAmericas (AMTA'96), Montreal, Canada.Menezes, A.
& Richardson, S. (2001).
A Best-First Alignment Algorithm for AutomaticExtraction of Transfer Mappings fromBilingual Corpora.
In Proceedings of theWorkshop on Data-Driven MachineTranslation, ACL Conference, June 2001.Moore, R.C.
(2001).
Towards a Simple andAccurate Statistical Approach to LearningTranslation Relationships Between Words.
InProceedings of the Workshop on Data-DrivenMachine Translation, ACL Conference, June2001.Pinkham, J & Smets, M (2002) MachineTranslation without a bilingual dictionaryProceedings of the TMI conference, Kyoto,Japan.Palmer, M. & Rambow, O.
& Nasr, A.
(1998).Rapid Prototyping of Domain-SpecificMachine Translation Systems, in Proceedingsof the AMTA ?98.Richardson, S. & Dolan, W. & Menezes, A.
&Corston-Oliver, M. (2001).
Overcoming theCustomisation Bottleneck Using Example-Based MT.
In Proceedings of the Workshopon Data-Driven Machine Translation, ACLConference, June 2001.
