The Importance of Supertagging for Wide-Coverage CCG ParsingStephen ClarkSchool of InformaticsUniversity of Edinburgh2 Buccleuch Place, Edinburgh, UKstephen.clark@ed.ac.ukJames R. CurranSchool of Information TechnologiesUniversity of SydneyNSW 2006, Australiajames@it.usyd.edu.auAbstractThis paper describes the role of supertaggingin a wide-coverage CCG parser which uses alog-linear model to select an analysis.
Thesupertagger reduces the derivation space overwhich model estimation is performed, reducingthe space required for discriminative training.It also dramatically increases the speed of theparser.
We show that large increases in speedcan be obtained by tightly integrating the su-pertagger with the CCG grammar and parser.This is the first work we are aware of to success-fully integrate a supertagger with a full parserwhich uses an automatically extracted grammar.We also further reduce the derivation space us-ing constraints on category combination.
Theresult is an accurate wide-coverage CCG parserwhich is an order of magnitude faster than com-parable systems for other linguistically moti-vated formalisms.1 IntroductionLexicalised grammar formalisms such as Lexical-ized Tree Adjoining Grammar (LTAG) and Com-binatory Categorial Grammar (CCG) assign one ormore syntactic structures to each word in a sentencewhich are then manipulated by the parser.
Supertag-ging was introduced for LTAG as a way of increasingparsing efficiency by reducing the number of struc-tures assigned to each word (Bangalore and Joshi,1999).
Supertagging has more recently been appliedto CCG (Clark, 2002; Curran and Clark, 2003).Supertagging accuracy is relatively high for man-ually constructed LTAGs (Bangalore and Joshi,1999).
However, for LTAGs extracted automati-cally from the Penn Treebank, performance is muchlower (Chen et al, 1999; Chen et al, 2002).
Infact, performance for such grammars is below thatneeded for successful integration into a full parser(Sarkar et al, 2000).
In this paper we demonstratethat CCG supertagging accuracy is not only suffi-cient for accurate and robust parsing using an auto-matically extracted grammar, but also offers severalpractical advantages.Our wide-coverage CCG parser uses a log-linearmodel to select an analysis.
The model paramatersare estimated using a discriminative method, that is,one which requires all incorrect parses for a sen-tence as well as the correct parse.
Since an auto-matically extracted CCG grammar can produce anextremely large number of parses, the use of a su-pertagger is crucial in limiting the total number ofparses for the training data to a computationallymanageable number.The supertagger is also crucial for increasing thespeed of the parser.
We show that spectacular in-creases in speed can be obtained, without affectingaccuracy or coverage, by tightly integrating the su-pertagger with the CCG grammar and parser.
Toachieve maximum speed, the supertagger initiallyassigns only a small number of CCG categories toeach word, and the parser only requests more cate-gories from the supertagger if it cannot provide ananalysis.
We also demonstrate how extra constraintson the category combinations, and the applicationof beam search using the parsing model, can furtherincrease parsing speed.This is the first work we are aware of to succes-fully integrate a supertagger with a full parser whichuses a lexicalised grammar automatically extractedfrom the Penn Treebank.
We also report signifi-cantly higher parsing speeds on newspaper text thanany previously reported for a full wide-coverageparser.
Our results confirm that wide-coverage CCGparsing is feasible for many large-scale NLP tasks.2 CCG SupertaggingParsing using CCG can be viewed as a two-stageprocess: first assign lexical categories to the wordsin the sentence, and then combine the categories to-gether using CCG?s combinatory rules.1 The firststage can be accomplished by simply assigning toeach word all categories from the word?s entry inthe lexicon (Hockenmaier, 2003).1See Steedman (2000) for an introduction to CCG, and seeClark et al (2002) and Hockenmaier (2003) for an introductionto wide-coverage parsing using CCG.The WSJ is a publication that I enjoy readingNP/N N (S[dcl]\NP)/NP NP/N N (NP\NP)/(S[dcl]/NP) NP (S[dcl]\NP)/(S[ng]\NP) (S[ng]\NP)/NPFigure 1: Example sentence with CCG lexical categoriesfrequency # cat types # cat tokens in # sentences in 2-21 # cat tokens in # sentences in 00cut-off 2-21 not in cat set with missing cat 00 not in cat set with missing cat1 1 225 0 0 12 (0.03%) 12 (0.6%)10 409 1 933 (0.2%) 1 712 (4.3%) 79 (0.2%) 69 (3.6%)Table 1: Statistics for the lexical category setAn alternative is to use a statistical tagging ap-proach to assign one or more categories.
A statisti-cal model can be used to determine the most likelycategories given the word?s context.
The advan-tage of this supertagging approach is that the num-ber of categories assigned to each word can be re-duced, with a correspondingly massive reduction inthe number of derivations.Bangalore and Joshi (1999) use a standardMarkov model tagger to assign LTAG elementarytrees to words.
Here we use the Maximum En-tropy models described in Curran and Clark (2003).An advantage of the Maximum Entropy approachis that it is easy to encode a wide range of poten-tially useful information as features; for example,Clark (2002) has shown that POS tags provide use-ful information for supertagging.
The next sectiondescribes the set of lexical categories used by oursupertagger and parser.2.1 The Lexical Category SetThe set of lexical categories is obtained from CCG-bank (Hockenmaier and Steedman, 2002; Hocken-maier, 2003), a corpus of CCG normal-form deriva-tions derived semi-automatically from the PennTreebank.
Following Clark (2002), we apply a fre-quency cutoff to the training set, only using thosecategories which appear at least 10 times in sec-tions 2-21.
Figure 1 gives an example sentence su-pertagged with the correct CCG lexical categories.Table 1 gives the number of different categorytypes and shows the coverage on training (seen) anddevelopment (unseen) data (section 00 from CCG-bank).
The table also gives statistics for the com-plete set containing every lexical category type inCCGbank.2 These figures show that using a fre-quency cutoff can significantly reduce the size ofthe category set with only a small loss in coverage.2The numbers differ slightly from those reported in Clark(2002) since a newer version of CCGbank is being used here.Clark (2002) compares the size of grammarsextracted from CCGbank with automatically ex-tracted LTAGs.
The grammars of Chen and Vijay-Shanker (2000) contain between 2,000 and 9,000tree frames, depending on the parameters used inthe extraction process, significantly more elemen-tary structures than the number of lexical categoriesderived from CCGbank.
We hypothesise this is akey factor in the higher accuracy for supertaggingusing a CCG grammar compared with an automati-cally extracted LTAG.2.2 The Tagging ModelThe supertagger uses probabilities p(y|x) where y isa lexical category and x is a context.
The conditionalprobabilities have the following log-linear form:p(y|x) = 1Z(x)e?i ?i fi(y,x) (1)where fi is a feature, ?i is the corresponding weight,and Z(x) is a normalisation constant.
The contextis a 5-word window surrounding the target word.Features are defined for each word in the windowand for the POS tag of each word.
Curran and Clark(2003) describes the model and explains how Gen-eralised Iterative Scaling, together with a Gaussianprior for smoothing, can be used to set the weights.The supertagger in Curran and Clark (2003) findsthe single most probable category sequence giventhe sentence, and uses additional features definedin terms of the previously assigned categories.
Theper-word accuracy is between 91 and 92% on un-seen data in CCGbank; however, Clark (2002)shows this is not high enough for integration into aparser since the large number of incorrect categoriesresults in a significant loss in coverage.Clark (2002) shows how the models in (1) canbe used to define a multi-tagger which can assignmore than one category to a word.
For each word inthe sentence, the multi-tagger assigns all those cat-?
CATS/ ACC SENT ACC SENTWORD ACC (POS) ACC0.1 1.4 97.0 62.6 96.4 57.40.075 1.5 97.4 65.9 96.8 60.60.05 1.7 97.8 70.2 97.3 64.40.01 2.9 98.5 78.4 98.2 74.20.01k=100 3.5 98.9 83.6 98.6 78.90 21.9 99.1 84.8 99.0 83.0Table 2: Supertagger accuracy on section 00egories whose probability according to (1) is withinsome factor, ?, of the highest probability categoryfor the word.We follow Clark (2002) in ignoring the featuresbased on the previously assigned categories; there-fore every tagging decision is local and the Viterbialgorithm is not required.
This simple approach hasthe advantage of being very efficient, and we findthat it is accurate enough to enable highly accu-rate parsing.
However, a method which used theforward-backward algorithm to sum over all possi-ble sequences, or some other method which tookinto account category sequence information, maywell improve the results.For words seen at least k times in the trainingdata, the tagger can only assign categories appear-ing in the word?s entry in the tag dictionary.
Eachentry in the tag dictionary is a list of all the cate-gories seen with that word in the training data.
Forwords seen less than k times, we use an alternativedictionary based on the word?s POS tag: the taggercan only assign categories that have been seen withthe POS tag in the training data.
A value of k = 20was used in this work, and sections 2-21 of CCG-bank were used as training data.Table 2 gives the per-word accuracy (acc) on sec-tion 00 for various values of ?, together with theaverage number of categories per word.
The sentacc column gives the precentage of sentences whosewords are all supertagged correctly.
The figures for?
= 0.01k=100 correspond to a value of 100 for thetag dictionary parameter k. The set of categories as-signed to a word is considered correct if it containsthe correct category.
The table gives results for goldstandard POS tags and, in the final 2 columns, forPOS tags automatically assigned by the Curran andClark (2003) tagger.
The drop in accuracy is ex-pected given the importance of POS tags as features.The figures for ?
= 0 are obtained by assigningall categories to a word from the word?s entry in thetag dictionary.
For words which appear less than 20times in the training data, the dictionary based onthe word?s POS tag is used.
The table demonstratesthe significant reduction in the average number ofcategories that can be achieved through the use ofa supertagger.
To give one example, the number ofcategories in the tag dictionary?s entry for the wordis is 45 (only considering categories which have ap-peared at least 10 times in the training data).
How-ever, in the sentence Mr. Vinken is chairman of Else-vier N.V., the Dutch publishing group., the supertag-ger correctly assigns 1 category to is for ?
= 0.1,and 3 categories for ?
= 0.01.3 The ParserThe parser is described in detail in Clark and Curran(2004).
It takes POS tagged sentences as input witheach word assigned a set of lexical categories.
Apacked chart is used to efficiently represent all of thepossible analyses for a sentence, and the CKY chartparsing algorithm described in Steedman (2000) isused to build the chart.Clark and Curran (2004) evaluate a number oflog-linear parsing models for CCG.
In this paper weuse the normal-form model, which defines proba-bilities with the conditional log-linear form in (1),where y is a derivation and x is a sentence.
Featuresare defined in terms of the local trees in the deriva-tion, including lexical head information and word-word dependencies.
The normal-form derivations inCCGbank provide the gold standard training data.The feature set we use is from the best performingnormal-form model in Clark and Curran (2004).For a given sentence the output of the parser isa dependency structure corresponding to the mostprobable derivation, which can be found using theViterbi algorithm.
The dependency relations are de-fined in terms of the argument slots of CCG lexicalcategories.
Clark et al (2002) and Clark and Curran(2004) give a detailed description of the dependencystructures.3.1 Model EstimationIn Clark and Curran (2004) we describe a discrim-inative method for estimating the parameters of alog-linear parsing model.
The estimation methodmaximises the following objective function:L?(?)
= L(?)
?G(?)
(2)= logm?j=1P?
(d j|S j) ?n?i=1?2i2?2The data consists of sentences S 1, .
.
.
, S m, to-gether with gold standard normal-form derivations,d1, .
.
.
, dm.
L(?)
is the log-likelihood of model ?,and G(?)
is a Gaussian prior term used to avoidoverfitting (n is the number of features; ?i is theweight for feature fi; and ?
is a parameter of theGaussian).
The objective function is optimised us-ing L-BFGS (Nocedal and Wright, 1999), an itera-tive algorithm from the numerical optimisation lit-erature.The algorithm requires the gradient of the objec-tive function, and the value of the objective func-tion, at each iteration.
Calculation of these val-ues requires all derivations for each sentence inthe training data.
In Clark and Curran (2004) wedescribe efficient methods for performing the cal-culations using packed charts.
However, a verylarge amount of memory is still needed to store thepacked charts for the complete training data eventhough the representation is very compact; in Clarkand Curran (2003) we report a memory usage of 30GB.
To handle this we have developed a parallelimplementation of the estimation algorithm whichruns on a Beowulf cluster.The need for large high-performance computingresources is a disadvantage of our earlier approach.In the next section we show how use of the supertag-ger, combined with normal-form constraints on thederivations, can significantly reduce the memory re-quirements for the model estimation.4 Generating Parser Training DataSince the training data contains the correct lexicalcategories, we ensure the correct category is as-signed to each word when generating the packedcharts for model estimation.
Whilst training theparser, the supertagger can be thought of as supply-ing a number of plausible but incorrect categoriesfor each word; these, together with the correct cat-egories, determine the parts of the parse space thatare used in the estimation process.
We would liketo keep the packed charts as small as possible, butnot lose accuracy in the resulting parser.
Section 4.2discusses the use of various settings on the supertag-ger.
The next section describes how normal-formconstraints can further reduce the derivation space.4.1 Normal-Form ConstraintsAs well as the supertagger, we use two additionalstrategies for reducing the derivation space.
Thefirst, following Hockenmaier (2003), is to only al-low categories to combine if the combination hasbeen seen in sections 2-21 of CCGbank.
For exam-ple, NP/NP could combine with NP/NP accordingto CCG?s combinatory rules (by forward composi-tion), but since this particular combination does notappear in CCGbank the parser does not allow it.The second strategy is to use Eisner?s normal-form constraints (Eisner, 1996).
The constraintsSUPERTAGGING/PARSING USAGECONSTRAINTS DISK MEMORY?
= 0.01 ?
0.05 ?
0.1 17 GB 31 GBCCGbank constraints 13 GB 23 GBEisner constraints 9 GB 16 GB?
= 0.05 ?
0.1 2 GB 4 GBTable 3: Space requirements for model training dataprevent any constituent which is the result of a for-ward (backward) composition serving as the pri-mary functor in another forward (backward) com-position or a forward (backward) application.
Eis-ner only deals with a grammar without type-raising,and so the constraints do not guarantee a normal-form parse when using a grammar extracted fromCCGbank.
However, the constraints are still usefulin restricting the derivation space.
As far as we areaware, this is the first demonstration of the utility ofsuch constraints for a wide-coverage CCG parser.4.2 Results (Space Requirements)Table 3 shows the effect of different supertagger set-tings, and the normal-form constraints, on the sizeof the packed charts used for model estimation.
Thedisk usage is the space taken on disk by the charts,and the memory usage is the space taken in mem-ory during the estimation process.
The training sen-tences are parsed using a number of nodes from a64-node Beowulf cluster.3 The time taken to parsethe training sentences depends on the supertaggingand parsing constraints, and the number of nodesused, but is typically around 30 minutes.The first row of the table corresponds to usingthe least restrictive ?
value of 0.01, and revertingto ?
= 0.05, and finally ?
= 0.1, if the chart sizeexceeds some threshold.
The threshold was set at300,000 nodes in the chart.
Packed charts are cre-ated for approximately 94% of the sentences in sec-tions 2-21 of CCGbank.
The coverage is not 100%because, for some sentences, the parser cannot pro-vide an analysis, and some charts exceed the nodelimit even at the ?
= 0.1 level.
This strategy wasused in our earlier work (Clark and Curran, 2003)and, as the table shows, results in very large charts.Note that, even with this relaxed setting on the su-pertagger, the number of categories assigned to eachword is only around 3 on average.
This suggests thatit is only through use of the supertagger that we areable to estimate a log-linear parsing model on all ofthe training data at all, since without it the memory3The figures in the table are estimates based on a sample ofthe nodes in the cluster.requirements would be far too great, even for theentire 64-node cluster.4The second row shows the reduction in size ifthe parser is only allowed to combine categorieswhich have combined in the training data.
This sig-nificantly reduces the number of categories createdusing the composition rules, and also prevents thecreation of unlikely categories using rule combina-tions not seen in CCGbank.
The results show thatthe memory and disk usage are reduced by approx-imately 25% using these constraints.The third row shows a further reduction in sizewhen using the Eisner normal-form constraints.Even with the CCGbank rule constraints, theparser still builds many non-normal-form deriva-tions, since CCGbank does contain cases of compo-sition and type-raising.
(These are used to analysesome coordination and extraction cases, for exam-ple.)
The combination of the two types of normal-form constraints reduces the memory requirementsby 48% over the original approach.
In Clark andCurran (2004) we show that the parsing model re-sulting from training data generated in this wayproduces state-of-the-art CCG dependency recovery:84.6 F-score over labelled dependencies.The final row corresponds to a more restrictivesetting on the supertagger, in which a value of ?
=0.05 is used initially and ?
= 0.1 is used if thenode limit is exceeded.
The two types of normal-form constraints are also used.
In Clark and Curran(2004) we show that using this more restrictive set-ting has a small negative impact on the accuracy ofthe resulting parser (about 0.6 F-score over labelleddependencies).
However, the memory requirementfor training the model is now only 4 GB, a reductionof 87% compared with the original approach.5 Parsing Unseen DataThe previous section showed how to combine thesupertagger and parser for the purpose of creatingtraining data, assuming the correct category for eachword is known.
In this section we describe ourapproach to tightly integrating the supertagger andparser for parsing unseen data.Our previous approach to parsing unseen data(Clark et al, 2002; Clark and Curran, 2003) wasto use the least restrictive setting of the supertag-ger which still allows a reasonable compromise be-tween speed and accuracy.
Our philosophy was togive the parser the greatest possibility of finding thecorrect parse, by giving it as many categories as pos-sible, while still retaining reasonable efficiency.4Another possible solution would be to use sampling meth-ods, e.g.
Osborne (2000).SUPERTAGGING/PARSING TIME SENTS WORDSCONSTRAINTS SEC /SEC /SEC?
= 0.01?
.
.
.?
0.1 3 523 0.7 16CCGbank constraints 1 181 2.0 46Eisner constraints 995 2.4 55?
= 0.1?
.
.
.
0.01k=100 608 3.9 90CCGbank constraints 124 19.4 440Eisner constraints 100 24.0 546Parser beam 67 35.8 81494% coverage 49 49.0 1 114Parser beam 46 52.2 1 186Oracle 18 133.4 3 031Table 4: Parse times for section 23The problem with this approach is that, for somesentences, the number of categories in the chart stillgets extremely large and so parsing is unacceptablyslow.
Hence we applied a limit to the number ofcategories in the chart, as in the previous section,and reverted to a more restrictive setting of the su-pertagger if the limit was exceeded.
We first useda value of ?
= 0.01, and then reverted to ?
= 0.05,and finally ?
= 0.1.In this paper we take the opposite approach: westart with a very restrictive setting of the supertag-ger, and only assign more categories if the parsercannot find an analysis spanning the sentence.
Inthis way the parser interacts much more closely withthe supertagger.
In effect, the parser is using thegrammar to decide if the categories provided by thesupertagger are acceptable, and if not the parser re-quests more categories.
The parser uses the 5 levelsgiven in Table 2, starting with ?
= 0.1 and movingthrough the levels to ?
= 0.01k=100 .The advantage of this approach is that parsingspeeds are much higher.
We also show that ournew approach slightly increases parsing accuracyover the previous method.
This suggests that, givenour current parsing model, it is better to rely largelyon the supertagger to provide the correct categoriesrather than use the parsing model to select the cor-rect categories from a very large derivation space.5.1 Results (Parse Times)The results in this section are all using the best per-forming normal-form model in Clark and Curran(2004), which corresponds to row 3 in Table 3.
Allexperiments were run on a 2.8 GHZ Intel Xeon P4with 2 GB RAM.Table 4 gives parse times for the 2,401 sentencesin section 23 of CCGbank.
The final two columnsgive the number of sentences, and the number of?
CATS/ 0.1 FIRST 0.01 FIRSTWORD PARSES % PARSES %0.1 1.4 1689 88.4 0 0.00.075 1.5 43 2.3 7 0.40.05 1.7 51 2.7 39 2.00.01 2.9 79 4.1 1816 95.10.01k=100 3.5 33 1.7 33 1.7NO SPAN 15 0.8 15 0.8Table 5: Supertagger ?
levels used on section 00words, parsed per second.
For all of the figures re-ported on section 23, unless stated otherwise, theparser is able to provide an analysis for 98.5% of thesentences.
The parse times and speeds include thefailed sentences, but do not include the time takenby the supertagger; however, the supertagger is ex-tremely efficient, and takes less than 6 seconds tosupertag section 23, most of which consists of loadtime for the Maximum Entropy model.The first three rows correspond to our strategy ofearlier work by starting with the least restrictive set-ting of the supertagger.
The first value of ?
is 0.01;if the parser cannot find a spanning analysis, this ischanged to ?
= 0.01k=100; if the node limit is ex-ceeded (for these experiments set at 1,000,000), ?
ischanged to 0.05.
If the node limit is still exceeded,?
is changed to 0.075, and finally 0.1.
The secondrow has the CCGbank rule restriction applied, andthe third row the Eisner normal-form restrictions.The next three rows correspond to our new strat-egy of starting with the least restrictive setting of thesupertagger (?
= 0.1), and moving through the set-tings if the parser cannot find a spanning analysis.The table shows that the normal-form constraintshave a significant impact on the speed, reducing theparse times for the old strategy by 72%, and reduc-ing the times for the new strategy by 84%.
Thenew strategy also has a spectacular impact on thespeed compared with the old strategy, reducing thetimes by 83% without the normal-form constraintsand 90% with the constraints.The 94% coverage row corresponds to using onlythe first two supertagging levels; the parser ignoresthe sentence if it cannot get an analysis at the ?
=0.05 level.
The percentage of sentences without ananalysis is now 6%, but the parser is extremely fast,processing almost 50 sentences a second.
This con-figuration of the system would be useful for obtain-ing data for lexical knowledge acquisition, for ex-ample, for which large amounts of data are required.The oracle row shows the parser speed when itis provided with only the correct lexical categories.The parser is extremely fast, and in Clark and Cur-ran (2004) we show that the F-score for labelleddependencies is almost 98%.
This demonstratesthe large amount of information in the lexical cat-egories, and the potential for improving parser ac-curacy and efficiency by improving the supertagger.Finally, the first parser beam row corresponds tothe parser using a beam search to further reduce thederivation space.
The beam search works by prun-ing categories from the chart: a category can onlybe part of a derivation if its beam score is withinsome factor, ?, of the highest scoring category forthat cell in the chart.
Here we simply use the ex-ponential of the inside score of a category as thebeam score; the inside score for a category c is thesum over all sub-derivations dominated by c of theweights of the features in those sub-derivations (seeClark and Curran (2004).5The value of ?
that we use here reduces the accu-racy of the parser on section 00 by a small amount(0.3% labelled F-score), but has a significant impacton parser speed, reducing the parse times by a fur-ther 33%.
The final parser beam row combines thebeam search with the fast, reduced coverage config-uration of the parser, producing speeds of over 50sentences per second.Table 5 gives the percentage of sentences whichare parsed at each supertagger level, for both thenew and old parsing strategies.
The results showthat, for the old approach, most of the sentences areparsed using the least restrictive setting of the su-pertagger (?
= 0.01); conversely, for the new ap-proach, most of the sentences are parsed using themost restrictive setting (?
= 0.1).As well as investigating parser efficiency, wehave also evaluated the accuracy of the parser onsection 00 of CCGbank, using both parsing strate-gies together with the normal-form constraints.
Thenew strategy increases the F-score over labelled de-pendencies by approximately 0.5%, leading to thefigures reported in Clark and Curran (2004).5.2 Comparison with Other WorkThe only other work we are aware of to investigatethe impact of supertagging on parsing efficiency isthe work of Sarkar et al (2000) for LTAG.
Sarkar etal.
did find that LTAG supertagging increased pars-ing speed, but at a significant cost in coverage: only1,324 sentences out of a test set of 2,250 received aparse.
The parse times reported are also not as goodas those reported here: the time taken to parse the2,250 test sentences was over 5 hours.5Multiplying by an estimate of the outside score may im-prove the efficacy of the beam.Kaplan et al (2004) report high parsing speedsfor a deep parsing system which uses an LFG gram-mar: 1.9 sentences per second for 560 sentencesfrom section 23 of the Penn Treebank.
They also re-port speeds for the publicly available Collins parser(Collins, 1999): 2.8 sentences per second for thesame set.
The best speeds we have reported for theCCG parser are an order of magnitude faster.6 ConclusionsThis paper has shown that by tightly integrating asupertagger with a CCG parser, very fast parse timescan be achieved for Penn Treebank WSJ text.
As faras we are aware, the times reported here are an orderof magnitude faster than any reported for compara-ble systems using linguistically motivated grammarformalisms.
The techniques we have presented inthis paper increase the speed of the parser by a fac-tor of 77.
This makes this parser suitable for large-scale NLP tasks.The results also suggest that further improve-ments can be obtained by improving the supertag-ger, which should be possible given the simple tag-ging approach currently being used.The novel parsing strategy of allowing the gram-mar to decide if the supertagging is likely to be cor-rect suggests a number of interesting possibilities.In particular, we would like to investigate only re-pairing those areas of the chart that are most likelyto contain errors, rather than parsing the sentencefrom scratch using a new set of lexical categories.This could further increase parsing effficiency.AcknowledgementsWe would like to thank Julia Hockenmaier, whosework creating the CCGbank made this research pos-sible, and Mark Steedman for his advice and guid-ance.
This research was supported by EPSRC grantGR/M96889, and a Commonwealth scholarship anda Sydney University Travelling scholarship to thesecond author.ReferencesSrinivas Bangalore and Aravind Joshi.
1999.
Supertag-ging: An approach to almost parsing.
ComputationalLinguistics, 25(2):237?265.John Chen and K. Vijay-Shanker.
2000.
Automated ex-traction of TAGS from the Penn Treebank.
In Pro-ceedings of IWPT 2000, Trento, Italy.John Chen, Srinivas Bangalore, and K. Vijay-Shanker.1999.
New models for improving supertag disam-biguation.
In Proceedings of the 9th Meeting ofEACL, Bergen, Norway.John Chen, Srinivas Bangalore, Michael Collins, andOwen Rambow.
2002.
Reranking an N-gram su-pertagger.
In Proceedings of the TAG+ Workshop,pages 259?268, Venice, Italy.Stephen Clark and James R. Curran.
2003.
Log-linearmodels for wide-coverage CCG parsing.
In Proceed-ings of the EMNLP Conference, pages 97?104, Sap-poro, Japan.Stephen Clark and James R. Curran.
2004.
Parsingthe WSJ using CCG and log-linear models.
In Pro-ceedings of the 42nd Meeting of the ACL, Barcelona,Spain.Stephen Clark, Julia Hockenmaier, and Mark Steedman.2002.
Building deep dependency structures with awide-coverage CCG parser.
In Proceedings of the40th Meeting of the ACL, pages 327?334, Philadel-phia, PA.Stephen Clark.
2002.
A supertagger for CombinatoryCategorial Grammar.
In Proceedings of the TAG+Workshop, pages 19?24, Venice, Italy.Michael Collins.
1999.
Head-Driven Statistical Modelsfor Natural Language Parsing.
Ph.D. thesis, Univer-sity of Pennsylvania.James R. Curran and Stephen Clark.
2003.
InvestigatingGIS and smoothing for maximum entropy taggers.
InProceedings of the 10th Meeting of the EACL, pages91?98, Budapest, Hungary.Jason Eisner.
1996.
Efficient normal-form parsing forCombinatory Categorial Grammar.
In Proceedings ofthe 34th Meeting of the ACL, pages 79?86, SantaCruz, CA.Julia Hockenmaier and Mark Steedman.
2002.
Acquir-ing compact lexicalized grammars from a cleaner tree-bank.
In Proceedings of the Third LREC Conference,pages 1974?1981, Las Palmas, Spain.Julia Hockenmaier.
2003.
Data and Models for Statis-tical Parsing with Combinatory Categorial Grammar.Ph.D.
thesis, University of Edinburgh.Ronald M. Kaplan, Stefan Riezler, Tracy H. King,John T. Maxwell III, Alexander Vasserman, andRichard Crouch.
2004.
Speed and accuracy in shal-low and deep stochastic parsing.
In Proceedings ofthe HLT/NAACL Conference, Boston, MA.Jorge Nocedal and Stephen J. Wright.
1999.
NumericalOptimization.
Springer, New York, USA.Miles Osborne.
2000.
Estimation of stochasticattribute-value grammars using an informative sam-ple.
In Proceedings of the 18th International Confer-ence on Computational Linguistics, pages 586?592,Saarbru?cken, Germany.Anoop Sarkar, Fei Xia, and Aravind Joshi.
2000.
Someexperiments on indicators of parsing complexity forlexicalized grammars.
In Proceedings of the COLINGWorkshop on Efficiency in Large-Scale Parsing Sys-tems, pages 37?42, Luxembourg.Mark Steedman.
2000.
The Syntactic Process.
The MITPress, Cambridge, MA.
