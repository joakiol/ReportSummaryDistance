The R2D2 Team at SENSEVAL-3?Sonia Va?zquez, Rafael RomeroArmando Sua?rez and Andre?s MontoyoDpto.
de Lenguajes y Sistemas.
Informa?ticosUniversidad de Alicante, Spain{svazquez,romero}@dlsi.ua.es{armando,montoyo}@dlsi.ua.esManuel Garc?
?a, M. Teresa Mart?
?n ?M.
?Angel Garc?
?a and L. Alfonso Uren?aDpto.
de Informa?ticaUniversidad de Jae?n, Spain{mgarcia,maite}@ujaen.es{magc,laurena}@ujaen.esDavide Buscaldi, Paolo Rosso ?Antonio Molina, Ferra?n Pla?
and Encarna SegarraDpto.
de Sistemas Informa?ticos y Computacio?nUniv.
Polit.
de Valencia, Spain{dbuscaldi,prosso}@dsic.upv.es{amolina,fpla,esegarra}@dsic.upv.esAbstractThe R2D2 systems for the English All-Words andLexical Sample tasks at SENSEVAL-3 are based onseveral supervised and unsupervised methods com-bined by means of a voting procedure.
Main goalwas to take advantage of training data when avail-able, and getting maximum coverage with the helpof methods that not need such learning examples.The results reported in this paper show that super-vised and unsupervised methods working in par-allel, and a simple sequence of preferences whencomparing the answers of such methods, is a feasi-ble method.
.
.The whole system is, in fact, a cascade of deci-sions of what label to assign to a concrete instancebased on the agreement of pairs of systems, whenit is possible, or selecting the available answer fromone of them.
In this way, supervised are preferred tounsupervised methods, but these last ones are ableto tag such words that not have available trainingdata.1 IntroductionDesigning a system for Natural Language Process-ing (NLP) requires a large knowledge on languagestructure, morphology, syntax, semantics and prag-matic nuances.
All of these different linguisticknowledge forms, however, have a common asso-ciated problem, their many ambiguities, which aredifficult to resolve.In this paper we concentrate on the resolutionof the lexical ambiguity that appears when a givenword in a context has several different meanings.?
This paper has been partially supported by the SpanishGovernment (CICyT) under project number TIC-2003-7180and the Valencia Government (OCyT) under project numberCTIDIB-2002-151This specific task is commonly referred as WordSense Disambiguation (WSD).
This is a difficultproblem that is receiving a great deal of attentionfrom the research community because its resolu-tion can help other NLP applications as MachineTranslation (MT), Information Retrieval (IR), TextProcessing, Grammatical Analysis, Information Ex-traction (IE), hypertext navigation and so on.The R2D2 Team has participated in two tasks:English all-words and lexical sample.
We use sev-eral different systems both supervised and unsuper-vised.
The supervised methods are based on Max-imum Entropy (ME) (Lau et al, 1993; Berger etal., 1996; Ratnaparkhi, 1998), neural network usingthe Learning Vector Quantization algorithm (Koho-nen, 1995) and Specialized Hidden Markov Mod-els (Pla, 2000).
The unsupervised methods are Rel-evant Domains (RD) (Montoyo et al, 2003) andthe CIAOSENSO WSD system which is based onConceptual Density (Agirre and Rigau, 1995), fre-quency of WordNet (Miller et al, 1993a) senses andWordNet Domains (Magnini and Cavaglia, 2000).In the following section we will show a morecomplete description of the systems.
Next, howsuch methods were combined in two voting sys-tems, and the results obtained in SENSEVAL-3.
Fi-nally, some conclusions will be presented.2 Systems descriptionIn this section the systems that have participated atSENSEVAL-3 will be described.2.1 Maximum EntropyME modeling provides a framework for integratinginformation for classification from many heteroge-neous information sources (Manning and Schu?tze,1999).
ME probability models have been success-Association for Computational Linguisticsfor the Semantic Analysis of Text, Barcelona, Spain, July 2004SENSEVAL-3: Third International Workshop on the Evaluation of Systemsfully applied to some NLP tasks, such as POS tag-ging or sentence boundary detection (Ratnaparkhi,1998).
ME have been also applied to WSD (vanHalteren et al, 2001; Montoyo and Sua?rez, 2001;Sua?rez and Palomar, 2002), and as meta-learner in(Ilhan et al, 2001).Our ME-based system has been shown competi-tive (Ma`rquez et al, 2003) when compared to othersupervised systems such as Decision Lists, SupportVector Machines, and AdaBoost.
The features thatwere defined to train the system are those describedin Figure 1.?
the target word itself?
lemmas of content-words at positions ?1, ?2, ?3?
words at positions ?1, ?2,?
words at positions ?1, ?2, ?3?
content-words at positions ?1, ?2, ?3?
POS-tags of words at positions ?1, ?2, ?3?
lemmas of collocations at positions (?2,?1),(?1,+1), (+1,+2)?
collocations at positions (?2,?1), (?1,+1),(+1,+2)?
lemmas of nouns at any position in context, occur-ring at least m% times with a sense?
grammatical relation of the target word?
the word that the target word depends on?
the verb that the target word depends on?
the target word belongs to a multi-word, as identi-fied by the parserFigure 1: Features Used for the Supervised Learn-ing of the ME systemBecause the ME system needs annotated datafor the training, Semcor (Miller et al, 1993b) wasused for the English All-Words task, the systemwas trained using Semcor (Miller et al, 1993b), andparsed by Minipar (Lin, 1998).
Only those wordsthat have 10 examples or more in Semcor were pro-cessed in order to obtain a ME classifier.For the Spanish Lexical Sample task, the train-ing data from SENSEVAL-3 was the source of la-beled examples.
We did not use any parser, just thelemmatization and POS-tagging information sup-plied into the training data itself.2.2 UPV-SHMM-AWThe upv-shmm-aw WSD system is a supervised ap-proach based on Specialized Hidden Markov Mod-els (SHMM).Basically, a SHMM consists of changing thetopology of a Hidden Markov Model in order to geta more accurate model which includes more infor-mation.
This is done by means of an initial stepprevious to the learning process.
It consists of theredefinition of the input vocabulary and the outputtags.
This redefinition is done by means of two pro-cesses which transform the training set: the selec-tion process chooses which input features (words,lemmas, part-of-speech tags, ...) are relevant to thetask, and the specialization process redefines theoutput tags by adding information from the input.This specialization produces some changes in themodel topology, in order to allow the model to bet-ter capture some contextual restrictions and to get amore accurate model.We used as training data the part of the Sem-Cor corpus that is semantically annotated and su-pervised for nouns, verbs, adjectives and adverbs,and the test data set provided by SENSEVAL-2.We used 10% of the training corpus as a develop-ment data set in order to determine the best selectionand specialization criteria.In the experiments, we used WordNet1.6 (Milleret al, 1993a) as a dictionary that supplies all thepossible semantic senses for a given word.
Our sys-tem disambiguated all the polysemic lemmas, thatis, the coverage of our system was 100%.
For un-known words (words that did not appear in the train-ing data set), we assigned the first sense in WordNet.2.3 Relevant DomainsThis is an unsupervised WSD method based on theWordNet Domains lexical resource (Magnini andCavaglia, 2000).
The underlaying working hypoth-esis is that domain labels, such as ARCHITEC-TURE, SPORT and MEDICINE provide a naturalway to establish semantic relations between wordsenses, that can be used during the disambiguationprocess.
This resource has already been used onWord Sense Disambiguation (Magnini and Strappa-rava, 2000), but it has not made use of glosses infor-mation.
So our approach make use of a new lexicalresource obtained from glosses information namedRelevant Domains.First step is to obtain the Relevant Domains re-source from WordNet glosses.
For this task is nec-essary a previous part-of-speech tagging of Word-Net glosses (each gloss has associated a domain la-bel).
So we extract all nouns, verbs, adjectives andadverbs from glosses and assign them their associ-ated domain label.
With this information and usingthe Association Ratio formula(w=word,D=domainlabel), in (1), we obtain the Relevant Domains re-source.AR(w,D) = Pr(w|D)log2Pr(w|D)Pr(w) (1)The final result is for each word, a set of domainlabels sorted by Association Ratio, for example,for word plant?
its Relevant Domains are: genetics0.177515, ecology 0.050065, botany 0.038544 .
.
.
.Once obtained Relevant Domains the disam-biguation process is carried out.
We obtain fromthe text source the context words that co-occur withthe word to be disambiguated (context could bea sentence or a window of words).
We obtain acontext vector from Relevant Domains and contextwords (in case of repeated domain labels, they areweighted).
Furthermore we need a sense vector ob-tained in the same way as context vector from wordsof glosses of each word sense.
We select the cor-rect sense using the cosine measure between con-text vector and sense vectors.
So the selected senseis that for which the cosine with the context vectoris closer to one.2.4 LVQ-JA ?EN-ELSThe LVQ-JA ?EN-ELS system (Garc?
?a-Vega et al,2003) is based on a supervised learning algorithmfor WSD.
The method trains a neural network usingthe Learning Vector Quantization (LVQ) algorithm(Kohonen, 1995), integrating Semcor and severalsemantic relations of WordNet.The Vector Space Model (VSM) is used as an in-formation representation model.
Each sense of aword is represented as a vector in an n-dimensionalspace where n is the number of words in all its con-texts.We use the LVQ algorithm to adjust the wordweights.
The input vector weights are calculatedas shown by (Salton and McGill, 1983) with thestandard (tf ?
idf).
They are presented to the LVQnetwork and, after training, the output vectors areobtained, containing the adjusted weights for allsenses of each word.Any word to disambiguate is represented with avector in the same way.
This representation must becompared with all the trained sense vectors of theword by applying the cosine similarity rule:sim(wk, xi) = wk ?
xi| wk | ?
| xi | (2)The sense corresponding to the vector of highestsimilarity is selected as the disambiguated sense.To train the neural network we have inte-grated semantic information from two linguistic re-sources: SemCor1.6 corpus and WordNet1.7.1 lex-ical database.
From Semcor1.6 we used the para-graph as a contextual semantic unit and each con-text was included in the training vector set.
FromWordNet1.7.1 some semantic relations were consid-ered, specifically, synonymy, antonymy, hyponymy,homonymy, hyperonymy, meronymy, and coordi-nate terms.
This information was introduced to thetraining set through the creation of artificial para-graphs with the words of each relation.
So, for aword with 7 senses, 7 artificial paragraphs with thesynonyms of the 7 senses were added, 7 more withall its hyponyms, and so on.The learning algorithm is very simple.
First, thelearning rate and the codebook vectors are initial-ized.
Then, the following procedure is repeated forall the training input vectors until a stopping crite-rion is satisfied:- Select a training input pattern, x, with class d,and present it to the network- Calculate the Euclidean distance between the in-put vector and each codebook vector || x?
wk ||- Select the codebook vector, wc, that is closest tothe input vector, x, like the winner sense.- The winner neuron updates its weights accord-ing the learning equation:wc(t+ 1) = wc(t) + s ?
?
(t) ?
[x(t)?
wc(t)] (3)where s = 0, if k 6= c; s = 1, if x(t) and wc(t)belong to the same class (c = d); and s = ?1, ifthey do not (c 6= d).
?
(t) is the learning rate, and0 < ?
(t) < 1 is a monotically decreasing func-tion of time.
It is recommended that ?
(t) shouldalready initially be rather small, say, smaller than0.1 (Kohonen, 1995) and ?
(t) continues decreasingto a given threshold, u, very close to 0.2.5 CIAOSENSOThe CIAOSENSO WSD system is an unsupervisedsystem based on Conceptual Density, the frequencyof WordNet sense, and WordNet Domains.
Concep-tual Density is a measure of the correlation amongthe sense of a given word and its context.
Thenoun sense disambiguation is performed by meansof a formula combining the Conceptual Densitywith WordNet sense frequency (Rosso et al, 2003).The context window used in both the English all-words and lexical sample tasks is of 4 nouns.
Ad-ditional weights are assigned to those senses hav-ing the same domain as the context nouns?
senses.Each weight is proportional to the frequency of suchsenses, and is calculated as MDW (f, i) = 1/f ?1/iwhere f is an integer representing the frequencyof the sense of the word to be disambiguated andi gives the same information for the context word.Example: If the word to be disambiguated is doc-tor, the domains for senses 1 and 4 are, respec-tively, Medicine and School.
Therefore, if one ofthe context words is university, the resulting weightfor doctor(4) and university(3) is 1/4 ?
1/3.The sense disambiguation of an adjective is per-formed only on the basis of the above weights.Given one of its senses, we extract the synsets ob-tained by the similar to, pertainym and attributerelationships.
For each of them, we calculate theMDW with respect to the senses of the contextnoun.
The weight assigned to the adjective senseis the average between these MDWs.
The se-lected sense is the one having the maximum averageweight.The sense disambiguation of a verb is done nearlyin the same way, but taking into consideration onlythe MDWs with the context words.
In the all-wordstask the context words are the noun before and af-ter the verb, whereas in the lexical sample task thecontext words are four (two before and two after theverb), without regard to their morphological cate-gory.
This has been done in order to improve therecall in the latter task, for which the test corpus ismade up mostly by verbs.The sense disambiguation of adverbs (in bothtasks) is carried out in the same way of the disam-biguation of verbs for the lexical sample task.3 Tasks ProcessingWe have selected several combinations of such sys-tems described before for two voting systems, onefor the Lexical-Sample task and the other for theAll-Words task.3.1 English Lexical Sample TaskAt the English Lexical Sample task we combinedthe answers of four systems: Relevant Domains,CIAOSENSO, LVQ-JA ?EN-ELS and Maximum En-tropy.The four methods worked in parallel and theirsets of answers were the input of a majority votingprocedure.
This procedure selected those answerswith more systems agreements.
In case of tie wegave priority to supervised systems.With this voting system we obtained around a63% precision and a 52% recall.3.2 English All Words TaskFor this task we used a voting system combiningthe results of Relevant Domains, Maximum En-tropy, CIAOSENSO and UPV-SHMM-AW.
So weobtained the final results after 10 steps.Step 1, we selected those answers with agree-ment between ME and UPV-SHMM-AW (super-vised systems).Step 2, from no agreement in step 1 we selectedthose answers with agreement between ME and Rel-evant Domains.Step 3, from no agreement in step 2 we selectedthose answers with agreement between ME andCIAOSENSO.Step 4, from no agreement in step 3 we se-lected those answers with agreement betweenCIAOSENSO and UPV-SHMM-AW.Step 5, from no agreement in step 4 we se-lected those answers with agreement between UPV-SHMM-AW and Relevant Domains.Step 6, from no agreement in step 5 we selectedthose answers with agreement between RelevantDomains and CIAOSENSO.Step 7, from no agreement in step 6 we selectedMaximum Entropy answers.Step 8, from the remaining unlabeled instanceswe selected UPV-SHMM-AW answers.Step 9, from the remaining unlabeled instanceswe selected Relevant Domains answers.Step 10, from the remaining unlabeled instanceswe selected CIAOSENSO answers.Last step was labeling with the most frequentsense in WordNet those instances that had been nottagged by any system, but in view of the final resultsonly two instances had not answer and we didn?tfind them in WordNet.With this voting system preference was given tosupervised systems over unsupervised systems.We obtained around a 63% precision and a 63%recall.4 ConclusionsThis paper presents the main characteristics ofthe Maximum Entropy, LVQ-JAEN-ELS, UPV-SHMM-AW, Relevant Domains and CIAOSENSOsystems within the framework of SENSEVAL-3 En-glish Lexical Sample and All Words tasks.
Thesesystems are combined with a voting technique ob-taining a promising results for English All Wordsand English Lexical Sample tasks.ReferencesEneko Agirre and German Rigau.
1995.
A pro-posal for word sense disambiguation using Con-ceptual Distance.
In Proceedings of the Interna-tional Conference ?Recent Advances in NaturalLanguage Processing?
(RANLP95).Adam L. Berger, Stephen A. Della Pietra, and Vin-cent J. Della Pietra.
1996.
A maximum entropyapproach to natural language processing.
Com-putational Linguistics, 22(1):39?71.Manuel Garc?
?a-Vega, Mar?
?a Teresa Mart?
?n-Valdivia, and Luis Alfonso Uren?a.
2003.Aprendizaje competitivo lvq para la desam-biguacio?n le?xica.
Revista de la SociedadEspaola para el Procesamiento del LenguajeNatural, 31:125?132.H.
Tolga Ilhan, Sepandar D. Kamvar, Dan Klein,Christopher D. Manning, and Kristina Toutanova.2001.
Combining Heterogeneous Classifiers forWord-Sense Disambiguation.
In Judita Preissand David Yarowsky, editors, Proceedings of the2nd International Workshop on Evaluating WordSense Disambiguation Systems (SENSEVAL-2),pages 87?90, Toulouse, France, July.
ACL-SIGLEX.T.
Kohonen.
1995.
Self-organization and associa-tive memory.
2nd Ed.
Springer Verlag, Berlin.R.
Lau, R. Rosenfeld, and S. Roukos.
1993.Adaptative statistical language modeling usingthe maximum entropy principle.
In Proceedingsof the Human Language Technology Workshop,ARPA.Dekang Lin.
1998.
Dependency-based evaluationof minipar.
In Proceedings of the Workshop onthe Evaluation of Parsing Systems, First Inter-national Conference on Language Resources andEvaluation, Granada, Spain.Bernardo Magnini and Gabriela Cavaglia.
2000.Integrating Subject Field Codes into WordNet.
InM.
Gavrilidou, G. Crayannis, S. Markantonatu,S.
Piperidis, and G. Stainhaouer, editors, Pro-ceedings of LREC-2000, Second InternationalConference on Language Resources and Evalu-ation, pages 1413?1418, Athens, Greece.Bernardo Magnini and C. Strapparava.
2000.
Ex-periments in Word Domain Disambiguation forParallel Texts.
In Proceedings of the ACL Work-shop on Word Senses and Multilinguality, HongKong, China.Christopher D. Manning and Hinrich Schu?tze.1999.
Foundations of Statistical Natural Lan-guage Processing.
The MIT Press, Cambridge,Massachusetts.Llu?
?s Ma`rquez, Fco.
Javier Raya, John Car-roll, Diana McCarthy, Eneko Agirre, DavidMart?
?nez, Carlo Strapparava, and AlfioGliozzo.
2003.
Experiment A: several all-wordsWSD systems for English.
Technical ReportWP6.2, MEANING project (IST-2001-34460),http://www.lsi.upc.es/?nlp/meaning/meaning.html.George A. Miller, Richard Beckwith, ChristianeFellbaum, Derek Gross, and Katherine J. Miller.1993a.
Five Papers on WordNet.
Special Issue ofthe International journal of lexicography, 3(4).George A. Miller, C. Leacock, R. Tengi, andT.
Bunker.
1993b.
A Semantic Concordance.
InProceedings of ARPA Workshop on Human Lan-guage Technology, pages 303?308, Plainsboro,New Jersey.Andre?s Montoyo and Armando Sua?rez.
2001.The University of Alicante word sense disam-biguation system.
In Judita Preiss and DavidYarowsky, editors, Proceedings of the 2nd In-ternational Workshop on Evaluating Word SenseDisambiguation Systems (SENSEVAL-2), pages131?134, Toulouse, France, July.
ACL-SIGLEX.Andre?s Montoyo, Sonia Va?zquez, and GermanRigau.
2003.
Me?todo de desambiguacio?n le?xicabasada en el recurso le?xico Dominios Rele-vantes.
Procesamiento del Lenguaje Natural, 30,september.F.
Pla.
2000.
Etiquetado Le?xico y Ana?lisisSinta?ctico Superficial basado en Modelos Es-tad??sticos.
Tesis doctoral, Departamento de Sis-temas Informa?ticos y Computacio?n.
Universidadde Polite?cnica de Valencia, Septiembre.Adwait Ratnaparkhi.
1998.
Maximum EntropyModels for Natural Language Ambiguity Resolu-tion.
Ph.D. thesis, University of Pennsylvania.P.
Rosso, F. Masulli, D. Buscaldi, F. Pla, andA.
Molina.
2003.
Automatic noun disambigua-tion.
LNCS, Springer Verlag, 2588:273?276.G.
Salton and M.J. McGill.
1983.
Introductionto modern information retrieval.
McGraw-Hill,New York.Armando Sua?rez and Manuel Palomar.
2002.A maximum entropy-based word sense disam-biguation system.
In Hsin-Hsi Chen and Chin-Yew Lin, editors, Proceedings of the 19th In-ternational Conference on Computational Lin-guistics, pages 960?966, Taipei, Taiwan, August.COLING 2002.H.
van Halteren, J. Zavrel, and W. Daelemans.2001.
Improving accuracy in wordclass tag-ging through combination of machine learningsystems.
Computational Linguistics, 27(2):199?230.
