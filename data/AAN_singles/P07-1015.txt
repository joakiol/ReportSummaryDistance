Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 112?119,Prague, Czech Republic, June 2007. c?2007 Association for Computational LinguisticsMultilingual Transliteration Using Feature based Phonetic MethodSu-Youn Yoon, Kyoung-Young Kim and Richard SproatUniversity of Illinois at Urbana-Champaign{syoon9,kkim36,rws}@uiuc.eduAbstractIn this paper we investigate named entitytransliteration based on a phonetic scoringmethod.
The phonetic method is computedusing phonetic features and carefullydesigned pseudo features.
The proposedmethod is tested with four languages ?Arabic, Chinese, Hindi and Korean ?
andone source language ?
English, usingcomparable corpora.
The proposed methodis developed from the phonetic methodoriginally proposed in Tao et al (2006).
Incontrast to the phonetic method in Tao et al(2006) constructed on the basis of purelinguistic knowledge, the method in thisstudy is trained using the Winnow machinelearning algorithm.
There is salientimprovement in Hindi and Arabiccompared to the previous study.
Moreover,we demonstrate that the method can alsoachieve comparable results, when it istrained on language data different from thetarget language.
The method can be appliedboth with minimal data, and without targetlanguage data for various languages.1 Introduction.In this paper, we develop a multi-lingualtransliteration system for named entities.
Namedentity transliteration is the process of producing,for a name in a source language, a set of one ormore transliteration candidates in a target language.The correct transliteration of named entities iscrucial, since they are frequent and important keywords in information retrieval.
In addition,requests in retrieving relevant documents inmultiple languages require the development of themulti-lingual system.The system is constructed using pairedcomparable texts.
The comparable texts are aboutthe same or related topics, but are not, in general,translations of each other.
Using this data, thetransliteration method aims to find transliterationcorrespondences in the paired languages.
Forexample, if there were an English and Arabicnewspaper on the same day, each of thenewspapers would contain articles about the sameimportant international events.
From thesecomparable articles across the paired languages,the same named entities are expected to be found.Thus, from the named entities in an Englishnewspaper, the method would find transliterationcorrespondences in comparable texts in otherlanguages.The multi-lingual transliteration system entailssolving several problems which are verychallenging.
First, it should show stableperformance for many unrelated languages.
Thetransliteration will be influenced by the differencein the phonological systems of the language pairs,and the process of transliteration differs accordingto the languages involved.
For example, in Arabictexts, short vowels are rarely written while longvowels are written.
When transliterating Englishnames, the vowels are disappeared or written aslong vowels.
For example London is transliteratedas lndn ????????
?, and both vowels are not representedin the transliteration.
However, Washington isoften transliterated as  wSnjTwn ??????
?????????????
, andthe final vowel is realized with long vowel.Transliterations in Chinese are very different fromthe original English pronunciation due to the112limited syllable structure and phoneme inventoryof Chinese.
For example, Chinese does not allowconsonant clusters or coda consonants except [n,N],and this results in deletion, substitution ofconsonants or insertion of vowels.
Thus while asyllable initial /d/ may surface as in Baghdad???
ba-ge-da, note that the syllable final /d/ isnot represented.
Multi-lingual transliterationsystem should solve these language dependentcharacteristics.One of the most important concerns in amultilingual transliteration system is itsapplicability given a small amount of training data,or even no training data: for arbitrary languagepairs, one cannot in general assume resources suchas name dictionaries.
Indeed, for some rarelyspoken languages, it is practically impossible tofind enough training data.
Therefore, the proposedmethod aims to obtain comparable performancewith little training data.2 Previous WorkPrevious work ?
e.g.
(Knight and Graehl, 1998;Meng et al, 2001; Al-Onaizan and Knight, 2002;Gao et al, 2004) ?
has mostly assumed that onehas a training lexicon of transliteration pairs, fromwhich one can learn a model, often a source-channel or MaxEnt-based model.Comparable corpora have been studiedextensively in the literature, but transliteration inthe context of comparable corpora has not beenwell addressed.
In our work, we adopt the methodproposed in (Tao et al, 2006) and apply it to theproblem of transliteration.Measuring phonetic similarity between wordshas been studied for a long time.
In many studies,two strings are aligned using a string alignmentalgorithm, and an edit distance (the sum of the costfor each edit operation), is used as the phoneticdistance between them.
The resulting distancedepends on the costs of the edit operation.
Thereare several approaches that use distinctive featuresto determine the costs of the edit operation.
Gildeaand Jurafsky (1996) counted the number offeatures whose values are different, and used themas a substitution cost.
However, this approach has acrucial limitation: the cost does not consider theimportance of the features.
Nerbonne and Heeringa(1997) assigned a weight for each feature based onentropy and information gain, but the results wereeven less accurate than the method without weight.3 Phonetic transliteration methodIn this paper, the phonetic transliteration isperformed using the following steps:1) Generation of the pronunciation forEnglish words and target words:a. Pronunciations for English words are obtainedusing the Festival text-to-speech system (Taylor etal., 1998).b.
Target words are automatically converted intotheir phonemic level transcriptions by variouslanguage-dependent means.
In the case ofMandarin Chinese, this is based on the standardPinyin transliteration system.
Arabic words areconverted based on orthography, and the resultingtranscriptions are reasonably correct except for thefact that short vowels were not represented.Similarly, the pronunciation of Hindi and Koreancan be well-approximated based on the standardorthographic representation.
All pronunciations arebased on the WorldBet transliteration system(Hieronymus, 1995), an ascii-only version of theIPA.2) Training a linear classifier using theWinnow algorithm:A linear classifier is trained using the trainingdata which is composed of transliteration pairs andnon-transliteration pairs.
Transliteration pairs areextracted from the transliteration dictionary, whilenon-transliteration pairs are composed of anEnglish named entity and a random word from thetarget language newspaper.a.
For all the training data, the pairs ofpronunciations are aligned using standard stringalignment algorithm based on Kruskal (1999).
Thesubstitution/insertion/deletion cost for the stringalignment algorithm is based on the baseline costfrom (Tao et al 2006).b.
All phonemes in the pronunciations aredecomposed into their features.
The features usedin this study will be explained in detail in part 3.1.c.
For every phoneme pair (p1, p2) in the alignedpronunciations, a feature xi has a ?+1?
value or a ??1?
value:xi =   +1   when p1 and p2  have the samevalues for feature xi?1   otherwise113d.
A linear classifier is trained using theWinnow algorithm from the SNoW toolkit(Carlson et al, 1999).3) Scoring English-target word pair:a.
For a given English word, the score between itand a target word is computed using the linearclassifier.b.
The score ranges from 0 to any positivenumber, and the candidate with the highest score isselected as the transliteration of the given Englishname.3.1  Feature setHalle and Clements (1983)?s distinctive featuresare used in order to model the substitution/insertion/deletion costs for the string-alignmentalgorithm and linear classifier.
A distinctivefeature is a feature that describes the phoneticcharacteristics of phonetic segments.However, distinctive features alone are notenough to model the frequent sound changepatterns that occur when words are adapted acrosslanguages.
For example, stop and fricativeconsonants such as /p, t, k, b, d, g, s, z/ arefrequently deleted when they appear in the codaposition.
This tendency is extremely salient whenthe target languages do not allow coda consonantsor consonant clusters.
For example, since Chineseonly allows /n, N/ in coda position, stop consonantsin the coda position are frequently lost; Stanford istransliterated as sitanfu, with the final /d/ lost.Since traditional distinctive features do notconsider the position in the syllable, this patterncannot be captured by distinctive features alone.To capture these sound change patterns, additionalfeatures such as ?deletion of stop/fricativeconsonant in the coda position?
must be considered.Based on the pronunciation error data of learnersof English as a second language as reported in(Swan and Smith, 2002), we propose the use ofwhat we will term pseudofeatures.
The pseudofeatures in this study are same as in Tao et al(2006).
Swan & Smith (2002)?s study covers 25languages including Asian languages such as Thai,Korean, Chinese and Japanese, Europeanlanguages such as German, Italian, French andPolish, and Middle East languages such as Arabicand Farsi.
The substitution/insertion/deletion errorsof phonemes were collected from this data.
Thefollowing types of errors frequently occur insecond language learners?
speech production.
(1) Substitution: If the learner?s first languagedoes not have a particular phoneme found inEnglish, it is substituted by the most similarphoneme in their first language.
(2) Insertion: If the learner?s first language doesnot have a particular consonant cluster in English,a vowel is inserted.
(3) Deletion: If the learner?s first language doesnot have a particular consonant cluster in English,one consonant in the consonant cluster is deleted.The same substitution/deletion/insertion patternsin a second language learner?s errors also appear inthe transliteration of foreign names.
The deletionof the stop consonant which appears in English-Chinese transliterations occurs frequently in theEnglish pronunciation spoken by Chinese speakers.Therefore, the error patterns in second languagelearners?
can be used in transliteration.Based on (1) ~ (3), 21 pseudo features weredesigned.
All features have binary values.
Usingthese 21 pseudo features and 20 distinctive features,a linear classifier is trained.
Some examples ofpseudo features are presented in Table 1.Pseudo-Feature Description ExampleConsonant-codaSubstitutionof consonantfeature incoda positionSonorant-codaSubstitutionof sonorantfeature incoda positionSubstitutionbetween [N] and[g] in codaposition in ArabicLabial-codaSubstitutionof labialfeature incoda positionSubstitutionbetween [m] and[n] in codaposition in Chinesej-exceptionSubstitutionof [j] and [dZ]Spanish/Catalanand Festival errorw-exception Substitution of [v] and [w]Chinese/Farsi andFestival errorTable 1.
Examples of pseudo features1143.2 Scoring the English-target word pairA linear classifier is trained using the Winnowalgorithm from the SNoW toolkit.The Winnow algorithm is one of the updaterules for linear classifier.
A linear classifier is analgorithm to find a linear function that bestseparates the data.
For the set of features X and setof weights W, the linear classifier is defined as [1](Mitchell, T., 1997)1 21 20 1 1 2 2{ , ,  ... }{ , , ... }( )   1        ...    0-1nnn nX x x xW w w wf x if w wx w x w xotherwise=== + + + + >[1]The linear function assigns label +1 when thepaired target language word is the transliteration ofgiven English word, while it assigns label ?1 whenit is not a transliteration of given English word.The score of an English word and target wordpair is computed using equation [2] which is partof the definition of f(x) in equation [1].01ni iiw w x=+?
[2]The output of equation [2] is termed the targetnode activation.
If this value is high, class 1 ismore activated, and the pair is more likely to be atransliteration pair.
To illustrate, let us assumethere are two candidates in target language (t1 andt2) for an English word e. If the score of (e, t1) ishigher than the score of (e, t2), the pair (e, t1) hasstronger activation than (e, t2).
It means that t1scores higher as the transliteration of e than t2.Therefore, the candidate with the highest score (inthis case t1) is selected as the transliteration of thegiven English name.4 Experiment and ResultsThe linear function was trained for eachlanguage, separately.
500 transliteration pairs wererandomly selected from each transliterationdictionary, and used as positive examples in thetraining procedure.
This is quite small compared toprevious approaches such as Knight and Graehl(1998) or Gao et al (2004).
In addition, 1500words were randomly selected from the newspaperin the target languages, and paired with Englishwords in the positive examples.
A total of 750,000pairs (500 English words?
1500 target words) weregenerated, and used as negative examples in thetraining procedure.Table 2 presents the source of training data foreach language.Transliteration pair Target wordArabic New Mexico State UniversityXinhua ArabicnewswireChinese Behavior Design CorporationXinhuaChinesenewswireHindi Naidunia Hindi newswireNaidunia HindinewswireKoreanthe NationalInstitute of theKorean languageChosunKoreannewspaperTable 2.
Sources of the training dataThe phonetic transliteration method wasevaluated using comparable corpora, consisting ofnewspaper articles in English and the targetlanguages?Arabic, Chinese, Hindi, and Korean?from the same day, or almost the same day.
Usingcomparable corpora, the named-entities for personsand locations were extracted from the English text;in this paper, the English named-entities wereextracted using the named-entity recognizerdescribed in Li et al (2004), based on the SNoWmachine learning toolkit (Carlson et al, 1999).The transliteration task was performed using thefollowing steps:1) English text was tagged using the named-entity recognizer.
The 200 most frequent namedentities were extracted from seven days?
worth ofthe English newswire text.
Among pronunciationsof words generated by the Festival text-to speechsystem, 3% contained errors representingmonophthongs instead of diphthongs or vice versa.1.5% of all cases misrepresented single consonant,and 6% showed errors in the vowels.
Overall,10.5% of the tokens contained pronunciation errorswhich could trigger errors in transliteration.2) To generate the Arabic and Hindi candidates,all words from the same seven days were extracted.In the case of Korean corpus, the collection ofnewspapers was from every five days, unlike theother three language corpora which were collectedevery day; therefore, candidates of Korean were115generated from one month of newspapers, sinceseven days of newspaper articles did not show asufficient number of transliteration candidates.This caused the total number of candidates to bemuch bigger than for the other languages.The words were stemmed all possible waysusing simple hand-developed affix lists: forexample, given a Hindi word c1c2c3, if both c3and c2c3 are in the suffix and ending list, then thissingle word generated three possible candidates: c1,c1c2, and c1c2c3.3) Segmenting Chinese sentences requires adictionary or supervised segmenter.
Since the goalis to use minimal knowledge or data from thetarget language, using supervised methods isinappropriate for our approach.
Therefore, Chinesesentences were not segmented.
Using the 495characters that are frequently used fortransliterating foreign names (Sproat et al, 1996),a sequence of three of more characters from the listwas taken as a possible candidate for Chinese.4) For the given 200 English named entities andtarget language candidate lists, all the possiblepairings of English and target-language name wereconsidered as possible transliteration pairs.The number of candidates for each targetlanguage is presented in Table 3.Language The number of candidatesArabic 12,466Chinese 6,291Hindi 10,169Korean 42,757Table 3.
Number of candidates for each targetlanguage.5) Node activation scores were calculated foreach pair in the test data, and the candidates wereranked by their score.
The candidate with thehighest node activation score was selected as thetransliteration of the given English name.Some examples of English words and the topthree ranking candidates among all of the potentialtarget-language candidates were given in Tables 4,5.
Starred entries are correct.Candidate EnglishWord Rank Script RomanizationArafat*123??????????
?a-la-fa-tela-fa-di-aola-wei-qiTable 4.
Examples of the top-3 candidates in thetransliteration of English ?
ChineseCandidate EnglishWord RankScript Romanization*1 ???
be-thu-nam2 ????
be-thu-nam-chug Vietnam3 ????
pyo-jun-e-wa*1 ??????
?o-su-thu-ley-il-li-a2 ???
us-tol-la Australia3 ????????
?o-su-thu-ley-il-li-a-ey-seTable 5.
Examples of the top-3 candidates in thetransliteration of English-KoreanTo evaluate the proposed transliteration methodsquantitatively, the Mean Reciprocal Rank (MRR),a measure commonly used in information retrievalwhen there is precisely one correct answer (Kandorand Vorhees, 2000) was measured, following Taoand Zhai (2005).Since the evaluation data obtained from thecomparable corpus was small, the systems wereevaluated using both held-out data from thetransliteration dictionary and comparable corpus.First, the results of the held-out data will bepresented.
For a given English name and targetlanguage candidates, all possible combinationswere generated.
Table 6 presents the size of held-out data, and Table 7 presents MRR of the held-outdata.116Numberof EnglishnamedentitiesNumber ofCandidatesin targetlanguageNumber oftotal pairsused in theevaluationArabic 500 1,500 750,000Chinese 500 1,500 750,000Hindi 100 1,500 150,000Korean 100 1,500 150,000Table 6.
Size of the test dataWinnowBaseline  TotalfeaturedistinctivefeatureonlyArabic 0.66 0.74 0.70Chinese 0.74 0.74 0.72Hindi 0.87 0.91 0.91Korean 0.82 0.85 0.82Table 7.
MRRs of the phonetic transliterationThe baseline was computed using the phonetictransliteration method proposed in Tao et al(2006).
In contrast to the method in this study, thebaseline system is purely based on linguisticknowledge.
In the baseline system, the editdistance, which was the result of the stringalignment algorithm, was used as the score of anEnglish-target word pair.
The performance of theedit distance was dependent on insertion/deletion/substitution costs.
These costs were determinedbased on the distinctive features and pseudofeatures, based on the pure linguistic knowledgewithout training data.
As illustrated in Table 7, thephonetic transliteration method using featuresworked adequately for multilingual data, asphonetic features are universal, unlike thephonemes which are composed of them.
Adoptingphonetic features as the units for transliterationyielded the baseline performance.In order to evaluate the effectiveness of pseudofeatures, the method was trained using twodifferent feature sets: a total feature set and adistinctive feature-only set.
For Arabic, Chineseand Korean, the MRR of the total feature set washigher than the MRR of the distinctive feature-onlyset.
The improvement of the total set was 4% forArabic, 2.6% for Chinese, 2.4% for Korean.
Therewas no improvement of the total set in Hindi.
Ingeneral, the pseudo features improved the accuracyof the transliteration.For all languages, the MRR of the Winnowalgorithm with the total feature set was higher thanthe baseline.
There was 7% improvement forArabic, 0.7% improvement for Chinese, 4%improvement for Hindi and 3% improvement forKorean.We turn now to the results on comparablecorpora.
We attempted to create a complete set ofanswers for the 200 English names in our test set,but part of the English names did not seem to haveany standard transliteration in the target languageaccording to the native speaker?s judgment.Accordingly, we removed these names from theevaluation set.
Thus, the resulting list was less than200 English names, as shown in the second columnof Table 8; (Table 8 All).
Furthermore, somecorrect transliterations were not found in ourcandidate list for the target languages, since theanswer never occurred in the target news articles;(Table 8 Missing).
Thus this results in a smallernumber of candidates to evaluate.
This smallernumber is given in the fourth column of Table 8;(Table 8 Core).Language # All # Missing #CoreArabic 192 121 71Chinese 186 92 94Hindi 144 83 61Korean 195 114 81Table 8.
Number of evaluated English NameMRRs were computed on the two setsrepresented by the count in column 2, and thesmaller set represented by the count in column 4.We termed the former MRR ?AllMRR?
and thelatter ?CoreMRR?.
In Table 9, ?CoreMRR?
and?AllMRR?
of the method were presented.117Baseline  WinnowAll-MRRCoreMRRAll-MRRCoreMRRArabic 0.20 0.53 0.22 0.61Chinese 0.25 0.49 0.25 0.50Hindi 0.30 0.69 0.36 0.86Korean 0.30 0.71 0.29 0.69Table 9.
MRRs of the phonetic transliterationIn both methods, CoreMRRs were higher than0.49 for all languages.
That is, if the answer is inthe target language texts, then the method finds thecorrect answer within the top 2 words.As with the previously discussed results, therewere salient improvements in Arabic and Hindiwhen using the Winnow algorithm.
The MRRs ofthe Winnow algorithm except Korean were higherthan the baseline.
There was 7% improvement forArabic and 17% improvement for Hindi inCoreMRR.
In contrast to the 3% improvement inheld-out data, there was a 2% decrease in Korean:the MRRs of Korean from the Winnow algorithmwere lower than baseline, possibly because of thelimited size of the evaluation data.
Similar to theresults of held-out data, the improvement inChinese was small (1%).The MRRs of Hindi and the MRRs of Koreanwere higher than the MRRs of Arabic and Chinese.The lower MRRs of Arabic and Chinese may resultfrom the phonological structures of the languages.In general, transliteration of English word intoArabic and Chinese is much more irregular thanthe transliteration into Hindi and Korean in termsof phonetics.To test the applicability to languages for whichtraining data is not available, we also investigatedthe use of models trained on language pairsdifferent from the target language pair.
Thus, foreach test language pair, we evaluated theperformance of models trained on each of the otherlanguage pairs.
For example, three models weretrained using Chinese, Hindi, and Korean, and theywere tested with Arabic data.
The CoreMRRs ofthis experiment were presented in Table 10.
Notethat the diagonal in this Table represents thewithin-language-pair training and testing scenariothat we reported on above.test dataArabic Chinese HindiKoreanArabic 0.61 0.50 0.86 0.63Chinese 0.59 0.50 0.80 0.66Hindi 0.59 0.54 0.86 0.67train-ingdataKorean 0.56 0.51 0.76 0.69Table 10.
MRRs for the phonetic transliteration 2For Arabic, Hindi, and Korean, MRRs wereindeed the highest when the methods were trainedusing data from the same language, as indicated bythe boldface MRR scores on the diagonal.
Ingeneral, however, the MRRs were not salientlylower across the board when using differentlanguage data than using same-language data intraining and testing.
For all languages, MRRs forthe cross-language case were best when themethods were trained using Hindi.
The differencesbetween MRRs of the method trained from Hindiand MRRs of the method by homogeneouslanguage data were 2% for Arabic and Korean.
Inthe case of Chinese, MRRs of the method trainedby Hindi was actually better than MRRs obtainedby Chinese training data.
Hindi has a largephoneme inventory compared to Korean, Arabic,and Chinese, so the relationship between Englishphonemes and Hindi phonemes is relatively regular,and only small number of language specifictransliteration rules exist.
That is, the languagespecific influences from Hindi are smaller thanthose from other languages.
This characteristic ofHindi may result in the high MRRs for otherlanguages.
What these results imply is that namedentity transliteration could be performed withouttraining data for the target language with phoneticfeature as a unit.
This approach is especiallyvaluable for languages for which training data isminimal or lacking.5 ConclusionIn this paper, a phonetic method for multilingualtransliteration was proposed.
The method wasbased on string alignment, and linear classifierstrained using the Winnow algorithm.
In order tolearn both language-universal and language-specific transliteration characteristics, distinctive118features and pseudo features were used in training.The method can be trained using a small amount oftraining data, and the performance decreases onlyby a small degree when it is trained with alanguage different from the test data.
Therefore,this method is extremely useful forunderrepresented languages for which training datais difficult to find.AcknowledgmentsThis work was funded the National SecurityAgency contract NBCHC040176 (REFLEX) and aGoogle Research grant.ReferencesY.
Al-Onaizan and K. Knight.
2002.
Machinetransliteration of names in Arabic text.
InProceedings of the ACL Workshop on ComputationalApproaches to Semitic Languages, Philadelphia, PA.Andrew J. Carlson, Chad M. Cumby, Jeff L. Rosen, andDan Roth.
1999.
The SNoW learning architecture.Technical Report UIUCDCS-R-99-2101, UIUC CSDept.Wei Gao, Kam-Fai Wong, and Wai Lam.
2004.Phoneme based transliteration of foreign names forOOV problem.
Proceeding of IJCNLP, 374?381.Daniel Gildea and Daniel Jurafsky.
1996.
Learning Biasand Phonological-Rule Induction.
ComputationalLinguistics 22(4):497?530.Morris Halle and G.N.
Clements.
1983.
Problem bookin phonology.
MIT press, Cambridge.James Hieronymus.
1995.
Ascii phonetic symbols forthe world?s languages: Worldbet.http://www.ling.ohio-tate.edu/ edwards/worldbet.pdf.Paul B. Kantor and Ellen B. Voorhees.
2000.
TheTREC-5 confusion track: Comparing retrievalmethods for scanned text.
Information Retrieval, 2:165?176.Kevin Knight and Jonathan Graehl.
1998.
Machinetransliteration.
Computational Linguistics, 24(4).Joseph B. Kruskal.
1999.
An overview of sequencecomparison.
Time Warps, String Edits, andMacromolecules, CSLI, 2nd edition, 1?44.Xin Li, Paul Morie, and Dan Roth.
2004.
Robustreading: Identification and tracing of ambiguousnames.
Proceeding of NAACL-2004.H.M.
Meng, W.K Lo, B. Chen, and K. Tang.
2001.Generating phonetic cognates to handle namedentities in English-Chinese cross-language spokendocument retrieval.
In Proceedings of the AutomaticSpeech Recognition and Understanding Workshop.Tom M. Mitchell.
1997.
Machine Learning, McCraw-Hill, Boston.John Nerbonne and Wilbert Heeringa.
1997.
MeasuringDialect Distance Phonetically.
Proceedings of the 3rdMeeting of the ACL Special Interest Group inComputational Phonology.Richard Sproat, Chilin.
Shih, William A. Gale, andNancy Chang.
1996.
A stochastic finite-state word-segmentation algorithm for Chinese.
ComputationalLinguistics, 22(3).Michael Swan and Bernard Smith.
2002.
LearnerEnglish, Cambridge University Press, Cambridge .Tao Tao and ChengXiang Zhai.
2005.
Miningcomparable bilingual text corpora for cross-languageinformation integration.
Proceeding of the eleventhACM SIGKDD international conference onKnowledge discovery in data mining, 691?696.Tao Tao, Su-Youn Yoon, Andrew Fister, RichardSproat and ChengXiang Zhai.
"Unsupervised NamedEntity Transliteration Using Temporal and PhoneticCorrelation."
EMNLP, July 22-23, 2006, Sydney,Australia.Paul A. Taylor, Alan Black, and Richard Caley.
1998.The architecture of the Festival speech synthesissystem.
Proceedings of the Third ESCAWorkshop onSpeechSynthesis, 147?151.119
