Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1363?1373,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsCan characters reveal your native language?
A language-independentapproach to native language identificationRadu Tudor Ionescu, Marius Popescu, Aoife Cahill?University of BucharestDepartment of Computer Science14 Academiei, Bucharest, Romaniaraducu.ionescu@gmail.compopescunmarius@gmail.com?Educational Testing Service660 Rosedale RdPrinceton, NJ 08541, USAacahill@ets.orgAbstractA common approach in text mining taskssuch as text categorization, authorshipidentification or plagiarism detection is torely on features like words, part-of-speechtags, stems, or some other high-level lin-guistic features.
In this work, an approachthat uses character n-grams as features isproposed for the task of native languageidentification.
Instead of doing standardfeature selection, the proposed approachcombines several string kernels using mul-tiple kernel learning.
Kernel Ridge Re-gression and Kernel Discriminant Analy-sis are independently used in the learningstage.
The empirical results obtained in allthe experiments conducted in this work in-dicate that the proposed approach achievesstate of the art performance in native lan-guage identification, reaching an accuracythat is 1.7% above the top scoring systemof the 2013 NLI Shared Task.
Further-more, the proposed approach has an im-portant advantage in that it is language in-dependent and linguistic theory neutral.
Inthe cross-corpus experiment, the proposedapproach shows that it can also be topicindependent, improving the state of the artsystem by 32.3%.1 IntroductionUsing words as basic units is natural in textualanalysis tasks such as text categorization, author-ship identification or plagiarism detection.
Per-haps surprisingly, recent results indicate that meth-ods handling the text at the character level canalso be very effective (Lodhi et al., 2002; Sander-son and Guenter, 2006; Popescu and Dinu, 2007;Grozea et al., 2009; Popescu, 2011; Popescu andGrozea, 2012).
By disregarding features of natu-ral language such as words, phrases, or meaning,an approach that works at the character level hasan important advantage in that it is language inde-pendent and linguistic theory neutral.
This paperpresents a state of the art machine learning systemfor native language identification that works at thecharacter level.
The proposed system is inspiredby the system of Popescu and Ionescu (2013), butincludes some variations and improvements.
Amajor improvement is that several string kernelsare combined via multiple kernel learning (Shawe-Taylor and Cristianini, 2004).
Despite the fact thatthe (histogram) intersection kernel is very popularin computer vision (Maji et al., 2008; Vedaldi andZisserman, 2010), it has never been used before intext mining.
In this work, the intersection kernel isused for the first time in a text categorization task,alone and in combination with other kernels.
Theintersection kernel lies somewhere in the middlebetween the kernel that takes into account only thepresence of n-grams and the kernel based on thefrequency of n-grams (p-spectrum string kernel).Two kernel classifiers are proposed for thelearning task, namely Kernel Ridge Regression(KRR) and Kernel Discriminant Analysis (KDA).The KDA classifier is able to avoid the class-masking problem (Hastie and Tibshirani, 2003),which may often arise in the context of nativelanguage identification.
Several experiments areconducted to evaluate the performance of the ap-proach proposed in this work.
While multiple ker-nel learning seems to produce a more robust sys-tem, the two kernel classifiers obtained mixed re-sults in the experiments.
Overall, the empirical re-sults indicate that the approach proposed in thispaper achieves state of the art performance in na-tive language identification, while being both lan-1363guage independent and linguistic theory neutral.Furthermore, the approach based on string kernelsdoes not need any expert knowledge of words orphrases in the language.The paper is organized as follows.
Relatedwork is presented in Section 2.
Section 3 presentsseveral similarity measures for strings, includingstring kernels and Local Rank Distance.
Thelearning methods used in the experiments are de-scribed in Section 4.
Section 5 presents detailsabout the experiments.
Finally, the conclusions aredrawn in Section 6.2 Related Work2.1 Native Language IdentificationThe goal of automatic native language identifica-tion (NLI) is to determine the native language ofa language learner, based on a piece of writing ina foreign language.
This can provide useful in-formation in forensic linguistic tasks (Estival etal., 2007) or could be used in an educational set-ting to provide contrastive feedback to languagelearners.
Most research has focused on identify-ing the native language of English language learn-ers, though there have been some efforts recentlyto identify the native language of writing in otherlanguages (Malmasi and Dras, 2014).In general most approaches to NLI have usedmulti-way classification with SVMs or similarmodels along with a range of linguistic features.The seminal paper by Koppel et al.
(2005) intro-duced some of the best-performing features: char-acter, word and part-of-speech n-grams along withfeatures inspired by the work in the area of second-language acquisition such as spelling and gram-matical errors.
In 2013, Tetreault et al.
(2013) or-ganized the first shared task in the field.
This al-lowed researchers to compare approaches for thefirst time on a specifically designed NLI corpusthat was much larger than previously availabledata sets.
In the shared task, 29 teams submit-ted results for the test set, and one of the mostsuccessful aspects of the competition was that itdrew submissions from teams working in a varietyof research fields.
The submitted systems utilizeda wide range of machine learning approaches,combined with several innovative feature contri-butions.
The best performing system achieved anoverall accuracy of 83.6% on the 11-way classifi-cation of the test set, although there was no signif-icant difference between the top teams.2.2 Methods that Work at the CharacterLevelIn recent years, methods of handling text atthe character level have demonstrated impres-sive performance levels in various text analy-sis tasks (Lodhi et al., 2002; Sanderson andGuenter, 2006; Popescu and Dinu, 2007; Grozeaet al., 2009; Popescu, 2011; Popescu and Grozea,2012).
Lodhi et al.
(2002) used string kernelsfor document categorization with very good re-sults.
String kernels were also successfully used inauthorship identification (Sanderson and Guenter,2006; Popescu and Dinu, 2007; Popescu andGrozea, 2012).
For example, the system describedin (Popescu and Grozea, 2012) ranked first in mostproblems and overall in the PAN 2012 TraditionalAuthorship Attribution tasks.Using string kernels makes the correspondinglearning method completely language indepen-dent, because the texts will be treated as sequencesof symbols (strings).
Methods working at theword level or above very often restrict their featurespace according to theoretical or empirical princi-ples.
For instance, they select only features that re-flect various types of spelling errors or only sometype of words, such as function words.
These fea-tures prove to be very effective for specific tasks,but it is possible that other good features also ex-ist.
String kernels embed the texts in a very largefeature space, given by all the substrings of lengthp, and leave it to the learning algorithm to selectimportant features for the specific task, by highlyweighting these features.
It is important to notethat this approach is also linguistic theory neutral,since it disregards any features of natural languagesuch as words, phrases, or meaning.
On the otherhand, a method that considers words as featurescannot be completely language independent, sincethe definition of a word is necessarily language-specific.
For example, a method that uses onlyfunction words as features is not completely lan-guage independent because it needs a list of func-tion words which is specific to a language.
Whenfeatures such as part-of-speech tags are used, asin the work of Jarvis et al.
(2013), the method re-lies on a part-of-speech tagger which might not beavailable (yet) for some languages.
Furthermore,a way to segment a text into words is not an easytask for some languages, such as Chinese.Character n-grams are used by some of the sys-tems developed for native language identification.1364In work where feature ablation results have beenreported, the performance with only character n-gram features was modest compared to other typesof features (Tetreault et al., 2012).
Initially, mostwork limited the character features to unigrams,bigrams and trigrams, perhaps because longer n-grams were considered too expensive to computeor unlikely to improve performance.
However,some of the top systems in the 2013 NLI SharedTask were based on longer character n-grams,up to 9-grams (Jarvis et al., 2013; Popescu andIonescu, 2013).
The results presented in this workare obtained using a range of 5?8 n-grams.
Com-bining all 5?8 n-grams would generate millionsof features, which are indeed expensive to com-pute and represent.
The key to avoiding the com-putation of such a large number of features liesin using the dual representation provided by thestring kernel.
String kernel similarity matrices canbe computed much faster and are extremely usefulwhen the number of samples is much lower thanthe number of features.3 Similarity Measures for Strings3.1 String KernelsThe kernel function gives kernel methods thepower to naturally handle input data that is notin the form of numerical vectors, e.g.
strings.The kernel function captures the intuitive notionof similarity between objects in a specific domainand can be any function defined on the respec-tive domain that is symmetric and positive definite.For strings, many such kernel functions exist withvarious applications in computational biology andcomputational linguistics (Shawe-Taylor and Cris-tianini, 2004).Perhaps one of the most natural ways to mea-sure the similarity of two strings is to count howmany substrings of length p the two strings havein common.
This gives rise to the p-spectrum ker-nel.
Formally, for two strings over an alphabet ?,s, t ?
?
?, the p-spectrum kernel is defined as:kp(s, t) =?v?
?pnumv(s) ?
numv(t),where numv(s) is the number of occurrences ofstring v as a substring in s.1The feature map de-1Note that the notion of substring requires contiguity.Shawe-Taylor and Cristianini (2004) discuss the ambiguitybetween the terms substring and subsequence across differ-ent domains: biology, computer science.fined by this kernel associates a vector of dimen-sion |?|pcontaining the histogram of frequenciesof all its substrings of length p (p-grams) with eachstring.A variant of this kernel can be obtained if theembedding feature map is modified to associate avector of dimension |?|pcontaining the presencebits (instead of frequencies) of all its substrings oflength p with each string.
Thus, the character p-grams presence bits kernel is obtained:k0/1p(s, t) =?v?
?pinv(s) ?
inv(t),where inv(s) is 1 if string v occurs as a substringin s, and 0 otherwise.In computer vision, the (histogram) intersec-tion kernel has successfully been used for objectclass recognition from images (Maji et al., 2008;Vedaldi and Zisserman, 2010).
In this paper, theintersection kernel is used for the first time as akernel for strings.
The intersection string kernel isdefined as follows:k?p(s, t) =?v?
?pmin{numv(s), numv(t)},where numv(s) is the number of occurrences ofstring v as a substring in s.For the p-spectrum kernel, the frequency of a p-gram has a very significant contribution to the ker-nel, since it considers the product of such frequen-cies.
On the other hand, the frequency of a p-gramis completely disregarded in the p-grams presencebits kernel.
The intersection kernel lies some-where in the middle between the p-grams presencebits kernel and p-spectrum kernel, in the sense thatthe frequency of a p-gram has a moderate contri-bution to the intersection kernel.
More precisely,the following inequality that describes the relationbetween the three kernels holds:k0/1p(s, t) ?
k?p(s, t) ?
kp(s, t).What is actually more interesting is that the inter-section kernel assigns a high score to a p-gram if ithas a high frequency in both strings, since it con-siders the minimum of the two frequencies.
Thep-spectrum kernel assigns a high score even whenthe p-gram has a high frequency in only one ofthe two strings.
Thus, the intersection kernel cap-tures something about the correlation between thep-gram frequencies in the two strings, which maylead to a more sensitive similarity between strings.1365Normalized versions of these kernels ensure afair comparison of strings of different lengths:?kp(s, t) =kp(s, t)?kp(s, s) ?
kp(t, t),?k0/1p(s, t) =k0/1p(s, t)?k0/1p(s, s) ?
k0/1p(t, t),?k?p(s, t) =k?p(s, t)?k?p(s, s) ?
k?p(t, t).Taking into account p-grams of different lengthand summing up the corresponding kernels, newkernels, termed blended spectrum kernels, can beobtained.The string kernel implicitly embeds the textsin a high dimensional feature space.
Then, akernel-based learning algorithm implicitly assignsa weight to each feature, thus selecting the fea-tures that are important for the discrimination task.For example, in the case of text categorizationthe learning algorithm enhances the features rep-resenting stems of content words (Lodhi et al.,2002), while in the case of authorship identifica-tion the same learning algorithm enhances the fea-tures representing function words (Popescu andDinu, 2007).3.2 Local Rank DistanceA recently introduced distance measure, termedLocal Rank Distance (Ionescu, 2013), comes fromthe idea of better adapting rank distance (Dinu,2003) to string data, in order to capture a bet-ter similarity between strings, such as DNA se-quences or text.
Local Rank Distance (LRD) hasalready shown promising results in computationalbiology (Ionescu, 2013) and native language iden-tification (Popescu and Ionescu, 2013).In order to describe LRD, the following nota-tions are defined.
Given a string x over an al-phabet ?, and a character a ?
?, the length ofx is denoted by |x|.
Strings are considered tobe indexed starting from position 1, that is x =x[1]x[2] ?
?
?x[|x|].
Moreover, x[i : j] denotes itssubstring x[i]x[i+ 1] ?
?
?x[j ?
1].Local Rank Distance is inspired by rank dis-tance (Dinu, 2003), the main differences beingthat it uses p-grams instead of single charac-ters, and that it matches each p-gram in the firststring with the nearest equal p-gram in the secondstring.
Given a fixed integer p ?
1, a thresh-old m ?
1, and two strings x and y over ?,the Local Rank Distance between x and y, de-noted by ?LRD(x, y), is defined through the fol-lowing algorithmic process.
For each position i inx (1 ?
i ?
|x|?p+1), the algorithm searches forthat position j in y (1 ?
j ?
|y|?
p+ 1) such thatx[i : i+p] = y[j : j+p] and |i?
j| is minimized.If j exists and |i ?
j| < m, then the offset |i ?
j|is added to the Local Rank Distance.
Otherwise,the maximal offset m is added to the Local RankDistance.
An important remark is that LRD doesnot impose any mathematically developed globalconstraints, such as matching the i-th occurrenceof a p-gram in x with the i-th occurrence of thatsame p-gram in y.
Instead, it is focused on the lo-cal phenomenon, and tries to pair equal p-grams ata minimum offset.
To ensure that LRD is a (sym-metric) distance function, the algorithm also hasto sum up the offsets obtained from the above pro-cess by exchanging x and y. LRD can be formallydefined as follows.Definition 1 Let x, y ?
?
?be two strings, and letp ?
1 and m ?
1 be two fixed integer values.
TheLocal Rank Distance between x and y is definedas:?LRD(x, y) = ?left(x, y) + ?right(x, y),where ?left(x, y) and ?right(x, y) are defined asfollows:?left(x, y) =|x|?p+1?i=1min{|i?
j| such that1 ?
j ?
|y| ?
p+ 1 andx[i : i+ p] = y[j : j + p]} ?
{m},?right(x, y) =|y|?p+1?j=1min{|j ?
i| such that1 ?
i ?
|x| ?
p+ 1 andy[j : j + p] = x[i : i+ p]} ?
{m}.Interestingly, the search for matching p-grams islimited within a window of fixed size.
The size ofthis window is determined by the maximum offsetparameter m. This parameter must be set a prioriand should be proportional to the size of the alpha-bet, the p-grams, and to the lengths of the strings.The following example offers a better under-standing of how LRD actually works.
LRD iscomputed between two strings using 2-grams.Example 1 Given two strings x = abcaa andy = cabca, a fixed maximal offset m = 3, and1366a fixed size of p-grams p = 2, ?leftand ?rightare computed as follows:?left(x, y) = |1?
2|+ |2?
3|+ |3?
4|+ 3 = 6,?right(x, y) = |1?
3|+ |2?
1|+ |3?
2|+ |4?
3| = 5.By summing up the two partial sums, Local RankDistance is obtained?LRD(x, y) = ?left(x, y) + ?right(x, y) = 11.The maximum LRD value between two stringscan be computed as the product between the max-imum offset m and the number of pairs of com-pared p-grams.
Thus, LRD can be normalizedto a value in the [0, 1] interval.
By normalizing,LRD becomes a dissimilarity measure.
LRD canbe also used as a kernel, since kernel methods arebased on similarity.
The classical way to transforma distance or dissimilarity measure into a simi-larity measure is by using the Gaussian-like ker-nel (Shawe-Taylor and Cristianini, 2004):?kLRDp(s, t) = e?
?LRD(s, t)2?2,where s and t are two strings and p is the p-gramslength.
The parameter ?
is usually chosen so thatvalues of?k(s, t) are well scaled.
In the aboveequation, ?LRDis already normalized to a valuein the [0, 1] interval to ensure a fair comparison ofstrings of different length.4 Learning MethodsKernel-based learning algorithms work by embed-ding the data into a Hilbert feature space, andsearching for linear relations in that space.
Theembedding is performed implicitly, that is by spec-ifying the inner product between each pair ofpoints rather than by giving their coordinates ex-plicitly.
More precisely, a kernel matrix that con-tains the pairwise similarities between every pairof training samples is used in the learning stageto assign a vector of weights to the training sam-ples.
Let ?
denote this weight vector.
In the teststage, the pairwise similarities between a test sam-ple x and all the training samples are computed.Then, the following binary classification functionassigns a positive or a negative label to the testsample:g(x) =n?i=1?i?
k(x, xi),where x is the test sample, n is the number oftraining samples, X = {x1, x2, ..., xn} is the setof training samples, k is a kernel function, and ?iis the weight assigned to the training sample xi.In the primal form, the same binary classificationfunction can be expressed as:g(x) = ?w, x?,where ?
?, ??
denotes the scalar product, x ?
Rmisthe test sample represented as a vector of features,and w ?
Rmis a vector of feature weights that canbe computed as follows:w =n?i=1?i?
xi,given that the kernel function k can be expressedas a scalar product between samples.The advantage of using the dual representationinduced by the kernel function becomes clear ifthe dimension of the feature space m is takeninto consideration.
Since string kernels are basedon character n-grams, the feature space is indeedvery high.
For instance, using 5-grams based onlyon the 26 letters of the English alphabet will re-sult in a feature space of 265= 11, 881, 376 fea-tures.
However, in the experiments presented inthis work the feature space includes 5-grams alongwith 6-grams, 7-grams and 8-grams.
As long asthe number of samples n is not greater than thenumber of features m, it is more efficient to usethe dual representation given by the kernel matrix.This fact is also known as the kernel trick (Shawe-Taylor and Cristianini, 2004).Various kernel methods differ in the way theylearn to separate the samples.
In the case of binaryclassification problems, kernel-based learning al-gorithms look for a discriminant function, a func-tion that assigns +1 to examples belonging to oneclass and ?1 to examples belonging to the otherclass.
For the NLI experiments, two binary kernelclassifiers are used, namely the SVM (Cortes andVapnik, 1995), and the KRR.
Support Vector Ma-chines try to find the vector of weights that definesthe hyperplane that maximally separates the im-ages in the Hilbert space of the training examples1367belonging to the two classes.
Kernel Ridge Re-gression selects the vector of weights that simulta-neously has small empirical error and small normin the Reproducing Kernel Hilbert Space gener-ated by the kernel function.
More details aboutSVM and KRR can be found in (Shawe-Taylor andCristianini, 2004).
The important fact is that theabove optimization problems are solved in such away that the coordinates of the embedded pointsare not needed, only their pairwise inner productswhich in turn are given by the kernel function.SVM and KRR produce binary classifiers, butnative language identification is usually a multi-class classification problem.
There are many ap-proaches for combining binary classifiers to solvemulti-class problems.
Typically, the multi-classproblem is broken down into multiple binary clas-sification problems using common decomposingschemes such as: one-versus-all and one-versus-one.
There are also kernel methods that take themulti-class nature of the problem directly into ac-count, e.g.
Kernel Discriminant Analysis.
TheKDA classifier is able to improve accuracy byavoiding the masking problem (Hastie and Tib-shirani, 2003).
In the case of multi-class nativelanguage identification, the masking problem mayappear when non-native English speakers have ac-quired, as the second language, a different lan-guage to English.
For example, an essay written inEnglish produced by a French native speaker thatis also proficient in German, could be identified aseither French or German.5 Experiments5.1 Data Sets DescriptionIn this paper, experiments are carried out on threedatasets: a modified version of the ICLEv2 cor-pus (Granger et al., 2009), the ETS Corpus ofNon-Native Written English, or TOEFL11 (Blan-chard et al., 2013), and the TOEFL11-Big corpusas used by Tetreault et al.
(2012).
A summary ofthe corpora is given in Table 1.Corpus Languages DocumentsICLE 7 770TOEFL11 11 12, 100TOEFL11-Big 11 87, 502Table 1: Summary of corpora used in the experi-ments.The ICLEv2 is a corpus of essays written byhighly-proficient non-native college-level studentsof English.
For many years this was the standardcorpus used in the task of native language identi-fication.
However, the corpus was originally col-lected for the purpose of corpus linguistic inves-tigations, and because of this contains some id-iosyncrasies that make it problematic for the taskof NLI (Brooke and Hirst, 2012).
Therefore, amodified version of the corpus that has been nor-malized as much as possible for topic and charac-ter encoding (Tetreault et al., 2012) is used.
Thisversion of the corpus contains 110 essays each for7 native languages: Bulgarian, Chinese, Czech,French, Japanese, Russian and Spanish.The ETS Corpus of Non-Native Written English(TOEFL11) was first introduced by Tetreault et al.
(2012) and extended for the 2013 Native LanguageIdentification Shared Task (Tetreault et al., 2013).It was designed to overcome many of the short-comings identified with using the ICLEv2 corpusfor this task.
The TOEFL11 corpus contains abalanced distribution of essays per prompt (topic)per native language.
It also contains informationabout the language proficiency of each writer.
Thecorpus contains essays written by speakers of thefollowing 11 languages: Arabic, Chinese, French,German, Hindi, Italian, Japanese, Korean, Span-ish, Telugu and Turkish.
For the shared task, the12, 100 essays were split into 9, 900 for training,1, 100 for development and 1, 100 for testing.Tetreault et al.
(2012) present a corpus,TOEFL11-Big, to investigate the performance oftheir NLI system on a very large data set.
Thisdata set contains the same languages as TOEFL11,but with no overlap in content.
It contains a totalof over 87 thousand essays written to a total of76 different prompts.
The distribution of L1 perprompt is not as even as for TOEFL11, though alltopics are represented for all L1s.5.2 Parameter Tuning and ImplementationChoicesIn the string kernels approach proposed in thiswork, documents or essays from this corpus aretreated as strings.
Therefore, the notions of stringor document is used interchangeably throughoutthis work.
Because the approach works at the char-acter level, there is no need to split the texts intowords, or to do any NLP-specific preprocessing.The only editing done to the texts was the replac-ing of sequences of consecutive space characters1368(space, tab, new line, and so on) with a singlespace character.
This normalization was needed inorder to prevent the artificial increase or decreaseof the similarity between texts, as a result of differ-ent spacing.
All uppercase letters were convertedto the corresponding lowercase ones.A series of preliminary experiments were con-ducted in order to select the best-performing learn-ing method.
In these experiments the string ker-nel was fixed to the p-spectrum normalized ker-nel of length 5 (?k5), because the goal was to se-lect the best learning method, and not to find thebest kernel.
The following learning methods wereevaluated: one-versus-one SVM, one-versus-allSVM, one-versus-one KRR, one-versus-all KRR,and KDA.
A 10-fold cross-validation procedurewas carried out on the TOEFL11 training set toevaluate the classifiers.
The preliminary results in-dicate that the one-versus-all KRR and the KDAclassifiers produce the best results.
Therefore,they are selected for the remaining experiments.Another set of preliminary experiments wereperformed to determine the range of n-grams thatgives the most accurate results on a 10-fold cross-validation procedure carried out on the TOEFL11training set.
All the n-grams in the range 2-10were evaluated.
Furthermore, experiments withdifferent blended kernels were conducted to seewhether combining n-grams of different lengthscould improve the accuracy.
The best results wereobtained when all the n-grams with the length inthe range 5-8 were used.
Other authors (Bykhand Meurers, 2012; Popescu and Ionescu, 2013)also report better results by using n-grams withthe length in a range, rather than using n-gramsof fixed length.
Consequently, the results reportedin this work are based on blended string kernelsbased on 5-8 n-grams.Some preliminary experiments were also per-formed to establish the type of kernel to be used,namely the blended p-spectrum kernel (?k5?8), theblended p-grams presence bits kernel (?k0/15?8), theblended p-grams intersection kernel (?k?5?8), or thekernel based on LRD (?kLRD5?8.).
These differentkernel representations are obtained from the samedata.
The idea of combining all these kernels isnatural when one wants to improve the perfor-mance of a classifier.
When multiple kernels arecombined, the features are actually embedded ina higher-dimensional space.
As a consequence,the search space of linear patterns grows, whichhelps the classifier to select a better discriminantfunction.
The most natural way of combining twokernels is to sum them up.
Summing up kernelsor kernel matrices is equivalent to feature vectorconcatenation.
Another option is to combine ker-nels by kernel alignment (Cristianini et al., 2001).Instead of simply summing kernels, kernel align-ment assigns weights for each of the two kernelsbased on how well they are aligned with the idealkernel Y Y?obtained from training labels.
The ker-nels were evaluated alone and in various combina-tions.
The best kernels are the blended p-gramspresence bits kernel and the blended p-grams in-tersection kernel.
The best kernel combinationsinclude the blended p-grams presence bits kernel,the blended p-grams intersection kernel and thekernel based on LRD.
Since the kernel based onLRD is slightly slower than the other string ker-nels, the kernel combinations that include it wereonly evaluated on the TOEFL11 corpus and on theICLE corpus.5.3 Experiment on TOEFL11 CorpusThis section describes the results on the TOEFL11corpus.
Thus, results for the 2013 Closed NLIShared Task are also included.
In the closed sharedtask the goal is to predict the native language oftesting examples, restricted to learning only fromthe training and the development data.
The ad-ditional information from prompts or the Englishlanguage proficiency level were not used in theproposed approach.The regularization parameters were tuned on thedevelopment set.
In this case, the systems weretrained on the entire training set.
A 10-fold cross-validation (CV) procedure was done on the train-ing and the development sets.
The folds were pro-vided along with the TOEFL11 corpus.
Finally,the results of the proposed systems are also re-ported on the NLI Shared Task test set.
For test-ing, the systems were trained on both the trainingset and the development set.
The results are sum-marized in Table 2.The results presented in Table 2 show that stringkernels can reach state of the art accuracy levelsfor this task.
Overall, it seems that KDA is ableto obtain better results than KRR.
The intersectionkernel alone is able to obtain slightly better resultsthan the presence bits kernel.
The kernel based onLRD gives significantly lower accuracy rates, butit is able to improve the performance when it is1369Method Development 10-fold CV TestEnsemble model (Tetreault et al., 2012) - 80.9% -KRR and string kernels (Popescu and Ionescu, 2013) - 82.6% 82.7%SVM and word features (Jarvis et al., 2013) - 84.5% 83.6%KRR and?k0/15?885.4% 82.5% 82.0%KRR and?k?5?884.9% 82.2% 82.6%KRR and?kLRD5?878.7% 77.1% 77.5%KRR and?k0/15?8+?kLRD5?885.7% 82.6% 82.7%KRR and?k?5?8+?kLRD5?884.9% 82.2% 82.0%KRR and?k0/15?8+?k?5?885.5% 82.6% 82.5%KRR and a1?k0/15?8+ a2?k?5?885.5% 82.6% 82.5%KDA and?k0/15?886.2% 83.6% 83.6%KDA and?k?5?885.2% 83.5% 84.6%KDA and?kLRD5?879.7% 78.5% 79.2%KDA and?k0/15?8+?kLRD5?887.1% 84.0% 84.7%KDA and?k?5?8+?kLRD5?885.8% 83.4% 83.9%KDA and?k0/15?8+?k?5?886.4% 84.1% 85.0%KDA and a1?k0/15?8+ a2?k?5?886.5% 84.1% 85.3%KDA and?k0/15?8+?k?5?8+?kLRD5?887.0% 84.1% 84.8%Table 2: Accuracy rates on TOEFL11 corpus of various classification systems based on string kernelscompared with other state of the art approaches.
The best accuracy rates on each set of experiments arehighlighted in bold.
The weights a1and a2from the weighted sums of kernels are computed by kernelalignment.combined with the blended p-grams presence bitskernel.
In fact, most of the kernel combinationsgive better results than each of their components.The best kernel combination is that of the pres-ence bits kernel and the intersection kernel.
Re-sults are quite similar when they are combined ei-ther by summing them up or by kernel alignment.The best performance on the test set (85.3%) is ob-tained by the system that combines these two ker-nels via kernel alignment and learns using KDA.This system is 1.7% better than the state of the artsystem of Jarvis et al.
(2013) based on SVM andword features, this being the top scoring system inthe NLI 2013 Shared Task.
It is also 2.6% betterthan the state of the art system based on string ker-nels of Popescu and Ionescu (2013).
On the crossvalidation procedure, there are three systems thatreach the accuracy rate of 84.1%.
All of them arebased on KDA and various kernel combinations.The greatest accuracy rate of 84.1% reported forthe cross validation procedure is 3.2% above thestate of the art system of Tetreault et al.
(2012) and0.4% below the top scoring system of Jarvis et al.(2013).
The empirical results obtained in this ex-periment demonstrate that the approach proposedin this paper can reach state of the art accuracylevels.
It is worth mentioning that a significancetest performed by the organizers of the NLI 2013Shared Task showed that the top systems that par-ticipated in the competition are not essentially dif-ferent.
Further experiments on the ICLE corpusand on the TOEFL11-Big corpus are conducted todetermine whether the approach proposed in thispaper is significantly better than other state of theart approaches.5.4 Experiment on ICLE CorpusThe results on the ICLE corpus using a 5-foldcross validation procedure are summarized in Ta-ble 3.
To adequately compare the results with astate of the art system, the same 5-fold cross val-idation procedure used by Tetreault et al.
(2012)was also used in this experiment.
Table 3 showsthat the results obtained by the presence bits kerneland by the intersection kernel are systematicallybetter than the state of the art system of Tetreaultet al.
(2012).
While both KRR and KDA produceaccuracy rates that are better than the state of theart accuracy rate, it seems that KRR is slightly bet-ter in this experiment.
Again, the idea of com-bining kernels seems to produce more robust sys-tems.
The best systems are based on combin-ing the presence bits kernel either with the kernelbased on LRD or the intersection kernel.
Over-all, the reported accuracy rates are higher than thestate of the art accuracy rate.
The best perfor-mance (91.3%) is achieved by the KRR classifierbased on combining the presence bits kernel with1370Method 5-fold CVEnsemble model (Tetreault et al., 2012) 90.1%KRR and?k0/15?891.2%KRR and?k?5?890.5%KRR and?kLRD5?881.8%KRR and?k0/15?8+?kLRD5?891.3%KRR and?k?5?8+?kLRD5?890.1%KRR and?k0/15?8+?k?5?890.9%KRR and?k0/15?8+?k?5?8+?kLRD5?890.6%KDA and?k0/15?890.5%KDA and?k?5?890.5%KDA and?kLRD5?882.3%KDA and?k0/15?8+?kLRD5?890.8%KDA and?k?5?8+?kLRD5?890.4%KDA and?k0/15?8+?k?5?891.0%KDA and?k0/15?8+?k?5?8+?kLRD5?890.8%Table 3: Accuracy rates on ICLE corpus of vari-ous classification systems based on string kernelscompared with a state of the art approach.
The ac-curacy rates are reported for the same 5-fold CVprocedure as in (Tetreault et al., 2012).
The bestaccuracy rate is highlighted in bold.the kernel based on LRD.
This represents an 1.2%improvement over the state of the art accuracy rateof Tetreault et al.
(2012).
Two more systems areable to obtain accuracy rates greater than 91.0%.These are the KRR classifier based on the presencebits kernel (91.2%) and the KDA classifier basedon the sum of the presence bits kernel and the in-tersection kernel (91.0%).
The overall results onthe ICLE corpus show that the string kernels ap-proach can reach state of the art accuracy levels.It is worth mentioning the purpose of this experi-ment was to use the same approach determined towork well in the TOEFL11 corpus.
To serve thispurpose, the range of n-grams was not tuned onthis data set.
Furthermore, other classifiers werenot tested in this experiment.
Nevertheless, betterresults can probably be obtained by adding theseaspects into the equation.5.5 Cross-corpus ExperimentIn this experiment, various systems based on KRRor KDA are trained on the TOEFL11 corpus andtested on the TOEFL11-Big corpus.
The kernelbased on LRD was not included in this experimentsince it is more computationally expensive.
There-fore, only the presence bits kernel and the intersec-tion kernel were evaluated on the TOEFL11-Bigcorpus.
The results are summarized in Table 4.The same regularization parameters determined toMethod TestEnsemble model (Tetreault et al., 2012) 35.4%KRR and?k0/15?866.7%KRR and?k?5?867.2%KRR and?k0/15?8+?k?5?867.7%KRR and a1?k0/15?8+ a2?k?5?867.7%KDA and?k0/15?865.6%KDA and?k?5?865.7%KDA and?k0/15?8+?k?5?866.2%KDA and a1?k0/15?8+ a2?k?5?866.2%Table 4: Accuracy rates on TOEFL11-Big corpusof various classification systems based on stringkernels compared with a state of the art approach.The systems are trained on the TOEFL11 corpusand tested on the TOEFL11-Big corpus.
The bestaccuracy rate is highlighted in bold.
The weightsa1and a2from the weighted sums of kernels arecomputed by kernel alignment.work well on the TOEFL11 development set wereused.The most interesting fact is that all the proposedsystems are at least 30% better than the state of theart system.
Considering that the TOEFL11-Bigcorpus contains 87 thousand samples, the 30% im-provement is significant without any doubt.
Div-ing into details, it can be observed that the resultsobtained by KRR are higher than those obtainedby KDA.
However, both methods perform verywell compared to the state of the art.
Again, kernelcombinations are better than each of their individ-ual kernels alone.It is important to mention that the significantperformance increase is not due to the learningmethod (KRR or KDA), but rather due to the stringkernels that work at the character level.
It is notonly the case that string kernels are language in-dependent, but for the same reasons they can alsobe topic independent.
Since the topics (prompts)from TOEFL11 are different from the topics fromTOEFL11-Big, it becomes clear that a methodthat uses words as features is strongly affected,since the distribution of words per topic can becompletely different.
But mistakes that reveal thenative language can be captured by character n-grams that can appear more often even in differ-ent topics.
The results indicate that this is alsothe case of the approach based on string kernels,which seems to be more robust to such topic vari-ations of the data set.
The best system has an ac-curacy rate that is 32.3% better than the state of1371the art system of Tetreault et al.
(2012).
Overall,the empirical results indicate that the string ker-nels approach can achieve significantly better re-sults than other state of the art approaches.6 ConclusionsA language-independent approach to native lan-guage identification was presented in this paper.The system works at the character level, mak-ing the approach completely language indepen-dent and linguistic theory neutral.
The results ob-tained in all the three experiments were very good.The best system presented in this work is based oncombining the intersection and the presence stringkernels by kernel alignment and on deciding theclass label either with KDA or KRR.
The best sys-tem is 1.7% above the top scoring system of the2013 NLI Shared Task.
Furthermore, it has an im-pressive generalization capacity, achieving resultsthat are 30% higher than the state of the art methodin the cross-corpus experiment.Despite the fact that the approach based onstring kernels performed so well, it remains to befurther investigated why this is the case and whysuch a simple approach can compete with far morecomplex approaches that take words, lemmas,syntactic information, or even semantics into ac-count.
It seems that there are generalizations to thekinds of mistakes that certain non-native Englishspeakers make that can be captured by n-gramsof different lengths.
Interestingly, using a rangeof n-grams generates a large number of featuresincluding (but not limited to) stop words, stemsof content words, word suffixes, entire words, andeven n-grams of short words.
Rather than doingfeature selection before the training step, whichis the usual NLP approach, the kernel classifierselects the most relevant features during training.With enough training samples, the kernel classi-fier does a better job of selecting the right featuresfrom a very high feature space.
This may be onereason for why the string kernel approach worksso well.
To gain additional insights into why thistechnique is working well, the features selectedby the classifier as being more discriminating canbe analyzed in future work.
This analysis wouldalso offer some information about localized lan-guage transfer effects, since the features used bythe proposed model are n-grams of lengths 5 to8.
As mentioned before, the features captured bythe model typically include stems, function words,word prefixes and suffixes, which have the poten-tial to generalize over purely word-based features.These features would offer insights into two kindsof language transfer effects, namely word choice(lexical transfer) and morphological differences.AcknowledgmentsThe authors would like to thank Beata BeigmanKlebanov, Nitin Madnani and Xinhao Wang fromETS for their helpful comments and suggestions.The author also thank the anonymous reviewersfor their valuable insights which lead to improve-ments in the presentation of this work.ReferencesDaniel Blanchard, Joel Tetreault, Derrick Higgins,Aoife Cahill, and Martin Chodorow.
2013.TOEFL11: A Corpus of Non-Native English.
Tech-nical report, Educational Testing Service ResearchReport No.
RR?13?24.Julian Brooke and Graeme Hirst.
2012.
Robust, Lex-icalized Native Language Identification.
Proceed-ings of COLING 2012, pages 391?408, December.Serhiy Bykh and Detmar Meurers.
2012.
Native Lan-guage Identification using Recurring n-grams ?
In-vestigating Abstraction and Domain Dependence.Proceedings of COLING 2012, pages 425?440, De-cember.Corinna Cortes and Vladimir Vapnik.
1995.
Support-Vector Networks.
Machine Learning, 20(3):273?297.Nello Cristianini, John Shawe-Taylor, Andr?e Elisseeff,and Jaz S. Kandola.
2001.
On kernel-target align-ment.
Proceedings of NIPS, pages 367?373, De-cember.Liviu P. Dinu.
2003.
On the classification and aggre-gation of hierarchies with different constitutive ele-ments.
Fundamenta Informaticae, 55(1):39?50.Dominique Estival, Tanja Gaustad, Son-Bao Pham,Will Radford, and Ben Hutchinson.
2007.
Authorprofiling for English emails.
Proceedings of PA-CLING, pages 263?272.Sylviane Granger, Estelle Dagneaux, and Fanny Me-unier.
2009.
The International Corpus ofLearner English: Handbook and CD-ROM, version2.
Presses Universitaires de Louvain, Louvain-la-Neuve, Belgium.Cristian Grozea, Christian Gehl, and Marius Popescu.2009.
ENCOPLOT: Pairwise Sequence Matchingin Linear Time Applied to Plagiarism Detection.
In3rd PAN Workshop.
Uncovering Plagiarism, Author-ship, and Social Software Misuse, page 10.1372Trevor Hastie and Robert Tibshirani.
2003.
The El-ements of Statistical Learning.
Springer, correctededition, July.Radu Tudor Ionescu.
2013.
Local Rank Distance.Proceedings of SYNASC, pages 221?228.Scott Jarvis, Yves Bestgen, and Steve Pepper.
2013.Maximizing classification accuracy in native lan-guage identification.
Proceedings of the EighthWorkshop on Innovative Use of NLP for BuildingEducational Applications, pages 111?118, June.Moshe Koppel, Jonathan Schler, and Kfir Zigdon.2005.
Automatically Determining an AnonymousAuthor?s Native Language.
Proceedings of ISI,pages 209?217.Huma Lodhi, Craig Saunders, John Shawe-Taylor,Nello Cristianini, and Christopher J. C. H. Watkins.2002.
Text classification using string kernels.
Jour-nal of Machine Learning Research, 2:419?444.Subhransu Maji, Alexander C. Berg, and Jitendra Ma-lik.
2008.
Classification using intersection kernelsupport vector machines is efficient.
Proceedings ofCVPR.Shervin Malmasi and Mark Dras.
2014.
Chinese Na-tive Language Identification.
Proceedings of EACL,2:95?99, April.Marius Popescu and Liviu P. Dinu.
2007.
Kernel meth-ods and string kernels for authorship identification:The federalist papers case.
Proceedings of RANLP,September.Marius Popescu and Cristian Grozea.
2012.
Ker-nel methods and string kernels for authorship analy-sis.
CLEF (Online Working Notes/Labs/Workshop),September.Marius Popescu and Radu Tudor Ionescu.
2013.
TheStory of the Characters, the DNA and the NativeLanguage.
Proceedings of the Eighth Workshop onInnovative Use of NLP for Building Educational Ap-plications, pages 270?278, June.Marius Popescu.
2011.
Studying translationese at thecharacter level.
Proceedings of RANLP, pages 634?639, September.Conrad Sanderson and Simon Guenter.
2006.
Shorttext authorship attribution via sequence kernels,markov chains and author unmasking: An investiga-tion.
Proceedings of EMNLP, pages 482?491, July.John Shawe-Taylor and Nello Cristianini.
2004.
Ker-nel Methods for Pattern Analysis.
Cambridge Uni-versity Press.Joel Tetreault, Daniel Blanchard, Aoife Cahill, andMartin Chodorow.
2012.
Native Tongues, Lost andFound: Resources and Empirical Evaluations in Na-tive Language Identification.
Proceedings of COL-ING 2012, pages 2585?2602, December.Joel Tetreault, Daniel Blanchard, and Aoife Cahill.2013.
A report on the first native language identifi-cation shared task.
Proceedings of the Eighth Work-shop on Innovative Use of NLP for Building Educa-tional Applications, pages 48?57, June.Andrea Vedaldi and Andrew Zisserman.
2010.
Effi-cient additive kernels via explicit feature maps.
Pro-ceedings of CVPR, pages 3539?3546.1373
