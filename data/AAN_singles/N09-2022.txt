Proceedings of NAACL HLT 2009: Short Papers, pages 85?88,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsShallow Semantic Parsing for Spoken Language UnderstandingBonaventura Coppola and Alessandro Moschitti and Giuseppe RiccardiDepartment of Information Engineering and Computer Science - University of Trento, Italy{coppola,moschitti,riccardi}@disi.unitn.itAbstractMost Spoken Dialog Systems are based onspeech grammars and frame/slot semantics.The semantic descriptions of input utterancesare usually defined ad-hoc with no ability togeneralize beyond the target application do-main or to learn from annotated corpora.
Theapproach we propose in this paper exploitsmachine learning of frame semantics, bor-rowing its theoretical model from computa-tional linguistics.
While traditional automaticSemantic Role Labeling approaches on writ-ten texts may not perform as well on spo-ken dialogs, we show successful experimentson such porting.
Hence, we design and eval-uate automatic FrameNet-based parsers bothfor English written texts and for Italian dia-log utterances.
The results show that disflu-encies of dialog data do not severely hurt per-formance.
Also, a small set of FrameNet-likemanual annotations is enough for realizing ac-curate Semantic Role Labeling on the targetdomains of typical Dialog Systems.1 IntroductionCommercial services based on spoken dialog sys-tems have consistently increased both in number andin application scenarios (Gorin et al, 1997).
De-spite its success, current Spoken Language Under-standing (SLU) technology is mainly based on sim-ple conceptual annotation, where just very simplesemantic composition is attempted.
In contrast, theavailability of richer semantic models as FrameNet(Baker et al, 1998) is very appealing for the de-sign of better dialog managers.
The first step to en-able the exploitation of frame semantics is to showthat accurate automatic semantic labelers can be de-signed for processing conversational speech.In this paper, we face the problem of perform-ing shallow semantic analysis of speech transcrip-tions from real-world dialogs.
In particular, we ap-ply Support Vector Machines (SVMs) and KernelMethods to the design of a semantic role labeler(SRL) based on FrameNet.
Exploiting Tree Kernels(Collins and Duffy, 2002; Moschitti et al, 2008), wecan quickly port our system to different languagesand domains.
In the experiments, we compareresults achieved on the English FrameNet againstthose achieved on a smaller Italian FrameNet-likecorpus of spoken dialog transcriptions.
They showthat the system is robust enough to disfluencies andnoise, and that it can be easily ported to new do-mains and languages.In the remainder of the paper, Section 2 presentsour basic Semantic Role Labeling approach, Sec-tion 3 describes the experiments on the EnglishFrameNet and on our Italian dialog corpus, and Sec-tion 4 draws the conclusions.2 FrameNet-based Semantic Role LabelingSemantic frames represent prototypical events orsituations which individually define their own setof actors, or frame participants.
For example,the COMMERCE SCENARIO frame includes partic-ipants as SELLER, BUYER, GOODS, and MONEY.The task of FrameNet-based shallow semantic pars-ing can be implemented as a combination of multi-ple specialized semantic labelers as those in (Car-reras and Ma`rquez, 2005), one for each frame.Therefore, the general semantic parsing work-flowincludes 4 main steps: (i) Target Word Detec-tion, where the semantically relevant words bringingpredicative information (the frame targets) are de-tected, e.g.
the verb to purchase for the above exam-ple; (ii) Frame Disambiguation, where the correctframe for every target word (which may be ambigu-ous) is determined, e.g.
COMMERCE SCENARIO;(iii) Boundary Detection (BD), where the sequencesof words realizing the frame elements (or predicate85arguments) are detected; and (iv) Role Classification(RC) (or argument classification), which assigns se-mantic labels to the frame elements detected in theprevious step, e.g.
GOODS.
Therefore, we imple-ment the full task of FrameNet-based parsing by acombination of multiple specialized SRL-like label-ers, one for each frame (Coppola et al, 2008).
Forthe design of each single labeler, we use the state-of-the-art strategy developed in (Pradhan et al, 2005;Moschitti et al, 2008).2.1 Standard versus Structural FeaturesIn machine learning tasks, the manual engineeringof effective features is a complex and time con-suming process.
For this reason, our SVM-basedSRL approach exploits the combination of two dif-ferent models.
We first used Polynomial Kernelsover handcrafted, linguistically-motivated, ?stan-dard?
SRL features (Gildea and Jurafsky, 2002;Pradhan et al, 2005; Xue and Palmer, 2004).Nonetheless, since we aim at modeling an SRL sys-tem for a new language (Italian) and a new domain(dialog transcriptions), the above features may re-sult ineffective.
Thus, to achieve independence onthe application domain, we exploited Tree Kernels(Collins and Duffy, 2002) over automatic structuralfeatures proposed in (Moschitti et al, 2005; Mos-chitti et al, 2008).
These are complementary to stan-dard features and are obtained by applying Tree Ker-nels (Collins and Duffy, 2002; Moschitti et al, 2008)to basic tree structures expressing the syntactic rela-tion between arguments and predicates.3 ExperimentsOur purpose is to show that an accurate automaticFrameNet parser can be designed with reasonableeffort for Italian conversational speech.
For this pur-pose, we designed and evaluated both a semanticparser for the English FrameNet (Section 3.1) andone for a corpus of Italian spoken dialogs (Section3.2).
The accuracy of the latter and its comparisonagainst the former can provide evidence to sustainout thesis or not.3.1 Evaluation on the English FrameNetIn this experiment we trained and tested boundarydetectors (BD) and role classifiers (RC) as describedin Section 2.
More in detail, (a) we trained 5 BDsaccording to the syntactic categories of the possi-ble target predicates, namely nouns, verbs, adjec-tives, adverbs and prepositions; (b) we trained 782one-versus-all multi-role classifiers RC, one for eachavailable frame and predicate syntactic category, fora total of 5,345 binary classifiers; and (c) we ap-plied the above models for recognizing predicate ar-guments and their associated semantic labels in sen-tences, where the frame label and the target predi-cate were considered as given.3.1.1 Data SetWe exploited the FrameNet 1.3 data base.
Afterpreprocessing and parsing the sentences with Char-niak?s parser, we obtained 135,293 semantically-annotated and syntactically-parsed sentences.The above dataset was partitioned into three sub-sets: 2% of data (2,782 sentences) for training theBDs, 90% (121,798 sentences) for training RC, and1% (1,345 sentences) as test set.
The remaining datawere discarded.
Accordingly, the number of pos-itive and negative training examples for BD were:2,764 positive and 37,497 negative examples for ver-bal, 1,189 and 35,576 for nominal, 615 and 14,544for adjectival, 0 and 40 for adverbial, and 7 and 177for prepositional predicates (for a total of 4,575 and87,834).
For RC, the total numbers were 207,662and 1,960,423, which divided by the number of roletypes show the average number of 39 positive versus367 negative examples per role label.3.1.2 ResultsWe tested several kernels over standard fea-tures (Gildea and Jurafsky, 2002; Pradhan et al,2005) and structured features (Moschitti et al,2008): the Polynomial Kernel (PK, with a degree of3), the Tree Kernel (TK) and its combination withthe bag of word kernel on the tree leaves (TKL).Also, the combinations PK+TK and PK+TKL weretested.The 4 rows of Table 1 report the performance ofdifferent classification tasks.
They show in turn: (1)the ?pure?
performance of the BD classifiers, i.e.considering correct the classification decisions alsowhen a correctly classified tree node does not ex-actly correspond to its argument?s word boundaries.Such mismatch frequently happens when the parsetree (which is automatically generated) contains in-86PK TK PK+TK TKL PK+TKLEval sett.
P R F1 P R F1 P R F1 P R F1 P R F1BD .887 .675 .767 .949 .652 .773 .915 .698 .792 .938 .659 .774 .908 .701 .791BD pj .850 .647 .735 .919 .631 .748 .875 .668 .758 .906 .636 .747 .868 .670 .757BD+RC .654 .498 .565 .697 .479 .568 .680 .519 .588 .689 .484 .569 .675 .521 .588BD+RC pj .625 .476 .540 .672 .462 .548 .648 .495 .561 .663 .466 .547 .644 .497 .561Table 1: Results on FrameNet dataset: Polynomial Kernel, two different Tree Kernels, and their combinations (seeSection 3.1.2) with 2% training for BD and 90% for RC.correct node attachments; (2) the real performanceof the BD classification when actually ?projected?(?pj?)
on the tree leaves, i.e.
when matching notonly the constituent node as in 1, but also exactlymatching the selected words (leaves) with those inthe FrameNet gold standard.
This also implies theexact automatic syntactic analysis for the subtree;(3) the same as in (1), with the argument role classi-fication (RC) also performed (frame element labelsmust also match); (4) the same as in (2), with RCalso performed.
For each classification task, the Pre-cision, Recall and F1 measure achieved by meansof different kernel combinations are shown in thecolumns of the table.
Only for the best configurationin Table 1 (PK+TK, results in bold) the amount oftraining data for the BD model was increased from2% to 90%, resulting in a popular splitting for thistask(Erk and Pado, 2006).
Results are shown in Ta-ble 2: the PK+TK kernel achieves 1.0 Precision,0.732 Recall, and 0.847 F1.
These figures can becompared to 0.855 Precision, 0.669 Recall and 0.751F1 of the system described in (Erk and Pado, 2006)and trained over the same amount of data.
In con-clusion, our best learning scheme is currently capa-ble of tagging FrameNet data with exact boundariesand role labels at 63% F1.
Our next steps will be (1)further improving the RC models using FrameNet-specific information (such as Frame and role inheri-tance), and (2) introducing an effective Frame clas-sifier to automatically choose Frame labels.Enhanced PK+TKEval Setting P R F1BD (nodes) 1.0 .732 .847BD (words) .963 .702 .813BD+RC (nodes) .784 .571 .661BD+RC (words) .747 .545 .630Table 2: Results on the FrameNet dataset.
Best configu-ration from Table 1, raised to 90% of training data for BDand RC.Eval Setting P R F1 P R F1PKBD - - - .900 .869 .884BD+RC - - - .769 .742 .756TK PK+TKBD .887 .856 .871 .905 .873 .889BD+RC .765 .738 .751 .774 .747 .760Table 3: Experiment Results on the Italian dialog corpusfor different learning schemes and kernel combinations.3.2 Evaluation on Italian Spoken DialogsIn this section, we present the results of BD and RCof our FrameNet parser on the smaller Italian spokendialog corpus.
We assume here as well that the targetword (i.e.
the predicate for which arguments have tobe extracted) along with the correct frame are given.3.2.1 Data SetThe Italian dialog corpus includes 50 real human-human dialogs recorded and manually transcribed atthe call center of the help-desk facility of an Ital-ian Consortium for Information Systems.
The di-alogs are fluent and spontaneous conversations be-tween a caller and an operator, concerning hard-ware and software problems.
The dialog turns con-tain 1,677 annotated frame instances spanning 154FrameNet frames and 20 new ad hoc frames spe-cific for the domain.
New frames mostly con-cern data processing such as NAVIGATION, DIS-PLAY DATA, LOSE DATA, CREATE DATA.
Beingintended as a reference resource, this dataset in-cludes partially human-validated syntactic analysis,i.e.
lower branches corrected to fit arguments.
Wedivided such dataset into 90% training (1,521 frameinstances) and 10% testing (156 frame instances).Each frame instance brings its own set of frame par-ticipant (or predicate argument) instances.For BD, the very same approach as in Section 3.1was followed.
For RC, we also followed the sameapproach but, in order to cope with data sparse-87ness, we also attempted a different RC strategy bymerging data related to different syntactic predicateswithin the same frame.
So, within each frame, wemerged data related to verbal predicates, nominalpredicates, and so on.
Due to the short space avail-able, we will just report results for this latter ap-proach, which performed sensitively better.3.2.2 ResultsThe results are reported in Table 3.
Each ta-ble block shows Precision, Recall and F1 for ei-ther PK, TK, or PK+TK.
The rows marked as BDshow the results for the task of marking the exactconstituent boundaries of every frame element (ar-gument) found.
The rows marked as BD+RC showthe results for the two-stage pipeline of bothmarkingthe exact constituent boundaries and also assigningthe correct semantic label.
A few observations hold.First, the highest F1 has been achieved using thePK+TK combination.
On this concern, we under-line that kernel combinations always gave the bestperformance in any experiment we run.Second, we emphasize that the F1 of PK is sur-prisingly high, since it exploits the set of standardSRL feature (Gildea and Jurafsky, 2002; Pradhanet al, 2005), originally developed for English andleft unmodified for Italian.
Nonetheless, their per-formance is comparable to the Tree Kernels and,as we said, their combination improves the result.Concerning the structured features exploited by TreeKernels, we note that they work as well without anytuning when ported to Italian dialogs.Finally, the achieved F1 is extremely good.
Infact, our corresponding result on the FrameNet cor-pus (Table 2) is P=0.784, R=0.571, F1=0.661,where the corpus contains much more data, its sen-tences come from a standard written text (no dis-fluencies are present) and it is in English language,which is morphologically simpler than Italian.
Onthe other hand, the Italian corpus includes optimalsyntactic annotation which exactly fits the frame se-mantics, and the number of frames is lower than inthe FrameNet experiment.4 ConclusionsThe good performance achieved for Italian dialogsshows that FrameNet-based parsing is viable for la-beling conversational speech in any language us-ing a few training data.
Moreover, the approachworks well for very specific domains, like help-desk/customer conversations.
Nonetheless, addi-tional tests based on fully automatic transcriptionand syntactic parsing are needed.
However, our cur-rent results show that future research on complexspoken dialog systems is enabled to exploit automat-ically generated frame semantics, which is our verydirection.AcknowledgmentsThe authors wish to thank Daniele Pighin for the SRL subsys-tem and Sara Tonelli for the Italian corpus.
This work has beenpartially funded by the European Commission - LUNA project(contract n.33549), and by the Marie Curie Excellence Grantfor the ADAMACH project (contract n.022593).ReferencesCollin F. Baker, Charles J. Fillmore, and John B. Lowe.1998.
The Berkeley FrameNet project.
In Proceed-ings of COLING-ACL ?98, pages 86?90.Xavier Carreras and Llu?
?s Ma`rquez.
2005.
Introductionto the CoNLL-2005 Shared Task: Semantic Role La-beling.
In Proceedings of CoNLL-2005.Michael Collins and Nigel Duffy.
2002.
New RankingAlgorithms for Parsing and Tagging: Kernels over Dis-crete structures, and the voted perceptron.
In ACL02.Bonaventura Coppola, Alessandro Moschitti, andDaniele Pighin.
2008.
Generalized framework forsyntax-based relation mining.
In IEEE-ICDM 2008.Katrin Erk and Sebastian Pado.
2006.
Shalmaneser - aflexible toolbox for semantic role assignment.
In Pro-ceedings of LREC 2006, Genoa, Italy.Daniel Gildea and Daniel Jurafsky.
2002.
Automatic La-beling of Semantic Roles.
Computational Linguistics.A.
L. Gorin, G. Riccardi, and J. H. Wright.
1997.
Howmay i help you?
Speech Communication.Alessandro Moschitti, Bonaventura Coppola, DanielePighin, and Roberto Basili.
2005.
Engineering of syn-tactic features for shallow semantic parsing.
In ACLWS on Feature Engineering for ML in NLP.Alessandro Moschitti, Daniele Pighin, and RobertoBasili.
2008.
Tree kernels for semantic role labeling.Computational Linguistics, 34(2):193?224.Sameer Pradhan, Kadri Hacioglu, Valerie Krugler,Wayne Ward, James H. Martin, and Daniel Jurafsky.2005.
Support Vector Learning for Semantic Argu-ment Classification.
Machine Learning.Nianwen Xue and Martha Palmer.
2004.
Calibratingfeatures for semantic role labeling.
In Proceedings ofEMNLP 2004.88
