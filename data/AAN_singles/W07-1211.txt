Proceedings of the 5th Workshop on Important Unresolved Matters, pages 81?88,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsA Task-based Comparison of Information Extraction Pattern ModelsMark A. Greenwood and Mark StevensonDepartment of Computer ScienceUniversity of SheffieldSheffield, S1 4DP, UK{m.greenwood, marks}@dcs.shef.ac.ukAbstractSeveral recent approaches to InformationExtraction (IE) have used dependency treesas the basis for an extraction pattern repre-sentation.
These approaches have used a va-riety of pattern models (schemes which de-fine the parts of the dependency tree whichcan be used to form extraction patterns).Previous comparisons of these pattern mod-els are limited by the fact that they have usedindirect tasks to evaluate each model.
Thislimitation is addressed here in an experimentwhich compares four pattern models usingan unsupervised learning algorithm and astandard IE scenario.
It is found that thereis a wide variation between the models?
per-formance and suggests that one model is themost useful for IE.1 IntroductionA common approach to Information Extraction (IE)is to (manually or automatically) create a set of pat-terns which match against text to identify informa-tion of interest.
Muslea (1999) reviewed the ap-proaches which were used at the time and foundthat the most common techniques relied on lexico-syntactic patterns being applied to text which hasundergone relatively shallow linguistic processing.For example, the extraction rules used by Soderland(1999) and Riloff (1996) match text in which syn-tactic chunks have been identified.
More recentlyresearchers have begun to employ deeper syntacticanalysis, such as dependency parsing (Yangarber etal., 2000; Stevenson and Greenwood, 2005; Sudo etal., 2001; Sudo et al, 2003; Yangarber, 2003).
Inthese approaches extraction patterns are essentiallyparts of the dependency tree.
To perform extractionthey are compared against the dependency analysisof a sentence to determine whether it contains thepattern.Each of these approaches relies on a patternmodel to define which parts of the dependency treecan be used to form the extraction patterns.
A vari-ety of pattern models have been proposed.
For ex-ample the patterns used by Yangarber et al (2000)are the subject-verb-object tuples from the depen-dency tree (the remainder of the dependency parse isdiscarded) while Sudo et al (2003) allow any sub-tree within the dependency parse to act as an ex-traction pattern.
Stevenson and Greenwood (2006)showed that the choice of pattern model has impor-tant implications for IE algorithms including signifi-cant differences between the various models in termsof their ability to identify information of interest intext.However, there has been little comparison be-tween the various pattern models.
Those which havebeen carried out have been limited by the fact thatthey used indirect tasks to evaluate the various mod-els and did not compare them in an IE scenario.We address this limitation here by presenting a di-rect comparison of four previously described patternmodels using an unsupervised learning method ap-plied to a commonly used IE scenario.The remainder of the paper is organised as fol-lows.
The next section presents four pattern modelswhich have been previously introduced in the litera-81ture.
Section 3 describes two previous studies whichcompared these models and their limitations.
Sec-tion 4 describes an experiment which compares thefour models on an IE task, the results of which aredescribed in Section 5.
Finally, Section 6 discussesthe conclusions which may be drawn from this work.2 IE Pattern ModelsIn dependency analysis (Mel?c?uk, 1987) the syntaxof a sentence is represented by a set of directed bi-nary links between a word (the head) and one of itsmodifiers.
These links may be labelled to indicatethe relation between the head and modifier (e.g.
sub-ject, object).
An example dependency analysis forthe sentence ?Acme hired Smith as their new CEO,replacing Bloggs.?
is shown Figure 1.Figure 1: An example dependency tree.The remainder of this section outlines four mod-els for representing extraction patterns which can bederived from dependency trees.Predicate-Argument Model (SVO): A simpleapproach, used by Yangarber et al (2000), Yangar-ber (2003) and Stevenson and Greenwood (2005),is to use subject-verb-object tuples from the depen-dency parse as extraction patterns.
These consist ofa verb and its subject and/or direct object.
Figure2 shows the two SVO patterns1 which are producedfor the dependency tree shown in Figure 1.This model can identify information which is ex-pressed using simple predicate-argument construc-tions such as the relation between Acme and Smith1The formalism used for representing dependency patternsis similar to the one introduced by Sudo et al (2003).
Eachnode in the tree is represented in the format a[b/c] (e.g.subj[N/Acme]) where c is the lexical item (Acme), b itsgrammatical tag (N) and a the dependency relation between thisnode and its parent (subj).
The relationship between nodes isrepresented as X(A+B+C) which indicates that nodes A, B andC are direct descendents of node X.in the dependency tree shown in Figure 1.
How-ever, the SVO model cannot represent informationdescribed using other linguistic constructions suchas nominalisations or prepositional phrases.
For ex-ample the SVO model would not be able to recog-nise that Smith?s new job title is CEO since thesepatterns ignore the part of the dependency tree con-taining that information.Chains: A pattern is defined as a path between averb node and any other node in the dependency treepassing through zero or more intermediate nodes(Sudo et al, 2001).
Figure 2 shows examples of thechains which can be extracted from the tree in Figure1.Chains provide a mechanism for encoding infor-mation beyond the direct arguments of predicatesand includes areas of the dependency tree ignored bythe SVO model.
For example, they can represent in-formation expressed as a nominalisation or within aprepositional phrase, e.g.
?The resignation of Smithfrom the board of Acme ...?
However, a potentialshortcoming of this model is that it cannot representthe link between arguments of a verb.
Patterns in thechain model format are unable to represent even thesimplest of sentences containing a transitive verb,e.g.
?Smith left Acme?.Linked Chains: The linked chains model(Greenwood et al, 2005) represents extraction pat-terns as a pair of chains which share the same verbbut no direct descendants.
Example linked chainsare shown in Figure 2.
This pattern representa-tion encodes most of the information in the sen-tence with the advantage of being able to link to-gether event participants which neither of the SVOor chain model can, for example the relation be-tween ?Smith?
and ?Bloggs?
in Figure 1.Subtrees: The final model to be considered is thesubtree model (Sudo et al, 2003).
In this model anysubtree of a dependency tree can be used as an ex-traction pattern, where a subtree is any set of nodesin the tree which are connected to one another.
Sin-gle nodes are not considered to be subtrees.
Thesubtree model is a richer representation than thosediscussed so far and can represent any part of a de-pendency tree.
Each of the previous models form aproper subset of the subtrees.
By choosing an appro-priate subtree it is possible to link together any pairof nodes in a tree and consequently this model can82SVO[V/hire](subj[N/Acme]+obj[N/Smith])[V/replace](obj[N/Bloggs])Chains[V/hire](subj[N/Acme])[V/hire](obj[N/Smith])[V/hire](obj[N/Smith](as[N/CEO]))[V/hire](obj[N/Smith](as[N/CEO](gen[N/their])))Linked Chains[V/hire](subj[N/Acme]+obj[N/Smith])[V/hire](subj[N/Acme]+obj[N/Smith](as[N/CEO]))[V/hire](obj[N/Smith]+vpsc mod[V/replace](obj[N/Bloggs]))Subtrees[V/hire](subj[N/Acme]+obj[N/Smith]+vpsc mod[V/replace])[V/hire](subj[N/Acme]+vpsc mod[V/replace](obj[N/Bloggs]))[N/Smith](as[N/CEO](gen[N/their]+mod[A/new]))Figure 2: Example patterns for four modelsrepresent the relation between any set of items in thesentence.3 Previous ComparisonsThere have been few direct comparisons of the var-ious pattern models.
Sudo et al (2003) comparedthree models (SVO, chains and subtrees) on twoIE scenarios using a entity extraction task.
Mod-els were evaluated in terms of their ability to iden-tify entities taking part in events and distinguishthem from those which did not.
They found theSVO model performed poorly in comparison withthe other two models and that the performance ofthe subtree model was generally the same as, orbetter than, the chain model.
However, they didnot attempt to determine whether the models couldidentify the relations between these entities, simplywhether they could identify the entities participatingin relevant events.Stevenson and Greenwood (2006) compared thefour pattern models described in Section 2 in termsof their complexity and ability to represent rela-tions found in text.
The complexity of each modelwas analysed in terms of the number of patternswhich would be generated from a given depen-dency parse.
This is important since several ofthe algorithms which have been proposed to makeuse of dependency-based IE patterns use iterativelearning (e.g.
(Yangarber et al, 2000; Yangarber,2003; Stevenson and Greenwood, 2005)) and are un-likely to cope with very large sets of candidate pat-terns.
The number of patterns generated thereforehas an effect on how practical computations usingthat model may be.
It was found that the numberof patterns generated for the SVO model is a lin-ear function of the size of the dependency tree.
Thenumber of chains and linked chains is a polynomialfunction while the number of subtrees is exponen-tial.Stevenson and Greenwood (2006) also analysedthe representational power of each model by measur-ing how many of the relations found in a standard IEcorpus they are expressive enough to represent.
(Thedocuments used were taken from newswire texts andbiomedical journal articles.)
They found that theSVO and chain model could only represent a smallproportion of the relations in the corpora.
The sub-tree model could represent more of the relations thanany other model but that there was no statistical dif-ference between those relations and the ones cov-ered by the linked chain model.
They concludedthat the linked chain model was optional since it isexpressive enough to represent the information ofinterest without introducing a potentially unwieldynumber of patterns.There is some agreement between these two stud-ies, for example that the SVO model performspoorly in comparison with other models.
However,Stevenson and Greenwood (2006) also found thatthe coverage of the chain model was significantlyworse than the subtree model, although Sudo et al83(2003) found that in some cases their performancecould not be distinguished.
In addition to these dis-agreements, these studies are also limited by the factthat they are indirect; they do not evaluate the vari-ous pattern models on an IE task.4 ExperimentsWe compared each of the patterns models describedin Section 2 using an unsupervised IE experimentsimilar to one described by Sudo et al (2003).Let D be a corpus of documents and R a set ofdocuments which are relevant to a particular extrac-tion task.
In this context ?relevant?
means that thedocument contains the information we are interestedin identifying.
D and R are such that D = R ?
R?and R?R?
= ?.
As assumption behind this approachis that useful patterns will be far more likely to occurin R than D overall.4.1 Ranking PatternsPatterns for each model are ranked using a techniqueinspired by the tf-idf scoring commonly used in In-formation Retrieval (Manning and Schu?tze, 1999).The score for each pattern, p, is given by:score(p) = tfp ?(Ndfp)?
(1)where tfp is the number of times pattern p ap-pears in relevant documents, N is the total numberof documents in the corpus and dfp the number ofdocuments in the collection containing the patternp.Equation 1 combines two factors: the term fre-quency (in relevant documents) and inverse docu-ment frequency (across the corpus).
Patterns whichoccur frequently in relevant documents without be-ing too prevalent in the corpus are preferred.
Sudoet al (2003) found that it was important to find theappropriate balance between these two factors.
Theyintroduced the ?
parameter as a way of controllingthe relative contribution of the inverse document fre-quency.
?
is tuned for each extraction task and pat-tern model combination.Although simple, this approach has the advantagethat it can be applied to each of the four pattern mod-els to provide a direct comparison.4.2 Extraction ScenarioThe ranking process was applied to the IE scenarioused for the sixth Message Understanding confer-ence (MUC-6).
The aim of this task was to iden-tify management succession events from a corpusof newswire texts.
Relevant information describesan executive entering or leaving a position within acompany, for example ?Last month Smith resignedas CEO of Rooter Ltd.?.
This sentence described asevent involving three items: a person (Smith), po-sition (CEO) and company (Rooter Ltd).
We madeuse of a version of the MUC-6 corpus described bySoderland (1999) which consists of 598 documents.For these experiments relevant documents wereidentified using annotations in the corpus.
However,this is not necessary since Sudo et al (2003) showedthat adequate knowledge about document relevancecould be obtained automatically using an IR system.4.3 Pattern GenerationThe texts used for these experiments were parsedusing the Stanford dependency parser (Klein andManning, 2002).
The dependency trees were pro-cessed to replace the names of entities belongingto specific semantic classes with a general token.Three of these classes were used for the manage-ment succession domain (PERSON, ORGANISA-TION and POST).
For example, in the dependencyanalysis of ?Smith will became CEO next year?,?Smith?
is replaced by PERSON and ?CEO?
byPOST.
This process allows more general patterns tobe extracted from the dependency trees.
For exam-ple, [V/become](subj[N/PERSON]+obj[N/POST]).In the MUC-6 corpus items belonging to the relevantsemantic classes are already identified.Patterns for each of the four models were ex-tracted from the processed dependency trees.
Forthe SVO, chain and linked chain models this wasachieved using depth-first search.
However, theenumeration of all subtrees is less straightforwardand has been shown to be a #P -complete prob-lem (Goldberg and Jerrum, 2000).
We made use ofthe rightmost extension algorithm (Abe et al, 2002;Zaki, 2002) which is an efficient way of enumeratingall subtrees.
This approach constructs subtrees iter-atively by combining together subtrees which havealready been observed.
The algorithm starts with a84set of trees, each of which consists of a single node.At each stage the known trees are extended by theaddition of a single node.
In order to avoid dupli-cation the extension is restricted to allowing nodesonly to be added to the nodes on the rightmost pathof the tree.
Applying the process recursively createsa search space in which all subtrees are enumeratedwith minimal duplication.The rightmost extension algorithm is most suitedto finding subtrees which occur multiple times and,even using this efficient approach, we were unableto generate subtrees which occurred fewer than fourtimes in the MUC-6 texts in a reasonable time.
Sim-ilar restrictions have been encountered within otherapproaches which have relied on the generation ofa comprehensive set of subtrees from a parse for-est.
For example, Kudo et al (2005) used subtreesfor parse ranking but could only generate subtreeswhich appear at least ten times in a 40,000 sentencecorpus.
They comment that the size of their data setmeant that it would have been difficult to completethe experiments with less restrictive parameters.
Inaddition, Sudo et al (2003) only generated subtreeswhich appeared in at least three documents.
Kudoet al (2005) and Sudo et al (2003) both used therightmost extension algorithm to generate subtrees.To provide a direct comparison of the patternmodels we also produced versions of the sets of pat-terns extracted for the SVO, chain and linked chainmodels in which patterns which occurred fewer thanfour times were removed.
Table 1 shows the num-ber of patterns generated for each of the four mod-els when the patterns are both filtered and unfil-tered.
(Although the set of unfiltered subtree pat-terns were not generated it is possible to determinethe number of patterns which would be generatedusing a process described by Stevenson and Green-wood (2006).
)Model Filtered UnfilteredSVO 9,189 23,128Chains 16,563 142,019Linked chains 23,452 493,463Subtrees 369,453 1.69 ?1012Table 1: Number of patterns generated by eachmodelIt can be seen that the various pattern models gen-erate vastly different numbers of patterns and thatthe number of subtrees is significantly greater thanthe other three models.
Previous analysis (see Sec-tion 3) suggested that the number of subtrees whichwould be generated from a corpus could be difficultto process computationally and this is supported byour findings here.4.4 Parameter TuningThe value of ?
in equation 1 was set using a sep-arate corpus from which the patterns were gener-ated, a methodology suggested by Sudo et al (2003).To generate this additional text we used the ReutersCorpus (Rose et al, 2002) which consists of a year?sworth of newswire output.
Each document in theReuters corpus has been manually annotated withtopic codes indicating its general subject area(s).One of these topic codes (C411) refers to man-agement succession events and was used to identifydocuments which are relevant to the MUC6 IE sce-nario.
A corpus consisting of 348 documents anno-tated with code C411 and 250 documents withoutthat code, representing irrelevant documents, weretaken from the Reuters corpus to create a corpuswith the same distribution of relevant and irrelevantdocuments as found in the MUC-6 corpus.
Unlikethe MUC-6 corpus, items belonging to the requiredsemantic classes are not annotated in the ReutersCorpus.
They were identified automatically usinga named entity identifier.The patterns generated from the MUC-6 textswere ranked using formula 1 with a variety of val-ues of ?.
These sets of ranked patterns were thenused to carry out a document filtering task on theReuters corpus - the aim of which is to differentiatedocuments based on whether or not they contain arelation of interest.
The various values for ?
werecompared by computing the area under the curve.
Itwas found that the optimal value for ?
was 2 for allpattern models and this setting was used for the ex-periments.4.5 EvaluationEvaluation was carried out by comparing the rankedlists of patterns against the dependency trees for theMUC-6 texts.
When a pattern is found to matchagainst a tree the items which match any seman-85tic classes in the pattern are extracted.
These itemsare considered to be related and compared againstthe gold standard data in the corpus to determinewhether they are in fact related.The precision of a set of patterns is computed asthe proportion of the relations which were identifiedthat are listed in the gold standard data.
The recall isthe proportion of relations in the gold standard datawhich are identified by the set of patterns.The ranked set of patterns are evaluated incremen-tally with the precision and recall of the first (highestranked) pattern computed.
The next pattern is thenadded to the relations extracted by both are evalu-ated.
This process continues until all patterns areexhausted.5 ResultsFigure 3 shows the results when the four filtered pat-tern models, ranked using equation 1, are compared.A first observation is that the chain modelperforms poorly in comparison to the otherthree models.
The highest precision achieved bythis model is 19.9% and recall never increasesbeyond 9%.
In comparison the SVO model in-cludes patterns with extremely high precision butthe maximum recall achieved by this model islow.
Analysis showed that the first three SVOpatterns had very high precision.
These were[V/succeed](subj[N/PERSON]+obj[N/PERSON]),[V/be](subj[N/PERSON]+obj[N/POST]) and[V/become](subj[N/PERSON]+obj[N/POST]),which have precision of 90.1%, 80.8% and 78.9%respectively.
If these high precision patterns areremoved the maximum precision of the SVO modelis around 32%, which is comparable with the linkedchain and subtree models.
This suggests that, whilethe SVO model includes very useful extractionpatterns, the format is restrictive and is unable torepresent much of the information in this corpus.The remaining two pattern models, linked chainsand subtrees, have very similar performance andeach achieves higher recall than the SVO model, al-beit with lower precision.
The maximum recall ob-tained by the linked chain model is slightly lowerthan the subtree model but it does maintain higherprecision at higher recall levels.The maximum recall achieved by all four modelsis very low in this evaluation and part of the reasonfor this is the fact that the patterns have been filteredto allow direct comparison with the subtree model.Figure 4 shows the results when the unfiltered SVO,chain and linked chain patterns are used.
(Perfor-mance of the filtered subtrees are also included inthis graph for comparison.
)This result shows that the addition of extra pat-terns for each model improves recall without effect-ing the maximum precision achieved.
The chainmodel also performs badly in this experiment.
Pre-cision of the SVO model is still high (again this isdue to the same three highly accurate patterns) how-ever the maximum recall achieved by this model isnot particularly increased by the addition of the un-filtered patterns.
The linked chain model benefitsmost from the unfiltered patterns.
The extra patternslead to a maximum recall which is more than dou-ble any of the other models without overly degrad-ing precision.
The fact that the linked chain modelis able to achieve such a high recall shows that it isable to represent the relations found in the MUC-6text, unlike the SVO and chain models.
It is likelythat the subtrees model would also produce a set ofpatterns with high recall but the number of poten-tial patterns which are allowable within this modelmakes this impractical.6 Discussion and ConclusionsSome of the results reported for each model in theseexperiments are low.
Precision levels are generallybelow 40% (with the exception of the SVO modelwhich achieves high precision using a small numberof patterns).
One reason for this that the the patternswere ranked using a simple unsupervised learningalgorithm which allowed direct comparison of fourdifferent pattern models.
This approach only madeuse of information about the distribution of patternsin the corpus and it is likely that results could be im-proved for a particular pattern model by employingmore sophisticated approaches which make use ofadditional information, for example the structure ofthe patterns.The results presented here provide insight into theusefulness of the various pattern models by evaluat-ing them on an actual IE task.
It is found that SVOpatterns are capable of high precision but that the860.0 0.1 0.2 0.3 0.4Recall0.00.10.20.30.40.50.60.70.80.9PrecisionSubject-Verb-ObjectChainsLinked ChainsSubtreesFigure 3: Comparisons of filtered pattern models.0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8Recall0.00.10.20.30.40.50.60.70.80.9PrecisionSubject-Verb-ObjectChainsLinked ChainsSubtreesFigure 4: Comparison of unfiltered models.87restricted set of possible patterns leads to low re-call.
The chain model was found to perform badlywith low recall and precision regardless of whetherthe patterns were filtered.
Performance of the linkedchain and subtree models were similar when the pat-terns were filtered but unfiltered linked chains werecapable of achieving far higher recall than the fil-tered subtrees.These experiments suggest that the linked chainmodel is a useful one for IE since it is simple enoughfor an unfiltered set of patterns to be extracted andable to represent a wider range of information thanthe SVO and chain models.ReferencesKenji Abe, Shinji Kawasoe, Tatsuya Asai, HirokiArimura, and Setsuo Arikawa.
2002.
Optimised Sub-structure Discovery for Semi-Structured Data.
In Pro-ceedings of the 6th European Conference on Princi-ples and Practice of Knowledge in Databases (PKDD-2002), pages 1?14.Leslie Ann Goldberg and Mark Jerrum.
2000.
CountingUnlabelled Subtrees of a Tree is #P -Complete.
Lon-don Mathmatical Society Journal of Computation andMathematics, 3:117?124.Mark A. Greenwood, Mark Stevenson, Yikun Guo, HenkHarkema, and Angus Roberts.
2005.
Automati-cally Acquiring a Linguistically Motivated Genic In-teraction Extraction System.
In Proceedings of the4th Learning Language in Logic Workshop (LLL05),Bonn, Germany.Dan Klein and Christopher D. Manning.
2002.
FastExact Inference with a Factored Model for NaturalLanguage Parsing.
In Advances in Neural Informa-tion Processing Systems 15 (NIPS 2002), Vancouver,Canada.Taku Kudo, Jun Suzuki, and Hideki Isozaki.
2005.Boosting-based Parse Reranking with Subtree Fea-tures.
In Proceedings of the 43rd Annual Meeting ofthe Association for Computational Linguistics, pages189?196, Ann Arbour, MI.Chritopher Manning and Hinrich Schu?tze.
1999.
Foun-dations of Statistical Natural Language Processing.MIT Press, Cambridge, MA.Igor Mel?c?uk.
1987.
Dependency Syntax: Theory andPractice.
SUNY Press, New York.Ion Muslea.
1999.
Extraction Patterns for InformationExtraction: A Survey.
In Proceedings of the AAAI-99workshop on Machine Learning for Information Ex-traction, Orlando, FL.Ellen Riloff.
1996.
Automatically Generating ExtractionPatterns from Untagged Text.
In Thirteenth NationalConference on Artificial Intelligence (AAAI-96), pages1044?1049, Portland, OR.Tony Rose, Mark Stevenson, and Miles Whitehead.2002.
The Reuters Corpus Volume 1 - from Yes-terday?s News to Tomorrow?s Language Resources.In Proceedings of the Third International Conferenceon Language Resources and Evaluation (LREC-02),pages 827?832, La Palmas de Gran Canaria.Stephen Soderland.
1999.
Learning Information Extrac-tion Rules for Semi-structured and Free Text.
MachineLearning, 31(1-3):233?272.Mark Stevenson and Mark A. Greenwood.
2005.
A Se-mantic Approach to IE Pattern Induction.
In Proceed-ings of the 43rd Annual Meeting of the Association forComputational Linguistics, pages 379?386, Ann Ar-bor, MI.Mark Stevenson and Mark A. Greenwood.
2006.
Com-paring Information Extraction Pattern Models.
In Pro-ceedings of the Information Extraction Beyond TheDocument Workshop (COLING/ACL 2006), pages 12?19, Sydney, Australia.Kiyoshi Sudo, Satoshi Sekine, and Ralph Grishman.2001.
Automatic Pattern Acquisition for JapaneseInformation Extraction.
In Proceedings of the Hu-man Language Technology Conference (HLT2001),San Diego, CA.Kiyoshi Sudo, Satoshi Sekine, and Ralph Grishman.2003.
An Improved Extraction Pattern Representa-tion Model for Automatic IE Pattern Acquisition.
InProceedings of the 41st Annual Meeting of the Associ-ation for Computational Linguistics (ACL-03), pages224?231, Sapporo, Japan.Roman Yangarber, Ralph Grishman, Pasi Tapanainen,and Silja Huttunen.
2000.
Unsupervised Discov-ery of Scenario-level Patterns for Information Extrac-tion.
In Proceedings of the Applied Natural LanguageProcessing Conference (ANLP 2000), pages 282?289,Seattle, WA.Roman Yangarber.
2003.
Counter-training in the Dis-covery of Semantic Patterns.
In Proceedings of the41st Annual Meeting of the Association for Computa-tional Linguistics (ACL-03), pages 343?350, Sapporo,Japan.Mohammed Zaki.
2002.
Effectively Mining FrequentTrees in a Forest.
In 8th ACM SIGKDD InternationalConference on Knowledge Discovery and Data Min-ing, pages 71?80, Edmonton, Canada.88
