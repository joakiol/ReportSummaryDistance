An Application of Lexical Semanticsto Knowledge Acquisition from CorporaPeter AnickComputer Science DepartlnentBrandeis UniversityWaltham, MA 02254James PustejovskyComputer Science DepartmentBrandeis UniversityWaltham, MA 022,54AbstractIn this paper, we describe aprogram of researchdesigned to explore.'
how a lexical semantic the-ory may be exploited for extracting informationfrom corpora suitable for use in Information Re-trieval applications.
Unlike with purely statis-tical collocational analyses, the framework of asemantic theory allows the ~ultomatic construc-tion of predictions about semantic relationshipsamong words appearing in coltocatioz~al sys-tems.
We illustrate the at)proach for the acqui-sition of lexical information for several classesof nominals.Keywords:: Knowledge Acquisition, Information Re-trieval, Lexical Semantics.
:, Introduction'Fl:e proliferation of on-line textual information hasintensified the search for ctlieient automated in(h;x-.ing and retrieval techniques, l"ull-text indexing, inwhich all the content words in a document are usedas keywords, is one of the most promising of recentautomated approaches, yet its mediocre precision andi'ecall characteristics indicate that there is much roomfor improvement \[Croft, 1989\].
The use of domainknowledge can enhance the elDctiveness of a full-text:~;ystem by providing related ~erms that can be used lobroaden, narrow, or retbcus a query at retrieval time(\[Thompson and Croft 1989\], \[Anick et al 1!
)89\] [l)e-bill et al 1988\].
Likewise, domain knowledge mayI,e applied at indexing time to do word sense disam-biguation \[Krovetz & Croft, 19891 or content analy-~;is \[Jacobs, 1989\].
Unfortunately, for many domains,~mch knowledge, even in the form of a thesaurus, iseither not available or is incomplete with respect tothe vocabulary of the texts indexed.The tradition in both AI and Library Science hasbeen to hand-craft domain knowledge., but the cur-b:eut availability of machine-readal)le dictioimries andlarge text corpora presents the possibility of derivingat least some domain knowledge via automated pro-cedures \[amsler, 1980\] \[Maarek and Smadja, 1989\]\[Wilks et al 1988\].
The approach describe.d in thispaper outlines one such experiment.We start with: (1) a lexicon containing morpho-~yntaetie information for el>proximately 20,000 con,-mon Fmglish words; (2) encodings of English mor-phological paradigms and a morphological analyzercapable of producing potential citation forms fi'omintlected forms; (3) a bottom-up arser for recogniz-ing sub-sentential t)hrasal constructions; and (4) atheory of lexical semantics embodying a collection ofpowerful semantic princilfles and their syntactic real-izations.The aim of our research is to discover what kinds ofknowledge can be reliably acquired through tile useof these methods, exploiting, as they do, general in-guistic knowh'.dge rather than domain knowledge.
Inthis respect, our program is similar to Zernik's (1989)work on extracting verb semantics from corpora us-ing lexical categories.
()tar research, however, differsin two respects: first, we employ a more expressivelexical semantics for encoding lexical knowledge; andsecondly, our focus is on nominals, for both pragmaticand theoretical reasons, l'~or full-text information re-trieval, information about nominals is pararnomlt, asmost queries tend to be expressed as conjunctionsO\[" t\]O/lllS.
Frol l l  Ollr thc'oretical perspective, we be-lieve that the c(mtribution of the lexieal semantics ofnominals to the overall structure of the lexicon hasbeen somewhat neglected (relative to that of verbs)\[1)ustejovsky and Anick, 1!
:)88\], \[Pustejovsky 1989\].Indeed, whereas Zcrnik (1989) presents metonymy asa potc~d, ial obstacle to effective corpus analysis, webeliew: that the existe,ce of motivated nletonymicstructures provides valuable clues for semantic anal-ysis of nouns in a corpus.Our current work attempts to acquire the followingkinds of lexical information without domain knowl-edge:o Part of st;eech and morphological paradigms fornew words and new uses of  old words;o Bracketing of noun compounds;o Subclass relations between nouns;o Lexical semantic ategorization of nouns;o Clustering of verbs into semantic classes basedon the collections of nouns they predicate.While such information is still inadequate for natu-ral language "understanding" systems, it.
vastly sim-plifies the task of knowledge ngineering, should onedesire to hand-code lexical items.
Furthernlore, suchinformation can be trot to use directly in full-text1 7information retrieval systems, fulfilling some of theroles typically played by thesauri and faceted classi-fications \[Vickery, 1975\].2 A \ ]~amework  fo r  Lex ica l  Semant icsThe framework for lexical knowledge we will be as-suming is that developed by Pustejovsky (1989), whoproposes a theory of lexieal semantics which exploresthe internal structure of lexical items from a com-putational perspective.
In this theory, lexical andconceptual decomposition is performed generatively.That is, rather than assuming a fixed set of primi-tives, we assume a fixed set of rules of compositionand generative devices.
Thus, just a.s a formal lan-guage is described more in terms of the productionsof the grammar ather than in terms of its accom-panying vocabulary, a semantic language should bedefined by the rules generating the structures for ex-pressions, rather than the vocabulary of primitivesitself.
For this reason, a dictionary of lexical itemsand the concepts they derive can be viewed a.s a gen-erative lexicon)Such a theory of lexical meaning specifies both ageneral methodology and a specific language for ex-pressing the semantic ontent of lexical items in natu-ral language.
The aspect of this theory most relevantto our own concerns is a language for structuring thesemantics of nominals.
Pustejovsky (1989) calls thisthe Qualia Structure of a noun, which is essentiallya structured representation similar to a verb's argu-ment structure.
This structure specifies four aspectsof a noun's meaning: its constituent parts; its for-mal structure; its purpose and function (i.e.
its Telicrole); and how it comes about (i.e.
its Agentive role).For example, book might be represented as contain-ing the following information:book (*x*, *y* )\[Const: in: formation(*y*)\ ]\[Form: bound-pages(*x*) or d isk(*x*) \ ]\[Telic : read(T ,~,*y* ) \ ]\[Agentive : ar t i fac t ( *x* )write (T,z,*y*)\]This permits us to use the same lexical representa-tion in very different contexts, where the word seemsto refer to different qualia of the noun's meaning.
Forexample, the sentences in (2)-(3) refer to different as-pects (or qualia) of the general meaning of book.1: This book weighs four ounces.2: John finished a book.3: This is an interesting book.Sentence (1) makes reference to the Formal role,while sentence (3) refers to the Constitutive role.
Ex-ample (2), however, can refer to either the Telic orthe Agentive aspects given above.
The utility of suchknowledge for information retrieval is readily appar-ent.
This theory claims that noun meanings houldmake reference to related concepts and the relationsinto which they enter.
The qualia structure, thus, canIF or elaboration on this idea and how it applies tovarious lexical classes, see Pustejovsky (forthcoming).be viewed as a kind of generic template for structur-ing this knowledge.To further illustrate how objects cluster accordingto these dimensions, we will briefly consider three ob-ject types: (1) containers (of information), e.g.
book,tape, record; (2) instruments, e.g.
gun, /Jammer,paintbrush; and (3) figure-ground objects, e.g.
door,room, fireplace.
Because of how their qualia struc-tures differ, these classes appear in vastly differentgrammatical contexts.As with containers in general, information contain-ers permit metonymic extensions between the con-tainer and the material contained within it.
Colloca-tions such as those in (4) through (7) indicate thatthis metonymy is gramrnaticalized through specificand systematic head-PP constructions.4: read a book5: read a story in a book6: read a tape7: read the informatioz~ on ghe tapeInstruments, on the other hand, display clas-sic agent-instrument causative alternations, such asthose in (8) through ( l l ) .8: ... smash the wse with the hammer9: The hammer smashed the wtse.10: ... kill him with a g~m11: The gun killed him.Finally, figure-ground nominals permit perspectiveshifts such ms those in (12) through (15).
212: John painted the door.13: John walked through the door.14: John is scrubbing the fireplace.15: The smoke filled the fireplace.That is, paint and scrub are actions on physicalobjects while walk through and fill are processes inspaces.
These collocational patterns, we argue, aresystematically predictable from the lexical semanticsof the noun, and we term such sets of collocatedphrases collocational systems, aTo make this point clearer, let us consider a specificexample of a collocational system.
Because of theparticular nmtonymy observed for a noun like tape,we will classify it as a 'container.'
In terms of the se-nmntic representation presented here, we can view itas a relational noun, with the following qualia struc-ture:tape(*x*, *y*)\[Const: in fo rmat ion(*y* ) \ ]\[Form: phys-obj  ect  (*x*)\]\ [Te l ic  : ho ld (S ,*x* , *y* ) \ ]\[Agent: ar t i fac t ( *x* )  ~ wr i te (T ,w,*y* ) \ ]This simply states that any semantics for tapemust logically make reference to the object itself (F),2See Pustejovsky and Anick (1988) for details.aThis relates to Mel'~uk's lexical functions and thesyntactic structures they associate with an element.
SeeMel'euk (1988) and references therein.
Cruse (1986) dis-cusses the foregrounding and backgronnding of informa-tion with respect o similar examples.8 2what it can contain (C), what purpose it serves (T);and how it arises (A).
This provides us with a se-mantic representation which can capture the multipleperspectives which a single lexical item may assumein different contexts.
Yet, the qualia for a lexical itemsuch as tape are not isolated values for that one word,but are integrated into a global knowledge b~tse indi-cating how these senses relate to other lexical itemsand their senses.
This is the contribution of inheri-tance and the hierarchical structuring of knowledge(e.g.
\[Brachman and Schmolze 1985\] and \[Bobrowand Winograd 1977\]).
In Pustejovsky (1989), it issuggested that there are two types of relational struc-tures for lexical knowledge; a t~xed inheritance similarto that of an ISA hierarchy (cf.
Touretsky (1986))4;and a dymamic structure which operates generativelyfrom the qualia structure of a lexical item to createa relational structure for ad hoc categories.Let us suppose then, that in addition to tile tixedrelational structures, our semantics allows us to dy-namically create arbitrary concepts through the ap-plication of certain transformations to lexical mean-ings.
For example, for any predicate, Q --- e.g.
thevalue of a qualia role - -  we can generate its oppo-sition, -,Q.
By relating these two predicates tempo-rally we can generate the arbitrary transition eventsfor this opposition.
Similarly, by operating over otherqualia role values we can generate semantically re-lated concepts.
The set of transformations includes:-~, negation, <, temporal precedence, >, temporalsuccession, =, temporal equivalence, and act, an op-erator adding agency to an argument.Intuitively, the space of concepts traversed by theapplication of such operators will be related expres-sions in the neighborhood of the original lexical item.We will call this the Projective Conclusion Space of aspecific quale for a lexical item.
5 To return to the ex-ample of tape above, the predicates read and copy arerelated to the Telic value by just such an operation.PredicalLes uch as mount and dismount, however, arerelated to the Formal role since they refer to the tapeas a physical object alone.It is our view that the approach outlined abovefor representing lexical knowledge can be put to usein the service of information retrieval tasks.
On theone hand, the projective conclusion space, with itsstructured assembly of terms, clusterd about a nom-inal entity, can serve as a "virtual script", capable ofhomonym disambiguation (\[Krovetz 1990\], \[Culling-ford and Pazzani 1984\]) and query reformulation.
Onthe other hand, the qualia structure cal)tures the in-herent polysemy of many nouns.
In the latter re-spect, our proposal can be compared to attemptsat object classification in information science.
Oneapproach, known as "faceted classification" (Vickery(1975)) proceeds roughly as follows.
Collect terms ly-ing within a field.
Then, group the terms into facetsby assigning them to categories.
Typical examples of4The,~aurus-like structures are similar within the Ill.community, ef.
\[National Library and Information Asso-ciations Council 1980\].5See Pustejovsky (1989) for details.this are state, property, reaction, device, tlowever,each subject area is likely to have its own sets ofcategories, making it ditficult to re-use a set of facetclassifications in another domain.
6Even if the relational information provided by thequalia structure and inheritance would improve per-%rmance in information retrieval tasks, one problemstill remains; namely that it would be very time-consuming to hand-code such structnres for all nounsin a domain.
Since it is our belief that such represen-tations are generic structures across all domains, ourlong term goal is to develop methods \['or how theserelations and values can be automatically extractedfrom on-line corpora.
In the section that follows, wedescribe one such experiment which indicates thatthe qualia ,;tructures do, in fact, correlate with col-locational systems, thereby allowing us to performstructure-matching operations over corpora to findthese relations.3 A Knowledge  Acqu is i t ionP rocedureIn this section, we outline our procedure for knowl-edge acquisition, implemented as part of the LINKSLexicon/Corpus Management System.
r Steps are il-lustrated with examples drawn from an analysis doneon a Digital Equipnlent Corporation on-line corpusof 3000 articles containing VMS troubleshooting in-formation.
Briefly, the procedure consists of the foblowing steps.1.
Ass ign nmrpho log ica l  parad igms to wordsin the corpus.2.
Generate  of  a set of b racketed  noun com-pounds ,  e.g.
\[TK50 \[tape drive\]\], \ [ \ [datablemanagement\] system\].3.
Col lect Nmm Phrases  re la ted  by prepos i -t ions from the collocational systems for the de-sired lexical items, e.g.
"file on tape", "formatof tape".4.
Hypot :hes ize subc lass  re la t ionsh ips  on thebasis of collocational information: e.g.
If Xand Y are nouns and the phrase X Y ap-pears in the corpus, and there is no phra.seY Prep X, then 1.5'A(X,Y).
For exam-ple: From \[TK50 \[tape drive\]\] we can pre-dict that ISA(TK50, iape drive), lIowever,the potential prediction from "tape drive" thatISA(tape, drive) is blocked by the existence ofphrase,~ like "tape in drive".5.
Seek d i s t r ibut iona l  ver i f icat ion of  subc lassre la t ionsh ips .
For each subclass so generated,seek distributional evidence to support tile hy-pothesis.
That is, is there a "substantial" inter-6This is reflected in the sublanguage work of Clrishmanet al(1986), whose automated iscovery procedures areaimed at clustering nouns into domain-specific categorieslike "body-part," symptom," etc.rThis is a system currently under development a Dig-ital Equipment Corporation.3 9section between verbs collocated with the sub-class and superclass terms?6.
At tempt  semant ic  classif ication into aknown lexical category.
Try to match theset of syntactic constructions within which Xappears with one of our diagnostic onstructionsets.
This may involve searching for the set ofconstructions that contain nouns in other argu-ment positions of the original set of construc-tions.
For example, the set of expressions in-volving the word "tape" in the context of its useas a secondary storage device suggests that itfits the container artifact schema of the qualiastructure, with "information" and "file" as itscontainees:(a) read information from tape(b) write file to tape(c) read information on tape(d) read tape(e) write tape7.
Use heur is t ics  to c luster  p red icates  thatre la te  to the  Telic quale of  the  noun.
Forexample, the word "tape" is the object of 34verbs in our corpus:( requ i re  use unload rep lace  mountres tore  t ime request  cont ro lposition dismount allocate offinitialize satisfy contain createencounter get alow try leave beload read write have cause protectup perform enforce copy)Among these verbs are some that refer to theformal quale: mount, dismount and some whichrefer to tape in its function ,as an informationcontainer: read, write, and copy.One of the ways to tease these sets apart isto take advantage of the linguistic rule that al-lows a container to be referred to in place ofthe contaiuce, i.e.
the container can be usedmetonymically.
The verbs which have "infor-mation" (previously identified as a likely "con-tainee" for tape) as an object in the corpus are:(check include display enter comparelist find get extract set be write fitcontain read recreate update returnprovide specify see open publish giveinsert have copy take relay lose gather)When we intersect he verb sets for "informa-tion" and "tape", we get a set that reflects thepredicates appropriate to the telic role of tape,a container of information (plus several emptyverbs):(copy have read contain write be get)Thus, the metonymy between container and con-tainee allows us to use set intersection to dis-criminate among predicates referring to the telicvs.
formal roles of the container.What results from this acquisition procedure isa kind of minimal faceted analysis for the nountape, as illustrated below.tape (*x*, *y*)\[Const : information(*y*), file(*y*)\]\[Form: mount (w,*x*), dismount (w,*x*)\]\[Telic: read(T,z,*y*), write(T,z,*y*),copy (T, z , *y* ) \ ]\[Agent : ar t i fac t  (*x*)\]To illustrate this procedure on another seman-tic category, consider the term "mouse" in itscomputer artifact sense.
In our corpus, it ap-pears in the object position of the verb "use"in a "use-to" construction, as well as the objectof tile preposition "with" following a transitiveverb and its object:(a) use the mouse to set breakpoints(b) use the mouse anywhere(c) move a window with the mouse(d) click on it with tile mouse ...These constructions are symptomatic of its roleas an instrument; and the VP complement of"to" as well as the VP dominating the "with"PP's identify the telic predicates for the noun.Other verbs, for which "mouse" appears as a di-rect object are currently defaulted into the for-real role, resulting in an entry for "mouse" asfollows:mouse(*x*)\[Cont : but ton(*x* ) \ ]\[Form: move(w,*x*), click(w,*x*)~hold(w, *x*)\]\[Telic: set(*x*,breakpoint),move (*x*, window),click-on (*x* ,window)\]\[Agent: i ns t  (*x*)\]Thus, by bringing together the automatic on-struction of collocational systems with a notionof qualia structure for nouns, we have arrived ata fairly useful lexical representation for Informa-tion Retrieval tasks.4 Discuss ionPrevious investigators involved in corpus anal-ysis using weak methods have documented lim-ited successes and warned of many pitfalls (e.g.\[Grishman el al 1986\] and \[Zernik 1989\]).
Theapproach described here differs from previous ef-forts in its combination of diagnostic colloca-tional systems with a generic target represen-tation for nouns.
While our limited experi-ments with the acquisition algorithm show somepromise, it is too early to tell how well thisapproach will do in a larger corpus containinga greater range of senses for terms.
One dan-ger is for the algorithm to be overly optimisticin matching a set of occurrences to a diagno-sis.
Given the rampant ambiguity of preposi-tions and the potential for verb object combi-nations that, can spuriously suggest metonymicI0 4relationships, we have found the algorithm as itstands to be too susceptible to jumping to falseconclusions.
We are looking to improve precisionby increasing our repertoire of both positive andnegative diagnostics, as well as by incorl)orat-ing information theoretic statistics (as in Churchand ttindle (1990)).Likewise, we have been investigating ways toreduce misses - cases in which evidence of re-lationships between terms known to be relatedis not detected by our current set, of heuristics.One case in point regards our analysis of "disk",which we initially expected to behaw~' similar to"tape" in its telic quale, ttowever, the intersec-tion of predicate sets for "disk" and "informa-tion" yielded the terms(copy s;pecify set be have)Missing are "read and "write", the relic pred-icates for tape.
This exarnf, le reveals tlwsubtleties present in the container nletonylny.Specifically, tlle container can stand in for itscontents only in I, hose situations where one refersto the contents as a whole.
While one lypically"reads" an entire talle, o~le usually reads onlyparts of a disk at a time.
':Copying" a wholedisk is more typical, however, and hence showsu 1) in our corpus.
Reading and writing still ap-ply to disks; \]lowcvcr, since tllt'.y do not applykolislically, we find instead construct.ions withthe I)repositions to and from.
e.g.
read/writef?om the disk.This example ilhi;-tl'atcs the pill'ails thai archMdng if the linguistic rules are too coarsei~ defined, but it also shows that such rules are liotdomain specific, an(l thus, once I)rol)('rly formu-lated, could function in a general mrposc diag-nostic context.
It, renla ins an empirical questionhow well weak method,, can I;e employc(l to dis--criminate among thequa leo fano .n .
While thisconstitutes the primary focus of our current re-search, we also I)elieve that the abo~c melho(/scomplement well other ongoing rcsearc\]l iJl theconstruction of word-disan~biguatcd dictionaries(e.g.
\[m~,in 1990\]).5 ConclusionWe contend that using lexical semantic methodsto guide lexical knowledge acquisition from cor-pora can yield structured thesaurus-like informa-tion in a form amenable for use within informa-tion retrieval applications.
The work reportedhere, though preliminary, illustrates the appli-cability of this approach for several importantcla.sses of nominals.
Future.
work im:ludes re-fining the discovery !
)rocevlures to reduce missesand false alarms and extending the coverage ofthe lexical semantics component o allow thetesting of such t.echniques on a greater range ofterms.
Finally, we intend to at>ply the resullsof the analysis within an experimental infonua-lion retrieval system to test their effectiveness asindexing and retrieval aids.Acknowledgements'\]'he authors wish to thank Bran Boguraev tbrusefifl discussion, and Jeff Brennan, Rex Flynn,and David flanssen, members of Digital Equip-ment Corporation's AI-STAI{S Information Re-triewd group, for their contributions to the de-velopment of the software used to conduct thisresearch, as well as for many discussions aroundthe applicat, ions of natural language processingto textual information retrieval.6 BibliographyAmsler, Robert (1980) The Structure of lhe MW-riam Webster Pockcl Diclionaw, Ph.D. Disser-tation, University of Texas at.
Austin, 1980.Anick; Peter, Jeff llrennan, Rex Flynn, Davidllanssen, Bryan Alvey, and Jeffrey Robbins(1990) A Direct Manipulation Interface forBoolean hffornmtion Retrieval via Natural Lan-guage Query, to appear ill Proceedings of SIGIR'90.Bobrow, 1).
G. and T. Winograd (1977) "AnOverview of KItL, a Knowledge llepresenlationl,anguage," Coguilivc Science, 1.1.l~ra('hman, R. J. and J. Schmolze (1985) "AnOverview of the KL-ONE Knowledge Represen-tation System," Cognilivc Science 9.2.Church, Kenneth and Donald Itindle (1990) Col-iocational Constraints and Corpus-Based Lin-guistics.
In Working Notes of the AAAI Sym-posium: Texl-Based lnlelligent Systems.Croft, \V.
B.
(1989) Automatic Indexing.
in IN-I-)I';XtNG: The State of Our Knowhxtge and theState of Our Ignorance, edited by Belle ItassWeinberg, \[,earned hfformation, Inc., Medford,N.
J., pp.
87-100.
(',rofl, W. B. and R. lI.
Thompson (1987) 13R: ANew Approach to the Design of l)ocument Re-trieval Systems.
JASIS, 38(6):389-404.Cullingford I{.
and Pazzani M. (1984) "Word-Meaning Selction in Multiprocess Language Un-derstanding Programs," IEEE Transactions onPattern Analysis and Machine Intelligence, Vol.6.4.l)ebili, Fathi, Christian Fluhr, Pierre RadaLsoa(1988) About l{efornmlation i  Full-Text IRS.RIAO 88 proceedings, pp.
343-357.Grishman, Ralph, Lynette tlirscMnan, NgoThanh Nhan (1986) l)iscovery Procedures forSublanguagc Selcctional Patterns: Initial Exper-iments.
Conlpulational IAnguistics, Vol.
12,Number 3, pp.
205-215.5 i iJackendoff, Ray (1983) Semantics and Cogni-lion, MIT Press, Cambridge, MA.Jacobs, Paul (1989) Paper presented at the FirstInternational Workshop on Lexical Acquisition,IJCAI-1989, Detroit.Krovetz, Robert and W. B. Croft (1989) WordSense Disambiguation Using Machine-ReadableDictionaries.
Proceedings ofSIGIR '89, pp.
127-136.Krovetz, Robert (1.990) "hfformation Retrievaland Lexical Ambiguity" In Working Notes of theAAAI Symposium: Text-Based Intelligent Sys-tems.Maarek, Y.S.
and F. Z. Smadja (1989) Full TextIndexing Based on Lexical Relations, An Appli-cation: Software Libraries.
Proceedings of SI-GIR '89, pp.
127-136.Mel'6uk, I.
(1988) Dependency Syntax, SUNYPress.
Albany, New York.Moravcsik, J. M. (1975) Aita as Generative Fac-tor in Aristotle's Philosophy, Dialogue.National Library and hfforInation AssociationsCouncil (1980) Guidelines/'or Thesaurus Struc-ture, Construction, and Use, New York: Ameri-can National Standards Institute.Pustejovsky, James (1989a) Type Coercion andSelection, Proceedings of West Coast Conferenceon Formal Linguistics, Vancouver, 1989.Pustejovsky, James (1989b) The GenerativeLexicon.
ms. Brandeis University.Pustejovsky, James (forthcoming) The Genera-tire Lexicon: A Theory of Computational LeziealSemantics, MIT Press, Cambridge, MA.Pustejovsky, James and Peter Anick (1988) TheSemantic Interpretation of Nominals, COLING'88.Ravin, Yael (1990) "Heuristics for Disambiguat-ing and Interpreting Verb Definitions," Proceed-ings of 1990 ACL, Pittsburgh, PA.Thompson, R,H.
and W.B.
Croft (1989) "Sup-port for Browsing in an Intelligent Text RetrievalSystem," Internation Journal of Man-MachineStudies, 30:639-668.Touretzky, David S. (1986) The Mathematicsof Inheritance Systems, Morgan Kaufmann, LosAltos, CA.Vickery, B. C. (1975) Classification and Indexingin Science.
Butterworth and Co., Ltd. London,England.Wilks, Yorick (1975) An Intelligent Analyzerand Understander for English.
Comm ACM, 18,264-274.Wilks, Yorick A, Dan C. Fass, Cheng-Ming Guo,James E. McDonald, Tony Plate, and Brian M.Slator (1988) Machine Tractable Dictionaries asTools and Resources for Natural Language Pro-cessing.
Proceeding of COLING-88, Budapest,Hungary.Zernik, Uri (1989) Lexicon Acquisition: Learn-ing from Corpus by Exploiting Lexical Cate-gories.
Proceedings of IJCAI 89.12 6
