Coling 2008: Proceedings of the workshop on Multi-source Multilingual Information Extraction and Summarization, pages 49?56Manchester, August 2008Story tracking: linking similar news over time and across languagesBruno Pouliquen & Ralf SteinbergerEuropean CommissionJoint Research CentreVia E. Fermi 2749, 21027 Ispra, ItalyFirstname.Lastname@jrc.itOlivier DeguernelTemis S.A.Tour Gamma B, 193-197 rue de Bercy75582 Paris Cedex, FranceOlivier.Deguernel@temis.comAbstractThe Europe Media Monitor system(EMM) gathers and aggregates an aver-age of 50,000 newspaper articles per dayin over 40 languages.
To manage the in-formation overflow, it was decided togroup similar articles per day and perlanguage into clusters and to link dailyclusters over time into stories.
A storyautomatically comes into existence whenrelated groups of articles occur within a7-day window.
While cross-lingual linksacross 19 languages for individual newsclusters have been displayed since 2004as part of a freely accessible online appli-cation (http://press.jrc.it/NewsExplorer),the newest development is work on link-ing entire stories across languages.
Theevaluation of the monolingual aggrega-tion of historical clusters into stories andof the linking of stories across languagesyielded mostly satisfying results.1 IntroductionLarge amounts of information are publisheddaily on news web portals around the world.
Pre-senting the most important news on simple,newspaper-like pages is enough when the userwants to be informed about the latest news.However, such websites do not provide a long-term view on how any given story or event de-veloped over time.
Our objective is to provideusers with a fully automatic tool that groups in-dividual news articles every day into clusters ofrelated news and to aggregate the daily clustersinto stories, by linking them to the related ones?
2008.
Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license(http://creativecommons.org/licenses/by-nc-sa/3.0/).
Somerights reserved.identified in the previous weeks and months.
Inour jargon, stories are thus groups of articlestalking about a similar event or theme over time.We work with the daily clusters computed by theNewsExplorer application (Pouliquen et al2004).
For each daily cluster in currently nine-teen languages, the similarity to all clusters pro-duced during the previous seven days is com-puted and a link is established if the similarity isabove a certain threshold.
It is on the basis ofthese individual links that stories are built, i.e.longer chains of news clusters related over time.The current NewsExplorer application addition-ally identifies for all news clusters, whether thereare related clusters in the other languages.
Thesedaily cross-lingual links are used to link thelonger-lasting stories across languages.After a review of related work (Section  1 2),we will present the Europe Media Monitor(EMM) system and its NewsExplorer application(section  3).
We will then provide details on theprocess to build the multi-monolingual stories(Section  4) and on the more recent work on link-ing stories across languages (Section  5).
Sec-tion  6 presents evaluation results both for themonolingual story compilation and for the estab-lishment of cross-lingual links.
Section  7 con-cludes and points to future work.2 Related workThe presented work falls into the two fields ofTopic Detection and Tracking and cross-lingualdocument similarity calculation.2.1 Topic detection and tracking (TDT)TDT was promoted and meticulously defined bythe US-American DARPA programme (seeWayne 2000).
An example explaining the TDTconcept was that of the Oklahoma City bombingin 1995, where not only the bombing, but alsothe related memorial services, investigations,prosecution etc.
were supposed to be captured.49Human evaluators will often differ in their opin-ion whether a given document belongs to a topicor not, especially as ?topic?
can be definedbroadly (e.g.
the Iraq war and the following pe-riod of insurgence) or more specifically.
For in-stance, the capture and prosecution of SaddamHussein, individual roadside bombings and airstrikes, or the killing of Al Qaeda leader AbuMusab al-Zarqawi could either be seen as indi-vidual topics or as part of the Iraq war.
Thisfuzziness regarding what is a ?topic?
makes aformal evaluation rather difficult.
Our system ismore inclusive and will thus include all the men-tioned sub-events into one topic (story).
A sepa-rate clustering system was developed as part ofthe EMM-NewsBrief (http://press.jrc.it/NewsBrief/),which produces more short-lived and thus morespecific historical cluster links.2.2 Cross-lingual linking of documentsSince 2000, the TDT task was part of the TIDESprogramme (Translingual Information Detection,Extraction and Summarisation), which focusedon cross-lingual information access.
The goal ofTIDES was to enable English-speaking users toaccess, correlate and interpret multilingualsources of real-time information and to share theessence of this information with collaborators.The purpose of our own work includes the topicdetection and tracking as well as the cross-lingual aspect.
Main differences between ourown work and TIDES are that we need to moni-tor more languages, that we are interested in allcross-lingual links (as opposed to targeting onlyEnglish), and that we use different methods toestablish cross-lingual links (see Section 5).All TDT and TIDES participants used eitherMachine Translation (MT; e.g.
Leek et al 1999)or bilingual dictionaries (e.g.
Wactlar 1999) forthe cross-lingual tasks.
Performance was alwayslower for cross-lingual topic tracking (Wayne2000).
An interesting insight was formulated inthe ?native language hypothesis?
by Larkey et al(2004), which states that topic tracking worksbetter in the original language than in (ma-chine-)translated collections.
Various partici-pants stated that the usage of named entitieshelped (Wayne 2000).
Taking these insights intoaccount, we always work in the source languageand make intensive use of named entities.Outside TDT, an additional two approachesfor linking related documents across languageshave been proposed, both of which use bilingualvector space models: Landauer & Littman (1991)used bilingual Lexical Semantic Analysis and Vi-nokourov et al (2002) used Kernel CanonicalCorrelation Analysis.
These and the approachesusing MT or bilingual dictionaries have in com-mon that they require bilingual resources and arethus not easily scalable for many language pairs.For N languages, there are N*(N-1)/2 languagepairs (e.g.
for 20 languages, there are 190 lan-guage pairs and 380 language pair directions).Due to the multilinguality requirement in theEuropean Union (EU) context (there are 23 offi-cial EU languages as of 2007), Steinberger et al(2004) proposed to produce an interlingual docu-ment (or document cluster) representation basedon named entities (persons, organisations, disam-biguated locations), units of measurement, multi-lingual specialist taxonomies (e.g.
medicine),thesauri and other similar resources that may helpproduce a language-independent document repre-sentation.
Similarly to Steinberger et al (2004),the work described in the following sectionsequally goes beyond the language pair-specificapproach, but it does not make use of the wholerange of information types.In Pouliquen et al (2004), we showed howNewsExplorer links individual news clustersover time and across languages, but without ag-gregating the clusters into the more compact andhigh-level representations (which we call sto-ries).
This new level of abstraction was achievedby exploiting the monolingual and cross-lingualcluster links and by adding additional filteringheuristics to eliminate wrong story candidateclusters.
As a result, long-term developments cannow be visualised in timelines and users can ex-plore the development of events over long timeperiods (see Section  4.2).
Additionally, meta-information for each story can be compiledautomatically, including article and cluster statis-tics as well as lists of named entities associatedto a given story.2.3 Commercial applicationsCompared to commercial or other publicly accessi-ble news analysis and navigation applications, theone presented here is unique in that it is the onlyone offering automatic linking of news items re-lated either historically or across languages.
Thenews aggregators Google News(http://news.google.com) and Yahoo!
News(http://news.yahoo.com/), for instance, deliver dailynews in multiple languages, but do not link thefound articles over time or across languages.
Themonolingual English language applications Day-Life (http://www.daylife.com/), SiloBreaker(http://www.silobreaker.com/), and NewsVine50Figure 1.
Example of historical links betweenclusters: The graph shows the cosine similaritybetween today?s English language cluster (Finalhole being drilled ?)
and seven clusters identi-fied during five previous days.
Only clusters witha similarity above 0.5 will be retained.
(http://www.newsvine.com/) do not link related newsover time either.
NewsTin (http://www.newstin.com)is the only one to offer more languages (ten) and tocategorise news into a number of broad categories,but  they, again, do not link related news over timeor across languages.3 Europe Media Monitor (EMM) &NewsExplorerEMM has been gathering multilingual news arti-cles from many different web portals since 2002.It?s NewsBrief application has since displayedthe world?s most recent news items on its publicweb servers (http://emm.jrc.it/overview.html).Every day, and for each of 19 languages sepa-rately, EMM?s NewsExplorer application groupsrelated articles into clusters.
Clusters are com-puted using a group average agglomerative bot-tom-up clustering algorithm (similar to Schultz& Liberman 1999).
Each article is represented asa vector of keywords with the keywords beingthe words of the text (except stop words) andtheir weight being the log-likelihood value com-puted using word frequency lists based on sev-eral years of news.
We additionally enrich thevector space representation of each cluster withcountry information (see Pouliquen et al, 2004),based on log-likelihood-weighted, automaticallyrecognised and disambiguated location and coun-try names (see Pouliquen et al 2006).Each computed daily cluster consists of itskeywords (i.e.
the average log-likelihood weightfor each word) and the title of the cluster?s me-doid (i.e.
the article closest to the centroid of thecluster).
In addition we enrich the cluster withfeatures that will be used in further processes.These include the cluster size, lists of persons,organisations, geo-locations and subject domaincodes (see Section  5).When comparing two clusters in the same lan-guage, the keywords offer a good representation(especially when the keywords are enriched withthe country information).
Section  5 will showthat the additional ingredients are useful to com-pare two clusters in different languages.4 Building stories enriched with meta-informationFor each language separately and for each individ-ual cluster of the day, we compute the cosine simi-larity with all clusters of the past 7 days (see Fig-ure 1).
Similarity is based on the keywords associ-ated with each cluster.
If the similarity between thekeyword vectors of two clusters is above the em-pirically derived threshold of 0.5, clusters arelinked.
This optimised threshold was established byevaluating cluster linking in several languages (seePouliquen et al 2004).
A cluster can be linked toseveral previous clusters, and it can even be linkedto two different clusters of the same day.4.1 Building stories by linking clusters overtimeStories are composed of several clusters.
If a newcluster is similar to clusters that are part of astory, it is likely that this new cluster is a con-tinuation of the existing story.
For the purpose ofbuilding stories, individual and yet unlinked clus-ters of the previous seven days are treated like(single cluster) stories.
If clusters have not beenlinked to within seven days, they remain individ-ual clusters that are not part of a story.
Buildingstories out of clusters is done using the followingincremental algorithm (for a given day):for each cluster cfor each story sscore[s]=0;for each cluster cp (linked to c)if (s: story containing cp) thenscore[s] += (1-score[s])*sim(cp,s);endifendforendforif (s: story having the maximum score)thenadd c to story s (with sim score[s])else // not similar to any storycreate new story containing only cendifendfor51Lang Biggest title KeywordsEn US Airways won't pursue DeltaforeverUnited states / Doug Parker, Delta Airlines / airways, offer, emerge,grinstein, bid, regulatory, creditors, bankruptcy, atlanta, increasedIt Stop al massacro di balene.
Ilmondo contro il GiapponeAustralia, N. Zealand, Japan/ Greenpeace International, John Ho-ward/ caccia, megattere, balene, sydney, acqua, mesi, antartico, saltiEs Mayor operaci?n contra la por-nograf?a infantil en Internet en lahistoria de Espa?aGuardia Civil, Fernando Herrero Tejedor / pornograf?a, imputa-dos, mayor, cinco, delito, internet, registros, siete, inform?tica, sciDe Australian Open: "Tommynator"mit Gala-VorstellungRussia, Australia, United states / Australian Open, Mischa Zverev/ satz, tennis, deutschen, bozoljac, erstrunden, melbourne, kohl-schreiber, DonnerstagFr Il faut aider l'Afrique ?
se mon-dialiser, dit Jacques ChiracJacques Chirac, African Union / afrique, sommet, continent, pr?si-dent, cannes, darfour, ?tat, pays, conf?rence, chefs, omarTable 1.
Examples of stories, their biggest titles and their corresponding keywords.
Countries are dis-played in italic, person and organisation names in boldface.with sim(cp,s) being the similarity of the clusterto the story (the first cluster of a story gets a simof 1, the following depend on the score com-puted by the algorithm).When deciding whether a new cluster shouldbe part of an existing story, the challenge is tocombine the similarities of the new cluster witheach of the clusters in the story.
As storieschange over time and the purpose is to link thenewest events to existing stories, the new clusteris only compared to the story?s clusters of the last7 days.
A seven-day window is intuitive andautomatically takes care of fluctuations regardingthe number of articles during the week (week-ends are quieter).
In the algorithm to determinewhether the new cluster is linked to the story, thesimilarity score is computed incrementally: Thescore is the similarity of the new cluster with thelatest cluster of the story (typically yesterday?s)plus the similarity of the new cluster with thestory?s cluster of the day before multiplied with areducing factor (1-scorei-1), plus the similarity ofthe new cluster with the story?s cluster of yet an-other day before multiplied with a reducing fac-tor (1-scorei-2), etc.
The reducing factor helps tokeep the similarity score between the theoreticalvalues 0 (unrelated) and 1 (highly related):???<<??==?
)70(),()1()0(01 iscsimscoreiscoreiiiIf the final score is above the threshold of 0.5,the cluster gets linked to the existing story.Otherwise it remains unlinked.
The story buildingalgorithm is language-independent and could thusbe applied to all of the 19 NewsExplorer lan-guages.
Currently, it is run every day (insequential order) in the following nine languages:Dutch, English, French, German, Italian,Portuguese, Slovene, Spanish and Swedish.Out of the daily average of 970 new clusters(average computed for all nine languages over aperiod of one month), only 281 get linked to anexisting story (29%) and 90 contribute to a newstory (9%).
The remaining 599 clusters (62%)remain unlinked singleton clusters.
A small num-ber of stories are very big and go on over a longtime.
This reflects big media issues such as theIraq insurgence, the Iran-nuclear negotiationsand the Israel-Palestine conflict.
The latter is thecurrently longest story ever (seehttp://press.jrc.it/NewsExplorer/storyedition/en/RTERadio-5f47a76fe35215964cbab22dcbc88d7b.html).4.2 Aggregating and displaying informationabout each storyFor each story, daily updated information getsstored in the NewsExplorer knowledge base.This includes (a) the title of the first cluster ofthe story (i.e.
the title of the medoid article ofthat first cluster); (b) the title of the biggest clus-ter of the story (i.e.
the cluster with most arti-cles); (c) the most frequently mentioned personnames in the story (related people); (d) the per-son names most highly associated to the story(associated people, see below); (e) the most fre-quently mentioned other names in the story(mostly organisations, but also events such asOlympics, World War II, etc.
); (f) the countriesmost frequently referred to in the story (eitherdirectly with the country name or indirectly, e.g.by referring to a city in that country); (g) a list ofkeywords describing the story (see below).
Thismeta-information is exported every day intoXML files for display on NewsExplorer.
Thepublic web pages display up to 13 keywords, in-cluding up to three country names and up to twoperson or organisation names (see Table 1).
To52see examples of all meta-information types foreach story, see the NewsExplorer pages.Stories are currently accessible through threedifferent indexes (see Figure 2): the stories of theweek, the stories of the month and the biggeststories (all displayed on the main page ofNewsExplorer).
The biggest stories are orderedby the number of clusters they contain withoutany consideration of the beginning date or theend date.
The stories of the month present storiesthat started within the last 30 days, stories of theweek those that started within the last sevendays.For each story, a time line graph (a flash ap-plication taking an XML export as input) is pro-duced automatically, allowing users to see trendsand to navigate and explore the story (Figure 3).While a story can have more than one cluster ona given day, the graph only displays the largestcluster for that day.The story?s keyword signature is computed us-ing the keywords appearing in most of the con-stituent clusters.
If any of the keywords repre-sents a country, it will be displayed first.
A filter-ing function eliminates keywords that are part ofone of the selected entities.
For instance, if a se-lected entity is George W. Bush and a selectedcountry is Iraq, the keywords Bush, George,Iraqi, etc.
will not be displayed.Figure 2.
Examples of English language stories, as on the NewsExplorer main page (2.04.
2008).As mentioned in the previous paragraph, astory?s related entities are those that have beenmentioned most frequently.
This typically in-cludes many media VIPs.
Associated entities arenames that appear in this particular story, but arenot so frequently mentioned in news clusters out-side this story, according to the following,TF.IDF-like formula:?
?=SciiecfreSrelated ),(),()),(log(1()1)),(min(log(),(),( eSCefrecfreSass Scii +?=?
?with fr(e) being the number of clusters the entityappears in (in a collection of three years of news)and C(S,e) being the number of clusters in thestory S mentioning the entity.
Inversely, theNewsExplorer person and organisation pagesalso display, for each entity, the biggest storiesthey are involved in.Figure 3.
Sample of a short story timeline.
Whenmousing over the graph, title, date and clustersize for that day are displayed.
A simple click al-lows to jump to the relevant cluster, enabling us-ers to explore the story.
Available on pagehttp://press.jrc.it/NewsExplorer/storyedition/en/guardian-ee9f870100be631c0147646d29222de9.html.5 Cross-lingual cluster and story linkingFor each daily cluster in nine NewsExplorer lan-guages, the similarity to clusters in the other 18languages is computed.
To achieve this, we pro-duce three different language-independent vectorrepresentations for each cluster (for details, seePouliquen et al 2004): a weighted list of Euro-voc subject domain descriptors (eurov, availableonly for EU languages), a frequency list of per-son and organisation names (ent), and a weightedlist of direct or indirect references to countries(geo).
As a fourth ingredient, we also make useof language-dependent keyword lists becauseeven monolingual keywords sometimes match53across languages due to cognate words (cog), etc.(e.g.
tsunami, airlines, Tibet etc.).
The overallsimilarity clsim for two clusters c?
and c??
in dif-ferent languages is calculated using a linearcombination of the four cosine similarities, usingthe values for ????
&,, as 0.4, 0.3, 0.2 and0.1, respectively (see Figure 4):),(.),(.),(.),(),(cccogccentccgeocceurovccclsim???+???+???+????=??????
?5.1 Filtering and refining cross-lingual clus-ter linksThe process described in the previous paragraphsproduces some unwanted cross-lingual links.
Wealso observed that not all cross-lingual links aretransitive although they should be.
We thus de-veloped an additional filtering and link weightingalgorithm to improve matters, whose basic ideais the following: When clusters are linked inmore than two languages, our assumption is: Ifcluster A is linked to cluster B and cluster C,then cluster B should also be linked to cluster C.We furthermore assume that if cluster B is notlinked to cluster C, then cluster B is less likely tobe linked to cluster A.
The new algorithm thuschecks these ?inter-links?
and calculates a newsimilarity value which combines the standardsimilarity (described in 5.0) with the number ofinter-links.
The formula punishes links to an iso-lated cluster (i.e.
links to a target language clus-ter which itself is not linked to other linked lan-guages) and raises the score for inter-linked clus-ters (i.e.
links to a target language cluster whichitself is linked to other linked languages).
Thenew similarity score uses the formula:)()().,(),(CElCClCCclsimCCmclsi ?????=???
?with Cl(C) being the number of computed cross-lingual links and El(C) being the number of ex-pected cross-links (i.e.
all cross-language linksobserved when looking at all languages).
For in-stance, if a cluster is linked to three languagesand these are linked to a further three, thenCl(C?
)=3 and El(C?
)=6.Figure 4.
Example of the similarity calculationfor an English and a French cluster.
The overallsimilarity for these two clusters, based on the lin-ear combination of four  different vectors, is 0.46.5.2 Linking whole stories across languagesThe stories contain clusters which are themselveslinked to clusters in other languages (see 5.1).This information can be used to compute thesimilarity between two whole stories in differentlanguages.
The formula is quite simple:?????????????=??
?ScScjijiccmclsiSSSclsim,),(),(with S' and S'' being two stories in different lan-guages, and c' and c'' being constituent clusters.Cross-lingual cluster similarity values are onlyadded if they are above the threshold of 0.15.Table 2 shows an English story and its links inseven languages.As the evaluation results in Section 6 show, thisformula produces reasonable results, but it hassome limitations.
Firstly, it relies exclusively onLang.Biggest titleNb.
ofclustersNb.
ofarticlesCommonclustersSimi-larityEn Rescuers injured at mine collapse 17 200 --- ---Pt EUA: mineiros presos numa mina continuam incontact?veis 12 63 7 2.1363Es Colapsa mina en EE.UU.
5 24 3 0.9138De USA: Sechs Bergleute eingeschlossen 3 28 2 0.7672Nl Mijnwerkers vast na aardbeving in Utah 2 7 2 0.6082Fr Le sauvetage de mineurs dans l'Utah tourne au drame 3 16 2 0.5541Nl Reddingswerkers omgekomen in mijn Utah 2 12 2 0.4644Sv Mystisk "ub?t" unders?ks i New York 4 16 2 0.3681Table 2.
Example of cross-lingual links between the English language US mine collapse story and storiesin seven other languages.
The Swedish story, which has the lowest similarity score, is actually unrelated.54daily cross-lingual links, whereas stories are notnecessarily reported on the same day across lan-guages.
Secondly, we might be able to producebetter results by making use of the availablemeta-information at story level described in Sec-tion 4.2.
We are thus planning to refine this for-mula in future work.Type of storyNumber ofstoriesNbofcorrectcross-linguallinksNumber ofcross-linguallinksPrecisionAll stories 112 275 465 0.59Stories containing atleast 5 clusters39 145 232 0.62Stories containing atleast 10 clusters11 75 100 0.7510 top stories in 4languages40 235 270 0.87Table 4.
Evaluation of cross-lingual story linking.6 EvaluationEvaluating such a system is not straightforwardas there is a lot of room for  interpretation re-garding the relatedness of clusters and stories.Cluster consistency evaluation and the monolin-gual and cross-lingual linking of individual clus-ters using a very similar approach has alreadybeen evaluated in Pouliquen et al (2004).In order to evaluate the precision for the storybuilding in four languages, we have evaluatedthe relatedness of the individual components (theclusters) with the story itself.
We compiled a listof 330 randomly selected stories (in the 4 lan-guages English, German, Italian and Spanish)and asked an expert to judge if each of the clus-ters is linked to the main story.
For each story,we thus have a ratio of 'correctly linked' clusters(see Table 3).
The average ratio corresponds tothe precision of the story tracking system.
Thereclearly is room for improvement, but we found theresults good enough to display the automaticallyidentified stories as part of the live application.We did make an attempt at evaluating also therecall for story building, but soon found out thatthe results would not make sense.
The idea wasto carry out a usage-oriented evaluation for thesituation in which users are looking for any storyof their choice using their own search words (e.g.Oscar and nomination, Pavarotti and death,etc.).
It was found that relevant stories did indeedexist for almost every query.
However, the re-sults would entirely depend on the type of storythe evaluator is looking for and on the evalua-tor?s capacity to identify significant searchwords.
We can thus not present results for the re-call evaluation of the story tracking system.The purpose of a second test was to evaluatethe accuracy of the cross-lingual story linking.For that purpose, we evaluated those 112 multi-lingual stories out of the 330 stories in the previ-ous experiment that had cross-lingual links toany of the languages Dutch, English, French,German, Italian, Portuguese, Spanish or Swedish.Table 4 shows that only 59% of the automati-cally established cross-lingual story links wereaccurate, but that the situation improves whenlooking at stories consisting of more clusters, i.e.5 or 10.
This trend was confirmed by a separatestudy evaluating only the cross-lingual links forthe 10 largest stories in the same four languages,into the same eight other languages: 87% of thecross-lingual links were correct.
Note that ?
forthese large stories ?
the cross-lingual links were96.5% complete (270 out of 280 possible linkswere present).
Further insights from this evalua-tion are that there are only two out of the 40 topstories that should be merged (there are two Eng-lish top stories on Israel) and that there is onecluster in each of the four languages whichshould be split (all China-related news mergesinto one story).
It is clear that more experimentsare needed to improve the cross-lingual links forsmaller stories.
We have not evaluated the recallof the cross-lingual story linking as recall evalua-tion is very time-consuming and we first want tooptimise the algorithm.7 Conclusion and Future WorkLan-guageNumberof storiesCorrect com-ponentsAll com-ponentsPrecisionGerman 93 249 265 0.94English 113 490 570 0.86Spanish 33 78 91 0.86Italian 91 239 299 0.80All  330 1056 1225 0.86Table 3.
Evaluation of the monolingual linkingof clusters into stories for four languages.The story tracking system has been running fortwo years.
There is definitely space for improve-ment as unrelated clusters are sometimes part ofa story, but informal positive user feedbackmakes us believe that users already find the cur-rent results useful.
An analysis of the web logsshows that more than 400 separate visitors perday look at story-related information, split quiteevenly across the different languages (Table 5).55The story tracking algorithm is rather sensi-tive to the starting date for the process: Differentstarting dates may result in different stories andcertain starting dates may result in having twoseparate parallel stories talking about veryclosely related subjects.
Another issue is theseven-day window: We may want to extend thewindow as it happens occasionally that a story?dies?
because no related articles are publishedon the subject for a week, and that another storytalking about the same subject starts 8 days later.Finally, our algorithm should try to cope with thefact that stories can split or merge (an issue notcurrently dealt with), but this is a non-trivial issue.Regarding the cross-lingual linking, the currentresults are encouraging, but not sufficient.
The ac-curacy needs to be improved before the results cango online.
The most promising idea here is tomake use of each story?s meta-information (listsof related persons, organisations, countries andkeywords at story level) and to allow a time de-lay in the publication of stories across languages.However, the application has high potential, as itwill provide users with (graphically visualisable)information on how the media report eventsacross languages and countries.In a separate effort, a ?live?
news clusteringsystem has been developed within EMM, whichgroups the news as they come in during the day(see http://press.jrc.it/NewsBrief/).
This processneeds to be integrated with the daily and morelong-term story tracking process so that users canexplore the history and the background for cur-rent events.AcknowledgementsWe thank the Web Mining and Intelligence teamand our team leader Erik van der Goot for the valu-able news data and the robust web sites.
A specialthanks to Jenya Belyaeva for her evaluation.ReferencesLandauer Thomas & Michael Littman (1991).
A Sta-tistical Method for Language-Independent Repre-sentation of the Topical Content of Text Segments.Proceedings of the 11th International Conference?Expert Systems and Their Applications?, vol.
8:pp.
77-85.Larkey Leah, Fangfang Feng, Margaret Connell, Vic-tor Lavrenko (2004).
Language-specific Models inMultilingual Topic Tracking.
Proceedings of the27th annual international ACM SIGIR conferenceon Research and development in information re-trieval, pp.
402-409.Leek Tim, Hubert Jin, Sreenivasa Sista & RichardSchwartz (1999).
The BBN Crosslingual Topic De-tection and Tracking System.
In 1999 TDT Evalua-tion System Summary Papers.Pouliquen Bruno, Ralf Steinberger, Camelia Ignat,Emilia K?sper & Irina Temnikova (2004).
Multi-lingual and cross-lingual news topic tracking.
In:Proceedings of the 20th International Conference onComputational Linguistics, Vol.
II, pp.
959-965.Pouliquen Bruno, Marco Kimler, Ralf Steinber-ger,  Camelia Ignat, Tamara Oellinger, Ken Black-ler, Flavio Fuart, Wajdi Zaghouani, Anna Widiger,Ann-Charlotte Forslund & Clive Best (2006).
Geo-coding multilingual texts: Recognition, Disam-biguation and Visualisation.
Proceedings of the 5thInternational Conference on Language Resourcesand Evaluation (LREC'2006), pp.
53-58.Schultz J. Michael & Mark Liberman (1999).
Topicdetection and Tracking using idf-weighted CosineCoefficient.
DARPA Broadcast News WorkshopProceedings.Steinberger Ralf, Bruno Pouliquen & Camelia Ignat(2004).
Providing cross-lingual information accesswith knowledge-poor methods.
In: Andrej Brodnik,Matja?
Gams & Ian Munro (eds.
): Informatica.
Aninternational Journal of Computing and Informat-ics.
Vol.
28-4, pp.
415-423.
Special Issue 'Informa-tion Society in 2004'.Lang Hits PctHits/day VisitsVisits/day PctDe  59993 14% 2143 1611 58 13%En  164557 38% 5877 2273 81 19%Es  49360 11% 1763 1431 51 12%Fr  56023 13% 2001 1514 54 12%It  29445 7% 1052 1425 51 12%Nl  25175 6% 899 1242 44 10%Pt  42933 10% 1533 2170 78 18%Sv  7284 2% 260 575 21 5%Total: 434770  15527 12241 437Table 5.
Number of connections to story-relatedNewsExplorer web pages only, and distributionper language (period 1-28/06/2008).
Only visitsfrom different IP addresses were counted.Vinokourov Alexei, John Shawe-Taylor, Nello Cristi-anini (2002).
Inferring a semantic representation oftext via cross-language correlation analysis.
Ad-vances of Neural Information Processing Systems 15.Wactlar Howard (1999).
New Directions in Video In-formation Extraction and Summarization.
Proceed-ings of the 10th DELOS Workshop.Wayne Charles (2000).
Multilingual topic detectionand tracking: Successful research enabled by cor-pora and evaluation.
Proceedings of 2nd Interna-tional Conference on Language Resources andEvaluation.56
