Multi-Agent Explanation Strategies in Real-Time DomainsKumiko Tanaka-IshiiUniversity of Tokyo,7-3-1 Hongo Bunkyo-kuTokyo 113-8656Japankumiko@ipl.t.u-tokyo.ac.jpIan FrankElectrotechnical Laboratory1-1-4 Umezono, TsukubaIbaraki 305-0085Japanianf@etl.go.jpAbstractWe examine the benets of using multi-ple agents to produce explanations.
Inparticular, we identify the ability to con-struct prior plans as a key issue con-straining the eectiveness of a single-agent approach.
We describe an imple-mented system that uses multiple agentsto tackle a problem for which prior plan-ning is particularly impractical: real-time soccer commentary.
Our commen-tary system demonstrates a number ofthe advantages of decomposing an expla-nation task among several agents.
Mostnotably, it shows how individual agentscan benet from following dierent dis-course strategies.
Further, it illustratesthat discourse issues such as controllinginterruption, abbreviation, and main-taining consistency can also be decom-posed: rather than considering them atthe single level of one linear explana-tion they can also be tackled separatelywithin each individual agent.
We evalu-ate our system's output, and show thatit closely compares to the speaking pat-terns of a human commentary team.1 IntroductionThis paper deals with the issue of high-level vslow-level explanation strategies.
How should anexplanation nd a balance between describing theoverall, high-level properties of the discourse sub-ject, and the low-level, procedural details?
In par-ticular, we look at the di?culties presented by do-mains that change in real-time.
For such domains,the balance between reacting to the domain eventsas they occur and maintaining the overall, high-level consistency is critical.We argue that it is benecial to decompose theoverall explanation task so that it is carried out bymore than one agent.
This allows a single agentto deal with the tracking of the low-level develop-ments in the domain, leaving the others to con-centrate on the high-level picture.
The task ofeach individual agent is simplied, since they onlyhave to maintain consistency for a single discoursestrategy.
Further, discourse issues such as control-ling interruption, abbreviation, and maintainingconsistency can also be decomposed: rather thanconsidering them at the single level of one linearexplanation they can be tackled separately withineach individual agent and then also at the level ofinter-agent cooperation.We look at real-world examples of explanationtasks that are carried out by multiple agents, andalso give a more detailed protocol analysis of oneof these examples: World Cup soccer commen-tary by TV announcers.
We then describe anactual implementation of an explanation systemthat produces multi-agent commentary in real-time for a game of simulated soccer.
In this sys-tem, each of the agents selects their discourse con-tent on the basis of importance scores attached toevents in the domain.
The interaction betweenthe agents is controlled to maximise the impor-tance score of the uttered comments.Although our work focuses on real-time do-mains such as soccer, our discussion in x2 putsour contribution in a wider context and iden-ties a number of the general benets of usingmultiple agents for explanation tasks.
We chosethe game of soccer for our research primarily be-cause it is a multi-agent game in which variousevents happen simultaneously on the eld.
Thus,it is an excellent domain to study real-time con-tent selection among many heterogeneous facts.A second reason for choosing soccer is that de-tailed, high-quality logs of simulated soccer gamesare available on a real-time basis from SoccerServer, the o?cial soccer simulation system forthe `RoboCup' Robotic Soccer World Cup initia-tive (Kitano et al, 1997).Ease of making prior plansdifficult possible easysportscommentarymindgamescommentarycarnavigationsystemspaneldiscussionlivelecturelecture(TV)  businesspresentationFigure 1: Common explanation tasks categorised according to the ease of planning them in advance2 Explanation StrategiesIn this paper, we use the term explanation in itsbroadest possible sense, covering the entire spec-trum from planned lectures to commentating onsports events.
Any such explanation task is af-fected by many considerations, including the levelof knowledge assumed of the listeners and theavailable explanation time.
However, the issue wemainly concentrate on here has not previously re-ceived signicant attention: the benets of split-ting an explanation task between multiple agents.2.1 Explanations and Multi-AgencyThe general task of producing explanations withmultiple agents has not been studied in depthin the literature.
Even for the `naturally' multi-agent task of soccer commentary, the systems de-scribed in the recent AI Magazine special issue onRoboCup (Andre et al, 2000) are all single-agent.However, one general issue that has been studiedat the level of single agents is the trade-o be-tween low-level and high-level explanations.
Forexample, in tutoring systems (Cawsey, 1991) hasdescribed a system that handles real-time interac-tions with a user by separating the control of thecontent planning and dialogue planning.We believe that the key issue constraining theuse of high-level and low-level explanations in adiscourse is the ability to construct prior plans .For example, researchers in the eld of discourseanalysis, (e.g., (Sinclair and Coulthard, 1975))have found that relatively formal types of di-alogues follow a regular hierarchical structure.When it is possible to nd these kinds of a prioriplans for a discourse to follow, approaches such asthose cited above for tutoring are very eective.However, if prior plans are hard to specify, a sin-gle agent may simply nd it becomes overloaded.Typically there will be two conicting goals: dealwith and explain each individual (unplanned) do-main event as it occurs, or build up and explaina more abstract picture that conveys the overallnature of the explanation topic.Thus, for any changing domain in which it ishard to plan the overall discourse, it can be bene-cial to divide the explanation task between mul-tiple agents.
Especially for real-time domains, theprimary benet of decomposing the explanationtask in this way is that it allows each agent touse a dierent discourse strategy to explain dif-ferent aspects of the domain (typically, high-levelor low-level).
However, we can see from Figure 1that even some activities that are highly plannedare sometimes carried out by multiple agents.
Forexample, business presentations are often carriedout by a team of people, each of which is an expertin some particular area.
Clearly, there are otherbenets that come from decomposing the explana-tion task between more than one agent.
We cangive a partial list of these here: Agents may start with dierent abilities.
Forexample, in a panel session, one panellist maybe an expert on Etruscan vases, while anothermay be an expert on Byzantian art. It can take time to observe high-level pat-terns in a domain, and to explain them co-herently.
Having a dedicated agent for com-menting on the low-level changes increasesthe chance that higher-level agents have achance to carry out analysis. A team of agents can converse together.In particular, they can make explanationsto each other instead of directly explainingthings to the listeners.
This can be a morecomfortable psychological position for the lis-tener to accept new information. The simple label of \expert" adds weight tothe words of a speaker, as shown convincinglyby the research of (Reeves and Nass, 1996).The use of multiple agents actually gives achance to describe individual agents as \ex-perts" on specic topics. Even a single agent speaking in isolationcould describe itself as an expert on varioustopics.
However, (Reeves and Nass, 1996)also show that self-praise has far less impactthan the same praise from another source.Rather than describing themselves as experts,a multi-agent framework allows agents to de-scribe the other agents as experts.To illustrate the dierent roles that can betaken by multiple agents in an explanation task,we carried out a simple protocol analysis of an ex-ample from the far left of our scale of Figure 1:soccer commentary.2.2 Soccer Protocol AnalysisWe analysed the video of the NHK coverage of therst half 1998 World Cup nal.
This commentarywas carried out by a team of two people who wecall the `announcer' and the `expert'.
The guresin Table 1 demonstrate that there are clear dier-ences between the roles assumed by this commen-tary team.
Although both use some backgroundknowledge to ll out their portions of the commen-tary, the announcer mostly comments on low-levelevents, whilst the expert mostly gives higher-level,state-based information.
Further, we can see thatthe announcer asked questions of the expert witha high frequency.Overall, there is a clear indication that oneagent follows the low-level events and that theother follows the high-level nature of the game.Accordingly, their discourse strategies are also dif-ferent: the announcer tends to speak in shorterphrases, whereas the expert produces longer anal-yses of any given subject.
The commentary teamcollaborates so that the consistency between high-level, low-level, and background comments is bal-anced within the content spoken by each individ-ual, and also within the overall commentary.2.3 A First ImplementationAs a rst step towards a multi-agent explanationsystem based on the above observations, the fol-lowing sections describe how we implemented acommentary system for a game of simulated soc-cer.
Our experience with this system reectedthe discussion above in that we found it was verydi?cult to consistently manage all the possiblediscourse topics within a single-agent framework.When changing to a multi-agent system, however,we found that a small number of simple rules forinter-agent interaction produced a far more man-ageable system.
We also found that the systemwas behaviourally very similar to the protocol ofTable 1.3 An Architecture For Multi-Agent Soccer CommentaryFigure 2 shows the basic architecture of our soc-cer commentator system.
As we mentioned in theIntroduction, this system is designed to producelive commentary for games played on RoboCup'sSoccer Server.
Since the Soccer Server was orig-inally designed as a testbed for multi-agent sys-tems (Noda et al, 1998), we call our commenta-tor Mike (\Multi-agent Interactions Knowledge-ably Explained").
Typically, Mike is used to addatmosphere to games played in the RoboCup tour-naments, so we assume that the people listeningto Mike can also see the game being described.AnalyserAnnouncerSoccer ServerVoronoiStatisticsBasicTTSsharedmemorycommentaryCommunicatorFigure 2: Mike | a multi-agent commentatorThe Soccer Server provides a real-time game logof a very high quality, sending information on thepositions of the players and the ball to a moni-toring program every 100msec.
Specically, thisinformation consists of 1) player location and ori-entation, 2) ball location, and 3) game score andplay modes (throw ins, goal kicks, etc).This information is placed in Mike's sharedmemory, where it is processed by a number of`Soccer Analyser' modules that analyse higher-level features of a game.
These features includestatistics on player positions, and also `bigrams' ofball play chains represented as rst order Markovchains.
The Voronoi analyser uses Voronoi dia-grams to assess game features such as defensive ar-eas.
Note that we do not consider the Soccer Anal-ysers to be `agents'; they are simply processes thatmanipulate the information in the shared mem-ory.
The only true `agents' in the system are theAnnouncer and the Analyser, which communicateboth with each other and with the audience.All information in Mike's shared memory isrepresented in the form of commentary fragmentsthat we call propositions.
Each proposition con-sists of a tag and some attributes.
For example,a pass from player No.5 to No.11 is representedas (Pass 5 11), where Pass is the tag, and theCommentary Feature Announcer Expert NoteBackground comment(e.g., on stadium, or team backgrounds)7% 20% (predened plan)Event-based comment 82% 3% (low-level)State-based comment 11% 77% (high-level)Average length of comment 1.3sec 3.8sec (consistency)Asks a question to the other 30 0 (new explanation mode)Interrupts the other 5 0 (priority of roles)Announcer describes expert as expert 0 n/a (adds weight to expert)Table 1: Protocol analysis of announcer and expert utterances in professional TV coverage of soccerLocal GlobalE Kick ChangeFormv Passe Dribble SideChangen ShootPredicttS Mark TeamPassSuccessRatet PlayerPassSuccessRate AveragePassDistancea ProblematicPlayer Scoret PlayerActive TimeeTable 2: Examples of Mike's proposition tagsnumbers 5 and 11 are the attributes.
Mike usesaround 80 dierent tags categorised in two ways:as being local or global and as being state-basedor event-based.
Table 2 shows some examples ofcategorised proposition tags.The operation of the Announcer and the Anal-yser agents is described in detail in the followingsection.
Basically, they select propositions fromthe shared memory (based on their `importancescores') and process them with inference rules toproduce higher-level chains of explanations.
Thediscourse control techniques of interruption, rep-etition, abbreviation, and silence are used to con-trol both the dialogue strategies of each individualagent and also the interaction between them.To produce variety in the commentary, eachpossible proposition is associated with several pos-sible commentary templates (output can be in En-glish or Japanese).
Figure 3 shows the overallrepertoire of Mike's comments.
The actual spo-ken commentary is realised with o-the-shelf text-to-speech software (Fujitsu's Japanese Synthesiserfor Japanese, and DecTalk for English).4 Multi-Agent NL GenerationIn this section, we describe how Mike uses impor-tance scores, real-time inferencing, and discoursecontrol strategies to implement | and control theinteraction between | agents with diering expla- Explanation of complex events.
Forma-tion and position changes, advanced plays. Evaluation of team plays.
Average forma-tions, formations at a certain moment, play-ers' locations, indication of active or prob-lematic players, winning passwork patterns,wasteful movements. Suggestions for improving play.
Loosedefence areas, better locations for inactiveplayers. Predictions.
Passes, game results, shots. Set pieces.
Goal kicks, throw ins, kick os,corner kicks, free kicks. Passwork.
Tracking of basic passing play.Figure 3: Mike's repertoire of statementsnation strategies.To form a single coherent commentary withmultiple agents we extended the single-agentframework of (Tanaka-Ishii et al, 1998).
The ba-sic principle of this framework is that given a setof scores that capture the information transmit-ted by making any utterance, the most eectivedialogue is the one that maximises the total scoreof all the propositions that are verbalised.
Wetherefore created two agents with dierent strate-gies for content scheduling.
One agent acts as anannouncer, following the low-level events on theeld.
This agent's strategy is biased to allow fre-quent topic change and although it uses inferencerules to look for connections between propositionsin the shared memory, it only uses short chains ofinference.
On the other hand, the second agentacts as an `expert analyst', and is predominantlystate based.
The expert's strategy is biased tohave more consistency, and to apply longer chainsof inference rules than the announcer.4.1 Importance ScoresIn Mike, importance scores are designed to cap-ture the amount of information that any givenproposition will transmit to an audience.
They arenot xed values, but are computed from scratch atevery game step (100msec).
The importance scoreof each proposition depends on three factors: 1)the elapsed time since the proposition was gener-ated, 2) for event-based propositions, a compar-ison of the place associated with the propositionand the current location of the ball, and 3) thefrequency that the proposition has already beenstated.
To keep the number of comments in theshared memory to a manageable number they aresimply limited in number, with the oldest entriesbeing removed as new propositions are added.4.2 Real Time InferenceMike's commentary propositions are the resultsof large amounts of real-time data processing,but are typically low-level.
A commentary basedsolely on these propositions would be rather de-tailed and disconnected.
Thus, to analyse theplay more deeply, Mike gives the commentaryagents access to a set of forward-chaining rulesthat describe the possible relationships betweenthe propositions.
In total, there are 145 of theserules, divided into the two classes of logical con-sequences and second order relations.
We give arepresentative example from each class here: Logical consequence:(PassSuccessRate player percentage)(PassPattern player Goal) !
(active player) Second order relation:(PassSuccessRate player percentage)(PlayerOnVoronoiLine player) !
(Reason @1 @2)The basic premise of the announcer's dialoguestrategy is to follow the play by repeatedly choos-ing the proposition with the highest importancescore.
Before stating this proposition, however,the announcer checks any applicable inferencerules in a top down manner, in an attempt toproduce higher-level commentary fragments andbackground related information.
In contrast tothis, the expert agent has a library of themes (e.g.,pass statistics, formation, stamina) between whichit chooses based on the propositions selected bythe announcer so far.
It then uses inference rulesto try to construct a series of high-level inferencesrelated to the theme.
The expert applies rulesuntil it succeeds in constructing a single coherentpiece of structured commentary.
When it is theagent's turn to speak it can then send this com-mentary to the TTS software.4.3 Discourse Control StrategiesConsider a passage of commentary where the an-nouncer is speaking and a proposition with amuch larger importance score than the one be-ing uttered appears in the shared memory.
If thisoccurs, the total importance score may becomelarger if the announcer immediately interrupts thecurrent utterance and switches to the new one.As an example, the left of Figure 4 shows (solidline) the change of the importance score with timewhen an interruption takes place (the dotted linerepresents the importance score without interrup-tion).
The left part of the solid line is lower thanthe dotted, because we assume that the rst utter-ance conveys less of its importance score when itis not completely uttered.
However, the right partof the solid line is higher than the dotted line, be-cause the importance of the second utterance willbe lower by the time it is uttered without inter-rupting the commentary.
Note that after selectinga proposition to be uttered, its importance scoreis assumed to decrease with time (as indicated inthe gure, the decrease is computed dynamicallyand will be dierent for each proposition, and of-ten not even linear).
The decision of whether ornot to interrupt is based on a comparison of thearea between the solid or dotted lines and the hor-izontal axis.Similarly, it may happen that when the twomost important propositions in shared memoryImportance Score/TimeEnds thefirst utterrancewithout interruptionAn Importantevent occurswith interruptionwithout interruptiontime<>?Importance Score/TimeBut can utter otherimportant contentwith abbreviationwithout abbreviationtime<>?Becomes less comprehensivebecause of abbreviationFigure 4: Change of importance score on inter-ruption and abbreviationImportance Score/TimeAnother utterrancewith repetitionwithout repetitiontime<>?Repeated utterrance have higherscore by emphasisFigure 5: Increase in importance scores caused byemphasis of repeating a propositionare of similar importance, the amount of com-municated information can best be maximised byquickly uttering the most important propositionand then moving on to the second before it losesimportance due to some development of the gamesituation.
This is illustrated in the second graphof Figure 4.
Here, the left hand side of the solidline is lower than that of the dotted because anabbreviated utterance (which might not be gram-matically correct, or whose context might not befully given) transmits less information than a morecomplete utterance.
But since the second propo-sition can be uttered before losing its importancescore, the right hand part of the solid line is higherthan that of the dotted.
As before, the benets orotherwise of this modication should be decidedby comparing the two areas made by the solid andthe dotted line with the horizontal axis.We originally designed these techniques just toimprove the ability of the announcer agent tofollow the play.
With two commentary agents,however, both interruption and abbreviation canbe adapted to control inter-agent switching.
InMike, the default operation is for the announcerto keep talking while the ball is in the nal thirdof the eld, or while there are important proposi-tions to utter.
When the announcer has nothingto say, the expert agent can speak or both agentscan remain silent.
If the expert agent chooses tospeak, it may happen that an important eventon the eld makes the announcer wants to speakagain.
We model both interruption and abbre-viation as multi-agent versions of the graphs ofFigure 4: the agent speaking the rst utterance isthe expert and the agent speaking the second isthe announcer.We use two further discourse control techniquesin Mike: repetition and silence.
Repetition isdepicted in Figure 5.
Sometimes it can happenthat the remaining un-uttered propositions in theshared memory have much smaller scores thanany of those that have already been selected.
Inthis case, we allow individual agents to repeatthings that they have previously said.
Also, weallow them to repeat things that the other agenthas said, to increase the eectiveness of the dia-logue between them.
Finally, we also model si-lence by adding bonuses to the importance scoresof the propositions uttered by the commentators.Specically, we add a bonus to the scores of propo-sitions uttered directly before a period where bothcommentators are silent (the longer that a com-mentary continues uninterrupted, the higher thesilence bonus).
This models the benet of givinglisteners time to actually digest the commentary.Also, a period of silence contributes a bonus tothe importance scores of the immediately follow-ing propositions.
This models the increased em-phasis of pausing before an important statement.4.3.1 Communication TemplatesTo improve the smoothness of the transfer of thecommentary between the two agents we devised asmall number of simple communication templates.The phrases contained in these templates are spo-ken by the agents wheneverMike realises that thecommentary is switching between them.
For thepurposes of keeping the two agents distinct, theexpert agent is referred to by the announcer as E-Mike (\Expert Mike").
To pass the commentaryto the Expert, the Announcer can use a numberof phrases such as \E-Mike, over to you", \Anyimpressions, E-Mike?
", or just \E-Mike?".
Theannouncer can also pass over control by simplystopping speaking.
If the commentary switchesfrom Announcer to Expert with a question, theExpert will start with \Yes..." or \Well...".The communication templates for passing thecommentary in the other direction (Expert to An-nouncer) are shown in Table 3.
To help listenersdistinguish the dialogue between the Announcerand Expert better, we also use a female voice forone agent and a male voice for the other.5 EvaluationMike is robust enough for us to have used itto produce live commentary at RoboCup events,and to be distributed on the Internet (it has beendownloaded by groups in Australia and Hungaryand used for public demonstrations).
A short ex-ample of Mike's output is shown in Figure 6.To evaluate Mike more rigorously we carriedout two questionnaire-based evaluations, and alsoa log comparison with the data produced from thereal-world soccer commentary in x2.
For the rstof the questionnaire evaluations, we used as sub-Question Scale ResultsIs the game better with or without commentary?
(5=with, 1=without) 4.97Was the commentary easy to understand?
(5=easy, 1=hard) 3.44Were the commentary contents accurate?
(5=correct, 1=incorrect) 3.25Was the commentary informative?
(5=yes, 1=no) 3.53Did you get tired of the commentary?
(5=no, 1=quickly) 3.97Table 4: Average responses of 20 subjects to rst questionnaire evaluation of (two-agent) MikeQuestion Scale 1-agent 2-agent DiIs the game better with or without...?
(5=with, 1=without) 4.45 4.45 0%Was the commentary easy to understand?
(5=easy, 1=hard) 2.95 3.25 +10%Were the commentary contents accurate?
(5=correct, 1=incorrect) 2.65 2.95 +11%Was the commentary informative?
(5=yes, 1=no) 3.15 3.35 +6%Did you get tired of the commentary?
(5=no, 1=quickly) 2.35 3.35 +43%Table 5: Dierence in response with ten subjects when viewing 1-agent and 2-agent versions of MikeAnnouncer interrupts expertSorry, E-MIKE.Have to stop you there E-MIKE.Oh!...But look at this!Announcer speaks when expert stopsThanks.That's very true.Thanks E-MIKE.Maybe that will change as the game goes on.OK...Table 3: Phrases used by announcer when inter-rupting the expert, or when speaking after the ex-pert agent has simply stopped (no interruption)jects twenty of the attendees of a recent RoboCupSpring camp.
All these subjects were familiar withthe RoboCup domain and the Soccer Server en-vironment.
We showed them an entire half of aRoboCup game commentated by Mike and col-lated their responses to the questions shown inTable 4.
These results largely show that the lis-teners found the commentary to be useful and tocontain enough information to maintain their at-tention.
We also included some open-ended ques-tions on the questionnaire to elicit suggestionsfor features that should be strengthened or incor-porated in future versions of Mike.
The mostfrequent responses here were requests for morebackground information on previous games playedby the teams (possible in RoboCup, but to datewe have only done this thoroughly for individ-Announcer: yellow 9,in the middle of theeld,yellow team (a set play happened here).
Anyimpressions, E-Mike?Analyser: Well, here are statistics concerningpossessions, left team has slightly smaller value ofpossession, it is 43 percent versus 56. right teamhas rather higher value of territorial advantage,Overall, right team is ahead there.
(Score is cur-rently 0-0.
E-Mikejudges that red team is doingbetter).Announcer: Really.
dribble , yellow 3, on theleft, great long pass made to yellow 1, for red 6,red 2's pass success rate is 100 percent.
E-Mike?Analyser: Looking at the dribbles and steals, redteam was a little less successful in dribbling, redteam has a lower value of dribble average length,left is 21 meters whereas right is 11, right teamhas a few less players making zero passes, yellowteam has made slightly less stealing,Announcer: wow (interruption because red 11made a shot), red 11, goal, red 11, Goal !
It wasred 10, And a pass for red 11 !
The score is 0 1!Figure 6: Example of Mike's commentary fromRoboCup'98 nalual games), more conversation between the agents(we plan to improve this with more communica-tion templates), and more emotion in the voices ofthe commentators (we have not yet tackled suchsurface-level NLG issues).
We also asked what theideal number of commentators for a game wouldbe; almost all subjects replied 2, with just tworeplying 3 and one replying 1.The above results are encouraging for Mike,but to show that the use of multiple agents wasactually one of the reasons for the favourable audi-ence impression, we carried out a further test.
WeCommentary feature Announcer Expert NoteBackground comment 16% 22% (predened plan)Event-based comment 64% 0% (low-level)State-based comment 20% 78% (high-level)Average length of comment 1.1sec 2.9sec (consistency)Asks a question to the other 12.2 0 (new explanation mode)Interrupts the other 8.6 0 (priority of roles)Announcer describes expert as expert 0 n/a (adds weight to expert)Table 6: Breakdown of Mike's agent utterances over ten randomly selected RoboCup half-gamescreated a single-agent version of Mike by switch-ing o the male/female voices in the TTS soft-ware and disabling the communication templates.This single-agent commentator comments on al-most exactly the same game content as the multi-agent version, but with a single voice.
We re-cruited ten volunteers with no prior knowledge ofRoboCup and showed them both the single-agentand multi-agent versions of Mike commentatingthe same game as used in the previous experiment.We split the subjects into two groups so that onegroup watched the multi-agent version rst, andthe other watched the single-agent version rst.Table 5 shows that the average questionnaire re-sponses over the two groups were lower than withthe subjects who were familiar with RoboCup, butthat the multi-agent version was more highly eval-uated than the single-agent version.
Thus, eventhe supercially small modication of removingthe agent dialogue has a measurable eect on thecommentary.Finally, we analysed Mike's commentary us-ing the same criteria as our protocol analysis ofhuman soccer commentary in x2.2.
We selectedten half-games at random from the 1998 RoboCupand compiled statistics on Mike's output with anautomatic script.
The results of this analysis (Ta-ble 6) show a marked similarity to those of thehuman commentators.
This initial result is a veryencouraging sign for further work in this area.6 ConclusionsWe have argued for superiority of producingexplanations with multiple, rather than single,agents.
In particular, we identied the di?culty ofproducing prior plans as the key issue constrain-ing the ability of a single agent to switch betweenhigh-level and low-level discourse strategies.As a rst step towards a multi-agent explana-tion system with solid theoretical underpinnings,we described the explanation strategies used byour live soccer commentary system, Mike.
Weshowed how a set of importance scores and infer-ence rules can be used as the basis for agents withdierent discourse strategies, and how the dis-course control techniques of interruption, abbrevi-ation, repetition and silence can be used not justto moderate the discourse of an individual agent,but also the interaction between agents.
We eval-uated Mike's output through listener surveys,showing that it represents an advance over exist-ing commentary programs, which are all single-agent.
We also found that the discourse strategiesof Mike's agents closely resembled those revealedby the protocol analysis of a team of real-life soc-cer commentators.ReferencesE.
Andre, K. Binsted, K. Tanaka-Ishii, S. Luke,G.
Herzog, and T. Rist.
2000.
Three RoboCupsimulation league commentator systems.
AIMagazine, 21(1):57{66, Spring.A.J.
Cawsey.
1991.
Generating intreractive expla-nations.
In Proceedings of the Ninth NationalConference on Articial Intelligence (AAAI-91), pages 86{91.H.
Kitano, M. Asada, Y. Kuniyoshi, I. Noda,E.
Osawa, and H. Matsubara.
1997.
RoboCup:A challenge problem for AI.
AI Magazine,pages 73{85, Spring.I.
Noda, H. Matsubara, K. Hiraki, and I. Frank.1998.
Soccer Server: a tool for research onmulti-agent systems.
Applied Articial Intelli-gence, 12(2{3):233{251.B.
Reeves and C. Nass.
1996.
The Media Equa-tion.
CSLI Publications.J.
Sinclair and R. Coulthard.
1975.
Towardsan Analysis of Discourse: The English Used byTeachers and Pupils.
Oxford University Press.K.
Tanaka-Ishii, K. Hasida, and I. Noda.
1998.Reactive content selection in the generation ofreal-time soccer commentary.
In Proceedings ofCOLING-ACL'98, pages 1282{1288, Montreal.
