Efficiency Considerations for LFG-Parsers - Incrementaland Table-Lookup TechniquesAbstractIstv?n B?tori and Stefan MarokFB 2 Linguistics EWH Rheinland-Pfalz,  l~heinun 3-4,D-5400 Koblenz~ FRGThe paper presents a concise description of the LFG-Parser-Generator developed at the EWH in Koblenz.
Special attentionis paid to efficiency considerations to speed up the system in theexecution phase.
Lexicon is separated, ll(k)-parsing tables are usedand some preliminary ratifications are carried out before the actualexecution.
The run time system follows the single path strategyand produce.
'; the f-structures simultaneously with the processingof the c-stru~:tures.1 Genera l  Cons iderat ions  of  Pars ing Effi-c iencyBasic parsing techniques (both shift reduce and recursive descent)seem to be inherently inefficient inasmuch as they proceed strictlyaccording to the sequence of the rules in the grammar and theyare not able to exploit the surrounding (preceeding and following)syntactic information.
Their scope is limited to a single rule andthey jump mechanically to the sequentially next rule, even if sucha move is obviously abortive and must be innmdiately abandoned(Winograd 1'483, 108-115; Phillips 1984; Hellwig 1988).Parsing tables - as they are conceived in current compiler con-struction devices for LR(k) and LL(k) languages - make 1. theizfformation provided by the grammar accessible throughout theentire processing and not just at the point where they happen tooccur, and 2. tlmy can be constructed algorittnnically (Aho/Ullman1979).I I Generator I,1 ti i --Figure 1: The LFG-System in Koblenz2 The  LFG-Mode l  of  the  EWH:  Genera lDesignThe Koblenzer LFG-Parser-Generator is an interactive system, de-signed to create and to test grammars for natural anguages ac-cording to the linguistic philosophy of the LFG as conceived inBresnan und Kaplan (1982).
Both lexicon and syntax follow clo-sely the original format specifications.
The system can be dividedinto two main phases: preprocessing and actual execotion).1.
Prepro~:essing of the input gralmnar (including lexicon) ge-nerates the executable code, which in turn involves two lo-gically distinct steps:?
Generating the P~OLOG code and?
Optimizing the PP~OLOG code, - and2.
the actual execution phase analyses the input string andproduces the f-structures.2.1 Code-Generat ionIn the preprocessing phase the grammar rules are entered into thesystem and translated into an executable PB,OLOG Code.
Thispart of the system is written in PASCAL.
The implementationincludes facilities for the treatment of the metavariables ~ andneeded for the treatment of the long distance dependencies (Weis-weber 1986).
The grammar may contain both optional categoriesand multiply reoccurring categories (marked by the Kleene-star.-operator).In order to facilitate the generation of the tables with the reachrelations the phrase-structure portion of the rules of the gran~nar(c-structure rules) is extracted and stored as azl additional, sepa-rate data set.2.2 Code  Opt imizat ionThe second task of the preprocessor is to produce a more efficientPKOLOG code.
Optimization covers construction ofparsing tableand code revision.In order to speed up the actual analysis in the execution phasethe preprocessor constructs a table of reach relations on the basis offirst and follow sets, connecting nontermlnal nd preterminal nodeswith a lookahead of 1.The definition of the first and follow sets is based on context freegrammar (Aho/Ullman (1979, 186-192,429-30)):G = (N, r~,7,,S)~,jO, E (N E ~,)* and ..4 F_ 31".The first sets are defined for a non terminal symbol A overa string c~ of preterminals as the potential preterminal symbolswhich can occur in the leftmost position of the string:F~IRST(a) = {a E Y, I c~==~afl}u {el ,~=~e}The follow sets of a nonterminal A are defined as the first setsof the preterminals which may occur after the nonterminal A:FOLLOW(A)  := {a E $ I S=~aA~ A a E FIRST(f l )}u {$1 S:~A*}.25Contrary to the standard efinition of the terms (op.
cit.)
theKoblenzer system does not exclude the application to left recursiveconstructions.
The reach relations are build up uniformly both forleft recursive and for all other constructions.The first and follow sets allow to define the reach relations, whichprovide the information for a nonterminals A (in the stack) andfor a preterminal symbol (located in the input string a) by whichproduction rule(s) the preterminal can be accessed:REACH(A,a ,P )~3P67 > wi th  P = A ~ ~ :a 6 FIRST(~) ^  ~(a = ~)Va 6 FOLLOW(A) ^  a =~eThe reach relations are valid for all context free languages andextend the applicability of LL(1)-tables for them in general.
Theyare calculeted over the first and follow sets and stored in tables forthe execution phase.
The practical construction of the table ofreach relations i  based on the systematic separation ofdictionaryand grammar rules, without which the construction of the tablewould not be feasible.There are a number of grammatically predefined f-descriptions,which caa be preprocessed in advance independently of the actualinput, reducing the number of unifications at run time.
Prelimi-nary unification of f-structures can be carried out in the followingconfigurations:?
If an f-description subsumes another f-description, the subsumedf-structure can be regarded as already unified and dropped.In the execution phase the system will Use only the subsu-ming (i.e.
larger) f-description.
E.g.
if a dictionary entryin the PROLOG code, produced in the preprocessing phase,has the specifications as (TSUBJ NUM) = SO, and simulta-neously: !
(TSUBJ), the later can be safely dropped in orderto avoid the vacuous ratification of the explicit subject in theexecution phase.?
I f  an f-description is unified with new attributes, hitherto not usedin the grammar, the operation will always ucceed, regardlessof the actual value of the attributes.
Unifications of thistype can be carried out safely in advance regardless of laterpossible changes of the attribute value.?
There are further minor possible f-structure configurationswhich can be simplified before the actual unification in theexecution phase.
The current optimization will recognizeI Monitorhelp facilitiespretty printertraces e tc .\[ Lexicon lookup \]TConstructing 1reach relationstableLL(l)-Parserincrementalconstruction off-structuresI OJpn- - - - - - - *  I'"' Unification of'I ~- - - - J  f-structures I~tstralni~g Iions and I - - - - - - - - - -~teness Test s~Figure 2: The run time system26some of these special cases and replace the general unifi-cation procedures by specialized and hence more restrictedprocedures already at the time of code generation.
The ge-neral broad unification procedures (merge functions) will besubstituted here by more specific and computationally lessexpensive procedures.3 The Run Time SystemFirstly, the run time system can be characterized by the basic sepa-ration of lexicon lookup and actual parsing, The separation of lexiconrules and syntactic rules is based on the linguistic insight thatthe two components (lexicon and grammar) eflect entirely diffe-rent language properties.
The division can be supported also byconsideration f processing efficiency.The lexicon lookup is carried out at the beginning of the pro-cessing and it immediately allows the rejection of input in case ofmissing entries in the lexicon.
The user can enter another wordon the spot and proceed with the processing of the same sentence.The next step is the inspection of the LL(1) tables by means ofwhich the reach relations are established, The table of reach relationsprovides the optimal subset of grammatical symbols and connectsthem to the lexlcal entries occurring in the actual input sentence.Secondly, the run time system is characterized by the single-pass strategy of processing, i.e.
the input is read in only once,merging two fundamental tasks of the LFG: 1. the constructingof the c-structures and 2. the unification of the f-structures in asingle step.A special treatment is necessary for the left recursive construc-tions.
The entries in the LL(1)-table for potential left recursionsmay be used only as long as the repetion isnot spurious, otherwisetheir further application is suspended.
At the time of the proces-sing of phrase structure rules, the associated functional descriptionis processed immediately.
At this point the nodes relevant o thefunctional assignments are easily accessible as the left hand sidesymbol (for the metavariable T) and the right hand side symbols(for the metavariables ~}in the rules.As the input is processed the f-structure is constructed step bystep incrementally.
A l l  available attributes and values are mergedtogether as soon as they emerge, which is efficient for at least woreasons: 1.
There is no need to store and reprocess the cumulatedf-equations in an additional step and 2. merging the f-descriptionsincrementally step by step operates with smaller chunks, whichimplies faster unification.The incremental processing means that at the end of the inputsentence the analysis is complete and solved and does not need tobe scanned again in order to solve a series of f-equations.
Thereis only one single control operation at the end of the sentencechecking the wellformedness (completeness and exhaustiveness) ofthe output.The single-pass model differs therefore from the Kaplan-Bresnan-model by lacking a separate processing phase for the cumnlatedf-structures following tile generation ofc-structures.
In fact thereis no explicit need for retaining the c-structures, except for theirpossible display in tutorials and in tracing errenous production,while testing the rules of the input grammar,The current implementation delivers both the c-structure aswell as the f-structure of the input sentence.
In case of multi-ple interpretations all c-structures and all valid f-structures aredisplayed in succession.4 Adequacy  and  E f f i c iency  o f  GrammarsLFG-Grammars have been mostly studied from the point of viewof linguistic adequacy, i.e.
they have been developed in order tocover substantial spects of natural language syntax phenomena.The parser should help the working linguist to find the optimalgrammar for a particular language, to test the individual rules ofthe grammar as well as the general formalism.Parsing efficiency can be studied at least at three differentlevels:1. in view of the efficiency of developing grammars (concernsthe work of the linguist).2. in view o~ optimizing processing of the input grammar (con-cerus the preproce~sing phase)3. in view of optimizing the processing of the input sentence"(concerml the execution phase and the run time system)The present study is concerned mostl~ with the third type ofefficiency i.e.
~lith improving parsing efficiency, presupposing lin-guistic adequm:y of the model.
Pructical efficiency of standard par-sing technique~ depends on the amount of back tracking and repro-cessing needed in cases of errenous analysis.
While using standardrecursive desct:nt parsing techniques guarantees the comprehen-sive coverage of the whole language, it does not exploit availableinformation in an optimal manner.
Parsing tables with REACHrelations entail more information than single phrase structure ru-les, they acctmtulate information on the distribution of symbols inthe whole grannnar and enable the parser to build up the correctc-structure at the first attempt.
If for some reason o valid struc-ture is produced, ordinary back tracking applies and the inputstring is reprocessed.In the final version of the paper further details of current im-provements will be reported.5 Litera~ure usedAho, Alfred V. and Ullman, Jeffrey D. (1979) Principles ofCompiler Design.
Reading, Massachusetts et al, Addison-Wesley Publishing Company.Bresnan,  Joan (1982) (ed.)
The mental representation f gram-maticalrelations.
Cambridge, Massachusetts, The MIT Press.Hellwig, Peter  (in print) Parsing natiirlicher Sprachen: Grund-lagen und Reallsiertmgen.
In: BAtori, I., Lenders, W. audPutschke, W. (eds): Computational Linguistics - An inter-national Handbook on Computer Oriented Language Kese-arch and Applications.
Berlin, Walter de GruyterK indermann,  J6rg and Meier,  Justus  (1986)AnextensionofLR-Paraing for Lexical-Fauctional Grammar.
Universit~itBielefeht, FakultKt LiLi, Forschungsschwerpunkt 8prach- undTextveracbeitun.
(To be published in: Reyle, U.
(ed.
): WordOrder and Parsing in Unification Grammars).Phi l l ips,  Brhm (1984) An object-oriented parser.
In: Bara, BrunoG.
and Guida, Giovanni (eds.)
Computational Models ofNaturM Language Processing.
Amsterdam et al North-Holland, 297-321.Tomlta~ Masaru  (1987) An Efficient Augmented-Context-FreeParsing Algoritlnn.
CL 13:31-46.Wejsweber~ Wi lhe lm (1986) Ein Parsergenerator fti die lexicalfunctioned grammar (LFG).
EWH Rheinland-Pfalz - Abtei-lung Kol,lenz - Fachberichte Informatik 4/86.Winograd,  ~l~rry (1983) Language as a Cognitive Process - Syn-tax.
Reading, Massachusetts et al, Addison-Wesley Pnblis-hing Cmapany.27
