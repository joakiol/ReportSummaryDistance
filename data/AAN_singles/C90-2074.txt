Morphological Analysis and Synthesis byAutomated Discovery and Acquisition ofLinguistic RulesByoung- Tak ZHANG 1 and Yung- Taek KIMDepar tment  of Computer  Engineer ingSeoul National UniversitySeoul 151742, South KoreaAbst rac t':\[his paper describes a rule-based machine learn-ing approach to morphological processing in thesystem called XMAS.
XMAS discovers and ac-quires linguistic rules from examples of morpho-logical combinations and accomplishes the mor-phological analysis and synthesis by applyingthe rules.
This approach is independent of lan-guages, saves time and effort for developmentand maintenance, and takes small lexicon space.A Korean version of XMAS is effectively work-ing in the English-Korean machine translationsystem KSHALT.1 In t roduct ionFrom the knowledge ngineering perspective inartificial intelligence, a natural language process-Jng (NLP) system can be seen as a knowledge-based system in which major concerns are thediscovery, acqlfisition and maintenance of knowl-edge or rules \[2\].The main purpose of this paper is to presenta method for facilitating the development andmaintenance of NLP systems by automating thediscovery and acquisition of linguistic rules inthe domain of morphology.
This method wasimplemented in a morphological processor calledXMAS as a part of the English-Korean machinetranslation project KSHALT \[4\].In Section 2, we give an overview of the XMASsystem.
Section 3 illustrates the representationalformalism.
In Section 4, the processes of discov-ery and acquisition of morphological rules aredescribed.
In Section 5, the procedures for mor-phologicM analysis and synthesis are briefly de-scribed and the application results are reported.Section 6 concludes this paper by comparingXMAS with other related works and by remark-ing on further work.2 An  Overv iew o f  XMASXMAS (Xpert in Morphological Analysis andSynthesis) is a learning system \[12,13,14\] whichconsists of a learning element (Meta-XMAS), aknowledge base (KB), and two inference nginesof a morphological nalyzer (MOA) and a mor-phological synthesizer (MOS).
Figure 1 shows anoverview of XMAS and its operational environ-ment (parser and generator of natural anguagesystems).I I I ~OA ~d~--~ r~.~ IcritiqueInductive Deductive NL SystemLearning Solving (e.g.
MT system)Figure 1: The overview of XMAS1Present address: Artificial Intelligence Division, Institute for Computer Science,and Computational Linguistics Division, Institute for Communication Research and Phonetics (IKP),University of Bonn, D-5300, Bonn 1, West Germany, E-mail: ZHANG@DBNINF5.BITNET.i 431The knowledge base contains a lexicon anda rule base.
The lexicon has entries only forword stems.
The rule base contains the mor-phological rules which are learned from trainingexamples.
TEACHER, a human trainer, tracesthe execution of XMAS and provides trainingexamples and critiques for Meta-XMAS.
Meta-XMAS, a machine learner, acquires linguisticknowledge by discovering, formulating, general-izing and specializing rammatical rules.
MOAsolves the morphological analysis problems byapplying the rules.
MOS accomplishes the mor-phological synthesis by applying the rules.3 Description Languages3.1 Example  Descr ip t ion  LanguageThe rule discovery procedure is initiated bytraining examples.
Two kinds of training ex-amples are used: generalization examples andspecialization examples.
The generalization ex-amples are used to maintain the completenessof the rule base and the specializaition examplesare used to maintain the consistency of the rulebase \[3\].
A training example consists of a classname, two strings of before and after, and a cri-t ique-an optional tag, indicating if the exampleis a specialization example.
An instance of a gen-eralization example is (PLURAL "baby" "ba-bies").3.2 Rule  Descr ip t ion  LanguageThe formalism for the representation f morpho-logical rules is the string productions which aresimilar to if-then production rules \[14\].
A stringproduction is a self-contained operator whichconsists of a left-hand side (LHS) and a right-hand side (RHS).
It is symmetric and thereforeapplicable bidirectionally.<strlng-production> : := ( <LHS> ------* < I~HS> )<LHS> : := ( (  <feature>*  ) <pat tern>)< I tHS> : := ( <pattern> ( <feature>* ) )<feature> ::= <category:> \]<conjugation:> \[<prononciation> \[<accent> \[ .
.
.<pattern> : := ( < lw indow> <main> <rwiadow>)<category> : := NOUN \] VERB \[ ADJ  \[ ADV I " ' "The string production can accomodate notonly graphemic patterns but also syntactic andphonological features \[1\].
A string productioncan have name(s) which is useful for direct ac-cess and maintenance of the rules.For example, the following rule is a string pro-duction(((NOUN SG) ((b) (y) (%))) --~(((=) (i c s) (%))(NOUN BL)))where =y/ies% can be assigned to the name ofthe rule whose class name is PLURAL.4 Automated Learning ofMorphological Rules4.1 Learn ing  ProcedureThe procedure LEARNING (Figure 2) describesthe top-level algorithm for rule learning in Meta-XMAS.procedure L\]~ARNING(classname, before, after~ critique)features ~-- LEX ICON(before)(mop, rulename) *- D ISCOVER(before ,  ~fier)H 4-- FORMULATE(c I~ssname~ ration&me, featnre6~ mop)matchset 4~- MA'~CH(ru lename)if (matchset = {})then CREATE(H)  / /  a new rule H is generated / \ [elseK ~ I tESOLVE(matchset )  / /  ~elect one rule / /if positive(crltlque)then GENERAL IZE( I t ,H)  / /  It is general ized \]/else SPECIAL IZE( r t ,H)  / /  I t  is specialized \]/end LE AI'tNIN GFigure 2: The learning procedure ofMeta-XMASGiven a training example, Meta-XMAS searchesthe lexicon for the features of the word stembefore.
By comparing the before with after,a micro-operator (mop) and its name is con-structed (DISCOVER).
The mop is a descrip-tion of the transformation procedure from be-fore to after.
From these, a hypothetical ruleH is generated (FORMULATE).
Then it checksif other rules with the same name already exist(MATCH).
If yes, then the most special rule Ris selected (RESOLVE) and H and R are gen-eralized or specialized according to the critique(GENERALIZE or SPECIALIZE).
If no, thenthe rule H is appended to the present rule basewith the new rule name (CREATE).4.2 D iscovery  o f  Ru lesThe rule discovery procedure works as follows.First, the input strings before and after of thetraining example are compared and splitted byusing the four pointers--/b, rb, la and ra.
Thepointers Ib and la move one grapheme at a timefrom the left end to the right, while the pointersrb and ra move from the right end to the left,until lb and la (rb and ra, respectively) pointdifferent graphemes.432 2This results in dividing each string into thethree regions (lwindow, main and rwindow)which represent he left context, main string,and the right context, respectively.
The cor-responding contexts of both strings are gener-alized to '='  symbol which means remains un-changed.
The result is a micro-operator (mop).And then, a rule name is given to the mop bycreating a symbol representing the transforma-tion form.
For the training example(PLURAL "baby" "babies")the mop is((b) (y) (%)) --+ ((=) (i e s) (%))whose name is =y/ies%.Finally, a hypothetical rule for the given train-ing ex0anple is generated by integrating the classname, the rule name, the features, and the mop.In our example, the following rule is generated(in a simplified form):=y/ies%: (PLURAL (NOUN) ((b) (y) (%)) -~((=) (i e s) (%)))4.:~ Acquis i t ion of  RulesThe acquisition process of rules is the iteration ofthe creation of new rules and the modification ofexisting rules.
Modification is carried out by gen-eralization on the one hand and specialization onthe other hand.
Meta-XMAS uses the four kindsof induction rules in generalization \[10\]:1.
Variablization of constant: replace agrapheme by =.2.
Dropping AND conditions: decrement thecontextual window size.3.
Adding OR conditions: 1talon the twographeme sets.4.
Climbing generalization trees: climb thepath to the root of the tree.A concept is represented asa set of graphemesor features which can have an explicit name.
Thegeneralization tree \[11\] is a tree which describesthe generalization relations between the conceptsin the domain.
Figure 3 shows a generalizationtree for Korean graphemes.AnyGraphemeVowel space = Consonant*PVowel NVowel * Consonant~ \ ] -  r ~ _  I~ a T z .
a .
z ~ z ~ s ~ xFigure 3: A generalization tree for KoreangraphemesGeneralization using the tree is a process offollowing the path to the root on the basis oftraining examples.
This is useful in conceptlearning in a well-established domain.
In gen-eral, however, the generalization tree is not givena priori.
In this case the Meta-XMAS builds thetrees for itself (see Appendix A).
The two gener-alization strategies have their strengths and \]im-itations.
The first strategy needs more a priorilinguistic knowledge, but it is better in learn-ing efficiency.
The second strategy guarantees tofind detailed rules, but is less efficient in learningspeed.If Meta-XMAS applies only the generaliza-tion schemes, the rules learned can be over-generalized.
So at any point (e.g.
in case offalse output) the rules should be specialized toavoid the overgeneralization or to handle the ex-ceptions.
Meta-XMAS accomplishes this auto-matically with the aid of specialization exam-ples.
The specialization process is a kind ofrule creation procedure in which overgeneraliza-tion is checked and the overly generalized ruleis recovered--by going down the generalizationtree to the leaves or eliminating a grapheme froma concept, if necessary.5 Morpho log ica l  Ana lys i s  andSynthes isXMAS has two inference engines (or rule-interpreters) of MOA and MOS.
MOA, themorphological analyzer, solves the morpholog-ical analysis problms by applying the rules inthe RHS-driven forward chaining manner \[14\].MOS, the morphological synthesizer, solves themorphologicM synthesis problems by applying?
the rules in the LHS-driven forward chaining3 433manner  (see Appendix B).
More than one mor-phemes can be synthesized and analyzed by aninstruction.
If more than one rule is applicable inrule selection, then MOA/MOS selects the mostspecial rule.
So the rules in the rule base neednot be ordered, making the maintenance of therule base very easy.XMAS is implemented on a SUN workstationin a Common-LISP program.
A variety of exper-iments were carried out with XMAS on deriva~tional and inflectional phenomena in almost all ofthe Korean language and part of the English andthe German languages \[17\].
The results were suc-cessful in the sense that Meta-XMAS learns thegralnmatical rules and MOA/MOS solves cor-rectly the morphological nalysis and synthesisproblems by applying the rules.
Part of the ruleslearned by XMAS are shown in Appendix C. Amore efficient Korean version of XMAS, calledMASK \[19\], was applied to the generation ofKorean language in the English-Korean machinetranslation system KSHALT \[4\] and MASK iseffectively working now.improved by the capabilities (1), (2), (4)and (6).The advantage (8) comes especially from (6) and(7).
The property (9)is an indirect demonstra-tion of XMAS approach as a practical approach.As for all rule-based systems, XMAS is lessefficient in run time in comparison with proce-dural systems \[6\].
There is a way to improvethe run-time fficiency.
One can construct a rulecompiler as the transducer in KIMMO systems\[5,7\].But XMAS is better in effectiveness in devel-opment and maintenance.
In addition to therun-time efficiency, these factors should also beconsidered because, as was mentioned at the be-ginning, a natltral language processing systemis a complex knowledge-based system which reoquires a long period of design, implementation,test, debugging, and extention time.In addition to being a practical knowledge ac-quisition tool, Meta-XMAS in isolation can alsobe used as a linguists' tool for scientific discovery\[8\] which aids linguists in the discovery and testof grammatical rules in morphology.6 Related Work and Conclud-ing RemarksIn stunmary, XMAS, including Meta-XMAS asa linguistic knowledge acquisition tool, is char-acterized by the following capabilities and prop-erties:1. using graphemic, phonological, and syntac-tic information2.
analysis as well as synthesis3.
:language independent4.
capable of treating infix inflections as wellas prefix and suffix5.
simple and small lexicon6.
rules need not be orderd7.
automatic discovery and acquisition of lin-guistic knowledge by inductive machinelearning8.
easily maintainable9.
working in a machine translation system.The properties (2), (3), and (4) are the sameas in Kaplan et al \[5\], but XMAS has in ad-dition the properties (5)-(9).
XMAS shares theproperties (3) and (7) with Wothke \[15\], but isAcknowledgementsThis work was supported in part by IBM Ko-rea, Korea Science Foundation, and Departmentof Science and Technology of Korean Govern-ment.
We would like to thank Hyuck-CheolKwon, Young-Hoon Seo, Duck-Ho Yun, Kwang-Seob Shim, Seung-Sik Kang, Se-Jung Kim, andthe other members of the project KSI:\[ALT fortheir discussions and useful comments.
The firstauthor thanks also Prof. Dr. Winfried Lendersand Hooshang Mehrjerdian for careful readingand suggestions.References\[1\] Bear, J., A morphological recognizer withsyntactic and phonological rules, Proc.
ofCOLING-86, pp.
272-275, Bonn, 1986.\[2\] Hayes-Roth, F., Waterman, D.A., andLenat, D.B., Building Expert Systems,Addison-Wesley, 1983.\[3\] Jansen-Winkeln, t~.M., Induktives Lernenyon Granunatikregeln aus ausgewaehltenBeispielen, In: Savory, S.
(ed.
), KuenstlicheIntelligenz und Expertensysteme, pp.
211-223, Oldenbourg, 1985.434 4\[4\] Kang, S.S., Shim, K.S., Zhang, B.T.,Kwon, H.C., Woo, C.S.
and Kim, Y.T., AnEnglish-Korean system for hmnan-assistedlanguage translation, Proc.
of TENCON-87, IEEE, pp.
550-555, 1987.\[5\] Kaplan, R. and Karttunen, L., Computa-tional Morphology, CSLI Report No.
LI 283,Jlme 1987.\[6\] Kim, S.Y., Choi, K.S., and Kim, K.C., AKorean morphological nalyser using tab-ular parsing and connection information,Proc.
of 87 Spring Conf, on Arti.
Intell.,Korea Info.
Sci.
Soc., pp.
133-147, 1987, (inKorean).\[7\] Koskenniemi, K., Two-level model for mor-phological analysis, Proc.
of IJCAI-85, pp.683-685, 1985.\[8\] Langley, P., Zytkow, J.M., Bradshaw, G.L.,and Simon, H.A., Three facets of scientificdiscovery, Proc.
of IJCAI-83, pp.
465-468,1983.\[9\] Lenders, W. and Will4e, G., LinguistiseheDatenverarbeitung: Ein Lehrbueh, West-deutscher Verlag, 1986.\[10\] Michalski, R.S., A theory and methodologyof inductive l axning, in: Machine Learning,Michalski et al (eds.
), Tioga press, pp.
83-134, 1983.\[11\] Mitchell, T.M., Utgoff, P.E.
and Banerji,R., Learning by experimentation: acquiringand refining problem-solving heuristics, In:Machine Learning, Michalski et al (eds.
),Tioga press, pp.
163-190, 1983.\[12\] Smith, R.G., Mitchell, T.M., Chestek, R.A.,and Buchanan, B.G., A model for learningsystems, Proc.
of IJCAI-77, pp.
338-343,1977.\[13\] Veenker, G.
(ed.
), Automatisches Lernen,Arti.
Intell.
Seminar, Inst.
for Comp.
Sci.,Univ.
of Bonn, 1990.\[14\] Waterman, D.A.
and Hayes-Roth, F., Anoverview of pattern-directed inference sys-tems, In: Pattern-Directed Inference Sys-tems, Waterman, D.A.
and Hayes-Roth, F.(eds.
), Academic press, pp.
3-22, 1978.\[15\] Wothke, K., Machine learning of morpho-logical rules by generalization a d analogy,Proc.
of COLING-86, pp.
289-293, Bonn,1986.\[16\] Wothke, K., Maschinelle Erlernung und Si-.mulation morphologischer A bleitungsregeln,Dissertation, IKP, Univ.
of Bonn, 1985.\[17\] Zhang, B.T.
and Kim, Y.T., Macldne learn-ing of linguistic rules for multi\]ingual mor-phological analysis and synthesis, Journalof Korea Info.
Sci.
Soc., in press.\[18\] Zhang, B.T., Yoo, S.I, and Kim, Y.T.,XMAS: An expert in Morphological Analy-sis and Synthesis, Proc.
of '88 Spring Conf.on Arti.
Intell., Korea Info.
Sci.
Soc., pp.179-188, March 1988.\[19\] Zhang, B.T.
and Kim, Y.T., Morphologi-cal synthesis and analysis of Korean: a ma-chine learning approach, Proc.
of 87 Au-tomn Conf.
of Korea Info.
Sci.
Soc., pp.573-576, Sept. 1987.AppendixA LearningI ,F, AILNINCt\[IN$1ANCE\] "l'laini.ll cXamlde:\[I.F2(ICON~ lt).~c~ c, lry:( o,'?t ~i' (At)J))\[DISCOVEKER\] TrlRslMI~ Irairtln i inll~t~:((( ~)} ( , )  ((%))) -> ( ( ( t ) )  ~ ..- t ~)  ((%)j)\[FDI(MUIA'I'OR\] Focnllllaled gr~mmalic~d rule:Rh (PASTX (AIM) ((\[ i)) (") ((%))) -7.
((~} (* ,.
t " )  {%)))\[RII'MA'I'CIIER\[ Malched rule:Ni l .
(I'ASFX (Al)I (((I~) (" } ((%) .> ((,) (* , \[ a ) (%~)}\[IIUIJ~ flASH l Ctlrfedll fide b.~.~:RI: =,1~% (PARI'X (AIM) ( ( ( t ) )  (u )  ((%)}) .> ( (=)  ( .
.
.
.  )
u )  (%)))"lk~al ntlntb?
: of tlal=: Ia'i;;;;"~;;S",~;i~ .....................\] IN, rANCH\] Training c~l~e:II.F.XlCOI~I ItxiLxm entry:(~ (VI:I(I I))\[I)\]SCOVI~IIER\] 'l'r~i~lalcd Irainin~, instance:((( .-))  (") ((%))) -> ( ( ( .
*d ) I  ....
I ~) ((%)))\[1~$\] ( \ [  \[ .A  "O \] F~I1 l;llcd gramm~lliC~\] nile:It.~: (PAg lX  (Vii i , l it) (((.~1) ( " )  ~) ) )  .> ( ( : )  ( .
.. $ " ) (%)))\[RB-~.
A" 'C tE  ~\] Malch~l rule:{I 'ASI '~ (ADJ) ( ( ( t ) )  ( , )  ((%))) "> ( (~)  (0 ~ } " )  (%)))\[G N A >'.
| Grne al/~,tl rode:(I'A~I'X Vlilll Al)) ( ) " % ) "> " \[~ ' ") (%~d new in~tance (I)A$1'X (VEgI I )  (~...} .
%)) "> = ~ ?
~ %D\[ItUIJ~ BASE I Curre.nt nile har~:P,l': ,~, / I )% ( I 'A~rX (VEIt I!
AI)J} ( ( ( , .
i)) (~)  ((%))) .> i f - )  (o , .
~ ~)  (9~,)))~;iJJ~i~"i;J,-.~m'~ ......................IIN.
'~I'ANCHI 'l','aining ex~ple:ilJ?XICON\] I~xk~l entry:('.?
( V I-.IO1)))ISCf)V ?IIE (\[ ?
"ran.Jatcd ttaininx imt~mcc:fib, ) (") ((~'))) -> (((,') ~o ,, ~ ((%)))I :O~K U A''(') \] F inn  acd ?tamma cal rld~;R3: (I'ASI'X VI If{) (((~:) (w) ((%))) ,> ((:) (o "i I ~ ) (%)))IRII/~II{)*ICIIEI( Mmch=d role:IGFd~' /A  ZE L/ Created role:(I 'AS;rx (VEI~II) ((('I')) u ) ((%))) -> ( (e )  (.
"r I i ) {9~))}\[RUI.E BAS H (:lltlCnl r lllc h~-~;Total numl'<r of ml~: 25 435B Analysis and SynthesisSYI~'I"HESI.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.\[INSTANCE\] Synthesis problem:(VASq'X ,~-)\[LEXICON\] Lexicon entry:C~ (ADO.
)\[TRANSLATOR\] Translated problem in,lance:(PASTX(ADJ) (%* ~'~ ~.
%)-> ?
)\[MOS-MATCHER/Conflict set:((I'AS'IX (VERB ADJ) (((~ \],)) (u) ((%))) -> ((=) (o ~ } ~) (%))))\[ MOS- RESOLVER \] Select ed rule:(P~s-rx (VER~ ADO (((~- ~)) (.)
((%))) -> ((=) (?
-,.
~ ~) (%)))\[GENERATOR\] Synthesized output:*11~ + PASTX--> ~ql.~.~ANALYSIS.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.IlNSTANCE I Analysis problem:\[TRANSLATOR\] Translated instance:\[MOA-MATCHER|Conflivt set: (((PASTX (VERB ADJ) (((~ t)) ( .)
((%))) -> ((=) (o ~ t ~) (%))) (x II ?
~ .
)))\[MOA-~LVER1SSelected rule(s):(((PASTX (VERB ADJ) (.
(o at) ,ql~ ((ADJ)))) (((-,- ~)) ) ((%))) -> ((=) ~ t (%)))\[RECOGNIZER\] Analysis outpu,}:~1t%~--> -4t~((AI)J)) + I ASTXCC.1Part of rules learned by XMASEnglish Plural=/,,;% (PLURAL (N) (((o f y w p t n m thc  d k r a)) NIL ((%))) -> ((=) (s) (%))):=los% (PLURAl.
(N) (((o ch sh x z s)) NII.
((%))) -> ((=) (e s) (%)))=f/vcs% (PLURAL (N) (((a e 1)) (f) ((%))) -> ((=) (v e s) (%)))=fe/vcs% (PLURAL (N) (((i)) (f c) ((%))) -> ((=) (v e s) (%)))=y/its% (PLURAL (N) (((p d b t)) (y) ((%))) -> ((=) (i e s) (%)))=/x% (PLURAL (N) (((u)) NIL ((%))) -> ((=) (x) (%))):=on/a% (PLURAL (N) (((n)) (o n) ((%))) -> ((=) (a) (%)))=i/c= (PLURAL (N) (((s)) (i) ((s))) -> ((=) (e) (=))):=/e% (PLURAL (N) (((a)) NIL ((%))) -> ((=) (e) (%)))=us/i% (PLURAL (N) (((g 1 c)) (u s) ((%))) -> ((=) (i) (%)))=urn/a% (PLURAL (N) (((d t)) (u m) ((%))) -> ((=) (a) (%)))=/rcn% (PLURAL (N) (((d)) NIL ((%))) -> ((=) (r e n) (%)))=/on% (PLURAL (N) (((x)) NIL ((%))) -> ((=) (e n) (%))):=We= (PLURAL (N) (((m)) (a) ((n))) -> ((=) (e) (=)))=oNcc= (PLURAl.
(N) (((t g O) (o o) ((s t))) -> ((=) (c e) (=)))C.2 Past Tense of Korean== \]-'8/ )\]at % (PASTX (ADJ) ((( \]- .~.)
(~;' ~)) ( \]- "8) ((%))) -> ((= =) ( II at) (%)))==1.
% (PASTA (VERB) (((z 7)  (}*)) NIL ((%))) -> ((= =) () (%)))%=~-,-  I-'~ % (PASTX (VERB) (((%) (, o )) (~) ((%))) -> ((% =) (_,_ ~ .  )
(%)))==~/~oA% (PASTX (VERB) (((~) (~)) (~) ((%))) -> ((= =) (~ o ~ . )
(%)))==~/~ ~% (PASTX (VERB) frO' ~ ) ( "1 --)) (~) ((%))) -> (( :  =) (~ o -I * ) (%)))==/~.% (PASTX (VERB ADJ) (((~) (__)) Nm ((%))) -> ((: =) (~ q *) (%)))==_._J~% (PASq'X (VERB ADJ) (((_t_ \]-) (~.))
(_) ((%))) -> ((= =) (~ \]- . )
(%)))=:.__/~% (PASTX (VERB) (((_) (~) ) ( _ )  ((%))) -> ((= =) (~ ~ at ) (%)))==,  /~% (PASTX (VERB ADJ) (((~ Y ) ( \]- .,..))
( , )  ((%))) -> ((= =) (o ~ }.
at) (%)))- - -=.
/~% (PASTX (VERB ADJ) (((7 t. ~ o)  (-r- "I 4)) (u)  ((%))) -> ((= =) (o T "I ~)  (%)))==); /o~% (PASTX (VERB ADJ) (((x ~-) (}-)) ( z )  ((%))) -> ( ( -  =) (o }- ~ ) (%)))==x ;~o/o (PASTX (VERB) (((.
7 )  ('1" --)) (x)  ((%))) -> ((= =) (o -\] at) (%)))==/~% (PASTX (VERB) ((('8) (}-)) NIL ((%))) -> ((= =) ( o :\] at) (%)))%=-i-I "\]* % (PASTX (VERB) (((%) (~)) (T) ((%))) -> ((% =) ( { * ) (%)))%=__/ -\]at % (PASTX (VERB) (((%) Cat )) (--) ((%))) -> ((% =) ( q ~ ) (%)))==1~,% (PASTX (VERB ADJ) (((.x.
}-) (" z ~ :7 i~ 7 )) NIL ((%))) -> ((= =) (o I" '~) (%)))==/~% (PA~FX (VERB) ((( -\] \] -1-) (~ "?
~-)) NIL ((%))) -> ((= =) (o "l "~) (%)))4366
