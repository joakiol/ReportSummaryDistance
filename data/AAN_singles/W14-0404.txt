Felix Bildhauer & Roland Sch?fer (eds.
), Proceedings of the 9th Web as Corpus Workshop (WaC-9) @ EACL 2014, pages 22?28,Gothenburg, Sweden, April 26 2014. c?2014 Association for Computational LinguisticsSome issues on the normalization of a corpus of products reviews inPortugueseMagali S. DuranNILC-ICMCUniversity of S?o PauloBrazilmagali.duran@gmail.comLucas V. Avan?oNILC-ICMCUniversity of S?o PauloBrazilavanco89@gmail.comSandra M. Alu?sioNILC-ICMCUniversity of S?o PauloBrazilsandra@icmc.usp.brThiago A. S. PardoNILC-ICMCUniversity of S?o PauloBraziltaspardo@icmc.usp.brMaria G. V. NunesNILC-ICMCUniversity of S?o PauloBrazilgracan@icmc.usp.brAbstractThis paper describes the analysis of differentkinds of noises in a corpus of productsreviews in Brazilian Portuguese.
Casefolding, punctuation, spelling and the use ofinternet slang are the major kinds of noise weface.
After noting the effect of these noiseson the POS tagging task, we propose someprocedures to minimize them.1.
IntroductionCorpus normalization has become a commonchallenge for everyone interested in processing aweb corpus.
Some normalization tasks arelanguage and genre independent, like boilerplateremoval and deduplication of texts.
Others, likeorthographic errors correction and internet slanghandling, are not.Two approaches to web corpus normalizationhave been discussed in Web as a Corpus (WAC)literature.
One of them is to tackle the task as atranslation problem, being the web texts thesource language and the normalized texts thetarget language (Aw et al., 2006; Contractor etal., 2010; Schlippe et al., 2013).
Such approachrequires a parallel corpus of original andnormalized texts of reasonable size for training asystem with acceptable accuracy.
The otherapproach is to tackle the problem as a number ofsub problems to be solved in sequence(Ringlstetter et al., 2006; Bildhauer & Sch?fer,2013; Sch?fer et al., 2013).The discussion we engage herein adopts thesecond approach and is motivated by thedemand of preprocessing a Brazilian Portugueseweb corpus constituted of products reviews forthe specific purpose of building an opinionmining classifier and summarizer.
Our projectalso includes the task of adding a layer ofsemantic role labeling to the corpus.
The roleswill be assigned to nodes of the syntactic treesand, therefore, SRL subsumes the existence oflayers of morphosyntactic and syntacticannotations.
The annotated corpus will be usedas training corpus for a SRL classifier.
The aimof SRL classifier, on its turn, is to provide deepsemantic information that may be used asfeatures by the opinion miner.
If the text is notnormalized, the POS tagger does not performwell and compromise the parsing result, which,as consequence, may generate defective trees,compromising the assignment of role labels totheir nodes.In fact, mining opinions from a web corpus isa non-trivial NLP task which often requires somelanguage processing, such as POS tagging andparsing.
Most of taggers and parsers are made tohandle error-free texts; therefore they mayjeopardize the application results when they facemajor noises.
What constitutes a major noise andwhich noise may be removed or corrected insuch a corpus is the challenge we are facing inthis project.222.
Related WorkDepending on the point of view, there areseveral studies that face problems similar tothose faced by us.
The general issue is: how toconvert a non-standard text into a standard one?By non-standard text we mean a text producedby people that have low literacy level or byforeign language learners or by speech-to-textconverters, machine translators or even bydigitization process.
Also included in this classare the texts produced in special and informalenvironments such as the web.
Each one of thesenon-standard texts has its own characteristics.They may differ in what concerns spelling, non-canonical use of case, hyphen, apostrophe,punctuation, etc.
Such characteristics are seen as?noise?
by NLP tools trained in well written textsthat represent what is commonly known asstandard language.
Furthermore, with thewidespread use of web as corpus, other types ofnoise need to be eliminated, as for exampleduplication of texts and boilerplates.The procedures that aim to adapt texts torender them more similar to standard texts arecalled normalization.
Some normalizationprocedures like deduplication and boilerplateremoval are less likely to cause destruction ofrelevant material.
The problem arises when thenoise category contains some forms that areambiguous to other forms of the standardlanguage.
For example, the words ?Oi?
and?Claro?
are the names of two Brazilian mobilenetwork operators, but they are also commonwords (?oi?
= hi; ?claro?
= clear).
Cases likethese led Lita et al.
(2003) to consider casenormalization as a problem of word sensedisambiguation.
Proper nouns which are derivedfrom common nouns (hence, distinguished onlyby case) are one of the challenges for casenormalization reported by Manning et al.
(2008).Similar problem is reported by Bildhauer andSch?fer (2013) regarding dehyphenation, that is,the removal of hyphens used in typeset texts andcommonly found in digitized texts.
In German,there are many hyphenated words and thechallenge is to remove noisy hyphens withoutaffecting the correct ones.
There are situations,however, in which both the corrected and theoriginal text are desired.
For example, socialmedia corpora are plain of noises that expressemotions, a rich material for sentiment analysis.For these cases, the non-destructive strategyproposed by Bildhauer and Sch?fer (2013),keeping the corrected form as an additionalannotation layer, may be the best solution.3.
Corpus of Products ReviewsTo build the corpus of products reviews, wehave crawled  a products reviews database of oneof the most traditional online services in Brazil,called Buscap?, where customers post theircomments about several products.
The commentsare written in a free format within a templatewith three sections: Pros, Cons, and Opinion.
Wegathered 85,910 reviews, totaling 4,088,718tokens and 90,513 types.
After removing stopwords, numbers and punctuation, the frequencylist totaled 63,917 types.Customers have different levels of literacyand some reviews are very well written whereasothers present several types of errors.
In addition,some reviewers adopt a standard language style,whereas others incorporate features that aretypical of the internet informality, like abusiveuse of abbreviations, missing or inadequatepunctuation; a high percentage of named entities(many of which are misspelled); a highpercentage of foreign words; the use of internetslang; non-conventional use of uppercase;spelling errors and missing of diacritic signals.A previous work (Hartmann et al.
2014)investigated the nature and the distribution of the34,774 words of the corpus Buscap?
notrecognized by Unitex, a Brazilian Portugueselexicon (Muniz et.
al.
2005).
The words forwhich only the diacritic signals were missing(3,652 or 10.2%) have been automaticallycorrected.
Then, all the remaining words withmore than 2 occurrences (5775) were classifiedin a double-blind annotation task, which obtained0,752 of inter-annotator agreement (Kappastatistics, Carletta, 1996).
The results obtainedare shown in Table 1.Table 1.
Non-Recognized Words with morethan 2 occurrences in the corpusCommon Portuguese misspelled words 44%Acronyms 5%Proper Nouns 24%Abbreviations 2%Internet Slang 4%Foreign words used in Portuguese 8%Units of Measurement 0%Other problems  13%Total 100%23The study reported herein aims to investigatehow some of these problems occur in the corpusand to what extent they may affect POS tagging.Future improvements remain to be done in thespecific tools that individually tackle theseproblems.4.
MethodologyAs the same corpus is to be used for differentsubtasks ?
semantic role labeling, opiniondetection, classification and summarization ?
thechallenge is to normalize the corpus but alsokeep some original occurrences that may berelevant for such tasks.
Maintaining two or moreversions of the corpus is also being considered.To enable a semi-automatic qualitative andquantitative investigation, a random 10-reviewssample (1226 tokens) of the original corpus wasselected and POS tagged by the MXPOST taggerwhich was trained on MAC-Morpho, a 1.2million tokens corpus of Brazilian Portuguesenewspaper articles (Alu?sio et al., 2003).It is worthwhile to say that the sampling didnot follow statistical principles.
In fact, werandomly selected 10 texts (1226 tokens from acorpus of 4,088,718 tokens), which weconsidered a reasonable portion of text toundertake the manual tasks required by the firstdiagnosis experiments.
Our aim was to exploretendencies and not to have a precise statisticaldescription of the percentage of types of errors inthe corpus.
Therefore, the probabilities of eachtype of error may not reflect those of the entirecorpus.We manually corrected the POS taggedversion to evaluate how many tags werecorrectly assigned.
The precision of MXPOST inour sample is 88.74%, while its better precision,of 96.98%, has been obtained in its trainingcorpus.
As one may see, there was a decrease of8.49% in performance, which is expected in suchchange of text genre.In the sequence, we created four manuallycorrected versions of the sample, regarding eachof the following normalization categories:spelling (including foreign words and namedentities); case use; punctuation; and use ofinternet slang.
This step produced four goldencorpus samples which were used for separateevaluations.
The calculation of the differencebetween the original corpus sample and each ofthe golden ones led us to the followingconclusions.The manual corrections of the sample weremade by a linguist who followed some rulesestablished in accordance with the project goalsand the MXPOST annotation guidelines1.
As aresult, only the punctuation correction allowedsome subjective decisions; the other kinds ofcorrection were very objective.5.
Results of diagnosing experimentsRegarding to spelling, 2 foreign words, 3named entities and 19 common words weredetected as misspelled.
A total of 24 (1.96%)words have been corrected.
There are 35 words(2.90%) for which the case have been changed (6upper to lower and 29 in the reverse direction).Punctuation has showed to be a relevantissue: 48 interventions (deletions, insertions orsubstitutions) have been made to turn the textscorrect, representing 3.92% of the sample.Regarding internet slang, only 3 occurrences(0.24%) were detected in the sample, whatcontradicted our expectation that such lexiconwould have a huge impact in our corpus.However due to the size of our sample, this mayhave occurred by chance.The precision of the POS tagged sample hasbeen compared with the ones of the POS taggedversions of golden samples.
The results showedus the impact of the above four normalizationcategories on the tagger performance.We have verified that there was improvementafter the correction of each category, reducingthe POS tagger errors as shown in Table 2.
Whenwe combine all the categories of correctionbefore tagging the sample, the cumulative resultis an error reduction of 19.56%.Table 2.
Improvement of the tagger precisionin the sampleCase Correction + 15.94%Punctuation Correction + 4.34%Spelling + 2.90%Internet Slang Convertion + 1.45%Cumulative Error Reduction 19.56%These first experiments revealed that casecorrection has major relevance in the process ofnormalizing our corpus of products reviews.
It isimportant to note that case information is largely1Available athttp://www.nilc.icmc.usp.br/lacioweb/manuais.htm24used as feature by Named Entities Recognizers(NER), POS taggers and parsers.To evaluate whether the case use distributionis different from that of a corpus of well writtentexts, we compared the statistics of case use inour corpus with those of a newspaper corpus(http://www.linguateca.pt/CETENFolha/), asshown in Table 3.Table 3.
Percentage of case use in newspaperand products reviews corpus genresCORPUS NewspaperProductsReviewsUppercase words 6.41% 5.30%Initial uppercasewords20.86% 7.30%Lowercase words 70.79% 85.37%The differences observed led us to concludethat the tendency observed in our sample (propernames and acronyms written in lower case) isprobably a problem for the whole corpus.To confirm such conclusion, we searched inthe corpus the 1,339 proper nouns identified inour previous annotation task.
They occurred40,009 times with the case distribution shown inTable 4.Table 4.
Case distribution of Proper NounsInitial uppercase words 15,148 38%Uppercase words 7,392 18%Lower case words 17,469 44%Total 40,009 100%The main result of these experiments is theevidence that the four kind of errors investigateddo affect POS tagging.
In the next section wewill detail the procedures envisaged to providenormalization for each one of the four categoriesof errors.6.
Towards automatic normalizationproceduresAfter diagnosing the needs of textnormalization of our corpus, we started to testautomatic procedures to meet them.
Theprocessing of a new genre always poses aquestion: should we normalize the new genre tomake it similar to the input expected by availableautomatic tools or should we adapt the existingtools to process the new genre?
This is not aquestion of choice, indeed.
We argue that bothmovements are needed.
Furthermore, theprocessing of a new genre is an opportunity notonly to make genre-adaptation, but also toimprove general purpose features of NLP tools.6.1 Case normalization: truecasingIn NLP the problem of case normalization isusually called ?truecasing?
(Lita et al, 2003,Manning et al., 2008).
The challenge is to decidewhen uppercase should be changed into lowercase and when lower case should be changed intoupper case.
In brief, truecasing is the process ofcorrecting case use in badly-cased or non-casedtext.The problem is particularly relevant in twoscenarios; speech recognition and informal webtexts.We prioritized the case normalization for tworeasons: first, badly-cased text seems to be ageneralized problem in the genre of productsreviews and, second, it is important to make casenormalization before using a spell checker.
Thisis crucial to ?protect?
Named Entities fromspelling corrections because when non-recognized lowercase words are checked byspellers, there is the risk of wrong correction.Indeed, the more extensive is the speller lexicon,the greater is the risk of miscorrection.The genre under inspection presents awidespread misuse of case.
By one side, lowercase is used in place of uppercase in the initialletter of proper names.
On the other side, uppercase is used to emphasize any kind of word.Our first tentative to tackle the problem ofcapitalization was to submit the samples to aNamed Entity Recognizer.
We chose Rembrandt2(Cardoso, 2012), a Portuguese NER thatenhances both lexical knowledge extracted fromWikipedia and statistical knowledge.The procedure was: 1) to submit the sampleto Rembrandt; 2) to capitalize the recognizedentities written in lower case; 3) to change all thewords capitalized, except the named entities, tolower case.
Then we tagged the sample withMXPOST to evaluate the effect on POS taggingaccuracy.The number of errors of POS taggingincreased (149) when compared to the one of thesample without preprocessing (138).
The2The Portuguese named entity recognition is made bysystem Rembrandt (http://xldb.di.fc.ul.pt/Rembrandt/)25explanation for this is that among the words notrecognized as named entities there werecapitalized named entities which were lost bythis strategy.Next we tried a new version of this sameexperiment: we only changed into lower case thewords not recognized as named entities that weresimultaneously recognized by Unitex.
The resultswere slightly better (143 errors) compared to thefirst version of the experiment, but still worsethan those of the sample without preprocessing.Our expectation was to automaticallycapitalize the recognized entities written in lowercase.
In both experiments, however, no word waschanged from lower to upper case because all theentities recognized by the NER were alreadycapitalized.The sample contains 57 tokens of namedentities (corresponding to proper nouns andacronyms) from which 24 were written in lowercase.
The NER recognized 22 of the 57 or 18 ofthe 38 types of named entities (a performance of47.4%).
Unfortunately the NER is strongly basedon the presence of capitalized initial letters andwas of no aid in the procedure we tested.We argue that a finite list of known propernouns and acronyms, although useful forimproving evaluation figures, is of limited usefor an application such as an opinion miner.
Inreal scenarios this constitutes an open class andnew entities shall be recognized as well.We observed that many of the named entitiesfound in the reviews relate to the product beingreviewed and to the company that produces it.Then we realized an advantage of the sourcefrom which we have crawled the reviews: thecustomers are only allowed to review productsthat have been previously registered in the sitedatabase.
The register of the name of the productis kept in our corpus as metadata for each review.This situation gave us the opportunity toexperiment another strategy: to identify namedentities of each review in its respective metadatafile.
We first gathered all the words annotated asProper Nouns and Acronyms in our previousannotation task3.
Then we search for the matches.The result is promising: from 1,334 proper nounsand from 271 acronyms, respectively 6763Confusion matrix of our double annotated data showthat annotators diverged in what concerns Proper Nouns andAcronyms.
For our purposes, however, all of them arenamed entities and need to be capitalized, so that this kindof disagreement did not affect the use we have made of theannotated words.
(50.67%) and 44 (16.23%) were found in themetadata.
Adding both types of named entities,we have a match of 44.85% (720 of 1605).
Thisis pretty good mainly because the named entitiesrecognized are precisely the names of productsfor which opinions will be mined.However, we still need to solve therecognition of the other named entities in orderto support the truecasing strategies.Following Lita et al.
(2003) and Beaufays andStrope (2013), we are considering using alanguage model.
Lita et al.
developed a truecaserfor news articles, a genre more ?stable?
thanproducts reviews.
Beaufays and Strope, on theirturn, developed a truecaser to tackle textsgenerated from speech recognition.
Languagemodeling may be a good approach to ourproblem because many named entities ofproducts domain do not sound as Portuguesewords.
For example, they frequently have theconsonants k, y and w, which are only used inproper names in Portuguese.
Other approaches totruecasing reported in the literature include finitestate transducers automatically built fromlanguage models and maximum entropy models(Batista et al.
2008).6.2 Punctuation problemsMany reviews have no punctuation at all.This prevents processing the text by most of NLPtools which processes sentences.
Somegrammatical rules may be used to correct the useof comma, but the problem is more complex inwhat concerns full stop.
We are now training amachine learning based program with a corpus ofwell written texts by using features related to n-grams.
We aim at building a sentencesegmentation tool which does not depend on thepresence of punctuation or case folding, sincethese are major noises in the corpus.6.3 Spelling correctionThe common Portuguese words in the corpuswhich were not recognized by Unitex have beenspell checked.
Manual analysis is beingundertaken to determine whether the word hasbeen accurately corrected or not.
Early resultsevidenced opportunity to extend Unitex and toimprove our spellers with more phonetic rules inorder to suggest more adequate alternatives.
Aswe have already mentioned, product reviewershave several levels of literacy and those of lowerlevel frequently swap the consonant letters that26conveys the same phonetic value.
For example,in Portuguese the letters ?s?, ?c?, ?xc?
?ss?
and???
can have the same sound: /s/.
Therefore, it isa common mistake to employ one instead of theother.
These rules shall be incorporated in spellchecker.
In addition, there are many words whichwere correctly spelled, but were not part ofUnitex or of the speller?s dictionary or both.Both lexicons will be extended with the missingwords.In the same way, the foreign words of current usein Brazilian Portuguese shall be incorporated inthe spell checkers in order to improve theirsuggestions of correction.
As a matter of fact,foreign words are frequently misspelled.
Forexample, ?touchscreen?
appeared as 10 differentspelling forms in our corpus with more than 2occurrences (?toch escreen?, ?touch screem?,?touch sreen?, ?touche?, ?touch scream?,?touchscream?, ?touchscreem?, ?touch-screen?,?touchsren?, ?touch screen").6.4 Internet slang normalizationInternet slang is a class that combines: 1)words written in a different way andabbreviations of recurrent expressions, for whichthere is an equivalent in the standard language(in this case the procedure is to substitute one foranother); 2) repeated letters and punctuation (e.g.!!!!!!!!!!!
!, and ameiiiiiiiiiiiiiiiiiiiiiii, in which theword "amei" = ?love?
is being emphasized),which may be normalized by eliminatingrepetitions; and 3) sequences of letters related toemotion expression, like emoticons (e.g.
?:)?,?:=(?
), laughing (e.g.
rsrsrsrs, heheheh,kkkkkkkk), which for some purposes shall beeliminated and for others shall not.
Theprocedures relating to internet slang will beimplemented carefully  to allow the user toactivate each one of the three proceduresseparately, depending on his/her interest inpreserving emotion expression or not.7.
Final RemarksThis preliminary investigation about theneeds of text normalization for the genre ofproducts reviews led us to deep understand ourchallenges and to envisage some solutions.We have opened some avenues for futureworks and established an agenda for the nextsteps towards corpus normalization.AcknowledgmentsThis research work is being carried on as part ofan academic agreement between University ofS?o Paulo and Samsung Eletr?nica da Amaz?niaLtda.ReferencesAlu?sio, S. M.; Pelizzoni, J. M.; Marchi, A. R.;Oliveira, L. H.; Manenti, R.; Marquivaf?vel, V.(2003).
An account of the challenge of tagging areference corpus of Brazilian Portuguese.
In:Proceedings of PROPOR?2003.
Springer Verlag,2003, pp.
110-117.Aw, A.; Zhang, M.; Xiao, J.; Su, J.
(2006).
A Phrase-based Statistical Model for SMS TextNormalization.
In: Proceedings of the COLING-2006 .ACL, Sydney, 2006, pp.
33?40.Batista, F.; Caseiro, D. A.;  Mamede, N. J.; Trancoso,I.
(2008).
Recovering Capitalization andPunctuation Marks for Automatic SpeechRecognition: Case Study for the PortugueseBroadcast News, Speech Communication, vol.
50,n.
10, pages 847-862, doi:10.1016/j.specom.2008.05.008, October 2008Beaufays, F.; Strope, B.
(2013) Language ModelCapitalization.
In:  2013 IEEE InternationalConference on Acoustics, Speech and SignalProcessing (ICASSP), p. 6749 ?
6752.Bildhauer, F.; Sch?fer, R. (2013) Token-level noise inlarge Web corpora and non-destructivenormalization for linguistic applications.
In:Proceedings of Corpus Analysis with Noise in theSignal (CANS 2013) .Cardoso, N. (2012).
Rembrandt - a named-entityrecognition framework.
In: Proceedings of theEight International Conference on LanguageResources and Evaluation (LREC'12).
May, 23-25,Istanbul, Turkey.Carletta, J.: Assessing Agreement on ClassificationTasks: The Kappa Statistic.
ComputationalLinguistics, vol.
22, n. 2, pp.
249--254.
(1996)Contractor, D.; Tanveer A.; Faruquie; L.;Subramaniam, V. (2010).
Unsupervised cleansingof noisy text.
Coling 2010: Poster Volume, pages189?196, Beijing, August 2010.Hartmann, N. S.; Avan?o.
L.; Balage, P. P.; Duran,M.
S.; Nunes, M. G. V.; Pardo, T.; Alu?sio, S.(2014).
A Large Opinion Corpus in Portuguese -Tackling Out-Of-Vocabulary Words.
In:Proceedings of the Ninth International Conference27on Language Resources and Evaluation (LREC2014).
Forthcoming.Lita, L., Ittycheriah, A., Roukos, S. & Kambhatla,N.
(2003), Truecasing, In: Proceedings of the 41stAnnual Meeting of the Association forComputational Linguistics, Japan.Manning, C. D., Raghavan, P., & Sch?tze, H. (2008).Introduction to information retrieval (Vol.
1).Cambridge: Cambridge university press.Muniz, M.C.M.
; Nunes, M.G.V.
; Laporte.
E. (2005)"UNITEX-PB, a set of flexible language resourcesfor Brazilian Portuguese", Proceedings of theWorkshop on Technology of Information andHuman Language (TIL), S?o Leopoldo (Brazil):Unisinos.Ringlstetter, C.; Schulz, K. U. and Mihov, S. (2006).Orthographic Errors in Web Pages: TowardCleaner Web Corpora.
In: ComputationalLinguistics Volume 32, Number 3, p. 295-340.Sch?fer, R.; Barbaresi, A.; Bildhauer, F. (2013) TheGood, the Bad, and the Hazy: Design Decisions inWeb Corpus Construction.
In:  Proceedings of the8th Web as Corpus Workshop (WAC-8).Schlippe, T.; Zhu, C.; Gebhardt J.;, Schultz, T.(2013).Text Normalization based on Statistical MachineTranslation and Internet User Support.
In:Proceedings of The 38th International Conferenceon Acoustics, Speech, and Signal Processing(ICASSP-2013) p. 8406 ?
841.28
