Parsing Noisy SentencesHiroaki SAITOCenter for Machine TranslationCarnegie Mellon UniversityPittsburgh, PA 15213, USAandATR Interpreting Telephony Research LaboratoriesTwin 21 MID Tower, 2-1-61 ShiromiHigashi ku, Osaka 540, JapanMasaru TOMITACenter for Machine TranslationCarnegie Mellon UniversityPittsburgh, PA 15213, USAAbst ractThis paper describes a method to parse and understand a"noisy" sentence that possibly includes errors caused by aspeech recognition device.
Our parser is connected to aspeech recognition device which takes a continuouslyspoken sentence in Japanese and produces a sequence ofphonemes.
The output sequence of phonemes can quitepossibly include errors: altered phonemes, extra phonemesand missing phonemes.
The  task is to parse the noisyphoneme sequence and understand the meaning of theoriginal input sentence, given an augmented context-freegrammar whose terminal symbols are phonemes.
A veryefficient parsing method is required, as the task's searchspace is much larger than that of parsing un-noisysentences.
We adopt he generalized LR parsing algorithm,and a certain scoring scheme to select the most l ikelysentence o~t of multiple sentence candidates.
The use of aconfusion matrix, which is created in advance by analyzinga large set of input/output pairs, is discussed to improve thescoring accuracy.
The system has been integrated intoCMU's knowledge-based machine translation system.1.
Introduct ionThere have~ been a few attempts to integrate a speechrecognition device with a natural anguage understandingsystem.
Ita~,es et.
al /Hayes86/ adopted the technique ofcaseframe instantiation to parse a continuously spokenEnglish sentence in the form of a word lattice (a set of wordcandidates hypothesized by a speech recognition module)and produce a frame representation f the utterance.
Poesioand Rul lemt /Poesio 1987/ suggested  a mod i f iedimplementation f the caseframe parsing to parse a wordlattice in :italian.
Lee et.
al /Lee 1987/ developed aprototype Chinese (Mandarin) dictation machine whichtakes a syllable lattice (a set of syllables, such as \[guo-2\]and \[tieng-:l\], hypothesized by a speech recognition module)and produces a Chinese character sequence which is bothsyntactically and semantically sound.In this paper, we try to parse a Japanese utterance in theform of a sequence of phonemes.1 Our speech recognitiondevice, which is a high-speed speaker-independent systemdeveloped by Matsushita Research Institute/Mori i  1985/,/Hiraoka 1986/ takes a continuous peech utterance, for1.
Phonemes (e.g./g\],/ed, Is/, etc.)
are even lower level units thansyllables.2.
We distinguish noisy from ill-formed.
The former is due torecognition device rrors, while the latter is due to human users.example "megaitai" ("I have a pain in my eye.
"), from amicrophone and produces a noisy phoneme sequence suchas "ebaitaai.
"2The speech recognition device does not have any syntacticor semantic knowledge.
More input/output examples of thespeech device are presented in Figure 1-1.< correct sequence > <recognition output>igarnukamukasuru ---> igangukamukusjuruigamukamonkasjurukubigakowabaqteiru ---> kurigakoogateiruazubigakoabaqciiruatamagaitai ---:> otomogaitaiatamogeitainFigurel-1:  Input and Output of Recognition DeviceNote that the speech recognition device produces aphoneme sequence, not a phoneme lattice; there are noother phoneme candidates available as alternates.
Wemust make the best guess based solely on the phonemesequence generated by the speech device.
Errors caused bythe speech device can be classified into three groups:?
A l tered Phonemes -- Phonemes recognized incorrectly.The second phoneme /b/ in "ebaitaai"  is an a l teredphoneme, for example.?
Miss ing Phonemes -- Phonemes which are actuallyspoken but not recognized by the device.
The first phoneme/nd in "megaitai", for example, is a missing phoneme.?
Extra Phonemes -- Phonemes recognized by the devicewhich are not actually spoken.
The penultimate phoneme/a/in "ebaitaai", for example, is an extra phoneme.To cope with these problems, we need:?
A very efficient parsing algorithm, as our task requiresmuch more search than conventional typed sentenceparsing.
And?
A good scoring scheme, to select he most likely sentenceout of multiple candidates.In sections 2 and 3, we describe the parsing algorithm andthe scoring schelhe, respectively.2.
The Pars ing Algor i thmThe grammar we are using is an Augmented Context-FreeGrammar whose terminal symbols are phonemes ratherthan words.
That is, the grammar includes rules like561Noun- ->watas iinstead ofNoun -- > 'watasi 'The grammar has ?been developed primari ly for CMU'sknowledge-based machine translat ion system /Tomita1987/and consists of more than 2000 rules including lexicalrules like One above.32.1.
General ized LR Pars ingTomita /Tomita 1985/, /Tomita 1987b/ introduced theGeneralized LR Parsing Algorithm for AugmentedContext-Free Grammars, which?
can ingeniously handlenondeterminism and ambiguity with a graph-structured?
stack.
Tomita also showed that it can be used for a wordlattice parsing fromita 1986/.
Our algorithm here is basedon Tomita's parsing algorithm.A very simple example grammar is shown in Figure 2-1,and its LR parsing table, compiled automatically from thegrammar, is shown in Figure 2-2.
(1) S - ->  NP PD(2) S - ->  N(3) S - ->  PD(4) NP- -> N P(5) N - ->  m e(6) N - -> i(7) P - ->  g a(8) PD - ->  i t a iFigure 2-1: An Example GrammarState a e m g t $ N NP P PD S. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.0 s4 s5 2 3 1 61 r32 s7,r2 83 s9 104 r6 s11,r65 s126 acc7 s138 r491011 s141213 r714 s1515s l lr lr5 r5r8Figure 2-2: LR Parsing Table with Multiple EntriesGrammar  symbols of lower case characters are terminals.The Generalized LR  parsing algorithm is a table drivenshift-reduce parsing algorithm that can handle arbitrarycontext-free grammars in polynomial time.
Entries "s n" inthe action table (the left part of the table) indicate the3.
The run-time grammar, which contains both syntax andsemantics, is compiled automatically from more abstractformalisms: the Functional Grammar formalism for syntax andframe representation forsemantics.
For more discussions on thisUniversaIParser A chitecture, see fromita 1987a\].action "shift one word frominput buffer onto the stack andgo to state n".
Entries "r n" indicate the action "reduceconstituents on the stack using rule n".
The entry "acc"stands for the action "accept", and blank spaces represent"error".
The goto table (the right part of the table) decidesto which state the parser should go after a reduce action.While the encountered entry has only one action, parsingproceeds exactly the same way as LR parsers, which areoften used in compilers of programming languages.
Whenthere are multiple actions in one entry called conflicts, allthe actions are executed in paral lel  with the graph-structured stack.
We do not describe the Generalized LRparsing algorithm in greater detail, referring the reader to/Tomita 1985/,/Tomita 1986/, fromita 1987b/.2.2.
Handl ing altered, extra,  and missing phonemesTo cope with altered, extra and missing phonemes, theparser must consider these errors as it parses an input fromleft to right.
While the algorithm described in the previoussubsectio n cannot handle these noisy phenomena, it is wellsuited to consider many possibilities at the same time, andtherefore, it can be relatively easily modified to handlesuch noisy phenomena as the following.?
A l tered phonemes  -- Each phoneme in a phonemesequence may have been altered and thus may be incorrect.The parser has to consider all these possibilities.
We cancreate a phoneme lattice dynamically by placing alternatephoneme candidates in the same location as  the originalphoneme.
Each possibility is then explored by each branchof the parser, Not all phonemes can be altered to any otherphoneme~ For example, whi le/o/can be mis-recognized as/u / , / i /can never be mis-recognized as/o/.
This kind ofinformation can be obtained from a confusion matr ix,which we shall discuss in the next section.
With theconfusion matrix, the parser does not have to exhaustivelycreate alternate phoneme candidates.?
Extra  phonemes  -- Each phoneme in a phonemesequence may be an extra, and the parser has to considerthese possibilities.
We have one branch of the parserconsider an extra phoneme by s imply ignor ing thephoneme.
The parser assumes at most one extra phonemecan exist between two real phonemes, and we have foundthe assumption quite reasonable and safe.?
Missing phonemes -- Missing phonemes can be handledby inserting possible missing phonemes between two realphonemes.
The parser assumes that at most one phonemecan be missing between two real phonemes.2.3.
An ExampleIn this subsection, we present a sample trace of the parser.Here we use the grammar in Figure 2-1 and the LR table inFigure 2-2 to try to parse the phoneme sequence "ebaitaai"represented in F igure  2-3.
(The r ight  sequence is"megaitai" which means "I have a pain in my eye.
")T.i r I,l ,, : J,Figure 2-3: An input sequence ofphonemes562In this example we make the following asumptions foraltered and Z aissing phonemes.
?/ i /may possibly be mis-recognized as/e/.
?/e/may posvibly be mis-recognized as/a/.. /g/may possibly be mis-recognized as/b/.?
/m/may be missed in the output sequence with a higherprobability.Now we begin parsing: first an initial state 0 is created.The action table indicates that the initial state is expecting"m" and 'T' (Figure 2-4).
Since the parsing proceeds strictlyfrom left to right, the parser looks for the missing phonemecandidates between the first time frame 1 - 2.
(We will usethe term T1, T2 .... for representing the time 1, time 2 .... inFigure 2-3.)
Only the missing phoneme "m" in this group isappl icable to state 0.
The new state number 5 isdetermined from the action table(Figure 2-5).The next group of phonemes between T2 and T3 consists ofthe %" phoneme in the phoneme sequence and the alteredcandidate phonemes of "e".
In this group %" is expected bystate 5 and 'T' is expected by state 0(Figure 2-6).
After "e"is taken, the new state is 12, which is ready for the action"reduce 5".
Thus, using the rule 5(N -- > m e), we reducethe phonemes "m e" into N. From state 0 with thenonterminal N, state 2 is determined from the goto table.The action table, then, indicates that state 2 has a multipleentry, i.e., state 2 is expecting "g" and ready for the reduceaction(Figure 2-7).
Thus, we reduce the nonterminal N intoS by rule 2(S - -> N), and the new state number 6 isdetermined fl'om the goto table(Figure 2-8).
The actiontable indicates that state 6 is an accept state, which meansthat "m e" is a successful parse.
But only the first phoneme"e" of the input sequence "ebaitaai" is consumed at thispoint.
Thus we discard this parse by the fol lowingconstraint?\ [Constraint 1\] The successful parse should consume thephonemes at least until the phoneme just before the end ofthe input sequence.Note that only the parse S in Figure 2-8 is ignored and thatthe nonterminal N in Figure 2-7 is alive.Now we return to the Figure 2-6 and continue the shiftaction of 'T'.
After "i" is taken, the new state 4 isdetermined from the action table.
This state has a multipleentry, i.e.
state 4 is expecting "t" and ready for the reduceaction.
Thus we reduce "i" into N by rule 6.
Here we use thelocal ambigu i ty  pack ing  technique, because the reducednonterminal is the same, the starting state is 0 for both,and the new state is 2 for both.
Thus we do not create thenew nonterminal N.Now we go on to the next group of phonemes between T3and T4.
Only "m" is applied to the initial state(Figure 2-9).The next group of phonemes between T4 and T5 has oneapplicable phoneme, i.e.
an altered phoneme candidate "g"to state 2.
After "g" is taken, the new state 7 is determinedfrom the action table (Figure 2-10).The next group of phonemes between T5 and T6 has onlyone applicable phoneme; a missing phoneme candidate "m"to stateO.
Here we can introduce another constraint whichdiscards this partial-parse.\ [Constraint 2\] After consuming two phonemes of the inputsequence, no phonemes can be applied to the initial state 0.i0 *i*m,Figure 2-41 2:~."
5*eFigure 2-51 2 3*i 5*m "e 12o "::;::: "7""7"- "::'" 4 ".::....
, m2*gFigure 2-101 2*i \[ 5*m 1~3 *e\[rS\]4Figure 2-6I 2*i*m oz ..... ~0 "(':::: m',.
:;::::::5*e '7g *a "~35*e"7"i%,*i*m0 ;;'"",124*tSg'.iFigure 2-112 3*e..m..Figure 2-7'12'4'2Jr2\]i *g61 i!
"7 .... \[rT\]*a\[r4\]1*i*mo "::::::*i*m2i'e 12, i  4 \[r61* t2*g$ 6aecFigure 2-82,5*e:::::.mN*i*mo ".
):'~3 4,12I 4N ' * t, , .
.
,~5m I *e 13NP \[ 13iFigure 2-12mm::::::..35*e m 12e~ 4'i.... *t~mi 2*g iFigure 2-95*e5631*i*m0 ""::".:.
~.
,,:"i2 '53*em eN4 " Y (*eg "Y""*R, iFigure 2-1351t'i 13/ *i*i*m0 ""::'"..~':::i3 45*e 12e4m5This constraint is natural because it is unlikely that morethan two phonemes are recorded before the actua lbeginning phoneme for our speech recognition device.The next group of phonemes between T6 and T7 has twoapplicable phonemes, i.e.
the output phoneme "a" to state 7and the altered phoneme candidate "e" to state 5.
After "a"is taken, the new state 7 is ready for the reduce action.Thus, we reduce "g a" into P by rule 7 (Figure 2-11).
Thenew state 8 is determined by the goto table, and is alsoready for the reduce action.
Thus we reduce "N P" into NPby rule 4 (Figure 2-12).
The new state is 3.
In applying "e",there are two "state 2"s: one is "m" between T1 and T2; theother one is "m" between T3 and T4.
'Here we can introducea third constraint which discards the former partial-parse.\ [Constra int  3\] A shift action is not applied when ,thed is tance between the phoneme and the app l ied(non)terminal is more than 4.
(This distance contains atleast one real phoneme.
)Figure 2-13 shows the situation after "e" is applied.The parsing continues in this way, and the final situationis shown in Figure 2-14.
As a result, the parser finds twosuccessful parses; "megaitai" and "igaitai"(which means "Ihave a stomachache.")3.
Scoring and the Confusion Matr ixThere are two main reasons why we want to score eachparse: first, to prune the search space by discardingbranches of the parse whose score is hopelessly low; second,to select he best sentence out of multiple candidates bycomparing their scores.
Branches of the parse whichconsider fewer altered/extra/missing phonemes hould begiven higher scores?
Whenever a branch of the parsehandles an altered/extra/missing phoneme, a specificpenalty is given to the branch.
Scoring accuracy canimprove with the confusion matrix.Figure 3-1 shows a part of the confusion matrix made bythe manufacturer of the recognition device from the largeword data.
This matrix tells us, for example, that if thephoneme /a/ is inputed, then the device recognizes it564PmM12*g13. '
."
!51 1' 12.
13t, .
.Figure2-1414*i"2"I15.
161417~ 15\[r8111I I "~cI\O la l  Io /  lu l  l i l  ~el I j l  lw l  ... (I) (ll)la/Io llu l/i/~el/j/Iw l(m)93.8 1.1 1.3 0 2.7 0 0 ... 0.9 54772.4 84.3 5.8 0 0.3 0 0.6 ... 6.5 75290.3 1.8 79.7 2.4 4,6 0.1 0 ... 9.7 57220.2 0 0.9 91.2 3~5 0.7 0 ... 2.9 61581.9 0 4.5 3.3 89.1 0.1 0 .... 1.1 32480 0 1.1 2.3 2.2 80.1 0.3 ... 11.4 26600;2 5.1 5.8 0.5 0 2.6 56.1 .
.
.
.
11.2 428327 176 564 512 290 864 212rate of missing phonemes(ii') number of extra phonemestotal number of samplesFigure 3.
I: A Confusion Matrix (portion)correctly 93,8% of the time; mls-recognizes it as/o/1.1% ofthe time, as/u/1.3% of the time, and so on.
The column (I)says that the input is missed 0.9% of the time.Conversely, if the phoneme/o/is generated from the device,there is a slight chance that the original input was/a/, /u/and/w/, respectively, but no chance that the original inputwas/i/ , /e/or/ j / .
The probability of the original input being/a/ is much higher than being /w/.
Thus, an alteredphoneme/w/should be given a more severe penalty than/a/.
A score for altered phonemes can be obtained in thisway, missing phonemes should be Even a negative score,and extra phonemes should be given a zero or a negativescore.
With this scoring a score of a partial parse iscalculated by summing up the score of each constituent.Therefore, themore likely parse has a higher score.Two methods have been adopted to prune partial parses bya score:?
Discarding the low-score shift-waiting branches when aphoneme is applied.?
Discarding the low-score branches in a local ambiguitypacking.The former method is very effective when strictly applied.The confasion matrix only shows us the phoneme-to-phoneme f;ransition, therefore a broader unit transitionshould also be considered, such as a tendency for the/w/:phoneme ia 'owa' or 'owo' to be missed or for the very first/h/ sound of an input to be missed, and the frequenttransformation to 'h@' of the 'su' sound in 'desuka.'4.
Conclu,,donsThe parser has been implemented in Common Lisp on aSymbolics Lisp Machine and is being integrated intoCMU's knowledge-based machine translation system toaccept aspoken Japanese sentence in the domain of doctor-patient conversation and generate sentences in English,German and Japanese.The parser has been tested against five persons.
Eachperson pronounced 27 sentences in which long sentencesare not included ue to the limits of the speech recognitiondevice.
84 % of the inputs are parsed correctly and the rightsentence appears as the best-score candidate in 88 % out ofthe correct~ly parsed inputs.
The average parsing time forone sentence is82 seconds.AcknowledgementsThe authors would like to thank Shuji Morii for giving usthe opportunity ouse the speech recognition device and tothank other members of the Center for MachineTranslatioa for useful comments and advices.
We are alsoindebted to ATR Interpreting Telephony ResearchLaboratories for providing the computational environment.Appendix.
Sample RunsTwo actual outputs of the parser are shown on the nextpage.
The first input phoneme sequence is "ebaitaai" andthe correct sequence is "megaitai"(which is the samesentence as in the example in Section 2.
), which isproduced as the top-score sentence of all parses.
The secondinput sequence is "kurigakoogateiru =" and the correctsequence is "kubigakowabaqteiru" which means "I have astiff neck."
The frame-structure output after each parse isthe meaning of the sentence.
This meaning is extracted inthe same way the CMU's machine translation system does.Namely, ~;ach rule of the context free grammar has afunction which is executed each time the rule is applied (i.e.when the reduce action occurs.)
If tale function returns nil,this partial parse is discarded because the parse is notcorrect semantically.
If the function returns a non-nilvalue, the value becomes the semantic of the right-hand-side of the rule and is forwarded to the left-hand-sidenonterminal symbol.
The details are described in fromita19870/.References/Hayes 1986/ Hayes, P. J., Hauptmann, A. G., Carbonell,J.
G., and Tomita, M.Parsing Spoken Language: A Semantic CaseframeApproach.
l l th International Conference onComputational Linguistics (COLING86).
Bonn, August,1986./Hiraoka 1986/ Hiraoka, S., Morii, S., Hoshimi, M., andNiyada, K.Compact Isolated Word Recognition System for LargeVocabulary.
IEEE-IECEJ-ASJ International Conferenceon Acoustics, Speech, and Signal Processing (ICASSP86).Tokyo, April, 1986./Lee 1987/ Lin-shan Lee, Chiu-yu Tseng, K.J.
Chen, andJames Huang.The Preliminary Results of A Mandarin Dictation MachineBased Upon Chinese Natural Language Analysis.Proceedings ofthe Tenth International Joint Conference onArtificial Intelligence.
Milan, August, 1987./lVlorii 1985/ Morii, S., Niyada, K., Fujii, S., and Hoshimi,M.Large Vocabulary Speaker-independent Japanese SpeechRecognition System.
IEEE International Conference onAcoustics, Speech, and Signal Processing (ICASSP85).TamPa, March, 1985./Poesio 1987/ Poesio, M. and Rullent, C.Modified Caseframe Parsing for Speech UnderstandingSystems Based Upon Chinese Natural Language Analysis.Proceedings ofthe Tenth International Joint Conference onArtificial Intelligence.
Milan, August, 1987.fromita 19851 Tomita, M.Efficient Parsing for Natural Language: A Fast algorithmfor Practical Systems.
Kluwer Academic Publishers.Boston, MA, 1985./Tomita 1986/ Tomita, M.An Efficient Word Lattice Parsing Algorithm forContinuous Speech Recognition.
1EEE-IECEJ-ASJInternational Conference on Acoustics, Speech, and SignalProcessing (ICASSP86).
Tokyo, April, 1986.fromita 1987a/ Tomita, M. and Carbonell, J. G.The Universal Parser Architecture for Knowledge-BasedMachine Translation.
Proceedings ofthe TenthInternational Joint Conference on Artificial Intelligence.Milan, August, 1987./Tomita 1987b/ Tomita, M.An Efficient Augmented-Context-Free Parsing Algorithm.Computational Linguistics.
1987.565Command: input=ebaitaa~'Co~nand: (parse-s)Evaluation of (PRRSE) took 31o522721 seconds of elapsed t insinoludin9 7.183 seconds uait in9 for  the disk for  39 faul ts .245,861 li~t.
51,644 structure, 22,287 stack uorda oonaed in HORKIMG-BTORRGE-RRER.204 structure words consad in *MRMESPRCE-OOJECT-RRER*.7 parsee Found.1: (185) M<l-2#-lO> E<2-3#38> G<4-5#1O) R<6-7#32> I<B-9#OO> T<IO-11#31> R<12-13#32> I<16-17#3g>((MOOD ((ROOT DEC))) (SEM *HRVE-R-PRIM1802) (OBJ ((:NH -) (ORSE OR) (SEM *EYE) (ROOT ME))) (CRUBRTIUE -)  (OBJ-CRBE OR)(SUBJ-CRSE OR) (SUBCRT 2RRG-GR) (COT RDJ) (TIME ((ROOT PRESEMT))) (ROOT ITRI))2: (172) 1<2-3#7> O(4-5#10> R<6-?#32> I<8-9U39> T<1@-11#31> R<12-13#32> I<16-1?#50>((MOOD ((ROOT DEC))) (SEM *HRUE-R-PRIM810) (OBJ ((:NH -) (CRSE OR) (SEM *STOMROH) (ROOT I ) ) )  (ORUSRTIUE -) (OBJ-CROE OR)(SUBJ-ORSE OR) (SUBCRT 2RRG-fiR) (COT RDJ) (TIME ((ROOT PRESENT))) (ROOT ITRI))3: (115) I<2-3#?> T<4-5#1> R<6mT#32> I<8-9#30> K<IO-11#13> R<12-13#32>((SEM *HRVE-R-PRIM930) (TIME ((ROOT (*OR~ PRESEMT FUTURE)))) (MOOD ((ROOT gUE8))) (OBJ-CRBE SR) (8UBJ-OROE OR) (SUBCRT 2RRG-GR)(CRT RDJ) (ROOT ITRI))4: (119) H<4-5#S> R<6-7#32> I<O-g#38> K<IO-11#10> R<12-18#32>((SEM *HRUE-R-FEUER46) (TIME ((ROOT (*OR* PRESEMT FUTURE)))) (MOOD ((ROOT QUES))) (0OJ-CRBE OR) (EUBJ-CRSE OR) (CRUSRTIVE -)(PRBSIUE -) (SUBCRT STRT) (MESRTIOM ((ROOT HITEI))) (CRT U) (ROOT RRU))5: (70) I<2-3#7> T<4-5#1> R<6-?#92> I<D-g#SS>((MOOD ((ROOT DEC))) (OBJ-CRSE OR) (6UBJ-CREE OR) (SUBCOT 2RRG-GR) (ORT ROJ) (BEM *HRUE-R-PRIM9@) (TIME ((ROOT PRESEMT)))(ROOT ITRI))6: (65) M<4-5#3> R<6-?#32> I<Bm9#SO>((MOOD ((ROOT DEC))) (OBJ-CRSE OR) (SUBJ-CRSE OR) (CRUSRTIUE -) (PRBSIUE -)  (SUBORT STRT) (BEM *HRUE-R-FEUER1B)(TIME ((ROOT PRESEMT))) (MEGRTIOM ((ROOT HITEI))) (CRT U) (ROOT RRU))?
: (43) R<2-3#6> R<4-5#3> R<6-?#32> U<B-9#2>((MOOD ((ROOT DEC))) (OBJ-CRSE O) (SUBJ-CRSE GR) (CRUS@TIUE -) (PRSBIUE m) (SUBCRT TRRMO) (SEM *MRKE--CLERM248)(TIME ((ROOT (*OR* PRESEMT FUTURE)))) (CRT U) (ROOT RI~FIU))TCommand :I ~ -~- ; ; , , -w~: - - - - -~ ,  I I I I I I I IDynamic Lisp Listener 12Sample Run 125: "KURI*RKOOIRTEIRU=' .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.Evaluation of (PRRSE) took 95.719693 seconds of elapsed timeincludin9 10,550 seconds waltln9 for the disk for 142 faults.The 9arbage col lector  has f l ippedj so oonstn9 wma not neaaurad.8 parsee found1: (393) K<2-3#2B> U(4-5#29> B<6-?we> I<B-9#B@> O<18-11#33> R<12-18#62> K<lq-15#28> 0<16-17#24> N<1?-18#O> R<18-19#2> B<2@-21#9>R<22-23#32> 0<23-24#-10> T<24-25#31> E<26-27#30> I<28-29#36> R<30-31#31> U<32-33#29>((MOOD ((ROOT DEC))) (SEM *HRUE-R-BTIFFMESE1268) (OBJ ((:HH -)  (OROE OR) (SEM *MECK) (ROOT KUBI))) (CRUSRTIUE -) (OBJ-ORBE OR)(SUBJ-CRSE OR) (PRSSIVE -) (BUBORT STRT) (TIME ((ROOT (*ORs PREOEMT FUTURE)))) (PROOREGBIUE *) (ORT U) (ROOT KOMRBRRU))2: (372) K<2-3#28> 0<4-5#10> R<6-?#31> E<8-9#2> O<1@-11#33> R<12-13flO2> K<14-15#28> 0(16-17fl24> N<17-18#O> R<18-19#2> B<2g-21#9>R<22-23#32> 0<23-24#-10> T<24-25f191> E<26-27#3O> I(28-29#30> R<86-31#91> U<32-33#29>((MOO0 ((ROOT DEC))) (OBJ ((:WH -) (CRSE OR) (ROOT KORE))) (CRUSRTIVE -)  (OBJ-ORBE OR) (6UBJ-CRSE OR) (PRSBIUE -7 (BUOORT ST?T)(BEM *HRUE-R-BTIFFMESS214) (TIME ((ROOT (*OR* PRESEHT FUTURE)))) (PROGRESSIVE ?)
(CRI U) (ROOT KOHRBRRU))2: (372) K<2-9#28> 0<4-5fllO> R<6-7#31> E(B-9#2> G(18-11#33> R(12-19#32> K(14-15#28> 0<16-17424> M<l~-lB#@> R<18-19#2> B(28-21~9>R<22-23f102) Q<23-24#-18> T<24-25#31> E<2G-27#OO> I<28-29#3@> R<30-31#31> U<32-OO#~>((MOOD ((ROOT DEC))) (OUBJ ((:NH -) (CRBE OR) (ROOT KORE))) (BUBJ-CRSE OR) (OBJ-CRBE OR) (CRUBRTIUE -)  (PRBBIUE -) (SUBCRT ETRT)(SEM *HRUE-R-BTIFFMERB214) (TIME ((ROOT (*OR* PREBEHT FUTURE)))) (PROgREBSIYE ?)
(CRT U) (ROOT KO~RBRRU))4: (279) K<2-3#28> U(4-5#29> B<6-7#5> I<B-O#Og> G<1@-11#33> R?12-18M32> K<14-15#28> 0(16-17#24> N<17-18#g> R<18-19#2> B<28-21#9>'R<22-23#32> Q<23-24#-19> T<24-25#31> R<26-27#G>((MOOD ((ROOT DEC))) (SEM *HRUE-R-BTIFFMEBB1264) (OBJ ((:HH -)  (SRSE OR) (SEN ~HEOK) (ROOT KUBI))) (CRUORTIUE -) (OBJ-CROE GO)(SUBJ-CRSE DR) (PRBBIVE -)  (BUBCRT STRT) (TIME ((ROOT PRST))) (ORT V) (ROOT KOWRBRRU))5: (256) K<2-3#28> 0<4-5#1D> R<6-7#31> E<8-9#2> g<18-11#33> R(12-13#32> K<14-15#28> 0<16-17#24> M<1~-18#8> R<10-19#2> B<20-21#9>R<22-23#32> O<23-24#-10> T<24-25#31> R<26-2?#G>((HOOD ((ROOT DEC))) (OBJ ((:WH -) (CRBE GR) (ROOT KORE))) (CRUBRTIVE -) (OBJ-ORBE OR) (OUBJ-CRBE OR) (PRSSIVE -) (BUBORT BTRT)(SEM *HRUE-R-BTIFFMEBSOB) (TIME ((ROOT PRST))) (CRT V) (ROOT KOMRBRRU))5: (258) K<2-3#20> 0<4-5#10> R<S-7#51> E<B-9#2> O<10-11#33> R(12-13#32> K<14-15#28> 0<16-17#24> M<17-16#O) R<lB-19#2> B<28-21#9>R<22-23#32> O<23-24#-18> T(24-25#51> R<26-2?#fi>((MOOD ((ROOT DEC))) (BUBJ ((:HH -) (CROE SO) (ROOT ~DRE))) (BUBJ-CRBE OR) (OBJ-CRBE OR) (CRUORTIVE -)  (PRBBIVE -) (BUBCRT OTRT)(SEM *HRVE-R-BTIFFMESBOB) (TIME ((ROOT PRST))) (CRTrf~/) (ROOT KOWRBRRU))7: (232) K<2-3#2B> 0<4-5#10> R<6-7~31) E<B-9#2> G<lS-11#33> R<12-13#B2> K<14-15#28> 0<16-17#24> N<26-21#5> R<22-23#32> 1<26-27#7>((MOOD ((ROOT DEC))) (BUBJ ((:NH -) (ORSE OR) (ROOT KORE))) (SUBJ-CRGE OR) (CAUSATIVE -)  (PROBIVE -) (OUBCRT INTRRNB)(SEM *PTRRHSBBO) (TIME ((ROOT PRESENT))) (MEORTION ((ROOT HITEI))) (CRT V) (ROOT KURU))**MORE**II !Dynamic Lisp Listener 12566Sample Run
