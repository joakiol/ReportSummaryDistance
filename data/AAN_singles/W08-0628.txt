BioNLP 2008: Current Trends in Biomedical Natural Language Processing, pages 120?121,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsAdaptive Information Extraction for Complex Biomedical TasksDonghui Feng            Gully Burns            Eduard HovyInformation Sciences InsituteUniversity of Southern CaliforniaMarina del Rey, CA, 90292{donghui, burns, hovy}@isi.eduAbstractBiomedical information extraction tasks are of-ten more complex and contain uncertainty ateach step during problem solving processes.
Wepresent an adaptive information extractionframework and demonstrate how to explore un-certainty using feedback integration.1 Adaptive Information ExtractionBiomedical information extraction (IE) tasks areoften more complex and contain uncertainty at eachstep during problem solving processes.When in the first place the desired information isnot easy to define and to annotate (even by humans),iterative IE cycles are to be expected.
There mightbe gaps between the domain knowledge representa-tion and computer processing ability.
Domainknowledge might be hard to represent in a clearformat easy for computers to process.
Computer sci-entists may need time to understand the inherentcharacteristics of domain problems so as to find ef-fective approaches to solve them.
All these issuesmandate a more expressive IE process.In these situations, the traditional, straightfor-ward, and one-pass problem-solving procedure, con-sisting of definition-learning-testing, is no longeradequate for the solution.Figure 1.
Adaptive information extraction.For more complex tasks requiring iterative cycles,an adaptive and extended IE framework has not yetbeen fully defined although variants have been ex-plored.
We describe an adaptive IE framework tocharacterize the activities involved in complex IEtasks.
Figure 1 depicts the adaptive information ex-traction framework.This procedure emphasizes one important adap-tive step between the learning and applicationphases.
If the IE result is not adequate, some adapta-tions are required:Our study focuses on extracting tract-tracing ex-periments (Swanson, 2004) from neuroscience arti-cles.
The goal of tract-tracing experiment is to chartthe interconnectivity of the brain by injecting tracerchemicals into a region of the brain and then identi-fying corresponding labeled regions where the traceris transported to (Burns et al, 2007).
Our work isperformed in the context of NeuroScholar1, a projectthat aims to develop a Knowledge Base Manage-ment System to benefit neuroscience research.We show how this new framework evolves tomeet the demands of the more complex scenario ofbiomedical text mining.2 Feedback IntegrationThis task requires finding the knowledge describingone or more experiments within an article as well asidentifying desired fields within individual sen-tences.
Significant complexity arises from the pres-ence of a variable number of records (experiments)in a single research article --- anywhere from one tomany.Table 1.
An example tract-tracing experiment.Table 1 provides an example of a tract-tracing ex-periment.
In this experiment, when the tracer wasinjected into the injection location ?the contralateralAVCN?, ?no labeled cells?
was found in the label-ing location ?the DCN?.For sentence level fields labeling, the perform-ance of F1 score is around 0.79 (Feng et al, 2008).1 http://www.neuroscholar.org/120We here show how the adaptive information extrac-tion framework is applied to labeling individual sen-tences.
Please see Feng et al (2007) for the detailsof segmenting data records.2.1 Choosing Learning Approach via F1A natural way to label sentences is to obtain (byhand or learning) patterns characterizing each field(Feng et al, 2006; Ravichandran and Hovy, 2002).We tried to annotate field values for the biomedicaldata, but we found few intuitive clues that rich sur-face text patterns could be learned with this corpus.This insight, Feedback F1, caused us to give upthe idea of learning surface text patterns as usual,and switch to the Conditional Random Fields (CRF)(Lafferty et al, 2001) for labeling sentences instead.In contrast to fixed-order patterns, the CRF modelprovides a compact way to integrate different typesof features for sequential labeling problems and canreach state-of-the-art level performance.2.2 Determining Knowledge Schema via F2In the first place, it is not clear what granularity ofknowledge/information can be extracted from textand whether the knowledge representation is suitablefor computer processing.
We tried a series of ap-proaches, using different levels of granularity anddescription, in order to obtain formulation suitablefor IE.
Figure 2 represents the evolution of theknowledge schema in our repeated activities.Figure 2.
Knowledge schema evolution.Figure 3.
System performance at stage 1 and 2.We initially started with the schema in the left-most column but our pilot study showed that somefields, for example, ?label_type?, had too manyvariations in text description, making it very hard forCRF to learn clues about it.
We then switched to thesecond schema but ended up seeing that the field?injectionSpread?
needed more domain knowledgeand was therefore not able to be learned by the sys-tems.
The last column is the final schema after thosepilot studies.
Figure 3 shows system performance(overall and the worst field) corresponding to thefirst and the second representation schemas.2.3 Exploring Features via F3To train CRF sentence labeling systems, it is vital todecide what features to use and how to prepare thosefeatures.
Through the cycle of Feedback F3, we ex-plored five categories of features and their combina-tions to determine the best features for optimalsystem performance.
Table 2 shows system per-formance with different feature combinations.System Features Prec.
Recall F_ScoreBaseline 0.4067 0.1761 0.2458Lexicon 0.5998 0.3734 0.4602Lexicon+ Surface Words0.7663 0.7302 0.7478Lexicon+ Surface Words+ Context Window0.7717 0.7279 0.7491Lexicon + SurfaceWords + ContextWindow + WindowWords0.8076 0.7451 0.7751Lexicon + SurfaceWords + ContextWindow + WindowWords + Depend-ency Features0.7991 0.7828 0.7909Table 2.
Precision, Recall, and F_Score for labeling.Please see Feng et al (2008) for the details of thesentence level extraction and feature preparation,3 ConclusionsIn this paper, we have shown an adaptive informa-tion extraction framework for complex biomedicaltasks.
Using the iterative development cycle, wehave been able to explore uncertainty at differentlevels using feedback integration.ReferencesBurns, G., Feng, D., and Hovy, E.H. 2007.
Intelligent Approaches toMining the Primary Research Literature: Techniques, Systems, andExamples.
Book Chapter in Computational Intelligence in Bioinfor-matics, Springer-Verlag, Germany.Feng, D., Burns, G., and Hovy, E.H. 2007.
Extracting Data Recordsfrom Unstructured Biomedical Full Text.
In Proc.
of EMNLP 2007.Feng, D., Burns, G., Zhu, J., and Hovy, E.H. 2008.
Towards AutomatedSemantic Analysis on Biomedical Research Articles.
In Proc.
ofIJCNLP-2008.
Poster Paper.Feng, D., Ravichandran, D., and Hovy, E.H. 2006.
Mining and re-ranking for answering biographical queries on the web.
In Proc.
ofAAAI-2006.
pp.
1283-1288.Lafferty, J., McCallum, A. and Pereira, F. 2001.
Conditional randomfields: probabilistic models for segmenting and labeling sequencedata.
In Proc.
of ICML-2001.Ravichandran, D. and Hovy, E.H. 2002.
Learning surface text patternsfor a question answering system.
In Proceedings of ACL-2002.Swanson, L.W.
2004.
Brain maps: structure of the rat brain.
3rd edition,Elsevier Academic Press.121
