Proceedings of the ACL-ISMB Workshop on Linking Biological Literature, Ontologies and Databases: MiningBiological Semantics, pages 17?24, Detroit, June 2005. c?2005 Association for Computational LinguisticsAbstractGene and protein named-entity recognition (NER) andnormalization is often treated as a two-step process.While the first step, NER, has received considerableattention over the last few years, normalization hasreceived much less attention.
We have built a dictionarybased gene and protein NER and normalization systemthat requires no supervised training and no humanintervention to build the dictionaries from onlinegenomics resources.
We have tested our system on theGenia corpus and the BioCreative Task 1B mouse andyeast corpora and achieved a level of performancecomparable to state-of-the-art systems that requiresupervised learning and manual dictionary creation.
Ourtechnique should also work for organisms followingsimilar naming conventions as mouse, such as human.Further evaluation and improvement of gene/proteinNER and normalization systems is somewhat hamperedby the lack of larger test collections and collections foradditional organisms, such as human.1 IntroductionIn the genomics era, the field of biomedical researchfinds itself in the ironic situation of generating newinformation more rapidly than ever before, while at thesame time individual researchers are having moredifficulty getting the specific information they need.This hampers their productivity and efficiency.
Textmining has been proposed as a means to assistresearchers in handling the current expansion of thebiomedical knowledge base (Hirschman et al, 2002).Fundamental tasks in text mining are named entityrecognition (NER) and normalization.
NER is theidentification of text terms referring to items of interest,and normalization is the mapping of these terms to theunique concept to which they refer.
Once the conceptsof interest are identified, text mining can proceed toextract facts and other relationships of interest thatinvolve these recognized entities.
With the currentresearch focus on genomics, identifying genes andproteins in biomedical text has become a fundamentalproblem in biomedical text mining research (Cohen andHersh, 2005).
The goal of our work here is to explorethe potential of using curated genomics databases fordictionary-based NER and normalization.
Thesedatabases contain a large number of the names,symbols, and synonyms and would likely enablerecognition of a wide range of genes on a wide range ofliterature without corpus-specific training.Unsupervised gene/protein named entity normalization using automaticallyextracted dictionariesAaron M. CohenDepartment of Medical Informatics and Clinical Epidemiology, Oregon Health & Science University, Portland, OR, USAcohenaa@ohsu.eduGene and protein NER and normalization can beviewed as a two-step process.
The first step, NER,identifies the strings within a sample of text that refer togenes and proteins.
The second step, normalization,determines the specific genes and proteins referred to bythe text strings.Many investigators have examined the initial step ofgene and protein NER.
One of the most successfulrules-based approaches to gene and protein NER inbiomedical texts has been the AbGene system (Tanabeand Wilbur, 2002), which has been used by severalother researchers.
After training on hand-taggedsentences from biomedical text, it applies a Brill-styletagger (Brill, 1992) and manually generated post-processing rules.
AbGene achieves a precision of 85.7%at a recall of 66.7% (F1 = 75%).
Another successfulsystem is GAPSCORE (Chang et al, 2004).
It assigns anumeric score to each word in a sentence based onappearance, morphology, and context of the word andthen applies a classifier trained on these features.
Aftertraining on the Yapex corpus (Franzen et al, 2002), thesystem achieved a precision of 81.5% at a recall of83.3% for partial matches.For many applications of text mining, the second step,normalization is as important as the first step.
Manybiomedical concepts, including genes and proteins, havelarge numbers of synonymous terms (Yu and Agichtein,2003, Tuason et al, 2004).
Without normalization,different terms for the same concept are treated asdistinct items, which can distort statistical and otheranalysis.
Normalization can aggregate references agiven gene or protein and can therefore increase thesample size for concepts with common synonyms.However, normalization of gene and protein referenceshas not received as much attention as the NER step.One recent conference, the BioCreative CriticalAssessment for Information Extraction in Biology(Krallinger, 2004), had a challenge task that addressedgene and protein normalization.
The task was to identifythe specific genes mentioned in a set of abstracts giventhat the organism of interest was mouse, fly, or yeast.Training and test collections of about 250 abstracts weremanually prepared and made available to theparticipants along with synonym lists.
Seven groupsparticipated in this challenge task (Hirschman et al,2004),  with the best F-measures ranging from 92.1% on17yeast to 79.1% on mouse.
The overall best performingsystem used a combination of hand built dictionaries,approximate string matching, and parameter tuningbased on the training data, and performed matchdisambiguation using a collection of biomedicalabbreviations combined with approximate string matchscoring and preferring concepts with a high count ofoccurring terms (Hanisch et al, 2004).One thing that almost all of these systems have incommon is that they need to be trained on a text corpusand/or use manually built dictionaries based on thetraining corpus.
Since the training corpus may be asmall sample of the total relevant biomedical literature,it is uncertain how the performance of these systemswill change over time or when applied to other sourcesof biomedical text.
Also, since new genes and proteinsare being described all the time, it is unclear how thesesystems will handle genes discovered after systemtraining is complete.
This is may especially be aproblem for normalization.Dictionary-based approaches to gene and protein NERand normalization that require no training have severaladvantages over orthographic, lexical, and contextualbased approaches.
Currently there are few testcollections for gene and protein normalization, and theyare relatively small (Hirschman et al, 2004).Unsupervised systems therefore may perform moreuniformly over different data sets and over time for thenear future.
Since they are not dependent upon trainingto discover local orthographic or lexigraphic clues, theycan recognize long multi-word names as easily as shortforms.
Dictionary-based approaches can also normalizegene and protein names, reducing many synonyms andphrases representing the same concept to a singleidentifier for that gene or protein.In addition, dictionary-based approaches can makeuse of the huge amount of information in curatedgenomics databases.
Currently, there is an enormousamount of manual curation activity related to gene andprotein function.
Several genomics databases containlarge amounts of curated gene and protein namesymbols as well as full names.
Groups such as theHuman Genome Organisation (HUGO), Mouse GenomeInstitute (MGI), UniProt, and the National Center forBiotechnology Information (NCBI) collect and organizeinformation on gene and proteins, much of it from thebiomedical literature, including gene names, symbols,and synonyms.
Dictionary-based approaches provide away to make use of this information for gene andprotein NER and normalization.
As the databases areupdated by the curating organization, a NER systembased on these databases can automatically incorporateadditional new names and symbols.
These approachescan also be very fast.
Much of the computation can beperformed during the construction of the dictionary.This can leave the actual searching for dictionary termsa simple and rapid process.Tsuruoka and Tsujii recently studied the use ofdictionary-based approaches for protein namerecognition (Tsuruoka and Tsujii, 2004), although theydid not evaluate the normalization performance.
Theyapplied a probabilistic term variant generator to expandthe dictionary, and a Bayesian contextual filter with asub-sentence window size to classify the terms in theGENIA corpus as likely to represent protein names.Overall they obtained a precision of 71.1%, at a recall of62.3% and an F-measure of 66.6%.
Tsuruoka and Tsujiidid not make use of curated database information, andinstead split the GENIA corpus into training and testdata sets of 1800 and 200 abstracts respectively, andextracted the tagged protein names from the training setto use as a dictionary.
These results compare well to,being a bit below, other non-dictionary based methodsapplied to the GENIA corpus (Lee et al, 2004, Zhou etal., 2004).In this work we attempt to answer several questionspertaining to dictionary-based gene/protein NER:?
What curated databases provide the best collectionof names and symbols??
Can simple rules generate sufficient orthographicvariants??
Can common English word lists be used to decreasefalse positives??
What is the overall normalization performance ofan unsupervised dictionary-based approach?2 MethodsA dictionary-based NER system starts out with a list,potentially very large, of text strings, called terms,which represent concepts of interest.
In our system, theterms are organized by concept, in this case a uniqueidentifier for the gene or protein.
All terms for a givenconcept are kept together.
The combination of termsindexed by concept is similar to a traditional thesaurus,and when used for NER and normalization is usuallycalled a dictionary.
When a term is found in a sample oftext, it is a simple process to map the term to the uniquegene or protein that it represents.
There are severalunique identifiers in use by the gene curationorganizations, we chose to use the official symbol as adefault, but it is easy to use other database identifiers asneeded.2.1 Building the dictionaryBuilding the initial dictionary is an essential first stepin dictionary-based NER.
The dictionaries we used inthis study were built automatically from five databases18available for download: MGI, Saccharomyces, UniProt(the curated SwissProt portion only), LocusLink, andthe Entrez Gene database.
For each of these databases,the official symbol, unique identifiers, name, symbol,synonym, and alias fields were extracted.
Symbols,synonyms, and aliases corresponding to the sameofficial symbol were combined into a single list.
At thisstage in dictionary generation, any leading or trailingwhite space characters are removed.
The originalcapitalization of each term is kept.
This will beimportant in a later stepLike several other investigators (Tanabe and Wilbur,2002, Chang et al, 2004), we do not discriminatebetween the names of genes and the proteins that theycode for.
For many text mining purposes, recognizing amention of a gene or the coded protein has been treatedas equivalent (Cohen and Hersh, 2005).
Therefore,combining terms corresponding to the same officialsymbol is justified, even if one database is composed ofgenes and the other proteins.2.2 Generating orthographic variantsOur previous work on gene and protein name synonyms(Cohen et al, 2005) led us to make the observation thatmany name synonyms are simple orthographic variantsof each other, and that most of these variants can begenerated with a few simple rules.
The next step indictionary generation is to generate variant terms foreach term extracted from the downloaded databases.Our system uses seven simple rules to generatevariants:(1) If the original term includes internal spaces,these can be replaced by hyphens (e.g., ?IL 10?to ?IL-10?).
(2) If the original term includes internal hyphens,these can be replaced by spaces (e.g., ?mmac-1?to ?mmac 1?).
(3) If the original term includes internal spaces orhyphens, these can be removed (e.g., ?nf-kappab?
to ?nfkappab?).
(4) If the original term ends in a letter followed bysingle digit, or a letter followed by single digitand then a single letter, a hyphen can be addedbefore the digit (e.g., ?NFXL1?
to ?NFXL-1?).
(5) If the original term ends in a digit, followed bythe single letter ?a?
or ?b?, we can add a hyphenbefore the ?a?
or ?b?
and also expand ?a?
to?alpha?
and ?b?
to ?beta?
(e.g., ?epm2b?
to?epm2-beta?).
(6) If the original term ends in ?-1?
or a ?-2?, replacethis ending with the Roman numeral equivalent,?-i?
or ?-ii?
respectively.
(7) For yeast only, if the original term consists ofone space-delimited token, append a ?p?
(see(Cherry, 1995)).These rules are applied iteratively until no new termsare generated.2.3 Separating common English wordsThe next step aids in discriminating mentions of geneand protein names from common English words.
Thedictionary now contains a large number of termsextracted from the databases along with generatedvariants.
At this point the dictionary is split into twoparts.
Terms that case-insensitively match a list ofcommon English words are put into the one dictionary,and other terms are put into a separate dictionary.In practice, this creates a small dictionary of termseasy to confuse with common English words (theconfusion dictionary) and a much larger dictionary ofterms that are not confused with English words (themain dictionary).
When searching text for gene andprotein names, the terms in the smaller dictionary willbe handled differently than the terms in the largerdictionary.For the work presented here, a file of 74,550 commonEnglish words was used to filter the terms.
This file isavailable as part of the Moby lexical resource, and isavailable at (Ward, 2000).2.4 Screening out the most common EnglishwordsSome English words are so common that when theyoccur they are rarely references to gene and proteinnames.
Our approach includes a list of about 300English words that is used as a ?stop?
list.
In our systemthese words are never recognized as gene or proteinterms, even if those terms appear in one of the curateddatabases.We obtained our list of the 300 most common wordsin the English language (Carroll et al, 1971).
To thislist we added a few terms that are commonly found inthe biomedical literature that should not be confusedwith specific gene names.
These include ?gene?,?genes?, ?protein?, ?proteins?, ?locus?, ?site?, ?alpha?,?beta?, and ?as a?.Terms appearing in this most common word list areremoved from both of the dictionaries.
The final productof the four preceding steps are two dictionaries, a maindictionary and a confusion dictionary, each which mapterms to the unique identifier for the gene/proteinsymbol corresponding to that term.2.5 Searching the textWith the two dictionaries complete it is straightforwardto search input text for mentions of gene and protein19names.
While the algorithm can handle practically anysize input text, in practice the input will usually beindividual sentences or abstracts, and this is the inputsize to which we have tuned our system.For speed and accuracy, we first search the input textfor the terms within the dictionary, and if a term isfound, we then check to ensure that the matching text isbounded by characters that are acceptable delimiters forgene and protein names.
In our system this includeswhite space characters as well as these characters:.,/\\(){}[]=;?*!".
Note that our approach does notprohibit these characters from appearing within thename, only that the matching sequence of characters isbounded by these delimiters.
Also, the approach doesnot require tokenization of the input string.
We considerthis more flexible than delimiter-based tokenization,which would not allow delimiters to appear within theterms.This method of searching and checking delimiters isapplied for every term in both the main and confusiondictionaries with one essential difference.
Case-insensitive search is performed on the terms in the maindictionary.
Strict case-sensitive search is performed onterms in the confusion dictionary.
This requires terms inthe confusion dictionary to exactly match thecapitalization of the input text.
The observation here isthat a string like ?dark?
appearing in biomedical text ismost often being used as a normal English word, whilea string like ?DARK?, is likely being used as a genename.Finally, the algorithm examines all matching terms onthe input text.
Overlaps are resolved with a combinationof criteria based on comparing the confidence andlength of each recognized entity.
In the currentimplementation, the confidence of the dictionary-basedNER is always 1.0, so in practice the system resolvesoverlap by keeping the entity recognized by the longestoverlapping term and discarding any shorteroverlapping entities.2.6 DisambiguationIt has been shown that a large number of gene andprotein terms refer to more than one actual concept withover 5% of terms being ambiguous intra-species and85% being ambiguous with gene names for otherorganisms (Tuason et al, 2004, Chen et al, 2005).
Fornormalization, occurrences of these ambiguous termsneed to be resolved to the correct concept.
This is calleddisambiguation.Various disambiguation approaches have beenproposed, including the method of Hanisch previouslydescribed, as well as simply ignoring ambiguous terms.Ignoring all ambiguous terms can be wasteful, sincecontext may allow disambiguation to a unique concept.This can helpful for increasing the sample size forfurther text mining.
For example NER andnormalization can be performed on abstracts, andfurther processing (e.g., co-occurrence detection)performed at the sentence level.
Our approach todisambiguation makes two assumptions about thebiomedical literature.
First, ambiguous terms are oftensynonyms for other, non-ambiguous terms within thesame text sample, and second, authors usually explicitlyprovide sufficient context for readers to resolveambiguous terms.For each ambiguous term, we collect the potentialnormalized concepts.
If any of those concepts appears inthe text sample using an unambiguous term for thatconcept, we assign the ambiguous term to the conceptwith the unambiguous term.
If there is more than oneconcept with an unambiguous term (this occursinfrequently), we select one of these concepts atrandom.
We ignore terms that cannot be resolved in thismanner.
Notice that this is a general dictionarydisambiguation algorithm and does not require anyinformation specific to genes and proteins.2.7 OptimizationOne of the benefits of the dictionary-based approach isthat it is simple and amenable to code optimization.
Inour case we were able to gain almost a thousand-foldspeed improvement over brute force searching againstevery term in the database.
We accomplished this usingan approach based on indexing the term prefixes, takingeach unique sequence of n initial term characters as theindex for all terms with that initial sequence.
In oursystem we chose an n of 6 as a good balance betweenperformance and memory requirements.Searching for gene and protein terms then becomes anefficient matter of only searching for the terms thatcorrespond to 6 character sequences (prefixed by adelimiter) that actually exist in the input text.
Thisgreatly reduces the number of searching operationsnecessary.
While other more complex optimizationalgorithms are possible, such as organizing the termscharacter-by-character into an n-way tree, or completelygrouping the terms into a complete prefix tree, ourapproach is simple, very fast, and has modest memoryneeds.3 EvaluationWe based our evaluation on two test corpora that havebeen previous used to evaluate gene and protein NERand normalization.
We used the GENIA corpus, version3.02 (Kim et al, 2003), to evaluate the utility of eachonline database as a source of terms for gene andprotein NER, and we used the BioCreative Task1B20mouse and yeast collections to evaluate the performanceof our system for normalized gene and proteinidentification.The GENIA corpus is a key resource in biomedicaltext mining, and has been used by many investigators(e.g., (Collier and Takeuchi, 2004, Lee et al, 2004,Tsuruoka and Tsujii, 2004)).
However, some system-dependent decisions still need to be made in order to useit as a gold standard for gene and protein NER.
First,GENIA marks genes separately from proteins.
Whilethe ?protein_molecule?
attribute appears to be used in amanner that tightly and specifically delimits mentions ofproteins, other attributes such as the?DNA_domain_or_region?
attribute and the?protein_family_or_group?
attribute are used moreloosely.
?DNA_domain_or_region?
can be used tomark a specific gene (e.g., ?IL-2 gene?, ?peri kappa-Bsite?
), sometimes including words such as ?gene?
and?site?.
At other times the attribute marks a non-specificgene concept (e.g., ?viral gene?).
Similar observationsare true about the ?protein_family_or_group?
attributes(e.g., ?CD28?, ?transcription factor?).
Clearly whenevaluating dictionary-based (possibly as opposed tocorpus trained) gene/protein NER, many of the conceptsmarked with the  ?DNA_domain_or_region?,?protein_family_or_group?
and other similar attributesshould be treated as correct for the purposes ofprecision.
However, the large number of more genericconcepts that these attributes mark should not beincluded in the calculation of recall.Because of these issues, here we have used a hybridtechnique in order to produce the most meaningfulresults in choosing a database for wide coverage of geneand protein names and symbols.
Entities marked withthe ?protein_molecule?
attribute are included forcomputation of both precision and recall.
The textmarked with the DNA and protein family attributes areonly used for the computation of precision.
This methodis different from that applied by others using theGENIA corpus for both training and testing andtherefore our NER results here are not directlycomparable to prior work using GENIA.In the first set of experiments we are primarilyconcerned with evaluating the richness of each databaseand combination of databases as a source of names forgene and protein NER.
Therefore, we use the weakmatch criteria of Chang et al, to evaluate performance(Chang et al, 2004).
The weak match criteria treats anyoverlap of identified text with the gold standard as apositive.In the second set of experiments we use theBioCreative mouse and yeast test collections to evaluatethe performance of our unsupervised dictionary-basedmethod of gene and protein NER and normalization.
Formouse, the more challenging organism, we evaluate theeffect of each system feature separately and incombination.
We also evaluate the effect of using justthe organism-specific database to populate thedictionary, along with the organism-specific database incombination with the richest database determined in thefirst set of experiments.
Table 1 shows information onthe databases that were used to generate the dictionariesand the fields taken from each database.4 ResultsTable 2 presents the results of applying our dictionary-based NER to the GENIA 3.02 corpus using the threemulti-organism databases individually.
The Entrez Genedatabase performs the best, having both the highest F-measure of 75.5% at a precision of 73.5% and a recallof 77.6%.
The LocusLink database is next, and notsignificantly different in performance (LocusLink isbeing phased out and replaced with Entrez Gene as ofMarch 2005).
The UniProt database performs muchworse overall.
This is surprising, performing well onprecision at 78.5%, but having recall of 59.1%, poorerthan we expected for a multi-species database.Table 1.
Databases used to create protein/gene NER dictionaries.Fields marked with an asterisk were used as the unique identifier.Table 2.
Results of creating dictionary from a single database forNER of GENIA genes and proteins.DictionaryDatabase &Precision Recall F-measureEntrez 0.735 0.776 0.755LocusLink 0.723 0.773 0.747UniProt 0.785 0.474 0.591OrganismFields used DictionarySizeEntrezmulti-organismSYMBOL*, SYNONYMS, 59 MbytesDESCRIPTIONLocusLinkmulti-organismPRODUCT,OFFICIAL_SYMBOL*,PREFERRED_SYMBOL,OFFICIAL_GENE_NAME,PREFERRED_GENE_NAME,PREFERRED_PRODUCT,ALIAS_SYMBOL,ALIAS_PROT14 MbytesMGImouse onlyMGI MARKER ACCESSIONID*,MGI GENE TERM,STATUS7 MbytesUniProtmulti-organismName*, Synonyms,OrderedLocusNames,ORFNames5 MBytesSaccharomycesyeast onlyLocus, ORF, SGID*, alias,standard name, feature name1.5 MBytes21Table 3.
Results of creating dictionary from a combination of twodatabases for NER of GENIA genes and proteins.Dictionaries Precision Recall F-measureEntrez 0.735 0.776 0.755Entrez+UniProt 0.707 0.792 0.747Entrez+LocusLink 0.734 0.780 0.756Table 4.
Results of using dictionary created from databases for NERand normalization for mouse.Dictionary Precision Recall F-measureEntrez/MGI 0.775 0.726 0.750MGI 0.710 0.535 0.610Having found that Entrez Gene was the single bestonline database for dictionary creation, we triedcombining it with the other databases.
As can be seenfrom Table 3, this did not result in any meaningfulperformance improvement.For the remainder of our experiments we used theBioCreative mouse and yeast test collections and goldstandard files to evaluate the performance of our systemfor gene/protein NER and normalization.
The goldstandard required the unique identifiers to be MGI orSGD accession numbers.
To accomplish this, weperformed a join between the Entrez database and theMGI (or Saccharomyces) database using a mappingidentifier between the MGI (or SGI) database entriesand the Entrez Gene ids while extracting dictionaryterms.Table 4 shows the results of using the joinedEntrez/MGI dictionary for mouse NER andnormalization compared to using the dictionary createdfrom the MGI database alone.
Using the MGI databasealone has much worse recall than using the dictionarycreated with a combination of Entrez and MGIdatabases, with recall falling almost 20%.
Restrictingthe dictionary to the MGI database also results in a6.5% decrease in precision.Table 5 shows the results of individually removingeach of the three main dictionary pre-processingfeatures and the disambiguation algorithm andevaluating the NER and normalization performance formouse.
All four of these variations perform worse thanour full system.
Variant generation made the smallestdifference, giving an F-measure improvement of 2.0%.Ambiguity resolution improves the F-measure 2.8%.The 300 most common word stop list contributed animprovement of 6.8%.
Lastly, separation into case-sensitive and case-insensitive dictionaries made thelargest improvement of 15.6%.
Removing all of the pre-processing features at once and using the combinedEntrez/MGI database as a ?raw?
term list performs verybadly, with good recall but a precision of only 30.1%.Table 6 compares the results of our system to theparticipants of BioCreative Task 1B for the mouse andyeast corpora.
On both mouse and yeast, our systemperforms above the median F-measure.
On mouse thedifference in F-measure between our system and the topscoring system is less than 5%.
On the yeast corpus, ourapproach has among the highest precision, with recallslightly below the median, and F-measure about 3%below the highest scoring system.While ambiguity resolution resulted in a modestimprovement, we wanted to get an idea of themagnitude of the ambiguity within our automaticallycreated dictionaries.
Table 7 shows the number andpercentage of ambiguous terms and genes with at leastone ambiguous term in the dictionaries that we createdusing Entrez in combination with the MGI database, aswell as MGI alone.The system runs very rapidly.
On a 1.7GHz Pentium4m laptop with 512M RAM, the 18,000 sentences in theGENIA corpus were processed in about 30 seconds.
The250 abstracts in the BioCreative corpora were processedin less than 5 seconds.5 DiscussionThe Entrez Gene database was identified as the bestgeneral-purpose source of gene and protein terms foruse in a dictionary-based NER and normalization.Including data from other databases did not improveNER performance.
It appears that the producers ofEntrez Gene are doing an excellent job in finding andcurating this information from the available sources.One of the most common difficulties cited inrecognizing gene and protein names is that thevocabulary of terms is continuously expanding(Hirschman et al, 2002).
Online databases, such asEntrez Gene provide a curated central repository forthese terms, making the task of keeping gene/proteinNER and normalization systems up to date on newgenes and proteins somewhat easier.All three of our dictionary pre-processingenhancements improved performance, as did theambiguity resolution algorithm.
Surprisingly, variantgeneration made the smallest difference in F-measure.This may be due to the tendency for genes to bementioned multiple times within an abstract, or thatauthors are keeping to the forms collected in thegenomics databases, or that the database curators aredoing a good job in keeping up with the terms used byauthors.
The BioCreative test collection scoresnormalization at the level of an entire abstract.
It ispossible that variant generation might have made alarger difference if the test collection was scored at asentence level.
On the other hand, it may be that the22Entrez database itself contains sufficient variants.
Ineither case, the small improvement gained from variantgeneration suggests that computationally expensiveapproximate string matching techniques may not beworth the effort.The next largest improvement was made by ambiguityresolution.
Precision increased almost 8%, while recalldropped only about 2%.
While an F-measureimprovement of 2.8% is small, this figure is highlydependent upon the make up of the test corpus.Certainly, as seen in Table 7, there are a largeproportion of mouse genes with ambiguous terms in ourdictionary.
How often these ambiguous terms actuallyappear in the literature is an open question.
Additionaland larger test collections may be necessary toaccurately measure the overall importance of ambiguityresolution.Table 5.
NER and normalization performance results when removingdictionary pre-processing features and ambiguity resolution formouse.System Precision Recall F-measure Differencefull system 0.775 0.726 0.750 -- case 0.493 0.746 0.594 -15.6%- stop 0.643 0.726 0.682 -6.8%- variant 0.771 0.693 0.730 -2.0%- ambiguity 0.697 0.748 0.722 -2.8%- all 0.301 0.713 0.423 -32.7%Table 6.
Comparison with results from BioCreative on mouse andyeast corpora.Organism System Precision Recall F-measurebiocreative-highest 0.765 0.819 0.791cohen 0.775 0.726 0.750biocreative-median 0.765 0.730 0.738Mousebiocreative-lowest 0.418 0.898 0.571biocreative-highest 0.950 0.894 0.921cohen 0.950 0.837 0.890biocreative-median 0.940 0.848 0.858Yeastbiocreative-lowest 0.661 0.902 0.763Table 7.
Term ambiguity measurements for mouse genes.Entrez/MGI MGI# All Distinct Genes 57185 57180# All Distinct Terms 336353 250435# Ambiguous Terms 6585 (1.96%) 2104 (0.84%)# Genes w/ AmbiguousTerms 8036 (14.05%) 2619 (4.58%)The stop-list made the next largest improvement in F-measure, 6.8%.
Use of the stop list improved precisiongreatly and did not change recall.
Case-sensitivity usingthe common word file made the largest improvement of15.6%.
While making a large, almost 30% difference inprecision, case sensitivity decreased recall by only 2%.Overall, all three of the dictionary pre-processingmethods we applied worked well, as did ambiguityresolution.
Each method resulted in improvement ineither precision or recall, and did not greatly degrade theother measure.
Together the three techniques gave an F-measure improvement of over 30% as compared tousing a plain unprocessed dictionary.Chen et al investigated the ambiguity of official genenames within and across organisms and found the levelof shared official names within an organism to be low(~0.02%) but the level of ambiguity when consideringall terms associated with a gene to be higher, about 5%(Chen et al, 2005).
Our results are similar, with about5% of genes in the MGI database having terms alsoassociated with other genes.
This rises to 14% whencombined with the information in the Entrez database.As previously noted, inter-organism ambiguity is muchhigher.
Further work is needed to determine the extentof the problem present within in the actual literature.We did not apply our method to fly, the otherorganism in the BioCreative Task 1B test collection.
Wewere unable to find direct mappings between identifiersin the fly database and Entrez Gene.
Moreover, the flycorpus would present special problems for our method.Unlike for mouse and yeast, the fly genome containsmany genes that have the same names as commonEnglish words, and the use of these words as genenames are not commonly delineated using capitalizationas they are with mouse.
For fly at least, methods such asours are at a disadvantage compared to trained systems.However, the literature of one of the most importantand interesting genomes (at least to us), human, doesappear to follow the practice of differentiating commonEnglish words from gene and protein names byuppercase or initial capitalization similar to the mouseliterature (Chen et al, 2005).
Therefore we expect thatour unsupervised approach will be useful for humangenomics literature as well.Unfortunately at the present time we are unable to testthis hypothesis.
We are unaware of any human geneNER and normalization test collection.
While there areseveral test collections widely available for NER alone(Franzen et al, 2002, Kim et al, 2003, Hu et al, 2004),the same cannot be said for the essential normalizationstep.
More and larger collections, covering additionalorganisms such as human and rat, are necessary tomeasure and motivate progress in gene and protein NERand normalization.236 Conclusions and Future WorkThese results demonstrate that an unsuperviseddictionary-based approach to gene and protein NER andnormalization can be effective.
The dictionaries can becreated automatically without human intervention orreview.
Dictionary-based systems such as ours can beset up to automatically update themselves bydownloading the database files on the Internet and pre-processing the files into updated dictionaries.
This couldbe done on a nightly basis if necessary, since the entiredictionary creation process only takes a few minutes.One general database, combined with an organism-specific database for each species, is sufficient.Our work is distinguished from other dictionary-basedwork such as Tsurukoka and Tsujii, and Hanisch et alin several ways.
Unlike both of these prior investigators,we use on-line curated information as our primarysource of terms, instead of deriving them from a trainingset, and have shown both which databases to use andhow to process them into effective sources of terms forNER.
Our textual variants are generated by simple rulesdetermined by domain knowledge instead of machinelearning on training data.
Lastly, the disambiguationalgorithm presented here is unique and has been shownto have a positive impact on performance.The system is as accurate as other more complexapproaches.
It does not require training, and so may beless sensitive to specific characteristics of a given textcorpus.
It may also be applied to organisms for whichthere do not exist sufficient training and test collections.In addition, the system is very fast.
This may enablesome text mining tasks to be done for users in real time,rather than the batch processing mode that is currentlymost common in biomedical text mining research.Dictionary-based approaches are likely to remain anessential part of gene and protein normalization, even ifthe NER step is handled by other methods.
Further workis necessary to determine the best manner to combineautomatically created dictionaries with trained NERsystems.
It may be the case that different approacheswork best for different organisms, depending upon thespecific naming conventions of scientists working onthat species.ReferencesBrill, E. (1992) A simple rule-based part of spech tagger.
InProceedings of the Third Conference on Applied NaturalLanguage Processing.Carroll, J.
B., Davies, P. and Richman, B.
(1971) TheAmerican heritage word frequency book.
Houghton Mifflin,Boston,.Chang, J. T., Schutze, H. and Altman, R. B.
(2004)GAPSCORE: finding gene and protein names one word at atime.
Bioinformatics, 20, 216-25.Chen, L., Liu, H. and Friedman, C. (2005) Gene nameambiguity of eukaryotic nomenclatures.
Bioinformatics, 21,248-56.Cherry, J. M. (1995) Genetic nomenclature guide.Saccharomyces cerevisiae.
Trends Genet, 11-2.Cohen, A. M. and Hersh, W. (2005) A Survey of CurrentWork in Biomedical Text Mining.
Briefings inBioinformatics, 6, 57-71.Cohen, A. M., Hersh, W. R., Dubay, C. and Spackman, K.(2005) Using co-occurrence network structure to extractsynonymous gene and protein names from MEDLINEabstracts.
BMC Bioinformatics, 6,Collier, N. and Takeuchi, K. (2004) Comparison of character-level and part of speech features for name recognition inbiomedical texts.
J Biomed Inform, 37, 423-35.Franzen, K., Eriksson, G., Olsson, F., Asker, L., Liden, P. andCoster, J.
(2002) Protein names and how to find them.
Int JMed Inf, 67, 49-61.Hanisch, D., Fundel, K., Mevissen, H. T., Zimmer, R. andFluck, J.
(2004) ProMiner: Organism-specific protein namedetection using approximate string matching.
InBioCreative: Critical Assessment for InformationExtraction in Biology.Hirschman, L., Morgan, A.
A. and Yeh, A. S. (2002) Rutabagaby any other name: extracting biological names.
J BiomedInform, 35, 247-59.Hirschman, L., Colosimo, M., Morgan, A., Columbe, J. andYeh, A.
(2004) Task 1B: Gene List Task BioCreAtIveWorkshop.
In BioCreative: Critical Assessment forInformation Extraction in Biology.Hu, Z.
Z., Mani, I., Hermoso, V., Liu, H. and Wu, C. H.(2004) iProLINK: an integrated protein resource forliterature mining.
Comput Biol Chem, 28, 409-16.Kim, J. D., Ohta, T., Tateisi, Y. and Tsujii, J.
(2003) GENIAcorpus - a semantically annotated corpus for bio-textmining.Bioinformatics, 19, i180-i182.Krallinger, M. (2004) BioCreAtIvE - Critical Assessment ofInformation Extraction systems in Biology.http://www.pdg.cnb.uam.es/BioLINK/BioCreative.eval.htmlLee, K. J., Hwang, Y. S., Kim, S. and Rim, H. C. (2004)Biomedical named entity recognition using two-phasemodel based on SVMs.
J Biomed Inform, 37, 436-47.Tanabe, L. and Wilbur, W. J.
(2002) Tagging gene and proteinnames in biomedical text.
Bioinformatics, 18, 1124-32.Tsuruoka, Y. and Tsujii, J.
(2004) Improving the performanceof dictionary-based approaches in protein name recognition.J Biomed Inform, 37, 461-70.Tuason, O., Chen, L., Liu, H., Blake, J.
A. and Friedman, C.(2004) Biological nomenclatures: a source of lexicalknowledge and ambiguity.
Pac Symp Biocomput, 238-49.Ward, G. (2000) Grady Ward's Moby.http://www.dcs.shef.ac.uk/research/ilash/Moby/mwords.htmlYu, H. and Agichtein, E. (2003) Extracting synonymous geneand protein terms from biological literature.
Bioinformatics,19, i340-i349.Zhou, G., Zhang, J., Su, J., Shen, D. and Tan, C. (2004)Recognizing names in biomedical texts: a machine learningapproach.
Bioinformatics, 20, 1178-90.24
