Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 732?741,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsA Summariser based on Human Memory Limitations andLexical CompetitionYimai FangComputer LaboratoryUniversity of Cambridge15 JJ Thomson Avenue, CB3 0FD, UKYimai.Fang@cl.cam.ac.ukSimone TeufelComputer LaboratoryUniversity of Cambridge15 JJ Thomson Avenue, CB3 0FD, UKSimone.Teufel@cl.cam.ac.ukAbstractKintsch and van Dijk proposed a modelof human comprehension and summarisa-tion which is based on the idea of pro-cessing propositions on a sentence-by-sentence basis, detecting argument over-lap, and creating a summary on the basisof the best connected propositions.
Wepresent an implementation of that model,which gets around the problem of identi-fying concepts in text by applying coref-erence resolution, named entity detection,and semantic similarity detection, imple-mented as a two-step competition.
Weevaluate the resulting summariser againsttwo commonly used extractive summaris-ers using ROUGE, with encouraging re-sults.1 IntroductionKintsch and van Dijk (1978) (henceforth KvD)present a model of human comprehension andmemory retention which is based on research in ar-tificial intelligence, experimental psychology anddiscourse linguistics.
It models the processing ofincoming text or speech by human memory lim-itations, and makes verifiable predictions aboutwhich propositions in a text will be recalled bysubjects later.
It has been very influential, particu-larly in the 1980 and 1990s in educational (Palin-scar and Brown, 1984; King, 1992) and cognitive(Paivio, 1990) psychology, and is still today usedas a theoretical model of reading and comprehen-sion (Baddeley, 2007; Zwaan, 2003; DeLong etal., 2005; Smith, 2004).
It has also been used forimproving education, particularly for the produc-tion of better instructional text (Britton and Gul-goz, 1991; Pressley, 2006), and for teaching hu-mans how to read for deep comprehension (Coiroand Dobler, 2007; Duke and Pearson, 2002; Koda,2005; Driscoll, 2005) and to summarise (Hidi,1986; Brown et al., 1983).In the summarisation community, the model hasbeen commended for its elegant and explana-tory ?deep?
treatment of the summarisation pro-cess (Lehnert, 1981; Sp?arck Jones, 1993; Endres-Niggemeyer, 1998), but has not lead to any prac-tical prototypes, mainly due the impossibility ofimplementing the knowledge- and inference-basedaspects the model relies on.We present here an implementation of the model,which attempts to circumvent some of these prob-lems by the application of distributional seman-tics, and by modelling the construction of the co-herence tree as a double competition (firstly ofconcept partners for word forms, secondly of at-tachment sites for propositions).In the KvD model, a text (e.g.
Figure 1) is con-verted into propositions (see Table 1) which haveone functor and one or more arguments.
The func-tor can be taken either from a fixed list of gram-matical relations (e.g.
IS A; AT; BETWEEN; OR)or an open class-set of so-called concepts, (e.g.BLOODY; TEACH).
Arguments can be conceptsor proposition numbers.
Proposition numbers ex-press embedded semantic structures (e.g.
#9 inTable 1).
Kintsch et al.
(1979) assumed that thistranformation is performed manually; they wereable to train humans to do so consistently.A series of violent, bloody encounters between policeand Black Panther members punctuated the early sum-mer days of 1969.
Soon after, a group of black studentsI teach at California State College, Los Angeles, whowere members of the Panther Party, began to complainof continuous harassment by law enforcement officers.Figure 1: First two sentences from the exampleparagraph Bumperstickers by KvD (1978).732No.
PropositionCycle 11 SERIES (ENCOUNTER)2 VIOLENT (ENCOUNTER)3 BLOODY (ENCOUNTER)4 BETWEEN (ENCOUNTER, POLICE, BLACK PAN-THER)5 TIME: IN (ENCOUNTER, SUMMER)6 EARLY (SUMMER)7 TIME: IN (SUMMER, 1969)Cycle 28 SOON (#9)9 AFTER (#4, #16)10 GROUP (STUDENT)11 BLACK (STUDENT)12 TEACH (SPEAKER, STUDENT)13 LOCATION: AT (#12, CAL STATE COLLEGE)14 LOCATION: AT (CAL STATE COLLEGE, LOSANGELES)15 IS A (STUDENT, BLACK PANTHER)16 BEGIN (#17)17 COMPLAIN (STUDENT, #19)18 CONTINUOUS (#19)19 HARASS (POLICE, STUDENT)Table 1: Propositions for Figure 1.The KvD algorithm is manually simulated in theirwork, but is described in a mechanistic mannerthat should in principle lend itself to implemen-tation, once propositions are created.
Propositionsform a tree where a proposition is attached to an-other proposition with which they share at leastone argument; attachment higher in the tree is pre-ferred.
The tree is built incrementally; blocks ofpropositions, each of which roughly correspond-ing to one sentence, are processed in cycles.
Af-ter each cycle, a process of ?forgetting?
is sim-ulated by copying only the most salient proposi-tions to the short-term memory (STM).
This se-lection is performed by the so-called leading edgestrategy (LES), which prefers propositions thatare attached more recently and those attached athigher positions.
This algorithms mirrors vanDijk?s (1977) model of textual coherence.When choosing an attachment site for proposition,arguments which are currently in STM are pre-ferred.
A resource-consuming search in long-termmemory (LTM) is only triggered if a propositioncannot be attached in STM; in that case a bridgingproposition is reintroduced into the tree.The KvD model can be used to explain human re-call of stories, and can also to create a summary ofa text.
The most natural way for a human to sum-marise from scratch is to replace propositions withso-called macropropositions, and the KvD modelprefers this style of summary creation.
An exam-ple for macroproposition is a statement that gen-eralises over other propositions.
This results in amore abstract version of the text.
However if forany reason it is not possible to create macropropo-sitions (for instance due to lack of deep knowledgerepresentation), a summary can also be created ina simpler way based only on the propositions con-tained in the text.
In that case, the selection cri-terion is the number of cycles a proposition hasremained in STM.There are three main stumbling blocks in the wayof an implementation of the KvD model:1.
The automatic creation of propositions fromtext, and of summary text from summarypropositions;2.
The automatic creation of concepts fromwords (including coreference resolution);3.
The creation of macropropositions, whichwould require sophisticated knowledge rep-resentation and reasoning.We present a fully automatic version of the KvDmodel based on the following assumptions:1.
Current parser technology allows us to recon-struct the compositional semantics of the textwell enough to make the KvD model opera-tional, both in terms of creating propositionsfrom text, and in terms of creating reasonablyunderstandable output text from propositions(even if not fully grammatical).2.
We model the lexical variation of how a con-cept is expressed in a text probabilisticallyby semantic similarity and coreference reso-lution.
This creates a competition betweenplausible expressions for argument overlap.3.
Our core algorithm is modelled as two com-petitions: (a) the competition between con-cept matches as mentioned in the pointabove; and (b) the competition between pos-sible positions in a tree where a propositioncould attach.4.
We also observed that KvD?s method ofchoosing the tree root in the first processingcycle, and to never change it afterwards un-less texts are truly incoherent (resorting tomultiple trees), is too limiting, in particu-lar in combination with their LES.
Texts canhave topic changes and still be perfectly co-733herent, particularly if they are longer and lesslinearly structured than the examples usedby KvD.
We therefore experiment with moreflexible root choice strategies.We have nothing to say on the third and biggestobstacle, the creation of macropropositions.
Nev-ertheless, the experiments presented here testwhether our hypotheses 1 ?
4 are strong enoughto provide our summariser with useful informa-tion concerning the discourse structure of the texts.We test this by comparing its performance to thatof two current state-of-the-art summarisers, whichinstead rely on the sole use of lexical informa-tion.
A psychologically-motivated summarisersuch as ours should be evaluated by compari-son to abstractive, i.e., reformulated human sum-maries, rather than by comparison to extractivesummaries.
We do so using ROUGE, an evalu-ation framework that supports such comparisons(Lin and Hovy, 2003).The structure of the paper is as follows.
In thenext section, we will detail our implementation ofthe KvD model, with particular emphasis on thecreation of propositions, probabilistic concepts,proposition attachment, and root choice.
In Sec-tion 4, we will present experiments comparing oursummariser against two research extractive sum-marisers, MEAD and LexRank.
We also test howour inventions including similarity-based conceptmatching and root choice strategy contribute toperformance.
We compare to related work in Sec-tion 3, and draw our conclusions in Section 5.2 Our implementation of KvDFigure 2 shows the structure of our summariser.The Proposition Creation module transforms sur-face text to propositions with the aid of a grammat-ical parser.
Recall that in the original KvD model(shown as ?Human (KvD)?
), propositions are gen-erated manually.
Apart from such, our implemen-tation follows the KvD algorithm as closely aspossible.
The core of this algorithm is the Mem-ory Retention Cycle in the centre of the figure.A cycle begins with the detection of coherence be-tween the new propositions and the current STMcontent.
This results in a hierarchy of all so-farprocessed propositions called the Coherence Tree.Propositions are attached to the tree by a variety ofstrategies, as explained in Subsection 2.2.Input: Full textParserProposition BuilderDependenciesHuman (KvD)PropositionsCoherence DetectorCoherence TreeSelectorIPs in STMSummary propositionsExtractorHuman (KvD)Output: Summary textEach sentenceMost frequent onesProposition CreationMemory RetentionCycleProposition totextLTMFigure 2: Framework of the summariser.At the end of each cycle, important propositions(IPs) are selected by the Selector, stored in STM,and thus retained for the next cycle, where they areavailable for new incoming propositions to attachto.
The selector is a full implementation of KvD?sLES, which also updates the recency of proposi-tions reinstantiated from the LTM.1Less impor-tant propositions leave the cycle and go into theLTM, which is conceptually a secondary reposi-tory of propositions to provide the ?missing links?when no coherence between the STM and the in-coming propositions can be established.After the text is consumed, a propositional repre-sentation of the summary is created by recallingthe propositions that were retained in STM mostfrequently.
The summary text is then either cre-ated manually (in the KvD model), or in our im-plementation, as a prototype, automatically by ex-tracting words from the parser?s dependencies.2.1 Proposition builderWe aim to create propositions of comparable se-mantic weight to each other.
This is a consequenceof our decision to recast KvD as a competitionmodel (as will become clear in subsection 2.2),because by defining propositions as blocks of ar-guments they should contain a similar number of1KvD implied this in the last cycle of the Bumperstick-ers paragraph, by placing the two reinstantiated propositionsbelow #37, though they are older than #37.734meaningful arguments to ensure similar potentialfor overlap.To achieve suitable granularity of propositions,we aggregate information spread out over severalgrammatical dependencies, and exclude semanti-cally empty words from participating in argumentoverlap.
We use Stanford Parser (Klein and Man-ning, 2003), and aggregate subjects and comple-ments of a predicate into a single proposition.
Ac-tive and passive voices are unified; clauses aretreated as embedded propositions; controlling sub-jects of open clausal complements are recovered.Some predicates are not verbs, but nominalisedverbs or coordination.
For instance, KvD modelthe phrase ?
encounters between police and BlackPanther Party members ?
as BETWEEN (EN-COUNTER, POLICE, BLACK PANTHER).
Produc-ing such a proposition instead of two separateones BETWEEN (ENCOUNTER, POLICE) and BE-TWEEN (ENCOUNTER, BLACK PANTHER) is ad-vantageous, because this single proposition pro-vides a strong connection between POLICE andBLACK PANTHER which cannot be derived fromother dependencies.However we lack a subcategorisation lexicon thatprovides information about how many argumentsa preposition like ?between?
takes.
Therefore wescan conjoined prepositional phrases, aggregatethe objects, and attach them to the governors of theprepositional phrases.
In this example, the result-ing preposition is ENCOUNTER (POLICE, MEM-BER).
The word ?between?
is excluded because itis semantically empty and may interfere with over-lap detection.We take care to detect and exclude semanticallyempty material.
For instance, the empty semanticheads in noun phrases such as ?a series of?
and ?agroup of?
are detected using a list of of 21 wordswe collected, and treated by redirecting the depen-dencies involving the empty heads to the corre-sponding content heads.
In this treatment, the rela-tion between an empty head and its content head isnot entirely erased, but encoded as a general mod-ifier relation.2.2 Probabilistic concept matchingThe notion of argument overlap in KvD?s modelis sophisticated in that it ?knows?
which surfaceexpressions (pronouns, synonyms, etc) in text re-fer to the same concept.
Concept mapping is thetask of forming equivalence classes of surface ex-pressions; each concept then corresponds to onesuch equivalence class.
The KvD model, becauseit simulates concept mapping and proposition at-tachment in parallel, conceals some of the choicesthat a fully automatic model has to make.Given current technology, concept mapping canonly be performed probabilistically.
We use theStanford coreference resolution, named-entity de-tection (to extend coreference detection to non-same-head references, e.g.
mapping ?the techgiant?
to ?Apple Inc.?2); and to find synonymyor at least semantic relatedness, we use a well-known measure of semantic similarity, namelyLin?s Dependency-Based Thesaurus (Lin, 1998).We are not committed to this particular measure,but it empirically performed best out of the 11 wetried; especially it outperformed WordNet path-based measures.
Note however that only the 200most similar words for each word are provided bythis tool.
The similarity measure is normalised byrelative ranking to provide the probability that anexpression refers to the same concept as anotherexpression.
We use WordNet (Miller, 1995) forderivationally related forms (to solve e.g.
nomi-nalisation).
This establishes the first competition,the one between concept matches.policeBlack Pan-ther memberslaw enforce-ment officersmembers of thePanther Party1 111Figure 3: KvD?s concept matching.policeBlack Pan-ther memberslaw enforce-ment officersmembers of thePanther Party0.99 0.6700.331 10.010Figure 4: Probabilistic concept matching.Modelling concepts probabilistically has its impli-cation for the next task: finding the best attach-ment site for a proposition.
Let us explain this withan example.
Notice that in the example text in Fig-ure 1, ?police?
(from #4, in the first sentence) and2A WordNet synset is defined for each named-entity type;here ?giant?
is connected to its hypernym ?organization?
via?enterprise?.735?law enforcement officer?
(from #19, in the sec-ond sentence) refer to the same concept POLICE.Figure 3 illustrates how this is handled in KvD?smodel, where intelligent concept matching estab-lishes with 100% certainty that the two strings re-fer to the same concept.
Certainty about the ar-gument overlap then enables them to later attach#19 to #4.
In their model it is important whethera matching proposition is found in STM or LTM:If the only proposition that mentions ?police?
(#4)is no longer in STM when the proposition contain-ing ?law enforcement officer?
(#19) is processed,and for any reason the other arguments in #19 (i.e.STUDENT) cannot find overlaps either, KvD findno concept match in STM and know therefore,again with full certainty, that an LTM search mustbe triggered3, which in this case leads to the suc-cessful recall of #19 for #4 to attach to.Figure 4 illustrates the corresponding situation inour model, where #4 with ?police?
is in LTM, theprobability of a concept match between ?law en-forcement officer?
and ?police?
is 66.7%, whereasthat of a match with ?members?, which is in STM,is 33.3%.
The probabilistic concept matching can-not provide enough certainty to single out #4 be-cause of full argument overlap.
The probabilitiesof concept match have to act as a much weakerfilter in our model, and all previous propositionshave to be considered as potential landing sitesfor #19.
In particular, we do not know whethera concept match within STM is ?good enough?,or whether a LTM search is needed.
There is, inthis case, a competition between a weak match inSTM (the direct vicinity) and a strong match inLTM (further away), which will hopefully resultin a successful match between ?police?
and ?lawenforcement officer?.
In other words, we alwayshave to search for matches in both repositories.After obtaining the graph of interrelated expres-sions, the competition between landing sites foreach proposition takes place, whereby higher po-sitions are preferred.
This double competition is acore aspect of our model.2.3 Choice of rootThe KvD model almost always maintains the rootdetermined in the first cycle (either by overlap3KvD only mentioned retrieving embedded propositionsas LTM search rarely happens, but the goal is the same ashere: to establish overlap.with title concepts or by coverage of the mainclause of the first sentence).
The model intro-duces multiple roots if a text is totally incoher-ent, namely when propositions cannot be attachedanywhere and therefore a forest of disjoint treeshas to be developed.
This strategy does not gen-eralise well to longer texts with topic changes,for example newspaper texts with anecdotal leads.Although these texts are perfectly coherent, KvDcannot treat them appropriately.4Our more flexible rooting strategy is run oncein each cycle, assessing whether any of the cur-rent root?s children in the working memory wouldmake a better root.
In case of a root change, theedge between the old and the new root is reversed,and the old root becomes a child of the new root.Then we perform the same strategy on the new treeuntil no root change is needed.We denote the current root as i, and a new rootcandidate (a child of i) j. J is the set of descen-dants of j (inclusive of j), and I the set of all nodesV excluding J , i.e.
I = V \ J .
Then nodes in Jwill be promoted after the root change, while thosein I will go one level deeper.
Since edge weights,i.e.
attachment strengths, are asymmetric, we de-note the weight for j being a child of i as wi,j, andwj,ifor the reversed attachment.
Each node v alsocarries a weight xv= mv?
adv, where mvis amemory status factor (e.g.
mv= 1 if v is in STM,0.5 if otherwise), 0 < a ?
1 is an attenuation fac-tor, and dvis depth of v in the tree.
To decide, weevaluates = wj,i?v?Jxv?
wi,j?v?Ixv(1)If s > 0, the root change is permitted.5This evalu-ation makes root change easier if the edge in ques-tion favours i being a child of j, or there are moreimportant nodes that can benefit from the change,and vice versa.An example of such a root change taken from theBumperstickers is given in Figure 5 (refer to Ta-ble 1 for proposition contents).
As the centraltopic of the text changes from the encounters to4In our scenario the situation can barely ever arise whereabsolutely no proposition attachment is possible, as the prob-abilistic concept mapping is usually able suggest some con-cept match, albeit with small probability.5In case when multiple candidates are permitted, the onewith the highest s is chosen.736that the identity of Panther Party members are ac-tually the author?s students, the summariser recog-nises this change after reading one more sentence,by flipping the edge connecting #3 and #14.3 2 4 14 16 17 183 2 4 14 16 17 18Figure 5: Tree before and after a root change.3 Related WorkOne of the dilemmas in summarisation research ishow ?deep?, i.e.
semantics-oriented, a summarisershould be.
Shallow analysis of lexical similaritybetween sentences and/or the keywords containedin sentences has lead to summarisers that are ro-bust and perform very well for most texts (Radevet al., 2004; Dorr and Zajic, 2003; Carbonell andGoldstein, 1998).
The methods applied include arandom-surfer model (Mihalcea and Tarau, 2004;Radev, 2004), a model of attraction and repul-sion of similar summary sentences (Carbonell andGoldstein, 1998).
There are statistical models ofsentence shortening (Knight and Marcu, 2002).While much work in summarisation has concen-trated on multi-document summarisation, wherethe main challenge is the detection of redundantinformation, the summariser presented here is asingle-document summariser.However, researchers have been attracted bydeeper, more symbolic and thus more explana-tory summarisation models that use semantic rep-resentations of some form (Radev and McKe-own, 1998) and often rely on explicit discoursemodelling (Lehnert, 1981; Kintsch and van Dijk,1978; Cohen, 1984).
The problem with template-based summarisers is that they tend to be domain-dependent; the problem with discourse structure-based summarisers is in general that they requireknowledge modelling and reasoning far beyondthe capability of today?s state of the art in arti-ficial intelligence.
Rhetorical Structure Theory(Mann and Thompson, 1987) provides a domain-independent framework that takes local discoursestructure into account, which has lead to a suc-cessful prototype summariser (Marcu, 2000).
Thissummarisation strategy does not however look atthe lexical content of the propositions or clause-like units it connects, only at the way how the con-nection is performed.The summariser presented here is a hybrid: itscore algorithm is symbolic, but its limited powersof generalisation come from a semantic similaritymetric that is defined via distributionally derivedprobabilities.
Because its core processing is sym-bolic and based on a simple semantic representa-tion, it is possible to derive an explanation basedon the coherence tree and the propositions selectedfrom it.
There are some similarities to the idea ofsummarisation via lexical chains (Barzilay and El-hadad, 1997), as both methods trace concepts (asrepresentatives of topics) across a document.
TheKvD model arguably uses more informative mean-ing units, as it is based on the combination of con-cepts within propositions, rather than on conceptrepetition alone.A different, related stream of research lookedat the automatic detection of coherence in text.Graesser et al (2004) present a coherence checkerbased on over 200 coherence metrics, includingargument overlap as in KvD.
Barzilay and Lap-ata (2008) use a profiling of texts akin to Centeringtheory to rank texts according to their coherence.It would be interesting to combine their notion ofentity-based coherence with KvD?s notion of ar-gument overlap.4 ExperimentsWe now perform two experiments.
The first teststhe contribution of our concept matcher and rootchange strategy on a small document set we havecollected, and compares against two research sum-marisers.
In the second experiment, we test theperformance of our summariser on a much largerand standard dataset.We will use the intrinsic evaluation strategy ofcomparison to a gold standard.
Human judge-ments would be the most credible, but as a cheapalternative, we use ROUGE-L (Lin, 2004), whichhas been shown to correlate well to human judge-ments.
For each sentence, ROUGE-L treats it as asequence of words, and finds the longest commonsubsequences (LCSs) with any sentence in a goldstandard summary.
The score is defined as the F-measure of the precision and recall of the LCSs.737The next question is how the gold standard sum-maries used in ROUGE are defined.
Because oursummariser is deep and has a fine granularity, itshould be compared against human-written sum-maries on a variety of texts.For the first experiment, we have collected fromvolunteers 8 human abstractive summaries foreach of the 4 short scientific articles or storieswe found in Kintsch and Vipond (1979) (averagelength: 120 words), and 4 for each of 2 longer po-litical news texts (average length: 523 words).
Thevolunteers were instructed to condense the text to1/3 of its length for the short texts, and to 100words for the longer ones.
They were also in-structed not to paraphrase, but to use the words inthe text as much as possible.
This was because nosummariser in this experiment has a paraphrasingability.
Nevertheless, not all subjects followed thisinstruction strictly.For the second experiment, we use the DUC 2002dataset (Over and Liggett, 2002).
There are 827texts from news media, of a variety of topics andlengths, among which our script is able to extracttitles and contents of 822 documents.
We use theprovided single document abstractive summaries,which are of 100 words in length each, as goldstandard summaries.
A few of the documents areselected in multiple clusters and therefore havemultiple summaries; all of them are used in evalu-ation.We compare our summariser against a baselineconstructed with the first n words from the origi-nal text, where n is the summary length as definedabove, and two summarisers: MEAD (Radev etal., 2004) is a research summariser which uses acentroid-based paradigm and is known to performgenerally well over a range of texts.
LexRank(Radev, 2004) uses lexically derived similarities inits similarity graph of sentences, sharing the sameidea of sentence similarity with MEAD.
Note thatboth summarisers are extractive.We illustrate what our summaries look like in Ta-ble 2, where we asked the summariser to give ussummaries as close to 20 and 50 word summariesas possible, with Table 3 showing the underlyingpropositions.
In contrast, MEAD can only extractsentences as-is (thus not as flexible in length), anddoes not have meaning blocks like our proposi-tions.Encounters between police and Black Panther members.Students to complain of harassment.
Automobiles PantherParty signs glued to bumpers.Bloody encounters between police and Black Panthermembers punctuated the summer days of 1969.
Studentsto complain of continuous harassment by law enforcementofficers.
They receiving many traffic citations.
Automo-biles with Panther Party signs glued to their bumpers.
I todetermine whether we were hearing the voice of paranoiaor reality.Table 2: Summaries produced by our summariser.3 encounters (between: police; between: Black Pan-ther members)16 to complain (students; of: harassment)34 with: Panther Party signs (automobiles)35 glued (#34; to: bumpers)Table 3: Summary propositions for the first sum-mary above.We create summaries for all three summarisersfollowing this procedure: We provide sentence-split texts and their headlines (not needed byLexRank), and run the summarisers in such a wayas to produce a summary of the same length asstipulated for the standard summaries.
Our sum-mariser controls word count precisely; we requireMEAD to produce summaries close to the length(allowing variations), and for LexRank we allowit to go beyond the limit by less than one sentenceand then discard the exceeding part in the sentencewith the lowest salience.The results of Experiment 1 are summarised in Ta-ble 4.
As is well-known from similar experiments,it is hard beating the first n baseline due to the factthat journalistic style (in the long texts) alreadyputs a summary of each text first.
It is slightlysurprising that this effect also holds for the shorttexts (literary style).
It is of note that our KvDsummariser beats both MEAD and LexRank onthis dataset, which is shelved away during devel-opment, with statistical significance on the longtexts: the 95%-confidence interval of ours is 0.403?
0.432, and that of MEAD is 0.370 ?
0.411.Long Texts Short TextsOurs 0.418 0.333Ours ?
without similarity 0.396 0.271Ours ?
without word info 0.319 0.185Ours ?
without root change 0.388 0.348MEAD 0.391 0.343LexRank 0.378 0.326First n words 0.460 0.368Table 4: ROUGE-L F-measures for Experiment 1.738Precision Recall F-measureOur summariser 0.361 0.332 0.344MEAD 0.366 0.355 0.358First n words 0.403 0.395 0.399Table 5: ROUGE-L scores for Experiment 2.We test whether concept matching is beneficialby switching off similarity derived from distribu-tional semantics, or switching off all ?word infor-mation?
which includes distributional semantics,lemmatisation, and coreference detection, i.e.
toconsider matching only for the same word.
Per-formance deteriorates when concept matching isswitched off, substantially if all word informationis off.
This confirms our hypothesis that one ofthe cornerstones of KvD, concept matching, canbe at least partially simulated using today?s distri-butional semantics methods.
As for root change,turning it off seems to hurt performance on thelonger texts, but not so on the shorter ones, whichmatches our speculation that root change is usefulfor longer texts, which have some focus shifts.The result of Experiment 2 is shown in Table 5.This experiment on a large dataset demonstratesthat our summariser performs in the ballpark oftypical results of extractive summarisers, althoughit is still statistically a little worse than the state-of-the-art MEAD (whose F-measure 95%-confidenceinterval is 0.349 ?
0.367).
Our summariser isgood at precision because many summaries pro-duced have not used up the 100-word limit, mak-ing the average summary length smaller than thatof MEAD?s.
This indicates that our summarisermight be good at very short summaries, or wecould improve the memory selection to allow fora more diversified important proposition set.
Con-sidering this, and the fact that we have many pa-rameters not tuned for the task, and we have notutilised the structural / positional features (whoseimportance is shown in the first-n baseline), theresult is still encouraging.5 ConclusionsWe present here a first prototype of the feasibilityof basing a summarisation algorithm on Kintschand van Dijk?s (1978) model.
Our implemen-tation successfully creates flexible-length sum-maries, highly compressed if desired, and providessome explanation for why certain meaning unitsappear in the summary.
We have avoided some ofthe hardest aspects of KvD?s model, which have todo with the generation of macropropositions andwith keeping closer track of larger discourse struc-tures, but we show that some core aspects of themodel can be approximated with today?s parsingand lexical semantics technology.
Although theoutput summaries are not yet in all cases grammat-ical, we show that our system performs compara-bly with extractive state-of-the-art summarisers.During the implementation, we had to solve sev-eral practical problems that the KvD did not giveenough procedural detail about, or skipped overin their manual simulation.
For instance, we haveturned the distinction between LTM and STM totwo parallel salience levels from KvD?s two dis-joint stages, formalised the tree building processand improved KvD?s root choice strategy.The KvD model does not keep track of uniqueevents, but would profit from doing so, for in-stance in texts where more than one event of thesame type is referred to.
It has no explicit modelof time, but would profit from one.
It does noteven use information about which entities in a textform the same concept or individual, for selectingall information about that concept into the sum-mary.
There are also many interesting ways howthe memory cycle could be modified by givingmore weight to particular events, concepts and in-dividuals.On the implementational side, much remains tobe tried.
Anything that improves the propositionbuilder should bear direct fruit in the quality ofthe summaries.
The limitations of our proposi-tion builder come from the limitations of parsingtechnology as well as the fact that semantics is notentirely determined by syntax.
For instance, wenoticed some problems caused by incorrect prepo-sitional phrase attachment.
A better coreferencesystem would also improve this summariser im-mensely, reducing much uncertainty in the con-cept matching.
The deep nature of the summariseralso enables natural language generation to im-prove the readability of our textual summary.AcknowledgementJoint scholarship from the Cambridge Common-wealth, European & International Trust and theChina Scholarship Council is gratefully acknowl-edged.739ReferencesA Baddeley.
2007.
Working memory, thought, and ac-tion.
Oxford University Press.Regina Barzilay and Michael Elhadad.
1997.
Us-ing lexical chains for text summarization.
In InderjeetMani and Mark T. Maybury, editors, Proceedings of theACL/EACL-97 Workshop on Intelligent Scalable TextSummarization.Regina Barzilay and Mirella Lapata.
2008.
Modelinglocal coherence: An entity-based approach.
Computa-tional Linguistics, 34(1):1?34.BK Britton and S Gulgoz.
1991.
Using kintsch?scomputational model to improve instructional text: Ef-fects of repairing inference calls on recall and cognitivestructures.
Journal of Educational Psychology.Ann L. Brown, Jeanne D. Day, and Jones R. S. 1983.The development of plans for summarizing text.
Childdevelopment.
was in press in 1983.Jaime Carbonell and Jade Goldstein.
1998.
The useof MMR, diversity-based reranking for reordering doc-uments and producing summaries.
In Proceedings ofthe 21th (SIGIR-98), pages 335?336, Melbourne, Aus-tralia.Robin Cohen.
1984.
A computational theory of thefunction of clue words in argument understanding.
InProceedings of the 10th (COLING-84), pages 251?255.J Coiro and E Dobler.
2007.
Exploring the onlinereading comprehension strategies used by sixthgradeskilled readers to search for and locate information onthe internet.
Reading research quarterly.KA DeLong, TP Urbach, and M Kutas.
2005.
Prob-abilistic word pre-activation during language compre-hension inferred from electrical brain activity.
Natureneuroscience.Bonnie Dorr and David Zajic.
2003.
Hedge trimmer:A parse-and-trim approach to headline generation.
Inin Proceedings of Workshop on Automatic Summariza-tion, pages 1?8.MP Driscoll.
2005.
Psychology of learning for instruc-tion.
Allyn and Bacon.NK Duke and PD Pearson.
2002.
Effective practicesfor developing reading comprehension.
In Alan E.Farstrup and S. Jay Samuels, editors, What researchhas to say about reading instruction.Brigitte Endres-Niggemeyer.
1998.
Summarizing In-formation.
Springer-Verlag, New York, NY.Arthur C. Graesser, Danielle S. McNamara, Max M.Louwerse, and Zhiqiang Cai.
2004.
Coh-metrix:Analysis of text on cohesion and language.
Behav-ior Research Methods, Instruments, & Computers,36(2):193?202.V Anderson Hidi.
1986.
Producing written sum-maries: Task demands, cognitive operations, and impli-cations for instruction.
Review of educational research.A King.
1992.
Comparison of self-questioning, sum-marizing, and notetaking-review as strategies for learn-ing from lectures.
American Educational ResearchJournal.Walter Kintsch and Teun A. van Dijk.
1978.
Toward amodel of text comprehension and production.
Psycho-logical review, 85(5):363?394.Walter Kintsch and Douglas Vipond.
1979.
Read-ing comprehension and readability in educational prac-tice and psychological theory.
In Lars-G?oran Nilsson,editor, Perspectives on Memory Research: Essays inHonor of Uppsala?s 500th Anniversary, pages 329?365.
Erlbaum Associates.Dan Klein and Christopher D Manning.
2003.
Ac-curate unlexicalized parsing.
In Proceedings of the41st Annual Meeting on Association for ComputationalLinguistics-Volume 1, pages 423?430.
Association forComputational Linguistics.Kevin Knight and Daniel Marcu.
2002.
Summariza-tion beyond sentence extraction: A probabilistic ap-proach to sentence compression.
Artificial Intelligence,139(1).Keiko Koda.
2005.
Insights into second languagereading: A cross-linguistic approach.
Cambridge Uni-veristy Press.Wendy G Lehnert.
1981.
Plot units and narrative sum-marization.
Cognitive Science, 5(4):293?331.Chin-Yew Lin and Eduard Hovy.
2003.
Automaticevaluation of summaries using n-gram co-occurrencestatistics.
In Proceedings of the 2003 Conference of theNorth American Chapter of the Association for Compu-tational Linguistics on Human Language Technology-Volume 1, pages 71?78.
Association for ComputationalLinguistics.Dekang Lin.
1998.
Automatic retrieval and clusteringof similar words.
In Proceedings of the 17th interna-tional conference on Computational linguistics-Volume2, pages 768?774.
Association for Computational Lin-guistics.Chin-Yew Lin.
2004.
ROUGE: A package for auto-matic evaluation of summaries.
In Text SummarizationBranches Out: Proceedings of the ACL-04 Workshop,pages 74?81.William C. Mann and Sandra A. Thompson.
1987.Rhetorical Structure Theory: Description and construc-tion of text structures.
In Gerard Kempen, editor, Natu-ral Language Generation: New Results in Artificial In-telligence, Psychology, and Linguistics, pages 85?95.Marinus Nijhoff Publishers, Dordrecht, NL.Daniel Marcu.
2000.
The Theory and Practice of Dis-course Parsing and Summarization.
MIT Press.R Mihalcea and P Tarau.
2004.
Textrank: Bringingorder into texts.
In Proceedings of the EMLNP.George A Miller.
1995.
Wordnet: a lexical database740for english.
Communications of the ACM, 38(11):39?41.Paul Over and W Liggett.
2002.
Introduction toduc: An intrinsic evaluation of generic news text sum-marization systems.
In Proc.
DUC.
http://www-nlpir.nist.gov/projects/duc/guidelines/2002.html.A Paivio.
1990.
Mental representations.
Oxford Sci-ence Publications.Aannemarie Sullivan Palinscar and Ann L. Brown.1984.
Reciprocal teaching of comprehension-fosteringand comprehension-monitoring activities.
Cognitionand Instruction, 1:117?175.Michael Pressley.
2006.
Reading instruction thatworks: The case for balanced teaching.
GuildfordPress.Dragomir R. Radev and Kathleen R. McKeown.
1998.Generating natural language summaries from multipleon-line sources.
24(3):469?500.Dragomir Radev, Timothy Allison, Sasha Blair-Goldensohn, John Blitzer, Arda Celebi, Stanko Dim-itrov, Elliott Drabek, Ali Hakim, Wai Lam, Danyu Liu,Jahna Otterbacher, Hong Qi, Horacio Saggion, SimoneTeufel, Michael Topper, Adam Winkel, and Zhu Zhang.2004.
Mead ?
a platform for multidocument multilin-gual text summarization.
In Proceedings of LREC-04.Dragomir R. Radev.
2004.
Lexrank: Graph-based lex-ical centrality as salience in text summarization.
Jour-nal of Artificial Intelligence Research.F Smith.
2004.
Understanding reading: A psy-cholinguistic analysis of reading and learning to read.Lawrence Erlbaum.Karen Sp?arck Jones.
1993.
What might be in a sum-mary?
Technical report, Computer Laboratory, Uni-versity of Cambridge.Teun A. van Dijk.
1977.
Text and Context: Explo-rations in the Semantics and Pragmatics of Discourse.Longman, London, UK.RA Zwaan.
2003.
The immersed experiencer: Towardan embodied theory of language comprehension.
Psy-chology of learning and motivation.741
