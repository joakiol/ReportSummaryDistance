Magic for Filter Optimization in Dynamic Bottom-up ProcessingGuido  Minnen*SFB 340, University of Tf ibingenKleine Wilhelmstrafle.
113D-72074 Tiibingen,Germanye-mail : minnen~sf s. nphil, uni-tuebingen, deAbstractOff-line compilation of logic grammars us-ing Magic allows an incorporation of fil-tering into the logic underlying the gram-mar.
The explicit definite clause charac-terization of filtering resulting from Magiccompilation allows processor independentand logically clean optimizations of dy-namic bottom-up rocessing with respect togoal-directedness.
Two filter optimizationsbased on the program transformation tech-nique of Unfolding are discussed which areof practical and theoretical interest.1 In t roduct ionIn natural anguage processing filtering is used toweed out those search paths that are redundant, i.e.,are not going to be used in the proof tree corre-sponding to the natural anguage xpression to begenerated or parsed.
Filter optimization often com-prises an extension of a specific processing strategysuch that it exploits pecific knowledge about gram-mars and/or the computational task(s) that one isusing them for.
At the same time it often remainsunclear how these optimizations relate to each otherand what they actually mean.
In this paper I showhow starting from a definite clause characterizationof filtering derived automatically from a logic gram-mar using Magic compilation, filter optimizationscan be performed in a processor independent andlogically clean fashion.Magic (templates) is a general compilation tech-nique for efficient bottom-up evaluation of logic pro-grams developed in the deductive database commu-nity (Ramakrishnan et al, 1992).
Given a logic pro-gram, Magic produces a new program in which thefiltering as normally resulting from top-down eval-uation is explicitly characterized through, so-called,*url: http://www.sfs.nphil.uni-tuebingen/'minnenmagic predicates, which produce variable bindingsfor filtering when evaluated bottom-up.
The origi-nal rules of the program are extended such that thesebindings can be made effective.As a result of the definite clause characterizationof filtering, Magic brings filtering into the logic un-derlying the grammar.
I discuss two filter optimiza-tions.
These optimizations are direction indepen-dent in the sense that they are useful for both gen-eration and parsing.
For expository reasons, though,they are presented merely on the basis of examplesof generation.Magic compilation does not limit the informa-tion that can be used for filtering.
This can leadto nontermination as the tree fragments enumer-ated in bottom-up evaluation of magic compiledgrammars are connected (Johnson, forthcoming).More specifically, 'magic generation' falls prey tonon-termination in the face of head recursion, i.e.,the generation analog of left recursion in parsing.This necessitates a dynamic processing strategy, i.e.,memoization, extended with an abstraction functionlike, e.g., restriction (Shieber, 1985), to weaken fil-tering and a subsumption check to discard redun-dant results.
It is shown that for a large class ofgrammars the subsumption check which often influ-ences processing efficiency rather dramatically canbe eliminated through fine-tuning of the magic pred-icates derived for a particular grammar after apply-ing an abstraction function in an off-line fashion.Unfolding can be used to eliminate superfluous fil-tering steps.
Given an off-line optimization of theorder in which the right-hand side categories in therules of a logic grammar are processed (Minnen etal., 1996) the resulting processing behavior can beconsidered a generalization f the head corner gen-eration approach (Shieber et al, 1990): Without heneed to rely on notions such as semantic head andchain rule, a head corner behavior can be mimickedin a strict bottom-up fashion.2472 Definite Clause Characterizationof FilteringMany approaches focus on exploiting specific knowl-edge about grammars and/or the computationaltask(s) that one is using them for by making filter-ing explicit and extending the processing strategysuch that this information can be made effective.In generation, examples of such extended process-ing strategies are head corner generation with itssemantic linking (Shieber et al, 1990) or bottom-up(Earley) generation with a semantic filter (Shieber,1988).
Even though these approaches often accom-plish considerable improvements with respect o ef-ficiency or termination behavior, it remains unclearhow these optimizations relate to each other andwhat  comprises the logic behind these specializedforms of filtering.
By bringing filtering into the logicunderlying the grammar it is possible to show in aperspicuous and logically clean way how and why fil-tering can be optimized in a particular fashion andhow various approaches relate to each other.2.1 Magic CompilationMagic makes filtering explicit hrough characterizingit as definite clauses.
Intuitively understood, filter-ing is reversed as binding information that normallybecomes available as a result of top-down evaluationis derived by bottom-up evaluation of the definiteclause characterization f filtering.
The following isthe basic Magic algorithm taken from Ramakrishnanet al (1992).Let P be a program and q(E) a query onthe program.
We construct a new programping.
Initially ping is empty.1.
Create a new predicate magic_p foreach predicate p in P. The arity is thatof p.2.
For each rule in P, add the modifiedversion of the rule to p-~9.
If rule rhas head, say, p({), the modified ver-sion is obtained by adding the literalmagic_p(t) to the body.3.
For each rule r in P with head, say,p({), and for each literal q~(~) in itsbody, add a magic rule to ping.
Thehead is magic_qi(~).
The body con-tains the literal magic_p(t), and all theliterals that precede qi in the rule.4.
Create a seed fact magic_q(5) from thequery.To illustrate the algorithm I zoom in on the applica-tion of the above algorithm to one particular gram-mar rule.
Suppose the original grammar ule looksas follows:s (P0, P, VForm, SSem) : -vp(Pl  ,P,VForm, \[CSem\] ,SSem),np (P0,PI, CSem).Step 2 of the algorithm results in the following mod-ified version of the original grammar ule:s (P0, P ,VForm,  SSem) : -magic_s (P0,P,VForm, SSem) ,vp(Pl ,P ,VForm, \[CSem\] , SSem) ,np (P0, PI, CSem).A magic literal is added to the right-hand side ofthe rule which 'guards' the application of the rule.This does not change the semantics of the originalgrammar as it merely serves as a way to incorpo-rate the relevant bindings derived with the magicpredicates to avoid redundant applications of a rule.Corresponding to the first right-hand side literal inthe original rule step 3 derives the following magicrule:magic_vp  (Pl, P, VForm, \[CSem\] , SSem) : -magic_s  (P0, P, VForm,  SSem) .It is used to derive from the guard for the originalrule a guard for the rules defining the first right-handside literal.
The second right-hand side literal in theoriginal rule leads to the following magic rule:magic_up (P0, P1, CSem) : -magi c_s (P0, P, VForm, SSem) ,vp(Pl ,P ,VForm, \[CSem\] ,SSem) .Finally, step 4 of the algorithm ensures that a seed iscreated.
Assuming that the original rule is definingthe start category, the query corresponding to thegeneration of the s "John buys Mary a book" leadsto the following seed:magic_s (P0 ,P, finite ,buys (john, a (book) ,mary) ).The seed constitutes a representation of the initialbindings provided by the query that is used by themagic predicates to derive guards.
Note that thecreation of the seed can be delayed until run-time,i.e., the grammar does not need to be recompiled forevery possible query.2.2 ExampleMagic compilation is illustrated on the basis of thesimple logic grammar extract in figure 1.
This gram-mar has been optimized automatically for generation(Minnen et al, 1996): The right-hand sides of therules are reordered such that a simple left-to-rightevaluation order constitutes the optimal evaluationorder.
With this grammar a simple top-down gen-eration strategy does not terminate as a result ofthe head recursion in rule 3.
It is necessary to use248(1) sentence(P0,P,decl(SSem)):-s(P0,P,finite,SSem).
(2) s(P0,P,VForm,SSem):-vp(P1,P,VForm,\[CSem\],SSem).np(P0,PI,CSem),(3) vp(P0,P,VForm,Args,SSem):-vp(PO,Pl,VForm,\[CSemIArgs\],SSem),np(Pl,P,CSem).
(4) vp(PO,P,VForm,Args,SSem):-v(PO,P,VForm,Args,SSem).
(5) np(P0,P,NPSem) :-pn (P0, P, NPSem)(6) np(P0,P,NPSem) :-det (P0 ,PI ,NSem, NPSem),n(Pl ,P, NSem).
(7) det ( \[alP\], P,NSem, a (NSem)).
(8) v( \[buyslP\] ,P, finite, \[I ,D,S\] ,buys (S ,D, I) ).
(9) pn(\[mary\[P\] ,P,mary)(10)n ( \[bookIP\] ,P,book).Figure 1: Simple head-recursive grammar.memoization extended with an abstraction functionand a subsumption check.
Strict bottom-up gener-ation is not attractive ither as it is extremely in-efficient: One is forced to generate all possible nat-ural language xpressions licensed by  the grammarand subsequently check them against he start cate-gory.
It is possible to make the process more efficientthrough excluding specific lexical entries with a se-mantic filter.
The use of such a semantic filter inbottom-up evaluation requires the grammar to obeythe semantic monotonicity constraint in order to en-sure completeness(Shieber, 1988) (see below).The 'magic-compiled grammar' in figure 2 is theresult of applying the algorithm in the previous ec-tion to the head-recursive example grammar andsubsequently performing two optimizations (Beeriand Ramakrishnan, 1991): All (calls to) magic pred-icates corresponding to lexical entries are removed.Furthermore, data-flow analysis is used to fine-tunethe magic predicates for the specific processing taskat hand, i.e., generation3 Given a user-specifiedabstract query, i.e., a specification of the intendedinput (Beeri and Ramakrishnan, 1991) those argu-ments which are not bound and which thereforeserve no filtering purpose are removed.
The modi-fied versions of the original rules in the grammar areadapted accordingly.
The effect of taking data-flowinto account can be observed by comparing the rulesfor mag?c_vp and mag?c_np in the previous sectionwith rule 12 and 14 in figure 2, respectively.Figure 3 shows the results from generation of thesentence "John buys Mary a book".
In the case ofthis example the seed looks as follows:magic_sentence (decl (buys (john, a (book) ,mary) ) ).The \]acts, i.e., passive edges/items, in figure 3 re-sulted from semi-naive bottom-up evaluation (Ra-IFor expository reasons some data-flow informationthat does restrict processing is not taken into account.E.g., the fact that the vp literal in rule 2 is alwayscalled with a one-element list is ignored here, but seesection 3.1.makrishnan et al, 1992) which constitutes a dy-namic bottom-up evaluation, where repeated eriva-tion of facts from the same earlier derived facts (as innaive evaluation; Bancilhon, 1985) is blocked.
(Ac-tive edges are not memoized.)
The figure 2 consist oftwo tree structures (connected through dotted lines)of which the left one corresponds to the filteringpart of the derivation.
The filtering tree is reversedand derives magic facts starting from the seed in abottom-up fashion.
The tree on the right is the prooftree for the example sentence which is built up as aresult of unifying in the derived magic facts whenapplying a particular ule.
E.g., in order to derivefact 13, magic fact 2 is unified with the magic literalin the modified version of rule 2 (in addition to thefacts 12 and 10).
This, however, is not representedin order to keep the figure clear.
Dotted lines areused to represent when 'normal' facts are combinedwith magic facts to derive new magic facts.As can be reconstructed from the numbering ofthe facts in figure 3 the resulting processing behav-ior is identical to the behavior that would resultfrom Earley generation as in Gerdemann (1991) ex-cept that the different filtering steps are performedin a bottom-up fashion.
In order to obtain a gen-erator similar to the bottom-up generator as de-scribed in Shieber (1988) the compilation processcan be modified such that only lexical entries areextended with magic literals.
Just like in case ofShieber's bottom-up generator, bottom-up evalua-tion of magic-compiled grammars produced with thisMagic variant is only guaranteed to be complete incase the original grammar obeys the semantic mono-tonicity constraint.~The numbering of the facts corresponds to the orderin which they are derived.
A number of lexical entrieshave been added to the example grammar.
The facts cor-responding to lexical entries are ignored.
For expositoryreasons the phonology and semantics of lexical entries(except for vs) are abbreviated by the first letter.
Fur-thermore the fact corresponding to the vp "buys Mary abook John" is not included.249(1) sentence (P0 ,P ,decl (SSem)) : -magic_sentence (decl (SSem)),s (P0, P, finite, SSem).
(2) s(P0,P,VForm,SSem) :-magic_s (VForm, SSem),vp(P1 ,P,VForm, \[CSem\] ,SSem),np (P0 ,PI, CSem).
(3) vp(P0,P,VForm,hrgs,SSem) :-magic_vp (VForm, SSem),vp(P0,PI ,VForm, \[CSem\]hrgs\] ,SSem),np (Pl, P, CSem).
(4) vp(PO,P,VForm,Args,SSem) :-magic_vp (VForm, SSem),v (P0,P,VForm, Args, SSem) .
(5) np(P0,P,NPSem) :-magic_np (NPSem) ,pn (P0, P, NPSem).
(6) np(P0,P,NPSem) :-magic_np (NPSem),det (P0 ,PI ,NSem,NPSem),n (PI,P,NSem).
(7) det ( \[aiP\] , P, NSem, a (NSem)) .
(8) v (\[buyslP\] ,P,finite, \[I,D,S\] ,buys (S,D,I)).
(9) pn(\[mary\[P\] ,P,mary)(i0) n( \[booklP\] ,P,book).
(I I) magic_s (finite, SSem) : -magic_sentence (decl (SSem)) .
(12) magic_vp(VForm,SSem) :-magic_s (VForm, SSem) .
(13) magic_vp(VForm,SSem) :-magic_vp (VForm, SSem).
(14) magic_np(CSem) :-magic_s (VForm, SSem) ,vp(Pl ,P,VForm, \[CSem\] ,SSem).
(15) magic_np(CSem) :-magic_vp (VForm, SSem) ,vp (P0,Pl,VForm, \[CSemlArgs\] , SSem) .Figure 2: Magic compiled version 1 of the grammar in figure 1.
'FILTERING TREE' 'PROOF TREE'11 magic.rip(j) \ ?"
~  " " .
?
?
?
?
?8.magic-n~" " ?
li.sentence(~,buys,m,a,b\[A\],A,decl(buys(j,a(b),m))).~-m~'magic -vp( f i r * i t~ ,buys( j ,a (b ) ,mi ) . "
" " ?
, 13.s(~,buys,m,a,blA\],A,finite,buys(j,a(b),m)).\ 3.maglc-*vp(finite,buys (j,a(b),ml).""
~\ ] ,A , f in i te , \ [ j l ,buys( j ,a (b ) ,m) ) .2 rn gic (finite,b~s (j,a(b),rn)).. / / "  ?
"~.vi(,buy.s:m,Ai,A tinct , \ [ .~ .~a(b) ,m) ) .I 12 np(\[jlA \] j) 4 vp(\[buyslA \] A finlte,\[m,a(b) 3\] buys(j a(b) m)) 6 np(\[mIA\],A m) 9 np(\[a blA \] A a(b))1.magic-sentence(decl(buys(j,a(b),m))).Figure 3: 'Connecting up' facts resulting from semi-naive generation of the sentence "John buys Mary abook" with the magic-compiled grammar from figure 2.2503 Filter Optimization throughProgram TransformationAs a result of characterizing filtering by a definiteclause representation Magic brings filtering inside ofthe logic underlying the grammar.
This allows it tobe optimized in a processor independent and logi-cally clean fashion.
I discuss two possible filter opti-mizations based on a program transformation tech-nique called unfolding (Tamaki and Sato, 1984) alsoreferred to as partial execution, e.g., in Pereira andShieber (1987).3.1 Subsumption CheckingJust like top-down evaluation of the original gram-mar bottom-up evaluation of its magic compiled ver-sion falls prey to non-termination in the face of headrecursion.
It is however possible to eliminate thesubsumption check through fine-tuning the magicpredicates derived for a particular grammar in anoff-line fashion.
In order to illustrate how the magicpredicates can be adapted such that the subsump-tion check can be eliminated it is necessary to take acloser look at the relation between the magic pred-icates and the facts they derive.
In figure 4 the re-lation between the magic predicates for the examplegrammar is represented by an unfolding tree (Pet-torossi and Proietti, 1994).
This, however, is not anordinary unfolding tree as it is constructed on thebasis of an abstract seed, i.e., a seed adorned witha specification of which arguments are to be con-sidered bound.
Note that an abstract seed can bederived from the user-specified abstract query.
Onlythe magic part of the abstract unfolding tree is rep-resented.ABSTRACT SEEDL.
.
.4- magie_sentenee(SSem), .
.
....4-- magic_s f in i te,SSem), .
.
.- .4-  magic_vp (VForm,SSem),......+-- magic_np(CSem), .
.
.Figure 4: Abstract unfolding tree representing therelation between the magic predicates in the compiledgrammar.The abstract unfolding tree in figure 4 clearlyshows why there exists the need for subsumptionchecking: Rule 13 in figure 2 produces infinitelymany magic_vp facts.
This 'cyclic' magic rule is de-rived from the head-recursive p rule in the examplegrammar.
There is however no reason to keep thisrule in the magic-compiled grammar.
It influencesneither the efficiency of processing with the gram-mar nor the completeness of the evaluation process.3.1.1 Off-line AbstractionFinding these types of cycles in the magic part ofthe compiled grammar is in general undecidable.
Itis possible though to 'trim' the magic predicates byapplying an abstraction function.
As a result of theexplicit representation f filtering we do not need topostpone abstraction until run-time, but can trimthe magic predicates off-line.
One can consider thisas bringing abstraction i to the logic as the definiteclause representation f filtering is weakened suchthat only a mild form of connectedness re ults whichdoes not affect completeness (Shieber, 1985).
Con-sider the following magic rule:magic_vp(VForm, \[CgemlArgs\] , SSem) :-magic_vp (VForm, Args, SSem) .This is the rule that is derived from the head-recursive vp rule when the partially specified sub-categorization list is considered as filtering informa-tion (cf., fn.
1).
The rule builds up infinitely largesubcategorization lists of which eventually only oneis to be matched against he subcategorization listof, e.g., the lexical entry for "buys".
Though thisrule is not cyclic, it becomes cyclic upon off-line ab-straction:magic_vp (VForm, \[CSem I_3 , SSem) : -mag ic_vp  (VForm, \[CSem2l_\] , SSem) .Through trimming this magic rule, e.g., given abounded term depth (Sato and Tamaki, 1984) or arestrictor (Shieber, 1985), constructing an abstractunfolding tree reveals the fact that a cycle resultsfrom the magic rule.
This information can then beused to discard the culprit.3.1.2 IndexingRemoving the direct or indirect cycles from themagic part of the compiled grammar does eliminatethe necessity of subsumption checking in many cases.However, consider the magic rules 14 and 15 in fig-ure 2.
Rule 15 is more general than rule 14.
Withoutsubsumption checking this leads to spurious ambigu-ity: Both rules produce a magic fact with which asubject np can be built.
A possible solution to thisproblem is to couple magic rules with the modifiedversion of the original grammar rule that instigatedit.
To accomplish this I propose a technique thatcan be considered the off-line variant of an index-251ing technique described in Gerdemann (1991).
3 Theindexing technique is illustrated on the basis of therunning example: Rule 14 in figure 1 is coupled tothe modified version of the original s rule that insti-gated it, i.e., rule 2.
Both rules receive an index:s (PO, P, VForm, SSem) : -magic _s (P0, P, VForm, SSem),vp(P1 ,P,VForm, \[CSem\], SSem),np (P0,P1 ,CSem, index_l).magic_rip (CSem, index_l) : -magi c_s (P0, P, VForm, SSem),vp (P1, P, VForm, \[CSem\], SSem).The modified versions of the rules defining nps areadapted such that they percolate up the index ofthe guarding magic fact that licensed its application.This is illustrated on the basis of the adapted versionof rule 14:np (P0, P, NPSem, INDEX) : -magic_rip (NPSem, INDEX),pn (P0, P, NPSem).As is illustrated in section 3.3 this allows the avoid-ance of spurious ambiguities in the absence of sub-sumption check in case of the example grammar.3.2 Redundant  F i l te r ing  StepsUnfolding can also be used to collapse filtering steps.As becomes apparent upon closer investigation f theabstract unfolding tree in figure 4 the magic predi-cates magic_sentence, magic_s and magic_vp ro-vide virtually identical variable bindings to guardbottom-up application of the modified versions ofthe original grammar rules.
Unfolding can be used toreduce the number of magic facts that are producedduring processing.
E.g., in figure 2 the magic_s rule:magic_s ( f in i te ,  SSem)  : -mag ic_sentence  (decl (SSem))  .can be eliminated by unfolding the magic_s literalin the modified s rule:s(PO,P,VFOP~,SSem):-magic_s(VFORM,SSem),vp(P1,P,VF01~,,\[CSem\],SSem),np(P0,P1,CSem).This results in the following new rule which uses theseed for filtering directly without the need for anintermediate filtering step:3This technique resembles an extension of Magiccalled Counting (Beeri and Ramakrishnan, 1991).
How-ever, Counting is more refined as it allows to distinguishbetween different levels of recursion and serves entirelydifferent purposes.s(P0,P,finite,SSem):-magic_sentence(decl(SSem)),vp(P1,P,finite,\[CSem\],SSem),np(P0,P1,CSem).Note that the unfolding of the magic_s literalleads to the instantiation of the argument VFORMto f in i te .
As a result of the fact that there areno other magic_s literals in the remainder of themagic-compiled grammar the magic_s rule can bediscarded.This filter optimization is reminiscent of comput-ing the deterministic closure over the magic part ofa compiled grammar (DSrre, 1993) at compile time.Performing this optimization throughout the magicpart of the grammar in figure 2 not only leads to amore succinct grammar, but brings about a differentprocessing behavior.
Generation with the resultinggrammar can be compared best with head cornergeneration (Shieber et al, 1990) (see next section).3.3 ExampleAfter cycle removal, incorporating relevant indexingand the collapsing of redundant magic predicates themagic-compiled grammar from figure 2 looks as dis-played in figure 5.
Figure 6 shows the chart resultingfrom generation of the sentence "John buys Mary abook" .4 The seed is identical to the one used for theexample in the previous ection.
The facts in thechart resulted from not-so-naive bottom-up evalu-ation: semi-naive valuation without subsumptionchecking (Ramakrishnan et al, 1992).
The result-ing processing behavior is similar to the behaviorthat would result from head corner generation ex-cept that the different filtering steps are performedin a bottom-up fashion.
The head corner approachjumps top-down from pivot to pivot in order to sat-isfy its assumptions concerning the flow of seman-tic information, i.e., semantic haining, and subse-quently generates starting from the semantic headin a bottom-up fashion.
In the example, the seed isused without any delay to apply the base case of thevp-procedure, thereby jumping over all intermediatechain and non-chain rules.
In this respect the initialreordering of rule 2 which led to rule 2 in the finalgrammar in figure 5 is crucial (see section 4).4 Dependency  Const ra in t  onGrammarTo which extent it is useful to collapse magic predi-cates using unfolding depends on whether the gram-mar has been optimized through reordering the4In addition to the conventions already described re-garding figure 3, indices are abbreviated.252(i) sentence(P0,P,decl(SSem)):-magic_sentence(dec1(SSem)),s(P0,P,finite,SSem).
(2) s(P0,P,finite,SSem):-magic_sentence(decl(SSem)),vp(Pl,P,finite,\[CSem\],SSem),np(P0,PI,CSem, index_l).
(3) vp(P0,P,finite,Args,SSem):-magic_sentence(decl(SSem)),vp(P0,Pl,finite,\[CSem)Args\],SSem),np(Pi,P,CSem,index_2),(4) vp(P0,P,finite,Args,SSem):-magic_sentence(decl(SSem)),v(P0,P,finite,Args,SSem).
(5) np(P0,P,NPSem, INDEX):-magic_np(NPSem, INDEX),pn(P0,P,NPSem).
(6) np(P0,P,NPSem,INDEX) :-magic_up (NPSem, INDEX),det (P0,PI ,NSem,NPSem),n(Pl ,P,NSem).
(7) det(\[aIP\],P,NSem,a(NSem)).
(8) v( \ [buys lP \ ] ,P , f in i te ,  \[I,D,S\] ,buys(S ,D , I ) ) .
(9) pn ( \[marylP\], P ,mary)(10) n(\[booklP\] ,P,book).
(14) magic_np(CSem, index_l) :-magic_sentence (decl (SSem)),vp (PI,P, finite, \[CSem\], SSem).
(15) magic_np (CSem, index_2) : -magic_sentence (decl (SSem)),vp (P0,PI, finite, \[CSemlArgs\], SSem).11.magic_np(j,i_l).
?6.magic.np(a(b i ,i..2).
"_2)Figure 5: Magic compiled version 2 of the grammar in figure 1.lS.sentence(~,buys,m,a,bIA\],A,decl(buys(j,a(b),m))).I.
.
.
.
13.s(\[j,buys,m,a,blA\],A,finite,buys(j,a(b),m)).?
.
.
, .
.
. "
, .
, .
, , , ?
~,A,finite,\[j\],buys(j,a(b),m)).ll.nP(~mA\],Aj,iA).
2.vp(\[buyslA\],A,finite,\[m,a(b)j\],buys(j,a(b),m)).
4.np(\[mlA\],A,m,i-2).
7.np(\[a,bIA\],A,a(b),i-2 ).1.magic_sentence(decl(buys(j,a(b),m))).Figure 6: 'Connecting up' facts resulting from not-so-naive generation of the sentence "John buys Mary abook" with the magic-compiled grammar from figure 5.right-hand sides of the rules in the grammar as dis-cussed in section 3.3.
If the s rule in the runningexample is not optimized, the resulting processingbehavior would not have fallen out so nicely: In thiscase it leads either to an intermediate filtering stepfor the non-chaining sentence rule or to the addi-tion of the literal corresponding to the subject np toall chain and non-chain rules along the path to thesemantic head.Even when cycles are removed from the magic partof a compiled grammar and indexing is used to avoidspurious ambiguities as discussed in the previous ec-tion, subsumption checking can not always be elim-inated.
The grammar must be finitely ambiguous,i.e., fulfill the off-line parsability constraint (Shieber,1989).
Furthermore, the grammar is required toobey what I refer to as the dependency constraint:When a particular ight-hand side literal can not beevaluated eterministically, the results of its evalu-ation must uniquely determine the remainder of theright-hand side of the rule in which it appears.
Fig-ure 7 gives a schematic example of a grammar thatdoes not obey the dependency constraint.
Given(1) cat_l(...):-magic_cat_l(Filter),cat_2(Filter,Dependency ....
),cat_3(Dependency).
(2) magic_cat_3(Filter):-magic_cat_l(Filter),cat_2(Filter,Dependency,...).
(3) cat_2(property_l,property_2 ....
).
(4) cat_2(property_l,property_2 .... ).Figure 7: Abstract example grammar not obeying thedependency constraint.253a derived fact or seed magic_cat_l(property_l)bottom-up evaluation of the abstract grammar infigure 7 leads to spurious ambiguity.
There are twopossible solutions for cat_2 as a result of the factthat the filtering resulting from the magic literal inrule 1 is too unspecific.
This is not problematic aslong as this nondeterminism will eventually disap-pear, e.g., by combining these solutions with the so-lutions to cat_3.
The problem arises as a result ofthe fact that these solutions lead to identical filtersfor the evaluation of the cat_~ literal, i.e., the solu-tions to cat_2 do not uniquely determine cat_3.Also with respect to the dependency onstraint anoptimization of the rules in the grammar is impor-tant.
Through reordering the right-hand sides of therules in the grammar the amount of nondeterminismcan be drastically reduced as shown in Minnen et al(1996).
This way of following the intended semanticdependencies the dependency onstraint is satisfiedautomatically for a large class of grammars.5 Conc lud ing  RemarksMagic evaluation constitutes an interesting combi-nation of the advantages of top-down and bottom-up evaluation.
It allows bottom-up filtering thatachieves a goai-directedness which corresponds todynamic top-down evaluation with abstraction andsubsumption checking.
For a large class of grammarsin effect identical operations can be performed off-line thereby allowing for more efficient processing.Furthermore, it enables a reduction of the numberof edges that need to be stored through unfoldingmagic predicates.6 AcknowledgmentsThe presented research was sponsored by TeilprojektB4 "From Constraints to Rules: Efficient Compila-tion of HPSG Grammars" of the Sonderforschungs-bereich 340 of the Deutsche Forschungsgemeinschaft.The author wishes to thank Dale Gerdemann, MarkJohnson, Thilo G6tz and the anonymous reviewersfor valuable comments and discussion.
Of course,the author is responsible for all remaining errors.Re ferencesFrancois Bancilhon.
1985.
Naive Evaluation of Re-cursively Defined Relations.
In Brodie and My-lopoulos, editors, On Knowledge Base Manage-ment Systems - Integrating Database and AI Sys-tems.
Springer-Verlag.Catriel Beeri and Raghu Ramakrishnan.
1991.
Onthe Power of Magic.
Journal of Logic Program-ming 10.Jochen DSrre.
1993.
Generalizing Earley De-duction for Constraint-based Grammars.
DSrreand Dorna, editors, Computational Aspectsof Constraint-Based Linguistic Description I,DYANA-2, Deliverable R1.2.A.Dale Gerdemann.
1991.
Parsing and Generation ofUnification Grammars.
Ph.D. thesis, Universityof Illinois, USA.Mark Johnson.
forthcoming.
Constraint-based Nat-ural Language Parsing.
Brown University, Rich-mond, USA.
Draft of 6 August 1995.Guido Minnen, Dale Gerdemann, and Erhard Hin-richs.
1996.
Direct Automated Inversion of LogicGrammars.
New Generation Computing 14.Fernando Pereira and Stuart Shieber.
1987.
Pro-log and Natui'al Language Analysis.
CSLI LectureNotes, No.
10.
Center for the Study of Languageand Information, Chicago, USA.Alberto Pettorossi and Maurizio Proietti.
1994.Transformations of Logic Programs: Foundationsand Techniques.
Journal of Logic Programming19/2o.Raghu Ramakrishnan, Divesh Srivastava, nd S. Su-darshan.
1992.
Efficient Bottom-up Evaluation ofLogic Programs.
In Vandewalle, ditor, The Stateof the Art in Computer Systems and Software En-gineering.
Kluwer Academic Publishers.Taisuke Sato and Hisao Tamaki.
1984.
Enumerationof Success Patterns in Logic Programs.
Theoreti-cal Computer Sience 34.Stuart Shieber, Gertjan van Noord, Robert Moore,and Fernando Pereira.
1990.
Semantic Head-driven Generation.
Computational Linguistics 16.Stuart Shieber.
1985.
Using Restriction to ExtendParsing Algorithms for Complex Feature-basedFormalisms.
In Proceedings of the 23rd AnnualMeeting Association for Computational Linguis-tics, Chicago, USA.Stuart Shieber.
1988.
A Uniform Architecturefor Parsing and Generation.
In Proceedings ofthe 12th Conference on Computational Linguis-tics, Budapest, Hungary.Stuart Shieber.
1989.
Parsing and Type Inferencefor Natural and Computer Languages.
Ph.D. the-sis, Stanford University, USA.Hisao Tamaki and Taisuke Sato.
1984.
Unfold/FoldTransformation of Logic Programs.
In Proceed-ings of the 2nd International Conference on LogicProgramming, Uppsala, Sweden.254
