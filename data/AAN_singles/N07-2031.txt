Proceedings of NAACL HLT 2007, Companion Volume, pages 121?124,Rochester, NY, April 2007. c?2007 Association for Computational LinguisticsRH: A Retro Hybrid ParserPaula S. Newmannewmanp@acm.orgAbstractContemporary parser research is, to alarge extent, focused on statistical parsersand deep-unification-based parsers.
Thispaper describes an alternative, hybrid ar-chitecture in which an ATN-like parser,augmented by many preference tests,builds on the results of a fast chunker.The combination is as efficient as moststochastic parsers, and accuracy is closeand continues to improve.
These resultsraise questions about the practicality ofdeep unification for symbolic parsing.1 IntroductionThe original goals of the RH parser were to obtainaccurate parses where (a) application speed wasneeded, and (b) large amounts of annotated mate-rial for a subject idiom were not available.
Addi-tional goals that evolved were (c) that parses forparticular documents could be brought to an almostarbitrary level of correctness for research purposes,by grammar correction, and (d) that informationcollected during parsing could be modified for anapplication with a modest amount of effort.
Goal(a) ruled out the use of unification-based symbolicparsers, because deep unification is a relativelyslow operation, no matter what amount of compu-tational sophistication is employed.
Until very re-cently, goal (b) ruled out stochastic parsers, butnew results (McClosky et al 2006) suggest thismay no longer be the case.
However, the "addi-tional" goals still favor symbolic parsing.To meet these goals, the RH parser combines avery efficient shallow parser with an overlay parserthat is "retro", in that the grammar is related toAugmented Transition Networks (Woods, 1970),operating on the shallow-parser output.
A major"augmentation" is a preference-scoring component.Section 2 below reviews the shallow parserused, and Section 3 describes the overlay parser.Some current results are presented in section 4.Section 5 examines some closely-related work, andSection 6 discusses some implications.2 The XIP Parser for EnglishXIP is a robust parser developed by XeroxResearch Center Europe.
It is actually a full parserthat produces a tree of chunks, plus identificationof (sometimes alternative) typed dependenciesamong the chunk heads  (Ait-Mokhtar et al 2002,Gala 2004).
But because the XIP dependencyanalyzer for English was incomplete when RHwork began, and because classic parse trees aremore convenient for discourse-related applications,we focused on the chunk output.XIP is astonishingly fast, contributing very littleto RH parse time.
It consists of the XIP engine,plus language-specific grammars, each consistingof: (a) a finite state lexicon producing alternativetags and morphological analyses for each token,together with subcategorization, control and(some) semantic class features, (b) a part of speechtagger, and (c) conveniently expressed, layeredrule sets that perform the following functions:- Lexicon extension, which adds words andadds or overrides feature information,- Lexical disambiguation (including use of thetagger to provide default assignments)- Multi-word identification for named entities,dates, short constructions, etc.- Chunking, obtaining basic chunks such asbasic adjective, adverbial, noun andprepositional phrases.- Dependency Analysis (not used in RH)All rule sets have been extended within RHdevelopment except for the dependency rule sets..3   Overlay ParserThe overlay parser builds on chunker output toproduce a single tree (figure 1) providing syntacticcategories and functions, heads, and head features.The output tree requires further processing to ob-tain long distance dependency information, andmake some unambiguous coordination adjustments121Figure 1.
Output Parse Tree.
* indicates head.
Mouseover shows head featuresSome of this has already been done in a post-parsephase.
The feasibility of such post-parse deepening(for a statistical parser) is demonstrated by Cahillet al(2004).The major parser components are a control, theATN-like grammar networks, and collections oftests.
The control is invoked recursively to buildnon-chunk constituents by following grammarnetwork paths and creating output networks.Figure 2 shows the arcs of an excerpt from agrammar network used to build a noun phrase.
TheTest labels on the arcs resemble specialized cate-gories.
The MetaOps (limited in the illustration toProlog-like cuts) expedite processing by permittingor barring exploration of further ordered arcsoriginating at the same state.An output network, illustrated in figure 3,mirrors the full paths traversed in a grammar net-FromToTest SynfunFinal?MetaOpS1 S1 PREADV PRE No cutS1 S2 PRON HEAD Yes cutS1 S3 PROPER HEAD Yes cutS1 S4S7BASENP HEAD Yes cut//After pronounS2 - REFL REFL Yes cutS2 - PEOPLE APPS Yes cutFigure 2.
Some arcs of grammar network for GNPFrom To Cat Synfun RefOSa OSb NP HEAD NPChunk(The park)OSb OSc PP NMOD Final state ofPP net for(in Paris)States Score Final?Osa 0 NoOsb 0 YesOSc 1 YesFigure 3.
Output network for "The park in Paris"work by one invocation of the control.
The arcsrefer either to chunks or to final states of other out-put networks.
Output networks do not contain cy-cles or converging arcs, so states represent uniquepaths.
They carry head and other path information,and a preference score.
The final parser output is asingle tree, derived from a highest scoring path of atopmost output network.
Ties are broken by lowattach considerations.Each invocation of the control is given agrammar network entry state and a desiredconstituent category.
After initializing a newoutput network, the arcs from the given entry stateare followed.
Processing an arc may begin with anoptional pretest.
If that succeeds, or there is nopretest, a constructive test follows.
The tests areindexed by grammar network test labels, and areexpressed as blocks of procedural code, for initialflexibility in determining the necessary checks.Pretests include fast feasibility checks, and con-texted checks of consistency of the potential newconstituent with the current output network path.Constructive tests can make additional feasibilitychecks.
If these checks succeed, either a chunk isreturned, or the control is reentered to try to build asubordinate output network.
Results are cached, toavoid repeated testing.After a chunk or subordinate network ON' isreturned from a constructive test, one new arc Ai isadded to the current output network ON torepresent each full path through ON'.
All addedarcs have the same origin state in ON, but uniquesuccessor states and associated preference scores.The preference score is the sum of the score at thecommon origin state, plus the score of the repre-sented path in ON', plus a contexted score for thealternative within ON.
The latter is one of <-1, 0,+1>, and expresses the consistency of Ai with thecurrent path with respect to dependency, coordina-tion and apposition.
Structural and punctuation122aspects are also considered.
Preference tests areindexed by syntactic category or syntactic func-tion, and are organized for speed.
Most tests areindependent of Ai length, and can be applied onceand the results assumed for all Ai.Before a completed output network is returned,paths ending at those lower scoring final stateswhich cannot ultimately be optimal are pruned.Such pruning is critical to efficiency.4 Indicative Current ResultsTo provide a snapshot of current RH parserperformance, we compare its current speed andaccuracy directly to those of a widely usedstatistical parser, Collins model 3 (Collins, 1999),and indirectly to two other parsers.
Wall StreetJournal section 23 of the Penn Treebank (Marcuset al 1994) was used in all experiments.
"Training" of the RH parser on  the Wall StreetJournal area (beyond general RH development)occupied about 8 weeks, and involved testing and(non-exhaustively) correcting the parser using twoWSJ texts: (a) section 00, and (b) 700 sentences ofsection 23 used as a dependency bank by King etal.
(2003).
The latter were used early in RH devel-opment, and so were included in the training set.4.1 Comparative SpeedTable 1 compares RH parser speed with Collinsmodel 3, using the same CPU, showing the elapsedtimes for the entire 2416-line section 23.The results are then extrapolated to two otherparsers, based on published comparisons withCollins.
The extrapolation to XLE, a matureunification-based parser that uses a disambiguatingstatistical post-processor, is drawn from Kaplan etal.
(2004).
Results are given for both the fullgrammar and a reduced version that omits lesslikely rules.
The second comparison is with thefast stochastic parser by Sagae and Lavie (2005).Summarizing these results, RH is much fasterthan Collins model 3 and the reduced version ofXLE, but a bit slower than Sagae-Lavie.The table also compares coverage, as percent-ages of non-parsed sentences.
For RH this was10% for the test set discussed below, which did notcontain any training sentences, and was 10.4% forthe full section 23.
This is reasonable for a sym-bolic parser with limited training on an idiom, andbetter than the 21% reported for XLE English.Time No full parseSagae/ Lavie ~ 4 min 1.1%RH parser 5 min 10%Collins m3 16 min  .6%XLE full ~80 minutes ~21%XLE reduced ~24 minutes unknownTable 1: Speeds and Extrapolated speedsFullyaccurateF-score AvgcrossbracketsSagae/Lavie unknwn 86% unknwnCollins Lbl 33.6% 88.2% 1.05CollinsNoLbl 35.4% 89.4 % 1.05RH NoLbl 46% 86 % .59Table 2.
Accuracy Comparison4.2 Comparative AcccuracyTable 2 primarily compares the accuracy of theCollins model 3 and RH parsers.
The entries showthe proportion of fully accurate parses, the f-scoreaverage of bracket precision and recall, andaverage crossing brackets,  as obtained by EVALB(Sekine and Collins, 1997).
The RH f-score iscurrently somewhat lower, but the proportion offully correct parses is significantly higher.This data may be biased toward RH, because, ofnecessity, the test set used is smaller, and adifferent bracketing method is used.
For Collinsmodel 3, the entries show both labeled andunlabeled results for all of WSJ section 23.
TheCollins results were generated from the bracketedoutput and Penn Treebank gold standard filesprovided in a recent Collins download.But because RH does not generate treebank styletags, the RH entries reflect a test only on a randomsample of 100 sentences from the 1716 sentencesof section 23 not used as "training" data, using adifferent, available, gold standard creation andbracketing method.
In that method (Newman,2005), parser results are produced in a "TextTree"form, initially developed for fast visual review ofparser output, and then edited to obtain goldstandard trees.
Both sets of trees are then bracketedby a script to obtain, e.g.,{An automatic transformation{of parse trees}{to text trees}}{can expedite{parser output reviews}}123For non-parsed sentences in the parser outputs,brackets are applied to the chunks.
EVALB is thenused to compare the two sets of bracketed results.Accuracy for XLE is not given, because theresults reported by Kaplan et al (2004) comparelabeled functional dependencies drawn from LFGf-structures with equivalents derived automaticallyfrom Collins outputs.
(All f-scores are <= 80%).5 Related WorkSeveral efforts combine a chunker with adependency analyzer operating on the chunks,including XIP itself.
The XIP dependency analyzeris very fast, but we do not have current coverage oraccuracy data for XIP English.Other related hybrids do not build on chunks,but, rather, adjust full parsers to  require or preferresults consistent with chunk boundaries.
Daum etal.
(2003) use chunks to constrain a WCDGgrammar for German, reducing parse times byabout 2/3 (but the same results are obtained using atagger alone).
They estimate that an ideal chunkerwould reduce times by about 75%.
No absolutenumbers are given.
Also, Frank et al (2003) use aGerman topological field identifier to constrain anHPSG  parser.
They show speedups of about 2.2relative to a tagged baseline, on a corpus whoseaverage sentence length is about 9 words.6 DiscussionWe have shown that the RH hybrid can competewith stochastic parsers in efficiency and, with onlylimited "training" on an idiom, can approach themin accuracy.
Also, the test organization preventsspeed from degrading as the parser is improved.The method is significant in itself, but also leadsto questions about the advantages of deep-unification-based parsers for practical NLP.
Theseparsers are relatively slow, and their large numbersof results require disambiguation, e.g., by corpus-trained back-ends.
They do provide more informa-tion than RH, but there is much evidence that theadditional information can be obtained by rapidanalysis of a single best parse.
Also, it has neverbeen shown that their elegant notations actuallyfacilitate grammar development and maintenance.Finally, while unification grammars are reversiblefor use in generation, good generation methodsremain an open research problem.ReferencesSalah A?t-Mokhtar, Jean-Pierre Chanod, andClaude Roux.
2002.
Robustness beyond shallowness:incremental deep parsing, Natural Language Engi-neering 8:121-144, Cambridge University Press.Aoife Cahill, Michael Burke, Ruth O?Donovan, Josefvan Genabith, and Andy Way.
2004.
Long-DistanceDependency Resolution in Automatically AcquiredWide-Coverage PCFG-Based LFG Approximations,In Proc ACL'04.
BarcelonaMichael Collins.
1999.
Head-Driven Statistical Modelsfor Natural Language Parsing.
Ph.D. thesis, Univer-sity of Pennsylvania.Michael A. Daum, Kilian A. Foth, and WolfgangMenzel.
2003.
Constraint-based integration of deepand shallow parsing techniques.
In Proc EACL'03,BudapestAnette Frank, Markus Becker, Berthold Crysmann,Bernd Kiefer and Ulrich Schaefer.
2003.
IntegratedShallow and Deep Parsing: TopP Meets HPSG.
InProc ACL'2003, SapporoNuria Gala.
2004.
Using a robust parser grammar toautomatically generate UNL graphs.
In Proc Work-shop on Robust Methods for Natural Language Dataat COLING'04, GenevaRonald M. Kaplan, Stephan Riezler, Tracy H. King,John T. Maxwell, Alex Vasserman.
2004.
Speed andaccuracy in shallow and deep stochastic parsing.
InProc HLT/NAACL'04, Boston, MA.Tracy H. King, Richard Crouch, Stefan Riezler, MaryDalrymple, and Ronald M. Kaplan.
2003.
The PARC700 dependency bank.
In Proc Workshop on Linguis-tically Interpreted Corpora, (LINC?03), BudapestDavid McClosky, Eugene Charniak, and Mark Johnson.2006.
Reranking and Self-Training for Parser Adap-tation.
In Proc ACL'06.
SydneyPaula Newman.
2005.
TextTree Construction for Parserand Grammar Development.
In Proc.
Workshop onSoftware at ACL'05  Ann Arbor, MI.
Available athttp://www.cs.columbia.edu/nlp/acl05soft/Satoshi Sekine and Michael Collins.
1997.
EvalB.Available at http://nlp.cs.nyu.edu/evalbKenji Sagae and Alon Lavie.
2005.
A classifier-basedparser with linear run-time complexity.
In Proc.
9thInt'l Workshop on Parsing Technologies.
VancouverWilliam Woods.
1970.
Transition network grammars fornatural language analysis.
Communications of theACM 13(10), 591-606124
