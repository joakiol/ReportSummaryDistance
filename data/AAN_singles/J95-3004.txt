Learning Morpho-Lexical Probabilitiesfrom an Untagged Corpus with anApplication to HebrewMoshe Lev inger*Haifa Research LaboratoryA lon  ItaitTechnionUzz i  Ornan  tTechnionThis paper proposes anew approach for acquiring morpho-lexical probabilities from an untaggedcorpus.
This approach demonstrates a way to extract very useful and nontrivial information froman untagged corpus, which otherwise would require laborious tagging of large corpora.
The paperdescribes the use of these morpho-lexical probabilities as an information source for morphologicaldisambiguation i  Hebrew.
The suggested method epends primarily on the following property:a lexical entry in Hebrew may have many different word forms, some of which are ambiguousand some of which are not.
Thus, the disambiguation f a given word can be achieved using otherword forms of the same lexical entry.
Even though it was originally devised and implemented for?
dealing with the morphological mbiguity problem in Hebrew, the basic idea can be extended andused to handle similar problems in other languages with rich morphology.1.
IntroductionThis paper addresses the problem of morphological disambiguation i  Hebrew byextracting statistical information from an untagged corpus.
Yet, the primary point is notto propose a method for morphological disambiguation per se, but rather to suggest amethod to compute morpho-lexical probabilities to be used as a linguistic source formorphological disambiguation.
Let us start with a few definitions and terminologythat will be used throughout this paper.We consider written languages, and for the purpose of this paper, a word is astring of letters delimited by spaces or punctuation.
Given a language L, and a wordw E L, we can find (manually or automatically by a morphological analyzer for L) allthe possible morphological nalyses of the word w. Suppose a word w has k differentanalyses, then A1 .
.
.
.
.
Ak, will be used to denote these k analyses.
A word is morpho-logically ambiguous if k > 2.
The number and character of the analyses depend onthe language model.
We have used the definitions of the automatic morphological n-alyzer developed at the IBM Scientific Center, Haifa, Israel (Bentur, Angel', and Segev1992).Given a text T with n words: Wl, .
.
.
,  wn, for each morphologically ambiguous wordWi E T, with k analyses: A1 .
.
.
.
.
Ak, there is one analysis, 1 AF E {A1 .
.
.
.
.
Ak} that is the* Haifa Research Laboratory, IBM Science & Technology, Haifa, Israel.j- Computer Science Department, Technion, Haifa, Israel.1 We will assume that there is only one right analysis, although, in rare cases, there might be more thanone.
(~) 1995 Association for Computational LinguisticsComputational Linguistics Volume 21, Number 3right analysis, while all the other k - 1 analyses of w are wrong analyses.
The sameword wi in a different ext, may have, of course, a different right analysis, thus, rightand wrong in this case are meaningful only with respect o the context in which wiappears.Morphological disambiguation of a text T is done by indicating for each ambigu-ous word in T--which of its different analyses is the right one.
At present, this can bedone manually by a speaker of the language, and hopefully in the future it will be doneautomatically by a computer program.
When dealing with automatic disambiguationof a text it is sometimes useful to reduce its ambiguity level.
A reduction of the ambi-guity level of an ambiguous word w, with k morphological nalyses: A1 .
.
.
.
.
Ak, occurswhen it is possible to select from A1 .
.
.
.
.
Ak, a proper subset of I analyses 1 G 1 < k,such that the right analysis of w is one of these 1 analyses.
In the case where l = 1, wesay that the word w is fully disambiguated.Since this paper suggests a method for morphological disambiguation using prob-abilities, the notion of morpho-lexical probabilities is also required.
Our model ofthe language is based on a large fixed Hebrew corpus.
For a word w with k analy-ses, A1,..., Ak, the morpho-lexical probability of Ai is the estimate of the conditionalprobability P(Ai \[ w) from the given corpus, i.e.,Pi = P(ai \] w) =no.
of times Ai was the right analysis of wno.
of occurrences of wNote that Pi is the probability that Ai is the right analysis of w independently ofthe context in which w appears.
Since the word w has exactly k different analyses:k E~ 1P(Ai w) Ei=I Pi = = \[ = 1.For reasons that will be elaborated in Section 2, our problem is most acute inHebrew and some other languages (e.g., Arabic), though ambiguity problems of asimilar nature occur in other languages.
One such problem is sense disambiguation.In the context of machine translation, Dagan and Itai (Dagan, Itai, and Schwall 1991;Dagan and Itai 1994) used corpora in the target language to resolve ambiguities inthe source language.
Yarowsky (1992) proposed a method for sense disambiguationusing wide contexts.
Part-of-speech tagging--deciding the correct part of speech inthe current context of the sentence--has received major attention.
Most successfulmethods have followed speech recognition systems (Jelinek, Mercer, and Roukos 1992)and used large corpora to deduce the probability of each part of speech in the currentcontext (usually the two previous words--trigrams).
These methods have reportedperformance in the range of 95-99% "correct" by word (DeRose 1988; Cutting et al1992; Jelinek, Mercer, and Roukos 1992; Kupiec 1992).
(The difference in performanceis due to different evaluation methods, different ag sets, and different corpora).
SeeChurch (1992) for a survey.Our work did not use the trigram model, since because of the relatively free wordorder in Hebrew it was less promising, and also, in some cases the different choicesare among words of the same part-of-speech ategory.
Thus tagging for part of speechalone would not solve our problems.
Note that a single morphological analysis maycorrespond to several senses.
Even though each sense may have different behaviorpatterns, in practice this did not present a problem for our program.The rest of this paper is organized as follows.
Sections 2 through 4 include adescription of the morphological mbiguity problem in Hebrew, followed by the claimthat knowing the morpho-lexical probabilities of an ambiguous word can be veryeffective for automatic morphological disambiguation i Hebrew.384Moshe Levinger et alTable 1The dimension of morphological mbiguity in Hebrew.Learning Morpho-Lexical Probabilitiesno.
of Analyses 1 2 3 4 5 6no.
of Word-Tokens 17,551 9,876 6,401 2,760 1,309 493% 45.1 25.4 16.5 7.1 3.37 1.27no.
of Analyses 7 8 9 10 11 12 13no.
of Word-Tokens 337 134 10 18 1 3 5% 0.87 0.34 0.02 0.05 0.002 0.007 0.01Then, in Sections 5 and 6, we present he key idea of this paper: How to acquirea good approximation for the morpho-lexical probabilities from an untagged corpus.Using this method we can find for each ambiguous word w with k analyses: A1 .
.
.
.
.
Ak,probabilities P1 .
.
.
.
, P---k that are an approximation to the morpho-lexical probabilities:P1 .
.
.
.
, Pk.In Section 7 we clarify some subtle aspects of the algorithm presented in Section 6by looking at its application to several ambiguous words in Hebrew.
A description ofan experiment that serves to evaluate the approximated morpho-lexical probabilitiescalculated using an untagged corpus will be given in Section 8.Finally, in Section 9, a simple strategy for morphological disambiguation i  He-brew using morpho-lexical probabilities will be described.
This simple strategy wasused in an experiment conducted in order to test the significance of the morpho-lexicalprobabilities as a basis for morphological disambiguation in Hebrew.
The experimentshows that using our method we can significantly reduce the level of ambiguity in aHebrew text.2.
Morphological Ambiguity in HebrewMorphological mbiguity is a severe problem in modern Hebrew.
Thus, finding meth-ods to reduce the morphological mbiguity in the language is a great challenge forresearchers in the field and for people who wish to develop natural language appli-cations for Hebrew.Table 1 demonstrates the dimension of the morphological mbiguity in Hebrew.The data was obtained by analyzing large texts, randomly chosen from the Hebrewpress, consisting of nearly 40,000 word-tokens.
According to this table, the averagenumber of possible analyses per word-token was 2.1, while 55% of the word-tokenswere morphologically ambiguous.
The main reason for this amount of ambiguity is thestandard writing system used in modern Hebrew (unpointed script).
In this writingsystem not all the vowels are represented, several etters represent both consonantsand different vowels, and gemination is not represented atall (Ornan 1986, 1991).
Therich morphology of the language and the fact that many particles are attached to theword, forming a single string, further contribute to the morphological mbiguity.In order to demonstrate he complexity of the problem, we should take a closerlook at Hebrew morphology.
A morphological analysis of a word in Hebrew shouldextract he following information:?
lexical entry385Computational Linguistics Volume 21, Number 3?
category?
tense (for verbs only)?
attached particles (i.e., prepositions, connectives, determiners)?
status--a flag indicating whether a noun is in its construct or absoluteform?
gender, number, and person (for nouns, adjectives, verbs etc.)?
gender, number, and person of pronoun suffixesFor example, the morphological nalysis of the Hebrew string 1)D~I'~'lVd~I (writtenin a Latin transliteration 2 WK$RAYTYW) is as follows:?
lexical entry: R^H (nN'l)--the verb 'to see'?
category: verb?
tense: past?
attached particles: W + K$ (~ + ~) = 'and when'?
gender: feminine/masculine, number: singular, person: first person?
object pronoun: masculine, singular, third personThus, WK$R^YTYW should be translated into English as: 'and when I saw him.
'To see the nature of the morphological mbiguity in Hebrew, consider, for example,the string HQPH (ngpn), which has three possible analyses:1.
The determiner H + the noun QPH (ngp + D, 'the coffee').2.
The noun HQPH (ngpn, 'encirclement').3.
The noun HQP + the feminine possessive suffix H (n + qpn, 'herperimeter').The use of computers for morphological analysis of Hebrew words is nowadayswell studied and understood.
Several high-quality morphological analyzers for He-brew have been developed in the last decade.
One such morphological nalyzer 3 wasused to supply the input for the morphological disambiguation project described inthis paper.3.
Former ApproachesEliminating or reducing the ambiguity at this early stage of automatic processing ofHebrew is crucial for the efficiency and the success rate of parsers and other naturallanguage applications.
It should be noted that the morphological mbiguity in Hebrewmakes even "simple" applications--as i  often considered when dealing with otherlanguages--complicated.2 See Appendix A for the Hebrew-Latin transliteration.3 The morphological nalyzer was developed at the IBM Scientific Center, Haifa, Israel (Bentur, Angel,and Segev 1992).
We would like to thank the center for letting us use it for research purposes.386Moshe Levinger et al Learning Morpho-Lexical ProbabilitiesOne good example for this is full-text retrieval systems (Choueka 1980).
Suchsystems must handle the morphological mbiguity problem.
To see that, consider, forexample, the case where we look for all the texts with the word HQPH ('encirclement').Without morphological disambiguation, we get many texts which really include theword H+QPH ('the coffee'), or even HQP+H ('her perimeter') (Ornan 1987).
Anotherapplication which is more difficult in Hebrew than in other languages i text-to-speechsystems, which cannot be implemented in Hebrew without first solving the morpho-logical ambiguity, since in many cases different analyses of a word imply differentpronunciations.
A much simpler problem occurs in English, where for some wordsthe correct syntactic tag is necessary for pronunciation (Church 1988).The notion that this ambiguity problem in Hebrew is very complicated and thatit can be dealt with only by using vast syntactic and semantic knowledge has ledresearchers tolook for solutions involving a considerable amount of human interaction.Ornan (1986) for instance, developed a new writing system for Hebrew, called'The Phonemic Script.'
This script enables the user to write Hebrew texts that aremorphologically unambiguous, in order to use them later as an input for variouskinds of natural anguage applications.
However, since regular Hebrew texts are notwritten in this script, they first must be transcribed to phonemic texts.
Choueka andLusignan (1985) presented a system for the morphological tagging of large texts that isbased on the short context of the word but also depends heavily on human interaction.Methods using the short context of a word in order to resolve ambiguity (usu-ally categorical mbiguity) are very common in English and other languages (DeRose1988; Church 1988; Karlsson 1990).
A system using this approach was developed byLevinger and Ornan in order to serve as a component in their project of morphologicaldisambiguation i Hebrew (Levinger 1992).
The main resource, used by this systemfor disambiguation, is a set of syntactic constraints that were defined manually bythe authors and followed two theoretical works that defined short context rules forHebrew (Pines 1975; Albeck 1992).
The syntactic onstraints approach, which is anextension of the short context approach, was found to be useful and reliable, but itsapplicability (based on the proportion of ambiguous words that were fully disam-biguated) was very poor.
Hence, the overall performance of this system is much lesspromising in Hebrew than in other languages.
These results can be explained by thefollowing properties of the ambiguity problem in Hebrew:1..(a)(b)In many cases two or more alternative analyses hare the same category,and hence these alternatives satisfy the same syntactic onstraints.Moreover, there are cases where two or even more analyses hare exactlythe same morphological ttributes and differ only in their lexical entry.For instance, the word XLW (~n) has two such morphological nalyses:The verb XLH (n~n), fem./masc., plural, third person, past tense('they became ill').The verb XL (Vn), fem./masc., plural, third person, past tense('they occurred').The short context constraints use unambiguous anchors that are oftenfunction words such as determiners and prepositions.
In English mostsuch function words are unambiguous.
In Hebrew, these words arealmost always morphologically ambiguous.
Moreover, many of themappear as prefixes of the word to be analyzed, and their identification ispart of the morphological nalysis.
We thus have a circularity problem: Inorder to perform the morphological nalysis, we need the short context,387Computational Linguistics Volume 21, Number 3to identify the short context, we have to find anchors, but in order tofind such words, we need first to perform the morphological nalysis.3.
The word order in Hebrew is rather free.4.
Our ApproachThe purpose of this paper is to suggest a new approach to deal with the above-mentioned problem.
This approach provides highly useful data that can be used bysystems for automatic, unsupervised morphological tagging of Hebrew texts.
In orderto justify and motivate our approach, we must first make the following conjecture:Although the Hebrew language is highly ambiguous morphologically, it seemsthat in many cases a native speaker of the language can accurately "guess" theright analysis of a word, without even being exposed to the concrete context inwhich it appears.
The accuracy can even be enhanced if the native speaker istold from which sublanguage the ambiguous word was taken.If this conjecture is true, we can now suggest a simple strategy for automatictagging of Hebrew texts:For each ambiguous word, find the morpho-lexical probabilities of each possibleanalysis.
If any of these analyses is substantially more frequent than the others,choose it as the right analysis.As we have already noted, by saying morpho-lexical probabilities, we mean theprobability of a given analysis to be the right analysis of a word, independently ofthe context in which it appears.
It should be emphasized that having these morpho-lexical probabilities enables us not only to use them rather naively in the above-mentioned strategy, but also to incorporate these probabilities into other systems thatexploit higher level knowledge (syntactic, semantic etc.).
Such a system that usesthe morpho-lexical probabilities together with a syntactic knowledge is described inLevinger (1992).5.
Acquiring the ProbabilitiesAdopting this approach leaves us with the problem of finding the morpho-lexicalprobabilities for the different analyses of every ambiguous word in the language.
Sincewe use a large corpus for this purpose, the morpho-lexical probabilities we acquiremust be considered relative to this specific training corpus.One way to acquire morpho-lexical probabilities from a corpus is to use a largetagged corpus.
Given a corpus in which every word is tagged with its right analysis,we can find the morpho-lexical probabilities as reflected in the corpus.
This is done bysimply counting for each analysis the number of times that it was the right analysis,and using these counters to calculate the probability of each analysis being the rightone.
The main drawback of this solution is the need for a very large tagged corpus.
Nosuch corpus exists for modern Hebrew.
Moreover, for such a solution aseparate taggedcorpus is required for each domain.
The method we are about o present saves us thelaborious effort of tagging a large corpus, and enables us to find a good approximationto the morpho-lexical probabilities by learning about them from an untagged corpus.Using this method, one can easily move to a new domain by applying the method toa new untagged corpus suited to this new domain.388Moshe Levinger et al Learning Morpho-Lexical ProbabilitiesThis might seem, at first sight, an impossible mission.
When we see the wordHQPH in an untagged corpus we cannot automatically decide which of its possiblereadings is the right one.
The key idea is to shift each of the analyses of an ambiguousword in such a way that they all become distinguishable.
To be more specific, for eachpossible analysis (lexical entry + the morphological information), we define a set ofwords that we call Similar Words (SW).
An element in this set is another word form ofthe same lexical entry that has similar morphological ttributes to the given analysis.These words are assumed similar to the analysis in the sense that we expect hem tohave approximately the same frequency in the language as the analysis they belong to.A reasonable assumption of this kind would be, for instance, to say that the masculineform of a verb in a certain tense in Hebrew is expected to have approximately the samefrequency as the feminine form of the same verb, in the same tense.
This assumptionholds for most of the Hebrew verbs, since all Hebrew nouns (and not only animateones) have the gender attribute.
4 To see a concrete xample, consider the word R^H(nt~7) and one of its analyses: the verb 'to see', masculine, singular, third person, pasttense.
A similar word for this analysis is the following one:?
RATH (n~t~7), feminine, singular, third person, past tense.The choice of which words should be included in the SW set of a given anal-ysis is determined by a set of pre-defined rules based on the intuition of a nativespeaker.
Nevertheless, the elements in the SW sets are not determined for each anal-ysis separately, but rather are generated automatically, for each analysis, by changingthe contents of one or several morphological ttributes in the morphological nalysis.In the previous example the elements are generated by changing the contents of thegender attribute in the morphological nalysis, while keeping all the other attributesunchanged.The set of rules used by the algorithm for automatic generation of SW sets foreach analysis in the language are of a heuristic nature.
For the problem in Hebrew,a set of ten rules 5 was sufficient for the generation of SW sets for all the possiblemorphological nalyses in Hebrew.
In case we wish to move to some other domain inHebrew, we should be able to use the same set of rules, but with a suitable trainingcorpus.
Hence, the set of rules are language-dependent but not domain-dependent.To clarify this point, consider the word MCBY& (~'~Xr2), which has the following twomorphological nalyses:..The verb HCBY& (~2Xn), masculine, singular, present ense ('indicates'or 'votes').The noun MCBY& (~2xr~, 'a pointer').The set of rules defined for Hebrew would enable us to observe that in the do-main of daily newspaper articles, the first analysis probably has a high morpho-lexicalprobability while the second analysis has a very low probability.
Using the same setof rules, we should be able to deduce for a domain of articles dealing with computerlanguages that the second analysis is probably much more frequent than the first one.Whenever we wish to apply our method to some other language that has a similar4 This assumption does not hold for a small number of verbs that take as a subject only animate nounswith a specific gender, such as YLDH (n"f~ ~, 'she gave birth.
')5 See Appendix B for the list of the rules used for Hebrew.389Computational Linguistics Volume 21, Number 3ambiguity problem, all we need to do is define a new set of rules for generation ofSW sets in that other language.By choosing the elements in the SW set carefully so that they meet he requirementof similarity, we can study the frequency of an analysis from the frequencies of theelements in its SW set.
Note that we should choose the words for the SW sets suchthat they are morphologically unambiguous.
We assume that this is the case in thefollowing examples, and will return to this issue in the next two sections.To illustrate the whole process, let us reconsider the ambiguous word HQPH(~flpn) and its three different analyses.
The SW sets for each analysis is as follows:?
HQPH (n~pn, 'encirclement')SW1 = { HHQPH (n~pnn, 'the encirclement') }?
H + QPH ( n~p + n, 'the coffee')SW2 = { QPH (hillY, 'coffee') }?
HQP + H (n + qpn, 'her perimeter')SW3 = { HQPW (~flpn, 'his perimeter'),HQPM (O~pn, masculine 'their perimeter'),HQPN (lflpn, feminine 'their perimeter') }.Given the SW set of each analysis we can now find in the corpus how many timeseach word appears, calculate the expected frequency of each analysis, and get thedesired probabilities by normalizing the frequency distribution.Had our similarity assumption been totally correct, namely, that each word inthe SW set appears exactly the same number of times as the related analysis, wewould have expected to get a neat situation such as the following (assuming that theambiguous word HQPH appears 200 times in the corpus): 6?
SW 1 = { HHQPH = 18 }" SW2={QPH=180}?
SW3 = { HQPW = 2, HQPM = 2, HQPN = 2 }.These counters uggest hat if we manually tagged the 200 occurrences of thestring HQPH in the corpus, we would find that the first analysis of HQPH is the rightone 18 times out of the 200 times that the word appears in the corpus, that the secondanalysis is the right one 180 times, and that the third analysis is the right analysis onlytwice.Using these counters we can relate the following morpho-lexical probabilities tothe three analyses of HQPH: 0.09, 0.90, 0.01, respectively.
These probabilities must beconsidered an approximation to the real morpho-lexical probabilities, because of thefollowing reasons:..The words in the SW set are only expected to appear approximately thesame number of times as the analysis they represent.The reliability of the probabilities we acquire using our method ependson the number of times the ambiguous word appears in the corpus6 The numbers inthis example are fictitious.
They were chosen i  order to clarify our point.390Moshe Levinger et al Learning Morpho-Lexical Probabilities(which is really the size of the sample we use to calculate themorpho-lexical probabilities).In the corpus we worked with, the word HQPH appeared 202 times, and thenumber of occurrences of the words in its SW sets were as follows:?
SW1 ={HHQPH=3}?
SW2={QPH=368}?
SW3 = { HQPW = 0, HQPM = 0, HQPN = 0 }.By applying now the algorithm of the next section on these counters, we cancalculate the desired probabilities.6.
The AlgorithmOur algorithm has to handle the frequently occurring case in which a certain wordappears in more than one SW set.
In that case, we would like to consider the counterof such a word appropriately.
The algorithm takes care of this problem and works asfollows:Initially we assume that the proportions between the different analysesare equal.For each analysis we compute its average number of occurrences, bysumming up all the counters for each word in the SW set and dividingthis sum by the SW size.
Note that in this stage we also include theambiguous word in each of the SW sets.
7If a word appears in several SW sets, we calculate its contribution to thetotal sum according to the proportions between all those sets, using theproportions calculated in the previous iteration.Calculate the new proportions between the different analyses bycomputing the proportions between the average number of occurrencesof each analysis.This process is iterated until the new proportions calculated aresufficiently close to the proportions calculated in the previous iteration.Finally, the proportions are normalized to obtain probabilities.A formal description of the algorithm written in a pseudo-code is given in Figure 1.7 This is done mainly in order to handle cases where a certain analysis has an empty SW set, since itdoes not have naturally similar words.
The third example in the next section serves to clarify this point.391Computational Linguistics Volume 21, Number 3Input:w - A word  with k analyses: A1 .
.
.
.
.
Ak.SW1 .
.
.
.
.
SWk - The similar words  sets of analyses A1, .
.
.
,Ak.sw - A word  in some SW set.C(sw) - The number  of occurrences of sw in the training corpus.Inc (sw) - A set of indexes representing the analyses for which sw is a member  intheir SW set, i.e., Inc(sw) = {1:1 < / < k, sw E SWl}e - A prespecif ied threshold indicating the convergence of the algorithm.Internal Variables:/:j - The approx imated morphoqexica l  probabi l i ty of Aj in the i-th iteration.SumAnalj - The sum over the contr ibut ion of all the words  in SWj.AvgAnalj - The average contr ibut ion of a single word  in SWj to SumAnalj.The Algorithm:p0 := pO2... := pk o := 1/k;i := O;repeati := i+ l ;for j := 1 to k do beginK-~ pi-1 ,~ .SumAnalj = ~sw~SWj C(sw) x (F} -1 / ," 4~1nc(sw) l '"AvgAnalj := SumAnalj / size(SWj)end;for j := 1 to k doF~ := AvgAnalj / (AvgAnall + .
.
.
+ AvgAnalk)until ( maxj \[ P~ - p~-I \]< ~.
).Figure 1Calculating the approximated morpho-lexical probabilities.App ly ing  this a lgor i thm to the sets and the counters extracted from the corpus(our previous example) yields the fol lowing probabilities: 8?
HQPH = 0.0113?
H + QPH = 0.98708 Because of the finite nature of our algorithm, we assign non-zero probabilities even to events that donot occur in the training corpus.
This property agrees with common statistical practice (Agresti 1990).392Moshe Levinger et al Learning Morpho-Lexical Probabilities?
HQP + H = 0.0017.Although this method for acquiring morpho-lexical probabilities gives very goodresults for many ambiguous words, as will be shown in Section 8, we detected twotypes of inherently problematic ases:..Because of the high degree of morphological ambiguity in Hebrew, someof the words in the SW sets may also be ambiguous.
As long as the otherpossible analyses of such a word are not too frequent, it only slightlyaffects the final probabilities.
Otherwise, we might get wrong results byerroneously crediting the high number  of occurrences of such a word 9 toone of the analyses.
For this reason, we try to construct he SW sets fromas many suitable elements as possible, in order to be able to detect"misleading" words of this sort.Occasionally, the SW sets defined for two different analyses are actuallythe same.
Thus, a differentiation between those two analyses cannot bedone using our method.Another potentially problematic ase is the coverage problem, that arises when-ever we do not have enough data in the corpus for disambiguation of a certain word(see a discussion on this problem in Dagan, Itai, and Schwall \[1991\]).
This problem wasfound to occur very rarely-- for  only 3% of the ambiguous words in our test texts thecounters found in the corpus were smaller than 20.
We expect this percentage wouldbe even smaller had we used a larger training corpus.
For such words, we simplyignored the data and arbitrarily gave a uniform probabil ity to all their analyses.7.
ExamplesSeveral aspects of the algorithm described in the previous section can be better under-stood by looking at some clarifying examples.
To see an example for the convergenceof the algorithm, consider the neat situation described in Section 5 for the word HQPH:?
SWI= { HQPH = 200, HHQPH = 18 }?
SW2 = { HQPH = 200, QPH = 180 }?
SW3 = { HQPH = 200, HQPW = 2, HQPM = 2, HQPN = 2 }.For these sets and counters and for ~ = 0.001, the algorithm converges after 10iterations.
The probabilities for each iteration are given below:?
Iteration no.
1: P1 = 0.333, P2 = 0.333, P3 = 0.333?
Iteration no.
2: P1 = 0.230, P2 -= 0.671, P3 = 0.099?
Iteration no.
3: P1 = 0.164, P2 --- 0.803, P3 = 0.033?
Iteration no.
4: P1 = 0.128, P2 -= 0.857, P3 = 0.015?
Iteration no.
5: P1 = 0.110, P2 = 0.880, P3 = 0.010?
Iteration no.
6: P1 = 0.100, P2 = 0.890, P3 = 0.010?
Iteration no.
7: P1 = 0.095, P2 = 0.895, P3 = 0.0109 Because of technical reasons, we cannot decide whether a given word is ambiguous or not when weautomatically generate the words for the SW sets.
See Section 7 for more details.393Computational Linguistics Volume 21, Number 3?
Iteration no.
8: P1 = 0.092, P2 = 0.898, P3 = 0.010?
Iteration o.
9: Pt = 0.091, P2 = 0.899, P3 = 0.010?
Iteration o.
10: P1 = 0.091, P2 = 0.899, P3 = 0.010In this example the similarity assumption holds, and the words in the SW sets(excluding the word HQPH itself) are also unambiguous.
This need not hold in othersituations.As we have pointed out already, because of technical reasons we have not been ableto apply the morphological analyzer to the words in the SW sets, and thus we havenot been able to automatically observe that a given similar word is ambiguous by itself.The problem stems from the fact that we have been able to use the morphologicalanalyzer on personal computers only, while both the corpus and the program thatautomatically generates the SW sets for each analysis could have been used only onour mainframe computer.
Given this, the morphological analyzer was only used inorder to obtain the input files for the disambiguation project.Nonetheless, the fact that ambiguous words in the SW sets cannot be automaticallyidentified does not affect the quality of the probabilities obtained by our method formost ambiguous words.
1?
To see the reason for this, consider the word XWD$ (vd'nn)and its two analyses:..The noun XWD$ (Vd'I~r~, 'a month'):SW1 = { XWD$ = 2079, HXWD$ = 970 (~'nnn, 'the month') }The verb XWD$, masculine, singular, third person, past tense ('he/it wasresumed').SW2 = { XWD$ = 2079, XWD$H = 41 (n~'rln, 'she/it  was resumed'),XWD$W = 57 (Wd'f~r~, 'they were resumed') }Both XWD$H and XWD$W (SW2) are ambiguous words.
Still, since the countersfor these two words are substantially smaller than the counter for the word HXWD$(SW1), the probabilities calculated according to these counters can be considered asa reasonable approximation for the real morpho-lexical probabilities.
The algorithm,applied to these sets and counters, yielded the following probabilities: P1 = 0.961,P2 = 0.039.This kind of situation is not unique for the word XWD$.
Similar situations occurin many other ambiguous words in Hebrew.
Hence, not having the ability to identifyambiguous words in the SW sets has a meaningful effect on the quality of the prob-abilities only in cases where some similar word is ambiguous and its other analysisis frequent in the language.
In such cases the analysis that this word belongs to isassigned a higher probability than its real morpho-lexical probability.
We use the termmisleading words for such ambiguous imilar words.A partial solution for such cases was implemented in the revised algorithm weused for morpho-lexical probabilities calculation.
In this revised version we automat-ically identified similar words as misleading words by looking at the counters of allthe similar words in a given SW set.
A word was considered misleading if its counterwas at least five times greater than that of any other word in the set.
This solution wasnot applicable in cases where all the similar words in a given SW set were misleadingwords.10 In our test sample of 53 words, the probabilities were significantly affected by this phenomenon inonly three cases.394Moshe Levinger et al Learning Morpho-Lexical ProbabilitiesThe need to add the original ambiguous word to all the SW sets of its analysescan be made clear by the following example.
Consider the word AT (~t~) and its setsand counters, as found in our training corpus:1.
The direct object particle for definite nouns, AT.SW 1 = { AT = 197,501 }2.
The feminine, singular, second person, nominal personal pronoun AT(feminine 'you').SW2 = { AT = 197,501, ATH (n~I'() = 1689, ATM (t3nt~) = 891, ATN Qnl'0 =105 }3.
The noun AT ('a spade').SW3 = { AT = 197,501, HAT (nnn) = 0 }The key point here is that the particle AT has no natural similar word.
u Yet, fromthe above counters we should be able to deduce that the first analysis has a very highmorpho-lexical probability.
This is since the ambiguous word AT is very frequent inthe corpus, while the counters in the SW sets for the second and third analyses indicatethat these analyses are not the "reason" for the high frequency of AT in the corpus.Adding the ambiguous word to all the SW sets allows the algorithm to take thisfact into account.
Applying the algorithm on the above sets and counters yields thefollowing morpho-lexical probabilities: P1 = 0.9954, P2 = 0.0045, P3 = 0.0001.8.
Evaluating the ProbabilitiesBefore we evaluate the quality of the approximated probabilities that can be acquiredusing our method, we would like to start with a definition of three terms that will beused in this section:Morpho-Lexical Probabilities Estimated from a Training Corpus Given a largecorpus in Hebrew the morpho-lexical probabilities of a given word arethe probabilities of its analyses as calculated by manually tagging all theoccurrences of the given word in the corpus.
We will use the abbreviationmorpho-lexical probabilities to denote this term.Morpho-Lexical Probabilities Estimated over a Test-Corpus In order to avoidthe laborious effort needed for the manual tagging of all the occurrencesof an ambiguous word in a large corpus, we estimate the morpho-lexicalprobabilities by calculating them from a relatively small corpus.
The ab-breviation test-corpus probabilities will be used for this term.Approximated Probabilities Given an ambiguous word, the approximated prob-abilities of the word are the probabilities calculated using the methoddescribed in this paper.The approximated probabilities obtained by our method were evaluated by com-paring these probabilities with test-corpus probabilities obtained by manual tagging ofa relatively small corpus.
Since the approximation we acquire depends on the corpuswe have been using--texts taken from the Hebrew newspaper Ha'aretz12--we have to11 In fact, all the prepositions i  the language lack natural similar words.12 We would like to thank Ha'aretz for the permission touse magnetic tapes from its archives.395Computational Linguistics Volume 21, Number 3calculate the test-corpus probabilities from texts taken from the same source.
For thispurpose we used a small corpus consisting of more than 500,000 word-tokens takenfrom the same newspaper.For our experiment we picked from this small corpus two kinds of test groups.Test-group1 consisted of 30 ambiguous word-types chosen randomly from all the am-biguous word types appearing more than 100 times in the corpus.
For the secondtest group, test-group2, we randomly picked a short text from the corpus from whichwe extracted all the ambiguous word-tokens appearing at least 30 times in the smallcorpus.
This test group consisted of 23 words.These two test groups are of a different nature.
Test-group1 consists only of veryfrequent word types in Hebrew, but the test-corpus probabilities for these word typescan be viewed as a reliable estimate of the morpho-lexical probabilities.
The word-tokens in test-group2 better epresent the typical ambiguous word in the language,but their test-corpus probabilities were calculated from a relatively small sample oftagged words.For each word in these test groups, we extracted from the small corpus all thesentences in which the ambiguous word appears.
We then manually tagged each am-biguous word and found for each one of its analyses how many times it was theright analysis.
For example, the word AWLM (O~1b0 (taken from test-group1) has thefollowing two morphological nalyses:1.
The particle AWLM ('but').2.
The noun ^ WLM ('a hall').The word AWLM appeared 236 times in the small corpus.
By manually tagging allthe relevant sentences we found that the first analysis, 'but,' was the right analysis 232times, and the second analysis, 'a hall,' was the right analysis only 4 times.
Given thesenumbers we can calculate the relative weights of these two analyses: 232/236, 4/236and the test-corpus probabilities: 0.983, 0.017, respectively.
In the same way, using thesmall corpus we found the test-corpus probability, Ptest, for each of the analyses in thetest groups.Table 2 shows the test-corpus probabilities and the approximated probabilities forfive representative ambiguous words from our test groups.
In this table the approxima-tion for the probabilities of the first three words is very good while the approximationfor the fourth word is quantitatively poor, but still succeeds in identifying the firstanalysis of LPNY (~3~V, "before') as the dominant analysis.
As for the fifth word, herethe approximation we got is totally incorrect.
At the end of this section we shall iden-tify some cases for which our method fails to find a reasonable approximation for themorpho-lexical probabilities of an ambiguous word.In order to evaluate the quality of the approximation we got by our method, weshould compare the approximated probabilities for the words in these test groups withthe test-corpus probabilities we found.When we tried to make a quantitative comparison using statistical methods wefound that for many analyses Papp "looks" like a good approximation for Ptest, but froma statistical point of view the approximation is not satisfying.
The main reason for thisis that the words in the SW set of a given analysis can be considered similar in theirfrequency to the analysis only from a qualitative point of view, and not from a quan-titative one.
Thus, the comparison we describe in what follows serves for evaluationof the quality of the approximated probabilities.Motivated by the way we use the morpho-lexical probabilities for morphologicaldisambiguation, we can divide the probability of an analysis into three categories:396Moshe Levinger et al Learning Morpho-Lexical ProbabilitiesTable 2Approximated and test-corpus probabilities for five ambiguous words from the two testgroups.Ambiguous Approximated Relative Test-CorpusWord  Probability Weight Probability^WLM 0.968 232/236 0.983(~N)  0.032 4/236 0.017AT 0.995 300/300 1.000(~)  0.001 0/300 0.0000.004 0/300 0.000XWD$ 0.976 75/78 0.962(?A~ID) 0.024 3/78 0.038LPNY 0.725 100/100 1.000(~)  0.274 0/100 0.0000.001 0/100 0.000^LH 0.141 112/168 0.667(n~N) 0.005 0/168 0.0000.001 0/168 0.0000.849 56/168 0.3330.001 0/168 0.000...Very high probability An analysis with a probability from this categoryis the dominant analysis of the ambiguous word and thus, given that wecannot use any other source of information to disambiguate he givenword, we would like to select he dominant analysis as the right analysis.Very low probability Given no other information, an analysis with avery low probability should be treated as a wrong analysis.All other probabilities An analysis with probability of this sort shouldnot be selected as wrong/right analysis olely according to itsmorpho-lexical probability.Formally, the mapping from the probability of an analysis to its category is doneusing two thresholds, upper threshold and lower threshold, as follows:1 prob ~ upper thresholdCAT(prob) = 2 prob ~ lower threshold3 otherwiseThe quality of the approximated probabilities we acquire using our method is nowmeasured by examining the proportion of words for which the estimated category foreach of their analyses agrees with the category defined by the approximated proba-bilities.
The results of this comparison for the two test groups we used are shown inTable 3 and Table 4.
In these tables we divide the words into three groups accordingto the quality of the approximation found for them:1.
Words with good approximation--words for whichCAT(Ptest) = CAT(Papp) holds for all their analyses, using: lower397Computational LinguisticsTable 3The quality of the approximation for test-group1.Volume 21, Number 3Total Good Reasonable IncorrectApproximation Approximation ApproximationNumber of Words 30 29 0 1% 100 97 0 3Table 4The quality of the approximation for test-group2.Total Good Reasonable IncorrectApproximation Approximation ApproximationNumber of Words 23 17 2 4% 100 74 9 17..threshold = 0.20, and upper threshold = 0.80.
(The first three words inTable 2 belong to this category).Words with reasonable approximation--words that do not fall into theprevious category, but CAT(Ptest) = CAT(Papp) holds for all their analyses,using: lower  threshold = 0.35, and upper threshold = 0.65 (The fourthword in Table 2 belongs to this category).Words with incorrect approximation--the words whose approximation isneither good nor reasonable.
(The fifth word in Table 2 belongs to thiscategory).From these tables we can see that our method yielded incorrect approximation foronly 5 words out of the 53 words in the test groups (9.5%).
By closely looking at thesewords, we can identify two reasons for failure:..Ambiguity of a word in the SW set of a given analysis.
This may affectthe probabilities calculated for this analysis.
To see that, consider theword MWNH (~\]1r2) (test-group2), one analysis of which is the nounMWNH ('a counter').
By manually tagging all the occurrences ofMWNH in our small corpus, we found that the above-mentionedanalysis is extremely rare--its relative weight is 0/44.
As for theapproximated probability of this analysis, its SW set contains a singleword: HMWNH (n~lr~n, 'the counter'), the definite form of the samenoun.
The word HMWNH is very frequent in our corpus and for thatreason the approximated probability found for this analysis is very high:0.894.
The mismatch between Ptest and Papp in this case is due to the factthat HMWNH is a misleading word- -an  ambiguous word one analysisof which H + present form of MNH (~\]r~, 'numbered'), is a frequentidiom in Hebrew ('which numbers').Our method may also yield an incorrect approximation for analyseswhere the similarity assumption we use between the frequency of an398Moshe Levinger et al Learning Morpho-Lexical Probabilitiesanalysis and the frequency of the words in its SW set does not hold.
Anexample for this is the word $&H (n~Vd) (test-group2), and one of itsanalyses the noun $&H ('an hour').
The approximated probability forthis analysis is calculated by looking at the frequency of the similar wordH$&H (~Vdn, 'the hour').
Unfortunately, the similarity assumption doesnot hold in this case, since the indefinite form of $&H is much morefrequent in Hebrew than the definite form of the word.
For this reason, 13the approximated probability for this analysis (0.376) is substantiallylower than its test-corpus probability (0.847).9.
Morphological DisambiguationIn the previous ection we compared the approximated probabilities obtained by ourmethod to the probabilities found by manually tagging a small corpus.
We found thatthe acquired probabilities are truly a good approximation for the morpho-lexical prob-abilities.
In this section we describe an experiment that was conducted in order to testthe effectiveness of the morpho-lexical probabilities for morphological disambiguationin Hebrew.Following are the main components in our project that were used in order toconduct he experiment:1.
A robust morphological nalyzer for Hebrew that gives for each word inthe language all its possible analyses.
The input for our project issupplied by this module.2.
An interactive program for manually tagging Hebrew texts.
It wascreated in order to rapidly tag large texts and was used to mark the rightanalysis for each ambiguous word in order to be used later to evaluatethe performance of our method.3.
Untagged Hebrew corpus.
Because of the fact that Hebrew corpora(untagged and tagged as well) are not available in the public domain, wehad to build a Hebrew corpus especially for this project.
This corpusconsists of 11 million word-tokens taken from the daily newspaperHa'aretz.4.
A hash table that stores all the words in the corpus.
Each word isaccompanied by a counter indicating how many times it appears in thecorpus.
Since this is the only information we extract from the corpus, ouralgorithm needs only this hash table and is therefore very efficient.5.
A morphological generator for Hebrew that was written especially forthis project.
The SW sets for every analysis are generated using thismodule.
Because of technical reasons, we were not able to use themorphological nalyzer at this stage, and thus we could not identifyambiguous words in the SW sets.6.
An implementation of the iterative algorithm that calculates theprobabilities.13 The indefinite form of $&H appears in many Hebrew idioms, e.g., LPY $&H (n~)9~,  'for the timebeing'), B^WTH $&H (D~ ~l lR~l ,  'at the same time') etc.399Computational Linguistics Volume 21, Number 3.
A simple selection algorithm that reduces the level of morphologicalambiguity using the probabilities obtained from the corpus.
Thealgorithm uses two thresholds, an upper threshold and a lowerthreshold, which serve to choose the right analysis or to rule out wronganalyses, respectively.A set of 21 articles was selected in order to test the performance of the method.Since the morpho-lexical probabilities we use are calculated from a large Hebrewcorpus (representing a certain Hebrew sublanguage), these 21 texts were randomlyselected from texts belonging to the same sublanguage.
The total number of word-tokens in these test texts was 3,400, out of which nearly 50% were morphologicallyambiguous.The reason for testing the method only on a relatively small set of test texts is thatno tagged Hebrew corpus is currently available for a more powerful evaluation.
Theneed to manually tag the texts used for evaluation limited the number of words in thetest texts we used.
Nevertheless, we believe that the results obtained for this restrictedset of texts gives a fairly good indication for the success of the method on large textsas well.We tested the performance of the method on the test texts from two differentperspectives.
First, we used the probabilities only for ambiguous words that can befully disambiguated.
In this case a single analysis can be selected as the right analysis.The performance of the method for full-disambiguation is measured by the recallparameter, which is defined as follows:no.
of correctly assigned words Recall = no.
of ambiguous wordsIn addition to this parameter we present wo additional performance parameters:applicability and precision.
We believe that these parameters are relevant for theparticular naive method described in the current section.
This is due to the fact thatthe morpho-lexical probabilities are not supposed to be used alone for disambiguation,but rather are meant to serve as one information source in a system that combinesseveral inguistic sources for disambiguation.
The above-mentioned parameters aredefined as follows:no.
of correctly assigned words Precision = no.
of fully disambiguated wordsno.
of fully disambiguated wordsApplicability = no.
of ambiguous wordsThe results obtained for full disambiguation are shown in Table 5.
However, themorpho-lexical probabilities can also be used in order to reduce the ambiguity levelin the text.
The performance of the method in this sense is much more interestingand important since it examines, more accurately, the quality of the probabilities asdata for other, more sophisticated, systems that use higher levels of information.
Inthis experiment we test the performance of the morpho-lexical probabilities on thetask of analysis assignment.
Here one or more analyses of an ambiguous word arerecognized as wrong and hence are rejected.
The right analysis should be one of theremaining analyses.
The three parameters used for evaluation are as follows:no.
of correct right assignments Recall = no.
of ambiguous words400Moshe Levinger et alTable 5The performance for full disambiguation.Learning Morpho-Lexical ProbabilitiesAmbiguous Disambiguated Correct Recall Applicability PrecisionWords Words Assignments1613 1315 1160 72% 82% 88%Table 6The performance for analysis assignment.Ambiguous Wrong Remaining Correct Incorrect Recall Precision FalloutWords Analyses Analyses Assignments Assignments1613 3260 1802 1444 358 90% 80% 11%Table 7Reducing the degree of ambiguity.Number of Remaining AnalysesAnalyses Total 1 2 3 4 5 6 7 8 9 103 487 411 62 144 218 170 36 11 15 90 72 12 4 2 06 52 40 12 0 0 07 28 22 6 0 0 08 11 8 2 1 0 09 1 1 0 0 0 010 4 4 0 0 0 0total 891 728 130 30 3 000 00 0 00 0 0 00 0 0 00 0 0 0Precision = no.
of correct right assignmentsno.
of remaining analysesFallout -- no.
of incorrect assignmentsno.
o/wrong analysesThe results are shown in Table 6.
In another experiment we examined 891 wordswith more than two analyses.
Table 7 shows how our algorithm reduced the ambiguityof these words.These results demonstrate the effectiveness of morpho-lexical probabilities in re-ducing the ambiguity level in a Hebrew text, and it seems that by using such informa-tion combined with other approaches for morphological disambiguation i Hebrew,we come very close to a practical solution for this problem.10.
ConclusionsA method to acquire morpho-lexical probabilities from an untagged corpus has beendescribed.
The main idea was to use the rich morphology of the language to learn the401Computational Linguistics Volume 21, Number 3frequency of a certain analysis from the frequency of other word forms of the samelexical entry.The results of the experiment confirm the conjecture we made about the nature ofthe morphological mbiguity problem in Hebrew.
It can be argued, therefore, that thecomputer with its complete morphological knowledge is facing a much more complexproblem than that of a human who may be ignorant of some rare analyses readinga Hebrew text.
This observation is also supported by the fact that humans are veryoften surprised to see the amount of possible analyses of a given ambiguous word.It may even have a significance from a psycholinguistic point of view, by suggestingthat these kind of probabilities are also used by a human reader of Hebrew.
However,this conjecture should be tested empirically.An experiment to test the usefulness of the morpho-lexical probabilities for mor-phological disambiguation i  Hebrew yielded the following results: a recall of 70% forfull disambiguation, and a recall of 90% for analysis assignment.However, the morpho-lexical probabilities cannot serve as the only source of infor-mation for morphological disambiguation, since they are imperfect by definition--theyalways choose the same analysis as the right one, regardless of the context in whichthe ambiguous word appears.
Thus, as has been already mentioned, we have incor-porated these probabilities into an existing system for morphological disambiguation.The combined system tackles the disambiguation problem by combining two kindsof linguistic information sources: Morpho-Lexical Probabilities and Syntactic Con-straints (a full description of this system can be found in Levinger \[1992\]).Appendix  AGiven below is the Latin-Hebrew transliteration used throughout he paper.
Notethat accepted transcriptions for Hebrew (Academy of The Hebrew Language 1957;Ornan 1994) include indication for the vowels that are missing in the modern Hebrewwriting system.
For this reason, these transcriptions are not suitable for demonstratingthe morphological mbiguity problem in the language.
Instead, we use the followingtransliteration, which is based on the phonemic script (Ornan 1994); see Table 8.Appendix  BFollowing is the set of rules used for Hebrew in order to automatically generate the SWset for every morphological nalysis in Hebrew.
Note that in case an analysis includesa particular attached particle, this particle is also attached to each of its similar words.Table 8The Hebrew-Latin transliteration.Latin Hebrew Latin Hebrew Latin HebrewP %9 @ k3 A NC R,~ Y ) B 2Q ~ K 1,~ GR 7 L ~ D "t$ Vd M 0,~ H DT n N "1,\] W "1S t3 Z& ~ X B402Moshe Levinger et al Learning Morpho-Lexical Probabilities.
?3......9.10.A definite form of a noun- - the SW set includes the indefinite form ofthe same noun.An indefinite form of a noun- - the definite form of the same noun.A noun with a possessive pronoun-- the same noun with all the otherpossessive pronouns with the same person attribute.An adjective---the other forms of the same adjective (changing thegender and number attributes).A verb without an object pronoun-- the same verb in the same tense andperson (changing the gender and number  attributes only).A verb with an object pronoun- - the same verb form with all the otherobject pronouns forms (preserving the person attribute while changingthe gender and number  ones).Nominal personal pronoun- - the other nominal personal pronouns of thesame person.A masculine form of a number- - the feminine form of the same number.A feminine form of a number- - the masculine form of the same number.A proper noun, a particle (preposition, connective, etc.)
--the mpty SWset.AcknowledgmentsThis research was partially supported bygrant number 1380031 of the Israel Councilfor Research and Development.We would like to thank Ayal Shiran andOhad Zeliger for programming support ofthis project and Ido Dagan for usefuldiscussions concerning this paper.
Wewould also like to thank IBM, whichenabled us to complete this paper.ReferencesAcademy of The Hebrew Language (1957).
"The rules for Hebrew-Latin transcription.
"Memoirs of the Academy of the HebrewLanguage, 5--8.Agresti, Alan (1990).
Categorical DataAnalysis.
John Wiley and Sons.Albeck, Orly (1992).
"Formal analysis in aregister of Israeli Hebrew using apredicative grammar."
In HebrewComputational Linguistics, edited byU.
Ornan, G. Arieli, and I. Doron, 88-102.Israel Ministry of Science and Technology.Bentur, Esther; Angel, Aviela; and Segev, D.(1992).
"Computerized analysis ofHebrew words."
In Hebrew ComputerizedLinguistics.
Israel Ministry of Science andTechnology.Choueka, Yaacov (1980).
"Full-text systemsand research in the humanities.
"Computers and the Humanities, 14, 153-169.Choueka, Yaacov, and Lusignan, S.
(1985).
"Disambiguation by short contexts.
"Computers and the Humanities, 19, 147-157.Church, Kenneth W. (1988).
"A stochasticparts program and noun phrase parserfor unrestricted text."
In Proceedings, ACLConference on Applied Natural LanguageProcessing, 136-143.Church, Kenneth W. (1992).
"Currentpractice in part of speech tagging andsuggestions for the future."
In For HenryKu~era, edited by A. W. Mackie,T.
K. McAuley, and C. Simmons, 13-48.Michigan Slavic Publications, Universityof Michigan.Cutting, Doug; Kupiec, Julian; Pedersen,Jan; and Sibun, Penelope (1992).
"Apractical part-of-speech tagger."
InProceedings, ACL Conference on AppliedNatural Language Processing, 133-140.Dagan, Ido, and Itai, Alon (1994).
"Wordsense disambiguation using a secondlanguage monolingual corpus.
"Computational Linguistics, 20(4), 563-596.Dagan, Ido; Itai, Alon; and Schwall, Ulrike(1991).
"Two languages are moreinformative than one."
In Proceedings,Annual Meeting of the ACL, 130-137.403Computational Linguistics Volume 21, Number 3DeRose, Steven J.
(1988).
"Grammaticalcategory disambiguation by statisticaloptimization."
Computational Linguistics,14(1), 31-39.ISO Conference (1994).
Conversion ofHebrew characters into Latin characters,Part 3: Phonemic Conversion (ISO-259-3).Stockholm: Ornan, Uzzi.Jelinek, Frederick; Mercer, Robert L.; andRoukos, Salim (1992).
"Principles oflexical anguage modeling for speechrecognition."
In Advances in Speech SignalProcessing, edited by Sadaoki Furui andM.
Mohan Sondhi, 651-699.
MarcelDekker, Inc.Karlsson, Fred (1990).
"Constraint grammaras a framework for parsing running text.
"In Proceedings, 13 th International Conferenceon Computational Linguistics (COLING-90).3:168-179.Kupiec, Julian (1992).
"Robustpart-of-speech tagging using a hiddenMarkov model."
Computer Speech andLanguage, 6, 225-242.Levinger, Moshe (1992).
Morphologicaldisambiguation.
Master's thesis, ComputerScience Department, Technion--IsraelInstitute of Technology.Ornan, Uzzi (1986).
"Phonemic script: Acentral vehicle for processing NL--thecase of Hebrew."
Technical Report 88-181,IBM Scientific Center, Haifa.Ornan, Uzzi (1987).
"Computerized index todecisions of supreme court by phonemicscript."
Mishpatim, 17, 15-24.Ornan, Uzzi (1991).
"Theoretical geminationin Israeli Hebrew."
In Semitic Studies inHonor of Wolf Leslau, edited by Alan S.Kaye, Otto Harrassowitz.
1158-1168.Pines, Ronny (1975).
"Ambiguity on thesyntactic level."
In Rosen Memorial Volume,edited by Ben-Zion Fischler and UzziOrnan, 74-85.
Council of the Teaching ofHebrew.Yarowsky, David (1992).
"Word sensedisambiguation using statistical models ofRoget's categories trained on largecorpora."
In Proceedings, 14th InternationalConference on Computational Linguistics(COLING-92).
454-460.404
