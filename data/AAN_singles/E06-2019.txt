Classifying Biological Full-Text Articles for Multi-Database CurationWen-Juan Hou, Chih Lee and Hsin-Hsi ChenDepartment of Computer Science and Information Engineering,National Taiwan University, Taipei, Taiwan{wjhou, clee}@nlg.csie.ntu.edu.tw; hhchen@csie.ntu.edu.twAbstractIn this paper, we propose an approachfor identifying curatable articles from alarge document set.
This systemconsiders three parts of an article (titleand abstract, MeSH terms, and captions)as its three individual representationsand utilizes two domain-specificresources (UMLS and a tumor name list)to reveal the deep knowledge containedin the article.
An SVM classifier istrained and cross-validation is employedto find the best combination ofrepresentations.
The experimentalresults show overall high performance.1 IntroductionOrganism databases play a crucial role ingenomic and proteomic research.
It stores theup-to-date profile of each gene of the speciesinterested.
For example, the Mouse GenomeDatabase (MGD) provides essential integrationof experimental knowledge for the mousesystem with information annotated from bothliterature and online sources (Bult et al, 2004).To provide biomedical scientists with easyaccess to complete and accurate information,curators have to constantly update databaseswith new information.
With the rapidlygrowing rate of publication, it is impossible forcurators to read every published article.
Sincefully automated curation systems have not metthe strict requirement of high accuracy and recall,database curators still have to read some (if notall) of the articles sent to them.
Therefore, itwill be very helpful if a classification system cancorrectly identify the curatable or relevantarticles in a large number of biological articles.Recently, several attempts have been made toclassify documents from biomedical domain(Hirschman et al, 2002).
Couto et al (2004)used the information extracted from related webresources to classify biomedical literature.
Houet al (2005) used the reference corpus to helpclassifying gene annotation.
The GenomicsTrack (http://ir.ohsu.edu/genomics) of TREC2004 and 2005 organized categorization tasks.The former focused on simplified GO termswhile the latter included the triage for "tumorbiology", "embryologic gene expression","alleles of mutant phenotypes" and "GO" articles.The increase of the numbers of participants atGenomics Track shows that biologicalclassification problems attracted much attention.This paper employs the domain-specificknowledge and knowledge learned from full-textarticles to classify biological text.
Given acollection of articles, various methods areexplored to extract features to represent adocument.
We use the experimental dataprovided by the TREC 2005 Genomics Track toevaluate different methods.The rest of this paper is organized as follows.Section 2 sketches the overview of the systemarchitecture.
Section 3 specifies the test bedused to evaluate the proposed methods.
Thedetails of the proposed system are explained inSection 4.
The experimental results are shownand discussed in Section 5.
Finally, we makeconclusions and present some further work.2 System OverviewFigure 1 shows the overall architecture of theproposed system.
At first, we preprocess eachtraining article, and divide it into three parts,including (1) title and abstract, (2) MeSH termsassigned to this article, and (3) captions offigures and tables.
They are denoted as"Abstract", "MeSH", and "Caption" in this paper,respectively.
Each part is considered as arepresentation of an article.
With the help ofdomain-specific knowledge, we obtain moredetail representations of an article.
In themodel selection phase, we perform featureranking on each representation of an article andemploy cross-validation to determine thenumber of features to be kept.
Moreover, weuse cross-validation to obtain the bestcombination of all the representations.
Finally,a support vector machine (SVM) (Vapnik, 1995;Hsu et al, 2003) classifier is obtained.1593 Experimental DataWe train classifiers for classifying biomedicalarticles on the Categorization Task of the TREC2005 Genomics Track.
The task uses data fromthe Mouse Genome Informatics (MGI) system(http://www.informatics.jax.org/) for fourcategorization tasks, including tumor biology,embryologic gene expression, alleles of mutantphenotypes and GO annotation.
Given adocument and a category, we have to identifywhether it is relevant to the given category.The document set consists of some full-textdata obtained from three journals, i.e., Journal ofBiological Chemistry, Journal of Cell Biologyand Proceedings of the National Academy ofScience in 2002 and 2003.
There are 5,837training documents and 6,043 testing documents.4 Methods4.1 Document PreprocessingIn the preprocessing phase, we perform acronymexpansion on the articles, remove the remainingtags from the articles and extract three parts ofinterest from each article.
Abbreviations areoften used to replace long terms in writingarticles, but it is possible that several long termsshare the same short form, especially forgene/protein names.
To avoid ambiguity andenhance clarity, the acronym expansionoperation replaces every tagged abbreviationwith its long form followed by itself in a pair ofparentheses.4.2 Employing Domain-Specific KnowledgeWith the help of domain-specific knowledge, wecan extract the deeper knowledge in an article.For example, with a gene name dictionary, wecan identify the gene names contained in anarticle.
Moreover, by further consultingorganism databases, we can get the properties ofthe genes.
Two domain-specific resources areexploited in this study.
One is the UnifiedMedical Language System (UMLS) (Humphreyset al, 1998) and the other is a list of tumornames obtained from Mouse Tumor BiologyDatabase (MTB)1.UMLS contains a huge dictionary ofbiomedical terms ?
the UMLS Metathesaurusand defines a hierarchy of semantic types ?
theUMLS Semantic Network.
Each concept in theMetathesaurus contains a set of strings, whichare variants of each other and belong to one ormore semantic types in the Semantic Network.Therefore, given a string, we can obtain a set ofsemantic types to which it belongs.
Then weobtain another representation of the article bygathering the semantic types found in the part ofthe article.
Consequently, we get another threemuch deeper representations of an article afterthis step.
They are denoted as "AbstractSEM","MeSHSEM" and "CaptionSEM".We use the list of tumor names on the Tumortask.
We first tokenize all the tumor names andstem each unique token.
With the resulting listof unique stemmed tokens, we use it as a filter toremove the tokens not in the list from the"Abstract" and "Caption", which produce"AbstractTM" and "CaptionTM".4.3 Model SelectionAs mentioned above, we generate severalrepresentations for an article.
In this section,we explain how feature selection is done andhow the best combination of the representations1 http://tumor.informatics.jax.org/mtbwi/tumorSearch.doA NewFull-TextArticleFull-TextTrainingArticlesAbstractMeSHCaptionModelSelectionAbsSEM/TMPreprocessingMeSHSEMCapSEM/TMDomain-SpecificKnowledgeSVMClassifierYes/NoPartsSEM/TMPreprocessing MultiplePartsFigure 1.
System Architecture160of an article is obtained.For each representation, we first rank all thetokens in the training documents via thechi-square test of independence.
Postulatingthe ranking perfectly reflects the effectiveness ofthe tokens in classification, we then decide thenumber of tokens to be used in SVMclassification by 4-fold cross-validation.
Incross-validation, we use the TF*IDF weightingscheme.
Each feature vector is thennormalized to a unit vector.
We set C+ to ur* C-because of the relatively small number ofpositive examples, where C+ and C- are thepenalty constants on positive and negativeexamples in SVMs.
After that, we obtain theoptimal number of tokens and the correspondingSVM parameters C- and gamma, a parameter inthe radial basis kernel.
In the rest of this paper,"Abstract30" denotes the "Abstract"representation with top-30 tokens,"CaptionSEM10" denotes "CaptionSEM" withtop-10 tokens, and so forth.After feature selection is done for eachrepresentation, we try to find the bestcombination by the following algorithm.Given the candidate representations withselected features, we start with an initial setcontaining some or zero representation.
Foreach iteration, we add one representation to theset by picking the one that enhances thecross-validation performance the most.
Theiteration stops when we have exhausted all therepresentations or adding more representation tothe set doesn?t improve the cross-validationperformance.For classifying the documents with betterfeatures, we run the algorithm twice.
We firststart with an empty set and obtain the bestcombination of the basic three representations,e.g., "Abstract10", "MeSH30" and "Caption10".Then, starting with this combination, we attemptto incorporate the three semantic representations,e.g., "Abstract30SEM", "MeSH30SEM" and"Caption10SEM", and obtain the finalcombination.
Instead of using this algorithm toincorporate the "AbstractTM" and "CaptionTM"representations, we use them to replace theirunfiltered counterparts "Abstract" and "Caption"when the cross-validation performance is better.5 Results and DiscussionsTable 1 lists the cross-validation results of eachrepresentation for each category (in NormalizedUtility (NU)2 measure).
For category Allele,"Caption" and "AbstractSEM" perform the bestamong the basic and semantic representations,respectively.
For category Expression,"Caption" plays an important role in identifyingrelevant documents, which agrees with thefinding by the winner of KDD CUP 2002 task 1(Regev et al, 2002).
Similarly, MeSH termsare crucial to the GO category, which are usedby top-performing teams (Dayanik et al, 2004;Fujita, 2004) in TREC Genomics 2004.
Forcategory Tumor, MeSH terms are important, butafter semantic type extraction, "AbstractSEM"exhibits relatively high cross-validationperformance.
Since only 10 features areselected for the "AbstractSEM", using thisrepresentation alone may be susceptible toover-fitting.
Finally, by comparing theperformance of the "AbstractTM" and"Abstract", we find the list of tumor nameshelpful for filtering abstracts.We list the results for the test data in Table 2.Column "Experiment" identifies our proposedmethods.
We show six experiments in Table 2:one for Allele (AL), one for Expression (EX),one for GO (GO) and three for Tumor (TU, TNand TS).
Column "cv NU" shows thecross-validation NU measure, "NU" shows theperformance on the test data and column"Combination" lists the combination of therepresentations used for each experiment.
Inthis table, "M30" is the abbreviation for"MeSH30", "CS10" is for "CaptionSEM10", andso on.
The combinations for the first 4experiments, i.e., AL, EX, GO and TU, areobtained by the algorithm described in Section4.3, while the combination for TN is obtained bysubstituting "AbstractTM30" for "Abstract30" inthe combination for TU.
The experiment TSonly uses the "AbstractSEM10" because itscross-validation performance beats all othercombinations for the Tumor category.The combinations of the first 5 experimentsillustrate that adding other inferiorrepresentations to the best one enhances theperformance, which implies that the inferiorones may contain important exclusiveinformation.
The cross-validation performancefairly predicts the performance on the test data,except for the last experiment TS, which relieson only 10 features and is therefore susceptibleto over-fitting.2 Please refer to the TREC 2005 Genomics Track Protocol(http://ir.ohsu.edu/genomics/2005protocol.html).161Allele Expression GO Tumor# Tokens / NU # Tokens / NU # Tokens / NU # Tokens / NUAbstract 10 / 0.7707 10 / 0.5586 10 / 0.4411 10 / 0.8055MeSH 10 / 0.7965 10 / 0.6044 10 / 0.4968 30 / 0.8106Caption 10 / 0.8179 10 / 0.7192 10 / 0.4091 10 / 0.7644AbstractSEM 10 / 0.7209 10 / 0.4811 10 / 0.3493 10 / 0.8814MeSHSEM 10 / 0.6942 10 / 0.4563 10 / 0.4403 10 / 0.7047CaptionSEM 30 / 0.6789 10 / 0.5433 10 / 0.2551 30 / 0.7160AbstractTM 30 / 0.8325CaptionTM 10 / 0.7498Table 1.
Partial Cross-validation Results.Experiment cv NU NU Recall Precision F-score CombinationAL (for Allele) 0.8717 0.8423 0.9488 0.3439 0.5048 M30+C10+A10+CS10+AS10+MS10EX (for Expression) 0.7691 0.7515 0.8190 0.1593 0.2667 M10+C10+CS10+MS10GO (for GO) 0.5402 0.5332 0.8803 0.1873 0.3089 M10+C10+MS10TU (for Tumor) 0.8742 0.8299 0.9000 0.0526 0.0994 M30+C30+A30+AS10+CS30TN (for Tumor) 0.8764 0.8747 0.9500 0.0518 0.0982 M30+C30+AT30+AS10+CS30TS (for Tumor) 0.8814 0.5699 0.6500 0.0339 0.0645 AS10Table 2.
Evaluation Results.Subtask NU (Best/Median) Recall (Best/Median) Precision (Best/Median) F-score (Best/Median)Allele 0.8710/0.7773 0.9337/0.8720 0.4669/0.3153 0.6225/0.5010Expression 0.8711/0.6413 0.9333/0.7286 0.1899/0.1164 0.3156/0.2005GO Annotation 0.5870/0.4575 0.8861/0.5656 0.2122/0.3223 0.3424/0.4107Tumor 0.9433/0.7610 1.0000/0.9500 0.0709/0.0213 0.1325/0.0417Table 3.
Best and Median Results for Each Subtask on TREC 2005 (Hersh et al, 2005).To compare with our performance, we list thebest and median results for each subtask on thegenomics classification task of TREC 2005 inTable 3.
Comparing to Tables 2 and 3, it showsour experimental results have overall highperformance.6 Conclusions and Further WorkIn this paper, we demonstrate how our system isconstructed.
Three parts of an article areextracted to represent its content.
Weincorporate two domain-specific resources, i.e.,UMLS and a list of tumor names.
For eachcategorization work, we propose an algorithm toget the best combination of the representationsand train an SVM classifier out of thiscombination.
Evaluation results show overallhigh performance in this study.Except for MeSH terms, we can try othersections in the article, e.g., Results, Discussionsand Conclusions as targets of feature extractionbesides the abstract and captions in the future.Finally, we will try to make use of otheravailable domain-specific resources in hope ofenhancing the performance of this system.AcknowledgementsResearch of this paper was partially supported byNational Science Council, Taiwan, under thecontracts NSC94-2213-E-002-033 andNSC94-2752-E-001-001-PAE.ReferencesBult, C.J., Blake, J.A., Richardson, J.E., Kadin, J.A., Eppig,J.T.
and the Mouse Genome Database Group.
The MouseGenome Database (MGD): Integrating Biology with theGenome.
Nucleic Acids Research, 32, D476?D481, 2004.Couto, F.M., Martins, B. and Silva, M.J.
Classifying BiologicalArticles Using Web Resources.
Proceedings of the 2004ACM Symposium on Applied Computing, 111-115, 2004.Dayanik, A., Fradkin, D., Genkin, A., Kantor, P., Lewis, D.D.,Madigan, D. and Menkov, V. DIMACS at the TREC 2004Genomics Track.
Proceedings of the Thirteenth TextRetrieval Conference, 2004.Fujita, S., Revisiting Again Document Length HypothesesTREC-2004 Genomics Track Experiments at Patolis.Proceedings of the Thirteenth Text Retrieval Conference,2004.Hersh, W., Cohen, A., Yang, J., Bhuptiraju, R.T., Toberts, P.and Hearst, M. TREC 2005 Genomics Track Overview.Proceedings of the Fourteenth Text Retrieval Conference,2005.Hirschman, L., Park, J., Tsujii, J., Wong, L. and Wu, C.H.Accomplishments and Challenges in Literature DataMining for Biology.
Bioinformatics, 18(12): 1553-1561,2002.Hou, W.J., Lee, C., Lin, K.H.Y.
and Chen, H.H.
A RelevanceDetection Approach to Gene Annotation.
Proceedings of theFirst International Symposium on Semantic Mining inBiomedicine, http://ceur-ws.org, 148: 15-23, 2005.Hsu, C.W., Chang, C.C.
and Lin, C.J.
A Practical Guide toSupport Vector Classification.
http://www.csie.ntu.edu.tw/~cjlin/libsvm/index.html, 2003.Humphreys, B.L., Lindberg, D.A., Schoolman, H.M. andBarnett, G.O.
The Unified Medical Language System: anInformatics Research Collaboration.
Journal of AmericanMedical Information Association, 5(1):1-11, 1998.Regev, Y., Finkelstein-Landau, M. and Feldman, R. Rule-basedExtraction of Experimental Evidence in the BiomedicalDomain - the KDD Cup (Task 1).
SIGKDD Explorations,4(2):90-92, 2002.Vapnik, V. The Nature of Statistical Learning Theory,Springer-Verlag, 1995.162
