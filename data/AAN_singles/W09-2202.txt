Proceedings of the NAACL HLT Workshop on Semi-supervised Learning for Natural Language Processing, pages 10?18,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsSurrogate Learning -From Feature Independence to Semi-Supervised ClassificationSriharsha Veeramachaneni and Ravi Kumar KondadadiThomson Reuters Research and DevelopmentEagan, MN 55123, USA[harsha.veeramachaneni,ravikumar.kondadadi]@thomsonreuters.comAbstractWe consider the task of learning a classi-fier from the feature space X to the set ofclasses Y = {0, 1}, when the features canbe partitioned into class-conditionally inde-pendent feature sets X1 and X2.
We showthat the class-conditional independence can beused to represent the original learning taskin terms of 1) learning a classifier from X2to X1 (in the sense of estimating the prob-ability P (x1|x2))and 2) learning the class-conditional distribution of the feature set X1.This fact can be exploited for semi-supervisedlearning because the former task can be ac-complished purely from unlabeled samples.We present experimental evaluation of the ideain two real world applications.1 IntroductionSemi-supervised learning is said to occur when thelearner exploits (a presumably large quantity of) un-labeled data to supplement a relatively small labeledsample, for accurate induction.
The high cost of la-beled data and the simultaneous plenitude of unla-beled data in many application domains, has led toconsiderable interest in semi-supervised learning inrecent years (Chapelle et al, 2006).We show a somewhat surprising consequence ofclass-conditional feature independence that leadsto a principled and easily implementable semi-supervised learning algorithm.
When the feature setcan be partitioned into two class-conditionally in-dependent sets, we show that the original learningproblem can be reformulated in terms of the problemof learning a first predictor from one of the partitionsto the other, plus a second predictor from the latterpartition to class label.
That is, the latter partitionacts as a surrogate for the class variable.
Assum-ing that the second predictor can be learned froma relatively small labeled sample this results in aneffective semi-supervised algorithm, since the firstpredictor can be learned from only unlabeled sam-ples.In the next section we present the simple yet in-teresting result on which our semi-supervised learn-ing algorithm (which we call surrogate learning) isbased.
We present examples to clarify the intuitionbehind the approach and present a special case ofour approach that is used in the applications section.We then examine related ideas in previous work andsituate our algorithm among previous approachesto semi-supervised learning.
We present empiricalevaluation on two real world applications where therequired assumptions of our algorithm are satisfied.2 Surrogate LearningWe consider the problem of learning a classifierfrom the feature space X to the set of classes Y ={0, 1}.
Let the features be partitioned into X =X1 ?
X2.
The random feature vector x ?
X will berepresented correspondingly as x = (x1,x2).
Sincewe restrict our consideration to a two-class problem,the construction of the classifier involves the esti-mation of the probability P (y = 0|x1,x2) at everypoint (x1,x2) ?
X .We make the following assumptions on the jointprobabilities of the classes and features.101.
P (x1,x2|y) = P (x1|y)P (x2|y) for y ?
{0, 1}.
That is, the feature sets x1 and x2are class-conditionally independent for bothclasses.
Note that, when X1 and X2 are one-dimensional, this condition is identical to theNaive Bayes assumption, although in generalour assumption is weaker.2.
P (x1|x2) 6= 0, P (x1|y) 6= 0 and P (x1|y =0) 6= P (x1|y = 1).
These assumptions areto avoid divide-by-zero problems in the alge-bra below.
If x1 is a discrete valued randomvariable and not irrelevant for the classificationtask, these conditions are often satisfied.We can now show that P (y = 0|x1,x2) canbe written as a function of P (x1|x2) and P (x1|y).When we consider the quantity P (y,x1|x2), wemay derive the following.P (y,x1|x2) = P (x1|y,x2)P (y|x2)?
P (y,x1|x2) = P (x1|y)P (y|x2)(from the independence assumption)?
P (y|x1,x2)P (x1|x2) = P (x1|y)P (y|x2)?
P (y|x1,x2)P (x1|x2)P (x1|y) = P (y|x2) (1)Since P (y = 0|x2) + P (y = 1|x2) = 1, Equa-tion 1 impliesP (y = 0|x1,x2)P (x1|x2)P (x1|y = 0) +P (y = 1|x1,x2)P (x1|x2)P (x1|y = 1) = 1?
P (y = 0|x1,x2)P (x1|x2)P (x1|y = 0) +(1?
P (y = 0|x1,x2))P (x1|x2)P (x1|y = 1) = 1(2)Solving Equation 2 for P (y = 0|x1,x2), we ob-tainP (y = 0|x1,x2) =P (x1|y = 0)P (x1|x2) ?P (x1|y = 1)?
P (x1|x2)P (x1|y = 1)?
P (x1|y = 0)(3)We have succeeded in writing P (y = 0|x1,x2) asa function of P (x1|x2) and P (x1|y).
Although thisresult was previously observed in a different contextby Abney in (Abney, 2002), he does not use it toderive a semi-supervised learning algorithm.
Thisresult can lead to a significant simplification of thelearning task when a large amount of unlabeled datais available.
The semi-supervised learning algorithminvolves the following two steps.1.
From unlabeled data learn a predictor from thefeature space X2 to the space X1 to predictP (x1|x2).
There is no restriction on the learnerthat can be used as long as it outputs posteriorclass probability estimates.2.
Estimate the quantity P (x1|y) from a labeledsamples.
In case x1 is finite valued, this canbe done by just counting.
If X1 has low car-dinality the estimation problem requires veryfew labeled samples.
For example, if x1 isbinary, then estimating P (x1|y) involves esti-mating just two Bernoulli probabilities.Thus, we can decouple the prediction problem intotwo separate tasks, one of which involves predict-ing x1 from the remaining features.
In other words,x1 serves as a surrogate for the class label.
Fur-thermore, for the two steps above there is no neces-sity for complete samples.
The labeled examples canhave the feature x2 missing.At test time, an input sample (x1,x2) is classifiedby computing P (x1|y) and P (x1|x2) from the pre-dictors obtained from training, and plugging thesevalues into Equation 3.
Note that these two quanti-ties are computed for the actual value of x1 taken bythe input sample.The following example illustrates surrogate learn-ing.?????????????
?Example 1Consider the following variation on a problemfrom (Duda et al, 2000) of classifying fish on a con-veryor belt as either salmon (y = 0) or sea bass(y = 1).
The features describing the fish are x1,a binary feature describing whether the fish is light(x1 = 0) or dark (x1 = 1), and x2 describes thelength of the fish which is real-valued.
Assume (un-realistically) that P (x2|y), the class-conditional dis-tribution of x2, the length for salmon is Gaussian,11and for the sea bass is Laplacian as shown in Fig-ure 1.?4 ?2 0 2 400.5x2P(x2|y=0) P(x2|y=1)Figure 1: Class-conditional probability distributions ofthe feature x2.Because of the class-conditional feature in-dependence assumption, the joint distributionP (x1,x2,y) = P (x2|y)P (x1,y) can now becompletely specified by fixing the joint probabil-ity P (x1,y).
Let P (x1 = 0,y = 0) = 0.3,P (x1 = 0,y = 1) = 0.1, P (x1 = 1,y = 0) = 0.2,and P (x1 = 1,y = 1) = 0.4.
I.e., a salmon is morelikely to be light than dark and a sea bass is morelikely to be dark than light.The full joint distribution is depicted in Figure 2.Also shown in Figure 2 are the conditional distribu-tions P (x1 = 0|x2) and P (y = 0|x1,x2).Assume that we build a predictor to decide be-tween x1 = light and x1 = dark from the length us-ing a data set of unlabeled fish.
On a random salmon,this predictor will most likely decide that x1 = light(because, for a salmon, x1 = light is more likelythan x1 = dark, and similarly for a sea bass thepredictor often decides that x1 = dark.
Conse-quently the predictor provides information about thetrue class label y.
This can also be seen in the sim-ilarities between the curves P (y = 0|x1,x2) to thecurve P (x1|x2) in Figure 2.Another way to interpret the example is to notethat if a predictor for P (x1|x2) were built on onlythe salmons then P (x1 = light|x2) will be a con-stant value (0.6).
Similarly the value of P (x1 =light|x2) for sea basses will also be a constant value(0.2).
That is, the value of P (x1 = light|x2) fora sample is a good predictor of its class.
However,?4 ?2 0 2 40.5x1 = 0x1 = 1x2P(x1=1,y=0,x2) P(x1=1,y=1,x2)P(x1=0,y=1,x2)P(x1=0,y=0,x2)P(y=0|x1=1,x2)P(y=0|x1=0,x2)P(x1=0|,x2)Figure 2: The joint distributions and the posterior distri-butions of the class y and the surrogate class x1.surrogate learning builds the predictor P (x1|x2) onunlabeled data from both types of fish and there-fore additionally requires P (x1|y) to estimate theboundary between the classes.2.1 A Special CaseThe independence assumptions made in the settingabove may seem too strong to hold in real problems,especially because the feature sets are required tobe class-conditionally independent for both classes.We now specialize the setting of the classificationproblem to the one realized in the applications wepresent later.We still wish to learn a classifier from X = X1 ?X2 to the set of classes Y = {0, 1}.
We make thefollowing slightly modified assumptions.1.
x1 is a binary random variable.
That is, X1 ={0, 1}.2.
P (x1,x2|y = 0) = P (x1|y = 0)P (x2|y =0).
We require that the feature x1 be class-conditionally independent of the remaining fea-tures only for the class y = 0.3.
P (x1 = 0,y = 1) = 0.
This assumption saysthat x1 is a ?100% recall?
feature for y = 11.Assumption 3 simplifies the learning task to theestimation of the probability P (y = 0|x1 = 1,x2)for every point x2 ?
X2.
We can proceed as before1This assumption can be seen to trivially enforce the inde-pendence of the features for class y = 1.12to obtain the expression in Equation 3.P (y = 0|x1 = 1,x2)= P (x1 = 1|y = 0)P (x1 = 1|x2) .
.
.. .
.
P (x1 = 1|y = 1)?
P (x1 = 1|x2)P (x1 = 1|y = 1)?
P (x1 = 1|y = 0)= P (x1 = 1|y = 0)P (x1 = 1|x2) ?1?
P (x1 = 1|x2)1?
P (x1 = 1|y = 0)= P (x1 = 1|y = 0)P (x1 = 1|x2) ?P (x1 = 0|x2)P (x1 = 0|y = 0)= P (x1 = 1|y = 0)P (x1 = 0|y = 0) ?P (x1 = 0|x2)(1?
P (x1 = 0|x2))(4)Equation 4 shows that P (y = 0|x1 = 1,x2)is a monotonically increasing function of P (x1 =0|x2).
This means that after we build a predictorfrom X2 to X1, we only need to establish the thresh-old on P (x1 = 0|x2) to yield the optimum classi-fication between y = 0 and y = 1.
Therefore thelearning proceeds as follows.1.
From unlabeled data learn a predictor from thefeature space X2 to the binary space X1 to pre-dict the quantity P (x1|x2).2.
Use labeled sample to establish the thresh-old on P (x1 = 0|x2) to achieve the desiredprecision-recall trade-off for the original clas-sification problem.Because of our assumptions, for a sample fromclass y = 0 it is impossible to predict whetherx1 = 0 or x1 = 1 better than random by lookingat the x2 feature, whereas a sample from the posi-tive class always has x1 = 1.
Therefore the sampleswith x1 = 0 serve to delineate the positive exam-ples among the samples with x1 = 1.
We thereforecall the samples that have x1 = 1 as the target sam-ples and those that have x1 = 0 as the backgroundsamples.3 Related WorkAlthough the idea of using unlabeled data to im-prove classifier accuracy has been around for severaldecades (Nagy and Shelton, 1966), semi-supervisedlearning has received much attention recently dueto impressive results in some domains.
The com-pilation of chapters edited by Chappelle et al is anexcellent introduction to the various approaches tosemi-supervised learning, and the related practicaland theoretical issues (Chapelle et al, 2006).Similar to our setup, co-training assumes that thefeatures can be split into two class-conditionallyindependent sets or ?views?
(Blum and Mitchell,1998).
Also assumed is the sufficiency of eitherview for accurate classification.
The co-training al-gorithm iteratively uses the unlabeled data classifiedwith high confidence by the classifier on one view,to generate labeled data for learning the classifier onthe other.The intuition underlying co-training is that the er-rors caused by the classifier on one view are inde-pendent of the other view, hence can be conceivedas uniform2 noise added to the training examplesfor the other view.
Consequently, the number of la-bel errors in a region in the feature space is propor-tional to the number of samples in the region.
If theformer classifier is reasonably accurate, the propor-tionally distributed errors are ?washed out?
by thecorrectly labeled examples for the latter classifier.Seeger showed that co-training can also be viewedas an instance of the Expectation-Maximization al-gorithm (Seeger, 2000).The main distinction of surrogate learning fromco-training is the learning of a predictor from oneview to the other, as opposed to learning predictorsfrom both views to the class label.
We can there-fore eliminate the requirement that both views besufficiently informative for reasonably accurate pre-diction.
Furthermore, unlike co-training, surrogatelearning has no iterative component.Ando and Zhang propose an algorithm to regu-larize the hypothesis space by simultaneously con-sidering multiple classification tasks on the samefeature space (Ando and Zhang, 2005).
They thenuse their so-called structural learning algorithm forsemi-supervised learning of one classification task,by the artificial construction of ?related?
problemson unlabeled data.
This is done by creating prob-lems of predicting observable features of the dataand learning the structural regularization parame-ters from these ?auxiliary?
problems and unlabeleddata.
More recently in (Ando and Zhang, 2007) they2Whether or not a label is erroneous is independent of thefeature values of the latter view.13showed that, with conditionally independent featuresets predicting from one set to the other allows theconstruction of a feature representation that leadsto an effective semi-supervised learning algorithm.Our approach directly operates on the original fea-ture space and can be viewed another justificationfor the algorithm in (Ando and Zhang, 2005).Multiple Instance Learning (MIL) is a learningsetting where training data is provided as positiveand negative bags of samples (Dietterich et al,1997).
A negative bag contains only negative ex-amples whereas a positive bag contains at least onepositive example.
Surrogate learning can be viewedas artificially constructing a MIL problem, with thetargets acting as one positive bag and the back-grounds acting as one negative bag (Section 2.1).The class-conditional feature independence assump-tion for class y = 0 translates to the identical andindependent distribution of the negative samples inboth bags.4 Two ApplicationsWe applied the surrogate learning algorithm to theproblems of record linkage and paraphrase genera-tion.
As we shall see, the applications satisfy theassumptions in our second (100% recall) setting.4.1 Record Linkage/ Entity ResolutionRecord linkage is the process of identification andmerging of records of the same entity in differentdatabases or the unification of records in a singledatabase, and constitutes an important component ofdata management.
The reader is referred to (Win-kler, 1995) for an overview of the record linkageproblem, strategies and systems.
In natural languageprocessing record linkage problems arise during res-olution of entities found in natural language text toa gazetteer.Our problem consisted of merging each of ?20000 physician records, which we call the updatedatabase, to the record of the same physician ina master database of ?
106 records.
The updatedatabase has fields that are absent in the masterdatabase and vice versa.
The fields in common in-clude the name (first, last and middle initial), sev-eral address fields, phone, specialty, and the year-of-graduation.
Although the last name and year-of-graduation are consistent when present, the ad-dress, specialty and phone fields have several incon-sistencies owing to different ways of writing the ad-dress, new addresses, different terms for the samespecialty, missing fields, etc.
However, the nameand year alone are insufficient for disambiguation.We had access to ?
500 manually matched updaterecords for training and evaluation (about 40 of theseupdate records were labeled as unmatchable due toinsufficient information).The general approach to record linkage involvestwo steps: 1) blocking, where a small set of can-didate records is retrieved from the master recorddatabase, which contains the correct match withhigh probability, and 2) matching, where the fieldsof the update records are compared to those of thecandidates for scoring and selecting the match.
Weperformed blocking by querying the master recorddatabase with the last name from the update record.Matching was done by scoring a feature vector ofsimilarities over the various fields.
The feature val-ues were either binary (verifying the equality of aparticular field in the update and a master record) orcontinuous (some kind of normalized string edit dis-tance between fields like street address, first nameetc.
).The surrogate learning solution to our matchingproblem was set up as follows.
We designated thebinary feature of equality of year of graduation3 asthe ?100% recall?
feature x1, and the remaining fea-tures are relegated to x2.
The required conditionsfor surrogate learning are satisfied because 1) in ourdata it is highly unlikely for two records with differ-ent year- of-graduation to belong to the same physi-cian and 2) if it is known that the update recordand a master record belong to two different physi-cians, then knowing that they have the same (or dif-ferent) year-of-graduation provides no informationabout the other features.
Therefore all the featurevectors with the binary feature indicating equalityof year-of-graduation are targets and the remainingare backgrounds.First, we used feature vectors obtained from therecords in all blocks from all 20000 update recordsto estimate the probability P (x1|x2).
We used lo-3We believe that the equality of the middle intial would haveworked just as well for x1.14Table 1: Precision and Recall for record linkage.Training Precision RecallproportionSurrogate 0.96 0.95Supervised 0.5 0.96 0.94Supervised 0.2 0.96 0.91gistic regression for this prediction task.
For learn-ing the logistic regression parameters, we discardedthe feature vectors for which x1 was missing andperformed mean imputation for the missing valuesof other features.
Second, the probability P (x1 =1|y = 0) (the probability that two different ran-domly chosen physicians have the same year ofgraduation) was estimated straightforwardly fromthe counts of the different years-of-graduation in themaster record database.These estimates were used to assign the scoreP (y = 1|x1 = 1,x2) to the records in a block (cf.Equation 4).
The score of 0 is assigned to featurevectors which have x1 = 0.
The only caveat is cal-culating the score for feature vectors that had miss-ing x1.
For such records we assign the score P (y =1|x2) = P (y = 1|x1 = 1,x2)P (x1 = 1|x2).
Wehave estimates for both quantities on the right handside.
The highest scoring record in each block wasflagged as a match if it exceeded some appropriatethreshold.We compared the results of the surrogate learn-ing approach to a supervised logistic regressionbased matcher which used a portion of the manualmatches for training and the remaining for testing.Table 1 shows the match precision and recall forboth the surrogate learning and the supervised ap-proaches.
For the supervised algorithm, we show theresults for the case where half the manually matchedrecords were used for training and half for testing,as well as for the case where a fifth of the records oftraining and the remaining four-fifths for testing.
Inthe latter case, every record participated in exactlyone training fold but in four test folds.The results indicate that the surrogate learner per-forms better matching by exploiting the unlabeleddata than the supervised learner with insufficienttraining data.
The results although not dramatic arestill promising, considering that the surrogate learn-ing approach used none of the manually matchedrecords.4.2 Paraphrase Generation for EventExtractionSentence classification is often a preprocessing stepfor event or relation extraction from text.
One of thechallenges posed by sentence classification is the di-versity in the language for expressing the same eventor relationship.
We present a surrogate learning ap-proach to generating paraphrases for expressing themerger-acquisition (MA) event between two organi-zations in financial news.
Our goal is to find para-phrase sentences for the MA event from an unla-beled corpus of news articles, that might eventuallybe used to train a sentence classifier that discrimi-nates between MA and non-MA sentences.We assume that the unlabeled sentence corpus istime-stamped and named entity tagged with orga-nizations.
We further assume that a MA sentencemust mention at least two organizations.
Our ap-proach to generate paraphrases is the following.
Wefirst extract all the so-called source sentences fromthe corpus that match a few high-precision seed pat-terns.
An example of a seed pattern used for theMA event is ?<ORG1> acquired<ORG2>?
(where<ORG1> and <ORG2> are place holders forstrings that have been tagged as organizations).
Anexample of a source sentence that matches the seedis ?It was announced yesterday that <ORG>GoogleInc.<ORG> acquired <ORG>Youtube <ORG>?.The purpose of the seed patterns is to produce pairsof participant organizations in an MA event withhigh precision.We then extract every sentence in the corpus thatcontains at least two organizations, such that at leastone of them matches an organization in the sourcesentences, and has a time-stamp within a two monthtime window of the matching source sentence.
Ofthis set of sentences, all that contain two or more or-ganizations from the same source sentence are des-ignated as target sentences, and the rest are desig-nated as background sentences.We speculate that since an organization is unlikelyto have a MA relationship with two different orga-nizations in the same time period the backgroundsare unlikely to contain MA sentences, and more-over the language of the non-MA target sentences is15Table 2: Patterns used as seeds and the number of sourcesentences matching each seed.Seed pattern # of sources1 <ORG> acquired <ORG> 572 <ORG> bought <ORG> 703 offer for <ORG> 2874 to buy <ORG> 3965 merger with <ORG> 294indistinguishable from that of the background sen-tences.
To relate the approach to surrogate learning,we note that the binary ?organization-pair equality?feature (both organizations in the current sentencebeing the same as those in a source sentence) servesas the ?100% recall?
feature x1.
Word unigram, bi-gram and trigram features were used as x2.
Thissetup satisfies the required conditions for surrogatelearning because 1) if a sentence is about MA, theorganization pair mentioned in it must be the sameas that in a source sentence, (i.e., if only one of theorganizations match those in a source sentence, thesentence is unlikely to be about MA) and 2) if an un-labeled sentence is non-MA, then knowing whetheror not it shares an organization with a source doesnot provide any information about the language inthe sentence.If the original unlabeled corpus is sufficientlylarge, we expect the target set to cover most of theparaphrases for the MA event but may contain manynon-MA sentences as well.
The task of generatingparaphrases involves filtering the target sentencesthat are non-MA and flagging the rest of the tar-gets as paraphrases.
This is done by constructing aclassifier between the targets and backgrounds.
Thefeature set used for this task was a bag of word un-igrams, bigrams and trigrams, generated from thesentences and selected by ranking the n-grams bythe divergence of their distributions in the targetsand backgrounds.
A support vector machine (SVM)was used to learn to classify between the targets andbackgrounds and the sentences were ranked accord-ing to the score assigned by the SVM (which is aproxy for P (x1 = 1|x2)).
We then thresholded thescore to obtain the paraphrases.Our approach is similar in principle to the ?Snow-ball?
system proposed in (Agichtein and Gravano,2000) for relation extraction.
Similar to us, ?Snow-ball?
looks for known participants in a relationship inan unlabeled corpus, and uses the newly discoveredcontexts to extract more participant tuples.
How-ever, unlike surrogate learning, which can use a richset of features for ranking the targets, ?Snowball?scores the newly extracted contexts according to asingle feature value which is confidence measurebased only on the number of known participant tu-ples that are found in the context.Example 2 below lists some sentences to illustratethe surrogate learning approach.
Note that the tar-gets may contain both MA and non-MA sentencesbut the backgrounds are unlikely to be MA.?????????????
?Example 2Seed Pattern?offer for <ORG>?Source Sentences1.
<ORG>US Airways<ORG> said Wednesday it willincrease its offer for <ORG>Delta<ORG>.Target Sentences (SVM score)1.<ORG>US Airways<ORG> were to combine with astandalone <ORG>Delta<ORG>.
(1.0008563)2.<ORG>US Airways<ORG> argued that the nearly$10 billion acquisition of <ORG>Delta<ORG> wouldresult in an efficiently run carrier that could offer lowfares to fliers.
(0.99958149)3.<ORG>US Airways<ORG> is asking<ORG>Delta<ORG>?s official creditors commit-tee to support postponing that hearing.
(-0.99914371)Background Sentences (SVM score)1.
The cities have made various overtures to<ORG>US Airways<ORG>, including a promisefrom <ORG>America West Airlines<ORG> and theformer <ORG>US Airways<ORG>.
(0.99957752)2.
<ORG>US Airways<ORG> shares rose 8 centsto close at $53.35 on the <ORG>New York StockExchange<ORG>.
(-0.99906444)?????????????
?We tested our algorithm on an unlabeled corpus ofapproximately 700000 financial news articles.
Weexperimented with the five seed patterns shown inTable 2.
We extracted a total of 870 source sentencesfrom the five seeds.
The number of source sentencesmatching each of the seeds is also shown in Table 2.Note that the numbers add to more than 870 becauseit is possible for a source sentence to match morethan one seed.The participants that were extracted from sources16Table 3: Precision/Recall of surrogate learning on theMA paraphrase problem for various thresholds.
Thebaseline of using all the targets as paraphrases for MAhas a precision of 66% and a recall of 100%.Threshold Precision Recall0.0 0.83 0.94-0.2 0.82 0.95-0.8 0.79 0.99corresponded to approximately 12000 target sen-tences and approximately 120000 background sen-tences.
For the purpose of evaluation, 500 randomlyselected sentences from the targets were manuallychecked leading to 330 being tagged as MA and theremaining 170 as non-MA.
This corresponds to a66% precision of the targets.We then ranked the targets according to the scoreassigned by the SVM trained to classify between thetargets and backgrounds, and selected all the targetsabove a threshold as paraphrases for MA.
Table 3presents the precision and recall on the 500 manu-ally tagged sentences as the threshold varies.
Theresults indicate that our approach provides an effec-tive way to rank the target sentences according totheir likelihood of being about MA.To evaluate the capability of the method to findparaphrases, we conducted five separate experi-ments using each pattern in Table 2 individually as aseed and counting the number of obtained sentencescontaining each of the other patterns (using a thresh-old of 0.0).
These numbers are shown in the differ-ent columns of Table 4.
Although new patterns areobtained, their distribution only roughly resemblesthe original distribution in the corpus.
We attributethis to the correlation in the language used to de-scribe a MA event based on its type (merger vs. ac-quisition, hostile takeover vs. seeking a buyer, etc.
).Finally we used the paraphrases, which werefound by surrogate learning, to augment the train-ing data for a MA sentence classifier and evaluatedits accuracy.
We first built a SVM classifier onlyon a portion of the labeled targets and classified theremaining.
This approach yielded an accuracy of76% on the test set (with two-fold cross validation).We then added all the targets scored above a thresh-old by surrogate learning as positive examples (4000Table 4: Number of sentences found by surrogate learn-ing matching each of the remaining seed patterns, whenonly one of the patterns was used as a seed.
Each columnis for one experiment with the corresponding pattern usedas the seed.
For example, when only the first pattern wasused as the seed, we obtained 18 sentences that match thefourth pattern.Seeds 1 2 3 4 51 2 2 5 12 5 6 7 53 4 6 152 1034 18 16 93 575 3 9 195 57positive sentences in all were added), and all thebackgrounds that scored below a low threshold asnegative examples (27000 sentences), to the trainingdata and repeated the two-fold cross validation.
Theclassifier learned on the augmented training data im-proved the accuracy on the test data to 86% .We believe that better designed features (thanword n-grams) will provide paraphrases with higherprecision and recall of the MA sentences found bysurrogate learning.
To apply our approach to a newevent extraction problem, the design step also in-volves the selection of the x1 feature such that thetargets and backgrounds satisfy our assumptions.5 ConclusionsWe presented surrogate learning ?
an easily imple-mentable semi-supervised learning algorithm thatcan be applied when the features satisfy the requiredindependence assumptions.
We presented two appli-cations, showed how the assumptions are satisfied,and presented empirical evidence for the efficacy ofour algorithm.
We have also applied surrogate learn-ing to problems in information retrieval and docu-ment zoning.
We expect that surrogate learning issufficiently general to be applied in many NLP ap-plications, if the features are carefully designed.
Webriefly note that a surrogate learning method basedon regression and requiring only mean independenceinstead of full statistical independence can be de-rived using techniques similar to those in Section 2?
this modification is closely related to the problemand solution presented in (Quadrianto et al, 2008).17ReferencesS.
Abney.
2002.
Bootstrapping.
In In Proceedings of the40th Annual Meeting of the Association for Computa-tional Linguistics, pages 360?367.E.
Agichtein and L. Gravano.
2000.
Snowball: Extract-ing Relations from Large Plain-Text Collections.
InProceedings of the 5th ACM International Conferenceon Digital Libraries (ACM DL), pages 85?94, June,2-7.R.
K. Ando and T. Zhang.
2005.
A framework for learn-ing predictive structures from multiple tasks and unla-beled data.
JMLR, 6:1817?1853.R.
K. Ando and T. Zhang.
2007.
Two-view feature gen-eration model for semi-supervised learning.
In ICML,pages 25?32.A.
Blum and T. Mitchell.
1998.
Combining labeled andunlabeled data with co-training.
In COLT, pages 92?100.O.
Chapelle, B. Scho?lkopf, and A. Zien, editors.
2006.Semi-Supervised Learning.
MIT Press, Cambridge,MA.T.
G. Dietterich, R. H. Lathrop, and T. Lozano-Perez.1997.
Solving the multiple instance problem withaxis-parallel rectangles.
Artificial Intelligence, 89(1-2):31?71.R.
O. Duda, P. E. Hart, and D. G. Stork.
2000.
PatternClassification.
Wiley-Interscience Publication.G.
Nagy and G. L. Shelton.
1966.
Self-corrective charac-ter recognition system.
IEEE Trans.
Information The-ory, 12(2):215?222.N.
Quadrianto, A. J. Smola, T. S. Caetano, and Q. V. Le.2008.
Estimating labels from label proportions.
InICML ?08: Proceedings of the 25th international con-ference on Machine learning, pages 776?783.M.
Seeger.
2000.
Input-dependent regularizationof conditional density models.
Technical re-port, Institute for ANC, Edinburgh, UK.
Seehttp://www.dai.ed.ac.uk/?seeger/papers.html.W.
E. Winkler.
1995.
Matching and record linkage.
InBusiness Survey Methods, pages 355?384.
Wiley.18
