AN EVALUATION OF COREFERENCE RESOLUTION STRATEGIESFOR ACQUIRING ASSOCIATED INFORMATIONLois C. ChildsLockheed Mar t in  Corporat ionP.O.
Box 8048Philadelphia, PA 19101lois@mds.lmco.com(610) 354-5816Category - Information Extraction1.
INTRODUCTIONAs part of our TIPSTER research program \[Con-tract Number 94-F133200-000\], wehave developed avariety of strategies toresolve coreferences within a freetext document.
Coreference is typically defined tomean the identification ofnoun phrases that refer to thesame object.
This paper investigates a more generalview of coreference in which our automatic systemidentifies not only coreferenfial phrases, but alsophrases which additionally describe an object.
Corefer-ence has been found to be an important component ofmany applications.The following example illustrates ageneral viewof coreference.American Express, the large financialinstitution, also known as Amex, willopen an office in Peking.In this example, we would like to associate the fol-lowing information about American Express:its name is American Express;an alias for it is Amex;its location is Peking, China; andit can be described as the large financialinstitution.In the work described in this paper, our goal wasto evaluate the contributions of various techniques forassociating an entity with three types of information:1.
NameV~atious.3.Data  SetDescriptive PhrasesLocation InformationThe MUC6 Template Element ask is typical ofwhat our applications often require; it encapsulates in-formation about one entity within the Template Ele-ment.
Since we have a way to evaluate our performanceon this task via the MUC6 data, we used it to conduct ourexperiments.
The corpus for the MUC6 Template Ele-ment ask consists of approximately 200 documents fordevelopment (pre- and post-dry-run) and 100 docu-ments for scoring.
The scoring set had previously beenheld blind, but it has been released for the purposes ofa thorough evaluation of our metheds.ScoringScores discussed in this paper measure perfor-mance of experimental system reconfigurafions run onthe 100 documents u ed for the final MUC6 evaluation.These scores were generated for inter-experiment com-parison proposes, using the MUC6 scoring program,v 1.3.
Scores reported here are relevant only as relativemeasures within this paper and are not meant o repre-sent official performance measu~s.
Official MUC6scores were generated using a later version of the scor-ing program.
Furthermore, the scoring program resultscan vary depending on how the mapping between re-spouse and answer key is done.
For example, if an auto-marie system has failed to make the link between a des-cdptor and a name, it may create two objects - - -  one foreach.
The scoring system ust hen decide which objectto map to the answer key.Obiect 1NAME: American ExpressALIAS: AmexTYPE: COMPANYLOCALE: PekingCOUNTRY: ChinaObiect2DESCRIPTORTYPE:the large financialinstitutionCOMPANY179KevNAME:ALIAS:DESCRIPTOR:TYPE;LOCAl .~:COUNTRY:American ExpressAmexthe large financialinstitutionCOMPANYPekingChinaThe scoring program tries to optimize the scoresduring mapping but, if two objects would score equally,the scoring program chooses arbitrarily, thus, in effect,sacrificing aslot as a penalty for coreference failure.
Inthe following example, the slot can be either NAME orDESCRIPTOR, depending on the mapping.Obiect 1NAME: American ExpressTYPE: COMPANYObiect2DESCRIPTOR:TYPE:the large financialinstitutionCOMPANYAdditionally, the answer key contains optional ob-jects which are included in the scoring calculations onlyff they have been mapped to a response object.
'ntissometimes causes a fluctuation in the number of pos-sible correct answers, as reported by the scoring pro-gram.
The scores, therefore, do not represent an abso-lute measure of performance.Scores reported here use the following abbrevi-ations:POS possible correct answersACT actual answers producedCOR correct answersINC incorrect answersREC recall(% of the correct answers found)PRE precision(% of answers found that are correct)2.
NAME VARIATIONSIdentifying variations of a person name or orga-nization ame is a basic form of coreference that under-lies other strategies.
Our process tores each newly rec-ognized named entity, along with its computedvariations and acronyms.
The variations and acronymsare algorithmlcally generated without reference to thetext.
These are stored in a temporary lexicon so thatvariations of the name in the text can be recognized andlinked to the original occurrence.A careful examination of the name/alias resultsprovides insight into the success of this technique.Approximately two-thirds of the aliases were cor-rectly identified.
Of the one-third which were missed,besides an unfortunate system error which threw awayfour aliases which the system had found, five maingroups of error were found.
They can be categorized asfollows:1.
Corporate Subsidiaries2.
Corporate Name Changes3.
Missing Name4.
Incomplete Name Variation5.
UnusualFirstnameCorporate SubsidiariesThere were approximately five missed aliases thatinvolved corporations and their subsidiaries.
In thesecases, the aliases were assigned to the wrong entity.Usually, these were stories in which corporate officerswere transferring from one part of a company to another.Confusien can quickly ensue when trying to link an aliaswith the correct entity in this case.
(This is often true forthe human reader, as well.)
Find the three organizationsin the following list of phrases:EMI Records Group, a unit of London'sThorn EMI PLCEMI Records Group North AmericaEM1 Records GroupEMIEMI RecordsThe three organizations are:NAME: Thorn EMI PLCALIAS: EMINAME: EMI Records GroupALIAS: EMI RecordsNAME: EMI Records Group NorthAmericaOf course, presentation f the names as a list is un-fair to the reader because iteliminates all context cues.Rules which allow the automatic system to take greateradvantage of context cues will be developed for suchspecialized areas.Corporate Name ChangesAnother five missed aliases were found in scenar-ios of changing corporate identity.
By the rules of theTemplate Element task, the old name should become thealias of the new name.
When these scenarios went un-180recognized by the system, the names were tagged assep-arate ntities.
The following is an example of a confus-ing name changing scenario which the automaticsystem missed.HEADLINE: Waste Management NewNameWaste Management lnc.
shareholders ap-proved changing the name of this trashhauling, recycling and environmentalservices concern to WMX TechnologiesInc.The company's North American solid-waste operations will retain the nameWaste Management Inc.The answer key for this scenario contains two or-ganization entities.NAME: Waste Management Inc.andNAME: Waste Management lnc.orWMX Technologies Inc.ALIAS: Waste ManagementWMX Technologies Inc.orWaste ManagementWaste Management Inc.Because there is sc~te uncertainty within the textas to whether the change has already taken place, the se-cond entity is given optional names covering both alter-natives.
This is difficult for an automatic extraction sys-tem to decipher.Missing NameMany aliases are found because they are variationsof names which have been recognized by their form(i.e., they contain a corporate designator - Co.) or bytheir context (e.g., CEO of Atlas).
Approximately tenmissed aliases were due to the fact that the names them-selves were not recotmiTed.
Improvement ofname rec-ognition is an on-going process as the system and its de-velopers are exposed to more and more text.Incomplete Name VariationName variations are generated algofthmically.There were only four aliases missed because they werenot generated from the full name.
Examination of theresults has uncovered two new rules for making varia-tions.
These will be added to the set.First, the abbreviation portion of the name shouldbe included within an acronym, for example, ARCO asalias for Atlantic Richfield Company and RLA as aliasfor Rebuild L.A.Second, a structural member like Chamber orPartnership can stand alone as a variation, for example,Chamber as alias for Chamber of Commerce and Part-nership as alias for New York City Partnership.It should be noted that our rule packages employvariable bindings to collect information during the pat-tern matching process.
In the case of name variations,it would be helpful to tag the pattern's structural mem-bers that can stand alone as variants during the rule bind-ing process.
This can then guide the variation generatorwhen that pattern has been matched.Unusual FirstnameSeven PERSON aliases were missed because thesystem did not know the firstname, e.g.
Clive, Vana,Rupert.
The solution to this problem is not only to ex-pand the system's knowledge of human firsmames, butalso to widen the context which can trigger human amerecognition.
The system will be expanded to rec~izeas human those unknown words which are laki~g humanroles, such as participating in family relationships.Performance on the Name/Alias TaskOur system had the second highest score in orga-nization alias identification i  the MUC6 evaluation.
(See the MUC6 Conference proceedings for officialscores.
)OF~iANIZATION ALIAS SCORE 0/1.3)PO6 ACT COR INC REC PRE170 153 110 2 65 72Person alias scores were suppressed by 5 points ofrecall due to an error in the gender eference code.
Thefollowing show the original scores and those after the er-ror has been fixed.PERSON ALIAS SCORE 0/1.3) - ORIGINALPOS ACT COR INC REC PRE170 157 146 1 86 93PERSON ALIAS SCORE 0/1.3) - ERROR FIXEDPOS ACT COR INC REC PRE170 167 155 1 91 933.
DESCRIPTIVE PHRASESAssociating an organization name with a descrip-tor requires resolving coroferences among names, nounphrases, and pronouns.
Several techniques are involvedhere.
Appositives, prenominals, and name-modifiedhead nouns are directly associated with their respective181named entities during name recognition.
After nounphrase recognition, those phrases which have not al-ready been associated with a name are compared againstknown names in the text in order to fred the correct ref-erent.Assoc ia t ion  by  ContextDuring name recognition, entities are direcdylinked, via variable bindings within the patterns, withdescriptive phrases that make up their context.
This isa thrifty process because it allows the system to mine thevery context which it has used to recognize the entity inthe first place, thus allowing it to store linked informa-tion with the entity discovered.
In this manner, the sys-tem is able to link descriptive phrases that are found inthe following forms:APPOSITIVEMUCster Group, a New York consultingfirm,PRENOMINALthe New York consulting firm, MUCsterGroupNAME-MODWIED HEAD NOUNthe MUCster Group consulting firmSince the Template Element task described hereres~ctea the descriptor slot to a single phrase, our sys-tem sought o choose the most reliable of all the phraseswhich had been linked to an entity.
It did this by rankingthe descriptors based on their syntactic role.
The fol-lowing is the ranking used for the MUC6 system:1. appositive2.
predicate nominative3.
prenominal4.
name-modified head noun5.
longest descriptor (found by ref-erence)This ranking gives greater confidence to those des-criptors associated by context, with the default choice,the longest descriptor, having been associated by refer-ence .70% of our system's name-linked descriptorswere associated by context.
This is not surprising inview of our ranked selection system.
The following isa score of the original configuration, using the rankedselection system.DESCRIPTOR SCORE 0/1.3) - ORIGINAL CONRGURATIONPOS ACT COR INC REC PRE224 233 104 39 46 45When the ranking is abandoned and the selectionis based on the longest descriptor alone, 62% of the re-sponse descriptors are drawn from those associated bycontext.
This change has a deleterious effect on thescores for the descriptor slot and confirins our hypothe-sis that the context-associated descriptors are more reli-able.DESCRIPTOR SCORE 0/1.3) - LONGEST PREFERREDPOS ACT COR INC REC PRE223 233 87 53 39 37A surprising result of this experiment is that thepercentage ofdescriptors associated by context is still sohigh.
This is believed to be due to their predominancewithin the set of noun phrases found by our system.Assoc iat ion  by  ReferenceOnce an organization oun phrase has been recog-nized, the reference resolution module seeks to find itsreferent.
This process involves everal steps.
First, thephrase is checked to mske sure it hasn't already beenassociated by context.
If not, a content filter for thephrase is run against a content filtered version of eachknown organization name; if there is a match, the linkis made.Content Filters:"the jewelry chain" =>(jewelry jewel chain )=Smith Jewelers" =>( smith jewelers jeweler jewel )For example, if the organization noun phrase, "thejewelry chain" is identified, its content filter would beapplied to the list of known company names.
When itreaches "Smith Jewelers", it will compare the falteragainst a faltered version of the name.
The best matchis considered the referent.
If there is a fie, file positionis considered as a factor, the closest name being the mostlikely referent.To assess the value of this filtering mechanism, theMUC6 evaluation corpus was processed without he ill-mr.
The following results show that the falter did helpthe system link the correct descriptors; without it, thesystem lost five points of recall and seven points of pre-cision.DESCRIPTOR SCORE 0/1,3) - WFI'I-IOUT FILTERPOS ACT COR INC REC PRE222 235 90 48 41 38For genetic phrases like "the company" and forpronouns referring to people, reference is currently de-termined solely by file position and entity type.
Planshave been formulated to increase the sophistication ofthis selection process, and to expand the system to ban-die coreference ofpronouns to organizations.182Named vs. Un-named OrganizationsBecame of the possibility that a text may refer toan un-named organization by a noun phrase alone, it isnecessary to recognize all definite and iMefmite nounphrases that may refer to an organization.
The followingare examples of some un-named organiTations:the Clinton administrationfederal appeals courtMUCster's coreference r search groupa New York consultancyits banking unitan arm of the MUCster unitThose phrases that have not already beenassociated with a named entity through context cuesmust then be associated by reference, if possible.
Forevery definite noun phrase, if a reference can be found,it will be associated with that entity; otherwise, it willbecome an un-named entity.
Every indefinite nounphrase that cannot be associated by context becomes anun-named entity.During the f'dtering process, the system used anadditional heuristic to decide whether to apply a contentfilter to a noun phrase, or to make it into an un-namedentity.
If a noun phrase is found to be especially rich indescription, it is thought o he too specific to refer to aprevious entity, and is made into an un-named entity.This heuristic turned out to be detrimental to perfor-mance; it suppressed the descriptor scores ubstantially.When the original configuration (i.e.
ranked selection,favoring appositives) is run, without this heuristic, anincrease of four recall and three precision points isachieved.DESCRIPTOR SCORE (V1,3) - WITHOUT HEURISTICPOS ACT COR INC REC PRE223 230 111 35 50 48Context vs. ReferenceThe majority of descriptors reported were foundthrough association by context, even when the "longestdescriptor" selection method is used.
This is partly dueto the relative scarcity of -nattached:l organizationalnoun phrases.
Sixty-eight of the 224 possible descrip-tors were missed because the system did not recognizethe noun phrase as describing an organization.
Whenthe key's descriptive phrases were added directly to thesystem's knowledge base, as a hard-coded rule pack-age, to eliminate this variable, the following scores wereproduced.DESCRIPTOR SCORE (V1.3) - ALL NOUN PHRASES ADDEDPOS ACT COR INC REC PRE230 359 135 28 59 38The responses scored were produced with the orig-inal system configuration which uses the ranked selec-tion system.
When the system reveas to preferring thelongest descriptor, the following scores are achieved.DESCRIPTOR SCORE (V1.3) - ALL NOUN PHRASESADDED,LONGEST PREFERREDPOS ACT COR INC REC PRE230 366 132 3'1 57 36The decline in scores adds further confirmation toour hypothesis that the context-associated descriptorsare more reliable.4, LOCATION INFORMATIONFinally, techniques for associating an organizationname with location information are examined.
This isan extension of traditional coreference, but a task we doin many applications.
Biographical information abouta person often falls into this category, e.g.
address, tele-phone, or passport information.
The intuition is thatlocation inftnmation is found frequently within descrip-tive noun phrases and is extractable once that link hasbeen established.This approach was evaluated by examining thesource of the answer key's locale fillers.
It was foundthat 67% originated in appositives, prenominals, andpost-modifiers, and 20% originated in other descriptivenoun phrases.APPOSITIVEMUCster Group, a New York consultingfirm,PRENOMINALthe New York consulting firm, MUCsterGroupPOST-MODIFIERSMUCster Group (New York)MUCster Group is based in New YorkThis may account for our system's superior perfor-mance in identifying locale/country information; ourscores were the highest of the MUC6 participants.
(Seethe MUC6 Conference proceedings for official scores.
)We believe that this success is due to our method of col-lecting related information during name recognition.LOCALE/COUNTRY SCORE 0/1 ,.3)POS ACT COR INC REC PRE114 105 67 10 59 64115 102 75 2 65 74183Breaking this down further, our system found 60%of those kxmle fillers which originated in prenominals,appositives, and post-modifiers, and 57% of the other20%.5.
CONCLUSIONIn the work described in this paper, our goal wasto evaluate the contributions of various coreference r s-olution techniques for acquiring information associatedwith an entity.
We looked at our system's perfcxlnancein the MUC6 Template Element evaluation in threeareas:1.
Name Variations2.
Descriptive Phrases3.
Location InformationName VariationsFive areas were identified in which improvementto the name variation code is needed.
Two areas will beimproved by better modeling the events which may ef-fect organizational names, e.g.
the forming of subsid-iaries and the changing of names.
This can be extendedto include other organizational events, such as corporatejoint ventures.
The third area.
missing names, is an areaof on-going improvement.
Two new rules were identi-fied to help the name variation algorithm, The last areaof improvement, person ames, can be improved on twofronts: 1) expanding the knowledge base of acceptedfirst names, grouped by ethnic origin, and 2) better mod-eling frequent behaviors in which person ames partici-pate.
The latter will be explored through automatic ac-quisition of person ame context over a large corpus.Despite the many areas for improvement that wereidentified, our system still had the second highest recallmeasure in organization alias, confirrning the basicsoundness of our approach.Descriptive PhrasesExamination of our system's performance inassociating descriptive phrases to a referent entitybrought us to several conclusions regarding our sys-tem's techniques.
First, our method of directly linkingentities to the descriptive phrases that make up theircontext via variable bindings within patterns has beenvery successful.
Second, the content filter does contrib-ute to the effectiveness ofour coreference r solution; itsabsence caused our scores to decline.
It may be im-proved by expanding the falter to include semantic cate-gories via a facility like WordNet, or through our inter-nal conceptual hierarchy.
Third, the heuristic thatcaused the system to discard phrases that it deemed toospecific,for resolution was extremely bad and costly toour performance.
Fourth, our recognition of organiza-tional noun phrases needs improvement.
This may alsobenefit from a survey of typical contexts over a largecorpus.Locat ion In format ionOur system's uccess in identifying associatedlocation information was due mainly to Our methed ofcollecting related information during name recognition,since 67% of the answer key's location informationcould be found within appositives, prenominals, andpost-modifiers.
As our methods of associating nounphrases by reference improves, our ability to associatelocation information may improve, as well.Overall PerformanceIll summary, Our system has incorporated manynew techniques for associating coreferential informa-tion as part of our TIPSTER research program.
This pa-concludes that most of the techniques have beenbeneficial to our performance and suggests ways to fur-ther improvement.184
