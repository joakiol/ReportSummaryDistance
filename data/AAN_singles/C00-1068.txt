Flexible Mixed-Initiative Dialogue Management usingConcept-Level Confidence Measures of Speech Recognizer OutputKazunor i  Korea |an |  and Tatsuya  KawaharaGraduat(~ School of lnt'ormati(:s, I{yoto UniversityKyoto 606-8501, JaI)an{kolnatani, kawahara} (@kuis.k.yoto-u.
ac.j i)Abst rac tWe i)rcsent a method to r(:aliz(: th:xil)le mix(;(l-initiative dialogue, in which the syst(:m canmak(, etti:ctive COlflirmation mad guidmn(:(: us-ing (-oncel)t-leve,1 confidcn('e mcmsur(,s (CMs)derived from st)eech recognizer output in ord(:rto handl(: sl)eech recognition errors.
W(: d(:tinetwo con('et)t-level CMs, which are oil COllt(~,Ilt -words and on semantic-attrilmtes, u ing 10-bestouttmts of the Sl)e(:ch r(:cognizt:r and l)arsingwith t)hrmse-level grammars.
Content-word CMis useflll for s(:lecting 1)\]ausible int(:rl)retati(ms.Less contid(:nt illt(:rl)r(:tmtions arc given to con-firmation 1)roc(:ss.
The strat(:gy iml)roved theinterpr(:tmtion accuracy l)y 11.5(/0.
Moreover,th(: semanti(:-mttrilmt(: CM ix us(:d to (:stimmtcuser's intention and generates syst(mi-initiativeguidances (:v(,,n wh(:n suc(-(:sstSfl int(:rl)r(:tmtiol~ isnot o|)tain(:(1.1 I n t roduct ionIn a st)oken dialogu(: system, it fr(:(tuently o(:-cm:s that the system incorrectly rccogniz(:s userutterances and the user makes exl)ressions thesystem has not (~xt)ccted.
These prot)lcms arcessentially incvital)le in handling the naturallanguage 1)y comlmters , even if vocal)ulary andgrammar of the system are |~lmed.
This lack ofrobustness i one of the reason why spoken dia-logue systems have not been widely deployed.In order to realize a rol)ust st)oken dialoguesystem, it is inevital)le to handle speech recog-nition errors.
To sut)t)ress recognition errors,system-initiative dialogue is eitbctive.
But itca.n 1)e adopted only in a simi)le task.
For in-stance, the form-tilling task can 1)e realized 1)y asimi)le strategy where the system asks a user theslut wdues in a fixed order.
In such a systeln-initiated intera('tion, the recognizer easily nar-rows down the vocabulary of the next user's ut-tcrance, thus the recognition gets easier.
()n the other hand, in more eoniplicat('A tasksuch ms inforination rctriewd, the vocml)ulmry ofthe llCXI; lltt(2rauco callllot 1)e limited on all oc-casions, because the user should be abh~ to in-put the values in various orders based on hisi)rel'erence.
Therefore, without imposing a rigidteml)late ut)on the user, the system must behav(~at)t)rol)riately even when sl)ecch recognizer out-1)ut contains ome errors.Obviously, making confirmal;ion is efl'cctiveto mvoid misun(lerstandings caused by slme(:hrecognition errors, ttowcver, when contirmm-tions are made \]'or every utterance, |;lie di-~dogue will l)ccome too redundant mad con-sequcntly |;rout)lcsomc, for users.
Previousworks have, shown that confirmation strategyshouM 1)c decided according to the frequency ofstretch recognition errors, using mathematicmlformula (Niimi and Kolmymshi, 1.996) and usingcomt)uter-to-comlml;er silnulation (W~tanabe etal., 1!)98).
These works assume tixe(t l)erfofmance (averaged speech recognition accuracy)in whole (lialogue with any speakers.
For flex-ible dialogue management, howeve, r the confir-mation strategy luust 1)e dynamically changc, dbmsed on the individual utterances.
For in-stmncc, we human make contirmation only whenwe arc not coat|dent.
Similarly, confidence, inca-sures (CMs) of every speech recognition outputshould be modeled as a criterion to control dia-logue management.CMs have been calculated in previous worksusing transcripts and various knowledge sources(Litman et al, 1999) (Pao et, al., 1998).
Formore tlexible interaction, it, ix desirable thatCMs are detined on each word rather than wholesentence, because the systeln can handle onlyunreliable portions of an utterance instead ofaccepting/rejecting whole sentence.467In this paper, we propose two concept-levelCMs that are on content-word level and onsemantic-attribute level for every content word.Because the CMs are defined using only speechrecognizer output, they can be computed in realtime.
The system can make efficient confir-mation and effective guidance according to theCMs.
Even when successful interpretation isnot obtained o51 content-word level, the systemgenerates ystem-initiative guidances based onthe semantic-attribute level, which lead the nextuser's utterance to successful interpretation.2 Def in i t ion  o f  Conf idence  Measures(CMs)Confidence Measures (CMs) have been studiedfor utterance verification that verifies speechrecognition result as a post-processing (Kawa-hara et al, 1998).
Since an automatic speechrecognition is a process finding a sentence hy-pothesis with the maximum likelihood for aninput speech, some measures are needed in or-der to distinguish a correct recognition resultfrom incorrect one.
In this section, we de-scribe definition of two level CMs which are oncontent-words and on semantic-attritmtes, us-ing 10-best output of the speech recognizer andparsing with phrase-level grammars.2.1 Def init ion of  CM for Content WordIn the speech recognition process, both acousticprobability and linguistic t)robability of wordsare multiplied (summed up in log-scale) overa sentence, and the sequence having maximumlikelihood is obtained by a search algorithm.
Ascore of sentence derived from the speech rec-ognizer is log-scaled likelihood of a hypothesissequence.
We use a grammar-based speech rec-ognizer Julian (Lee et al, 1999), which was de-veloped in our laboratory.
It correctly obtainsthe N-best candidates and their scores by usingA* search algorithm.Using the scores of these N-best candidates,we calculate content-word CMs as below.
Thecontent words are extracted by parsing withphrase-level grammars that are used in speechrecognition process.
In this paper, we set N =10 after we examined various values of N as thenmnber of computed candidates J1Even if we set N larger tt,an 10, the scores of i-thhypotheses (i > 10) are too small to affect resulting CMs.First, each i-th score is multiplied by a factora (a  < 1).
This factor smoothes tile differenceof N-best scores to get adequately distributedCMs.
Because the distribution of the abso-lute values is different among kinds of statisti-cal acoustic model (monophone, triphone, andso oi1), different values must be used.
The valueof c~ is examined in the preliminary experiment.In this paper, we set c~ = 0.05 when using tri-phone model as acoustic model.
Next, they aretranstbrnmd from log-scaled value (<t.
scaledi)to probability dimension by taking its exponen-tial, and calculate a posteriori probability tbreach i-th candidate (Bouwman et al, 1999).e~.scalediPi = ~n Co~.scaledj j=lThis Pi represents a posteriori probability of thei-th sentence hypothesis.Then, we compute a posteriori probability tbra word.
If the i-th sentence contains a word w,let 5w,i = 1, and 0 otherwise.
A posteriori prob-ability that a word w is contained (Pw) is de-rived as summation of a posteriori prob~bilitiesof sentences that contain the word./LPw = ~ Pi " 5w,ii=1We define this Pw as the content-word CM(CM,,).
This CM.,, is calculated tbr every con-tent word.
Intuitively, words that appear manytimes in N-best hypotheses get high CMs, andfrequently substituted ones in N-best hypothe-ses are judged as mn'eliable.In Figure 1, we show an example in CMwcalculation with recognizer outputs (i-th recog-nized candidates and their a posteriori proba-bilities) tbr an utterance "Futaishisctsu ni rcsu-toran no aru yado (Tell me hotels with restau-rant facility.)".
It can be observed that a correctcontent word 'restaurant as facility' gets a highCM value (CMw = 1).
The others, which areincorrectly recognized, get low CMs, and shallbe rejected.2.2 CM for Semant ic  At t r ibuteA concept category is semantic attribute as-signed to content words, and it is identifiedby parsing with phrase-level gramnmrs that areused in speech recognition process and repre-sented with Finite State Automata (FSA).
Since46812345678910Recognition candidatesaa  sh isetsu  ni  resutmnu, no kayachowith restaurant facility / Kayacho(location)aa  sh isetsu  ni rcsuto7nn no katsurn nowith restaurant fimility / Katsura(location)aa  sh isctsu  ni  resutoran no kamigamowith restaurant facility / Kmnigamo(location)<g> sh isc tsu  niwith restaurant<g> sh isetsu  niwith restaurant<g> sh isetsu  niresutoran no kayachofacility / Kayacho(location)rcsutor'a~t 7to kat.~'~trafacility / Katsura(location)7"cs?ttoritTt 7~,o kamigamowith restaurant facility / I(amigamo(location)aa  sh, i setsu  ni  resutoran no kafcwith restaurant fimility / care(facility)<g> sh isetsu  ni resutoran no kafewith restaurant facility / cafc(facility)<g> setsub i  wo rcsutoran no kayachowith restaurant facility / I(ayacho(locatlon)<g> sctsub i  wo resutoran no katsura nowith restaurant facility / Katsura(location).24.24.20.08.08.06.05.02.01.01<g>: tiller modelCM,,,\].0.330.330.250,07(content word) ~ (semantic attribute)restaurant @ fimilityKayacho @ locationKatsura 0 locationKmnigmno ~ locationcare ~ facilityFigure.
1: Example of content-word CM (CM,,,)these FSAs are, classified into (:on(:cl)t categorieslmforehand, we can auton|atically derive theconcept categories of words by parsing withthese grammars.
In our hotel query task, thereare sevelt concept categories uch as qocation','fi, cility' and so on.For this concept (:ategory, we also de-fine semantic-attritmtc CMs (CM~:) as tbllows.First, we (-ah:ulnte a t)osteriori probabilities ofN-best sentences in the same.
way of comtmt-ing content-word CM.
If a concel)t c~tegory c iscontained in the i-th sentence, let 5,,,i = 1, and 0otherwise.
The t)robability that a concept cat-egory c is correct (Pc) is derived as below.Pc = E pi ' sc,ii=1We define this Pc as semantic-attribute CM(CM~).
This CMc estimates which category theuser refers to and is used to generate tt'ectiveguidances.HSel'~ S ut\[el'ancc )v~__  speech recognizer(___ each content word ) g'N-be~t, candidatcs-~' j./ cont{3n~wo|'d / ',CMracccpt~isemantic atl|ibutc /CM Sfill \]semantic slots \[ guidance \] prompt o rcpht'ascFigure 2: Overview of OlU" strategy3 Mixed-initiative Dialogue Strategyusing CMsThere m:e a lot of systems that hawe a(lopteda mixed-initiative strategy (Sturm et al,1999)(Goddeau et a.l., 1996)(Bennacef e.t al.,1996).
It has several adwmtages.
As the.
sys-tems do not impose rigid system-initiated tem-plates, the user can input values he has inmind directly, thus the dialogue l)ecomes morenatural.
In conventional systems, the system-initiated utterances are considered only whensemantic mnbiguity occurs.
But in order to re-alize robust interaction, the system should makeconfirmations to remove recognition errors andgenerate guidances to lead next user's utteranceto succcssflll interpretation.
In this section, wedescribe how to generate the system-initiatedutterances to deal with recognition errors.
Anoverview of our strategy is shown in Figure 2.3.1 Making Ef fect ive Conf i rmat ionsConfidence Measure (CM) is useflll in selectingreliable camlidates and controlling coniirnlationstrategy.
By setting two thresholds 01,02(01 >0~) on content-word CM (CM.,), we provide theconfirmation strategy as tbllows.469?
C-Mw > 0~accept the hypothesis?
Oj >_CM~>02-~ make confirmation to the user"Did you say ...?"?
02 >_ CM~,,--* reject the hypothesisThe.
threshold 01 is used to judge whether thehypothesis is accepted or should be confirmed,and tile threshold 02 is used to judge whether itis reiected.Because UMw is defined for every contentword, judgment among acceptance, confirma-tion, or rejection is made for every contentword when one utterance contains several con-tent words.
Suppose in a single utterance, oneword has CM,,,, between 0~ and 0~ and tile otherhas t)elow 02, the tbrlner is given to confirma-tion process, and tile latter is rejected.
Only ifall content words are rejected, the system willprompt the user to utter again.
By acceptingconfident words and rejecting mlreliable candi-dates, this strategy avoids redundant confirma-tions and tbcuses on necessary confirmation.We optinfize these thresholds 0t, 02 consider-tug the false, acceptance (FA) and the false re-jection (FR) using real data.Moreover, the system should confirm usingtask-level knowledge.
It is not usual that userschange the already specified slot; values.
Thus,recognition results that overwrite filled slots arelikely to be errors, even though its CM~, is high.By making confirmations ill such a situation, itis expected that false acceptance (FA) is sup-pressed.3.2  Generat ing  System- In l t ia tedGu idaneesIt is necessary to guide tile users to recover ti'omrecognition errors.
Especially for novice users,it is often eflbctive to instruct acceptable slotsof the system.
It will be helpful that tile systemgenerates a guidance about the acceptable slotswhen the user is silent without carrying out tiledialogue.The system-initiated guidances are also effec-tive when recognition does not go well.
Evenwhen any successflfl output of content words isnot obtained, the system cast generate ffectiveguidances based on the semantic attribute withfutterance:correct:"shozai  ga oosakaflt no yado"(hotels located in Osaka pref.
)Osaka-pref?locationi12345678910recognition candi(tat, es(<g>: filler model)dtozai ga potoairando no <g>located in Port-islandshozai ga potoairando no <g>located in Port-islandshozai ga oosakafu no <g>located in Osaka-pref.shozai ga oosakafu no <g>located in Osaka-pref.shozai ga oosa\]cashi no <g>located in Osaka-cityshozai ga oosakashi no <g>located in Osaka-cityshozai ga ohazaki no <g>located in Okazakishozai ga otcazaki no <g>located in Okazakishozai ga oohara no <g>located in Oharashozai ga oohara no <g>located in OharaC2~tc semantic attributes1 locationCMw0.380.300.130.110.08content wordsPort-islandelocationOsaka-pref.~locationOsaka-city,locationOkazakielocationOhara01ocationFigure 3: Example of high semantic attributeconfidence in spite of low word confidencehigh confidence.
An example is shown in Fig-ure 3.
In this example, all the 10-best candi-dates are concerning a name of place but theirCMw values are lower than the threshold (02).As a result, any word will be neither acceptednor confirmed.
In this case, rather than re-jecting the whole sentence and telling the user"Please say again", it; is better to guide the userbased oll the attr ibute having high CM,.
,  suchas "Which city is your destination?".
This guid-ance enables tile system to narrow down thevocabulary of the next user's utterance and toreduce the recognition difficulty.
It will conse-quently lead next user's utterance to successfulinterpretation.When recognition on a content word does not470go well repeatedly in spite of high semanti(:-attr ibute CM, it is reasoned that the contentword may be out-ofvocalmlary, in such a case,the systmn shouht change the que.stion.
Forexample, if an uttermme coal;alas all out-ofvocat)ulary word and its semantic-attribute isinibrred as "location", the system can makeguidance, "Please st)eci(y with the name of t)re-fecture", which will lead the next user's utter-ance into the system's vocabulary.4 Exper imenta l  Eva luat ion4.1 Task and DataWe evaluate our nmthod on the hotel querytask.
We colh;cted 120 mimll;es speech data by24 novice users l)y using the 1)rototylm systemwith GUI (Figure 4) (Kawahara et al, 1999).The users were given siml)le instruction before-hand oll the system's task, retriewfi)le il;(nns,how to cancel intmt values, and so o11.
The datais segmented into 705 utterances, with a t)auseof 1.25 seconds.
The voeal)ulary of I;he systemcontains 982 words, and the aural)or of databaserecords is 2040.
()tit of 705 lltterailces, \]24 llttelTallces (1.7.6%)are beyond the system's eal)al)ility , namely theyare out-ofvocalmlary, ou|;-ofgrmnmar~ out-oftask, or fragment of llttel'allC(L \]i1 tbllowing ex-1)erim(mt;s, we cvahmte th(', sys|;t',ln \])erl))rm~nceusing all (lath including these mm,c(:el)tnt)le ut-terances in order to evahlalt;e how the systemcan reject unexl)ected utterances at)t)rot)riatelyas well as recognize hernial utterances correctly.4.2 Thresho lds  to Make Conf i rmat ionsIn section 3.1, we t)resented confirmation strat-egy 1)y setting two thresholds 01,02 (01 > 02) foreolfl, enl;-word CM (CMw).
We optinlize thesethreshoht wflues using t;11(; collected data.
\?ecount ca:ors 11ol; by the utterance lint by thecontent-word (slot).
The number of slots is 804.The threshold 01 decides t)etween accel)taneeand confirmation.
The wdue of 0\] shouhl bedetermined considering both the ratio of ineofrectly accepting recognition errors (False At--ceptance; FA) and the ratio of slots that arenot filh;d with correct wfiues (Slot; Error; SErr).Namely, FA and SErr are defined an the (:(mq)le-meats of t)recision and recall rate of the outl)ltt ,respectively.FA = ~ el' incorrectly accepted wordsof accepted wordsfl~ of correet;ty aecel)ted wordsSE'rr = I -of all correct wordsAfter experimental optimization to minimizeFA+SErr, we derive a wflue of 0i as 0.9.Similarly, the threshold 02 decides contirlna-tion and rejection.
The value of 02 should bedecided considering both the ratio of incorrectlyrqjeeting content words (False Rejection; FR)and the ratio of aceel)ting recognition errors intothe eonfirlnation 1)recess (conditional False At:-eel)tahoe; cFA).fl: of incorrectly re.jetted words~- of all rejected wordsIf we set the threshohl 02 lower, FR de-creases and correspondingly cFA increases,which means that more candidates are ol)tainedbut more eontirmations are needed.
By mini-m izing \]q/.+cFA, we deriw; a value of 02 as 0.6.4.3 Compar i son  w i th  Convent iona lMethodsIll many conventional st)oken di~dogue syst;ems,only 1-best candidate of a speech recognizeroutt)ut is used in the subsequent processing.\?e (:Oral)are ore' method with a conventionalmethod that uses only 1-best ean(lidate in in-terpretation ae(:uraey.
'l.
'he result is shown in%rifle 1.1111 the qlo eonfirnlation' strategy, the hy-pothes(,s are classified by a single threshohl (0)into either the accepted or the rejected.
Namely,(:ontent words having CM,,, over threshohl 0 areaecet)ted, mM otherwise siml)ly r(\[iected.
In thiscase, a 1;hreshold wflue of 0 is set to 0.9 thatgives miniature FA-FSErr.
111 the 'with con-firmation' strategy~ the proposed (:oniirmationstrategy is adol)ted using ()1 and 02.
We set01 = 0.9 and 02 = 0.6.
The qTA+SErr' in Ta-ble 1 means FA(0~)+SErr(02), on the assump-tion that the contirnmd l)hrases are correctly ei-ther accel)ted or rejected.
-We regard this as-smnt)tion as at)l)rol)riate, because users tend toanswer ~ye, s' simply to express their affirmation(Hockey et al, 1997), so the sys|;em can dis-tinguish affirmative answer and negative olle bygrasping simple 'yes' utterances correctly.471i~ ........................ % ............. II III I ~t(a) A real system in JapaneseHote l  Accommodat ion  Searchhotel type is I Japanese-style Ilocation is I downtown Kyoto \]room rate is less than I 10,000 I yenThese are query results ?
(b) Upper I)ortion translated in EnglishFigure 4: An outlook of GUI (Graphical User Interface.
)Table 1: Comparison of methodsFA+SErr FA SErfonly 1st candidate 51.5 27.6 23.9no confirmation 46.1 14.8 31.3with confirmation 40.0 14.8 25.2FA: ratio of incorrectly accepting recognition errorsSErr: ratio of slots that are not filled with correct valuesAs shown in Table 1, interpretation ~,c('u-racy is improved by 5.4% in the 'no confirma-tion' strategy compared with the conwmtionalmethod.
And 'with confirmation' strategy, weachieve 11.5% improvement in total.
This resultproves that our method successflflly eliminatesrecognition errors.By making confirmation, the interaction be-comes robust, but accordingly the number ofwhole utterances increases.
If all candidateshaving CM, o under 01 are given to confirma-tion process without setting 0u, 332 wdn con-firmation for incorrect contents are generatedout of 400 candidates.
By setting 02,102 candi-dates having CMw between 01 and 02 are con-firmed, and the number of incorrect confirma-tions is suppressed to 53.
Namely, the ratioof correct hypotheses and incorrect ones beingconfirmed are ahnost equM.
This result showsindistinct candidates are given to confirmationprocess whereas scarcely confident candidatesare rejected.content-word CM and semantic-attribute CM 100FA+SErr(content word)FA+SErr(semantic attribute) - - - - -8O6O+m< 40"N ,_~.~.~.~ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
~ ' / /121 , _\]0 0.2 0.4 0.6 0.8 1thresholdFigure 5: Pertbrm~mce of the two CMs4.4 Effect iveness of Semant ic -At t r ibuteCMIn Figure 5, the relationship between content-word CM and semantic-attribute CM is shown.It is observed that semantic-attribute CMs areestimated more correctly than content-wordCMs.
Therefore, even when successful interpre-tation is not obtained fl'om content-word CMs,semantic-attribute can be estimated correctly.In experimental data, there are 148 slots 2that are rejected by content-word CMs.
It isalso observed that 52% of semantic-attributes2Out-of-vocabulary and out-of-grammar utterancesare included in their phrases.472with CA4c over 0.9 is correct.
Such slots amomitto 34.
Namely, our system can generate tt.
'cc-rive guidances against 23% (34/148) of utter-antes that had been only rejected in conven-tional methods.5 Conc lus ionWe present dialogue mallagement using twoconcel)t-level CMs in order to realize rolmst ill-teractioll.
The content-word CM provides acriterion to decide whether an interpretationshould be accel)ted, confirmed, or rejected.
Thisstrategy is realized by setting two thresholdsthat are optimized balancing false acceptanceand false rejection.
The interpretation error(FA+SErr) is reduced by 5.4% with no confir-mation and by \] 1.5% with confirmations.
More-over, we &',line CM on semantic attribut(~s, andpropose a new met;hod to generate ilbx:tiveguidances.
The concept-t)ased (:onfidence mea-sure realizes tlexible mixed-initiative dialogue inwhich the system can make effective contirma-tion and guidance by estimating user's inten-tion.Re ferencesS.
\]~(mnacef, L. Devillers: S. Rosset, andL.
Lamel.
1996.
Dialog in the I/.AIIfl?ELtelet)hone-1)as(~(t system.
In Pwc.
\]nt'l Con.fion ,5'pokc'n, Language l)Tvcc.ssi'n.g.G.
Bouwman, ,1.
Sturm, and L. Boves.
1999.
In-cort)orating contidcnce measures in the.
Dutchtrain timetable information system developedin the ARISE t)roject.
In P'lvc.
ICASSP.D.
God(lean, H. Meng, J. Polifroni, S. Seneff,and S. Busayapongchai.
1996.
A form-baseddiah)gue manager for spoken language al)pli-cations.
In P~vc.
lnt'l Co7@ on Spoken Lan-guage \])rocessing.B.
A. Hockey, D. l:l,ossen-Knill, B. Spejew-ski, M. Stone, and S. Isard.
1997.
Canyou predict resl)onses to yes/no questions?yes,no,and stuff.
In Proc.
EUIl, OSPEECI\]'97.T.
Kawahara, C.-H. Lee, ~md B.-H. Juang.1998.
Flexible speech understanding basedon confl)ined key-t)hrase detection and veri-fication.
IEEE TTnns.
on Speech and AudioProcessing, 6 (6):558-568.T.
Kawahara, K. q_?maka, nd S. Doshita.
1999.Domain-independent t)latform of spoken di-alogue interfaces for information query, inProc.
ESCA workshop on Interactive Dia-loguc in Multi-Modal Systems, pages 69 72.A.
Lee, T. Kawahara, and S. Doshita.
1999.Large.
vocabulary continuous speech recogni-tion 1)arser based on A* search using gram-mar category category-pair constraint (in,lapancsc).
Trans.
h~:formation ProcessingSociety of ,lapau,, 40(4):1374-1382.D.
J. Litman, M. A. Walker, and M. S. Kearns.1999.
Automatic detection of 1)oor speechrecognition at the dialogue level.
In Pwc.
of37th Annual Meeting o.f the A CL.Y.
Niimi and Y. Kobayashi.
1996.
A dialog con-trol strategy based on the reliability of st)eechrecognition.
In Proc.
Int'l Cml:\[.
on ,5'pokcnLanguage Processing.C.
Pao, P. S('hmid, and J.
Glass.
1998.
Con-tidence scoring tbr st)eech mlderstnnding sys-tems.
In P~v(:.
\]'nt'l Conf.
on S"poken Lan-guage P~vcessing..}.
Sturm, E. Os, and L. Boves.
1999.
Issues inspoken dialogue systems: Experiences withthe Dutch ARISE system.
In Pwc.
of ESCAIDS'99 Workshop.T.
Watanal)e, M. Ar~ki, and S. Doshitm 1998.Evaluating diah)gue strategies un(lex colnnm-nication errors using COlntmter-to-comlmtersimulation.
7}'an.s.
of IEICE, he:fo g Syst.,E81-D(9):I025 1033.473
