A Model of Early Syntactic DevelopmentPat LangleyThe Robotics InstituteCarnegie-Mellon UniversityPittsburgh, Pennsylvania 1521,3 USAABSTRACTAMBER is a model of first language acquisition that improves itsperformance through a process of error recovery.
The model isimplemented as an adaptive production system that introducesnew condition-action rules on the basis of experience.
AMBERstarts with the ability to say only one word at a time, but addsrules for ordering goals and producing grammatical morphemes,based on comparisons between predicted and observedsentences.
The morpheme rules may be overly general and leadto errors of commission; such errors evoke a discriminationprocess, producing more conservative rules with additionalconditions.
The system's performance improves gradually, sincerules must be relearned many times before they are used.AMBER'S learning mechanisms account for some of the majordevelopments observed in children's early speech.1.
IntroductionIn this paper, I present a model that attempts to explain theregularities in children's early syntactic development.
The modelis called AMBER, an acronym for Acquisition Model Based onError Recovery.
As its name implies, AMBER learns language bycomparing its own utterances to those of adults and attemptingto correct any errors.
The model is implemented as an adaptiveproduction system - a formalism well-suited to modeling theincremental nature of human learning.
AMEER focuses on issuessuch as the omission of content words, the occurrence oftelegraphic speech, and the order in which function words aremastered.
Before considering AMBER in detail, I will first reviewsome major features of child language, and discuss some earliermodels of these phenomena.Children do not learn language in an all.or.none fashion.
Theybegin their linguistic careers uttering one word at a time, andslowly evolve through a number of stages, each containing moreadult-like speech than the one before.
Around the age of oneyear, the child begins to produce words in isolation, andcontinues this strategy for some months.
At approximately 18months, the child begins to combine words into meaningfulsequences.
In order-based languages such as English, the childusually follows the adult order.
Initially only pairs of words areproduced, but these are followed by three-word and later byfour-word utterances.
The simple sentences occurring in thisstage consist almost entirely of content words, whilegrammatical morphemes uch as tense endings and prepositionsare largely absent.During the period from about 24 to 40 months, the childmasters the grammatical morphemes which were absent duringthe previous stage.
These "function words" are learnedgradually; the time between the initial production of a morphemeand its mastery may be as long as 16 months.
Brown (1973) hasexamined the order in which 14 English morphemes areacquired, finding the order of acquisition to be remarkablyconsistent across children.
In addition, those morphemes withsimpler meanings and involved in fewer transformations arelearned earlier than more complex ones.
These findings placesome strong constraints on the learning mechanisms onepostulates for morpheme acquisition.Now that we have reviewed some of the major aspects of childlanguage, let us consider the earlier attempts at modeling thesephenomena.
Computer programs that learn language can beusefully divided into two groups: those which take advantage ofsemantic feedback, and those which do not.
In general, the earlywork concerned itself with learning grammars in the absence ofinformation about the meaning of sentences.
Examples of thisapproach can be found in Solomonoff (1959), Feldman (1969)and Homing (1969).
Since children almost certainly havesemantic information available to them, I will not focus on theirresearch here.
However, much of the early work is interesting inits own right, and some excellent systems along these lines haverecently been produced by Berwick (1980) and Wolff (1980).In the late 1960's, some researchers began to incorporatesemantic information into their language learning systems.
Themajority of the resulting programs showed little concern with theobserved phenomena, including Siklossy's ZBIE (1972), Ktein'sAUTOLING (1973), Hedrick's production system model (1976),Anderson's LAS (1977), and Sembugamoorthy's PLAS (1979).These systems failed as models of human language acquisitionin two major areas.
First, they learned language in an all-or.nonemanner, and much too rapidly to provide useful models of childlanguage.
Second, these systems employed conservativelearning strategies in the hope of avoiding errors.
In contrast,children themselves make many errors in their earlyconstructions, but eventually recover from them.However, a few researchers have attempted to constructplausible models of the child's learning process.
For example,Kelley (1967) has described an "hypothesis testing" model thatlearned successively more complex phrase structure grammarsfor parsing simple sentences.
As new syntactic classes becameavailable, the program rejected its current grammar in favor of amore accurate one.
Thus, the model moved from a stage inwhich individual words were viewed as "things" to the moresophisticated view that "subjects" precede "actions".
Onedrawback of the model was that it could not learn new categorieson its own initiative; instead, the author was forced to introducethem manually.Reeker (1976) has described PST, another theory of earlysyntactic development.
This model assumed that children havelimited short term memories, so that they store onty portions ofan adult sample sentence.
The model compared this reducedsentence to an internally generated utterance, and differences145between the two were noted.
Six types of differences wererecognized (missing prefixes, missing suffixes, missing infixes,substitutions, extra words, and transpositions), and each led toan associated alteration of the grammar.
PST accounted forchildren's omission of content words and the gradual increase inutterance length.
The limited memory hypothesis also explainedthe telegraphic nature of early speech, though Reeker did notaddress the issue of function word acquisition.
Overgeneral-izations did occur in PST, but the model could revise its grammarupon their discovery, so as to avoid similar errors in the future.PST also helped account for the incremental nature of languageacquisition, since differences were addressed one at a time andthe grammar changed only slowly.Selfridge (1981) has described CHILD, another program thatattempted to explain some of the basic phenomena of firstlanguage acquisition.
This system began by learning themeanings of words in terms of a conceptual dependencyrepresentation.
Word meanings were initially overly specific, butwere generalized as more examples were encountered.
As morewords were learned and their definitions became less restrictive,the length of CHILD'S utterances increased.
CHILD differed fromother models of language learning by incorporating, a non-linguistic component.
This enabled the system to correctlyrespond to adult sentences such as Put the ba/I in the box, andled to the appearance that the system understood languagebefore it could produce it.
Of course, this strategy sometimes ledto errors in comprehension.
Coupled with the disapproval of atutor, such errors were one of the major spurs to the learning ofword orders.
Syntactic knowledge was stored with the meaningsof words, so that the acquisition of syntax necessarily occurredafter the acquisition of individual words.Although tl~ese systems fare much better as psychologicalmodels than other language learning programs, they have someimportant limitations.
We have seen that Kelley's system requiredsyntactic classes to be introduced by hand, making hisexplanation less than satisfactory.
Selfridge's CHILD was muchmore robust than Kelley's program, and was unique in modelingchildren's use of nonlinguistic ues for understanding.
However,CHILD'S explanation for the omission of content words - thatthose words are not yet known - was implausible, since childrenoften omit words that they have used in previous utterances.Reeker's PST explained this phenomenon through a limitedmemory hypothesis, which is consistent with our knowledge ofchildren's memory skills.
Still, PST included no model of theprocess through which memory improved; in order to simulatethe acquisition of longer constructions, Reeker would have hadto increase the system's memory size by hand.
Both CHILD andPST learned relatively slowly, and made mistakes of the generaltype observed with children.
Both systems addressed the issueof error recovery, starting off as abominable language users, butgetting progressively better with time.
This is a promisingapproach that I' attempt o develop it in its extreme form in thefollowing pages.2.
An Overview of AMBERAlthough Reeker's PST and Selfridge's CHILD address thetransition from one-word to multi-word utterances, we have seenthat problems exist with both accounts.
Neither of theseprograms focus on the acquisition of function words, theirexplanations of content word omissions leave something to bedesired, and though they learn more slowly than other systems,they still learn more rapidly than children.
In response to theselimitations, the goals of the current research are:?
Account for the omission of content" words, and theeventual recovery from such omissions.?
Account for the omission of function words, and the order inwhich these morphemes are mastered.?
Account for the gradual nature of both these linguisticdevelopments.In this section I provide an overview of AMBER, a model thatprovides one set of answers to these questions.
Since more isknown about children's utterances than their ability tounderstand the utterances of others, AMBER models the learningof generation strategies, rather than strategies for understandinglanguage.Selfridge's and Reeker's models differ from other languagelearning systems in their concern with the problem of recoveringfrom errors.
The current research extends this idea even further,since all of AMBER'S learning strategies operate through aprocess of error recovery.
1 The model is presented with threepieces of information: a legal sentence, an event to bedescribed, and a main goal or topic of the sentence.
An event isrepresented as a semantic network, using relations like agent,action, object, size, color, and type.
The specification of one ofthe nodes as the main topic allows the system to restate thenetwork as a tree structure, and it is from this tree that AMBERgenerates a sentence.
If this sentence is identical to the samplesentence, no learning is required.
If a disagreement between thetwo sentences is found, AMBER modifies its set of rules in anattempt to avoid similar errors in the future, and the systemmoves on to the next example.AMBER'S performance system is stated as a set of condition-action rules or productions that operate upon the goal tree toproduce utterances.
Although the model starts with the potentialfor producing (unordered) telegraphic sentences, it can initiallygenerate only one word at a time.
To see why this occurs, wemust consider the three productions that make up AMBER'S initialperformance system.
The first rule (the start rul~) is responsiblefor establishing subgoals; it may be paraphrased as:STARTIf you want to descr ibe node1,and node2 is in relation to node1,then descr ibe node2.Matching first against the main goal node, this rule selects one ofthe nodes below it in the tree and creates a subgoal to describethat node.
This rule continues to establish lower level goals until1 In spirit, AMBER is very similar to Reeker's model, though theydiffer in many details.
Historically, PST had no impact on thedevelopment of AMBER.
The initial plans for AMBER arose fromdiscussions with John R..Anderson in the fall of 1979, while I didnot become aware of Reeker's work until the fall of 1980.2For the sake of clarity, I will be presenting only Englishparaphrases of the actual PRISM productions.
All variables areitalicized; these may match against any symbol, but alloccurrences of a variable -"  ~'.
~,~atch to the same element.146a terminal node is reached.
At this point, a second production(the speak rule) is matched; this rule may be stated:SPEAKIf you want to descr ibe a concepttand word is the word for concept,then say word and note that concepthas been described.This production retrieves the word for the concept AMBER wantsto describe, actually says this word, and marks the terminal goalas satisfied.
Once this has been done, the third and finalperformance production becomes true.
This rule matcheswhenever a subgoal has been satisfied, and attempts to mark thesupergoal as satisfied; it may be paraphrased as:STOPIf you want to descr ibe node1,and node2 is in re/ation to nodel,and node2 has already been described,then note that node1 has been described.Since the stop rule is stronger 3 than the start rule (which wouldlike to create another subgoal), it moves back up the tree,marking each of the active goals as satisfied (including the maingoal).
As a result, AMBER believes it has successfully describedan event after it has uttered only a single word.
Thus, althoughthe model starts with the potential for producing multi.wordutterances, it must learn additional rules (and make themstronger than the stop rule) before it can generate multiplecontent words in the correct order.In general, AMBER learns by comparing adult sentences to thesentences it would produce in the same situations.
Thesepredictions reveal two types of mistakes - errors of omissionand errors of commission.
These errors are detected byadditional/earning productions that are responsible for creatingnew performance rules.
Thus, AMBER is an example of whatWaterman (1975) has called an adaptive production system,which modifies its own behavior by inserting new condition-action rules.
Below I discuss AMBER'S response to errors ofomission, since these are the first to occur and thus lead to thesystem's first steps beyond the one-word stage.
I consider theomission of content words first, and then the omission ofgrammatical morphemes.
Finally, I discuss the importance oferrors of commission in discovering conditions on theproduction of morphemes.3.
Learning Preferences and OrdersAMBER'S initial self-modifications result from tile failure topredict content words.
Given its initial ability to say one word ata time, the system can make two types of content wordomissions - it can fail to predict a word before a correctlypredicted one, or it can omit a word after a correctly predictedone.
Rather different rules are created in each case.
Forexample, imagine that Daddy is bouncing a ball, and supposethat AMBEa predicted only the word "ball", while hearing thesentence "Daddy is bounce ing the ball".
In this case, one of thesystem's learning rules would note the omitted content word3The notion of strength plays an important role in AMBER'Sexplanation of language learning.
When a new rule is created, itis given a low initial strength, but this is increased whenever thatrule is relearned.
And since stronger productions are preferredto their weaker competitors, rules that have been learned manytimes determine behavior.
"Daddy" before the content word "ball", and an agentproduction would be created:AGENTIf you want to descr ibe event1,and agent1 is the agent of event1,then desc ribe agent1.Although I do not have the space to describe the responsiblelearning rule in detail, I can say that it matches against situationsin which one content word is omitted before another, and that italways constructs new productions with the same form as theagent rule described above.
In this case, it would also create asimilar rule for describing actions, based on the omitted"bounce".
Note that these new productions do not give AMBERthe ability to say more than one word at a time.
They merelyincrease the likelihood that the program will describe the agentor action of an event instead of the object.However, as AMBER begins to prefer agents to actions andactions to objects, the probability of the second type of error(omitting a word after a correctly predicted one) increases.
Forexample, suppose that Daddy is again bouncing a ball, and thesystem says "Daddy" while it hears "Daddy is bounce ing theball".
In this case, a slightly different production is created thatis responsible for ordering the creation of goals.
Since the agentrelation was described but the object was omitted, an agent.object rule is constructed:AGENT- OBJECTIf you want to descr ibe event1,and agent1 is the agent of event1,and you have descr ibed agent1,and object1 is the object  of event1,then descr ibe object1.Together with the agent rule shown above, this production letsAMBER produce utterances such as "Daddy ball".
Thus, themodel provides a simple explanation of why children omit somecontent words in their early multi-word utterances.
Such rulesmust be constructed many times before they become strongenough to have an effect, but eventually they let the systemproduce telegraphic sentences containing all relevant contentwords in the standard order and lacking only grammaticalmorphemes.4.
Learning Suffixes and PrefixesOnce AMBER begins to correctly predict content words, it canlearn rules for saying grammatical morphemes as well.
As withcontent words, such rules are created when the system hears amorpheme but fails to predict it in that position.
For example,suppose the.
program hears the sentence "Daddy ?
is bounce ing"the ball", 4 but predicts only "Daddy bounce ball".
In this case,the following rule is generated:ING-1If you have descr ibed action1,and action1 is the action of event1,then say ING.Once it has gained sufficient strength, this rule will say themorpheme "ing" after any action word.
As stated, the productionis overly general and will lead to errors of commission.
Iconsider AMBER'S response to such errors in the followingsection.4Asterisks represent pauses in the adult sentence.
Thesecues are necessary for AMBER to decide that a morpheme like"is" is a prefix for "bounce" instead of a suffix for "Daddy".147The omission of prefixes leads to very similar rules.
In theabove example, the morpheme "is" was omitted before"bounce", leading to the creation of a prefix rule for producingthe missing function word:IS-1If you want to descr ibe action1,and action I is the action of event1,then say IS.Note that this rule will become true before an action has beendescribed, while the rule ing- I  can apply only after the goal todescribe the action has been satisfied.
AMBER uses suchconditions to control the order in which morphemes areproduced.Figure 1 shows AMBER'S mean length of utterance as afunction of the number of sample sentences (taken in groups offive) seen by the program, b As one would expect, the systemstarts with an average of around one word per utterance, and thelength slowly increases with time.
AMBER moves through a two.word and then a three-word stage, until it eventually producessentences lacking only grammatical morphemes.
Finally, themorphemes are included, and adult-like sentences areproduced.
The incremental nature of the learning curve resultsfrom the piecemeal way in which AMBER learns rules forproducing sentences, and from the system's reliance on thestrengthening process.m 9?
!o ;o Jo ,boNumber  of  sample  sen tencesFigure 1.
Mean length of AMBER's utterances.5.
Recovering from Errors of CommissionErrors of commission occur when AMBER predicts a morphemethat does not occur in the adult sentence.
These errors resultfrom the overly general prefix and suffix rules that we saw in thelast section.
In response to such errors, AMBER calls on adiscrimination routine in an attempt to generate moreconservative productions with additional conditions.
~ Earlier, Iconsidered a rule (is-1) for producing "is" before the action of anevent.
As stated, this rule would apply in inappropriate situationsas well as correct ones.
For example, suppose that AMBERlearned this rule in the context of the sentence "Daddy is bounceing the ball".
Now suppose the system later uses this rule topredict the same sentence, but that it instead hears the sentence"Daddy was bounce ing the ball".5AMBER iS implemented on a PDP KL.
tO in PRISM (Langley andNeches, t981), an adaptive production system languagedesigned for modeling learning phenomena; the run summarizedin Figure t took approximately 2 hours of CPU time.At this point, AMBER'S discrimination routine would retrieve therule responsible for predicting "is" and lowers its strength; itwould also retrieve the situation that led to the faulty application,passing this information to the discrimination routine.
Comparingthe earlier good case to the current bad case, the discriminationmechanism finds only one difference - in the good example, theaction node was marked present, while no such marker occurredduring the faulty application.
The result is a new production thatis identical to the original rule, except that an additionalcondition has been included:IS-2If you want to descr ibe action1,and action I is the action of event1,and action1 is in the present,then say IS.This new condition will let the variant rule fire only when theaction is marked as occurring in the present.
When first created,the is-2 production is too weak to be seriously considered.However, as it is learned again and again, it will eventually cometo mask its predecessor.
This transition is aided by theweakening of the faulty is-1 rule each time it leads to an error.Once the variant production has gained enough strength toapply, it will produce its own errors of commission.
For example,suppose AMBER uses the is-2 rule to predict "The boy s isbounce ing the ball", while the system hears "The boy s arebounce ing the ball".
This time the difference is morecomplicated.
The fact that the action had an agent in the goodsituation is no help, since an agent was present during the faultyfiring as well.
However, the agent was singular in the first casebut not during the second.
Accordingly, the discriminationmechanism creates a secondvariant:IS-3If you want to descr ibe action1,and action1 is the action of event1,and action1 is in the present,and agent1 is the agent of event1,and agent1 is singular,then say IS.The resulting rule contains two additional conditions, since thelearning process was forced to chain through two elements tofind a difference.
Together, these conditions keep theproduction from saying the morpheme "is" unless tl~e agent ofthe current action is singular in number.Note that since the discrimination process must learn thesesets of conditions separately, an important prediction results:the more complex the conditions on a morpheme's use, thelonger it will take to master.
For example, three sets ofconditions are required for the "is" rule, while only a singlecondition is needed for the "ing" production.
As a result, theformer is mastered after the latter, just as found in children'sspeech.
Table 1 presents the order of acquisition for the sixclasses of morpheme learned by AMBER, and the order in whichthe same morphemes were mastered by Brown's children.
Thenumber of sample sentences the model required before masteryare also included.6Anderson's ALAS (1981) system uses a very similar process torecover from overly general morpheme rules.
AMBER and AL, ~ :~have much in common, both having grown out of discussionsbetween Anderson and the author.
Although there isconsiderable overlap, ALAS generally accounts for laterdevelopments in children's speech than does AMBER.148The general trend is very similar for the children and themodel, but two pairs of morphemes are switched.
For AMEER, theplural construction was mastered before "ing", while in theobserved data the reverse was true.
However, note that AMBERmastered the progressive construction almost immediately afterthe plural, so this difference does not seem especially significant.Second, the model mastered the articles "the", "a", and "some"before the construction for past tense.
However, Brown hasargued that the notions of "definite" and "indefinite" may bemore complex than they appear on the surface; thus, AMBER'Srepresentation of these concepts as single features may haveoversimplified matters, making articles easier to learn than theyare for the child.Thus, the discrimination process provides an elegantexplanation for the observed correlation between a morpheme'scomplexity and its order of acquisition.
Observe that if theconditions on a morpheme's application were learned through aprocess of generalization such as that proposed by Winston(1970), exactly the opposite prediction would result.
Sincegeneralization operates by removing conditions which differ insuccessive examples, simpler rules would be finalized later thanmore complex ones.
Langley (1982) has discussed thedifferences between generalization-based and discrimination.based approaches to learning in more detail.CHILDREN'S ORDER AMBER'S ORDER LEARNING TIMEPROGRESSIVE PLURAL 59PLURAL PROGRESSIVE 63PAST TENSE A RTICLES 166A RTICLES PAST TENSE 1S6THIRD PERSON THIRD PERSON 283AUXILIARY AUXILIARY 306Table 1.
Order of morpheme mastery by the child and AMBER.Some readers will have noted the careful crafting of the aboveexamples, so that only one difference occurred in each case.This meant that the relevant conditions were obvious, and thediscrimination mechanism was not forced to consider alternatecorrections.
In order to more closely model the environment inwhich children learn language, AMBER was presented withrandomly generated sentence/meaning pairs.
Thus, it wasusually impossible to determine the correct discrimination thatshould be made from a single pair of good and bad situations.AMBER'S response to this situation is to create all possiblediscriminations, but to give each of the variants a low initialstrengtl~.
Correct rules, or rules containing at least some correctconditions, are learned more often than rules containingspurious conditions.
And since AMBER strengthens a productionwhenever it is relearned, variants with useful conditions come tobe preferred over their competitors.
Thus, AMEER may be viewedas carrying out a breadth-first search through the space ofpossible rules, considering many alternatives at the same time,and selecting the best of these for further attention.
Onlyvariants that exceed a certain threshold (generally those withcorrect conditions) lead to new errors of commission andadditional variants.
Eventually, this search process leads to thecorrect rule, even in the presence of many irrelevant features.Figure 2 presents the learning curves for the "ing" morpheme.Since AMEER initially lacks an "ing" rule, errors of commissionabound at the outset, but as this production and its variants arestrengthened, such errors decrease.
In contrast, errors ofcommission are absent at the beginning, since AMEER lacks an"ing" rule to make false predictions.
As the morpheme rulebecomes stronger, errors of commission grow to a peak, but theydisappear as discrimination takes effect.
By the time it has seen63 sample sentences, the system has mastered the presentprogressive construction.0.8 ,,~ trots of omi0.60.40.2  Errors of corn miss,o 7 .
~, .
: -0 1"0 20  30 =~0 50 60 70 80 90 100Number of sample sentencesFigure 2.
AMBER's learning curves for the morpheme "ing".6.
Directions for Future ResearchIn the preceding pages, we have seen that AMEER offersexplanations for a number of phenomena observed in children'searly speech.
These include the omission of content words andmorphemes, the gradual manner in which these omissions areovercome, and the order in which grammatical morphemes aremastered.
As a psychological model of early syntacticdevelopment, AMEER constitutes an improvement over previouslanguage learning programs.
However, this does not mean thatthe model can not be improved, and in this section I outline somedirections for future research efforts.6.1.
Simplicity and GeneralityOne of the criteria by which any scientific theory can bejudged is simplicity, and this is one dimension along whichAMEER could stand some improvement.
In particular, some ofAMBER'S learning heuristics for coping with errors of omissionincorporate considerable knowledge about the task of learning alanguage.
For example, AMEER knows the form of the rules it willlearn for ordering goals and producing morphemes.
Anotherquestionable piece of information is the distinction betweenmajor and minor meanings that lets AMEER treat content wordsand morphemes as completely separate entities.
One mightargue that the child is born with such knowledge, so that anymodel of language acquisition should include it as well,However, until such innateness is proven, any model that canmanage without such information must be considered simlsler,more elegant, and more desirable than a model that requires it tolearn a language.149In contrast to these domain-apecific heuristics, AMBER'Sstrategy for dealing with errors of commission incorporates anapparently domain-independent learning mechanism - thediscrimination process.
This heuristic can be applied to anydomain in which overly general rules lead to errors, and can beused on a variety of representations to discover the conditionsunder which such rules should be selected.
In addition tolanguage development, the discrimination process has beenapplied to concept learning (Anderson, Kline, and Beasely, 1979;Langley, 1982) and strategy acquisition (Brazdil, 1978; Langley,1982)~ Langley (1982) has discussed the generality and power ofdiscrimination-based approaches to learning in greater detail.As we shall see below, this heuristic may Provide a moreplausible explanation for the learning of word order.
Moreover, itopens the way for dealing with some aspects of  languageacquisition that AMBER has so far ignored - the learning ofword/concept links and the mastering of irregular constructions.6.2.
Learning Word Order Through DiscriminationAMBER learns the order of content words through a two-stageprocess, first learning to prefer some relations (like agent) overothers (like action or object), and then learning the relativeorders in which such relations should be described.
Theadaptive productions responsible for these transitions containthe actual form of the rules that are learned; the particular ulesthat result are simply instantiations of these general forms.Ideally, future versions of AMBER should draw on more generallearning strategies to acquire ordering rules.Let us consider how the discrimination mechanism might beapplied to the discovery of such rules.
In the existing system, thegeneration of "ball" without a preceding "Daddy" is viewed asan error of omission.
However, it could as easily be viewed as anerror of commission in which the goal to describe the object wasprematurely satisfied.
In this case, one might use discriminationto generate a variant version of the start rule:If you want to describe node1,and node2 is the object of node1,and node3 is the agent of nodel,and you have described node3,then describe node2.This production is similar to the start rule, except that it will setup goals only to describe the object of an event, and then only ifthe agent has already been described.
In fact, this rule isidentical to the agent-object rule discussed in an earlier section;the important point is that it is also a special case of the start rulethat might be learned through discrimination when the moregeneral rule fires inappropriately.
The same process could leadto variants such as the agent rule, which express preferencesrather than order information.
Rather than starting withknowledge of the forms of rules at the outset, AMBER would beable to determine their form through a more general learningheuristic.6.3.
Major and Minor MeaningsThe current version of AMSEn relies heavily on therepresentational distinction between major meanings andmcJulations of those meanings.
Unfortunately, some languagesexpress through content wor~s what others express throughgrammatical morphemes.
Future versions of the system shouldlessen this distinction by using the same representation for bothtypes o\[ information.
In addition, the model might employ asingle production for learning to produce both content wordsand morphemes; thus, the program would lack the speak ruledescribed earlier, but would construct specific versions of thisproduction for particular words and morphemes.
This wouldalso remedy the existing model's inability to learn newconnections between words and concepts.
Although theresulting rules would probably be overly general, AMBER wouldbe able to recover from the resulting errors by additional use ofthe discrimination mechanism.The  present model also makes a distinction betweenmorphemes that act as prefixes (such as "the") and those thatact as suffixes (such as "ing").
Two separate learning rules areresponsible for recovering from function word omissions, andalthough they are very similar, the conditions under which theyapply and the resulting morpheme rules are different.Presumably, if a single adaptive production for learning wordsand morphemes were introduced, it would take over thefunctions of both the prefix and suffix rules.
If this approach canbe successfully implemented, then the current reliance on pauseinformation can be abandoned as welt, since the pauses serveonly to distinguish suffixes from prefixes.Such a reorganization would considerably simplify the theory,but it would also lead to two complications.
First, the resultingsystem would tend to produce utterances like "Daddy ed" or"the bounce", before it learned the correct conditions onmorphemes through discrimination.
(This problem is currentlyavoided by including information about the relation when amorpheme rule is first built, but this requires domain-specificknowledge about the language learning task.)
Since childrenvery seldom make such errors, some other mechanism must befound to explain their absence, or the model's ability to accountfor the observed phenomena will suffer,Second, if pause information (and the ability to take advantageof such information) is removed, the system wilt sometimesdecide a prefix is a suffix and vice versa.
For example, AMBERmight construct a rule to say "ing" before the object of an eventis described, rather than after the action has been mentioned.However, such variants would have little effect on the system'soverall performance, since they would be weakened if they everled to deviant utterances, and they would tend to be learned lessoften than the desired rules in any case.
Thus, the strengtheningand weakening processes would tend to direct search throughthe space of rules toward the correct segmentation, even in theabsence of pause information.6.4, Mastering Irregular ConstructionsAnother of AMBER'S limitations lies in its inability to learnirregular constructions uch as "men" and "ate".
However, bycombining discrimination and the approach to learningword/concept links described above, future implementationsshould fare much better along this dimension.
For example,consider the irregular noun "foot", which forms the plural "feet".Given a mechanism for connecting words and concepts, AMBERmight initially form a rule connecting the concept *foot to theword "foot".
After gaining sufficient strength, this rule would say"~?
'~+" whenever seeing an example of the concept ?foot.
Uponencountering an occurrence of "feet", the system would notethe error of commission and call on discrimination.
This wouldlead to a variant rule that produced "foot" only when a sing/emarker was present.
Also, a new rule connecting "foot to "feet"would be created.
Eventually, this new rule would also lead toerrors of commission, and a variant with a plural condition wouldcome to replace it.150Dealing with the rule for producing the plural marker "s"would be somewhat more difficult.
Although AMBER mightinitially learn to say "foot" and "feet" under the correctcircumstances, it would eventually learn the general rule forsaying "s" after plural agents and objects.
This would lead toconstructions uch as "feet s", which have been observed inchildren's utterances.
The system would have no difficulty indetecting such errors of commission, but the appropriateresponse is not so clear.
Conceivably, AMBER could createvariants of the "s" rule which stated that the concept to bedescribed must not be =foot.
However, a similar condition wouldatso have to be included for every situation in which irregularpluralization occurred (deer, man, cow, and so on).
Similardifficulties arise with irregular constructions for the past tense.A better solution would have AMBER construct a special rulefor each irregular word, which "imagined" that the inflection hadalready been said.
Once these productions became strongerthan the %" and "ed" rules, they would prevent the latter'sapplication and bypass the regular constructions in these cases.Overly general constructions like "foot s" constitute a relatedform of error.
Although AMBER would generate such mistakesbefore the irregular form was mastered, it would not revert to theovergeneral regular construction at a later point, as do manychildren.
The area of irregular constructions is clearly aphenomenon that deserves more attention in the future.7.
ConclusionsIn conclusion, AMBER provides explanations for severatimportant phenomena observed in children's early speech.
Thesystem accounts for the one-word stage and the child'stransition to the telegraphic stage.
Although AMBER and childreneventually learn to produce all relevant content words, both passthrough a stage where some are omitted.
Because it learns setsof conditions one at a time, the discrimination process explainsthe order in which grammatical morphemes are mastered.Finally, AMBER learns gradually enough to provide a plausibleexplanation of the incremental nature of first languageacquisition.
Thus the system constitutes a significant addition toour knowledge of syntactic development.Of course, AMBER has a number of limitations that should beaddressed in future research.
Successive versions should beable to learn the connections between words and concepts,should reduce the distinction between content words andmorphemes, and should be able to master irregularconstructions.
Moreover, they should require less knowledge ofthe language learning task, and rely more of domain-independent learning mechanisms such as discrimination.
Butdespite its limitations, the current version of AMBER has provenitself quite useful in clarifying the incremental nature of languageacquisition, and future models promise to further ourunderstanding of this complex process.ReferencesAnderson, J. R. Induction of augmented transition networks.Cognitive Science, 1977, 1,125-157.Anderson, J. R. A theory of language acquisition based ongeneral learning principles.
Proceedings of the SeventhInternational Joint Conference on Artificial Intelligence, 1981.Anderson, J. R., Kline, P. J., and Beasely, C. M. A generallearning theory and its application to schema abstraction.
InG.
H. Bower (ed.
), The Psychology of Learning andMotivation, Volume 13, 1979.Berwick, R. Computational analogues of constraints ongrammars: A model of syntactic acquisition.
Proceedings ofthe 18th Annual Conference of the Association forComputational Linguistics, 49-53, 1980.BrazdU, P. Experimental earning model.
Proceedings of theAISB Conference, 1978, 46-50.Brown, R. A First Language: The Early Stages.
Cambridge,Mass.
: Harvard Universi~ Press, 1973.Feldman, J.
A., Gips, J., Homing, J. J., and Reder, S.Grammatical complexity and inference.
Technical ReportNo.
CS 125, Computer Science Department, StanfordUniversity, 1969.Hedrick, C. Learning production systems from examples.Artificial Intelligence, 1976, 7, 21.49.Horning, J. J.
A study of grammatical inference.
TechnicalReport No.
CS 139, Computer Science Department, StanfordUniversity, 1969.Kelley, K. L. Early syntactic acquisition.
Rand Report P-3719,1967.Klein, S. Automatic inference of semantic deep structure rules ingenerative semantic grammars.
Technical Report No.
180,Computer Sciences Department, University Of Wisconsin,1973.Langley, P. A general theory of discrimination learning.
Toappear in Klahr, D., Langley, P., and Neches, R. T.
(eds.
)Self.Modifying Production System Mooels of Learning andDevelopment, 1982.Langley, P. and Neches, R. T. PRISM User's Manual.
TechnicalReport, Department of Computer Science, Carnegie-MellonUniversity, 1981.Reeker, L. H. The computational study of language acquisition.In M. Yovits and M. Rubinoff (eds.
), Advances in Computers,Volume 15.
New York: Academic Press, 1976.Selfridge, M. A computer model of child language acquisition.Proceedings of the Seventh International Joint Conferenceon Artificial Intelligence, 1981,92-96.Sembugamoorthy, V. PLAS, a paradigmatic languageacquisition system: An overview.
Proceedings of the SixthInternational Joint Conference on Artificial Intelligence, 1979,788-790.Siklossy, L. Natural language learning by computer.
In H. A.Simon and L. Siklossy (eds.
), Representation and Meaning:Experiments with Information Processing Systems.Englewood Cliffs, N. J.: Prentice.Hall, 1972.Solomonoff, R. A new method for discovering the grammars ofphrase structure languages.
Proceedings of the InternationalConference on Information Processing, UNESCO, 1959.Waterman, D.A.
Adaptive production systems.
Proceedings ofthe Fourth International Joint Conference on ArtificialIntelligence, 1975, 296-303.Winston, P. H. Learning structural descriptions from examples.MIT AI-TR-231, 1970.Wolff, J. G. Language acquisition and the discovery of phrasestructure.
Language and Speech, 1980, 23,255-269.151
