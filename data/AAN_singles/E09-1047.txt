Proceedings of the 12th Conference of the European Chapter of the ACL, pages 406?414,Athens, Greece, 30 March ?
3 April 2009. c?2009 Association for Computational LinguisticsParsing CoordinationsSandra Ku?blerIndiana Universityskuebler@indiana.eduErhard HinrichsUniversita?t Tu?bingeneh@sfs.uni-tuebingen.deWolfgang MaierUnversita?t Tu?bingenwo.maier@uni-tuebingen.deEva KlettUniversita?t Tu?bingeneklett@sfs.uni-tuebingen.deAbstractThe present paper is concerned with sta-tistical parsing of constituent structuresin German.
The paper presents four ex-periments that aim at improving parsingperformance of coordinate structure: 1)reranking the n-best parses of a PCFGparser, 2) enriching the input to a PCFGparser by gold scopes for any conjunct, 3)reranking the parser output for all possi-ble scopes for conjuncts that are permissi-ble with regard to clause structure.
Exper-iment 4 reranks a combination of parsesfrom experiments 1 and 3.The experiments presented show that n-best parsing combined with reranking im-proves results by a large margin.
Provid-ing the parser with different scope possi-bilities and reranking the resulting parsesresults in an increase in F-score from69.76 for the baseline to 74.69.
While theF-score is similar to the one of the first ex-periment (n-best parsing and reranking),the first experiment results in higher re-call (75.48% vs. 73.69%) and the third onein higher precision (75.43% vs. 73.26%).Combining the two methods results in thebest result with an F-score of 76.69.1 IntroductionThe present paper is concerned with statisticalparsing of constituent structures in German.
Ger-man is a language with relatively flexible phrasalordering, especially of verbal complements andadjuncts.
This makes processing complex casesof coordination particularly challenging and error-prone.
The paper presents four experiments thataim at improving parsing performance of coor-dinate structures: the first experiment involvesreranking of n-best parses produced by a PCFGparser, the second experiment enriches the inputto a PCFG parser by offering gold pre-bracketingsfor any coordinate structures that occur in the sen-tence.
In the third experiment, the reranker isgiven all possible pre-bracketed candidate struc-tures for coordinated constituents that are permis-sible with regard to clause macro- and microstruc-ture.
The parsed candidates are then reranked.The final experiment combines the parses from thefirst and the third experiment and reranks them.Improvements in this final experiment corroborateour hypothesis that forcing the parser to work withpre-bracketed conjuncts provides parsing alterna-tives that are not present in the n-best parses.Coordinate structures have been a central is-sue in both computational and theoretical linguis-tics for quite some time.
Coordination is one ofthose phenomena where the simple cases can beaccounted for by straightforward empirical gen-eralizations and computational techniques.
Morespecifically, it is the observation that coordinationinvolves two or more constituents of the same cat-egories.
However, there are a significant numberof more complex cases of coordination that defythis generalization and that make the parsing taskof detecting the right scope of individual conjunctsand correctly delineating the correct scope of thecoordinate structure as a whole difficult.
(1) showssome classical examples of this kind from English.
(1) a. Sandy is a Republican and proud of it.b.
Bob voted, but Sandy did not.c.
Bob supports him and Sandy me.In (1a), unlike categories (NP and adjective) areconjoined.
(1b) and (1c) are instances of ellipsis(VP ellipsis and gapping).
Yet another difficult setof examples present cases of non-constituent con-junction, as in (2), where the direct and indirectobject of a ditransitive verb are conjoined.
(2) Bob gave a book to Sam and a record to Jo.4062 Coordination in GermanThe above phenomena have direct analogues inGerman.1 Due to the flexible ordering of phrases,their variability is even higher.
For example, dueto constituent fronting to clause-initial position inGerman verb-second main clauses, cases of non-constituent conjunction can involve any two NPs(including the subject) of a ditransitive verb to theexclusion of the third NP complement that appearsin clause-initial position.
In addition, German ex-hibits cases of asymmetric coordination first dis-cussed by Ho?hle (1983; 1990; 1991) and illus-trated in (3).2(3) InIntodentheWaldwoodsgingwenteinaJa?gerhunterundandschossshoteinenaHasen.hare.Such cases of subject gap coordination are fre-quently found in text corpora (cf.
(4) below) andinvolve conjunction of a full verb-second clausewith a VP whose subject is identical to the subjectin the first conjunct.3 Experimental Setup and Baseline3.1 The TreebankThe data source used for the experiments is theTu?bingen Treebank of Written German (Tu?Ba-D/Z) (Telljohann et al, 2005).
Tu?Ba-D/Z usesthe newspaper ?die tageszeitung?
(taz) as its datasource, version 3 comprises approximately 27 000sentences.
The treebank annotation scheme dis-tinguishes four levels of syntactic constituency:the lexical level, the phrasal level, the level oftopological fields, and the clausal level.
The pri-mary ordering principle of a clause is the inventoryof topological fields (VF, LK, MF, VC, and NF),which characterize the word order regularitiesamong different clause types of German.
Tu?Ba-D/Z annotation relies on a context-free backbone(i.e.
proper trees without crossing branches) ofphrase structure combined with edge labels thatspecify the grammatical function of the phrase inquestion.
Conjuncts are generally marked with the1To avoid having to gloss German examples, they wereillustrated for English.2Yet, another case of such asymmetric coordination dis-cussed by Ho?hle involves cases of conjunction of differentclause types: [V?final Wenn du nach Hause kommst ] und[V?2nd da warten Polizeibeamte vor der Tu?r.
?If you comehome and there are policemen waiting in front of the door ] .
?function label KONJ.
Figure 1 shows the anno-tation that sentence (4) received in the treebank.Syntactic categories are displayed as nodes, gram-matical functions as edge labels in gray (e.g.
OA:direct object, PRED: predicate).
This is an exam-ple of a subject-gap coordination, in which bothconjuncts (FKONJ) share the subject (ON) that isrealized in the first conjunct.
(4) DamitSohathassichitselfdertheBevo?lkerungs-decline inru?ckgangpopulationzwarthoughabgeschwa?cht,lessened,istisaberhowevernochstilldoppeltdoublesosogro?bigwieas1996.1996.
?For this reason, although the decline inpopulation has lessened, it is still twice asbig as in 1996.?The syntactic annotation scheme of the Tu?Ba-D/Z is described in more detail in Telljohann et al(2004; 2005).All experiments reported here are based on adata split of 90% training data and 10% test data.3.2 The Parsers and the RerankerTwo parsers were used to investigate the influ-ence of scope information on parser performanceon coordinate structures: BitPar (Schmid, 2004)and LoPar (Schmid, 2000).
BitPar is an effi-cient implementation of an Earley style parser thatuses bit vectors.
However, BitPar cannot han-dle pre-bracketed input.
For this reason, we usedLoPar for the experiments where such input wasrequired.
LoPar, as it is used here, is a purePCFG parser, which allows the input to be par-tially bracketed.
We are aware that the resultsthat can be obtained by pure PCFG parsers arenot state of the art as reported in the shared taskof the ACL 2008 Workshop on Parsing German(Ku?bler, 2008).
While BitPar reaches an F-scoreof 69.76 (see next section), the best performingparser (Petrov and Klein, 2008) reaches an F-score of 83.97 on Tu?Ba-D/Z (but with a differentsplit of training and test data).
However, our ex-periments require certain features in the parsers,namely the capability to provide n-best analysesand to parse pre-bracketed input.
To our knowl-edge, the parsers that took part in the shared taskdo not provide these features.
Should they becomeavailable, the methods presented here could be ap-plied to such parsers.
We see no reason why our407Figure 1: A tree with coordination.methods should not be able to improve the resultsof these parsers further.Since we are interested in parsing coordina-tions, all experiments are conducted with goldPOS tags, so as to abstract away from POS tag-ging errors.
Although the treebank contains mor-phological information, this type of information isnot used in the experiments presented here.The reranking experiments were conducted us-ing the reranker by Collins and Koo (2005).
Thisreranker uses a set of candidate parses for a sen-tence and reranks them based on a set of featuresthat are extracted from the trees.
The reranker usesa boosting method based on the approach by Fre-und et al (1998).
We used a similar feature setto the one Collins and Koo used; the followingtypes of features were included: rules, bigrams,grandparent rules, grandparent bigrams, lexicalbigrams, two-level rules, two-level bigrams, tri-grams, head-modifiers, PPs, and distance for head-modifier relations, as well as all feature types in-volving rules extended by closed class lexicaliza-tion.
For a more detailed description of the rules,the interested reader is referred to Collins andKoo (2005).
For coordination, these features givea wider context than the original parser has andshould thus result in improvements for this phe-nomenon.3.3 The BaselineWhen trained on 90% of the approximately 27,000sentences of the Tu?Ba-D/Z treebank, BitParreaches an F-Score of 69.73 (precision: 68.63%,recall: 70.93%) on the full test set of 2611 sen-tences.
These results as well as all further re-sults presented here are labeled results, includinggrammatical functions.
Since German has a rela-tively free word order, it is impossible to deducethe grammatical function of a noun phrase fromthe configuration of the sentence.
Consequently,an evaluation based solely on syntactic constituentlabels would be meaningless (cf.
(Ku?bler, 2008)for a discussion of this point).
The inclusion ofgrammatical labels in the trees, makes the parsingprocess significantly more complex.Looking at sentences with coordination (i.e.sentences that contain a conjunction which is notin sentence-initial position), we find that 34.9%of the 2611 test sentences contain coordinations.An evaluation of only sentences with coordina-tion shows that there is a noticeable difference: theF-score reaches 67.28 (precision: 66.36%, recall:68.23%) as compared to 69.73 for the full test set.The example of a wrong parse shown below il-lustrates why parsing of complex coordinations isso hard.
Complex coordinations can take up a con-siderable part of the input string and accordinglyof the overall sentence structure.
Such global phe-nomena are particularly hard for pure PCFG pars-ing, due to the independence assumption inherentin the statistical models for PCFGs.Sentence (4) has the following Viterbi parse:(VROOT(SIMPX(VF(SIMPX-OS(VF (PX-MOD (PROP-HD Damit)))(LK(VXFIN-HD (VAFIN-HD hat)))(MF408(NX-OA (PRF-HD sich))(NX-ON (ART der)(NN-HD Bevo?lkerungsru?ckgang))(ADVX-MOD (ADV-HD zwar)))(VC (VXINF-OV(VVPP-HD abgeschwa?cht)))))($, ,)(LK(VXFIN-HD (VAFIN-HD ist)))(MF(ADVX-MOD (ADV-HD aber))(ADVX-MOD (ADV-HD noch))(ADJX-PRED(ADJX-HD (ADVX (ADV-HD mehr))(ADJX (KOKOM als)(ADJD-HD doppelt))(ADVX (ADV-HD so))(ADJD-HD gro?
))(NX (KOKOM wie)(CARD-HD 1996)))))($.
.
))The parse shows that the parser did notrecognize the coordination.
Instead, the first con-junct including the fronted constituent, Damithat sich der Bevo?lkerungsru?ckgangzwar abgeschwa?cht, is treated as a frontedsubordinate clause.4 Experiment 1: n-Best Parsing andRerankingThe first hypothesis for improving coordinationparsing is based on the assumption that the correctparse may not be the most probable one in Viterbiparsing but may be recovered by n-best parsingand reranking, a technique that has become stan-dard in the last few years.
If this hypothesis holds,we should find the correct parse among the n-bestparses.
In order to test this hypothesis, we con-ducted an experiment with BitPar (Schmid, 2004).We parsed the test sentences in a 50-best setting.A closer look at the 50-best parses shows that ofthe 2611 sentences, 195 (7.5%) were assigned thecorrect parse as the best parse.
For 325 more sen-tences (12.4%), the correct parse could be foundunder the 50 best analyses.
What is more, in90.2% of these 520 sentences, for which the cor-rect parse was among the 50 best parses, the bestparse was among the first 10 parses.
Additionally,only in 4 cases were the correct analyses amongthe 40-best to 50-best parses, an indication that in-creasing n may not result in improving the resultssignificantly.
These findings resulted in the deci-sion not to conduct experiments with higher n.That the 50 best analyses contain valuable infor-mation can be seen from an evaluation in which anoracle chooses from the 50 parses.
In this case, wereach an F-score of 80.28.
However, this F-scoreis also the upper limit for improvement that can beachieved by reranking the 50-best parses.For reranking, the features of Collins andKoo (2005) were extended in the following way:Since the German treebank used for our exper-iments includes grammatical function informa-tion on almost all levels in the tree, all featuretypes were also included with grammatical func-tions attached: All nodes except the root nodeof the subtree in question were annotated withtheir grammatical information.
Thus, for the nounphrase (NX) rule with grandparent prepositionalphrase (PX) PXGP NX?
ART ADJX NN, we addan additional rule PXGP NX-HD ?
ART ADJXNN-HD.After pruning all features that occurred in thetraining data with a frequency lower than 5, the ex-tractions produced more than 5 mio.
different fea-tures.
The reranker was optimized on the trainingdata, the 50-best parses were produced in a 5-foldcross-validation setting.
A non-exhaustive searchfor the best value for the ?
parameter showed thatCollins and Koo?s value of 0.0025 produced thebest results.
The row for exp.
1 in Table 1 showsthe results of this experiment.
The evaluation ofthe full data set shows an improvement of 4.77points in the F-score, which reached 74.53.
This isa relative reduction in error rate of 18.73%, whichis slightly higher that the error rate reduction re-ported by Collins and Koo for the Penn Treebank(13%).
However, the results for Collins and Koo?soriginal parses were higher, and they did not eval-uate on grammatical functions.The evaluation of coordination sentences showsthat such sentences profit from reranking to thesame degree.
These results prove that while coor-dination structures profit from reranking, they donot profit more than other phenomena.
We thusconclude that reranking is no cure-all for solvingthe problem of accurate coordination parsing.5 Experiment 2: Gold ScopeThe results of experiment 1 lead to the conclusionthat reranking the n-best parses can only resultin restricted improvements on coordinations.
Thefact that the correct parse often cannot be foundin the 50-best analyses suggests that the differentpossible scopes of a coordination are so differentin their probability distribution that not all of thepossible scopes are present in the 50-best analyses.409all sentences coord.
sentencesprecision recall F-score precision recall F-scorebaseline: 68.63 70.93 69.76 66.36 68.23 67.28exp.
1: 50-best reranking: 73.26 75.84 74.53 70.67 72.72 71.68exp.
2: with gold scope: 76.12 72.87 74.46 75.78 72.22 73.96exp.
3: automatic scope: 75.43 73.96 74.69 72.88 71.42 72.14exp.
4: comb.
1 and 3: 76.15 77.23 76.69 73.79 74.73 74.26Table 1: The results of parsing all sentences and coordinated sentences onlyIf this hypothesis holds, forcing the parser to con-sider the different scope readings should increasethe accuracy of coordination parsing.
In order toforce the parser to use the different scope readings,we first extract these scope readings, and then foreach of these scope readings generate a new sen-tence with partial bracketing that represents thecorresponding scope (see below for an example).LoPar is equipped to parse partially-bracketed in-put.
Given input sentences with partial brackets,the parser restricts analyses to such cases that donot contradict the brackets in the input.
(5) WasWhichstimmt,is correct,weilbecausesietheyunterhaltsamentertainingsind,are,aberbutauchalsofalschewrongAssoziationenassociationsweckt.wakes.
?Which is correct because they are enter-taining, but also triggers wrong associa-tions.
?In order to test the validity of this hypothe-sis, we conducted an experiment with coordinationscopes extracted from the treebank trees.
Thesescopes were translated into partial brackets thatwere included in the input sentences.
For the sen-tence in (5) from the treebank (sic), the input forLoPar would be the following:Was/PWS stimmt/VVFIN ,/$, weil/KOUS ( sie/PPER unterhalt-sam/ADJD sind/VAFIN ) ,/$,aber/KON ( auch/ADV falsche/ADJAAssoziationen/NN weckt/VVFIN )The round parentheses delineate the conjuncts.LoPar was then forced to parse sentences contain-ing coordination with the correct scope for the co-ordination.
The results for this experiment areshown in Table 1 as exp.
2.The introduction of partial brackets that delimitthe scope of the coordination improve overall re-sults on the full test set by 4.7 percent points, arather significant improvement when we considerthat only approximately one third of the test sen-tences were modified.
The evaluation of the setof sentences that contain coordination shows thathere, the difference is even higher: 6.7 percentpoints.
It is also worth noticing that provided withscope information, the parser parses such sen-tences with the same accuracy as other sentences.The difference in F-scores between all sentencesand only sentences with coordination in this ex-periment is much lower (0.5 percent points) thanfor all other experiments (2.5?3.0 percent points).When comparing the results of experiment 1 (n-best parsing) with the present one, it is evident thatthe F-scores are very similar: 74.53 for the 50-bestreranking setting, and 74.46 for the one where weprovided the gold scope.
However, a comparisonof precision and recall shows that there are differ-ences: 50-best reranking results in higher recall,providing gold scope for coordinations in higherprecision.
The lower recall in the latter experimentindicates that the provided brackets in some casesare not covered by the grammar.
This is corrob-orated by the fact that in n-best parsing, only 1sentence could not be parsed; but in parsing withgold scope, 8 sentences could not be parsed.6 Experiment 3: Extracting ScopeThe previous experiment has shown that providingthe scope of a coordination drastically improvesresults for sentences with coordination as well asfor the complete test set (although to a lower de-gree).
The question that remains to be answered iswhether automatically generated possible scopescan provide enough information for the rerankerto improve results.The first question that needs to be answered ishow to find the possible scopes for a coordina-tion.
One possibility is to access the parse forestof a chart parser such as LoPar and extract infor-410mation about all the possible scope analyses thatthe parser found.
If the same parser is used forthis step and for the final parse, we can be cer-tain that only scopes are extracted that are com-patible with the grammar of the final parser.
How-ever, parse forests are generally stored in a highlypacked format so that an exhaustive search of thestructures is very inefficient and proved impossi-ble with present day computing power.
(6) ?Es?TheregibtarezwarindeedeinapaarfewNiederflurbusse,low-floor buses,aberbutdasthatreichtsufficesjapart.nicht?,not?,sagtsayser.he.?
?There are indeed a few low-floor buses,but that isn?t enough?, he says.Another solution consists of generating all pos-sible scopes around the coordination.
Thus, forthe sentence in (6), the conjunction is aber.
Theshortest possible left conjunct is Niederflurbusse,the next one paar Niederflurbusse, etc.
Clearly,many of these possibilities, such as the last exam-ple, are nonsensical, especially when the proposedconjunct crosses into or out of base phrase bound-aries.
Another type of boundary that should notbe crossed is a clause boundary.
Since the con-junction is part of the subordinated clause in thepresent example, the right conjunct cannot extendbeyond the end of the clause, i.e.
beyond nicht.For this reason, we used KaRoPars (Mu?ller andUle, 2002), a partial parser for German, to parsethe sentences.
From the partial parses, we ex-tracted base phrases and clauses.
For (6), the rel-evant bracketing provided by KaRoPars is the fol-lowing:( " Es gibt zwar { ein paarNiederflurbusse } , ) aber ( dasreicht ja nicht ) " , sagt er .The round parentheses mark clause boundaries,the curly braces the one base phrase that is longerthan one word.
In the creation of possible con-juncts, only such conjuncts are listed that do notcross base phrase or clause boundaries.
In order toavoid unreasonably high numbers of pre-bracketedversions, we also use higher level phrases, such ascoordinated noun phrases.
KaRoPars groups suchhigher level phrases only in contexts that allowa reliable decision.
While a small percentage ofsuch decisions is wrong, the heuristic used turnsout to be reliable and efficient.For each scope, a partially bracketed versionof the input sentence is created, in which onlythe brackets for the suggested conjuncts are in-serted.
Each pre-bracketed version of the sentenceis parsed with LoPar.
Then all versions for onesentence are reranked.
The reranker was trainedon the data from experiment 1 (n-best parsing).The results of the reranker show that our restric-tions based on the partial parser may have beentoo restrictive.
Only 375 sentences had more thanone pre-bracketed version, and only 328 sentenceresulted in more than one parse.
Only the latter setcould then profit from reranking.The results of this experiment are shown in Ta-ble 1 as exp.
3.
They show that extracting pos-sible scopes for conjuncts from a partial parseis possible.
The difference in F-score betweenthis experiment and the baseline reaches 5.93 per-cent points.
The F-score is also minimally higherthan the F-score for experiment 2 (gold scope),and recall is increased by approximately 1 per-cent point (even though only 12.5% of the sen-tences were reranked).
This can be attributed totwo factors: First, we provide different scope pos-sibilities.
This means that if the correct scope isnot covered by the grammar, the parser may stillbe able to parse the next closest possibility in-stead of failing completely.
Second, reranking isnot specifically geared towards improving coordi-nated structures.
Thus, it is possible that a parse isreranked higher because of some other feature.
Itis, however, not the case that the improvement re-sults completely from reranking.
This can be de-duced from two points: First, while the F-scorefor experiment 1 (50-best analyses plus reranking)and the present experiment are very close (74.53vs.
74.69), there are again differences in precisionand recall: In experiment 1, recall is higher, and inthe present experiment precision.
Second, a lookat the evaluation on only sentences with coordi-nation shows that the F-score for the present ex-periment is higher than the one for experiment 1(72.14 vs. 71.68).
Additionally, precision for thepresent experiment is more than 2 percent pointshigher.7 Experiment 4: Combining n-BestParses and Extracted Scope ParsesAs described above, the results for reranking the50-best analyses and for reranking the versions411with automatically extracted scope readings arevery close.
This raises the question whether thetwo methods produce similar improvements in theparse trees.
One indicator that this is not the casecan be found in the differences in precision and re-call.
Another possibility of verifying our assump-tion that the improvements do not overlap lies inthe combination of the 50-best parses with theparses resulting from the automatically extractedscopes.
This increases the number of parses be-tween which the reranker can choose.
In effect,this means a combination of the methods of exper-iments 1 (n-best) and 3 (automatic scope).
Con-sequently, if the results from this experiment arevery close to the results from experiment 1 (n-best), we can conclude that adding the parses withautomatic scope readings does not add new infor-mation.
If, however, adding these parses improvesresults, we can conclude that new information waspresent in the parses with automatic scope thatwas not covered in the 50-best parses.
Note thatthe combination of the two types of input for thereranker should not be regarded as a parser ensem-ble but rather as a resampling of the n-best searchspace since both parsers use the same grammar,parsing model, and probability model.
The onlydifference is that LoPar can accept partially brack-eted input, and BitPar can list the n-best analyses.The results of this experiment are shown in Ta-ble 1 as exp.
4.
For all sentences, both precisionand recall are higher than for experiment 1 and 3,resulting in an F-score of 76.69.
This is more than2 percent points higher than for the 50-best parses.This is a very clear indication that the parses con-tributed by the automatically extracted scopes pro-vide parses that were not present in the 50 bestparses from experiment 1 (n-best).
The same trendcan be seen in the evaluation of the sentences con-taining coordination: Here, the improvement in F-score is higher than for the whole set, a clear in-dication that this method is suitable for improvingcoordination parsing.
A comparison of the resultsof the present experiment and experiment 3 (withautomatic scope only) shows that the gain in pre-cision is rather small, but the combination clearlyimproves recall, from 73.96% to 77.23%.
We canconclude that adding the 50 best parses remediesthe lacking coverage that was the problem of ex-periment 3.
More generally, experiment 4 suggeststhat for the notoriously difficult problem of pars-ing coordination structures, a hybrid approach thatcombines parse selection of n best analyses withpre-bracketed scope in the input results in a con-siderable reduction in error rate compared to eachof these methods used in isolation.8 Related WorkParsing of coordinate structures for English hasreceived considerable attention in computationallinguistics.
Collins (1999), among many other au-thors, reports in the error analysis of his WSJ pars-ing results that coordination is one of the most fre-quent cases of incorrect parses, particularly if theconjuncts involved are complex.
He manages toreduce errors for simple cases of NP coordinationby introducing a special phrasal category of baseNPs.
In the experiments presented above, no ex-plicit distinction is made between simple and com-plex cases of coordination, and no transformationsare performed on the treebank annotations used fortraining.Our experiment 1, reranking 50-best parses, issimilar to the approaches of Charniak and John-son (2005) and of Hogan (2007).
However, it dif-fers from their experiments in two crucial ways: 1)Compared to Charniak and Johnson, who use 1.1mio.
features, our feature set is appr.
five timeslarger (more than 5 mio.
features), with the samethreshold of at least five occurrences in the trainingset.
2) Both Hogan and Charniak and Johnson usespecial features for coordinate structures, such as aBoolean feature for marking parallelism (Charniakand Johnson) or for distinguishing between coor-dination of base NPs and coordination of complexconjuncts (Hogan), while our approach refrainsfrom such special-purpose features.Our experiments using scope information aresimilar to the approaches of Kurohashi and Na-gao (1994) and Agarwal and Bogges (1992) in thatthey try to identify coordinate structure bracket-ings.
However, the techniques used by Agarwaland Bogges and in the present paper are quite dif-ferent.
Agarwal and Bogges and Kurohashi andNagao rely on shallow parsing techniques to de-tect parallelism of conjuncts while we use a par-tial parser only for suggesting possible scopes ofconjuncts.
Both of these approaches are limitedto coordinate structures with two conjuncts only,while our approach has no such limitation.
More-over, the goal of Agarwal and Bogges is quite dif-ferent from ours.
Their goal is robust detection ofcoordinate structures only (with the intended ap-412plication of term extraction), while our goal is toimprove the performance of a parser that assigns acomplete sentence structure to an input sentence.Finally, our approach at present is restricted topurely syntactic structural properties.
This is incontrast to approaches that incorporate semanticinformation.
Hogan (2007) uses bi-lexical head-head co-occurrences in order to identify nominalheads of conjuncts more reliably than by syntacticinformation alone.
Chantree et al (2005) resolveattachment ambiguities in coordinate structures, asin (7a) and (7b), by using word frequency informa-tion obtained from generic corpora as an effectiveestimate of the semantic compatibility of a modi-fier vis-a`-vis the candidate heads.
(7) a.
Project managers and designersb.
Old shoes and bootsWe view the work by Hogan and by Chantreeet al as largely complementary to, but at the sametime as quite compatible with our approach.
Wemust leave the integration of structural syntac-tic and lexical semantic information to future re-search.9 Conclusion and Future WorkWe have presented a study on improving the treat-ment of coordinated structures in PCFG parsing.While we presented experiments for German, themethods are applicable for any language.
We havechosen German because it is a language with rel-atively flexible phrasal ordering (cf.
Section 2)which makes parsing coordinations particularlychallenging.
The experiments presented show thatn-best parsing combined with reranking improvesresults by a large margin.
However, the numberof cases in which the correct parse is present inthe n-best parses is rather low.
This led us to theassumption that the n-best analyses often do notcover the whole range of different scope possibil-ities but rather present minor variations of parseswith few differences in coordination scope.
Theexperiments in which the parser was forced to as-sume predefined scopes show that the scope infor-mation is important for parsing quality.
Provid-ing the parser with different scope possibilities andreranking the resulting parses results in an increasein F-score from 69.76 for the baseline to 74.69.One of the major challenges for this approach liesin extracting a list of possible conjuncts.
Forc-ing the parser to parse all possible sequences re-sults in a prohibitively large number of possibili-ties, especially for sentences with 3 or more con-junctions.
For this reason, we used chunks abovebase phases, such as coordinated noun chunks, torestrict the space.
However, an inspection of thelists of bracketed versions of the sentences showsthat the definition of base phrases is one of the ar-eas that must be refined.
As mentioned above, thepartial parser groups sequences of ?NP KON NP?into a single base phrase.
This may be correct inmany cases, but there are exceptions such as (8).
(8) DieThe31ja?hrige31-year-oldGewerkschaftsmitarbei-union staff memberterin undandausgebildetetrainedIndustriekauffrauindustrial clerkausfromOldenburgOldenburgbereitetis preparingnunnowihrehererstefirsteigeneownCDCDvor.part..For (8), the partial parser groups Die 31ja?hrigeGewerkschaftsmitarbeiterin und ausgebildete In-dustriekauffrau as one noun chunk.
Since ourproposed conjuncts cannot cross these boundaries,the correct second conjunct, ausgebildete Indus-triekauffrau aus Oldenburg, cannot be suggested.However, if we remove these chunk boundaries,the number of possible conjuncts increases dra-matically, and parsing times become prohibitive.As a consequence, we will need to find a good bal-ance between these two needs.
Our plan is to in-crease flexibility very selectively, for example byenabling the use of wider scopes in cases wherethe conjunction is preceded and followed by basenoun phrases.
For the future, we are planning torepeat experiment 3 (automatic scope) with differ-ent phrasal boundaries extracted from the partialparser.
It will be interesting to see if improvementsin this experiment will still improve results in ex-periment 4 (combining 50-best parses with exp.
3).Another area of improvement is the list of fea-tures used for reranking.
At present, we use a fea-ture set that is similar to the one used by Collinsand Koo (2005).
However, this feature set doesnot contain any coordination specific features.
Weare planning to extend the feature set by featureson structural parallelism as well as on lexical sim-ilarity of the conjunct heads.413ReferencesRajeev Agarwal and Lois Boggess.
1992.
A simple butuseful approach to conjunct identification.
In Pro-ceedings of the 30th Annual Meeting of the Associa-tion for Computational Linguistics (ACL-92), pages15?21, Newark, DE.Francis Chantree, Adam Kilgarriff, Anne de Roeck,and Alistair Willis.
2005.
Disambiguating coordi-nations using word distribution information.
In Pro-ceedings of Recent Advances in NLP (RANLP 2005),pages 144?151, Borovets, Bulgaria.Eugene Charniak and Mark Johnson.
2005.
Coarse-to-fine n-best parsing and MaxEnt discriminativereranking.
In Proceedings of the 43rd Annual Meet-ing of the Association for Computational Linguistics(ACL?05), pages 173?180, Ann Arbor, MI.Michael Collins and Terry Koo.
2005.
Discriminativereranking for natural language parsing.
Computa-tional Linguistics, 31(1):25?69.Michael Collins.
1999.
Head-Driven Statistical Mod-els for Natural Language Parsing.
Ph.D. thesis,University of Pennsylvania.Anette Frank.
2002.
A (discourse) functional analysisof asymmetric coordination.
In Proceedings of theLFG-02 Conference, Athens, Greece.Yoav Freund, Ray Iyer, Robert Shapire, and YoramSinger.
1998.
An efficient boosting algorithmfor combining preferences.
In Proceedings of the15th International Conference on Machine Learn-ing, Madison, WI.Deirdre Hogan.
2007.
Coordinate noun phrase disam-biguation in a generative parsing model.
In Proceed-ings of the 45th Annual Meeting of the Association ofComputational Linguistics, pages 680?687, Prague,Czech Republic.Tilman Ho?hle.
1983.
Subjektlu?cken in Koordinatio-nen.
Universita?t Tu?bingen.Tilman Ho?hle.
1990.
Assumptions about asymmetriccoordination in German.
In Joan Mascaro?
and Ma-rina Nespor, editors, Grammar in Progress.
GlowEssays for Henk van Riemsdijk, pages 221?235.Foris, Dordrecht.Tilman Ho?hle.
1991.
On reconstruction and coor-dination.
In Hubert Haider and Klaus Netter, ed-itors, Representation and Derivation in the The-ory of Grammar, volume 22 of Studies in NaturalLanguage and Linguistic Theory, pages 139?197.Kluwer, Dordrecht.Andreas Kathol.
1990.
Linearization vs. phrase struc-ture in German coordination constructions.
Cogni-tive Linguistics, 10(4):303?342.Sandra Ku?bler.
2008.
The PaGe 2008 shared task onparsing German.
In Proceedings of the ACL Work-shop on Parsing German, pages 55?63, Columbus,Ohio.Sadao Kurohashi and Makoto Nagao.
1994.
A syn-tactic analysis method of long Japanese sentencesbased on the detection of conjunctive structures.Computational Linguistics, 20(4):507?534.Frank Henrik Mu?ller and Tylman Ule.
2002.
Annotat-ing topological fields and chunks?and revising POStags at the same time.
In Proceedings of the 19th In-ternational Conference on Computational Linguis-tics, COLING?02, pages 695?701, Taipei, Taiwan.Slav Petrov and Dan Klein.
2008.
Parsing Germanwith latent variable grammars.
In Proceedings ofthe ACL Workshop on Parsing German, pages 33?39, Columbus, Ohio.Helmut Schmid.
2000.
LoPar: Design and implemen-tation.
Technical report, Universita?t Stuttgart.Helmut Schmid.
2004.
Efficient parsing of highlyambiguous context-free grammars with bit vectors.In Proceedings of the 20th International Confer-ence on Computational Linguistics (COLING 2004),Geneva, Switzerland.Heike Telljohann, Erhard Hinrichs, and Sandra Ku?bler.2004.
The Tu?Ba-D/Z treebank: Annotating Germanwith a context-free backbone.
In Proceedings of theFourth International Conference on Language Re-sources and Evaluation (LREC 2004), pages 2229?2235, Lisbon, Portugal.Heike Telljohann, Erhard W. Hinrichs, Sandra Ku?bler,and Heike Zinsmeister, 2005.
Stylebook for theTu?bingen Treebank of Written German (Tu?Ba-D/Z).
Seminar fu?r Sprachwissenschaft, Universita?tTu?bingen, Tu?bingen, Germany.Dieter Wunderlich.
1988.
Some problems of coor-dination in German.
In Uwe Reyle and ChristianRohrer, editors, Natural Language Parsing and Lin-guistic Theories, Studies in Linguistics and Philoso-phy, pages 289?316.
Reidel, Dordrecht.414
