Proceedings of the Joint Workshop on Social Dynamics and Personal Attributes in Social Media, pages 42?49,Baltimore, Maryland USA, 27 June 2014.c?2014 Association for Computational LinguisticsSelf-disclosure topic model for Twitter conversationsJinYeong BakDepartment of Computer ScienceKAISTDaejeon, South Koreajy.bak@kaist.ac.krChin-Yew LinMicrosoft Research AsiaBeijing 100080, P.R.
Chinacyl@microsoft.comAlice OhDepartment of Computer ScienceKAISTDaejeon, South Koreaalice.oh@kaist.eduAbstractSelf-disclosure, the act of revealing one-self to others, is an important social be-havior that contributes positively to inti-macy and social support from others.
Itis a natural behavior, and social scien-tists have carried out numerous quantita-tive analyses of it through manual taggingand survey questionnaires.
Recently, theflood of data from online social networks(OSN) offers a practical way to observeand analyze self-disclosure behavior at anunprecedented scale.
The challenge withsuch analysis is that OSN data come withno annotations, and it would be impos-sible to manually annotate the data for aquantitative analysis of self-disclosure.
Asa solution, we propose a semi-supervisedmachine learning approach, using a vari-ant of latent Dirichlet allocation for au-tomatically classifying self-disclosure in amassive dataset of Twitter conversations.For measuring the accuracy of our model,we manually annotate a small subset ofour dataset, and we show that our modelshows significantly higher accuracy andF-measure than various other methods.With the results our model, we uncovera positive and significant relationship be-tween self-disclosure and online conversa-tion frequency over time.1 IntroductionSelf-disclosure is an important and pervasive so-cial behavior.
People disclose personal informa-tion about themselves to improve and maintainrelationships (Jourard, 1971; Joinson and Paine,2007).
For example, when two people meet forthe first time, they disclose their names and in-terests.
One positive outcome of self-disclosureis social support from others (Wills, 1985; Der-lega et al., 1993), shown also in online social net-works (OSN) such as Twitter (Kim et al., 2012).Receiving social support would then lead the userto be more active on OSN (Steinfield et al., 2008;Trepte and Reinecke, 2013).
In this paper, we seekto understand this important social behavior usinga large-scale Twitter conversation data, automati-cally classifying the level of self-disclosure usingmachine learning and correlating the patterns withsubsequent OSN usage.Twitter conversation data, explained in more de-tail in section 4.1, enable a significantly largerscale study of naturally-occurring self-disclosurebehavior, compared to traditional social sciencestudies.
One challenge of such large scale study,though, remains in the lack of labeled ground-truth data of self-disclosure level.
That is,naturally-occurring Twitter conversations do notcome tagged with the level of self-disclosure ineach conversation.
To overcome that challenge,we propose a semi-supervised machine learningapproach using probabilistic topic modeling.
Ourself-disclosure topic model (SDTM) assumes thatself-disclosure behavior can be modeled using acombination of simple linguistic features (e.g.,pronouns) with automatically discovered seman-tic themes (i.e., topics).
For instance, an utterance?I am finally through with this disastrous relation-ship?
uses a first-person pronoun and contains atopic about personal relationships.In comparison with various other models,SDTM shows the highest accuracy, and the result-ing self-disclosure patterns of the users are cor-related significantly with their future OSN usage.Our contributions to the research community in-clude the following:?
We present a topic model that explicitly in-cludes the level of self-disclosure in a conver-sation using linguistic features and the latentsemantic topics (Sec.
3).42?
We collect a large dataset of Twitter conver-sations over three years and annotate a smallsubset with self-disclosure level (Sec.
4).?
We compare the classification accuracy ofSDTM with other models and show that itperforms the best (Sec.
5).?
We correlate the self-disclosure patterns ofusers and their subsequent OSN usage toshow that there is a positive and significantrelationship (Sec.
6).2 BackgroundIn this section, we review literature on the relevantaspects of self-disclosure.Self-disclosure (SD) level: To quantitativelyanalyze self-disclosure, researchers categorizeself-disclosure language into three levels: G (gen-eral) for no disclosure, M for medium disclosure,and H for high disclosure (Vondracek and Von-dracek, 1971; Barak and Gluck-Ofri, 2007).
Ut-terances that contain general (non-sensitive) infor-mation about the self or someone close (e.g., afamily member) are categorized as M. Examplesare personal events, past history, or future plans.Utterances about age, occupation and hobbies arealso included.
Utterances that contain sensitive in-formation about the self or someone close are cat-egorized as H. Sensitive information includes per-sonal characteristics, problematic behaviors, phys-ical appearance and wishful ideas.
Generally,these are thoughts and information that one wouldgenerally keep as secrets to himself.
All otherutterances, those that do not contain informationabout the self or someone close are categorizedas G. Examples include gossip about celebrities orfactual discourse about current events.Classifying self-disclosure level: Prior workon quantitatively analyzing self-disclosure has re-lied on user surveys (Trepte and Reinecke, 2013;Ledbetter et al., 2011) or human annotation (Barakand Gluck-Ofri, 2007).
These methods consumemuch time and effort, so they are not suitable forlarge-scale studies.
In prior work closest to ours,Bak et al.
(2012) showed that a topic model canbe used to identify self-disclosure, but that workapplies a two-step process in which a basic topicmodel is first applied to find the topics, and thenthe topics are post-processed for binary classifica-tion of self-disclosure.
We improve upon this workby applying a single unified model of topics and??????CTN??????
3??????
3Figure 1: Graphical model of SDTMself-disclosure for high accuracy in classifying thethree levels of self-disclosure.Self-disclosure and online social network:According to social psychology, when someonediscloses about himself, he will receive social sup-port from those around him (Wills, 1985; Derlegaet al., 1993), and this pattern of self-disclosureand social support was verified for Twitter con-versation data (Kim et al., 2012).
Social supportis a major motivation for active usage of socialnetworks services (SNS), and there are findingsthat show self-disclosure on SNS has a positivelongitudinal effect on future SNS use (Trepte andReinecke, 2013; Ledbetter et al., 2011).
Whilethese previous studies focused on small, qualita-tive studies, we conduct a large-scale, machinelearning driven study to approach the question ofself-disclosure behavior and SNS use.3 Self-Disclosure Topic ModelThis section describes our model, the self-disclosure topic model (SDTM), for classifyingself-disclosure level and discovering topics foreach self-disclosure level.3.1 ModelWe make two important assumptions based on ourobservations of the data.
First, first-person pro-nouns (I, my, me) are good indicators for mediumlevel of self-disclosure.
For example, phrases suchas ?I live?
or ?My age is?
occur in utterances that re-veal personal information.
Second, there are top-ics that occur much more frequently at a particularSD level.
For instance, topics such as physicalappearance and mental health occur frequently atlevel H, whereas topics such as birthday and hob-bies occur frequently at level M.Figure 1 illustrates the graphical model ofSDTM and how these assumptions are embodied43Notation DescriptionG; M ; H {general; medium; high} SD levelC; T ; N Number of conversations; tweets;wordsKG;KM;KHNumber of topics for {G; M; H}c; ct Conversation; tweet in conversation cyctSD level of tweet ct, G or M/HrctSD level of tweet ct, M or HzctTopic of tweet ctwctnnthword in tweet ct?
Learned Maximum entropy parame-tersxctFirst-person pronouns features?ctDistribution over SD level of tweet ctpicSD level proportion of conversation c?Gc;?Mc;?HcTopic proportion of {G; M; H} in con-versation c?G;?M ;?H Word distribution of {G; M; H}?
; ?
Dirichlet prior for ?
; pi?G,?M ;?H Dirichlet prior for ?G;?M ;?HnclNumber of tweets assigned SD level lin conversation cnlckNumber of tweets assigned SD level land topic k in conversation cnlkvNumber of instances of word v as-signed SD level l and topic kmctkvNumber of instances of word v as-signed topic k in tweet ctTable 1: Summary of notations used in SDTM.in it.
The first assumption about the first-personpronouns is implemented by the observed variablexctand the parameters ?
from a maximum en-tropy classifier for G vs. M/H level.
The secondassumption is implemented by the three separateword-topic probability vectors for the three lev-els of SD: ?lwhich has a Bayesian informativeprior ?lwhere l ?
{G,M,H}, the three levelsof self-disclosure.
Table 1 lists the notations usedin the model and the generative process, Figure 2describes the generative process.3.2 Classifying G vs M/H levelsClassifying the SD level for each tweet is done intwo parts, and the first part classifies G vs. M/Hlevels with first-person pronouns (I, my, me).
Inthe graphical model, y is the latent variable thatrepresents this classification, and ?
is the distri-bution over y. x is the observation of the first-person pronoun in the tweets, and?
are the param-eters learned from the maximum entropy classifier.With the annotated Twitter conversation dataset(described in Section 4.2), we experimented withseveral classifiers (Decision tree, Naive Bayes)and chose the maximum entropy classifier becauseit performed the best, similar to other joint topicmodels (Zhao et al., 2010; Mukherjee et al., 2013).1.
For each level l ?
{G, M, H}:For each topic k ?
{1, .
.
.
,Kl}:Draw ?lk ?
Dir(?l)2.
For each conversation c ?
{1, .
.
.
, C}:(a) Draw ?Gc ?
Dir(?
)(b) Draw ?Mc ?
Dir(?
)(c) Draw ?Hc ?
Dir(?
)(d) Draw pic ?
Dir(?
)(e) For each message t ?
{1, .
.
.
, T}:i.
Observe first-person pronouns features xctii.
Draw ?ct ?MaxEnt(xct,?)iii.
Draw yct ?
Bernoulli(?ct)iv.
If yct = 0 which is G level:A.
Draw zct ?Mult(?Gc )B.
For each word n ?
{1, .
.
.
, N}:Draw word wctn ?Mult(?Gzct)Else which can be M or H level:A.
Draw rct ?Mult(pic)B.
Draw zct ?Mult(?rctc )C. For each word n ?
{1, .
.
.
, N}:Draw word wctn ?Mult(?rctzct)Figure 2: Generative process of SDTM.3.3 Classifying M vs H levelsThe second part of the classification, the M and theH level, is driven by informative priors with seedwords and seed trigrams.Utterances with M level include two types:1) information related with past events and fu-ture plans, and 2) general information about self(Barak and Gluck-Ofri, 2007).
For the former, weadd as seed trigrams ?I have been?
and ?I will?.For the latter, we use seven types of informationgenerally accepted to be personally identifiable in-formation (McCallister, 2010), as listed in the leftcolumn of Table 2.
To find the appropriate tri-grams for those, we take Twitter conversation data(described in Section 4.1) and look for trigramsthat begin with ?I?
and ?my?
and occur more than200 times.
We then check each one to see whetherit is related with any of the seven types listed inthe table.
As a result, we find 57 seed trigrams forM level.
Table 2 shows several examples.Type TrigramName My name is, My last nameBirthday My birthday is, My birthday partyLocation I live in, I lived in, I live onContact My email address, My phone numberOccupation My job is, My new jobEducation My high school, My college isFamily My dad is, My mom is, My family isTable 2: Example seed trigrams for identifying Mlevel of SD.
There are 51 of these used in SDTM.Utterances with H level express secretive wishesor sensitive information that exposes self or some-one close (Barak and Gluck-Ofri, 2007).
These are44Category Keywordsphysicalappearanceacne, hair, overweight, stomach, chest,hand, scar, thighs, chubby, head, skinnymental/physicalconditionaddicted, bulimia, doctor, illness, alco-holic, disease, drugs, pills, anorexicTable 3: Example words for identifying H level ofSD.
Categories are hand-labeled.generally keep as secrests.
With this intuition, wecrawled 26,523 secret posts from Six Billion Se-crets1site where users post secrets anonymously.To extract seed words that might express secre-tive personal information, we compute mutual in-formation (Manning et al., 2008) with the secretposts and 24,610 randomly selected tweets.
Weselect 1,000 words with high mutual informationand filter out stop words.
Table 3 shows some ofthese words.
To extract seed trigrams of secretivewishes, we again look for trigrams that start with?I?
or ?my?, occur more than 200 times, and selecttrigrams of wishful thinking, such as ?I want to?,and ?I wish I?.
In total, there are 88 seed wordsand 8 seed trigrams for H.3.4 InferenceFor posterior inference of SDTM, we use col-lapsed Gibbs sampling which integrates out la-tent random variables ?,pi,?, and ?.
Then weonly need to compute y, r and z for each tweet.We compute full conditional distribution p(yct=j?, rct= l?, zct= k?|y?ct, r?ct, z?ct,w,x) fortweet ct as follows:p(yct= 0, zct= k?|y?ct, r?ct, z?ct,w,x)?exp(?0?
xct)?1j=0exp(?j?
xct)g(c, t, l?, k?
)p(yct= 1, rct= l?, zct= k?|y?ct, r?ct, z?ct,w,x)?exp(?1?
xct)?1j=0exp(?j?
xct)(?l?+ n(?ct)cl?)
g(c, t, l?, k?
)where z?ct, r?ct,y?ctare z, r,y without tweetct, mctk?(?
)is the marginalized sum over word v ofmctk?vand the function g(c, t, l?, k?)
as follows:g(c, t, l?, k?)
=?
(?Vv=1?l?v+ nl??(ct)k?v)?
(?Vv=1?l?v+ nl??(ct)k?v+mctk?(?
))(?k?+ nl?(?ct)ck?
?Kk=1?k+ nl?ck)V?v=1?
(?l?v+ nl??(ct)k?v+mctk?v)?
(?l?v+ nl??
(ct)k?v)1http://www.sixbillionsecrets.com4 Data Collection and AnnotationTo answer our research questions, we need alarge longitudinal dataset of conversations suchthat we can analyze the relationship between self-disclosure behavior and conversation frequencyover time.
We chose to crawl Twitter because itoffers a practical and large source of conversations(Ritter et al., 2010).
Others have also analyzedTwitter conversations for natural language and so-cial media research (Boyd et al., 2010; Danescu-Niculescu-Mizil et al., 2011), but we collect con-versations from the same set of dyads over severalmonths for a unique longitudinal dataset.4.1 Collecting Twitter conversationsWe define a Twitter conversation as a chain oftweets where two users are consecutively replyingto each other?s tweets using the Twitter reply but-ton.
We identify dyads of English-tweeting userswith at least twenty conversations and collect theirtweets.
We use an open source tool for detect-ing English tweets2, and to protect users?
privacy,we replace Twitter userid, usernames and url intweets with random strings.
This dataset consistsof 101,686 users, 61,451 dyads, 1,956,993 conver-sations and 17,178,638 tweets which were postedbetween August 2007 to July 2013.4.2 Annotating self-disclosure levelTo measure the accuracy of our model, we ran-domly sample 101 conversations, each with tenor fewer tweets, and ask three judges, fluent inEnglish, to annotate each tweet with the level ofself-disclosure.
Judges first read and discussedthe definitions and examples of self-disclosurelevel shown in (Barak and Gluck-Ofri, 2007), thenthey worked separately on a Web-based platform.Inter-rater agreement using Fleiss kappa (Fleiss,1971) is 0.67.5 Classification of Self-Disclosure LevelThis section describes experiments and results ofSDTM as well as several other methods for classi-fication of self-disclosure level.We first start with the annotated dataset in sec-tion 4.2 in which each tweet is annotated with SDlevel.
We then aggregate all of the tweets of aconversation, and we compute the proportions oftweets in each SD level.
When the proportion of2https://github.com/shuyo/ldig45tweets at M or H level is equal to or greater than 0.2,we take the level of the larger proportion and as-sign that level to the conversation.
When the pro-portions of tweets at M or H level are both less than0.2, we assign G to the SD level.We compare SDTM with the following methodsfor classifying tweets for SD level:?
LDA (Blei et al., 2003): A Bayesian topicmodel.
Each conversation is treated as a doc-ument.
Used in previous work (Bak et al.,2012).?
MedLDA (Zhu et al., 2012): A super-vised topic model for document classifica-tion.
Each conversation is treated as a doc-ument and response variable can be mappedto a SD level.?
LIWC (Tausczik and Pennebaker, 2010):Word counts of particular categories.
Usedin previous work (Houghton and Joinson,2012).?
Seed words and trigrams (SEED): Occur-rence of seed words and trigrams which aredescribed in section 3.3.?
ASUM (Jo and Oh, 2011): A joint model ofsentiment and topic using seed words.
Eachsentiment can be mapped to a SD level.
Usedin previous work (Bak et al., 2012).?
First-person pronouns (FirstP): Occurrenceof first-person pronouns which are describedin section 3.2.
To identify first-person pro-nouns, we tagged parts of speech in eachtweet with the Twitter POS tagger (Owoputiet al., 2013).SEED, LIWC, LDA and FirstP cannot be useddirectly for classification, so we use Maximum en-tropy model with outputs of each of those modelsas features.
We run MedLDA, ASUM and SDTM20 times each and compute the average accuraciesand F-measure for each level.
We set 40 topicsfor LDA, MedLDA and ASUM, 60; 40; 40 top-ics for SDTM KG,KMand KHrespectively, andset ?
= ?
= 0.1.
To incorporate the seed wordsand trigrams into ASUM and SDTM, we initial-ize ?G,?Mand ?Hdifferently.
We assign a highvalue of 2.0 for each seed word and trigram forthat level, and a low value of 10?6for each wordthat is a seed word for another level, and a defaultMethod Acc G F1M F1H F1Avg F1LDA 49.2 0.000 0.650 0.050 0.233MedLDA 43.3 0.406 0.516 0.093 0.338LIWC 49.2 0.341 0.607 0.180 0.376SEED 52.0 0.412 0.600 0.178 0.397ASUM 56.6 0.320 0.704 0.375 0.466FirstP 63.2 0.630 0.689 0.095 0.472SDTM 64.5 0.611 0.706 0.431 0.583Table 4: SD level classification accuracies and F-measures using annotated data.
Acc is accuracy,and G F1is F-measure for classifying the G level.Avg F1is the average value of G F1, M F1and HF1.
SDTM outperforms all other methods com-pared.
The difference between SDTM and FirstPis statistically significant (p-value < 0.05 for ac-curacy, < 0.0001 for Avg F1).value of 0.01 for all other words.
This approachis same as other topic model works (Jo and Oh,2011; Kim et al., 2013).As Table 4 shows, SDTM performs better thanother methods by accuracy and F-measure.
LDAand MedLDA generally show the lowest perfor-mance, which is not surprising given these mod-els are quite general and not tuned specificallyfor this type of semi-supervised classification task.LIWC and SEED perform better than LDA, butthese have quite low F-measure for G and H lev-els.
ASUM shows better performance for classi-fying H level than others, but not for classifyingthe G level.
FirstP shows good F-measure for theG level, but the H level F-measure is quite low,even lower than SEED.
Finally, SDTM has sim-ilar performance in G and M level with FirstP, butit performs better in H level than others.
Classi-fying the H level well is important because as wewill discuss later, the H level has the strongest rela-tionship with longitudinal OSN usage (see Section6.2), so SDTM is overall the best model for clas-sifying self-disclosure levels.6 Self-Disclosure and ConversationFrequencyIn this section, we investigate whether there is arelationship between self-disclosure and conversa-tion frequency over time.
(Trepte and Reinecke,2013) showed that frequent or high-level of self-disclosure in online social networks (OSN) con-tributes positively to OSN usage, and vice versa.They showed this through an online survey with46Facebook and StudiVZ users.
With SDTM, wecan automatically classify self-disclosure level ofa large number of conversations, so we investi-gate whether there is a similar relationship be-tween self-disclosure in conversations and subse-quent frequency of conversations with the samepartner on Twitter.
More specifically, we ask thefollowing two questions:1.
If a dyad displays high SD level in their con-versations at a particular time period, wouldthey have more frequent conversations subse-quently?2.
If a dyad shows high conversation frequencyat a particular time period, would they dis-play higher SD in their subsequent conver-sations?6.1 Experiment SetupWe first run SDTM with all of our Twitter con-versation data with 150; 120; 120 topics forSDTM KG,KMand KHrespectively.
Thehyper-parameters are the same as in section 5.
Tohandle a large dataset, we employ a distributed al-gorithm (Newman et al., 2009).Table 5 shows some of the topics that wereprominent in each SD level by KL-divergence.
Asexpected, G level includes general topics such asfood, celebrity, soccer and IT devices, M level in-cludes personal communication and birthday, andfinally, H level includes sickness and profanity.For comparing conversation frequencies overtime, we divided the conversations into two setsfor each dyad.
For the initial period, we includeconversations from the dyad?s first conversation to60 days later.
And for the subsequent period,we include conversations during the subsequent 30days.We compute proportions of conversation foreach SD level for each dyad in the initial andsubsequent periods.
Also, we define a new mea-surement, SD level score for a dyad in the period,which is a weighted sum of each conversation withSD levels mapped to 1, 2, and 3, for the levels G,M, and H, respectively.6.2 Does self-disclosure lead to more frequentconversations?We investigate the effect of the level self-disclosure on long-term use of OSN.
We run lin-ear regression with the intial SD level score as1.0 1.5 2.0 2.5 3.0Initial SD level1.00.50.00.51.01.5# Conversaction changes proportion overtimeFigure 3: Relationship between initial SD leveland conversation frequency changes over time.The solid line is the linear regression line, and thecoefficient is 0.118 with p < 0.001, which showsa significant positive relationship.G level M level H levelCoeff (?)
0.094 0.419 0.464p-value 0.1042 < 0.0001 < 0.0001Table 6: Relationship between initial SD levelproportions and changes in conversation fre-quency.
For M and H levels, there is significantpositive relationship (p < 0.0001), but for the Glevel, there is not (p > 0.1).the independent variable, and the rate of changein conversation frequency between initial periodand subsequent period as the dependent variable.The result of regression is that the independentvariable?s coefficient is 0.118 with a low p-value(p < 0.001).
Figure 3 shows the scatter plot withthe regression line, and we can see that the slopeof regression line is positive.We also investigate the importance of each SDlevel for changes in conversation frequency.
Werun linear regression with initial proportions ofeach SD level as the independent variable, andthe same dependent variable as above.
As ta-ble 6 shows, there is no significant relationshipbetween the initial proportion of the G level andthe changes in conversation frequency (p > 0.1).But for the M and H levels, the initial proportionsshow positive and significant relationships withthe subsequent changes to the conversation fre-quency (p < 0.0001).
These results show that Mand H levels are correlated with changes to the fre-quency of conversation.47G level M level H level101 184 176 36 104 82 113 33 19chocolate obama league send twitter going ass better lipsbutter he?s win email follow party bitch sick kissesgood romney game i?ll tumblr weekend fuck feel lovecake vote season sent tweet day yo throat smilespeanut right team dm following night shit cold softlymilk president cup address account dinner fucking hope handsugar people city know fb birthday lmao pain eyescream good arsenal check followers tomorrow shut good neckTable 5: High ranked topics in each level by comparing KL-divergence with other level?s topics0 20 40 60 80 100Initial conversation frequency1.801.851.901.952.002.05Subsequent SDlevelFigure 4: Relationship between initial conversa-tion frequency and subsequent SD level.
Thesolid line is the linear regression line, and the co-efficient is 0.0016 with p < 0.0001, which showsa significant positive relationship.6.3 Does high frequency of conversation leadto more self-disclosure?Now we investigate whether the initial conversa-tion frequency is correlated with the SD level inthe subsequent period.
We run linear regressionwith the initial conversation frequency as the inde-pendent variable, and SD level in the subsequentperiod as the dependent variable.The regression coefficient is 0.0016 with low p-value (p < 0.0001).
Figure 4 shows the scatterplot.
We can see that the slope of the regressionline is positive.
This result supports previous re-sults in social psychology (Leung, 2002) that fre-quency of instant chat program ICQ and sessiontime were correlated to depth of SD in message.7 Conclusion and Future WorkIn this paper, we have presented the self-disclosuretopic model (SDTM) for discovering topics andclassifying SD levels from Twitter conversationdata.
We devised a set of effective seed words andtrigrams, mined from a dataset of secrets.
We alsoannotated Twitter conversations to make a ground-truth dataset for SD level.
With annotated data, weshowed that SDTM outperforms previous methodsin classification accuracy and F-measure.We also analyzed the relationship between SDlevel and conversation frequency over time.
Wefound that there is a positive correlation betweeninitial SD level and subsequent conversation fre-quency.
Also, dyads show higher level of SD ifthey initially display high conversation frequency.These results support previous results in socialpsychology research with more robust results froma large-scale dataset, and show importance oflooking at SD behavior in OSN.There are several future directions for this re-search.
First, we can improve our modeling forhigher accuracy and better interpretability.
Forinstance, SDTM only considers first-person pro-nouns and topics.
Naturally, there are patternsthat can be identified by humans but not capturedby pronouns and topics.
Second, the number oftopics for each level is varied, and so we canexplore nonparametric topic models (Teh et al.,2006) which infer the number of topics from thedata.
Third, we can look at the relationship be-tween self-disclosure behavior and general onlinesocial network usage beyond conversations.AcknowledgmentsWe thank the anonymous reviewers for helpfulcomments.
Alice Oh was supported by the ITR&D Program of MSIP/KEIT.
[10041313, UX-oriented Mobile SW Platform]48ReferencesJinYeong Bak, Suin Kim, and Alice Oh.
2012.
Self-disclosure and relationship strength in twitter con-versations.
In Proceedings of ACL.Azy Barak and Orit Gluck-Ofri.
2007.
Degree andreciprocity of self-disclosure in online forums.
Cy-berPsychology & Behavior, 10(3):407?417.David M Blei, Andrew Y Ng, and Michael I Jordan.2003.
Latent dirichlet allocation.
Journal of Ma-chine Learning Research, 3:993?1022.Danah Boyd, Scott Golder, and Gilad Lotan.
2010.Tweet, tweet, retweet: Conversational aspects ofretweeting on twitter.
In Proceedings of HICSS.Cristian Danescu-Niculescu-Mizil, Michael Gamon,and Susan Dumais.
2011.
Mark my words!
: Lin-guistic style accommodation in social media.
InProceedings of WWW.Valerian J. Derlega, Sandra Metts, Sandra Petronio,and Stephen T. Margulis.
1993.
Self-Disclosure,volume 5 of SAGE Series on Close Relationships.SAGE Publications, Inc.Joseph L Fleiss.
1971.
Measuring nominal scaleagreement among many raters.
Psychological bul-letin, 76(5):378.David J Houghton and Adam N Joinson.
2012.Linguistic markers of secrets and sensitive self-disclosure in twitter.
In Proceedings of HICSS.Yohan Jo and Alice H Oh.
2011.
Aspect and senti-ment unification model for online review analysis.In Proceedings of WSDM.Adam N Joinson and Carina B Paine.
2007.
Self-disclosure, privacy and the internet.
The Oxfordhandbook of Internet psychology, pages 237?252.Sidney M Jourard.
1971.
Self-disclosure: An experi-mental analysis of the transparent self.Suin Kim, JinYeong Bak, and Alice Haeyun Oh.
2012.Do you feel what i feel?
social aspects of emotionsin twitter conversations.
In Proceedings of ICWSM.Suin Kim, Jianwen Zhang, Zheng Chen, Alice Oh, andShixia Liu.
2013.
A hierarchical aspect-sentimentmodel for online reviews.
In Proceedings of AAAI.Andrew M Ledbetter, Joseph P Mazer, Jocelyn M DeG-root, Kevin R Meyer, Yuping Mao, and Brian Swaf-ford.
2011.
Attitudes toward online social con-nection and self-disclosure as predictors of facebookcommunication and relational closeness.
Communi-cation Research, 38(1):27?53.Louis Leung.
2002.
Loneliness, self-disclosure, andicq (?
i seek you?)
use.
CyberPsychology & Behav-ior, 5(3):241?251.Christopher D Manning, Prabhakar Raghavan, andHinrich Sch?utze.
2008.
Introduction to informationretrieval, volume 1.
Cambridge University PressCambridge.Erika McCallister.
2010.
Guide to protecting the confi-dentiality of personally identifiable information.
DI-ANE Publishing.Arjun Mukherjee, Vivek Venkataraman, Bing Liu, andSharon Meraz.
2013.
Public dialogue: Analysis oftolerance in online discussions.
In Proceedings ofACL.David Newman, Arthur Asuncion, Padhraic Smyth,and Max Welling.
2009.
Distributed algorithmsfor topic models.
Journal of Machine Learning Re-search, 10:1801?1828.Olutobi Owoputi, Brendan OConnor, Chris Dyer,Kevin Gimpel, Nathan Schneider, and Noah ASmith.
2013.
Improved part-of-speech tagging foronline conversational text with word clusters.
InProceedings of HLT-NAACL.Alan Ritter, Colin Cherry, and Bill Dolan.
2010.
Unsu-pervised modeling of twitter conversations.
In Pro-ceedings of HLT-NAACL.Charles Steinfield, Nicole B Ellison, and Cliff Lampe.2008.
Social capital, self-esteem, and use of on-line social network sites: A longitudinal analy-sis.
Journal of Applied Developmental Psychology,29(6):434?445.Yla R Tausczik and James W Pennebaker.
2010.
Thepsychological meaning of words: Liwc and comput-erized text analysis methods.
Journal of Languageand Social Psychology.Yee Whye Teh, Michael I Jordan, Matthew J Beal, andDavid M Blei.
2006.
Hierarchical dirichlet pro-cesses.
Journal of the american statistical associ-ation, 101(476).Sabine Trepte and Leonard Reinecke.
2013.
The re-ciprocal effects of social network site use and thedisposition for self-disclosure: A longitudinal study.Computers in Human Behavior, 29(3):1102 ?
1112.Sarah I Vondracek and Fred W Vondracek.
1971.
Themanipulation and measurement of self-disclosure inpreadolescents.
Merrill-Palmer Quarterly of Behav-ior and Development, 17(1):51?58.Thomas Ashby Wills.
1985.
Supportive functionsof interpersonal relationships.
Social support andhealth, xvii:61?82.Wayne Xin Zhao, Jing Jiang, Hongfei Yan, and Xiaom-ing Li.
2010.
Jointly modeling aspects and opin-ions with a maxent-lda hybrid.
In Proceedings ofEMNLP.Jun Zhu, Amr Ahmed, and Eric P Xing.
2012.
Medlda:maximum margin supervised topic models.
Journalof Machine Learning Research, 13:2237?2278.49
