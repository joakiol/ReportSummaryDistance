Proceedings of the 2nd Workshop on Cognitive Aspects of the Lexicon (CogALex 2010), pages 75?84,Beijing, August 2010Lexical Access, a Search-ProblemMichael Zock (1), Didier Schwab (2) and Nirina Rakotonanahary (2)(1) LIF-CNRS, TALEP, 163, Avenue de Luminy(2) LIG-GETALP, University of Grenoblezock@free.fr, didier.schwab@imag.fr, damanidaddy@msn.comAbstractOur work is confined to word access,that is, we present here our ideas of how toimprove electronic dictionaries in order tohelp language producers (speaker/writer)to find the word they are looking for.
Ourapproach is based on psychological find-ings (representation, storage and access ofinformation in the human mind), observedsearch strategies and typical navigationalbehavior.If one agrees with the idea that lex-ical access (word finding) is basically asearch problem, then one may still wantto find out where and how to search.While the space, i.e.
the semantic mapin which search takes place is a resourceproblem,?
any of the following could beused: dictionary, corpus, thesauraus, etc.or a mix of them,?
its exploration is typ-ically a search problem.
Important as itmay be, the building of a high quality re-source is not the focus of this work, werely on an existing one, and while weare concerned with its quality, we will bemostly concerned here with search meth-ods, in order to determine the best.1 Problem: find the needle in a haystackOne of the most vexing problems in speaking orwriting is that one knows a given word, yet onefails to access it when needed.
This kind of searchfailure, often referred to as dysnomia or Tip of theTongue-problem, occurs not only in communica-tion, but also in other activities of everyday life.Being basically a search problem it is likely to oc-cur whenever we look for something that existsin real world (objects) or our mind: dates, phonenumbers, past events, peoples?
names, or you justname it.As one can see, we are concerned here with theproblem of words, or rather, how to find them inthe place where they are stored: the human brain,or an external resource, a dictionary.
Our workbeing confined to lexical access, we would liketo develp a semantic map and a compass to helplanguage producers to find the word they are look-ing for.
More precisely, we try to build an indexand a navigational tool allowing people to accesswords no matter how incomplete their conceptualinput may be.
Our approach is based on psy-chological findings concerning the mental lexicon(Aitchison, 2003; Levelt et al, 1999), i.e.
storageand access of information in the human mind, ob-served search strategies and typical navigationalbehavior.2 Consider the following elements beforeattempting an engineering solutionBefore conceiving a roadmap leading to an en-gineering solution it may be useful to considercertain points.
The list here below is by nomeans complete, neither is the following discus-sion.
Nevertheless we believe that the followingpoints are worth consideration: features of themental lexicon, how to build and use the resource,searching, ranking and weights, interface prob-lems.
For reasons of space constraints we willtouch briefly only upon some of these points.Our main goal is the enhancement of electronicdictionaries to help speakers or writers to find75quickly and intuitively the word they are looking.To achieve this target we take inspiration in thefindings concerning the human brain (structure,process) when it tries access words in the mentallexicon.2.1 The mental lexicon, a small-worldnetwork?While forms (lemma) and meanings (lexical con-cepts, definitions) are stored side by side in pa-per dictionaries (holistic presentation), the hu-man brain stores them differently.
The informa-tion concerning meaning, forms and sound is dis-tributed across various layers.
Lexical fragmen-tation or information distribution is supported bymany empirical findings,1 and while this fact isarguably the reason accounting for word accessproblems, it is probably also the explanation ofthe power and the flexibility of the human mindwhich generally manages to find in no time theright term after having searched for it in a hugestore of words.While it is still not entirely clear what is stored,or whether anything is stored at all 2 coming closeto the kind of information generally found in dic-tionaries, it does seem clear though that the struc-ture of mental lexicon is a multidimensional net-work in which the user navigates.
?Entries in thelexicon are not islands; the lexicon has an inter-nal structure.
Items are connected or related invarious ways...There are item relations within andbetween entries.?
(Levelt, 1989).
While the for-mer relate meanings and forms: syntactic (partof speech), morphological, phonological informa-tion, the latter connect lexical entries.3 In sum,1Speech errors (Fromkin, 1980), studies on aphasia (Dellet al, 1997; Blanken et al, 2004) or response times i.e.chronometric studies (Levelt et al, 1999), neuroimaging(Shafto et al, 2007; Kikyo et al, 2001), eye movements,(Roelofs, 2004), experiments on priming (Schvaneveldt etal., 1976) or the tip of the tongue problem (TOT) (Brownand McNeill, 1996).2An important feature of the mental lexicon lies in thefact that the entries are not accessed but activated (Marslen-Wilson, 1990; Altmann, 1997).
Of course, such a detail canhave far reaching consequences concerning knowledge rep-resentation and use, i.e.
structure and process.3These are typically the kind of relations we can find inWordNet (Fellbaum, 1998), which happens to be quite richin this respect, but relatively poor with regard to intrinsic, i.e.intralexical information.lexical networks store or encode the informationpeople typically have with regard to words, andfinding the needed information, amounts to enterthe graph at some point,?
in the case of writing orspeaking, usually a node dedicated to meaning,?and to follow the links until one has reached thegoal (target word).
While computer scientistscall this kind of search ?navigation?, psychologistsprefer the term ?activation spreading.
While notbeing exactly the same, functionally speaking theyare equivalent though.As every day language experience shows,things may go wrong, we lack information, hencewe get blocked.
Yet when trying to complete thepuzzle we do not start from scratch, we rely onexisting information, which, in terms of the net-work metaphor means that we start from (infor-mation underlying) a word being close to the tar-get word.4It is interesting to note, that our lexical graphsseem to have similar characteristics as small-world networks.
These latter are a type of graphin which most nodes, eventhough not being directneighbors, can be reached via a small number ofclicks, about 6, regardless of the starting point.This property of networks, where objects, or thenodes standing for them, are highly connected hasfirst been described by Frigyes Karinthy (1929)a Hungarian writer, to be tested then many yearslater by a social psychologist (Milgram, 1961).Nodes can be anything, people, words, etc.
If theyrepresent people, than edges specify their relation-ship, i.e.
the very fact that they know each other,that they are friends, etc.
Given this high connec-tivity, anything seems to be at the distance of a fewmouse clicks.
Hence, it is easy to connect peo-ple or to find out who entertains with whom whatkind of relationship.
Obviously, there is a strik-ing similarity to our lexical graphs, and the small-world feature has been tested by mathematicians,who concluded that the distance for words is evensmaller than in the original Milgram experiments,namely 4 rather than 6.
Indeed, (Motter et al,2002) and colleagues could show that more than4As TOT experiments have shown (Brown and McNeill,1996), people always know something concerning the targetword (meaning, form, relation to other words), hence findinga word in such a situation amounts to puzzle-completion.7699 percent of the word pairs of their corpus couldbe connected in 4 steps at the most.2.2 Building the resourceThere are two elements we need to get a clearerpicture of: the nature of the resource (semanticmap), and the search method i.e.
the way to ex-plore it.
Concerning the resource, there are manypossible sources (dictionary, thesaurus, corpora,or a mix of all this) and many ways of build-ing it.
Since our main goal is the building ofan index based on the notion of word relations(triples composed of two terms and a link), thetwo prime candidates are of course corpora andassociation lists like the ones collected by psy-chologists.
While the former are raw data, con-taining the information in a more or less hiddenform, the latter (often) contain the data explicitely,but they are scarce, subject to change, and some ofthe links are questionable.5Corpora: Concerning the resource the follow-ing points deserve consideration: size, representa-tivity and topic sensitivity.?
Size or coverage: While size or coverage arecritical variables, they should not be overem-phasized though, trading quantity againstquality.
We need to define the meaning ofquality here, and whether, when or how lackof quality can be (partially) compensated byquantity.
In other words, we need to definethresholds.
In the absence of clear guidelinesit is probably wise to strive for a good bal-ance between the two, which again assumesthat we know what quality means.?
Representativity: Obviously, the system wehave in mind is only as good as the data weuse, i.e.
the purity/accuracy and represen-tativity of the word/feature-association lists.5This flaw is due to the experimental protocol.
Subjectsare asked to give the first word coming to their mind rightafter a stimulas.
Not having been asked to specify the link itis the experimenter who does so.
Yet, many word pairs,?
say,cat and dog,?
allow for various links (love, tease, chase, etc.
),and it is not obvious at all which is the one intended by theuser.
This problem could have been avoided to a large extentif the instruction had been, ?build a sentence containing thefollowing word?.
Another potential problem may be due tothe distance between the source and the target word: the linkmay be mediated.No single set of data (dictionary, corpus, the-saurus) will ever suffice to capture the knowl-edge people have.
While it would be unreal-istic to try to model the semantic map of ev-eryone, it is not unreasonable to try to reachan average user, say someone who has beento school and is a computer literate.
If wewant to capture the world-knowledge of thiskind of user (target), than we must bewarethat it is contained in the material we use,since our resource will be based on this data.Hence, taking as corpus only the newspapersread by an elite (say, Le Monde, in France),will surely not suffice to capture the informa-tion we need, as it will not relate informationordinary citizens, say sport fans, are famil-iar with or interested in.
In sum, we need totake a wide variety of sources to extract thenthe needed information.
While there is short-age of some document types needed, thereare nevertheless quite a few sources one mayconsider to begin with: Wikipedia, domaintaxonomies, topic signatures, (Lin and Hovy,2000), a database like (http://openrdf.org),etc.?
Topic sensitivityWeights are important, but they tend tochange dynamically with time and the topic.Think of the word ?piano?
uttered in the con-texts of a ?concert?
or ?household moving?.
Itis only in this latter case that this term evokesideas like size or weight.
The dynamic re-compution of weights as a function of topicchanges requires that the system be able torecognize the topic changes, as otherwise itmight mislead the user by providing of in-adequate weights.
For some initial work see(Ferret and Zock, 2006).Association lists: Psychologists have built suchlists already decades ago (Deese, 1965; Schvan-eveldt, 1989).
Similar lists are nowadays freelyavailable on the web.
For example, for Englishthere is the Edinburgh Associative Thesaurus 6and the compilation done by Nelson and his col-leagues in Florida 7.
There are also some re-6http://www.eat.rl.ac.uk/7http://cyber.acomp.usf.edu/FreeAssociation/77sources for German (see 8 or 9), for Japanese,10and probably many other languages.While association lists are generally built man-ually, one can also try to do so automatically orwith the help of people (see section 5 in (Zockand Bilac, 2004)).
JeuxdeMot (JdM), a collec-tively built resource focusing on French being anexample in case.112.3 SearchingThe goal of searching is more complex than onemight think.
Of course, ultimately one should findthe object one is looking for,12 but the very pro-cess should also be carried out quickly and natu-rally.
In addition we want to allow for recovery incase of having taken the wrong turn, and we wantto avoid looping, that is, walking in circles, with-out ever getting closer to the goal.
Last, but notleast we want to make sure that stored informa-tion can also be accessed.That this is less obvious than it might seem atfirst sight has been shown by (Zock and Schwab,2008).
Taking two resources (WN and Wikipedia)that contain both a given target word, we wantedto see whether we could access it or not.
Thetarget word was ?vintage?.
In order to find it weprovided two access keys, i.e.
trigger words:?wine?
and ?harvest?.
Combining the two produceda list of 6 items in the case of WN and 45 in thecase of Wikipedia, yet, while the latter displayedthe target word, it was absent from the list pro-duced by WN.
This example illustrates the factthat our claim concerning storage and acess is wellfounded.
Having stored something does by nomeans guarantee its access.In the next sections we will present a small ex-periment concerning search.3 System architectureTo allow for word access, we need at least twocomponents: an index, i.e.
a resource, repre-senting or encoding the way words are connected8http://www.schulteimwalde.de/resource.html9http://www.coli.uni-saarland.de/projects/nag/10http://www.valdes.titech.ac.jp/ terry/jwad.html11http://www.lirmm.fr/jeuxdemots/rezo.php12This poses special requirements concerning the organi-zation, indexing and ranking of the data, i.e.
words.
We willnot get into these issues here.
(database or semantic network encoding associa-tive relations between words) and an efficientsearch algorithm to find the needed information,in our case, words.In other words, since search requires a map or aresource in which to search and a good algorithmto perform the search, we are keen in finding outhow different resources (for example, Wikipedia,WordNet or JeuxdeMots) and various search al-gorithms might affect efficiency of word access.While there is a link between (the quality of) theresource and the searching, we will separate thetwo, focusing here mainly on the search algo-rithms and possible ways to evaluate them. !" #$%&&'($&))&*+(Figure 1: Overall architecture of the system: theresource (association matrix) and a set of searchalgorithms4 Corpora and resourcesResources are built from corpora which can be ofvarious kinds: news, books, social media, ency-clopedias, lexical databases,...
They can be gen-eral or specific, representing a particular domain.
?Text genre?
may of course have an impact onwhat we can expect to retrieve.
Obviously, onewill not take a database of stock exchange newsif one is looking for words referring to tennis- orfishing equipment.To build our resource, we relied on Word-Net (WN).13 The resource can be seen in vari-ous ways: as a semantic network, an association13Note, that one may consider WN (Fellbaum, 1998) notonly as a dictionary, but also as a corpus.
Actually we usedprecisely this kind of corpus for building our resource.78matrix, or as a list or database of 4-tuples com-posed of terms, links and weights.
These ele-ments can be represented in the following way,< X,Y,RZ ,w>, where X and Y are terms or ar-guments of a given link, whose name expressesthe type of relationship holding between them[RZ (synonyme, antonyme, hyperonyme, colloca-tion,...)].
Links and terms have a certain weight wwhich can be crucial for navigation and informa-tion display (interface).
Words may be groupedinto clusters,14 and the clusters as well as their el-ements may be presented in the descending orderof the weight: frequent terms being shown on topof the list.Weights can be calculated in various ways: mu-tual information, co-occurences, etc.
For exam-ple, for corpora, they can be seen as the numberof times two items co-occur in a given window(sentence, phrase, paragraph, n words before orafter, .
.
.
).
Unfortunately, this kind of informationis not always available in current resources.
Forexample, WN relates terms (or senses), but doesnot assign them any particular weight.
Yet, thisinformation is very important and might be addedvia some learning method.5 Search Algorithms5.1 DefinitionsInformally, a search algorithm is a method allow-ing to retrieve a list of terms (candidate targetwords presented in a given order) from a list ofpairs containing the cue- or trigger words and theirrelations.
For example figure 1 shows that the pair(?beverage?, ako) allows the retrieval of {?coffee?and ?moccha#2?
}, two potential target words.
Moreformally, let?s definef({(t1, R1), (t2, R2), .
.
.
, (tm, Rm)})= {(T1, w1), (T2, w2), .
.
.
, (Tm, wm)}(1)where t1,t2,.
.
.
,tm are keys, cue- or trigger-words,R1,R2,.
.
.
,Rm the type of relation, T1,T2,.
.
.
,Tmcandidate target-words andw1,w2,.
.
.
,wm, the as-sociated weights.
The curley brackets {} representthe fact that we have an ordered set.14All words having the same link will be stored and pre-sented together.
For example, ?cat?
and ?dog?
are likely to fallin the category ?animal?, while ?hammer?
and ?screwdriver?will fall in the category ?tools?.Indeed, the ?trigger word-relation?
pairs are or-dered, that is, they parallel the order in whichthese terms were given as input at query time.The candidate target words are ordered in terms ofconfidence, ranking which may vary with respectto a given search algorithm.
In this paper, confi-dence is based on the weights in the resource.
Ofcourse, one could imagine other ways to define orcompute it.Note that we can have R1 = R2, provided thatwe do not have at the same time t1 = t2.
Forinstance, while it is possible to have {(?island?, in-stance), (?island?, ako)}, one cannot have at thesame time {(?island?, instance), (?island?, instance)}We present in the next sections various waysto use the resource and various search algorithms.In these experiments, we tried to use direct andindirect links (mediated associations) contained inthe tuples and to establish linearly the weight as afunction of the position of the word in the list ofthe trigger words.5.2 General algorithmIn the general algorithm, we consider that our can-didate target words are at the intersection of thesets corresponding to the pairs of trigger wordsand their relations.f({(t1, Ra), (t2, Rb)}) =f({(t1, Ra)} ?
f({t2, Rb}))(2)We will now show, step by step, how f({(t, R)})is affected by various uses (direct vs. indirect use)and orderings.
This will yield 4 kinds of searchalgorithms.5.3 The use of the tuplesTo illustrate our algorithms, let us consider the fol-lowing resource:< ?mouse?,?rodent?,ako,3>;< ?rodent?,?animal?,ako,4>;< ?rat?,?rodent?,ako,1>;< ?rat?,?animal?,ako,2>;5.3.1 Direct useIn this case, we rely only on the direct links< t,T ,R,w> of the resource Res:f({(t, R)}) = {(T,W )|< t,T ,R,w> ?
Res}(3)79that is, in the case of direct use, the search algo-rithm fed with the trigger word t and the relation-ship R found all target words T contained in thetuple < t,T ,R,w> of the resource Res.
The com-putation of the weight W is defined in 5.4.
Forexample, ?mouse?, would yield ?rodent?, while ?rat?,would trigger ?animal?
and ?rodent?.5.3.2 Indirect useIn order to boost recall this algorithm takes alsoindirect links into account.f({(t, R)}) = {(T,W )|< t,T ,R,w> ?
Res}?
{(T,W )|< t,X ,R,w1> ?
Resand < X ,T ,R,w2> ?
Res}(4)Hence, we consider neighbor words of the neigh-bors of the trigger words.15 Again, for ?mouse?, weget ?rodent?
and ?animal?, while for ?rat?, we continueto get ?animal?
and ?rodent?.5.4 Weighting5.4.1 Basic WeightingFor f({(t1, R1)}, {(t2, R2)}, .
.
.
, {(tn, Rn)}),W = ?ti,T,Ri,wjwj(5)In our example and for direct use, if our triggerword list is {?mouse?, ?rat?}
then the weight (W)will be 4 (3 + 1) for ?rodent?
and 6 (4 + 2) for?animal?.
In the case of indirect use, the weight willbe 4 (3 + 1) for ?rodent?
and 10 (3 + 4 + 1 + 2) for?animal?.5.4.2 Weighting based on the cue-word?sposition and its relation to other wordsLet us suppose that the user gave in this or-der the following cue words ?A?, ?B?, ?C?.
In thiscase we assume that ?A?
is more important than ?B?,which is more important than ?C?
in order to findthe target word.
Following this line of reasoning,we may consider the following cases:For f({(t1, R1)}, {(t2, R2)}, .
.
.
, {(tn, Rn)}),W = ?ti,T,Ri,wj (n?
i+ 1)?
wj(6)15Please note, we consider here only one intermediateword (two links), as this is, computationally speaking, al-ready quite expensive.In our example of direct use, if our trigger wordlist is {?mouse?, ?rat?
}, W will be 7 (2?
3 + 1?
1)for ?rodent?while W = 10 (2?4+1?2) for ?animal?.For indirect use, W is 4 (2+1?
1) for ?rodent?
and17 (2?
(3 + 4) + 1?
(1 + 2)) for ?animal?.5.5 Proposed Search AlgorithmsCrossing the characteristics of weight (direct vs.indirect) and use (direct vs. indirect), we get 4possible search methods : direct use with basicweighting (A1) or linear weighting (A2); and in-direct use with basic weighting (A3) or linearweighting (A4).6 Evaluation6.1 The problem of evaluation.The classical in vivo / vitro approaches do notseem to fit here.
While the former tests the systemfor a given application, the latter tests the systemindependently.
Given the fact that our system hasseveral components, we can evaluate each one ofthem separately.
More precisely, we can evaluatethe quality of the resource and/or the quality ofthe search algorithm.
We will focus here on thesearch method.6.2 ProcedureThe basic idea is to provide each algorithm withan ordered set of trigger words and to see howmany of them are generally needed in order to re-veal the target word.Another way to evaluate the quality of thesearch mechanism is to check at each step the po-sition of the target word in the list generated bythe algorithms (output).6.3 Building the test corpusPsychologists have studied the differences ofmonolingual and bilingual speakers experienc-ing the ?tip-of-the-tongue?
problem (Pyers et al,2009).
Their experiments were based on 52pictures corresponding to low-frequency names.Starting from this list we were looking for asso-ciated words.
In order to build this list we used asresource the results produced by ?Jeux de Mots?
(Lafourcade, 2007).1616As mentionned by one of the reviewers, we could andprobably should have used the Edinburgh Associative The-806.3.1 JeuxdeMots (JdM)JeuxdeMots, meaning in English ?word games?or ?playing with words?, is an attempt to buildcollaboratively, i.e.
via a game, a lexical re-source.
The goal is to find out which words peo-ple typically associate with each other and to buildthen the corresponding resource, that is, a lexical-semantic network.
What counts as a typical as-sociation is established empirically.
Given someinput from the system ?
(term and link, let us say?Americans?
and ?elect as president?)?
the userproduces the associated word ?
(second term, letus say ?Obama?),?
answering this way the ques-tion, what term x is related to y in this specificway.
Once the network is built, terms should beaccessible by entering the network at any point(via some input) and by following the links un-til one reaches the target word.
This is at least thetheory.
Unfortunately, in practice things do notalways work so well.Actually, JdM has several flaws, especially withrespect to acces or search.
The shortcomings areprobably rooted in too heavy reliance on the no-tion of weight and in excessive filtering of theoutput, i.e.
premature elimination of the can-didates presented to the user, list of elementsamong which the user is meant to choose.
In-deed, JdM presents only the highest ranked candi-date.
Hence, words may never make it to the crit-ical level to be included in the set from which theuser will choose the target word.
Also, weightsdo not necessarily correlate with users?
interests.This problem can be solved in interactive search,provided that the output contains a critical mass ofcandidates (possibly organized according to somepoint of view), but the problem is most likely re-main if one presents only one candidate (the high-est ranked term), as this latter is not necessarilythe target, neither is it always a term from whichone would like to continue search.There is also a problem with the link names,saurus (http://www.eat.rl.ac.uk/ ) as it containsauthentic word associations collected from people.
Thispoint is well taken and we will consider this resource in thefuture as its coverage is better than our current one and it alsoavoids possible problems due to the translation.
Though be-ing generic, JeuxdeMots has mainly data on French, yet ourtests were run on English.i.e.
(metalanguage),17 though, to be fair, one mustadmit that identifying and naming links is a verydifficult problem.
Last, but not least, though morerelated to the quality of the resource than to theproblem of search, there is a chance of user-bias.Indeed, it is not entirely clear whether people re-ally give the first association coming to their mind,or the one fitting them best to continue the gameand win more points.Despite these shortcomings, we will use JdMas a resource as it exists not only for various lan-guages, but is also quite rich, at least for French.Unfortunately, the English version is very poorcompared to the French part.18 This is why we?vedecided to use the French version for the test cor-pus.6.3.2 Building the test corpusStarting from Pyer?s list, we translated eachterm into French and inspected then JDM in orderto find the 10 most frequently connected words ac-cording to this resource.
Next, we translated theseterms into English, producing the list shown in theappendix.As we will see later, in our experiment we donot have typed relations between the words.
Actu-ally we took from JDM what they call ?associatedideas?.Nevertheless, when building the list we didhave some problems.
Some words do not haveany, only one, or simply very few associated ideas.This is particularly true for low frequency words.This being so, we deleted them (in our case 7)from the list.6.4 Description of the toolOur tool is implemented in Java.
To allow for on-line access 19 we use Google?s Web Toolkits20.The interface is very simple, akin to Google?ssearch engine.
At the top of the page the user isinvited to provide the input, i.e.
the trigger words,17The term typical association is underspecified to say theleast.18For example, while for English JdM has by today (july9, 2010) only 654 relations, the French part contained1.011.632 the very same day, and 994.889 a month ago.19http://getalp.imag.fr/homepages/schwab20http://code.google.com/intl/fr/webtoolkit/81a checkbox allows to choose relations and at thebottom are shown the candidate target words.6.5 Description of the resource for theexperimentIn this experiment, we use the English version ofWikipedia to build our resource.
Due to corpuscharacteristics, only one relation is used: neighbor(ngh).
We consider ?words occuring in the sameparagraph?
as neighbours.
After having deleted?stop words?
(articles, conjunction, .
.
. )
we lem-matize ?plain words?
by using DELA?
21For example, a corpus containing the follow-ing two sentences ?The cat eats the mouse \ Themouse eats some cheese?
would yield the follow-ing resource :< ?cat?,?mouse?,ngh,1>; < ?cat?,?eat?,ngh,1>;< ?eat?,?cat?,ngh,1>; < ?eat?,?mouse?,ngh,2>;< ?mouse?,?cat?,ngh,1>; < ?mouse?,?eat?,ngh,2>;< ?mouse?,?cheese?,ngh,1>;< ?eat?,?cheese?,ngh,1>;< ?cheese?,?mouse?,ngh,1>; < ?cheese?,?eat?,ngh,1>It should be noted that in this experiment, linksare symmetrical.< X,Y,ngh,w> ?
< Y,X,ngh,w> (7)6.6 Comparison and evaluation of resultsDue to time contraints, we decided to use only asmall sample of words, 10 to be precise.
Con-cerning search we have tested two parameters: thescope (direct vs. indirect links, i.e.
associations,A1 vs. A3) and the weight (presence or absence,A2 vs. A4).The results are shown in table 1, where ?meansthat the algorithm did not find any solution, while?
implies that the trigger word list has been fullyexhausted without being able to produce the targetword among the top ten candidates.
Indeed, inorder to be considered as a hit, the found targetword has to be among the top ten.As one can see our algorithms with indirectuse (A3 and A4) never manages to find the tar-get word.
Actually, it does not fail totally.
It isjust that the candidate term appears very late inthe list, too late to be considered.
The algorithmswith direct use (A1 and A2) do find the elusiveword or produce a ?list?
of zero candidates.21http://infolingu.univ-mlv.fr/DonneesLinguistiques/ Dic-tionnaires/telechargement.htmlTARGET A1 A2 A3 A4hive 1 1 ?
?peackock 4 4 ?
?comet 3 2 ?
?microscope ?
?
?
?snorkel 5 5 ?
?pitcher 4 3 ?
?axe ?
?
?
?gazebo ?
?
?
?hoe ?
?
?
?castle 3 3 ?
?Table 1: Comparison of the number of stepsneeded by each search algorithm to find the targetword ie.
to put it in the list of the top ten.
?
signalsthe fact that the algorithm does not find any solu-tion, while ?
implies that eventhough the triggerword list has been totally used, it did not manageto come up with the target word among the top tencandidates.target 1 2 3 4 5 6A1 115 112 325 ?
?
?A2 118 98 273 ?
?
?A3 256 288 254 189 114 59A4 234 267 262 156 115 54Table 2: Comparison of the position of the targetword at each step of the algorithm for ?microscope?Table 2 illustrates this last point by showing theposition of the target word with respect to one ofthe six trigger words.While the target word always appears in A3-A4, A1 and A2 never produce any results beyondthe 4th trigger word.
The two experiments alsoshow that linear weighting has hardly any effecton the results.7 Conclusions and Future WorkWe have started to caracterize lexical access as asearch problem.
Since search requires a resourcein which to search and a good algorithm to per-form the search, we were interested in establish-ing how different resources ?
(Wikipedia (WiP),WordNet (WN), JeuxdeMots (JdM))?
and varioussearch algorithms might affect efficiency of wordaccess.
The focus here has been on the latter.82Next to search algorithms, we presented somemethods for evaluating them.
While our resultsare clearly preliminary and on a very small scale,we believe that the questions we have raised areof the right sort.
Of course, a lot more work isneeded in order to answer our questions with moreauthority.8 Appendixhive (tw): bee; honey; queen; cell; royal jelly;pollen; wax; group; frame; nest; (aws)peacock: bird; feather; animal; spread; shout;blue; tail; disdainful; arrogant; despise;comet: star; space; shooting star; astronomy; sky;galaxy; night; universe; apparition;microscope: small; observe; enlarging; mi-croscopic; observation; ocular; optical; twin;eyeglass;glasses; sea; diving; breath; ocean;mask; flipper;pitcher: jug; jar; carafe; dishes; vase; ewer;container;axe: cut; kill; split; fell; murder; saw; agriculture;arboriculture;gazebo: pavilion; platform; viewpoint; ter-race;view; architecture; house; pavillon; es-planadehoe (tool): farming; tool; shovel; pick; tech-nique;spade;castle: tower; king; dungeon; fort; queen; draw-bridge; prince; princess; embrasure;eclipse: moon; sun; astronomie; disappearance;darkness;bolted joint: door; lock; padlock; key; close;button; metal; box; house; portal; bolt;megaphone: sound; loudspeaker;manta ray: fish; sea; wing;wheelbarrow: wheel; carry; garden; shovel;gardener; fill; push;dynamite: bomb; explosion; explosive;weapon;wick; chemistry; plastic;compass: direction; navigation; navy; windrose;chisels: cut; scissor; prune; pair; hairdresser;paper; school; chisel;ostrich: egg; bird; Australia; cassowary; emu;grater: woodwork; tool; poverty; polished;dishes;braille: blind; alphabet; writing;water well: dig; drill; pierce;guillotine: scaffold; widow; death penalty; head;reaper; decapitation; execution; torture;weathervane: rooster; direction; wind; rooftop;rotation; east; south; north; west;churning (butter): container; oil; milk; bottle;container; cuve; jerrycan; tank;carousel: fun fair; amusement park; children;entertainment;canteen (place): meal; school; eat; dessert; dish;tableland; entrance; restaurant; food; refectory;supervisor; glass; wood; tail; tooth; trapper;trunk;goggles: sight; glasses; myopia; eyes; rim;twin-lens; optician; sun; vision; see; rectifica-tion; improvement; astigmatic; ophthalmologist;farsighted; longsighted; blind; binoculars; nose;optical; pair; telescope; protection;boomerang: Australia; object; flying; throw;come back;easel: painting; drawing; support; tripod;propeller: boat; ship; plane; propulsion; curve;rotation; rolling;walnut: fruit; hazelnut; almond; tree; cashew;nutcracker; oil; salad; woodwork;catapult: ejection; old weapon; throw; stone;aircraft carrier; crossbow; ballista; sling;udder: milk; cow; chest; nipple tit;gyroscope: direction; rotation; instruments;gyrostat;mummy: pharaoh; Egypt; pyramid; strip; dead;embalm; sarcophagus; fruits; funeral;hinge: junction; woodwork; middle; locksmiths;assemblage;harmonica: music; instrument; breath; flute;musical instruments;metronome: musical, tempo, musical instru-ments;noose: hang; boat; attach; bind; cord;harp: musical instruments; zither; lute; lyre;psaltery;slingshot: weapon; attack; projectile weapon;catapult;eiffel tower: Paris; steel; monument; metal;syringe: drug; injection; sting; nurse; sick; ill;bodycare; drug addiction;Words containing too little information tobe usable for tests baster, unicycle, thermos,83antlers, plunger, cleftchin, handcuffs.ReferencesAitchison, J.
2003.
Words in the Mind: an Introduc-tion to the Mental Lexicon (3d edition).
Blackwell,Oxford.Altmann, G. T. M., 1997.
The ascent of Babel: Anexploration of language, mind, and understanding,chapter Accessing the Mental Lexicon: Words, andhow we (eventually) find them.
Oxford UniversityPress.Blanken, G., F. Kulke, T. Bormann, B. Biedermann,J.
Dittmann, and C.W.
Wallesch.
2004.
The dis-solution of word production in aphasia: Implica-tions for normal functions.
In Pechmann, T. andC.
Habel, editors, Multidisciplinary Approaches toLanguage Production, pages 303?338.
Mouton deGruyter, Berlin.Brown, R. and D. McNeill.
1996.
The tip of thetounge phenomenon.
Journal of Verbal Learningand Verbal Behaviour, 5:325?337.Deese, J.
1965.
The structure of associations in lan-guage and thought.
Johns Hopkins Press.Dell, G.S., M.F.
Schwartz, N. Martin, E.M. Saffran,and D.A Gagnon.
1997.
Lexical access in apha-sic and nonaphasic speakers.
Psychological Review,104(4):801?838.Fellbaum, C., editor.
1998.
WordNet: An Elec-tronic Lexical Database and some of its Applica-tions.
MIT Press.Ferret, O. and M. Zock.
2006.
Enhancing electronicdictionaries with an index based on associations.In ACL ?06: Proceedings of the 21st InternationalConference on Computational Linguistics and the44th annual meeting of the ACL, pages 281?288.Fromkin, V. 1980.
Errors in linguistic performance:Slips of the tongue, ear, pen and hand.Kikyo, H., K. Ohki, and K. Sekihara.
2001.
Temporalcharacterization of memory retrieval processes: anfMRI study of the tip of the tongue phenomenon.European Journal of Neuroscience, 14(5):887?92.Lafourcade, M. 2007.
Making people play for Lexi-cal Acquisition with the JeuxDeMots prototype.
In7th International Symposium on Natural LanguageProcessing, page 7, Pattaya, Chonburi, Thailand.Levelt, W., A. Roelofs, and A. Meyer.
1999.
A theoryof lexical access in speech production.
Behavioraland Brain Sciences, 22(1):1?75.Levelt, W. 1989.
Speaking : From Intention to Articu-lation.
MIT Press, Cambridge, MA.Lin, C-Y and E. H. Hovy.
2000.
The automated acqui-sition of topic signatures for text summarization.
InCOLING, pages 495?501.
M. Kaufmann.Marslen-Wilson, W.D.
1990.
Activation, competi-tion, and frequency in lexical access.
In Altmann,G.T.M., editor, Cognitive Models of Speech Pro-cessing: Psycholinguistics and Computational Per-spectives, pages 148?172.
MIT Press, Cambridge,MA.Milgram, S. 1961.
The small world problem.
Psy-chology Today, 1(1):61?67.Motter, A. E., A. P. S. de Moura, Y.-C. Lai, and P. Das-gupta.
2002.
Topology of the conceptual networkof language.
Physical Review E, 65(6).Pyers, J. E., T. H. Gollan, and K. Emmorey.
2009.Bimodal bilinguals reveal the source of tip-of-the-tongue states.
Cognition, 112(2):323 ?
329.Roelofs, A.
2004.
The seduced speaker: Modeling ofcognitive control.
In Belz, A., R. Evans, and P. Pi-wek, editors, INLG, volume 3123 of Lecture Notesin Computer Science, pages 1?10.
Springer.Schvaneveldt, R., D. Meyer, and C. Becker.
1976.Lexical ambiguity, semantic context and visualword recognition.
Journal of Experimental Psy-chology/ Human Perception and Performance,2(2):243?256.Schvaneveldt, R., editor.
1989.
Pathfinder Associa-tive Networks: studies in knowledge organization.Ablex, Norwood, New Jersey, US.Shafto, M. A., D. M. Burke, E. A. Stamatakis, P. P.Tam, and L. K. Tyler.
2007.
On the tip-of-the-tongue: Neural correlates of increased word-findingfailures in normal aging.
J. Cognitive Neuroscience,19(12):2060?2070.Zock, M. and S. Bilac.
2004.
Word lookup on the ba-sis of associations : from an idea to a roadmap.
InWorkshop on ?Enhancing and using electronic dic-tionaries?, pages 29?35, Geneva.
COLING.Zock, M. and D. Schwab.
2008.
Lexical accessbased on underspecified input.
In COGALEX, Col-ing workshop, page 8, Manchester.84
