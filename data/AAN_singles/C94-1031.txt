AN EFF IC IENT TREATMENT OF JAI)ANESE VERBINFLECTION FOR MORPHOLOGICAL ANALYSISToru Hisamitsu and Yoshihiko NittaAdvanced Research Laboratory, Hitachi, Ltd.Hatoyama, Saitama 350-03, JAPAN{ hisamitu, nitta } @harl.hitachi.co.jpABSTRACTBecause of its simple appearance, Japanese verbinflection has never been treated seriously.
In thispaper we reconsider t aditional lexical treatmentsof Japanese verb inflection, and propose a newtreatment of verb inflection which uses newly-devised segmenting units.
We show that ourproposed treatment minimizes the number oflexical entries and avoids useless egmentation.It requires 20 to 40% less chart parsingcomputation and it is also suitable for errorcorrection in optical character readers.Introduct ionIn this paper we focus on lexical entries forcoping with Japanese verb inflection.
Theproblem of treating verb inflection comes fromthe nature of written Japanese, in which wordboundaries are not usually indicated explicitly.The morphological nalyzer must herefore checkfor the existence of a verb and its inflection ateach position in an input character string.As a consequence, anawkward treatment ofverbinflection may result unacceptably lowcomputational efficiency.Japanese verb inflection seems to be quitesimple.
Therefore, it has never been a centralsubject of natural anguage processing (NLP)studies.
It is also because, in the early stages ofJapanese NLP, the most ime-consuming processof the Japanese morphological nalysis (JMA)was found to be accessing the dictionary storedin a secondary memory.
Therefore greater effortwas put into designing the dictionary datastructure and methods for quick access.The situation, however, has changed.Highly efficient data structures based on theTRIE structure seem to have finally solved thedata structure problems (for instance, Morimotoand Aoe, 1993), and the access problem is alsobeing resolved by the emergence of cheap mainmemory on which the dictionary can be storeddirectly, and a dictionary-accessing chip that canaccess the dictionary thousands of times faster(Fukushima, 1991).
As a result, problem oftreating Japanese verb inflection is becomingmore import,ant.Although phonological description ofJapanese verb inflection is highly simple, itcannot be applied to JMA directly.
Because achJapanese hiragana phonogram basicallycorresponds toa consonant-vowel pair, not to aphoneme.
On the other hand, traditional schoolgrammar gives a description based on theordinary Japanese writing system, and has thusbeen widely used in JMA.
However it is neitheras rational as the phonological description or isit the most efficient from a computationalviewpoint.We reconsider lexical entries for verbinflection and propose a new method forsegmenting verbal complexes.
Though ourmethod is based on the ordinary Japanese writingsystem, it has various advantages over existingones: 1) it minimizes tile number of lexicalentries together with avoiding uselesssegmentation; 2) it requires 20 to 40% less chartparsing computation, where the parser is basedon dynamic programming and suitable for robustanalysis; 3) it is also suitable for error correctionin OCRs; 4) it requires a smaller incident matrixthan other treatments, making the morphologicalanalyzer easier to construct and maintain.Section 1 overviews descriptions ofJapanese verb inflection in terms of phonologyand in terms of traditional school grammar.Section 2 reviews three different treatments ofverb inflection in NLP, which are based on thetwo descriptions in section 1.
Section 3introduces our proposed treatment, and section4 shows the advantages of our treatment fromseveral aspects, including a quantitativecomparison of the computational efficiency of achart parser.1941 Descriptions of Japanese VerbInflectionJapanese verbs can be roughly classified intothree groups as shown in l~lble 1.
The numberof regular verbs amounts to several thousand(our dictionary for JMA has about 3000 regularverbs).
Regular verbs are classified into twogroups: consonant-stem verbs whose stems endwith consonants, and vowel-stem verbs whosestems end with vowels.
Sahen-verbs are alsoclassified into two groups: verbal nouns, whosestems can be used as nouns, and the othcrs.
Thisis the largest of the three groups (our dictionaryhas about 6000 verbs in class II).
The nmnbcr ofirregular verbs is negligibly small.Examples groupconsonant- tob-u (to fly), kak-u (to write),regular stem verbs kes-u (to extinguisl0 ....verbsvowel-stem mi-ru (to see), ki-ru (to wear),verbs sake-ru (to avoid) ....verbal nouns kenkyuu-suru (to study),sahen- kopii-suru (to copy) .....verbs ?uttari-suru (to relax),others uttari-suru (to Ire, exhausted),..kuru (to come).irregular verbs sunl (to do)Table 1 Classification of VerbsIn terms of inflection processing, Sahen~verbs are the easiest of the three: their stemsprecede the special verb "S-ltrlt" (to do), andinflectional affixes are attached to its stem 's'.Thus their inflection can be reduced to theinflection of "s-uru" and we can treat them byregistering ,all inflectional forms in the dictionary.From the same reason irregular verbs are alsoeasy to treat.
Thus the central problem is treatingthe inflection of regular verbs.
In the following,we focus on the treatment of these verbs.First of all, we give two descriptions of theinflection of Japanese regular verbs.
One isbased on phonology, the other on tile traditionalschool grammar.1.1 Phonological DescriptionIn Japanese, morphemes which correspond to"Past / Non-past", "Causative", "Passive", andso on directly follow a verbal stem as inllection,'tlaffixes.
The first study of phonological analysisof Japanese verb inflection was done by anAmerican linguist 13.
Bloch (Bloch, 1946).Unlike traditional school grammar, phonologicaldescription is based purely on phonemes, not onJapanese phonograms.
A standard phonologicaldescription of Japanese regular verbs is shown inTable 2.consotumt-stemverbExample{Past -itaIndicative Non-past -uPresumptive \[ I)ast -itaroo\[ Non-past -oohnperalive -e/ Provisional -ebaI lypothetical I.
Conditional -itara1" Infinitive -iParticipal ,~ Gerund -itet Ahernatlve -itariNegative -anaCausative -asevowel-stemverbkes-u (to exlinguish) mi-ru (to see)-la-rid-taroo- too-FO-yo-reba-tara- /-ite-itari-ha-saseTable 2Verb Inflection (Phonological IN'.scription)For example, the inflection of a verb "~i'Is-u"(kes-u: to extinguish) is as follows:kes / ana / i, :(fj ~c /,i: t~ (kesanai: Negative);kes / ase / ru, '(i'J ~c -t~_ 7o (kesaseru: Causative);kes / u, 'd'I-~- (kesu: Non-past);kes / eba, ~i'I~-IY" (keseba: Provisional);kes / e, '(\]'l't~ (kese: Imperative).Consonanbstem verbs have nineconsonants {b, g, k, m, n, i, s, t, w} as theirstem endings.
According to phonologicaltransformation, they are classified into sixgroups {b, m, n}, {k}, {g}, {t; t}, {w} and{s}.
For instance, if x <-{b, m, n}, then tiletbllowing transformation ccurs:\[\[_X\]vs ita\] v .
.
.
.
.
> \[n&a\] v,where '_x' stands for a verbal stem whoseending is 'x', 'vs' for the boundary of the verbalstem and 'v' for the boundary of the inflectedverb respectively.
This transformation is calledOnbin.
For example,yon> + -ira .... > yonda.
(to read) (Past)1.2 Tradit ional School GrammarAs stated in the introduct ion,  the phonologicalanalysis of the previous subsection cannot bedirectly applied to JMA.
Because ach hiragana195corresponds to a consonant-vowel pair, somephonological morphemes, such as 'ana' and'ase' do not appear in character strings.
Forexample, in the character string "~i~I~:~ v'(kesanai: not to extinguish), the stem 'kes' andthe negative affix 'ana' are glued together to form""d'l~tx(kesana)".
This is why the schoolgrammar " description is a little bit complex.
Theschool grammar considers the indicative non-pastform of a verb to be the "basic form".
Verbs are"transformed" when inflectional affixes areattached.
This transformation is called Katsuyou,and is illustrated in Table 3.ExampleMizen(irrealis)Renyou(Adverbial)Renntai(Attributive)Shuushi(Conclusive)Katei(Hypothetical:Meirei(Imperative)Godan(consonant-stem verb) ~-~,~ sa-\[~,ou(kak-u: kes-u:tcto Write ?xtinsui~hl(-~a ) (-sa )(-ko) (-~o )(40 -- b- ~ ~ ( - s i )(q)-<  -9 -(.ku ) (-su )-<  --J-(-ku (-su )-~t  -+2--~t  - -~(-ke ) (-se )~(ami-ichidan\] Shimo-ichidan(vowel-stem verb) wa-~,ouYL'~ ~ '~(a~-u:to meet)  mi-ru : to see\] ~(ki-ru : to wear)(-w.) _(-o)(-i ) _ _(q )-5  -?
-~(-u ) (-:u ) k ~(-~) (-~, )- : c  -~-L  -g  -~:(-e ) (-re), ( -yo)(-ru )~-~)_~-~ -2:(-re), (-yo)Table 3Verbal Inflection (School  Grammar)This time the Katsuyou of "~i~'~" is described asfollows:'I~'~ + t~ + ~ ___> ~ ~ tz ~ (kesanai),to extinguish + Neg.
+ Non-past,transformation tl'l~ ---> ti'~ ~ ;tlr~ +@)5 ---> tl~ ~'~- ;5 (kesaseru),to extinguish + Caus.
+Non-past,transformation f l~  ---> tl~J ~;.
.
.
.
.
.
, , ?t~'~ + t~ -.-> t l '~lY (keseba),to extinguish + Prov.,transformation t~ ---> fl~-~;fl\]~ +~ ---> tt\]@ (kese),to extinguish + Imp.,transformation t l~  -> tl~'~.The underlined hiragana above are calledKatsuyougobi (inflectional endings), and theinf lected forms are called Katsuyoukei.Corresponding to the Onbin transformationstated in subsection 1.1, an additionaltransformation is needed.
For example,to read + Past,transformation ,6~ .... > ~}'~/~, tz .... > tZ.Although the description above lacks uniformityand seems to be far more complicated thanphonological description, traditional JMAs havefollowed this description.2 Ex is t ing  ApproachesIn this section, we sketch some methods ofinflection analysis based on the two descriptionsstated in the previous ection.2.1 Phonological  MethodTo use phonological description for verbinflection analysis, one first needs to convert hehiragana in an input character string into a stringof Roman characters (~vmaji) corresponding tothe Japanese phonemes.
In this way, morphemessuch as 'aria' and 'ase' become observable in thecharacter string.
Lexical entries for the inflectionanalysis of regular verbs are shown in Table 4.entry"~i'lsariaaseayei tacommentsstemNegativeCausativePassivePastTable 4Examples of Lexical Enu'ies (Phonological Method)For example, "~i!l ~ :.c h" ~ :~-" (kesanakatta:did not extinguish) is analyzed as tollows:'?1'1 ~ t,~ h" -9 Tz ---> tflsanakatta---> if'Is / ana / kattakes: to extinguish / ana: Neg.
/ katta: PastWe will refer to this method with the abbreviationPM in the rest of this paper.In the case of our dictionary, whichincludes 2807 regular verbs, an extra 1598allomorphs (morpheme that are transformed fromtheir basic form) are registered to cope withOnbin transfo~xnations f regular verbs.The disadvantage of PM is that the targetcharacter strings must be lengthened as they areanalyzed.
In particular, character sequencesincluding no kanji, which must be treated inkana-kanji conversion, are doubly lengthened.To make matters worse, for all the vowels a, i, u,196e, and o, there are lexical entries with a singlevowel.
These facts deteriorate he computationalefficiency.
Thus this framework is suitable forgeneration (Kamioka, Tsuchiya nd Anzai, 1989)but not for JMA.2.2 Schoo l  Grammar  MethodAlmost all existing systems employ inflectionalanalysis based on the school grammar.
In thisframework kana-to-romaji conversion is notnecessary.
There are two different lexicaltreatments for allomorphs.2.2.1 A l lomorph ExpansionThe simplest method is to register allKatsuyoukeis as lexical entries (see qable 5).For example, allomorphs of "}l'l~-(kes-u:to ext inguish)" ,  {?l'l#, }}'Ig, }l'J'~, ?i'i-t}_l, ~1'I-~2,}I'll} are all registered.
Using these lexicalentries, the example in subsection 2.1 isanalyzed as follows:~l'~  :~.
h" o tz (kesanakatta )---> fl'J~ I :.
?h'o I tckesa : to extinguish / nakat : Neg.
/ ta : PastThis method is referred to as sg - I  in the rest ofthis paper.entry cor l l lnentsMizenkei I (Irrealis l:orm)Renyookei (Adverbial Form)Rentaikei (Attribntive Fom~)Shuushikei (Basic Form)Kateikei (Hypothetical Form)Meireikei (Imperative Form)Mizenkei 2(Cohortative Form'NegativeCausativePassivePastTable SExamples of Lexical Entries (SG-I)If SG- I  is employed, an additional 11652allomorphs requires to be registered in ourdictionary to cope with Katsuyou transformationof regular verbs.
This number of allomorphs isfar larger than the true number of verbs: andexplains why this method is not usually used inexisting systems, especially those developedwhen inemories were much more expensive.2.2.2 Separat ing  In f lect ional  EndingsThe  most popular treatment of Katsuyouinvolves separating inflectional endings andregistering them as lexical entries (see Table 6).Since the number of inflectional endings ofregular verhs is 76, the number of lexical entriesis far smaller than in PM or SG- I .
For thisreason, this nlethod has been considered to bethe best one.
This time the same example isanalyzed as follows:~l!i~ta:h'otc .... > ~l'i/~ /ta:'h,o/t~kesanakatta ke\[s\]: to extinguish / sa: ~ /\[a\]nakat: Neg.
/ ta: PastWe will refer this method as SG- I I  in the rest ofthis papeLet~trs~ _LT*LcolnmetltsstemMizenkei inflectional endinglRenyookei inflectional endingRet, taikei nflectional endingShuushikei inflectional endingKateikei intlectional endingMeireikei inflectional endingMizenkei inflectional ending2NegativeCausativePassivePastTable 6l:.xamples of Lexical Entries (SG-II)Itowever, analysis by SG- I I  requires onemore segmentation than PM and S G-I.
Worsestill, the segment / ~/has no meaning, thus thissegmentation is useless.
Since memories havebecome much lower in price, this problem cannotbe disregarded.3 Proposed  lmx ica l  q ) 'eatment  o fJapanese  Verb  In f lec t ionIn tile previous section we described threedifferent lexical treatments.
Here we summarizetheir advantages ~m(l problems:1) PM is the simplest but is not directlyapplicable to ordinary written character strings.2) S G- I  realizes the minimum segmentation butrequhes a large number of allomorphs mnountingto several times the original number of regularverbs.3) S G - I 1 requires the smallest number of lexicalentries, but causes useless egmentations.Only our proposed lexical treatment can solvethese pmt)le,ns.197Let us explain our approach using the sameexample.
In PM, the character string "ti'-I ~ t.~ :~" -9F~ (kesanakatta)" is analyzed as "tl\]s/ana/katta",where the ending consonant's' of the stem "ti'Js"and the head vowel 'a' of the affix 'ana' comefrom the phonogram '~(sa)'.
Here recall thatneither 's' nor 'a' itself has a correspondingphonogram in the original character string.
Theschool grammar description gives an observablelexical entry 't i f f '  by concatenating the headvowel 'd of 'aria' to the tail of 'tj'ls'.
It may belinguistically appropriate, but computationallynot; there can be ,an alternative.We attach the consonant's' to the head of' aria' and generate an entry ' ~ t~ (sana =s+cma)'as a kind of an allomorph of 'am'.
At the sametime, the stem '~'i~ ' is marked as a morphemewhich can only be followed by "s-attachedinflectional affixes", that is, {#~ (s+ase:Causative), ~ (s+are: Passive), #/.~ (s+ana:Negative ..... }.
Other lexical entries are generatedin the same manner (see Table 7).entry comments~t.~LL:stemNegative (s + aria)Causative (s + ase)Passive (s + ,are)Past (s + ita)Table 7Examples of Lexical Entries (Proposed Method)This time the previous example is analyzedas follows:~t'~ t~.
7), o tz (kesanakatta)---> ~H I "$ t~.
I t ) 'o  \]'zke(s): to extinguish /sana: Neg.
/ katta: PastIt is obvious that this segmentation givesexactly the same semantic information as theother methods.
This time the number of"allomorphs" is only 125, which is comparableto one of SG-I I .
On the other hand, the numberof segments i as same as that of SG- I  in thisexample.
In the next section we discuss theadvantages of our proposed method.4 Advantages  of  P roposed  Lex ica lT reatment4.1 The Number of AllomorphsAs stated in the previous ections, SG- I  and ourproposed method require almost the samenumber of allomorphs, which is far smaller thanthat of the other methods.4.2 Quantitative Comparison of ParsingEfficiencyIn order to compare the computational efficiencyof each method, we used a chart parsingalgorithm (Hisamitsu and Nitta, 1991) and threedictionaries based on SG-I ,  SG-I I ,  and theproposed method.
Here we only sketch theoutline of the algorithm (See F ig.
1).o ' l  0"2 ............... a j : l  o ' j  ............ O'n-I r ln  : inputeharaeter, ', ', - string s?j-I - I I  : ' - - I  "~-a M irol l ,  I '  ' I I ', 1'1 .
.
.
.
tnl' F I ,  I | i  em,  / , ,  .
mI m21, F~ i I ~ , n  k ml" ' t '7) ~ c='N,,~.F2!
L .~ I - -  ~ "/ ,  l - -m 'n :~- - - -  Registering a New Element e' I ) ,T  k : Partial Path Liste i. e : Element of Partial Path ListF/F : Accumulated Cost o!
Partial SolutionMj  : Morpheme Listm?
m k : MorphemeFigm-e l Illustration of Chart ParsingHere s denotes an input string ,r~'" o" n. Acandidate-word lattice {Ml, '" ,  Mn} is used forrecording candidate morphelnes, where MJrecords the morphemes extracted at position j.Partial path lists {T1,'", T n} are used forrecording the fragments of partial solutions,where Tj contains fragments of partial solutionswhich reach the j-th position in s. An element inT k (1-<2_k<n) has the form {m, C, {<mr,C1>,... <mr,, Ck>} }where m is the last morpheme ofpartial solutions al,  " "  a k,  C is their commoncost, and <mj, C j> is the preceding morphemeof m at a,;j {<m ,1 Cl>, " ' ,<m ,k Ck>} isregarded as a "pointer" for tracing solutionsbackward.
The elements of T k are calculatedusing Tj and Mj+ l, where 1 Nj<n-1,  and j_<k <n.
Once the Partial path lists {T 1, "", Tn} isconstructed, the solutions are extracted by depth-198first backtracking to trace pointers backward.To enable a quantitative comparison, weuse the following three measures, which reflectthe eff ic iency of chart parsing and areindependent of implementing variations:A) Total number of morphemes contained inmorpheme lists {M 1 ..... M n }.B) Total number of tests which check for theconnectability between partial-solution fragmentsin Ti ,,rod morphemes in Mj+ t.C) Total number of elements contained in partialpath lists {T 1 ..... Tn}.Figure 2 compares the three methods.The comparison was made using 100 sentencestaken from Nikkei Shinbun, which contain a totalof 5286 characters.
The dictionary containedabout 60000 words.
Our proposed method is farmore efficient than the most popular methodSG- I I ,  and its efficiency is comparable to that ofSG- I .ratio1.00.82\[10"8~ 6!
~ 0.78I~-~ I Proposed {il I Methodmeasures o (A) (B) ~ (c)Figure 2 Comparison of Three Methods4.3 Application to OCR Er ror  CorrectionRecently, nmrphological analysis has beenapplied more extensively to various systems,especially to error correction in OCRs (opticalcharacter readers).
In general, a characterrecognition module outputs a sequence of listswhich include candidate characters at eachposition in the pattern sequence.
Each candidatecharacter is given a positive confidence ratio (seeFig.3).
We call the sequence of lists "candidatecharacter lattice".
Note that the character string ofthe top candidate characters, which is the finaloutput of a bare character ecognizer, is notnecessarily the cmxect sentence.To correct the errors, we use two mainprocesses: 1) constructing a candidate wordslattice by using the candidate character lattice anda dictionary; 2) extracting plausible wordsequences from the candidate words lattice.Generally process 1) is time-consuming,because we need to find potential wordcandidates fi'om the combination of candidatecharacters at each position.
To avoidcombinatorial explosion, a skillful method hasbeen widely used in error correction (Takao andNishio, 1989): at each position, frst  extract allwords whose first character matches the topcandidate character at the position, secondlycompare those words with the candidatecharacter lattice.input: "}i'J ~ ~ ~" --9/'c"Candid.
'tte Characters Position1 ((~\]'j, 0.79) 0JJJ, 0.72) (ll)J, 0.64) ...)2 (( ~", 0.81) (~, 0.79) (~, 0.58) ...)3 ((/at, 0.72) (/'2", 0.69) (L:, 0.65) ...)4 ((h', 0.89) (Ca ~, 0.86) (3J, 0.75) ...)5 ((o, 0.82) (o, 0.81) UC, 0.77) ...)6 ((/~, 0.84) (/Z, 0.82) (cat, 0.76) ...)Figure 3Example of Candidate Character LatticeFor this method to be effective, the lexicalentries should lye as long as possible, because alonger entry is easier to recover when one or twocharacters are ntis-recognized.
There should alsobe as few entries as possible whose firstcharacters coincide.In terms of the former requirement, ourproposed method is obviously better than S G-1I.
Although SG- I  results in the longest lexicalentries, it is the worst in terms of the latterrequirement because ach verb has basically sixallomorphs in the dictionary, and the firstcharacters of these words are inevitably thesame.
For this reason, our experiments haveshown that error correction based on the S G- Idictionary is 3.6 times more time-consumingthan error correction based on the proposeddictionm 7.
Thus out" proposed method is themost suitable lot- this purpose.4.4 Other  Advantages4.4.1 Incident Matrix SizeCompared with S G- I and S G- I I, our proposedmethod reduces the size of the incident matrix,because, using our lexical entries makes it199unnecessary to check for connection between aKatsuyougobi and various inflectional ffixes.4.4.2 The Number of Free Parameters inStatistical HeuristicsIn obtaining a (simple) Markov model, one maynotice a major difference between the proposedmethod and SG-I.
Figure 4 (a) illustrates thelinguistically possible incidence between ourlexical entries including a verbal stem v. Toconstruct a probabilistic likelihood function, oneneeds to estimate all of the free parameters Pwv,where Pwv denotes the transition probabilityfrom word w to v. Since a verbal stem cansucceed almost all grammatical categories, thenumber of parameters {Pwv} (= N(v)) is almostequal to the number of all categories.a) Proposed Method b) SG-I?
.
.
,,,.,~,,.
:_~,,, -.
.~Inflecllonal Words "',Words Affixes : "" :v: Stem of a Verbv i :  Intlected Form of vFigure 4Difference Between Two Methodsin Constructing l~obabilistic ModelsInflectionalAffixes andOther WordsWith SG-I, the number of parameters{Pww, Pwv2 .... } is about seven times as large asN(v), where 'v i' denotes a Katsuyoukei of theverb v (Fig.4 (b)).
In other words, the numberof free parameters i inevitably increased byusing S G-I.5 Fur ther  S tudyIn subsection 4.2, we used a standard chartparser based on dynamic programming for thecomparison.
While the parser itself is robust andefficient, there are several kinds of parsingmethods.
For example, the longest matchingmethod ispopular.
Actually, our lexical treatmentis also effective for such a parsing strategy.
Wewill also make an experimental comparison basedon various parsing methods.6 Conc lus ionIn this paper we reconsidered lexical entries forverb inflection and proposed a new way ofsegmenting verbal complexes that has variousadvantages over existing methods: 1) itminimizes the number of lexical entries andavoids useless egmentation; 2) it requires 20 to40% less computation than standard chartparsing; 3) it is suitable for error correction inOCRs; 4) it requires a smaller incident matrixthan other treatments, thus making it easier toconstruct and maintain the morphologicalanalyzer; 5) it is the most suitable for obtainingstatistical heuristics because it can intrinsicallyreduce the number of free parameters.ReferencesBloch, B.
(1946), "Studies in ColloquialJapanese, Part I, Inflection", Journal of theAmerican Oriental Society 66.Fukushima, T., (1991), "A MorphemeExtraction Hardware Algorithm and ItsImplementation", Transaction of lPSJ,Vol.
32, No.
10, pp.
1259-1268.Hisamitsu, T. and Nitta, Y.
( 1991), "A UniformTreatment of Heuristic Methods forMorphological Analysis of Written Japanese",in Prec.
of the 2nd Japan-Australia JointSymposium on Natural Language Processing,pp.
46-57.Kamioka, T., Tsucbiya, T. and Anzai, Y.
(1989), "Generation and Representation fPredicate Complex", Trans.
oflPSJ, Vol.
30,No.
4, pp.
457-466.Morimoto, K. and Aoe, J.
(1993), "Two TrieStructures for Natm'al LanguageDictionaries", in Prec.
of Natural l_zmguageProcessing Pacific Rim Symposium (NLPRS'93), pp.
302-311.Takao, T. and Nishio, E (1989),"hnplementation and Evaluation of Post-Processing for Japanese Document Readers",Trans.
oflPSJ, Vol.
30, No.
11, pp.
1394-1401.200
