Recognizing Digressive Questions During Interactive Generation *Susan  M.  Ha i le rDepar tment  of Computer  Science and  EngineeringUnivers i ty  of Wiscons in  - Parks ideKenosha ,  Wiscons in  53141haller?cs, bufgal o. eduiAbst rac tIn expository discourse, people sometimes ask ques-tions that digress from the purpose of the discussion.A system that provides interactive xplanations andadvice must be able to distinguish pertinent questionsfrom questions that digress.
It must also be able .torecognize questions that are incoherent.
These types ofquestions require different reatment.
Pertinent ques-tions must be answered to achieve the discourse ~phr~ ~pose.
If the user asks a digressive question, the sys-?tem may need to shift the focus of the discussion back 'to the original-purpose.
Incoherent questions ignal amore serious misunderstanding that requires clarifica-tion and repair.The Interactive Discourse Planner (IDP) is designedto plan text to describe and/or justify a domain planinteractively.
As a testbed, IDP plans text to discussdriving routes.
IDP uses questions from the user torecognize how to extend its own text plan in a waythat both satisfies its listener and achieves the system'sdiscourse goal.
In the process of recognizing ways toexpand its own text plan, IDP can detect hree types ofdigressions that the user can initiate with a question.1 Character i z ing  D igress ionsGrosz and Sidner define a digression as a type of :inter-ruption \[4\].
An interruption is a discourse segment witha purpose that does not contribute to the achievement ofthe current discourse purpose.
They describe three kinds.A true interruption has a discourse purpose that is unre-lated to the interrupted iscourse segment.
For example, ifa speaker says"John came by and dropped off the groceries Stop thatyou kids.
and I put them away after he left.
"the italized portion of text is a true interruption.Speakers use a second type of interruption, the flashbackor filling ~n missing places to bring objects and propositionsinto the discussion that aid in comprehension f the currentdiscourse segment.
This type of interruption provides back-ground knowledge.
However, it does not contribute directlyto the current discourse purpose.
For example in*I would like to thank  my advisor, S tuar t  C. Shapiro,  and themembers of the SNePS Research Group in the Computer ScienceDepartment at the State University of New York at Buffalo.Their advice and comments are reflected in the research thatthis paper describes."OK.
Now how do I say that Bill is Whoops I forgotabout ABC.
I need an individual concept for the com-pany ABC... Now back to Bill.
How do I say that Billis an employee of ABC?
"the speaker sets aside her current purpose to discuss a pre-?
.
requisite that should have been introduced earlier.We are concerned with a third type of interruption thatGrosz and Sidner describe as a digression.
A digression con-?
tams a reference to some entity that is salient in both theinterruption and the interrupted segment.
The digression'sPUrpose is not unrelated to the purpose of the interruptedsegment (as in a true interruption), but neither is it a pre-requisite (as in a flashback).
As an example of a digression,Grosz and Sidner note that if while discussing Bill's role incompany ABC, a conversational participant interrupts withSpeaking of Bill, that reminds me, he came to dinnerlast week,Bill remains alient, but the discourse purpose changes.In the IDP model, the system's purpose (or intent) isexpressed by its discourse goal and the text plan that thesystem formulates and executes to try to achieve it.
IDPdetects a digression when the user asks a question abouta discourse ntity or a proposition that is part of the sys-tem's text plan, and the answer to the question cannot beir/corporated into the text plan.IDP Operates in a cooperative interactive mode in whichthe System is the primary speaker and the user is the pri-mary listener.
Henceforth, I refer to the user as the lis-tener.
In this interactive mode, IDP controls the discussionto make its own intentions clear and to try to achieve them.2 D igress ion  TypesThe first and simplest kind of digression that IDP can de-tect is when the listener asks a direct question about aproposition that was expressed by the system earlier in thediscourse.
The following interaction demonstrates this kindof digression and how the system responds to it.
1i ?
.1All demonstrations given in courier font are actual  inter-actions with IDP.1817th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994Demonst ra t ion  I:L: Should I take Maple or Sheridan to go tothe Eastern Hills Mall?IDP: if now there was light traffic,you could take Sheridan however,now there is heavy traffic.you should take Maple.since taking Maple there are fewerbusinesses than taking Sheridan,taking Maple avoids heavy traffic.L: Why is there heavy traffic now?
*IDP: s ince now is rush hour,as I was saying taking Maple avoidsheavy traffic.As part of IDP's advice, it has expressed a propositionthat lets the listener know circumstances that motivate theadvice.
In particular, IDP has told the listener that nowthere  is  heavy t ra f : f i c .
The system identifies the lis-tener's question about this statement (marked with an as-terisk) as a digression from the discussion purpose.
There-fore, after answering the question, IDP shifts the discussionback to its recommendation.A second kind of digression that IDP can detect is whenthe listener questions a proposition that was never ex-pressed, but that can be inferred from a proposition thathas been presented.
The following demonstration illustratesthis digression type.~he listener's line of questioning keeps referring to the lastproposition that was expressed.
This eventually leads to anexplanation that does not address IDP's original purpose.The following interaction illustrates digressions of this kind.Demonst ra t ion  3:L: Should I take Maple or Sheridan to go tothe Eastern Hills Mall7IDP: take Maple.L: Why7IDP: taking Maple avoids heavy traffic.L: Why?IDP: taking Maple there are fewerbusinesses than taking Sheridan.L: Why?
*IDP: since taking Maple is a newer routethan taking Sheridan.anyways, taking Maple avoids heavytraffic.Unlike the first two questions, the listener's third why-question requires an answer that cannot be incorporatedinto the IDP's text plan, a plan for trying to convince thelistener to use the Maple Road route.
Therefore, the systemdetects a digression.3 Related  WorkDemonst ra t ion  2:L: Should I take Maple or Sheridan to go tothe Eastern Hills Mall7IDP: take Maple.L: Why take Maple?IDP: taking Maple avoids heavy t ra f f i c .L: Why?IDP: since taking Maple there are fewerbusinesses than taking Sheridan.L: Why is there heavy traffic now?
*IDP: since now is rush hour,as I was saying taking Maple avoidsheavy traffic.IDP uses its text plan to detect that the listener's thirdquestion, unlike the listener's first two questions, initiates adigression.
This is notwithstanding the fact that the systemnever expressed the proposition that the listener questions.The listener's digressive question relies on an inference thatshe made from the proposition that IDP conveyed in itssecond response.IDP does not analyze every question as a digression.Demonst ra t ion  2a:L: Should I take Maple or Sheridan to go tothe Eastern Hills Mall?IDP: take Maple.L: Why is there heavy- t ra f f i c  now?
*IDP Huh?In this example, IDP fails to make any coherent connectionbetween the question and the text plan that they systemhas used so far.
Note that the answer to this question doesnot fall outside the system's expertise.
In Demonstration 2,IDP analyzed this question as a digression, and respondedto it.A third type of digression that the system detects is whenMoore and Swartout note that prior to their work on theEES Text Planner, little work had been done on using asYstem's goals and plans as a model of the discourse andits purpose \[11, 12\].
The EES Text Planner records itsdiscourse goals and the plans that it formulates to achievethem in a dialogue history.
When the user asks a follow-upquestion, the system uses the goal structure of its text plan,assumptions that have been made during generation, andalternative plans that it did not use to disambiguate thequestion and select a perspective for the answer to it.
Thenthe system formulates the appropriate discourse goal andpasses it to the text planner to formulate a response.The dialogue history is a stack of text plans from previ-ous exchanges.
Each text plan in the stack has a pointer toa goal (called the global contex 0 that the text plan has beenconstructed to achieve.
However, the stack ordering is theonly relationship among the text plans and their respectivegoals.
There is no representation of the overarching oalfor the interaction or how the plan for each exchange con-tributes to it.
Therefore, the system cannot detect when theuser's follow-up question results in planning for a discoursegoal that does not contribute to the original discussion pur-pose.The IDP model treats the system's text plan as a richersource of information.
To produce answers to follow-upquestions, IDP replans or expands a single text plan thathas an overarching discourse goal.
In this respect, IDP issimilar to the Explanatory Discourse Generator (EDGE)\[2\].
EDGE plans tutorials by formulating a single text planin advance and then executing it incrementally.
EDGE usesfeedback from the listener to monitor the success of its planthereby making decisions to prune or extend parts of it thathave not been used yet.Planning text ahead is appropriate when a system planstutorials.
In this situation the system has a structure of1827th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994preset goals for the interaction.
In contrast, IDP is designedfor domains where there is no agenda for what the listenerwill come to know as a result of the interaction.
IDP planstext to give advice and answer questions until the listener issatisfied.
Therefore, like the EES Text Planner, IDP plansonly in reaction to foll0w-up questions.
However, to keeptrack of where the interaction is going, each plan that IDPconstructs extends a single text plan that is formulated toachieve an overarching discourse goal.4 Text  P lan  Operators4.1 The  P lann ing  Formal i smIDP's text plan operators (TP-operators) are based onRhetorical Structure Theory (RST) \[9\] and are written us-ing the SNePS Actor planning formalism \[16\].
In RST,each essential text message (called the nucleus) can be aug-mented with additional information (called the satellite)through a rhetorical relation.
In the SNePS Actor plan-ning formalism, plan operators are written as rules thatstate what consequent propositions can be deduced from aset of antecedents.Figure 1 shows a TP-operator for the motivate act.
~ Inthe formalism, an act decomposes into one or more struc-tures of other acts called plans.
IDP deduces propositionsthat state how acts decompose into plans (ACT-PLAN caseframe) by satisfying a rule's antecedents.
These are theconstraints on the plan, and the process of constraint satis-faction selects new content for the text.
For TP-operatorsthat are based on rhetorical relations, this new content isa satellite proposition that is appropriate to the rhetori-cal relation and the given nuclear proposition.
The sameconstraints are used to write rules for deducing the precon-ditions of the motivate act (ACT-PRECONDITION caseframe), the effects of the act (ACT-EFFECT case frame),and the goals that the act (viewed as a high-level plan) canbe used to achieve (GOAL-PLAN case frame).The TP-operator in Figure 1 is an asserted rule (indicatedby !)
stating that for all (FORALL) ?gl, ?g2, and ?p, if theantecedents (ANT) can be satisfied, then the consequentproposition (CQ) can be deduced.
The TP-operators aredomain-independent because the constraints on them arestated in terms of the planning formalism.
Hence, IDP'sTP-operators are for producing text about a set of domainplans that are under discussion.In Figure 1, the constraints are that ?gl must be a goal-act, act ?gl must be enacted by a plan ?p, ?g2 must be asecondary goal-act, and act ?g2 must also be enacted byplan ?p.
If an instantiati0n of?gl, ?g2, and ?p satisfies theconstraints, then the system can deduce a plan for the actof motivating the user to do ?p.
This plan is a sequence(snsequence) of four other acts.
The snsequence act is oneof six control acts that are used to structure several actsinto a plan for an act.4.2 The  K inds  o f  Text  P lansIDP uses two types of text plans (TPs) separating thoseplans that address the system's discourse goat (DG) di-rectly, from those plans that provide additional informationthat augments he system's essential text message.
The two2Arguments enclosed in braces,{...}, are unordered setarguments.
!FOKALL-ANT-CQ({?gI,?g2,?p},{GOAL-ACT(?gl),ACT-PLAN(?gI,?p),SECONDAB.Y-GOAL-ACT(?g2),ACT-PLAN(?g2,?p)},ACT.PLAN(motivate(user,DO(us,r,?p)),snsequenee(advise(user,DO(user,?p)),circumstantiate(ACT-PLAN(?g2,?p)),$ay(ACT-PLAN(?g2,?p)),restate(ACT-PLAN(?g2,Zp)))))Figure 1: A TP-operator for Motivatekinds of TPs are discourse text plans (DTPs) and content-selection text plans (CTPs).
The overarching plan is alwaysa DTP.
This is consistent with Moore and Pollack's con-tention that a speaker always structures information i  adiscourse with an high-level intention in mind \[14\].This division is based on a two-way division of the rhetor-ical relations that Mann and Thompson describe and thathas been used by Haller \[5, 6\] and Moore and Paris \[13\]to design systems with two types of text plans.
Each pre-sentational relation relates two text spans for the purposeof increasing an inclination in the hearer.
In contrast, asubject-matter relation is used with the intent of informingthe hearer of the rhetorical relation itseI?
In the IDP model,DTPs are used to attempt and reattempt the achievementof the system's discourse goals (DGs).
Since these goalshave to do with affecting the listener's attitudes and abili-ties towards domain plans, DTPs are based on speech actsand presentational rhetorical relations.
The DTPs describehow to try to achieve DGs by selecting some minimal textcontent.
IDP can augment this content without detractingfrom its own intent by using one or more CTPs.
Therefore,CTPs correspond to subject-matter rhetorical relations.Figure 2(a) shows a DTP for motivate that IDP instanti-ates from the TP-operator given in Figure 1.3 The motivateact takes the listener and a nuclear clause (the listener DO-ing the *Maple-plan) as its arguments.
The DTP for moti-vating the listener to take the Maple Road route sequencesup to four other acts.
The first act in the sequence, advise,is another DTP that must be expanded if the system hasnot already used it.
The third act, say, is the only primitiveact.
When the system executes it, a text message is sent toIDP's surface generation grammar.
The second and fourthacts, circumstantiate and restate, are references to CTPsthat are potential plan growth points.
Growth points arereferences to CTPs that are embedded in the body of eachTP along the active path.
Growth points suggest ways ofadding content hat augment the current TP \[7\].A plan for circumstantiate is given in Figure 2(b).
SinceCTPs are not executed to affect the listener in any wayother than to provide information, the listener is not anargument to acts for CTPs.
IDP can only deduce a CTPfor an act when there is an active content-goal (CG) thatthe plan satisfies.
A constraint on all CTP-operators re-quires there to be an active CG to let the listener know theproposition that will be the satellite in a subject-matterrhetorical relation.As shown in Figure 2(b) as the second step in executingS'Maple-plan represents a plan structure stated in terms ofgoing and turning acts that is not shown here.1837th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994!ACT-PLAN(motivate(listener,D O(listener,*Maple-plan)),snsequence(advise(list ener,DO(listener,~Maple-plan)),cireumst antiate(ACT-PLAN(avoid(heavy-t rattic,Maple-plan))),say(ACT- PLAN(avoid(heavy-t rafS?,=Maple-plan))),rest ate(ACT-PLAN(avoid(heavy.t raffle,*Maple-plan))))) (a)!ACT-PLAN(cireurast antiat ?
(ACT-PLAN(avoid(heavy-t raffic,SMaple-plan))),snsequence(say(OB J- PR0 P(W'Maple-plan,fewer-businesses)),disbelieve(CONTENT-GOAL(KNOW(listener,OB J-PB.OP(~Maple.plan,fewer-businesses)),(b)Figure 2: (a) A DTP for Motivate (b) A CTP for Circum-stantiatethe circumstantiate CTP, the CG is retracted (disbelievedby the system).
Because the ACT-PLAN proposition is de-ducible only when the CG exists, the SNePS Belief Revisioncomponent (SNeBR) \[10\] retracts the ACT-PLAN propo-sition from the knowledge base as part of the execution ofthe CTP.
Unless there is an active CG the CTP cannot bededuced.
This keeps the CTP from being expanded andused even though it appears in the body of DTPs like theone for the motivate act (Figure 2(a)).5 The  Ana lyzer5.1 The  D iscourse  ContextTo make the several sources of information that are neededfor highly interactive xplanations available, I representthem uniformly using the SNePS Semantic Network Pro-cessing and Reasoning System \[15\].
IDP's DGs are un-achieved system goals that have to do with the attitude orabilities of the listener toward a domain plan.
In the roleof the primary speaker, IDP can post one or both of thefollowing DGs:1. to have the listener adopt a domain plan2.
to have the listener be able to execute a domain planIDP plans text to try to achieve its DG, and it interprets thelistener's feedback in the context of three types of knowl-edge that are all related to its TP:1. the active path2.
growth points3.
the localized unknownsFollowing Carberry, once the listener knows the system'sintention and how it has been realized, she has expecta-tions for what will follow \[1\].
Motivated by Grice's Maximof Relation \[3\], IDP analyzes questions using growth pointson the active path.
The active path marks the TP thatmake up the most recent expansion of IDP's overall TP.IDP also uses a set of propositions called the localized un-knowns.
The localized unknowns are propositions aboutdomain plans and domain-related reasoning that, based onthe model of the listener, the listener does not know.
Thelocalized unknowns are linked to the system's TP by thereasoning chains that the system used to derive it TP.5.2 The  Local  TopicIn the IDP model, questions address the system's DG indi-rectly by making reference to what the system is doing toachieve its DG.
Therefore, IDP's Analyzer uses feedback totry to recognize a TP to use to expand or replan its cur-rent TP.
Following van Kuppevelt, the local topic is thatwhich is questioned, and the comment on the local topic isan answer to the question \[18\].
For each question, IDP'sAnalyzer determines the local topic and then searches for away to expand its TP to include a comment on it.The Analyzer processes questions in one of the followingforms:1.
Why {not}?2.
Why {not} plan?3.
Why {not} proposffion?
{not} indicates that the word "not" is an optional con-stituent of the input string.
The local topic is a domainplan or a proposition.
When there is a simple why-question(1), the local topic is the last proposition that was expressedby the system with a say-act.
If the question is in the formof 2 or 3, IDP makes the plan or proposition that is men-tioned the local topic.5.3 A Measure  of  CoherenceFrom the generation perspective, a conversation is a com-municative process that the system controls for its own pur-pose.
In this context, the appropriate measure of coherenceis the degree to which a new TP-expansion contributes tothe achievement of the system's goal.
Discourse xpecta-tion constrains IDP's choices to the growth points in theDTPs along the active path.
An important heuristic in se-lecting a TP-expansion is the degree to which the proposedexpansion highlights the system's intent as realized by theDTP-level portion of its TP.
Therefore, IDP considers thegrowth points for the DTPs on the active path in the fol-lowing order:1.
DTPs that replan a DTP2.
CTPs that expand a DTPIDP prefers DTPs that replan a DTP over CTPs that ex-pand a DTP.
This encodes a preference for plans that high-light the system's intent over plans that supply additionalinformation.In the first phase, IDP analyzes why-questions in rela-tion to its own intent as represented by the DTPs along theactive path.
The Analyzer starts with the most recentlyexecuted DTP (the last DTP on the active path), and thelocalized unknowns associated with it.
It tries to find an-other way to expand a DTP along the active path that letsthe listener know a localized unknown.
The Analyzer backsup the active path testing each DTP in turn.
If this fails,in the second phase, the Analyzer considers augmentingthe existing DTP at the informational level.
This level isreflected in the CTPs.
The Analyzer examines the most fo-cussed DTP on the active path to see if it can he expandedwith a CTP to let the user know a localized unknown.
Adetailed account of this type of processing is presented in\[5\].1847th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994co/DO (listener, =adopt ('Maple-plan))/comend (listener.
DO(listerle~ ,*Maple-plan))pt.A.~ ' ~ motive (listener, DO( listener, Msple-plaa)lSdZisC (.
.
.
.
.  )
// / ' -say( ACT-PLAN (avoid{l~avy-tramc), *Maple.plan)))Pl.
;t./ V~h~rllslanllat~ ''taking I-tapl .
.
.
.
iris heavy traffic.
''t * "ACT-P~( at, old(heavy-frame) *Maple-plan))) say ( DO( listener.
Maple-planD I'take Maple. '
' ~.~I~/say( FEWER-BUSINESSES( *Maple-plan, *Sheridan-p\]anD' "since taking Maple there are fewer businessesthan taking Sheridan. '
'Figure 3: The TP for Before the Digressive Question inDemonstrations 2 and 3IS -D IGRESSION( f  b)Let top ic  := IS -D IGRESSION-TYPE- I ( fb )orIS -D IGRESSION-TYPE-2( fb )orIS -D IGRESSION-TYPE-3( fb )  ,If topicThen Let c tps  =: get-ctps-with-nucleus(topic)Let re la ted- reason ing  =: get-reasoning(2,topic)Loop-for-each ctp  in c tpsI f  list ener-knows(effect-of(ctp))ornot(member(e~ect-of(ctp), related-reasonlng))Then Let ctps  := remove-from(ctps, ctp)End- loopIf  more-t han-one(ctps)Then Let etp- to -expand =: get-simplest-plan(ctps)Else Let t ip - to -expand =: ctpsI f  ctp -expans ionThen post-content-goal(KNOW(listener,effect-of(ctp-to-expand)))ret u rn( ct p--to-expand)Else return('nU)5.4 An Example  TPFigure 3 shows IDP's TP after its third response in Demon-strations 2 and 3.
The TP has been formulated to achievethe DG of having the listener adopt he plan to take MapleRoad.
The high-level plan is a DTP which can decomposeinto other DTPs and CTPs.
The TP always bottoms outin the primitive act, say.
The argument to the say act isa text message which includes a proposition as the contentto be expressed.In the TP, the checks (x/) mark the active path.
Notethat the plan for motivating the listener has not been ex-ecuted in the order indicated by the sequencing act snse-quence (see Figure 2(a))i In particular, to make the initialrecommendation the planner selected a simple plan (advise,indicated by a dashed line) over a more complex plan (mo-tivate).
In response to the listener's first why-question, IDPreplanned the recommendation with the more complex mo-tivate act.
Since its recorded TP indicated that it had justused the advise act, the only act in the plan for the motivateact that must be executed is the say act.
This act conveysthe satellite proposition ~that counts as the motivation forthe advice.The second act in the plan for motivate, circumstantiateexpands to an optional CTP.
IDP does not expand and usethis plan until it responds to Why?
a second time.
This hap-pens because IDP replans and expands its TP in reactionto the listener's questions.6 Detecting Digressive QuestionsIf the Analyzer fails to recognize a way to replan Or ex-pand its own TP from the listener's feedback (Section 5.3),it tests the feedback to See if is a digressive question.
Fig-ure 4 gives the algorithm that the Analyzer uses for theIS-DIGRESSION test.
:The Analyzer tests the feedback(fb) in two stages.
First, the Analyzer tests to see if thefeedback has the correct form and content for one of threekinds of digressive questions that the system can detect.
Ifone of the three tests succeeds, it will return a propositionthat is the topic (topic) for the digression.
The topic isthe proposition that the listener questions in her digressivequestion.In the second stage, if there is a topic, the Analyzer col-lects CTPs (ctps) that use the topic as a nuclear proposi-Figure 4: Detecting Digressive Questions from the Lis-tener's FeedbackIS-DIGRESSION-TYPE-1 (fb)If fb = "Why" {"not" }propositionandDONE(system, say(proposition))Then return(proposition)Else return('nil)Figure 5: Test 1: For Detecting Digressive Questions Basedon What the System Said Previouslytion.
It also collects domain reasoning that the system hasperformed that is related to the topic (related-reasoning).The Analyzer tests each CTP  and removes any CTPs  thathave the effect of letting the listener know a propositionthat she knows already.
It also removes a CTP  if its effectis not one of the related reasoning propositions.
If there isstill more than one candidate CTP,  the Analyzer picks thesimplest (ctp-to-expand).
If a CTP  has been found thatmeets all of the requirements, the Analyzer posts its effectas a CG and returns it for the Planner-Actor to expandto answer the question.
If there is no such CTP, then thedigression test fails.6.1 Detect ing  Digressive Quest ions  AboutWhat  has been  SaidThe simplest kind of digression that IDP can detect is whenthe listener asks a direct question about a proposition thatwas expressed as part of the system's TP.
The Analyzer usesthe first digression test, IS -DIGRESSION-TYPE- I ,  that isdescribed in Figure 5.
If the feedback (fb) is a question inthe form "Why" {"not"} proposition and the system hassaid the proposition as part of its TP, then the propositionis returned as the topic for the digression.
Otherwise, thefirst test fails.The first test is used to detect the digression in Demon-stration i.
Figure 6 gives IDP's TP  just before the listenerasks the digressive question in that example.
When the lis-tener asks Why is there heavy traffic now?, the Ana-lyzer tries to find a way to expand the DTP-portion of its1857th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994TP on the active path (Section 5.3).
This involves earchingthe growth points in the DTPs for motivate, concede, andrecommend.
When this fails, the Analyzer tries to processthe feedback as a digressive question.Testing for a digression (Figure 4) with the first digressionrule (Figure 5), the Analyzer checks the TP in Figure 6 tosee if the proposition in the listener's question was saidby the system.
The Analyzer finds that it has been said(Figure 6 in boldface).
Therefore, the first digression testsucceeds, and the following proposition is returned as thetopic of the digression:OBJ-PROP(now, heavy-traffic)The Analyzer finds another CTP that uses the topic as anucleus:circumstantiate(OBJ-PROP(now, heavy-traffic))and collects reasoning that is related to the topicACT-PLAN(avoid(heavy-traffic), *Maple-plan)OBJ-PROP(now, rush-hour))SECO N DARY-GOAL-ACT(avoid(heavy-traffic))The CTP's effect,KNOW(listener,OBJ-PROP(now, rush hour))lets the listener know a new satellite proposition: now isrush hour.
Since (he listener model does not assert hat thelistener knows this proposition, and since this proposition isrelated by domain reasoning to the topic, the CTP remainsas a candidate for expansion.
So that IDP's Planner-Actorcan instantiate a plan for this CTP, its effect is made a CG.Then the CTP is returned for the Planner-Actor to expandinto the TP.
This leads to the restatement found in the lastline of IDP's response in Demonstration 1.6.2 Detect ing  D igress ive  Quest ions  AboutIn fe r red  Propos i t ionsIn Demonstration 2, IDP never expressed the propositionthat the listener questions.
Therefore, the listener musthave inferred it.
In this case, the system cannot determinethat the question is digressive simply because the answeris something that the listener does not know.
Such a rulewould not distinguish digressive questions from incoherentones.To test for digressive questions about propositions thatthe listener has inferred, the Analyzer uses the secondtest, IS-DIGRESSION-TYPE-2, that is described in Fig-ure 7.
The Analyzer checks to see if the feedback is a why-question about a proposition (proposit ion) that has notbeen expressed by the system, but that can be inferred (IS-INFERABLE) from what has been said.
If the propositionsatisfies these requirements, then, as in the previous case,the proposition is returned as the topic for the digression.Otherwise, the second test fails.A question is coherent only if the listener has inferredit correctly from something that the system has said.
Fig-ure 8 describes the test, IS-INFERABLE, that the Analyzeruses to determine if the questioned proposition is inferable.First, the Analyzer gathers all the propositions that IDPhas said as the content of a say act (expressed-props).For each expressed proposition (prop), the Analyzer col-lects propositions that are within two reasoning steps ofIS-DIGRESSION-TYPE-2(fb)fb = "Why" {"not"} propositionandnot(DONE(system, say(proposition)))andIS-INFERABLE(proposition)Then return(proposition)Else return('nil)Figure 7: Test 2: For Detecting Digressive Questions thatthe Listener has InferredIS- INFEI~AB LE(proposition)Let expressed-props := get-said-propsLoop-for-each prop in expressed-propsLet inferable-props:=union(get-reasoning(2, expressed-props), inferable-pr0ps)Endlo0pLet inferable-props :=remove(expressed-props, i n fe rab le -props)If member(propositlon, inferable-props)Then return('true)Else return('nil)Figure 8: Determining if a Proposition is Inferableeach expressed proposition.
These are added to the propo-sitions that are inferable ( inferable-props).
Some of thepropositions that can be inferred may have been said al-ready.
Therefore, after collecting the inferable propositions,the Analyzer emoves any proposition that is also one of theexpressed propositions.
FinMly, the Analyzer checks to seeif the proposition that the listener has questioned is amongthose that are unsaid, but inferable, from what IDP hassaid previously.
If it is, the test succeeds.In Demonstration 2, the second digression test is usedto help determine that the listener's question is digres-sive.
Figure 3 gives the system's TP just before the di-gressive question Why is there heavy t ra f f i c  now?.
Inthis interaction, the questioned proposition has not beenexpressed by the system.
Therefore, the first digressiontest (Figure 5) fails immediately.
In the second digressiontest (Figure 7), the form of question is satisfactory andthe system has not expressed the questioned proposition.Therefore, IS-INFERABLE is invoked to see if the propo-sitionOBJ-PROP(now, heavy-traffic)can be inferred from what has been said.At this point in the discourse, the propositions that IDPhas expressed with say acts areDO(listener, *Maple-plan)ACT-PLAN(avoid(heavy traffic), *Maple-plan)FEWER-BUSINESSES(*Maple-plan, *Sheridan-plan)The Analyzer collects unsaid propositions that are relatedby reasoning to them.OBJECT-PROP(now, heavy-traffic)OBJECT-PROP(now, rush-hour)SECONDAR?-GOAL-ACT(avoid(heavy-traffic))N EWER-ROUTE(*Maple-plan, *Sheridan-plan)1867th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994~/7om~nend(listener, DO(listener.
*Maple-plan))4 :on c~de(listener.
DO(listener.
*Sheridan-plan)), ~ .
.
.
.
.
_ / , ,  v/mouv~te(listener, DO(listener, *Maple-plan))condifiona"llze(D(~st~ner, *Sheridan~Uan)) - -  |PLAN PLAN l?
'you could take Sheridan howe3;eT~ "' _ ~'.
.. / - -~.
j .5:~.-~ -, circu~0s~amiate(ACT/PLAN(avoid(heavy.ttaffic),FEWER INESSES Sheridan lall ~t  y( ~,?USINE5 ( p -p . "
-p  ))? '
'since ta ing Maple there are~ ' \ [  ) fewer ~si?n%sMs%~ then taking/ SheridCn/'?
cir~zumst~fiate(DO(~stener, *MapleCplan)) / __\[ \] 4~y(ACT-PLAN(avoid(heavy-traffie), *Maple-plan)))~ '~ / ?
'taking Maple avoids heavy traffic.
''say(OBJ-PROP(now,heavy-t raffi~))''now there is heavy cr~ffi_c.
''say(DO(listener, *Maple-plan)): ' 'you should ~ake Maple. '
'- Figure 6: The System's TP Just Before the Digressive Question - Demonstration 1IS-DIGRES SION-TYPE-3(fb)If ?b = "Why"i {"not"}Then Let proposition := get-last-proposifion-s~idFigure 9: Test 3: For Detecting Garden-path DigressionsThese are the inferable propositions.
Since the questionedproposition is among them, the test for the second type ofdigressive question succeeds.Next, the Analyzer tries to find a CTP that uses theproposition as a nucleus (Figure 4).
As before, the CTPthat it finds iscircumstantiate(OBJ-PROP(now, heavy-traffic))Since the listener does not know its effect, the Analyzerselects the CTP to answer the digressive question by makingits effect a CG, and returning the CTP to be expanded andexecuted by the Planner:Actor.6.3 Detect ing  Garden-path  D igress ionsDemonstration 3 shows that when the listener repeatedlyasks Why?, IDP eventually recognizes a garden-path digres-sion.
A garden-path digression will always occur at somepoint in an interaction, if the listener asks a series of simplewhy-questions.
The test is a simple one that is given inFigure 9.
If the feedback is Why?
or Why not?, then thetest succeeds and the last proposition that was expressed isreturned as the topic of the digression.In Demonstration 3, When the listener asks Why?
a thirdtime, the state of IDP's TP is the same as in Demonstration2 (Figure ??).
The first two digression tests fail because theform of the question is incorrect.
Using the third digressiontest (Figure 9), the last proposition that the system ex-pressed, and therefore, the topic of the digression becomesFEWER-BUSINESSES(*Maple-plan, *Sheridan-plan)IDP finds a CTP that uses this topic as a nucleuscircumstantiate(FEWER-BUSINESSES(*Maple-plan,*Sheridan-plan))Reasoning that is related to the topic isACT-PLAN(avoid(heavy-traffic), *Maple-plan)NEWER-ROUTE(*Maple-plan, *Sheridan-plan)The effect of the CTP is to let the listener know the sec-ond proposition above.
Since the listener does not knowthis proposition, and since it is reasoning that is related tothe topic, the CTP remains as a candidate for answeringthe digressive question (Figure 4).
After asserting that theeffect of the CTPKNOW(listener,NEWER-ROUTE(*Maple-plan, *Sheridan-plan))is a CG, the Analyzer returns it to be expanded to answerthe digressive question.
In Demonstration 3, this results inthe system response:since tak ing  Map le  is a newer route  thantaking Sheridan.6.4 Incoherent QuestionsIn the IDP model, an incoherent question is a questionthat cannot be related to the system's TP either by replan-ning/expanding the system's TP, or by identifying it as adigression.
Demonstration 2a shows how IDP processes in-coherent questions.
When the Analyzer tries to replan orexpand its DTP to answer the question (Section 5.3), it1877th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994cannot find a TP  that uses the propositional content of thequestionOBJ-PROP(now, heavy-traffic)as a nucleus.
Therefore, analyzing the question to recognizea way to extend IDP's TP  fails.Next, the Analyzer attempts to process the questionas a digression (Section 6).
IDP answered this questionin Demonstrations 1 and 2.
In Demonstration 2a, thequestioned proposition has not been expressed previously.Therefore, the first digression test fails immediately.
Thethird digression test also fails because the question is not asimple why-question.
In the second digression test, the ut-terance satisfies the first two conjuncts.
That is, it has thecorrect form, and it has not been expressed by the system.However, it is not inferable from what has been said so far.At the point in the discourse where the question is asked,the only proposition that IDP has expressed isDO(listener, *Maple-plan)Since this proposition is not a true fact in the knowledgebase, no propositions are inferable from it.
Therefore, theAnalyzer determines that the questioned proposition is nota digression.
Having failed all the tests, IDP responds withHuh?.Note that in Demonstration 2a, the proposition that thelistener questionsOBJ-PROP(now, heavy-traffic)and the answer to itOBJ-PROP(now, rush-hour)are among the localized unknowns (Section 5.1) that can beassociated with the TP  at the point in the discourse wherethe question is asked.
This means that the informationthat the listener refers to with her question is highly rele-vant domain information.
In spite of this, the question isincoherent.
This suggests that discourse focus and purposeare more important factors for determining the coherencyof a question than the domain structure.7 The  System Implementat ionIn the knowledge base, the several sources of informationthat the system needs to analyze and plan the discourseare all represented uniformly using the Semantic NetworkProcessing System (SNePS) \[17\].
This includes knowledgeof the text plan operators, the domain plans, entities in thedomain, the user model, the discourse plan executed so far,and rules for reasoning about all of the above.
The SNePSActor models a cognitive agent operating in a single-agentworld.
It integrates inference and acting by representingbeliefs, plans, and acts as structured intensional entitiesin the network formalism.
Because the agent's world andplanning knowledge is represented uniformly, the agent candiscuss, reason about, formulate, and also execute its plans.Based on the TOUR model \[8\], the various driving routesthat my system can discuss are represented as precon-structed plans that are composed of two types of actions:going and turning.
The domain plans are represented atvarious levels of detail and, as conceptual entities, can haveproperties.
Whenever the system reasons about the do-main, the reasoning that leads to deductions i  recorded inthe knowledge base along with the deductions themselvesand is available as content for explanatiol,s.Re ferences\[1\] s. Carberry.
A pragmatics-based approach to ellipsis reso-lution.
Computational Linguistics, 15(4), 1989.\[2\] A. Cawsey.
Generating explanatory discouse.
In R. Dale,C.
Mellish, and M. Zock, editors, Current Research in Nat-ural Language Generation.
Academic Press, 1990.\[3\] H. P. Grice.
Logic and conversation.
In P. Cole and J. L.Morgan, editors, Syntax and Semantics 3: Speech Acts.Academic Press, New York, 1975.\[4\] B. J. Grosz and C. L. Sidner.
Attention, intentions, andthe structure of discourse.
Computational Linquistics, 12,1986.\[5\] S. M. Hailer.
Interactive generation of plan justifications.
InProceedings of the Fourth European Workshop on NaturalLanguage Generation, 1993.\[6\] S. M. Hailer.
A model for cooperative interactive plan ex-planation.
In Proceedings of the The Tenth IEEE Confer-ence on Artificial Intelligence for Applications, San Anto-nio, Texas, 1994.\[7\] E. H. Hovy.
Unresolved issues in paragraph planning.
InR.
Dale, C. Mellish, and M. Zock, editors, Current Researchin Natural Language Generation.
Academic Press, 1990.\[8\] B. Kuipers.
Modeling spatial knowledge.
Cognitive Science,2, 1978.\[9\] W. C. Mann and S. A. Thompson.
Rhetorical structuretheory: Towards a functional theory of text organization.TEXT, 8(3), 1988.\[10\] J. P. Martins and S. C. Shapiro.
A model for belief revision.Artificial Intelligence, 35(1), 1988.\[11\] J. Moore and W. Swartout.
A reactive approach to ex-planation.
In International Joint Conference on ArtificialIntelligence, 1989.\[12\] J. Moore and W. Swartout.
A reactive approach to ex-planation: Taking the user's feedback into account.
InC. Paris, W. Swartout, and W. Mann, editors, NaturalLanguage Generation in Artificial Intelligence and Compu-tational Linguistics.
Kluwer Academic Publishers, 1991.\[13\] J. D. Moore and C. L. Paris.
Planning text for advisory di-alogues: Capturing intentional and rhetorical information.Computational Linguistics, 19(4), 1993.\[14\] J. D. Moore and M. E. Pollack.
A problem for RST: Theneed for multi-level discourse analysis.
Computational Lin-guistics, 18(4), 1992. discussion.\[15\] S. C. Shapiro and The SNePS Implementation Group.SNePS-2.1 User's Manual.
Department of Computer Sci-ence, SUNY at Buffalo, 1992.\[16\] S. C. Shapiro, D. Kumar, and S. Ali.
A propositional net-work approach to plans and plan recognition.
In Proceedingsof the 1988 Workshop on Plan Recognition, Los Altos, CA,1989.
Morgan Kaufmann.\[17\] S. C. Shapiro and W. J. Rapaport.
SNePS considered as afully intensional propositional semantic network.
In N. Cer-cone and G. McCalla, editors, The Knowledge Frontier.Springer-Verlag, New York, 1987.\[18\] J. van Kuppevelt.
About a uniform conception of S- and D-topics.
In Proceedings of the Prague Conference on Func-tional Approaches to Language Description, Prague, 1992.188
