G~4S: A MODEL OF SENTENCE PRODUCTIONDomenico Parisi Alessandra GiorgiIstituto di Psicologia del C.N.R.Reparto Processi Cognitivi e Intelligenza ArtificialeVia dei Monti Tiburtini, 50900157 Roma, ItalyABSTRACTThe paper describes GEMS, a system forGenerating and Expressing the Meaning ofSentences, focussing on the generation task,i.e.
how GEMS extracts a set of propositionalunits from a knowledge store that can beexpressed with a well-formed sentence in atarget language.
GEMS is lexicallydistributed.
After a central processor hasselected the first unit(s) from the knowledgestore and activated the corresponding lexicalentry, the further construction of thesentences meaning is entrusted to the entriesin the vocabulary.
Examples of how GEMSconstructs the meaning of a number of Englishsentence types are briefly described.I .
Constructing the meaning of sentencesMost work on natural language generationhas been concerned with the production ofconnected text (Davey, 1979; Goldman, 1975;Mann and Moore, 1981; Meehan, 1977) or withlanguage generation as a goal-directed,planned activity (Appelt, 1980; Mann andMoore, 1981).
Less attention has beendedicated to the linguistic details ofsentence generation, i.e.
to constructing ageneral device for imposing the appropriatelinguistic form to the content that must beexpressed (but see Kempen and Hoenkamp,1982).The aim of this paper is to describe GEMS,a system for Generating and Expressing theMeaning of Sentences.
GEMS takes a store ofknowledge as input and gives English sentencesexpressing that knowledge as output.
Theknowledge contained in the knowledge store ispurely conceptual knowledge with no trace oflinguistic form.
There is no partitioning ofknowledge in parts which can be expressed bysingle sentences or by single lexical items,no grammatical labelling of items as verbs,nouns, or subjects, objects, etc., no othertraces of syntactic or lexical form.
Hence, afirst task of GEMS is to extract from theknowledge store the knowledge which it isappropriate to express in a well-formedsentence, i.e.
to generate the meaning of thesentence.
Since the meaning thus constructedmust be expressed with a specific sequence ofwords, two further tasks of GEMS are toselect the semantic and grammatical morphemesthat make up the sentence and to put them inthe appropriate sequential order.Producing sentences is a goal-directedactivity: what one says depends on one'sgoals.
GEMS however is a model of how to saysomething, not of what to say.
When itarrives at a decision point on what to say,GEMS makes a random choice.
Hence, GEMS isnot a complete model of the activity ofproducing sentences but only a model of thelinguistic constraints on the communicationof knowledge and ideas.GEMS conceives the knowledge necessary toproduce sentences as largely distributed inthe lexicon.
This change from previous morecentralized version of GEMS (see Parisi andGiorgi, 1981; 1983) has been suggested to usby Oliviero Stock and Cristiano Castelfranchiand it is related to our view of a lexicallydistributed sentence comprehension process(see Stock, Castelfranchi, and Parisi, 1983;Parisi, Castelfranchi, and Stock, inpreparation).
The lexical entries areprocedures that activate each other in agiven order when a sentence is produced,although the order of activation may notcoincide with the external sequential orderof the words in the actual sentence.
Whenexecuted the entries' procedures (a) extractthe sentence's meaning from the knowledgestore, (b) lexicalize this meaning with theappropriate semantic and grammaticalmorphemes, and (c) put these morphemes in thecorrect sequential order.
A central processorhas the task of searching the knowledge storefor knowledge to be expressed and the lexiconfor the lexical entries that can express thisknowledge.
However, the main task of thecentral processor is to start theconstruction process and to keep a record ofthe order of activation of the lexicalentries.
The overall scheme of GEMS isrepresented in Fig.
1258KNOWLEDGESTORE/I LEXICONCERAL IIJ ~ SENTENCE IFig.
1.
Overall scheme of GEMSIn the present paper our purpose is todescribe GEMS with respect to its first task,i.e.
how GEMS generates the meanings ofsentences by extracting syntacticallyappropriate knowledge from the knowledgestore.
We will proceed by first describingthe knowledge store, the vocabulary, and thecentral processor, and then briefly analyzingsome sentence types to show how GEMSconstructs their meanings.2.
The knowledge storeThe world knowledge of the system, or aswe will say, its encyclopedia (ENC), isrepresented as a set of propositional units.A propositional unit is made up of apredicate, the predicate's arguments, and alabel that uniquely identifies each unit.Argument and labels have number codes thatindicate when they refer to the same entity(same code) or to different entities(different codes).
Labels are represented asCs whereas arguments can be either Xs or Cs.When an argument of a unit is a C, this meansthat the unit is a "recursive" one, i.e.
aunit which takes another unit as itsargument.
In such case the C argument is thelabel of the unit taken as an argument.Let us assume that the system has theknowledge items represented in (I), i.e.
(I)is the system's ENC.
Obviously, neither theabsolute numbers assigned to the argumentsand labels nor the order of listing of theunits in (I) have any meaning.
(I) CI: Xl BILL C6: Xl THINK C7C2: XI SEE X2 C7:X2  LEAVEC3:X2 MARY C8:X4  DOGC4:X3 ARRIVE C9:X4 SLEEPC5:X3  JOHN C I0 :C9  DEEPAs (I) makes it clear, no traces oflin~-uistic form are present in ENC.
Theknowledge items in (I) are not marked asbeing nouns, verbs, or any other grammaticalclasses; furthermore, nothing is subject,object, attribute, or any other functionalclass.
Finally, there is no indication in (I)of which items make up a well-formed sentenceor other syntactic phrases.3- The lexiconIn order to extract a syntactically well-formed meaning from ENC and express it withthe appropriate sequence of semantic andgrammatical morphemes the system utilizes avocabulary (VOC).
VOC is a set ofmeaning/signal pairs called lexical entries.GEMS' vocabulary is a morphological one, i.e.the vocabulary includes lexical entries whichare "roots" (e.g.
see-) and lexical entrieswhich are "(inflexional) suffixes" (e.g.
-s).However, for the purpose of describing thesentence meaning construction process we canassume a simplified vocabulary of wholewords.The meaning of a lexical entry is made upof four components.
(a) There  are first of all one or morepropositional units with the same types ofpredicates that are found in ENC.
The onlydifference is that the units which are foundin a lexical entry have letter codes and notnumber codes on their arguments and labels.
(The number codes show the llnklngs among thevarious units within ENC and, as we will see,within a sentence's meaning.
The letter codesindicate the linkings among units within asingle lexical entry.)
These propositionalunits represent the semantic content of alexical entry.
They are called semantic units(SU).
Even though the SUs of an entry may bemore than one, we will represent the semanticcontent of the entries with a single SU, i.e.without lexical decomposition.
(b) Secondly, the meaning of a lexical entrycontains a list of one or more "saturationinstructions" on the arguments of the SUs.These saturation instructions correspond tothe assembly instructions that play a centralrole in the sentence comprehension process(see Stock, Castelfranchi, and Parisi, 1983),where they serve to assemble together in theappropriate way the separate meanings of thewords making up the sentence to beunderstood.
A saturation instruction is "on"a given argument of the SUs of the lexicalentry.
For example, a verb like to take has aSU "CA: XA TAKE XB" and two saturationinstructions on XA and XB, respectively.
Anoun like president has a SU "CA: XAPRESIDENT XB" and a saturation instruction onXB.
A saturation instruction on a givenargument is a procedure for (i) extractingfrom the knowledge store a propositional unithaving the argument to be saturated as itsargument or its label, and (ii) identifying alexical entry in VOC which has the extracted259propositional unit among its SUs.
(c) A third component of a lexical entry is a"marker".
Lexlcal entries contain one ofthree types of markers: TEMP, HEAD, and ADV.TEMF is a marker of verbs (full verbs notcopula or auxiliary verbs), adjectives andsome uses of "semantic" prepositions (as inThe book is for.
Susan, The bottle is on thetable).
HEAD is a marker of nouns (includingnominalizations llke arrival).
ADV is amarker of adverbs, subordinatingconjunctions, and some other uses of"semantic" prepositions (as in Bill is eatin~in the kitchen).
Markers are procedures forselecting the next step to be taken by themeaning construction process when thesaturation instructions of a lexical entrieshave all been executed.
As procedures markersmake reference to the record of the order ofactivation of the lexical entries which iskept by the central processor.
Therefore, wewill explain the meaning of TEMP, HEAD, andADV after describing the central processor.
(d) Finally, lexical entries include as afourth component one or more additionalpropositional units having special predicateswhich are different from the semanticpredicates of the units in ENC and the SUs inthe vocabulary entries.
These special unitscontrol the lexlcallzation of the grammaticalmorphemes and therefore they won't bementioned in this paper.4.
The central processorThe central processor executes theprocedures of the lexical entries, both thesaturation instructions and the markers.However in addition it has two specific tasksof its own which represent the non-lexicallydistributed portion of GEMS.First of all, the central processor startsthe whole process by selecting in ENC a unithaving a specified argument as one of itsarguments or as its label, and then lookingup in VOC a lexical entry that can lexicalizethis unit, i.e.
that has this unit as thelexical entry's SU.
This is the first step ofthe sentence production process and it is thecentral processor which is responsible forit.Secondly, the central processor keeps arecord of the order of activation in VOC ofthe lexical entries that will make up thesentence (more precisely, the sentence's"content words").
The meaning of the sentenceto be produced is constructed step by step byactivating and executing the meanings ofthese lexical entries.
In order to controlthis process GEMS must rely on a trace of thepath traversed by the lexical activationprocess.
More specifically, for each lexicalentry which is activated there is a record ofthe lexical entry that activated the entry.This allows the system at any time to "stepback", i.e.
to trace back from an activelexical entry to the lexical entry thatactivated it.
The latter entry becomes thenew active lexical entry.We can now return to the markers containedin the lexical entries and explain themeaning of HEAD, TEMP, and ADV.
As alreadynoted, these are names of procedures that areexecuted after all the unsaturated argumentsof the lexical entry have been saturated.HEAD is a very simple instruction to stepback to the lexical entry from which thesystem originally moved to the currentlyactive lexical entry (ALE), and to make thisentry the new ALE.
As we know HEAD is carriedby nouns and therefore it is an instructionto move from the current noun to thegoverning verb (Bill sleeps), noun (thepresident o f  the Company) or adverbialpreposition (in the ~arden).TEMP is a two step procedure.
The firststep is a recursive instruction to search ENCfor a unit which has the label of the currentALE as one of its argument and thenlexicalize this unit.
Since TEMP is carriedby verbs and adjectives, it is an instructionfor constructing one or more adverbialsmodifying the verb or adjective (Bill sleepsdeeply, Mary is very nice, Bill sleeps deepl 7in the bed).
When this first step has beenexecuted TEMP has a second instruction tostep back.
This allows the system to stepback from a subordinate clause verb to thegoverning verb, noun or adverbial conjunction(Bill thinks that Mary left, The announcementthat Bill had won delighted Peter, When Billwent to New York Mary was relieved).
If thereare no entries to step back to, theconstruction process ends.ADV is very similar to TEMP.
It firstattempts to construct recursive adverbials inENC (adverbials modifying adverbials, e.g.Bill sleeps very deeply) and then it stepsback, ultimately to the verb or adjectivebeing modified.Before proceeding to analyze how GEMSconstructs the meaning of various Englishsentence types it is necessary to note twolimitations of the system as it is now.A first limitation is that the procedureproduces sentences only in response to aquestion to say something on a specificentity that is pointed out to the system fromoutside.
An example could be "Say somethingon Napoleon".
The system's response would beto produce a sentence expressing some260knowledge it has about Napoleon.
A secondlimitation is that GEMS does not producesentences containing pronouns and sentenceswhere the starting entity is not included inthe sentence's main clause.
An extension ofGEMS to sentences containing pronouns isdescribed in Giorgi and Parisi (1984).
As forsentences with the starting entity outsidetheir main clauses they raise problemsrelated to the status of the propositionalunits in ENC, i.e.
whether a particular unitis "believed" by the system or not (for atreatment within the present framework, seeCastelfranchi, Parisi and Stock, 1984).
Ifthe starting entity is "Mary" and the systemknows that Bill thinks that Mary left itwould not be appropriate for the system toproduce a statement like Mary left.
However,we won't deal with these problems in thepresent paper.5.
How the meaning of various sentence typesis constructedConsider how the meaning of a simplesentence llke Bill saw Mary isconstructed byGEMS.Let us assume that the system is asked toproduce a sentence about Mary, or moreprecisely about argument X2 (see theencyclopedia in (I)).
The central processorsearches ENC for a unit having X2 as itsargument or label.
The unit "C2: XI SEE X2"is selected.
The central processor looks upin VOC a lexical entry having a correspondingunit among its SUs.
Assume that VOC containslexical entry (2).
(2) Semantic Marker SaturationUnits Instruct.CA: XA SEE XB TEMP(CA) XA,XB saw 32This entry is identified and it becomes the"active lexlcal entry" (=ALE).
Itsidentification number, 32, is recorded by thecentral processor along with the activatingagent.
Since the activating agent in thiscase is the central processor (CP) itself thepair "CP, 32" is recorded.How the meaning of the entry executesitself.
Since the entry contains twosaturation instructions they are executed inwhatever order.
Assume that XA is tackledfirst.
The processor searches ENC for a unithaving XA, or more precisely itscorresponding argument in ENC, X1, as one ofits arguments or as its label.
The unit "C1:XI BILL" is selected.
To lexlcalize this unitthe processor identifies lexical entry 14 inVOC:(3)CA: XA BILL HEAD(XA) --- Bill 14Entry 14 becomes the new ALE and theprocessor record its identification number,14, along with the identification number ofthe activating entry: "32, 14".The entry Bill has no saturationinstructions.
Therefore, the processorexecutes its marker: HEAD(XA).
It steps back,i.e.
it makes the activating entry, 32, thenew ALE.The new ALE, saw, has a further argumentto be saturated: XB(=X2).
This leads to theselection of unit "C3 :X2  Mary" in ENC and tothe identification of the following entry inVOC:(4)CA: XA MARY BEAD(XA) --- Mary 55 is the new ALE.
The processor records "32,5".
Since Mary doesn't have saturationinstructions, BEAD directs the system to stepback to 32 again.At this point there are no furtherinstructions of saw and the entry's marker,TEMP(CA), can be executed.
TEMP checkswhether there are in ENC propositional unitshaving CA(=C2) as their argument that thesystem may want to express (as averbials).Since the answer is No, TEMP directs thesystem to step back.
But there is no lexicalentry to step back to because saw is theinitial lexical entry, i.e.
the entryinitially activated by the central processor.Hence, the meaning construction process endshere.
The meaning of the sentence Bill sawMary has been constructed.The mechanism of the saturationinstructions allows for an indefinite "goingdown" of the construction process.
A nounphrase like the president of the company inthe sentence Bill saw the president of thecompany is constructed by first selecting anoun which has a saturation instruction(president) and then a further noun tosaturate that instruction (company).
Whencompany is reached, since this noun has nosaturation instructions, the system stepsback first to president and then to theinitial verb saw.In a similar way the meaning ofnominalizations like John's arrival (see (I))can be generated using the following lexicalentry for arrival:(5)CA: XA ARRIVE HEAD(CA) XA arrival 15Subordinate clauses, i.e.
verb-, noun-, andadverbial-complements, can all be generatedby the same mechanism.
The only difference is261that when their meaning has been completedthe TEMP marker of the subordinate clauseverb directs the system to step back to thehigher verb, noun or adverbial to continuewith the construction process at the higherlevel.Consider how the meaning of the sentenceBill thinks that Mary left is constructed.Let us assume that the system is asked toproduce a sentence about XI (Bill) and thatthe unit which is selected in ENC is "C6: XITHINK C7".
This unit is lexicalized with thefollowing entry:(6)CA: XA THINK CB TEMP(CA) XA, CB thinks 81If the argument CB (:C7) is first taken upfor saturation, this leads to the selectionof unit "C7: X2 LEAVE" in ENC and theactivation of the entry left in VOC.
At thispoint left is the new ALE.
Its only argumentis saturated with Mary and then the systemsteps back first to left and then to thinks.Thinks has another argument to be saturated,XA--" :--XI).
The system saturates Xl with Bill.Thus, the meaning of Bill thinks that Mar xleft has been completed.Adverbials modifying verbs or adjectivesare also generated by TEMP.
Consider thesentence The dog sleeps deeply.
When thesaturation instruction of sleeps has beenexecuted (thereby generating the meaning ofdog), the TEMP marker of sleeps searches ENCfor units having the TEMP-marked argument(C9) as one of their arguments.
The unit"CIO: C9 DEEP" is found.
This unit islexicalized with the entry:(7)CA: CB DEEP ADV(CB) --- deeply 36Since deeply has no saturation instructionsand its marker ADV cannot find furtheradverbials in ENC, the system steps back tosaw and the construction process ends.
Themeaning of the sentence The  do~ sleepsdeeply has been constructed.GEMS can be slightly modified to generateequative sentences (Fido is a do~) andsentences containing noun modifiers (a nice~irl, the ~Irl who was smilinG).
Furthermore,GEMS can also deal with cases where theinitial lexlcal entry activated by thecentral processor is not a TEMP-marked entry,as it was the case in the examples analyzedabove, but it is a HEAD- or an ADV-markedentry, i.e.
a noun or an adverb.A version of GEMS for one-clause Italiansentences has been implemented by G.Adorni inFranzLisp on a VAX computer at the Universityof Genova.
"REFERENCES"Appelt, D.E.
Problem solving applied tolanguage generation.
Proceedings of the 18thAnnual Meetin G of ACL, 1980, pp.59-63.Castelfranchi, C., Parisi, D., Stock, O.Extending the expressive power of propositionnodes.
In B.G.Bara and G.Guida (eds.
),Computational ' Models o f  Natural LanguageProcessing.
Amsterdam: North Holland, 1984.Davey, A. Discourse Production.
Edinburgh:University Press, 1979.Olorgi, A., Parisi, D. Producin~ sentencescontainin G pronouns.
RPCIA/17, Istituto diPsicologia, CNR, 1984.Goldman, N.M.
Conceptual generation.
InR.Schank (ed.
), Conceptual InformationProcessing.
Amsterdam: North Holland, "1975.Kempen, G., Hoenkamp, E. An incrementalprocedural Grammar for sentence formulation.Unpubliched paper, University of Nijmegen,1982.Mann, W.C., Moore, J.A.
Computer generationof multiparagraph English text.
AmericanJournal of Computational Linguistics, 19"~,~, 17-29.Meehan, J.R. Tale-spin, an interactiveprogram that writes stories.
Proceedings ofthe 5th IJCAI, 1977, pp.91-98.Parisi, D., Giorgl, A.
A procedure for theproduction of sentences.
RPCIA/1, Istituto diPsicologla, CNR, 1981.Parisi, D., Giorgi, A.
A procedure forconstructin~ the meanin~ of sentences.RPCIA/7, Istituto di Psicologia, CNR, 1983.Parisi, D., Castelfranchi, C., Stock, O. Amodel of sentence comprehension an~production, in preparation.Stock, O., Castelfranchi, C., Parisi, D.WEDNESDAY: Parsing flexible word orderlanguages.
Proceedings of the Ist Meetin~ ofACL t European Chapter, 1983.262
