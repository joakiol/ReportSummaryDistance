Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 89?94,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsA Fast Approach for Semantic Similar Short Texts RetrievalYanhui Gu1Zhenglu Yang2?Junsheng Zhou1Weiguang Qu1Jinmao Wei2Xingtian Shi31School of Computer Science and Technology, Nanjing Normal University, China{gu,zhoujs,wgqu}@njnu.edu.cn2CCCE&CS, Nankai University, Tianjin, China{yangzl,weijm}@nankai.edu.cn3SAP Labs China, Shanghai, China{xingtian.shi}@sap.comAbstractRetrieving semantic similar short textsis a crucial issue to many applications,e.g., web search, ads matching, question-answer system, and so forth.
Most of thetraditional methods concentrate on howto improve the precision of the similar-ity measurement, while current real ap-plications need to efficiently explore thetop similar short texts semantically re-lated to the query one.
We address theefficiency issue in this paper by investi-gating the similarity strategies and incor-porating them into the FAST framework(efficient FrAmework for semantic sim-ilar Short Texts retrieval).
We conductcomprehensive performance evaluation onreal-life data which shows that our pro-posed method outperforms the state-of-the-art techniques.1 IntroductionIn this paper, we investigate the fast approachof short texts retrieval, which is important tomany applications, e.g., web search, ads match-ing, question-answer system, etc.
(Yu et al, 2016;Wang et al, 2015; Hua et al, 2015; Yang et al,2015; Wang et al, 2010; Wei et al, 2008; Cui etal., 2005; Metzler et al, 2007; Ceccarelli et al,2011; Radlinski et al, 2008).
The setting of theproblem is that users always ask for those mostsemantically related to their queries from a hugetext collection.
A common solution is applyingthe state-of-the-art short texts similarity measure-ment techniques (Islam and Inkpen, 2008; Li et al,2006; Mihalcea et al, 2006; Sahami and Heilman,2006; Tsatsaronis et al, 2010; Mohler et al, 2011;Wang et al, 2015), and then return the top-k ones?Corresponding author.by sorting them with regard to the similarity score.After surveying the previous approaches, we findthat almost all the methods concentrate on howto improve the precision, i.e., effectiveness issue.In addition, the data collections which they con-ducted are rather small.
However, the scale of theproblem has dramatically increased and the cur-rent short texts similarity measurement techniquescould not handle when the data collection size be-comes enormous.
In this paper, we aim to addressthe efficiency issue in the literature while keepingtheir high precision.
Moreover, we focus on thetop-k issue because users commonly do not careabout the individual similarity score but only thesorted results.
Furthermore, most of the previousstudies (Islam and Inkpen, 2008; Li et al, 2006;Tsatsaronis et al, 2010; Wang et al, 2015) needto set predefined threshold to filter out those dis-similar texts which is rather difficult to determineby users.Different from long texts, short texts cannot al-ways observe the syntax of a written languageand usually do not possess sufficient informationto support statistical based text processing tech-niques, e.g., TF-IDF.
This indicates that the tra-ditional NLP techniques for long texts may not bealways appropriate to apply to short texts.
The re-lated works on short texts similarity measurementcan be classified into the following major cate-gories, i.e., (1) inner resource based strategy (Liet al, 2006; Islam and Inkpen, 2008); (2) outerresource based strategy (Tsatsaronis et al, 2010;Mihalcea et al, 2006; Islam and Inkpen, 2008;Wang et al, 2015); and (3) hybrid based strat-egy (Islam and Inkpen, 2008; Li et al, 2006; Wanget al, 2015).Naively testing the candidate short texts for top-k similar short texts retrieval is inefficient whendirectly using these strategies.
To tackle the effi-ciency problem, we propose an efficient strategy89to evaluate as few candidates as possible.
More-over, our fast algorithm aims to output the resultsprogressively, i.e., the top-1 should be obtainedinstantly.
This scheme meets the demand of thereal world applications, especially for big data en-vironment.
We list our contribution of this paperas follows: we propose a fast approach to tacklethe efficiency problem for retrieving top-k seman-tic similar short texts; we present the optimizedtechniques and improve the efficiency which min-imizes the candidate number to be evaluated inour framework.
The results of four different set-tings demonstrate that the efficiency of our fastapproach outperforms the state-of-the-art methodswhile keeping effectiveness.2 PreliminariesFormally, for a given query short text q, retriev-ing a set of k short texts Tsin a data collec-tion Dswhich are most semantically similar toq, i.e., ?t ?
Tsand ?r ?
(Ds?
Ts) will yieldsim(q, t) ?
sim(q, r).
To obtain the similarityscore sim(q, t) between two short texts, we canapply the current state-of-the-art strategies (Tsat-saronis et al, 2010; Mihalcea et al, 2006; Islamand Inkpen, 2008; Wang et al, 2015).
In this pa-per, we judiciously select some similarity metricswhich are assembled into a general framework totackle the efficiency problem.
Most of the exist-ing strategies of evaluating the similarity betweenshort texts are based on word similarity, becauseof the intuitive idea that short text is composed ofwords.
As a result, we introduce the representativeword similarity in the next section.2.1 Selected Representative SimilarityMeasurement StrategiesThere are a number of semantic similaritystrategies having been developed in the previousdecades which are useful in some specific applica-tions of NLP tasks.
Recently, outer resources areindispensable for short texts similarity measure-ment (Tsatsaronis et al, 2010; Mihalcea et al,2006; Islam and Inkpen, 2008; Wang et al, 2015;Hua et al, 2015).
After extensively investigatinga number of similarity measurement strategies,we judiciously explore two representative wordsimilarity measurement strategies which obtainthe best performance compared with humanjudges.Knowledge based StrategyKnowledge based strategy determines whethertwo words are semantically similar by measur-ing their shortest path in the predefined taxonomy.The path between them can be calculated by ap-plying word thesauri, e.g., WordNet.
In this paper,we take one representative metric which has beenproposed in (Leacock and Chodorow, 1998).
Let?stake two wordswi,wjas an example, the similarityis as follows:Simk(wi, wj) = ?lnpaths(wi, wj)2 ?Dwhere paths(wi, wj) is the shortest path betweentwo word concepts by using related strategy, e.g.,node-counting strategy.
D is the maximum depthof such taxonomy (D is with different size ineither noun taxonomy or verb taxonomy).Corpus based StrategyDifferent from knowledge based strategy, corpusbased strategy cannot form a new entity whichmeans we can only apply statistical informationto determine the similarity between two words.There are a few corpus based similarity measure-ment strategies, e.g., PMI, LSA, HAL, and soforth.
In this paper, we select a representativestrategy which applies Wiki encyclopedia to mapWiki texts into appropriate topics.
EachWiki topicis represented as an attribute vector.
The words inthe vector occur in the corresponding articles.
En-tries of these vectors are assigned weight whichquantifies the association between words and eachWiki topic after applying vector based scheme,e.g., TF-IDF.
The similarity can be evaluated byaggregating each word distributing on these top-ics.
In addition, a short text is a vector basedon topics with weight of each topic Tiformulatedas:?wi?Tsvi?
dj, where viis TF-IDF weight ofwiand djwhich quantifies the degree of associ-ation of word wiwith Wiki topic Tj.
Here, theWiki topic could be concepts or topics generatedby other techniques, e.g., LDA, LSA, etc.2.2 Semantic Similarity Measurementbetween Two Short TextsSemantic similarity between two short texts canbe measured by combining the words similarity ina general framework.
Therefore, the method ofcombining the words similarities into a frameworkmay affect the efficiency and effectiveness of thesimilarity score.
In this paper, we integrate differ-90ent similarity strategies linearly and this methodhas been proved that it has high precision by com-paring with human judges (Li et al, 2006; Islamand Inkpen, 2008).
The scheme measures eachword pair of short texts and then constructs a sim-ilarity score matrix.
Finally, the similarity scorebetween two short texts is recursively executed byaggregating the representative words.3 A Fast Approach for Semantic SimilarShort Texts RetrievalWe propose a fast approach for retrieving the top-k semantic similar short texts to a given query q inthis section.
The key idea of this scheme is to ac-cess a rather small size of candidates in the wholedata collection.
The scheme is conducted by build-ing appropriate indices in offline procedure, i.e.,preprocessing procedure.
We illustrate the wholeframework in Figure 1.
The figure tells us, to ef-ficiently retrieve top-k similar short texts, our pro-posed strategy only accesses as small as possiblepart of candidates which are filled in grey color.Knowledge based Similarity Metric Corpus based Similarity MetricT2T3...delicious lunch Japan...top-1 result:wordLAYERtext LAYER T1T2...nice T2,...Very good food, but a little expensive.Anything after this wonderful lunch in Japan?Delicious sushi, tempura and sashimi near Okubo.Delicious sushi, tempura and sashimi near Okubo.goodwonderfultastyT2...fooddishsushitempura...Nipponsushitempuraservicedelicious lunch JapanT3,...T1,......T2,T3...T2,...T2,.........T2,...T2,.........Delicious sushi, tempura and sashimi near Okubo....word LAYER wonderful T1,...goodnicetasty ...sushitempurafooddish ...NipponShinjukuserviceT3,...T2,...... ...T2,...T2,...T2,T3............T2,...... ...Japan ......delicious T2,... lunch ... delicious T2,... lunch ... Japan ...OkuboFigure 1: The framework of proposed fast ap-proach3.1 Efficiently Aggregate Similarity MetricsIn this section, we present an efficient assemblingstrategy to hasten the process of retrieving top-ksimilar short texts (Fagin et al, 2001).
A concreteexample to illustrate our proposal is presented inFigure 1.
For example, let the query short textis: ?Delicious lunch in Japan?.
After preprocess-ing (stemming and removing the stopwords), thequery is: delicious lunch Japan.
From Figure 1,we can see that there is a hierarchical structure inour framework.
Suppose that if we want to retrievetop-1 short text from the whole data, the ranked list(i.e., order list) of knowledge based similarity andcorpus based similarity are needed respectively.From the analysis on the property of threshold al-gorithm, the top-1 short text comes from these tworanked lists instantly.
However, we cannot knowsuch ranking directly because these two lists aretexts layer but each list has its sub layer, i.e., wordlayer.
In this paper, we apply two kinds of sim-ilarity metrics.
Therefore, there are two assem-bling tasks, i.e., (1)assembling knowledge basedand corpus based similarities; and (2)assemblingwords to texts.
The words are query words andeach query word corresponds to a list which canbe found in Figure 1.
Figure 1 also tells us foreach word, it has the corresponding list in whichall the words have been ranked based on the re-latedness with such word.
Since each word mayoccur in several short texts, the proposed methodhere should take the ID of each short text into con-sideration (e.g., word ?delicious?
occurs T2, etc.
).We apply threshold algorithm to obtain the topshort texts based on each query word.
Therefore,the top-1 result comes from these two ranked listsbased on threshold algorithm.
In this example, T2is finally outputted as the top-1 value.3.2 Ranking list on Similarity StrategiesFrom the description in Section 3.1, we can seethat the ranked list is crucial for using thresholdalgorithm to retrieve top-k short texts.
In thissection, we introduce the optimized method oneach similarity metric.Ranking on Knowledge based strategySince WordNet is a representative knowledgebase, we apply the Leacock and Chodorow strat-egy as a WordNet evaluator which optimized as anefficient technique (Yang and Kitsuregawa, 2011).Lemma 1 (Ordering in WordNet) Let q be thequery.
Let P and S be two candidates that existin the same taxonomy of q, that is, TPand Tq.
Theshortest path between q and P (or S) is LPin TP(or LSin TS).
The maximum depth of TPis DP(or DSof TS).
P is more similar to Q comparedwith S. Thus, we haveDPLP>DSLS.The lemma tells us that the similarity ordering be-tween candidates in WordNet depends on the in-tegration of the shortest path and the maximumdepth of the taxonomy.
We access the related syn-onyms set between two taxonomies successivelybased on the value ofDLand obtain the top-k re-sults in a progressive manner.Ranking on Corpus based StrategyWe measure the similarity between short texts91by aggregating each word distribution on topics.A short text is a valued vector based on topics,where the weight of each topic Ticalculated as:?wi?Tsvi?
kj, where viis TF-IDF weight of wiand kjwhich quantifies the strength of associationof word wiwith Wiki topic Tj.
Different fromthe traditional approaches, we first calculate all thesimilarity scores between each word in Wiki andthat between topics in the data collection to ob-tain a set of lists during preprocessing.
The topiccould be generated either by ESA or by LDA.
Af-ter that, we build a weighted inverted list whereeach list presents a word with sorted correspond-ing short texts according to the similarity score.Therefore, for a given query text q, each word inq corresponds to a list of short texts.
As that, weapply the threshold algorithm retrieve the top-k re-sults by using this manner.
This manner accessesa small size of components of the data without ne-cessity to evaluate every candidate short text.After obtaining all the ranking lists, we can ap-ply the threshold algorithm aforementioned to ef-ficiently retrieve the top-k semantic similar shorttexts either by equal weight scheme or weight tun-ing strategy.4 Experimental EvaluationIn this section, we conduct on three differentdatasets to evaluate the performance of our ap-proach.
To evaluate the effectiveness, we test thedataset which was used in (Li et al, 2006).
For ef-ficiency evaluation, we apply the BNC and MSCdatasets which are extracted from British NationalCorpus and Microsoft Research Paraphrase Cor-pus respectively.
The baseline strategy is imple-mented according to the state-of-the-art (linear as-sembling strategy as (Islam and Inkpen, 2008)).In our proposed strategy, we take four differentsettings: (1) FASTEis the one that we apply theESA topic strategy; (2) FASTLemploys the LDAtopic strategy in corpus based similarity with equalweight; and (3) FASTEwand FASTLware im-plemented based on the former two ones, respec-tively, with the tuned combinational weights.4.1 Efficiency EvaluationWe evaluate the efficiency by using two real-lifedatasets which have been denoted as BNC andMSC.
To test the effect of size of data collec-tion, we select different size of these two datasets.Firstly, we conducted experiments on the fixedsize of data collection by using 4 settings of ourproposed approach.
The results show that com-paring with the baseline strategy, FASTE, FASTL,FASTEwand FASTLwhave promotion at 75.34%,74.68%, 75.31% and 74.59% respectively.
Thefour settings have similar results which indicatesthat the weight is not the crucial factor in ourproposed strategy.
Table.
1 tells us the numberof candidates accessed.
Our evaluation has beenconducted on different data collection size to testthe scalability of our proposed strategy.
Since thebaseline strategy should access all the short textsin each size of data collection, which means in 1ksize of BNC data collection, the baseline strategyaccess all these 1k candidates.
However, our pro-posed strategies under different settings only ac-cess small size candidates to obtain the results.From the table, we can see that, our proposed strat-egy can largely reduce the number of candidatesaccessed in both data collections.
In addition,the number of candidates accessed has increasesnot quickly which indicate our proposed approachscales well.
Therefore, the proposed strategy is ef-ficient than the baseline strategy.StrategiesBNC (#Candidates accessed)1k 5k 10k 20kFASTE215 1,368 1,559 1,974FASTL217 1,478 1,551 2,001FASTEw225 1,511 1,621 2,043FASTLw225 1,521 1,603 2,025StrategiesMSC (#Candidates accessed)10% 20% 50% 100%FASTE74 304 712 1,253FASTL85 313 705 1,128FASTEw87 308 725 1,135FASTLw81 309 712 1,076Table 1: Number of candidates accessed in effi-ciency evaluationWe also evaluate the effect of k which is animportant factor for evaluating the efficiency ofan algorithm.
The experiments conducted on afixed size of data collection which show that thetop-1 value has been outputted instantly by ap-ply our proposed strategy while baseline strategyshould access all candidates.
For the query timeof FASTEsetting costs only 19.12s while base-line strategy costs 897.5s for obtaining the top-1value.
FASTL, FASTEsand FASTLwcost 20.13s,21.21s and 20.32s respectively which confirmsthat combinational weight is not an important fac-tor in our proposed strategy.924.2 Effectiveness EvaluationWe illustrate the results of the correlation coeffi-cient with human ratings in Table.
2.
Note here,the baseline strategy is composed by knowledgebased strategy and corpus based strategy (ESAmethod) with equal weight.
From the table wecan see that, the FASTEhas the same precisionas the baseline because our proposed strategy onlychanges the order of the evaluated short texts butnot the similarity strategy.
FASTLhas better pre-cision than FASTEbecause we select the bestLDA topic size to form Wiki topic.
FASTEwandFASTLwhave dynamically changed the combina-tional weights and therefore, the performance ofthem has been improved.BaselineProposed StrategiesFASTEFASTLFASTEwFASTLw0.72162 0.72162 0.73333 0.74788 0.74941Table 2: Effectiveness evaluation on differentstrategies5 ConclusionIn this paper, we propose a fast approach totackle the efficiency problem of retrieving top-ksimilar short texts which has not been extensivelystudied before.
We select two representativesimilarity metrics, i.e., knowledge based andcorpus based similarity.
Efficient strategies areintroduced to test as few candidates as possiblein the querying process.
Four different settingshave been proposed to improve the effectiveness.The comprehensive experiments demonstratethe efficiency of the proposed techniques whilekeeping the high precision.
In the future, we willinvestigate new methods to tackle efficiency issueand take effect semantic similarity strategies toobtain high performance.Acknowledgment.
We would like to thankthe anonymous reviewers for their insightfulcomments.
This work is partially supportedby Chinese National Fund of Natural Scienceunder Grant 61272221, 61472191, 61070089,11431006, Jiangsu Province Fund of SocialScience under Grant 12YYA002, the NaturalScience Research of Jiangsu Higher EducationInstitutions of China under Grant 14KJB520022,and the Science Foundation of TianJin under grant14JCYBJC15700.ReferencesDiego Ceccarelli, Claudio Lucchese, Salvatore Or-lando, Raffaele Perego, and Fabrizio Silvestri.
2011.Caching query-biased snippets for efficient retrieval.In Proceedings of the International Conference onExtending Database Technology, EDBT/ICDT ?11,pages 93?104.Hang Cui, Renxu Sun, Keya Li, Min-Yen Kan, and Tat-Seng Chua.
2005.
Question answering passage re-trieval using dependency relations.
In Proceedingsof the International ACM SIGIR Conference on Re-search and Development in Information Retrieval,SIGIR ?05, pages 400?407.Ronald Fagin, Amnon Lotem, and Moni Naor.
2001.Optimal aggregation algorithms for middleware.
InProceedings of the ACM SIGMOD symposium onPrinciples of Database Systems, PODS ?01, pages102?113.Wen Hua, Zhongyuan Wang, Haixun Wang, KaiZheng, and Xiaofang Zhou.
2015.
Short text under-standing through lexical-semantic analysis.
In 31stIEEE International Conference on Data Engineer-ing, ICDE?15, pages 495?506.Aminul Islam and Diana Inkpen.
2008.
Semantic textsimilarity using corpus-based word similarity andstring similarity.
ACM Transactions on KnowledgeDiscovery from Data, 2(2):1?25.C.
Leacock and M. Chodorow.
1998.
Combining lo-cal context and wordnet similarity for word senseidentification.
In WordNet: An Electronic LexicalDatabase, pages 305?332.
In C. Fellbaum (Ed.
),MIT Press.Yuhua Li, David McLean, Zuhair Bandar, JamesO?Shea, and Keeley A. Crockett.
2006.
Sentencesimilarity based on semantic nets and corpus statis-tics.
IEEE Transactions on Knowledge and DataEngineering, 18(8):1138?1150.Donald Metzler, Susan T. Dumais, and ChristopherMeek.
2007.
Similarity measures for short seg-ments of text.
In Proceedings of the European Con-ference on Information Retrieval, ECIR ?07, pages16?27.Rada Mihalcea, Courtney Corley, and Carlo Strappa-rava.
2006.
Corpus-based and knowledge-basedmeasures of text semantic similarity.
In Proceedingsof the AAAI Conference on Artificial Intelligence,AAAI?06, pages 775?780.Michael Mohler, Razvan C. Bunescu, and Rada Mihal-cea.
2011.
Learning to grade short answer questionsusing semantic similarity measures and dependencygraph alignments.
In Proceedings of the 49th An-nual Meeting of the Association for ComputationalLinguistics: Human Language Technologies, Pro-ceedings of the Conference, ACL?11, pages 752?762.93Filip Radlinski, Andrei Broder, Peter Ciccolo, EvgeniyGabrilovich, Vanja Josifovski, and Lance Riedel.2008.
Optimizing relevance and revenue in adsearch: a query substitution approach.
In Proceed-ings of the International ACM SIGIR Conferenceon Research and Development in Information Re-trieval, SIGIR ?08, pages 403?410.Mehran Sahami and Timothy D. Heilman.
2006.
Aweb-based kernel function for measuring the simi-larity of short text snippets.
In Proceedings of the In-ternational Conference on World Wide Web, WWW?06.George Tsatsaronis, Iraklis Varlamis, and MichalisVazirgiannis.
2010.
Text relatedness based on aword thesaurus.
Journal of Artificial IntelligenceResearch, 37:1?39.Kai Wang, Zhao-Yan Ming, Xia Hu, and Tat-SengChua.
2010.
Segmentation of multi-sentence ques-tions: towards effective question retrieval in cqa ser-vices.
In Proceedings of the International ACM SI-GIR Conference on Research and Development inInformation Retrieval, SIGIR ?10, pages 387?394.Peng Wang, Jiaming Xu, Bo Xu, Cheng-Lin Liu, HengZhang, Fangyuan Wang, and Hongwei Hao.
2015.Semantic clustering and convolutional neural net-work for short text categorization.
In Proceedingsof the 53rd Annual Meeting of the Association forComputational Linguistics and the 7th InternationalJoint Conference on Natural Language Processingof the Asian Federation of Natural Language Pro-cessing, ACL ?15, pages 352?357.Furu Wei, Wenjie Li, Qin Lu, and Yanxiang He.
2008.Query-sensitive mutual reinforcement chain and itsapplication in query-oriented multi-document sum-marization.
In Proceedings of the InternationalACM SIGIR Conference on Research and Devel-opment in Information Retrieval, SIGIR ?08, pages283?290.Zhenglu Yang and Masaru Kitsuregawa.
2011.
Ef-ficient searching top-k semantic similar words.
InProceedings of the International Joint Conferenceon Artificial Intelligence, IJCAI?11, pages 2373?2378.Shansong Yang, Weiming Lu, Dezhi Yang, Liang Yao,and Baogang Wei.
2015.
Short text understand-ing by leveraging knowledge into topic model.
InThe 2015 Conference of the North American Chap-ter of the Association for Computational Linguistics:Human Language Technologies, NAACL/HLT?15,pages 1232?1237.Zheng Yu, Haixun Wang, Xuemin Lin, and Min Wang.2016.
Understanding short texts through semanticenrichment and hashing.
IEEE Trans.
Knowl.
DataEng., 28(2):566?579.94
