Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 441?448Manchester, August 2008Normalizing SMS: are two metaphors better than one ?Catherine KobusOrange Labs2, avenue Pierre MarzinF-22300 LannionFran?ois YvonUniv Paris-Sud 11 & LIMSI/CNRSBP 133F-91403 Orsay Cedex{catherine.kobus,geraldine.damnati}@orange-ftgroup.com, yvon@limsi.frG?raldine DamnatiOrange Labs2, avenue Pierre MarzinF-22300 LannionAbstractElectronic written texts used in computer-mediated interactions (e-mails, blogs,chats, etc) present major deviations fromthe norm of the language.
This paperpresents an comparative study of systemsaiming at normalizing the orthography ofFrench SMS messages: after discussingthe linguistic peculiarities of these mes-sages, and possible approaches to their au-tomatic normalization, we present, evalu-ate and contrast two systems, one draw-ing inspiration from the Machine Transla-tion task; the other using techniques thatare commonly used in automatic speechrecognition devices.
Combining both ap-proaches, our best normalization systemachieves about 11% Word Error Rate on atest set of about 3000 unseen messages.1 IntroductionThe rapid dissemination of electronic communi-cation devices (e-mails, Short Messaging Systems(SMS), chatrooms, instant messaging programs,blogs, etc) has triggered the emergence of newforms of written texts (see eg.
(Crystal, 2001;V?ronis and Guimier de Neef, 2006)).
Addressedto relatives or peers, written on the spur of themoment, using interfaces, each with its specificconstraints (computer keyboards, PDAs, mobilephones keypads), these electronic messages arecharacterised by massive and systematic devia-tions from the orthographic norm, as well as bya non conventional use of alphabetical symbols.c?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.In fact, letter and punctuation marks are not onlyused to conventionally encode a phonetic content,but also to introduce meta-discourse, and to sig-nal emotions, verbal effects (eg.
laughters), or at-titudes (humor, derision, emphasis etc).
If eachmedia enforces its own set of constraints and pro-motes idiosyncratic forms of writings, these newtypes of texts nonetheless share a lot of common-alities.
To effectively process these messages, itis thus necessary to develop robust language pro-cessing tools, capable of bearing with the extremeform of ?noise?
they contain.
In this study, wefocus more specifically on SMS, which, due tothe paucity of their input interface (mobile phonekeypads) seem to constitute the most challengingtype of data.
To a large extent, the techniques wepresent in this paper are also applicable to othertypes of electronic messages.The ?SMS language?
(or ?texting language?
)has been the subject of several linguistic studies(notably, for French, (Anis, 2001; Fairon et al,2006)), which have emphasized its main charac-teristics, amongst which the extraordinary ortho-graphic variability of lexical forms.
In brief, thisvariability results partly from the mixing of severalencoding systems: in SMS, the usual alphabeticsystem competes with a more ?phonetic?
type ofwriting (e.g.
rite for right1), as well as with tracesof a ?consonantic?
spelling (vowels are deleted,as in wrk for work or cn for can), and withnon-conventional use of letters or numbers, some-times used to encode the phonetic value of their1We will illustrate this general presentation of the SMSlanguage using examples taken from English messages, eventhough our systems deal with French messages.
As far as wecan see, the same types of deviations from the orthographicnorm are observed in both languages, albeit in different pro-portions.
A more thorough comparison of both languages cer-tainly remains to be carried out.441spelling, as in ani1 for anyone.
These spelling sys-tems can also be mixed as in Rtst (for artist) orbcum (for become).
This variability is also the re-sult of an informal style of communication, whichlicenses many deviations from the orthographic(simplification of repeated consonants, use of non-conventional abreviations) and grammatical (ab-sence of case distinction, erratic use of punctuationmarks, non-respect of agreement or tense mark-ers, etc) prescriptions, notwithstanding truly unin-tentional typos.
Finally, practitioners of the tex-ting language excel in devising acronyms whichcondense, sometimes in a radical way, multi-wordunits: this is for instance the case with afair, whichstands for as far as I recall.
As a result, from anatural language processing (NLP) point of view,these messages contain an abnormally high rate ofout-of-vocabulary forms, and the ambiguity of ex-isting word forms is aggravated, two factors thatcontribute to degrade the performance of naturallanguage processing tools.
Recovering a normal-ized orthography seems thus to be a necessary pre-processing step for many real-world NLP applica-tions, such as text-to-speech, translation, or textmining applications (filtering, routing, informationretrieval, etc).These short messages have so far received rel-atively little attention from the NLP community2:see, for English, (Aw et al, 2006; Choudhury etal., 2007), which both address the problem withstatistical learning techniques, and, for French,(Guimier de Neef et al, 2007), which detailsa complete pipe-line of hand-crafted, symbolic,modules.
In fact, the problem of normalizingSMS shares a lot of commonalities with other NLPapplications, and can be addressed from severalviewpoints.
The first, maybe the most natural an-gle, is to make an analogy with the spelling cor-rection problem.
This problem has been exten-sively studied in the past and a variety of statisti-cal approaches are readily available, most notablythe ?noisy channel?
approach (see eg.
(Church andGale, 1991; Brill and Moore, 2000; Toutanova andMoore, 2002)).
An alternative metaphor is thetranslation metaphor: under this view, the normal-ization task is accomplished by taking the SMS2A couple of on-line SMS-to-English translation systemsare accessible on the Internet, see notably http://www.transl8it.com/ and http://www.lingo2word.com/; ?Netspeak?
dictionaries, again for English, alsoabound.
The situation is more or less comparable for French,see eg http://www.traducteur-sms.com/.language as a foreign language, and using standard(statistical) translation techniques.
Both viewshave their own merit, and their limitations, whichwe shall review shortly.
In this paper, we proposeyet another metaphor, which stems from the simi-larities between the SMS language and speech, andnotably from the fact that in SMS, word separatorsare much less reliable than in conventional writ-ings.
As a result, it seems necessary to implementtechniques, which are, as in speech recognition,capable of recovering the correct word segmenta-tion.The main contribution of this work is to present,evaluate and contrast two approaches to the SMSnormalization problem.
We demonstrate that bothapproaches have different advantages and pitfalls,and show their combination yields significant im-provements wrt.
to both single systems.This paper is organized as follows: in section 2,we discuss these three metaphors; then go on todescribe our own implementation of two differentsystems for normalizing SMS in 3.
A comparativeevaluation of these systems is conducted in sec-tion 4, where we emphasize the complementarityof both approaches, and assess the performance ofa combined systems.
Section 5 presents a sum-mary of the main findings and future prospects.2 Three metaphors for SMSnormalization systemsIn this section, we set the general problem of SMSnormalization, and discuss, based on the analysisof SMS examples, the relevance of various NLPapproaches to this task.2.1 The "spell checking" metaphorA first approach to the problem considers each in-put token as ?noisy?
version of the correct wordform: normalization is thus viewed as a spellchecking task.
The spell-checking problem has re-ceived considerable attention in the past, and a va-riety of correction techniques have been proposed:in this context, noisy channel models (Church andGale, 1991; Brill and Moore, 2000; Toutanova andMoore, 2002), to quote just a few, constitute one ofthe predominant and most successfull approaches.Under this paradigm, correction is performed on aword-per-word basis, and concerns primarily out-of-vocabulary tokens: the general assumptions arethat most words are correctly spelled, and thatin-vocabulary words should preferably be left un-442touched.
In this context, the best correction(s) wof an erroneous word v is retrieved from the dictio-nary by combining the individual context indepen-dant probability ofw with an error model probabil-ity, which computes the probability of mistyping vforw, based on the surface similarity between bothforms.
The key component here is the error model,which should not only capture orthographic simi-larities (Brill and Moore, 2000), but also phoneticsimilarities (Toutanova and Moore, 2002).This framework easily extends to the case whereseveral words should simultaneously be corrected:it is simply a matter of exploring the lattice of allpossible corrections, which can be re-ranked us-ing conventional tools such as statistical languagemodels.
This is basically the idea behind the reacsystem (Michel Simard, 2001),which recovers thecorrect accentuation of unaccented French textsusing an error model, complemented with a sta-tistical language model.As far as SMS are concerned, this approachis essentially the one followed by (Choudhuryet al, 2007), which models the joint probabil-ity of observing the word w represented by thecharacter sequence c1...clby a Hidden MarkovModel (HMM) whose topology takes into accountboth ?graphemic?
variants (typos, omissions of re-peated letters, etc) and ?phonemic?
variants (i.espellings that resemble the word?s pronunciation).This HMM is initialized by considering the word?sreceived orthography and phonology, with addi-tional transitions to account for the possibility ofinserting, substituting or deleting symbols.
For themost frequent words in the corpus, the various pa-rameters associated with these transitions are esti-mated on a training corpus; various heuristic arethen used to plug these values in the HMMs thatmodel the less frequent dictionary items.2.2 The ?translation?
metaphorA second approach to the problem consists inadopting the translation metaphor: using this anal-ogy, the SMS language is just another foreign lan-guage and the normalization can be viewed as a?pure?
machine translation (MT) task.Using machine translation tools might be re-garded as ?an overkill?
(Choudhury et al, 2007),considering the close relationships between sourceand target languages.
Furthermore, learning thekinds of many-to-many correspondences betweensource and target sentences that make up for thehigh translation accuracy of phrase-based systemsmight be seen as introducing an unnecessary com-plexity, as SMS tend to be shorter, in terms ofwords, than their normalized counterparts.
Thissuggests that looking for many (on the normal-ized side) to one (on the SMS side) might be goodenough to capture most pairings.
Finally, statisticalmachine translation tools incorporate mechanismsto model the possible mismatch in word order be-tween source and target, which are virtually non-existing when it comes to translating SMS.This metaphor is, nonetheless, the one resortedto in (Aw et al, 2006), which uses a statisti-cal phrase-based machine translation tool to con-vert English SMS texts into standardized English.This system incorporates some of the peculiaritiesof this translation task, which both simplifies theconstruction of the phrase-table and the decodingsearch algorithm.
Using this system, (Aw et al,2006) reports a 0.81 BLEU (Papineni et al, 2001)score on a set of 5,000 English SMS.Normalization as translation is certainly a nat-ural, and simple to implement, idea.
Usingphrase-based systems, it becomes possible tomodel (context-dependant) one-to-many relation-ships that are out-of-reach of the spell checkingapproach.
We feel that it still overlooks some as-pects of the task, notably the fact that the lexi-cal creativity attested in SMS messages can hardlybe captured in a static phrase table, where corre-spondences between SMS phrases and normalizedphrases are learned by rote, rather than modeled.2.3 The "speech recognition" metaphorThe SMS language has on occasions been de-scribed, sometimes abusively, as being closer tooral productions than to regular written texts.
Ifwe do not subscribe to this view, we nonethelessfeel that a third metaphor is worth considering, thatwe call the ?automatic speech recognition?
(ASR)metaphor.
This analogy stems from the fact that,for a significant fraction of tokens, the spelling ofSMS forms tends to be a closer approximation ofthe phonemic representation of a word than of isits normative spelling.In the speech recognition metaphor, an SMSmessage is thus primarily viewed as an alpha-betic/syllabic approximation of a phonetic form.Given a suitable mechanism for converting theSMS stream into a phone lattice, the problem ofSMS normalization becomes very similar to that443of speech recognition, that is, the decoding of aword sequence in a (weighted) phone lattice.
Itactually becomes a much simpler problem, as (i)the acoustic ambiguity of speech input is typicallymuch higher than the phonemic indeterminacy ofSMS messages, (ii) some segmentation informa-tion is already available in the SMS text, which isin sharp contrast with (continuous) speech recogni-tion, where word boundaries have to be uncovered.Based on this general principle, we devised anASR-like normalization system, which has threeadditional benefits: using a phonemic approxima-tion provides the system with the ability to correctsome (unintentional) typos; adopting an ASR-likearchitecture provides us with a ?natural?
frame-work for resegmenting agglutinated word forms;finally, in the larger context of SMS-to-speech ap-plications, which is one of our targeted applica-tions, the computation of a phonemic representa-tion of the message can prove extremely valuable.3 Two normalization systems3.1 The MT-like systemOur first normalization system is entirely based onopen-source, public domain packages for statisti-cal machine translation.
Giza++ (Och and Ney,2003) is used to induce, based on statistical princi-ples (Brown et al, 1990), an automatic word align-ment of SMS tokens with their normalized coun-terparts; Moses (Koehn et al, 2007) is used tolearn the various parameters of the phrase-basedmodel, to optimize the weight combination and toperform the translation using a multi-stack searchalgorithm; the SRI language model toolkit (Stol-cke, 2002) is finally used to estimate statistical lan-guage models.
For this system, the training set hasbeen split in a learning set3(approximately 25000messages) and a development set (about 11700messages), which is used to tune parameters.As suggested in the previous sections, we haveconstrained both systems to consider only ?mono-tonic?
alignments between the source and the tar-get languages.3.2 The ASR-like systemIn a nutshell, our second normalization systemmimics the behavior of speech recognition sys-tem and decodes SMS message through a non-deterministic phonemic transduction; based onpreliminary experiments, this simple architecture3See section 4 for a description of the corpora.was augmented by an additional mechanism whichspecifically deals with out-of-vocabulary tokens.In the following, we denote ?
the set of alpha-betic symbols, ?
the set of phonemic symbols, and?
the set of lexical items.
Using these notations,our architecture can be described as a pipe-line ofthe following components:?
the first processing step consists in adictionary-based grapheme-to-phoneme con-version of some highly idiosyncratic forms,which deals with tokens4whose spelling inSMS does not reflect the phonemic content ofthe corresponding lexical item(s).
This is, forinstance, the case for common abbreviations(eg.
btw for by the way) and for instancesof ?consonantic?
spellings.
The dictionnaryused in the experiments reported above con-tains about 4,200 entries.This module is implemented as a finite-state transducer E which transduces lettersequences in ?
?into mixed grapheme andphoneme sequences (in (?
?
?)?).?
the second module converts the graphemicportions of the input message into a phone-mic string using a set of manually encodednon-deterministic letter-to-phone rules; theserules notably encode the possibility for eachsymbol to encode its spelling (eg.
u for /ju/ orR for /@r/).
Our system currently comprisesabout 150 letter-to-phone rules.
The outputof this module is a phone lattice, which rep-resents all the possible pronunciations of thecomplete input stream.This module is also implemented as a finite-state transducer P representing a rationalrelation between (?
?
?
)?and ??
: eachgrapheme-to-phoneme rule is compiled into afinite-state transducer; these individual rulesare then, once properly ordered, combinedthrough the composition operator.
The result-ing finite-state machine is denoted P .?
this phone lattice is then turned into a wordbased lattice, using an inverted pronuncia-tion dictionary, which registers the knownassociations between phone sequences andwords.
This inverted dictionary contains ap-proximately 21K words, which are the most4At this stage, we take advantage of usual word separatorsto identify tokens in the message.444frequent words in our reference training cor-pus.
This module is also implemented asa finite-state transducer D, which maps se-quences in ?
?to sequences in ?
?.A key aspect of this module is its ability toalter the original tokenization, by freely in-serting word separators whenever a phoneticword is recognized, no matter whether it cor-responds to a complete input token or not.This mechanism is illustrated on Figure 1.
Asa result, this system can bear with agglutina-tions (i.e.
absence of one or several word sep-arators) in the input sequence.?
the final processing step consists in searchingthe word lattice for the most probable wordsequence, as computed by a statistical lan-guage model (here, a smoothed n-gram lan-guage model estimated on the training cor-pus).
Here again, the entire process is com-puted through finite state operations: the out-put language of the previous steps is inter-sected with the stochastic language modelS (a weighted finite-state acceptor), and themost likely path is computed through dy-namic programming.As mentioned earlier, each module is imple-mented as a finite state acceptor or transducer;these modules are built and combined using toolsfrom the FSM (Mohri et al, 1998) and the GRM(Allauzen et al, 2005) toolkit.
As a result, theentire normalization process is computed by aweighted transducer (E ?P ?D ?S), which can beoptimized off-line as is commonly done in finite-state speech recognition systems (Mohri and Riley,1998).In addition to these four main modules, the pre-processing module of the ASR-like system con-tains a number of small enhancements that im-prove the normalization of dates and hours.
Wefurthermore had to modify the processing of out-of-vocabulary words: in the architecture sketchedabove, any word that does not belong to the vocab-ulary has to be decomposed into smaller, known,words, causing systematic errors.
Our final ASR-like system allows these forms to be either decom-posed phonetically or copied verbatim in the out-put.
A complete description of this system is givenin (Kobus et al, 2008).1230/0456<eps>:<eps>_#:<eps>p:paulO:<eps>l:<eps>_#:<eps><eps>:<eps>l:louisw:<eps>i:<eps>Figure 1: Transducing phone sequences into wordsequences with a dictionaryThis simplistic inverted dictionary recognizes twophonemic sequences: /lwi/ (for Louis) and /pOl/(for Paul).
Upon recognition of any such sequence,two transitions loop back to the initial state: onecarries the input symbol ?#?, which is used when-ever a word separator is encountered; the other isan ?
transition, which allows to re-segment the in-put stream.4 Experiments4.1 Experimental protocolThe experiments reported below use two corpora.The first one has been collected at the Universityof Aix-en-Provence (Hocq, 2006); it contains ap-proximately 9700 messages.
The second corpushas been gathered in Belgium by the Catholic Uni-versity of Louvain, and totals about 30000 mes-sages (Fairon and Paumier, 2006).
Both corporacontain, for each message, a reference normaliza-tion which has been produced and validated byhuman annotators.
Both corpora were merged,lowercased, stripped from punctuation signs andstandardized (in particular with respect to theanonymization conventions).
This database wassplit in a training set (about 36700 messages) anda distinct test set of about 3000 messages.
Thetraining set was used both to train and tune theMT-like system and to estimate a 3-gram languagemodel required in both approaches, using standardback-off procedures.
Some relevant statistics re-garding the sub-corpora that were used for trainingare given in Table 4.1.For the evaluation, contrarily to (Aw et al, 2006;Guimier de Neef et al, 2007), who by analogy445Aix Louvain Total# messages 8,700 28,000 36,700Original messagesavg.
length 14.3 21.6 19.9# tokens 124 700 606 100 730 800# types 13 600 37 900 43 600% unknown 43.7 % 30.4 % 32.7 %Normalized messagesavg.
length 15.4 23.2 21.3# tokens 133 800 650 100 783 900# types 8 200 20 800 23 300Table 1: Statistics of the training corporaStatistics on the original messages are computedafter preprocessing (punctuation removal, etc.
);the length of a message is the number of tokens;% unknown is the percentage of tokens that do notoccur in the normalized message.with the machine translation task, assess their sys-tem with the BLEU metric (Papineni et al, 2001),we decided to measure the performance of our nor-malization tool with the Word Error Rate (WER)and Sentence Error Rate (SER) metrics.
Thischoice is motivated by the fact that the outcomeof the normalization process is _ notwithstandinga couple of arbitrary normalization decisions _ al-most deterministic, and does not warrant the useof BLEU, which is more appropriate to evaluatetasks with multiple references.
Additionally, wefeel that error rates are easier to interprete thanBLEU values; for the sake of comparisons, someBLEU scores will nonetheless be reported.4.2 Baseline resultsIn a first series of experiments, we evaluate our twosystems and analyze their respective strengths andweakness.
Table 4.2 reports the results of these ex-periments; the line ?initial?
gives the correspondingnumbers for the original messages, which gives arough idea of the number of words that must bemodified.
As these results demonstrate, the MT-like system proves to be much more accurate thanthe ASR-like system.Looking at the errors, the main problem withthe latter system stems from the loss of the origi-nal spelling and tokenization information incurredduring the grapheme-to-phoneme conversion step:as a consequence, many words that were correctlyspelled in the input message are erroneously reseg-mented and decoded.
This is evidenced by the highSub Ins Del WER SERinitial 33.23 0.42 8.54 42.18 91.39ASR-like 11.94 2.21 2.36 16.51 76.05MT-like 7.34 0.71 4.22 12.26 63.41Table 2: Evaluation of the baseline systemsColumns ?Sub?, ?Ins?, and ?Del?
report respectivelythe number of substitution, insertion and deletionerrors at the word level.number of substitutions and insertions producedby this system, a large number of which concernfunction words.
This phenomena is accentuated bythe excessive liberality of grapheme-to-phonemerules.
For instance, to account for the erratic use ofaccentuated letters in SMS, the most general pro-nunciation rule for letter e (incidentally, e is themost frequent letter in French) predicts five pro-nunciations: /@/, /e/, /E/, /?/, /?/, plus the pos-sibility of being deleted.
As a result, first groupverbal forms such as aime (?I or he/he love(s)?
)yield (at least) six different pronunciations, whichresult in many more combinations after resegmen-tation, such as aime (?
(I, you, he/she) love(s)?),aim?
(?loved?
), aimer (?to love?
), aime et (?I loveand), aime est (I love is) etc.
The same occurs withde (?of (the)?, ?some-SING?)
and le (?the-SING?
),which, through the phonemic encoding/decoding,become systematically ambiguous with their cor-responding plural des and les.
Sorting out the cor-rect combination seems to be too hard a task forthe statistical language model, since all these hy-potheses include very high frequency tokens.The MT-like system is significantly less error-prone: an error analysis reveals that the most com-mon errors concern the insertion or deletion offunction words, which can be attributed to noisyalignments in the phrase table.
Another frequentsource of error stems from agglutinated forms, no-tably combinations of clitic(s)+verb (e.g.
jtombraifor je tomberai (?I will fall?
), jrentr for je rentre(?I am coming back?))
or (preposition and/or ar-ticle)+noun or verbs (e.g.
cours 2droit for coursde droit (?law class?
), dsortir for de sortir (?togo out?)...
): whenever these forms are met in thetraining corpus, they can be correctly decoded;however, many novel forms only occur in the testset, owing to the fact that these types of aggluti-nations are ?productive?
(in the appropriate con-text).
Contrarily to the findings of (Choudhuryet al, 2007), which considered English messages,446our corpus study reveals that this phenomena is farfrom marginal, and is a systematic source of errorsfor theMT system.
It is noteworthy that about 17%of the tokens in the test SMS corpus do not occur inthe training set, when the ?true?
out-of-vocabularyrate (computed on the reference messages) is onlyabout 2.1 %.Both systems are finally at pain to correctlyrecover the right number/gender/tense agreement,which is a general problem with n-gram languagemodels in French, aggravated here by some irre-ducible indeterminacy: should ?d?sol?
?
(masc.)
in?je suis d?sol?
?
be corrected as ?d?sol?e?
(fem) ?ultimately, this depends on the sex of the sender,which may be deduced from some other, poten-tially long distant, part of the message; the sameindeterminacy occurs with the normalization of?1 ?, which can be mapped to ?un?
(masc.)
or ?une?
(fem); with ?aurai ?
(?I will have?
), which can bemapped with ?aurai ?
or ?aurais?
(?I would have?
),etc.4.3 System combinationThe analysis of normalization errors reveals thatboth systems have different strengths and weak-nesses, suggesting that they could be used in com-bination.
Indeed, oracle selection of the best out-put on a per message basis would yield an over-all 9,63 WER, about 2.5 points absolute below theperformance of the MT-like system.Various ways to combine both approaches havebeen considered: we eventually decided to use theMT-like system for producing a first normaliza-tion; out-of-vocabulary tokens in the original SMSappear untouched in this output.
For each of these,we use the ASR-like system to produce a series of?local?
hypothesis, which are combined in a wordlattice.
This lattice is rescored with the statisti-cal language model to yield the final output.
Thissimple combination proved to yield significant im-provements, decreasing the word-error rate from12.26 to 10.82.
The corresponding BLEU scoreis close to 0,8, in line with the findings of (Awet al, 2006) for English, and comparing favorablywith the 0.68 score reported in (Guimier de Neef etal., 2007) (for French, using a different test bed).Preliminary experiments suggest that using n-bestlist outputs from Moses instead of just the one bestcould buy us an small additional WER decrease.The typical improvements brought by the com-bined system are illustrated by the following exam-ple, where two cases of agglutinated word formsare corrected, resulting in a correct output:SMS oubli?2tdir: tom a pom?
cfoto dlui en stringMT-like oubli?2tdir tom a paum?
sesphotos dlui en stringCombined oubli?
de te dire tom a paum?ses photos de lui en string(I) forgot to tell you (that)tom lost photos of himself ina thong5 Conclusion and PerspectivesIn this paper, we studied various ways to addressthe problem of normalization of SMS, by drawinganalogy with related NLP problems, and accord-ingly reusing as much as possible existing tools ormodules.
Following (Aw et al, 2006), we foundthat using off-the-shell statistical MT systems al-lows to achieve very satisfactory WER; combin-ing this system with a system based on an anal-ogy with the speech recognition problem yieldsan additional 1.5 absolute improvement in WER.As it stands, our statistical normalization systemseems to be sufficiently efficient to be used for textmining purposes; it also provides a useful tool toquantitatively analyze the various mechanisms in-volved in SMS spelling.
The problem nonethelessremains far from being solved: our best systemstill makes at least one error on about 60% of thetest messages.There are a number of obvious improvementswe might consider, such as using more accu-rate grapheme-to-phoneme rules, or plugging in alarger statistical language model, but we feel thesewould buy us only small increase in performance.As a first step to improve our normalization sys-tem, we would rather like to combine the existingapproaches with a spell-checking approach.
Themost natural way to proceed would be to devise analternative letter-to-word finite-state transducer C,aimed at converting space separated sequences ofalphabetic symbols to the corresponding sequenceof words, allowing for usual spelling errors (dele-tion/insertion of a letter, substitution, etc).
Usingthe notations of section 3.2, the normalization sys-tem would thus be computed by the following fi-nite state machine: ([E ?
P ?D] ?
C) ?
S.Another natural extension would be to make thisfinite-state transducer stochastic: again, this would447be a rather simple matter to train this transducer us-ing the forward-backward algorithm (see (Jansche,2003)) on the available training data.6 acknowledgmentsThe authors wish to thank E. Guimier de Neef forproviding us with one of the databases and otheruseful resources.
Many thanks to our anonymousreviewers for helpful comments.ReferencesAllauzen, Cyril, Mehryar Mohri, and Brian Roark.2005.
The design principles and algorithms of aweighted grammar library.
International Journal ofFoundations of Computer Science, 16(3):403?421.Anis, Jacques.
2001.
Parlez-vous texto ?
Guide desnouveaux langages du r?seau.
?ditions du ChercheMidi.Aw, Aiti, Min Zhang, Juan Xiao, and Jian Su.
2006.A phrase-based statistical model for SMS text nor-malization.
In Proceedings of COLING/ACL, pages33?40.Brill, Eric and Robert C. Moore.
2000.
An improvederror model for noisy channel spelling correction.
InProceedings of the 38th Annual Meeting of the As-sociation for Computational Linguistics, pages 286?293, Hong Kong.Brown, Peter F., John Cocke, Stephen Della Pietra, Vin-cent J. Della Pietra, Frederick Jelinek, John D. Laf-ferty, Robert L. Mercer, and Paul S. Roossin.
1990.A statistical approach to machine translation.
Jour-nal of Natural Language Engineering, 16(2):79?85.Choudhury, Monojit, Rahul Saraf, Vijit Jain, SudeshnaSarkar, and Anupam Basu.
2007.
Investigation andmodeling of the structure of texting language.
InProceedings of the IJCAIWorkshop on "Analytics forNoisy Unstructured Text Data", pages 63?70, Hyder-abad, India.Church, Kenneth W. and William Gale.
1991.
Proba-bility scoring for spelling correction.
Statistics andComputing, 1:91?103.Crystal, David.
2001.
Language and the Internet.Cambridge University Press.Fairon, C?drick and S?bastien Paumier.
2006.
A trans-lated corpus of 30,000 French SMS.
In Proceedingsof LREC 2006, Genoa, Italy.Fairon, C?drick, Jean Ren?
Klein, and S?bastien Pau-mier.
2006.
Le langage SMS.
UCL Presses Univer-sitaires de Louvain.Guimier de Neef, ?milie, Arnaud Debeurme, andJungyeul Park.
2007.
TILT correcteur de SMS :?valuation et bilan quantitatif.
In Actes de TALN,pages 123?132, Toulouse, France.Hocq, S. 2006.
?tude des sms en fran?ais : constitutionet exploitation d?un corpus align?
sms-langue stan-dard.
Technical report, Universit?
Aix-Marseille.Jansche, Martin.
2003.
Inference of string mappingsfor language technology.
Ph.D. thesis, Ohio StateUniversity.Kobus, Catherine, Fran?ois Yvon, and G?raldineDamnati.
2008.
Transcrire les SMS comme on re-conna?t la parole.
In Actes de la Conf?rence surle Traitement Automatique des Langues (TALN?08),pages 128?138, Avignon, France.Koehn, Philipp, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondrej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: Opensource toolkit for statistical machine translation.
InProc.
Annual Meeting of the Association for Com-putational Linguistics (ACL), demonstration session,Prague, Czech Republic.Michel Simard, Alexandre Deslauriers.
2001.
Real-time automatic insertion of accents in French text.Natural Language Engineering, 7(2):143?165.Mohri, Mehryar andMichael Riley.
1998.
Network op-timisation for large vocabulary speech recognition.Speech Communication, 25(3):1?12.Mohri, Mehryar, Fernando Pereira, and Michael Riley.1998.
A rational design for a weighted finite-statetransducer library.
Lecture Notes in Computer Sci-ence, (1438).Och, Franz Josef and Hermann Ney.
2003.
A system-atic comparison of various statistical alignment mod-els.
Computational Linguistics, 29(1):19?51.Papineni, Kishore, Salim Roukos, ToddWard, andWei-Jing Zhu.
2001.
Bleu: a method for automaticevaluation of machine translation.
Technical Re-port RC22176 (W0109-022), IBM Research Divi-sion, Thomas J. Watson Research Center.Stolcke, Andreas.
2002.
Srilm ?
an extensible lan-guage modeling toolkit.
In Proceedings of the Inter-national Conference on Spoken Langage Processing(ICSLP), volume 2, pages 901?904, Denver, CO.Toutanova, Kristina and Robert Moore.
2002.
Pronun-ciation modeling for improved spelling correction.In Proceedings of the 40th Annual Meeting of the As-sociation for Computational Linguistics, pages 144?151, Philadelphia, PA.V?ronis, Jean and ?milie Guimier de Neef.
2006.
Letraitement des nouvelles formes de communication?crite.
In Sabah, G?rard, editor, Compr?hensionautomatique des langues et interaction, pages 227?248.
Paris: Herm?s Science.448
