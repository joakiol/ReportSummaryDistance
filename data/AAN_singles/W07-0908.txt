Proceedings of the Workshop on Language Technology for Cultural Heritage Data (LaTeCH 2007), pages 57?64,Prague, 28 June 2007. c?2007 Association for Computational LinguisticsAnchoring Dutch Cultural Heritage Thesauri to WordNet: two case studiesVe?ronique Malaise?
and Antoine IsaacVrije UniversiteitAmsterdamThe Netherlands{vmalaise, aisaac}@few.vu.nlLuit GazendamTelematica InstituutEnschedeThe NetherlandsLuit.Gazendam@telin.nlHennie BrugmanMax Planck Institutefor Psycholinguistics, NijmegenThe NetherlandsHennie.Brugman@mpi.nlAbstractIn this paper, we argue on the interest of an-choring Dutch Cultural Heritage controlledvocabularies to WordNet, and demonstratea reusable methodology for achieving thisanchoring.
We test it on two controlledvocabularies, namely the GTAA thesaurus,used at the Netherlands Institute for Soundand Vision (the Dutch radio and televisionarchives), and the GTT thesaurus, used to in-dex books of the Dutch National Library.
Weevaluate the two anchorings having in mind aconcrete use case, namely generic alignmentscenarios where concepts from one thesaurusmust be aligned to concepts from the other.1 IntroductionCultural Heritage Institutions are the keepers of largecollections of data.
To optimize the core tasks ofindexing and searching through these collections,controlled vocabularies like thesauri are often used.These vocabularies are structured concept networks1and help indexers to select proper subjects for de-scription, and users to formulate queries or to browse1The typical semantic relationships found between elementsfrom thesauri are Broader Term linking a specialized conceptto a more general one, Narrower Term, its inverse relationship,and Related Term, which denotes a general associative link.Thesauri also contain lexical information, where the preferredterms used for description are given synonyms or non-preferredterms (Use and Used for links), as well as general scope notesgiving indexers instructions regarding the use of a term.collections using the concepts that appear in themetadata.The Netherlands Institute for Sound and Vision2,for example, uses the GTAA thesaurus for indexingpublic radio and TV programs ?
GTAA is a Dutchabbreviation for ?Common Thesaurus [for] Audio-visual Archives?.
Its hierarchy of subjects containsabout 3800 Preferred Terms and 2000 Non Preferredterms.
A second example is the GTT thesaurus, whichcontains 35000 concepts, gathering 50000 preferredand non-preferred Dutch terms.
This thesaurus isused to index and retrieve books from the Dutch Na-tional Library3 ?
GTT is a Dutch abbreviation for?GOO keyword thesaurus?, GOO referring to the JointSubject Indexing system used by many Dutch li-braries.Besides this classic scenario, thesauri can also al-low for (semi-)automatic optimization of search pro-cesses, like query expansion exploiting their hierar-chical structure.
But the available structure mightnot be rich and regular enough for such purposes.
Infact, it has been shown that a mapping to a richerand sounder terminology, like the English Word-Net (Fellbaum, 1998), would enable more sophisti-cated query expansion or other inferencing possibil-ities (Voorhees, 1994; Hollink, 2006).
This will be-come especially true now that WordNet exists in theform of an RDF ontology (van Assem et al, 2006).Mapping Cultural Heritage controlled vocabular-2http://www.beeldengeluid.nl3http://www.kb.nl57ies in Dutch to WordNet can also be beneficial forsharing information across institutions, which is dif-ficult when the metadata attached to the different doc-uments come from different thesauri.
This issue canbe solved by building equivalence links between theelements from these different vocabularies, as in (vanGendt et al, 2006).
This vocabulary alignment prob-lem is comparable to the ontology matching one, andtechniques similar to the ones developed by the Se-mantic Web research community can be applied here.As found e.g.
in (Euzenat, 2004), the existing meth-ods are quite diverse, and proposed strategies oftenmix several individual techniques:?
lexical techniques, trying to compare the labelsfound in vocabularies;?
structural techniques, assessing similarities be-tween concepts from the structure of vocabular-ies (e.g.
hierarchical links);?
instance-based techniques, looking at the ob-jects that are actually populating the ontologiesto infer from their similarities correspondencesbetween the concepts they instantiate.?
techniques making use of some backgroundknowledge source, by trying to derive from theinformation found there relations between theelements from the original vocabularies.Here, we are interested in the last kind of techniques.In these approaches, concepts from the vocabular-ies to be aligned are first attached ?
?anchored?
?to the concepts from a third vocabulary (Aleksovski,2006).
Then, these anchors in the background vo-cabulary are compared together.
When a relation isfound between them4, a similar relation can be in-ferred between the elements from the vocabulariesto be aligned.
This is especially interesting whenthe lexical overlap between the vocabularies is lowor when the vocabularies are quite poorly structured:it is expected then that the background knowledgewill alleviate these shortcomings.
The choice of4The reader can turn to (Budanitsky and Hirst, 2006) for anoverview of the different methods that have been proposed in thisfield.this knowledge is therefore crucial, and WordNet,which has a rich structure and a broad coverage, hasbeen exploited in many existing alignment methods(Giunchiglia et al, 2005; Castano et al, 2005).For these reasons ?
even if this paper will onlyfocus on the alignment scenario ?
we wanted to ex-periment the anchoring of two aforementioned Dutchthesauri to WordNet.
Unlike literature about linkingEnglish thesauri to WordNet, we propose in this pa-per an anchoring method for vocabularies in otherlanguages, and experiment it on these two thesauri,testing its usefulness in terms of possibilities for vo-cabulary alignment.
The remainder of the paper isorganized as follows: in section 2, we present thegeneral anchoring methodology.
The anchoring ex-periment is described in section 3: first the GTAAcase (section 3.1) and then the GTT one (section 3.2),as a reusability test.
We evaluate the two anchoringprocesses in section 3.3 and conclude on general re-flexions about this method.
Then, we show exam-ples of such anchorings in the context of a possiblealignment between GTAA and GTT in section 4.
Weconclude on perspectives to this research in section 5.2 Anchoring methodologyThe anchoring experiment presented in this paper isbased on a comparison of lexical descriptions of thethesaurus terms with the ones of WordNet synsets,the glosses: WordNet is a lexical database of En-glish, which entries are grouped ?into sets of cog-nitive synonyms (synsets), each expressing a distinctconcept?5.
In contrast to many anchoring methods,like the one in (Khan and Hovy, 1997), we do notcompare the terms from our thesauri to the labels ofsynsets, but measure the lexical overlap of their de-scriptions.
The same approach has already been fol-lowed, for example, by (Knight and Luk, 1994).As the thesauri we focus on in this paper are inDutch, we first need to map their terms to English de-scriptions, and possibly translations, to make a com-parison with the English glosses.
Given the fact thatthese thesauri cover a broad range of topics, we hy-pothesize that using a general language bilingual dic-5http://wordnet.princeton.edu/58tionary will lead to a good coverage of their content.Additionally, it might give on top of the definitions?
i.e.
the natural language descriptions of a term?smeaning ?
useful information such as term transla-tions and Part Of Speech (POS) tags ?
their gram-matical category: noun, verb, etc.
For each thesaurusterm which has been associated to an English defini-tion, the rest of the anchoring procedure consists inchecking the overlap between the lexical content ofthe definitions and the one of the different WordNetglosses, considered as bags of words.
The hypothesisis that the closest gloss should give us a pointer to asynset semantically equivalent to the intended mean-ing of a thesaurus term.3 Anchoring feasibility experiments andevaluations3.1 Anchoring GTAA conceptsFirst step: Finding English definitions for GTAAterms The first step in mapping Dutch terms fromthe GTAA to WordNet was to select an online dic-tionary that would cover a significant part of the the-saurus entries and that would allow automatic queriesfor these terms.
We have tested the bilingual dictio-nary LookWAYup6, which returned a 2222 results ?definitions and translations ?
on our query set.This query set consisted in the list of GTAA Pre-ferred terms (3800), Non preferred terms (2000) andtheir singular forms7 (3200).
These singular formswere computed in the context of a MultimediaNproject8, on the basis of linguistic derivational rulesand a manual correction.Given the fact that most of the thesaurus terms arein plural form, but not all of them9, and knowing thatthe dictionary entries are only standard lemma forms(most of the time in singular), we first assumed that6Built by RES Inc., Canada, online at the URL: http://lookwayup.com/free/.7Following the recommendations of the ISO standard, mostof GTAA terms are in plural form.8MultimediaN Project 5 ?
Semantic Multimedia Ac-cess, http://monetdb.cwi.nl/projects/trecvid/MN5/index.php/Main_Page, transformation done by GijsGeleijnse, from the Philips Research group.9For example, the term corresponding to Baptism is in singu-lar form.queries on the dictionary with a plural form wouldnot generate a result, and simply added the singu-lar forms to the singular ones in the query set.
Itturned out that the dictionary gave result for someplural forms, creating noise: some plural forms cor-responded to lemmas of verbs, and a spelling cor-rection facility provided definitions for some pluralforms.Removing doubles We cleaned manually the firstset of errors, and automatically the last one, basedon POS tag information.
In the future, we will avoidintroducing duplicate lemmas in our the query set.After cleaning, 1748 terms had one or more trans-lation in English together with their associated POStag(s) and definition(s)10.
This low number, com-pared with the original set of 5800 distinct thesaurusterms can be explained by the fact that our vocabu-lary contains numerous multi-words terms and alsocompound entries, both of which are rarely dictio-nary entries.
We discuss possible solutions to thisshortcoming in section 3.3.POS tag-based cleaning We did then a rough man-ual evaluation of these candidate definitions.
Theevaluation was conducted by three people and tookabout one day each.
It turned out that some of thedefinitions were irrelevant for our task: the Dutch Bijwas associated with the English Bee and Honey bee,but also with the preposition by.
We used again theinformation given by the POS tag to remove theseirrelevant definitions: we kept only definitions ofNouns and (relevant) Verbs.
After this last cleaning,some terms still had more then one definition.Cleaning based on thesaurus relationships Weused the hierarchical relationship in the thesaurus tocheck the intended meaning of these terms: for ex-ample, Universiteit (University) had a Broader Termrelationship with Wetenschappelijk onderwijs (Scien-tific education), so its meaning is restricted to the?Educational aspect?, and it should not be used todescribe TV programs about University buildings forinstance.
We used this information to restrict the101299 terms have more than one definition.59Step ResultGathering query set 3800 + 2000 + 3200termsQuerying dictionary 2222 defined termsRemoving doubles 1748 different definedtermsPOS tag-based cleaningThesaurus-based cleaning1655 def.
terms, 7530definitionsAnchoring to WordNet 1060 anchored con-ceptsTable 1: GTAA term anchoring experimentnumber of valid candidate definitions associated withevery GTAA term.
But in some cases the distinc-tion was hard to make between the different defini-tions, or no clue was provided by the thesaurus todismabiguate the senses of the term: sometimes itdid not have any relationship to other concepts norexplanatory text (Scope Note).Conclusion of the first step As a final result, assummarized in table 1, 1655 GTAA terms had oneor more English equivalent and their related candi-date definitions (7530).
We decided to postpone amore in-depth validation to the evaluation of anchor-ing results with WordNet: we kept all candidate def-initions and translations that were not obviously in-correct, and checked the WordNet anchoring resultto see if some further refinement had to be done.
Theidea was that the anchoring process would only workfor parts of the definitions, so we wanted to keep asmany data as possible.Second step: Anchoring to WordNet synsets Westemmed the candidate definitions of GTAA terms andthe glosses from WordNet with the Porter stemmer toaugment mapping possibilities.
Stemming is the op-eration of reducing words to a root, for example byremoving the ?s?
character at the end of an (English)word in plural form.
This process can reduce differ-ent unrelated words to a same root, and hence shouldbe handled with care, but it requires less resourcesthen a full fledged lemmatizing and helps compar-ing a larger number of words then on the basis of thegraphical forms only.
As announced, in order to mapsynset to GTAA terms, we compared their lexical de-scriptions: we compared the different sets of stems ina simple bag-of-words approach.
We actually foundout that the definitions of the online dictionary wereexact matches with WordNet glosses, thus all definedterms could be straightforwardly anchored to one ormore synsets.
In the end, 1060 concepts from GTAAare successfully anchored to a synset, which repre-sents 28% of the total number of concepts.Evaluation of the results We evaluated the num-ber of semantically relevant anchorings for a ran-dom representative part of the the 1655 GTAA termsthat had one or more WordNet anchor: we evaluated1789 mappings out of 7530.
On these 1789 map-pings, 85 were not equivalence links: 5 out of these85 links were relating Related Terms (like zeerov an-chored to corsair, the first being in GTAA a profes-sion and the second a ship in Wordnet), 17 pointedto Broader Terms, and the others were mapping aterm with a correct translation that was correct perse but did not correspond to the intended meaningof the term in GTAA.
For example, two anchoringswere proposed for Vrouwen: married woman and fe-male person, the latter one being the only valid forour thesaurus.
The first cases (RT and BT relation-ships between the original term and its anchoring)still provide useful information for aligning vocab-ularies, but we took only equivalence relationshipsinto account in this experiment.An additional evaluation that was also performedon a sample set was to check that non-preferred termsthat were given a definition were pointing to the samesynset as their related preferred terms.
It turned to becorrect for the evaluated pairs.On a qualitative perspective, we found differenttypes of mappings:?
some GTAA terms had more then one transla-tion, all of them pointing to the same synset: thiswas the confirmation that the mapping from theterm to the synset was correct;?
some GTAA terms had more then one trans-lation, pointing to different but close synsets:nothing in the thesaurus content could help usdistinguish between the different synsets, thuswe kept the different possibilities;60?
some different GTAA terms pointed to a samesynset and, although they were not linked inthe thesaurus, they had a semantic relationship.This information can be used to enrich the struc-ture of the GTAA.We can conclude that the anchoring was quite suc-cessful: only 4.7% of the anchorings were incorrectin the test sample.
And this was due to cases wheremultiple senses were linked to a same term, whichwould not cause a big problem in a semi-automatedanchoring process.
Moreover, this process can bringan additional value to the thesaurus structure itself,on top of the possible applications mentioned in theintroduction.3.2 Anchoring GTT conceptsSetting We carried out for GTT the same exper-iment as for GTAA, but did not compute singularforms, although GTT terms are generally in pluralform.
Also, because GTT had 70% of its concepts al-ready translated to English by human experts, we de-cided that we would measure the global performanceof our method based on this translation gold standard,additionally to manually assess the relevance of theproduced anchorings from GTT to WordNet.Results Out of the 35194 GTT general subjects,only 2458 were given some English definition andtranslation by the dictionary service we used.
For theset of 25775 concepts for which there was already atranslation, the figure drops down to 2279, slightlyless than 9%.As said, we tested the validity of these definitionsand translations by comparing them to the experttranslations.
Our assumption was that an English def-inition for a concept would prove to be correct if itsassociated term matched one of the expert transla-tions of the concept11.
We found that 1479 of the2279 concepts being given both expert and automatictranslations had the expert translation confirming one11A manual checking of this assumption on the first 150 con-cepts matching the criterion demonstrated an error rate of 4%:4% of the concepts had no correct definition in their associatedglosses while there was a match between the expert translationand one of the terms linked to the definitions.of the automatically found ones, i.e.
a precision rateof 65% in terms of defined concepts.When measuring accuracy of the found Englishdefinitions for the 2279 defined concepts, we saw thatout of a total 3813 English definitions associated to aconcept, 2626 ?
69% ?
had an associated term con-firmed by the expert translation.We also tried to assess the quality of the trans-lations associated to the concepts of this set by ourmethod: out of 5747 terms proposed as translations,1479 matched the expert translation.
This precisionrate is low (25.7%) but it actually highlights one ofthe problem of the expert translations found in thethesaurus: the manual translation had a very low lex-ical coverage, having provided with very few syn-onyms for the ?preferred?
translations.
The set of25775 translated GTT concepts only brings 26954English terms in total.
.
.The evaluation by comparison to the expert trans-lation brings useful information, but it has somedrawbacks, especially the limited coverage of thetranslation work and a correctness assumption bring-ing a (small) error rate.
To complete it, we carriedout a manual investigation, inspired by what had beendone for the GTAA thesaurus.For this, we selected the 179 concepts that weretranslated by our method but had not previously beenassigned English labels by experts.
For this subset,441 glosses had been assigned.
Of these, 172 werecorrect, concerning 138 concepts.
We therefore ob-tain a 77% precision rate in terms of anchored con-cepts.
However, if we aim at assessing the qualityof the method and its potential to be used in a semi-automatic anchoring process, we have to consider theobtained glosses themselves.
And here precision fallsto 39%, which is a far less satisfactory figure.Feasibility of the proposed method in GTT caseSome of the previously mentioned anchorings towrong glosses could have been successfully foundby applying the heuristics mentioned in section 3.1.The use of POS tags and the checking of the singu-lar form of terms allowed to manually spot 41 ob-viously wrong results.
The other irrelevant glosseswere mainly found using the thesaurus information:61Comparison with expert Gold StandardConcepts with expert translation 25775Concepts with a definition 2279Concepts with def.
confirmed by GS 1479Total definitions given 3813Definitions confirmed by GS 2626Total translations given 5747Translations confirmed by GS 1479Manual evaluationConcepts 179Concepts with correct definition 138Total definitions given 441Correct definitions 172Global resultsTotal GTT concepts 35194Concepts with a definition 2458Concepts with correct definition 1617Total definitions given 4254Correct definitions 2798Table 2: GTT term anchoring evaluationthe Broader Term information helped to discriminate68 cases, compared with 6 for Related Term, 6 forsynonyms and 15 for scope notes.It is however still uncertain whether these differ-ent kinds of information can be used in a more au-tomatised setting.
If we could count on translationof broader and related terms to be done by the pro-cess we have applied, taking into account scope noteswould require more effort.
And the poor structure ofthesauri such as GTT ?
some 20000 concepts have noparents at all ?
makes such validations by semanticlinks difficult.
It is also important to notice that in14 cases, it was necessary to check the books whichhave been indexed by a concept to find out its precisemeaning.This could yet be compensated by an interestingresult we have observed: the anchoring method gaveus material for inferring new semantic links, as in theGTAA case.
Amongst the translated GTT concepts,689 concepts are sharing at least one synset and arenot connected by a thesaurus link.
We found inter-esting matches, such as gratie (pardon) and absolutie(absolution) or between honger (hunger) and dorst(thirst).
This potential for enriching thesauri couldactually be used to spark some positive feedback loopfor the anchoring process itself: a richer vocabularyenables for example to use with greater profit the se-lection strategies based on thesaurus structure.An important problem for the implementation ofsuch strategies remains to deal with disambiguation(when several English definitions are found, whichone shall be selected?)
in a context of fine-grainedvocabularies.
Both GTT and WordNet have a highlevel of precision, but they are focused on differentmatters.
Especially, for a same GTT term the dic-tionary pointed at several meanings that were veryclose, but considered as different synsets in Word-Net.
A typical example is the distinction made be-tween the gloss attached to moderation and temper-ance, ?the trait of avoiding excesses?, and the oneattached to moderateness and moderation, ?qualityof being moderate and avoiding extremes?.
Look-ing at the books indexed by the concepts which theseglosses were attached to, it was not clear whether theindexers systematically considered such a distinction.Finally, we made rough estimattions of recall ?the number of concepts that were correctly anchoredcompared to the number of concepts anchored in theideal case.
If we compare the 1479 correctly definedconcepts to the 25775 concepts being given an experttranslation, we find a very disappointing recall rateof 5.7%.
This very low performance is in fact largelydue to three recurrent situations in which the onlinedictionary could not give any translation:?
terms containing some special Dutch characters?
especially the so-called Dutch ij, where i and jmake a single character ?
and which occurs formore than 2000 concepts;?
specialized scientific terms, like kwantum-halleffect;?
complex notions, rendered in Dutch by com-pound words (e.g.
gebruikersinterfaces for userinterfaces), multi words (Algemene kosten forgeneral costs) or a mixture of the two (Grafis-che gebruikersinterfaces for graphic user inter-faces).Whereas the encoding problem appears fairly sim-ple, the last ones are more serious ?
they were indeedalso encountered in the GTAA case ?
and shall be dis-cussed further.623.3 Conclusion on the anchoring methodologyAs just mentioned, a drawback of our anchoringmethod is the fact that there are very few multi-word entries in dictionaries but they compose a largepart of thesauri, and particularly thesauri in Dutch.Previous work about assigning a semantic relation-ship between a multi-word term and its components(see (Ibekwe, 2005)) could be used in order to giveelements of solution to this problem.
Using this pre-processing, we could apply our method to the single-word part that corresponds to the generic meaningof the original multi-word term, and try to anchorthe single-word corresponding to the semantic root ofthe thesaurus?
multi-word term (Kosten for Algemenekosten ?
Cost for General cost ?
for instance).From a more conceptual point of view, however,further effort would be needed to adapt our anchor-ing method ?
and the subsequent alignment of onevocabulary with the other ?
to the cases where aconcept from one vocabulary should be anchored tomore than one element from WordNet.
More com-plex heuristics come closer to traditional anchoringproblems cases ?
without translation ?
and couldbe solved using existing solutions, as proposed by(Giunchiglia et al, 2005; Castano et al, 2005).The last problem encountered in the anchoringprocess was the fact that specialized notions, that alsoappear in general purpose thesauri, have usually nodefinition in a general language dictionary.
Special-ized dictionaries should be used as a complementaryresource.These different shortcomings reduced the cover-age of the anchoring, but our method has still posi-tive points: the number of obviously wrong anchorswas rather low for the found pairs and additional linkscould be provided for both of the source thesauri.This method also provides a starting point for an-choring complex and large vocabularies to WordNet,which is also a large lexical resource, and both arehard to grasp completely by a human expert.4 GTAA and GTT alignment using WordNetanchoring: a qualitative evaluationOnce the anchoring is performed, the synsets cor-responding to the terms from the different thesaurican be compared, in order to infer from them equi-valences between the original concepts, as is donein classical alignment techniques using backgroundknowledge.
In this section, we present some exam-ples illustrating the kind of alignment results one canexpect from a proper anchoring of our Dutch con-trolled vocabularies.First, we can confirm alignments of equal Dutchlabels: gtaa:arbeiders is aligned to gtt:arbeiderssince they are both anchored to the synset ?some-one who works with their hand, someone engagedin manual labor?.
In some cases, though, a firststemming or lemmatizing process would have beenneeded to achieve alignment, as in the example ofgtaa:bekeringen and gtt:bekering (Conversion, re-spectively in plural and singular form), or gtaa:biljartand gtt:biljartspel12 (Billiard and Billiard game).Nevertheless, the more interesting cases are theones involving concepts with large semantic overlapbut a small lexical one, as in the case of gtaa:plant(Plant) and gtt:begroeiing (Excessive growth of ve-getation) via the WordNet flora synset.
Begroeiing isactually semantically related in the GTT to the con-cept Planting.
Here, the translation process compen-sates for the lack of lexical coverage in the respectivevocabularies, which precisely corresponds to one ofthe traditional features background knowledge-basedtechniques boast.
We can also derive general con-ceptual similarity relationship based on the overlapbetween glosses, such as the one between gtaa:drankand gtt:alcohol, which are not direct matches but forwhich our method has found some common glosseslike ?an alcoholic beverage that is distilled rather thanfermented?.12Notice that substring-based matching could also give theseresults, but this method is usually very noisy for alignment pro-cesses and therefore must be used cautiously.635 Conclusion and perspectivesOur experiments showed that the partial anchoringof large Dutch controlled vocabularies to WordNetcan be done via a bilingual dictionary, even thoughthere is an obvious loss in information: not everythesaurus concept can easily be found in a generallanguage bilingual dictionary, and a preprocessing ofmulti-word and compound thesaurus entries has to bedone.
Yet, a significant part of the GTAA thesauruscould be anchored, and with some improvement tothe method this could be true for GTT too.
Besidesmulti-word and compound words processing, usefulextensions should also take into account specializeddictionaries and have a closer look at methodologiesfor anchoring a thesaurus term to multiple WordNetsynsets with close meanings.
We plan to test suchstrategies in future experiments, and hope to obtain abetter coverage of the thesauri.In this paper, we have sketched a way to use ofthese anchorings in a vocabulary alignment scenario,and underlined the potential gains on test examples.Even if the number of results given by the current im-plementation of our method is quite low, the readershould notice that the process can already, as is,suggest new relationships between concepts of thesource thesauri.
Moreover, proposed strategies inthe alignment field often advocate using combinedmethods: combined contributions can be used to pro-ceed with some cross validation if they overlap, orto provide with larger number of candidate for fur-ther (semi-)automatic selection.
In such a setting, ev-ery contribution of candidate links is welcome.
Inthis respect, what is useful here is the ability of aWordNet-based method to provide with results thatcould not be obtained with other techniques becauseof the lack of explicit semantic information and hier-archical structure in the original vocabularies.Finally, as mentioned in the introduction, there areother motivating use cases that we plan to experimentwith.
Especially interesting is the way a mappingwithWordNet can enhance the existing access to doc-ument collections of the Dutch Cultural Heritage In-stitutes by providing with query refinement servicesand browsing possibilities.AcknowledgementsThis research was carried out in the context of theCATCH projects CHOICE and STITCH, funded byNWO, the Dutch organization for scientific research.ReferencesAleksovski Z.
2006.
Matching Unstructured Vocabulariesusing a Background Ontology.
15th International Confer-ence on Knowledge Engineering and Knowledge Manage-ment (EKAW 2006).van Assem M., Gangemi A. and Schreiber G. 2006.
RDF/OWLRepresentation ofWordNet.
W3C Working Draft, 19 June2006.
http://www.w3.org/TR/wordnet-rdf/Budanitsky A. and Hirst G. 2006.
EvaluatingWordNet-basedMeasures of Lexical Semantic Relatedness, volume 32(1).Computational Linguistics, 13?47.Castano S., Ferrara A. and Montanelli S. 2005.
Matching On-tologies in Open Networked Systems: Techniques and Appli-cations, volume 5.
Journal on Data Semantics (JoDS).Euzenat J., coordinator.
2004.
State of the art on ontology align-ment.
KnowledgeWeb Deliverable 2.2.3.Fellbaum C. 1998.
WordNet An Electronic Lexical Database.MIT Press.van Gendt M., Isaac A., van der Meij L. and Schlobach S. 2006.Semantic Web Techniques for Multiple Views on Heteroge-neous Collections: a Case Study.
10th European Conferenceon Research and Advanced Technology for Digital Libraries(ECDL 2006), 426?437.Giunchiglia F., Shvaiko P., and Yatskevich M. 2005.
SemanticSchema Matching.
13th International Conference on Cooper-ative Information Systems (CoopIS 2005).Hollink L. 2006.
Semantic annotation for retrieval of visualresources.
PHD Thesis, Vrije Universiteit Amsterdam.Ibekwe-SanJuan F. 2005.
Clustering semantic relations for con-structing and maintaining knowledge organization tools.
vol-ume 62 (2).
Journal of Documentation, Emerald PublishingGroup, 229?250.Khan L. R. and Hovy E. 1997.
Improving the Precision ofLexicon-to-Ontology Alignment Algorithm.
AMTA/SIG-ILFirst Workshop on Interlinguas, San Diego, CA, October 28.Knight K. and Luk S. 1994.
Building a Large-Scale KnowledgeBase for Machine Translation.
In Proceedings of the AAAI-94 Conference.Voorhees E. 1994.
Query expansion using lexical-semantic re-lations.
17th International ACM/SIGIR Conference on Re-search and Development in Information Retrieval, 61?69.64
