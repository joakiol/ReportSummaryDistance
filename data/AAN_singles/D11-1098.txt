Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1058?1068,Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational LinguisticsLexical Co-occurrence, Statistical Significance, and Word AssociationDipak L. ChaudhariComputer Science and Engg.IIT Bombaydipakc@cse.iitb.ac.inOm P. DamaniComputer Science and Engg.IIT Bombaydamani@cse.iitb.ac.inSrivatsan LaxmanMicrosoft Research IndiaBangaloreslaxman@microsoft.comAbstractLexical co-occurrence is an important cue fordetecting word associations.
We propose anew measure of word association based on anew notion of statistical significance for lex-ical co-occurrences.
Existing measures typ-ically rely on global unigram frequencies todetermine expected co-occurrence counts.
In-stead, we focus only on documents that con-tain both terms (of a candidate word-pair) andask if the distribution of the observed spans ofthe word-pair resembles that under a randomnull model.
This would imply that the wordsin the pair are not related strongly enoughfor one word to influence placement of theother.
However, if the words are found to oc-cur closer together than explainable by the nullmodel, then we hypothesize a more direct as-sociation between the words.
Through exten-sive empirical evaluation on most of the pub-licly available benchmark data sets, we showthe advantages of our measure over existingco-occurrence measures.1 IntroductionLexical co-occurrence is an important indicator ofword association and this has motivated severalco-occurrence1 measures for word association likePMI (Church and Hanks, 1989), LLR (Dunning,1993), Dice (Dice, 1945), and CWCD (Washtell andMarkert, 2009).
In this paper, we present a new mea-sure of word association based on a new notion ofstatistical significance for lexical co-occurrences.
Ingeneral, a lexical co-occurrence could refer to a pair1We use the term co-occurrence to refer to a pair of wordsthat co-occur in a document with an arbitrary number of inter-vening words.of words that co-occur in a large number of docu-ments; or it could refer to a pair of words that, al-though co-occur only in a small number of docu-ments, occur close to each other within those docu-ments.
We formalize these ideas and construct a sig-nificance test that allows us to detect different kindsof co-occurrences within a single unified framework(a feature which is absent in current measures forco-occurrence).
Another distinguishing feature ofour measure is that it is based solely on the co-occurrence counts in the documents containing bothwords of the pair, unlike all existing measures whichalso take global unigram frequencies in account.We need a null hypothesis that can account foran observed co-occurrence as a pure chance eventand this in-turn requires a corpus generation model.Documents in a corpus can be assumed to be gen-erated independent of each other.
Existing co-occurrence measures further assume that each docu-ment is drawn from a multinomial distribution basedon global unigram frequencies.
The main concernwith such a null model is the overbearing influenceof the unigram frequencies on the detection of wordassociations.
For example, the association betweenanomochilidae (dwarf pipe snakes) and snake couldgo undetected in our wikipedia corpus, since lessthan 0.1% of the pages containing snake also con-tained anomochilidae.
Also, under current models,the expected span2 of a word pair is very sensitiveto the associated unigram frequencies: the expectedspan of a word pair composed of low frequency un-igrams is much larger than that with high frequencyunigrams.
This is contrary to how word associa-2The span of an occurrence of a word-pair is the ?unsigneddistance?
between the positions of the corresponding word oc-currences.1058tions appear in language, where semantic relation-ships manifest with small inter-word distances irre-spective of the underlying unigram distributions.Based on these considerations we employ a nullmodel that represents each document as a bag ofwords 3.
A random permutation of the associatedbag of words gives a linear representation for thedocument.
Under this null model, the locations ofan unrelated pair of words will likely be randomlydistributed in the documents in which they co-occur.If the observed span distribution of a word-pair re-sembles that under the (random permutation) nullmodel, then the relation between the words is notstrong enough for one word to influence the place-ment of the other.
However, if the words are foundto occur closer together than explainable by our nullmodel, then we hypothesize a more direct associa-tion between the words.
Therefore, this null modeldetects biases in span distributions of word-pairswhile being agnostic to variations in global unigramfrequencies.In this paper, we propose a new measure of wordassociation based on the statistical significance ofthe observed span distribution of a word-pair.
Weperform extensive experiments on all the publiclyavailable benchmark data sets4 and compare ourmeasure against other popular co-occurrence mea-sures.
Our experiments demonstrate the advan-tages of our measure over all the competing mea-sures.
The ranked list of word associations outputby our measure has the best correlation with thecorresponding gold-standard in three (out of seven)data sets in our experiments, while remaining inthe top three in other four datasets.
While differ-ent measures perform best on different data sets,our measure outperforms other measures by beingconsistently either the best measure or very closeto the best measure on all the data sets.
The aver-age deviation of our measure?s correlation with thegold-standard from the best measure?s correlationwith the gold-standard (average taken across all the3There can be many ways to associate a bag of words with adocument.
Details of this association are not important for us,except that the bag of words provides some kind of quantitativesummary of the words within the document.4We exclude very small data sets of 80 word pairs or less.Sizes of the seven datasets we used range from 351 word-pairsto 83,713 word-pairs.datasets) is 0.02, which is the least average deviationamong all the measures, the next best deviations be-ing 0.04 and 0.06.The paper is organized as follows.
We present ournotion of statistical significance of span distributionin Section 2.
Algorithm for computing the proposedword association measure is described in Section 3.We discuss related work in Section 4.
Performanceevaluation is presented in Section 5 followed withconclusions in Section 6.2 Lexically significant co-occurrencesEvidence for significant lexical co-occurrences canbe gathered at two levels in the data ?
document-level and corpus-level.
First, at the document level,we may find that for a given word-pair, a surpris-ingly high proportion of its occurrences within adocument have smaller spans than they would haveby random chance.
Second, at the corpus-level,we may find a pair of words appearing closer-than-random in multiple documents in the corpus.
Wenow describe how to combine both kinds of evidenceto decide whether the nearby occurrences of a word-pair are statistically significant or not.Let the frequency f of a word-pair ?
in adocument D, be the maximum number of non-overlapped occurrences of ?
in D. A set of occur-rences of a word-pair is said to be non-overlapped ifthe words corresponding to one occurrence from theset do not appear in-between the words correspond-ing to any other occurrence from the set.Let f?x denote the maximum number of non-overlapped occurrences of ?
in D with span lessthan a given threshold x.
We refer to f?x as the span-constrained frequency of ?
in D. Note that f?x can-not exceed f .2.1 Document-level significant co-occurrenceTo assess the statistical significance of the word-pair?we ask if the span-constrained frequency f?x (of ?
)is more than what we would expect in a documentof size ` containing f ?random?
occurrences of ?.Our intuition is that if two words are associated insome way, they will often appear close to each otherin the document and so the distribution of the spanswill typically exhibit a bias toward values less thana suitably chosen threshold x.1059Definition 1 Consider the null hypothesis that thelinear representation of a document is generated bychoosing a random permutation of the bag of wordsassociated with the document.
Let ` be the length ofthe document and f denote the frequency of a word-pair in the document.
For a given a span thresholdx, we define pix(f?x, f, `) as the probability under thenull that the word-pair will appear in the documentwith a span-constrained frequency of at least f?x.Observe that pix(0, f, `) = 1 for any x > 0;also, for x ?
` we have pix(f, f, `) = 1 (i.e.
all foccurrences will always have span less than x forx ?
`).
However, for typical values of x (i.e.
forx  `) the probability pix(f?x, f, `) decreases withincreasing f?x.
For example, consider a documentof length 400 with 4 non-overlapped occurrencesof ?.
The probabilities of observing at least 4, 3,2, 1 and 0 occurrences of ?
within a span of 20words are 0.007, 0.09, 0.41, 0.83, and 1.0 respec-tively.
Since pi20(3, 4, 400) = 0.09, even if 3 of the4 occurrences of ?
have span less than 20 words,there is 9% chance that the occurrences were a con-sequence of a random event.
As a result, if we de-sired a confidence-level of at least 95%, we wouldhave to declare observed co-occurrences of ?
as in-significant.Given an  (0 <  < 1) and a span thresholdx (?
0) the document D is said to support the hy-pothesis ??
is an -significant word-pair within thedocument?
if we have [pix(f?x, f, `) < ].
We re-fer to  as the document-level evidence of the lexicalco-occurrence of ?.2.2 Corpus-level significant co-occurrenceWe now describe how to aggregate evidence for lex-ical significance by considering the occurrence of?
across multiple documents in the corpus.
Let{D1, .
.
.
, DK} denote the set ofK documents (fromout of the entire corpus) that contain at least oneoccurrence of ?.
Let `i be the length of Di, fibe the frequency of ?
in Di, and, f?xi be the span-constrained frequency of ?
in Di.
Define indicatorvariables zi, i = 1, .
.
.
,K as:zi ={1 if pix(f?xi , fi, `i) < 0 otherwise (1)As discussed previously, zi indicates whether ?
?is an -significant word-pair within the documentDi.?
Note that we view f?xi as the only random quan-tity here, with x fixed by the user, and `i and fifixed given the document Di and word-pair ?.
LetZ =?Ki=1 zi; Z models the number of documents(out of K) that support the hypothesis ??
is an -significant word-pair.?
The expected value of Z isgiven byE(Z) =K?i=1E(zi)=K?i=1pix(g,x(fi, `i), fi, `i) (2)where g,x(fi, `i) is given by Definition 2 below.Definition 2 Given a document of length ` in whicha word-pair has a frequency of f , and given a spanthreshold x, we define g,x(f, `) as the smallest r forwhich the inequality [pix(r, f, `) < ] holds.Note that g,x(f, `) is well-defined since pix(r, f, `)is non-increasing with respect to r. For theexample given earlier, g0.2,20(4, 400) = 3 andg0.05,20(4, 400) = 4.
Since each document in thecorpus is assumed to be generated independently,zi?s are independent random variables and we canbound the deviation of the observed value of Z fromits expectation using Hoeffding?s Inequality ?
forany t > 0, we haveP [Z ?
E(Z) +Kt] ?
exp(?2Kt2)= ?
(3)Recall that Z models the number of documents sup-porting the hypothesis ??
is an -significant word-pair.?).
Thus, the upper-bound ?
(= exp(?2Kt2)),0 < ?
< 1 denotes the upper-bound on the prob-ability that just due to random chance, more than(E(Z) +Kt) documents out of K will support thehypothesis ??
is an -significant word-pair.?
Wecall ?
the corpus-level evidence of the lexical co-occurrence ?.
For example, in our corpus, the word-pair (canyon, landscape) occurs in K = 416 doc-uments.
For  = 0.1, we have -significant occur-rences in Z = 33 documents (out of 416) , whileE(Z) = 14.34.
Suppose we want to be 99% surethat the occurrences of (canyon, landscape) in the33 documents were a consequence of non-randomphenomena.
Let ?
= 1 ?
0.99 = 0.01.
By setting1060word-1 word-2(0.1, 0.1) (0.1, 0.4) (0.4, 0.1)algae green mold poolamuse entertain clown amazedamn hell mad badrat dirty ugly diseasesedative drug narcotic calmtopping chocolate flavour caramelumbrella rain dry shadeunknown known dark secretworm insect dirt fishingwrap cover seal bandageTable 1: Examples of word-pairs from Florida datasethaving statistically significant co-occurrences in thewikipedia corpus for different (, ?)
combinations undera span constraint of 20 words.t =?ln ?/(?2K) = 0.07, we get E(Z) + Kt =43.46.
Only ifZ was 44 or more, there would be lessthan 1% chance of that being a random phenomena.Thus, we cannot be 99% sure that the observed co-occurrences in the 33 documents are non-random.Hence, our test declares (canyon, landscape) as in-significant at  = 0.1, ?
= 0.01.
We now summarizeour significance test in the definition below.Definition 3 (Significant lexical co-occurrence)Consider a word-pair ?
and a set of K documentscontaining at least one occurrence each of ?.
Fixa span threshold of x (> 0), a document-levelevidence of  (0 <  < 1) and a corpus-levelevidence of ?
(0 < ?
< 1).
Let Z denotethe number of documents (out of K) that sup-port the hypothesis ??
is -significant withinthe document.?
The word-pair ?
is said to be(, ?
)-significant if we have [Z ?
E(Z) + Kt],where t = ?log ?/(?2K) and E(Z) is given byEq.
(2).
The ratio [Z/(E(Z) + Kt)] is called theCo-occurrence Significance Ratio (CSR) for ?.2.3 DiscussionThe significance test of Definition 3 gathers bothdocument-level and corpus-level evidence from datain calibrated amounts.
Prescribing  fixes thestrength of the document-level hypothesis in ourtest, while, ?, controls the extent of corpus-level ev-idence we need to declare a word-pair as significant.A small ?
demands that there must be multiple doc-uments in the corpus, each of which, individuallyhave some evidence of relatedness for the pair ofwords.By running the significance test with different val-ues of  and ?, the CSR test can be used to detect dif-ferent types of lexically significant co-occurrences.For example, the strongest lexical co-occurrenceswould have both strong document-level evidence(low ) as well as high corpus-level evidence (low?).
Informally, these would represent pairs of wordsthat appear multiple times with small spans within adocument, in many documents, and in-practice, wefind that multi-word expressions or pairs of wordsseparated by stop words tend to dominate this type.On the other hand, a higher  would represent word-pairs that appear relatively farther apart within adocument, or a higher ?
would represent word-pairsthat appear together in relatively fewer documents.Note that to detect co-occurrences that exclusivelycorrespond to (say) low  and high ?, we would haveto run the test with low  and high ?, and then re-move word-pairs that were also found significant atlow  and low ?.In Table 1, we present some examples of differenttypes of co-occurrences.
The table lists word-pairsthat were found to be statistically significant for dif-ferent choices of (, ?).
Note that a word-pair is re-ported under ( = 0.1, ?
= 0.4) or ( = 0.4, ?
=0.1) only if it was not also found significant underother two parameter settings.
The strongest corre-lations are the word-pairs corresponding to ( =0.1, ?
= 0.1) e.g., algae-green, rat-dirty and worm-insect.
Different sets of weaker co-occurrences aredetected depending on whether we relaxed ?
or .For example, algae-mold is significant at a higher ?,while algae-pool is significant for higher .The semantic notion of word association is anabstract concept and different kinds of associations(with potentially different statistical characteriza-tions) may be preferred by human judges in differ-ent situations.
While in Section 5, we discuss in de-tail various datasets used, the evaluation methodol-ogy, and the performance of CSR across datasets,we wish to point out here that in 3 out of 5 cross-validation runs for wordsim dataset, the best per-forming CSR parameters were x = 50w,  = 0.1and ?
= 0.9, while in 3 out of 5 runs for Minnesotadataset, the best performing CSR parameters werex = 20w,  = 0.3 and ?
= 0.5.
This gives us someindication that different kinds of word associationswere preferred in different data sets.10613 Computing Co-occurrence SignificanceRatio(CSR)There are three main steps for computing CSRand the pseudocodes for these are listed in Proce-dures 1, 2 & 3.
Of these, the first two can be runoffline since they do not depend on the text corpus.They need to be run only once, after which CSR canbe computed for any word-pair on any given corpusof documents.
We describe these steps in the sub-sections below.3.1 Computing histogram histf,`,x(?
)The first step is to compute a histogram for the span-constrained frequency, f?x, of a word-pair whose fre-quency is f in a document of length `, given a cho-sen span threshold of x (under our null model).Definition 4 Given a document of length ` and aspan threshold of x, we define histf,`,x(f?x) as thenumber of ways to embed f non-overlapped occur-rences of a word-pair in the document such that ex-actly f?x occurrences have span less than x.Procedure 1 ComputeHist(f, `, x) ?
OfflineInput f - number of non-overlapped occurrences; ` - document length;x - span thresholdComputes histf,`,x[?]
as per Definition 41: Initialize histf,`,x[f?x]?
0 for f?x = 0, .
.
.
, f2: if f > ` then3: return4: if f = 0 then5: histf,`,x[0]?
16: return7: for i?
1 to (`?
1) do8: for j ?
(i+ 1) to ` do9: histf?1,`?j,x ?
ComputeHist(f ?
1, `?
j, x)10: for k ?
0 to f ?
1 do11: if (j ?
i) < x then12: histf,`,x[k + 1]?
histf,`,x[k + 1]+ histf?1,`?j,x[k]13: else14: histf,`,x[k]?
histf,`,x[k] + histf?1,`?j,x[k]Procedure 1 lists the pseudocode for computingthe histogram histf,`,x.
The main steps involve se-lecting a start and end position for embedding thevery first occurrence (lines 7-8) and then recursivelycalling ComputeHist(?, ?, ?)
(line 9).
The i-loopselects a start position for the first occurrence ofthe word-pair, and the j-loop selects the end posi-tion.
The recursion step now computes the num-ber of ways to embed the remaining (f ?
1) non-overlapped occurrences in the remaining (` ?
j)positions.
Once we have histf?1,`?j , we checkwhether the occurrence introduced at positions (i, j)will contribute to the f?x count.
If (j ?
i) < x,whenever there are k span-constrained occurrencesin positions (j + 1) to `, there will be (k + 1)span-constrained occurrences in positions 1 to `.Thus, we increment histf,`[k + 1] by the quantityhistf?1,`?j [k] (lines 10-12).
However, if (j ?
i) >x, there is no contribution to the span-constrainedfrequency from the (i, j) occurrence, and so we in-crement histf,`[k] by the quantity histf?1,`?j [k](lines 10-11, 13-14).
Finally, we note that in ourimplementation we use memorization to avoid re-dundant recursive calls.3.2 Computing pix(?, f, `) distributionProcedure 2 ComputeP iDist(f, `, x) ?
OfflineInput f - number of non-overlapped occurrences; ` - document length;x - span thresholdComputes Distribution pix[f, `, ?]
as per Definition 1 and g,x[f, `] asper Definition 21: N [f, `, x] =?fk=0 histf,`,x[k]2: for f?x ?
0 to f do3: Nx[f?x, f, `]?
?fk=f?x histf,`,x[k]4: pix[f?x, f, `]?
Nx[f?x,f,`]N [f,`,x]5: g,x[f, `]?
min{r | pix[r, f, `] < }The second offline step is computation of thepix(?, f, `) distribution.
We store the number of waysof embedding f non-overlapped occurrences of aword-pair in a document of length ` in the arrayN [f, `].
Similarly, the array Nx[f?x, f, `] stores thenumber of ways of embedding f non-overlapped oc-currences of the word-pair in a document of length `,such that at least f?x of the f occurrences have spanless than x.
To compute N [f, `, x] and Nx[f?x, f, `],we need the histogram histf,`,x[?]
which is the out-put of Procedure 1.
Procedure 2 lists the pseu-docode for computing pix(f?x, f, `) fromN(f, `) andNx(f?x, f, `) given histf,` from Procedure 1 (For thesake of readability the pseudocode does not describesome optimizations that we used in our implementa-tion).The Procedure 1 is exponential in f and ` butit does not depend on the data corpus.
Hence, wecan run the Procedures 1 and 2 off-line, and publishthe pix[] and g,x[] tables for various x, f?x, f and1062`.
Using these tables5, anyone wishing to computeCSR needs to only run Procedure 3.3.3 Computing CSR for a given word-pairProcedure 3 ComputeCSR(?, , ?, x)Input ?
- word-pair;  - document-level evidence; ?
- corpus-level ev-idence; x - span threshold; Corpus of documentsComputes CSR(?)
- Co-occurrence Significance Ratio (CSR) for ?as per Definition 31: D ?
{D1, .
.
.
, DK} // Set of documents from the corpus thateach contain at least one occurrence of ?.2: t?
?log ?/(?2K)3: Z ?
0 and ZE ?
04: for i?
1 to K do5: `i = Length of Di6: fi = Frequency of ?
in Di7: f?xi = Span-constrained frequency of ?
in Di8: if pix[f?xi , fi, `i] <  then9: zi ?
110: else11: zi ?
012: Z ?
Z + zi13: ZE ?
ZE + pix[g[fi, `i, x], fi, `i]14: CSR(?)
= Z/(ZE +Kt)Procedure 3 implements the significance testgiven in Definition 3 and requires that the pix[] andg,x[] tables have already been computed offline.The first step is to determine the subsetD of docu-ments containing the given word-pair (line 1).
Thenwe compute t based on ?
and K (the size of D)(line 2).
Next we determine how many of the Kdocuments support the hypothesis ??
is -significantwithin the document?
(lines 3-12).
The expectednumber of documents supporting the hypothesis isaccumulated in ZE (line 13).
CSR is then computedas the ratio of Z to (ZE +Kt) (line 14).3.4 Run-time overheadThe computation of Co-occurrence Significance Ra-tio (CSR) as given in Definition 3 might appearmore complex than the simple formulae for otherco-occurrence measures given in Table 2.
However,bulk of the complexity in calculating CSR lies inthe one-time (data independent) off-line computa-tion of the pix[] and g,x[] tables.
Once these tablesare published, the cost of comparing CSR for a givenword pair is comparable to the cost of computingany other (spanned) measure in Table 2.
The maindata-dependent computations for a spanned measure5http://www.cse.iitb.ac.in/?damani/papers/EMNLP11/resources.htmlare in determining span-constrained frequencies; allother steps are simple arithmetic operations or mem-ory lookups.
To illustrate this, Procedure 4 gives de-tails of computing PMI.
The comparison of Proce-dures 3 and 4 shows their almost parallel structures.The main overhead in these procedures is incurredin line 7, where span-constrained frequencies in agiven document are computed.Procedure 4 ComputePMI(a, b)Input (x, y) - word pair;Computes PMI (Table 2) for (x, y).1: let D = {D1, .
.
.
, DK} // set of documents containing at leastone occurrence of ?.2: N = total number of words in corpus3: (fx,fy) = unigram frequencies of x, y in corpus4: (px,py) = (fx/N ,fy/N )5: f?
= 06: for i?
1 to K do7: f?i = span-constrained frequency of ?
in Di8: f?
= f?
+ f?i9: p?x,y = f?/N10: PMI = log( p?x,ypxpy )4 Related WorkExisting word association measures can be dividedinto three broad categories: (i) Co-occurrence mea-sures that rely on co-occurrence frequencies of bothwords in a corpus in addition to the individualunigram frequencies (Table 2), (ii) Distributionalsimilarity-based measures that characterize a wordby the distribution of other words around it (Agirreet al, 2009; Bollegala et al, 2007; Chen et al, 2006;Wandmacher et al, 2008), and (iii) Knowledge-based measures that use knowledge-sources likethesauri, semantic networks, or taxonomies (Milneand Witten, 2008; Hughes and Ramage, 2007;Gabrilovich and Markovitch, 2007; Yeh et al, 2009;Strube and Ponzetto, 2006; Finkelstein et al, 2002;Liberman and Markovitch, 2009).In this paper, we focus on comparison withother co-occurrence measures.
These measuresare used in several domains like ecology, psy-chology, medicine, and language processing.
Ta-ble 2 lists several measures chosen from all thesedomains.
Except Ochiai (Ochiai, 1957; Jansonand Vegelius, 1981) and the recently introduced1063Method FormulaCSR (this work) Z/(E(Z) +Kt)CWCD (Washtell andMarkert, 2009)f?
(x,y)p(x)1/max(p(x),p(y))MDice (Dice, 1945) 2f?
(x,y)f(x)+f(y)LLR (Dunning, 1993)?x?
?
{x,?x}y?
?
{y,?y}p(x?, y?
)log p(x?,y?)p(x?)p(y?
)Jaccard (Jaccard, 1912) f?(x,y)f(x)+f(y)?f?
(x,y)Ochiai (Janson and Veg-elius, 1981)f?
(x,y)?f(x)f(y)Pearson?s ?2 test?x?
?
{x,?x}y?
?
{y,?y}(f?(x?,y?)?Ef?(x?,y?))2Ef?(x?,y?
)PMI (Church and Hanks,1989)log p(x,y)p(x)p(y)SCI (Washtell and Mark-ert, 2009)p(x,y)p(x)?p(y)T-test f?(x,y)?Ef?(x,y)?f?(x,y)(1?
f?
(x,y)N)N Total number of tokens in the corpusf(x), f(y) unigram frequencies of x, y in the corpusp(x), p(y) f(x)/N, f(y)/Nf?
(x, y) Span-constrained (x, y) word pair frequency in corpusp?
(x, y) f?
(x, y)/NM Harmonic mean of the spans of f?
(x, y) occurrencesEf?
(x, y) Expected value of f?
(x, y)Table 2: Co-occurrence measures.CWCD6 (Washtell and Markert, 2009) all othermeasures are well-known in the NLP commu-nity (Pecina and Schlesinger, 2006).
Our resultsshow that Ochiai and Chi-Square have almost iden-tical performance, differing only in 3rd decimal dig-its.
Rankings produced by Chi-square is almostmonotonic with respect to the rankings produced byOchiai.
This is because, for most word pairs (x, y),[f(x)  N ], [f(y)  N ], [f(x, y)  f(x)], and[f(x, y)  f(y)].
Therefore three of the four termsin the Chi-square summation become zero7 and thefourth term approximates to the square of Ochiai.Similarly Jaccard and Dice coincide.
While present-ing our experimental results, we report these pairs ofmeasures together.6CWCD was reported in (Washtell and Markert, 2009) asthe best performing variant among the so-called windowless (orspanless) measures.
In our experiments, we implemented win-dowed (spanned) version of the CWCD measure.7For example, f?
(x,?y) ?
Ef(x,?y) = f(x) ?
N ?pf(x) ?
pf(?y) = f(x) ?
1N ?
f(x) ?
f(?y) = f(x) ?1N ?
f(x)?N = 0.Aspect Data Set No.
ofRespon-dentsNo.
ofWordPairsNo.
ofFilteredWordPairsSemanticrelatednesswordsim 16 353 351(Finkelstein et al,2002)Edinburg (Kiss et al,1973)100 325,588 83,713Florida (Nelson etal., 1980)5,019 65,523 59,852Free-AssociationGoldfarb-Halpern(Goldfarb andHalpern, 1984)316 410 384Kent (Kent andRosanoff, 1910)1,000 14,576 14,086Minnesota (Russelland Jenkins, 1954)1,007 10,447 9,649White-Abrams(White and Abrams,2004)440 745 652Table 3: Characteristics of data sets used.5 Performance EvaluationTwo main aspects of word association studied in lit-erature are: a) semantic relatedness, and b) free as-sociation.
Semantic relatedness encompasses manydifferent relationships between words, like syn-onymy, meronymy, antonymy, and functional asso-ciation (Budanitsky and Hirst, 2006).
Free associ-ation refers to the first response-words that cometo mind when presented with a stimulus.
(ESSLLI,2008).
We experiment with all the publicly availabledatasets that come with gold standard judgement ofthese aspects, except the very small ones with lessthan 80 word-pairs8.5.1 DatasetsDetails9 of the datasets used in our experiments arelisted in Table 3.
Each data set comes with a gold-standard of human judgments - a ranked list of asso-ciation scores for the word-pairs in the data set.
Thewordsim dataset was prepared by asking the subjectsto estimate the relatedness of the word pairs on a8(MillerCharles (Miller and Charles, 1991), Rubenstein-Goodenough (Rubenstein and Goodenough, 1965) andTOEFL (Landauer and Dumais, 1997))9We removed word-pairs containing multiword expressions.For data sets with more than 10,000 word-pairs, we filtered outpairs that contain stop words listed in (StopWordList, 2010).For Edinburg (size 275393 after previous filtering), we furtherfiltered word-pairs where the response was supported by onlyone respondant.
Original and filtered data sets are available athttp://www.cse.iitb.ac.in/?damani/papers/EMNLP11/resources.html1064Edinburg(83,713)Florida(59,852)Kent(14,086)Minnesota(9,649)White-Abrams(652)Goldfarb-Halpern(384)wordsim(351)CSR 0.25 0.30 0.42 0.31 0.34 0.10 0.63CWCD 0.23 0.23 0.40 0.30 0.21 0.19 0.54Dice (Jaccard) 0.20 0.27 0.43 0.32 0.21 0.09 0.59LLR 0.20 0.26 0.40 0.29 0.18 0.03 0.51Ochiai (?2) 0.24 0.30 0.43 0.31 0.29 0.08 0.62PMI 0.22 0.25 0.36 0.26 0.22 0.11 0.69SCI 0.24 0.27 0.38 0.27 0.23 0.06 0.37TTest 0.17 0.23 0.37 0.26 0.17 -0.02 0.45Table 4: Comparison of the average Spearman coefficients obtained across five cross-validation runs by differentmeasures.
The best performing measure for each data-set is shown in bold.
All standard deviations for Edinburg andFlorida were less than 0.01, for Kent and Minnesota were between 0.01 and 0.02, for White-Abrams were between0.05 and 0.08, for Goldfarb-Halpern between 0.05 and 0.15 and for wordsim were between 0.02 and 0.15.
Number ofword-pairs in each dataset is shown in brackets against its name.Edinburg(83,713)Florida(59,852)Kent(14,086)Minnesota(9,649)White-Abrams(652)Goldfarb-Halpern(384)wordsim(351)WorstRankAvg.DeviationWorstDeviationCSR 0.00 (1) 0.00 (1) 0.01 (3) 0.01 (2) 0.00 (1) 0.09 (3) 0.06 (2) 3 0.02 0.09CWCD 0.02 (4) 0.07 (7) 0.03 (4) 0.02 (4) 0.13 (5) 0.00 (1) 0.15 (5) 7 0.06 0.15Dice (Jaccard) 0.05 (6) 0.03 (3) 0.00 (1) 0.00 (1) 0.13 (5) 0.10 (4) 0.10 (4) 6 0.06 0.13LLR 0.05 (6) 0.04 (5) 0.03 (4) 0.03 (5) 0.16 (7) 0.16 (7) 0.18 (6) 7 0.09 0.18Ochiai (?2) 0.01 (2) 0.00 (1) 0.00 (1) 0.01 (2) 0.05 (2) 0.11 (5) 0.07 (3) 5 0.04 0.11PMI 0.03 (5) 0.05 (6) 0.07 (8) 0.06 (7) 0.12 (4) 0.08 (2) 0.00 (1) 8 0.06 0.12SCI 0.01 (2) 0.03 (3) 0.05 (6) 0.05 (6) 0.11 (3) 0.13 (6) 0.32 (8) 8 0.10 0.32TTest 0.08 (8) 0.07 (7) 0.06 (7) 0.06 (7) 0.17 (8) 0.21 (8) 0.24 (7) 8 0.13 0.24Table 5: Comparison of deviations from the best performing measure on each data set.
Number of word-pairs in eachdataset is shown in brackets against its name.
Figures in brackets against the deviation values denote the ranks of themeasures in the corresponding data sets.scale from 0 to 10 (Finkelstein et al, 2002).
Themethodology for collecting free association data isexplained at (ESSLLI, 2008): The degree of free as-sociation between a stimulus (S) and response (R) isthe percentage of respondents who respond R as thefirst response when presented with stimulus S.These datasets are of varying size, and they wereconstructed at different point in time, in different ge-ographies.
This allows us to compare different mea-sures comprehensively under varying range of cir-cumstances.
To the best of our knowledge, no pre-vious work has reported such a detailed comparisonof co-occurrence measures.5.2 Resources UsedWe use the Wikipedia (Wikipedia, April 2008) cor-pus with 2.7 million articles (total of 1.24 Giga-words).
We did no pre-processing - no lemmatiza-tion or function-word removal.
When counting doc-ument size (in words), punctuations were ignored.Documents larger than 1500 words were partitionedsuch that each part was at most 1500 words10.
Weindexed the corpus using Lucene search engine li-brary and used Lucene APIs to obtain various statis-tics and documents containing given word-pairs.5.3 MethodologyEach measure listed in Table 2 produces a rankedlist of association scores for the word-pairs in a dataset.
We evaluate each measure by the Spearman?srank correlation between the ranking produced bythe measure and the gold-standard ranking.The span threshold (or window-width) x is a user-defined parameter in all measures.
In addition, CSRhas the parameters  and ?.
For any measure, theranking of word-pairs will likely change with chang-10While this limit can be raised using heavier computing re-sources, we believe that partitioning documents of sizes greaterthan 1500 words was reasonable (especially since typical spanvalues we used were less than 50, much less than 1500).1065Method Resourcewordsimwordsim sim rel Esslli(353) (203) (252) (272)PMI Wikipedia 0.69 0.72 0.68 0.32Ochiai (?2) Wikipedia 0.62 0.68 0.62 0.44Significance Ratio (CSR) Wikipedia 0.63 0.70 0.64 0.43Latent Semantic Analysis (Wandmacher et al, 2008) Newspaper corpus - - - 0.38Graph Traversal (WN30g) (Agirre et al, 2009)) Wordnet 0.66 0.72 0.56 -Bag of Words based Distributional Similarity (BoW) (Agirre et al, 2009)) Web corpus 0.65 0.70 0.62 -Context Window based Distributional Similarity (CW) (Agirre et al, 2009)) Web corpus 0.60 0.77 0.46 -Hyperlink Graph (Milne and Witten, 2008) Wikipedia hyperlinks graph 0.69 - - -Random Graph Walk (Hughes and Ramage, 2007) WordNet 0.55 - - -Explicit Semantic Analysis (Gabrilovich and Markovitch, 2007) Wikipedia concepts 0.75 - - -(reimplemented in (Yeh et al, 2009)) (0.71)Normalized Path-length (lch) (Strube and Ponzetto, 2006) Wikipedia category tree 0.55 - - -Thesarus based (Jarmasz, 2003) Roget?s thesaurus 0.55 - - -Latent Semantic Analysis (Finkelstein et al, 2002) Web corpus 0.56 - - -Table 6: Comparison of co-occurrence based measures with knowledge-based and distributional similarity basedmeasures.
These other measures have not been applied to the free association datasets shown in Table 3.
Data formissing entries is not available.
Note that sim and rel are subsets of wordsim dataset.
Number of word-pairs in eachdataset is shown in brackets against its name.ing parameter values.
Hence we follow the standardmethodology of fixing parameters through cross val-idation.
Specifically, we partition the data into fivefolds, four of which are used for training and onehold-out fold is used for testing.
For each mea-sure, the parameter values that achieve best corre-lation with human judgments on 4 training folds areused to predict on the 1 hold-out testing fold.
Thisexperiment is repeated 5 times for different trainingand test folds.
The average rank correlation obtainedby each measure over 5 cross-validation runs is re-ported for each dataset.
We varied  and ?
between0.01 and 0.90 and x between 5 and 50 words.5.4 ResultsFor each measure and for each data set, the aver-age correlation over the 5 cross-validation runs isreported in Table 4.
The corresponding standard de-viations are mentioned in the table?s caption.
Thebest performing measure in each case is highlightedin bold.
While different measures performed best ondifferent data sets, the results in Table 4 shows thatCSR performs consistently well across all data sets.In all data sets the correlation for CSR was alwayseither the best or close to the best.As expected, our results are statistically more sig-nificant for the larger data sets, compared to thesmaller ones.
The standard deviations of the resultsare small for two largest data sets (less than 0.01for Edinburg and Florida), gradually increasing (lessthan 0.02 for Kent and Minnesota), and becominghigh (upto .15) for the three smallest datasets.Although, among all measures, CSR has the bestaverage correlation over all datasets, taking averageof correlations across widely different dataset is nota meaningful way to decide on which measure touse.
Ideally one would like to access an oracle tolearn which measure will perform best on a particu-lar unseen application dataset.
Short of such an ora-cle, if one were to pick a fixed measure a-priori, thenone would like to know how much worse off one iscompared to the best measure for that dataset.To compare different measures from this perspec-tive, we compute the deviation of the correlation foreach measure from the correlation of the best mea-sure for each data set.
These deviations are reportedin Table 5, along with the corresponding ranks.
Theaverage deviation of CSR over all the data sets is0.02, which is the least among all the measures, thenext two being 0.04 and 0.06.
CSR also has the leastworst-deviation among all measures.
Also, CSR isnever ranked worse than 3 in any of the data sets.This is also the smallest worst-rank among all mea-sures.
Based on these results, we infer that CSRis overall the best performing co-occurrence basedword association measure.While the focus of our work is on the co-occurrence measures, for completeness, we presentall the known results for knowledge and distribu-tional similarity-based measures on the datasets un-1066der consideration in Table 6.
Note that in (Agirre etal., 2009), the wordsim data set was partitioned intotwo sets, namely sim and rel, and in Esslli sharedtask (ESSLLI, 2008), a 272 word pair subset of theEdinburgh dataset was chosen.
To facilitate compar-ison, in addition to CSR, we also present results forPMI and Ochiai (Chi-Square) which are the best per-forming co-occurrence measures on wordsim, andEsslli datasets.
For co-occurrence-based measures,we used 5-fold cross validation, which is inapplica-ble for parameterless measures.
Results show thatco-occurrence-based measures compare well withother resource-heavy measures.6 ConclusionsIn this paper, we introduced a new measure calledCSR for word-association based on statistical sig-nificance of lexical co-occurrences.
Our measure,while being agnostic to global unigram frequencies,detects skews in span distributions of word-pairs indocuments containing both words.
We carried outextensive evaluation on several benchmark datasets.Our experiments demonstrate the advantages of ourmeasure over all the competing measures.AcknowledgmentsThis work was supported in part by the Ministryof Human Resources Development, Government ofIndia and by the Tata Research Development andDesign Center (TRDDC).
We thank Mr. JustinWashtell (University of Leeds) for providing us withvarious datasets.ReferencesEneko Agirre, Enrique Alfonseca, Keith Hall, JanaKravalova, Marius Pasca, and Aitor Soroa.
2009.
Astudy on similarity and relatedness using distributionaland wordnet-based approaches.
In NAACL-HLT.Danushka Bollegala, Yutaka Matsuo, and MitsuruIshizuka.
2007.
Measuring semantic similarity be-tween words using web search engines.
In WWW,pages 757?766.Alexander Budanitsky and Graeme Hirst.
2006.
Evalu-ating wordnet-based measures of lexical semantic re-latedness.
Computational Linguists, 32(1):13?47.Hsin-Hsi Chen, Ming-Shun Lin, and Yu-Chuan Wei.2006.
Novel association measures using web searchwith double checking.
In ACL.Kenneth Ward Church and Patrick Hanks.
1989.
Wordassociation norms, mutual information and lexicogra-phy.
In ACL, pages 76?83.L.
R. Dice.
1945.
Measures of the amount of ecologicalassociation between species.
Ecology, 26:297?302.Ted Dunning.
1993.
Accurate methods for the statisticsof surprise and coincidence.
Computational Linguis-tics, 19(1):61?74.ESSLLI.
2008.
Free association task at lexical seman-tics workshop esslli 2008. http://wordspace.collocations.de/doku.php/workshop:esslli:task.Lev Finkelstein, Evgeniy Gabrilovich, Yossi Matias,Ehud Rivlin, Zach Solan, Gadi Wolfman, and EytanRuppin.
2002.
Placing search in context: the conceptrevisited.
ACM Trans.
Inf.
Syst., 20(1):116?131.Evgeniy Gabrilovich and Shaul Markovitch.
2007.
Com-puting semantic relatedness using wikipedia-based ex-plicit semantic analysis.
In IJCAI.Robert Goldfarb and Harvey Halpern.
1984.
Word asso-ciation responses in normal adult subjects.
Journal ofPsycholinguistic Research, 13(1):37?55.T Hughes and D Ramage.
2007.
Lexical semantic relat-edness with random graph walks.
In EMNLP.P.
Jaccard.
1912.
The distribution of the flora of thealpine zone.
New Phytologist, 11:37?50.Svante Janson and Jan Vegelius.
1981.
Measures of eco-logical association.
Oecologia, 49:371?376.Mario Jarmasz.
2003.
Rogets thesaurus as a lexical re-source for natural language processing.
Technical re-port, University of Ottowa.G.
Kent and A. Rosanoff.
1910.
A study of associationin insanity.
American Journal of Insanity, pages 317?390.G.
Kiss, C. Armstrong, R. Milroy, and J. Piper.
1973.An associative thesaurus of english and its computeranalysis.
In The Computer and Literary Studies, pages379?382.
Edinburgh University Press.T.
Landauer and S. Dumais.
1997.
The latent semanticanalysis theory of acquisition, induction, and represen-tation of knowledge.
In Psychological Review, volume104/2, pages 211?240.Sonya Liberman and Shaul Markovitch.
2009.
Com-pact hierarchical explicit semantic representation.
InProceedings of the IJCAI 2009 Workshop on User-Contributed Knowledge and Artificial Intelligence: AnEvolving Synergy (WikiAI09), Pasadena, CA, July.G.A.
Miller and W.G.
Charles.
1991.
Contextual corre-lates of semantic similarity.
Language and CognitiveProcesses, 6(1):1?28.David Milne and Ian H. Witten.
2008.
An effective, low-cost measure of semantic relatedness obtained fromwikipedia links.
In ACL.1067D.
Nelson, C. McEvoy, J. Walling, and J. Wheeler.1980.
The university of south florida homographnorms.
Behaviour Research Methods and Instrumen-tation, 12:16?37.A Ochiai.
1957.
Zoogeografical studies on the soleoidfishes found in japan and its neighbouring regions-ii.Bulletin of the Japanese Society of Scientific Fisheries,22.Pavel Pecina and Pavel Schlesinger.
2006.
Combin-ing association measures for collocation extraction.
InACL.Herbert Rubenstein and John B. Goodenough.
1965.Contextual correlates of synonymy.
Communicationsof the ACM, 8(10):627?633, October.W.A.
Russell and J.J. Jenkins.
1954.
The completeminnesota norms for responses to 100 words from thekent-rosanoff word association test.
Technical report,Office of Naval Research and University of Minnesota.StopWordList.
2010. http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words.
The Information Retrieval Group, Universityof Glasgow.
Accessed: November 15, 2010.Michael Strube and Simone Paolo Ponzetto.
2006.Wikirelate!
computing semantic relatedness usingwikipedia.
In AAAI, pages 1419?1424.T.
Wandmacher, E. Ovchinnikova, and T. Alexandrov.2008.
Does latent semantic analysis reflect human as-sociations?
In European Summer School in Logic,Language and Information (ESSLLI?08).Justin Washtell and Katja Markert.
2009.
A comparisonof windowless and window-based computational asso-ciation measures as predictors of syntagmatic humanassociations.
In EMNLP, pages 628?637.Katherine K. White and Lise Abrams.
2004.
Free as-sociations and dominance ratings of homophones foryoung and older adults.
Behavior Research Methods,Instruments, & Computers, 36(3):408?420.Wikipedia.
April 2008. http://www.wikipedia.org.Eric Yeh, Daniel Ramage, Chris Manning, Eneko Agirre,and Aitor Soroa.
2009.
Wikiwalk: Random walkson wikipedia for semantic relatedness.
In ACL work-shop ?TextGraphs-4: Graph-based Methods for Natu-ral Language Processing?.1068
