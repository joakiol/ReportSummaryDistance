Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 223?231,Beijing, August 2010Constraining robust constructions for broad-coverage parsing withprecision grammarsBart Cramer?
and Yi Zhang?
?Department of Computational Linguistics & Phonetics, Saarland University?LT-Lab, German Research Center for Artificial Intelligence (DFKI)?
{bcramer,yzhang}@coli.uni-saarland.deAbstractThis paper addresses two problems thatcommonly arise in parsing with precision-oriented, rule-based models of grammar:lack of speed and lack of robustness.
First,we show how we can reduce parsing timesby restricting the number of tasks theparser will carry out, based on a gener-ative model of rule applications.
Sec-ond, we show that a combination of searchspace restriction and radically overgen-erating robustness rules lead to a morerobust parser, with only a small penaltyin precision.
Applying both the robust-ness rules and a fragment fallback strat-egy showed better recall than just givingfragment analyses, with equal precision.Results are reported on a medium-sizedHPSG grammar for German.
11 IntroductionIn the field of natural language processing, itis common wisdom that handwritten, rule-basedmodels generally perform poorly on complexproblems, mainly due to the knowledge acquisi-tion bottleneck: it is hard for the human modellerto conceive of all possible scenarios the modelhas to cope with.
In parsing, many approacheshave relied on hand-written grammars, and theirfragility is one of their largest weaknesses.
Suchmodels can fail due to insufficiency of lexical en-tries or grammatical constructions, but also due1The research reported on in this paper has been carriedout with financial support from the Deutsche Forschungs-gemeinschaft and the German Excellence Cluster of Multi-modal Computing & Interaction.to creative or ungrammatical input.
In any case,the parser should always return a reasonable out-put.
A very simple technique is partial or fragmentparsing (Kiefer et al, 1999; Riezler et al, 2001;Zhang et al, 2007a): if there is no item in the chartthat both spans the complete sentence and fulfillsthe root condition, several chunks that do conformto a root condition are combined by minimising acertain cost function (for instance to favour largerchunks, or more probable chunks).A second problem with deep parsers is their rel-atively low efficiency.
For online applications, it isimpermissible to wait for longer than a minute be-fore the system responds.
Apart from studies thatwere aimed at increasing the efficiency of deepparsers by using smarter algorithms (e.g.
usingleft-corner relations (Van Noord, 1997)), severalstudies in recent years have suggested that searchspace restriction can offer a beneficial balance be-tween speed and accuracy as well.
Techniquesthat have been proposed are, among others, su-pertagging (Clark and Curran, 2007), CFG filter-ing (Matsuzaki et al, 2007) and beam threshold-ing (Ninomiya et al, 2005).A potential disadvantage of the latter techniqueis that the unifications have taken place by thetime the value of the resulting chart item is in-vestigated.
One strategy that tries to prevent ex-ecution of unlikely tasks altogether is presentedby van Noord (2009).
In this method, the parserlearns from an unannotated corpus which parsesteps contributed to the solution as preferred bythe disambiguation model (as opposed to a cer-tain gold standard).
Hence, this approach is self-learning.Another study that is close to our approach223to search space restriction is c-structure pruning(Cahill et al, 2008).
The authors show that alarge, hand-written, unification-based parser (theXLE LFG parser for English) can perform reason-ably faster (18%) without losing accuracy, by notallowing the parser to unify if the resulting itemwill have a span that does not conform to a CFGtree that was generated from the sentence before-hand by a PCFG parser.
Much better results (67%speed-up) are obtained by pruning chart items lo-cally, based on their relative probabilities (Cahillet al, 2008).
This is the approach that is closest tothe one we present in this paper.In this paper, we introduce a method that ad-dresses robustness and efficiency concurrently.The search space is restricted by setting a maxi-mum on the number of tasks per chart cell.
Be-cause tasks are carried out according to a prior-ity model based on the generative probabilities ofthe rule applications, it is unlikely that good read-ings are dropped.
More robustness is achieved byadding radically overgenerating rules to the gram-mar, which could cover all sentences, given an dis-proportionate amount of time and memory.
Bystrongly restricting the search space, however, thecomputation requirements remains within bounds.Because the robustness rules are strongly dispre-ferred by both the priority model and the dis-ambiguation model, all sentences that would becovered by the ?restricted?
grammar remain high-precision, but sentences that are not covered willget an additional push from the robustness rules.1.1 An HPSG grammar for GermanThe grammar we use (Cramer and Zhang, 2009)is the combination of a hand-written, constraint-based grammar in the framework of HPSG and anopen word class lexicon extracted from the Tigertreebank (Brants et al, 2002) in a deep lexical ac-quisition step.
One of the aims of this grammaris to be precision-oriented: it tries to give detailedanalyses of the German language, and reject un-grammatical sentences as much as possible.
How-ever, this precision comes at the cost of lower cov-erage, as we will see later in this paper.Along with the grammar, a treebank has beendeveloped by re-parsing the Tiger treebank, andincluding those sentences for which the grammarwas able to reproduce the original Tiger depen-dencies.
The treebank?s size is just over 25k sen-tences (only selected from the first 45k sentences,so they don?t overlap with either the developmentor test set), and contains the correct HPSG deriva-tion trees.
These (projective) derivation trees willfunction as the training set for the statistical mod-els we develop in this study.2 Restriction of the search space2.1 The PET parserThe parser we employ, the PET parser (Callmeier,2000), is an agenda-driven, bottom-up,unification-based parser.
In order to reduce com-putational demands, state-of-the-art techniquessuch as subsumption-based packing (Oepenand Carroll, 2000) and the quasi-destructiveunification operator (Tomabechi, 1991) have beenimplemented.A central component in the parser is the agenda,implemented as a priority queue of parsing tasks(unifications).
Tasks are popped from the agenda,until no task is left, after which all passive itemsspanning the complete sentence are comparedwith the root conditions as specified by the gram-mar writer.
The best parse is extracted from theparse forest by a Maximum Entropy parse disam-biguation model (Toutanova et al, 2002), usingselective unpacking (Zhang et al, 2007b).Two different types of items are identified: pas-sive items and active items.
Passive items are?normal?
chart items, in the sense that they canfreely combine with other items.
Active itemsstill need to combine with a passive item to becomplete.
Hence, the parser knows two types oftasks as well (see figure 1): rule+passive and ac-tive+passive.Each time a task succeeds, the following hap-pens:?
For each inserted passive item, add(rule+passive) tasks that combine thepassive item with each of the rules, and add(active+passive) tasks that combine witheach of the neighbouring active items.?
For each inserted active item, add (ac-tive+passive) tasks that combine the remain-224unary binaryrule+passivebinaryactive+passiveR+ P ?RPR+ P ?RPRP1+ P2?RP1P2Figure 1: Depicted are the different types of tasks in the PET parser.
Not shown are the featuresstructures imposed by the rules and the chart items.ing gaps in the active item with existingneighbouring passive items in the chart.2.2 Defining prioritiesThe priorities of the parsing tasks are calculatedbased on a generative PCFG model extracted fromthe treebank by maximum likelihood estimation,smoothed by Lidstone smoothing.
Each passivechart item receives a score based on its generativeprobability, calculated as the product of all appliedrule probabilities.
For active parsing items, we setthe score to be the upper bound of this generativeprobability, if the item succeeds later in combin-ing with other passive edge(s) to build a completesubtree.
This is done by simply assuming the un-determined subtree in the active item receiving agenerative score of 1.The priorities that are assigned to both types oftasks are not yet conditioned on the probabilityof the topmost rule application.
Hence, they arecomputed using the following simple formula:Pr = p(R) ?
p(P )where Pr is the task?s priority, p(R) the priorprobability of the rule category R; and p(P ) isthe highest possible generative probability of theresulting passive item P .2.3 Restriction strategiesIt is a natural thought to allocate more computa-tional resources to longer sentences, and this isexactly what happens in the restriction strategieswe develop in this study.
We define a cap onthe number of tasks for a certain cell/span (i, j),which means that the number of cells is quadrati-cally related to the number of words in a sentence:ncells = n(n + 1)/2.We define three task restriction strategies: all,success, and passive.
In all, the cap is definedfor all tasks, whether the unification is success-ful or not.
Success only counts tasks that are suc-cessful (i.e.
lead to either an active or a passiveitem), and passive only counts tasks that lead to apassive item.
In all strategies, morphological andlexical tasks are not counted, and hence not re-stricted.
Unary phrasal rules (such as empty-det)are counted, though.The implementation uses only one priorityqueue.
Each time a task is popped from theagenda, it is checked whether the limit for thisspan has been reached or not.
If so, the task isdiscarded; otherwise, it is executed.2.4 MethodologyAll our experiments are based on the Tiger tree-bank (Brants et al, 2002).
The grammar?s lex-icon is based on the first 45k sentences in thetreebank, and so are the MaxEnt disambiguationmodel (Toutanova et al, 2002) and the genera-tive model we developed for this study.
The de-velopment set (s45001-s47500) was used to fine-tune the methods, but all final results presented inthis paper are with respect to the test set (s47501-s50000).
The maximum time for building up thepacked parse forest is 60 seconds, after which un-packing is started.
Unpacking the first readingusually has negligible computation costs, and isnot reported on.
Along with the best reading?sderivation, the dependencies are output, and com-225Strategy exhaustive all success passiveCap size 3000 200 100Time (s) 7.20 1.04 0.92 1.06Coverage 59.4% 60.5% 60.0% 59.0%Exact 17.6% 17.6% 17.4% 17.4%Recall 37.6% 39.5% 38.9% 38.0%Precision 80.7% 80.3% 80.1% 80.4%F-score 51.3% 52.9% 52.4% 51.6%Table 1: A more detailed look into some data points from figure 2.
?Coverage?
and ?Exact?
are sententialpercentages, showing how many sentences receive at least one or the exactly correct reading.
Recall,precision and f-score are on a per-dependency basis.l0 2 4 6 84648505254Time (s)F?scorel exhaustiveallsuccesspassiveFigure 2: This figure shows the tradeoff betweenspeed and f-score for the standard grammar, usingthe restriction strategies with different cap sizes.pared to the gold standard dependencies from theTiger treebank.2.5 ResultsThe results of the experiments, with different capsizes, are summarized in table 1 and figure 2.As expected, for all strategies it holds that longercomputation times lead to higher coverage num-bers.
The interesting thing is that the restriction ofthe search space doesn?t affect the parses?
preci-sion, indicating that the priorities work well: thetasks leading to good solutions are indeed givenhigh priority scores.A striking observation is that the coverage num-bers go up by about 1%, with reductions in parsetimes of more than 80%.
This is due to the use ofthe timeout, and the generic tendency of our defi-nition of the priorities: because less rule applica-tions lead to higher log probabilities, the agendawill favour tasks with smaller span size.
If theagenda doesn?t apply too strong a restriction onthose tasks, the parser might not create any itemsspanning the whole sentence after the full 60 sec-onds, and hence produce no parse.
This is miti-gated by stronger restriction, leading to a quickerpath upwards in the chart.No large differences of success are found be-tween the different strategies.
The intuition be-hind the success and passive strategies was thatonly more effort should be invested into a par-ticular span if not enough chart items for thatspan have been created.
However, the time/qualitytrade-offs are very similar for all strategies, asshown in figure 22.The strategies we have reported on have onething in common: their counters are with respectto one particular span, and therefore, they havea very local scope.
We have tried other strate-gies that would give the algorithm more flexibil-ity by defining the caps on more global scale, forinstance per span length or for the entire chart.However, this degraded the performance severely,because the parser was not able to divide its atten-tion properly.2One might be tempted to consider the all strategy asthe best one.
However, the time/f-score tradeoff curves lookslightly different on the development set.2263 Increasing robustnessFor hand-written deep parsers, efficiency and cov-erage are often competing factors: allowing moreitems to be created might be beneficial for recall,but the parser will also be too slow.
However, be-cause the search space can be restricted so rigidly,we can make the grammar more permissive to ac-cept more sentences, hopefully without a heavyefficiency penalty.
One way to do this is to re-move constraints from the grammar rules.
How-ever, that would infringe on the precision-orientednature of the grammar.
Instead, we will keep thenormal grammar rules as they are, and create asmall number of additional, super-accepting ro-bustness rules.
The intuition is that when the re-stricted part of the grammar can find a solution,that solution will indeed be found, and preferredby the statistical models.
On the other hand, whenthe sentence is extragrammatical, the robustnessrules may be able to overcome the barriers.Let?s consider the following example, assumingthat the grammar only lists ?to run?
as an intransi-tive verb:?John ran the marathon yesterday?A fragment approach would come up with thefollowing solution:John ran the marathon yesterdaysubj-h?John?
will correctly be identified as the subjectof ?ran?, but that is all.
No dependencies are estab-lished between ?the marathon?
and ?ran?, or ?yes-terday?
and ?ran?.
The former is hard to establish,because of the missing lexical item.
However, thelatter should be doable: the lexicon knows that?yesterday?
is an adverb that modifies verbs.
Ifwe could create a robustness rule that would ab-sorb the object (?the marathon?)
without assigninga dependency, it would at least be able to identifythe modifier dependency between ?ran?
and ?yes-terday?.Johnran the marathonyesterdaym-robusth-adjunctsubj-hIn other words, a fragment analysis solely com-bines items at the top level, whereas a robustparser would ideally be able to overcome barri-ers in both the lower and the higher regions of thechart, meaning that the damage can be localisedand thus minimised.
The robustness rules we pro-pose are intended to achieve that.How does this idea interact with the restrictionmechanism explained in the previous section?
Ro-bustness rules get an inhibitively large, constantpenalty in both the priority model and the dis-ambiguation model.
That means that at first theparser will try to build the parse forest with the re-stricted set of rules, because tasks involving sub-trees with only rules from the standard grammarwill always have a higher priority than tasks us-ing an item with a robustness rule application inits subtree.
When this is finished, the robustnessrules try to fill the gaps.
Especially in the suc-cess and passive strategies, tasks with robustnessrules are discarded if already enough chart itemsare found for a particular span, meaning that theparser automatically focusses on those parts of thechart that haven?t been filled before.3.1 Defining robustness rulesDefining robustness rules is a sort of grammarengineering, and it took a bit of experimentationto find rules that worked well.
One of the fac-tors was the interaction between the subsumption-based packing and the robustness rules.
When thechart is built up, items that are subsumed by an ex-isting item are marked as ?frozen?, and the latter(more general) item functions as the representa-tive node in the remainder of the parsing process.When unpacking the best solution, the best deriva-tion tree is extracted from the packed forest, which227might include a frozen node.
Because this frozennode has more constraints than its representative,this derivation tree is not guaranteed to be free ofunification failures, and hence, before outputting,this is checked by replaying all the unifications inthe derivation tree.
This procedure is repeated un-til a sound derivation has been found.So what happens when the representative nodesare very general?
Many nodes will be packed,and hence the chart will remain compact.
How-ever, the unpacking process will become prob-lematic, because many of the proposed derivationtrees during unpacking will be incorrect, leadingto excessive computation times (in the order ofminutes).Therefore, we chose to define robustness rulessuch, that the resulting chart items will be equallyconstrained as their daughters.
They are all bi-nary, and have one common ancestor in the typehierarchy:?????????????
?structure-robustSYNSEM 1ROBUST +MN-DTR?
?signSYNSEM 1[LOCAL.CAT.HEAD verb]ROBUST -??RB-DTR?
?signSYNSEM[NONLOCAL no-nonlocal]ROBUST -???????????????
?All rules have a main daughter and a robustdaughter.
The co-indexation of the SYNSEM ofthe main daughter and the SYNSEM of the ruleitself has the effect that the resulting chart itemwill have the exact same syntactic properties as itsmain daughter, whereas the robust daughter doesnot contribute to the syntactic properties of themother node.
The ROBUST feature is used toprevent the application of two robust rules con-secutively.
Additional constraints (not shown)make sure that morphological processing is fin-ished, and that both parts are not involved in acoordination.
Robustness rules do not yield a de-pendency triple (although they mght be guessedaccurately by a few heuristics).We define two pairs of robustness rules, eachpair consisting of a rule with MN-DTR first andRB-DTR second, and one rule in the other order:+V The robust daughter is a verb, which is stillallowed to have valence, but cannot have anyfeatures in NONLOCAL.+NV The robust daughter is anything but a verb,cannot have any non-empty valence list, andcannot have any features in NONLOCAL.3.2 Fragment parsingAs a baseline for comparison, we investigate theexisting partial parsing algorithms that pick frag-mented analyses from the parse forest as a fall-back strategy when there is no full parse available.Kiefer et al (1999) took a shortest-path approachto find a sequence of fragment analysis that min-imizes a heuristics-based cost function.
Anothervariation of the algorithm (Riezler et al, 2001)is to pick fewest chunks that connect the entiresentence.
While these early approaches are basedon simple heuristics, more sophisticated parse se-lection methods also use the statistical models torank the partial analyses.
For example, Zhang etal.
(2007a) proposed several ways of integratingdiscriminative parse ranking scores with the par-tial parse selection algorithm.In this experiment, we first use the shortestpath algorithm to find candidate chunks of par-tial analysis.
All phrasal constituents were givenequal weights, and preferred over input and lex-ical edges.
For each chunk (edges spanning thesame sub-string of the input sentence), the edgewith the highest generative probability is picked.Consequently, the best partial reading (coveringthat edge) is decoded by the selective unpackingalgorithm using the MaxEnt parse ranking model.With each fragment, the partial semantic represen-tations were extracted.
Similar to the robustnessrules, no cross-fragment dependencies are recov-ered in this approach.
Due to the limited numberof chart items and the use of selective unpacking,the computation times for the shortest-path algo-rithm are marginal.3.3 ResultsThe results of this experiment are listed in ta-ble 2.
For the robust versions of the grammar,no exhaustive parsing results are reported, be-cause they take too long to compute, as can beexpected.
Coverage number are on a per-sentence228standard +V +NV +V+NVexhaustive restricted restrictedtime (s) 7.20 0.92 4.10 1.42 4.09no fragment coverage 59.3% 60.0% 72.6% 69.9% 78.6%recall 37.6% 38.9% 48.4% 47.0% 53.8%precision 80.7% 80.1% 78.6% 78.2% 77.7%f-score 51.3% 52.4% 59.9% 58.7% 63.6%fragment coverage 94.3% 98.3% 98.5% 98.7% 98.5%recall 50.4% 53.6% 59.5% 56.9% 61.3%precision 75.4% 75.0% 75.0% 74.5% 74.7%f-score 60.4% 62.5% 66.3% 64.5% 67.3%Table 2: Results for experiments with different robustness rules, and with or without fragment fallbackstrategy.basis, whereas the other percentages are on a per-dependency basis.
Time denotes the average num-ber of seconds it takes to build the parse forest.
Allresults under ?restricted?
are carried out with thesuccess strategy, with a cap of 200 tasks (success-200).
?
(No) fragment?
indicates whether a frag-ment parse is returned when no results are ob-tained after selective unpacking.The robustness rules significantly increase thesentential coverage, in the case of +V+NV almost20 percent points.
The gains of +V and +NVare fairly additive: they seem to cover differentsets of extragrammatical sentences.
In the mostpermissive setting (+V+NV), dependency recallgoes up by 16 percent point, with only a 3 per-cent point decrease of precision, showing that thenewly-covered sentences still receive fairly accu-rate parses.
Also, it can be seen that the +V pair ofrules is more effective than +NV to increase cov-erage.
The robust grammars are certainly slowerthan the standard grammar, but still twice as fastas the standard grammar in an exhaustive setting.Coverage numbers are approximating 100%when the fragment parsing fallback strategy is ap-plied, in all settings.
However, it is interestingto see that the recall numbers are higher whenthe robustness rules are more permissive, but thatno significant effect on the precision is observed.This suggests that the lumps that are connected bythe fragment parsing mechanism are larger, dueto previous applications of the robustness rules.From this, we conclude that the connections madeby the robustness rules are of relatively high qual-ity.We have also tried the all-3000 and passive-100 settings (the same as listed in table 1).
Thatyielded very similar results, except on the gram-mar with both +V and +NV enabled.
With pas-sive-100, there was a small decrease in cover-age (76.0%), but this drop was much more pro-nounced for all-3000: 72.0%.
This suggests that,if the pressure on the generative model is largerdue to heavier overgeneration, counting success-ful tasks or passive items performs better than justcounting the number of executed tasks.After manual inspection, we found out that thekind of constructions the robustness rules createdwere very diverse.
Most of the rule applicationswere not in the top of the tree, as was intended.There also seemed to be a correlation between thelength of the robust daughter and the quality of theparse.
When the robust daughter of the rule waslarge, the application of the robustness rule lookedlike an emergency strategy, with a correspondingquality of the parse.
However, when the robust-ness rule connects a verb to a relatively small con-stituent (a particle or an NP, for example), the re-sulting derivation tree was of reasonable quality,keeping most of the other dependencies intact.4 DiscussionAchieving broad coverage in deep parsing whilemaintaining high precision is difficult.
Until now,most existing hand-written grammar-based pars-ing systems rely on fragment analyses (or variousways of putting fragments together to compose229partial readings), but we argued (with the exam-ple in section 3) that such an approach delivers in-ferior results when the tree falls apart at the verybottom.
The use of robust constructions offers away to keep the damage local, but can create anintractable search space.
The proposed pruningstrategies carefully control the bound of overgen-eration, resulting in improvements on both pars-ing efficiency and coverage, with a significantlysmaller degradation in f-score than a pure frag-ment approach.
The combination of grammar en-gineering, statistical modelling and algorithmicdesign in the parser brings the parser performanceto a new level.Although the experiments were carried out ona specific grammar framework, we consider thetechniques put forward in this paper to be applica-ble to other linguistic frameworks.
The robustnessrules are easy to construct (with the precautionsfrom section 3.1 in mind), and all modern deepparsers have a treebank to their disposal, fromwhich the generative model can be learned.There are still points that can be improved on.Currently, there is no way to determine which ofthe robust rule applications are more promisingthan others, and the decision to try one before theother is solely based on the the probabilities of thepassive items, and not on the generative model.This can be inefficient: for instance, all robustnessrules presented in this paper (both +V and +NV)requires the main daughter to be a verb.
It wouldbe straightforward to learn from a small treebankthat trying to unify the main daughter of a robust-ness rules (which should have a verbal head) witha specifier-head rule application does not have ahigh chance on succeeding.Another possible improvement is to differenti-ate between different robustness rules.
We pre-sented a two-tier system here, but the frameworklends itself naturally to more layers with differingdegrees of specificity, creating a smoother scalefrom specific/prioritised to robust/non-prioritised.ReferencesBrants, S., S. Dipper, S. Hansen, W. Lezius, andG.
Smith.
2002.
The TIGER Treebank.
In Pro-ceedings of the Workshop on Treebanks and Lin-guistic Theories, pages 24?41.Cahill, A., J.T.
Maxwell III, P. Meurer, C. Rohrer, andV.
Rose?n.
2008.
Speeding up LFG parsing usingc-structure pruning.
In Proceedings of the Work-shop on Grammar Engineering Across Frameworks,pages 33?40.
Association for Computational Lin-guistics.Callmeier, U.
2000.
PET?a platform for experimen-tation with efficient HPSG processing techniques.Natural Language Engineering, 6(01):99?107.Clark, S. and J.R. Curran.
2007.
Wide-coverage ef-ficient statistical parsing with CCG and log-linearmodels.
Computational Linguistics, 33(4):493?552.Cramer, B. and Y. Zhang.
2009.
Construction ofa German HPSG grammar from a detailed tree-bank.
In Proceedings of the GEAF workshop ACL-IJCNLP 2009, pages 37?45.Kiefer, B., H.U.
Krieger, J. Carroll, and R. Malouf.1999.
A bag of useful techniques for efficient androbust parsing.
In Proceedings of the 37th annualmeeting of the Association for Computational Lin-guistics on Computational Linguistics, pages 473?480.
Association for Computational Linguistics.Matsuzaki, T., Y. Miyao, and J. Tsujii.
2007.
Ef-ficient HPSG parsing with supertagging and CFG-filtering.
In Proceedings of the 20th InternationalJoint Conference on Artificial Intelligence (IJCAI2007), pages 1671?1676, Hyderabad, India.Ninomiya, T., Y. Tsuruoka, Y. Miyao, and J. Tsujii.2005.
Efficacy of beam thresholding, unificationfiltering and hybrid parsing in probabilistic HPSGparsing.
In Proceedings of the Ninth InternationalWorkshop on Parsing Technology, pages 103?114.Association for Computational Linguistics.Oepen, S. and J. Carroll.
2000.
Ambiguity packing inconstraint-based parsing: practical results.
In Pro-ceedings of the first conference on North Americanchapter of the Association for Computational Lin-guistics, pages 162?169.
Morgan Kaufmann Pub-lishers Inc. San Francisco, CA, USA.Riezler, S., T.H.
King, R.M.
Kaplan, R. Crouch, J.T.Maxwell III, and M. Johnson.
2001.
Parsingthe Wall Street Journal using a Lexical-FunctionalGrammar and discriminative estimation techniques.In Proceedings of the 40th Annual Meeting on Asso-ciation for Computational Linguistics, pages 271?278.Tomabechi, H. 1991.
Quasi-destructive graph unifi-cation.
In Proceedings of the 29th annual meet-ing on Association for Computational Linguistics,pages 315?322.
Association for Computational Lin-guistics.230Toutanova, K., C.D.
Manning, S. Shieber,D.
Flickinger, and S. Oepen.
2002.
Parsedisambiguation for a rich HPSG grammar.
InProceedings of the First Workshop on Treebanksand Linguistic Theories, pages 253?263.Van Noord, G. 1997.
An efficient implementation ofthe head-corner parser.
Computational Linguistics,23(3):425?456.van Noord, G. 2009.
Learning efficient parsing.
InProceedings of the 12th Conference of the EuropeanChapter of the ACL (EACL 2009), pages 817?825,Athens, Greece, March.
Association for Computa-tional Linguistics.Zhang, Y., V. Kordoni, and E. Fitzgerald.
2007a.
Par-tial parse selection for robust deep processing.
InProceedings of ACL 2007 Workshop on Deep Lin-guistic Processing, pages 128?135, Prague, Czech.Zhang, Y., S. Oepen, and J. Carroll.
2007b.
Effi-ciency in Unification-Based N-Best Parsing.
In Pro-ceedings of the Tenth International Conference onParsing Technologies, pages 48?59.
Association forComputational Linguistics.231
