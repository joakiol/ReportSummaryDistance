BioNLP 2008: Current Trends in Biomedical Natural Language Processing, pages 1?9,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsA Graph Kernel for Protein-Protein Interaction ExtractionAntti Airola, Sampo Pyysalo, Jari Bjo?rne, Tapio Pahikkala, Filip Ginter and Tapio SalakoskiTurku Centre for Computer Scienceand Department of IT, University of TurkuJoukahaisenkatu 3-520520 Turku, Finlandfirstname.lastname@utu.fiAbstractIn this paper, we propose a graph kernelbased approach for the automated extractionof protein-protein interactions (PPI) from sci-entific literature.
In contrast to earlier ap-proaches to PPI extraction, the introduced all-dependency-paths kernel has the capabilityto consider full, general dependency graphs.We evaluate the proposed method across fivepublicly available PPI corpora providing themost comprehensive evaluation done for a ma-chine learning based PPI-extraction system.Our method is shown to achieve state-of-the-art performance with respect to comparableevaluations, achieving 56.4 F-score and 84.8AUC on the AImed corpus.
Further, we iden-tify several pitfalls that can make evaluationsof PPI-extraction systems incomparable, oreven invalid.
These include incorrect cross-validation strategies and problems related tocomparing F-score results achieved on differ-ent evaluation resources.1 IntroductionAutomated protein-protein interaction (PPI) extrac-tion from scientific literature is a task of significantinterest in the BioNLP field.
The most commonlyaddressed problem has been the extraction of binaryinteractions, where the system identifies which pro-tein pairs in a sentence have a biologically relevantrelationship between them.
Proposed solutions in-clude both hand-crafted rule-based systems and ma-chine learning approaches (see e.g.
(Bunescu et al,2005)).
A wide range of results have been reportedfor the systems, but as we will show, differences inevaluation resources, metrics and strategies make di-rect comparison of these numbers problematic.
Fur-ther, the results gained from the BioCreative II eval-uation, where the best performing system achieveda 29% F-score (Hunter et al, 2008), suggest that theproblem of extracting binary protein protein interac-tions is far from solved.The public availability of large annotated PPI-corpora such as AImed (Bunescu et al, 2005),BioInfer (Pyysalo et al, 2007a) and GENIA (Kimet al, 2008), provides an opportunity for buildingPPI extraction systems automatically using machinelearning.
A major challenge is how to supply thelearner with the contextual and syntactic informa-tion needed to distinguish between interactions andnon-interactions.
To address the ambiguity and vari-ability of the natural language expressions used tostate PPI, several recent studies have focused onthe development, adaptation and application of NLPtools for the biomedical domain.
Many high-qualitydomain-specific tools are now freely available, in-cluding full parsers such as that introduced by Char-niak and Lease (2005).
Additionally, a numberof conversions from phrase structure parses to de-pendency structures that make the relationships be-tween words more directly accessible have been in-troduced.
These include conversions into represen-tations such as the Stanford dependency scheme (deMarneffe et al, 2006) that are explicitly designed forinformation extraction purposes.
However, special-ized feature representations and kernels are requiredto make learning from such structures possible.Approaches such as subsequence kernels(Bunescu and Mooney, 2006), tree kernels (Zelenko1interaction of P1 and P2prep_of> conj_and>prep_of>P1 is a P2 binding protein<nn<nn<det<cop<nsubjP1 fails to bind P2<nsubj <aux dobj>xcomp><xsubjFigure 1: Stanford dependency parses (?collapsed?
rep-resentation) where the shortest path, shown in bold, ex-cludes important words.et al, 2003) and shortest path kernels (Bunescuand Mooney, 2005) have been proposed and suc-cessfully used for relation extraction.
However,these methods lack the expressive power to considerrepresentations derived from general, possiblycyclic, dependency graph structures, such as thosegenerated by the Stanford tools.
The subsequencekernel approach does not consider parses at all, andthe shortest path approach is limited to representingonly a single path in the full dependency graph,which excludes relevant words even in many simplecases (Figure 1).
Tree kernels can represent morecomplex structures, but are still restricted to treerepresentations.Lately, in the framework of kernel-based machinelearning methods there has been an increased in-terest in designing kernel functions for graph data.Building on the work of Ga?rtner et al (2003),graph representations tailored for the task of depen-dency parse ranking were proposed by Pahikkala etal.
(2006b).
Though the proposed representationsare not directly applicable to the task of PPI extrac-tion, they offer insight in how to learn from depen-dency graphs.
We develop a graph kernel approachfor PPI extraction based on these ideas.We next define a graph representation suitable fordescribing potential interactions and introduce a ker-nel which makes efficient learning from a general,unrestricted graph representation possible.
Then weprovide a short description of the sparse regular-ized least squares (sparse RLS) kernel-based ma-chine learning method we use for PPI-extraction.Further, we rigorously assess our method on fivepublicly available PPI corpora, providing the firstbroad cross-corpus evaluation with a machine learn-ing approach to PPI extraction.
Finally, we discussthe effects that different evaluation strategies, choiceof corpus and applied metrics have on measured per-formance, and conclude.2 MethodWe next present our graph representation, formalizethe notion of graph kernels, and present our learningmethod of choice, the sparse RLS.2.1 Graph encoding of sentence structureAs in most recent work on machine learning for PPIextraction, we cast the task as learning a decisionfunction that determines for each unordered candi-date pair of protein names occurring together in asentence whether the two proteins interact.
In thefollowing, we first define the graph representationused to represent an interaction candidate pair.
Wethen proceed to derive the kernel used to measurethe similarities of these graphs.We assume that the input of our learning methodis a dependency parse of a sentence where a pair ofprotein names is marked as the candidate interac-tion for which an extraction decision must be made.Based on this, we form a weighted, directed graphthat consists of two unconnected subgraphs.
Onerepresents the dependency structure of the sentence,and the other the linear order of the words (see Fig-ure 2).The first subgraph is built from the dependencyanalysis.
One vertex and an associated set of labelsis created in the graph for each token and for eachdependency.
The vertices that represent tokens haveas labels the text and part-of-speech (POS) of thetoken.
To ensure generalization of the learned ex-traction model, the labels of vertices that correspondto protein names are replaced with PROT1, PROT2or PROT, where PROT1 and PROT2 are the pair ofinterest.
The vertices that represent dependenciesare labeled with the type of the dependency.
Theedges in the subgraph are defined so that each de-pendency vertex is connected by an incoming edgefrom the vertex representing its governor token, andby an outgoing edge to the vertex representing its de-2Figure 2: Graph representation generated from an example sentence.
The candidate interaction pair is marked asPROT1 and PROT2, the third protein is marked as PROT.
The shortest path between the proteins is shown in bold.
Inthe dependency based subgraph all nodes in a shortest path are specialized using a post-tag (IP).
In the linear ordersubgraph possible tags are (B)efore, (M)iddle, and (A)fter.
For the other two candidate pairs in the sentence, graphswith the same structure but different weights and labels would be generated.pendent token.
The graph thus represents the entiresentence structure.It is widely acknowledged that the words betweenthe candidate entities or connecting them in a syn-tactic representation are particularly likely to carryinformation regarding their relationship; (Bunescuand Mooney, 2005) formalize this intuition for de-pendency graphs as the shortest path hypothesis.
Weapply this insight in two ways in the graph repre-sentation: the labels of the nodes on the shortestundirected paths connecting PROT1 and PROT2 aredifferentiated from the labels outside the paths us-ing a special tag.
Further, the edges are assignedweights; after limited preliminary experiments, wechose a simple weighting scheme where all edgeson the shortest paths receive a weight of 0.9 andother edges receive a weight of 0.3.
The represen-tation thus allows us to emphasize the shortest pathwithout completely disregarding potentially relevantwords outside of the path.The second subgraph is built from the linear struc-ture of the sentence.
For each token, a second ver-tex is created and the labels for the vertices are de-rived from the texts, POS-tags and named entity tag-ging as above.
The labels of each word are special-ized to denote whether the word appears before, in-between, or after the protein pair of interest.
Eachword node is connected by an edge to its succeed-ing word, as determined by sentence order the of thewords.
Each edge is given the weight 0.9.2.2 The all-dependency-paths graph kernelWe next formalize the graph representation andpresent the all-dependency-paths kernel.
This ker-nel can be considered as a practical instantiation ofthe theoretical graph kernel framework introducedby Ga?rtner et al (2003).
Let V be the set of ver-tices in the graph and L be the set of possible labelsvertices can have.
We represent the graph with anadjacency matrix A ?
R|V |?|V |, whose rows andcolumns are indexed by the vertices, and [A]i,j con-tains the weight of the edge connecting vi ?
V andvj ?
V if such an edge exists, and zero otherwise.Further, we represent the labels as a label allocationmatrix L ?
R|L|?|V | so that Li,j = 1 if the j-thvertex has the i-th label and Li,j = 0 otherwise.
Be-cause only a very small fraction of all the possiblelabels are ever assigned to any single node, this ma-trix is extremely sparse.It is well known that when an adjacency matrix ismultiplied with itself, each element [A2]i,j containsthe summed weight of paths from vertex vi to vertexvj through one intervening vertex, that is, paths oflength two.
Similarly, for any length n, the summedweights from vi to vj can be determined by calculat-ing [An]i,j .Since we are interested not only in paths of onespecific length, it is natural to combine the effect ofpaths of different lengths by summing the powersof the adjacency matrices.
We calculate the infinitesum of the weights of all possible paths connecting3the vertices using the Neumann Series, defined as(I ?A)?1 = I + A + A2 + ...
=?
?k=0Akif |A| < 1 where |A| is the spectral radius of A(Meyer, 2000).
From this sum we can form a newadjacency matrixW = (I ?A)?1 ?
I .The final adjacency matrix contains the summedweights of all possible paths connecting the ver-tices.
The identity matrix is subtracted to removethe paths of length zero, which would correspond toself-loops.Next, we present the graph kernel that utilizes thegraph representation defined previously.
We definean instance G representing a candidate interactionas G = LWLT, where L and W are the label al-location matrix and the final adjacency matrix cor-responding to the graph representation of the candi-date interaction.Following Ga?rtner et al (2003) the graph kernelis defined ask(G?, G??)
=|L|?i=1|L|?j=1G?i,jG?
?i,j ,where G?
and G??
are two instances formed as de-fined previously.
The features can be thought ascombinations of labels from connected pairs of ver-tices, with a value that represents the strength oftheir connection.
In practical implementations, thefull G matrices, which consist mostly of zeroes, arenever explicitly formed.
Rather, only the non-zeroelements are stored in memory and used when cal-culating the kernels.2.3 Scalable learning with Sparse RLSRLS is a state-of-the-art kernel-based machinelearning method which has been shown to havecomparable performance to support vector machines(Rifkin et al, 2003).
We choose the sparse versionof the algorithm, also known as subset of regressors,as it allows us to scale up the method to very largetraining set sizes.
Sparse RLS also has the propertythat it is possible to perform cross-validation andregularization parameter selection so that their timecomplexities are negligible compared to the trainingcomplexity.
These efficient methods are analogousto the ones proposed by Pahikkala et al (2006a) forthe basic RLS regression.We now briefly present the basic sparse RLS al-gorithm.
Let m denote the training set size andM = {1, .
.
.
,m} an index set in which the indicesrefer to the examples in the training set.
Instead ofallowing functions that can be expressed as a linearcombination over the whole training set, as in thecase of basic RLS regression, we only allow func-tions of the following restricted type:f(?)
=?i?Baik(?, xi), (1)where k is the kernel function, xi are training datapoints, ai ?
R are weights, and the set indexing thebasis vectors B ?
M is selected in advance.
The co-efficients ai that determine (1) are obtained by min-imizingm?i=1(yi ?
?j?Bajk(xi, xj))2 + ?
?i,j?Baiajk(xi, xj),where the first term is the squared loss function, thesecond term is the regularizer, and ?
?
R+ is a reg-ularization parameter.
Note that all the training in-stances are used for determining the coefficient vec-tor.
The minimizer is obtained by solving the corre-sponding system of linear equations, which can beperformed in O(m|B|2) time.We set the maximum number of basis vectors to4000 in all experiments in this study.
The subsetis selected randomly when the training set size ex-ceeds this number.
Other methods for the selectionof the basis vectors were considered by Rifkin etal.
(2003), who however reported that the randomselection worked as well as the more sophisticatedapproaches.3 Experimental evaluationWe next describe the evaluation resources and met-rics used, provide a comprehensive evaluation of ourmethod across five PPI corpora, and compare our re-sults to earlier work.
Further, we discuss the chal-lenges inherent in providing a valid method evalua-tion and propose solutions.4Statistics Graph Kernel Co-occ.Corpus #POS.
#NEG.
P R F ?F AUC ?AUC P FAIMed 1000 4834 0.529 0.618 0.564 0.050 0.848 0.023 0.178 0.301BioInfer 1370 8924 0.477 0.599 0.529 0.053 0.849 0.065 0.135 0.237HPRD50 163 270 0.643 0.658 0.634 0.114 0.797 0.063 0.389 0.554IEPA 335 482 0.696 0.827 0.751 0.070 0.851 0.051 0.408 0.576LLL 164 166 0.725 0.872 0.768 0.178 0.834 0.122 0.559 0.703Table 1: Counts of positive and negative examples in the corpora and (P)recision, (R)ecall (F)-score and AUC for thegraph kernel, with standard deviations provided for F and AUC.3.1 Corpora and evaluation criteriaWe evaluate our method using five publicly avail-able corpora that contain PPI interaction annotation:AImed (Bunescu et al, 2005), BioInfer (Pyysalo etal., 2007a), HPRD50 (Fundel et al, 2007), IEPA(Ding et al, 2002) and LLL (Ne?dellec, 2005).
Allthe corpora were processed to a common format us-ing transformations1 that we have introduced ear-lier (Pyysalo et al, 2008).
We parse these cor-pora with the Charniak-Lease parser (Charniak andLease, 2005), which has been found to perform bestamong a number of parsers tested in recent domainevaluations (Clegg and Shepherd, 2007; Pyysalo etal., 2007b).
The Charniak-Lease phrase structureparses are transformed into the collapsed Stanforddependency scheme using the Stanford tools (deMarneffe et al, 2006).
We cast the PPI extractiontask as binary classification, where protein pairs thatare stated to interact are positive examples and otherco-occuring pairs negative.
Thus, from each sen-tence,(n2)examples are generated, where n is thenumber of occurrences of protein names in the sen-tence.
Finally, we form the graph representation de-scribed earlier for each candidate interaction.We evaluate the method with 10-fold document-level cross-validation on all of the corpora.
Thisguarantees the maximal use of the available data,and also allows comparison to relevant earlier work.In particular, on the AImed corpus we apply the ex-act same 10-fold split that was used by Bunescu etal.
(2006) and Giuliano et al (2006).
Performanceis measured according to the following criteria: in-teractions are considered untyped, undirected pair-wise relations between specific protein mentions,that is, if the same protein name occurs multiple1Available at http://mars.cs.utu.fi/PPICorpora.times in a sentence, the correct interactions must beextracted for each occurrence.
Further, we do notconsider self-interactions as candidates and removethem from the corpora prior to evaluation.The majority of PPI extraction system evaluationsuse the balanced F-score measure for quantifying theperformance of the systems.
This metric is definedas F = 2prp+r , where p is precision and r recall.
Like-wise, we provide F-score, precision, and recall val-ues in our evaluation.
It should be noted that F-scoreis very sensitive to the underlying positive/negativepair distribution of the corpus ?
a property whoseimpact on evaluation is discussed in detail below.
Asan alternative to F-score, we also evaluate the per-formance of our system using the area under the re-ceiver operating characteristics curve (AUC) mea-sure (Hanley and McNeil, 1982).
AUC has the im-portant property that it is invariant to the class dis-tribution of the used dataset.
Due to this and otherbeneficial properties for comparative evaluation, theusage of AUC for performance evaluation has beenrecently advocated in the machine learning commu-nity (see e.g.
(Bradley, 1997)).
Formally, AUC canbe defined asAUC =?m+i=1?m?j=1H(xi ?
yi)m+m?,where m+ and m?
are the numbers of positiveand negative examples, respectively, and x1,...,xm+are the outputs of the system for the positive, andy1,...,ym?
for the negative examples, andH(r) =??
?1, if r > 00.5, if r = 00, otherwise.The measure corresponds to the probability thatgiven a randomly chosen positive and negative ex-5ample, the system will be able to correctly disin-guish which one is which.3.2 Performance across corporaThe performance of our method on the five corporafor the various metrics is presented in Table 1.
Forreference, we show also the performance of the co-occurrence (or all-true) baseline, which simply as-signs each candidate into the interaction class.
Therecall of the co-occurrence method is trivially 100%,and in terms of AUC it has a score of 0.5, the ran-dom baseline.
All the numbers in Table 1 are aver-ages taken over the ten folds.
One should note thatbecause of the non-linearity of the F-score measure,the average precision and recall will not produce ex-actly the average F.The results hold several interesting findings.
First,we briefly observe that on the AImed corpus, whichhas recently been applied in numerous evaluations(S?tre et al, 2008) and can be seen as an emergingde facto standard for PPI extraction method evalua-tion, the method achieves an F-score performance of56.4%.
As we argue in more detail below, this levelof performance is comparable to the state-of-the-artin machine learning based PPI extraction.
For theother large corpus, BioInfer, F-score performance isslightly lower.Second, we observe that the F-score performanceof the method varies strikingly between the differ-ent corpora, with results on IEPA and LLL approx-imately 20 percentage units higher than on AImedand BioInfer, despite the larger size of the latter two.In our previous work we have observed similar re-sults with a rule-based extraction method (Pyysalo etal., 2008).
As the first broad cross-corpus evaluationusing a state-of-the-art machine learning method forPPI extraction, our results support and extend thekey finding that F-score performance results mea-sured on different corpora cannot, in general, bemeaningfully compared.The co-occurrence baseline numbers indicate onereason for the high F-score variance between thecorpora.
The F-score metric is not invariant to thedistribution of positive and negative examples: forexample, halving the number of negative test exam-ples is expected to approximately halve the numberof false positives at a given recall point.
Thus, thegreater the fraction of true interactions in a corpusis, the easier it is to reach high performance in termsof F-score.
This is reflected in co-occurrence re-sults, which range from 24% to 70% depending onthe class distribution of the corpus.This is a critical weakness of the F-score metric incross-corpus comparisons as, for example, the frac-tion of true interactions out of all candidates is 50%on the LLL corpus but only 17% on AImed.
Bycontrast to the large differences in performance mea-sured using F-score, we find that for the distribution-invariant AUC measure the performance for all ofthe AImed, BioInfer, IEPA, and LLL corpora falls inthe narrow range of 83-85%.
In terms of AUC, per-formance on the HPRD50 corpus is an outlier, beingapproximately three percentage units lower than forany other corpus.
Nevertheless, the results provide astrong argument in favor of applying the AUC met-ric instead of, or in addition to, F-score.
AUC is alsomore stable in terms of variance.Finally, we note that the similar performance interms of AUC for corpora with as widely differingsizes as LLL and BioInfer indicates that past a rel-atively modest number of examples, increasing cor-pus size has a surprisingly small effect on the perfor-mance of the method.
A similar finding can be seen,for example, in the relatively flat learning curve ofGiuliano et al (2006).
While the issue requires fur-ther investigation, these results suggest that theremay be more value in investing effort in develop-ing better learning methods as opposed to larger cor-pora.3.3 Performance compared to other methodsWe next discuss the performance of our methodcompared to other methods introduced in the liter-ature and the challenges of meaningful comparison,where we identify three major issues.First, as indicated by the results above, differ-ences in the makeup of different corpora rendercross-corpus comparisons in terms of F-score es-sentially meaningless.
As F-score is typically theonly metric for which results are reported in the PPIextraction literature, we are limited to comparingagainst results on single corpora.
We consider theAImed and BioInfer evaluations to be the most rele-vant ones, as these corpora are sufficiently large fortraining and reliably testing machine learning meth-ods.
As the present study is, to the best of our knowl-6P R F(Giuliano et al, 2006) 60.9% 57.2% 59.0%All-dependency-paths graph kernel 52.9% 61.8% 56.4%(Bunescu and Mooney, 2006) 65.0% 46.4% 54.2%(S?tre et al, 2008) 64.3% 44.1% 52.0%(Mitsumori et al, 2006) 54.2% 42.6% 47.7%(Yakushiji et al, 2005) 33.7% 33.1% 33.4%Table 2: (P)recision, (R)ecall and (F)-score results for methods evaluated on AImed with the correct cross-validationmethodology.edge, the first to report machine learning methodperformance on BioInfer, we will focus on AImedin the following comparison.Second, the cross-validation strategy used in eval-uation has a large impact on measured performance.In earlier system evaluations, two major strategiesfor defining the splits used in cross-validation canbe observed.
The approach used by Bunescu andMooney (2006), which we consider the correct one,is to split the data into folds on level of docu-ments.
This guarantees that all pairs generated fromthe same document are always either in the train-ing set or in the test set.
Another approach is topool all the generated pairs together, and then ran-domly split them to folds.
To illustrate the signifi-cance of this choice, consider two interaction candi-dates extracted from the same sentence, e.g.
froma statement of the form ?P1 and P2 [.
.
. ]
P3?,where ?[.
.
.
]?
is any statement of interaction or non-interaction.
Due to the near-identity of contexts, amachine learning method will easily learn to predictthat the label of the pair (P1, P2) should match thatof (P1, P3).
However, such ?learning?
will clearlynot generalize.
This approach must thus be consid-ered invalid, because allowing pairs generated fromsame sentences to appear in different folds leads toan information leak between the training and testsets.
S?tre et al (2008) observed that adopting thelatter cross-validation strategy on AImed could leadup to 18 F-score percentage unit overestimation ofperformance.
For this reason, we will not considerresults listed in the ?False 10-fold cross-validation?table (2b) of S?tre et al (2008).With these restrictions in place, we now turn tocomparison with relevant results reported in relatedresearch, summarized in Table 2.
We note thatBunescu and Mooney (2006) only applied evalua-tion criteria where it is enough to extract only oneoccurrence of each mention of an interaction fromeach abstract, while the other results shown wereevaluated using the same criteria as applied here.The former approach can produce higher perfor-mance: the evaluation of Giuliano et al (2006) in-cludes both alternatives, and their method achievesan F-score of 63.9% under the former criterion,which they term One Answer per Relation in agiven Document (OARD).
Our method outperformsmost studies using similar evaluation methodology,with the exception being the approach of Giulianoet al (2006).
This result is somewhat surprising,as the method proposed by Giuliano does not ap-ply any form of parsing but relies instead only onthe sequential order of the words.
This brings usto our third point regarding comparability of meth-ods.
As pointed out by S?tre et al (2008), theAImed corpus allows remarkably different ?inter-pretations?
regarding the number of interacting andnon-interacting pairs.
For example, where we haveidentified 1000 interacting and 4834 non-interactingprotein pairs in AImed, in the data used by Giulianothere are eight more interacting and 200 fewer non-interacting pairs.
The corpus can also be prepro-cessed in a number of ways.
In particular we noticedthat whereas protein names are always blinded in ourdata, in the data used by Giuliano protein names aresometimes partly left visible.
As Giuliano has gen-erously made his method implementation available2,we were able to test the performance of his systemon the data we used in our experiments.
This re-sulted in an F-score of 52.4%.Finally, there remains an issue of parameter se-lection.
For sparse RLS the values of the regular-2Available at http://tcc.itc.it/research/textec/tools-resources/jsre.html.7ization parameter ?
and the decision threshold sep-arating the positive and negative classes must bechosen, which can be problematic when no sepa-rate data for choosing them is available.
Choos-ing from several parameter values the ones that givebest results in testing, or picking the best pointfrom a precision/recall curve when evaluating interms of F-score, will lead to an overoptimistic eval-uation of performance.
This issue has often notbeen addressed in earlier evaluations that do cross-validation on a whole corpus.
We choose the pa-rameters by doing further leave-one-document-outcross-validation within each round of 10-fold-cross-validation, on the nine folds that constitute the train-ing set.As a conclusion, we observe the results achievedwith the all-dependency-paths kernel to be state-of-the-art level.
However, differences in evaluationstrategies and the large variance exhibited in the re-sults make it impossible to state which of the sys-tems considered can be expected in general to per-form best.
We encourage future PPI-system evalua-tions to report AUC and F-score results over mul-tiple corpora, following clearly defined evaluationstrategies, to bring further clarity to this issue.4 Conclusions and future workIn this paper we have proposed a graph kernelapproach to extracting protein-protein interactions,which captures the information in unrestricted de-pendency graphs to a format that kernel based learn-ing algorithms can process.
The method combinessyntactic analysis with a representation of the lin-ear order of the sentence, and considers all possi-ble paths connecting any two vertices in the result-ing graph.
We demonstrate state-of-the art perfor-mance for the approach.
All software developed inthe course of this study is made publicly available athttp://mars.cs.utu.fi/PPICorpora.We identify a number of issues which make re-sults achieved with different evaluation strategiesand resources incomparable, or even incorrect.
Inour experimental design we consider the problemsrelated to differences across corpora, the effects dif-ferent cross-validation strategies have, and how pa-rameter selection can be done.
Our recommendationis to provide evaluations over different corpora, touse document-level cross-validation and to alwaysselected parameters on the training set.We draw attention to the behaviour of the F-scoremetric over corpora with differing pair distributions.The higher the relative frequency of interacting pairsis, the higher the performance can be expected tobe.
This is noticed both for the graph kernel methodand for the naive co-occurrence baseline.
Indeed,the strategy of just stating that all pairs interact leadsto as high result as 70% F-score on one of the cor-pora.
We consider AUC as an alternative measurethat does not exhibit such behaviour, as it is invari-ant to the distribution of pairs.
The AUC metric ismuch more stable across all the corpora, and nevergives better results than random for approaches suchas the naive co-occurrence.Though we only consider binary interactions inthis work, the graph representations have the prop-erty that they could be used to represent more com-plex structures than pairs.
The availability of cor-pora that annotate complex interactions, such as thefull BioInfer and GENIA, makes training a PPI ex-traction system for extracting complex interactionsan important avenue of future research.
However,how to avoid the combinatorial explosion followingfrom considering triplets, quartets etc.
remains anopen question.
Also, the performance of the cur-rent approaches may need to be yet improved beforeextending them to recognize complex interactions.AcknowledgementsWe would like to thank Razvan Bunescu, ClaudioGiuliano and Rune S?tre for their generous assis-tance in providing us with data, software and infor-mation about their work on PPI extraction.
Further,we thank CSC, the Finnish IT center for science,for providing us extensive computational resources.This work has been supported by the Academy ofFinland and the Finnish Funding Agency for Tech-nology and Innovation, Tekes.ReferencesAndrew P. Bradley.
1997.
The use of the area underthe ROC curve in the evaluation of machine learningalgorithms.
Pattern Recognition, 30(7):1145?1159.Razvan Bunescu and Raymond Mooney.
2005.
A short-est path dependency kernel for relation extraction.
InProceedings of HLT/EMNLP?05, pages 724?731.8Razvan Bunescu and Raymond Mooney.
2006.
Subse-quence kernels for relation extraction.
In Proceedingsof NIPS?05, pages 171?178.
MIT Press.Razvan C. Bunescu, Ruifang Ge, Rohit J. Kate, Ed-ward M. Marcotte, Raymond J. Mooney, Arun Ku-mar Ramani, and Yuk Wah Wong.
2005.
Compar-ative experiments on learning information extractorsfor proteins and their interactions.
Artif Intell Med,33(2):139?155.Eugene Charniak and Matthew Lease.
2005.
Parsingbiomedical literature.
In Proceedings of IJCNLP?05,pages 58?69.Andrew Brian Clegg and Adrian Shepherd.
2007.Benchmarking natural-language parsers for biologicalapplications using dependency graphs.
BMC Bioinfor-matics, 8(1):24.Marie-Catherine de Marneffe, Bill MacCartney, andChristopher D. Manning.
2006.
Generating typed de-pendency parses from phrase structure parses.
In Pro-ceedings of LREC?06, pages 449?454.J.
Ding, D. Berleant, D. Nettleton, and E. Wurtele.
2002.Mining MEDLINE: abstracts, sentences, or phrases?In Proceedings of PSB?02, pages 326?337.Katrin Fundel, Robert Kuffner, and Ralf Zimmer.
2007.RelEx?Relation extraction using dependency parsetrees.
Bioinformatics, 23(3):365?371.Thomas Ga?rtner, Peter A. Flach, and Stefan Wrobel.2003.
On graph kernels: Hardness results and efficientalternatives.
In COLT?03, pages 129?143.
Springer.Claudio Giuliano, Alberto Lavelli, and Lorenza Romano.2006.
Exploiting shallow linguistic information for re-lation extraction from biomedical literature.
In Pro-ceedings of EACL?06.James A. Hanley and B. J. McNeil.
1982.
The meaningand use of the area under a receiver operating charac-teristic (roc) curve.
Radiology, 143(1):29?36.Lawrence Hunter, Zhiyong Lu, James Firby, William A.Baumgartner, Helen L Johnson, Philip V. Ogren, andK.
Bretonnel Cohen.
2008.
OpenDMAP: An open-source, ontology-driven concept analysis engine, withapplications to capturing knowledge regarding proteintransport, protein interactions and cell-specific geneexpression.
BMC Bioinformatics, 9(78).Jin-Dong Kim, Tomoko Ohta, and Jun?ichi Tsujii.
2008.Corpus annotation for mining biomedical events fromliterature.
BMC Bioinformatics, 9(10).Carl D. Meyer.
2000.
Matrix analysis and applied linearalgebra.
Society for Industrial and Applied Mathe-matics.Tomohiro Mitsumori, Masaki Murata, Yasushi Fukuda,Kouichi Doi, and Hirohumi Doi.
2006.
Extractingprotein-protein interaction information from biomed-ical text with svm.
IEICE - Trans.
Inf.
Syst., E89-D(8):2464?2466.Claire Ne?dellec.
2005.
Learning language in logic -genic interaction extraction challenge.
In Proceedingsof LLL?05.Tapio Pahikkala, Jorma Boberg, and Tapio Salakoski.2006a.
Fast n-fold cross-validation for regularizedleast-squares.
In Proceedings of SCAI?06, pages 83?90.Tapio Pahikkala, Evgeni Tsivtsivadze, Jorma Boberg, andTapio Salakoski.
2006b.
Graph kernels versus graphrepresentations: a case study in parse ranking.
In Pro-ceedings of the ECML/PKDD?06 workshop on Miningand Learning with Graphs.Sampo Pyysalo, Filip Ginter, Juho Heimonen, JariBjo?rne, Jorma Boberg, Jouni Ja?rvinen, and TapioSalakoski.
2007a.
BioInfer: A corpus for informationextraction in the biomedical domain.
BMC Bioinfor-matics, 8(50).Sampo Pyysalo, Filip Ginter, Veronika Laippala, Ka-tri Haverinen, Juho Heimonen, and Tapio Salakoski.2007b.
On the unification of syntactic annotations un-der the stanford dependency scheme: A case study onBioInfer and GENIA.
In Proceedings of BioNLP?07,pages 25?32.Sampo Pyysalo, Antti Airola, Juho Heimonen, JariBjo?rne, Filip Ginter, and Tapio Salakoski.
2008.Comparative analysis of five protein-protein interac-tion corpora.
BMC Bioinformatics, special issue,9(Suppl 3):S6.Ryan Rifkin, Gene Yeo, and Tomaso Poggio, 2003.
Reg-ularized Least-squares Classification, volume 190 ofNATO Science Series III: Computer and System Sci-ences, chapter 7, pages 131?154.
IOS Press.Rune S?tre, Kenji Sagae, and Jun?ichi Tsujii.
2008.
Syn-tactic features for protein-protein interaction extrac-tion.
In Proceedings of LBM?07, volume 319, pages6.1?6.14.Akane Yakushiji, Yusuke Miyao, Yuka Tateisi, andJun?ichi Tsujii.
2005.
Biomedical information ex-traction with predicate-argument structure patterns.
InProceedings of SMBM?05, pages 60?69.Dmitry Zelenko, Chinatsu Aone, and AnthonyRichardella.
2003.
Kernel methods for relationextraction.
J. Mach.
Learn.
Res., 3:1083?1106.9
