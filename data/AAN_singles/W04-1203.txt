Analysis of Link Grammar on Biomedical Dependency CorpusTargeted at Protein-Protein InteractionsSampo Pyysalo, Filip Ginter, Tapio Pahikkala,Jorma Boberg, Jouni Ja?rvinen, Tapio SalakoskiTurku Centre for Computer Science (TUCS)and Dept.
of computer science, University of TurkuLemminka?isenkatu 14A20520 Turku, Finland,first name.last name@it.utu.fiJeppe KoivulaMediCel Ltd.,Haartmaninkatu 800290 Helsinki, Finland,jeppe.koivula@medicel.comAbstractIn this paper, we present an evaluation of theLink Grammar parser on a corpus consistingof sentences describing protein-protein interac-tions.
We introduce the notion of an interac-tion subgraph, which is the subgraph of a de-pendency graph expressing a protein-protein in-teraction.
We measure the performance of theparser for recovery of dependencies, fully correctlinkages and interaction subgraphs.
We analyzethe causes of parser failure and report specificcauses of error, and identify potential modifica-tions to the grammar to address the identifiedissues.
We also report and discuss the effect ofan extension to the dictionary of the parser.1 IntroductionThe challenges of processing the vast amounts ofbiomedical publications available in databasessuch as MEDLINE have recently attracted aconsiderable interest in the Natural LanguageProcessing (NLP) research community.
Thetask of information extraction, commonly tar-geting entity relationships, such as protein-protein interactions, is an often studied prob-lem to which various NLP methods have beenapplied, ranging from keyword-based methods(see, e.g., Ginter et al (2004)) to full syntacticanalysis as employed, for example, by Cravenand Kumlien (1999), Temkin and Gilder (2003)and Daraselia et al (2004).In this paper, we focus on the syntactic anal-ysis component of an information extractionsystem targeted to find protein-protein inter-actions from the dependency output producedby the Link Grammar1 (LG) parser of Sleatorand Temperley (1991).
Two recent papers studyLG in the context of biomedical NLP.
The workby Szolovits (2003) proposes a fully automatedmethod to extend the dictionary of the LG1http://www.link.cs.cmu.edu/link/parser with the UMLS Specialist2 lexicon, andDing et al (2003) perform a basic evaluationof LG performance on biomedical text.
As bothpapers suggest, LG will require modifications inorder to provide a correct analysis of grammat-ical phenomena that are rare in general Englishtext, but common in biomedical language.
Im-plementing such modifications is a major effortthat requires a careful analysis of the perfor-mance of the LG parser to identify the mostcommon causes of parsing failures and to targetmodification efforts.While Szolovits (2003) does not attempt toevaluate parser performance at all and Dinget al (2003) provide only an informal evalua-tion on manually simplified sentences, we focuson a more formal evaluation of the LG parser.For the purpose of this study and also for sub-sequent research of biomedical information ex-traction with the LG parser, we have developeda hand-annotated corpus consisting of unmod-ified sentences from publications.
We use thiscorpus to evaluate the performance of the LGparser and to identify problems and potentialimprovements to the grammar and parser.2 Link Grammar and parserThe Link Grammar and its parser represent animplementation of a dependency-based compu-tational grammar.
The result of LG analysis fora sentence is a labeled undirected simple graph,whose nodes represent the words of the sentenceand whose edges and their labels express thegrammatical relationships between the words.In LG terminology, the graph is called a link-age, and its edges are called links.
The linkagemust be planar (i.e., links must not cross) whendrawn above the words of the sentence, and thelabels of the links must satisfy the linking con-straints specified for each word in the grammar.A connected linkage is termed complete.2http://www.nlm.nih.gov/research/umls/15findings suggest that PIP2 binds to proteins such as profilinFigure 1: Annotation example.
The interaction of two proteins, PIP2 and profilin, is stated bythe words binds to.
The links joining these words form the interaction subgraph (drawn with solidlines).Due to the structural ambiguity of naturallanguage, several linkages can typically be con-structed for an input sentence.
In such cases,the LG parser enumerates all linkages allowedby the grammar.
A post-processing step is thenemployed to enforce a number of additional con-straints.
The number of linkages for some sen-tences can be very high, making post-processingand storage prohibitively expensive.
This prob-lem is addressed in the LG parser by definingkmax, the maximal number of linkages to bepost-processed.
If the parsing algorithm pro-duces more than kmax linkages, the output isreduced to kmax linkages by random sampling.The linkages are then ordered from best to worstusing heuristic goodness criteria.In order to be usable in practice, a parser istypically required to provide a partial analysisof a sentence for which it cannot construct a fullanalysis.
If the LG parser cannot construct acomplete linkage for a sentence, the connected-ness requirement is relaxed so that some wordsdo not belong to the linkage at all.
The LGparser is also time-limited.
If the full set oflinkages cannot be constructed in a given timetmax, the parser enters a panic mode, in which itperforms an efficient but considerably restrictedparse, resulting in reduced performance.
Theparameters tmax and kmax set the trade-off be-tween the qualitative performance and the re-source efficiency of the parser.3 Corpus annotation and interactionsubgraphsTo compile a corpus of sentences describingprotein-protein interactions, we first selectedpairs of proteins that are known to interactfrom the Database of Interacting Proteins3.
Weentered these pairs as search terms into thePubMed retrieval system.
We then split thepublication abstracts returned by the searchesinto sentences and included titles.
These wereagain searched for the protein pairs.
This gaveus a set of 1927 sentences that contain the3http://dip.doe-mbi.ucla.edu/names of at least two proteins that are knownto interact.
A domain expert annotated thesesentences for protein names and for words stat-ing their interactions.
Of these sentences, 1114described at least one protein-protein interac-tion.Thereafter, we performed a dependency anal-ysis and produced annotation of dependencies.To minimize the amount of mistakes, each sen-tence was independently annotated by two an-notators and differences were then resolved bydiscussion.
The assigned dependency structurewas produced according to the LG linkage con-ventions.
Link types were not included in theannotation, and no cycles were introduced inthe dependency graphs.
All ambiguities wherethe LG parser is capable of at least enumerat-ing all alternatives (such as prepositional phraseattachment) were enforced in the annotation.A random sample consisting of 300 sentences,including 28 publication titles, has so far beenfully annotated, giving 7098 word-to-word de-pendencies.
This set of sentences is the corpuswe refer to in the following sections.An information extraction system targetedat protein-protein interactions and their typesneeds to identify three constituents that expressan interaction in a sentence: the proteins in-volved and the word or phrase that states theirinteraction and suggests the type of this inter-action.
To extract this information from a LGlinkage, the links connecting these items mustbe recovered correctly by the parser.
The fol-lowing definition formalizes this notion.Definition 1 (Interaction subgraph) Theinteraction subgraph for an interaction betweentwo proteins A and B in a linkage L is theminimal connected subgraph of L that containsA, B, and the word or phrase that states theirinteraction.The recovery of a connected component con-taining the protein names and the interactionword is not sufficient: by the definition of acomplete linkage, such a component is alwayspresent.
Consequently, the exact set of links16that forms the interaction subgraph must be re-covered.For each interaction stated in a sentence,the corpus annotation specifies the proteins in-volved and the interaction word.
The interac-tion subgraph for each interaction can thus beextracted automatically from the corpus.
Be-cause the corpus does not contain cyclic depen-dencies, the interaction subgraphs are unique.366 interaction subgraphs were identified fromthe corpus, one for each described interaction.The interaction subgraphs can be partially over-lapping, because a single link can be part ofmore than one interaction subgraph.
Figure 1shows an example of an annotated text frag-ment.4 Evaluation criteriaWe evaluated the performance of the LG parseraccording to the following three quantitative cri-teria:?
Number of dependencies recovered?
Number of fully correct linkages?
Number of interaction subgraphs recoveredThe number of recovered dependencies gives anestimate of the probability that a dependencywill be correctly identified by the LG parser(this criterion is also employed by, e.g., Collinset al (1999)).
The number of fully correct link-ages, i.e.
linkages where all annotated depen-dencies are recovered, measures the fraction ofsentences that are parsed without error.
How-ever, a fully correct linkage is not necessary toextract protein-protein interactions from a sen-tence; to estimate how many interactions canpotentially be recovered, we measure the num-ber of interaction subgraphs for which all de-pendencies were recovered.For each criterion, we measure the perfor-mance for the first linkage returned by theparser.
However, the first linkage as orderedby the heuristics of the LG parser was often notthe best (according to the criteria above) of thelinkages returned by the parser.
To separatethe effect of the heuristics from overall LG per-formance, we identify separately for each of thethree criteria the best linkage among the link-ages returned by the parser, and we also reportperformance for the best linkages.We further divide the parsed sentences intothree categories: (1) sentences for which thetime tmax for producing a normal parse was ex-hausted and the parser entered panic mode, (2)sentences where linkages were sampled becausemore than kmax linkages were produced, and(3) stable sentences for which neither of theseoccurred.
A full analysis of all linkages thatthe grammar allows is only possible for stablesentences.
For sentences in the other two cat-egories, random effects may affect the results:sentences for which more than kmax linkages areproduced are subject to randomness in sam-pling, and sentences where the parser enterspanic mode were always subject to subsequentsampling in our experiments.5 EvaluationTo evaluate the ability of the LG parser to pro-duce correct linkages, we increased the numberof stable sentences by setting the tmax param-eter to 10 minutes and the kmax parameter to10000 instead of using the defaults tmax = 30seconds and kmax = 1000.
When parsing thecorpus using these parameters, 28 sentences fellinto the panic category, 61 into the sampledcategory, and 211 were stable.
The measuredparser performance for the corpus is presentedin Table 1.While the fraction of sentences that have afully correct linkage as the first linkage is quitelow (approximately 7%), for 28% of sentencesthe parser is capable of producing a fully cor-rect linkage.
Performance was especially poorfor the publication titles in the corpus.
Becausetitles are typically fragments not containing averb, and LG is designed to model full clauses,the parser failed to produce a fully correct link-age for any of the titles.The performance for recovered interactionsubgraphs is more encouraging, as 25% of thesubgraphs were recovered in the first linkage andmore than half in the best linkage.
Yet many in-teraction subgraphs remain unrecovered by theparser: the results suggest an upper limit ofapproximately 60% to the fraction of protein-protein interactions that can be recovered fromany linkage produced by the unmodified LG.In the following sections we further analyze thereasons why the parser fails to recover all de-pendencies.5.1 PanicsNo fully correct linkages and very few interac-tion subgraphs were found in the panic mode.This effect may be partly due to the complex-ity of the sentences for which the parser en-17CategoryCriterion Linkage Stable Sampled Panic OverallDependency First linkage 3242 (80.0%) 1376 (74.3%) 569 (52.3%) 5187 (73.1%)Best linkage 3601 (86.6%) 1576 (85.0%) 620 (57.0%) 5797 (81.7%)Total 4157 1853 1088 7098Fully correct First linkage 22 (10.4%) 0 (0.0%) 0 (0.0%) 22 (7.3%)Best linkage 79 (37.4%) 6 (9.8%) 0 (0.0%) 85 (28.3%)Total 211 61 28 300Interaction First linkage 75 (30.5%) 16 (20.2%) 0 (0.0%) 91 (24.9%)subgraph Best linkage 156 (63.4%) 49 (62.0%) 4 (9.8%) 209 (57.1%)Total 246 79 41 366Table 1: Parser performance.
The fraction of fulfilled criteria is shown by category (the criteria andcategories are explained in Section 4).
The total rows give the number of criteria for each category,and the overall column gives combined results for all categories.tered panic mode.
The effect of panics canbe better estimated by forcing the parser tobypass standard parsing and to directly applypanic options.
For the 272 sentences where theparser did not enter the panic mode, 77% ofdependencies were recovered in the first link-age.
When these sentences were parsed in forcedpanic mode, 67% of dependencies were recov-ered, suggesting that on average parses in panicmode recover approximately 10% fewer depen-dencies than in standard parsing mode.
Simi-larly, the number of fully correct first linkagesdecreased from 22 to 6 and the number of inter-action subgraphs recovered in the first linkagefrom 91 to 65.
These numbers indicate thatpanics are a significant cause of error.Experiments indicate than on a 1GHz ma-chine approximately 40% of sentences can befully parsed in under a second, 80% in under 10seconds and 90% within 10 minutes; yet approx-imately 5% of sentences take more than an hourto fully parse.
With tmax set to 10 minutes, thetotal parsing time was 165 minutes.Long parsing times are caused by ambiguoussentences for which the parser creates thousandsor even millions of alternative linkages.
In ad-dition to simply increasing the time limit, thefraction of sentences where the parser enters thepanic mode could therefore be reduced by re-ducing the ambiguity of the sentences, for ex-ample, by extending the dictionary of the parser(see Section 7).5.2 HeuristicsWhen several linkages are produced for a sen-tence, the LG parser applies heuristics to or-der the sentences so that linkages that are morelikely to be correct are presented first.
Theheuristics are based on examination and intu-itions on general English, and may not be opti-mal for biomedical text.
Note in Table 1 thatboth for recovered full linkages and interactionsubgraphs, the number of items that were recov-ered in the best linkage is more than twice thenumber recovered in the first linkage, suggestingthat a better ordering heuristic could dramat-ically improve the performance of the parser.Such improvements could perhaps be achievedby tuning the heuristics to the domain or byadopting a probabilistic ordering model.6 Failure analysisA significant fraction of dependencies were notrecovered in any linkage, even in sentenceswhere resources were not exhausted.
In order toidentify reasons for the parser failing to recoverthe correct dependencies, we analyze sentencesfor which it is certain that the grammar cannotproduce a fully correct linkage.
We thus ana-lyzed the 132 stable sentences for which somedependencies were not recovered.For each sentence, we attempt to identify thereason for the failure of the parser.
For eachidentified reason, we manually edit the sentenceto remove the source of failure.
We repeat thisprocedure until the parser is capable of pro-ducing a correct parse for the sentence.
Notethat this implies that also the interaction sub-graphs in the sentence are correctly recovered,and therefore the reasons for failures to recoverinteraction subgraphs are a subset of the iden-tified issues.
The results of the analysis are18Reason for failure CasesUnknown grammatical structure 72 (34.4%)Dictionary issue 54 (25.8%)Unknown word handling 35 (16.7%)Sentence fragment 27 (12.9%)Ungrammatical sentence 17 (8.1%)Other 4 (1.9%)Table 2: Results of failure analysissummarized in Table 2.
In many of the sen-tences, more than one reason for parser failurewas found; in total 209 issues were identified inthe 132 sentences.
The results are described inmore detail in the following sections.6.1 Fragments and ungrammaticalsentencesAs some of the analyzed sentences were takenfrom publication titles, not all of them werefull clauses.
To identify further problems whenparsing fragments not containing a verb, thephrase ?is explained?
and required determinerswere added to these fragments, a technique usedalso by Ding et al (2003).
The completed frag-ments were then analyzed for potential furtherproblems.A number of other ungrammatical sentenceswere also encountered.
The most commonproblem was the omission of determiners, butsome other issues such as missing possessivemarkers and errors in agreement (e.g., ?expres-sions.
.
.
has?)
were also encountered.Ungrammatical sentences pose interestingchallenges for parsing.
Because many authorsare not native English speakers, a greater toler-ance for grammatical mistakes should allow theparser to identify the intended parse for moresentences.
Similarly, the ability to parse publi-cation titles would extend the applicability ofthe parser; in some cases it may be possibleto extract information concerning the key find-ings of a publication from the title.
However,while relaxing completeness and correctness re-quirements, such as mandatory determiners andsubject-predicate agreement, would allow theparser to create a complete linkage for more sen-tences, it would also be expected to lead to in-creased ambiguity for all sentences, and subse-quent difficulties in identifying the correct link-age.
If the ability to parse titles is consideredimportant, a potential solution not incurringthis cost would be to develop a separate versionof the grammar for parsing titles.capping protein and actin genescapping protein and actin genesFigure 2: Multiple modifier coordination prob-lem.
Above: correct linkage disallowed by theLG parser.
Below: solution by chaining modi-fiers.6.2 Unknown grammatical structuresThe method of the LG implementation for pars-ing coordinations was found to be a frequentcause of failures.
A specific coordination prob-lem occurs with multiple noun-modifiers: theparser assumes that coordinated constituentscan be connected to the rest of the sentencethrough exactly one word, and the grammar at-taches all noun-modifiers to the head.
Biomed-ical texts frequently contain phrases that causethese requirements to conflict: for example, inthe phrase ?capping protein and actin genes?
(where ?capping protein genes?
and ?actingenes?
is the intended parse), the parser allowsonly one of the words ?capping?
and ?protein?to connect to the word ?genes?, and is thus un-able to produce the correct linkage (for illustra-tion, see Figure 2(a)).This multiple modifier coordination issuecould be addressed by modifying the grammarto chain modifiers (Figure 2(b)).
This alterna-tive model is adopted by another major depen-dency grammar, the EngCG-based ConnexorMachinese.
The problem could also be ad-dressed by altering the coordination handlingsystem in the parser.Other identified grammatical structures notknown to the parser were number postmodifiersto nouns (e.g., ?serine 38?
), specifiers in paren-theses (e.g., ?profilin mutant (H119E)?
), coor-dination with the phrase ?but not?, and variousunknown uses of colons and quotes.
Single in-stances of several distinct unknown grammati-cal structures were also noted (e.g., ?5 to 10?,?as expected from?, ?most concentrated in?
).Most of these issues can be addressed by localmodifications to the grammar.6.3 Unknown word handlingThe LG parser assigns unknown words to cate-gories based on morphological or other surfaceclues when possible.
For remaining unknown19words, parses are attempted by assigning thewords to the generic noun, verb and adjectivetypes in all possible combinations.Some problems with the unknown word pro-cessing method were encountered during analy-sis; for example, the assumption that unknowncapitalized words are proper nouns often causedfailures, especially in sentences beginning withan unknown word.
Similarly, the assumptionthat words containing a hyphen behave as ad-jectives was violated by a number of unknownverbs (e.g., ?cross-links?
).Another problem that was noted occurredwith lowercase unknown words that should betreated as proper nouns: because LG does notallow unknown lowercase words to act as propernouns, the parser assigns incorrect structure toa number of phrases containing words such as?actin?.
Improving unknown word handling re-quires some modifications to the LG parser.6.4 Dictionary issuesCases where the LG dictionary contains a word,but not in the sense in which it appears in asentence, almost always lead to errors.
For ex-ample, the LG dictionary does not contain theword ?assembly?
in the sense ?construction?,causing the parser to erroneously require a de-terminer for ?protein assembly?4.
A relatedfrequent problem occurred with proper namesheaded by a common noun, where the parser ex-pects a determiner for such names (e.g., ?myosinheavy chain?
), and fails when one is not present.These issues are mostly straightforward to ad-dress in the grammar, but difficult to identifyautomatically.6.5 Biomedical entity namesMany of the causes for parser failure discussedabove are related to the presence of biomed-ical entity names.
While the causes for fail-ures relating to names can be addressed in thegrammar, the existence of biomedical named en-tity (NE) recognition systems (for a recent sur-vey, see, e.g., Bunescu et al (2004)) suggestsan alternative solution: NEs could be identifiedin preprocessing, and treated as single (propernoun) tokens during the parse.
During failureanalysis, 59 cases (28% of all cases) were notedwhere this procedure would have eliminated theerror, assuming that no errors are made in NE430 distinct problematic word definitions were iden-tified, including ?breakdown?, ?composed?, ?factor?,?half?, ?independent?, ?localized?, ?parallel?, ?pro-moter?, ?segment?, ?upstream?
and ?via?.recognition.
However, the performance of cur-rent NE recognition systems is not perfect, andit is not clear what the effect of adopting sucha method would be on parser performance.7 Dictionary extensionSzolovits (2003) describes an automatic methodfor mapping lexical information from one lexi-con to another, and applies this method to aug-ment the LG dictionary with terms from the ex-tensive UMLS Specialist lexicon.
The extensionintroduces more than 125,000 new words intothe LG dictionary, more than tripling its size.We evaluated the effect of this dictionary exten-sion on LG parser performance using the criteriadescribed above.
The fraction of distinct tokensin the corpus found in the parser dictionary in-creased from 52% to 72% with the dictionaryextension, representing a significant reductionin uncertainty.
This decrease was coupled witha 32% reduction in total parsing time.Because the LG parser is unable to produceany linkage for sentences where it cannot iden-tify a verb (even incorrectly), extending the dic-tionary significantly reduced the ability of LGto extract dependencies in titles, where the frac-tion of recovered dependencies fell from the al-ready low value of 67% to 55%.For the sentences excluding titles, the benefitsof the dictionary extension were most significantfor sentences that were in the panic categorywhen using the unextended LG dictionary; 12of these 28 sentences could be parsed withoutpanic with the dictionary extension.
In the firstlinkage of these sentences, the fraction of re-covered dependencies increased by 8%, and thefraction of recovered interaction subgraphs in-creased from zero to 15% with the dictionaryextension.The overall effect of the dictionary extensionwas positive but modest, with no more than2.5% improvement for either the first or bestlinkages for any criterion, despite the threefoldincrease in dictionary size.
This result agreeswith the failure analysis: most problems can-not be removed by extending the dictionary andmust instead be addressed by modifications ofthe grammar or parser.8 ConclusionWe have presented an analysis of Link Gram-mar performance using a custom dependencycorpus targeted at protein-protein interactions.We introduced the concept of the interaction20subgraph and reported parser performance forthree criteria: recovery of dependencies, in-teraction subgraphs and fully correct linkages.While LG was able to recover 73% of dependen-cies in the first linkage, only 7% of sentences hada fully correct first linkage.
However, fully cor-rect linkages are not required for information ex-traction, and we found that 25% of interactionsubgraphs were recovered in the first linkage.Resource exhaustion was found to be a signif-icant cause of poor performance.
Furthermore,an evaluation of performance in the case whenoptimal heuristics for ordering linkages are ap-plied indicated that the fraction of recovered in-teraction subgraphs could be more than doubled(to 57%) by optimal heuristics.To further analyze the cases where the parsercannot produce a correct linkage, we carefullyexamined the sentences and were able to iden-tify five problem types.
For each identifiedcase, we discussed potential modifications foraddressing the problems.
We also consideredthe possibility of using a named entity recogni-tion system to improve parser performance andfound that 28% of LG failures would be avoidedby a flawless named entity recognition system.We evaluated the effect of the dictionary ex-tension proposed by Szolovits (2003), and foundthat while it significantly reduced ambiguityand improved performance for the most ambigu-ous sentences, overall improvement was only2.5%.
This indicates that extending the dic-tionary is not sufficient to address the perfor-mance problems and that modifications to thegrammar and parser are necessary.The quantitative analysis of LG performanceconfirms that, in its current state, LG is not wellsuited to the IE task discussed.
However, in thefailure analysis we have identified a number ofspecific issues and problematic areas for LG inparsing biomedical publications, and suggestedimprovements for adapting the parser to thisdomain.
The examination and implementationof these improvements is a natural follow-up ofthis study.
Our initial experiments suggest thatit is indeed possible to implement general so-lutions to many of the discussed problems, andsuch modifications would be expected to lead toimproved applicability of LG to the biomedicaldomain.9 AcknowledgmentsThis work has been supported by Tekes, theFinnish National Technology Agency.ReferencesRazvan Bunescu, Ruifang Ge, Rohit J. Kate,Edward M. Marcotte, Raymond J. Mooney,Arun Kumar Ramani, and Yuk Wah Wong.
2004(to appear).
Comparative experiments on learn-ing information extractors for proteins and theirinteractions.
Artificial Intelligence in Medicine.Special Issue on Summarization and InformationExtraction from Medical Documents.Michael Collins, Jan Hajic, Lance Ramshaw, andChristoph Tillmann.
1999.
A statistical parserfor Czech.
In 37th Annual Meeting of the Associ-ation for Computational Linguistics, pages 505?512.
Association for Computational Linguistics,Somerset, New Jersey.Mark Craven and Johan Kumlien.
1999.
Construct-ing biological knowledge bases by extracting in-formation from text sources.
In T. Lengauer,R.
Schneider, P. Bork, D. Brutlag, J. Glasgow,H HW Mewes, and Zimmer R., editors, Proceed-ings of the 7th International Conference on Intel-ligent Systems in Molecular Biology, pages 77?86.AAAI Press, Menlo Park, CA.Nikolai Daraselia, Anton Yuryev, Sergei Egorov,Svetalana Novichkova, Alexander Nikitin, andIlya Mazo.
2004.
Extracting human protein in-teractions from MEDLINE using a full-sentenceparser.
Bioinformatics, 20(5):604?611.Jing Ding, Daniel Berleant, Jun Xu, and Andy W.Fulmer.
2003.
Extracting biochemical interac-tions from medline using a link grammar parser.In B. Werner, editor, Proceedings of the 15thIEEE International Conference on Tools with Ar-tificial Intelligence, pages 467?471.
IEEE Com-puter Society, Los Alamitos, CA.Filip Ginter, Tapio Pahikkala, Sampo Pyysalo,Jorma Boberg, Jouni Ja?rvinen, and TapioSalakoski.
2004.
Extracting protein-protein inter-action sentences by applying rough set data anal-ysis.
In S. Tsumoto, R. Slowinski, J. Komorowski,and J.W.
Grzymala-Busse, editors, Lecture Notesin Computer Science 3066.
Springer, Heidelberg.Daniel D. Sleator and Davy Temperley.
1991.
Pars-ing english with a link grammar.
Technical Re-port CMU-CS-91-196, Department of ComputerScience, Carnegie Mellon University, Pittsburgh,PA.Peter Szolovits.
2003.
Adding a medical lexicon toan english parser.
In Mark Musen, editor, Pro-ceedings of the 2003 AMIA Annual Symposium,pages 639?643.
American Medical Informatics As-sociation, Bethesda, MD.Joshua M. Temkin and Mark R. Gilder.
2003.
Ex-traction of protein interaction information fromunstructured text using a context-free grammar.Bioinformatics, 19(16):2046?2053.21
