THE USE OF A COMMERCIAL NATURAL LANGUAGEINTERFACE IN THE ATIS TASKEvelyne TzoukermannAT&T Bell Laboratories600 Mountain AvenueMurray Hill, NJ 07974AbstractA natural language interface for relational databases hasbeen utilized at AT&T Bell Laboratories as the natu-ral language component of the DARPA ATIS commontask.
This is a part of a larger project hat consists of in-corporating a natural language component into the BellLaboratories Speech Recognizer.The commercially available system used in this projectwas developed by Natural Language Incorporation(NLI), in particular by J. Ginsparg \[Ginsparg, 1976\].
Werelate our experience in adapting the NLI interface tohandle domain dependent ATIS queries.
The results ofthis allowed the exploration of several important issuesin speech and natural language:1. the feasabilitiy of using an off-the-shelf commercialproduct for a language understanding front end toa speech recognizer,2.
the constraints of using a general-purpose productfor a specific task.1 Int roduct ionThe ATIS common task was designed by DARPA andthe members of the DARPA community to build andevaluate a system capable of handling continuous andspontaneous speech recognition as well as natural an-guage understanding.
Although the evaluation task isstill not fully defined, the ATIS common task presentsthe opportunity to develop reliable and measurable crite-ria.
The present paper focuses on the natural anguagecomponent only, the integration with speech being re-ported in other papers \[Pieraccini and Levin, 1991\].
Thedomain of the task is on the Air Travel Information Ser-vice (ATIS).
The project touches on a wide range of is-sues both in natural anguage and speech recognition,including incorporation of an NL interface in speech un-derstanding, flexibility in the type of input language (i.e.spoken or written), relational databases, evaluation ofsystem performance, possible limitations, and others.The NLI system 1 is driven by a syntactic parser de-signed to handle English queries that are characteristic ofthe written language.
In contrast, ATIS syntax is charac-teristic of spoken and spontaneous language.
Therefore,one of the primary questions in using the NLI system hasbeen how to overcome problems related to the discrep-ancy between written and spoken language input.
Issuesrelated to the ATIS domain and queries on the one hand,and to the construction ofthe NLI interface on the otherhand are addressed.
The task of the experiment is thendescribed along with the results.2 Why use a commerc ia l  prod-uct?Using a commercial product is attractive for a numberof reasons:within Bell Laboratories, there has been no effort sofar to develop anatural language interface (althoughthis may change).
Therefore, it is a significant sav-ings of time and effort to use a publicly availablesystem in order to achieve the larger task, that isthe integration of speech and natural language.within the task of language understanding, the useof a natural language interface meant o understandwritten language input, exposes issues specific tospeech incorporation.3 NLI  sys tem descr ipt ionThe NLI system is composed of a series of modules, in-cluding a spelling corrector, a parser, a semantic inter-face consulting a knowledge representation base, a con-1The acronym NLI should not be confused with the suffix of thetranscription sentences ".rdi", meaning natural language input.134versation monitor, a deductive system, a database in-ference system as well as a database manager, and anEnglish language generator \[NLI Development Manual,1990\].
The components are:?
a spel l ing cor rector  which analyses morphologicalforms of the words and creates a word lattice.?
a parser  which converts the query represented bya word lattice into a grammatical structure resem-bling a sentence diagram.?
a semant ic  in ter face  which translates the parserouput into the representation language, a hybrid ofa semantic network and first-order predicate logic.This language permits representation f time depen-dencies, quantified statements, tense information,and general sets.
The representation produced bythis system component is concept-based rather thanword-based.?
a language generator  which transforms the repre-sentation language statements into an English sen-tence.?
an  in terpreter  which reasons about the represen-tation language statements and makes decisions.
Itis also called by the semantic interface to help re-solve reference, score ambiguous utterances, andperform certain noun and verb transformations.?
a database  in ter face  which translates the repre-sentation language statements into SQL databasestatements.?
a d ic t ionary  which contains over 9,000 Englishwords and their parts of speech.?
a set of  concepts  which consists of internal notionsof predicates, named objects, and statements.?
a set o f  ru les  which consists of "facts" that makeup the rule base of the system.
Rules are state-ments which are believed to be true.
The rule in-terface can handle quantification, sets, and generallogic constructs.4 Making the connectionsThe first steps in using NLI consisted of creating con-nections within the concept ables of the database andin reformatting the ATIS database into the NLI formal-ism.
This has required different ypes of operations; oneoperation consisted of taking a relation, naming whatit represents and connecting it with its properties.
Forexample, the relation "aircraft" represents plane, and at-tribute "weight" in aircraft represents the weight of theplane or how heavy or light it is with units of pounds.Another was to instantiate verb templates.
For example,verbs such as "travel", "fly", "go", etc.
must be linkedto a filler such as "from_airport" through the preposition"from".
The relation "flight" contains information aboutwhich airlines (relation "airline" via "airline_code") flyflights (relation "flight") from airports ("from_airport")to airports ("to_airport") on airplanes (relation "air-craft" via "aircraft_code") at times ("departure_time","arrival_time", "flight_day").
A third type of expansioninvolves the synonymy between two items; for example,the system must be informed that the string "transporta-tion" should be understood as "ground transportation".Connections were added incrementally in order to ex-pand the coverage.5 System performance and anal-ysis of resultsThe system has been trained on the set of training sen-tences (only the non-ambiguous sentences called "classA", i. e. about 550 sentences) recorded at Texas Instru-ments and the set of test sentences (i. e. about 100 sen-tences distributed by NIST) that were used for the June1990 DARPA task.
The last test made on the trainingsentences gave over 61% successfully answered querieswhich conformed to the Common Answer Specification(CAS) required by the NIST comparator program.
Itmust be pointed out that the translation of NLI outputanswers into the CAS format was not a straightforwardprocess.
For example, when the system could not "an-swer a query successfully, it output various expressionssuch as: Sorry, I didn't understand that.
Please checkyour spelling or phrasing, or The database contains noinformation about how expensive airports are, or I couldnot find a meaning for the noun "five", etc., so findingthe correct CAS format became guess work.
For thispurpose, a program was written by Mark Beutnagel ~at Bell Laboratories to handle the generM cases (trans-formation of the output tables into the CAS tables) butalso a number of idiosyncratic ones.The February '91 test was designed to handle differ-ent types of queries, unlike the June '90 test that hadonly class A sentences.
The queries were divided in fourcategories: class A or non-ambiguous, class AO non-ambiguous but containing some so-called verbal dele-tions (they have in fact all sorts of spoken-specific lan-guage peculiarities, such as What flights list the flights2I want to thank Mark Beutnagel for his masay hours of usefulhelp.135from Pittsburgh to San Francisco?
), class D for dialog-sentences where queries are presented by pairs (one mem-ber of the pair indicating the context of the sentence, theother member being the query itself), and class DO fordialog sentences with verbal deletions.
At the time ofthe experiment, although NLI could handle queries withanaphoric pronouns across sentences such as in the pairShow the flights from Atlanta to Baltimore.
When dothey leave?, the connection file had not been shaped inthat direction.
The system was trained only to han-dle the class A queries.
Answers to the four categorieswere run and sent, but only the class A results are ofreal interest and relevant.
The following table shows theresults of the four sets of sentences.
The queries wereevaluated in three different categories, "T" for "True","F" for "False" and "NA" for "No_Answer":CLASS CLASS CLASS CLASSA AO D DOT 69 2 17 0F 60 8 18 2NA 16 1 3 06 Error analysisThe first obstacle encountered in utilizing NLI was thenature of the input queries.
The ATIS task is meant tounderstand spoken and spontaneous language whereasNLI is built to understand written type of language.There are a number of discrepancies between spoken andwritten language that involve a different parsing strat-egy; spontaneous speech contains various kinds of:* repet i t ions  uch as through through in the sentencePlease show me all the flights from DFW to Balti-more that go through through Atlanta;?
res tar ts  as shown in the query What flights list theflights from Pittsburgh to San Francisco;?
de let ions  such as the missing word Francisco inDisplay ground transportation options from Oaklandto San downtown San Francisco;?
i n ter jec t ions  with the use of the word Okay inOkay I'd like to see a listing of all flights available...;?
ell ipsis such as in the third phrase I'm sorry cancelthat flight.
The passenger wants to fly on Delta.How about Delta 870 on the 12th?
;Note that in this format, the punctuation marks whichmight give the system information do not occur.There are a number of explanations for the unan-swered sentences:Lexical gaps: if a lexical item is not in the lexicon,no analysis is given.
The problem in lexical gaps ispartly due to the domain specific vocabulary of theATIS task.
In the following example I need flightschedule information from Denver to Philadelphia,the system does not have the word schedule in thelexicon; therefore the sentence is rejected.The informal addition of information is common tospoken language, more than written language.
Forexample, in the following sentence, the speaker addsinformation in what is almost telegraphic speech:Cost of a first class ticket Dallas to San Franciscodeparting August the 6th.Absence of additional connections: in sentences likethe following, the system cannot answer because ar-rival times are related to the flight relation and notto the fare ones in the relational database: On farecode 7100325 list your arrival times from Dallas toSan Francisco on August l~th.?
System incompletness at the time of the test:in the sentence Is there a flight from Den-ver through Dallas Fort Worth to Philadelphia?the connection was established to handle afrom-to relation, but not a through relation.length of the sentences such as Display lowestprice fare available from Dallas to Oakland orDallas to San Francisco and include the flightnumbers on which these options are available.This is a common problem in many NL sys-tems.Other sentences remain unanswered ue either to somecontradictory meanings in the lexical items of the queriesor to the design of the database.7 conclusionIt is important o note that the commercial system waspartially adapted in a reasonable amount of time.
Nev-ertheless, the overall system has not reached a fully sat-isfactory level of performance due to various factors:?
NLI was developed to handle "well-formed" writtenEnglish so its performance is expectably poor forprocessing spoken and spontaneous queries.136?
too small an amount of data was used to train thesystem.
It would be profitable to use a larger andbroader amount of training data, such as that avail-able at SRI, CMU, and MIT.?
More time needs to be spent on refining the databaseconnections and concepts.The system in its current state is not yet fully opera-tional.
We are in the process of improving its perfor-mance.
The focus of this paper is to point out the ques-tions that a natural anguage interface (here the NLI sys-tem) faces in tackling spoken language.
The interest forBell laboratories i in the integration of speech and nat-ural language.
This is a difficult problem; in the contextof the current architecture of the speech recognizer, themain question consists of processing the output of therecognizer to avoid too many multiple choices as inputinto the NLI component.References\[1\]\[21\[3\]\[4\]\[5\]\[6\]Bates, M., S Boisen and J. Makhoul, "Develop-ping an Evaluation Methodology for Spoken Lan-guage Systems", Proe.
DARPA Speech and Natu-ral Language Workshop, 102-108, Hidden Valley,Pennsylvannia, June 1990.Bates, M., R. Robrow, S Boisen, R. Ingria, D.Stallard, "BBN ATIS System Progress Report- June 1990", Proc.
DARPA Speech and Natu-ral Language Workshop, 125-126, Hidden Valley,Pennsylvannia, June 1990.Bly B., P. J.
Price, S. Park, S. Tepper, E. Jackson,V.
Abrash, "Designing the Human Machine Inter-face in the ATIS Domain", Proc.
DARPA Speechand Natural Language Workshop, 136-140, Hid-den Valley, Pennsylvannia, June 1990.Ginsparg, J. M. Natural Language Processing inan Automatic Programming Domain, Ph.D. Dis-sertation, Stanford University, California, 1976.Hirschman, L., D. A. Dalh, D. P. McKay, L.M.Norton and M. C. Linebarger, "Beyond ClassA: A Proposal for Automatic Evaluation of Dis-course", Proc.
DARPA Speech and Natural Lan.guage Workshop, 109-113, Hidden Valley, Penn-sylvannia, June 1990.Moore R., D. Appelt, J.
Bear, M Darymple, andD.
Moran, "SRI's Experience with the ATIS Eval-uation", Proc.
DARPA Speech and Natural Lan-guage Workshop, 147-150, Hidden Valley, Penn-sylvannia, June 1990.\['r\]\[8\]\[9\]\[101\[11\]\[12\]NLI Reference Manual, Natural Language Incor-porated, Berkeley, California, 1990.NLI Developer's Reference, Natural Language In-corporated, Berkeley, California, 1990.Norton L. M., D. A. Dalh, D. P. McKay, L.Hirschman, M. C. Linebarger, D. Magerman, andC.
N. Ball, "Management and Evaluation of In-teractive Dialog in the Air Travel Domain", Proc.DARPA Speech and Natural Language Workshop,141-146, Hidden Valley, Pennsylvannia, June1990.Pieraccini R., E. Levin, and C. H. Lee, "Stochas-tic representation of conceptual structure in theATIS task", Proc.
DARPA Speech and NaturalLanguage Workshop, Asilomar, California, June1991.Ward W., "The CMU Air Travel Information Ser-vice: Understanding Spontaneous Speech", Proe.DARPA Speech and Natural Language Workshop,127-129, Hidden Valley, Pennsylvannia, June1990.Zue, V., J.
Glass, D. Goodine, H. Leung, M.Phillips, J. Polifroni and S. Seneff, "Prelimi-nary ATIS Development at MIT", Proc.
DARPASpeech and Natural Language Workshop, 130-135,Hidden Valley, Pennsylvannia, June 1990.137
