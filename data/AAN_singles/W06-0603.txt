Proceedings of the Workshop on Frontiers in Linguistically Annotated Corpora 2006, pages 13?20,Sydney, July 2006. c?2006 Association for Computational LinguisticsHow and Where do People Fail with Time: Temporal Reference MappingAnnotation by Chinese and English BilingualsYang Ye?, Steven Abney??
?Department of Linguistics?Department of Electrical Engineering and Computer ScienceUniversity of MichiganAbstractThis work reports on three human tenseannotation experiments for Chinese verbsin Chinese-to-English translation scenar-ios.
The results show that inter-annotatoragreement increases as the context of theverb under the annotation becomes in-creasingly specified, i.e.
as the contextmoves from the situation in which the tar-get English sentence is unknown to thesituation in which the target lexicon andtarget syntactic structure are fully speci-fied.
The annotation scheme with a fullyspecified syntax and lexicon in the tar-get English sentence yields a satisfactorilyhigh agreement rate.
The annotation re-sults were then analyzed via an ANOVAanalysis, a logistic regression model and alog-linear model.
The analyses reveal thatwhile both the overt and the latent linguis-tic factors seem to significantly affect an-notation agreement under different scenar-ios, the latent features are the real drivingfactors of tense annotation disagreementamong multiple annotators.
The analy-ses also find the verb telicity feature, as-pect marker presence and syntactic em-bedding structure to be strongly associatedwith tense, suggesting their utility in theautomatic tense classification task.1 IntroductionIn recent years, the research community has seena fast-growing volume of work in temporal infor-mation processing.
Consequently, the investiga-tion and practice of temporal information anno-tation by human experts have emerged from thecorpus annotation research.
To evaluate automatictemporal relation classification systems, annotatedcorpora must be created and validated, which mo-tivates experiments and research in temporal infor-mation annotation.One important temporal relation distinction thathuman beings make is the temporal reference dis-tinction based on relative positioning between thefollowing three time parameters, as proposed by(Reichenbach, 1947): speech time (S), event time(E) and reference time (R).
Temporal referencedistinction is linguistically realized as tenses.
Lan-guages have various granularities of tense repre-sentations; some have finer-grained tenses or as-pects than others.
This poses a great challenge toautomatic cross-lingual tense mapping.
The samechallenge holds for cross-lingual tense annotation,especially for language pairs that have dramati-cally different tense strategies.
A decent solutionfor cross-lingual tense mapping will benefit a va-riety of NLP tasks such as Machine Translation,Cross-lingual Question Answering (CLQA), andMulti-lingual Information Summarization.
Whileautomatic cross-lingual tense mapping has re-cently started to receive research attention, suchas in (Olsen,et al, 2001) and (Ye, et al, 2005),to the best of our knowledge, human performanceon tense and aspect annotation for machine trans-lation between English and Chinese has not re-ceived any systematic investigation to date.
Cross-linguistic NLP tasks, especially those requiring amore accurate tense and aspect resolution, awaita more focused study of human tense and aspectannotation performance.Chinese and English are a language pair inwhich tense and aspect are represented at differ-ent levels of units: one being realized at the wordlevel and the other at the morpheme level.This paper reports on a series of cross-linguistictense annotation experiments between Chineseand English, and provides statistical inference fordifferent linguistic factors via a series of statisti-cal modeling.
Since tense and aspect are mor-phologically merged in English, tense annotation13discussed in this paper also includes elements ofaspect.
We only deal with tense annotation inChinese-to-English scenario in the scope of thispaper.The remaining part of the paper is organizedas follows: Section 2 summarizes the significantrelated works in temporal information annotationand points out how this study relates to yet differsfrom them.
Section 3 reports the details of threetense annotation experiments under three scenar-ios.
Section 4 discusses the inter-judge agree-ment by presenting two measures of agreement:the Kappa Statistic and accuracy-based measure-ment.
Section 5 investigates and reports on thesignificance of different linguistic factors in tenseannotation via an ANOVA analysis, a logistic re-gression analysis and a log-linear model analysis.Finally, section 6 concludes the paper and pointsout directions for future research.2 Related WorkThere are two basic types of temporal location re-lationships.
The first one is the ternary classifica-tion of past, present and future.
The second oneis the binary classification of ?BEFORE?
versus?AFTER?.
These two types of temporal relation-ships are intrinsically related but each stands as aseparate issue and is dealt with in different works.While the ?BEFORE?
versus ?AFTER?
relation-ship can easily be transferred across a languagepair, the ternary tense taxonomy is often very hardto transfer from one language to another.
(Wilson, et al, 1997) describes a multilin-gual approach to annotating temporal information,which involves flagging a temporal expression inthe document and identifying the time value thatthe expression designates.
Their work reports aninter-annotator reliability F-measure of 0.79 and0.86 respectively for English corpora.
(Katz, et al, 2001) describes a simple and gen-eral technique for the annotation of temporal rela-tion information based on binary interval relationtypes: precedence and inclusion.
Their annotationscheme could benefit a range of NLP applicationsand is easy to carry out.
(Pustejovsky et al, 2004) reports an annotationscheme, the TimeML metadata, for the markup ofevents and their anchoring in documents.
The an-notation schema of TimeML is very fine-grainedwith a wide coverage of different event types, de-pendencies between events and times, as well as?LINK?
tags which encode the various relationsexisting between the temporal elements of a doc-ument.
The challenge of human labeling of linksamong eventualities was discussed at great lengthin their paper.
Automatic ?time-stamping?
wasattempted on a small sample of text in an earlierwork of (Mani, 2003).
The result was not partic-ularly promising.
It showed the need for a largerquantity of training data as well as more predictivefeatures, especially on the discourse level.
At theword level, the semantic representation of tensescould be approached in various ways dependingon different applications.
So far, their work hasgone the furthest towards establishing a broad andopen standard metadata mark-up language for nat-ural language texts.
(Setzer, et al, 2004) presents a method of eval-uating temporal order relation annotations and anapproach to facilitate the creation of a gold stan-dard by introducing the notion of temporal clo-sure, which can be deduced from any annotationsthrough using a set of inference rules.From the above works, it can be seen that theeffort in temporal information annotation has thusfar been dominated by annotating temporal rela-tions that hold entities such as events or timesexplicitly mentioned in the text.
Cross-linguistictense and aspect annotation has so far gone un-studied.3 Chinese Tense AnnotationExperiments1In current section, we present three tense annota-tion experiments with the following scenarios:1.
Null-control situation by native Chinesespeakers where the annotators were providedwith the source Chinese sentences but not theEnglish translations;2.
High-control situation by native Englishspeakers where the annotators were providedwith the Chinese sentences as well as Englishtranslations with specified syntax and lexi-cons;3.
Semi-control situation by native Englishspeakers where the annotators were allowedto choose the syntax and lexicons for the En-glish sentence with appropriate tenses;1All experiments in the paper are approved by Behav-ioral Sciences Institutional Review Board at the Universityof Michigan, the IRB file number is B04-00007481-I.143.1 Experiment OneExperiment One presents the first scenario oftense annotation for Chinese verbs in Chinese-to-English cross-lingual situation.
In the first sce-nario, the annotation experiment was carried outon 25 news articles from LDC Xinhua News re-lease with category number LDC2001T11.
The ar-ticles were divided into 5 groups with 5 articles ineach group.
There are a total number of 985 verbs.For each group, three native Chinese speakers whowere bilingual in Chinese and English annotatedthe tense of the verbs in the articles independently.Prior to annotating the data, the annotators under-went brief training during which they were askedto read an example of a Chinese sentence for eachtense and make sure they understand the exam-ples.
During the annotation, the annotators wereasked to read the whole articles first and then se-lect a tense tag based on the context of each verb.The tense taxonomy provided to the annotators in-clude the twelve tenses that are different combi-nations of the simple tenses (present, past and fu-ture), the prograssive aspect and the perfect aspect.In cases where the judges were unable to decidethe tense of a verb, they were instructed to tag itas ?unknown?.
In this experiment, the annotatorswere asked to tag the tense for all Chinese wordsthat were tagged as verbs in the Penn Treebankcorpora.
Conceivably, the task under the currentscenario is meta-linguistic in nature for the reasonthat tense is an elusive notion for Chinese speak-ers.
Nevertheless, the experiment provides a base-line situation for human tense annotation agree-ment.
The following is an example of the anno-tation where the annotators were to choose an ap-propriate tense tag from the provided tense tags:((IP (NP-TPC (NP-PN (NR ??
))(NP (NN ??)(NN??
)))(LCP-TMP (NP (NT ??))(LC?))
(NP-SBJ (NP (PP (P ?
)(NP (NN ?
)))(NP (NN ??
)))(NP (NN ??
)))(VP (ADVP (AD ???))
(VP (VV??)))(PU?))
)1. simple present tense2.
simple past tense3.
simple future tense4.
present perfect tense5.
past perfect tense6.
future perfect tense7.
present progressive tense8.
past progressive tense9.
future progressive10.
present perfect progressive11.
past perfect progressive3.2 Experiment TwoExperiment Two was carried out using 25 newsarticles from the parallel Chinese and Englishnews articles available from LDC Multiple Trans-lation Chinese corpora (MTC catalog numberLDC2002T01).
In the previous experiment, theannotators tagged all verbs.
In the current experi-mental set-up, we preprocessed the materials andremoved those verbs that lose their verbal status intranslation from Chinese to English due to nom-inalization.
After this preprocessing, there wasa total of 288 verbs annotated by the annotators.Three native speakers, who were bilingually fluentin English and Chinese, were recruited to annotatethe tense for the English verbs that were translatedfrom Chinese.
As in the previous scenario, the an-notators were encouraged to pay attention to thecontext of the target verb when tagging its tense.The annotators were provided with the full taxon-omy illustrated by examples of English verbs andthey worked independently.
The following is anexample of the annotation where the annotatorswere to choose an appropriate tense tag from theprovided tense tags:?????????????????????????????????????????
?According to statistics, the cities (achieve) a combined gross domestic product of RMB19billion last year, an increase of more than 90% over 1991 before their opening.A.
achievesB.
achievedC.
will achieveD.
are achievingE.
were achievingF.
will be achievingG.
have achievedH.
had achievedI.
will have achievedJ.
have been achievingK.
had been achievingL.
will have been achievingM.
would achieve3.3 Experiment ThreeExperiment Three was an experiment simulatedon 52 Xinhua news articles from the MultipleTranslation Corpus (MTC) mentioned in the pre-vious section.
Since in the MTC corpora, eachChinese article is translated into English by tenhuman translation teams, conceptually, we couldview these ten translation teams as different an-notators.
They were making decisions about ap-propriate tense for the English verbs.
These an-notators differ from those in Experiment Two de-scribed above in that they were allowed to chooseany syntactic structure and verb lexicon.
This isbecause they were performing tense annotation ina bigger task of sentence translation.
Therefore,their tense annotations were performed with muchless specification of the annotation context.
Wemanually aligned the Chinese verbs with the En-glish verbs for the 10 translation teams from theMTC corpora and thus obtained our third sourceof tense annotation results.
For the Chinese verbs15that were not translated as verbs into English, weassigned a ?Not Available?
tag.
There are 1505verbs in total including the ones that lost their ver-bal status across the language.4 Inter-Judge AgreementResearchers use consistency checking to validatehuman annotation experiments.
There are vari-ous ways of performing consistency checking de-scribed in the literature, depending on the scale ofthe measurements.
Each has its advantages anddisadvantages.
Since our tense taxonomy is nomi-nal without any ordinal information, Kappa statis-tics measurement is the most appropriate choice tomeasure inter-judge agreement.4.1 Kappa StatisticKappa scores were calculated for the three humanjudges?
annotation results.
The Kappa score is thede facto standard for evaluating inter-judge agree-ment on tagging tasks.
It reports the agreementrate among multiple annotators while correctingfor the agreement brought about by pure chance.It is defined by the following formula, where P(A)is the observed agreement among the judges andP(E) is the expected agreement:k =P (A)?
P (E)1?
P (E)(1)Depending on how one identifies the expectedagreement brought about by pure chance, there aretwo ways to calculate the Kappa score.
One is the?Seigel-Castellian?
Kappa discussed in (Eugenio,2004), which assumes that there is one hypotheti-cal distribution of labels for all judges.
In contrast,the ?Cohen?
Kappa discussed in (Cohen, 1960),assumes that each annotator has an individual dis-tribution of labels.
This discrepancy slightly af-fects the calculation of P(E).
There is no consen-sus regarding which Kappa is the ?right?
one andresearchers use both.
In our experiments, we usethe ?Seigel-Castellian?
Kappa.The Kappa statistic for the annotation results ofExperiment One are 0.277 on the full taxonomyand 0.37 if we collapse the tenses into three bigclasses: present, past and future.
The observedagreement rate,that is, P(A), is 0.42.The Kappa score for tense resolution from theten human translation teams for the 52 Xinhuanews articles is 0.585 on the full taxonomy; weexpect the Kappa score to be higher if we excludethe verbs that are nominalized.
Interestingly, theKappa score calculated by collapsing the 13 tensesinto 3 tenses (present, past and future) is onlyslightly higher: 0.595.
The observed agreementrate is 0.72.Human tense annotation in the Chinese-to-English restricted translation scenario achieved aKappa score of 0.723 on the full taxonomy with anobserved agreement of 0.798.
If we collapse sim-ple past and present perfect, the Kappa score goesup to 0.792 with an observed agreement of 0.893.The Kappa score is 0.81 on the reduced taxonomy.4.2 AccuracyThe Kappa score is a relatively conservative mea-surement of the inter-judge agreement rate.
Con-ceptually, we could also obtain an alternative mea-surement of reliability by taking one annotator asthe gold standard at one time and averaging overthe accuracies of the different annotators acrossdifferent gold standards.
While it is true that nu-merically, this would yield a higher score than theKappa score and seems to be inflating the agree-ment rate, we argue that the difference betweenthe Kappa score and the accuracy-based measure-ment is not limited to one being more aggressivethan the other.
The policies of these two mea-surements are different.
The Kappa score is con-cerned purely with agreement without any consid-eration of truthfulness or falsehood, while the pro-cedure we described above gives equal weights toeach annotator being the gold standard.
Therefore,it considers both the agreement and the truthful-ness of the annotation.
Additionally, the accuracy-based measurement is the same measurement thatis typically used to evaluate machine performance;therefore it gives a genuine ceiling for machineperformance.The accuracy under such a scheme for the threeannotators in Experiment One is 43% on the fulltense taxonomy.The accuracy under such a scheme for tensegeneration agreement from three annotators in Ex-periment Two is 80% on the full tense taxonomy.The accuracy under such a scheme for the tentranslation teams in Experiment Three is 70.8% onthe full tense taxonomy.Table 1 summarizes the inter-judge agreementfor the three experiments.Examining the annotation results, we identifiedthe following sources of disagreement.
While the16Agreement Exp 1 Exp 2 Exp 3Kappa Statistic 0.277 0.723 0.585Kappa Statistic 0.37 0.81 0.595(Reduced Taxonomy)Accuracy 43% 80% 70.8%Table 1: Inter-Annotator Agreement for the ThreeTense Annotation Experimentsfirst two factors can be controlled for by a clearlypre-defined annotation guideline, the last two fac-tors are intrinsically rooted in natural languagesand therefore hard to deal with:1.
Different compliance with Sequence of Tense(SOT) principle among annotators;2.
?Headline Effect?;3.
Ambiguous POS of the ?verb?
: sometimes itis not clear whether a verb is adjective or pastparticiple.
e.g.
The Fenglingdu EconomicDevelopment Zone is the only one in Chinathat is/was built on the basis of a small town.4.
Ambiguous aspectual property of the verb:the annotator?s view with respect to whetheror not the verb is an atelic verb or a telic verb.e.g.
?statistics showed/show......?Put abstractly, ambiguity is an intrinsic propertyof natural languages.
A taxonomy allows us toinvestigate the research problem, yet any clearlydefined discrete taxonomy will inevitably fail onboundary cases between different classes.5 Significance of Linguistic Factors inAnnotationIn the NLP community, researchers carry out an-notation experiments mainly to acquire a goldstandard data set for evaluation.
Little effort hasbeen made beyond the scope of agreement ratecalculations.
We propose that not only does fea-ture analysis for annotation experiments fall un-der the concern of psycholinguists, it also meritsinvestigation within the enterprise of natural lan-guage processing.
There are at least two waysthat the analysis of annotation results can helpthe NLP task besides just providing a gold stan-dard: identifying certain features that are respon-sible for the inter-judge disagreement and model-ing the situation of associations among the differ-ent features.
The former attempts to answer theFigure 1: Interaction between Aspect Marker andTemporal Modifierquestion of where the challenge for human classi-fication comes from, and thereby provides an ex-ternal reference for an automatic NLP system, al-though not necessarily in a direct way.
The lattersheds light on the structures hidden among groupsof features, the identification of which could pro-vide insights for feature selection as well as of-fer convergent evidence for the significance of cer-tain features confirmed from classification practicebased on machine learning.In this section, we discuss at some length a fea-ture analysis for the results of each of the anno-tation experiments discussed in the previous sec-tions and summarize the findings.5.1 ANOVA analysis of Agreement andLinguistic Factors in Free TranslationTense AnnotationThis analysis tries to find the relationship be-tween the linguistic properties of the verb and thetense annotation agreement across the ten differenttranslation teams in Experiment Three.
Specifi-cally, we use an ANOVA analysis to explore howthe overall variance in the inconsistency of thetenses of a particular verb with respect to differ-ent translation teams can be attributed to differentlinguistic properties associated with the Chineseverb.
It is a three-way ANOVA with three linguis-tic factors under investigation: whether the sen-tence contains a temporal modifier or not; whetherthe verb is embedded in a relative clause, a senten-tial complement, an appositive clause or none ofthe above; and whether the verb is followed by as-pect markers or not.
The dependent variable is theinconsistency of the tenses from the teams.
The17inconsistency rate is measured by the ratio of thenumber of distinct tenses over the number of tensetokens from the ten translation teams.Our ANOVA analysis shows that all of the threemain effects, i.e.
the embedding structures of theverb (p  0.001), the presence of aspect markers(p  0.01), and the presence of temporal mod-ifiers (p < 0.05) significantly affect the rate ofdisagreement in tense generation among the dif-ferent translation teams.
The following graphsshow the trend: tense generation disagreementrates are consistently lower when the Chinese as-pect marker is present, whether there is a temporalmodifier present or not (Figure 1).
The model alsosuggested that the presence of temporal modifiersis associated with a lower rate of disagreementfor three embedding structures except for verbs insentential complements (Figure 2, 0: the verb isnot in any embedding structures; 1: the verb isembedded in a relative clause; 2: the verb is em-bedded in an appositive clause; 3: the verb is em-bedded in sentential complement).
Our explana-tion for this is that the annotators receive varyingdegrees of prescriptive writing training, so whenthere is a temporal modifier in the sentence as aconfounder, there will be a larger number, a higherincidence of SOT violations than when there isno temporal modifier present in the sentence.
Ontop of this, the rate of disagreement in tense tag-ging between the case where a temporal modifieris present in the sentence and the case where it isnot depends on different types of embedding struc-tures (Figure 2, p value < 0.05).We also note that the relative clause embed-ding structure is associated with a much higherdisagreement rate than any other embedding struc-tures (Figure 3).5.2 Logistic Regression Analysis ofAgreement and Linguistic Factors inRestricted Tense AnnotationThe ANOVA analysis in the previous section isconcerned with the confounding power of theovert linguistic features.
The current section ex-amines the significance of the more latent fea-tures on tense annotation agreement when the SOTeffect is removed by providing the annotators aclear guideline about the SOT principle.
Specif-ically, we are interested in the effect of verb telic-ity and punctuality features on tense annotationagreement.
The telicity and punctuality featuresFigure 2: Interaction between the Temporal Mod-ifier and the Syntactic Embedding Structurewere obtained through manual annotation basedon the situation in the context.
The data are fromExperiment Two.
Since there are only three an-notators, the inconsistency rate we discussed in5.1 would have insufficient variance in the currentscenario, making logistic regression a more appro-priate analysis.
The response is now binary beingeither agreement or disagreement (including par-tial agreement and pure disagreement).
To avoid amulti-colinearity problem, we model Chinese fea-tures and English features separately.
In orderto truly investigate the effects of the latent fea-tures, we keep the overt linguistic features in themodel as well.
The overt features include: type ofsyntactic embedding, presence of aspect marker,presence of temporal expression in the sentence,whether the verb is in a headline or not, and thepresence of certain signal adverbs including ?yi-jing?
(already), ?zhengzai?
(Chinese pre-verb pro-gressive marker), ?jiang?
(Chinese pre-verbal ad-verb indicating future tense).
We used backwardelimination to obtain the final model.The result showed that punctuality is the onlyfactor that significantly affects the agreement rateamong multiple judges in both the model of En-glish features and the model of Chinese features.The significance level is higher for the punctualityof English verbs, suggesting that the source lan-guage environment is more relevant in tense gener-ation.
The annotators are roughly four times morelikely to fail to agree on the tense for verbs as-sociated with an interval event.
This supports thehypothesis that human beings use the latent fea-tures for tense classification tasks.
Surprisingly,the telicity feature is not significant at all.
We sus-18Figure 3: Effect of Syntactic Embedding Structureon Tense Annotation Disagreementpect this is partly due to the correlation betweenthe punctuality feature and the telicity feature.
Ad-ditionally, none of the overt linguistic features issignificant in the presence of the latent features,which implies that the latent features drive dis-agreement among multiple annotators.5.3 Log-linear Model Analysis ofAssociations between Linguistic Factorsin Free Translation Tense AnnotationThis section discusses the association patterns be-tween tense and the relevant linguistic factors viaa log-linear model.
A log-linear model is a specialcase of generalized linear models (GLMs) and hasbeen widely applied in many fields of social sci-ence research for multivariate analysis of categor-ical data.
The model reveals the interaction be-tween categorical variables.
The log-linear modelis different from other GLMs in that it does notdistinguish between ?response?
and ?explanatoryvariables?.
All variables are treated alike as ?re-sponse variables?, whose mutual associations areexplored.
Under the log-linear model, the ex-pected cell frequencies are functions of all vari-ables in the model.
The most parsimonious modelthat produces the smallest discrepancy betweenthe expected cell and the observed cell frequen-cies is chosen as the final model.
This providesthe best explanation of the observed relationshipsamong variables.We use the data from Experiment Two for thecurrent analysis.
The results show that three lin-guistic features under investigation are signifi-cantly associated with tense.
First, there is a strongassociation between aspect marker presence andtense, independent of punctuality, telicity featureand embedding structure.
Second, there is a strongassociation between telicity and tense, indepen-dent of punctuality, aspect marker presence andpunctuality feature.
Thirdly, there is a strong as-sociation between embedding structure and tense,independent of telicity, punctuality feature and as-pect marker presence.
This result is consistentwith (Olsen, 2001), in that the lexical telicity fea-ture, when used heuristically as the single knowl-edge source, can achieve a good prediction of verbtense in Chinese to English Machine Translation.For example, the odds of the verb being atelic inthe past tense is 2.5 times the odds of the verbbeing atelic in the future tense, with a 95% con-fidence interval of (0.9, 7.2).
And the odds of averb in the future tense having an aspect markerapproaches zero when compared to the odds of averb in the past tense having an aspect marker.Putting together the pieces from the logisticanalysis and the current analysis, we see that an-notators fail to agree on tense selection mostlywith apunctual verbs, while the agreed-upon tenseis jointly decided by the telicity feature, aspectmarker feature and the syntactic embedding struc-ture that are associated with the verb.6 Conclusions and Future WorkAs the initial attempt to assess human beings?cross-lingual tense annotation, the current papercarries out a series of tense annotation experi-ments between Chinese and English under differ-ent scenarios.
We show that even if tense is anabstract grammatical category, multiple annotatorsare still able to achieve a good agreement ratewhen the target English context is fully specified.We also show that in a non-restricted scenario,the overt linguistic features (aspect markers, em-bedding structures and temporal modifiers), cancause people to fail to agree with each other signif-icantly in tense annotation.
These factors exhibitcertain interaction patterns in the decision mak-ing of the annotators.
Our analysis of the anno-tation results from the scenario with a fully speci-fied context show that people tend to fail to agreewith each other on tense for verbs associated withinterval events.
The disagreement seems not tobe driven by the overt linguistic features such asembedding structure and aspect markers.
Lastly,among a set of overt and latent linguistic features,aspect marker presence, embedding structure and19the telicity feature exhibit the strongest associationwith tense, potentially indicating their high utilityin tense classification task.The current analysis, while suggesting certaininteresting patterns in tense annotation, could bemore significant if the findings could be replicatedby experiments of different scales on different datasets.
Furthermore, the statistical analysis could bemore finely geared to capture the more subtle dis-tinctions encoded in the features.AcknowledgementAll of the annotation exper-iments in this paper are funded by Rackham Grad-uate School?s Discretionary Funds at the Univer-sity of Michigan.ReferencesHans Reichenbach,1947.
Elements of Symbolic Logic,Macmillan, New York, N.Y.Mari Olson, David Traum, Carol Van Ess-Dykema,and AmyWeinberg, 2001.
Implicit Cues for ExplicitGeneration: Using Telicity as a Cue for Tense Struc-ture in a Chinese to English MT System, Proceed-ings Machine Translation Summit VIII, Santiago deCompostela, Spain.Yang Ye, Zhu Zhang, 2005.
Tense Tagging for Verbsin Cross-Lingual Context: A Case Study.
Proceed-ings of 2nd International Joint Conference in NaturalLanguage Processing (IJCNLP), 885-895.George Wilson, Inderjeet Mani, Beth Sundheim, andLisa Ferro, 2001.
A Multilingual Approach to An-notating and Extracting Temporal Information, Pro-ceedings of the ACL 2001 Workshop on TemporalAnd Spatial Information Processing, 39th AnnualMeeting of ACL, Toulouse, 81-87.Graham Katz and Fabrizio Arosio, 2001.
The Annota-tion of Temporal Information in Natural LanguageSentences, Proceedings of the ACL 2001 Workshopon Temporal And Spatial Information Processing,39th Annual Meeting of ACL, Toulouse, 104-111.James Pustejovsky, Robert Ingria, Roser Sauri, JoseCastano, Jessica Littman, Rob Gaizauskas, AndreaSetzer, Graham Katz, and Inderjeet Mani.
2004.
TheSpecification Language TimeML.
The Language ofTime: A Reader.
Oxford, 185-96.Barbara Di Eugenio and Michael Glass.
2004.
Thekappa statistic: A second look.
Computational Lin-guistics, 30(1): 95-101.Inderjeet Mani, 2003.
Recent Developments in Tem-poral Information Extraction.
In Nicolov, N. andMitkov, R., editors, Proceedings of RANLP?03.John Benjamins.Andrea Setzer, Robert Gaizauskas, and Mark Hep-ple, 2003.
Using Semantic Inferences for Tem-poral Annotation Comparison, Proceedings of theFourth International Workshop on Inference inComputational Semantics (ICOS-4), INRIA, Lor-raine, Nancy, France, September 25-26, 185-96.Jacob Cohen, 1960.
A Coefficient of Agreement forNominal Scales, Educational and PsychologicalMeasurement, 20, 37-46.20
