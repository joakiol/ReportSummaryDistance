Proceedings of the NAACL HLT Workshop on Software Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 14?21,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsUsing Paraphrases of Deep Semantic Representionsto Support Regression Testing in Spoken Dialogue SystemsBeth Ann HockeyUC Santa Cruz and BAHRC LLCMail Stop 19-26, UCSC UARCNASA Ames Research Center, Moffett Field, CA 94035?1000bahockey@bahrc.netManny RaynerUniversity of Geneva, TIM/ISSCO40 bvd du Pont-d?Arve, CH-1211 Geneva 4, SwitzerlandEmmanuel.Rayner@unige.chAbstractRule-based spoken dialogue systems requirea good regression testing framework if theyare to be maintainable.
We argue that thereis a tension between two extreme positionswhen constructing the database of test exam-ples.
On the one hand, if the examples con-sist of input/output tuples representing manylevels of internal processing, they are fine-grained enough to catch most processing er-rors, but unstable under most system modi-fications.
If the examples are pairs of userinput and final system output, they are muchmore stable, but too coarse-grained to catchmany errors.
In either case, there are fairlysevere difficulties in judging examples cor-rectly.
We claim that a good compromise canbe reached by implementing a paraphrasingmechanism which maps internal semantic rep-resentations into surface forms, and carryingout regression testing using paraphrases of se-mantic forms rather than the semantic formsthemselves.
We describe an implementationof the idea using the Open Source Regulustoolkit, where paraphrases are produced us-ing Regulus grammars compiled in generationmode.
Paraphrases can also be used at run-time to produce confirmations.
By compilingthe paraphrase grammar a second time, as arecogniser, it is possible in a simple and nat-ural way to guarantee that confirmations arealways within system coverage.1 IntroductionDesign features that enable important functionalityin medium vocabulary, mixed-initiative spoken dia-logue systems also create challenges for the projectcycle, and in particular for regression testing.
Twoissues that make regression testing particularly dif-ficult are the need for context dependent interpre-tation, and the use of multiple levels of representa-tion.
Both of these features are typically necessaryfor non-trivial dialogue systems of this type.
Mul-tiple levels of processing, as usual, provide neces-sary modularity.
Context dependent interpretationenables responses that are tuned to the current cir-cumstances of the interaction or the world, and fre-quently helps resolve ambiguity.The implications for regression testing, though,are less happy.
The context of each interaction inthe test suite needs to be stored as part of the inter-action.
Multiple levels of representation that are, forexample, useful for doing ellipsis resolution or ref-erence resolution, also complicate testing.
If regres-sion testing is done on each separate level of pro-cessing, or involves internal representations, smallchanges to a representation at one level can meanhaving to revise and rejudge the entire test suite tokeep it up to date.This paper discusses the methodology we havedeveloped to address regression testing issues withinthe Regulus framework.
Regulus (Rayner et al,2006) is an Open Source toolkit for builting medium14vocabulary spoken dialogue and translation appli-cations, and has been used to build a number ofnon-trivial spoken dialogue systems.
Prominent ex-amples include NASA?s Clarissa Procedure Navi-gator (Rayner et al, 2005), Geneva University?smulti-modal mobile-platform Calendar application(Tsourakis et al, 2008), SDS, a prototype in-car sys-tem developed by UC Santa Cruz in collaborationwith Ford Motors Research which was voted firstin Ford?s 2007 internal technology fair, and Taxi,a speech-enabled game in which the user interactswith a simulated cab driver to navigate around a mapof Manhattan.
It has also been used to build theMedSLT medical speech translation system (Bouil-lon et al, 2008).The Regulus platform includes tools for develop-ing feature grammars, and compiling them in var-ious ways.
In particular, it is possible to compilegrammars into generators, and use them to supportparaphrasing from the internal semantic representa-tions created during dialogue processing.
This ca-pability is key to the newest part of our regressiontesting approach, and is discussed in detail in Sec-tion 3.
First, though, Section 2 gives an overview ofRegulus and the architecture of Regulus-based sys-tems; we discuss features that complicate regressiontesting, and how to address these problems withinthis type of architecture.
Section 4 discusses howtest suites are constructed and what types of itemsthey may contain.
In Section 5 we show how para-phrases can also be included in the run-time archi-tecture.
The final section concludes.2 The Regulus platformRegulus is an Open Source toolkit for buildingmedium vocabulary grammar-based spoken dia-logue and translation systems.
The central idea is tobase run-time processing on efficient, task-specificgrammars derived from general, reusable, domain-independent core grammars.
Early versions of Reg-ulus used a single core grammar per language; a de-tailed description of the core grammar for Englishcan be found in (Rayner et al, 2006, Chapter 9).More recently, there have been attempts to go fur-ther, and merge together core grammars for closelyrelated languages (Bouillon et al, 2007).The core grammars are automatically specialised,Figure 1: The Regulus compilation path.
The generalunification grammar is first transformed into a specialisedfeature grammar.
This can then be transformed either intoa CFG grammar and Nuance recogniser, or into a gener-ator.
and a Nuance recogniser.using corpus-driven methods based on small cor-pora, to derive simpler grammars.
Specialisationis both with respect to task (recognition, analysis,generation) and to application domain.
The special-isation process uses the Explanation Based Learningalgorithm (van Harmelen and Bundy, 1988; Rayner,1988).
It starts with a parsed treebank derived fromthe training corpus, and then divides the parse treecreated from each training example into a set of oneor more subtrees, following a set of domain- andgrammar-specific rules conventionally known in theMachine Learning literature as operationality crite-ria.
The rules in each subtree are then combined, us-ing the unification operation, into a single rule.
Theset of all such rules constitutes a specialised unifica-tion grammar.
Each of these specialised unificationgrammars is then subjected to a second compila-tion step, which converts it into its executable form.For analysis and generation, this form is a standardparser or generator.
For recognition, it is a semanti-cally annotated CFG grammar in the form requiredby the Nuance engine, which is then subjected tofurther Nuance-specific compilation steps to derivea speech recognition package.
Figure 1 summarisescompile-time processing.The Regulus platform also contains infrastructureto support construction of applications which use therecognisers, parsers and generators as components.In this paper, we will only discuss spoken dialoguesystem applications.
(There is also an elaborate in-frastructure to support speech translation systems).15Figure 2: Top-level architecture for Regulus-based spo-ken dialogue systemAt a high level of generality, the architecture is astandard one (Figure 2; cf.
for example (Allen etal., 2000)).
The central component is the DialogueManager (DM), which receives dialogue moves andproduces abstract actions.
It also manipulates an in-formation state, which maintains context; process-ing will generally be context-dependent.
The DM isbracketed between two other components, the InputManager (IM) and the Output Manager (OM).
TheIM receives logical forms, and non-speech inputs ifthere are any, and turns them into dialogue moves.The OM received abstract actions and turns theminto concrete actions.
Usually, these actions will beeither speaking, though TTS or recorded speech, ormanipulation of a GUI?s screen area.In the next section, we examine in more detailhow the various components are constructed, andwhat the implications are for the software develop-ment cycle.
We will in particular be interested inregression testing.3 Context, regression testing andparaphrasingThe three main components of the spoken dia-logue system ?
the IM, DM and OM ?
all trans-form one or more inputs into one or more outputs.With the current focus on machine learning tech-niques, a natural thought is to learn the relevanttranformations from examples.
Implemented mainlythrough Partially Observable Markov Decision Pro-cesses (POMDPs), this idea is attractive theoreti-cally, but has been challenging to scale up.
Systemshave been restricted to very simple domains (Royet al, 2000; Zhang et al, 2001) and only recentlyhave techniques been developed that show promisefor use in real-world systems (Williams and Young,2007; Gasic?
et al, 2008).
The representations re-quired in many systems are more complex than thoseemployed even in the more recent POMDP basedwork, and there is also the usual problem that it is noteasy to obtain training data.
In practice, most peo-ple are forced to construct the transformation rulesby hand; the Regulus framework assumes this willbe the case.
Hand-coding of dialogue processingcomponents involves the usual software engineeringproblems that arise when building and maintainingsubstantial rule-sets.
In particular, it is necessary tohave a framework that supports efficient regressiontesting.As everyone who has tried will know, the thingthat makes regression testing difficult for this kindof application is context-dependency.
In the worstcase, the context is the whole world, or at least thepart of it that the system is interacting with, and re-gression testing is impossible.
In more typical cases,however, good architectural choices can make theproblem reasonably tractable.
In particular, thingsbecome enormously simpler if it is possible to en-capsulate all the context information in a datastruc-ture that can be passed around.
In the dialogue man-agement architecture realised in Regulus (Rayner etal., 2006, Chapter 5), the assumption is that this isthe case; it is then possible to use a version of ?up-date semantics?
(Larsson and Traum, 2000).
Thecentral concepts are those of dialogue move, infor-mation state and dialogue action.
At the beginningof each turn, the dialogue manager is in an infor-mation state.
Inputs to the dialogue manager are bydefinition dialogue moves, and outputs are dialogueactions.
The behaviour of the dialogue manager overa turn is completely specified by an update functionf of the formf : State?Move ?
State?ActionsThus if a dialogue move is applied in a given infor-mation state, the result is a new information stateand a set of zero or more dialogue actions.3.1 Regression testingUsing the side-effect free framework is certainly alarge step in the right direction; it is in principle pos-16sible to construct a regression test suite consisting of4-tuples of the form?InState,Move,OutState,Actions?There are however several problems.
First, pro-cessing consists of much more than just the updatefunction.
It is optimistic to assume that the speechrecogniser will be able to produce dialogue movesdirectly.
In simple cases, this may be possible.
Inmore complex cases, extra levels of processing be-come necessary; in other words, the IM componentwill generally have a substantial amount of structure.There are several reasons for this.
The representa-tion delivered by the grammar-based speech recog-niser is syntax-oriented; it needs to be translatedinto a semantic form.
Again, because of context-dependency, this translation often needs to be car-ried out in more than one step.
For example, in theCalendar application, a question like ?When is thenext meeting in Switzerland??
might be followed bythe elliptical utterance ?In England??.
Some kindof mechanism is needed in order to resolve this toa representation meaning ?When is the next meet-ing in England??
A separate mechanism is used toperform reference resolution.
For instance, the de-fault database for the Calendar application containsone person called ?Nikos?
and two called ?Mari-anne?.
The question ?Is Nikos attending the meet-ing??
needs to be converted into a database querythat looks up the appropriate record; however, thestructurally similar query ?Is Marianne attending themeeting??
should produce a disambiguation query.Examples like these motivate the introduction of yetanother processing step, which carries out referenceresolution.Of course, different systems will address these is-sues in different ways; but, whatever the solution,the general point remains that there will usually bemany layers of representation.
From a system devel-opment point of view, the problem is how to struc-ture the regression testing needed in order to main-tain the stability of each processing step.
The mostcautious and direct way to do this is to have a corpusof input/output tuples representing each individualstep, but experience shows that this type of solutionplaces an enormous burden on the annotators whoare required to judge the correctness or otherwise ofthe tuples.
First of all, under this approach the anno-tators must be experts capable of reading and under-standing internal representations.
Second, even verysmall changes in the system often require completereannotation of the test corpus; for example, somedata structure may have been changed so as to in-clude an extra field.
If constant rejudging is requiredto keep the test suite coherent with the current ver-sion of the system, either the testing is abandoned asoverly difficult and time consuming, or it is done ina less careful way in order to speed up the process.Neither outcome is satisfactory.If annotation uses input/output tuples referring tointernal representations, the problems we have justnamed appear inescapable.
At the opposite end ofthe spectrum, a common approach is not to lookat internal representations at all, but only at in-put/output pairs consisting of top-level inputs andoutputs.
For example, we can pair ?When is the nextmeeting in Geneva??
with ?March 31 2009?, and?Is Marianne attending the meeting??
with ?WhichMarianne do you mean??
This is generally, in prac-tice, easier than doing regression testing on internalrepresentations; the key advantages are that, sincewe are only dealing with pre-theoretical notions, an-notation can be performed by non-experts, and an-notations remain stable across most changes to in-ternal representations.Unfortunately, however, new problems arise.First, determining the correct output response for agiven input is often tedious and slow.
For example,in the Calendar application, this generally involvescarrying out a database search.
Suitable annotationtools can alleviate the pain here, but then a worseproblem arises; it is often possible to produce a cor-rect system response, even if processing is incorrect.For instance, even if the system correctly answers?No?
to a yes/no question, this proves very little;the question could have been interpreted in a mul-titude of ways, and still produced a negative answer.Knowing that a WH-question provides a correct an-swer says more, but can still often be misleading.Suppose, for example, that we know that the Calen-dar system correctly answers ?None?
to the question?What meetings are there during the next week?
?and there are no meetings for the next 15 days.
Wewill be unable to tell whether the question has beeninterpreted as ?What meetings are there during the17World Context time=2008-10-14 14:34, speaker=mikeLast Para (none)Input when is the next meeting with markParaphrase when is [ the next meeting attended by mark green ]World Context time=2008-10-16 09:47, speaker=mikeLast Para (none)Input when is my next meeting with markParaphrase when is [ the next meeting attended by mark green and mike jones ]World Context time=2007-07-08 15:03, speaker=susanLast Para (none)Input is there a meeting next weekParaphrase are there meetings between Mon Jul 9 2007 and Sun Jul 15 2007World Context time=2008-11-17 18:20, speaker=mikeLast Para (none)Input do i have a meeting on friday morning this weekParaphrase are there meetings between 06:00 and 12:00 on Fri Nov 21 2008 attended by mike jonesWorld Context time=2008-11-12 10:19, speaker=mikeLast Para when is [ the next meeting attended by mike jones ]Input will alex participateParaphrase will that meeting be attended by alex millerWorld Context time=2007-07-08 15:56), speaker=susanLast Para are there meetings on Mon Jul 9 2007Input how about on tuesdayParaphrase are there meetings on Tue Jul 10 2007Table 1: Examples of regression testing tuples in the English Calendar system.
Each tuple shows the current worldcontext (timestamp and speaker), the preceding paraphrase, the input, and the paraphrase produced from it.next 7 days?
?, as ?What meetings are there duringthe 7 day period starting this Sunday??
or as ?Whatmeetings are there during the 7 day period startingthis Monday??
Examples like these mean that re-gression testing often fails to catch bugs introducedby system changes.3.2 Paraphrasing dialogue movesTo summarise: when carrying out regression testing,we have two competing requirements.
First, we needto be able to access internal representations, sincethey are so informative.
At the same time, we preferto work with human-readable, pretheorically mean-ingful objects, which will be stable at least undermost small changes in underlying representations.There is, in fact, a good compromise between thesegoals: we define a transformation which realises thedialogue move as a human-readable string, whichwe call a dialogue move paraphrase.
So, for ex-ample, consider the possible interpretations when,on March 6 2009, a user asks ?What meetings arethere during the next week??.
If ?What meetingsare there during the next week??
is interpreted as?What meetings are there during the next 7 days?
?,then the paraphrase might be ?What meetings arethere between Fri Mar 6 and Thu Mar 12 2009??
; ifthe interpretation is ?What meetings are there dur-ing the 7 day period starting this Monday?
?, thenthe corresponding paraphrase would be ?What meet-ings are there between Mon Mar 9 and Sun Mar 152009??
Regression testing can be carried out usingparaphrases of dialogue moves, rather than the dia-logue moves themselves.The paraphrase mechanism is implemented as aRegulus grammar, compiled in generation mode,which directly relates a dialogue move and its sur-face form.
We have found that it is not hard to de-sign ?paraphrase grammars?
which produce outputs18fulfilling the main design requirements.
Regressiontesting is carried out on tuples consisting of the pre-ceding paraphrase, the world context (if any), the in-put, and the resulting paraphrase.
Examples of suchtuples for the English Calendar grammar are shownin Table 1; in Calendar, the world context consists ofthe utterance time-stamp and the speaker.A tuple combines the results of IM and DM(but not OM) processing for a given example, andpresents them in a pre-theoretically meaningful way.Although they are not as fine-grained as tuples forindividual processing steps, they are stable overmost system changes.
In the opposite direction, theyare far more fine-grained than straight system in-put/system output tuples.
They are much easier tojudge than both of the other types of tuple.
The bot-tom line, at least as far as we are concerned, is that aregression testing database of paraphrase-based tu-ples can actually be maintained without inordinateeffort, implying corresponding gains for system sta-bility.
Previously, this was impossible.The idea of creating paraphrases from dialoguemoves is of course not new; in previous work, how-ever, they have generally been used at runtime toprovide feedback to the user as to how their input hasbeen interpreted by the system.
Although in the cur-rent discussion we have been more concerned withtheir use in regression testing, we have in fact alsoemployed them for the more traditional purpose.We return to this theme in Section 5.
First, wedescribe in more detail where our test suites comefrom.4 Collecting test suitesThe tradition in the speech engineering communityis that a test suite consists of a list of recorded wav-files, together with accompanying transcriptions.The Nuance platform contains a fair amount of in-frastructure, in particular the batchrec utility, forprocessing lists of wavfiles.
These tools are veryuseful for computing measures like WER, and thereis a strong temptation to try to build on top ofthem.
After a while, however, we discovered thatthey meshed poorly with the the basic goals of re-gression testing in a spoken dialogue system, whichrevolve around speech understanding rather thanspeech recognition.
There are two central problems.One of them is context-dependence, which we havealready discussed at length.
The other is the fact thatmany applications require that the IM process bothspeech and non-speech actions, with the sequenceand even the timing of actions being important.For example, as we have already seen, time isa central concept in the Calendar system.
If theuser says ?Are there any meetings this afternoon?
?the system interprets her as meaning ?Are there anymeetings from now until the end of the afternoon?
?This means that the exact clock time for each utter-ance is important.
In the Taxi application, the taxi iscontinually in motion, even when the user is not talk-ing.
The simulator sends the IM an non-speech mes-sage several times a second, giving the taxi?s newposition and heading.
This information is passed tothe DM, updating its state, and is essential for cor-rect interpretation of commands like ?Turn right atthe next corner?.Considerations like these finally convinced us tomove to a different strategy, in which offline regres-sion testing more closely models the runtime be-haviour of the application.
At runtime, the systemproduces a time-stamped log of all input passed tothe IM, including both speech and non-speech mes-sages, in the sequence in which they were received.Each speech message is paired with a pointer to therecorded wavfile which produced it.
Sets of suchlogs make up the test suite.
Offline testing essen-tially re-runs the sequence of time-stamped records.Wavfiles are passed to a recognition server, whichreturns recognition results; time-stamps are used toset a notional internal clock, which replaces the realone for the purposes of performing temporal calcula-tions.
The test harness was quite easy to implement,and solves all the problems that arose from close ad-herence to a more speech recognition oriented testframework.5 Using paraphrases at run-timeAs mentioned in Section 3.2, paraphrase grammarscan also be used at runtime, in order to providea direct confirmation to the user showing how thesystem has interpreted what they have said.
Thisis not a compelling design for every system; in aspeech-only system, constant direct confirmation us-ing paraphrases is in most cases unnatural and te-19dious.
It is, however, a potentially valid strategy in amulti-modal system where it is possible to present avisual display of the paraphrase.
In such a system, ifparaphrases are regularly displayed to a user, thereis, however, a good possibility of lexical and/or syn-tactic entrainment.
Entrainment increases the likeli-hood that the user will produce the paraphrase lan-guage, which means that it would be valuable to beable to process that language through the system.In the Regulus framework, this problem can bevery straightforwardly addressed.
Since the para-phrase grammar is a valid Regulus grammar, it canbe compiled into a Nuance grammar, and hence intoa second recognition package.
At runtime, this pack-age can be used in parallel with the main systemrecogniser.
Because the paraphrase grammar is de-signed to directly relate surface language to dialoguemoves, dialogue moves are generated directly, skip-ping the Input Manager processing.
In particular,since the original point of the paraphrase grammaris to restate the user?s content in a way that resolvesand disambiguates underspecified material, there isno need for resolution processing.
Figure 3 showsthe dialogue system architecture with the additionalparaphrase processing path.InputManagerDialogueManagerOutputManagerMainRecognizerParaphraseRecognizerPlaybackor TTSGUILogical FormDialogueMoveDialogueMoveAbstractActionConcreteActionConcreteActionFigure 3: Regulus dialogue architecture with a processingpath for paraphrases added.
The paraphrase recognizersends a dialogue move directly to the Dialogue Manager.Although it may seem preferable to include theparaphrase coverage in the main recogniser cover-age, we have found, somewhat to our surprise, thatthis is not nearly as straightforward as it first ap-pears.
The problem is that the two grammars are de-signed for very different tasks; the recognition gram-mar is intended to capture natural user language,while the paraphrase grammar?s job is to produceunambiguous surface renderings of resolved seman-tic representations.
Although we have endeavouredto make the paraphrase language as natural as pos-sible, it is hard to avoid at least a few marginalconstructions, which do not fit well into the struc-ture of the normal recognition grammar; even if wedid try to include them, the burden of keeping thetwo different grammars in synch would be consider-able.
From a software engineering point of view, itis far simpler just to maintain the two grammars sep-arately, with each of them generating its own versionof the recogniser.We tested the paraphrase grammar recognizer forthe Calendar application using paraphrases takenfrom a previous run log and recorded by the twoauthors.
There were 249 recorded paraphrases to-tal used.
Because the Calendar paraphrase grammarhad originally been designed with only visual dis-play in mind, some augmentation of the paraphrasegrammar was needed to cover the spoken versionsof the paraphrases.
There is often more than onepossible spoken version corresponding to a writtenrepresentation as was the case for this data.
For ex-ample with a paraphrase such as ?when are meet-ings on Sat Jan 3 2009?, ?Sat?
could be pronounced?sat?
or ?Saturday?, ?3?
could be ?third?
or ?three?,?Jan?
could be produced as either ?jan?
or ?January?and ?2009?
could be ?two thousand nine?
or ?twothousand and nine?.
With the paraphrase compo-nent structured as a standard Regulus grammar, allthat was needed was to add lexical items to coverthe spoken variants.
These additions were restrictedto the recognition use of the paraphrase grammarand not used for generation.
Word Error (WER) was4.43% for the paraphrase grammar recognizer, Sen-tence Error (SER)was 34.53% and Semantic Error(SemER)was 17.9%.
This SemER was calculatedon untuned n-best.
Clearly it is not possible to com-pare with the main recognizer on the same data, butfor a rough comparison, we can look at numbers re-ported for the Calendar application in (Georgesculet al, 2008).
That paper reports WER of 11.17%and SemER of 18.85% for the 1-best baseline.
TheSemER on the paraphrase grammar is 21.5% for 1-best.
The paraphrase grammar recognizer has muchbetter WER because it is so much more restrictedthan the main recognizer.
However, the sentencescovered by the paraphrase grammar are much longerthan those covered in the main grammar, and thisdifference is reflected in the poorer performance byparaphrase grammar when measured in terms of Se-20mER.
The paraphrase language is long, very unnatu-ral, yet we are able to produce a level of recognitionperformance that is quite usable.Given the ability to recognize with the paraphrasegrammar, a question which we hope to be ableto investigate empirically is the effect that entrain-ment from exposure to the longer and less naturalparaphrases actually has on user language, whichinitially tends to be biased towards short, natural-sounding utterances, with frequent use of ellipsis.This is a interesting topic for future research.6 ConclusionsThe dialogue move paraphrase mechanism providesa useful approach to streamlining regression testingwithout abandoning necessary detail.
In non-trivialspoken dialogue systems, it is generally necessaryto have a number of levels of representation.
Ourapproach provides a middle ground between track-ing each of these levels in the test suites, creating aexcessive maintenance burden, and keeping only toplevel inputs and outputs, which is too coarse-grainedto catch many errors.
The Regulus framework pro-vides the opportunity to implement this mechanismas a Regulus grammar, which makes the compilationinto recognisers, parsers and generators available.While generation with the paraphrase grammar sup-ports the described improvement in regression test-ing methodology, compiling the paraphrase gram-mar into a recogniser allows us to ensure that para-phrases used as confirmations can also be processedif directed at the dialogue system.
The frameworkhas been used with several fairly different kinds ofapplications, and appears to have a major impact onthe overhead associated with maintenance of a use-ful regression testing regime.ReferencesJ.
Allen, D. Byron, M. Dzikovska, G. Ferguson,L.
Galescu, and A. Stent.
2000.
An architecture fora generic dialogue shell.
Natural Language Engineer-ing, Special Issue on Best Practice in Spoken Lan-guage Dialogue Systems Engineering, pages 1?16.P.
Bouillon, M. Rayner, B. Novellas, M. Starlander,M.
Santaholma, Y. Nakao, and N. Chatzichrisafis.2007.
Une grammaire partage?e multi-ta?che pour letraitement de la parole: application aux langues ro-manes.
TAL.P.
Bouillon, G. Flores, M. Georgescul, S. Halimi, B.A.Hockey, H. Isahara, K. Kanzaki, Y. Nakao, M. Rayner,M.
Santaholma, M. Starlander, and N. Tsourakis.2008.
Many-to-many multilingual medical speechtranslation on a PDA.
In Proceedings of The EighthConference of the Association for Machine Translationin the Americas, Waikiki, Hawaii.Milica Gasic?, Simon Keizer, Francois Mairesse, JostSchatzmann, Blaise Thomson, Kai Yu, and SteveYoung.
2008.
Training and evaluation of the hispomdp dialogue system in noise.
In Proceedings of the9th SIGDIAL Workshop on Discourse and Dialogue.Maria Georgescul, Manny Rayner, Pierrette Bouillon,and Nikos Tsourakis.
2008.
Discriminative learningusing linguistic features to rescore n-best speech hy-potheses.
In The IEEE Workshop on Spoken LanguageTechnology, Goa, India.S.
Larsson and D. Traum.
2000.
Information state anddialogue management in the TRINDI dialogue moveengine toolkit.
Natural Language Engineering, Spe-cial Issue on Best Practice in Spoken Language Dia-logue Systems Engineering, pages 323?340.M.
Rayner, B.A.
Hockey, J.M.
Renders,N.
Chatzichrisafis, and K. Farrell.
2005.
A voiceenabled procedure browser for the international spacestation.
In Proceedings of the 43rd Annual Meetingof the Association for Computational Linguistics(interactive poster and demo track), Ann Arbor, MI.M.
Rayner, B.A.
Hockey, and P. Bouillon.
2006.
PuttingLinguistics into Speech Recognition: The RegulusGrammar Compiler.
CSLI Press, Chicago.M.
Rayner.
1988.
Applying explanation-based general-ization to natural-language processing.
In Proceedingsof the International Conference on Fifth GenerationComputer Systems, pages 1267?1274, Tokyo, Japan.N.
Roy, J Pineau, and S. Thrun.
2000.
Spoken dia-logue management using probabilistic reasoning.
InProceedings of ACL, Hong Kong.N.
Tsourakis, M. Georghescul, P. Bouillon, andM.
Rayner.
2008.
Building mobile spoken dialogueapplications using regulus.
In Proceedings of LREC2008, Marrakesh, Morocco.T.
van Harmelen and A. Bundy.
1988.
Explanation-based generalization = partial evaluation (researchnote).
Artificial Intelligence, 36:401?412.JD Williams and SJ Young.
2007.
Partially observablemarkov decision processes for spoken dialog systems.Computer Speech and Language.B.
Zhang, Q Cai, J. Mao, E. Chang, and B Guo.
2001.Spoken dialogue management as planning and actingunder uncertainty.
In Proceedings of Eurospeech, Aal-borg, Denmark.21
