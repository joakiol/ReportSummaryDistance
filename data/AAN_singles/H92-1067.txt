An A* algorithm for very large vocabulary continuous peechrecognition IP.
Kenny, R. Hollan 2, G. Boulianne, H. Garudadri, M. Lennig 2 and D. O'ShaughnessyINRS-T616communications3 Place du CommerceMontreal, Quebec, Canada H3E 1H6ABSTRACTWe present anew search algorithm for very large vocabulary contin-uous speech recognition.
Continuous speech recognition with thisalgorithm is only about 10 times more computationally expensivethan isolated word recognition.
We report preliminary recognitionresults obtained by testing our recognizer on "books on tape" usinga 60,000 word dictionary.1.
IntroductionIn this paper we will give a preliminary report on our effortsto extend our earlier work on very large vocabulary isolatedword recognition \[16, 17, 19\] to continuous speech tasks.
Weare aiming to perform speaker-dependent continuous speechrecognition using a trigram language model and a vocabularyof 50,000-100,000 words.Although the problem of very large vocabulary isolated wordrecognition has largely been solved \[I, 19\], no experimentshave yet been conducted in continuous peech recognitionwith comparably arge vocabularies because the search prob-lem is so formidable.
The best known approach to the searchproblem uses the word as the fundamental search unit anda stack decoding algorithm \[II, 20\] (also known as an A*search \[14\]).
The effectiveness of this approach depends onhaving a good fast match strategy to identify candidate wordswhenever a word boundary is hypothesized.
Many differentfast match algorithms have been proposed \[3, 4, 5, 15\] butthey have yet to be shown to perform satisfactorily on con-tinuous speech tasks having a vocabulary larger than 5,000words \[2\].An alternative approach developped by Phillips \[6\] (on a103300 word vocabulary in German) uses the phoneme asthe fundamental search unit and consists ofa Viterbi search ofthe hidden Markov model obtained by combining phonemeHMMs with a Markovian language model (such as a trigrammodel).
Aggressive pruning is necessary since the searchspace is very large.
(For instance, if a trigram languagemodel is used then one copy of the lexical tree is neededfor every possible bigram.)
The phoneme inventory is surf-icently small that exact matches can be calculated whenever1This work was supported by the Natural Sciences and Engineering Re-search Council of Canada2Also with Bell-Northern Research, Montreal, Canadathey are needed.
However, it remains to be seen whether thephoneme unit is capable of attaining respectable accuracieson very large-scale r cognition tasks.A new type of bi-directional search strategy has emerged re-cently.
The basic idea is to guide the search by means of aheuristic obtained by first carrying out an inexpensive searchin the reverse time direction (subject o relatively weak lin-guistic and/or lexical constraints).
This type of approachappears to have been discovered independently b  severalgroups and has been shown to work effectively on a variety ofapplications \[8, 9, 16\].
In \[16\] we presented a very efficientalgorithm for very large vocabulary isolated word recogni-tion using this paradigm and the phoneme as the fundamentalsearch unit.
Our current efforts are devoted to extending thisalgorithm to continuous speech.This isolated word recognition algorithm is an A* algorithmwhich uses a heuristic obtained by searching a phoneticgraph \[16\] which imposes triphone phonotactic constraintson phoneme strings.
This search is conducted using the stan-dard Viterbi algorithm in the reverse time direction (startingfrom the end of the utterance).
In addition to providing averyefficient heuristic, a major advantage inusing triphone phono-tactic constraints i that it enables us to identify the endpointof the third-to-last phoneme in each partial recognition hy-pothesis with a high degree of accuracy, thereby substantiallyreducing the size of the search space.
Another innovative f a-ture of this algorithm is that it computes the acoustic matchesof every segment of data with each of the phoneme models('the point scores') before carrying out the A* search.
(Theprincipal reason for doing so is that this approach enablessegment-level f atures such as phoneme durations to be mod-elled in an optimal way \[16, 18, 7\].
)The effectiveness of the triphone heuristic depends more onthe quality of the phoneme models than on the size of thesearch space.
Thus we have found that, even without anypruning, the isolated word recognition algorithm runs morequickly on a 60,000-word recognition task with clean speechand speaker-dependent models than on a 1,600-word task withtelephone speech and speaker-independent models \[16\].
Inthe speaker-dependent case most of the computaion is takenup by the pre-processing (the calculation of the point scores333and the Viterbi search) and the A* search itself accounts foronly about 1% of the total.
In extending the algorithm tocontinuous speech (also with a 60,000 word vocabulary andspeaker dependent models), we have found that the amount ofpre-processing per unit time remains essentially the same, butthe amount of computation needed for the A* search increasesby three orders of magnitude.
Hence, the total computationaldemands of the algorithm only increase by a factor of about10.The experiments reported here have been conducted usingphoneme models, but the search algorithm can be extendedto accommodate allophone models (including cross-word al-lophones) fairly easily.2.
Block ProcessingIn developping our algorithms, we have decided to work withcommercially distributed books on tape (analog recordingsof well known novels).
Half of each recording is used astraining data and the other half for testing and we use an opticalcharacter recognizer to read the accompanying texts.
Sincethis data is not segmented into sentences we have designedour training and recogniton algorithms to work with chunksof data of arbitrary size.
This means that the data has to beprocessed in blocks which can fit comfortably into memory.Our approach is to use an A* search in each block whichis similar to the isolated word recognition algorithm exceptinsofar as word boundaries are not known in advance and atrigram language model is used in the scoring procedure.
Asin the isolated word case, an admissible heuristic is obtainedby means of an initial Viterbi search through a graph whichimposes triphone phonotactic constraints on phone strings.The A* search generates a list of theories (partial phonemictranscriptions together with word histories) for the speech dataup to the end of the block 3 As soon as the list of theories forthe current block has been obtained, the block is swapped outof memory and the search of the next block begins using thislist to initialize the stack.This list of theories plays the same role as the beam used ina time synchronous Viterbi search.
The Markov property ofthe trigram language model allows us to merge theories thathave identical recent pasts but different remote pasts so thenumber of theories that have to be generated atthe end of eachblock (the 'beam width') can held fixed without running therisk of losing the optimal theory.
In order to pursue the searchin subsequent blocks, the only information eeded concernsthe recent pasts of these theories.
By logging the informationconcerning the remote pasts to disk we are able to ensure thatthe memory required to recognize a file is independent of its3More precisely, each of the theories generated has the property hatall of the hypothesized end points for the third-to-last phoneme in the partialphonemic transcription are beyond the end of the block.
'nae partial phonemictranscription need not  end at a word boundary.length (instead of increasing exponentially with the lengthof the file as would be necessary without merging and blockprocessing).For the last block in a file it is only necessary to generatea single recognition hypothesis and, once the last block hasbeen processed, the transcription of the entire utterance canbe obtained by back-tracking.
The recognition algorithm cantherefore be viewed globally as a beam search and locally asan A* search.3.
The Heurist icBroadly speaking, an A* search of the data in a block pro-ceeds as follows.
At each iteration of the algorithm, thereis a sorted list (or 'stack') of theories each with a heuristicscore.
This heuristic score is calculated by combining theexact likelihood score of the speech data accounted for bythe theory (using phoneme HMMs and the language model)with an overestimate of the score of the remaining data onthe optimal extension of the theory permitted by the lexiconand the language model.
The theory with the highest heuristicscore is expanded, meaning that for each of the one-phonemeextensions permitted by the lexicon the heuristic score of theextended theory is calculated and the extended theory is in-serted into the stack at the appropriate position.
This processis iterated until sufficiently many theories atisfying a suitabletermination criterion have been generated.For the time being, we have decided to ignore the issue of over-estimating language model scores altogether in constructingthe heuristic (that is, we use an estimate of 1 for the languagemodel probability of any extension of a given theory).
Ourstrategy for overestimating acoustic scores is essentially thesame as in the isolated word case, that is, we conduct an ex-haustive search backwards in time through a phonetic graphwhich imposes triphone phonotactic constraints on phonemestrings rather than full lexical constraints and enables the third-to-last phoneme in a given partial phonemic transcription tobe accurately endpointed.
Naturally, the triphone phonotac-tic constraints must take account of triphones which occur atword boundaries.
The simplest graph with these properties ispecified as follows:.2..Nodes: there is one node for every possible diphone fgBranches: for every legitimate triphone fgh (that is,a triphone that can be obtained by concatenating thephonemic transcriptions of words in the dictionary) thereis a branch from the node corresponding to the diphonefg to the node corresponding to the diphone ghBranch Labels: if fgh is a legitimate triphone then thebranch from the node fg to the node g h carries the labelf.334Denote this graph by G*.
It is easy to see that this graphimposes triphone constraints on phoneme strings, that is, if9~, g2, 93 ?
?
?
is the sequence of phoneme labels encounteredon a given path through G* then every triple gtgt +t gt +2 (k =1,2, .
.
. )
is a legitimate triphone.
The labelling scheme (3) ischosen so that the endpointing condition is satisfied (see thenext section).4.
Searching a blockIn order to search a block extending from times T1 to T2, wefirst construct the hidden Markov model corresponding to thegraph G* \[16\] and, for a suitably chosen positive integer A,we perform a Viterbi search backwards in time through thisHMM from time T2 + A to time T1.
(The condition used todetermine the parameter A is given below.)
The boundarycondition used to initialize the search is that the backwardprobability at every state in the model at time T2 + A is 1.For each node n in G* and each t = T1 - 1 , .
.
.
,  T2 + A - 1we thus obtain the Viterbi score of the data in the intervalIt + 1, T2 + A\] on the best path in G* which leaves n at timet and is subject o no constraints on the state in the modeloccupied at time T + A; denote this quantity by/3~ (n).Suppose we are given a partial phonemic transcriptionfl .
.
.
f t .
Let n be the node corresponding to the diphoneA-~A and for each time t, let c~,(fl .
.
.
fk-2) denote theViterbi score of all of the data up to time t (starting fromthe beginning of the utterance) for the truncated transcriptionfl .
.
.
f t -2.
Since fl~ (n) is the Viterbi score of the data in theinterval \[t + 1, T + A\] on the best path in G* which leavesn at time t and the construction of G* constrains this path topass first through a branch labelled f t -1 and then through abranch labelled f t ,  it is reasonable to estimate the endpointof the phoneme f t -2  asargmax o~,(fl....~-2)fl~ (n).tIn the case of clean speech and speaker-dependent models,this estimate turns out to be exact almost all of the time \[16\]but it is safer to hypothesize s veral end points (for instanceby taking the five values of t for which+,(Y l  .
.
.is largest).A stack entry (theory) 0 is a septuple (w, f, m, n, o', {o~}, S)where1.
w = w l .
.
.
w,~ is a word history.2.
f = f~ .. .
f t  is a partial phonemic transcription whichmay extend into a word following w, (but there are nocomplete words after w, in the partial transcription f).
rn is a node in the lexical tree \[16\] corresponding to thepart f which extends beyond Wn, if any; m is the rootnode of the lexical tree otherwise4.
n is the node in the graph G* which corresponds tothediphone fk-  1 fA.
o- is the current state of the trigram language model;there are three possibilities depending on whether theword following wn is predicted using a trigram distribu-tion P(.
Iw,_ lw,) ,  a bigram distribution P(.lw,0 or aunigram distribution P(.).
for each endpoint hypothesis t, at is the Viterbi score ofthe data up to time t against he model for the truncatedtranscription fl .
.
.
f t -27.
S is the heuristic score which is given by* r t  S = P(w)  m~lx at(f1 .
.
.
fk -2)~ ( )where P(w)  is the probability of the word string wcalculated using the trigram language model.The reason why both w and f have to be specified is thatdifferent words may have the same transcription and differenttranscriptions may correspond to the same word.
Obviouslyit is redundant to specify m, n and~ in addition to w and fbut it is convenient to do so.A stack entry is said to be complete if all of its hypothesizedendpoints are to the right of T2.
The parameter A is deter-mined empirically by the condition that the exact endpointof a complete stack entry should always be included amongthe hypothesized endpoints.
(Since it is not actually possi-ble because of memory limitations to carry around sufficientinformation with each theory to be able to generate its seg-mentation, we test his condition by verifying that he acousticscore of the global transcription found by the recognizer of thedata in each file is the same as the score found by the trainingprogram when it is run with this transcription.
)At the start of the search, the stack is initialized using thelist of theories generated by searching the previous block(ending at time T1).
Each of these has the property that allof its hypothesised endpoints are to the right of T~, so thespeech data prior to the beginning of the current block is nolonger needed.
The search terminates when sufficiently manycomplete theories have been generated atwhich point the nextblock is swapped into memory and a new search begins.The Markov property of the trigram language model en-ables us to merge theories that have identical recent pastsbut different remote pasts.
Specifically, suppose wehave two theories 0 = (w, f ,  rn, n,~r,{~t},S) and O' =(w', f ' ,m',n' ,o",  {a~}, S') such that m = m', n = n' and335or = o-'.
(In this case we will say that 0 and 0' are equivalent.
)The future extensions of both theories which best account forthe data starting at any given time (subject to lexical and lan-guage model constraints) will be identical.
Thus if it happensthat t is on the list of hypothesized ndpoints for both theoriesandP(w')ct~ < P(w)oLtthen we can remove t from the hypothesis list for the secondtheory without running the risk of losing the optimal path.
Inpractice, the condition  = n' means that the list of hypoth-esized endpoints for both theories will be the same (exceptin very rare cases).
Furthermore, if this inequality holds forone such t then it is typically because the first theory gives abetter fit to the remote past than the second theory; hence itwill usually be the case that if the inequality holds for one tthen it will hold for all t and the second theory can be prunedaway completely.We can take advantage of this fact to speed up the A* searchby maintaining a list of 'merge buckets' consisting of all theequivalence classes of theories encountered in the course ofthe search.
Associated with each equivalence class we havean array of forward scores {At } which is updated throughoutthe search.
For each t, At is defined to bemax P(w)o~t0where 0 extends over all theories (w, f, m, n, o', {oct}, S) inthe given equivalence lass that have been encountered sofar(in the course of searching the current block).
When a newtheory 0' = (w', f', m', n', a', {o~}, S') in this equivalenceclass comes to be inserted into the stack we can test to see ifthe inequalityP(w')ogt < Atholds for each hypothesized endpoint t. If it does, then wecan prune this endpoint hypothesis before ntering the theoryinto the stack; if not, then At is updated and the endpointhypothesis has to be retained.We have not been able to implement this scheme fully becauseof memory limitations.
In practice, we only invoke mergingwhen a word boundary is hypothesized so the only mergebuckets generated in the course of the search are those whichcorrespond to theories for which m is the root node of thelexical tree.
(However, before starting the search we prunethe list of hypotheses generated by searching the previousblock by merging at arbitrary phoneme boundaries and weuse this pruned list to initialize the stack.)5.
Experimental ResultsOur first experimental results obtained from two books on tape(analog recordings) appear in Table 1.
The first book "WhiteFang" by Jack London was recorded by a male speaker;the second book "Washington Square" by Henry James wasrecorded by a female.Training TestBook Set Set AccuracySize Size %WF 18,012 730 51AWS 16,257 786 73.2Table 1: Preliminary recognition results.The second and third columns in this table give the trainingand test set sizes in words; the third column gives the accuracywhich is calculated asN-  (Substitutions + ?\[Deletions + Insertions\])Nwhere N is the size of the test set.These experiments were run using 41 phonemic mixtureHMMs for each speaker, a 60,000 word dictionary whichwas edited to include all of the words in both books (1.5% ofthe words in each of the books had to be added) and a trigramlanguage model which was trained on 60,000,000 words ofnewspaper texts.
No attempt was made to tailor the languagemodel to the task domains.
The test set perplexity was 1,743in the case of "White Fang" and 749 in the case of "Washing-ton Sqaure".
These perplexities can be reduced to 576 and347 respectively by smoothing the language model statisticsusing word frequencies collected from the training set but wedid not take advantage of this in running our experiments.The CPU time required to run the "Washington Square" ex-periment was 120 times real time on a HP 720 workstation.We had to use a block advance of only 10 frames (1 frame= 10 ms) in order to keep the stack size within reasonablebounds.
The parameter A was set at 140 frames.
The stackwas implemented asa heap and the maximum number of stackentries was set to 60,000.
(When this figure is reached, thesize of the stack is cut back to 30,000).
The number of theo-ries passed from one block to the next was 3,000.
In the caseof "'White Fang" a larger stack was needed to prevent searcherrors and the execution time was longer.
We will have to runthe recognizer on several more speakers before attempting tooptimize these parameters.6.
Future WorkThere is obviously a substantial mount of work to be doneto improve both the accuracy and speed of our recognitionalgorithm.
These problems are not independent of each other:we expect that he search algorithm will run faster with a betterlanguage model and better acoustic models and conversely336improvements in the search algorithm will lead to fewer searcherrors and hence higher ecognition rates.At present, the only types of pruning that have been im-plemented are the merging of theories having identical recentpasts and the limitations on the size of the stack used in search-ing a block as well as the length of the list of theories passedfrom one block to the next.
Several other possibilities remainto be explored.
We may be able to get away with a beamsearch in the calculation of the ~/*'s.
It may be possible toprune hypotheses based on poor local acoustic matches (eval-uated using the point scores or the/~* 's or a combination ofthetwo).
Since the branching factor at the root node of the lexicaltree is 41, we would expect abig payoff if this type of pruningcan be made to work successfully whenever a word boundaryis hypothesized.
Also the limitations on the stack size andthe length of the hypothesis lists passed from one block tothe next should probably be made threshold-dependent ratherthan preset.In our current implementation, wehave not taken full advan-tage of the sparseness ofthe language model statistics (the thenumber of bigrams wl w2 for which we have trained trigramdistributions P (.
\]wx w2) is relatively small and these distribu-tions are typically concentrated onvery small subsets of thedictionary).
Our present implementation gets some mileageout of this fact by using the notion of a language model state(~r) to determine when theories can be merged, but more workremains to be done.
Adding a language model component tothe heuristic would probably help as well.As for acoustic modelling, we can expect a major improve-ment by using allophone models.
From the way we havepresented the algorithm, it may appear that we have lockedourselves into the choice of the phoneme as the modelling unitso it may come as a surprise to learn that our algorithm canaccommodate allophone models in a natural way (without un-duly increasing the amount of computation needed).
The onlyrestriction is that he allophones of a given phoneme should bedefined by looking at contexts which extend no more than twophonemes to the right (there is no restriction on left contexts).Since this is an important issue, we take the time to explainwhat is involved here.
Certainly, we would encounter prob-lems if we were to proceed in a straightforward manner andrecompile the lexicon in terms of allophonic transcriptionsrather than phonemic transcriptions.
Firstly, the structure ofthe lexical tree would have to be radically altered to acco-modate allophones defined by contexts which extend acrossword boundaries.
Secondly, with a reasonably large allo-phone inventory (say a few thousand), the size of the graphG* would become so large as to make the computation ofthe/~* 's practically infeasible.
So the approach is to retainthe structure of the lexical tree and the graph G* determinedby the phonemic transcriptions and perform the translation toallophonic transcriptions on-line.
(The same method could beused to incorporate phonological rules whose domain spansword boundaries.
)Suppose we have a theory 0 whose partial phonemic tran-scription is fl .
.
.
fk.
We have to explain how oct(f1 .
.
.
fk-2)and fl~ (n) are computed when allophone models are used.In calculating o~t(ft .
.
.
fk-2), we simply use the appropriateallophonic models for each of the phonemes f l , .
.
- ,  fk-2.
(Note that sufficent information concerning the right contextsis available to determine which allophones to use).It is natural to organize the calculation of the t* 's in termsof the point scores.
To see how this goes, consider first thecase of phoneme models.
The ~*'s can be calculated usingthe block Viterbi algorithm \[16\].
Recall that, for a given noden, the first two phoneme labels on any path in G* which startsat node n are uniquely determined.
Denote the first phonemeby f and the second by g. The recursion formula is~t~ (n) = max V(\[t + 1, t '\] lf) max ~7,(n')tt>twhere n' ranges over all nodes uch that (n, f,  n') is a branchin G* and V(\[t + 1, t'\] lf) denotes the Viterbi score of the datain the interval It + 1, t'\] calculated using the f model.In the case of allophone models, we can calculate the back-ward probabilities using the recursion formula~/~(n) = max max V(\[t + 1,t'\]l~) m,ax/~,(n' )t~>t qbwhere, as before, n' ranges over all nodes such that (n, f, n')is a branch in G* and ~b ranges over all the allophones of fdetermined by the condition that the phoneme immediatelyfollowing f is g. It is obvious that the backward probabilitiescalculated in this way provide an overestimate of the acousticscore of the data which has not yet been accounted for onthe optimal extension of the theory 0 so the admissibilitycondition is satisfied.
Of course, it is not possible to endpointthe phoneme fk-2 exactly in this case since the allophonemodels needed to score fk-~ and fk cannot be determineduntil the theory has been extended.
This does not presenta problem since we already have a mechanism in place forhandling multiple ndpoint hypotheses.Finally, we have recently embarked on a project o parallelizethe search algorithm with a view to obtaining a real-timeresponse on a platform supplied by ALEX Informatique con-taining 48 i860's and 48 'I'800 transputers.References1.
Averbuch A., "Experiments with the Tangora 20,000 wordspeech recognizer," Proc.
ICASSP 87, pp.
701-704, 1987.2.
Bahl, L.R.
et al "Large Vocabulary Natural Language Con-tinuous Speech Recognition", Proc.
ICASSP 89, pp.
465.-.467,1989.3373.
Bahl, L.R., De Gennaro S.V., Oopalakrishnan, P.S., Mercer,R.L., "A fast approximate acoustic match for large vocabularyspeech recognition", personal communication.4.
Bahl, L.R., Bakis, R., de Souza, P.V., Mercer, R.L., "Obtain-ing candidate words by polling in a large vocabulary speechrecognition system", Proc.
ICASSP 88, pp.
489-492, 1988.5.
Fissore, L., Laface, P., Micca, O., Pieraccini, R., "Lexicalaccess to large vocabularies for speech recognition", Proc.ICASSP 89, pp.
1197-1213, 1989.6.
Steinbiss, V., "A 10 000-word continuous speech recognitionsystem", Proc.
ICASSP 90, pp.
57-60, 1990.7.
Sagayama, S., "A matrix representation f HMM-based speechrecognition algorithms", Proc.
Eurospeech 91, pp.
1225-1228,1991.8.
Soong, EK., Huang, E.-E, "A tree-trellis based fast search forfinding the N best sentence hypotheses in continuous speechrecognition", Proc.
ICASSP 91, pp.
705-708, 1991.9.
Zue, V. et al, "Integration of speech recognition and naturallanguage processing in the M1T VOYAGER system", Proc.ICASSP 91, pp.
713-716, 1991.10.
Austin, S., Schwartz, R., Placeway, P., "The forward-backwardsearch algorithm", Proc.
ICASSP 91, pp.
697-700, 1991.11.
Jelinek, F., "A fast sequential decoding algorithm using astack", IBM Journal of Research and Development, 13, pp.675-685, 1969.12.
Jelinek, F., "Continuous Speech Recognition by StatisticalMethods", Proc.
IEEE, 64, 1976.13.
Seitz, F., Gupta, V., Lennig, M., Kenny, P., Deng, L., andMermelstein, P. "Dictionary for a very large vocabulary wordrecognition system," Computer, Speech and Language, 4, pp.193-202, 1990.14.
Nilsson, N., "Principles of artificial intelligence," Tioga Pub-lishing Company, 1982.15.
Gupta, V., Lennig, M., and Mermeistein, P., "Fast search strat-egy in a large vocabulary word recognizer," J. Acoust.
Soc.Am.
84(6), 2007-2017, 198816.
Kenny, P., Hollan, R., Gupta, V., Lennig, M., Mermeistein,P., and O'Shaughnessy, D., "A* - admissible heuristics forrapid lexical access", to appear in IEEE Transactions on SignalProcessing, November 1992.17.
Deng, L., Kenny, P., Lennig, M., Gupta, V., Seitz, F., andMermeistein, P., "Phonemic hidden Markov models with con-finuous mixture output densities for large vocabulary wordrecognition," IEEE Transactions on Signal Processing, 39, pp.1677-1681, 991.18.
Kenny, P., Parthasarathy, S., Gupta, V., Lennig, M., Mer-melstein, P., and O'Shaughnessy, D., "Energy, Duration andMarkov models", Proc.
Eurospeech91, pp.
655-658, 1991.19.
Lennig, M., Gupta, V., Kenny, P., Mermelstein, P.,O'Shanghnessy, D. "An 86,000-Word Recognizer Based onPhonemic Models", Proc.
DARPA Speech and Natural Lan-guage Workshop, p. 391-396, 1990.20.
Paul, D., "Algorithms for an optimal A* search and linearizingthe search in the stack decoder", Proc.
ICASSP 91, pp.
693-696, 1991.338
