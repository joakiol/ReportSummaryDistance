Large-Scale Acquisition of LCS-Based Lexiconsfor Foreign Language TutoringBonnie J. DorrDepar tment  of Computer  Sc ienceUn ivers i ty  of Mary landCo l lege Park ,  MD 20742, USAbonn ie?cs ,  urad.
eduAbst rac tWe focus on the probleln of building largerepositories of le.rical coJtceplual structure(LCS) representations for verbs in multi-ple languages.
One of the main resultsof this work is the definition of a rela-t, ion between broad semantic classes andLCS meaniug components.
Our acquisi-tion program--LEXICALL- - takes,  as in-put, the result of previous work on verbclassification and thematic grid tagging,and outputs LCS representations for differ-ent.
languages.
These representations havebeen ported into English, Arabic and Span-ish lexicons, each containing approximately9000 verbs.
We are currently using theselexicons in an operational foreign languagetutoring and machine translation.1 In t roduct ionA wide range of new capabilities in NLP applicationssuch as foreign language tutoring (FLT) has beenmade possible by recent advances in lexica.1 seman-tics (Carrier and Randall, 1993; Dowty, 1991; Fill-more, 1968; Foley and Van Valin, 1984; Grimshaw,1990; Gruber, 1965; Hale and Keyser, 1993; Jack-endoff, 1983; aackendoff, 1990: Jackendoff, 1996;Levin, 1993; Levin and Rappaport Hovav, To ap-pear; Pesetsky, 1982; Pinker, 1989).
Many of theseresearchers adopt the hypothesis that verbs can begrouped into broad classes, each of which corre-sponds to some combination of basic meaning con>ponents.
This is the basic premise underlying ourapproach to multilingual exicon construction.
Inparticular, we have organized verbs into broad se-lnantic classes and subsequently designed a set ofle,ical conceptual structures (LC, S), for each class.These representations have been ported into English,Arabic, and Spanish lexicons, each containing ap-proximately 9000 verbs.An example of a NLP application for which theselexicons are currently in use is an operational foreignlanguage tutoring (FLT) system called Military Lan-guage Tutor (MILT).
This system provides a widerange of lessons for use in language training.
Oneof the tutoring lessons, the MicroWorld Lesson (seeFigure 1) requires the capability of the language-learner to state domain-specific actions in a varietyof different ways.
For example, the language-learnermight connnand the agent (pictured at the left inthe graphical interface) to take the following action:Walt" to the table and pick up the document.
Thesame action should be taken if the user says: Go tothe table and remove document, Retrieve the docu-ment from the table, etc.
The LCS representationprovides the capability to execute various forms ofthe same command without hardcoding them as part,of the graphical interface.In another tutoring lesson, Question-Answering,the student is asked to answer questions about aforeign language text that they have read.
Theiranswer is converted into an LCS which is matchedagainst a prestored LCS corresponding to an answertyped in by a human instructor (henceforth, calledthe "author").
The prestored LCS is an idealizedform of the answer to a question, which can take oneof many forms.
Suppose, for example, the questionposed to the user is: Where did Jack put the book'?
(or Addnde paso Jack el libro?
in Spanish).
Theauthor's answer, e.g., Jack put the book in the trash,has been stored as an LCS by the tutoring system.If the student ypes Jack threw the book in the trash,or Jack moved the book from the table into the trash,the system is able to nautch against the prestoredLCS and determine that all three of these responsesare semantically appropriate.We have developed an acquisition program--LEXICALL- - that  allows us to construct LCS-basedlexicons for the FLT system.
This program is de-signed to be used for multiple languages, and also forother NLP applications (e.g., machine translation).One of the main results of this work is the definitionof a relation between broad semantic lasses (basedon work by Levin (1993)) and LCS meaning com-ponents.
We build on previous work, where verbswere classified automatically (Doff and .Jones, 1996:139Figure 1: MicroWorld Lesson in MILTx~ # , ~ .~ ~,a  ~ ~ ~ ~: ' :  ::: :Dorr, To appear) and tagged with thematic grid in-formation (Dorr, Garman, and Weinberg, 1995).
Weuse these pre-assigned classes and thematic grids asinput to LEXICALL.
The output is a set of LCS'scorresponding to individual verb entries in our lexi-con.Previous research in automatic acquisition focusesprimarily on the use of statistical techniques, such asbilingual alignment (Church and Hanks, 1990; Kla-vans and Tzoukermann, 1995; Wu and Xia, 1995)or extraction of syntactic constructions from on-line dictionaries and corpora (Brent, 1993).
Othershave taken a more knowledge-based (interlingual)approach (Lonsdale, Mitamura, and Nyberg, 1995).Still others (Copestake t al.. 1995), use English-based grammatical codes for acquisition of lexicalrepresentations.Our approach differs from these in that it exploitscertain linguistic constraints that govern the rela-tion between a word's surface behavior and its cor-responding semantic lass.
We delnonstrate that - -by assigning a LCS representatioll to each semanticclass--we can produce verb entries on a broad scale;these, in turn, are ported into multiple languages.We first show how the LCS is used in a FLT system.We then present an overview of the LCS acquisitionprocess.
Finally, we describe how LEXICALL con-structs entries for specific lexical items.2 Application of the LCSRepresentation to FLTOne of the types of knowledge that must be cap-tured in FLT is linguistic knowledge at the levelof the lexicon, which covers a wide range of infor-mation types such as verbal subcategorization forevents (e.g., that a transitive verb such as hit occurswith an object noun phrase), featural information(e.g., that the direct object of a verb such as frighlenis animate), thematic information (e.g., that Mary isthe agent in Mary hie the ball), and lexical-semanticinformation (e.g., spatial verbs such as throw areconceptually distinct fi'om verbs of possession suchas give).
By modularizing the lexicon, we treat eachinformation type separately, thus allowing us to varythe degree of dependence on each level so that wecan address the question of how much knowledge isnecessary for the success of the particular NLP ap-plication.This section describes the use of the LCS repre-sentation in a question-answering component of theMILT system (Sains, 1993; Weinberg et al, 1995).As described above, the LCS representation is usedas the basis of matching routines for assessing stu-dents' answers to free response questions about ashort foreign language passage.
In order to informthe student whether a question has been answered140Table 1: Correspondence Between NLP Output and Tutor FeedbackSystem Prompt:  Where did Jack put the book?Student Answer Prestored Answer Matcher Output  FeedbackJack threw the book in the trash Jack threw the book in the trash exact match "That's right"Jack put the book in the trash Jack threw the book in the trash missing MANNER "How?
".Jack threw the book in the trash Jack put the book in the trash extra MANNER "You're assuming things".Jack is friendly Jack put the book in the trash mismatch primitive "Please reread"Jack threw the book Jack put the book in the trash missing argument "Where?
"correctly, the author of the lesson must provide thedesired response in advance.
The system parses andsemantically analyzes the author's response into acorresponding LCS representation which is then pre-stored in a database of possible responses.
Once thequestion answering lesson is activated, each of thestudent's responses is parsed and semantically ana-lyzed into a LCS representation which is checked fora match against the corresponding prestored LCSrepresentation.
The student is then informed as towhether the question has been answered correctlydepending on how closely the student's responseLCS matches the author's prestored LCS.Consider what happens in a lesson if the authorhas specified that a correct answer to the questionAddnde paso Jack el libro?
in Spanish is Jack fir6el libro a la basura ('Jack threw out the book intothe trash').
This answer is processed by the systemto produce the following LCS:(1) \[E,'~nt CAUSE(\[Thing JACK\],\[Ev..t GOLo~(\[Thing BOOK\],\[P~th TOLo~(\[Position ATLoc(\[Thing BOOK\], \[Thing TRASH\])\])\])\],\[M ...... THROWINGLY\])\]The LCS is stored by the tutor and then latermatched against the student's answer.
If the stu-dent types Jack movio ' el libro de la mesa a la basura('Jack moved the book froln the table to the trash'),the system must determine if these two match.
Thestudent's entence is processed and the followingLCS structure is produced:(2) \[E ....
CAUSE(\[Thing JACK\],\[Event GOLoc(\[Thing BOOK\],\[Path ZOLoc (\[Position ATLo?
(\[Thing BOOK\], \[Thing TRASH\])\])\],\[Path FROMLo~ (\[Position ATLo~(\[Thing BOOK\], \[Thin~; TABLE\])\])\])\])\]The matcher compares these two, and produces thefollowing output:Missing: MANNER THROWINGLYExtra: FROM LOCThe system identifies the student's response as amatch with the prestored answer, but it also recog-nizes that there is one piece of missing informationand one piece of extra information.The "Missing" and "Extra" output is internal tothe NLP component of the Tutor, i.e., this is notthe final response displayed to the student.
The sys-tem must convert, this information into meaningfulfeedback so that the student knows how to repairthe answer that was originally given.
For example,the instructor can program the tutor to notify thestudent about the omitted information in the formof a 'How' question, or it can choose to ignore it.The extra information is generally ignored, althoughit is recorded in case the instructor decides to pro-gram the system to notify the student about thisas well.
The full range of feedback is not presentedhere.
Some possibilities are summarized (in English)in Table 1 (adapted from (Holland, 1994)).
Notethat.
the main advantage of using the LCS is that itallows the author to type in an answer that is generalenough to match any number of additional answers.3 Overv iew o f  LCS  Acqu is i t ionWe use Levin's publicly available online index(Levin, 1993) as a starting point for building LCS-based verb entries.
1 While this index provides aunique and extensive catalog of verb classes, it doesnot define the underlying meaning components ofeach class.
One of the main contributions of ourwork is that it provides a relation between Levin'sclasses and meaning components as defined in theLCS representation.Table 2 shows three broad semantic ategories andexample verbs along with their associated LCS rep-resentations.
We have band-constructed a databasecontaining 191 LCS templates, i.e., one for each verbclass in (Levin, 1993).
In addition, we have gener-a.ted LCS templates for 26 additional classes that arenot included in Levin's system.
Several of these cor-respond to verbs that take sentential complements(e.g., coerce).1We focus on building entries for verbs; however,we have approximately 30,000 non-verb entries perlanguage.141Category VerbLocation suspendtouchMotion abandonfloatPlacement adornspillTable 2: Sample Templates Stored in the LCS DatabaseClass Gr id9.2 ,ag_th, loc()47.8 th loc51.2 _th,src51.3.1 th ,s rc ( )  ,goal()9.8 _ag th ,raod-poss (with)9.5 , agthKo\]I\[CAUSE (X,\[BELo?
(Y, \[ATLo?
(Y, Z)\])\], \[BY (MANNER)\])\]\[BELo?
(Y,\[ATLo~ (Y, Z)\], \[BY (MANNER}\])\]\[GOLo~ (Y, \[(DIRECTION)Lo?
(Y, \[ATLo?
(Y, Z)\])\])\]\[GOLo?
(Y, \[BY (MANNER)\])\]\[CAUSE (X,\[GOIdent (Y,\[TOWARDId~t (Y,\[ATId?n~ (Y,\[(STATE)Id~nt (\[(WITH>po~ (*HEAD*, Z)\])\])\])\])\])\]\[CAUSE (X, \[GOLo?
(Y)\], \[BY (MANNER)\])\]A full entry in the dal:abase includes a semanticclass number with a list of possible verbs, a thematicgrid, and a LCS template:(3) Class 47.8: adjoin, intersect., meet, touch ....Themat ic  Grid: _th_locLCS Template:(be loc (thing 2)(at loc (thing 2) (thing 11))( !
!
- ing ly  26) )The semantic class label 47.8 above is taken fromLevin's 1993 book (Verbs of Contiguous Location),i.e., the class to which the verb touch has beenassigned.
2 A verb, together with its semantic lassuniquely identifies the word sense, or LCS tem-plate, to which the verb refers.
The thematic grid(_th_ loc)  indicates that the verb has two obligatoryarguments, a theme and a location.
3 The !!
in theLCS Template acts as a wildcard; it will be filled bya lexeme (i.e., a root form of the verb).
The resultingform is called a constant, i.e., the idiosyncratic partof the meaning that distinguishes among membersof a verb class (in the spirit of (Grimshaw, 1993;Levin and Rappaport Hovav, To appear; Pinker,1989; Talmy, 1985)).
4Three inputs are required for acquisition of verbentries: a semantic class, a thematic grid, anda lexeme, which we will henceforth abbreviate as"class/grid/lexeme."
The output is a Lisp-like ex-pression corresponding to the LCS representation.An example of input/output for our acquisition pro-cedure is shown here:(4) Acquisit ion of LCS for: touchInput:  47.8: _th_loc; "touch"2Verbs not occurring in Levin's book are also assignedto classes using techniques described in {Dorr and Jones,1996; Dorr, To appear).ZAn underscore (_) designates an obligatory role anda comma (,) designates an optional role.4The !
!
in the Lisp representation corresponds to theangle-bracketed constants ill Table 2, e.g., !
!
- ingly cor-responds to (MANNER}.Output :(be loc (* thing 2)(at loc (thing 2) (* thing 11))(touchingly 26) )Language-specific annotations such as the .-,uarkerin the LCS Output are added to the templates byprocessing the components of thematic grid specifi-cations, as we will see in more detail next.4 Language-Specific AnnotationsIn our on-going example (4), the thematic grid_th loc  indicates that the theme and the loca-tion are both obligatory (in English) and shouldbe annotated as such in the instantiated LCS.
Thisis achieved by inserting a *-marker appropriately.Consider the structural divergence between the fol-lowing English/Spanish equivalents:(5) Structura l  Divergence:E: John entered the house.S: John entr6 a la casa.
'John entered into the house.
'The English sentence differs structurally from theSpanish in that the noun phrase the house corre-sponds to a prepositional phrase a la casa.
Thisdistinction is characterized by different positioningsof the *-marker in the lexical entries produced byLEXICALL:(6) Lexical Entries:enter: (go loc (* thing 2)(toward loc (thing 2)(in loc (thing 2) (* thing 6)))(enteringly 26) )entrar: (go loc (* thing 2)((* toward 5) loc (thing 2)(in loc (thing 2) (thing 6)))(enteringly 26) )The lexicon entries for enter and entrar both mean"X (= Thing 2) goes into location Y (= Thing 6).
"Variable positions (designated by numbers, such as2, 5 and 6) are used in place of the ult imate fillers142such as john and house.
The structural divergenceof (,5) is a.ccomnaodated as follows: the *-marked leafnode, i.e., ( th ing  6) in the enter definition, is filleddirectly, whereas the .-marked non-leaf node, i.e.,( ( toward 5) loc  .
.
. )
in the en?rar definition, isfilled in through unification at the internal towardnode.5 Const ruct ion  o f  Lex ica l  Ent r iesC.onsider the construction of a lexical entry for theverb adorn.
The LC, S for this verb is in the class ofFill Verbs (9.8): s(7) (cause (thing 1)(go ident (thing 2)(toward ident (thing 2)(at ident (thing 2) ( !
!
-ed  9))))(with poss (*head*) (thing 16)))This list structure recursively associates logi-cal heads with their arguments and modifiers.The logical head is represented as a primi-tive/field Colnbination, e.g., GOIdent is repre-sented as (go ident  .
.
. )
.
The argumentsfor CAUSE are ( th ing  1) and (go ident  .
.
. )
.The substructure GO itself has two arguments( th ing  2) and (toward ident  .
.
. )
and a modi-fier (with poss .
.
. )
.6  The !
!
-ed constant refersto a resulting state, e.g., adorned for the verb adorn.The LC.S produced by our program for this verb is:(8) (cause (thing 1)(go ident (thing 2)(toward ident (thing 2)(at ident (thing 2) (adorned 9))))(with poss (*head*) (thing 16)))The variables in the representation map betweenLCS positions and their corresponding thematicroles.
In the LCS framework, thematic roles providesemantic information about properties of the argu-ment and modifier structures.
In (7) and (8) above,the numbers 1, 2, 9, and 16 correspond to the rolesagent (ag), theme (th), predicate (pred), and pos-sessional modifier (mod-poss), respectively.
Thesenumbers enter into the construction of LCS entries:they correspond to argument positions in the LCStemplate (extracted using the class/grid/lexemespecification), hfformatiou is filled into the LCStemplate using these numbers, coupled with the the-matic grid tag for the particular word being defined.5.1 Pundmnenta lsLEXICALL locates the appropriate template in theLCS database using the class/grid pairing as an in-5Some of the other 9.8 verbs are: anoint, bandage.flood, frame, garland, stud, s~@~se, surround, veil.6The *head* symbol--used for modifiers--is a place-holder that points to the root (cause) of the overall ex-icaJ entry.dex, and then determines the language-specifc an-notations to instantiate for that template.
The de-fault position of the .
-marker is the left-most oc-currence of the LCS node corresponding to a par-ticula.r thematic role.
However, if a preposition oc-curs in the grid, the .
-marker may be placed dif-ferently.
In such a. case, a. primitive representation(e.g., ( to loc (at  loc ) ) )  is extracted from a setof predefined mappings.
If this representation cor-responds to a subcomponent of the LCS template,the program recognizes this as a match against thegrid, and the .-marker is placed in the template atthe level where this match occurs (as in the entryfor entrar given in (6) above).If a preposition occurs in the grid but there is nomatching primitive representation, the preposition isconsidered to be a. collocation, and it is placed in aspecial s lo t - - : co l locat ions - -wh ich  indicates thatthe LCS already covers the semantics of the verband the preposition is an idiosyncratic variation (asin learn about, know of, etc.
).If a preposition is required but it is not specified(i.e., empty parentheses 0), then the .
-marker is po-sitioned at the level dominating the node that cor-responds to that role--which indicates that severaldifferent prepositions might apply (as in put on, putunder, put through, etc.
).5.2 ExamplesThe input to LEXICALL is a class/grid/lexemespecification, where each piece of information is sep-arated by a hash sign (#):<class>#<grid>#<lexeme>#<other semantic information>For example, the input specification for the verb re-plant (a word not classified by Levin) is:9.7#_ag_th,mod-poss(with)#replant#!
!-ed = planted (manner = again)This input indicates that the class assigned to re-plant is 9.7 (Levin's Spray/Load verbs) and its gridhas a.n obligatory agent (ag), theme (tit), and alloptional possessional modifer with preposition with(mod-poss (with) ).
The information following thefinal # is optional; this information was previouslyhand-added to the assigned thematic grids.
In thecurrent example, the !
!
-ed  designates the form ofthe constant planted which, in this case, is a mor-phological variant of the lexeme replant, r Also, therThe constant akes one of several forms, including:!
!
- ingly for a manner, !
!
-er  for an instrument, and!
!-ed for resulting states.
If this information has notbeen hand-added to the class/grid/lexeme specification(as is the case with most of the verbs), a default mor-phological process produces the appropriate form fromtile lexeme.143manner again is specified as an additional semanticcoin ponent .For presentational purposes, the remainder of thissection uses English examples.
However, as we sawin Section 4, the representations u ed here carry overto other languages a.s well.
In fact, we have usedthe same acquisition program, without modification,for building our Spanish and Arabic LCS-based lex-icons, each of size comparable to our English LCS-based lexicon.I.
Themat ic  Roles  w i thout  P repos i t ions(9) Example: The flower decorated the room.Input:  9.8#_mod-poss_th#decorate#Template:(be ident (thing 2)(at ident (thing 2) (!
!-ed 9))(with poss (*head*) (thing 16)))Two thematic roles, th and mod-poss, are specifiedfor the above sense of the English verb decorate.
Thethematic ode numbers--2 and 16, respectively--are.
-marked and the constant decorated replaces thewildcard:(10) Output :(be ident (* thing 2)(at ident (thing 2) (decorated 9))(with poss (*head*) (* thing 16)))I I .
Themat ic  Ro les  w i th  Unspec i f ied  P repos i -t ions(11) Example:  We parked the car near the store.We parked the car in the garage.Input:  9. l#_ag_th_goal ( )#park#Template:(cause (thing 1)(go loc (thing 2)(toward loc (thing 2)(\[at\] loc (thing 2) (thing 6))))( !
!
-ingly 26) )The input for this example indicates that the goal isheaded by an unspecifed preposition.
The thematicroles ag, th, and goa l ( )  correspond to code num-bers 1, 2, and 6, respectively.
The variable positionsfor ag and th  are .
-marked just as in the previouscase, whereas goa l ( )  requires a different reatment.When a required preposition is left.
unspecified, the.
-marker is associated with a LCS node dominatinga generic \ [at \ ]  position:(12) Output :(cause (* thing 1)(go loc (* thing 2)((* toward S) loc (thing 2)(\[at\] loc (thing 2) (thing 6))))(parkingly 26) ) }I I I .
Themat ic  ro les w i th  Spec i f ied P repos i -t ions(13) Example: We decorated the room with flowers.Input:  9.8#_ag_th ,mod-poss (with) #decorate#Template:(cause (thing 1)(go ident (thing 2)(toward ident (thing 2)(at ident (thing 2) (!
!-ed 9))))(with poss (*head*) (thing 16)))Here, the mod-poss role requires the preposition'w~th in the modifier position:(14) Output :(cause (* thing 1)(go ident (* thing 2)(toward ident (thing 2)(at ident (thing 2) (decorated 9))))((* with 15) poss (*head*) (thing 16)))In order to determine the position of the .
-markerfor a thematic role with a required preposition,LEXICALL consults a set of predefined mappingsbetween prepositions (or postpositions, in a lan-guage like Korean) and their corresponding primi-tive representations, s In the current case, the prepo-sition with is mapped to the following primitive rep-resentation: (with poss) .
Since this matches asub-component of the LCS template, the programrecognizes this as a match against the grid, and the.
-marker is placed in the template at the level ofwith.6 L imi ta t ions  and  Conc lus ionsWe have described techniques for automatic con-struction of dictionaries for use in large-scaleFLT.
The dictionaries are based on a language-independent representation called lexical conceptualstructure (LCS).
Significant enhancements o LCS-based tutoring could be achieved by combining thisrepresentation with a mechanism for handling issuesrelated to discourse and pragmatics.
For example,Mthough the LCS processor is capable of determin-ing that the phrase in the trash partially matches theanswer to Where did John put the book?, a prag-matic component would be required to determinethat this answer is (perhaps) more appropriate thanthe full answer, He put the book in the trash.
Repre-senting conversational context and dynamic contextupdating (Traum et al, 1996; Haller, 1996; DiEu-genio and Webber, 1996) would provide a fl'ame-work for this type of response "relaxation."
AlongSWe have defined approximately 100 such mappingsper language.
For example, the mapping producesthe following primitive representations for the Englishword to: (to loc (at loc) ) ,  (to poss (at poss)) ,(to temp (at temp)), (toward loc (at loc ) ) ,(toward poss (at poss)).
We have similar mappingsdefined in Arabic and Spanish.
For example, the follow-ing primitive representations are produced for the Span-ish word a: (at loc) ,  (to loc (at loc) ) ,  (to poss(at poss)) ,  (toward loc (at lo t ) ) .144these same lines, a pragmatic omponent could pro-vide a mechanism for det, ermining that certain fullymatched responses (e.g., John hurled the book inlothe trash) are not.
as "realistic sounding" as partiallymatched alternatives.Initially, LEXICALL was designed to support thedevelopment of LCS's for English only; however, thesame techniques can be used for nmltilingual acquisi-tion.
As the lexicon coverage for other languages ex-pands, it, is expected that our acquisition techniqueswill help further in the cross-linguistic investigationof the relationship between Levin's verb classes andthe basic meaning components in the LCS represen-t, ation.
In addition, it is expected that verbs in thesame Levin class may have finer distinctions thanwhat we have specified in the current LCS templates.We view the importation of LCS's from the En-glish LCS database into Arabic and Spanish asa first, approxin~ation to the development of com-plete lexicons for these languages.
The results havebeen hand-checked by native speakers using theclass/grid/lexeme format (which is much easier tocheck than the flfily expanded LCS's).
The lexicalverification process took only two weeks by the na-tive speakers.
We estimate that, it would take atleast 6 months to build such a lexicon from scratch(by human recall and data.
entry alone), and in sucha case, the potential for error would be a.t least twiceas high.One important benefit of using the Levin classi-fication as the basis of our program is that, oncethe mapping between verb classes and LCS repre-sentations has been established, we can acquire theLCS representation for a new verb (i.e., one not inLevin) simply by associating it.
with one of the 191classes.
We see our approach as a first step towardcompression of lexical entries in that it allows lex-icons to be stored in terms of the more condensedclass/grid/lexeme specifications; these can expandedonline, as needed, during sentence processing in theNLP application.We conclude that, while human intervention isnecessary for the acquisition of class/grid informa-tion, this intervention is virtually eliminated fi'omthe LCS construction process because of our pro-vision of a lnapping between semantic classes andprimitive meaning components.AcknowledgementsI would like t.o thank Jungshin Park and Mine UlkuSencan for their aid in the development of certaincomponents of the LEXICALL program.
In ad-dition, comments from five anonymous reviewersgreatly enhanced the presentation of this work.
Theauthor has been supported, in part, by Army Re-search Office contract DAAL03-91-C-0034 throughBattelle Corporation, NSF NYI IRI-9357731 andLogos Corporation, NSF CNRS INT-9314583, Ad-vanced Research Projects Agency and ONR contractN00014-92-J-1929, Alfred P. Sloan Research FellowAward BR3336, Army Research Institute contractMDA-903-92-R-0035 and Microelectronics and De-sign, Inc., and the University of Maryland GeneralResearch Board.ReferencesBrent, Michael.
1993.
Unsupervised Learningof Lexical Syntax.
Computational Linguistics,19:243-262.Carrier, .Jill and Janet H. Randall.
1993.
Lexicalmapping.
In Eric Reuland and Werner Abraham,editors, Knowledge and Language II: Lexical andConceptual Structure.
Kluwer, Dordrecht, pages119-142.Church, Kenneth and P. Hanks.
1990.
Word Asso-ciation Norms, Mutual Information and Lexicog-raphy.
Computational Linguistics, 16:22-29.Copestake, Ann, Ted Briscoe, P. Vossen, A. Ageno,I.
Cast.ellon, F. Ribas, G. Rigau, H. Rodrlguez,and A. Samiotou.
1995.
Acquisition of Lexi-cal Translation Relations from MRDS.
MachineTranslation, 9:183-219.DiEugenio, Barbara and Bonnie Lynn Webher.1996.
Pragmatic Overloading in Natural Lan-guage Instructions.
International Journal of Ex-pert Systems, 9(1):53-84.Dorr, Bonnie J.
To appear.
Large-Scale Dictio-nary Construction for Foreign Language Tutoringand Interlingual Machine Translation.
MachineTranslation, 12(1).Dorr, Bonnie J., .Joseph Garman, and Amy Wein-berg.
1995.
From Syntactic Encodings to The-matic Roles: Building Lexical Entries for Interlin-gum MT.
Machine Translation, 9:71-100.Dorr, Bonnie J. and Douglas Jones.
1996.
Roleof Word Sense Disarnbiguation in Lexical Ac-quisition: Predicting Semantics from SyntacticCues.
In Proceedings of the International Con-ference on Computational Linguistics, pages 322-333, Copenhagen, Denmark.Dowty, David.
1991.
The Effects of Aspectual Classon the Temporal Structure of Discourse: Seman-tics or Pragmatics?
Language, 67:547 619.Filhnore, Charles.
1968.
The Case for Case.
InE.
Bach and R. Harms, editors, Universals inLinguislic Theory.
Holt., Rinehart, and Winston,pages 1-88.Foley, William A. and Robert D. Van Valin.
1984.Functional Syntax and Universal Grammar.
Cam-bridge University Press, Cambridge.Grimshaw, Jane.
1990.
Argument Structure.
MITPress.
Cambridge, MA.145Grilnshaw, Jane.
1993.
Semantic Structureand Semantic Content in Lexical Representa-tion.
unpublished ms., Rutgers University, NewBrunswick, NJ.Gruber, Jeffrey S. 196.5.
Studies in Le~:ical Rela-tim~s.
Ph.D. thesis, MIT, Cambridge, MA.Hale, Ken and Samuel J. Keyser.
1993.
On Argu-ment Structure and Lexical Expression of Syntac-tic Relations.
In Ken Hale and Samuel J. Keyser,editors, The View from Building 20: Essays inHonor of Sylvain Bromberger.
MIT Press, Canl-bridge, MA.Haller, Susan.
1996.
Planning Text About Plans In-teractively.
International JourTml of Expert ,C;ys-terns, 9(1):85-112.Holland, Melissa.
1994.
Intelligent Tutors for For-eign Languages: How Parsers and Lexical Se-mantics can Help Learners and Assess Learning.In Proceedings of the Educational Testing ServiceConference on Natural Language Processing Tech-niques and Technology i7~ Assessment and Educa-tion, Princeton, NJ: ETS.Jackendoff, Ray.
1983.
Semantics and Cognition.MIT Press, Cambridge, MA.Jackendoff, Ray.
1990.
Semantic Structures.
MITPress, Cambridge, MA.Jackendoff, Ray.
1996.
The Proper Treatment ofMeasuring Out, Telicity, and Perhaps Even Quan-tification in English.
Natural Language and Lin-guistic Theory, 14:305-354.Klavans, Judith L. and Evelynne Tzoukernaann.1995.
Dictionaries and Corpora: Combining Cor-pus and Machine-Readable Dictionary Data forBuilding Bilingual Lexicons.
Machine Transla-tion, 10:185-218.Levin, Beth.
1993.
English Verb Classes and Alter-nations: A Preliminary Investigatiom Chicago,IL.Levin, Beth and Malka Rappaport Hovav.
To ap-pear.
Building Verb Meanings.
In M. Butt andW.
Gauder, editors, Th.e Projection of Argum.ents:Lexical and Syntactic Constraints.
CSLI.Lonsdale, Deryle, Teruko Mitalnura, and Eric Ny-berg.
1995.
Acquisition of Large Lexicons forPractical Knowledge-Based MT.
Machine Trans-lation, 9:251-283.Pesetsky, David.
1982.
Paths and Categories.
Ph.D.thesis, MIT, Cambridge, MA.Pinker, Steven.
1989.
Learn.ability aT~d Cognition:The Acquisition of Argument Structure.
MITPress, Cambridge, MA.Sams, Michelle.
1993.
An Intelligent Foreign Lan-guage Tutor Incorporating Natural Language Pro-cessing.
In Proceedings of (.
'onfereT~ce on h~telli-146gent Computer-Aided Training and Virtual Envi-ronmeT~t Technology, NASA: Houston, TX.Tahny, Leonard.
1985.
Lexicalization Patterns: Se-mantic Structure in Lexical Forms.
In T. Shopen,editor, Language Typology and Syntactic Descrip-tion 3: Grammatical Categories and the Lexicon.University Press, Cambridge, England, pages 57-149.Traum, David R., Lenhart K. Schu-bert, Nathaniel G. Martin, Chung Hee Hwang, Pe-ter Heeman, George Ferguson, James Allen, Mas-simo Poesio, and Marc Light.
1996.
KnowledgeRepresentation i the TRAINS-93 ConversationSystem.
International Journal of Expert Systems,9(1):173-223.Weinberg, Amy, Joseph Garman, Jeffery Martin,and Paola Merlo.
1995.
Principle-Based Parserfor Foreign Language Training in German andArabic.
In Melissa Holland, Jonathan Kaplan,and Michelle Sams, editors, Intelligent LanguageTutors: Th.eory Shaping Technology.
LawrenceErlbaum Associates, Hillsdale, NJ.Wu, D. and X. Xia.
1995.
Large-Scale AutomaticExtraction of an English-Chinese Translation Lex-icon.
Machine Translation, 9:285-313.
