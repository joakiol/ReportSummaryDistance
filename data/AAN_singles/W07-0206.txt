TextGraphs-2: Graph-Based Algorithms for Natural Language Processing, pages 37?44,Rochester, April 2007 c?2007 Association for Computational LinguisticsTransductive Structured Classification through ConstrainedMin-CutsKuzman Ganchev Fernando PereiraComputer and Information ScienceUniversity of PennsylvaniaPhiladelphia PA{kuzman,pereira}@cis.upenn.eduAbstractWe extend the Blum and Chawla(2001) graph min-cut algorithm tostructured problems.
This extensioncan alternatively be viewed as a jointinference method over a set of train-ing and test instances where parts ofthe instances interact through a pre-specified associative network.
Themethod has has an efficient approxima-tion through a linear-programming re-laxation.
On small training data sets,the method achieves up to 34.8% rela-tive error reduction.1 IntroductionWe describe a method for transductive classifi-cation in structured problems.
Our method ex-tends the Blum and Chawla (2001) algorithm fortransductive classification.
In that algorithm,each training and test instance is representedby a vertex in a graph.
The algorithm finds themin-cut that separates the positively and nega-tively labeled instances.
We give a linear pro-gram that implements an approximation of thisalgorithm and extend it in several ways.
First,our formulation can be used in cases where thereare more than two labels.
Second, we can usethe output of a classifier to provide a prior pref-erence of each instance for a particular label.This lets us trade off the strengths of the min-cut algorithm against those of a standard classi-fier.
Finally, we extend the algorithm further todeal with structured output spaces, by encodingparts of instances as well as constraints that en-sure a consistent labeling of an entire instance.The rest of this paper is organized as follows.Section 2 explains what we mean by transduc-tive classification and by structured problems.Section 3 reviews the Blum and Chawla (2001)algorithm, how we formulate it as a linear pro-gram and our proposed extensions.
Section 4relates our proposal to previous work.
Section 5describes our experimental results on real andsynthetic data and Section 6 concludes the pa-per.2 Concepts and NotationIn this work we combine two separate ap-proaches to learning: transductive methods, inwhich classification of test instances arises fromoptimizing a single objective involving bothtraining and test instances; and structured clas-sification, in which instances involve several in-terdependent classification problems.
The de-scription of structured problems also introducesuseful terminology for the rest of the paper.2.1 Transductive ClassificationIn supervised classification, training instancesare used to induce a classifier that is then ap-plied to individual test instances that need tobe classified.
In transductive classification, asingle optimization problem is set up involvingall training and test instances; the solution ofthe optimization problem yields labels for thetest instances.
In this way, the test instancesprovide evidence about the distribution of thedata, which may be useful when the labeled datais limited and the distribution of unlabeled data37Figure 1: An example where unlabeled datahelps to reveal the underlying distribution ofthe data points, borrowed from Sindhwani et al(2005).
The circles represent data points (unla-beled are empty, positive have a ?+?
and neg-ative have a ?-?).
The dashed lines representdecision boundaries for a classifier.
The first fig-ure shows the labeled data and the max-margindecision boundary (we use a linear boundary toconform with Occam?s razor principle).
The sec-ond figure shows the unlabeled data points re-vealing the distribution from which the trainingexamples were selected.
This distribution sug-gests that a linear boundary might not be ap-propriate for this data.
The final figure showsa more appropriate decision boundary given thedistribution of the unlabeled data.is informative about the location of the decisionboundary.
Figure 1 illustrates this.2.2 Structured ClassificationThe usual view of structured classification is asfollows.
An instance consists of a set of classifi-cation problems in which the labels of the differ-ent problems are correlated according to a cer-tain graphical structure.
The collection of clas-sification labels in the instance forms a singlestructured label.
A typical structured problemis part of speech (POS) tagging.
The parts ofspeech of consecutive words are strongly corre-lated, while the POS of words that are far awaydo not influence each other much.
In the natu-ral language processing tasks that motivate thiswork, we usually formalize this observation witha Markov assumption, implemented by breakingup the instance into parts consisting of pairs ofconsecutive words.
We assign a score for eachpossible label of each part and then use a dy-namic programming algorithm to find the high-est scoring label of the entire instance.In the rest of this paper, it will be sometimesmore convenient to think of all the (labeled andunlabeled) instances of interest as forming a sin-gle joint classification problem on a large graph.In this joint problem, the atomic classificationproblems are linked according to the graphicalstructure imposed by their partition into struc-tured classification instances.
As we will see,other links between atomic problems arise in oursetting that may cross between different struc-tured instances.2.3 TerminologyFor structured problems, instance refers to anentire problem (for example, an entire sentencefor POS tagging).
A token refers to the smallestunit that receives a label.
In POS tagging, a to-ken is a word.
A part is one or more tokens andis a division used by a learning algorithm.
Forall our experiments, a part is a pair of consecu-tive tokens, but extension to other types of partsis trivial.
If two parts share a token then a con-sistent label for those parts has to have the samelabel on the shared token.
For example in thesentence ?I love learning .?
we have parts for?I love?
and ?love learning?.
These share thetoken ?love?
and two labels for the two partshas to agree on the label for the token in orderto be consistent.
In all our experiments, a partis a pair of consecutive tokens so two parts areindependent unless one immediately follows theother.3 ApproachWe extend the min-cut formulation of Blum andChawla (2001) to multiple labels and structuredvariables by adapting a linear-programming en-coding of metric labeling problems.
By relaxingthe linear program, we obtain an efficient ap-proximate inference algorithm.
To understandour method, it is useful to review the min-cut transductive classification algorithm (Sec-tion 3.1) as well as the metric labeling prob-lem and its linear programming relaxation (Sec-tion 3.2).
Section 3.3 describes how to encodea multi-way min-cut problem as an instance ofmetric labeling as well as a trivial extension thatlets us introduce a bias when computing the cut.38Section 3.4 extends this formalism to structuredclassification.3.1 Min-Cuts for TransductiveClassificationBlum and Chawla (2001) present an efficientalgorithm for semi-supervised machine learningin the unstructured binary classification setting.At a high level, the algorithm is as follows:?
Construct a graph where each instance cor-responds to a vertex;?
Add weighted edges between similar ver-tices with weight proportional to a measureof similarity;?
Find the min-cut that separates positivelyand negatively labeled training instances;?
Label all instances on the positive side ofthe cut as positive and all others as nega-tive.For our purposes we need to consider two exten-sions to this problem: multi-way classificationand constrained min-cut.For multi-way classification, instead of com-puting the binary min-cut as above, we needto find the multi-way min-cut.
Unfortunately,doing this in general is NP-hard, but a poly-nomial time approximation exists (Dahlhaus etal., 1992).
In Section 3.3 we describe how weapproximate this problem.We extend this approach to structured databy constructing a graph whose vertices corre-spond to different parts of the instance, and addweighted edges between similar parts.
We thenfind the multi-way min-cut that separates ver-tices with different labels subject to some con-straints: if two parts overlap then the labels haveto be consistent.
Our main contribution is an al-gorithm that approximately computes this con-strained multi-way min-cut with a linear pro-gramming relaxation.3.2 Metric LabelingKleinberg and Tardos (1999) introduce the met-ric labeling problem as a common inferenceproblem in a variety of fields.
The inputs tothe problem are a weighted graph G = (V,E), aset of labels L = {i|i ?
1 .
.
.
k}, a cost functionc(v, i) which represents the preference of eachvertex for each possible label and a metric d(i, j)between labels i and j.
The goal is to assign alabel to each vertex l : V ?
L so as to minimizethe cost given by:c(l) =?v?V c(v, l(v))+?
(u,v)?E d(l(u), l(v)) ?
w(u, v) .
(1)Kleinberg and Tardos (1999) give a linear pro-gramming approximation for this problem withan approximation factor of two and explain howthis can be extended to an O(log k) approxima-tion for arbitrary metrics by creating a hierar-chy of labels.
Chekuri et al (2001) present animproved linear program that incorporates arbi-trary metrics directly and provides an approxi-mation at least as good as that of Kleinberg andTardos (1999).
The idea in the new linear pro-gram is to have a variable for each edge labelingas well as one for each vertex labeling.Following Chekuri et al (2001), we representthe event that vertex u has label i by the vari-able x(u, i) having the value 1; if x(u, i) = 0 thenvertex v must have some other label.
Similarly,we use the variable and value x(u, i, v, j) = 1 tomean that the vertices u and v (which are con-nected by an edge) have label i and j respec-tively.
The edge variables allow us to encodethe costs associated with violated edges in themetric labeling problem.
Edge variables shouldagree with vertex labels, and by symmetry weshould have x(u, i, v, j) = x(v, j, u, i).
If thelinear program gives an integer solution, this isclearly the optimal solution to the original met-ric labeling instance.
Chekuri et al (2001) de-scribe a rounding procedure to compute an in-teger solution to the LP that is guaranteed tobe an approximation of the optimal integer so-lution.
For the problems we considered, this wasvery rarely necessary.
Their linear program re-laxation is shown in Figure 2.
The cost functionis the sum of the vertex costs and edge costs.The first constraint requires that each vertexhave a total of one labeling unit distributed overits labels, that is, we cannot assign more or lessthan one label per vertex.
The second constraint39minXu?VXi?Lc(u, i)x(u, i)+X(u,v)?EXk,j?Lw(u, v)d(i, j)x(u, i, v, j)subject toXi?Lx(u, i) = 1 ?u ?
Vx(u, i)?Xj?Lx(u, i, v, j) = 0 ?u ?
V, v ?
N(u), i ?
Lx(u, i, v, j)?
x(v, j, u, i) = 0 ?u, v ?
V, i, j ?
Lx(u, i, v, j), x(u, i) ?
[0, 1] ?u, v ?
V, i, j ?
LFigure 2: The Chekuri et al (2001) linear pro-gram used to approximate metric labeling.
Seetext for discussion.requires that vertex- and edge-label variables areconsistent: the label that vertex variables givea vertex should agree with the labels that edgevariables give that vertex.
The third constraintimposes the edge-variable symmetry condition,and the final constraint requires that all the vari-ables be in the range [0, 1].3.3 Min Cut as an Instance of MetricLabelingGiven an instance of the (multi-way) min-cutproblem, we can translate it to an instance ofmetric labeling as follows.
The underlying graphand edge weights will be the same as min-cutproblem.
We add vertex costs (c(u, i) ?u ?V, i ?
L) and a label metric (d(i, j) ?i, j ?
L).For all unlabeled vertices set the vertex cost tozero for all labels.
For labeled vertices set thecost of the correct label to zero and all other la-bels to infinity.
Finally let d(i, j) be one if i 6= jand zero otherwise.The optimal solution to this instance of metriclabeling will be the same as the optimal solutionof the initial min cut instance: the cost of anylabeling is the number of edges that link verticeswith different labels, which is exactly the num-ber of cut edges.
Also by the same argument,every possible labeling will correspond to somecut and approximations of the metric labelingformulation will be approximations of the origi-nal min-cut problem.Since the metric labeling problem allows ar-bitrary affinities between a vertex in the graphand possible labels for that vertex, we can triv-ially extend the algorithm by introducing a biasat each vertex for labels more compatible withthat vertex.
We use the output of a classifier tobias the cost towards agreement with the clas-sifier.
Depending on the strength of the bias,we can trade off our confidence in the perfor-mance of the min-cut algorithm against the ourconfidence in a fully-supervised classifier.3.4 Extension to StructuredClassificationTo extend this further to structured classifica-tion we modify the Chekuri et al (2001) linearprogram (Figure 2).
In the structured case, weconstruct a vertex for every part of an instance.Since we want to find a consistent labeling for anentire instance composed of overlapping parts,we need to add some more constraints to the lin-ear program.
We want to ensure that if two ver-tices correspond to two overlapping parts, thenthey are assigned consistent labels, that is, thetoken shared by two parts is given the same labelby both.
First we add a new zero-weight edgebetween every pair of vertices corresponding tooverlapping parts.
Since its weight is zero, thisedge will not affect the cost.
We then add aconstraint to the linear-program that the edgevariables for inconsistent labelings of the newedges have a value of zero.More formally, let (u, i, v, j) ?
?
denote thatthe part u having label i is consistent with thepart v having label j; if u and v do not share anytokens, then any pair of labels for those parts areconsistent.
Now add zero-weight edges betweenoverlapping parts.
Then the only modificationto the linear program is thatx(u, i)?
?j?L x(u, i, v, j) = 0?u ?
V, v ?
N(u), i ?
Lwill becomex(u, i)??j:(u,i,v,j)??
x(u, i, v, j) = 0?u ?
V, v ?
N(u), i ?
L .40minXu?VXi?Lc(u, i)x(u, i)+X(u,v)?EXk,j?Lw(u, v)d(i, j)x(u, i, v, j)subject toXi?Lx(u, i) = 1 ?u ?
Vx(u, i)?Xj:(u,i,v,j)?
?x(u, i, v, j) = 0 ?u ?
V, v ?
N(u), i ?
Lx(u, i, v, j)?
x(v, j, u, i) = 0 ?
(u, i, v, j) ?
?x(u, i, v, j), x(u, i) ?
[0, 1] ?u, v ?
V, i, j ?
LFigure 3: The modified linear program used toapproximate metric labeling.
See text for dis-cussion.What this modification does is to ensure that allthe mass of the edge variables between verticesu and v lies in consistent labelings for their edge.The modified linear program is shown in Figure3.
We can show that this can be encoded asa larger instance of the metric labeling problem(with roughly |V |+|E| more vertices and a labelset that is four times as large), but modifying thelinear program directly results in a more efficientimplementation.
The final LP has one variablefor each labeling of each edge in the graph, sowe have O(|E||L|2) variables.
Note that |L| isthe number of labelings of a pair of tokens forus ?
even so, computation of a single datasettook on the order of minutes using the XpressMP package.4 Relation to Previous workOur work is set of extensions to the work of-Blum and Chawla (2001), which we have alreadydescribed.
Our extensions allow us to handlemulti-class and structured data, as well as totake hints from a classifier.
We can also spec-ify a similarity metric between labels so that acut-edge can cost different amounts dependingon what partitions it spans.Taskar et al (2004a) describe a class ofMarkov networks with associative clique poten-tials.
That is, the clique potentials always preferthat all the nodes in the clique have the samelabel.
The inference problem in these networksis to find the assignment of labels to all nodes inthe graph that maximizes the sum of the cliquepotentials.
Their paper describes a linear pro-gramming relaxation to find (or approximate)this inference problem which is very similar tothe LP formulation of Chekuri et al (2001) whenall cliques are of size 2.
They generalize thisto larger cliques and prove that their LP givesan integral solution when the label alphabet hassize 2 (even for large cliques).
For the learn-ing problem they exploit the dual of the LP for-mulation and use a maximum margin objectivesimilar to the one used by Taskar et al (2004b).If we ignore the learning problem and focus oninference, one could view our work as inferenceover a Markov network created by combining aset of linear chain conditional random fields withan associative Markov network (with arbitrarystructure).
A direction for future work would beto train the associative Markov network eitherindependently from the chain-structured modelor jointly with it.
This would be very similar tothe joint inference work described in the nextparagraph, and could be seen as a particularinstantiation of either a non-linear conditionalrandom field (Lafferty et al, 2001) or relationalMarkov network (Taskar et al, 2002).Sutton and McCallum (2004) consider the useof linear chain CRFs augmented with extra skipedges which encode a probabilistic belief thatthe labels of two entities might be correlated.They provide experimental results on named en-tity recognition for e-mail messages announcingseminars, and their system achieves a 13.7% rel-ative reduction in error on the ?Speaker?
field.Their work differs from ours in that they addskip edges only between identical capitalizedwords and only within an instance, which forthem is an e-mail message.
In particular, theycan never have an edge between labeled and un-labeled parts.
Their approach is useful for iden-tification of personal names but less helpful forother named entity tasks where the names maynot be capitalized.Lafferty et al (2004) show a representer the-orem allowing the use of Mercer kernels with41CRFs.
They use a kernel CRF with a graphkernel (Smola and Kondor, 2003) to do semi-supervised learning.
For them, the graph de-fines an implicit representation of the data, butinference is still performed only on the (chain)structure of the CRF.
By contrast, we performinference over the whole set of examples at thesame time.Altun et al (2006) extend the use of graph-based regularization to structured variables.Their work is in the framework of maximummargin learning for structured variables wherelearning is framed as an optimization problem.They modify the objective function by addinga penalty whenever two parts that are expectedto have a similar label assign a different score tothe same label.
They show improvements of upto 5.3% on two real tasks: pitch accent predic-tion and optical character recognition (OCR).Unfortunately, to solve their optimization prob-lem they have to invert an n?n matrix, where nis the number of parts in the training and test-ing data times the number of possible labels foreach part.
Because of this they are forced totrain on an unrealistically small amount of data(4-40 utterances for pitch accent prediction and10 words for OCR).5 ExperimentsWe performed experiments using our approachon three different datasets using a conditionalrandom field as the base classifier.
Unless oth-erwise noted this was regularized using a zero-mean Gaussian prior with a variance of 1.The first dataset is the pitch-accent predictiondataset used in semi-supervised learning by Al-tun et al (2006).
There are 31 real and binaryfeatures (all are encoded as real values) and onlytwo labels.
Instances correspond to an utteranceand each token corresponds to a word.
Altunet al (2006) perform experiments on 4 and 40training instances using at most 200 unlabeledinstances.The second dataset is the reference part ofthe Cora information extraction dataset.1 This1The Cora IE dataset has been used in Seymore etal.
(1999), Peng and McCallum (2004), McCallum etal.
(2000) and Han et al (2003), among others.
Weconsists of 500 computer science research papercitations.
Each token in a citation is labeled asbeing part of the name of an author, part of thetitle, part of the date or one of several otherlabels that we combined into a single category(?other?
).The third dataset is the chunking datasetfrom the CoNLL 2000 (Sang and Buchholz,2000) shared task restricted to noun phrases.The task for this dataset is, given the words in asentence as well as automatically assigned partsof speech for these words, label each word withB-NP if it is the first word in a base noun phrase,I-NP if it is part of a base noun phrase but notthe first word and O if it is not part of a nounphrase.For all experiments, we let each word be atoken and consider parts consisting of two con-secutive tokens.5.1 Pitch Accent PredictionFor the pitch accent prediction dataset, we usedthe 5-nearest neighbors of each instance accord-ing to the Euclidean distance in the original fea-ture space to construct the graph for min-cut.Table 1 shows the results of our experiments onthis data, as well as the results reported by Al-tun et al (2006).
The numbers in the table areper-token accuracy and each entry is the meanof 10 random train-test data selections.For this problem, our method improves per-formance over the base CRF classifier (exceptwhen the training data consists of only 4 utter-ances), but we do not see improvements as dra-matic as those observed by Altun et al (2006).Note that even the larger dataset here is quitesmall ?
40 utterances where each token has beenannotated with a binary value.5.2 Cora-IEFor the Cora information extraction dataset, weused the first 100 principal components of thefeature space to find 5 nearest neighbors of eachpart.
This approximation is due to the cost ofcomuting nearest neighbors in high dimensions.In these experiments we trained on 40 instancesobtained the dataset from http://www.cs.umass.edu/~mccallum/data/cora-ie.tar.gz.42Method 4:80 40:80 40:200CRF 71.2 72.5 73.1MinCut 69.4 74.4 74.3STR 70.7 75.7 77.5SVM 69.9 72.0 73.1Table 1: Results on the pitch accent predictiontask.
The methods we compare are as follows.CRF is supervised CRF training.
MinCut is ourmethod with a CRF as base classifier.
STR andSVM are the semi-supervised results reported inAltun et al (2006).
The experiments are 4 la-beled and 80 unlabeled, 40 labeled and 80 unla-beled and 40 labeled and 200 unlabeled respec-tively.Variance 10 100 1000CRF 84.5% 84.3% 83.9%MinCut 88.8% 89.6% 89.9%Table 2: Accuracy on the Cora-IE dataset asa percentage of tokens correctly classified at dif-ferent settings for the CRF variance.
Results fortraining on 40 instances and testing on 80.
Inall cases the scores are the mean of 10 randomselections of 120 instances from the set of 500available.and used 80 as testing data.
In all cases werandomly selected training and testing instances10 times from the total set of 500.
Table 2shows the average accuracies for the 10 repe-titions, with different values for the variance ofthe Gaussian prior used to regularize the CRF.If we choose the optimal value for each method,our approach gives a 34.8% relative reductionin error over the CRF, and improves over it ineach of the 10 random data selections, and allsettings of the Guassian prior variance.5.3 CoNLL NP-ChunkingOur results are worst for the CoNLL NP-Chunking dataset.
As above, we used 10 ran-dom selections of training and test sets, andused the 100 principal components of the fea-ture space to find 5 nearest neighbors of eachpart.
Table 3 shows the results of our experi-ments.
The numbers in the table are per-tokenMethod 20:40 40:80CRF 87.6 90.6MinCut(CRF) 88.2 89.6Table 3: Results on the NP-chunking task.
Thetable compares a CRF with our method using aCRF as a base classifier.
The experiments use20 labeled and 40 unlabeled and 40 labeled and80 unlabeled instances.accuracy as before.
When the amount of train-ing data is very small (20 instances) we improveslightly over the base CRF classifier, but withan increased amount of training data, the smallimprovement is replaced with a small loss.6 DiscussionWe have presented a new transductive algorithmfor structured classification, which achieves er-ror reductions on some real-world problems.
Un-fortunately, those gains are not always realized,and sometimes our approach leads to an increasein error.
The main reason that our approachdoes not always work seems to be that our mea-sure of similarity between different parts is verycoarse.
In general, finding all the pairs of partshave the same label is as difficult as finding thecorrect labeling of all instances, but it might bepossible to use unlabeled data to learn the sim-ilarity measure.ReferencesYasemin Altun, David McAllester, and MikhailBelkin.
2006.
Maximum margin semi-supervisedlearning for structured variables.
In Y. Weiss,B.
Scho?lkopf, and J. Platt, editors, Advances inNeural Information Processing Systems 18, pages33?40.
MIT Press, Cambridge, MA.Avrim Blum and Shuchi Chawla.
2001.
Learn-ing from labeled and unlabeled data using graphmincuts.
In Proceedings of the 18th InternationalConf.
on Machine Learning, pages 19?26.
MorganKaufmann, San Francisco, CA.Chandra Chekuri, Sanjeev Khanna, Joseph Naor,and Leonid Zosin.
2001.
Approximation algo-rithms for the metric labeling problem via a newlinear programming formulation.
In Symposiumon Discrete Algorithms, pages 109?118.43E.
Dahlhaus, D. S. Johnson, C. H. Papadimitriou,P.
D. Seymour, and M. Yannakakis.
1992.
Thecomplexity of multiway cuts (extended abstract).In Proceedings of the twenty-fourth annual ACMsymposium on Theory of computing, pages 241?251, New York, NY, USA.
ACM Press.H.
Han, C. Giles, E. Manavoglu, H. Zha, Z. Zhang,and E. Fox.
2003.
Automatic document meta-data extraction using support vector machines.
InJoint Conference on Digital Libraries.Jon Kleinberg and Eva Tardos.
1999.
Approx-imation algorithms for classification problemswith pairwise relationships: Metric labeling andmarkov random fields.
In Proceedings of the 40thAnnual Symposium on Foundations of ComputerScience, page 14, Washington, DC, USA.
IEEEComputer Society.John D. Lafferty, Andrew McCallum, and FernandoC.
N. Pereira.
2001.
Conditional random fields:Probabilistic models for segmenting and labelingsequence data.
In Proceedings of the 10th Inter-national Conference on Machine Learning, pages282?289, San Francisco, CA, USA.
Morgan Kauf-mann Publishers Inc.John Lafferty, Xiaojin Zhu, and Yan Liu.
2004.Kernel conditional random fields: representationand clique selection.
In Proceedings of the twenty-first international conference on Machine learn-ing, page 64, New York, NY, USA.
ACM Press.A.
McCallum, K. Nigam, J. Rennie, and K. Sey-more.
2000.
Automating the construction of in-ternet portals with machine learning.
InformationRetrieval, 3:127?163.Fuchun Peng and Andrew McCallum.
2004.Accurate information extraction from researchpapers using conditional random fields.
InDaniel Marcu Susan Dumais and Salim Roukos,editors, Main Proceedings of HLT-NAACL, pages329?336, Boston, Massachusetts, USA, May 2 -May 7.
Association for Computational Linguistics.Erik Tjong Kim Sang and Sabine Buchholz.
2000.Introduction to the CoNLL-2000 shared task:Chunking.
In Proceedings of the Fourth Confer-ence on Computational Natural Language Learn-ing and of the Second Learning Language in LogicWorkshop.
Association for Computational Lin-guistics.K.
Seymore, A. McCallum, and R. Rosenfeld.
1999.Learning hidden markov model structure for in-formation extraction.
In AAAI?99 Workshop onMachine Learning for Information Extraction.Vikas Sindhwani, Partha Niyogi, and Mikhail Belkin.2005.
Beyond the point cloud: from transductiveto semi-supervised learning.
In Proceedings of the22nd International Conference on Machine Learn-ing, pages 824?831.Alexander Smola and Risi Kondor.
2003.
Kernelsand regularization on graphs.
In M. Warmuth andB.
Scholkopf, editors, Proceedings of the SixteenthAnnual Conference on Learning Theory and Ker-nels Workshop.Charles Sutton and Andrew McCallum.
2004.
Col-lective segmentation and labeling of distant enti-ties in information extraction.
Technical ReportTR # 04-49, University of Massachusetts, July.Presented at ICML Workshop on Statistical Re-lational Learning and Its Connections to OtherFields.Ben Taskar, Abbeel Pieter, and Daphne Koller.2002.
Discriminative probabilistic models for re-lational data.
In Proceedings of the 18th An-nual Conference on Uncertainty in Artificial Intel-ligence (UAI-02), pages 485?492, San Francisco,CA.
Morgan Kaufmann Publishers.B.
Taskar, V. Chatalbashev, and D. Koller.
2004a.Learning associative markov networks.
In Pro-ceedings of the Twenty-First International Con-ference on Machine Learning (ICML).Ben Taskar, Carlos Guestrin, and Daphne Koller.2004b.
Max-margin markov networks.
In Se-bastian Thrun, Lawrence Saul, and BernhardScho?lkopf, editors, Advances in Neural Informa-tion Processing Systems 16.
MIT Press, Cam-bridge, MA.Ioannis Tsochantaridis, Thorsten Joachims, ThomasHofmann, and Yasemin Altun.
2005.
Large mar-gin methods for structured and interdependentoutput variables.
JMLR, 6:1453?1484.44
