Proceedings of the Workshop on Information Extraction Beyond The Document, pages 29?35,Sydney, July 2006. c?2006 Association for Computational LinguisticsImproving Semi-Supervised Acquisition of Relation Extraction PatternsMark A. Greenwood and Mark StevensonDepartment of Computer ScienceUniversity of SheffieldSheffield, S1 4DP, UK{m.greenwood,marks}@dcs.shef.ac.ukAbstractThis paper presents a novel approach tothe semi-supervised learning of Informa-tion Extraction patterns.
The methodmakes use of more complex patterns thanprevious approaches and determines theirsimilarity using a measure inspired by re-cent work using kernel methods (Culottaand Sorensen, 2004).
Experiments showthat the proposed similarity measure out-performs a previously reported measurebased on cosine similarity when used toperform binary relation extraction.1 IntroductionA recent approach to Information Extraction (IE)is to make use of machine learning algorithmswhich allow systems to be rapidly developed oradapted to new extraction problems.
This reducesthe need for manual development which is a majorbottleneck in the development of IE technologiesand can be extremely time consuming (e.g.
Riloff(1996)).A number of machine learning approaches haverecently been applied.
One is the use of itera-tive learning algorithms to infer extraction patternsfrom a small number of seed examples (Yangar-ber et al, 2000; Stevenson and Greenwood, 2005).These approaches use dependency analysis as thebasis of IE patterns.
Training text is parsed and aset of candidate patterns extracted.
These patternsare then compared against the seeds with the mostsimilar being selected and added to the seed set.
(Optionally, a user may verify the patterns at thispoint.)
The process is then repeated with the re-maining patterns being compared to the enlargedseed set.
The process continues until a suitable setof patterns has been learned.
These approachesrequire only a small number of example extractionpatterns which greatly reduces the effort requiredto develop IE systems.While it has been found that these approachesare capable of learning useful IE patterns froma handful of examples (Yangarber et al, 2000;Stevenson and Greenwood, 2005) they are limitedby the use of basic extraction patterns: SVO tu-ples.
The patterns used by these systems are de-fined as a verb and its direct subject and/or object.They could then only extract a limited set of re-lations; those expressed using a verb and its di-rect arguments.
For example, these patterns couldidentify the relation between Jones and Smith inthe sentence ?Jones replaced Smith?.
However,no pattern consisting of a verb and its argumentscould be constructed which could identify thesame relation in ?Jones was named as Smith?s suc-cessor.
?Others have suggested alternative approachesfor generating extraction patterns from depen-dency trees, each of which allows a particular partof the dependency analysis to act as an extractionpattern.
For example, Sudo et al (2003) used pat-terns consisting of a path from a verb to any ofits descendents (direct or indirect) while Bunescuand Mooney (2005) suggest the shortest path be-tween the items being related.
However, iterativelearning algorithms, such as the ones used by Yan-garber et al (2000) and Stevenson and Greenwood(2005), have not made use of these more complexextraction patterns.
Part of the reason for this isthat these algorithms require a way of determiningthe similarity between patterns (in order to com-pare candidate patterns with the seeds).
This pro-cess is straightforward for simple patterns, basedon SVO tuples, but less so for more complex ex-29traction patterns.In this paper we present a semi-supervised al-gorithm for the iterative learning of relation ex-traction patterns which makes use of a more com-plex pattern representation than has been previ-ously used by these approaches (Sections 2 and 3).The algorithm makes use of a similarity functionbased on those which have been proposed for usewith non-iterative learning algorithms (Zelenko etal., 2003; Culotta and Sorensen, 2004; Bunescuand Mooney, 2005).
These are extended to includeinformation about lexical similarity derived fromWordNet (Section 4).
We present results of usingpatterns acquired through this similarity functionto perform binary relation extraction (Sections 5and 6).2 Semi-Supervised Learning ofExtraction PatternsWe begin by outlining the general process of learn-ing extraction patterns using a semi-supervised al-gorithm, similar to one presented by Yangarber(2003).1.
For a given IE scenario we assume the ex-istence of a set of documents against whichthe system can be trained.
The documents areunannotated and may be either relevant (con-tain the description of an event relevant to thescenario) or irrelevant.2.
This corpus is pre-processed to generate a setof all patterns which could be used to repre-sent sentences contained in the corpus, callthis set P .
The aim of the learning process isto identify the subset of P representing pat-terns which are relevant to the IE scenario.3.
The user provides a small set of seed pat-terns, Pseed, which are relevant to the sce-nario.
These patterns are used to form theset of currently accepted patterns, Pacc, soPacc ?
Pseed.
The remaining patterns aretreated as candidates for inclusion in the ac-cepted set, these form the set Pcand(= P ?Pacc).4.
A function, f , is used to assign a score toeach pattern in Pcand based on those whichare currently in Pacc.
This function as-signs a real number to candidate patterns so?
c  Pcand, f(c, Pacc) 7?
R. A set of highscoring patterns (based on absolute scores orranks after the set of patterns has been or-dered by scores) are chosen as being suitablefor inclusion in the set of accepted patterns.These form the set Plearn.5.
(Optional) The patterns in Plearn may be re-viewed by a user who may remove any theydo not believe to be useful for the scenario.6.
The patterns in Plearn are added to Pacc andremoved from Pcand, so Pacc ?
Pacc ?Plearn and Pcand ?
Pacc ?
Plearn7.
Stop if an acceptable set of patterns has beenlearned, otherwise goto step 4Previous algorithms which use this approach in-clude those described by Yangarber et al (2000)and Stevenson and Greenwood (2005).
A keychoice in the development of an algorithm usingthis approach is the process of ranking candidatepatterns (step 4) since this determines the patternswhich will be learned at each iteration.
Yangar-ber et al (2000) chose an approach motivated bythe assumption that documents containing a largenumber of patterns already identified as relevant toa particular IE scenario are likely to contain furtherrelevant patterns.
This approach operates by asso-ciating confidence scores with patterns and rele-vance scores with documents.
Initially seed pat-terns are given a maximum confidence score of 1and all others a 0 score.
Each document is givena relevance score based on the patterns which oc-cur within it.
Candidate patterns are ranked ac-cording to the proportion of relevant and irrele-vant documents in which they occur, those foundin relevant documents far more than in irrelevantones are ranked highly.
After new patterns havebeen accepted all patterns?
confidence scores areupdated, based on the documents in which theyoccur, and documents?
relevance according to theaccepted patterns they contain.Stevenson and Greenwood (2005) suggested analternative method for ranking the candidate pat-terns.
Their approach relied on the assumptionthat useful patterns will have similar meanings tothe patterns which have already been accepted.They chose to represent each pattern as a vectorconsisting of the lexical items which formed thepattern and used a version of the cosine metric todetermine the similarity between pairs of patterns,consequently this approach is referred to as ?co-sine similarity?.
The metric used by this approachincorporated information from WordNet and as-signed high similarity scores to patterns with sim-ilar meanings expressed in different ways.30Figure 1: An example dependency tree.3 Relation Extraction PatternsBoth these approaches used extraction pat-terns which were based on dependency analysis(Tesnie?re, 1959) of text.
Under this approach thestructure of a sentence is represented by a set of di-rected binary links between a word (the head) andone of its modifiers.
These links may be labelledto indicate the grammatical relation between thehead and modifier (e.g.
subject, object).
Cycli-cal paths are generally disallowed and the analysisforms a tree structure.
An example dependencyanalysis for the sentence ?Acme Inc. hired MrSmith as their new CEO, replacing Mr Bloggs.
?is shown in Figure 1.The extraction patterns used by both Yan-garber et al (2000) and Stevenson and Green-wood (2005) were based on SVO tuples ex-tracted from dependency trees.
The depen-dency tree shown in Figure 1 would gener-ate two patterns: replace obj???
Mr Bloggsand Acme Inc.
subj???
hire obj???
Mr Smith.While these represent some of the core informa-tion in this sentence, they cannot be used to iden-tify a number of relations including the connectionbetween Mr. Smith and CEO or between Mr. Smithand Mr. Bloggs.A number of alternative approaches to con-structing extraction patterns from dependencytrees have been proposed (e.g.
(Sudo et al, 2003;Bunescu and Mooney, 2005)).
Previous analysis(Stevenson and Greenwood, 2006a) suggests thatthe most useful of these is one based on pairs oflinked chains from the dependency tree.
A chaincan be defined as a path between a verb node andany other node in the dependency tree passingthrough zero or more intermediate nodes (Sudoet al, 2001).
The linked chains model (Green-wood et al, 2005) represents extraction patternsas a pair of chains which share the same verb butno direct descendants.
It can be shown that linkedFigure 2: Example linked chain patternschain patterns can represent the majority of rela-tions within a dependency analysis (Stevenson andGreenwood, 2006a).
For example, the dependencytree shown in Figure 1 contains four named enti-ties (Acme Inc., Mr Smith, CEO and Mr. Bloggs)and linked chains patterns can be used to repre-sent the relation between any pair.1 Some exam-ple patterns extracted from the analysis in Figure 1can be seen in Figure 2.
An additional advantageof linked chain patterns is that they do not causean unwieldy number of candidate patterns to begenerated unlike some other approaches for rep-resenting extraction patterns, such as the one pro-posed by Sudo et al (2003) where any subtree ofthe dependency tree can act as a potential pattern.When used within IE systems these pat-terns are generalised by replacing termswhich refer to specific entities with a gen-eral semantic class.
For example, the patternAcme Inc.subj???
hire obj???
Mr Smithwouldbecome COMPANY subj???
hire obj???
PERSON.4 Pattern SimilarityPatterns such as linked chains have not been usedby semi-supervised approaches to pattern learn-ing.
These algorithms require a method of de-termining the similarity of patterns.
Simple pat-terns, such as SVO tuples, have a fixed structurecontaining few items and tend to occur relativelyfrequently in corpora.
However, more complexpatterns, such as linked chains, have a less fixedstructure and occur less frequently.
Consequently,the previously proposed approaches for determin-ing pattern similarity (see Section 2) are unlikelyto be as successful with these more complex pat-terns.
The approach proposed by Stevenson and1Note that we allow a linked chain pattern to represent therelation between two items when they are on the same chain,such as Mr Smith and CEO in this example.31Greenwood (2005) relies on representing patternsas vectors which is appropriate for SVO tuplesbut not when patterns may include significant por-tions of the dependency tree.
Yangarber et al(2000) suggested a method where patterns werecompared based on their distribution across doc-uments in a corpus.
However, since more complexpatterns are more specific they occur with fewercorpus instances which is likely to hamper thistype of approach.Another approach to relation extraction is to usesupervised learning algorithms, although they re-quire more training data than semi-supervised ap-proaches.
In particular various approaches (Ze-lenko et al, 2003; Culotta and Sorensen, 2004;Bunescu and Mooney, 2005) have used kernelmethods to determine the sentences in a corpuswhich contain instances of a particular relation.Kernel methods (Vapnik, 1998) allow the repre-sentation of large and complicated feature spacesand are therefore suitable when the instances arecomplex extraction rules, such as linked chains.Several previous kernels used for relation extrac-tion have been based on trees and include meth-ods based on shallow parse trees (Zelenko et al,2003), dependency trees (Culotta and Sorensen,2004) and part of a dependency tree which rep-resents the shortest path between the items be-ing related (Bunescu and Mooney, 2005).
Ker-nels methods rely on a similarity function betweenpairs of instances (the kernel) and these can beused within semi-supervised approaches to patternlearning such as those outlined in Section 2.4.1 Structural Similarity MeasureThe remainder of this Section describes a similar-ity function for pairs of linked chains, based onthe tree kernel proposed by Culotta and Sorensen(2004).
The measure compares patterns by follow-ing their structure from the root nodes through thepatterns until they diverge too far to be consideredsimilar.Each node in an extraction pattern has three fea-tures associated with it: the word, the relation toa parent, and the part-of-speech (POS) tag.
Thevalues of these features for node n are denotedby nword, nreln and npos respectively.
Pairs ofnodes can be compared by examining the values ofthese features and also by determining the seman-tic similarity of the words.
A set of four functions,F = {word, relation, pos, semantic}, is used tocompare nodes.
The first three of these correspondto the node features with the same name; the rel-evant function returns 1 if the value of the featureis equal for the two nodes and 0 otherwise.
Forexample, the pos function compares the values ofthe part of speech feature for nodes n1 and n2:pos (n1, n2) ={1 if n1, pos = n2, pos0 otherwiseThe remaining function, semantic, returns avalue between 0 and 1 to signify the semantic sim-ilarity of lexical items contained in the word fea-ture of each node.
This similarity is computed us-ing the WordNet (Fellbaum, 1998) similarity func-tion introduced by Lin (1998) .The similarity of two nodes is zero if their partof speech tags are different and, otherwise, is sim-ply the sum of the scores provided by the fourfunctions which form the set F .
This is repre-sented by the function s:s (n1, n2) ={ 0 if pos(n1, n2) = 0?f?Ff (n1, n2) otherwiseThe similarity of a pair of linked chain patterns,l1 and l2, is determined by the function sim:sim (l1, l2) =??
?0 if s (r1, r2) = 0s (r1, r2)+simc (Cr1 , Cr2) otherwisewhere r1 and r2 are the root nodes of patterns l1and l2 (respectively) and Cr is the set of childrenof node r.The final part of the similarity function calcu-lates the similarity between the child nodes of n1and n2.2simc (Cn1, Cn2) =?c1?Cn1?c2?Cn2sim (c1, c2)Using this similarity function a pair of identi-cal nodes have a similarity score of four.
Conse-quently, the similarity score for a pair of linkedchain patterns can be normalised by dividing thesimilarity score by 4 times the size (in nodes) ofthe larger pattern.
This results in a similarity func-tion that is not biased towards either small or largepatterns but will select the most similar pattern tothose already accepted as representative of the do-main.This similarity function resembles the one in-troduced by Culotta and Sorensen (2004) but also2In linked chain patterns the only nodes with multiplechildren are the root nodes so, in all but the first applica-tion, this formula can be simplified to simc (Cn1 , Cn2) =sim(c1, c2).32differs in a number of ways.
Both functions makeuse of WordNet to compare tree nodes.
Culottaand Sorensen (2004) consider whether one node isthe hypernym of the other while the approach in-troduced here makes use of existing techniques tomeasure semantic similarity.
The similarity func-tion introduced by Culotta and Sorensen (2004)compares subsequences of child nodes which isnot required for our measure since it is concernedonly with linked chain extraction patterns.5 ExperimentsThis structural similarity metric was implementedwithin the general framework for semi-supervisedpattern learning presented in Section 2.
Ateach iteration the candidate patterns are comparedagainst the set of currently accepted patterns andranked according to the average similarity with theset of similar accepted patterns.
The four highestscoring patterns are considered for acceptance buta pattern is only accepted if its score is within 0.95of the similarity of the highest scoring pattern.We conducted experiments which compared theproposed pattern similarity metric with the vec-tor space approach used by Stevenson and Green-wood (2005) (see Section 2).
That approach wasoriginally developed for simple extraction patternsconsisting of subject-verb-object tuples but wasextended for extraction patterns in the linked chainformat by Greenwood et al (2005).
We use themeasure developed by Lin (1998) to provide infor-mation about lexical similarity.
This is the samemeasure which is used within the structural simi-larity metric (Section 4).Three different configurations of the iterativelearning algorithm were compared.
(1) Cosine(SVO) This approach uses the SVO model for ex-traction patterns and the cosine similarity metricto compare them (see Section 2).
This version ofthe algorithm acts as a baseline which representspreviously reported approaches (Stevenson andGreenwood, 2005; Stevenson and Greenwood,2006b).
(2) Cosine (Linked chain) uses extrac-tion patterns based on the linked chain modelalong with the cosine similarity to compare themand is intended to determine the benefit which isgained from using the more expressive patterns.
(3) Structural (Linked chain) also uses linkedchain extraction patterns but compares them usingthe similarity measure introduced in Section 4.1.COMPANYsubj??
?appoint obj???PERSONCOMPANYsubj??
?elect obj???PERSONCOMPANYsubj??
?promote obj???PERSONCOMPANYsubj??
?name obj???PERSONPERSONsubj???resignPERSONsubj???departPERSONsubj??
?quitTable 1: Seed patterns used by the learning algo-rithm5.1 IE ScenarioExperiments were carried out on the managementsuccession extraction task used for the SixthMessage Understanding Conference (MUC-6)(MUC, 1995).
This IE scenario concerns themovement of executives between positions andcompanies.
We used a version of the evaluationdata which was produced by Soderland (1999)in which each event was converted into a set ofbinary asymmetric relations.
The corpus con-tains four types of relation: Person-Person,Person-Post, Person-Organisation,and Post-Organisation.
At each iterationof the algorithm the related items identified by thecurrent set of learned patterns are extracted fromthe text and compared against the set of relateditems which are known to be correct.
The systemsare evaluated using the widely used precision (P)and recall (R) metrics which are combined usingthe F-measure (F).The texts used for these experiments have beenpreviously annotated with named entities.
MINI-PAR (Lin, 1999), after being adapted to handle thenamed entity tags, was used to produce the depen-dency analysis from which the pattersn were gen-erated.
All experiments used the seed patterns inTable 1 which are indicative of this extraction taskand have been used in previous experiments intosemi-supervised IE pattern acquisition (Stevensonand Greenwood, 2005; Yangarber et al, 2000).The majority of previous semi-supervised ap-proaches to IE have been evaluated over prelim-inary tasks such as the identification of event par-ticipants (Sudo et al, 2003) or sentence filtering(Stevenson and Greenwood, 2005).
These may bea useful preliminary tasks but it is not clear to whatextent the success of such systems will be repeatedwhen used to perform relation extraction.
Conse-330 25 50 75 100 125 150 175 200 225 250Iteration0.000.050.100.150.200.250.300.35F-measureCosine (SVO)Cosine (Linked-Chains)Structural (Linked-Chains)Figure 3: F-measure scores for relation extractionover 250 iterationsquently we chose a relation extraction task to eval-uate the work presented here.6 ResultsResults from the relation extraction evaluation canbe seen in Table 2 and Figure 3.
The seven seedpatterns achieve a precision of 0.833 and recall of0.022.
The two approaches based on cosine sim-ilarity performs poorly, irrespective of the patternmodel being used.
The maximum increase in F-measure of 0.15 (when using the cosine measurewith the linked chain model) results in a maximumF-measure for the cosine similarity model of 0.194(with a precision of 0.491 and recall of 0.121) after200 iterations.The best result is recorded when the linkedchain model is used with the similarity measureintroduced in Section 4.1, achieving a maximumF-measure of 0.329 (with a precision of 0.434 andrecall of 0.265) after 190 iterations.
This is nota high F-measure when compared against super-vised IE systems, however it should be remem-bered that this represents an increase of 0.285 inF-measure over the original seven seed patternsand that this is achieved with a semi-supervisedalgorithm.7 ConclusionsA number of conclusions can be drawn fromthe work described in this paper.
Firstly, semi-supervised approaches to IE pattern acquisitionbenefit from the use of more expressive extractionpattern models since it has been shown that theperformance of the linked chain model on the rela-tion extraction task is superior to the simpler SVOmodel.
We have previously presented a theoret-ical analysis (Stevenson and Greenwood, 2006a)which suggested that the linked chain model was amore suitable format for IE patterns than the SVOmodel but these experiments are, to our knowl-edge, the first to show that applying this modelimproves learning performance.
Secondly, theseexperiments demonstrate that similarity measuresinspired by kernel functions developed for use insupervised learning algorithms can be applied tosemi-supervised approaches.
This suggests thatfuture work in this area should consider applyingother similarity functions, including kernel meth-ods, developed for supervised learning algorithmsto the task of semi-supervised IE pattern acquisi-tion.
Finally, we demonstrated that this similar-ity measure outperforms a previously proposed ap-proach which was based on cosine similarity and avector space representation of patterns (Stevensonand Greenwood, 2005).AcknowledgementsThis work was carried out as part of the RESuLTproject funded by the Engineering and PhysicalSciences Research Council (GR/T06391) and par-tially funded by the IST 6th Framework project X-Media (FP6-26978).ReferencesRazvan Bunescu and Raymond Mooney.
2005.
Ashortest path dependency kernel for relation extrac-tion.
In Proceedings of the Human Language Tech-nology Conference and Conference on EmpiricalMethods in Natural Language Processing, pages724?731, Vancouver, B.C.Aron Culotta and Jeffery Sorensen.
2004.
DependencyTree Kernels for Relation Extraction.
In 42nd An-nual Meeting of the Association for ComputationalLinguistics, Barcelona, Spain.Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database and some of its Applica-tions.
MIT Press, Cambridge, MA.Mark A. Greenwood, Mark Stevenson, Yikun Guo,Henk Harkema, and Angus Roberts.
2005.
Au-tomatically Acquiring a Linguistically MotivatedGenic Interaction Extraction System.
In Proceed-ings of the 4th Learning Language in Logic Work-shop (LLL05), Bonn, Germany.Dekang Lin.
1998.
An information-theoretic def-inition of similarity.
In Proceedings of the Fif-34Iteration Cosine (SVO) Cosine (Linked Chains) Structural (Linked Chains)# P R F P R F P R F0 0.833 0.022 0.044 0.833 0.022 0.044 0.833 0.022 0.04425 0.600 0.081 0.142 0.833 0.022 0.044 0.511 0.103 0.17250 0.380 0.085 0.139 0.500 0.022 0.043 0.482 0.179 0.26175 0.383 0.103 0.163 0.417 0.022 0.043 0.484 0.197 0.280100 0.383 0.103 0.163 0.385 0.022 0.042 0.471 0.220 0.300125 0.383 0.103 0.163 0.500 0.081 0.139 0.441 0.220 0.293150 0.383 0.103 0.163 0.500 0.099 0.165 0.429 0.229 0.298175 0.383 0.103 0.163 0.481 0.112 0.182 0.437 0.247 0.315200 0.383 0.103 0.163 0.491 0.121 0.194 0.434 0.265 0.329225 0.383 0.103 0.163 0.415 0.121 0.188 0.434 0.265 0.329250 0.383 0.103 0.163 0.409 0.121 0.187 0.413 0.265 0.322Table 2: Comparison of the different similarity functions when used to perform relation extractionteenth International Conference on Machine learn-ing (ICML-98), Madison, Wisconsin.Dekang Lin.
1999.
MINIPAR: A Minimalist Parser.In Maryland Linguistics Colloquium, University ofMaryland, College Park.MUC.
1995.
Proceedings of the Sixth Message Un-derstanding Conference (MUC-6), San Mateo, CA.Morgan Kaufmann.Ellen Riloff.
1996.
Automatically generating extrac-tion patterns from untagged text.
In Thirteenth Na-tional Conference on Artificial Intelligence (AAAI-96), pages 1044?1049, Portland, OR.Stephen Soderland.
1999.
Learning Information Ex-traction Rules for Semi-structured and free text.
Ma-chine Learning, 31(1-3):233?272.Mark Stevenson and Mark A. Greenwood.
2005.
ASemantic Approach to IE Pattern Induction.
In Pro-ceedings of the 43rd Annual Meeting of the Associa-tion for Computational Linguistics, pages 379?386,Ann Arbor, MI.Mark Stevenson and Mark A. Greenwood.
2006a.Comparing Information Extraction Pattern Mod-els.
In Proceedings of the Information ExtractionBeyond The Document Workshop (COLING/ACL2006), Sydney, Australia.Mark Stevenson and Mark A. Greenwood.
2006b.Learning Information Extraction Patterns usingWordNet.
In Third International Global WordNetConference (GWC-2006), Jeju Island, Korea.Kiyoshi Sudo, Satoshi Sekine, and Ralph Grishman.2001.
Automatic Pattern Acquisition for JapaneseInformation Extraction.
In Proceedings of the Hu-man Language Technology Conference (HLT2001).Kiyoshi Sudo, Satoshi Sekine, and Ralph Grishman.2003.
An Improved Extraction Pattern Representa-tion Model for Automatic IE Pattern Acquisition.
InProceedings of the 41st Annual Meeting of the As-sociation for Computational Linguistics (ACL-03),pages 224?231, Sapporo, Japan.Lucien Tesnie?re.
1959.
Eleme?nts de Syntaxe Struc-turale.
Klincksiek, Paris.Vladimir Vapnik.
1998.
Statistical Learning Theory.John Wiley and Sons.Roman Yangarber, Ralph Grishman, Pasi Tapanainen,and Silja Huttunen.
2000.
Automatic Acquisition ofDomain Knowledge for Information Extraction.
InProceedings of the 18th International Conference onComputational Linguistics (COLING 2000), pages940?946, Saarbru?cken, Germany.Roman Yangarber.
2003.
Counter-training in the Dis-covery of Semantic Patterns.
In Proceedings of the41st Annual Meeting of the Association for Compu-tational Linguistics (ACL-03), pages 343?350, Sap-poro, Japan.Dimitry Zelenko, Chinatsu Aone, and AnthonyRichardella.
2003.
Kernel methods for relation ex-traction.
Journal of Machine Learning Research,3:1083?1106.35
