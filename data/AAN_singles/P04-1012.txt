User Expertise Modelling and Adaptivityin a Speech-based E-mail SystemKristiina JOKINENUniversity of HelsinkiandUniversity of Art and Design HelsinkiH?meentie 135C00560 Helsinkikjokinen@uiah.fiKari KANTOUniversity of Art and Design HelsinkiH?meentie 135C00560 Helsinkikanto@uiah.fiAbstractThis paper describes the user expertise modelin AthosMail, a mobile, speech-based e-mailsystem.
The model encodes the system?sassumptions about the user expertise, andgives recommendations on how the systemshould respond depending on the assumedcompetence levels of the user.
Therecommendations are realized as three types ofexplicitness in the system responses.
Thesystem monitors the user?s competence withthe help of parameters that describe e.g.
thesuccess of the user?s interaction with thesystem.
The model consists of an online andan offline version, the former taking care ofthe expertise level changes during the samesession, the latter modelling the overall userexpertise as a function of time and repeatedinteractions.1 IntroductionAdaptive functionality in spoken dialogue systemsis usually geared towards dealing withcommunication disfluencies and facilitating morenatural interaction (e.g.
Danieli and Gerbino, 1995;Litman and Pan, 1999; Krahmer et al 1999;Walker et al 2000).
In the AthosMail system(Turunen et al, 2004), the focus has been onadaptivity that addresses the user?s expertise levelswith respect to a dialogue system?s functionality,and allows adaptation to take place both online andbetween the sessions.The main idea is that while novice users needguidance, it would be inefficient and annoying forexperienced users to be forced to listen to the sameinstructions every time they use the system.
Forinstance, already (Smith, 1993) observed that it issafer for beginners to be closely guided by thesystem, while experienced users like to take theinitiative which results in more efficient dialoguesin terms of decreased average completion time anda decreased average number of utterances.However, being able to decide when to switchfrom guiding a novice to facilitating an expertrequires the system to be able to keep track of theuser's expertise level.
Depending on the system,the migration from one end of the expertise scaleto the other may take anything from one session toan extended period of time.In some systems (e.g.
Chu-Carroll, 2000), userinexperience is countered with initiative shiftstowards the system, so that in the extreme case, thesystem leads the user from one task state to thenext.
This is a natural direction if the applicationincludes tasks that can be pictured as a sequence ofchoices, like choosing turns from a road map whennavigating towards a particular place.
Examples ofsuch a task structure include travel reservationsystems, where the requested information can begiven when all the relevant parameters have beencollected.
If, on the other hand, the task structure isflat, system initiative may not be very useful, sincenothing is gained by leading the user along pathsthat are only one or two steps long.Yankelovich (1996) points out that speechapplications are like command line interfaces: theavailable commands and the limitations of thesystem are not readily visible, which presents anadditional burden to the user trying to familiarizeherself with the system.
There are essentially fourways the user can learn to use a system: 1) byunaided trial and error, 2) by having a pre-usetutorial, 3) by trying to use the system and thenasking for help when in trouble, or 4) by relying onadvice the system gives when concluding the useris in trouble.
Kamm, Litman & Walker (1998)experimented with a pre-session tutorial for aspoken dialogue e-mail system and found itefficient in teaching the users what they can do;apparently this approach could be enhanced byadding items 3 and 4.
However, users often lackenthusiasm towards tutorials and want to proceedstraight to using the system.Yankelovich (1996) regards the system promptdesign at the heart of the effective interface designwhich helps users to produce well-formed spokeninput and simultaneously to become familiar withthe functionality that is available.
She introducedvarious prompt design techniques, e.g.
taperingwhich means that the system shortens the promptsfor users as they gain experience with the system,and incremental prompts, which means that when aprompt is met with silence (or a timeout occurs in agraphical interface), the repeated prompt will beincorporated with helpful hints or instructions.
Thesystem utterances are thus adapted online to mirrorthe perceived user expertise.The user model that keeps track of the perceiveduser expertise may be session-specific, but it couldalso store the information between sessions,depending on the application.
A call serviceproviding bus timetables may harmlessly assumethat the user is always new to the system, but an e-mail system is personal and the user couldpresumably benefit from personalized adaptations.If the system stores user modelling informationbetween sessions, there are two paths foradaptation: the adaptations take place betweensessions on the basis of observations made duringearlier sessions, or the system adapts online andthe resulting parameters are then passed from onesession to another by means of the user modelinformation storage.
A combination of the two isalso possible, and this is the chosen path forAthosMail as disclosed in section 3.User expertise has long been the subject of usermodelling in the related fields of text generation,question answering and tutorial systems.
Forexample, Paris (1988) describes methods for takingthe user's expertise level into account whendesigning how to tailor descriptions to the noviceand expert users.
Although the applications aresomewhat different, we expect a fair amount offurther inspiration to be forthcoming from thisdirection also.In this paper, we describe the AthosMail userexpertise model, the Cooperativity Model, anddiscuss its effect on the system behaviour.
Thepaper is organised as follows.
In Section 2 we willfirst briefly introduce the AthosMail functionalitywhich the user needs to familiarise herself with.Section 3 describes the user expertise model inmore detail.
We define the three expertise levelsand the concept of DASEX (dialogue act specificexplicitness), and present the parameters that areused to calculate the online, session-specificDASEX values as well as offline, between-the-sessions DASEX values.
We also list some of thesystem responses that correspond to the system'sassumptions about the user expertise.
In Section 4,we report on the evaluation of the system?sadaptive responses and user errors.
In Section 5,we provide conclusions and future work.2 System functionalityAthosMail is an interactive speech-based e-mailsystem being developed for mobile telephone usein the project DUMAS (Jokinen and Gamb?ck,2004).
The research goal is to investigateadaptivity in spoken dialogue systems in order toenable users to interact with the speech-basedsystems in a more flexible and natural way.
Thepractical goal of AthosMail is to give an option forvisually impaired users to check their email byvoice commands, and for sighted users to accesstheir email using a mobile phone.The functionality of the test prototype is rathersimple, comprising of three main functions:navigation in the mailbox, reading of messages,and deletion of messages.
For ease of navigation,AthosMail makes use of automatic classification ofmessages by sender, subject, topic, or otherrelevant criteria, which is initially chosen by thesystem.
The classification provides different"views" to the mailbox contents, and the user canmove from one view to the next, e.g.
from Paul'smessages to Maria's messages, with commandslike "next", "previous" or "first view", and so on.Within a particular view, the user may navigatefrom one message to another in a similar fashion,saying "next", "fourth message" or "last message",and so on.
Reading messages is straightforward,the user may say "read (the message)", when themessage in question has been selected, or refer toanother message by saying, for example, "read thethird message".
Deletion is handled in the sameway, with some room for referring expressions.The user has the option of asking the system torepeat its previous utterance.The system asks for a confirmation when theuser's command entails something that has morepotential consequences than just wasting time (bye.g.
reading the wrong message), namely, quittingand the deletion of messages.
AthosMail may alsoask for clarifications, if the speech recognition isdeemed unreliable, but otherwise the user has theinitiative.The purpose of the AthosMail user model is toprovide flexibility and variation in the systemutterances.
The system monitors the user?s actionsin general, and especially on each possible systemact.
Since the user may master some part of thesystem functionality, while not be familiar with allcommands, the system can thus provide responsestailored with respect to the user?s familiarity withindividual acts.The user model produces recommendations forthe dialogue manager on how the system shouldrespond depending on the assumed competencelevels of the user.
The user model consists ofdifferent subcomponents, such as MessagePrioritizing, Message Categorization and UserPreference components (Jokinen et al 2004).
TheCooperativity Model utilizes two parameters,explicitness and dialogue control (i.e.
initiative),and the combination of their values then guidesutterance generation.
The former is an estimate ofthe user?s competence level, and is described in thefollowing sections.3 User expertise modelling in AthosMailAthosMail uses a three-level user expertise scale toencode varied skill levels of the users.
Thecommon assumption of only two classes, expertsand novices, seems too simple a model which doesnot take into account the fact that the user'sexpertise level increases gradually, and many usersconsider themselves neither novices nor expertsbut something in between.
Moreover, the usersmay be experienced with the system selectively:they may use some commands more often thanothers, and thus their skill levels are not uniformacross the system functionality.A more fine-grained description of competenceand expertise can also be presented.
For instance,Dreyfus and Dreyfus (1986) in their studies aboutwhether it is possible to build systems that couldbehave in the way of a human expert, distinguishfive levels in skill acquisition: Novice, Advancedbeginner, Competent, Proficient, and Expert.
Inpractical dialogue systems, however, it is difficultto maintain subtle user models, and it is alsodifficult to define such observable facts that wouldallow fine-grained competence levels to bedistinguished in rather simple application tasks.We have thus ended up with a compromise, anddesigned three levels of user expertise in ourmodel: novice, competent, and expert.
These levelsare reflected in the system responses, which canvary from explicit to concise utterances dependingon how much extra information the system is togive to the user in one go.As mentioned above, one of the goals of theCooperativity model is to facilitate more naturalinteraction by allowing the system to adapt itsutterances according to the perceived expertiselevel.
On the other hand, we also want to validateand assess the usability of the three-level model ofuser expertise.
While not entering into discussionsabout the limits of rule-based thinking (e.g.
inorder to model intuitive decision making of theexperts according to the Dreyfus model), we wantto study if the designed system responses, adaptedaccording to the assumed user skill levels, canprovide useful assistance to the user in interactivesituations where she is still uncertain about how touse the system.Since the user can always ask for help explicitly,our main goal is not to study the decrease in theuser's help requests when she becomes more usedto the system, but rather, to design the systemresponses so that they would reflect the differentskill levels that the system assumes the user is on,and to get a better understanding whether theexpertise levels and their reflection in the systemresponses is valid or not, so as to provide the bestassistance for the user.3.1 Dialogue act specific explicitnessThe user expertise model utilized in AthosMail is acollection of parameters aimed at observing tell-tale signals of the user's skill level and a set ofsecond-order parameters (dialogue act specificexplicitness DASEX, and dialogue control CTL)that reflect what has been concluded from the first-order parameters.
Most first-order parameters aretuned to spot incoherence between newinformation and the current user model (seebelow).
If there's evidence that the user is actuallymore experienced than previously thought, the userexpertise model is updated to reflect this.
Theprocess can naturally proceed in the other directionas well, if the user model has been too fast inconcluding that the user has advanced to a higherlevel of expertise.
The second-order parametersaffect the system behaviour directly.
There is aseparate experience value for each systemfunction, which enables the system to behaveappropriately even if the user is very experiencedin using one function but has never used another.The higher the value, the less experienced the user;the less experienced the user, the more explicit themanner of expression and the more additionaladvice is incorporated in the system utterances.The values are called DASEX, short for DialogueAct Specific Explicitness, and their value rangecorresponds to the user expertise as follows: 1 =expert, 2 = competent, 3 = novice.The model comprises an online component andan offline component.
The former is responsiblefor observing runtime events and calculatingDASEX recommendations on the fly, whereas thelatter makes long-time observations and, based onthese, calculates default DASEX values to be usedat the beginning of the next session.
The offlinecomponent is, so to speak, rather conservative; itoperates on statistical event distributions instead ofindividual parameter values and tends to round offthe extremes, trying to catch the overall learningcurve behind the local variations.
The componentswork separately.
In the beginning of a new session,the current offline model of the user?s skill level iscopied onto the online component and used as thebasis for producing the DASEX recommendations,while at the end of each session, the offlinecomponent calculates the new default level on thebasis of the occurred events.Figure 1 provides an illustration of therelationships between the parameters.
In the nextsection we describe them in detail.3.1.1 Online parameter descriptionsThe online component can be seen as an extensionof the ideas proposed by Yankelovich (1996) andChu-Carroll (2000).
The relative weights of theparameters are those used in our user tests, partlybased on those of (Krahmer et al 1999).
They willbe fine-tuned according to our results.Figure 1 The functional relationships between the offline and online parameters used to calculatethe DASEX values.DASEX (dialogue act specific explicitness): Thevalue is modified during sessions.
Value:DDASEX (see offline parameters) modified bySDAI, HLP, TIM, and INT as specified in therespective parameter definitions.SDAI (system dialogue act invoked): A set ofparameters (one for each system dialogue act) thattracks whether a particular dialogue act has beeninvoked during the previous round.
If SDAI = 'yes',then DASEX -1.
This means that when a particularsystem dialogue move has been instantiated, itsexplicitness value is decreased and will thereforebe presented in a less explicit form the next time itis instantiated during the same session.HLP (the occurrence of a help request by theuser): The system incorporates a separate helpfunction; this parameter is only used to notify theoffline side about the frequency of help requests.TIM (the occurrence of a timeout on the user'sturn): If TIM = 'yes', then DASEX +1.
This refersto speech recognizer timeouts.INT (occurrence of a user interruption duringsystem turn): Can be either a barge-in or aninterruption by telephone keys.
If INT = 'yes', thenDASEX = 1.3.1.2 Offline parameter descriptionsDDASEX (default dialogue act specificexplicitness): Every system dialogue act has itsown default explicitness value invoked at thebeginning of a session.
Value: DASE + GEX / 2.GEX (general expertise): General expertise.
Ageneral indicator of user expertise.
Value: NSES +OHLP + OTIM / 3.DASE (dialogue act specific experience): Thisvalue is based on the number of sessions duringwhich the system dialogue act has been invoked.There is a separate DASE value for every systemdialogue act.number of sessions DASE0-2   33-6   2more than 7  1NSES (number of sessions): Based on the totalnumber of sessions the user has used the system.number of sessions NSES0-2   33-6   2more than 7  1OHLP (occurrence of help requests): Thisparameter tracks whether the user has requestedsystem help during the last 1 or 3 sessions.
TheHLP parameter is logged by the online component.HLP occurred during OHLPthe last session 3the last 3 sessions 2if not   1OTIM (occurrence of timeouts): This parametertracks whether a timeout has occurred during thelast 1 or 3 sessions.
The TIM parameter is loggedby the online component.TIM occurred during OTIMthe last session 3the last 3 sessions 2if not   13.2 DASEX-dependent surface formsEach system utterance type has three differentsurface realizations corresponding to the threeDASEX values.
The explicitness of a systemutterance can thus range between [1 = taciturn, 2 =normal, 3 = explicit]; the higher the value, themore additional information the surface realizationwill include (cf.
Jokinen and Wilcock, 2001).
Thevalue is used for choosing between the surfacerealizations which are generated by thepresentation components as natural languageutterances.
The following two examples have beentranslated from their original Finnish forms.Example 1: A speech recognition error (the ASRscore has been too low).DASEX = 1: I'm sorry, I didn't understand.DASEX = 2: I'm sorry, I didn't understand.
Pleasespeak clearly, but do not over-articulate, andspeak only after the beep.DASEX = 3: I'm sorry, I didn't understand.
Pleasespeak clearly, but do not over-articulate, andspeak only after the beep.
To hear examples ofwhat you can say to the system, say 'what now'.Example 2: Basic information about a message thatthe user has chosen from a listing of messagesfrom a particular sender.DASEX = 1: First message, about "reply: samplefile".DASEX = 2: First message, about "reply: samplefile".
Say 'tell me more', if you want more details.DASEX = 3: First message, about "reply: samplefile".
Say 'read', if you want to hear the messages,or 'tell me more', if you want to hear a summaryand the send date and length of the message.These examples show the basic idea behind theDASEX effect on surface generation.
In the firstexample, the novice user is given additionalinformation about how to try and avoid ASRproblems, while the expert user is only given theerror message.
In the second example, the expertuser gets the basic information about the messageonly, whereas the novice user is also provided withsome possible commands how to continue.
A fullinteraction with AthosMail is given in Appendix 1.4 Evaluation of AthosMailWithin the DUMAS project, we are in the processof conducting exhaustive user studies with theprototype AthosMail system that incorporates theuser expertise model described above.
We havealready conducted a preliminary qualitative expertevaluation, the goal of which was to provideinsights into the design of system utterances so asto appropriately reflect the three user expertiselevels, and the first set of user evaluations where aset of four tasks was carried out during twoconsecutive days.4.1 Adaptation and system utterancesFor the expert evaluation, we interviewed 5interactive systems experts (two women and threemen).
They all had earlier experience in interactivesystems and interface design, but were unfamiliarwith the current system and with interactive emailsystems in general.
Each interview included threewalkthroughs of the system, one for a novice, onefor a competent, and one for an expert user.
Theexperts were asked to comment on the naturalnessand appropriateness of each system utterance, aswell as provide any other comments that they mayhave on adaptation and adaptive systems.All interviewees agreed on one major theme,namely that the system should be as friendly andreassuring as possible towards novices.
Dialoguesystems can be intimidating to new users, andmany people are so afraid of making mistakes thatthey give up after the first communication failure,regardless of what caused it.
Graphical userinterfaces differ from speech interfaces in thisrespect, because there is always something salientto observe as long as the system is running at all.Four of the five experts agreed that in an errorsituation the system should always signal the userthat the machine is to blame, but there are thingsthat the user can do in case she wants to help thesystem in the task.
The system shouldacknowledge its shortcomings "humbly" and makesure that the user doesn't get feelings of guilt ?
allproblems are due to imperfect design.
E.g., theresponses in Example 1 were viewed as accusingthe user of not being able to act in the correct way.We have since moved towards forms like "I mayhave misheard", where the system appearsresponsible for the miscommunication.
This canpave the way when the user is taking the first warysteps in getting acquainted with the system.Novice users also need error messages that donot bother the user with technical matters thatconcern only the designers.
For instance, a noviceuser doesn't need information about error codes orcharacteristics of the speech recognizer; when ASRerrors occur, the system can simply talk about nothearing correctly; a reference to a piece ofequipment that does the job ?
namely, the speechrecognizer ?
is unnecessary and the user should notbe burdened with it.Experienced users, on the other hand, wish tohear only the essentials.
All our intervieweesagreed that at the highest skill level, the systemprompts should be as terse as possible, to the pointof being blunt.
Politeness words like "I'm sorry"are not necessary at this level, because the expert'sattitude towards the system is pragmatic: they seeit as a tool, know its limitations, and "rudeness" onthe part of the system doesn't scare or annoy themanymore.
However, it is not clear how the changein politeness when migrating from novice to expertlevels actually affects the user?s perception of thesystem; the transition should at least be gradualand not too fast.
There may also be culturaldifferences regarding certain politeness rules.The virtues of adaptivity are still a matter ofdebate.
One of the experts expressed serious doubtover the usability of any kind of automaticadaptivity and maintained that the user shoulddecide whether she wants the system to adapt at agiven moment or not.
In the related field oftutoring systems, Kay (2001) has argued for givingthe user the control over adaptation.
Whatever thecase, it is clear that badly designed adaptivity isconfusing to the user, and especially a novice usermay feel disoriented if faced with prompts wherenothing seems to stay the same.
It is essential thatthe system is consistent in its use of concepts, andmanner of speech.In AthosMail, the expert level (DASEX=1 forall dialogue acts) acts as the core around which theother two expertise levels are built.
While the coreremains essentially unchanged, further informationelements are added after it.
In practise, when theperceived user expertise rises, the system simplyremoves information elements that have becomeunnecessary from the end of the utterance, withouttouching the core.
This should contribute to afeeling of consistency and dependability.
On theother hand, Paris (1988) argued that the user?sexpertise level does not affect only the amount butthe kind of information given to the user.
It willprove interesting to reconcile these views in a moregeneral kind of user expertise modeling.4.2 Adaptation and user errorsThe user evaluation of AthosMail consisted of fourtasks that were performed on two consecutivedays.
The 26 test users, aged 20-62, thus producedfour separate dialogues each and a total of 104dialogues.
They had no previous experience withspeech-based dialogue systems, and to familiarizethemselves to synthesized speech and speechrecognizers, they had a short training session withanother speech application in the beginning of thefirst test session.
An outline of AthosMailfunctionality was presented to the users, and theywere allowed to keep it when interacting with thesystem.
At the end of each of the four tests, theusers were asked to assess how familiar they werewith the system functionality and how confidentthey felt about using it.
Also, they were asked toassess whether the system gave too littleinformation about its functionality, too much, orthe right amount.
The results are reported in(Jokinen et al 2004).
We also identified four errortypes, as a point of comparison for the userexpertise model.5 ConclusionsPrevious studies concerning user modelling invarious interactive applications have shown theimportance of the user model in making theinteraction with the system more enjoyable.
Wehave introduced the three-level user expertisemodel, implemented in our speech-based e-mailsystem, AthosMail, and argued for its effect on thebehaviour of the overall system.Future work will focus on analyzing the datacollected through the evaluations of the completeAthosMail system with real users.
Preliminaryexpert evaluation revealed that it is important tomake sure the novice user is not intimidated andfeels comfortable with the system, but also that theexperienced users should not be forced to listen tothe same advice every time they use the system.The hand-tagged error classification shows a slightdownward tendency in user errors, suggestingaccumulation of user experience.
This will act as apoint of comparison for the user expertise modelassembled automatically by the system.Another future research topic is to applymachine-learning and statistical techniques in theimplementation of the user expertise model.Through the user studies we will also collect datawhich we plan to use in re-implementing theDASEX decision mechanism as a Bayesiannetwork.6 AcknowledgementsThis research was carried out within the EU?sInformation Society Technologies project DUMAS(Dynamic Universal Mobility for Adaptive SpeechInterfaces), IST-2000-29452.
We thank all projectparticipants from KTH and SICS, Sweden;UMIST, UK; ETeX Sprachsynthese AG,Germany; U. of Tampere, U. of Art and Design,Connexor Oy, and Timehouse Oy, Finland.ReferencesJennifer Chu-Carroll.
2000.
MIMIC: An AdaptiveMixed Initiative Spoken Dialogue System forInformation Queries.
In Procs of ANLP 6, 2000, pp.97-104.Morena Danieli and Elisabetta Gerbino.
1995.
Metricsfor Evaluating Dialogue Strategies in a SpokenLanguage System.
Working Notes, AAAI SpringSymposium Series, Stanford University.Hubert L. Dreyfus and Stuart E. Dreyfus.
1986.
Mindover Machine: The Power of Human Intuition andExpertise in the Era of the Computer.
New York:The Free Press.Kristiina Jokinen and Bj?rn Gamb?ck.
2004.
DUMAS -Adaptation and Robust Information Processing forMobile Speech Interfaces.
Procs of The 1st BalticConference ?Human Language Technologies ?
TheBaltic Perspective?, Riga, Latvia, 115-120.Kristiina Jokinen, Kari Kanto, Antti Kerminen and JyrkiRissanen.
2004.
Evaluation of Adaptivity and UserExpertise in a Speech-based E-mail System.
Procs ofthe COLING Satellite Workshop Robust andAdaptive Information Processing for Mobile SpeechInterfaces, Geneva, Switzerland.Kristiina Jokinen and Graham Wilcock.
2001.Adaptivity and Response Generation in a SpokenDialogue System.
In van Kuppevelt, J. and R. W.Smith (eds.)
Current and New Directions inDiscourse and Dialogue.
Kluwer AcademicPublishers.
pp.
213-234.Candace Kamm, Diane Litman, and Marilyn Walker.1998.
From novice to expert: the effect of tutorials onuser expertise with spoken dialogue systems.
Procsof the International Conference on Spoken LanguageProcessing (ICSLP98).Judy Kay.
2001.
Learner control.
User Modeling andUser-Adapted Interaction 11: 111-127.Emiel Krahmer, Marc Swerts, Mariet Theune andMieke Weegels.
1999.
Problem Spotting in Human-Machine Interaction.
In Procs of Eurospeech '99.Vol.
3, 1423-1426.
Budapest, Hungary.Diane J. Litman and Shimei Pan.
2002.
Designing andEvaluating an Adaptive Spoken Dialogue System.User Modeling and User-Adapted Interaction.
Vol12(2/3):111-137.C?cile Paris.
1988.
Tailoring Descriptions to a User'sLevel of Expertise.
Journal of ComputationalLinguistics, 14 (3): 64-78.Ronnie W. Smith.
1993.
Effective Spoken NaturalLanguage Dialog Requires Variable InitiativeBehavior: An Empirical Study.
Procs of the AAAIFall Symposium on Human-Computer Collaboration:Reconciling Theory, Synthesizing Practice.M.
Turunen, E-P. Salonen, M. Hartikainen, J.Hakulinen, W.J.
Black, A: Ramsay, A. Funk, A.Conroy, P. Thompson, M. Stairmand, K. Jokinen, J.Rissanen, K. Kanto, A. Kerminen, B. Gamb?ck, M.Cheadle, F. Olsson, M. Sahlgren.
2004.
AthosMail ?a multilingual Adaptive Spoken Dialogue System forE-mail Domain.
Procs of the COLING WorkshopRobust and Adaptive Information Processing forMobile Speech Interfaces, Geneva, Switzerland.Marilyn A. Walker, Irene Langkilde, Jerry Wright,Allen Gorin, Diane J. Litman.
2000.
Learning toPredict Problematic Situations in a Spoken DialogueSystem: Experiments with How May I Help You?Procs of NAACL?00, Seattle, US, 210-217.Nicole Yankelovich.
1996.
How do users know what tosay?
Interactions 3(6): 32-43.7 Appendix 1.
Sample dialogue with anovice userSystem: Welcome to AthosMail.
Please dial your user code.User: [dials the four-digit code]S: Please dial your secret passcode.U: [dials the passcode]System: Please wait, I'll contact your mail server.
(...) HelloJukka, you have twelve unread messages.
They have beendivided into three groups.
In the first group, there are themessages about Re: Comments about the draft.
In thesecond group, the messages from Timothy.
In the thirdgroup, the rest of the messages.
You can select a group bysaying for example "first group" or "second group".
Sayhelp if you want further instructions.User: First group.S: You are in the first group, with three messages about Re:Comments about the draft.
The first message is from MattiHahtomaa, the second from Jaana Jaakkola, the third fromSakari Rantala.
If you want to select a message, say forexample "second message" or "Eddie Everyman'smessage".U: First message.S: First message, from Matti Hahtomaa, about Re: Commentsabout the draft.
If you want to hear the message, say "read".You can have additional information about the message bysaying "tell me more".U: Second message.S: Second message, from Jaana Jaakkola, about Re:Comments about the draft.
You can have additionalinformation about the message by saying "tell me more".U: Tell me more.S: Message sent on February 3rd, 2004.
Message length 24lines.U: Read Sakari Rantala's message.S: Third message, from Sakari Rantala, about Re: Commentsabout the draft.
[reads the message]Message read.
You are in the first message group.U: Quit.S: Are you sure you want to quit?
Say yes or no.U: Yes.S: Bye bye.
