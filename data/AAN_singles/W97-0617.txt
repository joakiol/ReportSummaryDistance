Towards a PURE Spoken Dia logue System for Information AccessRajeev AgarwalMedia Technologies LaboratoryTexas Ins t ruments  Inc.PO Box 655303, MS 8374 Dallas, TX  75265USArajeev@csc.ti.comAbst rac tWith the rapid explosion of the WorldWide Web, it is becoming increasingly pos-sible to easily acquire a wide variety ofinformation such as flight schedules, yel-low pages, used car prices, current stockprices, entertainment event schedules, ac-count balances, etc.
It would be veryuseful to have spoken dialogue interfacesfor such information access tasks.
Weidentify portability, usability, robustness,and extensibility as the four primary de-sign objectives for such systems.
In otherwords, the objective is to develop a PURE(Portable, Usable, Robust, Extensible) sys-tem.
A two-layered ialogue architec-ture for spoken dialogue systems is pre-sented where the upper layer is domain-independent and the lower layer is domain-specific.
We are implementing this archi-tecture in a mixed-initiative system thataccesses flight arrival/departure informa-tion from the World Wide Web.1 IntroductionWith the rapid rate at which the availability of infor-mation is increasing, it is important to make accessto this information easier.
One may wish to get thearrival/departure information for a given flight, ver-ify if a particular book is available at a library, findthe stock price for any fund, access yellow page infor-mation on-line, check/maintain voice mail remotely,get schedules for entertainment events, perform re-mote banking transactions, get used car prices, andthe list goes on and on.
Such tasks can be clas-sifted as information access (IA) tasks, where theprimary objective is to get some piece of informa-tion from a certain place by providing constraintsfor the search.
Some of these tasks may also involvean "action" that may change the state of the un-derlying database, .g., making a reservation for anevent, making transactions on an account, etc.
Itwould be very helpful to develop Spoken Dialogue(SD) interfaces for such IA applications, and severalsuch attempts are already being made (Seneff et al,1996; Sadek et al, 1996; Abella et al, 1996; Fraserand Dalsgaard, 1996; Lamel et al, 1996; Kellneret al, 1996; Niedermair, 1996; Barnett and Singh,1996; Gorin et ell., 1996).In this paper, we differentiate between such IAtasks and the more complicated problem solvingtasks where multiple sub-problems are concurrentlyactive, each with different constraints on them andthe final solution consists of identifying and meetingthe user's goals while satisfying these multiple con-straints.
Examples of such applications include asystem that offers investment advice to a user basedon personal preferences and the existing market con-ditions, or an ATIS-like application that assists theuser in travel planning including flight reservations,car rental, hotel accommodations, etc.In addition to the general requirement .ofaccuracy,there are four other important design objectives forSD systems:?
Portability of an SD system refers to the abilityof the system to be moved from one applica-tion/domain to another.?
Usability of an SD system refers to the ease withwhich a user can use the system and the natu-ralness that it provides.?
Robustness of an SD system refers to the abil-ity of the system to help the user acquire thedesired information even in the presence of userand system errors.?
Extensibility of an SD system implies that ad-ditional queries within a given application canbe added to the system without much trouble.90Input  _ \[Speech - \[S peeclvTexfflmageF~db~ks.o  I,co,- I IRecognizer UU~rance ~ Pro-processor UtteranceI Updated Grarmnarg(Based On the Dialogue State) \[lCompleteQueryInformationi ?
- ?
\ [  Generator\[ Pragmatics \]Parsed ~'- Component - \[ Parser UtteranceQuery-Relau~dInformationQueryResponseSQI..JCGI Query _ \] Dau\[ Rerrk Wet0toFigure I: Outline of the Components of the Spoken Dialogue SystemThe purpose of this paper is to describe an SDsystem, in particular the dialogue manager, that isbeing developed with these objectives in mind.
Sincethese design objectives are often conflicting in na-ture, one has to strike a balance between them.
Ina manner of speaking, one could say that the objec-tive is to create a PURE (Portable, Usable, Robust,Extensible) system.
It is our belief that it is possibleto develop an "almost" PURE system for IA tasks.2 Overa l l  Sys tem Descr ip t ionThe overall SD system is responsible for taking userutterances as input, processing them in a given con-text in an attempt to understand the user's query,and satisfying his/her request.
The user does notneed to know anything about the structure of thedatabase or the architecture of the system.
In casethe user's utterance has missing, ambiguous, incon-sistent, or erroneous information, the system en-gages the user in a dialogue to resolve these.
Thesystem is designed to be mixed-initiative, i.e., eitherthe user or the system can initiate a dialogue or sub-dialogue at any time.
The dialogue ends when theuser decides to quit the system.
The system can beused for querying a relational database using SQL orinvoking a CGI 1 script on the web.
A brief overviewof the different components i presented in Figure 1.
* Speech Recognizer: It  is responsible for rec-ognizing the user utterance and producing a1CGI stands for Common Gateway Interface.
It is atool that assists web programmers in creating interac-tive, user-driven applications.
Several web sites permitdatabase queries where the user types in the search con-straints on an HTML FORM and the server submits thisform to the CGI script which generates a response aftersearching a local database.
Note that here we refer tosuch database searches and not to the string searches asoffered by Lycos, WebCrawler, Excite, etc.recognition string.
We currently write sepa-rate context-free grammars for each state ofthe dialogue and use these to recognize theutterances with the DAGGER speech recogni-tion system described in (Hemphill and Thrift,1995).
An important feature of this recognizeris that based on the dialogue state, certaingrammars may be switched into or out of thedynamic vocabulary 2, thereby leading to betterspeech recognition accuracy.Preprocessor: This component is responsiblefor identifying domain-independent (e.g., time,place name, date) and domain-specific semanticpatterns (e.g., airport name, book title) in theinput utterance.Parser: Since user utterances could be ungram-matical in nature, a partial parser has been im-plemented to parse the input utterance into itscomponent phrases.
This provides added ro-bustness, although lack of a deep structure inthe parse sometimes causes the pragmatics com-ponent to miss useful information.Pragrnatics Component: This component is re-sponsible for identifying the values of relevantfields that are specified in the utterance, basedon the partial parse of the utterance.
It uses anapplication specific input file called the appli-cation schema, which describes all the relevantfields in that application and lexico-semanticpatterns that indicate their presence.
It also de-scribes the possible queries that may be madein that application.2Vq'e only use the grammar switching feature of DAG-GER, but it offers the ability to load completely newgrammars dynamically if such a need arises.91?
Dialogue Manager: It evaluates the knowledgeextracted by the pragmatics component to de-termine the current state of the dialogue.
Itprocesses this new dialogue state and constructsan "interaction template" that determines whatfeedback should be provided to the user.?
Query Generator: This component is respon-sible for generating a database query.
It cangenerate ither a SQL query for a relationaldatabase or a CGI script query for querying aweb site.?
?
Interactor: It is responsible for converting theinteraction template generated by the dialoguemanager into English sentences that can beprinted and/or spoken (using a text-to-speechsystem) to the user to provide feedback.
It usesa template-to-string rules file that contains rulesfor all possible types of interactions.
In somecases, it may also provide feedback by updatinga displayed image.This gives a brief overview of our SD system.The system is still under development, and is be-ing tested on the flight arrival/departure informa-tion application for which we query the AmericanAirlines web site (American Airlines, 1997).
Sys-tem development is expected to be completed soon.We have also used this system to begin developinga "Map Finder" demo that queries the MapQuestweb site (MapQuest, 1997) to display maps of anystreet address or intersection i the United States.We intend to port this system to the yellow pagesinformation access application in the near future.3 D ia logue  Manager  Des ign3.1 BackgroundExisting approaches todesigning dialogue managerscan be broadly classified into three types: graph-based, frame-based, and plan-based.
This sectiongives a brief overview of these approaches and arguesthat for IA tasks, the frame-based approaches arethe most suitable.Graph-based approaches require the entire dia-logue state transition graph for an application tobe pre-specified.
Several dialogue design toolkits areavailable to assist developers in this task, such as theSLUrp toolkit (Sutton et al, 1996), SpeechWorkstoolkit (Applied Language Technologies, 1997), orDDL-tool (Baekgaard, 1996).
It is often cumber-some and sometimes impossible to pre-specify sucha dialogue graph.
Further, such approaches are notrobust as they cannot appropriately handle any un-foreseen circumstances.92Plan-based approaches attempt o recognize theintentions of the entities involved in the discourseand interpret future utterances in this light.
Theyare usually based on some underlying discoursemodel, several of which have been developed over theyears (Cohen and Perranlt, 1979; Mann and Thomp-son, 1983; Grosz and Sidner, 1986; Carberry, 1990).We argue here that although plan-based systems arevery useful for problem-solving tasks like the onesdescribed earlier, that degree of sophistication is notneeded for IA tasks.
For example, of the five typesof intentions outlined by Grosz and Sidner (1986),only "intent hat some agent believe some fact" and"intent hat some agent know some property of anobject" are encountered in IA tasks, and they can beeasily conflated for such tasks, without any loss ofinformation.
Further, although modeling aspeaker'sintentions and the relations between them is infor-mative about the structure of the discourse, theirrecognition i  an actual system may be non-trivialand prone to errors.
Most IA tasks have only onediscourse purpose, and that is to get some informa-tion from the system.
The various discourse seg-ments are all directed at providing the system withrelevant constraints for the database query.
There-fore, explicit modeling of the discourse purpose ordiscourse segment purpose is unnecessary.Frame-based systems typically have a do-main/application model to which they map user ut-terances in an attempt to recognize the nature of theuser's query.
The constraints ofthe application drivethe analysis of utterances.
Such systems usually ig-nore phenomena like diectic references, expressionsof surprise, discourse segment shifts, etc.3.2 Two-Layered ArchitectureIt is our contention that for IA tasks, the dialoguebetween the user and the system proceeds in adomain-independent manner at a higher level andcan be described by a set of domain-independentstates.
Some domain-specific interactions are re-quired once the dialogue is in one of these higherlevel states and these can be described by a dif-ferent set of states.
This view of the structureof the dialogue led us to a two-layered architec-ture for the DM.
The upper layer is completelydomain-independent, while the lower layer has di-alogue states that constitute domain-specific sub-dialogues.
Further, although the different statesof the dialogue are pre-specified, the system auto-matically identifies what state it is in based on theuser's utterance, the result of the database query,and knowledge of the previous dialogue state.
Thisis what Fraser and Dalsgaard (1996) refer to as aUpper Layer Dialogue States Before a Database Query Upper Layer Dialogue States After a Database Query.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
I~  .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
!\].
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.Lower Layer Dialogue States (Examples)Figure 2: States in the Two-Layered Dialogue Management Architectureself-organizing system.
Most plan-based and frame-based systems are self-organizing.
The states in theDM are shown in Figure 2 and are described in detailin this section.3.2.1 Dialogue StatesAll fourteen states presented here at the top levelbelong to the upper layer of the dialogue.
For someof these upper layer states, references are made tothe lower layer states that they may spawn to ac-complish domain-specific sub-dialogues.
After everyuser utterance, the DM checks to see if the dialogueis in one of the upper layer dialogue states.
Lowerlayer states are checked only if the system is alreadyin a sub-dialogue.
The upper layer states are triedin the order in which they are described below sinceif the dialogue is in any of the earlier states, there isno point in trying later ones.
The existence of one ofthe first nine states listed below may be determinedwithout a database query.
If the dialogue is not inany one of these nine states, then there is enough in-formation to issue a query, and the dialogue may bein one of the last five states based on the results ofthe query.
The dialogue ends when the QUIT stateis reached.1.
INITIAL: This is the state in which each dia-logue starts and reverts to after a query madeby the user has been completely processed.. QUIT: If the system detects that the user wantsto terminate the current dialogue, then the di-alogne enters this state.3.
META_QUERY: The dialogue reaches thisstate when the user either explicitly asks forhelp (e.g., "Please help me," "what can I say,"etc.)
or asks for some meta-level informa-tion about the system's capabilities (e.g., "whatcities do you know about?").
The help mes-sages in the system are context-sensitive andare based on the current dialogue state.4.
OUT_OF_BOUNDS: This state is reachedwhen the system realizes that the user eitherwants to access information that the system isnot equipped to handle or access "legitimate"information in ways the system is not designedto handle.
For example, if a system is de-signed to access American Airlines flight infor-mation and the user says "what time does Deltaflight 472 reach Dallas?," the system enters theOUT_OF_BOUNDS state.
An example of animproper legitimate query could be "what timedoes my plane leave?," if the system expectsthe word 'flight' but not 'plane'.
The objectiveis not just to quit gracefully, but to allow theuser to re-enter the dialogue at some place.
Inthe first case, the system informs the user of thelimitations of the system, switches the dialogueto the INITIAL state, and permits the user torevert to some query within the bounds of thesystem.
In the second case, it informs the userthat the word 'plane' is unknown to the system,and requests him/her to rephrase the query.5.
STATUS_ Q UO: This state is reached if the sys-tem determines that the most recent utteranceby the user provided no additional query-relatedinformation to the system.
This is an indica-tion that the user was either completely silent,did not know the answer to the system's pre-vious question (may have responded by saying"I don't know" to something the system hadasked), explicitly asked the system to repeat helast feedback (may have said "Can you repeatthat"), the speech recognizer misrecognized thepart of the utterance that was meant to be in-formational, or the utterance really had no new93information.
Based on what the user said, anappropriate response is generated.6.
AMBIGUOUS: This state is reached when oneof three types of ambiguities exists in the sys-tem.
Lexical ambiguity arises if some user termmatches two entities within the same semanticclass.
For example, in a library application, ifthe user asks for "Dickens" and the databasecontains two or more authors with that lastname, this term is lexically ambiguous.
Classambiguity arises if a term may belong to twoor more semantic lasses.
In the above exam-ple, if there is also a book entitled "Dickens" inthe database, then class ambiguity exists sinceit is unknown whether the user meant the 'au-thor' or the 'title'.
This can often be resolvedbased on the surrounding context.
Field ambi-guity arises when the system has found a termthat could refer to more than one database field.For example, in a flight arrival/departure appli-cation, if the system prompts the user for eitherthe arrival city or departure city, and the userjust says "Newark," the field to which the termbelongs is ambiguous.7.
INCONSISTENT: User or system errors maysometimes lead the DM to this state where thesystem's knowledge of the various fields violatessome consistency rule.
The consistency rulesspecific to an application are provided in an in-put file.
For example, an error may cause thesystem to believe that the departure city andthe arrival city in a flights arrival/departure ap-plication are the same.
If that happens, the useris notified of the inconsistency so that the errormay be rectified.8.
CORRECTION: This state is reached when thesystem realizes that the user is attempting tocorrect either an error the user may have madeor an error made by the recognizer.
As a re-sult, the system accepts the corrected valueprovided by the user (assuming that this newvalue is correctly recognized) and provides ap-propriate feedback.
For example, in a flight ar-r ivai/departure application, the user might say"I said Dallas, not Dulles" to correct a misrecog-nition by the speech recognizer.9.
MANDATORY_FIELDS: This state is neededonly for applications in which values for certainfields must be known before a query can be is-sued.
This is often true of applications that in-voke CGI scripts on the web.
For example, theAmerican Airlines web site only permits a query9410.11.if the user specifies either the flight number, orthe arrival and departure city and approximatearrival time, or the arrival and departure cityand approximate departure time.
This stateensures that values for these mandatory fieldsare obtained from the user before issuing a CGIquery.SUCCESS: If none of the previous states werefound, a query is issued to the system.
If thisquery results in a successful match, then thedialogue is in this state.
After providing appro-priate feedback to the user, the system performsa further check to see if any "action" needs tobe carried out on the accessed item(s) of infor-mation.
For example, in a banking application,having checked the balance in a savings account,the user may now wish to transfer money fromchecking to savings.
This state usually spawns asub-dialogue which may or may not be domain-specific.
The lower level dialogue states in thissub-dialogue could be -?
VERIFY_ USER: which asks for the user'saccount ID and password,?
SIDE_EFFECTS: which informs the userof some side effects of the imposed con-straints, e.g.
"This transaction will leadto a negative balance in the checking ac-count," or?
some other domain-specific state depend-ing upon the nature of the action involved.Once in this state, the user may start a newquery, ask for more information about thematched item, or quit the system.DATABASE_CONFLICT: A database conflictarises when the constraints specified by the userdo not match any item in the database.
Thiscould be because of conflicting information fromthe user or speech recognition errors.
Such con-flicts must be resolved before proceeding in thedialogue.
Conflict resolution may be accom-plished by a sub-dialogue in the lower layer.Some of the possible states in the lower layerare :?
RELAX_ CONSTRAINT: asks the user torelax a certain constraint, e.g., "No Thairestaurant found on Legacy, but there isone on Spring Creek - is that OK?"
(thesystem needs domain-specific informationthat Legacy and Spring Creek are close toeach other).
In some cases, the system alsoneeds to know which constraints axe "ne-?
gotiable".?
CONFIRM_ VALUE: asks the user to con-firm some field values provided by the user.The confirmation is needed to ensure thatit was not a system or user error thatcaused a conflict.12.
UNKNOWN_QUERY: In most applications,the user may query for different types of in-formation.
In a yellow pages application, forexample, the user may ask about a phone num-ber, an email address, or a postal address.
TheDM may need to know what item of informa-tion the user is interested in, as this determinesthe feedback provided to the user.
This is es-pecially useful in applications without a display(queries made over the telephone) since it takestime to give more information than is necessary.Note that it is often possible to issue a databasequery even if this information is not known, andthat is why this state belongs to the set of pos-sible states after a query has been made.13.
FEW_MATCHES: If the database query resultsin a "few" matches, then the dialogue nters thisstate.
Whenever few matches are found, themost efficient way to consummate the query isto enumerate these matches o the user can theselect the one of interest.14.
MANY_MATCHES: If none of the previousstates are reached, the database query musthave resulted in too many matches, i.e., notenough information was supplied by the userto match only a single or a few database items.This state may spawn a domain-specific sub-dialogue in the lower layer, one of whose statescould be:GET_CONSTRAINT: The objective is toask the user to specify the least numberof constraints that lead to the SUCCESSstate.
So, whenever possible, this dialoguestate identifies what piece of informationwould be "most informative" at that pointin time, and asks the user to specify itsvalue.This concludes the description of the various di-alogue states.
While we have attempted to providean upper layer that covers most IA tasks, the lowerlayer states given here axe just examples of some pos-sible states.
Depending upon the application, morelower layer states can be added to improve the us-ability/robustness of the system.4 Compar i son  to  Other  ApproachesSeveral other mixed-initiative spoken dialogue sys-tems have been developed for information accesstasks (Abella et al, 1996; Bennacef et al, 1996;Kellner et al, 1996; Seneff et al, 1996; Fraser andDalsgaard, 1996; S~:lek et al, 1996; Barnett andSingh, 1996) and they provide varying degrees of di-alogue management capability.
Our dialogue man-agement approach is possibly most similar to thatproposed by Abella et al (1996), with some im-po~ant differences.
We have attempted to clearlydefine a comprehensive s t of states to handle var-ious contingencies including out-of-bounds queries,meta-queries, ambiguities, and inconsistencies dueto user/system errors.
We feel that our two-layeredarchitecture should make the system more portable.We further contend that if one encounters a dialoguestate that is not covered by our state set, it can beabstracted to an upper level state which may laterbe useful in other applications.
Abella et al (1996)do present a nice question selection methodologythat we lack 3.
We currently resort to a domain-dependent GET_CONSTRAINT state but hope toimprove on that in the future.The primary bottleneck in our system at this timeis the parser which only identifies partial parses anddoes not perform appropriate PP-attachment, con-junct identification, or do anaphora resolution or el-lipsis handling.
We need to replace the existing par-tial parser with a better parser to improve the overallsystem accuracy.5 How PURE is it?We started out by saying that the objective is todevelop a PURE spoken dialogue system for infor-mation access tasks.
We want to ensure that oursystem aims to be as PURE as it can be.
In thissection, we list those features of our system that areintended to make it PURE.?
Portability:- In  order to move the SD system to anew domain, the following files must bespecified: an application schema that wasbriefly described in Section 2; a schema-to-database mapping file that maps itemsin the application schema to the fieldsin the relational database or in the CGIscript (e.g., the flight_number schema3It may be noted that such a methodology is possibleonly with local relational databases.
It cannot be imple-mented when querying CGI scripts on the web since wedo not have access to the underlying database.95field maps to the f l tNumber field in theCGI script); a user-to-database mappingfile that consists of the various ways a usermay refer to a value of a database field(e.g., "Big Apple" maps to "New York");and a consistency-rules file.- The two-layered architecture nsures thatthe overall dialogue progresses at a domain-independent level, and keeps the domain-independent and domain-specific statesseparate.- Self-organizing dialogue structure makes itmore portable.- Partial parser can be directly ported to anew domain.?
Usability:- Mixed-initiative approach elps to promoteusability.- Feedback provided by the interactor canbe made more domain-friendly by specify-ing some extra domain-specific rules at thetop of the template-to-string rules file, sincethese rules are executed in the order spec-ified.- User may say "I don't know," "Please helpme, .... What can I say," etc.
at any time toget some guidance.
The help messages arecontext-sensitive.- We intend to add prompt randomization,as suggested by Kellner et al (1996) tomake the interactions "less boring.
"-The  OUT_OF_BOUNDS state and theMETA_QUERY state improve usability byinforming the user of why a certain utter-ance was inappropriate and allowing theuser to ask about the system's abilities re-spectively.?
Robustness:- Partial parser can handle ungrammaticalinput.- Lexico-semantic pattern matching for fieldvalues ensures that misrecognition ofa partof the utterance will still extract usefulinformation from the correctly recognizedpart.- The CORRECTION and INCONSIS-TENT states increase the robustness of thesystem by making it possible to continueeven in the presence of errors.?
Extensibility:- Additional queries can be added to any ap-plication by specifying the query seman-tics in the application schema nd any newfields that they may need.6 Final  CommentsWe have presented a dialogue management architec-ture that is mixed-initiative, self-organizing, and hasa two-layered state set whose upper layer is portableto other applications.
The system is designed togenerate ither SQL queries or CGI script queries,which makes it capable of querying the vast amountof information available on the World Wide Web.Although the generation of CGI queries is drivenby the schema-to-database and user-to-databasemappings files, some degree of application specificwork still needs to be performed.
One has to exper-iment with the web site and study the source pagesfor the HTML FORMS screens in order to createthese mappings files and possibly write additionalcode to generate the appropriate query.
For exam-ple, the American Airlines web site provides threedifferent web pages to support queries about flightarrival/departure information.
An examination ofall three source pages revealed that a hidden fieldf l tAns  gets one of three values based on which pageinvokes the script.
A special hack had to be builtinto the query generator to assign an appropriatevalue to this field.
Generation of proper user feed-back requires us to also examine the source pageof the result of the query.
The main limitation ofquerying CGI scripts is that if the web site beingqueried is modified by its creators, slight modifica-tions will have to be made to the query generator toaccommodate hose changes.Our initial experience with this system, especiallyporting it from the flights arrival/departure applica-tion to the Map Finder application, has been veryencouraging.
Map Finder is a simpler task and someof the upper layer states (UNKNOWN_QUERY,FEWMATCHES,  and MANY_MATCHES) neveroccur in this application.
An additional lower layerstate called MAP_COMMANDS had to be imple-mented under the SUCCESS state to allow the userto scroll the  displayed map in any direction usingspoken commands.
This required understanding theway the MapQuest web site handles these map nav-igation commands.
The rest of the DM was easilyported to this new application.This system is still work-in-progress and morework remains.
We intend to continue improving theexisting components while also porting the systemto other applications o that we can learn from ourporting experiences.96AcknowledgementsThe author wishes to thank Jack Godfrey for severaluseful discussions and his comments on an earlierdraft of this paper; Charles HemphiU for his com-ments and for developing and providing the DAG-GER speech recognizer; and the anonymous review-ers for their valuable suggestions that helped im-prove the final version of this paper.Re ferencesAlicia Abella, Michael K. Brown, and BruceBuntschuh.
1996.
Development principles fordialog-based interfaces.
In Dialogue Processing inSpoken Language Systems Workshop Notes, pages1-7, Budapest, Hungary, August.American Airlines.
1997.
Gates and times informa-tion request: http://www.amrcorp.com.Applied Language Technologies.
1997.http://www.altech.com/products.htm.Anders Baekgaard.
1996.
Dialogue management ia generic dialogue system.
In Proceedings of theEleventh Workshop on Language Technology: Di-alogue Management in Natural Language Systems,pages 123-132, Enschede.
University of Twente.Jim Barnett and Mona Singh.
1996.
Architecturalissues in spoken natural anguage dialogue sys-tems.
In Dialogue Processing in Spoken LanguageSystems Workshop Notes, pages 13-20, Budapest,Hungary, August.S.
K. Bennacef, L. Devillers, S. Rosset, and L. F.Lamel.
1996.
Dialog in the RAILTEL telephone-based system.
In Proceedings o/ the Fourth Inter-national Conference on Spoken Language Process-ing, volume 1, pages 550--553, October.Sandra Carberry.
1990.
Plan Recognition in NaturalLanguage Dialogue.
MIT Press, Cambridge, MA.Philip R. Cohen and Raymond C. Perrault.
1979.Elements of a plan-based theory of speech acts.Cognitive Science, 3:177-212.Norman M. Fraser and Paul Dalsgaard.
1996.
Spo-ken dialogue systems: A European perspective.In Hiroya Fujisaki, editor, Proceedings of Interna-tional Symposium on Spoken Dialogue, pages 25-36, Philadelphia, PA, October.
Acoustical Societyof Japan.A.
L. Gorin, B.
A. Parker, R. M. Sachs, and J. G.Wilpon.
1996.
How may I help you?
In Proceed-ings of the IEEE Third Workshop.on InteractiveVoice Technology for Telecommunications Appli-cations, pages 57-60.
IEEE Communications So-ciety.Barbara Grosz and Candace Sidner.
1986.
Atten-tion, intentions, and structure of discourse.
Com-putational Linguistics, 12(3):175-204.Charles Hemphill and Philip Thrift.
1995.
Surfingthe web by voice.
In Proceedings of ACM Multi-media, pages 215-222, San Francisco, CA, Novem-ber 7-9.A.
Kellner, B. Rueber, and F. Seide.
1996.
A voice-controlled automatic telephone switchboard anddirectory information system.
In Proceedings ofthe IEEE Third Workshop on Interactive VoiceTechnology \]or Telecommunications Applications,pages 117-120.
IEEE Communication Society.L.
F. Lamel, J. L. Gauvain, S. K. Bennacef, L. Dev-illers, S. Foukia, J. J. Gangolf, and S. Rosset.1996.
Field trials of a telephone service for railtravel information.
In Proceedings o\] the IEEEThird Workshop on Interactive Voice Technologyfor Telecommunications Applications, pages 111-116.
IEEE Communication Society.W.
C. Mann and S. A. Thompson.
1983.
Relationalpropositions in discourse.
Technical Report RR-83-115, Information Sciences Institute, Marina delRey, CA.MapQuest.
1997.
Interactive atlas:http://www.mapquest.com.Gerhard T. Niedermair.
1996.
A flexible call-server architecture for multi-media and speech di-alog systems.
In Proceedings of the IEEE ThirdWorkshop on Interactive Voice Technology forTelecommunications Applications, pages 29-32.IEEE Communication Society.M.
D. Sadek, A. Ferrieux, A. Cazannet, P. Bretier,F.
Panaget, and J. Simonin.
1996.
Effectivehuman-computer cooperative spoken dialogue:The AGS demonstrator.
In Hiroya Fujisaki, ed-itor, Proceedings of International Symposium onSpoken Dialogue, pages 169-172, Philadelphia,PA, October.
Acoustical Society of Japan.Stephanie Seneff, David Goddeau, Christine Pao,and Joe Polifroni.
1996.
Multimodal discoursemodelling in a multi-user multi-domain environ-ment.
In Hiroya Fujisaki, editor, Proceedingsof International Symposium on Spoken Dialogue,pages 105-108, Philadelphia, PA, October.
Acous-tical Society of Japan.Stephen Sutton, David Novick, Ronald Cole, PieterVermeulen, Jacques deVilliers, Johan Schalkwyk,and Mark Fanty.
1996.
Building 10,000 spokendialogue systems.
In Proceedings of the Fourth In-ternational Conference on Spoken Language Pro-cessing, volume 2, pages 709-712, October.9?
