Spoken Language TranslationProceedings of a WorkshopSponsored by theAssociation of Computational Linguisticsand by theEuropean Network in Language and Speech(ELSNET)Edited bySteven KrauwerDoug ArnoldWalter KasperManny RaynerHarold Somers11 July 1997Universidad Nacional de Educaci6n a DistanciaMadrid, SpainSpoken Language TranslationProceedings of a WorkshopSponsored by theAssociation of Computational Linguisticsand by theEuropean Network in Language and Speech(ELSNET)Edited bySteven KrauwerDoug ArnoldWalter KasperManny RaynerHarold Somers11 July 1997Universidad Nacional de Educaci6n a DistanciaMadrid, SpainQ1997, Association for Computational LinguisticsOrder copies of this and other ACL proceedings from:Association for Computational Linguistics (ACL)P.O.
Box 6090Somerset, NJ 08875, USA+1 908-873-3898; +1 908-873-0014 faxacl~bellcore.comhttp://www.aclweb.org/Spoken Language TranslationIn t roduct ionSteven KrauwerDoug ArnoldWalter KasperManny RaynerHarold SomersSome 15 years ago, when Machine Translation had become fashionable again in Europe, fewpeople would be prepared to consider seriously embarking upon spoken language translation (SLT).After all, where neither machine translation of written text, nor speech understanding or speechproduction had led to any significant results yet, it seemed clear that putting three not evenhalfway understood systems together would be premature, and bound to fail.Since then, the world has changed.
If we look at the papers contained in the proceedings of thisworkshop we can clearly see that many researchers, both in academia nd in industry, have takenup the challenge to build systems capable of translating spoken language.
Does that mean thatmost of the problems involved in speech-to-text, text-to-text translation, and text-to-speechhave been solved?
Or should we rather conclude that all these courageous people are heading foranother traumatic experience, just as we have seen happen in the sixties and, to a lesser extent,in the eighties.The answer to the first question is probably: No  - although we have made a tremendous progress,both from a scientific and from a technological point of view, many of the fundamental problemsin MT and in speech understanding remain unsolved.
Yet we are convinced that the bleak scenariowe mentioned as the alternative does not apply either.There are a few reasons why we feel confident that a certain degree of optimism is justified here.First of all, it is clear that on the whole people's expectations of what MT will do for them arechanging.
Where in the past the ultimate goal of MT  seemed to be to provide a perfect, butcheaper and faster alternative to the human translator, there is now a clear shift from the idealof fully automated high quality translation of unrestricted texts to the more practical problem ofovercoming the language barriers we encounter in various situations.
This shift of focus allows usto partition the problem we address into a series of smaller ones, the solution to which may bewithin our reach.
In other words, instead of trying to win the war against an enemy we are noteven sure we can see, we have decided to engage into a series of battles we can be confident ofwinning.This applies both to spoken and written language translation.
If we look at spoken communicationbetween human beings with different native languages, very often the main success criterion forthis communication is not whether or not the individual sentences produced by the participantshave been expressed or understood without errors (which will rarely be the case), but ratherwhether the intended goal of the communication has been attained (hotel room reservation, airlineinformation, etc).
This observation is extremely important when we try to set our goals for spokentranslation systems.
Once we have realized that communication takes place in a specific context,with a specific goal, and have accepted that sentence-by-sentence linguistically correct translationis not a necessary condition for successful multilingual communication, we can start exploiting thefull potential of spoken dialogues in human-human and human-machine interaction: the basicstructure of dialogues, the ways to control dialogue flow, the possibility for repair.To summarize, although many of the fundamental problems of MT and speech have not beensolved, the movement  towards more specialized systems, the redefinition of the notion of success,and the potential of dialogues, taken together, give us reason to believe that we will see manysuccessful spoken translation systems in the near future, and we hope that this workshop willcontribute to this.In the rest of the introduction we will introduce very briefly the topics of the four sessions of theworkshop.In the proceedings one will also find three 'poster papers'.
Although the workshop session itselfdid not leave space for poster presentations, we felt that it was important to dedicate a smallsection of the proceedings to short poster papers, where researchers can communicate to otherswhat they are doing, so that people who are interested in the same or related research topics knowwhere to go.Exploiting and Exploring Dialogue StructureSLT is the latest frontier for MT research - perhaps the last frontier.
A term sometimes seen usedis "Machine Interpreting", but it seems that this might apply to only one aspect of SLT, implyingsome activity similar to that of human interpreters, i.e.
simultaneous or consecutive translationof spoken language, often in the context of a meeting or someone addressing a group of people.Notice that such speech may or may not be wholly spontaneous.
This contrasts with the typeof SLT  which is the theme of this first session, and indeed more predominantly influences SLTresearch so far, namely Dialogue Translation.
Let us note in passing a third type of SLT, "Messagepassing", for example so-called "voice-mall", or real-time messages between emergency or securityservices across linguistic borders (e.g.
the Channel Tunnel).Within the subdomain of Dialogue Translation, we can make some further relevant distinctions,all of which will impinge on the design of the MT system: telephonic vs. face-to-face dialogue,co-operative vs. adversarial (Kay et a/1994:175f), involving completely or partially monolingualspeakers, with or without system-user "meta-dialogue" (Somerset a/1990), and so on.Dialogue MT introduces interesting problems beyond the already difficult issues of integratingspeech processing with translation.
As has clearly been recognised in the three papers whichmake up this opening session, identifying the special pragmatic features of spoken dialogue whichdistinguish such "texts" from the type of input that a traditional MT system might deal with isa crucial part of the problem.
Traditionally (e.g.
Hutchins & Somers 1992:92)~ the incorpora-tion of contextual knowledge into an MT system was just dismissed as impractical, or at best,uneconomical.
In a dialogue system, such an approach is unthinkable.Manfred Stede and Birte Schmitz initiate the proceedings with a close look at "discourse particles",the little words which can carry so much meaning, especially in terms of the overall dialoguestructure.
An  additional problem is that many of these particles are ambiguous in that they alsohave an interpretation not related to discourse structure.Jae-won Lee et allook at words whose translation is particularly dependent on the context, aproblem which is exacerbated in a language-pair such as Korean-English.
Their approach is toapply a statistical model of dialogue structure based on trigrams of speech acts.Keiko Horiguchi discusses meaningful "errors" in speech which convey contextual meaning or thespeaker's attitude, and then focuses on the translation of discourse particles from Japanese intoEnglish.
The approach adopted here is an analogical framework using a Cascaded Noisy ChannelModel.iiDealing with DifferencesAlthough translation of written and spoken language have much in common, there is no evading thefact that text and speech are in some ways fundamentally different modalities.
The impermanentnature of vocal communication makes speech an intrinsically more unreliable medium; conversely,a spoken utterance contains information that is only residually present in its text version, such asprosody, tone and accent.The three papers in this section explore some aspects of the SLT problem which highlight thedifferences between translation of written and spoken text.
Yumi Wakita et aldescribe a methodwhich attempts to extract the parts of a spoken utterance which have been reliably recognized,ignoring those which represent probable recognition errors.
They present results indicating thattheir method has an appreciable effect on the performance of a Japanese-English speech translationsystem.Keiko Horiguchi and Alexander Franz describe another piece of work aimed at counteractingthe problems involved in taking translation input from a speech recognizer.
They present anexample-based hybrid approach containing aspects of both corpus-based and rule-based stylesof translation architecture; this move towards hybrid architectures seems to represent a strongtendency in current work within the field of SLTFinally, Pascale Fung et alpresent a paper focussed on the problems which a speech recognizerhas to contend with in a multilingual environment, where people typically speak using a variety oflanguages and accents.
The paper describes initial experiments which investigate the parametersof the problem, and in particular explores the possibility of constructing recognizers capable ofrecognizing multilingual input.Towards EfficiencyThe papers in this section address problems of efficiency in two senses.
On  the one hand SLT hasto meet specific requirements of effciency and robustness in processing, because?
speech recognition is imperfect and the input is often not a string but a lattice of wordhypotheses representing a set of possible utterances?
spoken utterances are often linguistically not well-formed?
the translation must be available nearly simultaneously with the utterance?
the quality of the translation must be sufficiently high as in most applications post-editingis not possible.
The approach of Frederking et a/differs in this respect as it allows for userinteraction to improve the translation.To solve these problems finite state transducer technologies are often employed and investigated.The papers by Alshawi et a/and Amengual et aldiscuss different approaches along these lines.Both attempt to gain additional efficiency by a tight integration of analysis and transfer insteadof assuming two different processing stages.Another efffciency problem is that of acquiring the knowledge for building such a system.
SLTsystems are often heavily restricted to specific domains and in their vocabulary.
This raises thequestion how such systems can be adapted to new domains and vocabulary.
Therefore corpus-based statistical methods for language modelling and automatic acquisition are of special interestfor SLT as addressed in in Amengual et aland Frederking eta/.iiiMethodo log ica l  I ssuesThe common theme for the final three papers in the workshop is an emphasis on methodologyand architecture.
In the first two, the focus is on the methodology required when one moves fromone application domain to another.
In the case of the first paper, it is the move from smallerdomains to larger more inclusive domains, in the case of the second, it is the move "across" fromone domain to a distinct and separate domain of similar size.
Both papers explore the sorts ofapproach and architecture that the different sorts of move require.
Given that the state of theart in Speech Translation is such that realistic applications are restricted to particular domains,this sort of study is clearly of general importance.
The third paper, by Mark Seligman, takes abroader methodological nd architectural perspective, and identifies ix issues of importance tothe field as a whole.The first paper in the section, Lavie et al focuses on the issues that arise when one transfersfrom a relatively narrow domain (in this case, Appointment Scheduling dialogues) to a broaderdomain (Travel Planning dialogues).
The paper describes ome preliminary results of making thistransfer for the JANUS system, and some modifications that may be required.
Differences betweensmaller and larger domains include a higher out-of-vocabulary rate, a higher rate of ambiguity, andgenerally the existence of a much wider range of expressions and expressive devices in dialogueswhich make the 'semantic grammar' approach - -  which worked well in the narrower domainproblematic.
Lavie et a/'s suggestion is that this problem and the problems that arise fromincreased ambiguity can both be overcome if the larger domain can be factored into a number ofsub-domains, each of which can be given its own semantic grammar.
Such sub-grammars shouldbe far less ambiguous than a grammar for the whole domain would be, if parsing proceeds withseparate sub-grammars in parallel, which should also yield benefits in terms of processing speed.In the second paper in this section (by Carter eta/), the main issue is not how one can broaden orenlarge the domain of a system, but how one can move from one domain to a distinct, potentiallyunrelated, domain of similar size (or even to a distinct language pair, which can raise similarissues - -  this should be clear if one compares moving between pairs of very similar languageswhich may share a great deal of grammar and vocabulary with moving between very differentdomains which share very few features of grammar and vocabulary).
In other words, the focus ison the problems of customizing systems for new domains and languages.
Carter et alargue that thecharacteristics of the Core Language Engine - -  the language processing component of the systemthey are describing (SLT) -- facilitate this customization.
In particular, they suggest that the useof a general-purpose linguistic rule component, and a transfer architecture, in combination withstatistical information derived from supervised training on corpora make most of the SLT systemportable across domains, and even languages, and the remaining, non-portable, parts of the systemare such that they require relatively little expert knowledge.
This conclusion is interestingly atvariance with that of Lavie et a/in the previous paper, who argue for an interlingual approach totranslation and the use of domain-specific semantic grammars.The final contribution in this section is Mark Seligman's, which takes a personal perspectivein identifying six areas of SLT  research as particularly interesting.
(I) He argues the need forinteractive disambiguation (a view that the authors of the other papers in this section wouldprobably reject), and (2) for a particular kind of system architecture (a variant of the blackboardarchitecture incorporating a supervisory coordinator program) which may also be controversial.
(3) The third issue he addresses is that of how Speech Recognition and MT techniques houldbe integrated - -  in particular, whether a single set of techniques can or should be used to coverboth tasks, e.g.
parsing to the level of phones.
Seligman suggests that this is promising, thoughthere are technical problems.
(4) Seligman's fourth issue is how far natural pauses can be usedin segmenting utterances, and how far analysis and translation can proceed on the basis of suchsegmentation.
(5) The fifth issue recognizes the importance of Speech Act identification i dialoguetranslation, and considers how a defensible and usable classification may be found.
(6) Finally,there is the question of how one can restrict the range of candidate lexical items that have toivbe considered at each point in processing, and how candidates can be weighted appropriately.Seligman observes that accepting the importance of these issues suggests a particular architecturefor an experimental SLT system which differs from systems described in other contributions insignificant ways.Concluding RemarksAs we wdcome delegates to what we believe is the first major open meeting in Europe devotedentirely to SLT, but surely not the last, we signal yet another important milestone in the historyof Machine Translation.
Just fifty years since Warren Weaver, in his letter to Norbert Wiener(later reproduced in his famous memorandum), first expressed realistic hopes for "mechanicaltranslation" (see Hutchins, in press), we find ourselves realistically discussing the possibility ofusing computers to translate the spoken word.
Dismissed not so long ago as an impossible dream,the contributions to this workshop demonstrate that, while still perhaps something of a dream,it is far from impossible.
As the world of MT looks for new directions, SLT offers a wide rangeof new challenges.
This new focus will be reflected in a Special Issue of the journal MachineTranslation devoted to SLT, for which a call for papers will be issued soon; and already we cansee, in other MT-related conferences and publications, a clear inclination towards this problemarea.
Let us hope that in years to come, the Workshop on Spoken Language Translation atthe 1997 ACL/EACL meeting in Madrid is seen as an important and memorable vent in thedevelopment of SLT techniques.ReferencesHutchins, W. John and Harold L. Somers.
1992.
An Introduction to Machine Translation, London:Academic Press.Hutchins, John.
in press.
From first conception to first demonstration: A chronology of thenascent years of machine translation, 1947-1954.
To appear in Machine Translation, 12 (1997).Kay, Martin, Jean Mark Gawron and Peter Norvig.
1994.
Verbrnobil: A Translation System forFace-to-Face Dialog, CSLI Lecture Notes No.
33, Stanford, CA: Center for the Study of Languageand Information.Somers, Harold L., Jun-ichi Tsujii and Danny Jones.
1990.
Machine Translation without a sourcetext.
In COLING-90: Papers presented to the 13th International Conference on ComputationalLinguistics, Helsinki, Vol.3,271-276.Programme and Organizing Commit teeSteven KrauwerDoug ArnoldWalter KasperManny RaynerHarold SomersELSNET and Utrecht Institute of Linguistics OTS, Utrecht University (chair)steven.krauwer@let.ruu.nlDepartment of Language and Linguistics, University of Essex, ColchesterdougOessex.ac.ukDFKI, Saarbrfickenkaspe r O dfki.
uni- sb.
deSRI International, CambridgernannyOcarn, sri.
cornDepartment of Language Engineering, UMIST, ManchesterharoldOccl, urnist, ac.
ukWorkshop programme, Friday 11 July 199709:00 OPENING (Steven Krauwer)09:00 - 09:3009:30- 10:0010:00- 10:30Sess ion  i: EXPLOIT ING AND EXPLORING DIALOGUE STRUCTUREChair: Harold SomersDiscourse Part ic les and Rout ine Formulas in Spoken LanguageTranslat ionManfred Stede, Birte SchrnitzA Dialogue Analysis Model  with Statist ical  Speech Act Processing forDialogue Machine Translat ionJae-won Lee, Gil Chang Kim, Jungyun SeoTowards Translat ing Spoken Language Pragmat lcs  in an AnalogicalF rameworkKeiko Horiguchi10:30- 11:00 COFFEE11:00- 11:3011:30- 12:0012:00- 12:3012:30- 13:00Session 2: DEALING WITH DIFFERENCESChair: Manny RaynerCorrect  Par ts  Extract ion from Speech Recognit ion Resul ts  Us-ing Semant ic  Distance Calculation, and its Appl icat ion to SpeechTranslat ionYumi Wakita, Jun Kawai, Hitoshi IidaA Formal  Basis for Spoken Language Translat ion by AnalogyKeiko Horiguchi, Alezander FranzDeal ing with Mult i l ingual i ty in a Spoken Language Query TranslatorPascale ~ung, Bertram Shi, Dekai Wu, Lain Wai Bun, Wong Shuen KongDISCUSSION13:00- 15:00 LUNCH15:00- 15:3015:30- 16:0016:00- 16:30Session 3: TOWARDS EFFICIENCYChair: Walter KasperUsing Categories in the EUTRANS SystemJ.C.
Amengual, J.M.
Bened~, F. Casacuberta, A. Casta~o, A. Castellanos, D.Llorens, A. Marzal, F. Prat, E. Vidal, J.M.
VilarEngl ish-to-Mandar ln Speech Translat ion with Head TransducersHiyan Alshawi, Fei XiaInteract ive Speech Translat ion in the D IPLOMAT Pro jec tRobert Frederking, Alezander Rudnicky, Christopher Hogan16:30- 17:00 TEA17:00- 17:3017:30- 18:0018:00- 18:3018:30- 19:00Session 4: METHODOLOGICAL  ISSUESChair: Doug ArnoldExpanding the Domain  of a Mult i l ingual Speech-to-Speech Transla-t ion SystemAlon Lavie, Lori Levin, Puming Zhan, Maite Taboada, Donna Gates, MirellaLapata, Cortis Clark, Matthew Broadhead, Alez WaibelTranslat ion Methodo logy  in the Spoken Language Translator:  AnEvaluat ionDavid Carter, Ralph Becket, Manny Rayner, Robert Eklund, Catriona MacDer-mid, Mats Wirdn, Sabine Kirchmeier-Andersen, Christina PhilpSix Issues in Speech Translat ionMark SeligmanDISCUSSION19:00 CLOSING (Steven Krauwer)viContentsPAPERS3 Discourse Particles and Routine Formulas in Spoken Language TranslationManfred Stede, Birte Schmitz10 A Dialogue Analysis Model with Statistical Speech Act Processing for Dia-logue Machine TranslationJae-won Lee, Gil Chang Kim, Jungyun Seo16 Towards TranslatingFrameworkKeiko HoriguchiSpoken Language Pragmatics in an Analogical24 Correct Parts Extraction from Speech Recognition Results Using SemanticDistance Calculation, and its Application to Speech TranslationYumi Wakita, Jun Kawai, Hitoshi Iida32 A Formal Basis for Spoken Language Translation by AnalogyKeiko Horiguchi, Alexander Franz40 Dealing with Multillnguallty in a Spoken Language Query TranslatorPascale Fung, Bertram Shi, Dekai Wu, Lain Wai Bun, Wong Shuen Kong44 Using Categories in the EUTRANS SystemJ.C.
Amengual, J.M.
Bened(, F. Casacuberta, A. CastaKo, A. CasteUanos, D. Llorens,A.
Marzal, F. Prat, E. Vidal, J.M.
Vilar54 English-to-Mandarln Speech Translation with Head TransducersHiyan Alshawi, Fei Xia61 Interactive Speech Translation in the DIPLOMAT ProjectRobert Frederking, Alexander Rudnicky, Christopher Hogan67 Expanding the Domain of a Multilingual Speech-to-Speech TranslationSystemAlon Lavie, Lori Levin, Puming Zhan, Maite Taboada, Donna Gates, Mirella Lapata,Cortis Clark, Matthew Broadhead, Alex Waibel73 Translation Methodology in the Spoken Language Translator: An  EvaluationDavid Carter, Ralph Becket, Manny Rayner, Robert Eklund, Catriona MacDermid, MatsWir~n, Sabine Kirchmeier-Andersen, Christina Philp83 Six Issues in Speech TranslationMark SeligmanPOSTERS929496Combining Situated Reasoning with Semantic Transfer MinimallyTsutomu FujinamiPOLENGKrzysztof JassemSpoken Language Translation with the ITSVox SystemEric Wehrli, Jean-Luc CochardviiVl l lPapers
