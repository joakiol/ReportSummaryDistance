Proceedings of HLT/EMNLP 2005 Demonstration Abstracts, pages 34?35,Vancouver, October 2005.OpinionFinder: A system for subjectivity analysisTheresa Wilson?, Paul Hoffmann?, Swapna Somasundaran?, Jason Kessler?,Janyce Wiebe?
?, Yejin Choi?, Claire Cardie?, Ellen Riloff?, Siddharth Patwardhan?
?Intelligent Systems Program, University of Pittsburgh, Pittsburgh, PA 15260?Department of Computer Science, University of Pittsburgh, Pittsburgh, PA 15260?Department of Computer Science, Cornell University, Ithaca, NY 14853?School of Computing, University of Utah, Salt Lake City, UT 84112{twilson,hoffmanp,swapna,jsk44,wiebe}@cs.pitt.edu,{ychoi,cardie}@cs.cornell.edu, {riloff,sidd}@cs.utah.edu1 IntroductionOpinionFinder is a system that performs subjectivityanalysis, automatically identifying when opinions,sentiments, speculations, and other private states arepresent in text.
Specifically, OpinionFinder aims toidentify subjective sentences and to mark various as-pects of the subjectivity in these sentences, includ-ing the source (holder) of the subjectivity and wordsthat are included in phrases expressing positive ornegative sentiments.Our goal with OpinionFinder is to develop a sys-tem capable of supporting other Natural LanguageProcessing (NLP) applications by providing themwith information about the subjectivity in docu-ments.
Of particular interest are question answeringsystems that focus on being able to answer opinion-oriented questions, such as the following:How is Bush?s decision not to ratify theKyoto Protocol looked upon by Japan andother US allies?How do the Chinese regard the humanrights record of the United States?To answer these types of questions, a system needsto be able to identify when opinions are expressed intext and who is expressing them.
Other applicationsthat would benefit from knowledge of subjective lan-guage include systems that summarize the variousviewpoints in a document or that mine product re-views.
Even typical fact-oriented applications, suchas information extraction, can benefit from subjec-tivity analysis by filtering out opinionated sentences(Riloff et al, 2005).2 OpinionFinderOpinionFinder runs in two modes, batch and inter-active.
Document processing is largely the same forboth modes.
In batch mode, OpinionFinder takes alist of documents to process.
Interactive mode pro-vides a front-end that allows a user to query on-linenews sources for documents to process.2.1 System Architecture OverviewOpinionFinder operates as one large pipeline.
Con-ceptually, the pipeline can be divided into two parts.The first part performs mostly general purpose doc-ument processing (e.g., tokenization and part-of-speech tagging).
The second part performs the sub-jectivity analysis.
The results of the subjectivityanalysis are returned to the user in the form ofSGML/XML markup of the original documents.2.2 Document ProcessingFor general document processing, OpinionFinderfirst runs the Sundance partial parser (Riloff andPhillips, 2004) to provide semantic class tags, iden-tify Named Entities, and match extraction patternsthat correspond to subjective language (Riloff andWiebe, 2003).
Next, OpenNLP1 1.1.0 is used to tok-enize, sentence split, and part-of-speech tag the data,and the Abney stemmer2 is used to stem.
In batchmode, OpinionFinder parses the data again, this timeto obtain constituency parse trees (Collins, 1997),which are then converted to dependency parse trees(Xia and Palmer, 2001).
Currently, this stage is only1http://opennlp.sourceforge.net/2SCOL version 1g available at http://www.vinartus.net/spa/34available for batch mode processing due to the timerequired for parsing.
Finally, a clue-finder is run toidentify words and phrases from a large subjectivelanguage lexicon.2.3 Subjectivity AnalysisThe subjectivity analysis has four components.2.3.1 Subjective Sentence ClassificationThe first component is a Naive Bayes classifierthat distinguishes between subjective and objectivesentences using a variety of lexical and contextualfeatures (Wiebe and Riloff, 2005; Riloff and Wiebe,2003).
The classifier is trained using subjective andobjective sentences, which are automatically gener-ated from a large corpus of unannotated data by twohigh-precision, rule-based classifiers.2.3.2 Speech Events and Direct SubjectiveExpression ClassificationThe second component identifies speech events(e.g., ?said,?
?according to?)
and direct subjectiveexpressions (e.g., ?fears,?
?is happy?).
Speechevents include both speaking and writing events.Direct subjective expressions are words or phraseswhere an opinion, emotion, sentiment, etc.
is di-rectly described.
A high-precision, rule-based clas-sifier is used to identify these expressions.2.3.3 Opinion Source IdentificationThe third component is a source identifier thatcombines a Conditional Random Field sequencetagging model (Lafferty et al, 2001) and extractionpattern learning (Riloff, 1996) to identify the sourcesof speech events and subjective expressions (Choiet al, 2005).
The source of a speech event is thespeaker; the source of a subjective expression is theexperiencer of the private state.
The source identifieris trained on the MPQA Opinion Corpus3 using avariety of features.
Because the source identifier re-lies on dependency parse information, it is currentlyonly available in batch mode.2.3.4 Sentiment Expression ClassificationThe final component uses two classifiers to iden-tify words contained in phrases that express pos-itive or negative sentiments (Wilson et al, 2005).3The MPQA Opinion Corpus can be freely obtained athttp://nrrc.mitre.org/NRRC/publications.htm.The first classifier focuses on identifying sentimentexpressions.
The second classifier takes the senti-ment expressions and identifies those that are pos-itive and negative.
Both classifiers were developedusing BoosTexter (Schapire and Singer, 2000) andtrained on the MPQA Corpus.3 Related WorkPlease see (Wiebe and Riloff, 2005; Choi et al,2005; Wilson et al, 2005) for discussions of relatedwork in automatic opinion and sentiment analysis.4 AcknowledgmentsThis work was supported by the Advanced Researchand Development Activity (ARDA), by the NSFunder grants IIS-0208028, IIS-0208798 and IIS-0208985, and by the Xerox Foundation.ReferencesY.
Choi, C. Cardie, E. Riloff, and S. Patwardhan.
2005.
Identi-fying sources of opinions with conditional random fields andextraction patterns.
In HLT/EMNLP 2005.M.
Collins.
1997.
Three generative, lexicalised models for sta-tistical parsing.
In ACL-1997.J.
Lafferty, A. McCallum, and F. Pereira.
2001.
Conditionalrandom fields: Probabilistic models for segmenting and la-beling sequence data.
In ICML-2001.E.
Riloff and W. Phillips.
2004.
An Introduction to the Sun-dance and AutoSlog Systems.
Technical Report UUCS-04-015, School of Computing, University of Utah.E.
Riloff and J. Wiebe.
2003.
Learning extraction patterns forsubjective expressions.
In EMNLP-2003.E.
Riloff, J. Wiebe, and W. Phillips.
2005.
Exploiting sub-jectivity classification to improve information extraction.
InAAAI-2005.E.
Riloff.
1996.
An Empirical Study of Automated DictionaryConstruction for Information Extraction in Three Domains.Artificial Intelligence, 85:101?134.R.
E. Schapire and Y.
Singer.
2000.
BoosTexter: A boosting-based system for text categorization.
Machine Learning,39(2/3):135?168.J.
Wiebe and E. Riloff.
2005.
Creating subjective and objec-tive sentence classifiers from unannotated texts.
In CICLing-2005.T.
Wilson, J. Wiebe, and P. Hoffmann.
2005.
Recognizingcontextual polarity in phrase-level sentiment analysis.
InHLT/EMNLP 2005.F.
Xia and M. Palmer.
2001.
Converting dependency structuresto phrase structures.
In HLT-2001.35
