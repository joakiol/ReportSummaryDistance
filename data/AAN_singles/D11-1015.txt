Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 162?171,Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational LinguisticsUnsupervised Discovery of Discourse Relations for EliminatingIntra-sentence Polarity AmbiguitiesLanjun Zhou, Binyang Li, Wei Gao, Zhongyu Wei, Kam-Fai WongDepartment of Systems Engineering and Engineering ManagementThe Chinese University of Hong KongShatin, NT, Hong Kong, ChinaKey Laboratory of High Confidence Software TechnologiesMinistry of Education, China{ljzhou, byli, wgao, zywei, kfwong}@se.cuhk.edu.hkAbstractPolarity classification of opinionated sen-tences with both positive and negative senti-ments1 is a key challenge in sentiment anal-ysis.
This paper presents a novel unsuper-vised method for discovering intra-sentencelevel discourse relations for eliminating polar-ity ambiguities.
Firstly, a discourse schemewith discourse constraints on polarity was de-fined empirically based on Rhetorical Struc-ture Theory (RST).
Then, a small set of cue-phrase-based patterns were utilized to collecta large number of discourse instances whichwere later converted to semantic sequentialrepresentations (SSRs).
Finally, an unsuper-vised method was adopted to generate, weighand filter new SSRs without cue phrases forrecognizing discourse relations.
Experimen-tal results showed that the proposed methodsnot only effectively recognized the defineddiscourse relations but also achieved signifi-cant improvement by integrating discourse in-formation in sentence-level polarity classifica-tion.1 IntroductionAs an important task of sentiment analysis, polar-ity classification is critically affected by discoursestructure (Polanyi and Zaenen, 2006).
Previous re-search developed discourse schema (Asher et al,2008) (Somasundaran et al, 2008) and proved thatthe utilization of discourse relations could improvethe performance of polarity classification on dia-logues (Somasundaran et al, 2009).
However, cur-1Defined as ambiguous sentences in this paperrent state-of-the-art methods for sentence-level po-larity classification are facing difficulties in ascer-taining the polarity of some sentences.
For example:(a) [Although Fujimori was criticized by the internationalcommunity]?
[he was loved by the domestic population]?
[because people hated the corrupted ruling class].
(??????????????????????????????????????????????
)Example (a) is a positive sentence holding a Con-trast relation between first two segments and aCause relation between last two segments.
The po-larity of "criticized", "hated" and "corrupted" are rec-ognized as negative expressions while "loved" is rec-ognized as a positive expression.
Example (a) is dif-ficult for existing polarity classification methods fortwo reasons: (1) the number of positive expressionsis less than negative expressions; (2) the importanceof each sentiment expression is unknown.
However,consider Figure 1, if we know that the polarity ofthe first two segments holding a Contrast relationis determined by the nucleus (Mann and Thompson,1988) segment and the polarity of the last two seg-ments holding aCause relation is also determined bythe nucleus segment, the polarity of the sentence willbe determined by the polarity of "[he...population]".Thus, the polarity of Example (a) is positive.Statistics showed that 43% of the opinionatedsentences in NTCIR2 MOAT (Multilingual OpinionAnalysis Task) Chinese corpus3 are ambiguous.
Ex-isting sentence-level polarity classification methodsignoring discourse structure often give wrong resultsfor these sentences.
We implemented state-of-the-2http://research.nii.ac.jp/ntcir/3Including simplified Chinese and traditional Chinese cor-pus from NTCIR-6 MOAT and NTCIR-7 MOAT162Figure 1: Discourse relations for Example (a).
(n and sdenote nucleus and satellite segment, respectively)art method (Xu and Kit, 2010) in NTCIR-8 ChineseMOAT as the baseline polarity classifier (BPC) inthis paper.
Error analysis of BPC showed that 49%errors came from ambiguous sentences.In this paper, we focused on the automation ofrecognizing intra-sentence level discourse relationsfor polarity classification.
Based on the previouswork of Rhetorical Structure Theory (RST) (Mannand Thompson, 1988), a discourse scheme with dis-course constraints on polarity was defined empiri-cally (see Section 3).
The scheme contains 5 rela-tions: Contrast, Condition, Continuation, Cause andPurpose.
From a raw corpus, a small set of cue-phrase-based patterns were used to collect discourseinstances.
These instances were then converted tosemantic sequential representations (SSRs).
Finally,an unsupervised SSR learner was adopted to gener-ate, weigh and filter high quality new SSRs with-out cue phrases.
Experimental results showed thatthe proposed methods could effectively recognizethe defined discourse relations and achieve signifi-cant improvement in sentence-level polarity classi-fication comparing to BPC.The remainder of this paper is organized as fol-lows.
Section 2 introduces the related work.
Sec-tion 3 presents the discourse scheme with discourseconstraints on polarity.
Section 4 gives the detail ofproposed method.
Experimental results are reportedand discussed in Section 5 and Section 6 concludesthis paper.2 Related WorkResearch on polarity classification were generallyconducted on 4 levels: document-level (Pang et al,2002), sentence-level (Riloff et al, 2003), phrase-level (Wilson et al, 2009) and feature-level (Hu andLiu, 2004; Xia et al, 2007).There was little research focusing on the auto-matic recognition of intra-sentence level discourserelations for sentiment analysis in the literature.Polanyi and Zaenen (2006) argued that valence cal-culation is critically affected by discourse struc-ture.
Asher et al (2008) proposed a shallow se-mantic representation using a feature structure anduse five types of rhetorical relations to build a fine-grained corpus for deep contextual sentiment anal-ysis.
Nevertheless, they did not propose a com-putational model for their discourse scheme.
Sny-der and Barzilay (2007) combined an agreementmodel based on contrastive RST relations with a lo-cal aspect model to make a more informed over-all decision for sentiment classification.
Nonethe-less, contrastive relations were only one type of dis-course relations which may help polarity classifica-tion.
Sadamitsu et al (2008) modeled polarity re-versal using HCRFs integrated with inter-sentencediscourse structures.
However, our work is on intra-sentence level and our purpose is not to find polar-ity reversals but trying to adapt general discourseschemes (e.g., RST) to help determine the overallpolarity of ambiguous sentences.The most closely related works were (Somasun-daran et al, 2008) and (Somasundaran et al, 2009),which proposed opinion frames as a representationof discourse-level associations on dialogue andmod-eled the scheme to improve opinion polarity clas-sification.
However, opinion frames was difficultto be implemented because the recognition of opin-ion target was very challenging in general text.
Ourwork differs from their approaches in two key as-pects: (1) we distinguished nucleus and satellite indiscourse but opinion frames did not; (2) our methodfor discourse discovery was unsupervised while theirmethod needed annotated data.Most research works about discourse classifica-tion were not related to sentiment analysis.
Su-pervised discourse classification methods (Soricutand Marcu, 2003; Duverle and Prendinger, 2009)needed manually annotated data.
Marcu and Echi-habi (2002) presented an unsupervised method torecognize discourse relations held between arbitraryspans of text.
They showed that lexical pairs ex-tracted from massive amount of data can have amajor impact on discourse classification.
Blair-Goldensohn et al (2007) extended Marcu's work byusing parameter opitimization, topic segmentationand syntactic parsing.
However, syntactic parsers163were usually costly and impractical when dealingwith large scale of text.
Thus, in additional to lex-ical features, we incorporated sequential and seman-tic information in proposed method for discourse re-lation classification.
Moreover, our method kept thecharacteristic of language independent, so it could beapplied to other languages.3 Discourse Scheme for EliminatingPolarity AmbiguitiesSince not all of the discourse relations in RSTwould help eliminate polarity ambiguities, the dis-course scheme defined in this paper was on a muchcoarser level.
In order to ascertain which relationsshould be included in our scheme, 500 ambigu-ous sentences were randomly chosen from NTCIRMOAT Chinese corpus and the most common dis-course relations for connecting independent clausesin compound sentences were annotated.
We foundthat 13 relations from RST occupied about 70% ofthe annotated discourse relations which may helpeliminate polarity ambiguities.
Inspired by Marcuand Echihabi (2002), to construct relatively low-noise discourse instances for unsupervised methodsusing cue phrases, we grouped the 13 relations intothe following 5 relations:Contrast is a union of Antithesis, Concession, Oth-erwise and Contrast from RST.Condition is selected from RST.Continuation is a union of Continuation, Parallelfrom RST.Cause is a union of Evidence, Volitional-Cause,Nonvolitional-Cause, Volitional-result andNonvolitional-result from RST.Purpose is selected from RST.The discourse constraints on polarity presentedhere were based on the observation of annotated dis-course instances: (1) discourse instances holdingContrast relation should contain two segments withopposite polarities; (2) discourse instances hold-ing Continuation relation should contain two seg-ments with the same polarity; (3) the polarity of dis-course instances holdingContrast,Condition,Causeor Purpose was determined by the nucleus segment;(4) the polarity of discourse instances holding Con-tinuation was determined by either segment.Relation Cue Phrases(English Translation)Contrast although1, but2, however2Condition if1, (if1?then2)Continuation and, further more,(not only, but also)Cause because1, thus2, accordingly2,as a result2Purpose in order to2, in order that2,so that21 means CUE1 and 2 means CUE2Table 1: Examples of cue phrases4 MethodsThe proposed methods were based on two as-sumptions: (1) Cue-phrase-based patterns could beused to find limited number of high quality discourseinstances; (2) discourse relations were determinedby lexical, structural and semantic information be-tween two segments.Cue-phrase-based patterns could find only lim-ited number of discourse instances with high pre-cision (Marcu and Echihabi, 2002).
Therefore, wecould not rely on cue-phrase-based patterns alone.Moreover, there was no annotated corpus similar toPenn Discourse TreeBank (Miltsakaki et al, 2004)in other languages such as Chinese.
Thus, we pro-posed a language independent unsupervised methodto identify discourse relations without cue phraseswhile maintaining relatively high precision.
Foreach discourse relation, we started with several cue-phrase-based patterns and collected a large numberof discourse instances from raw corpus.
Then, dis-course instances were converted to semantic sequen-tial representations (SSRs).
Finally, an unsupervisedmethod was adopted to generate, weigh and filtercommon SSRswithout cue phrases.
Themined com-mon SSRs could be directly used in our SSR-basedclassifier in unsupervised manner or be employed aseffective features for supervised methods.4.1 Gathering and representing discourseinstancesA discourse instance, denoted by Di, consists oftwo successive segments (Di[1], Di[2]) within a sen-tence.
For example:D1: [Although Boris is very brilliant at math]s, [he164BOS...
?
[CUE2]...EOSBOS [CUE1]...
?...EOSBOS...
?
[CUE1]...EOSBOS [CUE1]...
?
[CUE2]...EOSTable 2: Cue-phrase-based patterns.
BOS and EOS de-noted the beginning and end of two segments.is a horrible teacher]nD2: [John is good at basketball]s, [but he lacks teamspirit]nIn D1, "although" indicated the satellite sectionwhile inD2, "but" indicated the nucleus section.
Ac-cordingly, different cue phrases may indicate differ-ent segment type.
Table 1 listed some examples ofcue phrases for each discourse relation.
Some cuephrases were singleton (e.g.
"although" and "as a re-sult") and some were used as a pair (e.g.
"not only,but also").
"CUE1" indicated satellite segments and"CUE2" indicated nucleus segments.
Note that wedid not distinguish satellite from nucleus for Con-tinuation in this paper because the polarity could bedetermined by either segment.Table 2 listed cue-phrase-based patterns for all re-lations.
To simplify the problem of discourse seg-mentation, we split compound sentences into dis-course segments using commas and semicolons.
Al-though we collected discourse instances from com-pound sentences only, the number of instances foreach discourse relation was large enough for the pro-posed unsupervised method.
Note that we only col-lected instances containing at least one sentimentword in each segment.In order to incorporate lexical and semantic infor-mation in our method, we represented each word ina discourse instance using a part-of-speech tag, a se-mantic label and a sentiment tag.
Then, all discourseinstances were converted to SSRs.
The rules for con-verting were as follows:(1) Cue phrases and punctuations were ingored.But the information of nucleus(n) and satellite(s)was preserved.
(2) Adverbs(RB) appearing in sentiment lexicon,verbs(V ), adjectives(JJ ) and nouns(NN) were repre-sented by their part-of-speech (pos) tag with seman-tic label (semlabel) if available.
(3) Named entities (NE; PER: person name;ORG:organization), pronouns (PRP), and function wordswere represented by their corresponding named en-tity tags and part-of-speech tags, respectively.
(4) Added sentiment tag (P : Positive; N : Nega-tive) to all sentiment words.By applying above rules, the SSRs forD1 andD2would be:d1: [PERV|Ja01 RB|Ka01 JJ|Ee14|P IN NN|Dk03]s, [PRP V|Ja01 DT JJ|Ga16|N NN|Ae13 ]nd2: [PER V|Ja01 JJ|Ee14|P IN NN|Bp12]s, [PRPV|He15|N NN|Di10 NN|Dd08 ]nRefer to d1 and d2, "Boris" could match "John"in SSRs because they were converted to "PER" andthey all appeared at the beginning of discourse in-stances.
"Ja01", "Ee14" etc.
were semantic labelsfrom Chinese synonym list extended version (Che etal., 2010).
There were similar resources in other lan-guages such asWordnet(Fellbaum, 1998) in English.The next problem became how to start from currentSSRs and generate new SSRs for recognizing dis-course relations without cue phrases.4.2 Mining common SSRsRecall assumption (2), in order to incorporate lex-ical, structural and semantic information for the sim-ilarity calculation of two SSRs holding the samediscourse relation, three types of matches were de-fined for {(u, v)|u ?
di[k], v ?
dj[k], k = 1, 2}:(1)Full match: (i) u = v or (ii) u.pos = v.pos andu.semlabel=v.semlabel or (iii) u.pos=v.pos andu had a sentiment tag and v had a sentiment tag or(iv) u.pos and v.pos?
{PRP, PER, ORG} (2) Partialmatch: u.pos = v.pos but not Full match; (3) Mis-match: u.pos ?= v.pos.Generating common SSRsIntuitively, a simple way of estimating the simi-larity between two SSRs was using the number ofmismatches.
Therefore, we utilized match(di, dj)where i ?= j, which integrated the three types ofmatches defined above to calculate the number ofmismatches and generate common SSRs.
ConsiderTable 3, in common SSRs, full matches were pre-served, partial matches were replaced by part ofspeech tags and mismatches were replaced by '*'s.The common SSRs generated during the calculationof match(di, dj) consisted of two parts.
The firstpart was generated by di[1] and dj[1] and the secondpart was generated by di[2] and dj[2].
We stipulated165d1 d2 mis conf ssrPER PER 0 0 PERV|Ja01 V|Ja01 0 0 V|Ja01RB|Ka01 +1 ?0.298 *JJ|Ee14|P JJ|Ee14|P 0 0 JJ|Ee14|PIN IN 0 0 INNN|Dk03 NN|Bp12 0 ?0.50 NNconf(ssr[1]) = ?0.798PRP PRP 0 0 PRPV|Ja01 V|He15|N 0 ?0.50 VDT +1 ?0.184 *JJ|Ga16|N +1 ?1.0 *NN|Ae13 NN|Di10 0 ?0.50 NNNN|Dd08 +1 ?1.0 *conf(ssr[2]) = ?3.184Table 3: Calculation of match(d1, d2).
ssr denotedthe common SSR between d1 and d2 , conf(ssr[1]) andconf(ssr[2]) denoted the confidence of ssr.that di and dj could generate a common SSR if andonly if the orders of nucleus segment and satellitesegment were the same.In order to guarantee relatively high quality com-mon SSRs, we empirically set the upper thresholdof the number of mismatches as 0.5 (i.e., ?
1/2 ofthe number of words in the generated SSR).
It's notdifficult to figure out that the number of mismatchesgenerated in Table 3 satisfied this requirement.
As aresult, for each discourse relation rn, a correspond-ing common SSR set Sn could be obtained by adopt-ing match(di, dj) where i ?= j for all discourse in-stances.
An advantage of match(d1, d2) was thatthe generated common SSRs preserved the sequen-tial structure of original discourse instances.
Andcommon SSRs allows us to build high precision dis-course classifiers (See Section 5).Weighing and filtering common SSRsA problem of match(di, dj) was that it ignoredsome important information by treating differentmismatches equally.
For example, the adverb "very"in "very brilliant" of D1 was not important for dis-course recognition.
In other words, the number ofmismatches inmatch(di, dj) could not precisely re-flect the confidence of the generated common SSRs.Therefore, it was needed to weigh different mis-matches for the confidence calculation of commonSSRs.Intuitively, if a partial match or a mismatch (de-noted by um) occurred very frequently in the gener-ation of common SSRs, the importance of um tendsto diminish.
Inspired by the tf-idf model, givenssri?Sn, we utilized the following equation to esti-mate the weight (denoted by wm) of um.wm = ?ufm ?
log (|Sn|/ssrfm )where ufm denoted the frequency of um during thegeneration of ssri, |Sn| denoted the size of Sn andssrfm denoted the number of common SSRs in Sncontaining um .
All weights were normalized to[?1, 0).Nouns (except for named entities) and verbs weremost representative words in discourse recognition(Marcu and Echihabi, 2002).
In addition, adjectivesand adverbs appearing in sentiment lexicons wereimportant for polarity classification.
Therefore, forthese 4 kinds of words, we utilized ?1.0 for a mis-match and ?0.50 for a partial match.As we had got the weights for all partial matchesand mismatches, the confidence of ssri?Sn could becalculated using the cumulation of weights of par-tial matches and mismatches in ssri[1] and ssri[2].Recall Table 3, conf(ssr[1]) and conf(ssr[2]) rep-resented the confidence scores ofmatch(di[1], dj[1])and match(di[2], dj[2]), respectively.
In order tocontrol the quantity and quality of mined SSRs, athreshold minconf was introduced.
ssri will bepreserved if and only if conf(ssri[1]) ?minconfand conf(ssri[2]) ?
minconf .
The value ofminconf was tuned using the development data.Finally, we combined adjacent '*'s and preservedSSRs containing at least one notional word and atleast two words in each segment to meet the de-mand of maintaining high precision (e.g., "[* DT*]", "[PER *]" will be dropped).
Moreover, sincemany of the SSRs were duplicated, we ranked allthe generated SSRs according to their occurrencesand dropped those appearing only once in order topreserve common SSRs.
At last, SSRs appearing inmore than one common SSR set were removed formaintaining the uniqueness of each set.
The com-mon SSR set Sn for each discourse relation rn couldbe directly used in SSR-based unsupervised classi-fiers or be employed as effective features in super-vised methods.166Relation OccurrenceContrast 86 (8.2%)Condition 27 (2.6%)Continuation 445 (42.2%)Cause 123 (11.7%)Purpose 55 (5.2%)Others 318 (30.2%)Table 4: Distribution of discourse relations on NTC-7.Others represents discourse relations not included in ourdiscourse scheme.5 Experiments5.1 Annotation work and DataWe extracted all compound sentences which maycontain the defined discourse relations from opinion-ated sentences (neutral ones were dropped) of NT-CIR7MOAT simplified Chinese training data.
1,225discourse instances were extracted and two annota-tors were trained to annotate discourse relations ac-cording to the discourse scheme defined in Section 3.Note that we annotate both explicit and implicit dis-course relations.
The overall inter annotator agree-ment was 86.05% and the Kappa-value was 0.8031.Table 4 showed the distribution of annotated dis-course relations based on the inter-annotator agree-ment.
The proportion of occurrences of each dis-course relations varied greatly.
For example, Con-tinuation was the most common relation in anno-tated corpus, but the occurrences of Condition rela-tion were rare.The experiments of this paper were performed us-ing the following data sets:NTC-7 contained manually annotated discourseinstances (shown in Table 4).
The experiments ofdiscourse identification were performed on this dataset.NTC-8 contained all opinionated sentences (neu-tral ones were dropped) extracted from NTCIR8MOAT simplified Chinese test data.
The experi-ments of polarity ambiguity elimination using theidentified discourse relations were performed on thisdata set.XINHUA contained simplified Chinese raw newstext from Xinhua.com (2002-2005).
A word seg-mentation tool, a part-of-speech tagging tool, anamed entity recognizer and a word sense disam-biguation tool (Che et al, 2010) were adopted to allsentences.
The common SSRs were mined from thisdata set.5.2 Experimental SettingsDiscourse relation identificationIn order to systematically justify the effectivenessof proposed unsupervised method, following exper-iments were performed on NTC-7:Baseline used only cue-phrase-based patterns.M&E proposed by Marcu and Echihabi (2002).Given a discourse instance Di, the probabilities:P (rk|(Di[1], Di[2])) for each relation rk were esti-mated on all text from XINHUA.
Then, the mostlikely discourse relation was determined by takingthe maximum over argmaxk{P (rk|(Di[1], Di[2])}.cSSR used both cue-phrase-based patterns to-gether with common SSRs for recognizing discourserelations.
Common SSRs were mined from dis-course instances extracted fromXINHUAusing cue-phrase-based patterns.
Development data were ran-domly selected for tuning minconf .SVM was trained utilizing cue phrases, probabil-ities from M&E, topic similarity, structure overlap,polarity of segments and mined common SSRs (Op-tional).
The parameters of the SVM classifier wereset by a grid search on the training set.
We performed4-fold cross validation on NTC-7 to get an averageperformance.The purposes of introducing SVM in our experi-ment were: (1) to compare the performance of cSSRto supervised method; (2) to examine the effective-ness of integrating common SSRs as features for su-pervised methods.Polarity ambiguity eliminationBPC was trained mainly utilizing punctuation,uni-gram, bi-gram features with confidence scoreoutput.
Discourse classifiers such as Baseline, cSSRor SVM were adopted individually for the post-processing of BPC.
Given an ambiguous sentencewhich contained more than one segment, an intuitivethree-step method was adopted to integrated a dis-course classifier and discourse constraints on polar-ity for the post-processing of BPC:(1) Recognize all discourse relations together withnucleus and satellite information using a discourseclassifier.
The nucleus and satellite information is167Figure 2: Influences of different values of minconf tothe performance of cSSRacquired by cSSR if a segment pair could match acSSR.
Otherwise, we use the annotated nucleus andsatellite information.
(2) Apply discourse constraints on polarity toascertain the polarity for each discourse instance.There may be conflicts between polarities acquiredby BPC and discourse constraints on polarity (e.g.,Two segments with the same polarity holding a Con-trast relation).
To handle this problem, we chosethe segment with higher polarity confidence and ad-justed the polarity of the other segment using dis-course constraints on polarity.
(3) If there was more than one discourse instancein a single sentence, the overall polarity of the sen-tence was determined by voting of polarities fromeach discourse instance under the majority rule.5.3 Experimental ResultsRefer to Figure 2, the performance of cSSR wassignificantly affected by minconf .
Note that weperformed the tuning process ofminconf on differ-ent development data (1/4 instances randomly se-lected from NTC-7) and Figure 2 showed the av-erage performance.
cSSR became Baseline whenminconf =0.
A significant drop of precision wasobserved when minconf was less than ?2.5.
Therecall remained around 0.495 when minconf ??4.0.
The best performance was observed whenminconf=?3.5.
As a result, ?3.5 was utilized asthe threshold value for cSSR in the following exper-iments.Table 5 presented the experimental results for dis-course relation classification.
it showed that:(1) Cue-phrase-based patterns could find only lim-ited number of discourse relations (34.1% of averageBPC Baseline cSSR SVM+SSRsPrecision 0.7661 0.7982 0.8059 0.8113Recall 0.7634 0.7957 0.8038 0.8091F-score 0.7648 0.7970 0.8048 0.8102Table 6: Performance of integrating discourse classifiersand constraints to polarity classification.
Note that theexperiments were performed on NTC-8 which containedonly opinionated sentences.recall) with a very high precision (96.17% of averageprecision).
This is a proof of assumption (1) givenin Section 4.
On the other side, M&E which onlyconsidered word pairs between two segments of dis-course instances got a higher recall with a large dropof precision.
The drop of precision may be causedby the neglect of structural and semantic informationof discourse instances.
However, M&E still outper-formed Baseline in average F -score.
(2) cSSR enhanced Baseline by increasing the av-erage recall by about 15% with only a small drop ofprecision.
The performance of cSSR demonstratedthat our method could effectively discover high qual-ity common SSRs.
The most remarkable improve-ment was observed on Continuation in which the re-call increased by almost 20% with only a minor dropof precision.
Actually, cSSR outperformed Baselinein all discourse relations except forContrast.
In Dis-course Tree Bank (Carlson et al, 2001) only 26%of Contrast relations were indicated by cue phraseswhile in NTC-7 about 70% of Contrast were indi-cated by cue phrases.
A possible reason was thatwe were dealing with Chinese news text which wereusually well written.
Another important observationwas that the performance of cSSR was very close tothe result of SVM.
(3) SVM+SSRs achieved the best F -score onContinuation and average performance.
The integra-tion of SSRs to the feature set of SVM contributed toa remarkable increase in average F -score.
The re-sults of cSSR and SVM+SSRs demonstrated the ef-fectiveness of common SSRs mined by the proposedunsupervised method.Table 6 presented the performance of integrat-ing discourse classifiers to polarity classification.For Baseline and cSSR, the information of nucleusand satellite could be obtained directly from cue-168Relation Baseline M&E cSSR SVM SVM+SSRsContrastP 0.9375 0.4527 0.7531 0.9375 0.9375R 0.6977 0.7791 0.7093 0.6977 0.6977F 0.8000 0.5726 0.7305 0.8000 0.8000ConditionP 1.0000 0.4444 0.6774 1.0000 0.7083R 0.5556 0.8889 0.7778 0.5185 0.6296F 0.7143 0.5926 0.7241 0.6829 0.6667ContinuationP 0.9831 0.6028 0.9761 0.6507 0.7266R 0.2607 0.5865 0.4584 0.6697 0.6629F 0.4120 0.5945 0.6239 0.6600 0.6933CauseP 1.0000 0.5542 0.9429 1.0000 0.9412R 0.2114 0.3740 0.2683 0.2114 0.2602F 0.3489 0.4466 0.4177 0.3489 0.4076PurposeP 0.8947 0.3704 0.8163 0.9167 0.7193R 0.6182 0.7273 0.7273 0.6000 0.7455F 0.7312 0.4908 0.7692 0.7253 0.7321AverageP 0.9617 0.5302 0.8864 0.7207 0.7607R 0.3410 0.5951 0.4878 0.5856 0.6046F 0.5035 0.5608 0.6293 0.6461 0.6737Table 5: Performance of recognizing discourse relations.
(The evaluation criteria are Precision, Recall and F-score)phrase-based patterns and SSRs, respectively.
ForSVM+cSSR, the nucleus and satellite informationwas acquired by cSSR if a segment pair could matcha cSSR.
Otherwise, we used manually annotated nu-cleus and satellite information.
It's clear that theperformance of polarity classification was enhancedwith the improvement of discourse relation recogni-tion.
M&E was not included in this experiment be-cause the performance of polarity classification wasdecreased by the mis-classified discourse relations.SVM+SSRs achieved significant (p<0.01) improve-ment in polarity classification compared to BPC.5.4 DiscussionEffect of weighing and filteringTo assess the contribution of weighing and filter-ing in mining SSRs using a minimum confidencethreshold, i.e.
minconf , we implemented cSSR?without weighing and filtering on the same data set.Consider Table 7, cSSR achieved obvious improve-ment in Precision and F -score than cSSR?.
More-over, the total number of SSRs was greatly reducedin cSSR with only a minor drop of recall.
This wasbecause cSSR?
was affected by thousands of lowquality common SSRs which would be filtered incSSR.
The result in Table 7 proved that weighing andcSSR?
cSSRPrecision 0.6182 0.8864Recall 0.5014 0.4878F-score 0.5537 0.6293NOS > 1 million ?
0.12 millionTable 7: Comparison of cSSR?
and cSSR.
"NOS" denotedthe number of mined common SSRs.filtering were essential in our proposed method.We further analyzed how the improvement wasachieved in cSSR.
In our experiment, the most com-mon mismatches were auxiliary words, named enti-ties, adjectives or adverbs without sentiments (e.g.,"green", "very", etc.
), prepositions, numbers andquantifiers.
It's straightforward that these wordswere insignificant in discourse relation classificationpurpose.
Moreover, these words did not belong tothe 4 kinds of most representative words.
In otherwords, the weights of most mismatches were calcu-lated using the equation presented in Section 4.2 in-stead of utilizing a unified value, i.e.
?1.
RecallTable 3, the weight of "RB|Ka01" (original: "very")was ?0.298 and "DT" (original: 'a') was ?0.184.Comparing to the weights of mismatches for mostrepresentative words (?1.0), the proposed methodsuccessfully down weighed the words which were169Figure 3: Improvement from individual discourse rela-tions.
N denoted the number of ambiguities eliminated.not important for discourse identification.
There-fore, weighing and filtering were able to preservehigh quality SSRs while filter out low quality SSRsby setting the confidence threshold, i.e.
minconf .Contribution of different discourse relationsWe also analyzed the contribution of different dis-course relations in eliminating polarity ambiguities.Refer to Figure 3, the improvement of polarity classi-fication mainly came from three discourse relations:Contrast, Continuation and Cause.
It was straight-forward that Contrast relation could eliminate po-larity ambiguities because it held between two seg-ments with opposite polarities.
The contribution ofCause relation also result from two segments holdingdifferent polarities such as example (a) in Section 1.However, recall Table 4, although Cause occurredmore often than Contrast, only a part of discourseinstances holding Cause relation contained two seg-ments with the opposite polarities.
Another impor-tant relation in eliminating ambiguity was Continu-ation.
We investigated sentences with polarities cor-rected by Continuation relation.
Most of them fellinto two categories: (1) sentences with mistakenlyclassified sentiments by BPC; (2) sentences with im-plicit sentiments.
For example:(b) [France and Germany have banned human cloning atpresent]?
[on 20th, U.S. President George W. Bush calledfor regulations of the same content to Congress] (????????????????????????
20???????????????????
)The first segment of example (b) was negative("banned" expressed a negative sentiment) and aContinuation relation held between these two seg-ments.
Consequently, the polarity of the second seg-ment should be negative.6 Conclusions and Future workThis paper focused on unsupervised discoveryof intra-sentence discourse relations for sentencelevel polarity classification.
We firstly presented adiscourse scheme based on empirical observations.Then, an unsupervised method was proposed start-ing from a small set of cue-phrase-based patterns tomine high quality common SSRs for each discourserelation.
The performance of discourse classificationwas further improved by employing SSRs as featuresin supervisedmethods.
Experimental results showedthat our methods not only effectively recognized dis-course relations but also achieved significant im-provement (p<0.01) in sentence level polarity clas-sification.
Although we were dealing with Chinesetext, the proposed unsupervised method could beeasily generalized to other languages.The future work will be focused on (1) integratingmore semantic and syntactic information in proposedunsupervised method; (2) extending our method tointer-sentence level and then jointly modeling intra-sentence level and inter-sentence level discourseconstraints on polarity to reach a global optimal in-ference for polarity classification.AcknowledgmentsThis work is partially supported by National 863program of China (Grant No.
2009AA01Z150),the Innovation and Technology Fund of Hong KongSAR (Project No.
GHP/036/09SZ) and 2010/11CUHK Direct Grants (Project No.
EE09743).ReferencesN.
Asher, F. Benamara, and Y.Y.
Mathieu.
2008.
Distill-ing opinion in discourse: A preliminary study.
Coling2008: Companion volume: Posters and Demonstra-tions, pages 5--8.S.
Blair-Goldensohn, K.R.
McKeown, and O.C.
Ram-bow.
2007.
Building and refining rhetorical-semanticrelationmodels.
InProceedings of NAACLHLT, pages428--435.L.
Carlson, D.Marcu, andM.E.
Okurowski.
2001.
Build-ing a discourse-tagged corpus in the framework of170rhetorical structure theory.
In Proceedings of the Sec-ond SIGdial Workshop on Discourse and Dialogue-Volume 16, pages 1--10.
Association for Computa-tional Linguistics.W.
Che, Z. Li, and T. Liu.
2010.
Ltp: A chinese languagetechnology platform.
In Proceedings of the 23rd In-ternational Conference on Computational Linguistics:Demonstrations, pages 13--16.
Association for Com-putational Linguistics.D.A.
Duverle and H. Prendinger.
2009.
A novel dis-course parser based on support vector machine classi-fication.
In Proceedings of the Joint Conference of the47th Annual Meeting of the ACL and the 4th Interna-tional Joint Conference on Natural Language Process-ing of the AFNLP: Volume 2, pages 665--673.
Associ-ation for Computational Linguistics.C.
Fellbaum.
1998.
WordNet: An electronic lexicaldatabase.
The MIT press.M.
Hu and B. Liu.
2004.
Mining and summarizingcustomer reviews.
In Proceedings of the tenth ACMSIGKDD international conference on Knowledge dis-covery and data mining, pages 168--177.
ACM.W.C.
Mann and S.A. Thompson.
1988.
Rhetorical struc-ture theory: Toward a functional theory of text organi-zation.
Text-Interdisciplinary Journal for the Study ofDiscourse, 8(3):243--281.D.
Marcu and A. Echihabi.
2002.
An unsupervised ap-proach to recognizing discourse relations.
In Proceed-ings of the 40th Annual Meeting on Association forComputational Linguistics, pages 368--375.
Associa-tion for Computational Linguistics.E.
Miltsakaki, R. Prasad, A. Joshi, and B. Webber.
2004.The penn discourse treebank.
InProceedings of the 4thInternational Conference on Language Resources andEvaluation.
Citeseer.B.
Pang, L. Lee, and S. Vaithyanathan.
2002.
Thumbsup?
: sentiment classification using machine learningtechniques.
In Proceedings of the ACL-02 conferenceon Empirical methods in natural language processing-Volume 10, pages 79--86.
Association for Computa-tional Linguistics.L.
Polanyi and A. Zaenen.
2006.
Contextual valenceshifters.
Computing attitude and affect in text: The-ory and applications, pages 1--10.E.
Riloff, J. Wiebe, and T. Wilson.
2003.
Learning sub-jective nouns using extraction pattern bootstrapping.In Proceedings of the seventh conference on Natu-ral language learning at HLT-NAACL 2003-Volume 4,pages 25--32.
Association for Computational Linguis-tics.K.
Sadamitsu, S. Sekine, and M. Yamamoto.
2008.
Sen-timent analysis based on probabilistic models usinginter-sentence information.B.
Snyder and R. Barzilay.
2007.
Multiple aspect rank-ing using the good grief algorithm.
In Proceedings ofNAACL HLT, pages 300--307.S.
Somasundaran, J. Wiebe, and J. Ruppenhofer.
2008.Discourse level opinion interpretation.
In Proceed-ings of the 22nd International Conference on Compu-tational Linguistics, pages 801--808.
Association forComputational Linguistics.S.
Somasundaran, G. Namata, J. Wiebe, and L. Getoor.2009.
Supervised and unsupervised methods in em-ploying discourse relations for improving opinion po-larity classification.
In Proceedings of the 2009 Con-ference on Empirical Methods in Natural LanguageProcessing, pages 170--179.
Association for Compu-tational Linguistics.R.
Soricut and D. Marcu.
2003.
Sentence level dis-course parsing using syntactic and lexical information.In Proceedings of the 2003 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics on Human Language Technology,pages 149--156.
Association for Computational Lin-guistics.T.
Wilson, J. Wiebe, and P. Hoffmann.
2009.
Recogniz-ing Contextual Polarity: an exploration of features forphrase-level sentiment analysis.
Computational Lin-guistics, 35(3):399--433.Y.Q.
Xia, R.F.
Xu, K.F.
Wong, and F. Zheng.
2007.
Theunified collocation framework for opinion mining.
InInternational Conference on Machine Learning andCybernetics, volume 2, pages 844--850.
IEEE.R.
Xu and C. Kit.
2010.
Incorporating feature-based andsimilarity-based opinion mining--ctl in ntcir-8 moat.InProceedings of the 8th NTCIRWorkshop, pages 276--281.171
