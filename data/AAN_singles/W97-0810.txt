Subject and Object Dependency Extraction Using Finite-State TransducersSalah Ait-Mokhtar, Jean-Pierre ChanodRank Xerox Research Centre, 6 Chemin de MaupertuisF-38240 Meylan, France{Ait,Chanod}@grenoble.rxrc.xerox.comAbstractWe describe and evaluate an approach for fastautomatic recognition and extraction of subjectand object dependency relations from largeFrench corpora, using a sequence of finite-statetransducers.
The extraction is performed in twomajor steps: incremental finite-state parsing andextraction of subject/verb and object/verb rela-tions.
Our incremental and cautious approachduring the first phase allows the system to dealsuccessfully with complex phenomena such asembeddings, coordination of VPs and NPs ornon-standard word order.
The extraction re-quires no subcategorisation nformation.
It relieson POS information only.
After describing thetwo steps, we give the results of an evaluationon various types of unrestricted corpora.
Preci-sion is around 90-97% for subjects (84-88% forobjects) and recall around 86-92% for subjects(80-90% for objects).
We also provide some er-ror analysis; in particular, we evaluate the im-pact of POS tagging errors on subject/object de-pendency extraction.1 IntroductionDependency extraction from large corpora is mainlyused in two major directions: automatic acquisition oflexical patterns \[Brent, 1991; Grishman and Sterling,1992; Briscoe and Carrol, 1994; Sanfilippo, 1994\] ~ orfor end-user applications uch as document indexing orinformation retrieval \[Grefenstette, 1994\].We describe and evaluate an approach for fast auto-matic recognition and extraction of subject and objectdependency relations from large French corpora, using asequence of finite-state transducers.
The extraction isbased on robust shallow parsing.
We extract syntacticrelations without producing complete parse trees in the1 See also the SPARKLE European project,http.//www.dc.p~ cnr.it/sparkle.html.traditional sense.
The extraction requires no subcategori-sation information.
It relies on POS information only.The extraction is performed in two major steps:1. incremental finite-state parsing annotates theinput string with syntactic markings;2. the annotated string is transduced in order toextract subject/verb and object/verb relations.Our incremental nd cautious approach during the firstphase allows the system to deal successfully with com-plex phenomena such as embeddings, coordination ofVPs and NPs or non-standard word order.We evaluated subject and object dependency extrac-tion on various types of unrestricted corpora.
Precisionis around 90-97% for subjects (84-88% for objects) andrecall around 86-92% for subjects (80-90% for objects).The paper also provides some error analysis; in par-ticular, we evaluate the impact of POS tagging errors onthe extraction process.2 Incremental Finite-State Parsing\[AB-Mekhtar and Chanod, 1997\] fully describes theincremental finite-state parser.
Unlike previous work inthis area \[Abney, 1991; Roche, 1993; Appelt et al,1993; Koskenniemi et al 1992; Voutilainen and Ta-panainen, 1993; Chanod and Tapanainen, 1996\] theparser combines constructivist and reductionist ap-proaches, in order to maximise efficiency and robust-ness.Before the parsing proper, we perform tokenisation,iexical lookup and part-of-speech disarnbiguation, usingthe French Xerox tagger \[Chanod and Tapanainen,1995\].
The input to the parser is a tagged string repre-sented by a sequence of word-form + tag pairs of thetype:le bon vin (the good wine)<Ie+DET-SG><bon+ADJ-SG><vin+NOUN-SG>71The parser output is a shallow parse where phrasal andclausal constructs are bracketed and more or less richlyannotated as in:Jean  aime le ben vin (lit.
: J ohn  likes thegood wine)\[VC \[NP Jean  NP\]/SUBJ :v airne v: VC\]\[NP le \[AP bon AP\] vin NP\]/OBJThe parser consists of a sequence of transducers.These transducers are compiled from regular expressionsthat mainly involve the longest match replace operator 2\[Karttunen, 1996\].
Each of these transducers adds syn-tactic information represented by reserved symbols(annotations), such as segment names, boundaries andtags for syntactic functions.
At any given stage of thesequence, the input and the output represent the wholesentence as an annotated string.
The output of a trans-ducer is the input to the next transducer.The parsing process is incremental in the sense thatthe linguistic description attached to a given transducerin the sequence:- adds information relying on the preceding sequenceof transductions;- applies only to some instances of a given linguisticphenomenon;- may be revised at a later stage.Each step defines a syntactic onstruction using twomajor operations: segmentation and syntactic marking.Segmentation consists in bracketing and labeling adja-cent elements belonging to a same partial construction(e.g.
a nominal or a verbal phrase, or a more partialsyntactic hain if necessary).
Segmentation includes alsothe identification of clause boundaries.
Syntactic mark-ing annotates egments with syntactic functions (e.g.subject, object, PPObj).The two operations of segmentation and syntacticmarking are performed throughout the cascade in aninterrelated fashion.
Some segmentations depend onprevious yntactic marking and vice versa.If the constraints encoded by a given transducer donot hold, the string remains unchanged.
This ensures thatthere is always an output string at the end of the cascade,with possibly under-specified segments.The additional information provided at each stage inthe sequence is instrumental in the definition of the laterstages of the cascade.
Networks are ordered in such away that the easiest asks are addressed first.
They canbe performed accurately with less background informa-tion.2.1 P r imary  Segmentat ionA segment (or chunk) is a continuous sequence of wordsthat are syntactically linked to each other or to a gov-erning head (see \[Federici et  al .
,  1996; A~t-Mokhtar andChanod, 1997\] for a more detailed escription).Segments are marked using regular expressions such asthe following one for NPs:\[TBeginNP ~$\[TEndNP\] TEndNP \]@->\[NP ... NP\]where the longest-match left-to-right Replace Operator(noted @->) inserts \[NP and NP\] boundaries around thelongest sequence that begins with a potential NP start(TBeginNP) and ends with the first NP end (TEndNP) tothe right.In the primary segmentation step, we mark segmentboundaries within sentences as shown below.
Here NPstands for Noun Phrase, PP for Preposition Phrase andVC for Verb Chunk (a VC contains at least one verb andpossibly some of its arguments and modifiers).Example:Nc\[VC Lorsqu' \[NP on NP\] tourne VC\]\[NP le commutateur  NP\]\[PP de d6marrage PP\]\[PP sur  la position PP\] \[AP auxiliaire AP\] ,\[NP r aiguille NP\] retoumevc\]alors \[PP ~t z6ro PP\] ./SENT 3All the words within a segment, except he head, arelinked to words in the same segment at the same level.The main purpose of marking segments i therefore toconstrain the linguistic space that determines the syn-tactic function of a word.As one can see from the example above, segmentationis very cautious.
Structural ambiguity inherent to modi-fiers attachment, verb arguments and coordination is notresolved at this stage.2.2 Mark ing  Syntact ic  Funct ionsSyntactic functions within nonrecursive segments (AP,NP and pp4) are handled first because they are easier tomark.
The other functions within verb segments and atsentence level (subject, object, verb modifier, etc.)
areconsidered later.
The string marked with segmentationand syntactic annotations i the input to the extractioncomponent described below.2 In brmf, the expression: A @-> B \]1 Left _ Rtght  m&catesthat he longest string that matches the regular expressmn A isreplaced by B, if it appears inthe context defined by Left andRight.3 In English: Turning the starter switch to the auxdlary posi-tron, the pointer will then return to zero.4 As a consequence of the cautious segmentation such seg-ments are always nonrecursive.72Extracting dependency relations from annotatedstrings is not straightforward, as the annotations do notexplicitly relate arguments otheir governing heads.
Forinstance, shared arguments of coordinated verbs or de-pendencies accross embedded structures need to be re-solved during the extraction phase, as illustrated in theexample belowS:La ville de Lattes rejette toujours la proposi-tion de remonter le niveau du fleuve pour fa-ciliter la circulation des bateaux et n'exclutpus a priori l'idee d'instaurer un p6age.The parser outputs is:\[VC \[NP La ville NP\]/SUBJ \[PP de Lattes PP\]:v rejette v: VC\] toujours\[NP la proposition NP\]/OBJ\[VC de remonter VC\] \[NP le niveau NP\]/OBJ\[PP du fleuve PP\] \[VC pour faciliter VC\]\[NP la circulation NP\]/OBJ\[PP des bateaux PP\]\[VC et :v n' exclut v: VC\] pasa  priori\[NP I' id6e NP\]/OBJ \[VC d' instaurer VC\]\[NP un p6age NP\]/OBJ.As objects are marked outside the verb chunks (VC),the extraction phase must still expand the VCs in orderto identify object dependencies.
Moreover, the extrac-tion must identify la ville as the shared subject of thecoordinated verbs rejette and exclut, which are separatedby two infinitival clauses.
After the preliminary parsingstage, the two coordinated verbs still belong to two dif-ferent VCs.3 Subject and Object Recognition andExtractionThe task consists in recognizing the subject and objectsegments and extracting them along with their respectiveverbs.
Function tagging is performed uring the shallowparsing process; then a special transducer recognizessubject/verb and object/verb dependencies (i.e.
it findsout which is the subject or object of which verb) andextracts them.3.1 Subject and object taggingPotential subjects are marked first.
An NP is a potentialsubject if and only if it is followed by a finite verb and itsatisfies some typographical conditions (it should not beseparated from the verb with only one comma, etc.).
Thisprevents he NP Jacques Boutet for instance frombeing marked as a subject in the sentence below:5 In Enghsh The city of Lattes till rejects he proposal toraise the level of the river to facdttate he boat raffic anddoes not exclude a priori the idea of imposing a toll\[VC \[NP le pr6sident NP\]/SUBJ\[PP du CSA PP\], \[NP Jacques Boutet NP\],a d6cid6 VC\]\[VC de publier VC\]\[NP la profession NP\]/OBJ\[PP de foi PP\]./SENTIf this type of subject does not exist, we look for in-verted subjects under the same typographical constraints.Other constraints are applied later to eliminate someof the potential subject hypotheses.
These constraints aremainly syntactic:1.
A potential subject is not a subject if it has no de-terminer, unless it is a proper noun or it is a coordinatedcommon oun.2.
A potential subject is not a subject if it immediatelyfollows a PP or an NP (i.e.
with no connector in be-tween) and is preceded or followed by another potentialsubject.3.
A potential subject is not a subject if it is followedby another potential subject with no coordination.The remaining potential subjects are taken to be actualsubjects.
The whole process of tagging and correctingsubject ags consists of a sequence of replace expres-sions.Once the subjects are tagged, another transducer per-forms object tagging with similar steps and constraintsbut now only non subject NPs are considered.3.2 Embeddings and regular expressionsTo make this approach work properly, we must be verycareful to take into account embedded contexts(embedded clauses, text within parentheses, and so on).For instance, subject constraint 3above should not applyif the two potential subjects are not at the same level,like the subjects \[NP l'usine NP\] and \[NP le ministreNP\] in the following sentence:\[VC \[NP L' usine NP\]/SUBJ,\[VC que \[NP le ministre NP\]/SUBJ :v devraitv: VC\]\[VC implanter VC\] \[PP ~t Eloyes PP\],:v repr6sente v: VC\] \[NP un investissementNP\]/OBJ\[PP d'environ 148 milliards NP\]/N\[PP de francs PP\] ./SENT 6This also applies throughout the dependency extrac-tion process as described in the next section.In order to handle this difficulty properly with the fi-nite state calculus, we take advantage of the verb seg-menting marks produced by the shallow parser and de-fine a maximal embedding level:6The factory which the minister should establish atEloyesrepresents approximately a 148 bdhon francs investment73level0 = ~$\[BeginVC I EndVC\]level1 = \[ level0 I \[BeginVC level0 EndVC\] \]*curlev = \[ level1 \[ \[BeginVC levell EndVC\] \]*The regular expression levelO matches any stringwhich does not contain any BeginVC or EndVC marks,i.e, an embedded clause, level1 matches any string thatcontains strings matching levelO or entire embeddedclauses that contains only levelO matching strings.Therefore, curlev (which stands for Current Level)matches trings that either do not contain any embeddedclauses, or may contain entire embedded clauses to amaximal depth of 2 embedded levels.We can easily extend the definition of curlev to handlepunctuated embeddings such as texts within parenthesesor hyphens.
We define Bs as the beginning of such em-beddings (either an opening parenthesis or a hyphen)and Es as the ending (a closing parenthesis or anotherhyphen):Bs = \["("  I \]Es = \[" )"  I \]and redefine the curler expression as:level0 = ~$\[BeginVC \[ EndVC I Bs \ [  Es\]level1 = \[ level0 I \[BeginVC level0 EndVC\]I \[ Bs level0 Es\] \]*curlev = \[ levell \] \[BeginVC levell EndVC\]l \[ Bs level1 Es\] \]*Given these definitions, we can control the linguisticspace in which rules and constraints apply.
For instance,Subject constraint 3 can be written this way:TSUBJ  -> \[\] II -\[curlev\ \[COORD \[ BeginVC \[ EndVC i Bs \[Es\]BeginNP ~$EndNP EndNP TSUBJ~\[ curlev TSUBJ  curlev\] Beginv \]which means: remove a potential subject tag (TSUBJ)whenever there is another potential subject on the rightwhich is not preceded by a coordination.
The other po-tential subject should be the last one before the finiteverb.
All these considerations are stated over the samesentence level (expressed as curlev) so that embeddingsrelative to a given level and what they contain are notconcerned at all.3.3 Extraction of Dependency RelationsOnce the subjects and objects are tagged, we get a shal-low parse of the sentence where phrasal units and func-tion tags appears, as shown in the example below:\[VC \[NP Le pr6sident NP\]/SUBJ \[PP du CSAPP\], \[NP Jacques  Boutet NP\] , a d6cid6 VC\]\[VC de publier VC\] \[NP la professionNP\ ] /OBJ  \[PP de foi PP\] ./SENTOne nontrivial task consists in associating the subjectsand objects with the right verb.
There are two main dif-ficulties: with subjects and objects of embedded sen-tences, and with coordinated verbs and shared subjectsand objects.To find out which is the subject/object of a givenverb, only the Nps tagged as subjects/objects that are inthe same level should be considered.
This is necessary inorder to avoid overgeneration of dependencies, that is,extracting the subject of an embedded sentence as thesubject of the main verb or of another embedded sen-tence.
The definition of curlev is very useful for suchtask.
For instance, the transducer obtained from the fol-lowing regular expression7:\[\[ 0 .x.
\["SUBJ:'\] \]\[\[7"I .x.
o I\[ BeginNP ~$\[EndNP\] EndNP\] \[SUBJ : ".-)" \]\[ curlev .x.
0 \]\[Beginv .x.
BeginVC\] \[~$Endv\] \[Endv .x.EndVC\].x.
O l\]can be applied on the previous sentence to extract nor-mal subject/verb dependencies:SUBJ:  \[NP le president NP\] -->\[VC a d6cid6 VC\]Other similar expressions are written for the extractionof inverted subjects, shared subjects and objects.
All theextracting expressions are joined using the Union op-erator \] and compiled into a single transducer whichtakes as input shallow parses and produces ubject/verband object/verb dependencies.3.4 SamplesBelow are some samples from the output of the extract-ing transducer.7 This expression applies to the parsed sentence.
It leaves un-changed any NP  marked as SUBJ  and the corresponding VCfound at the same level.
All other segments are erased andrelational markings (the "SUB J:" tag and the arrow"~'?)
are inserted.74Sentence 1: A l'interpr6tation des sentiments pr6sidentielss'ajoute l'atmosph6re d surench6re politique qui pr6c6detout congr6s du Parti socialiste.Shallow parse:\[VC \[PP A I' interpr6tation PP\]\[PP des sentiments PP\] lAP pr6sidentiels AP\]:v s' ajoute v: VC\]\[NP l'atmosphare NP\]/<SUBJ\[PP de surenchare PP\] \[AP politique AP\]\[VC \[NP qui NP\]/SUBJ :v pr6cade v: VC\] tout\[NP congr6s NP\]/OBJ \[PP du Patti PP\] \[APsocialiste AP\] .Dependencies:SUBJ: \[VC s' ajoute VC\]\[NP r atmosph6re NP\]SUBJ: \[NP qui NP\] ---> \[VC pr6cade VC\]OBJ: \[VC pr6cade VC\] ~-- \[NP congas  NP\]Sentence 2: En relanfant ainsi d61ib~r6ment ragitation surdes enjeux de la gr~ve de septembre 1988, Mr Guilhaumemet en difficult6 le gouvernement t force les autres PDGde raudiovisuel public it choisir leur camp.Shallow parse:\[VC \[VC En relan~ant VC\] ainsi dalib~r6ment\[NP 1' agitation NP\]/OBJ\[PP sur des enjeux PP\] \[PP de la grave PP\]\[PP de septembre PP\] \[NP 1988 NP\]/N,\[NP Mr Guilhaume NP\]/SUBJ :v met v: VC\]\[PP en difficult6 PP\]\[NP le gouvernement NP\]/OBJ\[VC et :v force v: VC\]\[NP les \[AP autres AP\] PDG NP\]/OBJ\[PP de l'audiovisuel PP\] lAP public AP\]\[VC & choisir VC\] \[NP leur camp NP\]/OBJ .Dependencies:SUB.I: \[NP Mr Guilhaume NP\] ~ \[VC met VC\]SUB J: \[NP Mr Guilhaume NP\] ---> \[VC force VC\]OBJ: \[VC En relan~ant VC\] ~ \[NP 1' agitation NP\]OBJ: \[VC met VC\] , -  \[NP le gouvernement NP\]OBJ: \[VC force VC\]\[NP les lAP autres AP\] PDG NP\]OBJ: \[VC ~t choisir VC\] ~ \[NP leur camp NP\]Sentence 3: Mais, d6j/t, l'id6e que ceux-ci puissent avoir laresponsabilit~ d' un mus6e class6 (6tablissement d6pendantjuridiquement d'une ville ou d' un d6partement, mais dontles responsables sont nomm6s par l'Etat) provoque unecertaine 6motion chez les nationaux (voir le Monde du 23novembre 1989).Shallow parse:\[VC Mais, d6jtt, \[NP l'id6e NP\]/SUBJ\[VC que \[NP ceux-ci NP\]/SUBJ:v puissent v: VC\]\[VC avoir VC\] \[NP la responsabilit6 NP\]/OBJ\[PP d' un mus6e PP\] \[AP class6 AP\]( \[NP 6tablissement NP\]/NlAP d6pendant AP\] juridiquement\[PP d' une viUe PP\]ou \[PP d' un d6partement PP\], mais\[VC dont \[NP les responsables NP\]/SUBJ:v sont nomm6s v: VC\] \[PP par r Etat PP\] ):v provoque v: VC\]\[NP une \[AP certaine AP\] 6rnotion NP\]/OBJ\[PP chez les nationaux PP\]( \[VC voir VC\] \[NP le Monde NP\]/OBJ\[PP du 23 novembre PP\] \[NP 1989 NP\]/N ) .Dependencies:SUBJ: \[NP 1' id6e NP\] ---> \[VC provoque VC\]SUB J: \[NP ceux-ci NP\] ~ \[VC puissent VC\]SUB J: \[NP les responsables NP\] .-.q,\[VC sont nomm~s VC\]OBJ:OBJ:OBJ:\[VC avoir VC\] ~ \[NP la responsabilit6 NP\]\[VC provoque VC\]\[NP une lAP certaine AP\] 6motion NP\]\[VC voir VC\] ~-- \[NP le Monde NP\]4 Eva luat ionThe 15 networks of the parser and extractor equireabout 750 KBytes of disk space.
The speed of analysis isaround 150 words per second on a SPARCstation 10,including preprocessing (tokenisation, lexical lookup,POS tagging), parsing and dependency extraction s.We evaluated the extraction on three different types ofcorpus: newspaper Le Monde (187 sentences, 4560words, average 24.3 words/sentence), financial reports(524 sentences, 12551 words, average 24words/sentence) and technical documentation (294 sen-tences, 5300 words, average 18 words/sentence).
Thesentences were selected randomly; they are independentfrom the corpus used for grammar development.The evaluation concentrated onrecognition of surfacenominal and pronominal subjects and on nominal directobject.
Relations are counted as correct only if both thegoverning head and its argument are correct (for in-stance, we counted the subject/Verb relation as errone-ous if the verb group was not fully correct, even if thesubject was).Results are given in tables 1 and 2.8 Future work includes optimismg the implementauon tospeed up the process.75CorpusNewspa-perFmancmlreportsTechmcDocActualSubj.350452275Taggedas CorrectSu~ect Sub Tag324 306430 418263 238Preci-sion %94 497.290.5Recall%87 492.586 5Table 1: SubJect recognmon on three different corporaPreci- ' Recall Corpus Tagged as CorrectObjects Object Obj Tag slon % %Newspa- 214 198 171 86 3 79.9perFinancial 135 160 124 84.4 91 8reportsTechmc.
337 311 275 88.4 81 6DocTable 2: Object recognmon on three different corporaActual4.1 Error analys isWe conducted a detailed error analysis on the newspapercorpus.
The major source of subject/verb and object/verberrors was identified for each sentence.
If  the samesource of error accounts for more than one error in agiven sentence, it is counted once.
There may be alsomore than one source of error for the same sentence.
Weidentified 81 sources of errors, distributed across the 68sentences that included at least 1 error (table 3).Source of errors Number ofoccurrenceserrors due to tagger 20errors due to coordination 9errors due to apposition or NP enumeration 9errors due to time expressions 7errors due to pronouns 7errors due to mctse 2errors due to subject inversion (not incise) 3messed input (typos, missing blanks) 3numerical expressions 3punctuation 3NP adverbials (other than time expressions) 2errors due to missing determiners 2errors due to frozen expressions 2errors due to clause boundaries 2errors due to negation (e.g.
pas moins de) 2predicate of non-finite verbs 2bugs 1emphatic onstructions 1book title (as object) 1Table 3.
Error AnalysisAmong the errors, some can be corrected easily withlimited additional work.
For instance, the tested versionof the parser did not include preprocessing for time ad-verbials or numerical expressions.
The tagset associatedwith the POS tagger did not provide enough distinctionsbetween different ypes of pronouns 9.The most significant errors are due to long NP se-quences (coordination, enumeration, apposition) and tothe POS tagger.
NP sequences are challenging, as it isdifficult for the parser to distinguish between apposi-tions, enumeration and coordinated NPs.
Various pa-rameters are to be taken into account (determiners,proper nouns, punctuation, semantic relations, etc.
)many of which go beyond the scope of a shallow (oreven non shallow) syntactic parser.4.2 Errors due to POS taggerThere is little to be found in the literature on the impactof POS tagging errors on syntactic analysis.
Out of 187sentences in our newspaper corpus, 20 had subject orobject errors due primarily to tagging errors.
This doesnot mean that other sentences did not have tagging er-rors, but such errors had no impact on the assignment ofsubjects and objects (neither on the identification ofhead verbs).
This is encouraging, because taggers with97% acccuracy at word level may have a limited accu-racy at sentence level (70%).Table 4 shows the extraction results from sentenceswhere errors due to the POS tagger had no impact.
Thefigures between parentheses refer to the results obtainedon the whole corpus, i.e.
including tagging errors.CorpusSubjectsObjectsTable 4.
Sub:errorsActual Tagged Correct  Precl- Recallas Tag slon % %296 278 266 95.6 89 8(94 4) (87 4)177 175 152 86.8 85 8(86 3) (79 9)ect and object recognition without POS taggingThe improvement is mostly for recall of objects.
Thisis due to the French specific ambiguity for the words de,du, des which can be indefinite determiners or preposi-tion+determiner sequences.
The tagger does not do agood job at distinguishing between the two tags, espe-cially in postverbal position.
This has an obvious impacton the dependency analysis, as segments mistagged asPPs cannot be identified as subjects or objects.9 This project started around mid-96; some of the obviousimprovements are already part of a recently updated version.765 ConclusionWe presented a finite-state approach to subject and ob-ject dependency extraction from unrestricted Frenchcorpora.
The method involves incremental finite-stateparsing and transductions for dependency extraction,using only part-of-speech information.
The evaluationon different corpora (22,000 words) shows high accu-racy and precision.The method is being expanded to other dependencyrelations and to other languages.The extracted ependencies can be used to automati-cally build subcategorisation frames or semantic restric-tions for verb arguments, which, in turn, can be reusedin further steps of incremental parsing.
They can also beused for knowledge xtraction from large corpora andfor document indexing.Acknowledgments:We are grateful to Annie Zaenen and Lauri Karttunen fortheir editorial advices.References\[Abney, 1991 \] Steve Abney.
Parsing by chunks.
Princtpled-BasedParsmg, R. Berwick, S. Abney, and C. Tenny, edi-tors.
Kluwer Academic Publishers, Dordrecht, 1991.\[AR-Mokhtar and Chanod, 1997\] Salah AR-Mokhtar andJean-Pierre Chanod.
Incremental Finite-State Parsing.Proceedings of ANLP-97, Washington, 1997.\[Appelt et al 1993\] Douglas E. Appelt, Jerry R. Hobbs,John Bear, David Israel, and Mabry Tyson.
FASTUS: AFinite-State Processor for Information Extraction fromReal-World Text.Proceedings 1JCA1-93, Charnbery, France, August 1993.\[Brent, 1991\] Michael Brent.
Automatic Acquisition ofsubcategorization frames from untagged texts.
Proceedmgsof the 29th Annual Meetmg of the Associationfor Computattonal Lmgutsttcs.
Berkeley, CA, 1991.Briscoe and Carroll, 1994\] Edward Briscoe and John Car-roll.
Towards Automatic Extraction of Argument Structurefrom Corpora.
Technical Report MLTT-006, Rank XeroxResearch Centre, Meylan, 1994.\[Chanod and Tapanainen, 1995\] Jean-Pierre Chanod andPasi Tapanainen.
Tagging French - comparing astatisticaland a constraint-based method.
Proceedings ofthe SeventhConference of the European Chapter of the Association forComputat:onal Linguistics, pages 149-- 156, Dublin, 1995.\[Chanod and Tapanainen, 1996\] Jean-Pierre Chanod andPasi Tapanainen.
A Robust Finite-State Parser for French.Proceedmgs ofESSLLI'96 Workshop on Robust ParsingPrague, 1996.\[Federici etal, 1996\] Stefano Federici, Simonetta Monte-magni and Vito Pirrelli.
Shallow Parsing and Text Chunk-ing: a View on Underspeeification in Syntax.
ProceedingsSLLI'96 Workshop on Robust Parsing, Prague, 1996.\[Grefenstette, 1994\] Gregory Grefenstette.
FExplorattons mAutomat:e Thesaurus Dtscovery.
Kluwer Academic Press,Boston, 1994.\[Grishman and Sterling, 1992\] Ralph Grishman and JohnSterling.
Acquisition of Selectional Patterns.
Proceedings ofCohng-92 Nantes, 1992.\[Karttunen, 1996\] Lauri Karttunen.
Directed replacement.Proceedings of the 34th Annual Meeting of the Assoczatzonfor Computatwnal Lmgulsttcs, Santa Cruz, USA, ssociationfor Computational Linguistics.
1996.\[Koskenniemi etal., 1992\] Kimmo Koskenniemi, Pasi Ta-panainen, and Atro Voutilainen.
Compiling and using finite-state syntactic rules.
Proceedings ofthe Fourteenth Interna-nonal Conference on Computatzonal Lmgulstzcs COLING-92, Nantes, 1992.\[Roche, 1993\] Emmanuel Roche.
Analyse syntaxique trans-formationnelle du francais par transducteurs et lexique-grammaire, Ph.D. dissertation, Universit6 deParis 7, 1993.\[Sanfilippo, 1994\] Antonio Sanfilippo.
Word KnowledgeAcquisition, Lexicon Construction and Dictionary Compi-lation.
Proceedings ofCohng-94, Kyoto, 1994.\[Voutilainen and Tapanainen, 1993\] Atro Voutilainen andPasi Tapanainen.
Ambiguity resolution in a reductionisticparser.
Proceedings ofthe Sixth Conference ofthe EuropeanChapter of the Assoetatton for Computatwnal Lmgulstws,Utrecht, 1993.77
