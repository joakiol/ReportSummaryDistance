Automatic Semantic Tagging of Unknown Proper NamesAlessandro CUCCHIARELLIUniversith di AnconaIstituto di InformaticaVia Brecce Bianche60131 Ancona, Italiaalex @inform.unian.itDanilo LUZIUniversith di AnconaIstituto di InformaticaVia Brecce Bianche60131 Ancona, Italialuzi @ inform.unian.itPaola VELARDIUniversit~ di Roma 'La Sapienza'Dip.
di Scienze delrlnformazioneVia Salaria 11300198 Roma, Italiavelardi @ dsi.uniroma 1 .itAbstractImplemented methods for proper namesrecognition rely on large gazetteers ofcommon proper nouns and a set ofheuristic rules (e.g.
Mr. as an indicator of aPERSON entity type).
Though theperformance of current PN recognizers isvery high (over 90%), it is important onote that this problem is by no means a"solved problem".
Existing systemsperform extremely well on newswirecorpora by virtue of the availability oflarge gazetteers and rule bases designedfor specific tasks (e.g.
recognition ofOrganization and Person entity types asspecified in recent Message UnderstandingConferences MUC).However, large gazetteers are not availablefor most languages and applications otherthan newswire texts and, in any case,proper nouns are an open class.In this paper we describe a context-basedmethod to assign an entity type tounknown proper names (PNs).
Like manyothers, our system relies on a gazetteer anda set of context-dependent heuristics toclassify proper nouns.
However, due to theunavailability of large gazetteers in Italian,over 20% detected PNs cannot besemantically tagged.The algorithm that we propose assigns anentity type to an unknown PN based onthe analysis of syntactically andsemantically similar contexts already seenin the application corpus.The performance of the algorithm isevaluated not only in terms of precision,fo l lowing the tradit ion of MUCconferences, but also in terms ofInformation Gain, an information theoreticmeasure that takes into account thecomplexity of the classification task.IntroductionIn terms of syntactic categories, propernouns are lexical NPs that can be formedby primitive proper names (Adol -fo_Battaglia), groups of proper nouns ofdifferent semantic ategories (San Paolodi Brescia), and also of non-proper nouns(Banca dei regolamenti internazionali).
Inthe latter case, capital letters are optional,making the problem of PN itemsidentification even more complex.In the literature, it is accepted that anadeq.uate treatment of proper nounsreqmres the use of a context-sensitivegrammar (McDonald, 1996).
McDonaldpoints out that the context sensitivityrequirement involves two complementarytypes of evidence: internal and external.The internal evidence, can be derived fromthe sequence of words in a text (propernouns and trigger words, such as Inc., &,Ltd., Company, etc.
), and is gained inalmost all state-of-art PNs recognisers bythe use of large gazetteers and lists oftrigger words.The external evidence is the context of aproper noun, that provides classificatorycriteria to reinforce internal evidence, ifany, or supplies some classificatoryevidence.
In fact, proper names form anopen class, making the incompleteness ofgazetteers an obvious problem.The methods for recognition of propernouns (PNs) described in literature closelyreflects this view of the problem.PN identification typically includes:?
a gazetteer lookup, which locates simpleand complex nominals identifyingcommon PNs, such as companies,person names, locations, etc.?
a set of patterns or rules, stated in termsof part-of-speech, syntactic or lexicalfeatures (e.g.
Mr. as an indicator of aPERSON entity type), orthographicfeatures (e.g.
capitalization), etc.286Proper nouns recognition has recentlyattracted much attention especially in thearea of Information Extraction, where thisproblem is known as the Named Entityrecognition task.
The highest performingsystems include large numbers of hand-coded rules, or patterns, such as VIE(Humphreys et al 1996), the UMasssystem (Fisher et al 1997) and Proteus(Grishman et al 1992), but lately a highperformance has been obtained by the useof statistical methods.
For example,Ny.mble (Bikel et al 1997) learns namesusing a trained approach based on avariant of Hidden Markov Models.However, a 90% success rate is reached atthe price of tagging manually around halfa million words.
Since PNs are mostlydomain-specific, presumably a comparableeffort is needed when shifting to differentdomains.High performances of the existing systemsare by no means the result of many yearsof studies and research in the area of IEfrom newswire English texts, promotedand funded by the Message UnderstandingConferences (MUC) organizers.
Yet, thereis no evidence that a similar performancecould be obtained in other languages anddomains, if not at the price of a similareffort for rule writing (or manual training),and for the compilation of a high-coverage gazetteer.
A recent study (Palmerand Day, 1997) established that thebasel ine performances of the PNrecognition task for several anguages andapplication domains vary between 34%and 71%.
The lower bound is calculatedby considering a simple algorithm thatrecognizes PNs on the basis of a list offrequent proper nouns seen in a trainingset.The method we propose in this papercombines symbolic and statisticalapproaches to classify unknown PNs usingcontext evidence previously extractedfrom the application corpus.
The methodcan be used to overcome the limitation ofsmall gazetteers and poorly encoded rulebases.Our method is untrained: what is needed isa learning (raw) corpus, a surface syntacticanalyzer, a dictionary of synonyms, a listof category names for classifying PNs (weused the categories proposed in theforthcoming MUC-7), and a "start-up"gazetteer and rule base, used to acquire aninitial model of typical PNs contexts.In the next section, we describe the methodin detail.
Section 3 is dedicated to adiscussion of experimental results.2 The MethodThe problem of PN recognition has beenconsidered in our group in the context ofthe European project ECRAN, aimed atimproving domain adaptability of IEsystems through the integrated use ofcorpora and MRDs.A first version of the Named Entity (NE)recognizer, in Italian, closely reproducedthe architecture of the VIE recognizer,developed at the University of Sheffield(Humphreys et al 1996).Proper noun recognition is initiallyperformed in two steps:1) common proper nouns are identifiedusing a gazetteer, structured in filesand related lists of trigger words foreach proper nouns category (e.g.
"Gulf" for LOCATIONs ,  or"Association" for ORGANIZATIONs);2) a context-sensitive grammar of about250 rules is used to parse propernouns in contexts.
The majority ofrules uses internal evidence to identifyand classify proper nouns made ofcomplex NPs.
For example thefollowing rule is used to recognizestreet names:rule(tagged_location_np(s form: \[via, ", F2,' ',F3\],sem:A^B),\[nome(s..form:via, sem:_a_),organ_names_np( s_form: F2,sem:_^_),num(s_form:F3)\])Ex: " via Giorgio Marini 34 "When running these first two modules on aone million word corpus of economicnews (extracted from the newspaper II Sole24 Ore), we obtained the followingperformances: 84% precision, 85% recall,about 20% proper nouns correctlyidentified as such, but NOT classified.Unknown proper nouns are identifiedinitially by the Brill part-of-speech tagger(Brill, 1995).
Complex unknown nominals(e.g.
Quick Take 200) are partly detectedby simple heuristics.One of the motivations for such a highpercentage of unknowns and relatively lowperformance (as compared with state-of-art PN recognizers) is that at the presentstate of implementation the gazetteer has a287l imited coveragel ;  yet, the problem ofunknowns is generally recognized ascrucial in real-world applications, becauseoroDer nouns are an open class.We have therefore devised a method toreinforce external evidence, using acorpus-driven algorithm to incrementallyupdate the gazetteer and classification ofunknown PNs in running texts.The algorithm to classify unknown propernouns uses the fo l lowing l inguisticresources: a (raw text) learning corpus inthe same domain as the application, ashallow corpus parser, a "seed" gazetteer,and a dictionary of synonyms.The shallow parser (Basili et al 1994),extracts f rom the learning corpuselementary syntactic relations such assubject-object, noun-preposition-noun, etc.A syntact ic l ink (hereafter esl) isrepresented as:esli(wj, mod(typei, wk))where w i is the head word, Wk is themodifier, ~-ad typei is the type of syntacticrelation (e.g.
PP(of), PP(for), SUB J-Verb,Verb-DirectObject, etc.
).The learning corpus is previous lymorpho log ica l ly  and syntact ica l lyprocessed.
Step 1 and 2 described at thebeginning of this section are used to detectPNs.
A database of esls including knownPNs  2 is then created and used by thealgorithm to assign a category to unknownPNs.
The algorithm works as follows:let PN_U be an unknown proper noun, i.e.a single word or a complex nominal.
LetCpn = (Cpnl, Cpn2 ..... CpnN) be the set ofsemantic ategories for proper nouns (e.g.Person,  Organizat ion,  Product etc.
).Finally, let ESL  be the set of elementarysyntactic links (esl) extracted from the1 The context sensitive grammar closely reflects,with extension, that developed for a similarapplication in the English VIE system.Therefore, low performance is likely due to thelow-coverage gazzetteer.
The absence of availablelinguistic resources in languages other thanEnglish is a well known problem.2Note that the database is not manually inspectedfor correctness (POS tagging and parsing errors).However, the parser assigns to each detected esl astatistical measure of confidence, calledplausibility (Basili et al 1994b).learning corpus that include PN_U as oneof its arguments.For each esli in ESL let:es li(w j, m od(typei, Wk)) = esli(x, PN U)where x=wj or Wk and PN_U =Wk or wj,typei is the syntactic type of esl (e.g.
N-di-N, N_N, V-per-N ecc), and further let:pl(esli (x, PN_U)be the plausibility of a detected esl.
Theplausibility is a measure of the statisticalevidence of a detected syntactic link (Basiliet al 1994b), that depends upon local (i.e.at the sentence level) syntactic ambiguityand global corpus evidence.Finally, let:- ESLA be a set of esls defined as follows:for each esli(x,PN_U) in ESL  put inESLA the set of es l j (x ,PNj) ,  in thecorpus, with type=typei, x in the sameposition of esli, and PNi a known propernoun, in the same position as PN_U inesli,ESLB be the set of eslk defined asfollows: for each esli(x,PN_U) in ESLput in ESLB the set of eslj(w,PNj), in thecorpus, with type=typei, w in the sameposition of x in esli, Sim(w,x)> 8, andPNj a known proper noun, in the sameposition as PNU in esl i. Sim(w,x) is asimilarity measure between x and w. Inour first experiments, Sim(w,x)> 8 iff wis a synonym of x.For each semantic ategory Con i computeevidence(Cpnj) as shown ih-Figure 1,where:amb(esl(x, PNi)) is a measure of theambiguity of x and PNj in esli;- tx and 13 are experimentally determinedweights (currently, t~=0.7 and 13=0.3).The selected category for PN_U is:C=argmax( evidence( Cpnk) )=maxj( evidence( Cpnj)The underlying hypothesis is that, in agiven application corpus, a PN has aunique sense.
This is a reasonablerestr ict ion supported by empir ica levidence (see also (Gale et al 1992)).
Analternative solution would be to select the"best performing" tags, and then apply288?
(1)ev idence (Cpn j) =~,  (pl(esl i (x, PNj)) * amb(esl i (x, PN~)))(~ esll EESL a ,C(PNI)=Ct,,, jEpl(esl i(x,PNj)esl i ~ESL ~ ,anyPN+E (pl (esl i (w, PNj)) * arab (esl i (x, PNj)))~ eslj ,~ESL a .C(PN j )=Cp./Ep l (es l  i (w,PNj)eslj EESL s ,anyPNFigure 1 - The evidence(Cpnj) computation formulasome WSD algorithm to predict he precisesense?
in running texts.3 Discuss ion of  the Exper imentIn our experiment, we used a corpus ofone million words extracted from articlesin the II Sole 24 Ore economic newspaper.A database of 76055 esls including propernouns was obtained.Table 1 shows the distribution of esls bycategory, and the prior probability (i.e.relative distribution) of each category.Category N ?
ESLi Prior Prob.ORGANIZ 26418 0.347LOCATION 25087 0.330PERSON 20558 0.270DATE 544 0.007TIME 879 0.011MONEY 1076 0.014PERCENT 520 0.007PRODUCT 2671 0.035OTHERS 1112 0.015Tot.ESL 76055Table 1 - PN distribution by categoryThe semantic ategories in Table 1, withthe addition of Product, are those that willbe used for Named Entity task evaluationin the forthcoming MUC-7 contest.In Figure 2, a complete experiment isreported.
In the figure, an esl isrepresented as a list, for example (0.5G_N_P_N Quick_Take_200 0 1 indocumento) .
The detected esl is'Quick_Take_200 in documento '(Quick_Take_200 in document), thesyntactic type is G N P N (noun-preposition-noun), the plausibility is 0.5,the initial category of Quick_Take_200 is0 (= unknown) and its ambiguity isinitially set to 1.It is seen in the figure that some detectedesls do not contribute to the computationof (1) (e.g.
acqu is i re  conQuick Take_200 to acquire withQuick_Take_200) while some other eslturns out to be particularly informative(e.g.
qualita' di Quick_Take_200 qualityof Quick_Take_200)For the name Quick_Take_200 (a softwareproduct), the category 8 is finally selected(PRODUCT, as shown in the figure).An extended experiment was designed asfollows:We selected from the corpus 35 PNs foreach of the .
following categories:Organization, Person, Location andProduct 3.
The PNs are selected by rangesof frequency in the corpus, except forProducs, that are very rare in our excerptof the II Sole 24 Ore: here we selected the35 top frequency PNs.We then removed each of the 140 PNsfrom the gazetteer, one at the time, andattempted a re-classification using ouralgorithm.To evaluate the performances we used, inaddition to the classical Precision measure,the Information Gain (Kononenko andBratko, 1991).The Information Gain is an information-theoretic measure that takes into accountthe complexity of the classification task.3The other categories are less interesting in ourview.
Numbers, dates etc.
are recursive andregular phenomena that can be detected ina moregeneral way by the use of specific grammars orpattern matchers.289pRop~ N~E:  Quick_Take_2000.5 G_N_P_N Quick_Take_200 0 1 in d:cxnmato1.0 G_N_V Quick_Take 200 0 1 nil dotareESLB= 1.0 G_N_V Apple 1 1 nil fornirem= 1.0 G_N_V Pcwer Fc 1 1 nil fonzire~= 1.0 G N_V Tank Franca/se_Chrcr~reflex 8 1O.
1 G_AgI_P_N acquisito ccn Quick_Take_200 0 10.i G_p~._P_N acquisire eon Quick_Take_200 0 I0.333000 G_N_P_N Forza di Quick_Take_200 0 1ESLA= 0.333000 G_~._Pjq Forza di Linea_Pret 2 1ESI23= 0.333000 G N_P._N grande di ~_il 3 1ESLB= 0.250000 G_j~_P_N ~aL-z~e di Europa 2 1ESLB= 0.2 G_N_P_N gr-azrle di Casa 1 10.333000 G_N_P_N qualita' di Quick_Take_200 0 1ESLA= i.
0 G_N_P_N quali~' di ~ 8 1~-~R:: 0.333000 G__N P_N scrta di Iri 1 1ESI2~ i.
0 G__N_P_N generazic~e di G 3 1r~r~: 0.125000 G_N P_~ caratteristica di c~ 1 1ESLB= 0.250000 G_Jq__P_N caratteristica diMacinto~_Performa 8 1ESI~= 0.250000 G_N P_N caratteristica di Vs 8 1ESL~ 0.5 G_N._P_N marca di Arese 2 1o.
1 G_V_P_N acquisire ccn Oaick_Take_200 0 10.2 G V P N utilizzare ccn Quick_TaMe_200 0 10.333000 G_N_P_N Punti di Qu/ck_Take_200 0 10.333000 G_N_P_N aoquisizicme di Quick_Take 200 0 10.333000 G_N_P_~ c ~D~__cita' di Quick_Take_200 0 1RqTm= 0.167000 G_N_P_N portata di 280_F G 9 1k~rm= 0.2 G_N_P_N portata di 300_I~ 9 1ESLB= 0.333000 G_N_P_N mezzo di Cartier 3 1~= 0.333000 G N P N facilita' di Apple_Share 8 I0.333000 G_~_P_N immgine di Quick_Take_200 0 1Coefficient u: 0.7Coefficient ~: 0.3CLASS S/~_ESLA SLM_~ ~1 CR3 0.000 2.658 0.1092. iCC 0.333 0.750 0.2053 P~RSCIq 0.000 i.
666 0.0684 \[ATE 0.000 0.000 0.
0005 ~ 0.000 0.000 0.0006 ~ 0.000 0.000 0.0007 ~ 0.000 0.000 0.0008 PRCE/JL~ 1.000 1.833 0.6009 OIHERS 0.000 0.367 0.015S3M_ESLA= 1.333 SL IM_~= 7.274Max evidenoe category is: PRCILL-T0.333000 G_N_P_N 5 ~ t e  di Quick_Take_200 0 1 Selected category: PRCIx/urFigure 2 - A complete exampleIf P(C) is the prior (a-priori) probability 4that an instance c is a member of class C,and P'(C) is the probability of c e C, ascomputed by the classifier in a given test ti,the Information Gain I(ti) is defined as:I(ti) = log(1-P(C)) - log(1-P'(C))if P(C) > P'(C)orI(ti) = log(P'(C)) - log(P(C))if P'(C) > P(C)That is, if the classification is wrong, I(ti) isa penalty as high as the classification task4The prior probability can be easily computed ina learning set as the ratio between the number oftraining instances belonging to a class C and thetotal number of training instances.
In ourexperiment, the prior probabilities are listed inTable 1.was an easy one (i.e.
the prior probabilityof C was high).
If the classification iscorrect, I(ti) is a price as high as theclassification task was complex (i.e.
theprior probability of C was low).Over a test set of T cases, I is given by:I TI= - -z~, I ( t i )T i=1Table 2 illustrates the results.
It is seen thatunknown PNs in the three major categories(those for which there is evidence in thecorpus and in the gazetteer) have a veryhigh probabil ity of  being correctlyclassified (up to 100% for Organizations).On the contrary, we obtain poorperformances with Products.However, Product is interesting because:- there are no more than 50-60 productnames in the gazetteer (which we290manually added for the purpose of thisexperiment)there are no contextual rules forProducts in the context-sensit ivegrammar.Thus, both prior probability and priorknowledge on Products are close to zero.This is numerically evidenced by theInformation Gain: though we are notlearning much about Products, theInformation Gain is higher than for theother categories, and also as an absolutevalue (in (Kononenko and Bratko, 1991) a0,5 bit improvement is among the highestmeasured values in a comparativeexperiment).
In addition, the relativeprecision of classifying PNs as Product is100%.
This means that most products aremisclassified, but, if something is classifiedas Product, this information can be reliablyused to enrich the gazetteer.Category Precision Inf.
GainORGANIZ.
100.00% 0.11LOCATION.
91.43% 0.14PERSON 80.00% 0.23PRODUCT 22.86% 0.65Table 2 - Precision and Information Gainof the methodTable 3 reports an experiment on a smallcorpus extracted from another portion ofII Sole 24 Ore, indexed as "New Products".Category N ?
ESLi Prior Prob.ORGANIZ 735 0.160LOCATION 583 0.126PERSON 902 0.196DATE 7 0.001TIME 8 0.001MONEY 31 0.007PERCENT 114 0.025PRODUCT 2184 0.473OTHERS 262 0.057Tot.
ESL 4615Precision Inf.
GainPRODUCT 88.57% 0.12Table 3 - Experiment with a small "NewProduct" CorpusHere, the prior probability of Products isobviously higher, though -due to the poorgazetteer- there is an elevated number ofunrecognized products.In this corpus we selected and thenremoved 35 product names, and now thesystem correctly classifies 31.
Notice thatin this experiment the gazetteer and the PNgrammar are the same as before, The onlydifference is that the corpus provides moreevidence (contexts) concerning thoseproducts that have been recognized assuch.
Notice on the other side, that theInformation Gain now is very low.4 Conc lus ions  and Future  WorkOur current implementation of a PNanalyzer still has a limited performance,caused by a variety of problems that rangefrom unsatisfactory performance of state-of-art POS taggers in inflected languages,to l imited availability of l inguisticresources,in Italian, such as PN gazetteers.The algorithm that we propose has indeedthe purpose of overcoming limitations ofgazetteers and manual ly  def inedcontextual rules for PN recognition.
In(Cucchiarelli et al 1998) we also showhow to extend our method toincrementally update the initial gazzeteer.The performance of the proposedalgorithm is more than satisfactory.
Acomparison with existing systems isdifficult because in the literature global PNrecognition performances are reported,without consider ing the semanticclassification of unknowns as a subtask.The only exception is in (Wacholder et al1997) where the reported performance forthe sole semantic disambiguation task ofPNs is 79%.
In that paper, however,semantic disambiguation is performedamong a lower number of classes 5.The performance of our system is clearlyaffected by the dimension of the initialseed gazetteer and contextual rules.
If thesets ESLA and ESLB are large enough,obviously more examples of similarcontexts are found, even for unknown PNswith a single occurrence.In our test experiment, we always managedto find at least one or two similar contextsof an unknown PN, but in some cases theywere misleading and caused a wrongclassification, especially for Products.However, it may be possible to increase theevidence provided by the set ESLB byincluding contexts in which the words are5One of the advantages of Information Gain isthat, if widely adopted, this measure facilitatesthe comparison among learning methods withdifferent complexity of the classification task.291not strictly synonyms, but belong to thesame semantic ategory.One such experiment requires a wordtaxonomy, like for example WordNet.WordNet is currently unavailable in Italian(the first known results of theEuroWordNet project are too preliminary),therefore we plan to reproduce ourexperiment in English.Another strategy to improve performancesin absence of a substantial evidence is thedefinition of general (not contextual) rulesto capture unknown complex nominals.For example ,  looking at the Productexperiment in more detail, we found thatproduct names are often formed by verycomplex nominals, e.g.
Fiat- MareaWeekend 2000 (the name of a car model).Capturing complex nominals in absence ofanchors and specific contextual rules (herethe only anchor is Fiat, which appears inthe gazetteer as an Organization ame)may be difficult, and if a complex nominalis not captured as a unit, the resultingsyntactic ontext may be misleading (e.g.N_ADJ(Fiat_Marea_Weekend, 2000)).We believe that finding class-independentheuristics for capturing complex nominalsis a more "general" way of improving theperformance of the method, rather thanadding specific rules for specific entitytypes and enriching the gazetteer.AcknowledgmentsThe authors would like to thank Mr. EnzoPeracchia for his support in the softwaredevelopent and for aiding with experi-ments.
This research has been fundedunder the EC project ECRAN LE-2110.ReferencesBasili, R., Pazienza M.T., Velardi P. (1994) A(not-so) shallow parser for collocational naly-sis.
Proc.
of Coling '94, Kyoto, Japan, 1994.Basili, R., Marziali A., Pazienza M.T.
(1994b)Modelling syntax uncertainty in lexical acqui-sition from texts.
Journal of Quantitative Lin-guistics, vol.1, n.1, 1994.Bikel D.,Miller S., Schwartz R. and WeischedelR.
(1997) Nymble: a High-Performance L arn-ing Name-finder.
in proc.
of 5th Conference onApplied natural Language Processing, Wash-ington, 1997Brill, E (1995).
Transformation-based Error-Driven Learning and Natural Language Pro-cessing: A case study of Part of Speech Tag-ging.
Computational Linguistics, vol.
21, n.24, 1995Cucchiarelli A., Luzi D., Velardi P. UsingCorpus evidence for Automatic GazetteerExtension in Proc.
of first Language Resourcesand Evaluation, Granada, May 1988ECRAN: Extraction of Content: Research atNear Market.
http://www2.echo.lu/langeng/en/le 1/ecra~ecran.htmlFisher D., Soderland S., McCarthy J., Feng F.and Lenhart W. (1996) Description of theUMass system as used for MUC-6.http://ciir.cs.urnass.edu/info/psfiles/tepubs/tepubs.htmlGale, Church W. K. and Yarowsky D.(1992)One sense per discourse, in Proc.
of theDARPA speech and and Natural Languageworkshop, Harriman, N'Y, February 1992Grishraan R., Macleod C. and Meyers A.
(1992)NYU: description of the Proteus System asused for MUC-4.
in Proc.
of Fourth MessageUnderstanding Conference (MUC-4) June 1992Humphreys (1996) VIE Technical Specifications,1996/10/1815.
ILASH, University ofSheffield.Kononenko I. and Bratko I.
(1991) Information-based Evaluation Criterion for Classifier's Per-formance.
Machine Learning 6, pp.
67-80,1991Mani I., McMillian R., Luperfoy S., Lusher E.,Laskowski S. (1996) Identifying UnknownProper Names in Newswire Text.
in CorpusProcessing for Lexical Acquisition, J. Puste-jovsky and B. Boguraev Eds., MIT Press 1996.McDonald D. (1996) Internal and External Evi-dence in the Identification and Semantic Cate-gorization of Proper Names.
in Corpus Pro-cessing for Lexical Acquisition, J. Pustejovskyand B. Boguraev Eds., MIT Press 1996.Paik W., Liddy E., Yu E. and McKenna M.(1996) Categorizing and standardizing propernouns for effcient Information Retrieval.
inCorpus Processing for Lexical Acquisition, J.Pustejovsky and B. Boguraev Eds., MIT Press1996.Palmer D. and Day D. (1997) A Statistical Pro-file of the Named Enity Task.
in Proc.
of 5thConference on Applied natural Language Pro-cessing, Washington, 1997Wacholder N., Ravin Y. and Choi M. (1997)Disambiguation of Proper Names in Text.
inProc.
of 5th Conference on Applied naturalLanguage Processing, Washington, 1997292
