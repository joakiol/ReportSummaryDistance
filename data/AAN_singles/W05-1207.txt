Proceedings of the ACL Workshop on Empirical Modeling of Semantic Equivalence and Entailment, pages 37?42,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsDiscovering entailment relations using ?textual entailment patterns?Fabio Massimo ZanzottoDISCo, University of Milano-Bicocca,Via Bicocca degli Arcimboldi 8, Milano, Italy,zanzotto@disco.unimib.itMaria Teresa Pazienza, Marco PennacchiottiDISP, University of Rome ?Tor Vergata?,Viale del Politecnico 1, Roma, Italy,{pennacchiotti, pazienza}@info.uniroma2.itAbstractIn this work we investigate methods to en-able the detection of a specific type of tex-tual entailment (strict entailment), start-ing from the preliminary assumption thatthese relations are often clearly expressedin texts.
Our method is a statistical ap-proach based on what we call textual en-tailment patterns, prototypical sentenceshiding entailment relations among two ac-tivities.
We experimented the proposedmethod using the entailment relations ofWordNet as test case and the web as cor-pus where to estimate the probabilities;obtained results will be shown.1 IntroductionTextual entailment has been recently defined as acommon solution for modelling language variabilityin different NLP tasks (Glickman and Dagan, 2004).Roughly, the problem is to recognise if a given tex-tual expression, the text (t), entails another expres-sion, the hypothesis (h).
An example is determiningwhether or not ?Yahoo acquired Overture (t) entailsYahoo owns Overture (h)?.
More formally, the prob-lem of determining a textual entailment between tand h is to find a possibly graded truth value for theentailment relation t ?
h.Since the task involves natural language expres-sions, textual entailment has a more difficult naturewith respect to logic entailment, as it hides two dif-ferent problems: paraphrase detection and what canbe called strict entailment detection.
Generally, thistask is faced under the simplifying assumption thatthe analysed text fragments represent facts (ft forthe ones in the text and fh for those in the hypothe-sis) in an assertive or negative way.
Paraphrase de-tection is then needed when the hypothesis h carriesa fact f that is also in the target text t but is describedwith different words, e.g., Yahoo acquired Overturevs.
Yahoo bought Overture.
On the other hand, strictentailment emerges when target sentences carry dif-ferent facts, fh 6= ft.
The challenge here is to derivethe truth value of the entailment ft ?
fh.
For exam-ple, a strict entailment is ?Yahoo acquired Overture?
Yahoo owns Overture?.
In fact, it does not de-pend on the possible paraphrasing between the twoexpressions but on an entailment of the two factsgoverned by acquire and own.Whatever the form of textual entailment is, thereal research challenge consists in finding a rel-evant number of textual entailment prototype re-lations such as ?X acquired Y entails X owns Y?
or?X acquired Y entails X bought Y?
that can be usedto recognise entailment relations.
Methods for ac-quiring such textual entailment prototype relationsare based on the assumption that specific facts areoften repeated in possibly different linguistic forms.These forms may be retrieved using their anchors,generally nouns or noun phrases completely char-acterising specific facts.
The retrieved text frag-ments are thus considered alternative expressionsfor the same fact.
This supposed equivalence isthen exploited to derive textual entailment proto-type relations.
For example, the specific fact Yahoobought Overture is characterised by the two anchors37{Yahoo, Overture}, that are used to retrieve in thecorpus text fragments where they co-occur, e.g.
?Ya-hoo purchased Overture (July 2003).
?, ?Now thatOverture is completely owned by Yahoo!...?.
Theseretrieved text fragments are then considered goodcandidate for paraphrasing X bought Y.Anchor-based learning methods have been usedto investigate many semantic relations ranging fromvery general ones as the isa relation in (Morin, 1999)to very specific ones as in (Ravichandran and Hovy,2002) where paraphrases of question-answer pairsare searched in the web or as in (Szpektor et al,2004) where a method to scan the web for searchingtextual entailment prototype relations is presented.These methods are mainly devoted to induce entail-ment pairs related to the first kind of textual entail-ment, that is, paraphrasing as their target is mainlyto look for the same ?fact?
in different textual forms.Incidentally, these methods can come across strictentailment relations whenever specific anchors areused for both a fact ft and a strictly entailed fact fh.In this work we will investigate specific meth-ods to induce the second kind of textual entailmentrelations, that is, strict entailment.
We will focuson entailment between verbs, due to the fact thatverbs generally govern the meaning of sentences.The problem we are facing is to look for (or ver-ify) entailment relations like vt ?
vh (where vt isthe text verb and vh the hypothesis verb).
Our ap-proach is based on an intuition: strict entailment re-lations among verbs are often clearly expressed intexts.
For instance the text fragment ?Player wins$50K in Montana Cash?
hides an entailment rela-tion between two activities, namely play and win.
Ifsomeone wins, he has first of all to play, thus, win ?play.
The idea exploits the existence of what can becalled textual entailment pattern, a prototypical sen-tence hiding an entailment relation among two activ-ities.
In the abovementioned example the pattern in-stance player win subsumes the entailment relation?win ?
play?.In the following we will firstly describe in Sec.2 our method to recognise entailment relations be-tween verbs that uses: (1) the prior linguistic knowl-edge of these textual entailment patterns and (2) sta-tistical models to assess stability of the implied re-lations in a corpus.
Then, we will experiment ourmethod by using the WordNet entailment relationsas test cases and the web as corpus where to esti-mate the probabilities (Sec.
3).
Finally we will drawsome conclusions (Sec.
4).2 The methodDiscovering entailment relations within texts im-plies the understanding of two aspects: firstly, howthese entailment relations are usually expressed and,secondly, when an entailment relation may be con-sidered stable and commonly shared.
Assessing thefirst aspect requires the investigation of which arethe prototypical textual forms that describe entail-ment relations.
We will call them textual entailmentpatterns.
These patterns (analysed in Sec.
2.2) willenable the detection of point-wise entailment asser-tions, that is, candidate verb pairs that still need afurther step of analysis in order to be consideredtrue entailment expressions.
In fact, some of thesecandidates may be not enough stable and commonlyshared in the language to be considered true en-tailments.
To better deal with this second aspect,methods for statistically analysing large corpora areneeded (see later in Sec.
2.3).The method we propose may be used in either: (1)recognising if entailment holds between two verbs,or, (2) extracting from a corpus C all the impliedentailment relations.
In recognition, given a verbpair, the related textual entailment expressions arederived as instances of the textual entailment pat-terns and, then, the statistical entailment indicatorson a corpus C are computed to evaluate the stabilityof the relation.
In extraction, the corpus C shouldbe scanned to extract textual expressions that are in-stances of the textual entailment patterns.
The re-sulting pairs are sorted according to the statisticalentailment indicators and only the best ranked areretained as useful verb entailment pairs.2.1 An intuitionOur method stems from an observation: verb logicalsubjects, as any verb role filler, have to satisfy spe-cific preconditions as the theory of selectional re-strictions suggests.
Then, if in a given sentence averb v has a specific logical subject x, its selectionalrestrictions imply that the subject has to satisfy somepreconditions p, that is, v(x) ?
p(x).
This can beread also as: if x has the property of doing the action38v this implies that x has the property p. For example,if the verb is to eat, the selectional restrictions of eatwould imply, among other things, that its subject isan animal.
If the precondition p is ?having the prop-erty of doing an action a?, the constraint may implythat the action v entails the action a, that is, v ?
a.As for selectional restriction acquisition, the pre-vious observation can enable the use of corpora asenormous sources of candidate entailment relationsamong verbs.
For example ?John McEnroe won thematch...?
can contribute to the definition of the selec-tional restriction win(x) ?
human(x) (since JohnMcEnroe is a human), as well as to the induction (orverification) of the entailment relation between winand play, since John McEnroe has the property ofplaying.
However, as the example shows, classesrelevant for acquiring selectional preferences maybe more explicit than active properties useful to de-rive entailment relations (i.e., it is easier to derivethat John McEnroe is a human than that he has theproperty of playing).This limitation can be overcome when agentivenouns such as runner play subject roles in some sen-tences.
Agentive nouns usually denote the ?doer?
or?performer?
of some action a.
This is exactly whatis needed to make clearer the relevant property ofthe noun playing the logical subject role, in order todiscover entailment.
The action a will be the one en-tailed by the verb heading the sentence.
For exam-ple, in ?the player wins?, the action play evocatedby the agentive noun player is entailed by win.2.2 Textual entailment patternsAs observed for the isa relations in (Hearst, 1992)local and simple inter-sentential patterns may carryrelevant semantic relations.
As we saw in the pre-vious section, this also happens for entailment re-lations.
Our aim is thus to search for an initial setof textual patterns that describe possible linguisticforms expressing entailment relations between twoverbs (vt, vh).
By using these patterns, actual point-wise assertions of entailment can be detected or ver-ified in texts.
We call these prototypical patterns tex-tual entailment patterns.The idea described in Sec.
2.1 can be straight-forwardly applied to generate textual entailment pat-terns, as it often happens that verbs can undergo anagentive nominalization (hereafter called personifi-cation), e.g., play vs. player.
Whether or not anentailment relation between two verbs (vt, vh) holdsaccording to some writer can be verified looking forsentences with expressions involving the agentivenominalization of the hypothesis verb vh.
Then, theprocedure to verify if entailment between two verbs(vt, vh) holds in a point-wise assertion is: wheneverit is possible to personify the hypothesis vh, scan thecorpus to detect the expressions where the personi-fied hypothesis verb is the subject of a clause gov-erned by the text verb vt.Given the two investigated verbs (vt, vh) we willrefer to this first set of textual entailment patternsas personified patterns Ppers(vt, vh).
This set willcontain the following textual patterns:Ppers(vt, vh) ={?pers(vh)|number:sing vt|person:third,tense:present?,?pers(vh)|number:plur vt|person:nothird,tense:present?,?pers(vh)|number:sing vt|tense:past?,?pers(vh)|number:plur vt|tense:past?
}where pers(v) is the noun deriving from the person-ification of the verb v and elements such as l|f1,...,fNare the tokens generated from lemmas l by apply-ing constraints expressed via the features f1, ..., fN .For example, in the case of the verbs play and win,the related set of textual entailment expressions de-rived from the patterns will be Ppers(win, play)= { ?player wins?, ?players win?, ?player won?,?players won?
}.
In the experiments hereafter de-scribed, the required verbal inflections (except per-sonification) have been obtained using the publiclyavailable morphological tools described in (Minnenet al, 2001) whilst simple heuristics have been usedto personify verbs1.As the statistical measures introduced in the fol-lowing section are those usually used for study-ing co-occurrences, two more sets of expressions,Fpers(v) and F(v), are needed to represent the sin-gle events in the pair.
These are defined as:Fpers(v) = {?pers(v)|number:sing?, ?pers(v)|number:plur?
}F(v) = {?v|person:third,tense:present?,?v|person:nothird,tense:present?, ?v|tense:past?
}1Personification, i.e.
agentive nominalization, has been ob-tained adding ?-er?
to the verb root taking into account possiblespecial cases such as verbs ending in ?-y?.
A form is retainedas a correct personification if it is in WordNet.392.3 Measures to estimate the entailmentstrengthThe above textual entailment patterns define point-wise entailment assertions.
In fact, if pattern in-stances are found in texts, the only conclusion thatmay be drawn is that someone (the author of thetext) sustains the related entailment pairs.
A sen-tence like ?Painter draws on old techniques but cre-ates only decorative objects.?
suggests that paintingentails drawing.
However, it may happen that thesecorrectly detected entailments are accidental, that is,the detected relation is only valid for that given text.For example, the text fragment ?When a painter dis-covers this hidden treasure, other people are imme-diately struck by its beauty.?
if taken in insulationsuggests that painting entails discovering, but this isquestionable.
Furthermore, it may also happen thatpatterns detect wrong cases due to ambiguous ex-pressions like ?Painter draws inspiration from for-est, field?
where the sense of the verb draw is notthe one expected.In order to get rid of these wrong verb pairs, anassessment of point-wise entailment assertions overa corpus is needed to understand how much the de-rived entailment relations are shared and commonlyagreed.
This validation activity can be obtained byboth analysing large textual collections and applyingstatistical measures relevant for the task.Before introducing the statistical entailment indi-cators, some definitions are necessary.
Given a cor-pus C containing samples, we will refer to the abso-lute frequency of a textual expression t in the corpusC with fC(t).
The definition is easily extended to aset of expressions T as follows:fC(T ) =?t?TfC(t)Given a pair vt and vh we may thus define the fol-lowing entailment strength indicators S(vt, vh), re-lated to more general statistical measures.The first relevance indicator, Sf (vt, vh), is relatedto the probability of the textual entailment patternas it is.
This probability may be represented by thefrequency, as the fixed corpus C makes constant thetotal number of pairs:Sf (vt, vh) = log10(fC(Ppers(vt, vh)))where logarithm is used to contrast the effect of theZipf?s law.
This measure is often positively used interminology extraction (e.g., (Daille, 1994)).Secondly, another measure Smi(vt, vh) related topoint-wise mutual information (Fano, 1961) maybe also used.
Given the possibility of estimatingthe probabilities through maximum-likelihood prin-ciple, the definition is straightforward:Smi(vt, vh) = log10p(Ppers(vt, vh))p(Fpers(vt))p(F(vh))where p(x) = fC(x)/fC(.).
The aim of this mea-sure is to indicate the relatedness between two el-ements composing a pair.
Mutual information hasbeen positively used in many NLP tasks such as col-location analysis (Church and Hanks, 1989), termi-nology extraction (Damerau, 1993), and word sensedisambiguation (Brown et al, 1991).3 Experimental EvaluationAs many other corpus linguistic approaches, our en-tailment detection model relies partially on some lin-guistic prior knowledge (the expected structure ofthe searched collocations, i.e., the textual entailmentpatterns) and partially on some probability distribu-tion estimation.
Only a positive combination of boththese two ingredients can give good results when ap-plying (and evaluating) the model.The aim of the experimental evaluation is then tounderstand, on the one side, if the proposed textualentailment patterns are useful to detect entailmentbetween verbs and, on the other, if a statistical mea-sure is preferable with respect to the other.
We willhere evaluate the capability of our method to recog-nise entailment between given pairs of verbs.We carried out the experiments using the web asthe corpus C where to estimate our two textual en-tailment measures (Sf and Smi) and GoogleTM asa count estimator.
The findings described in (Kellerand Lapata, 2003) seem to suggest that count estima-tions we need in the present study over Subject-Verbbigrams are highly correlated to corpus counts.As test bed we used existing resources: a non triv-ial set of controlled verb entailment pairs is in factcontained in WordNet (Miller, 1995).
There, the en-tailment relation is a semantic relation defined at thesynset level, standing in the verb subhierarchy.
Each40Figure 1: ROC curvespair of synsets (St, Sh) is an oriented entailment re-lation between St and Sh.
WordNet contains 415entailed synsets.
These entailment relations are con-sequently stated also at the lexical level.
The pair(St, Sh) naturally implies that vt entails vh for eachpossible vt ?
St and vh ?
Sh.
It is then possibleto derive from the 415 entailment synset a test set of2,250 verb pairs.
As the proposed model is appli-cable only when hypotheses can be personified, thenumber of the pairs relevant for the experiment isthus reduced to 856.
This set is hereafter called theTrue Set (TS).As the True Set is our starting point for the eval-uation, it is not possible to produce a natural distri-bution in the verb pair space between entailed andnot-entailed elements.
Then, precision, recall, andf-measure are not applicable.
The only solution isto use a ROC (Green and Swets, 1996) curve mix-ing sensitity and specificity.
What we then need is aControl Set (CS) of verb pairs that in principle arenot in entailment relation.
The Control Set has beenrandomly built on the basis of the True Set: giventhe set of all the hypothesis verbs H and the set ofall the text verbs T of the True Set, control pairs areobtained randomly extracting one element from Hand one element from T .
A pair is considered a con-trol pair if it is not in the True Set.
For comparativepurposes the Control Set has the same cardinalityof the True Set.
However, even if the intersectionbetween the True Set and the Control Set is empty,we are not completely sure that the Control Set doesnot contains any pair where the entailment relationholds.
What we may assume is that this last set atleast contains a smaller number of positive pairs.Sensitivity, i.e.
the probability of having positiveanswers for positive pairs, and specificity, i.e.
theprobability of having negative answers for negativepairs, are then defined as:Sensitivity(t) = p((vh, vt) ?
TS|S(vh, vt) > t)Specificity(t) = p((vh, vt) ?
CS|S(vh, vt) < t)where p((vh, vt) ?
TS|S(vh, vt) > t) is the prob-ability of a candidate pair (vh, vt) to belong to TSif the test is positive, i.e.
the value S(vh, vt) of theentailment detection measure is greater than t, whilep((vh, vt) ?
CS|S(vh, vt) < t) is the probabilityof belonging to CS if the test is negative.
The ROCcurve (Sensitivity vs. 1 ?
Specificity) naturallyfollows (see Fig.
1).Results are encouraging as textual entailment pat-terns show a positive correlation with the entailmentrelation.
Both ROC curves, the one related to the fre-quency indicator Sf (f in figure) and the one relatedto the mutual information SMI (MI in figure), areabove the Baseline curve.
Moreover, both curvesare above the second baseline (Baseline2) applica-ble when it is really possible to use the indicators.
Infact, textual entailment patterns have a non-zero fre-quency only for 61.4% of the elements in the TrueSet.
This is true also for 48.1% of the elements in theControl Set.
The presence-absence in the corpus isthen already an indicator for the entailment relationof verb pairs, but the application of the two indica-tors can help in deciding among elements that havea non-zero frequency in the corpus.
Finally, in thiscase, mutual information appears to be a better indi-cator for the entailment relation with respect to thefrequency.4 ConclusionsWe have defined a method to recognise and extractentailment relations between verb pairs based onwhat we call textual entailment pattern.
In this workwe defined a first kernel of textual entailment pat-terns based on subject-verb relations.
Potentials ofthe method are still high as different kinds of textual41entailment patterns may be defined or discoveredinvestigating relations between sentences and sub-sentences as done in (Lapata and Lascarides, 2004)for temporal relations or between near sentences asdone in (Basili et al, 2003) for cause-effect relationsbetween domain events.
Some interesting and sim-ple inter-sentential patters are defined in (Chklovskiand Pantel, 2004).
Moreover, with respect to anchor-based approaches, the method we presented hereoffers a different point of view on the problem ofacquiring textual entailment relation prototypes, astextual entailment patterns do not depend on the rep-etition of ?similar?
facts.
This practically indepen-dent view may open the possibility to experimentco-training algorithms (Blum and Mitchell, 1998)also in this area.
Finally, the approach proposed canbe useful to define better probability estimations inprobabilistic entailment detection methods such asthe one described in (Glickman et al, 2005).ReferencesRoberto Basili, Maria Teresa Pazienza, and Fabio Mas-simo Zanzotto.
2003.
Inducing hyperlinking rulesfrom text collections.
In Proceedings of the Interna-tional Conference Recent Advances of Natural Lan-guage Processing (RANLP-2003), Borovets, Bulgaria.Avrim Blum and Tom Mitchell.
1998.
Combin-ing labeled and unlabeled data with co-training.
InCOLT: Proceedings of the Conference on Computa-tional Learning Theory.
Morgan Kaufmann.Peter F. Brown, Stephen A. Della Pietra, Vincent J.Della Pietra, and Robert L. Mercer.
1991.
Word-sensedisambiguation using statistical methods.
In Proceed-ings of the 29th Annual Meeting of the Association forComputational Linguistics (ACL), Berkely, CA.Timoty Chklovski and Patrick Pantel.
2004.
VerbO-CEAN: Mining the web for fine-grained semantic verbrelations.
In Proceedings of the 2004 Conference onEmpirical Methods in Natural Language Processing,Barcellona, Spain.K.W.
Church and P. Hanks.
1989.
Word associationnorms, mutual information and lexicography.
In Pro-ceedings of the 27th Annual Meeting of the Associa-tion for Computational Linguistics (ACL), Vancouver,Canada.Beatrice Daille.
1994.
Approche mixte pour l?extractionde terminologie: statistque lexicale et filtres linguis-tiques.
Ph.D. thesis, C2V, TALANA, Universite` ParisVII.F.J.
Damerau.
1993.
Evaluating domain-oriented multi-word terms from text.
Information Processing andManagement, 29(4):433?447.R.M.
Fano.
1961.
Transmission of Information: a sta-tistical theory of communications.
MIT Press, Cam-bridge,MA.Oren Glickman and Ido Dagan.
2004.
Probabilistictextual entailment: Generic applied modeling of lan-guage variability.
In Proceedings of the Workshop onLearning Methods for Text Understanding and Mining,Grenoble, France.Oren Glickman, Ido Dagan, and Moshe Koppel.
2005.Web based probabilistic textual entailment.
In Pro-ceedings of the 1st Pascal Challenge Workshop,Southampton, UK.D.M.
Green and J.A.
Swets.
1996.
Signal Detection The-ory and Psychophysics.
John Wiley and Sons, NewYork, USA.Marti A. Hearst.
1992.
Automatic acquisition of hy-ponyms from large text corpora.
In Proceedings ofthe 15th International Conference on ComputationalLinguistics (CoLing-92), Nantes, France.Frank Keller and Mirella Lapata.
2003.
Using the web toobtain frequencies for unseen bigrams.
ComputationalLinguistics, 29(3), September.Mirella Lapata and Alex Lascarides.
2004.
Inferringsentence-internal temporal relations.
In Proceedingsof the Human Language Technology Conference of theNorth American Chapter of the Association for Com-putational Linguistics, Boston, MA.George A. Miller.
1995.
WordNet: A lexical database forEnglish.
Communications of the ACM, 38(11):39?41,November.G.
Minnen, J. Carroll, and D. Pearce.
2001.
Appliedmorphological processing of english.
Natural Lan-guage Engineering, 7(3):207?223.Emmanuel Morin.
1999.
Extraction de liensse?mantiques entre termes a` partir de corpus de textestechniques.
Ph.D. thesis, Univesite?
de Nantes, Faculte?des Sciences et de Techniques.Deepak Ravichandran and Eduard Hovy.
2002.
Learningsurface text patterns for a question answering system.In Proceedings of the 40th ACL Meeting, Philadelphia,Pennsilvania.Idan Szpektor, Hristo Tanev, Ido Dagan, and BonaventuraCoppola.
2004.
Scaling web-based acquisition of en-tailment relations.
In Proceedings of the 2004 Confer-ence on Empirical Methods in Natural Language Pro-cessing, Barcellona, Spain.42
