Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural LanguageProcessing (HLT/EMNLP), pages 89?96, Vancouver, October 2005. c?2005 Association for Computational LinguisticsA Maximum Entropy Word Aligner for Arabic-English MachineTranslationAbraham Ittycheriah and Salim RoukosIBM T.J. Watson Research Center1101 Kitchawan RoadYorktown Heights, NY 10598{abei,roukos}@us.ibm.comAbstractThis paper presents a maximum entropyword alignment algorithm for Arabic-English based on supervised training data.We demonstrate that it is feasible to cre-ate training material for problems in ma-chine translation and that a mixture of su-pervised and unsupervised methods yieldssuperior performance.
The probabilisticmodel used in the alignment directly mod-els the link decisions.
Significant improve-ment over traditional word alignment tech-niques is shown as well as improvement onseveral machine translation tests.
Perfor-mance of the algorithm is contrasted withhuman annotation performance.1 IntroductionMachine translation takes a source sequence,S = [s1 s2 .
.
.
sK ]and generates a target sequence,T = [t1 t2 .
.
.
tM ]that renders the meaning of the source sequence intothe target sequence.
Typically, algorithms operateon sentences.
In the most general setup, one or moresource words can generate 0, 1 or more target words.Current state of the art machine translation systems(Och, 2003) use phrasal (n-gram) features extractedautomatically from parallel corpora.
These phrasesare extracted using word alignment algorithms thatare trained on parallel corpora.
Phrases, or phrasalfeatures, represent a mapping of source sequencesinto a target sequences which are typically a fewwords long.In this paper, we investigate the feasibility of train-ing alignment algorithms based on supervised align-ment data.
Although there is a modest cost associ-ated with annotating data, we show that a reductionof 40% relative in alignment error (AER) is possibleover the GIZA++ aligner (Och and Ney, 2003).Although there are a number of other applicationsfor word alignment, for example in creating bilingualdictionaries, the primary application continues to beas a component in a machine translation system.
Wetest our aligner on several machine translation testsand show encouraging improvements.2 Related WorkMost of the prior work on word alignments has beendone on parallel corpora where the alignment at thesentence level is also done automatically.
The IBMmodels 1-5 (Brown et al, 1993) produce word align-ments with increasing algorithmic complexity andperformance.
These IBM models and more recentrefinements (Moore, 2004) as well as algorithms thatbootstrap from these models like the HMM algo-rithm described in (Vogel et al, 1996) are unsuper-vised algorithms.The relative success of these automatic techniquestogether with the human annotation cost has delayedthe collection of supervised word-aligned corpora formore than a decade.
(Cherry and Lin, 2003) recently proposed a di-rect alignment formulation and state that it wouldbe straightforward to estimate the parameters givena supervised alignment corpus.
In this paper, we ex-tend their work and show that with a small amountof annotated data, together with a modeling strat-egy and search algorithm yield significant gains inalignment F-measure.89showvAny +pAl#AlvAnypsecondWordsWordNetthe2nd2dpointed+pwvyqAl#+tA$Arw#wA$Art AlwvyqpWordsSegm.toAlyAlySourceTargetpapersdocumentindicatepointFigure 1: Alignment example.3 AlgorithmIn order to describe the algorithm, we will need tofirst describe the direct link model.
Figure 1 showstwo sequences where the top sequence is consideredthe source sequence and the bottom sequence thetarget sequence.
Each sequence can have auxilliaryinformation such as Arabic segmentation or EnglishWordNet (Miller, 1990) information as shown.
Giventhe source and target sequences, there are a numberof different ways to link each target word to a sourceword.
Each target word has a link li which indi-cates which source position it links to.
The rangeof li is from 0 to K and there are M of these links.The source word position 0 is used to indicate NULLwhich we imagine gives rise to unaligned Englishwords.
In this paper, we refer to these words as be-ing spontaneous.
A valid link configuration has Mlinks.
Define L to be the set of all possible valid linkconfigurations, and L to be a member of that set.We seek to maximize the alignment probability byfinding the optimum link configuration Lopt,p(Lopt|S, T ) = argmaxL?Lp(L|S, T )= p(lMi |tM1 , sK1 )=M?i=0p(li|tM1 , sK1 , li?11 ).We factor this into a transition model and an obser-vation model,p(L|S, T ) = 1ZM?i=0p(li|li?1)?p(li|tM1 , sK1 , li?11 )1?
?.where Z is the normalizing constant.We factor the model as above so that the tran-sition model computation, which uses informationavailable on the search hypotheses, is reduced duringthe search process.
In the aligner presented here, ?is always set to 0.5.
Next we will describe the tran-sition model, then the observation model and finallythe experiments in alignment and machine transla-tion.In the IBM Model 1 aligner, the choice of the lan-guage to serve as states of the search algorithm is notprescribed, but practically the choice is important asit affects performance.
To see this, note that in gen-erative models an input word can only be aligned toa single state in the search.
In our current situa-tion, we are interested in aligning unsegmented Ara-bic words and typical words have a few affixes toindicate for example pronouns, definiteness, prepo-sitions and conjunctions.
In English these are sepa-rate words, and therefore to maximize performancethe unsegmented Arabic words serve as states in thesearch algorithm and we align English words to thesestates.3.1 Transition ModelThe transition model tends to keep the alignmentsclose together and penalizes alignments in which ad-jacent words in the target language come from verydistant words in the source language.
Also, we wouldlike to penalize many English words coming from thesame Arabic state; we call this the state visit penaltyand will be described later.
In this paper, we use aparametric form for the transition model,p(li|li?1) =1Z(li?1)[ 1dist(li, li?1)+ 1ns(li)](1)90where ns(i) represents the state visit penalty forstate i, Z(li?1) is the normalization constant anddist(li, li?1) = min(|li ?
li?1|, |li ?
fi|) + a.Here a is a penalty for a zero distance transition andis set to 1 in the experiments below.
The min op-erator chooses the lowest cost transition distance ei-ther from the previous state or the frontier state, fi,which is the right most state that has been visited(even though Arabic is normally displayed right toleft, we make our Arabic state graphs from left toright).
This is a language specific criteria and in-tended to model the adjective noun reversal betweenEnglish and Arabic.
Once the current noun phraseis completed, the next word often aligns to the statejust beyond frontier state.
As an example, in Fig-ure 1, the verb ?pointed?
aligns to the first Arabicword ?wA$Art?, and aligning the ?to?
to its Arabiccounterpart ?Aly?
would incur normally a distance of3 but with the frontier notion it incurs only a penaltyof 1 on the hypothesis that aligns the word ?second?to ?AlvAnyp?.
In this alignment with the frontier no-tion, there are only distance 1 transitions, whereasthe traditional shapes would incur a penalty of 2 foralignment of ?pointed?
and a penalty of 3 for the word?to?.The state visit penalty, ns(i) is the distance be-tween the English words aligned to this state timesthe number of state visits1.
This penalty controlsthe fertility of the Arabic words.
To determine theEnglish words that aligned to the Arabic position,the search path is traced back for each hypothe-sis and a sufficiently large beam is maintained sothat alignments in the future can correct past align-ment decisions.
This penalty allows English deter-miners and prepositions to align to the Arabic con-tent word while penalizing distant words from align-ing to the state.
In terms of alignment F-measureto be described below, the state visit penalty, if re-moved makes the performance degrade from F=87.8to F=84.0 compared to removing the frontier notionwhich only degrades performance to F=86.9.3.2 Observation ModelThe observation model measures the linkage of thesource and target using a set of feature functionsdefined on the words and their context.
In Figure 1,an event is a single link from an English word toan Arabic state and the event space is the sentencepair.
We use the maximum entropy formulation (e.g.
(Berger et al, 1996)),1We are overloading the word ?state?
to mean Arabicword position.f = ?
(li)h =[ti?11 , sK1]p(f |h) = 1Z(h) exp?i?i?i(h, f),where Z(h) is the normalizing constant,Z(h) =?fexp?i?i?i(h, f).and ?i(h, f) are binary valued feature functions.
Thefunction ?
selects the Arabic word at the positionbeing linked or in the case of segmentation features,one of the segmentations of that position.
We re-strict the history context to select from the currentEnglish word and words to the left as well as thecurrent word?s WordNet (Miller, 1990) synset as re-quired by the features defined below.
As in (Cherryand Lin, 2003), the above functions simplify the con-ditioning portion, h by utilizing only the words andcontext involved in the link li.
Training is done us-ing the IIS technique (Della Pietra et al, 1995) andconvergence often occurs in 3-10 iterations.
The fivetypes of features which are utilized in the system aredescribed below.Phrase to phrase (for example, idiomatic phrases)alignments are intepreted as each English word com-ing from each of the Arabic words.3.2.1 Lexical FeaturesThe lexical features are similar to the translationmatrix of the IBM Model 1.
However, there is a sign-ficant out of vocabulary (OOV) issue in the modelsince training data is limited.
All words that havea corpus frequency of 1 are left out of the modeland classed into an unknown word class in order toexplicitly model connecting unknown words.
Fromthe training data we obtain 50K lexical features, andapplying the Arabic segmenter obtain another 17Klexical features of the form ?
(English content word,Arabic stem).3.2.2 Arabic Segmentation FeaturesAn Arabic segmenter similar to (Lee et al, 2003)provides the segmentation features.
A small dictio-nary is used (with 71 rules) to restrict the set of Ara-bic segments that can align to English stopwords, forexample that ?the?
aligns to ?Al#?
and that ?for?, ?in?and ?to?
align to ?b#?
and ?her?
aligns with the suf-fix ?+hA?.
Segmentation features also help align un-known words, as stems might be seen in the trainingcorpus with other prefixes or suffixes.
Additionally,the ability to align the prefix and suffix accurately,tends to ?drag?
the unknown stem to its English tar-get.913.2.3 WordNet FeaturesWordNet features provide normalization on theEnglish words.
The feature is instantiated for nouns,adjectives, adverbs and verbs following their defini-tions in WordNet.
If the Arabic word has a seg-mentation then the feature is ?
(WordNet synset id,Arabic stem), otherwise it is ?
(WordNet synset id,Arabic word).
The feature ties together English syn-onyms and helps improve recall of the aligner.3.2.4 Spelling FeatureThe spelling feature is applied only on unknownwords and is used to measure the string kernel dis-tance(Lodhi et al, 2000) between romanized Arabicand English words.
The feature is designed primar-ily to link unknown names.
For example, ?Clinton?is written as ?klyntwn?
in one of its romanized Ara-bic versions.
In a sentence, measuring the string ker-nel distance shows a correlation between these nameseven though there is not much overlap between thecharacters.
The feature has four possible values: no-match, somematch, goodmatch, and exact.3.2.5 Dynamic FeaturesDynamic features are defined on the lattice of thesearch algorithm.
These features fire when the pre-vious source and target word pair are linked.
Forexample, one such feature is ?b# in?
and if on thehypothesis we have just linked this pair and the nextEnglish word is being aligned to the stem of the Ara-bic word where this prefix occurs, this feature firesand boosts the probability that the next words arealigned.
The basic intuition behind this feature isthat words inside prepositional phrases tend to align,which is similar to the dependency structure featureof (Cherry and Lin, 2003).At training time, the lattice reduces to the sin-gle path provided by the annotation.
Since this fea-ture tends to suffer from the drag of function words,we insist that the next words that are being linkedhave at least one feature that applies.
All word pairslinked in the training data have lexical features as de-scribed above, and if both source and target wordsare unknown they have a single feature for their link.Applying dynamic features on words that have atleast one other feature prevents words which are com-pletely unrelated from being linked because of a fea-ture about the context of the words.Two types of dynamic features are distinguished:(a) English word with Arabic prefix/suffix and (b)English word with Arabic stem.4 Smoothing the Observation ModelSince the annotated training data for word alignmentis limited and a much larger parallel corpus is avail-able for other aligners, we smooth the observationAnno.
1 Anno.
1?
Anno.
2CorrectionAnno.
1 96.5 92.4 91.7Anno.
1?
95.2 ?
93.2Table 1: F-measure for human performance on wordalignment for Arabic-English.probability with an IBM Model 1 estimate,p(li|tM1 , sK1 ) =1Z pME(li|tM1 , sK1 )?pM1(s|ti)1??
.where ?
is set to 0.9 in the experiments below.
Inthe equation above, the s represents the Arabic wordthat is being linked from the English word ti.When ?
is set to 1.0 there is no smoothing per-formed and performance degrades to F=84.0 fromthe best system performance (F=87.8).
When ?
isset to 0, the model uses only the IBM Model 1 distri-bution and the resulting aligner is similar to an HMMaligner with the transition shape discussed above andyields performance of F=73.2.5 Search AlgorithmA beam search algorithm is utilized with the Englishwords consumed in sequence and the Arabic wordpositions serving as states in the search process.
Inorder to take advantage of the transition model de-scribed above, a large beam must be maintained.
Tosee this, note that English words often repeat in asentence and the models will tend to link the wordto all Arabic positions which have the same Ara-bic content.
In traditional algorithms, the Markovassumption is made and hypothesis are merged ifthey have the same history in the previous time step.However, here we maintain all hypotheses and mergeonly if the paths are same for 30 words which is theaverage sentence length.6 Experimental DataWe have word aligned a portion of the Arabic Tree-bank (4300 sentences) and material from the LDCnews sources (LDC, 2005) to obtain a total of 10.3Ksentence pairs for training.
As a test of alignment,we use the first 50 sentences of the MT03 Evaluationtest set which has 1313 Arabic words and 1528 En-glish words 2.
In terms of annotation guidelines, weuse the following instructions: (a) Align determinersto their head nouns, (b) Alignments are done wordby word unless the phrase is idiomatic in which casethe entire phrase to phrase alignment was marked,(c) spontaneous words are marked as being part of a2The test data is available by contacting the authors.921K 3K 5K 7K 9K 10.3K# of features 15510 32111 47962 63140 73650 80321English % OOV 15.9 8.2 5.5 4.4 4.05 3.6Arabic % OOV 31 19.6 15.6 13.2 10.8 10.3F-measure 83.2 85.4 86.5 87.4 87.5 87.8Table 2: Varying Training data size.phrase wherever possible but left unaligned if thereis no evidence to link the word.In order to measure alignment performance, weuse the standard AER measure (Och and Ney, 2000)but consider all links as sure.
This measure is thenrelated to the F-measure which can be defined interms of precision and recall asPrecision The number of correct word links overthe total number of proposed links.Recall The number of correct word links over thetotal number of links in the reference.and the usual definition of the F-measure,F = 2PR(R+ P )and define the alignment error as AER = 1 ?
F .In this paper, we report our results in terms of F-measure over aligned links.
Note that links to theNULL state (unaligned English words) are not in-cluded in the F-measure.
Systems are compared rel-ative to the reduction in AER.6.1 Annotator AgreementWe measure intra/inter-annotator agreement on thetest set in order to determine the feasibility of hu-man annotation of word links.
These are shown inTable 1.
In the table, the column for ?Annotator 1Correction?
is the first annotator correcting his ownword alignments after a span of a year.
After twoweeks, the annotator (Annotator 1?)
was given thesame material with all the links removed and askedto realign and we see that there is more discrepancyin resulting alignments.
The differences are largelyon the head concept where determiners are attachedand the alignment of spontaneous words.
The perfor-mance with a second annotator is in the same rangeas the reannotation by a single annotator.7 ExperimentsIn order to evaluate the performance of the algo-rithm, we investigate the effect due to: (a) increasingthe training data size, (b) additional feature types,and (c) comparable algorithms.7.1 Training Data SizeWe varied the training data size from 1K sentences tothe complete set in Table 2.
Each batch re-estimatesthe unknown word class by creating a vocabularyon the training set.
The trend indicates a reasonableprogression of performance and more data is requiredto determine the saturation point.7.2 Feature TypesThe results obtained by different feature sets areshown in Table 3.
Each feature type was added incre-mentally (Add Feature column) to the line above todetermine the effect of the individual feature typesand then removed incrementally from the full sys-tem (Subtract Feature column) in order to see thefinal effect.
The results indicate that lexical featuresare the most important type of feature; segmenta-tion features further reduce the AER by 15.8%.
Theother features add small gains in performance which,although are not statistically significant for the align-ment F-measure, are important in terms of featureextraction.
Segmentation features discussed aboveresult in both suffix and prefix features as well asstem features.
In the Subtract column, for the seg-mentation feature, only the suffix and prefix featureswere removed.
This result indicates that most of thealignment improvement from the segmentation fea-ture comes in the form of new lexical features to linkArabic stems and English words.7.3 Comparison to other alignmentalgorithmsIn order to gauge the performance of the algorithmwith respect to other alignment strategies, we pro-vide results using GIZA++ and an HMM Max Poste-rior Algorithm (Ge, 2004).
These algorithms, as wellas the Model 1 smoothing for the MaxEnt aligner,are all trained on a corpus of 500K sentence pairsfrom the UN parallel corpus and the LDC news cor-pora released for 2005 (LDC, 2005).
Note that thesealgorithms are unsupervised by design but we utilizethem to have a baseline for comparing the perfor-mance of this supervised approach.7.3.1 HMM Max Posterior AlignerThe maximum-posterior word alignments are ob-tained by finding the link configuration that maxi-93System # of Add Subtractfeats Feature FeatureWord pairs 50070 85.03 76.3Spelling 4 85.11 87.7Segmentation 70 87.39 87.5(*)WordNet 13789 87.54 87.5Dynamic-Words 1952 87.80 87.1Dynamic-Segmentation 42 87.84 87.8Table 3: Alignment performance in terms of the feature types utilized.F-MeasureGIZA++ 79.5HMM 76.3MaxEnt 87.8Table 4: Alignment performancemizes the posterior state probability.
In contrast, inperforming a Viterbi alignment, we compute the beststate sequence given the observation.
The maximumposterior computes the best state one at a time anditerates over all possible combinations.
Once we findthe maximum in the posterior probability matrix,we also know the corresponding state and observa-tion which is nothing but the word pair (sj , ti).
Wewill then align the pair and continue to find the nextposterior maximum and align the resulting pair.
Ateach iteration of the process, a word pair is aligned.The process is repeated until either every word in one(or both) language is aligned or no more maximumcan be found, whichever happens first.7.3.2 GIZA AlignmentIn order to contrast our algorithm, we ranGIZA++ in the standard configuration which im-plies 5 iterations of IBM Model 1, HMM, Model 3and Model 4.
All parameters are left to their defaultvalues.The results using the three different aligners isshown in Table 4.
The reduction in AER over theGIZA++ system is 40.5% and over the HMM sys-tem is 48.5%.
The Wilcoxon signed-rank test yieldsa probability of 0.39 for rejecting the GIZA++ align-ment over the HMM alignment, whereas the MaxEntalgorithm should be rejected with a probability of1.7e-6 over the HMM algorithm and similarly Max-Ent should be rejected with a probability of 0.9e-6 over the GIZA++ algorithm.
These significancetests indicate that the MaxEnt algorithm presentedabove is significantly better than either GIZA++ orHMM.Figure 2: An alignment showing a split link from anArabic word.8 Phrase ExtractionOnce an alignment is obtained, phrases which sat-isfy the inverse projection constraint are extracted(although earlier this constraint was called consis-tent alignments (Och et al, 1999)).
This constraintenforces that a sequence of source words align to asequence of target words as defined by the lowest andhighest target index, and when the target words areprojected back to the source language through thealignment, the original source sequence is retrieved.Examination of the hand alignment training datashowed that this criteria is often violated for Ara-bic and English.
Prepositional phrases with adjec-tives often require a split?
for example, the align-ment shown in Figure 2 has ?of its relations?
alignedto a word in Arabic and ?tense?
aligned to the nextword.
The inverse projection constraint fails in thiscase, and in the experiments below, we relax this con-straint and generate features for single source wordsas long as the target phrase has a gap less than 2English words.
This relaxation allows a pair of ad-jectives to modify the head noun.
In future work weexplore the use of features with variables to be filledat decode time.9 Translation ExperimentsThe experiments in machine translation are carriedout on a phrase based decoder similar to the one de-94MT03 MT04 MT05GIZA++ 0.454 ?
?HMM 0.459 0.419 0.456MaxEnt 0.468 0.433 0.451Combined 0.479 0.437 0.465Significance 0.017 0.020 ?Table 5: Machine Translation Performance using theNIST 2005 Bleu scorerscribed in (Tillmann and Ney, 2003).
In order to con-trast the performance of the extracted features, wecompare the translation performance to (a) a systembuilt from alignments proposed by an HMM MaxPosterior Aligner, and (b) a system built from GIZAalignments.
All other parameters of the decoder re-main constant and only the feature set is changed forthese experiments.
As training data, we use the UNparallel corpus and the LDC news corpora releasedin 2005.
Comparison should therefore be only madeacross systems reported here and not to earlier eval-uations or other systems.
The results are shown inTable 5.Combination of the phrasal features from theHMM and MaxEnt alignments results in the ?Com-bined?
system.
The Combined system performs bet-ter in all cases; in MT03 and MT04 the MaxEntderived features perform better than the HMM sys-tem.
In MT05, there is a slight degradation which isnot significant and the combination system still re-sults in an improvement over either system.
Sincethe MaxEnt aligner has access to a unique resource,every attempt was made to make that resource avail-able to the other systems.
Although GIZA++ andHMM can not directly utilize word aligned data, thetraining data for MaxEnt was converted to paral-lel sentences where each sentence has only the pairof linked words.
The resulting numbers make bothHMM and GIZA much closer in performance to theMaxEnt aligner but the results are better for com-paring alignment methods.10 Error Analysis and DiscussionThe alignment errors made by the system can beattributed to?
English words that require multi-word Arabicstates, for example (a) dates which are writtenin Arabic in more than one form ?kAnwn Al-vAny / ynAyr?
for ?january?, and (b) compoundwords like ?rAm Allh?
in English is ?Ramallah?.?
Rare translation of a common Arabic word aswell as a common English word used as thetranslation for a rare Arabic word.?
Parallel corpora mismatch: training material fortranslation is processed at a document level andyet systems often operate at a sentence level.Human translators often use pronouns for ear-lier mentioned names although in the source lan-guage the name is repeated.
Information whichis sometimes repeated in the source in an ear-lier sentence is dropped in future sentences ofthe document.
Document level features are re-quired to allow the system to have informationto leave these words unaligned.Figure 3 shows a human alignment on the left anda machine output on the right.
The columns nextto the words indicate whether the alignments are?good?
or ?extra?
which indicates that these wordsare aligned to the special NULL state.
There are twoexamples of multi-word Arabic states shown: (a) for?january?, and (b) the English word ?agenda?.
Thesystem aligns ?the?
before committee and it seemsin this case its an annotation error.
In this exam-ple the Arabic words lnAHyp, AltnZym, wAlAEdAdand Allwjsty are all unknown words in the vocabu-lary yet the system managed to link 3 out 4 wordscorrectly.While significant gains have been made in align-ment performance, these gains have not directlytranslated to machine translation improvements.
Infact, although the GIZA system is better than theHMM system at alignment, the machine translationresult on MT03 indicates a slight degradation (al-though it is not statistically significant).
The primereason for this is that features extracted from thealignments are aggregated over the training corpusand this process helps good alignments to have signif-icantly better counts than errors in alignment.
Align-ing rare words correctly should help performance butsince their count is low it is not reflected in bleuscores.11 Conclusion and Future WorkThis paper presented a word aligner trained on anno-tated data.
While the performance of the aligner isshown to be significantly better than other unsuper-vised algorithms, the utility of these alignments inmachine translation is still an open subject althoughgains are shown in two of the test sets.
Since featuresare extracted from a parallel corpus, most of the in-formation relating to the specific sentence alignmentis lost in the aggregation of features across sentences.Improvements in capturing sentence context couldallow the machine translation system to use a rarebut correct link appropriately.Another significant result is that a small amount(5K sentences) of word-aligned data is sufficient forthis algorithm since a provision is made to handle95Figure 3: An example sentence with human output on the left and system output on the right.unknown words appropriately.12 AcknowledgementsThis work was partially supported by the DefenseAdvanced Research Projects Agency and monitoredby SPAWAR under contract No.
N66001-99-2-8916.The views and findings contained in this material arethose of the authors and do not necessarily reflectthe position or policy of the U.S. government and noofficial endorsement should be inferred.
This paperowes much to the collaboration of the Statistical MTgroup at IBM.ReferencesAdam L. Berger, Vincent Della Pietra, and Stephen DellaPietra.
1996.
A maximum entropy approach to nat-ural language processing.
Computational Linguistics,22(1):39?71.Peter F. Brown, Vincent J. Della Pietra, StephenA.
Della Pietra, and Robert L. Mercer.
1993.The Mathematics of Statistical Machine Translation:Parameter Estimation.
Computational Linguistics,19(2):263?311.Colin Cherry and Dekang Lin.
2003.
A probability modelto improve word alignment.
In 41st Annual Meeting ofthe Association for Computational Linguistics, pages88?95, Sapporo, Japan.Stephen Della Pietra, Vincent Della Pietra, and JohnLafferty.
1995.
Inducing features of random fields.Technical Report, Department of Computer Science,Carnegie-Mellon University, CMU-CS-95-144, May.Niyu Ge.
2004.
Improvement in Word Alignments.
Pre-sentation given at DARPA/TIDES MT workshop.LDC.
2005. http://ldc.upenn.edu/projects/tides/mt2005ar.htm.Young-Suk Lee, Kishore Papineni, and Salim Roukos.2003.
Language model based arabic word segmenta-tion.
In 41st Annual Meeting of the Association forComputational Linguistics, pages 399?406, Sapporo,Japan.Huma Lodhi, John Shawe-Taylor, Nello Cristianini, andChristopher J. C. H. Watkins.
2000.
Text classificationusing string kernels.
In NIPS, pages 563?569.G.
Miller.
1990.
Wordnet: An on-line lexical database.International Journal of Lexicography, 3(4):235?244.Robert C. Moore.
2004.
Improving IBM Word-AlignmentModel 1.
In 42nd Annual Meeting of the Associ-ation for Computational Linguistics, pages 518?525,Barcelona, Spain.Franz Josef Och and Hermann Ney.
2000.
Improved sta-tistical alignment models.
In 38th Annual Meeting ofthe Association for Computational Linguistics, pages440?447, Hong Kong, China.Franz Josef Och and Hermann Ney.
2003.
A system-atic comparison of various statistical alignment mod-els.
Computational Linguistics, 29(1):19?51.Franz Josef Och, Christoph Tillmann, and Hermann Ney.1999.
Improved alignment models for statistical ma-chine translation.
In Joint Conf.
of Empirical Methodsin Natural Language Processing and Very Large Cor-pora, pages 20?28, College Park, Maryland.Franz Josef Och.
2003.
Minimum error rate training inStatistical Machine Translation.
In 41st Annual Meet-ing of the Association for Computational Linguistics,pages 160?167, Sapporo, Japan.Christoph Tillmann and Hermann Ney.
2003.
Word re-ordering and a dynamic programming beam search al-gorithm for Statistical Machine Translation.
29(1):97?133.Stefan Vogel, Hermann Ney, and Christoph Tillmann.1996.
HMM BasedWord Alignment in Statistical Ma-chine Translation.
In Proc.
of the 16th Int.
Conf.on Computational Linguistics (COLING 1996), pages836?841, Copenhagen, Denmark, August.96
