A Measure of Term Representativeness Based on the Number ofCo-occurring Salient WordsToru Hisamitsu and Yoshiki NiwaCentral Research Laboratory, Hitachi, Ltd.Hatoyama, Saitama, 350-0095, Japan{hisamitu, yniwa}@harl.hitachi.co.jpAbstractWe propose a novel measure of therepresentativeness (i.e., indicativeness or topicspecificity) of a term in a given corpus.
Themeasure embodies the idea that the distributionof words co-occurring with a representative termshould be biased according to the worddistribution in the whole corpus.
The bias of theword distribution in the co-occurring words isdefined as the number of distinct words whoseoccurrences are saliently biased in theco-occurring words.
The saliency of a word isdefined by a threshold probability that can beautomatically defined using the whole corpus.Comparative evaluation clarified that themeasure is clearly superior to conventionalmeasures in finding topic-specific words in thenewspaper archives of different sizes.IntroductionMeasuring the representativeness (i.e., theinformativeness or domain specificity) of a term?
isessential to various tasks in natural languageprocessing (NLP) and information retrieval (IR).Such a measure is particularly crucial to automaticdictionary construction and IR interfaces to show auser words indicative of topics in retrievals thatoften consist of an intractably large number ofdocuments (Niwa et al 2000).This paper proposes a novel and effectivemeasure of term representativeness that reflects thebias of the words co-occurring with a term.
In thefollowing, we focus on extracting topic words froman archive of newspaper articles.In the literature of NLP and IR, there have beena number of studies on term weighting, and these arestrongly related to measures of term?
A term is a word or a word sequence.representativeness (see section 1).
In this paper weemploy the basic idea of the ?baseline method?proposed by Hisamitsu (Hisamitsu et al 2000).
Theidea is that the distribution of words co-occurringwith a representative term should be biasedaccording to the word distribution of the wholecorpus.
Concretely, for any term T and any measureM for the degree of bias of word occurrences inD(T), a set of words co-occurring with T, accordingto those of the whole corpus D0, the baseline methoddefines representativeness of term T by normalizingM(D(T)).
In what follows, D0 is an archive ofnewspaper articles and D(T) is defined as the set ofall articles containing T.The normalization of M(D(T)) is done by afunction BM, called the baseline function, whichestimates the value of M(Drand) using #Drand for anyrandomly sampled document (in our case, ?article?
)set Drand, where #Drand stands for the total number ofwords contained in Drand.
By dividing M(D(T)) byBM(#D(T)), comparison of M(D(T1)) and M(D(T2))becomes meaningful even if the frequencies of T1and T2 are very different.
We denote this normalizedvalue by NormM(D(T)).Hisamitsu et al reported that NormM(D(T)) isvery effective in capturing topic-specific wordswhen M(D(T)) is defined as the distance betweentwo word distributions PD(T) and P0 (see subsection1.2), which we denote by Dist(D(T)).Although NormDist(D(T)) outperforms existingmeasures, it has still an intrinsic drawback shared byother measures, that is, words which are irrelevant toT and simply happen to occur in D(T) --- let us callthese words non-typical words --- contribute to thecalculation of M(D(T)).
Their contributionaccumulates as background noise in M(D(T)), whichis the part to be offset by the baseline function.
Inother words, if M(D(T)) were to exclude thecontribution of non-typical words, it would not needto be normalized and would be more precise.This consideration led us to propose a differentapproach to measure the bias of word occurrences ina discrete way: that is, we only take words whoseoccurrences are saliently biased in D(T) into account,and let the number of such words be the degree ofbias of word occurrences in D(T).
Thus, SAL(D(T),s), the number of words in D(T) whose saliency isover a threshold value s, is expected to be free fromthe background noise and sensitive to number ofmajor subtopics in D(T).
The essential problem nowis how to define the saliency of bias of wordoccurrences and the threshold value of saliency.
Thispaper solves this problem by giving amathematically sound measure.
Furthermore, it isshown that the optimal threshold value can bedefined automatically.
The newly defined measureSAL(D(T), s) outperforms existing measures inpicking out topic-specific words from newspaperarticles.1.
Brief review of term representativenessmeasures1.1 Conventional measuresRegarding term weighting, various measures ofimportance or domain specificity of a term havebeen proposed in NLP and IR domains (Kageura etal.
1996).
In his survey, Kageura introduced twoaspects of a term: unithood and termhood.
Unithoodis "the degree of strength or stability of syntagmaticcombinations or collocations," and termhood is "thedegree to which a linguistic unit is related to (ormore straightforwardly, represents) domain-specificconcepts."
Kageura's termhood is therefore what wecall representativeness here.Representativeness measures were firstintroduced in the context of determining indexingwords for IR (for instance, Salton et al 1973;Spark-Jones et al 1973; Nagao et al 1976).
Amonga number of measures introduced there, the mostcommonly used one is tf-idf proposed by Salton et alThere are a variety of modifications of tf-idf (forexample, Singhal et al 1996) but all share the basicfeature that a word appearing more frequently infewer documents is assigned a higher value.In NLP domains several measuresconcentrating on the unithood of a word sequencehave been proposed.
For instance, the mutualinformation (Church et al 1990) and log-likelihoodratio (Dunning 1993; Cohen 1995) have been widelyused for extracting word bigrams.
Some measuresfor termhood have also been proposed, such as Imp(Nakagawa 2000), C-value and NC-value (Mima etal.
2000).Although certain existing measures are widelyused, they have major problems as follows: (1)classical measures such as tf-idf are so sensitive toterm frequencies that they fail to avoiduninformative words that occur very frequently; (2)measures based on unithood cannot handlesingle-word terms; and (3) the threshold value for aterm to be considered as being representative isdifficult to define or can only be defined in an adhoc manner.
It is reported that measures defined bythe baseline method do not have these problems(Hisamitsu et al 2000).1.2 Baseline methodThe basic idea of the baseline method stated inintroduction can be summarized by the famousquote (Firth 1957) :"You shall know a word by the company it keeps.
"This is interpreted as the following hypothesis:For any term T, if the term isrepresentative, word occurrences inD(T), the set of words co-occurringwith T, should be biased according tothe word distribution in D0.This hypothesis is transformed into the followingprocedure:Given a measure M for the bias ofword occurrences in D(T) and a termT, calculate M(D(T)), the value ofthe measure for D(T).
Then compareM(D(T)) with BM(#D(T)), where #D(T)is the number of words contained in#D(T), and BM estimates the valueof M(D) when D is a randomly chosendocument set of size #D(T).Here, as stated in introduction, D(T) is considered tobe the set of all articles containing term T.Hisamitsu et al tried a number of measures forM, and found that using Dist(D(T)), the distancebetween the word distribution PD(T) in D(T) and theword distribution P0 in the whole corpus D0 iseffective in picking out topic-specific words innewspaper articles.
The value of Dist(D(T)) can bedefined in various ways, and they found that usinglog-likelihood ratio (see Dunning 1993) worked bestwhich is represented as follows:0#log)(#logDKkTDkk iMiiiiMiii ??==?
,where ki and Ki are the frequency of a word wi inD(W) and D0 respectively, and {w1,...,wM} is the setof all words in D0.As stated in introduction, Dist(D(T)) isnormalized by the baseline function, which isreferred as BDist(?)
here.
Figure 1(a) illustrates thenecessity of the normalization: the graph?scoordinates are {(#D(T), Dist(D(T))) and {(#Drand,Dist(Drand))}, where T varies over ?cipher?, ?do?,and ?economy?, and Drand varies over a widenumerical range of randomly sampled articles.
Thisfigure shows that Dist(D(?do?))
is smaller thanDist(D(?electronic?
)), which reflects our linguisticintuition that words co-occurring with ?electronic?are more biased than those with ?do?.
However,Dist(D(?cipher?))
is smaller than Dist(D(?do?
)),which contradicts our linguistic intuition.
This iswhy values of Dist(D(T)) are not directly used tocompare the representativeness of terms.Figure 1(a)Baseline curve and sample word distributionThis phenomenon can be explained by thecurve, referred to as the baseline curve, composed of{(#Drand, Dist(Drand)}.
The curve indicates that a partof Dist(D(T)) systematically varies depending onlyon #D(T) and not on T itself.
It indicates the verynotion of background noise stated in introduction,and by offsetting this part using the baselinefunction BDist(#D(T)), which approximates thebaseline curve, the graph is converted into that ofFigure 1(b).
Since the baseline curve is not verymeaningful as #Drand approaches to #D0, extremelyfrequent terms, such as ?do?
are treated in a specialway: that is, if the number of documents in D(T) islarger than a threshold value N0, which wascalculated from the average number of wordscontained in a document, N0 documents arerandomly chosen from D(T).
This is because thecoordinates of the point corresponding to ?do?
differin Fig.
1(a) and Fig.
1(b).
As stated in introduction,Hisamitsu et al (2000) reported on that thesuperiority of NormDist(D(T)), normalizedDist(D(T)), in picking out topic-specific words overvarious measures including existing ones and otherones developed by using the baseline method.Figure 1(b)Effect of Normalization1.3 Reconsideration of normalizationThe effectiveness of the baseline method?snormalization indicates that Dist(D(T)) can bedecomposed into two parts, one depending on Titself and another depending only on the size of D(T),which is considered to be background noise.
Theessence of the baseline method is to make thebackground noise explicit as a baseline function andto offset the noise by using the baseline function.
Toput it the other way round, if a termrepresentativeness measure is designed so that thisnoise part does not exist in the first place, there is noneed for the baseline function and calculation ofrepresentativeness becomes much simpler.
Moreimportantly, the precision of the measure itselfshould improve.The definition of Dist(D(T)) shows, as withother measures, that every word in D(T) contributesto the value of Dist(D(T)).
This explains whybackground noise, BDist(#D(T)), grows as #D(T)increases.
One way to improve this situation is toeliminate the contribution of non-typical (seeintroduction) words.
The simplest way to archivethis is to focus only on saliently occurring words(precisely, words whose occurrences are salientlybiased in D(T)) and let the number of words whosesaliency is over a threshold value s, denoted bySAL(D(T), s), be the degree of bias of word1000100001000001000000100 1000 10000 100000 1000000 10000000 100000000cipherdoelectronic#Drand and #D(T)Dist(Drand) andDist(D(T))0.50.60.70.80.911.11.21.31.41.51.61.71.81.922.12.20 5000 10000 15000 20000 25000 30000 35000 40000 45000 50000cipherelectronicdothreshold#Drand and #D(T)NormDist(Drand) andNormDist(D(T))occurrences in D(T).
SAL(D(T), s) should reflect therichness of subtopics in D(T) and should be freefrom the contribution of non-typical words in D(T).Thus, we need to define the saliency ofoccurrences of a word and a threshold value withwhich the occurrences of a word in D(T) isdetermined as salient.2.
Term representativeness measure based onthe number of co-occurring salient words2.1 A measure of word occurrence saliencyTo define saliency of occurrences of a word w inD(T), we employ a probabilistic measure proposedby Hisamitsu et al (2001) as follows:Let the total number (occurrences) of words inthe whole corpus be N, the number (occurrences)of words in D(T) be n, the frequency of w in thewhole corpus be K, and the frequency of w inD(T) be k. Denote the probability of ?No lessthan k red balls are contained in n balls that arearbitrarily chosen from N balls containing K redballs?
by hgs(N, K, n, k).
Then the saliency of win D(T) is defined as ?log(hgs(N, K, n, k))?.Note that the probability of ?k red balls arecontained in n balls arbitrarily chosen from N ballscontaining K red balls?, which we denote as hg(N, K,n, k), is a hypergeometric distribution with variablek.
We denote the value ?log(hgs(N, K, n, k)) byHGS(w).
HGS(w) is expressed as follows:}),min{},0(max{.)!()!()!(!!)!()!(!!),,,(,),,,(),,,()),,,,(log()(KnlnKNlnKNlKlnlNnNKNKnnNlnKNlKlnKNhglnKNhgknKNhgsknKNhgswHGSkl???++??????=????????????????????==?=?
?Due to its probabilistic meaning, comparison of the?
The reason why HGS(v) should be defined by ?hgs(N,K, n, k) instead of ?hg(N, K, n, k) is that the value of?hg(N, K, n, k) itself cannot tell whether occurrence of vk-times is saliently frequent or saliently infrequent.
Onlyhgs(N, K, n, l), the sum of  hg (N, K, n, l) over l(k?l?min{n,K}) can tell which is the case since the sumindicates how far the event ?v occurs k-times in D(w)?
isfrom the extreme event ?v occurs min{n,K} times inD(w)?.value of HGS(w)= ?log(hgs(N, K, n, k)) is alwaysmeaningful between any combination of N, K, n, andk.
HGS(w) can be calculated very efficiently usingan approximation technique (Hisamitsu et al 2001).2.2 Definition of SAL(D(T), s)Now we can define SAL(D(T), s) using the saliencymeasure defined above and a parameter s ?
0:},)(|)({)),(( swHGSTDwDIFFNUMsTDSAL ?
?=where DIFFNUM(X) stands for the number ofdistinct items in set X.
That is, SAL(D(T), s) is thenumber of distinct words in D(T) whose saliency ofoccurrence is not less than s. For instance, using the1996 archive of Nihon Keizai Shimbun (a Japanesefinancial newspaper),  SAL(D(?Aum??
), 110) = 74,SAL(D(?Aum?
), 200) = 50, SAL(D*(?do?
), 110) = 1,and SAL(D*(?do?
), 200) = 0, where D*(?do?)
is aset of N0 randomly chosen articles from D(?do?)
andN0 is the threshold value stated in subsection 1.2.This strongly suggests that SAL(D(T), s) candiscriminate topic-specific words from non-topicalwords.2.3 Optimizing threshold of saliencyNote that SAL(D(T), 0) gives the number of distinctwords in D(T), and as s increases to ?, SAL(D(T), s)becomes a constant function (zero).
If westraightforwardly follow the baseline method, wehave to construct the baseline function BSAL(D(T), s) forvarying s and test the performance ofNormSAL(D(T), s), the normalized SAL(D(T), s).There are, however, a problem that BSAL(D(T), s) cannotbe precisely approximated because SAL(D(T), s) is adiscrete-valued function.By considering the meaning of the baselinefunction, we can solve the problem of determiningthe optimal value of saliency parameter s withoutapproximating baseline functions.
That is, since thebaseline function is considered as background noiseto be offset, the best situation should be that thebaseline function is a constant-valued function whileSAL(D(T), s) is a non-trivial function (i.e., not aconstant function).
If there exists s0 satisfying thecondition, SAL(D(T), s0) does not need to benormalized and is reliable itself, and s0 is the optimalparameter.Figure 2 plots the coordinates {#Drand,?
Aum is the name of a religious cult that attacked Tokyosubway with sarin gas in 1995.SAL(Drand, s)} for Drand and s, where Drand variesover randomly sampled article sets and s varies overseveral discrete values.
Although BSAL(D(T), s) cannotbe precisely approximated by using analyticalfunctions, it can be seen that BSAL(D(T), s) changes froma monotone increasing function to a monotonedecreasing function when s is greater than about 110,and the graph of BSAL(D(T), 110) is roughly parallel tothe x-axis.
Considering the meaning of baselinefunctions again, this means that s0 = 110 is theoptimal value of saliency and that SAL(D(T), 110)can be used without normalization and is the mosteffective SAL.
The important thing here is that thisprocedure to find the optimal value of s can be doneautomatically because it only requires randomsampling of documents and curve fitting.
Section 3experimentally confirms the superiority of SAL(D(T),s0) as a representativeness measure.Figure 2{(#Drand, SAL(Drand, s)) and BSAL(D(T), s)3.
ExperimentsAs in Hisamitsu et al (2000), taking topic-wordselection for IR navigation into account, weexamined the relation between the value ofrepresentative measures and a manual classificationof words (monograms) extracted from nearly160,000 articles in the 1996 archive of the NihonKeizai Shimbun (denoted by D0 later on).3.1 PreparationWe randomly chose 20,000 words from 86,000words having document frequencies larger than 2 inD0, then randomly chose 2,000 of them andclassified these into three groups: (1) class P(positive): topic-specific words which are useful forthe navigation of IR, (2) class N (negative): words,such as ?do?, not topic-specific and useless for IRnavigation, and (3) class U (uncertain): wordswhose usefulness in IR navigation was either neutralor difficult to judge.
In the classification process, ajudge used an IR system called DualNAVI (Niwa etal.
2000) having dual windows one of which showsthe titles of retrieved articles and another displayssalient words occurring in the articles.
The details ofthe guideline of classification are stated in Hisamitsuet al (2001).3.2 Measures compared in the experimentsFour measures were compared by Hisamitsu et al(2000): NormDist(D(T)), NormDIFFNUM(D(T)),tf-idf, and tf(term frequency), whereNormDIFFNUM(D(T)) is a normalized version of ameasure called DIFFNUM(D(T)), which gives thenumber of distinct words in D(T).
DIFFNUM isbased on the hypothesis that the number of distinctwords co-occurring with a representative word issmaller than that with a generic word (Teramoto etal.
1999).
The definition of tf-idf used in thecomparison was as follows:,)(log)(TNNTTFidftf total?=?where T is a term, TF(T) is the term frequency of T,Ntotal is the total number of documents, and N(T) isthe number of documents that contain T. Wecompared these four measures with SAL(D(T), s),varying s.3.3 Comparative experiments and resultsWe compared the ability of each measure to gatherclass P words.
We randomly sorted the 20,000words mentioned above, and then compared theresult with the results of sorting by other measures.The comparison was done using the accumulatednumber of words marked by class P that appeared inthe first k (1 ?
k ?
20,000) words.
For simplicity, weuse the following notation:Rand(P, k): the accumulated number of class Pwords appearing in the first k wordswhen random sorting was applied,M(P, k): the accumulated number of class Pwords appearing in the first k wordswhen sorting was done by measure M,DP(M, k) = M(P, k)- Rand(P, k), and.
),(),(1?== kllMDPkMADPThe values of DP(M, k) and ADP(M, k) are called1101001000 10000 100000s=20s=40s=120s=110s=100s=80s=60s=90#Drand{(#Drand, SAL(Drand, s))andBSAL(D(T),s)DP-score and ADP-score, respectively.
For thesescores, higher is better.Figure 3 compares DP(M, k) for 1 ?
k ?
20,000and Figure 4 compares ADP(M, 5,000), ADP(M,10,000), and ADP(M, 20,000).
Where M varies over{NormDist(D(?
)), NormDIFFNUM(D(?
)), tf-idf, tf,SAL(D(?
), s)}.
These figures shows that SAL(D(T),s0) is overall superior to other measures exceptNormDist(D(?)).
It is also superior toNormDist(D(?))
for 0?k?15,000.
In terms ofADP-scores, SAL(D(T), s0) is superior to all othermeasures for k=5,000?10,000, 20,000.
This meansthat SAL(D(?
), s0) is superior to NormDist(D(?))
onthe whole, and particularly superior in gatheringtopic-specific words near the top of the sorting.Comparison of SAL(D(T), s) for different values of sshows that s = s0 is actually the optimal value.3.4 Effect of corpus sizeTo see the effect of corpus size on theperformance of SAL(D(?
), s), we conducted thesame kind of experiments that comparedNormDist(D(?))
and SAL(D(?
), s) by usingdifferent size of corpora D1/2 and D1/4, whosesizes were 1/2 and 1/4 of D0 respectively.
Theoptimal value of s was determined for eachcorpus in the same way as stated in subsection2.3.
The optimal value was around 70 for D1/2and around 40 for D1/4.
Figure 5 comparesDP-scores when D1/2 is used.
Figure 6 comparesthe same when D1/4 is used.
Figures 5 and 6show that SAL(D(?
), s0) is superior toNormDist(D(?))
for corpora of different sizes.Judging from the results, we expect that thesuperiority of SAL(D(?
), s0) would be evenmore apparent for a larger corpus.01020304050607080901001101201300 5000 10000 15000 20000RankAccumulatedNumber of ClassPWordsNormDist SAL(D(T),30) SAL(D(T),70) SAL(D(T),100)0204060801001200 5000 10000 15000 20000RankAccumulatedNumber of ClassPWordsNormDist SAL(D(T),30) SAL(D(T),40) SAL(D(T),50)Figure 4Comparison of ADP-scores using D0Figure 3Comparison of DP-scores using D0Figure 5Comparison of DP-scores using D1/2Figure 6Comparison of DP-scores using D1/40200040006000800010000120001400016000180002000022000NormDist s=50 70 90 110 130 150 170ADP-scoreADP(M, 20,000), ADP(M, 10,000), ADP(M, 5,000),0204060801001201401600 5000 10000 15000 20000RankAccumulatedNumber of ClassPWordsNormDist NormDIFFNUM tf tf-idfSAL(D(T),30) SAL(D(T),110) SAL(D(T),180)ConclusionWe proposed a novel measure of therepresentativeness of a term T in a given corpus.Denoting the words co-occurring with T by D(T),the measure is defined as SAL(D(T), s), the numberof words in D(T) whose saliency of occurrences isover a threshold s. This measure embodies the ideathat the distribution of words in D(T) should besaliently biased according to that of the wholecorpus if T is a representative term.
The saliency ofword occurrences is defined by using acombinatorial probability, and the threshold value sis defined automatically so that the baseline functionof SAL(D(T), s) does not depend on #D(T), thenumber of words contained in D(T).
Comparativeevaluation clarified that the proposed measure issuperior to conventional measures in findingtopic-specific words in newspaper archives ofdifferent sizes.AcknowledgementsWe would like to express our gratitude to Prof.Jun-ichi Tsujii of the University Tokyo and Prof.Kyo Kageura of National Institute of Informatics fortheir insightful comments.This project is supported in part by the CoreResearch for Evolutional Science and Technology(CREST) under the auspices of the Japan Scienceand Technology Corporation.ReferencesChurch, K. W. and Hanks, P. (1990).
Word AssociationNorms, Mutual Information, and Lexicography,Computational Linguistics 6(1), pp.22-29.Cohen, J. D. (1995).
Highlights: Language- andDomain-independent Automatic Indexing Terms forAbstracting, Journal of American Soc.
for InformationScience 46(3), pp.162-174.Dunning, T. (1993).
Accurate Method for the Statistics ofSurprise and Coincidence, Computational Linguistics19(1), pp.61-74.Firth, J.
A synopsis of linguistic theory 1930-1955.(1957).
Studies in Linguistic Analysis, PhilologicalSociety, Oxford.Hisamitsu, T., Niwa, Y., and Tsujii, J.
(2000).
A Methodof Measuring Term Representativeness - BaselineMethod Using Co-occurrence Distribution-, Proc.
ofCOLING2000, pp.320-326.Hisamitsu, T., Niwa, Y.
(2001).
Topic-Word SelectionBased on Combinatorial Probability, Proc.
ofNLPRS2001, pp.289-296.Kageura, K. and Umino, B.
(1996).
Methods of automaticterm recognition: A review.
Terminology 3(2),pp.259-289.Mima, H. and Ananiadou, S. (2000).
An application and ealuation of the C/NC-value approach for the automaticterm recognition of multi-word units in Japanese,Terminology, Vol.6, No.2, pp.
175?194.Nagao, M., Mizutani, M., and Ikeda, H. (1976).
An Auto-mated Method of the Extraction of Important Wordsfrom Japanese Scientific Documents, Trans.
of IPSJ,17(2), pp.110-117.Nakagawa, H. (2000).
Automatic Term Recognition basedon Statistics of Compound Nouns", Terminology, Vol.6,No.2, pp.195 ?
210.Niwa, Y., Iwayama, M., Hisamitsu, T., Nishioka,  S.,Takano, A., Sakurai, H., and Imaichi, O.
(2000).DualNAVI -dual view interface bridges dual querytypes, Proc.
of RIAO 2000, pp.19-20.Salton, G. and Yang, C. S. (1973).
On the Specification ofTerm Values in Automatic Indexing.
Journal ofDocumentation 29(4), pp.351-372.Singhal, A., Buckley, C., and Mitra, M. (1996).
PivotedDocument Length Normalization, Proc.
of ACM SIGIR?96, pp.21-29.Sparck-Jones, K. (1973).
Index Term Weighting.Information Storage and Retrieval 9(11), pp.616-633.Teramoto, Y., Miyahara, Y., and Matsumoto, S. (1999).Word weight calculation for document retrieval byanalyzing the distribution of co-occurrence words, Proc.of the 59th Annual Meeting of IPSJ, IP-06.
(in Japanese)
