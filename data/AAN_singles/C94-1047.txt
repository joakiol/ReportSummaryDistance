LOGIC COMPRESSION OF DICTIONARIES FORMULTILINGUAL SPELLING CHECKERSBoubaker MEDI)EII I IAMROUNIGETA, IMAG-campus (UJF & CNRS)BP 53, I;-38041 Grenoble Cedcx 09, FRANCEBoubaker .
Meddeb-namrouni@ i mag.
t7 r&WinSoft SA.34, Bd.
de l'Esplanade1:-38000 Grenoble, FRANCFABSTRACTTo provide practical spelling checkers on micro-com-puters, good compression algorithms ,'~'c essenlial.
CutTeuttechniques used to compress lexicons for indo-Fmropeanlanguages provide efficient spelling checker.
Applying the.~une methods to languages which have a different morpho-logical system (Arabic, Turkish,...) gives insufficient re-suits.
To get better esults, we apply other "logical" com-pression mechanisms based on tile structure of the lan-guage itself.
Experiments with muir)lingual dictionariesshow a significant reduction rate attributable to our logiccompression alone and even better esnlls when using ourmethod in conjunction with existing methods.KEY WORDS: Spelling checkers, Multilinguism,Compression, Dictionary, Finite-state machines.INTRODUCTIONSince the first work in 1957 by Glantz \[611, a greatdeal of timer)zing and reseltrch as taken place on the sub-ject of spelling verificatiou and correction.
Many commer-cial products (word processors, desktop resentation,...) in-elude efficient spelling checkers on mic,'o-computers.
Theclassical methods, used arc generally based on a morpho-logical analyzer.
This is sufficient o provide a robustmonolingual spelling checker, but using morphologicalamdyzers can become unrealistic when wc want to developan univers~d solution.
In fact, tile analyzers built for eachlanguage use various linguistic models and engines, and itis impossible to convert a morphoh)gical nalyzer fromone formalism to another.
Furthermore, using flmse classi-cal mcthods would lead to combining into the host appli-cation as many of grammars and parsers as languages,which would increase the code size and Ihe mainten:mccproblem of rules and data.
The method presented in thispaper is based on building a dictionary of all surface formsfor each language, which is sufficient for spelling checkersapplications.
"llle dictionary built with the existing genera-)ors can bc e~ily updated manually bt,t may l)e huge, es-pecially for some agglutinative language (Arabic,Turkish,...).
A compression process on the muir)lingualdictionaries i neeess,'u'y toobtain a reduced size.
The exist-ins compression methods generally used are physical andprovide good results for indo-European languages.Applying the sane techniques to other languages (Arabic,Tnrkish,...) shows their limits.
For this reason we intro-duce a new kind of compression techniques that we called"logic compression".
This new technique requires ap,'imi-tire morphological knowledge during tile compressionprocess and requires less storage space than prevkms meth-ods.
It ,also has the advantage of being an universal lnelhodapplicable to all languages,Seclion 1 contains an overview of existing methodsfor building spell checkers and the limits of such systemwhcl l  we take into account  new constra ints  uch as lnnlt i-lingual)sin.
Section 2 outlines tile first two steps of ourwork: we adapt an existing method to Arabic, then make afirst extension hy introducing a new kind of compressioncalled "logic compression".
Section 3 introduces ill detailthe logic compression with its application to other lan-gtmges, ll,ld shows the improvcinents obtained when usinglogic compression ill conjunction with existing methods.Section 4 outlines the architecture of our lnullilhlgualspelling checker system and some future projects.1.
OVERVIEW OF EXISTINGMETl lO I )S1.1.
(~rammar-hased approachThese methods were used in the beginning on earlycomputers when storage space was expensive.
It consistsin building a small lexicon contaiuing roots and affixes, agrammar of rules that express tile morphographemic alter-nations, and all engiue that uses tile grammar and the lexi..con to see if an input word belongs to the lauguage or not.If the process of recognition fails, some operations(substitution, insertion,...) are performed on the misspelledword to provide a list of candidale words that helps the userIo select ile correct form.Even though, it is a great accomplishment to design apowcrful cnginc \[3\] \[8\] and to cxprcss rules in a pseudonatural way \[9\] even for different languages \[1\] \[2\] \[11\],these systems present some limits:- Multilinguism: This methods does not support all lan-guages.
To offer a rot, It)lingual solution for n languagesyou have to store n grammars and n lexicons, and gener-ally n different engines inlo tile host application.- Cosl of retrievak For some languages, the retriewd ofwords may be long.
For instance, a vocalized Arabic spellchecker nlust accept non-vocalized or partially vocalizedwords which require more lime to be accepted than fullyvocalized words.- Cost of guessing alternalives for a misspelled word: Toguess a correct word when a misspelled word is found, wehave to modify the misspelled word by all possible ope,'a-tions (substitution, insertion, suppression,...) for 1 or 2characters and then try to check them.
This matter can takea lot of time before displaying the correct forms lot end-users.- Maintaining file grammars and data: The grammars andlexicon require conti,nlous updating.
You need to fiud amuir)lingual computational linguist who knows the lin-guistic theory and tile ft)rmalism to easily update data andrules \[811.- Ergonomic fcalures: In some languages, end users wantto have some options that let Ihem choose how tile spellchecker will accept words.
In Arabic, for example, differentregions have slightly different orthographical conventions.2921.2.
Lexicai-f iased appro.
'tch:Lexical-based approach appear after the first methodsdescribed above, when storage space become lessexpensive.
The first step is to build complete list ofsurface forms belonging to the language usingmorphological generators, SI,LP (Specialized l+anguagcsfor Linguistic Progr,'uns), etc.
and then compresses thelarge word-dictionary.
They are generally used for officeapl)lications such as word processors, desktop resentation,etc.
Their main advantage is that they cover a completelanguage since all the forms can be fouud in the initiallisl.
Also, they allow efficient rctricval and guessing ofmisspelled words \[4\].
Ilowever, some limits exist in suchsystems:- Multilinguism: The compression process give a goodratio for languages with awcak  inflexion factor(English,...) where the compression nteehanism give up to150 KB of storage fi'om around 3 MB of a fifll list \[4\].
Thecompression technologies arc still powcrfifl for languageswith a medium iuflexion factor (Russian,...).
For example,a list of all surface Russian words of between 10 and 15MB of size can be reduced to 700 KB \[41.
For hmguagcswith a high inflexion factor (Arabic, I ' innish,llungarian,..+), it won't be easy to find compression tech-nologies that give practical results \[4\].
For instance, a fulllist of completed vocalized woMs in Arabic h:m 300 MB insize anti the current compression mefll(xls are itnpraclical.- No morphological knowledge : These methods arc neu-tral with respect o the text language, the efficiency ofcompression techniques +nay be improved by using spe-cific properties of the language \[41.I1.
A F IRST  APPROACI I :  ADAPT INGAN EX IST ING MET I tOD FOR ARABICIL l .
Using an exist ing methodAs a first step, we take an eflicieut method used tocompress dictionaries for F+uropean (l:nglish, l:rench,...)spelling checkers 11411 and try tit apply it to Arabic.
Thefirst step of our work cousists in building a full list of sur-face fin+ms usiug a morphological generator 151 anti com-pleted by all irregular fonns and existing corpus.
The finallarge word dictionary which covers uou-vocalizcd Arabichas a size of 75 MB.
The comprcssiou process yickls 18MB iu a or)repressed fi)rmat.
I:or .
'm idea of the compres-sion process readers can refer to \[10\].
Table 1 gives someresults of the compression process for a few Europeau lan-guagcs to see the efficiency of thc method aud its itm/le-quacy for the Arabic language.wordformsl)anish 448.000German 403.000Arab ic  7 mill lous,"E~'tglish 88.000size sizcuncomprcssed compressed5689 KB 725 KB5297 KB 866 KB75 i'~lB '18 MB84l KB" 224 KBTable 1The result fl)r Arabic is impractical for small computers.We must titan find other techniques that produce a smallerdictionary or extend this method; to get an exploit'dale so-lution.11.2.
Extension of the method:The initial idea is applied to the morphological sys-tem of Aral)ic.
While most of the fully inflectc/l formswords in Arabic mc built by adding to a stem prefixes andsuffixes wc l)roposc replacing some words with only oneform beginning by a special code that represents it familyof prefixes and finishing by another special code whichrepresents a family of suffixes.
For this purpesc, wc wrotea program in MPW-C that processes a full list of inflected/brms and (+sing an existing decomposition of affixes intosub-sets already established, give the reduced lcxicou wheremany for,ns are replaced by only otto representation(PSi stem SSj) where PSi (with rcspect o SSj) is the set i(with respect o j) of prefixes (with respect o suffixes).Note that the reduced lexicon reprcscnts faithfully the iui-tial list without any silence (missing words) or noise(incorrect words).
Only compressed words are replaced, andthe rest remain in the reduced list.
The figure 1 gives anexample of words, an example it1" a decompositions luld theobtained result.Decmn +osilionFull sttrfa?c forlm ~ 7 -  Reduced listJ weAXl~l~ \]S~II!!
s\[ qeAX!
)dwI w~Xl~,us\] xyAXl)~usFig.
I: Ikaml@, of the compression processThe next crucial problem to resolve is lit find the best dc-composilion that provide the best retluced lcxicon.
Theme+hill must t~ automatic, It must process the large word-dictionary, and rcgar(ling an initial list of prcl\]xes and sill Lfixes, must give as oulput the best dccompositiou and theoptimal reduced dictionary.
But, hclk)rc studying the im-plementation of such an algorithm, we began, tit see howmuch space we coukl gain by this teChlfique starting from alt)anual decomposition.~ ~tldRclh~d;_ Starting front a different fifll lists foreach category of words (transitive verbs, nouns,...), wechoose different decompositions and processed the full listwith the coml)rcssion tool.
The best decomposition kept\[or each category was lhc decomposition which eliminatedthe maxiluum forms.
This method gave mauy candidatedecompositious depending ou Ihc grammalio'tl calcgory ofihc word.
To choose Ihe best global one we took into ac-count the fi'equency of dictionary etlIries.
This method wastested tit+ differeut Arabic word lists and some results  :Iredescribed here, Re:tders cat+ refer to 1101 or f i l l  for luoreitfformation.
To see some dccolnpositiou, consider the fol-lowing sets:l i l : \ [wa, fa\], I~ l  l;+2={la, sa }, /,3~/l;, 3 = {ha, at}, 1 ,3 i /  .......F 1 ~ {tom, ttnuna, ta, Uma}, / ~3~.../F 2 : {ya, ;din, yimt, +ulna}, /,31,31 ,3~.
/ ......I; 6 = {ha, haft, ya, ka, kern, kt)uma, kent, l).om, houma, bona,haft}, F 7 -~ F6\  {ya, i+laS} 4.
{hi},1:9 ~=(wa} .
.
.
.
.
.l:.
i (with respect o Fj) is a set of prefixes (with respect osuffixes).
We uotc the quantity I(i.E j (wilh respect o FI.Fi)all strings built by a collcalcnation of each clcmcut of l~+i(with rcsl~ecl to Fit with each clement of l(j (with rcspectIo l:j).l'~xaml)le of 3 class (from 6) of Ihe prefix class:29+3ell v i i / ' - "  ' - '  " - '  - "%lk  S lCI '"o-  -  ,v-v ' ' o -o -  - - (}Fig, 2: Initial automatonPl = El- P2 = E4.P3 = E3 + ~ -E3 + El.E2 .E3Ex,'unple of 4 class (from 13) of Ihe suffix class:S t =F  1.
S2 =F  2.
$7 =177 .
S 8 =F9.F  7.?
pirs~ r?,~,!1~8: case of Arabic: With all the classes al-ready found for Arabic (6 classes of prefixes, 13 cl,'tsscs ofsuffixes; each class containing an average of 8 affixes), weprocessed a collection of non-vocalized Arabic dictionaries(17 MB), the restllt gave a reduction lexicon of 254 KB.Used this in combination with the compression processdescribed in ?
1.2, tile final result is 121 KB.
Note alsothat part of this work was implemented in a commercialmulti l ingual word processor (WinText ?)
to offer Arabicspell checking.I I1  LOGIC  COMPRESSION:I I I .1.
Theoret i ca l  aspects :Let V be a finite set and V* the set of words built onV including null strings noted ~.W E V*.
W = WiW>..Wn.
W i e V.i c \[1..n\].
Let V + = V* - {~l}.Let Y be a sub-set of V that contain vowels.1.
Prefix(W).
V W c V +.We call order i prefix the quantity:Pi = WlW2.
.
.Wi .
(1 _< i _< n-I).2.
Suffix(W).
V W e V +.We c,'fll order j suffix Ibe quantity:Sj = WjWj+t...W.. (1 _< j _< n).3.
VoePat(W) gWe V +.We call vocalic pattern of W the set:Vy = {Wi ,Wj,...Wk}, W i < Y.card(Vy) __.
leugfll(W)4.
Root(W).
V W e V +.We call root the quantity:R = Wp...Wq.
(1 _< p < q _< n),card(R) _< q-p+l.5.
Pi: Prefixes class.
Pi = {~, F'il,Pi>...l:Ji',:} ?Pij is a prefix.
1 _< j _< kCard(Pi) =k+ 1. if k>__ 1.= 1. if l ' i  = {0} ,6.
Sj: Suffixes class.
Sj = {~, Sjl, Sj2,...Si~:}.Sji is a suffix.
1 _< i _< kCard(Sj) =k+l .
if k_> 1.= 1. ifSj = {tZi}.7.
Vl: Vowel class.Vk = {?J, VYkI,VYk2,...VYtk}Vyii is a vocalic pattern.
1 <_ i <_ kCard(Vv.)
= k + 1. if k _>.
1.= 1. i fVk= {~}.I l l .2.
Imgic Con lpress ion:  Wl lat  is it ?Let's take the following automala that represent somesurface w)calized words (fig 2)Pij is a prefix.
1 _<_ j <_ n.Sji is a suffix.
1 _< i _< n.C i are tile consonalltS of the vocabtilary.1 _<i_<k.Vij iS the vowel attached to the consonaut Cj.l ~<i_<qand l_<j_<_k.
?J is the null string.This automata recognizes all words beginning from an ini-tial state (marked by *) and finishing in a final state(marked by a double circle)The utunher of arcs of such an aulofuala is:11 II~_.~ length (l'ik) + + Z Iength(Sjk) 2q(k-1)k=l k=lIf we consider, for example, that affixes have a single chm'-acter, the nmnber of a,cs is equal to 2(n+1) + 2q(k-1).The logic compression consist in supplying the class ofprefixes, suffixes and vowels and replaces each set by onlyone arc that represent a family of prefixes, suffixes orvowels.Starting from the following sets already eslablished:Pi = {~, Pil,Pi2,-..l~i,~\] a class of prefixes slored as x.Sj = {~'J, Sjl , Sj2,...Sjn } a chiss of suff ixes stored ;is y.Vk = {{Vll,...Vlk},{V21,...V2~: } ....
{Vql,...Vql?}
) a class Ofv(K'alic pallern slorcd as z.The logic compression reduces the initial automalOU tothis new one:Fig,.
3: P.cduced automataThe number of arcs kept in the automata is equal to 3 + k.The SOl Vt: contains a sub-scl of k vowels which must beapplied to the last k characlers.I l l .3 .
Exper iments :The logic compression with only an affix decomposi-tion, built by the manual meflmd cxplaiued above, hasbeen tested on various list of words that represent collec-lions of mult i l ingual dicl ionaries (a list of inflectedforms).
Three languages are tesmd: non-vocalized Arabicwhich has a great inl lexion lactor, French which has a2.94Arabic French RussianSize of uncompressed list (MB)Ratio from it complete dictionaryNumber of inflected formsClass decomlx3sition (Ih'efixes)?
.
(suffixes)17331.980.280613..~1- l'hysical compression --, 5 6602 - Morphg-physica.1 comp.
+= ,l 22 l3 - FSM compression 884 + l~8ic compression 253.6864 + 1 145.0862.636 180 16247.406084892.646311.593201.216480.770207.3764+2 121.500 1114.665~ , ,44-3 57 .214  150.32175.234323348.636109,41848.78163.20256.78437.7436.717}lble 2weak inflexion factor, Russian which has a medium inflex-toll factor, l;.xtmrimenls arc dolie in two ways.
First by us-ing our logic compression alone anti, thel|, in conji||tctionwith other methods by supplying the reduced lexicon (lislof compressed words in text format) obtained with ourmethod as input to existing methods.
The three othermethods tested a,e Ihe following:o Physical compression: Using a commercial physicalprocess (Stuffit).- Morpho-physical coinprcssion: This method was usedto compress dictionaries used to buiM a spell checker 1411.It combines morphological proprieties by taking inlo ac-count the suffixes of the language, but wilhout any linkbetween Ihem.
It also contains onie physical features 171.?
FSM (Finite-State Machine) Compression: Using fileLexc (Finite State Lexicon Compiler) which allows theconversion of a list of surface forms inlo a transducerwhich is then minimized \[81.Resttlls are described in table 2.111.4.
In terpretat ions :The nlost interesting thing observed on this table isthe improvement obtained when we combine our methodwith a previotls one.
These resulls show that the existingmethods are not optimal and can be improved by our logi-cal compression in its first step.
These important resultsin storage space shouhl not hide others aspects of Slmllchecker systems (retrieval and guessing).
It would be inter-esting if the results given in the table were followed byoilier results showing impmvenmnts in the |etrieval andguessing of words.IV.
A PROPOSEI )  ARCI I ITECTURI , ;  OFA UNIVERSAL  S I 'ELL ING CHECKI , 'R :Figure 3 shows the architecture of our proposed uni-versal spelling checker.
Our method is inspired from pre-vious methods (?
1.2), but presents ome new original as-pects that allow it to be considered a truly multilingual so-lution.
In summary, our system has the following l'ea+ttlles:?
Multilinguism: lhis mclhod will insure the multi-lingual constraint By using different tools, specific toeach langt|age, to create a list of all surface lk),'ms.?
Storage space: by introducing the logic compressioninto the compression process, we will be able to get a re-duced lexicon for whalever langu'lgc we have to use.
Onetask that still remains is to improve the logic comp,'essionby making the lask of finding the best decomposilionmore automatic.
This problem is coii|bi|latorial; we lllllSldiscover how to apply the optimization algorithms(genetic algorithll|, stochastic algorithm,...) in each case Iofind an optimal reduced lexicon starling from Ihe largeword-dictiolmry and primilive morphological km)wledge(list of affixes and w}wets).?
Retrieval/guessing: even lllollgh we havell'l anyconc|'ele ,-esults now, the firsl experinlenls how Ihat theprocess of checking words in an I;SM formalisln is faster\[halt other exisling methods, l'urlhermore, we are explor-ing paths Io introduce functions (similarily key,...) intothe final obtained lexicon to make a rapkl guessing of re-placements for misslxflled words.CONCI ,US ION()ill" approach 1o spell checking differs from previousinethods by faking into llccolm\[ a liew para|neler which is?
i n  - -  # .
.< ,  .
.
.
.
.
.
.
.
.
.
.
........ - - .
.
.
.
.
.
.
.
.
{\ ]xe~:~ s t ,  re~e \ [ _~ Machine (Psm) \[-~('- l !}.y~!ca!
1 ComiSressit; n ' ' ,~ ._4~ Reduced lexicon. "
l   or,n,l,S,. "
J "Fig.
3: Universal spelling checker29.5file multilinguism.
The system proposed tries to give so-lutions for the three main problems: Multilinguism, de-teclion/guessiug and storage size.The first results, although using a manual method tofind the decomposition i  this first step, show that theprevious methods to store dictionaries ,are not opthnal andcan be improved by exploring other techniques from thelanguage itself.
Another interesting experiment is to findm~ original opfimiz~ation algorithm to find the optimal re-duced lexicon that represents faithfully the initi'd listwithout any silence (missing words) or noise (incorrectwords).
Yet another project is to build a more robustmethod for the two other problems (detection and guess-iug) from the reduced lexicon.ACKNOWLEDGMENTSqlie author would like to thank Prof. Christian BOI'I'I-~'I"for his constant support ,'uld encouragement.
I am also verygrateful to Mr. Kenneth BEESLEY (Rank Xerox,Grenoble) for his fruitful discussions and Mr. LauriKARTTUNEN (Rank Xerox, Grenoble) for his help torealize some experiments.REFERENCES\[1\] Beesley K. R., Bukwalter T., (:1989)Two-level, Finite-State Analysis of Arabic Morphology.Proceedings of the Seminar on Bilingual Computing inArabic and English, 6-7 Sept. 1989.
Camhridge, England:The Literary and Linguistic Computing Center & TheCenter for Middle Eastern Studies.\[2\] Beesley K. R., (1990)Finite-state descrip-tion of Arabic Morphology, iu the Pr(vceediug of theSecond Cambridge Conference on Bilingual Computing inArabic and English, Cambridge, England, 6-7 September1989.
No pagination.\[3\] Ben l lamadou A., (1986)A Compressiontechnique for Arabic Dictionaries: The affix Analysis, inthe Proceeding of COLING-86, Boml 1986, pp.
286-289.\[41 Circle Noetic Services (1989) Passwd,Reference Manual, MIT Branch Office, Boston, pp.
1-6.\[5\] Circle Noetic Services (1989)Conjugatetool, Reference Manual, MIT Branch Office, Boston, pp.1-5.\[6\] Glantz 11., (1957)On the recognition of in-fornultion with a digital computer, J. ACM, Vol.
4, No.2, 178-188.\[7\] l luffman D. A., (1951)A method for theconstruction ofminimum redundancy odes, Proc.
IRE 40(1951), 1098-1101.\[8\] Karttunen L. (1993), Finite-State LexiconCompiler, Xerox P,'do Alto Research Center, April 1993,1-35.\[9\] Koskeniemmi K., (1983) Two levelMorphology, Publication o.
11, Department of GeucralLinguistics, University of llelsinki, pp.
18.\[101 Meddeb ll.B., (1993)lntdgration d'une com-posante morphologique pour la compression d'un diction-naire arabe, in Proc.
Langue Arabe c.t TechnologiesInfonnatiques Avancfes, C,-t~ablanca, pp.14.\[11\] Meddeh II.R., (1994)Logic Compression ofMultilingual dictionaries, in Proe.
of ICEMCO-94,International Confcreuce and Fxhibition on Multi-lingualComputing, University of C~unbridge, Center of MiddleEastern Studies, London, April-1994, pp.
14.\[12\] Oflazer K, Solak A, (1992)Parsing agglu-tinative word structures and its application to spellingchecking for Turkish, Proc.
of COI~ING-92, Nantes, Aug.23-28, Vol.
1, pp.
39-45.296
