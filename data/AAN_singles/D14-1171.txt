Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1634?1642,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsFast and Accurate Misspelling Correction in Large CorporaOctavian PopescuFondazione Bruno KesslerTrento, Italypopescu@fbk.euNgoc Phuoc An VoUniversity of TrentoFondazione Bruno KesslerTrento, Italyngoc@fbk.euAbstractThere are several NLP systems whose ac-curacy depends crucially on finding mis-spellings fast.
However, the classical ap-proach is based on a quadratic time algo-rithm with 80% coverage.
We present anovel algorithm for misspelling detection,which runs in constant time and improvesthe coverage to more than 96%.
We usethis algorithm together with a cross docu-ment coreference system in order to findproper name misspellings.
The experi-ments confirmed significant improvementover the state of the art.1 IntroductionThe problem of finding the misspelled words in acorpus is an important issue for many NLP sys-tems which have to process large collections oftext documents, like news or tweets corpora, dig-italized libraries etc.
Any accurate systems, suchas the ones developed for cross document corefer-ence, text similarity, semantic search or digital hu-manities, should be able to handle the misspellingsin corpora.
However, the issue is not easy andthe required processing time, memory or the de-pendence on external resources grow fast with thesize of the analyzed corpus; consequently, most ofthe existing algorithms are inefficient.
In this pa-per, we present a novel algorithm for misspellingdetection which overcomes the drawbacks of theprevious approaches and we show that this algo-rithm is instrumental in improving the state of theart of a cross document coreference system.Many spelling errors in a corpus are acciden-tal and usually just one or two letters in a wordare affected, like existnece vs. the dictionary formexistence.
Such misspellings are rather a uniquephenomenon occurring randomly in a text.
For anautomatic speller which has access to a dictionary,finding and compiling a list of correct candidatesfor the misspelled words like the one above is notvery difficult.
However, not all misspellings are inthis category.
To begin with, proper nouns, espe-cially foreign proper names, are not present in thedictionary and their misspelling may affect morethan one or two characters.
Moreover, the mis-spelling of proper names may not be random, forexample there might be different spellings of thesame Chinese or Russian name in English, the in-correct ones occurring with some frequency.
Also,especially if the corpus contains documents writ-ten by non native speakers, the number of char-acters varying between the correct and the actualwritten form may be more than two.
In this case,finding and compiling the list of correct candidatesis computationally challenging for traditional al-gorithms, as the distance between the source stringand the words in the candidates list is high.The Levenshtein distance has been used to com-pile a list of correct form candidates for a mis-spelled word.
The Levenshtein distance betweentwo strings counts the number of changes neededto transform one string into the other, where achange is one of the basic edit operations: dele-tion, insertion, substitution of a character and thetransposition of two characters.
The Edit Dis-tance algorithm, (ED) computes the similarity be-tween two strings according to the Levenshteindistance.
Most of the random misspellings whichare produced by a native speaker are within oneor maximum two basic edit operations (Damerau,1964).
For this reason the ED algorithm is themost common way to detect and correct the mis-spellings.
However, there is a major inconve-nience associated with the use of ED, namely, ED1634runs in quadratic time considering the length ofthe strings, O(n2).
The computation time for morethan a few thousands pairs is up to several tens ofseconds, which is impracticably large for most oflarge scale applications.
By comparison, the num-ber of proper names occurring in a medium sizedEnglish news corpus is around 200, 000, whichmeans that there are some 200, 000, 000 pairs.In order to cope with the need for a lower com-putation time, on the basis of ED, a series of algo-rithms have been developed that run in linear time(Navaro 2001).
Unfortunately, this improvementis not enough for practical applications which in-volve a large amount of data coming from largecorpora.
The reason is two-fold: firstly, the lineartime is still too slow (Mihov and Schulz, 2004)and secondly, the required memory depends bothon the strings?
length and on the number of differ-ent characters between the source string and thecorrect word, and may well exceed several GBs.Another solution is to index the corpus using struc-tures like trie trees, or large finite state automata.However, this solution may require large amountsof memory and is inefficient when the number ofcharacters that differ between the source string andthe candidate words is more than two characters(Boytsov, 2011).We focus specifically on misspellings for whichthere is no dictionary containing the correct formand/or for which the Levenshtein distance to thecorrect word may be higher than two characters.For this purpose, we developed a novel approachto misspelling correction based on a non indexingalgorithm, which we call the prime mapping algo-rithm, PM.
PM runs in constant time, O(1), withinsignificant memory consumption.
The runningtime of the PM algorithm does not depend eitheron the strings?
length or on the number of differentcharacters between the source string and the can-didate word.
It requires a static amount of mem-ory, ranging from a few KBs to a maximum of afew MBs, irrespective of the size of the corpus orthe number of pairs for which the misspelling rela-tionship is tested.
We run a series of experimentsusing PM on various corpora in English and Ital-ian.
The results confirm that PM is practical forlarge corpora.
It successfully finds the candidatewords for misspellings even for large Levenshteindistances, being more than 30 times faster than alinear algorithm, and several hundred times fasterthan ED.
The running time difference is due to thefact that PM maps the strings into numbers andperforms only one arithmetic operation in order todecide whether the two strings may be in a mis-spelling relationship.
Instead of a quadratic num-ber of characters comparisons, PM executes onlyone arithmetic operation with integers.We also report here the results obtained whenusing PM inside a cross document coreferencesystem for proper nouns.
Correcting a propername misspelling is actually a more complex taskthan correcting a misspelled common word.
Somemisspellings may not be random and in order tocope with repetitive misspellings, as the ones re-sulting from the transliteration of foreign names,the PM is combined with a statistical learning al-gorithm which estimates the probability of a cer-tain type of misspelling considering the surround-ing characters in the source string.
Unlike withcommon words, where a misspelling is obvious,in the case of proper names, John vs. Jon for ex-ample, it is unclear whether we are looking at twodifferent names or a misspelling.
The string sim-ilarity evidence is combined with contextual evi-dence provided by a CDC system to disambiguate.To evaluate the PM algorithm we use publiclyavailable misspelling annotated corpora contain-ing documents created by both native and non-native speakers.
The PM within a CDC system forproper names is evaluated using CRIPCO (Ben-tivogli et al., 2008).
The experiments confirm thatPM is a competitive algorithm and that the CDCsystem gains in accuracy by using a module ofmisspelling correction.The rest of the paper is organized as follows.
InSection 2 we review the relevant literature.
In Sec-tion 3 we introduce the PM algorithm and com-pare it against other algorithms.
In Section 4 wepresent the CDC system with misspelling correc-tion for proper names.
In Section 5 we present theresults obtained on English and Italian corpora.2 Related WorkIn a seminal paper (Damerau, 1964) introducedthe ED algorithm.
The rationale for this algorithmwas the empirical observation that about 80% ofthe misspelled words produced by native speakershave distance 1 to the correct word.
ED cannot beextended to increase the accuracy, because for k =2, k being the maximal admissible distance to thecorrect word, the running time is too high.
Most ofthe techniques developed further use ED togetherwith indexing methods and/or parallel processing.In (San Segundo et al., 2001) an M-best can-1635didate HMM recognizer for 10,000 Spanish citynames is built for speech documents.
An N-gramlanguage model is incorporated to minimize thesearch spaces.
A 90% recognition rate is reported.The model is not easily generalizable to the situ-ation in which the names are unknown - as it isthe case with the personal proper names in a largecorpus.
The N-gram model is memory demandingand for 200,000 different names the dimension ofthe requested memory is impracticably big.The problem related to personal proper nameswas discussed in (Allan and Raghavan, 2002).However, the paper addresses only the problem ofclustering together the names which ?sound alike?and no cross document coreference check was car-ried out.
The technique to find similar namesis based on a noisy channel model.
The condi-tional probabilities for each two names to be sim-ilarly spelled are computed.
The time complex-ity is quadratic, which renders this technique un-feasible for big data.
In fact, the results are re-ported for a 100 word set.
A different approachcomes from considering search queries databases(Bassil and Alwani, 2012).
These techniques aresimilar to the model based on the noisy channel,as they compute the conditional probabilities ofmisspellings based on their frequencies in similarqueries.
Unfortunately, large numbers of queriesfor proper names are not available.
A similar tech-nique, but using morphological features, was pre-sented in (Veronis, 1988).
The method can man-age complex combinations of typographical andphonographic errors.It has been noted in many works dedicated toerror correction, see among others (Mihov andSchulz, 2004), that the ED algorithm is imprac-ticably slow when the number of pairs is large.
Asolution is to build a large tries tree.
While thissolution improves the searching time drastically,the memory consumption may be large.
Automataindexing was used in (Oflazer, 1996).
While thememory consumption is much less than for thetries tree approaches, it is still high.
For Turk-ish, the author reported 28,825 states and 118,352transitions labeled with surface symbols.
The re-covery error rate is 80%.
In (Boytsov, 2011) areview of indexing methods is given.
Testing on5,000 strings for k=1,2,3 is reported and the papershows the problem the systems run into for biggervalues of k. In (Huld?en, 2009) a solution employ-ing approximations via an A* strategy with finiteautomata is presented.
The method is much fasterfor k bigger than the one presented in (Chodorowand Leacock, 2000).
However, the usage of A*for proper names may be less accurate than theone reported in the paper, because unlike the com-mon words in a given language, the names mayhave unpredictable forms, especially the foreignnames.
The results reported show how the timeand memory vary for indexing methods accordingto the length of the words for k=1,2,3.A method that uses mapping from strings tonumbers is presented in (Reynaert, 2004).
Thismethod uses sum of exponentials.
The value ofthe exponential was empirically found.
However,the mapping is only approximative.
Our mappingis precise and does not use exponential operationswhich are time consuming.The study in (Navarro, 2001) is focused on nonindexing approximate string search methods, inparticular on the simple ED distance.
The non-indexing methods may reach linear running time,but it is not always the case that they are scalableto big data.
In (Nagata et al., 2006) a study on thetype of errors produced by non-native speakers ofEnglish is carried out, but the long distance mis-spellings are not considered.3 Prime Mapping Misspeling AlgorithmThe algorithms based on the Levenshtein dis-tance use the dynamic programming technique tobuild a table of character to character comparisons.We present here a novel approach to misspellingwhich does not build this table, skipping the needto compare characters.
In a nutshell, the primemapping algorithm, PM, replaces the characterscompare operations to a unique arithmetic oper-ation.This can be done by associating to any letterof the alphabet a unique prime number.
For ex-ample we can associate 2 to a, 3 to b, 5 to c ...97 to z.
Any string will be mapped into a uniquenumber which is the product of the prime numberscorresponding to its letters.
For example the nameabba is mapped to 2 ?
3 ?
3 ?
2 = 36.
By computingthe ratio between any two words we can detect thedifferent letters with just one operation.
For exam-ple, the difference between abba and aba is 36/12= 3, which corresponds uniquely to b because theproduct/ratio of prime numbers is unique.Unlike the ED algorithm, the prime mappingdoes not find the number of edit operations neededto transform one string into another.
In fact, twowords that have just one letter in the mutual dif-ference set may be quite distinct: all the strings1636aba, aab, baa differ by one letter when comparedwith abba.
In order to be in a misspelling relation-ship, the two strings should also have a commonpart, like prefix or middle, or suffix.
The com-plete Prime Mapping (PM) algorithm consists oftwo successive steps: (1) find all the candidatewords that differ from the target word by at mostk characters and (2) check weather the target wordand the candidate word have a common part, suf-fix, prefix or middle part.
Both steps above areexecuted in constant time, therefore they do notdepend either on the length of the strings or on k,the maximal number of different characters.
Nor-mally, k = 3, because the probability of a mis-spelled word having more than three distinct let-ters is insignificant, but unlike in the case of ED,the choice of k has no influence on the runningtime.
The first step takes an integer ratio and ahash table key check, both being O(1).
The sec-ond step checks if the first k letters at the begin-ning or at the end of the word are the same, and itrequires 2k character comparisons, which is alsoan O(1) process, as k is fixed.
The pseudo codeand detailed description of the PM algorithm aregiven below.Algorithm 1 Prime MappingRequire: charList wordsList, primeList, kEnsure: misspList1: misspList?
?2: foreach ?
in charList: p(?)?
pi, piin primeList3: foreach w in wordsList: p(w)??p(?)
, ?
in w4: primeKTable?
(nk)of prime arithmetics5: for w in wordsList do6: for w?
in wordsList, w 6= w?
do7: r?p(w)p(w?
)8: if r in primeKTable then9: if commonPart (w, w?)
6= ?
then10: misspList?misspList + (w, w?
)11: end if12: end if13: end for14: end formap letters to prime numbers.
A helpful wayto assign primes to letters is according to their fre-quency; on average, the numbers corresponding tonames are smaller and the operation gets less time.compute a hash table with prime arithmeticsof K primes.
In the hash table primeKTable werecord all the combinations that can result from di-viding two products which have less than k primes:1/pi, pi, pi/pjetc.
If the ratio between two map-pings is in the hash table, then the correspondingwords have all the letters in common, except forat most k. The number of all the combination isk letter difference #combination Memory1 60 480B2 435 8K5 142,506 0.9MB6 593, 775 3.8MB10 30, 045, 015 180MBTable 1: The PM algorithm memory needs(nk).
The memory consumption for different val-ues for k is given in Table 1.
The figures compareextremely favorably with the ones of ED based ap-proaches (gigs magnitude) .
(line 7-8)find misspelling candidates by ratio.
By com-puting the ratio and by checking the hash table, wefound the pairs which use the same letters, exceptfor at most k. The procedure commonpart checkswhether the two strings also have a common partby looking at the start and end k. If this is the case,the pair is in a misspelling relationship.Figure 1: PM vs. the fastest ED type algorithmThe PM is much faster than ED.
The fastestvariant of ED, which does not compare stringshaving length difference bigger than 1, theoret-ically finds only 80% of the misspellings.
Inpractice, only around 60% of the misspellings arefound because of proper names and words mis-spelled by non-native speakers.
The PM algorithmconsiders all possible pairs, finds more than 99%of misspellings and is 35 times faster.
To obtainthe same coverage, the ED algorithm must run formore than 100 days.
The time comparison for mil-lions of pairs is plotted in Figure 1.
The experi-ments were performed on an i5, 2.8 GHz proces-sor.There is an immediate improvement we canbring to the basic variant of PM.
The figures re-ported above are obtained by doing the whole setof possible pairs.
By taking into account the factthat two words differing by k+1 letters cannot bek similar, we can organize the number represent-ing the names into an array which reduced drasti-1637cally the number of comparisons.
For example, allthe words containing the letters x, y, z cannot bek = 2 similar with the words not containing any ofthese letters.
By dividing the mapping of a word tothe primes associated with the letters of an k-gram,we know if the words containing the k-gram canbe misspelling candidates with at most k differ-ence, and there is no more need to carry out all theratios.
We arrange the mappings of all words intoan array such that on the first indexes we have thewords containing the less frequent k + 1 gram, onthe next indexes we have the words containing thesecond less frequent k+1 gram and do not containthe first k+1 gram, on the next indexes the wordscontaining the third less frequent k + 1 gram anddo not contain the first two k+1 gram, etc.
In thisway, even the most frequent k + 1 gram has onlya few words assigned and consequently the num-ber of direct comparisons is reduced to the mini-mum.
The mapping corresponding to a k+1 gramare ordered in this array according to the length ofthe words.
The number of trigrams is theoreticallylarge, the k + 1 power of the size of the alpha-bet.
However, the number of actually occurringk-trigrams is only a small fraction of it.
For exam-ple, for k = 2, the number of trigrams is a few hun-dred, out of the 2, 700 possible ones.
PM2gramruns in almost a quarter of the time needed by thebasic PM.
For the same set of names we obtainedthe results reported in Table 2.
The last columnindicates how many times the algorithm is slowerthan the PM in its basic form.algorithm time coverage times slowerbasicED 132 days 99% 310ED1 14 days 80% 35PM 9 hours 99% 1PM2gram 2 hours 42min 96% 0.26Table 2: ED variants versus MP4 Correcting Proper Names MisspellingsIn this section we focus on a class of words whichdo not occur in a priorly given dictionary and forwhich the misspelled variants may not be random.Proper names are representative for this class.
Forexample, the same Russian name occurs in corpusas Berezovski, Berezovsky or Berezovschi becauseof inaccurate transliteration.
By convention, weconsider the most frequent form as the canonicalone, and all the other forms as misspelled variants.Many times, the difference between a canonicalform and a misspelled variant follows a pattern: aPattern Context Exampledj?dji ovic djiukanovic djukanovick?kh aler kaler khaler, taler thalerki?ky ovsk berezovski berezovskyn?ng chan chan-hee chang-heedl?del abd abdelkarim abdlkrimTable 3: Name misspellings patternsparticular group of letters substitutes another onein the context created by the other characters inthe name.
A misspelling pattern specifies the con-text, as prefix or suffix of a string, where a particu-lar group of characters is a misspelling of another.See Table 3 for examples of such patterns.Finding and learning such patterns, along withtheir probability of indicating a true misspelling,bring an important gain to CDC systems both inrunning time and in alleviating the data-sparsenessproblem.
The CDC system computes the prob-ability of coreference for two mentions t and t?using a similarity metrics into a vectorial space,where vectors are made out of contextual featuresoccurring with t and t?
respectively (Grishman,1994).
However, the information extracted fromdocuments is often too sparse to decide on coref-erence (Popescu, 2009).
Coreference has a globaleffect, as the CDC systems generally improve thecoverage creating new vectors by interpolating theinformation resulting from the documents whichwere coreferred (Hastie et al., 2005).
This infor-mation is used to find further coreferences that nosingle pair of documents would allow.
Thus, miss-ing a coreference pair may result in losing the pos-sibility of realizing further coreferences.
However,for two mentions matching a misspelling patternwhich is highly accurate, the threshold for contex-tual evidence is lowered.
Thus, correcting a mis-spelling is not beneficial for a single mention only,but for the accuracy of the whole.The strategy we adopt for finding patterns isto work in a bootstrapping manner, enlarging thevalid patterns list while maintaining a high accu-racy of the coreference, over 90%.
Initially, westart with an empty base of patterns.
Consideringonly the very high precision threshold for coref-erence, above 98% certainty, we obtain a set ofmisspelling pairs.
This set is used to extract pat-terns of misspellings via a parameter estimationfound using the EM-algorithm.
The pattern is con-sidered valid only if it also has more than a givennumber of occurrences.
The recursion of the pre-vious steps is carried out by lowering with an ?the threshold for accuracy of coreference for pat-1638tern candidates.
The details and the pseudo codeare given below.Algorithm 2 Misspelling Pattern ExtractionRequire: thCoref , ?, minO, thAccRequire: thCDCEnsure: pattList1: pattList, candPattList?
?2: while there is a pair (t, t?)
to test for coreference do3: if (t, t?)
matches p, p in pattList then4: prob?
corefProb(p)5: else6: use PM algorithm on pair (t, t?
)7: prob?
thCoref8: end if9: if pair (t, t?)
coref with prob then10: candPattList?
candPattList + (t, t?
)11: end if12: extractPatterns from candPattList13: for cp in new extracted patterns do14: if #cp>minO and corefProb(cp)>thAcc then15: pattList?
pattList + (t, t?
)16: end if17: end for18: if prob>thCDC then19: corefer (t, t?
)20: end if21: end while22: thCoref ?
thCoref - ?23: goto line 21.
Compile a list of misspelling candidatesFor each source string, t, try to match t against thelist of patterns (initially empty).
If there is a pat-tern matching (t, t?)
then their prior probability ofcoreference is the probability associated with thatpattern (line 4).2.
CDC coreference evidence For each pair (t,t?)
in the canonical candidates list use the CDCsystem to compute the probability of coreferencebetween t and t?.
If the probability of coreferenceof t and t?
is higher than thCoref , the defaultvalue is 98%, then consider t as a misspelling of t?and put (t, t?)
in a candidate pattern list (line 10).3.
Extract misspelling patterns Find patternsin the candidate pattern list.
Consider only pat-terns with more than minO occurrences, whosedefault value is 10, and which have the probabilityof coreference higher than thAcc, whose defaultvalue is 90% (line 15).4.
CDC and pattern evidence For each (t,t?
)pair matching a pattern and the CDC probabil-ity of coreference more then thCDC, whose de-fault value is 80%, then corefer t and t?
(line21).
The fact that the pair (t,t?)
matches a patternof misspelling is considered supporting evidencefor coreference and in this way it plays a directrole in enhancing the system coverage.
DecreasethCoref by ?,whose default is value 0.5, and re-peat the process of finding patterns (goto line 2).To extract the pattern from a given list of pairs,procedure extractPatterns at line 12 above, wegenerate all the suffixes and prefixes of the strings.We compute the probability that a group of char-acters represents a spelling error, given a certainsuffix and/or prefix.
We use the EM algorithm tocompute these probabilities.
For a pair (P, S) ofa prefix and a suffix, the tuples (p(P)=p, p(S)=s,pi) are the quantities to be estimated via EM, withpi being the coreference probability.
A corefer-ence event is directly observable, without know-ing, however, which prefix or suffix contribute tothe coreference.
The EM equations are given be-low, where X is the observed data; Z are the hid-den variable, p and s respectively; ?
the parame-ters (p,s, pi); Q(?,?
(t)) the expected log likelihoodat iteration t.E?
step ?(t)i?
(t)i= E[zi|xi, ?(t)]=p(xi|zi,?
(t)) p(zi=P |?(t))p(xi|?(t))=pi(t)[p(t)]xi[(1?p(t)](1?xi)pi(t)[p(t)]xi[(1?p(t)](1?xi)+(1?pi(t))[s(t)]xi[(1?s(t)](1?xi)(1)M?
step ?
(t+1)?Q(?|?t)?pi= 0 pi(t+1)=?i?
(t)in?Q(?|?t)?p= 0 p(t+1)=?i?(t)ixi?i?
(t)i?Q(?|?t)?s= 0 s(t+1)=?i(1??(t)i)xi?i(1??
(t)i)(2)5 ExperimentsWe performed a set of experiments on differentcorpora in order to evaluate: (1) the performancesof the PM algorithm for misspelling detection, (2)the accuracy of proper name misspelling patternacquisition from large corpora, and (3) the im-provements of a CDC system, employing a cor-rection module for proper name misspellings.In Section 5.1 the accuracy of the PM algorithmis tested on various corpora containing annotatedmisspellings of English words.
In particular, wewere interested to see the results when the edit dis-tance between the misspelled pair is bigger than 3,because handling bigger values for k is crucial forfinding misspelling errors produced by non-nativespeakers.
The evaluation is directly relevant forthe correction of the spelling of foreign names.1639In Section 5.2 the proper name misspelling pat-terns were extracted from two large news cor-pora.
One corpus is part of the English Gigawords,LDC2009T13 (Parker et al., 2009) and the sec-ond corpus is Adige500k in Italian (Magnini et al.,2006).
We use a Named Entity Recognizer whichhas an accuracy above 90% for proper names.
Weevaluated the accuracy of the patterns by randomsampling.In Section 5.3 the accuracy of the CDC systemwith the correction module for proper name mis-spellings was tested against a gold standard.5.1 PM EvaluationWe consider the following publicly available En-glish corpora containing the annotation of the mis-spelled words: Birkbeck, Aspell, Holbrook, Wiki-pidia.
Birkbeck is a heterogeneous collection ofdocuments, so in the experiments below we re-fer to each document separately.
In particular wedistinguish between misspellings of native speak-ers vs. misspelling of non-native speakers.
Fig-ure 2 shows that there are two types of corpora.For the first type, the misspellings found withintwo characters are between 80% and 100% ofthe whole number of misspellings.
For the sec-ond type, less than 50% of the misspellings arewithin two characters.The second category is rep-resented by the misspellings of non native speak-ers.
The misspellings are far from the correctforms and they represent chunks of phoneticallysimilar phonemes, like boiz vs. boys.
The situa-tion of the foreign name misspellings is likely tobe similar to the misspellings found in the sec-ond type of corpora.
For those cases, handlinga k value bigger than 2 is crucial.
Not only theFigure 2: k = 1, 2non-indexing methods, but also indexing ones arerather inefficient for k values bigger than 2 forlarge corpora.
The PM algorithm does not havethis drawback, and we tested the coverage of theerrors we found for values of k ranging from 3 to10.
In Figure 3 we plot the distributions for theFigure 3: Foreign Misspellingscorpora which are problematic for k=2.
Values ofk are plotted on the OX axis, and the percentage ofthe misspellings within the respective k on the OYaxis.
The results showed PM is also able to findthe phonemically similar misspellings.
We can seethat for k bigger than 9 the number of misspellingsis not significant.The PM algorithm performed very well, beingable to find the misspellings even for large k val-ues.
There were 47, 837 words in Aspell, Holbrrokand Wikipedia, and 30, 671 in Birkbeck, and PMfound all the misspelling pairs in a running time of25 minutes.
This is a very competitive time, evenfor indexing methods.
For k above 8 the access tothe hash table containing the prime combinationswas slower, but not significantly so.5.2 Pattern Extraction EvaluationWe extracted the set of names using a NER fromthe two corpora, LDC2009T13 and Adige500k.The set of proper names is rather large in both cor-pora - 160, 869 names from the English corpus and185, 508 from the Italian corpus.
Apparently, thequasi-similar names, which are considered as mis-spelled name candidates, is very high.
In Figure4 we plot this data.
The English Cand and ItalianCand are absolute values, while the English Trueand Italian True represent percentages.
For exam-ple, a name of length 5 is likely to have around 23misspelling candidates, but only 17% of them arelikely to be true misspellings, the rest being differ-ent names.Figure 4: Candidates vs.
True Misspellings1640The numbers are estimated considering sampleshaving the size between 30 and 50, for each namelength.
The percentages change rapidly with thelength of the string.
For names with the lengthbigger than 11, the probability that a misspellingcandidate is a true misspelling is more than 98%.This fact suggests a strategy for pattern extrac-tion: start from the higher name length towards thelower length names.
The patterns found by the al-gorithm described in Section 4 have between 900and 20 occurrences.
There are 12 patterns havingmore than 400 occurrences, 20 having between 20and 50 occurrences, see Fig.
5.Figure 5: Distribution of the patterns:5.3 CDC and Misspelling correctionThe CRIPCO corpus (Bentivogli et al., 2008)is a gold standard for CDC in Italian, contain-ing pieces of news extracted from Adige500k.There are 107 names, the majority being Ital-ian names.
We scrambled the names to cre-ate misspelling candidates.
For example thename leonardo was scrambled like teonardo,lionaldo, loenarod etc.
We considered the top 15frequency letters and maximum 4 letters for eachscrambling.
We randomly selected 70% of theoriginal CRIPCO making no modifications, andcalled this corpus CRwCR.
30% of the originaldocuments were assigned to the invented pseudo-names, and we called this corpus CRwSC (cor-rect documents with scrambled names).
FromAdige500k we randomly chose 20, 000 documentsand assigned them to the scrambled names aswell, calling this corpus NCRwSC.
From thesepieces we created a new corpus: 70% of the initialCRIPCO documents with the original names, 30%of the CRIPCO documents with scrambled namesand 20, 000 documents with the same scramblednames.
For the names occurring in CRwCR, thescrambled names are valid name misspellings inthe CRwSC corpus, and invalid in NCRwSC.As expected, the PM algorithm found all theFigure 6: Proper Names CRIPCO Evaluationmisspelling candidates and some others as well.We let the threshold confidence of coreference tovary from 90% to 98%.
The number in Figure6 refers to the precision and recall for the namemisspellings in the CRIPCO corpus created viarandom scrambling.
We were also interested tosee how the pattern finding procedure works, butscrambling randomly produced too many contexts.Therefore, we chose to modify the names in a nonrandom way, by replacing the final o to ino, ex.paolo goes to paolino, and modifying one letter inthe word for half of the occurrences, ex.
paorino.The idea is that ino is a very common suffix fornames in Italian.
The system was able to learn thepseudo alternatives created in the context ino.
Thenoise introduced was relatively low, see Fig.
6.6 Conclusion and Further ResearchIn this paper we described a system able to correctmisspellings, including proper name misspellings,fast and accurately.
The algorithm introduced,PM, overcomes the time/memory limitations ofthe approaches based on the edit distance.The system is built on a novel string comparealgorithm which runs in constant time indepen-dently of the length of the names or the number ofdifferent letters allowed, with no auxiliary mem-ory request.
As such, the algorithm is much fasterthan any other non-indexing algorithms.
Becauseit is independent of k, it can be used even for largek, where even the indexing methods have limita-tions.
We also used an EM based technique to findmisspelling patterns.
The results obtained are veryaccurate.The system makes a first selection of the docu-ments, drastically reducing the human work load.Another line of future research is to use the PMalgorithm in other NLP tasks, where finding thepairs having some particular elements in commonis necessary: for example, comparing parsing treesor dependency trees.
We think that PM can beused in other NLP tasks as well and we hope thecommunity can take advantage of it.1641ReferencesJames Allan and Hema Raghavan.
2002.
Using Part-of-Speech Patterns to Reduce Query Ambiguity.
InProceedings of the 25th annual international ACMSIGIR conference on Research and development ininformation retrieval, pages 307?314.
ACM.Youssef Bassil and Mohammad Alwani.
2012.
OCRPost-Processing Error Correction Algorithm UsingGoogle?s Online Spelling Suggestion.
Journal ofEmerging Trends in Computing and Information Sci-ences, ISSN 2079-8407, Vol.
3, No.
1.Luisa Bentivogli, Christian Girardi, and Emanuele Pi-anta.
2008.
Creating a Gold Standard for PersonCross-Document Coreference Resolution in ItalianNews.
In The Workshop Programme, page 19.Leonid Boytsov.
2011.
Indexing Methods for Approx-imate Dictionary Searching: Comparative Analysis.Journal of Experimental Algorithmics (JEA), 16:1?1.Martin Chodorow and Claudia Leacock.
2000.
An Un-supervised Method for Detecting Grammatical Er-rors.
In Proceedings of the 1st North Americanchapter of the Association for Computational Lin-guistics conference, pages 140?147.
Association forComputational Linguistics.Fred J Damerau.
1964.
A Technique for ComputerDetection and Correction of Spelling Errors.
Com-munications of the ACM, 7(3):171?176.Ralph Grishman.
1994.
Whither Written LanguageEvaluation?
In Proceedings of the workshop on Hu-man Language Technology, pages 120?125.
Associ-ation for Computational Linguistics.Trevor Hastie, Robert Tibshirani, Jerome Friedman,and James Franklin.
2005.
The Elements of Statis-tical Learning: Data Mining, Inference and Predic-tion.
The Mathematical Intelligencer, 27(2):83?85.M?ans Huld?en.
2009.
Fast Approximate StringMatching with Finite Automata.
Procesamiento dellenguaje natural, 43:57?64.Bernardo Magnini, Emanuele Pianta, Christian Girardi,Matteo Negri, Lorenza Romano, Manuela Speranza,Valentina Bartalesi Lenzi, and Rachele Sprugnoli.2006.
I-CAB: The Italian Content Annotation Bank.In Proceedings of LREC, pages 963?968.Stoyan Mihov and Klaus U Schulz.
2004.
Fast Ap-proximate Search in Large Dictionaries.
Computa-tional Linguistics, 30(4):451?477.Ryo Nagata, Koichiro Morihiro, Atsuo Kawai, andNaoki Isu.
2006.
A Feedback-Augmented Methodfor Detecting Errors in The Writing of Learners ofEnglish.
In Proceedings of the 21st InternationalConference on Computational Linguistics and the44th annual meeting of the Association for Compu-tational Linguistics, pages 241?248.
Association forComputational Linguistics.Gonzalo Navarro.
2001.
A Guided Tour to Approx-imate String Matching.
ACM computing surveys(CSUR), 33(1):31?88.Kemal Oflazer.
1996.
Error-tolerant Finite-stateRecognition with Applications to MorphologicalAnalysis and Spelling Correction.
ComputationalLinguistics, 22(1):73?89.Robert Parker, Linguistic Data Consortium, et al.2009.
English Gigaword Fourth Edition.
LinguisticData Consortium.Octavian Popescu.
2009.
Person Cross DocumentCoreference with Name Perplexity Estimates.
InProceedings of the 2009 Conference on EmpiricalMethods in Natural Language Processing: Volume2-Volume 2, pages 997?1006.
Association for Com-putational Linguistics.Martin Reynaert.
2004.
Text Induced Spelling Cor-rection.
In Proceedings of the 20th internationalconference on Computational Linguistics, page 834.Association for Computational Linguistics.Rub?en San Segundo, Javier Mac?
?as Guarasa, JavierFerreiros, P Martin, and Jos?e Manuel Pardo.
2001.Detection of Recognition Errors and Out of theSpelling Dictionary Names in a Spelled Name Rec-ognizer for Spanish.
In INTERSPEECH, pages2553?2556.Jean Veronis.
1988.
Morphosyntactic Correction inNatural Language Interfaces.
In Proceedings ofthe 12th conference on Computational linguistics-Volume 2, pages 708?713.
Association for Compu-tational Linguistics.1642
