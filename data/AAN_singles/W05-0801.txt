Proceedings of the ACL Workshop on Building and Using Parallel Texts, pages 1?8,Ann Arbor, June 2005. c?Association for Computational Linguistics, 2005Association-Based Bilingual Word AlignmentRobert C. MooreMicrosoft ResearchOne Microsoft WayRedmond, WA 98052bobmoore@microsoft.comAbstractBilingual word alignment forms the foun-dation of current work on statisticalmachine translation.
Standard word-alignment methods involve the use ofprobabilistic generative models that arecomplex to implement and slow to train.In this paper we show that it is possibleto approach the alignment accuracy of thestandard models using algorithms that aremuch faster, and in some ways simpler,based on basic word-association statistics.1 MotivationBilingual word alignment is the first step of mostcurrent approaches to statistical machine translation.Although the best performing systems are ?phrase-based?
(see, for instance, Och and Ney (2004) orKoehn et al (2003)), possible phrase translationsmust first be extracted from word-aligned bilingualtext segments.
The standard approach to word align-ment makes use of five translation models definedby Brown et al (1993), sometimes augmented byan HMM-based model or Och and Ney?s ?Model6?
(Och and Ney, 2003).
The best of these mod-els can produce high accuracy alignments, at leastwhen trained on a large parallel corpus of fairly di-rect translations in closely related languages.There are a number of ways in which these stan-dard models are less than ideal, however.
Thehigher-accuracy models are mathematically com-plex, and also difficult to train, as they do not factorin a way that permits a dynamic programming solu-tion.
It can thus take many hours of processing timeon current standard computers to train the modelsand produce an alignment of a large parallel corpus.In this paper, we take a different approach toword alignment, based on the use of bilingual word-association statistics rather than the generative prob-abilistic framework that the IBM and HMM modelsuse.
In the end we obtain alignment algorithms thatare much faster, and in some ways simpler, whoseaccuracy comes surprisingly close to the establishedprobabilistic generative approach.2 Data and Methodology for theseExperimentsThe experiments reported here were carried out us-ing data from the workshop on building and usingparallel texts held at HLT-NAACL 2003 (Mihalceaand Pedersen, 2003).
For the majority of our experi-ments, we used a subset of the Canadian Hansardsbilingual corpus supplied for the workshop, com-prising 500,000 English-French sentences pairs, in-cluding 37 sentence pairs designated as ?trial?
data,and 447 sentence pairs designated as test data.
Thetrial and test data have been manually aligned atthe word level, noting particular pairs of words ei-ther as ?sure?
or ?possible?
alignments.
As anadditional test, we evaluated our best alignmentmethod using the workshop corpus of approximately49,000 English-Romanian sentences pairs from di-verse sources, including 248 manually aligned sen-tence pairs designated as test data.11For the English-French corpus, automatic sentence align-ment of the training data was provided by Ulrich Germann,1We needed annotated development data to opti-mize certain parameters of our algorithms, and wewere concerned that the small number of sentencepairs designated as trial data would not be enoughfor this purpose.
We therefore randomly split each ofthe English-French and English-Romanian test datasets into two virtually equal subsets, by randomlyordering the test data pairs, and assigning alternatepairs from the random order to the two subsets.
Weused one of these subsets as a development set forparameter optimization, and held out the other for afinal test set.We report the performance of various alignmentalgorithms in terms of precision, recall, and align-ment error rate (AER) as defined by Och and Ney(2003):recall =|A ?
S||S|precision =|A ?
P ||A|AER = 1?|A ?
P |+ |A ?
S||A| + |S|In these definitions, S denotes the set of alignmentsannotated as sure, P denotes the set of alignmentsannotated possible or sure, and A denotes the set ofalignments produced by the method under test.
Fol-lowing standard practice in the field, we take AER,which is derived from F-measure, as the primaryevaluation metric that we are attempting to optimize.Our initial experiments involve algorithms that donot consider the positions of words in the sentences.Thus, they are incapable of distinguishing amongmultiple instances of the same word type in a sen-tence.
We will say that these methods produce wordtype alignments.
We compare these algorithms onthe basis of the best possible alignment of word to-kens given an alignment of word types.
We go onto consider various ways of choosing a word tokenalignment for a given word type alignment, and allour final evaluations are conducted on the basis ofthe alignment of individual word tokens.and the hand alignments of the words in the trial and test datawere created by Franz Och and Hermann Ney (Och and Ney,2003).
The manual word alignments for the English-Romaniantest data were created by Rada Mihalcea and Ted Pedersen.3 The Log-Likelihood-Ratio AssociationMeasureWe base all our association-based word-alignmentmethods on the log-likelihood-ratio (LLR) statis-tic introduced to the NLP community by Dunning(1993).
We chose this statistic because it has previ-ously been found to be effective for automaticallyconstructing translation lexicons (e.g., Melamed,2000).
We compute LLR scores using the follow-ing formula presented by Moore (2004):LLR(f, e) =?f??{f,?f}?e??
{e,?e}C(f?, e?)
log p(f?|e?)p(f?
)In this formula f and e mean that the words whosedegree of association is being measured occur in therespective target and source sentences of an alignedsentence pair, ?f and ?e mean that the correspond-ing words do not occur in the respective sentences,f?
and e?
are variables ranging over these values,and C(f?, e?)
is the observed joint count for the val-ues of f?
and e?.
The probabilities in the formularefer to maximum likelihood estimates.Since the LLR score for a pair of words is highif the words have either a strong positive associ-ation or a strong negative association, we discardany negatively associated word pairs by requiringthat p(f, e) > p(f) ?
p(e).
Initially, we computedthe LLR scores for all positively associated En-glish/French word pairs in our 500K sentence paircorpus.
To reduce the memory requirements of ouralgorithms we discarded any word pairs whose LLRscore was less than 1.0.
This left us with 12,797,697word pairs out of a total of 21,451,083 pairs that hadat least one co-occurrence.4 One-to-One, Word Type AlignmentMethods4.1 Method 1The first set of association-based word-aligmentmethods we consider permit only one-to-one align-ments and do not take word position into account.The simplest method we consider uses the LLRscores to link words according to Melamed?s (2000)?competitive linking algorithm?
for aligning wordsin a pair of sentences.
Since competitive linking has2no way to distinguish one instance of a particularword type from another, we operate with counts oflinked and unlinked instances of word types, with-out trying to designate the particular instances thecounts refer to.
This version of competitive linkingcan be described as follows:?
Find the pair consisting of an English word typeand a French word type that have the highestassociation score of any pair of words types thatboth have remaining unlinked instances.?
Increase by 1 the count of linked occurrencesof this pair of word types, and decrease by 1the count of unlinked instances of each of theseword types.?
Repeat until no more words can be linked.We will refer to this version of the competitive link-ing algorithm using LLR scores as Method 1.
Thisis the method that Melamed uses to generate an ini-tial alignment that he refines by re-estimation in his?Method A?
(Melamed, 2000).Method 1 can terminate either because one orboth sentences of the pair have no more unlinkedwords, or because no association scores exist for theremaining unlinked words.
We can use this fact totrade off recall for precision by discarding associa-tion scores below a given threshold.
Table 1 showsthe precision/recall trade-off for Method 1 on our de-velopment set.
Since Method 1 produces only wordtype alignments, these recall and precision scoresare computed with respect to an oracle that makesthe best possible choice among multiple occurrencesof the same word type.2 The best (oracular) AER is0.216, with recall of 0.840 and precision of 0.747,occurring at an LLR threshold of 11.7.4.2 Method 2A disadvantage of Method 1 is that it makes align-ment decisions for each sentence pair independentlyof the decisions for the same words in other sentencepairs.
It turns out that we can improve alignment2The oracle goes through the word type pairs in the sameorder as the competitive linking algorithm, linking particularinstances of the word types.
It prefers a pair that has a surealignment in the annotated test data to a pair that has a possiblealignment; and prefers a pair with a possible alignment to onewith no alignment.Recall Precision Threshold0.111 0.991 1683680.239 0.923 710740.304 0.902 532860.400 0.838 260010.501 0.822 113060.600 0.788 42240.700 0.778 11410.800 0.765 1240.848 0.732 1Table 1: Recall/Precision Trade-Off for Method 1.accuracy by biasing the alignment method towardslinking words in a given sentence that are also linkedin many other sentences.
A simple way to do thisis to perform a second alignment based on the con-ditional probability of a pair of words being linkedaccording to Method 1, given that they both occur ina given sentence pair.
We estimate this link proba-bility LP asLP (f, e) = links1(f, e)cooc(f, e)where links1(f, e) is the number of times f and eare linked according to Method 1, and cooc(f, e) isthe number of times f and e co-occur in aligned sen-tences.3We now define alignment Method 2 as follows:?
Count the number of links in the training cor-pus for each pair of words linked in any sen-tence pair by Method 1.?
Count the number of co-occurrences in thetraining corpus for each pair of words linkedin any sentence pair by Method 1.?
Compute LP scores for each pair of wordslinked in any sentence pair by Method 1.?
Align sentence pairs by competitive linking us-ing LP scores.3Melamed (1998) points out there are at least three ways tocount the number of co-ccurrences of f and e in a given sen-tence pair if one or both of f and e have more than one occur-rence.
Based on preliminary explorations, we chose to countthe co-occurrences of f and e as the maximum of the numberof occurrences of f and the number of occurrences of e, if bothf and e occur; otherwise cooc(f, e) = 0.3Recall Precision Threshold0.100 0.887 0.9890.230 0.941 0.9820.301 0.952 0.9670.400 0.964 0.9380.501 0.967 0.8750.600 0.967 0.8110.705 0.948 0.6490.816 0.921 0.4410.880 0.775 0.000Table 2: Recall/Precision Trade-Off for Method 2.Table 2 shows the precision/recall trade-off forMethod 2 on our development set.
Again, an ora-cle is used to choose among multiple occurrencesof the same word type.
The best (oracular) AER is0.126, with recall of 0.830 and precision of 0.913,occurring at an LP threshold of 0.215.4.3 Method 3It is apparent that Method 2 performs much betterthan Method 1 at any but the lowest recall levels.However, it fails to display a monotonic relation-ship between recall and precision as the score cut-off threshold is tightened or loosened.
This seemsto be due to the fact that the LP measure, unlikeLLR, does not discount estimates made on the basisof little data.
Thus a pair of words that has one co-occurrence in the corpus, which is linked by Method1, gets the same LP score of 1.0 as a pair of wordsthat have 100 co-occurrences in the corpus and arelinked by Method 1 every time they co-occur.A simple method of compensating for this over-confidence in rare events is to apply absolute dis-counting.
We will define the discounted link proba-bility LPd similarly to LP , except that a fixed dis-count d is subtracted from each link count:LPd(f, e) =links1(f, e) ?
dcooc(f, e)Method 3 is then identical to Method 2, except thatLPd is used in place of LP .
We determined the op-timal value of d for our development set to be ap-proximately 0.9, using the optimal, oracular AER asour objective function.Table 3 shows the precision/recall trade-off forMethod 3 on our development set, with d = 0.9Recall Precision Threshold0.178 1.000 0.9820.200 0.998 0.9770.300 0.999 0.9580.405 0.998 0.9230.502 0.994 0.8710.602 0.987 0.7580.737 0.947 0.6470.804 0.938 0.4410.883 0.776 0.000Table 3: Recall/Precision Trade-Off for Method 3.and use of an oracle to choose among multiple oc-currences of the same word type.
The best (orac-ular) AER is 0.119, with recall of 0.827 and pre-cision of 0.929, occurring at an LPd threshold of0.184.
This is an improvement of 0.7% absolutein AER, but perhaps as importantly, the monotonictrade-off between precision and recall is essentiallyrestored.
We can see in Table 3 that we can achieverecall of 60% on this development set with precisionof 98.7%, and we can obtain even higher precisionby sacrificing recall slightly more.
With Method 2,96.7% was the highest precision that could be ob-tained at any recall level measured.5 Allowing Many-to-One AlignmentsIt appears from the results for Methods 2 and 3 onthe development set that reasonable alignment ac-curacy may be achievable using association-basedtechniques (pending a way of selecting the best wordtoken alignments for a given word type alignment).However, we can never learn any many-to-one align-ments with methods based on competitive linking, aseither we or Melamed have used it so far.To address this issue, we introduce the notion ofbilingual word clusters and show how iterated appli-cations of variations of Method 3 can learn many-to-one mappings by building up clusters incrementally.Consider the abstract data structure to which com-petitive linking is applied as a tuple of bags (multi-sets).
In Methods 1?3, for each sentence pair, com-petitive linking is applied to a tuple of a bag ofFrench words and a bag of English words.
Sup-pose we apply Method 3 with a high LPd cut-offthreshold so that we can be confident that almost all4the links we produce are correct, but many Frenchand English words remain unlinked.
We can regardthis as producing for each sentence pair a tuple ofthree bags: bags of the remaining unlinked Englishand French words, plus a third bag of word clustersconsisting of the linked English and French words.To produce more complex alignments, we can thencarry out an iteration of a generalized version ofMethod 3, in which competitive linking connects re-maining unlinked English and French words to eachother or to previously derived bilingual clusters.4As just described, the approach does not workvery well, because it tends to build clusters too of-ten when it should produce one-to-one alignments.The problem seems to be that translation tends tobe nearly one-to-one, especially with closely re-lated languages, and this bias is not reflected in themethod so far.
To remedy this, we introduce two bi-ases in favor of one-to-one alignments.
First, we dis-count the LLR scores between words and clusters,so the competitive linking pass using these scoresmust find a substantially stronger association for agiven word to a cluster than to any other unlinkedword before it will link the word to the cluster.
Sec-ond, we apply the same high LPd cut-off on word-to-cluster links that we used in the first iterationof Method 3 to generate word-to-word links.
Thisleaves many unlinked words, so we apply one moreiteration of yet another modified version of Method3 in which competitive linking is allowed to link theremaining unlinked words to other unlinked words,but not to clusters.
We refer to this sequence of threeiterations of variations of Method 3 as Method 4.To evaluate alignments involving clusters accord-ing Och and Ney?s method, we translate clustersback into all possible word-to-word alignments con-sistent with the cluster.
We found the optimal valueon the development set for the LLR discount forclusters to be about 2000, and the optimal value forthe LPd cut-off for the first two iterations of Method3 to be about 0.7.
With these parameter values, thebest (oracular) AER for Method 4 is 0.110, with re-call of 0.845 and precision of 0.929, occurring at afinal LPd threshold of 0.188.
This is an improve-4In principle, the process can be further iterated to build upclusters of arbitrary size, but at this stage we have not yet foundan effective way of deciding when a cluster should be expandedbeyond two-to-one or one-to-two.ment of 0.9% absolute in AER over Method 3, re-sulting from an improvement of 1.7% absolute inrecall, with virtually no change in precision.6 Token Alignment Selection MethodsFinally, we turn to the problem of selecting the bestword token alignment for a given word type align-ment, and more generally to the incorporation ofpositional information into association-based word-alignment.
We consider three token alignment se-lection methods, each of which can be combinedwith any of the word type alignment methods wehave previously described.
We will therefore referto these methods by letter rather than number, witha complete word token alignment method being des-ignated by a number/letter combination.6.1 Method AThe simplest method for choosing a word tokenalignment for a given word type alignment is tomake a random choice (without replacement) foreach word type in the alignment from among the to-kens of that type.
We refer to this as Method A.6.2 Method BIn Method B, we find the word token alignment con-sistent with a given word type alignment that is themost nearly mononotonic.
We decide this by defin-ing the degree of nonmonotonicity of an alignment,and minimizing that.
If more than one word tokenalignment has the lowest degree of nonmonotonic-ity, we pick one of them arbitrarily.To compute the nonmonotonicity of a word to-ken alignment, we arbitrarily designate one of thelanguages as the source and the other as the target.We sort the word pairs in the alignment, primarilyby source word position, and secondarily by targetword position.
We then iterate through the sortedalignment, looking only at the target word positions.The nonmonotonicity of the alignment is definedas the sum of the absolute values of the backwardjumps in this sequence of target word positions.For example, suppose we have the sorted align-ment ((1,1)(2,4)(2,5)(3,2)).
The sequence of targetword positions in this sorted alignment is (1,4,5,2).This has only one backwards jump, which is ofsize 3, so that is the nonmonotonicity value for thisalignment.
For a complete or partial alignment, the5nonmonotonicity is clearly easy to compute, andnonmonotonicity can never be decreased by addinglinks to a partial alignment.
The least nonmono-tonic alignment is found by an incremental best-first search over partial alignments kept in a priorityqueue sorted by nonmonotonicity.6.3 Method CMethod C is similiar to Method B, but it also usesnonmonotonicity in deciding which word types toalign.
In Method C, we modify the last pass of com-petitive linking of the word type alignment methodto stop at a relatively high score threshold, and wecompute all minimally nonmonotonic word tokenalignments for the resulting word type alignment.We then continue the final competitive linkingpass applied to word tokens rather than types, but weselect only word token links that can be added to oneof the remaining word token alignments without in-creasing its nonmonotonicity.
Specifically, for eachremaining word type pair (in order of decreasingscore) we make repeated passes through all of theword token alignments under consideration, addingone link between previously unlinked instances ofthe two word types to each alignment where it ispossible to do so without increasing nonmonotonic-ity, until there are no longer unlinked instances ofboth word types or no more links between the twoword types can be added to any alignment withoutincreasing its nonmonotonicity.
At the end of eachpass, if some, but not all of the alignments have had alink added, we discard the alignments that have nothad a link added; if no alignments have had a linkadded, we go on to the next word type pair.
This fi-nal competitive linking pass continues until another,lower score threshold is reached.6.4 Comparison of Token Alignment SelectionMethodsOf these three methods, only C has additional freeparameters, which we jointly optimized on the de-velopment set for each of the word type alignmentmethods.
All other parameters were left at their op-timal values for the oracular choice of word tokenalignment.Table 4 shows the optimal AER on the develop-ment set, for each combination of word type align-ment method and token alignment selection methodOracle A B C1 0.216 0.307 0.255 0.2432 0.126 0.210 0.147 0.1093 0.119 0.208 0.138 0.1034 0.110 0.196 0.130 0.098Table 4: Development Set AER for all Methods.that we have described.
For comparison, the ora-cle for each of the pure word type alignment meth-ods is added to the table as a token alignment selec-tion method.
As we see from the table, Method 4is the best word type alignment method for everytoken alignment selection method, and Method Cis the best actual token alignment selection methodfor every word type alignment method.
Method Ceven beats the token alignment selection oracle forevery word alignment type method except Method1.
This is possible because Method C incorporatesnonmonotonicity information into the selection oflinked word types, whereas the oracle is applied af-ter all word type alignments have been chosen.The best combined overall method is 4C.
For thiscombination, the optimal value on the developmentset for the first score threshold of Method C wasabout 0.65 and the optimal value of the second scorethreshold of Method C was about 0.075.7 EvaluationWe computed the recall, precision, and AER on theheld-out subset of the English-French data both forour Method 4C (using parameter values optimizedon the development subset) and for IBM Model4, computed using Och?s Giza++ software package(Och and Ney, 2003) trained on the same data asMethod 4C.
We used the default configuration fileincluded with the version of Giza++ that we used,which resulted in five iterations of Model 1, fol-lowed by five iterations of the HMM model, fol-lowed by five iterations of Model 4.
We trained andevaluated the models in both directions, English-to-French and French-to-English, as well as the union,intersection, and what Och and Ney (2003) call the?refined?
combination of the two alignments.
Theresults are shown in Table 5.
We applied the sameevaluation methodology to the English-Romaniandata, with the results shown in Table 6.6Alignment Recall Precision AERMethod 4C 0.879 0.929 0.094E ?
F 0.870 0.890 0.118F ?
E 0.876 0.907 0.106Union 0.929 0.845 0.124Intersection 0.817 0.981 0.097Refined 0.908 0.929 0.079Table 5: English-French Results.Comparison of the AER for Method 4C and IBMModel 4 shows that, in these experiments, only therefined combination of both directions of the Model4 alignments outperforms our method, and only onthe English-French data (and by a relatively smallamount: 16% relative reduction in error rate).
Ourexisting Perl implementation of Method 4C takesabout 3.5 hours for the 500K sentence pair dataset on a standard desk top computer.
It took over8 hours to train each direction of Model 4 usingGiza++ (which is written in C++).
We believe that ifour method was ported to C++, our speed advantageover Giza++ would be substantially greater.
Previ-ous experience porting algorithms of the same gen-eral type as Method 4C from Perl to C++ has givenus speed ups of a factor of 10 or more.Note that we were unable to optimize the manyoptions and free parameters of Giza++ on the de-velopment data, as we did with the parameters ofMethod 4C, which perhaps inhibits us from drawingstronger conclusions from these experiments.
How-ever, it was simply impractical to do so, due the timerequired to re-train the Giza++ models with new set-tings.
With Method 4C, on the other hand, most ofthe time is spent either in computing initial corpusstatistics that are independent of the parameters set-tings, or in performing the final corpus alignmentonce the parameters settings have been optimized.Of the five parameters Method 4C requires, changesto three of them took less than one hour of retrain-ing (on the English-French data ?
much less on theEnglish-Romanian data), and settings of the last twoneed to be tested only on the small amount of anno-tated development data, which took only a few sec-onds.
This made it possible to optimize the parame-ters of Method 4C in a small fraction of the time thatwould have been required for Giza++.Alignment Recall Precision AERMethod 4C 0.580 0.881 0.301E ?
R 0.545 0.759 0.365R ?
E 0.549 0.741 0.370Union 0.570 0.423 0.515Intersection 0.180 0.901 0.820Refined 0.584 0.759 0.328Table 6: English-Romanian Results.8 Related WorkThe literature on measures of bilingual word asso-ciation is too large to review thoroughly, but mostlyit concerns extracting bilingual lexicons rather thanword alignment.
We discuss three previous researchefforts that seem particularly relevant here.Gale and Church (1991) made what may be thefirst application of word association to word align-ment.
Their method seems somewhat like ourMethod 1B.
They use a word association score di-rectly, although they use the ?2 statistic instead ofLLR, and they consider forward jumps as well asbackward jumps in a probability model in place ofour nonmonotonicity measure.
They report 61% re-call at 95% precision on Canadian Hansards data.Obviously, we are building directly on the work ofMelamed (2000), sharing his use of the LLR statis-tic and adopting his competitive linking algorithm.We diverge in other details, however.
Moreover,Melamed makes no provision for other than one-to-one alignments, and he does not deal with the prob-lem of turning a word type alignment into a wordtoken alignment.
As Table 4 shows, this is crucial toobtaining high accuracy alignments.Finally, our work is similar to that of Cherry andLin (2003) in our use of the conditional probabil-ity of a link given the co-occurrence of the linkedwords.
Cherry and Lin generalize this idea to in-corporate additional features of the aligned sentencepair into the conditioning information.
The chiefdifference between their work and ours, however, istheir dependence on having parses for the sentencesin one of the languages being aligned.
They use thisto enforce a phrasal coherence constraint, which ba-sically says that word alignments cannot cross con-stituent boundaries.
They report excellent alignment7accuracy using this approach, and one way of com-paring our results to theirs is to say that we show it isalso possible to get good results (at least for Englishand French) by using nonmonotonicity informationin place of constituency information.9 ConclusionsThe conventional wisdom in the statistical MT com-munity has been that ?heuristic?
alignment meth-ods based on word association statistics could not becompetitive with methods that have a ?well-foundedmathematical theory that underlies their parame-ter estimation?
(Och and Ney, 2003, p. 37).
Ourresults seem to suggest that this is not the case.While we would not claim to have demonstated thatassociation-based methods are superior to the es-tablished approach, they certainly now appear to beworth investigating further.Moreover, our alignment method is faster thanstandard models to train; potentially much faster ifit were re-implemented in a language like C++.
Ef-ficiency issues, especially in training, are often dis-missed as unimportant, but one should consider sim-ply the number of experiments that it is possible todo in the course of system development.
In our case,for example, it was impractical to try to try to opti-mize all the options and parameters of the Giza++models in a reasonable amount of time, given thecomputational resources at our disposal.While the wealth of details regarding variouspasses through the data in our best methods mightseem to undercut our claim of simplicity, it is impor-tant to realize that each of our methods makes a fixednumber of passes, and each of those passes involvesa simple procedure of computing LLR scores, col-lecting co-occurrence counts to estimate link proba-bilities, or performing competitive linking; plus onebest first search for minimally nonmonotonic align-ments.
All these procedures are simple to under-stand and straightforward to implement, in contrastto some of the difficult mathematical and computa-tional issues with the standard models.ReferencesPeter F. Brown, Stephen A. Della Pietra, Vincent J.Della Pietra, and Robert L. Mercer.
1993.
TheMathematics of Statistical Machine Translation:Parameter Estimation.
Computational Linguis-tics, 19(2):263?311.Colin Cherry and Dekang Lin.
2003.
A ProbabilityModel to Improve Word Alignment.
In Proceed-ings of the 41st Meeting of the Association forComputational Linguistics, pp.
88?95, Sapporo,Japan.Ted Dunning.
1993.
Accurate Methods for theStatistics of Surprise and Coincidence.
Compu-tational Linguistics, 19(1):61?74.William A. Gale and Kenneth W. Church.
1991.Identifying Word Correspondences in ParallelTexts.
In Proceedings of the Speech and NaturalLanguage Workshop, pp.
152?157, Pacific Grove,California.Philipp Koehn, Franz Joseph Och, and DanielMarcu.
2003.
Statistical Phrase-Based Trans-lation.
In Proceedings of the Human LanguageTechnology Conference of the North AmericanChapter of the Association for ComputationalLinguistics (HLT-NAACL 2003), pp.
127?133,Edmonton, Alberta, Canada.I.
Dan Melamed.
1998.
Models of Co-occurrence.University of Pennsylvania, IRCS Technical Re-port #98-05.I.
Dan Melamed.
2000.
Models of Transla-tional Equivalence.
Computational Linguistics,26(2):221?249.Rada Mihalcea and Ted Pedersen.
2003.
An Evalu-ation Exercise for Word Alignment.
In Proceed-ings of the HLT-NAACL 2003 Workshop, Buildingand Using Parallel Texts: Data Driven MachineTranslation and Beyond, pp.
1?6, Edmonton, Al-berta, Canada.Robert C. Moore.
2004.
On Log-Likelihood-Ratiosand the Significance of Rare Events.
In Proceed-ings of the 2004 Conference on Empirical Meth-ods in Natural Language Processing, pp.
333?340, Barcelona, Spain.Franz Joseph Och and Hermann Ney.
2003.A Systematic Comparison of Various StatisticalAlignment Models.
Computational Linguistics,29(1):19?51.8
