Japanese Case Structure Analysisby Unsupervised Construction of a Case Frame DictionaryDaisuke Kawahara, Nobuhiro Kaji and Sadao KurohashiGraduate  School of Intbrm~tics, Kyoto  UniversityYoshida-Honmachi ,  S~kyo-ku, Kyoto,  606-8501, Japan{kawahara, kaj i ,  kuro }@p inc. kuee.
kyoto-u, ac.
jpAbstractIn Japanese, case structure analysis is very im-t)ortant to handle several troublesome charac-teristics of Japanese snch as scrambling, onfis-sion of ease components, mid disappearance ofcase markers.
However, fi)r lack of a wide-coverage ase frame dictionary, it has been dif-ficult to perfornl case structure analysis accu-rat;ely.
Although several methods to constructa ease fl'mne dictionary from analyzed corporahave been proposed, they cannot avoid datasparseness 1)rol)lem.
This paper proposes an un-supervised method of constructing a case framedictionary from an enormous raw corpus by us-ing a robust and accurate parser.
It also pro-rides a case structure analysis method based onthe constructed ictionary.1 I n t roduct ionSyntactic analysis, or parsing has been a mainobjective in Natural Language Processing.
Incase of Jat)anese , however, syntactic analysiscannot clarify relations between words ill sen-tences because of several troublesome character-istics of Japanese such as scrambling, omissionof case components, and disappearance of casemarkers.
Therefore, in Japanese sentence analy-sis, case structure analysis is an important issue,and a case frame dictionary is necessary for theanalysis.Some research institutes have constructedJapanese case frmne dictiouaries manually (Ike-hara et al, 1997; Infbrmation-Technology Pro-motion Agency, Japan, 1987).
However, it isquite expensive, or almost impossible to con-struct a wide-coverage ease fl'anm dictionary byhand.Others have tried to construct a case fl'mnedictionary automatically from analyzed corpora(Utsuro et al, 1998).
However, existing syntac-tically analyzed corpora are too small to learn adictionary, since case fl'ame iuformation consistsof relations between ouns and verbs, which rnul-tiplies to millions of combinations.Based on such a consideration, we took thefbllowing unsupervised learning strategy to the.Japanese case structure analysis:1.
At first, a robust and accurate parser is de-veloped, which does not utilize a case fl'mnedictionary,2.
a very large corI)us is parsed by the parser,3.
reliable noun-verb relations are extractedfrom the parse results, and a case frmne dic-tionary is constructed from them, and4.
the dictionary is utilized for case structureanalysis.2 Characteristics of Japaneselanguage and necessity of cases t ructure  ana lys i sIn Japanese, postpositions function as casemarkers ( (Ms)  mid a verb is final in a sentence.The basic structure of a Japanese sentence is asfbllows:(1) kate  9a coat wo ki~'u.he nominative-CM coat accusative-CM wear(lie wears a coat)A clause modifier is left to the modified nounas follows:(2) kate  9 a k i te - i ru  coatlie nom-CM wear coat(the coat he wears)The modified noun followed by a postpositionthen becomes a case component of a matrix verb.The typical structure of a Japanese complex sen-tence is as fbllows:432(3) boush, i no irv wa kitc-ir'uhat of color tol)ic-marker wearcoat ni a'wa~'cr"~,.coal; dative-CM harmonize(c/) harmonizes the color of his/her hat withthe coat he/she wears)In terms of autolnatic analysis, the problen>atic characteristics of Japanese sentences can besummarized as follows:1.
Case componenl;s are often scrambled oromitted.2.
Case-marking postpositions disappear whencase components are accompanied by topic-markers or other special 1)ostpositionsmeaning 'just', 'also' and others.cx) karv 'wa coat me ti:itc-iv'u.he tol}iC-lna.rker coat also wear(Ile wears a coat a.lso)3.
A noun modified 1)y a clause is usually a casecomponent for the verb of the mo(litlyingclause.
However, there is no case-marker fortheir relation.
In case of sentence 3, there isno case-marker for coat in relation to kite-ir'u 'wear'.
Note that 'hi (dative-CM) of coat:ni does not show the case to kitc-ivu 'wear',lint to awascr'v, 'harmonize'.4.
Sentence 3 exhibits a typical structural am-1)iguity in a ,lalmnese sentence.
That is,ir'o "~va 'color topic-marker' possit)ly modi-ties kit, c- iru 'wear' or awa.scv'u qmrmonize'.In English, sentence structure is rather rigid,and word order (the position in relation to theverb) clearly defines cases.
In Japanese, how-ew% the l)roblem 1 above makes word order use-less, and CMs constitute the only int'ormation fordetecting cases.Nevertheless, CMs often disapl)ear because ofthe problems 2 and 3, whidl means that sim-ple syntactic analysis cmmot clari(5~ cases sui\[i-cientl> For eXalnple, given an inlmt sentence:(4) har'c wa Dcv, tsch,-go me hano, sv,.he topic-marker Germall also sl)eak(he speaks German also)a simple syntactic analysis just detects both kar'c'he' and Dcutsch-go 'German' modifies \]ta'aas~t'speak', but tells nothing about which is subjectand object.
This analysis result is not sufficientfor subsequent NLP applieations like Japaneseto English machine l;rmmlation.Then, what we need to do is a case structure.analysis based on a case fl'ame dictiolmry, or asubcat, of each verb as follows:hanasu 'speak':ga (nora) ks're 'he', hire 'person''we (ace) cigo 'English', kotoba 'language'~;i?
'U, ~%vear':ga (nora) kavc qm', hil, o 'person'we (ace) fuhu 'cloth', coat 'coat'a'tl Jasel'~t 'har l l lonize' :ga (nora) kar'c 'he', hito 'person''we (ace) ire ~color'ni (dat) fltku 'cloth'Consultation of such a dictionary can easily findthat kar'c 'he' is a nomilmtive case and Dev, tsch,-90 'German' is an accusative (:as(', in the sentence4.Furthermore, a (:ase frame dictionary Call so lvethe problem 4 above, that is, some part of struc-tural ambiguity in sentences.
In case of sentence3, a t)r()l)er head for 'ir'o wa 'color topic-marker'(:all })e selected by consulting case slots of kir'u~wear' and those of a'wascru 'harmonize'.3 Unsupe,  rv i sed  const ruct ion  o f  acase  f ra lne  d ic t ionaryThis s(x:tion explains how to construct a casefralll(*, dictionary fl'om corl)ora autonmtica.lly.As mentioned in the introduction section, it;is quite expensive, or ahnost ilnl)ossible to con-struct a wide-coverage case frame dictionary bylmnd.
In Japanese,, some noun q- copula workslike an adjective.
For example, sa~tsei da 'posi-tiveness + Colmla' can take 9a case and 'hi case.However, such case frames are rarely covered t)ythe existing handmade dictionaries 1.Fm'thermore, existing halldmade dictionariescover typical obligatory cases like ga (nomina-tive), wo (accusative), ni (dative), but do notcover compound case markers uch as ni-kandz.itc'in terms of', 'wo-rncqutte 'concerning' and oth-ers.Then, we tried to construct an example-basedcase frmne dictionary from corpora, which de-lOut method collects case frames not only tbr verbs,but also tbr adjectives mM nouns-kcopula.
In this paper,we use 'verb' instead of 'w;rb/adjective.
orllOllll -{- copula.
'for simplicity.433Table 1: The accuracy of KNP.
'wa~ 7tto c lause  clause9 a 'we n i  ka'r'a rr~.ade ?lori topic- modif~ying modifyingnoln.
ace.
dative from to from marker verbs nouIIS'lbtal91.2% 97.7% 94.2% 83.8% 85.3% 82.8% 88.0% 84.3% 95.5% 91.3%scribes what kind of cases each verb has andwhat kind of nouns can fill a case slot.
Very largesyntactically analyzed corpora could be useful toconstruct such a dictionary.
However, corpus an-notation costs very much and existing analyzedcorpora are too small from the view point of caseframe learning.
For exmnple, in Kyoto Univer-sity Corpus which consists of about 40,000 ana-lyzed sentences of newspaper articles, very basicverbs like te tsudau 'help' or v, ketsv ,  kcr 'u 'accept'appear only 10 times or 15 times respectively.
Itis obvious that such small data are insufficientfor automatic ase frmne learning.
That is, caseframe learning must be done from enormous un-analyzed corpora, in unsupervised way 2.3.1 Good parserNLP research group at Kyoto University hasbeen developing a robust and accurate parsingsystem, KNP, over the last ten yem's (Kurohashiand Nagao, 1994; Kurohashi and Nagao, 1998).This parser has the following advantages:?
.Japanese is an agglutinative language, andseveral Nnction words (auxiliary verbs, suf-fixes, and postpositions) often appear to-gether and in many cases compositionalitydoes not hold among them.
KNP treatssuch function words careflflly and precisely.?
KNP detects scopes of coordination struc-tures well based on their parallelism.?
KNP employs everal heuristic rules to pro-duce mfique parses for the input sentences.The accuracy of KNP is shown in Table 1,which counted whether each phrase modifies aproper head or not.
The overall accuracy wasaround 90%, and the accuracy concerning casecomponents varies from 82% to 98%.21n English, several unsupervised methods have beenproposed (Manning, 1993; Briscoe and Carroll, 19!
)7).However, as mentioned in Section 3, automatic Japanesecase analysis is much harder than English.We can collect pairs of verbs and case compo-nents from the automatic analyses of large cor-pora by KNP.3.2 Cop ing wi th  two problemsThe quality of automatic ase frame learningcould be negatively influenced by the %llowingtwo problems:Word sense ambiguity:  A verb sometimeshas w~rious usages and possibly has severalcase frames depending on its usages.Structura l  ambiguity:  KNP performs fairlywell, but automatic parse results inevitablycontt~in errors.The tbllowing sections explain how to solvethese problems.3.2.1 Word sense ambigu i tyIf a verb has two or more meanings and theircase fl'ame patterns differ, we htwe to disam-biguate the sense of each occurrence of the verbin a corpus first, and collect case components foreach sense respectively.
However, unsupervisedword sense disambiguation f fl'ee texts is one ofthe most ditficult problems in NLP.
At the verybegimfing, even the definition of word senses isopen to question.To cope with this problem, we made a verysimple but usefltl assumption: a light verb hasdiffbrent case frames det)ending on its main casecomponent; an ordinary verb has a unique casefrmne even if it has two or more meanings.
Forexample, the case frmne of the verb narn  'be-come' differs depending on its ni (dative) caseas %llows:.
.
.
ga  b?
}ouki n i  na ' runora.
become ill?
.
.
ga  .
.
.
to  to rnodach i  n i  na'r"unora.
with become a fliendIn most cases, the main case components areplaced just in front of the light verbs so thatthe automatic parser can detect their relations434Tal/le 2: EXmnl)les of the constructed ease frames.verl)st, aS?t\]gCl"~l,'help'yomul'ead'case lnarkel"s(1,o111),,,,o (it(:(:)'r~,i (dat)ae (op).qa (no\]n)'wo (at(;)hi, (dat)& (o10example  nomlshusband, person, child, staff, I, SUSl)eet, faculty, ....jol), shol) , farmwork, preparation, election, move, ...son, friend, ambassador, meml~er, thank, holid~\y, ...volunte(,r, aft'air, otfice, rewar(l, house, headquarters, ...lX;rson, \], chihl, adult, parent, teacher, ...newspaper, book, magazine, article, nov(J, letter, ...chiht, person, daughter, teacher, student, reader, ...newspaper, book, magazine, library, classroom, bathroom, ...reliably.
Therefore, as for five major and trou-t)lesome light verbs (.~'.,r'u 'do', 'nwr'u, q)ceomo?,ar'u 'is .
.
. '
,  iu ~s~w', nai 'not'), their case fl'mnesare distinguished epending (m their left neigh-bouring case components.
For other verbs, weaSStlllle a \] lnique ease f rame.3.2 .2  St ructura l  ambigu i tyAs shown in '_\['~dfle 1, KNP detects heads of caseconlt~onents in faMy high accuracy.
However,in order to collect nmch reliable data, we dis-carded moditier-hcad relations in the aul;onmti-tal ly Imrsed corpora in the following cases:?
When CMs of ease conqxments disappearbecause oi" topic markers or others.?
When the verb is followed 1)y a causativeauxil iary o1' a passive auxiliary, l;he case tm.t-t(:rn is e\]mnged and the 1;race in KNI '  is notso rclial)le.Based on the conditions al)ove, case compo-nents of each verb are collected froln the 1)arscdcorpora, and the collected ata arc considered ascase frames of verbs.
However, if the f lcquencyof a CM is very low compared to other CMs, itmight t)e collected because of parse errors.
So,we set the threshold for the CM flequency as2~,  where m.f means the frequency of the1nest folln(t ChJ.
i f  the fl'equeney of ~t CM is lesst lmn the threshold, it is discarded, l.~br exalnple,suppose the most frequent CM fin' a verb is we,100 times, and the frequency of ni CM tbr theverb is 1.6, ni CM is discarded (since it is lessthan the threshold, 20).a.3  Const ructed  case  f rmne d ic t ionaryWe applied the al)ow', procedure to MainichiNewst)al)er Corpus (7 years, 3,600,00(} sen-tences).
Fronl the cortms , case franws of 23,497verbs are constructed; the average number ofease slots of a verb is 2.8; the average munberof cxanqflc nouns in a (:as(: slot is 33.6.
Table 2shows exmnlfles of constructed ease Dames.Although the constructed ata look apl)ropri-ate in most cases, it is hard to evaluate a (lictio-nary statica.ll> In the next section, we use thedictiomu'y in case structure analysis and eval-uate the analysis result, wlfich also im\])lies ancvahu~.ti(m of the dictionary itself.4 Case  s t ructure  ana lys i s  us ing  theconst ructed  case  f rame d ic t ionary4.1.
Match ing  o f  an  input  sentence  anda case  f ra l l le'Jl~e basic 1)ro(:cdure in ('ase strucl;ul"e analysis islo match an inlml sentence with a case frame,aS show11 ill lqgUl'C, 1.The matching of case conq)onenl:s in an inputand case slots in a case  fl'alllO is (\[Olle Oll thefollowing conditions:I.
When a ease component has a CM, it mustbe assigned to 1;11o case slot with the sameCM..
When a case COml)Onent does nol: have aCM, it can 1)e assigned to the 9a, we, or niCM slot.. ()nly one case component can be assignedto a case slot (unique case assiglmmnt con-straint).The conditions above may produce nmltil)lematching patterns, and to select the proper onealllOng {,llclll, 11Oll118 of case COlllpon(',lltS al'o COlll-pared with examph',s in case slots of the (tictio-nary.435syorui wa .
(5) document topic-marker /ka,'e .i .___1!,,e 1~" walashila" hand\[ (1 handed the document to him.
)WaRlSU 'hand'ga defendam, president ....we money, nlelllO, bribe ....ni person, suspect, ...de affair, office, room ....(6) Deutsch-go me/ Gcl'nlan also qhHI I ( IS I Ispeak " -7{';cq/;i'i;ira teacher who speaks also German)~ professor, president 1ni person, friend ....- -  we reason English Japaneseto (sentence)Figure 1: Matching of an inl)ut sentence and a case fl:ame.Even though a 3,600,000 sentences corpus wasused for learning, examples in case slots are stillsparse, and an input noun mostly does not matchexactly an example in the dictionary.
Then, athesaurus i employed to solve this problem.In our experiments, NTT Semantic FeatureDictionary (Ikehara et al, 1997) is employed asa thesaurus.
Suppose we calculate the silnilar-ity between Wl and w2, their depth is dl and d2in the thesaurus, and the depth of their lowest(most specitic) common ode is de, the similarityscore between them is calculated as follows:= (4  ?
+If W 1 and w2 are in the same node of the the-saurus, the similarity is 1.0, the maximum scorebased on this criteria.
If Wl and w2 are identical,the similarity is 1.0, of course.The score of case assigmnent is the best sim-ilarity between the input noun and examples inthe case slots.
The score of a matching patternis the sum of scores of case assignments in it.
Iftwo or more patterns meet the above conditions,one which has the best score is selected as a finalresult.In the case of sentence 5 in Figure 1, karc 7ti'he dativc-CM' is assigned to the ni case slot.Then, syorui wa 'document topic-marker' can beassigned to the ga or wo case slot.
By calculatingsimilarity between syorui and 9a-slot examplesand wo-slot exmnples, it; is considered to be as-signed to the wo slot.In case of sentence 6, none of the case compo-nents has a CM.
Based on similarity calculation,Deutsch,-go is assigned to 'wo, sensei is assignedto ga.4.2 Pars ing with case structure analysisA complex sentence which contains a clausalmodifier exhit)its a typical structural ambiguityof Japanese; case components left to a verb ofa clausal modifier, Vc, possibly modify V~: or amatrix verb Vm.For example, in sentence 3, ir'o 'w~L 'colortopic-inarker' possibly modifies kite-iru 'wear' or(l,~l)(\],Sel'~l, q lar i i l on ize ' .KNP, a rule-based parser, handles this type ofambiguity ~s follows.
If a case component is fol-lowed by a comma, it is treated as modif\[ying Vm ;if not, it is treated as modif\[ying 1~:.
Althoughthis heuristic rule usually explains real data verywell, sentence 3 will be analyzed incorrectly.Parsing which utilizes a case frame dictionarycan consider which is a proper head, V~ or Vm,tbr an ambiguous case compolmnt by comparingexamples in the case slots of V~ and 14~.
Sucha consideration nmst be done considering wlmtother case components modifly Vc and Vm, sincethe assigned case slot of a case component mightdiffer depending on the candidate structure ofthe sentence due to the unique case assignmentconstraint.Therefore, it is necessary to expand the struc-tural ambiguity and consider all the possiblestructures fbr an input.
So, we calculate thematching score of all pairs of case componentsand verbs in all possible structures of the sen-tence, and select the best structure based on the436boushi tic; ire wahat colorbott.~\]ti nohal ~,~~-- - __  ire waco lo r - -  IC(;?lt It\[COat ~5"?rllharlllOlliZeWe ClOth, tllli\]'/)l'lll, CI)la .... ~ WO \] pOWCI', face, }l}ind~ .
II de party, oily, home .... ni I prcl)lcnce, cItlth ....kite-it'lt Co(It I1i HWCLTCI'llweal" coat hllrnlolliZChati re wa -2 (distance penalty)c?
l ?
r  ~ \]kite-iru \[co.t ,,i ~~ COat IdilA't!rllk i ru  'wear' ~.
\  awa,~emt 'harllloilizc'2 ,:2,,,,,,6 ....Figure 2: Parsing with east structure analysis.sum of the matching scores in it.Since the heuristic rule employed ill KNP isactually very useful, we in(:orporate it, that is,l)enalty score is imposed to the modifier-hea(l re-la.tion depending on the distraint between ~t mod-ifi(;l" and a head.
If a moditier is not followed bya comma, the penalty score, 0 , -2 , -4 , -6 ,  ... isimposed when a moditler modifie.s the first (nea.r-est), second, third, tburth, ... verbs ill a sentencerespectively; if with a comma, the tmnalty score,-2 ,  0, -2,  -4,  ... is impose&For example, sentence 3 was analyzed t)y ourmethod as shown ill Figure 2.
Since the simi-lm'ity score between fro ~color' a.nd the 'we-slotof uwa.s'cr'u hmunonize is nmch larger t;\]iall theftl)etween ire 'eoloff and the ga-slot of lci'r'u.
'wear',the correct structure of the selltellee was de-tected (the right-lmnd parse of Figure 2).
Notethat, furthermore, both the ease of ire ill reb>tion to awascru  'harmonize', and the case of coal,in relation to kite-iru 'wear' were dete(:ted cor-rectly.Structm'al ambiguities often cause a combina-torial explosion when a sentence is long.
How-ever, by detecting the SeOl)eS of coordinate struc-tures 1)e%rehand, which off;ell aPl)ear in long'l'td)le 3: The at:curacy of case detection.
(;orre(:I; ill(:orl'e(;t\])arsing ease caseer ror  (lel;e(:l;ion (tete(:tiontopic-marleer 82 13 5clausal modifier 73 18 9senl;ences, we can reasonably limit the possil)lesl;ructures of the sentence.The ~werage analysis peed of tile ext)crimentsdescribed in the next section was about 50 sen-tenets/aria.
'File tinm-oul, of one rain.
was onlyemployed to 7 out of 4,272 test Selltellces.4.3 Exper i lnents  and discuss ionWe used 4,272 sentences of Kyoto University co lpus as a test set.
We parsed them by our newlnethod (Figure 3 shows several examt)les) andcheekc, d two 1)oints: case detection of mnbiguouscase (-omponents and syntactic analysis.First, we randomly selected ambiguous easecomponents: 100 l,ol)ic-markcA case componentsall(t 100 (:ase coral)orients moditied by clausal437ookllrasyo hathe Treasury3gatsuki kes:~an desettlenlellt ill March ,,.l'hintakuginkotl kakukmt ga I impr<n'ed bycase iajbmtatimleach trust banktsttmitareteirttsave liptokubetsu t3,uhokil~ ,1ospecially reserved moneymrikuzushi wocollstllllptiollgai,,'yolthathe Foreign Minislcrmtnitonwruallowhm~shhula.policymikka nion tile third \]4 Mexico ga Mexico\[Iglppyolt shiRl imln'ored hy cave i@~tmltli?~*iillltl(RlnCC ~ ~ \ ]i@lre Ixmshi mulo ?prevention o1" inl\]alion \[IL'eizai misaku nifimmclal pllllcyt,wtiteal~(Rl\[st'Lvlltttl'i ~hifacxphdnFigure 3: Exmnt)les of the mmlysis results.modifiers, and checked whether their cases werecorrectly detected or not.
As shown in Table 3,the accuracy of the analysis was fairly good: thattbr topic-markers was 82% and that tbr clausalmodifiers was 73%.Then, we compared the parse results of ourmethod with those of the original KNP.
As a re-sult, 565 modifier-head relations differed; in 260cases, our method was correct and the originalKNP was incorrect (by considering the struc-tures in the Kyoto University Corpus as a goldenstandard); in 224 cases, vice versa.
That is,our method was superior to KNP by 36 cases,and increased the overall accuracy from 89.8%to 89.9%.
Since the heuristic rule used in KNPis very strong, the improvement was not big.The improvement of the accuracy, though small,is valuable, because the accuracy around 90%seems close to the ceiling of this task.5 Conc lus ionWe proposed an unsupervised constructionmethod of a case frame dictionary.
We obtaineda large case fl'alne dictionary, which consistsof 23,497 verbs.
Using this dictionary, we candetect ambiguous case components accurately.Also since our method employs unsupervised dic-tionary learning, it can be easily scaled up.Re ferencesTed Briscoe and John Carroll.
1997.
Automaticextraction of subcategorization from corpora.In Prvccedings of ANLP-97.Satoru Ikehara, Masahiro Miyazaki, SatoshiShirai, Akio Yokoo, Hiromi Nakaiwa, Ken-tarou Ogura, and Yoshiflmfi Oyama Yoshi-hiko Hayashi, editors.
1997.
Japanese Lexi-con.
Iwananfi Publishing.Information-q~chnology Promotion Agency,,Japan.
1987.
Japanese Verbs : A Guide tothe H~A Lea:icon of Basic ,Japa~tcsc Verbs.S.
Kurohashi and M. Nagao.
1994.
A syntac-tic analysis method of long japanese sentencesbased on the detection of conjunctive struc-tures.
Computational Linguistics, 20(4).S.
Kurohashi and M. Nagao.
1998.
Build-ing a jal)anese parsed corpus while improv-ing the t)arsing system.
In Prvcccdin.qs of" Th.cFir;st h~,tcr'national Co't@r~ncc on LwnguageR.csources 64 Evaluation, pages 719 724.Christopher D. Maturing.
1993.
Automatic ac-quisition of a large snbcategorization dictio-nary froln corpora.
In Pr'occcding s of A CL-93.Takehito Utsuro, Takashi Miyata, and Yuji Mat-sumoto.
1998.
General-to-simeific model se-lection tbr subcategorization preference.
InProceedings of th.c 17th International ConJ'cr-cncc on Computational Li'n.quistics and the36th Annual Mectin.q of the Association forComputational Lin.quistics.438
