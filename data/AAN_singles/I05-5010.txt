Automatic generation of large-scale paraphrasesRichard Power and Donia ScottCentre for Research in ComputingThe Open UniversityWalton HallMilton Keynes MK7 6AA{r.power,d.scott}@open.ac.ukAbstractResearch on paraphrase has mostly fo-cussed on lexical or syntactic variationwithin individual sentences.
Our con-cern is with larger-scale paraphrases,from multiple sentences or paragraphsto entire documents.
In this paperwe address the problem of generatingparaphrases of large chunks of texts.We ground our discussion through aworked example of extending an exist-ing NLG system to accept as input asource text, and to generate a range offluent semantically-equivalent alterna-tives, varying not only at the lexical andsyntactic levels, but also in documentstructure and layout.1 IntroductionMuch work on paraphrase generation has fo-cussed on lexical variation and syntactic trans-formation within individual sentences (Barzilayand McKeown, 2001; Carroll et al, 1999; Dras,1999; Inui and Nogami, 2001; Kozlowski et al,2003; Langkilde and Knight, 1998; Takahashiet al, 2001; Stede, 1999).
Our interest in thispaper lies instead with variations at the level oftext structuring ?
the way in which propositionsare grouped into units like paragraphs, sections,and bulletted lists, and linked rhetorically by dis-course connectives such as ?since?, ?nevertheless?,and ?however?.
Elsewhere, we have described atext-structuring method in which the options fororganising propositions in a text are laid out as aset of constraints, so that acceptable solutions canbe enumerated using constraint satisfaction andevaluated using a cost metric (Power et al, 2003).In this paper we show how this method, whenharnessed to a system for recognising rhetoricalstructure in an input text, can be employed in or-der to produce large-scale paraphrases fulfillingpurposes like improving coherence and achievinga desired style of layout.2 Text structureThe input to our text-structuring system (ICONO-CLAST) is a rhetorical structure tree (Mann andThompson, 1983) in which the leaves are elemen-tary propositions, specified either as semantic for-mulas or as canned text.
The following is a simpleexample, containing one nucleus-satellite relation(REASON) and one multinuclear relation (CON-JUNCTION1):reasonNUCLEUS: recommend(doctors, elixir)SATELLITE: conjunction1: quick-results(elixir)2: few-side-effects(elixir)Ignoring variations in the wording of proposi-tions, ICONOCLAST generates over 20 texts re-alising this input (or many more if a larger reper-toire of discourse connectives is allowed).
Theyinclude the following two solutions, which lie atstylistic extremes, the first compressing the mes-sage into a sentence (suitable if space is at a pre-mium), the second laying it out more expansivelyin a list:1This is the RST relation, LIST, which we have renamedhere to avoid possible confusion with the layout style of ver-tical lists.73Solution 1Doctors recommend Elixir since it gives quickresults and it has few side effects.Solution 2?
Elixir gives quick results.?
Elixir has few side effects.Therefore, it is recommended by doctors.Comparing these solutions illustrates some of thetext-structuring options, and some ways in whichthey interact.?
Propositions, or groups of propositions, canbe realised by different text categories.
Thusquick-results(elixir) is realisedby a text-phrase (in Nunberg?s sense (Nun-berg, 1990)) in Solution 1, and by a text-sentence (also a list item) in Solution 2.?
Rhetorical relations can be expressed by dif-ferent discourse connectives or layout op-tions.
In Solution 1, REASON is realised by?since?
and CONJUNCTION by ?and?
; in So-lution 2 REASON is realised by ?therefore?and CONJUNCTION (more implicitly) by abulletted list.?
Propositions may be realised in different or-ders: for instance, the nucleus of the REA-SON relation comes first in Solution 1, whilethe satellite comes first in Solution 2.
Notethat order is constrained by the choice ofdiscourse connective: ?therefore?
requiressatellite-first; ?since?
allows both orders.These text-structuring decisions strongly influ-ence the options for wording the individual propo-sitions, mostly because they determine the orderin which propositions are presented.
In Solution1, the nucleus of the REASON relation is presentedfirst, so ?Elixir?
has to be referenced by name, andthere is no particular reason for preferring passiveto active.
In Solution 2, the same proposition oc-curs at the end, when Elixir has been introducedand established as the topic focus; it is thereforeappropriate to refer to Elixir by a pronoun, and topromote this reference to the most salient positionin the clause by passivization.Text structuring is controlled by hard con-straints, which determine the set of solutions thatcan be generated, and by preferences (or soft con-straints), which allow a ranking of solutions frombest to worst.
The purpose of hard constraintsis to avoid solutions that are clearly anomalous,such as the following text in which the argumentsof the CONJUNCTION relation are separated, thusaltering the rhetorical interpretation:Since Elixir gives quick results doctors recom-mend it, and it has few side effects.A more marginal case is the following solution,in which the arguments of a nucleus-satellite re-lation are expressed as items in a bulletted list.In the default settings this is also considered ananomaly, since a bulletted list usually implies aparallelism among the items that is violated whenone argument dominates the other.?
Elixir gives quick results and hasfew side-effects.?
Therefore, it is recommended by doctors.The purpose of soft constraints is to representstylistic preferences.
These include general prin-ciples of prose quality that are likely to apply toany context, as well as preferences specificallylinked to the purpose of the text and the natureof the intended reader.
Here are four examplesof preferences supported in ICONOCLAST: wewould assume that the first two are general, thesecond two specific.?
Avoid single-sentence paragraphs Thiswould penalise a solution in which our ex-ample was laid out in two paragraphs, onefor satellite and one for nucleus.?
Avoid discontinuity of reference As Kibbleand Power (2004) have shown, centering cri-teria can be used to penalize solutions withrelatively many topic shifts.?
Avoid passivization In contexts requiringan informal, popular style, there might be astronger tendency to favour active over pas-sive.?
Avoid complex sentences For some con-texts we might prefer to penalize solutionsin which many propositions are presentedwithin the same sentence (e.g., Solution 1).All these preferences are implemented through acost metric.
To calculate the cost of a solution,74the program first recognizes all violations, thenmultiplies each by a weight representing its im-portance before summing to obtain a total score.During execution, the program can either enumer-ate all solutions, ranking them from low cost tohigh, or it can simply search for the best solutionusing branch-and-bound optimization.3 Controlling constraints andpreferencesICONOCLAST was originally developed as acomponent of a Natural Language Generationsystem.
It assumes that the propositional contentof the desired text is already formally encoded,along with a rhetorical-structure tree represent-ing the role of each proposition in the argument.The program can also be run on a simplified in-put in which propositions are replaced by cannedphrases; however, the quality in this case willobviously suffer, since referring expressions andclause structure cannot be adapted to context.
Byitself, then, ICONOCLAST cannot be used in or-der to paraphrase an independently provided text.However, once a semantic model is available, thesystem allows an unusual degree of flexibility andprecision in controlling paraphrases.
The sourceof this power lies in the use of explicitly encodedconstraints and preferences, which can be editedthrough a direct-manipulation user interface in or-der to guide the generator in the desired direc-tions.For hard constraints, the control interfaceworks mostly by buttons for switching constraintson and off, or occasionally by menus for fixingthe value of a parameter.
Examples of switchesare the following (also mentioned above):Allow indented list for arguments of amultinuclear relation (Yes/No)Allow indented list for arguments of anucleus-satellite relation (No/Yes)Allow discourse connective introducinga list item (Yes/No)The default in each case is the option given first,which would allow (but not require) a solutionto our example in which the conjunction was re-alised by a list including the discourse connective?and?
:Doctors recommend Elixir because?
Elixir gives quick results?
And it has few side effectsAn example of a parameter setting would be aconstraint fixing the textual unit governing thewhole text, or the maximum text level allowed foran indented list item:Root textual unit(document/section/paragraph/text-sentence)Maximum level for list item(paragraph/text-sentence/text-clause)By constraining the whole text to fit in a para-graph, we could eliminate any solution requiringmultiple paragraphs (e.g., nucleus in one para-graph and satellite in another).
Under this set-ting, both solutions 1 and 2 could be generated(although solution 1 would have to be a single-sentence paragraph).
Further constraining theroot level to sentence would preserve solution1 but eliminate solution 2.For soft constraints, the user interface worksthrough sliders representing both the direction ofa preference and its intensity.
In most cases, thesliders are calibrated to an 11-point scale from-5 to +5.
A straightforward example is the di-chotomy between active and passive voice, wherenegative values penalize use of the passive, whilepositive values penalize use of the active; thecentral value (zero) represents neutrality.
A costvalue is computed every time a proposition is re-alised by a clause for which the grammar allowspassivization.
Depending on the setting of the11-point scale, a cost is incurred either for useof the passive (negative values on the scale), orfor failure to use it (positive values on the scale);the amount of cost varies from 1 to 5, again de-pending on the setting.
Thus if the user sets thepassivization slider to a value of -4, a cost of 4accrues every time a proposition is realised by apassive clause; or for a value of +2, a cost of 2accrues every time a proposition that could havebeen realised by a passive clause is realised by anactive one.In practice, this method of evaluating solu-tions typically means that every solution is flawed,given a non-trivial semantic input and a suffi-cient range of preferences.
The reason is thatmany decisions are trade-offs: avoiding cost on75one preference often means incurring cost else-where.
For instance, a preference to avoid the pas-sive conflicts with the preference to preserve top-ical coherence, which is expressed by penalizinga ?salience violation?
?
that is, a failure to equatethe backward-looking center in a clause with themost salient forward-looking center (i.e., Cb withCp) (Kibble and Power, 2004).
If salience re-quires passivization, and passivization is penal-ized, then a cost must be incurred somewhere: theissue is which is the lesser evil.We have considered two ways of control-ling a paraphrase in a constraint-based gener-ator: imposing/relaxing a hard constraint, andchanging a preference.
A possibility thatwe have not yet implemented is a hard con-straint defined only on the current problem,as opposed to the general settings illustratedabove.
The constraint might state, for example,that the proposition recommend(doctors,elixir) should appear at the beginning of thetext, thus eliminating Solution 2.
Or it mightstate that the conjunction relation between theother propositions should be realised by a bullet-ted list, thus eliminating Solution 1.
To supportconstraints of this kind one would need a user in-terface in which the user can select part of thesemantic input, perhaps by clicking on the cor-responding part of the text, as in a WYSIWYMinterface (Power and Scott, 1998); a dialoguebox would then appear allowing a range of con-straints specifically directed to the selected frag-ment.
Such an interface would mimic the typicalinteraction between a human writer and humancritic ?
e.g., the critic might highlight a para-graph and advise the writer to reformat it as a list.4 Deriving the rhetorical-semantic inputWe have shown that by defining text-structuringas a Constraint Satisfaction Problem, our methodallows considerable flexibility and precision incontrolling the generation of paraphrases (Poweret al, 2003).
The question now is whether thesystem can be extended so that it accepts a text asinput, rather than a formally encoded rhetorical-semantic representation.
Obviously the extendedsystem will require an extra component perform-ing interpretation of the input text ?
but howmuch interpretation is needed in order to pro-vide an encoding that the current ICONOCLASTtext-structurer can use?
Can we extract suffi-cient rhetorical and referential information to al-low reasonable paraphrases, without dependingon a full semantic analysis of the original text?In this section we consider three stages of inter-pretation, which could be applied incrementally:1.
Rhetorical mark-up: The program marksup the EDUs (Elementary Discourse Units)(Marcu, 2000) in the input text ?
what wehave been calling the elementary proposi-tions ?
and also identifies the rhetoricalrelations among them, expressed through aRhetorical Structure Tree.
Within EDUsthere is no mark-up: at this stage they aretreated as canned strings.2.
Coreference mark-up: The program identi-fies noun-phrases referring to discourse en-tities, and recognises chains referring tothe same entity.
For each discourse entity,enough semantic information is recovered toallow a correct choice of pronoun (i.e., val-ues are assigned to features like NUMBER,GENDER, HUMAN), but no further semanticanalysis is assumed.3.
Clause transformations: The syntactic struc-ture of each EDU is analysed sufficiently toallow a reformulation that promotes a differ-ent discourse entity as the most salient of theclause (i.e., the Cp).
Typically this wouldmean a change of voice from active to pas-sive, or vice-versa, although there might beother variations like fronting that could beexplored.We now discuss these stages in turn.4.1 Recognising rhetorical structureMaintaining the same example, suppose that theinput text is the following (a slight variation ofSolution 1):Doctors recommend Elixir since it gives quickresults and has few side effects.The goal at this stage is to interpret this text asa set of elementary propositions, represented bycanned phrases, organised into a tree by rhetoricalrelations.
An example of the desired encoding, in76the format actually used as input to the currentsystem, is the following XML fragment:<RhetRep relation=reason><SemRep prop="doctors recommend Elixir"/><RhetRep relation=conjunction><SemRep prop="it gives quick results"/><SemRep prop="it has few side-effects"/></RhetRep></RhetRep>As can be seen, even though this representationprovides no analysis within propositions (EDUs),the task of deriving the rhetorical structure and thecanned phrases is not trivial.
First, the rhetoricalrelations REASON and CONJUNCTION must be in-ferred.
Second, the correct tree structure must beassigned, with REASON dominating CONJUNC-TION.
Third, the discourse connectives ?since?and ?and?
must be separated from the phrasesin which they occur ?
the aim is that thesephrases should represent only the propositions.Finally, where parts of a phrase have been elidedthrough aggregation (e.g., ?has few side-effects?
),the missing part (?it?)
should be found and re-placed.If this level of interpretation is achieved, theprogram will be able to generate several dozenparaphrases, but referential continuity will bepoor unless we pose the additional constraint thatthe order of propositions should remain the sameas in the original.
Thus a successful paraphrase,including some reformatting, would be the fol-lowing:Doctors recommend Elixir since:?
it gives quick results.?
it has few side effects.However, with satellite preceding nucleus, as inSolution 2, the text becomes incoherent becausethe first mentions of Elixir are through a pronoun.?
It gives quick results.?
It has few side effects.Therefore, doctors recommend Elixir.4.2 Recognising coreferenceIncoherence resulting from canned propositionscan be partly remedied if the analysis of the in-put text is taken a stage further, by recognisingsome simple semantic features on noun phrases,and marking them up for coreference.
The ele-mentary propositions in our example could for in-stance be marked up as follows:<edu><np id=1 phrase="doctors"class="human" number="plural"/>recommend<np id=2 phrase="Elixir"class="thing" number="singular"/></edu><edu><pronoun id=2 phrase="it"/>gives<np id=3 phrase="quick results"class="thing" number="plural"/></edu><edu><pronoun id=2 phrase="it"/>has<np id=4 phrase="few side-effects"class="thing" number="plural"/></edu>This further mark-up facilitates text-structuring intwo ways.
First, since centering information isnow available (the Cb and Cp of each proposi-tion can be computed), the evaluation of solu-tions can take account of the centering prefer-ences proposed by Kibble and Power (2004).
Sec-ondly, when realising individual propositions, thereferring expressions can be adapted to context,perhaps by replacing a name/description with apronoun, or even eliding it altogether when twopropositions are aggregated.
This means that theprogram will be able to generate solutions such asthe following, in which the wordings of the propo-sitions has been revised:Since Elixir gives quick results and has few side-effects, doctors recommend it.This solution illustrates three ways in of revisinga proposition:?
Pronoun ?
Name ?it gives quick results?becomes ?Elixir gives quick results?.?
Elision ?it has few side-effects?
becomes?has few side-effects?.?
Name ?
Pronoun ?doctors recommendElixir?
becomes ?doctors recommend it?.The generated paraphrases should now be morefluent, but the program is still limited by its inabil-ity to control the most salient referent in a propo-sition (i.e., to modify the Cp).
To add this op-tion, we need the third level of interpretation men-tioned above, in which the structure of a clausecan be transformed (e.g., from active to passive).774.3 Clause transformationsAssuming that the analysis program can com-pletely parse a clause identified as an EDU, it maybe able to apply a syntactic transformation whichexpresses the same proposition with changed in-formation focus.
An obviously useful transforma-tion is passivization ?
or its opposite if the orig-inal sentence is in the passive.
Assuming that theparser has correctly identified the main verb, andthat the program has access to a lexical databaseincluding irregular morphology, it could derivealternative formulations for the original proposi-tions by a rule such as the following:[NP1] recommends [NP2]?
[NP2] is recommended by [NP1]Of course the program should not allow suchtransformations for special verbs like ?be?
and?have?, so as to avoid clumsy renderings like ?fewside effects are had by Elixir?.
However, whenused on an appropriate verb, passivization can im-prove the fluency of the solution by promotingthe Cb of the proposition to the subject position,so that it becomes the Cp; revisions of this kindalso provide more opportunities for favourablepronominalization and elision.
With this extraresource, the solution just proposed can be im-proved as follows:Since Elixir gives quick results and has few side-effects, it is recommended by doctors.A more ambitious aim would be to transform be-tween finite and reduced forms of a subordinateclause.
For instance, if the original text is ?De-spite having few side-effects, Elixir is bannedby the FDA?, we could allow the transformationof ?having few side-effects?
into the finite clause?Elixir has few side-effects, borrowing the subjectand tense from the main clause.
This transforma-tion would enable the system to generate a solu-tion using a connective such as ?however?
whichrequires that full clauses are employed both forthe nucleus and the satellite.
Alternatively, a fi-nite clause could be transformed into the reducedform, so allowing the connective ?despite?.ConclusionIt is hard to conceive of an NLG system thatcannot produce alternative realisations, and thusparaphrases.
Most systems, however, are onlycapable of producing variations at the lexical orsyntactic levels (or both).
As such, they operatevery much like traditional Machine Translationsystems ?
except that the source and target textsare now in the same language ?
and have similarlimitations.
Additionally, most of them work withinput that is a representation of the meaning of a(source) text, rather than the text itself.The system described in this paper develops anexisting NLG system into a full-blown paraphasegenerator capable of producing a wide range ofalternative renditions of the source text, with vari-ations at three linguistic levels: lexical choice,syntactic structure, and document structure.
Thisis in contrast to most existing paraphrase gener-ators, which are constrained to vary only the firstor second of these levels (Barzilay and McKeown,2001; Carroll et al, 1999; Dras, 1999; Inui andNogami, 2001; Kozlowski et al, 2003; Langkildeand Knight, 1998; Takahashi et al, 2001; Stede,1999).
The range of lexical and syntactic varia-tion in a paraphrase generator obviously dependson how deeply the input text is interpreted, buteven with the relatively superficial analysis pro-posed here, we can introduce variations for dis-course connectives, referring expressions (in par-ticular, when to use pronouns), and some clausepatterns (e.g., whether to use active or passive).However, the innovation in our work lies in itscontrolled variation in the third level, documentstructure: just as the other paraphrase generatorsprovide multiple lexical-syntactic structures forthe same semantic structure, so our system pro-vides multiple document structures for the samediscourse structure (i.e., for the same rhetori-cal structure).
The document structure solutionsserve not only to realise the rhetorical input, butalso to create a context that determines which ofthe alternative syntactic realisations is most suit-able for the elementary propositions.Our paraphrase generator links an exist-ing general-purpose discourse parser ?
DAS(Le Thanh et al, 2004)2 ?
which builds a dis-course tree automatically from an input text, to anexisting NLG system ?ICONOCLAST (Poweret al, 2003) ?
which generates a wide range of2Similar parsers have been developed by Marcu (2000)and Corston-Oliver (1998)78formulations for a given discourse structure.
Wehave described here the issues that need to betaken into account when turning any NLG sys-tem into a fully-fledged paraphraser.
We believethat our approach to text-structuring, whereby op-tions for organising propositions in a text are laidout as a set of constraints, and acceptable solu-tions are enumerated using constraint satisfactionand evaluated using a cost metric, provides a par-ticularly useful method for achieving large-scaleparaphrases.
Although we are agnostic with re-spect to the issue of psychological validity, it isworth noting that our method reflects many ofthe processes facing any writer or editor trying toachieve their ideal text, but constrained by the lin-guistic resources at hand (e.g., wording, syntax,discourse and layout) which interact with eachother such that the final text is invariably a flawedversion of the ideal.For evaluation of our system, two points needto be addressed.
The first concerns fidelity: are thegenerated solutions equivalent in meaning to theoriginal input text?
The second concerns qual-ity: are the generated solutions ranked, by thecost metric, in a way that corresponds to the pref-erences of good judges?
More practically, wewould like to explore the issue of usability: themain question here is whether human users cansuccessfully manipulate the system?s constraintsand preferences in order to guide solutions in thedesired direction.ReferencesRegina Barzilay and Kathleen McKeown.
2001.
Ex-tracting paraphrases from a parallel corpus.
In Pro-ceedings of the 39th Annual Meeting of the Associ-ation for Computational Linguistics, pages 50?57,Toulouse.J.
Carroll, G. G. Minnen, D. Pearce, Y. Canning,S.
Devlin, and J. Tait.
1999.
Simplifying textfor language-impaired readers.
In Proceedings ofthe 9th Conference of the European Chapter of theAssociation for Computational Linguistics (EACL-99), pages 269?270, Bergen, Norway.S.
Corston-Oliver.
1998.
Computing Representationsof the Structure of Written Discourse.
Ph.D. thesis,University of California, Santa Barbara, CA, USA.Mark Dras.
1999.
Tree Adjoining Grammar and theReluctant Paraphrasing of Text.
Ph.D. thesis, Mac-quarie University, Australia.Kentaro Inui and Masaru Nogami.
2001.
Aparaphrase-based exploration of cohesiveness crite-ria.
In Proceedings of the 8th European Workshopon Natural Language Generation (EWNLG-01).Rodger Kibble and Richard Power.
2004.
Optimisingreferential coherence in text generation.
Computa-tional Linguistics, 30(4).Raymond Kozlowski, Kathleen F. McCoy, andK.
Vijay-Shanker.
2003.
Generation of single-sentence paraphrases from predicate/argumentstructure using lexico-grammatical resources.
InProceedings of the Second International Workshopon Paraphrasing, pages 1?8.Irene Langkilde and Kevin Knight.
1998.
Generationthat exploits corpus-based statistical knowledge.
InProceedings of the 17th International Conferenceon Computational Linguistics and the 36th AnnualMeeting of the Association for Computational Lin-guistics (COLING-ACL98), pages 704?710, Mon-treal.H.
Le Thanh, G. Abeysinghe, and C. Huyck.
2004.Generating discourse structures for written texts.In Proceedings of the 20th International Con-ference on Computational Linguistics (COLING-2004), pages 329?335.W.C Mann and S.A. Thompson.
1983.
Relationalpropositions in discourse.
Technical Report RR-83-115, Information Sciences Institute.D.
Marcu.
2000.
The theory and practice of dis-course parsing and summarisation.
MIT Press,Cambridge, Massachusetts, USA.Geoffrey Nunberg.
1990.
The Linguistics of Punctu-ation.
CSLI Lecture Notes, No.
18.
Center for theStudy of Language and Information, Stanford.Richard Power and Donia Scott.
1998.
Multilingualauthoring using feedback texts.
In Proceedings of17th International Conference on ComputationalLinguistics and 36th Annual Meeting of the Associ-ation for Computational Linguistics (COLING-ACL98), pages 1053?1059, Montreal, Canada.Richard Power, Donia Scott, and Nadjet Bouayad-Agha.
2003.
Document structure.
ComputationalLinguistics, 29(2):211?260.Manfred Stede.
1999.
Lexical semantics and knowl-edge representation in multilingual text genera-tion.
Kluwer Academic Publishers, Boston.Tetsuro Takahashi, Tomoyam Iwakura, Ryu Iida, At-sushi Fujita, and Kentaro Inui.
2001.
Kura: Atransfer- based lexico-structural paraphrasing en-gine.
In Proceedings of the Workshop on AutomaticParaphrasing.
(NLPRS 2001), Tokyo.79
