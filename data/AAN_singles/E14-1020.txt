Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 183?191,Gothenburg, Sweden, April 26-30 2014. c?2014 Association for Computational LinguisticsIncremental Query GenerationLaura Perez-BeltrachiniFaculty of Computer ScienceFree University of Bozen-BolzanoBozen-Bolzano, Italylaura.perez@loria.frClaire GardentCNRS/LORIANancy, Franceclaire.gardent@loria.frEnrico FranconiFaculty of Computer ScienceFree University of Bozen-BolzanoBozen-Bolzano, Italyfranconi@inf.unibz.itAbstractWe present a natural language genera-tion system which supports the incremen-tal specification of ontology-based queriesin natural language.
Our contribution istwo fold.
First, we introduce a chartbased surface realisation algorithm whichsupports the kind of incremental process-ing required by ontology-based querying.Crucially, this algorithm avoids confusingthe end user by preserving a consistentordering of the query elements through-out the incremental query formulation pro-cess.
Second, we show that grammarbased surface realisation better supportsthe generation of fluent, natural soundingqueries than previous template-based ap-proaches.1 IntroductionPrevious research has shown that formal ontolo-gies could be used as a means not only to providea uniform and flexible approach to integrating anddescribing heterogeneous data sources, but also tosupport the final user in querying them, thus im-proving the usability of the integrated system.
Tosupport the wide access to these data sources, it iscrucial to develop efficient and user-friendly waysto query them (Wache et al., 2001).In this paper, we present a Natural Language(NL) interface of an ontology-based query tool,called Quelo1, which allows the end user to for-mulate a query without any knowledge either ofthe formal languages used to specify ontologies, orof the content of the ontology being used.
Follow-ing the conceptual authoring approach describedin (Tennant et al., 1983; Hallett et al., 2007), thisinterface masks the composition of a formal query1krdbapp.inf.unibz.it:8080/queloas the composition of an English text describ-ing the equivalent information needs using natu-ral language generation techniques.
The naturallanguage generation system that we propose forQuelo?s NL interface departs from similar work(Hallett et al., 2007; Franconi et al., 2010a; Fran-coni et al., 2011b; Franconi et al., 2010b; Franconiet al., 2011a) in that it makes use of standard gram-mar based surface realisation techniques.
Our con-tribution is two fold.
First, we introduce a chartbased surface realisation algorithm which supportsthe kind of incremental processing required by on-tology driven query formulation.
Crucially, thisalgorithm avoids confusing the end user by pre-serving a consistent ordering of the query ele-ments throughout the incremental query formu-lation process.
Second, we show that grammarbased surface realisation better supports the gener-ation of fluent, natural sounding queries than pre-vious template-based approaches.The paper is structured as follows.
Section 2discusses related work and situates our approach.Section 3 describes the task being addressednamely, ontology driven query formulation.
It in-troduces the input being handled, the constraintsunder which generation operates and the opera-tions the user may perform to build her query.In Section 4, we present the generation algo-rithm used to support the verbalisation of possi-ble queries.
Section 5 reports on an evaluation ofthe system with respect to fluency, clarity, cover-age and incrementality.
Section 6 concludes withpointers for further research.2 Related WorkOur approach is related to two main strands ofwork: incremental generation and conceptual au-thoring.Incremental Generation (Oh and Rudnicky,2000) used an n-gram language model to stochas-183tically generate system turns.
The language modelis trained on a dialog corpus manually annotatedwith word and utterance classes.
The generationengine uses the appropriate language model forthe utterance class and generates word sequencesrandomly according to the language model distri-bution.
The generated word sequences are thenranked using a scoring mechanism and only thebest-scored utterance is kept.
The system is incre-mental is that each word class to be verbalised canyield a new set of utterance candidates.
Howeverit supports only addition not revisions.
Moreoverit requires domain specific training data and man-ual annotation while the approach we propose isunsupervised and generic to any ontology.
(Dethlefs et al., 2013) use Conditional RandomFields to find the best surface realisation from asemantic tree.
They show that the resulting sys-tem is able to modify generation results on the flywhen new or updated input is provided by the dia-log manager.
While their approach is fast to ex-ecute, it is limited to a restricted set of domainspecific attributes; requires a training corpus ofexample sentences to define the space of possi-ble surface realisations; and is based on a largeset (800 rules) of domain specific rules extractedsemi-automatically from the training corpus.
Incontrast, we use a general, small size grammar(around 50 rules) and a lexicon which is automat-ically derived from the input ontologies.
The re-sulting system requires no training and thus canbe applied to any ontology with any given signa-ture of concepts and relations.
Another differencebetween the two approaches concerns revisions:while our approach supports revisions anywherein the input, the CRF approach proposed by (Deth-lefs et al., 2013) only supports revisions occurringat the end of the generated string.There is also much work (Schlangen andSkantze, 2009; Schlangen et al., 2009) in the do-main of spoken dialog systems geared at mod-elling the incremental nature of dialog and in par-ticular, at developing dialog systems where pro-cessing starts before the input is complete.
In theseapproaches, the focus is on developing efficient ar-chitectures which support the timely interleavingof parsing and generation.
Instead, our aim is todevelop a principled approach to the incrementalgeneration of a user query which supports revisionand additions at arbitrary points of the query beingbuilt; generates natural sounding text; and maxi-mally preserves the linear order of the query.Conceptual authoring Our proposal is closelyrelated to the conceptual authoring approach de-scribed in (Hallett et al., 2007).
In this approach,a text generated from a knowledge base, describesin natural language the knowledge encoded so far,and the options for extending it.
Starting with aninitial very general query (e.g., all things), the usercan formulate a query by choosing between theseoptions.
Similarly, (Franconi et al., 2010a; Fran-coni et al., 2011b; Franconi et al., 2010b; Fran-coni et al., 2011a) describes a conceptual author-ing approach to querying semantic data where inaddition , logical inference is used to semanticallyconstrain the possible completions/revisions dis-played to the user.Our approach departs from this work in that itmakes use of standard grammars and algorithms.While previous work was based on procedures andtemplates, we rely on a Feature-Based Tree Ad-joining Grammar to capture the link between textand semantics required by conceptual authoring;and we adapt a chart based algorithm to supportthe addition, the revision and the substitution ofinput material.
To avoid confusing the user, weadditionally introduce a scoring function whichhelps preserve the linear order of the NL query.The generation system we present is in fact inte-grated in the Quelo interface developed by (Fran-coni et al., 2011a) and compared with their previ-ous template-based approach.3 Incremental Generation of CandidateQuery ExtensionsThe generation task we address is the following.Given a knowledge base K , some initial formalquery q and a focus point p in that query, the rea-soning services supported by Quelo?s query logicframework (see (Guagliardo, 2009)) will computea set of new queries rev(q) formed by adding,deleting and revising the current query q at pointp.
The task of the generator is then to producea natural language sentence for each new formalquery q?
?
rev(q) which results from this revisionprocess.
In other words, each time the user refinesa query q to produce a new query q?, the systemcomputes all revisions rev(q) of q?
that are com-patible with the underlying knowledge base usinga reasoner.
Each of these possible revisions is theninput to the generator and the resulting revised NLqueries are displayed to the user.
In what follows,184we assume that formal queries are represented us-ing Description Logics (Baader, 2003).The following examples show a possible se-quence of NL queries, their corresponding DL rep-resentation and the operations provided by Quelothat can be performed on a query (bold face is usedto indicate the point in the query at which the nextrevision takes place).
For instance, the query in(1c) results from adding the concept Y oung to thequery underlying (1b) at the point highlighted byman.
(1) a. I am looking for something (initial query)?b.
I am looking for a man (substitute con-cept)Manc.
I am looking for a young man (add com-patible concept)Man ?
Y oungd.
I am looking for a young man who ismarried to a person (add relation)Man?Y oung??isMarried.(Person)e.
I am looking for a young married man(substitute selection)MarriedMan ?
Y oungf.
I am looking for a married man (deleteconcept)MarriedMan4 Generating QueriesGeneration of KB queries differs from standardnatural language generation algorithms in twomain ways.
First it should support the revi-sions, deletions and additions required by incre-mental processing.
Second, to avoid confusingthe user, the revisions (modifications, extensions,deletions) performed by the user should have aminimal effect on the linear order of the NL query.That is the generator is not free to produce any NLvariant verbalising the query but should producea verbalisation that is linearly as close as possi-ble, modulo the revision applied by the user, to thequery before revisions.
Thus for instance, giventhe DL query (2) and assuming a linearisation ofthat formula that matches the linear order it is pre-sented in (see Section 4.2.1 below for a definitionof the linearisation of DL formulae), sentence (2b)will be preferred over (2c).
(2) a.
Car ?
?runOn.
(Diesel) ??equippedWith.(AirCond)b.
A car which runs on Diesel and isequipped with air conditioningc.
A car which is equipped with air condi-tioning and runs on DieselIn what follows, we describe the generation al-gorithm used to verbalise possible extensions ofuser queries as proposed by the Quelo tool.
Westart by introducing and motivating the underlyingformal language supported by Quelo and the inputto the generator.
We then describe the overall ar-chitecture of our generator.
Finally, we present theincremental surface realisation algorithm support-ing the verbalisation of the possible query exten-sions.4.1 The Input LanguageFollowing (Franconi et al., 2010a; Franconi et al.,2011b; Franconi et al., 2010b; Franconi et al.,2011a) we assume a formal language for queriesthat targets the querying of various knowledge anddata bases independent of their specification lan-guage.
To this end, it uses a minimal query lan-guage L that is shared by most knowledge repre-sentation languages and is supported by Descrip-tion Logic (DL) reasoners namely, the language oftree shaped conjunctive DL queries.
Let R be aset of relations and C be a set of concepts, then thelanguage of tree-shaped conjunctive DL queries isdefined as follows: S ::= C | ?R.
(S) | S ?
Swhere R ?
R, C ?
C, ?
denotes conjunction and?
is the existential quantifier.A tree shaped conjunctive DL query can be rep-resented as a tree where nodes are associated witha set of concept names (node labels) and edges arelabelled with a relation name (edge labels).
Figure1 shows some example query trees.4.2 NLG architectureOur generator takes as input two L formula: theformula representing the current query q and theformula representing a possible revision r (addi-tion/deletion/modification) of q.
Given this in-put, the system architecture follows a traditionalpipeline sequencing a document planner which (i)linearises the input query and (ii) partition the in-put into sentence size chunks; a surface realisermapping each sentence size L formula into a sen-tence; and a referring expression generator verbal-ising NPs.4.2.1 Document PlanningThe document planning module linearises the in-put query and segments the resulting linearised185x{Man}(a)xw{Man}{House}livesIn(b)xwz{Man}{House}livesIn{RichPerson}ownedBy(c)xwz{Man}{House,Beautiful}livesIn{RichPerson}ownedBy(d)???
?xywz{Man}{Person}{House,Beautiful}{RichPerson}marriedTo livesInownedBy(e)Figure 1: Example of query tree and incremental query construction.query into sentence size chunks.Query Linearisation Among the differentstrategies investigated in (Dongilli, 2008) tofind a good order for the content contained in aquery tree the depth-first planning, i.e.
depth-firsttraversal of the query tree, was found to be themost appropriate one.
Partly because it is obtainedstraightforward from the query tree but mostlydue to the fact that it minimizes the changes in thetext plan that are required by incremental querymodifications.
Thus, (Franconi et al., 2010a)defines a query linearisation as a strict total order2on the query tree that satisfies the followingconditions:?
all labels associated with the edge?s leavingnode precede the edge label?
the edge label is followed by at least one labelassociated with the edge?s arriving node?
between any two labels of a node there canonly be (distinct) labels of the same nodeThe specific linearisation adopted in Quelo isdefined by the depth-first traversal strategy of thequery tree and a total order on the children whichis based on the query operations.
That is, the la-bels of a node are ordered according to the se-quence applications of the add compatibleconcept operation.
The children of a node areinversely ordered according to the sequence of ap-plications of the add relation operation.According to this linearisation definition, forthe query tree (e) in Figure 1 the following linearorder is produced:(3) a.
Man marriedTo Person livesIn HouseBeautiful ownedBy RichPeron2A strict total order can be obtained by fixing an order inthe children nodes and traversing the tree according to sometree traversal strategy.Query Segmentation Given a linearised queryq, the document planner uses some heuristicsbased on the number and the types of rela-tions/concepts present in q to output a sequenceof sub-formulae each of which will be verbalisedas a sentence.4.2.2 Incremental Surface Realisation andLinearisation ConstraintsWe now describe the main module of the generatornamely the surface realiser which supports boththe incremental refinement of a query and a min-imal modification of the linear order between in-crements.
This surface realiser is caracterised bythe following three main features.Grammar-Based We use a symbolic, grammar-based approach rather than a statistical one for tworeasons.
First, there is no training corpus availablethat would consist of knowledge base queries andtheir increments.
Second, the approach must beportable and should apply to any knowledge baseindependent of the domain it covers and indepen-dent of the presence of a training corpus.
By com-bining a lexicon automatically extracted from theontology with a small grammar tailored to producenatural sounding queries, we provide a generatorwhich can effectively apply to any ontology with-out requiring the construction of a training corpus.Chart-Based A chart-based architecture en-hances efficiency by avoiding the recomputationof intermediate structures while allowing for anatural implementation of the revisions (addition,deletion, substitution) operations required by theincremental formulation of user queries.
We showhow the chart can be used to implement these op-erations.Beam search.
As already mentioned, for er-gonomic reasons, the linear order of the gener-ated NL query should be minimally disturbed dur-ing query formulation.
The generation system186should also be sufficiently fast to support a timelyMan/Machine interaction.
We use beam searchand a customised scoring function both to preservelinear order and to support efficiency.We now introduce each of these components inmore details.Feature-Based Tree Adjoining GrammarA tree adjoining grammar (TAG) is a tuple?
?, N, I,A, S?
with ?
a set of terminals, N a setof non-terminals, I a finite set of initial trees, A afinite set of auxiliary trees, and S a distinguishednon-terminal (S ?
N ).
Initial trees are treeswhose leaves are labeled with substitution nodes(marked with a down-arrow) or with terminalcategories3 .
Auxiliary trees are distinguished bya foot node (marked with a star) whose categorymust be the same as that of the root node.Two tree-composition operations are used tocombine trees: substitution and adjunction.
Sub-stitution inserts a tree onto a substitution node ofsome other tree while adjunction inserts an aux-iliary tree into a tree.
In a Feature-Based Lexi-calised TAG (FB-LTAG), tree nodes are further-more decorated with two feature structures whichare unified during derivation; and each tree is an-chored with a lexical item.
Figure 2 shows an ex-ample toy FB-LTAG with unification semantics.The dotted arrows indicate possible tree combina-tions (substitution for John, adjunction for often).As the trees are combined, the semantics is theunion of their semantics modulo unification.
Thusgiven the grammar and the derivation shown, thesemantics of John often runs is as shown namely,named(j john), run(a,j), often(a).NPjJohnl1:john(j)SbNP?c VPbaVarunslv:run(a,j)VPxoften VP*xlo:often(x)l1:named(j john), lv:run(a,j), lv:often(a)Figure 2: Derivation and Semantics for ?John often runs?Chart-Based Surface Realisation Given anFB-LTAG G of the type described above, sen-tences can be generated from semantic formulaeby (i) selecting all trees in G whose semantics sub-sumes part of the input formula and (ii) combining3For a more detailed introduction to TAG and FB-LTAG,see (Vijay-Shanker and Joshi, 1988).these trees using the FB-LTAG combining opera-tions namely substitution and adjunction.
Thus forinstance, in Figure 2, given the semantics l1:named(jjohn), lv:run(a,j), lv:often(a), the three trees shown areselected.
When combined they produce a com-plete phrase structure tree whose yield (John runsoften) is the generated sentence.Following (Gardent and Perez-Beltrachini,2011), we implement an Earley style generationalgorithm for FB-LTAG which makes use of thefact that the derivation trees of an FB-LTAG arecontext free and that an FB-LTAG can be con-verted to a a Feature-Based Regular Tree Gram-mar (FB-RTG) describing the derivation trees ofthis FB-LTAG4.On the one hand, this Earley algorithm en-hances efficiency in that (i) it avoids recomput-ing intermediate structures by storing them and(ii) it packs locally equivalent structures into asingle representative (the most general one).
Lo-cally equivalent structures are taken to be partialderivation trees with identical semantic coverageand similar combinatorics (same number and typeof substitution and adjunction requirements).On the other hand, it naturally supports therange of revisions required for the incremental for-mulation of ontology-based queries.
Let C be thecurrent chart i.e., the chart built when generating aNL query from the formal query.
Then additions,revisions and deletion can be handled as follows.?
Add concept or property X: the grammarunits selected by X are added to the agenda5and tried for combinations with the elementsof C .?
Substitute selection X with Y : all chart itemsderived from a grammar unit selected by anelement of X are removed from the chart.Conversely, all chart items derived from agrammar unit selected by an element of Y areadded to the agenda.
All items in the agendaare then processed until generation halts.?
Delete selection X: all chart items derivedfrom a grammar unit selected by an elementof X are removed from the chart.
Intermedi-ate structures that had previously used X aremoved to the agenda and the agenda is pro-cessed until generation halts.4For more details on this algorithm, we refer the reader to(Gardent and Perez-Beltrachini, 2010).5The agenda is a book keeping device which stores allitems that needs to be processed i.e., which need to be triedfor combination with elements in the chart.187Beam Search To enhance efficiency and favorthose structures which best preserve the word or-der while covering maximal input, we base ourbeam search on a scoring function combining lin-ear order and semantic coverage information.
Thisworks as follows.
First, we associate each literalin the input query with its positional informatione.g.,(4) a. man(x)[0] marriedTo(x y)[1]person(y)[2] livesIn(x w)[3]house(w)[4]This positional information is copied over toeach FB-LTAG tree selected by a given literal andis then used to compute a word order cost (Cwo)for each derived tree as follows:Cwo(ti+j) = Cwo(ti) + Cwo(tj) + Cwo(ti+ tj)That is the cost of a tree ti+jobtained by com-bining tiand tjis the sum of the cost of eachof these trees plus the cost incurred by combin-ing these two trees.
We define this latter cost tobe proportional to the distance separating the ac-tual position (api) of the tree (ti) being substi-tuted/adjoined in from its required position (rpi).If tiis substituted/adjoined at position n to theright (left) of the anchor of a tree tjwith posi-tion pj, then the actual position of tiis pj + n(pj ?
n) and the cost of combining tiwith tjis| pj + n ?
rpi| /?
(| pj ?
n ?
rpi| /?)
wherewe empirically determined ?
to be 1006.Finally, the total score of a tree reflects the rela-tion between the cost of the built tree, i.e.
its wordorder cost, and its semantic coverage, i.e.
nb.
ofliterals from the input semantics:S(ti) ={?
(|literals| ?
1) Cwo(ti) = 0Cwo(ti)/(|literals| ?
1) otherwiseThe total score is defined by cases.
Those treeswith Cwo= 0 get a negative value according totheir input coverage (i.e.
those that cover a largersubset of the input semantics are favored as thetrees in the agenda are ordered by increasing totalscore).
Conversely, those trees with Cwo> 0 geta score that is the word order cost proportional tothe covered input.In effect, this scoring mechanism favors treeswith low word order cost and large semantic cov-erage.
The beam search will select those trees withlowest score.6In the current implementation we assume that n = 1.Furthermore, as timight be a derived tree we also add toCwo(ti+ tj) the cost computed on each tree tkused in thederivation of tiwith respect to tj.4.2.3 Referring Expression GenerationThe referring expression (RE) module takes asinput the sequence of phrase structure trees out-put by the surface realiser and uses heuristics todecide for each NP whether it should be ver-balised as a pronoun, a definite or an indefiniteNP.
These heuristics are based on the linear orderand morpho-syntactic information contained in thephrase structure trees of the generated sentences.5 Experiments and evaluationWe conducted evaluation experiments designed toaddress the following questions:?
Does the scoring mechanism appropriatelycapture the ordering constraints on the gen-erated queries ?
That is, does it ensure thatthe generated queries respect the strict totalorder of the query tree linearisation ??
Does our grammar based approach producemore fluent and less ambiguous NL querythan the initial template based approach cur-rently used by Quelo ??
Does the automatic extraction of lexiconsfrom ontology support generic coverage ofarbitrary ontologies ?We start by describing the grammar used.
Wethen report on the results obtained for each of theseevaluation points.5.1 Grammar and LexiconWe specify an FB-LTAG with unification seman-tics which covers a set of basic constructions usedto formulate queries namely, active and passivetransitive verbs, adjectives, prepositional phrases,relative and elliptical clauses, gerund and partici-ple modifiers.
The resulting grammar consists of53 FB-LTAG pairs of syntactic trees and semanticschema.To ensure the appropriate syntax/semantic in-terface, we make explicit the arguments of arelation using the variables associated with thenodes of the query tree.
Thus for instance,given the rightmost query tree shown in Figure1, the flat semantics input to surface realisation is{Man(x), Person(y), House(w), Beautiful(w), RichPerson(z),marriedTo(x,y), livesIn(x,w), ownedBy(w,z)}.For each ontology, a lexicon mapping con-cepts and relations to FB-LTAG trees is automat-ically derived from the ontology using (Trevisan,2010)?s approach.
We specify for each experimentbelow, the size of the extracted lexicon.1885.2 LinearisationIn this first experiment, we manually examinedwhether the incremental algorithm we proposesupports the generation of NL queries whose wordorder matches the linearisation of the input querytree.We created four series of queries such that eachserie is a sequence q1.
.
.
qnwhere qi+1is an in-crement of qi.
That is, qi+1is derived from qiby adding, removing or substituting to qia con-cept or a relation.
The series were devised so as toencompass the whole range of possible operationsat different points of the preceding query (e.g., atthe last node/edge or on some node/edge occur-ring further to the left of the previous query); andinclude 14 revisions on 4 initial queries.For all queries, the word order of the best NLquery produced by the generator was found tomatch the linearisation of the DL query.5.3 Fluency and ClarityFollowing the so-called consensus model (Powerand Third, 2010), the current, template based ver-sion of Quelo generates one clause per relation7.Thus for instance, template-based Quelo will gen-erate (5a) while our grammar based approach sup-ports the generation of arguably more fluent sen-tences such as (5b).
(5) a. I am looking for a car.
Its make shouldbe a Land Rover.
The body style of thecar should be an off-road car.
The exteriorcolor of the car should be beige.b.
I am looking for car whose make is a LandRover, whose body style is an off-road carand whose exterior color is beige.We ran two experiments designed to assess howfluency impacts users.
The first experiment aimsto assess how Quelo template based queries areperceived by the users in terms of clarity and flu-ency, the second aims to compare these templatebased queries with the queries produced by ourgrammar-based approach.Assessing Quelo template-based queries Us-ing the Quelo interface, we generated a set of41 queries chosen to capture different combina-tions of concepts and relations.
Eight persons(four native speakers of English, four with C27This is modulo aggregation of relations.
Thus two sub-ject sharing relations may be realised in the same clause.level of competence for foreign learners of En-glish) were then asked to classify (a binary choice)each query in terms of clarity and fluency.
Fol-lowing (Kow and Belz, 2012), we take Fluencyto be a single quality criterion intended to cap-ture language quality as distinct from its meaning,i.e.
how well a piece of text reads.
In contrast,Clarity/ambiguity refers to ease of understanding(Is the sentence easy to understand?).
Taking theaverage of the majority vote, we found that thejudges evaluated the queries as non fluent in 50%of the cases and as unclear in 10% of the cases.In other words, template based queries were foundto be disfluent about half of the time and unclearto a lesser extent.
The major observation made bymost of the participants was that the generated textis too repetitive and lacks aggregation.Figure 3: Online Evaluation.Comparing template- and grammar-basedqueries In this second experiment, we asked 10persons (all proficient in the English language) tocompare pairs of NL queries where one query isproduced using templates and the other using ourgrammar-based generation algorithm.
The evalu-ation was done online using the LG-Eval toolkit(Kow and Belz, 2012) and geared to collect rel-ative quality judgements using visual analoguescales.
After logging in, judges were given a de-scription of the task.
The sentence pairs were dis-played as shown in Figure 3 with one sentence tothe left and the other to the right.
The judges wereinstructed to move the slider to the left to favorthe sentence shown on the left side of the screen;and to the right to favor the sentence appearing tothe right.
Not moving the slider means that bothsentences rank equally.
To avoid creating a bias,189the sentences from both systems were equally dis-tributed to both sides of the screen.For this experiment, we used 14 queries builtfrom two ontologies, an ontology on cars and theother on universities.
The extracted lexicons foreach of these ontology contained 465 and 297 en-tries respectively.The results indicate that the queries generatedby the grammar based approach are perceived asmore fluent than those produced by the templatebased approach (19.76 points in average for thegrammar based approach against 7.20 for the tem-plate based approach).
Furthermore, although thetemplate based queries are perceived as clearer(8.57 for Quelo, 6.87 for our approach), the dif-ference is not statistically significant (p < 0.5).Overall thus, the grammar based approach appearsto produce verbalisations that are better acceptedby the users.
Concerning clarity, we observed thatlonger sentences let through by document plan-ning were often deemed unclear.
In future work,we plan to improve clarity by better integratingdocument planning and sentence realisation.5.4 CoverageOne motivation for the symbolic based approachwas the lack of training corpus and the need forportability: the query interface should be usableindependently of the underlying ontology and ofthe existence of a training corpus.
To supportcoverage, we combined the grammar based ap-proach with a lexicon which is automatically ex-tracted from the ontology using the methodologydescribed in (Trevisan, 2010).
When tested ona corpus of 200 ontologies, this approach wasshown to be able to provide appropriate verbalisa-tion templates for about 85% of the relation iden-tifiers present in these ontologies.
12 000 relationidentifiers were extracted from the 200 ontologiesand 13 syntactic templates were found to be suf-ficient to verbalise these relation identifiers (see(Trevisan, 2010) for more details on this evalua-tion).That is, in general, the extracted lexicons permitcovering about 85% of the ontological data.
In ad-dition, we evaluated the coverage of our approachby running the generator on 40 queries generatedfrom five distinct ontologies.
The domains ob-served are cinema, wines, human abilities, dis-abilities, and assistive devices, e-commerce on theWeb, and a fishery database for observations aboutan aquatic resource.
The extracted lexicons con-tained in average 453 lexical entries and the cov-erage (proportion of DL queries for which the gen-erator produced a NL query) was 87%.Fuller coverage could be obtained by manuallyadding lexical entries, or by developing new waysof inducing lexical entries from ontologies (c.f.e.g.
(Walter et al., 2013)).6 ConclusionConceptual authoring (CA) allows the user toquery a knowledge base without having anyknowledge either of the formal representation lan-guage used to specify that knowledge base or ofthe content of the knowledge base.
Although thisapproach builds on a tight integration betweensyntax and semantics and requires an efficient pro-cessing of revisions, existing CA tools predomi-nantly make use of ad hoc generation algorithmsand restricted computational grammars (e.g., Def-inite Clause Grammars or templates).
In this pa-per, we have shown that FB-LTAG and chart basedsurface realisation provide a natural framework inwhich to implement conceptual authoring.
In par-ticular, we show that the chart based approach nat-urally supports the definition of an incremental al-gorithm for query verbalisation; and that the addedfluency provided by the grammar based approachpotentially provides for query interfaces that arebetter accepted by the human evaluators.In the future, we would like to investigate theinteraction between context, document structuringand surface realisation.
In our experiments wefound out that this interaction strongly impacts flu-ency whereby for instance, a complex sentencemight be perceived as more fluent than severalclauses but a too long sentence will be perceivedas difficult to read (non fluent).
Using data thatcan now be collected using our grammar basedapproach to query verbalisation and generalisingover FB-LTAG tree names rather than lemmas orPOS tags, we plan to explore how e.g., ConditionalRandom Fields can be used to model these inter-actions.AcknowledgmentsWe would like to thank Marco Trevisan, PaoloGuagliardo and Alexandre Denis for facilitatingthe access to the libraries they developed and toNatalia Korchagina and the judges who partici-pated in the evaluation experiments.190ReferencesFranz Baader.
2003.
The description logic handbook:theory, implementation, and applications.
Cam-bridge university press.Nina Dethlefs, Helen Hastie, Heriberto Cuaya?huitl, andOliver Lemon.
2013.
Conditional Random Fieldsfor Responsive Surface Realisation using GlobalFeatures.
Proceedings of ACL, Sofia, Bulgaria.Paolo Dongilli.
2008.
Natural language rendering of aconjunctive query.
KRDB Research Centre Techni-cal Report No.
KRDB08-3).
Bozen, IT: Free Univer-sity of Bozen-Bolzano, 2:5.E.
Franconi, P. Guagliardo, and M. Trevisan.
2010a.An intelligent query interface based on ontologynavigation.
In Workshop on Visual Interfaces to theSocial and Semantic Web, VISSW, volume 10.
Cite-seer.E.
Franconi, P. Guagliardo, and M. Trevisan.
2010b.Quelo: a NL-based intelligent query interface.
InPre-Proceedings of the Second Workshop on Con-trolled Natural Languages, volume 622.E.
Franconi, P. Guagliardo, S. Tessaris, and M. Tre-visan.
2011a.
A natural language ontology-drivenquery interface.
In 9th International Conference onTerminology and Artificial Intelligence, page 43.E.
Franconi, P. Guagliardo, M. Trevisan, and S. Tes-saris.
2011b.
Quelo: an Ontology-Driven QueryInterface.
In Description Logics.C.
Gardent and L. Perez-Beltrachini.
2010.
RTG basedSurface Realisation for TAG.
In COLING?10, Bei-jing, China.B.
Gottesman Gardent, C. and L. Perez-Beltrachini.2011.
Using regular tree grammar to enhance sur-face realisation.
Natural Language Engineering,17:185?201.
Special Issue on Finite State Methodsand Models in Natural Language Processing.Paolo Guagliardo.
2009.
Theoretical foundations ofan ontology-based visual tool for query formulationsupport.
Technical report, KRDB Research Centre,Free University of Bozen-Bolzano, October.C.
Hallett, D. Scott, and R. Power.
2007.
Composingquestions through conceptual authoring.
Computa-tional Linguistics, 33(1):105?133.Eric Kow and Anja Belz.
2012.
LG-Eval: A Toolkitfor Creating Online Language Evaluation Experi-ments.
In LREC, pages 4033?4037.Alice H Oh and Alexander I Rudnicky.
2000.
Stochas-tic language generation for spoken dialogue sys-tems.
In Proceedings of the 2000 ANLP/NAACLWorkshop on Conversational systems-Volume 3,pages 27?32.
Association for Computational Lin-guistics.R.
Power and A.
Third.
2010.
Expressing owl ax-ioms by english sentences: dubious in theory, fea-sible in practice.
In Proceedings of the 23rd Inter-national Conference on Computational Linguistics:Posters, pages 1006?1013.
Association for Compu-tational Linguistics.David Schlangen and Gabriel Skantze.
2009.
A gen-eral, abstract model of incremental dialogue pro-cessing.
In Proceedings of the 12th Conference ofthe European Chapter of the Association for Com-putational Linguistics, pages 710?718.
Associationfor Computational Linguistics.David Schlangen, Timo Baumann, and Michaela At-terer.
2009.
Incremental reference resolution: Thetask, metrics for evaluation, and a bayesian filteringmodel that is sensitive to disfluencies.
In Proceed-ings of the SIGDIAL 2009 Conference: The 10th An-nual Meeting of the Special Interest Group on Dis-course and Dialogue, pages 30?37.
Association forComputational Linguistics.H.
R Tennant, K. M Ross, R. M Saenz, C. W Thomp-son, and J. R Miller.
1983.
Menu-based natural lan-guage understanding.
In Proceedings of the 21st an-nual meeting on Association for Computational Lin-guistics, pages 151?158.
Association for Computa-tional Linguistics.Marco Trevisan.
2010.
A Portable Menuguided Nat-ural Language Interface to Knowledge Bases forQuerytool.
Ph.D. thesis, Masters thesis, Free Uni-versity of Bozen-Bolzano (Italy) and University ofGroningen (Netherlands).K.
Vijay-Shanker and A. Joshi.
1988.
Feature basedtags.
In Proceedings of the 12th International Con-ference of the Association for Computational Lin-guistics, pages 573?577, Budapest.Holger Wache, Thomas Voegele, Ubbo Visser, HeinerStuckenschmidt, Gerhard Schuster, Holger Neu-mann, and Sebastian Hu?bner.
2001.
Ontology-based integration of information-a survey of existingapproaches.
In IJCAI-01 workshop: ontologies andinformation sharing, volume 2001, pages 108?117.Citeseer.Sebastian Walter, Christina Unger, and Philipp Cimi-ano.
2013.
A corpus-based approach for the induc-tion of ontology lexica.
In Natural Language Pro-cessing and Information Systems, pages 102?113.Springer.191
