Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational NaturalLanguage Learning, pages 883?892, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational LinguisticsIdentifying Constant and Unique Relations by using Time-Series TextYohei Takaku?Toyo Keizai Inc.Chuo-ku, Tokyo 103-8345, Japantakaku.yohei@gmail.comNobuhiro Kaji and Naoki YoshinagaInstitute of Industrial Science,University of TokyoMeguro-ku, Tokyo 153-8505, Japan{kaji,ynaga}@tkl.iis.u-tokyo.ac.jpMasashi ToyodaInstitute of Industrial Science,University of TokyoMeguro-ku, Tokyo 153-8505, Japantoyoda@tkl.iis.u-tokyo.ac.jpAbstractBecause the real world evolves over time, nu-merous relations between entities written inpresently available texts are already obsoleteor will potentially evolve in the future.
Thisstudy aims at resolving the intricacy in con-sistently compiling relations extracted fromtext, and presents a method for identifyingconstancy and uniqueness of the relations inthe context of supervised learning.
We ex-ploit massive time-series web texts to inducefeatures on the basis of time-series frequencyand linguistic cues.
Experimental results con-firmed that the time-series frequency distribu-tions contributed much to the recall of con-stancy identification and the precision of theuniqueness identification.1 IntroductionWe have witnessed a number of success stories inacquiring semantic relations between entities fromever-increasing text on the web (Pantel and Pennac-chiotti, 2006; Banko et al2007; Suchanek et al2007; Wu et al2008; Zhu et al2009; Mintz et al2009; Wu and Weld, 2010).
These studies have suc-cessfully revealed to us millions of relations betweenreal-world entities, which have been proven to bebeneficial in solving knowledge-rich problems suchas question answering and textual entailment (Fer-rucci et al2010).
?This work was conducted while the first author was a grad-uate student at University of Tokyo.There exists, however, a great challenge to com-pile consistently relations extracted from text bythese methods, because they assume a simplifyingassumption that relations are time-invariant.
In otherwords, they implicitly disregard the fact that state-ments in texts actually reflect the state of the worldat the time when they were written, which followsthat relations extracted from such texts eventuallybecome outdated as the real world evolves over time.Let us consider that relations are extracted fromthe following sentences:1(1) a.
1Q84 is written by Haruki Murakami.b.
Moselle river flows through Germany.c.
U.S.?s president is George Bush.d.
Pentax sells K-5, a digital SLR.Here, italicized predicates represent the relations,while underlined entities are their arguments.
Therelations in statements 1a and 1b are true acrosstime, so we can simply accumulate all the relationinstances.
The relations in 1c and 1d in contrastevolve over time.
The relation written in 1c be-comes outdated when the other person takes theposition, so we need to supersede it when a newrelation is extracted from text (e.g., U.S?s presidentis Barack Obama).
For the relation in 1d, we do notalways need to supersede it with a new relation.This study is motivated from the above consider-1Since our task settings are language-independent, we here-after employ English examples as much as possible to widenthe potential readership of the paper, although we conductedexperiments with relations between entities in Japanese.883ations and proposes a method for identifying con-stancy and uniqueness of relations in order to se-lect an appropriate strategy to maintain relation in-stances extracted from text.
For example, the rela-tions written in statements 1a and 1b are constant,while those in 1c and 1d are non-constant; the re-lation in 1c is unique,2 whereas the relation in 1dis non-unique.
With these properties of relations inmind, we can accumulate constant relations whileappropriately superseding non-constant, unique re-lations with newly acquired relations.We locate each identification task in the contextof supervised classification.
The key challenge insolving these classification tasks is how to induce aneffective feature that identifies unique, non-constantrelations (statement 1c) that seemingly appear asnon-unique relations on text (statement 1b).
We ex-ploit massive time-series web text to observe actualevolutions of relation instances and induce featuresfrom the relation instances taken from a time slidingwindow and linguistic cues modifying the predicateand arguments of the target relation.We evaluated our method on 1000 relations ex-tracted from 6-year?s worth of Japanese blog postswith 2.3-billion sentences.
We have thereby con-firmed that the features induced from this time-seriestext contributed much to improve the classificationaccuracy.The main contributions of this paper are twofold:?
We have introduced a novel task for identify-ing constancy relations.
Since most of the ex-isting studies assume that relations are time-invariant as discussed by Weikum et al2011),non-constant relations prevalent in their out-come incur a serious problem in maintainingthe acquired relations.
The notion of constancyis meant to resolve this stalemate.?
We have for the first time demonstrated theusefulness of a time-series text in relation ac-quisition and confirmed its impact in the tworelation classification tasks.
The features in-duced from the time-series text have greatlycontributed to the accuracy of the classificationbased on uniqueness as well as the recall of theclassification based on constancy.2This kind of relation is referred to as functional relation inthe literature (Ritter et al2008; Lin et al2010).Constant Non-constantarg1 was born in arg2 arg1?s president is arg2arg1 is a father of arg2 arg1 belongs to arg2arg1 is written by arg2 arg1 lives in arg2Table 1: Examples of constant, non-constant relations.The reminder of this paper is structured as fol-lows.
Section 2 introduces the two properties ofrelations (constancy and uniqueness) and then de-fines the task setting of this study.
Sections 3 and 4describe the features induced from time-series textfor constancy and uniqueness classification, respec-tively.
Section 5 reports experimental results.
Sec-tion 6 addresses work related to this study.
Section 7concludes this study and mentions future work.2 Classification of Relations based onConstancy and Uniqueness2.1 Constancy and uniquenessWe introduce two properties of relations: constancyand uniqueness.A relation is constant if, for most values of arg1,the value of arg2 is independent of time (Table 1).For example, ?arg1 was born in arg2?
is a constantrelation since one?s birthplace never changes.
On theother hand, ?arg1 ?s president is arg2?
is an exampleof non-constant relations.
This can be checked bynoting that, for example, the president of the UnitedStates was Barack Obama in 2011 but was previ-ously George Bush and Bill Clinton before him.A relation is unique if, for most values of arg1,there exists, at any given point in time, only onevalue of arg2 that satisfies the relation (Table 2).
Forexample, ?arg1 was born in arg2?
is obviously aunique relation.
The relation ?arg1 is headquarteredin arg2?
is also unique, while it is non-constant.
No-tice that there is usually only one headquarters at anypoint in time, although the location of a headquarterscan change.
In contrast, the relation ?arg1 is fundedby arg2?
is a non-unique relation since it is likelythat there exist more than one funder.2.2 DiscussionBoth constancy and uniqueness are properties thatusually, not always, hold for most, not all, of thearg1?s values.
To see this, let us examine the relation?arg1 ?s president is arg2?.
Although this relation is884Unique Non-uniquearg1 was born in arg2 arg1 is funded by arg2arg1 is headquartered in arg2 arg1 consists of arg2arg1?s president is arg2 arg1 borders on arg2Table 2: Examples of unique and non-unique relations.non-constant and unique (Table 1 and 2), it is stillpossible to find exceptional cases.
For example, acountry might exist in which the president has neverchanged; a country might have more than one pres-ident at the same time during civil war.
However,since such situations are rare, the relation ?arg1 ?spresident is arg2?
is considered as neither constantnor non-unique.The above discussion implies that the constancyand uniqueness of relations can not be determinedcompletely objectively.
We, nevertheless, claim thatthese properties of relations are intuitively accept-able and thus they can be identified with moderateagreement by different people (see section 5).2.3 Task and our approachThis paper explores classifying given relations onthe basis of constancy and uniqueness.
We treatthe problem as two independent binary classificationtasks, and train supervised classifiers.The technical challenge we address in this paperis how to design features for the two tasks.
Section3 presents features based on time-series frequencyand linguistic cues for classifying constant and non-constant relations.
Similarly, section 4 presentsanalogous features for classifying unique and non-unique relations.3 Features for Constancy Classification3.1 Time-series frequencyIt is intuitive to identify constant relations by com-paring frequency distributions over arg2 in differenttime periods.
This idea leads us to use frequencyestimates from time-series text as features.Time-series text For a time-series text, we usedJapanese blog posts that had been gathered fromFeb.
2006 to Sep. 2011 (68 months).
These data in-clude 2.3 billions of sentences.
These posts were ag-gregated on a monthly basis by using time stamps at-tached with them, i.e., the unit of time is one month024681012Mar-08 Sep-08 Mar-09 Sep-09 Mar-10 Sep-10 Mar-11 Sep-11FrequencyPAO ChelseaChairman Haiberuden Luzhniki StadiumDutch league ItalyVVV VVV VenloCSKA MoscowFigure 1: Time-series frequency distribution of ?arg1 be-longs to arg2?
when arg1 takes Keisuke Honda.in our corpus.Basic idea For constant relations (e.g., ?arg1 wasborn in arg2?
), we can expect that the frequency dis-tributions over arg2 for a given arg1 (e.g., Mozart)are similar to each other irrespective of the time win-dows that are used to estimate frequency.In the case of non-constant relations (e.g., ?arg1belongs to arg2?
), on the other hand, the frequencydistributions over arg2 for a given arg1 significantlydiffer depending on the time window.
For exam-ple, Figure 1 illustrates the frequency distributionsof arg2s for ?arg1 belongs to arg2?
in which arg1takes Keisuke Honda, a famous football player.
Wecan clearly observe that due to Keisuke Honda beingsold from VVV Venlo to CSKA Moscow, the distri-butions differ greatly between 2008 and 2010.As is evident from the above discussions, the sta-bility/change in the distribution over arg2 is a goodindicator of constant/non-constant relations.
Thefollowing subsection addresses how to encode suchinformation as features.Feature computation Let us examine using asfeatures the cosine similarity between frequency dis-tributions over arg2.
Averaging such similaritiesover representative values of arg1, we have1N?e?EN (r)cos(Fw1(r, e), Fw2(r, e)),where r is a relation (e.g., ?arg1 ?s president isarg2?
), e is a named entity (e.g., United States) ap-pearing in arg1, and Fw(r, e) is the frequency distri-bution over arg2 when arg1 takes e. The subscripts885w1 and w2 denote the time window (e.g., from Jan.2011 to Feb. 2011) used to estimate the frequencydistribution.
EN (r) denotes a set of top N frequententities appearing in arg1.
We use the entire time-series text to obtain EN (r).Unfortunately, this idea is not suitable for our pur-pose.
The problem is that it is not clear how to deter-mine the two time windows, w1 and w2.
To identifynon-constant relations, arg2 must have different val-ues in the two time periods.
Such time windows are,however, impossible to know of in advance.We propose avoiding this difficulty by using av-erage, maximum and minimum similarity over allpossible time windows:1N?e?EN (r)avew1,w2?WTcos(Fw1(r, e), Fw2(r, e)),1N?e?EN (r)maxw1,w2?WTcos(Fw1(r, e), Fw2(r, e)),1N?e?EN (r)minw1,w2?WTcos(Fw1(r, e), Fw2(r, e)),where WT is a set of all time windows of the sizeT .
For example, if we set T to 3 (months) in the68-month?s worth of blog posts, WT consists of 66(= 68?3+1) time windows.
Although we still haveto specify the number of entities N and the windowsize T , this is not a serious problem in practice.
Weset N to 100.
We use four window sizes (1, 3, 6, and12 months) and induce different features for eachwindow size.
As a result, we have 12 real-valuedfeatures.3.2 Linguistic cuesThis subsection presents two types of linguistically-motivated features for discriminating between con-stant and non-constant relations.Nominal modifiers We observe that non-constantrelations could be indicated by some nominal modi-fiers:(2) a. George Bush, ex-president of USA.b.
Lincoln is the first president of the USA.The use of the prefix ex- and the adjective first im-plies that the president changes, and hence the rela-tion ?arg1 ?s president is arg2?
is not constant.?
(ex-),?
(present),??
(next),?
(former),?
(new),?
(old),??
(successive),??
(first),?
(first)Table 3: Japanese prefixes and adjectives indicating non-constant relations.
The translations are provided in theparentheses.We propose making use of such modifiers as fea-tures.
Although the above examples are in English,we think modifiers also exist that have similar mean-ings in other languages including Japanese, our tar-get language.Our new features are induced as follows:?
First, we manually list eight nominal modifiersthat indicate the non-constancy (Table 3).?
Next, we extract nouns from a relation tobe classified (e.g., president), and count thefrequency with which each modifier modifiesthose nouns.
We use the same blog posts as insection 3.1 for counting the frequency.
Sincetime information is not important in this case,the frequency is simply accumulated over theentire time span.?
We then generate eight features, one for each ofthe eight modifiers.
The value of the featuresis one if the frequency exceeds threshold ?1,3otherwise it is zero.
Note that the value of thisfeature is always zero if the relation includes nonouns.Tense and aspect Tense and aspect of verbs arealso important indicators of the non-constancy:(3) The U.S. president was George Bush.If a relation, such as ?arg1 ?s president is arg2?, canoften be rephrased in the past tense as in (3), it islikely to be, if not always, a non-constant relation.It is, fortunately, straightforward to recognizetense and aspect in Japanese, because they are ex-pressed by attaching suffixes to verbs.
In this study,we use three common suffixes: ??
?, ????
?, and????.
The first suffix expresses past tense, whilethe other two express present continuous or progres-sive aspects depending on context.3?1 = 10 in our experiment.886A given relation is transformed into differentforms by attaching the suffixes to a verb in the rela-tion, and their frequencies are counted.
By using thefrequency estimates, we generate three new features,each of which corresponds to one of the three suf-fixes.
The value of the new features is one if the fre-quency exceeds threshold ?2,4 otherwise it is zero.The frequency is counted in the same way as inthe case of the nominal modifiers.
The value ofthis feature is always zero if the relation includes noverbs.4 Features for Uniqueness ClassificationThis section provides features for identifying uniquerelations.
These features are also based on the time-series text and linguistic cues, as in the case of con-stancy classification.4.1 Time-series frequencyNumber of entity types A straightforward ap-proach to identifying unique relations is, for a givenarg1, to count the number of entity types appear-ing in arg2 (Lin et al2010).
For unique relations,the number of entity types should be one in an idealnoiseless situation.
Even if the estimate is contam-inated by noise, a small number of entity types canstill be considered to indicate the uniqueness of therelation.A shortcoming of such a simple approach is thatit never considers the (non-)constancy of relations.Presume counting the number of entity types in arg2of the relation ?arg1 is headquartered in arg2?,which is non-constant and unique.
If we use largesize of time window to obtain counts, we will ob-serve multiple types of entities in arg2, not becausethe relation is non-unique, but because it is non-constant.
This problem cannot be resolved by triv-ially using very small windows, since a time win-dow that is too small in turn causes a data sparsenessproblem.This problem is attributed to the difficulty in de-termining the appropriate size of the time window.We tackle this problem by using the same techniquepresented in section 3.1.
Specifically, we use the fol-4?2 = 3000 in our experiment.lowing three measures as features:1N?e?EN (r)avew?WT#type(Fw(r, e)),1N?e?EN (r)maxw?WT#type(Fw(r, e)),1N?e?EN (r)minw?WT#type(Fw(r, e)),where the function #type(?)
denotes the number ofentity types appearing in arg2.Ratio of entity frequency Since it is not reliableenough to use only the number of entity types, wealso exploit the frequency of the entity.
Let e1st ande2nd be the most and the second most frequent enti-ties found in arg2.
If the frequency of e1st is muchlarger than that of e2nd, the relation is likely to beconstant.To encode this intuition, the following measuresare used as features:1N?e?EN (r)avew?WTfw(e, r, e1st)fw(e, r, e2nd)1N?e?EN (r)maxw?WTfw(e, r, e1st)fw(e, r, e2nd)1N?e?EN (r)minw?WTfw(e, r, e1st)fw(e, r, e2nd)where the fw(e, r, e?)
is the frequency of the relationr in which arg1 and arg2 take e and e?, respectively.The subscript w denotes the time window.4.2 Linguistic cuesCoordination structures and some keywords indicatenon-unique relations:(4) a. France borders on Italy and Spain.b.
France borders on Italy etc.The coordination structure in the first example im-plies an entity can border on more than one entity,and hence the relation ?arg1 borders on arg2?
is notunique.
The keyword etc.
in the second example alsoindicates the non-uniqueness.887?,??,?,??,??,?
?,?Table 4: List of Japanese particles that are used to formcoordination structures.To capture this intuition, we introduce two typesof linguistic features for classifying unique and non-unique relations.
The first feature checks whetherentities in arg2 form coordination structures.
Thefeature is fired if the number of times that coordina-tion structures are found in arg2 exceeds threshold?3.5 Coordination structures are identified by a listof Japanese particles, which roughly correspond toand or or in English (Table 4).
If two entities areconnected by one of those particles, they are seen asforming a coordination structure.The second feature exploits such keywords as etc.for identifying non-unique relations.
We list fourJapanese keywords that have similar meaning to theEnglish word etc., and induce another binary fea-ture6.
The feature is fired if the number of times thatan entity in arg2 is followed by one of the four key-words exceeds threshold ?3.5 Experiments and discussionsWe built labeled data and examine the classificationperformance of the proposed method.
We also an-alyzed the influence of window size T on the per-formance, as well as major errors caused by ourmethod.5.1 DataWe built a dataset for evaluation by extracting rela-tions from the time-series text (section 3.1) and thenmanually annotating 1000 relations.
The detailedprocedure is as follows.First, we parsed the time-series text and extractedas relation dependency paths connecting two namedentities.
We used J.DepP,7 an efficient shift-reduceparser with feature sequence trie (Yoshinaga andKitsuregawa, 2009; Yoshinaga and Kitsuregawa,2010), for parsing.
All Japanese words that conju-gate were normalized into standard forms.5?3 = 10 in our experiment.6The keywords we used are?,?,?
?, and?.7http://www.tkl.iis.u-tokyo.ac.jp/?ynaga/jdepp/00.20.40.60.81.00 0.2 0.4 0.6 0.8 1.0PrecisionRecallProposedBaselineFigure 2: Recall-precision curve (constancy classifica-tion).Then, annotators were asked to label 1000 rela-tions as not only constant or non-constant but alsounique or non-unique.
Three annotators were as-signed to each relation, and the goldstandard labelis determined by majority vote.
The Fleiss kappa(Fleiss, 1971) was 0.346 for constancy classificationand was 0.428 for uniqueness classification.
Theyindicate fair and moderate agreement, respectively(Landis and Koch, 1977).We have briefly investigated the relations whoselabels assigned by the annotators conflicted.
Themajor cause was that the annotators sometimes as-sumed different types of named entities as valuesof arguments.
A typical case in which this problemarises is that the relation has polysemous meanings,e.g., ?arg1 was born in arg2?, or a vague meaning,e.g., ?arg1makes arg2?.
For example, arg2 of ?arg1was born in arg2?
can be filled with different typesof entities such as date and place.
We can addressthis problem by typing arguments (Lin et al2010).5.2 ResultUsing the dataset, we performed 5-fold cross-validation for both classification tasks.
We usedthe passive-aggressive algorithm for our classifier(Crammer et al2006).Constancy classification Figure 2 illustrates therecall-precision curve in constancy classification.Because we are unaware of any previous methodsfor classifying constant and non-constant relations,a simple method based on the cosine similarity was88800.20.40.60.81.00 0.2 0.4 0.6 0.8 1.0PrecisionRecallProposedBaselineFigure 3: Recall-precision curve (uniqueness classifica-tion).used as a baseline:1N?e?EN (r)cos(Fw1(r, e), Fw2(r, e)),where the time windows w1 and w2 are determinedas the first and last month in which the relation ris observed.
A given relation is classified as non-constant if the above similarity exceeds a threshold.The recall-precision curve was drawn by changingthe threshold.The results demonstrated that our method outper-forms the baseline.
This indicates the effectivenessof using time-series frequency and linguistic cues asfeatures.The poor performance of the baseline was mainlydue to data sparseness.
Since the baseline method isdependent on the frequency estimates obtained fromonly two months of texts, it is less reliable than theproposed method.Uniqueness classification Figure 3 illustrates therecall-precision curve in uniqueness classification.As a baseline we implemented the method proposedby Lin et al2010).
While they have presentedthree methods (KLFUNC, KLDIFF, and their aver-age), we report the results of the last one because itperformed the best among the three in our experi-ment.From the figure, we can again see that the pro-posed method outperforms the baseline method.Lin?s method is similar to ours, but differs in thatthey do not exploit time-series information at all.00.20.40.60.81.00 0.2 0.4 0.6 0.8 1.0PrecisionRecallN = 2N = 10N = 20N = 100Figure 4: Comparison with the methods varying a valueof N for constancy classification.00.20.40.60.81.00 0.2 0.4 0.6 0.8 1.0PrecisionRecallN = 2N = 10N = 20N = 100Figure 5: Comparison with the methods varying a valueof N for uniqueness classification.We hence conclude time-series information is use-ful for classifying not only constant but also uniquerelations.5.3 Investigation into the number of entities, NWe ranged the value of N in {2, 10, 20, 100}.
Set-ting N to a larger value yields the better recall forconstancy classification and the better precision foruniqueness classification (Figures 4 and 5).
Theseresults meet our expectations, since features derivedfrom frequency distributions of arg2 over variousarg1s capture the generic nature of the target rela-tion.88900.20.40.60.81.00 0.2 0.4 0.6 0.8 1.0PrecisionRecallT = 1, 3, 6, 12T = 1T = 3T = 6T = 12Figure 6: Comparison with the methods using only a sin-gle value of T for constancy classification.00.20.40.60.81.00 0.2 0.4 0.6 0.8 1.0PrecisionRecallT = 1, 3, 6, 12T = 1T = 3T = 6T = 12Figure 7: Comparison with the methods using only a sin-gle value of T for uniqueness classification.5.4 Investigation into the window size, TOur method uses multiple time windows of differentsizes (i.e., different values of T ) to induce features,as detailed in sections 3.1 and 4.1.
To confirm theeffect of this technique, we investigated the perfor-mance when we use only a single value of T (Fig-ures 6 and 7).The results in the uniqueness classification taskdemonstrated that our method achieves better over-all results than the methods using a single value ofT .
We can therefore consider that using multiplevalues of T as features is a reasonable strategy.
Onthe other hand, we could not confirm the effect ofusing multiple time windows of different sizes in theconstancy classification task.5.5 Error analysisWe randomly selected and analyzed 200 misclassi-fied relations for both tasks.
The analysis revealedfour types of errors.Paraphrases We observed that constant relationsare prone to be miss-classified as non-constant whenmore than one paraphrase appear in arg2 and thusthe value of arg2 is pretended to change.
For exam-ple, America was also referred to as USA or UnitedStates of America.
A similar problem was observedfor unique relations as well.Topical bias Topics mentioned in the blog postsare sometimes biased, and such bias can have a neg-ative effect on classification, especially when a rela-tion takes a small number of entity types in arg2 forgiven arg1.
For example, Jaden Smith, who is oneof Will Smith?s sons, is frequently mentioned in ourtime-series text because he co-starred with his fatherin a movie, while Will Smith?s other sons never ap-peared in our text.
We consider this a possible rea-son for our method wrongly identifying ?arg1 ?s sonis arg2?
as a unique relation.Short-/Long-term evolution Since we have ag-gregated on a monthly basis the 6-year?s worth ofblog posts, the induced features cannot capture evo-lutions that occur in shorter or longer intervals.
Forexample, consider relation ?arg1 beats arg2?
tak-ing Real Madrid as arg1.
Since Real Madrid usuallyhave more than one football match in a month, theycan beat several teams in a month, which misleadsthe classifier to recognize the relation as non-unique.Similarly when a relation takes more than 6 years toevolve, it will be regarded as constant.Reference to past, future, or speculative factsThe blog authors sometimes refer to relations that donot occur around when they write their posts; suchrelations actually occurred in the past, will occur inthe future, or even speculative.
Since our methodexploits the time stamps attached to the posts to as-sociate the relations with time, those relations in-troduce noises in the frequency distributions.
Al-though our robust feature induction could in mostcases avoid an adverse effect caused by these noises,they sometimes leaded to misclassification.8906 Related WorkIn recent years, much attention has been given toextracting relations from a massive amount of tex-tual data, especially the web (cf.
section 1).
Most ofthose studies, however, explored just extracting re-lations from text.
Only a few studies, as describedbelow, have discussed classifying those relations.There has been no previous work on identify-ing the constancy of relations.
The most relevantresearch topic is the temporal information extrac-tion (Verhagen et al2007; Verhagen et al2010;Ling and Weld, 2010; Wang et al2010; Hovy etal., 2012).
This is the task of extracting from textualdata an event and the time it happened, e.g., Othellowas written by Shakespeare in 1602.
Such tempo-ral information alone is not sufficient for identifyingthe constancy of relations, while we think it wouldbe helpful.On the other hand, the uniqueness of relations hasso far been discussed in some studies.
Ritter et al(2008) have pointed out the importance of identi-fying unique relations for various NLP tasks suchas contradiction detection, quantifier scope disam-biguation, and synonym resolution.
They proposedan EM-style algorithm for scoring the uniquenessof relations.
Lin et al2010) also proposed threealgorithms for identifying unique relations.
Whilethose studies discussed the same problem as this pa-per, they did not point out the importance of theconstancy in identifying unique relations (cf.
sec-tion 4.1).7 ConclusionThis paper discussed that the notion of constancyis essential in compiling relations between enti-ties extracted from real-world text and proposed amethod for classifying relations on the basis of con-stancy and uniqueness.
The time-series web textwas fully exploited to induce frequency-based fea-tures from time-series frequency distribution on re-lation instances as well as language-based featurestailored for individual classification tasks.
Exper-imental results confirmed that the frequency-basedfeatures contributed much to the precision and recallin both identification tasks.We will utilize the identified properties of the re-lations to adopt an appropriate strategy to compiletheir instances.
We also plan to start a spin-off re-search that acquires paraphrases by grouping valuesof arg2s for each value of arg1 in a constant, uniquerelation.We consider that the notion of constancy will evenbe beneficial in acquiring world knowledge, otherthan relations between entities, from text; we aimat extending the notion of constancy to other typesof knowledge involving real-world entities, such asconcept-instance relations.AcknowledgmentsThis work was supported by the Multimedia WebAnalysis Framework towards Development of So-cial Analysis Software program of the Ministry ofEducation, Culture, Sports, Science and Technol-ogy, Japan.
The authors thank the annotators fortheir hard work.
The authors are also indebted to thethree anonymous reviewers for their valuable com-ments.ReferencesMichele Banko, Michael J. Cafarella, Stephen Soderland,Matt Broadhead, and Oren Etzioni.
2007.
Open in-formation extraction from the web.
In Proceedings ofIJCAI, pages 2670?2676.Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-Shawartz, and Yoram Singer.
2006.
Online passive-aggressive algorithms.
Journal of Machine LearningResearch, 7:551?583.David Ferrucci, Eric Brown, Jennifer Chu-Carroll, JamesFan, David Gondek, Aditya A. Kalyanpur, AdamLally, J. William Murdock, Eric Nyberg, John Prager,Nico Schlaefer, and Chris Welty.
2010.
Building Wat-son: An overview of the DeepQA project.
AI Maga-zine, 31(3):59?79.Joseph L. Fleiss.
1971.
Measuring nominal scale agree-ment among many raters.
Psychological Bulletin,76(5):378?382.Dirk Hovy, James Fan, Alfio Gliozzo, Siddharth Patward-han, and Christopher Welty.
2012.
When did that hap-pen?
?
linking events and relations to timestamps.
InProceedings of EACL, pages 185?193.Richard J. Landis and Gary G. Koch.
1977.
The mea-surement of observer agreement for categorical data.Biometrics, 1(33):159?174.Thomas Lin, Mausam, and Oren Etzioni.
2010.
Identify-ing functional relation in web text.
In Proceedings ofEMNLP, pages 1266?1276.891Xiao Ling and Daniel S. Weld.
2010.
Temporal informa-tion extraction.
In Proceedings of AAAI, pages 1385?1390.Mike Mintz, Steven Bills, Rion Snow, and Dan Juraf-sky.
2009.
Distant supervision for relation extractionwithout labeled data.
In Proceedings of ACL-IJCNLP,pages 1003?1011.Patrick Pantel and Marco Pennacchiotti.
2006.
Espresso:Leveraging generic patterns for automatically harvest-ing semantic relations.
In Proceedings of ACL, pages113?120.Alan Ritter, Doug Downey, Stephen Soderland, and OrenEtzioni.
2008.
It?s a contradiction?no, it?s not: Acase study using functional relations.
In Proceedingsof EMNLP, pages 11?20.Fabian M. Suchanek, Gjergji Kasneci, and GerhardWeikum.
2007.
YAGO: A core of semantic knowl-edge unifying WordNet and Wikipedia.
In Proceed-ings of WWW, pages 697?706.Marc Verhagen, Robert Gaizauskas, Frank Schilder,Mark Hepple, Graham Katz, and James Pustejovsky.2007.
SemEval-2007 task 15: TempEval temporalrelation identification.
In Proceedings of SemEval,pages 75?80.Marc Verhagen, Roser Sauri, Tommaso Caselli, andJames Pustejovsky.
2010.
SemEval-2010 task 13:TempEval-2.
In Proceedings of SemEval, pages 57?62.Yafang Wang, Mingjie Zhu, Lizhen Qu, Marc Spaniol,and Gerhard Weikum.
2010.
Timely YAGO: har-vesting, querying, and visualizing temporal knowledgefrom Wikipedia.
In Proceedings of EDBT, pages 697?700.Gerhard Weikum, Srikanta Bedathur, and Ralf Schenkel.2011.
Temporal knowledge for timely intelligence.
InProceedings of BIRTE, pages 1?6.Fei Wu and Daniel S. Weld.
2010.
Open informationextraction using Wikipedia.
In Proceedings of ACL,pages 118?127.Fei Wu, Raphael Hoffmann, and Daniel S. Weld.
2008.Information extraction from Wikipedia: moving downthe long tail.
In Proceedings of KDD, pages 731?739.Naoki Yoshinaga and Masaru Kitsuregawa.
2009.
Poly-nomial to linear: Efficient classification with conjunc-tive features.
In Proceedings of EMNLP, pages 1542?1551.Naoki Yoshinaga andMasaru Kitsuregawa.
2010.
Kernelslicing: Scalable online training with conjunctive fea-tures.
In Proceedings of COLING, pages 1245?1253.Jun Zhu, Zaiqing Nie, Xiaojiang Liu, Bo Zhang, and Ji-Rong Wen.
2009.
StatSnowball: a statistical approachto extracting entity relationships.
In Proceedings ofWWW, pages 101?110.892
