Proceedings of NAACL-HLT 2013, pages 106?116,Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational LinguisticsCross-Lingual Semantic Similarity of Words as the Similarity of TheirSemantic Word ResponsesIvan Vulic?
and Marie-Francine MoensDepartment of Computer ScienceKU LeuvenCelestijnenlaan 200ALeuven, Belgium{ivan.vulic,marie-francine.moens}@cs.kuleuven.beAbstractWe propose a new approach to identifyingsemantically similar words across languages.The approach is based on an idea that twowords in different languages are similar if theyare likely to generate similar words (which in-cludes both source and target language words)as their top semantic word responses.
Se-mantic word responding is a concept fromcognitive science which addresses detectingmost likely words that humans output as freeword associations given some cue word.
Themethod consists of two main steps: (1) it uti-lizes a probabilistic multilingual topic modeltrained on comparable data to learn and quan-tify the semantic word responses, (2) it pro-vides ranked lists of similar words accord-ing to the similarity of their semantic wordresponse vectors.
We evaluate our approachin the task of bilingual lexicon extraction(BLE) for a variety of language pairs.
Weshow that in the cross-lingual settings withoutany language pair dependent knowledge theresponse-based method of similarity is morerobust and outperforms current state-of-the artmethods that directly operate in the semanticspace of latent cross-lingual concepts/topics.1 IntroductionCross-lingual semantic word similarity addressesthe task of detecting words that refer to similar se-mantic concepts and convey similar meanings acrosslanguages.
It ultimately boils down to the automaticidentification of translation pairs, that is, bilinguallexicon extraction (BLE).
Such lexicons and seman-tically similar words serve as important resourcesin cross-lingual knowledge induction (e.g., Zhao etal.
(2009)), statistical machine translation (Och andNey, 2003) and cross-lingual information retrieval(Ballesteros and Croft, 1997; Levow et al 2005).From parallel corpora, semantically similar wordsand bilingual lexicons are induced on the basis ofword alignment models (Brown et al 1993; Ochand Ney, 2003).
However, due to a relative scarce-ness of parallel texts for many language pairs anddomains, there has been a recent growing interest inmining semantically similar words across languageson the basis of comparable data readily available onthe Web (e.g., Wikipedia, news stories) (Haghighi etal., 2008; Hassan and Mihalcea, 2009; Vulic?
et al2011; Prochasson and Fung, 2011).Approaches to detecting semantic word similarityfrom comparable corpora are most commonly basedon an idea known as the distributional hypothesis(Harris, 1954), which states that words with sim-ilar meanings are likely to appear in similar con-texts.
Each word is typically represented by a high-dimensional vector in a feature vector space or a so-called semantic space, where the dimensions of thevector are its context features.
The semantic similar-ity of two words, wS1 given in the source languageLS with vocabulary V S and wT2 in the target lan-guage LT with vocabulary V T is then:Sim(wS1 , wT2 ) = SF (cv(wS1 ), cv(wT2 )) (1)cv(wS1 ) = [scS1 (c1), .
.
.
, scS1 (cN )] denotes a contextvector for wS1 with N context features ck, wherescS1 (ck) denotes the score for wS1 associated withcontext feature ck (similar for wT2 ).
SF is a sim-ilarity function (e.g., cosine, the Kullback-Leibler106divergence, the Jaccard index) operating on the con-text vectors (Lee, 1999; Cha, 2007).In order to compute cross-lingual semantic wordsimilarity, one needs to design the context featuresof words given in two different languages that spana shared cross-lingual semantic space.
Such cross-lingual semantic spaces are typically spanned by:(1) bilingual lexicon entries (Rapp, 1999; Gaussieret al 2004; Laroche and Langlais, 2010; Tamuraet al 2012), or (2) latent language-independent se-mantic concepts/axes (e.g., latent cross-lingual top-ics) induced by an algebraic model (Dumais et al1996), or more recently by a generative probabilis-tic model (Haghighi et al 2008; Daume?
III and Ja-garlamudi, 2011; Vulic?
et al 2011).
Context vec-tors cv(wS1 ) and cv(wT2 ) for both source and targetwords are then compared in the semantic space in-dependently of their respective languages.In this work, we propose a new approach to con-structing the shared cross-lingual semantic spacethat relies on a paradigm of semantic word respond-ing or free word association.
We borrow that con-cept from the psychology/cognitive science litera-ture.
Semantic word responding addresses a taskthat requires participants to produce first words thatcome to their mind that are related to a presented cueword (Nelson et al 2000; Steyvers et al 2004).The new cross-lingual semantic space is spannedby all vocabulary words in the source and the targetlanguage.
Each axis in the space denotes a semanticword response.
The similarity between two words isthen computed as the similarity between the vectorscomprising their semantic word responses using anyof existing SF -s. Two words are considered seman-tically similar if they are likely to generate similarsemantic word responses and assign similar impor-tance to them.We utilize a shared semantic space of latent cross-lingual topics learned by a multilingual probabilistictopic model to obtain semantic word responses andquantify the strength of association between any cueword and its responses monolingually and acrosslanguages, and, consequently, to build semantic re-sponse vectors.
That effectively translates the taskof word similarity from the semantic space spannedby latent cross-lingual topics to the semantic spacespanned by all vocabulary words in both languages.The main contributions of this article are:?
We propose a new approach to modeling cross-lingual semantic similarity of words based onthe similarity of their semantic word responses.?
We present how to estimate and quantify se-mantic word responses by means of a multilin-gual probabilistic topic model.?
We demonstrate how to employ our novelparadigm that relies on semantic word respond-ing in the task of bilingual lexicon extraction(BLE) from comparable data.?
We show that the response-based model of sim-ilarity is more robust and obtains better resultsfor BLE than the models that operate in the se-mantic space spanned by latent semantic con-cepts, i.e., cross-lingual topics directly.The following sections first review relevant priorwork and provide a very short introduction to multi-lingual probabilistic topic modeling, then describeour response-based approach to modeling cross-lingual semantic word similarity, and finally presentour evaluation and results on the BLE task for a va-riety of language pairs.2 Related WorkWhen dealing with the cross-lingual semantic wordsimilarity, the focus of the researchers is typicallyon BLE, since usually the most similar words acrosslanguages are direct translations of each other.
Nu-merous approaches emerged over the years that tryto induce bilingual word lexicons on the basis ofdistributional information.
Especially challengingis the task of mining semantically similar wordsfrom comparable data without any external knowl-edge source such as machine-readable seed bilin-gual lexicons used in (Fung and Yee, 1998; Rapp,1999; Fung and Cheung, 2004; Gaussier et al 2004;Morin et al 2007; Andrade et al 2010; Tamuraet al 2012), predefined explicit ontology or cate-gory knowledge used in (De?jean et al 2002; Hassanand Mihalcea, 2009; Agirre et al 2009), or ortho-graphic clues as used in (Koehn and Knight, 2002;Haghighi et al 2008; Daume?
III and Jagarlamudi,2011).
This work addresses that particularly difficultsetting which does not assume any language pair de-pendent background knowledge.
It makes methods107developed in such a setting applicable even on dis-tant language pairs with scarce resources.Recently, Griffiths et al(2007), and Steyvers andGriffiths (2007) proposed models of free word asso-ciation and semantic word similarity in the monolin-gual settings based on per-topic word distributionsfrom probabilistic topic models such as pLSA (Hof-mann, 1999) and LDA (Blei et al 2003).
Addition-ally, Vulic?
et al(2011) constructed several modelsthat utilize a shared cross-lingual topical space ob-tained by a multilingual topic model (Mimno et al2009; De Smet and Moens, 2009; Boyd-Graber andBlei, 2009; Ni et al 2009; Jagarlamudi and Daume?III, 2010; Zhang et al 2010) to identify potentialtranslation candidates in the cross-lingual settingswithout any background knowledge.
In this paper,we show that a transition from their semantic spacespanned by cross-lingual topics to a semantic spacespanned by all vocabulary words yields more robustmodels of cross-lingual semantic word similarity.3 Modeling Word Similarity as theSimilarity of Semantic Word ResponsesThis section contains a detailed description of oursemantic word similarity method that relies on se-mantic word responses.
Since the method utilizesthe concept of multilingual probabilistic topic mod-eling, we first provide a very short overview of thatconcept, then present the intuition behind the ap-proach, and finally describe our method in detail.3.1 Multilingual Probabilistic Topic ModelingAssume that we are given a multilingual corpusC of l languages, and C is a set of text collec-tions {C1, .
.
.
, Cl} in those languages.
A multi-lingual probabilistic topic model (Mimno et al2009; De Smet and Moens, 2009; Boyd-Graberand Blei, 2009; Ni et al 2009; Jagarlamudi andDaume?
III, 2010; Zhang et al 2010) of a mul-tilingual corpus C is defined as a set of semanti-cally coherent multinomial distributions of wordswith values Pj(wji |zk), j = 1, .
.
.
, l, for each vo-cabulary V 1, .
.
.
, V j , .
.
.
, V l associated with textcollections C1, .
.
.
, Cj , .
.
.
, Cl ?
C given in lan-guages L1, .
.
.
, Lj , .
.
.
, Ll.
Pj(wji |zk) is calculatedfor eachwji ?
Vj .
The probability scores Pj(wji |zk)build per-topic word distributions, and they consti-tute a language-specific representation (e.g., a prob-ability value is assigned only for words from V j)of a language-independent cross-lingual latent con-cept, that is, latent cross-lingual topic zk ?
Z .Z = {z1, .
.
.
, zK} represents the set of all K la-tent cross-lingual topics present in the multilingualcorpus.
Each document in the multilingual corpusis thus considered a mixture of K cross-lingual top-ics from the set Z .
That mixture for some docu-ment dji ?
Cj is modeled by the probability scoresPj(zk|dji ) that altogether build per-document topicdistributions.Each cross-lingual topic from the set Z can beobserved as a latent language-independent conceptpresent in the multilingual corpus, but each lan-guage in the corpus uses only words from its ownvocabulary to describe the content of that concept.For instance, having a multilingual collection in En-glish, Spanish and Dutch and discovering a topicon Soccer, that cross-lingual topic would be repre-sented by words (actually probabilities over words){player, goal, coach, .
.
.}
in English, {balo?n (ball),futbolista (soccer player), goleador (scorer), .
.
.
}in Spanish, and {wedstrijd (match), elftal (soccerteam), doelpunt (goal), .
.
.}
in Dutch.
We have?wji?Vj Pj(wji |zk) = 1, for each vocabulary Vjrepresenting language Lj , and for each topic zk ?Z .
Therefore, the latent cross-lingual topics alsospan a shared cross-lingual semantic space.3.2 The Intuition Behind the ApproachImagine the following thought experiment.
A groupof human subjects who have been raised bilinguallyand thus are native speakers of two languages LSand LT , is playing a game of word associations.The game consists of possibly an infinite number ofiterations, and each iteration consists of 4 rounds.In the first round (the S-S round), given a word inthe language LS , the subject has to generate a listof words in the same language LS that first occurto her/him as semantic word responses to the givenword.
The list is in descending order, with moreprominent word responses occurring higher in thelist.
In the second round (the S-T round), the sub-ject repeats the procedure, and generates the list ofword responses to the same word from LS , but nowin the other language LT .
The third (the T-T round)108and the fourth round (the T-S round) are similar tothe first and the second round, but now a list of wordresponses in both LS and LT has to be generated forsome cue word from LT .
The process of generatingthe lists of semantic responses then continues withother cue words and other human subjects.As the final result, for each word in the sourcelanguage LS , and each word in the target languageLT , we obtain a single list of semantic word re-sponses comprising words in both languages.
Alllists are sorted in descending order, based on someassociation score that takes into account both thenumber of times a word has occurred as an asso-ciative response, as well as the position in the listin each round.
We can now measure the similarityof any two words, regardless of their correspondinglanguages, according to the similarity of their cor-responding lists that contain their word responses.Words that are equally likely to trigger the same as-sociative responses in the human brain, and more-over assign equal importance to those responses, asprovided in the lists of associative responses, arevery likely to be closely semantically similar.
Addi-tionally, for a given word wS1 in the source languageLS , some word wT2 in LT that has the highest simi-larity score among all words inLT should be a directword-to-word translation of wS1 .3.3 Modeling Semantic Word Responses viaCross-Lingual TopicsCross-lingual topics provide a sound framework toconstruct a probabilistic model of the aforemen-tioned experiment.
To model semantic word re-sponses via the shared space of cross-lingual top-ics, we have to set a probabilistic mass that quan-tifies the degree of association.
Given two wordsw1, w2 ?
V S ?
V T , a natural way of expressing theasymmetric semantic association is by modeling theprobability P (w2|w1) (Griffiths et al 2007), that is,the probability to generate word w2 as a responsegiven word w1.
After the training of a multilin-gual topic model on a multilingual corpus, we obtainper-topic word distributions with scores PS(wSi |zk)and PT (wTi |zk) (see Sect.
3.1).1 The probability1A remark on notation throughout the paper: Since theshared space of cross-lingual topics allows us to construct auniform representation for all words regardless of a vocabularythey belong to, due to simplicity and to stress the uniformity,P (w2|w1) is then decomposed as follows:Resp(w1, w2) = P (w2|w1) =K?k=1P (w2|zk)P (zk|w1) (2)The probability scores P (w2|zk) select words thatare highly descriptive for each particular topic.
Theprobability scores P (zk|w1) ensure that topics zkthat are semantically relevant to the given wordw1 dominate the sum, so the overall high scoreResp(w1, w2) of the semantic word response is as-signed only to highly descriptive words of the se-mantically related topics.
Using the shared spaceof cross-lingual topics, semantic response scores canbe derived for any two words w1, w2 ?
V S ?
V T .1The generative model closely resembles the ac-tual process in the human brain - when we gener-ate semantic word responses, we first tend to as-sociate that word with a related semantic/cognitiveconcept, in this case a cross-lingual topic (the factorP (zk|w1)), and then, after establishing the concept,we output a list of words that we consider the mostprominent/descriptive for that concept (words withhigh scores in the factor P (w2|zk)) (Nelson et al2000; Steyvers et al 2004).
Due to such modelingproperties, this model of semantic word respondingtends to assign higher association scores for highfrequency words.
It eventually leads to asymmet-ric associations/responses.
We have detected thatphenomenon both monolingually and across lan-guages.
For instance, the first response to Span-ish word mutacio?n (mutation) is English word gene.Other examples include caldera (boiler)-steam, de-portista (sportsman)-sport, horario (schedule)-houror pescador (fisherman)-fish.
In the other associa-tion direction, we have detected top responses suchas merchant-comercio (trade) or neologism-palabra(word).
In the monolingual setting, we acquireEnglish pairs such as songwriter-music, discipline-sport, or Spanish pairs gripe (flu)-enfermedad (dis-ease), cuenca (basin)-r?
?o (river), etc.3.4 Response-Based Model of SimilarityEq.
(2) provides a way to measure the strength ofsemantic word responses.
In order to establish thewe sometimes use notation P (wi|zk) and P (zk|wi) instead ofPS(wi|zk) or PS(zk|wi) (similar for subscript T ).
However,the reader must be aware that, for instance, P (wi|zk) actuallymeans PS(wi|zk) if wi ?
V S , and PT (wi|zk) if wi ?
V T .109Semantic responses Response-based similaritydramaturgo (playwright) play playwright dramaturgoobra (play) .101 play .142 play .122 playwrightescritor (writer) .083 obra (play) .111 escritor (writer) .087 dramatistplay .066 player .033 obra (play) .073 tragedywriter .050 escena (scene) .031 writer .060 playpoet .047 jugador (player) .026 poeta (poet) .055 essayistautor (author) .041 adaptation .025 poet .053 novelistpoeta (poet) .039 stage .024 autor (author) .046 dramateatro (theatre) .030 game .022 teatro (theatre) .043 tragediandrama .026 juego (game) .021 tragedy .031 satiristcontribution .025 teatro (theatre) .019 drama .026 writerTable 1: An example of top 10 semantic word responses and the final response-based similarity for some Spanish andEnglish words.
The responses are estimated from Spanish-English Wikipedia data by bilingual LDA.
We can observeseveral interesting phenomena: (1) High-frequency words tend to appear higher in the lists of semantic responses(e.g., play and obra for all 3 words), (2) Due to the modeling properties that give preference to high-frequency words(Sect.
3.3), a word might not generate itself as the top semantic response (e.g., playwright-play), (3) Both sourceand target language words occur as the top responses in the lists, (4) Although play is the top semantic response inEnglish for both dramaturgo and playwright, its list of top semantic responses is less similar to the lists of those twowords, (5) Although the English word playwright does not appear in the top 10 semantic responses to dramaturgo,and dramaturgo does not appear in the top 10 responses to playwright, the more robust response-based similaritymethod detects that the two words are actually very similar based on their lists of responses, (6) dramaturgo andplaywright have very similar lists of semantic responses which ultimately leads to detecting that playwright is themost semantically similar word to dramaturgo across the two languages (the last column), i.e., they are direct one-to-one translations of each other, (7) Another English word dramatist very similar to Spanish dramaturgo is also pushedhigher in the final list, although it is not found in the list of top semantic responses to dramaturgo.final similarity between two words, we have to com-pare their semantic response vectors, that is, theirsemantic response scores over all words in bothvocabularies.
The final model of word similarityclosely mimics our thought experiment.
First, foreach word wSi ?
VS , we generate probability scoresP (wSj |wSi ) for all words wSj ?
VS (the S-S rounds).Note that P (wSi |wSi ) is also defined by Eq.
(2).Following that, for each word wSi ?
VS , we gen-erate probability scores P (wTj |wSi ), for all wordswTj ?
VT (the S-T rounds).
Similarly, we calcu-late probability scores P (wTj |wTi ) and P (wSj |wTi ),for each wTi , wTj ?
VT , and for each wSj ?
VS (theT-T and T-S rounds).Now, each word wi ?
V S ?
V T may be repre-sented by a (|V S |+ |V T |)-dimensional context vec-tor cv(wi) as follows:2[P (wS1 |wi), .
.
.
, P (wS|V S ||wi), .
.
.
, P (wT|V T ||wi)].We have created a language-independent cross-2We assume that the two sets V S and V T are disjunct.
Itmeans that, for instance, Spanish word pie (foot) from V S andEnglish word pie from V T are treated as two different wordtypes.
In that case, it holds |V S ?
V T | = |V S |+ |V T |.lingual semantic space spanned by all vocabularywords in both languages.
Each feature correspondsto one word from vocabularies V S and V T , whilethe exact score for each feature in the contextvector cv(wi) is precisely the probability that thisword/feature will be generated as a word responsegiven word wi.
The degree of similarity betweentwo words is then computed on the basis of similar-ity between their feature vectors using some of thestandard similarity functions (Cha, 2007).The novel response-based approach of similarityremoves the effect of high-frequency words that tendto appear higher in the lists of semantic word re-sponses.
Therefore, the real synonyms and trans-lations should occur as top candidates in the listsof similar words obtained by the response-basedmethod.
That property may be exploited to identifyone-to-one translations across languages and build abilingual lexicon (see Table 1).4 Experimental Setup4.1 Data CollectionsWe work with the following corpora:110?
IT-EN-W: A collection of 18, 898 Italian-English Wikipedia article pairs previously usedby Vulic?
et al(2011).?
ES-EN-W: A collection of 13, 696 Spanish-English Wikipedia article pairs.?
NL-EN-W: A collection of 7, 612 Dutch-English Wikipedia article pairs.?
NL-EN-W+EP: The NL-EN-W corpus aug-mented with 6,206 Dutch-English documentpairs from Europarl (Koehn, 2005).
AlthoughEuroparl is a parallel corpus, no explicit use ismade of sentence-level alignments.All corpora are theme-aligned, that is, the aligneddocument pairs discuss similar subjects, but arein general not direct translations (except the Eu-roparl document pairs).
NL-EN-W+EP serves to testwhether better semantic responses could be learnedfrom data of higher quality, and to measure how itaffects the response-based similarity method and thequality of induced lexicons.
Following (Koehn andKnight, 2002; Haghighi et al 2008; Prochasson andFung, 2011), we consider only noun word types.
Weretain only nouns that occur at least 5 times in thecorpus.
We record the lemmatized form when avail-able, and the original form otherwise.
Again follow-ing their setup, we use TreeTagger (Schmid, 1994)for POS tagging and lemmatization.4.2 Multilingual Topic ModelThe multilingual probabilistic topic model we useis a straightforward multilingual extension of thestandard Blei et als LDA model (Blei et al 2003)called bilingual LDA (Mimno et al 2009; Ni etal., 2009; De Smet and Moens, 2009).
For the de-tails regarding the modeling assumptions, generativestory, training and inference procedure of the bilin-gual LDA model, we refer the interested reader tothe aforementioned relevant literature.
The poten-tial of the model in the task of bilingual lexicon ex-traction was investigated before (Mimno et al 2009;Vulic?
et al 2011), and it was also utilized in othercross-lingual tasks (e.g., Platt et al(2010); Ni etal.
(2011)).
We use Gibbs sampling for training.In a typical setting for mining semantically similarwords using latent topic models in both monolingual(Griffiths et al 2007; Dinu and Lapata, 2010) andcross-lingual setting (Vulic?
et al 2011), the best re-sults are obtained with the number of topics set toa few thousands (?
2000).
Therefore, our bilingualLDA model on all corpora is trained with the numberof topics K = 2000.
Other parameters of the modelare set to the standard values according to Steyversand Griffiths (2007): ?
= 50/K and ?
= 0.01.We are aware that different hyper-parameter settings(Asuncion et al 2009; Lu et al 2011), might haveinfluence on the quality of learned cross-lingual top-ics, but that analysis is out of the scope of this paper.4.3 Compared MethodsWe evaluate and compare the following word simi-larity approaches in all our experiments:1) The method that regards the lists of semanticword responses across languages obtained by Eq.
(2) directly as the lists of semantically similar words(Direct-SWR).2) The state-of-the-art method that employs a simi-larity function (SF) on theK-dimensional word vec-tors cv(wi) in the semantic space of latent cross-lingual topics.
The dimensions of the vectors areconditional topic distribution scores P (zk|wi) thatare obtained by the multilingual topic model directly(Steyvers and Griffiths, 2007; Vulic?
et al 2011).
Wehave tested different SF-s (e.g., the Kullback-Leiblerand the Jensen-Shannon divergence, the cosine mea-sure), and have detected that in general the bestscores are obtained when using the Bhattacharyyacoefficient (BC) (Bhattacharyya, 1943; Kazama etal., 2010) (Topic-BC).3) The best scoring similarity method from Vulic?et al(2011) named TI+Cue.
This state-of-the-artmethod also operates in the semantic space of latentcross-lingual concepts/topics.4) The response-based similarity described in Sect.3.
As for Topic-BC, we again use BC as the simi-larity function, but now on |V S ?
V T |-dimensionalcontext vectors in the semantic space spanned byall words in both vocabularies that represent seman-tic word responses (Response-BC).
Given two N -dimensional word vectors cv(wS1 ) and cv(wT2 ), theBC or the fidelity measure (Cha, 2007) is defined as:BC(cv(wS1 ), cv(wT2 )) =N?n=1?scS1 (cn) ?
scT2 (cn) (3)111Corpus: IT-EN-W ES-EN-W NL-EN-W NL-EN-W+EPMethod Acc1 MRR Acc10 Acc1 MRR Acc10 Acc1 MRR Acc10 Acc1 MRR Acc10Direct-SWR .501 .576 .740 .332 .437 .675 .186 .254 .423 .344 .450 .652Topic-BC .578 .667 .834 .433 .576 .843 .237 .314 .489 .534 .630 .836TI+Cue .597 .702 .897 .429 .569 .828 .225 .296 .459 .446 .569 .808Response-BC .622 .729 .882 .517 .635 .891 .236 .320 .511 .574 .653 .864Table 2: BLE performance of all the methods for Italian-English, Spanish-English and Dutch-English (with 2 differentcorpora utilized for the training of bilingual LDA and the estimation of semantic word responses for Dutch-English).For the Topic-BC method N = K, while N =|V S ?
V T | for Response-BC.
Additionally, sinceP (zk|wi) > 0 and P (wk|wi) > 0 for each zk ?
Zand each wk ?
V S ?
V T , a lot of probability massis assigned to topics and semantic responses thatare completely irrelevant to the given word.
Re-ducing the dimensionality of the semantic repre-sentation a posteriori to only a smaller number ofmost important semantic axes in the semantic spacesshould decrease the effects of that statistical noise,and even more firmly emphasize the latent corre-lation among words.
The utility of such semanticspace truncating or feature pruning in monolingualsettings (Reisinger and Mooney, 2010) was also de-tected previously for LSA and LDA-based models(Landauer and Dumais, 1997; Griffiths et al 2007).Therefore, unless noted otherwise, we perform allour calculations over the best scoring 200 cross-lingual topics and the best scoring 2000 semanticword responses.34.4 EvaluationGround truth translation pairs.4 Since our taskis bilingual lexicon extraction, we designed a setof ground truth one-to-one translation pairs for all3 language pairs as follows.
For Dutch-Englishand Spanish-English, we randomly sampled a setof Dutch (Spanish) nouns from our Wikipedia cor-pora.
Following that, we used the Google Trans-late tool plus an additional annotator to translatethose words to English.
The annotator manuallyrevised the lists and retained only words that have3The values are set empirically.
Calculating similaritySim(wS1 , wT2 ) may be interpreted as: ?Given word wS1 detecthow similar word wT2 is to the word wS1 .?
Therefore, whencalculating Sim(wS1 , wT2 ), even when dealing with symmetricsimilarity functions such as BC, we always consider only thescores P (?|wS1 ) for truncating.4Available online: http://people.cs.kuleuven.be/?ivan.vulic/software/their corresponding translation in the English vo-cabulary.
Additionally, only one possible translationwas annotated as correct.
When more than 1 trans-lation is possible, the annotator marked as correctthe translation that occurs more frequently in the En-glish Wikipedia data.
Finally, we built a set of 1000one-to-one translation pairs for Dutch-English andSpanish-English.
The same procedure was followedfor Italian-English, but there we obtained the groundtruth one-to-one translation pairs for 1000 most fre-quent Italian nouns in order to test the effect of wordfrequency on the quality of semantic word responsesand the overall lexicon quality.Evaluation metrics.
All the methods under con-sideration actually retrieve ranked lists of semanti-cally similar words that could be observed as poten-tial translation candidates.
We measure the perfor-mance on BLE as Top M accuracy (AccM ).
It de-notes the number of source words from ground truthtranslation pairs whose top M semantically simi-lar words contain the correct translation accordingto our ground truth over the total number of groundtruth translation pairs (=1000) (Tamura et al 2012).Additionally, we compute the mean reciprocal rank(MRR) scores (Voorhees, 1999).5 Results and DiscussionTable 2 displays the performance of each comparedmethod on the BLE task.
It shows the difference inresults for different language pairs and different cor-pora used to extract latent cross-lingual topics andestimate the lists of semantic word responses.
Ex-ample lists of semantically similar words over all 3language pairs are shown in Table 3.
Based on theseresults, we are able to derive several conclusions:(i) Response-BC performs consistently better thanthe other 3 methods over all corpora and all languagepairs.
It is more robust and is able to find somecross-lingual similarities omitted by the other meth-112Italian-English (IT-EN) Spanish-English (ES-EN) Dutch-English (NL-EN)(1) affresco (2) spigolo (3) coppa (1) caza (2) discurso (3) comprador (1) behoud (2) schroef (3) spar(fresco) (edge) (cup) (hunting) (speech) (buyer) (conservation) (screw) (fir)fresco polyhedron club hunting rhetoric purchase conservation socket conifermural polygon competition hunt oration seller preservation wire pinenave vertices final hunter speech tariff heritage wrap firewoodwall diagonal champion hound discourse market diversity wrench seedlingtestimonial edge football safari dialectic bidding emphasis screw weevilapse vertex trophy huntsman rhetorician auction consequence pin chestnutrediscovery binomial team wildlife oratory bid danger fastener acorndraughtsman solid relegation animal wisdom microeconomics contribution torque girthceiling graph tournament ungulate oration trade decline pipe lumberpalace modifier soccer chase persuasion listing framework routing barkTable 3: Example lists of top 10 semantically similar words across all 3 language pairs according to our Response-BCsimilarity method, where the correct translation word is: (col. 1) found as the most similar word, (2) contained lowerin the list, and (3) not found in the top 10 words.IT-EN ES-EN NL-ENdirettore-director flauta-flute kustlijn-coastlineradice-root eficacia-efficacy begrafenis-funeralsintomo-symptom empleo-employment mengsel-mixtureperdita-loss descubierta-discovery lijm-gluedanno-damage desalojo-eviction kijker-viewerbattaglione-battalion miedo-fear oppervlak-surfaceTable 4: Example translations found by the Response-BCmethod, but missed by the other 3 methods.ods (see Table 4).
The overall quality of the cross-lingual word similarities and lexicons extracted bythe method is dependent on the quality of estimatedsemantic response vectors.
The quality of thesevectors is of course further dependent on the qual-ity of multilingual training data.
For instance, forDutch-English, we may observe a rather spectacularincrease in overall scores (the tests are performedover the same set of 1000 words) when we aug-ment Wikipedia data with Europarl data (comparethe scores for NL-EN-W and NL-EN-W+EP).
(ii) A transition from a semantic space spanned bycross-lingual topics (Topic-BC) to a semantic spacespanned by vocabulary words (Response-BC) leadsto better results over all corpora and language pairs.The difference is less visible when using trainingdata of lesser quality (the scores for NL-EN-W).Moreover, since the shared space of cross-lingualtopics is used to obtain and quantify semantic wordresponses, the quality of learned cross-lingual topicsinfluences the quality of semantic word responses.If the semantic coherence of the cross-lingual top-ical space is unsatisfying, the method is unable togenerate good semantic response vectors, and ul-timately unable to correctly identify semanticallysimilar words across languages.
(iii) Due to its modeling properties that assign moreimportance to high-frequency words, Direct-SWRproduces reasonable results in the BLE task only forhigh-frequency words (see results for IT-EN-W).
Al-though Eq.
(2) models the concept of semantic wordresponding in a sound way (Griffiths et al 2007),using the semantic word responses directly is notsuitable for the actual BLE task.
(iv) The effect of word frequency is clearly visi-ble when comparing the results obtained on IT-EN-W with the results obtained on the other Wikipediacorpora.
High-frequency words produce more re-dundancies in training data that are captured by sta-tistical models such as latent topic models.
High-frequency words then obtain better estimates of theirsemantic response vectors which consequently leadsto better overall scores.
The effect of word fre-quency on statistical methods in the BLE task wasinvestigated before (Pekar et al 2006; Prochassonand Fung, 2011; Tamura et al 2012), and we alsoconfirm their findings.
(v) Unlike (Koehn and Knight, 2002; Haghighi etal., 2008), our response-based method does not relyon any orthographic features such as cognates orwords shared across languages.
It is a pure statis-tical method that only relies on word distributionsover a multilingual corpus.
Based on these distribu-tions, it performs the initial shallow semantic analy-sis of the corpus by means of a multilingual prob-abilistic model.
The method then builds, via theconcept of semantic word responding, a language-113independent semantic space spanned by all vocabu-lary words/responses in both languages.
That makesthe method portable to distant language pairs.
How-ever, for similar languages, including more evidencesuch as orthographic clues might lead to further in-crease in scores, but we leave that for future work.6 ConclusionWe have proposed a new statistical approach to iden-tifying semantically similar words across languagesthat relies on the paradigm of semantic word re-sponding previously defined in cognitive science.The proposed approach is robust and does not makeany additional language-pair dependent assumptions(e.g., it does not rely on a seed lexicon, orthographicclues or predefined concept categories).
That effec-tively makes it applicable to any language pair.
Ourexperiments on the task of bilingual lexicon extrac-tion for a variety of language pairs have proved thatthe response-based approach is more robust and out-performs the methods that operate in the semanticspace of latent concepts (e.g., cross-lingual topics)directly.AcknowledgmentsWe would like to thank Steven Bethard and theanonymous reviewers for their useful suggestions.This research has been carried out in the frame-work of the TermWise Knowledge Platform (IOF-KP/09/001) funded by the Industrial Research Fund,KU Leuven, Belgium.ReferencesEneko Agirre, Enrique Alfonseca, Keith Hall, JanaKravalova, Marius Pasca, and Aitor Soroa.
2009.
Astudy on similarity and relatedness using distributionaland WordNet-based approaches.
In Proceedings ofNAACL-HLT, pages 19?27.Daniel Andrade, Tetsuya Nasukawa, and Junichi Tsujii.2010.
Robust measurement and comparison of contextsimilarity for finding translation pairs.
In Proceedingsof COLING, pages 19?27.Arthur Asuncion, Max Welling, Padhraic Smyth, andYee Whye Teh.
2009.
On smoothing and inference fortopic models.
In Proceedings of UAI, pages 27?34.Lisa Ballesteros and W. Bruce Croft.
1997.
Phrasaltranslation and query expansion techniques for cross-language information retrieval.
In Proceedings of SI-GIR, pages 84?91.A.
Bhattacharyya.
1943.
On a measure of divergence be-tween two statistical populations defined by their prob-ability distributions.
Bulletin of the Calcutta Mathe-matical Society, 35:199?209.David M. Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent Dirichlet Allocation.
Journal of Ma-chine Learning Research, 3:993?1022.Jordan Boyd-Graber and David M. Blei.
2009.
Multilin-gual topic models for unaligned text.
In Proceedingsof UAI, pages 75?82.Peter F. Brown, Vincent J. Della Pietra, Stephen A. DellaPietra, and Robert L. Mercer.
1993.
The mathemat-ics of statistical machine translation: parameter esti-mation.
Computational Linguistics, 19(2):263?311.Sung-Hyuk Cha.
2007.
Comprehensive survey ondistance/similarity measures between probability den-sity functions.
International Journal of MathematicalModels and Methods in Applied Sciences, 1(4):300?307.Hal Daume?
III and Jagadeesh Jagarlamudi.
2011.
Do-main adaptation for machine translation by mining un-seen words.
In Proceedings of ACL, pages 407?412.Wim De Smet and Marie-Francine Moens.
2009.
Cross-language linking of news stories on the Web using in-terlingual topic modeling.
In CIKM Workshop on So-cial Web Search and Mining (SWSM), pages 57?64.Herve?
De?jean, Eric Gaussier, and Fatia Sadat.
2002.An approach based on multilingual thesauri and modelcombination for bilingual lexicon extraction.
In Pro-ceedings of COLING, pages 1?7.Georgiana Dinu and Mirella Lapata.
2010.
Topic modelsfor meaning similarity in context.
In Proceedings ofCOLING, pages 250?258.Susan T. Dumais, Thomas K. Landauer, and MichaelLittman.
1996.
Automatic cross-linguistic informa-tion retrieval using Latent Semantic Indexing.
In Pro-ceedings of the SIGIR Workshop on Cross-LinguisticInformation Retrieval, pages 16?23.Pascale Fung and Percy Cheung.
2004.
Mining very-non-parallel corpora: Parallel sentence and lexicon ex-traction via bootstrapping and EM.
In Proceedings ofEMNLP, pages 57?63.Pascale Fung and Lo Yuen Yee.
1998.
An IR approachfor translating new words from nonparallel, compara-ble texts.
In Proceedings of COLING, pages 414?420.Eric Gaussier, Jean-Michel Renders, Irina Matveeva,Cyril Goutte, and Herve?
De?jean.
2004.
A geometricview on bilingual lexicon extraction from comparablecorpora.
In Proceedings of ACL, pages 526?533.Thomas L. Griffiths, Mark Steyvers, and Joshua B.Tenenbaum.
2007.
Topics in semantic representation.Psychological Review, 114(2):211?244.114Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick,and Dan Klein.
2008.
Learning bilingual lexiconsfrom monolingual corpora.
In Proceedings of ACL,pages 771?779.Zellig S. Harris.
1954.
Distributional structure.
Word,10(23):146?162.Samer Hassan and Rada Mihalcea.
2009.
Cross-lingualsemantic relatedness using encyclopedic knowledge.In Proceedings of EMNLP, pages 1192?1201.Thomas Hofmann.
1999.
Probabilistic Latent SemanticIndexing.
In Proceedings of SIGIR, pages 50?57.Jagadeesh Jagarlamudi and Hal Daume?
III.
2010.
Ex-tracting multilingual topics from unaligned compara-ble corpora.
In Proceedings of ECIR, pages 444?456.Jun?ichi Kazama, Stijn De Saeger, Kow Kuroda, MasakiMurata, and Kentaro Torisawa.
2010.
A Bayesianmethod for robust estimation of distributional similar-ities.
In Proceedings of ACL, pages 247?256.Philipp Koehn and Kevin Knight.
2002.
Learning atranslation lexicon from monolingual corpora.
In ACLWorkshop on Unsupervised Lexical Acquisition, pages9?16.Philipp Koehn.
2005.
Europarl: A parallel corpus forstatistical machine translation.
In Proceedings of MTSummit, pages 79?86.Thomas K. Landauer and Susan T. Dumais.
1997.
Solu-tions to Plato?s problem: The Latent Semantic Analy-sis theory of acquisition, induction, and representationof knowledge.
Psychological Review, 104(2):211?240.Audrey Laroche and Philippe Langlais.
2010.
Revisitingcontext-based projection methods for term-translationspotting in comparable corpora.
In Proceedings ofCOLING, pages 617?625.Lillian Lee.
1999.
Measures of distributional similarity.In Proceedings of ACL, pages 25?32.Gina-Anne Levow, Douglas W. Oard, and Philip Resnik.2005.
Dictionary-based techniques for cross-languageinformation retrieval.
Information Processing andManagement, 41:523?547.Yue Lu, Qiaozhu Mei, and ChengXiang Zhai.
2011.Investigating task performance of probabilistic topicmodels: an empirical study of PLSA and LDA.
In-formation Retrieval, 14(2):178?203.David Mimno, Hanna M. Wallach, Jason Naradowsky,David A. Smith, and Andrew McCallum.
2009.Polylingual topic models.
In Proceedings of EMNLP,pages 880?889.Emmanuel Morin, Be?atrice Daille, Koichi Takeuchi, andKyo Kageura.
2007.
Bilingual terminology mining -using brain, not brawn comparable corpora.
In Pro-ceedings of ACL, pages 664?671.Douglas L. Nelson, Cathy L. McEvoy, and Simon Den-nis.
2000.
What is free association and what does itmeasure?
Memory and Cognition, 28:887?899.Xiaochuan Ni, Jian-Tao Sun, Jian Hu, and Zheng Chen.2009.
Mining multilingual topics from Wikipedia.
InProceedings of WWW, pages 1155?1156.Xiaochuan Ni, Jian-Tao Sun, Jian Hu, and Zheng Chen.2011.
Cross lingual text classification by mining mul-tilingual topics from Wikipedia.
In Proceedings ofWSDM, pages 375?384.Franz Josef Och and Hermann Ney.
2003.
A system-atic comparison of various statistical alignment mod-els.
Computational Linguistics, 29(1):19?51.Viktor Pekar, Ruslan Mitkov, Dimitar Blagoev, and An-drea Mulloni.
2006.
Finding translations for low-frequency words in comparable corpora.
MachineTranslation, 20(4):247?266.John C. Platt, Kristina Toutanova, and Wen-Tau Yih.2010.
Translingual document representations fromdiscriminative projections.
In Proceedings of EMNLP,pages 251?261.Emmanuel Prochasson and Pascale Fung.
2011.
Rareword translation extraction from aligned comparabledocuments.
In Proceedings of ACL, pages 1327?1335.Reinhard Rapp.
1999.
Automatic identification of wordtranslations from unrelated English and German cor-pora.
In Proceedings of ACL, pages 519?526.Joseph Reisinger and Raymond J. Mooney.
2010.
Amixture model with sharing for lexical semantics.
InProceedings of EMNLP, pages 1173?1182.Helmut Schmid.
1994.
Probabilistic part-of-speech tag-ging using decision trees.
In International Conferenceon New Methods in Language Processing.Mark Steyvers and Tom Griffiths.
2007.
Probabilistictopic models.
Handbook of Latent Semantic Analysis,427(7):424?440.Mark Steyvers, Richard M. Shiffrin, and Douglas L. Nel-son.
2004.
Word association spaces for predicting se-mantic similarity effects in episodic memory.
In Ex-perimental Cognitive Psychology and Its Applications,pages 237?249.Akihiro Tamura, Taro Watanabe, and Eiichiro Sumita.2012.
Bilingual lexicon extraction from comparablecorpora using label propagation.
In Proceedings ofEMNLP, pages 24?36.Ellen M. Voorhees.
1999.
The TREC-8 question answer-ing track report.
In Proceedings of TREC, pages 77?82.Ivan Vulic?, Wim De Smet, and Marie-Francine Moens.2011.
Identifying word translations from comparablecorpora using latent topic models.
In Proceedings ofACL, pages 479?484.115Duo Zhang, Qiaozhu Mei, and ChengXiang Zhai.
2010.Cross-lingual latent topic extraction.
In Proceedingsof ACL, pages 1128?1137.Hai Zhao, Yan Song, Chunyu Kit, and Guodong Zhou.2009.
Cross language dependency parsing using abilingual lexicon.
In Proceedings of ACL, pages 55?63.116
