Proceedings of the 12th European Workshop on Natural Language Generation, pages 162?164,Athens, Greece, 30 ?
31 March 2009. c?2009 Association for Computational LinguisticsGeneration Challenges 2009162PrefaceGeneration Challenges 2009 was the third round of shared-task evaluationcompetitions (STECs) that involve the generation of natural language, andfollowed the Pilot Attribute Selection for Generating Referring ExpressionsChallenge in 2007 (ASGRE?07) and Referring Expression Generation Chal-lenges in 2008 (REG?08).
More information about all these NLG STEC ac-tivities can be found via the links on the Generation Challenges homepage:http://www.nltg.brighton.ac.uk/research/genchal09Generation Challenges 2009 brought together four STECs: the TUNA Refer-ring Expression Generation Task (TUNA-REG) organised by Albert Gatt, Anja Belzand Eric Kow; the two GREC Challenges, GREC Main Subject Reference Genera-tion (GREC-MSR) and GREC Named Entity Generation (GREC-NEG), organised byAnja Belz, Eric Kow, Jette Viethen and Albert Gatt; and the Giving Instructions inVirtual Environments Challenge (GIVE) organised by Donna Byron, Justine Cas-sell, Robert Dale, Alexander Koller, Johanna Moore, Jon Oberlander, and KristinaStriegnitz.In the GIVE Challenge, participating teams developed systems which generatenatural-language instructions to users navigating a virtual 3D environment and per-forming computer-game-like tasks.
The four participating systems were evaluatedby measuring how quickly, accurately and efficiently users were able to performtasks with a given system?s instructions.
The evaluation report for the GIVE Chal-lenge can be found in this volume; the participants?
reports will be made publiclyavailable at a later stage.The TUNA-REG Task was the end-to-end referring expression generation task(combining the attribute selection and realisation subtasks) which was first intro-duced in REG?08, and which used the TUNA corpus of paired descriptions andpictures of entities.
This year?s TUNA-REG Task had an open call for participation,but it was also organised in the spirit of a progress check which would give partic-ipants from TUNA-REG?08 an opportunity to submit improved systems, the resultsfor which could be compared to last year?s results.
Of five registered teams fromfive countries, four teams submitted a total of 6 systems to TUNA-REG.
These,along with two sets of human outputs, were evaluated by automatic intrinsic andhuman-based intrinsic and extrinsic evaluations.
The results report and the partici-pants?
reports can be found in this volume.The GREC-MSR Task was the same as in REG?08 and used a corpus of intro-ductory sections from Wikipedia articles on geographic entities and people.
Thetask was to generate referring expressions for mentions of the main subject of thearticle in the context of the full text of the article.
The new GREC-NEG Task useda separate corpus of introductory sections from Wikipedia articles on people, andthe task was to generate referring expressions for all mentions of all people in anarticle.Eight teams from seven countries registered for each of the GREC-MSR andGREC-NEG tasks.
As the system submission deadline approached, it became clearthat just two teams were certain that they were going to complete their systems intime.
For this reason, and also because of a moving camera-ready deadline, we de-cided, after careful consideration and consultation with participants, to extend thesystem development period for the GREC Tasks and to hold the GREC?09 results163meeting at the ACL-IJCNLP?09 Workshop on Language Generation and Summari-sation in Singapore on 6 August 2009, and to publish all GREC?09 reports in theproceedings of that workshop.In addition to the four shared tasks, Generation Challenges 2009 offered (i) anopen submission track in which participants could submit any work involving thedata from any of the shared tasks, while opting out of the competetive element, (ii)an evaluation track, in which proposals for new evaluation methods for the sharedtask could be submitted, and (iii) a task proposal track in which proposals for newshared tasks could be submitted.
We believe that these types of open-access tracksare important because they allow the wider research community to shape the focusand methodologies of STECs directly.
We received one submission in the opensubmission track, involving the TUNA data, and none in the other tracks.We successfully applied (with the help of support letters from many of lastyear?s participants and other HLT colleagues) for funding from the Engineeringand Physical Sciences Research Council (EPSRC), the main funding body for HLTin the UK.
This support helped with all aspects of organising Generation Chal-lenges 2009, and enabled us to create the new GREC-People corpus and to carryout extensive human evaluations, as well as to employ a dedicated research fellow(Eric Kow) to help with all aspects of Generation Challenges 2009.Preparations are already underway for a fourth NLG shared-task evaluationevent next year, Generation Challenges 2010, which is likely to include a furtherrun of the GREC-NEG Task with an extended training/development corpus, a newtask which links GREC-NEG to a named-entity recognition preprocessing stage, anda second run of the GIVE Challenge.
We are hoping that results will be presentedat INLG?10.Like our previous STECs, Generation Challenges 2009 would not have beenpossible without the contributions of many different people.
Wewould like to thankthe faculty and staff of Brighton University, and the students of UCL, Brightonand Sussex Universities who participated in the evaluation experiments as wellas all other participants in our online data elicitation and evaluation exercises; theENLG?09 organisers, Mariet Theune and Emiel Krahmer; the research support teamat Brighton University and the EPSRC for help with obtaining funding; and last butnot least, the participants in the shared tasks for making the most of the shortavailable time to build some very successful systems.February 2009 Anja Belz and Albert Gatt164
