Proceedings of the 5th International Workshop on Health Text Mining and Information Analysis (Louhi) @ EACL 2014, pages 85?89,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsAdverse Drug Event prediction combiningshallow analysis and machine learningSara SantisoAlicia P?erezKoldo GojenolaIXA Taldea (UPV-EHU)Arantza CasillasMaite OronozIXA Taldea (UPV-EHU)http://ixa.si.ehu.esAbstractThe aim of this work is to infer a modelable to extract cause-effect relations be-tween drugs and diseases.
A two-levelsystem is proposed.
The first level car-ries out a shallow analysis of ElectronicHealth Records (EHRs) in order to iden-tify medical concepts such as drug brand-names, substances, diseases, etc.
Next,all the combination pairs formed by aconcept from the group of drugs (drugand substances) and the group of diseases(diseases and symptoms) are characterisedthrough a set of 57 features.
A supervisedclassifier inferred on those features is incharge of deciding whether that pair rep-resents a cause-effect type of event.One of the challenges of this work is thefact that the system explores the entiredocument.
The contributions of this pa-per stand on the use of real EHRs to dis-cover adverse drug reaction events even indifferent sentences.
Besides, the work fo-cuses on Spanish language.1 IntroductionThis work deals with semantic data mining withinthe clinical domain.
The aim is to automaticallyhighlight the Adverse Drug Reactions (ADRs) inEHRs in order to alleviate the work-load to sev-eral services within a hospital (pharmacy service,documentation service,.
.
. )
that have to read thesereports.
Event detection was thoroughly tackled inthe Natural Language Processing for Clinical Data2010 Challenge.
Since then, cause-effect event ex-traction has emerged as a field of interest in theBiomedical domain (Bj?orne et al., 2010; Mihailaet al., 2013).
The motivation is, above all, practi-cal.
Electronic Health Records (EHRs) are studiedby several services in the hospital, not only by thedoctor in charge of the patient but also by the phar-macy and documentation services, amongst oth-ers.
There are some attempts in the literature thataim to make the reading of the reports in Englisheasier and less time-consuming by means of an au-tomatic annotation toolkit (Rink et al., 2011; Bot-sis et al., 2011; Toldo et al., 2012).
This work isa first approach on automatic learning of relationsbetween drugs causing diseases in Spanish EHRs.This work presents a system that entails twostages in cascade: 1) the first one carries out theannotation of drugs or substances (from now on-wards both of them shall be referred to as DRUG)and diseases or symptoms (referred to as DIS-EASE); 2) the second one determines whether agiven (DRUG, DISEASE) pair of concepts repre-sents a cause-effect reaction.
Note that we are in-terested in highlighting events involving (DRUG,DISEASE) pairs where the drug caused an adversereaction or a disease.
By contrast, often, (DRUG,DISEASE) pairs would entail a drug prescribed tocombat a disease, but these correspond to a differ-ent kind of events (indeed, diametrically opposed).Besides, (DRUG, DISEASE) pairs might representother sort of events or they might even be unre-lated at all.
Finally, the system should present theADRs marked in a friendly front-end.
To this end,the aim is to represent the text in the frameworkprovided by Brat (Stenetorp et al., 2012).
Figure 1shows an example, represented in Brat, of somecause-effect events manually tagged by experts.There are related works in this field aiming ata variety of biomedical event extraction, such asbinary protein-protein interaction (Wong, 2001),biomolecular event extraction (Kim et al., 2011),and drug-drug interaction extraction (Segura-Bedmar et al., 2013).
We are focusing on a varietyof interaction extraction: drugs causing diseases.There are previous works in the literature that tryto warn whether a document contains or not thistype of events.
There are more recent works that85Figure 1: Some cause-effect events manually annotated in the Brat framework.cope with event extraction within the same sen-tence, that is, intra-sentence events.
By contrast, inthis work we have realised that around 26% of theevents occur between concepts that are in differ-ent sentences.
Moreover, some of them are at verylong distance.
Hence, our method aims at provid-ing all the (DRUG, DISEASE) concepts within thedocument that represent a cause-effect relation.We cope with real discharge EHRs written byaround 400 different doctors.
These records arenot written in a template, that is, the EHRs do notfollow a pre-determined structure, and this, by it-self entails a challenge.
The EHRs we are dealingwith are written in a free structure using naturallanguage, non-standard abbreviations etc.
More-over, we tackle Spanish language, for which littlework has been carried out.
In addition, we do notonly aim at single concept-words but also at con-cepts based on multi-word terms.2 System overviewThe system, as depicted in Figure 2 entails twostages.EHRStage 1:ANNOTATINGCONCEPTSStage 2:EXTRACTINGEVENTSMARKEDEHRFigure 2: The ADR event extraction system.In the first stage, relevant pairs of concepts haveto be identified within an EHR.
Concept annota-tion is accomplished by means of a shallow anal-yser system (described in section 2.1).
Once theanalyser has detected (DRUG, DISEASE) pairs ina document, all the pairs will be examined byan inferred supervised classifier (described in sec-tion 2.2).2.1 Annotating concepts by shallow analysisThe first stage of the system has to detect and an-notate two types of semantic concepts: drugs anddiseases.
Each concept, as requested by the phar-macy service, should gather several sub-conceptsstated as follows:1.
DRUG concept:(a) Generic names for pharmaceuticaldrugs: e.g.
corticoids;(b) Brand-names for pharmaceutical drugs:e.g.
Aspirin;(c) Active ingredients: e.g.
vancomycin;(d) Substances: e.g.
dust, rubber;2.
DISEASE concept:(a) Diseases(b) Signs(c) SymptomsThese concepts were identified by means of ageneral purpose analyser available for Spanish,called FreeLing (Padr?o et al., 2010), that had beenenhanced with medical ontologies and dictionar-ies, such as SNOMED-CT, BotPLUS, ICD-9-CM,etc.
(Oronoz et al., 2013).
This toolkit is ableto identify multi-word context-terms, lemmas andalso POS tags.
An example of the morphological,semantic and syntactic analysis, provided by thisparser is given in Figure 3.
In the figure two piecesof information can be distinguished: for exam-ple, given the word ?secundarios?
(meaning sec-ondaries) 1) the POS tag provided is AQOM corre-sponding to Qualificative Adjective Ordinal Mas-culine Singular; and 2) the provided lemma is ?se-cundario?
(secondary).
Besides, in a third layer,the semantic tag is given, that is, the tag ?ENFER-MEDAD?
(meaning disease) involves the multi-word concept ?HTP severa?
(severe pulmonaryhypertension).86Figure 3: Lemmas, POS-tags and semantic tags are identified by the clinic domain analyser (diseases inyellow and drugs or substances in violet).2.2 Extracting adverse drug reaction eventsusing inferred classifiersThe goal of the second stage is to determine if agiven (DRUG, DISEASE) pair represents an ADRevent or not.
On account of this, we resorted tosupervised classification models.
These modelscan be automatically inferred from a set of doc-uments in which the target concepts had been pre-viously annotated.
Hence, first of all, a set of an-notated data representative for the task is required.To this end, our starting point is a manually anno-tated corpus (presented in section 2.2.1).
Besides,in order to automatically learn the classifier, the(DRUG, DISEASE) pairs have to be described in anoperative way, that is, in terms of a finite-set offeatures (see section 2.2.2).
The supervised clas-sification model selected was a type of ensembleclassifier: Random Forests (for further details turnto section 2.2.3).2.2.1 Producing an annotated setA supervised classifier was inferred from an-notated real EHRs.
The annotation was carriedout by doctors from the same hospital that pro-duced the EHRs.
Given the text with the con-cepts marked on the first stage (turn to section 2.1)and represented within the framework provided byBrat1, around 4 doctors from the same hospital an-notated the events.
This annotated set would workas a source of data to get instances that wouldserve to train supervised classification models, asthe one referred in section 2.2.2.2.2 Operational description of eventsAs it is well-known, the success of the techniquesbased on Machine Learning relies upon the fea-tures used to describe the instances.
Hence, we se-lected the following features that eventually have1Brat is the framework a priori selected as the outputfront-end shown in Figure 1proven useful to capture the semantic relations be-tween ADRs.
The features can be organised in thefollowing sets:?
Concept-words and context-words: to beprecise, we make use of entire termsincluding both single-words and multi-words.?
DRUG concept-word together withleft and right context words (a con-text up to 3, yielding, thus, 7 fea-tures).?
DISEASE concept-word togetherwith left and right context words (7features).?
Concept-lemmas and context-lemmasfor both drug and disease (14 featuresoverall)?
Concept-POS and context-POS for bothdrug and disease (14 features)?
Negation and speculation: these arebinary valued features to determinewhether the concept words or their con-text was either negated or speculated (2features).?
Presence/absence of other drugs in thecontext of the target drug and disease (12features)?
Distance: the number of characters fromthe DRUG concept to the DISEASE con-cept (1 feature).2.2.3 Inferring a supervised classifierGiven the operational description of a set of(DRUG, DISEASE) pairs, this stage has to deter-87mine if there exists an ADR event (that is, a cause-effect relation) or not.
To do so, we resortedto Random Forests (RFs), a variety of ensemblemodels.
RFs combine a number of decision treesbeing each tree built on the basis of the C4.5 algo-rithm (Quinlan, 1993) but with a distinctive char-acteristic: some randomness is introduced in theorder in which the nodes are generated.
Particu-larly, each time a node is generated in the tree, in-stead of chosing the attribute that maximizes theInformation Gain, the attribute is randomly se-lected amongst the k best options.
We made useof the implementation of this algorithm availablein Weka-6.9 (Hall et al., 2009).
Ensemble modelswere proved useful on drug-drug interaction ex-traction tasks (Thomas et al., 2011).3 Experimental resultsWe count on data consisting of discharge sum-maries from Galdakao-Usansolo Hospital.
Therecords are semi-structured in the sense that thereare two main fields: the first one for personal dataof the patient (age, dates relating to admittance)that were not provided by the hospital for privacyissues; and the second one, our target, a singlefield that contains the antecedents, treatment, clin-ical analysis, etc.
This second field is an unstruc-tured section (some hospitals rely upon templatesthat divide this field into several subfields, provid-ing it with further structure).
The discharge notesdescribe a chronological development of the pa-tient?s condition, the undergone treatments, andalso the clinical tests that were carried out.Given the entire set of manually annotated doc-uments, 34% were randomly selected without re-placement to produce the evaluation set.
The re-sulting partition is presented in Table 1 (where thetrain and evaluation sets are referred to as Trainand Eval respectivelly).Documents Concepts RelationsTrain 144 6,105 4,675Eval 50 2,206 1,598Table 1: Quantitative description of the data.All together, there are 194 EHRs manuallytagged with more than 8,000 concepts (entailingdiseases, symptoms, drugs, substances and proce-dures).
From these EHRs all the (DRUG,DISEASE)pairs are taken into account as event candidates,and these are referred to as relations in Table 1.The system was assessed using per-class aver-aged precision, recall and f1-measure as presentedin Table 2.Precision Recall F1-measure0.932 0.849 0.883Table 2: Experimental results.Semantic knowledge and contextual featureshave proven very relevant to detect cause-effect re-lations.
Particularly, those used to detect the con-cepts and also negation or speculation of the con-text in which the concept appear.A manual inspection was carried out on both thefalse positives and false negative predictions andthe following conclusions were drawn:?
The majority of false positives were causedby i) pairs of concepts at a very long distance;ii) pairs where one of the elements is relatedto past-events undergone while the other el-ement is in the current treatment prescribed(e.g.
the disease is in the antecedents and thedrug in the current diagnostics).?
The vast majority of false negatives weredue to concepts in the same sentence wherethe context-words are irrelevant (e.g.
fillerwords, determiners, etc.
).4 Concluding Remarks and Future WorkThis work presents a system that first identifies rel-evant pairs of concepts in EHRs by means of ashallow analysis and next examines all the pairsby an inferred supervised classifier to determine ifa given pair represents a cause-effect event.
A rel-evant contribution of this work is that we extractevents occurring between concepts that are in dif-ferent sentences.
In addition, this is one of the firstworks on medical event extraction for Spanish.Our aim for future work is to determine whetherthe (DRUG, DISEASE) pair represents either a rela-tion where 1) the drug is to overcome the disease;2) the drug causes the disease; 3) there is no rela-tionship between the drug and the disease.The aim of context features is to capture charac-teristics of the text surrounding the relevant con-cepts that trigger a relation.
More features couldalso be explored such as trigger words, regular pat-terns, n-grams, etc.88AcknowledgmentsThe authors would like to thank the Pharmacyand Pharmacovigilance services of Galdakao-Usansolo Hospital.This work was partially supported by the Euro-pean Commission (325099 and SEP-210087649),the Spanish Ministry of Science and Innovation(TIN2012-38584-C06-02) and the Industry of theBasque Government (IT344-10).ReferencesJari Bj?orne, Filip Ginter, Sampo Pyysalo, Jun?ichi Tsu-jii, and Tapio Salakoski.
2010.
Complex event ex-traction at pubmed scale.
Bioinformatics [ISMB],26(12):382?390.Taxiarchis Botsis, Michael D. Nguyen, Emily JaneWoo, Marianthi Markatou, and Robert Ball.
2011.Text mining for the vaccine adverse event reportingsystem: medical text classification using informativefeature selection.
JAMIA, 18(5):631?638.Mark Hall, Eibe Frank, Geoffrey Holmes, BernhardPfahringer, Peter Reutemann, and Ian H. Witten.2009.
The WEKA data mining software: An up-date.
SIGKDD Explorations, 11(1):10?18.Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, RobertBossy, Ngan Nguyen, and Jun?ichi Tsujii.
2011.Overview of bionlp shared task 2011.
InProceedings of the BioNLP Shared Task 2011Workshop, pages 1?6.
Association for Computa-tional Linguistics.Claudiu Mihaila, Tomoko Ohta, Sampo Pyysalo, andSophia Ananiadou.
2013.
Biocause: Annotatingand analysing causality in the biomedical domain.BMC Bioinformatics, 14:2.Maite Oronoz, Arantza Casillas, Koldo Gojenola, andAlicia Perez.
2013.
Automatic annotation ofmedical records in Spanish with disease, drug andsubstance names.
In Lecture Notes in ComputerScience, volume 8259, pages 536?547.
Springer-Verlag.Lluis Padr?o, S. Reese, Eneko Agirre, and Aitor Soroa.2010.
Semantic Services in Freeling 2.1: WordNetand UKB.
In Global Wordnet Conference, Mumbai,India.Ross Quinlan.
1993.
C4.5: Programs for MachineLearning.
Morgan Kaufmann Publishers, San Ma-teo, CA.Bryan Rink, Sanda Harabagiu, and Kirk Roberts.2011.
Automatic extraction of relations betweenmedical concepts in clinical texts.
JAMIA, 18:594?600.Isabel Segura-Bedmar, P Mart?
?nez, and Mar?a Herrero-Zazo.
2013.
Semeval-2013 task 9: Extraction ofdrug-drug interactions from biomedical texts (ddiex-traction 2013).
Proceedings of Semeval, pages 341?350.Pontus Stenetorp, Sampo Pyysalo, Goran Topi?c,Tomoko Ohta, Sophia Ananiadou, and Jun?ichi Tsu-jii.
2012.
Brat: A web-based tool for nlp-assisted text annotation.
In In Proceedings of theDemonstrations Session at EACL 2012.Philippe Thomas, Mariana Neves, Ill?es Solt,Domonkos Tikk, and Ulf Leser.
2011.
Relationextraction for drug-drug interactions using ensem-ble learning.
1st Challenge task on Drug-DrugInteraction Extraction (DDIExtraction 2011), pages11?18.Luca Toldo, Sanmitra Bhattacharya, and Harsha Gu-rulingappa.
2012.
Automated identification of ad-verse events from case reports using machine learn-ing.
In Workshop on Computational Methods inPharmacovigilance.Limsoon Wong.
2001.
A protein interaction extractionsystem.
In Pacific Symposium on Biocomputing,volume 6, pages 520?531.
Citeseer.89
