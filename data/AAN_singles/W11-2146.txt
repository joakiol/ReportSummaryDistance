Proceedings of the 6th Workshop on Statistical Machine Translation, pages 386?392,Edinburgh, Scotland, UK, July 30?31, 2011. c?2011 Association for Computational LinguisticsCMU Haitian Creole-English Translation System for WMT 2011Sanjika Hewavitharana, Nguyen Bach, Qin Gao, Vamshi Ambati, Stephan VogelLanguage Technologies InstituteCarnegie Mellon UniversityPittsburgh, PA 15213, USA{sanjika,nbach,qing,vamshi,vogel+}@cs.cmu.eduAbstractThis paper describes the statistical machinetranslation system submitted to the WMT11Featured Translation Task, which involvestranslating Haitian Creole SMS messages intoEnglish.
In our experiments we try to ad-dress the issue of noise in the training data,as well as the lack of parallel training data.Spelling normalization is applied to reduceout-of-vocabulary words in the corpus.
Us-ing Semantic Role Labeling rules we expandthe available training corpus.
Additionally weinvestigate extracting parallel sentences fromcomparable data to enhance the available par-allel data.1 IntroductionIn this paper we describe the CMU-SMT HaitianCreole-English translation system that was built aspart of the Featured Translation Task of the WMT11.The task involved translating text (SMS) messagesthat were collected during the humanitarian opera-tions in the aftermath of the earthquake in Haiti in2010.Due to the circumstances of this situation, theSMS messages were often noisy, and contained in-complete information.
Additionally they sometimescontained text from other languages (e.g.
French).As is typical in SMS messages, abbreviated text (aswell as misspelled words) were present.
Further,since the Haitian Creole orthography is not fullystandardized (Allen, 1998), the text inherently con-tained several different spelling variants.These messages were translated into English bya group of volunteers during the disaster response.The background and the details of this crowdsourc-ing translation effort is discussed in Munro (2010).Some translations contain additional annotationswhich are not part of the original SMS, possiblyadded by the translators to clarify certain issues withthe original message.
Along with the noise, spellingvariants, and fragmented nature of the SMS mes-sages, the annotations contribute to the overall diffi-culty in building a machine translation system withthis type of data.
We aim to address some of theseissues in out effort.Another challenge with building a Haitian Creole-English translation system is the lack of paralleldata.
As Haitian Creole is a less commonly spo-ken language, the available resources are limited.Other than the manually translated SMS messages,the available Haitian Creole-English parallel datais about 2 million tokens, which is considerablysmaller than the parallel data available for the Stan-dard Translation Task of the WMT11.Lewis (2010) details the effort quickly putforth by the Microsoft Translator team in buildinga Haitian Creole-English translation system fromscratch, as part of the relief effort in Haiti.
We tooka similar approach to this shared task: rapidly build-ing a translation system to a new language pair uti-lizing available resources.
Within a short span (ofabout one week), we built a baseline translation sys-tem, identified the problems with the system, andexploited several approaches to rectify them and im-prove its overall performance.
We addressed the is-sues above (namely: noise in the data and sparsity ofparallel data) when building our translation systemfor Haitian Creole-English task.
We also normalized386different spelling variations to reduce the number ofout-of-vocabulary (OOV) tokens in the corpus.
Weused Semantic Role Labeling to expand the availabletraining corpus.
Additionally we exploited other re-sources, such as comparable corpora, to extract par-allel data to enhance the limited amount of availableparallel data.The paper is organized as follows: Section 2presents the baseline system used, along with a de-scription of training and testing data used.
Section 3explains different preprocessing schemes that weretested for SMS data, and their effect on the trans-lation performance.
Corpus expansion approach isgiven in Section 4.
Parallel data extraction fromcomparable corpora is presented in section 5.
Wepresent our concluding remarks in Section 6.2 System ArchitectureThe WMT11 has provided a collection of HaitianCreole-English parallel data from a variety ofsources, including data from CMU1.
A summaryof the data is given in Table 1.
The primary in-domain data comprises the translated (noisy) SMSmessages.
The additional data contains newswiretext, medical dialogs, the Bible, several bilingualdictionaries, and parallel sentences from Wikipedia.Corpus Sentences Tokens (HT/EN)SMS messages 16,676 351K / 324KNewswire text 13,517 336K / 292KMedical dialog 1,619 10K / 10KDictionaries 42,178 97K / 92KOther 41,872 939K / 865KWikipedia 8,476 77K / 90KTotal 124,338 1.81M / 1.67MTable 1: Haitian Creole (HT) and English (EN) paralleldata provide by WMT11We preprocessed the data by separating the punc-tuations, and converting both sides into lower case.SMS data was further processed to normalize quo-tations and other punctuation marks, and to removeall markups.To build a baseline translation system we fol-lowed the recommended steps: generate word align-1www.speech.cs.cmu.edu/haitian/ments using GIZA++ (Och and Ney, 2003) andphrase extraction using Moses (Koehn et al, 2007).We built a 4-gram language model with the SRILM toolkit (Stolcke, 2002) using English side ofthe training corpus.
Model parameters for the lan-guage model, phrase table, and lexicalized reorder-ing model were optimized via minimum error-rate(MER) training (Och, 2003).The SMS test sets were provided in two formats:raw (r) and cleaned (cl), where the latter had beenmanually cleaned.
We used the SMS dev clean to op-timize the decoder parameters and the SMS devtestclean and SMS devtest raw as held-out evaluation sets.Each set contains 900 sentences.
A separate SMStest, with 1274 sentences, was used as the unseentest set in the final evaluation.
For each experimentwe report the case-insensitive BLEU (Papineni etal., 2002) score.Using the available training data we built severalbaseline systems: The first system (Parallel-OOD),uses all the out-of-domain parallel data except theWikipedia sentences.
The second system, in addi-tion, includes Wikipedia data.
The third system usesall available parallel training data (including both theout-of-domain data as well as in-domain SMS data).We used the third system as the baseline for laterexperiments.dev (cl) devtest (cl) devtest (r)Parallel-OOD 23.84 22.28 17.32+Wikipedia 23.89 22.42 17.37+SMS 32.28 33.49 29.95Table 2: Translation results in BLEU for different corporaTranslation results for different test sets using thethree systems are presented in Table 2.
No signifi-cant difference in BLEU was observed with the ad-dition of Wikipedia data.
However, a significantimprovement in performance can be seen when in-domain SMS data is added, despite the fact that thisis noisy data.
Because of this, we paid special atten-tion to clean the noisy SMS data.3 Preprocessing of SMS DataIn this section we explain two approaches that weexplored to reduce the noise in the SMS data.3873.1 Lexicon-based Collapsing of OOV WordsWe observed that a number of words in the raw SMSdata consisted of asterisks or special character sym-bols.
This seems to occur because either users hadto type with a phone-based keyboard or simply dueto processing errors in the pipeline.
Our aim, there-fore, was to collapse these incorrectly spelled wordsto their closest vocabulary entires from the rest ofthe data.We first built a lexicon of words using the entiredata provided for the Featured Task.
We then builta second probabilistic lexicon by cross-referencingSMS dev raw with the cleaned-up SMS dev clean.The first resource can be treated as a dictionarywhile the second is a look-up table.
We processedincoming text by first selecting all the words withspecial characters in the text, and then computingan edit distance with each of the words in the firstlexicon.
We return the most frequent word that isthe closest match as a substitute.
For all words thatdon?t have a closest match, we looked them up in theprobabilistic dictionary and return a potential substi-tution if it exists.
As the probabilistic dictionary isconstructed using a very small amount of data, thetwo-level lookup helps to place less trust in it anduse it only as a back-off option for a missing matchin the larger lexicon.This approach only collapses words with specialcharacters to their closest in-vocabulary words.
Itdoes not make a significant difference to the OOVratios, but reduces the number of tokens in thedataset.
Using this approach we were able to col-lapse about 80% of the words with special charactersto existing vocabulary entries.3.2 Spelling NormalizationOne of the most problematic issues in Haitian Cre-ole SMS translation system is misspelled words.When training data contains misspelled words, thetranslation system performance will be affected atseveral levels, such as word alignment, phrase/ruleextractions, and tuning parameters (Bertoldi et al,2010).
Therefore, it is desirable to perform spellingcorrection on the data.
Spelling correction basedon the noisy channel model has been explored in(Kernighan et al, 1990; Brill and Moore, 2000;Toutanova and Moore, 2002).
The model is gener-ally presented in the following form:p(c?|h) = argmax?cp(h|c)p(c) (1)where h is the Haitian Creole word, and c is a pos-sible correction.
p(c) is a source model which is aprior of word probabilities.
p(h|c) is an error modelor noisy channel model that accounts for spellingtransformations on letter sequences.Unfortunately, in the case of Haitian Creole SMSwe do not have sufficient data to estimate p(h|c)and p(c).
However, we can assume p(c|h) ?
p(c)and c is in the French vocabulary and is not an En-glish word.
The rationale for this, from linguisticpoint of view, is that Haitian Creole developed fromthe 18th century French.
As a result, an importantpart of the Haitian Creole lexicon is directly derivedfrom French.
Furthermore, SMS messages some-times were mixed with English words.
Therefore,we ignore c if it appears in an English dictionary.Given h, how do we get a list of possible normal-ization c and estimate p(c)?
We use edit distanceof 1 between h and c. An edit can be a deletion,transposition, substitution, or insertion.
If a wordhas l characters, there will be 66l+31 possible cor-rections2.
It may result in a large list.
However,we only keep possible normalizations which appearin a French dictionary and do not appear in an En-glish dictionary3.
To approximate p(c), we use theFrench parallel Giga training data from the SharedTask of the WMT11.
p(c) is estimated by MLE.
Fi-nally, our system chooses the French word with thehighest probability.dev (cl) devtest (cl) test (cl)Before 2.6 ; 16 2.7 ; 16 2.6 ; 16After 2.2 ; 13.63 2.3 ; 13.95 2.2 ; 14.3Table 3: Percentage of OOV tokens and types in test setsbefore and after performing spelling normalization.Table 3 shows that spelling normalization helpsto bring down the percentage of OOV tokens andtypes by 0.4% and 2% respectively on the three test2l deletions, l-1 transpositions, 32l substitutions, and 32(l+1)insertions; Haitian Creole orthography has 32 forms.3The English dictionary was created from the English Gigawordcorpus.388sets.
Some examples of Haitian Creole words andtheir French normalization are (tropikal:tropical),(economiques:economique), (irjan:iran), (idanti-fie:identifie).dev (cl) devtest (cl) devtest (r)Baseline 32.28 33.49 29.95S1 32.18 30.22 25.45S2 28.9 31.06 27.69Table 4: Translation results in BLEU with/withoutspelling correctionGiven the encouraging OOV reductions, we ap-plied the spelling normalization for the full corpus,and built new translation systems.
Our baseline sys-tem has no spelling correction (for the training cor-pus or the test sets); in S1, the spelling correctionsis applied to all words; in S2, the spelling correc-tion is only applied to Haitian Creole words that oc-cur only once or twice in the data.
In S1, 11.5% ofHaitian Creole words had been mapped to French,including high frequency words.
Meanwhile, 4.5%Haitian Creole words on training data were mappedto French words in S2.
Table 4 presents a compar-ison of translation performance of the baseline, S1and S2 for the SMS test sets.
Unfortunately, none ofsystems with spelling normalization outperformedthe system trained on the original data.
Restrictingthe spelling correction only to infrequent words (S2)performed better for the devtest sets, but not for thedev set, although all the test sets come from the samedomain.4 Corpus Expansion using Semantic RoleLabelingTo address the problem of limited resources, wetried to expand the training corpus by applying thecorpus expansion method described in (Gao and Vo-gel, 2011).
First, we parsed and labeled the semanticroles of the English side of the corpus, using the AS-SERT labeler (Pradhan et al, 2004).
Next, using theword alignment models of the parallel corpus, weextracted Semantic Role Label (SRL) substitutionrules.
SRL rules consist of source and target phrasesthat cover whole constituents of semantic roles, theverb frames they belong to, and the role labels ofthe constituents.
The source and target phrases mustcomply with the restrictions detailed in (Gao and Vo-gel, 2011).
Third, for each sentence, we replacedone of embedded SRL substitution rules with equiv-alent rules that have the same verb frame and thesame role label.The original method includes an additional butcrucial step of filtering out the grammatically incor-rect sentences using an SVM classifier, trained withlabeled samples.
However, we were unable to findHaitian Creole speakers who could manually labeltraining data for the filtering step.
Therefore, wewere forced to skip this filtering step.
We expandedthe full training corpus which contained 124K sen-tence pairs, resulting in an expanded corpus with505K sentences.
The expanded corpus was force-aligned using the word alignment models trainedon the original unexpanded corpus.
A new trans-lation system was built using the original plus theexpanded corpus.
As seen in Table 5, we observeda small improvement with the expanded corpus forthe raw devtest.
This method did not improve per-formance for the other two test sets.dev (cl) devtest (cl) devtest (r)Baseline 32.28 33.49 29.95+Expanded 31.79 32.98 30.1Table 5: Translation results in BLEU with/without corpusexpansionA possible explanation for this, in addition tothe missing component of filtering, is the low qual-ity of SRL parsing on the SMS corpus.
We ob-served a very small ratio of expansions in theHaitian Creole-English data, when compared to theChinese-English experiment shown in (Gao and Vo-gel, 2011).
The latter used a high quality corpus forthe expansion and the expanded corpus was 20 timeslarger than the original one.
Due to the noisy natureof the available parallel data, only 61K of the 124Ksentences were successfully parsed and SRL-labeledby the labeler.3895 Extracting Parallel Data fromComparable DataAs we only have a limited amount of parallel data,we focused on automatically extracting additionalparallel data from other available resources, such ascomparable corpora.
We were not able to find com-parable news articles in Haitian Creole and English.However, we found several hundred Haitian Creolemedical articles on the Web which were linked tocomparable English articles4.
Although some of themedical articles seemed to be direct translations ofeach other, converting the original pdf formats intotext did not produce sentence aligned parallel arti-cles.
Rather, it produced sentence fragments (some-times in different orders) due to the structural dif-ferences in the article pair.
Hence a parallel sen-tence detection technique was necessary to processthe data.
Because the SMS messages are related tothe disaster relief effort, which may include manywords in the medical domain, we believe the newlyextracted data may help improve translation perfor-mance.Following Munteanu and Marcu (2005), we useda Maximum Entropy classifier to identify compara-ble sentence.
To avoid the problem of having dif-ferent sentence orderings in the article pair, we takeevery source-target sentence pair in the two articles,and apply the classifier to detect if they are paral-lel.
The classifier approach is appealing to a low-resource language such as Haitian Creole, becausethe features for the classifier can be generated withminimal translation resources (i.e.
a translation lex-icon).5.1 Maximum Entropy ClassifierThe classifier probability can be defined as:Pr(ci|S, T ) =exp(?nj=1 ?jfij(ci, S, T ))Z(S, T )(2)where (S, T ) is a sentence pair, ci is the class, fijare feature functions and Z(S) is a normalizing fac-tor.
The parameters ?i are the weights for the featurefunctions and are estimated by optimizing on a train-ing data set.
For the task of classifying a sentencepair, there are two classes, c0 = non ?
parallel4Two main sources were: www.rhin.org and www.nlm.nih.govand c1 = parallel .
A value closer to one forPr(c1|S, T ) indicates that (S, T ) are parallel.The features are defined primarily based on trans-lation lexicon probabilities.
Rather than computingword alignment between the two sentences, we uselexical probabilities to determine alignment pointsas follows: a source word s is aligned to a tar-get word t if p(s|t) > 0.5.
Target word align-ment is computed similarly.
We defined a feature setwhich includes: length ratio and length differencebetween source and target sentences, lexical proba-bility scores similar to IBM model 1 (Brown et al,1993), number of aligned/unaligned words and thelength of the longest aligned word sequence.
Lexi-cal probability score, and alignment features gener-ate two sets of features based on translation lexicaobtained by training in both directions.
Features arenormalized with respect to the sentence length.5.2 Training and Testing the ClassifierTo train the model we need training examples thatbelong to each of the two classes: parallel and non-parallel.
Initially we used a subset of the availableparallel data as training examples for the classifier.This data was primarily sourced from medical con-versations and newswire text, whereas the compa-rable data was found in medical articles.
This mis-match in domain resulted in poor classification per-formance.
Therefore we manually aligned a set of250 Haitian Creole-English sentence pairs from themedical articles and divided them in to a training set(175 sentences) and a test set (100 sentences).The parallel sentence pairs were directly used aspositive examples.
In selecting negative examples,we followed the same approach as in (Munteanuand Marcu, 2005): pairing all source phrases withall target phrases, but filter out the parallel pairs andthose that have high length difference or a low lex-ical overlap, and then randomly select a subset ofphrase pairs as the negative training set.
The testset was generated in a similar manner.
The modelparameters were estimated using the GIS algorithm.We used the trained ME model to classify the sen-tences in the test set into the two classes, and noticehow many instances are classified correctly.Classification results are as given in Table 6.
Wenotice that even with a smaller training set, the clas-sifier produces results with high precision.
Using390Precision Recall F-1 ScoreTraining Set 93.90 77.00 84.61Test Set 85.53 74.29 79.52Table 6: Performance of the Classifierthe trained classifier, we processed 220 article pairswhich contained a total of 20K source sentencesand 18K target sentences.
The classifier selectedabout 10K sentences as parallel.
From these, we se-lected sentences where pr(c1|S, T ) > 0.7 for trans-lation experiments.
The extracted data expanded thesource vocabulary by about 5%.We built a second translation system by combin-ing the baseline parallel corpus and the extractedcorpus.
Table 7 shows the translation results for thissystem.dev (cl) devtest (cl) devtest (r)Baseline 32.28 33.49 29.95+Extracted 32.29 33.29 29.89Table 7: Translation results in BLEU with/without ex-tracted dataThe results indicate that there is no significant per-formance difference in using the extracted data.
Thismay be due to the relatively small size of the com-parable corpus we used when extract the data.6 ConclusionBuilding an MT system to translate Haitian CreoleSMS messages involved several challenges.
Therewas only a limited amount of parallel data to trainthe models.
The SMS messages tend to be quitenoisy.
After building a baseline MT system, weinvestigated several approaches to improve its per-formance.
In particular, we tried collapsing OOVwords using a lexicon generated with clean data, andnormalize different variations in spelling.
However,these methods did not results in improved translationperformance.We tried to address the data sparseness problemwith two approaches: expanding the corpus usingSRL rules, and extracting parallel sentences froma collection of comparable documents.
Corpus ex-pansion showed a small improvement for the rawdevtest.
Both corpus expansion and parallel dataextraction did not have a positive impact on othertest sets.
Both these methods have shown significantperformance improvement in the past in large datascenarios (for Chinese-English and Arabic-English),but failed to show improvements in the current low-data scenario.
Thus, we need further investigationsin handling noisy data, especially in low-resourcescenarios.AcknowledgmentWe thank Julianne Mentzer for assisting with editingand proofreading the final version of the paper.
Wealso thank the anonymous reviewers for their valu-able comments.ReferencesJeff Allen.
1998.
Lexical variation in haitian cre-ole and orthographic issues for machine translation(MT) and optical character recognition (OCR) appli-cations.
In Proceedings of the First Workshop on Em-bedded Machine Translation systems of AMTA confer-ence, Philadelphia, Pennsylvania, USA, October.Nicola Bertoldi, Mauro Cettolo, and Marcello Federico.2010.
Statistical machine translation of texts with mis-spelled words.
In Human Language Technologies:The 2010 Annual Conference of the North AmericanChapter of the Association for Computational Linguis-tics, Los Angeles, California, June.Eric Brill and Robert C. Moore.
2000.
An improvederror model for noisy channel spelling correction.
InProceedings of the 38th Annual Meeting on Associa-tion for Computational Linguistics (ACL 2000), pages286?293.Peter F. Brown, Stephen A. Della Pietra, Vincent J. DellaPietra, and Robert L. Mercer.
1993.
The mathematicsof statistical machine translation: Parameter estima-tion.
Computational Linguistics, 19(2):263?311.Qin Gao and Stephan Vogel.
2011.
Corpus expansionfor statistical machine translation with semantic rolelabel substitution rules.
In Proceedings of the 49thAnnual Meeting of the Association for ComputationalLinguistics: Human Language Technologies, Portland,Oregon, USA, June.Mark D. Kernighan, Kenneth W. Church, and William A.Gale.
1990.
A spelling correction program based ona noisy channel model.
In Proceedings of the 13thconference on Computational linguistics - Volume 2,COLING ?90, pages 205?210.391Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open sourcetoolkit for statistical machine translation.
In Proceed-ings of the 45th Annual Meeting of the Association forComputational Linguistics, Prague, Czech Republic,June.William Lewis.
2010.
Haitian Creole: How to build andship an mt engine from scratch in 4 days, 17 hours, &30 minutes.
In Proceedings of the 14th Annual confer-ence of the European Association for Machine Trans-lation (EAMT), Saint-Raphae?l, France, May.Robert Munro.
2010.
Crowdsourced translation foremergency response in haiti: the global collaborationof local knowledge.
In AMTA Workshop on Collab-orative Crowdsourcing for Translation, Denver, Col-orado, USA, October-November.Dragos Stefan Munteanu and Daniel Marcu.
2005.
Im-proving machine translation performance by exploit-ing non-parallel corpora.
Computational Linguistics,31(4):477?504.Franz Josef Och and Hermann Ney.
2003.
A system-atic comparison of various statistical alignment mod-els.
Computational Linguistics, 29(1):19?51.Franz Josef Och.
2003.
Minimum error rate training instatistical machine translation.
In Proceedings of the41st Annual Meeting of the Association for Computa-tional Linguistics, pages 160?167, Sapporo, Japan.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: a method for automatic evalua-tion of machine translation.
In Proceedings of the 40thAnnual Meeting of the Association for ComputationalLinguistics, pages 311?318, Philadelphia, Pennsylva-nia, USA, July.Sameer S. Pradhan, Wayne Ward, Kadri Hacioglu,James H. Martin, and Daniel Jurafsky.
2004.
Shal-low semantic parsing using support vector machines.In Proceedings of the Human Language TechnologyConference/North American chapter of the Associa-tion for Computational Linguistics annual meeting(HLT/NAACL-2004).Andreas Stolcke.
2002.
An extensible language model-ing toolkit.
In Proc.
of International Conference onSpoken Language Processing, volume 2, pages 901?904, Denver, CO, September.Kristina Toutanova and Robert Moore.
2002.
Pronun-ciation modeling for improved spelling correction.
In40th Annual Meeting of the Association for Computa-tional Linguistics (ACL 2002).392
