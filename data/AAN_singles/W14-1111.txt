Proceedings of the 5th International Workshop on Health Text Mining and Information Analysis (Louhi) @ EACL 2014, pages 75?79,Gothenburg, Sweden, April 26-30 2014. c?2014 Association for Computational LinguisticsPrecise Medication Extraction using Agile Text MiningChaitanya Shivade*,  James Cormack?, David Milward?
*The Ohio State University, Columbus, Ohio, USA?Linguamatics Ltd, Cambridge, UKshivade@cse.ohio-state.edu,{james.cormack,david.milward}@linguamatics.comAbstractAgile text mining is widely used for commercialtext mining in the pharmaceutical industry.
It canbe applied without building an annotated trainingcorpus, so is well-suited to novel or one-offextraction tasks.
In this work we wanted to see howefficiently it could be adapted for healthcareextraction tasks such as medication extraction.
Theaim was to identify medication names, associateddosage, route of administration, frequency,duration and reason, as specified in the 2009 i2b2medication challenge.Queries were constructed based on 696 dischargesummaries available as training data.
Performancewas measured on a test dataset of 251 unseendocuments.
F1-scores were calculated bycomparing system annotations against ground truthprovided for the test data.Despite the short amount of time spent in adaptingthe system to this task, it achieved high precisionand reasonable recall (precision of 0.92, recall of0.715).
It would have ranked fourth in comparisonto the original challenge participants on the basis ofits F-score of 0.805 for phrase level horizontalevaluation.
This shows that agile text mining is aneffective approach towards information extractionthat can yield highly accurate results.1 IntroductionMedication information occupies a sizeableportion of clinical notes, especially dischargesummaries.
This includes medications onadmission, during hospital course, and atdischarge.
This information is useful for clinicaltasks such as inferring adverse drug reactions,clinical trial recruitment, etc.
The i2b2 NaturalLanguage Processing (NLP) challengesencourage the development of systems forclinical applications, using a shared task,publicly available clinical data, and comparisonof performance with the other participatingsystems, subject to rigid evaluation metrics.
The2009 challenge (Uzuner, Solti, & Cadag, 2010)aimed to extract mentions of medication names,associated dosage, route of administration,frequency, duration and the reason formedication.The project used the Linguamatics InteractiveInformation Extraction (I2E) platform.
Thiscombines NLP,  terminologies and searchtechnology to provide a unique ?agile?
textmining approach (Milward et al., 2005) that canyield highly precise results in a small amount oftime.
The approach involves semantic annotationand indexing of data followed by interactivedesign of queries that capture typical syntacticand semantic features of the desired information.While the system uses machine learningapproaches within its core linguistic processing,the final set of queries are essentiallysyntactic/semantic rules identifying specificinformation in the text.2 Section IdentificationAlthough discharge summaries are considered tobe unstructured data, there are typicalcharacteristics associated with them.
There is aspecific flow of information within everydischarge summary, starting with details ofpatient?s admission, followed by the hospitalcourse and ending with discharge instructions.Other common sections include chief complaint,physical examination, etc.
There were more thantwenty headings to express dischargemedications in the training data (?Medications ondischarge,?
?Discharge meds,?
etc.).
The trainingdata was processed to identify section headingsand multiple forms of the same heading werenormalized to a single heading.
The plain text75was converted into XML with tags representingsection names.3 Offset InformationTo allow evaluation of results in the i2b2 format,the text was preprocessed to include linenumbers and word numbers as further XMLannotations.4 Natural Language ProcessingIndexing documents with I2E uses a standardNLP pipeline involving tokenization of the text,part-of-speech tagging, and linguistic chunking.The output of the pipeline provides usefullinguistic information, particularly about thelocation of noun phrases and verb phrases, foruse in entity extraction and querying.5 TerminologiesThe I2E platform uses hierarchical terminologiesto extract entities from the text.
These caninclude freely available terminologies such asMeSH, and the NCI thesaurus, as well asproprietary terminologies such as MedDRA.
Aseries of regular expressions allow for theindexing of numeric terms (integers, fractions,decimal numbers) and measurement units (length,time, weight, etc.).
In addition, customterminologies can be created for specific tasks bycombining or merging existing terminologies, orby using the system itself to help discoverterminology from the data.6 QueryingThe I2E framework provides an interactivequerying experience that is similar to a websearch.
While users can enter text queries just asone might in an internet search engine,  the queryinterface also allows specification of linguisticand non-linguistic units as ?containers?
for otherunits.
For example, it is possible to search for anoun phrase within a sentence and to specifywords, regular expressions and concepts fromterminologies.
Non-linguistic units can becustomized to regulate the ordering of itemswithin the container, the number of items thatmay occur between two items and whether theyare constrained by linguistic boundaries, such asthe sentence.
The output of the query can also becustomized so as to provide structuredrepresentation of the query results.As an example, one of the typical ways amedication is prescribed follows the construct:?Aspirin 625 mg p.o.
b.i.d.?
This means Aspirinwith a dosage of 625 milligrams is to beconsumed orally (p.o.
), twice a day (b.i.d.).
Aquery to capture this construct can be constructedas a non-linguistic phrase, starting with (a) apharmacological substance (a concept from theappropriate branch of the NCI-thesaurus),followed by (b) a numerical term, (c) a unit formeasuring weight, (d) a dosage abbreviation andfinally, (e) an abbreviation for the frequency ofmedication.A query containing items only for (a), (b) and (c)will give results for all phrases containing apharmacological substance followed by itsdosage (Aspirin 625 mg, Tylenol 350 mg, etc.
).The graphical query interface is sufficientlyflexible to allow many different orderings ofthese constructs and to negate false positiveresults.User defined terminologies can besystematically constructed to allow consistentmatching of lists of terms and to generate concisequeries.
For example, candidates forabbreviations corresponding to the route ofadministration were found by constructing aquery with items for (a), (b), (c) and (e) and anempty word container for (d).
This gave allphrases containing (a), (b), (c), and any word inthe discharge summary that was followed by (e).The results of this query were candidates forroute of administration.
The efficiency ofquerying in I2E provides an opportunity tointeractively refine parts of the final query anddiscover terms in the training data that might bemissed by regular expressions and thesauri.Queries can also be limited to specific sectionsof the document.
The pre-processing stepdescribed above identified sections in dischargesummaries of the i2b2 medications challenge76corpus.
The queries can thus be limited to only afew specific sections such as ?Medications onAdmission?
and ?Medications on Discharge?
byembedding the query in a section container.
Thechallenge specified not to include medicationsmentioned as allergies for a patient.
Resultsobtained in the allergies section of dischargesummaries were therefore ignored using thisapproach.7 Post-processingI2E?s default output is an HTML table withcolumns corresponding to different containersused in the query.
Output can also be limited topredefined columns of interest.
Multiple queriesare often required to capture different pieces ofinformation spread across the corpus.
In the i2b2challenge, there are multiple fields associatedwith every mention of medication.
A singlestructured record corresponding to every mentionof medication is expected as an output.
Spasic etal.
(2010) view the challenge as a template fillingtask where the participating system is expectedto fill slots in a template.
Thus, the output can beconfigured to be 6 columns representing each ofthe templates.
Following their terminology,different semantic queries filled different slots ofthe same template.
These slots were aggregatedinto a single template using post-processing.Multiple issues had to be taken care of in thisstep.
Different queries captured parts of the textcorresponding to the same slot.
For example, aquery aimed at capturing a particular linguisticconstruct may extract frequency as ?daily afterdinner,?
while another query may capture itssubstring ?daily.?
In this case, the formerextraction, which is the longer string, receivedpriority as per the challenge specifications.Another important problem encountered was thatof multiple matches for the same field.
Forexample, Insulin and Aspart were identified asseparate pharmacological substances during theindexing process.
However, ?Insulin aspart?
isconsidered as a single medication name as perthe challenge specifications.
Two separatetemplates are thus created.
The results of the postprocessing collapse them into one.
Certain termsfrom the terminologies did not match thedefinition of a medication, since terminologybranches are often generic.
For example, theChemicals and Drugs branch of MeSHconstitutes terms such as coffee.
Therefore, a listof false positives for medication namescorresponding to these matches was generatedfrom the training data.8 ExperimentsThe i2b2 website offers downloading of the NLPdataset for the 2009 challenge after signing aData Usage Agreement.
The training dataconsists of 696 discharge summaries.
A subset often documents with gold standard annotationshas been made available by the organizers.
Thetest dataset consists of 251 documents whichwere annotated by the participants under acommunity annotation experiment conducted bythe organizers (Uzuner, Solti, Xia, et al.
2010).These 251 documents and their correspondinggold standard annotations are also available.
Theperformance was calculated using phrase leveland token level metrics for horizontal andvertical evaluations as defined in (Uzuner, Solti,& Cadag, 2010).
The phrase level horizontalevaluation measures the performance of a systemacross all six fields.
This was used as a primarymetric to rank the results in the challenge.Terminology P R F1NCI  0.953 0.657 0.777MeSH  0.923 0.563 0.699NCI + MeSH  0.932 0.688 0.792NCI + FDA  0.947 0.678 0.790MeSH + FDA  0.921 0.571 0.705NCI + MeSH +FDA0.931 0.698 0.798NCI + MeSH +FDA + RxNorm0.92 0.715 0.805Table 1: Comparison of Different Terminologies.In order to assess the utility of differentterminologies, the same set of queries weremodified by replacing the concept from one withthe corresponding concept in another.
Forexample: Pharmacological substance from NCI77was replaced with Chemicals and Drugs fromMeSH.
This offered an objective way to comparethe coverage of MeSH and NCI with respect tomedication names.
Coverage of multipleterminologies can be leveraged by aggregatingthe results of queries resulting from differentterminologies.
NCI thesaurus, MeSH, a list ofFDA drug labels, and RxNorm were used.
Inaddition a custom terminology was prepared bycapturing medication names in the training datathat were missed by the terminologies.
The bestF-score was obtained when query results for allsources were aggregated.
Addition of sourcesresulted in a drop in precision but increasedrecall.
Table 1 summarizes these results, wherecolumns P and R denote precision and recallrespectively.9 ResultsTwenty teams representing 23 organizations andnine countries participated in the medicationchallenge.
The other systems used a variety ofrule-based, machine-learning and hybrid systems,with the most popular being rule-based systems(Uzuner et al., 2010).
The best ranked system,detailed in Patrick & Li (2009), was an exampleof a hybrid system, using both rule-based andstatistical classifiers.No.
Group P R F11 USyd  0.896 0.82 0.8572 Vanderbilt  0.840 0.803 0.8213 Manchester  0.864 0.766 0.812*  I2E  0.920 0.715 0.8054 NLM  0.784 0.823 0.8035 BME -Humboldt0.841 0.758 0.7976 OpenU  0.850 0.748 0.7967 UParis  0.799 0.761 7808 LIMSI  0.827 0.725 0.7739 UofUtah  0.832 0.715 0.76910 UWisconsinMadison0.904 0.661 0.764Table 2: Phrase level horizontal evaluationPhrase level horizontal evaluation was used as ametric to rank the performance of participants inthe challenge.
Table 2 compares the performanceof I2E with the top ten participants in thechallenge using this metric.
It achieves highlyprecise results as compared to other participantsof the challenge.
The vertical evaluation whichmeasures the performance along individual fieldsshowed that the system performed poorly onduration and reason, in common with othersystems.
As reported by the organizers of thechallenge (Uzuner et al., 2010), capturingduration and reason is a hard task.
They reportthat this is primarily due to the variation inlength and content of these fields in the trainingand testing data.10 ConclusionExtracting information through interactive designof queries can achieve highly precise results in ashort amount of time.
Much of the time in thisproject was spent on pre-processing documentsto allow the results to conform to the i2b2 format.The time taken on query development was of theorder of a few weeks, including a couple of daystraining in the system at the start of the project.This process requires far less specialistknowledge of Artificial Intelligence than othersolutions to this challenge and the easy to useinterface means refinement is straightforward.Clearly, recall still needs to be improved: ourbest system would have been ranked 4th out of21 systems in the phrase level horizontalevaluation.
Examination of the training materialsuggests this is due to gaps in the drug coverageprovided by the terminologies rather than gaps inthe query patterns.
We will therefore concentrateon extending drug coverage in our future work.AcknowledgmentsThe authors would like to thank Tracy Gregory,Himanshu Agarwal and Matthijs Vakar for theirhelp in this project.ReferencesMilward, D. et al., 2005.
Ontology-based interactiveinformation extraction from scientific abstracts.78Comparative and functional genomics, 6(1-2), pp.67?71.Spasic, I. et al., 2010.
Medication informationextraction with linguistic pattern matching andsemantic rules.
Journal of the American MedicalInformatics Association?
: JAMIA, 17(5), pp.532?5.Uzuner, O., Solti, I., Xia, F., et al., 2010.
Communityannotation experiment for ground truth generation forthe i2b2 medication challenge.
Journal of theAmerican Medical Informatics Association?
: JAMIA,17(5), pp.519?23.Uzuner, O. Solti, I.
& Cadag, E., 2010.
Extractingmedication information from clinical text.
Journal ofthe American Medical Informatics Association?
:JAMIA, 17(5), pp.514?8Patrick J & Li M. A Cascade Approach to ExtractingMedication Events.
Proceedings of the Third i2b2Workshop on Challenges in Natural LanguageProcessing for Clinical Data, 2009.79
