Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 106?111,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsAutomatically constructing Wordnet synsetsKhang Nhut Lam, Feras Al Tarouti and Jugal KalitaComputer Science departmentUniversity of Colorado1420 Austin Bluffs Pkwy, Colorado Springs, CO 80918, USA{klam2,faltarou,jkalita}@uccs.eduAbstractManually constructing a Wordnet is a dif-ficult task, needing years of experts?
time.As a first step to automatically constructfull Wordnets, we propose approaches togenerate Wordnet synsets for languagesboth resource-rich and resource-poor, us-ing publicly available Wordnets, a ma-chine translator and/or a single bilin-gual dictionary.
Our algorithms translatesynsets of existing Wordnets to a targetlanguage T, then apply a ranking methodon the translation candidates to find besttranslations in T. Our approaches are ap-plicable to any language which has at leastone existing bilingual dictionary translat-ing from English to it.1 IntroductionWordnets are intricate and substantive reposito-ries of lexical knowledge and have become im-portant resources for computational processing ofnatural languages and for information retrieval.Good quality Wordnets are available only for afew "resource-rich" languages such as English andJapanese.
Published approaches to automaticallybuild new Wordnets are manual or semi-automaticand can be used only for languages that alreadypossess some lexical resources.The Princeton Wordnet (PWN) (Fellbaum,1998) was painstakingly constructed manuallyover many decades.
Wordnets, except the PWN,have been usually constructed by one of two ap-proaches.
The first approach translates the PWNto T (Bilgin et al, 2004), (Barbu and Mititelu,2005), (Kaji and Watanabe, 2006), (Sagot andFi?er, 2008), (Saveski and Trajkovsk, 2010) and(Oliver and Climent, 2012); while the second ap-proach builds a Wordnet in T, and then alignsit with the PWN by generating translations (Gu-nawan and Saputra, 2010).
In terms of popular-ity, the first approach dominates over the secondapproach.
Wordnets generated using the secondapproach have different structures from the PWN;however, the complex agglutinative morphology,culture specific meanings and usages of words andphrases of target languages can be maintained.
Incontrast, Wordnets created using the first approachhave the same structure as the PWN.One of our goals is to automatically gener-ate high quality synsets, each of which is a setof cognitive synonyms, for Wordnets having thesame structure as the PWN in several languages.Therefore, we use the first approach to constructWordnets.
This paper discusses the first step of aproject to automatically build core Wordnets forlanguages with low amounts of resources (viz.,Arabic and Vietnamese), resource-poor languages(viz., Assamese) or endangered languages (viz.,Dimasa and Karbi)1.
The sizes and the qualitiesof freely existing resources, if any, for these lan-guages vary, but are not usually high.
Hence, oursecond goal is to use a limited number of freelyavailable resources in the target languages as in-put to our algorithms to ensure that our methodscan be felicitously used with languages that lackmuch resource.
In addition, our approaches needto have a capability to reduce noise coming fromthe existing resources that we use.
For transla-tion, we use a free machine translator (MT) andrestrict ourselves to using it as the only "dictio-nary" we can have.
For research purposes, we haveobtained free access to the Microsoft Translator,which supports translations among 44 languages.In particular, given public Wordnets aligned to thePWN ( such as the FinnWordNet (FWN) (Lind?n,2010) and the JapaneseWordNet (JWN) (Isahara etal., 2008) ) and the Microsoft Translator, we buildWordnet synsets for arb, asm, dis, ajz and vie.1ISO 693-3 codes of Arabic, Assamese, Dimasa, Karbiand Vietnamese are arb, asm, dis, ajz and vie, respectively.1062 Proposed approachesIn this section, we propose approaches to createWordnet synsets for a target languages T using ex-isting Wordnets and the MT and/or a single bilin-gual dictionary.
We take advantage of the factthat every synset in PWN has a unique offset-POS,referring to the offset for a synset with a partic-ular part-of-speech (POS) from the beginning ofits data file.
Each synset may have one or morewords, each of which may be in one or moresynsets.
Words in a synset have the same sense.The basic idea is to extract corresponding synsetsfor each offset-POS from existing Wordnets linkedto PWN, in several languages.
Next, we translateextracted synsets in each language to T to produceso-called synset candidates using MT.
Then, weapply a ranking method on these candidates to findthe correct words for a specific offset-POS in T.2.1 Generating synset candidatesWe propose three approaches to generate synsetcandidates for each offset-POS in T.2.1.1 The direct translation (DR) approachThe first approach directly translates synsets inPWN to T as in Figure 1.Figure 1: The DR approach to construct Wordnetsynsets in a target language T.For each offset-POS, we extract words in thatsynset from the PWN and translate them to the tar-get language to generate translation candidates.2.1.2 Approach using intermediate Wordnets(IW)To handle ambiguities in synset translation, wepropose the IW approach as in Figure 2.
Publiclyavailable Wordnets in various languages, whichwe call intermediate Wordnets, are used as re-sources to create synsets for Wordnets.
For eachoffset-POS, we extract its corresponding synsetsfrom intermediate Wordnets.
Then, the extractedsynsets, which are in different languages, aretranslated to T using MT to generate synset candi-dates.
Depending on which Wordnets are used andthe number of intermediate Wordnets, the num-ber of candidates in each synset and the numberof synsets in the new Wordnets change.Figure 2: The IW approach to construct Wordnetsynsets in a target language T2.1.3 Approach using intermediate Wordnetsand a dictionary (IWND)The IW approach for creating Wordnet synsets de-creases ambiguities in translations.
However, weneed more than one bilingual dictionary from eachintermediate languages to T. Such dictionaries arenot always available for many languages, espe-cially the ones that are resource poor.
The IWNDapproach is like the IW approach, but instead oftranslating immediately from the intermediate lan-guages to the target language, we translate synsetsextracted from intermediate Wordnets to English(eng), then translate them to the target language.The IWND approach is presented in Figure 3.Figure 3: The IWND approach to construct Word-net synsets1072.2 Ranking methodFor each of offset-POS, we have many translationcandidates.
A translation candidate with a higherrank is more likely to become a word belonging tothe corresponding offset-POS of the new Wordnetin the target language.
Candidates having the sameranks are treated similarly.
The rank value in therange 0.00 to 1.00.
The rank of a word w, the so-called rankw, is computed as below.rankw=occurwnumCandidates?numDstWordnetsnumWordnetswhere:- numCandidates is the total number of trans-lation candidates of an offset-POS- occurwis the occurrence count of the word win the numCandidates- numWordnets is the number of intermediateWordnets used, and- numDstWordnets is the number of distinct in-termediate Wordnets that have words trans-lated to the word w in the target language.Our motivation for this rank formula is the fol-lowing.
If a candidate has a higher occurrencecount, it has a greater chance to become a cor-rect translation.
Therefore, the occurrence countof each candidate needs to be taken into account.We normalize the occurrence count of a word bydividing it by numCandidates.
In addition, if acandidate is translated from different words hav-ing the same sense in different languages, this can-didate is more likely to be a correct translation.Hence, we multiply the first fraction by numDst-Wordnets.
To normalize, we divide results by thenumber of intermediate Wordnet used.For instance, in our experiments we use 4 in-termediate Wordnets, viz., PWN, FWN, JWN andWOLF Wordnet (WWN) (Sagot and Fi?er, 2008).The words in the offset-POS "00006802-v" ob-tained from all 4 Wordnets, their translations toarb, the occurrence count and the rank of eachtranslation are presented in the second, the fourthand the fifth columns, respectively, of Figure 4.2.3 Selecting candidates based on ranksWe separate candidates based on three cases as be-low.Case 1: A candidate w has the highest chanceto become a correct word belonging to a specificsynset in the target language if its rank is 1.0.
Thismeans that all intermediate Wordnets contain thesynset having a specific offset-POS and all wordsbelonging to these synsets are translated to theFigure 4: Example of calculating the ranks ofcandidates translated from words belonging to theoffset-POS "00006802-v" in 4 Wordnets: PWN,FWN, JWN and WWN.
The wordA, wordBandwordCare obtained from PWN, FWN and WWN,respectively.
The JWN does not contain this offset-POS.
TL presents transliterations of the words inarb.
The numWordnets is 4 and the numCandi-dates is 7.
The rank of each candidate is shown inthe last column of Figure 4.same word w. The more the number of intermedi-ate Wordnets used, the higher the chance the can-didate with the rank of 1.0 has to become the cor-rect translation.
Therefore, we accept all transla-tions that satisfy this criterion.
An example of thisscenario is presented in Figure 5.Figure 5: Example of Case 1: Using the IW ap-proach with four intermediate Wordnets, PWN,FWN, JWN and WWN.
All words belonging tothe offSet-POS "00952615-n" in all 4 Wordnets aretranslated to the same word "?i?n" in vie.
Theword "?i?n" is accepted as the correct word be-longing to the offSet-POS "00952615-n" in theVietnamese Wordnet we create.Case 2: If an offSet-POS does not have candi-dates having the rank of 1.0, we accept the candi-dates having the greatest rank.
Figure 6 shows theexample of the second scenario.Case 3: If all candidates of an offSet-POS hasthe same rank which is also the greatest rank, we108Figure 6: Example of Case 2: Using the IW ap-proach with three intermediate Wordnets, PWN,FWN and WWN.
For the offSet-POS "01437254-v", there is no candidate with the rank of 1.0.The highest rank of the candidates in "vie" is 0.67which is the word g?i.
We accept "g?i" as the cor-rect word in the offSet-POS "01437254-v" in theVietnamese Wordnet we create.skip these candidates.
Table 1 gives an example ofthe last scenario.Wordnet Words Cand.
RankPWN act h?nh ?
?ng 0.33PWN behave ho?t ?
?ng 0.33FWN do l?m 0.33Table 1: Example of Case 3: Using the DR ap-proach.
For the offSet-POS "00010435-v", thereis no candidate with the rank of 1.0.
The highestrank of the candidates in vie is 0.33.
All of 3 can-didates have the rank as same as the highest rank.Therefore, we do not accept any candidate as thecorrect word in the offSet-POS "00010435-v" inthe Vietnamese Wordnet we create.3 Experiments3.1 Publicly available WordnetsThe PWN is the oldest and the biggest availableWordnet.
It is also free.
Wordnets in manylanguages are being constructed and developed2.However, only a few of these Wordnets are of highquality and free for downloading.
The EuroWord-net (Vossen, 1998) is a multilingual database withWordnets in European languages (e.g., Dutch, Ital-ian and Spanish).
The AsianWordnet3providesa platform for building and sharing Wordnets forAsian languages (e.g., Mongolian, Thai and Viet-namese).
Unfortunately, the progress in buildingmost of these Wordnets is slow and they are farfrom being finished.2http://www.globalWordnet.org/gwa/Wordnet_table.html3http://www.asianWordnet.org/progressIn our current experiments as mentioned ear-lier, we use the PWN and other Wordnets linkedto the PWN 3.0 provided by the Open MultilingualWordnet4project (Bond and Foster, 2013): WWN,FWN and JWN.
Table 2 provides some details ofthe Wordnets used.Wordnet Synsets CoreJWN 57,179 95%FWN 116,763 100%PWN 117,659 100%WWN 59,091 92%Table 2: The number of synsets in the Wordnetslinked to the PWN 3.0 are obtained from the OpenMultilingual Wordnet, along with the percentageof synsets covered from the semi-automaticallycompiled list of 5,000 "core" word senses in PWN.Note that synsets which are not linked to the PWNare not taken into account.For languages not supported by MT, we usethree additional bilingual dictionaries: two dictio-naries Dict(eng,ajz) and Dict(eng,dis) provided byXobdo5; one Dict(eng,asm) created by integrat-ing two dictionaries Dict(eng,asm) provided byXobdo and Panlex6.
The dictionaries are of vary-ing qualities and sizes.
The total number of entriesin Dict(eng,ajz), Dict(eng,asm) and Dict(eng,dis)are 4682, 76634 and 6628, respectively.3.2 Experimental results and discussionAs previously mentioned, our primary goal is tobuild high quality synsets for Wordnets in lan-guages with low amount of resources: ajz, asm,arb, dis and vie.
The number of Wordnet synsetswe create for arb and vie using the DR approachand the coverage percentage compared to thePWN synsets are 4813 (4.10%) and 2983 (2.54%),respectively.
The number of synsets for eachWordnet we create using the IW approach withdifferent numbers of intermediate Wordnets andthe coverage percentage compared to the PWNsynsets are presented in Table 3.For the IWND approach, we use all 4 Wordnetsas intermediate resources.
The number of Wordnetsynsets we create using the IWND approach arepresented in Table 4.
We only construct Wordnetsynsets for ajz, asm and dis using the IWND ap-4http://compling.hss.ntu.edu.sg/omw/5http://www.xobdo.org/6http://panlex.org/109App.
Lang.
WNs Synsets % coverageIW arb 2 48,245 41.00%IW vie 2 42,938 36.49%IW arb 3 61,354 52.15%IW vie 3 57,439 48.82%IW arb 4 75,234 63.94%IW vie 4 72,010 61.20%Table 3: The number of Wordnet synsets we createusing the IW approach.
WNs is the number of in-termediate Wordnets used: 2: PWN and FWN, 3:PWN, FWN and JWN and 4: PWN, FWN, JWNand WWN.proach because these languages are not supportedby MT.App.
Lang.
Synsets % coverageIWND ajz 21,882 18.60%IWND arb 70,536 59.95%IWND asm 43,479 36.95%IWND dis 24,131 20.51%IWND vie 42,592 36.20%Table 4: The number of Wordnets synsets we cre-ate using the IWND approach.Finally, we combine all of the Wordnet synsetswe create using different approaches to generatethe final Wordnet synsets.
Table 5 presents the fi-nal number of Wordnet synsets we create and theircoverage percentage.Lang.
Synsets % coverageajz 21,882 18.60%arb 76,322 64.87%asm 43,479 36.95%dis 24,131 20.51%vie 98,210 83.47%Table 5: The number and the average score ofWordnets synsets we create.Evaluations were performed by volunteers whouse the language of the Wordnet as mother tongue.To achieve reliable judgment, we use the sameset of 500 offSet-POSs, randomly chosen from thesynsets we create.
Each volunteer was requestedto evaluate using a 5-point scale ?
5: excellent, 4:good, 3: average, 2: fair and 1: bad.
The aver-age score of Wordnet synsets for arb, asm and vieare 3.82, 3.78 and 3.75, respectively.
We noticethat the Wordnet synsets generated using the IWapproach with all 4 intermediate Wordnets havethe highest average score: 4.16/5.00 for arb and4.26/5.00 for vie.
We are in the process of findingvolunteers to evaluate the Wordnet synsets for ajzand dis.It is difficult to compare Wordnets because thelanguages involved in different papers are differ-ent, the number and quality of input resources varyand the evaluation methods are not standard.
How-ever, for the sake of completeness, we make an at-tempt at comparing our results with published pa-pers.
Although our score is not in terms of percent-age, we obtain the average score of 3.78/5.00 (orinformally and possibly incorrectly, 75.60% preci-sion) which we believe it is better than 55.30% ob-tained by (Bond et al, 2008) and 43.20% obtainedby (Charoenporn et al, 2008).
In addition, the av-erage coverage percentage of all Wordnet synsetswe create is 44.85% which is better than 12% in(Charoenporn et al, 2008) and 33276 synsets ('28.28%) in (Saveski and Trajkovsk, 2010) .The previous studies need more than one dic-tionary to translate between a target languageand intermediate-helper languages.
For exam-ple, to create the JWN, (Bond et al, 2008) needsthe Japanese-Multilingual dictionary, Japanese-English lexicon and Japanese-English life sci-ence dictionary.
For asm, there are a numberof Dict(eng,asm); to the best of our knowledgeonly two online dictionaries, both between engand asm, are available.
The IWND approach re-quires only one input dictionary between a pair oflanguages.
This is a strength of our method.4 Conclusion and future workWe present approaches to create Wordnet synsetsfor languages using available Wordnets, a publicMT and a single bilingual dictionary.
We createWordnet synsets with good accuracy and high cov-erage for languages with low resources (arb andvie), resource-poor (asm) and endangered (ajz anddis).
We believe that our work has the potentialto construct full Wordnets for languages which donot have many existing resources.
We are in theprocess of creating a Website where all Wordnetsynsets we create will be available, along with auser friendly interface to give feedback on individ-ual entries.
We will solicit feedback from commu-nities that use these languages as mother-tongue.Our goal is to use this feedback to improve thequality of the Wordnet synsets.
Some of Word-net synsets we created can be downloaded fromhttp://cs.uccs.edu/?linclab/projects.html.110ReferencesAntoni Oliver and Salvador Climent.
2012.
Parallelcorpora for Wordnet construction: Machine trans-lation vs. automatic sense tagging.
In Proceed-ings of the 13th International Conference on Com-putational Linguistics and Intelligent Text Process-ing (CICLing), volume part II, pages 110-121, NewDelhi, India, March.Beno?t Sagot and Darja Fi?er.
2008.
Building a freeFrench Wordnet from multilingual resources.
InProceedings of the Ontolex 2008 Workshop, Mar-rakech, Morocco, May.Fellbaum, Christiane.
1998.
Wordnet: An electroniclexical database.
MIT Press, Cambridge, Mas-sachusetts, USA.Francis Bond and Ryan Foster.
2013.
Linking and ex-tending an open multilingual Wordnet.
In Proceed-ings of the 51st Annual Meeting of the Associationfor Computational Linguistics (ACL), pages 1352?1362, Sofia, Bulgaria, August.Francis Bond, Hitoshi Isahara, Kyoko Kanzaki andKiyotaka Uchimoto.
2008.
Boot-strapping a Word-net using multiple existing Wordnets.
In Proceed-ings of the 6th International Conference on Lan-guage Resources and Evaluation (LREC), pages1619?1624, Genoa, Italy, May.Eduard Barbu and Verginica Barbu Mititelu.
2005.Automatic building of Wordnets.
In Proceedings ofthe International Conference on Recent Advances inNatural Language Processing (RANLP), Borovets,Bulgaria, September.Gunawan and Andy Saputra.
2010.
Building synsetsfor Indonesian Wordnet with monolingual lexical re-sources.
In Proceedings of the International Confer-ence on Asian Language Processing (IALP), pages297?300, Harbin, China, December.Hiroyuki Kaji and Mariko Watanabe.
2006.
Auto-matic construction of Japanese Wordnet.
In Pro-ceedings of the 5th International Conference onLanguage Resources and Evaluation (LREC), pages1262?1267, Genoa, Italy, May.Hitoshi Isahara, Francis Bond, Kiyotaka Uchimoto,Masao Utiyama and Kyoko Kanzaki.
2008.
De-velopment of Japanese Wordnet.
In Proceedings ofthe 6th International Conference on Language Re-sources and Evaluation (LREC), pages 2420?2423,Marrakech, Morocco, May.Krister Lind?n and Laur Carlson.
2010.
FinnWordnet -WordNet p?finska via ?vers?ttning, LexicoNordica.Nordic Journal of Lexicography, 17:119?140.Martin Saveski and Igor Trajkovsk.
2010.
Automaticconstruction of Wordnets by using machine transla-tion and language modeling.
In Proceedings of the13th Multiconference Information Society, Ljubl-jana, Slovenia.Orhan Bilgin, ?zlem ?entino?glu and Kemal Oflazer.2004.
Building a Wordnet for Turkish.
RomanianJournal of Information Science and Technology, 7(1-2): 163?172.Piek Vossen.
1998.
A multilingual database with lex-ical semantic networks.
Kluwer Academic Publish-ers, Dordrecht, Netherlands.Thatsanee Charoenporn, Virach Sornlertlamvanich,Chumpol Mokarat and Hitoshi Isahara.
2008.
Semi-automatic compilation of Asian Wordnet, In Pro-ceedings of the 14th Annual Meeting of the Associa-tion for Natural Language Processing, pages 1041?1044, Tokyo, Japan.111
