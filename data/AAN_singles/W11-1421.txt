Proceedings of the Sixth Workshop on Innovative Use of NLP for Building Educational Applications, pages 170?179,Portland, Oregon, 24 June 2011. c?2011 Association for Computational LinguisticsBilingual Random Walk Models for Automated Grammar Correction ofESL Author-Produced TextRandy West and Y. Albert ParkDepartment of Computer Science & EngineeringUniversity of California, San DiegoLa Jolla, CA 92093-0533{rdwest,yapark}@cs.ucsd.eduRoger LevyDepartment of LinguisticsUniversity of California, San DiegoLa Jolla, CA 92093-0533rlevy@ucsd.eduAbstractWe present a novel noisy channel model forcorrecting text produced by English as a sec-ond language (ESL) authors.
We model theEnglish word choices made by ESL authors asa random walk across an undirected bipartitedictionary graph composed of edges betweenEnglish words and associated words in an au-thor?s native language.
We present two suchmodels, using cascades of weighted finite-state transducers (wFSTs) to model languagemodel priors, random walk-induced noise, andobserved sentences, and expectation maxi-mization (EM) to learn model parameters af-ter Park and Levy (2011).
We show that suchmodels can make intelligent word substitu-tions to improve grammaticality in an unsu-pervised setting.1 IntroductionHow do language learners make word choices asthey compose text in a language in which they arenot fluent?
Anyone who has attempted to learn a for-eign language can attest to spending a great deal oftime leafing through the pages of a bilingual dictio-nary.
However, dictionaries, especially those with-out a wealth of example sentences or accompany-ing word sense information, can often lead even themost scrupulous of language learners in the wrongdirection.
Consider an example: the English noun?head?
has several senses, e.g.
the physical head andthe head of an organization.
However, the Japaneseatama can only mean the physical head or mind, andlikewise shuchou, meaning ?chief,?
can only map tothe second sense of head.
A native English speakerand Japanese learner faced with the choice of thesetwo words and no additional explanation of whichJapanese word corresponds to which sense is liableto make a mistake on the flip of a coin.One could of course conceive of more subtle ex-amples where the semantics of a set of choices arenot so blatantly orthogonal.
?Complete?
and ?en-tire?
are synonyms, but they are not necessarily in-terchangeable.
?Complete stranger?
is a commontwo-word phrase, but ?entire stranger?
sounds com-pletely strange, if not entirely ungrammatical, to thenative English speaker, who will correct ?entire?to ?complete?
in a surprisingly automatic fashion.Thus, correct word choice in non-native languageproduction is essential not only to the preservationof intended meaning, but also to fluent expression ofthe correct meaning.The development of software to correct ESL textis valuable for both learning and communication.A language learner provided instant grammatical-ity feedback during self-study is less likely to fallinto patterns of misuse, and the comprehension diffi-culties one may encounter when corresponding withnon-native speakers would be ameliorated by an au-tomated system to improve text fluency.
Addition-ally, since machine-translated text is often ungram-matical, automated grammar correction algorithmscan be deployed as part of a machine translation sys-tem to improve the quality of output.We propose that word choice production errorson the part of the language learner can be mod-eled as follows.
Given an observed word and anundirected bipartite graph with nodes representing170words in one of two languages, i.e.
English and thesentence author?s native tongue, and edges betweenwords in each language and their dictionary trans-lation in the other (see Figure 1 for an example),there exists some function f 7?
[0, 1] that definesthe parameters of a random walk along graph edges,conditioned on the source word.
By composing thisgraph with a language model prior such as an n-gram model or probabilistic context-free grammar,we can ?correct?
an observed sentence by inferringthe most likely unobserved sentence from which itoriginated.More concretely, given that we know f , we cancompute argmaxw?
p(w?|w, f, ?
), where w is theobserved sentence, ?
is the language model, and w?is the ?corrected,?
unobserved sentence.
Under thisview, some w?
drawn from the distribution ?
is sub-jected to some noise process f , which perturbs thesentence author?s intended meaning and outputs w.We perform this computation in the standard wayfrom the statistical machine translation (SMT) liter-ature (Brown et al, 1993), namely by using Bayes?theorem to writep(w?|w, f, ?)
= p(w?|?
)p(w|w?, f, ?)p(w|?
)Since the denominator of the RHS is independent ofw?, we can rewrite our argmax asargmaxw?p(w?|?
)p(w|w?, f, ?
)We have now decomposed our original equation intotwo manageable parts, a prior belief about the gram-maticality of an unobserved sentence w?, which wecan compute using a language model ?
learned sepa-rately using standard supervised techniques (in par-ticular, n-gram estimation), and the probability ofthe observed sentence w given w?, f , and ?.
To-gether, these constitute a noisy channel model frominformation theory (Shannon, 1948).
All that re-mains is to learn an appropriate f , for which we willemploy unsupervised methods, namely expectationmaximization.The rest of this paper is organized as follows.
InSection 2, we will discuss related work.
In Section3, we will present the implementation, methodologyand results of two experiments with different f .
InSection 4, we will discuss our experimental results,and we will conclude in Section 5.2 Related WorkThe literature on automated grammar correctionis mostly focused on rule-based methods and er-ror identification rather than correction.
However,there has been a recent outgrowth in the applica-tion of machine translation (MT) techniques to ad-dress the problem of single-language grammar cor-rection.
Park and Levy (2011) propose a noisy chan-nel model for learning to correct various types of er-rors, including article and preposition errors, word-form errors, and spelling mistakes, to which this pa-per is an extension.
As the present work builds onPark and Levy?s basic model, we will reserve a moredetailed discussion of their work for Section 3.Brockett et al (2006) use phrasal SMT techniquesto identify and correct mass noun errors of ESL stu-dents with some success, but they correct no otherproduction error classes to our knowledge.Lee and Seneff (2006) learn a method to aid ESLstudents in language acquisition by reducing sen-tences to their canonical form, i.e.
a lemmatizedform devoid of articles, prepositions, and auxil-iaries, and then building an over-specified lattice byreinserting all word inflections and removed wordclasses.
They then score this lattice using a trigrammodel and PCFG.
While this method has many ad-vantages, it does not take into account the full con-text of the original sentence.Kok and Brockett (2010) use random walks overbi- and multilingual graphs generated by aligningEnglish sentences with translations in 10 other Eu-ropean languages to learn paraphrases, which theythen evaluate in the context of the original sentence.While their approach shares many high-level simi-larities with ours, both their task, paraphrasing cor-rect sentences, and the details of their methodologyare divergent from the present work.De?silets and Hermet (2009) employ round-tripmachine translation from L1 to L2 and back againto correct second language learner text by keep-ing track of the word alignments between transla-tions.
They operate on a very similar hypothesisto that of this work, namely that language learnersmake overly-literal translations when the producetext in their second language.
However, they goabout correcting these errors in a very different waythan the present work, which is novel to the best of171Figure 1: Example English-Korean dictionary graph for a subset of the edges out of the English head, leader, andchief.head???????
??????
?????
?chiefleaderour knowledge, and their technique of using error-annotated sentences for evaluation makes a compar-ison difficult.3 Model Implementation and ExperimentsWe present the results of two experiments with dif-ferent random walk parametrizations.
We begin bydescribing our dataset, then proceed to an overviewof our model and experimental procedures, and fi-nally detail the experiments themselves.3.1 DatasetWe use the dataset of Park and Levy (2011), a col-lection of approximately 25,000 essays comprised of478,350 sentences scraped from web postings madeby Korean ESL students studying for the Test of En-glish as a Foreign Language (TOEFL).
Of these, werandomly select 10,000 sentences for training, 504as a development set, and 1017 held out for finalmodel evaluation.Our English-Korean dictionary is scraped fromhttp://endic2009.naver.com, a widely-used and trusted online dictionary source in SouthKorea.
We are unfortunately unaware of any freelyavailable, downloadable English-Korean dictionarydatabases.3.2 Model and Experimental Procedures3.2.1 OverviewThe bulk of our experimental methodology andmachinery is borrowed from Park and Levy (2011),so we will summarize that portion of it only brieflyhere.
At a high level, there are three major compo-nents to the model of a sentence: a language prior,a noise model, and an observed sentence.
Eachof these is implemented as a wFST and composedtogether into a single transducer whose acceptingpaths represent all possibilities of transducing froman (unobserved) input sentence to the (observed)output sentence, with the path weight being associ-ated probability.
See Figure 2 for an example.3.2.2 Language ModelFor our language model, we use a Kneser-Neysmoothed trigram model learned from a versionof the British National Corpus modified to useAmericanized spellings (Chen and Goodman, 1996;Burnard, 1995).
The implementation of an n-grammodel as a wFST requires that each state represent acontext, and so one must necessarily instantiate arcsfor all words in the alphabet from each state.
In orderto reduce model size and minimize memory usage, itis standard practice to remove relatively uninforma-tive higher-order n-grams from the model, but underthe wFST regime one cannot, for example, removesome trigrams from a bigram context without re-moving all of them.
Instead, we retain only the 1,000most informative bigram contexts, as measured bythe Kullback-Leibler divergence between each bi-gram context and its unigram counterpart.
This isin contrast to standard cutoff models, which removen-grams occurring less than some cutoff number oftimes in the corpus.3.2.3 Noise ModelsThe structure of the noise wFST differs for eachnoise model; for our model of word-choice error, wecan use a single initial/final state with arcs labeledwith unobserved words as input, observed words asoutput, and a weight defined by the function f thatgoverns the parameters of a random walk across ourdictionary graph (again, see Figure 2 for an exam-ple).
We will reserve the definition of f , which is172Figure 2: Example wFSTs for the sentence ?head chief?.From top to bottom, the pictured transducers are the ob-served sentence s, a noise model n with parameter ?, aunigram language model l representing the normalizedfrequency of each word, and the fully composed model,l ?
n ?
s.0 1head:head/12chief:chief/1Observed Sentence0leader:chief/(?/2)leader:head/(?/2)leader:leader/(1-?)chief:leader/(?/2)chief:head/(?/2)chief:chief/?head:chief/(?/2)head:leader/(?/2)head:head/(1-?
)Noise Model0chief:chief/(1/5)leader:leader/(3/10)head:head/(1/2)Language Model0 1head:head/((1-?)/2)leader:head/(3?/20)chief:head/(?/10)2head:chief/(?/4)leader:chief/(3?/20)chief:chief/((1-?
)/5)Composed Modeldifferent for each experiment, for Section 3.3.We have thus far proceeded by describing the con-struction of an ideal noise model that completelyimplements the dictionary graph described previ-ously.
However, due to the size of the dictionarygraph, such a model would be computationally pro-hibitive1.
Moreover, we must handle the non-trivialpeculiars of arbitrary lookups in a roughly lem-matized dictionary and preservation of word formsthrough random walks, which we discuss now.1The maximum degree of the dictionary graph is 515, mean-ing that the upper bound on the number of paths in a randomwalk of length 2 is 5152 = 265, 225!Among its various capabilities, the CELEX database(Baayen et al, 1995) provides interfaces for map-ping arbitrary English words to their lemmas, query-ing for lemma syntactic (sub)classes, and discover-ing the morphological inflectional features of arbi-trary words.
We use these capabilities in conjunctionwith unigram frequencies from our language modeland a standard stop word filter to build abridged setsof random walk candidates as in Algorithm 1.Algorithm 1 Build an abridged set of random walkcandidates C for an observed word w s.t.
eachci ?
C has syntactic and morphological characteris-tics similar to w and is in the top m such candidatesas sorted by word frequency.Let G = (V,E) be the undirected dictionarygraph, m the max candidates per word, B the setof stop words, I the set of inflectional features ofw, and C the set of random walk candidates forw, initially {}if w ?
B thenreturn {}end iffor lemmas l of w doLet S be the set of syntactic classes of lfor l?
generated from a random walk of length2 in G from l doif S ?
{syntactic classes of l?}
6= {} thenfor words w?
related to l?
doif I ?
{inflectional features of w?}
6={} ?w?
6?
B thenC ?
C ?
{w?
}end ifend forend ifend forend forif |C| > m thenC ?
top m members of C by word frequencyend ifreturn C3.2.4 Sentence ModelsSentences are simply identity transducers, i.e.wFSTs with n + 1 states for a sentence of lengthn and a single arc between each state 0 ?
i < n andstate i+1 labeled with input and output token i from173the sentence and weight 1.3.2.5 Training and DecodingFor training, we hold language model parametersconstant and use expectation maximization (Demp-ster et al, 1977) to learn noise model parameters asfollows.
We replace language model input symbolsand sentence model output symbols with the emptysymbol  and use the V-expectation semiring of Eis-ner (2002) to annotate noise model arcs with ini-tial parameter values.
This is our M-step.
Then,we compose the language, noise, and sentence mod-els, which produces a transducer with only -labeledarcs, and use -removal to move expectation infor-mation into a single state from which we can eas-ily read off expected noise model parameter countsthanks to the V-expectation semiring?s bookkeeping(Eisner, 2002; Mohri, 2001).
We repeat this pro-cess over a batch of training sentences and add theresults together to yield a final vector of expectedcounts.
This is our E-step.
Finally, we normalize theexpected parameter counts to recompute our param-eters and rebuild the noise model in a repetition ofthe M-step.
This process goes back and forth fromE- to M-step until the parameters converge withinsome threshold.The decoding or inference process is performedin a similar fashion, the main difference being thatwe use the negative log Viterbi semiring for com-puting shortest paths instead of the V-expectationsemiring.
We first build a new noise model for eachsentence using the parameter values learned duringtraining.
Then, the language, noise, and sentencemodels (sans  substitutions) are composed together,and the shortest path is computed.3.2.6 wFST ImplementationAll wFST manipulation is performed using Open-FST (Allauzen et al, 2007), an open sourceweighted finite-state transducer library written inC++.
Additionally, we use the V-expectation semir-ing code of Dreyer et al (2008) for training.3.2.7 EvaluationThe most probable unobserved sentence w?
fromwhich the observed sentence w was generated underour model, argmaxw?
p(w?|?
)p(w|w?, f, ?
), can beread off from the input of the transducer producedduring the decoding process.
In order to evaluateits quality versus the observed ESL sentence, weuse the METEOR2 and BLEU evaluation metrics formachine translation (Lavie and Agarwal, 2007; Pap-ineni et al, 2002).
This evaluation is performed us-ing a set of human-corrected sentences gathered viaAmazon Mechanical Turk, an online service whereworkers are paid to perform a short task, and furtherfiltered for correctness by an undergraduate researchassistant.
8 workers were assigned to correct eachsentence from the development and evaluation setsdescribed in Section 3.1, and so after filtering wehad 8 or fewer unique corrected versions per sen-tence available for evaluation.
We note that the useof METEOR and BLEU is justified inasmuch as theprocess of grammar correction is translation froman ungrammatical ?language?
to a grammatical one(Park and Levy, 2011).
However, it is far from per-fect, as we shall see shortly.While human evaluation is far too costly to at-tempt at every step during development, it is veryworthwhile to examine our corrections through a hu-man eye for final evaluation, especially given thesomewhat tenuous suitability of METEOR and BLEUfor our evaluation task.
In order to facilitate this, wedesigned a simple task, again using Amazon Me-chanical Turk, where native English speakers arepresented with side-by-side ESL and corrected sen-tences and asked to choose which is more correct.Workers are instructed to ?judge whether the cor-rected sentence improves the grammaticality and/orfluency of the ESL sentence without changing theESL sentence?s basic meaning.?
They are then pre-sented with two questions per sentence pair:1.
Question: ?Between the two sentences listedabove, which is more correct?
?Answer choices: ?ESL sentence is more cor-rect,?
?Corrected sentence is more correct,?
?Both are equally correct,?
and, ?The sentencesare identical.
?2Although the METEOR ?synonymy?
module may initiallyseem appropriate to our evaluation task, we find that it doeslittle to improve or clarify evaluation results.
For that reason,and moreover since we do not wish for differing forms of thesame lemma to be given equal weight in a grammar correctiontask, we instead use the ?exact?
module for all evaluation in thispaper.1742.
Question: ?Is the meaning of the corrected sen-tence significantly different from that of theESL sentence?
?Answer choices: ?Yes, the two sentences do notmean the same thing,?
and, ?No, the two sen-tences have roughly the same meaning.
?Each task is 10 sentences long, 3 of which are iden-tical filler sentences.
When a worker mislabels morethan one sentence as identical in any single task, theresults for that task are thrown out and resubmittedfor another worker to complete.
We additionally re-quire that each sentence pair be judged by 5 unique,U.S.-based workers.3.3 Experiments3.3.1 Experiment 1Motivation and Noise Model For our first exper-iment, we assume that the probability of arriving atsome word w?
6= w after a random walk of length2 from an observed word w is uniform across all w.This is perhaps not the most plausible model, but itserves as a baseline by which we can evaluate morecomplex models.More concretely, we use a single parameter ?modeling the probability of walking two steps alongthe dictionary graph from an observed English wordw to its Korean definition(s), and then back to someother English word w?
6= w. Since we treat un-observed words as transducer input and observedwords as output, ?
is normalized by |{w|w 6= w?}|,i.e.
the number of edges with different input and out-put per input word, and p(w|w) = 1 ?
?
such that?w p(w|w?)
= 1.Initialization and Other Settings We train twovariations on the same model, setting m from Al-gorithm 1, i.e.
the maximum number of allowedrandom walk candidates per word, to 5 and 10.
Weinitialize ?
to 0.01 for each.Results We find that both variations converge af-ter roughly 10 iterations3 .
The parameters learnedare slightly lower than the initialization value (?
=3Running on a Linux server with two quad-core Intel Xeonprocessors and 72GB of memory, training for all models in thispaper takes around 4 hours per model.
Note that decoding is amuch quicker process, requiring less than one second per sen-tence.0.01), 0.007246 for the 5 candidate variation and0.009528 for the 10 candidate variation.
We inter-pret the parameter value disparity between the twomodel variations as follows.
The larger the num-ber of random walk candidates available for eachobserved word, the more likely that at least one ofthe candidates has a high probability in the sentencecontext, so it makes sense that the 10 candidate vari-ation would yield a higher value for ?.
Moreover,recalling that ?
is normalized by the number of ob-served words |{w|w 6= w?
}| reachable from each un-observed candidate word w?, it is reasonable that ahigher value of ?
would need to be learned in orderto distribute enough probability mass to candidatesthat are highly probable in the sentence context.The METEOR and BLEU scores for this Experi-ment are summarized in Table 1, and the final pa-rameter values after 10 iterations are listed in Table2.
We discuss these in greater detail in Section 4.Table 1: METEOR and BLEU scores for all experiments.METEOR BLEUESL baseline 0.820802 0.715625Exp.
1, 5 candidates 0.816055 0.708871Exp.
1, 10 candidates 0.815703 0.708284Exp.
2, 5 candidates 0.815162 0.707549Exp.
2, 10 candidates 0.814533 0.706587Table 2: Final parameter values after 10 iterations for Ex-periment 1 with 5 and 10 word random walk candidatelimits.Max 5 Candidates Max 10 Candidates?
0.007246 0.0095283.3.2 Experiment 2Motivation and Noise Model For our second ex-periment, we hypothesize that there is an inverse re-lationship between unobserved word frequency andrandom walk path probability.
We motivate this byobserving that when a language learner produces acommon word, it is likely that she either meant touse that word or used it in place of a rarer word thatshe did not know.
Likewise, when she uses a rareword, it is likely that she chose it above any of the175common words that she knows.
If the word that shechose was erroneous, then, it is most likely that shedid not mean to use a common word but could havemeant to use a different rare word with a subtle se-mantic difference.
Hence, we should always preferto replace observed words, regardless of their fre-quency, with rare words unless the language modeloverwhelmingly prefers a common word.In order to model this hypothesis, we introducea second parameter ?
< 0 to which power theunigram frequency of each unobserved word w?,freq(w?
), is raised.
The resulting full model isp(w|w?
)w 6=w?
= freq(w?)?
?|{w|w 6=w?
}| and p(w|w) = 1 ?freq(w)??.
We approximate the full model to sim-ple coin flips by bucketing the unique word frequen-cies from the language model and initializing eachbucket using its average frequency and some appro-priate initial values of ?
and ?, leaving us with anumber of parameters equal to the number of fre-quency buckets.Initialization and Other Settings We train twovariations on the same model, setting m from Al-gorithm 1 to 5 and 10.
We initialize ?
to 0.01 and ?to ?0.1 for each and use 10 frequency buckets.Results As in Experiment 1, we find that bothmodel variations converge after roughly 10 itera-tions.
The random walk parameters learned forboth variations in the highest frequency bucket,freq(w?)??
?
0.004803 and 0.004845 for 5 and10 candidates, respectively, seem to validate ourhypothesis that we should prefer rare unobservedwords.
However, the parameters learned for the pro-ceeding buckets do not indicate the smooth positiveslope that we might have hoped for, which we dis-cuss further in Section 4.
The 10 candidate variationlearns consistently higher parameter values than the5 candidate variation, and we interpret this disparityin the same way as in Experiment 1.The METEOR and BLEU scores for this Experi-ment are summarized in Table 1, and the final pa-rameter values after 10 iterations are listed in Table3.
We discuss these in greater detail in Section 4.4 DiscussionAt first glance, the experimental results are less thansatisfactory.
However, METEOR and BLEU do notTable 3: Final parameter values after 10 iterations for Ex-periment 2 with 5 and 10 word random walk candidatelimits.Word Frequency Max 5 Max 10(high to low) Candidates CandidatesBucket 1 0.004803 0.004845Bucket 2 0.031505 0.052706Bucket 3 0.019211 0.036479Bucket 4 0.006871 0.013130Bucket 5 0.002603 0.005024Bucket 6 0.000032 0.000599Bucket 7 0.001908 0.003336Bucket 8 0.000609 0.002771Bucket 9 0.001256 0.002014Bucket 10 0.006085 0.006828tell the whole story.
At a high level, these metricswork by computing the level of agreement, e.g.
un-igram and bigram precision, between the sentencebeing evaluated and a pool of ?correct?
sentences(Lavie and Agarwal, 2007; Papineni et al, 2002).When the correct sentences agree strongly with eachother, the evaluated sentence is heavily penalizedfor any departures from the correct sentence pool.This sort of penalization can occur even when themodel-corrected sentence is a perfectly valid correc-tion that just had the misfortune of choosing a dif-ferent replacement word than the majority of the hu-man workers.
For example, one ESL sentence inour evaluation set reads, progress of medical sciencehelps human live longer.
All four of our models cor-rect this to progress of medical science helps peo-ple live longer, but none of the workers correct to?people,?
instead opting for ?humans.?
This issue isexacerbated by the fact that Mechanical Turk work-ers were instructed to change each ESL sentence aslittle as possible, which helps their consistency buthurts these particular models?
evaluation scores.With the exception of some mostly harmless butultimately useless exchanges, e.g.
changing ?reducemistakes?
to ?reduce errors,?
the models actually dofairly well when they correct ungrammatical wordsand phrases.
As we alluded to in Section 1, all fourmodel variations correct the sentence to begin with,i?d rather not room with someone who is a entirestranger to me from our development set to to be-176gin with, i?d rather not room with someone who isa complete stranger to me.
But only 2 out of 5 hu-man workers make this correction, 2 retain ?entire,?and 1 removes it altogether.
As another example, allmodel variations correct however, depending merelyon luck is very dangerous from our evaluation set tohowever, depending solely on luck is very danger-ous.
However, only 1 worker corrects ?merely?
to?solely,?
with the others either preferring to retain?merely?
or leaving it out entirely.None of this is to say that the models suffer onlyfrom an unfortunate difference in correction bias rel-ative to the workers, or even that the models makegood corrections a majority of the time.
In fact, theymake a range of false-positive corrections as well4.These seem to fall into three major categories: slightpreferences for similar words that don?t fit in theoverall context of the sentence or change its mean-ing in an undesired way, e.g.
changing ?roommate?to ?lodger?
in you and your roommate must dev-ide [sic] the housework, strong preferences for verycommon words in the local context that render thecorrected sentence ungrammatical, e.g.
changing?compose?
to ?take?
in first, during childhood years,we compose our personality, and misinterpretationsof ambiguous parts of speech that cause nouns tobe replaced with verbs, etc., e.g.
changing ?circum-stance?
to ?go?
in .
.
.
that help you look abound yourcircumstance and find out .
.
.
.Many of these issues can be blamed at least par-tially on the myopia of the language model, which,for example, vastly prefers ?go and find?
to ?cir-cumstance and find.?
However, they can also beattributed to the motivational intuition for Experi-ment 2, which states that we should avoid replacingobserved words with common alternatives.
WhileTable 3 does demonstrate that the models in Ex-periment 2 learn this preference to a degree for thehighest frequency bucket, the proceeding buckets donot exhibit a smooth upwards slope analogous to thefunction being approximated.
Indeed, the words inbucket 2 are preferred an order of magnitude more4Although Type I errors are of course undesirable, Gamonet al (2009) suggest that learners are able to effectively distin-guish between good and bad corrections when presented withpossible error locations and scored alternatives.
Such an inter-active system is beyond the scope of this paper but nonethelessfeasible without significant model modification.than those in bucket 1.
This can be traced to thetruncation policy of Algorithm 1, which selects onlythe highest frequency words from an over-sized setof random walk candidates.
While it is unclear howto intelligently select a good candidate set of man-ageable size, a policy that butts heads with our intu-ition about which words we should be correcting isclearly not the right one.The differences between the models themselvesare somewhat more difficult to interpret.
The 5 and10 candidate variations of Experiment 1 and thoseof Experiment 2 correct 103, 108, 115, and 130 sen-tences out of 1017, respectively, and at least onemodel differs from the others on 123 of those sen-tences (they all agree on 42 sentences).
These dis-agreements are of all types: sometimes only a singlemodel corrects or vice versa, sometimes two modelsare pitted against the other two, and occasionally allfour will choose a different word, but none of theseinconsistencies seem to follow any sort of pattern,e.g.
the two five candidate models agreeing moreoften than the other two or the like.Interestingly, however, the models tend to be inagreement on the sentences that they correct themost effectively.
We explore this more concretely inTable 4, in which we manually judge the quality ofsentence corrections versus the agreement betweenmodels.
Specifically, we judge a set of sentencecorrections as Good if all of the corrections madebetween models improve sentence grammaticality,Harmless if the corrections do not significantly im-prove or reduce grammaticality, and Bad if at leastone of the corrections is either ungrammatical orchanges the sentence meaning.
We note that Badcorrections for the most part do not take grammaticalsentences and make them ungrammatical, only per-turb them in some other erroneous fashion.
Clearly,there is a strong correlation between corrected sen-tence quality and model agreement.
We concludefrom this observation that the models are all learn-ing to correct the most unambiguously incorrect sen-tences in a consistent way, but where some deal ofambiguity remains, they are subject to random dif-ferences inherent in each?s construction.To round out our evaluation of correction qual-ity, we presented the corrected sentences from all4 model variations to human workers for judgmentusing the task detailed in Section 3.2.7.
The results177Table 4: Manual judgments of model-corrected sentencequality between experiments.
If all models are in agree-ment, a sentence is marked as Same, and Different oth-erwise.
We judge a set of sentence corrections as Goodif all of the corrections made between models improvesentence grammaticality, Harmless if the corrections donot significantly improve or reduce grammaticality, andBad if at least one of the corrections is either ungram-matical or changes the sentence meaning.
Only correctedsentences are listed.Model Judgment # of % ofAgreement Sentences TotalSameGood 6 14.3%Harmless 11 26.2%Bad 25 59.5%Total 42 ?DifferentGood 4 3.3%Harmless 34 27.6%Bad 85 69.1%Total 123 ?of this effort are detailed in Figure 3.
The work-ers are perhaps a bit more generous with their judg-ments than we are, but overall, they tend towards thesame results that we do in our manual evaluation.Aside from the conclusions already presented, theworker judgments do expose one interesting finding:When the corrected sentence is judged to be at leastas grammatical as the ESL sentence, it also tendsto preserve the ESL sentence?s meaning.
However,when the ESL sentence is judged more correct, themeaning preservation trend is reversed.
This obser-vation leads us to believe that incorporating somemeasure of semantic distance into our random walkfunction f might prove effective.5 Conclusion and Future WorkWe have presented a novel noisy channel model forcorrecting a broad class of language learner produc-tion errors.
Although our experimental results aremixed, we believe that our model constitutes an in-teresting and potentially very fruitful approach toESL grammar correction.
There are a number ofopportunities for improvement available.
Using aricher language model, such as a PCFG, would un-doubtedly improve our results.
Noting that ESL er-rors tend to occur in groups within sentences andFigure 3: Human judgments of corrected sentences gath-ered using Mechanical Turk.
The items listed in the leg-end are answers to the questions Between the [original(ESL) and corrected] sentences, which is more correct?
/Is the meaning of the corrected sentence significantly dif-ferent from that of the ESL sentence?
See Section 3.2.7for methodological details and Section 4 for results dis-cussion.12.1%14.4%16.2%14.8%20.0%18.8%19.4%21.3%29.3%28.5%31.4%30.1%18.2%16.1%15.4%14.5%7.7%7.3%6.2%6.1%12.7%14.9%11.4%13.2%0.0% 5.0% 10.0% 15.0% 20.0% 25.0% 30.0% 35.0%Exp.
210 candidatesExp.
25 candidatesExp.
110 candidatesExp.
15 candidatesCorrected better/Same meaning Corrected better/Different meaningESL better/Same meaning ESL better/Different meaningBoth equally good/Same meaning Both equally good/Different meaningare often interdependent, the addition of other noisemodels, such as those detailed in Park and Levy(2011), would further improve things by allowingthe language model to consider a wider range of cor-rected contexts around each word.
Our random walkmodel itself could also be improved by incorporat-ing observed word frequency information or somenotion of semantic difference between observed andunobserved words, or by learning separate parame-ters for different word classes.
Somewhat counter-intuitively, a structured reduction of dictionary rich-ness could also yield better results by limiting thebreadth of random walk candidates.
Finally, a moreintelligent heuristic for truncating large sets of ran-dom walk candidates would likely foster improve-ment.AcknowledgmentsWe would like to thank three anonymous reviewersfor their insightful comments and suggestions, andMarkus Dreyer for providing us with his expecta-tion semiring code.
Additionally, we are grateful tothe San Diego Supercomputer Center for allowingus access to DASH.178ReferencesCyril Allauzen, Michael Riley, Johan Schalkwyk, Wo-jciech Skut, and Mehryar Mohri.
2007.
Open-fst: a general and efficient weighted finite-state trans-ducer library.
In Proceedings of the 12th internationalconference on Implementation and application of au-tomata, CIAA?07, pages 11?23, Berlin, Heidelberg.Springer-Verlag.Harald R. Baayen, Richard Piepenbrock, and Leon Gu-likers.
1995.
The CELEX Lexical Database.
Release2 (CD-ROM).
Linguistic Data Consortium, Universityof Pennsylvania, Philadelphia, Pennsylvania.Chris Brockett, William B. Dolan, and Michael Gamon.2006.
Correcting esl errors using phrasal smt tech-niques.
In Proceedings of the 21st International Con-ference on Computational Linguistics and the 44thannual meeting of the Association for ComputationalLinguistics, ACL-44, pages 249?256, Stroudsburg,PA, USA.
Association for Computational Linguistics.Peter F. Brown, Vincent J. Della Pietra, Stephen A. DellaPietra, and Robert L. Mercer.
1993.
The mathemat-ics of statistical machine translation: parameter esti-mation.
Comput.
Linguist., 19:263?311, June.Lou Burnard.
1995.
Users Reference Guide British Na-tional Corpus Version 1.0.
Oxford University Com-puting Services, UK.Stanley F. Chen and Joshua Goodman.
1996.
An empir-ical study of smoothing techniques for language mod-eling.
In Proceedings of the 34th annual meeting onAssociation for Computational Linguistics, ACL ?96,pages 310?318, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Arthur P. Dempster, Nan M. Laird, and Donald B. Rubin.1977.
Maximum likelihood from incomplete data viathe EM algorithm (with discussion).
Journal of theRoyal Statistical Society B, 39:1?38.Alain De?silets and Matthieu Hermet.
2009.
Using au-tomatic roundtrip translation to repair general errors insecond language writing.
pages 198?206.
MT SummitXII.Markus Dreyer, Jason R. Smith, and Jason Eisner.
2008.Latent-variable modeling of string transductions withfinite-state methods.
In Proceedings of the Conferenceon Empirical Methods in Natural Language Process-ing, EMNLP ?08, pages 1080?1089, Stroudsburg, PA,USA.
Association for Computational Linguistics.Jason Eisner.
2002.
Parameter estimation for proba-bilistic finite-state transducers.
In Proceedings of the40th Annual Meeting on Association for Computa-tional Linguistics, ACL ?02, pages 1?8, Stroudsburg,PA, USA.
Association for Computational Linguistics.Michael Gamon, Claudia Leacock, Chris Brockett,William B Dolan, Jianfeng Gao, Dmitriy Belenko, andAlexandre Klementiev.
2009.
Using statistical tech-niques and web search to correct esl errors.
CALICOJournal, 26:491?511.Stanley Kok and Chris Brockett.
2010.
Hitting the rightparaphrases in good time.
In Human Language Tech-nologies: The 2010 Annual Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics, HLT ?10, pages 145?153, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Alon Lavie and Abhaya Agarwal.
2007.
Meteor: an au-tomatic metric for mt evaluation with high levels ofcorrelation with human judgments.
In Proceedingsof the Second Workshop on Statistical Machine Trans-lation, StatMT ?07, pages 228?231, Stroudsburg, PA,USA.
Association for Computational Linguistics.John Lee and Stephanie Seneff.
2006.
Automatic gram-mar correction for second-language learners.
ICSLP.Mehryar Mohri.
2001.
Generic -removal algorithmfor weighted automata.
In Shen Yu and Andrei Paun,editors, Implementation and Application of Automata,volume 2088 of Lecture Notes in Computer Science,pages 230?242.
Springer Berlin / Heidelberg.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: a method for automatic eval-uation of machine translation.
In Proceedings of the40th Annual Meeting on Association for Computa-tional Linguistics, ACL ?02, pages 311?318, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Y.
Albert Park and Roger Levy.
2011.
Automated wholesentence grammar correction using a noisy channelmodel.
ACL ?11.
Association for Computational Lin-guistics.
In Press.C.
E. Shannon.
1948.
A mathematical theory of commu-nication.
Bell Systems Technical Journal, 27:623?656.179
