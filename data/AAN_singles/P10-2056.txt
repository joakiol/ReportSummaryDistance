Proceedings of the ACL 2010 Conference Short Papers, pages 301?306,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsDomain Adaptation of Maximum Entropy Language ModelsTanel Aluma?e?Adaptive Informatics Research CentreSchool of Science and TechnologyAalto UniversityHelsinki, Finlandtanel@cis.hut.fiMikko KurimoAdaptive Informatics Research CentreSchool of Science and TechnologyAalto UniversityHelsinki, FinlandMikko.Kurimo@tkk.fiAbstractWe investigate a recently proposedBayesian adaptation method for buildingstyle-adapted maximum entropy languagemodels for speech recognition, given alarge corpus of written language dataand a small corpus of speech transcripts.Experiments show that the method con-sistently outperforms linear interpolationwhich is typically used in such cases.1 IntroductionIn large vocabulary speech recognition, a languagemodel (LM) is typically estimated from largeamounts of written text data.
However, recogni-tion is typically applied to speech that is stylisti-cally different from written language.
For exam-ple, in an often-tried setting, speech recognition isapplied to broadcast news, that includes introduc-tory segments, conversations and spontaneous in-terviews.
To decrease the mismatch between train-ing and test data, often a small amount of speechdata is human-transcribed.
A LM is then builtby interpolating the models estimated from largecorpus of written language and the small corpusof transcribed data.
However, in practice, differ-ent models might be of different importance de-pending on the word context.
Global interpola-tion doesn?t take such variability into account andall predictions are weighted across models identi-cally, regardless of the context.In this paper we investigate a recently proposedBayesian adaptation approach (Daume III, 2007;Finkel and Manning, 2009) for adapting a con-ditional maximum entropy (ME) LM (Rosenfeld,1996) to a new domain, given a large corpus ofout-of-domain training data and a small corpusof in-domain data.
The main contribution of this?Currently with Tallinn University of Technology, Esto-niapaper is that we show how the suggested hierar-chical adaptation can be used with suitable pri-ors and combined with the class-based speeduptechnique (Goodman, 2001) to adapt ME LMsin large-vocabulary speech recognition when theamount of target data is small.
The results outper-form the conventional linear interpolation of back-ground and target models in both N -grams andME models.
It seems that with the adapted MEmodels, the same recognition accuracy for the tar-get evaluation data can be obtained with 50% lessadaptation data than in interpolated ME models.2 Review of Conditional MaximumEntropy Language ModelsMaximum entropy (ME) modeling is a frameworkthat has been used in a wide area of natural lan-guage processing (NLP) tasks.
A conditional MEmodel has the following form:P (x|h) =e?i ?ifi(x,h)?x?
e?j ?jfj(x?,h)(1)where x is an outcome (in case of a LM, a word),h is a context (the word history), and x?
a set of allpossible outcomes (words).
The functions fi are(typically binary) feature functions.
During MEtraining, the optimal weights ?i corresponding tofeatures fi(x, h) are learned.
More precisely, find-ing the ME model is equal to finding weights thatmaximize the log-likelihood L(X; ?)
of the train-ing data X .
The weights are learned via improvediterative scaling algorithm or some of its modernfast counterparts (i.e., conjugate gradient descent).Since LMs typically have a vocabulary of tensof thousands of words, the use of a normalizationfactor over all possible outcomes makes estimat-ing a ME LM very memory and time consuming.Goodman (2001) proposed a class-based methodthat drastically reduces the resource requirementsfor training such models.
The idea is to cluster301words in the vocabulary into classes (e.g., basedon their distributional similarity).
Then, we candecompose the prediction of a word given its his-tory into prediction of its class given the history,and prediction of the word given the history andits class :P (w|h) = P (C(w)|h)?P (w|h,C(w)) (2)Using such decomposition, we can create two MEmodels: one corresponding to P (C(w)|h) and theother corresponding to P (w|h,C(w)).
It is easy tosee that computing the normalization factor of thefirst component model now requires only loopingover all classes.
It turns out that normalizing thesecond model is also easier: for a context h,C(w),we only need to normalize over words that belongto class C(w), since other words cannot occur inthis context.
This decomposition can be furtherextended by using hierarchical classes.To avoid overfitting, ME models are usuallysmoothed (regularized).
The most widely usedsmoothing method for ME LMs is Gaussian pri-ors (Chen and Rosenfeld, 2000): a zero-meanprior with a given variance is added to all featureweights, and the model optimization criteria be-comes:L?
(X; ?)
= L(X; ?
)?F?i=1?2i2?2i(3)where F is the number of feature functions.
Typi-cally, a fixed hyperparameter ?i = ?
is used forall parameters.
The optimal variance is usuallyestimated on a development set.
Intuitively, thismethod encourages feature weights to be smaller,by penalizing weights with big absolute values.3 Domain Adaptation of MaximumEntropy ModelsRecently, a hierarchical Bayesian adaptationmethod was proposed that can be applied to a largefamily of discriminative learning tasks (such asME models, SVMs) (Daume III, 2007; Finkel andManning, 2009).
In NLP problems, data oftencomes from different sources (e.g., newspapers,web, textbooks, speech transcriptions).
There arethree classic approaches for building models frommultiple sources.
We can pool all training data andestimate a single model, and apply it for all tasks.The second approach is to ?unpool?
the data, i.e,only use training data from the test domain.
Thethird and often the best performing approach is totrain separate models for each data source, applythem to test data and interpolate the results.The hierarchical Bayesian adaptation methodis a generalization of the three approaches de-scribed above.
The hierarchical model jointlyoptimizes global and domain-specific parameters,using parameters built from pooled data as priorsfor domain-specific parameters.
In other words,instead of using smoothing to encourage param-eters to be closer to zero, it encourages domain-specific model parameters to be closer to thecorresponding global parameters, while a zeromean Gaussian prior is still applied for global pa-rameters.
For processing test data during run-time, the domain-specific model is applied.
Intu-itively, this approach can be described as follows:the domain-specific parameters are largely deter-mined by global data, unless there is good domain-specific evidence that they should be different.The key to this approach is that the global anddomain-specific parameters are learned jointly, nothierarchically.
This allows domain-specific pa-rameters to influence the global parameters, andvice versa.
Formally, the joint optimization crite-ria becomes:Lhier(X; ?)
=?d(Lorig(Xd,?d)?F?i=1(?d,i ?
??,i)22?2d)?F?i=1?2?,i2?2?
(4)where Xd is data for domain d, ?
?,i the globalparameters, ?d,i the domain-specific parameters,?2?
the global variance and ?2d the domain-specificvariances.
The global and domain-specific vari-ances are optimized on the heldout data.
Usually,larger values are used for global parameters andfor domains with more data, while for domainswith less data, the variance is typically set to besmaller, encouraging the domain-specific parame-ters to be closer to global values.This adaptation scheme is very similar to the ap-proaches proposed by (Chelba and Acero, 2006)and (Chen, 2009b): both use a model estimatedfrom background data as a prior when learninga model from in-domain data.
The main differ-ence is the fact that in this method, the models areestimated jointly while in the other works, back-302ground model has to be estimated before learningthe in-domain model.4 ExperimentsIn this section, we look at experimental resultsover two speech recognition tasks.4.1 TasksTask 1: English Broadcast News.
This recog-nition task consists of the English broadcast newssection of the 2003 NIST Rich Transcription Eval-uation Data.
The data includes six news record-ings from six different sources with a total lengthof 176 minutes.As acoustic models, the CMU Sphinx opensource triphone HUB4 models for wideband(16kHz) speech1 were used.
The models havebeen trained using 140 hours of speech.For training the LMs, two sources were used:first 5M sentences from the Gigaword (2nd ed.
)corpus (99.5M words), and broadcast news tran-scriptions from the TDT4 corpus (1.19M words).The latter was treated as in-domain data in theadaptation experiments.
A vocabulary of 26Kwords was used.
It is a subset of a bigger 60Kvocabulary, and only includes words that occurredin the training data.
The OOV rate against the testset was 2.4%.The audio used for testing was segmentedinto parts of up to 20 seconds in length.Speaker diarization was applied using theLIUM SpkDiarization toolkit (Dele?glise et al,2005).
The CMU Sphinx 3.7 was used fordecoding.
A three-pass recognition strategy wasapplied: the first pass recognition hypotheseswere used for calculating MLLR-adapted modelsfor each speaker.
In the second pass, the adaptedacoustic models were used for generating a5000-best list of hypotheses for each segment.
Inthe third pass, the ME LM was used to re-rank thehypotheses and select the best one.
During decod-ing, a trigram LM model was used.
The trigrammodel was an interpolation of source-specificmodels which were estimated using Kneser-Neydiscounting.Task 2: Estonian Broadcast Conversations.The second recognition task consists of fourrecordings from different live talk programs from1http://www.speech.cs.cmu.edu/sphinx/models/three Estonian radio stations.
Their format con-sists of hosts and invited guests, spontaneouslydiscussing current affairs.
There are 40 minutesof transcriptions, with 11 different speakers.The acoustic models were trained on variouswideband Estonian speech corpora: the BABELspeech database (9h), transcriptions of Estonianbroadcast news (7.5h) and transcriptions of radiolive talk programs (10h).
The models are triphoneHMMs, using MFCC features.For training the LMs, two sources were used:about 10M sentences from various Estonian news-papers, and manual transcriptions of 10 hours oflive talk programs from three Estonian radio sta-tions.
The latter is identical in style to the test data,although it originates from a different time periodand covers a wider variety of programs, and wastreated as in-domain data.As Estonian is a highly inflective language,morphemes are used as basic units in the LM.We use a morphological analyzer (Kaalep andVaino, 2001) for splitting the words into mor-phemes.
After such processing, the newspapercorpus includes of 185M tokens, and the tran-scribed data 104K tokens.
A vocabulary of 30Ktokens was used for this task, with an OOV rateof 1.7% against the test data.
After recognition,morphemes were concatenated back to words.As with English data, a three-pass recognitionstrategy involving MLLR adaptation was applied.4.2 ResultsFor both tasks, we rescored the N-best lists intwo different ways: (1) using linear interpolationof source-specific ME models and (2) using hi-erarchically domain-adapted ME model (as de-scribed in previous chapter).
The English MEmodels had a three-level and Estonian models afour-level class hierarchy.
The classes were de-rived using the word exchange algorithm (Kneserand Ney, 1993).
The number of classes at eachlevel was determined experimentally so as to op-timize the resource requirements for training MEmodels (specifically, the number of classes was150, 1000 and 5000 for the English models and20, 150, 1000 and 6000 for the Estonian models).We used unigram, bigram and trigram features thatoccurred at least twice in the training data.
Thefeature cut-off was applied in order to accommo-date the memory requirements.
The feature setwas identical for interpolated and adapted models.303Interp.
models Adapted modelsAdapta-tion data(No ofwords)?2OD ?2ID ?2?
?2OD ?2IDEnglish Broadcast News147K 2e8 3e5 5e7 2e7 2e6292K 2e8 5e5 5e7 2e7 2e6591K 2e8 1e6 5e7 2e7 2e61119K 2e8 2e6 5e7 2e7 5e6Estonian Broadcast Conversations104K 5e8 3e5 5e7 1e7 2e6Table 1: The unnormalized values of Gaus-sian prior variances for interpolated out-of-domain(OD) and in-domain (ID) ME models, and hierar-chically adapted global (*), out-of-odomain (OD)and in-domain (ID) models that were used in theexperiments.For the English task, we also explored the ef-ficiency of these two approaches with varyingsize of adaptation data: we repeated the exper-iments when using one eighth, one quarter, halfand all of the TDT4 transcription data for interpo-lation/adaptation.
The amount of used Gigaworddata was not changed.
In all cases, interpolationweights were re-optimized and new Gaussian vari-ance values were heuristically determined.The TADM toolkit2 was used for estimating MEmodels, utilizing its implementation of the conju-gate gradient algorithm.The models were regularized using Gaussianpriors.
The variance parameters were chosenheuristically based on light tuning on develop-ment set perplexity.
For the source-specific MEmodels, the variance was fixed on per-model ba-sis.
For the adapted model, that jointly modelsglobal and domain-specific data, the Gaussian pri-ors were fixed for each hierarchy node (i.e., thevariance was fixed across global, out-of-domain,and in-domain parameters).
Table 1 lists valuesfor the variances of Gaussian priors (as in equa-tions 3 and 4) that we used in the experiments.
Inother publications, the variance values are oftennormalized to the size of the data.
We chose notto normalize the values, since in the hierarchicaladaptation scheme, also data from other domainshave impact on the learned model parameters, thus2http://tadm.sourceforge.net/it?s not possible to simply normalize the variances.The experimental results are presented in Table2.
Perplexity and word error rate (WER) results ofthe interpolated and adapted models are compared.For the Estonian task, letter error rate (LER) isalso reported, since it tends to be a more indicativemeasure of speech recognition quality for highlyinflected languages.
In all experiments, using theadapted models resulted in lower perplexity andlower error rate.
Improvements in the English ex-periment were less evident than in the Estoniansystem, with under 10% improvement in perplex-ity and 1-3% in WER, against 15% and 4% for theEstonian experiment.
In most cases, there was asignificant improvement in WER when using theadapted ME model (according to the Wilcoxontest), with and exception of the English experi-ments on the 292K and 591K data sets.The comparison between N -gram models andME models is not entirely fair since ME modelsare actually class-based.
Such transformation in-troduces additional smoothing into the model andcan improve model perplexity, as also noticed byGoodman (2001).5 DiscussionIn this paper we have tested a hierarchical adapta-tion method (Daume III, 2007; Finkel and Man-ning, 2009) on building style-adapted LMs forspeech recognition.
We showed that the methodachieves consistently lower error rates than whenusing linear interpolation which is typically usedin such scenarios.The tested method is ideally suited for languagemodeling in speech recognition: we almost alwayshave access to large amounts of data from writtensources but commonly the speech to be recognizedis stylistically noticeably different.
The hierarchi-cal adaptation method enables to use even a smallamount of in-domain data to modify the parame-ters estimated from out-of-domain data, if there isenough evidence.As Finkel and Manning (2009) point out, thehierarchical nature of the method makes it possi-ble to estimate highly specific models: we coulddraw style-specific models from general high-levelpriors, and topic-and-style specific models fromstyle-specific priors.
Furthermore, the modelsdon?t have to be hierarchical: it is easy to gen-eralize the method to general multilevel approachwhere a model is drawn from multiple priors.
For304Perplexity WER LERAdaptationdata (No.of words)PooledN-gramInterp.N-gramInterp.MEAdaptedMEInterp.N-gramInterp.MEAdaptedMEInterp.N-gramInterp.MEAdaptedMEEnglish Broadcast News147K 290 255 243 230 27.2 26.3 25.9292K 286 250 236 223 26.7 25.8 25.6591K 280 243 228 215 26.6 25.9 25.61119K 272 232 217 204 26.2 25.6 24.9Estonian Broadcast Conversations104K 237 197 200 169 40.5 38.9 37.4 17.7 17.3 16.6Table 2: Perplexity, WER and LER results comparing pooled and interpolated N -gram models andinterpolated and adapted ME models, with changing amount of available in-domain data.instance, we could build a model for recognizingcomputer science lectures, given data from text-books, including those about computer science,and transcripts of lectures on various topics (whichdon?t even need to include lectures about computerscience).The method has some considerable shortcom-ings from the practical perspective.
First, train-ing ME LMs in general has much higher resourcerequirements than training N -gram models whichare typically used in speech recognition.
More-over, training hierarchical ME models requireseven more memory than training simple ME mod-els, proportional to the number of nodes in the hi-erarchy.
However, it should be possible to allevi-ate this problem by profiting from the hierarchi-cal nature of n-gram features, as proposed in (Wuand Khudanpur, 2002).
It is also difficult to deter-mine good variance values ?2i for the global anddomain-specific priors.
While good variance val-ues for simple ME models can be chosen quite re-liably based on the size of the training data (Chen,2009a), we have found that it is more demand-ing to find good hyperparameters for hierarchicalmodels since weights for the same feature in dif-ferent nodes in the hierarchy are all related to eachother.
We plan to investigate this problem in thefuture since the choice of hyperparameters has astrong impact on the performance of the model.AcknowledgmentsThis research was partly funded by the Academyof Finland in the project Adaptive Informatics,by the target-financed theme No.
0322709s06 ofthe Estonian Ministry of Education and Researchand by the National Programme for Estonian Lan-guage Technology.ReferencesCiprian Chelba and Alex Acero.
2006.
Adaptation ofmaximum entropy capitalizer: Little data can help alot.
Computer Speech & Language, 20(4):382?399,October.S.
F. Chen and R. Rosenfeld.
2000.
A survey ofsmoothing techniques for ME models.
IEEE Trans-actions on Speech and Audio Processing, 8(1):37?50.S.
F. Chen.
2009a.
Performance prediction for expo-nential language models.
In Proceedings of HLT-NAACL, pages 450?458, Boulder, Colorado.Stanley F. Chen.
2009b.
Shrinking exponential lan-guage models.
In Proceedings of HLT-NAACL,pages 468?476, Boulder, Colorado.H.
Daume III.
2007.
Frustratingly easy domain adap-tation.
In Proceedings of ACL, pages 256?263.P.
Dele?glise, Y. Este?ve, S. Meignier, and T. Merlin.2005.
The LIUM speech transcription system: aCMU Sphinx III-based system for French broadcastnews.
In Proceedings of Interspeech, Lisboa, Portu-gal.J.
R. Finkel and Ch.
Manning.
2009.
Hierarchi-cal Bayesian domain adaptation.
In Proceedings ofHLT-NAACL, pages 602?610, Boulder, Colorado.J.
Goodman.
2001.
Classes for fast maximum entropytraining.
In Proceedings of ICASSP, Utah, USA.H.-J.
Kaalep and T. Vaino.
2001.
Complete morpho-logical analysis in the linguist?s toolbox.
In Con-gressus Nonus Internationalis Fenno-UgristarumPars V, pages 9?16, Tartu, Estonia.R.
Kneser and H. Ney.
1993.
Improved clusteringtechniques for class-based statistical language mod-elling.
In Proceedings of the European Conference305on Speech Communication and Technology, pages973?976.R.
Rosenfeld.
1996.
A maximum entropy approach toadaptive statistical language modeling.
Computer,Speech and Language, 10:187?228.J.
Wu and S. Khudanpur.
2002.
Building a topic-dependent maximum entropy model for very largecorpora.
In Proceedings of ICASSP, Orlando,Florida, USA.306
