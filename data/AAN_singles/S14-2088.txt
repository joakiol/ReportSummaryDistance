Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 508?511,Dublin, Ireland, August 23-24, 2014.SAIL-GRS: Grammar Induction for Spoken Dialogue Systems usingCF-IRF Rule SimilarityKalliopi Zervanou, Nikolaos Malandrakis and Shrikanth NarayananSignal Analysis and Interpretation Laboratory (SAIL),University of Southern California, Los Angeles, CA 90089, USAkzervanou@gmail.com, malandra@usc.edu , shri@sipi.usc.eduAbstractThe SAIL-GRS system is based on awidely used approach originating from in-formation retrieval and document index-ing, the TF -IDF measure.
In this im-plementation for spoken dialogue systemgrammar induction, rule constituent fre-quency and inverse rule frequency mea-sures are used for estimating lexical andsemantic similarity of candidate grammarrules to a seed set of rule pattern instances.The performance of the system is evalu-ated for the English language in three dif-ferent domains, travel, tourism and financeand in the travel domain, for Greek.
Thesimplicity of our approach makes it quiteeasy and fast to implement irrespective oflanguage and domain.
The results showthat the SAIL-GRS system performs quitewell in all three domains and in both lan-guages.1 IntroductionSpoken dialogue systems typically rely on gram-mars which define the semantic frames and re-spective fillers in dialogue scenarios (Chen et al.,2013).
Such systems are tailored for specificdomains for which the respective grammars aremostly manually developed (Ward, 1990; Seneff,1992).
In order to address this issue, numerouscurrent approaches attempt to infer these grammarrules automatically (Pargellis et al., 2001; Mengand Siu, 2002; Yoshino et al., 2011; Chen et al.,2013).The acquisition of grammar rules for spokenlanguage systems is defined as a task comprisingThis work is licensed under a Creative Commons Attribution4.0 International Licence.
Page numbers and proceedingsfooter are added by the organisers.
Licence details: http://creativecommons.org/licenses/by/4.0/of two subtasks (Meng and Siu, 2002; Iosif andPotamianos, 2007), the acquisition of:(i) Low-level rules These are rules definingdomain-specific entities, such as names of lo-cations, hotels, airports, e.g.
CountryName:?USA?, Date: ?July 15th, 2014?, CardType:?VISA?
and other common domain multi-word ex-pressions, e.g.
DoYouKnowQ: ?do you know?.
(ii) High-level rules These are larger,frame-like rule patterns which contain assemantic slot fillers multi-word entitiesidentified by low-level rules.
For exam-ple: DirectionsQ: ?<DoYouKnowQ><where> the <MuseumName> is lo-cated?, ExpressionCardProblem: ?my<CardType> has expired?.The shared task of Grammar Induction for Spo-ken Dialogue Systems, where our system partic-ipated, focused on the induction of high-levelgrammar rules and in particular on the identifica-tion and semantic classification of new rule pat-terns based on their semantic similarity to knownrule instances.Within this research framework, the work de-scribed in this paper proposes a methodology forestimating rule semantic similarity using a varia-tion of the well-known measure of TF -IDF asrule constituent frequency vs. inverse rule fre-quency, henceforth CF -IRF .In the remainder of this paper, we start in Sec-tion 2 by a detailed description of our system.
Sub-sequently, in Section 3, we present the datasetsused and the evaluation process, and in Section 4we discuss our results.
We conclude in Section 5with a summary of our observations and directionsfor future work.2 System DescriptionThe SAIL-GRS system is based on a widely usedapproach in information retrieval and documentindexing, the TF -IDF measure.
TF -IDF is508an approach that has found numerous applicationsin information management applications, such asdocument keyword extraction, (e.g., Dillon andGray (1983)), document clustering, summarisa-tion, (e.g., Gong and Liu (2001)), event cluster-ing, (e.g., De Smet and Moens (2013)).
In dia-logue systems, TF -IDF has been used, amongother applications, for discovering local coher-ence (Gandhe and Traum, 2007) and for acquir-ing predicate-argument rule fragments in an opendomain, information extraction-based spoken dia-logue system (Yoshino et al., 2011).
In their ap-proach, Yoshino et al.
(2011) use the TF -IDFmeasure to determine the importance of a givenword for a given domain or topic, so as to selectthe most salient predicate-argument structure rulepatterns from their corpus.In our implementation for spoken dialoguesystem grammar induction, rule constituent fre-quency (CF ) and inverse rule frequency (IRF )measures are used for estimating lexical and se-mantic similarity of candidate grammar rules to aseed set of rule pattern instances.
As illustrated inTable 1, the SAIL-GRS algorithm has two mainsteps, the training stage and the rule inductionstage.Input: known rule pattern instancesOutput: new candidate rule patternsTraining stage:1.
Known rule instance parsing2.
Rule constituent extraction (uni-/bigrams)3.
Rule constituent frequency count (CF )4.
Inverse rule frequency count (IRF )5.
CF -IRF rule instance vector creationRule induction stage:1.
Unknown text fragment parsing2.
Unigram & bigram extraction3.
Uni-/bigram CF -IRF value lookup4.
Creation of CF -IRF vector forunknown text fragment5.
Estimation of cosine similarity ofunknown fragment to rule instances6.
New candidate rule selection & rulesemantic category classification usingmaximum cosine similarityTable 1: The SAIL-GRS system algorithm.In the first, the Training stage, known rule in-stances are parsed and, for each rule semantic cat-egory, the respective high-level rule pattern in-stances are acquired.
These patterns are subse-quently split into unigram and bigram constituentsand the respective constituent frequencies and in-verse rule frequencies are estimated.
Finally, foreach rule category, a vector representation is cre-ated for the respective rule pattern instance, basedon the CF -IRF value of its unigram and bigramconstituents.In the second step, the Rule induction stage, theunknown text fragments are parsed and split intounigrams and bigrams.
Subsequently, we lookupthe known rule instance unigram and bigram rep-resentations for potential lexical matches to thesenew unigrams and bigrams.
If these are found,then the new n-grams acquire the respective CF -IRF values found in the training instances and therespective CF -IRF vector for the unknown textfragments is created.
Finally, we estimate the co-sine similarity of this unknown text vector to eachknown rule vector.
The unknown text fragmentsthat are most similar to a given rule category areselected as candidate rule patterns and are classi-fied in the known rule semantic category.
An un-known text fragment that is selected as candidaterule pattern is assigned only to one, the most sim-ilar, rule category.3 Experimental SetupThe overall objective in spoken dialogue systemgrammar induction is the fast and efficient devel-opment and portability of grammar resources.
Inthe Grammar Induction for Spoken Dialogue Sys-tems task, this challenge was addressed by pro-viding datasets in three different domains, travel,tourism and finance, and by attempting to covermore than one language for the travel domain,namely English and Greek.As illustrated in Table 2, the travel domain datafor the two languages are comparable, with 32 and35 number of known rule categories, for Englishand Greek, comprising of 982 and 956 high-levelrule pattern instances respectively.
The smallestdataset is the finance dataset, with 9 rule categoriesand 136 rule pattern instances, while the tourismdataset has a relatively low number of rule cate-gories comprising of the highest number of rulepattern instances.
Interestingly, as indicated in thecolumn depicting the percent of unknown n-gramsin the test-set, i.e.
the unigrams and the bigramswithout a CF -IRF value in the training data, thetourism domain test-set appears also to be the one509with the greatest overlap with the training data,with a mere 0.72% and 4.84% of unknown uni-grams and bigrams respectively.For the evaluation, the system performance isestimated in terms of precision (P ), recall (R) andF -score measures, for the correct classification ofan unknown text fragment to a given rule cate-gory cluster of pattern instances.
In addition tothese measures, the weighted average of the perrule scores is computed as follows:Pw=?N?1i=1Pici?N?1i=1ci, Rw=?N?1i=1Rini?N?1i=1ni(1)Fw=2 ?
Pw?RwPw+ Rw(2)where N ?
1 is the total number of rule cate-gories, Piand Riare the per rule i scores for preci-sion and recall, cithe unknown patterns correctlyassigned to rule i, and nithe total number of cor-rect rule instance patterns for rule i indicated inthe ground truth data.4 ResultsThe results of the SAIL-GRS system outperformthe Baseline in all dataset categories, except theTourism domain, as illustrated in Table 3.
In thisdomain, both systems present the highest scorescompared to the other domains.
The high resultsin the travel domain are probably due to the highdata overlap between the train and the test data, asdiscussed in the previous section and illustrated inTable 2.
However, this domain was also the onewith the highest average number of rule instancesper rule category, compared to the other domains,thus presenting an additional challenge in the cor-rect classification of unknown rule fragments.We observe that the overall higher F measuresof the SAIL-GRS system in the travel and fi-nance domains are due to higher precision scores,whereas Baseline system displays higher recall butlower precision scores and lower F-measure inthese domains.The overall lowest scores for both systems arereached in the Travel domain for Greek, whichis also the dataset with the lowest overlap withthe training data.
However, the performance ofthe SAIL-GRS system does not deteriorate to thesame extent as the Baseline, the precision of whichfalls to a mere 0.16-0.17, compared to 0.49-0.46for the SAIL-GRS system.5 ConclusionIn this work, we have presented the SAIL-GRSsystem used for the Grammar Induction for Spo-ken Dialogue Systems task.
Our approach usesa fairly simple, language independent method formeasuring lexical and semantic similarity of rulepattern instances.
Our rule constituent frequencyvs.
inverse rule frequency measure, CF -IRF is amodification the TF -IDF measure for estimatingrule similarity in the induction process of new ruleinstances.The performance of our system in rule induc-tion and rule pattern semantic classification wastested in three different domains, travel, tourismand finance in four datasets, three for Englishand an additional dataset for the travel domainin Greek.
SAIL-GRS outperforms the Baselinein all datasets, except the travel domain for En-glish.
Moreover, our results showed that our sys-tem achieved an overall better score in precisionand respective F-measure, in the travel and financedomains, even when applied to a language otherthan English.
Finally, in cases of a larger percent-age of unknown data in the test set, as in the Greektravel dataset, the smooth degradation of SAIL-GRS results compared to the Baseline indicatesthe robustness of our method.A limitation of our system in its current versionlies in the requirement for absolute lexical matchwith unknown rule unigrams and bigrams.
Fu-ture extensions of the system could include ruleconstituent expansion using synonyms, variants orsemantically or lexically similar words, so as toimprove recall and the overall F-measure perfor-mance.ReferencesYun-Nung Chen, William Yang Wang, and Alexan-der I. Rudnicky.
2013.
Unsupervised induction andfilling of semantic slots for spoken dialogue systemsusing frame-semantic parsing.
In Proceedings of the2013 IEEEWorkshop on Automatic Speech Recogni-tion and Understanding, pages 120?125.Wim De Smet and Marie-Francine Moens.
2013.
Rep-resentations for multi-document event clustering.Data Mining and Knowledge Discovery, 26(3):533?558.Martin Dillon and Ann S. Gray.
1983.
FASIT: Afully automatic syntactically based indexing system.Journal of the American Society for Information Sci-ence, 34(2):99?108.510High-Level Rule Rule Patterns # Test-set: Unknown n-grams %Domain Categories #Training-set Test-set Unigrams BigramsTravel EN 32 982 284 5.13% 20.71%Travel GR 35 956 324 17.26% 33.09%Tourism EN 24 1004 285 0.72% 4.84%Finance EN 9 136 37 12.35% 36.74%Table 2: Characteristics of training and test datasets.Domain SAIL-GRS BaselineP PwR RwF FwP PwR RwF FwTravel EN 0.57 0.54 0.66 0.62 0.61 0.58 0.38 0.40 0.67 0.69 0.48 0.51Travel GR 0.49 0.46 0.62 0.51 0.55 0.49 0.16 0.17 0.73 0.65 0.26 0.26Tourism EN 0.75 0.75 0.90 0.90 0.82 0.82 0.82 0.80 0.94 0.94 0.87 0.87Finance EN 0.67 0.78 0.62 0.78 0.65 0.78 0.40 0.48 0.63 0.78 0.49 0.60Table 3: Evaluation results for SAIL-GRS system compared to the baseline in all four datasets in termsof per rule Precision P , Recall R, and F-score F .
In the grey column, Pw, Rw, and Fwstand for theweighted average of the per rule precision, recall and F-score respectively, as defined in Equ.
1 and 2.Sudeep Gandhe and David Traum.
2007.
First stepstowards dialogue modelling from an un-annotatedhuman-human corpus.
In Proceedings of the FifthIJCAI Workshop on Knowledge and Reasoning inPractical Dialogue Systems, pages 22?27.Yihong Gong and Xin Liu.
2001.
Generic text summa-rization using relevance measure and latent semanticanalysis.
In Proceedings of the 24th Annual Inter-national ACM SIGIR Conference on Research andDevelopment in Information Retrieval, SIGIR ?01,pages 19?25, New York, NY, USA.
ACM.Elias Iosif and Alexandros Potamianos.
2007.
A soft-clustering algorithm for automatic induction of se-mantic classes.
In Proceedings of the 8th AnnualConference of the International Speech Communi-cation Association, pages 1609?1612.
ISCA.Helen M. Meng and Kai-Chung Siu.
2002.
Semi-automatic acquisition of semantic structures forunderstanding domain-specific natural languagequeries.
IEEE Transactions on Knowledge and DataEngineering, 14(1):172?181.Andrew N. Pargellis, Eric Fosler-Lussier, AlexandrosPotamianos, and Chin-Hui Lee.
2001.
Metricsfor measuring domain independence of semanticclasses.
In Proceedings of the 7th European Con-ference on Speech Communication and Technology,pages 447?450.
ISCA.Stephanie Seneff.
1992.
TINA: A natural languagesystem for spoken language applications.
Computa-tional Linguistics, 18(1):61?86, March.Wayne Ward.
1990.
The CMU air travel informa-tion service: Understanding spontaneous speech.In Speech and Natural Language: Proceedings ofa Workshop Held at Hidden Valley, Pennsylvania,pages 127?129.Koichiro Yoshino, Shinsuke Mori, and Tatsuya Kawa-hara.
2011.
Spoken dialogue system based on in-formation extraction using similarity of predicate ar-gument structures.
In Proceedings of the SIGDIAL2011 Conference, pages 59?66.511
