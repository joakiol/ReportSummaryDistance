Generating statistical language models from interpretation grammars indialogue systemsRebecca JonsonDept.
of Linguistics, Go?teborg University and GSLTrj@ling.gu.seAbstractIn this paper, we explore statistical lan-guage modelling for a speech-enabledMP3 player application by generating acorpus from the interpretation grammarwritten for the application with the Gram-matical Framework (GF) (Ranta, 2004).We create a statistical language model(SLM) directly from our interpretationgrammar and compare recognition per-formance of this model against a speechrecognition grammar compiled from thesame GF interpretation grammar.
Theresults show a relative Word Error Rate(WER) reduction of 37% for the SLMderived from the interpretation grammarwhile maintaining a low in-grammarWERcomparable to that associated with thespeech recognition grammar.
From thisstarting point we try to improve our arti-ficially generated model by interpolatingit with different corpora achieving greatreduction in perplexity and 8% relativerecognition improvement.1 IntroductionIdeally when building spoken dialogue systems,we would like to use a corpus of transcribed di-alogues corresponding to the specific task of thedialogue system, in order to build a statistical lan-guage model (SLM).
However, it is rarely the casethat such a corpus exists in the early stage ofthe development of a dialogue system.
Collect-ing such a corpus and transcribing it is very time-consuming and delays the building of the actualdialogue system.An approach taken both in dialogue systemsand dictation applications is to first write an in-terpretation grammar and from that generate anartificial corpus which is used as training corpusfor the SLM (Raux et al 2003; Pakhomov et al2001; Fosler-Lussier & Kuo, 2001).
These mod-els obtained from grammars are not as good as theones built from real data as the estimates are arti-ficial, lacking a real distribution.
However, it is aquick way to get a dialogue system working withan SLM.
When the system is up and running itis possible to collect real data that can be used toimprove the model.
We will explore this idea bygenerating a corpus from an interpretation gram-mar from one of our applications.A different approach is to compile the interpre-tation grammar into a speech recognition gram-mar as the Gemini and REGULUS compilers do(Rayner et al 2000; Rayner et al 2003).
In thisway it is assured that the linguistic coverage of thespeech recognition and interpretation are kept insync.
Such an approach enables us to interpret althat we can recognize and the other way round.
Inthe European-funded project TALK the Grammat-ical Framework (Ranta, 2005) has been extendedwith such a facility that compiles GF grammarsinto speech recognition grammars in Nuance GSLformat (www.nuance.com).Speech recognition for commercial dialoguesystems has focused on grammar-based ap-proaches despite the fact that statistical languagemodels seem to have a better overall performance(Gorrell et al 2002).
This probably depends onthe time-consuming work of collecting corpora fortraining SLMs compared with the more rapid andstraightforward development of speech recogni-tion grammars.
However, SLMs are more robust,can handle out-of-coverage output, perform bet-ter in difficult conditions and seem to work bet-57ter for naive users (see (Knight et al 2001)) whilespeech recognition grammars are limited in theircoverage depending on how well grammar writerssucceed in predicting what users may say (Huanget al 2001).Nevertheless, as grammars only output phrasesthat can be interpreted their output makes the fol-lowing interpretation task easier than with the un-predictable output from an SLM (especially if thespeech recognition grammar has been compiledfrom the interpretation grammar and these are bothin sync).
In addition, the grammar-based approachin the experiments reported in (Knight et al 2001)outperforms the SLM approach on semantic errorrate on in-coverage data.
This has lead to the ideaof trying to combine both approaches, as shown in(Rayner & Hockey, 2003).
This is also somethingthat we are aiming for.Domain adaptation of SLMs is another issuein dialogue system recognition which involves re-using a successful language model by adapting itto a new domain i.e.
a new application (Janiszek etal, 1998).
If a large corpus is not available for thespecific domain but there is a corpus for a collec-tion of topics we could use this corpus and adaptthe resulting SLM to the domain.
One may as-sume that the resulting SLM based on a large cor-pus with a good mixture of topics should be able tocapture at least a part of general language use thatdoes not vary from one domain to another.
We willexplore this idea by using the Gothenburg SpokenLanguage Corpus (GSLC) (Allwood, 1999) and anewspaper corpus to adapt these to our MP3 do-main.We will consider several different SLMs basedon the corpus generated from the GF interpreta-tion grammar and compare their recognition per-formance with the baseline: a Speech Recogni-tion Grammar in Nuance format compiled fromthe same interpretation grammar.
Hence, what wecould expect from our experiment, by looking atearlier research, is very low word error rate forour speech recognition grammar on in-grammarcoverage but a lot worse performance on out-of-grammar coverage.
The SLMs we are consider-ing should tackle out-of-grammar utterances bet-ter and it will be interesting to see how well thesemodels built from the grammar will perform onin-grammar utterances.This study is organized as follows.
Section 2introduces the domain for which we are doinglanguage modelling and the corpora we have atour disposal.
Section 3 will describe the differentSLMs we have generated.
Section 4 describes theevaluation of these and the results.
Finally, we re-view the main conclusions of the work and discussfuture work.2 Description of Corpora2.1 The MP3 corpusThe domain that we are considering in this pa-per is the domain of an MP3 player application.The talking MP3 player, DJGoDiS, is one of sev-eral applications that are under development in theTALK project.
It has been built with the TrindiKittoolkit (Larsson et al 2002) and the GoDiS dia-logue system (Larsson, 2002) as a GoDiS appli-cation and works as a voice interface to a graphi-cal MP3 player.
The user can among other thingschange settings, choose stations or songs to playand create playlists.
The current version of DJ-GoDiS works in both English and Swedish.The interpretation and generation grammars arewritten with the GF grammar formalism.
GF isbeing further developed in the project to adaptit to the use in spoken dialogue systems.
Thisadaptation includes the facility of generating Nu-ance recognition grammars from the interpretationgrammar and the possibility of generating corporafrom the grammars.
The interpretation grammarfor the domain, written in GF, translates user utter-ances to dialogue moves and thereby holds all pos-sible interpretations of user utterances (Ljunglo?fet al 2005).
We used GF?s facilities to generate acorpus in Swedish consisting of all possible mean-ingful utterances generated by the grammar to acertain depth of the analysis trees in GF?s abstractsyntax as explained in (Weilhammer et al 2006).As the current grammar is under development itis not complete and some linguistic structures aremissing.
The grammar is written on the phraselevel accepting spoken language utterances suchas e.g.
?next, please?.The corpus of possible user utterances resultedin around 320 000 user utterances (about 3 mil-lion words) corresponding to a vocabulary of only301 words.
The database of songs and artists inthis first version of the application is limited to60 Swedish songs, 60 Swedish artists, 3 albumsand 3 radio stations.
The vocabulary may seemsmall if you consider the number of songs andartists included, but the small size is due to a huge58overlap of words in songs and artists as pronouns(such as Jag (I) and Du (You)) and articles (such asDet (The)) are very common.
This corpus is verydomain specific as it includes many artist names,songs and radio stations that often consist of rarewords.
It is also very repetitive covering all com-binations of songs and artists in utterances such as?I want to listen to Mamma Mia with Abba?.
Allutterances in the corpus occur exactly once.2.2 The GSLC corpusThe Gothenburg Spoken Language (GSLC) cor-pus consists of transcribed Swedish spoken lan-guage from different social activities such as auc-tions, phone calls, meetings, lectures and task-oriented dialogue (Allwood, 1999).
To be ableto use the GSLC corpus for language modellingit was pre-processed to remove annotations and allnon-alphabetic characters.
The final GSLC corpusconsisted of a corpus of about 1,300,000 wordswith a vocabulary of almost 50,000 words.2.3 The newspaper corpusWe have also used a corpus consisting of a col-lection of Swedish newspaper texts of 397 millionwords.1 Additionally, we have created a subcor-pus of the newspaper corpus by extracting only thesentences including domain related words.
Withdomain related words we mean typical words foran MP3 domain such as ?music?, ?mp3-player?,?song?
etc.
This domain vocabulary was hand-crafted.
The domain-adapted newspaper corpus,obtained by selecting sentences where these wordsoccurred, consisted of about 15 million words i.e.4% of the larger corpus.2.4 The Test CorpusTo collect a test set we asked students to describehow they would address a speech-enabled MP3player by writing Nuance grammars that wouldcover the domain and its functionality.
Anothergroup of students evaluated these grammars byrecording utterances they thought they would sayto an MP3 player.
One of the Nuance grammarswas used to create a development test set by gen-erating a corpus of 1500 utterances from it.
Thecorpus generated from another grammar writtenby some other students was used as evaluationtest set.
Added to the evaluation test set were thetranscriptions of the recordings made by the third1This corpus was made available by Leif Gro?nqvist, Dept.of Linguistics, Go?teborg Universitygroup of students that evaluated both grammars.This resulted in a evaluation test set of 1700 utter-ances.The recording test set was made up partly of thestudents?
recordings.
Additional recordings werecarried out by letting people at our lab record ran-domly chosen utterances from the evaluation testset.
We also had a demo running for a short time tocollect user interactions at a demo session.
The fi-nal test set included 500 recorded utterances from26 persons.
This test set has been used to com-pare recognition performance between the differ-ent models under consideration.The recording test set is just an approximationto the real task and conditions as the students onlycapture how they think they would act in an MP3task.
Their actual interaction in a real dialoguesituation may differ considerably so ideally, wewould want more recordings from dialogue sys-tem interactions which at the moment constitutesonly a fifth of the test set.
However, until we cancollect more recordings we will have to rely onthis approximation.In addition to the recorded evaluation test set,a second set of recordings was created coveringonly in-grammar utterances by randomly generat-ing a test set of 300 utterances from the GF gram-mar.
These were recorded by 8 persons.
This testset was used to contrast with a comparison of in-grammar recognition performance.3 Language modellingTo generate the different trigram language modelswe used the SRI language modelling toolkit (Stol-cke, 2002) with Good-Turing discounting.The first model was generated directly from theMP3 corpus we got from the GF grammar.
Thissimple SLM (named MP3GFLM) has the same vo-cabulary as the Nuance Grammar and models thesame language as the GF grammar.
This modelwas chosen to see if we could increase flexibilityand robustness in such a simple way while main-taining in-grammar performance.We also created two other simple SLMs: aclass-based one (with the classes Song, Artistand Radiostation) and a model based on avariant of the MP3 corpus where the utterancesin which songs and artists co-occur would onlymatch real artist-song pairs (i.e.
including somemusic knowledge in the model).These three SLMs were the three basic MP359models considered although we only report the re-sults for the MP3GFLM in this article (the class-based model gave a slightly worse result and the aother slightly better result).In addition to this we used our general corporato produce three different models: GSLCLM fromthe GSLC corpus, NewsLM from the newspapercorpus and DomNewsLM from the domain adaptednewspaper Corpus.3.1 Interpolating the GSLC corpus and theMP3 corpusA technique used in language modelling to com-bine different SLMs is linear interpolation (Jelinek& Mercer, 1980).
This is often used when the do-main corpus is too small and a bigger corpus isavailable.
There have been many attempts at com-bining domain corpora with news corpora, as thishas been the biggest type of corpus available andthis has given slightly better models (Janiszek etal, 1998; Rosenfeld, 2000a).
Linear interpolationhas also been used when building state dependentmodels by combining the state models with a gen-eral domain model (Xu & Rudnicky, 2000; Sol-sona et al 2002).Rosenfeld (Rosenfeld, 2000a) argues that a lit-tle more domain corpus is always better than a lotmore training data outside the domain.
Many ofthese interpolation experiments have been carriedout by adding news text, i.e.
written language.
Inthis experiment we are going to interpolate our do-main model (MP3GFLM) with a spoken languagecorpus, the GSLC, to see if this improves perplex-ity and recognition rates.
As the MP3 corpus isgenerated from a grammar without probabilitiesthis is hopefully a way to obtain better and morerealistic estimates on words and word sequences.Ideally, what we would like to capture from theGSLC corpus is language that is invariant fromdomain to domain.
However, Rosenfeld (Rosen-feld, 2000b) is quite pessimistic about this, argu-ing that this is not possible with today?s interpo-lation methods.
The GSLC corpus is also quitesmall.The interpolation was carried out with theSRILM toolkit2 based on equation 1.MixGSLCMP 3GF = ?
?
MP 3GFLM +(1 ?
?)
?
GSLCLM(1)The optimal lambda weight was estimated to0.65 with the SRILM toolkit using the develop-ment test set.2http://www.speech.sri.com/projects/srilm, as of 2005.3.2 Interpolating the newspaper corpus andthe MP3 corpusWe also created two models in the same way asabove by interpolating the two variants of the newscorpus with our simplest model.MixNewsMP 3GF = ?
?
MP 3GFLM + (1 ?
?)
?
NewsLM(2)MixDomNewsMP 3GF = ?
?MP 3GFLM+(1??
)?DomNewsLM(3)In addition to these models we created a modelwhere we interpolated both the GSLC modeland the domain adapted newspaper model withMP3GFLM.
This model was named TripleLM.3.2.1 Choice of vocabularyThe resulting mixed models have a huge vocab-ulary as the GSLC corpus and the newspaper cor-pus include thousands of words.
This is not a con-venient size for recognition as it will affect accu-racy and speed.
Therefore we tried to find an opti-mal vocabulary combining the small MP3 vocabu-lary of around 300 words with a smaller part of theGSLC vocabulary and the newspaper vocabulary.We used the the CMU toolkit (Clarkson &Rosenfeld, 1997) to obtain the most frequentwords of the GSLC corpus and the News Corpus.We then merged these vocabularies with the smallMP3 vocabulary.
It should be noted that the over-lap between the most frequent GSLC words andthe MP3 vocabulary was quite low (73 words forthe smallest vocabulary) showing the peculiarityof the MP3 domain.
We also added the vocabu-lary used for extracting domain data to this mixedvocabulary.
This merging of vocabularies resultedin a vocabulary of 1153 words.
The vocabularyfor the MP3GFLM and the MP3NuanceGr is thesmall MP3 vocabulary.4 Evaluation and Results4.1 Perplexity measuresThe 8 SLMs (all using the vocabulary of 1153words) were evaluated by measuring perplexitywith the tools SRI provides on the evaluation testset of 1700 utterances.In Table 1 we can see a dramatic perplexity re-duction with the mixed models compared to thesimplest of our models the MP3GFLM.
Surpris-ingly, the GSLCLM models the test set better than60Table 1: Perplexity for the different SLMs.LM PerplexityMP3GFLM 587GSLCLM 350NewsLM 386DomNewsLM 395MixGSLCMP3GF 65MixNewsMP3GF 78MixDomNewsMP3GF 88TripleLM 64the MP3GFLMwhich indicates that our MP3 gram-mar is too restricted and differs considerably fromthe students?
grammars.Lower perplexity does not necessarily meanlower word error rates and the relation betweenthese two measures is not very clear.
One of thereasons that language model complexity does notmeasure the recognition task complexity is thatlanguage models do not take into account acousticconfusability (Huang et al 2001; Jelinek, 1997).According to Rosenfeld (Rosenfeld, 2000a), a per-plexity reduction of 5% is usually practically notsignificant, 10-20% is noteworthy and a perplex-ity reduction of 30% or more is quite significant.The above results of the mixed models could thenmean an improvement in word error rate over thebaseline model MP3GFLM.
This has been testedand is reported in the next section.
In addition, wewant to test if we can reduce word error rate usingour simple SLM opposed to the Nuance grammar(MP3NuanceGr) which is our recognition base-line.4.2 Recognition ratesThe 8 SLMs under consideration were convertedwith the SRILM toolkit into a format that Nuanceaccepts and then compiled into recognition pack-ages.
These were evaluated with Nuance?s batchrecognition program on the recorded evaluationtest set of 500 utterances (26 speakers).
Table 2presents word error rates (WER) and in parenthe-sis N-Best (N=10)WER for the models under con-sideration and for the Nuance Grammar.As seen, our simple SLM, MP3GFLM, im-proves recognition performance considerablycompared with the Nuance grammar baseline(MP3NuanceGr) showing a much more robustbehaviour to the data.
Remember that these twomodels have the same vocabulary and are both de-Table 2: Word error rates(WER) for the recordingtest setLM WER(NBest)MP3GFLM 37.11 (29.48)GSLCLM 83.04 (71.51)NewsLM 61.62 (49.53)DomNewsLM 45.03 (31.58)MixGSLCMP3GF 34.58 (22.68)MixNewsMP3GF 38.00 (27.37)MixDomNewsMP3GF 34.07 (22.07)TripleLM 33.97 (22.02)MP3NuanceGr 59.37 (53.19)rived from the same GF interpretation grammar.However the flexibility of the SLM gives a relativeimprovement of 37% over the Nuance grammar.The models giving the best results are the modelsinterpolated with the GSLC corpus and the domainnews corpus in different ways which at best givesa relative reduction in WER of 8% in comparisonwith MP3GFLM and 43% compared with the base-line.
It is interesting to see that the simple way weused to create a domain specific newspaper cor-pus gives a model that better fits our data than theoriginal much larger newspaper corpus.4.3 In-grammar recognition ratesTo contrast the word error rate performance within-grammar utterances i.e.
utterances that the orig-inal GF interpretation grammar covers, we car-ried out a second evaluation with the in-grammarrecordings.
We also used Nuance?s parsing tool toextract the utterances that were in-grammar fromthe recorded evaluation test set.
These few record-ings (5%) were added to the in-grammar test set.The results of the second recognition experimentare reported in Table 3.Table 3: WER on the in-grammar test setLM WER (NBest)MP3GFLM 4.95 (2.04)GSLCLM 78.07 (64.15)NewsLM 48.03 (36.64)DomNewsLM 26.34 (15.25)MixGSLCMP3GF 14.23 (6,29)MixNewsMP3GF 18.63 (10.22)MixDomNewsMP3GF 15.57 (6.13)TripleLM 15.17 (6.05)MP3NuanceGr 3.69 (1.49)61The in-grammar results reveal an increase inWER for all the SLMs in comparison to thebaseline MP3NuanceGr.
However, the simplestmodel (MP3GFLM), modelling the language of thegrammar, do not show any greater reduction inrecognition performance.4.4 Discussion of resultsThe word error rates obtained for the best mod-els show a relative improvement over the Nuancegrammar of 40%.
The most interesting result isthat the simplest of our models, modelling thesame language as the Nuance grammar, gives suchan important gain in performance that it lowersthe WER with 22%.
We used the Chi-square testof significance to statistically compare the resultswith the results of the Nuance grammar show-ing that the differences of WER of the modelsin comparison with the baseline are all signifi-cant on the p=0.05 significance level.
However,the Chi-square test points out that the differenceof WER for in-grammar utterances of the Nu-ance model and the MP3GFLM is significant on thep=0.05 level.
This means that all the statistical lan-guage models significantly outperform the base-line i.e.
the Nuance Grammar MP3NuanceGron the evaluation test set (being mostly out-of-coverage) and that the MP3GFLM outperforms thebaseline overall as the difference of WER in thein-grammar test is significant but very small.However, as the reader may have noticed, theword error rates are quite high, which is partlydue to a totally independent test set with out-of-vocabulary words (9% OOV for the MP3GFLM )indicating that domain language grammar writingis very subjective.
The students have captureda quite different language for the same domainand functionality.
This shows the risk of a hand-tailored domain grammar and the difficulty of pre-dicting what users may say.
In addition, a fair testof the model would be to measure concept errorrate or more specifically dialogue move error rate(i.e.
both ?yes?
and ?yeah?
correspond to the samedialogue move answer(yes)).
A closer lookat the MP3GFLM results give a hint that in manycases the transcription reference and the recogni-tion hypothesis hold the same semantic content inthe domain (e.g.
confusing the Swedish preposi-tions ?i?
(into) and ?till?
(to) which are both usedwhen referring to the playlist).
It was manuallyestimated that 53% of the recognition hypothesescould be considered as correct in this way opposedto the 65% Sentence Error Rate (SER) that theautomatic evaluation gave.
This implies that theevaluation carried out is not strictly fair consid-ering the possible task improvement.
However, afair automatic evaluation of dialogue move errorrate will be possible only when we have a way todo semantic decoding that is not entirely depen-dent on the GF grammar rules.The N-Best results indicate that it could beworth putting effort on re-ranking the N-Best listsas both WER and SER of the N-Best candidatesare considerably lower.
This could ideally give usa reduction in SER of 10% and, considering dia-logue move error rate, perhaps even more.
Moreor less advanced post-process methods have beenused to analyze and decide on the best choice fromthe N-Best list.
Several different re-ranking meth-ods have been proposed that show how recogni-tion rates can be improved by letting external pro-cesses do the top N ranking and not the recognizer(Chotimongkol & Rudnicky, 2001; van Noord etal., 1997).
However, the way that seems most ap-pealing is how (Gabsdil & Lemon, 2004) and (Ha-cioglu & Ward, 2001) re-rank N-Best lists basedon dialogue context achieving a considerable im-provement in recognition performance.
We areconsidering basing our re-ranking on the informa-tion held in the dialogue information state, knowl-edge of what is going on in the graphical interfaceand on dialogue moves in the list that seem appro-priate to the context.
In this way we can take ad-vantage of what the dialogue system knows aboutthe current situation.5 Concluding remarks and future workA first observation is that the SLMs give us a muchmore robust recognition, as expected.
Our bestSLMs, i.e.
the mixed models, give a 43% rela-tive improvement over the baseline i.e.
the Nu-ance grammar compiled from the GF interpreta-tion grammar.
However, this also implies a fallingoff in in-grammar performance.
It is interest-ing that the SLM that only models the grammar(MP3GFLM), although being more robust and giv-ing a significant reduction in WER rate, does notdegrade its in-grammar performance to a great ex-tent.
This simple model seems promising for usein a first version of the system with the possibil-ity of improving it when logs from system interac-tions have been collected.
In addition, the vocabu-62lary of this model is in sync with our GF interpre-tation grammar.
The results seem comparable withthose obtained by (Bangalore & Johnston, 2004)using random generation to produce an SLM froman interpretation grammar.Although interpolating our MP3 model with theGSLC corpus and the newspaper corpora gave alarge perplexity reduction it did not have as muchimpact on WER as expected even though it gavea significant improvement.
It seems from the teststhat the quality of the data is more important thanthe quantity.
This makes extraction of domaindata from larger corpora an important issue andincreases the interest of generating artificial cor-pora.As the approach of using SLMs in our dia-logue systems seems promising and could im-prove recognition performance considerably weare planning to apply the experiment to other ap-plications that are under development in TALKwhen the corresponding GF application grammarsare finished.
In this way we hope to find out ifthere is a tendency in the performance gain ofa statistical language model vs its correspondentspeech recognition grammar.
If so, we have founda good way of compromising between the ease ofgrammar writing and the robustness of SLMs inthe first stage of dialogue system development.
Inthis way we can use the knowledge and intuitionwe have about the domain and include it in ourfirst SLM and get a more robust behaviour thanwith a grammar.
From this starting point we canthen collect more data with our first prototype ofthe system to improve our SLM.We have also started to look at dialogue movespecific statistical language models (DM-SLMs)by using GF to generate all utterances that arespecific to certain dialogue moves from our in-terpretation grammar.
In this way we can pro-duce models that are sensitive to the context butalso, by interpolating these more restricted mod-els with the general GF SLM, do not restrict whatthe users can say but take into account that cer-tain utterances should be more probable in a spe-cific dialogue context.
Context-sensitive modelsand specifically grammars for different contextshave been explored earlier (Baggia et al 1997;Wright et al 1999; Lemon, 2004) but generatingsuch language models artificially from an interpre-tation grammar by choosing which moves to com-bine seems to be a new direction.
Our first ex-periments seem promising but the dialogue movespecific test sets are too small to draw any conclu-sions.
We hope to report more on this in the nearfuture.AcknowledgementsI am grateful to Steve Young, Robin Cooper andthe EACL reviewers for comments on previousversions of this paper.
I would also like to thankAarne Ranta, Peter Ljunglo?f, Karl Weilhammerand David Hjelm for help with GF and data col-lection and finally Nuance Communications Inc.for making available the speech recognition soft-ware used in this work.
This work was supportedin part by the TALK project (FP6-IST 507802,http://www.talk-project.org/).ReferencesAllwood, J.
1999.
The Swedish Spoken Language Cor-pus at Go?teborg University.
In Fonetik 99, Gothen-burg Papers in Theoretical Linguistics 81.
Dept.
ofLinguistics, University of Go?teborg.Baggia P., Danieli M., Gerbino E., Moisa L. M., andPopovici C. 1997.
Contextual Information and Spe-cific Language Models for Spoken Language Un-derstanding.
In Proceedings of SPECOM?97, Cluj-Napoca, Romania, pp.
51?56.Bangalore S. and Johnston M. 2004.
Balancing Data-Driven And Rule-Based Approaches in the Contextof aMultimodal Conversational System.
In Proceed-ings of Human Language Technology conference.HLT-NAACL 2004.Chotimongkol A. and Rudnicky A.I.
2001.
N-bestSpeech Hypotheses Reordering Using Linear Re-gression.
In Proceedings of Eurospeech 2001.
Aal-borg, Denmark, pp.
1829?1832.Clarkson P.R.
and Rosenfeld R. 1997.
StatisticalLanguage Modeling Using the CMU-CambridgeToolkit.
In Proceedings of Eurospeech.Fosler-Lussier E. and Kuo H.-K. J.
2001.
Using Se-mantic Class Information for Rapid Development ofLanguage Models within ASR Dialogue Systems.
InProceedings of ICASSP-2001, Salt Lake City, Utah.Gabsdil M. and Lemon O.
2004.
Combining Acousticand Pragmatic Features to Predict Recognition Per-formance in Spoken Dialogue Systems.
In Proceed-ings of ACL, Barcelona.Gorrell G., Lewin I. and Rayner M. 2002.
Adding In-telligent Help to Mixed Initiative Spoken DialogueSystems.
In Proceedings of ICSLP-2002.63Hacioglu K. and Ward W. 2001.
Dialog-context de-pendent language modeling combining n-grams andstochastic context-free grammars.
In Proceedings ofICASSP-2001, Salt Lake City, Utah.Huang X., Acero A., Hon H-W. 2001.
Spoken Lan-guage Processing: A guide to theory, algorithm andsystem development.
Prentice Hall.Janiszek D., De Mori R., Bechet F. 1998.
Data Aug-mentation And Language Model Adaptation.
Uni-versity of Avignon 84911 Avignon Cedex 9 - France.Jelinek, F. and Mercer, R. 1980.
Interpolated Estima-tion ofMarkov Source Parameters from Sparse Data.In Pattern Recognition in Practice.
E. S. Gelsemaand L. N. Kanal, North Holland, Amsterdam.Jelinek, F. 1997.
Statistical Methods for Speech Recog-nition.
MIT Press.Knight S., Gorrell G., Rayner M., Milward D., KoelingR.
and Lewin I.
2001.
Comparing Grammar-Basedand Robust Approaches to Speech Understanding:A Case Study.
In Proceedings of Eurospeech 2001.Larsson S. 2002.
Issue-based Dialogue Management.PhD Thesis, Go?teborg University.Larsson S., Berman A., Gro?nqvist L., Kronlid, F. 2002.TRINDIKIT 3.0 Manual.
D6.4, Siridus Project,Go?teborg University.Lemon O.
2004.
Context-sensitive speech recognitionin ISU dialogue systems: results for the grammarswitching approach.
In Proceedings of CATALOG,8th Workshop on the Semantics and Pragmatics ofDialogue, Barcelona.Ljunglo?f P., Bringert B., Cooper R., Forslund A-C.,Hjelm D., Jonson R., Larsson S. and Ranta A.
2005.The TALK Grammar Library: an Integration of GFwith TrindiKit.
Deliverable 1.1, TALK project.Nuance Communications.
http://www.nuance.com, asof May 2005.Pakhomov SV., Schonwetter M., Bachenko, J.
2001.Generating Training Data for Medical Dictations.
InProceedings NAACL-2001.Ranta A.
2004.
Grammatical Framework.
A Type-Theoretical Grammar Formalism.
In The Journal ofFunctional Programming., Vol.
14, No.
2, pp.
145?189.Ranta A. Grammatical Framework Homepagehttp://www.cs.chalmers.se/a?arne/GF, as of May2005.Raux A., Langner B., Black A. and Eskenazi M. 2003.LET?S GO: Improving Spoken Dialog Systems forthe Elderly and Non-natives.
In Proceedings of Eu-rospeech 2003.
Geneva, Switzerland.Rayner M., Hockey B.A., James F., Owen Bratt E.,Goldwater S., Gawron J.M.
2000.
Compiling Lan-guage Models from a Linguistically Motivated Uni-fication Grammar.
In Proceedings of COLING-2000.Rayner M., Hockey B.A., Dowding J.
2003.
An Open-Source Environment for Compiling Typed Unifica-tion Grammars into Speech Recognisers.
In Pro-ceedings of EACL, pp.
223?226.Rayner M. and Hockey B.A.
2003.
Transparent combi-nation of rule-based and data-driven approaches inspeech understanding.
In Proceedings of EACL.Rosenfeld R. 2000.
Two decades of statistical languagemodeling: Where do we go from here?
In Proceed-ings of IEEE:88(8).Rosenfeld R. 2000.
Incorporating Linguistic Structureinto Statistical Language Models.
In PhilosophicalTransactions of the Royal Society of London A, 358.Solsona R., Fosler-Lussier E., Kuo H.J., PotamianosA.
and Zitouni I.
2002.
Adaptive Language Mod-els for Spoken Dialogue Systems.
In Proceedings ofICASSP-2002, Orlando, Florida, USA.Stolcke A.
2002.
SRILM ?
An Extensible LanguageModeling Toolkit.
In Proceedings of ICSLP-2002,Vol.
2, pp.
901?904, Denver.van Noord G., Bouma G., Koeling R. and Nederhof,M.
1999.
Robust Grammatical Analysis for SpokenDialogue Systems.
In Journal of Natural LanguageEngineering, 5(1), pp.
45?93.Wright H., Poesio M. and Isard S. 1999.
Using highlevel dialogue information for dialogue act recogni-tion using prosodic features.
In DIAPRO-1999, pp.139?143.Weilhammer K., Jonson R., Ranta A, Young Steve.2006.
SLM generation in the Grammatical Frame-work.
Deliverable 1.3, TALK project.Xu W. and Rudnicky A.
2000.
Language modeling fordialog system?
In Proceedings of ICSLP-2000, Bei-jing, China.
Paper B1-06.64
