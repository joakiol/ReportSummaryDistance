Semantic Forensics:An Application of Ontological Semantics to Information AssuranceVictor Raskin, Christian F. Hempelmann, and Katrina E. TriezenbergNLP Lab and CERIASPurdue University{vraskin, hempelma, kattriez}@purdue.eduAbstractThe paper deals with the latest application ofnatural language processing (NLP), specifically ofontological semantics (ONSE) to natural languageinformation assurance and security (NL IAS).
Itdemonstrates how the existing ideas, methods,and resources of ontological semantics can beapplied to detect deception in NL text (and,eventually, in data and other media as well).
Afterstating the problem, the paper proceeds to a briefintroduction to ONSE, followed by an equallybrief survey of our 5-year-old effort in?colonizing?
IAS.
The main part of the paperdeals with the following issues:?
human deception detection abilities and NLPmodeling of it;?
manipulation of fact repositories for thispurpose beyond the current state of the art;?
acquisition of scripts for complex ontologicalconcepts;?
degrees of lying complexity and feasibility oftheir automatic detection.This is not a report on a systemimplementation but rather an application-establishing proof-of-concept effort based on thealgorithmic and machine-tractable recombinationand extension of the previously implementedONSE modules.
The strength of the approach isthat it emphasizes the use of the existing NLPapplications, with very few domain- and goal-specific adjustments, in a most promising andgrowing new area of IAS.
So, while clearlydealing with a new application, the paperaddresses theoretical and methodologicalextensions of ONSE, as defined currently, thatwill be useful for other applications as well.1 The ProblemThe proposed application falls within the rapidlygrowing domain of cyber forensics, and theinclusion of NLP in it is a desirable and mutuallybeneficial goal.
Forensic science, in general,encompasses any scientific discipline that isconcerned with the direct application of scientificprinciples and theories to law enforcement(Saferstein 2004), that is, the systematic searchfor, discovery, and application of clues to eventreconstruction?for the purposes of justice.
Aswith any of the other traditional forensic sciences(e.g., DNA, Serology, Latent Fingerprint Analysisetc.)
the development of the cyber forensicsFigure 1: Resources of Ontological Semanticsdiscipline is based on a sound scientificfoundation, compliance with legal requirements,and a unified maturation process (Palmer 2002;Rogers & Seigfried 2004; Whitcomb 2002).
Thecurrent foundation for cyber forensics ismultidisciplinary in nature and combinesestablished pure sciences (e.g., computer science,math) and applied sciences (e.g., informationtechnology, engineering, and now NLP).
Cyberforensics is still in search of its theory andmethodology; NLP comes into it on strong andexplicit theoretical foundations (see Nirenburgand Raskin 2004: 34-91).As far as we know, no similar research hasbeen undertaken yet.
The Patrick group at theUniversity of Sydney reported on a "bag-of-words" system comparing the Nigerian e-mailswith Reuters' financial reports and concluding thatthe presence of the personal pronouns I/me andyou in the former but not in the latter violates theinterpersonal relations of the register in theformer, thus leading to characterizing them asscams (Herke-Couchman et al 2003; Whitelawand Argamon 2004).
The difference in theproposed approach is that it goes beyond treatingwords as just character strings and represents theirmeanings, as well as those of the sentences and oftheir text, explicitly and manipulates themlogically, as it were, rather than statistically.
Theresult, typical for the comparison ofcomputational semantics with computationalstatistics, is that a semantic forensics system iscapable of identifying specific facts/events thatcontribute to the deception and of understandingwhat those events are?the characterization of thetext as fraudulent comes then as a trivial sideeffect.
The Patrick approach can, however, beused to assists semantic forensics by pre-identifying some texts as suspicious cheaply andthus reducing the general semantic forensics to amore targeted and feasible task (see Section 6below).
Also, their ScamSeek Project has declaredan intention to move towards true meaningfeatures (http://www.cs.usyd.edu.au/~lkmrl/scam-seek.htm).Outside of NLP, the British-centeredlinguistic forensics community (IAFL) has beenengaged in traditional largely qualitative stylisticresearch in the spirit of the 1960s?
text attribution,an effort to break the anonymity of a text and toidentify its authorship for the purposes of lawenforcement (McMenamin 2002, Gibbons 2003,Olsson 2004).While other disciplines within cyber forensicsexplore largely non-textual materials?and thosewhich look at texts, with the above-mentionedexceptions.
do not do so linguistically?semanticforensics, as defined here, uses NLP to identifythe clues of deception in NL texts in order toreconstruct the described events as they actuallyoccurred.
Now, it can be argued, with reason, thatthe truthful elements in NL texts are also clues forevent reconstruction and should be included insemantic forensics, and, of course, in a way theyare.
But those, if indeed truthful, do not comeunder the task of reconstructing events; rather,they establish the events.
Besides, the truthfulelements of NL texts get the text meaningrepresentation (TMR) in the normal course ofevents, so no special semantic forensic effortneeds to be developed with regard to them.
This isnot set in concrete, however, because theidentification and exploration of deception cluesclearly involves the non-deceptive TMRs andtheir fragments.Semantic forensics is firmly based on ONSE,and a semantic forensic analysis of the textpresupposes and follows the regular ONSEprocess of automatic meaning representation ofeach input sentence and, ultimately, the text.
Thenext section offers a brief introduction into theONSE process of meaning representation, with anemphasis on analysis rather than generation andwith a bias towards IAS applications.
It can belargely skipped by those familiar with ONSE.2 Ontological Semantics in BriefONSE contains several modules, with an ontologyat the center; the other important modules arelexicons of languages and a fact repository, inwhich information about the world is stored, and,of course, the analyzer and generator.
Theanalytical goal of ONSE is to produce a TMR forNL input as well as NL or other output for eachTMR (see figure 1).PAYdefinition value ?to compensatesomebody for goodsor services rendered?is-a value EVERYDAY-FINANCIAL-EVENTsubclasses value PAY-TAXSUBSCRIBE-TOagent sem HUMANrelaxable-to ORGANIZATIONtheme default MONEYsem COMMODITYrelaxable-to EVENTpatient sem HUMANrelaxable-to ORGANIZATIONFigure 2: Ontological Concept PAYThe ontology is a tangled hierarchy (lattice)of concepts, beginning at the root ALL, branchinginto OBJECT, EVENT, and PROPERTY, and so forth.Each node of the hierarchy is a concept with a setof properties, many of which are inherited fromits ancestors, and at least one property other thanthe IS-A property is distinguished from its parentnode as well as from its sibling nodes.
Theontological concept for PAY might therefore looklike figure 2 (cf.
Nirenburg and Raskin 2004:196ff.
).As we see, the IS-A and SUBCLASSES slots arefilled with other ontological concepts, as areAGENT, THEME, and PATIENT, the case-role slots.VALUE, SEM, RELAXABLE-TO and DEFAULT are allfacets of their slots.good-adj1cat adjSYN-STRUC1 root $var1cat nmods root good2 root $var0cat adjsubj root $var1cat nSEM-STRUCmodality type evaluativevalue value >0.75relaxable-to >0.6scope ^$var1attributed-to *speaker*Figure 3: Lexical Entry for ?good?Lexicons contain the actual words of alanguage, in contrast to the ontology?s universal,language-independent concepts.
The entry foreach word in the lexicon contains all possiblesenses of that word, labeled with a part of speechand a sense number.
The lexical entry for theEnglish word p a y  contains three senses,respectively pay-n1, pay-n2, and pay-v1.
Each ofthe senses is then assigned, most importantly, theinformation about the acceptable syntacticenvironments for the sense, or SYN-STRUC, andinformation about the word?s meaning, or SEM-STRUC.
It is in SEM-STRUC that each lexical itemis linked to one or more ontological concepts, orto literals.
The lexical entry for the Englishadjective good looks something like figure 3.When a text is fed into the ONSE system, itslexical items are identified, as well as severalTMR parameters, such as discourse relationsincluding modalities, aspect, information aboutordering and duration in time, style, and sets ofconcepts working together.
The first step inbuilding a TMR is finding meanings for heads ofclauses in the syntactic representation of input,which are most commonly verbs.
The TMR,however, will typically end up containing moreevent instances than there are verbs in the originaltext.
After identifying these events, building theTMR is a (non-trivial) matter of fitting all theother information of the text into the filler slots ofthe events and the additional parameters.
In figure4 are the much-simplified TMRs for three relatedsentences, which demonstrate how small changesin texts affect TMRs.Who won the match?win-1theme value sports-match-2request-information-1theme value win-1.agentDid Arsenal win the match?win-1agent value Arsenaltheme value sports-match-1request-information-1theme value win-1Was it Arsenal who won the match?win-1agent value Arsenaltheme value sports-match-1request-information-1theme value win-1modality-1type saliencescope win-1.themevalue 1Figure 4: TMR ExampleThe next section reviews the NL IASapplications discovered and explored?frominitial steps to pilot implementations?in theongoing effort to export NLP into computer andinformation security.3  Applications of NLP to InformationAssurance and SecurityIn the last 5 years, a CERIAS-based team led by acomputer scientist and an NLP expert has steadilyexpanded its groundbreaking effort in improving,focusing, and strengthening information assuranceand security by applying the NLP resources tothem.
The result has been a growing number ofapplications, some of them NL counterparts ofpre-existing applications, others NL extensionsand developments of known applications, and stillothers unique to NL IAS.
In the mostimplemented one, NL watermarking (see Atallahet al 2002), a sophisticated mathematicalprocedure, based on a secret large prime number,selects certain sentences in a text for watermarkbearing and transforms their TMRs into bitstringsthat contribute up to 4 bits per sentence to thewatermark.
The goal of the software is, of course,to embed a robust watermark in the hiddensemantic meaning of NL text, represented as itsTMR in tree structure.
The NLP role is to?torture?
the TMR tree of the sentence, whosecontributing bits do not fit the watermark, so thatthey do.
The tool for that is a number ofminuscule TMR tree transformations, resulting insuch surface changes as The coalition forcesbombed Kabul ?
The coalition forces bombedthe capital of Afghanistan.
The applications aresummarized in table 1.4  Human Deception Detection and ItsNLP ModelingLike all NLP systems, a Semantic Forensic (SF)NLP system models a human faculty.
In this case,it is the human ability to detect deception (DD),i.e., to know when they are being lied to and toattempt to reconstruct the truth.
The former abilityis a highly desirable but, interestingly, notnecessary precondition for DD (see anexplanation below, in the Feasibility section).
Thelatter functionality is the ultimate goal of SF NLPbut, like all full automation in NLP, it may not beeasily attainable.Humans detect lying by analyzing meaning ofwhat they hear or read and compare that meaningto other parts of the same discourse, to theirpreviously set expectations, and to theirknowledge of the world.
Perhaps the easiest lie todetect is a direct contradiction: If one hears firstthat John is in Barcelona today and then that he isnot, one should suspect that one of the twostatements is incorrect and to investigate?if oneis interested, a crucial point.
The harder type ofdeception to perceive is by omission: The firstauthor was pushed into SF after having read adetailed profile of Howard Dean, then a leadingcontender for the Democratic nomination in theUS 2004 presidential election, and noticed that theoccupation of every single adult mentioned in thearticle was indicated with the exception of thecandidate?s father, who had been a stockbroker.Glossing over, such as saying that one has not hadmuch opportunity to talk to John lately, whichmay be technically true, while covering up amajor fallout with John, is yet more complicated.And perhaps topping the hierarchy is lying bytelling the truth: when a loyal secretary tells theboss?
jealous wife that her husband is not in theoffice because he is running errands downtown,she may well be telling the truth (though not thewhole truth?but, realistically, can one tell thewhole truth ever?
?is it even a useful notion,especially given the fact that languageunderdetermines reality (cf.
Barwise and Perry1983)); but what she wants to accomplish is forthe wife to infer, incorrectly, that this is all theboss is doing downtown.
It is the latter,linguistically interesting type that was the focus ofRaskin (1987).Application Function Implementation ReferenceMnemonic String Generator Generates jingles corresponding torandom-generated passwordsPilot Raskin et al2001aSyntactic NL Watermarking Embeds the watermark in the syntactictree of a sentencePilot/demo Atallah et al2001Semantic NL Watermarking Embeds the watermark in the TMR treeof a sentencePilot Atallah et al2002NL Tamperproofing Embeds a brittle watermark to detect anychanges to the textPilot Atallah et al2002NL Sanitization Seamlessly removes and replacessensitive informationProof of concept Mohamed2001Automatic TerminologyStandardizerTranslates different terminologicaldialects in IAS into TMRsProof of concept Raskin et al2002aPerimeter Protection Sanitizes outgoing e-mail online Proof of concept Raskin et al2001bNL Streaming Processor Interprets incoming information before itis completeResearch Raskin et al2002bNL Steganalysis Detects the presence of a hiddenmessageResearch Raskin et al2002bSemantic Mimicking Creates a meaningful cohesive text tohide a secret messageResearch Bennett 2003Web Crawler for PlannedAttacksCrawls the web in search of credibleinformation on computer attacksResearch Raskin et al2002bOntological support for Non-NLdataHelps to classify incoming strings in acomputer attackInitial Research Raskin 2004Table 1: NL IAS ApplicationsA new TMR contradicting a previouslyprocessed one should lead to a fact repositoryflag, and this is where we are moving next.5  Using the Fact Repository forDeception DetectionThe fact repository (FR?see Nirenburg andRaskin 2004: 350-1), so far the least developedstatic resource in ONSE, records the rememberedevent instances.
In principle, it should record allof them.
Realistically, it records them selectivelyto suit the needs of an implementation.
Thus, inCRESP, a small QA system for queries about the2000 Olympics in Sydney, the FR remembered allthe nations, all the participants, all the competitiveevents, and all the results.
A SF NLP system maystart at the same level of prominence (and detectone?s lie about having participated in the Gamesand/or achieved a better result), but like almost allNLP systems with reasoning abilities, it will beonly as powerful as its FR allows.A contradiction will be flagged when twoTMR (fragments) are discovered: For example,one having been just processed for J o h nis/was/will be in Barcelona at noon on the 25th(ofJuly 2004) and the other in the FR for Johnis/was/will be in Valencia at noon on the 25th(ofJuly 2004)?or their paraphrases (see figure 5).human-17name John-23location Barcelonatime noon, July 25, 2004human-89name John-23location Valenciatime noon, July 25, 2004Figure 5: Fact Repository Sample EntriesIn the case of Papa Dean?s occupation,apparently too shameful for the reporter tomention even after he had divulged the ParkAvenue childhood, hereditary Republicanism, anddiscriminatory country club and even though thereare still a few stockbrokers on this side of thebars, the FR will easily detect it by presenting thisinformation, very simplistically, as in figure 6.To detect a gloss-over, it is not quite enoughto receive a new TMR which contains an eventinvolving a different interaction between thesetwo individuals at the same time.
The co-reference microtheory (see Nirenburg and Raskin2004: 301-5) will have to be able to determine orat least to suspect that these events are indeed oneand the same event rather than two consecutive oreven parallel events.
Even the time parameters arenot a trivial task to equate, as in the case of I havenot much opportunity to talk to John lately andJohn insulted me last May.
It would be trivial, ofcourse, if the temporal adverbials were since thatnight at Maude?s and that night at Maude?s,respectively, but a human sleuth does not get suchincredibly easy clues most of the time and has tooperate on crude proximity and hypothesizing.Also helping him or her is a powerful inferencingengine, obviously a must for an NLP system ofany reasonable complexity, reinforced by amicrotheory of euphemisms, which must containrepresentative sets of event types that people lieabout and of fossilized, clich?-like ways of lyingabout them, as in How is this paper??Well?
it?sdifferent!human-1name Howard Deanage adultoccupation physicianhuman-2name Judy Deanage adultoccupation physicianhuman-3name Papa Deanage adult (very: rather dead, actually)occupation unknownFigure 6: Fact Repository Sample EntriesThe reason we think that the loyal secretary?stype of lying is harder to detect is not because itmay involve more inferencing of a more complexkind?this is not necessarily so.
It has to do withthe notion of the whole truth: It is not realistic toexpect a human, let alne an SF NLP to suspectany information to be incomplete and subjectevery single TMR to the ?and what else did he dodowntown?
type of query.
But, in many cases, thisis necessary to do, which brings up the usefuldistinction between general and targeted SF.6  Feasibility of Semantic ForensicSystemsA general SF (GSF) task is, basically, a fishingexpedition.
An SF NLP system may indeedexpose obvious contradictions and manyomissions.
It is a long and expensive process,however, definitely overloading the system?s FR.Inferring from every established contradiction oromission, while possibly valuable forensically, isan unaffordable luxury in this kind of task.
It may,however, be a necessary evil: for instance, if anSF NLP system is to address a source that isknown to be tainted or if it to be used to classifytexts by the degree of their trustworthiness?quitea possible assignment.Humans do a degree of general SF undersimilar circumstances.
But even in an exchangewithout a prior agenda, such as a conversationwith a stranger under neutral, casual, indifferentcircumstances, the SF/DD module may not beactivated unless flagged by, again, acontradiction, an omission, etc.
And such a flagwill transform general SF into targeted SF (TSF).Now, TSF is what professional forensics doesfor a living, and there is no reason why the entry-level SF NLP systems should not be all TSF.Even in the case of the Dean text, a TSF system(?look for anything compromising in thecandidate?s background?)
will be able to detectthe occupation omission much faster.
A TSF issimpler and cheaper, and the FR use is much morereasonable and manageable: it can store only veryselective, limited material.
The flip side of a TSFsystem is the easy ability to overlook highlyrelated information an inference away, so we havereasons to suspect that a quality TSF NLP systemis not that much simpler than, say, a limiteddomain GSF system.What is important to realize is that some NLPsystems with SF capabilities are within reach inONSE, using the already available resources,possibly with some modifications, primarily if notentirely on the static side, and that is not muchdifferent than changing domains for a ?regular?NLP system (see Raskin et al 2002b).7  Using Scripts of Complex Events forDeception DetectionA main tool for DD, in particular TSF, is theexpansion of the ontology by acquiring scripts ofcomplex events, already found necessary for otherhigher-end NLP tasks (see Raskin et al 2003).There are strong connections among elementsof many texts.
These have to do with theunderstanding that individual propositions mayhold well-defined places in ?routine,?
?typical?sequences of events (often called complex events,scripts or scenarios) that happen in the world,with a well-specified set of object-like entitiesthat appear in different roles throughout thatsequence.
A script captures the entities of such anevent and their temporal and causal sequences, asshown for the complex event BANKRUPTCY infigure 7.As a general tool in ONSE, the scripts that getinstantiated from the text input provideexpectations for processing further sentences in atext.
Indeed, if a sentence in a text can be seen asinstantiating a script in the nascent TMR, theanalysis and disambiguation of subsequentsentences can be aided by the expectation thatpropositions contained in them are instantiationsof event types that are listed as components of theactivated script.BANKRUPTCYis-a financial-eventagent corporation-1human-1lending-institution-1corporation-2human-2precondition approach-bankruptcyhas-parts (IFANDmodality.scope = paymodality.value < .5THEN bankruptcy-chapter-7ELSE bankruptcy-chapter-11)BANKRUPTCY-APPROACH-STATEis-a financial-eventagent bankruptcy.agentdestination bankruptcyagent bankruptcy.agenthas-parts(IFANDoweagent corporation-1human-1beneficiary human-2employed-by    corporation-1lending-institution-2corporation-2theme moneypayagent corporation-1human-1beneficiary human-2lending-institution-1corporation-2theme moneyTHEN bankruptcyagent corporation-1human-1CONCEALis-a sales-eventagent bankruptcy.agenttheme assetsowned-by bankruptcy.agentprecondition bankruptcyagent bankruptcy.agenttime.sales-event  ?
time.bankruptcy-approach-stateFigure 7: Simplified Fragments of Scripts in theBANKRUPTCY DomainIn addition, the expectations that scriptsprovide play a crucial role for DD, namely in thedetection of omission, in two complementaryways.The more obvious one is the need for anexpectation of what information is to be found ina text in order to be able to infer gaps.
A commonattempt at deception in bankruptcy cases, forexample, is concealment of pre-bankruptcyconversions of property from creditors, which is amajor factor considered by the courts indetermining whether there was an intent to hinder,delay or defraud in a bankruptcy.
Thus, if a sale ofassets by a company prior to its filing bankruptcyis found in a text and there is no mention of howclosely to the filing this conversion took place,this needs to raise a flag that possiblyconcealment took place.
This can be establishedsince CONCEALMENT is defined as part of thescript BANKRUPTCY, which is instantiated for theTMR of the text.
If it can be established, from thetext itself or the FR, that the sale of the assets tookplace while the company was approaching thestate of bankruptcy, the omission of the specifictime of sale in the report constitutes deception.Here, the script facilitates the targeting of SF (seeprevious section) by mapping where omissions inthe text point to the omission of crucialinformation.The second mechanism by which scriptsfacilitate DD is when an event that occurscommonly or exclusively as a subevent of ascript, which is otherwise not mentioned, is foundin a text.
Here, the inference should be that thelarger context of this subevent, captured by thescript, is to be concealed.
If, for example, acompany issues a report that mentions the layoffof some of its employees, this should lead to theinference that it approaches the state ofbankruptcy, for which layoffs are a possiblesubevent.Simplified to a few subevents, these twoDD mechanisms on the basis of scripts can besummarized as follows (cf.
figure 8): 1.
If anecessary element of a script is missing it is likelyto be intentionally omitted.
2.
If an element thatcommonly occurs as part of a script is found in atext, but no other element of it, that is, the script isunderinstantiated, the script is likely to beintentionally omitted.SCRIPThas-partANDevent-1 found in textevent-2 found in textevent-3 not found in textevent-4 found in textSCRIPThas-partANDevent-1 not found in textevent-2 not found in textevent-3 found in textevent-4 not found in textFigure 8: Simplified Script Structures8 ConclusionThe main thrust of the paper has been not so muchthe establishment of a sexy application as todemonstrate that the rich resources of NLP, ingeneral, and ONSE, in particular, are versatileenough to be extended to interesting new uses andthat getting there involves theoretical andmethodological developments that are generallygood for the field rather than just for SF (e.g.,who will refuse a microtheory of euphemisms?
).Throughout, we have insinuated, ever so subtly,that the tasks in hand are not manageable by anyof the past or current meaning-avoiding, non-representational approaches.
This is not to say thata good SF NLP system must be statistics-free:Crude measures are good to have for heuristic andother startup purposes?but it is TMR elementsthat such statistics will be counting.
We have leftout many aspects of SF, such as potential demand,which is great, and other practical considerations.As resources permit, we have been movingconsistently to enrich our ONSE resources withIAS capabilities and functionalities, and SF is thelatest but, very probably, not the last of those.9 AcknowledgmentsWe are grateful to the two anonymous referees fortheir thought-provoking remarks.
We appreciateProfessor Jon Patrick?s unsolicited comments aswell as his making two hard-to-access papersfrom his research group available to us.
We haveprofited greatly from the cooperation with ourCERIAS colleagues and from the Center?ssupport for the NL IAS endeavors over the last 5years.10 ReferencesAtallah, M. J., V. Raskin, M. Crogan, C. F.Hempelmann, F. Kerschbaum, D. Mohamed,and S. Naik.
2001.
Natural LanguageWatermarking: Design, Analysis, and a Proof-of-Concept Implementation.
In: I. S.Moskowitz (ed.
), Information Hiding: 4thInternational Workshop, IH 2001, Pittsburgh,PA, USA, April 2001 Proceedings.
Berlin:Springer, 185-199.Atallah, M. J., V. Raskin, C. F. Hempelmann, M.Karahan, R. Sion, U. Topkara, and K. E.Triezenberg.
2002.
Natural LanguageWatermarking and Tamperproofing.
In: F. A.P.
Petitcolas (ed.
), Information Hiding: 5thInternational Workshop, IH 2002,Proceedings.
Berlin: Springer, 196-210.Barwise, J., and J. Perry.
1983.
Situations andAttitudes.
Cambridge, MA: MIT Press.Bennett, K. 2003.
Semantic mimicking.
CERIASTR (www.cerias.purdue.edu), PurdueUniversity, W. Lafayette, IN.Herke-Couchman, M., C. Whitelaw, and J. Patrick2003.
Identifying interpersonal features usingsystemic features, AAAI Symposium.Gibbons, J.
2003.
Forensic Linguistics: AnIntroduction to Language in the JusticeSystem.
Oxford: Blackwell.McMenamin, G. R. 2002.
Forensic Linguistics:Advances in Forensic Stylistics.
Boca Raton,LA: CRC Press.Mohamed, D. 2001.
Ontological SemanticsMethods for Automatic Downgrading.
Anunpublished Masters?
thesis, Program inLinguistics and CERIAS, Purdue University.Nirenburg, S. and V. Raskin.
2004.
OntologicalSemantics.
Cambridge, MA: MIT Press(forthcoming).Olsson, J.
2004.
Forensic Linguistics: AnIntroduction to Language, Crime and theLaw.
London-New York: Continuum.Palmer, G. 2002.
Forensic analysis in a digitalworld.
International Journal of DigitalEvidence, Spring 2002, 1.Raskin, V. 1987.
The semantics of lying.
In: R.Crespo, B. D. Smith, and H. Schultinik (eds.
),Aspects of  Language: Studies in Honour ofMario Alinei, Vol.
II.
Theoretical and AppliedSemantics.
Amsterdam: Rodopi, 443-469.Raskin, V. 2004.
Natural Language InformationAssurance and Security.
Tutorial, COLING2004, Geneva, Switzerland.
August 22.Raskin, V., M. J. Atallah, C. J. McDonough, andS.
Nirenburg.
2001a.
Natural LanguageProcessing for Information Assurance andSecurity: An Overview and Implementations.In: M. Schaefer (ed.
), Proceedings.
NewSecurity Paradigm Workshop.
September18th-22nd, 2000, Ballycotton,  County CorkIreland.
New York: ACM Press, 51-65.Raskin, V., M. J. Atallah, C. F. Hempelmann, andD.
Mohamed.
2001b.
Hybrid Data and TextSystem for Downgrading SensitiveDocuments.
CERIAS TR.Raskin, V., C. F. Hempelmann, K. E.Triezenberg, and S. Nirenburg.
2002a.Ontology in information security: A usefultheoretical foundation and methodologicaltool.
In: V. Raskin & C. F.
Hempelmann(eds.
), Proceedings.
New Security ParadigmsWorkshop 2001.
September 10th-13th,Cloudcroft, NM, USA, New York: ACMPress, 53-59.Raskin, V., S. Nirenburg, M. J. Atallah, C. F.Hempelmann, and K. E. Triezenberg.
2002b.Why NLP should move into IAS.
In: StevenKrauwer (ed.
), Proceedings of the Workshopon a Roadmap for Computational Linguistics,Taipei, Taiwan: Academia Sinica, 2002, 1-7.Raskin, V., S. Nirenburg, C. F. Hempelmann, I.Nirenburg, K. E. Triezenberg.
2003.
TheGenesis of a Script for Bankruptcy inOntological Semantics.
Proceedings of theHLT-NAACL 2003 Workshop on TextMeaning.
Available at:http://acl.ldc.upenn.edu/W/W03/W03-0905.pdfRogers, M. and K. Seigfried.
2004.
The future ofcomputer forensics: A needs analysis survey.Computers and Security, 23, 1, 12-16.Saferstein, R. 2004.
Criminalistics: Anintroduction to forensic science.
New York:Prentice Hall.Whitcomb, C. 2002.
A historical perspective ofdigital evidence: A forensic scientist?s view.International Journal of Digital Evidence,Spring 2002, 1Whitelaw, C., and Sh.
Argamon 2004.
Systemicfunctional features in stylistic textclassification.
Ms., Sydney LanguageTechnology Research Group, University ofSydney, Sydney, Australia.
