Using Roget?s Thesaurus for Fine-grained Emotion RecognitionSaima AmanSchool of Information Technologyand EngineeringUniversity of Ottawa, Ottawa, Canadasaman071@site.uottawa.caStan SzpakowiczSchool of Information Technologyand EngineeringUniversity of Ottawa, Ottawa, CanadaICS, Polish Academy of SciencesWarszawa, Polandszpak@site.uottawa.caAbstractRecognizing the emotive meaning of textcan add another dimension to the under-standing of text.
We study the task ofautomatically categorizing sentences in atext into Ekman?s six basic emotion cate-gories.
We experiment with corpus-basedfeatures as well as features derived fromtwo emotion lexicons.
One lexicon isautomatically built using the classificationsystem of Roget?s Thesaurus, while theother consists of words extracted fromWordNet-Affect.
Experiments on the dataobtained from blogs show that a combina-tion of corpus-based unigram features withemotion-related features provides superiorclassification performance.
We achieve F-measure values that outperform the rule-based baseline method for all emotionclasses.1 IntroductionRecognizing emotions conveyed by a text can pro-vide an insight into the author?s intent and senti-ment, and can lead to better understanding of thetext?s content.
Emotion recognition in text has re-cently attracted increased attention of the NLPcommunity (Alm et al, 2005; Liu et al 2003; Mi-halcea and Liu, 2006); it is also one of the tasks atSemeval-20071.Automatic recognition of emotions can be ap-plied in the development of affective interfaces for1 Affective Text: Semeval Task at the 4th International Work-shop on Semantic Evaluations, 2007, Prague(nlp.cs.swarthmore.edu/semeval/tasks/task14/summary.shtml).Computer-Mediated Communication and Human-Computer Interaction.
Other areas that can poten-tially benefit from automatic emotion analysis arepersonality modeling and profiling (Liu and Maes,2004), affective interfaces and communication sys-tems (Liu et al 2003; Neviarouskaya et al, 2007a)consumer feedback analysis, affective tutoring ine-learning systems (Zhang et al, 2006), and text-to-speech synthesis (Alm et al, 2005).In this study, we address the task of automati-cally assigning an emotion label to each sentencein the given dataset, indicating the predominantemotion type expressed in the sentence.
The possi-ble labels are happiness, sadness, anger, disgust,surprise, fear and no-emotion.
Those are Ekman?s(1992) six basic emotion categories, and an addi-tional label to account for the absence of a clearlydiscernible emotion.We experiment with two types of features forrepresenting text in emotion classification based onmachine learning (ML).
Features of the first typeare a corpus-based unigram representation of text.Features of the second type comprise words thatappear in emotion lexicons.
One such lexicon con-sists of words that we automatically extracted fromRoget?s Thesaurus (1852).
We chose words fortheir semantic similarity to a basic set of terms thatrepresent each emotion category.
Another lexiconbuilds on lists of words for each emotion category,extracted from WordNet-Affect (Strapparava andValitutti, 2004).We compare the classification results for groupsof features of these two types.
We get good resultswhen the features are combined in a series of MLexperiments.3122 Related WorkResearch in emotion recognition has focused ondiscerning emotions along the dimensions of va-lence (positive / negative) and arousal (calm / ex-cited), and on recognizing distinct emotion catego-ries.
We focus on the latter.Liu et al (2003) use a real-world commonsenseknowledge base to classify sentences into Ekman?s(1992) basic emotion categories.
They use an en-semble of rule-based affect models to determinethe emotional affinity of individual sentences.Neviarouskaya et al (2007b) also use rules to de-termine the emotions in sentences in blog posts;their analysis relies on a manually prepared data-base of words, abbreviations and emoticons la-beled with emotion categories.Since these papers do not report conventionalperformance metrics such as precision and recall,the effectiveness of their methods cannot be judgedempirically.
They also disregard statistical learningmethods as ineffective for emotion recognition atsentence level.
They surmise that the small size ofthe text input (a sentence) gives insufficient datafor statistical analysis, and that statistical methodscannot handle negation.
In this paper, we show thatML-based approach with the appropriate combina-tion of features can be applied to distinguishingemotions in text.Previous work has used lexical resources such asWordNet to automatically acquire emotion-relatedwords for emotion classification experiments.Starting from a set of primary emotion adjectives,Alm et al (2005) retrieve similar words fromWordNet utilizing all senses of all words in thesynsets that contain the adjectives.
They also ex-ploit the synonym and hyponym relations inWordNet to manually find words similar to nomi-nal emotion words.
Kamps and Marx (2002) useWordNet?s synset relations to determine the affec-tive meaning of words.
They assign multi-dimensional scores to individual words based onthe minimum path length between them and a pairof polar words (such as ?good?
and ?bad?)
inWordNet?s structure.There is also a corpus-driven method of deter-mining the emotional affinity of words: learn prob-abilistic affective scores of words from large cor-pora.
Mihalcea and Liu (2006) have used thismethod to assign a happiness factor to words de-pending on the frequency of their occurrences inhappy-labeled blogposts compared to their totalfrequency in the corpus.In this paper, we study a new approach to auto-matically acquiring a wide variety of words thatexpress emotions or emotion-related concepts, us-ing Roget?s Thesaurus (1852).3 Emotion-Labeled DataWe have based our study on data collected fromblogs.
We chose blogs as data source because theyare potentially rich in emotion content, and containgood examples of real-world instances of emotionsexpressed in text.
Additionally, text in blogs doesnot conform to the style of any particular genre perse, and thus offers a variety in writing styles,choice and combination of words, as well as topics.So, the methods learned for discerning emotionusing blog data are quite general and thereforeapplicable to a variety of genres rather than toblogs only.We retrieved blogs using seed words for allemotion categories.
Four human judges manuallyannotated the blog posts with emotion-relatedinformation - every sentence received twojudgments.
The annotators were required to markeach sentence with one of the eight labels:happiness, sadness, anger, disgust, surprise, fear,mixed-emotion, and no-emotion.
The mixed-emotion label was included to handle thosesentences that had more than one type of emotionor whose emotion content could not fit into any ofthe given emotion categories.
Sample sentencesfrom the annotated corpus are shown in Fig.
1.We measured the inter-annotator agreement us-ing Cohen?s (1960) kappa.
The average pair-wiseagreement for different emotion categories rangedfrom 0.6 to 0.79.
In the experiments reported inthis paper, we use only those sentences for whichthere was agreement between both judgments (toform a benchmark for the evaluation of the resultsof automatic classification).
The distribution ofemotion categories in the corpus used in our ex-periments is shown in Table 1.313Emotion Class Number of sentencesHappiness 536Sadness 173Anger 179Disgust 172Surprise 115Fear 115No-emotion 600Table 1.
Distribution of emotion classes4 A Baseline ApproachWe are interested in investigating if emotion in textcan be discerned on the basis of its lexical content.A na?ve approach to determining the emotionalorientation of text is to look for obvious emotionwords, such as ?happy?, ?afraid?
or ?astonished?.The presence of one or more words of a particularemotion category in a sentence provides a goodpremise for interpreting the overall emotion of thesentence.
This approach relies on a list of wordswith prior information about their emotion type,and uses it for sentence-level classification.
Theobvious advantage is that no training data are re-quired.For evaluation purposes, we took this approachto develop a baseline system that counts the num-ber of emotion words of each category in a sen-tence, and then assigns this sentence the categorywith the largest number of words.
Ties were re-solved by choosing the emotion label according toan arbitrarily predefined ordering of emotionclasses.
A sentence containing no emotion word ofany type was assigned the no emotion category.This system worked with word lists 2  extracted2  Emotion words from WordNet-Affect(http://www.cse.unt.edu/~rada/affectivetext/data/WordNetAffectEmotionLists.tar.gz)from WordNet-Affect (Strapparava and Valitutti,2004) for six basic emotion categories.Table 2 shows the precision, recall, and F-measure values for the baseline system.
As wehave seven classes in our experiments, the classimbalance makes accuracy values less relevantthan precision, recall and F-measure.
That is whywe do not report accuracy values in our results.The baseline system shows precision valuesabove 50% for all but two classes.
This shows theusefulness of this approach.
This method, however,fails in the absence of obvious emotion words inthe sentence, as indicated by low recall values.Thus, in order to improve recall, we need to in-crease the ambit of words that are considered emo-tion-related.
An alternative approach is to use MLto learn automatically rules that classify emotion intext.Class Precision Recall F-MeasureHappiness 0.589 0.390 0.469Sadness 0.527 0.283 0.368Anger 0.681 0.262 0.379Disgust 0.944 0.099 0.179Surprise 0.318 0.296 0.306Fear 0.824 0.365 0.506No-emotion 0.434 0.867 0.579Table 2.
Performance metrics of the base-line system5 Approach Based on Machine LearningWe study two types of features: corpus-based fea-tures and features based on emotion lexicons.5.1 Corpus-based featuresThe corpus-based features exploit the statisticalcharacteristics of the data on the basis of the n-gram distribution.
In our experiments, we take uni-grams (n=1) as features.
Unigram models havebeen previously shown to give good results in sen-timent classification tasks (Kennedy and Inkpen,2006; Pang et al, 2002): unigram representationscan capture a variety of lexical combinations anddistributions, including those of emotion words.This is particularly important in the case of blogs,whose language is often characterized by frequentuse of new words, acronyms (such as ?lol?
), ono-matopoeic words (?haha?, ?grrr?
), and slang, mostof which can be captured in a unigram representa-This was the best summer I haveever experienced.
(happiness)I don?t feel like I ever have thatkind of privacy where I can talkto God and cry and figure thingsout.
(sadness)Finally, I got fed up.
(disgust)I can?t believe she is finally here!
(surprise)Fig 1.
Sample sentences from the corpus314tion.
Another advantage of a unigram representa-tion is that it does not require any prior knowledgeabout the data under investigation or the classes tobe identified.For our experiments, we selected all unigramsthat occur more than three times in the corpus.
Thiseliminates rare words, as well as foreign-languagewords and spelling mistakes, which are quitecommon in blogs.
We also excluded words thatoccur in a list of stopwords - primarily functionwords that do not generally have emotional conno-tations.
We used the SMART list of stopword3,with minor modifications.
For instance, we re-moved from the stop list words such as ?what?
and?why?, which may be used in the context of ex-pressing surprise.5.2 Features derived from Roget?s ThesaurusWe utilized Roget?s Thesaurus (Jarmasz andSzpakowicz, 2001) to automatically build a lexicon3 SMART stopwords list.
Used with the SMART informationretrieval system at Cornell University(ftp://ftp.cs.cornell.edu/pub/smart/english.stop)of emotion-related words.
The features based on anemotion lexiconrequire prior knowledge aboutemotion relatedness of words.
We extracted thisknowledge from the classification system inRoget?s, which groups related concepts into vari-ous levels of a hierarchy.
For a detailed account ofthis classification structure, see Jarmasz andSzpakowicz (2001).Roget?s structure allows the calculation of se-mantic relatedness between words, based on thepath length between the nodes in the structure thatrepresent those words.
In case of multiple paths,the shortest path is considered.
Jarmasz and Szpak-owicz (2004) have introduced a similarity measurederived from path length, which assigns scoresranging from a maximum of 16 to most semanti-cally related words to a minimum of 0 to leastrelated words.
They have shown that on semanticsimilarity tests this measure outperforms severalother methods.To build a lexicon of emotion-related words utiliz-ing Roget?s structure, we need first to make twodecisions: select a primary set of emotion wordsstarting with which we can extract other similarSimilarityScoreHappiness Sadness Anger Disgust Surprise Fear16family, home,friends, life,house, loving,partying, bed,pleasure, rest,close, event,lucks, timescrying, lost,wounds, bad,pills, falling,messed, spot,unhappy,pass, black,events, hurts,shockedpride, fits,stormed,abandoned,bothered,mental, an-ger, feelings,distractionsshock, dis-gust, dislike,loathingplans, catch,expected,early, slid,slipped, ear-lier, caught,actnervous, cry,terror, panic,feelings, run,fog, fire, turn,police, faith,battle, war,sounds14love, like,feel, pretty,lovely, better,smiling, nice,beautiful,hope, cutestcelebrations,warm, desiresill, bored,feeling, ruin,blow, down,wrong, awful,evil, worry,crushing,bug, death,trouble, darkhate, burn,upset, dislike,wrong, blood,ill, flaws, bar,defects, bit-ter, growled,black, slowhate, pain,horrifying, ill,pills, sad,wear, blood,appalling,end, work,weighed,regrets, badleft, swing,noticed,worry, times,amazing,stolen, break,interesting,attentionfalling, life,stunned, pay,broken, hate,blast, times,hanging,hope, broken,blood, blue12gift, treats,adorable, fun,hug, kidding,bigger, great,lighting, won,stars, enjoy,favourite,social, divinedefeat, nasty,boring, ugly,loser, end,victim, sick,hard, serious,aggravating,bothering,burninglose, throw,offended, hit,power, feel,flaring, pills,broken, life,forgot, rant-ingfeel, fun, lies,drawn, lose,missed, de-prived, lack,sighs, defeat,down, hurt,tears, insultedrealize, pick,wake, sense,jumped, new,late, magic,omen, forget,popped, feel,question, late,throwfearful, spy,night, upset,feel, chased,hazardous,tomorrow,victim, grim,terrorists,apprehensiveTable 3.
Emotion-related words automatically extracted from Roget?s Thesaurus315words, and choose an appropriate similarity scoreto serve as cutoff for determining semantic relat-edness between words.The primary set of words that we selected con-sists of one word for each emotion category, repre-senting the base form of the name of the category:{happy, sad, anger, disgust, surprise, fear}.Experiments performed on Miller and Charlessimilarity data (1991), reported in Jarmasz andSzpakowicz (2004), have shown that pairs ofwords with a semantic similarity value of 16 havehigh similarity, while those with a score of 12 to14 have intermediate similarity.
Therefore, we se-lect the score of 12 as cutoff, and include in thelexicon all words that have similarity scores of 12or higher with respect to the words in the primaryset.
This selection of cutoff therefore serves as aform of feature selection.
In Table 3, we presentsample words from the lexicon with similarityscores of 16, 14, and 12 for each emotion category.These words represent three different levels of re-latedness to each emotion category.
We are able toidentify a large variety of emotion-related wordsbelonging to different parts of speech that go wellbeyond the stereotypical words associated withdifferent emotions.
We particularly note some ge-neric neutral words, such as ?feel?, ?life?, and?times?
associated with many emotion categories,indicating their conceptual relevance to emotions.5.3 Features derived from WordNet-AffectWordNet-Affect is an affective lexical resource thatassigns a variety of affect-related labels to a subsetModel Class Precision Recall F-Measure Baseline F-MeasureHappiness 0.840 0.675 0.740 0.469Sadness 0.619 0.301 0.405 0.368Anger 0.634 0.358 0.457 0.379Disgust 0.772 0.453 0.571 0.179Surprise 0.813 0.339 0.479 0.306Fear 0.889 0.487 0.629 0.506UnigramsNo-emotion 0.581 0.342 0.431 0.579Happiness 0.772 0.562 0.650 0.469Sadness 0.574 0.225 0.324 0.368Anger 0.638 0.246 0.355 0.379Disgust 0.729 0.297 0.421 0.179Surprise 0.778 0.243 0.371 0.306Fear 0.857 0.470 0.607 0.506Roget?s Thesaurus(RT) FeaturesNo-emotion 0.498 0.258 0.340 0.579Happiness 0.809 0.705 0.754 0.469Sadness 0.577 0.370 0.451 0.368Anger 0.636 0.419 0.505 0.379Disgust 0.686 0.471 0.559 0.179Surprise 0.717 0.374 0.491 0.306Fear 0.831 0.513 0.634 0.506Unigrams +RT FeaturesNo-emotion 0.586 0.512 0.546 0.579Happiness 0.813 0.698 0.751 0.469Sadness 0.605 0.416 0.493 0.368Anger 0.650 0.436 0.522 0.379Disgust 0.672 0.488 0.566 0.179Surprise 0.723 0.409 0.522 0.306Fear 0.868 0.513 0.645 0.506Unigrams +RT Features +WNA FeaturesNo-emotion 0.587 0.625 0.605 0.579* Highest precision, recall, and F-measure values for each class are shown in boldTable 4 ML Classification Results316of WordNet synsets comprising affective concepts.We used lists of words extracted from it for each ofthe six emotion categories.6 Experiments and ResultsWe train classifiers with unigram features for eachemotion class using Support Vector Machine(SVM) for predicting the emotion category of thesentences in our corpus.
SVM has been shown tobe useful for text classification tasks (Joachims,1998), and has previously given good performancein sentiment classification experiments (Kennedyand Inkpen, 2006; Mullen and Collier, 2004; Pangand Lee, 2004; Pang et al, 2002).
In Table 4, wereport results from ten-fold cross-validation ex-periments conducted using the SMO implementa-tion of SVM in Weka (Witten and Frank, 2005).
Ineach experiment, we represent a sentence by a vec-tor indicating the number of times each feature oc-curs.In the first experiment, we use only corpus-based unigram features.
We obtain high precisionvalues for all emotion classes (as shown in Table4), and the recall and F-measure values surpassbaseline values for all classes except no-emotion.This validates our premise that unigrams can helplearn lexical distributions well to accurately predictemotion categories.Next, we use as features all words in the emo-tion lexicon acquired from Roget?s Thesaurus(RT).
The F-measure scores beat the baseline forfour out of seven classes.
When we combine bothcorpus-based unigrams with RT features, we canincrease recall values across all seven classes.Finally, we add features from WordNet-Affectto the feature set containing corpus unigrams andRT features.
This leads to further improvement inoverall performance.
Combining all features, weachieve highest recall values across all but oneclass.
The resulting F-measure values (rangingfrom 0.493 to 0.751) surpass the baseline valuesacross all seven classes.
This increase was found tobe statistically significant (paired t-test, p=0.05).7 DiscussionWe observe that corpus-based features and emo-tion-related features together contribute to im-proved performance, better than given by any onetype of feature group alone.Any automatic way of recognizing emotionshould inevitably take into account a wide varietyof words that are semantically connected to emo-tions.
While some words are obviously affective,many more are only potentially affective.
The lat-ter derive their affective property from their asso-ciations with emotional concepts.
For instance,words like ?family?, ?friends?, ?home?
are not in-herently emotional, but because of their well-known semantic association with emotion con-cepts, their presence in a sentence can be taken asan indicator of emotion expression in the sentence.We can interpret the results as indicators of howmuch correlation the classifiers can find betweenthe features and the predicted class.
Consideringour best results using all features, we find that thiscorrelation is highest for the ?happy?
class, indi-cated by a precision of 0.813 and recall of 0.698,the highest among all classes.
We can thereforeconclude that it is easier to discern happiness intext than Ekman?s other basic emotions.8 ConclusionsWorking on a corpus of blog sentences anno-tated with emotion labels, we were able to demon-strate that a combination of corpus-based unigramfeatures and features derived from emotion lexi-cons can help automatically distinguish basic emo-tion categories in written text.
When used togetherin an SVM-based learning environment, these fea-tures increased recall in all cases and the resultingF-measure values significantly surpassed the base-line scores for all emotion categories.In addition, we described a method of buildingan emotion lexicon derived from Roget?s Thesau-rus on the basis of semantic relatedness of wordsto a set of basic emotion words for each emotioncategory.
The effectiveness of this emotion lexiconwas demonstrated in the emotion classificationtasks.ReferencesCecilia O. Alm, Dan Roth, and Richard Sproat, Emo-tions from text: machine learning for text-based emo-tion prediction.
In Proceedings of Joint Conferenceon HLT/EMNLP, pages 579-586, Vancouver, Can-ada, Oct 2005.M.M.
Bradley and P.J.
Lang, Affective norms for Eng-lish words (ANEW): Instruction manual and affective317ratings, Technical Report C-1, The Center for Re-search in Psychophysiology, University of Florida,1999.J.
Cohen, A coefficient of agreement for nominal scales,Educational and Psychological Measurement, 1960,20 (1): 37?46.Paul Ekman, An Argument for Basic Emotions, Cogni-tion and Emotion, 6, 1992, 169-200.Mario Jarmasz and Stan Szpakowicz, The Design andImplementation of an Electronic Lexical KnowledgeBase.
In Proceedings of the 14th Biennial Confer-ence of the Canadian Society for ComputationalStudies of Intelligence (AI 2001), Ottawa, Canada,June 2001, 325-333.Mario Jarmasz and Stan Szpakowicz, Roget's Thesaurusand Semantic Similarity.
N. Nicolov, K. Bontcheva,G.
Angelova, R. Mitkov (eds.)
Recent Advances inNatural Language Processing III: Selected Papersfrom RANLP 2003, John Benjamins, Amster-dam/Philadelphia, Current Issues in Linguistic The-ory, 260, 2004, 111-120.Thorsten Joachims, Text categorization with supportvector machines: Learning with many relevant fea-tures.
In Proceedings of the European Conference onMachine Learning (ECML-98), pages 137?142.Jaap Kamps, Maarten Marx, Robert J. Mokken, andMarten de Rijke, Words with attitude, In Proceedingsof the 1st International Conference on Global Word-Net, pages 332-341, Mysore, India, 2002.Alistair Kennedy and Diana Inkpen, Sentiment Classifi-cation of Movie Reviews Using Contextual ValenceShifters.
Computational Intelligence, 2006,22(2):110-125.Hugo Liu, Henry Lieberman, and Ted Selker, A modelof textual affect sensing using real-world knowledge.In Proceedings of the ACM Conference on IntelligentUser Interfaces, 2003, 125?132.Hugo Liu, and P. Maes, What Would They Think?
AComputational Model of Attitudes.
In Proceedings ofthe ACM International Conference on IntelligentUser Interfaces, IUI 2004, 38-45, ACM Press.Rada Mihalcea and Hugo Liu, A corpus-based approachto finding happiness, In Proceedings of the AAAISpring Symposium on Computational Approaches forAnalysis of Weblogs, Stanford, CA, USA, March2006.G.
Miller and W. Charles.
Contextual correlates of se-mantic similarity.
Language and Cognitive Proc-esses, 6(1):1-28, 1991.T Mullen and N Collier.
Sentiment analysis using sup-port vector machines with diverse informationsources.
In Dekang Lin and Dekai Wu, editors, Pro-ceedings of the 2004 Conference on Empirical Meth-ods in Natural Language Processing (EMNLP-2004),pages 412?418, Barcelona, Spain.Alena Neviarouskaya, Helmut Prendinger, and MitsuruIshizuka.
Analysis of affect expressed through theevolving language of online communication.
In Pro-ceedings of the 12th International Conference on In-telligent User Interfaces (IUI-07), pages 278-281,Honolulu, Hawaii, USA, 2007a.Alena Neviarouskaya, Helmut Prendinger, and MitsuruIshizuka, Narrowing the Social Gap among Peopleinvolved in Global Dialog: Automatic Emotion De-tection in Blog Posts, In Proceedings of the Interna-tional Conference on Weblogs and Social Media(ICWSM 2007), pages 293-294, Boulder, CO, USA,March 2007b.A.
Ortony, G.L.
Clore, and A. Collins, The cognitivestructure of emotions.
New York: Cambridge Uni-versity Press, 1988Bo Pang and Lillian Lee, 2004.
A Sentimental Educa-tion: Sentiment Analysis Using Subjectivity Summa-rization Based on Minimum Cuts.
In Proceedings ofthe 42nd Annual Meeting of the Association forComputational Linguistics (ACL?04), Barcelona,Spain, pages 271-278.Bo Pang, Lillian Lee, and S. Vaithyanathan, Thumbsup?
Sentiment classification using machine learningtechniques, In Proceedings of the 2002 Conferenceon Empirical Methods in Natural Language Process-ing, Philadelphia, PA, 2002, 79?86.Peter Mark Roget, Roget?s Thesaurus of English Wordsand Phrases.
Harlow, Essex, England: LongmanGroup Limited, 1852.Carlo Strapparava and A Valitutti, WordNet-Affect: anaffective extension of WordNet.
In Proceedings ofthe 4th International Conference on Language Re-sources and Evaluation (LREC-2004), Lisbon, 2004,1083-1086.Ian H. Witten and Eibe Frank.
Data Mining: PracticalMachine Learning Tools and Techniques (2nd ed.
),Morgan Kaufmann, San Francisco, 2005.(www.cs.waikato.ac.nz/ml/weka/)L.
Zhang, J. Barnden, R. Hendley, and A. Wallington,Exploitation in Affect Detection in Open-Ended Im-provisational Text.
In Proceedings of the ACL Work-shop on Sentiment and Subjectivity in Text, 2006,pages 47-54, Sydney, Australia.318
