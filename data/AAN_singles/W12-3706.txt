Proceedings of the 3rd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis, pages 29?37,Jeju, Republic of Korea, 12 July 2012. c?2012 Association for Computational LinguisticsOpinum: statistical sentiment analysis for opinion classificationBoyan Bonev, Gema Ram?
?rez-Sa?nchez, Sergio Ortiz RojasPrompsit Language EngineeringAvenida Universidad, s/n.
Edificio Quorum III.03202 Elche, Alicante (Spain){boyan,gramirez,sortiz}@prompsit.comAbstractThe classification of opinion texts in positiveand negative can be tackled by evaluating sep-arate key words but this is a very limited ap-proach.
We propose an approach based on theorder of the words without using any syntac-tic and semantic information.
It consists ofbuilding one probabilistic model for the posi-tive and another one for the negative opinions.Then the test opinions are compared to bothmodels and a decision and confidence mea-sure are calculated.
In order to reduce thecomplexity of the training corpus we first lem-matize the texts and we replace most named-entities with wildcards.
We present an accu-racy above 81% for Spanish opinions in thefinancial products domain.1 IntroductionMost of the texts written by humans reflect somekind of sentiment.
The interpretation of these sen-timents depend on the linguistic skills and emo-tional intelligence of both the author and the reader,but above all, this interpretation is subjective to thereader.
They don?t really exist in a string of charac-ters, for they are subjective states of mind.
Thereforesentiment analysis is a prediction of how most read-ers would react to a given text.There are texts which intend to be objective andtexts which are intentionally subjective.
The latter isthe case of opinion texts, in which the authors inten-tionally use an appropriate language to express theirpositive or negative sentiments about something.
Inthis paper we work on the classification of opinionsin two classes: those expressing positive sentiment(the author is in favour of something) and those ex-pressing negative sentiment, and we will refer tothem as positive opinions and negative opinions.Sentiment analysis is possible thanks to the opin-ions available online.
There are vast amounts of textin fora, user reviews, comments in blogs and socialnetworks.
It is valuable for marketing and sociolog-ical studies to analyse these freely available data onsome definite subject or entity.
Some of the textsavailable do include opinion information like stars,or recommend-or-not, but most of them do not.
Agood corpus for building sentiment analysis systemswould be a set of opinions separated by domains.
Itshould include some information about the culturalorigin of authors and their job, and each opinionshould be sentiment-evaluated not only by its ownauthor, but by many other readers as well.
It wouldalso be good to have a marking of the subjective andobjective parts of the text.
Unfortunately this kindof corpora are not available at the moment.In the present work we place our attention at thesupervised classification of opinions in positive andnegative.
Our system, which we call Opinum1, istrained from a corpus labeled with a value indicat-ing whether an opinion is positive or negative.
Thecorpus was crawled from the web and it consists of a160MB collection of Spanish opinions about finan-cial products.
Opinum?s approach is general enoughand it is not limited to this corpus nor to the financialdomain.There are state-of-the-art works on sentiment1An Opinum installation can be tested from a web interfaceat http://aplica.prompsit.com/en/opinum29analysis which care about differentiating betweenthe objective and the subjective part of a text.
Forinstance, in the review of a film there is an objec-tive part and then the opinion (Raaijmakers et al,2008).
In our case we work directly with opiniontexts and we do not make such difference.
We havenoticed that in customer reviews, even when statingobjective facts, some positive or negative sentimentis usually expressed.Many works in the literature of sentiment anal-ysis take lexicon-based approaches (Taboada et al,2011).
For instance (Hu and Liu, 2004; Blair-Goldensohn et al, 2008) use WordNet to extendthe relation of positive and negative words to otherrelated lexical units.
However the combination ofwhich words appear together may also be impor-tant and there are comparisons of different Ma-chine learning approaches (Pang et al, 2002) inthe literature, like Support Vector Machines, k-Nearest Neighbours, Naive-Bayes, and other classi-fiers based on global features.
In (McDonald et al,2007) structured models are used to infer the senti-ment from different levels of granularity.
They scorecliques of text based on a high-dimensional featurevector.In the Opinum approach we score each sentencebased on its n-gram probabilites.
For a completeopinion we sum the scores of all its sentences.
Thus,if an opinion has several positive sentences and it fi-nally concludes with a negative sentence which set-tles the whole opinion as negative, Opinum wouldprobably fail.
The n-gram sequences are good atcapturing phrasemes (multiwords), the motivationfor which is stated in Section 2.
Basically, thereare phrasemes which bear sentiment.
They maybe different depending on the domain and it is rec-ommendable to build the models with opinions be-longing to the target domain, for instance, financialproducts, computers, airlines, etc.
A study of do-main adaptation for sentiment analysis is presentedin (Blitzer et al, 2007).
In Opinum different clas-sifiers would be built for different domains.
Build-ing the models does not require the aid of experts,only a labeled set of opinions is necessary.
Anothercontribution of Opinum is that it applies some sim-plifications on the original text of the opinions forimproving the performance of the models.In the remainder of the paper we first state the mo-tivation of our approach in Section 2, then in Sec-tion 3 we describe in detail the Opinum approach.In Section 4 we present our experiments with Span-ish financial opinions and we state some conclusionsand future work in Section 5.2 HypothesisWhen humans read an opinion, even if they donot understand it completely because of the techni-cal details or domain-specific terminology, in mostcases they can notice whether it is positive or nega-tive.
The reason for this is that the author of the opin-ion, consciously or not, uses nuances and structureswhich show a positive or negative feeling.
Usually,when a user writes an opinion about a product, theintention is to communicate that subjective feeling,apart from describing the experience with the prod-uct and giving some technical details.The hypothesis underlying the traditionalkeyword or lexicon-based approaches (Blair-Goldensohn et al, 2008; Hu and Liu, 2004) consistin looking for some specific positive or negativewords.
For instance, ?great?
should be positive and?disgusting?
should be negative.
Of course thereare some exceptions like ?not great?, and someapproaches detect negation to invert the meaning ofthe word.
More elaborate cases are constructionslike ?an offer you can?t refuse?
or ?the best way tolose your money?.There are domains in which the authors of theopinions might not use these explicit keywords.
Inthe financial domain we can notice that many of theopinions which express the author?s insecurity areactually negative, even though the words are mostlyneutral.
For example, ?I am not sure if I would geta loan from this bank?
has a negative meaning.
An-other difficulty is that the same words could be posi-tive or negative depending on other words of the sen-tence: ?A loan with high interests?
is negative while?A savings account with high interests?
is positive.In general more complex products have more com-plex and subtle opinions.
The opinion about a cud-dly toy would contain many keywords and would bemuch more explicit than the opinion about the con-ditions of a loan.
Even so, the human readers canget the positive or negative feeling at a glance.The hypothesis of our approach is that it is pos-30sible to classify opinions in negative and positivebased on canonical (lemmatized) word sequences.Given a set of positive opinions Op and a set ofnegative opinions On, the probability distributionsof their n-gram word sequences are different andcan be compared to the n-grams of a new opin-ion in order to classify it.
In terms of statisticallanguage models, given the language models M pand M n obtained from Op and On, the probabilityppo = P (o|Op) that a new opinion would be gener-ated by the positive model is smaller or greater thanthe probability pno = P (o|ON ) that a new opinionwould be generated by the negative model.We build the models based on sequences ofcanonical words in order to simplify the text, as ex-plained in the following section.
We also replacesome named entities like names of banks, organiza-tions and people by wildcards so that the models donot depend on specific entities.3 The Opinum approachThe proposed approach is based on n-gram languagemodels.
Therefore building a consistent model is thekey for its success.
In the field of machine transla-tion a corpus with size of 500MB is usually enoughfor building a 5-gram language model, depending onthe morphological complexity of the language.In the field of sentiment analysis it is very diffi-cult to find a big corpus of context-specific opinions.Opinions labeled with stars or a positive/negative la-bel can be automatically downloaded from differ-ent customers?
opinion websites.
The sizes of thecorpora collected that way range between 1MB and20MB for both positive and negative opinions.Such a small amount of text would be suitable forbigrams and would capture the difference between?not good?
and ?really good?, but this is not enoughfor longer sequences like ?offer you can?t refuse?.In order to build consistent 5-gram language mod-els we need to simplify the language complexity byremoving all the morphology and replacing the sur-face forms by their canonical forms.
Therefore wemake no difference between ?offer you can?t refuse?and ?offers you couldn?t refuse?.We also replace named entities by wildcards: per-son entity, organization entity and company entity.Although these replacements also simplify the lan-guage models to some extent, their actual purposeis to avoid some negative constructions to be as-sociated to concrete entities.
For instance, we donot care that ?do not trust John Doe Bank?
is neg-ative, instead we prefer to know that ?do not trustcompany entity?
is negative regardless of the entity.This generality allows us to better evaluate opinionsabout new entities.
Also, in the cases when all theopinions about some entity E1 are good and all theopinions about some other entity E2 are bad, entityreplacement prevents the models from acquiring thiskind of bias.Following we detail the lemmatization process,the named entities detection and how we build andevaluate the positive and negative language models.3.1 LemmatizationWorking with the words in their canonical form isfor the sake of generality and simplification of thelanguage model.
Removing the morphological in-formation does not change the semantics of mostphrasemes (or multiwords).There are some lexical forms for which we keepthe surface form or we add some morphological in-formation to the token.
These exceptions are thesubject pronouns, the object pronouns and the pos-sessive forms.
The reason for this is that for somephrasemes the personal information is the key fordeciding the positive or negative sense.
For instance,let us suppose that some opinions contain the se-quencesot = ?They made money from me?,oi = ?I made money from them?.Their lemmatization, referred to as L0(?
), would be2L0(ot) = L0(oi) = ?SubjectPronoun make moneyfrom ObjectPronoun?,Therefore we would have equally probableP (ot|Mp) = P (oi|Mp) and P (ot|Mn) =P (oi|Mn), which does not express the actualsentiment of the phrasemes.
In order to capture this2The notation we use here is for the sake of readability andit slightly differs from the one we use in Opinum.31kind of differences we prefer to haveL1(ot) = ?SubjectPronoun 3p make moneyfrom ObjectPronoun 1p?,L1(oi) = ?SubjectPronoun 1p make moneyfrom ObjectPronoun 3p?.The probabilities still depend on how many times dothese lexical sequences appear in opinions labeled aspositive or negative, but with L1(?)
we would havethatP (ot|Mp) < P (oi|Mp),P (ot|Mn) > P (oi|Mn),that is, oi fits better the positive model than ot does,and vice versa for the negative model.In our implementation lemmatization is per-formed with Apertium, which is an open-sourcerule-based machine translation engine.
Thanks toits modularized architecture (described in (Tyers etal., 2010)) we use its morphological analyser andits part-of-speech disambiguation module in orderto take one lexical form as the most probable one,in case there are several possibilities for a given sur-face.
Apertium currently has morphological anal-ysers for 30 languages (most of them European),which allows us to adapt Opinum to other languageswithout much effort.3.2 Named entities replacementThe corpora with labeled opinions are usually lim-ited to a number of enterprises and organizations.For a generalization purpose we make the texts in-dependent of concrete entities.
We do make a differ-ence between names of places, people and organiza-tions/companies.
We also detect dates, phone num-bers, e-mails and URL/IP.
We substitute them all bydifferent wildcards.
All the rest of the numbers aresubstituted by a ?Num?
wildcard.
For instance, thefollowing subsequence would have aL2(oe) lemma-tization + named entity substitution:oe = ?Joe bought 300 sharesof Acme Corp. in 2012?L2(oe) = ?Person buy Num shareof Company in Date?The named entity recognition task is integratedwithin the lemmatization process.
We collected alist of names of people, places, companies and orga-nizations to complete the morphological dictionaryof Apertium.
The morphological analysis module isstill very fast, as the dictionary is first compiled andtransformed to the minimal deterministic finite au-tomaton.
For the dates, phone numbers, e-mails, IPand URL we use regular expressions which are alsosupported by the same Apertium module.Regarding the list of named entities, for a givenlanguage (Spanish in our experiments) we downloadits Wikipedia database which is a freely available re-source.
We heuristically search it for organizations,companies, places and people.
Based on the numberof references a given entity has in Wikipedia?s arti-cles, we keep the first 1.500.000 most relevant en-tities, which cover the entities with 4 references ormore (the popular entities are referenced from tensto thousands of times).Finally, unknown surface forms are replaced bythe ?Unknown?
lemma (the known lemmas are low-ercase).
These would usually correspond to strangenames of products, erroneous words and finally towords which are not covered by the monolingualdictionary of Apertium.
Therefore our approach issuitable for opinions written in a rather correct lan-guage.
If unknown surfaces were not replaced, thefrequently misspelled words would not be excluded,which is useful in some domains.
This is at the costof increasing the complexity of the model, as all mis-spelled words would be included.
Alternatively, thefrequently misspelled words could be added to thedictionary.3.3 Language modelsThe language models we build are based on n-gramword sequences.
They model the likelihood of awordwi given the sequence of n?1 previous words,P (wi|wi?
(n?1), .
.
.
, wi?1).
This kind of models as-sume independence between the word wi and thewords not belonging to the n-gram, wj , j < i ?
n.This is a drawback for unbounded dependenciesbut we are not interested in capturing the completegrammatical relationships.
We intend to capturethe probabilities of smaller constructions which mayhold positive/negative sentiment.
Another assump-tion we make is independence between different sen-32tences.In Opinum the words are lemmas (or wildcardsreplacing entities), and the number of words amongwhich we assume dependence is n = 5.
A max-imum n of 5 or 6 is common in machine transla-tion where huge amounts of text are used for build-ing a language model (Kohen et al, 2007).
In ourcase we have at our disposal a small amount of databut the language is drastically simplified by remov-ing the morphology and entities, as previously ex-plained.
We have experimentally found that n > 5does not improve the classification performance oflemmatized opinions and could incur over-fitting.In our setup we use the IRSTLM open-source li-brary for building the language model.
It performsan n-gram count for all n-grams from n = 1 ton = 5 in our case.
To deal with data sparsenessa redistribution of the zero-frequency probabilitiesis performed for those sets of words which have notbeen observed in the training set L(O).
Relative fre-quencies are discounted to assign positive probabil-ities to every possible n-gram.
Finally a smoothingmethod is applied.
Details about the process can befound in (Federico et al, 2007).
For Opinum we runIRSTLM twice during the training phase: once tak-ing as input the opinions labeled as positive and oncetaking the negatives:M p ?
Irstlm (L (Op))M n ?
Irstlm (L (On))These two models are further used for querying newopinions on them and deciding whether it is positiveor negative, as detailed in the next subsection.3.4 Evaluation and confidenceIn the Opinum system we query the M p ,M n mod-els with the KenLM (Heafield, 2011) open-sourcelibrary because it answers the queries very quicklyand has a short loading time, which is suitable fora web application.
It also has an efficient mem-ory management which is positive for simultaneousqueries to the server.The queries are performed at sentence level.
Eachsentence s ?
ot is assigned a score which is the logprobability of the sentence being generated by thelanguage model.
The decision is taken by compar-ing its scores for the positive and for the negativemodels.
For a given opinion ot, the log-probabilitysums can be taken:dot =?s?otlogP (s|M p)?
?s?otlogP (s|M n) ?
?0If this difference is close to zero, |dot |/wot < ?0,it can be considered that the classification is neutral.The number of words wot is used as a normalizationfactor.
If it is large, |dot |/wot > ?1, it can be con-sidered that the opinion has a very positive or verynegative sentiment.
Therefore Opinum classifies theopinions with qualifiers: very/somewhat/little posi-tive/negative depending on the magnitude |dot |/wotand sign(dot), respectively.The previous assessment is also accompanied by aconfidence measure given by the level of agreementamong the different sentences of an opinion.
If all itssentences have the same positivity/negativity, mea-sured by sign(dsj ), sj ?
o, with large magnitudesthen the confidence is the highest.
In the oppositecase in which there is the same number of positiveand negative sentences with similar magnitudes theconfidence is the lowest.
The intermediate cases arethose with sentences agreeing in sign but some ofthem with very low magnitude, and those with mostsentences of the same sign and some with differentsign.
We use Shannon?s entropy measure H(?)
toquantify the amount of disagreement.
For its esti-mation we divide the range of possible values of din B ranges, referred to as bins:Hot =B?b=1p(db) log1p(db).The number of bins should be low (less than 10),otherwise it is difficult to get a low entropy mea-sure because of the sparse values of db.
We set twothresholds ?0 and ?1 such that the confidence is saidto be high/normal/low if Hot < ?0, ?0 < Hot < ?1or Hot > ?1, respectivelyThe thresholds ?, ?
and the number of bins Bare experimentally set.
The reason for this is thatthey are used to tune subjective qualifiers (very/little,high/low confidence) and will usually depend on thetraining set and on the requirements of the applica-tion.
Note that the classification in positive or neg-ative sentiment is not affected by these parameters.33From a human point of view it is also a subjectiveassessment but in our setup it is looked at as a fea-ture implicitly given by the labeled opinions of thetraining set.4 Experiments and resultsIn our experimental setup we have a set of positiveand negative opinions in Spanish, collected from aweb site for user reviews and opinions.
The opin-ions are constrained to the financial field includingbanks, savings accounts, loans, mortgages, invest-ments, credit cards, and all other related topics.
Theauthors of the opinions are not professionals, theyare mainly customers.
There is no structure requiredfor their opinions, and they are free to tell their ex-perience, their opinion or their feeling about the en-tity or the product.
The users meant to communicatetheir review to other humans and they don?t bear inmind any natural language processing tools.
The au-thors decide whether their own opinion is positive ornegative and this field is mandatory.The users provide a number of stars as well: fromone to five, but we have not used this information.
Itis interesting to note that there are 66 opinions withonly one star which are marked as positive.
Thereare also 67 opinions with five stars which are markedas negative.
This is partially due to human errors,a human can notice when reading them.
Howeverwe have not filtered these noisy data, as removinghuman errors could be regarded as biasing the dataset with our own subjective criteria.Regarding the size of the corpus, it consists of9320 opinions about 180 different Spanish banksand financial products.
From these opinions 5877are positive and 3443 are negative.
There is a total of709741 words and the mean length of the opinionsis 282 words for the positive and 300 words for thenegative ones.
In the experiments we present in thiswork, we randomly divide the data set in 75% fortraining and 25% for testing.
We check that the dis-tribution of positive and negative remains the sameamong test and train.After the L2(?)
lemmatization and entity substitu-tion, the number of different words in the data set is13067 in contrast with the 78470 different words inthe original texts.
In other words, the lexical com-plexity is reduced by 83%.
Different substitutionsplay a different role in this simplification.
The ?Un-known?
wildcard represents a 7,13% of the origi-nal text.
Entities were detected and replaced 33858times (7807 locations, 5409 people, 19049 com-panies, 502 e-mails addresses and phone numbers,2055 URLs, 1136 dates) which is a 4,77% of thetext.
There are also 46780 number substitutions, a7% of the text.
The rest of complexity reduction isdue to the removal of the morphology as explainedin Subsection 3.1.In our experiments, the training of Opinum con-sisted of lemmatizing and susbstituting entities ofthe 6990 opinions belonging the training set andbuilding the language models.
The positive modelis built from 4403 positive opinions and the neg-ative model is built from 2587 negative opinions.Balancing the amount of positive and negative sam-ples does not improve the performance.
Instead, itobliges us to remove an important amount of pos-itive opinions and the classification results are de-creased by approximately 2%.
This is why we useall the opinions available in the training set.
Bothlanguage models are n-grams with n ?
[1, 5].
Hav-ing a 37% less samples for the negative opinionsis not a problem thank to the smoothing techniquesapplied by IRSTLM.
Nonetheless if the amount oftraining texts is too low we would recommend tak-ing a lower n. A simple way to set n is to takethe lowest value of n for which classification perfor-mance is improved.
An unnecessarily high n couldoverfit the models.The tests are performed with 2330 opinions (notinvolved in building the models).
For measuring theaccuracy we do not use the qualifiers informationbut only the decision about the positive or negativeclass.
In Figure 1 we show the scores of the opin-ions for the positive and negative models.
The scoreis the sum of scores of the sentences, thus it can beseen that longer opinions (bigger markers) have big-ger scores.
Independence of the size is not necessaryfor classifying in positive and negative.
In the diag-onal it can be seen that positive samples are closeto the negative ones, this is to be expected: bothpositive and negative language models are built forthe same language.
However the small differencein their scores yields an 81,98% success rate in theclassification.
An improvement of this rate would bedifficult to achieve taking into account that there is34Test Original Spanish text Meaning in English ResultSimilarwords,differentmeaning?Al tener la web, no pierdesel tiempo por tele?fono.
?As you have the website youdon?t waste time on the phone.Positive?En el telfono os hacen perderel tiempo y no tienen web.
?They waste your time on the phoneand they don?t have a website.Negative?De todas formas mesolucionaron el problema.
?Anyway, they solved my problem.
Positive?No hay forma de queme solucionen el problema.
?There is no way to make themsolve my problem.NegativeA negativeopinionof severalsentences?Con XXXXXX me fue muy bien.?
I was fine with XXXXXX.
Positive?Hasta que surgieron los problemas.?
Until the problems began.
Negative?Por hacerme cliente me regalaban100 euros.
?They gave me 100 euros forbecoming a client.Positive?Pero una vez que eres clienteno te aportan nada bueno.
?But once you are a client, theythey do not offer anything good.Negative?Estoy pensando cambiar de banco.
?I am considering switching toanother bank.NegativeThe completeopinion?Con XXXXXX me fue muy[.
.
.]
cambiar de banco.
?I was fine with XXXXXX[.
.
.]
switching to another bank.NegativeTable 1: Some tests on Opinum for financial opinions in Spanish.noise in the training set and that there are opinionswithout a clear positive or negative feeling.
A largercorpus would also contribute to a better result.
Eventhough we have placed many efforts in simplifyingthe text, this does not help in the cases in which aconstruction of words is never found in the corpus.A construction could even be present in the corpusbut in the wrong class.
For instance, in our corpus?no estoy satisfecho?
(meaning ?I am not satisfied?
)appears 3 times among the positive opinions and 0times among the negative ones.
This weakness ofthe corpus is due to sentences referring to a moneyback guarantee: ?si no esta satisfecho le devolvemosel dinero?
which are used in a positive context.Usually in long opinions a single sentence doesnot change the positiveness score.
For some exam-ples see Table 4.
In long opinions every sentence isprone to show the sentiment except for the cases ofirony or opinions with an objective part.
The per-formance of Opinum depending on the size of theopinions of the test set is shown in Figure 2.
In Fig-ure 3 the ROC curve of the classifier shows its sta-bility against changing the true-positive versus false-negative rates.
A comparison with other methodswould be a valuable source of evaluation.
It is notfeasible at this moment because of the lack of freecustomers opinions databases and opionion classi-fiers as well.
The success rate we obtain can be com-pared to the 69% baseline given by a classifier basedon the frequencies of single words.
?2500 ?2000 ?1500 ?1000 ?500 0?2500?2000?1500?1000?5000Similarity to positive LMSimilaritytonegativeLMSimilarity to the Language Models and text sizes (Test set)Figure 1: Relation between similarity to the models (xand y axis) and the relative size of the opinions (size ofthe points).The query time of Opinum on a standard com-puter ranges from 1, 63 s for the shortest opinions to1, 67 s for those with more than 1000 words.
In oursetup, most of the time is spent in loading the mor-phological dictionary, few milliseconds are spent inthe morphological analysis of the opinion and thenamed entity substitution, and less than a millisec-ond is spent in querying each model.
In a batch350 500 1000 1500020406080100120140160Opinion size (characters)eventsDistribution of test?text sizesSuccessesErrorsFigure 2: Number of successful and erroneous classifi-cations (vertical axis) depending on the size of the testopinions (horizontal axis).mode, the morphological analysis could be donefor all the opinions together and thousands of themcould be evaluated in seconds.
In Opinum?s web in-terface we only provide the single opinion queriesand we output the decision, the qualifiers informa-tion and the confidence measure.5 Conclusions and future workOpinum is a sentiment analysis system designed forclassifying customer opinions in positive and neg-ative.
Its approach based on morphological sim-plification, entity substitution and n-gram languagemodels, makes it easily adaptable to other classifica-tion targets different from positive/negative.
In thiswork we present experiments for Spanish in the fi-nancial domain but Opinum could easily be trainedfor a different language or domain.
To this end anApertium morphological analyser would be neces-sary (30 languages are currently available) as wellas a labeled data set of opinions.
Setting n for the n-gram models depends on the size of the corpus butit would usually range from 4 to 6, 5 in our case.There are other parameters which have to be exper-imentally tuned and they are not related to the pos-itive or negative classification but to the subjectivequalifier very/somewhat/little and to the confidencemeasure.The classification performance of Opinum inour financial-domain experiments is 81,98% whichwould be difficult to improve because of the noise in0 0.2 0.4 0.6 0.8 100.20.40.60.81ROC on test setFalse positive rateTrue positive rateFigure 3: Receiver Operating Characteristic (ROC) curveof the Opinum classifier for financial opinions.the data and the subjectivity of the labeling in posi-tive and negative.
The next steps would be to studythe possibility to classify in more than two classesby using several language models.
The use of anexternal neutral corpus should also be considered inthe future.It is necessary to perform a deeper analysis of theimpact of lexical simplification on the accuracy ofthe language models.
It is also very important toestablish the limitations of this approach for differ-ent domains.
Is it equally successful for a wider do-main?
For instance, trying to build the models froma mixed set of opinions of the financial domain andthe IT domain.
Would it work for a general domain?Regarding applications, Opinum could be trainedfor a given domain without expert knowledge.
Itsqueries are very fast which makes it feasible for freeon-line services.
An interesting application wouldbe to exploit the named entity recognition and as-sociate positive/negative scores to the entities basedon their surrounding text.
If several domains wereavailable, then the same entities would have differ-ent scores depending on the domain, which wouldbe a valuable analysis.ReferencesPhilipp Koehn, H. Hoang, A. Birch, C. Callison-Burch,M.
Federico, N. Bertoldi, B. Cowan, W. Shen, C.Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin andE.
Herbst.
2007.
Moses: open source toolkit for sta-36tistical machine translation.
Proceedings of the 45thAnnual Meeting of the ACL on Interactive Poster andDemonstration Sessions, pp.
177?180.
Prague, CzechRepublic, 2007.Sasha Blair-Goldensohn, Tyler Neylon, Kerry Hannan,George A. Reis, Ryan Mcdonald and Jeff Reynar.2008.
Building a sentiment summarizer for local ser-vice reviews.
In NLP in the Information ExplosionEra, NLPIX2008, Beiging, China, April 22nd, 2008.Hu, Minqing and Liu, Bing.
2004.
Mining and sum-marizing customer reviews.
Proceedings of the tenthACM SIGKDD international conference on Knowl-edge discovery and data mining, Seattle, WA, USA,2004.Ryan McDonald, Kerry Hannan, Tyler Neylon, MikeWells and Jeff Reynar.
2007.
Structured Models forFine-to-Coarse Sentiment Analysis.
Proceedings ofthe 45th Annual Meeting of the Association of Com-putational Linguistics, 2007.John Blitzer, Mark Dredze and Fernando Pereira.
2007.Biographies, bollywood, boomboxes and blenders:Domain adaptation for sentiment classification.
ACL,2007.Bo Pang, Lillian Lee and Shivakumar Vaithyanathan.2002.
Thumbs up?
Sentiment Classification usingMachine Learning Techniques.
EMNLP, 2002.Maite Taboada, Julian Brooke, Milan Tofiloski, KimberlyVoll, Manfred Stede.
2011.
Lexicon-based meth-ods for sentiment analysis.
Computational Linguis-tics, Vol.
37, Nr.
2, pp.
267?307, June 2011.Stephan Raaijmakers, Khiet P. Truong and Theresa Wil-son.
2008.
Multimodal Subjectivity Analysis of Mul-tiparty Conversation.
EMNLP, 2008.Tyers, F. M., Snchez-Martnez, F., Ortiz-Rojas, S. andForcada, M. L. 2010.
Free/open-source resourcesin the Apertium platform for machine translation re-search and development.
The Prague Bulletin ofMathematical Linguistics, No.
93, pp.
67?76, 2010.Marcello Federico and Mauro Cettolo.
2007.
EfficientHandling of N-gram Language Models for StatisticalMachine Translation.
ACL 2007 Workshop on SMT,Prague, Czech Republic, 2007.Kenneth Heafield.
2011.
KenLM: Faster and SmallerLanguage Model Queries.
ACL 6th Workshop on SMT,Edinburgh, Scotland, UK, July 30?31, 2011.37
