Learning Micro-Planning Rules for Preventative Expressions*Keith Vander Linden tInformation Technology Research InstituteUniversity of  BrightonBrighton BN2 4AT, UKemail: knvl@itri.brighton.ac.ukBarbara Di EugenioComputational LinguisticsCarnegie Mellon UniversityPittsburgh, PA, 15213 USAemail: dieugeni@andrew.cmu.eduAbstractBuilding text planning resources by hand is time-consuming and difficult.
Certainly, a numberof planning architectures and their accompanyingplan libraries have been implemented, but whilethe architectures themselves may be reused in anew domain, the library of plans typically cannot.One way to address this problem is to use ma-chine learning techniques to automate the deriva-tion of planning resources for new domains.
Inthis paper, we apply this technique to build micro-planning rules for preventative expressions in in-structional text.1 Int roduct ionBuilding text planning resources by hand is time-consuming and difficult.
Certainly, much workhas been done in this regard; there are a num-ber of freely available text planning architectures(e.g., Moore and Paris, 1993).
It is frequentlythe case, however, that while the architecture it-self can be reused in a new domain, the libraryof text plans developed for it cannot.
In particu-lar, micro-planning rules, those rules that specifythe low-level grammatical details of expression,are highly sensitive to variations between sub-languages, and are therefore difficult o reuse.When faced with a new domain in which togenerate text, the typical scenario is to perform a* This work is partially supported by the Engineering andPhysical Sciences Research Council (EPSRC) Grant J19221,by BC/DAA9 ARC Project 293, and by the Commission of theEuropean Union Grant LRE-62009.t After September 1,Dr.
Vander Linden's address will beDepartment of Mathematics and Computer Science, CalvinCollege, Grand Rapids, MI 49546, USA.corpus analysis on a representative collection ofthe text produced by human authors in that do-main and to induce a set of micro-planning rulesguiding the generation process in accordance withthe results.
Some fairly simple rules usually jumpout of the analysis quickly, mostly based on theanalyst's intuitions.
For example, in written in-structions, user actions are typically expressed asimperatives.
Such observations, however, tend tobe gross characterisations.
More accurate micro-planning requires painstaking analysis.
In thispaper, for example, the micro-planner must distin-guish between phrasing such as "Don't do action-,V' and "Take care not to do action-X".
Withoutanalysis, it is far from clear how this decision canbest be made.Some form of automation would clearly bedesirable.
Unfortunately, corpus analysis tech-niques are not yet capable of automating the ini-tial phases of the corpus study (nor will they befor the foreseeable future).
There are, however,techniques for rule induction which are useful forthe later stages of corpus analysis and for imple-mentation.In this paper, we focus on the use of such ruleinduction techniques in the context of the micro-planning of preventative expressions in instruc-tional text.
We define what we mean by a pre-ventative xpression, and go on to describe acor-pus analysis in which we derive three featuresthat predict he grammatical form of such expres-sions.
We then use the C4.5 learning algorithmto construct a micro-planning sub-network appro-priate for these expressions.
We conclude withan implemented example in which the technicalauthor is allowed to set the relevant features, andthe system generates the appropriate expressionsin English and in French.112 Preventative ExpressionsPreventative xpressions are used to warn thereader not to perform certain inappropriate or po-tentially dangerous actions.
The reader may betold, for example, "Do not enter" or "Take carenot to push too hard".
Both of these examplesinvolve negation ("do not" and "take care not").Although this is not strictly necessary for preven-tative expressions (e.g., one might say "stay out"rather than "do not enter"), we will focus on theuse of negative forms in this paper, using the fol-lowing categorisation: l?
negative imperatives proper (termed DONTimperatives) - -  These are characterised bythe negative auxiliary do not or don 7, as in:(1) Your sheet vinyl floor may be vinylasbestos, which is no longer on themarket.
Don ~ sand it or tear it upbecause this will put dangerousasbestos fibers into the air.?
NEVER imperatives - -These  are charac-terised by the use of the negative adverbnever, as in:(2) Whatever you do, never go to Viennaif  you are on a diet.?
other negative imperatives (termed neg-TCimperatives) - - These include take care andbe careful followed by a negative infinitivalcomplement, as in the following examples:(3) To book the strip, fold the bottom thirdor more of the strip over the middle ofthe panel, pasted sides together, takingcare not to crease the wallpapersharply at the fold.
(4) If your plans call for replacing thewood base molding with vinyl covemolding, be careful not to damage thewalls as you remove the wood base.3 Corpus AnalysisIn terms of text generation, our interest is in find-ing mappings from features related to the functionI Hom (1989) gives a more complete categofisation fnegative forms.of these xpressions, tothose related to their gram-maticalform.
Functional features include the se-mantic features of the message being expressed,the pragmatic features of the context of commu-nication, and the features of the surrounding textbeing generated.
In this section we will brieflydiscuss the nature of our corpus, and the fimctionand form features that we have coded.
We willconclude with a discussion of the inter-coder reli-ability.
A more detailed iscussion of this portionof the work is given elsewhere (Vander Lindenand Di Eugenio, 1996).3.1 CorpusThe corpus from which we take all our codedexamples has been collected opportunistically offthe intemet and from other sources.
It is 4.5 MBin size and is made entirely of written Englishinstructional texts.
As a collection, these textsare the result of a variety of authors working in avariety of contexts.We broke the corpus texts into expressions us-ing a simple sentence breaking algorithm and thencollected the negative imperatives by probing forexpressions that contain the grammatical formswe were interested in (i.e., expressions contain-ing phrases uch as don 7, never, and take care).The grammatical forms we found, 1283 occur-rences in all, constitute 2.7% of the expressions inthe filll corpus.
The first line in Table 1, marked"Raw Grep", indicates the quantity of each type.We then filtered the results.
When the probe re-turned more than 100 examples for a grammaticalform, we randomly selected around 100 of thosereturned, as shown in line 2 of Table 1 (labelled"Raw Sample").
We then removed those exam-ples that, although they contained the desired lex-ical string, did not constitute negative imperatives(e.g., "If you don ~ like the colors of the file .
.
.
.
,use Binder to change them.
"), as shown in line 3,labelled "Final Coding".The final corpus sample is made up of 279 ex-amples, all of which have been coded for the fea-tures to be discussed in the next two sections.Table 2 also shows the relative sizes of the var-ious types of instructions in the corpus as wellas the number of examples from this sample thatcame from each type.12Raw GrepRaw SampleFinal CodingDONT NEVER~n~ ~ not417 385100 9978 891671081084040take care212117Neg-TC; take sure229104be careful52524672be sure7171,6Table 1: Distribution of negative imperativesInstruction type Corpus size # of preventativesRecipesDo-it-yourselfDi Eugenio's thesis 2Software instructionsAdministrative formsOtherTotals1.7M1.26M336K264K317K565K4.5M8399690919279Table 2: Distribution of examples from sample3.2 FormBecause of its syntactic nature, the form featurecoding was very robust.
The possible feature val-ues were: DONT - -  for the do not and donforms discussed above; NEVER, for imperativescontaining never; and neg-TC - -  for take care,make sure, be careful, and be sure expressionswith negative arguments.
The two authors agreedon their coding of this feature in all cases.3.3 Function FeaturesWe will now briefly discuss three of the func-tion features we have coded: IINTENTIONALITY,AWARENESS, and SAFETY.
We illustrate them inturn using a to refer to the prevented action andusing "agent" to refer to the reader and executerof the instructions.Intentionality: This feature ncodes whether ornot the writer believes that the agent will con-sciously adopt he intention of performing a:CON is used to code situations where the agentintends to perform a.
In this case, the agent2Note that we used a number of examples from Di Eu-genio's thesis (1993) which were included as excerpts.
Inthis table we include only an estimate of the full size of thatportion of the corpus.must be aware that a is one of his or herpossible alternatives.UNC is used to code situations in which the agentdoesn't realize that there is a choice involved(cf.
Di Eugenio, 1993).
It is used in twosituations: when a is totally accidental, orthe agent may not take into account acrucialfeature of a.Awareness: This feature captures whether ornot the writer believes that the agent is aware thatthe consequences of ~ are bad:AW is used when the agent is aware that a isbad.
For example, the agent may be told"Be careful not to burn the garlic" when heor she is perfectly well aware that burningthings when cooking them is bad.UNAW is used when the agent is perceived to beunaware that a is bad.Safety: This feature captures whether or not theauthor believes that the agent's afety is put at riskby performing a:BADP is used when the agent's afety is put atrisk by performing a.NOT is used when it is not unsafe to perform c~,but may, rather, be simply inconvenient.133.4 Inter -coder  e l iab i l i tyEach author independently coded each of the fea-tures for all the examples in the sample.
Thepercentage agreement for each of the features isshown in the following table:feature percent agreementform 100%intentionality 74.9%awareness 93.5%safety 90.7%As advocated by Carletta (1996), we have usedthe Kappa coefficient (Siegel and Castellan, 1988)as a measure of coder agreement.
For nominaldata, this statistic not only measures agreement,but also factors out chance agreement.If P(A) is the proportion of times the codersagree, and P(E) is the proportion of times thatcoders are expected to agree by chance, K is com-puted as follows:P(A) - P(E)K=1 - P (E )There are various ways of computing P(E)according to Siegel and Castellan (1988); mostresearchers agree on the following formula, whichwe also adopted:mP ie )  =j=lwhere m is the number of categories, andpj is theproportion of objects assigned to category j.The mere fact that K may have a value k greaterthan zero is not sufficient o draw any conclusion,however, as it must be established whether k issignificantly different from zero.
There are sug-gestions in the literature that allow us to drawgeneral conclusions without these further com-putations.
For example, Rietveld and van Hout(1993) suggest he correlation between K valuesand inter-coder reliability shown in the followingtable:Kappa Value.00 - .20.21 - .40.41 - .60.61 - .80.81 - 1.00Reliability Levelslightfairmoderatesubstantialalmost perfectFor the form feature, the Kappa value is 1.0, indi-cating perfect agreement.
The function features,which are more subjective in nature, engendermore disagreement among coders, as shown bythe K values in the following table:feature KINTENTIONALITY 0.46AWARENESS 0.76SAFETY 0.71According to this table, therefore, the AWARE-NESS and SAFETY features show "substantial"agreement and the INTENTIONALITY feature shows"moderate" agreement.
We have coded otherfunctional features as well, but they have eithernot proven as reliable as these, or are not as usefulin text planning.In addition, Siegel and Castellan (1988) pointout that it is possible to check the significance of Kwhen the number of objects is large; this involvescomputing the distribution of K itself.
Under thisapproach, the three values above are significant atthe .000005 level.4 Automated LearningThe corpus analysis results in a set of examplescoded with the values of the function and formfeatures.
This data can be used to find correla-tions between the two types of features, correla-tions, which, in text generation, are typically im-plemented as decision trees or rule sets mappingfrom function features to forms.In this study, we used 179 coded examples asinput to the learning algorithm.
These are theexamples on which the two authors agreed on theircoding of all the features.
The distribution of thegrammatical forms in these examples is shown inthe following table:form frequencyDONT 100Neg-TC 57NEVER 22The learning algorithm used these examples toderive a decision tree which we then integratedinto an existing micro-planner.144.1 Data MiningWe have used Quinlan's C4.5 learning algorithm(1993) in this study; this algorithm can induce ei-ther decision trees or rules.
To provide a moreconvenient learning environment, we have usedClementine (1995), a tool which allows rapid re-configuration of various data manipulation facil-ities, including C4.5.
Figure I shows the basiccontrol stream we used for learning and testing de-cision trees.
Data is input from the split-outputfile node on the left of the figure and is passedthrough filtering modules until it reaches the out-put modules on the right.
The two select mod-ules (pointed to by the main input node) selectthe examples reserved for the training set and thetesting set respectively.
The upper stream pro-cesses the training set and contains a type mod-ule which marks the main syntactic form (i.e.,DONT, NEVER, or Neg-TC) as the variable tobe predicted and the AWARENESS, SAFETY, andINTENTIONALITY features as the inputs.
Its out-put is passed to the C4.5 node, labelled reform,which produces the decision tree.
We then usetwo copies of the resulting decision tree, repre-sented by the diamond shaped nodes marked withmform, to test the accuracy of the testing and thetraining sets.One run of the system, for example, gave thefollowing decision tree:awareness  = AW:  NEG-TCawareness  = UNAW:\] in tent ion  = CON:  DONT\] i n tent ion  = UNC:\] \[ sa fe ty  = BADP:  NEVER\] 1 sa fe ty  = NOT:  DONTThis tree takes the three function features and pre-dicts the DONT, NEVER, and Neg-TC forms.
Itconfirms our intuitions that never  imperatives areused when personal safety may be endangered(coded as safety="BADP"), and that Neg-TCforms are used when the reader is expected tobe aware of the danger that may arise (cf.
VanderLinden and Di Eugenio, 1996).
It accurately pre-dicts the grammatical form of 74.5% of the 161training examples, and 83.3% of the 18 testingexamples.Because there are relatively few training exam-ples in our coded corpus, we have also performeda 10-way cross-validation test.
3 None of the de-rived trees in this test were -emarkably differentfrom the one just shown, although they did or-der the INTENTIONALITY and AWARENESS featuresdifferently.
The average accuracy of the learneddecision trees on the testing sets was 75.4%.Note that although this level of accuracy isbet-ter than 55.9%, the score achieved by simply se-lecting DONT in all cases, there is still more workto be done.
The current features must be refined,and more features may be need to be added.
Weare currently experimenting with a number of pos-sibilities.
Note also that we have not distinguishedbetween the various ub-forms of DONT and Neg-TC shown in Table l; this will require yet morefeatures.Clementine can also "balance" the input toC4.5 by duplicating training examples with under-represented feature values.
We used this to in-crease the number of NEVER and Neg-TC exam-ples to match the number of DONT examples.
Ul-timately, this reduced the accuracy of the learnedtrees to 68.0% in a cross-validation test.
Theresulting decision trees tended not to include allthree features.4.2 IntegrationBecause it is common for us to rebuild decisiontrees frequently during analysis, we implementeda routine which automatically converts the deci-sion tree into the appropriate KPML-style sys-tem networks with their associated choosers, in-quiries, and inquiry implementations (Bateman,1995).
This makes the network compatible withthe DRAFTER micro-planner, a descendent of IM-AGENE (Vander Linden and Martin, 1995).
Theconversion routine takes the following inputs:?
the applicable language(s) - -C4.5 producesits decision trees based on examples from aparticular language, and KPML is capableof being conditionalised for particular lan-guages.
Thus, we may perform separate cor-pus analyses of a particular phenomenon forvarious languages, and learn separate micro-planning trees;3A cross-validation test is a test where C4.5 breaks thedata into different combinations of training and testing sets,builds and tests decision trees for each, and averages theresults (Clementine, 1995).150 split-output~@select  type#afore0 ,#  ,Iraselect afore analysis,manalysisFigure 1: The Clementine l arning environment.
the input feature(s) - -  The sub-network be-ing built must fit into the overall categorisa-tions of the full micro-planner, and thus wemust specify the text functions that wouldtrigger entry to the new sub-network;?
the decision tree itself;?
a feature-value function - -  To traverse thenew sub-network, the KPML inquiries re-quire a function that can determine the valueof the features for each pass through the net-work;?
grammatical form specifications- The sub-network must eventually build sentence planlanguage (SPL) commands for input toKPML, and thus must be told the appropri-ate SPL terms to use to specify the requiredgrammatical forms;?
an output file name.For our example, the system sub-network shownin Figure 2 is produced based on the decision treeshown above.
4 It is important to note here that al-though the micro-planner is implemented as a sys-temic resource, the machine learning algorithm isno respecter of systemic linguistic theory.
It sim-ply builds decision trees.
This gives rise to threedistinctly non-systemic features of these learnednetworks:~Only the systems are shown in the KPML dump givenin Figure 2.
The realisation statements, choosers, ii,quiries,and inquiry implementations are not shown.1.
The realisation statements are included onlyat the leaf nodes of the network.
We havebuilt no intelligent facility for decomposingthe realisation statements and filtering com-mon realisations up the tree.2.
The learning algorithm will freely reuse sys-tems (i.e., features) as various points in thetree.
This did not happen in Figure 2, butoccasionally one of the features is indepen-dently used in different sub-trees of the net-work.
We are forced, therefore, to index thesystem and feature names with integers todisambiguate.3.
There is no meta-functional distinction in thenetwork, but rather, all the features, regard-less of their semantic type, are included inthe same tree.The sub-network derived in this section wasspliced into the existing micro-planning net-work for the full generation system.
As men-tioned above, this integration was done by man-ually specifying the desired input conditions forthe sub-network when the micro-planning rulesare built.
For the preventative expression ub-network, this turned out to be a relatively simplematter.
DRAFTER'S model of procedural relationsincludes awarning relation which may be attachedby the author where appropriate.
The micro-planner, therefore, is able to identify those por-tions of the procedure which are to be expressedas warnings, and to enter the derived sub-network16~#,.
,~.
.
.~, ,~.r~_ o iii\[(A W A R E - 1 j |CON SCiOU SNE SS_SYSTE M_3iiij/CON SCIOU S-4  ,)|SAF ETY_SYSTEM_611i~N OT-BADP_7'll XUNAWARE -2 /~ Ul I \UNCONSCIOUS-5/~ tlIJ~ADP~8 \[Figure 2: The micro-planner system network derived from the decision treeappropriately.
This same process could be donewith any of the other procedural relations (e.g.,purpose, precondition).
This assumes, however,the existence of a core set of micro-plans whichperform the procedural categorisation properly;these were built by hand.
We have only just be-gun to experiment with the possibility of buildingthe entire network automatically from a more ex-haustive corpus analysis.5 A DRAFTER ExampleGiven the corpus analysis and the learned sys-tem networks discussed above, we will present anexample of how preventative expressions can bedelivered in DRAFTER, an implemented text gen-eration application.
DRAFTER is a instructionaltext authoring tool that allows technical authorsto specify a procedural structure, and then usesthat structure as input to a multilingual text gen-eration facility (Paris and Vander Linden, 1996).The instructions are generated in English and inFrench.To date, our domain of application has beenmanuals for software user interfaces, but becausethis domain does not commonly contain preventa-tive expressions ( ee Table 2), we have extendedDRAFTER's domain model to include coverage fordo-it-yourself applications.
Although this switchhas entailed some additions to the domain model,DRAFTER's input and generation facilities remainas they were.5.1 Input SpecificationIn DRAFTER, technical authors pecify the contentof instructions in a language independent mannerusing the DRAFTER specification tool.
This tool al-lows the authors to specify both the propositionalrepresentations of the actions to be included, andthe procedural relationships between those propo-sitions.
Figure 3 shows the DRAFTER interface af-ter this has been done.
We will use the procedureshown there as an example in this section, detailsoff how to build it can be found elsewhere (Parisand Vander Linden, 1996).The INTERFACE and ACTIONS panes on theleft of figure 3 list all the objects and actions de-fined so far.
These are all shown in terms of apseudo-text which gives an indication, albeit un-grammatical, of the nature of the action.
For ex-ample, the main goal, "repair device", representsthe action of the reader epairing an arbitrary de-vice.
This node may be expressed in any numberof different grammatical forms depending uponcontext.The WORKSPACE pane shows the procedure,represented in an outline format.
The main usergoal of repairing the device is represented by thelargest, enclosing box.
Within this box, there isa single method, called "Repair Method" whichdetails how the repair should be done.
There arethree sub-actions: consulting the manual, unplug-ging the device, and removing the cover.
There isalso a waming slot filled with the action "\[reader\]damage service cover".
This indicates that thereader should avoid damaging the service cover.
5Neither the propositional nor the procedural in-formation discussed so far specify the three fea-tures needed by the decision network derived inthe previous section (i.e., intentionality, aware-ness, and safety).
At this point, we see no straight-forward way in which they could be determinedautomatically (see Ansari's discussion of this is-sue (1995)).
We, therefore, rely on the author toset them manually.
DR.AFTER allows authors to setgeneration parameters on individual actions usinga dialog box mechanism.
Figure 4 shows a casein which the author has marked the following fourfeatures for the warning action "damage servicecover":5Actually, this could also be interpreted as an ensurativewarning, meaning that the reader should make sure to damagethe service cover (although this is clearly nonsensical in thiscase).
We have not yet analysed such expressions and thusdo not support hem in DRAFTER.17INTERFACETest Device Prooram"4 i.
*"ACTIONSRepair DeviceConsul t Repair ManuzWORKSPACEISub-steps .V_ con,,~,zffrepa~- manu# ~ unp/ug dev/ce .V_ remove serv/ce cover ~Unplug Device I i'" "Damage Service CoverStart Test Device ProgrzQuit Test Device PrograI..4 I .-Plan -a \[Repair MethodFOCUSRepair Meth'odPrecond~onSlde-egectCancellationWarning damage.,~rvlce coverSub-steps ~ consuff repair manual ~ Ol~ug device ~ removeFigure 3: DRAFTER screen with the procedural structure for the example?
The action is to be prevented, rather thanensured;?
Performing the action would result in incon-venience, but not in personal danger;?
The user is likely to do the action acciden-tally, rather than consciously;?
The user is likely to be aware that performingthe action would create problems;5.2 Text GenerationOnce the input procedure is specified, the authormay initiate text generation from any node in theprocedural hierarchy.
When the technical authorgenerates from the root goal node in Figure 3, forexample, the following texts are produced:English.
"To repair  the device1.
Consult the repair manual.2.
Unplug the device.3.
Remove the service cover.Take care not to damage the servicecover.French.
"R~paration du dispositif1.
Se reporter au manuel de r6paration.2.
D6brancher le dispositif.3.
Enlever le couvercle de service.Eviter d'endornmager le couvercle deservice.18What type o, warn,n u `  ' -  is this?
~ prevent the action .~ ensure the actionWhat are the consequences of ignonng it?Is the user likely to do it on purpose?Is the user likely to be aware of this problem?inconvenience ~ serious dangeron purpose ~ by accidentv unaware ~ aware 1Figure 4: The DRAFTER dialog box for setting the local parametersNote that the French version employs Oviter(avoid) rather than the less common prendre soinde ne pas (take care not).
This is possible be-cause the French text is produced by a separatemicro-planning sub-network.
This sub-networkwas not based on a corpus study of French pre-ventatives, but rather was implemented by takingthe leamed English decision tree, modifying it inaccordance with the intuitions of a French speaker,and automatically constructing French systemsfrom that modified decision tree.
Clearly, a cor-pus study French of preventatives is still needed,but this does show DRAFTER'S ability to make useof KPML's language conditionalised resources.Were we to replace the warning with other sortsof warnings, the expression would also change ac-cording to the learned micro-planning network.
Ifauthors, for example, wish to prevent he readerfrom performing the action of dismantling theframe of the device, and they decide that thereader is unaware of this danger, that the action isconsciously performed and not unsafe, DRAFTERproduces the following text:Do not dismantle the frame.Ne pas d6monter l'armature.If authors wish to prevent the reader from dis-connecting the ground connection, and they de-cide that the reader is unaware of this danger, thatthe action would be unconsciously performed, andthat the consequences are indeed life-threatening,DRAFTER produces the following text:Never disconnect the ground.Ne jamais deconnecter la borne de terre.6 ConclusionIn this paper we have discussed the use of ma-chine learning techniques for the automatic on-struction of micro-planning sub-networks.
Wedemonstrated this for the case of preventative ex-pressions in instructional text.We noted that because the automatic deriva-tion of useful, well-defined features for corpusanalysis is beyond the current state of the art,the painstaking process of corpus analysis muststill be performed manually.
As an example ofhow this can be done, we presented an analysis ofEnglish preventative expressions.
We intend tocontinue this part of the work by addressing morepreventative forms, addressing ensurative forms,and by extending the analysis to other languages.Although the analysis cannot be fully auto-mated, we noted that the derivation of decisionnetworks from coded corpus examples can.
Thisgreatly simplifies the tasks of building and testingtext planning resources for new domains.
We in-tend to continue this part of the work by applyingthe technique to larger portions of the planningresources.AcknowledgementsThe authors wish to acknowledge valuable discus-sions with Tony Hartley, Xiaorong Huang, AdamKilgarriff, Cecile Paris, Richard Power, and Do-nia Scott, as well as detailed comments from theanonymous reviewers.19ReferencesAnsari, D. (1995).
Deriving procedural nd warn-ing instructions from device and environ-ment models.
Master's thesis, Departmentof Computer Science, University of Toronto.Bateman, J.
A.
(1995).
KPML: The KOMET-Penman (Multilingual) Development Envi-ronment.
Technical report, Institut ftir In-tegrierte Publikations- und Informationssys-teme (IPSI), GMD, Darmstadt.
Release 0.8.Carletta, J.
(1996).
Assessing agreement on clas-sification tasks: the kappa statistic.
Compu-tational Lingustics, 22(2).
to appear.Clementine (1995).
Clementine User Guide, Ver-sion 2.0.
Integral Solutions Limited.Di Eugenio, B.
(1993).
A Study of Negation inInstructions.
In The Penn Review of Linguis-tics, Volume 17.Di Eugenio, B.
(1993).
Understanding Natu-ral Language Instructions: A ComputationalApproach to Purpose Clauses.
PhD thesis,University of Pennsylvania.
also availableas IRCS Report 93-52.Horn, L. R. (1989).
A Natural History of Nega-tion.
University of Chicago Press, Chicago.Moore, J. D. and Paris, C. L. (1993).
Planningtext for advisory dialogues: Capturing in-tentional and rhetorical information.
Com-putational Linguistics, 19(4):651-694.Paris, C. and Vander Linden, K. (1996).
Drafter:An interactive support ool for writing mul-tilingual instructions.
IEEE Computer.
toappear.Quinlan, J. R. (1993).
C4.5: Programs for Ma-chine Learning.
Morgan Kaufmann.Rietveld, T. and van Hout, R. (1993).
StatisticalTechniques for the Study of Language andLanguage Behaviour.
Mouton de Gruyter.Siegel, S. and Castellan, Jr., N. J.
(1988).
Non-parametric statistics for the behavioral sci-ences.
McGraw Hill.Vander Linden, K. and Di Eugenio, B.
(1996).
Anempirical study of negative imperatives innatural anguage instructions.
In Proceed-ings of the 16th International Cont'erenceon Computational Linguistics, August 5-9,Copenhagen, Denmark.
To appear.Vander Linden, K. and Martin, J. H. (1995).
Ex-pressing local rhetorical relations in instruc-tional text: A case-study ofthe purpose rela-tion.
Computational Linguistics, 21(I):29-57.20
