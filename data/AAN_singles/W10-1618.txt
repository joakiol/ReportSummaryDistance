Proceedings of the NAACL HLT 2010 Young Investigators Workshop on Computational Approaches to Languages of the Americas,pages 132?140, Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsDialogue Systems for Virtual EnvironmentsLuciana Benotti, Paula Estrella, Carlos ArecesGrupo de Procesamiento de Lenguaje Natural (PLN)Seccio?n de Ciencias de la Computacio?nFacultad de Matema?tica, Astronom?
?a y F?
?sica (FaMAF)Universidad Nacional de Co?rdoba, ArgentinaAbstractWe present an on-going research project car-ried out at the Universidad Nacional de Co?rdo-ba in Argentina.
This project investigates the-oretical and practical research questions re-lated to the development of a dialogue systemsituated in a virtual environment.
We describethe PLN research group in which this projectis being developed and, in particular, we spellout the areas of expertise of the authors.
More-over, we discuss relevant past, current and fu-ture collaborations of the research group.1 IntroductionThe goal of this project is to implement a dialoguesystem which automatically generates instructionsin order to help a user to fulfill a given task in a 3Dvirtual environment.
In this context, we will investi-gate fundamental issues about human-computer in-teraction.
The expected results of the project can beclassified in three areas: pragmatics of interaction;information representation and inference; and eval-uation of dialogue systems.
Once a working proto-type is finished, we will adapt it to the specific taskof language learning, using the system as a virtuallanguage teacher.
Our prototype will teach Englishto native Spanish speakers.
Hence, it will need tounderstand and produce both languages.Initially, we will investigate a model of unidirec-tional linguistic interaction (i.e., linguistic informa-tion flows only from the system to the user).
In sub-sequent stages, the model will be extended to allowbidirectional language exchange.
For example, theuser may ask clarifications to the system or redefinethe goal of the interaction.The architecture of the envisioned dialogue sys-tem presents both theoretical and practical chal-lenges.
On the theoretical side, heuristics are neededin order to govern decisions such as what to say,when, and how (given the current context).
In addi-tion, the system should implement inference meth-ods in order to figure out how to modify the cur-rent situation and reach the task goal.
The complex-ity of the theoretical issues is reflected, in practice,in a system of multiple components: a natural lan-guage generator, a planner, a 3D interactive envi-ronment, to mention a few.
Designing and imple-menting all these components from scratch wouldrequire a prohibitive effort.
Instead we will adapttools already implemented and freely available forprototyping this kind of systems, such as the plat-form GIVE1, Generating Instructions in Virtual En-vironments (Byron et al, 2009).The quality of each of the components of the sys-tem affects the perception users have of it.
It is im-perative to carry out extensive evaluation.
We planto adapt and apply different evaluation techniquesand metrics from the area of Machine Translation toassess the performance of the system.The plan of the paper is as follows.
Section 2describes the project in detail.
Section 3 spells outthe expected results as well as their foreseen impactin the Argentinean socio-economic landscape.
Sec-tion 4 presents the PLN research group including itslines of research.
Section 5 discuss past, current andfuture collaborations that are relevant to the project.1http://www.give-challenge.org1322 Description of the ProjectThis section first introduces the virtual environ-ment in which our dialogue system will be situated,namely the GIVE platform, which is the basic ar-chitecture of our dialogue system.
Then we explainin detail the tasks that our situated dialogue systemwill implement, and we spell out the evaluation chal-lenges that such a system poses.
We close the sec-tion discussing the application of our dialogue sys-tem for the task of second language learning.2.1 The Virtual EnvironmentIn the scenario proposed by GIVE (Byron et al,2009), a human user carries out a ?treasure hunt?
ina 3D virtual environment and the task of the genera-tion system is to provide real-time, natural languageinstructions that help the user find the hidden trea-sure.In the GIVE setup, the instruction giving systemmust guide the user through interconnected rooms.The final goal is to get a trophy which is hidden ina safe.
In order to achieve this goal, the system in-structs the user to perform several subtasks such asdeactivating alarms and opening the safe combina-tion by pressing a sequence of buttons on the wallsof the rooms.Figure 1: The user?s view of the 3D worldFigure 1 shows a screen-shot of the user?s view onthe 3D world.
On the top of the picture, the currentinstruction generated by the dialogue system is dis-played.
The picture shows a closed door and an opendoor that has an activated alarm (that looks like a redtile) in the doorway.
There are five visible buttons inthis room (two yellow, two red and one green) andthe instruction giver is instructing the user to pressa red button.
Pressing a button can have differenteffects such as opening a door, moving an object,deactivating an alarm, etc.The characteristics of the world, including thefunctions of the buttons, are described in the worldspecification by the world designers.
The user canmove freely around the world (using the directionkeys as indicated in the bottom of the screen) butshe can loose the game if she triggers an alarm.
Theuser can also ask for help pressing ?H?
if she did notmanage to read or understand the last instruction.For the correct definition of the interaction poli-cies of our prototype we need a corpus that pro-vides examples of typical interactions in the domain.GIVE provides tools for collecting such a corpus inthe form of a Wizard of Oz platform that records alldetails of the interaction, thus allowing to easily ob-tain a corpus of interaction in virtual environmentsannotated automatically.2.2 The Dialogue System TasksFrom the collected corpus we will begin the design,implementation and testing of our dialogue system.The main components that we will have to designand implement can be organized using the tradi-tional four tasks that a dialogue system should ad-dress: (1) content planning, (2) generation of refer-ring expressions, (3) management of the interactioncontext, and (4) interpretation of user responses.
(1) Content Planning: Given the envisioned setupwe described before, the first task of the system is toobtain a plan to reach the desired goal, from the cur-rent state.
The plan will contain physical actions tobe performed in the virtual environment.
The secondstep is to decide how to transmit this sequence of ac-tions to the user.
E.g, to decide how many actionsto communicate per instruction, and how to aggre-gate them coherently.
The result of the action ag-gregation process can be represented as a tree de-scribing the task structure at different levels of ab-straction.
The third and final step is to decide howto navigate the tree of actions to verbalize the in-structions (for example, post or preorder as exploredin (Foster et al, 2009)).
We will investigate different133aggregation policies (e.g., aggregating actions thatmanipulate similar objects) and innovative ways inwhich to navigate the task tree (e.g., moving to alower level of abstraction in case of misunderstand-ings).
Plan computation can be solved using clas-sical planners (Kautz and Selman, 1999; Hoffmannand Nebel, 2001; Nau et al, 2004).
However, whilethere are planners that work well when optimized forcertain applications, none provides services such asthe generation of alternative plans, or the generationof incomplete plans in case of the absence of plan.One of the goals of the project is to design and im-plement these extensions to classical planning algo-rithms.
We will also study the theoretical behavior(e.g., complexity) of these new algorithms.
(2) Generation of Referring Expressions: Oncecontent planning is complete, the next step is to gen-eration adequate referring expressions.
This taskinvolves producing a phrase that describes a refer-able entity so that the user can identify it (e.g., ?thevase on the table?).
To be acceptable, these expres-sions should be ?natural:?
they should be at the sametime sufficiently but not overly constrained, and theyshould not impose on the user a heavier cognitiveload than necessary.
For example, producing theexpression ?the vase that is not above the chair orsofa or under the table?
would probably not be ac-ceptable.
Areces et al (2008b) propose to use sym-bolic minimization of the model that represents thestate of the world, in order to obtain a logical repre-sentation that describe each object uniquely.
In ourproject we will implement this method and evaluateit within the dialogue system.
(3) Management of the Interaction Context: Tomanage the use of the interaction context we will useexisting knowledge maintenance systems such asRACER2 or Pellet3, which support inference taskssuch as definition, maintenance and querying of on-tologies.
These systems have been used as infer-ence engines in numerous applications in the areaand, in particular, in dialogue systems for text ad-ventures (Benotti, 2009b).
Once we have studiedthe behavior of these inference engines on the task,we will analyze its limitations and investigate the re-quired extensions.2http://www.racer-systems.com3http://clarkparsia.com/pellet(4) Interpretation of User Responses: The inter-pretation of user responses in the unidirectional sys-tem is relatively simple: it amounts to discretizingthe continuous flow of user behavior in the 3D worldinto actions meaningful for the domain task.
In afirst stage, we will use the discretizer provided byGIVE.
After evaluating it we can determine whetheror not this module meets the requirements of ourtask and what are its limitations.
In the bidirectionalsystem, however, the interpretation of user responsesis the task that will require more attention.
To startwith, the bidirectional system should be expandedwith capabilities for processing statements comingfrom the user (namely, parsing, semantic construc-tion, resolution of references, etc.).
We will study,in particular, two types of user contributions: re-quests for clarification of the instruction given (whatwe call ?short-term repairs?
), and for redefinition ofgoals (what we call ?long-term repairs?).
We willimplement short-term repairs using the approach de-scribed in (Purver, 2006).
For long-term repairs wewill use the guidelines of (Blaylock, 2005).A sample interaction with the unidirectional sys-tem guiding the player in the identification of a par-ticular blue button is as follows:(1) System says: Push a blue button.The user focuses a blue button.System says: Not this one.Look for another one.The user turns and focuses another blue button.System says: Yes this one!The user pushes the button.This interaction illustrates the tasks describedabove.
To begin with, the verbalization of the in-struction ?Push a blue button?
is making explicit oneof the steps of the plan that needs to be performed inorder to achieve the task goal.
As we can see, thesystem implements in this case a referring strategywhich does not uniquely identify the referent (thesystem generates ?a blue button?
when there is morethan one blue button in the domain).
But it is ca-pable of producing further details about the referentif the user focus in the wrong object.
Finally, thisexample makes evident that the interpretation of theuser responses is crucial even in a linguistically uni-directional system.
The user cannot make linguistic134contributions but can change the context by perform-ing physical acts, the correct interpretation of suchacts is essential if the system is to react coherently.2.3 EvaluationTo determine the quality of the obtained prototypeswe propose to create a quality model following theISO/IEC 9126 and 14528 standards for the evalua-tion of software products (ISO/IEC, 2001; ISO/IEC,1999).
These standards were successfully appliedto the Machine Translation domain, resulting in theFEMTI4, Framework for the Evaluation of MachineTranslation (Estrella et al, 2005).
FEMTI guidesevaluators towards creating parameterized evalua-tion plans that include various aspects of the to-be-evaluated system and offer a relevant set of met-rics.
The identification of relevant metrics can beperformed using various methods, e.g., based onprevious experience (Hajdinjak and Mihelic, 2006;Litman and Pan, 2002), conducting surveys or re-quirement specifications (Lecoeuche et al, 1998), orcollecting such data through Wizard of Oz experi-ments (Dahlba?ck et al, 1998).
After developing aquality model, several methodologies to assess vari-ous aspects of the system can be applied: automaticmetrics, subjective metrics or metrics based on thetask (to evaluate both the contribution of each com-ponent and the quality of the whole system).The GIVE platform is used every year as a uni-fied framework for evaluating generation systems.Systems have to generate natural language instruc-tions and be able to participate in a real-time interac-tion situated in a 3D environment.
The GIVE Chal-lenge is one of the shared tasks endorsed by ACL?sspecial interests groups in generation, dialogue andsemantics.
We plan to participate in the challenge,which will serve as an additional source of informa-tion about aspects of the system that need improve-ment.
The evaluation metrics used in the Challenge(such as average reference identification time) aredescribed in (Byron et al, 2009).
In (Amoia et al,2010) we extended such metrics in order to measurealingment between system and user.
Once the pro-totype is evaluated and improved using the results ofthe challenge, we will investigate its use as a virtuallanguage tutor as described in the next section.4http://www.issco.unige.ch/femti/2.4 An Application: A Virtual TutorThe project outcome will be a system capable of giv-ing natural language instructions situated in a virtual3D environment.
The technology and theoretical ad-vances of the project could be used in various appli-cations, but one of the most interesting character-istics we plan to investigate is that, a priori, by justchanging the linguistic resources, the language of in-teraction with the system (input and output) can bechanged as desired.
After obtaining a first prototypeof an instruction giving dialogue system, we will in-vestigate its use for distance learning, adapting thesystem to operate as a foreign language tutor (Wikand Hjalmarsson, 2009).A one-way system that generates instructions inEnglish can be used to test the user understandingof a foreign language.
The correct interpretation ofthe instructions can be evaluated from the proper ex-ecution of the instructions.
The two-way systemwill allow the user to formulate clarifications (ei-ther in their native language or in the foreign lan-guage).
The user may also redefine the objective tobe achieved during the interaction, and thus selectthe type of vocabulary he wants to practice.Virtual worlds (like Second Life) are beingrapidly incorporated into education, both initialand superior (Doswell, 2005; Molka-Danielsen andDeutschmann, 2009).
The use of a virtual tutorhas certain advantages over a human tutor.
Eng-wall (2004) mentioned the following.
(1) Amountof practice: the chance to practice the new languageis essential for learning, and a virtual tutor providesopportunities only limited by the technological re-sources.
(2) Prestige: a student may feel embar-rassed about making mistakes with a human tutor,and this might limit his willingness to speak in theforeign language.
(3) Augmented Reality: a virtualtutor can provide additional material (e.g., examplesin context, explanatory images, etc.)
with less effortthan a human tutor.Such a virtual tutor can be used in distance learn-ing.
To develop distance learning systems, it is es-sential to model the user?s learning progress.
Thisrequires a system aware of the evolution of the user,and that takes into account their achievements andtheir problems.
The system must be able to interpretrequirements, and generate appropriate responses,135for non-experts uses whose knowledge evolves dur-ing the interaction.
Moreover, the system must beable to properly represent both the information con-cerning the course material, and information aboutthe evolution of the user.
For example, the systemmust be able to diagnose what part of the course ma-terial should be reviewed from the wrong answers ofthe user.
Finally, the system must be able to evaluatethe user interaction in order to decide which learningobjectives have been achieved.
The theoretical andpractical results of the project contribute to solvingthese difficult problems.3 Impact of the ProjectThis project aims to achieve a balance between asystem which is sufficiently generic to be applica-ble in different areas, and specific enough to ben-efit from the efficient use of existing techniquesfor knowledge management, planning and naturallanguage processing.
Designing and implementingsuch a system is a multidisciplinary effort leading toresearch in diverse scientific areas:Pragmatics is an interdisciplinary field which inte-grates insights from linguistics (e.g., conversationalimplicatures (Grice, 1975)), sociology (e.g., conver-sational analysis (Schegloff, 1987)) and philosophy(e.g., theory of speech acts (Austin, 1962)).
It aimsto explore how the context (in which a conversationis situated) contributes to the meaning (of everythingthat is said during that conversation).
The meaningconveyed during a conversation depends not only onlinguistic information (entities in focus, grammati-cal and morphological rules, etc.)
but also on extra-linguistic information (physical situation of conver-sation, previous experiences of speakers, etc.).
As aresult, the same sentence may mean different thingsin different contexts.
The area of pragmatics studiesthe process by which a sentence is disambiguatedusing its context.
A dialogue system needs to havepragmatic capabilities in order to interact in a nat-ural way with its users.
In particular, it must definewhat kind of contextual information should be repre-sented; and what inference tasks on a sentence andcontext are necessary in order to interpret an utter-ance.
In such a system it is important that sentencesmakes explicit the right amount of information: toomuch information will delay and bore the user, but ifthe information is not enough the user will not knowhow to perform the task and make mistakes.One of the major contributions of the project inthis area will be a virtual laboratory for pragmatictheories: a controlled environment for studying in-teraction set in a world where physical actions andlanguage intermingle.
The prototype will let us in-vestigate the impact that different instruction givingpolicies (e.g., post order on the tree structure of thetask) have on successful achievement of the goal.Similar studies have been done before (e.g., (Fos-ter et al, 2009)) but they usually assume a prede-termined task.
Since our prototype allows for thespecification of the virtual world, the available ac-tions, and the goal, we will be able to determinewhen the impact associated to a particular policy isdependent on the task or not.
We will also investi-gate short and long term repairs.
Repairs are usu-ally caused by conversational implicatures (Benotti,2009a).
Modeling these implicatures in a generic di-alogue system is difficult because they are too openended.
However, since the present prototype pro-vides a situated interaction, restricted to the virtualworld, it will be possible to test the relationship be-tween implicatures, the type of repairs they give riseto, and the inference tasks needed to predict them.Inference can be understood as any operation thattransforms implicit information in explicit informa-tion.
This definition is general enough to cover tasksranging from logical inference (i.e., deduction ina formal language) to inference tasks common inAI (e.g., planning and non-monotonic inference), aswell as statistical operations (e.g.
obtaining estima-tors on a data set).
A dialogue system has to contin-ually perform inference operations.
E.g., inferenceis needed to interpret information received from theuser, incorporate it to the system?s data repository,and then decide what should be conveyed back tothe user.
The very problem of deciding what kindof logical representation and what type of inferenceto use in a given situation is complex (propositionallogic vs. first-order logic, validity vs. model check-ing, logical inference vs. statistical inference).
Inde-pendently of which type of inference is used, theyare usually computationally expensive.
The chal-lenge here is to find the appropriate balance betweenthe expressivity of the representation formalism and136the cost of the required inference methods.The main contribution of the project in this areais in the design, development and study of planningalgorithms.
A typical planning system takes threeinputs ?initial state, possible actions and expectedgoal?
and returns a sequence of actions (a plan) thatwhen sequentially applied to the initial state, endsin a state that satisfies the goal.
Different methodsto obtain a plan have been studied (forward chain-ing, backward chaining, coding in terms of proposi-tional satisfiability, etc.
), and they are currently im-plemented in systems that can solve many planningtasks efficiently.
However, most of these systemsmake assumptions that simplify the problem (deter-ministic atomic time, complete information, absenceof a background theory, etc.).
And most of them re-turn a single plan.
We will investigate algorithmsthat eliminate some of these simplifications (in par-ticular, we will study planning with incomplete in-formation and based on a background theory).
Wewill also provide extended planning services: alter-native plans, minimal plans, conditional plans, in-complete plans, affordability of a given state, etc.Evaluation of natural language generation systemsis one of the most difficult tasks in the area of NLP.A given concept can be expressed in many differentways, all of them correct.
Hence, it is not possibleto determining the quality of a generated sentencesimply by, for example, comparing the result with agold standard.
The problem of absence of gold stan-dards is shared with another area of the NLP, namelyMachine Translation, for which various evaluationmethodologies, both direct and indirect, have beenproposed.
Direct methods applies a metric to thetext generated by the system, while indirect meth-ods evaluates the performance of the system throughthe use of the generated text to perform some task.But none of these methods is a standard and gener-ally accepted methodology, which has been provento be effective in all cases.
Since what is being eval-uated in this project is a system that interacts via thegeneration of natural language instructions, we candetermine its performance through quantitative met-rics (e.g., average task completion time), qualitativemetrics (e.g., general user satisfaction) and metricsbased on the context (e.g., how well the system ad-dressed the user needs in particular situations).
Wewill study the portability of evaluation techniquesfrom the domain of machine translation and multi-modal human-computer interaction to the evaluationof the system proposed in this project.One of the main contributions of our project atthis respect is the integration of assessment tech-niques from different areas into a methodology forevaluating dialog systems for virtual environments,aiming to estimate their usability and effectiveness.This methodology could be used both to determinewhether a system is suitable for a task type anduser, and to compare the performance of differentsystems of the same type.
Another contributionwill be the study and application of software eval-uation standards to the developed systems, creat-ing a standardized quality model and proposing aset of appropriate metrics to assess each of the as-pects of the model.
Finally, the annotated corpusof human-human interaction, together with the cor-pus of human-machine interaction collected duringthe project will be made public.
Such corpora willserve, for example, to design more general platformsfor evaluating dialog systems, going beyond the as-pects evaluated by existing platforms like GIVE.Impact in the Argentinean Landscape: Naturallanguage processing, and in particular the field ofdialogue systems is a rapidly growing area in devel-oped countries.
The automatic processing of natu-ral language has become a strategic capability forcompanies and the wider community.
However, thisarea is extremely underdeveloped in Argentina.
Thiscan be attributed to several factors.
(a) The relativeyouth of the area of NLP, which implies a relativedearth of trained professionals throughout the world.
(b) The underdevelopment of the area of research inArtificial Intelligence and Formal Linguistics in Ar-gentina, for historical reasons and lack of industrydemand.
(c) Poor interaction between the few re-searchers in NLP that are in the region.NLP is a strategic research area for Argentinawhich can achieve academic excellence and indus-try relevance.
We believe in supporting the devel-opment of this area by promoting the following.
(a) Training of human resources through doctoralprograms and courses taught in Argentina by in-ternationally renowned professionals.
(b) Incorpo-ration of trained human resources to contribute to137the growth and diversification of the critical mass inthe area.
(c) Improving interaction between variousgroups and individual researchers in NLP, throughthe organization of workshops, courses, visits, co-tutoring, coordinated specialization programs, etc.The particular topics investigated in the frame-work of this project are of relevance in the currentArgentinean landscape for at least two reasons.
Onthe one hand, the project integrates and develops var-ious key aspects of the area of computational lin-guistics (syntax, semantics, pragmatics, representa-tion, inference, evaluation); an area which, as wementioned, is today almost nonexistent in Argentina.This project will be a step towards reversing this sit-uation.
On the other hand, the ultimate goal of theproject is to investigate the use of the developed plat-form for distance education (specifically, as a toolfor language learning).
Distance education is a valu-able resource to overcome the problem of centraliza-tion of educational resources in the country.4 Introducing the Research GroupThe PLN5 research group, in which the describescientific project will be carried out, was fundedin 2005.
Te group is developing an importantrole in human resource training, delivering coursesto undergraduate and postgraduate student at theUniversidad de Co?rdoba and other universities.
Italso works in the development of various researchprojects and integration with other groups in the re-gion, both within Argentina and with neighboringcountries (Chile, Brazil and Uruguay).The current project pools together many of thekey areas of expertise of the members of the group.To begin with, some members of the group special-ize in computational logic, particularly in the theo-retical and applied study of languages for knowledgerepresentation (e.g., modal, hybrid and descriptionlogics).
They have also developed automated theo-rem provers for these languages6.
In relation withthe study of knowledge representation, they havealso investigated and developed algorithms for gen-erating referring expressions (Areces et al, 2008b).The second line of research of the PLN group thatis relevant for this project is context-based evalua-5http://www.cs.famaf.unc.edu.ar/?pln6http://www.glyc.dc.uba.ar/intohylo/tion.
Members of the group have proposed an eval-uation model for machine translation systems whichrelates the context of use to potentially importantquality characteristics (Estrella et al, 2008; Estrellaet al, 2009).
This model is general enough to beapplied to other systems that produce natural lan-guage like the ones proposed in this paper.
Thanks tothe background on machine translation systems theteam has experience evaluating and comparing natu-ral language output produced in different languages(Spanish and English in particular), which will berelevant for the development of the language tutordescribed in Section 2.4.
Finally, the team has ex-perience developing and evaluating multimodal cor-pora like those described in Section 2 (Estrella andPopescu-Belis, 2008).The third line of research that is relevant for thisproject is pragmatics.
In this area the team has im-plemented a conversational agent which is able toinfer and negotiate conversational implicatures us-ing inference tasks such as classical planning andplanning under incomplete information (Benotti,2009b).
We have also investigated how to inferconversational implicatures triggered by compara-tive utterances (Benotti and Traum, 2009).
Recentlywe have done corpus-based work, which shows whatkinds of implicatures are inferred and negotiated byhuman dialogue participants during a task situatedin a 3D virtual environment (Benotti, 2009a).Other lines of research in the PLN group are notdirectly related to the project at this stage, but mightbecome relevant in the future.
They include gram-mar induction, text mining, statistical syntactic anal-ysis and ontology population from raw text.5 Ongoing and Future CollaborationsThe members of the PLN in general and the authorsof this paper in particular have several collaborationswith national and international research groups incomputational linguistics and related fields that arerelevant for this project.At the international level, we have ongoing col-laboration with the TIM/ISSCO7 Multilingual In-formation Processing Department at the Universityof Geneva, with the Idiap Research Institute8 and7http://www.issco.unige.ch/en8http://www.idiap.ch138with some members of the PAI9, Pervasive Artifi-cial Intelligence group of the University of Fribourg.These collaborations include the evaluation of NLPsystems and the development of multilingual andmultimodal human language technology systems.Members of the group have a long standing col-laboration with the TALARIS10 group of the Labo-ratoire Lorrain de Recherche en Informatique et sesApplications (LORIA).
The main research topic atTALARIS is computational linguistics with strongemphasis on semantics and inference.
In the frame-work of this collaboration we are participating in the2010 edition of the GIVE Challenge.
In the pro-cess of designing the systems that will participate inthe challenge we jointly investigated the use of dif-ferent referring strategies in situated instruction giv-ing (Amoia et al, 2010).We have also collaborated with the Virtual Hu-mans group of the Institute for Creative Technolo-gies11 from the University of Southern California.In particular we computationally modeled the in-ference of conversational implicatures triggered bycomparative utterances (Benotti and Traum, 2009).The Institute for Creative Technologies offers In-ternship programs every year that we plan to use inorder to strengthen our collaboration.All these collaborations are directly related to themain theme of the project described in this arti-cle.
The PLN group has also research collaborationswith other international research teams in the frame-work of other scientific programs.
For example, thePLN group has being part of a recently finished in-ternational project MICROBIO12 on ontology popu-lation from raw text.
The project was funded by theStic-Amsud13 program, a scientific-technologicalcooperation program integrated by France, Argen-tine, Brazil, Chile, Paraguay, Peru and Uruguay.
Theexpertise obtained during this project might be use-ful in the future when trying to extend our GIVE on-tologies to new domains.
Similarly, the team main-tain scientific relations with the University of Texasat Austin (mainly with Dr. J. Moore in projects re-9http://diuf.unifr.ch/pai/wiki10http://talaris.loria.fr11http://ict.usc.edu/projects/virtual_humans12http://www.microbioamsud.net13http://www.sticamsud.orglated to the development of the ACL214 prover); andwith the Research team Symbiose15 of the Institut deRecherche en Informatique et Syste?mes Ale?atoires(working on the use of linguistic techniques for themodelisation of genomic sequences).At the national level, the group has inten-sively collaborated with GLyC16, Grupo de Lo?gica,Lenguaje y Computabilidad on knowledge represen-tation and inference (see, e.g.
(Areces and Gor?
?n,2005; Areces et al, 2008a)).
GLyC is part of theComputer Science Department of the Universidadde Buenos Aires.
During 2010, teams PLN andGLyC will join forces and collaborate in the organi-zation of ELiC17, the First School in ComputationalLinguistics in Argentina, which will take place inJuly at the Universidad de Buenos Aires.
ELiC 2010will be co-located with the ECI18, Escuela de Cien-cias Informa?ticas which has a long standing repu-tation as a high-quality winter school in ComputerScience in Argentina, and is being organized yearlysince 1987.
With ELiC we aim at creating, for thefirst time, a space to introduce the field of computa-tional linguistics to graduate students in Argentina.Thanks to the support of the North American Chap-ter of the Association for Computational Linguis-tics (NAACL) and of the Universidad de BuenosAires, ELiC is offering student travel grants and feewaivers to encourage participation.The PLN group is also contacting other groupsworking in computational linguistics in Argentinalike the research group in Artificial Intelligence fromthe Universidad Nacional del Comahue19.
Takingadvantage of previous co-participation in differentproject we plan to organize exchange programs inthe framework of a research network.Finally, the PLN group is planning to orga-nize a workshop on Computational Linguistics asa satellite event of IBERAMIA 201020, the Ibero-American Conference on Artificial Intelligence, thatwill be organized by the Universidad del Sur, in thecity of Bah?
?a Blanca, Argentina.14http://www.cs.utexas.edu/users/moore/acl215http://www.irisa.fr/symbiose16http://www.glyc.dc.uba.ar17http://www.glyc.dc.uba.ar/elic201018http://www.dc.uba.ar/events/eci/2009/eci200919http://www.uncoma.edu.ar/20http://cs.uns.edu.ar/iberamia2010139ReferencesM.
Amoia, A. Denis, L. Benotti, and C. Gardent.
2010.Evaluating referring strategies in situated instructiongiving.
Topics in Cognitive Science.
Submitted.C.
Areces and D.
Gor??n.
2005.
Ordered resolution withselection for H(@).
In F. Baader and A. Voronkov,editors, Proc.
of LPAR 2004, volume 3452 of LNCS,pages 125?141.
Springer.C.
Areces, D. Figueira, S. Figueira, and S. Mera.
2008a.Expressive power and decidability for memory log-ics.
In Logic, Language, Information and Computa-tion, volume 5110 of LNCSs, pages 56?68.
Springer.C.
Areces, A. Koller, and K. Striegnitz.
2008b.
Referringexpressions as formulas of description logic.
In Proc.of INLG-08.J.
Austin.
1962.
How to do Things with Words.
OxfordUniversity Press.L.
Benotti and D. Traum.
2009.
A computational ac-count of comparative implicatures for a spoken dia-logue agent.
In Proc.
of IWCS-8.L.
Benotti.
2009a.
Clarification potential of instructions.In SIGDIAL-09.L.
Benotti.
2009b.
Frolog: An accommodating text-adventure game.
In Proc.
of EACL-09.N.
Blaylock.
2005.
Towards tractable agent-based dia-logue.
Ph.D. thesis, University of Rochester, Depart-ment of Computer Science.D.
Byron, A. Koller, K. Striegnitz, J. Cassell, R. Dale,J.
Moore, and J. Oberlander.
2009.
Report on the 1stGIVE challenge.
In Proc.
of ENLG, pages 165?173.N.
Dahlba?ck, A. Jo?nsson, and L. Ahrenberg.
1998.
Wiz-ard of Oz studies?why and how.
In Readings in intel-ligent user interfaces, pages 610?619.
Morgan Kauf-mann Publishers Inc.J.
Doswell.
2005.
It?s virtually pedagogical: pedagogi-cal agents in mixed reality learning environments.
InProc.
of SIGGRAPH-05, page 25.
ACM.O.
Engwall, P. Wik, J. Beskow, and G. Granstro?m.
2004.Design strategies for a virtual language tutor.
InS.
Kim and D. Young, editors, Proc.
of ICSLP-04, vol-ume 3, pages 1693?1696.P.
Estrella and A. Popescu-Belis.
2008.
Multi-eval: anevaluation framework for multimodal dialogue anno-tations.
Poster at the Joint IM2 and ASSI.P.
Estrella, A. Popescu-Belis, and N. Underwood.
2005.Finding the system that suits you best: Towards thenormalization of MT evaluation.
In Proc.
of ASLIB-05, pages 23?34.P.
Estrella, A. Popescu-Belis, and M. King.
2008.
Im-proving contextual quality models for MT evaluationbased on evaluators?
feedback.
In Proc.
of LREC-08.P.
Estrella, A. Popescu-Belis, and M. King.
2009.
Thefemti guidelines for contextual mt evaluation: princi-ples and tools.
In W. Daelemans and V. Hoste, ed-itors, Evaluation of Translation Technology.
Linguis-tica Antverpiensia.M.
Foster, M. Giuliani, A. Isard, C. Matheson, J. Ober-lander, and A. Knoll.
2009.
Evaluating descriptionand reference strategies in a cooperative human-robotdialogue system.
In Proc.
of IJCAI-09.P.
Grice.
1975.
Logic and conversation.
In P. Coleand J. Morgan, editors, Syntax and Semantics: Vol.
3:Speech Acts, pages 41?58.
Academic Press.M.
Hajdinjak and F. Mihelic.
2006.
The paradise evalu-ation framework: Issues and findings.
ComputationalLinguistics, 32(2):263?272.J.
Hoffmann and B. Nebel.
2001.
The FF planningsystem: Fast plan generation through heuristic search.JAIR, 14:253?302.ISO/IEC.
1999.
14598-1:1999 (E) ?
Information Tech-nology ?
Software Product Evaluation ?
Part 1: Gen-eral Overview.ISO/IEC.
2001.
9126-1:2001 (E) ?
Software Engineer-ing ?
Product Quality ?
Part 1:Quality Model.H.
Kautz and B. Selman.
1999.
Unifying SAT-basedand graph-based planning.
In Proc of the IJCAI, pages318?325.R.
Lecoeuche, C. Mellish, and D. Robertson.
1998.
Aframework for requirements elicitation through mixed-initiative dialogue.
In Proc.
ICRE-98.
IEEE.D.
Litman and S. Pan.
2002.
Designing and evaluatingan adaptive spoken dialogue system.
User Modelingand User-Adapted Interaction, 12(2-3):111?137.J.
Molka-Danielsen and M. Deutschmann, editors.
2009.Learning and Teaching in the Virtual World of SecondLife.
Tapir Academic Press.D.
Nau, M. Ghallab, and P. Traverso.
2004.
AutomatedPlanning: Theory & Practice.
Morgan KaufmannPublishers Inc.M.
Purver.
2006.
CLARIE: Handling clarification re-quests in a dialogue system.
Research on Languageand Computation, 4(2-3):259?288.E.
Schegloff.
1987.
Some sources of misunderstandingin talk-in-interaction.
Linguistics, 8:201?218.P.
Wik and A. Hjalmarsson.
2009.
Embodied conversa-tional agents in computer assisted language learning.Speech Commun., 51(10):1024?1037.140
