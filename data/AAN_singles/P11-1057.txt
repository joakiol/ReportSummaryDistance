Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 561?569,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsTogether We Can: Bilingual Bootstrapping for WSDMitesh M. Khapra Salil Joshi Arindam Chatterjee Pushpak BhattacharyyaDepartment Of Computer Science and Engineering,IIT Bombay,Powai,Mumbai, 400076.
{miteshk,salilj,arindam,pb}@cse.iitb.ac.inAbstractRecent work on bilingual Word Sense Disam-biguation (WSD) has shown that a resourcedeprived language (L1) can benefit from theannotation work done in a resource rich lan-guage (L2) via parameter projection.
How-ever, this method assumes the presence of suf-ficient annotated data in one resource rich lan-guage which may not always be possible.
In-stead, we focus on the situation where thereare two resource deprived languages, bothhaving a very small amount of seed annotateddata and a large amount of untagged data.
Wethen use bilingual bootstrapping, wherein, amodel trained using the seed annotated dataof L1 is used to annotate the untagged data ofL2 and vice versa using parameter projection.The untagged instances of L1 and L2 whichget annotated with high confidence are thenadded to the seed data of the respective lan-guages and the above process is repeated.
Ourexperiments show that such a bilingual boot-strapping algorithm when evaluated on twodifferent domains with small seed sizes usingHindi (L1) and Marathi (L2) as the languagepair performs better than monolingual boot-strapping and significantly reduces annotationcost.1 IntroductionThe high cost of collecting sense annotated data forsupervised approaches (Ng and Lee, 1996; Lee etal., 2004) has always remained a matter of concernfor some of the resource deprived languages of theworld.
The problem is even more hard-hitting formultilingual regions (e.g., India which has more than20 constitutionally recognized languages).
To cir-cumvent this problem, unsupervised and knowledgebased approaches (Lesk, 1986; Walker and Amsler,1986; Agirre and Rigau, 1996; McCarthy et al,2004; Mihalcea, 2005) have been proposed as an al-ternative but they have failed to deliver good accura-cies.
Semi-supervised approaches (Yarowsky, 1995)which use a small amount of annotated data and alarge amount of untagged data have shown promisealbeit for a limited set of target words.
The abovesituation highlights the need for high accuracy re-source conscious approaches to all-words multilin-gual WSD.Recent work by Khapra et al (2010) in this di-rection has shown that it is possible to perform costeffective WSD in a target language (L2) withoutcompromising much on accuracy by leveraging onthe annotation work done in another language (L1).This is achieved with the help of a novel synset-aligned multilingual dictionary which facilitates theprojection of parameters learned from the Wordnetand annotated corpus of L1 to L2.
This approachthus obviates the need for collecting large amountsof annotated corpora in multiple languages by rely-ing on sufficient annotated corpus in one resourcerich language.
However, in many situations such apivot resource rich language itself may not be avail-able.
Instead, we might have two or more languageshaving a small amount of annotated corpus and alarge amount of untagged corpus.
Addressing suchsituations is the main focus of this work.
Specifi-cally, we address the following question:In the absence of a pivot resource rich lan-guage is it possible for two resource de-prived languages to mutually benefit fromeach other?s annotated data?While addressing the above question we assume that561even though it is hard to obtain large amounts ofannotated data in multiple languages, it should befairly easy to obtain a large amount of untagged datain these languages.
We leverage on such untaggeddata by employing a bootstrapping strategy.
Theidea is to train an initial model using a small amountof annotated data in both the languages and itera-tively expand this seed data by including untaggedinstances which get tagged with a high confidencein successive iterations.
Instead of using monolin-gual bootstrapping, we use bilingual bootstrappingvia parameter projection.
In other words, the pa-rameters learned from the annotated data of L1 (andL2 respectively) are projected to L2 (and L1 respec-tively) and the projected model is used to tag the un-tagged instances of L2 (and L1 respectively).Such a bilingual bootstrapping strategy whentested on two domains, viz., Tourism and Health us-ing Hindi (L1) and Marathi (L2) as the languagepair, consistently does better than a baseline strat-egy which uses only seed data for training withoutperforming any bootstrapping.
Further, it consis-tently performs better than monolingual bootstrap-ping.
A simple and intuitive explanation for this isas follows.
In monolingual bootstrapping a languagecan benefit only from its own seed data and hencecan tag only those instances with high confidencewhich it has already seen.
On the other hand, inbilingual bootstrapping a language can benefit fromthe seed data available in the other language whichwas not previously seen in its self corpus.
This isvery similar to the process of co-training (Blum andMitchell, 1998) wherein the annotated data in thetwo languages can be seen as two different views ofthe same data.
Hence, the classifier trained on oneview can be improved by adding those untagged in-stances which are tagged with a high confidence bythe classifier trained on the other view.The remainder of this paper is organized as fol-lows.
In section 2 we present related work.
Section3 describes the Synset algned multilingual dictio-nary which facilitates parameter projection.
Section4 discusses the work of Khapra et al (2009) on pa-rameter projection.
In section 5 we discuss bilin-gual bootstrapping which is the main focus of ourwork followed by a brief discussion on monolingualbootstrapping.
Section 6 describes the experimentalsetup.
In section 7 we present the results followedby discussion in section 8.
Section 9 concludes thepaper.2 Related WorkBootstrapping for Word Sense Disambiguation wasfirst discussed in (Yarowsky, 1995).
Starting with avery small number of seed collocations an initial de-cision list is created.
This decisions list is then ap-plied to untagged data and the instances which gettagged with a high confidence are added to the seeddata.
This algorithm thus proceeds iteratively in-creasing the seed size in successive iterations.
Thismonolingual bootstrapping method showed promisewhen tested on a limited set of target words but wasnot tried for all-words WSD.The failure of monolingual approaches (Ng andLee, 1996; Lee et al, 2004; Lesk, 1986; Walker andAmsler, 1986; Agirre and Rigau, 1996; McCarthyet al, 2004; Mihalcea, 2005) to deliver high accura-cies for all-words WSD at low costs created interestin bilingual approaches which aim at reducing theannotation effort.
Recent work in this direction byKhapra et al (2009) aims at reducing the annotationeffort in multiple languages by leveraging on exist-ing resources in a pivot language.
They showed thatit is possible to project the parameters learned fromthe annotation work of one language to another lan-guage provided aligned Wordnets for the two lan-guages are available.
However, they do not addresssituations where two resource deprived languageshave aligned Wordnets but neither has sufficient an-notated data.
In such cases bilingual bootstrappingcan be used so that the two languages can mutuallybenefit from each other?s small annotated data.Li and Li (2004) proposed a bilingual bootstrap-ping approach for the more specific task of WordTranslation Disambiguation (WTD) as opposed tothe more general task of WSD.
This approach doesnot need parallel corpora (just like our approach)and relies only on in-domain corpora from two lan-guages.
However, their work was evaluated only ona handful of target words (9 nouns) for WTD as op-posed to the broader task of WSD.
Our work insteadfocuses on improving the performance of all wordsWSD for two resource deprived languages usingbilingual bootstrapping.
At the heart of our work liesparameter projection facilitated by a synset algned562multilingual dictionary described in the next section.3 Synset Aligned Multilingual DictionaryA novel and effective method of storage and use ofdictionary in a multilingual setting was proposed byMohanty et al (2008).
For the purpose of currentdiscussion, we will refer to this multilingual dictio-nary framework as MultiDict.
One important de-parture in this framework from the traditional dic-tionary is that synsets are linked, and after thatthe words inside the synsets are linked.
The ba-sic mapping is thus between synsets and thereafterbetween the words.Concepts L1(English)L2(Hindi)L3(Marathi)04321:a youth-ful maleperson{malechild,boy}{lwkA(ladkaa),bAlk(baalak),bQcA(bachchaa)}{m  lgA(mulgaa),porgA(porgaa),por (por)}Table 1: Multilingual Dictionary FrameworkTable 1 shows the structure of MultiDict, with oneexample row standing for the concept of boy.
Thefirst column is the pivot describing a concept with aunique ID.
The subsequent columns show the wordsexpressing the concept in respective languages (inthe example table, English, Hindi and Marathi).
Af-ter the synsets are linked, cross linkages are set upmanually from the words of a synset to the wordsof a linked synset of the pivot language.
For exam-ple, for the Marathi word m  lgA (mulgaa), ?a youth-ful male person?, the correct lexical substitute fromthe corresponding Hindi synset is lwkA (ladkaa).The average number of such links per synset per lan-guage pair is approximately 3.
However, since ourwork takes place in a semi-supervised setting, wedo not assume the presence of these manual crosslinkages between synset members.
Instead, in theabove example, we assume that all the words inthe Hindi synset are equally probable translationsof every word in the corresponding Marathi synset.Such cross-linkages between synset members facil-itate parameter projection as explained in the nextsection.4 Parameter ProjectionKhapra et al (2009) proposed that the variousparameters essential for domain-specific WordSense Disambiguation can be broadly classified intotwo categories:Wordnet-dependent parameters:?
belongingness-to-dominant-concept?
conceptual distance?
semantic distanceCorpus-dependent parameters:?
sense distributions?
corpus co-occurrenceThey proposed a scoring function (Equation (1))which combines these parameters to identify the cor-rect sense of a word in a context:S?
= argmaxi(?iVi +?j?JWij ?
Vi ?
Vj) (1)where,i ?
Candidate SynsetsJ = Set of disambiguated words?i = BelongingnessToDominantConcept(Si)Vi = P (Si|word)Wij = CorpusCooccurrence(Si, Sj)?
1/WNConceptualDistance(Si, Sj)?
1/WNSemanticGraphDistance(Si, Sj)The first component ?iVi of Equation (1) capturesinfluence of the corpus specific sense of a word in adomain.
The other component Wij ?Vi ?Vj capturesthe influence of interaction of the candidate sensewith the senses of context words weighted by factorsof co-occurrence, conceptual distance and semanticdistance.Wordnet-dependent parameters depend on thestructure of the Wordnet whereas the Corpus-dependent parameters depend on various statisticslearned from a sense marked corpora.
Both thetasks of (a) constructing a Wordnet from scratch and(b) collecting sense marked corpora for multiplelanguages are tedious and expensive.
Khapra et563al.
(2009) observed that by projecting relationsfrom the Wordnet of a language and by projectingcorpus statistics from the sense marked corporaof the language to those of the target language,the effort required in constructing semantic graphsfor multiple Wordnets and collecting sense markedcorpora for multiple languages can be avoidedor reduced.
At the heart of their work lies theMultiDict described in previous section whichfacilitates parameter projection in the followingmanner:1.
By linking with the synsets of a pivot resourcerich language (Hindi, in our case), the cost of build-ing Wordnets of other languages is partly reduced(semantic relations are inherited).
The Wordnet pa-rameters of Hindi Wordnet now become projectableto other languages.2.
For calculating corpus specific sense distribu-tions, P (Sense Si|Word W ), we need the counts,#(Si,W ).
By using cross linked words in thesynsets, these counts become projectable to the tar-get language (Marathi, in our case) as they can beapproximated by the counts of the cross linked Hindiwords calculated from the Hindi sense marked cor-pus as follows:P (Si|W ) =#(Si,marathi word)?j #(Sj ,marathi word)P (Si|W ) ?#(Si, cross linked hindi word)?j #(Sj , cross linked hindi word)The rationale behind the above approximation is theobservation that within a domain the counts of cross-linked words will remain the same across languages.This parameter projection strategy as explainedabove lies at the heart of our work and allows usto perform bilingual bootstrapping by projecting themodels learned from one language to another.5 Bilingual BootstrappingWe now come to the main contribution of our work,i.e., bilingual bootstrapping.
As shown in Algorithm1, we start with a small amount of seed data (LD1and LD2) in the two languages.
Using this data welearn the parameters described in the previous sec-tion.
We collectively refer to the parameters learnedAlgorithm 1 Bilingual BootstrappingLD1 := Seed Labeled Data from L1LD2 := Seed Labeled Data from L2UD1 := Unlabeled Data from L1UD2 := Unlabeled Data from L2repeat?1 := model trained using LD1?2 := model trained using LD2{Project models from L1/L2 to L2/L1}?
?2 := project(?1, L2)?
?1 := project(?2, L1)for all u1 ?
UD1 dos := sense assigned by ?
?1 to u1if confidence(s) >  thenLD1 := LD1 + u1UD1 := UD1 - u1end ifend forfor all u2 ?
UD2 dos := sense assigned by ?
?2 to u2if confidence(s) >  thenLD2 := LD2 + u2UD2 := UD2 - u2end ifend foruntil convergencefrom the seed data as models ?1 and ?2 for L1 and L2respectively.
The parameter projection strategy de-scribed in the previous section is then applied to ?1and ?2 to obtain the projected models ?
?2 and ?
?1 re-spectively.
These projected models are then appliedto the untagged data of L1 and L2 and the instanceswhich get labeled with a high confidence are addedto the labeled data of the respective languages.
Thisprocess is repeated till we reach convergence, i.e.,till it is no longer possible to move any data fromUD1 (and UD2) to LD1 (and LD2 respectively).We compare our algorithm with monolingualbootstrapping where the self models ?1 and ?2 aredirectly used to annotate the unlabeled instances inL1 and L2 respectively instead of using the projectedmodels ?
?1 and ??2.
The process of monolingual boot-564Algorithm 2 Monolingual BootstrappingLD1 := Seed Labeled Data from L1LD2 := Seed Labeled Data from L2UD1 := Unlabeled Data from L1UD2 := Unlabeled Data from L2repeat?1 := model trained using LD1?2 := model trained using LD2for all u1 ?
UD1 dos := sense assigned by ?1 to u1if confidence(s) >  thenLD1 := LD1 + u1UD1 := UD1 - u1end ifend forfor all u2 ?
UD2 dos := sense assigned by ?2 to u2if confidence(s) >  thenLD2 := LD2 + u2UD2 := UD2 - u2end ifend foruntil convergencestrapping is shown in Algorithm 2.6 Experimental SetupWe used the publicly available dataset1 describedin Khapra et al (2010) for all our experiments.The data was collected from two domains, viz.,Tourism and Health.
The data for Tourism domainwas collected by manually translating English doc-uments downloaded from Indian Tourism websitesinto Hindi and Marathi.
Similarly, English docu-ments for Health domain were obtained from twodoctors and were manually translated into Hindi andMarathi.
The entire data was then manually an-notated by three lexicographers adept in Hindi andMarathi.
The various statistics pertaining to the totalnumber of words, number of words per POS cate-gory and average degree of polysemy are describedin Tables 2 to 5.Although Tables 2 and 3 also report the num-1http://www.cfilt.iitb.ac.in/wsd/annotated corpusPolysemous words Monosemous wordsCategory Tourism Health Tourism HealthNoun 62336 24089 35811 18923Verb 6386 1401 3667 5109Adjective 18949 8773 28998 12138Adverb 4860 2527 13699 7152All 92531 36790 82175 43322Table 2: Polysemous and Monosemous words per cate-gory in each domain for HindiPolysemous words Monosemous wordsCategory Tourism Health Tourism HealthNoun 45589 17482 27386 11383Verb 7879 3120 2672 1500Adjective 13107 4788 16725 6032Adverb 4036 1727 5023 1874All 70611 27117 51806 20789Table 3: Polysemous and Monosemous words per cate-gory in each domain for MarathiAvg.
degree of Wordnet polysemyfor polysemous wordsCategory Tourism HealthNoun 3.02 3.17Verb 5.05 6.58Adjective 2.66 2.75Adverb 2.52 2.57All 3.09 3.23Table 4: Average degree of Wordnet polysemy per cate-gory in the 2 domains for HindiAvg.
degree of Wordnet polysemyfor polysemous wordsCategory Tourism HealthNoun 3.06 3.18Verb 4.96 5.18Adjective 2.60 2.72Adverb 2.44 2.45All 3.14 3.29Table 5: Average degree of Wordnet polysemy per cate-gory in the 2 domains for Marathi565010203040506070800  1000  2000  3000  4000  5000F-score(%)Seed Size (words)Seed Size v/s F-scoreOnlySeedWFSBiBootMonoBoot010203040506070800  1000  2000  3000  4000  5000F-score(%)Seed Size (words)Seed Size v/s F-scoreOnlySeedWFSBiBootMonoBootFigure 1: Comparison of BiBoot, Mono-Boot, OnlySeed and WFS on Hindi HealthdataFigure 2: Comparison of BiBoot, Mono-Boot, OnlySeed and WFS on HindiTourism data010203040506070800  1000  2000  3000  4000  5000F-score(%)Seed Size (words)Seed Size v/s F-scoreOnlySeedWFSBiBootMonoBoot010203040506070800  1000  2000  3000  4000  5000F-score(%)Seed Size (words)Seed Size v/s F-scoreOnlySeedWFSBiBootMonoBootFigure 3: Comparison of BiBoot, Mono-Boot, OnlySeed and WFS on MarathiHealth dataFigure 4: Comparison of BiBoot, Mono-Boot, OnlySeed and WFS on MarathiTourism databer of monosemous words, we would like to clearlystate that we do not consider monosemous wordswhile evaluating the performance of our algorithms(as monosemous words do not need any disambigua-tion).We did a 4-fold cross validation of our algorithmusing the above described corpora.
Note that eventhough the corpora were parallel we did not use thisproperty in any way in our experiments or algorithm.In fact, the documents in the two languages wererandomly split into 4 folds without ensuring that theparallel documents remain in the same folds for thetwo languages.
We experimented with different seedsizes varying from 0 to 5000 in steps of 250.
Theseed annotated data and untagged instances for boot-strapping are extracted from 3 folds of the data andthe final evaluation is done on the held-out data inthe 4th fold.We ran both the bootstrapping algorithms (i.e.,monolingual bootstrapping and bilingual boot-strapping) for 10 iterations but, we observedthat after 1-2 iterations the algorithms converge.In each iteration only those words for whichP (assigned sense|word) > 0.6 get moved to thelabeled data.
Ideally, this threshold (0.6) shouldhave been selected using a development set.
How-ever, since our work focuses on resource scarce lan-guages we did not want to incur the additional costof using a development set.
Hence, we used a fixedthreshold of 0.6 so that in each iteration only thosewords get moved to the labeled data for which theassigned sense is clearly a majority sense (P > 0.6).566Language-Domain Algorithm F-score(%)No.
of taggedwords needed toachieve thisF-score% Reduction in annotationcostHindi-Health Biboot 57.70 1250(2250+2250)?
(1250+1750)(2250+2250) ?
100 = 33.33%OnlySeed 57.99 2250Marathi-Health Biboot 64.97 1750OnlySeed 64.51 2250Hindi-Tourism Biboot 60.67 1000(2000+2000)?
(1000+1250)(2000+2000) ?
100 = 43.75%OnlySeed 59.83 2000Marathi-Tourism Biboot 61.90 1250OnlySeed 61.68 2000Table 6: Reduction in annotation cost achieved using Bilingual Bootstrapping7 ResultsThe results of our experiments are summarized inFigures 1 to 4.
The x-axis represents the amount ofseed data used and the y-axis represents the F-scoresobtained.
The different curves in each graph are asfollows:a. BiBoot: This curve represents the F-score ob-tained after 10 iterations by using bilingual boot-strapping with different amounts of seed data.b.
MonoBoot: This curve represents the F-score ob-tained after 10 iterations by using monolingualbootstrapping with different amounts of seed data.c.
OnlySeed: This curve represents the F-score ob-tained by training on the seed data alone withoutusing any bootstrapping.d.
WFS: This curve represents the F-score obtainedby simply selecting the first sense from Wordnet,a typically reported baseline.8 DiscussionsIn this section we discuss the important observationsmade from Figures 1 to 4.8.1 Performance of Bilingual bootstrappingFor small seed sizes, the F-score of bilingual boot-strapping is consistently better than the F-score ob-tained by training only on the seed data without us-ing any bootstrapping.
This is true for both the lan-guages in both the domains.
Further, bilingual boot-strapping also does better than monolingual boot-strapping for small seed sizes.
As explained earlier,this better performance can be attributed to the factthat in monolingual bootstrapping the algorithm cantag only those instances with high confidence whichit has already seen in the training data.
Hence, insuccessive iterations, very little new information be-comes available to the algorithm.
This is clearlyevident from the fact that the curve of monolin-gual bootstrapping (MonoBoot) is always close tothe curve of OnlySeed.8.2 Effect of seed sizeThe benefit of bilingual bootstrapping is clearly feltfor small seed sizes.
However, as the seed size in-creases the performance of the 3 algorithms, viz.,MonoBoot, BiBoot and OnlySeed is more or less thesame.
This is intuitive, because, as the seed size in-creases the algorithm is able to see more and moretagged instances in its self corpora and hence doesnot need any assistance from the other language.
Inother words, the annotated data in L1 is not able toadd any new information to the training process ofL2 and vice versa.8.3 Bilingual bootstrapping reduces annotationcostThe performance boost obtained at small seed sizessuggests that bilingual bootstrapping helps to reducethe overall annotation costs for both the languages.To further illustrate this, we take some sample pointsfrom the graph and compare the number of taggedwords needed by BiBoot and OnlySeed to reach thesame (or nearly the same) F-score.
We present thiscomparison in Table 6.567The rows for Hindi-Health and Marathi-Health inTable 6 show that when BiBoot is employed weneed 1250 tagged words in Hindi and 1750 taggedwords in Marathi to attain F-scores of 57.70% and64.97% respectively.
On the other hand, in the ab-sence of bilingual bootstrapping, (i.e., using Only-Seed) we need 2250 tagged words each in Hindi andMarathi to achieve similar F-scores.
BiBoot thusgives a reduction of 33.33% in the overall annota-tion cost ( {1250 + 1750} v/s {2250 + 2250}) whileachieving similar F-scores.
Similarly, the results forHindi-Tourism and Marathi-Tourism show that Bi-Boot gives a reduction of 43.75% in the overall an-notation cost while achieving similar F-scores.
Fur-ther, since the results of MonoBoot are almost thesame as OnlySeed, the above numbers indicate thatBiBoot provides a reduction in cost when comparedto MonoBoot also.8.4 Contribution of monosemous words in theperformance of BiBootAs mentioned earlier, monosemous words in the testset are not considered while evaluating the perfor-mance of our algorithm but, we add monosemouswords to the seed data.
However, we do not countmonosemous words while calculating the seed sizeas there is no manual annotation cost associated withmonosemous words (they can be tagged automati-cally by fetching their singleton sense id from thewordnet).
We observed that the monosemous wordsof L1 help in boosting the performance of L2 andvice versa.
This is because for a given monose-mous word in L2 (or L1 respectively) the corre-sponding cross-linked word in L1 (or L2 respec-tively) need not necessarily be monosemous.
In suchcases, the cross-linked polysemous word in L2 (orL1 respectively) benefits from the projected statis-tics of a monosemous word in L1 (or L2 respec-tively).
This explains why BiBoot gives an F-scoreof 35-52% even at zero seed size even though theF-score of OnlySeed is only 2-5% (see Figures 1 to4).9 ConclusionWe presented a bilingual bootstrapping algorithmfor Word Sense Disambiguation which allows tworesource deprived languages to mutually benefitfrom each other?s data via parameter projection.
Thealgorithm consistently performs better than mono-lingual bootstrapping.
It also performs better thanusing only monolingual seed data without using anybootstrapping.
The benefit of bilingual bootstrap-ping is felt prominently when the seed size in the twolanguages is very small thus highlighting the useful-ness of this algorithm in highly resource constrainedscenarios.AcknowledgmentsWe acknowledge the support of Microsoft Re-search India in the form of an International TravelGrant, which enabled one of the authors (Mitesh M.Khapra) to attend this conference.ReferencesEneko Agirre and German Rigau.
1996.
Word sense dis-ambiguation using conceptual density.
In In Proceed-ings of the 16th International Conference on Compu-tational Linguistics (COLING).Avrim Blum and Tom Mitchell.
1998.
Combining la-beled and unlabeled data with co-training.
pages 92?100.
Morgan Kaufmann Publishers.Mitesh M. Khapra, Sapan Shah, Piyush Kedia, and Push-pak Bhattacharyya.
2009.
Projecting parameters formultilingual word sense disambiguation.
In Proceed-ings of the 2009 Conference on Empirical Methods inNatural Language Processing, pages 459?467, Singa-pore, August.
Association for Computational Linguis-tics.Mitesh Khapra, Saurabh Sohoney, Anup Kulkarni, andPushpak Bhattacharyya.
2010.
Value for money: Bal-ancing annotation effort, lexicon building and accu-racy for multilingual wsd.
In Proceedings of the 23rdInternational Conference on Computational Linguis-tics.Yoong Keok Lee, Hwee Tou Ng, and Tee Kiah Chia.2004.
Supervised word sense disambiguation withsupport vector machines and multiple knowledgesources.
In Proceedings of Senseval-3: Third Inter-national Workshop on the Evaluation of Systems forthe Semantic Analysis of Text, pages 137?140.Michael Lesk.
1986.
Automatic sense disambiguationusing machine readable dictionaries: how to tell a pinecone from an ice cream cone.
In In Proceedings of the5th annual international conference on Systems docu-mentation.Hang Li and Cong Li.
2004.
Word translation disam-biguation using bilingual bootstrapping.
Comput.
Lin-guist., 30:1?22, March.568Diana McCarthy, Rob Koeling, Julie Weeds, and JohnCarroll.
2004.
Finding predominant word sensesin untagged text.
In ACL ?04: Proceedings of the42nd Annual Meeting on Association for Computa-tional Linguistics, page 279, Morristown, NJ, USA.Association for Computational Linguistics.Rada Mihalcea.
2005.
Large vocabulary unsupervisedword sense disambiguation with graph-based algo-rithms for sequence data labeling.
In In Proceedings ofthe Joint Human Language Technology and EmpiricalMethods in Natural Language Processing Conference(HLT/EMNLP), pages 411?418.Rajat Mohanty, Pushpak Bhattacharyya, PrabhakarPande, Shraddha Kalele, Mitesh Khapra, and AdityaSharma.
2008.
Synset based multilingual dictionary:Insights, applications and challenges.
In Global Word-net Conference.Hwee Tou Ng and Hian Beng Lee.
1996.
Integrat-ing multiple knowledge sources to disambiguate wordsenses: An exemplar-based approach.
In In Proceed-ings of the 34th Annual Meeting of the Association forComputational Linguistics (ACL), pages 40?47.D.
Walker and R. Amsler.
1986.
The use of machinereadable dictionaries in sublanguage analysis.
In InAnalyzing Language in Restricted Domains, Grish-man and Kittredge (eds), LEA Press, pages 69?83.David Yarowsky.
1995.
Unsupervised word sense dis-ambiguation rivaling supervised methods.
In Proceed-ings of the 33rd annual meeting on Association forComputational Linguistics, pages 189?196, Morris-town, NJ, USA.
Association for Computational Lin-guistics.569
