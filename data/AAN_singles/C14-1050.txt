Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 520?529, Dublin, Ireland, August 23-29 2014.Skill Inference with Personal and Skill ConnectionsZhongqing Wang?, Shoushan Li?
?, Hanxiao Shi?, and Guodong Zhou?
?Natural Language Processing Lab, School of Computer Science and Technology,Soochow University, China?School of Computer Science and Information Engineering,Zhejiang Gongshang University, China{wangzq.antony, shoushan.li}@gmail.comhxshi@mail.zjgsu.edu.cn, gdzhou@suda.edu.cnAbstractPersonal skill information on social media is at the core of many interesting applications.
Inthis paper, we propose a factor graph based approach to automatically infer skills from per-sonal profile incorporated with both personal and skill connections.
We first extract personalconnections with similar academic and business background (e.g.
co-major, co-university, andco-corporation).
We then extract skill connections between skills from the same person.
To wellintegrate various kinds of connections, we propose a joint prediction factor graph (JPFG) modelto collectively infer personal skills with help of personal connection factor, skill connection fac-tor, besides the normal textual attributes.
Evaluation on a large-scale dataset from LinkedIn.comvalidates the effectiveness of our approach.1 IntroductionWith the large amount of user-generated content (UGC) published online every day in the context ofsocial networks (Tan et al., 2011; Luo et al., 2013), such online social networks (e.g., Twitter, Facebook,and LinkedIn) have significantly enlarged our social circles and much affected our everyday life.
Onepopular and important type of UGC is the personal profile, where people post their detailed information,such as education, experience and other personal information, on online portals.
Social websites likeFacebook.com and LinkedIn.com have created a viable business as profile portals, with the popularityand success largely attributed to their comprehensive personal profiles.Obviously, online personal profiles can help people connect with others of similar backgrounds andprovide valuable resources for businesses, especially for personnel resource managers to find talents(Yang et al., 2011a; Guy et al., 2010).
In the profiles, the personal skill information is the most impor-tant aspect to reflect the expertise of a person.
However, few social platforms allow users to manuallyattach such personal skill information into their personal profiles.
For example, in our collected dataset,91.8% skills appear less than 10 times.
Even the distribution of the top 10 frequently occurring skills isasymmetric, and only 43.1% people attach skills on their profiles.
For this regard, it is highly desirableto develop reliable methods to automatically infer personal skills for personal profiles.Although it is straightforward to recast skill inference as a standard text classification problem, i.e.,predicting the skills with the profile text alone, personal profiles usually are poorly organized, even withcritical information missing.
Thus, it is challenging to infer skills given the limited information fromthe profile texts.
We propose two assumptions to address above challenges by incorporating additionalconnection information between persons and skills:?
People are always connected to others with similar academic and business backgrounds (e.g.
co-major, co-corporation).
For example if there is co-major, co-university, or co-corporation rela-tionship between two persons, it is very likely that they may share similar skills.
Therefore, it isreasonable to resort to personal connection information to improve the performance of skill infer-ence.
*corresponding authorThis work is licensed under a Creative Commons Attribution 4.0 International Licence.
Page numbers and proceedings footerare added by the organisers.
Licence details: http://creativecommons.org/licenses/by/4.0/520?
One person tends to have some related skills.
For example, it is very likely that C++, C, and Pythonprogramming languages may co-occur in the one?s profile, i.e., if a person has skill C++, it is highlypossible that he would have the skills such as C or Python.
Thus, it is useful to integrate skillconnection information when inferring personal skills.Based on these assumptions, we propose a Joint Prediction Factor Graph (JPFG) model, which collec-tively predicts personal skills with help of both personal and skill connections.
In particular, the JPFGmodel provides a general framework to integrate three kinds of knowledge, i.e.
local textual attributefunctions of an individual person, personal connection factors between persons, and skill connection fac-tors between skills, in collectively inferring personal skills.
Specially, we extract personal connectionswith similar academic and business background (e.g.
co-major, co-corporation).
We then extract skillconnections between skills from same person.
Evaluation on a large-scale data set from LinkedIn.comindicates that our JPFG model can significantly improve the performance of personal skill inference.The remainder of this paper is structured as follows.
We review the related work in Section 2.
In Sec-tion 3, we introduce the data collection.
In Section 4, we give the problem definition and some analysison the task of personal skill reference.
In Section 5, we propose the JPFG model and correspondingalgorithms for parameter estimation and prediction.
In Section 6, we present our experimental results.
InSection 7, we summarize our work and discuss future directions.2 Related WorksIn this section, we briefly review related studies in expert finding, social tag suggestion and factor graphmodel.2.1 Expert FindingExpert finding aims to find right persons with appropriate skills or knowledge, i.e.
?Who are the expertson topic X??
TREC-2005 and TREC-2006 have provided a common platform for researchers to empiri-cally evaluate methods and techniques on expert finding (Soboroff et al, 2006; Zhang et al., 2007a).In the literature, expert finding tends to consider each skill individually and seeks the most authorityexperts for each skill.
Thus, expert finding is always considered as a ranking process, i.e., ranking theexperts from the candidates who are most suitable for the skill (Balog and Rijke, 2007).
For example,Campbell et al.
(2003) investigated the issue of expert finding in an email network.
They utilized thelink between email authors and receivers to improve the expert finding performance.Besides that link structure-based algorithms, such as PageRank and HITS, are employed to analyzethe relationship of the link-relationship graph, social networks are utilized to improve the performanceof expert finding.
Zhang et al.
(2007a) proposed a unified propagation-based approach to address theissue of expert finding in a social network, considering both personal local and network information (e.g.the relationship between persons).Expert finding is in nature different from skill inference.
Our study predicts various skills attachable toa person collectively with both personal and skill connections among people.
One distinguishing charac-teristics of our study is that several skills from a person are simultaneously modeled and the relationshipamong these skills is fully leveraged in the inference.2.2 Social Tag SuggestionSocial tag suggestion aims to extract proper tags from social media and can thus help people organizetheir information in an unconstrained manner (Ohkura et al., 2006; Si et al., 2010).
Ohkura et al.
(2006)created a multi-tagger to determine whether a particular tag from a candidate tag list should be attachedto a weblog.
Lappas et al.
(2011) proposed a social endorsement-based approach to generate social tagsfrom Twitter.com and Flickr.com where various kinds of information in recommendations and commentsare used.
Liu et al.
(2012) propose a probabilistic model to connect the semantic relations between wordsand tags of microblog, and takes the social network structure as regularization.
Li et al., (2012) proposeto model context-aware relations of tags for suggestion by regarding resource content as context of tags.521Different from above researches, our study is forced on skill inference instead of traditional tag sugges-tion.
Basically, the social connections in skill inference are much different from those in social tagging.In our study, we use co-major, co-title and other academic and business relationships to build the socialconnections.
Meanwhile, there are also few researches concern to propose a joint model to leverage bothpersonal and skill connections.2.3 Factor Graph ModelAmong various approaches investigated in social networks in the last several years (Leskovec et al.,2010; Lu et al., 2010; Lampos et al., 2013; Guo et al., 2013), Factor Graph Model (FGM) becomes aneffective way to represent and optimize the relationship in social networks (Dong et al., 2012; Yang etal., 2012b) via a graph structure.
Tang et al.
(2011a) and Zhuang et al.
(2012) formalized the problemof social relationship learning as a semi-supervised framework, and proposed Partially-labeled PairwiseFactor Graph Model (PLP-FGM) for inferring the types of social ties.
Tang et al.
(2013) further proposeda factor graph based distributed learning method to construct a conformity influence model and formalizethe effects of social conformity in a probabilistic way.Different from previous studies, this paper proposes a pairwise factor graph model to collectively inferpersonal skills with both social connection factor and skill connection factor.3 Data ConstructionWe collect our data set from LinkedIn.com.
It contains a large number of personal profiles generated byusers, containing various kinds of information, such as personal Summary, Experience, Education, andSkills & Expertise.
We do not collect personal names in public profiles to protect people?s privacy.The dataset contains 7,381 personal profiles, among which only 3,182 profiles (43.1% of all the pro-files) show the Skills & Expertise field.
In this study, we adopt only these profiles in all our experiments.As a result, we get 6,863 skills in total, among which 6,299 skills (91.8% of them) appear less than 10times.
Among the remaining 564 skills, we select top 10 frequently occurring skills as the candidatepersonal skills in this study (Since the remaining 554 skills only appear less than 250 times in total, it isdifficult to build an effective classifier for them).
Table 1 illustrates the statistics.Skill Number RatioSemiconductors 948 0.298IC 369 0.116Thin Films 328 0.103Characterization 326 0.102CMOS 311 0.098Matlab 287 0.090Microsoft Office 283 0.089Manufacturing 278 0.087Design of Experiments 262 0.082Semiconductor Industry 250 0.079Table 1: The distribution of the candidate personal skillsFrom Table 1, we can see that the skill distribution in the personal profiles is asymmetric.
For example,the Semiconductor skill occurs about 1,000 times, taking 29.8%, while the Semiconductor Industry skilloccurs 250 times only, taking 7.9%.4 Problem Definition and AnalysisBefore presenting our approach for skill inference, we first give the definition of the problem, and conveya series of discoveries we observed from the data.5224.1 Problem DefinitionWe first introduce some necessary definitions and then formulate of the problem.Definition 1: Skill inference.
In principle, we cast skill inference as a skill prediction problem.
Sinceone person might have several skills, we build several vectors for a person and each vector is designed todetermine whether the corresponding skill is appropriate for the person or not (?Positive?
means that theperson has the target skill, whereas ?Negative?
stands for the opposite).
Note that the number of vectorsfor a person is equal to the number of candidate skills.
For example, suppose we have m persons andn candidate skills in the dataset, we totally build vectors to represent if these skills are attached in thesepersons?
profiles.Definition 2: Textual information.
We use texts of Summary and Experience as the textual informationfor our research.
Texts of Summary and Experience are unstructured information, while texts of Skills& Expertise are structured information.
However, some skills in the Skill & Expertise fields may not bementioned in the Summary and Experience fields.Definition 3: Personal connections.
We can explicitly extract four kinds of personal relationshipsbetween two persons from the Education and Experience fields, as follows:?
co major, which denotes that two persons have the same major at school?
co univ, which denotes that two persons graduated from the same university?
co title, which denotes that two persons have the same title in a corporation.?
co corp, which denotes that two persons work in the same corporation.Definition 4: Skill connections.
We extract skill connections from same person.
That is, if two vectorsare from the same person with different skills, we consider these two vectors share skill connections (e.g.John has IC and Thin Films skills).Learn task: Given the textual information of each profile, the personal connections between pro-files, and skill connections of skill from same persons, the goal is to infer the skill through the aboveinformation.To learn the skill inference model, there are several requirements.
First, the skills of persons are relatedto multiple factors, e.g., network structure, personal connections, and skill connections, it is important tofind a unified model which is able to incorporate all the information together.
Second, the algorithm tolearn the inference model should be efficient.
In practice, the scale of the social network might be verylarge.4.2 Statistics and ObservationsIn the following, we give some statistics and observations on personal and skill connections.Figure 1: The statistic of personal connection edges in our datasetStatistics of personal connections: Figure 1 gives the statistics of personal connection edges.
Itshows that with 3,182 profiles, there exist 332,390 personal connection edges.
Besides, among all the523four relations, co major, co unvi, co title, and co corp occupy 11.7%, 40.0%, 17.7% and 30.6% respec-tively.Observations of skills connections: To validate the tendency of a person sharing similar skills, weuse PMI (Point-wise Mutual Information) to measure the co-occurrence between two skills.
As a popularway to measure the co-occurrence between a pair (Turney, 2002), PMI is calculated as follows:PMI(i, j) = log(NP (i&j)P (i)P (j))(1)N is the number of profiles, P (i&j) denotes the probability of the skills (i.e., i and j) co-occurrence ina person?s profile, while P (i) denotes the probability of the skill i appearing in a person?s profile.Skill i Skill j PMIC COMS 1.711Thin Films Characterization 1.624Thin Films Design of Experiments 1.543Semiconductor Industry IC 1.345Semiconductor Industry Design of Experiments 1.345IC Microsoft Office -2.390CMOS Microsoft Office -2.627Semiconductor Industry Matlab -3.112Average PMI score 0.190Table 2: The top-5 and bottom-3 co-occurred skill pairs with their PMI scoresTable 2 lists the top-5 and bottom-3 co-occurred skill pairs with their PMI scores, together with theaverage PMI score.
From this table, we can see that if two skills are related, e.g., ?IC?
and ?CMOS?,these two skills tend to co-occur in one person?s profile, vice versa.5 Joint Prediction Factor Graph ModelIn this section, we propose a Joint Prediction Factor Graph (JPFG) model for learning and predicting theskills with personal and skill connection information besides local textual information.5.1 ModelWe formalize the problem of skill prediction using a pairwise factor graph model, and our basic idea ofdefining the correlations is to use different types of factor functions (i.e., personal connection factor, andskill connection factor).
Here, the objective function P?
(Y |X,G) is defined based on the joint probabilityof the factor functions, and the problem of collective skill inference model learning is cast as learningmodel parameters ?
that maximizes the joint probability of skills based on the input continuous dynamicnetwork.Since directly maximizing the conditional probability P?
(Y |X,G) is often intractable, we factorizethe ?global?
probability as a product of ?local?
factor functions, each of which depends on a subset ofthe variables in the graph (Tang et al., 2013).
In particular, we use three kinds of functions to representthe local textual information of the vector (local textual attribute function), personal connection informa-tion between vectors (personal connection factor) and skill connection information between skills (skillconnection factor), respectively.
We now briefly introduce the ways to define the above three functions.Local textual attribute functions f(xij, yi)j: It denotes the attribute value associated with eachperson i.
Here, we define the local textual attribute as a feature (Lafferty et al., 2001) and accumulate allthe attribute functions to obtain local entropy for a person:1Z1exp(?i?k?kfk(xik, yi))(2)524Where ?kis the function weight, representing the influence degree of the attribute k. For simplicity, weuse word unigrams of a text as the basic textual attributes.Personal connection factor function g(yi, yj) : For the personal correlation factor function, wedefine it through the pairwise network structure.
That is, if a person i and another person j have apersonal relationship, we define a personal connection factor function as follows:g(yi, yj) = exp{?ij(yi?
yj)2}(3)The personal connections are defined Section 4, i.e., co major, co univ, co title, and co corp. We definethat if two persons have at least one personal connection edge, they have a personal relationship.
Inaddition, ?ijis the weight of the function, representing the influence degree of i on j.Skill connection factor function h(yi, yj): For the skill connection factor function, we define itthrough the pairwise network structure.
That is, if vector i and vector j are from the same person withdifferent skills, we define their skill connection influence factor function as follows:h(yi, yj) = exp{?ij(yi?
yj)2}(4)Where ?ijis the function weight, representing the influence degree of i on j.By the above defined correlations, we can construct the graphical structure in the factor model.
Ac-cording to the Hammersley-Clifford theorem (Hammersley and Clifford, 1971), we integrate all the factorfunctions and obtain the following log-likelihood objective function:L(?)
= log?P (Y |X,G)=1Z1?i?k?kfk(xik, yi)+1Z2?i?j?NB(i)exp{?ij(yi?
yj)2}+1Z3?i?k?SAME(i)exp{?ik(yi?
yk)2}?
logZ(5)Where (i, j) is a pair derived from the input network, Z = Z1Z2Z3is a normalization factor and?
= ({?
}, {?
}, {?})
indicates a parameter configuration, NB(i) denotes the set of social relationshipneighbors nodes of i (personal connection), and SAME(i) denotes the set of the node with the sameperson of i (skill connection).5.2 Learning and PredictionModel Learning: Learning of the factor model is to find the best configuration for free parameters?
= ({?
}, {?
}, {?})
that maximizes the log likelihood objective function L(?).?
?= argmaxL(?)
(6)As the network structure in a social network can be arbitrary (e.g.
possible of containing cycles), weuse the Loopy Belief Propagation (LBP) algorithm (Tang et al., 2011a) to approximate the marginaldistribution.
To explain how we learn the parameters, we can get the gradient of each ?kwith regard tothe objective function (Eq.
5), taking ?
(the weight of the personal connection factor function g(yi, yj))as an example:L(?
)?k= E[g(i, j)] + E?kP (Y |X,G)[g(i, j)] (7)Where E[g(i, j)] is the expectation of factor function g(i, j) given the data distribution in the inputnetwork and E?kP (Y |X,G)[g(i, j)] represents the expectation under the distribution learned by the model,i.e., P (yi|X,G) .With the marginal probabilities, the gradient is obtained by summing up all triads (similar gradientscan be derived for parameter ?kand ?ij).
It is worth noting that we need to perform the LBP process525twice in each iteration.
The first run to estimate the marginal distribution of unknown variables yi=?
andthe second one is to estimate the marginal distribution over all pairs.
Finally, with the obtained gradient,we update each parameter with a learning rate ?.Skill Prediction: We can see that in the learning process, additional loopy belief propagation is usedto infer the label of unknown relationships.
After learning, all unknown skills are assigned with labelsthat maximize the marginal probabilities (Tang et al., 2011b), i.e.,Y?= argmaxL(Y |X,G, ?)
(8)6 ExperimentationIn this section, we first introduce the experimental setting, and then evaluate the performance of ourproposed JPFG model with both personal and skill connection information.6.1 Experimental SettingAs described in Section 3, the experimental data are collected from LinkedIn.com.
With top 10 frequentlyused skills as candidate skills in all our experiments, we randomly select 2,000 profiles as training dataand 1,000 profiles as testing data.Though positive and negative samples of each skill are imbalanced (In this paper, the number of thenegative samples is much larger than that of the positive samples), we select balanced testing and trainingsamples for each skill.
Following models are implemented and compared.?
Keyword, for each profile, we consider the profile attached with the skill, only if the text of the skillappears on the profile article with textual information.?
MaxEnt, which first uses local textual information as features to train a maximum entropy (ME)classification model, and then employs the classification model to predict the skills in the testingdata set.
The ME algorithm is implemented with the mallet toolkit1.?
JPFG, exactly our proposed model, which jointly predicts personal skills with local textual infor-mation, personal connection and skill connection.For performance evaluation, we adopt Precision (P.), Recall (R.) and F1-Measure (F1.
).6.2 Comparison with BaselinesOur first group of experiments is to investigate whether the JPFG model is able to improve skill inferenceand whether the personal and skill connections are useful.
The experimental results are shown in Table3.
From the table we can find that as some skills may not be mentioned on the Summary and Experiencefields directly, the performance of the Keyword approach is far from satisfaction.
As incorporatingpersonal and skill connections, the JPFG model yields a much higher F1-measure, which improves theperformance with about 6.8% gain than the MaxEnt model.6.3 Performance of JPFG with Different Training Data SizesAfter we evaluate the effective of the JPFG model with the large-scale training data, we carry out ex-periments to test the effect of the JPFG model with different training data sizes.
Experiment results areshown in Figure 3.
It shows that the JPFG model with both personal and skill connections always out-perform the two baseline models.
Impressively, our JPFG model using 20% training data outperformsMaxEnt using 100% training data.1http://mallet.cs.umass.edu/526Figure 2: The performance of different methods for skill inferenceFigure 3: The performance of JPFG with different training data sizes6.4 Connections Contribution AnalysisPersonal connections and skill connections can be also used to build the factor graph models to infer theskills.
We therefore want to compare our JPFG model with the factor graph model with only considerthe personal connections or skill connections, and analysis the contribution of each kinds of connection.Specifically, MaxEnt-Personal employs the personal connections as additional features incorporated withtextual features to build the maximum entropy classification.
FGM-Personal is a simplified version ofthe JPFG model, which only employs textual attribute functions and personal connection factor functionsto build the factor graph model.
Likewise, FGM-Skill only employs textual attribute functions and skillconnection factor functions to build the factor graph model.
Table 3 shows the experiment results.System P. R. F1.MaxEnt 0.744 0.797 0.769MaxEnt-Personal 0.758 0.812 0.783FGM-Personal 0.765 0.817 0.790FGM-Skill 0.704 0.967 0.815JPFG 0.780 0.905 0.837Table 3: The contribution of connectionsFrom Table 3, we can observe that, 1) Both FGM-Personal and FGM-Skill outperform the baseline527MaxEnt approach.
It shows that both personal connections and skill connections are helpful for skillinference; 2) MaxEnt-Personal and FGM-Personal outperform the baseline MaxEnt approach, it showthat personal connections are helpful for inferring skills, and as considering the global optimization,FGM-Personal is more effective; 3) FGM-Skill built on the skill connections is more effective thanMaxEnt-Personal and FGM-Personal, it show that skill connections are more useful than personal con-nections; 4) JPFG model outperforms both FGM-Personal and FGM-Skill, it suggests that we shouldincorporate both personal and skill connections to the factor graph model when we infer the skills fromprofile.7 ConclusionIn this study, we propose a novel task named personal skill inference, which aims to determine whether aperson takes a specific skill or not.
To address this task, we propose a joint prediction factor graph modelwith help of both personal and skill connections besides local textual information.
Evaluation on a large-scale dataset shows that our joint model performs much better than several baselines.
In particular, itshows that the performance on personal skill inference can be greatly improved by incorporating skillconnection information.The general idea of exploring personal and skill connections to help predict people?s skills representsan interesting research direction in social networking, which has many potential applications.
Besides,as skill information of a person is normally incomplete and fuzzy, how to better infer personal skills withweakly labeled information is challenging.AcknowledgementsThis research work is supported by the National Natural Science Foundation of China (No.
61273320,No.
61331011, and No.
61375073), National High-tech Research and Development Program of China(No.
2012AA011102), Zhejiang Provincial Natural Science Foundation of China (No.
LY13F020007),the Humanity and Social Science on Young Fund of the Ministry of Education (No.
12YJC630170).We thank Dr. Jie Tang and Honglei Zhuang for providing their software and useful suggestions aboutPGM.
We thank Prof. Deyi Xiong for helpful discussions, and we acknowledge Dr. Xinfang Liu, andYunxia Xue for corpus construction and insightful comments.
We also thank anonymous reviewers fortheir valuable suggestions and comments.ReferencesBalog K and M. Rijke.
2007.
Determining Expert Profiles (With an Application to Expert Finding).
In Proceedingsof IJCAI-07.Campbell C, P. Maglio, A. Cozzi, and B. Dom.
2003.
Expertise Identification Using Email Communications.
InProceedings of CIKM-03.Dong Y., J. Tang, S. Wu, J. Tian, N. Chawla, J. Rao, and H. Cao.
2012.
Link Prediction and Recommendationacross Heterogeneous Social Networks.
In Proceedings of ICDM-12.Guo W., H. Li, H. Ji, and M. Diab.
2013.
Linking Tweets to News: A Framework to Enrich Short Text Data inSocial Media.
In Proceedings of ACL-13 .Guy I., N. Zwerdling, I. Ronen, D. Carmel, and E. Uziel.
2010.
Social Media Recommendation based on Peopleand Tags.
In Proceedings of SIGIR-10 .Hammersley J. and P. Clifford.
1971.
Markov Field on Finite Graphs and Lattices, Unpublished manuscript.Helic D. and M. Strohmaier.
2011.
Building Directories for Social Tagging Systems.
In Proceedings of CIKM-2011.Lafferty J, A. McCallum, and F. Pereira.
2001.
Conditional Random Fields: Probabilistic Models for Segmentingand Labeling Sequence Data.
In Proceedings of ICML-01.528Lampos V., D. Preo?iuc-Pietro, and T. Cohn.
2013.
A User-centric Model of Voting Intention from Social Media.In Proceedings of ACL-13.Lappas T., K. Punera, and T. Sarlos.
2011.
Mining Tags Using Social Endorsement Networks.
In Proceedings ofSIGIR-11.Li H., Z. Liu, and M. Sun.
2012.
Random Walks on Context-Aware Relation Graphs for Ranking Social Tags.
InProceedings of COLING-12.Liu Z., X. Chen, and M. Sun.
2011.
A Simple Word Trigger Method for Social Tag Suggestion.
In Proceedings ofEMNLP-2011.Liu Z., C. Tu, and M. Sun.
2012.
Tag Dispatch Model with Social Network Regularization for Microblog User TagSuggestion.
In Proceedings of COLING-12.Lu Y., and P. Tsaparas, A.
2010.
Ntoulas and L. Polanyi.
2010.
Exploiting Social Context for Review QualityPrediction.
In Proceedings of WWW-10.Luo T., J. Tang, J. Hopcroft, Z. Fang, and X. Ding.
2013.
Learning to Predict Reciprocity and Triadic Closure inSocial Networks.
ACM Transactions on Knowledge Discovery from Data.
vol.7(2), Article No.
5.Murphy K., Y. Weiss, and M. Jordan.
1999.
Loopy Belief Propagation for Approximate Inference: An EmpiricalStudy.
In Proceedings of UAI-99 .Ohkura T., Y. Kiyota and H. Nakagawa.
2006.
Browsing System for Weblog Articles based on Automated Folk-sonomy.
In Proceedings of WWW-06.Si X., Z. Liu, and M. Sun.
2010.
Explore the Structure of Social Tags by Subsumption Relations.
In Proceedingsof COLING-10.Soboroff I., A. Vries and N. Craswell.
2006.
Overview of the TREC 2006 Enterprise Track In Proceedings ofTREC-06.Turney P. 2002.
Thumbs up or Thumbs down?
Semantic Orientation Applied to Unsupervised Classification ofreviews.
In Proceedings of ACL-02.Tan C., L. Lee, J. Tang, L. Jiang, M. Zhou, and P. Li.
2011.
User-Level Sentiment Analysis Incorporating SocialNetworks.
In Proceedings of KDD-11.Tang W., H. Zhuang, and J. Tang.
2011a.
Learning to Infer Social Ties in Large Networks.
In Proceedings ofECML/PKDD-11.Tang J., Y. Zhang, J.
Sun, J. Rao, W. Yu, Y. Chen, and A. Fong.
2011b.
Quantitative Study of Individual EmotionalStates in Social Networks.
IEEE Transactions on Affective Computing.
vol.3(2), Pages 132-144.Tang J., S. Wu, J.
Sun, and H. Su.
2012.
Cross-domain Collaboration Recommendation.
In Proceedings of KDD-12.Tang J., S. Wu, and J.
Sun.
2013.
Confluence: Conformity Influence in Large Social Networks.
In Proceedings ofKDD-13.Xing E, M. Jordan, and S. Russell.
2003.
A Generalized Mean Field Algorithm for Variational Inference in Expo-nential Families.
In Proceedings of UAI-03.Yang S., B.
Long, A. Smola, N. Sadagopan, Z. Zheng, and H. Zha.
2011a.
Like like alike - Joint Friendship andInterest Propagation in Social Networks.
In Proceedings of WWW-11.Yang Z., K. Cai, J. Tang, L. Zhang, Z. Su, and J. Li.
2011b.
Social Context Summarization.
In Proceedings ofSIGIR-11.Zhang J., J. Tang, and J. Li.
2007a.
Expert Finding in A Social Network.
In Proceedings of the Twelfth DatabaseSystems for Advanced Applications (DASFAA-2007).Zhang J., M. Ackerman, and L. Adamic.
2007b.
Expertise Networks in Online Communities: Structure and Algo-rithms.
In Proceedings of TREC-07.Zhuang H, J. Tang, W. Tang, T. Lou, A. Chin, and X. Wang.
2012.
Actively Learning to Infer Social Ties.
InProceedings of Data Mining and Knowledge Discovery (DMKD-12), vol.25 (2), pages 270-297.529
