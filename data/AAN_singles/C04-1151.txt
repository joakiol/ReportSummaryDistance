Multi-level Bootstrapping for Extracting Parallel Sentences from aQuasi-Comparable CorpusPascale Fung and Percy CheungHuman Language Technology Center,Department of Electrical & Electronic Engineering, HKUST,Clear Water Bay, Hong Kong{pascale,eepercy}@ee.ust.hkAbstractWe propose a completely unsupervisedmethod for mining parallel sentences fromquasi-comparable bilingual texts whichhave very different sizes, and whichinclude both in-topic and off-topicdocuments.
We discuss and analyzedifferent bilingual corpora with variouslevels of comparability.
We propose thatwhile better document matching leads tobetter parallel sentence extraction, bettersentence matching also leads to betterdocument matching.
Based on this, we usemulti-level bootstrapping to improve thealignments between documents, sentences,and bilingual word pairs, iteratively.
Ourmethod is the first method that does notrely on any supervised training data, suchas a sentence-aligned corpus, or temporalinformation, such as the publishing date ofa news article.
It is validated byexperimental results that show a 23%improvement over a method withoutmultilevel bootstrapping.1 IntroductionSentence-aligned parallel corpus is an importantresource for empirical natural language tasks suchas statistical machine translation and cross-lingualinformation retrieval.
Recent work has shown thateven parallel sentences extracted from comparablecorpora helps improve machine translationqualities (Munteanu and Marcu, 2004).
Manydifferent methods have been previously proposedto mine parallel sentences from multilingualcorpora.
Many of these algorithms are described indetail in (Manning and Sch?tze, 1999, Dale et al,2000, Veronis 2001).
The challenge of these tasksvaries according to the degree of comparability ofthe input multilingual documents.
Existing workextract parallel sentences from parallel, noisyparallel or comparable corpora based on theassumption that parallel sentences should besimilar in sentence length, sentence order and bi-lexical context.
In our work, we try to find parallelsentences from a quasi-comparable corpus, and wefind that many of assumptions in previous work areno longer applicable in this case.
Alternatively, wepropose an effective, multi-level bootstrappingapproach to accomplish this task (Figure 1).Figure1.
Multi-level bootstrapping for parallelsentence extractionExtraction of matching bilingual segments fromnon-parallel data has remained a challenging taskafter almost a decade.
Previously, the author andother researchers had suggested that bi-lexicalinformation based on context can still be used tofind correspondences between passages, sentences,or words, in non-parallel, comparable texts of thesame topic (Fung and McKeown 1995, Rapp 1995,Grefenstette 1998, Fung and Lo 1998, Kikui 1999).More recent works on parallel sentence extractionfrom comparable data align documents first, beforeextracting sentences from the aligned documents(Munteanu and Marcu, 2002, Zhao and Vogel,2002).
Both work used a translation model trainedfrom parallel corpus and adaptively extract moreparallel sentences and bilingual lexicon in thecomparable corpus.
In Zhao and Vogel (2002), thecomparable corpus consists of Chinese and Englishversions of new stories from the Xinhua Newsagency.
Munteanu and Marcu (2002) usedunaligned segments from the French-EnglishHansard corpus and finds parallel sentences amongthem.
Zhao and Vogel (2002) used a generativestatistical machine translation alignment model,Munteanu and Marcu (2002) used suffix trees-based alignment model, and Munteanu and Marcu(2004) used a maximum entropy based classifiertrained from parallel corpus to extract matchingsentences from a comparable corpus of Arabic andEnglish news.
The comparable corpora used in allthese work consist of documents on the same topic.Our challenge is to find matching bilingualsentences from documents that might or might notbe on the same topic.2 Bilingual Sentence AlignmentThere have been various definitions of the term?parallel corpora?
in the research community.
Inthis paper, we compare and analyze differentbilingual corpora, ranging from the parallel, noisyparallel, comparable, to quasi-comparable.A parallel corpus is a sentence-aligned corpuscontaining bilingual translations of the samedocument.
The Hong Kong Laws Corpus is aparallel corpus with sentence level alignment; andis used as a parallel sentence resource for statisticalmachine translation systems.
There are 313,659sentence pairs in Chinese and English.
Alignmentof parallel sentences from this type of database hasbeen the focus of research throughout the lastdecade and can be accomplished by many off-the-shelf, publicly available alignment tools.A noisy parallel and comparable corpus containsnon-aligned sentences that are nevertheless mostlybilingual translations of the same document.Previous works have extracted bilingual wordsenses, lexicon and parallel sentence pairs fromnoisy parallel corpora (Fung and McKeown 1995,Fung and Lo 1998).
Corpora such as the HongKong News are in fact rough translations of eachother, focused on the same thematic topics, withsome insertions and deletions of paragraphs.Another type of comparable corpus is one thatcontains non-sentence-aligned, non-translatedbilingual documents that are topic-aligned.
Forexample, newspaper articles from two sources indifferent languages, within the same window ofpublished dates, can constitute a comparablecorpus.
Note that many existing algorithms forsentence alignment from comparable corpus are, infact, methods for noisy parallel corpus.On the other hand, a quasi-comparable corpus isone that contains non-aligned, and non-translatedbilingual documents that could either be on thesame topic (in-topic) or not (off-topic).
TDT3Corpus is a good source of truly non-parallel andquasi-comparable corpus.
It contains transcriptionsof various news stories from radio broadcasting orTV news report from 1998-2000 in English andChinese.
In this corpus, there are about 7,500Chinese and 12,400 English documents, coveringmore than 60 different topics.
Among these, 1,200Chinese and 4,500 English documents aremanually marked as being in-topic.
The remainingdocuments are marked as off-topic as they areeither only weakly relevant to a topic or irrelevantto all topics in the existing documents.
From thein-topic documents, most are found to becomparable.
A few of the Chinese and Englishpassages are almost translations of each other.Nevertheless, the existence of considerable amountof off-topic document gives rise to more variety ofsentences in terms of content and structure.Overall, the TDT 3 corpus contains 110,000Chinese sentences and 290,000 English sentences.A very small number of the bilingual sentences aretranslations of each other, while some others arebilingual paraphrases.
In this paper, we describe amethod to extract translated and paraphrasedbilingual sentence pairs from this quasi-comparable corpus.2.1 Comparing bilingual corporaWe explore the usability of different bilingualcorpora for the purpose of multilingual naturallanguage processing.
We argue that the usability ofbilingual corpus depends how well the sentencesare aligned.
To quantify this corpus characteristic,we propose using a lexical alignment scorecomputed from the bilingual word pairs distributedthroughout the bilingual sentence pairs.We first identify bilingual word pairs that appear inthe aligned sentence pairs by using a bilinguallexicon (bilexicon).
Lexical alignment score is thendefined as the sum of the mutual information scoreof all word pairs that appear in the corpus:?==),(),()()(),(),(ec WWallececececWWSSWfWfWWfWWSwhere f(Wc,We) is the co-occurrence frequency ofbilexicon pair (Wc,We) in the aligned sentence pairs.f(Wc) and f(We) are the occurrence frequencies ofChinese word Wc and English word We, in thebilingual corpus.Table 1 shows the lexical alignment scores ofparallel sentences extracted from a parallel corpus(Hong Kong Law), a comparable noisy parallelcorpus (Hong Kong News), and a non-parallel,quasi-comparable corpus (TDT 3).
We can see thatthe scores are in direct proportion to the parallel-ness or comparability of the corpus.Corpus Parallel Comparable Quasi-ComparableBilexiconscore359.1 253.8 160.3Table 1: Bilingual lexicon scores of differentcorpora2.2 Comparing alignment assumptionsAll previous work on sentence alignment fromparallel corpus makes use of one or multiple of thefollowing nine (albeit imperfect) assumptions, asdescribed in the literature (Somers 2001, Manning& Sch?tze, 1999), and summarized as below:1.
There are no missing translations in thetarget document;2.
Sentence lengths: a bilingual sentence pairare similarly long in the two languages;3.
Sentence position: Sentences are assumedto correspond to those roughly at the sameposition in the other language.4.
Bi-lexical context: A pair of bilingualsentences which contain more words thatare translations of each other tend to betranslations themselves.For noisy parallel corpora without sentencedelimiters, assumptions made previously forbilingual word pairs are as follows:5.
Occurrence frequencies of bilingual wordpairs are similar;6.
The positions of bilingual word pairs aresimilar;7.
Words have one sense per corpus;8.
Following 7, words have a singletranslation per corpus;9.
Following 4, the sentence contexts in twolanguages of a bilingual word pair aresimilar.Different sentence alignment algorithms based onboth sentence and lexical information can be foundin Manning and Sch?tze (1999), Wu (2000), Daleet al (2001), Veronis (2002), and Somers (2002).These methods have also been applied recently in asentence alignment shared task at NAACL 20031.We have learned that as bilingual corpora becomeless parallel, it is better to rely on informationabout word translations rather than sentence lengthand position.For comparable corpora, previous bilingualsentence or word pair extraction works are basedsoly on bilexical context assumption (Fung &McKeown 1995, Rapp 1995, Grefenstette 1998,Fung and Lo 1998, Kikui 1999, Barzilay andElhadad 2003, Masao and Hitoshi 2003, Kenji andHideki 2002).
Similarly, for quasi-comparablecorpora, we cannot rely on any other sentence levelor word level statistics but the bi-lexical contextassumption.
We also postulate one additionalassumption:10.
Seed parallel sentences: Documents andpassages that are found to contain at leastone pair of parallel sentences are likely tocontain more parallel sentences.3 Our approach: Multi-level BootstrappingExisting algorithms (Zhao and Vogel, 2002,Munteanu and Marcu, 2002) for extracting parallelsentences from comparable documents seem tofollow the 2 steps: (1) extract comparabledocuments (2) extract parallel corpus fromcomparable documents.
Other work onmonolingual, comparable sentence alignment by(Barzilay and Elhadad 2003) also supports that it isadvantageous to first align comparable passagesand then align the bilingual sentences within thealigned passages.
The algorithms proposed byZhao and Vogel, and by Munteanu and Marcudiffer in the training and computation of documentsimilarity scores and sentence similarity scores.Examples of document similarity computationinclude counting word overlap and cosinesimilarity.
Examples of sentence similaritycomputation include word overlap count, cosinesimilarity, and classification scores of a binaryclassifier trained from parallel corpora, generativealignment classifier.
In our work, we use simplecosine similarity measures and we dispense withusing parallel corpora to train an alignmentclassifier.
In addition, we do not make any1 http://www.cs.unt.edu/~rada/wpt/document position assumptions since suchinformation is not always available.In addition to assumption 10 on the seed sentencepairs, we propose that while better documentmatching leads to better parallel sentenceextraction, better sentence matching leads to betterbilingual lexical extraction, better bilingual lexiconyields better glossing words, which improve thedocument and sentence match.
We can iterate thiswhole process for incrementally improved resultsusing a multi-level bootstrapping algorithm.
Figure2 outlines the algorithm in more detail.
In thefollowing sections 3.1-3.4, we describe the fourdifferent steps of our algorithm.3.1 Extract comparable documentsThe aim of this step is to extract the Chinese-English documents pairs that are comparable, andtherefore should have similar term distributions.The documents are word segmented with theLanguage Data Consortium (LDC) Chinese-English dictionary 2.0.
The Chinese document isthen glossed using all the dictionary entries.Multiple translations of a Chinese word isdisambiguated by looking at the context of thesentences this word appears in (Fung et al, 1999).Both the glossed Chinese document and theEnglish document are then represented in wordvectors, with term weighting.
We evaluateddifferent combinations of term weighting of eachword in the corpus: term freuency (tf), inversedocument frequency (idf), tf.idf, the product of afunction of tf and idf.
The?documents?
here are sentences.
We find thatusing idf  alone gives the best sentence pair rank.This is due to the fact that frequencies of bilingualword pairs are not comparable in a non-parallel,quasi-comparable corpus.1.
Extract comparable documentsFor all documents in the comparable corpus D:a.
Gloss Chinese documents using the bilingual lexicon (Bilex);b.
For every pair of glossed Chinese and English documents, compute document similarity=>S(i,j);c. Obtain all matched bilingual document pairs whose S(i,j)> threshold1=>C2.
Extract parallel sentencesFor each document pair in C:a.
For every pair of glossed Chinese sentence and English sentence, compute sentence similarity=>S2(i,j);b.
Obtain all matched bilingual sentence pairs whose S2(i,j)> threshold2=>C23.
Update bilingual lexicon with unknown word translationsFor each bilingual word pair in C2;a. Compute correlation scores of all bilingual word pairs =>S3(i,j);b.
Obtain all bilingual word pairs previously unseen in Bilex and whose S3(i,j)> threshold3=>C3and update Bilex;c. Compute alignment score=>S4; if (S4> threshold4) return C3 otherwise continue;4.
Update comparable document pairsa.
Find all pairs of glossed Chinese and English documents which contain parallel sentences(anchor sentences) from C2=>C4;b.
Expand C4 by finding documents similar to each of the document in C4;c. C:=C4;d. Goto 2;Figure 2.
Multi-level bootstrapping algorithmPair-wise similarities are calculated for all possibleChinese-English document pairs, and bilingualdocuments with similarities above a certainthreshold are considered to be comparable.
Forquasi-comparable corpora, this documentalignment step also serves as topic alignment.3.2 Extract parallel sentencesIn this step, we extract parallel sentences from thematched English and Chinese documents in theprevious section.
Each sentence is againrepresented as word vectors.
For each extracteddocument pair, the pair-wise cosine similarities arecalculated for all possible Chinese-Englishsentence pairs.
Sentence pairs above a set thresholdare considered parallel and extracted from thedocuments.We have only used one criterion to determine theparallel-ness of sentences at this stage, namely thenumber of words in the two sentences that aretranslations of each other.
Further extensions arediscussed in the final section of this paper.3.3  Update bilingual lexiconStep 3 updates the bilingual lexicon according tothe intermediate results of parallel sentenceextraction.The occurrence of unknown words can adverselyaffect parallel sentence extraction by introducingerroneous word segmentations.
This is particularlynotorious for Chinese to English translation.
Forexample, ??
?
??
(?Olympic Committee?)
is notfound in the bilingual lexicon so the Chinese issegmented into three separate words in the originalcorpus, each word with an erroneous English gloss.Note that this occurs for unknown words in general,not just transliterated words.Hence, we need to refine bi-lexicon by learningnew word translations from the intermediate outputof parallel sentences extraction.
In this work, wefocus on learning translations for name entitiessince these are the words most likely missing inour baseline lexicon.
The Chinese name entities areextracted with the system described in (Zhai et al2004).
New bilingual word pairs are learned fromthe extracted sentence pairs based on (Fung and Lo98) as follows:1.
Extract new Chinese name entities (Zhai etal 2004);2.
For each new Chinese name entity:z Extract all sentences that it appears in,from the original Chinese corpus, andbuild a context word vector;z For all English words, collect allsentences it appears in from theoriginal corpus, and build the contextvectors;z Calculate the similarity  between theChinese word  and each of the Englishword vectors???
?=jjijjAECiwECwEwCwECSim ji)()(.
)(),( )(KKwhere A is the aligned bilexicon pairbetween the two word vector.z Rank the English candidate accordingto the similarity score.Sometimes a Chinese named entity might betranslated into a multi-word English collocation.
Insuch a case, we search for and accept the Englishcollocation candidate that does appear in theEnglish documents.Below are some examples of unknown nameentities that have been translated (or transliterated)correctly:????.
Augusto Pinochet (transliteration)???
Space Shuttle Endeavor (translation)???
Olympic Committee (translation)????
Benjamin Netanyahu (transliteration)3.4 Update comparable documentsThis step replaces the original corpus by the set ofdocuments that are found to contain at least onepair of parallel sentences.
Other documents that arecomparable to this set are also included since webelieve that even though they were judged to benot similar at the document level, they might stillcontain one or two parallel sentences.
Thealgorithm then iterates to refine documentextraction and parallel sentence extraction.
Analignment score is computed in each iteration,which counts, on average, how many knownbilingual word pairs actually co-occur in theextracted ?parallel?
sentences.
The alignment scoreis high when these sentence pairs are reallytranslations of each other.4 EvaluationWe evaluate our algorithm on a quasi-comparablecorpus of TDT3 data, which contains various newsstories transcription of radio broadcasting or TVnews report from 1998-2000 in English andChinese Channels.4.2.
Baseline methodThe baseline method shares the samepreprocessing, document matching and sentencematching with our proposed method.
However, itdoes not iterate to update the comparabledocument set, the parallel sentence set, or thebilingual lexicon.Human evaluators then manually check whetherthe matched sentence pairs are indeed parallel.
Theprecision of the parallel sentences extracted is 43%for the top 2,500 pairs, ranked by sentencesimilarity scores.4.3 Multi-level bootstrappingThere are 110,000 Chinese sentences and  290,000English sentences,  which lead to more than 30billion  possible sentence pairs.
Few of thesentence pairs turn out to be parallel, but many areparaphrasing sentence pairs.
For example, in thefollowing extracted sentence pair,?
??
?
??
???
?
??
??
?
(Hun Sen becomes Cambodia ' s soleprime minister)?
Under the agreement, Hun Sen becomesCambodia ' s sole prime minister .the English sentence has the extra phrase ?underthe agreement?.The precision of parallel sentences extraction is67% for the top 2,500 pairs using our method,which is 24% higher than the baseline.
In addition,we also found that the precision of parallelsentence pair extraction increases steadily overeach iteration, until convergence.For another evaluation, we use the bilingual lexicalscore as described in Section 2.1 again as ameasure of the quality of the extracted bilingualsentence pairs from the parallel corpus,comparable corpus, and quasi-comparable corpus.Word pairs common to all corpora are used in thelexical alignment score.
Table 2 shows that thequality of the extracted parallel sentences from thequasi-comparable corpus is similar to those fromnoisy parallel and comparable corpus, even thoughboth are understandably inferior in terms ofparallel-ness when compared to the manuallyaligned parallel corpus.
It is worth noting that thelexical alignment score for the extracted sentencepairs from the quasi-comparable corpus is similarto that for the comparable corpus.
This is becausewe must evaluate different corpora by using wordpairs that appear in all corpora.
This has eliminatedmany word pairs some of which are likely tocontribute significantly to the alignment score.Table 2: Lexical alignment scores of extractedparallel sentences, based on a common lexiconFigure 3 shows two pairs of parallel sentencesfrom a parallel corpus and a comparable corpus,showing that the latter are closer to bilingualparaphrases rather than literal translations.Parallel sentence from parallel corpus:??
??
??
???
??
??
??
????
?Chinese president Jiang_Zemin arrived inJapan today for a landmark state visit.Parallel sentence from comparablecorpus:?
??
??
??
??
??
??
??
?Mr Jiang is the first Chinese head of state tovisit the island country.Figure 3.
Example parallel sentences5 ConclusionWe explore the usability of different bilingualcorpora for the purpose of multilingual naturallanguage processing.
We compare and contrast anumber of bilingual corpora, ranging from theparallel, to comparable, and to non-parallel corpora.The usability of each type of corpus is thenevaluated by a lexical alignment score calculatedfor the bi-lexicon pair in the aligned bilingualsentence pairs.We compared different alignment assumptions formining parallel sentences from these differenttypes of bilingual corpora and proposed newassumptions for quasi-comparable corpora.
Bypostulating additional assumptions on seed parallelsentences of comparable documents, we propose amulti-level bootstrapping algorithm to extractuseful material, such as parallel sentences andbilexicon, from quasi-comparable corpora.
This isa completely unsupervised method.
Evaluationresults show that our approach achieves 67%accuracy and a 23% improvement from baseline.This shows that the proposed assumptions andalgorithm are promising for the final objective.
Thelexical alignment score for the comparablesentences extracted with our unsupervised methodis found to be very close to that of the parallelcorpus.
This shows that our extraction method iseffective.Corpus AlignmentmethodBilexiconalignment scoreParallelmanual 3.924949Comparable  DP on sentenceposition1.3685069Comparable Absolute sentenceposition1.0636631Quasi-comparableMulti-levelbootstrapping2.649668Quasi-comparableCosine similarity 1.507132The main contributions of our work lie in steps 3and 4 and in the iterative process.
Step 3 updatesthe bilingual lexicon from the intermediate resultsof parallel sentence extraction.
Step 4 replaces theoriginal corpus by the set of documents that arefound to contain parallel sentences.
The algorithmthen iterates to refine document extraction andparallel sentence extraction.
An alignment score iscomputed at each iteration, which counts, onaverage, how many known bilingual word pairsactually co-occur in the extracted parallelsentences.
The alignment score is high when thesesentence pairs are really translations of each other.By using the correct alignment assumptions, wehave demonstrated that a bootstrapping iterativeprocess is also possible for finding parallelsentences and new word translations fromcomparable corpus.6 AcknowledgementsThis work is partly supported by grants CERG#HKUST6206/03E and CERG#HKUST6213/02Eof the Hong Kong Research Grants Council.ReferencesRegina Barzilay and Noemie Elhadad, SentenceAlignment for Monolingual ComparableCorpora, Proc.
of EMNLP, 2003, Sapporo,Japan.Christopher D. Manning and Hinrich Sch?tze.Foundations of Statistical Natural LanguageProcessing.
The MIT Press.Robert Dale, Hermann Moisl, and Harold Somers(editors), Handbook of Natural LanguageProcessing.Pascale Fung and Kathleen Mckeown.
Findingterminology translations from non-parallelcorpora.
In The 5th Annual Workshop on VeryLarge Corpora.
pages 192--202, Hong Kong,Aug.
1997.
",Pascale Fung and Lo Yuen Yee.
An IR Approachfor Translating New Words from Nonparallel,Comparable Texts.
In COLING/ACL  1998Gale, W A and Kenneth W.Church.
A Program forAligning Sentences in Bilingual Corpora.Computatinal Linguistics.
vol.19 No.1 March,1993.Pascale Fung, Liu, Xiaohu, and Cheung, Chi Shun.Mixed-language Query Disambiguation.
InProceedings of ACL ?99, Maryland: June 1999Gregory Grefenstette, editor.
Cross-LanguageInformation Retrieval.
Kluwer AcademicPublishers, 1998.Hiroyuki Kaji, Word sense acquisition frombilingual comparable corpora, in Proceedings ofthe NAACL, 2003, Edmonton, Canada, pp 111-118.Genichiro Kikui.
Resolving translation ambiguityusing non-parallel bilingual corpora.
InProceedings of ACL99 Workshop onUnsupervised Learning in Natural LanguageDragos Stefan Munteanu, Daniel Marcu, 2002.Processing Comparable Corpora With BilingualSuffix Trees.
In Proceedings of the 2002Conference on Empirical Methods in NaturalLanguage Processing (EMNLP 2002).Dragos Stefan Munteanu, Daniel Marcu, 2004.Improved Machine Translation Performace viaParallel Sentence Extraction from ComparableCorpora.
In Proceedings of the HumanLanguage Technology and North AmericanAssociation for Computational LinguisticsConference (HLT/NAACL 2004).Reinhard Rapp.
Identifying word translations innon-parallel texts.
Proceedings of the 33rdMeeting of the Association for ComputationalLinguistics.
Cambridge, MA, 1995.
320-322Philip Resnik and Noah A. Smith.
The Web as aParallel Corpus.
Computational Linguistics29(3), pp.
349-380, September 2003.Frank Smadja.
Retrieving collocations from text:Xtract.
In Computational Linguistics, 19(1):143-177,1993Harold Somers.
Bilingual Parallel Corpora andLanguage Engineering.
Anglo-Indian workshop"Language Engineering for South-Asianlanguages" (LESAL), (Mumbai, April 2001).Jean Veronis (editor).
Parallel Text Processing:Alignment and Use of Translation Corpora.Dordrecht: Kluwer.
ISBN 0-7923-6546-1.
Aug2000.Dekai Wu.
Alignment.
In Robert Dale, HermannMoisl, and Harold Somers (editors), Handbookof Natural Language Processing.
415-458.
NewYork: Marcel Dekker.
ISBN 0-8247-9000-6.
Jul2000.Bing Zhao, Stephan Vogel.
ProcessingComparable Corpora With Bilingual SuffixTrees.
In Proceedings of the EMNLP 2002.Zhai, Lufeng, Pascale Fung.
Richard Schwartz,Marine Carpuat and Dekai Wu.
Using N-best listfor Named Entity Recognition from ChineseSpeech.
To appear in the Proceedings of theNAACL 2004.
