Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 314?318,Dublin, Ireland, August 23-24, 2014.IITP: A Supervised Approach for Disorder Mention Detection andDisambiguationUtpal Kumar Sikdar, Asif Ekbal and Sriparna SahaDepartment of Computer Science and EngineeringIndian Institute of Technology Patna, India{utpal.sikdar,asif,sriparna}@iitp.ac.inAbstractIn this paper we briefly describe our super-vised machine learning approach for dis-order mention detection system that wesubmitted as part of our participation inthe SemEval-2014 Shared task.
The maingoal of this task is to build a system thatautomatically identifies mentions of clini-cal conditions from the clinical texts.
Themain challenge lies due in the fact that thesame mention of concept may be repre-sented in many surface forms.
We developthe system based on the supervised ma-chine learning algorithms, namely Condi-tional Random Field and Support VectorMachine.
One appealing characteristics ofour system is that most of the features forlearning are extracted automatically fromthe given training or test datasets with-out using deep domain specific resourcesand/or tools.
We submitted three runs, andbest performing system is based on Condi-tional Random Field.
For task A, it showsthe precision, recall and F-measure valuesof 50.00%, 47.90% and 48.90%, respec-tively under the strict matching criterion.When the matching criterion is relaxed, itshows the precision, recall and F-measureof 81.50%, 79.70% and 80.60%, respec-tively.
For task B, we obtain the accuraciesof 33.30% and 69.60% for the relaxed andstrict matches, respectively.1 IntroductionThe SemEval-2014 Shared Task 7 is concernedwith the analysis of clinical texts, particularly fordisorder mention detection and disambiguation.This work is licensed under a Creative Commons At-tribution 4.0 International Licence.
Page numbers and pro-ceedings footer are added by the organisers.
Licence details:http://creativecommons.org/licenses/by/4.0/The purpose of this task is to enhance currentresearch in Natural Language Processing (NLP)methods used in the clinical domain.
The task isa continuation of the CLEF/eHealth ShARe 2013Shared Task.
In particular there were two specifictasks, viz.
(i).
Task A: To identify disorder men-tions from biomedicine domain and (ii) Task B:To classify each mention with respect to the Uni-fied Medical Language System (UMLS) ConceptUnique Identifier (CUI).
The task is challengingin the sense that the same mention of concept maybe represented in many surface forms and men-tion may appear in the different parts of texts.Some systems (Cogley et al., 2013; Zuccon et al.,2013; Tang et al., 2013; Cogley et al., 2013) areavailable for disorder mention detection.
Look-ing at the challenges and resources available atour hand we planned to adapt our existing system(Sikdar et al., 2013) for disorder mention detec-tion.
The original architecture was conceptualizedas part of our participation in the BioCreative-IVTrack-2 Shared Task on Chemical Compound andDrug Name Recognition.
Although our submit-ted system for SemEval-14 shared task is in linewith BioCreative-IV1, it has many different fea-tures and characteristics.We develop three systems (e.g.
Model-1:sikdar.run-0, Model-2: sikdar.run-1 and Model-3: sikdar.run-2) based on the popular supervisedmachine learning algorithms, namely ConditionalRandom Field (CRF) (Lafferty et al., 2001) andSupport Vector Machine (SVM) (Cortes and Vap-nik, 1995; Joachims, 1999).
The models were de-veloped by varying the features and feature tem-plates.
A baseline model is constructed by us-ing the UMLS MetaMap2tool.
During testingwe merge the development set with the train-ing set.
Evaluation results on test data with thebenchmark set up show the F-measure values of1www.biocreative.org/tasks/biocreative-iv/chemdner/2http://mmtx.nlm.nih.gov/31448.90%, 46.50% and 46.50%, respectively underthe strict criterion.
Under relaxed matching cri-terion the models show the F-measure values of80.60%, 78.20% and 79.60%, respectively.
Oursubmission for Task-B is simple in nature wherewe consider only those mentions that are also pre-dicted in the baseline model, i.e.
only the com-mon CUIs are considered.
It shows the accuraciesof 33.30%, 31.90% and 33.20%, respectively un-der strict matching criterion; and 69.60%, 69.60%and 69.10%, respectively under the relaxed match-ing criterion.2 MethodOur method for disorder mention detection fromclinical text is based on the supervised machinelearning algorithms, namely CRF and SVM.
Thekey focus was to develop a system that could beeasily adapted to other domains and applications.We submitted three runs defined as below:Model-1:sikdar.run-0: This is based on CRF,and makes use of the features as mentioned below.Model-2:sikdar.run-1: This model is built bytraining a SVM classifier with the same set offeatures as CRF.Model-3:sikdar.run-2: This model is constructedby defining a heuristics that looks at the outputsof both the models.
For given instance, if one ofthe models predicts it to belong to the categoryof candidate disorder mention then this is givenmore priority in assigning the class.
We observedperformance improvement on the development setwith this heuristic.We identify and implement different features,mostly without using any deep domain knowledgeor domain-specific external resources and/or tools.The features that are used to train the classifiers arebriefly described below:?
Context words: Surrounding words carry ef-fective information to identify disorder men-tion.
In our case we consider the previousthree and next three words as the features.?
MetaMapmatch: MetaMap is a widely usedtool that maps biomedical mention to theUMLS CUI3.
In UMLS, there are 11 seman-tic types denoting disorders.
These are Con-genital Abnormality, Acquired Abnormality,Injury or Poisoning, Pathologic Function,3http://www.nlm.nih.gov/research/umls/Disease or Syndrome, Mental or BehavioralDysfunction, Cell or Molecular Dysfunction,Experimental Model of Disease, AnatomicalAbnormality, Neoplastic Process and Signsand Symptoms.
The training set is passedthrough the MetaMap, and then we prepare alist of mentions that belong to the UMLS se-mantic types.
A feature is thereafter definedthat takes a value of 1 if the current token ap-pears in the list; otherwise the value becomes0.?
Part-of-Speech (PoS) Information: In thiswork, we use PoS information of the currenttoken as the feature.
PoS information wasextracted from the GENIA tagger4V2.0.2,which is a freely available resource.?
Root words: Stems or root words, whichare extracted form GENIA tagger V2.0.2, areused as the feature.?
Chunk information: We use GENIA taggerV2.0.2 to extract the chunk information.
Ithelps to identify the boundaries of disordermentions.?
Initial capital: The feature is set to true if thefirst character of the current token is a capitalletter.?
All capital: The feature is set to true if all theletters of the current token are capitalized.?
Stop words: A feature is defined that is setto one if the current token appears in the listof stop words.?
Word normalization: Word shapes refer tothe mapping of each word to their equiva-lence classes.
Each capitalized character ofthe word is replaced by ?A?, small charactersare replaced by ?a?
and digits are replaced by?0?.?
Word suffix and prefix: These features in-dicate the fixed-length character sequences(here 4) stripped either from the end (suffix)or beginning positions of words.
This is use-ful in the sense that disorder mentions sharesome common sub-strings.4http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA/tagger315?
Unknown word: This feature is imple-mented depending upon whether the currenttoken was found during training or not.
Forthe training set this has been set randomly.?
Word length: If the length of a token is morethan a predefined threshold (here 5) then it ismost likely a disorder mention.
This featureis defined with the observation that very shortwords are most probably not disorder men-tions.?
Alpha digit: If the current token containsdigit character(s), then the feature is set totrue otherwise false.?
Informative words: This feature is devel-oped from the training dataset.
The words orthe sequence of words that precede and fol-low the disorder mentions could be useful formention detection.
The most frequently oc-curring words that appear within the contextof wi+2i?2= wi?2.
.
.
wi+2of wiare extractedfrom the training data.
Two different lists areprepared, one for the informative words thatprecede the mentions and the other containsthe informative words that follow the men-tions.
Thereafter we define two features thatfire for the words of these lists.?
Disorder mention prefix and suffix: We ex-tract most frequently occurring prefixes andsuffixes of length 2 from the disorder men-tions present in the training data.
We pre-pare two lists containing the prefix and suffixsub-sequences (of length two) that appear atleast 10 times in the training set.
We definetwo features that go on/off depending uponwhether the current word contains any sub-sequence present in the lists.?
Dynamic information: The feature is ex-tracted from the output label(s) of the previ-ous token(s).
The feature value is determinedat run time.3 Experimental Results3.1 DatasetsIn SemEval-2014 Shared task 7, three types ofdata were provided- training, development andtest.
Training data contains four different typesof notes- discharge, ecg, echo and radiology.
De-velopment data consists of notes of three differentdomains, viz.
discharge, echo and radiology.
Butthe test set contains only the discharge notes.
Fora given document, the start and end indices arementioned for the disorder mentions.
There are199, 99 and 133 documents in the training, devel-opment and test set, respectively.3.2 Results and AnalysisWe use a regular expression based simple pattern(e.g.
dot and space) matching techniques for thesentence splitting and tokenization.
We use C++based CRF++package5for CRF experiments.
Weset the default values of the following parame-ters (a).
the hyper-parameter of CRF.
With largervalue, CRF tends to overfit to the given trainingdata; (b).
parameter which sets the cut-off thresh-old for the features (default value is 1).
CRF usesonly those features, having more than the cut-offthreshold in the given training data.In case of SVM we used YamCha6toolkitalong with TinySVM7.
We use the polynomialkernel function of degree two.
In order to denotethe boundaries of a multi-word disorder mentionproperly we use the standard BIO encodingscheme, where B, I and O represent the beginning,intermediate and outside, respectively, for amulti-word token.
Please note that the mentionsare not continuous, i.e.
they could appear at thevarious positions of the text.
For example, in thesentence The left atrium is moderately dilated,there is a single mention left atrium dilated.
ItsBIO format is represented in Table 1.Token TagThe Oleft B-Menatrium I-Menis Omoderately Odilated I-Men.
OTable 1: An example of BIO representation.Experiments are conducted on the benchmarksetup as provided by the competition organizer.
Atfirst we train our system using the training set andevaluate using the development set in order to de-5http://crfpp.sourceforge.net6http://chasen-org/ taku/software/yamcha/7http://chasen.org/ taku/software/TinySVM/316System Strict RelaxedP R F P R FBaseline 19.9 29.0 23.6 44.9 63.0 52.4Model-1 52.5 43.0 47.3 86.2 72.6 78.8Model-2 49.3 41.0 44.8 82.8 70.6 76.2Model-3 46.7 44.0 45.3 81.2 77.5 79.3Table 2: Results on development set for Task A.System Strict RelaxedAccuracy AccuracyBaseline 24.6 85.1Model-1 31.2 72.5Model-2 29.9 73.0Model-3 31.8 72.4Table 3: Results on development set for Task B.termine the best configuration.
We define a base-line model by passing the development set to theUMLS MetaMap tool.
Its results along with thebaseline model are reported in Table 2 for Task A.Evaluation shows that our proposed system per-forms reasonably better compared to the baselinemodel.
It is also to be noted that Model-1 performsbetter compared to the other two submitted mod-els for the strict matching, but for relaxed evalu-ation, Model-3 performs better than Model-1 andModel-2.
Under strict matching criterion, Model-1 achieves 2.7% and 5.0% increments in precisionover the second and third models, respectively.For relaxed matching, Model-3 achieves 4.9% and6.9% increments in recall over the first and sec-ond models, respectively.
Results on the develop-ment set for Task-B are reported in Table 3.
Pleasenote that although our system performs better thanthe baseline in terms of strict matching, it does notshow better accuracy under relaxed matching cri-terion.
This is because our system for Task-B isdeveloped by considering only those mentions thatlie in the intersection of baseline and CRF models.As a result many mentions are missed.
During fi-nal submissions we merged development sets withthe respective training sets, and perform evalua-tion on the test sets.
We report our results on thetest sets in Table 4 and Table 5 for Task-A andTask-B, respectively.We carefully analyze the results and find thatmost of the errors encountered because of the dis-contiguous mentions.
Different components of amention may be mapped to the different concepts.In our system we treat two mentions as a singleSystem Strict RelaxedP R F P R FModel-1 50.0 47.9 48.9 81.5 79.7 80.6Model-2 47.3 45.8 46.5 78.9 77.6 78.2Model-3 45.0 48.1 46.5 76.9 82.6 79.6Table 4: Evaluation results on test set for Task A.System Strict RelaxedAccuracy AccuracyModel-1 33.3 69.6Model-2 31.9 69.6Model-3 33.2 69.1Table 5: Results of Task B for the test set.unit if they have some shared tokens.
For exam-ple, the sentence ?She also notes new sharp pain inleft shoulder blade/back area?
contains two differ-ent mentions, viz.
?pain shoulder blade?
and ?painback?.
Here shared word of these two mentionsis ?pain?, but we consider these two mentions asa single unit such as ?pain shoulder blade back?.This contributes largely to the errors that our sys-tem faces for the first task.
For the second task,we miss a number of mentions, and this can becaptured if we directly match the system identifiedmentions to the entire UMLS database.4 ConclusionIn this paper we report on our works as part of ourparticipation in the SemEval-2014 shared task re-lated to clinical text mining.
We submitted threeruns for both the tasks, viz.
disorder mention de-tection and disambiguation.
Our submitted runsfor the first task are based on CRF and SVM.
Wemake use of a set of features that are not verydomain-specific.
The system developed for thesecond task is very simple and is based on UMLSMeta Map tool.There are many avenues for future research:identification of more features for the first task;use of some domain-specific resources and/ortools for the first task; use of entire UMLS the-saurus for mapping the disorder mentions; useof some machine learning techniques for disam-biguation.
We also plan to investigate how sys-tematic feature selection, ensemble learning andmachine learning optimization have impact on dis-order mention detection and disambiguation.317ReferencesJames Cogley, Nicola Stokes, and Joe Carthy.
2013.Medical Disorder Recognition with Structural Sup-port Vector Machines.
In Proceedings of CLEF.Corinna Cortes and Vladimir Vapnik.
1995.
SupportVector Networks.
Machine Learning, 20:273?297.Thorsten Joachims, 1999.
Making Large Scale SVMLearning Practical, pages 169?184.
MIT Press,Cambridge, MA, USA.John Lafferty, Andrew McCallum, and Fernando C. N.Pereira.
2001.
Conditional Random Fields: Prob-abilistic Models for Segmenting and Labeling Se-quence Data.
In ICML, pages 282?289.Utpal Kumar Sikdar, Asif Ekbal, and Sriparna Saha.2013.
Domain-independent Model for ChemicalCompound and Drug Name Recognition.
Proceed-ings of the Fourth BioCreative Challenge EvaluationWorkshop, vol.
2:158?161.Buzhou Tang, Yonghui Wu, M. Jiang, J. C. Denny, andHua Xu.
2013.
Recognizing and Encoding DisorderConcepts in Clinical Text using Machine Learningand Vector Space Model.
In Proceedings of CLEF.Guido Zuccon, A. Holloway, B. Koopman, andA.
Nguyen.
2013.
Identify Disorders in HealthRecords using Conditional Random Fields andMetamap.
In Proceedings of CLEF.318
