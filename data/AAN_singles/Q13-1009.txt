Transactions of the Association for Computational Linguistics, 1 (2013) 99?110.
Action Editor: Chris Callison-Burch.Submitted 12/2012; Published 5/2013.
c?2013 Association for Computational Linguistics.Using Pivot-Based Paraphrasing and Sentiment Profiles to Improve aSubjectivity Lexicon for Essay DataBeata Beigman Klebanov, Nitin Madnani, Jill BursteinEducational Testing Service660 Rosedale Road, Princeton, NJ 08541, USA{bbeigmanklebanov,nmadnani,jburstein@ets.org}AbstractWe demonstrate a method of improving a seedsentiment lexicon developed on essay data byusing a pivot-based paraphrasing system forlexical expansion coupled with sentiment pro-file enrichment using crowdsourcing.
Profileenrichment alone yields up to 15% improve-ment in the accuracy of the seed lexicon on 3-way sentence-level sentiment polarity classifi-cation of essay data.
Using lexical expansionin addition to sentiment profiles provides afurther 7% improvement in performance.
Ad-ditional experiments show that the proposedmethod is also effective with other subjectivitylexicons and in a different domain of applica-tion (product reviews).1 IntroductionIn almost any sub-field of computational linguistics,creation of working systems starts with an invest-ment in manually-generated or manually-annotateddata for computational exploration.
In subjectivityand sentiment analysis, annotation of training andtesting data and construction of subjectivity lexiconshave been the loci of costly labor investment.Many subjectivity lexicons are mentioned in theliterature.
The two large manually-built lexiconsfor English ?
the General Inquirer (Stone et al1966) and the lexicon provided with the Opinion-Finder distribution (Wiebe and Riloff, 2005) ?
areavailable for research and education only1 and un-der GNU GPL license that disallows their incor-poration into proprietary materials,2 respectively.1http://www.wjh.harvard.edu/ inquirer/j1 1/manual/2http://www.gnu.org/copyleft/gpl.htmlThose wishing to integrate sentiment analysis intoproducts, along with those studying subjectivity inlanguages other than English, or for specific do-mains such as finance, or for particular genressuch as MySpace comments, reported constructionof lexicons (Taboada et al 2011; Loughran andMcDonald, 2011; Thelwall et al 2010; Rao andRavichandran, 2009; Jijkoun and Hofmann, 2009;Pitel and Grefenstette, 2008; Mihalcea et al 2007).In this paper, we address the step of expandinga small-scale, manually-built subjectivity lexicon (aseed lexicon, typically for a domain or languagein question) into a much larger but noisier lexi-con using an automatic procedure.
We presenta novel expansion method using a state-of-the-artparaphrasing system.
The expansion yields a 4-foldincrease in lexicon size; yet, the expansion aloneis insufficient in order to improve performance onsentence-level sentiment polarity classification.In this paper we test the following hypothesis.We suggest that the effectiveness of the expansionis hampered by (1) introduction of opposite-polarityitems, such as introducing resolute as an expansionof forceful, or remarkable as an expansion of pecu-liar; (2) introduction of weakly polar, neutral, or am-biguous words as expansions of polar seed words,such as generating concern as an expansion of anx-iety or future as an expansion of aftermath;3 (3) in-ability to distinguish between stronger or clear-cutversus weaker or ambiguous sentiment and to makea differential use of those.We address items (1) and (2) by enriching the lexi-con with sentiment profiles (section 3), and propose3Table 2 and Figure 1 provide support to these assessments.99a way of effectively utilizing this information forthe sentence-level sentiment polarity classificationtask (sections 5 and 6).
Profile-enrichment aloneyields up to 15% increase in performance for theseed lexicon when using different machine learningalgorithms; paraphraser-based expansion with sen-timent profiles improves performance by an addi-tional 7%.
Overall, we observe an improvement ofup to 25% in classification accuracy over the seedlexicon without profiles.In section 7, we present comparative evaluations,demonstrating the competitiveness of the expandedand profile-enriched lexicon, as well as the effective-ness of the expansion and enrichment paradigm pre-sented here for different subjectivity lexicons, dif-ferent lexical expansion methods, and in a differentdomain of application (product reviews).2 Building Subjectivity LexiconsThe goal of our sentiment analysis project is to allowfor the identification of sentiment in sentences thatappear in essay responses to a variety of tasks de-signed to test English proficiency in both native- andnon-native-speaker populations in a standardized as-sessment as well as in an instructional settings.
Inorder to allow for the future use of the sentimentanalyzer in a proprietory product and to ensure its fitto the test-taker essay domain, we began our workwith the construction of a seed lexicon relying onour materials (section 2.1).
We then used a statisti-cal paraphrasing system to expand the seed lexicon(section 2.2).2.1 Seed LexiconIn order to inform the process of lexicon construc-tion, we randomly sampled 5,000 essays from a cor-pus of about 100,000 essays containing writing sam-ples across many topics.
Essays were responsesto several different writing assignments, includinggraduate school entrance exams, non-native Englishspeaker proficiency exams, and professional licen-sure exams.
Our seed lexicon is a combination of(1) positive and negative sentiment words manuallyselected from a full list of word types in these data,and (2) words marked in a small-scale annotation ofa sample of sentences from these data for all posi-tive and negative words.
A more detailed descrip-tion of the construction of seed lexicon can be foundin Beigman Klebanov et al2012).
The seed lexi-con contains 749 single words, 406 positive and 343negative.2.2 Expanded LexiconWe used a pivot-based lexical and phrasal para-phrase generation system (Madnani and Dorr, 2013).The paraphraser implements the pivot-based methodas described by Bannard and Callison-Burch (2005)with several additional filtering mechanisms to in-crease the precision of the extracted pairs.
Thepivot-based method utilizes the inherent monolin-gual semantic knowledge from bilingual corpora:We first identify phrasal correspondences betweenEnglish and a given foreign language F , then mapfrom English to English by following translationunits from English to the other language and back.For example, if the two English phrases e1 and e2both correspond to the same foreign phrase f , thenthey may be considered to be paraphrases of eachother with the following probability:p(e1|e2) ?
p(e1|f)p(f |e2)If there are several pivot phrases that link the twoEnglish phrases, then they are all used in computingthe probability:p(e1|e2) ?
?f ?p(e1|f ?
)p(f ?|e2)Seed Expansion Seed Expansionabuse exploitation costly onerousaccuse reproach dangerous unsafeanxiety disquiet improve reinforceconflict crisis invaluable preciousTable 1: Examples of paraphraser expansions.Some examples of expansions generated by theparaphraser are shown in Table 1.
More detailsabout this kind of approach can be found in Ban-nard and Callison-Burch (2005).
We use the French-English parallel corpus (approximately 1.2 millionsentences) from the corpus of European parliamen-tary proceedings (Koehn, 2005) as the data on whichpivoting is performed to extract the paraphrases.However, the base paraphrase system is susceptible100to large amounts of noise due to the imperfect bilin-gual word alignments.
Therefore, we implement ad-ditional heuristics in order to minimize the num-ber of noisy paraphrase pairs (Madnani and Dorr,2013).
For example, one such heuristic filters outpairs where a function word may have been inferredas a paraphrase of a content word.
For the lexiconexpansion experiment reported here, we use the top15 single-word paraphrases for every word from theseed lexicon, excluding morphological variants ofthe seed word.
This process results in an expandedlexicon of 2,994 different words, 1,666 positive and1,761 negative (433 words are in both the positiveand the negative lists).
The expanded lexicon in-cludes the seed lexicon.3 Inducing sentiment profilesLet ?w be the sentiment profile of the word w.?w = (pposw , pnegw , pneuw ) (1)where ?i?
{pos,neg,neu} piw = 1.
Thus, a sentimentprofile of a word is essentially a 3-sided coin, cor-responding to its probability of coming out positive,negative, and neutral, respectively.3.1 Estimating sentiment profilesOur goal is to estimate the profile using outcomes ofmultiple trials as follows.
For every word, a personis shown the word and asked whether it is positive,negative, or neutral.
A person?s decision is modeledas flipping the coin corresponding to the word, andrecording the outcome ?
positive, negative, or neu-tral.
We run N=20 such trials for every word in theexpanded lexicon using the CrowdFlower crowd-sourcing site,4 for a total cost of $800.
We use maxi-mum likelihood estimate of sentiment profile:p?iw = niw (2)where niw is the proportion ofN trials on the wordwthat fell in cell i ?
{pos, neg, neu}.
Table 2 showssome estimated profiles.Following Goodman (1965) and Quesenberry andHurst (1964), we calculate confidence intervals forthe parameters piw:(p?iw)?
= (B + 2niw ?
T )/(2(N +B)) (3)4www.crowdflower.comWord p?posw p?neuw p?negwforceful 0 0.15 0.85resolute 0.8 0.15 0.05peculiar 0.05 0.15 0.8remarkable 1 0 0anxiety 0 0 1concern 0.25 0.4 0.35absurd 0 0 1laughable 0.5 0.05 0.45deadly 0 0 1fateful 0.25 0.45 0.3consequence 0.05 0.15 0.8outcome 0.15 0.85 0Table 2: Examples of estimated sentiment profiles.Words in gray are expansions generated from words inthe preceding row; note the difference in the profiles.
(p?iw)+ = (B + 2niw + T )/(2(N +B)) (4)whereT =?B[B + 4niw(N ?
niw)/N ]) (5)For confidence ?
that all piw, i ?
{pos, neg, neu}are simultaneously within their respective intervals,the value of B is determined as the upper?/3?100thpercentile of the ?2 distribution with one degree offreedom.
We use ?=0.1, resulting in B=4.55.
Theresulting interval is about 0.2 around the estimatedvalue when p?iw is close to 0.5, and somewhat nar-rower for p?iw closer to 0 or 1.
We will use this infor-mation when inducing features from the profiles.3.2 Sentiment distributions of the lexiconsThe estimated sentiment profiles per word allow usto visualize the distributions of the two lexicons.
InFigure 1, we plot the number of entries in the lexi-con as a function of the difference in positive andnegative parts of the profile, in 0.2-wide bins.
Thus,a word w would be in the second-leftmost bin if?0.8 < (p?posw ?
p?negw ) < ?0.6.While the expansion process more than doublesthe number of words in the highest bins for boththe positive and the negative polarity, it clearlyintroduces a large number of words in the low-and medium bins into the lexicon.
It is in thissense that the expansion process is noisy; appa-rently, seed words with clear and strong polarity1011020040060080010001200?1.0?0.50.00.51.02.2020040060080010001200?1.0?0.50.00.51.03.2020040060080010001200?1.0?0.50.00.51.04.2.1020040060080010001200?1.0?0.50.00.51.05.2020040060080010001200?1.0?0.50.00.51.06.2020040060080010001200?1.0?0.50.00.51.07.2.1020040060080010001200?1.0?0.50.00.51.08.2020040060080010001200?1.0?0.50.00.51.09.2.1020040060080010001200?1.0?0.50.00.51.010.2.1020040060080010001200?1.0?0.50.00.51.011.2.1020040060080010001200?1.0?0.50.00.51.012.2.1020040060080010001200?1.0?0.50.00.51.013.2020040060080010001200?1.0?0.50.00.51.014.2.1020040060080010001200?1.0?0.50.00.51.01020040060080010001200?1.0?0.50.00.51.02.2020040060080010001200?1.0?0.50.00.51.03.2020040060080010001200?1.0?0.50.00.51.04.2.1020040060080010001200?1.0?0.50.00.51.05.2020040060080010001200?1.0?0.50.00.51.06.2020040060080010001200?1.0?0.50.00.51.07.2.1020040060080010001200?1.0?0.50.00.51.08.2020040060080010001200?1.0?0.50.00.51.09.2.1020040060080010001200?1.0?0.50.00.51.010.2.1020040060080010001200?1.0?0.50.00.51.011.2.1020040060080010001200?1.0?0.50.00.51.012.2.1020040060080010001200?1.0?0.50.00.51.013.2020040060080010001200?1.0?0.50.00.51.014.2.1020040060080010001200?1.0?0.50.00.51.0Figure 1: Sentiment distributions for the seed (left) andthe expanded (right) lexicons.are often expanded into low intensity, neutral, orambiguous ones, as in pairs like absurd/laughable,deadly/fateful, anxiety/concern shown in Table 2.4 Related WorkThe most popular seed expansion methods discussedin the literature are based on WordNet (Miller,1995) or another lexicographic resource, on dis-tributional similarity with the seeds, or on a mix-ture thereof (Cruz et al 2011; Baccianella et al2010; Velikovich et al 2010; Qiu et al 2009; Mo-hammad et al 2009; Esuli and Sebastiani, 2006;Kim and Hovy, 2004; Andreevskaia and Bergler,2006; Hu and Liu, 2004; Kanayama and Nasukawa,2006; Strapparava and Valitutti, 2004; Kamps et al2004; Takamura et al 2005; Turney and Littman,2003; Hatzivassiloglou and McKeown, 1997).
Theparaphrase-based expansion method is in the dis-tributional similarity camp; we also experimentedwith WordNet-based expansion as descibed in sec-tion 7.2.The task of assigning sentiment profiles to wordsin a sentiment lexicon has been addressed in the lite-rature.
SentiWordNet assigns profiles to all words inWordNet based on a propagation algorithm from asmall seed set manually annotated by a small num-ber of judges (Baccianella et al 2010; Cerini et al2007).
Andreevskaia and Bergler (2006) use graphpropagation algorithms on WordNet to assign cen-trality scores in positive and negative categories; asimilar approach based on web-scale co-occurrencegraphs is discussed in Velikovich et al2010).
Thel-wall et al2010) manually annotated a set of wordsfor strength of sentiment and used machine learningto fine-tune it.
Taboada et al2011) produced anexpert annotation of their lexicon with strength ofsentiment.
Subasic and Huettner (2001) manuallybuilt an affect lexicon with intensities.
Wiebe andRiloff (2005) classifed lexicon entries into weaklyand strongly subjective, based on their relative fre-quency of appearance in subjective versus objectivecontexts in a large annotated dataset.Our sentiment profiles are best thought of asrelatively fine-grained priors for the sentiment ex-pressed by a given word out-of-context.
These re-flect a mixture of strength of sentiment (p?posgood >p?posdecent), contextual ambiguity (concern can be in-terpreted as similar to worry or to care, as in ?Hercondition was causing concern?
versus ?He showedgenuine concern for her?
), and dominance of a po-lar connotation (abandon is p?neg=1; it has a negativeovertone even if the actual sense is not that of desertbut of vacate, as in ?You must abandon your office?
).To the best of our knowledge, this paper presentsthe first attempt to integrate judgements obtainedthrough crowdsourcing on a large scale into a sen-timent lexicon, showing the effectiveness of thislexicon-enrichment procedure for a sentiment clas-sification task.5 Using profiles for sentence-levelsentiment polarity classificationTo evaluate the usefulness of the lexicons, we usethem to generate features for machine learning sys-tems, and compare performance on 3-way sentence-level sentiment polarity classification.
To ensure ro-bustness of the observed trends, we experiment witha number of machine learning algorithms: SVMLinear and RBF, Na?
?ve Bayes, Logistic Regression(using WEKA (Hall et al 2009)), and c5.0 DecisionTrees (Quinlan, 1993).55.1 DataWe generated the data for training and testing themachine learning systems as follows.
We used our5available from http://rulequest.com/102pool of 100,000 essays to sample a second, non-overlapping set of 5,000 essays, so that no essayused for lexicon development appears in this set.From these essays, we randomly sampled 550 sen-tences, and submitted them to sentiment polarity an-notation by two experienced research assistants; 50double-annotated sentenced showed ?=0.8.
TESTset contains the 43 agreed double-annotated sen-tences, and additional 238 sampled from the 500single-annotated sentences, 281 sentence in total.The category distribution in the TEST set is 46.6%neutral, 32.4% positive, and 21% negative.The TRAIN set contains the remaining sentences,plus positive, negative, and neutral sentences anno-tated during lexicon development, for the total of1,631 sentences.
The category distribution in TRAINis 39% neutral, 35% positive, 26% negative.5.2 From lexicons to featuresOur goal is to evaluate the impact of sentiment pro-files on sentence-level sentiment polarity classifica-tion for the seed and the expanded lexicons, whilealso looking for the most effective ways to representthis information for machine learners.We implement two baseline systems.
One pro-vides the machine learner with the most detailed in-formation contained in a lexicon: BL-full has 2 fea-tures for every lexicon word, taking the values (1,0)for positive match in a sentence, (0,1) ?
for negative,(1,1) for a word in both positive and negative partsof the lexicon, and (0,0) otherwise.The second baseline provides the machine learnerwith only summary information about the overallsentiment of the sentence.
BL-sum uses only 2 fea-tures: (1) the total count of positive words in thesentence; (2) the total count of negative words in thesentence, according to the given lexicon.For the sentiment-enriched runs, we construct anumber of representations: Int-full, Int-sum, Int-bin, and Int-c. Int-full and Int-sum are parallel tothe respective baseline systems.
Int-full representseach lexicon word as 2 features corresponding to theword?s estimated p?posw and p?negw , providing the mostdetailed information to the machine learner.
In theInt-sum condition, we use p?posw and p?negw for everyword to induce 2 features: (1) the sum of positiveprobabilities of all words in the sentence; (2) thesum of negative probabilities for all words in thesentence, according to the given lexicon.For Int-bin runs, we use bins of the size of 0.2 ?half of the maximal confidence interval ?
to grouptogether words with close estimates.
We produce10 features.
For positive bins, the 5 features countthe number of words in the sentence that fall inbini, 1 ?
i ?
5, respectively, that is, words with0.2(i?
1) < p?posw ?
0.2i.
Bin 1 also includes wordswith p?posw = 0, since these cannot be distinguishedwith high confidence from p?posw =0.1.
Note that wedo not provide a scale, we merely represent differentranges with different features.
This should allow themachine learners the flexibility to weight the diffe-rent bins differently when inducing classifiers.The Int-c condition represents a coarse-grainedsetting.
We produce 4 features, two for each pola-rity: (1) the number of words such that 0 ?
p?posw <0.4; (2) the number of words such that 0.4 ?
p?posw ?1; similarity for the negative polarity.Table 3 summarizes conditions and features.Cond.
#F Feature DescriptionBL-full 2|L| (1Lpos?S(w),1Lneg?S(w))BL-sum 2 f1=|{w : w ?
Lpos ?
S}|f2=|{w : w ?
Lneg ?
S}|Int-full 2|L| (p?posw , p?negw ) ?w ?
AInt-sum 2 (?w?A p?posw , ?w?A p?negw )Int-bin 10 f1=|{w ?
A : 0 ?
p?posw ?
0.2}|...f10=|{w ?
A : 0.8 < p?negw ?
1}|Int-c 4 f1=|{w ?
A : 0 ?
p?posw < 0.4}|...f4=|{w ?
A : 0.4 ?
p?negw ?
1}|Table 3: Description of conditions.
Column 2 shows thenumber of features.
In column 3: 1 is an indicator func-tion; L is a lexicon; Lpos is the part of the lexicon con-taining positive words (same with negatives); S is a sen-tence for which a feature vector is built; A = L ?
S. Forall w ?
L ?
S in the -full conditions, w is representedwith (0,0).6 ResultsTable 4 shows classification accuracies for 5 ma-chine learning systems across 6 conditions, for theseed and the expanded lexicons.Let BL denote the best-performing baseline (BL-103Machine Condition Seed ExpandedLearner?
Majority 0.466 0.466c5.0 BL-full 0.441 0.498BL-sum 0.512 0.480Int-full 0.441 0.498Int-sum 0.566 0.616Int-bin 0.587 0.641Int-c 0.530 0.577SVM BL-full 0.466 0.466RBF BL-sum 0.527 0.495Int-full 0.466 0.466Int-sum 0.548 0.601Int-bin 0.573 0.644Int-c 0.530 0.562SVM BL-full 0.584 0.566Linear BL-sum 0.509 0.502Int-full 0.580 0.609Int-sum 0.601 0.580Int-bin 0.573 0.630Int-c 0.569 0.569Logistic BL-full 0.545 0.509Regression BL-sum 0.545 0.509Int-full 0.534 0.502Int-sum 0.555 0.584Int-bin 0.584 0.616Int-c 0.545 0.577Na?
?ve BL-full 0.598 0.584Bayes BL-sum 0.509 0.473Int-full 0.598 0.580Int-sum 0.545 0.605Int-bin 0.559 0.626Int-c 0.537 0.601Table 4: Classification accuracies on TEST set.
Majo-rity baseline corresponds to classifying all sentences asneutral.
The best performance is boldfaced.
Let BLstand for the best-performing baseline (BL-full or BL-sum) for a combination of machine learner and lexicon.We use Wilcoxon Signed-Rank test, reporting the num-ber of signed ranks (N) and the sum of signed ranks (W).Statistically significant results at p=0.05 are: Int-sum >BL (N=10, W=43); Int-bin > BL (N=10, W=48); Int-bin > Int-sum (N=10, W=43); Int-bin > Int-full (N=10,W=47); Int-sum > Int-full (N=10, W=37); Int-bin > Int-c (N=10, W=55); Int-sum > Int-c (N=10, W=55); Ex-panded> Seed under Int condition (includes Int-full, Int-sum, Int-bin, Int-c) (N=18, W=152, z=3.3).
Differencesbetween Int-full, Int-c, and BL are not significant.full or BL-sum) for a combination of machinelearner and lexicon.
The results show that (1) Int-bin > Int-sum > BL = Int-c = Int-full; (2) Ex-panded > Seed under Int condition.
All inequalitiesare statistically significant at p=0.05 (see caption ofTable 4 for details).First, both the seed and the expanded lexiconsbenefit from profile enrichment, although, as pre-dicted, the expanded lexicon yields larger gains dueto its more varied profiles: The seed lexicon gains upto 15% in accuracy (c5.0 BL-sum vs Int-bin), whilethe expanded lexicon gains up to 30%, as SVM RBFscores go up from 0.495 to 0.644.Second, observe that profiling allows the ex-panded lexicon to leverage its improved coverage:While it is inferior to the best baseline run with theseed lexicon for all systems, it succeeds in impro-ving the seed lexicon accuracies by 5%-12% acrossthe different systems for the Int-bin runs.
The bestrun of the expanded lexicon (Int-bin for SVM RBF)improves upon the best run of the seed lexicon (Int-sum for SVM-linear) by 7%, demonstrating the suc-cess of the paraphraser-based expansion once pro-files are taken into account.
Overall, comparing thebest baseline for the seed lexicon with Int-bin con-dition of the expanded lexicon, we observe an im-provement between 5% (0.598 to 0.626 for Na?
?veBayes) and 25% (0.512 to 0.641 for c5.0), provingthe effectiviness of the paraphrase-based expansionwith profile enrichment paradigm.Third, representing profiles using 10 bins (Int-bin)provides a small but consistent improvement overthe summary representation (Int-sum) that sumspositivity and negativity of the sentiment-bearingwords in a sentence, over a coarse-grained represen-tation (Int-c), as well as over the full-informationrepresentation (Int-full).
Even Na?
?ve Bayes andSVM linear, known to work well with large featuresets, show better performance in the Int-bin con-dition for the expanded lexicon.
The results indi-cate that an intermediate degree of detail ?
betweensummary-only and coarse-grained representation onthe one hand and full-information representation onthe other ?
is the best choice in our setting.1047 Comparative EvaluationsIn this section, we present comparative evaluationsof the work presented in this paper with respect torelated work.
This section shows that the paraphraseexpansion+profile enrichment solution proposed inthis paper is effective for our task beyond off-the-shelf solutions, and that its effectiveness generalizesto sentiment analysis in a different domain.
We alsoshow that profile enrichment can be effectively cou-pled with other methods of lexical expansion, al-though the paraphraser-based expansion receives alarger boost in performance from profile enrichmentthan the alternative expansion methods we consider.In section 7.1, we demonstrate that theparaphrase-based expansion and profile enrich-ment yield superior performance on our datarelative to state-of-art subjectivity lexicons ?
Opin-ionFinder, General Inquirer, and SentiWordNet.In section 7.2, we show that profile enrichmentcan be effectively coupled with other methodsof lexical expansion, such as a WordNet-basedexpansion and an expansion that utilizes Lin?sdistributional thesaurus.
However, we find that theparaphraser-based expansion benefits the most fromprofile enrichment, and attains better performanceon our data than the alterantive expansion methods.In section 7.3, we show that the paraphrase-basedexpansion and profile enrichment paradigm iseffective for other subjecitivy lexicons on otherdata.
We use a dataset of product reviews annotatedfor sentence-level positivity and negativity asnew data for evaluation (Hu and Liu, 2004).
Weuse subsets of OpinionFinder, General Inquirer,and sentiment lexicon from Hu and Liu (2004).We demonstrate that paraphrase-based expansionand profile enrichment improve the accuracy ofsentiment classification of product reviews forevery lexicon and machine learner combination; themagnitude of improvement is 5% on average.7.1 Competitiveness of the Expanded LexiconHad we been able to use the OpinionFinder orthe General Inquirer lexicons (OFL and GIL) as-is, how would the results have compared to thoseattained using our lexicons?
We performed thebaseline runs with both lexicons; OFL accuracieswere 0.544-0.594 across machine learning systems,GIL?s ?
0.491-0.584 (see GIL column in Table 5).We also experimented with using the weaksubjand strongsubj labels in OFL as somewhat paralleldistinctions to the ones presented here (see sec-tion 4 ?
Related Work ?
for a more detailed discus-sion).
We used (1,0,0) profile for strong positives,(0.3,0,0.7) for weak positives, (0,1,0) for strong neg-atives, and (0,0.3,0.7) for weak negatives, and ran allthe feature representations discussed in section 5.2.Table 5 column OFL shows the best run for everymachine learning system, across the different featurerepresentations, and choosing the better performingrun between vanilla OFL and the version enrichedwith weak/strong distinctions.Machine Seed OFL GIL SWN Exp.Learner BLc5.0 0.512 0.598 0.491 0.516 0.641SVM-RBF 0.527 0.594 0.495 0.520 0.644SVM-lin.
0.584 0.594 0.580 0.569 0.630Log.
Reg.
0.545 0.598 0.541 0.537 0.616Na?
?ve B.
0.598 0.573 0.584 0.587 0.626Table 5: Performance of different lexicons on essay datausing various machine learning systems.
For each sys-tem and lexicon, the best performance across the applica-ble feature representations from section 5.2 and the vari-ants (see text) is shown.
Seed BL column shows the bestbaseline performance of our seed lexicon ?
before para-phraser expansion and profile enrichment were applied.Exp.
column shows the performance of Int-bin featurerepresentation for the expanded lexicon after profile en-richment.Additionally, we experimented with SentiWord-Net (Baccianella et al 2010).
SentiWordNet is aresource for opinion mining built on top of Word-Net, which assigns each synset in WordNet a scoretriplet (positive, negative, and objective), indicatingthe strength of each of these three properties for thewords in the synset.
The SentiWordNet annotationswere automatically generated, starting with a set ofmanually labeled synsets.
Currently, SentiWordNetincludes an automatic annotation for all the synsetsin WordNet, totaling more than 100,000 words.
Itis therefore the largest-scale lexicon with intensityinformation that is currently available.Since SentiWordNet assigns scores to synsets andsince our data is not sense-tagged, we induced Sen-105tiWordNet scores in the following ways.
We part-of-speech tagged our train and test data using Stan-ford tagger (Toutanova et al 2003).
Then, we tookthe SentiWordNet scores for the top sense for thegiven part-of-speech (SWN-1).
In a different vari-ant, we took a weighted average of the scores for thedifferent senses, using the weighting algorithm pro-vided on SentiWordNet website6 (SWN-2).
Table 5column SWN shows the best performance figuresbetween SWN-1 and SWN-2, across the feature rep-resentations in section 5.2.The comparative results in Table 5 clearly showthat while our vanilla seed lexicon performs com-parably to off-the-shelf lexicons on our data, theparaphraser-expanded lexicon with sentitment pro-files outperforms OpinionFinder, General Inquirer,and SentiWordNet.7.2 Sentiment Profile Enrichment with OtherLexical Expansion MethodsWe presented a novel lexicon expansion methodusing a paraphrasing system.
We also experimentedwith more standard methods, using WordNet anddistributional similarity (Beigman Klebanov et al2012; Esuli and Sebastiani, 2006; Kim and Hovy,2004; Andreevskaia and Bergler, 2006; Hu and Liu,2004; Kanayama and Nasukawa, 2006; Strapparavaand Valitutti, 2004; Kamps et al 2004; Takamuraet al 2005; Turney and Littman, 2003; Hatzivas-siloglou and McKeown, 1997).
Specifically, we im-plemented a WordNet (Miller, 1995) based expan-sion that uses the 3 most frequent synonyms of thetop sense of the seed word (WN-e).
We also imple-mented a method based on distributional similarity:Using Lin?s proximity-based thesaurus (Lin, 1998)trained on our in-house essay data as well as on well-formed newswire texts, we took all words with theproximity score > 1.80 to any of the seed lexiconwords (Lin-e).
Just like the paraphraser lexicon,both perform worse than the seed lexicon in 9 outof 10 baseline runs (BL-sum and Bl-full conditionsfor the 5 machine learners).To test the effect of profile enrichment, all wordsin WN-e and Lin-e underwent profile estimation asdescribed in section 3.1, yielding lexicons WN-e-pand Lin-e-p, respectively.
Figure 2 shows the distri-6http://sentiwordnet.isti.cnr.it/, under ?Sample code.
?1020040060080010001200?1.0?0.50.00.51.02.2020040060080010001200?1.0?0.50.00.51.03.2020040060080010001200?1.0?0.50.00.51.04.2.1020040060080010001200?1.0?0.50.00.51.05.2020040060080010001200?1.0?0.50.00.51.06.2020040060080010001200?1.0?0.50.00.51.07.2.1020040060080010001200?1.0?0.50.00.51.08.2020040060080010001200?1.0?0.50.00.51.09.2.1020040060080010001200?1.0?0.50.00.51.010.2.1020040060080010001200?1.0?0.50.00.51.011.2.1020040060080010001200?1.0?0.50.00.51.012.2.1020040060080010001200?1.0?0.50.00.51.013.2020040060080010001200?1.0?0.50.00.51.014.2.1020040060080010001200?1.0?0.50.00.51.0Figure 2: Sentiment profile distributions for Lin-e-p (left)and WN-e-p (right) lexicons.butions.
WN-e-p and Lin-e-p exhibit similar trendsto those of the paraphraser.
Substituting WN-e-pfor Expanded data in Table 4, we find the same re-lationships between the different feature sets: Int-bin>Int-sum>Int-full=BL.
For Lin-e-p, Int-sum de-teriorates: Int-bin>Int-sum=Int-full=BL.
For the20 runs in the Int condition, Paraphraser>WN-e-p>Lin-e-p.7 Note that this is also the order of lexi-con sizes: Lin-e is the most conservative expan-sion (1,907 words), WN-e is the second with 2,527words, and the lexicon expanded using paraphrasingis the largest with 2,994 words.
Table 6 shows theperformance of Lin-e-p, WN-e-p, and of the Ex-panded lexicon from Table 4 using the Int-bin fea-ture representation.
The average relative improve-ments over the best baseline range between 6.6% to14.6% for the different expansion methods.Profile induction appears to be a powerful lexiconclean-up procedure that works especially well withmore aggressive and thus potentially noisier expan-sions: The machine learners depress low-intensityand ambiguous expansions, thereby allowing theeffective utilization of the improved coverage ofsentiment-bearing vocabulary.7.3 Effectiveness of the Paraphrase Expansionwith Profile Enrichment Paradigm in aDifferent DomainIn order to check whether the paraphrase-based ex-pasion and profile enrichment paradigm discussed inthis paper generalizes to other subjectivity lexicons7All > are signficant at p=0.05 using Wilcoxon test.106Machine Seed Lin-e-p WN-e-p Exp.Learner BLc5.0 0.512 0.584 0.616 0.641SVM-RBF 0.527 0.598 0.601 0.644SVM-lin.
0.584 0.577 0.569 0.630Log.
Reg.
0.545 0.587 0.580 0.616Na?
?ve B.
0.598 0.591 0.623 0.626Av.
Gain 0.066 0.085 0.146Table 6: Performance of WordNet-based, Lin-based, andParaphraser-based expansions with profile enrichment inthe Int-bin condition.
Seed BL column shows the bestbaseline performance of the seed lexicon ?
before expan-sion and profile enrichment were applied.
The last lineshows the average relative gain over the best baselinecalculated as AGlex = ?m?M Lexm?SeedBLmSeedBLm , whereM = {c5.0, SVM-RBF, SVM-linear, Logistic Regres-sion, Na?
?ve Bayes}, and lex ?
{Lin-e-p, Wn-e-p, Exp}.and domains of application, we experimented witha product reviews dataset (Hu and Liu, 2004) andadditional lexicons as follows.7.3.1 LexiconsWe use the OpinionFinder and General Inquirerlexicons (OFL and GIL) as before, as well asthe lexicon of positive and negative sentiment andopinion words available along with (Hu and Liu,2004) product reviews dataset ?
HL.8Since each of these lexicons contains more than3,000 words, enrichment of the full lexicons withprofiles is beyond the financial scope of our project.We therefore restrict each of the lexicons to the sizeof their overlap with our seed lexicon (see 2.1); theoverlaps have between 415 and 467 words.
These re-stricted lexicons are our initial lexicons for the newexperiment that parallel the role of the seed lexiconin the experiments on essay data.For each of the 3 initial lexicons L, L?
{OFL,GIL, HL}, we follow the paraphrase-based expan-sion as described in section 2.2.
This results in about4.5-fold expansion of each lexicon, the new lexi-cons L-e, L?
{OFL, GIL, HL}, numbering between2,015 and 2,167 words.
Both the initial and the ex-panded lexicons now undergo profile enrichment asdescribed in section 3.1, producing lexicons L-p and8http://www.cs.uic.edu/?liub/FBS/sentiment-analysis.html#lexiconL-e-p, L?
{OFL, GIL, HL}.7.3.2 DataWe use the dataset from Hu and Liu (2004)9 thatcontains reviews of 5 products from amazon.com:two digital cameras, a DVD player, an MP3 player,and a cellular phone.
The reviews are annotated atsentence level with a label that desrcibes the par-ticular feature that is the subject of the positive ornegative evaluation and the polarity and extent ofthe evaluation.
For example, the sentence ?Thephone book is very user-friendly and the speaker-phone is excellent?
is labeled as PHONE BOOK[+2],SPEAKERPHONE[+2], while the sentence ?I ambored with the silver look?
is labeled LOOK[?1].
Weused all sentences that were labeled with a numeri-cal score for at least one feature, removing a smallnumber of sentences labeled with both positive andnegative scores for different features.10 We used thesign of the numerical score to label the sentences aspositive or negative.
The resulting dataset consistsof 1,695 sentences, 1,061 positive and 634 nega-tive; accuracy for a majority baseline on this datasetis 0.626.
Our experiments on this dataset are doneusing 5-fold cross-validation.7.3.3 ResultsTable 7 shows classification accuracies for theproduct review data using different lexicons and ma-chine learners.
We observe that the combination ofparaphrase-based expansion and profile enrichment(L-e-p column in the table) resulted in an improvedperformance over the initial lexicon (L column inthe table) in all cases, with the average gain of 5%in accuracy.Furthermore, the contributions of the expansionand the profile enrichment are complementary, sincetheir combination performs better than each in iso-lation.
We note that profile enrichment alone for theinitial lexicon did not yield an improvement.
Thiscan be explained by the fact that the initial lexiconsare highly polar, so profiles provide little additionalinformation: The percentage of words with p?pos ?0.8 or p?neg ?
0.8 is 84%, 86% and 91% for GIL,9http://www.cs.uic.edu/?liub/FBS/sentiment-analysis.html#datasets, the link under ?Customer ReviewDatasets (5 products)?10such as ?The headset that comes with the phone has goodsound volume but it hurts the ears like you cannot imagine!
?107Machine Lexicon VariantLearner L L-p L-e L-e-pL = OFL?Seed, |L|=467, |L-e|=2,167c5.0 0.663 0.670 0.691 0.704SVM-RBF 0.668 0.676 0.693 0.714SVM-lin.
0.675 0.670 0.688 0.696Log.
Reg.
0.666 0.658 0.693 0.698Na?
?ve B.
0.668 0.668 0.686 0.695L = GIL?Seed, |L|=415,|L-e|=2,015c5.0 0.644 0.658 0.663 0.686SVM-RBF 0.650 0.665 0.653 0.683SVM-lin.
0.665 0.665 0.677 0.681Log.
Reg.
0.664 0.658 0.678 0.694Na?
?ve B.
0.669 0.666 0.678 0.703L = HL?Seed, |L|=434, |L-e|=2,054c5.0 0.676 0.675 0.689 0.706SVM-RBF 0.673 0.674 0.700 0.713SVM-lin.
0.676 0.664 0.703 0.710Log.
Reg.
0.668 0.661 0.703 0.699Na?
?ve B.
0.668 0.672 0.697 0.697Table 7: Accuracies on product review data.
For each ma-chine learner and lexicon, the best baseline performanceis shown as L for the initial lexicon and as L-e for theparaphrase-expanded lexicon.
L-p and L-e-p show theperformance of Int-bin feature set on the profile-enrichedinitial and paraphrase-expanded lexicons, respectively.The three initial lexicons L are OpinionFinder (OFL),General Inquirer (GIL), and (Hu and Liu, 2004) (HL),each intersected with our seed lexicon.
Sizes of the intialand expanded lexicons are provided.OFL, and HL-derived lexicons, respectively.
In con-trast, for the expanded lexicons, these percentagesare 51%, 53%, and 56%; these lexicons benefit fromprofile enrichment.8 ConclusionsWe demonstrated a method of improving a seed sen-timent lexicon by using a pivot-based paraphrasingsystem for lexical expansion and sentiment profileenrichment using crowdsourcing.
Profile enrich-ment alone yielded up to 15% improvement in theperformance of the seed lexicon on the task of 3-way sentence-level sentiment polarity classificationof test-taker essay data.
While the lexical expansionon its own failed to improve upon the performanceof the seed lexicon, it became much more effectiveon top of sentiment profiles, generating a 7% perfor-mance boost over the best profile-enriched run withthe seed lexicon.
Overall, paraphrase-based expan-sion coupled with profile enrichment yields an up to25% improvement in accuracy.Additionally, we showed that our paraphrase-expanded and profile-enriched lexicon performssignificantly better on our data than off-the-shelfsubjectivity lexicons, namely, Opinion Finder, Gen-eral Inquirer, and SentiWordNet.
Furthermore, ourresults suggest that paraphrase-based expansion de-rives more benefit from profiles than two competingexpansion mechanisms based on WordNet and onLin?s distributional thesaurus.Finally, we demonstrated the effectiveness of theparaphraser-based expansion with profile enrich-ment paradigm on a different dataset.
We used Huand Liu (2004) product review data with sentence-level sentiment polarity labels.
Paraphrase-basedexpansion with profile enrichment yielded an im-proved performance across all lexicons and machinelearning algorithms we tried, with an average im-provement rate of 5% in classification accuracy.Recent literature argues that sentiment polarityis a property of word senses, rather than of words(Gyamfi et al 2009; Su and Markert, 2008; Wiebeand Mihalcea, 2006), although Dragut et al2012)successfully operate with ?mostly negative?
and?mostly positive?
words based on the polarity distri-butions of word senses.
We plan to address in futurework sense disambiguation for words that have mul-tiple senses with very different sentiment, such asstress, as either anxiety (negative) or emphasis (neu-tral).ReferencesAlina Andreevskaia and Sabine Bergler.
2006.
MiningWordNet for a fuzzy sentiment: Sentiment tag extrac-tion of WordNet glosses.
In Proceedings of EACL,pages 209?216, Trento, Italy.Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-tiani.
2010.
SENTIWORDNET 3.0: An EnhancedLexical Resource for Sentiment Analysis and OpinionMining.
In Proceedings of LREC, pages 2200?2204,Malta.Colin Bannard and Chris Callison-Burch.
2005.
Para-phrasing with bilingual parallel corpora.
In Proceed-ings of ACL, pages 597?604, Ann Arbor, MI.108Beata Beigman Klebanov, Jill Burstein, Nitin Madnani,Adam Faulkner, and Joel Tetreault.
2012.
Build-ing sentiment lexicon(s) from scratch for essay data.In Proceedings of the 13th International Conferenceon Intelligent Text Processing and Computational Lin-guistics (CICLing), New Delhi, India, March.S.
Cerini, V. Compagnoni, A. Demontis, M. Formentelli,and G. Gandini.
2007.
Micro-WNOp: A gold stan-dard for the evaluation of automatically compiled lexi-cal resources for opinion mining.
In Andrea Sanso,editor, Language resources and linguistic theory: Ty-pology, second language acquisition, pages 200?210.Franco Angeli Editore, Milano, IT.Ferm?
?n L. Cruz, Jose?
A. Troyano, F. Javier Ortega, andFernando Enr??quez.
2011.
Automatic expansionof feature-level opinion lexicons.
In Proceedings ofthe 2nd Workshop on Computational Approaches toSubjectivity and Sentiment Analysis, pages 125?131,Portland, Oregon, June.Eduard Dragut, Hong Wang, Clement Yu, Prasad Sistla,and Weiyi Meng.
2012.
Polarity consistency check-ing for sentiment dictionaries.
In Proceedings of the50th Annual Meeting of the Association for Compu-tational Linguistics (Volume 1: Long Papers), pages997?1005, Jeju Island, Korea, July.
Association forComputational Linguistics.Andrea Esuli and Fabrizio Sebastiani.
2006.
Determin-ing term subjectivity and term orientation for opinionmining.
In Proceedings of EACL, pages 193?200,Trento, Italy.Leo A. Goodman.
1965.
On Simultaneous ConfidenceIntervals for Multinomial Proportions.
Technometrics,7(2):247?254.Yaw Gyamfi, Janyce Wiebe, Rada Mihalcea, and CemAkkaya.
2009.
Integrating knowledge for subjectivitysense labeling.
In Proceedings of NAACL, pages 10?18, Boulder, CO.Mark Hall, Eibe Frank, Geoffrey Holmes, BernhardPfahringer, Peter Reutemann, and Ian H. Witten.2009.
The WEKA Data Mining Software: An Update.SIGKDD Explorations, 11.Vasileios Hatzivassiloglou and Kathleen McKeown.1997.
Predicting the semantic orientation of adjec-tives.
In Proceedings of ACL, pages 174?181, Madrid,Spain.Minqing Hu and Bing Liu.
2004.
Mining andsummarizing customer reviews.
In Proceedings ofACM SIGKDD International Conference on Knowl-edge Discovery and Data Mining, pages 168?177,Seattle, WA.Valentin Jijkoun and Katja Hofmann.
2009.
Gener-ating a Non-English Subjectivity Lexicon: RelationsThat Matter.
In Proceedings of EACL, pages 398?405,Athens, Greece.Jaap Kamps, Maarten Marx, Robert Mokken, andMaarten de Rijke.
2004.
Using WordNet to measuresemantic orientation of adjectives.
In Proceedings ofLREC, pages 1115?1118, Lisbon, Portugal.Hiroshi Kanayama and Tetsuya Nasukawa.
2006.
Fullyautomatic Lexicon Expansion for Domain-orientedSentiment Analysis.
In Proceedings of EMNLP, pages355?363, Syndey, Australia.Soo-Min Kim and Edward Hovy.
2004.
Determining thesentiment of opinions.
In Proceedings of COLING,pages 1367?1373, Geneva, Switzerland.Philip Koehn.
2005.
EUROPARL: A Parallel corpus forStatistical Machine Translation.
In Proceedings of theMachine Translation Summit.Dekang Lin.
1998.
Automatic retrieval and clustering ofsimilar words.
In Proceedings of ACL, pages 768?774,Montreal, Canada.Tim Loughran and Bill McDonald.
2011.
When is a Li-ability not a Liability?
Textual Analysis, Dictionaries,and 10-Ks.
Journal of Finance, 66:35?65.Nitin Madnani and Bonnie Dorr.
2013.
Generating Tar-geted Paraphrases for Improved Translation.
ACMTransactions on Intelligent Systems and Technology, toappear.Rada Mihalcea, Carmen Banea, and Janyce Wiebe.
2007.Learning multilingual subjective language via cross-lingual projections.
In Proceedings of ACL, pages976?983, Prague, Czech Republic.George Miller.
1995.
WordNet: A lexical database.Communications of the ACM, 38:39?41.Saif Mohammad, Cody Dunne, and Bonnie Dorr.
2009.Generating high-coverage semantic orientation lexi-cons from overtly marked words and a thesaurus.
InProceedings of EMNLP, pages 599?608, Singapore,August.Guillaume Pitel and Gregory Grefenstette.
2008.
Semi-automatic building method for a multidimensional af-fect dictionary for a new language.
In Proceedings ofLREC, Marrakech, Morocco.Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen.
2009.Expanding domain sentiment lexicon through doublepropagation.
In Proceedings of the 21st internationaljont conference on Artifical intelligence, IJCAI?09,pages 1199?1204.C.
Quesenberry and D. Hurst.
1964.
Large sample si-multaneous confidence intervals for multinomial pro-portions.
Technometrics, 6:191?195.J.
R. Quinlan.
1993.
C4.5: Programs for machine lear-ning.
Morgan Kaufmann Publishers.Delip Rao and Deepak Ravichandran.
2009.
Semi-supervised polarity lexicon induction.
In Proceedingsof EACL, pages 675?682, Athens.109Philip Stone, Dexter Dunphy, Marshall Smith, and DanielOgilvie.
1966.
The General Inquirer: A ComputerApproach to Content Analysis.
MIT Press.Carlo Strapparava and Alessandro Valitutti.
2004.WordNet-affect: an affective extension of WordNet.In Proceedings of LREC, pages 1083?1086, Lisbon,Portugal.Fangzhong Su and Katja Markert.
2008.
ElicitingSubjectivity and Polarity Judgements on Word Senses.In Proceedings of COLING, pages 825?832, Manch-ester, UK.P.
Subasic and A. Huettner.
2001.
Affect analysis of textusing fuzzy semantic typing.
IEEE Transactions onFuzzy Systems, 9(4).Maite Taboada, Julian Brooke, Milan Tofiloski, Kim-berly Voll, and Manfred Stede.
2011.
Lexicon-BasedMethod for Sentiment Analysis.
Computational Lin-guistics, 37(2):267?307.Hiroya Takamura, Takashi Inui, and Manabu Okumura.2005.
Extracting semantic orientation of words usingspin model.
In Proceedings of ACL, pages 133?140,Ann Arbor, MI.Mike Thelwall, Kevan Buckley, Georgios Paltoglou,Di Cai, and Arvid Kappas.
2010.
Sentiment strengthdetection in short informal text.
Journal of the Amer-ican Society for Information Science and Technology,61(12):2544?2558.Kristina Toutanova, Dan Klein, Christopher Manning,and Yoram Singer.
2003.
Feature-Rich Part-of-Speech Tagging with a Cyclic Dependency Network.In Proceedings of HLT-NAACL, pages 252?259.Peter Turney and Michael Littman.
2003.
Measuringpraise and criticism: Inference of semantic orientationfrom association.
ACM Transactions on InformationSystems, 21(4):315346.Leonid Velikovich, Sasha Blair-Goldensohn, Kerry Han-nan, and Ryan McDonald.
2010.
The viability ofWeb-derived polarity lexicons.
In Proceedings ofNAACL, pages 777?785, Los Angeles, CA.Janyce Wiebe and Rada Mihalcea.
2006.
Word senseand subjectivity.
In Proceedings of ACL, pages 1065?1072, Sydney, Australia.Janyce Wiebe and Ellen Riloff.
2005.
Creating subjec-tive and objective sentence classifiers from unanno-tated texts.
In Proceedings of CICLING (invited pa-per), pages 486?497, Mexico City.110
