Exploiting Paraphrases in a Question Answering SystemFabio Rinaldi, James Dowdall,Kaarel Kaljurand, Michael HessInstitute of Computational Linguistics,University of Zu?richWinterthurerstrasse 190CH-8057 Zu?rich, Switzerland{rinaldi,dowdall,kalju,hess}@ifi.unizh.chDiego Molla?Centre for Language Technology,Macquarie University,Sydney NSW 2109, Australia{diego}@ics.mq.edu.auAbstractWe present a Question Answering systemfor technical domains which makes an in-telligent use of paraphrases to increase thelikelihood of finding the answer to the user?squestion.
The system implements a simpleand efficient logic representation of ques-tions and answers that maps paraphrasesto the same underlying semantic represen-tation.
Further, paraphrases of technicalterminology are dealt with by a separateprocess that detects surface variants.1 IntroductionThe problem of paraphrases conceals a number ofdifferent linguistic problems, which in our opinionneed to be treated in separate ways.
In fact, para-phrases can happen at various levels in language.
Us-ing the examples provided in the call for papers forthis workshop, we would like to attempt a simpleclassification, without any pretense of being exhaus-tive:1.
Lexical synonymy.Example: article, paper, publication2.
Morpho-syntactic variants.a) Oswald killed Kennedy.
/ Kennedy was killedby Oswald.b) Edison invented the light bulb.
/ Edison?sinvention of the light bulb.while (a) is purely syntactical (active vs pas-sive), (b) involves a nominalisation.3.
PP-attachment.a plant in Alabama / the Alabama plant4.
Comparatives vs superlatives.be better than anybody else / be the best5.
Subordinate clauses vs separate sentences linkedby anaphoric pronouns.The tree healed its wounds by growing new bark./ The tree healed its wounds.
It grew new bark.6.
Inference.The stapler costs $10.
/ The price of the stapleris $10.Where is Thimphu located?
/ Thimphu is capi-tal of what country?Of course combinations of the different types arepossible, e.g.
Oswald killed Kennedy / Kennedywas assassinated by Oswald is a combination of (1)and (2).Different types of knowledge and different linguis-tic resources are needed to deal with each of theabove types.
While type (1) can be dealt with us-ing a resource such as WordNet (Fellbaum, 1998),type (2) needs effective parsing and mapping of syn-tactic structures into a common deeper structure,possibly using a repository of nominalisations likeNOMLEX (Meyers et al, 1998).
More complexapproaches are needed for the other types, up totype (6) where generic world knowledge is required,for instance to know that being a capital of a countryimplies being located in that country.
1 Such worldknowledge could be expressed in the form of axioms,like the following:(X costs Y) iff (the price of X is Y)In this paper we focus on the role of paraphrasesin a Question Answering (QA) system targeted at1Note that the reverse is not true, and therefore thisis not a perfect paraphrase.technical manuals.
Technical documentation is char-acterised by vast amounts of domain-specific termi-nology, which needs to be exploited for providing in-telligent access to the information contained in themanuals (Rinaldi et al, 2002b).
The approach takenby QA systems is to allow a user to ask a query (for-mulated in natural language) and have the systemsearch a background collection of documents in orderto locate an answer.
The field of Question Answer-ing has flourished in recent years2, in part, due tothe QA track of the TREC competitions (Voorheesand Harman, 2001).
These competitions evaluatesystems over a common data set alowing develop-ers to benchmark performance in relation to othercompetitors.It is a common assumption that technical termi-nology is subject to strict controls and cannot varywithin a given editing process.
However this assump-tion proves all too often to be incorrect.
Unless edi-tors are making use of a terminology control systemthat forces them to use a specific version of a term,they will naturally tend to use various paraphrasesto refer to the intended domain concept.
Besides ina query a user could use an arbitrary paraphrases ofthe target term, which might happen to be one ofthose used in the manual itself or might happen tobe a novel one.We describe some potential solutions to this prob-lem, taking our Question Answering system as an ex-ample.
We show which benefits our approach basedon paraphrases bring to the system.
So far two dif-ferent domains have been targeted by the system.An initial application aims at answering questionsabout the Unix man pages (Molla?
et al, 2000a; Molla?et al, 2000b).
A more complex application targetsthe Aircraft Maintenance Manual (AMM) of the Air-bus A320 (Rinaldi et al, 2002b).
Recently we havestarted new work, using the Linux HOWTOs as anew target domain.In dealing with these domains we have identifiedtwo major obstacles for a QA system, which we cansummarise as follows:?
The Parsing Problem?
The Paraphrase ProblemThe Parsing Problem consists in the increaseddifficulty of parsing text in a technical domain due todomain-specific sublanguage.
Various types of multiword expressions characterise these domains, in par-ticular referring to specific concepts like tools, partsor procedures.
These multi word expressions might2Although early work in AI already touched upon thetopic, e.g.
(Woods, 1977).include lexical items which are either unknown toa generic lexicon (e.g.
coax cable) or have a spe-cific meaning unique to this domain.
Abbreviationsand acronyms are another common source of incon-sistencies.
In such cases the parser might eitherfail to identify the compound as a phrase and con-sequently fail to parse the sentence including suchitems.
Alternatively the parser might attempt to?guess?
their lexical category (in the set of open classcategories), leading to an exponential growth of thenumber of possible syntactic parses.
Not only the in-ternal structure of the compound can be multi-wayambiguous, even the boundaries of the compoundsmight be difficult to detect and the parsers mighttry odd combinations of the tokens belonging to thecompounds with neighbouring tokens.The Paraphrase Problem resides in the imper-fect knowledge of users of the systems, who can-not be expected to be completely familiar with thedomain terminology.
Even experienced users, whoknow very well the domain, might not remember theexact wording of a compound and use a paraphraseto refer to the underlying domain concept.
Besideseven in the manual itself, unless the editors have beenforced to use some strict terminology control system,various paraphrases of the same compound will ap-pear, and they need to be identified as co-referent.However, it is not enough to identify all paraphraseswithin the manual, novel paraphrases might be cre-ated by the users each time they query the system.In the rest of this paper we describe first our Ques-tion Answering System (in Section 2) and brieflyshow how we solved the first of the two problemsdescribed above.
Then, in Section 3 we show in de-tail how the system is capable of coping with theParaphrase Problem.
Finally in Section 4 we discusssome related work.2 A Question Answering System forTechnical DomainsOver the past few years our research group has devel-oped an Answer Extraction system (ExtrAns) thatworks by transforming documents and queries into asemantic representation called Minimal Logical Form(MLF) (Molla?
et al, 2000a) and derives the answersby logical proof from the documents.
A full linguis-tic (syntactic and semantic) analysis, complete withlexical alternations (synonyms and hyponyms) is per-formed.
While documents are processed in an off-linestage, the query is processed on-line.Two real world applications have so far been im-plemented with the same underlying technology.
Theoriginal ExtrAns system (Molla?
et al, 2000b) is used///// a.d electrical coax cable.n4 connects.v062 the.d external antenna.n1 to.o the.d ANT connection.n1 /////-Wdff Dsu ff Ss-MVp-Osff Ds-Jsff DsRWFigure 1: An Example of LG Outputto extract answers to arbitrary user queries over theUnix documentation files (?man pages?).
A set of500+ unedited man pages has been used for this ap-plication.
An on-line demo of ExtrAns can be foundat the project web page.3KnowledgeBaseDocumentLinguisticAnalysisTermprocessingFigure 2: Off-lineProcessing of Docu-mentsMore recently we tackleda different domain, the Air-plane Maintenance Manu-als (AMM) of the Air-bus A320 (Rinaldi et al,2002b), which offered theadditional challenges of anSGML-based format and amuch larger size (120MB).4Despite being developedinitially for a specific do-main, ExtrAns has demon-strated a high level of do-main independence.As we work on relativelysmall volumes of data wecan afford to process (inan off-line stage) all thedocuments in our collectionrather than just a few se-lected paragraphs (see Fig-ure 2).
Clearly in some sit-uations (e.g.
processing in-coming news) such an ap-proach might not be fea-sible and paragraph index-ing techniques would needto be used.
Our current ap-proach is particularly tar-geted to small and medium sized collections.In an initial phase all multi-word expressionsfrom the domain are collected and structured inan external resource, which we will refer to as theTermBase (Rinaldi et al, 2003; Dowdall et al, 2003).The document sentences (and user queries) are syn-tactically processed with the Link Grammar (LG)parser (Sleator and Temperley, 1993) which uses a3http://www.ifi.unizh.ch/cl/extrans/4Still considerably smaller than the size of the docu-ment collections used for TRECgrammar with a wide coverage of English and hasa robust treatment of ungrammatical sentences andunknown words.
The multi-word terms from the the-saurus are identified and passed to the parser as sin-gle tokens.
This prevents (futile) analysis of the in-ternal structure of terms (see Figure 1), simplifyingparsing by 46%.
This solves the first of the problemsthat we have identified in the introduction (?TheParsing Problem?
).In later stages of processing, a corpus-based ap-proach (Brill and Resnik, 1994) is used to deal withambiguities that cannot be solved with syntactic in-formation only, in particular attachments of preposi-tional phrases, gerunds and infinitive constructions.ExtrAns adopts an anaphora resolution algorithm(Molla?
et al, 2003) that is based on Lappin and Le-ass?
approach (Lappin and Leass, 1994).
The originalalgorithm, which was applied to the syntactic struc-tures generated by McCord?s Slot Grammar (Mc-Cord et al, 1992), has been ported to the output ofLink Grammar.
So far the resolution is restricted tosentence-internal pronouns but the same algorithmcan be applied to sentence-external pronouns too.A lexicon of nominalisations based on NOMLEX(Meyers et al, 1998) is used for the most importantcases.
The main problem here is that the semanticrelationship between the base words (mostly, but notexclusively, verbs) and the derived words (mostly,but not exclusively, nouns) is not sufficiently sys-tematic to allow a derivation lexicon to be compiledautomatically.
Only in relatively rare cases is therelationship as simple as with to edit <a text> ?editor of <a text> / <text> editor, as the effortthat went into building resources such as NOMLEXalso shows.User queries are processed on-line and convertedinto MLFs (possibly expanded by synonyms) andproved by refutation over the document knowledgebase (see Figure 3).
Pointers to the original text at-tached to the retrieved logical forms allow the systemto identify and highlight those words in the retrievedsentence that contribute most to that particular an-swer.
When the user clicks on one of the answersprovided, the corresponding document will be dis-played with the relevant passages highlighted.KnowledgeBaseANSWERSQueryDocumentLinguisticAnalysisParaphraseIdentificationFigure 3: On-line Processing of QueriesThe meaning of the documents and of the queriesproduced by ExtrAns is expressed by means of Mini-mal Logical Forms (MLFs).
The MLFs are designedso that they can be found for any sentence (usingrobust approaches to treat very complex or ungram-matical sentences), and they are optimized for NLPtasks that involve the semantic comparison of sen-tences, such as Answer Extraction.The expressivity of the MLFs is minimal in thesense that the main syntactic dependencies betweenthe words are used to express verb-argument rela-tions, and modifier and adjunct relations.
However,complex quantification, tense and aspect, temporalrelations, plurality, and modality are not expressed.One of the effects of this kind of underspecificationis that several natural language queries, althoughslightly different in meaning, produce the same logi-cal form.The main feature of the MLFs is the use of reifi-cation (the expression of abstract concepts as con-crete objects) to achieve flat expressions (Molla?
etal., 2000b).
The MLFs are expressed as conjunc-tions of predicates with all the variables existentiallybound with wide scope.
For example, the MLF ofthe sentence ?cp will quickly copy the files?
is:(1) holds(e4), object(cp,o1,[x1]),object(s command,o2,[x1]),evt(s copy,e4,[x1,x6]),object(s file,o3,[x6]),prop(quickly,p3,[e4]).In other words, there is an entity x1 which rep-resents an object of type cp and of type command,there is an entity x6 (a file), there is an entity e4,which represents a copying event where the first ar-gument is x1 and the second argument is x6, thereis an entity p3 which states that e4 is done quickly,and the event e4, that is, the copying, holds.
Theentities o1, o2, o3, e4, and p3 are the result of reifi-cation.
The reification of the event, e4, has been usedto express that the event is done quickly.
The otherentities are not used in this MLF, but other morecomplex sentences may need to refer to the reifica-tion of properties (adjective-modifying adverbs) orobject predicates (non-intersective adjectives such asthe alleged suspect).ExtrAns finds the answers to the questions byforming the MLFs of the questions and then run-ning Prolog?s default resolution mechanism to findthose MLFs that can prove the question.
When nodirect proof for the user query is found, the systemis capable of relaxing the proof criteria in a stepwisemanner.
First, hyponyms of the query terms will beadded as disjunctions in the logical form of the ques-tion, thus making it more general but still logicallycorrect.
If that fails, the system will attempt approx-imate matching, in which the sentence (or sentences)with the highest overlap of predicates with the queryis retrieved.
The (partially) matching sentences arescored and the best fits are returned.
In the casethat this method finds too many answers becausethe overlap is too low, the system will attempt key-word matching, in which syntactic criteria are aban-doned and only information about word classes isused.
This last step corresponds approximately to atraditional passage-retrieval methodology with con-sideration of the POS tags.3 Dealing with ParaphrasesThe system is capable of dealing with paraphrasesat two different levels.
On the phrase level, differ-ent surface realizations (terms) which refer to thesame domain concept will be mapped into a com-mon identifier (synset identifier).
On the sentencelevel, paraphrases which involve a (simple) syntactictransformation will be dealt with by mapping theminto the same logical form.
In this section we willdescribe these two approaches and discuss ways tocope with complex types of parapharases.3.1 Identifying Terminological ParaphrasesDuring the construction of the MLFs, thesaurusterms are replaced by their synset identifiers.
Thisresults in an implicit ?terminological normalization?for the domain.
The benefit to the QA process isan assurance that a query and answer need not in-volve exactly the same surface realization of a term.Utilizing the synsets in the semantic representationmeans that when the query includes a term, ExtrAnsreturns sentences that logically answer the query, in-FastrTermExtractionHyponymyThesaurus ExtrAnsDocumentFigure 4: Term Processingvolving any known paraphrase of that term.For example, the logical form of the query Whereare the stowage compartments installed?
is trans-lated internally into the Horn query (2).
(2) evt(install,A,[B,C]),object(D,E,[B]),object(s stowage compartment,G,[C])This means that a term (belonging to the samesynset as stowage compartment) is involved in an in-stall event with an anonymous object.
If there isan MLF from the document that can match exam-ple (2), then it is selected as a candidate answer andthe sentence it originates from is shown to the user.The process of terminological variation is wellinvestigated (Ibekwe-SanJuan and Dubois, 2002;Daille et al, 1996; Ibekwe-Sanjuan, 1998).
Theprimary focus has been to use linguistically basedvariation to expand existing term sets through cor-pus investigation or to produce domain representa-tions.
A subset of such variations identifies termswhich are strictly synonymous.
ExtrAns gathersthese morpho-syntactic variations into synsets.
Thesets are augmented with terms exhibiting threeweaker synonymy relations described by Hamon &Nazarenko (2001).
These synsets are organized intoa hyponymy (isa) hierarchy, a small example of whichcan be seen in Figure 5.
Figure 4 shows a schematicrepresentation of this process.The first stage is to normalize any terms that con-tain punctuation by creating a punctuation free ver-sion and recording the fact that that the two arestrictly synonymous.
Further processing is involvedin terms containing brackets to determine if thebracketed token is an acronym or simply optional.
Inthe former case an acronym-free term is created andthe acronym is stored as a synonym of the remain-ing tokens which contain it as a regular expression.So evac is synonymous with evacuation and ohsc issynonymous with overhead stowage compartment.
Incases such as emergency (hard landings) the brack-eted tokens can not be interpreted as acronyms andso are not removed.The synonymy relations are identified using theterminology tool Fastr (Jacquemin, 2001).
Every to-ken of each term is associated with its part-of-speech,its morphological root, and its synonyms.
Phrasalrules represent the manner in which tokens combineto form multi-token terms, and feature-value pairscarry the token specific information.
Metarules li-cense the relation between two terms by constrain-ing their phrase structures in conjunction with themorphological and semantic information on the indi-vidual tokens.The metarules can identify simple paraphrasesthat result from morpho-syntactic variation (cargocompartment door ??
doors of the cargo compart-ment), terms with synonymous heads (electrical ca-ble ??
electrical line), terms with synonymous mod-ifiers (fastener strip ??
attachment strip) and both(functional test ??
operational check).
For a de-scription of the frequency and range of types of vari-ation present in the AMM see Rinaldi et al (2002a).3.2 Identifying Syntactic ParaphrasesAn important effect of using a simplified semantic-based representation such as the Minimal LogicalForms is that various types of syntactic variationsare automatically captured by a common representa-tion.
This ensures that many potential paraphrasesin a user query can map to the same answer into themanual.For example the question shown in Figure 6 canbe answered thanks to the combination of two fac-tors.
On the lexical level ExtrAns knows that APUis an abbreviation of Auxiliary Power Unit, while onthe syntactic level the active and passive voices (sup-plies vs supplied with) map into the same underlyingrepresentation (the same MLF).Another type of paraphrase which can be detectedat this level is the kind that was classified as type (3)in the introduction.
For example the question: Isthe sensor connected to the APU ECB?, can locatethe answer This sensor is connected to the Elec-tronic Control Box (ECB) of the APU.
This has beenachieved by introducing meaning postulates that op-erate at the level of the MLFs (such as ?any predicatethat affects an object will also affect the of -modifiersof that object?
).3.3 Weaker Types of ParaphrasesWhen the thesaurus definition of terminological syn-onymy fails to locate an answer from the docu-ment collection, ExtrAns explores weaker types ofparaphrases, where the equivalence between the twoterms might not be complete.TERMdoors of the cargo compartmentcargo compartment doorcargo comparment doorscargo-compartment dooremergency ( hard landings )emergency hard landingsemergency hard landingemergency evacuation (evac)emergency evacuationevacuationevacelectrical cableelectrical linefastner stripattachment stripfunctional testoperational checkdoor functional teststowage compartmentoverhead stowage compartmentOHSC123567109811Figure 5: A Sample of the TermBaseFigure 6: Active vs Passive VoiceFirst, ExtrAns makes use of the hyponymy rela-tions, which can be considered as sort of unidirec-tional paraphrases.
Instead of looking for synsetmembers, the query is reformulated to included hy-ponyms and hyperonyms of the terms:(3) (object(s stowage compartment,A,[B]);object(s overhead stowage compartment,A,[B])),evt(install,C,[D,B]),object(E,F,[D|G])Now the alternative objects are in a logical OR rela-tion.
This query finds the answer in Figure 7 (wherestowage compartment is a hyperonym of overheadstowage compartment).We have implemented a very simple ad-hoc algo-rithm to determine lexical hyponymy between terms.Term A is a hyponym of term B if (i) A has more to-kens than B, (ii) all the tokens of B are present in A,and (iii) both terms have the same head.
There arethree provisions.
First, ignore terms with dashes andbrackets as cargo compartment is not a hyponym ofcargo - compartment and this relation (synonymy) isalready known from the normalisation process.
Sec-ond, compare lemmatised versions of the terms tocapture that stowage compartment is a hyperonymof overhead stowage compartments.
Finally, the headof a term is the rightmost non-symbol token (i.e.
aword) which can be determined from the part-of-speech tags.
This hyponymy relation is compara-ble to the insertion variations defined by Daille etal.
(1996).The expressivity of the MLF can further be ex-panded through the use of meaning postulates of thetype: ?If x is installed in y, then x is in y?.
Thisensures that the query Where are the equipment andfurnishings?
extracts the answer The equipment andfurnishings are installed in the cockpit.4 Related WorkThe importance of detecting paraphrasing in Ques-tion Answering has been shown dramatically inTREC9 by the Falcon system (Harabagiu et al,2001), which made use of an ad-hoc module capableof caching answers and detecting question similar-ity.
As in that particular evaluation the organisersdeliberately used a set of paraphrases of the samequestions, such approach certainly helped in boost-ing the performance of the system.
In an environ-ment where the same question (in different formula-tions) is likely to be repeated a number of times, amodule capable of detecting paraphrases can signif-icantly improve the performance of a Question An-Figure 7: Overhead stowage compartment is a Hyponym of Stowage compartmentswering system.Another example of application of paraphrases forQuestion Answering is given in (Murata and Isahara,2001), which further argues for the importance ofparaphrases for other applications such Summarisa-tion, error correction and speech generation.Our approach for the acquisition of terminologicalparaphrases might have some points in common withthe approach described in (Terada and Tokunaga,2001).
The motivation that they bring forward forthe necessity of identifying abbreviations is related tothe problem that we have called ?the Parsing Prob-lem?.A very different approach to paraphrases is takenin (Takahashi et al, 2001) where they formulate theproblem as a special case of Machine Translation,where the source and target language are the samebut special rules, based on different parameters, li-cense different types of surface realizations.Hamon & Nazarenko (2001) explore the termino-logical needs of consulting systems.
This type of IRguides the user in query/keyword expansion or pro-poses various levels of access into the document baseon the original query.
A method of generating threetypes of synonymy relations is investigated using gen-eral language and domain specific dictionaries.5 ConclusionAutomatic recognition of paraphrases is an effec-tive technique to ease the information access bur-den in a technical domain.
We have presented sometechniques that we have adopted in a Question An-swering system for dealing with paraphrases.
Thesetechniques range from the detection of lexical para-phrases and terminology variants, to the use of asimplified logical form that provides the same repre-sentation for morpho-syntactic paraphrases, and theuse of meaning postulates for paraphrases that re-quire inferences.ReferencesEric Brill and Philip Resnik.
1994.
A rule-basedapproach to prepositional phrase attachment dis-ambiguation.
In Proc.
COLING ?94, volume 2,pages 998?1004, Kyoto, Japan.Beatrice Daille, Benot Habert, Christian Jacquemin,and Jean Royaute?.
1996.
Empirical observation ofterm variations and principles for their description.Terminology, 3(2):197?258.James Dowdall, Fabio Rinaldi, Fidelia Ibekwe-SanJuan, and Eric SanJuan.
2003.
Complexstructuring of term variants for Question Answer-ing.
In Proc.
ACL-2003 Workshop on MultiwordExpressions, Sapporo, Japan.Christiane Fellbaum 1998.
WordNet: an electroniclexical database.
MIT Press, Cambridge, MA.Thierry Hamon and Adeline Nazarenko.
2001.
De-tection of synonymy links between terms: Experi-ment and results.
In Didier Bourigault, ChristianJacquemin, and Marie-Claude L?Homme, editors,Recent Advances in Computational Terminology,pages 185?208.
John Benjamins Publishing Com-pany.Sanda Harabagiu, Dan Moldovan, Marius Pas?ca,Rada Mihalcea, Mihai Surdeanu, Razvan Bunescu,Roxana G?
?rju, Vasile Rus, and Paul Morarescu.2001.
Falcon: Boosting knowledge for answerengines.
In Voorhees and Harman (Voorhees andHarman, 2001).Fidelia Ibekwe-SanJuan and Cyrille Dubois.
2002.Can Syntactic Variations Highlight SemanticLinks Between Domain Topics?
In Proceedingsof the 6th International Conference on Terminol-ogy and Knowledge Engineering (TKE02), pages57?64, Nancy, August.Fidelia Ibekwe-Sanjuan.
1998.
Terminological Vari-ation, a Means of Identifying Research Topics fromTexts.
In Proceedings of COLING-ACL, pages571?577, Quebec,Canada, August.Christian Jacquemin.
2001.
Spotting and Discover-ing Terms through Natural Language Processing.MIT Press.Shalom Lappin and Herbert J. Leass.
1994.
An algo-rithm for pronominal anaphora resolution.
Com-putational Linguistics, 20(4):535?561.Michael McCord, Arendse Bernth, Shalom Lap-pin, and Wlodek Zadrozny.
1992.
Natural lan-guage processing within a slot grammar frame-work.
International Journal on Artificial Intelli-gence Tools, 1(2):229?277.Adam Meyers, Catherine Macleod, Roman Yangar-ber, Ralph Grishman, Leslie Barrett, and RuthReeves.
1998.
Using NOMLEX to producenominalization patterns for information extrac-tion.
In Proceedings: the Computational Treat-ment of Nominals, Montreal, Canada, (Coling-ACL98 workshop), August.Diego Molla?, Gerold Schneider, Rolf Schwitter, andMichael Hess.
2000a.
Answer Extraction usinga Dependency Grammar in ExtrAns.
TraitementAutomatique de Langues (T.A.L.
), Special Issueon Dependency Grammar, 41(1):127?156.Diego Molla?, Rolf Schwitter, Michael Hess, andRachel Fournier.
2000b.
Extrans, an answer ex-traction system.
T.A.L.
special issue on Informa-tion Retrieval oriented Natural Language Process-ing.Diego Molla?, Rolf Schwitter, Fabio Rinaldi, JamesDowdall, and Michael Hess.
2003.
Anaphora res-olution in ExtrAns.
In Proceedings of the Interna-tional Symposium on Reference Resolution and ItsApplications to Question Answering and Summa-rization, 23?25 June, Venice, Italy.Masaki Murata and Hitoshi Isahara.
2001.
Univer-sal model for paraphrasing - using transformationbased on a defined criteria.
In Proceedings of theNLPRS2001 Workshop on Automatic Paraphras-ing: Theories and Applications.Fabio Rinaldi, James Dowdall, Michael Hess, KaarelKaljurand, Mare Koit, Kadri Vider, and NeemeKahusk.
2002a.
Terminology as Knowledge in An-swer Extraction.
In Proceedings of the 6th Interna-tional Conference on Terminology and KnowledgeEngineering (TKE02), pages 107?113, Nancy, 28?30 August.Fabio Rinaldi, James Dowdall, Michael Hess, DiegoMolla?, and Rolf Schwitter.
2002b.
Towards An-swer Extraction: an application to Technical Do-mains.
In ECAI2002, European Conference on Ar-tificial Intelligence, Lyon, 21?26 July.Fabio Rinaldi, James Dowdall, Michael Hess, KaarelKaljurand, and Magnus Karlsson.
2003.
The Roleof Technical Terminology in Question Answering.In Proceedings of TIA-2003, Terminologie et In-telligence Artificielle, Strasbourg, April.Daniel D. Sleator and Davy Temperley.
1993.
Pars-ing English with a link grammar.
In Proc.
ThirdInternational Workshop on Parsing Technologies,pages 277?292.Tetsuro Takahashi, Tomoya Iwakura, Ryu Iida, andKentaro Inui.
2001.
Kura: A revision-basedlexico-structural paraphrasing engine.
In Proceed-ings of the NLPRS2001 Workshop on AutomaticParaphrasing: Theories and Applications.Akira Terada and Takenobu Tokunaga.
2001.
Au-tomatic disabbreviation by using context informa-tion.
In Proceedings of the NLPRS2001 Workshopon Automatic Paraphrasing: Theories and Appli-cations.Ellen M. Voorhees and Donna Harman, editors.2001.
Proceedings of the Ninth Text REtrievalConference (TREC-9), Gaithersburg, Maryland,November 13-16, 2000.W.A.
Woods.
1977.
Lunar rocks in natural English:Explorations in Natural Language Question An-swering.
In A. Zampolli, editor, Linguistic Struc-tures Processing, volume 5 of Fundamental Studiesin Computer Science, pages 521?569.
North Hol-land.
