USC :Description of the SNAP System Used for MUC- 4D.
Moldovan, S .
Chet, M. Chung, K. Hendrickson, J. Kim, and S .
KowalskiParallel Knowledge Processing Laborator yUniversity of Southern Californi aLos Angeles, California 90089-2562moldovan@gringo .usc.edu(213)740-4477INTRODUCTIONBackgroun dThe main goal of the SNAP project is to build a massively parallel computer capable of fast and accurat enatural language processing [3] .
Under NSF funding, a parallel computer was built in the Parallel Knowledg eProcessing Laboratory at USC and software was developed to operate the machine [2] .
The approach i ndesigning SNAP was to find a knowledge representation and a reasoning paradigm useful for natural languag eprocessing which exibits massive parallelism .
We have selected marker-passing on semantic networks as away to represent and process linguistic knowledge .The work for MUC-4 started at the end of January 1992 .
Prior to this we had implemented on SNAP asimple parsing system accompanied by a small knowledge base .
When we started the MUC-4 effort we ha donly vague ideas how to implement large semantic network knowledge bases for linguistic processing .
Thusfor us MUC-4 was a major undertaking and soon we realized the difficulties and the time limitation .
Facedwith the MUG4 challenge, our group consisting of one faculty and five graduate students spent approxi-mately 1450 hours to engineer a large system .ApproachThe underlying ideas of the SNAP natural language processing system are : (1) memory based parsing, and(2) marker passing on semantic networks [4] .
In SNAP, parsing becomes a guided search over the knowledg ebase which stores linguistic information .
Input words activate and predict concepts in the knowledge base .While the semantic network represents the static part of the knowledge base, marker passing is the mechanis mwhich changes the state of the knowledge base with each new word .SYSTEM ARCHITECTUR EThe SNAP architecture is shown in Figure 1 .SUN HostSNAP Controller& ArmyText-i-3 PreprocessorPhrasalMemory basedgeneratorTemplate sparserparSCrKnowledg ebase..Figure 1 : SNAP text understanding system .296input sentence Si :SALVADORAN PRESIDENT-ELECT ALFREDO CRISTIANI CONDEMNED THE TERRORIST KILLING OF ATTORNEY GENERA LROBERTO GARCIA ALVARADO AND ACCUSED THE FARABUNDO MAR11 NATIONAL LIBERATION FRONT (FMLN) OF THE CRIM Eresults of preliminary preprocessing :SALVADORAN PRESIDENT_ELECT AIFREDO_CRISTIANI CONDEMNED THE TERRORIST KILLING OF ATTORNEY_GENERALROBERTO GARCIA ALVARADO AND ACCUSED THE FARABUNDO MARILNATIONAL LIBERATION .RONT (FMLN) OF THE CRIME.preprocessor output :PRESIDENT_ELECTcommon-noun PRESIDENTELECT sg GOVERNMENT-OFFICIA LALFREDO_CRISTIANIproper-noun ALFREDO_CRISTIANI sg HUMAN-NAMEACCUSEDverb ACCUSE pp 1FMLN2proper-noun FMLN sg FMLNproper-noun FMLN sg ORGANIZATIONphrasal parser output :[SALVADORAN PRESIDENTELECT ALFREDO_CRISTIAN44p [CONDEMNEDIvERB_sEQ ITHU TERRORIS RULING),, [OF) .
,[ATTORNEY GENERAL ROBERTO GARCIA ALVARADO],, [ANDIco Nn,p,,,.,,o, [ACCUSEDIvERB sr[7HEEARABUNDO MAR1I_NATIONAL LIBERATION_FRONTINp [OF)pp noN [THE CR1ME]?e [ .IpUNcit,A1oNFigure 2: Preprocessor and phrasal parser outputs for the first sentence of TST2-MUC4-0048 .PREPROCESSO RPreprocessor Purpose and Requirement sIn the memory based parsing, the knowledge base memory must be used to the greatest possible ad-vantage .
For this reason, it was decided to move part of the natural language knowledge base, namely thelexical information, out of the SNAP memory, in order to use SNAP memory for parsing and inferencing .This also necessitates moving the dictionary look-up function for words out of SNAP, and prior to SNA Pprocessing.
There were other requirements levied on the preprocessor as well : the preprocessor should rec-ognize previously known noun phrases, a number of contractions and also a number of semi-auxiliary verbs .The preprocessor should detect and block off paragraphs, individual sentence boundaries, and the messag eheaders .Example of PreprocessingAn intermediate form generated by the preprocessor for S1 of message TST2-0048 is shown in Figure 2 .This is before looking up each word in the dictionary .
It is not possible to show here, but the preprocesso rconcatenated all the words of this sentence onto one line .
As can be seen, noun phrases like PRESIDENT_ELECTand ALFREDO_CRISTIANI were grouped together into single words .
These single words also have correspondingentries in the preprocessor dictionary.
By grouping well known noun phrases, including well known huma nnames, a considerable load is removed from the parser .
In addition to grouping noun phrases, the preprocesso ralso groups semi-auxiliary verbs like USED_TO, prepositional phrases like SUCH_AS and AS_TO, and converts297contractions like CAN 'T and DON 'T into CAN NOT and DO NOT .
The preprocessor also separates punctuatio nmarkers from the words they are attached to .
This can be seen in the case of (FMLN), and CRIME at theend of the sentence .
Neither FMLN nor CRIME could be looked up in the dictionary unless the punctuationmarks were stripped from these words .The preprocessor failed to group ROBERTO_GARCIA_ILVARADO into a single word, because this namewas not known to the preprocessor .
This example illustrates the primary failing of the preprocessor .
Toimprove the performance of the preprocessor, the knowledge base that the preprocessor is built from shoul dbe enhanced in the domain of interest .
It is also necessary to add the corresponding entries, and any othe runknown words, to the preprocessor dictionary .After the above discussed processing, the preprocessor looks up each word in the sentence, and thenpresents the results to the parser .
Examples for four words from the sentence are shown in Figure 2 .For each word, the number of dictionary entries is given, followed by those dictionary entries .
Eachdictionary entry contains the part of speech, the root of the word, number information for nouns, tens einformation for verbs, and a semantic definition at the end of the line .
These semantic definitions are impor-tant, since the parser will mark these nodes in the knowledge-base, and they will be used later in inferencin gfor template generation .Preprocessor Implementation and PerformanceThe preprocessor is implemented solely with the standard Unix commands cat, tr, sed, and awk, usin gUnix piping with a filtering paradigm .
With a dictionary of 16,700 words and 1770 noun phrases, th epreprocessor requires approximately 10 seconds to handle a 1 .5k byte message .
This is not at all badperformance for a largely interpreted process .KNOWLEDGE BAS EThe knowledge base consisting of concept nodes and links between them is distributed over the processo rarray.
The parsing and template filling are performed within the knowledge base by propagating markersthrough the network .Linguistic Knowledge RepresentationIn our memory-based parsing approach, the parsing is performed by matching the linguistic pattern i nthe input against stored templates in the knowledge base, called concept sequences.
A concept sequence is aphrasal pattern consisting of a concept sequence root (CSR) and a set of concept sequence elements (CSE )with specific ordering connections.To provide flexibility, the concept sequences are separated into basic concept sequences (BCS) whichrepresent obligatory cases and auxiliary concept sequences (ACS) which represent optional cases.
Parsingis performed by dynamically combining BCS and ACS .
Syntactic information is given by specifying th eordering of CSE, and by attaching a syntactic constraint to each CSE .
Semantic information is also givenby attaching semantic constraints to each CSE node .The domain knowledge is represented in a concept hierarchy with is-a relations and various propertylinks between concepts .
The concept hierarchy contains concepts which are related to the terrorist domain ,such as different event types, target types, and instrument types.
It also contains knowledge about differen tlocations in South America and various terrorist organization names .
The semantic constraints of the basi cconcept sequence elements are mapped to one or more of the concepts in the concept hierarchy .The knowledge base is divided into several layers .
At the top, there are CSRs which identify the type o finterpretation.
Below the roots are CSEs which constitute the components of concept sequences .
The nextlevels down are the syntactic patterns and semantic concept hierarchy, which serve as connections betweenthe lexical entries and the CSEs .
The lexical layer consists of the input words produced by the preprocessor .Figure 3 illustrates the layered organization of the knowledge base and how the surface linguistic pattern sare mapped to a concept sequence through the syntactic constraints and the semantic concept hierarchy .The accuse-event is a CSR, and the agent, beniiiciery, object, and predicate are CSEs for the298BCS : [ agent, ACCUSE, beneficiary, OF object jCverrmerR- croriem-organ :-tic1\ 1i1t 2 tmhttt{;\I i EFigure 3: Example of the concept sequence .accuse-event .
Each CSE has its own syntactic and semantic constraints .
For example, the syntacticconstraint of agent is NP, and the semantic constraint is animate.The links from the lexical input to those constraints are made in the pre-parsing stage .
The SALVADORA NPRESIDENT-ELECT is segmentized as a NP, and its semantic meaning is mapped to government-official .When a marker is initiated at the concept government-official, it propagates through the concept hier-archy via is-a relation to a CSE to activate a concept sequence .
Actual memory-based parsing is starte dby initiating markers from those nodes which are mapped by pre-parsing .Knowledge Base Components and Siz eCurrently the entire knowledge base has approximately 12,000 semantic concept nodes and 47,000 link sbetween them .
This network of concepts was formed by using a frame-like representation language, converte dto a set of SNAP create instructions by a conversion program, and allocated inside the SNAP array by th econtroller at the loading time .
The major components of the knowledge base are the basic concept sequence sand the concept hierarchy for event-concepts, domain phrases, and the geographical concepts .The basic concept sequences occupy 9000 nodes for the CSR, CSE, and the syntactic constraints .
Theknowledge base contains about 1200 basic concept sequences for about 900 verb entries.
Among the 300 0nodes in the concept hierarchy, 1000 nodes are used for the domain concepts including event types, ob-ject hierarchy, physical target types, human target types, and instrument types .
Another 1000 are usedfor domain-phrases containing terrorist organization names .
The rest are used for geographical concept scontaining all the names of countries, cities, and regional names in South America .
They are connectedvertically to their location types, and horizontally to their location names .
For example, San Salvador i sconnected to city as its type, and to El Salvador as its location .PHRASAL PARSE RThe phrasal parser takes a sequence of dictionary definitions of words generated by the preprocessor, andgroups the words into the following phrasal segments : noun phrase, verb sequence, adverb sequence, adjectivesequence, conjunction, preposition, postposition, relativizer, possessive marker ( 's), date-time group, andpunctuation .
The resulting sequence of phrasal segments drives the memory-based parser to get the meanin gof the input sentence .
The output of the phrasal parser for S1 of message 0048 is shown in Figure 2 .Lexical ambiguity was the major problem in this stage .
Most words can have several syntactic categoriesand semantic meanings .
In order to resolve the lexical ambiguity as far as possible, we have derived abou t30 heuristic disambiguation rules based on the syntactic information of neighboring words .
As a result, mostphrasal segments are correctly assigned .
However, in case of structural ambiguity or garden path sentences ,CS Elayerconnstra tNPr`NP_Qreposil~ _ ,semantic Canimattaccusei ~ tfconcepthierarchylexicallayer "SALVADORAN PRESmeM-ELECT^ ACCUSED" 'IHEFMLN" roP 'THE CRAW'299the phrasal parser yields all possible multiple phrasal definitions, and the next stage, the memory-base dparser, performs the disambiguation .If the lexical entry and its corresponding features are defined in the knowledge base as a lexical layer, an dthe syntax handling modules are added to the knowledge base, then the input word itself can directly drivethe parallel memory-based parser .
In this case, a separate sequential phrasal parsing stage can be removed .However, since the maximum number of nodes allowable in the current SNAP computer is 20K, we canno tdefine all of the lexical entries for the MUC-4 domain in the SNAP knowledge base .
Therefore, we ha dto separate the dictionary from the knowledge base, and the phrasal segmentation based on the dictionar yinformation from the memory-based parsing module .MEMORY-BASED PARSERMemory-Based Parsing AlgorithmThe memory-based parsing algorithm is based on repeated applications of expectations, activations, an dverifications [1] .
Two marker types are used for expectations and activations .
A prediction marker (P-marker) identifies nodes that are expected to occur next .
An activation marker (A-marker) identifies thenode that actually occurred.
An expected node in the concept sequence element layer is verified only if itreceives activation markers through both semantic and syntactic constraint links, whereas an expected nod eat any other layer is verified whenever it receives an activation marker .
Only verified nodes perform anaction specific to the node type .In the beginning of parsing, all concept sequence roots are expected as possible hypotheses, and accord-ingly their first concept sequence elements are also expected .
In effect, we prepare to parse all concep tsequences defined in the knowledge base .When a phrasal input is read, a concept instance is created and a bottom-up activation is propagate dfrom the concept instance to the corresponding subsuming nodes in the knowledge base .
Even though man ynodes are initially expected, only a small part of them receive activations as input phrases are further pro-cessed .
Therefore, candidate hypotheses are quickly narrowed down to correct ones .
In this way, multiplehypotheses are handled in parallel, and eventually only relevant hypotheses survive as an interpretation o fthe input sentence .Parsing Example: processing Sl of TST2-MUC4-0048Among the basic concept sequences in the knowledge base, [agent, condemn, object] and [agent ,accuse, beneficiary, of, object] are related to S1 .
We will explain how these two are used to interpreteach clause of S1 .As shown in Figure 4, the concept sequence root condemn-event and its first concept sequence elemen tagent1238 are initially expected, which is indicated by P-markers .
When the noun phrase [SALVADORANPRESIDENTELECT ALFREDO_CRISTIANI] is input to the memory-based parser, a concept instance of the headnoun, alfredo_cristiani#0 is created and connected to the corresponding semantic node human-name andsyntactic node NP .
Several links are reserved to represent the relationship between the concept instance ofa head noun and instances of noun phrase constituents .
In this case, the concept instance of a head nou nis connected to the instances of modifiers, salvadoran#i and president_elect#2 via np_adjective andnp-uoun links, respectively .After the concept instance is created, A-markers are moved up from the concept instance alfredo_cristiani# 0to the subsuming nodes in the knowledge base .
Since human-name is subsumed not only by animate, butalso by object, two concept sequence elements agent1238 and object1239 in the basic concept sequence[agent, condemn, object] receive A-markers from both semantic and syntactic constraint nodes .
At thi sstage, only the first concept sequence element agent1238 is predicted.
Therefore, A-marker at object1239is neglected, and only agent1238 is verified and triggers the expectation of the next concept sequence ele-ment predicate1240 .
P-marker at agent1238 and A-markers are now removed, and the new P-marker a tpredicate1240 waits for A-markers.
The superscripts of P?, A l , and P2 in Figure 4 represent the order ofmarker activities explained so far .300Basic Concept Sequnece InstanceInterpretationFigure 4: Parsing result of the first clause of Si is shown with the knowledge base .The arrival of the next input verb [CONDEMNED] moves activation markers up to the concept sequence ele-ment predicate1240, and then triggers the expectation of the next concept sequence element object1239 .When the last concept sequence element object1239 receives activation markers from the next input nounphrase [THE TERRORIST KILLING], it sends an activation marker to its concept sequence root condemn-event .Since it was already expected, a basic concept sequence instance condemn-event#7 is created as an interpreta-tion of a clause SALVADORAN PRESIDENT-ELECT ALFREDO CRISTIANI CONDEMNED THE TERRORIST KILLING .This basic concept sequence instance is linked to the corresponding concept instances to represent the mean-ing of the input sentence .
For example, in Figure 4, condemn-event#1 is linked to alfredo_cristiani# Oby an agent link, and to killing#4 by an object link .The next input phrase is a preposition [OF], which calls the oF-preposition specific rules .
As a result, the0E-prepositional phrase is attached to the immediately preceding noun phrase [THE TERRORIST KILLING] ,which is represented by the pp_modifier link from killing#4 to of#8, and the pp_object link from of#8to alvarado#9 .
From these relations, the template generator infers that alvarado#9 is an object of akilling-event by using rules related to the concept killing .When a conjunction [AND] is input, a conjunction handling routine is called .
Since the following phras eis a verb [ACCUSED], AND is recognized as conjoining two verb phrases.
As a result, the verb ACCUSED isprocessed as the beginning of a new clause, and the subject of the preceding verb CONDEMN becomes thesubject of ACCUSED .
In the knowledge base, this is represented by agent link from accuse-event#19 toalfredo_cristiani#0, as shown in Figure 5 .Parsing Example: processing embedded sentences in S 3Complex sentences are parsed by using the same knowledge base used for simple sentences .
When abeginning of an embedded sentence is detected, parsing is guided by different set of markers correspondin gto its clause hierarchy, until the end of the embedded sentence .
For example, markers P[0] and A[0] areused for the main clause of S3, "GARCIA ALVARADO, 56, WAS KILLED" .
The conjunction WHEN indicates thebeginning of a subordinate clause .
Different markers P[1] and A[1] are used for processing the next input ssem : semantic-constrain tsyn: syntactic-constraintsolid link: created before parsingdashed link : created during parsingP: Prediction markerA: Activation marker(superscripts of P and A denotethe order of applications)Basic Concept Sequence[agent, condemn, object]301condemn-event#7 accuse-event# 1agent \agent beneficiaryalfredo cristiani#0Figure 5: Parsing result of S1 .BCS : [object, explode]BCS: [agent, place, object ]Figure 6 : Parsing result of processing "A BOMB PLACED BY URBAN GUERRILLAS OH HIS VEHICL EEXPLODED" in S3 .from the phrase [A BOMB] .
Since the past participle verb "PLACED" marks the beginning of an embeddedsentence, another set of different markers P[2] and A[2] are used to process the next level of embeddedsentence "PLACED BY URBAN GUERRILLAS ON HIS VEHICLE" , until the verb [EXPLODED] indicates returningto markers P[1] and A[1] for the clause of level 1 .
Therefore, [EXPLODED] is processed by P[1] and AN .The resulting basic concept sequence instances explode-event#7 and place-event#6 are connected to theshared concept instance bomb#1 by corresponding semantic case links, as shown in Figure 6 .TEMPLATE GENERATO RTemplate Generation AlgorithmThe memory-based parser generates one or several concept sequence instances (CSI's) for each sentence .These CSI's are collected and processed by the template generator .
One template is generated for eachnewly created CSI .
Slots in a template are filled by performing parallel marker propagation, search and se toperations directly inside the knowledge base.The slot filling routine implements some complex rules based on the occurance of "key" verbs and nouns .In the current system, 118 rules (out of 195 rules formulated) have been implemented .
The current systemconsiders only a limited set of verbs and nouns .
Much more information can be retrieved from the parser'soutput by using more rules .
Some of the rules for a bombing-event are shown below .RULE 1 : If [there is a bombing-event that is not the object of a denial-event, a cease-event, or a stop-event] and [the bombing-event does not have tense future, infinitive, or modal,] then [fill slot 4 (inciden ttype) with BOMBING] .RULE 1 .1 : If the object of the bombing-event (from RULE 1) is not a <human> or <group-of-humans >then [fill slot 12 (physical target ID) with the object of the bombing-event] .RULE 1 .2 : If the agent of the bombing-event is an <organization> then [fill slot 10 (perp organizatio nID) with the agent of the bombing-event] .RULE 1 .3 : If the agent of the bombing-event is not an <organization> then [fill slot 9 (perp individua lID) with the agent of the bombing-event] .302Verbs such as BOMB and MURDER activate the corresponding slot filling routine based on verbs .
Forexample :S3 : GARCIA ALVARADO, 56, WAS KILLED WHEN A BOMB PLACED BY URBAN GUERRILLAS ON HISVEHICLE EXPLODED AS IT CAME TO A HALT AT AN INTERSECTION IN DOWNTOWN SAN SALVADOR .The parser produces : BCSI[O] : kill-event#47, object : 56#45 .
The object case of kill-event i shuman-target name or description and here, GARCIA ALVARADO is human target name .
The incident typebecomes attack-event and the effect of the incident is death .SII : GUERRILLAS ATTACKED MERINO'S HOME IN SAN SALVADOR 5 DAYS AGO WITH EXPLOSIVES .The parser's result for S11 is BCSI[0] : attack-event#211, agent : guerrilla#205, object :home#210, time : day#214, location : san_salvador#213 .
The object case of attack-event is thephysical target id, and the agent case is the perpetrator .After filling slots in each newly generated template, the template is split if necessary into multiple tem-plates .
For example if the physical targets are the embassies of the PRC and the Soviet Union, two template sare created .ControlNewly generated templates are later checked for possible merging .
Merging is performed by checkingseveral conditions (incident date, incident location, target's nationality, etc .)
.
For example, in S3, the attack -incident template generated by kill-event and the bombing-incident template generated by explode-eventare merged into one .
The attack-incident template of Si is merged with the bombing-incident template of S3 .Discourse Processin gThere is little discourse processing in the current implementation .
It is assumed that the discourse i scontinuing unless the time or location is changed .
The message date is kept as a reference time, and thesystem keeps the discourse time.
If there is no explicit change of time, the next sentence is assumed to havethe same discourse time .
If the time is mentioned explicitly, the discourse time is updated .
For example, inS11, 5 DAYS AGO shows the change of discourse time.There are no inference routines to catch the implicit meaning of sentences .
Slots are filled only fro mthe explicit statements using key verbs or nouns .
Within a sentence, the parser does not give the relation sbetween events .
This is an area of improvement for future versions .Also, the current implementation does not have reference resolution .
Reference resolution is importantin discourse processing since it may indicate the connection of texts .
For example, in S23 the discourseis returned to the incident of GARCIA ALVARADO who is an attorney general, and this plays a big part intemplate merging .S23 : ACCORDING TO THE POLICE AND GARCIA ALVARADO'S DRIVER, WHO ESCAPTED UNSCATHED, THEATTORNEY GENERAL WAS TRAVELING WITH TWO BODYGUARDS .
ONE OF THEM WAS INJURED .REFERENCE S[1]Chung, M .
and Moldovan, D., "Memory-Based Parsing with Integrated Syntactic and Semantic Analysi son SNAP", Technical Report PKPL 91-10, Dept.
of Electrical Engineering-Systems, University of SouthernCalifornia, 1991 .
[2] DeMara, R. and Moldovan, D., "The SNAP-1 Parallel AI Prototype", Technical Report PKPL 92-3 ,Dept.
of Electrical Engineering-Systems, University of Southern California, 1992 .
[3] Moldovan, D ., Lee, W ., Lin, C ., and Chung, M ., "SNAP : Parallel Processing Applied to AI", IEEEComputer, May 1992 .
[4]Riesbeck, C .
and Martin, C ., "Direct Memory Access Parsing," Report 354, Dept .
of Computer Science ,Yale University, 1985 .303
