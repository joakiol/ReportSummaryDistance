Understanding Information Graphics: A Discourse-Level Problem ?
?Sandra Carberry, ?Stephanie Elzer, ?
?Nancy Green, ?Kathleen McCoy, and ?Daniel Chester?Dept.
of Computer Science, University of Delaware, Newark, DE 19716(carberry, elzer, mccoy, chester@cis.udel.edu)??Dept.
of Math.
Sciences, Univ.
of North Carolina at Greensboro, Greensboro, NC 27402(nlgreen@uncg.edu)AbstractKeywords: graphics, understanding, dis-course, plan-based modelsInformation graphics that appear in newspa-pers and magazines generally have a message thatthe viewer is intended to recognize.
This paper ar-gues that understanding such information graph-ics is a discourse-level problem.
In particular,it requires assimilating information from multi-ple knowledge sources to recognize the intendedmessage of the graphic, just as recognizing in-tention in text does.
Moreover, when an articleis composed of text and graphics, the intendedmessage of the information graphic (its discourseintention) must be integrated into the discoursestructure of the surrounding text and contributesto the overall discourse intention of the article.This paper describes how we extend plan-basedtechniques that have been used for understandingtraditional discourse to the understanding of in-formation graphics.
This work is part of a projectto develop an interactive natural language systemthat provides sight-impaired users with access toinformation graphics.1 IntroductionInformation graphics (non-pictorial graphicssuch as bar charts and line graphs) are a variant oflanguage with many similarities to other forms ofcommunication.
Information graphics are preva-lent in information resources since they enablecomplex information to be assimilated perceptu-ally with ease.
Unfortunately, knowledge sourcessuch as information graphics are not accessible tosome users.
For example, individuals with im-0The work of the third author was supported by the Na-tional Science Foundation under Grant No.
0132821.paired eyesight have limited access to informationgraphics, thus preventing them from fully utiliz-ing information resources.Some information graphics are only intendedto display data values; (Yu et al, 2002) devel-oped a pattern recognition algorithm for summa-rizing interesting features of automatically gener-ated graphics of time-series data from a gas tur-bine engine.
However, the overwhelming major-ity of the graphics that we have examined (takenfrom newspaper, magazine, and web articles) ap-pear to have some underlying goal, such as get-ting the viewer to believe that interest rates havefallen substantially and that this would thereforebe a good time to refinance a mortgage.
Wehave found that understanding information graph-ics is a discourse-level problem.
In particular,it requires assimilating information from multi-ple knowledge sources to recognize the intendedmessage of the graphic, just as recognizing inten-tion in text does.
Moreover, the communicativeintention of the information graphic must be in-tegrated into the discourse intentions of the sur-rounding text.We are developing an interactive natural lan-guage system that infers the intended messageunderlying an information graphic, augments itwith related interesting features of the graphic,provides an initial summary of the graphic, andthen responds to followup questions from theuser.
This paper presents the system architecture,shows why interpreting information graphics isa discourse-level problem, and outlines how weextend techniques that have been used for under-standing traditional discourse to the understand-ing of information graphics.2 A Natural Language ModalityInformation is the key to knowledge and ef-fective decision-making.
But information is use-ful only if it is accessible in a form that can beeasily assimilated.
For sighted users, informationgraphics capture complex information and enableit to be assimilated perceptually with ease.
Forindividuals who have serious sight-impairments,documents that contain information graphics posechallenging problems.
Although devices havebeen developed for conveying information graph-ics in alternative mediums such as musical tonesor tactile images, these approaches have seriouslimitations.
For example, systems that attempt toconvey graphics via a soundscape(Meijer, 1992)do not facilitate easy comparison of two linegraphs linked in a single graphical display.
More-over, these approaches require the user to con-struct a ?mental map?
of the graphic, which isdifficult for congenitally blind users who do nothave the personal knowledge to assist them in theinterpretation of the image(Kennel, 1996).
Theunderlying hypothesis of our work is that alterna-tive access to what the graphic looks like is notenough ?
the user should be provided with themessage and knowledge that one would gain fromviewing the graphic in order to enable effectiveand efficient use of this information resource.
Toaccomplish this objective, we are developing aninteractive natural language system for communi-cating the content of an information graphic.
Ourmethodology offers promise as a means of provid-ing access to information graphics without expen-sive equipment, with few limitations on the com-plexity of the graphic that can be handled, andwith relatively little cognitive load on the user.3 Architecture and OverviewOur current work is concerned with bar charts,line graphs, and pie charts, although eventuallywe will handle other kinds of graphics.
Figure 1shows the architecture of our system for convey-ing information graphics.
The visual extractioncomponent (VEC) analyzes the graphic and pro-vides an XML representation of the graphic tothe intention recognition component (IRC).
TheIRC is responsible for recognizing the intendedmessage of the information graphic and sending itto the content planning component (CPC), whichwill augment the intended message of the graphicwith related interesting features.
The message or-ganization component (MOC) then organizes themost salient propositions into a coherent sum-mary, which will be rendered in natural languageand conveyed to the user via speech synthesis.The followup question component (FQC) will al-low the user to interactively seek additional infor-mation about the graphic.Our work thus far (Section 4) has focused onunderstanding an information graphic so that itsintended message can be conveyed to the user.Section 4.1 discusses the extension of speech acttheory to the generation and understanding of in-formation graphics.
Section 4.2 argues that un-derstanding information graphics is a discourse-level problem in which the system must recog-nize the intended message of the graphic and in-tegrate it into the intentions of any surroundingtext; it further argues that understanding informa-tion graphics requires similar kinds of knowledgeand processing as does the understanding of tra-ditional textual discourse.
Section 4.3 providesa brief overview of the visual extraction compo-nent that analyzes the graphical image and con-structs an XML representation of the graphic foruse by the graphic understanding system.
Sec-tion 4.4 then describes how we have extendedtechniques used for understanding traditional dis-course and dialogue to the understanding of infor-mation graphics.
Section 5 gives a brief overviewof future work on the rest of the system.
The Ap-pendix contains information graphics that are partof the corpus on which our work is based.4 Understanding Information Graphics4.1 Intention in Information GraphicsInformation graphics are a variant of language.As noted by Clark(Clark, 1996), language is morethan just words.
It is any ?signal?
(or lack of sig-nal when one is expected), where a signal is a de-liberate action that is intended to convey a mes-sage.
According to speech act theory, a speakeror writer executes a speech act whose intendedmeaning he expects the listener or reader to beable to deduce(Searle, 1970; Grice, 1969; Clark,1996).
In their work on multimedia generation,Figure 1: System Architecturethe AutoBrief group proposed that speech act the-ory could be extended to cover the generationof graphical representations(Kerpedjiev and Roth,2000).
They developed a multimedia presenta-tion system that generated text and informationgraphics.
It included 1) an algorithm that couldmap communicative goals to a set of perceptualand cognitive tasks that must be enabled for aviewer to recognize the goals and 2) an automaticgraph designer that used constraint satisfaction toconstruct an information graphic that best facili-tated those tasks, subject to competing constraintsamong the tasks.The overwhelming majority of informationgraphics accompanying newspaper and magazinearticles appear to carry a message that the de-signer intends to convey to the viewer by virtueof the graphic?s design and the data presented inthe graphic.
Consider the graphic in Figure 9.
Itconveys the message that the salary of womenin science, mathematics, and engineering fieldsis consistently less than that of men in the samefields.
Other messages could have been con-veyed by a different graphic design.
For ex-ample, by grouping the bars for men together,grouping the bars for women together, and or-dering the bars for each group by height, thegraphic would have conveyed the message thatboth men and women earn the least in the so-cial sciences and the most in engineering.
Orif the bars for Computer/Mathematical Scienceswere highlighted in Figure 9 by coloring themsignificantly differently from the other bars in thegraphic, the graphic would have invoked a com-parison of the discrepancies between male andfemale salaries in Computer/Mathematical Sci-ences and the salary discrepancies between menand women in other fields.
Although a graphic?scaption can be helpful in identifying its intendedmessage (as in Figure 8), Corio performed a largecorpus study(Corio and Lapalme, 1999) in whichhe found that captions are often missing or failto provide any indication of what the informationgraphic conveys (as in Figures 6 and 10).
Thuswe cannot rely entirely on the presence of usefulcaptions to identify the intended message of aninformation graphic.Language research has posited that the listeneror reader who is interpreting a speech act identi-fies its intended meaning by reasoning about theobserved signals and the mutual beliefs of authorand interpreter(Grice, 1969; Clark, 1996).
Ap-plying this to graphical displays, it is reasonableto presume that the author of a graphic similarlyexpects the viewer to use perceptual skills alongwith other knowledge sources to deduce from thegraphic the message that he intended to convey.Thus we are applying speech act theory in the re-verse direction of the AutoBrief project, namelyto the recognition of the intended message under-lying an information graphic.4.2 A Discourse Level ProblemThis section argues that interpreting informa-tion graphics is a discourse-level problem ?
notonly is it necessary to recognize the intention ofthe graphic as noted in Section 4.1, but under-standing an information graphic requires similarkinds of knowledge and processing as does un-derstanding traditional discourse.Grosz and Sidner contended that discoursehas a structure comprised of discourse segments.Each discourse segment has a discourse seg-ment purpose that contributes to the discoursepurpose or intention underlying the overall dis-course(Grosz and Sidner, 1986).
When an arti-cle is comprised of text and graphics, the graphicgenerally expands on the text and contributes tothe discourse purpose of the article.
Consider thegraphic and partial surrounding text reproducedin Figure 6.
Nowhere in the text is it stated thatthe income of black women has risen dramati-cally over the last decade and has reached thelevel of white women.
Yet this message is clearlyconveyed by the graphic and contributes to theoverall communicative intention of this portionof the article ?
namely, that there has been a?monumental shifting of the sands?
with regardto the achievements of black women.
Not onlydoes the intended message of the graphic (its dis-course segment purpose) contribute to this overallintention, but in fact the discourse intention of thegraphic helps to recognize the overall intention.Even when the graphic stands in isolation asin Figures 7 and 8, understanding the graphicis a discourse-level problem.
Grosz and Sid-ner(Grosz and Sidner, 1986) claim that a robustmodel of discourse understanding must use mul-tiple knowledge sources in order to recognize thecomplex relationships that utterances have to oneanother.
Information graphics have similar com-plex relationships among their component ele-ments.
Not only might the graphic include mul-tiple elements that must be related to one another(such as multiple lines in a line graph, or individ-ual bars in a bar chart), but information graphicsoften include highlighting of certain elements tomake them particularly salient (as in Figure 10)or include captions that might contribute to rec-ognizing the graphic?s intention.
The graphic inFigure 8 includes such a helpful caption, althoughmany graphics, such as the ones in Figures 7and 9, do not.Furthermore, identifying the intended messageof a composite graphic (one comprised of multi-ple individual graphics) requires relating the in-dividual graphics to one another to identify theintended message of the composite.
Figure 11 il-lustrates a composite information graphic.
Thediscourse purpose of the composite graphic is thataudits of affluent taxpayers are declining with re-spect to audits of all taxpayers.
This message canonly be deduced by relating the two individualgraphics and their underlying messages.Moreover, understanding information graphicsrequires the use of multiple knowledge sources.In earlier work on recognizing expressions ofdoubt, we developed an algorithm that combinedlinguistic, contextual, and world knowledge andapplied it to the recognition of complex discourseacts(Carberry and Lambert, 1999).
In the caseof information graphics, the corollary to linguis-tic knowledge is perceptual knowledge, by whichone recognizes the individual elements of thegraphic (for example, the bars in a bar chart), therelation of the individual elements in the graphicto one another, the type of graphic (line graph,bar chart, pie chart, etc.
), and what the differentgraphic types can be used to convey.
For exam-ple, both a scatter plot and a pie chart can beused to portray how an entity (such as govern-ment income) is divided up among several cate-gories (such as social welfare, military spending,etc.
); however, a graphic designer will choose apie chart if the intent is to convey the relative dis-tributions as opposed to their absolute amounts.Furthermore, a particular type of graphic (such asa line graph) might be appropriate for conveyingseveral different intentions (maximum data point,data trend, data variation, etc.
).Contextual and world knowledge are also es-sential for understanding information graphics.Contextual knowledge includes the caption as-sociated with the graphic, any highlighting ofgraphic elements that affects the focus of atten-tion in the graphic, and the discourse structure andfocus of attention in any surrounding text.
Worldknowledge consists of mutual beliefs between de-signer and viewer about entities of interest to theintended viewing audience.
For example, if an in-formation graphic appears in a document targetedat residents of New York City, then both the de-signer and the viewer will mutually believe thatentities such as New York City, its football andbaseball teams, etc.
will be particularly salientto the viewer.
Our methodology for understand-ing information graphics takes these knowledgesources into account.4.3 The Visual Extraction ComponentThe visual extraction component (VEC) cap-tures much of the perceptual knowledge discussedin Section 4.2.
It is responsible for recogniz-ing the individual components comprising thegraphic, identifying the relationship of the differ-ent components to one another and to the graphicas a whole, and classifying the graphic as to type.Extracted components include not only the bars,lines, or wedges of a graphic but also the titles ofthe axes, the legend, and the graphic?s title or cap-tion.
The present implementation deals only withgray scale images (in pgm format) of bar charts,pie charts, and line graphs, though eventually itwill be extended to handle color and other kindsof information graphics.
Words and numbers thatappear in the chart are associated with particularbars, wedges and lines by their proximity to thechart component in question.
The output of thevisual extraction component is an XML file thatdescribes the chart and all of its components.4.4 Applying Discourse UnderstandingStrategiesMany researchers have cast the understandingof discourse and dialogue as a plan recognitionproblem ?
that is, the writer or speaker (or char-acters in the case of a story) has an underlyinggoal and a plan for accomplishing that goal, andunderstanding requires that the reader or listenerinfer the plan and in turn the goal that the plan isintended to achieve.
(Perrault and Allen, 1980;Wilensky, 1983; Litman and Allen, 1987; Car-berry, 1990; Charniak and Goldman, 1993; Ardis-onno and Sestero, 1996) are just a few examplesof such systems.Since understanding information graphics is adiscourse-level problem, we are extending planinference techniques to recognizing the intendedmessage of an information graphic(Elzer et al,2003) and to identifying its contribution to anextended discourse that includes both text andgraphics.
Planning and plan inference systems re-quire knowledge about goals and how they canbe achieved.
Typically, this is provided by a li-brary of operators.
Each operator encodes a goalin its header; the body of the operator encodesthe subgoals that must be accomplished in orderto achieve the operator?s goal.
A planning sys-tem starts with a high-level goal, and uses oper-ators to decompose the goal into a set of simplersubgoals, which eventually decompose into prim-itive subgoals that can be accomplished by prim-itive actions in the domain.
On the other hand,a plan inference system starts with the primitivegoals associated with observed actions, and usesthe operators to chain backwards to higher-levelgoals which the lower-level subgoals contribute toachieving.
In the case of traditional discourse anddialogue, the subgoals in the plan operators are ei-ther communicative or domain goals, and the ob-served actions that start the plan inference processare the speech acts represented by the utterancesin a story or a dialogue.To extend plan inference to information graph-ics, the plan operators must include goals thatcan be accomplished by viewing an informationgraphic, as opposed to being the recipient of anutterance.
As discussed in Section 4.1, the Auto-Brief project(Kerpedjiev and Roth, 2000) devel-oped an algorithm to map communicative goals toa sequence of perceptual and cognitive tasks thatthe graphic should support.
Perceptual tasks aretasks that can be performed by simply viewing thegraphic, such as finding the top of a bar in a barchart; cognitive tasks are tasks that are performedvia mental computations, such as computing thedifference between two numbers.
We draw onthe AutoBrief notion of perceptual and cognitivetasks enabled by an information graphic.
Our planoperators not only encode knowledge about howto achieve domain and communicative goals (thelatter of which may require that the viewer per-form perceptual and cognitive tasks) but they alsoencode knowledge about how information-accesstasks, such as finding the value of an entity ina graphic, can be decomposed into simpler sub-goals.
Figures 2 and 3 present two plan operatorsfor achieving the goal of finding the value <v> ofan attribute <att> for a graphical element <e>(for example, the value associated with the top ofa bar in a bar chart).
The body of the operator inGoal: Find-value(<viewer>, <g>, <e>, <ds>, <att>, <v>)Gloss: Given graphical element <e> in graphic <g>, <viewer> can find the value <v>in dataset <ds> of attribute <att> for <e>Data-req: Dependent-variable(<att>, <ds>)Body: 1.
Perceive-dependent-value(<viewer>, <g>, <att>, <e>, <v>)Figure 2: Operator for achieving a goal perceptuallyGoal: Find-value(<viewer>, <g>, <e>, <ds>, <att>, <v>)Gloss: Given graphical element <e> in graphic <g>, <viewer> can find the value <v>in dataset <ds> of attribute <att> for <e>Data-req: Natural-quantitative-ordering(<att>)Display-const: Ordered-values-on-axis(<g>, <axis>, <att>)Body: 1.
Perceive-info-to-interpolate(<viewer>,<g>,<axis>,<e>,<l1>,<l2>,<f>)2.
Interpolate(<viewer>, <l1>, <l2>, <f>, <v>)Figure 3: Operator that employs both perceptual and cognitive subgoalsFigure 2 specifies that the goal can be achievedby a primitive perceptual task in which the viewerjust perceives the value; this could be done, forexample, if the element in the graphic is annotatedwith its value, as are the bars in the bar chart inFigure 8 of the Appendix.
On the other hand, thebody of the operator in Figure 3 captures a differ-ent way of finding the value, one that presumablyrequires more effort.
It specifies the perceptualtask of finding the values <l1> and <l2> sur-rounding the desired value on the axis along withthe fraction <f> of the distance that the desiredvalue lies between <l1> and <l2>, followed bythe cognitive task of interpolating between the re-trieved values <l1> and <l2>.Our operators contain data requirements (la-belled Data-req) which the data must satisfy inorder for the operator to be applicable in a graphicplanning paradigm; they may also contain displayconstraints (labelled Display-const) which con-strain how the information graphic is constructedif this operator is part of a final plan.
In the caseof plan recognition, these constraints are usedin reverse.
The display constraints are used toeliminate operators from consideration, since ifa graphic does not satisfy the operator?s displayconstraints, then the operator could not be part ofa plan that led to the graphic.
If a graphic meetsthe display constraints of an operator, then thedata requirements are used to limit how the op-erator?s parameters might be instantiated.4.4.1 Beginning the Plan Inference ProcessTraditional plan inference systems used forlanguage understanding start with the primitivegoal achieved by the speech act in the dialogueor discourse.
In the case of information graphics,the role of the speech act is played by the primi-tive perceptual tasks that the viewer performs onthe graphic.
To limit the set of perceptual tasksthat are considered, we make two observations:?
The graphic designer has many alternativeways of designing a graphic, and the de-sign choices facilitate some perceptual tasksmore than others.
Following the Auto-Brief work(Kerpedjiev and Roth, 2000) ongenerating graphics that fulfill communica-tive goals, we hypothesize that the designerchooses a design that best facilitates thetasks that are most important to conveyinghis intended message, subject to the con-straints imposed by competing tasks.?
Entities may become particularly salient byvirtue of highlighting in the graphic (for ex-ample, coloring certain elements differentfrom the others, annotating an element withan asterisk, or exploding one piece of a piechart1), by their mention in the caption orsurrounding text, or via world knowledge1(Mittal, 1997) discusses a variety of such design tech-niques in the context of distorting the message inferred froma graphic.capturing mutual beliefs about entities of in-terest to the intended audience.
We hypoth-esize that the designer relies on the viewerrecognizing particularly salient entities, inorder to make certain perceptual tasks moresalient to the viewer.As noted in Section 4.1, one cannot rely on agraphic?s caption to provide the intended mes-sage of the graphic.
Consequently, the plan in-ference process starts with both the set of tasksthat are best enabled by the information graphicand the set of tasks (if any) that are particularlysalient.
These will be referred to as candidatetasks.
The next two subsections describe howcandidate tasks are identified.Identifying the Best Enabled Tasks TheAPTE (Analysis of Perceptual Task Effort) sub-module, shown in Figure 1 as part of the Inten-tion Recognition Component, captures perceptualknowledge about performing primitive perceptualtasks2, and it encapsulates the results of cognitivepsychology research to estimate the relative effortrequired for different tasks.
The output of APTEis the set of perceptual tasks that are best enabledby the graphic.
These become candidate tasks.Each APTE rule captures a primitive percep-tual task that can be performed on a particu-lar type of information graphic, the conditions(graphic design choices) that affect the difficultyof performing that task, and the estimated effortexpended by a viewer if those conditions are sat-isfied in the graphic.
The condition-computationpairs are ordered so that the ones producing thelowest effort estimates appear first in a rule.To derive the effort estimates in the rules, wehave followed the GOMS approach(Card et al,1983) by breaking down the tasks that are re-garded as primitive in our plan operators intoeven more basic component tasks, and then sum-ming the effort estimates for these very basictasks.
Lohse?s work(Lohse, 1993) is an exam-ple of the GOMS architecture applied to predict-ing performance on graph comprehension tasks,and many of our effort estimates are based onLohse?s research.
For example, Figure 4 dis-2Primitive perceptual tasks are those that we do not de-compose into a set of simpler subtasks; this is not to be con-fused with the notion of a psychological primitive.plays the APTE rule for the task of finding thevalue associated with the top of a bar in a barchart.
If the bar is annotated with its value,then condition-computation pair B1-1 estimatesits effort as 150 units for discriminating the label(based on work by Lohse(Lohse, 1993)) and 300units for recognizing a 6-letter word (John andNewell, 1990).
If the bar is not annotated with itsvalue but is aligned with a tick mark on the axis,then condition-computation pair B1-2 estimatesthe perceptual effort in terms of the distance to thedependent axis (in order to capture the degrees ofvisual arc scanned(Kosslyn, 1989)) plus the effortof discriminating and recognizing the label.
Fig-ure 5 displays the APTE rule associated with thefirst subgoal in Figure 3.
It estimates the effort forthe primitive task Perceive-info-to-interpolate asthe effort of the scan to the dependent axis (basedon (Kosslyn, 1989)), the effort of discriminatingthe intersection location on the axis (150 unitsbased on (Lohse, 1993)), plus the effort of the sac-cade to each label (230 units each (Russo, 1978))along with the effort involved in discriminatingand recognizing the labels.
Similarly, there is acognitive rule (not discussed here) for estimatingthe effort associated with the cognitive task Inter-polate (the second subgoal in the operator in Fig-ure 3).
(Elzer et al, 2003a) presents a more ex-tensive discussion of the cognitive principles un-derlying the APTE rules.Given the XML representation of an informa-tion graphic, each APTE rule that is applicableto the graphic produces an effort estimate for thetask captured by the rule.
When a task might beinstantiated in multiple ways and still satisfy theconditions of a condition-computation pair (forexample, the task of finding the value of the topof a bar could be instantiated for each bar in abar chart), only the instantiation that produces thelowest effort estimate becomes a candidate task.
(If the bars are not annotated with values, then theinstantiation that will produce the lowest effort es-timate for the task of finding the value of the topof a bar in a bar chart would be the bar with theshortest scan to the dependent axis.)
This is con-sistent with the idea that the graphic designer willmake the important tasks easy to perform.
Theset of perceptual tasks that require the least effortbecome candidate tasks.Rule-1:Estimate effort for task Perceive-dependent-value(<viewer>, <g>, <att>, <e>, <v>)Graphic-type: bar-chartGloss: Compute effort for finding the exact value <v> for attribute <att> represented by top <e>of a bar <b> in graph <g>B1-1: IF the top of bar <b> is annotated with a value,THEN effort=150 + 300B1-2: IF the top <e> of bar <b> aligns with a labelled tick mark on the dependent axis,THEN effort=scan + 150 + 300Figure 4: A rule for estimating effort for the primitive perceptual task Perceive-valueRule-2:Estimate effort for taskPerceive-info-to-interpolate(<viewer>,<g>,<axis>,<e>,<l1>,<l2>,<f>)Graphic-type: bar-chartGloss: Compute effort for finding the information needed for interpolation, including the labels<l1> and <l2> on either side of entity <e> on axis <axis> in graph <g>,and the fraction <f> that is the distance between <l1> and entity <e> on <axis>relative to the distance between <l1> and <l2>B2-1: IF <axis> is labelled with values THEN effort=scan + 150 + ((230 + 150 + 300) x 2)Figure 5: A rule for estimating effort for the primitive perceptual task Perceive-info-to-interpolateIdentifying Particularly Salient TasksSalient tasks are those that the viewer mightperform because they relate to entities that arein the viewer?s current focus of attention, asdetermined by contextual knowledge providedby the caption, highlighting, and the surroundingtext and by world knowledge in the form ofmutual beliefs about items of particular interestto the viewing audience.Ideally, a caption will provide clues about themessage that an information graphic is intendedto convey, and thus noun phrases in captions rep-resent salient entities.3 The graphic designer canalso call into focus certain aspects of the graphicby using attention-getting devices such as col-oring it differently from the rest of the graphic,annotating it with an arrow, etc.
Our workinghypothesis is that if the graphic designer goesto the effort of employing such attention-gettingdevices, then the highlighted items almost cer-tainly contribute to the intended message.
Thusthe attributes of these highlighted items (for ex-ample, the attributes of a highlighted bar in a barchart), which are captured in the XML represen-3Verb phrases in captions also provide evidence, but theysuggest particular operators of interest rather than instanti-ated perceptual tasks, and thus we associate verbs with oper-ators in the plan library.tation of the graphic, are also regarded as saliententities.
Salient entities also include those thatworld knowledge suggests are mutually believedto be of interest to the viewing audience.
We en-vision in the future using the notion of lexicalchains(Silber and McCoy, 2000) to identify enti-ties that the accompanying text makes particularlysalient.
Perceptual tasks that are instantiated witha salient entity and that can be performed on thegraphic are designated salient tasks.4.4.2 The Search ProcessCandidate tasks consist of the set of percep-tual tasks that require the least effort and the set ofsalient tasks.
Once the set of candidate tasks hasbeen identified, plan inference begins.
Initial can-didate plans are constructed from each operatorin which a candidate task appears as a subgoal;the root of the candidate plan is the goal of theoperator, and its children are the subgoals in thebody of the operator.
Chaining from the root goalto other operators whose body contains the rootgoal as a subgoal produces larger candidate planswith higher-level goals as the new root goal.Plan inference systems have used a variety ofheuristics to evaluate candidate plans and to se-lect the candidate plan to expand further.
Theseheuristics help to guide the search through thespace of candidate plans in order to hypothe-size the plan that best represents the user?s in-tentions.
These heuristics have included increas-ing the rating of partial plans as their argumentsbecome instantiated(Perrault and Allen, 1980),preferring coherent discourse moves(Litman andAllen, 1987; Carberry, 1990), and biasing theplan inference process based on knowledge aboutthe user group(Gertner and Webber, 1996).
Wehave identified several kinds of evidence for guid-ing plan inference from information graphics, in-cluding the estimated effort required by a candi-date plan, the basis for instantiating parameters inthe plan, adherence to the proximity compatibil-ity principle from cognitive science research, andthe relation between a candidate plan and the es-tablished discourse context.Since our working hypothesis is that thegraphic designer tried to enable those tasks neces-sary to recognize his intended message, candidateplans that require substantially more effort thanother candidate plans are less likely to representthe intentions of the designer.
The effort associ-ated with a candidate plan is measured as the sumof the effort of the tasks comprising it.There are many ways that a parameter in a taskor subgoal might become instantiated, and the ba-sis for the instantiation provides evidence aboutthe likelihood that a hypothesized candidate planrepresents the graphic designer?s intentions.
Ifan instantiation is suggested by highlighting ora caption or entities that are particularly salientto the targeted audience, that partial plan shouldbe evaluated more favorably since the designer ofthe graphic has provided reasons for the viewer touse these instantiations in recognizing his inten-tions.
Similarly, if the instantiation is one of sev-eral possible alternatives with no reason for pre-ferring one over the other, then the partial planshould be evaluated less favorably since the de-signer did not give the viewer any reason to preferone over the other.
This relates to Allen?s forkingheuristic(Perrault and Allen, 1980).
The proxim-ity compatibility principle(Wickens and Carswell,1995) also suggests that candidate plans whichuse similarly encoded elements (for example, allred bars) in an integrated fashion should be eval-uated more favorably than those that do not.If there is a context established by the text pre-ceding or surrounding the graphic, then candidateplans whose root goal contributes to the exist-ing discourse context should be preferred.
If thesurrounding text has a reference to the graphic,then focusing heuristics(Carberry, 1990) will pre-fer candidate plans that relate most closely to thecurrent focus of attention at that point in the sur-rounding text.
However, the surrounding text of-ten does not refer to accompanying graphics, as isthe case in the Newsweek article whose excerpt isshown in Figure 6.
Future work will investigatehow we should handle instances such as this.5 Response Generation and FollowupThe intended message of the graphic must beaugmented with additional propositions that con-vey interesting features that a viewer would gleanfrom the graphic.
For example, the intended mes-sage of the graphic in Figure 6 appears to be thatthe income of black women has risen dramati-cally over the last decade and reached the levelof white women.
But other interesting features ofthe graphic might include the trends over the pastseveral decades, periods where they were closest,etc.
In future work, we anticipate developing amethodology for identifying propositions that ex-pand on the message of the graphic designer andfor including the most salient of these in the sum-marization of the graphic.
We also envision re-sponding to followup requests for further infor-mation about the graphic by selecting the highestranking propositions that were not included in theinitial message, organizing them into a coherentresponse, and conveying it to the user.6 SummaryThis paper has argued that understandinginformation graphics is a discourse-level prob-lem.
Not only must the system recognize the in-tended message of the information graphic, butthe recognition process requires similar kinds ofknowledge sources and similar kinds of process-ing as does the understanding of traditional dis-course and dialogue.
Moreover, when an articleis composed of text and graphics, the intendedmessage of the information graphic must be in-tegrated into the discourse structure of the sur-rounding text, and it contributes to the overall dis-course intention of the article.ReferencesL.
Ardisonno and D. Sestero.
1996.
Using dynamicuser models in the recognition of the plans of theuser.
User Modeling and User-Adapted Interac-tion, 5(2):157?190.S.
Carberry and L. Lambert.
1999.
A process modelfor recognizing communicative acts and modelingnegotiation subdialogues.
Computational Linguis-tics, 25(1):1?53.S.
Carberry.
1990.
Plan Recognition in Natural Lan-guage Dialogue.
ACL-MIT Press Series on NaturalLanguage Processing.
MIT Press, Cambridge, MA.S.
Card, T. Moran, and A. Newell.
1983.
The Psychol-ogy of Human-Computer Interaction.
LawrenceErlbaum Associates, Inc., Hillsdale, NJ.E.
Charniak and R. Goldman.
1993.
A bayesianmodel of plan recognition.
Artificial Intelligence,64:53?79.H.
Clark.
1996.
Using Language.
Cambridge Univer-sity Press.M.
Corio and G. Lapalme.
1999.
Generation of textsfor information graphics.
In Proceedings of the 7thEuropean Workshop on Natural Language Genera-tion EWNLG?99, pages 49?58.S.
Elzer, N. Green, and S. Carberry.
2003a.
Exploit-ing cognitive psychology research for recognizingintention in information graphics.
In Proceedingsof the 25th Annual Meeting of the Cognitive ScienceSociety.
To appear.S.
Elzer, N. Green, S. Carberry, and K. McCoy.
2003.Extending plan inference techniques to recognizeintentions in information graphics.
In Proceedingsof the Ninth International Conference on User Mod-eling.
To appear.A.
Gertner and B. Webber.
1996.
A Bias TowardsRelevance: Recognizing Plans Where Goal Mini-mization Fails.
In Proc.
of the Thirteenth NationalConference on Artificial Intelligence, pages 1133?1138.H.
P. Grice.
1969.
Utterer?s Meaning and Intentions.Philosophical Review, 68:147?177.B.
Grosz and C. Sidner.
1986.
Attention, Intentions,and the Structure of Discourse.
Computational Lin-guistics, 12(3):175?204.B.
John and A. Newell.
1990.
Toward an engi-neering model of stimulus response compatibility.In R. Gilmore and T. Reeve, editors, Stimulus-response compatibility: An integrated approach,pages 107?115.
North-Holland, New York.A.
Kennel.
1996.
Audiograf: A diagram-reader forthe blind.
In Second Annual ACM Conference onAssistive Technologies, pages 51?56.S.
Kerpedjiev and S. Roth.
2000.
Mapping com-municative goals into conceptual tasks to generategraphics in discourse.
In Proc.
of the InternationalConference on Intelligent User Interfaces, pages60?67.S.
Kosslyn.
1989.
Understanding charts and graphs.Applied Cognitive Psychology, 3:185?226.D.
Litman and J. Allen.
1987.
A Plan RecognitionModel for Subdialogues in Conversation.
CognitiveScience, 11:163?200.G.
Lohse.
1993.
A cognitive model for understand-ing graphical perception.
Human-Computer Inter-action, 8:353?388.Peter B. Meijer.
1992.
An experimental system forauditory image representations.
IEEE Transactionson Biomedical Engineering, 39(2):291?300, Febru-ary.V.
Mittal.
1997.
Visual prompts and graphical design:A framework for exploring the design space of 2-Dcharts and graphs.
In Proc.
of the Fourteenth Na-tional Conference on Artificial Intelligence, pages57?63.R.
Perrault and J. Allen.
1980.
A Plan-Based Anal-ysis of Indirect Speech Acts.
American Journal ofComputational Linguistics, 6(3-4):167?182.J.
Russo.
1978.
Adaptation of cognitive processes toeye movement systems.
In J. Senders, D. Fisher,and R. Monty, editors, Eye movements and higherpsychological functions.
Lawrence Erlbaum, Hills-dale, NJ.J.
Searle.
1970.
Speech Acts: An Essay in the Phi-losophy of Language.
Cambridge University Press,London.G.
Silber and K. McCoy.
2000.
Efficient text summa-rization using lexical chains.
In Proc.
of the Inter-national Conference on Intelligent User Interfaces,pages 252?255.C.
Wickens and M. Carswell.
1995.
The proximitycompatibility principle: Its psychological founda-tion and relevance to display design.
Human Fac-tors, 37(3):473?494.R.
Wilensky.
1983.
Planning and Understanding.Addison-Wesley.J.
Yu, J.
Hunter, E. Reiter, and S. Sripada.
2002.Recognising visual patterns to communicate gasturbine time-series data.
In ES2002, pages 105?118.Appendix of Graphics from our CorpusGraphic from Newsweek Article60 70 80 90 01$15105Black womenWhite womenMedian IncomeIn thousands of 2001 dollars1948Relevant Text from Newsweek ArticleThis is not to say that black women haveclimbed the storied crystal stair.
They remain?in the proving stage?, observes Alabama ex-ecutive Alice Gordon.
Nearly 14 percent ofworking black women remain below the povertylevel.
And women don?t yet out-earn black men.But the growing educational-achievement gapportends a monumental shifting of the sands.College-educated black women already earnmore than the median for all black working men?
or, for that matter, for all women.
And aswomen in general move up the corporate pyra-mid, black women, increasingly, are part of theparade.
In 1995 women held less than 9 per-cent of corporate-officer positions in Fortune500 companies, according to Catalyst, a NewYork-based organization that promotes the inter-ests of women in business.
Last year they heldclose to 16 percent, a significant step up.
Ofthose 2,140 women, 163 were black ?
a minus-cule proportion, but one that is certain to grow.Figure 6: Excerpt from Newsweek MagazineHow reliable adults think DNA tests are for identifying an individual:Trusting DNADon?t knowVery unreliableunreliableSomewhatreliableSomewhatVery reliable2%3%4%68%23%Figure 7: Standalone Graphic from USA TodayEuropeCanadaAfricanOthercountriesSouthUnitedStatesAfrica21metric tonsLeading producers inin gold productionSouth Africa tops428355187 155Gold ProductionMetricTonsFigure 8: Standalone Graphic from USA Today010,000Median Salaries (in dollars), Full?Time Employed SMET Doctorates, by Field and Gender, 1997Computer/All SMET Physical SciencesSalaries(indollars)SciencesMathematicalEngineering Life Sciences Social Sciences80,00070,00060,00050,00040,00030,00020,000MaleFemaleFigure 9: Graphic from Report of the NSF Committee on Equal Opportunities in Science & Engineeringpersonal filingsDelaware bankruptcy300025001000150020001998 1999 2000 2001Figure 10: Graphic from Wilmington NewsJournal0.6%?96 ?97 ?98 ?99 ?00 ?011.0%2.0%3.0%0.8%0?96 ?97 ?98 ?99 ?00 ?01All taxpayersAffluent taxpayers1.2%continue to slideAudits of affluentwere audited by the IRS:Percentage of taxpayers who00.6%1.8%Figure 11: Graphic from USA Today
