Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 1466?1471,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsCross-lingual Text Classification Using Topic-Dependent Word ProbabilitiesDaniel Andrade Akihiro Tamura Masaaki Tsuchida Kunihiko SadamasaKnowledge Discovery Research Laboratories, NEC Corporation, Japan{s-andrade@cj, a-tamura@ah,m-tsuchida@cq, k-sadamasa@az}.jp.nec.comAbstractCross-lingual text classification is a majorchallenge in natural language processing,since often training data is available in onlyone language (target language), but not avail-able for the language of the document we wantto classify (source language).
Here, we pro-pose a method that only requires a bilingualdictionary to bridge the language gap.
Ourproposed probabilistic model allows us to es-timate translation probabilities that are condi-tioned on the whole source document.
Theassumption of our probabilistic model is thateach document can be characterized by a dis-tribution over topics that help to solve thetranslation ambiguity of single words.
Us-ing the derived translation probabilities, wethen calculate the expected word frequency ofeach word type in the target language.
Fi-nally, these expected word frequencies can beused to classify the source text with any classi-fier that was trained using only target languagedocuments.
Our experiments confirm the use-fulness of our proposed method.1 IntroductionText classification is ubiquitous in natural languageprocessing.
It?s applications range from simple topicdetection, like articles about sport vs articles aboutcomputers, to sentimental analysis, and subtle dis-crimination of Tweets that report the abuse of drugsor the metaphoric use of drugs (?love is like a drug?
).Text classification hugely relies on manually anno-tated training data in one language.However, creating training data for each languageis expensive, and therefore, we are interested in us-ing training data given in only one language (e.g.English, denoted as target language) to classify textwritten in a different language (e.g.
Chinese, orJapanese, denoted as source language).Our approach addresses this issue by using a sim-ple bilingual dictionary.
Bilingual dictionaries havethe great advantage that they are available often forfree1, and have good coverage for major languages,like Chinese and Japanese.
With the help of the dic-tionary, we calculate the expected frequency of eachword in the target language.
Finally, we create a fea-ture vector in the target language that is used as inputfor the text classifier.However, due to the translation ambiguity of aword in the source language, it is important to care-fully choose the translation probability for calculat-ing the expected frequencies of the target words.
Forexample, consider a Japanese news article that con-tains the word ??
(restrict, restrain, in custody),and we want to find out whether the article is about?foreign policy?
or not.
The most simple methodis to use all its English translations, and assumea uniform distribution over them, i.e.
{0.33, 0.33and 0.33}.
However, depending on the topic of thenews article, the translation ?in custody?
is more ap-propriate.
For example, if the article reports abouta crime/crime suspect, the translation ?in custody?is more likely than ?restrict?
and ?restrain?.
Con-versely, if the article is about ?military?, the trans-lation ?in custody?
is less likely.
Moreover, an arti-cle that is about the topic ?military?
is more likelyto belong to the class ?foreign policy?.
This exam-ple demonstrates the importance of estimating goodtranslation probabilities in order to improve the clas-1For example from Wikitionay.org under Creative Com-mons Licence.1466sification of the source text.Therefore, we propose a probabilistic model thatuses latent document topics to help improve thetranslation probabilities for a source document.
Ourexperiments, on three different pairs of corpora, con-firm that our probabilistic model for estimating wordtranslation probabilities is helpful for cross-lingualtext classification.2 Related WorkThe work in (Wu et al, 2008) and (Shi et al,2010) uses a bilingual dictionary for cross-lingualtext classification.
The method described in (Wu etal., 2008) is motivated by transfer learning to adjustthe class probability p(c) to account for the differ-ences in distributions between source and target lan-guage.
Similar to our work, in the first step, theygenerate a probabilistic bilingual lexicon that con-tain word translation probabilities p(e|f).
However,one main difference to our work is that they translateeach source word f in source text F independently,without considering any topic or context informationof F .Instead of translating the source text into the tar-get language, the method in (Shi et al, 2010) sug-gests to translate the target classification model intothe source language.
They directly estimate thetranslation probabilities p(f |e, c) using the sourceand target language data.
One limitation of theirmethod is that it assumes that the class of the docu-ment, that we want to translate, is given.Our idea of learning word translation probabili-ties in context is related to the work in (Koehn andKnight, 2000).
They describe an efficient method forlearning word translation probabilities p(f |e) usinga bilingual dictionary and a pair of comparable cor-pora2.
Like our approach, their method has the ad-vantage that no parallel corpora are needed for trans-lation.
However, to solve the ambiguity of word-translation they considered only (local) bi-gram con-text.
Moreover, their method assumes that the wordorder in the languages are the same.
This is obvi-ously not the case for language pairs like Englishand Japanese.We note that the bilingual paired topic model,2Two corpora written in different languages which do notneed to be translations of each othersuggested in (Jagarlamudi and Gao, 2013), can alsobe used to disambiguate and select the appropriateword translations by using the topic associated withthe given document.
However, their model does notconsider the use of a document class, and uses fixedword translation probabilities.
In Section 3.2, weshow that our model can also be used to learn thetranslation probabilities.Alternatively, the multi-lingual topic model de-scribed in (Ni et al, 2011), and the use of a commonlow-dimensional projection described in (Platt et al,2010) have also been applied to the cross-lingualtext classification problem.
However, both modelsrequire for training that cross-lingually aligned doc-uments are available.3 Proposed MethodOur proposed method does not use one translationof F , but implicitly generates all translations andweights them by the probability of each translation.More formally, let E be one translation of sourcetext F .
Moreover, let countE(e) denote the fre-quency of word e in E. Instead of using countE(e),we use the expected number of word occurrences de-noted by E[countE(e)|F ] as features.
When we usea simple uni-gram language model in the source lan-guage we get:E[countE(e)|F ] =k?j=1p(ej= e|fj) (1)where we might write F as (f1, f2, f3, ...fk), wherefjis the j-th word in F , and k is the number of wordsin source text F .3The random variable ejdenotesthe translation of the j-th word in F .
However, sucha simple model translates each source word indepen-dently and ignores the context of the word.In the following, we describe a probabilisticmodel that allows us to consider the whole documentcontext F into account for translating one word fj.The generative story is as follows:1.
For each document, we generate a class label cwith probability ?c.
Here we consider only thebinary classification task with class label ?pos-itive?, or ?negative?.3Here ?word?
refers to a word occurrence (and not uniqueword).
Therefore, k is the length of the source text F .14672.
For each document, we generate a topic z withprobability piz|c.3.
Given topic z, we generate each word e in thetarget language document independently froma categorical distribution with probability ?e|z.4.
For each word e in the target language, we gen-erate a word f in the source language inde-pendently from a categorical distribution withprobability ?f |e.4Under this model, for one target docu-ment (e1, ..., ek) and its corresponding sourcedocument (f1, ..., fk), the joint probabilityp(z, c, e1, ..., ek, f1, ..., fk) is?cpiz|ck?j=1?ej|z?
?fj|ej.The parameter vector ?zspecifies the target wordprobabilities ?e|zthat can be learned from the targetlanguage training data as described in Section 3.1.The parameter vector ?especifies the word transla-tion probability ?f |efor a target word e into a sourcelanguage word f .
These word translation probabil-ities are determined with the help of the bilingualdictionary as described in Section 3.2.Our goal is to estimate the translation probabilityp(e|fj, F ), since this allows us to calculateE[countE(e)|F ] =k?j=1p(ej= e|fj, F ) .
(2)Note, that under our proposed probabilistic model, itholds thatp(ej|fj, F ) =?zp(ej|fj, z) ?
p(z|F ) .This can be interpreted as follows.
First, the modeldetermines a probability distribution over the latenttopics, conditioned on the given input source docu-ment, i.e.
p(z|F ).
And then, second, the model usesthe conditional probability p(z|F ) to determine the4It might seem that we need cross-lingually aligned docu-ments, or documents of same length in both languages.
How-ever, both is not the case, since in our experiments the trans-lations will always be unobserved, and therefore sum over allpossible translations.translation probability for each word in the sourcedocument, i.e.
p(ej|fj, z).The actual calculation of p(ej= e|fj, F ) can bederived as follows.5p(ej|fj, F ) = p(ej|f1, ..., fk)?
p(ej, f1, ..., fk)=?c?zp(ej, f1, ..., fk|z)p(z|c)p(c) ,where the probability p(ej, f1, ..., fk|z) can be effi-ciently calculated using?el1?V...?elk?1?Vp(e1, .
.
.
, ek, f1, .
.
.
, fk|z)=?el1?V...?elk?1?Vk?j?=1?fj?|ej??
?ej?|z= ?fj|ej?
?ej|z?j??{l1...lk?1}?ej??V?fj?|ej??
?ej?|z,where the indexes l1.
.
.
lk?1correspond to1, .
.
.
, j ?
1, j + 1, .
.
.
k.3.1 Learning ?c, piz|c, and ?e|zNote that under our model, class c and topic z are in-dependent from f1, ..., fkgiven document e1, ..., ekin the target language.
Therefore, the parameters?c, piz|c, and ?e|zcan be learned solely using thetraining documents in the target language.
Given acollection of training documents with known classesD = {(E1, c1)..., (En, cn)}, we can estimate the pa-rameters as follows.Parameter ?cis estimated using the maximum-likelihood (ML), which is?
?c=?ni=11c(ci)n, (3)where 1x(y) is the indicator function which is 1, ifx = y, otherwise 0.The optimal ML-estimate of ?e|zand piz|ccanbe found by maximizing log p(D|?, pi), for which,however, an analytic solution cannot be derived.Therefore, instead, we use the EM-algorithm5When it is clear from the context, we write p(ej) instead ofp(ej= e).1468(Dempster et al, 1977), deriving for the E-step: set-ting the probability distribution q top(zi|D,?, pi) ?
pizi|ciki?j=1?ej?ej|zi, (4)and in the M-step:?
?e|z=?ni=1?kij=11e(ej) ?
q(zi= z)?ni=1?kij=1q(zi= z)(5)andpi?z|c=?ni=11c(ci) ?
q(zi= z)?ni=1q(zi= z).
(6)3.2 Learning ?f |eHere we propose to chose the translation probabili-ties ?f |ewith highest probability, under our currentmodel, and such that the probability of observingthe source documents (without labels) is maximized.Formally, given a collection of source documentsD?
:= F1, ..., Fm, the optimal translation probabil-ity ?
?f |eisargmax?f|ep(D?|?f |e, ?
?c, pi?z|c, ?
?e|z) ,where ?
?c, pi?z|c, ?
?e|zare the parameters learned in theprevious section.
Unfortunately, the exact optimiza-tion is intractable, and therefore, we resort again toan EM-approximation, analogously to before.The E-step corresponds to setting for each sourcedocument i, the probability q(ei,1, ..., ei,ki) top(ei,1, ..., ei,ki|fi,1, .
.
.
fi,k, ?f |e)?
?ci?zip(ci)p(zi|ci)k?j=1p(ei,j|zi)?fi,j|ei,j.In the M-step, we update ?f |eto?
?f |e=?mi=1?kij=11f(fj,i) ?
q(ei,j= e)?mi=1?kij=1q(ei,j= e).4 ExperimentsFor our experiments we use three pair of corporadenoted by NEWS, WEB, and TWEETS.
The cor-pora NEWS contains news articles in English andMethod NEWS WEB TWEETSCo 0.687 (0.68) 0.842 (0.84) 0.430 (0.18)Co (freq) 0.668 (0.68) 0.849 (0.83) 0.424 (0.20)Co (uni) 0.666 (0.68) 0.842 (0.83) 0.426 (0.22)Wu et al 0.632 (0.56) 0.849 (0.74) 0.391 (0.13)Freq 0.635 (0.58) 0.842 (0.76) 0.376 (0.13)Uniform 0.628 (0.53) 0.856 (0.76) 0.407 (0.13)CN/JA only 0.816 (0.81) 0.893 (0.90) 0.894 (0.89)EN only 0.718 (0.67) 0.967 (0.97) 0.682 (0.67)Table 1: Shows the break-even point (f1-score) of the pro-posed method Co and three baselines for each pair of cor-pora.
Co (freq) and Co (uni) denote the proposed methodwithout estimation of dictionary probabilities, but insteadusing word frequency and uniform distribution, respec-tively.Japanese crawled from Internet news sites during2012-2013, and were annotated as being related to?foreign policy?
or not related.
The corpora WEBcontains web pages in English and Chinese that arecategorized either as ?sport?
or ?computer?
in theOpen Directory Project (ODP)6crawled in 2013.TWEETS contains tweets in English and Chinesegathered during 2013, classified as related to ?vio-lence?, or not related.7We tokenize and stem the words in the Englishcorpora using Senna (Collobert et al, 2011).
ForChinese and Japanese we use the morphological an-alyzers described in (Qiu et al, 2013), and an in-house analyzer, respectively.
The Chinese to Englishdictionary, and the Japanese to English dictionarycontains translations for 94351 and 1483440 words,respectively.For the classification we use LIBSVM (Changand Lin, 2011) with linear kernel, and the featurerepresentation as suggested in (Rennie et al, 2003).For the parameter estimation of our proposedmodel we use EM, as described in Section 3.1 and3.2.8The number of topics was determined by opti-mizing the f1-measure using only the English train-ing data when applying the probabilistic model tomonolingual text classification.
In order to preventnon-zero probabilities, we use a symmetric Dirichlet6www.dmoz.com7The number of documents in the corpora pairs forsource/target language are 2472/2289, 1302/6294, and2005/1499 for NEWS, WEB and TWEETS, respectively.8We observed convergence for less than 50 iterations.1469prior.We compare our proposed method ?Co?
to fourdifferent baselines that also use solely a bilingualdictionary.
For all methods (baselines and pro-posed), we use Equation (2) to estimate the expectedword frequencies.
The baseline ?Wu et al?
refersto the method proposed in (Wu et al, 2008).
Thebaseline ?Freq?
sets the probability p(e|f) to be pro-portional to the word frequency in the training data.Analogously, the baseline ?Uniform?
assumes a uni-form probability over all translations of f .For measuring the performance of each text clas-sifier we use precision and recall.
The break-evenpoint9and the f1-measure of our proposed methodand all baselines are shown in Table 1.
As can beseen, our method performs favorable for the NEWSand TWEETS corpora.
For the WEB corpora pairand our proposed method is at par with the base-line ?Wu et al?, and looses slightly to the ?Uni-form?
baseline.
For reference, we also show the up-per bounds ?CN/JA only?
and ?EN only?
that trainand test in the same source and target language, re-spectively.10We also analyzed the contribution of using theword translation probabilities learned in Section 3.2.The method ?Co (freq)?
is the same as our pro-posed method, except that the translation proba-bilities p(f |e) are not estimated using the methoddescribed in Section 3.2, but instead simply usesthe word-frequency distribution.
Analogously, themethod ?Co (uni)?
is the same as our proposedmethod, except that p(f |e) is set to the uniformprobability for all translations of e. Limiting the dis-cussion to break-even points, we see, in Table 1, animprovement of around 2 percent points for NEWS,but only minor changes in performance for the othertwo corpora (WEB and TWEETS).Finally, we give an example which shows thetranslation probabilities for the word ??
(restrict,restrain, custody) for two different source docu-ments in NEWS.
The first source document F1re-ports a military action, and is labeled as ?foreignpolicy?.
The second document F2is a news articleabout terror, and is labeled as ?not foreign policy?.The results shown in Table 2, confirm our intuition,9That is the point where precision and recall are equal.10These results were acquired using cross-validation.that the translation ?custody?
is more likely in doc-uments related to crime.e = restrict e = restrain e = custodyp(e|f, F1) 0.33 0.10 0.57p(e|f, F2) 0.02 0.00 0.98Table 2: Shows the translation probabilities for the sourceword f = ?
?, within document F1(military related,class is ?foreign policy?)
and document F2(terror related,class is not ?foreign policy?
).5 ConclusionsIn contrast, to most previous work, we focusedon the word translation problem, rather than thedomain-adaptation problem for cross-lingual textclassification.
We have proposed a probabilisticmodel that allows us to estimate word-translationprobabilities that are conditioned on the wholesource document.
Our experiments on three differ-ent pairs of corpora, show that our estimated transla-tion probabilities can improve text classification ac-curacy, and that our estimated word translation prob-abilities are able to reflect the topic of a text.ReferencesChih-Chung Chang and Chih-Jen Lin.
2011.
LIBSVM:A library for support vector machines.
ACM Transac-tions on Intelligent Systems and Technology, 2:27:1?27:27.
Software available at http://www.csie.ntu.edu.tw/?cjlin/libsvm.Ronan Collobert, Jason Weston, L?eon Bottou, MichaelKarlen, Koray Kavukcuoglu, and Pavel Kuksa.
2011.Natural language processing (almost) from scratch.The Journal of Machine Learning Research, 12:2493?2537.Arthur P Dempster, Nan M Laird, Donald B Rubin, et al1977.
Maximum likelihood from incomplete data viathe em algorithm.
Journal of the Royal statistical So-ciety, 39(1):1?38.Jagadeesh Jagarlamudi and Jianfeng Gao.
2013.
Mod-eling click-through based word-pairs for web search.In Proceedings of the ACM SIGIR Conference, pages483?492.
ACM.P.
Koehn and K. Knight.
2000.
Estimating word trans-lation probabilities from unrelated monolingual cor-pora using the em algorithm.
In Proceedings of theNational Conference on Artificial Intelligence, pages711?715.
Association for the Advancement of Artifi-cial Intelligence.1470Xiaochuan Ni, Jian-Tao Sun, Jian Hu, and Zheng Chen.2011.
Cross lingual text classification by mining mul-tilingual topics from wikipedia.
In Proceedings ofthe ACM International Conference on Web Search andData Mining, pages 375?384.
ACM.John C Platt, Kristina Toutanova, andWen-tau Yih.
2010.Translingual document representations from discrimi-native projections.
In Proceedings of the Conferenceon Empirical Methods in Natural Language Process-ing, pages 251?261.
Association for ComputationalLinguistics.Xipeng Qiu, Qi Zhang, and Xuanjing Huang.
2013.
Fu-dannlp: A toolkit for chinese natural language process-ing.
In Proceedings of Annual Meeting of the Associ-ation for Computational Linguistics.Jason D Rennie, Lawrence Shih, Jaime Teevan, andDavid R Karger.
2003.
Tackling the poor assump-tions of naive bayes text classifiers.
In Proceedingsof the International Conference on Machine Learning,volume 3, pages 616?623.Lei Shi, Rada Mihalcea, and Mingjun Tian.
2010.
Crosslanguage text classification by model translation andsemi-supervised learning.
In Proceedings of the Con-ference on Empirical Methods in Natural LanguageProcessing, pages 1057?1067.
Association for Com-putational Linguistics.Ke Wu, Xiaolin Wang, and Bao-Liang Lu.
2008.
Crosslanguage text categorization using a bilingual lexicon.In Proceedings of the International Joint Conferenceon Natural Language Processing, pages 165?172.1471
