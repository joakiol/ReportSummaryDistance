Speech Acts as a Basis for Understanding Dialogue CoherencebyC.
Raymond Perraul t  and James F. Al lenDept.
of Computer ScienceUnivers i ty  of TorontoToronto CanadaandPhi l ip  R. CohenBolt Beranek and NewmanCambridge Mass.i.
Introduct ionWebster 's  d ict ionary def ines"coherence" as "the qual i ty of beinglogical ly integrated, consistent,  andintel l igible".
If one were asked whethera sequence of physical  acts beingperformed by an agent was coherent, acrucial  factor in the decis ion would bewhether the acts were perceived ascontr ibut ing to the achievement of anoveral l  goal.
In that case they canfrequently be described briefly, by namingthe goal or the procedure executed toachieve it.
Once the intended goal hasbeen conjectured, the sequence can bedescr ibed as a more or less correct, moreor less optimal attempt at the achievementof the goal.One of the mainstreams of AI researchhas been the study of problem solvingbehaviour in humans and its s imulat ion bymachines.
This can be considered as thetask of transforming an initial state ofthe world into a goal state by f inding anappropr iate sequence of appl icat ions ofoperators from a given set.
Each operatorhas two modes of execution: in the f irstit changes the "real world", and in thesecond it changes a model of the realworld.
Sequences of these operators wecall plans.
They can be constructed,simulated, executed, opt imized anddebugged.
Operators are usual ly thoughtof as achieving certain effects and ofbeing appl icable only when certainprecondit ions hold.The effects of one agent executing hisplans may be observable by other agents,who, assuming that these plans wereproduced by the first agent's planconstruct ion algorithms, may try to inferthe plan being executed from the observedchanges to the world.
The fact that thisinferencing may be intended by the f irstagent underl ies human communicat ion.
* This research was supported in part bythe National Research Counci l  of Canada.Each agent maintains a model of theworld, including a model of the models ofother agents.
L inguist ic  utterances arethe result  of the execut ion of operatorswhose effects are main ly  on the modelsthat the speaker and hearer maintain ofeach other.
These effects are intended bythe speaker to be produced part ly  by thehearer 's  recognit ion of the speaker'splan.This view of the communicat ion processis very c lose in spir it  to the Aust in-Gr ice-St rawson-Sear le  approach toi l locut ionary acts, and indeed wasstrongly inf luenced by it.
We are workingon a theory of speech acts based on thenotions of plans, world models, planconstruct ion and plan recognit ion.
It isintended that this theory should answerquest ions such as:(i) Under what c i rcumstances can anobserver bel ieve that a speaker hass incerely and non-defect ive ly  performed apart icular i l locut ionary act in producingutterance for a hearer?
The observercould also be the hearer or speaker.
(2) What changes does the successfulexecut ion of a speech act make to thespeaker's  model of the hearer, and to theheater 's  model of the speaker?
(3) How is the meaning (sense/reference)of an utterance x related to the acts thatcan be performed in uttering x?A theory of speech acts based on plansmust specify at least the fol lowing:(i) A Planning System: a language fordescr ib ing states of the world, a languagefor descr ib ing operators and algor i thmsfor plan construct ion and plan inference.Semantics for the languages should also begiven.
(2) Def in i t ions of speech acts asoperators in the planning system.
Whatare their effects?
When are theyappl icable?
How can they be real ized inwords?125To make possib le a first attempt atsuch a theory we have imposed severalrestr ict ions on the system to be model led.
(I) Any agent Al's model of another agentA2 is def ined in terms of "facts" that A1bel ieves A2 believes, and goals that A1bel ieves A2 is attempting to achieve.
Weare not attempting to model obl igations,feel ings ~ etc.
(2) The only speech acts we try to modelare some that appear to be def inable interms of bel iefs and goals, namely REQUESTand INFORM.
We have been taking these tobe prototypical  members of Sear le 's"direct ive" and "representat ive" classes(Searle (1976)).
We represent quest ionsas REQUESTs to INFORM.
These acts areinteresting for they have a wide range ofsyntact ic real izat ions, and account for alarge proport ion of everyday utterances.
(3) We have l imited ourselves so far tothe study of so-cal led task-or ientedd ia logues which we interpret to beconversat ions between two agentscooperat ing in the achievement of a singlehigh- level  goal.
These dia logues do notal low changes in the topic of d iscoursebut stil l  d isplay a wide range ofl inguist ic behaviour.Much of our work so far has dealt  withthe problem of generat ing plans containingREQUEST and INFORM, as well as non-l inguist ic operators.
Suppose that anagent is attempting to achieve some task,with incomplete knowledge of that task andof the methods to complete it, but withsome knowledge of the abi l i t ies of anotheragent.
How can the f irst agent make use ofthe abi l i t ies of the second?
Under whatc i rcumstances can the first useful lyproduce utterances to transmit or acquirefacts and goals?
How can he init iateact ion on the part of the second?We view the plan related aspects oflanguage generat ion and recognit ion asindissociable,  and strongly related to theprocess by which agents cooperate in theachievement of goals.
For example, foragent2 to reply "It's closed" to agent l 'squery "Where's the nearest servicestation?"
seems to require him to inferthat agentl wants to make use of theservice stat ion which he could not do ifit were closed.
The reply "Two blockseast" would be seen as mis leading if g ivenalone, and unnecessary if g iven along with"It 's closed".
Thus part  of cooperat ivebehaviour is the detect ion by one a~ent ofobstacles in the plans he bel ieves theother agent holds, possib ly fo l lowed by anattempt to overcome them.
We claim thatspeakers expect (and intend) hearers tooperate this way and therefore that anyhearer can assume that inferences that hecan draw based on knowledge that is sharedwith the speaker are in fact intended bythe speaker.
These processes under!~e ouranalysis  of indirect speech acts (such as"Can you pass the salt?")
- utteranceswhich appear to result from onei l locut ionary act but can be used toperform another.Sect ion 2 of this paper out l ines somerequirements on the models which thevar ious agents must have of each other.Sect ion 3 descr ibes the planning operatorsfor REQUEST and INFORM, and how they canbe used to generate plans which includeassert ions,  imperatives, and several typesof questions.Sect ion 4 d iscusses the relat ionbetween the operators  of sect ion 3 and thel inguist ic  sentences which can realizethem.
We concentrate on the problem ofidenti fying i l locut ionary force, inpart icular  on indirect speech acts.
Auseful consequence of the i l locut ionaryforce ident i f icat ion process is that itprovides a natural way to understand someel l ipt ical  utterances, and utteranceswhose purpose is to acknowledge, corrector c lar i fy  interpretat ions of previousutterances.A cr i t ical  part of communicat ion isthe process by which a speaker canconstruct  descr ipt ions of objects involvedin his plans such that the hearer canidentify the intended referent.
Why cansomeone asking "Where's the screwdriver?
"be answered with "In the drawer with thehammer" if it is assumed he knows wherethe hammer is, but maybe by "In the thirddrawer from the left" if he doesn't.
Howaccurate must descr ipt ive phrases be?Sect ion 5 examines how the speaker andhearer 's  models of each other inf luencetheir references.
Final ly, sect ion 6contains some ideas on future research.Most examples in the paper are drawnfrom a s i tuat ion in which one part ic ipantis an information clerk at a trainstation, whose object ive is to assistpassengers  in boarding and meeting trains.The domain is obviously l imited, but stil lprovides a natural  setting for a widerange of utterances, both in form and inintention.2.
On models  of othersIn this section we present  cr i ter iathat one agent 's  model of another ought tosatisfy.
For convenience we dub theagents SELF and OTHER.
Our research hasconcentrated on model l ing bel iefs andgoals.
We claim that a theory of languageneed not be concerned with what isactual ly  true in the real world: itshould descr ibe language processing interms of a person's bel iefs  about theworld.
Accordingly,  SELF's model of OTHERshould be based on "believe" as descr ibed,for example, in Hint ikka(1962) and not on"know" in its sense of "true belief".126Henceforth, all uses of the words "know"and "knowledge" are to be treated assynonyms for "believe" and "beliefs".
Wehave neglected other aspects of a model ofanother, such as focus of attent ion (butsee Grosz(1977)) .Bel iefClearly, SELF ought to be able tod ist inguish his bel iefs about the worldfrom what he bel ieves other bel ieves.SELF ought to have the poss ib i l i ty  ofbel ieving a proposi t ion P, of bel ievingnot-P, or of being ignorant of P.Whatever his stand on P, he should also beable to bel ieve that OTHER can hold any ofthese posit ions on P. Not ice that suchd isagreements  cannot be represented if therepresentat ion is based on "know" as inMoore(1977).SELF's bel ief representat ion ought toal low him to represent the fact that OTHERknows whether some proposi t ion P is true,without SELFIs having to know which of Por -P he does believe.
Such informationcan be represented as a d is junct ion ofbel iefs (e.g., OR(OTHER BELIEVE P, OTHERBELIEVE ~P)) .
Such d is junct ions areessential  to the planning of yes/noquestions.Finally, a bel ief  representat ion mustd ist inguish between situat ions l ike thefol lowing:I.
OTHER bel ieves that the train leavesfrom gate 8.2.
OTHER bel ieves that the train has adeparture gate.3.
OTHER knows what the departure gate forthe train is.Case 1 can be represented by a proposi t ionthat contains no variables.
Case 2 can berepresented by a bel ief  of a quanti f iedproposi t ion -- i.e.,OTHER BELIEVE (x (the y ~ GATE(TRAIN,y) = x))However, case 3 is representedquanti f ied bel ief namely,x OTHER BELIEVE(the y : GATE(TRAIN,y) = x)by aThe formal semantics such bel iefs havebeen problematic for phi losophers (cf.Quine (1956) and Hint ikka (1962)).
Ourapproach to them is discussed in Cohen(1978).
In Section 3, we discuss howquanti f ied bel iefs are used duringplanning, and how they can be acquiredduring conversat ion.WantAny representat ion of OTHER's goals(wants) must d ist inguish such informationfrom: OTHER'S beliefs, SELF's bel iefs andgoals, and (recursively) from the other 'smodel of someone else's bel iefs and goals.The representat ion for WANT must alsoal low for d i f ferent scopes of quantif iers.For example, it should d ist inguish betweenthe readings of "John wants to take atrain" as "There is a specif ic train whichJohn wants to take" or as "John wants totake any train".
F inal ly it should al lowarbi t rary embeddings with BELIEVE.
Wantsof bel iefs (as in "SELF wants OTHER tobel ieve P") become the reasons for tel l ingP to OTHER, whi le bel iefs of wants (e.g.,SELF Bel ieves SELF wants P) will be theway to represent SELF's goals P.Level____~s of  EmbeddingA natural quest ion to ask is how manylevels of bel ief embedding are needed byan agent capable of part ic ipat ing in adialogue.
Obviously,  to be able to dealwith a disagreement,  SELF needs two levels(SELF BELIEVE and SELF BELIEVE OTHERBELIEVE ).
If SELF were to lie to OTHER,he would have to be able to bel ieve someproposi t ion P (i.e.
SELF BELIEVE (P)),whi le OTHER bel ieves that SELF bel ievesnot P (i.e.
SELF BELIEVE OTHER BELIEVESELF BELIEVE (~P)), and hence he wouldneed at least three levels.We show in Cohen (1978) how one canrepresent, in a f inite fashion, theunbounded number of bel iefs created by anycommunicat ion act or by face-to-facesituations.
The finite representat ion,which employs a circular data structure,formal izes the concept of mutual bel ief(cf.
Schiffer (1972)).
Typical ly,  allthese levels of bel ief embedding can berepresented in three levels, buttheoret ical ly,  any finite number arepossible.3.
U?in@ a Model of the Other to DecideWhat to SayAs an  aid in evaluat ing speech actdef init ions,  we have constructed acomputer program, OSCAR, that plans arange of speech acts.
The goal of theprogram is to character ize a speaker'scapaci ty  to issue speech acts bypredict ing, for specif ied situations, alland only those speech acts that would beappropr iate ly  issued by a person under thec ircumstances.
In this section, we willmake reference to prototypical  speakers byway of the OSCAR program, and to hearersby way of the program's user.Specif ia l ly,  the program is able to:- Plan REQUEST speech acts, for instancea speech act that could be real ized by127"Please open the door", when its goal isto get the user to want to perform someaction.- Plan INFORM speech acts, such as onethat could be real ized by "The door islocked", when its goal is to get the userto bel ieve some proposit ion.- Combine the above to produce mult ip lespeech acts in one plan, where one speechact may establ ish bel iefs of the user thatcan then be employed in the planning ofanother speech act.- Plan quest ions as requests that theuser inform, when its goal is to bel ievesomething and when it be l ieves that theuser knows the answer.- P lan speech acts incorporat ing thirdpart ies,  as in "Ask Tom to tell you wherethe key is and then tell me.
"To i l lustrate the planning of speechacts, consider f irst the fol lowings impl i f ied def in i t ions  of REQUEST andINFORM as STRIPS- l ike  operators  (cf.
F ikesand Ni l sson (1971)).
Let SP denote thespeaker, H the hearer, ACT some action,and PROP some proposi t ion.
Due to spacel imitat ions,  the intuit ive Engl ishmeanings of the formal terms appearing inthese def in i t ions  wil l  have to suff ice asexplanat ion.REQUEST(SP,H,ACT)precondit ions:SP BELIEVE H CANDO ACTSP BELIEVE H BELIEVE H CANDO ACTSP BELIEVE SP WANT TO REQUESTeffects:H BELIEVE SP BELIEVE SP WANT H TO ACTINFORM(SP,H,PROP)precondit ions:SP BELIEVE PROPSP BELIEVE SP WANT TO INFORMeffects:H BELIEVE SP BELIEVE PROPThe program uses a s impl ist icbackward-chain ing a lgor i thm that plansactions when their ef fects  are wanted assubgoals that are not bel ieved to betrue.
It is the testing of precondi t ionsof the newly planned act ion beforecreating new subgoals that exerc ises theprogram's model of its user.
We shallbr ief ly sketch how to plan a REQUEST.Every act ion has "want precondit ions" ,which speci fy  that before an agent doesthat action, he must want to do it.
OSCARplans REQUEST speech acts to achieveprec ise ly  this precondi t ion  of act ionsthat it wants the user to perform.Similar ly,  the goal of the user'sbel ieving some propos i t ion PROP becomesOSCAR'S reason for planning to INFORM himof PROP.Suppose, for example, that OSCAR isouts ide a room whose door is c losed andthat it be l ieves that the user is inside.When planning to move itself into theroom, it might  REQUEST that the user openthe door.
However, it would only planthis speech act if it bel ieved that theuser did not a lready want to open the doorand if it bel ieved (and bel ieved the userbelieved) that the precondi t ions  toopening the door held.
If that were notso, OSCAR could plan addit ional  INFORM orREQUEST speech acts.
For example, assumethat to open a door one needs to have thekey and OSCAR bel ieves the user doesn ' tknow where it is.
Then OSCAR could plan"Please open the door.
The key is in thecloset".
OSCAR thus employs its usermodel  in tel l ing him what it bel ieves heneeds to know.Mediat ing Acts and Per locut ionary  Ef fectsThe effects of INFORM (and REQUEST)are model led so that the bearer 'sbel ieving P (or wanting to do ACT) is notessent ia l  to the successful  complet ion ofthe speech act.
Speakers, we claim,cannot inf luence their hearers' bel iefsand goals direct ly.
Thus, theper locut ionary  effects of a speech act arenot part of that act's def in i t ion.
Wepropose, then, as a pr inc ip le  ofcommunicat ion  that a speaker 's  purpose ins incere communicat ion is to produce in thehearer an accurate model of his mentalstate.To br idge the gap between the speechacts and their intended per locut ionaryeffects,  we posi t  mediat ing acts, namedCONVINCE and DECIDE, which model what ittakes to get someone to bel ieve somethingor want to do something.
Our currentanalys is  of these mediat ing actst r iv ia l i zes  the processes that they areintended to model  by proposing that toconvince someone of something, forexample, one need only get that person toknow that one bel ieves it.Using Quant i f ied Bel iefs  -- P lanningQuest ionsNot ice that theOSCAR's  gett ing the keyit is -- is of the form:precond i t ion  to-- knowing wherex OSCAR BELIEVE(the y : LOC(KEY,y) = x)When such a quant i f ied bel ief  is a goal,it leads OSCAR to plan the quest ion "Whereis the key?"
(i.e., REQUEST(OSCAR,  USER,INFORM(USER, OSCAR, the yLOC(KEY,y)) ) .
In creat ing this question,OSCAR f irst p lans a CONVINCE and thenplans the user's INFORM speech act, whichit then tries to get him to perform by wayof request ing.128The above def in i t ion of INFORM isinadequate for deal ing with the quant i f iedbel iefs that arise in model l ing someoneelse.
This INFORM should be viewed asthat version of the speech act that theplanning agent (e.g., OSCAR) plans foritself to perform.
A di f ferent v iew ofINFORM, say INFORM-BY-OTHER, is necessaryto represent acts of informing by agentsother than the speaker.
The d i f ferencebetween the two INFORMs is that for thefirst, the planner knows what he wants tosay, but he obviously does not have suchknowledge of the content of the secondact.The precondit ion for this new act is aquanti f ied speaker-bel ief :x USER BELIEVE(the y : LOC(KEY,y) = x)where the user is to be the speaker.
Forthe system to plan an INFORM-BY-OTHER actfor the user, it must bel ieve that theuser knows where the key is, but it doesnot have to know that location!Similarly, the effects of the INFORM-BY-OTHER act is also a quanti f ied belief, asinx OSCAR BELIEVEUSER BELIEVE(the y .~ LOC(KEY,y) = x)Thus, OSCAR plans this INFORM-BY-OTHER actof the key's locat ion in order to knowwhere the user thinks the key is.Such information has been lackingfrom all other formulat ions of ASK (orINFORM) that we have seen in thel i terature (e.g., Schank (1975), Mann etal.
(1976), Searle (1969)).
Cohen (1978)presents one approach to def ining this newview of INFORM, and its associatedmediat ing act CONVINCE.4.
Recogniz in @ Speech ActsIn the previous section we discussedthe structure of p lans  that includeinstances of the operators REQUEST andINFORM without explaining the relat ionbetween these speech acts and sentencesused to perform them.
This sect ionsketches our first steps in explor ing thisrelation.
We have been part icu lar lyconcerned with the problem of recogniz ingi l l ocut ionary  force and proposi t ionalcontent of the utterances of a speaker.Detai led algor i thms which handle theexamples given in this section have beendesigned by J. Al len and are beingimplemented by him.
Further detai ls  canbe found in (Allen and Perrault  1978) andAl len's  forthcoming Ph.D. d issertat ion.Certain syntactic clues in anutterance such as its mood and the use ofexpl ic i t  per format ives indicate what actthe speaker intends to perform, but' as iswell known, utterances which takenl i tera l ly  would indicate one i l locut ionaryforce can be used to indicate another.Thus "Can you close the door?"
can be arequest as well as a question.
These so-called indirect speech acts are the acidtest of a theory of speech acts.
We claimthat a p lan-based theory gives someinsight into this phenomenon.Searle(1975) correct ly suggests that"In cases where these sentences <indirectforms of requests> are uttered asrequests, they sti l l  have their l iteralmeaning and are uttered with and as havingthat l i teral meaning".
How then can theyalso have their indirect meaning?Our answer rel ies in part on the factthat an agent part ic ipat ing in acooperat ive d ia logue must have processesto:(I) Achieve goals based on what hebelieves.
(2) Adopt goals of other agents as hisown.
(3) Infer goals of other agents.
(4) Predict  future behaviour of otheragents.These processes would be necessary even ifall speech acts were l i te ra l  to accountfor exchanges where the response indicatesa knowledge of the speaker's plan.
ForexamplePassenger: "When does the next train toMontreal  leave?
"Clerk : "At 6:15 at Gate 7"orClerk - "There won't  be one untiltomorrow.
"Speakers expect hearers to beexecut ing these processes and they expecthearers to know this.
Inferences that ahearer can draw by executing theseprocesses based on information he thinksthe speaker bel ieves can be taken by thehearer to be intended by the speaker.This accounts for many of the standardexamples of indirect speech acts such as"Can you close the door?"
and "It's coldhere".
For instance, even if "It 's coldhere" is intended l i teral ly  and isrecognized as such, the helpful hearer maysti l l  c lose the window.
When the sentenceis uttered as a request, the speakerintends the hearer to recognize thespeaker 's  intention that the hearer shouldperform the helpful behaviour.If indirect speech acts are to beexplained in terms of inferences speakerscan expect of hearers, then a theory ofspeech acts must concern itself with howsuch inferences are control led.
Someheur ist ics  are part icu lar ly  helpful.
If achain of inference by the hearer has thespeaker planning an action whose effects129are true before the action is executed,then the chain is l ikely to be wrong, orelse must be cont inued further.
Thisaccounts for "Can you pass the salt?"
as arequest for the salt, not a quest ion aboutsalt -passing prowess.
As Searle(1975)points out, a crucial part ofunderstanding indirect speech acts isbeing able to recognize that they are notto be interpreted l iteral ly.A second heur ist ic  is that a chain ofinference that leads to an action whoseprecondi t ions are known to be not easi lyachievable is l ikely to be wrong.Inferencing can also be control ledthrough the use of expectat ions about thespeaker 's  goals.
Pr ior i ty can be given toinferences which relate an observed speechact to an expected goal.
Expectat ionsenable inferencing to work top-down aswell as bottom-up.The use of expected goals to guide theinferencing has another advantage: ita l lows for the recognit ion ofi l locut ionary force in el l ipt icalutterances such as "The 3:15 train toWindsor?
",  wi thout  requir ing that thesyntact ic and semantic analysis"reconst i tute" a complete semanticrepresentat ion such as "Where does the3:15 train to Windsor leave?".
Forexample, let the clerk assume thatpassengers want to either meet incomingtrains or board depart ing ones.
Then theutterance "The 3:15 train to Windsor?"
isf irst interpreted as a REQUEST about atrain to Windsor with 3:15 as eitherarr ival or departure time.
Only depart ingtrains have dest inat ions d i f ferent  fromToronto and this leads to bel ieving thatthe passenger wants to board a 3:15 trainto Windsor.
Attempting to identifyobstacles in the passenger 's  plan leads tof inding that the passenger knows the timebut probably not the place of departure.Final ly, overcoming the obstacle thenleads to an INFORM like "Gate 8".Our analysis of el l ipt ical  utterancesraises two questions.
First, whatinformation does the i l locut ionary forcerecognit ion module expect from the syntaxand semantics?
Our approach here has beento require from the syntax and semantics ahypothesis  about the l iteral i l locut ionaryforce and a predicate ca lcu lus- l ikerepresentat ion of the proposi t ionalcontent, but where undetermined predicatesand objects could be replaced by patternson which certain restr ict ions can beimposed.
As part of the plan inferencingprocess these patterns become furtherspecif ied.The second quest ion is: what shouldthe hearer do if more than one pathbetween the observed utterance and theexpectat ions is possible?
He may suspendplan deduct ion and start planning toachieve a goal which would al low plandeduct ion to continue.
Consider thefol lowing example.Passenger : When is the Windsor train?Clerk : The train to Windsor?Passenger : Yes.Clerk : 3:15.After the first sentence the clerkcannot d ist inguish between theexpectat ions "Passenger travel by train toWindsor" and "Passenger meets train fromWindsor",  so he sets up a goal : (clerkbel ieves passenger wants to travel) or(clerk bel ieves passenger wants to meettrain).
The planning for this goalproduces a plan that involves asking thepassenger if he wants one of theal ternat ives,  and receiving back theanswer.
The execut ion of this planproduces the clerk response "The train toWindsor?"
and recognizes the response"Yes".
Once the passenger 's  goal isknown, the clerk can cont inue the or iginaldeduct ion process with the "travel toWindsor" a l ternat ive favoured.
This planis accepted and the clerk produces theresponse "3:15" to overcome the obstac le"passenger knows departure time".5.
Reference and the Model of the OtherWe have shown that quant i f ied bel iefsare needed in deciding to ask someone aquestion.
They are also involved, weclaim, in the representat ion of s ingulardef in i te  noun phrases and hence anynatural  language system wil l  need them.According to our analysis,  a hearer shouldrepresent the referr ing phrase in aspeaker 's  statement "The pi lot  of TWA 510is drunk" by:x SPEAKER BELIEVE(the y : P ILOT(y,TWA510) = x &DRUNK (x))This is the reading whereby the speaker isbel ieved to "know who the pi lot  of TW~ 510is" (at least part ia l ly  accounting forDonnel lan 's  (1966) referent ial  reading).This is to be contrasted with the readingof whoever is pi lot ing that plane is drunk(Donnel lan's attr ibut ive noun phrases).In this latter case, the existent ia lquant i f ier  would be inside the scope ofthe belief.These existent ia l  presuppos i t ions  ofdef in i te referential  noun phrases give oneimportant way for hearers to acquirequanti f ied speaker-bel iefs .
Such bel iefs,we have seen, can be used as the basis forplanning further c lar i f icat ion questions.We agree with Strawson (1950) (andmany others) that hearers understandreferr ing phrases based on what theybel ieve speakers intend to refer to.130Undoubtedly,  a hearer wil l  understand aspeaker's  (reference) intentions by usinga model of that speaker's beliefs.Speakers, of course, know of theseinterpretat ion strategies and thus plantheir referr ing phrases to take theappropr iate referent within the hearer 'smodel of them.
A speaker cannot usepr ivate descr ipt ions,  nor descr ipt ionsthat he thinks the hearer thinks areprivate, for communicat ion.For instance, consider the fol lowingvariant of an example of Donnel lan's(1966): At a party, a woman is holding amart ini  glass which Jones bel ievescontains water, but of which he is certaineveryone else bel ieves (and bel ieves hebelieves) contains a martini .
Jones wouldunderstand that Smith, via quest ion (I),but not via quest ion (2) is referr ing tothis woman.
(i) Who is the woman holding the mart ini?
(2) Who is the woman holding the water?since Jones does not bel ieve Smith knowsabout the water in her glass.Conversely,  if Jones wanted to referto the woman in an utterance intended forSmith, he could do so using (i) but not(2) since in the latter case he would notthink the hearer could pick out hisintended referent.Thus it appears that for a speaker toplan a successful  singular def in i tereferential  express ion requires that thespeaker bel ieve the express ion he f inal lychooses have the right referent in thehearer 's  model of the speaker.
Ourconcept of mutual bel ief  can be used (asin Cohen (1978)) to ensure that theexpression denotes appropr iate ly  in allfurther embedded bel ief models.
Thisexample is problematic  for any approach toreference where a communicat ing partyassumes that its real i ty is the onlyreality.
Speakers and hearers can be"wrong" or "ignorant" and yetcommunicat ion can stil l  be meaningful  andsuccessful.6.
Further ResearchWe bel ieve that speech acts provide anexcel lent  way of explaining the relat ionsbetween utterances in a dialogue, as wellas relating l inguist ic  to non- l inguist icactivity.
Unti l  we better understand themechanisms by which conversants change thetopic and goals of the conversat ion itwill be d i f f icu l t  to extend this analysisbeyond exchanges of a few utterances, inpart icular to non-task or iented dialogues.Fuller just i f icat ion of our approach alsorequires its appl icat ion to a much broaderrange of speech acts.
Here the problem ismain ly  representat ional :  how can wehandle promises without f irst deal ing withobl igat ions,  or warnings without thenot ions of danger and undesirabi l i ty?
Weare current ly  consider ing an extension ofthe approach to understanding storieswhich report s imple dialogue.Much remains to be done on therepresentat ion of the abi l i t ies of angtheragent.
A simple sett ing suggests a numberof problems.
Let one agent H be seated ina room in front of a table with acol lect ion of blocks.
Let another agentS be outside the room but communicat ing bytelephone.
If S bel ieves that there is agreen block on the table and wants itcleared, but knows nothing about any otherblocks except that H can see them, thenhow can S ask H to clear the green block?The blocks S wants removed are those whichare in fact there, perhaps those which hecould perceive to be there if he were inthe room.
The goal seems to be of theformS BELIEVEx (x on the green block => S WANT(x removed from green block))but our planning machinery and def in i t ionof REQUEST are inadequate for generat ing"I request you to clear the green block".We have not yet spent much timeinvest igat ing the process of givinganswers to How and Why questions, or to WHquest ions requir ing an event descr ipt ionas an answer.
We conjecture that becauseof the speech act approach answers to"What did he say?"
should be found in muchthe same way as answers to "What did hedo?"
and that this para l le l ism shouldextend to other quest ion types.
Thenatural extension of our analysis  wouldsuggest represent ing "How did AGT achievegoal G?"
as a REQUEST by the speaker thatthe hearer inform him of a plan by whichAGT achieved G. We have not yetinvest igated the repercuss ions of thisextension on the representat ion language.F inal ly consider the fol lowingdialogue.
Assume that S is a shadybusinessman, A his secretary.A : IRS is on the phone.S : I 'm not here.How is A to understand S's utterance?Al though its proposi t ional  content isl i tera l ly  false, maybe even nonsensical ,the utterance's  intention is unmistakable.How tolerant does the understanding systemhave to be to infer its way to a correctinterpretat ion?
Must "I'm not here" betreated id iomatical ly?131B ibl log r aphyAllen, J.F.
and Perrault, C.R.,"Participating in Dialogue:Understanding via Plan Deduction", 2ndNational Conference of the CanadianSociety for Studies in ComputationalIntelligence, Toronto, July, 1978.Cohen, P.R., "On Knowing What to Say:Planning Speech Acts", TRII8 Dept.
ofComputer Science, University ofToronto, 1978.Donnellan, K., "Reference and DefiniteDescription", The PhilosophicalReview, vol.
75, 1960, pp280-304.Reprinted in Semantics, Steinberg andJacobovits, eds., Cambridge UniversityPress, 1970.Fikes, R. E. and Nilsson, N. J., 1970,"STRIPS: A new approach to theapplication of theorem proving",Artificial Intelligence 2, 1970.Grosz, B. J., "The Representation and Useof Focus in Natural LanguageDialogues", 5IJCAI, 1977.Hintikka, K.J., Knowled~\[e and Belief,Cornell University Press, 1962.Mann, W.C., Moore, J.A., Levin, J.A.
; "AComprehension Model for HumanDialogue", 5IJCAI, 1977.Moore, R.C.
; "Reasoning about Knowledgeand Action", 5IJCAI, 1977.Quine, w.v., "Quantifiers andPropositional Attitudes", The Journalof Philosophy 53, (1956), 177-187.Schiffer, S., Meaning, Oxford UniversityPress, 1972.Schank, R. and Abelson, R., "Scripts,Plans and Knowledge", 4IJCAI, 1975.Searle, J. R., Speech Acts, CambridgeUniversity Press, 1969.Searle, J. R.; "Indirect Speech Acts" inSyntax and Semantics, Vol.
3: SpeechActs, Cole and Morgan (eds), AcademicPress, 1975.Searle, J. R., "A Taxonomy ofIllocutionary Acts", Language, Mindand Knowledge, K. Gunderson (ed.
),University of Minnesota Press, 1976.Strawson, P. F., "On Referring", Mind,1950.132
