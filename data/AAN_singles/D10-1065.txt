Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 667?673,MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Association for Computational LinguisticsCombining Unsupervised and Supervised Alignments for MT:An Empirical StudyJinxi Xu and Antti-Veikko I. RostiRaytheon BBN Technologies, 10 Moulton Street, Cambridge, MA 02138, USA{jxu,arosti}@bbn.comAbstractWord alignment plays a central role in statisti-cal MT (SMT) since almost all SMT systemsextract translation rules from word alignedparallel training data.
While most SMTsystems use unsupervised algorithms (e.g.GIZA++) for training word alignment, super-vised methods, which exploit a small amountof human-aligned data, have become increas-ingly popular recently.
This work empiricallystudies the performance of these two classesof alignment algorithms and explores strate-gies to combine them to improve overall sys-tem performance.
We used two unsupervisedaligners, GIZA++ and HMM, and one super-vised aligner, ITG, in this study.
To avoid lan-guage and genre specific conclusions, we ranexperiments on test sets consisting of two lan-guage pairs (Chinese-to-English and Arabic-to-English) and two genres (newswire and we-blog).
Results show that the two classes of al-gorithms achieve the same level of MT perfor-mance.
Modest improvements were achievedby taking the union of the translation gram-mars extracted from different alignments.
Sig-nificant improvements (around 1.0 in BLEU)were achieved by combining outputs of differ-ent systems trained with different alignments.The improvements are consistent across lan-guages and genres.1 IntroductionWord alignment plays a central role in training sta-tistical machine translation (SMT) systems since al-most all SMT systems extract translation rules fromword aligned parallel training data.
Until recently,most SMT systems used GIZA++ (Och and Ney,2003), an unsupervised algorithm, for aligning par-allel training data.
In recent years, with the availabil-ity of human aligned training data, supervised meth-ods (e.g.
the ITG aligner (Haghighi et al, 2009))have become increasingly popular.The main objective of this work is to show thetwo classes (unsupervised and supervised) of al-gorithms are complementary and combining themwill improve overall system performance.
The useof human aligned training data allows supervisedmethods such as ITG to more accurately align fre-quent words, such as the alignments of Chinese par-ticles (e.g.
?bei?, ?de?, etc) to their English equiv-alents (e.g.
?is/are/was/..?, ?of?, etc).
On the otherhand, supervised methods can be affected by sub-optimal alignments in hand-aligned data.
For exam-ple, the hand-aligned data used in our experimentscontain some coarse-grained alignments (e.g.
?lian-he guo?
to ?United Nations?)
although fine-grainedalignments (?lian-he?
to ?United?
and ?guo?
to ?Na-tions?)
are usually more appropriate for SMT.
Un-supervised methods are less likely to be affectedby this problem.
We used two well studied unsu-pervised aligners, GIZA++ (Och and Ney, 2003)and HMM (Liang et al, 2006) and one supervisedaligner, ITG (Haghighi et al, 2009) as representa-tives in this work.We explored two techniques to combine differentalignment algorithms.
One is to take the union ofthe translation rules extracted from alignments pro-duced by different aligners.
This is motivated bystudies that showed that the coverage of translationrules is critical to SMT (DeNeefe et al, 2007).
The667other method is to combine the outputs of differentMT systems trained using different aligners.
As-suming different systems make independent errors,system combination can generate a better transla-tion than those of individual systems through voting(Rosti et al, 2007).Our work differs from previous work in two ways.Past studies of combining alternative alignments fo-cused on minimizing alignment errors, usually bymerging alternative alignments for a sentence pairinto a single alignment with the fewest number ofincorrect alignment links (Ayan and Dorr, 2006).
Incontrast, our work is based on the assumption thatperfect word alignment is impossible due to the in-trinsic difficulty of the problem, and it is more effec-tive to resolve translation ambiguities at later stagesof the MT pipeline.
A main focus of much previouswork on word alignments is on theoretical aspectsof the proposed algorithms.
In contrast, the natureof this work is purely empirical.
Our system wastrained on a large amount of training data and evalu-ated on multiple languages (Chinese-to-English andArabic-to-English) and multiple genres (newswireand weblog).
Furthermore, we used a state of the artstring-to-tree decoder (Shen et al, 2008) to estab-lish the strongest possible baseline.
In comparison,experiments in previous studies typically used onelanguage pair and one genre (usually newswire), areduced amount of training data and a phrase baseddecoder.This paper is organized as follows.
Section 2 de-scribes the three alignment algorithms.
Section 3describes the two methods used to combine thesealigners to improve MT.
The experimental setupused to compare these methods is presented in Sec-tion 4.
Section 5 shows the results including a dis-cussion.
Section 6 discusses related work.
Section 7concludes the paper.2 Alignment AlgorithmsWe used three aligners in this work: GIZA++ (Ochand Ney, 2003), jointly trained HMM (Liang et al,2006), and ITG (Haghighi et al, 2009).
GIZA++is an unsupervised method based on models 1-5 ofBrown et al (1993).
Given a sentence pair e ?
f ,it seeks the alignment a that maximizes the proba-bility P (f, a|e).
As in most previous studies usingGIZA++, we ran GIZA++ in both directions, from eto f and from f to e, and symmetrized the bidirec-tional alignments into one, using a method similarto the grow-diagonal-final method described in Ochand Ney (2003).
We ran GIZA++ up to model 4.The jointly trained HMM aligner, or HMM forshort, is also unsupervised but it uses a small amountof hand-aligned data to tweak a few high level pa-rameters.
Low level parameters are estimated in anunsupervised manner like GIZA++.The ITG aligner is a supervised method whose pa-rameters are tuned to optimize alignment accuracyon hand-aligned data.
It uses the inversion transduc-tion grammar (ITG) (Wu, 1997) to narrow the spaceof possible alignments.
Since the ITG aligner usesfeatures extracted from HMM alignments, HMMwas run as a prepossessing step in our experiments.Both the HMM and ITG aligners are publicly avail-able1.3 Methods of Combining AlternativeAlignments for MTWe explored two methods of combining alternativealignments for MT.
One is to extract translation rulesfrom the three alternative alignments and take theunion of the three sets of rules as the single transla-tion grammar.
Procedurally, this is done by concate-nating the alignment files before extracting transla-tion rules.
We call this method unioned grammar.This method greatly increases the coverage of therules, as the unioned translation grammar has about80% more rules than the ones extracted from the in-dividual alignment in our experiments.
As such, de-coding is also slower.The other is to use system combination to com-bine outputs of systems trained using different align-ers.
Due to differences in the alignment algorithms,these systems would produce different hypotheseswith independent errors.
Combining a diverse setof hypotheses could improve overall system perfor-mance.
While system combination is a well-knowntechnique, to our knowledge this work is the first toapply it to explicitly exploit complementary align-ment algorithms on a large scale.Since system combination is an established tech-nique, here we only briefly discuss our system com-1http://code.google.com/p/berkeleyaligner/668bination setup.
The basic algorithm was described inRosti et al (2007).
In this work, we use incrementalhypothesis alignment with flexible matching (Rostiet al, 2009) to produce the confusion networks.
10-best lists from all systems are collected first.
All1-best hypotheses for each segment are used as con-fusion network skeletons, the remaining hypothesesare aligned to the confusion networks, and the result-ing networks are connected in parallel into a jointlattice with skeleton specific prior probabilities es-timated from the alignment statistics on the initialarcs.
This lattice is expanded with an unpruned bi-gram language model and the system combinationweights are tuned directly to maximize the BLEUscore of the 1-best decoding outputs.
Given thetuned system combination weights, a 300-best listis extracted from the lattice, the hypotheses are re-scored using an unpruned 5-gram language model,and a second set of system combination weights istuned to maximize the BLEU score of the 1-best hy-pothesis of the re-scored 300-best list.
The same re-scoring step is also applied to the outputs of individ-ual systems.4 Experiment SetupTo establish strong baselines, we used a string-to-tree SMT system (Shen et al, 2008), one of the topperforming systems in the NIST 2009 MT evalua-tion, and trained it with very large amounts of par-allel and language model data.
The system usedlarge sets of discriminatively tuned features (up to55,000 on Arabic) inspired by the work of Chiang etal.
(2009).
To avoid drawing language, genre, andmetric specific conclusions, we experimented withtwo language pairs, Arabic-English and Chinese-English, and two genres, newswire and weblog, andreport both BLEU (Papineni et al, 2002) and TER(Snover et al, 2006) scores.
Systems were tuned tomaximize BLEU on the tuning set using a proceduredescribed in Devlin (2009).The sizes of the parallel training corpora are238M words (target side) for Arabic-English MTand 265M words for Chinese-English.
While themajority of the data is publicly available from theLinguistic Data Consortium (LDC), some of the datais available under the DARPA GALE program.
Dueto the size of the parallel corpora, we divided theminto five chunks and aligned them in parallel to savetime.
Due to its running complexity, we ran ITGonly on sentences with 60 or fewer words.
Forlonger sentences, we used HMM alignments instead,which were conveniently generated in the prepro-cessing step of ITG aligner.
For language modeltraining, we used about 9 billion words of Englishtext, most of which are from English Gigaword cor-pus and GoogleNews.
Each system used a 3-gramLM for decoding and a 5-gram LM for re-scoring.The same 5-gram LM was also used for re-scoringsystem combination results.For each combination of language pair and genre,we used three development sets:?
Tune, which was used to tune parameters ofindividual MT systems.
Each system was tunedten iterations based on BLEU.?
SysCombTune, which was used to tune pa-rameters of system combination.
A subset of itwas also used as validation for determining thebest iteration in tuning individual systems.?
Test, which was the blind test corpus for mea-suring performances of both individual systemsand system combination.Test materials were drawn from two sources:NIST MT evaluations 2004 to 2008, and develop-ment and evaluation data for the DARPA GALE pro-gram.
Due to the mixing of different data sources,some test sentences have four reference translationswhile the rest have only one.
The average num-ber of references per test sentence varies across testsets.
For this reason, MT scores are not comparableacross test sets.
Table 1 shows the size and the av-erage number of references per sentence of the testsets.Two hand-aligned corpora were used to train theITG aligner: LDC2009E82 (Arabic-English) andLDC2009E83 (Chinese-English).
We re-tokenizedthe corpora using our tokenizers and projected theLDC alignments to our tokenization heuristically.The projection was not perfect and sometimes cre-ated very coarse-grained alignments.
We used a setof filters to remove such problematic data.
We endedup with 3,667 Arabic-English and 879 Chinese-English hand-aligned sentence pairs with sufficientquality for training automatic aligners.669language and genre Tune SysCombTune TestArabic newswire 2963 (2.9) 3223 (2.7) 2242 (2.7)Arabic web 4597 (1.5) 4526 (1.4) 2703 (2.7)Chinese newswire 3085 (2.6) 3001 (2.7) 2055 (1.4)Chinese web 4221 (1.3) 4285 (1.3) 3092 (1.2)Table 1: Numbers of sentences and average number of references (in parentheses) of test sets5 ResultsThree baseline systems were trained using the threedifferent aligners.
Case insensitive BLEU and TERscores for Arabic newswire, Arabic weblog, Chi-nese newswire, and Chinese weblog are shown inTables 2, 3, 4, and 5, respectively2.
The BLEUscores on the Test set are fairly similar but theordering between different alignment algorithms ismixed between different languages and genres.
Tocompare the two alignment combination strategies,we trained a system using the union of the rules ex-tracted from the alternative alignments (union inthe tables) and a combination of the three baselinesystem outputs (3 syscomb in the tables).
Thesystem with the unioned grammar was also addedas an additional system in the combination markedby 4 syscomb.As seen in the tables, unioned grammar and sys-tem combination improve MT on both languages(Arabic and Chinese) and both genres (newswireand weblog).
While there are improvements onboth SysCombTune and Test, the results onSysCombTune are not totally fair since it was usedfor tuning system combination weights and as val-idation for optimizing weights of the MT systems.Therefore our discussion will focus on results onTest.
(We did not show scores on Tune becausesystems were directly tuned on it.)
Statistical sig-nificance is determined at 95% confidence level us-ing the bootstrap method described in Koehn (2004),and is only applied on results obtained on the blindTest set.For unioned grammar, the overall improvementin BLEU is modest, ranging from 0.1 to 0.6 point2Dagger (?)
indicates statistically better results than the bestindividual alignment system.
Double dagger (?)
indicates sta-tistically better results than both best individual alignment andunioned grammar.
Bold indicates best Test set performanceamong individual alignment systems.compared with the best baseline system, with littlechange in TER score.
The improvements in BLEUscore are statistically significant for Arabic (bothgenres), but not for Chinese.
The improvements inTER are not significant for either language.System combination produces bigger improve-ments in performance.
Compared with the best base-line system, the improvement in BLEU ranges from0.8 to 1.6 point.
There are also noticeable improve-ments in TER, around 1.0 point.
The TER improve-ments are mostly explained by the hypothesis align-ment algorithm which is closely related to TER scor-ing (Rosti et al, 2009).
The results are interestingbecause all three baseline systems (GIZA++, HMMand ITG) are identical except for the word align-ments used in rule extraction.
The results confirmthat the aligners are indeed complementary, as weconjectured earlier.
Also, the four-system combi-nation yields consistent gains over the three-systemcombination, suggesting that the system using theunioned grammar is somewhat complementary tothe three baseline systems.
The statistical test in-dicates that both the three and four system combi-nations are significantly better than the single bestalignment system for all languages and genres inBLEU and TER.
In most cases, they are also sig-nificantly better than unioned grammar.Somewhat surprisingly, the GIZA++ trained sys-tem is slightly better than the ITG trained system onall genres but Chinese weblog.
However, we shouldpoint out that such a comparison is not entirely fair.First, we only ran ITG on short sentences.
(For longsentences, we had to settle for HMM alignments forcomputing reasons.)
Second, the hand-aligned dataused for ITG training are not very clean, as we saidbefore.
The ITG results could be improved if theseproblems were not present.670SysCombTune TestSystem BLEU TER BLEU TERGIZA++ 51.31 38.01 50.96 38.38HMM 50.87 38.49 50.84 38.87ITG 51.04 38.44 50.69 38.94union 51.55 37.93 51.53?
38.323 syscomb 52.66 37.20 52.43?
37.69?4 syscomb 52.80 37.05 52.55?
37.46?Table 2: MT results on Arabic newswire (see footnote 2).SysCombTune TestSystem BLEU TER BLEU TERGIZA++ 27.49 55.00 38.00 49.55HMM 27.42 55.53 37.81 50.12ITG 27.19 55.32 37.77 49.94union 27.66 54.82 38.43?
49.433 syscomb 27.65 53.89 38.70?
48.72?4 syscomb 27.83 53.68 38.82?
48.53?Table 3: MT results on Arabic weblog (see footnote 2).SysCombTune TestSystem BLEU TER BLEU TERGIZA++ 36.42 54.21 26.77 57.67HMM 36.12 54.50 26.17 58.22ITG 36.23 54.11 26.53 57.40union 36.57 54.07 26.83 57.373 syscomb 37.60 53.19 27.46?
56.88?4 syscomb 37.77 53.11 27.57?
56.57?Table 4: MT results on Chinese newswire (see footnote2).SysCombTune TestSystem BLEU TER BLEU TERGIZA++ 18.71 64.10 16.94 63.46HMM 18.35 64.66 16.66 64.02ITG 18.76 63.67 16.97 63.29union 18.97 63.86 17.22 63.203 syscomb 19.66 63.40 17.98?
62.47?4 syscomb 19.80 63.32 18.05?
62.36?Table 5: MT results on Chinese weblog (see footnote 2).5.1 DiscussionInter-aligner agreements provide additional evi-dence about the differences between the aligners.Suppose on a common data set, the sets of align-ment links produced by two aligners are A andB, we compute their agreement as (|A?B|/|A| +|A?B|/|B|)/2.
(This is the average of recall andprecision of one set by treating the other set as refer-ence.)
The agreement between GIZA++ and ITGis around 78% on a subset of the Arabic-Englishparallel data.
The agreements between GIZA++and HMM, and between HMM and ITG are slightlyhigher, around 83%.
Since ITG could not align longsentences, we only used short sentences (at most 60words in length) in our calculation.Due to the large differences between the align-ers, significantly more rules were extracted withthe unioned grammar method in our experiments.On average, the size of the grammar (number ofrules) was increased by about 80% compared withthe baseline systems.
The larger grammar resultsin more combinations of partial theories in decod-ing.
However, for computing reasons, we kept thebeam size of the decoder constant despite the in-crease in grammar size, potentially pruning out goodtheories.
Performance could be improved further iflarger beam sizes were used.
We will leave this tofuture work.6 Related WorkAyan and Dorr (2006) described a method to min-imize alignment errors by combining alternativealignments into a single alignment for each sentencepair.
Deng and Zhou (2009) used the number of ex-tractable translation pairs as the objective functionfor alignment combination.
Och and Ney (2003) andKoehn et al (2003) used heuristics to merge the bidi-rectional GIZA++ alignments into a single align-ment.
Despite differences in algorithms and objec-tive functions in these studies, they all attempted toproduce a single final alignment for each sentencepair.
In comparison, all alternative alignments aredirectly used by the translation system in this work.The unioned grammar method in this work isvery similar to Gime?nez and Ma`rquez (2005), whichcombined phrase pairs extracted from differentalignments into a single phrase table.
The difference671from that work is that our focus is to leverage com-plementary alignment algorithms, while theirs wasto leverage alignments of different lexical units pro-duced by the same aligner.Some studies leveraged other types of differencesbetween systems to improve MT.
For example, deGispert et al (2009) combined systems trained withdifferent tokenizations.The theory behind the GIZA++ aligner was due toBrown et al (1993).
The theory of Inversion Trans-duction Grammars (ITG) was due to Wu (1997).The ITG aligner (Haghighi et al, 2009) used in thiswork extended the original ITG to handle blocks ofwords in addition to single words.
The use of HMMfor word alignment can be traced as far back as toVogel et al (1996).
The HMM aligner used in thiswork was due to Liang et al (2006).
It refined theoriginal HMM alignment algorithm by jointly train-ing two HMMs, one in each direction.
Furthermore,it used a small amount of supervised data to tweaksome high level parameters, although it did not di-rectly use the supervised data in training.7 ConclusionsWe explored two methods to exploit complementaryalignment algorithms.
One is to extract translationrules from all alternative alignments.
The other is tocombine outputs of different MT systems trained us-ing different aligners.
Experiments on two languagepairs and two genres show consistent improvementsover the baseline systems.AcknowledgmentsThis work was supported by DARPA/IPTO ContractNo.
HR0011-06-C-0022 under the GALE program3(Approved for Public Release, Distribution Unlim-ited).
The authors are grateful to John DeNero andJohn Blitzer for their help with the Berkeley HMMand ITG aligners.3The views, opinions, and/or findings contained in this ar-ticle/presentation are those of the author/presenter and shouldnot be interpreted as representing the official views or policies,either expressed or implied, of the Defense Advanced ResearchProjects Agency or the Department of Defense.ReferencesNecip Fazil Ayan and Bonnie J. Dorr.
2006.
A maximumentropy approach to combining word alignments.
InProceedings of the Human Language Technology Con-ference of the North American Chapter of the ACL,pages 96?103.Peter F. Brown, Stephen A. Della Pietra, Vincent J. DellaPietra, and Robert L. Mercer.
1993.
The mathematicsof statistical machine translation: Parameter estima-tion.
Computational Linguistics, 19(2):263?311.David Chiang, Kevin Knight, and Wei Wang.
2009.11,001 new features for statistical machine transla-tion.
In Proceedings of Human Language Technolo-gies: The 2009 Annual Conference of the North Amer-ican Chapter of the ACL, pages 218?226.Adria` de Gispert, Sami Virpioja, Mikko Kurimo, andWilliam Byrne.
2009.
Minimum Bayes risk combi-nation of translation hypotheses from alternative mor-phological decompositions.
In Proceedings of HumanLanguage Technologies: The 2009 Annual Conferenceof the North American Chapter of the ACL, pages 73?76.Steve DeNeefe, Kevin Knight, Wei Wang, and DanielMarcu.
2007.
What can syntax-based MT learn fromphrase-based MT?
In Proceedings of the 2007 JointConference on Empirical Methods in Natural Lan-guage Processing and Computational Natural Lan-guage Learning, pages 755?763.Yonggang Deng and Bowen Zhou.
2009.
Optimizingword alignment combination for phrase table training.In Proceedings of the Joint Conference of the 47th An-nual Meeting of the ACL and the 4th IJCNLP of theAFNLP, pages 229?232.Jacob Devlin.
2009.
Lexical features for statistical ma-chine translation.
Master?s thesis, University of Mary-land.Jesu?s Gime?nez and Llu?
?s Ma`rquez.
2005.
Combininglinguistic data views for phrase-based SMT.
In Pro-ceedings of the ACL Workshop on Building and UsingParallel Texts, pages 145?148.Aria Haghighi, John Blitzer, John DeNero, and DanKlein.
2009.
Better word alignments with supervisedITG models.
In Proceedings of the Joint Conferenceof the 47th Annual Meeting of the ACL and the 4thIJCNLP of the AFNLP, pages 923?931.Philipp Koehn, Franz J. Och, and Daniel Marcu.
2003.Statistical phrase-based translation.
In Proceedings ofthe 2003 Human Language Technology Conference ofthe North American Chapter of the ACL, pages 48?54.Philipp Koehn.
2004.
Statistical significance tests formachine translation evaluation.
In Proceedings of the2004 Conference on Empirical Methods in NaturalLanguage Processing, pages 388?395.672Percy Liang, Ben Taskar, and Dan Klein.
2006.
Align-ment by agreement.
In Proceedings of the HumanLanguage Technology Conference of the North Ameri-can Chapter of the ACL, pages 104?111.Franz J. Och and Hermann Ney.
2003.
A systematiccomparison of various statistical alignment models.Computational Linguistics, 29(1):19?51.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a method for automatic eval-uation of machine translation.
In Proceedings of the40th Annual Meeting of the Association for Computa-tional Linguistics, pages 311?318.Antti-Veikko I. Rosti, Bing Xiang, Spyros Matsoukas,Richard Schwartz, Necip Fazil Ayan, and Bonnie J.Dorr.
2007.
Combining outputs from multiple ma-chine translation systems.
In Proceedings of HumanLanguage Technologies 2007: The Conference of theNorth American Chapter of the ACL, pages 228?235.Antti-Veikko I. Rosti, Bing Zhang, Spyros Matsoukas,and Richard Schwartz.
2009.
Incremental hypothe-sis alignment with flexible matching for building con-fusion networks: BBN system description for WMT09system combination task.
In Proceedings of the FourthWorkshop on Statistical Machine Translation, pages61?65.Libin Shen, Jinxi Xu, and Ralph Weischedel.
2008.
Anew string-to-dependency machine translation algo-rithm with a target dependency language model.
InProceedings of ACL-08: HLT, pages 577?585.Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-nea Micciula, and John Makhoul.
2006.
A study oftranslation edit rate with targeted human annotation.In Proceedings of the 7th Conference of the Associa-tion for Machine Translation in the Americas, pages223?231.Stephan Vogel, Hermann Ney, and Christoph Tillman.1996.
HMM-based word alignment in statistical trans-lation.
In The 16th International Conference on Com-putational Linguistics, pages 836?841.Dekai Wu.
1997.
Stochastic inversion transductiongrammars and bilingual parsing of parallel corpora.Computational Linguistics, 23(3).673
