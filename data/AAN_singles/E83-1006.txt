AN EXPERT SYSTEM FOR THE PRODUCTION OF PHONEME STRINGSFROM UNMARKED ENGLISH TEXT USING MACHINE-INDUCED RULESAlberto Maria SegreUniversity of Illlnolsat Urbana-ChampaignCoordinated ScienceLaboratory1101W.
SpringfieldUrbana, IL 61801 U.S.A.Bruce Arne SherwoodUniversity of Illlnolsat  Urbana-ChampalgnComputer-based EducationResearch Laboratory103 S. HathewsUrbana, IL 61801 U.S.A.Wayne B. DickersonUniversity of Illinoisat Urbana-ChampalgnEnglish as a Second LanguageForeign Language Building707 S. MathewsUrbana, IL 61801 U.S.A.ABSTRACTThe speech synthesis group at the Computer-Based Education Research Laboratory (CERL) of theUniversity of Illinois at Urbana-Champalgn isdeveloping a diphone speech synthesis system basedon pltch-adaptive short-tlme Fourier transforms.This system accepts the phonemic specification ofan utterance along with pitch, time, and amplitudewarping functions in order to produce high qualityspeech output from stored dlphone templates.This paper describes the operation of aprogram which operates as a front end for thedlphone speech synthesis system.
The UTTER (for"Unmarked Text Transcription by Expert Rule")system maps English text onto a phoneme string,which is then used as an input to the dlphonespeech synthesis system.
The program is a two-tiered Expert System which operates first on theword level and then on the (vowel or consonant)cluster level.
The system's knowledge aboutpronunciation is organized in two decision treesautomatically generated by an induction algorithmon a dynamically specified "training set" ofexamples.in that they are often unable to cope with aletter pattern that maps onto more than onephoneme pattern.
Extreme cases are those wordswhich, although differing in pronunciation, shareorthographic representations (an analogous problemexists in speech recognition, where words whichshare phonemic representations differ inorthographic representation, and thereforepossibly in semantic interpretation).
A notableexception is the MIT speech synthesis systemfAllen81\] which is llngulstlcally-based, but notsolely phoneme-based.A desirable feature in any rule-based systemis the ability to automatically acquire or modifyits own rules.
Previous work \[Oakey81\] appliesthis automatic inference process to the text-to-phoneme transcription problem.
Unfortunately,Onkey's system is strlctly letter-based andsuffers from the same deficiencies as othernonilnguistlcally-based systems.The UTTER system is an attempt to provide allngulstlcally-based transcription system whichhas the ability to automatically acquire its ownrule base.I INTRODUCTIONMost speech synthesis systems in use todayrequire that eventual utterances be specified interms of phoneme strings.
The automatictransformation of normal English texts intophoneme strings is therefore a useful front-endprocess for any speech synthesis unit whichrequires such phonemic utterance specification.Unfortunately, this transcription process isnot nearly as straightforward as one mightinitially imagine.
It is common knowledge tononnatlve speakers that English poses someparticularly treacherous pronunciation problems.This is due, in part, to the mixed heritage of thelanguage, which shares several orthographicbloodlines.Past attempts to create orthographically-based computer algorithms have not met with greatsuccess.
Algorithms such as the Naval ResearchLaboratory pronunciation algorithm \[Elovitz76\] areletter-based instead of llnguistlcally-based.
Forthis reason, such algorithms are excessively rigidII METHODThe system's basic goal is the transcriptionof input text into phoneme strings.
The methodused to accomplish this goal is based on a methodtaught to foreign students which enables them toproperly pronounce unknown English words\[DickersonF1, DickersonF2\].
The method isbasically a two stage process.
The first stageconsists in assigning major stress to one of theword's syllables.
The second stage maps a vowel orconsonant group with a known stress value uniquelyonto its corresponding phoneme string.
It is thestress-asslgnment process which distinguishes thispronunciation method from applying purely letter-based text-to-speech rules, as in, for example,the Naval Research Laboratory algorithm\[Elovltz76\].In order to accomplish the transcription oftext into phoneme strings, the system uses a setof two transcription rules which are machinegenerated over a set of sample transcriptions.
Asthe system transcribes new input texts, anyimproper transcriptions (i.e., mispronunciations)35would be flagged by the user and added to thesample set for future generations of transcriptionrules.The first stage operates on  "words "1 whilethe second stage operates on "clusters" of vowelsor consonants.
2 Each word is examinedindividually, and "major stress "3 is assigned toone of the "syllables".
~ Major stress is assignedon the basis of certain "features" or"attrlbutes "5 extracted from the word (an exampleof  a word-level attribute is "sufflx-type").
Theassignment of major stress is always made uniquelyfor a given word.
The assignment process consistsof invoking and applying the "stress-rule".The "stress-rule" is one of two machine-generated transcription rules, the other being the"cluster-rule".
A transcription rule consists of adecision tree which, when invoked, is traversed onthe basis of the feature values of the word orcluster under consideration.
The transcriptionrule "test "6 is evaluated and the proper branch isthen selected on the basis of values of the wordfeatures.
The process is repeated until a leafnode of the tree is reached.
The leaf nodecontains the value returned for that invocation ofthis transcription rule, which uniquely determineswhich syllable is to receive the major stress.I A "word" is delimited by conventional wordseparators such as common punctuation or blankspaces in the input stream.2 A "cluster" consists of contiguous vowels orcontiguous consonants.
The following classificato-ry scheme is used to determine if a letter is avowel (-v-) or a consonant (-c-):"a m, "e", "i", and "o" are -v-,"u" is -v- unless it follows a "g" or "q","i" is a special consonant represented by -i-,mr" is a special consonant represented by -r-,"y" is -v- if it follows -v-, -c-, -i- or -r-,"w" is -v- if it follows -v-.3 "Major stress" corresponds to that syllablewhich receives the most emphasis in spoken En-glish.4A "syllable" will be taken to be a set of twoadjacent clusters, with the first cluster of thevowel type and the second cluster of the consonanttype.
For syllable division purposes, if the wordbegins with a consonant the first syllable in thatword will consist solely of a consonant cluster.Similarly, if the word ends in a vowel then thefinal syllable will consist of a vowel clusteralone.
In all other cases, a syllable will alwaysconsist of a vowel cluster followed by a consonantcluster.5 The terms "feature" and "attribute" will beused interchangeably to refer to some identifiableelement in a word or cluster.
For more informationregarding word or cluster attributes see the fol-lowing section.6 A transcription rule "test" refers to thebranching criteria at the current node.After word stress is assigned, each clusterwithin the word is considered sequentially.
Thecluster features are extracted, and the cluster-rule is invoked and applied to obtain the phonemictranscription for that particular cluster.
Notethat one of the cluster features is the stress ofthe particular syllable to which the clusterbelongs.
In other words, it is necessary todetermine major stress before it is possible totranscribe the individual clusters of which theword is comprised.
The value returned frominvoking the cluster rule is the phoneme stringcorresponding to the current cluster.UTTER uses the World English Spelling\[Sherwood78\] phonetic alphabet to specify theforty-odd sounds in the English language.
Themajor advantage of WES over other phoneticrepresentations (such as the InternationalPhonetic Alphabet, normally referred to as IPA) isthat WES does not require special characters torepresent phonemes.
In UTTER's version of WES,WES uses no more than two Roman alphabetcharacters to specify a phoneme.
7The choice of WES over other phonemerepresentation systems was also motivated by thefact that Gllnski's system \[Glinski81\], with whichUTTER was designed to interface, uses WES.
Thechoice was strictly implementatlonal, and by nomeans excludes the use of a differentrepresentation system for future versions ofUTTER.III SYSTEM ORGANIZATIONThe current implementation of UTTER operatesin one of three modes, each of which correspondsto one of the three tasks required of the system:(I) execution mode: the transcription of inputtext usir~ existing transcription rules.
(2) trainin~ mode: flagglr~ incorrecttranscriptions for inclusion in the nextgeneration of transcription rules.
(3) inference mode: automatic induction of a newset of transcription rules to cover the setof training examples (including any additionsmade i n / 2 .
~ ~ .What follows is a more detailed descriptionof each of these three modes of operation.~.
~ H o d eExecution mode is UTTER's normal mode ofoperat ion .
Whi le  in  execut ion  mode, UTTER acceptsEng l i sh  input  one sentence  a t  a t ime and producesthe corresponding pronunciation as a list ofphonemes.What follows is a detailed description ofeach step taken by UTTER when operating inexecution mode.7 For a complete listing of the World EnglishSpelling phonetic alphabet see Appendix A.36(I) The input text is scanned for word andcluster boundaries, and lists of pointers toboundary locations in the string areconstructed.
The parser also counts thenumber of syllables in each word, andconstructs a new representation of theoriginal string which consists only of theletters 'v', 'c', 'i', and 'r'.This new representation, which will bereferred to as the "vowel-consonant mapping,"or simply "v-c map," is the same length asthe original input.
Therefore, all pointersto the original string (such as those showingword and cluster boundaries) are alsoapplicable to the v-c map.
The v-c map willbe used in the extraction of clusterfeatures.
(2) Each word is now processed individually.
Thefirst step is to determine whether the nextword belongs to the group of "functionwords".
8 If the search through the functionword list is successful, it will return thecross-listed pronunciation for that word.Table look-up provides time-efflclenttranscription for this small class of wordswhich have a very high frequency ofoccurrence in the English language, as wellas highly irregular pronunciations.
If theword is a function word, its pronunciation isadded to the output and processing continueswith the next word.Positioning of function words provides avaluable clue to the syntax of the input.Syntactic information is essential indlsamblguating certain words.
Although thecurrent version of UTTER supports part-of-speech distinctions, the current version ofthe parser fails to supply this information.A new version of UTTER should include abetter parser which is capable of makingthese sorts of part-of-speech dlstlnctlons.
9Such a parser need not be very accurate interms of the proper assignment of words topart-of-speech classes.
However, it must becapable of separating identically spelledwords into different classes on the basis offunction.
These words often differ inpronunciation, such as "present" (N) and"present" (V) or "moderate" (N) and"moderate" (V).
In other words, the parserneed not classify these two words as noun andverb, as long as it makes some distinctionbetween them.
(3) Each word is now checked against another llstof words (with their associatedpronunciations) called the "permanentexception llst," or PEL.
The PEL provides the8 For a complete listing of function words seeAppendix B.9 It should be possible to model a new parseron an existing parser which already makes thissort of part-of-speech distinction.
For example,the STYLE program developed at Bell Laboratoriesprovides a tool for analyzing documents \[CherryBO\]and yleids more part-of-speech classes than wouldbe required for UTTER's purposes.user with the opportunity to specify commondomaln-speclflc words whose transcriptionwould best be handled by table-look-up,without reconstructing the pronunciation ofthe word each time it is encountered.The time required to search this llst isrelatively small (provided the size of thellst itself is not too large) compared to thetime necessary for UTTER to transcribe theword normally.If the word is on the PEL, its pronunciationis returned by the search routine and addedto the output.
Processing continues with thenext word.
(4) At this point the set of word-level featuresis extracted.
These features are used by thestress-rule for the assignment of majorstress to a particular syllable in the word.A major stress assignment is made for eachword.The set of word level attributes includes:part-of-speech (assigned by the parser);key-syllable (in terms of the v-c maprepresentation);left-syllable (in terms of the v-c maprepresentation);suffix type (neutral, weak or strong);preflx/left-syllable overlap(true or false).These features are both necessary andsufficient to assign major stress to anygiven word \[Dickerson81\].Although a detailed account of the selectionof these features is beyond the scope of thispaper, an example of an input word and theappropriate attribute values should give thereader a better grasp of the word-levelfeature concept.Consider the input word "preeminent".The weak suffix "ent" is stripped.Key-syllable (final syllable excludingsuffixes) is "in".Left-syllable (left of key-syllable)is "eem".Prefix ("pre") overlaps left-syllable("eem") since they share an "e".Proper stress placement for the word"preeminent" is on the left-syllable.
(5) The word and its attributes are checkedagainst a list of exceptions to the currentstress rule (called the "stress exceptionlist" or SEL).
This llst is normally empty,in which case checklng does not take place.Additions to the list can only be made intraining mode (see below).If the word and its features are indexed onthe SEL, the SEL search returns the properstress in terms of the number 0 or -1.
Ifstress is returned as 0, major stress fallson the key-syllable.
If stress is returnedas -I, major stress falls on the left-syllable.37(6) If the word does not appear on the SEL, thenthe current stress rule is applied.
Thestress rule is essentially a decision treewhich is traversed on the basis of the valuesof the word's word level attributes.Application of the stress rule also returnseither 0 or -I.
(7) Now processingcontlnues for the current wordon a cluster-by-cluster basis.
The cluster-level attributes are extracted.
They include:cluster type (vowel or consonant);cluster (orthography);left neighbor cluster map (from v-c map);right neighbor cluster (orthography);right neighbor cluster map(from v-c map);cluster position (prefix, suffix, etc.
);stress (distance in syllables from majorstress syllable).These features are necessary and sufficientto classify a cluster \[Dickerson82\].As before, an example of cluster levelattributes is appropriate.
Consider thecluster "ee" (from our sample word"preeminent").The cluster type is "vowel".The cluster orthography is "ee".The left neighbor cluster map is "cr"(v-c map of "pr").The right neighbor cluster is "m".The right neighbor cluster map is "c"(v-c map of "m").The cluster position is"word-prefix boundary".The cluster is inside the syllablewith major stress (see above).
(8) The cluster and its associated attributes arechecked against a list of exceptions to thecluster rule (called the "cluster exceptionlist" or CEL).
This list is normally empty,and addltlons can only be made in trainingmode (see below).
If the search through theCEL is successful, it will return the properpronunciation for the particular cluster.
Thepronunciation (in terms of a WES phonemestring) is added to the output, andprocessing continues with the next cluster inthe current word, or with the next word.
(9) The cluster transcription rule is applied tothe current cluster.
As in the case of thestress rule, the cluster rule is a decisiontree which is traversed on the basis of thevalues of the cluster level attributes.
Thecluster rule returns the proper pronunciationfor this particular cluster and adds it (interms of a WES phoneme string) to the output.Processing continues with the next cluster inthe current word, or with t~ next word inthe input.~.
Traininm ModeWhen UTTER is operating in training mode, thesystem allows the user to correct errors intranscription interactively by specifying theproper pronunciation for the incorrectlytranscribed word.The training mode operates in the same manneras the execution mode with the exception that,whenever either rule is applied (see steps 6 and 9above), the user is prompted for a judgement onthe accuracy of the rule.
The user functions asthe "oracle" who has the final word on what is tobe considered proper pronunciation.Let us assume, for example, that the stressrule applied to a given word yields the result"stress left-syllable" (in other words, the ruleapplication routine returns a -I) and the properresult should be "stress key-syllable" (or aresult of 0).
If the system were operating inexecution mode, processing would continue and itis unlikely that the word would be properlytranscribed.
The user could switch to trainingmode and repeat the transcription of the problemword in the same context.In training mode, the user has theopportunity to inspect the results from every ruleapplication, allowing the user to flag incorrectresults.
When an incorrect rule result isdetected, the proper result (alone with thecurrent features) will be saved on the appropriateexception list.
In terms of the previous example,the current word and word-level features would besaved on the SEL.If the given word should arise again in thesame context, the SEL would contain the exceptionto the transcription rule, prohibiting theapplication of the stress rule.
The informationfrom the SEL (and from the CEL at the cluster-level) will be used to infer the next generationof transcription rules.It is important to note that UTTER makes agiven mistake only once.
If the transcriptionerror is spotted and added to the SEL (or CEL,depending on which transcription rule is at fault)it will not be repeated as long as the exceptioninformation exists.
The SEL (and CEL) can only becleared by the rule inference process (see below)which guarantees that the new generation of ruleswill cover any example that is to be removed fromthe appropriate exception llst.~.
Inference ModeInference mode allows for the generation ofnew transcription rules.
The inference routine isbased on techniques deve loped in artificialintelligence for the purpose of generatingdecision trees based on sets of examples and theirrespective classifications \[Qulnlan79\].
The basicidea behind such an inference scheme is that someset of examples (the "training set") and theirproper classifications are available.
Inaddition, a finite set of features which aresufficient to classify these examples, as well assome method for extracting these features, arealso available.
For example, consider the trainingset \[dog, cat, eagle, whale, trout\] where each38element is classified as one of \[mammal, fish,bird\].
In addition, consider the feature set\[has-fur, llves-ln-water, can-fly, is-warm-blooded\] and assume there exists a method forextracting values for each feature of every entryin the training set (in this example, values wouldbe "true" or "false" but this need not always beso).
From this information, the inference routinewould extract a decision tree whose branch nodeswould be tests of the form "if has-fur is truethen branch-left else branch-rlght" and whoseterminal nodes would be of the form "the animal inquestion is a mammal."
The premls is that such adecision tree would be capable of correctlyclassifying not only the examples contained in thetraining set but any other example whose featurevalues are known or extractable.
I0What follows is a step-by-step description ofthe inference algorithm as applied to thegeneration of the stress transcription rule.Generation of the cluster transcription rule issimilar, except that the cluster transcriptionrule returns a phoneme string rather than anumber.
For a more complete discussion of theinference algorithm, which would be beyond thescope of this paper, see \[Qulnlan79\].
(I) The current stress exception llst is combinedwith the training set used to generate theprevious stress transcription rule.
The oldtraining set is referred to as the "stressclassified llst," or SCL, and is storedfollowing rule generatlon.
11 Since the SCL isnot used again until a new rule is generated,it can be stored on an inexpensive remotedevice, such as magnetic tape.
The SCL (aswell as  the CCL) tends to become quitelarge.
1210 The inference algorithm need not be time- orspace-efflclent.
In fact, in the current implemen-tation of UTTER, it is neither.
This observationis not particularly alarming, since inference modeis not used very often, in comparison to executionor training modes (where space- and time-efficiency are particularly vital to fast texttranscription).
There are some inference systems\[Oakey81\] in which the inference routine is some-what streamlined and not nearly as inefficient asin the case of the current implementation.
Futureversions of UTTER might consider using a morestreamlined inference routine.
However, since theinference routine need not be invoked very often,its inefficiency does not have any effect on whatthe user percleves as transcription time.11 The equivalent llst in the cluster tran-scription rule case is called the "cluster classi-fied llst," or CCL.12 It should be possible to use an existingcomputer encoded pronunciation dictionary (or asubset thereof) to provide the initial SCL andCCL.
The current version of UTTER uses null listsas the initial SCL and CCL, and therefore forcesthe user to build these lists via the SEL and CEL.This implies a rather time consuming process ofrunning text through UTTER in training mode.
An(2) Features are extracted for each of theentries in the training set.
Features whichcannot be extracted in isolation, such asthe part-of-speech of a given word, arestored along with the entry and its result inthe SEL.
These unextractable attributes relyon the context the entry appeared in ratherthan on the entry itself and, therefore,cannot be reconstructed "a posterlori.
"The training set now consists of all of theentries from the SCL and the SEL, as well asall of the features for each entry.
At thispoint an initial "window" on the training setis chosen.
Since the inference algorithm'sexecution time increases comblnatorlally withthe size of the training set, it is wise tobegin the inference procedure with a subsetof the training set.
This is acceptable sincethere is often a relatively high rate ofredundancy in the training set.
The selectionof the window may be done arbitrarily (as inthe current version of UTTER), or one mighttry to select an initial window with thewidest possible set of feature values.
13(3) For each "attrlbute-value "14 in the currentwindow a "desirability index" is computed.This index dlrectiy reflects the ability of atest on the attrlbute-value to spilt thewindow into two relatively even subwindows.The current version of UTTER uses adesirability index which is defined as:samples with this attribute-valuedistinct final values in this subset.Different desirability indices might besubstituted to reflect the informationcontent of attrlbute-vaiues.When generating rules using UTTER the userhas the option of using either only a testfor equality in the decision tree, or alarger set of tests containing "equals,""not-equals," "less-than," and "greater-than".
If the larger set of possible testsis used, then the inference routine takesexisting pronunciation dictionary would allowtraining mode to be used rather infrequently, andthen only to make more subtle corrections to thetranscription rules.13 The selection of all those examples whichhave unique combinations of feature values shouldreduce the number of iterations required in theinference routine by eliminating redundant entriesin the training set.
This type of training setpruning should be done at the same time the train-ing set is scanned for clashes (discussed below).14 An "attribute-value" refers to the value ofa feature or attribute for the given example.
Forinstance, let the attribute in question be theword-level attribute "part-of-speech" and assumeit may take one of five possible values (noun,verb, adjective, adverb, or function word).
Ifthis attribute appears with only three values(such as noun, verb, adjective) in the currentwindow, then only those three attrlbute-valuesneed be considered.39much longer to execute.
However, the decisiontrees generated uslr~ the larger set areoften smaller and therefore usually faster totraverse.
(4) The attrlbute-value with the greatestdesirability index is chosen as the next testin the decision tree.
This test is added tothe decision tree.
In this manner, examplesoccurring most frequently will take the leastamount of time to classify and, thus, totranscribe.
15(5) The current window is split into twosubwlndows.
The spilt is based on whichexamples in the window contain theattrlbute-value selected as the new test, andwhich examples do not.
(6) For each subwlndow, it is determined whetherthere is only one result value in a givensubwlndow (i.e., is the result uniform on thewindow?)
or whether there is more than oneresult.
(7) If there is more than one result in asubwlndow, this procedure is appliedrecurslvely with the subwlndow as the newwindow.If there is only one result across a givensubwlndow, then generate a "terminal" or"leaf" node for the decision tree whichreturns this singular result as the value ofthe tree at that terminal.
Terminal nodesare thus easily recognized since they haveonly one distinct result.
(8) When the original window is completelyclassified the resulting decision tree is thenew rule which is gUaranteed to cover theoriginal window.The newly generated  ru le  i s  app l ied  to  theremaining examples in the training set.
Fromthe examples it fails to correctly classify,a subset of the failures is chosen foraddition to the previous iteratlon's startingwindow.
The inference algorithm is reapplledusing this new starting window.
(9) When no failures exist, the most recentlygenerated decision tree completely covers thetraining set.
In this case, the training setthen becomes the SCL, and is stored in remotestorage until the next rule generatingsession.
The most recently generateddecision tree becomes the new rule and theSEL i s  zeroed.It is, of course, possible to terminate theinference algorithm before it completelyclassifies the training set.
In this case, UTTERsimply places all of the "failures" on the SEL andall of the properly classified examples from thetraining set on the SCL.
In this fashion it is15 In certain pathological cases, the tree gen-erated is not optimal in terms of traversai time.This problem has not yet occurred with real tran-scription data, and, in any case, would stillyield an acceptable, though less than optimal, de-cision tree.possible to reduce the size of the SEL withoutexhaustively classifying the entire training set.The procedure for creating a cluster rule isidentical.In the course of rule generation, aninconsistency called a "clash" may arise when theattributes are insufficient to classify two ormore examples.
A clash manifests itself as awindow with uniform values for all of theattributes, but with more than one result presentin the window.
The current version of UTTER abortsthe rule generation process when a clash occurs.Future versions of UTTER should screen the entiretraining set for clashes before starting the rulegeneration process, as well as allow the user toremove or correct the entries responsible for theclash.Clashes are usually the result of an errormade by the user in training mode.
If a clashshould arise which is not the result of a usererror, it would indicate that the attribute set isinsufficient to characterize the set oftranscriptions.
Additional attributes would haveto be added to UTTER in order to handle thisevent .For example, the word "read" is pronounceddifferently in present tense than it is in pasttense.
Since UTTER cannot extract contextual orsemantic informatlon, the distinction cannot bemade.
Therefore, two entries in the training setmight be present with the came attributes, butdifferent transcriptions.
This situation resultsin a clash which cannot be resolved without theaddition of another attribute, such as "tense.
"Fortunately, such cases account for a very smallportion of the English language.IV CONCLUSIONThis paper has described a newly developedsystem for the transcription of unmarked Er~lishtext into strings of phonemes for eventualComputer speech output.
The currentimplementation of the system has shown thistechnique to be feasible in terms of speed ofexecution and storage requirements, and desirablein terms of transcription accuracy.One of the unique features of UTTER is thepossibility of creating "mlnl-lmplementatlons" ofUTTER for use on evermore popular micro computers.These reduced versions of UTTER would only need toprovide execution mode.
The two transcriptionrules could be developed on a full-scale system,and provided to the user on floppy diskettes foruse on a micro computer.
The micro systems neednot provide a training mode, so no SEL or CEL needbe retained (or checked during the transcriptionprocess).
The PEL should still be provided so theuser could tailor the operation of the system tothe particular application by adding domain-specific words to this list.
The micro systemsneed not supply an inference mode which requiresthe most processor time and memory space of allthe modes of operation.
Updated rules (on floppydiskettes) could be provided perlodlcaily from the40main system -- thus keeping memory and storagerequirements well within the capabilities oftoday's micro computers.Accurate phoneme string transcription fromur~arked text will become increasingly vital asspeech synthesis technology continues to improve.Better speech synthesis tools will encourage thetrend from dlgltally-encoded recorded messages (aswell as other phrase- or word-based computerspeech methods) towards sub-word synthetic speechmethods (such as diphone or phoneme basedsynthesis).
The UTTER system is an example of anew approach to this old problem, embodyingfeatures from both the linguistic and artificialintelligence communities.REFERENCES\[Allen81\]Allen, Jonathen, "Linguistic Based AlgorithmsOffer Practical Text-to-Speech Systems,"SPeech Technology, pp12-16: Fall 1981.Phonetics," IEEE ~ on ACOustics.Soeech, and Signal Processing, Vol 24, p446-459: 1976.\[Gllnski81\]Glinskl, Stephen C., Diohone Speech SynthesisBased on A yitch Adaotlve Short Time FourierTransform, Ph.D. thesis, University ofIllinois at Urbana-Champaign: 1981.\[Kenyon53\]Kenyon, John S. and Knott, Thomas A., APronou~clng Dictionary of American English,G.
C. Miriam Company: 1953.\[Oakey81\]Oakey, S. and Cawthorn, R. C., "InductiveLearning of Pronunciation Rules by HypothesisTesting and Correction," Proceedings of theInternational Joint Conference on Artificial(IJCAI) lq81, pp109-114: 1981.\[CherrySO\]Cherry, L. L .
.and Vesterman, W., "WritingTools - The STYLE and DICTION Programs," UNIX~ ' ~  Manual, Seventh Ed., Vol.
2C,Computer Science Division, Department ofElectrical Engineering and Computer Science,University of California at Berkeley: 1980.\[Dickerson81\]Dickerson, Wayne B., "A PedagogicalInterpretation of Generative Phonology, II.The Main Word Stress Rules of English," TESLStudies~ Vol 4, pp27-93: 1981.\[Dickerson82\]Dickerson, Wayne B., "A PedagogicalInterpretation of Generative Phonology, III.Vowels in the Key and Left Syllables," TESLStudies, Vol.
5: 1982.\[Quinlan79\]Qulnlan, J. R., "Discovering Rules byInduction from Large Collections ofExamples," ExPert Systems in the Micro3g~, (Ed.
D. Michle), EdinburghUniversity Press, pp168-201: 1979.\[Segre83\]Segre, Alberto Maria, A System for theProduction of Phoneme Strings from U~arkedEnRlish Texts, M.S.
thesis, University ofIllinois at Urbana-Champalgn: 1983.\[Sherwood78\]Sherwood, Bruce Arne, "Fast Text-to-SpeechAlgorithms for Esperanto, Spanish, Italian,Russian, and English," ~nternational Journalof Man-Machine Studies I0, pp669-892: 1978.\[DickersonF1\]Dickerson, Wayne B., Learning EnglishPronunciation, Volume II I ,  "Word Stress andVowel Quality," Part I, forthcoming.\[DlckersonF2\]Dlckerson, Wayne B., Le~nir, z EmzlishPronunciation, Volume IV, "Word Stress andVowel Quallty," Part II, forthcoming.\[Elovitz76\]Elovltz, H. S., Johnson, R., McHugh, A. andShore, J. E., "Letter-to-Sound Rules forAutomatic Translation of English Text toAPPENDIX A - World EnglishSpellln~a fat le tie s setaa far J Jam sh shedae Mac k kit t tinau taut i let th thisb but m met tx thinch chum n net u upd dig ng sing ur fure set nk sink uu bookee see oe toe ux aboveer adder ol oll v vanf fat oo too w wing gum or for wh whenh hat ou out y yesi in p pet z zooix engage r run zh vision41aaboutacrossagalnstalthouEhamamor~anandanyanybodyanyoneanythingarearoundasatbebecausebeenbeforebehindbelowbeneathbesidebetweenbeyondbutbyAPPENDIX B -cancou ldd iddodoesdowndur ingeache i therevereveryeverybodyeveryoneeverythingforfromgoinghadhashaveheherhersherselfhimhimselfhishowhoweverFunctionIifinintoisititsitselflikemaymemightminemustmymyselfneithernevernonobodynoonenornotnothingoffononeontoorWordsoughtourou~sOurselvesovershallsheshouldsincesosomesomebodysomeonesomethirq~thanthatthetheirthemthemsei yesthentherforethesetheythisthosethoughthroughtounderunlessuntilupuswaswewerewhatwhateverwhenwheneverwherewhereverwhetherwhichwhilewhowhomwhosewhywillwithwithoutwouldyouyouryoursyourself42
