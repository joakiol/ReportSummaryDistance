Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 81?84,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsMachine Translation System Combinationusing ITG-based Alignments?Damianos Karakos, Jason Eisner, Sanjeev Khudanpur, Markus DreyerCenter for Language and Speech ProcessingJohns Hopkins University, Baltimore, MD 21218{damianos,eisner,khudanpur,dreyer}@jhu.eduAbstractGiven several systems?
automatic translationsof the same sentence, we show how to com-bine them into a confusion network, whosevarious paths represent composite translationsthat could be considered in a subsequentrescoring step.
We build our confusion net-works using the method of Rosti et al (2007),but, instead of forming alignments using thetercom script (Snover et al, 2006), we createalignments that minimize invWER (Leuschet al, 2003), a form of edit distance thatpermits properly nested block movements ofsubstrings.
Oracle experiments with Chinesenewswire and weblog translations show thatour confusion networks contain paths whichare significantly better (in terms of BLEU andTER) than those in tercom-based confusionnetworks.1 IntroductionLarge improvements in machine translation (MT)may result from combining different approachesto MT with mutually complementary strengths.System-level combination of translation outputs isa promising path towards such improvements.
Yetthere are some significant hurdles in this path.
Onemust somehow align the multiple outputs?to iden-tify where different hypotheses reinforce each otherand where they offer alternatives.
One must then?This work was partially supported by the DARPA GALEprogram (Contract No HR0011-06-2-0001).
Also, we wouldlike to thank the IBM Rosetta team for the availability of severalMT system outputs.use this alignment to hypothesize a set of new, com-posite translations, and select the best composite hy-pothesis from this set.
The alignment step is difficultbecause different MT approaches usually reorder thetranslated words differently.
Training the selectionstep is difficult because identifying the best hypothe-sis (relative to a known reference translation) meansscoring all the composite hypotheses, of which theremay be exponentially many.Most MT combination methods do create an ex-ponentially large hypothesis set, representing it as aconfusion network of strings in the target language(e.g., English).
(A confusion network is a latticewhere every node is on every path; i.e., each timestep presents an independent choice among severalphrases.
Note that our contributions in this papercould be applied to arbitrary lattice topologies.)
Forexample, Bangalore et al (2001) show how to builda confusion network following a multistring align-ment procedure of several MT outputs.
The proce-dure (used primarily in biology, (Thompson et al,1994)) yields monotone alignments that minimizethe number of insertions, deletions, and substitu-tions.
Unfortunately, monotone alignments are oftenpoor, since machine translations (particularly fromdifferent models) can vary significantly in their wordorder.
Thus, when Matusov et al (2006) use thisprocedure, they deterministically reorder each trans-lation prior to the monotone alignment.The procedure described by Rosti et al (2007)has been shown to yield significant improvements intranslation quality, and uses an estimate of Trans-lation Error Rate (TER) to guide the alignment.
(TER is defined as the minimum number of inser-81tions, deletions, substitutions and block shifts be-tween two strings.)
A remarkable feature of thatprocedure is that it performs the alignment of theoutput translations (i) without any knowledge of thetranslation model used to generate the translations,and (ii) without any knowledge of how the targetwords in each translation align back to the sourcewords.
In fact, it only requires a procedure for cre-ating pairwise alignments of translations that allowappropriate re-orderings.
For this, Rosti et al (2007)use the tercom script (Snover et al, 2006), whichuses a number of heuristics (as well as dynamic pro-gramming) for finding a sequence of edits (inser-tions, deletions, substitutions and block shifts) thatconvert an input string to another.
In this paper, weshow that one can build better confusion networks(in terms of the best translation possible from theconfusion network) when the pairwise alignmentsare computed not by tercom, which approximatelyminimizes TER, but instead by an exact minimiza-tion of invWER (Leusch et al, 2003), which is a re-stricted version of TER that permits only properlynested sets of block shifts, and can be computed inpolynomial time.The paper is organized as follows: a summary ofTER, tercom, and invWER, is presented in Section2.
The system combination procedure is summa-rized in Section 3, while experimental (oracle) re-sults are presented in Section 4.
Conclusions aregiven in Section 5.2 Comparing tercom and invWERThe tercom script was created mainly in order tomeasure translation quality based on TER.
As isproved by Shapira and Storer (2002), computationof TER is an NP-complete problem.
For this reason,tercom uses some heuristics in order to compute anapproximation to TER in polynomial time.
In therest of the paper, we will denote this approximationas tercomTER, to distinguish it from (the intractable)TER.
The block shifts which are allowed in tercomhave to adhere to the following constraints: (i) Ablock that has an exact match cannot be moved, and(ii) for a block to be moved, it should have an exactmatch in its new position.
However, this sometimesleads to counter-intuitive sequences of edits; for in-stance, for the sentence pair?thomas jefferson says eat your vegetables?
?eat your cereal thomas edison says?,tercom finds an edit sequence of cost 5, instead ofthe optimum 3.
Furthermore, the block selection isdone in a greedy manner, and the final outcome isdependent on the shift order, even when the aboveconstraints are imposed.An alternative to tercom, considered in this pa-per, is to use the Inversion Transduction Grammar(ITG) formalism (Wu, 1997) which allows one toview the problem of alignment as a problem of bilin-gual parsing.
Specifically, ITGs can be used to findthe optimal edit sequence under the restriction thatblock moves must be properly nested, like paren-theses.
That is, if an edit sequence swaps adjacentsubstrings A and B of the original string, then anyother block move that affects A (or B) must staycompletely within A (or B).
An edit sequence withthis restriction corresponds to a synchronous parsetree under a simple ITG that has one nonterminaland whose terminal symbols allow insertion, dele-tion, and substitution.The minimum-cost ITG tree can be found by dy-namic programming.
This leads to invWER (Leuschet al, 2003), which is defined as the minimum num-ber of edits (insertions, deletions, substitutions andblock shifts allowed by the ITG) needed to convertone string to another.
In this paper, the minimum-invWER alignments are used for generating confu-sion networks.
The alignments are found with a 11-rule Dyna program (Dyna is an environment that fa-cilitates the development of dynamic programs?see(Eisner et al, 2005) for more details).
This pro-gram was further sped up (by about a factor of 2)with an A?
search heuristic computed by additionalcode.
Specifically, our admissible outside heuris-tic for aligning two substrings estimated the cost ofaligning the words outside those substrings as if re-ordering those words were free.
This was compli-cated somewhat by type/token issues and by the factthat we were aligning (possibly weighted) lattices.Moreover, the same Dyna program was used for thecomputation of the minimum invWER path in theseconfusion networks (oracle path), without having toinvoke tercom numerous times to compute the bestsentence in an N -best list.The two competing alignment procedures were82Lang.
/ Genre tercomTER invWERArabic NW 15.1% 14.9%Arabic WB 26.0% 25.8%Chinese NW 26.1% 25.6%Chinese WB 30.9% 30.4%Table 1: Comparison of average per-document ter-comTER with invWER on the EVAL07 GALE Newswire(?NW?)
and Weblogs (?WB?)
data sets.used to estimate the TER between machine transla-tion system outputs and reference translations.
Ta-ble 1 shows the TER estimates using tercom andinvWER.
These were computed on the translationssubmitted by a system to NIST for the GALE eval-uation in June 2007.
The references used are thepost-edited translations for that system (i.e., theseare ?HTER?
approximations).
As can be seen fromthe table, in all language and genre conditions, in-vWER gives a better approximation to TER thantercomTER.
In fact, out of the roughly 2000 totalsegments in all languages/genres, tercomTER givesa lower number of edits in only 8 cases!
This is aclear indication that ITGs can explore the space ofstring permutations more effectively than tercom.3 The System Combination ApproachITG-based alignments and tercom-based alignmentswere also compared in oracle experiments involvingconfusion networks created through the algorithm ofRosti et al (2007).
The algorithm entails the follow-ing steps:?
Computation of all pairwise alignments be-tween system hypotheses (either using ITGs ortercom); for each pair, one of the hypothesesplays the role of the ?reference?.?
Selection of a system output as the ?skele-ton?
of the confusion network, whose wordsare used as anchors for aligning all other ma-chine translation outputs together.
Each arc hasa translation output word as its label, with thespecial token ?NULL?
used to denote an inser-tion/deletion between the skeleton and anothersystem output.?
Multiple consecutive words which are insertedrelative to the skeleton form a phrase that getsGenre CNs with tercom CNs with ITGNW 50.1% (27.7%) 48.8% (28.3%)WB 51.0% (25.5%) 50.5% (26.0%)Table 2: TercomTERs of invWER-oracles and (in paren-theses) oracle BLEU scores of confusion networks gen-erated with tercom and ITG alignments.
The best resultsper row are shown in bold.aligned with an epsilon arc of the confusionnetwork.?
Setting the weight of each arc equal to thenegative log (posterior) probability of its la-bel; this probability is proportional to the num-ber of systems which output the word that getsaligned in that location.
Note that the algo-rithm of Rosti et al (2007) used N -best lists inthe combination.
Instead, we used the single-best output of each system; this was done be-cause not all systems were providing N -bestlists, and an unbalanced inclusion would favorsome systems much more than others.
Further-more, for each genre, one of our MT systemswas significantly better than the others in termsof word order, and it was chosen as the skele-ton.4 Experimental ResultsTable 2 shows tercomTERs of invWER-oracles (ascomputed by the aforementioned Dyna program)and oracle BLEU scores of the confusion networks.The confusion networks were generated using 9MT systems applied to the Chinese GALE 2007Dev set, which consists of roughly 550 Newswiresegments, and 650 Weblog segments.
The confu-sion networks which were generated with the ITG-based alignments gave significantly better oracle ter-comTERs (significance tested with a Fisher signtest, p ?
0.02) and better oracle BLEU scores.The BLEU oracle sentences were found using thedynamic-programming algorithm given in Dreyer etal.
(2007) and measured using Philipp Koehn?s eval-uation script.
On the other hand, a comparison be-tween the 1-best paths did not reveal significant dif-ferences that would favor one approach or the other(either in terms of tercomTER or BLEU).83We also tried to understand which alignmentmethod gives higher probability to paths ?close?to the corresponding oracle.
To do that, we com-puted the probability that a random path from aconfusion network is within x edits from its ora-cle.
This computation was done efficiently usingfinite-state-machine operations, and did not involveany randomization.
Preliminary experiments withthe invWER-oracles show that the probability of allpaths which are within x = 3 edits from the oracleis roughly the same for ITG-based and tercom-basedconfusion networks.
We plan to report our findingsfor a whole range of x-values in future work.
Fi-nally, a runtime comparison of the two techniquesshows that ITGs are much more computationallyintensive: on average, ITG-based alignments took1.5 hours/sentence (owing to their O(n6) complex-ity), while tercom-based alignments only took 0.4sec/sentence.5 Concluding RemarksWe compared alignments obtained using the widelyused program tercom with alignments obtained withITGs and we established that the ITG alignments aresuperior in two ways.
Specifically: (a) we showedthat invWER (computed using the ITG alignments)gives a better approximation to TER between ma-chine translation outputs and human references thantercom; and (b) in an oracle system combination ex-periment, we found that confusion networks gen-erated with ITG alignments contain better oracles,both in terms of tercomTER and in terms of BLEU.Future work will include rescoring results with alanguage model, as well as exploration of heuristics(e.g., allowing only ?short?
block moves) that canreduce the ITG alignment complexity to O(n4).ReferencesS.
Bangalore, G. Bordel, and G. Riccardi.
2001.
Com-puting consensus translation from multiple machinetranslation systems.
In Proceedings of ASRU, pages351?354.M.
Dreyer, K. Hall, and S. Khudanpur.
2007.
Compar-ing reordering constraints for smt using efficient bleuoracle computation.
In Proceedings of SSST, NAACL-HLT 2007 / AMTA Workshop on Syntax and Structurein Statistical Translation, pages 103?110, Rochester,New York, April.
Association for Computational Lin-guistics.Jason Eisner, Eric Goldlust, and Noah A. Smith.
2005.Compiling comp ling: Weighted dynamic program-ming and the Dyna language.
In Proceedings of HLT-EMNLP, pages 281?290.
Association for Computa-tional Linguistics, October.G.
Leusch, N. Ueffing, and H. Ney.
2003.
A novelstring-to-string distance measure with applications tomachine translation evaluation.
In Proceedings of theMachine Translation Summit 2003, pages 240?247,September.E.
Matusov, N. Ueffing, and H. Ney.
2006.
Computingconsensus translation from multiple machine transla-tion systems using enhanced hypotheses alignment.
InProceedings of EACL, pages 33?40.A.-V.I.
Rosti, S. Matsoukas, and R. Schwartz.
2007.Improved word-level system combination for machinetranslation.
In Proceedings of the ACL, pages 312?319, June.D.
Shapira and J.
A. Storer.
2002.
Edit distance withmove operations.
In Proceedings of the 13th AnnualSymposium on Combinatorial Pattern Matching, vol-ume 2373/2002, pages 85?98, Fukuoka, Japan, July.M.
Snover, B. Dorr, R. Schwartz, L. Micciulla, andJ.
Makhoul.
2006.
A study of translation edit rate withtargeted human annotation.
In Proceedings of Associ-ation for Machine Translation in the Americas, Cam-bridge, MA, August.J.
D. Thompson, D. G. Higgins, and T. J. Gibson.1994.
Clustalw: Improving the sensitivity of progres-sive multiple sequence alignment through sequenceweighting, position-specific gap penalties and weightmatrix choice.
Nucleic Acids Research, 22(22):4673?4680.D.
Wu.
1997.
Stochastic inversion transduction gram-mars and bilingual parsing of parallel corpora.
Com-putational Linguistics, 23(3):377?403, September.84
