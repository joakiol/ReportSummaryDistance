Proceedings of the 5th Workshop on Important Unresolved Matters, pages 81?88,Prague, Czech Republic, June 2007. c?2007 Association for Computational LinguisticsAn Arabic Slot Grammar ParserMichael C. McCordIBM T. J. Watson Research CenterP.O.B.
704Hawthorne, NY 10532mcmccord@us.ibm.comVioletta Cavalli-SforzaLanguage Technologies InstituteCarnegie Mellon University5000 Forbes AvenuePittsburgh, PA 15213violetta@cs.cmu.eduAbstractWe describe a Slot Grammar (SG) parserfor Arabic, ASG, and new features of SGdesigned to accommodate Arabic as well asthe European languages for which SGshave been built.
We focus on the integra-tion of BAMA with ASG, and on a new,expressive SG grammar formalism, SGF,and illustrate how SGF is used to advan-tage in ASG.1 IntroductionIn this paper we describe an initial version of a SlotGrammar parser, ASG, for Arabic.
Slot Grammar(SG) (McCord, 1980.
1993) is dependency-oriented, and has the feature that deep structure(via logical predicate arguments) and surface struc-ture are both shown in parse trees.A new formalism SGF (Slot Grammar Formal-ism) for SG syntax rules has been developed(McCord, 2006), and the ASG syntax rules arewritten in SGF.
SGF is largely declarative, andcan be called ?object-oriented?
in a sense we willexplain.
The rules in SGF all have to do with slotfilling.ASG uses BAMA (Buckwalter, 2002), in a ver-sion from Qamus, as its morphological analyzer.All the internal processing of ASG is done with theBuckwalter Arabic transliteration ?
though ofcourse ASG can take real Arabic script (in UTF-8form) as input.
We use BAMA features in theprocessing (and parse trees), but augmented withother features more unique to ASG.
The PennArabic Treebank (ATB), which also uses BAMAfeatures, has served as a development guide in thework.
But SG is a rule-based system, and there isno automatic training from the ATB.Prior to this work, SGs had been written forEnglish (McCord), German (Claudia Gdaniec), andfor the Romance languages (Esm?ralda Manandise)Spanish, French, Italian and Portuguese.
For han-dling Arabic, there have been two main new adap-tations of SG.One adaptation is in the treatment of features inthe form that BAMA delivers.
This treatment in-cludes a feature lexicon in ASG, which can specifytwo kinds of relations among features, which wewill describe below.
We also take steps to handlethe large number of analyses returned by BAMA.Special treatment of features appears as well in theSGF syntax rules.
The other main adaptation is inthe treatment of clitics, where special things hap-pen in Arabic for proclitics.Although the basic ideas of SG have notchanged in treating Arabic, ASG has been servingas a test bed for the new syntax rule formalismSGF.Overall, the design of the SG system has be-come neater by including Arabic as well as theEuropean languages.
For instance, the new treat-ment of features generalizes the existing treatmentin the German SG.
And the new treatment of cli-tics will make the treatment of clitics for the Ro-mance languages neater.In Section 2, we discuss the ASG feature system.Section 3 briefly describes the ASG slot framelexicon.
Sections 4 and 5 deal with syntacticanalysis.
In Section 6, we discuss current perform-ance of ASG  (coverage and speed), and in Section7, related work.812 The Feature SystemFeatures for an SG parser for language X are speci-fied externally as character strings, listed by thegrammar writer in the feature lexicon Xfeas.lx (Ar-feas.lx for Arabic).
Internally, features are repre-sented in two ways, for efficient processing:  (1)The features themselves are ?atoms?, representedby integers.
(2) The set of features for a parsenode is represented by a bit string, where each fea-ture atom is assigned a bit position.
For ASG,these bit strings are currently of length 512.
Butthese internal representations are invisible to thegrammar writer.In the set of features for a node, some subsetscan be viewed disjunctively.
For instance if a nounis ambiguously singular or plural, it might haveboth features sg and pl.
This situation occursvery much for Arabic text input because of theambiguity due to unvocalized script.
In order notto choke the parse space, the  SG-BAMA interfacecombines some BAMA analyses, basically onesthat have the same stem and POS, so that nodeshave disjunctive BAMA features.
But agreementrules or slot filler constraints often reduce theambiguity.
Such rules, specified in a  perspicuousway in SGF, as we will see below, areimplemented internally by intersecting the bitstring representations of relevant feature sets.For ASG, there are two categories of features.One category consists of BAMA compoundfeatures likeNOUN+NSUFF_FEM_PL+CASE_DEF_ACC(indicating a feminine plural definite accusativenoun).
Although such features are compound inintent, they are treated as atomic symbols by ASG(as are all features specified in Xfeas.lx).Features of the other category are more specialto ASG.
Some of them have to do with syntacticstructure (like presence of an overt subject), andothers are morphological.
Typical morphologicalfeatures are standard, simple ones that appear insets of values for attributes like case, number,gender, and definiteness ?
for example:nom, acc, gensg, dual, plm, f,def, indefBesides declaring features, Xfeas.lx can specifyrelations between features.
One way is to specifysimple hierarchical relations.
An entry of the formx  <  y ?
z ?specifies that feature x implies features y ?
z.  Thismeans for instance that if the feature x is markedon a node, then a test in the grammar for feature ywill succeed.
Hierarchical information like this isstored internally in bit string arrays and allows ef-ficient processing.If an entry is of the formx  < ?
>   u ?
vthen we say that x extends the feature set {u ... v},and x is an extending feature.
The basic idea is thatx is a kind of abbreviation for the disjunction of theset {u ... v}, but x may appear on a node independ-ently of that set.
We will explain the exact mean-ing in the section below on the syntax rules.
Atypical example of an extending feature rule in Ar-feas.lx is as follows:gen < >NOUN+NSUFF_FEM_DU_GENNOUN+NSUFF_FEM_PL+CASE_DEF_GENNOUN+NSUFF_FEM_PL+CASE_INDEF_GEN...where we list all BAMA compound features thatinclude a genitive subfeature.
Rules in the syntaxcomponent can test simply for extending featureslike gen, as we will see below.
The syntax com-ponent does not even mention BAMA features.But this representational scheme allows us to keepBAMA compound features as units -- and this isimportant, because the morphological analysis(with ambiguities shown) requires such groupings.The internal representation of an extending featurerelationship of x to {u ... v} associates with theatom for x the disjunction of the bit strings for u ...v, and the processing is quite efficient.Although the features in Xfeas.lx are generallymorphosyntactic, and have internal atom and bitstring position representations in limited storageareas, SG also allows open-ended features, whichmay be used in the SG lexicon and tested for in thesyntax component.
These are typically semanticfeatures.823 The SG LexiconAlthough BAMA contains lexicons for doingArabic morphological analysis, an SG needs its SGlexicon to drive syntactic analysis and help pro-duce parse trees that show (deep) predicate argu-ment structure.
The main ingredients associatedwith index words in an SG lexicon are senseframes.
A sense frame can specify a part of speech(POS), features (typically semantic features), a slotframe, and other ingredients.
The most importantingredient is the slot frame, which consists of anordered list of (complement) slots.
Slots can bethought of as grammatical relations, but also asnames for logical arguments for word sense predi-cates.
An example from the ASG lexicon, calledAr.lx,  is:Eoniy < v (obj n fin)This says that Eoniy () is a verb (stem) with adirect object slot (obj) which can be filled by ei-ther an NP (indicated by the n) or a finite VP (in-dicated by the fin).
A slot can be either an atomicsymbol or a list of the form(SlotName Option1 ?
Optionn)where the options are terms that specify conditionson the fillers of the slot.
If no options are specified,then defaults are used.
The Eoniy () exampleshows no subject slot, but the default is that everyverb has a subject slot (even though it may not beovertly filled).
One can specify a subject slot(subj) if it needs non-default options.For the index words for ASG, we are currentlyusing vocalized stems ?
stems as in the ATB, or asproduced by BAMA.
To produce a starter forAr.lx, we extracted stems from the ATB, listed byfrequency, and associated default sense framesbased on the BAMA features in the ATB.
Usingvocalized stems entails some repetition of senseframes, since there can be more than one vocalizedstem for a given word sense.Index words in the SG lexicon can also be mul-tiwords.
Some multiword entries occur in Ar.lx.Morpholexical analysis for ASG combinesBAMA analysis with look-up in Ar.lx.
BAMAprovides morphological features (BAMA com-pound features) associated with vocalized stems.Also, an algorithm in ASG separates clitics out ofthe BAMA analyses and represents them in a formconvenient for the parser.
The vocalized stems arelooked up in Ar.lx, and the sense frames foundthere (if look-up is successful) are merged withcompatible analyses from BAMA.
If look-up inAr.lx fails, then the BAMA analyses can still beused, with default slot frames assigned.
In theother direction, look-up in BAMA may fail, andspecial entries in Ar.lx can cover such words(specifying morphological features as well as slotframes).4 The Parsing AlgorithmThe SG parser is a bottom-up chart parser.
Ini-tial chart elements are one-word (or one-multiword)phrases that arise from morpholexical analysis.
Allfurther chart elements arise from binary combina-tions of a modifier phrase M with a higher phraseH, where M fills a slot S in H.  The slot S could bea complement slot which is stored with H, havingarisen from the lexical slot frame of the word sensehead of H.  Or S could be an adjunct slot associatedwith the POS of M in the syntax rule componentX.gram.
In both cases, the conditions for filling Sare specified in X.gram.
The parser attaches post-modifiers first, then premodifiers.Normally, M and H will be existing adjacentphrases in the chart.
But there is an interestingtreatment of clitics that is especially relevant forArabic.
The SG data structure for a phrase P in-cludes two fields for clitics associated with thehead word of P ?
a list of proclitics, and a list ofenclitics.
Each clitic is itself a (one-word) phrasedata structure, ready to be used for slot filling.
Sothe parsing algorithm can combine not only adja-cent phrases in the chart in the normal way, but canalso combine a phrase with one of its clitics.
ForArabic, all enclitics (typically pronouns) for aphrase P are attached to P (by postmodification)before P enters into any other slot filling.
On theother side, proclitics (typically conjunctions andprepositions) of P are used only as higher phraseswhere P is the modifier.
But a proclitic can get?passed upwards?
before it is treated as a higherphrase.
A non-deterministic option in the parser isthat a phrase M becomes a premodifier of an adja-cent phrase H in the chart, and the proclitic list ofM is passed up to become the proclitic list of H.For instance a conjunction like ?w?/?wa?
[ , ?and?
]might be attached as a proclitic to the first word in83a (premodifying) subject of a clause C, and theconjunction proclitic gets passed upwards until itfinally takes C as a postconjunct modifier.Although SG is a rule-based system, it does usea numerical scoring system for phrases duringparsing.
Real numbers are attached to phrases,indicating, roughly, how likely it is that the phraseis a good analysis of what it spans.
Partial analy-ses (phrases) can be pruned out of the chart if theirscores are too bad.
Also, final parses get ranked bytheir scores.
Scores can arise from rules in thesyntax component, in the lexicon, or in the shell.A general rule in the shell is that complement slotsare preferred over adjunct slots.
The specific val-ues of scores are normally determined by thegrammar writer, with regression testing.5 The ASG Syntax Rule ComponentIn an SG syntax rule component X.gram(Ar.gram for Arabic), the rules are written in theformalism SGF (McCord, 2006).
Each rule dealswith slot filling, and is either a complement slotrule or an adjunct slot rule.
Each rule is of theformS  <  Bodywhere S is the index, which is a complement slotfor a complement slot rule, or a POS for an adjunctslot rule.
The Body is basically a logical expres-sion (in a form we will describe) which is true iffthe corresponding slot filling can succeed.
Therules can be viewed largely declaratively, eventhough there are some operators that look likecommands.The rule system is applied by the parsing algo-rithm when it is looking at specific phrases M andH that are adjacent or have a clitic relationship, andasking whether M can fill a slot in H.  For a yetunfilled complement slot S of H, with a chosen slotoption, the parser looks for the complement slotrule in X.gram indexed by S, and applies its body,requiring that to be true before doing the slot fill-ing.
And the parser also looks at the POS of M,finds the corresponding adjunct slot rule indexedby that POS, and applies its body.
In this case, thebody determines what the adjunct slot and optionare; and it can do so non-deterministically:  Thebody may be a disjunction, with operator ||, of sev-eral sub-bodies, which are all tried for insertion ofthe filled version of H into the chart.
Complementslot rules can also use the infix operator || for dis-junctions of the body on the top level, but in thiscase the || behaves deterministically ?
as in an if-then-else.A simple example of a complement slot rule isthe following, for the object of a preposition:objprep <ri(opt n)(mpos noun)(extmf gen)(removemf nom acc)satisfiedThe body is a sequence of tests which are viewedconjunctively.
The first test, ri, means that thefiller M is on the ?
right?
of H (a postmodifier).The opt test checks that the slot option is n, re-quiring an NP.
The next test requires that the fillerM has POS noun.
In SGF rules, the letter m inoperators indicates the filler M as an implicit oper-and, and h indicates the higher phrase H.The term (extmf gen) is an extending featuretest on M for the feature gen (genitive).
This willsucceed iff either gen is marked explicitly on M orM has at least one of the BAMA features associ-ated with gen in the extending feature rule for genin Arfeas.lx (see Section 2).
The test (removemfnom acc) always succeeds, and it will removeexplicit occurrences of  nom or acc on M, as wellas any BAMA features associated with those fea-tures by extending feature rules.Finally, the test satisfied succeeds iff M hasno unfilled obligatory complement slots.The syntax of the SGF formalism is CambridgePolish (Lisplike), except for the uses of the binaryoperators < and ||.
There are quite a number of?
built-in?
operators in SGF, and many of them cantake any number of arguments.Tests in SGF can be nested; some operators, in-cluding all the logical operators, can contain othertests as arguments.
We mentioned that SGF is?
object-oriented?
in a certain sense.
In any giventest, however much embedded, there is always aphrase in focus, which is an implicit argument ofthe test.
The phrase in focus can be consideredlike this in object-oriented languages.
The de-fault phrase in focus on top-level tests is M (themodifier).
But some operators can shift the focus84to another phrase, and this can happen an unlimitednumber of times in nested tests.
For example, atest of the form(rmod Test1 ... Testn)searches the postmodifiers of the current phrase infocus and succeeds iff, for one of them as a newphrase in focus, all of the test arguments are satis-fied.
This scheme allows for quite compact ex-pressions for searching and testing parse trees.Now let us look at (a modified form of) an ad-junct slot rule in Ar.gram, for adjectives that post-modify nouns:adj <ri(hf noun)(agreef nom acc gen)(agreef def indef)(if (& (exthf pl) (nhf h))/* then */(extmf sg f)/* else */(& (agreef sg pl dual)(agreef m f) ) )satisfied(setslot nadj)(setopt aj)So the filler M should be an adjective phrase.The first two tests check that M postmodifies H,and H is a noun phrase.
The main operator here isagreef, which works with a list of extending fea-tures.
The list of features should consist of thepossible values of an attribute like case, number,gender, etc.
The agreef test will succeed iff Mand H agree along this dimension.
For at least oneof the argument features, both M and H shouldhave this feature (as an extending feature).
Fur-thermore, agreef takes care of reducing featureambiguity in M and H (if it succeeds):  If x is anargument feature such that one of M and H has x(as an extending feature) but the other does not,then x is removed from the other (as an extendingfeature).For the adj rule at hand, the if statement canbe interpreted as follows:  If H (the noun) is pluraland not human, then M (the adjective) must be sin-gular and feminine; otherwise M and H must agreein number and gender.
The actual current rule inAr.gram skips the agreement test for plural non-human nouns, because we do not currently haveenough marking of the human (h) features.For subject-verb agreement, we have the situa-tion that verbs do not use the same extending fea-ture names as nouns do.
(This has to do with cor-responding BAMA features.)
To handle this,agreef can take as arguments pairs of features,like (sg vsg), where the first element is checkedfor M (the subj noun), and the second is checkedfor H (the verb).
Here is a shortened form of thesubject slot rule of ASG, which contains the cur-rent subject-verb agreement rule for ASG:subj <(opt n)(mpos noun)(if (mf pron)/* then */(& (agreef (m vm) (f vf))(agreef (sg vsg)(pl vpl)(dual vdual))(agreef (pers1 vpers1)(pers2 vpers2)(pers3 vpers3)) )/* else */(& (exthf vpers3)(if (| (^ (extmf pl)) (mf h))(&(agreef (m vm) (f vf))(if le/* subj before verb */(agreef (sg vsg)(pl vpl)(dual vdual))/*subj after verb: */(exthf vsg) ) ) ) ))The agreement part is the outer if test, and can beinterpreted as follows:1.
If  M is a pronoun, then M agrees with Hin gender, number and person;2. else H must be 3rd-person and if M isnon-plural or human, then:a. M agrees with H  in gender andb.
if M premodifies H then itagrees with H in number,c.
else H is singular.This formulation shows the way we are currentlyignoring agreement for plural non-human nouns,until we get human markings on nouns.85Now let us illustrate how an adjunct slot rule canovercome a seeming problem for dependencygrammars when there is a ?
missing head word?
fora phrase.
Consider n the sentence shown in Figure1, along with its ASG parse tree.   .wh*h ZAhrp $A}Ep jdAF qd ysbbhA Alxwf Aw AlADTrAbAt AlmEwyp.
[This is a very common phenomenon, which may be caused by fear or intestinal disorder.]
------------------------------------------------------------------------o----------- top     wa(111,u,1)     noun pron`----------- rconj   h`*ihi(1)       noun pron`--------- npred   ZAhir(2)        noun sg cn def indef nom f`------- nadj    $A}iE(3)        adj sg def indef nom acc gen f| `----- adjpost jid~(4)         noun cn indef acc qualnoun| .----- vadv    qad(5)          adv`-+----- nrel    sab~ib(6,8,113) verb pronobj`----- obj(n)  hA(113)         noun pron acc encliticf| .--- lconj   xawof(7)        noun cn def nom acc gen`-+--- subj(n) Oaw(8,7,9)      noun pl cn def nom acc f`--- rconj   {iDoTirAb(9)    noun pl cn def nom acc gen f`- nadj    miEawiy~(10)    adj sg def nom acc gen f------------------------------------------------------------------------Figure 1.
Handling a ?
missing head word?Here Arabic does without a form of ?
be?
.
In theATB, the parse tree shows an S node with threedaughters:(S(CONJ wa)(NP-SBJ(DEM_PRON_F h`*ihi))(NP-PRD(NP (NOUN?
ZAhir+ap+N))... ))Since the ATB does not use a dependency treescheme, there is no need for a word acting as averb head of this S.In ASG we solve the problem of the ?
missinghead word?
by letting the ?
clause?
be a nominalphrase with head h`*ihi [ 	 ?
this? ]
(this is thesubj in the ATB tree), where the predicate NP fillsan adjunct slot npred of the head NP.
Logically,this is not unreasonable, because adjuncts oftenpredicate logically on the phrase they modify.
Anda predicate NP for a ?
be?
verb can do just that.The npred rule in Ar.gram is as follows (in ab-breviated form):noun <ri(hf noun)(exthf nom)(extmf nom)(^ (mf propn) (hf propn))(nhf ri1 num)satisfied(^ (lmod lconj (rmod nrel)))(removehf acc gen)(removemf acc gen)(setslot npred)(setopt n)The rule is indexed under the POS  noun, since thenpred  filler M is an NP.
(Actually the noun rulehas several other disjunctive components, sepa-rated by the operator ||, for other ways NPs canmodify other phrases as adjuncts.)
So this rulerequires that M postmodifies H, H is an NP, bothM and H have extending features nom, neither Mnor H is a proper noun, H has no postmodfiers, andis not a number, and H is satisfied.
The test(^ (lmod lconj (rmod nrel)))illustrates two focus-shifting operations (seeabove).
This says that it is not the case that M hasa preconjunct which has a postmodifying relativeclause.
Finally, the rule removes the extending86features acc and gen from both H and M, sets theadjunct slot to npred, and sets its option to n.The parse in Figure 1 illustrates several otherinteresting features of Arabic syntax, for instancethe resumptive pronoun in the relative clause (ad-junct slot nrel).
And this pronoun is an enclitic,treated by the ASG methods described in Section 4.
(The conjunction ?
wa?
in the tree is marked as anoun, because (coordinating) conjunctions in SGinherit features from their conjuncts.
In SG, aphrase?s features are carried on its head word.
)6 Performance of ASGSince SG has its own linguistic choices (includ-ing being a dependency grammar), it is difficult tomeasure ASG automatically against the ATB with-out considerable conversion efforts.
We plan tolook into comparisons with the Prague Treebank(!
"#$%&'"()*+,-., but have not had time yet.
Thebest approach, however, may be to create a tree-bank that simply uses the ASG design.
The SGsystem has some tools for doing that ?
using SGparsing as a starter, and hand-correcting the trees.For the immediate purposes of getting some ideaof where ASG currently stands, we did a shortmeasurement (hand-scored) on 20 untrained-onsegments from the ATB chosen at random, scoringonly the first (highest-ranked) parse for each seg-ment.
The scoring consisted of marking each parsetree node N for correctness of N in the sense that Nhas the correct mother node and the correct POS.
(The parser does make an assignment of POS andmother for every word/node, even when there is nocomplete (segment-spanning) parse for the seg-ment.)
Note that correctness of all mother nodesimplies correct tree shape.
With this measurement,the percentage of correct nodes in the test set was64%.On 1,000 sentences from ATB3 of length 13 to20 words, the percentage of complete parses(phrase analyses that span the whole segment) was72% (with no guarantee of correctness of theseparses).Speed of ASG analysis seems good.
On the1,000 sentences mentioned above, parsing was atthe rate of 2,500 words per second (on a laptop).This is with SGF being used in interpreted mode.There is a compiler for SGF (compiling X.gram toa C program) that provides about a twofold speed-up for syntactic analysis, although the compiler isnot currently up-to-date with the latest set of opera-tors for SGF.For the morpholexical processing part ofanalysis, the rate was 10,000 words per second.This includes look-up and morphology in BAMA,and look-up in Ar.lx ?
the complete morpholexicalprocess.7 Related WorkSurprisingly little information is available regard-ing existing Arabic parsers and their performance,though some commercial parsers must exist.
Untilvery recently, the focus of published research forArabic NLP has been on low-level forms of proc-essing, including morphological analysis, part-of-speech tagging, automatic diacriticization, andnamed entity transliteration; and frequently theterm ?
parsing?
in the context of Semitic languagesrefers to morphological and not syntactic parsing.One symbolic approach to parsing Arabic (Oth-man et al, 2003, 2004) uses a unification-basedgrammar formalism and a chart parser imple-mented in Prolog.
Information in the lexicon on?
subject rationality?
and ?
object rationality?
iscombined with ?
rationality?
features on headnouns and noun phrases to eliminate some of thechoices proposed by the morphological analyzer.No information is provided regarding the coverageof the grammar or the performance of the parser.More performance data is available for two re-lated statistical parsers trained on Arabic treebankdata.
Bikel's (2004) implementation of the Collins(2003) parser, trained on the Arabic TreeBank 1(ATB1), reached recall/precision = 75.4/76.0 onsentences of 40 words or less and 72.5/73.4 on allsentences.
Kulick et al (2006) used the Bikelparser on a revised version of the ATB1 with re-sults comparable to Bikel, and then on ATB3,where initial performance dropped slightly.
Anumber of successive improvements allowed theparser to achieve recall/precision = 78.14/80.26 onsentences of 40 words or less and 73.61/75.64 onall sentences.
The two most substantial improve-ments were obtained by changing the handling ofpunctuation and choosing a tagset that preserves abit more information than the severely reduced onedistributed with the ATB segments.Other statistical parsers that have been used withArabic include one trained on a segment of thePrague Arabic Dependency TreeBank (!
"#$% et al,872004) and then used to assist in the annotation ofthe remainder, but little seems to be publishedabout its performance.
The Stanford Parser hasbeen used with Arabic (http://nlp.stanford.edu/downloads/ lex-parser.shtml), but no specificperformance information could be found.
It isbased on the ideas that there are advantages in fac-toring out the phrase structure tree and the lexicaldependency tree models and estimating them sepa-rately, and that significant improvements can beachieved without including any lexical dependencyinformation by adding a few linguistically moti-vated annotations to phrase structure tree models(Klein and Manning, 2002, 2003).Finally Chiang et al (2006) used both Bikel's(2002) and Chiang's (2000) parsers to develop dif-ferent approaches to parsing text in Levantine Ara-bic based on the Arabic Treebank data.Even less information was found for parsing ofother Semitic Languages (with the exception ofhttp://www.cs.technion.ac.il/~winter/Corpus-Project/project-description.html) and Wintner's(1998) discussion of Hebrew syntax form a com-putational perspective.
However, while the authorsare not very familiar with this language, knownsimilarities with Arabic give us reason to believethat some of our work on ASG could be readilyreusable for Hebrew SG.ReferencesDaniel M. Bikel.
2002.
Design of a multi-lingual, paral-lel processing statistical parsing engine.
In Proceed-ings of International Conference on Human Lan-guage Technology Research (HLT).Daniel M. Bikel.
2004.
On the Parameter Space ofLexicalized Statistical Parsing Models.
PhD thesis,Department of Computer and Information Sciences,University of Pennsylvania.Tim Buckwalter.
2002.
Arabic Morphological AnalyzerVersion 1.0.
Linguistic Data Consortium catalognumber LDC2002L49, ISBN 1-58563-257-0.David Chiang.
2000.
Statistical parsing with an auto-matically-extracted tree adjoining grammar.
In Pro-ceedings of the 38th Meeting of the Association forComputational Linguistics (ACL?00), Hong Kong,China, 456?463.David Chiang, Mona Diab, Nizar Habash, Owen Ram-bow, and Safiullah Sharif.
2006.
Parsing Arabic Dia-lects.
In Proceedings of the 11th Conference of theEuropean Chapter of the Association for Computa-tional Linguistics, Trento, Italy, 369?376.Michael Collins.
2003.
Head-driven statistical modelsfor natural language parsing.
Computational Lin-guistics, 29:589?637.
/"0!
"#$%*1'"2"34536*7&'38&590&2*/"0:0"idauf,and Emanuel Be?ka.
2004.
Prague Arabic Depend-ency Treebank: Development in Data and Tools.
InProceedings of NEMLAR 2004.
/"0!
"#$%&'"()+,-) Prague Dependency TreebankVersion 2.0.
Linguistic Data Consortium catalognumber LDC2006T01, ISBN 1-58563-370-4.Seth Kulick, Ryan Gabbard, and Mitchell Marcus.
2006.Parsing the Arabic Treebank: Analysis and Im-;3<=&5&0'>) ?0!
"#$%/)"0@A$=3&*/)B&@>).C Pro-ceedings of the TLT 2006, pp.
31-42.
Institute ofFormal and Applied Linguistics, Prague, Czech Re-public.Dan Klein and Christopher D. Manning.
2002.
Fast Ex-act Inference with a Factored Model for Natural Lan-guage Parsing.
In Advances in Neural InformationProcessing Systems 15 (NIPS 2002).Dan Klein and Christopher D. Manning.
2003.
AccurateUnlexicalized Parsing.
In Proceedings of the 41stMeeting of the Association for Computational Lin-guistics.Michael C. McCord.
1980.
Slot Grammars.
Computa-tional Linguistics, 6:31-43.Michael C. McCord.
1993.
Heuristics for Broad-Coverage Natural Language Parsing.
In Proceedingsof the ARPA Human Language Technology Work-shop.
Morgan-Kaufmann, 127-132.Michael C. McCord.
2006.
A Formal System for SlotGrammar.
Technical Report RC 23976, IBM T.J.Watson Research Center.E Othman, K Shaalan, A Rafea.
2003.
A Chart Parserfor Analyzing Modern Standard Arabic Sentence.
InProceedings of the MT Summit IX Workshop on Ma-chine Translation.E Othman, K Shaalan, and A Rafea.
2004.
TowardsResolving Ambiguity in Understanding Arabic Sen-tences.
In Proceedings of NEMLAR 2004.Shuly Wintner.
1998.
Towards a linguistically moti-vated computational grammar for Hebrew.
In Pro-ceedings of the ACL-98 Workshop on ComputationalApproaches to Semitic Languages, 82-88.88
