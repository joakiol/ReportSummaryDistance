Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 290?295,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsAn Augmented Three-Pass System Combination Framework:DCU Combination System for WMT 2010Jinhua Du, Pavel Pecina, Andy WayCNGL, School of ComputingDublin City UniversityDublin 9, Ireland{jdu,ppecina,away}@computing.dcu.ieAbstractThis paper describes the augmented three-pass system combination framework ofthe Dublin City University (DCU) MTgroup for the WMT 2010 system combi-nation task.
The basic three-pass frame-work includes building individual confu-sion networks (CNs), a super network, anda modified Minimum Bayes-risk (mCon-MBR) decoder.
The augmented parts forWMT2010 tasks include 1) a rescoringcomponent which is used to re-rank theN -best lists generated from the individualCNs and the super network, 2) a new hy-pothesis alignment metric ?
TERp ?
thatis used to carry out English-targeted hy-pothesis alignment, and 3) more differ-ent backbone-based CNs which are em-ployed to increase the diversity of themConMBR decoding phase.
We tookpart in the combination tasks of English-to-Czech and French-to-English.
Exper-imental results show that our proposedcombination framework achieved 2.17 ab-solute points (13.36 relative points) and1.52 absolute points (5.37 relative points)in terms of BLEU score on English-to-Czech and French-to-English tasks re-spectively than the best single system.
Wealso achieved better performance on hu-man evaluation.1 IntroductionIn several recent years, system combination hasbecome not only a research focus, but also a pop-ular evaluation task due to its help in improvingmachine translation quality.
Generally, most com-bination approaches are based on a confusion net-work (CN) which can effectively re-shuffle thetranslation hypotheses and generate a new targetsentence.
A CN is essentially a directed acyclicgraph built from a set of translation hypothesesagainst a reference or ?backbone?.
Each arc be-tween two nodes in the CN denotes a word or to-ken, possibly a null item, with an associated pos-terior probability.Typically, the dominant CN is constructed at theword level by a state-of-the-art framework: firstly,a minimum Bayes-risk (MBR) decoder (Kumarand Byrne, 2004) is utilised to choose the back-bone from a merged set of hypotheses, and thenthe remaining hypotheses are aligned against thebackbone by a specific alignment approach.
Cur-rently, most research in system combination hasfocused on hypothesis alignment due to its signif-icant influence on combination quality.A multiple CN or ?super-network?
frameworkwas firstly proposed in Rosti et al (2007) whoused each of all individual system results as thebackbone to build CNs based on the same align-ment metric, TER (Snover et al, 2006).
A consen-sus network MBR (ConMBR) approach was pre-sented in (Sim et al, 2007), where MBR decod-ing is employed to select the best hypothesis withthe minimum cost from the original single systemoutputs compared to the consensus output.Du and Way (2009) proposed a combinationstrategy that employs MBR, super network, anda modified ConMBR (mConMBR) approach toconstruct a three-pass system combination frame-work which can effectively combine different hy-pothesis alignment results and easily be extendedto more alignment metrics.
Firstly, a number ofindividual CNs are built based on different back-bones and different kinds of alignment metrics.Each network generates a 1-best output.
Secondly,a super network is constructed combining all theindividual networks, and a consensus is generatedbased on a weighted search model.
In the third290pass, all the 1-best hypotheses coming from sin-gle MT systems, individual networks, and the su-per network are combined to select the final resultusing the mConMBR decoder.In the system combination task of WMT 2010,we adopted an augmented framework by extend-ing the strategy in (Du and Way, 2009).
In addi-tion to the basic three-pass architecture, we aug-ment our combination system as follows:?
We add a rescoring component in Pass 1 andPass 2.?
We introduce the TERp (Snover et al, 2009)alignment metric for the English-targetedcombination.?
We employ different backbones and hypothe-sis alignment metrics to increase the diversityof candidates for our mConMBR decoding.The remainder of this paper is organised as fol-lows.
In Section 2, we introduce the three hy-pothesis alignment methods used in our frame-work.
Section 3 details the steps for building ouraugmented three-pass combination framework.
InSection 4, a rescoring model with rich featuresis described.
Then, Sections 5 and 6 respec-tively report the experimental settings and exper-imental results on English-to-Czech and French-to-English combination tasks.
Section 7 gives ourconclusions.2 Hypothesis Alignment MethodsHypothesis alignment plays a vital role in the CN,as the backbone sentence determines the skeletonand the word order of the consensus output.In the combination evaluation task, we inte-grated TER (Snover et al, 2006), HMM (Ma-tusov et al, 2006) and TERp (Snover et al,2009) into our augmented three-pass combinationframework.
In this section, we briefly describethese three methods.2.1 TERThe TER (Translation Edit Rate) metric measuresthe ratio of the number of edit operations betweenthe hypothesis E?
and the reference Eb to the totalnumber of words in Eb.
Here the backbone Eb isassumed to be the reference.
The allowable editsinclude insertions (Ins), deletions (Del), substitu-tions (Sub), and phrase shifts (Shft).
The TER ofE?
compared to Eb is computed as in (1):TER(E?, Eb) = Ins + Del + Sub + ShftNb ?
100% (1)where Nb is the total number of words in Eb.
Thedifference between TER and Levenshtein edit dis-tance (or WER) is the sequence shift operation al-lowing phrasal shifts in the output to be captured.The phrase shift edit is carried out by a greedyalgorithm and restricted by three constraints: 1)The shifted words must exactly match the refer-ence words in the destination position.
2) Theword sequence of the hypothesis in the originalposition and the corresponding reference wordsmust not exactly match.
3) The word sequenceof the reference that corresponds to the desti-nation position must be misaligned before theshift (Snover et al, 2006).2.2 HMMThe hypothesis alignment model based on HMM(Hidden Markov Model) considers the align-ment between the backbone and the hypoth-esis as a hidden variable in the conditionalprobability Pr(E?|Eb).
Given the backboneEb = {e1, .
.
.
, eI} and the hypothesis E?
={e?1, .
.
.
, e?J}, which are both in the same lan-guage, the probability Pr(E?|Eb) is defined as in(2):Pr(E?|Eb) =?APr(E?, A|Eb) (2)where the alignemnt A ?
{(j, i) : 1 ?
j ?J ; 1 ?
i ?
I}, i and j represent the word po-sition in Eb and E?
respectively.
Hence, the align-ment issue is to seek the optimum alignment A?such that:A?
= argmaxAP (A|eI1, e?J1 ) (3)For the HMM-based model, equation (2) can berepresented as in (4):Pr(E?|Eb) =?aJjJ?j=1[p(aj |aj?1, I) ?
p(e?j |eaj )] (4)where p(aj |aj?1, I) is the alignment probabilityand p(e?j |ei) is the translation probability.2.3 TER-PlusTER-Plus (TERp) is an extension of TER thataligns words in the hypothesis and reference notonly when they are exact matches but also whenthe words share a stem or are synonyms (Snoveret al, 2009).
In addition, it uses probabilisticphrasal substitutions to align phrases in the hy-pothesis and reference.
In contrast to the use of291the constant edit cost for all operations such asshifts, insertion, deleting or substituting in TER,all edit costs in TERp are optimized to maximizecorrelation with human judgments.TERp uses all the edit operations of TER ?matches, insertions, deletions, substitutions, andshifts ?
as well as three new edit operations:stem matches, synonym matches, and phrase sub-stitutions (Snover et al, 2009).
TERp employsthe Porter stemming algorithm (Porter, 1980) andWordNet (Fellbaum, 1998) to perform the ?stemmatch?
and ?synonym match?
respectively.
Se-quences of words in the reference are consideredto be paraphrases of a sequence of words in thehypothesis if that phrase pair occurs in the TERpphrase table (Snover et al, 2009).In our experiments, TERp was used for theFrench-English system combination task, and weused the default configuration of optimised editcosts.3 Augmented Three-Pass CombinationFrameworkThe construction of the augmented three-passcombination framework is shown in Figure 1.Hypotheses SetBLEU TER TERpMBRBLEU TER TERpTop M SingleHMM TER TERpAlignmentIndividual CNsNbestRe-ranking Super CN NetworksmConMBRPass 1Pass 2Pass 3N Single MTSystemsFigure 1: Three-Pass Combination FrameworkIn Figure 1, the dashed boxes labeled ?TERp?indicate that the TERp alignment is only appli-cable for English-targeted hypothesis alignment.The lines with arrows pointing to ?mConMBR?represent adding outputs into the mConMBR de-coding component.
?Top M Single?
indicates thatthe 1-best results from the best M individual MTsystems are also used as backbones to build in-dividual CNs under different alignment metrics.The three dashed boxes represent Pass 1, Pass 2and Pass 3 respectively.
The steps can be sum-marised as follows:Pass 1: Specific Metric-based Single Networks1.
Merge all the 1-best hypotheses from singleMT systems into a new N -best set Ns.2.
Utilise the standard MBR decoder to se-lect one from the Ns as the backbone givensome specific loss function such as TER,BLEU (Papineni et al, 2002) and TERp; Ad-ditionally, in order to increase the diversityof candidates used for Pass 2 and Pass 3, wealso use the 1-best hypotheses from the topM single MT systems as the backbone.
Addthe backbones generated by MBR into Ns.3.
Perform the word alignment between the dif-ferent backbones and the other hypothesesvia the TER, HMM, TERp (only for English)metrics.4.
Carry out word reordering based on wordalignment (TER and TERp have completedthe reordering in the process of scoring) andbuild individual CNs (Rosti et al, 2007);5.
Decode the single networks and export the 1-best outputs and the N -best lists separately.Add these 1-best outputs into Ns.Pass 2: Super-Network1.
Connect the single networks using a startnode and an end node to form a super-network based on multiple hypothesis align-ment and different backbones.
In this evalu-ation, we set uniform weights for these dif-ferent individual networks when building thesuper network(Du and Way, 2009).2.
Decode the super network and generate aconsensus output as well as the N -best list.Add the 1-best result into Ns.3.
Rescore the N -best lists from all individualnetworks and super network and add the new1-best results into Ns.Pass 3: mConMBR1.
Rename the set Ns as a new set Ncon;2.
Use mConMBR decoding to search for thebest final result from Ncon.
In this step, weset a uniform distribution between the candi-dates in Ncon.2924 Rescoring ModelWe adapted our previous rescoring model (Duet al, 2009) to larger-scale data.
The features weused are as follows:?
Direct and inverse IBM model;?
4-gram and 5-gram target language model;?
3, 4, and 5-gram Part-of-Speech (POS) lan-guage model (Schmid, 1994; Ratnaparkhi,1996);?
Sentence-length posterior probability (Zensand Ney, 2006);?
N -gram posterior probabilities within the N -best list (Zens and Ney, 2006);?
Minimum Bayes Risk cost.
This process issimilar to the calculation of the MBR decod-ing in which we take the current hypothesisin the N -best list as the ?backbone?, and thencalculate and sum up all the Bayes risk costbetween the backbone and each of the rest ofthe N -best list using BLEU metric as the lossfunction;?
Length ratio between source and target sen-tence.The weights are optimized via the MERT algo-rithm (Och, 2003).5 Experimental SettingsWe participated in the English?Czech andFrench?English system combination tasks.In our system combination framework, we usea large-scale monolingual data to train languagemodels and carry out POS-tagging.5.1 English-CzechTraining DataThe statistics of the data used for language modelstraining are shown in Table 1.Monolingual Number ofCorpus tokens (Cz) sentencesNews-Comm 2,214,757 84,706CzEng 81,161,278 8,027,391News 205,600,053 13,042,040Total 288,976,088 21,154,137Table 1: Statistics of data in the En?Cz taskAll the data are provided by the workshoporganisers.
1 In Table 1, ?News-Comm?
indi-cates the data set of News-Commentary v1.0 and1http://www.statmt.org/wmt10/translation-task.html?CzEng?
is the Czech?English corpus v0.9 (Bo-jar and Z?abokrtsky?, 2009).
?News?
is the Czechmonolingual News corpus.As to our CN and rescoring components,we use ?News-Comm+CzEng?
to train a4-gram language model and use ?News-Comm+CzEng+News?
to train a 5-gramlanguage model.
Additionally, we per-form POS tagging (Hajic?, 2004) for ?News-Comm+CzEng+News?
data, and train 3-gram,4-gram, and 5-gram POS-tag language models.Devset and TestsetThe devset includes 455 sentences and the testsetcontains 2,034 sentences.
Both data sets are pro-vided by the workshop organizers.
Each sourcesentence has only one reference.
There are 11 MTsystems in the En-Cz track and we use all of themin our combination experiments.5.2 French-EnglishTraining DataThe statistics of the data used for language modelstraining and POS tagging are shown in Table 2.Monolingual Number ofCorpus tokens (En) sentencesNews-Comm 2,973,711 125,879Europarl 50,738,215 1,843,035News 1,131,527,255 48,648,160Total 1,184,234,384 50,617,074Table 2: Statistics of data in the Fr?En task?News?
is the English monolingual Newscorpus.
We use ?News-Comm+Europarl?
totrain a 4-gram language model and use ?News-Comm+Europarl+News?
to train a 5-gram lan-guage model.
We also perform POS tagging (Rat-naparkhi, 1996) for all available data, and train3-gram, 4-gram and, 5-gram POS-tag languagemodels.Devset and TestsetWe also use all the 1-best results to carry out sys-tem combination.
There are 14 MT systems in theFr-En track and we use all of them in our combi-nation experiments.6 Experimental ResultsIn this section, all the results are reported on de-vsets in terms of BLEU and NIST scores.6.1 English?CzechIn this task, we only used one hypothesis align-ment method ?
TER ?
to carry out hypothesis293alignment.
However, in order to increase diversityfor our 3-pass framework, in addition to using theoutput from MBR decoding as the backbone, wealso separately selected the top 4 individual sys-tems (SYS1, SYS4, SYS6, and SYS11 in our sys-tem set) in terms of BLEU scores on the devset asthe backbones so that we can build multiple indi-vidual CNs for the super network.
All the resultsare shown in Table 3.SYS BLEU4 NISTWorst 9.09 3.83Best 17.28 4.99SYS1 15.11 4.76SYS4 12.67 4.40SYS6 17.28 4.99SYS11 15.75 4.81CN-SYS1 17.36 5.12CN-SYS4 16.94 5.10CN-SYS6 17.91 5.13CN-SYS11 17.45 5.09CN-MBR 18.29 5.15SuperCN 18.44 5.17mConMBR-BAS 18.60 5.18mConMBR-New 18.84 5.11Table 3: Automatic evaluation of the combinationresults on the En-Cz devset.?Worst?
indicates the 1-best hypothesis fromthe worst single system, the ?Best?
is the 1-besthypothesis from the best single system (SYS11)).?CN-SYSX?
denotes that we use SYSX (X =1, 4, 6, 11 and MBR) as the backbone to build anindividual CN.
?mConMBR-BAS?
stands for theoriginal three-pass combination framework with-out rescoring component, while ?mConMBR-New?
indicates the proposed augmented combina-tion framework.
It can be seen from Table 3 that 1)in all individual CNs, the CN-MBR achieved thebest performance; 2) SuperCN and mConMBR-New improved by 1.16 (6.71% relative) and 1.56(9.03% relative) absolute BLEU points comparedto the best single MT system.
3) our newthree-pass combination framework achieved theimprovement of 0.24 absolute (1.29% relative)BLEU points than the original framework.The final results on the test set are shown in Ta-ble 4.SYS BLEU4 human eval.
(%win)Best 16.24 70.38mConMBR-BAS 17.91 -mConMBR-New 18.41 2 75.17Table 4: Evaluation of the combination results onthe En-Cz testset.It can be seen that our ?mConMBR-New?framework performs better than the best singlesystem and our original framework ?mConMBR-BAS?
in terms of automatic BLEU scores and hu-man evaluation for the English-to-Czech task.
Inthis task campaign, we achieved top 1 in terms ofthe human evaluation.6.2 French?EnglishWe used three hypothesis alignment methods ?TER, TERp and HMM ?
to carry out word align-ment between the backbone and the rest of thehypotheses.
Apart from the backbone generatedfrom MBR, we separately select the top 5 individ-ual systems (SYS1, SYS10, SYS11, SYS12, andSYS13 in our system set) respectively as the back-bones using HMM, TER and TERp to carry outhypothesis alignment so that we can build moreindividual CNs for the super network to increasethe diversity of candidates for mConMBR.
The re-sults are shown in Table 5.3SYS BLEU4(%) NISTWorst 15.04 4.97Best 28.88 6.71CN-SYS1-TER 29.56 6.78CN-SYS1-HMM 29.60 6.84CN-SYS1-TERp 29.77 6.83CN-MBR-TER 30.16 6.91CN-MBR-HMM 30.19 6.92CN-MBR-TERp 30.27 6.92SuperCN 30.58 6.90mConMBR-BAS 30.74 7.01mConMBR-New 31.02 6.96Table 5: Automatic evaluation of the combinationresults on the Fr-En devset.?CN-MBR-X?
represents the different possi-ble hypothesis alignment methods (X = {TER,HMM, TERp}) which are used to build indi-vidual CNs using the output from MBR de-coding as the backbone.
We can see that theSuperCN and mConMBR-New respectively im-proved by 1.7 absolute (5.89% relative) and 2.88absolute (9.97% relative) BLEU points comparedto the best single system.
Furthermore, our aug-mented framework ?mConMBR-New?
achievedthe improvement of 0.28 absolute (0.91% relative)BLEU points than the original three-pass frame-work as well.2This score was measured in-house on the refer-ence provided by the organizer using metric mteval-v13(ftp://jaguar.ncsl.nist.gov/mt/resources/mteval-v13.pl).3In this Table, we take SYS1 as an example to show theresults using a single MT system as the backbone under thethree alignment metrics.294The final results on the test set are shown in Ta-ble 6.SYS BLEU4 human eval.
(%win)Best 28.30 66.84mConMBR-BAS 29.21 -mConMBR-New 29.82 2 72.15Table 6: Evaluation of the combination results onFr-En test set.It can be seen that our ?mConMBR-New?framework performs the best than the best singlesystem and our original framework ?mConMBR-BAS?
in terms of automatic BLEU scores and hu-man evaluation for the French?English task.7 Conclusions and Future WorkWe proposed an augmented three-pass mul-tiple system combination framework for theWMT2010 system combination shared task.
Theaugmented parts include 1) a rescoring model toselect the potential 1-best result from the indi-vidual CNs and super network to increase the di-versity for ?mConMBR?
decoding; 2) a new hy-pothesis alignment metric ?TERp?
for English-targeted alignment; 3) 1-best results from the topM individual systems employed to build CNsto augment the ?mConMBR?
decoding.
Wetook part in the English-to-Czech and French-to-English tasks.
Experimental results reported ontest set of these two tasks showed that our aug-mented framework performed better than the bestsingle system in terms of BLEU scores and hu-man evaluation.
Furthermore, the proposed aug-mented framework achieved better results than ourbasic three-pass combination framework (Du andWay, 2009) as well in terms of automatic evalua-tion scores.
In the released preliminary results, weachieved top 1 and top 3 for the English-to-Czechand French-to-English tasks respectively in termsof human evaluation.As for future work, firstly we plan to do furtherexperiments using automatic weight-tuning algo-rithm to tune our framework.
Secondly, we planto examine how the differences between the hy-pothesis alignment metrics impact on the accuracyof the super network.
We also intend to integratemore alignment metrics to the networks and verifyon the other language pairs.AcknowledgmentsThis research is supported by the Science Foundation Ireland(Grant 07/CE/I1142) as part of the Centre for Next Gener-ation Localisation (www.cngl.ie) at Dublin City Universityand has been partially funded by PANACEA, a 7th Frame-work Research Programme of the European Union (contractnumber: 7FP-ITC-248064) as well as partially supported bythe project GA405/09/0278 of the Grant Agency of the CzechRepublic.
Thanks also to the reviewers for their insightfulcomments.ReferencesBojar, O. and Z?abokrtsky?, Z.
(2009).
CzEng0.9: Large Par-allel Treebank with Rich Annotation.
Prague Bulletin ofMathematical Linguistics, 92.Du, J., He, Y., Penkale, S., and Way, A.
(2009).
MaTrEx:The DCU MT System for WMT2009.
In Proceedings ofthe EACL-WMT 2009, pages 95?99, Athens, Greece.Du, J. and Way, A.
(2009).
A Three-pass System Com-bination Framework by Combining Multiple HypothesisAlignment Methods.
In Proceedings of the InternationalConference on Asian Language Processing (IALP), pages172?176, Singapore.Fellbaum, C., editor (1998).
WordNet: an electronic lexicaldatabase.
MIT Press.Hajic?, J.
(2004).
Disambiguation of Rich Inflection (Compu-tational Morphology of Czech), volume 1.
Charles Uni-versity Press, Prague.Kumar, S. and Byrne, W. (2004).
Minimum Bayes-Risk De-coding for Statistical Machine Translation.
In Proceed-ings of the HLT-NAACL 2004, pages 169?176, Boston,MA.Matusov, E., Ueffing, N., and Ney, H. (2006).
Computingconsensus translation from multiple machine translationsystems using enhanced hypotheses alignment.
In Pro-ceedings of EACL?06, pages 33?40.Och, F. (2003).
Minimum error rate training in statisticalmachine translation.
In Proceedings of the 41st AnnualMeeting of the Association for Computational Linguistics(ACL), pages 160?167, Sapporo, Japan.Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J.
(2002).BLEU: a Method for Automatic Evaluation of MachineTranslation.
In Proceedings of the ACL-02, pages 311?318, Philadelphia, PA.Porter, M. F. (1980).
An algorithm for suffix stripping, pro-gram.Ratnaparkhi, A.
(1996).
A Maximum Entropy Modelfor Part-of-Speech Tagging.
In Proceedings of theEMNLP?96, pages 133?142, Philadelphia, PA.Rosti, A., Matsoukas, S., and Schwartz, R. (2007).
ImprovedWord-Level System Combination for Machine Transla-tion.
In Proceedings of ACL?07, pages 312?319.Schmid, H. (1994).
Probabilistic Part-of-Speech Tagging Us-ing Decision Trees.
In Proceedings of International Con-ference on New Methods in Language Processing, pages44?49, Manchester, UK.Sim, K., Byrne, W., Gales, M., Sahbi, H., and Woodland, P.(2007).
Consensus network decoding for statistical ma-chine translation system combination.
In Proceedings ofthe ICASSP?07, pages 105?108.Snover, M., Dorr, B., Schwartz, R., Micciula, L., andMakhoul, J.
(2006).
A study of translation edit ratewith targeted human annotation.
In Proceedings of theAMTA?06), pages 223?231, Cambridge, MA.Snover, M., Madnani, N., J.Dorr, B., and Schwartz, R.(2009).
Fluency, adequacy, or HTER?
Exploring differenthuman judgments with a tunable MT metric.
In Proceed-ings of the WMT?09, pages 259?268, Athens, Greece.Zens, R. and Ney, H. (2006).
N-gram Posterior Probabilitiesfor Statistical Machine Translation.
In Proceedings of theHLT-NAACL?06), pages 72?77, New York, USA.295
