Automatic Identification of Rhetorical Roles using ConditionalRandom Fields for Legal Document SummarizationM.
SaravananDepartment of CS & EIIT Madras, Chennai-36msdess@yahoo.comB.
RavindranDepartment of CS & EIIT Madras, Chennai-36ravi@cse.iitm.ac.inS.
RamanDepartment of CS & EIIT Madras, Chennai-36ramansubra@gmail.comAbstractIn this paper, we propose a machinelearning approach to rhetorical roleidentification from legal documents.
In ourapproach, we annotate roles in sampledocuments with the help of legal expertsand take them as training data.
Conditionalrandom field model has been trained withthe data to perform rhetorical roleidentification with reinforcement of richfeature sets.
The understanding of structureof a legal document and the application ofmathematical model can brings out aneffective summary in the final stage.
Otherimportant new findings in this workinclude that the training of a model for onesub-domain can be extended to anothersub-domains with very limited augmenta-tion of feature sets.
Moreover, we cansignificantly improve extraction-basedsummarization results by modifying theranking of sentences with the importanceof specific roles.1 IntroductionWith the availability of large number of colossallegal documents in electronic format, there is arising need for effective information retrieval toolsto assist in organizing, processing and retrievingthis information and presenting them in a suitableuser-friendly format.
To that end, text summariza-tion is an important step for many of these largerinformation management goals.
In recent years,much attention has been focused on the problem ofunderstanding the structure and textual units inlegal judgments (Farzindar & Lapalme, 2004).
Inthis case, performing automatic segmentation of adocument to understand the rhetorical roles turnsout to be an important research issue.
For instance,Farzindar (2004) proposed a text summarizationmethod to manipulate factual and heuristicknowledge from legal documents.
Hachey andGrover (2005) explored machine learning approachto rhetorical status classification by performingfact extraction and sentence extraction forautomatic summarization of texts in the legaldomain.
They formalized the problem to extractmost important units based on the identification ofthematic structure of the document and determina-tion of argumentative roles of the textual units inthe judgment.
They mainly used linguistic featuresto identify the thematic structures.In this paper, we discuss methods for automaticidentification of rhetorical roles in legal judgmentsbased on rules and on machine learning techniques.Using manually annotated sample documents onthree different legal sub-domains (rent control,income tax and sales tax), we train an undirectedgraphical model to segment the documents alongdifferent rhetorical structures.
To represent thedocuments for this work, we mainly used featureslike cue words, state transition, named entity,position and other local and global features.
Thesegmented texts with identified roles play a crucialpart in re-ordering the ranking in the finalextraction-based summary.
The importantsentences are extracted based on the termdistribution model given in [Saravanan et al2006].
In   order to develop a generic approach toperform segmentation, we use a fixed set of sevenrhetorical categories based on Bhatia?s (1993)genre analysis shown in Table 1.Graphical Models are nowadays used in manytext   processing  applications;   however  the  main481Rhetorical Roles DescriptionIdentifying the case  (1) The sentences that are present in a judgment to identify the issues to be decided for acase.
Courts call them as ?Framing the issues?.Establishing facts of thecase  (2)The facts that are relevant to the present proceedings/litigations that stand proved, dis-proved or unproved for proper applications of correct legal principle/law.Arguing the case   (3) Application of legal principle/law advocated by contending parties to a given set ofproved facts.History of the case  (4) Chronology of events with factual details that led to the present case between partiesnamed therein before the court on which the judgment is delivered.Arguments (Analysis ) (5) The court discussion on the law that is applicable to the set of proved facts by weighingthe arguments of contending parties with reference to the statute and precedents that areavailable.Ratio decidendi    (6)(Ratio of the decision)Applying the correct law to a set of facts is the duty of any court.
The reason given forapplication of any legal principle/law to decide a case is called Ratio decidendi in legalparlance.
It can also be described as the central generic reference of text.Final decision  (7)(Disposal)It is an ultimate decision or conclusion of the court following as a natural or logical out-come of ratio of the decisionTable 1.
The current working version of the rhetorical annotation scheme for legal judgments.focus has been performing Natural Languageprocessing tasks on newspaper and research paperdomains.
As a novel approach, we have tried andimplemented the CRF model for role identificationin legal domain.
In this regard, we have firstimplemented rule based approach and extend thismethod with additional features and a probabilisticmodel.
In another study, CRF is used as a tool tomodel the sequence labeling problem for summari-zation task (Shen at al., 2006).
In our work, we arein the process of   developing a fully automaticsummarization system for a legal domain on thebasis of Lafferty?s (2001) segmentation task andTeufel & Moen?s (2004) gold standard approaches.Legal judgments are different in characteristicscompared with articles reporting scientific researchpapers and other simple domains related to theidentification of basic structures of a document.
Toperform a summarization methodology and findout important portions of a legal document is acomplex problem (Moens, 2004).
Even the skilledlawyers are facing difficulty in identifying themain       decision part of a law report.
The genrestructure identified for legal judgment in our workplays a crucial role in identifying the main decisionpart in the way of breaking the document inanaphoric chains.
The sentence extraction taskforms part of an automatic summarization systemin the legal domain.
The main focus of this paper isinformation extraction task based on the identifiedroles and methods of structuring summarieswhich  has considered  being a  hot  research  topicMost traditional rule learning algorithms are basedon a divide-and-conquer strategy.
SLIPPER[Cohen, 1999] is one of the standard rule learningalgorithms used for information retrieval task.
InSLIPPER, the ad hoc metrics used to guide thegrowing and pruning of rules are replaced withmetrics based on the formal analysis of boostingalgorithms.
For each instance, we need to checkeach and every rule in the rule set for a givensentence.
It takes more time for larger corpora(Yeh et al, 2005).
Now we will discuss theimportance of identifying rules in the datacollection by various methods available for rulelearning in the next section.2 Text Segmentation AlgorithmsWe explain two approaches to text segmentationfor identifying the rhetorical roles in legaljudgments.
The focus of the first approach is on arule-based method with novel rule sets which wefine-tuned for legal domains.
That is, we frame textsegmentation as a rule learning problem.
Theproposed rule-based method can be enhanced withadditional features and a probabilistic model.
Anundirected graphical model, Conditional RandomField (CRF) is used for this purpose.
It showssignificant improvement over the rule-basedmethod.
The explanation of these methods is givenin the following sections.2.1 Rule-based learning algorithms482compared to other rule learning algorithms evenfor  a  two-class  problem.
If  we  need to  considermore than two classes and to avoid overfitting ofensemble of rules, one has to think of grouping therules in a rule set and some chaining mechanismhas to be followed.
Another rule learning algorithmRuleFit (Friedman & Popescu, 2005) generates asmall comprehensible rule set which is used inensemble learning with larger margin.
In this case,overfitting may happen, if the rule set gets toolarge and thus some form of control has to bemaintained.
Our main idea is to find a preferablysmall set of rules with high predictive accuracy andwith marginal execution time.We propose an alternative rule learning strategythat concentrates on classification of rules andchaining relation in each rhetorical role (Table 1)based on the human annotation schemes.
A chainrelation is a technique used to identify co-occurrences of roles in legal judgments.
In ourapproach, rules are conjunctions of primitiveconditions.
As used by the boosting algorithms, arule set R can be any hypothesis that partitions theset of instance X into particular role categorization;the set of instances which satisfy any one of sevendifferent set of categorized roles.
We start bygenerating rules that describe the original featuresfound in the training set.
Each rule outputs 1 if itscondition is met, 0 if it is not met.
Let us nowdefine for a sample document X = (S1, S2,?.,Sm)of size m, we assume that the set of rulesR = {rThe CRF model-based retrieval system designed inthis paper will depict the way a human can summa-rize a legal judgment by understanding theimportance of roles and related contents.Conditional Random Fields is one of the recentlyemerging graphical models which have been usedfor text segmentation problems and proved to beone of the best available frame works compared toother existing models (Lafferty, 2001).
Ajudgment can be regarded as a sequence ofsentences that can be segmented along the sevenrhetorical roles where each segments is relativelycoherent in content.
We use CRF as a tool tomodel the text segmentation problem.
CRFs areundirected graphical models used to specify theconditional probabilities of possible labelsequences given an observation sequence.
More-over, the conditional probabilities of labelsequences can depend on arbitrary, non independ-ent features of the observation sequence, since weare not forming the model to consider thedistribution of those dependencies.
In a specialcase in which the output nodes of the graphicalmodel are linked by edges in a linear chain, CRFsmake a first-order Markov independenceassumption with binary feature functions, and thuscan be understood as conditionally-trained finitestate   machines (FSMs) which are suitable for se-quence labeling.A linear chain CRF with parametersC = {C1,r2,?}
are applied to sample X, where eachrule ri : X ?
L  represents the mapping ofsentences of X onto a rhetorical role andL = {L1,L2,?,L7}.
Each Li represents a rhetoricalrole from the fixed set shown in Table 1.
Anoutline of our method is given below.Procedure Test (X){    Read test setRead instances from sample X (instances  may  bewords,  N-grams or even full sentences)Apply rules in R (with role categorizationby maintaining chain relation)For k = 1 to m sentencesFor i = 1, 2, ?.
no.
of instances in each sentenceFor j = 1 to 7      /* 7 identified roles */If there exist a rule which satisfies thenX(i,j)  gets a value  1ElseX(i,j) gets a value {1,0} based on chain relationS(k) = L (argmax ?
(X(i,j)))j       i}2.2 Conditional Random Fields and Features1,C2,?..}
defines a  conditional probabilityfor a label sequence l = l1,?..lw (e.g., Establishingfacts of the case, Final decision, etc.)
given anobserved input sequence s = s1,?sW to be1          w mPC(l | s) = ---  exp[??
Ck fk (lt-1, lt. s, t)  ?.
(1)Zs             t=1 k=1where Zs  is the normalization factor that makes theprobability of all state sequences sum to one,fk (lt-1, lt, s, t) is one of  m feature functions which isgenerally binary valued and Ck is a learned weightassociated with feature function.
For example, afeature may have the value of 0 in most cases, butgiven the text ?points for consideration?, it has thevalue 1 along the transition where lt-1 correspondsto a state with the label identifying the case, lt   cor-responds to a state  with the label  history of thecase,  and  fk is  the feature  function  PHRASE=483?points for consideration?
belongs to s at position tin the sequence.
Large positive values for Ckindicate a preference for such an event, while largenegative values make the event unlikely and nearzero for relatively uninformative features.
Theseweights are set to maximize the conditional loglikelihood of labeled sequence in a training setD = {( sState Transition features - In CRFs, statetransitions are also represented as features (Peng &McCullam, 2006).
The feature function ft, lt) : t = 1,2,?w), written as:LC (D) =   ?log PC(li | si)iw m=  ?
(?
?
Ck fk (lt-1, lt. s, t)  - log Zsi )...(2)it=1 k=1The training state sequences are fully labeled anddefinite, the objective function is convex, and thusthe model is guaranteed to find the optimal weightsettings in terms of LC (D).
The probable labelingsequence for an input si can be efficientlycalculated by dynamic programming usingmodified Viterbi algorithm.
These implementa-tions of CRFs are done using newly developed javaclasses which also use a quasi-Newton methodcalled L-BFGS to find these feature weightsefficiently.
In addition to the following standard setof features, we also added other related features toreduce the complexity of legal domain.Legal vocabulary features - One of the simplestand most obvious set of features is decided usingthe basic vocabularies from a training data.
Thewords that appear with capitalizations, affixes, andin abbreviated texts are considered as importantfeatures.
Some of the phrases that include v. andact/section are the salient features for arguing thecase and arguments categories.We have gathered a corpus of legal judgments upto the year 2006 which were downloaded fromwww.keralawyer.com specific to the sub-domainsof rent control, income tax and sales tax.
Using themanually annotated subset of the corpus (200judgments) we have performed a number ofpreliminary experiments to determine whichmethod would be appropriate for role identifica-tion.
The annotated corpus is available fromiil.cs.iitm.ernet.in/datasets.
Even though, incometax and sales tax judgments are based on similarfacts, the number of relevant legal sections /provisions are differ.
The details and structure ofjudgments related to rent control domain are notthe same compared to income tax and sales taxdomains.
Moreover, the roles like ratio decidendiand final decision occur many times spread overthe full judgment in sales tax domain, which iscomparatively different to other sub-domains.
Wehave implemented both the approaches on rentcontrol domain successfully.
We found that theother sub-domains need specific add-on featureswhich improve the result by an additional 20%.Based on this, we have introduced additionalfeatures and new set of rules for the income taxand sales tax related judgments.
The modified ruleset and additional features are smaller in number,but  create  a  good impact  on the  rhetorical statusIndicator/cue phrases ?
The term ?cue phrase?indicates the key phrases frequently used which arethe indicators of common rhetorical roles of thesentences (e.g.
phrases such as ?We agree withcourt?, ?Question for consideration is?, etc.,).
Inthis study, we encoded this information andgenerated automatically explicit linguistic features.Feature functions for the rules are set to 1 if theymatch words/phrases in the input sequence exactly.Named entity recognition - This type ofrecognition is not considered fully in summarizingscientific articles (Teufel & Moens, 2002).
But inour work, we included few named entities likeSupreme Court, Lower court etc., and generatebinary-valued entity type features which take thevalue 0 or 1 indicating the presence or absence of aparticular entity type in the sentences.Local features and Layout features - One of themain advantages of CRFs is that they easily affordthe use of arbitrary features of the input.
One canencode abbreviated features; layout features suchas position of paragraph beginning, as well as thesentences appearing with quotes, all in oneframework.k (lt-1, lt. s,t) in Eq.
(1) is a general function over states andobservations.
Different state transition features canbe defined to form different Markov-orderstructures.
We define state transition featurescorresponding to appearance of years attached withSection and Act nos.
related to the labels arguingthe case and arguments.2.3 Experiments with role identification484Precision Recall F-measureRhetorical RolesSlipperRule-basedCRF Slipper Rule-basedCRF Slipper Rule-basedCRFIdentifying the case    0.641 0.742 0.846 0.512 0.703 0.768 0.569 0.722 0.853Establishing the facts of the case 0.562 0.737 0.824 0.456 0.664 0.786 0.503 0.699 0.824Arguing the case 0.436 0.654 0.824 0.408 0.654 0.786 0.422 0.654 0.805History of the case 0.841 0.768 0.838 0.594 0.716 0.793 0.696 0.741 0.815Arguments 0.543 0.692 0.760 0.313 0.702 0.816 0.397 0.697 0.787Ratio of decidendi 0.574 0.821 0.874 0.480 0.857 0.903 0.523 0.839 0.888RentControlDomainFinal Decision 0.700 0.896 0.986 0.594 0.927 0.961 0.643 0.911 0.973Micro-Average of F-measure   0.536 0.752 0.849Precision Recall F-measureRhetorical RolesSlipperRule-basedCRF Slipper Rule-basedCRF Slipper Rule-basedCRFIdentifying the case 0.590 0.726 0.912 0.431 0.690 0.852 0.498 0.708 0.881Establishing the facts of the case 0.597 0.711 0.864 0.512 0.659 0.813 0.551 0.684 0.838Arguing the case 0.614 0.658 0.784 0.551 0.616 0.682 0.581 0.636 0.729History of the case 0.437 0.729 0.812 0.418 0.724 0.762 0.427 0.726 0.786Arguments 0.740 0.638 0.736 0.216 0.599 0.718 0.334 0.618 0.727Ratio of decidendi 0.416 0.708 0.906 0.339 0.663 0.878 0.374 0.685 0.892IncomeTaxDomainFinal Decision   0.382 0.752 0.938 0.375 0.733 0.802 0.378 0.742 0.865Micro-Average of F-measure   0.449 0.686 0.817Precision Recall F-measureRhetorical RolesSlipperRule-basedCRF Slipper Rule-basedCRF Slipper Rule-basedCRFIdentifying the case 0.539 0.675 0.842 0.398 0.610 0.782 0.458 0.641 0.811Establishing the facts of the case 0.416 0.635 0.784 0.319 0.559 0.753 0.361 0.595 0.768Arguing the case 0.476 0.718 0.821 0.343 0.636 0.747 0.399 0.675 0.782History of the case 0.624 0.788 0.867 0.412 0.684 0.782 0.496 0.732 0.822Arguments 0.500 0.638 0.736 0.438 0.614 0.692 0.467 0.626 0.713Ratio of decidendi 0.456 0.646 0.792 0.318 0.553 0.828 0.375 0.596 0.810Sales TaxDomainFinal Decision 0.300 0.614 0.818 0.281 0.582 0.786 0.290 0.598 0.802Micro-Average of F-measure   0.407 0.637 0.787classification in   the  sales  tax   and  income   taxdomains.
It is common practice to consider humanperformances as an upper bound for most of the IRtasks, so in our evaluation, the performance of thesystem has been successfully tested by matchingwith human annotated documents.Kappa (Siegal & Castellan, 1988) is anevaluation measure used in our work to comparethe inter-agreement between sentences extractedby two human annotators for role identification inlegal judgments.
The value (K=0.803) shows thegood reliability of human annotated corpus.
Theresults given in Table 2 show that CRF-based andrule-based methods perform well for each rolecategories compared to SLIPPER method.
CRF-based method performs extremely well and pairedt-test result indicates that it is significantly (p <.01) higher than the other two methods onrhetorical role identification for legal judgmentsbelonging to  rent control, income tax and sales taxFigure 1 shows that the distribution of the sevencategories is very much skewed, with 60% of allsentences being classified as history of the case.Basically it includes the   remaining contents of theTable 2.
Precision, Recall and F-measure for seven rhetorical rolessub-domains.
In this experiment, we also made aneffort to understand the annotation of relevance ofseven rhetorical categories.Figure 1.
Distribution of rhetorical roles (10 entiredocuments from rent control sub-domain)112%%29% 3 4%460%519%65%7485document other than the six categories.
In thiscase, we have calculated the distribution among 10judgments related to rent control documents.Figure 2 shows the rhetorical category distributionamong the 10 different summaries from rentcontrol domain.
This shows that the resultingcategory distribution is far more evenly distributedthan the one covering all sentences in Figure 1.Ratio of decidendi and final decision are thetwo most frequent categories in the sentencesextracted from judgments.
The label numbers men-tioned in the Figures denote the rhetorical roleswhich as defined in Table 1.The automatic text summarization process startswith sending legal document to a preprocessingstage.
In this preprocessing stage, the document isto be divided into segments, sentences and tokens.We have introduced some new feature identifica-tion techniques to explore paragraph alignments.This process includes the understanding ofabbreviated texts and section numbers and argu-ments which are very specific to the structure oflegal documents.
The other useful statisticalnatural language processing tools, such as filteringout stop list words, stemming etc., are carried outin the preprocessing stage.
The resultingintelligible words are useful in the normalization ofterms in the term distribution model (Saravanan etal., 2006).
During the final stage, we have alteredthe ranks or removed some of the sentences fromthe final summary based on the structurediscovered using CRF.
The summarization modulearchitecture is shown in Figure 3.18% 215%312%414%516%627%78%Figure 2.
Distribution of rhetorical roles (10different summaries from rent control sub-domain)The application of term distribution modelbrings out a good extract of sentences present in alegal document to generate a summary.
Thesentences with labels identified during CRFimplementation can be used with the termdistribution model to give more significance tosome of the sentences with specific roles.Moreover, the structure details available in thisstage are useful in improving the coherency andreadability among the sentences present in thesummary.3 Legal Document SummarizationExtraction of sentences in the generation of asummary at different percentage levels of text isone of the widely used methods in documentsummarization (Radev et al, 2002).
For the legaldomain, generating a summary from the originaljudgment is a complex problem.
Our approach toproduce the summary is extraction-based methodwhich identifies important elements present in alegal judgment.
The identification of the documentstructure using CRF-model categorizes the keyideas from the details of a legal judgment.
Thegenre structure has been applied to final summaryto improve the readability and coherence.
In orderto evaluate the effectiveness of our summarizer, wehave applied four different measures to look for amatch on the model summary generated byhumans (head notes) from the text of the originaljudgments.Extrinsic and intrinsic are the two differentevaluation strategies available for text summariza-tion (Sparck Jones & Gablier, 1996).
Intrinsicmeasure shows the presence of source contents inthe summary.
F-measure and MAP are twostandard intrinsic measures used for the evaluationof our system-generated summary.
We have alsoused ROUGE evaluation approach (Lin, 2004)which is based on n-gram co-occurrences betweenmachine summaries and ideal human summaries.3.1 Applying term distribution modelLegalDocumentsSegmented text withlabels (CRF imple-mentation)Pre-processingTerm distri-bution modelSummary withratio & finaldecisionFigure 3.
Architectural view of summarizationsystem.3.2 Evaluation of  a summary486In this paper, we have applied ROUGE-1 andROUGE-2 which are simple n-gram measures.
Wecompared our results with Microsoft, MeadSummarizer (Radev et al, 2003) and other twosimple baselines: one which chooses 15% ofwords of the beginning of the judgment andsecond chooses last 10% of words of the judgmentwith human reference summaries.
Both thebaselines defined in this study are standardbaselines for newspaper and research domains.The result shown in Table 3 highlights the betterperformances of our summarizer compared toother methods considered in this study.
We cansee that the results of MEAD and WORDsummaries are not at the expected level, while oursummarizer is best in terms of all four evaluationmeasures.
Results are clearly indicated that oursystem performs significantly better than the othersystems for legal judgments.We would like to thank the legal fraternity for theassistance and guidance governs to us.
Especiallywe express our sincere gratitude to the advocatesMr.
S.B.C.
Karunakaran and Mr. K.N.
Somasunda-ram for their domain advice and continuousguidance in understanding the structure of legaldocument and for hand annotated legal judgments.Table 3.
MAP, F-measure and ROUGE scores.4 ConclusionThis paper describes a novel method for generatinga summary for legal judgments with the help ofundirected graphical models.
We observed thatrhetorical role identification from legal documentsis one of the primary tasks to understand thestructure of the judgments.
CRF model performsmuch better than rule based and other rule learningmethod in segmenting the text for legal domains.Our approach to summary extraction is based onthe extended version of term weighting method.With the identified roles, the important sentencesgenerated in the probabilistic model will bereordered or suppressed in the final summary.
Theevaluation results show that the summarygenerated by our summarizer is closer to thehuman generated head notes, compared to the othermethods considered in this study.
Hence the legalcommunity will get a better insight without readinga full judgment.
Moreover, our system-generatedsummary is more useful for lawyers to prepare thecase history related to presently appearing cases.Dou Shen, Jian-Tao Sun, Hua Li, Qiang Yang, andZheng Chen.
2007.
Document Summarization usingConditional Random Fields.
International JointConference on Artificial Intelligence, IJCAI 2007,Hyderabad, India, PP.2862-2867.AcknowledgementReferencesAtefeh Farzindar and Guy Lapalme.
2004.
Legal textsummarization by exploration of the thematicstructures and      argumentative roles, In Text sum-marization Branches out workshop held in conjunc-tion with ACL 2004, pages 27-34, Barcelona, Spain.
MAP F-meas-ureROUGE-1ROUGE-2Baseline 1 0.370 0.426 0.522 0.286Baseline 2 0.452 0.415 0.402 0.213MicrosoftWord0.294 0.309 0.347 0.201Mead 0.518 0.494 0.491 0.263Our system 0.646 0.654 0.685 0.418Atefeh Farzindar and Guy Lapalme.
2004.
Letsum, anautomatic legal text summarizing system, LegalKnowledge and Information System, Jurix 2004: TheSeventeenth   Annual Conference, Amsterdam, IOSPress, PP.11-18.Ben Hachey and Claire Grover.
2005.
Sequence Model-ing for sentence classification in a legal summariza-tion system, Proceedings of the 2005 ACM sympo-sium on Applied Computing.Bhatia, V.K., 1999.
Analyzing Genre: Language Use inProfessional Settings, London, Longman.Cohen,W., and Singer, Y.
1999.
A simple, fast, andeffective rule learner, Proceedings of the SixteenthNational      Conference on Artificial Intelligence(AAAI-99), AAAI Press, pp.335-342.Dragomir Radev, Eduard Hovy, Kathleen McKeown.2002.
Introduction to the special issue on summari-zation,     Computational Linguistics 28(4)4, Associa-tion for Computing Machinery.Dragomir Radev, Jahna Otterbaher, Hong Qi, andDaniel Tam.
2003.
Mead Reducs: Michigan at DUC,2003.
In DUC03, Edmonton, Alberta, Canada, May31- June 1.
Association for Computational Linguis-tics.487Friedmen, J.H., & and Popescu, B. E. 2005.
Predictivelearning via rule ensembles (Technical Report),Stanford University.Fuchun Peng and Andrew McCullam, 2006.
Accurateinformation extraction from research papers usingconditional random fields, Information ProcessingManagement, 42(4):  963-979.John Lafferty, Andrew McCullam and FernandoPereira, 2001.
Conditional Random Fields: Probabil-istic models and for segmenting and labelingsequence data, Proceedings of internationalconference on Machine learning.Karen Sparck Jones and Julia Galliers.
1996.
EvaluatingNatural Language Processing Systems: An Analysisand Review.
Natural Language Engineering,4(2):175?190, Springer-Verlag.Lin, Chin-Yew.
2004.
ROUGE: a Package forAutomatic Evaluation of Summaries, Proceedings ofWorkshop on Text Summarization,  pp: 21--26, Bar-celona, Spain.Marie-Francine Moens, 2004.
An Evaluation Forum forLegal Information Retrieval Systems?
Proceedingsof the ICAIL-2003 Workshop on Evaluation of LegalReasoning and Problem-Solving Systems (pp.
18-24).
International        Organization for Artificial In-telligence and Law.Saravanan , M., Ravindran, B. and Raman, S. 2006.
AProbabilistic Approach to Multi-document summari-zation for generating a Tiled Sumamry, InternationalJournal of Computational Intelligence and Applica-tions, 6(2): 231-243, Imperial College Press.Saravanan , M., Ravindran, B. and Raman, S. 2006.Improving legal document Summarization usinggraphical models, Legal Knowledge and InformationSystem, JURIX 2006: The Nineteenth Annual Con-ference, Paris, IOS Press, PP.51-60.Siegal, Sidney and N.John Jr. Castellan.
1988.
Non-parametric statistics for the behavioral sciences,McGraw Hill,    Berkeley, CA.Simone Teufel and Marc Moens, 2002.
Summarizingscientific articles ?
experiments with relevance andrhetorical status, Association of ComputationalLinguistics, 28(4): 409-445.Yen-Yuan Yeh, Hao-Ren Ke, Wei-Pang Yang, andI-Heng Meng, 2005.
Text summarization using atrainable   summarizer and latent semantic analysis,Information processing management, 41(1):75-95.488
