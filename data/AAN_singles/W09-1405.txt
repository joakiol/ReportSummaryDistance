Proceedings of the Workshop on BioNLP: Shared Task, pages 37?40,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsBiomedical Event Extraction without Training DataAndreas Vlachos, Paula Buttery, Diarmuid O?
Se?aghdha, Ted BriscoeComputer LaboratoryUniversity of CambridgeCambridge, UKav308,pjb48,do242,ejb@cl.cam.ac.ukAbstractWe describe our system for the BioNLP 2009event detection task.
It is designed to be asdomain-independent and unsupervised as pos-sible.
Nevertheless, the precisions achievedfor single theme event classes range from 75%to 92%, while maintaining reasonable recall.The overall F-scores achieved were 36.44%and 30.80% on the development and the testsets respectively.1 IntroductionIn this paper we describe the system built for theBioNLP 2009 event detection and characterizationtask (Task 1).
The approach is based on the outputof a syntactic parser and standard linguistic process-ing, augmented by rules acquired from the develop-ment data.
The key idea is that a trigger connectedwith an appropriate argument along a path throughthe syntactic dependency graph forms an event.The goal we set for our approach was to avoidusing training data explicitly annotated for the taskand to preserve domain independence.
While weacknowledge the utility of supervision (in the formof annotated data) and domain knowledge, we be-lieve it is valuable to explore an unsupervised ap-proach.
Firstly, manually annotated data is ex-pensive to create and the annotation process itselfis difficult and unavoidably results in inconsisten-cies, even in well-explored tasks such as named en-tity recognition (NER).
Secondly, unsupervised ap-proaches, even if they fail to reach the performanceof supervised ones, are likely to be informative inidentifying useful features for the latter.
Thirdly, ex-ploring the potential of such a system may highlightwhat domain knowledge is useful and its potentialcontribution to performance.
Finally, preserving do-main independence allows us to develop and evalu-ate a system that could be used for similar tasks withminimal adaptation.The overall architecture of the system is as fol-lows.
Initiallly, event triggers are identified and la-belled with event types using seed terms.
Based onthe dependency output of the parser the triggers areconnected with candidate arguments using patternsidentified in the development data.
Anaphoric can-didate arguments are then resolved.
Finally, the trig-gers connected with appropriate arguments are post-processed to generate the final set of events.
Eachof these stages are described in detail in subsequentsections, followed by experiments and discussion.2 Trigger identificationWe perform trigger identification using the assump-tion that events are triggered in text either by verbalor nominal prdicates (Cohen et al, 2008).To build a dictionary of verbs and their associ-ated event classes we use the triggers annotated inthe training data.
We lemmatize and stem the trig-gers with the morphology component of the RASPtoolkit (Briscoe et al, 2006)1 and the Porter stem-mer2 respectively.
We sort the trigger stem - eventclass pairs found according to their frequency inthe training data and we keep only those pairs thatappear at least 10 times.
The trigger stems arethen mapped to verbs.
This excludes some rela-tively common triggers, which will reduce recall,but, given that we rely exclusively on the parser for1http://www.cogs.susx.ac.uk/lab/nlp/rasp/2http://www.tartarus.org/?martin/PorterStemmer37argument extraction, such triggers would be difficultto handle.
For verbs with more than one event classwe keep only the most frequent one.We consider the assumption that each verb de-notes a single event class to be a reasonable onegiven the restricted task domain.
It hinders us fromdealing with triggers denoting multiple event classesbut it simplifies the task so that we do not need anno-tated data.
While we use the training data triggers toobtain the list of verbs and their corresponding eventtypes, we believe that such lists could be obtained byclustering (Korhonen et al, 2008) with editing andlabelling by domain experts.
This is the only use ofthe training data we make in our system.During testing, using the tokenized text provided,we attempt to match each token with one of theverbs associated with an event type.
We performthis by relaxing the matching successively, using thetoken lemma, then stem, and finally allowing a par-tial match in order to deal with particles (so that e.g.co-transfect matches transfect).
This process returnssingle-token candidate triggers which, while they donot reproduce the trigger annotation, are likely to beadequate for event extraction.
We overgenerate trig-gers, since not all occurrences denote an event, ei-ther because they are not connected with appropriatearguments or because they are found in a non-eventdenoting context, but we expect to filter these at theargument extraction stage.3 Argument extractionGiven a set of candidate triggers, we attempt to con-nect them with appropriate arguments using the de-pendency graph provided by a parser.
In our ex-periments we use the domain-independent unlexi-calized RASP parser, which generates parses overthe part-of-speech (PoS) tags of the tokens generatedby an HMM-based tagger trained on balanced En-glish text.
While we expect that a parser adapted tothe biomedical domain may perform better, we wantto preserve the domain-independence of the systemand explore its potential.The only adjustment we make is to change thePoS tags of tokens that are part of a protein nameto proper names tags.
We consider such an adjust-ment domain-independent given that NER is avail-able in many domains (Lewin, 2007).
FollowingHaghighi et al(2005), in order to ameliorate pars-ing errors, we use the top-10 parses and return aset of bilexical head-dependent grammatical rela-tions (GRs) weighted according to the proportionand probability of the top parses supporting that GR.The GRs produced by the parser define directedgraphs between tokens in the sentence, and a partialevent is formed when a path that connects a triggerwith an appropriate argument is identified.
GR pathsthat are likely to generate events are selected usingthe development data, which does not contradict thegoals of our approach because we do not require an-notated training data.
Development data is alwaysneeded in order to build and test a system, and suchsupervision could be provided by a human expert,albeit not as easily as for the list of trigger verbs.The set of GR paths identified follow:VERB-TRIGGER ?subject?
ARGNOUN-TRIGGER ?iobj?
PREP ?dobj?
ARGNOUN-TRIGGER ?modifier?
ARGTRIGGER ?modifier?
PREP ?obj?
ARGTRIGGER ?passive subject?
ARGThe final system uses three sets of GR paths:one for Regulation events; one for Binding events;and one for all other events.
The difference be-tween these sets is in the lexicalization of the link-ing prepositions.
For example, in Binding eventsthe linking preposition required lexicalization sincebinds x to/with y denotes a correct event but notbinds x by y.
Binding events also required additionalGR paths to capture constructions such as binding ofx to y.
For Regulation events, the path set was fur-ther augmented to differentiate between theme andcause.
When the lexicalized GR pattern sets yieldedno events we backed-off to the unlexicalized patternset, which is identical for all event types.
In all GRpath sets, the trigger was unlexicalized and only re-stricted by PoS tag.4 Anaphora resolutionThe events and arguments identified in the parsedabstracts are post-processed in context to iden-tify protein referents for event arguments that areanaphoric (e.g., these proteins, its phosphorylation)or too complex to be extracted directly from thegrammatical relations (phosphorylation of cellularproteins , notably phospholipase C gamma 1).
The38anaphoric linking is performed by a set of heuris-tic rules manually designed to capture a number ofcommon cases observed in the development dataset.A further phenomenon dealt with by rules is coref-erence between events, for example in The expres-sion of LAL-mRNA is induced.
This induction is de-pendent on.
.
.
where the Induction event describedby the first sentence is the same as the theme of theRegulation event in the second and should be giventhe same event index.
The development of the post-processing rules favoured precision over recall, butthe low frequency of each case considered meansthat some overfitting to the development data mayhave been unavoidable.5 Event post-processingAt the event post-processing stage, we form com-plete events considering the trigger-argument pairsproduced at the argument extraction stage whose ar-guments are resolved (possibly using anaphora res-olution) either to a protein name or to a candidatetrigger.
The latter are considered only for regula-tion event triggers.
Furthermore, regulation eventtrigger-argument pairs are tagged either as theme orcause at the argument extraction stage.For each non-regulation trigger-argument pair, wegenerate a single event with the argument marked astheme.
Given that we are dealing only with Task1, this approach is expected to deal adequately withall event types except Binding, which can have mul-tiple themes.
Regulation events are formed in thefollowing way.
Given that the cause argument isoptional, we generate regulation events for trigger-argument pairs whose argument is a protein name ora trigger that has a formed event.
Since regulationevents can have other regulation events as themes,we repeat this process until no more events can beformed.
Occasionally, the use of multiple parses re-sults in cycles between regulation triggers which areresolved using the weighted GR scores.
Then, we at-tach any cause arguments that share the same triggerwith a formed regulation event.In the analysis performed for trigger identificationin Section 2, we observed that certain verbs wereconsistently annotated with two events (namelyoverexpress and transfect), a non-regulation eventand a regulation event with the former event as itstheme.
For candidate triggers that were recognizeddue to such verbs, we treat them as non-regulationevents until the post-processing stage where we gen-erate two events.6 Experiments - DiscussionWe expected that our approach would achieve highprecision but relatively low recall.
The evaluationof our final submissions on the development and testdata (Table 1) confirmed this to a large extent.
Forthe non-regulation event classes excluding Binding,the precisions achieved range from 75% to 92% inboth development and test data, with the exceptionof Transcription in the test data.
Our approach ex-tracts Binding events with a single theme, more suit-ably evaluated by the Event Decomposition evalua-tion mode in which a similar high precision/low re-call trend is observed, albeit with lower scores.Of particular interest are the event classes forwhich a single trigger verb was identified, namelyTranscription, Protein catabolism and Phosphoryla-tion, which makes it easier to identify the strengthsand weaknesses of our approach.
For the Phos-phorylation class, almost all the triggers that wereannotated in the training data can be captured us-ing the verb phosporylate and as a result, the per-formances achieved by our system are 70.59% and60.63% F-score on the development and test data re-spectively.
The precision was approximately 78% inboth datasets, while recall was lower due to parsererrors and unresolved anaphoric references.
For theProtein catabolism class, degrade was identified asthe only trigger verb, resulting in similar high preci-sion but relatively lower recall due to the higher lex-ical variation of the triggers for this class.
For theTranscription class we considered only transcribeas a trigger verb, but while the performance on thedevelopment data is reasonable (55%), the perfor-mance on the test data is substantially lower (20%).Inspecting the event triggers in the training data re-veals that some very common triggers for this classeither cannot be mapped to a verb (e.g., mrna) or arecommonly used as triggers for other event classes.A notable case of the latter type is the verb express,which, while mostly a Gene Expressions trigger, isalso annotated as Transcription more than 100 timesin the training data.
Assuming that this is desirable,39Development TestEvent Class recall precision fscore recall precision fscoreLocalization 45.28 92.31 60.76 25.86 90.00 40.18Binding 12.50 24.41 16.53 12.68 31.88 18.14Gene expression 52.25 80.79 63.46 45.57 75.81 56.92Transcription 42.68 77.78 55.12 12.41 56.67 20.36Protein catabolism 42.86 81.82 56.25 35.71 83.33 50.00Phosphorylation 63.83 78.95 70.59 49.63 77.91 60.63Event Total 39.03 65.97 49.05 33.16 68.15 44.61Regulation 20.12 50.75 28.81 9.28 36.49 14.79Positive regulation 16.86 48.83 25.06 11.39 38.49 17.58Negative regulation 11.22 36.67 17.19 6.86 36.11 11.53Regulation Total 16.29 47.06 24.21 9.98 37.76 15.79Total 26.55 58.09 36.44 21.12 56.90 30.80Binding (decomposed) 26.92 66.14 38.27 18.84 54.35 27.99Table 1: Performance analysis on development and test data using Approximate Span/Partial Recursive Matching.a more appropriate solution would need to take con-text into account.Our performance on the regulation events is sub-stantially lower in both recall and precision.
Thisis expected, as they rely on the extraction of non-regulation events.
The variety of lexical triggers isnot causing the drop in performance though, sinceour system performed reasonably well in the GeneExpression and Localization classes which havesimilar lexical variation.
Rather it is due to the com-bination of the lexical variation with the requirementto make the distinction between the theme and op-tional cause argument, which cannot be handled ap-propriately by the small set of GR paths employed.The contribution of anaphora resolution to oursystem is limited as it relies on the argument ex-traction stage which, apart from introducing noise,is geared towards maintaining high precision.
Over-all, it contributes 22 additional events on the de-velopment set, of which 14 out of 16 are correctnon-regulation events.
Of the remaining 6 regula-tion events only 2 were correct.
Similar trends wereobserved on the test data.7 Conclusions - Future workWe described an almost unsupervised approach forthe BioNLP09 shared task on biomedical event ex-traction which requires only a dictionary of verbsand a set of argument extraction rules.
Ignoring trig-ger spans, the performance of the approach is parser-dependent and while we used a domain-independentparser in our experiments we also want to explorethe benefits of using an adapted one.The main weakness of our approach is the han-dling of events with multiple arguments and the dis-tinctions between them, which are difficult to dealwith using simple unlexicalized rules.
In our fu-ture work we intend to explore semi-supervised ap-proaches that allow us to acquire more complexrules efficiently.ReferencesTed Briscoe, John Carroll, and Rebecca Watson.
2006.The second release of the RASP system.
In Proceed-ings of the COLING/ACL Interactive presentation ses-sions, pages 77?80.Kevin B. Cohen, Martha Palmer, and Lawrence Hunter.2008.
Nominalization and alternations in biomedicallanguage.
PLoS ONE, 3(9).Aria Haghighi, Kristina Toutanova, and Chris Manning.2005.
A Joint Model for Semantic Role Labeling.
InProceedings of CoNLL-2005: Shared Task.Anna Korhonen, Yuval Krymolowski, and Nigel Collier.2008.
The choice of features for classification of verbsin biomedical texts.
In Proceedings of Coling.Ian Lewin.
2007.
BaseNPs that contain gene names:domain specificity and genericity.
In Proceedings ofthe ACL workshop BioNLP: Biological, translational,and clinical language processing, pages 163?170.40
