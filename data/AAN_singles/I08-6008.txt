A Document Graph Based Query Focused Multi-Document SummarizerSibabrata Paladhi                                       Sivaji BandyopadhyayDepartment of Computer Sc.
& Engg.
Department of Computer Sc.
& Engg.Jadavpur University, India                              Jadavpur University, Indiasibabrata_paladhi@yahoo.com                        sivaji_cse_ju@yahoo.comAbstractThis paper explores the research issue andmethodology of a query focused multi-document summarizer.
Considering its pos-sible application area is Web, the computa-tion is clearly divided into offline andonline tasks.
At initial preprocessing stagean offline document graph is constructed,where the nodes are basically paragraphs ofthe documents and edge scores are definedas the correlation measure between thenodes.
At query time, given a set of key-words, each node is assigned a query de-pendent score, the initial graph is expandedand keyword search is performed over thegraph to find a spanning tree identifyingrelevant nodes satisfying the keywords.Paragraph ordering of the output summaryis taken care of so that the output looks co-herent.
Although all the examples, shownin this paper are based on English language,we show that our system is useful in gener-ating query dependent summarization fornon- English languages also.
We also pre-sent the evaluation of the system.1 IntroductionWith the proliferation of information in the Inter-net, it is becoming very difficult for users to iden-tify the exact information.
So many sites are pro-viding same piece of information and a typicalquery based search in Google results in thousandsof links if not million.
Web Search engines gener-ally produce query dependent snippets for eachresult which help users to explore further.
Anautomated query focused multi-document summar-izer, which will generate a query based shortsummary of web pages will be very useful to get aglimpse over the complete story.
Automated multi-document summarization has drawn much atten-tion in recent years.
Most multi-document sum-marizers are query independent, which producemajority of information content from multipledocuments using much less lengthy text.
Each ofthe systems fall into two different categories: eitherthey are sentence extraction based where they justextract relevant sentences and concatenate them toproduce summary or they fuse information frommultiple sources to produce a coherent summary.In this paper, we propose a query focused multi-document summarizer, based on paragraph extrac-tion scheme.
Unlike traditional extraction basedsummarizers which do not take into considerationthe inherent structure of the document, our systemwill add structure to documents in the form ofgraph.
During initial preprocessing, text fragmentsare identified from the documents which constitutethe nodes of the graph.
Edges are defined as thecorrelation measure between nodes of the graph.We define our text fragments as paragraph ratherthan sentence with the view that generally a para-graph contains more correlated informationwhereas sentence level extraction might lead toloss of some coherent information.Since the system produces multi-documentsummary based on user?s query, the response timeof the system should be minimal for practical pur-pose.
With this goal, our system takes followingsteps: First, during preprocessing stage (offline) itperforms some query independent tasks like identi-fying seed summary nodes and constructing graphover them.
Then at query time (online), given a setof keywords, it expands the initial graph and per-forms keyword search over the graph to find aspanning tree identifying relevant nodes (para-graphs) satisfying the keywords.
The performanceof the system depends much on the identificationof the initial query independent nodes (seed nodes).Although, we have presented all the examples inthe current discussion for English language only,we argue that our system can be adapted to work inmultilingual environment (i.e.
Hindi, Bengali,Japanese etc.)
with some minor changes in imple-mentation of the system like incorporating lan-guage dependent stop word list, stemmer, WodrNetlike lexicon etc.In section 2, related works in this field is pre-sented.
In section 3 the overall approach is de-scribed.
In section 4 query independent preprocess-ing steps are explained.
In section 5 query depend-ent summary generation and paragraph orderingscheme is presented.
Section 6 presents the evalua-tion scheme of the system.
In section 7 we discusshow our system can be modified to work in multi-lingual scenario.
In section 8 we have drawn con-clusion and discussed about future work in thisfield.2 Related WorkA lot of research work has been done in the do-main of multi-document summarization (bothquery dependent/independent).
MEAD (Radev etal., 2004) is centroid based multi-document sum-marizer which generates summaries using clustercentroids produced by topic detection and trackingsystem.
NeATS (Lin and Hovy, 2002) selects im-portant content using sentence position, term fre-quency, topic signature and term clustering.
XDoX(Hardy et al, 2002) identifies the most salientthemes within the document set by passage cluster-ing and then composes an extraction summary,which reflects these main themes.Graph based methods have been proposed forgenerating query independent summaries.
Web-summ (Mani and Bloedorn, 2000) uses a graph-connectivity model to identify salient information.Zhang et al(2004) proposed the methodology ofcorrelated summarization for multiple news arti-cles.
In the domain of single document summariza-tion a system for query-specific document summa-rization has been proposed (Varadarajan and Hris-tidis, 2006) based on the concept of documentgraph.In this paper, the graph based approach has beenextended to formulate a framework for generatingquery dependent summary from related  multipledocument set describing same event.3 Graph Based ModelingThe proposed graph based multi-document sum-marization method consists of following steps: (1)The document set D = {d1,d2, ?
dn} is processedto extract text fragments, which are paragraphs inour case as it has been discussed earlier.
Here, weassume that the entire document in a particular setare related i.e.
they describe the same event.
Somedocument clustering techniques may be adopted tofind related documents from a large collection.Document clustering is out of the scope of our cur-rent discussion and is itself a research interest.
Letfor a document di, the paragraphs are{pi1,pi2,?pim}.
But the system can be easily modi-fied to work with sentence level extraction.
Eachtext fragment becomes a node of the graph.
(2)Next, edges are created between nodes across thedocument where edge score represents the degreeof correlation between inter documents nodes.
(3)Seed nodes are extracted which identify the rele-vant paragraphs within D and a search graph isbuilt offline to reflect the semantic relationshipbetween the nodes.
(4) At query time, each node isassigned a query dependent score and the searchgraph is expanded.
(5) A query dependent multi-document summary is generated from the searchgraph which is nothing but constructing a totalminimal spanning tree T (Varadarajan and Hristi-dis, 2006).
For a set of keywords Q = {q1,q2, .. qn} ,T is total if ?q?Q, T consists of at least one nodesatisfying q and T is  minimal if no node can beremoved from T while getting the total T.4 Building Query Independent Compo-nentsMainly there are two criteria for the performanceevaluation of such systems: First it?s accuracy i.e.the quality of output with respect to specific que-ries and next of course the turn around time i.e.,how fast it can produce the result.
Both are veryimportant aspects of such system, and we willshow how these aspects are taken care of in oursystem.
Runtime of such system greatly dependson how well the query independent graph is con-structed.
At one extreme, offline graph can be builtconnecting all the nodes from each of the docu-ments, constituting a total document graph.
Butkeyword search over such large graph is time con-suming and practically not plausible.
On the otherhand, it is possible to select query specific nodes atruntime and to create a graph over those nodes.
Butif the number of such nodes is high, then calculat-ing similarity scores between all the nodes willtake large computing time, thus resulting in slowerperformance.We will take an intermediate approach to attackthe problem.
It can be safely assumed that signifi-cant information for a group of keywords can befound in ?relevant/topic paragraphs?
of the docu-ments.
So, if relevant/topic nodes can be selectedfrom document set D during offline processing,then the significant part of the search graph can beconstructed offline which greatly reduce the onlineprocessing time.
For example, if a user wants tofind the information about the IBM Hindi speechrecognition system, then the keywords are likely tobe {IBM, speech recognition, accuracy}.
For a setof news articles about this system, the topic para-graphs, identified offline, naturally satisfy first twokeywords and theoretically, they are the most in-formative paragraphs for those keywords.
The lastterm ?accuracy?
(relevant for accuracy of the sys-tem) may not be satisfied by seed nodes.
So, at runtime, the graph needs to be expanded purposefullyby including nodes so that the paragraphs, relevantto ?accuracy of the system?
are included.4.1 Identification of Seed/ Topic NodesAt the preprocessing stage, text is tokenized, stopwords are eliminated, and words are stemmed(Porter, 1980).
The text in each document is splitinto paragraphs and each paragraph is representedwith a vector of constituent words.
If we considerpair of related document, then the inter documentgraph can be represented as a set of nodes in theform of bipartite graph.
The edges connect twonodes corresponding to paragraphs from differentdocuments.
The similarity between two nodes isexpressed as the edge weight of the bipartite graph.Two nodes are related if they share common words(except stop words) and the degree of relationshipcan be measured by adapting some traditional IRformula (Varadarajan and Hristidis, 2006).
( ( ( ( ) , ) ( ( ) , ) ) .
( ) )( ) ( ( ) ) ( ( ) )t f t u w t f t v w id f wS c o r e es iz e t u s i z e t v+=+?Where ( , )tf d w  is number of occurrence of w ind, ( )id f w is the inverse of the number of docu-ments containing w, and ( )size d is the size of thedocuments in words.
The score can be accuratelyset if stemmer and lexicon are used to match theequivalent words.
With the idea of page rankingalgorithms, it can be easily observed that a para-graph in a document is relevant if it is highly re-lated to many relevant paragraphs of other docu-ment.
If some less stringent rules are adopted, thena node from a document is selected as seed/topicnode if it has high edge scores with nodes of otherdocument.
Actually for a particular node, totaledge score is defined as the sum of scores of all outgoing edges from that node.
The nodes with highertotal edge scores than some predefined thresholdare included as seed nodes.
In Figure 1. correlationbetween two news articles is shown as a bipartitegraph.But the challenge for multi-document summari-zation is that the information stored in differentdocuments inevitably overlap with each other.
So,before inclusion of a particular node (paragraph), ithas to be checked whether it is being repeated ornot.
Two paragraphs are said to be similar if theyshare for example, 70% words (non stop words) incommon.Figure 1.
A bipartite graph representing correlationamong two news articles on same event.4.2 Offline Construction of Search GraphAfter detection of seed/topic nodes a search graphis constructed.
For nodes, pertaining to differentdocuments, edge scores are already calculated, butfor intra document nodes, edge scores are calcu-lated in the similar fashion as said earlier.
Since,highly dense graph leads to highersearch/execution time, only the edges having edgescores well above the threshold value might beconsidered.
The construction of query independentpart of the search graph completes the offline proc-essing phase of the system.5 Building Query Dependent Compo-nentsAt query time, first, the nodes of the already con-structed search graph are given a query dependentscore.
The score signifies the relevance of theparagraph with respect to given queries.
Duringevaluation if it is found that any keyword is notsatisfied by the seed nodes, then system goes backto individual document structure and collects rele-vant nodes.
Finally, it expands the offline graph byadding those nodes, fetched from individual docu-ments.
Next, the expanded search graph is proc-essed to find the total minimum spanning tree Tover the graph.5.1 Expanding Search GraphWhen query arrives, system evaluates nodes of theoffline search graph and computes query depend-ent score.
This computation is based on rankingprincipals from IR community.
The most popularIR ranking is okapi equation (Varadarajan andHristidis, 2006) which is based on tf-idf principle.1 1 33, 10 .5 ( ).
( 1).ln .
.0 .5 ( (1 ) )t Q dN df k tf k q tfd ld f k q tfk b b tfavd l+??
+ ++ +?
+ +?tf is the term?s frequency in document, qtf is term?sfrequency in the query, N is the total no.
of docu-ments in collection, df is the number of documentsthat contain the term, dl is the document length(number of words), avdl is the average documentlength and k1 (1.0 ?
2.0), b (0.75), k3 (0 -1000) areconstants.During node score computation, the system in-telligently partitions the query set Q into two parts.One part consists of qi?s which are satisfied by atleast one node from offline search graph.
The otherpart consists of qi?s which are not satisfied by anynode from offline search graph.
The system thencomputes query dependent scores for the nodes ofall the individual documents for the unsatisfiedkeyword set and relevant nodes (having scoreabove threshold) are added to the search graph.Edge scores are computed only for edges connect-ing newly added nodes with the existing ones andbetween the new nodes.
In this way, the offlinegraph is expanded by adding some query depend-ent nodes at runtime.
Query dependent scoring canbe made faster using a full text indexing which is amapping Ki ?
(Di , Ni); where Ki?s are contentwords (i.e., not stop words)and Di?s and Ni?s arerespectively the document ids and the node idswithin the document set.
Since, the node score iscalculated at runtime, it needs to be accelerated.Thus a full text index developed offline will be ofgreat help.5.2 Summary GenerationSummary generation is basically a keyword searchtechnique in the expanded search graph.
This is tomention that the search technique discussed here isbasically based on AND semantic, i.e.
it requiresall the keywords to be present in the summary, butthe algorithm can be modified to take care of ORsemantic also.
Keyword search in graph structureis itself a research topic and several efficient algo-rithms are there to solve the problem.
DBXplorer(Agrawal et al, 2002), BANKS (Bhalotia et al,2002), are popular algorithms in this field whichconsider relational database as graph and devisealgorithms for keyword based search in the graph.Finally, Varadarajan and Hristidis (2006) has pro-posed Top-k Enumeration and MultiResultExpand-ing search for constructing total minimum span-ning tree over a document graph.
Any of the abovepopular algorithms can be adapted to use withinour framework.In our system we have used a search algorithmwhich finds different combinations of nodes thatrepresent total spanning tree.
For each of the com-bination we compute score of the summary basedon some IR principle (Varadarajan and Hristidis,2006).
Then we take the one having best score(minimal in our case).
If the graph is not too dense,then the response time will be small enough.
Theequation given below is used to compute the scoreof individual spanning tree T.1 1s c o r es c o r e s c o r ee Tn TT a bne?
?= +?
?Where scoreT the score of the spanning tree, e andn is are edge and node of T respectively, scoreeand scoren  are edge score and individual nodescore respectively.
a and b are non zero positiveconstants in the range of [0 ?
1].
For a particularsearch graph, it is possible to find many total span-ning trees, having different summary scores.
In oursystem, the summary with the best score is consid-ered.In Figure 2 two sample news stories are shownalong with system identified seed nodes, shown inbold.
A query based summary from that relateddocument set is shown in Figure 3.5.3 Paragraph Ordering SchemeIn the previous sections, the techniques for genera-tion of summary nodes have been discussed.
Here,we will investigate the method for ordering theminto a coherent text.
In case of single documentsummarization, sentence/paragraph ordering isdone based on the position of extracted paragraphs/sentences in the original document.
But in multi-document scenario, the problem is non trivial sinceinformation is extracted from different documentsand no single document can provide ordering.
Be-sides, the ordering of information in two differentdocuments may be significantly varying becauseFigure 2.
Paragraphs of two news articles with five extracted seed/ topic paragraphs (in bold).
Un-derlined paragraphs are added later during graph expansion phase.Software major IBM has developed a speech recognition technology in Hindi which would help physically challenged andless literate Hindi speakers access information through a variety of systems.
[Doc-2, Para - 0 ]Besides, the technology could also enable C-DAC to ensure a high level of accuracy in Hindi translation in a number of do-mains like administration, finance, agriculture and the small-scale industry.
[Doc-1, Para-5]A spellchecker to correct spoken-word errors also enhances the accuracy of the system.
[Doc-2, Para - 4 ]Figure 3.
Automatic summary based on {speech recognition, accuracy, spellchecker} queryP0: Software giant IBM has developed a speech recognitionsoftware in Hindi.P1 : The company hopes that this development will helpphysically challenged and less literate Hindi speakers toaccess information using a variety of applications.P2 : The Desktop Hindi Speech Recognition Technologydeveloped by the IBM India Software Lab in collabora-tion with Centre for Development of Advanced Com-puting would provide a natural interface for human-computer interaction.P3 : The new IBM technology could help to provide a natu-ral interface for human-computer interaction.P4: According to Dr. Daniel Dias, Director, IBM IndianResearch Laboratory, the technology which helps tran-scribe continuous Hindi speech instantly into text form,could find use in a variety of appli In Figure 1. corre-lation between two news articles is shownas a bipartite graph.
cations like voice-enabledATMs, car navigation systems, banking, telecom, railways,and airlines.P5: Besides, the technology could also enable C-DAC toensure a high level of accuracy in Hindi translation in anumber of domains like administration, finance, agri-culture and the small-scale industry.P6: The IBM Desktop Hindi Speech Recognition softwareis capable of recognizing over 75,000 Hindi words withdialectical variations, providing an accuracy of 90 to 95%.P7: What?s more; this software also has an integrated spell-checker that corrects spoken-word errors, enhancing theaccuracy to a great extent.P8:  The Desktop Hindi Speech Recognition Technologyalso integrates a number of user-friendly features such asthe facility to convert text to digits and decimals, date andcurrency format, and into fonts which could be imported toany Windows-based application.P9: ?IBM believes in taking high-end research to the benefitof the masses and bridging the digital divide through afaster diffusion process,?
concluded Dias.P0: Software major IBM has developed a speech recog-nition technology in Hindi which would help physicallychallenged and less literate Hindi speakers access in-formation through a variety of systems.P1 : Called the Desktop Hindi Speech Recognition technol-ogy, this software was developed by the IBM India Soft-ware Lab jointly with the Centre for Development of Ad-vanced Computing.P2 : The technology, which helps transcribe continuousHindi speech instantly into text form, could find use in avariety of applications like voice-enabled ATMs, carnavigation systems, banking, telecom, railways andairlines, said Dr Daniel Dias, Director, IBM India Re-search Laboratory.P3 : The system can recognize more than 75,000 Hindiwords with dialectical variations, providing an accuracylevel of 90-95 per cent, he said.P4:  A spellchecker to correct spoken-word errors alsoenhances the accuracy of the system.P5:  The technology also has integrated many user-friendly features such as facility to convert text to digitsand decimals, date and currency format, and into fontswhich could be imported to any windows-based applica-tion.P6: "IBM believes in taking high-end research to the benefitof the masses and bridging the digital divide through afaster diffusion process", Dias said.P7: The technology also would enable C-DAC to ensurehigh-level accuracy in Hindi translation in a host of do-mains, including administration, finance, agriculture andsmall scale industry.the writing styles of different authors are different.In case of news event summarization, chronologi-cal ordering is a popular choice which considersthe temporal sequence of information pieces, whendeciding the ordering process.In this paper, we will propose a scheme of or-dering which is different from the above two ap-proaches in that, it only takes into considerationthe semantic closeness of information pieces(paragraphs) in deciding the ordering among them.First, the starting paragraph is identified which isthe paragraph with lowest positional rankingamong selected ones over the document set.
Nextfor any source node (paragraph) we find the sum-mary node that is not already selected and have(correlation value) with the source node.
This nodewill be selected as next source node in ordering.This ordering process will continue until the nodesare totally ordered.
The above ordering schemewill order the nodes independent of the actual or-dering of nodes in the original document, thuseliminating the source bias due to individual writ-ing style of human authors.
Moreover, the schemeis logical because we select a paragraph for posi-tion p at output summary, based on how coherent itis with the (p-1)th paragraph.6 EvaluationEvaluation of summarization methods is generallyperformed in two ways.
Evaluation measure basedon information retrieval task is termed as the ex-trinsic method, while the evaluation based on userjudgments is called the intrinsic measure.
Weadopted the latter, since we concentrated more onuser?s satisfaction.
We measure the quality of out-put based on the percentage of overlap of systemgenerated output with the manual extract.
Salton etal (1997) observed that an extract generated by oneperson is likely to cover 46% of the informationthat is regarded as most important by another per-son.
Mitra et.
al.
(1998) proposed an interestingmethod for evaluation of paragraph based auto-matic summarization and identified the followingfour quality-measures ?
Optimistic (O), Pessimistic(P), Intersection (I) and Union (U) based evalua-tion.
For evaluation purpose, we identify differentrelated document set (D) from different domainslike technical, business etc and keyword (query)list for each domain.
Users are asked to manuallyprepare the multi-document summarization basedon the given queries.
They prepared it by markingrelevant paragraphs over D. Based on the excerptsprepared by the users; the above scores are calcu-lated as O: Percentage overlap with that manualextract for which the number of common para-graphs is highest, P: Percentage overlap with thatmanual extract for which the number of commonparagraphs is lowest; I: Percentage overlap withthe intersection of manual extracts; U: Percentageoverlap with the union of manual extracts.
The re-sults are shown in Table 1.
A comparative surveyof quality measures for the set of articles is shownin Figure 3.Table 1.
Evaluation scoreD Omeasure Pmeasure Imeasure Umeasurearticle1&article244.4 27 33.3 66.6article3&article475 60 50 100article5&article650 35.5 25 66article7&article845.5 28.7 33.3 56.4O -  M easure010203040506070801 2 3 4Dat a SetScoreScoreScoreScoreP - Measure0204060801 2 3 4Data SetScoreFigure 3.
Comparative measure scores for setof articles7 Baseline Approach to MultilingualSummarizationOur baseline approach to multilingual multidocu-ment summarization is to apply our English basedmulti-document summarization system to othernon-English languages like Hindi, Bengali, Japa-nese etc.
We have initially implemented the systemfor English language only, but it can be modifiedto work in multilingual scenario also.
To workwith other languages, the system requires somelanguage dependent tools for that particular lan-guage:1) A stop word list of that language is required be-cause they have no significance in finding similar-ity between the paragraphs and need to be removedduring initial preprocessing stage.2) A language dependent stemmer is required.
Inmost of the languages, stemmer is yet to be devel-oped.
Another problem is that suffix stripping isnot the only solution for all languages becausesome languages have affix, circumfix etc.
in theirinflected form.
A morphological analyzer to findthe root word may be used for those languages.3) A lexicon for that language is required to matchthe similar words.
For English, WordNet is widelyavailable.
For other languages also, similar type oflexicons are required.If these tools are available then our system canbe tuned to generate query dependent multilingualmulti-document summary.8 Conclusion and Future WorkIn this work we present a graph based approach forquery dependent multi-document summarizationsystem.
Considering its possible application in theweb document, we clearly divided the computationinto two segments.
Extraction of seed/topic sum-mary nodes and construction of offline graph is apart of query independent computation.
At querytime, the precomputed graph is processed to extractthe best multi-document summary.
We have testedour algorithm with news articles from differentdomains.
The experimental results suggest that ouralgorithm is effective.
Although we experimentedwith pair of articles, the proposed algorithm can beimproved to handle more than two articles simul-taneously.The important aspect of our system is that it canbe modified to compute query independent sum-mary which consists of topic nodes, generated dur-ing preprocessing stage.
The paragraph orderingmodule can be used to define ordering amongthose topic paragraphs.
Another important aspect isthat our system can be tuned to generate summarywith custom size specified by users.
The spanningtree generation algorithm can be so modified that itproduces not only total spanning tree but also takescare of the size requirement of user.
Lastly, it isshown that our system can generate summary forother non-English documents also if some lan-guage dependent tools are available.The performance of our algorithm greatly de-pends on quality of selection of topic nodes.
So ifwe can improve the identification of topic para-graphs and shared topics among multiple docu-ments it would surely enhance the quality of oursystem.9 ReferencesA.
Singhal , M. Mitra, and C. Buckley.
1997.
AutomaticText Summarization by Paragraph Extraction.
Pro-ceedings of ACL/EACL Workshop.C.-Y.
Lin and E.H. Hovy.
2002.
From Single to Multi-document Summarization: A Prototype System andits Evaluation.
Proceedings of ACL: 457?464.I -  M easure01020304050601 2 3 4Dat a SetScoreU  -  M easure0204060801001201 2 3 4Dat a SetScoreD.R.
Radev, H. Jing, M. Sty?
and D. Tam.
2004.
Cen-troid-based summarization of multiple documents.Information Processing and Management,Vol.40:919?938.G.
Salton , A. Singhal , M. Mitra, and C. Buckley.
1997.Automatic text structuring and summarization.
In-formation Processing and Management: Vol.
33, No.2: 193-207.G.
Bhalotia, C. Nakhe, A. Hulgeri, S. Chakrabarti andS.Sudarshan.
2002.
Keyword Searching and Brows-ing in Databases using BANKS.
Proceedings ofICDE : 431-440.H.
Hardy, N. Shimizu, T. Strzalkowski, L. Ting, G. B.Wise and X. Zhang.
2002.
Cross-document summari-zation by concept classification.
Proceedings ofSIGIR.02: 65-69 .I.
Mani and E. Bloedorn.
2000.
Summarizing Similari-ties and Differences Among Related Documents.
In-formation Retrieval, Vol.
1(1): 35-67.M.
Porter.
1980.
An algorithm for suffix stripping.
Pro-gram, 14(3):130?137.R.
Varadarajan,.
V. Hristidis.
2006.
A system for query-specific document summarization.
Proceedings ofCIKM 2006: 622-631.S.
Agrawal, S. Chaudhuri, and G. Das.2002.
DBXplorer:A System for Keyword-Based Search over RelationalDatabases.
Proceedings of ICDE: 5-16.Y.
Zhang, X. Ji, C. H. Chu, and H. Zha.
2004.
Correlat-ing Summarization of Multisource News with K-Way Graph Biclustering.
SIGKDD Explorations6(2): 34-42.
