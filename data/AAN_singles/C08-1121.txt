Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 961?968Manchester, August 2008Coreference Systems based on Kernels MethodsYannick VersleySFB 441University of Tu?bingenversley@sfs.uni-tuebingen.deAlessandro MoschittiDISIUniversity of Trentomoschitti@disi.unitn.itMassimo PoesioDISIUniversity of Trentomassimo.poesio@unitn.itXiaofeng YangData Mining DepartmentInstitute for Infocomm Researchxiaofengy@i2r.a-star.edu.sgAbstractVarious types of structural information -e.g., about the type of constructions inwhich binding constraints apply, or aboutthe structure of names - play a central rolein coreference resolution, often in combi-nation with lexical information (as in ex-pletive detection).
Kernel functions ap-pear to be a promising candidate to capturestructure-sensitive similarities and com-plex feature combinations, but care is re-quired to ensure they are exploited in thebest possible fashion.
In this paper wepropose kernel functions for three subtasksof coreference resolution - binding con-straint detection, expletive identification,and aliasing - together with an architec-ture to integrate them within the standardframework for coreference resolution.1 IntroductionInformation about coreference relations?i.e.,which noun phrases are mentions of the sameentity?has been shown to be beneficial in a greatnumber of NLP tasks, including informationextraction (McCarthy and Lehnert 1995), textplanning (Barzilay and Lapata 2005) and sum-marization (Steinberger et al 2007).
However,the performance of coreference resolvers onunrestricted text is still quite low.
One reasonfor this is that coreference resolution requires agreat deal of information, ranging from stringmatching to syntactic constraints to semanticknowledge to discourse salience information toc?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.full common sense reasoning (Sidner 1979; Hobbs1978, 1979; Grosz et al 1995; Vieira and Poesio2000; Mitkov 2002).
Much of this informationwon?t be available to robust coreference resolversuntil better methods are found to represent andencode common sense knowledge; but part ofthe problem is also the need for better methodsto encode information that is in part structural,in part lexical.
Enforcing binding constraints?e.g., ruling out Peter as antecedent of him in (1a)requires recognizing that the anaphor occurs in aparticular type of construction (Chomsky 1981;Lappin and Leass 1994; Yang et al 2006) whoseexact definition however has not yet been agreedupon by linguists (indeed, it may only be definablein a graded sense (Sturt 2003; Yang et al 2006)),witness examples like (1b).
Parallelism effects area good example of structural information inducingpreferences rather than constraints.
Recognizingthat It in examples such as (1c,d) are expletivesrequires a combination of structural informationand lexical information (Lappin and Leass 1994;Evans 2001).
But some sort of structure alsounderlies our interpretation of other types ofcoreference: e.g., knowledge about the structureof names certainly plays a role in recognizingthat BJ Habibie is a possible antecedent for Mr.Habibie.
(1) a. John thinks that Peter hates him.b.
John hopes that Jane is speaking only tohimself.c.
It?s lonely here.d.
It had been raining all day.The need to capture such information suggestsa role for kernel methods (Vapnik 1995) in coref-erence resolution.
Kernel functions make it pos-sible to capture the similarity between structures961without explicitly enumerating all the substruc-tures, and have therefore been shown to be a vi-able approach to feature engineering for naturallanguage processing for any task in which struc-tural information plays a role, e.g.
(Collins andDuffy 2002; Zelenko et al 2003; Giuglea and Mos-chitti 2006; Zanzotto and Moschitti 2006; Mos-chitti et al 2007).
Indeed, they have already beenused in NLP to encode the type of structural in-formation that plays a role in binding constraints(Yang et al 2006); however, the methods used inthis previous work do not make it possible to ex-ploit the full power of kernel functions.
In thiswork, we extend the use of kernel functions forcoreference by designing and testing kernels forthree subtasks of the coreference task:?
Binding constraints?
Expletive detection?
Aliasingand developing distinct classifiers for each of thesetasks.
We show that our developed kernels producehigh accuracy for both distinct classifiers for thesesubtasks as well as for the complete coreferencesystem.In the remainder: Section 2, briefly describesthe basic kernel functions that we used; Section3 illustrates our new kernels for expletive, bindingand name alias detection along with a coreferencecontext kernel; Section 4 reports the experimentson individual classifiers on expletives, binding andnames whereas Section 5 shows the results on thecomplete coreference task; Finally, Section 6 de-rives the conclusions.2 Kernel for Structured DataWe used three kernel functions in this work: theString Kernel (SK) proposed in Shawe-Taylor andCristianini (2004) to evaluate the number of sub-sequences between two sequences, the SyntacticTree Kernel (STK; see Collins and Duffy 2002)which computes the number of syntactic tree frag-ments and the Partial Tree Kernel (PTK; see Mos-chitti 2006) which provides a more general repre-sentation of trees in terms of tree fragments.
Wediscuss each in turn.2.1 String Kernels (SK)The string kernels that we consider count the num-ber of substrings shared by two sequences contain-ing gaps, i.e.
some of the characters of the originalNPD NacatNPD NNPD NaNPD NNPD NVPVbroughtacatcatNPD NVPVacatNPD NVPVNcatDaVbroughtNMary?Figure 1: A tree with some of its STFs .NPD NVPVbroughtacatNPD NVPVacatNPD NVPacatNPD NVPaNPDVPaNPDVPNPNVPNPNNP NPD N DNP?VPFigure 2: A tree with some of its PTFs.string are skipped.
Gaps penalize the weight asso-ciated with the matched substrings.
More in detail,(a) longer subsequences receive lower weights.
(b) Valid substrings are sequences of the originalstring with some characters omitted, i.e.
gaps.
(c)Gaps are accounted by weighting functions and (d)symbols of a string can also be whole words, i.e.the word sequence kernel Cancedda et al (2003).2.2 Tree KernelsThe main idea underlying tree kernels is to com-pute the number of common tree fragments be-tween two trees without explicitly considering thewhole fragment space.
The type of fragments char-acterize different kernel functions.
We considersyntactic tree fragments (STFs) and partial treefragments (PTFs)2.2.1 Syntactic Tree Kernels (STK)An STF is a connected subset of the nodes andedges of the original tree, with the constraint thatany node must have all or none of its children.
Thisis equivalent to stating that the production rulescontained in the STF cannot be partial.
For ex-ample, Figure 1 shows a tree with its PTFs: [VP [VNP]] is an STF, [VP [V]] or [VP [NP]] are not STFs.2.2.2 Partial Tree Kernel (PTK)If we relax the production rule constraint overthe STFs, we obtain a more general substructuretype, i.e.
PTF, generated by the application of par-tial production rules, e.g.
Figure 2 shows that [VP[NP[D]]] is indeed a valid fragment.
Note thatPTK can be seen as a STK applied to all possiblechild sequences of the tree nodes, i.e.
a string ker-nel combined with a STK.2.3 Kernel EngineeringThe Kernels of previous section are basic functionsthat can be applied to feature vectors, strings and962trees.
In order to make them effective for a specifictask, e.g.
for coreference resolution: (a) we cancombine them with additive or multiplicative op-erators and (b) we can design specific data objects(vectors, sequences and tree structures) for the tar-get tasks.It is worth noting that a basic kernel applied toan innovative view of a structure yields a new ker-nel (e.g.
Moschitti and Bejan (2004); Moschittiet al (2006)), as we show below:Let K(t1, t2) = ?
(t1) ?
?
(t2) be a basic ker-nel, where t1and t2are two trees.
If we map t1and t2into two new structures s1and s2with amapping ?M(?
), we obtain: K(s1, s2) = ?
(s1) ??
(s2) = ?
(?M(t1)) ?
?
(?M(t2)) = ??
(t1) ???(t2)=K?
(t1, t2), which is a noticeably differentkernel induced by the mapping ??
= ?
?
?M.3 Kernels for Coreference ResolutionIn this paper we follow the standard learning ap-proach to coreference developed by Soon et al(2001) and also used the few variants in Ng andCardie (2002).
In this framework, training andtesting instances consist of a pair (anaphor, an-tecedent).
During training, a positive instance iscreated for each anaphor encountered by pairingthe anaphor with its closest antecedent; each of thenon-coreferential mentions between anaphor andantecedent is used to produce a negative instance.During resolution, every mention to be resolved ispaired with each preceding antecedent candidateto form a testing instance.
This instance is pre-sented to the classifier which then returns a classlabel with a confidence value indicating the likeli-hood that the candidate is the antecedent.The nearest candidate with a positive classifica-tion will be selected as the antecedent of the pos-sible anaphor.
The crucial point is that in this ap-proach, the classifier is trained to identify positiveand negative instances of the resolution process.
Inprevious work on using kernel functions for coref-erence (Yang et al 2006), structural informationin the form of tree features was included in theinstances.
This approach is appropriate for iden-tifying contexts in which the binding constraintsapply, but not, for instance, to recognize exple-tives.
In this work we adopted therefore a moregeneral approach, in which separate classifiers areused to recognize each relevant configuration, andtheir output is then used as an input to the coref-erence classifier.
In this section we discuss thetypes of structures and kernel functions we usedfor three different kinds of classifiers: expletive,binding and alias classifiers.
We then present theresults of these classifiers, and finally the resultswith the coreference resolver as a whole.3.1 Expletive KernelsIn written text, about a third of the occurrencesof the pronoun it are not coreferent to a previ-ous mention, but either refer to a general discoursetopic (it?s a shame) or do not refer at all, as in thecase of extraposed subjects (it is thought that .
.
.
)or weather verbs (it?s raining).
It is desirable tominimize the impact that these non-anaphoric pro-nouns have on the accuracy of a anaphora resolu-tion: Lappin and Leass (1994), for example, useseveral heuristics to filter out expletive pronouns,including a check for patterns including modal ad-jectives (it is good/necessary/.
.
.
that .
.
.
), and cog-nitive verbs (it is thought/believed/.
.
.
that .
.
.
).Newer approaches to the problem use machine-learning on hand-annotated examples: Evans(2001) compares a shallow approach based onsurrounding lemmas, part-of-speech tags, and thepresence of certain elements such as modal adjec-tives and cognitive verbs, trained on 3171 exam-ples from Susanne and the BNC to a reimplemen-tation of a pattern-based approach due to Paice andHusk (1987) and finds that the shallower machine-learning approach compares favorably to it.
Boydet al (2005) use an approach that combines someof Evans?
shallow features with hand-crafted pat-terns in a memory based learning approach andfind that the more informative features are ben-eficial for the system?s performance (88% accu-racy against 71% for their reimplementation usingEvans?
shallow features).Evans?
study also mentions that incorporatingthe expletive classifier as a filter for a pronoun re-solver gives a gain between 2.86% (for manuallydetermined weights) and 1% (for automatically op-timized weights).Tree kernels are a good fit for expletive classi-fication since they can naturally represent the lex-ical and structural context around a word.
Our fi-nal classifier uses the combination of an unmodi-fied tree (UT) (where the embedding clause or verbphrase of the pronoun is used as a tree), and a treethat only preserves the most salient structural fea-tures (ST).The reduced representation prunes all nodes that963would not be seen as indicative in a pattern ap-proach, essentially keeping verb argument struc-ture and important lexical items, such as the gov-erning verb and, in the case of copula construc-tions, the predicate.
For example, the phrase(S (NP (PRP It))(VP (VBZ has)(NP (NP (DT no) (NN bearing))(PP (IN on)(NP (NP (PRP$ our)(NN work)(NN force))(NP (NN today)))))(.
.
))would be reduced to the ST:(S-I (NP-I (PRP-I It))(VP (VBX have)(NP))(.
))or, in a similar fashion,(S (NP (PRP it))(VP (VBZ ?s)(NP (NP (NN time))(PP (IN for)(NP (PRP$ their)(JJ biannual)(NN powwow))))))would just be represented as the ST:(S-I (NP-I (PRP-I it))(VP (BE VBZ)(NP-PRD (NN time))))3.2 Binding KernelsThe resolution of pronominal anaphora heavily re-lies on the syntactic information and relationshipsbetween the anaphor and the antecedent candi-dates, including binding and other constraints, butalso context-induced preferences in sub-clauses.Some researchers (Lappin and Leass 1994;Kennedy and Boguraev 1996) use manually de-signed rules to take into account the grammati-cal role of the antecedent candidates as well asthe governing relations between the candidate andthe pronoun, while others use features determinedover the parse tree in a machine-learning approach(Aone and Bennett 1995; Yang et al 2004; Luoand Zitouni 2005).
However, such a solution haslimitations, since the syntactic features have to beselected and defined manually, and it is still partlyan open question which syntactic properties shouldbe considered in anaphora resolution.We follow (Yang et al 2006; Iida et al 2006) inusing a tree kernel to represent structural informa-tion using the subtree that covers a pronoun and itsantecedent candidate.
Given a sentence like ?TheFigure 3: The structure for binding detection forthe instance inst(?the man?, ?him?)
in the sentence?the man in the room saw him?man in the room saw him.
?, we represent the syn-tactic relation between ?The man?
and ?him?, bythe shortest node path connecting the pronoun andthe candidate, along with the first-level of the nodechildren in the path.Figure 3 graphically shows such tree highlightedwith dash lines.
More in detail we operate the fol-lowing tree transformation:(a) To distinguish from other words, we explic-itly mark up in the structured feature the pronounand the antecedent candidate under consideration,by appending a string tag ?ANA?
and ?CANDI?in their respective nodes, i.e.
?NN-CANDI?
for?man?
and ?PRP-ANA?
for ?him?.
(b) To reduce the data sparseness, the leaf nodesrepresenting the words are not incorporated in thefeature, except that the word is the word node ofthe ?DET?
type (this is to indicate the lexical prop-erties of an expression, e.g., whether it is a definite,indefinite or bare NP).
(c) If the pronoun and the candidate are not in thesame sentence, we do not include the nodes denot-ing the sentences (i.e., ?S?
nodes) before the can-didate or after the pronoun.The above tree structures will be jointly usedwith the basic STK which extracts tree fragmentsable to characterize the following information: (a)the candidate is post-modified by a prepositionphrase, (the node ?PP?
for ?in the room?
is in-cluded), (b) the candidate is a definite noun phrase(the article word ?the?
is included), (c) the candi-date is in a subject position (NP-S-VP structure),(d) the anaphor is an object of a verb (the node?VB?
for ?saw?
is included) and (e) the candidateis c-commanding the anaphor (the parent of theNP node for ?the main in the room?
is dominat-ing the anaphor (?him?
), which are important forreference determination in the pronoun resolution.9643.3 Encoding Context via Word SequenceKernelThe previous structures aim at describing the in-teraction between one referential and one referent;if such interaction is observed on another mentionpair, an automatic algorithm can establish if theycorefer or not.
This kind of information is the mostuseful to characterize the target problem, however,the context in which such interaction takes place isalso very important.
Indeed, natural language pro-poses many exceptions to linguistic rules and thesecan only be detect by looking at the context.
To beable to represent context words or phrases, we usecontext word windows around the mentions andthe subsequence kernel function (see section 2.1)to extract many features from it.For example, in the context of ?and so BillGates says that?, a string kernel would ex-tract features including: Bill Gates says that,says that, Gates, Gates says that, Bill says that,so Gates says that, and so that and so on.Name AliasBJ Habibie Mr. HabibieFederal Express FedexJu Rong Zhi JuTable 1: Examples of coreferent named entities(aliases) taken from the MUC 6 corpus.3.4 Kernels for Alias ResolutionMost methods currently employed by coreferenceresolution (CR) systems for identifying coreferentnamed entities, i.e.
aliases, are fairly simplistic innature, relying on simple surface features such asthe edit distance between two strings representingnames.
We investigate the potential of using thestructure contained within names.
This can be veryuseful to solve complex cases like those shown inTable 1, taken from the MUC 6 corpus (Chinchorand Sundheim 2003).
For this purpose, we addsyntactic information to the feature set by taggingthe parts of a name (e.g.
first name, last name, etc.
)as illustrated in Figure 4.To automatically extract such structure we usedthe High Accuracy Parsing of Name Internal Struc-ture (HAPNIS) script1.
HAPNIS takes a name asinput and returns a tagged name like what is shownin Figure 4.
It uses a series of heuristics in makingits classifications based on information such as the1The script is freely available athttp://www.cs.utah.edu/ hal/HAPNIS/.Figure 4: A proper name labeled with syntactic in-formation.serial positions of tokens in a name, the total num-ber of tokens, the presence of meaningful punctua-tion such as periods and dashes, as well as a libraryof common first names which can be arbitrarily ex-tended to any size.
The tag set consists of the fol-lowing: surname, forename, middle, link, role, andsuffix2.Once the structure for a name has been de-rived, we can apply tree kernels to represent it inthe learning algorithms thus avoiding the manualfeature design.
Such structures are not based onany particular grammar, therefore, any tree sub-part may be relevant.
In this case the most suitablekernel is PTK, which extracts any tree subpart.
Itis worth to note that the name tree structure canbe improved by inserting a separate node for eachname character and exploiting the string matchingapproximation carried out by PTK.
For example,Microsoft Inc. will have a large match with Mi-crosoft Incorporated whereas the standard stringmatching would be null.4 Experiments with Coreference SubtaskClassifiersIn these experiments we test the kernels devised forexpletive (see Section 3.1), binding (see Section3.2) and alias detection (see Section 3.4), to studythe level of accuracy reachable by our kernel-basedclassifiers.
The baseline framework is constitutedby SVMs along with a polynomial kernel over theSoon et al?s features.4.1 Experiments on Expletive ClassificationWe used the BBN Pronoun corpus3 as a source ofexamples, with the training set consisting of sec-tions 00-19, yielding more than 5800 instances of2Daume?
reports a 99.1% accuracy rate on his test data set.We therefore concluded that it was sufficient for our purposes.3Ralph Weischedel and Ada Brunstein (2005): BBN Pro-noun Coreference and Entity Type Corpus, LDC2005T33965it, with the testing set consisting of sections 20 and21, using the corresponding parses from the PennTreebank for the parse trees.
Additionally, we re-port on the performance of the classifier learnt ononly the first 1000 instances to verify that our ap-proach also works for small datasets.
The resultsin Table 2 show that full tree (UT) achieves goodresults whereas the salient tree (ST) leads to a bet-ter ability to generalize, and the combination ap-proach outperforms both individual trees.BBN large BBN smallPrec Recl Acc Prec Recl AccUT 83.87 61.54 84.35 78.76 52.66 80.85ST 78.08 67.46 83.98 77.61 61.54 82.50UT+ST 81.12 68.64 85.27 80.74 64.50 84.16Table 2: Results for kernel-based expletive detec-tion (using STK)Note that the accuracy we get by training on1000 examples (84% accuracy; see the small col-umn in Table 2) is better than Boyd?s replication ofEvans (76% accuracy) or their decision tree clas-sifier (81% accuracy) even though Boyd et al?sdataset is three times bigger.
On the other hand,Boyd et als full system, which uses substantialhand-crafted knowledge, gets a still better result(88% accuracy), which is also higher than the ac-curacy of our classifier even when trained on thefull 5800 instances.MUC-6Prec Recl FSoon et al 51.25 55.51 53.29STK 71.93 55.41 62.59Table 3: Binding classifier: coreference classifica-tion on same-sentence pronouns4.2 Experiments with the Binding ClassifierTo assess the effect of the binding classifier onsame-sentence pronoun links, we extracted 1398mention pairs from the MUC-6 training data whereboth mentions were in the same sentence and atleast one item of the pair included a pronoun, us-ing the first 1000 for training and the remaining398 examples for testing.
The results (see Table 3)show that the syntactic tree kernel (STK) consider-ably improves the precision of classification of theSoon et al?s features.4.3 Experiments on Alias ClassificationFor our preliminary experiments, we extractedonly pairs in the MUC 6 testing set in which bothmentions were proper names, as determined bythe coreference resolver?s named entity recognizer.This set of proper names contained about 37,000pairs of proper names of which about 600 werepositive instances.
About 5,500 pairs were ran-domly selected as test instances and the rest wereused for training.In the first experiment, we trained a decisiontree classifier to detect if two names are aliases.For this task, we used either the string kernel scoreover the sequence of characters or the edit distance.The results in Table 4 show that the string kernelscore performs better by 21.6 percentage points inF-measure.In the second experiments we used SVMstrained with the string kernel over the name-character sequences and with PTK, which takesinto account the structure of names.
The re-sults in Table 5 show that the structure improvesalias detection by almost 5 absolute percent points.This suggests that an effective coreference sys-tem should embed PTK and name structures in thecoreference pair representation.Recall Precision F-measureString kernel 49.5% 60.8% 54.6%Edit distance 23.9% 53.1% 33.0%Table 4: Decision-tree based classification of namealiases using string kernels and edit distance.Recall Precision F-measureString kernel 58.4% 67.5% 62.6%PTK 64.8% 70.0% 67.3%Table 5: SVM-based classification of name aliasesusing string kernels and tree-based feature.5 Experiments on Coreference SystemsIn this section we evaluate the contribution in thewhole coreference task of the expletive classifierand the binding kernel.
The predictions of the for-mer are used as a feature of our basic coreferencesystem whereas the latter is used directly in thecoreference classifier by adding it to the polyno-mial kernel of the basic system.Our basic system is based on the standard learn-ing approach to coreference developed by Soonet al (2001).
It uses the features from Soon etal?s work, including lexical properties, morpho-logic type, distance, salience, parallelism, gram-matical role and so on.
The main difference with966Soon et al (2001) is the use of SVMs along with apolynomial kernel.MUC-6Prec Recl Fplain 65.2 66.9 66.0plain+expletive 66.1 66.9 66.5upper limit 70.0 66.9 68.4Table 6: Expletive classification: influence on pro-noun resolution5.1 Influence of Expletive classificationTo see how useful a classifier for expletives canbe, we conducted experiments using the expletiveclassifier learned on the BBN pronoun corpus onthe MUC-6 corpus.
Preliminary experiments indi-cated that perfect detection of expletives (i.e.
usinggold standard annotation) could raise the precisionof pronoun resolution from 65.2% to 70.0%, yield-ing a 2.4% improvement in the F-score for pronounresolution alone, or 0.6% improvement in the over-all coreference F-score (see Table 6).For a more realistic assessment, we used theclassifier learned on the BBN pronoun corpus ex-amples as an additional feature to gauge the im-provement that could be achieved using it.
Whilethe gain in precision is small even in comparisonto the achievable error reduction, we need to keepin mind that our baseline is in fact a well-tunedsystem.MUC-6 ACE02-BNewsR P F R P FPK 64.3 63.1 63.7 58.9 68.1 63.1PK+TK 65.2 80.1 71.9 65.6 69.7 67.6Table 7: Results of the pronoun resolution5.2 Binding and Context KernelsIn these experiments, we compared our corefer-ence system based on Polynomial Kernel (PK)against its combinations with Syntactic Tree Ker-nels (STK) over the binding structures (Sec.
3.2)and Word Sequence Kernel (WSK) on contextwindows (Sec.
3.3).
We experimented withboth the only pronoun and the complete corefer-ence resolution tasks on the standard MUC-6 andACE03-BNews data sets.On the validation set, the best kernel combina-tion between PK and STK was STK(T1, T2) ?PK(~x1, ~x2)+PK(~x1, ~x2).
Then an improvementarises when simply summing WSK.Table 7 lists the results for the pronoun resolu-tion.
We used PK on the Soon et al?s features asthe baseline.
On MUC-6, the system achieves arecall of 64.3% and precision 63.1% and an over-all F-measure of 63.7%.
On ACE02-BNews, therecall is lower 58.9% but the precision is higher,i.e.
68.1%, for a resulting F-measure of 63.1%.In contrast, adding the binding kernel (PK+STK)leads to a significant improvement in 17% preci-sion for MUC-6 with a small gain (1%) in recall,whereas on the ACE data set, it also helps to in-crease the recall by 7%.
Overall, we can see anincrease in F-measure of around 8% for MUC and4.5% for ACE02-BNews.
These results suggestthat the structured feature is very effective for pro-noun resolution.MUC-6 ACE02-BNewsR P F R P FPK 61.5 67.2 64.2 54.8 66.1 59.9PK+STK 63.4 67.5 65.4 56.6 66.0 60.9PK+STK+WSK 64.4 67.8 66.0 57.1 65.4 61.0Table 8: Results of the coreference resolutionTable 8 lists the results on the coreference res-olution.
We note that adding the structured fea-ture to the polynomial kernel, i.e.
using the modelPK+STK, improves the recall of 1.9% for MUC-6 and 1.8% for ACE-02-BNews and keeps invari-ant the precision.
Compared to pronoun resolu-tion, the improvement of the overall F-measure issmaller (about 1%).
This occurs since the resolu-tion of non-pronouns case does not require a mas-sive use of syntactic knowledge as in the pronounresolution problem.
WSK further improves thesystem?s F1 suggesting that adding structured fea-tures of different types helps in solving the coref-erece task.6 ConclusionsWe presented four examples of using kernel-basedmethods to take advantage of a structured repre-sentation for learning problems that arise in coref-erence systems, presenting high-accuracy classi-fiers for expletive detection, binding constraintsand same-sentence pronoun resolution, and namealias matching.
We have shown the accuracyof the individual classifiers for the above tasksand the impact of expletives and binding classi-fiers/kernels in the complete coreference resolu-tion system.
The improvement over the individualand complete tasks suggests that kernel methods967are a promising research direction to achieve state-of-the-art coreference resolution systems.Future work is devoted on making the use of ker-nels for coreference more efficient since the size ofthe ACE-2 corpora prevented us to directly use thecombination of all kernels that we designed.
In thispaper, we have also studied a solution which re-lates to factoring out decisions into separate clas-sifiers and using the decisions as binary features.However, this solution shows some loss in terms ofaccuracy.
We are currently investigating methodsthat allow us to combine the accuracy and flexibil-ity of the integrated approach with the speed of theseparate classifier approach.Acknowledgements Y. Versley was funded by theDeutsche Forschungsgemeinschaft as part of SFB (Collabora-tive Research Centre) 441.
A. Moschitti has been partly sup-ported by the FP6 IST LUNA project (contract No.
33549).Part of the work reported in this paper was done at the JohnsHopkins Summer Workshop in 2007, funded by NSF andDARPA.
We are especially grateful for Alan Jern?s implemen-tation help for name structure identification.ReferencesAone, C. and Bennett, S. W. (1995).
Evaluating automatedand manual acquisition of anaphora resolution strategies.In Proc.
ACL 1995, pages 122?129.Barzilay, R. and Lapata, M. (2005).
Modelling local coher-ence: An entity-based approach.
In Proc.
of ACL, AnnArbor, MI.Boyd, A., Gegg-Harrison, W., and Byron, D. (2005).
Iden-tifying non-referential it: a machine learning approach in-corporating linguistically motivated features.
In Proc.
ACLWS on Feature Engineering for Machine Learning in Nat-ural Language Processing.Cancedda, N., Gaussier, E., Goutte, C., and Renders, J. M.(2003).
Word sequence kernels.
JMLR, 3:1059?1082.Chinchor, N. and Sundheim, B.
(2003).
Muc 6 corpus.
Mes-sage Understanding Conference (MUC) 6.Chomsky, N. (1981).
Lectures on government and binding.Foris, Dordrecht, The Netherlands.Collins, M. and Duffy, N. (2002).
New ranking algorithms forparsing and tagging: kernels over discrete structures andthe voted perceptron.
In Proc.
ACL 2002, pages 263?270.Evans, R. (2001).
Applying machine learning toward an au-tomatic classification of it.
Literary and Linguistic Com-puting, 16(1):45?57.Giuglea, A.-M. and Moschitti, A.
(2006).
Semantic role la-beling via framenet, verbnet and propbank.
In Proceedingsof Coling-ACL, Sydney, Australia.Grosz, B., Joshi, A., and Weinstein, S. (1995).
Centering: aframework for modeling the local coherence of discourse.CL, 21(2):203?225.Hobbs, J.
(1978).
Resolving pronoun references.
Lingua,44:339?352.Hobbs, J.
(1979).
Resolving pronoun references.
Coherenceand Coreference, 3(1):67?90.Iida, R., Inui, K., and Matsumoto, Y.
(2006).
Exploiting syn-tactic patterns as clues in zero-anaphora resolution.
InProc.
Coling/ACL 2006, pages 625?632.Kennedy, C. and Boguraev, B.
(1996).
Anaphora for every-one: pronominal anaphora resolution without a parser.
InProc.
Coling 1996.Lappin, S. and Leass, H. (1994).
An algorithm for pronominalanaphora resolution.
CL, 20(4):525?561.Luo, X. and Zitouni, I.
(2005).
Multi-lingual coreference res-olution with syntactic features.
In Proc.
HLT/EMNLP 05.McCarthy, J. and Lehnert, W. (1995).
Using decision trees forcoreference resolution.
In Proc.
IJCAI 1995.Mitkov, R. (2002).
Anaphora resolution.
Longman.Moschitti, A.
(2006).
Efficient convolution kernels for depen-dency and constituent syntactic trees.
Proc.
ECML 2006.Moschitti, A. and Bejan, C. A.
(2004).
A semantic kernel forpredicate argument classification.
In CoNLL-2004, USA.Moschitti, A., Pighin, D., and Basili, R. (2006).
SemanticRole Labeling via Tree Kernel Joint Inference.
In Pro-ceedings of CoNLL-X.Moschitti, A., Quarteroni, S., Basili, R., and Manandhar, S.(2007).
Exploiting syntactic and shallow semantic kernelsfor question answer classification.
In Proceedings ACL,Prague, Czech Republic.Ng, V. and Cardie, C. (2002).
Improving machine learningapproaches to coreference resolution.
In Proc.
ACL 2002.Paice, C. D. and Husk, G. D. (1987).
Towards an automaticrecognition of anaphoric features in english text: The im-personal pronoun ?it?.
Computer Speech and Language,2:109?132.Shawe-Taylor, J. and Cristianini, N. (2004).
Kernel Methodsfor Pattern Analysis.
Cambridge University Press.Sidner, C. (1979).
Toward a computational theory of definiteanaphora comprehension in english.
Technical report AI-TR-537, MIT, Cambridge, MA.Soon, W., Ng, H., and Lim, D. (2001).
A machine learningapproach to coreference resolution of noun phrases.
CL,27(4):521?544.Steinberger, J., Poesio, M., Kabadjov, M., and Jezek, K.(2007).
Two uses of anaphora resolution in summarization.Information Processing and Management, 43:1663?1680.Special issue on Summarization.Sturt, P. (2003).
The time-course of the application of bindingconstraints in reference resolution.
Journal of Memory andLanguage.Vapnik, V. (1995).
The Nature of Statistical Learning Theory.Springer.Vieira, R. and Poesio, M. (2000).
An empirically based sys-tem for processing definite descriptions.
CL, 27(4):539?592.Yang, X., Su, J., and Tan, C. (2006).
Kernel-based pronounresolution with structured syntactic knowledge.
In Proc.COLING-ACL 06.Yang, X., Su, J., Zhou, G., and Tan, C. (2004).
Improving pro-noun resolution by incorporating coreferential informationof candidates.
In Proc.
ACL 2004.Zanzotto, F. M. and Moschitti, A.
(2006).
Automatic learn-ing of textual entailments with cross-pair similarities.
InProceedings of Coling-ACL, Sydney, Australia.Zelenko, D., Aone, C., and Richardella, A.
(2003).
Kernelmethods for relation extraction.
JMLR, 3(6):1083 ?
1106.968
