Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically Rich Languages, pages 34?45,Seattle, Washington, USA, 18 October 2013. c?2013 Association for Computational LinguisticsA Cross-Task Flexible Transition Model for Arabic Tokenization, AffixDetection, Affix Labeling, POS Tagging, and Dependency ParsingStephen TratzArmy Research LaboratoryAdelphi Laboratory Center2800 Powder Mill RoadAdelphi, MD 20783stephen.c.tratz.civ@mail.milAbstractThis paper describes cross-task flexible tran-sition models (CTF-TMs) and demonstratestheir effectiveness for Arabic natural languageprocessing (NLP).
NLP pipelines often sufferfrom error propagation, as errors committedin lower-level tasks cascade through the re-mainder of the processing pipeline.
By al-lowing a flexible order of operations acrossand within multiple NLP tasks, a CTF-TM canmitigate both cross-task and within-task errorpropagation.
Our Arabic CTF-TM models to-kenization, affix detection, affix labeling, part-of-speech tagging, and dependency parsing,achieving state-of-the-art results.
We presentthe details of our general framework, our Ara-bic CTF-TM, and the setup and results of ourexperiments.1 IntroductionNatural Language Processing (NLP) systems oftenconsist of a series of NLP components, each trainedto perform a specific task such as parsing.
Thesepipelines tend to suffer from error propagation?errors introduced by early components cascadethrough the remainder of the pipeline causing subse-quent components to commit additional errors.
Par-tial solutions from higher-level tasks (e.g., parsing)can aid in resolving the difficult decisions that mustbe made in solving lower-level tasks, as with part-of-speech tagging the classic ?garden path?
sentenceexample ?The horse raced past the barn fell.?
Tothis end, this paper presents cross-task flexible tran-sition models (CTF-TMs), which model multipletasks and solve these tasks in a more flexible or-der than pipeline approaches.
We implement andexperiment with a CTF-TM for Arabic1 languageprocessing and report experimental results for it onArabic tokenization (i.e., clitic separation), affix de-tection, affix labeling, part-of-speech tagging, anddependency parsing.In addition to error propagation between mod-ules within a parsing pipeline, errors may propa-gate within the parsing process itself due to thefixed order of operations of the parser.
This is com-mon for standard transition-based dependency pars-ing models (McDonald and Nivre, 2007), such asshift-reduce parsers, which incrementally constructa parse by processing the input in a fixed left-to-rightor right-to-left fashion.
However, using a transitionmodel that allows a more flexible order of opera-tions, such as Goldberg and Elhadad?s (2010) parser,allows difficult decisions to be postponed until later,when more of the solution has been constructed.CTF-TMs extend this approach by modeling mul-tiple tasks and providing this flexibility across tasksso that no one task needs to be complete before an-other can be partially solved.As a morphologically rich language, Arabic re-quires a significant number of processing steps.
Ara-bic uses a variety of affixes to inflect for case, gen-der, number (including dual), and mood, has cliticsthat attach to other words, permits both VSO andSVO constructions, and rarely includes short vow-els in written form.
The presence of clitics and theabsence of written short vowels are particularly sig-nificant sources of ambiguity.
As Tsarfaty (2006)argues for Modern Hebrew, a Semitic language thatshares these characteristics, we contend that mor-1This paper focuses on Modern Standard Arabic rather thanany of the dialects.34phological analysis and parsing should be done ina unified framework, such as a CTF-TM, rather thanby separate components.In this paper, we describe CTF-TMs, which canbe used for a wide variety of NLP tasks, and presentour Arabic CTF-TM for Arabic tokenization, af-fix detection, affix labeling, part-of-speech tagging,and dependency parsing as well as the results ob-tained in applying it to our dependency conversionof the Penn Arabic Treebank (ATB) (Maamouri etal., 2004; Maamouri and Bies, 2004).
We findthat our Arabic CTF-TM for tokenization, affix de-tection, affix labeling, POS tagging, and parsingachieves slightly better results than a similar CTF-TM that performs all the tasks except parsing.
TheCTF-TM that supports parsing appears to be moreaccurate at distinguishing between passive and ac-tive verbs as well as between nouns and adjectives?cases where the context is crucial for proper inter-pretation due to Arabic?s ambiguities.
Our systemachieves tokenization accuracy similar to Kulick?s(2011) state-of-the-art system for a standard split ofthe ATB part 3, and, in our experiments using ATBparts 1?3, our system achieves the highest labeledattachment, unlabeled attachment, and clitic separa-tion figures (including pronomial clitics) for Arabicyet reported (although no other work can be com-pared directly).2 Relevant Arabic LinguisticsArabic has rich morphology, with a wide array of af-fixes and clitics and inflecting for case, number, gen-der, and, occasionally, mood.
Coordinating conjunc-tions, pronouns, and most true prepositions, alongwith some other particles and the definite article,usually occur as clitics in Arabic.
Thus, a space-delimited2 sequence of Arabic characters may con-sist of multiple words, and identifying the bound-aries between these must be done in order to producesyntactic parses.
These boundaries can?t be detectedperfectly using simple deterministic rules.
Signifi-cantly, short vowels, which are expressed using dia-critics, are not typically written in Arabic, resultingin pervasive ambiguity.
For example, active and pas-sive forms of verbs vary only in their diacritics, andnouns and adjectives are both derived from Arabic2Technically, space-and-punctuation-deliminated.roots using the same templates and, thus, look sim-ilar.
A single Arabic token may permit a variety ofdifferent analyses, as the example in Table 1 illus-trates.??@?
wAlY ?ruler??+??@+?
w+AlY+y ?and to me???@+?
w+<ly ?and I follow??+?@+?
w+|l+y ?and my clan???@+?
w+|ly ?and automatic?Table 1: Possible interpretations for the text wAlY(Habash and Rambow, 2005).3 CTF-TM FrameworkError propagation is not simply a problem that oc-curs between components in a pipeline but one thatoften occurs within a single component?s process-ing.
Since transition systems can use the partiallybuilt solution for feature generation, incorrect ac-tions taken early on result not only in an invalidfinal solution, but the invalid partial solution maydissuade the system from making correct decisionswith respect to other parts of the solution.
If atransition system can postpone decisions it is notconfident of until later, the partial solution createdby performing other actions may provide more orbetter information that enables the system to prop-erly resolve more difficult decisions.
This ?easy-first?
strategy is adopted by Goldberg and Elhadad?s(2010) parsing system, which starts with an orderedlist of unattached words and, in each iteration, cre-ates a new arc between any of the adjacent pairsof words in the list and removes the daughter node(word) from the list.This strategy is much more flexible than shift-reduce style parsing because the system has moreoptions available to it at any one step for buildingup the solution.
However, simply having flexibil-ity within a single component does not reduce er-ror propagation to or from other components in apipeline and, to mitigate the potential for this, onemay use a cross-task flexible transition model (CTF-TM) that does not have to wait for lower level tasksto be 100% complete before starting work on higherlevel tasks.35McDonald and Nivre (2007) define a transitionsystem as follows:1. a set C of parse configurations, each of whichdefines a (partially built) dependency graph G2.
a set T of transitions, each a function t : C ?C3.
for every sentence x = w0, w1, ..., wn(a) a unique initial configuration cx(b) a set Cx of terminal configurationsThese systems start at the initial configuration anduse a scoring function s : C ?
T ?
R to repeatedlyselect and follow the locally optimal transition, stop-ping when a terminal configuration is reached.We make a few changes to McDonald and Nivre?stransition system definition in order to explain ourframework.
First, to support modeling of multipletasks, instead of referring to parse configurations,we simply use the term configuration, defining it torepresent a partially built solution rather than a de-pendency graph.
Second, we specify that there ex-ists a routine for enumerating a set of anchors forany given configuration.
Anchors are an organiza-tional concept for dealing with arbitrary data struc-tures; each anchor acts as a hook into some por-tion of the configuration that may be changed.
Fi-nally, there exist routines for enumerating legal ac-tions that can be performed in relation to any anchorand, for training, a routine for verifying that per-forming a given action will lead to a configurationconsistent with the final solution.
The performanceof an action constitutes a transition between config-urations.3 It is quite straightfoward to adapt Gold-berg and Elhadad?s (2010) parsing approach to anyconfiguration that is indexable by anchors, and in sodoing we are able to create cross-task flexible tran-sition models.3For example, in a fixed order, one-word-at-a-time POS tag-ging system, there would be only one anchor?the word cur-rently being labeled?but, for a one-at-a-time POS tagger capa-ble of tagging words in any order, the anchor set would containthe entire list of still-unlabeled words.
The POS labeling ac-tions for the anchors in each of these cases constitute transitionsto new configurations.4 Our Arabic CTF-TM4.1 TasksOur Arabic CTF-TM system performs the follow-ing tasks: split a series of space-delimited Arabic to-kens into words (tokenization), identify the boundsof affixes within the words (affix detection), labelthe affixes (affix labeling), label the words with theirparts of speech (POS tagging), and construct a la-beled dependency tree (dependency parsing).
Tok-enization, part-of-speech tagging, and dependencyparsing are frequent topics in NLP literature.
Affixidentification and labeling are parts of morphologi-cal analysis that are sometimes completely ignoredor are performed using an external morphologicalanalyzer.
Identifying affixes and labeling them canhelp the overall system contend with lexical sparsityissues as well as utilize the information encoded bythe affixes (e.g., person).4.2 Anchors and ActionsThe configurations that the system deals with haveanchors of two types, token anchors and affix an-chors.
The initial configuration consists of an or-dered list of neighboring token anchors (neighbor-hood), each of which corresponds to one of the orig-inal space-delimited tokens.
As processing contin-ues, new token anchors may be created by splittingoff clitics, new affix anchors may be created by iden-tifying substrings of tokens as affixes, and token an-chors will be removed from the ordered list to be-come daughter nodes of their neighbors, attached vialabeled dependency arcs.
The complete list of ac-tions that can be performed on the anchors, which, asdescribed earlier, constitute the transitions betweenconfigurations, are as follows:Tokenization1.
Separate a proclitic of length l from a token anchor, cre-ating a new token anchor for the clitic and reducing thewidth of the original token2.
Separate an enclitic of length l from a token anchor, cre-ating a new token anchor for the clitic and reducing thewidth of the original tokenAffix Detection3.
Create an affix (prefix) anchor from the first l charactersof a token anchor that are not labeled as part of an affix(If the affix is the definite determiner Al, which we treatas an affix for consistency with the ATB?s tokenizationscheme, it is automatically labeled as DET and removedfrom further processing for the sake of efficiency.)364.
Create an affix (suffix) anchor from the last l charactersof a token anchor that are not labeled as part of an affixPOS and affix labeling5.
Assign a label l to the anchor (Affixes are automaticallyremoved from further processing after labeling)Dependency parsing6.
Create a dependency arc with label d between a token an-chor and the preceding unattached neighbor token anchorand remove the attached anchor from the neighborhood7.
Create a dependency arc with label d between a tokenanchor and the following unattached neighbor token an-chor with label l and remove the attached anchor from theneighborhood8.
Swap the position of two neighboring token anchors (thisadds Nivre-style (2009) non-projectivity support as de-scribed by Tratz and Hovy (2011))General9.
Mark an anchor as fully processed and remove it fromfurther processingThe dependency labels, POS labels, clitic lengths,and affix lengths used to define the actions are allcollected automatically from the training data.
4The actions are subject to the following con-straints/preconditions:1.
Labeling is only valid if the anchor has not been labeled2.
Tokens may only be labeled with token labels, prefixeswith prefix labels, and suffixes with suffix labels (as de-termined by the training data)3.
Affix strings observed in the training data may not be la-beled with any label not used with them in the trainingdata4.
Token anchors may not be assigned labels that do not co-occur with the labels of any already-labeled affixes andvice versa5.
A prefix creation action may only be applied to a tokenanchor that doesn?t yet have a prefix6.
Proclitics may not be created and detached if the tokenalready has a prefix, and enclitics are similarly restrictedby the presence of a suffix7.
Clitics may not be detached from a token that has alreadybeen attached to another token via a dependency arc8.
A dependency arc with label x may not be created be-tween token anchors T1 and T2 if 1) one or both are la-beled and 2) no arc between similarly POS tagged an-chors exists in the training data9.
Swap actions may not undo previous swaps10.
Marking a token anchor as fully processed may only oc-cur if it has already been labeled, and it must either be 1)the last unattached token or 2) already attached4Training examples with clitics that are invalid (i.e., toolong) are discarded at the beginning of training.4.3 Scoring FunctionFor our scoring function, like Goldberg and El-hadad, we use the structured perceptron algorithm(Collins, 2002) with parameter averaging.
Thishas previously been shown to produce strong re-sults when modeling multiple NLP tasks (Zhang andClark, 2008).4.4 FeaturesFor a given anchor5, the system extracts featuresfrom the partially built solution (e.g., the text, af-fixes, POS tags, and syntactic dependencies of theanchor and nearby anchors).
The same feature tem-plates are used for all action types except the affix la-beling actions?affix labeling is applied to affix an-chors instead of word-level anchors, and, since alltemplates are defined relative to an anchor, the tem-plates must be different.
The system uses no externalresources (e.g., lexicons, morphological analyzers).We leave out a more exhaustive listing and descrip-tion of the features due to space limitations6, the factthat the focus of this paper is not on the value of anyparticular feature template but rather on our overallapproach and experimental results, and because weplan to release our code, which will be more helpfulfor reproducibility efforts.4.5 Data PreparationFor our experiments, we use the original writ-ten form of the data from the latest versions ofthe first three parts of the Penn Arabic Treebank(ATB) (Maamouri et al 2004; Maamouri and Bies,2004) as well as the new broadcast news collection(Maamouri et al 2012).7 We convert the constituenttrees into dependency trees and adjust the part-of-speech tags.5?A given action?
may be more correct technically, but ourimplementation is set up to share the same set of string-basedfeatures across all actions associated with a given anchor.6Simply listing the feature templates in a normal font sizewith minimal (insufficient) explanation would require well overa page.
The set of feature templates is based upon the tem-plates used by Tratz and Hovy?s (2011) English parser, whichare given in Tratz?s (2011) thesis.7We use version 4.1 of ATB part 1, 3.1 of part 2, 3.2 of part3, and 1.0 of the broadcast news transcriptions.374.5.1 Dependency ConversionThe two main Modern Standard Arabic de-pendency treebanks currently available are theColumbia Arabic Treebank (CATiB) (Habash andRoth, 2009) and the Prague Arabic DependencyTreebank (PADT) (Hajic?
et al 2004).
CATiB hasover 228,000 manually annotated words as well asan automatic ATB conversion.
It uses only 8 de-pendency relations (subject, object, predicate, topic,idafa, tamyiz, modifier, and flat) and 6 part-of-speech tags, and it has not yet been publicly releasedby the LDC.
The PADT, which was used in theCoNLL 2006 and 2007 shared tasks (Buchholz andMarsi, 2006; Nivre et al 2007), is much smaller,with only about 148,000 annotated tokens.
Since wewant a large annotated corpus with fine-grained la-bels, we create our own ATB conversion.4.5.2 TransformationsIn addition to converting the ATB?s constituentparses to dependency trees, we make a handfulof other changes.
Following Green and Manning(2010) and others, sentences headed by X nodesare deleted because the treebank annotators con-sidered them unbracketable or somehow erroneous.Following Rambow et al(2005), Treebank sen-tences headed by TOP elements containing multipleS daughters are split into separate sentences.8 Addi-tionally, if the dependency converter concludes thatan S node without treebank functional tags is depen-dent upon another S node and is separated from itvia sentence-final punctuation (e.g., an exclamationpoint), these S nodes are separated into distinct sen-tences as well.
For the broadcast news data, we re-move all subtrees headed by EDITED tags to makeit more closely resemble newswire text.9Since we adhere to the tokenization scheme usedby the ATB, and we do not split off the determiner Alas its own tree token.
Instead, we treat it as a prefix.The words referred to as inna and her sisters areannotated using two different part-of-speech cate-gories and syntactic structures in the ATB.
In ourconversion, both ATB structures are converted to8The ATB often has multiple sentences, or even entire para-graphs, annotated under a single TOP element.9The EDITED tag ?is used to show the repetition and restart-ing of constituents that are repaired by subsequent speech?
(Maamouri et al 2012).the same dependency structure headed by the INNAword, similar to CATiB (Habash and Roth, 2009).We treat the focus particle AmmA like a preposi-tion in our dependency structure, following CATiB.4.5.3 Dependency Label SchemeOur dependency scheme consists of a total of35 labels.
Many of these are similar to those ofStanford?s basic dependency scheme for English (deMarneffe and Manning, 2008), although they aresomewhat closer to a similar scheme used by (Tratzand Hovy, 2011).
The list of relations is presentedin Table 2.Most of the relations are self-explanatory or cor-respond to similar labels in either Tratz and Hovy?s(2011) scheme for English or CATiB?s (Habash andRoth, 2009) scheme for Arabic.
A few are newor significantly different from their similarly namedcounterparts in other schemes and are described ingreater detail below.?
adjnom ?
connects the head of an NP to that of a sisterNP (occurs with apposition and preposition-like nouns)?
advcl ?
connects verbal nouns to their syntactic governorin what resemble English?s adverbial participle clauses?
advnp ?
connects NPs with treebank adverbial functiontags (e.g., -LOC, -TMP, -DIR), which are often headed bypreposition-like nouns, to what they modify?
fidafa ?
for false idafa (idafa-like structures that areheaded by adjectives instead of nouns)?
kccmp ?
connects a clausal complement that is part of apast progressive or habitual construction to the head verbkana?
lakinna ?
similar to cc but used with the sister of innalakinna instead of coordinating conjunctions?
part ?
particle modifier; connects particles (other thanFOCUS PART) to their governors?
rcmod ?
connects a bare relative clause to its head?
reladv ?
connects an adverbial WH- clause to its gover-nor?
relmod ?
connects the head of a WH- node to the rela-tivized word?
ripcmp ?
connects a clause to the relative or interrogativepronoun that heads it4.5.4 Part-of-Speech Tag SchemeThe Penn Arabic Treebank uses complex partof speech tags for the entire tree token such asDET+NOUN+NSUFF FEM SG+CASE DEF GEN.Across the treebank data used in our experiments,there are a total of 579 such tags, which arecomposed of 179 different parts separated by plussigns.
Each part corresponds to a substring of the38adjnom adjunct nominal intj interjection prep preposition modifieradvcl adverbial clause iobj indirect object punct punctuation modifieradvmod adverbial modifier idafa idafa rcmod (bare) relative clause modifieradvnp adverbial noun phrase fidafa false idafa reladv relative pronoun adverbialcc coordinating conjunction flat flat structure relmod relative pronoun modifierccinit initial coordinating conjunction kccmp kana clausal complement ripcmp relative/interrogative pronoun complementccomp clausal complement lakinna see text sc subordinating conjunction modifiercombo combination term neg negation subj subjectconj conjunction obj object tmz tamyizcop copula complement objcomp object complement tpc topicalized elementdep unspecified dependency part particle modifier voc vocativedet determiner pcomp preposition complementTable 2: Syntactic dependency scheme used in this work.
Labels that aren?t self-explanatory or similar to the labelsused by Tratz and Hovy (2011) for English or CATiB for Arabic (Habash and Roth, 2009) are in bold (for completelynew relations) or italics (for similarly named but semantically different relations)vowelized version of the word.10 Due at least in partto the enormity of this label set, simpler schemesare often preferred, such as the ?Bies?
labels (Bikel,2004; Kulick et al 2006), Diab?s (2007) labels,Kulick?s (2011) labels, and CATiB?s labels (Habashand Roth, 2009).
Marton et al(2010) find thatusing simpler schemes allow them to get betterparsing results when using predicted POS tags dueto the relatively poor performance of taggers trainedusing the full ATB scheme.The part-of-speech tag scheme we use is quitesimilar to that of the original ATB but has severalsimplifications.
These changes are listed below.1.
Possessive and direct object pronoun clitics are all giventhe same label (PRON OPP) (50 fewer tags; mapping backto the originals is trival in almost all cases)2.
.VN forms of NOUN and ADJ are merged with their re-spective more generic categories3.
Interrogative and relative adverbial and pronoun labelsare merged together into RI ADV and RI PRON4.
Noun suffix labels (e.g., NSUFF MASC PL GEN,NSUFF MASC PL ACC) with genitive or accusative casedistinctions are merged because there is no distinction inunvowelized form5.
Labels for dual masculine noun suffixes are merged withtheir plural counterparts (no distinction in the unvow-elized forms)6.
Demonstrative pronoun labels are collapsed toDEM PRON (person and number information is easilyrecovered)7.
The words called inna and her sisters are labeled INNAinstead of PSEUDO VERB or SUB CONJ10Since we use the original written form of the data and theinternal segmentation of the words are only provided for thevowelized versions, we project the segmentation into the orig-inal written forms, discarding any parts that weren?t actuallywritten (e.g., case labels associated with unwritten diacritics).Since our system splits off clitics and identifiesthe affixes, the tagging is performed at the individualmorpheme level instead of producing a single all-encompassing tag for the entire token.Some of the part-of-speech tags (mostly in-stances of DIALECT, TYPO, TRANSERR, andNOT IN LEXICON tags) are automatically cor-rected/improved during the dependency conversionbased upon the original constituent parse.4.6 FilteringSentences containing invalid clitics are not used intraining both because they are erroneous and be-cause including them would require allowing thesystem to perform actions that should not occur (i.e.,splitting off a clitic of length 8); similarly, train-ing examples with more than 20% of their tokenstagged as DIALECT, TRANSERR, LATIN, PARTIAL,GRAMMAR PROBLEM, and/or TYPO are ignored onthe assumption that including them would harm themodel.
This filtering process is not applied in test-ing.4.7 Data SplitWe train and test models using three different splitsof the data.
The first split is based upon the split usedby Zitouni et al(2006) in their diacritization workand is the same as that used by Marton et al(2013)in their parsing work and by Kulick (2011) in his to-kenization and part-of-speech tagging work, in orderto facilitate better comparison.
However, Marton etal.
use the CATiB conversion of a slightly earlierversion of the data (3.1, not 3.2), and, thus, the re-sults are not directly comparable.
This split places39Part Use Files Sent Toks Tree Toks Affixes1 train 514 4090 101629 116892 49057dev 110 909 22932 26261 11074test 110 823 20825 24127 100322 train 351 3011 102795 120605 56273dev 75 559 20869 24619 11245test 75 630 20518 24078 110783 train 509 11350 287945 341033 145621dev 45 1029 26347 31200 13828test 45 992 25299 29938 12220BN train 68 5504 82388 98040 48190dev 26 1801 29873 35676 17890test 26 2082 34361 41192 20366Table 3: Counts of the number of files, sentences (Sent),original space-delimited tokens (Tok), ATB tree tokens(Tree Toks), and affixes in the experimental data.the first (in name and chronological order) 85% ofthe documents in ATB part 3 in training, the next7.5% in development, and the final 7.5% in test.In the second split, we use data from the firstthree parts of the ATB, each of which consistsof documents coming from a different newswiresource.
Parts 1 and 2 are split 70%/15%/15% train-ing/dev/test, and we reuse the split of part 3 justmentioned.
Under this setup, we train two differentCTF-TMs, one that performs all of the tasks and onethat performs all of the tasks except parsing.
Thisenables us to test whether modeling parsing task im-proves performance on the lower level tasks.In the final split, we use the splits for parts 1?3plus the data in LDC?s annotated broadcast newstranscripts (Maamouri et al 2012).
Unlike parts1?3, the broadcast news data are drawn from a va-riety of sources.
Files from sources with three ormore files are split across training, development, andtest, with the latest documents being placed in test.11 This experiment illustrates how the system per-forms when additional, out-of-domain data are in-cluded.Statistics for the data are given in Table 3.4.8 Evaluation MeasuresDependency parsing quality is measured in terms oflabeled and unlabeled attachment scores (LAS andUAS), which indicate the percentage of words at-tached to their correct parent and, in the case ofLAS, whose attachment is labeled with the correct11We will make the exact list of files used in the training,development, and test sets available.dependency.
Since a given space-delimited tokenmay not be tokenized into words correctly, the de-pendency arcs are only counted as correct if theyoccur between the correct words (spans of charac-ter indices).
We measure part-of-speech tagging interms of F-score (F1) and require that the tree tokenhave the correct bounds (was tokenized correctly)and have the correct label.Normally, we would choose LAS on the develop-ment set as the measure for determining the versionof the model to keep for testing because it measuresperformance on the highest-level task (labeled de-pendency parsing).
However, since one of the CTF-TMs does not perform parsing, we instead use POStagging F1.
In general, we observe that the scoresare highly correlated, making the point moot.
Forthe ATB part 3 experiment, POS tagging F1 peakson iteration 437.12 For the second experiment, POStagging F1 peaks at iteration 301 for the CTF-TMwith parsing and iteration 278 for the one without.For the third experiment, the highest score occurson iteration 431.4.9 Results and DiscussionThe results for the various experimental setups arepresented in Table 4.ATB 3 Experiment When using the same splitof ATB part 3 as Kulick (2011) and Marton et al(2013), the system correctly tokenizes 99.3% of thespace-delimited tokens, similar to Kulick?s (2011)accuracy (99.3%) and slightly higher than the 99.0%figure Kulick calculates for MADA.
Though theseresults are obtained using our dependency conver-sion of the ATB rather than the original, we use thesame tokenization scheme.
The POS labeling F1score of 95.8 can?t be compared well with any otherwork due to differences in tag schemes, which varygreatly, as well as use of gold tokenization and otherdifferences.
Our system obtains 84.9 UAS and 82.0LAS, which are higher than Marton et als best re-sults of 84.0 UAS and 81.0 LAS, but they were usinga different conversion (CATiB) of a different versionof the data (3.1, not 3.2) as well as gold tokenization,so the results are not directly comparable.Framework Internal Experiment The CTF-TM12We run 500 iterations for each experiment, which can takeas long as a week using a quad-core machine.
However, littleimprovement is seen after the first 100 iterations.40Train Eval Data Tok Acc POS F1 Affix Bounds F1 Affix Label F1 UAS LAS3 3 Dev 99.5 96.6 98.7 98.4 86.3 83.83 3 Test 99.3 95.8 98.4 97.9 84.9 82.01,2,3 1,2,3 Dev 99.6 97.1 99.1 98.9 88.3 86.01,2,3 1,2,3 Test 99.6 96.8 99.0 98.7 87.4 84.81,2,3,BN 1,2,3 Dev 99.6 97.1 99.1 98.9 88.5 86.21,2,3,BN 1,2,3 Test 99.6 96.8 99.0 98.8 87.5 85.01,2,3,BN 1,2,3,BN Dev 99.5 96.0 98.8 98.5 87.4 84.61,2,3,BN 1,2,3,BN Test 99.3 95.7 98.7 98.4 86.6 83.8Without Parsing1,2,3 1,2,3 Dev 99.6 96.9 99.1 98.9 NA NA1,2,3 1,2,3 Test 99.5 96.5 98.9 98.6 NA NATable 4: Results for the various experiments (Exp) for both the development and test portions of the data, including per-token clitic separation (tokenization) accuracy, part-of-speech tagging F1, affix boundary detection F1, affix labelingF1, and both unlabeled and labeled attachment scores.that does parsing and the CTF-TM that doesn?tachieve similar overall results for the different tasks(other than parsing, of course).
However, whenlooking deeper at the individual POS tagging mis-takes that one system made more often by one sys-tem than the other, (see Tables 5 and 6), we ob-serve that the parsing CTF-TM does a better jobwith labeling some parts-of-speech.
For instance,the non-parsing system mismarks passive verbs asactive more than 29% more often than the other.
InArabic, passive and active forms of verbs are onlydistinguished by their short vowels, which are typi-cally unwritten, and, thus, the context is of particularimportance in distinguishing between the two.
Thenon-parsing system also has more trouble with thedistinction between nouns and adjectives, which islikely because adjectives are derived using the sametemplatic structures as nouns (Attia et al 2010) and,thus, context is, once again, of great importance.Broadcast News Experiment The scores ob-tained in the experiment with the broadcast newsdata are slightly lower than in the second exper-iment.
However, this appears to be because thebroadcast news portions of the development and testsections are more difficult to parse than the remain-der.
If we apply the model to the development andtest sections of parts 1, 2, and 3, we observe thatthe results, which are given in Table 4, are higherthan those of the model trained without the broad-cast news data.Gold Prediction Errors Diff-parse +parseNOUN ADJ 297 238 -59ADJ NOUN 328 298 -30VB IV PASS VB IV 109 80 -29VB PV PASS VB PV 86 68 -18VB PV NOUN 104 88 -16VB IV VB PV 12 22 +10INNA SUB CONJ 9 2 -7VB PV VB IV 19 13 -6NOUN NOUN PROP 140 134 -6ADJ NOUN PROP 32 27 -5Table 5: Top 10 POS mistakes made more often by eitherthe CTF-TM with parsing or the CTF-TM without on theATB part 1, 2, and 3 development set.Tag #Gold Tag #GoldNOUN 26195 INNA 1456ADJ 7491 SUB CONJ 641NOUN PROP 5913 VB PV PASS 231VB PV 3478 VB IV PASS 207VB IV 2682Table 6: Counts for the POS tags mentioned in Table 5.5 Related Work5.1 Semitic Language ParsingMuch of the Arabic parsing research to date uses thepipeline approach, either running a tokenizer prior toparsing or simply assuming the existence of gold to-kenization (Bikel, 2004; Buchholz and Marsi, 2006;Kulick et al 2006; Nivre et al 2007; Marton et al2010; Marton et al 2011; Marton et al 2013).
Ofcourse, using gold tokenization results in optimistic41evaluation figures.13Other methods exist however.
For example, toparse Modern Hebrew, Cohen and Smith (2007)combine a morphological model with a syntacticmodel using a product of experts.
Another alterna-tive is lattice parsing, which can be used to jointlymodel both tokenization and parsing (Chappelier etal., 1999).
Curiously, while researchers of Mod-ern Hebrew parsing find lattice parsers outperform-ing their pipeline systems (Goldberg and Tsarfaty,2008; Goldberg and Elhadad, 2011; Goldberg andElhadad, 2013), Green and Manning (2010) obtainthe opposite result in their Arabic parsing experi-ments, with the lattice parser underperforming thepipeline system by over 3 points (76.01 F1 vs 79.17F1).
Why lattice parsing may help in some cases butnot others is not clear.Some Arabic parsing work focuses on the useful-ness of various features and part-of-speech tagsets.Marton et al(2013) examine various morphologi-cal features and part-of-speech tagsets, employingMADA (Habash and Rambow, 2005; Habash et al2009) to predict form-based morphological featuresand an in-house system (Alkuhlani and Habash,2012) to predict functional morphological features.Dehdari et al(2011) investigate the best set of fea-tures for Arabic constituent parsing and try severalapproaches for selecting an optimal feature set, find-ing that the best-first with backtracking algorithm isthe most effective in their experiments.5.2 Other LanguagesThere has been a flurry of recent research involv-ing the joint modeling of dependency parsing andlower-level tasks14 for a variety of languages, withmost of the attention focused on Chinese.
Whilelacking Arabic?s morphological richness, Chinesehas its own challenges, such as word segmentationand part-of-speech ambiguities, which have led re-searchers to develop new unified approaches for pro-cessing it.
Qian and Liu (2012) train independentmodels for word segmentation, POS tagging, and13Green and Manning (2010) find that using automatic tok-enization provided by MADA (Habash et al 2009) instead ofgold tokenization results in a 1.92% F score drop in their con-stituent parsing work.14Systems that jointly model POS tagging and constituentparsing have existed for some time.parsing but then incorporate them together duringdecoding.
Li et al(2011), Li and Zhou (2012), Ha-tori et al(2011), and Ma et al(2012) present sys-tems that jointly model Chinese POS tagging anddependency parsing.
Li et al(2011) use a dy-namic programming approach similar to Koo andCollins (2010), Li and Zhou (2012) present a shift-reduce style system that uses structured perceptronand beam search, Hatori et al(2011) implementa shift-reduce style algorithm that utilizes dynamicprogramming and beam search in the manner ofHuang and Sagae (2010), and Ma et al(2012) ex-tend Goldberg and Elhadad?s (2010) easy-first ap-proach to support both dependency parsing and POStagging and is thus similar to our work.
Hatori et al(2012) extend their previous system to tackle wordsegmentation, and Ma et al(2013) build upon ear-lier work by implementing beam search to get bet-ter results.
Li and Zhou (2012) side step some ofthe issues of Chinese word segmentation by pars-ing structures of words, phrases, and sentences in aunified framework using a structured perceptron andbeam search.Some researchers focus their work on other lan-guages.
Lee et al(2011) present a graphical modelfor morphological disambiguation and dependencyparsing that they apply to Latin, Ancient Greek,Hungarian, and Czech.
Bohnet and Nivre (2012)present a shift-reduce style system similar to Liand Zhou?s (2012) system that jointly models POStagging and labeled dependency parsing, achievingstate-of-the-art accuracy on Czech, German, Chi-nese, and English.6 ConclusionIn this paper, we described cross-task flexible transi-tion models (CTF-TMs) and demonstrated their via-bility for Arabic tokenization, affix detection, affixlabeling, part-of-speech labeling, and dependencyparsing, obtaining very strong results in each tasks.We plan to release our software in the near future,including the software for converting the ATB to de-pendency parses, and would like to release our de-pendency conversion of the Penn Arabic Treebankvia the LDC.427 Future WorkIn the future, we plan to integrate beam search intothe training and decoding.
We want to add supportfor the recovery of diacritics, roots, and derivationtemplates, and we would like to apply modified ver-sions of our system to other languages.Our choice of anchors, operations, and constraintsrepresent one possible design for an Arabic CTF-TM.
Other options, such as creating unlabeled de-pendencies and adding labels in subsequent opera-tions, restricting clitic separation to a hand-craftedlist of clitics, utilizing information from a dictionaryor morphological analyzer, or following some sortof coarse-to-fine labeling scheme, are also possible,and we hope to investigate more of these options.ReferencesSarah Alkuhlani and Nizar Habash.
2012.
Identifyingbroken plurals, irregular gender, and rationality in ara-bic text.
In Proceedings of EACL 2012, pages 675?685.Mohammed Attia, Jennifer Foster, Deirdre Hogan,Joseph Le Roux, Lamia Tounsi, and Josef Van Gen-abith.
2010.
Handling Unknown Words in Statis-tical Latent-Variable Parsing Models for Arabic, En-glish and French.
In Proceedings of the NAACLHLT 2010 First Workshop on Statistical Parsing ofMorphologically-Rich Languages, pages 67?75.Dan M Bikel.
2004.
On the parameter space of gen-erative lexicalized statistical parsing models.
Ph.D.thesis, University of Pennsylvania.Bernd Bohnet and Joakim Nivre.
2012.
A transition-based system for joint part-of-speech tagging and la-beled non-projective dependency parsing.
In Proceed-ings of the 2012 Joint Conference on Empirical Meth-ods in Natural Language Processing and Computa-tional Natural Language Learning, pages 1455?1465.Sabine Buchholz and Erwin Marsi.
2006.
CoNLL-Xshared task on Multilingual Dependency Parsing.
InProceedings of the 10th Conference on ComputationalNatural Language Learning, pages 149?164.Jean-Ce?dric Chappelier, Martin Rajman, Ramo?nAragu?e?s, and Antoine Rozenknop.
1999.
LatticeParsing for Speech Recognition.
In Proc.
of 6e`meconfe?rence sur le Traitement Automatique du LangageNaturel (TALN 99), pages 95?104.Shay B Cohen and Noah A Smith.
2007.
Joint Morpho-logical and Syntactic Disambiguation.
In Proceedingsof the EMNLP-CoNLL 2007.Michael J. Collins.
2002.
Discriminative Training Meth-ods for Hidden Markov Models: Theory and experi-ments with Perceptron Algorithms.
In Proceedings ofthe 2002 Conference on Empirical Methods in NaturalLanguage Processing.Marie-Catherine de Marneffe and Christopher D. Man-ning.
2008.
The Stanford typed dependencies repre-sentation.
In COLING 2008: Proceedings of the work-shop on Cross-Framework and Cross-Domain ParserEvaluation.Jon Dehdari, Lamia Tounsi, and Josef van Gen-abith.
2011.
Morphological Features for ParsingMorphologically-Rich Languages: A Case of Arabic.In Proceedings of the Second Workshop on StatisticalParsing of Morphologically Rich Languages.Mona Diab.
2007.
Toward an Optimal POS Tag Set forModern Standard Arabic Processing.
In Proceedingsof Recent Advances in Natural Language Processing.Yoav Goldberg and Michael Elhadad.
2010.
An Ef-ficient Algorithm for Easy-First Non-Directional De-pendency Parsing.
In Human Language Technologies:The 2010 Annual Conference of the North AmericanChapter of the Association for Computational Linguis-tics, pages 742?750.Yoav Goldberg and Michael Elhadad.
2011.
Joint He-brew Segmentation and Parsing Using a PCFG-LALattice Parser.
In Proceedings of ACL 2011.Yoav Goldberg and Michael Elhadad.
2013.
Word Seg-mentation, Unknown-word Resolution, and Morpho-logical Agreement in a Hebrew Parsing System.
Com-putational Linguistics, 39(1):121?160.Yoav Goldberg and Reut Tsarfaty.
2008.
A Single Gen-erative Model for Joint Morphological Segmentationand Syntactic Parsing.
Proceedings of ACL-08: HLT.Spence Green and Christopher Manning.
2010.
BetterArabic Parsing: Baselines, Evaluations, and Analysis.In Proceedings of the 23rd International Conferenceon Computational Linguistics, pages 394?402.Nizar Habash and Owen Rambow.
2005.
Arabic Tok-enization, Part-of-Speech Tagging and MorphologicalDisambiguation in One Fell Swoop.
In Proceedings ofthe 43rd Annual Meeting of Association for Computa-tional Linguistics, pages 573?580.Nizar Habash and Ryan Roth.
2009.
CATiB: TheColumbia Arabic Treebank.
In Proceedings of theACL-IJCNLP 2009 Conference Short Papers.Nizar Habash, Owen Rambow, and Ryan Roth.
2009.MADA+TOKAN: A Toolkit for Arabic Tokenization,Diacritization, Morphological Disambiguation, POSTagging, Stemming and Lemmatization.
In Proceed-ings of the 2nd International Conference on ArabicLanguage Resources and Tools (MEDAR).Jan Hajic?, Otakar Smrz, Petr Zema?nek, Jan S?naidauf, andEmanuel Bes?ka.
2004.
Prague Arabic Dependency43Treebank: Development in Data and Tools.
In Pro-ceedings of the NEMLAR International Conference onArabic Language Resources and Tools.Jun Hatori, Takuya Matsuzaki, Yusuke Miyao, andJun?ichi Tsujii.
2011.
Incremental joint pos taggingand dependency parsing in chinese.
In IJCNLP, pages1216?1224.Jun Hatori, Takuya Matsuzaki, Yusuke Miyao, andJun?ichi Tsujii.
2012.
Incremental joint approach toword segmentation, pos tagging, and dependency pars-ing in chinese.
In Proceedings of the 50th AnnualMeeting of the Association for Computational Linguis-tics: Long Papers-Volume 1, pages 1045?1053.Liang Huang and Kenji Sagae.
2010.
Dynamic Program-ming for Linear-Time Shift-Reduce Parsing.
In Pro-ceedings of the 48th Annual Meeting of the Associationfor Computational Linguistics, pages 1077?1086.Terry Koo and Michael Collins.
2010.
Efficient Third-order Dependency Parsers.
In Proceedings of ACL2010, pages 1?11.Seth Kulick, Ryan Gabbard, and Mitchell Marcus.
2006.Parsing the Arabic Treebank: Analysis and Improve-ments.
In Proceedings of the Treebanks and LinguisticTheories Conference, pages 31?42.Seth Kulick.
2011.
Exploiting Separation of Closed-Class Categories for Arabic Tokenization and Part-of-Speech Tagging.
ACM Transactions on Asian Lan-guage Information Processing (TALIP), 10(1):4.John Lee, Jason Naradowsky, and David A Smith.
2011.A discriminative model for joint morphological dis-ambiguation and dependency parsing.
In Proceed-ings of the 49th Annual Meeting of the Associa-tion for Computational Linguistics: Human LanguageTechnologies-Volume 1, pages 885?894.Zhongguo Li and Guodong Zhou.
2012.
Unified depen-dency parsing of chinese morphological and syntacticstructures.
In Proceedings of the 2012 Joint Confer-ence on Empirical Methods in Natural Language Pro-cessing and Computational Natural Language Learn-ing, EMNLP-CoNLL ?12, pages 1445?1454.Zhenghua Li, Min Zhang, Wanxiang Che, Ting Liu, Wen-liang Chen, and Haizhou Li.
2011.
Joint models forchinese pos tagging and dependency parsing.
In Pro-ceedings of the Conference on Empirical Methods inNatural Language Processing, pages 1180?1191.Ji Ma, Tong Xiao, Jingbo Zhu, and Feiliang Ren.
2012.Easy-First Chinese POS Tagging and DependencyParsing.
In Proceedings of COLING 2012, pages1731?1746, Mumbai, India.Ji Ma, Jingbo Zhu, Tong Xiao, and Nan Yang.
2013.Easy-first pos tagging and dependency parsing withbeam search.
In Proceedings of the 51st Annual Meet-ing of the Association for Computational Linguistics(Volume 2: Short Papers), pages 110?114, Sofia, Bul-garia.
Association for Computational Linguistics.Mohamed Maamouri and Ann Bies.
2004.
Develop-ing an Arabic Treebank: Methods, Guidelines, Pro-cedures, and Tools.
In Proceedings of the Workshopon Computational Approaches to Arabic Script-basedlanguages, pages 2?9.Mohamed Maamouri, Ann Bies, Tim Buckwalter, andWigdan Mekki.
2004.
The Penn Arabic Treebank:Building a Large-Scale Annotated Arabic Corpus.
InNEMLAR Conference on Arabic Language Resourcesand Tools, pages 102?109.Mohamed Maamouri, Ann Bies, and Seth Kulick.
2012.Expanding Arabic Treebank to Speech: Results fromBroadcast News.
In Proceedings of LREC 2012.Yuval Marton, Nizar Habash, and Owen Rambow.
2010.Improving Arabic Dependency Parsing with Lexicaland Inflectional Morphological Features.
In Proceed-ings of the NAACL HLT 2010 First Workshop on Sta-tistical Parsing of Morphologically-Rich Languages.Yuval Marton, Nizar Habash, and Owen Rambow.
2011.Improving Arabic Dependency Parsing with Form-based and Functional Morphological Features.
In Pro-ceedings of the 49th Annual Meeting of the Associa-tion for Computational Linguistics: Human LanguageTechnologies, pages 1586?1596.Yuval Marton, Nizar Habash, and Owen Rambow.
2013.Dependency Parsing of Modern Standard Arabic withLexical and Inflectional Features.
Computational Lin-guistics, 39(1):161?194.Ryan McDonald and Joakim Nivre.
2007.
Character-izing the Errors of Data-Driven Dependency ParsingModels.
In Proceedings of the EMNLP-CoNLL 2007,pages 122?131.Joakim Nivre, Johan Hall, Sandra Ku?bler, Ryan McDon-ald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret.2007.
The CoNLL 2007 Shared Task on DependencyParsing.
In Proceedings of the CoNLL Shared TaskSession of EMNLP-CoNLL 2007.Joakim Nivre.
2009.
Non-Projective Dependency Pars-ing in Expected Linear Time.
In Proceedings of theJoint Conference of the 47th Annual Meeting of theACL and the 4th International Joint Conference onNatural Language Processing of the AFNLP.Xian Qian and Yang Liu.
2012.
Joint Chinese Word Seg-mentation, POS tagging and Parsing.
In Proceedingsof the 2012 Joint Conference on Empirical Methodsin Natural Language Processing and ComputationalNatural Language Learning, pages 501?511.Owen Rambow, David Chiang, Mona Diab, NizarHabash, Rebecca Hwa, Khalil Simaan, Vincent Lacey,Roger Levy, Carol Nichols, and Safiullah Shareef.2005.
Parsing arabic dialects.
In Final Report, JHUSummer Workshop.44Stephen Tratz and Eduard Hovy.
2011.
A Fast, Ac-curate, Non-Projective, Semantically-Enriched Parser.In Proceedings of EMNLP 2011.Stephen Tratz.
2011.
Semantically-Enriched Parsing forNatural Language Understanding.
Ph.D. thesis, Uni-versity of Southern California.Reut Tsarfaty.
2006.
Integrated Morphological and Syn-tactic Disambiguation for Modern Hebrew.
In Pro-ceedings of the 21st International Conference on Com-putational Linguistics and 44th Annual Meeting of theAssociation for Computational Linguistics: StudentResearch Workshop, pages 49?54.Yue Zhang and Stephen Clark.
2008.
Joint Word Seg-mentation and POS Tagging Using a Single Percep-tron.
In Proceedings of ACL 2008, pages 888?896.Imed Zitouni, Jeffrey S Sorensen, and Ruhi Sarikaya.2006.
Maximum entropy based restoration of Ara-bic diacritics.
In Proceedings of the 21st InternationalConference on Computational Linguistics and the 44thannual meeting of the Association for ComputationalLinguistics, pages 577?584.45
