Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 18?27,The University of Tokyo, September 24-25, 2010. c?2010 Association for Computational LinguisticsModeling User Satisfaction Transitions in Dialogues from Overall RatingsRyuichiro Higashinaka?, Yasuhiro Minami?, Kohji Dohsaka?, and Toyomi Meguro??
NTT Cyber Space Laboratories, NTT Corporation?
NTT Communication Science Laboratories, NTT Corporationhigashinaka.ryuichiro@lab.ntt.co.jp{minami,dohsaka,meguro}@cslab.kecl.ntt.co.jpAbstractThis paper proposes a novel approachfor predicting user satisfaction transitionsduring a dialogue only from the ratingsgiven to entire dialogues, with the aimof reducing the cost of creating refer-ence ratings for utterances/dialogue-actsthat have been necessary in conventionalapproaches.
In our approach, we firsttrain hidden Markov models (HMMs) ofdialogue-act sequences associated witheach overall rating.
Then, we combinesuch rating-related HMMs into a singleHMM to decode a sequence of dialogue-acts into state sequences representing towhich overall rating each dialogue-act ismost related, which leads to our rating pre-dictions.
Experimental results in two di-alogue domains show that our approachcan make reasonable predictions; it signif-icantly outperforms a baseline and nearsthe upper bound of a supervised approachin some evaluation criteria.
We alsoshow that introducing states that representdialogue-act sequences that occur com-monly in all ratings into an HMM signifi-cantly improves prediction accuracy.1 IntroductionIn recent years, there has been intensive workon the automatic evaluation of dialogues (Walkeret al, 1997; Mo?ller et al, 2008).
Automaticevaluation makes it possible to predict the per-formance of dialogue systems without the costlyprocess of performing surveys with human sub-jects, leading to a rapid improvement cycle fordialogue systems.
It is also useful for detect-ing problematic situations in an ongoing dialogue(Walker et al, 2002; Herm et al, 2008; Kim,2007).
In these studies, the typical approach isto train a prediction model, such as a regressionor classification model, using features represent-ing the whole or a part of a dialogue together withhuman reference labels (e.g., reference ratings).However, creating such reference labels by handcan be extremely costly when we want to predictuser satisfaction transitions during a dialogue be-cause we need to create reference labels after eachutterance/dialogue-act in the training data (Engel-brecht et al, 2009).This paper proposes a novel approach for pre-dicting user satisfaction transitions during a dia-logue only from the dialogues with overall rat-ings.
The approach makes it possible to avoidcreating reference labels for utterances/dialogue-acts and only requires a single reference label foreach dialogue.
More specifically, we predict theuser satisfaction rating after each dialogue-act in adialogue only by using dialogues with dialogue-level (overall) user satisfaction ratings as train-ing data.
Our basic approach is to train hid-den Markov models (HMMs) of dialogue-act se-quences associated with each overall rating andcombine such rating-related HMMs into a singleHMM.
We use this combined HMM to decode asequence of dialogue-acts by the Viterbi algorithm(Rabiner, 1990) into state sequences that indicatefrom which rating-related HMM each dialogue-actis most likely to have been generated, leading toour rating predictions for the dialogue-acts.
Thispaper experimentally examines the validity of ourapproach and explores several model topologiesfor possible improvement.In Section 2, we review related work on auto-matic evaluation of dialogues.
In Section 3, wedescribe our approach in detail.
In Section 4, wedescribe the experiment we performed to verifyour approach and present the results.
In Section5, we summarize and mention future work.2 Related WorkRegression models are typically utilized for eval-uating the quality of an entire dialogue.
Most fa-mously, the PARADISE framework (Walker et al,1997) learns from data a linear regression modelthat predicts dialogue-level user satisfaction fromvarious objective characteristics of a dialogue thatconcern task success and dialogue costs.
Thisframework is widely used today and a number ofextensions have been proposed to improve the pre-diction performance (Mo?ller et al, 2008); how-18ever, it is not aimed at predicting user satisfactiontransitions.Classification models are widely employed todetect problematic situations in an ongoing dia-logue.
Walker et al (2002) developed the Prob-lematic Dialogue Predictor for the ?How May IHelp You?
system (Gorin et al, 1997) to robustlytransfer problematic calls to human operators incall routing tasks.
They derive speech recogni-tion, language understanding, and dialogue man-agement features from the first few turns of a dia-logue and apply a decision tree classifier to detectproblematic calls.
For a similar task, Hirschberget al (2004) and Herm et al (2008) used prosodicand emotional features.
Kim (2007) recently pro-posed an approach for online call quality monitor-ing so that problematic calls can be transferred tohuman operators as quickly as possible rather thanwaiting for the first few turns.N-grams andHMM-based approaches have alsobeen actively studied.
Hara et al (2010) proposedpredicting the most likely user satisfaction level ofa dialogue by using N-grams of dialogues for eachsatisfaction level in the music navigation domain.Isomura et al (2009) used HMMs to evaluate thenaturalness of a dialogue in their interview system.They trained HMMs that model dialogue-act se-quences between human subjects and used them toevaluate human-machine dialogues by the outputprobabilities of the HMMs.
Recently, there havebeen approaches to predict user satisfaction tran-sitions by evaluating the quality of individual ut-terances in a dialogue.
For example, Engelbrechtet al (2009) predicted user satisfaction ratings af-ter each user utterance by HMMs trained fromutterance-level features and utterance-level refer-ence ratings.The problem with these approaches is that theyrequire a lot of training data, especially when wewant to predict the quality of smaller units suchas utterances.
Our aim is to reduce such cost.Our work is similar to Engelbrecht?s work (Engel-brecht et al, 2009) in that we useHMMs to predictuser satisfaction transitions during a dialogue butdifferent in that we only use dialogue-level ratingsto model dialogue-act-level user satisfaction tran-sitions.3 ApproachWe aim to predict user satisfaction transitions onlyfrom dialogues with overall ratings.
More for-mally, given a dialogue diof a set of dialoguesD (= {d1.
.
.dN}), we want to predict the usersatisfaction rating after each dialogue-act in di,namely, r?
(da(di, 1)) .
.
.r?
(da(di, mi)), using Dwith their dialogue-level ratings r(d1) .
.
.
r(dN).1:speaker1 2:speaker2Speaker HMM for Rating 13:speaker1 4:speaker2Speaker HMM for Rating 2Figure 1: SHMMs connected ergodically.
In thefigure, an oval marked with speaker1/speaker2indicates a state that emits speaker1/speaker2?sdialogue-acts.
Arrows denote transitions andnumbers before speaker1/speaker2 are state IDs.Boxes group together the states related to a partic-ular overall rating.Here, da(di, l) denotes the l-th dialogue-act in di,N the total number of dialogues, and mithe totalnumber of dialogue-acts in di.Our basic idea is to train HMMs representingdialogue-act sequences of dialogues for each over-all rating and combine these rating-related HMMsinto a single HMM that can assign ratings fordialogue-acts by estimating from which HMMeach dialogue-act has most likely to have beengenerated by the Viterbi decoding.
We use HMMsbecause they can deal with sequences that evolveover time and have been successfully utilized tomodel and evaluate dialogue-act sequences (Shi-rai, 1996; Isomura et al, 2009; Engelbrecht etal., 2009).
The generative feature of an HMM isalso useful when we want to build a probabilis-tic dialogue manager that produces the most likelydialogue-act sequences (Hori et al, 2008) or thataims to maximize a reward function in partiallyobservable Markov decision processes (Williamsand Young, 2007; Minami et al, 2009).When there are K levels of user satisfaction asoverall ratings, we create K HMMs each of whichis trained using the dialogue-act sequences in dia-logues Dk?
D, where Dk= {?di, |r(di) = k}.We use the EM-algorithm to train HMMs.
Here,we assume that each HMM has two states, eachof which emits dialogue-acts of one of the con-versational participants.
This type of HMM iscalled a speaker HMM (SHMM) and has beensuccessfully utilized to model two-party conversa-tion (Meguro et al, 2009).As an illustrative example, Fig.
1 shows twoSHMMs for ratings 1 and 2 that are connectedergodically.
We can simply use these connectedSHMMs (namely, states 1, 2, 3, and 4) to decode asequence of dialogue-acts into state sequences andthereby obtain rating predictions.
For example, ifthe optimal state sequence obtained by the Viterbidecoding is {4, 2, 1, 3, 2}, we can convert it intoratings <2, 1, 1, 2, 1> using the ratings associatedwith the states.193:speaker1 4:speaker21:speaker1 2:speaker25:speaker1 6:speaker2Speaker HMM for Rating 1Speaker HMM for Rating 2Speaker HMM for All RatingsFigure 2: SHMMs with an additional SHMMtrained from all dialogues.Introducing Common States: The simple er-godic model may not be sufficient for appropri-ately assigning ratings to input dialogue-act se-quences because it is often the case that thereare dialogue-act sequences, such as greetings andquestion-answer pairs, that commonly occur in ev-ery dialogue.
If we forcefully assign a rating forsuch dialogue-act sequences, it may result in de-grading the prediction accuracy.
Therefore, inaddition to the simple ergodic model, we intro-duce another SHMM that represents dialogue-actsequences of dialogues for all ratings (see Fig.2).
This additional SHMM models dialogue-actsequences that occur commonly in all dialoguesand it can simply be trained using all dialogues.Hence, we call the states in this SHMM commonstates.
When this SHMM is added to the ergodicmodel, it may be possible to reduce the possibil-ity of our having to forcefully assign inappropriatescores to common dialogue-act sequences.
In thismodel, when the optimal state sequence is {1, 4,5, 6, 2}, the predicted ratings become <1, 2, 0, 0,1>.
Here, we assume that the SHMM for all rat-ings corresponds to rating 0, which is reasonablebecause common dialogue-acts should not affectratings.
The obtained ratings can also be inter-preted as <1, 2, 2, 2, 1> when we assume thatthe rating of a dialogue-act is taken over from theprevious turn.Using Concatenated Training: We have so farpresented two model topologies, one with KSHMMs connected ergodically and the other withK + 1 SHMMs having an additional SHMM rep-resenting all ratings.
However, we still have aproblem; that is, we need to find optimal transi-tion probabilities between the SHMMs of differentratings.
Our solution is to use concatenated train-ing (Lee, 1989).
The procedure for concatenatedtraining is illustrated in Fig.
3 and has the follow-ing three steps.step 1 Train an SHMM Mk(Mk?
M, 1 ?k ?
K) using dialogues Dk, where Dk=CopyRating1M1M1M0RetrainTrainRatingkM0MkMkRetrainTrainRatingKM0MKMKRetrainTrainAllRatingsM0Train+M0M1 Mk MKAVGConcatenateM1+0 Mk+0 MK+0M1M0 M0 MkM0 MKM1+0 Mk+0 MK+0Step 1Step 2Step 3Step 2?ENDMconcatIf the fitting hasconverged forall Mk+0Split Mconcat intopairs again andretrain Mk+0M1?MK becomeless likely tooutput commonsequencesTransition probabilitiesof M0 are redistributedbetween M0 and MkFigure 3: Three steps to combine SHMMs usingconcatenated training.
{?di|r(di) = k}, and an SHMM M0usingall dialogues; i.e., D. Here, K means themaximum level of user satisfaction and r(di)the rating assigned to di.step 2 Connect each Mk?
M with a copy ofM0using equal initial and transition proba-bilities (we call this connected model Mk+0)and retrain Mk+0with ?di?
Dk, wherer(di) = k.step 3 Merge all models Mk+0(1 ?
k ?
K) toproduce one concatenated HMM (Mconcat).Here, the output probabilities of the copiesof M0are averaged over K when all modelsare merged to create a combined model.
Ifthe fitting of all Mk+0models has convergedagainst the training data, exit this procedure;otherwise, go to step 2 by connecting a copyof M0and Mkfor all k. Here, the transi-tion probabilities from M0to Ml(l 6= k) aresummed and equally distributed between thecopied M0?s self-loop and transitions to thestates in Mk.In concatenated training, the transition and out-put probabilities can be optimized between M0and Mk, meaning that the output probabilitiesof dialogue-act sequences that are common andalso found in Mkcan be moved from MktoM0.
This makes the distribution of Mksharp (notbroad/uniform), making it likely to output onlythe dialogue-acts specific to a rating k. As re-gards M0, its distribution of output probabilitiescan also be sharpened for dialogue-acts that oc-cur commonly in all ratings.
This sharpening ofdistributions is likely to be helpful in assigning20appropriate ratings to dialogue-act sequences.
Inthe next section, we experimentally examine howthese proposed HMMs perform in modeling andpredicting user satisfaction transitions in dialogue.4 ExperimentTo verify our approach, we first prepared dialoguedata.
Then, we trained our HMMs and comparedthem with a random baseline and an upper boundthat uses a supervised approach; that is, an HMMis trained using reference labels on the dialogue-act level.4.1 Dialogue DataWe used dialogues in two domains; the animaldiscussion (AD) domain and the attentive listen-ing (AL) domain.
All dialogues are in Japanese.In both domains, the data we used were text dia-logues.
We did not use spoken dialogue data be-cause we wanted to avoid particular problems ofvoice, such as filled pauses and overlaps, althoughwe aim to deal with spoken dialogue in the future.4.1.1 Animal DiscussionWe used the dialogue data in the AD domain thatwe previously collected (Higashinaka et al, 2008).In this domain, the system and user talk about likesand dislikes about animals via a text chat inter-face.
The data consist of 1000 dialogues betweena dialogue system and 50 human users.
Eachuser conversed with the system 20 times, includ-ing two example dialogues at the beginning.
Alluser/system utterances have been annotated withdialogue-acts.
There are 29 dialogue-act types in-cluding those related to self-disclosure, question,response, and greetings.
For example, a dialogue-act DISC-P denotes one?s self-disclosure about aproposition P. Here, P is either like(X,A) ordislike(X,A) where X is a conversational par-ticipant and A a certain animal.
DISC-R denotesone?s self-disclosure of a reason for a proposition.See (Higashinaka et al, 2008) for the details of thedialogue-acts.For our experiment, we created two subsets ofthe data.
We first extracted 180 dialogues bytaking all 18 non-example dialogues for the ini-tial ten users sorted by user ID (AD-SUB1; 4147user dialogue-acts and 6628 system dialogue-acts).
Then, from AD-SUB1, we randomly ex-tracted nine dialogues per user to form anothersubset of 90 dialogues (AD-SUB2; 2050 userdialogue-acts and 3290 system dialogue-acts).
Anannotator, who was not one of the authors, la-beled AD-SUB1 with dialogue-level user satis-faction ratings and AD-SUB2 with utterance-levelratings.
More specifically, each dialogue/utteranceUtterance (dialogue-acts) Sm Cl WiSYS Do you like rabbits?
(DA: Q-DISC-P) 6 6 6USR I like rabbits.
They are cute.
(DA: DISC-P, DISC-R)SYS Indeed they are cute.
(DA: REPEAT) 6 6 6SYS Tell me why you like rabbits.
6 5 6(DA: Q-DISC-R-OTHER)USR I like them because they are small andwarm.
(DA: DISC-P-R)SYS You like them because they are warm.
7 5 7(DA: REPEAT)Overall rating for the dialogue 7 5 6Figure 4: Excerpt of a dialogue with utterance-level user satisfaction ratings for smoothness(Sm), closeness (Cl), and willingness (Wi) in theAD domain.
SYS and USR denote system anduser, respectively.
The dialogue was translated bythe authors.was given three different user satisfaction rat-ings related to ?Smoothness of the conversation?,?Closeness perceived by the user towards the sys-tem?, and ?Willingness to continue the conversa-tion?.
The ratings ranged from 1 to 7, where 1is the worst and 7 the best (see Fig.
4 for exam-ples of utterance-level and overall ratings given bythe annotator for an excerpt of a dialogue).
In amanner similar to (Evanini et al, 2008), we used athird-person?s user satisfaction rating for the sakeof consistency.For utterance-level ratings, the annotator care-fully read each utterance and gave ratings aftereach system utterance according to how she wouldhave felt after receiving each system utterance ifshe had been the user in the dialogue.
To makethe situation more realistic, she was not allowedto look down at the dialogue after the current ut-terance.
At the beginning of a dialogue, the rat-ings always started from four (neutral).
When theannotator gave dialogue-level ratings, she lookedthrough the entire dialogue and rated its quality(smoothness, closeness, and willingness) accord-ing to how she would have felt after having hadthe dialogue in question.4.1.2 Attentive ListeningWe collected human-human listening-oriented di-alogues in a manner similar to (Meguro et al,2009).
In this AL domain, a listener attentivelylistens to the other in order to satisfy the speaker?sdesire to speak and to make himself/herself heard.We collected such listening-oriented dialogues us-ing a website where users taking the roles of lis-teners and speakers were matched up to have con-versations.
There were ten listeners who alwaysstayed at the website and 37 speakers who couldtalk to them anytime the listeners were available.They were all paid for their participation.
A con-versation was done through a text-chat interface.21The use of facial and other non-linguistic expres-sions were not allowed for analysis purposes.
Theparticipants were instructed to end the conversa-tion approximately after ten minutes.
Within athree-week period, each speaker was instructed tohave at least two conversations a day, resulting inour collecting 1260 listening-oriented dialogues.Two independent annotators labeled each utter-ance with 40 dialogue-act types, including thoserelated to self-disclosure, question, internal argu-ment, sympathy, and information giving.
Theinter-annotator agreement was reasonable, with0.57 in Cohen?s ?.
Although we cannot describethe full details of our dialogue-acts for lack ofspace, we have dialogue-acts DISC-EVAL-POS forone?s self-disclosure of his/her positive evalua-tion towards a certain entity, DISC-EXP for one?sself-disclosure of his/her experience, and SELF-Q-DESIRE for one?s internal argument about his/herdesire (e.g., ?Have I ever wanted to go abroad??
).We used the dialogue-act annotation of one of theannotators in this work.An annotator gave dialogue-level user satis-faction ratings to all 1260 dialogues (AL-ALL;31779 speaker dialogue-acts and 28681 listenerdialogue-acts).
Then, we made a subset of thedata by randomly selecting ten dialogues foreach of the ten listeners to obtain 100 dialogues(AL-SUB1; 2453 speaker dialogue-acts and 2197listener dialogue-acts).
Finally, the annotatorgave utterance-level ratings to AL-SUB1.
Theutterance-level ratings were given only after lis-teners?
utterances.
The annotator gave three rat-ings as in the AD domain; namely, smoothness,closeness, and good listening.
Instead of willing-ness, we have a ?good listener?
criterion askingfor how good the annotator thinks the listener isfrom the viewpoint of attentive listening; for ex-ample, how well the listener is making it easy forthe speaker to speak.
All ratings ranged from 1 to7.
See Fig.
5 for a sample dialogue in the AL do-main with utterance-level and overall ratings givenby the annotator.4.2 Training HMMsFrom the dialogue data and their dialogue-levelratings, we created our proposed HMMs.
We hadfive topology variations:ergodic0: The simple ergodic model with no ad-ditional SHMM for all ratings.
See Fig.1 for the topology.
This HMM has 7SHMMs connected ergodically with equalinitial/transition probabilities.ergodic1: The simple ergodic model with an ad-ditional SHMM for all ratings.
See Fig.
2for the topology.
This HMM has 8 (7 +Utterance (dialogue-acts) Sm Cl GLLIS You know, in spring, Japanese food tastes de-licious.
(DA: DISC-EVAL-POS)5 5 5SPK This time every year, I make a plan to go ona healthy diet.
But .
.
.
(DA: DISC-HABIT)LIS Uh-huh (DA: ACK) 6 5 6SPK The temperature goes up suddenly!
(DA: INFO)SPK It?s always too late!
(DA: DISC-EVAL-NEG)LIS Clothing worn gets less and less while not be-ing able to lose weight.
(DA: DISC-FACT)6 6 6SPK Well, people around me soon get used to mybody shape though.
(DA: DISC-FACT)Overall rating for the dialogue 7 7 7Figure 5: Excerpt of a dialogue with utterance-level user satisfaction ratings for smoothness(Sm), closeness (Cl), and good listener (GL) in theAL domain.
SPK and LIS denote speaker and lis-tener, respectively.
Both the speaker and listenerare human.1) SHMMs connected ergodically with equalinitial/transition probabilities.ergodic2: Same as ergodic1 except that the num-ber of common states is doubled so that com-mon dialogue-act sequences can be more ac-curately modeled.
Note that without concate-nated training, SHMMs for each rating mayalso have sharp distributions for common se-quences.
One possible solution to avoid thisis to sharpen the distributions of commonstates by increasing its number of states.concat1: 8 (7 + 1) SHMMs combined using con-catenated training.
See Fig.
3 for the topol-ogy.concat2: Same as concat1 except that the numberof common states is doubled.
[See Appendices A and B for the actual examplesof the obtained models]4.2.1 Baseline and Upper BoundWe created the following baseline (random) andupper bound (supervised) models for comparison:random: This outputs ratings 1?7 at random.supervised: This is an HMM trained in a man-ner similar to (Engelbrecht et al, 2009).
Thismodel is the same as ergodic0 in topology butdifferent in that the initial, transition, and out-put probabilities are trained in a supervisedmanner using the dialogue-acts and dialogue-act-level reference ratings in AD-SUB2 andAL-SUB1.
Since we only have ratings forsystem/listener utterances in the corpora, inorder to make training data, we assumed thatthe ratings for dialogue-acts correspondingto user/speaker utterances were the same as22those after the previous system/listener utter-ances.
This model simulates the ideal situ-ation where we possess user satisfaction rat-ings for all dialogue-acts in the data.4.3 Evaluation ProcedureWe performed a ten-fold cross validation.
We firstseparated utterance-level labeled data (i.e., AD-SUB2 or AL-SUB1) into 10 disjoint sets.
Then,for each set S, we used dialogue-level labeleddata (i.e., AD-SUB1 or AL-ALL) excluding Sfor training HMMs.
Here, ?supervised?
only usedthe utterance-level labeled data excluding S fortraining.
Then, we made the models (i.e., er-godic0, ergodic1, ergodic2, concat1, concat2, ran-dom and supervised) output rating sequences forthe dialogue-acts in S and evaluated them with thereference ratings in S. We repeated this processten times to evaluate the overall performance.Since utterance-level ratings are provided onlyafter system/listener utterances, we only evaluatedratings after dialogue-acts corresponding to sys-tem/listener utterances.
When a system/listenerutterance contained multiple dialogue-acts, thedialogue-acts were assumed to have the same rat-ing as that utterance.
When the output ratingsequences contain 0, which can be the case forergodic1?2 and concat1?2, the 0 is replaced by themost previous non-zero rating.
When 0 is found atthe beginning of a dialogue, it remained 0.
Al-though our reference ratings always started withfour (cf.
Section 4.1.1), we did not use this in-formation to fill initial zeros because we wantedto evaluate the prediction accuracy when we donot have any prior knowledge.
Since some mod-els may benefit from avoiding evaluating dialogue-acts at the beginning because of these zeros, wesimply compared the rating sequences where allmodels produced non-zero values.
For exam-ple, when we have three output rating sequences<0,5,6,0,4>, <0,0,1,2,0>, and <1,2,3,4,5> for agiven dialogue-act sequence, the zeros that follownon-zero values are first filled with their preceed-ing values, and thereby we obtain <0,5,6,6,4>,<0,0,1,2,2>, and <1,2,3,4,5>.
Then, by croppingthe common non-zero span, we obtain <6,6,4>,<1,2,2>, and <3,4,5>, and use these rating se-quences for evaluation.4.3.1 Evaluation CriteriaWe used two kinds of evaluation criteria: one forevaluating individual matches and the other forevaluating distributions.Evaluating Individual Matches: We used thematch rate and mean absolute error to evaluate thematching of reference and hypothesis rating se-quences.
They are derived by the equations shownbelow.
In the equations, R (= {R1.
.
.RL}) andH (= {H1.
.
.HL}) denote reference and hypoth-esis rating sequences for a dialogue, respectively.L is the length of R and H (Note that they havethe same length).?
Match Rate (MR)MR(R, H) = 1LL?i=1match(Ri, Hi), (1)where ?match?
returns 1 or 0 depending onwhether a rating in R matches that in H .?
Mean Absolute Error (MAE)MAE(R, H) = 1LL?i=1|Ri?
Hi|.
(2)Evaluating Distributions: In generative mod-els, it is important that the output distributionmatches that of the reference.
Therefore, we ad-ditionally use Kullback-Leibler divergence, matchrate per rating, and mean absolute error per rat-ing.
The Kullback-Leibler divergence evaluatesthe shape of output distributions.
The match rateper rating and mean absolute error per rating eval-uate how accurately each individual rating canbe predicted; namely, the accuracy for predict-ing dialogue-acts with one rating is equally val-ued with those for other ratings irrespective of thedistribution of ratings in the reference.
It is im-portant to use these metrics in the practical as wellas information theoretic sense because it is no usepredicting only easy-to-guess ratings; we shouldbe able to correctly predict rare but still importantcases.
For example, rating 1 in human-human di-alogue is quite rare; however, predicting it is veryimportant for detecting problematic situations in adialogue.?
Kullback-Leibler Divergence (KL)KL(R,H) =K?r=1P(H, r) ?
log(P(H, r)P(R, r)), (3)where K is the maximum user satisfaction rating(i.e.
7 in this experiment),R andH denote the se-quentially concatenated reference/hypothesis rat-ing sequences of the entire dialogues, and P(?, r)denotes the occurrence probability that a rating ris found in an arbitrary rating sequence.?
Match Rate per rating (MR/r)MR/r(R,H) = 1KK?r=1?i?{i|Ri=r}match(Ri,Hi)?i?
{i|Ri=r}1,(4)23Criterion random ergodic0 ergodic1 ergodic2 concat1 concat2 supervisedSmoothnessMR 0.142e0e10.111 0.111 0.157e0e10.153 0.199e0e1r0.275c1e0e1e2rMAE 1.988e0e12.212 2.212 1.980 1.936e0e11.870e0e11.420c1c2e0e1e2rKL 0.287 0.699 0.699 0.562 0.280 0.369 0.162MR/r 0.143 0.137 0.137 0.176 0.136 0.177 0.217MAE/r 2.286 2.414 2.414 2.152 2.301 2.206 1.782ClosenessMR 0.143 0.129 0.129 0.171e0e10.174 0.189e0e10.279c1c2e0e1e2rMAE 2.028 2.066 2.066 1.964 1.798e0e1r1.886 1.431c1c2e0e1e2rKL 0.195 0.449 0.449 0.261 0.138 0.263 0.092MR/r 0.143 0.156 0.156 0.170 0.155 0.164 0.231MAE/r 2.283 2.236 2.236 2.221 2.079 2.067 1.702WillingnessMR 0.143e0e10.112 0.112 0.180e0e10.152 0.183e0e10.283c1c2e0e1e2rMAE 2.005 2.133 2.133 1.962 1.801e0e1r1.882 1.403c1c2e0e1e2rKL 0.225 0.568 0.568 0.507 0.238 0.255 0.125MR/r 0.143 0.152 0.152 0.192 0.181 0.167 0.224MAE/r 2.286 2.258 2.258 2.107 1.958 2.164 1.705Table 1: The match rate (MR), mean absolute error (MAE), Kullback-Leibler divergence (KL), matchrate per rating (MR/r) and mean absolute error per rating (MAE/r) for our proposed HMMs, the randombaseline, and the upper bound (supervised) for the AD domain.
?e0?e2?, ?c1?c2?, and ?r?
indicate the sta-tistical significance (p<0.01) over ergodic0?2, concat1?2, and random, respectively.
Bold font indicatesthe best value within each row (except for ?supervised?
).whereRiandHidenote ratings at i-th positions.?
Mean Absolute Error per rating (MAE/r)MAE/r(R,H) = 1KK?r=1?i?{i|Ri=r}|Ri?Hi|?i?{i|Ri=r}1.
(5)4.4 Evaluation ResultsTables 1 and 2 show the evaluation results for theAD and AL domains, respectively.
The MR andMAE values are averaged over all dialogues.
Tocompare the means of the MR and MAE, we per-formed a non-parametric multiple comparison test[Steel-Dwass test (Dwass, 1960)].
We did not per-form a statistical test for other criteria because itwas difficult to perform sample-wise comparisonfor distributions.
Naturally, ?supervised?
is thebest performing model for all criteria in both do-mains.
Therefore, we focus on how much our pro-posed models differ from the baseline (random)and the upper bound (supervised).In the AD domain, we find that ergodic0 and er-godic1 performed rather poorly and concat1 andconcat2 performed fairly well, significantly out-performing the random baseline.
However, it isalso clear that we still need a great deal of im-provement for our models to reach the level of?supervised?.
A promising sign is that concat2is not significantly different from ?supervised?
insmoothness.
Here, ergodic0 and ergodic1 re-turned the exact same results.
This means that thestate transition paths did not go through the com-mon states at all in ergodic1, suggesting that thecommon states in ergodic1 have very broad out-put distributions and the optimal path could notgo through the common states, instead preferringother states having sharper distributions.
How-ever, this phenomenon was rightly avoided by in-troducing more common states as seen in the re-sults for ergodic2; nonetheless, as the results forconcat1 and concat2 indicate, the transition prob-abilities have to be trained appropriately to obtainbetter results.In the AL domain, although the tendency ofthe evaluation results is the same as that for theAD domain, concat2 is clearly the best perform-ing model.
It outperformed other models in al-most all cases except for ?Good Listener?
forwhich concat1 performed better.
In fact, the MR/rand MAE/r of concat1 are quite close to those of?supervised?, suggesting the potential of our ap-proach.Overall, although we still need further improve-ment in order for our models to be closer to theupper bound, we showed that we can, to some ex-tent, predict user satisfaction transitions in a dia-logue only from overall ratings of dialogues usingour proposed HMMs.
We also showed that modeltopologies and learning methods can make signif-icant differences.
Especially, we found the intro-duction of common states to be crucial in makingappropriate models for prediction.
Since our mod-els, especially concat2, significantly outperformedthe baseline, we believe that our approach can beone of the viable options for automatically predict-ing user satisfaction transitions when there existonly overall rating data.5 Summary and Future WorkWe presented a novel approach for modeling usersatisfaction transitions only from dialogues withoverall ratings.
The experimental results show thatit is possible to predict user satisfaction transi-24Criterion random ergodic0 ergodic1 ergodic2 concat1 concat2 supervisedSmoothnessMR 0.143e0e1e20.069 0.069 0.131e0e10.173e0e10.243c1e0e1e2r0.439c1c2e0e1e2rMAE 1.868e0e1e22.519 2.519 2.433 1.687e0e1e2r1.594e0e1e2r0.802c1c2e0e1e2rKL 0.989 2.253 2.253 2.319 0.851 0.753 0.087MR/r 0.141 0.118 0.118 0.156 0.161 0.167 0.231MAE/r 2.289 2.500 2.500 2.492 2.093 2.077 1.868ClosenessMR 0.143e0e10.050 0.050 0.175e0e10.158e0e10.263c1e0e1e2r0.425c1c2e0e1e2rMAE 1.849e0e1e22.357 2.357 2.316 1.778e0e1e21.562e0e1e2r0.890c1c2e0e1e2rKL 1.022 2.137 2.137 2.220 1.155 0.909 0.109MR/r 0.143 0.090 0.090 0.122 0.117 0.159 0.237MAE/r 2.281 2.577 2.577 2.811 2.260 2.039 1.972Good ListenerMR 0.143e0e10.075 0.075 0.145e0e10.199e0e10.206e0e1e20.422c1c2e0e1e2rMAE 1.890e0e1e22.237 2.237 2.150 1.634e0e1e2r1.634e0e1e2r0.852c1c2e0e1e2rKL 0.945 1.738 1.738 1.782 0.924 0.824 0.087MR/r 0.143 0.121 0.121 0.184 0.224 0.200 0.227MAE/r 2.284 2.358 2.358 2.236 1.911 2.083 1.769Table 2: Evaluation results for the AL domain.
See Table 1 for the notations in the table.tions to some extent by our approach and that in-troducing common states and concatenated train-ing can significantly improve prediction accuracy.For improvement, we plan to explore new dialogicfeatures for emissions, different topologies, andother optimization functions, such as discrimina-tive ones.
We also need to validate our approachusing dialogue-act recognition results instead ofhand-labeled dialogue-acts.
We also want to ap-ply our approach to sequence mining in dialogueswhere we have categories instead of ratings for di-alogues.
It is also necessary to test whether ourHMMs can be generalized over different raters,since user satisfaction ratings may differ greatlyamong individuals.
Although there remain suchissues, we believe we have presented a new di-rection in automatic evaluation of dialogues andthe experimental results show that our approach ispromising.ReferencesMeyer Dwass.
1960.
Some k-sample rank-order tests.
InIngram Olkin et al, editor, Contributions to Probabilityand Statistics, pages 198?202.
Stanford University Press.Klaus-Peter Engelbrecht, Florian Go?dde, Felix Hartard,Hamed Ketabdar, and Sebastian Mo?ller.
2009.
Model-ing user satisfactionwith hidden Markov models.
In Proc.SIGDIAL, pages 170?177.Keelan Evanini, Phillip Hunter, Jackson Liscombe, DavidSuendermann, Krishna Dayanidhi, and Roberto Pierac-cini.
2008.
Caller experience: A method for evaluatingdialog systems and its automatic prediction.
In Proc.
SLT,pages 129?132.Allen L. Gorin, Giuseppe Riccardi, and Jerry H. Wright.1997.
How may I help you?
Speech Communication,23(1-2):113?127.Sunao Hara, Norihide Kitaoka, and Kazuya Takeda.
2010.Estimation method of user satisfaction using N-gram-based dialog history model for spoken dialog system.
InProc.
LREC, pages 78?83.Ota Herm, Alexander Schmitt, and Jackson Liscombe.
2008.When calls go wrong: How to detect problematic callsbased on log-files and emotions?
In Proc.
INTER-SPEECH, pages 463?466.Ryuichiro Higashinaka, Kohji Dohsaka, and Hideki Isozaki.2008.
Effects of self-disclosure and empathy in human-computer dialogue.
In Proc.
SLT, pages 109?112.Julia Hirschberg, Diane Litman, and Marc Swerts.
2004.Prosodic and other cues to speech recognition failures.Speech Communication, 43:155?175.Chiori Hori, Kiyonori Ohtake, Teruhisa Misu, Hideki Kash-ioka, and Satoshi Nakamura.
2008.
Dialog managementusing weighted finite-state transducers.
In Proc.
INTER-SPEECH, pages 211?214.Naoki Isomura, Fujio Toriumi, and Kenichiro Ishii.
2009.Evaluation method of non-task-oriented dialogue systemusingHMM.
IEICE Transactions on Information and Sys-tems, J92-D(4):542?551.Woosung Kim.
2007.
Online call quality monitoring forautomating agent-based call centers.
In Proc.
INTER-SPEECH, pages 130?133.Kai-Fu Lee.
1989.
Automatic speech recognition: the de-velopment of the SPHINX system.
Kluwer Academic Pub-lishers.ToyomiMeguro, Ryuichiro Higashinaka,Kohji Dohsaka,Ya-suhiro Minami, and Hideki Isozaki.
2009.
Analysis oflistening-oriented dialogue for building listening agents.In Proc.
SIGDIAL, pages 124?127.Yasuhiro Minami, Akira Mori, Toyomi Meguro, RyuichiroHigashinaka, Kohji Dohsaka, and Eisaku Maeda.
2009.Dialogue control algorithm for ambient intelligence basedon partially observable Markov decision processes.
InProc.
IWSDS, pages 254?263.Sebastian Mo?ller, Klaus-Peter Engelbrecht, and RobertSchleicher.
2008.
Predicting the quality and usability ofspoken dialogue services.
Speech Communication, 50(8-9):730?744.Lawrence R. Rabiner.
1990.
A tutorial on hidden Markovmodels and selected applications in speech recognition.Readings in speech recognition, 53(3):267?296.Katsuhiko Shirai.
1996.
Modeling of spoken dialogue withand without visual information.
In Proc.
ICSLP, vol-ume 1, pages 188?191.Marilyn A. Walker, Diane Litman, Candace A. Kamm, andAlicia Abella.
1997.
PARADISE: A framework for evalu-ating spoken dialogue agents.
In Proc.
EACL, pages 271?280.Marilyn A. Walker, Irene Langkilde-Geary, Helen WrightHastie, Jerry Wright, and Allen Gorin.
2002.
Automat-ically training a problematic dialogue predictor for a spo-ken dialogue system.
Journal of Artificial Intelligence Re-search, 16(1):293?319.Jason D. Williams and Steve Young.
2007.
Partially ob-servableMarkov decision processes for spokendialog sys-tems.
Computer Speech & Language, 21(2):393?422.25Appendix A. HMM obtained by concat2 for Willingness rating in the AD domain.This HMM is the model obtained for one of the folds in the experiment.
Square and oval states emita system?s dialogue-act and a user?s dialogue-act, respectively.
Emissions (dialogue-acts) are shown ineach state as a table with their probabilities.
Only the emissions and transitions over the probability of0.1 are displayed for the sake of brevity.
Here, ?pi?
denotes initial probability.rating:0rating:1rating:2rating:3rating:4rating:5rating:6rating:7SYSTEM(pi:0.00)ACK0.35DISC-AGREE-P0.14DISC-DISAGREE-P0.14REPEAT0.10SYSTEM(pi:1.00)DISC-R-OTHER0.17Q-DISC-R0.23Q-DISC-R-OTHER0.240.35USER(pi:0.00)ACK0.14DISC-R-OTHER0.300.130.37USER(pi:0.00)DISC-P0.40DISC-R0.260.310.610.120.490.15SYSTEM(pi:0.00)ACK0.81EMP0.110.270.26USER(pi:0.00)ACK0.30DISC-OTHER0.14OTHER0.27Q-DISC-P0.100.330.120.260.56SYSTEM(pi:0.00)ACK0.77Q-DISC-P0.140.210.220.220.11USER(pi:0.00)OTHER0.29Q-DISC-OTHER0.20Q-DISC-R0.230.230.230.160.59SYSTEM(pi:0.00)DISC-AGREE-P0.33DISC-P0.13GOODBYE0.11Q-DISC-P0.22Q-DISC-P-OPEN0.180.190.22USER(pi:0.00)DISC-P0.46OTHER0.26Q-DISC-R0.180.460.620.120.21SYSTEM(pi:0.00)DISC-DISAGREE-P0.46DISC-P0.20DISC-P-R0.12GOODBYE0.150.540.19USER(pi:0.00)DISC-P-R0.10GREETING0.14Q-DISC-OTHER0.21Q-DISC-R0.19RES0.100.220.610.200.15SYSTEM(pi:0.00)DISC-AGREE-P0.28DISC-R0.10EMP0.14REPEAT0.170.510.150.14SYSTEM(pi:0.00)DISC-DISAGREE-P0.35DISC-P0.13DISC-R0.15Q-DISC-P-OPEN0.150.25 0.110.320.16USER(pi:0.00)DISC-DISAGREE-OTHER0.16DISC-OTHER0.27DISC-P-R0.14EMP0.18REPEAT0.160.170.520.170.19SYSTEM(pi:0.00)DISC-P0.14DISC-R0.15DISC-R-OTHER0.45GOODBYE0.11Q-DISC-P0.160.160.160.18USER(pi:0.00)ACK0.31DISC-OTHER0.23EMP0.10REPEAT0.100.460.510.20USER(pi:0.00)DISC-R-OTHER0.41GOODBYE0.12Q-DISC-OTHER0.22REPEAT0.120.370.160.4526Appendix B. HMM obtained by concat1 for Good Listener rating in the AL domain.This HMM is the model obtained for one of the folds in the experiment.
Square and oval states emit a lis-tener?s dialogue-act and a speaker?s dialogue-act, respectively.
We find DICS-EVAL-NEG (self-disclosureof one?s evaluation with a negative polarity) in the rating score 1 and DICS-EVAL-POS in the rating score7, indicating that it may be better to make speakers talk about positive evaluations to be a good listener.rating:0rating:1rating:2rating:3rating:4rating:5rating:6rating:7LISTENER(pi:0.16)GREETING0.13DISC-FACT0.10DISC-EVAL-POS0.110.22SPEAKER(pi:0.41)GREETING0.13DISC-FACT0.15SYNPATHY0.150.350.320.26LISTENER(pi:0.01)GREETING0.28DISC-FACT0.19INFO0.150.120.240.32SPEAKER(pi:0.14)GREETING0.23Q-FACT0.13DISC-EVAL-NEG0.120.330.240.120.320.33LISTENER(pi:0.00)DISC-FACT0.21INFO0.180.160.250.23SPEAKER(pi:0.00)INFO0.22Q-FACT0.120.360.270.140.350.24LISTENER(pi:0.00)DISC-FACT0.32Q-FACT0.24THANK0.10Q-INFO0.110.150.340.18SPEAKER(pi:0.00)DISC-FACT0.34DISC-EVAL-NEG0.120.330.390.130.210.27LISTENER(pi:0.04)GREETING0.23SYNPATHY0.16Q-FACT0.140.180.380.22SPEAKER(pi:0.10)GREETING0.31Q-FACT0.10DISC-EVAL-NEG0.150.230.240.160.410.19LISTENER(pi:0.00)SYNPATHY0.17DISC-EVAL-POS0.200.160.230.23SPEAKER(pi:0.00)DISC-FACT0.27SYNPATHY0.20DISC-EVAL-POS0.170.390.220.150.310.32LISTENER(pi:0.00)SYNPATHY0.19DISC-EVAL-POS0.24CONFIRM0.140.210.240.22SPEAKER(pi:0.00)SYNPATHY0.26DISC-EVAL-POS0.23INFO0.25DISC-EXP0.110.330.210.210.290.29LISTENER(pi:0.04)GREETING0.24DISC-EVAL-POS0.22INFO0.11CONFIRM0.130.170.240.22SPEAKER(pi:0.10)GREETING0.18DISC-FACT0.26DISC-EVAL-POS0.16INFO0.180.380.260.120.310.3027
