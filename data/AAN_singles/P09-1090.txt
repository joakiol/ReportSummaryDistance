Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 800?808,Suntec, Singapore, 2-7 August 2009. c?2009 ACL and AFNLPCase markers and Morphology: Addressing the crux of the fluencyproblem in English-Hindi SMTAnanthakrishnan Ramanathan, Hansraj ChoudharyAvishek Ghosh, Pushpak BhattacharyyaDepartment of Computer Science and EngineeringIndian Institute of Technology BombayPowai, Mumbai-400076India{anand, hansraj, avis, pb}@cse.iitb.ac.inAbstractWe report in this paper our work onaccurately generating case markers andsuffixes in English-to-Hindi SMT.
Hindiis a relatively free word-order language,and makes use of a comparatively richerset of case markers and morphologicalsuffixes for correct meaning representa-tion.
From our experience of large-scaleEnglish-Hindi MT, we are convinced thatfluency and fidelity in the Hindi output getan order of magnitude facelift if accuratecase markers and suffixes are produced.Now, the moot question is: what entity onthe English side encodes the informationcontained in case markers and suffixes onthe Hindi side?
Our studies of correspon-dences in the two languages show that casemarkers and suffixes in Hindi are predom-inantly determined by the combination ofsuffixes and semantic relations on the En-glish side.
We, therefore, augment thealigned corpus of the two languages, withthe correspondence of English suffixes andsemantic relations with Hindi suffixes andcase markers.
Our results on 400 testsentences, translated using an SMT sys-tem trained on around 13000 parallel sen-tences, show that suffix + semantic rela-tion?
case marker/suffix is a very usefultranslation factor, in the sense of making asignificant difference to output quality asindicated by subjective evaluation as wellas BLEU scores.1 IntroductionTwo fundamental problems in applying statisticalmachine translation (SMT) techniques to English-Hindi (and generally to Indian language) MT are:i) the wide syntactic divergence between the lan-guage pairs, and ii) the richer morphology andcase marking of Hindi compared to English.
Thefirst problem manifests itself in poor word-order inthe output translations, while the second one leadsto incorrect inflections (word-endings) and casemarking.
Being a free word-order language, Hindisuffers badly when morphology and case markersare incorrect.To solve the former, word-order related, prob-lem, we use a preprocessing technique, which wehave discussed in (Ananthakrishnan et al, 2008).This procedure is similar to what is suggested in(Collins et al, 2005) and (Wang, 2007), and re-sults in the input sentence being reordered to fol-low Hindi structure.The focus of this paper, however, is on thethorny problem of generating case markers andmorphology.
It is recognized that translating frompoor to rich morphology is a challenge (Avramidisand Koehn, 2008) that calls for deeper linguisticanalysis to be part of the translation process.
Suchanalysis is facilitated by factored models (Koehnet al, 2007), which provide a framework for incor-porating lemmas, suffixes, POS tags, and any otherlinguistic factors in a log-linear model for phrase-based SMT.
In this paper, we motivate a factoriza-tion well-suited to English-Hindi translation.
Thefactorization uses semantic relations and suffixesto generate inflections and case markers.
Our ex-periments include two different kinds of semanticrelations, namely, dependency relations providedby the Stanford parser, and the deeper semanticroles (agent, patient, etc.)
provided by the univer-sal networking language (UNL).
Our experimentsshow that the use of semantic relations and syntac-tic reordering leads to substantially better qualitytranslation.
The use of even moderately accuratesemantic relations has an especially salubrious ef-fect on fluency.8002 Related WorkThere have been quite a few attempts at includ-ing morphological information within statisticalMT.
Nie?en and Ney (2004) show that the use ofmorpho-syntactic information drastically reducesthe need for bilingual training data.
Popovic andNey (2006) report the use of morphological andsyntactic restructuring information for Spanish-English and Serbian-English translation.Koehn and Hoang (2007) propose factoredtranslation models that combine feature functionsto handle syntactic, morphological, and other lin-guistic information in a log-linear model.
Thiswork also describes experiments in translatingfrom English to German, Spanish, and Czech, in-cluding the use of morphological factors.Avramidis and Koehn (2008) report work ontranslating from poor to rich morphology, namely,English to Greek and Czech translation.
They usefactored models with case and verb conjugationrelated factors determined by heuristics on parsetrees.
The factors are used only on the source side,and not on the target side.To handle syntactic differences,Melamed (2004) proposes methods based ontree-to-tree mappings.
Imamura et al (2005)present a similar method that achieves significantimprovements over a phrase-based baseline modelfor Japanese-English translation.Another method for handling syntactic differ-ences is preprocessing, which is especially perti-nent when the target language does not have pars-ing tools.
These algorithms attempt to recon-cile the word-order differences between the sourceand target language sentences by reordering thesource language data prior to the SMT trainingand decoding cycles.
Nie?en and Ney (2004) pro-pose some restructuring steps for German-EnglishSMT.
Popovic and Ney (2006) report the useof simple local transformation rules for Spanish-English and Serbian-English translation.
Collinset al (2005) propose German clause restructur-ing to improve German-English SMT, while Wanget al (2007) present similar work for Chinese-English SMT.
Our earlier work (Ananthakrishnanet al, 2008) describes syntactic reordering andmorphological suffix separation for English-HindiSMT.3 MotivationThe fundamental differences between English andHindi are:?
English follows SVO order, whereas Hindifollows SOV order?
English uses post-modifiers, whereas Hindiuses pre-modifiers?
Hindi allows greater freedom in word-order,identifying constituents through case mark-ing?
Hindi has a relatively richer system of mor-phologyWe resolve the first two syntactic differencesby reordering the English sentence to conform toHindi word-order in a preprocessing step as de-scribed in (Ananthakrishnan et al, 2008).The focus of this paper, however, is on the lasttwo of these differences, and here we dwell a biton why this focus on case markers and morphol-ogy is crucial to the quality of translation.3.1 Case markersWhile in English, the major constituents of a sen-tence (subject, object, etc.)
can usually be iden-tified by their position in the sentence, Hindi is arelatively free word-order language.
Constituentscan be moved around in the sentence without im-pacting the core meaning.
For example, the fol-lowing sentence pair conveys the same meaning(John saw Mary), albeit with different emphases.jAn n mrF ko dKAJohn ne Mary ko dekhaaJohn-nom Mary-acc sawmrF ko jAn n dKAMary ko John ne dekhaaMary-acc John-nom sawThe identity of John as the subject and Maryas the object in both sentences comes from thecase markers n (ne ?
nominative) and ko (ko ?accusative).
Therefore, even though Hindi is pre-dominantly SOV in its word-order, correct casemarking is a crucial part of making translationsconvey the right meaning.8013.2 MorphologyThe following examples illustrate the richer mor-phology of Hindi compared to English:Oblique case: The plural-marker in the word?boys?
in English is translated as e (e ?
plural di-rect) or ao\ (on ?
plural oblique):The boys went to school.lXk pAWfAlA gyladake paathashaalaa gayeThe boys ate apples.lXko\ n sb KAyladokon ne seba khaayeFuture tense: Future tense in Hindi is markedon the verb.
In the following example, ?will go?
istranslated as jAy\g (jaaenge), with e\g (enge) asthe future tense marker:The boys will go to school.lXk pAWfAlA jAy\gladake paathashaalaa jayengeCausative constructions: The aAyA (aayaa)suffix indicates causativity:The boys made them cry.lXko\ n uh zlAyAladakon ne unhe rulaayaa3.3 SparsityUsing a standard SMT system for English-Hinditranslation will cause severe data sparsity with re-spect to case marking and morphology.For example, the fact that the word boys inoblique case (say, when followed by n (ne))should take the form lXko\ (ladakon) will belearnt only if the correspondence between boysand lXko\ n (ladakon ne) exists in the trainingcorpus.
The more general rule that n (ne) shouldbe preceded by the oblique case ending ao\ (on)cannot be learnt.
Similarly, the plural form of boyswill be produced only if that form exists in thetraining corpus.Essentially, all morphological forms of a wordand its translations have to exist in the training cor-pus, and every word has to appear with every pos-sible case marker, which will require an impossi-ble amount of training data.
Therefore, it is im-perative to make it possible for the system to learngeneral rules for morphology and case marking.The next section describes our approach to facili-tating the learning of such rules.4 ApproachWhile translating from a language of moderatecase marking and morphology (English) to onewith relatively richer case marking and morphol-ogy (Hindi), we are faced with the problem of ex-tracting information from the source language sen-tence, transferring the information onto the targetside, and translating this information into the ap-propriate case markers and morphological affixes.The key bits of information for us are suffixesand semantic relations, and the vehicle that trans-fers and translates the information is the factoredmodel for phrase based SMT (Koehn 2007).4.1 Factored ModelFactored models allow the translation to be brokendown into various components, which are com-bined using a log-linear model:p(e|f) =1Zexpn?i=1?ihi(e, f) (1)Each hi is a feature function for a component ofthe translation (such as the language model), andthe ?
values are weights for the feature functions.4.2 Our FactorizationOur factorization, which is illustrated in figure 1,consists of:1. a lemma to lemma translation factor (boy?lXk^ (ladak))2. a suffix + semantic relation to suffix/casemarker factor (-s + subj?
e (e))3. a lemma + suffix to surface form genera-tion factor (lXk^ + e (ladak + e) ?
lXk(ladake))The above factorization is motivated by the fol-lowing:?
Case markers are decided by semantic re-lations and tense-aspect information in suf-fixes.For example, if a clause has an object, andhas a perfective form, the subject usually re-quires the case marker n (ne).John ate an apple.John|empty|subj eat|ed|empty an|empty|detapple|empty|obj802Figure 1: Semantic and Suffix Factors: the combination of English suffixes and semantic relations isaligned with Hindi suffixes and case markersjAn n sb KAyAjohn ne seba khaayaaThus, the combination of the suffix andsemantic relation generates the right casemarker (ed|empty + empty|obj?
n (ne)).?
Target language suffixes are largely deter-mined by source language suffixes and casemarkers (which in turn are determined by thesemantic relations)The boys ate apples.The|empty|det boy|s|subj eat|ed|emptyapple|s|objlXko\ n sb KAyladakon ne seba khaayeHere, the plural suffix on boys leads to twopossibilities ?
lXk (ladake ?
plural direct)and lXko\ (ladakon ?
plural oblique).
Thecase marker n (ne) requires the oblique case.?
Our factorization provides the system withtwo sources to determine the case markersand suffixes.
While the translation steps dis-cussed above are one source, the languagemodel over the suffix/case marker factor re-inforces the decisions made.For example, the combination lXkA n(ladakaa ne) is impossible, while lXko\ n(ladakon ne) is very likely.
The separation ofthe lemma and suffix helps in tiding over thedata sparsity problem by allowing the systemto reason about the suffix-case marker com-bination rather than the combination of thespecific word and the case marker.5 Semantic RelationsThe experiments have been conducted with twokinds of semantic relations.
One of them is the re-lations from the Universal Networking Language(UNL), and the other is the grammatical relationsproduced by the Stanford parser.The relations in both UNL and the Stanford de-pendency parser are strictly binary and form a di-rected graph.
These relations express the semanticdependencies among the various words in the sen-tence.Stanford: The Stanford dependencyparser (Marie-Catherine and Manning, 2008)uses 55 relations to express the dependenciesamong the various words in a sentence.
Theserelations form a hierarchical structure with themost general relation at the root.
There arevarious argument relations like subject, object,objects of prepositions, and clausal complements,modifier relations like adjectival, adverbial,participial, and infinitival modifiers, and otherrelations like coordination, conjunct, expletive,and punctuation.UNL: The 44 UNL relations1 include relationssuch as agent, object, co-agent, and partner, tem-poral relations, locative relations, conjunctive anddisjunctive relations, comparative relations andalso hierarchical relationships like part-of and an-instance-of.Comparison: Unlike the Stanford parser whichexpresses the semantic relationships throughgrammatical relations, UNL uses attributes anduniversal words, in addition to the semantic roles,to express the same.
Universal words are used todisambiguate words, while attributes are used toexpress the speaker?s point of view in the sentence.UNL relations, compared to the relations in theStanford parser, are more semantic than grammat-ical.
For instance, in the Stanford parser, the agentrelation is the complement of a passive verb intro-duced by the preposition by, whereas in UNL it1http://www.undl.org/unlsys/unl/unl2005/803Figure 2: UNL and Stanford semantic relation graphs for the sentence ?John said that he was hitby Jack?#sentences #wordsTraining 12868 316508Tuning 600 15279Test 400 8557Table 1: Corpus Statisticssignifies the doer of an action.
Consider the fol-lowing sentence:John said that he was hit by Jack.In this sentence, the Stanford parser producesthe relation agent(hit, Jack) and nsubj(said, John)as shown in figure 2.
In UNL, however, both thecases use the agent relation.
The other distinguish-ing aspect of UNL is the hyper-node that repre-sents scope.
In the example sentence, the wholeclause ?that he was hit by Jack?
forms the ob-ject of the verb said, and hence is represented ina scope.
The Stanford dependency parser on theother hand represents these dependencies with thehelp of the clausal complement relation, whichlinks said with hit, and uses the complementizerrelation to introduce the subordinating conjunc-tion.The pre-dependency accuracy of the Stan-ford dependency parser is around 80% (Marie-Catherine et al, 2006), while the accuracyachieved by the UNL generating system is64.89%.6 Experiments6.1 SetupThe corpus described in table 1 was used for theexperiments.The SRILM toolkit 2 was used to create Hindilanguage models using the target side of the train-ing corpus.Training, tuning, and decoding were performedusing the Moses toolkit 3.
Tuning (learning the?
values discussed in section 4.1) was done usingminimum error rate training (Och, 2003).The Stanford parser 4 was used for parsing theEnglish text for syntactic reordering and to gener-ate ?stanford?
semantic relations.The program for syntactic reordering used theparse trees generated by the Stanford parser,and was written in perl using the moduleParse::RecDescent.English morphological analysis was performedusing morpha (Minnen et al, 2001), while Hindisuffix separation was done using the stemmer de-scribed in (Ananthakrishnan and Rao, 2003).Syntactic and morphological transformations,in the models where they were employed, were ap-plied at every phase: training, tuning, and testing.Evaluation Criteria: Automatic evaluationwas performed using BLEU and NIST on the en-tire test set of 400 sentences.
Subjective evaluationwas performed on 125 sentences from the test set.?
BLEU (Papineni et al, 2001): measures theprecision of n-grams with respect to the ref-erence translations, with a brevity penalty.
Ahigher BLEU score indicates better transla-tion.?
NIST 5: measures the precision of n-grams.This metric is a variant of BLEU, which was2http://www.speech.sri.com/projects/srilm/3http://www.statmt.org/moses/4http://nlp.stanford.edu/software/lex-parser.shtml5www.nist.gov/speech/tests/mt/doc/ngram-study.pdf804shown to correlate better with human judg-ments.
Again, a higher score indicates bettertranslation.?
Subjective: Human evaluators judged thefluency and adequacy, and counted the num-ber of errors in case markers and morphology.6.2 ResultsTable 2 shows the impact of suffix and semanticfactors.
The models experimented with are de-scribed below:baseline: The default settings of Moses wereused for this model.lemma + suffix: This uses the lemma and suf-fix factors on the source side, and the lemma andsuffix/case marker on the target side.
The trans-lation steps are i) lemma to lemma and ii) suffixto suffix/case marker, and the generation step islemma+suffix/case marker to surface form.lemma + suffix + unl: This model uses, in ad-dition to the factors in the lemma+suffix model,a semantic relation factor (UNL relations).
Thetranslation steps are i) lemma to lemma and ii)suffix+semantic relation to suffix/case marker, andthe generation step again is lemma+suffix/casemarker to surface form.lemma + suffix + stanford: This is identicalto the previous model, except that stanford depen-dency relations are used instead of UNL relations.We can see a substantial improvement in scoreswhen semantic relations are used.Table 5 shows the impact of syntactic reorder-ing.
The surface form with distortion-based, lex-icalized, and syntactic reordering were experi-mented with.
The model with the suffix and se-mantic factors was used with syntactic reordering.For subjective evaluation, sentences werejudged on fluency, adequacy and the number of er-rors in case marking/morphology.To judge fluency, the judges were asked to lookat how well-formed the output sentence is accord-ing to Hindi grammar, without considering whatthe translation is supposed to convey.
The five-point scale in table 3 was used for evaluation.To judge adequacy, the judges were asked tocompare each output sentence to the referencetranslation and judge how well the meaning con-veyed by the reference was also conveyed by theoutput sentence.
The five-point scale in table 4was used.Table 6 shows the average fluency and adequacyscores, and the average number of errors per sen-tence.All differences are significant at the 99%level, except the difference in adequacy be-tween the surface-syntactic model and thelemma+suffix+stanford syntactic model, which issignificant at the 95% level.7 DiscussionWe can see from the results that better fluency andadequacy are achieved with the use of semantic re-lations.
The improvement in fluency is especiallynoteworthy.
Figure 3 shows the distribution of flu-ency and adequacy scores.
What is worth notingis that the number of sentences at levels 4 and 5in terms of fluency and adequacy are much higherin case of the model that uses semantic relations.That is, the use of semantic relations, in combi-nation with syntactic reordering, produces manymore sentences that are reasonably or even per-fectly fluent and convey most or all of the mean-ing.Table 7 shows the impact of sentence length ontranslation quality.
We can see that with smallersentences the improvements using syntactic re-ordering and semantic relations are much morepronounced.
All models find long sentences dif-ficult to handle, which contributes to bringing themean performances closer.
However, it is clearthat many more useful translations are being pro-duced due to syntactic reordering and semantic re-lations.The following is an example of the kind of im-provements achieved:Input: Inland waterway is one of the most pop-ular picnic spots in Alappuzha.Baseline: m\ ek ata,-TlFy jlmAgksbs ?Es?
EpkEnk -Tl m\ jlo\ m\ dOXtaFh{men eka antahsthaliiya jalamaarga ke sabaseprasiddha pikanika sthala men jalon men daudatiihaigloss: in a waterway of most popular picnic spotin waters runs.Reorder: ata,-TlFy jlmAgaAlp  yA ksbs ?Es?
EpkEnk -Tl m\ s ek h{antahsthaliiya jalamaarga aalapuzaa ke sabaseprasiddha pikanika sthala men se eka hai805Model BLEU NISTBaseline (surface) 24.32 5.85lemma + suffix 25.16 5.87lemma + suffix + unl 27.79 6.05lemma + suffix + stanford 28.21 5.99Table 2: Results: The impact of suffix and semantic factorsLevel Interpretation5 Flawless Hindi, with no grammatical errors whatsoever4 Good Hindi, with a few minor errors in morphology3 Non-native Hindi, with possibly a few minor grammatical errors2 Disfluent Hindi, with most phrases correct, but ungrammatical overall1 IncomprehensibleTable 3: Subjective Evaluation: Fluency ScaleLevel Interpretation5 All meaning is conveyed4 Most of the meaning is conveyed3 Much of the meaning is conveyed2 Little meaning is conveyed1 None of the meaning is conveyedTable 4: Subjective Evaluation: Adequacy ScaleModel Reordering BLEU NISTsurface distortion 24.42 5.85surface lexicalized 28.75 6.19surface syntactic 31.57 6.40lemma + suffix + stanford syntactic 31.49 6.34Table 5: Results: The impact of reordering and semantic relationsModel Reordering Fluency Adequacy #errorssurface lexicalized 2.14 2.26 2.16surface syntactic 2.6 2.71 1.79lemma + suffix + stanford syntactic 2.88 2.82 1.44Table 6: Subjective Evaluation: The impact of reordering and semantic relationsBaseline Reorder StanfordF A E F A E F A ESmall (<19 words) 2.63 2.84 1.30 3.30 3.52 0.74 3.66 3.75 0.62Medium (20-34 words) 1.92 2.00 2.23 2.32 2.43 2.05 2.62 2.46 1.74Large (>34 words) 1.62 1.69 4.00 1.86 1.73 3.36 1.86 1.86 2.82Table 7: Impact of sentence length (F: Fluency; A:Adequacy; E:# Errors)806Figure 3: Subjective evaluation: analysisgloss: waterway Alappuzha of most popularpicnic spot of one isSemantic: ata,-TlFy jlmAgaAlp  yA ksbs ?Es?
EpkEnk -Tlo\ m\ s ek h{antahsthaliiya jalamaarga aalapuzaa ke sabaseprasiddha pikanika sthalon men se eka haigloss: waterway Alappuzha of most popularpicnic spots of one isWe can see that poor word-order makes thebaseline output almost incomprehensible, whilesyntactic reordering solves the problem correctly.The morphology improvement using semanticrelations can be seen in the correct inflectionachieved in the word -Tlo\ (sthalon ?
pluraloblique ?
spots), whereas the output without usingsemantic relations generates -Tl (sthala ?
singu-lar ?
spot).The next couple of examples illustrate how casemarking improves through the use of semantic re-lations.Input: Gandhi Darshan and Gandhi NationalMuseum is across Rajghat.Reorder: gA\DF dfn v gA\DF rA?~ Fy s\g}hAlyrAjGAV m\ h{gaandhii darshana va gaandhii raashtriiya san-grahaalaya raajaghaata men haiSemantic: gA\DF dfn v gA\DF rA?~ Fys\g}hAly rAjGAV k pAr h{gaandhii darshana va gaandhii raashtriiya san-grahaalaya raajaghaata ke paara haiHere, the use of semantic relations produces thecorrect meaning that the locations mentioned areacross (k pAr (ke paara)) Rajghat, and not in (m\(men)) Rajghat as suggested by the translation pro-duced without using semantic relations.Another common error in case marking is thattwo case markers are produced in successive po-sitions in the translation, which is not possible inHindi.
The following example (a fragment) showsthis error (kF (kii) repeated) being correctly han-dled by using semantic relations:Input: For varieties of migratory birdsReorder: ?vAsF pE"yo\ kF kF ?kAr k Elypravaasii pakshiyon kii kii prakaara ke liyeSemantic: ?vAsF pE"yo\ kF ?kAr k Elypravaasii pakshiyon kii prakaara ke liyeIt is important to note that the gains made us-ing syntactic reordering and semantic relations arelimited by the accuracy of the parsers (see section5).
We observe that even the use of moderate qual-ity semantic relations goes a long way in increas-ing the quality of translation.8 ConclusionWe have reported in this paper the marked im-provement in the output quality of Hindi transla-tions ?
especially fluency ?
when the correspon-dence of English semantic relations and suffixeswith Hindi case markers and inflections is used asa translation factor in English-Hindi SMT.
The im-provement is statistically significant.
Subjectiveevaluation too lends ample credence to this claim.Future work consists of investigations into (i) howthe internal structure of constituents can be strictlypreserved and (ii) how to glue together correctlythe syntactically well-formed bits and pieces ofthe sentences.
This course of future action is sug-gested by the fact that smaller sentences are muchmore fluent in translation compared to mediumlength and long sentences.807ReferencesAnanthakrishnan, R., and Rao, D., A LightweightStemmer for Hindi, Workshop on Com-putational Linguistics for South-Asian Lan-guages, EACL, 2003.Ananthakrishnan, R., Bhattacharyya, P., Hegde, J.J., Shah, R. M., and Sasikumar, M., Sim-ple Syntactic and Morphological ProcessingCan Help English-Hindi Statistical MachineTranslation, Proceedings of IJCNLP, 2008.Avramidis, E., and Koehn, P., Enriching Morpho-logically Poor Languages for Statistical Ma-chine Translation, Proceedings of ACL-08:HLT, 2008.Collins, M., Koehn, P., and I. Kucerova, ClauseRestructuring for Statistical Machine Trans-lation, Proceedings of ACL, 2005.Imamura, K., Okuma, H., Sumita, E., Prac-tical Approach to Syntax-based StatisticalMachine Translation, Proceedings of MT-SUMMIT X, 2005.Koehn, P., and Hoang, H., Factored TranslationModels, Proceedings of EMNLP, 2007.Marie-Catherine de Marneffe, MacCartney, B.,and Manning, C., Generating Typed Depen-dency Parses from Phrase Structure Parses,Proceedings of LREC, 2006.Marie-Catherine de Marneffe and Manning, C.,Stanford Typed Dependency Manual, 2008.Melamed, D., Statistical Machine Translation byParsing, Proceedings of ACL, 2004.Minnen, G., Carroll, J., and Pearce, D., AppliedMorphological Processing of English, Natu-ral Language Engineering, 7(3), pages 207?223, 2001.Nie?en, S., and Ney, H., Statistical MachineTranslation with Scarce Resources UsingMorpho-syntactic Information, Computa-tional Linguistics, 30(2), pages 181?204,2004.Och, F., Minimum Error Rate Training in Sta-tistical Machine Translation, Proceedings ofACL, 2003.Papineni, K., Roukos, S., Ward, T., and Zhu,W., BLEU: a Method for Automatic Evalu-ation of Machine Translation, IBM ResearchReport, Thomas J. Watson Research Center,2001.Popovic, M., and Ney, H., Statistical MachineTranslation with a Small Amount of Bilin-gual Training Data, 5th LREC SALTMILWorkshop on Minority Languages, 2006.Wang, C., Collins, M., and Koehn, P., ChineseSyntactic Reordering for Statistical MachineTranslation, Proceedings of the EMNLP-CoNLL, 2007.808
