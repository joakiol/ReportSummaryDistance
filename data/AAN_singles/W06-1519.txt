Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Related Formalisms, pages 133?136,Sydney, July 2006. c?2006 Association for Computational LinguisticsExtracting Syntactic Features from a Korean TreebankJungyeul ParkUFR LinguistiqueLaboratoire de linguistique formelleUniversit?
Paris VII - Denis Diderotjungyeul.park@linguist.jussieu.frAbstractIn this paper, we present a system whichcan extract syntactic feature structuresfrom a Korean Treebank (Sejong Tree-bank) to develop a Feature-based Lexi-calized Tree Adjoining Grammars.1 IntroductionIn a Tree Adjoining Grammar, a feature structureis associated with each node in an elementarytree (Vijay-Shanker and Joshi, 1991).
This fea-ture structure contains information about how thenode interacts with other nodes in the tree.
Itconsists of a top part, which generally containsinformation relating to the super-node, and a bot-tom part, which generally contains informationrelating to the sub-node.In this paper, we present a system which canextract syntactic feature structures from a Tree-bank to develop a Feature-based LexicalizedTree Adjoining Grammars.
Several works havebeen on extracting grammars, especially usingTAG formalism proposed.
Chen (2001) has ex-tracted lexicalized grammars from English PennTreebank and there are other works based onChen?s procedure such as Nasr (2004) for Frenchand Habash and Rambow (2004) for Arabic.
Xiaet al (2000) developed the uniform method of agrammar extraction for English, Chinese andKorean.
Neumann (2003) extracted LexicalizedTree Grammars from English Penn Treebank forEnglish and from NEGRA Treebank for German.However, none of these works have tried to ex-tract syntactic features for FB-LTAG.We use with Sejong Treebank (SJTree) whichcontains 32 054 eojeols (the unity of segmenta-tion in the Korean sentence), that is, 2 526 sen-tences.
SJTree uses 43 part-of-speech tags and 55syntactic tags (Sejong Project 2003).2 Extracting a Feature structure forFB-LTAGFB-LTAG grammars eventually use reducedtagset because FB-LTAG grammars contain theirsyntactic information in features structures.
Forexample, NP_SBJ syntactic tag in LTAG ischanged into NP and a syntactic feature<case=nominative> is added.
Therefore, we useactually a 13 reduced tagset for FB-LTAG gram-mars compared with a 55 syntactic tagset for anLTAG without features.
From full-scale syntactictags which end with _SBJ (subject), _OBJ (ob-ject) and _CMP (attribute), we extract <case>features which describe argument structures inthe sentence.Alongside <case> features, we also extract<mode> and <tense> from morphological analy-ses in SJTree.
Since however morphologicalanalyses for verbal and adjectival endings inSJTree are simply divided into EP, EF and ECwhich mean non-final endings, final endings andconjunctive endings, respectively, <mode> and<tense> features are not extracted directly fromSJTree.
In this paper, we analyze 7 non-finalendings (EP) and 77 final endings (EF) used inSJTree to extract automatically <mode> and<tense> features.
In general, EF carries <mode>inflections, and EP carries <tense> inflections.Conjunctive endings (EC) are not concerned with<mode> and <tense> features and we only ex-tract <ec> features with its string value.
<ef> and<ep> features are also extracted with their stringvalues.
Some of non-final endings like si are ex-tracted as <hor> features which have honorarymeaning.
In extracted FB-LTAG grammars, wepresent their lexical heads in a bare infinitivewith morphological features such as <ep>, <ef>and <ec> which make correspond with its in-flected forms.133<det> is another automatically extractable fea-ture in SJTree and it is extracted from both syn-tactic tag and morphological analysis unlikeother extracted features.
For example, while<det=-> is extracted from dependant nounswhich always need modifiers (extracted by mor-phological analyses), <det=+> is extracted from_MOD phrases (extracted by syntactic tags).From syntactic tag DP which contains MMs (de-terminative or demonstrative), <det=+> is alsoextracted.
See Table 1 for all the extractable fea-tures from SJTree.Feature Description Values<case> a case featureassigned bypredicatenom(inative),acc(usative),attr(ibut)<det> determiner,modifier+/-<mode> mode ind(icative),imp(erative),int(errogative),exc(lamatory)<temps> tense pre(sent), past,fut(ure)<ep>, <ef>,<ec>a featuremarked fordifferent waysof instantiatingmode and tensestring valueslike eoss, da,go, etc.<hor> honorific +/-Table 1.
Extractable Features from SJTreeKorean does not need features <person> or<number> as in English.
Han et al (2000) pro-posed several features for Korean FBLTAGwhich we do not use in this paper, such as <adv-pp>, <top> and <aux-pp> for nouns and <clause-type> for predicates.
While postpositions areseparated from eojeol during our grammar ex-traction procedure, Han et al considered them as?one?
inflectional morphology of noun phraseeojeol.
<aux-pp> adds semantic meaning of aux-iliary postpositions such as only, also etc.
whichwe can not extract automatically from SJTree orother Korean Treebank corpora because syntacti-cally annotated Treebank corpora generally donot contain such semantic information.
<top>marks the presence or absence of a topic markerin Korean like neun, however topic markers areannotated like a subject in SJTree which meansthat only <case=nominative> is extracted fortopic markers.
<clause-type> indicates the typeof the clause which has its values such as main,coord(inative), subordi(native), adnom(inal),nominal, aux-connect.
Since the distinction ofthe type of the clause is very vague except mainclause in Korea, we do not adopt this feature.Instead, <ef> is extracted if a clause type is amain clause and for <ec> is extracted for othertypes.3 ExperimentationsThe actual procedure of feature extraction isimplemented by two phases.
In the first phase,we convert syntactic tags and morphologicalanalysis into feature structure as explained above(see Table 2 for our conversion scheme forsyntactic tags and see Table 3 for morphologicalanalyses).
In the second phase, we completefeature structure onto nodes of the ?spine (pathbetween root and anchor, node in an initial treeand path between root and foot node in anauxiliary tree)?.
For example, we put the samefeature of VV bottom in Figure 1a onto VV top,VP top/bottom and S bottom because nodes indorsal spine share certain number of feature ofVV bottom.
The initial tree for a verbbalpyoha.eoss.da (?announced?)
in (1) iscompleted like Figure 1b for a FB-LTAG.
(1) ??
????
??
??
???
????.
(1)  ilbon    oimuseong.eun(1)  Japan   ministy_of_foreign_affairs.Nom(1)  jeukgak   haemyeng seongmyeng.eul(1)  immediately   elucidation declaration.Acc(1)  balpyo.ha.eoss.da(1)  announce.Pass.Ter(1) ?The ministry of foreign affairs in Japan(1) immediately announced their elucidation?SNP?
VPVPNP?VVbalpyoha<cas> = nom<cas> = accb: <ep> = eossb: <ef> = dab: <mode> = declb: <tense> = pasta.
First phaseSNP?
VPVPNP?VVbalpyohab: <ep> = eossb: <ef> = dab: <mode> = declb: <tense> = pastt:  <ep> = x, <ef> = y, <mode> = i, <tense> = jt:  <ep> = x, <ef> = y, <mode> = i, <tense> = jb: <ep> = x, <ef> = y, <mode> = i, <tense> = jt:  <ep> = x, <ef> = y, <mode> = i, <tense> = jb: <ep> = x, <ef> = y, <mode> = i, <tense> = jt:  -b: <ep> = x, <ef> = y, <mode> = i, <tense> = j<cas> = nom<det> = +<cas> = acc<det> = +b.
Second phaseFigure 1.
Extracted FB-LTAG grammar forbalpyoha.eoss.da (?announced?
)134Table 4 shows the results of experiments in ex-tracting feature-based lexicalized grammars.
SeePark (2006) for the detail extraction scheme.4 EvaluationsFinally, extracted grammars are evaluated by itssize (see Figure 2) and its coverage (see Table 5).The number of tree schemata is not stabilized atthe end of the extraction process, which seems toindicate that the size of Treebank is not enoughto reach the convergence of extracted grammars.However, the number of tree schemata appearingat least twice and three times (threshold = 2 and3) in Treebank is much stabilized at the end ofthe extraction process than that of tree schemataappearing only once (threshold = 1).The coverage of extracted grammars is calcu-lated not only by the frequency of tree schematabut also by the number of tree schemata.Figure 2.
Size of tree schemataWe manually overlap our 163 tree schemata forpredicates, which contain 14 subcategorizationframes with 11 subcategorization frames of aFB-LTAG grammar proposed in Han et al(2000) to evaluate the coverage of hand-craftedgrammars 1 .
Our extracted template grammarscover 72.7 % of their hand-crafted subcategori-zation frames2.1  Our extracted tree schemata contain not onlysubcategorization frames but also some phenomena ofsyntactic variations, the number of lexicalized trees and thefrequency information while Han el al.
(2000) only presentssubcategorization frames and some phenomena.2 Three subcategorization frames in Han el al.
(2000) whichcontain prepositional phrases are not covered by our ex-tracted tree schemata.
Generally, prepositional phrases inSJTree are labeled with _AJT which is marked for adjunc-tion operation.
Since there is no difference between nounadverbial phrase and prepositional phrases in SJTree like [Sna.neun [NP_AJT ojeon.e ?morning?]
[NP_AJT hakgyo.e ?toschool?]
ga.ss.da] (?I went to school this morning?
), we donot consider _AJT phrases as arguments.5 ConclusionIn this paper, we have presented a system forautomatic grammar extraction that produces fea-ture-based lexicalized grammars from a Tree-bank.
Also, we evaluated by its size and its cov-erage, and overlap our automatically extractedtree schemata from a Treebank with a manuallywritten subcategorization frames to evaluate thecoverage of hand-crafted grammars.ReferencesAlexis Nasr.
2004.
Analyse syntaxique probabilistepour grammaires de d?pendances extraites auto-matiquement.
Habilitation ?
diriger des recherches,Universit?
Paris 7.Chunghye Han, Juntae Yoon, Nari Kim, and MarthaPalmer.
2000.
A Feature-Based Lexicalized TreeAdjoining Grammar for Korean.
IRCS TechnicalReport 00-04.
University of Pennsylvania.Fei Xia, Martha Palmer, and Aravind K. Joshi.
2000.A Uniform Method of Grammar Extraction and ItsApplication.
In The Joint SIGDAT Conference onEmpirical Methods in Natural Language Process-ing and Very Large Corpora (EMNLP/VLC-2000),Hong Kong, Oct 7-8, 2000.G?nter Neumann.
2003.
A Uniform Method forAutomatically Extracting Stochastic LexicalizedTree Grammar from Treebank and HPSG, In A.Abeill?
(ed) Treebanks: Building and UsingParsed Corpora, Kluwer, Dordrecht.John Chen.
2001.
Towards Efficient Statistical Pars-ing Using Lexicalized Grammatical Information.Ph.D.
thesis, University of Delaware.Jungyeul Park.
2006.
Extraction automatique d?unegrammaire d?arbres adjoints ?
partir d?un corpusarbor?
pour le cor?en.
Ph.D. thesis, Universit?Paris 7.K.
Vijay-Shanker and Aravind K. Joshi.
1991.
Unifi-cation Based Tree Adjoining Grammar, in J.Wedekind ed., Unification-based Grammars, MITPress, Cambridge, Massachusetts.Nizar Habash and Owen Rambow.
2004.
Extracting aTree Adjoining Grammar from the Penn ArabicTreebank.
In Proceedings of Traitement Auto-matique du Langage Naturel (TALN-04).
Fez, Mo-rocco, 2004.Sejong Project.
2003.
Final Report of Sejong KoreanTreebank.
Ministry of Education & Human Re-sources Development in Korea.135Anchor Tree type Syntactic tag Node type Conversion exam-pleverb ?
NP_SBJ subst NP[<cas> = nom<det> = +]verb ?|?
VP, VP_MOD - VP[<ep> <ef><mode> <tense>]anchored by_MOD phrase?
NP|NP_CMP|NP_MOD|NP_OBJ||NP_SBJroot NP[<det> = +]postposition ?
NP_SBJ root NP[<cas> = nom]postposition ?
NP_SBJ subst NP[<cas> = NONE]Table 2.
Conversion example for syntactic tagsVerbal ending Ending type Conversion exampleeoss EP <ep> = eoss, <tense> = pastsi EP <ep> = si, <hor> = +da EF <ef> = da, <mode> = indTable 3.
Conversion example for morphological analyses# of lexicalizedtree(?
+ ?
)Average fre-quencies per lexi-calized tree# of tree sche-mata (?
+ ?
)Average fre-quencies per treeschemataG 12 239(7 315 + 4 766)3.26 338(109 + 229)118.1Table 4.
Results of experiments in extracting feature-based lexicalized grammarsCoverage of grammars by the fre-quency of tree schemataCoverage of grammars by the numberof tree schemataThreshold 1 2 3 1 2 360 % oftraining set60.75 % 60.7 % 60.66 % 81.66 % 83.83 % 83.5 %90 % oftraining set91.14 % 91.14 % 91.11 % 95.86 % 98.3 % 96.5 %Table 5.
Coverage of grammars: 60% of training set (1511 sentences) and 90% of training set (2265sentences)136
