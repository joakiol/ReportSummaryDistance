TOWARDS COMPUTER-AIDED LINGUISTIC ENGINEERINGVers une m~thodologie et des outils pout" ie g~nie linguistiqueRI~MI ZA JACGRILUniversit6 Blaise Pa~al ,  34 avenue Carno!F -63037 C lermont -Fer rand  cedexremi@ucfsl.uucpDans cet article, nous proposons unem6thodologie de g6nie logiciel pour letraitement automatique des languesfond6e sur la g6n6ration (semi-) automa-tique de programmes de TALN it partirde sp6cifications formelies.Cette m6thodologie est concue pourfavoriser la r6utilisation de sp6cificationslinguistiques dans la g6n6ration de dif-f6rentes applications de TALN, ainsi quele d6veloppement i cr6mental de cessp6cifications linguistiques.Le langage de spdcification fomlelle estfond6 sur les structures de traits typ6s.
Lar6utilisation de spdcifications linguis-tiques est favoris6e par l'organisation deces sp6cifications darts un style parobjets, en plusieurs niveaux de sp6cificit6croissante.
Ce langage st suffisementpuissant pour pouvoir d6crire tout typed'objet linguistique, t a l'avantage d'uti-liser une notation largement r6pandue nTALN,L'acquisition de connaissances linguis-tiques formalis6es au moyen de ce lan-gage peut 6tre automatis6e en utilisantdes outils d'exploration de corpus et des6diteurs p6cialis6s fond6s ur ce langageet directement com~ect6s ?a la base deconnaissances linguistiques.ACRES DE COLING-92, Nnt, rrE~s, 23-28 ao~r 1992 8 2 7La g6n6ration de progrmlmaes sp6cifiquesd'aualyse ou de g6n6ration peut ~treautomatis6e dans la mesure ou les lan-gages de programmation cibles sont deslangages de programmation logique ~tcontraintes dont les structures de donndessont des structures de traits typ6s.I.es diffdrents 616merits constituant cetteapproche sont actuellement darts un 6tatd'avancement vari6, qbutefois, cetteapproehe st d6ja partiellement u ilis6epar diff6rents groupes clans plusieurs pro-jets nationaux et europ6ens, en particulierdans le domaine des dictioImai~Tes 61ec-troniques.Pltc~c.
o1: COLING-92, NAbrIES, AUTO, 23-28.
1992TOWARDS COMPUTER-AIDED LINGUISTIC ENGINEERINGRI~MI ZAJACGRILUniversit~ Blaise Pascal, 34 avenue CarnotF-63037 Clermont-Ferrand cedexremi@ucfsl.uuepWe outline a framework for computer-aided linguisticengineering based on the automatic generation of NLPprograms from specifications, mid an automated construc-tion of reusable linguistic specifications.
The specificationlanguage is based on Typed Feature Structures, and thetarget programming language is a constraint logic pro-gramming language which data structures are typed fea-ture structures.
Reusability of linguistic specification isenhanced by the organization of the specifications in anobject-oriented style in several Myers of increasing speci-ficity, supporting for example the incremental develop-ment of grammar specification for sublanguages.1 A framework for NLP SoftwareEngineeringThe development of reliable high-quality linguisticsoftware is a time-consuming, error-prone, andcostly process.
A parser used in an industrial NLPsystem is typically developed by one person overseveral years.
The development of a linguistic engioneering methodology is one of the major in thedevelopment of a language induslry.
The process ofdeveloping an NLP application is an application andan adaptation of the classicalsoftware engineeringdevelopment methodology and follows three majorsteps: the initial requirements and specificationsexpressed in natural anguage, the formal specifica-tion of the system, and finally the implementation fthe system \[Biggerstaff/Perlis 89\].The requirements specific to a linguistic engineeringmethodology are:1.
The initial requirements are complemented by acorpus giving typical examples of the texts andlinguistic phenomena contained in these texts tobe treated by the system;2.
The set of formal specifications constitutes astandardized repository of formalized linguisticknowledgereusable across different NLP applications - acrucial property given the sheer size of granrmarsand dictionaries;executable - to be able to test the specificationsagainst corpora.3.
NLP programs are generated (semi-) automati-cally from formal specifications.These particularities have the following implica-tions:1.
The availability of a corpus allows to develop amethodology based on sublanguages and corpusanalysis, automating the knowledge acquisitionprocess.2.
The linguistic specification does not include anyinformation specific to some application (espe-cially, it does not contain any control informa-tion), thus the same specification can be reusedfor different applications (genericity).A specification language for describing linguisticknowledge could be based on a feature logic andhas an object-oriented inheritance style thatmakes it possible to distinguish formally betweengeneric knowledge and specific (e.g., sublan-guage) knowledge, thus enabling the reuse ofspecifications in the development of the specifi-cations tllemselves.The expressive power of the specification lan-guage (a non-decidable subset of first order logic)allows to remove the conventional distinctionbetween dictionaries and grammars, providing asingle homogeneous framework for an integrateddevelopment of linguistic knowledge bases.The use of a feature-based language also favorsstandardization, as feature structures become a"lingua franca" for computational linguists.Several modem specialized linguistic program-ming languages can be the targets of the auto-mated generation process.
Since the specificationlanguage isbased on typed feature structures, nat-ural candidates are ~unification-based grammarformalisms..3.Ac~lzs DE COLING-92, NANTEs, 23-28 AO~r 1992 8 2 8 Prtoc.
OV COLING-92, NANTES, AUG. 23-28, 1992A Computer-Aided Linguistic Engineering inethod-ology should also address the 1011owing poinls:?
strict separation between pure linguistic knowl-edge and knowledge about strategies tor its use ina particular application, a condition sine qua nonfor reusability;, concepts of modularity for lingnistic description,e.g., formal separation of knowledge pertainingto different levels of linguistic description, orga-nization of linguistic knowledge in hierarchies(from generic to specific);?
team organization of linguistic developmentprojects.1 Reusab le  l ingu is t i c  descr ip t ionsIn software ngineering, the use of the tenn <<reus-ability>> covers two main trends: the composition-based approach and the generation-based approach.In the first approach, software components can beplugged together with no or smaU modifications inorder to build software systems: programming lan-gnages uch as ADA or object-oriented languagesare designed to support his type of reuse.
Thisapproach is successful when the components aresmall and perform very precise functions, as li3rnumerical analysis \[Biggerst,'fff/l'erlis 891.
In NLP,this approach is exemplified by the reu~ of various,<engines>> such as parsers.In the second approach, software components aregenerated (semi-automatically) from a ~t  of formalspecifications, instantiating these specifications in aprogramming language by choosing appropriate datarepresentations and control structures: the knowl-edge expressed in the specification is reused in vari-ous contexts to generate different applications.
Thisapproach is successful when a fair alnount of domainknowledge is built into the specilication and the gen-eration environment, e.g., business knowledge in4GL (Fourth Generation Languages) environments.Tiffs is the approach we envisage for producing NLPprograms.To support reusability and incremenlal developmentof specifications, we organize and describe linguisticknowledge using partial specifications and con-trolled degrees of abstraction i the overall design.Tiffs approach should of course be supported by aspecification language which will be based on theconcept of partial information and provides themeans of stmcturing a specification i a hierarchy ofsubspecifications of increasing specificity.We envisage three basic levels of abstraction.
Thei~titial design of the linguistic domain is ratherabstract and largely free of details.
It establishes thebasic buildings blocks, the basic structures and thefoundations of the linguistic domait~.
At that level,we could aim at providing aeonsensual formal deft onition of tbese basic building blocks as a first steptowards the definition of standards for representiuglinguistic knowledge.
For example, the initial levelof abstraction could start from basic descriptive clas-siticalions, e.g.
at the categorial level nouns, verbs,etc., and li'om the basic syntactic dependenciesbetween these categories, and give them a fnrmaldelinition.A second level of specialization makes choices asfor the distribution of linguistic properties into moreline grained categories.
At that level, we observe theemergence of linguistic theories, where choices aretriggered by tlleoretical assumptions.
Given the rela-tive freedom of structuration, the choice betweencompeting representations should be guided by theconcern for modularity and reusability (internal con-sla'aints) and by the external constraints on the cover-age and the adequacy of the linguistic representationto the needs of NLP of applications.
Linguistic spec-ifications hould be developed as a set of indepen-dently defined nmdules with well-definedinterconnections: modularity is essential in support-ing reusability aud team work in the development ofspecilications.At the third level of specialization, the lingnisticorganization principles are instantiated in the fullydetailed escription of specilic linguistic phenom-ena.
This level is sufficiently detailed to test thespecification against actual sentences ( trings ofword tbnns).
Previous levels can 'also be tested butonly against abstract descriptions representing setsof sentences.
Tius is also tile level at which we haveseveral diflerent i~tstances corresponding to diflerentsublanguages, ach sublanguage d scription reusingthe same first mid second levels of specification,freeing the linguistic of redoing the same designdecisions for each instance.
There could also be asmlcturation among sublanguages which couldintroduce finer levels of abstraction, thus achieving ahigher degree of reusability.This overall framework in winch each level sets par-tial cxmstraints on the most specific instances i ableto support the incremental developnrent of linguisticknowledge by successive r finements and thus, far-tiler reusability.ACTf!S t)'~COLING-92, N^N-I~.s, 23-28 ^otJr 1992 8 2 9 I'v:o~:.
oI:COLING-92, N^l'rrgs, AUG. 23-28, 19922 A linguistic description languageThe crucial issue in the generation-based approachto reusability is the nature and the definition of thespecification language.
A specification language hasto be defined and implemented aspure logic to fullysupport reusability.
It should be suitable to describethe knowledge of a particular domain and shouldbuild on well-accepted notions and notations for thatdomain: here, natural language processing.
In NLP,the emergence of unification-based grammar formal-isms promoted the use of feature structures as a ,din-gua franca>, for representing linguistic information.Although some work on unification-based grammarformalisms i motivated by reusability of linguisticspecifications (e.g., <reversible grammars,,), suchwork does usually not address the problem of speci-fications in engineering terms.
Furthermore, theseformalisms make strong assumptions about henature of linguistic representation 1 thereby limitingseverely the expressive power of these languages.The linguistic specification language is based on atyped version of a logic for feature structures whichallows to define specifications atdifferent levels ofabstraction.
Using this language, it will be possibleto eliminate the conventional division between lexi-cal and grammatical knowledge, and also the divi-sion between generic and specific (e.g.,8ublanguage) knowledge.Such a specification language is executable(although it is potentially infinitely inefficient), andit should be executable for two reasons.
First, sincethe formal specification is the first level of formalityin the conception of a software system, correcmesscannot be proved by formal means.
However, anexecutable specification language allows at least otest the specifications against examples.
Second, itshould be possible to derive an actual program (e.g.,a parser) from a specification.
An executable specifi-cation language nsures the basic feasibility of anautomated generation of NLP programs.The specification language is formally based on asubset of first-order logic.
In order to make it man-ageable and intuitive, it employs yntactic constructscalled Typed Feature Structures (TFSs).
The ,~vocab-ulary~ of the language, its signature, consists ofunary predicates ( orts) and binary predicates (fea-tures).
Moreover, there is an ordering on the sorts(yielding a lower semi-lattice).
The structures overwhich the language is interpreted are determined inthat they have to satisfy certain axioms: the featuresgive partial functions, and the ordering on the sorts is1.
Which are sometimes only motivated byprocessing consider-ations.reflected as subset inclusion (unary predicates givesets).
They are not fully specific, however, whichreflects the situation in knowledge representationwhere the domain of discourse is not completelyspecified.
By adding new axioms, this domain ismade more and more specific; in the extreme case,one structure is singled out.The sort signature is extendable through (recursive)definitions of new sorts; these are done by definingexplicit constraints which come from the languageitself (the TFS constraint language).
The sorts areorganized into an inheritance hierarchy, with a clean(logical, algebraic and type-theoretic) semantics ofinheritance inthe object-oriented programmingstyle.
The subset of first-order logic can be mademore complex by adding logical connectives, uchas negation and quantification.Given the signature, which defines the constraintsavailable to the user, the user has the option toextend the language by specifying new predicates.These are interpreted as relations between the ele-ments of the domain of the respective interpretationstructure.
The language is still a subset of first-orderlogic; thus, its syntax can be chosen like the one ofdefinite clauses, but with TFS's instead of first-orderterms.The specification language thus obtained allows theuser to create partial specifications that can be incre-mentally extended, and to express controlled egreesof abstraction and precision.
Although of consider-able expressive power, this specification language isexecutable, but the control information isbeabstracted; that is, formally the execution is non-deterministic, and there will be no explicit program-ming feature to express control.
This has a good rea-son: control information coded in programs ispecific to particular applicatiorts.
For grammars forexample, for the same underlying logical specifica-tion the control will be different in parsing or in gen-eration, or even in different parsers (e.g., forindexing or for granunar checking).
Thus, abstract-ing from control is important for gaining enericity:logical specifications apply to more problems thanprograms.
The knowledge specification language isused in a first step in the generation of correctprograms.3 Automating the acquisition oflinguistic descriptionsWe assume that the acquisition of linguistic informa-tion will build upon the definition of broad linguisticAcrF.s DE COLING-92, NANTES, 23-28 AOt~T 1992 8 3 0 PROC.
OF COLING-92, NAbrrES, AUG. 23-28, 1992categories formalized as the initial and secondarylevel of linguistic abstraction described above.
In aComputer-Aided Linguistic Engineering fnunework,the acquisition of linguistic inibrmation is targetedtowards the needs of specific applications: we alsoassume that the linguist uses for testing purposes aset of examples of the kind of text Ire describes (testcase).
These exanlples (fire <~corpus>~) canbe con-stmcted (as a way for example to specify file kind ofdialogue nvisaged fox" a natural language man.,machine interface) or can come from existing texts,for example, existing teclmical documentation,The acquisition of linguistic iulonuation coltsists indescribing in lull detail the set of linguistic phenom-ena occurring in the corpus as a specialization of lin-guistic axioms and principles.
The acquisition isperformed in two steps.
First, the linguist uses cor-pus analysis tools to characterize the particularitiesof the sublanguage phenomena occurring in the cor-pus and to define the coverage (sel ot' linguistic ate-gories) that should be reached, q~en, the linguistdescribes formally (i.e., using the specification lan-guage) in all details phenomena occun'ing in the co lpus, using corpus analysis tools to lind examples andto refine the categorization \[Ananiadou 90, Tsujii etal.
901.This approach to tim acquisition of linguistic knowl-edge leads to the delinition of a precise methodology(basic concepts and working procedures) upportedby a specific set of sollware tools:.
Concepts.
The basic concepts underlying thismethodology are the notions of sublanguage andcoverage \[Grishman/Kittredge 86, Kittredge/Lehrberger 82, Gristmlm~lirsclnnan/Ngo 86\].Given a corpus, a linguist should be able to give ahigh level description of it in terms of its linguis-tic particularities which are not lkmnd m otherkinds of texts, and in terms of the set of lingttisticphenomena which are occurring in it: these con-cepts hould be defined operationally toallow thelinguist o apply them to actual texts..
Working procedure.
A working procedure delinesthe steps to be taken in the acquisition of linguis-tic knowledge, both in larger steps (characteriza-tion of the corpus, then acquisition) and in detailssuch as how to document the phenomenadescribed, to link a formal description to exam-pies of the corpus, to check the consistency o1' thedescription with other parts of the specification,etc.
It also gives examples of, e.g., how to detinenew lexical semantic classes using a cluster anal-ysis tool (see below).o Software tools, q he concepts and working proce-dures are suppo~ted by a set of specialized lin-guistic software tools integrated in a Computer~Aided Linguistic Engineering workstation.These ~ltware tools suplx)rling the acquisition oflinguistic knowledge should have tire tollowiugfunctio~mlities:.
Taggh~g.
A first set of fmictionafities is to tag acorpus using linguistic markels uch as the cate-gory of word forms, their inflection, etc.
Severallevels of sophistication will be distinguisheddepending on the availal~ility of the appropriateset of pat~uneters: sels of closed categories, etsof word fonns, sets of nlorphemes, definition ofphrase boundaries, etc.Text DBMS.
A tagged coq)us is be loaded into atext DBMS for further exploitation, and accessedthrough aspecialized linguistic interlace (using aspecialized query language).. Statistics and cluster analysis.
Two kinds ofinl2mnation can be extracted linm a tagged cornpus: statistical inlbnnation and concordance andclustering ildbnnation.
Statistical and clusteringaualysis algorithms will be implemented andincorlxn'ated ,as l~unctionalities of the linguisticinterlace of the text database.Semantic editor The essential operation in lin-guistic acquisition is the creation of specializa-finns of existing categories.
A semantic editortakes into account the delinition of existingclasses and interactively guides the user in thecreation of instances.4 Automat ing  the  generat ion  o f  NLPprogramsIn the development process ketched above (SectionI) the last step is the implementation f the system.Automatic gencratinn of NI.P soltware Ires beenlocused to the (crucial) domain of lexical resources(how to build generic rcsom~;es and compilers thatcan extract electronic dictionaries from a lexicalknowledge base lbr NLP systems) and to the domainof ,~reversible grammars,, 1.The process of transfomfing a specilication i to anelficient program is very similar to compilation.
Ifthe structure of a set of specilication is stable, a com-piler can be built to genelate a program.
This is theapproach envisaged for lexical infnnnation 2.
Lexical\].
Seefor exmnple file I)taw.eedings of the ACL Workshop onReversible Grammars, Berkeley, June 1991.Acq3/s DE COLING-92, NANTES, 23-28 An(n 1992 8 3 I l'r~oc.
O1: (5OLINGO2, NANTES, AU?;.
23-28, 1992information is here considered as <<static, informa-tion: once the structure of the lexicon is defined, add-ing or removing an entry will not modify thecompilation process.
This is less tree for grammati-cal information which defines how the basic linguis-tic buildings blocks, i.e., lexical entries, arecombined into larger structures.
Here, the needs mayvary depending on the processing requirements ofdifferent NLP applications.
For example, a grammarchecker and an indexing system will most probablynot use the same parsing scheme: they will treat dif-ferently errors and ambiguities.
Thus, a generalapproach is needed.Since the knowledge specification language isexe-cutable, this means that, to generate a program, thereare two basic choices to be made: the selection ofdata structures and the selection of control struc-tures.
The nature and the complexity of these choicesdepend on the distance between the specificationlanguage and the targeted programming language.As a programming language into which the specifi-cations are derived, we envisage to use the Con-stralnt Logic Programming (CLP) language LIFEdeveloped at DEC-PRL \[Ai't-Kaci/Meyer 90, Ai't-Kaci/Podelski 91\].
The reason is that its formal foun-dation has parts in common with the KnowledgeSpecification Language; in particular, its basic datastructures are also Typed Feature Structures, thusensuring abasic level of compatibility between thetwo.
Another eason is its descriptive power, its effi-ciency and its flexibility in execution (~data-driven.
): LIFE subsumes the two main program-ming paradigms (logic programming, asin PRO-LOG, and functional programming, asin LISP orML).
That is, a .
logic.
(or ~functional>>) program-mer may stick to his favorite programming style andstill write code in LIFE.Since the data model is the same, to generate an effi-cient program form a specification, the user will onlyhave to select appropriate control structures, Forexample, to generate dictionaries for a parsing pro-gram, the only refinement the user will have todevelop is to define an efficient indexing mechanismthat allows a parser direct access to a lexical entry.
Ingenerating NLP parsers or NLP generators, the userwill have to choose between a functional controlstructure (as in ML) or a relational control structure.as in PROLOG.
For the latter, additional choiceshave to be made, such as the ordering of clauses, theintroduction of cuts, etc.
\[Deville 90\].
Research incomputational linguistics has identified a few central2.
This is also the approach envisaged in the ESPRIT projectMultilex and in the Eurotra-7 study.computational concepts appropriate for NLP, amongthem regular grammars and regular transducers, aug-mented context-free grammars and tree transducers.In particular, augmented context-free grammars arethe framework of the research in so-called ~<revers-ible grammars>,.
This research can be used in thedevelopment of NLP processing schemes defined asannotations tothe specification \[Deville 90, Uszkor-eit 91\].Assuming that a set of specifications is stable, it ispossible to write a specialized compiler to generate aLIFE program for, e.g., parsing or generation.
Thiscompiler will embed the control choices that adesigner of a parser makes when developing a pars-ing algorithm.
This kind of generation has beenshown practically feasible for lexieal information,and research on ,<reversible grammars~> has demon-strated the feasibility for grammatical information aswell (see for exanlple \[Dymetman/Isabelle 88\]whopresent aprototype of a machine translation systemcapable of translating in both directions using thesame grammars and dictionaries).However, we have also a long term more ambitiousgoal, which is to develop methods and tools for fi.dlyautomating the generation of a program.
Using thesetools, the user will interactively guide the system inthe generation of a program, experimenting with var-ious choices and recording the design decisions forcontrol to be used in a fully automatic step once thedesign is completed \[Biggerstaff/Perlis 89\].5 Towards Computer -A idedLinguistic Engineeringwe have outlined a frmnework for Computer-AidedLinguistic Engineering based on the concepts ofreusability and automatic programming \[Biggerstaff/Peflis 89\], and showed that we have already all thebasic ingredients (although at various degree of elab-oration):?
aTFS based specification language \[Emele/Zajac90a, Emele/Zajac 90b\];?
a TFS based constraint logic programming lan-guage \[Ai't-Kaci/Meyer 90, Ai't-Kaci/Podelski91\];?
a methodology for the generation of NLP pro-grams \[Devine 90, Uszkoreit 91\];?
a methodology for linguistic acquisition \[Ananiaodou 90, Tsujii et al 90\].Acaxs DE COLING-92, NAMES, 23-28 AOt~T 1992 8 3 2 PROC.
OF COLING-92, NANTES, AUG. 23-28, 1992To arrive a a fully detailed framework tlmt could beimplemented in a Computer-Aided Linguistic Engi-neering workstation, the major parts that need to beresearched and developed are the elaboration of anannotation system to bridge the gap between thespecification language and the programming lan-guage, and the development of adequate ools for theautomated acquisition of linguistic knowledge.
Ofcourse, this approach as to be tested on a largerscale than what have been possible using the partialimplementations available at present.Part of the framework described in this paper is pres-ently used in several on-going projects or proposedin several projects proposals.
In the current projects,the primary domain of application of this frameworkis in the area of lexical representations (e.g., theMULTILEX ESPRIT project, the EUROLANGEUREKA project, the DELLS LRE proposal),Acknowledgments.
This paper was written while Iwas working in the Polygloss project at the IMS(University of Stuttgart).
Many of the ideas pre-sented in this paper have been discussed during thepreparation of an ESPRIT project proposal on Com-puter-Aided Linguistic Engineering.
I would espe-ciaUy like to thank Hassan Ai1-Kaci, Gabriel B~s,Ulrich Heir, Andreas Pedelski, and Harts Uszkoreit.References\[All-Kaci 84} Hassan Al't-Kaci.
A Lattice TheoreticApproach to Computation based on a Calculus ofPartially Ordered Types Structures.
Ph.D Dis~r-tation, University of Pennsylvania.\[Ail-Kaci 86\] Hassan Al't-Kaci.
~<An AlgebraicSemantics Approach to the Effective Resolutionof Type Equations>>.
Theoretical Computer Sci-ence 45,293-351.\[Ai~-Kaci/Meyer 90\] Hassan Al't-Kaci and RichardMeyer.
,~Wiid LIFE, a user manual>>.
DEC-PRLTechnical Note PRL-TN-l, Rueil-Malmaison,France, 1990.\[AiVKaci/Podelski 91 \] Hassan Alt-Kaci andAndreas Podelski.
<<Towards a meaning ofLIFE~.
DEC-PRL Research Report PRL-RR-11,RueiI-Malmaison, France, June 1991.\[Ananiadou 90\] S. Ananiadou.
,<The use of statisticaltechniques in identifying sublanguage patterns,.Eurotra Research Report, 1990.\[Biggerstaff/Perlis 89\] Ted J. Biggerstaff and Alan J.Perlis (eds).
Software Reusability, 2 volumes.ACM Press - Addison-Wesley, 1989.\[Carpenter 90\] Bob Carpenter.
~'I~yped feature struc-tures: inheritance, (in)equality and extensional-ity)>.
Proc.
of the Workshop on Inheritance inNatural Language Processing, Institute for Lan-guage Technology and AI, Tilhnrg University,Netherlands, August 1990.\[Deville 90\] Yves Deville.
Logic programming.
Sys-tematic Program Development.
Addison-Wesley,1990.\[Dymetman/lsabelle 88\] Marc Dymetman and PierreIsabelle.
,~Reversible logic grammars for machinetranslation>>.
Proc.
of the 2nd International Con-ference on Theoretical attd MethodologicalIssues in Machine 7)'anslation of Natural Lan-guage, June 1988, Pittsburgh.\[Dymetumn et al 90\] Marc Dymetman, Pierre Isa-belle and Franqois Perrault.
~(A symmetricalapproach to parsing and generation,.
Prec.
of the13th International Conference on ComputationalLinguistics - COLING'90, Helsinki, August1990.\[Emele 1988\] Martin Emele.
<<A typed feature stmc?tare unification-based approach to generation>,.Proc.
of the WGNLC of the IECE, Oiso Univer-sity, Japan, 1988.\[Emele 1991\] Martin Emele.
<<Unification with lazynon-redundant copying>>.
29th Annual Meeting ofthe ACL, Berkeley, June 1991.\[Emele/Zajac 90a\] Martin Emele and Rdmi Zajac.aA fixed-point semantics for feature type sys-tems,.
Proc.
of the 2nd Workshop on Conditionaland :l)~ped Rewriting Systems - CTRS'90, Moll-trdal, June 1990.\[Emele/Zajac 90b\] Martin Emele and Rdmi Zajac.<<Typed Unification Grammars>>.
Proc.
of the 13thInternational Conference on Computational Lin-guistics - COLING'90, Helsinki, August 1990.\[Emele t al.
90\] Martin Emele, Ulrich Heir, StefanMomma and R~mi Zajac.
,<Organizing linguisticknowledge for multilingual generation>>.
Proc.
ofthe 13th International Conference on Computa-tional Linguistics - COLING" 90, Helsinki,August 1990.\[Franz 90\] Alex Franz.
,~A parser for HPSG,.
CMUreport CMU-LCL-90-3, Laboratory for Computa-tional Linguistics, Carnegie Mellon University,July 1990.\[Grishman/Kittredge86\] R. Grishman and R. Kit-tredge.
Analyzing Language in RestrictedDomains.
Laurence Edbaum, 1986.\[Grishrnan/Hirschman/Ngo 861 Hirschman L. Grish-man, R. and T.N.
Ngo.
,,Discovery procedures forAc'r~ DE COLING-92, NAturES, 23-28 AO~" 1992 8 3 3 PROC.
OF COLING-92, NANTES, Autl.
23-28.
1992sublanguage s lecfional patterns: initial experi-ments~.
Computational Linguistics, 12(3):205-215, 1886.\[Kittredge/Lehrberger 82\] R. Kittredge and J. Lehr-berger.
Sublanguage: Studies of Language inRestricted Semantic Domains.
De Gruyter, 1982.\[Pollard 90\] Carl Pollard.
~Sorts in unification-basedgrammar and what they mean~.
In M. Pinkal andB.
Gregor (eds.
), Unification in Natural Lan-guage Analysis, MIT Press.
(in press)\[Pollard/Moshier 90\] Carl Pollard and Drew Mosh-ier.
~Unifying partial descriptions ofsets,>.
In P.Hanson (ed.)
Information, Language and Cogni-tion, Vancouver Studies in Cognitive Science 1,University of British Columbia Press, Vancouver.
(in press)\[Pollard/Sag 87\] Carl Pollard and Ivan A.
Sag.
Infor-mation-Based Syntax and Semantics.
CSL1 Lec-ture Notes 13, Chicago University Press, 1987.\[Pollard/Sag 91\] Carl Pollard and Ivan A. Sag.Agreement, Binding and Control.
Information-Based Syntax and Semantics.
Volume 2.
Toappear.\[Smolka 88\] Gert Smolka.
~A Feature Logic withSubsorts.. LILOG Report 33, IBM DeutschlandGmbH, Stuttgart.\[Smolka 89\] Gert Smolka.
~Feature Constraint Log-ics for Unification Grammars>~.
IWBS Report 93,IBM Deutschland GmbH, Stuttgart.\[Smolka/A'ft-Kaci 88\] Gert Smolka and Hassan Ai't-Kaci.
,dnheritance Hierarchies: Semantics andUnificatiom~.
J.
Symbolic Computation 7, 343-370.\[Strzalkowski 90\] Tomek Strzalkowski.
~How toinvert a natural language parser into an efficientgenerator: an algorithm for logic grammars>>.Proc.
of the 13th International Conference onComputational Linguistics - COLING'90,August 1990, Helsinki.\[Tsujii et al 90\] Tsujii, J., Ananiadou S., Carroll J.,and Phillips J.D.
,~Methodologies for the devel-opment of sublanguage MT systems~.
CCLResearch Report CCL/90-10, UMIST, Manches-ter, 1990.\[Uszkoreit 91\] Hans Uszkoreit.
,~Strategies for add-ing control information to declarative gram-marsh.
In Proceedings of the 1991 AnnualMeeting of the Association of Computational Lin-guistics, Berkeley, 1991.\[Zajac 89\] R6mi Zajac.
~A transfer model using atyped feature structure rewriting system withinheritance~.
Proc.
of the 27th Annual Meeting ofthe ACL, 26--27 June 1989, Vancouver.\[Zajac 90a\] R6mi Zajac.
,~A relational approach totranslatiom,.
Proc.
of the 3rd International Con-ference on Theoretical and MethodologicalIssues in Machine Translation of Natural Lan-guage, 11-13 June 1990, Austin.\[Zajac 90b\] R~mi Zajac.
,~Semantics oftyped featurestructures~.
Presented at the International Work-shop on Constraint Based Formalisms for Natu-ral Language Generation, Bad Teinach,Germany, November 1990.ACTES DE COLING-92, NANTES, 23-28 AOC'r 1992 8 3 4 PROC.
OF COLING-92, NANTES.
AUG. 23-28, 1992
