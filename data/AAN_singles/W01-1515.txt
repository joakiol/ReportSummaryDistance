Annotation Tools Based on the Annotation Graph APISteven Bird, Kazuaki Maeda, Xiaoyi Ma and Haejoong LeeLinguistic Data Consortium, University of Pennsylvania3615 Market Street, Suite 200, Philadelphia, PA 19104-2608, USAfsb,maeda,xma,haejoongg@ldc.upenn.eduAbstractAnnotation graphs provide an efficientand expressive data model for linguisticannotations of time-series data.
Thispaper reports progress on a completeopen-source software infrastructuresupporting the rapid development oftools for transcribing and annotatingtime-series data.
This general-purpose infrastructure uses annotationgraphs as the underlying model, andallows developers to quickly createspecial-purpose annotation tools usingcommon components.
An applicationprogramming interface, an I/O library,and graphical user interfaces aredescribed.
Our experience has shownus that it is a straightforward task tocreate new special-purpose annotationtools based on this general-purposeinfrastructure.1 IntroductionIn the past, standardized file formats and codingpractices have greatly facilitated data sharing andsoftware reuse.
Yet it has so far proved impossibleto work out universally agreed formats and codesfor linguistic annotation.
We contend that this is avain hope, and that the interests of sharing andreuse are better served by agreeing on the datamodels and interfaces.Annotation graphs (AGs) provide an efficientand expressive data model for linguistic anno-tations of time-series data (Bird and Liberman,Figure 1: Architecture for Annotation Systems2001).
Recently, the LDC has been develop-ing a complete software infrastructure supportingthe rapid development of tools for transcribingand annotating time-series data, in cooperationwith NIST and MITRE as part of the ATLASproject, and with the developers of other widelyused annotation systems, Transcriber and Emu(Bird et al, 2000; Barras et al, 2001; Cassidy andHarrington, 2001).The infrastructure is being used in the devel-opment of a series of annotation tools at the Lin-guistic Data Consortium.
Two tools are shown inthe paper: one for dialogue annotation and onefor interlinear transcription.
In both cases, thetranscriptions are time-aligned to a digital audiosignal.This paper will cover the following points: theapplication programming interfaces for manipu-lating annotation graph data and importing datafrom other formats; the model of inter-componentcommunication which permits easy reuse of soft-ware components; and the design of the graphicaluser interfaces.2 Architecture2.1 General architectureFigure 1 shows the architecture of the toolscurrently being developed.
Annotation tools,such as the ones discussed below, must providegraphical user interface components for signalvisualization and annotation.
The communicationbetween components is handled through anextensible event language.
An applicationprogramming interface for annotation graphshas been developed to support well-formedoperations on annotation graphs.
This permitsapplications to abstract away from file formatissues, and deal with annotations purely at thelogical level.2.2 The annotation graph APIThe application programming interface providesaccess to internal objects (signals, anchors,annotations etc) using identifiers, representedas formatted strings.
For example, an AGidentifier is qualified with an AGSet identifier:AGSetId:AGId.
Annotations and anchors aredoubly qualified: AGSetId:AGId:AnnotationId,AGSetId:AGId:AnchorId.
Thus, the identifierencodes the unique membership of an object inthe containing objects.We demonstrate the behavior of the API witha series of simple examples.
Suppose we havealready constructed an AG and now wish to createa new anchor.
We might have the following APIcall:CreateAnchor("agSet12:ag5", 15.234, "sec");This call would construct a new anchor objectand return its identifier: agSet12:ag5:anchor34.Alternatively, if we already have an anchor iden-tifier that we wish to use for the new anchor (e.g.because we are reading previously created anno-tation data from a file and do not wish to assignnew identifiers), then we could have the followingAPI call:CreateAnchor("agset12:ag5:anchor34",15.234, "sec");This call will return agset12:ag5:anchor34.Once a pair of anchors have been created itis possible to create an annotation which spansthem:CreateAnnotation("agSet12:ag5","agSet12:ag5:anchor34","agSet12:ag5:anchor35","phonetic" );This call will construct an annotationobject and return an identifier for it, e.g.agSet12:ag5:annotation41.
We can now addfeatures to this annotation:SetFeature("agSet12:ag5:annotation41","date", "1999-07-02" );The implementation maintains indexes on allthe features, and also on the temporal informationand graph structure, permitting efficient searchusing a family of functions such as:GetAnnotationSetByFeature("agSet12:ag5", "date", "1999-07-02");2.3 A file I/O libraryA file I/O library (AG-FIO) supports input andoutput of AG data to existing formats.
Formatscurrently supported by the AG-FIO libraryinclude the TIMIT, BU, Treebank, AIF (ATLASInterchange Format), Switchboard and BASPartitur formats.
In time, the library will handleall widely-used signal annotation formats.2.4 Inter-component communicationFigure 2 shows the structure of an annotation toolin terms of components and their communication.The main program is typically a small scriptwhich sets up the widgets and provides callbackfunctions to handle widget events.
In thisexample there are four other components whichMain program - a small scriptWaveformdisplayTranscriptioneditorInternalrepresentationFile input/ outputAG-GUI-APIAG-GUI-API AG-APIAG-FIO-APIFigure 2: The Structure of an Annotation ToolMain programWaveform display AG-API Transcription editorUser types Control-G Update DisplaySetRegion t1 t2 AG::SetAnchorOffset SetRegion t1 t2UpdateInternal RepresentationFigure 3: Inter-component Communicationare reused by several annotation tools.
The AGand AG-FIO components have already beendescribed.
The waveform display component (ofwhich there may be multiple instances) receivesinstructions to pan and zoom, to play a segmentof audio data, and so on.
The transcriptioneditor is an annotation component which isspecialized for a particular coding task.
Most toolcustomization is accomplished by substituting forthis component.Both GUI components and the main programsupport a common API for transmitting andreceiving events.
For example, GUI componentshave a notion of a ?current region?
?
thetimespan which is currently in focus.
Awaveform component can change an annotationcomponent?s idea of the current region bysending a SetRegion event (Figure 3).
Thesame event can also be used in the reversedirection.
The main program routes the eventsbetween GUI components, calling the annotationgraph API to update the internal representation asneeded.
With this communication mechanism, itis straightforward to add new commands, specificto the annotation task.2.5 Reuse of software componentsThe architecture described in this paper allowsrapid development of special-purpose annotationtools using common components.
In particular,our model of inter-component communicationfacilitates reuse of software components.The annotation tools described in the nextsection are not intended for general purposeannotation/transcription tasks; the goal is notto create an ?emacs for linguistic annotation?.Instead, they are special-purpose tools based onthe general purpose infrastructure.
These GUIFigure 4: Dialogue Annotation Tool for theTRAINS/DAMSL Corpuscomponents can be modified or replaced whenbuilding new special-purpose tools.3 Graphical User Interfaces3.1 A spreadsheet componentDialogue annotation typically consists of assign-ing a field-structured record to each utterance ineach speaker turn.
A key challenge is to handleoverlapping turns and back-channel cues withoutdisrupting the structure of individual speaker con-tributions.
The tool side-steps these problems bypermitting utterances to be independently alignedto a (multi-channel) recording.
The records aredisplayed in a spreadsheet; clicking on a row ofthe spreadsheet causes the corresponding extentof audio signal to be highlighted.
As an extendedrecording is played back, annotated sections arehighlighted, in both the waveform and spread-sheet displays.Figure 4 shows the tool with a section of theTRAINS/DAMSL corpus (Jurafsky et al, 1997).Note that the highlighted segment in the audiochannel corresponds to the highlighted annotationin the spreadsheet.3.2 An interlinear transcription componentInterlinear text is a kind of text in whicheach word is annotated with phonological,morphological and syntactic information(displayed under the word) and each sentenceis annotated with a free translation.
Our toolFigure 5: Interlinear Transcription Toolpermits interlinear transcription aligned to aprimary audio signal, for greater accuracy andaccountability.
Whole words and sub-parts ofwords can be easily aligned with the audio.Clicking on a piece of the annotation causesthe corresponding extent of audio signal to behighlighted.
As an extended recording is playedback, annotated sections are highlighted (bothwaveform and interlinear text displays).The screenshot in Figure 5 shows the tool withsome interlinear text from Mawu (a Manding lan-guage of the Ivory Coast, West Africa).3.3 A waveform display componentThe tools described above utilize WaveSurferand Snack (Sjo?lander, 2000; Sjo?lander andBeskow, 2000).
We have developed a plug-infor WaveSurfer to support the inter-componentcommunication described in this paper.4 Available Software and Future WorkThe Annotation Graph Toolkit, version 1.0, con-tains a complete implementation of the annota-tion graph model, import filters for several for-mats, loading/storing data to an annotation server(MySQL), application programming interfaces inC++ and Tcl/tk, and example annotation tools fordialogue, ethology and interlinear text.
The sup-ported formats are: xlabel, TIMIT, BAS Parti-tur, Penn Treebank, Switchboard, LDC Callhome,CSV and AIF level 0.
All software is distributedunder an open source license, and is availablefrom http://www.ldc.upenn.edu/AG/.Future work will provide Python and Perl inter-faces, more supported formats, a query languageand interpreter, a multichannel transcription tool,and a client/server model.5 ConclusionThis paper has described a comprehensive infras-tructure for developing annotation tools based onannotation graphs.
Our experience has shown usthat it is a simple matter to construct new special-purpose annotation tools using high-level soft-ware components.
The tools can be quickly cre-ated and deployed, and replaced by new versionsas annotation tasks evolve.AcknowledgementsThis material is based upon work supported by theNational Science Foundation under Grant Nos.9978056, 9980009, and 9983258.ReferencesClaude Barras, Edouard Geoffrois, Zhibiao Wu, and MarkLiberman.
2001.
Transcriber: development and use of atool for assisting speech corpora production.
SpeechCommunication, 33:5?22.Steven Bird and Mark Liberman.
2001.
A formalframework for linguistic annotation.
SpeechCommunication, 33:23?60.Steven Bird, David Day, John Garofolo, John Henderson,Chris Laprun, and Mark Liberman.
2000.
ATLAS: Aflexible and extensible architecture for linguistic annotation.In Proceedings of the Second International Conference onLanguage Resources and Evaluation.
Paris: EuropeanLanguage Resources Association.Steve Cassidy and Jonathan Harrington.
2001.
Multi-levelannotation of speech: An overview of the emu speechdatabase management system.
Speech Communication,33:61?77.Daniel Jurafsky, Elizabeth Shriberg, and Debra Biasca.1997.
Switchboard SWBD-DAMSL Labeling ProjectCoder?s Manual, Draft 13.
Technical Report 97-02,University of Colorado Institute of Cognitive Science.
[stripe.colorado.edu/?jurafsky/manual.august1.html].Ka?re Sjo?lander and Jonas Beskow.
2000.
Wavesurfer ?
anopen source speech tool.
In Proceedings of the 6thInternational Conference on Spoken Language Processing.http://www.speech.kth.se/wavesurfer/.Ka?re Sjo?lander.
2000.
The Snack sound toolkit.http://www.speech.kth.se/snack/.
