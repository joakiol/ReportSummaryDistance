Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 372?381,Honolulu, October 2008. c?2008 Association for Computational LinguisticsTriplet Lexicon Models for Statistical Machine TranslationSas?a Hasan, Juri Ganitkevitch, Hermann Ney, Jesu?s Andre?s-Ferrer?
?Human Language Technology and Pattern Recognition, RWTH Aachen University, Germany?Universidad Polite?cnica de Valencia, Dept.
Sist.
Informa?ticos y Computacio?n{hasan,ganitkevitch,ney}@cs.rwth-aachen.de jandres@dsic.upv.esAbstractThis paper describes a lexical trigger modelfor statistical machine translation.
We presentvarious methods using triplets incorporatinglong-distance dependencies that can go be-yond the local context of phrases or n-grambased language models.
We evaluate the pre-sented methods on two translation tasks in areranking framework and compare it to the re-lated IBM model 1.
We show slightly im-proved translation quality in terms of BLEUand TER and address various constraints tospeed up the training based on Expectation-Maximization and to lower the overall num-ber of triplets without loss in translation per-formance.1 IntroductionData-driven methods have been applied very suc-cessfully within the machine translation domainsince the early 90s.
Starting from single-word-based translation approaches, significant improve-ments have been made through advances in mod-eling, availability of larger corpora and more pow-erful computers.
Thus, substantial progress madein the past enables today?s MT systems to achieveacceptable results in terms of translation quality forspecific language pairs such as Arabic-English.
Ifsufficient amounts of parallel data are available, sta-tistical MT systems can be trained on millions of?The work was carried out while the author was at the Hu-man Language Technology and Pattern Recognition group atRWTH Aachen University and partly supported by the Valen-cian Conselleria d?Empresa, Universitat i Cie`ncia under grantsCTBPRA/2005/ and BEFPI/2007/014.targetsourcee e?fFigure 1: Triplet example: a source word f is triggeredby two target words e and e?, where one of the words iswithin and the other outside the considered phrase pair(indicated by the dashed line).sentence pairs and use an extended level of contextbased on bilingual groups of words which denotethe building blocks of state-of-the-art phrase-basedSMT systems.Due to data sparseness, statistical models are of-ten trained on local context only.
Language mod-els are derived from n-grams with n ?
5 and bilin-gual phrase pairs are extracted with lengths up to10 words on the target side.
This captures the localdependencies of the data in detail and is responsi-ble for the success of data-driven phrase-based ap-proaches.In this work, we will introduce a new statisticalmodel based on lexicalized triplets (f, e, e?)
whichwe will also refer to as cross-lingual triggers ofthe form (e, e?
?
f).
This can be understoodas two words in one language triggering one wordin another language.
These triplets, modeled byp(f |e, e?
), are closely related to lexical translationprobabilities based on the IBM model 1, i.e.
p(f |e).Several constraints and setups will be described lateron in more detail, but as an introduction one can372think of the following interpretation which is de-picted in Figure 1: Using a phrase-based MT ap-proach, a source word f is triggered by its trans-lation e which is part of the phrase being consid-ered, whereas another target word e?
outside thisphrase serves as an additional trigger in order to al-low for more fine-grained distinction of a specificword sense.
Thus, this cross-lingual trigger modelcan be seen as a combination of a lexicon model (i.e.f and e) and a model similar to monolingual long-range (i.e.
distant bigram) trigger models (i.e.
e ande?, although these dependencies are reflected indi-rectly via e?
?
f ) which uses both local (in-phrase)and global (in-sentence) information for the scoring.The motivation behind this approach is to get non-local information outside the current context (i.e.
thecurrently considered bilingual phrase pair) into thetranslation process.
The triplets are trained via theEM algorithm, as will be shown later in more detail.2 Related WorkIn the past, a significant number of methods hasbeen presented that try to capture long-distance de-pendencies, i.e.
use dependencies in the data thatreach beyond the local context of n-grams or phrasepairs.
In language modeling, monolingual triggerapproaches have been presented (Rosenfeld, 1996;Tillmann and Ney, 1997) as well as syntactical meth-ods that parse the input and model long-range de-pendencies on the syntactic level by conditioning onthe predecessing words and their corresponding par-ent nodes (Chelba and Jelinek, 2000; Roark, 2001).The latter approach was shown to reduce perplex-ities and improve the WER in speech recognitionsystems.
One drawback is that the parsing processmight slow down the system significantly and theapproach is complicated to be integrated directly inthe search process.
Thus, the effect is often shownoffline in reranking experiments using n-best lists.One of the simplest models that can be seen inthe context of lexical triggers is the IBM model 1(Brown et al, 1993) which captures lexical depen-dencies between source and target words.
It can beseen as a lexicon containing correspondents of trans-lations of source and target words in a very broadsense since the pairs are trained on the full sentencelevel.
The model presented in this work is very closeto the initial IBM model 1 and can be seen as takinganother word into the conditioning part, i.e.
the trig-gering items.1 Furthermore, since the second trig-ger can come from any part of the sentence, we alsohave a link to long-range monolingual triggers aspresented above.A long-range trigram model is presented in(Della Pietra et al, 1994) where it is shown how toderive a probabilistic link grammar in order to cap-ture long-range dependencies in English using theEM algorithm.
Expectation-Maximization is usedin the presented triplet model as well which is de-scribed in more detail in Section 3.
Instead of deriv-ing a grammar automatically (based on POS tags ofthe words), we rely on a fully lexicalized approach,i.e.
the training is taking place at the word level.Related work in the context of fine-tuning lan-guage models by using cross-lingual lexical triggersis presented in (Kim and Khudanpur, 2003).
Theauthors show how to use cross-lingual triggers on adocument level in order to extract translation lexi-cons and domain-specific language models using amutual information criterion.Recently, word-sense disambiguation (WSD)methods have been shown to improve translationquality (Chan et al, 2007; Carpuat and Wu, 2007).Chan et al (2007) use an SVM based classifier fordisambiguating word senses which are directly in-corporated in the decoder through additional fea-tures that are part of the log-linear combination ofmodels.
They use local collocations based on sur-rounding words left and right of an ambiguous wordincluding the corresponding parts-of-speech.
Al-though no long-range dependencies are modeled, theapproach yields an improvement of +0.6% BLEU onthe NIST Chinese-English task.
In Carpuat and Wu(2007), another state-of-the-art WSD engine (a com-bination of naive Bayes, maximum entropy, boost-ing and Kernel PCA models) is used to dynamicallydetermine the score of a phrase pair under consid-eration and, thus, let the phrase selection adapt tothe context of the sentence.
Although the baseline issignificantly lower than in the work of Chan et al,this setup reaches an improvement of 0.5% BLEUon the NIST CE task and up to 1.1% BLEU on the1Thus, instead of p(f |e) we model p(f |e, e?)
with differentadditional constraints as explained later on.373IWSLT?06 test sets.The work in this paper tries to complement theWSD approaches by using long-range dependen-cies.
If triggers from a local context determine dif-ferent lexical choice for the word being triggered,the setting is comparable to the mentioned WSDapproaches (although local dependencies might al-ready be reflected sufficiently in the phrase models).A distant second trigger, however, might have a ben-eficial effect for specific languages, e.g.
by captur-ing word splits (as it is the case in German for verbswith separable prefixes) or, as already mentioned, al-lowing for a more fine-grained lexical choice of theword being triggered, namely based on another wordwhich is not part of the current local, i.e.
phrasal,context.The basic idea of triplets of the form (e, f ?
?
f),called multi-word extensions, is also mentioned in(Tillmann, 2001) but neither evaluated nor investi-gated in further detail.In the following sections, we will describe themodel proposed in this work.
In Section 3, a de-tailed introduction is given, as well as the EM train-ing and variations of the model.
The different set-tings will be evaluated in Section 4, where we showexperiments on the IWSLT Chinese-English andTC-STAR EPPS English-Spanish/Spanish-Englishtracks.
A discussion of the results and further ex-amples are given in Section 5.
Final remarks andfuture work are addressed in Section 6.3 ModelAs an extension to commonly used lexical wordpair probabilities p(f |e) as introduced in (Brownet al, 1993), we define our model to operate onword triplets.
A triplet (f, e, e?)
is assigned a value?
(f |e, e?)
?
0 with the constraint such that?e, e?
:?f?
(f |e, e?)
= 1.Throughout this paper, e and e?
will be referred to asthe first and the second trigger, respectively.
In viewof its triggers f will be termed the effect.For a given bilingual sentence pair (fJ1 , eI1), theprobability of a source word fj given the whole tar-get sentence eI1 for the triplet model is defined as:pall (fj |eI1) =1ZI?i=1I?k=i+1?
(fj |ei, ek), (1)where Z denotes a normalization factor based on thecorresponding target sentence length, i.e.Z =I(I ?
1)2.
(2)The introduction of a second trigger (i.e.
ek inEq.
1) enables the model to combine local (i.e.
wordor phrase level) and global (i.e.
sentence level) infor-mation.In the following, we will describe the training pro-cedure of the model via maximum likelihood esti-mation for the unconstrained case.3.1 TrainingThe goal of the training procedure is to maximize thelog-likelihood Fall of the triplet model for a givenbilingual training corpus {(fJ1 , eI1)}N1 consisting ofN sentence pairs:Fall :=N?n=1Jn?j=1log pall (fj |eIn1 ),where Jn and In are the lengths of the nth sourceand target sentences, respectively.
As there is noclosed form solution for the maximum likelihood es-timate, we resort to iterative training via the EM al-gorithm (Dempster et al, 1977).
We define the aux-iliary function Q(?
; ??)
based on Fall where ??
is thenew estimate within an iteration which is to be de-rived from the current estimate ?.
Here, ?
stands forthe entire set of model parameters to be estimated,i.e.
the set of all {?
(f |e, e?)}.
Thus, we obtainQ({?
(f |e, e?
)}; {??
(f |e, e?
)})=N?n=1Jn?j=1In?i=1In?k=i+1[Z?1n ?
(fj |ei, ek)pall (fj |eIn1 )?
(3)log(Z?1n ??
(fj |ei, ek))],where Zn is defined as in Eq.
2.
Using themethod of Lagrangian multipliers for the normaliza-tion constraint, we take the derivative with respect to374??
(f |e, e?)
and obtain:??
(f |e, e?)
=A(f, e, e?
)?f ?
A(f?, e, e?
)(4)where A(f, e, e?)
is a relative weight accumulatorover the parallel corpus:A(f, e, e?)
=N?n=1Jn?j=1?
(f, fj)Z?1n ?
(f |e, e?
)pall (fj |eIn1 )Cn(e, e?)
(5)andCn(e, e?)
=In?i=1In?k=i+1?
(e, ei)?
(e?, ek).The function ?
(?, ?)
denotes the Kronecker delta.The resulting training procedure is analogous to theone presented in (Brown et al, 1993) and (Tillmannand Ney, 1997).The next section presents variants of the ba-sic unconstrained model by putting restrictions onthe valid regions of triggers (in-phrase vs. out-of-phrase) and using alignments obtained from eitherGIZA++ training or forced alignments in order toreduce the model size and to incorporate knowledgealready obtained in previous training steps.3.2 Model variationsBased on the unconstrained triplet model presentedin Section 3, we introduce additional constraints,namely the phrase-bounded and the path-alignedtriplet model in the following.
The former reducesthe number of possible triplets by posing constraintson the position of where valid triggers may originatefrom.
In order to obtain phrase boundaries on thetraining data, we use forced alignments, i.e.
translatethe whole training data by constraining the transla-tion hypotheses to the target sentences of the trainingcorpus.Path-aligned triplets use an alignment constraintfrom the word alignments that are trained withGIZA++.
Here, we restrict the first trigger pair (f, e)to the alignment path as based on the alignment ma-trix produced by IBM model 4.These variants require information in addition tothe bilingual sentence pair (fJ1 , eI1), namely a corre-sponding phrase segmentation ?
= {piij} withpiij ={1 ?
a phrase pair that covers ei and fj0 otherwisefor the phrase-bounded method and, similarly, aword alignment A = {aij} whereaij ={1 if ei is aligned to fj0 otherwise.3.2.1 Phrase-bounded tripletsThe phrase-bounded triplet model (referred to aspphr in the following), restricts the first trigger e tothe same phrase as f , whereas the second trigger e?is set outside the phrase, resulting inpphr (fj |eI1,?)
=1ZjI?i=1I?k=1piij(1 ?
pikj)?
(fj |ei, ek).
(6)3.2.2 Path-aligned tripletThe path-aligned triplet model (denoted by palignin the following), restricts the scope of e to wordsaligned to f by A, yielding:palign(fj |eI1, A) =1ZjI?i=1I?k=1aij?
(fj |ei, ek) (7)where the Zj are, again, the appropriate normaliza-tion terms.Also, to account for non-aligned words (analo-gously to the IBM models), the empty word e0 isconsidered in all three model variations.
We showthe effect of the empty word in the experiments (Sec-tion 4).
Furthermore, we can train the presentedmodels in the inverse direction, i.e.
p(e|f, f ?
), andcombine the two directions in the rescoring frame-work.
The next section presents a set of experimentsthat evaluate the performance of the presented tripletmodel and its variations.4 ExperimentsIn this section, we describe the system setup used inthis work, including the translation tasks and the cor-responding training corpora.
The experiments arebased on an n-best list reranking framework.3754.1 SystemThe experiments were carried out using a state-of-the-art phrase-based SMT system.
The dynamicprogramming beam search decoder uses severalmodels during decoding by combining them log-linearly.
We incorporate phrase translation and wordlexicon models in both directions, a language model,as well as phrase and word penalties including adistortion model for the reordering.
While gener-ating the hypotheses, a word graph is created whichcompactly represents the most likely translation hy-potheses.
Out of this word graph, we generate n-best lists and use them to test the different setups asdescribed in Section 3.In the experiments, we use 10,000-best lists con-taining unique translation hypotheses, i.e.
duplicatesgenerated due to different phrase segmentations arereduced to one single entry.
The advantage of thisreranking approach is that we can directly test theobtained models since we already have fully gener-ated translations.
Thus, we can apply the triplet lex-icon model based on p(f |e, e?)
and its inverse coun-terpart p(e|f, f ?)
directly.
During decoding, since e?could be from anywhere outside the current phrase,i.e.
even from a part which lies beyond the currentcontext which has not yet been generated, we wouldhave to apply additional constraints during training(i.e.
make further restrictions such as i?
< i for atrigger pair (ei, ei?
)).Optimization of the model scaling factors is car-ried out using minimum error rate training (MERT)on the development sets.
The optimization criterionis 100-BLEU since we want to maximize the BLEUscore.4.2 Tasks4.2.1 IWSLTFor the first part of the experiments, we usethe corpora that were released for the IWSLT?07evaluation campaign.
The training corpus con-sists of approximately 43K Chinese-English sen-tence pairs, mainly coming from the BTEC cor-pus (Basic Travel Expression Corpus).
This is amultilingual speech corpus which contains tourism-related material, such as transcribed conversationsabout making reservations, asking for directions orconversations as taking place in restaurants.
For theexperiments, we use the clean data track, i.e.
tran-scriptions of read speech.
As the development setwhich is used for tuning the parameters of the base-line system and the reranking framework, we usethe IWSLT?04 evaluation set (500 sentence pairs).The two blind test sets which are used to evaluatethe final performance of the models are the officialevaluation sets from IWSLT?05 (506 sentences) andIWSLT?07 (489 sentences).The average sentence length of the training cor-pus is 10 words.
Thus, the task is somewhat lim-ited and very domain-specific.
One of the advan-tages of this setting is that preliminary experimentscan be carried out quickly in order to analyze the ef-fects of the different models in detail.
This and thesmall vocabulary size (12K entries) makes the cor-pus ideal for first ?rapid application development?-style setups without having to care about possibleconstraints due to memory requirements or CPUtime restrictions.4.2.2 EPPSFurthermore, additional experiments are based onthe EPPS corpus (European Parliament Plenary Ses-sions) as used within the FTE (Final Text Edition)track of the TC-STAR evaluations.
The corpus con-tains speeches held by politicians at plenary sessionsof the European Parliament that have been tran-scribed, ?corrected?
to make up valid written textsand translated into several target languages.
The lan-guage pairs considered in the experiments here areSpanish-English and English-Spanish.The training corpus consists of roughly 1.3M sen-tence pairs with 35.5M running words on the En-glish side.
The vocabulary sizes are considerablylarger than for the IWSLT task, namely around 170Kon the target side.
As development set, we usethe development data issued for the 2006 evaluation(1122 sentences), whereas the two blind test sets arethe official evaluation data from 2006 (TC-Star?06,1117 sentences) and 2007 (TC-Star?07, 1130 sen-tences).4.3 Results4.3.1 IWSLT experimentsOne of the first questions that arises is how manyEM iterations should be carried out during trainingof the triplet model.
Since the IWSLT task is small,37656.656.85757.257.457.60  10  20  30  40  50 34.634.83535.235.435.6BLEUscoreTER scoreEM iterationsIWSLT?04 BLEUIWSLT?04 TERFigure 2: Effect of EM iterations on IWSLT?04, left axisshows BLEU (higher numbers better), right axis (dashedgraph) shows TER score (lower numbers better).IWSLT?04 IWSLT?05BLEU TER BLEU TERbaseline 56.7 35.49 61.1 30.59pall(e|f, f ?)
57.1 35.03 61.3 30.55w/ singletons 57.3 35.04 61.3 30.61w/ empties 57.3 35.00 61.2 30.65+ pall(f |e, e?)
57.5 34.69 61.7 30.24Table 1: Different setups showing the effect of singletonsand empty words for IWSLT CE IWSLT?04 (dev) andIWSLT?05 (test) sets, pall triplets, 20 EM iterations.we can quickly run the experiments on a full uncon-strained triplet model without any cutoff or furtherconstraints.
Figure 2 shows the rescoring perfor-mance for different numbers of EM iterations.
Thefirst 10 iterations significantly improve the tripletmodel performance for the IWSLT task.
After that,there are no big changes.
The performance even de-grades a little bit after 30 iterations.
For the IWSLTtask, we therefore set a fixed number of 20 EM iter-ations for the following experiments since it shows agood performance in terms of both BLEU and TERscore.
The oracle TER scores of the 10k-best listsare 14.18% for IWSLT?04, 11.36% for IWSLT?05and 18.85% for IWSLT?07, respectively.The next chain of experiments on the IWSLT taskinvestigates the impact of changes to the setup oftraining an unconstrained triplet model, such as theaddition of the empty word and the inclusion of sin-gletons (i.e.
triplets that were only seen once in theIWSLT?05 IWSLT?07BLEU TER BLEU TERbaseline 61.1 30.59 38.9 45.60IBM model 1 61.5 30.29 39.4 45.31trip fe+ef pall 61.7 30.24 39.7 45.24trip fe+ef pphr 61.5 30.32 39.1 45.36trip fe+ef palign 61.2 30.60 39.7 45.02Table 2: Comparison of triplet variants on IWSLT CE testsets, 20 EM iterations, with singletons and empty words.training data).
This might show the importance ofrare events in order to derive strategies when mov-ing to larger tasks where it is not feasible to train allpossible triplets, such as e.g.
on the EPPS task (asshown later) or the Chinese-English NIST task.
Theresults for the unconstrained model are shown in Ta-ble 1, beginning with a full triplet model in reversedirection, pall (e|f, f ?
), that contains no singletonsand no empty words for the triggering side.
In thissetting, singletons seem to help on dev but there is noclear improvement on one of the test sets, whereasempty words do not make a significant difference butcan be used since they do not harm either.
The base-line can be improved by +0.6% BLEU and around-0.5% in TER on the IWSLT?04 set.
For the vari-ous setups, there are no big differences in the TERscore which might be an effect of optimization onBLEU.
Therefore, for further experiments using theconstraints from Section 3.2, we use both singletonsand empty words as the default.Adding the other direction p(f |e, e?)
results in an-other increase, with a total of +0.8% BLEU and-0.8% TER, which shows that the combination ofboth directions helps overall translation quality.
Theresults on the two test sets are shown in Table 2.As can be seen, we arrive at similar improvements,namely +0.6% BLEU and -0.3% TER on IWSLT?05and +0.8% BLEU and -0.4% TER on IWSLT?07, re-spectively.
The constrained models, i.e.
the phrase-bounded (pphr ) and path-aligned (palign ) triplets areoutperformed by the full unconstrained case, al-though on IWSLT?07 both unconstrained and path-aligned models are close.For a fair comparison, we added a classical IBMmodel 1 in the rescoring framework.
It can be seenthat the presented triplet models slightly outperform377TC-Star?06 TC-Star?07BLEU TER BLEU TERbaseline 52.3 34.57 50.4 36.46trip fe+ef pall 52.9 34.32 50.6 36.34+ max dist 10 52.9 34.20 50.8 36.22Table 3: Effect of using maximum distance constraint forpall on EPPS Spanish-English test sets, occ3, 4 EM iter-ations due to time constraints.the simple IBM model 1.
Note that IBM model 1is a special case of the triplet lexicon model if thesecond trigger is the empty word.4.3.2 EPPS experimentsSince EPPS is a considerably harder task (largervocabulary and longer sentences), the training of afull unconstrained triplet model cannot be done dueto memory restrictions.
One possibility to reducethe number of extracted triplets is to apply a max-imum distance constraint in the training procedure,i.e.
only trigger pairs are considered where the dis-tance between first and second trigger is below orequal to the specified maximum.Table 3 shows the effect of a maximum distanceconstraint for the Spanish-English direction.
Dueto the large amount of triplets (we extract roughlytwo billion triplets2 for the EPPS data), we drop alltriplets that occur less than 3 times which results in640 million triplets.
Also, due to time restrictions3,we only train 4 iterations and compare it to 4 itera-tions of the same setting with the maximum distanceset to 10.
The training with the maximum distanceconstraints ends with a total of 380 million triplets.As can be seen (Table 3), the performance is compa-rable while cutting down the computation time from9.2 to 3.1 hours.
The experiments were carried outon a 2.2GHz Opteron machine with 16 GB of mem-ory.
The overall gain is +0.4?0.6% BLEU and up to-0.4% in TER.
We even observe a slight increase inBLEU for the TC-Star?07 set which might be a ran-dom effect due to optimization on the developmentset where the behavior is the same as for TC-Star?06.2Extraction can be easily done in parallel by splitting thecorpus and merging identical triplets iteratively in a separatestep for two chunks at a time.3One iteration needs more than 12 hours for the uncon-strained case.TC-Star?06 TC-Star?07BLEU TER BLEU TERbaseline 49.5 37.65 51.0 36.03trip fe+ef pphr 50.2 37.01 51.5 35.38+ occ2 50.2 37.06 51.8 35.32Table 4: Results on EPPS, English-Spanish, pphr com-bined, occ3, 10 EM iterations.TC-Star?06 TC-Star?07BLEU TER BLEU TERbaseline 49.5 37.65 51.0 36.03using FA 50.0 37.18 51.7 35.52using IBM4 50.0 37.12 51.7 35.43+ occ2 50.2 36.84 52.0 35.10+ max dist 1 50.0 37.10 51.7 35.51Table 5: Results on EPPS, English-Spanish, maximumapproximation, palign combined, occ3, 10 EM iterations.Results on EPPS English-Spanish for the phrase-bounded triplet model are presented in Table 4.Since the number of triplets is less than for the un-constrained model, we can lower the cutoff from 3to 2 (denoted in the table by occ3 and occ2 , respec-tively).
There is a small additional gain on the TC-Star?07 test set by this step, with a total of +0.7%BLEU for TC-Star?06 and +0.8% BLEU for TC-Star?07.Table 5 shows results for a variation of the path-aligned triplet model palign that restricts the first trig-ger to the best aligned word as estimated in the IBMmodel 1, thus using a maximum-approximation ofthe given word alignment.
The model was trainedon two word alignments, firstly the one contained inthe forced alignments on the training data, and sec-ondly on an IBM-4 word alignment generated usingGIZA++.
For this second model we also demon-strate the improvement obtained when increasing thetriplet lexicon size by using less trimming.Another experiment was carried out to investigatethe effect of immediate neighboring words used astriggers within the palign setting.
This is equivalentto using a ?maximum distance of 1?
constraint.
Weobtained worse results, namely a 0.2-0.3% drop inBLEU and a 0.3-0.4% raise in TER (cf.
Table 5,last row), although the training is significantly fasterwith this setup, namely roughly 30 minutes per it-378TC-Star?06 TC-Star?07BLEU TER BLEU TERbaseline 49.5 37.65 51.0 36.03IBM model 1 50.0 37.12 51.8 35.51pall , occ3 50.0 37.17 51.8 35.43pphr , occ2 50.2 37.06 51.8 35.32palign , occ2 50.2 36.84 52.0 35.10Table 6: Final results on EPPS English-Spanish, con-strained triplet models, 10 EM iterations, compared tostandard IBM model 1.eration using less than 2 GB of memory.
However,this shows that triggers outside the immediate con-text help overall translation quality.
Additionally, itsupports the claim that the presented methods are acomplementary alternative to the WSD approachesmentioned in Section 2 which only consider the im-mediate context of a single word.Finally, we compare the constrained models to anunconstrained setting and, again, to a standard IBMmodel 1.
Table 6 shows that the palign model con-strained on using the IBM-4 word alignments yields+0.7% in BLEU on TC-Star?06 which is +0.2%more than with a standard IBM model 1.
TER de-creases by -0.3% when compared to model 1.
Forthe TC-Star?07 set, the observations are similar.The oracle TER scores of the development n-bestlist are 25.16% for English-Spanish and 27.0% forSpanish-English, respectively.5 DiscussionFrom the results of our reranking experiments, wecan conclude that the presented triplet lexicon modeloutperforms the baseline single-best hypotheses ofthe decoder.
When comparing to a standard IBMmodel 1, the improvements are significantly smallerthough measurable.
So far, since IBM model 1is considered one of the stronger rescoring mod-els, these results look promising.
An unconstrainedtriplet model has the best performance if training isfeasible since it also needs the most memory andtime to be trained, at least for larger tasks.In order to cut down computational requirements,we can apply phrase-bounded and path-alignedtraining constraints that restrict the possibilities ofselecting triplet candidates (in addition to simplef e e?
?
(f |e, e?
)pagar taxpayer bill 0.76factura taxpayer bill 0.11contribuyente taxpayer bill 0.10f e ?
pibm1 (f |e)contribuyente taxpayer 0.40contribuyentes taxpayer 0.18europeo taxpayer 0.08factura bill 0.19ley bill 0.18proyecto bill 0.11Table 7: Example of triplets and related IBM model 1lexical probabilities.
The triggers ?taxpayer?
and ?bill?have a new effect (?pagar?
), previously not seen in thetop ranks of the lexicon.thresholding).
Although no clear effect could beobserved for adding empty words on the trigger-ing side, it does not harm and, thus, we get a sim-ilar functionality to IBM model 1 being ?integrated?in the triplet lexicon model.
The phrase-boundedtraining variant uses forced alignments computedon the whole training data (i.e.
search constrainedto producing the target sentences of the bilingualcorpus) but could not outperform the path-alignedmodel which reuses the alignment path informationobtained in regular GIZA++ training.Additionally, we observe a positive impact fromtriggers lying outside the immediate context of onepredecessor or successor word.5.1 ExamplesTable 7 shows an excerpt of the top entries for(e, e?)
= (taxpayer , bill) and compares it to the topentries of a lexicon based on IBM model 1.
We ob-serve a triggering effect since the Spanish word pa-gar (to pay) is triggered at top position by the twoEnglish words taxpayer and bill.
The average dis-tance of taxpayer and bill is 5.4 words.
The modelspresented in this work try to capture this propertyand apply it in the scoring of hypotheses in order toallow for better lexical choice in specific contexts.In Table 8, we show an example translation whererescoring with the triplet model achieves higher n-gram coverage on the reference translation than thevariant based on IBM model 1 rescoring.
The differ-ing phrases are highlighted.379Source sen-tence.
.
.
respecto de la Posicio?n Comu?ndel Consejo con vistas a la adopcio?ndel Reglamento del Parlamento Eu-ropeo y del Consejo relativo al .
.
.IBM-1rescoring.
.
.
on the Council common positionwith a view to the adoption of theRules of Procedure of the EuropeanParliament and of the Council .
.
.Tripletrescoring.
.
.
on the common position of theCouncil with a view to the adop-tion of the regulation of the Euro-pean Parliament and of the Council.
.
.Referencetranslation.
.
.
as regards the Common Positionof the Council with a view to theadoption of a European Parliamentand Council Regulation as regardsthe .
.
.Table 8: A translation example on TC-Star?07 Spanish-English comparing the effect of the triplet model to astandard IBM-1 model.6 OutlookWe have presented a new lexicon model based ontriplets extracted on a sentence level and trained it-eratively using the EM algorithm.
The motivation ofthis approach is to add an additional second triggerto a translation lexicon component which can comefrom a more global context (on a sentence level) andallow for a more fine-grained lexical choice given aspecific context.
Thus, the method is related to wordsense disambiguation approaches.We showed improvements by rescoring n-bestlists of the IWSLT Chinese-English and EPPSSpanish-English/English-Spanish task.
In total, weachieve up to +1% BLEU for some of the test sets incomparison to the decoder baseline and up to +0.3%BLEU compared to IBM model 1.Future work will address an integration into thedecoder since the performance of the current rescor-ing framework is limited by the quality of the n-best lists.
For the inverse model, p(e|f, f ?
), an in-tegration into the search is directly possible.
Furtherexperiments will be conducted, especially on largetasks such as the NIST Chinese-English and Arabic-English task.
Training on these huge databases willonly be possible with an appropriate selection ofpromising triplets.AcknowledgmentsThis material is partly based upon work supportedby the Defense Advanced Research Projects Agency(DARPA) under Contract No.
HR0011-06-C-0023,and was partly realized as part of the Quaero Pro-gramme, funded by OSEO, French State agency forinnovation.The authors would like to thank the anonymousreviewers for their valuable comments.ReferencesPeter F. Brown, Stephen A. Della Pietra, Vincent J. DellaPietra, and Robert L. Mercer.
1993.
The mathemat-ics of statistical machine translation: Parameter esti-mation.
Computational Linguistics, 19(2):263?311,June.Marine Carpuat and Dekai Wu.
2007.
Improving sta-tistical machine translation using word sense disam-biguation.
In Joint Conference on Empirical Methodsin Natural Language Processing and ComputationalNatural Language Learning (EMNLP-CoNLL 2007),Prague, Czech Republic, June.Yee Seng Chan, Hwee Tou Ng, and David Chiang.
2007.Word sense disambiguation improves statistical ma-chine translation.
In Proceedings of the 45th AnnualMeeting of the Association of Computational Linguis-tics, pages 33?40, Prague, Czech Republic, June.
As-sociation for Computational Linguistics.Ciprian Chelba and Frederick Jelinek.
2000.
Structuredlanguage modeling.
Computer Speech and Language,14(4):283?332.Stephen A. Della Pietra, Vincent J. Della Pietra, John R.Gillett, John D. Lafferty, Harry Printz, and Lubos?Ures?.
1994.
Inference and estimation of a long-rangetrigram model.
In J. Oncina and R. C. Carrasco, ed-itors, Grammatical Inference and Applications, Sec-ond International Colloquium, ICGI-94, volume 862,pages 78?92, Alicante, Spain.
Springer Verlag.A.
P. Dempster, N. M. Laird, and D. B. Rubin.
1977.Maximum likelihood from incomplete data via the EMalgorithm.
Journal of the Royal Statistical Society, Se-ries B, 39(1):1?22.Woosung Kim and Sanjeev Khudanpur.
2003.
Cross-lingual lexical triggers in statistical language model-ing.
In Proceedings of the 2003 Conference on Empir-ical Methods in Natural Language Processing, pages17?24, Morristown, NJ, USA.
Association for Com-putational Linguistics.Brian Roark.
2001.
Probabilistic top-down parsingand language modeling.
Computational Linguistics,27(2):249?276.380Ronald Rosenfeld.
1996.
A maximum entropy approachto adaptive statistical language modeling.
ComputerSpeech and Language, 10(3):187?228.Christoph Tillmann and Hermann Ney.
1997.
Word trig-gers and the EM algorithm.
In Proc.
Special InterestGroup Workshop on Computational Natural LanguageLearning (ACL), pages 117?124, Madrid, Spain, July.Christoph Tillmann.
2001.
Word Re-Ordering and Dy-namic Programming based Search Algorithm for Sta-tistical Machine Translation.
Ph.D. thesis, RWTHAachen University, Aachen, Germany, May.381
