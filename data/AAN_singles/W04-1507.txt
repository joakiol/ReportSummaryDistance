Categorial Type Logic meets Dependency Grammar to annotatean Italian CorpusR.
BernardiKRDB,Free University of Bolzano Bozen,P.zza Domenicani, 339100 Bolzano Bozen,Italy,bernardi@inf.unibz.itA.
Bolognesi and F. TamburiniCILTA,University of Bologna,P.zza San Giovanni in Monte, 4,I-40124, Bologna,Italy,{bolognesi,tamburini}@cilta.unibo.itM.
MoortgatUiL OTS,Utrecht University,Trans 10,3512 JK, Utrecht,The NetherlandsMoortgat@phil.uu.nlAbstractIn this paper we present work in progress on theannotation of an Italian Corpus (CORIS) devel-oped at CILTA (University of Bologna).
We in-duce categorial type assignments from a depen-dency treebank (Torino University treebank,TUT) and use the obtained categories with an-notated dependency relations to study the dis-tributional behavior of Italian words and reachan empirically founded part-of-speech classifica-tion.1 IntroductionThe work reported on here is part of a project1aimed at annotating the CORIS/CODIS 100-million-words synchronic corpus of contempo-rary Italian with linguistic information: firstpart-of-speech tagging for the complete corpus,and in a later stage syntactic analysis for a sub-corpus.We have been investigating existing Italiantreebanks in order to assess their potential use-fulness for bootstrapping the CORIS/CODIS an-notation tasks.
We are aware of two such tree-banks that are relevant to our purposes: theTUT corpus developed at Torino University, andISST (Italian Syntactic-Semantic treebank) de-veloped under the national program SI-TAL bya consortium of companies and research centerscoordinated by the ?Consorzio Pisa Ricerche?
(CPR)2.ISST is a multi-layered corpus, annotated atthe syntactic and lexico-semantic levels.
A userinterface is provided to explore the corpus.
TheISST corpus is rather competitive in terms ofsize: it counts 305,547 word tokens (Monte-magni et al, 2003).
A drawback is that thecorpus is not publicly available yet.
The TUT1The project is funded under the FIRB 2001 action.2The parnters of the consortium were: ILC-CNR/CPR, Venice University/CVR, ITC-IRST, ?TorVergata?
University/CERTIA, and Synthema.corpus is rather small, consisting only of 38,653words.
There is no user interface for TUT butthe corpus is downloadable (http://www.di.unito.it/~tutreeb/).
Despite its small size,TUT can serve as a training corpus for creatinglarger annotated resources.Our goal is to annotate CORIS with part-of-speech (PoS) tags and semi-automatically builda treebank for a fragment of it.
To achieve thistwo-fold task we start from TUT exploiting itsinformation on dependency relations.
We arestill in a preliminary phase of the project andso far attention has been focused on the firsttask.
However, the work done in this phase isexpected to play a role in our second task too.In Section 2, we will describe in more detailthe problems which arise when working out thefirst task.
In Section 3, we briefly introduce theformalisms we work with.
In Section 4, we ex-plain how we encode dependency relations intocategorial type assignments (CTAs), and how weautomatically induce these types from TUT de-pendency structures.
Finally, in Section 5 wedraw some preliminary conclusions and brieflydescribe our action list.2 PoS tagging for ItalianBefore embarking on our first task, we havestudied the current situation with respect toPoS tagging for Italian.
Italian is one of thelanguages for which a set of annotation guide-lines has been developed in the context of theEAGLES project (Expert Advisory Group onLanguage Engineering Standards (Monachini,1995)).
Several research groups have worked onPoS annotation in practice (for example, TorinoUniversity, Xerox and Venice University).We have compared the tag sets used by thesegroups with Monachini?s guidelines.
From thiscomparison, it results that though there is ageneral agreement on the main parts of speechto be used3, considerable divergence exists whenit comes to the actual classification of Italianwords with respect to these main PoS classes.The classes for which differences of opinion aremost evident are adjectives, determiners andadverbs.
For instance, words like molti (tr.many) have been classified as ?indefinite deter-miners?
by Monachini, ?plural quantifiers?
byXerox, ?indefinite adjectives?
by the Venice andTurin groups.
This simple example shows thatthe choice of PoS tags is already influenced bythe linguistic theory adopted in the background.This theoretical bias will then influence the kindof conclusions one can draw from the annotatedcorpus.Our aim is to derive an empirically foundedPoS classification, making no a priori assump-tions about the PoS classes to be distinguished.Our background assumptions are minimal and,we hope, uncontroversial: we assume thatwe have access to head-dependent (H-D) andfunctor-argument (F-A) relations in our mate-rial.
We encode the H-D and F-A informationinto categorial type formulas.
These formulasthen serve as ?labels/tags?
from which we ob-tain the desired empirically founded PoS classi-fication by means of a clustering algorithm.To bootstrap the process of type induction,we transform the TUT corpus into a simpli-fied dependency treebank.
The transformationkeeps the bare dependency relations but re-moves the more theory-laden annotation.
InSection 4, we describe how we use the simpli-fied dependency treebank for our distributionalstudy of Italian PoS classification.
First, webriefly look at H-D and F-A relations as theyoccur in the TUT corpus and in Categorial TypeLogic (CTL).3 Dependency andfunctor-argument relations3.1 Dependency structures in TUTThe Turin University Treebank (TUT) is a cor-pus of Italian sentences annotated by specifyingrelational structures augmented with morpho-syntactic information and semantic role (hence-forth ARS) in a monostratal dependency-basedrepresentation.
The treebank in its current re-lease includes 38,653 words and 1,500 sentences3The standard classification consists of nouns, verbs,adjectives, determiners, articles, adverbs, prepositions,conjunctions, numerals, interjections, punctuation anda class of residual items which differs from project toproject.from the Italian civil law code, the nationalnewspapers La Stampa and La Repubblica, andfrom various reviews, newspapers, novels, andacademic papers.The ARS schema consists of i) morpho-syntactic, ii) functional-syntactic and iii) se-mantic components, specifying part-of-speech,grammatical relations, and thematic role infor-mation, respectively.
The reader is referredto (Bosco, 2003) for a detailed description of theTUT annotation schema.
An example is givenbelow (tr.
?The first steps have not been encour-aging?).
In this example, the node TOP-VERB isthe root of the whole structure4.
************** FRASE ALB-71 **************1 I (IL ART DEF M PL)[6;VERB-SUBJ]2 primi (PRIMO ADJ ORDIN M PL)[3;ADJC+ORDIN-RMOD]3 approcci (APPROCCIO NOUN COMMON M PL)[1;DET+DEF-ARG]4 non (NON ADV NEG)[6;ADVB-RMOD]5 sono (ESSERE VERB AUX IND PRES INTR 3 PL)[6;AUX+TENSE]6 stati (ESSERE VERB MAIN PART PAST INTR PL M)[0;TOP-VERB]7 esaltanti (ESALTANTE ADJ QUALIF ALLVAL PL)[6;VERB-PREDCOMPL+SUBJ]8 .
(#\.
PUNCT) [6;END]Because we are interested in extractingdependency relations, we can focus on thefunctional-syntactic component of the TUT an-notation, where information relating to gram-matical relations (heads and dependents) is en-coded.The TUT annotation schema for depen-dents makes a primary distinction between(a) functional and (b) non-functional tags,for dependents that can and that can-not be assigned thematic roles, respectively.These two classes are further divided into(a?)
arguments (ARG) and modifiers (MOD)and (b?
), AUX, COORDINATOR, INTERJECTION,CONTIN, EMPTYCOMPL, EMPTYLOC, SEPARATORand VISITOR5; and furthermore, the arguments4The top nodes used in TUT are TOP-VERB,TOP-NOUN, TOP-CONJ, TOP-ART, TOP-NUM, TOP-PRON,TOP-PHRAS and TOP-PREP5The labels that require some explanation are: (i)CONTIN, (ii) EMPTYCOMPL, (iii) EMPTYLOC and (iv) VISITOR.They are used for expressions that (i) introduce a partof an expression with a non-compositional interpreta-tion (e.g.
locative or idiomatic expressions and denom-inative structures: ?Arrivo` [prima]H [de]D ll?alba?, lit.tr.
?
(She) arrived ahead of the daybreak?
); (ii) link a re-(ARG) and modifiers (MOD) are sub-divided as fol-lowingARGSUBJ OBJ INDOBJ INDCOMPL PREDCOMPLMODIFIERRMODRELCLR RMODPREDAPPOSITIONRELCLA3.2 Categorial functor-argumentstructuresCategorial Type Logic (CTL) (Moortgat, 1997)is a logic-based formalism belonging to the fam-ily of Categorial Grammars (CG).
In CTL, thetype-forming operations of CG are viewed aslogical connectives.
As the slogan ?Parsing-as-Deduction?
suggests, such a view makes itpossible to do away with combinatory syn-tactic rules altogether; establishing the well-formedness of an expression becomes a processof deduction in the logic of the type-formingconnectives.The basic distinction expressed by the cat-egorial type formulas is the Fregean opposi-tion between complete and incomplete expres-sions.
Complete expressions are categorized bymeans of atomic type formulas; grammatical-ity judgements for expressions with an atomictype do not require further contextual informa-tion.
Typical examples of atomic types wouldbe ?sentence?
(s) and ?noun?
(n).
Incomplete ex-pressions are categorized by means of fractionaltype formulas; the denominators of these frac-tions indicate the material that has to be foundin the context in order to obtain a complete ex-pression of the type of the numerator.Definition 3.1 (Fractional type formulas)Given a set of basic types ATOM, the set oftypes TYPE is the smallest set such that:i. if A ?
ATOM, then A ?
TYPE;ii.
if A and B ?
TYPE, then A/B andB\A ?
TYPE.There are different ways of presenting validtype computations.
In a Natural Deduction for-mat, we write ?
` A for a demonstration thatflexive personal pronoun with particular verbal head (e.g.
?La porta [si]D [apre]H?, lit.
tr.
?the door (it) opens?
);(iii) link a pronoun with a verbal head introducing a sortof metaphorical location of the head (e.g.
?In Albania[ci]D [sono]H molti problemi?, lit.
tr.
?In Albany thereare many problems?.
); (iv) mark the extraction of a partof a structure (e.g.
?Cos`?
devi vedere questo argomento?,lit.
tr.
?This way (you) must see this topic?
).the structure ?
has the type A.
The statementA ` A is axiomatic.
Each of the connectives /and \ has an Elimination rule and an Introduc-tion rule.
Below, we give these inference rulesfor / (incompleteness to the right).
The casesfor \ (incompleteness to the left) are symmetric.Given structures ?
and ?
of types A/B and Brespectively, the Elimination rule builds a com-pound structure ???
of type A.
The Introduc-tion rule allows one to take apart a compoundstructure ?
?B into its immediate substructures.?
` A/B ?
` B?
??
` A /E?
?B ` A?
` A/B /INotice that the language of fractional typesis essentially higher-order: the denominator ofa fraction does not have to be atomic, but canitself be a fraction.
The Introduction rules areindispensable if one is interested in capturingthe full set of theorems of the type calculus.Classical CG (in the style of Ajdukiewicz andBar-Hillel) uses only the Elimination rules, andhence has restricted inferential capacities.
It isimpossible in classical CG to obtain the validityA ` B/(A\B), for example.
Still, the classi-cal CG perspective will be useful to realize ouraim of automatically inducing type assignmentsfrom structured data obtained from the TUTcorpus thanks to the type resolution algorithmexplained below.Type inference algorithms for classical CGhave been studied by (Buszkowski and Penn,1990).
The structured data needed by theirtype inference algorithms are so-called functor-argument structures (fa-structures).
An fa-structure for an expression is a binary branchingtree; the leaf nodes are labeled by lexical expres-sions (words), the internal nodes by one of thesymbols J (for structures with the functor asthe left daughter) or I (for structures with thefunctor as the right daughter).To assign types to the leaf nodes of an fa-structure, one proceeds in a top-down fashion.The type of the root of the structure is fixed (forexample: s).
Compound structures are typed asfollows:- to type a structure ?
J ?
as A, type ?
asA/B and ?
as B;- to type a structure ?
I ?
as A, type ?
asB and ?
as B\A.If a word occurs in different structural environ-ments, the typing algorithm will produce dis-tinct types.
The set of type assignments to aword can be reduced by factoring : one identi-fies type assignments that can be unified.
Foran example, compare the structured input be-low:a. Claudia I parlab.
Claudia I (parla I bene)Assuming a goal type s, from (a) we obtain theassignmentsClaudia : A,parla : A\sand from (b)Claudia : C,parla : B,bene : B\(C\s)Factoring leads to the identifications A = C,B = (A\s), producing for ?bene?
the modifiertype (A\s)\(A\s).3.3 From TUT dependency structuresto categorial typesTo accomplish our aims, we will have an oc-casion to use two extensions of the basic cate-gorial machinery outlined in the section above:a generalization of the type language to multi-ple modes of composition, and the addition ofstructural rules of inference to the logical rulesof slash Elimination and Introduction.Multimodal composition The intuitionsunderlying the distinction between heads anddependents in Dependency Grammars (DG) andbetween functors and arguments in CG oftencoincide, but there are also cases where theydiverge (Venneman, 1977).
In the particu-lar case of the TUT annotation schema, wesee that for all instances of dependents la-beled as ARG (or one of its sublabels), theDG head/dependent articulation coincides withthe CG functor/argument asymmetry.
But forDG modifiers, or dependents without thematicroles of the class AUX (auxiliary)6 there is amismatch between dependency structure andfunctor-argument structure.
Modifiers would befunctors in terms of their categorial type: func-tors where the numerator and the denominatorare identical.
This makes them into ?identities?for the fractional multiplication, which explainstheir optionality and the possibility of iteration.AUX elements in DG would count as morpholog-ical modifiers of the head verbs.
From the CGpoint of view, they would be typed as functors6And also COORDINATOR, INTERJECTION.with non-identical numerator and denomina-tor, distinguishing them that way from optionalmodifiers, and capturing the fact that they areindispensable to build a complete grammaticalstructure.To reconcile the competing demands of thehead-dependent and functor-argument classifi-cation, we make use of the type calculus pro-posed in (Moortgat and Morrill, 1991), whichtreats dependency and functor-argument rela-tions as two orthogonal dimensions of linguisticorganization.
Instead of one composition oper-ation ?, the system of (Moortgat and Morrill,1991) has two: ?l for structures where the leftdaughter is the head, and ?r for right-headedstructures.
The two composition operationseach have their slash and backslash operationsfor the typing of incomplete expressions:- A/lB: a functor looking for a B to the rightto form an A; the functor is the head, theargument the dependent;- A/rB: a functor looking for a B to the rightto form an A; the argument is the head, thefunctor the dependent;- B\lA: a functor looking for a B to the leftto form an A; the argument is the head,the functor the dependent;- B\rA: a functor looking for a B to the leftto form an A; the functor is the head, theargument the dependent.The type inference algorithm of (Buszkowskiand Penn, 1990) can be straightforwardlyadapted to the multimodal situation.
The inter-nal nodes of the fa-structures now are labeledwith a fourfold distinction: as before, the tri-angle points to the functor daughter of a con-stituent; in the case of the black triangle, thefunctor daughter is the head constituent, in thecase of the white triangle, the functor daughteris the dependent.ad ah fd fhfh Jfd Cah Bad IThe type-inference clauses can be adapted ac-cordingly.- to type a structure ?
J ?
as A, type ?
asA/lB and ?
as B;- to type a structure ?
C ?
as A, type ?
asA/rB and ?
as B.- to type a structure ?
I ?
as A, type ?
asB\rA and ?
as B;- to type a structure ?
B ?
as A, type ?
asB\lA and ?
as B.Structural reasoning The dependency rela-tions in the TUT corpus abstract from surfaceword order.
When we induce categorial typeformulas from these dependency relations, as wewill see in Section 4.1, the linear order imposedby ?/?
and ?\?
in the obtained formulas will notalways be compatible with the observable sur-face order.
Incompatibilities will arise, specif-ically, in the case of non-projective dependen-cies.
Where such mismatches occur, the inducedtypes will not be immediately useful for parsing?
the longer term subtask of the project dis-cussed here.To address this issue, we can extend the in-ference rules of our categorial logic with struc-tural rules.
The general pattern of these rulesis: infer ??
` A from ?
` A, where ??
is somerearrangement of the constituents of ?.
Theserules, in other words, characterize the structuraldeformations under which type assignment ispreserved.
Structural rules can be employedin two ways in CTL (see (Moortgat, 2001) fordiscussion).
In an on-line use, they actuallymanipulate structural configurations during theparsing process.
Such on-line use can be veryexpensive computationally.
Used off-line, theyplay a role complementary to the factoring op-eration, producing a number of derived lexicaltype-assignments from some canonical assign-ment.
With the derived assignments, parsingcan then proceed without altering the surfacestructure.As indicated in the introduction, the use ofCTL in the construction of a treebank for a partof the CILTA corpus belongs to a future phaseof our project.
For the purposes of this paperwe must leave the exact nature of the requiredstructural rules, and the trade-off between off-line and on-line uses, as a subject for furtherresearch.4 A distributional study of Italianpart-of-speech taggingIn order to annotate the CORIS corpus with atheory-neutral set of PoS tags, we plan to carryout a distributional study of its lexicon.Early approaches to this problem were basedon the hypothesis that if two words are syn-tactically and semantically different, they willappear in different contexts.
There are a num-ber of studies that, starting from this hypoth-esis, have built automatic or semi-automaticprocedures for clustering words (Brill and Mar-cus, 1992; Pereira et al, 1993; Martin et al,1998), especially in the field of cognitive sci-ences (Redington et al, 1998; Gobet and Pine,1997; Clark, 2000).
They examine the distribu-tional behaviour of some target words, compar-ing the lexical distribution of their respectivecollocates using quantitative measures of distri-butional similarity (Lee, 1999).In (Brill and Marcus, 1992) it is given a semi-automatic procedure that, starting from lexicalstatistical data collected from a large corpus,aims to arrange target words in a tree (moreprecisely a dendrogram), instead of clusteringthem automatically.
This procedure requires alinguistic examination of the resulting tree, inorder to identify the word classes that are mostappropriate to describe the phenomenon underinvestigation.
In this sense, they use a semi-automatic word-class generator method.A similar procedure has been applied on Ital-ian in (Tamburini et al, 2002).
The novelty ofthis work is that it derives the distributional in-formation on words from a very basic set of PoStags, namely nouns, verbs and adjectives.
Thismethod, completely avoiding the sparseness ofthe data affecting Brill and Marcus?
method,uses general information about the distributionof lexical words to study the internal subdivi-sions of the set of grammatical words, and re-sults more stable than the method based onlyon lexical co-occurrence.The main drawback of these techniques is thelimited context of analysis.
Collecting informa-tion from a defined context, typically two orthree words will invariably miss syntactic de-pendencies longer than the context interval.
Toovercome this problem we propose to exploit theexpressivity of CTAs (with encoded core depen-dency relations, as we saw in the section above)by applying the clustering algorithms on them.Below we sketch how we intend to induce CTAsfrom the TUT dependency treebank, and theclustering method we plan to implement.
Thewhole procedure can be summarized by the pic-ture below.Treebank conversion????????
CTL structures?
type resolutionPoS tagset clustering???????
Categorial Types4.1 Inducing categorial types from TUTThe first step is to reduce the distinctionsencoded in the TUT treebank to bare head-dependent relations: the ARG type on the onehand, and the MOD and AUX types on the other.These relations are converted into fa-structuresbuilt by means of the dependency-sensitive op-erators J, I, C , B .By means of example, we consider some sim-ple sentences exemplifying the different rela-tions.Figure 1 shows a head-dependent structurein which edges represent head-dependent rela-tions and each edge points to the dependent ofeach relation.
In this example, each H-D rela-tion agrees with the F-A relation, i.e.
each headcorresponds to a functor and the dependents areall labeled as arguments (or sub-tags of it).7Alan0AlanSUBJmangia1eatsTOP_VERBla2theOBJmela3appleARGSUBJ OBJ ARGFigure 1: ARG: Functor and Head coincideFigure 2 adds to the example from figure 1the use of qualifying adjectives, which is an ex-ample of a modifier, and past tense auxiliaries.Considering the relation between ?mela?
(apple)and ?rossa?
(red), and between ?ha?
(has) and?mangiato?
(eaten), we have the dependencytrees in Figure 2.In the first case, the noun is the head andthe adjective is the dependent, but from thefunctor-argument perspective, the adjective (ingeneral, the modifier) is the incomplete functorcomponent.
A similar discrepancy is observedfor the auxiliary and the main verb, where theauxiliary should be classified as the incompletefunctor, but as the dependent element with re-spect to the main verb.
In this case the absence7The example follows TUT practice in designating thedeterminer as the head of the noun phrases.
We areaware of the fact that this is far from controversial inthe dependency community.
In preprocessing TUT be-fore type inference, we have the occasion to adjust suchdebatable decisions, and representational issues such asthe use of empty categories, for which there is no needin a CTL framework.Alan0AlanSUBJha1AUXmangiato2ateTOP_VERBla3theOBJmela4appleARGSUBJ AUX OBJ ARGFigure 2: MOD and AUX: Functors as Dependentsof the auxiliary would result in an ungrammat-ical sentence.
The relations of MOD and AUX ex-hibit a different behavior than ARG, and henceare depicted with different arcs.Our simple example sentences could be con-verted into the following fa-structures:- Allen I (mangia J (la J mela)- Allen I (mangia J (la J (mela B rossa))- Allen I ((ha C mangiato) J (la J mela))The second step is to run the Buszkowski-Penn type-inference algorithm (in its extendedform, discussed above) on the fa-structures ob-tained from TUT, and to reduce the lexiconby factoring (identification of unifiable assign-ments) and (in a later phase) structural deriv-ability.
Fixing the goal type for these examplesas s, we obtain the following type assignmentsfrom the fa-structures given above:Allan Amangia (A\rs)/lBla B/lCmela Crossa C\lCha ((A\rs)/lB)/rDmangiato DNotice that from the output in our tiny sam-ple, we have no information allowing us to iden-tify the argument assignments A and B. No-tice also that from an fa-structure which takestogether ?ha mangiato?
in a constituent, weobtain a type assignment for ?mangiato?
thatdoes not express its incompleteness anymore?
instead, the combination with the auxil-iary expresses this.
This is already an exam-ple where structural reasoning can play a role:compare the above analysis with the type so-lution one would obtain by starting from anfa-structure which takes ?mangiato la mela?as a constituent, which yields a type solution(A\rs)/rE for the auxiliary, and E/lB for thehead verb.
We are currently experimenting withthe effect of different constituent groupings onthe size of the induced type lexicon.4.2 Clustering AlgorithmsOnce we have induced the categorial type as-signments for the TUT lexicon, the last step ofour first task is to divide it into clusters so tostudy the distributional behavior of the corre-sponding lexical entries.
The advantage of us-ing categorial types as objects of the clusteringalgorithm is that they represent long distancedependencies as well as limited distributionalinformation.
Thus the categorial types becomethe basic elements of syntactic information as-sociated with lexical entries and the basic ?dis-tributional fingerprints?
used in the clusteringprocess.Every clustering process is based on a no-tion of ?distance?
between the objects involvedin the process.
We should define an appropri-ate metric among categorial types.
We believethat a crucial role will be played by the depen-dency relation encoded into the types by meansof compositional modes.Currently, we are studying the application ofproper distance measures considering types astrees and adapting the theoretical results ontree metrics to our problem.
The algorithm forcomputing the tree-edit distance (Shasha andZhang, 1997), designed for generic trees, ap-pears to be a good candidate for clustering incategorial-type domain.
What remains to bedone is to experiment the algorithm and fine-tune the metrics to our purpose.5 Conclusions and Further ResearchIn this paper we have presented work in progressdevoted to the syntactic annotation of a largeItalian corpus.
We have just started working inthis direction and the biggest part of the workhas still to be done.
We are currently evaluatingthe TUT encoding of dependency information,and identifying areas that allow optimizationfrom the point of view of CTL type induction.A case in point is the heavy reliance of TUTon empty elements and/or traces, which con-flicts with our desire for an empirically-basedand theory-neutral representation of linguisticdependencies.
It seems that the trace artifactcan be avoided if one properly exploits the moreexpressive category concept of CTL, allowingproduct types for asyndetic constructions, andhigher-order types for multiple dependencies.
Inparallel, we are looking for other sources of de-pendency information for Italian, in order tocomplement the rather small TUT database wehave at our disposal now.6 AcknowledgmentsOur thanks go to FIRB 2001 projectRBNE01H8RS coordinated by prof. R. RossiniFavretti for the funding supports.
Thanks toL.
Surace and C. Seidenari for the detailedcomparison on Italian PoS classifications.ReferencesC.
Bosco.
2003.
A grammatical relation systemfor treebank annotation.
Ph.D. thesis, Com-puter Science Department, Turin University.E.
Brill and M. Marcus.
1992.
Tagging an un-familiar text with minimal human supervi-sion.
In Proceedings of the Fall Symposiumon Probabilistic Approaches to Natural Lan-guage, pages 10?16, Cambridge.
MA: Ameri-can Association for Artificial Intelligence.W.
Buszkowski and G. Penn.
1990.
Categorialgrammars determined from linguistic data byunification.
Studia Logica, 29:431?454.A.
Clark.
2000.
Inducing syntactic categoriesby context distribution clustering.
In Pro-ceedings of CoNLL-2000 and LLL-2000 Con-ference, pages 94?91, Lisbon, Portugal.F.
Gobet and J. Pine.
1997.
Modelling the ac-quisition of syntactic categories.
In Proceed-ings of the 19th Annual Meeting of the Cog-nitive Science Society, pages 265?270.L.
Lee.
1999.
Measures of distributional simi-larity.
In Proceedings of the 37th ACL, pages25?32, College Park, MD.S.
Martin, J. Liermann, and H. Ney.
1998.
Al-gorithms for bigram and trigram word clus-tering.
Speech Communication, 24:19?37.M.
Monachini.
1995.
ELM-IT: An Italian in-carnation of the EAGLES-TS.
definition oflexicon specification and classification guide-lines.
Technical report, Pisa.S.
Montemagni, F. Barsotti, M. Battista,N.
Calzolari, O. Corazzari, A. Lenci, A. Zam-polli, F. Fanciulli, M. Massetani, R. Raf-faelli, R. Basili, M. T. Pazienza, D. Saracino,F.
Zanzotto, N. Mana, F. Pianesi, and R. Del-monte, 2003.
Building and using parsed cor-pora, chapter Building the Italian Syntactic-Semantic Treebank, pages 189?210.
Lan-guage and Speech series.
Kluwer, Dordrecht.M.
Moortgat and G. Morrill.
1991.
Headsand phrases.
Type calculus for dependencyand constituent structure.
Technical report,Utrecht.M.
Moortgat.
1997.
Categorial type logics.In J. van Benthem and A. ter Meulen, edi-tors, Handbook of Logic and Language, pages93?178.
The MIT Press, Cambridge, Mas-sachusetts.Michael Moortgat.
2001.
Structural equa-tions in language learning.
In P. de Groote,G.
Morrill, and C.
Retore?, editors, Logical As-pects of Computational Linguistics, volume2099 of Lecture Notes in Artificial Intelli-gence, pages 1?16, Berlin.
Springer.F.
Pereira, T. Tishby, and L. Lee.
1993.
Dis-tributional clustering of English words.
InProceedings of the 31st ACL, pages 183?190,Columbus, Ohio.M.
Redington, N. Chater, and S. Finch.
1998.Distributional information: a powerful cue foracquiring syntactic categories.
Cognitive Sci-ence, 22(4):425?469.D.
Shasha and D. Zhang.
1997.
Approximatetree pattern matching.
In A. Apostolico andZ.
Galig, editors, Pattern matching algo-rithms.
Oxford University Press.F.
Tamburini, C. De Santis, and Zamuner E.2002.
Identifying phrasal connectives in Ital-ian using quantitative methods.
In S. Nuc-corini, editor, Phrases and Phraseology -Dataand Description.
Berlin: Peter Land.T.
Venneman.
1977.
Konstituenz und Depen-denz in einigen neueren Grammatiktheorien.Sprachwissenschaft, 2:259?301.
