Proceedings of the 4th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 2?11,Atlanta, Georgia, 14 June 2013. c?2013 Association for Computational LinguisticsBootstrapped Learning of Emotion Hashtags #hashtags4youAshequl QadirSchool of ComputingUniversity of UtahSalt Lake City, UT 84112, USAasheq@cs.utah.eduEllen RiloffSchool of ComputingUniversity of UtahSalt Lake City, UT 84112, USAriloff@cs.utah.eduAbstractWe present a bootstrapping algorithm to au-tomatically learn hashtags that convey emo-tion.
Using the bootstrapping framework, welearn lists of emotion hashtags from unlabeledtweets.
Our approach starts with a small num-ber of seed hashtags for each emotion, whichwe use to automatically label tweets as initialtraining data.
We then train emotion classi-fiers and use them to identify and score candi-date emotion hashtags.
We select the hashtagswith the highest scores, use them to automat-ically harvest new tweets from Twitter, andrepeat the bootstrapping process.
We showthat the learned hashtag lists help to improveemotion classification performance comparedto an N-gram classifier, obtaining 8% micro-average and 9% macro-average improvementsin F-measure.1 IntroductionThe increasing popularity of social media has givenbirth to new genres of text that have been thefocus of NLP research for applications such asevent discovery (Benson et al 2011), election out-come prediction (Tumasjan et al 2011; Berming-ham and Smeaton, 2011), user profile classification(De Choudhury et al 2012), conversation model-ing (Ritter et al 2010), consumer insight discovery(Chamlertwat et al 2012), etc.
A hallmark of so-cial media is that people tend to share their personalfeelings, often in publicly visible forums.
As a re-sult, social media has also been the focus of NLPresearch on sentiment analysis (Kouloumpis et al2011), emotion classification and lexicon generation(Mohammad, 2012), and sarcasm detection (Davi-dov et al 2010).
Identifying emotion in social me-dia text could be beneficial for many application ar-eas, for example to help companies understand howpeople feel about their products, to assist govern-ments in recognizing growing anger or fear associ-ated with an event, and to help media outlets under-stand the public?s emotional response toward con-troversial issues or international affairs.Twitter, a micro-blogging platform, is particularlywell-known for its use by people who like to in-stantly express thoughts within a limited length of140 characters.
These status updates, known astweets, are often emotional.
Hashtags are a distinc-tive characteristic of tweets, which are a community-created convention for providing meta-informationabout a tweet.
Hashtags are created by adding the ?#?symbol as a prefix to a word or a multi-word phrasethat consists of concatenated words without whites-pace (e.g., #welovehashtags).
People use hashtagsin many ways, for example to represent the topic ofa tweet (e.g., #graduation), to convey additional in-formation (e.g., #mybirthdaytoday), or to express anemotion (e.g., #pissedoff).The usage of hashtags in tweets is common, asreflected in the study of a sample of 0.6 milliontweets by Wang et al(2011) which found that14.6% of tweets in their sample had at least onehashtag.
In tweets that express emotion, it is com-mon to find hashtags representing the emotion feltby the tweeter, such as ?the new iphone is a wasteof money!
nothing new!
#angry?
denoting anger or?buying a new sweater for my mom for her birthday!#loveyoumom?
denoting affection.2Identifying the emotion conveyed by a hashtaghas not yet been studied by the natural language pro-cessing community.
The goal of our research is toautomatically identify hashtags that express one offive emotions: affection, anger/rage, fear/anxiety,joy, or sadness/disappointment.
The learned hash-tags are then used to recognize tweets that expressone of these emotions.
We use a bootstrapping ap-proach that begins with 5 seed hashtags for eachemotion class and iteratively learns more hashtagsfrom unlabeled tweets.
We show that the learnedhashtags can accurately identify tweets that conveyemotion and yield additional coverage beyond therecall of an N-gram classifier.The rest of the paper is divided into the followingsections.
In Section 2, we present a brief overviewof previous research related to emotion classificationin social media and the use of hashtags.
In Sec-tion 3, we describe our bootstrapping approach forlearning lists of emotion hashtags.
In Section 4 wediscuss the data collection process and our experi-mental design.
In Section 5, we present the resultsof our experiments.
Finally, we conclude by sum-marizing our findings and presenting directions forfuture work.2 Related WorkRecognizing emotions in social media texts hasgrown popular among researchers in recent years.Roberts et al(2012) investigated feature sets to clas-sify emotions in Twitter and presented an analysisof different linguistic styles people use to expressemotions.
The research of Kim et al(2012a) is fo-cused on discovering emotion influencing patternsto classify emotions in social network conversations.Esmin et al(2012) presented a 3-level hierarchi-cal emotion classification approach by differentiat-ing between emotion vs. non-emotion text, positivevs.
negative emotion, and then classified differentemotions.
Yang et al(2007b) investigated sentencecontexts to classify emotions in blogs at the doc-ument level.
Some researchers have also workedon analyzing the correlation of emotions with topicsand trends.
Kim et al(2012b) analyzed correlationsbetween topics and emotions in Twitter using topicmodeling.
Gilbert and Karahalios (2010) analyzedcorrelation of anxiety, worry and fear with down-ward trends in the stock market.
Bollen et al(2011)modeled public mood and emotion by creating six-dimensional mood vectors to correlate with popularevents that happened in the timeframe of the dataset.On the other hand, researchers have recentlystarted to pay attention to the hashtags of tweets, butmostly to use them to collect labeled data.
Davi-dov et al(2010) used #sarcasm to collect sarcastictweets from twitter.
Choudhury et al(2012) usedhashtags of 172 mood words to collect training datato find associations between mood and human af-fective states, and trained classifiers with unigramand bigram features to classify these states.
Purverand Battersby (2012) used emotion class name hash-tags and emoticons as distant supervision in emotionclassification.
Mohammad (2012) also used emotionclass names as hashtags to collect labeled data fromTwitter, and used these tweets to generate emotionlexicons.
Wang et al(2012) used a selection of emo-tion hashtags as the means to acquire labeled datafrom twitter, and found that a combination of uni-grams, bigrams, sentiment/emotion-bearing words,and parts-of-speech information to be the most ef-fective in classifying emotions.
A study by Wanget al(2012) also shows that hashtags can be usedto create a high quality emotion dataset.
They foundabout 93.16% of the tweets having emotion hashtagswere relevant to the corresponding emotion.However, none of this work investigated the useof emotion hashtag lists to help classify emotions intweets.
In cases where hashtags were used to collecttraining data, the hashtags were manually selectedfor each emotion class.
In many cases, only thename of the emotion classes were used for this pur-pose.
The work most closely related to our researchfocus is the work of Wang et al(2011) where theyinvestigated several graph based algorithms to col-lectively classify hashtag sentiments.
However, theirwork is focused on classifying hashtags of positiveand negative sentiment polarities, and they made useof sentiment polarity of the individual tweets to clas-sify hashtag sentiments.
On the contrary, we learnemotion hashtags and use the learned hashtag liststo classify emotion tweets.
To the best of our knowl-edge, we are the first to present a bootstrapped learn-ing framework to automatically learn emotion hash-tags from unlabeled data.33 Learning Emotion Hashtags viaBootstrapping3.1 MotivationThe hashtags that people use in tweets are often verycreative.
While it is common to use just single wordhashtags (e.g., #angry), many hashtags are multi-word phrases (e.g., #LoveHimSoMuch).
People alsouse elongated1 forms of words (e.g., #yaaaaay,#goawaaay) to put emphasis on their emotionalstate.
In addition, words are often spelled creativelyby replacing a word with a number or replacingsome characters with phonetically similar characters(e.g., #only4you, #YoureDaBest).
While many ofthese hashtags convey emotions, these stylistic vari-ations in the use of hashtags make it very difficultto create a repository of emotion hashtags manu-ally.
While emotion word lexicons exist (Yang et al2007a; Mohammad, 2012), and adding a ?#?
symbolas a prefix to these lexicon entries could potentiallygive us lists of emotion hashtags, it would be un-likely to find multi-word phrases or stylistic varia-tions frequently used in tweets.
This drives our mo-tivation to automatically learn hashtags that are com-monly used to express emotion in tweets.3.2 Emotion ClassesFor this research, we selected 5 prominent emo-tion classes that are frequent in tweets: Af-fection, Anger/Rage, Fear/Anxiety, Joy and Sad-ness/Disappointment.
We started by analyzing Par-rott?s (Parrott, 2001) emotion taxonomy and howthese emotions are expressed in tweets.
We alsowanted to ensure that the selected emotion classeswould have minimal overlap with each other.
Wetook Parrott?s primary emotion Joy and Fear2 di-rectly.
We merged Parrott?s secondary emotion Af-fection and Lust into our Affection class and mergedParrott?s secondary emotion Sadness and Disap-pointment into our Sadness/Disappointment class,since these emotions are often difficult to distinguishfrom each other.
Lastly, we mapped Parrott?s sec-ondary emotion Rage to our Anger/Rage class di-rectly.
There were other emotions in Parrott?s tax-onomy such as Surprise, Neglect, etc.
that we did1This feature has also been found to have a strong associa-tion with sentiment polarities (Brody and Diakopoulos, 2011)2we renamed the Fear class as Fear/Anxietynot use for this research.
In addition to the five emo-tion classes, we used a None of the Above class fortweets that do not carry any emotion or that carry anemotion other than one of our five emotion classes.3.3 Overview of Bootstrapping FrameworkFigure 1: Bootstrapping ArchitectureFigure 1 presents the framework of our bootstrap-ping algorithm for learning emotion hashtags.
Thealgorithm runs in two steps.
In the first step, thebootstrapping process begins with five manually de-fined ?seed?
hashtags for each emotion class.
Foreach seed hashtag, we search Twitter for tweets thatcontain the hashtag and label these tweets with theemotion class associated with the hashtag.
We usethese labeled tweets to train a supervised N-gramclassifier for every emotion e ?
E, where E is theset of emotion classes we are classifying.In the next step, the emotion classifiers are appliedto a large pool of unlabeled tweets and we collectthe tweets that are labeled by the classifiers.
Fromthese labeled tweets, we extract the hashtags foundin these tweets to create a candidate pool of emo-tion hashtags.
The hashtags in the candidate poolare then scored and ranked and we select the mosthighly ranked hashtags to add to a hashtag reposi-tory for each emotion class.Finally, we then search for tweets that containthe learned hashtags in a pool of unlabeled tweetsand label each of these with the appropriate emotionclass.
These newly labeled tweets are added to the4set of training instances.
The emotion classifiers areretrained using the larger set of training instances,and the bootstrapping process continues.3.4 SeedingFor each of the 5 emotion classes, we manuallyselected 5 seed hashtags that we determined to bestrongly representative of the emotion.
Before col-lecting the initial training tweets containing the seedhashtags, we manually searched in Twitter to en-sure that these seed hashtags are frequently used bytweeters.
Table 1 presents our seed hashtags.Emotion Classes Seed HashtagsAFFECTION #loveyou, #sweetheart, #bff#romantic, #soulmateANGER & #angry, #mad, #hateyouRAGE #pissedoff, #furiousFEAR & #afraid, #petrified, #scaredANXIETY #anxious, #worriedJOY #happy, #excited, #yay#blessed, #thrilledSADNESS & #sad, #depressedDISAPPOINT- #disappointed, #unhappyMENT #foreveraloneTable 1: Seed Emotion Hashtags3.5 N-gram Tweet ClassifierThe tweets acquired using the seed hashtags are usedas training instances to create emotion classifierswith supervised learning.
We first pre-process thetraining instances by tokenizing the tweets with afreely available tokenizer for Twitter (Owoputi etal., 2013).
Although it is not uncommon to expressemotion states in tweets with capitalized charactersinside words, the unique writing styles of the tweet-ers often create many variations of the same wordsand hashtags.
We, therefore, normalized case to en-sure generalization.We trained one logistic regression classifier foreach emotion class.
We chose logistic regressionas the classification algorithm because it producesprobabilities along with each prediction that we lateruse to assign scores to candidate emotion hashtags.As features, we used unigrams to represent all ofthe words and hashtags in a tweet, but we removedthe seed hashtags that were used to select the tweets(or the classifier would simply learn to recognize theseed hashtags).
Our hypothesis is that the seed hash-tag will not be the only emotion indicator in a tweet,most of the time.
The goal is for the classifier tolearn to recognize words and/or additional hashtagsthat are also indicative of the emotion.
Additionally,we removed from the feature set any user mentions(by looking for words with ?@?
prefix).
We also re-moved any word or hashtag from the feature set thatappeared only once in the training data.For emotion e, we used the tweets containingseed hashtags for e as the positive training instancesand the tweets containing hashtags for the otheremotions as negative instances.
However, we alsoneeded to provide negative training instances thatdo not belong to any of the 5 emotion classes.
Forthis purpose, we added 100,000 randomly collectedtweets to the training data.
While it is possible thatsome of these tweets are actually positive instancesfor e, our hope is that the vast majority of them willnot belong to emotion e.We experimented with feature options such as bi-grams, unigrams with the ?#?
symbol stripped offfrom hashtags, etc., but the combination of unigramsand hashtags as features worked the best.
We usedthe freely available java version of the LIBLINEAR(Fan et al 2008) package with its default parametersettings for logistic regression.3.6 Learning Emotion HashtagsThe next step is to learn emotion hashtags.
We applythe emotion classifiers to a pool of unlabeled tweetsand collect all of the tweets that the classifier canlabel.
For each emotion e ?
E, we first create a can-didate pool of emotion hashtags He, by collectingall of the hashtags in the labeled tweets for emotione.
To limit the size of the candidate pool, we dis-carded hashtags with just one character or more than20 characters, and imposed a frequency threshold of10.
We then score these hashtags to select the top Nemotion hashtags we feel most confident about.To score each candidate hashtag h ?
He, we com-pute the average of the probabilities assigned by thelogistic regression classifier to all the tweets con-taining hashtag h. We expect the classifier to as-sign higher probabilities only to tweets it feels confi-dent about.
Therefore, if h conveys e, we expect that5the average probability of all the tweets containingh will also be high.
We select the top 10 emotionhashtags for each emotion class e, and add them toour list of learned hashtags for e.3.7 Adding New Training Instances forBootstrappingTo facilitate the next stage of bootstrapping, we col-lect all tweets from the unlabeled data that containhashtag h and label them with the emotion associ-ated with h. By adding more training instances, weexpect to provide the classifiers with new tweets thatwill contain a potentially more diverse set of wordsthat the classifiers can consider in the next stage ofthe bootstrapping.When the new tweets are added to the training set,we remove the hashtags from them that we used forlabelling to avoid bias, and the bootstrapping pro-cess continues.
We ran the bootstrapped learning for100 iterations.
Since we learned 10 hashtags duringeach iteration, we ended up with emotion hashtaglists consisting of 1000 hashtags for each emotion.4 Experimental Setup4.1 Data CollectionTo collect our initial training data, we searched Twit-ter for the seed hashtags mentioned in Section 3.4using Twitter?s Search API3 over a period of time.To ensure that the collected tweets are written in En-glish, we used a freely available language recognizertrained for tweets (Carter et al 2013).
We filteredout tweets that were marked as re-tweets using #rt orbeginning with ?rt?4 because re-tweets are in manycases exactly the same or very similar to the origi-nal.
We also filtered out any tweet containing a URLbecause if such a tweet contains emotion, it is pos-sible that the emotion indicator may be present onlyon the linked website (e.g., a link to a comic stripfollowed by an emotion hashtag).
After these filter-ing steps, we ended up with a seed labeled trainingdataset of 325,343 tweets.In addition to the seed labeled data, we collectedrandom tweets using Twitter?s Streaming API5 overa period of time to use as our pool of unlabeled3https://dev.twitter.com/docs/api/1/get/search4a typical convention to mark a tweet as a re-tweet5https://dev.twitter.com/docs/streaming-apistweets.
Like the training data, we filtered out re-tweets and tweets containing a URL as well astweets containing any of the seed hashtags.
Sinceour research focus is on learning emotion hashtags,we also filtered out any tweet that did not have atleast one hashtag.
After filtering, we ended up withroughly 2.3 million unlabeled tweets.4.2 Test DataSince manual annotation is time consuming, to en-sure that many tweets in our test data have at leastone of our 5 emotions, we manually selected 25topic keywords/phrases6 that we considered to bestrongly associated with emotions, but not neces-sarily any specific emotion.
We then searched inTwitter for any of these topic phrases and their cor-responding hashtags.
These 25 topic phrases are:Prom, Exam, Graduation, Marriage, Divorce, Hus-band, Wife, Boyfriend, Girlfriend, Job, Hire, LaidOff, Retirement, Win, Lose, Accident, Failure, Suc-cess, Spider, Loud Noise, Chest Pain, Storm, HomeAlone, No Sleep and Interview.
Since the purpose ofcollecting these tweets is to evaluate the quality andcoverage of the emotion hashtags that we learn, wefiltered out any tweet that did not have at least onehashtag (other than the topic hashtag).To annotate tweets with respect to emotion, twoannotators were given definitions of the 5 emotionclasses from Collins English Dictionary7, Parrott?s(Parrott, 2001) emotion taxonomy of these 5 emo-tions and additional annotation guidelines.
The an-notators were instructed to label each tweet with upto two emotions.
The instructions specified that theemotion must be felt by the tweeter at the time thetweet was written.
After several trials and discus-sions, the annotators reached a satisfactory agree-ment level of 0.79 Kappa (?)
(Carletta, 1996).
Theannotation disagreements in these 500 tweets werethen adjudicated, and each annotator labeled an ad-ditional 2,500 tweets.
Altogether this gave us anemotion annotated dataset of 5,500 tweets.
We ran-domly separated out 1,000 tweets from this collec-tion as a tuning set, and used the remaining 4,500tweets as evaluation data.In Table 2, we present the emotion distribution in6This data collection process is similar to the emotion tweetdataset creation by Roberts et al(2012)7http://www.collinsdictionary.com/6tweets that were labeled using the seed hashtags inthe second column.
In the next column, we presentthe emotion distribution in the tweets that were an-notated for evaluation by the human annotators.Emotion Tweets with EvaluationSeed Hashtags TweetsAFFECTION 14.38% 6.42%ANGER/RAGE 14.01% 8.91%FEAR/ANXIETY 11.42% 13.16%JOY 37.47% 22.33%SADNESS/ 23.69% 12.45%DISAPPOINTMENTNONE OF THE ABOVE - 42.38%Table 2: Distribution of emotions in tweets with seedhashtags and evaluation tweets4.3 Evaluating Emotion HashtagsFor comparison, we trained logistic regression clas-sifiers with word unigrams and hashtags as featuresfor each emotion class, and performed 10-fold cross-validation on the evaluation data.
As a second base-line for comparison, we added bigrams to the featureset of the classifiers.To decide on the optimum size of the lists foreach emotion class, we performed list lookup on thetuning data that we had set aside before evaluation.For any hashtag in a tweet in the tuning dataset, welooked up that hashtag in our learned lists, and iffound, assigned the corresponding emotion as thelabel for that tweet.
We did this experiment startingwith only seeds in our lists, and incrementally in-creased the sizes of the lists by 50 hashtags at eachexperiment.
We decided on the optimum size basedon the best F-measure obtained for each emotionclass.
In Table 3, we show the list sizes we found toachieve the best F-measure for each emotion class inthe tuning dataset.Emotion List SizesAFFECTION 500ANGER/RAGE 1000FEAR/ANXIETY 850JOY 1000SADNESS/DISAPPOINTMENT 400Table 3: Optimum list sizes decided from tuning datasetTo use the learned lists of emotion hashtags forclassifying emotions in tweets, we first used them asfeatures for the logistic regression classifiers.
Wecreated 5 list features with binary values, one foreach emotion class.
Whenever a tweet in the evalua-tion data contained a hashtag from one of the learnedemotion hashtags lists, we set the value of that listfeature to be 1, and 0 otherwise.
We used these5 new features in addition to the word unigramsand hashtag features, and evaluated the classificationperformance of the logistic regression classifiers ina 10-fold cross-validation setup by calculating pre-cision, recall and F-measure.Since the more confident hashtags are added tothe lists at the beginning stages of bootstrapping, wealso tried creating subsets from each list by group-ing hashtags together that were learned after each 5iterations of bootstrapping (50 hashtags in each sub-set).
We then created 20 list subset features for eachemotion with binary values, yielding 100 additionalfeatures in total.
We also evaluated this feature rep-resentation of the hashtag lists in a 10-fold cross-validation setup.As a different approach, we also used the lists in-dependently from the logistic regression classifiers.For any hashtag in the evaluation tweets, we lookedup the hashtag in our learned lists.
If the hashtag wasfound, we assigned the corresponding emotion classlabel to the tweet containing the hashtag.
Lastly,we combined the list lookup decisions with the de-cisions of the baseline logistic regression classifiersby taking a union of the decisions, i.e., if either as-signed an emotion to a tweet, we assigned that emo-tion as the label for the tweet.
We present the resultsof these different approaches in Section 5.5 Results and AnalysisTable 4 shows the precision, recall and F-measureof the N-gram classifier as well as several differentutilizations of the learned hashtag lists.
The first andthe second row in Table 4 correspond to the resultsfor the baseline unigram classifier (UC) alone andwhen bigrams are added to the feature set.
Thesebaseline classifiers had low recall for most emotionclasses, suggesting that the N-grams and hashtagsare not adequate as features to recognize the emotionclasses.Results of using the hashtag lists as 5 additionalfeatures for the classifier are shown in the third row7Affection Anger Fear Joy SadnessEvaluation Rage Anxiety DisappointmentP R F P R F P R F P R F P R FBaseline ClassifiersUnigram Classifier (UC) 67 43 52 51 19 28 63 33 43 65 48 55 57 29 39UC + Bigram Features 70 38 50 52 15 23 64 29 40 65 45 53 57 25 34Baseline Classifier with List FeaturesUC + List Features 71 49 58 56 28 37 67 41 51 66 50 57 61 34 44UC + List Subset Features 73 45 56 58 23 33 69 38 49 66 48 55 61 32 42List LookupSeed Lookup 94 06 11 75 01 03 100 06 11 93 04 08 81 02 05List Lookup 73 40 52 59 25 35 61 36 45 70 16 26 80 17 28Baseline Classifier with List LookupUC ?
Seed Lookup 68 45 54 52 21 30 63 33 44 66 49 56 58 31 40UC ?
List Lookup 63 60 61 52 38 44 56 53 54 64 54 59 59 38 46Table 4: Emotion classification result (P = Precision, R = Recall, F = F-measure)of Table 4.
The hashtag lists consistently improveprecision and recall across all five emotions.
Com-pared to the unigram classifier, F-measure improvedby 6% for AFFECTION, by 9% for ANGER/RAGE,by 8% for FEAR/ANXIETY, by 2% for JOY, and by5% for SADNESS/DISAPPOINTMENT.
The nextrow presents the results when the list subset fea-tures were used.
Using this feature representationas opposed to using each list as a whole shows pre-cision recall tradeoff as the classifier learns to relyon the subsets of hashtags that are good, resulting inimproved precision for several emotion classes, butrecognizes emotions in fewer tweets, which resultedin less recall.The fifth and the sixth rows of Table 4 show re-sults of list lookup only.
As expected, seed lookuprecognizes emotions in tweets with high precision,but does not recognize the emotions in many tweetsbecause the seed lists have only 5 hashtags per emo-tion class.
Comparatively, using learned hashtaglists shows substantial improvement in recall as thelearned lists contain a lot more emotion hashtagsthan the initial seeds.Finally, the last two rows of Table 4 show classi-fication performance of taking the union of the de-cisions made by the unigram classifier and the deci-sions made by matching against just the seed hash-tags or the lists of learned hashtags.
The union withthe seed hashtags lookup shows consistent improve-ment across all emotion classes compared to the un-igram baseline but the improvements are small.
TheEvaluation Micro MacroAverage AverageP R F P R FBaseline ClassifiersUnigram Classifier (UC) 62 37 46 61 34 44UC + Bigram Features 63 33 43 62 30 41Baseline Classifier with List FeaturesUC + List Features 65 42 51 64 40 49UC + List Subset Features 66 39 49 65 37 48List LookupSeed Lookup 93 04 08 89 04 08List Lookup 67 24 35 68 27 38Baseline Classifier with List LookupUC ?
Seed Lookup 63 38 47 61 36 45UC ?
List Lookup 60 49 54 59 49 53Table 5: Micro and Macro averagesunion with the lookup in the learned lists of emo-tion hashtags shows substantial recall gains.
Thisapproach improves recall over the unigram baselineby 17% for AFFECTION, 19% for ANGER/RAGE,20% for FEAR/ANXIETY, 6% for JOY, and 9% forSADNESS/DISAPPOINTMENT.
At the same time,we observe that despite this large recall gain, preci-sion is about the same or just a little lower.
As a re-sult, we observe an overall F-measure improvementof 9% for AFFECTION, 16% for ANGER/RAGE,11% for FEAR/ANXIETY, 4% for JOY, and 7% forSADNESS/DISAPPOINTMENT.Table 5 shows the overall performance improve-ment of the classifiers, averaged across all five emo-tion classes, measured as micro and macro aver-8AFFECTION ANGER FEAR JOY SADNESSRAGE ANXIETY DISAPPOINT-MENT#youthebest #godie #hatespiders #thankinggod #catlady#yourthebest #donttalktome #freakedout #thankyoulord #buttrue#hyc #fuckyourself #creepedout #thankful #singleprobs#yourethebest #getoutofmylife #sinister #superexcited #singleproblems#alwaysandforever #irritated #wimp #tripleblessed #lonelytweet#missyou #pieceofshit #shittingmyself #24hours #lonely#loveyoumore #ruinedmyday #frightened #ecstatic #crushed#loveyoulots #notfriends #paranoid #happyme #lonerproblems#thanksforeverything #yourgross #haunted #lifesgood #unloved#flyhigh #madtweet #phobia #can?twait #friendless#comehomesoon #stupidbitch #shittingbricks #grateful #singlepringle#yougotthis #sofuckingannoying #hateneedles #goodmood #brokenheart#missyoutoo #annoyed #biggestfear #superhappy #singleforever#youdabest #fuming #worstfear #missedthem #nosociallife#otherhalf #wankers #concerned #greatmood #teamnofriends#youramazing #asshole #waitinggame #studio #foreverugly#cutiepie #dontbothermewhen #mama #tgfl #nofriends#bestfriendforever #fu #prayforme #exicted #leftout#alwayshereforyou #fuckyou #nightmares #smiles #singleforlife#howimetmybestfriend #yousuck #baddriver #liein #:?
(Table 6: Top 20 hashtags learned for each emotion classage precision, recall and F-measure scores.
We seeboth types of feature representations of the hashtaglists improve precision and recall across all emo-tion classes over the N-gram classifier baselines.Using the union of the classifier and list lookup,we see a 12% recall gain with only 2% precisiondrop in micro-average over the unigram baseline,and 15% recall gain with only 2% precision dropin macro-average.
As a result, we see an overall8% micro-average F-measure improvement and 9%macro-average F-measure improvement.In Table 6, we show the top 20 hashtags learnedin each emotion class by our bootstrapped learning.While many of these hashtags express emotion, wealso notice a few hashtags representing reasons (e.g.,#baddriver in FEAR/ANXIETY) that are stronglyassociated with the corresponding emotion, as wellas common misspellings (e.g., #exicted in JOY).6 ConclusionsIn this research we have presented a bootstrappedlearning framework to automatically learn emotionhashtags.
Our approach makes use of supervi-sion from seed hashtag labeled tweets, and througha bootstrapping process, iteratively learns emotionhashtags.
We have experimented with several ap-proaches to use the lists of emotion hashtags foremotion classification and have found that the hash-tag lists consistently improve emotion classificationperformance in tweets.
In future research, since ourbootstrapped learning approach does not rely on anylanguage specific techniques, we plan to learn emo-tion hashtags in other prominent languages such asSpanish, Portuguese, etc.7 AcknowledgmentsThis work was supported by the Intelligence Ad-vanced Research Projects Activity (IARPA) via De-partment of Interior National Business Center (DoI/ NBC) contract number D12PC00285.
The U.S.Government is authorized to reproduce and dis-tribute reprints for Governmental purposes notwith-standing any copyright annotation thereon.
Theviews and conclusions contained herein are thoseof the authors and should not be interpreted asnecessarily representing the official policies or en-dorsements, either expressed or implied, of IARPA,DoI/NBE, or the U.S. Government.9ReferencesEdward Benson, Aria Haghighi, and Regina Barzilay.2011.
Event discovery in social media feeds.
In Pro-ceedings of the 49th Annual Meeting of the Associa-tion for Computational Linguistics: Human LanguageTechnologies - Volume 1, HLT ?11, pages 389?398.Adam Bermingham and Alan Smeaton.
2011.
On usingtwitter to monitor political sentiment and predict elec-tion results.
In Proceedings of the Workshop on Sen-timent Analysis where AI meets Psychology (SAAIP2011), pages 2?10.Johan Bollen, Huina Mao, and Alberto Pepe.
2011.Modeling public mood and emotion: Twitter sentimentand socio-economic phenomena.
In Proceedings ofthe Fifth International Conference on Weblogs and So-cial Media.Samuel Brody and Nicholas Diakopoulos.
2011.Cooooooooooooooollllllllllllll!!!!!!!!!!!!!!
: usingword lengthening to detect sentiment in microblogs.In Proceedings of the Conference on EmpiricalMethods in Natural Language Processing, EMNLP?11, pages 562?570.Jean Carletta.
1996.
Assessing agreement on classifi-cation tasks: the kappa statistic.
Comput.
Linguist.,22:249?254, June.S.
Carter, W. Weerkamp, and E. Tsagkias.
2013.
Mi-croblog language identification: Overcoming the limi-tations of short, unedited and idiomatic text.
LanguageResources and Evaluation Journal, 47(1).Wilas Chamlertwat, Pattarasinee Bhattarakosol, Tip-pakorn Rungkasiri, and Choochart Haruechaiyasak.2012.
Discovering consumer insight from twitter viasentiment analysis.
Journal of Universal ComputerScience, 18(8):973?992, apr.Munmun De Choudhury, Michael Gamon, and ScottCounts.
2012.
Happy, nervous or surprised?
classi-fication of human affective states in social media.
InProceedings of the Sixth International Conference onWeblogs and Social Media.Dmitry Davidov, Oren Tsur, and Ari Rappoport.
2010.Semi-supervised recognition of sarcastic sentences intwitter and amazon.
In Proceedings of the Four-teenth Conference on Computational Natural Lan-guage Learning, CoNLL ?10, pages 107?116.Munmun De Choudhury, Nicholas Diakopoulos, and MorNaaman.
2012.
Unfolding the event landscape ontwitter: classification and exploration of user cate-gories.
In Proceedings of the ACM 2012 conference onComputer Supported Cooperative Work, CSCW ?12,pages 241?244.Ahmed Ali Abdalla Esmin, Roberto L. De Oliveira Jr.,and Stan Matwin.
2012.
Hierarchical classificationapproach to emotion recognition in twitter.
In Pro-ceedings of the 11th International Conference on Ma-chine Learning and Applications, ICMLA, Boca Ra-ton, FL, USA, December 12-15, 2012.
Volume 2, pages381?385.
IEEE.Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-RuiWang, and Chih-Jen Lin.
2008.
Liblinear: A libraryfor large linear classification.
J. Mach.
Learn.
Res.,9:1871?1874, June.Eric Gilbert and Karrie Karahalios.
2010.
Widespreadworry and the stock market.
In Proceedings of the In-ternational AAAI Conference on Weblogs and SocialMedia.Suin Kim, JinYeong Bak, and Alice Oh.
2012a.
Discov-ering emotion influence patterns in online social net-work conversations.
SIGWEB Newsl., (Autumn):3:1?3:6, September.Suin Kim, JinYeong Bak, and Alice Oh.
2012b.
Do youfeel what i feel?
social aspects of emotions in twitterconversations.
In International AAAI Conference onWeblogs and Social Media.Efthymios Kouloumpis, Theresa Wilson, and JohannaMoore.
2011.
Twitter sentiment analysis: The goodthe bad and the omg!
In Proceedings of the Fifth In-ternational Conference on Weblogs and Social Media.Saif Mohammad.
2012.
#emotional tweets.
In *SEM2012: The First Joint Conference on Lexical and Com-putational Semantics, pages 246?255.Olutobi Owoputi, Brendan OConnor, Chris Dyer, KevinGimpel, Nathan Schneider, and Noah A. Smith.
2013.Improved part-of-speech tagging for online conversa-tional text with word clusters.
In Proceedings of theNorth American Chapter of the Association for Com-putational Linguistics (NAACL-2013).W.
Gerrod Parrott, editor.
2001.
Emotions in Social Psy-chology.
Psychology Press.Matthew Purver and Stuart Battersby.
2012.
Experi-menting with distant supervision for emotion classi-fication.
In Proceedings of the 13th Conference ofthe European Chapter of the Association for Compu-tational Linguistics, EACL ?12, pages 482?491.Alan Ritter, Colin Cherry, and Bill Dolan.
2010.
Unsu-pervised modeling of twitter conversations.
In HumanLanguage Technologies: The 2010 Annual Conferenceof the North American Chapter of the Association forComputational Linguistics, HLT ?10, pages 172?180.Kirk Roberts, Michael A. Roach, Joseph Johnson, JoshGuthrie, and Sanda M. Harabagiu.
2012.
Empatweet:Annotating and detecting emotions on twitter.
In Pro-ceedings of the Eighth International Conference onLanguage Resources and Evaluation (LREC-2012),pages 3806?3813.
ACL Anthology Identifier: L12-1059.10Andranik Tumasjan, Timm O. Sprenger, Philipp G. Sand-ner, and Isabell M. Welpe.
2011.
Election fore-casts with twitter: How 140 characters reflect the po-litical landscape.
Social Science Computer Review,29(4):402?418, November.Xiaolong Wang, Furu Wei, Xiaohua Liu, Ming Zhou,and Ming Zhang.
2011.
Topic sentiment analysis intwitter: a graph-based hashtag sentiment classificationapproach.
In Proceedings of the 20th ACM interna-tional conference on Information and knowledge man-agement, CIKM ?11, pages 1031?1040.Wenbo Wang, Lu Chen, Krishnaprasad Thirunarayan,and Amit P. Sheth.
2012.
Harnessing twitter ?bigdata?
for automatic emotion identification.
In Pro-ceedings of the 2012 ASE/IEEE International Confer-ence on Social Computing and 2012 ASE/IEEE In-ternational Conference on Privacy, Security, Risk andTrust, SOCIALCOM-PASSAT ?12, pages 587?592.Changhua Yang, Kevin Hsin-Yih Lin, and Hsin-HsiChen.
2007a.
Building emotion lexicon from weblogcorpora.
In Proceedings of the 45th Annual Meetingof the ACL on Interactive Poster and DemonstrationSessions, ACL ?07, pages 133?136.Changhua Yang, Kevin Hsin-Yih Lin, and Hsin-HsiChen.
2007b.
Emotion classification using web blogcorpora.
In Proceedings of the IEEE/WIC/ACM In-ternational Conference on Web Intelligence, WI ?07,pages 275?278.11
