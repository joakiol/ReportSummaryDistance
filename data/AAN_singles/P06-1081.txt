Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 641?648,Sydney, July 2006. c?2006 Association for Computational LinguisticsConcept Unification of Terms in Different Languages for IRQing Li,  Sung-Hyon MyaengInformation & CommunicationsUniversity, Korea{liqing,myaeng}@icu.ac.krYun JinChungnam NationalUniversity, Koreawkim@cnu.ac.krBo-yeong KangSeoul National University,Koreacomeng99@snu.ac.krAbstractDue to the historical and cultural reasons,English phases, especially the propernouns and new words, frequently appearin Web pages written primarily in Asianlanguages such as Chinese and Korean.Although these English terms and theirequivalences in the Asian languages referto the same concept, they are erroneouslytreated as independent index units in tra-ditional Information Retrieval (IR).
Thispaper describes the degree to which theproblem arises in IR and suggests a noveltechnique to solve it.
Our method firstlyextracts an English phrase from Asianlanguage Web pages, and then unifies theextracted phrase and its equivalence(s) inthe language as one index unit.
Experi-mental results show that the high preci-sion of our conceptual unification ap-proach greatly improves the IR perform-ance.1 IntroductionThe mixed use of English and local languagespresents a classical problem of vocabulary mis-match in monolingual information retrieval(MIR).
The problem is significant especially inAsian language because words in the local lan-guages are often mixed with English words.
Al-though English terms and their equivalences in alocal language refer to the same concept, they areerroneously treated as independent index units intraditional MIR.
Such separation of semanticallyidentical words in different languages may limitretrieval performance.
For instance, as shown inFigure 1, there are three kinds of Chinese Webpages containing information related with?Viterbi Algorithm (?????)?.
The firstcase contains ?Viterbi Algorithm?
but not itsChinese equivalence ???????.
The secondFigure 1.
Three Kinds of Web Pagescontains ???????
but not ?Viterbi Algo-rithm?.
The third has both of them.
A user wouldexpect that a query with either ?Viterbi Algo-rithm?
or ???????
would retrieve all ofthese three groups of Chinese Web pages.
Oth-erwise some potentially useful information willbe ignored.Furthermore, one English term may have sev-eral corresponding terms in a different language.For instance, Korean words ????
?, ????
?,and ?????
are found in local Web pages,which all correspond to the English word ?digi-tal?
but are in different forms because of differ-ent phonetic interpretations.
Establishing anequivalence class among the three Korean wordsand the English counterpart is indispensable.
Bydoing so, although the query is ????
?, theWeb pages containing ????
?, ?????
or?digital?
can be all retrieved.
The same goes toChinese terms.
For example, two same semanticChinese terms ?????
and ?????
corre-spond to one English term ?Viterbi?.
Thereshould be a semantic equivalence relation be-tween them.Although tracing the original English termfrom a term in a native language by back trans-literation (Jeong et al, 1999) is a good way tobuild such mapping, it is only applicable to thewords that are amenable for transliteration basedon the phoneme.
It is difficult to expand themethod to abbreviations and compound words.641Since English abbreviations frequently appear inKorean and Chinese texts, such as???????
(WTO)?
in Korean, ???????
(WTO)?
in Chinese, it is essential in IR tohave a mapping between these English abbrevia-tions and the corresponding words.
The sameapplies to the compound words like ????
(Seoul National University)?
in Korean, ????
(mad cow disease)?
in Chinese.
Realizing thelimitation of the transliteration, we present a wayto extract the key English phrases in local Webpages and conceptually unify them with theirsemantically identical terms in the local language.2 Concept UnificationThe essence of the concept unification of termsin different languages is similar to that of thequery translation for cross-language informationretrieval (CLIR) which has been widely explored(Cheng et al, 2004; Cao and Li, 2002; Fung etal., 1998; Lee, 2004; Nagata et al, 2001; Rapp,1999; Zhang et al, 2005; Zhang and Vine, 2004).For concept unification in index, firstly key Eng-lish phrases should be extracted from local Webpages.
After translating them into the local lan-guage, the English phrase and their translation(s)are treated as the same index units for IR.
Differ-ent from previous work on query term translationthat aims at finding relevant terms in anotherlanguage for the target term in source language,conceptual unification requires a high translationprecision.
Although the fuzzy Chinese transla-tions (e.g.
???
(virus), ???
(designer?sname), ????
(computer virus)) of  Englishterm ?CIH?
can enhance the CLIR performanceby the ?query expansion?
gain (Cheng et al,2004), it does not work in the conceptual unifica-tion of terms in different languages for IR.While there are lots of additional sources to beutilized for phrase translation (e.g., anchor text,parallel or comparable corpus), we resort to themixed language Web pages which are the localWeb pages with some English words, becausethey are easily obtainable and frequently self-refresh.Observing the fact that English words some-times appear together with their equivalence in alocal language in Web texts as shown in Figure 1,it is possible to mine the mixed language search-result pages obtained from Web search enginesand extract proper translations for these Englishwords that are treated as queries.
Due to the lan-guage nature of Chinese and Korean, we inte-grate the phoneme and semanteme instead ofstatistical information alone to pick out the righttranslation from the search-result pages.3 Key Phrase ExtractionSince our intention is to unify the semanticallyidentical words in different languages and indexthem together, the primary task is to decide whatkinds of key English phrases in local Web pagesare necessary to be conceptually unified.In (Jeong et al, 1999), it extracts the Koreanforeign words for concept unification based onstatistical information.
Some of the Englishequivalences of these Korean foreign words,however, may not exist in the Korean Web pages.Therefore, it is meaningless to do the cross-language concept unification for these words.The English equivalence would not benefit anyretrieval performance since no local Web pagescontain it, even if the search system builds a se-mantic class among both local language andEnglish for these words.
In addition, the methodfor detecting Korean foreign words may bringsome noise.
The Korean terms detected as for-eign words sometimes are not meaningful.Therefore, we do it the other way around bychoosing the English phrases from the local Webpages based on a certain selection criteria.Instead of extracting all the English phrases inthe local Web pages, we only select the Englishphrases that occurred within the special marksincluding quotation marks and parenthesis.
Be-cause English phrases within these markers re-veal their significance in information searchingto some extent.
In addition, if the phrase startswith some stemming words (e.g., for, as) or in-cludes some special sign, it is excluded as thephrases to be translated.4 Translation of English PhrasesIn order to translate the English phrases extracted,we query the search engine with English phrasesto retrieve the local Web pages containing them.For each document returned, only the title andthe query-biased summary are kept for furtheranalysis.
We dig out the translation(s) for theEnglish phrases from these collected documents.4.1 Extraction of Candidates for SelectionAfter querying the search engine with the Eng-lish phrase, we can get the snippets (title andsummary) of Web texts in the returned search-result pages as shown in Figure 1.
The next stepthen is to extract translation candidates within awindow of a limited size, which includes the642English phrase, in the snippets of Web texts inthe returned search-result pages.
Because of theagglutinative nature of the Chinese and Koreanlanguages, we should group the words in the lo-cal language into proper units as translation can-didates, instead of treating each individual wordas candidates.
There are two typical ways: one isto group the words based on their co-occurrenceinformation in the corpus (Cheng et al, 2004),and the other is to employ all sequential combi-nations of the words as the candidates (Zhangand Vine, 2004).
Although the first reduces thenumber of candidates, it risks losing the rightcombination of words as candidates.
We adoptthe second in our approach, so that,  return to theaforementioned example in Figure 1, if there arethree Chinese characters (???)
within the pre-defined window, the translation candidates forEnglish phrases ?Viterbi?
are  ???,??
?, ???,???
?, ???
?, and ?????.
The number ofcandidates in the second method, however, isgreatly increased by enlarging the window sizek .
Realizing that the number of words, n , avail-able in the window size, k , is generally largerthan the predefined maximum length of candi-date, m ,  it is unreasonable to use all adjacentsequential combinations of available wordswithin the window size k .
Therefore, we tunethe method as follows:1.
If n m?
, all adjacent sequential combina-tions of words within the window are treated ascandidates2.
If n m> , only adjacent sequential combina-tions of which the word number is less than mare regarded as candidates.
For example, if weset n  to 4 and m  to 2, the window ?
1 2 3 4w w w w ?consists of four words.
Therefore, only ?
1 2w w ?,?
2 3w w ?, ?
3 4w w ?, ?
1w ?, ?
2w ??
?
3w ?, ?
4w ?
areemployed as the candidates for final translationselection.Based on our experiments, this tuning methodachieves the same performance while reducingthe candidate size greatly.4.2 Selection of candidatesThe final step is to select the proper candidate(s)as the translation(s) of the key English phrase.We present a method that considers the statistical,phonetic and semantic features of the Englishcandidates for selection.Statistical information such as co-occurrence,Chi-square, mutual information between theEnglish term and candidates helps distinguish theright translation(s).
Using Cheng?s Chi-squaremethod (Cheng et al, 2004), the probability tofind the right translation for English specificterm is around 30% in the top-1 case and 70% inthe top-5 case.
Since our goal is to find the corre-sponding counterpart(s) of the English phrase totreat them as one index unit in IR, the accuracylevel is not satisfactory.
Since it seems difficultto improve the precision solely through variantstatistical methods, we also consider semanticand phonetic information of candidates besidesthe statistical information.
For example, giventhe English Key phrase ?Attack of the clones?,the right Korean translation ???????
is faraway from the top-10 selected by Chi-squaremethod (Cheng et al, 2004).
However, based onthe semantic match of ????
and ?Attack?, andthe phonetic match of ????
and ?clones?, wecan safely infer they are the right translation.
Thesame rule applies to the Chinese translation  ???????
?, where ?????
is phoneticallymatch for ?clones?
and ????
semantically cor-responds to ?attack?.In selection step, we first remove most of thenoise candidates based on the statistical methodand re-rank the candidates based on the semanticand phonetic similarity.4.3 Statistical modelThere are several statistical models to rank thecandidates.
Nagata (2001) and Huang (2005) usethe frequency of co-occurrence and the textualdistance, the number of words between the Keyphrase and candidates in texts to rank the candi-dates, respectively.
Although the details of themethods are quite different, both of them sharethe same assumption that the higher co-occurrence between candidates and the Keyphrase, the more possible they are the right trans-lations for each other.
In addition, they observedthat most of the right translations for the Keyphrase are close to it in the text, especially, rightafter or before the key phrase (e.g.
?
??????(FBI)???).
Zhang (2004) sug-gested a statistical model based on the frequencyof co-occurrence and the length of the candidates.In the model, since the distance between the keyphrase and a candidate is not considered, theright translation located far away from the keyphrase also has a chance to be selected.
We ob-serve, however, that such case is very rare in ourstudy, and most of right translations are locatedwithin 5~8 words.
The distance information is avaluable factor to be considered.643In our statistical model, we consider the fre-quency, length and location of candidates to-gether.
The intuition is that if the candidate is theright translation, it tends to co-occur with the keyphrase frequently; its location tends to be close tothe key phrase; and the longer the candidates?length, the higher the chance to be the righttranslation.
The formula to calculate the rankingscore for a candidate is as follows:1( ) ( , )( , ) (1 )max maxki k iFL ilen Freq lenlen c d q cw q c ?
?
?= ?
+ ?
?
?where ( , )k id q c  is the word distance between theEnglish phrase  q  and the candidate ic  in the k-th occurrence of candidate in the search-resultpages.
If  q  is adjacent to ic  , the word distanceis one.
If there is one word between them, it iscounted as two and so forth.
?
is the coefficientconstant, and maxFreq len?
is the max reciprocal of( , )k id q c  among all the candidates.
( )ilen c  is thenumber of characters in the candidate ic .4.4 Phonetic and semantic modelPhonetic and semantic match: There has beensome related work on extracting term translationbased on the transliteration model (Kang andChoi, 2002; Kang and Kim, 2000).
Differentfrom transliteration that attempts to generateEnglish transliteration given a foreign word inlocal language, our approach is a kind a matchproblem since we already have the candidatesand aim at selecting the right candidates as thefinal translation(s) for the English key phrase.While the transliteration method is partiallysuccessful, it suffers form the problem that trans-literation rules are not applied consistently.
TheEnglish key phrase for which we are looking forthe translation sometimes contains several wordsthat may appear in a dictionary as an independentunit.
Therefore, it can only be partially matchedbased on the phonetic similarity, and the rest partmay be matched by the semantic similarity insuch situation.
Returning to the above example,?clone?
is matched with ????
by phoneticsimilarity.
?of?
and ?attack?
are matched with???
and ????
respectively by semantic simi-larity.
The objective is to find a set of mappingsbetween the English word(s) in the key phraseand the local language word(s) in candidates,which maximize the sum of the semantic andphonetic mapping weights.
We call the sum asSSP (Score of semanteme and phoneme).
Thehigher SSP value is, the higher the probability ofthe candidate to be the right translation.The solution for a maximization problem canbe found using an exhaustive search method.However, the complexity is very high in practicefor a large number of pairs to be processed.
Asshown in Figure 2, the problem can be repre-sented as a bipartite weighted graph matchingproblem.
Let the English key phrase, E, be repre-sented as a sequence of tokens 1,..., mew ew< > , andthe candidate in local language, C, be repre-sented as a sequence of tokens 1,..., ncw cw< > .Each English and candidate token is representedas a graph vertex.
An edge ( , )i jew cw  is formedwith the weight ( , )i jew cw?
calculated as the av-erage of normalized semantic and phonetic val-ues, whose calculation details are explained be-low.
In order to balance the number of verticeson both sides, we add the virtual vertex (vertices)with zero weight on the side with less number ofvertices.
The SSP is calculated:n( )i=1SSP=argmax ( , )i ikw ew??
?where ?
is a permutation of {1, 2, 3, ?, n}.
Itcan be solved by the Kuhn-Munkres algorithm(also known as Hungarian algorithm) with poly-nomial time complexity (Munkres, 1957).Figure 2.
Matching based on the semanteme andphonemePhonetic & Semantic Weights: If two lan-guages have a close linguistic relationship suchas English and French, cognate matching (Davis,1997) is typically employed to translate the un-translatable terms.
Interestingly, Buckley et al,(2000) points out that ?English query words aretreated as potentially misspelled French words?and attempts to treat English words as variationsof French words according to lexicographicalrules.
However, when two languages are verydistinct, e.g., English?Korean, English?Chinese,transliteration from English words is utilized forcognate matching.Phonetic weight is the transliteration probabil-ity between English and candidates in local lan-guage.
We adopt the method in (Jeong et al,1999) with some adjustments.
In essence, wecompute the probabilities of particular English??
??
?The of Clones Attack644key phrase EW given a candidate in the locallanguage CW.1 11 1 1( , ) ( ,..., , ,..., )1( ,..., , ,..., ) log ( | ) ( | )phoneme phoneme m kphoneme n k j j j jjEW CW e e c cg g c c P g g P c gn?
??
?== = ?where the English phrase consists of a string ofEnglish alphabets 1,..., me e , and the candidate inthe local language is comprised of  a string ofphonetic elements.
1,..., kc c .
For Korean language,the phonetic element is the Korean alphabetssuch as ??
?, ??
?, ???
, ???
and etc.
For Chi-nese language, the phonetic elements mean theelements of ?pinying?.
ig  is a pronunciation unitcomprised of one or more English alphabets( e.g., ?ss?
for ??
?, a Korean alphabet ).The first term in the product corresponds tothe transition probability between two states inHMM and the second term to the output prob-ability for each possible output that could corre-spond to the state, where the states are all possi-ble distinct English pronunciation units for thegiven Korean or Chinese word.
Because the dif-ference between Korean/Chinese and Englishphonetic systems makes the above uni-grammodel almost impractical in terms of outputquality, bi-grams are applied to substitute thesingle alphabet in the above equation.
Therefore,the phonetic weight should be calculated as:1 1 1 11( , ) log ( | ) ( | )phoneme j j j j j j j jjE C P g g g g P c c g gn?
+ ?
+ += ?where 1 1( | )j j j jP c c g g+ +  is computed from thetraining corpus as the ratio between the fre-quency of 1j jc c +  in the candidates, which wereoriginated from 1j jg g + in English words, to thefrequency of 1j jg g + .
If 1j =  or j n= , 1jg ?
or1jg + , 1jc +  is substituted with a space marker.The semantic weight is calculated from the bi-lingual dictionary.
The current bilingual diction-ary we employed for the local languages are Ko-rean-English WorldNet and LDC Chinese-English dictionary with additional entries in-serted manually.
The weight relies on the degreeof overlaps between an English translation andthe candidatesemantemeNo.
of  overlapping unitsw (E,C)= argmaxtotal No.
of   unitsFor example, given the English phrase ?InhaUniversity?
and its candidate ????
(InhaUniversity), ?University?
is translated into????
?, therefore, the semantic weight be-tween ?University?
and ???
is about 0.33 be-cause only one third of the full translation isavailable in the candidate.Due to the range difference between phoneticand semantic weights, we normalized them bydividing the maximum phonetic and semanticweights in each pair of the English phrase and acandidate if the maximum is larger than zero.The strategy for us to pick up the final transla-tion(s) is distinct on two different aspects fromthe others.
If the SSP values of all candidates areless than the threshold, the top one obtained bystatistical model is selected as the final transla-tion.
Otherwise, we re-rank the candidates ac-cording to the SSP value.
Then we look downthrough the new rank list and draw a ?virtual?line if there is a big jump of SSP value.
If there isno big jump of SSP values, the ?virtual?
line isdrawn at the bottom of the new rank list.
Insteadof the top-1 candidate, the candidates above the?virtual?
line are all selected as the final transla-tions.
It is because that an English phrase mayhave more than one correct translation in the lo-cal language.
Return to the previous example, theEnglish term ?Viterbi?
corresponds to two Chi-nese translations ?????
and ?????.
Thecandidate list based on the statistical informationis ??
?, ?
?, ?
?, ???,?,????.
Wethen calculate the SSP value of these candidatesand re-rank the candidates whose SSP values arelarger than the threshold which we set to 0.3.Since the SSP value of ????(0.91)?
and ????(0.91)?
are both larger than the thresholdand there is no big jump, both of them are se-lected as the final translation.5 Experimental EvaluationAlthough the technique we developed has valuesin their own right and can be applied for otherlanguage engineering fields such as query trans-lation for CLIR, we intend to understand to whatextent monolingual information retrieval effec-tiveness can be increased when relevant terms indifferent language are treated as one unit whileindexing.
We first examine the translation preci-sion and then study the impact of our approachfor monolingual IR.We crawls the web pages of a specific domain(university & research) by WIRE crawler pro-vided by center of Web Research, university ofChile (http://www.cwr.cl/projects/WIRE/).
Cur-rently, we have downloaded 32 sites with 5,847645Korean Web pages and 74 sites with 13,765 Chi-nese Web pages.
232 and 746 English termswere extracted from Korean Web pages and Chi-nese Web pages, respectively.
The accuracy ofunifying semantically identical words in differentlanguages is dependant on the translation per-formance.
The translation results are shown intable 1.
As it can be observed, 77% of Englishterms from Korean web pages and 83% of Eng-lish terms from Chinese Web pages can bestrictly translated into accurate Korean and Chi-nese, respectively.
However, additional 15% and14% translations contained at least one Koreanand Chinese translations, respectively.
The er-rors were brought in by containing additionalrelated information or incomplete translation.
Forinstance, the English term ?blue chip?
is trans-lated into ???
(blue chip)?, ????
(a kind ofstock)?.
However, another acceptable translation????
(a kind of stock)?
is ignored.
An ex-ample for incomplete translation is Englishphrase ?
SIGIR 2005?
which only can be trans-late into ??????????
(internationalconference of computer information retrieval?ignoring the year.Korean ChineseNo.
% No.
%Exactly correct 179 77% 618 83%At least one iscorrect but not all 35 15% 103 14%Wrong translation 18 8% 25 3%Total 232 100% 746 100%Table 1.
Translation performanceWe also compare our approach with two well-known translation systems.
We selected 200English words and translate them into Chineseand Korean by these systems.
Table2 and Table3 show the results in terms of the top 1, 3, 5 in-clusion rates for Korean and Chinese translation,respectively.
?Exactly and incomplete?
transla-tions are all regarded as the right translations.?LiveTrans?
and ?Google?
represent the systemsagainst which we compared the translation abil-ity.
Google provides a machine translation func-tion to translate text such as Web pages.
Al-though it works pretty well to translate sentences,it is ineligible for short terms where only a littlecontextual information is available for translation.LiveTrans (Cheng et al, 2004) provided by theWKD lab in Academia Sinica is the first un-known word translation system based on web-mining.
There are two ways in this system totranslate words: the fast one with lower precisionis based on the ?chi-square?
method ( 2? )
and thesmart one with higher precision is based on ?con-text-vector?
method (CV) and ?chi-square?method ( 2? )
together.
?ST?
and ?ST+PS?
repre-sent our approaches based on statistic model andstatistic model plus phonetic and semantic model,respectively.Top -1 Top-3 Top -5Google 56% NA NA?Fast?2?
37% 43% 53.5%LiveTrans ?Smart?2?
+CV42% 49% 60%ST(dk=1) 28.5 % 41% 47%ST 39 % 46.5% 55.5%OurMethodsST+PS 93% 93% 93%Table 2.
Comparison (Chinese case)Top -1 Top-3 Top -5Google 44% NA NA?Fast?2?
28% 37.5% 45% LiveTrans ?Smart?2?
+CV24.5% 44% 50%ST(dk=1) 26.5 % 35.5% 41.5%ST 32 % 40% 46.5%OurMethodsST+PS 89% 89.5% 89.5%Table 3.
Comparison  (Korean case)Even though the overall performance of Li-veTrans?
combined method ( 2?
+CV) is betterthan the simple method ( 2? )
in both Table 2 and3, the same doesn?t hold for each individual.
Forinstance, ?Jordan?
is the English translation ofKorean term   ????
?, which  ranks 2nd and5th in ( 2? )
and ( 2?
+CV), respectively.
The con-text-vector sometimes misguides the selection.In our two-step selection approach, the finalselection would not be diverted by the false sta-tistic information.
In addition, in order to exam-ine the contribution of distance information inthe statistical method, we ran our experimentsbased on statistical method (ST) with two differ-ent conditions.
In the first case, we set  ( , )k id q c  to1, that is, the location information of all candi-dates is ignored.
In the second case, ( , )k id q c  iscalculated based on the real textual distance ofthe candidates.
As in both Table 2 and Table 3,the later case shows better performance.As shown in both Table 2 and Table 3, it canbe observed that ?ST+PS?
shows the best per-formance, then followed by ?LiveTrans (smart)?,?ST?, ?LiveTrans(fast)?, and ?Google?.
The sta-646tistical methods seem to be able to give a roughestimate for potential translations without givinghigh precision.
Considering the contextual wordssurrounding the candidates and the Englishphrase can further improve the precision but stillless than the improvement made by the phoneticand semantic information in our approach.
Highprecision is very important to the practical appli-cation of the translation results.
The wrong trans-lation sometimes leads to more damage to itslater application than without any translationavailable.
For instance, the Chinese translationof ?viterbi?
is ???(algorithm)?
by LiveTrans(fast).
Obviously, treating ?Viterbi?
and  ???
(algorithm)?as one index unit is not acceptable.We ran monolingual retrieval experiment toexamine the impact of our concept unification onIR.
The retrieval system is based on the vectorspace model with our own indexing scheme towhich the concept unification part was added.We employed the standard tf idf?
scheme forindex term weighting and idf  for query termweighting.
Our experiment is based on KT-SETtest collection (Kim et al, 1994).
It contains 934documents and 30 queries together with rele-vance judgments for them.In our index scheme, we extracted the keyEnglish phrases in the Korean texts, and trans-lated them.
Each English phrases and its equiva-lence(s) in Korean is treated as one index unit.The baseline against which we compared ourapproach applied a relatively simple indexingtechnique.
It uses a dictionary that is Korean-English WordNet, to identify index terms.
Theeffectiveness of the baseline scheme is compara-ble with other indexing methods (Lee and Ahn,1999).
While there is a possibility that an index-ing method with a full morphological analysismay perform better than our rather simplemethod, it would also suffer from the same prob-lem, which can be alleviated by concept unifica-tion approach.
As shown in Figure 3, we ob-tained 14.9 % improvement based on mean aver-age 11-pt precision.
It should be also noted thatthis result was obtained even with the errorsmade by the unification of semantically identicalterms in different languages.6 ConclusionIn this paper, we showed the importance of theunification of semantically identical terms in dif-ferent languages for Asian monolingual informa-tion retrieval, especially Chinese and Korean.Taking the utilization of the high translation ac-curacy of our previous work, we successfullyunified the most semantically identical terms inthe corpus.
This is along the line of work whereresearchers attempt to index documents withconcepts rather than words.
We would extendour work along this road in the future.Recall0.0 .2 .4 .6 .8 1.0Precision0.0.2.4.6.81.0BaselineConceptual UnificationFigure 3.
Korean Monolingual IRReferenceBuckley, C., Mitra, M., Janet, A. and Walz, C.C..2000.
Using Clustering and Super Concepts withinSMART: TREC 6.
Information Processing &Management.
36(1): 109-131.Cao, Y. and Li., H.. 2002.
Base Noun Phrase Transla-tion Using Web Data and the EM Algorithm.
InProc.
of.
the 19th COLING.Cheng, P.,  Teng, J., Chen, R., Wang, J., Liu,W.,Chen, L.. 2004.
Translating Specific Queries withWeb Corpora for Cross-language Information Re-trieval.
In Proc.
of ACM SIGIR.Davis, M.. 1997.
New Experiments in Cross-languageText Retrieval at NMSU's Computing ResearchLab.
In Proc.
Of TREC-5.Fung, P. and Yee., L.Y.. 1998.
An IR Approach forTranslating New Words from Nonparallel, Compa-rable Texts.
In Proc.
of  COLING/ACL-98.Huang, F., Zhang, Y. and Vogel, S.. 2005.
MiningKey Phrase Translations from Web Corpora, InProc.
of the Human Language Technologies Con-ference (HLT-EMNLP).Jeong, K. S., Myaeng, S. H., Lee, J. S., Choi, K. S..1999.
Automatic identification and back-transliteration of foreign words for information re-trieval.
Information Processing & Management.35(4): 523-540.Kang, B. J., and Choi, K. S. 2002.
Effective ForeignWord Extraction for Korean Information Retrieval.Information Processing & Management, 38(1): 91-109.647Kang, I. H. and Kim, G. C.. 2000.
English-to-KoreanTransliteration using Multiple Unbounded Over-lapping Phoneme Chunks.
In Proc.
of COLING .Kim, S.-H. et al.
1994.
Development of the Test Setfor Testing Automatic Indexing.
In Proc.
of the22nd KISS Spring Conference.
(in Korean).Lee, J, H. and Ahn, J.
S.. 1996.
Using N-grams forKorean Test Retrieval.
In Proc.
of SIGIR.Lee, J.
S.. 2004.
Automatic Extraction of TranslationPhrase Enclosed within Parentheses using Bilin-gual Alignment Method.
In Proc.
of the 5th China-Korea Joint Symposium on Oriental LanguageProcessing and Pattern Recognition.Munkres, J.. 1957.
Algorithms for the Assignmentand Transportation Problems.
J. Soc.
Indust.
Appl.Math., 5 (1957).Nagata, M., Saito, T., and Suzuki, K.. 2001.
Using theWeb as a Bilingual Dictionary.
In Proc.
of ACL'2001 DD-MT Workshop.Rapp, R.. 1999.
Automatic Identification of WordTranslations from Unrelated English and Germancorpora.
In Proc.
of ACL.Zhang, Y., Huang, F. and Vogel, S.. 2005.
MiningTranslations of OOV Terms from the Web throughCross-lingual Query Expansion, In Proc.
of ACMSIGIR-05.Zhang, Y. and Vines, P.. 2004.
Using the Web forAutomated Translation Extraction in Cross-Language Information Retrieval.
In Proc.
of ACMSIGIR-04.648
