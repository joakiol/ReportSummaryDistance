Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-X),pages 216?220, New York City, June 2006. c?2006 Association for Computational LinguisticsMultilingual Dependency Analysis with a Two-Stage Discriminative ParserRyan McDonald Kevin Lerman Fernando PereiraDepartment of Computer and Information ScienceUniversity of PennsylvaniaPhiladelphia, PA{ryantm,klerman,pereira}@cis.upenn.eduAbstractWe present a two-stage multilingual de-pendency parser and evaluate it on 13diverse languages.
The first stage isbased on the unlabeled dependency pars-ing models described by McDonald andPereira (2006) augmented with morpho-logical features for a subset of the lan-guages.
The second stage takes the out-put from the first and labels all the edgesin the dependency graph with appropri-ate syntactic categories using a globallytrained sequence classifier over compo-nents of the graph.
We report results onthe CoNLL-X shared task (Buchholz etal., 2006) data sets and present an erroranalysis.1 IntroductionOften in language processing we require a deep syn-tactic representation of a sentence in order to assistfurther processing.
With the availability of resourcessuch as the Penn WSJ Treebank, much of the fo-cus in the parsing community had been on producingsyntactic representations based on phrase-structure.However, recently their has been a revived interestin parsing models that produce dependency graphrepresentations of sentences, which model wordsand their arguments through directed edges (Hud-son, 1984; Mel?c?uk, 1988).
This interest has gener-ally come about due to the computationally efficientand flexible nature of dependency graphs and theirability to easily model non-projectivity in freer-wordorder languages.
Nivre (2005) gives an introductionto dependency representations of sentences and re-cent developments in dependency parsing strategies.Dependency graphs also encode much of the deepsyntactic information needed for further process-ing.
This has been shown through their success-ful use in many standard natural language process-ing tasks, including machine translation (Ding andPalmer, 2005), sentence compression (McDonald,2006), and textual inference (Haghighi et al, 2005).In this paper we describe a two-stage discrimi-native parsing approach consisting of an unlabeledparser and a subsequent edge labeler.
We evaluatethis parser on a diverse set of 13 languages usingdata provided by the CoNLL-X shared-task organiz-ers (Buchholz et al, 2006; Hajic?
et al, 2004; Simovet al, 2005; Simov and Osenova, 2003; Chen et al,2003; Bo?hmova?
et al, 2003; Kromann, 2003; vander Beek et al, 2002; Brants et al, 2002; Kawataand Bartels, 2000; Afonso et al, 2002; Dz?eroski etal., 2006; Civit Torruella and Mart??
Anton?
?n, 2002;Nilsson et al, 2005; Oflazer et al, 2003; Atalay etal., 2003).
The results are promising and show thelanguage independence of our system under the as-sumption of a labeled dependency corpus in the tar-get language.For the remainder of this paper, we denote byx = x1, .
.
.
xn a sentence with n words and byy a corresponding dependency graph.
A depen-dency graph is represented by a set of ordered pairs(i, j) ?
y in which xj is a dependent and xi is thecorresponding head.
Each edge can be assigned a la-bel l(i,j) from a finite set L of predefined labels.
We216assume that all dependency graphs are trees but maybe non-projective, both of which are true in the datasets we use.2 Stage 1: Unlabeled ParsingThe first stage of our system creates an unlabeledparse y for an input sentence x.
This system isprimarily based on the parsing models describedby McDonald and Pereira (2006).
That work ex-tends the maximum spanning tree dependency pars-ing framework (McDonald et al, 2005a; McDonaldet al, 2005b) to incorporate features over multipleedges in the dependency graph.
An exact projec-tive and an approximate non-projective parsing al-gorithm are presented, since it is shown that non-projective dependency parsing becomes NP-hardwhen features are extended beyond a single edge.That system uses MIRA, an online large-marginlearning algorithm, to compute model parameters.Its power lies in the ability to define a rich set of fea-tures over parsing decisions, as well as surface levelfeatures relative to these decisions.
For instance, thesystem of McDonald et al (2005a) incorporates fea-tures over the part of speech of words occurring be-tween and around a possible head-dependent rela-tion.
These features are highly important to over-all accuracy since they eliminate unlikely scenariossuch as a preposition modifying a noun not directlyto its left, or a noun modifying a verb with anotherverb occurring between them.We augmented this model to incorporate morpho-logical features derived from each token.
Consider aproposed dependency of a dependent xj on the headxi, each with morphological features Mj and Mi re-spectively.
We then add to the representation of theedge: Mi as head features, Mj as dependent fea-tures, and also each conjunction of a feature fromboth sets.
These features play the obvious role ofexplicitly modeling consistencies and commonali-ties between a head and its dependents in terms ofattributes like gender, case, or number.
Not all datasets in our experiments include morphological fea-tures, so we use them only when available.3 Stage 2: Label ClassificationThe second stage takes the output parse y for sen-tence x and classifies each edge (i, j) ?
y with aparticular label l(i,j).
Ideally one would like to makeall parsing and labeling decisions jointly so that theshared knowledge of both decisions will help resolveany ambiguities.
However, the parser is fundamen-tally limited by the scope of local factorizations thatmake inference tractable.
In our case this meanswe are forced only to consider features over singleedges or pairs of edges.
However, in a two stagesystem we can incorporate features over the entireoutput of the unlabeled parser since that structure isfixed as input.
The simplest labeler would be to takeas input an edge (i, j) ?
y for sentence x and findthe label with highest score,l(i,j) = argmaxls(l, (i, j),y,x)Doing this for each edge in the tree would pro-duce the final output.
Such a model could easily betrained using the provided training data for each lan-guage.
However, it might be advantageous to knowthe labels of other nearby edges.
For instance, if weconsider a head xi with dependents xj1 , .
.
.
, xjM , itis often the case that many of these dependencieswill have correlated labels.
To model this we treatthe labeling of the edges (i, j1), .
.
.
, (i, jM ) as a se-quence labeling problem,(l(i,j1), .
.
.
, l(i,jM )) = l?
= argmaxl?s(l?, i,y,x)We use a first-order Markov factorization of thescorel?
= argmaxl?M?m=2s(l(i,jm), l(i,jm?1), i,y,x)in which each factor is the score of labeling the adja-cent edges (i, jm) and (i, jm?1) in the tree y.
We at-tempted higher-order Markov factorizations but theydid not improve performance uniformly across lan-guages and training became significantly slower.For score functions, we use simple dot productsbetween high dimensional feature representationsand a weight vectors(l(i,jm), l(i,jm?1), i,y,x) =w ?
f(l(i,jm), l(i,jm?1), i,y,x)Assuming we have an appropriate feature repre-sentation, we can find the highest scoring label se-quence with Viterbi?s algorithm.
We use the MIRA217online learner to set the weights (Crammer andSinger, 2003; McDonald et al, 2005a) since wefound it trained quickly and provide good perfor-mance.
Furthermore, it made the system homoge-neous in terms of learning algorithms since that iswhat is used to train our unlabeled parser (McDon-ald and Pereira, 2006).
Of course, we have to definea set of suitable features.
We used the following:?
Edge Features: Word/pre-suffix/part-of-speech(POS)/morphological feature identity of the head and thedependent (affix lengths 2 and 3).
Does the head and itsdependent share a prefix/suffix?
Attachment direction.What morphological features do head and dependenthave the same value for?
Is the dependent the first/lastword in the sentence??
Sibling Features: Word/POS/pre-suffix/morphologicalfeature identity of the dependent?s nearest left/right sib-lings in the tree (siblings are words with same parent inthe tree).
Do any of the dependent?s siblings share itsPOS??
Context Features: POS tag of each intervening word be-tween head and dependent.
Do any of the words betweenthe head and the dependent have a parent other than thehead?
Are any of the words between the head and the de-pendent not a descendant of the head (i.e.
non-projectiveedge)??
Non-local: How many children does the dependent have?What morphological features do the grandparent and thedependent have identical values?
Is this the left/right-most dependent for the head?
Is this the first dependentto the left/right of the head?Various conjunctions of these were includedbased on performance on held-out data.
Note thatmany of these features are beyond the scope of theedge based factorizations of the unlabeled parser.Thus a joint model of parsing and labeling could noteasily include them without some form of re-rankingor approximate parameter estimation.4 ResultsWe trained models for all 13 languages providedby the CoNLL organizers (Buchholz et al, 2006).Based on performance from a held-out section of thetraining data, we used non-projective parsing algo-rithms for Czech, Danish, Dutch, German, Japanese,Portuguese and Slovene, and projective parsing al-gorithms for Arabic, Bulgarian, Chinese, Spanish,Swedish and Turkish.
Furthermore, for Arabic andSpanish, we used lemmas instead of inflected wordDATA SET UA LAARABIC 79.3 66.9BULGARIAN 92.0 87.6CHINESE 91.1 85.9CZECH 87.3 80.2DANISH 90.6 84.8DUTCH 83.6 79.2GERMAN 90.4 87.3JAPANESE 92.8 90.7PORTUGUESE 91.4 86.8SLOVENE 83.2 73.4SPANISH 86.1 82.3SWEDISH 88.9 82.5TURKISH 74.7 63.2AVERAGE 87.0 80.8Table 1: Dependency accuracy on 13 languages.Unlabeled (UA) and Labeled Accuracy (LA).forms, again based on performance on held-outdata1.Results on the test set are given in Table 1.
Per-formance is measured through unlabeled accuracy,which is the percentage of words that modify thecorrect head in the dependency graph, and labeledaccuracy, which is the percentage of words thatmodify the correct head and label the dependencyedge correctly in the graph.
These results show thatthe discriminative spanning tree parsing framework(McDonald et al, 2005b; McDonald and Pereira,2006) is easily adapted across all these languages.Only Arabic, Turkish and Slovene have parsing ac-curacies significantly below 80%, and these lan-guages have relatively small training sets and/or arehighly inflected with little to no word order con-straints.
Furthermore, these results show that a two-stage system can achieve a relatively high perfor-mance.
In fact, for every language our models per-form significantly higher than the average perfor-mance for all the systems reported in Buchholz etal.
(2006).For the remainder of the paper we provide a gen-eral error analysis across a wide set of languagesplus a detailed error analysis of Spanish and Arabic.5 General Error AnalysisOur system has several components, including theability to produce non-projective edges, sequential1Using the non-projective parser for all languages does noteffect performance significantly.
Similarly, using the inflectedword form instead of the lemma for all languages does notchange performance significantly.218SYSTEM UA LAN+S+M 86.3 79.7P+S+M 85.6 79.2N+S+B 85.5 78.6N+A+M 86.3 79.4P+A+B 84.8 77.7Table 2: Error analysis of parser components av-eraged over Arabic, Bulgarian, Danish, Dutch,Japanese, Portuguese, Slovene, Spanish, Swedishand Turkish.
N/P: Allow non-projective/Force pro-jective, S/A: Sequential labeling/Atomic labeling,M/B: Include morphology features/No morphologyfeatures.assignment of edge labels instead of individual as-signment, and a rich feature set that incorporatesmorphological properties when available.
The bene-fit of each of these is shown in Table 2.
These resultsreport the average labeled and unlabeled precisionfor the 10 languages with the smallest training sets.This allowed us to train new models quickly.Table 2 shows that each component of our systemdoes not change performance significantly (rows 2-4 versus row 1).
However, if we only allow projec-tive parses, do not use morphological features andlabel edges with a simple atomic classifier, the over-all drop in performance becomes significant (row5 versus row 1).
Allowing non-projective parseshelped with freer word order languages like Dutch(78.8%/74.7% to 83.6%/79.2%, unlabeled/labeledaccuracy).
Including rich morphology features natu-rally helped with highly inflected languages, in par-ticular Spanish, Arabic, Turkish, Slovene and to alesser extent Dutch and Portuguese.
Derived mor-phological features improved accuracy in all theselanguages by 1-3% absolute.Sequential classification of labels had very lit-tle effect on overall labeled accuracy (79.4% to79.7%)2.
The major contribution was in helping todistinguish subjects, objects and other dependentsof main verbs, which is the most common label-ing error.
This is not surprising since these edgelabels typically are the most correlated (i.e., if youalready know which noun dependent is the subject,then it should be easy to find the object).
For in-stance, sequential labeling improves the labeling of2This difference was much larger for experiments in whichgold standard unlabeled dependencies are used.objects from 81.7%/75.6% to 84.2%/81.3% (la-beled precision/recall) and the labeling of subjectsfrom 86.8%/88.2% to 90.5%/90.4% for Swedish.Similar improvements are common across all lan-guages, though not as dramatic.
Even with this im-provement, the labeling of verb dependents remainsthe highest source of error.6 Detailed Analysis6.1 SpanishAlthough overall unlabeled accuracy is 86%, mostverbs and some conjunctions attach to their headwords with much lower accuracy: 69% for mainverbs, 75% for the verb ser, and 65% for coor-dinating conjunctions.
These words form 17% ofthe test corpus.
Other high-frequency word classeswith relatively low attachment accuracy are preposi-tions (80%), adverbs (82%) and subordinating con-junctions (80%), for a total of another 23% of thetest corpus.
These weaknesses are not surprising,since these decisions encode the more global as-pects of sentence structure: arrangement of clausesand adverbial dependents in multi-clause sentences,and prepositional phrase attachment.
In a prelimi-nary test of this hypothesis, we looked at all of thesentences from a development set in which a mainverb is incorrectly attached.
We confirmed that themain clause is often misidentified in multi-clausesentences, or that one of several conjoined clausesis incorrectly taken as the main clause.
To test thisfurther, we added features to count the number ofcommas and conjunctions between a dependent verband its candidate head.
Unlabeled accuracy for allverbs increases from 71% to 73% and for all con-junctions from 71% to 74%.
Unfortunately, accu-racy for other word types decreases somewhat, re-sulting in no significant net accuracy change.
Nev-ertheless, this very preliminary experiment suggeststhat wider-range features may be useful in improv-ing the recognition of overall sentence structure.Another common verb attachment error is aswitch between head and dependent verb in phrasalverb forms like dejan intrigar or qiero decir, possi-bly because the non-finite verb in these cases is oftena main verb in training sentences.
We need to lookmore carefully at verb features that may be usefulhere, in particular features that distinguish finite and219non-finite forms.In doing this preliminary analysis, we noticedsome inconsistencies in the reference dependencystructures.
For example, in the test sentence Loque decia Mae West de si misma podr?
?amos decirlotambie?n los hombres:..., decia?s head is given as de-cirlo, although the main verbs of relative clauses arenormally dependent on what the relative modifies, inthis case the article Lo.6.2 ArabicA quick look at unlabeled attachment accuracies in-dicate that errors in Arabic parsing are the mostcommon across all languages: prepositions (62%),conjunctions (69%) and to a lesser extent verbs(73%).
Similarly, for labeled accuracy, the hard-est edges to label are for dependents of verbs, i.e.,subjects, objects and adverbials.
Note the differ-ence in error between the unlabeled parser and theedge labeler: the former makes mistakes on edgesinto prepositions, conjunctions and verbs, and thelatter makes mistakes on edges into nouns (sub-ject/objects).
Each stage by itself is relatively ac-curate (unlabeled accuracy is 79% and labeling ac-curacy3 is also 79%), but since there is very littleoverlap in the kinds of errors each makes, overall la-beled accuracy drops to 67%.
This drop is not nearlyas significant for other languages.Another source of potential error is that the aver-age sentence length of Arabic is much higher thanother languages (around 37 words/sentence).
How-ever, if we only look at performance for sentencesof length less than 30, the labeled accuracy is stillonly 71%.
The fact that Arabic has only 1500 train-ing instances might also be problematic.
For exam-ple if we train on 200, 400, 800 and the full trainingset, labeled accuracies are 54%, 60%, 62% and 67%.Clearly adding more data is improving performance.However, when compared to the performance ofSlovene (1500 training instances) and Spanish (3300instances), it appears that Arabic parsing is lagging.7 ConclusionsWe have presented results showing that the spanningtree dependency parsing framework of McDonald et3Labeling accuracy is the percentage of words that correctlylabel the dependency between the head that they modify, evenif the right head was not identified.al.
(McDonald et al, 2005b; McDonald and Pereira,2006) generalizes well to languages other than En-glish.
In the future we plan to extend these mod-els in two ways.
First, we plan on examining theperformance difference between two-staged depen-dency parsing (as presented here) and joint parsingplus labeling.
It is our hypothesis that for languageswith fine-grained label sets, joint parsing and label-ing will improve performance.
Second, we plan onintegrating any available morphological features ina more principled manner.
The current system sim-ply includes all morphological bi-gram features.
Itis our hope that a better morphological feature setwill help with both unlabeled parsing and labelingfor highly inflected languages.ReferencesS.
Buchholz, E. Marsi, A. Dubey, and Y. Krymolowski.2006.
CoNLL-X shared task on multilingual depen-dency parsing.
SIGNLL.K.
Crammer and Y.
Singer.
2003.
Ultraconservative on-line algorithms for multiclass problems.
JMLR.Y.
Ding and M. Palmer.
2005.
Machine translation usingprobabilistic synchronous dependency insertion gram-mars.
In Proc.
ACL.A.
Haghighi, A. Ng, and C. Manning.
2005.
Robusttextual inference via graph matching.
In Proc.
HTL-EMNLP.R.
Hudson.
1984.
Word Grammar.
Blackwell.R.
McDonald and F. Pereira.
2006.
Online learning ofapproximate dependency parsing algorithms.
In Proc.EACL.R.
McDonald, K. Crammer, and F. Pereira.
2005a.
On-line large-margin training of dependency parsers.
InProc.
ACL.R.
McDonald, F. Pereira, K. Ribarov, and J. Hajic?.
2005b.Non-projective dependency parsing using spanningtree algorithms.
In Proc.
HLT-EMNLP.R.
McDonald.
2006.
Discriminative sentence compres-sion with soft syntactic constraints.
In Proc.
EACL.I.A.
Mel?c?uk.
1988.
Dependency Syntax: Theory andPractice.
State University of New York Press.J.
Nivre.
2005.
Dependency grammar and dependencyparsing.
Technical Report MSI report 05133, Va?xjo?University: School of Mathematics and Systems Engi-neering.220
