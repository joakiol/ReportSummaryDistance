Proceedings of the 2nd Workshop on Speech and Language Processing for Assistive Technologies, pages 52?62,Edinburgh, Scotland, UK, July 30, 2011. c?2011 Association for Computational LinguisticsImproving the Accessibility of Line Graphs in Multimodal DocumentsCharles F. Greenbacker Peng Wu Sandra Carberry Kathleen F. McCoyStephanie Elzer* David D. McDonald?
Daniel Chester Seniz Demir?Dept.
of Computer & Information Sciences, University of Delaware, USA[charlieg|pwu|carberry|mccoy|chester]@cis.udel.edu*Dept.
of Computer Science, Millersville University, USA elzer@cs.millersville.edu?SIFT LLC., Boston, Massachusetts, USA dmcdonald@sift.info?TU?BI?TAK BI?LGEM, Gebze, Kocaeli, Turkey senizd@uekae.tubitak.gov.trAbstractThis paper describes our work on improv-ing access to the content of multimodal docu-ments containing line graphs in popular mediafor people with visual impairments.
We pro-vide an overview of our implemented system,including our method for recognizing and con-veying the intended message of a line graph.The textual description of the graphic gener-ated by our system is presented at the most rel-evant point in the document.
We also describeongoing work into obtaining additional propo-sitions that elaborate on the intended message,and examine the potential benefits of analyz-ing the text and graphical content together inorder to extend our system to produce sum-maries of entire multimodal documents.1 IntroductionIndividuals with visual impairments have difficultyaccessing the information contained in multimodaldocuments.
Although screen-reading software canrender the text of the document as speech, the graph-ical content is largely inaccessible.
Here we con-sider information graphics (e.g., bar charts, linegraphs) often found in popular media sources suchas Time magazine, Businessweek, and USA Today.These graphics are typically intended to convey amessage that is an important part of the overall story,yet this message is generally not repeated in the ar-ticle text (Carberry et al, 2006).
People who areunable to see and assimilate the graphical materialwill be left with only partial information.While some work has addressed the accessibilityof scientific graphics through alternative means liketouch or sound (see Section 7), such graphs are de-signed for an audience of experts trained to use themfor data visualization.
In contrast, graphs in popularmedia are constructed to make a point which shouldbe obvious without complicated scientific reasoning.We are thus interested in generating a textual pre-sentation of the content of graphs in popular media.Other research has focused on textual descriptions(e.g., Ferres et al (2007)); however in that work thesame information is included in the textual summaryfor each instance of a graph type (i.e., all summariesof line graphs contain the same sorts of informa-tion), and the summary does not attempt to presentthe overall intended message of the graph.SIGHT (Demir et al, 2008; Elzer et al, 2011) isa natural language system whose overall goal is pro-viding blind users with interactive access to multi-modal documents from electronically-available pop-ular media sources.
To date, the SIGHT projecthas concentrated on simple bar charts.
Its user in-terface is implemented as a browser helper objectwithin Internet Explorer that works with the JAWSscreen reader.
When the system detects a bar chartin a document being read by the user, it prompts theuser to use keystrokes to request a brief summary ofthe graphic capturing its primary contribution to theoverall communicative goal of the document.
Thesummary text can either be read to the user withJAWS or read by the user with a screen magnifiertool.
The interface also enables the user to requestfurther information about the graphic, if desired.However, SIGHT is limited to bar charts only.In this work, we follow the methodology put forthby SIGHT, but investigate producing a summary of52?102468 1900?10?20?50?60?70?80?90?03?30?402000108.91.979 inches over the past century.
Annual difference from Seattle?sIn the seattle area, for example, thePacific Ocean has risennearlythey are rising about 0.04?0.09 of aninch each year.Sea levels fluctuate around the globe, but oceanographers believeOcean levels rising1899 sea level, in inches:Figure 1: From ?Worry flows from Arctic ice to tropicalwaters?
in USA Today, May 31, 2006.line graphs.
Line graphs have different discoursegoals and communicative signals than bar charts,1and thus require significantly different processing.In addition, our work addresses the issue of coher-ent placement of a graphic?s summary when readingthe text to the user and considers the summarizationof entire documents ?
not just their graphics.2 Message Recognition for Line GraphsThis section provides an overview of our imple-mented method for identifying the intended messageof a line graph.
In processing a line graph, a vi-sual extraction module first analyzes the image fileand produces an XML representation which fullyspecifies the graphic (including the beginning andending points of each segment, any annotations onpoints, axis labels, the caption, etc.).
To identifythe intended message of a line graph consisting ofmany short, jagged segments, we must generalizeit into a sequence of visually-distinguishable trends.This is performed by a graph segmentation modulewhich uses a support vector machine and a varietyof attributes (including statistical tests) to produce amodel that transforms the graphic into a sequence ofstraight lines representing visually-distinguishabletrends.
For example, the line graph in Figure 1 isdivided into a stable trend from 1900 to 1930 and arising trend from 1930 to 2003.
Similarly, the linegraph in Figure 2 is divided into a rising trend from1Bar charts present data as discrete bars and are often usedto compare entities, while line graphs contain continuous dataseries and are designed to portray longer trend relationships.2006200520042003200219971998199920012000200,000 150,0001999: 189,84070,6062006:50,000100,000Declining Durango sales0Figure 2: From ?Chrysler: Plant had $800 million im-pact?
in The (Wilmington) News Journal, Feb 15, 2007.1997 to 1999 and a falling trend from 1999 to 2006.In analyzing a corpus of around 100 line graphscollected from several popular media sources, weidentified 10 intended message categories (includ-ing rising-trend, change-trend, change-trend-return,and big-jump, etc.
), that seem to capture the kindsof high-level messages conveyed by line graphs.
Asuggestion generation module uses the sequence oftrends identified in the line graph to construct allof its possible candidate messages in these messagecategories.
For example, if a graph contains threetrends, several candidate messages are constructed,including two change-trend messages (one for eachadjacent pair of trends), a change-trend-return mes-sage if the first and third trends are of the same type(rising, falling, or stable), as well as a rising, falling,or stable trend message for each individual trend.Next, various communicative signals are ex-tracted from the graphic, including visual features(such as a point annotated with its value) that drawattention to a particular part of the line graph, andlinguistic clues (such as the presence of certainwords in the caption) that suggest a particular in-tended message category.
Figure 2 contains severalsuch signals, including two annotated points and theword declining in its caption.
Next, a Bayesian net-work is built to estimate the probability of the can-didate messages; the extracted communicative sig-nals serve as evidence for or against each candidatemessage.
For Figure 2, our system produces change-trend(1997, rise, 1999, fall, 2006) as the logical rep-resentation of the most probable intended message.Since the dependent axis is often not explicitly la-beled, a series of heuristics are used to identify anappropriate referent, which we term the measure-ment axis descriptor.
In Figure 2, the measurementaxis descriptor is identified as durango sales.
The53intended message and measurement axis descriptorare then passed to a realization component whichuses FUF/SURGE (Elhadad and Robin, 1996) togenerate the following initial description:This graphic conveys a changing trend indurango sales, rising from 1997 to 1999and then falling to 2006.3 Identifying a Relevant ParagraphIn presenting a multimodal document to a user via ascreen reader, if the author does not specify a read-ing order in the accessibility preferences, it is notentirely clear where the description of the graph-ical content should be given.
The text of scien-tific articles normally makes explicit references toany graphs contained in the document; in this case,it makes sense to insert the graphical descriptionalongside the first such reference.
However, popularmedia articles rarely contain explicit references tographics.
We hypothesize that describing the graphi-cal content together with the most relevant portion ofthe article text will result in a more coherent presen-tation.
Results of an experiment described in Sec-tion 3.3 suggest the paragraph which is geograph-ically closest to the graphic is very often not rele-vant.
Thus, our task becomes identifying the portionof the text that is most relevant to the graph.We have developed a method for identifying themost relevant paragraph by measuring the similaritybetween the graphic?s textual components and thecontent of each individual paragraph in the docu-ment.
An information graphic?s textual componentsmay consist of a title, caption, and any additionaldescriptions it contains (e.g., the five lines of text inFigure 1 beneath the caption Ocean levels rising).An initial method (P-KL) based on KL divergencemeasures the similarity between a paragraph and thegraphic?s textual component; a second method (P-KLA) is an extension of the first that incorporatesan augmented version of the textual component.3.1 Method P-KL: KL DivergenceKullback-Leibler (KL) divergence (Kullback, 1968)is widely used to measure the similarity between twolanguage models.
It can be expressed as:DKL(p||q) =?i?Vp(i)logp(i)q(i)where i is the index of a word in vocabulary V , andp and q are two distributions of words.
Liu et al(Liu and Croft, 2002) applied KL divergence to textpassages in order to improve the accuracy of docu-ment retrieval.
For our task, p is a smoothed worddistribution built from the line graph?s textual com-ponent, and q is another smoothed word distributionbuilt from a paragraph in the article text.
Smoothingaddresses the problem of zero occurrences of a wordin the distributions.
We rank the paragraphs by theirKL divergence scores from lowest to highest, sincelower scores indicate a higher similarity.3.2 Method P-KLA: Using Augmented TextIn analyzing paragraphs relevant to the graphics, werealized that they included words that were germaneto describing information graphics in general, butnot related to the domains of individual graphs.
Thisled us to build a set of ?expansion words?
that tend toappear in paragraphs relevant to information graph-ics.
If we could identify domain-independent termsthat were correlated with information graphics ingeneral, these expansion words could then be addedto the textual component of a graphic when measur-ing its similarity to a paragraph in the article text.We constructed the expansion word set using aniterative process.
The first step is to use P-KL toidentify m pseudo-relevant paragraphs in the cor-responding document for each graphic in the train-ing set (the current implementation uses m = 3).This is similar to pseudo-relevance feedback used inIR (Zhai, 2008), except only a single query is usedin the IR application, whereas we consider manypairs of graphics and documents to obtain an ex-pansion set applicable to any subsequent informa-tion graphic.
Given n graphics in the training set,we identify (up to) m ?
n relevant paragraphs.The second step is to extract a set of words re-lated to information graphics from these m ?n para-graphs.
We assume the collection of pseudo-relevantparagraphs was generated by two models, one pro-ducing words relevant to the information graphicsand another producing words relevant to the topicsof the individual documents.
Let Wg represent theword frequency vector yielding words relevant tothe graphics, Wa represent the word frequency vec-tor yielding words relevant to the document topics,and Wp represent the word frequency vector of the54pseudo-relevant paragraphs.
We compute Wp fromthe pseudo-relevant paragraphs themselves, and weestimate Wa using the word frequencies from thearticle text in the documents.
Finally, we computeWg by filtering-out the components ofWa fromWp.This process is related to the work by Widdows(2003) on orthogonal negation of vector spaces.The task can be formulated as follows:1.
Wp = ?Wa + ?Wg where ?
> 0 and ?
> 0,which means the word frequency vector forthe pseudo-relevant paragraphs is a linear com-bination of the background (topic) word fre-quency vector and the graphic word vector.2.
< Wa,Wg >= 0 which means the backgroundword vector is orthogonal to the graph descrip-tion word vector, under the assumption that thegraph description word vector is independent ofthe background word vector and that these twoshare minimal information.3.
Wg is assumed to be a unit vector, since we areonly interested in the relative rank of the wordfrequencies, not their actual values.Solving the above equations, we obtain:?
=< Wp,Wa >< Wa,Wa >Wg = normalized(Wp ?< Wp,Wa >< Wa,Wa >?Wa)After computing Wg, we use WordNet to filter-out words having a predominant sense other thanverb or adjective, under the assumption that nounswill be mainly relevant to the domains or topicsof the graphs (and are thus ?noise?)
whereas wewant a general set of words (e.g., ?increasing?
)that are typically used when describing the data inany graph.
As a rough estimate of whether a wordis predominantly a verb or adjective, we determinewhether there are more verb and adjective senses ofthe word in WordNet than there are noun senses.Next, we rank the words in the filteredWg accord-ing to frequency and select the k most frequent asour expansion word list (we used k = 25 in our ex-periments).
The two steps (identifyingm?n pseudo-relevant paragraphs and then extracting a word list ofsize k to expand the graphics?
textual components)are applied iteratively until convergence occurs orminimal changes are observed between iterations.In addition, parameters of the intended messagethat represent points on the x-axis capture domain-specific content of the graphic?s communicativegoal.
For example, the intended message of the linegraph in Figure 1 conveys a changing trend from1900 to 2003 with the change occurring in 1930.
Tohelp identify relevant paragraphs mentioning theseyears, we also add these parameters of the intendedmessage to the augmented word list.The result of this process is the final expansionword list used in method P-KLA.
Because the tex-tual component may be even shorter than the expan-sion word list, we do not add a word from the expan-sion word list to the textual component unless theparagraph being compared also contains this word.3.3 Results of P-KL and P-KLA334 training graphs with their accompanying articleswere used to build the expansion word set.
A sepa-rate set of 66 test graphs and articles was analyzedby two human annotators who identified the para-graphs in each document that were most relevant toits associated information graphic, ranking them interms of relevance.
On average, annotator 1 selected2.00 paragraphs and annotator 2 selected 1.71 para-graphs.
The annotators agreed on the top rankedparagraph for only 63.6% of the graphs.
Consid-ering the agreement by chance, we can calculate thekappa statistic as 0.594.
This fact shows that themost relevant paragraph is not necessarily obviousand multiple plausible options may exist.We applied both P-KL and P-KLA to the test set,with each method producing a list of the paragraphsranked by relevance.
Since our goal is to providethe summary of the graphic at a suitable point in thearticle text, two evaluation criteria are appropriate:1.
TOP: the method?s success rate in selectingthe most relevant paragraph, measured as howoften it chooses the paragraph ranked highestby either of the annotators2.
COVERED: the method?s success rate in se-lecting a relevant paragraph, measured as howoften it chooses one of the relevant paragraphsidentified by the annotatorsTable 1 provides the success rates of both of ourmethods for the TOP and COVERED criteria, alongwith a simple baseline that selected the paragraph55geographically-closest to the graphic.
These resultsshow that both methods outperform the baseline,and that P-KLA further improves on P-KL.
P-KLAselects the best paragraph in 60.6% of test cases,and selects a relevant paragraph in 71.2% of thecases.
For both TOP and COVERED, P-KLA nearlydoubles the baseline success rate.
The improve-ment of P-KLA over P-KL suggests that our expan-sion set successfully adds salient words to the tex-tual component.
A one-sided Z-test for proportionbased on binomial distribution is shown in Table 1and indicates that the improvements of P-KL overthe baseline and P-KLA over P-KL are statistically-significant at the 0.05 level across both criteria.
TheZ-test is calculated as:p?
p0?p0(1?p0)nwhere p0 is the lower result and p is the improvedresult.
The null hypothesis is H0 : p = p0 and thealternative hypothesis is H1 : p > p0.3.4 Using relevant paragraph identification toimprove the accessibility of line graphsOur system improves on SIGHT by using methodP-KLA to identify the paragraph that is most rele-vant to an information graphic.
When this paragraphis encountered, the user is asked whether he or shewould like to access the content of the graphic.
Forexample, our system identifies the following para-graph as most relevant to Figure 2:Doing so likely would require the com-pany to bring in a new model.
Sales ofthe Durango and other gas-guzzling SUVshave slumped in recent years as prices atthe pump spiked.In contrast, the geographically-closest paragraph haslittle relevance to the graphic:?We have three years to prove to themwe need to stay open,?
said Sam Latham,president of the AFL-CIO in Delaware,who retired from Chrysler after 39 years.4 Identifying Additional PropositionsAfter the intended message has been identified, thesystem next looks to identify elaborative informa-tional propositions that are salient in the graphic.These additional propositions expand on the initialdescription of the graph by filling-in details aboutthe knowledge being conveyed (e.g., noteworthypoints, properties of trends, visual features) in orderto round-out a summary of the graphic.We collected a corpus of 965 human-written sum-maries for 23 different line graphs to discover whichpropositions were deemed most salient under variedconditions.2 Subjects received an initial descriptionof the graph?s intended message, and were asked towrite additional sentences capturing the most impor-tant information conveyed by the graph.
The propo-sitions appearing in each summary were manuallycoded by an annotator to determine which were mostprevalent.
From this data, we developed rules toidentify important propositions in new graphs.
Therules assign weights to propositions indicating theirimportance, and the weights can be compared to de-cide which propositions to include in a summary.Three types of rules were built.
Type-1 (messagecategory-only) rules were created when a pluralityof summaries for all graphs having a given intendedmessage contained the same proposition (e.g., pro-vide the final value for all rising-trend and falling-trend graphs).
Weights for type-1 rules were basedon the frequency with which the proposition ap-peared in summaries for graphs in this category.Type-2 (visual feature-only) rules were built whenthere was a correlation between a visual feature andthe use of a proposition describing that feature, re-gardless of the graph?s message category (e.g., men-tion whether the graph is highly volatile).
Type-2rule weights are a function of the covariance be-tween the magnitude of the visual feature (e.g., de-gree of volatility) and the proportion of summariesmentioning this proposition for each graph.For propositions associated with visual featureslinked to a particular message category (e.g., de-scribe the trend immediately following a big-jumpor big-fall when it terminates prior to the end of thegraph), we constructed Type-3 (message category+ visual feature) rules.
Type-3 weights were cal-culated just like Type-2 weights, except the graphswere limited to the given category.As an example of identifying additional proposi-2This corpus is described in greater detail by Greenbacker etal.
(2011) and is available at www.cis.udel.edu/~mccoy/corpora56closest P-KL significance level over closest P-KLA significance level over P-KLTOP 0.272 0.469 (z = 3.5966, p < 0.01) 0.606 (z = 2.2303, p < 0.025)COVERED 0.378 0.606 (z = 3.8200, p < 0.01) 0.712 (z = 1.7624, p < 0.05)Table 1: Success rates for baseline method (?closest?
), P-KL, and P-KLA using the TOP and COVERED criteria.tions, consider Figures 1 and 2.
Both line graphsbelong to the same intended message category:change-trend.
However, the graph in Figure 1 is farmore volatile than Figure 2, and thus it is likely thatwe would want to mention this proposition (i.e., ?thegraph shows a high degree of volatility...?)
in a sum-mary of Figure 1.
By finding the covariance betweenthe visual feature (i.e., volatility) and the frequencywith which a corresponding proposition was anno-tated in the corpus summaries, a Type-2 rule assignsa weight to this proposition based on the magnitudeof the visual feature.
Thus, the volatility proposi-tion will be weighted strongly for Figure 1, and willlikely be selected to appear in the initial summary,while the weight for Figure 2 will be very low.5 Integrating Text and GraphicsUntil now, our system has only produced summariesfor the graphical content of multimodal documents.However, a user might prefer a summary of the en-tire document.
Possible use cases include examiningthis summary to decide whether to invest the time re-quired to read a lengthy article with a screen reader,or simply addressing the common problem of havingtoo much material to review in too little time (i.e.,information overload).
We are developing a systemextension that will allow users to request summariesof arbitrary length that cover both the text and graph-ical content of a multimodal document.Graphics in popular media convey a message thatis generally not repeated in the article text.
For ex-ample, the March 3, 2003 issue of Newsweek con-tained an article entitled, ?The Black Gender Gap,?which described the professional achievements ofblack women.
It included a line graph (Figure 3)showing that the historical gap in income equalitybetween white women and black women had beenclosed, yet this important message appears nowherein the article text.
Other work in multimodal doc-ument summarization has relied on image captionsand direct references to the graphic in the text (Bha-tia et al, 2009); however, these textual elements doFigure 3: From ?The Black Gender Gap?
in Newsweek,Mar 3, 2003.not necessarily capture the message conveyed by in-formation graphics in popular media.
Thus, the usermay miss out on an essential component of the over-all communicative goal of the document if the sum-mary covers only material presented in the text.One approach to producing a summary of the en-tire multimodal document might be to ?concatenate?a traditional extraction-based summary of the text(Kupiec et al, 1995; Witbrock and Mittal, 1999)with the description generated for the graphics byour existing system.
The summary of the graphi-cal content could be simply inserted wherever it isdeemed most relevant in the text summary.
How-ever, such an approach would overlook the relation-ships and interactions between the text and graphicalcontent.
The information graphics may make certainconcepts mentioned in the text more salient, and viceversa.
Unless we consider the contributions of boththe text and graphics together during the content se-lection phase, the most important information mightnot appear in the summary of the document.Instead, we must produce a summary that inte-grates the content conveyed by the text and graphics.We contend that this integration must occur at the se-mantic level if it is to take into account the influenceof the graphic?s content on the salience of conceptsin the text and vice versa.
Our tack is to first builda single semantic model of the concepts expressedin both the article text and information graphics, andthen use this model as the basis for generating anabstractive summary of the multimodal document.57Drawing from a model of the semantic content of thedocument, we select as many or as few concepts aswe wish, at any level of detail, to produce summariesof arbitrary length.
This will permit the user to re-quest a quick overview in order to decide whether toread the original document, or a more comprehen-sive synopsis to obtain the most important contentwithout having to read the entire article.5.1 Semantic Modeling of MultimodalDocumentsContent gathered from the article text by a seman-tic parser and from the information graphics byour graph understanding system is combined intoa single semantic model based on typed, struc-tured objects organized under a foundational ontol-ogy (McDonald, 2000a).
For the semantic pars-ing of text, we use Sparser (McDonald, 1992), abottom-up, phrase-structure-based chart parser, op-timized for semantic grammars and partial parsing.3Using a built-in model of core English grammarplus domain-specific grammars, Sparser extracts in-formation from the text and produces categorizedobjects as a semantic representation (McDonald,2000b).
The intended message and salient additionalpropositions identified by our system for the infor-mation graphics are decomposed and added to themodel constructed by Sparser.4Model entries contain slots for attributes in theconcept category?s ontology definition (fillable byother concepts or symbols), the original phrasingsmentioning this concept in the text (represented asparameterized synchronous TAG derivation trees),and markers recording document structure (i.e.,where in the text [including title, headings, etc.]
orgraphic the concept appeared).
Figure 4 shows someof the information contained in a small portion ofthe semantic model built for an article entitled ?WillMedtronic?s Pulse Quicken??
from the May 29,2006 edition of Businessweek magazine5, which in-cluded a line graph.
Nodes correspond to concepts3https://github.com/charlieg/Sparser4Although the framework is general enough to accommo-date any modality (e.g., images, video) given suitable seman-tic analysis tools, our prototype implementation focuses on barcharts and line graphs analyzed by SIGHT.5http://www.businessweek.com/magazine/content/06_22/b3986120.htmand edges denote relationships between concepts;dashed lines indicate links to concepts not shown inthis figure.
Nodes are labelled with the name of theconceptual category they instantiate, and a numberto distinguish between individuals.
The middle ofeach box displays the attributes of the concept, whilethe bottom portion shows some of the original textphrasings.
Angle brackets (<>) note references toother concepts, and hash marks (#) indicate a sym-bol that has not been instantiated as a concept.P1S1: "medical devicegiant Medtronic"P1S5: "Medtronic"Name: "Medtronic"Stock: "MDT"Industry: (#pacemakers,#defibrillators,#medical devices)Company1P1S4: "JoanneWuensch"P1S7: "Wuensch"FirstName: "Joanne"LastName: "Wuensch"Person1P1S4: "a 12-monthtarget of 62"Person: <Person 1>Company: <Company 1>Price: $62.00Horizon: #12_monthsTargetStockPrice1Figure 4: Detail of model for Businessweek article.5.2 Rating Content in Semantic ModelsThe model is then rated to determine which items aremost salient.
The concepts conveying the most in-formation and having the most connections to otherimportant concepts in the model are the ones thatshould be chosen for the summary.
The importanceof each concept is rated according to a measure ofinformation density (ID) involving several factors:6Saturation Level Completeness of attributes inmodel entry: a concept?s filled-in slots (f ) vs. itstotal slots (s), and the importance of the concepts(ci) filling those slots:fs ?
log(s) ?
?fi=1 ID(ci)Connectedness Number of connections (n) withother concepts (cj), and the importance of these con-nected concepts:?nj=1 ID(cj)Frequency Number of observed phrasings (e) re-alizing the concept in text of the current documentProminence in Text Prominence based on docu-ment structure (WD) and rhetorical devices (WR)Graph Salience Salience assessed by the graphunderstanding system (WG) ?
only applies to con-cepts appearing in the graphics6The first three factors are similar to the dominant slotfillers, connectivity patterns, and frequency criteria describedby Reimer and Hahn (1988).58Saturation corresponds to the completeness of theconcept in the model.
The more attribute slots thatare filled, the more we know about a particular con-cept instance.
However, this measure is highly sen-sitive to the degree of detail provided in the seman-tic grammar and ontology class definition (whethercreated by hand or automatically).
A concept havingtwo slots, both of which are filled-out, is not neces-sarily more important than a concept with only 12of its 15 slots filled.
The more important a conceptcategory is in a given domain, the more detailed itsontology class definition will likely be.
Thus, wecan assume that a concept definition having a dozenor more slots is, broadly speaking, more importantin the domain than a less well-defined concept hav-ing only one or two slots.
This insight is the basis ofa normalization factor (log(s)) used in ID.Saturation differs somewhat from repetition inthat it attempts to measure the amount of informa-tion associated with a concept, rather than simplythe number of times a concept is mentioned in thetext.
For example, a news article about a proposedlaw might mention ?Washington?
several times, butthe fact that the debate took place in Washington,D.C.
is unlikely to be an important part of the article.However, the key provisions of the bill, which mayindividually be mentioned only once, are likely moreimportant as a greater amount of detail is providedconcerning them.
Simple repetition is not necessar-ily indicative of the importance of a concept, but if alarge amount of information is provided for a givenconcept, it is safe to assume the concept is importantin the context of that document.Document structure (WD) is another importantclue in determining which elements of a text areimportant enough to include in a summary (Marcu,1997).
If a concept is featured prominently in thetitle, or appears in the first or final paragraphs, it islikely more important than a concept buried in themiddle of the document.
Importance is also affectedby certain rhetorical devices (WR) which serve tohighlight particular concepts.
Being used in an id-iom, or compared to another concept by means ofjuxtaposition suggests that a given concept may holdspecial significance.
Finally, the weights assignedby our graph understanding system for the additionalpropositions identified in the graphics are incorpo-rated into the ID of the concepts involved as WG.5.3 Selecting Content for a SummaryTo select concepts for inclusion in the summary,the model will then be passed to a discourse-awaregraph-based content selection framework (Demir etal., 2010), which selects concepts one at a timeand iteratively re-weights the remaining items soas to include related concepts and avoid redun-dancy.
This algorithm incorporates PageRank (Pageet al, 1999), but with several modifications.
In ad-dition to centrality assessment based on relation-ships between concepts, it includes apriori impor-tance nodes enabling us to incorporate concept com-pleteness, number of expressions, document struc-ture, and rhetorical devices.
More importantly froma summary generation perspective, the algorithm it-eratively picks concepts one at a time, and re-ranksthe remaining entries by increasing the weight of re-lated items and discounting redundant ones.
Thisallows us to select concepts that complement eachother while simultaneously avoiding redundancy.6 Generating an Abstractive Summary ofa Multimodal DocumentFigure 4 shows the two most important concepts(Company1 & Person1) selected from the Medtronicarticle in Section 5.1.
Following McDonald andGreenbacker (2010), we use the phrasings observedby the parser as the ?raw material?
for expressingthese selected concepts.
Reusing the original phras-ings reduces the reliance on built-in or ?canned?constructions, and allows the summary to reflect thestyle of the original text.
The derivation trees storedin the model to realize a particular concept may usedifferent syntactic constituents (e.g., noun phrases,verb phrases).
Multiple trees are often available foreach concept, and we must select particular trees thatfit together to form a complete sentence.The semantic model also contains concepts rep-resenting propositions extracted from the graphics,as well as relationships connecting these graphicalconcepts with those derived from the text, and thereare no existing phrasings in the original documentthat can be reused to convey this graphical content.However, the set of proposition types that can be ex-tracted from the graphics is finite.
To ensure that wehave realizations for every concept in our model, wecreate TAG derivation trees for each type of graphi-59cal proposition.
As long as realizations are suppliedfor every proposition that can be decomposed in themodel, our system will never be stuck with a conceptwithout the means to express it.The set of expressions is augmented by manybuilt-in realizations for common semantic relation-ships (e.g., ?is-a,?
?has-a?
), as well as expressionsinherited from other conceptual categories in the hi-erarchy.
If the observed expressions are retained asthe system analyzes multiple documents over time,making these realizations available for later use byconcepts in the same category, the variety of utter-ances we can generate is increased greatly.By using synchronous TAG trees, we know thatthe syntactic realizations of two semantically-relatedconcepts will fit together syntactically (via substitu-tion or adjunction).
However, the concepts selectedfor the summary of the Medtronic article (Com-pany1 & Person1), are not directly connected in themodel.
To produce a single summary sentence forthese two concepts, we must find a way of express-ing them together with the available phrasings.
Thiscan be accomplished by using an intermediary con-cept that connects both of the selected items in thesemantic model, in order to ?bridge the gap?
be-tween them.
In this example, a reasonable optionwould be TargetStockPrice1, one of the many con-cepts linking Company1 and Person1.
Combiningoriginal phrasings from all three concepts (via sub-stitution and adjunction operations on the underly-ing TAG trees), along with a ?built-in?
realizationinherited by the TargetStockPrice category (a sub-type of Expectation), yields this surface form:Wuensch expects a 12-month target of 62for medical device giant Medtronic.7 Related WorkResearch into providing alternative access to graph-ics has taken both verbal and non-verbal approaches.Kurze (1995) presented a verbal description of theproperties (e.g., diagram style, number of data sets,range and labels of axes) of business graphics.
Fer-res et al (2007) produced short descriptions of theinformation in graphs using template-driven genera-tion based on the graph type.
The SIGHT project(Demir et al, 2008; Elzer et al, 2011) generatedsummaries of the high-level message content con-veyed by simple bar charts.
Other modalities, likesound (Meijer, 1992; Alty and Rigas, 1998; Choiand Walker, 2010) and touch (Ina, 1996; Krufka etal., 2007), have been used to impart graphics via asubstitute medium.
Yu et al (2002) and Abu Doushet al (2010) combined haptic and aural feedback,enabling users to navigate and explore a chart.8 DiscussionThis paper presented our system for providing ac-cess to the full content of multimodal documentswith line graphs in popular media.
Such graph-ics generally have a high-level communicative goalwhich should constitute the core of a graphic?s sum-mary.
Rather than providing this summary at thepoint where the graphic is first encountered, our sys-tem identifies the most relevant paragraph in thearticle and relays the graphic?s summary at thispoint, thus increasing the presentation?s coherence.System extensions currently in development willprovide a more integrative and accessible way forvisually-impaired readers to experience multimodaldocuments.
By producing abstractive summaries ofthe entire document, we reduce the amount of timeand effort required to assimiliate the informationconveyed by such documents in popular media.Several tasks remain as future work.
The intendedmessage descriptions generated by our system needto be evaluated by both sighted and non-sighted hu-man subjects for clarity and accuracy.
We intendto test our hypothesis that graphics ought to be de-scribed alongside the most relevant part of the textby performing an experiment designed to determinethe presentation order preferred by people who areblind.
The rules developed to identify elaborativepropositions also must be validated by a corpus oruser study.
Finally, once the system is fully imple-mented, the abstractive summaries generated for en-tire multimodal documents will need to be evaluatedby both sighted and sight-impaired judges.AcknowledgmentsThis work was supported in part by the by the Na-tional Institute on Disability and Rehabilitation Re-search under grant H133G080047 and by the Na-tional Science Foundation under grant IIS-0534948.60ReferencesIyad Abu Doush, Enrico Pontelli, Tran Cao Son, DominicSimon, and Ou Ma.
2010.
Multimodal presenta-tion of two-dimensional charts: An investigation usingOpen Office XML and Microsoft Excel.
ACM Trans-actions on Accessible Computing (TACCESS), 3:8:1?8:50, November.James L. Alty and Dimitrios I. Rigas.
1998.
Communi-cating graphical information to blind users using mu-sic: the role of context.
In Proceedings of the SIGCHIConference on Human Factors in Computing Systems,CHI ?98, pages 574?581, Los Angeles, April.
ACM.Sumit Bhatia, Shibamouli Lahiri, and Prasenjit Mitra.2009.
Generating synopses for document-elementsearch.
In Proceeding of the 18th ACM Conferenceon Information and Knowledge Management, CIKM?09, pages 2003?2006, Hong Kong, November.
ACM.Sandra Carberry, Stephanie Elzer, and Seniz Demir.2006.
Information graphics: an untapped resource fordigital libraries.
In Proceedings of the 29th AnnualInternational ACM SIGIR Conference on Researchand Development in Information Retrieval, SIGIR ?06,pages 581?588, Seattle, August.
ACM.Stephen H. Choi and Bruce N. Walker.
2010.
Digitizerauditory graph: making graphs accessible to the visu-ally impaired.
In Proceedings of the 28th InternationalConference on Human Factors in Computing Systems,CHI ?10, pages 3445?3450, Atlanta, April.
ACM.Seniz Demir, Sandra Carberry, and Kathleen F. McCoy.2008.
Generating textual summaries of bar charts.In Proceedings of the 5th International Natural Lan-guage Generation Conference, INLG 2008, pages 7?15, Salt Fork, Ohio, June.
ACL.Seniz Demir, Sandra Carberry, and Kathleen F. Mc-Coy.
2010.
A discourse-aware graph-based content-selection framework.
In Proceedings of the 6th In-ternational Natural Language Generation Conference,INLG 2010, pages 17?26, Trim, Ireland, July.
ACL.Michael Elhadad and Jacques Robin.
1996.
An overviewof SURGE: a re-usable comprehensive syntactic re-alization component.
In Proceedings of the 8th In-ternational Natural Language Generation Workshop(Posters and Demonstrations), Sussex, UK, June.ACL.Stephanie Elzer, Sandra Carberry, and Ingrid Zukerman.2011.
The automated understanding of simple barcharts.
Artificial Intelligence, 175:526?555, February.Leo Ferres, Petro Verkhogliad, Gitte Lindgaard, LouisBoucher, Antoine Chretien, and Martin Lachance.2007.
Improving accessibility to statistical graphs: theiGraph-Lite system.
In Proceedings of the 9th Inter-national ACM SIGACCESS Conference on Computersand Accessibility, ASSETS ?07, pages 67?74, Tempe,October.
ACM.Charles F. Greenbacker, Sandra Carberry, and Kathleen F.McCoy.
2011.
A corpus of human-written summariesof line graphs.
In Proceedings of the EMNLP 2011Workshop on Language Generation and Evaluation,UCNLG+Eval, Edinburgh, July.
ACL.
(to appear).Satoshi Ina.
1996.
Computer graphics for the blind.
SIG-CAPH Newsletter on Computers and the PhysicallyHandicapped, pages 16?23, June.
Issue 55.Stephen E. Krufka, Kenneth E. Barner, and Tuncer CanAysal.
2007.
Visual to tactile conversion of vectorgraphics.
IEEE Transactions on Neural Systems andRehabilitation Engineering, 15(2):310?321, June.Solomon Kullback.
1968.
Information Theory andStatistics.
Dover, revised 2nd edition.Julian Kupiec, Jan Pedersen, and Francine Chen.
1995.A trainable document summarizer.
In Proceedingsof the 18th Annual International ACM SIGIR Confer-ence on Research and Development in Information Re-trieval, SIGIR ?95, pages 68?73, Seattle, July.
ACM.Martin Kurze.
1995.
Giving blind people accessto graphics (example: Business graphics).
In Pro-ceedings of the Software-Ergonomie ?95 Workshopon Nicht-visuelle graphische Benutzungsoberfla?chen(Non-visual Graphical User Interfaces), Darmstadt,Germany, February.Xiaoyong Liu and W. Bruce Croft.
2002.
Passage re-trieval based on language models.
In Proceedings ofthe eleventh international conference on Informationand knowledge management, CIKM ?02, pages 375?382.Daniel C. Marcu.
1997.
The Rhetorical Parsing, Summa-rization, and Generation of Natural Language Texts.Ph.D.
thesis, University of Toronto, December.David D. McDonald and Charles F. Greenbacker.
2010.?If you?ve heard it, you can say it?
- towards an ac-count of expressibility.
In Proceedings of the 6th In-ternational Natural Language Generation Conference,INLG 2010, pages 185?190, Trim, Ireland, July.
ACL.David D. McDonald.
1992.
An efficient chart-basedalgorithm for partial-parsing of unrestricted texts.
InProceedings of the 3rd Conference on Applied NaturalLanguage Processing, pages 193?200, Trento, March.ACL.David D. McDonald.
2000a.
Issues in the repre-sentation of real texts: the design of KRISP.
InLucja M. Iwan?ska and Stuart C. Shapiro, editors, Nat-ural Language Processing and Knowledge Represen-tation, pages 77?110.
MIT Press, Cambridge, MA.David D. McDonald.
2000b.
Partially saturated refer-ents as a source of complexity in semantic interpreta-tion.
In Proceedings of the NAACL-ANLP 2000 Work-shop on Syntactic and Semantic Complexity in Natural61Language Processing Systems, pages 51?58, Seattle,April.
ACL.Peter B.L.
Meijer.
1992.
An experimental system forauditory image representations.
IEEE Transactions onBiomedical Engineering, 39(2):112?121, February.Lawrence Page, Sergey Brin, Rajeev Motwani, and TerryWinograd.
1999.
The pagerank citation ranking:Bringing order to the web.
Technical Report 1999-66, Stanford InfoLab, November.
Previous number:SIDL-WP-1999-0120.Ulrich Reimer and Udo Hahn.
1988.
Text condensationas knowledge base abstraction.
In Proceedings of the4th Conference on Artificial Intelligence Applications,CAIA ?88, pages 338?344, San Diego, March.
IEEE.Dominic Widdows.
2003.
Orthogonal negation in vectorspaces for modelling word-meanings and documentretrieval.
In Proceedings of the 41st Annual Meetingon Association for Computational Linguistics - Volume1, ACL ?03, pages 136?143, Stroudsburg, PA, USA.Association for Computational Linguistics.Michael J. Witbrock and Vibhu O. Mittal.
1999.
Ultra-summarization: a statistical approach to generatinghighly condensed non-extractive summaries.
In Pro-ceedings of the 22nd Annual International ACM SIGIRConference on Research and Development in Informa-tion Retrieval, SIGIR ?99, pages 315?316, Berkeley,August.
ACM.Wai Yu, Douglas Reid, and Stephen Brewster.
2002.Web-based multimodal graphs for visually impairedpeople.
In Proceedings of the 1st Cambridge Work-shop on Universal Access and Assistive Technology,CWUAAT ?02, pages 97?108, Cambridge, March.Chengxiang Zhai.
2008.
Statistical Language Modelsfor Information Retrieval.
Morgan and Claypool Pub-lishers, December.62
