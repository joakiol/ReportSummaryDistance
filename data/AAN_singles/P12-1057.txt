Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 545?553,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsSpice it Up?
Mining Refinements to OnlineInstructions from User Generated ContentGregory DruckYahoo!
Researchgdruck@gmail.comBo PangYahoo!
Researchbopang42@gmail.comAbstractThere are a growing number of popular websites where users submit and review instruc-tions for completing tasks as varied as build-ing a table and baking a pie.
In addition to pro-viding their subjective evaluation, reviewersoften provide actionable refinements.
Theserefinements clarify, correct, improve, or pro-vide alternatives to the original instructions.However, identifying and reading all relevantreviews is a daunting task for a user.
In thispaper, we propose a generative model thatjointly identifies user-proposed refinements ininstruction reviews at multiple granularities,and aligns them to the appropriate steps in theoriginal instructions.
Labeled data is not read-ily available for these tasks, so we focus onthe unsupervised setting.
In experiments in therecipe domain, our model provides 90.1% F1for predicting refinements at the review level,and 77.0% F1 for predicting refinement seg-ments within reviews.1 IntroductionPeople turn to the web to seek advice on a widevariety of subjects.
An analysis of web searchqueries posed as questions revealed that ?how to?questions are the most popular (Pang and Kumar,2011).
People consult online resources to answertechnical questions like ?how to put music on myipod,?
and to find instructions for tasks like tyinga tie and cooking Thanksgiving dinner.
Not sur-prisingly, there are many Web sites dedicated toproviding instructions.
For instance, on the pop-ular DIY site instructables.com (?share what youmake?
), users post instructions for making a widevariety of objects ranging from bed frames to ?TheStirling Engine, absorb energy from candles, coffee,and more!1?
There are also sites like allrecipes.comthat are dedicated to a specific domain.
On thesecommunity-based instruction sites, instructions areposted and reviewed by users.
For instance, theaforementioned ?Stirling engine?
has received over350 reviews on instructables.com.While user-generated instructions greatly increasethe variety of instructions available online, theyare not necessarily foolproof, or appropriate for allusers.
For instance, in the case of recipes, a usermissing a certain ingredient at home might wonderwhether it can be safely omitted; a user who wantsto get a slightly different flavor might want to findout what substitutions can be used to achieve that ef-fect.
Reviews posted by other users provide a greatresource for mining such information.
In recipe re-views, users often offer their customized version ofthe recipe by describing changes they made: e.g., ?Ihalved the salt?
or ?I used honey instead of sugar.
?In addition, they may clarify portions of the instruc-tions that are too concise for a novice to follow, ordescribe changes to the cooking method that resultin a better dish.
We refer to such actionable infor-mation as a refinement.Refinements can be quite prevalent in instructionreviews.
In a random sample of recipe reviewsfrom allrecipes.com, we found that 57.8% containrefinements of the original recipe.
However, sift-ing through all reviews for refinements is a daunting1http://www.instructables.com/id/The-Sterling-Engine-absorb-energy-from-candles-c545task for a user.
Instead, we would like to automat-ically identify refinements in reviews, summarizethem, and either create an annotated version of theinstructions that reflects the collective experience ofthe community, or, more ambitiously, revise the in-structions directly.In this paper, we take first steps toward these goalsby addressing the following tasks: (1) identifying re-views that contain refinements, (2) identifying textsegments within reviews that describe refinements,and (3) aligning these refinement segments to stepsin the instructions being reviewed (Figure 1 providesan example).
Solving these tasks provides a foun-dation for downstream summarization and seman-tic analysis, and also suggests intermediate applica-tions.
For example, we can use review classifica-tion to filter or rank reviews as they are presented tofuture users, since reviews that contain refinementsare more informative than a review which only says?Great recipe, thanks for posting!
?To the best of our knowledge, no previous workhas explored this aspect of user-generated text.While review mining has been studied extensively,we differ from previous work in that instead of fo-cusing on evaluative information, we focus action-able information in the reviews.
(See Section 2 for amore detailed discussion.
)There is no existing labeled data for the tasks ofinterest, and we would like the methods we developto be easily applied in multiple domains.
Motivatedby this, we propose a generative model for solvingthese tasks jointly without labeled data.
Interest-ingly, we find that jointly modeling refinements atboth the review and segment level is beneficial.
Wecreated a new recipe data set, and manually labeleda random sample to evaluate our model and severalbaselines.
We obtain 90.1% F1 for predicting refine-ments at the review level, and 77.0% F1 for predict-ing refinement segments within reviews.2 Related WorkAt first glance, the task of identifying refinementsappears similar to subjectivity detection (see (Pangand Lee, 2008) for a survey).
However, note that anobjective sentence is not necessarily a refinement:e.g., ?I took the cake to work?
; and a subjective sen-tence can still contain a refinement: e.g., ?I reducedthe sugar and it came out perfectly.
?Our end goal is similar to review summarization.However, previous work on review summarization(Hu and Liu, 2004; Popescu and Etzioni, 2005; Titovand McDonald, 2008) in product or service domainsfocused on summarizing evaluative information ?more specifically, identifying ratable aspects (e.g.,?food?
and ?service?
for restaurants) and summariz-ing the overall sentiment polarity for each aspect.
Incontrast, we are interested in extracting a subset ofthe non-evaluative information.
Rather than ratableaspects that are common across the entire domain(e.g., ?ingredient?, ?cooking method?
), we are in-terested in actionable information that is related andspecific to the subject of the review.Note that while our end goal is to summa-rize objective information, it is still very differ-ent from standard multi-document summarization(Radev et al, 2002) of news articles.
Apart fromdifferences in the quantity and the nature of the in-put, we aim to summarize a distribution over whatshould or can be changed, rather than produce a con-sensus using different accounts of an event.
In termsof modeling approaches, in the context of extractivesummarization, Barzilay and Lee (2004) model con-tent structure (i.e., the order in which topics appear)in documents.
We also model document structure,but we do so to help identify refinement segments.We share with previous work on predicting re-view quality or helpfulness an interest in identify-ing ?informative?
text.
Early work tried to exploitthe intuition that a helpful review is one that com-ments on product details.
However, incorporatingproduct-aspect-mention count (Kim et al, 2006) orsimilarity between the review and product specifi-cation (Zhang and Varadarajan, 2006) as featuresdid not seem to improve the performance when thetask was predicting the percentage of helpfulnessvotes.
Instead of using the helpfulness votes, Liuet al (2007) manually annotated reviews with qual-ity judgements, where a best review was defined asone that contains complete and detailed comments.Our notion of informativeness differs from previ-ous work.
We do not seek reviews that contain de-tailed evaluative information; instead, we seek re-views that contain detailed actionable information.Furthermore, we are not expecting any single reviewto be comprehensive; rather, we seek to extract a546collection of refinements representing the collectivewisdom of the community.To the best of our knowledge, there is little pre-vious work on mining user-generated data for ac-tionable information.
However, there has been in-creasing interest in language grounding.
In partic-ular, recent work has studied learning to act in anexternal environment by following textual instruc-tions (Branavan et al, 2009, 2010, 2011; Vogel andJurafsky, 2010).
This line of research is complemen-tary to our work.
While we do not utilize extensivelinguistic knowledge to analyze actionable informa-tion, we view this is an interesting future direction.We propose a generative model that makes pre-dictions at both the review and review segment level.Recent work uses a discriminative model with a sim-ilar structure to perform sentence-level sentimentanalysis with review-level supervision (Ta?ckstro?mand McDonald, 2011).
However, sentiment polaritylabels at the review level are easily obtained.
In con-trast, refinement labels are not naturally available,motivating the use of unsupervised learning.
Notethat the model of Ta?ckstro?m and McDonald (2011)cannot be used in a fully unsupervised setting.3 RefinementsIn this section, we define refinements more pre-cisely.
We use recipes as our running example, butour problem formulation and models are not specificto this domain.A refinement is a piece of text containing action-able information that is not entailed by the originalinstructions, but can be used to modify or expand theoriginal instructions.
A refinement could propose analternative method or an improvement (e.g., ?I re-placed half of the shortening with butter?, ?Let theshrimp sit in 1/2 marinade for 3 hours?
), as well asprovide clarification (?definitely use THIN cut porkchops, otherwise your panko will burn before yourchops are cooked?
).Furthermore, we distinguish between a verifiedrefinement (what the user actually did) and a hy-pothetical refinement (?next time I think I will tryevaporated milk?).
In domains similar to recipes,where instructions may be carried out repeatedly,there exist refinements in both forms.
Since instruc-tions should, in principle, contain information thathas been well tested, in this work, we consider onlythe former as our target class.
In a small percent-age of reviews we observed ?failed attempts?
wherea user did not follow a certain step and regretted thediversion.
In this work, we do not consider them tobe refinements.
We refer to text that does not containrefinements as background.Finally, we note that the presence of a past tenseverb does not imply a refinement (e.g., ?Everyoneloved this dish?, ?I got many compliments?).
In fact,not all text segments that describe an action are re-finements (e.g., ?I took the cake to work?, ?I fol-lowed the instructions to a T?
).4 ModelsIn this section we describe our models.
To iden-tify refinements without labeled data, we proposea generative model of reviews (or more gener-ally documents) with latent variables.
We assumethat each review x is divided into segments, x =(x1, .
.
.
,xT ).
Each segment is a sub-sentence-leveltext span.
We assume that the segmentation is ob-served, and hence it is not modeled.
The segmenta-tion procedure we use is described in Section 5.1.While we focus on the unsupervised setting, notethat the model can also be used in a semi-supervisedsetting.
In particular, coarse (review-level) labelscan be used to guide the induction of fine-grainedlatent structure (segment labels, alignments).4.1 Identifying RefinementsWe start by directly modeling refinements at the seg-ment level.
Our first intuition is that refinement andbackground segments can often be identified by lex-ical differences.
Based on this intuition, we can ig-nore document structure and generate the segmentswith a segment-level mixture of multinomials (S-Mix).
In general we could use n multinomials torepresent refinements and m multinomials to repre-sent background text, but in this paper we simply usen=m= 1.
Therefore, unsupervised learning in S-Mix can be viewed as clustering the segments withtwo latent states.
As is standard practice in unsu-pervised learning, we subsequently map these latentstates onto the labels of interest: r and b, for refine-ment and background, respectively.
Note, however,that this model ignores potential sequential depen-547dencies among segments.
A segment following a re-finement segment in a review may be more likely tobe a refinement than background, for example.To incorporate this intuition, we could insteadgenerate reviews with a HMM (Rabiner, 1989) oversegments (S-HMM) with two latent states.
Let zibe the latent label variable for the ith segment.
Thejoint probability of a review and segment labeling isp(x, z;?)
=T?j=1p(zj |zj?1;?
)p(xj |zj ;?
), (1)where p(zj |zj?1;?)
are multinomial transition dis-tributions, allowing the model to learn that p(zj =r|zj?1 = r;?)
> p(zj = b|zj?1 = r;?)
as moti-vated above, and p(xj |zj ;?)
are multinomial emis-sion distributions.
Note that all words in a segmentare generated independently conditioned on zj .While S-HMM models sequential dependencies,note that it imposes the same transition probabili-ties on each review.
In a manually labeled randomsample of recipe reviews, we find that refinementsegments tend to be clustered together in certain re-views (?bursty?
), rather than uniformly distributedacross all reviews.
Specifically, while we estimatethat 23% of all segments are refinements, 42% ofreviews do not contain any refinements.
In reviewsthat contain a refinement, 34% of segments are re-finements.
S-HMM cannot model this phenomenon.Consequently, we extend S-HMM to include a la-tent label variable y for each review that takes val-ues yes (contains refinement) and no (does not con-tain refinement).
The extended model is a mixtureof HMMs (RS-MixHMM) where y is the mixturecomponent.p(x, y, z;?)
= p(y;?
)p(x, z|y;?)
(2)The two HMMs p(x, z | y=yes;?)
and p(x, z | y=no;?)
can learn different transition multinomialsand consequently different distributions over z fordifferent y.
On the other hand, we do not believethe textual content of the background segments in ay = yes review should be different from those ina y = no review.
Thus, the emission distributionsare shared between the two HMMs, p(xj |zj , y;?)
=p(xj |zj ;?
).Note that the definition of y imposes additionalconstraints on RS-MixHMM: 1) reviews with y=nocannot contain refinement segments, and 2) reviewswith y = yes must contain at least one refinementsegment.
We enforce constraint (1) by disallow-ing refinement segments zj = r when y = no:p(zj = r|zj?1, y = no;?)
= 0.
Therefore, withone background label, only the all background la-bel sequence has non-zero probability when y=no.Enforcing constraint (2) is more challenging, as they = yes HMM must assign zero probability whenall segments are background, but permit backgroundsegments when refinement segments are present.To enforce constraint (2), we ?rewire?
the HMMstructure for y = yes so that a path that does notgo through the refinement state r is impossible.
Wefirst expand the state representation by replacing bwith two states that encode whether or not the firstr has been encountered yet: bnot?yet encodes thatall previous states in the path have also been back-ground; bok encodes that at least one refinement statehas been encountered2.
We prohibit paths from end-ing with bnot?yet by augmenting RS-MixHMM witha special final state f , and fixing p(zT+1 = f |zT =bnot?yet, y = yes;?)
= 0.
Furthermore, to enforcethe correct semantics of each state, paths cannot startwith bok, p(z1 = bok|y = yes;?)
= 0, and transi-tions from bnot?yet to bok, bok to bnot?yet, and r tobnot?yet are prohibited.Note that RS-MixHMM also generalizes to thecase where there are multiple refinement (n>1) andbackground (m > 1) labels.
Let Zr be the set ofrefinement labels, and Zb be the set of backgroundlabels.
The transition structure is analogous to then= m= 1 case, but statements involving r are ap-plied for each z ?
Zr, and statements involving b areapplied for each z ?
Zb.
For example, the y = yesHMM contains 2|Zb| background states.In summary, the generative process of RS-MixHMM involves first selecting whether the re-view will contain a refinement.
If the answer is yes,a sequence of background segments and at least onerefinement segment are generated using the y= yesHMM.
If the answer is no, only background seg-ments are generated.
Interestingly, by enforcingconstraints (1) and (2), we break the label symme-try that necessitates mapping latent states onto labels2In this paper, the two background states share emissionmultinomials, p(xj |zj = bnot?yet;?)
= p(xj |zj = bok;?
),though this is not required.548when using S-Mix and S-HMM.
Indeed, in the ex-periments we present in Section 5.3, mapping is notnecessary for RS-MixHMM.Note that the relationship between document-level labels and segment-level labels that we modelis related to the multiple-instance setting (Dietterichet al, 1997) in the machine learning literature.
Inmultiple-instance learning (MIL), rather than havingexplicit labels at the instance (e.g., segment) level,labels are given for bags of instances (e.g., docu-ments).
In the binary case, a bag is negative onlyif all of its instances are negative.
While we sharethis problem formulation, work on MIL has mostlyfocussed on supervised learning settings, and thusit is not directly applicable to our unsupervised set-ting.
Foulds and Smyth (2011) propose a generativemodel for MIL in which the generation of the baglabel y is conditioned on the instance labels z.
As aresult of this setup, their model reduces to our S-Mixbaseline in a fully unsupervised setting.Finally, although we motivated including thereview-level latent variable y as a way to improvesegment-level prediction of z, note that predictionsof y are useful in and of themselves.
They providesome notion of review usefulness and can be used tofilter reviews for search and browsing.
They addi-tionally give us a way to measure whether a set ofinstructions is often modified or performed as speci-fied.
Finally, if we want to provide supervision, it ismuch easier to annotate whether a review contains arefinement than to annotate each segment.4.2 Alignment with the InstructionsIn addition to the review x, we also observe the set ofinstructions s being discussed.
Often a review willreference specific parts of the instructions.
We as-sume that each set of instructions is segmented intosteps, s = (s1, .
.
.
, sS).
We augment our modelwith latent alignment variables a = (a1, .
.
.
, aT ),where aj = ` denotes that the jth review segment isreferring to the `th step of s. We also define a specialNULL instruction step.
An alignment to NULL sig-nifies that the segment does not refer to a specific in-struction step.
Note that this encoding assumes thateach review segment refers to at most one instructionstep.
Alignment predictions could facilitate furtheranalysis of how refinements affect the instructions,as well as aid in summarization and visualization ofrefinements.The joint probability under the augmented model,which we refer to as RSA-MixHMM, isp(a,x, y, z|s;?)
= p(y;?
)p(a,x, z|y, s;?)
(3)p(a,x, z|y, s;?)
=T?j=1p(aj , zj |aj?1, zj?1, y, s;?)?
p(xj |aj , zj , s;?
).Note that the instructions s are assumed to be ob-served and hence are not generated by the model.RSA-MixHMM can be viewed as a mixture ofHMMs where each state encodes both a segment la-bel zj and an alignment variable aj .
Encoding analignment problem as a sequence labeling problemwas first proposed by Vogel et al (1996).
Note thatRSA-MixHMM uses a similar expanded state rep-resentation and transition structure as RS-MixHMMto encode the semantics of y.In our current model, the transition probability de-composes into the product of independent label tran-sition and alignment transition probabilitiesp(aj , zj |aj?1, zj?1, y, s;?)
=p(aj |aj?1, y, s;?)?
p(zj |zj?1, y, s;?
),and p(aj |aj?1, y, s;?)
= p(aj |y, s;?)
simply en-codes the probability that segments align to a (non-NULL) instruction step given y.
This allows themodel to learn, for example, that reviews that con-tain refinements refer to the instructions more often.Intuitively, a segment and the step it refers toshould be lexically similar.
Consequently, RSA-MixHMM generates segments using a mixture of themultinomial distribution for the segment label zj andthe (fixed) multinomial distribution3 for the step saj .In this paper, we do not model the mixture proba-bility and simply assume that all overlapping wordsare generated by the instruction step.
When aj =NULL, only the segment label multinomial is used.Finally, we disallow an alignment to a non-NULLstep if no words overlap: p(xj |aj , zj , s;?)
= 0.4.3 Inference and Parameter EstimationBecause our model is tree-structured, we canefficiently compute exact marginal distributions3Stopwords are removed from the instruction step.549over latent variables using the sum-product algo-rithm (Koller and Friedman, 2009).
Similarly, tofind maximum probability assignments, we use themax-product algorithm.At training time we observe a set of re-views and corresponding instructions, D ={(x1, s1), .
.
.
, (xN , sN )}.
The other variables, y, z,and a, are latent.
For all models, we estimate param-eters to maximize the marginal likelihood of the ob-served reviews.
For example, for RSA-MixHMM,we estimate parameters usingargmax?N?i=1log?a,z,yp(a,xi, y, z|si;?
).This problem cannot be solved analytically, so weuse the Expectation Maximization (EM) algorithm.5 Experiments5.1 DataIn this paper, we use recipes and reviews fromallrecipes.com, an active community where we es-timate that the mean number of reviews per recipe is54.2.
We randomly selected 22,437 reviews for ourdata set.
Of these, we randomly selected a subsetof 550 reviews and determined whether or not eachcontains a refinement, using the definition providedin Section 3.
In total, 318 of the 550 (57.8%) con-tain a refinement.
We then randomly selected 119 ofthe 550 and labeled the individual segments.
Of the712 segments in the selected reviews, 165 (23.2%)are refinements and 547 are background.We now define our review segmentation scheme.Most prior work on modeling latent document sub-structure uses sentence-level labels (Barzilay andLee, 2004; Ta?ckstro?m and McDonald, 2011).
Inthe recipe data, we find that sentences often con-tain both refinement and background segments: ?
[Iused a slow cooker with this recipe and] [it turnedout great!]?
Additionally, we find that sentences of-ten contain several distinct refinements: ?
[I set themon top and around the pork and] [tossed in a canof undrained french cut green beans and] [cookedeverything on high for about 3 hours].?
To make re-finements easier to identify, and to facilitate down-stream processing, we allow sub-sentence segments.Our segmentation procedure leverages a phrasestructure parser.
In this paper we use the StanfordParser4.
Based on a quick manual inspection, do-main shift and ungrammatical sentences do causea significant degradation in parsing accuracy whencompared to in-domain data.
However, this is ac-ceptable because we only use the parser for segmen-tation.
We first parse the entire review, and subse-quently iterate through the tokens, adding a segmentbreak when any of the following conditions is met:?
sentence break (determined by the parser)?
token is a coordinating conjunction (CC) withparent other than NP, PP, ADJP?
token is a comma (,) with parent other than NP,PP, ADJP?
token is a colon (:)The resulting segmentations are fixed during learn-ing.
In future work we could extend our model toadditionally identify segment boundaries.5.2 Experimental SetupWe first describe the methods we evaluate.
For com-parison, we provide results with a baseline that ran-domly guesses according to the class distribution foreach task.
We also evaluate a Review-level model:?
R-Mix: A review-level mixture of multinomi-als with two latent states.Note that this is similar to clustering at the reviewlevel, except that class priors are estimated.
R-Mixdoes not provide segment labels, though they can beobtained by labeling all segments with the reviewlabel.We also evaluate the two Segment-level modelsdescribed in Section 4.1 (with two latent states):?
S-Mix: A segment-level mixture model.?
S-HMM: A segment-level HMM (Eq.
1).These models do not provide review labels.
To ob-tain them, we assign y = yes if any segment is la-beled as a refinement, and y=no otherwise.Finally, we evaluate three versions of our model(Review + Segment and Review + Segment +4http://nlp.stanford.edu/software/lex-parser.shtml550Alignment) with one refinement segment label andone background segment label5:?
RS-MixHMM: A mixture of HMMs (Eq.
2)with constraints (1) and (2) (see Section 4).?
RS-MixMix: A variant of RS-MixHMM with-out sequential dependencies.?
RSA-MixHMM: The full model that also in-corporates alignment (Eq.
3).Segment multinomials are initialized with a smallamount of random noise to break the initial symme-try.
RSA-MixHMM segment multinomials are in-stead initialized to the RS-MixHMM solution.
Weapply add-0.01 smoothing to the emission multino-mials and add-1 smoothing to the transition multi-nomials in the M-step.
We estimate parameters with21,887 unlabeled reviews by running EM until therelative percentage decrease in the marginal likeli-hood is ?
10?4 (typically 10-20 iterations).The models are evaluated on refinement F1 andaccuracy for both review and segment predictionsusing the annotated data described in Section 5.1.For R-Mix and the segment (S-) models, we selectthe 1:1 mapping of latent states to labels that maxi-mizes F1.
For RSA-MixHMM and the RS- modelsthis was not necessary (see Section 4.1).5.3 ResultsTable 1 displays the results.
R-Mix fails to ac-curately distinguish refinement and background re-views.
The words that best discriminate the twodiscovered review classes are ?savory ingredients?
(chicken, pepper, meat, garlic, soup) and ?bak-ing/dessert ingredients?
(chocolate, cake, pie, these,flour).
In other words, reviews naturally cluster bytopics rather than whether they contain refinements.The segment models (S-) substantially outper-form R-Mix on all metrics, demonstrating the ben-efit of segment-level modeling and our segmenta-tion scheme.
However, S-HMM fails to modelthe ?burstiness?
of refinement segments (see Sec-tion 4.1).
It predicts that 76.2% of reviews con-tain refinements, and additionally that 40.9% of seg-ments contain refinements, whereas the true values5Attempts at modeling refinement and background sub-types by increasing the number of latent states failed to sub-stantially improve the results.are 57.8% and 23.2%, respectively.
As a result, thesemodels provide high recall but low precision.In comparison, our models, which model the re-view labels6 y, yield more accurate refinement pre-dictions.
They provide statistically significant im-provements in review and segment F1, as well asaccuracy, over the baseline models.
RS-MixHMMpredicts that 62.9% of reviews contain refinementsand 28.2% of segments contain refinements, valuesthat are much closer to the ground truth.
The re-finement emission distributions for S-HMM and RS-MixHMM are fairly similar, but the probabilities ofseveral key terms like added, used, and instead arehigher with RS-MixHMM.The review F1 results demonstrate that our mod-els are able to very accurately distinguish refinementreviews from background reviews.
As motivated inSection 4.1, there are several applications that canbenefit from review-level predictions directly.
Addi-tionally, note that review labeling is not a trivial task.We trained a supervised logistic regression modelwith bag-of-words and length features (for both thenumber of segments and the number of words) using10-fold cross validation on the labeled dataset.
Thissupervised model yields mean review F1 of 78.4,11.7 F1 points below the best unsupervised result7.Augmenting RS-MixMix with sequential depen-dencies, yielding RS-MixHMM, provides a mod-erate (though not statistically significant) improve-ment in segment F1.
RS-MixHMM learns that re-finement reviews typically begin and end with back-ground segments, and that refinement segments tendto appear in succession.RSA-MixHMM additionally learns that segmentsin refinement reviews are more likely to align to non-NULL recipe steps.
It also encourages the segmentmultinomials to focus modeling effort on words thatappear only in the reviews.
As a result, in addition toyielding alignments, RSA-MixHMM provides smallimprovements over RS-MixHMM (though they arenot statistically significant).6We note that enforcing the constraint that a refinement re-view must contain at least one refinement segment using themethod in Section 4.1 provides a statistically significant signif-icant improvement in review F1 of 4.0 for RS-MixHMM.7Note that we do not consider this performance to be theupper-bound of supervised approaches; clearly, supervised ap-proaches could benefit from additional labeled data.
However,labeled data is relatively expensive to obtain for this task.551Modelreview (57.8% refinement) segment (23.2% refinement)acc prec rec F1 acc prec rec F1random baseline 51.2?
57.8 57.8 57.8?
64.4?
23.2 23.2 23.2?R-Mix 61.5?
69.1 60.4 64.4?
55.8?
27.9 57.6 37.6?S-Mix 77.5?
72.4 98.7 83.5?
80.6?
54.7 95.2 69.5?S-HMM 79.8?
74.7 98.4 84.9?
80.3?
54.3 95.8 69.3?RS-MixMix 87.1 85.4 93.7 89.4 86.4 65.6 86.7 74.7RS-MixHMM 87.3 85.6 93.7 89.5 87.9 69.7 84.8 76.5RSA-MixHMM 88.2 87.1 93.4 90.1 88.5 71.7 83.0 77.0Table 1: Unsupervised experiments comparing models for review and segment refinement identification on the recipedata.
Bold indicates the best result, and a ?
next to an accuracy or F1 value indicates that the improvements obtainedby RS-MixMix, RS-MixHMM, and RSA-MixHMM are significant (p = 0.05 according to a bootstrap test).
[ I loved these muffins! ]
[ I used walnuts insidethe batter and ] [ used whole wheat flour onlyas well as flaxseed instead of wheat germ.
][ They turned out great! ]
[ I couldn't stop eatingthem. ]
[ I've made several batches of thesemuffins and all have been great. ]
[ I make tinyalterations each time usually. ]
[ These muffinsare great with pears as well. ]
[ I think goldenraisins are much better than regular also!
]1.
Preheat oven to 375 degrees F (190 degrees C).2.
Lightly oil 18 muffin cups, or coat with nonstickcooking spray.3.
In a medium bowl, whisk together eggs, egg whites,apple butter, oil and vanilla.4.
In a large bowl, stir together flours, sugar, cinnamon,baking powder, baking soda and salt.5.
Stir in carrots, apples and raisins.6.
Stir in apple butter mixture until just moistened.7.
Spoon the batter into the prepared muffin cups, fillingthem about 3/4 full.8.
In a small bowl, combine walnuts and wheat germ;sprinkle over the muffin tops.9.
Bake at 375 degrees F (190 degrees C) for 15 to 20minutes, or until the tops are golden and spring backwhen lightly pressed.Figure 1: Example output (best viewed in color).
Bold segments in the review (left) are those predicted to be refine-ments.
Red indicates an incorrect segment label, according to our gold labels.
Alignments to recipe steps (right) areindicated with colors and arrows.
Segments without colors and arrows align to the NULL recipe step (see Section 4.2).We provide an example alignment in Figure 1.Annotating ground truth alignments is challengingand time-consuming due to ambiguity, and we feelthat the alignments are best evaluated via a down-stream task.
Therefore, we leave thorough evalua-tion of the quality of the alignments to future work.6 Conclusion and Future WorkIn this paper, we developed unsupervised meth-ods based on generative models for mining refine-ments to online instructions from reviews.
The pro-posed models leverage lexical differences in refine-ment and background segments.
By augmenting thebase models with additional structure (review labels,alignments), we obtained more accurate predictions.However, to further improve accuracy, more lin-guistic knowledge and structure will need to be in-corporated.
The current models provide many falsepositives in the more subtle cases, when some wordsthat typically indicate a refinement are present, butthe text does not describe a refinement according tothe definition in Section 3.
Examples include hypo-thetical refinements (?next time I will substitute...?
)and discussion of the recipe without modification (?Ifound it strange to... but it worked ...?, ?I love bal-samic vinegar and herbs?, ?they baked up nicely?
).Other future directions include improving thealignment model, for example by allowing words inthe instruction step to be ?translated?
into words inthe review segment.
Though we focussed on recipes,the models we proposed are general, and could beapplied to other domains.
We also plan to considerthis task in other settings such as online forums, anddevelop methods for summarizing refinements.AcknowledgmentsWe thank Andrei Broder and the anonymous reviewersfor helpful discussions and comments.552ReferencesRegina Barzilay and Lillian Lee.
Catching the drift:Probabilistic content models, with applications togeneration and summarization.
In HLT-NAACL2004: Proceedings of the Main Conference, pages113?120, 2004.S.R.K Branavan, Harr Chen, Luke Zettlemoyer, andRegina Barzilay.
Reinforcement learning formapping instructions to actions.
In Proceedingsof the Association for Computational Linguistics(ACL), 2009.S.R.K Branavan, Luke Zettlemoyer, and ReginaBarzilay.
Reading between the lines: Learningto map high-level instructions to commands.
InProceedings of the Association for ComputationalLinguistics (ACL), 2010.S.R.K.
Branavan, David Silver, and Regina Barzilay.Learning to win by reading manuals in a monte-carlo framework.
In Proceedings of the Associa-tion for Computational Linguistics (ACL), 2011.Thomas G. Dietterich, Richard H. Lathrop, andToma?s Lozano-Pe?rez.
Solving the multiple in-stance problem with axis-parallel rectangles.
Ar-tificial Intelligence, 89(1 - 2):31 ?
71, 1997.J.
R. Foulds and P. Smyth.
Multi-instance mixturemodels and semi-supervised learning.
In SIAMInternational Conference on Data Mining, 2011.Minqing Hu and Bing Liu.
Mining and summa-rizing customer reviews.
In Proceedings of theACM SIGKDD Conference on Knowledge Dis-covery and Data Mining (KDD), pages 168?177,2004.Soo-Min Kim, Patrick Pantel, Tim Chklovski, andMarco Pennacchiotti.
Automatically assessing re-view helpfulness.
In Proceedings of the Confer-ence on Empirical Methods in Natural LanguageProcessing (EMNLP), pages 423?430, 2006.D.
Koller and N. Friedman.
Probabilistic GraphicalModels: Principles and Techniques.
MIT Press,2009.Jingjing Liu, Yunbo Cao, Chin-Yew Lin, YalouHuang, and Ming Zhou.
Low-quality productreview detection in opinion summarization.
InProceedings of the Joint Conference on Empir-ical Methods in Natural Language Processingand Computational Natural Language Learning(EMNLP-CoNLL), pages 334?342, 2007.Bo Pang and Ravi Kumar.
Search in the lost senseof query: Question formulation in web searchqueries and its temporal changes.
In Proceedingsof the Association for Computational Linguistics(ACL), 2011.Bo Pang and Lillian Lee.
Opinion mining and sen-timent analysis.
Foundations and Trends in Infor-mation Retrieval, 2(1-2):1?135, 2008.Ana-Maria Popescu and Oren Etzioni.
Extract-ing product features and opinions from reviews.In Proceedings of the Human Language Tech-nology Conference and the Conference on Em-pirical Methods in Natural Language Processing(HLT/EMNLP), 2005.Lawrence Rabiner.
A tutorial on hidden markovmodels and selected applications in speech recog-nition.
Proceedings of the IEEE, 77(2):257?286,1989.Dragomir R. Radev, Eduard Hovy, and KathleenMcKeown.
Introduction to the special issue onsummarization.
Computational Linguistics, 28(4):399?408, 2002.
ISSN 0891-2017.Oscar Ta?ckstro?m and Ryan McDonald.
Discoveringfine-grained sentiment with latent variable struc-tured prediction models.
In Proceedings of the33rd European conference on Advances in infor-mation retrieval, ECIR?11, pages 368?374, 2011.Ivan Titov and Ryan McDonald.
A joint model oftext and aspect ratings for sentiment summariza-tion.
In Proceedings of the Association for Com-putational Linguistics (ACL), 2008.Adam Vogel and Daniel Jurafsky.
Learning to fol-low navigational directions.
In Proceedings of theAssociation for Computational Linguistics (ACL),2010.Stephan Vogel, Hermann Ney, and Christoph Till-mann.
Hmm-based word alignment in statisticaltranslation.
In Proceedings of the 16th conferenceon Computational linguistics - Volume 2, COL-ING ?96, pages 836?841, 1996.Zhu Zhang and Balaji Varadarajan.
Utility scoringof product reviews.
In Proceedings of the ACMSIGIR Conference on Information and KnowledgeManagement (CIKM), pages 51?57, 2006.553
