Japanese Case Frame Construction by Coupling the Verband its Closest Case ComponentDaisuke KawaharaGraduate School of Informatics, Kyoto UniversityYoshida-Honmachi, Sakyo-ku, Kyoto, 606-8501,Japankawahara@pine.kuee.kyoto-u.ac.jpSadao KurohashiGraduate School of Informatics, Kyoto UniversityYoshida-Honmachi, Sakyo-ku, Kyoto, 606-8501,Japankuro@pine.kuee.kyoto-u.ac.jpABSTRACTThis paper describes a method to construct a case frame dic-tionary automatically from a raw corpus.
The main prob-lem is how to handle the diversity of verb usages.
We col-lect predicate-argument examples, which are distinguishedby the verb and its closest case component in order to dealwith verb usages, from parsed results of a corpus.
Sincethese couples multiply to millions of combinations, it is dif-ficult to make a wide-coverage case frame dictionary from asmall corpus like an analyzed corpus.
We, however, use araw corpus, so that this problem can be addressed.
Further-more, we cluster and merge predicate-argument exampleswhich does not have different usages but belong to differentcase frames because of different closest case components.We also report on an experimental result of case structureanalysis using the constructed case frame dictionary.1.
INTRODUCTIONSyntactic analysis or parsing has been a main objective inNatural Language Processing.
In case of Japanese, however,syntactic analysis cannot clarify relations between words insentences because of several troublesome characteristics ofJapanese such as scrambling, omission of case components,and disappearance of case markers.
Therefore, in Japanesesentence analysis, case structure analysis is an importantissue, and a case frame dictionary is necessary for the anal-ysis.Some research institutes have constructed Japanese caseframe dictionaries manually [2, 3].
However, it is quite ex-pensive, or almost impossible to construct a wide-coveragecase frame dictionary by hand.Others have tried to construct a case frame dictionaryautomatically from analyzed corpora.
However, existingsyntactically analyzed corpora are too small to learn a dic-tionary, since case frame information consists of relationsbetween nouns and verbs, which multiplies to millions ofcombinations.
Based on such a consideration, we took theunsupervised learning strategy to Japanese case frame con-struction1.To construct a case frame dictionary from a raw corpus,we parse a raw corpus first, but parse errors are problematicin this case.
However, if we use only reliable modifier-headrelations to construct a case frame dictionary, this problemcan be addressed.
Verb sense ambiguity is rather problem-atic.
Since verbs can have different cases and case compo-nents depending on their meanings, verbs which have dif-ferent meanings should have different case frames.
To dealwith this problem, we collect predicate-argument examples,which are distinguished by the verb and its closest case com-ponent, and cluster them.
That is, examples are not distin-guished by verbs such as naru ?make, become?
and tsumu?load, accumulate?, but by couples such as tomodachi ninaru ?make a friend?, byouki ni naru ?become sick?,nimotsuwo tsumu ?load baggage?, and keiken wo tsumu ?accumulateexperience?.
Since these couples multiply to millions of com-binations, it is difficult to make a wide-coverage case framedictionary from a small corpus like an analyzed corpus.
We,however, use a raw corpus, so that this problem can be ad-dressed.
The clustering process is to merge examples whichdoes not have different usages but belong to different caseframes because of different closest case components.2.
VARIOUS METHODS FOR CASE FRAMECONSTRUCTIONWe employ the following procedure of case frame construc-tion from raw corpus (Figure 1):1.
A large raw corpus is parsed by KNP [5], and reliablemodifier-head relations are extracted from the parseresults.
We call these modifier-head relations exam-ples.2.
The extracted examples are distinguished by the verband its closest case component.
We call these dataexample patterns.3.
The example patterns are clustered based on a the-saurus.
We call the output of this process examplecase frames, which is the final result of the system.We call words which compose case components caseexamples, and a group of case examples case exam-ple group.
In Figure 1, nimotsu ?baggage?, busshi1In English, several unsupervised methods have been pro-posed[7, 1].
However, it is different from those that combi-nations of nouns and verbs must be collected in Japanese.example patternsraw corpustagging oranalysis+extractionof reliable relationsthesaurusby hand or learningI.
examples example case framesIII.
merged frameII.
co-occurrencesIV.
semantic case frameswowonigagatsumuwonimotsubusshikeikennikurumatruckhikokigajugyoinsensyuwonigawonigawotsumutsumutsumutsumutsumutsumutsumutsumunimotsukurumajugyoinbusshitruckkeikensensyunihikokiwogaga woni tsumutsumusensyu keikenjugyoin kurumatruckhikokinimotsubusshininigawowowo tsumutsumutsumunimotsubusshikeikenkurumajugyointruckhikokigasensyuwowowowowoninigaganikurumacartsumuloadtsumuloadtsumuloadtsumuloadtsumunimotsubaggagenimotsubaggagejugyoinworkerbusshisupplybusshisupplyexperiencekeikensensyuplayertruckhikokitruckairplanetsumutsumu<mind><thing><vehicle><person><person>accumulateFigure 1: Several methods for case frame construction.
?supply?, and keiken ?experience?
are case examples,and {nimotsu ?baggage?, busshi ?supply?}
(of wo casemarker in the first example case frame of tsumu ?load,accumulate?)
is a case example group.
A case com-ponent therefore consists of a case example and a casemarker (CM).Let us now discuss several methods of case frame construc-tion as shown in Figure 1.First, examples (I of Figure 1) can be used individually,but this method cannot solve the sparse data problem.
Forexample,(1) kuruma ni nimotsu wo tsumucar dat-CM baggage acc-CM load(load baggage onto the car)(2) truck ni busshi wo tsumutruck dat-CM supply acc-CM load(load supply onto the truck)even if these two examples occur in a corpus, it cannotbe judged whether the expression ?kuruma ni busshi wotsumu?
(load supply onto the car) is allowed or not.Secondly, examples can be decomposed into binomial re-lations (II of Figure 1).
These co-occurrences are utilizedby statistical parsers, and can address the sparse data prob-lem.
In this case, however, verb sense ambiguity becomes aserious problem.
For example,(3) kuruma ni nimotsu wo tsumucar dat-CM baggage acc-CM load(load baggage onto the car)(4) keiken wo tsumuexperience acc-CM accumulate(accumulate experience)from these two examples, three co-occurrences (?kuruma nitsumu?, ?nimotsu wo tsumu?, and ?keiken wo tsumu?)
areextracted.
They, however, allow the incorrect expression?kuruma ni keiken wo tsumu?
(load experience onto thecar, accumulate experience onto the car).Thirdly, examples can be simply merged into one frame(III of Figure 1).
However, information quantity of this isequivalent to that of the co-occurrences (II of Figure 1), soverb sense ambiguity becomes a problem as well.We distinguish examples by the verb and its closest casecomponent.
Our method can address the two problemsabove: verb sense ambiguity and sparse data.On the other hand, semantic markers can be used as casecomponents instead of case examples.
These we call seman-tic case frames (IV of Figure 1).
Constructing semanticcase frames by hand leads to the problem mentioned in Sec-tion 1.
Utsuro et al constructed semantic case frames froma corpus [8].
There are three main differences to our ap-proach: they use an annotated corpus, depend deeply on athesaurus, and did not resolve verb sense ambiguity.3.
COLLECTING EXAMPLESThis section explains how to collect examples shown inFigure 1.
In order to improve the quality of collected exam-ples, reliable modifier-head relations are extracted from theparsed corpus.3.1 Conditions of case componentsWhen examples are collected, case markers, case exam-ples, and case components must satisfy the following condi-tions.Conditions of case markersCase components which have the following case markers(CMs) are collected: ga (nominative), wo (accusative), ni(dative), to (with, that), de (optional), kara (from), yori(from), he (to), and made (to).
We also handle compoundcase markers such as ni-tsuite ?in terms of?, wo-megutte?concerning?, and others.In addition to these cases, we introduce time case marker.Case components which belong to the class <time>(see be-low) and contain a ni, kara, or made CM are merged intotime CM.
This is because it is important whether a verbdeeply relates to time or not, but not to distinguish betweensurface CMs.Generalization of case examplesCase examples which have definite meanings are general-ized.
We introduce the following three classes, and use theseclasses instead of words as case examples.<time>?
nouns which mean timee.g.
asa ?morning?, haru ?spring?,rainen ?next year??
case examples which contain a unit of timee.g.
1999nen ?year?, 12gatsu ?month?,9ji ?o?clock??
words which are followed by the suffix mae ?before?,tyu ?during?, or go ?after?
and do not have the semanticmarker <place> on the thesauruse.g.
kaku mae ?before ?
?
?
write?,kaigi go ?after the meeting?<quantity>?
numeralse.g.
ichi ?one?, ni ?two?, juu ?ten??
numerals followed by a numeral classifier2 such as tsu,ko, and nin.They are expressed with pairs of the class <quan-tity> and a numeral classifier: <quantity>tsu, <quan-tity>ko, and <quantity>nin.e.g.
1tsu ?
<quantity>tsu2ko ?
<quantity>ko<clause>?
quotations (??
?
?
to?
?that ?
?
?
?)
and expressions whichfunction as quotations (??
?
?
koto wo?
?that ?
?
?
?).e.g.
kaku to ?that ?
?
?
write?,kaita koto wo ?that ?
?
?
wrote?Exclusion of ambiguous case componentsWe do not use the following case components:?
Since case components which contain topic markers(TMs) and clausal modifiers do not have surface casemarkers, we do not use them.
For example,sono giin wa ?
?
?
wo teian-shita.the assemblyman TM acc-CM proposedwa is a topic marker and giin wa ?assemblyman TM?depends on teian-shita ?proposed?, but there is no casemarker for giin ?assemblyman?
in relation to teian-shita ?proposed?.?
?
?
wo teian-shiteiru giin ga ?
?
?acc-CM proposing assemblyman??
?
?
wo teian-shiteiru?
is a clausal modifier and teian-shiteiru ?proposing?
depends on giin ?assemblyman?,but there is no case marker for giin ?assemblyman?
inrelation to teian-shiteiru ?proposing?.?
Case components which contain a ni or de case markerare sometimes used adverbially.
Since they have theoptional relation to their verbs, we do not use them.e.g.
tame ni ?because of?,mujouken ni ?unconditionally?,ue de ?in addition to?For example,30nichi ni souri daijin ga30th on prime minister nom-CMsono 2nin nithose two people dat-CMsyou wo okuttaaward acc-CM gave2Most nouns must take a numeral classifier when they arequantified in Japanese.
An English equivalent to it is ?piece?.
(On 30th the prime minister gave awards to those two peo-ple.
)from this sentence, the following example is acquired.<time>:time-CM daijin:gaminister:nom-CM<quantity>nin:ni syou:wo okurupeople:dat-CM award acc-CM give3.2 Conditions of verbsWe collect examples not only for verbs, but also for adjec-tives and noun+copulas3 .
However, when a verb is followedby a causative auxiliary or a passive auxiliary, we do notcollect examples, since the case pattern is changed.3.3 Extraction of reliable examplesWhen examples are extracted from automatically parsedresults, the problem is that the parsed results inevitablycontain errors.
Then, to decrease influences of such errors,we discard modifier-head relations whose parse accuraciesare low and use only reliable relations.KNP employs the following heuristic rules to determine ahead of a modifier:HR1 KNP narrows the scope of a head by finding a clearboundary of clauses in a sentence.
When there is onlyone candidate verb in the scope, KNP determines thisverb as the head of the modifier.HR2 Among the candidate verbs, verbs which rarely takecase components are excluded.HR3 KNP determines the head according to the preference:a modifier which is not followed by a comma dependson the nearest candidate, and a modifier with a commadepends on the second nearest candidate.Our approach trusts HR1 but not HR2 and HR3.
That is,modifier-head relations which are decided in HR1 (there isonly one candidate of the head in the scope) are extractedas examples, but relations which HR2 and HR3 are appliedto are not extracted.
The following examples illustrate theapplication of these rules.
(5) kare wa kai-tai hon wohe TM want to buy book acc-CMtakusan mitsuketa node,a lot found becauseTokyo he okutta.Tokyo to sent(Because he found a lot of books which he wants to buy, hesent them to Tokyo.
)In this example, an example which can be extracted withoutambiguity is ?Tokyo he okutta?
?sent ?
to Tokyo?
at the endof the sentence.
In addition, since node ?because?
is analyzedas a clear boundary of clauses, the head candidate of honwo ?book acc-CM?
is only mitsuketa ?find?, and this is alsoextracted.Verbs excluded from head candidates by HR2 possiblybecome heads, so we do not use the examples which HR2 isapplied to.
For example, when there is a strong verb right3In this paper, we use ?verb?
instead of ?verb/adjective ornoun+copula?
for simplicity.after an adjective, this adjective tends not to be a head of acase component, so it is excluded from head candidates.
(6) Hi no mawari ga hayakufire of spread nom-CM rapidlysukuidase-nakatta.could not save(The fire spread rapidly, so ?1could not save ?2.
)In this example, the correct head of mawari ga ?spread?
ishayaku ?rapidly?.
However, since hayaku ?rapidly?
is ex-cluded from the head candidates, the head of mawari ga?spread?
is analyzed incorrectly.We show an example of the process HR3:(7) kare ga shitsumon nihe nom-CM question acc-CMsentou wo kitte kotaeta.lead acc-CM take answered(He took the lead to answer the question.
)In this example, head candidates of shitsumon ni ?questionacc-CM?
are kitte ?take?
and kotaeta ?answered?.
Accordingto the preference ?modify the nearer head?, KNP incorrectlydecides the head is kitte ?take?.
Like this example, whenthere are many head candidates, the decided head is notreliable, so we do not use examples in this case.We extracted reliable examples from Kyoto UniversityCorpus[6], that is a syntactically analyzed corpus, and eval-uated the accuracy of them.
The accuracy of all the caseexamples which have the target cases was 90.9%, and theaccuracy of the reliable examples was 97.2%.
Accordingly,this process is very effective.4.
CONSTRUCTION OF EXAMPLE CASEFRAMESAs shown in Section 2, when examples whose verbs havedifferent meanings are merged, a case frame which allows anincorrect expression is created.
So, for verbs with differentmeanings, different case frames should be acquired.In most cases, an important case component which decidesthe sense of a verb is the closest one to the verb, that is, theverb sense ambiguity can be resolved by coupling the verband its closest case component.
Accordingly, we distinguishexamples by the verb and its closest case component.
Wecall the case marker of the closest case component closestcase marker.The number of example patterns which one verb has isequal to that of the closest case components.
That is, ex-ample patterns which have almost the same meaning areindividually handled as follows:(8) jugyoin:ga kuruma:niworker:nom-CM car:dat-CMnimotsu:wo tsumubaggage:acc-CM load(9) {truck,hikoki}:ni{truck,airplane}:dat-CMbusshi :wo tsumusupply:acc-CM loadIn order to merge example patterns that have almost thesame meaning, we cluster example patterns.
The final ex-( 5 + 8 ) + ( 3 + 2 + 10 )( 3 + 5 + 8 ) + ( 3 + 2 + 10 )( )1/2 = 0.90ratio of common cases :0.911.0 0.8651083 20.91= 0.941.0 ?
(5?
3) + 0.86 ?
(5?
2)(5?
3) + (5?
2)1/2 1/21/2 1/23 tsumutsumuwowonimotsubusshinikuruma{truck  , hikoki  }jugyoin ga ni0.92 ?
0.90 = 0.83similarity betweenexample patterns := 0.920.94 ?
( (5?
3) + (5?
2)  )   + 0.91 ?
(8?
10)1/2 1/2 1/2 1/4( (5?
3) + (5?
2)  )  + (8?
10)1/2 1/2 1/2 1/4similarity betweencase example groups :loadloadbaggageworker carsupplyairplanetruckFigure 2: Example of calculating the similarity be-tween example patterns (Numerals in the lowerright of examples represent their frequencies.
)ample case frames consist of the example pattern clusters.The detail of the clustering is described in the following sec-tion.4.1 Similarity between example patternsThe clustering of example patterns is performed by usingthe similarity between example patterns.
This similarityis based on the similarities between case examples and theratio of common cases.
Figure 2 shows an example of cal-culating the similarity between example patterns.First, the similarity between two examples e1, e2is calcu-lated using the NTT thesaurus as follows:sime(e1, e2) = maxx?s1,y?s2sim(x,y)sim(x,y) =2Llx + lywhere x, y are semantic markers, and s1, s2are sets of se-mantic markers of e1, e2respectively4.
lx, ly are the depthsof x, y in the thesaurus, and the depth of their lowest (mostspecific) common node is L. If x and y are in the same nodeof the thesaurus, the similarity is 1.0, the maximum scorebased on this criterion.Next, the similarity between the two case example groupsE1, E2is the normalized sum of the similarities of case ex-amples as follows:simE(E1, E2)=Pe1?E1Pe2?E2?|e1||e2| sime(e1,e2)Pe1?E1Pe2?E2?|e1||e2|where |e1| , |e2| represent the frequencies of e1, e2respec-tively.The ratio of common cases of example patterns F1, F2is4In many cases, nouns have many semantic markers in NTTthesaurus.calculated as follows:cs =sPni=1|E1cci|+Pni=1|E2cci|Pli=1|E1c1i|+Pmi=1|E2c2i|where the cases of example pattern F1are c11, c12, ?
?
?
, c1l,the cases of example pattern F2are c21, c22, ?
?
?
, c2m, andthe common cases of F1and F2is cc1, cc2, ?
?
?
, ccn.
E1cciis the case example group of cci in F1.
E2cci, E1c1i, andE2c2iare defined in the same way.
The square root in thisequation decreases influences of the frequencies.The similarity between F1and F2is the product of theratio of common cases and the similarities between case ex-ample groups of common cases of F1and F2as follows:score = cs ?Pni=1?wi simE(E1cci, E2cci)Pni=1?wiwi =Xe1?E1cciXe2?E2ccip|e1| |e2|where wi is the weight of the similarities between case ex-ample groups.4.2 Selection of semantic markers of examplepatternsThe similarities between example patterns are deeply in-fluenced by semantic markers of the closest case compo-nents.
So, when the closest case components have semanticambiguities, a problem arises.
For example, when cluster-ing example patterns of awaseru ?join, adjust?, the pair ofexample patterns (te ?hand?, kao, ?face?
)5 is created withthe common semantic marker <part of an animal>, and (te?method?, syouten ?focus?)
is created with the common se-mantic marker <logic, meaning>.
From these two pairs, thepair (te ?hand?, kao ?face?, syouten ?focus?)
is created, though<part of an animal> is not similar to <logic, meaning> atall.To address this problem, we select one semantic marker ofthe closest case component of each example pattern in orderof the similarity between example patterns as follows:1.
In order of the similarity of a pair, (p, q), of two exam-ple patterns, we select semantic markers of the closestcase components, np, nq of p, q.
The selected semanticmarkers sp, sq maximize the similarity between np andnq .2.
The similarities of example patterns related to p, q arerecalculated.3.
These two processes are iterated while there are pairsof two example patterns, of which the similarity ishigher than a threshold.4.3 Clustering procedureThe following is the clustering procedure:1.
Elimination of example patterns which occur infre-quentlyTarget example patterns of the clustering are thosewhose closest case components occur more frequentlythan a threshold.
We set this threshold to 5.5Example patterns are represented by the closest case com-ponents.2.
Clustering of example patterns which have the sameclosest CM(a) Similarities between pairs of two example pat-terns which have the same closest CM are calcu-lated, and semantic markers of closest case com-ponents are selected.
These two processes are it-erated as mentioned in 4.2.
(b) Each example pattern pair whose similarity is higherthan some threshold is merged.3.
Clustering of all the example patternsThe example patterns which are output by 2 are clus-tered.
In this phase, it is not considered whether theclosest CMs are the same or not.
The following exam-ple patterns have almost the same meaning, but theyare not merged by 2 because of the different closestCM.
This clustering can merge these example patterns.
(10) {busshi,kamotsu}:wo{supply,cargo}:acc-CMtruck :ni tsumutruck:dat-CM load(11) {truck,hikoki}:ni{truck,airplane}:dat-CM{nimotsu,busshi}:wo tsumu{baggage,supply}:acc-CM load5.
SELECTION OF OBLIGATORY CASEMARKERSIf a CM whose frequency is lower than other CMs, it mightbe collected because of parsing errors, or has little relationto its verb.
So, we set the threshold for the CM frequencyas 2?mf, where mf means the frequency of the most foundCM.
If the frequency of a CM is less than the threshold, itis discarded.
For example, suppose the most frequent CMfor a verb is wo, 100 times, and the frequency of ni CM forthe verb is 16, ni CM is discarded (since it is less than thethreshold, 20).However, since we can say that all the verbs have ga (nom-inative) CMs, ga CMs are not discarded.
Furthermore, if anexample case frame do not have a ga CM, we supplementits ga case with semantic marker <person>.6.
CONSTRUCTED CASE FRAME DICTIO-NARYWe applied the above procedure to Mainichi NewspaperCorpus (9 years, 4,600,000 sentences).
We set the thresholdof the clustering 0.80.
The criterion for setting this thresholdis that case frames which have different case patterns ordifferent meanings should not be merged into one case frame.Table1 shows examples of constructed example case frames.From the corpus, example case frames of 71,000 verbs areconstructed; the average number of example case frames ofa verb is 1.9; the average number of case slots of a verb is1.7; the average number of example nouns in a case slot is4.3.
The clustering led a decrease in the number of examplecase frames of 47%.Table 1: Examples of the constructed case frames(*means the closest CM).verb CM case exampleskau1 ga person, passenger?buy?
wo* stock, land, dollar, ticketde shop, station, yenkau2 ga treatment, welfare, postcardwo* anger, disgust, antipathy.........yomu1 ga student, prime minister?read?
wo* book, article, news paperyomu2 ga <person>wo talk, opinion, brutalityde* news paper, book, textbookyomu3 ga <person>wo* future.........tadasu1 ga member, assemblyman?examine?
wo* opinion, intention, policyni tsuite problem, <clause>, billtadasu2 ga chairman, oneself?improve?
wo* position, form.........kokuchi1 ga doctor?inform?
ni* the said personkokuchi2 ga colleaguewo* infection, cancerni* patient, familysanseida1 ga <person>?agree?
ni* opinion, idea, argumentsanseida2 ga <person>ni* <clause>As shown in Table1, example case frames of noun+copulassuch as sanseida ?positiveness+copula (agree)?, and com-pound case markers such as ni-tsuite ?in terms of?
of tadasu?examine?
are acquired.7.
EXPERIMENTS AND DISCUSSIONSince it is hard to evaluate the dictionary statically, weuse the dictionary in case structure analysis and evaluate theanalysis result.
We used 200 sentences of Mainichi Newspa-per Corpus as a test set.
We analyzed case structures of thesentences using the method proposed by [4].
As the evalua-tion of the case structure analysis, we checked whether casesof ambiguous case components (topic markers and clausalmodifiers) are correctly detected or not.
The evaluation re-sult is presented in Table 2.
The baseline is the result byassigning a vacant case in order of ?ga?, ?wo?, and ?ni?.
Whenwe do not consider parsing errors to evaluate the case de-tection, the accuracy of our method for topic markers was96% and that for clausal modifiers was 76%.
The baselineaccuracy for topic markers was 91% and that for clausalmodifiers was 62%.
Thus we see our method is superior tothe baseline.Table 2: The accuracy of case detection.correct casedetectionincorrect casedetectionparsing errorour methodtopic marker 85 4 13clausal modifier 48 15 2baselinetopic marker 81 8 13clausal modifier 39 24 2The following are examples of analysis results6:(1) 1ookurasyo?ga wa ginko gathe Ministry of Finance TM bank nom-CM2tsumitate-teiru2ryuhokin?wo nodeposit reserve fund oftorikuzushi wo3mitomeruconsume acc-CM consent3houshin?ni?
wo1kimeta .policy acc-CM decide(The Ministry of Finance decided the policy of con-senting to consume the reserve fund which the bankshave deposited.
)(2)korera no1gyokai?wo?
wa seijitekithese industry TM politicalhatsugenryoku ga tsuyoi toiuvoice nom-CM strongtokutyo ga 1 aru .characteristic nom-CM have(These industries have the characteristic ofstrong political voice.
)Analysis errors are mainly caused by two phenomena.
Thefirst is clausal modifiers which have no case relation to themodifees such as ??
?
?
wo mitomeru houshin?
?policy of con-senting ?
?
?
?
(?
above).
The Second is verbs which take twoga ?nominative?
case markers (one is wa superficially) suchas ?gyokai wa ?
?
?
toiu tokutyo ga aru?
?industries have thecharacteristic of ?
?
?
?
(?
above).
Handling these phenomenais an area of future work.8.
CONCLUSIONWe proposed an unsupervised method to construct a caseframe dictionary by coupling the verb and its closest casecomponent.
We obtained a large case frame dictionary,which consists of 71,000 verbs.
Using this dictionary, wecan detect ambiguous case components accurately.
We planto exploit this dictionary in anaphora resolution in the fu-ture.9.
ACKNOWLEDGMENTSThe research described in this paper was supported inpart by JSPS-RFTF96P00502 (The Japan Society for thePromotion of Science, Research for the Future Program).6The underlined words with ?
are correctly analyzed, butones with ?
are not.
The detected CMs are shown after theunderlines.10.
REFERENCES[1] T. Briscoe and J. Carroll.
Automatic extraction ofsubcategorization from corpora.
In Proceedings of the5th Conference on Applied Natural LanguageProcessing, pages 356?363, 1997.
[2] S. Ikehara, M. Miyazaki, S. Shirai, A. Yokoo,H.
Nakaiwa, K. Ogura, and Y. O. Y. Hayashi, editors.Japanese Lexicon.
Iwanami Publishing, 1997.
[3] Information-Technology Promotion Agency, Japan.Japanese Verbs : A Guide to the IPA Lexicon of BasicJapanese Verbs.
1987.
[4] S. Kurohashi and M. Nagao.
A method of casestructure analysis for japanese sentences based onexamples in case frame dictionary.
In IEICETransactions on Information and Systems, volumeE77-D No.2, 1994.
[5] S. Kurohashi and M. Nagao.
A syntactic analysismethod of long japanese sentences based on thedetection of conjunctive structures.
ComputationalLinguistics, 20(4), 1994.
[6] S. Kurohashi and M. Nagao.
Building a japaneseparsed corpus while improving the parsing system.
InProceedings of The First International Conference onLanguage Resources & Evaluation, pages 719?724, 1998.
[7] C. D. Manning.
Automatic acquisition of a largesubcategorization dictionary from corpora.
InProceedings of the 31th Annual Meeting of ACL, pages235?242, 1993.
[8] T. Utsuro, T. Miyata, and Y. Matsumoto.
Maximumentropy model learning of subcategorization preference.In Proceedings of the 5th Workshop on Very LargeCorpora, pages 246?260, 1997.
