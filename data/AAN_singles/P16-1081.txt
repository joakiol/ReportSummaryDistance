Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 855?865,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsModeling Social Norms Evolution for Personalized SentimentClassificationLin Gong1, Mohammad Al Boni2, Hongning Wang11Department of Computer Science,2Department of System and Information EngineeringUniversity of Virginia, Charlottesville VA, 22904 USA{lg5bt, ma2sm, hw5x}@virginia.eduAbstractMotivated by the findings in social sci-ence that people?s opinions are diverse andvariable while together they are shaped byevolving social norms, we perform person-alized sentiment classification via sharedmodel adaptation over time.
In our pro-posed solution, a global sentiment modelis constantly updated to capture the ho-mogeneity in which users express opin-ions, while personalized models are simul-taneously adapted from the global modelto recognize the heterogeneity of opin-ions from individuals.
Global model shar-ing alleviates data sparsity issue, and in-dividualized model adaptation enables ef-ficient online model learning.
Extensiveexperimentations are performed on twolarge review collections from Amazon andYelp, and encouraging performance gainis achieved against several state-of-the-arttransfer learning and multi-task learningbased sentiment classification solutions.1 IntroductionSentiment is personal; the same sentiment can beexpressed in various ways and the same expres-sion might carry distinct polarities across differentindividuals (Wiebe et al, 2005).
Current main-stream solutions of sentiment analysis overlookthis fact by focusing on population-level models(Liu, 2012; Pang and Lee, 2008).
But the id-iosyncratic and variable ways in which individ-uals communicate their opinions make a globalsentiment classifier incompetent and consequentlylead to suboptimal opinion mining results.
For in-stance, a shared statistical classifier can hardly rec-ognize that in restaurant reviews, the word ?expen-sive?
may indicate some users?
satisfaction with arestaurant?s quality, although it is generally asso-ciated with negative attitudes.
Hence, a person-alized sentiment classification solution is requiredto achieve fine-grained understanding of individu-als?
distinctive and dynamic opinions and benefitdownstream opinion mining applications.Sparse observations of individuals?
opinionateddata (Max, 2014) prevent straightforward solu-tions from building personalized sentiment clas-sification models, such as estimating supervisedclassifiers on a per-user basis.
Semi-supervisedmethods are developed to address the data spar-sity issue.
For example, leveraging auxiliary in-formation from user-user and user-document re-lations in transductive learning (Hu et al, 2013;Tan et al, 2011).
However, only one global modelis estimated there, and the details of how individ-ual users express diverse opinions cannot be cap-tured.
More importantly, existing solutions buildstatic sentiment models on historic data; but themeans in which a user expresses his/her opinion ischanging over time.
To capture temporal dynam-ics in a user?s opinions with existing solutions, re-peated model reconstruction is unavoidable, albeitit is prohibitively expensive.
As a result, personal-ized sentiment analysis requires effective exploita-tion of users?
own opinionated data and efficientexecution of model updates across all users.To address these challenges, we propose tobuild personalized sentiment classification modelsvia shared model adaptation.
Our solution rootsin the social psychology theories about humans?dispositional tendencies (Briley et al, 2000).
Hu-mans?
behaviors are shaped by social norms, a setof socially shared ?feelings?
and ?display rules?about how one should feel and express opinions(Bars?ade and Gibson, 1998; Sherif, 1936).
In thecontext of content-based sentiment classification,we interpret social norms as global model shar-ing and adaptation across users.
Formally, we as-sume a global sentiment model serves as the ba-sis to capture self-enforcing sentimental regulari-855ties across users, and each individual user tailorsthe shared model to realize his/her personal pref-erence.
In addition, social norms also evolve overtime (Ehrlich and Levin, 2005), which leads toshifts in individuals?
behaviors.
This can againbe interpreted as model adaptation: a new globalmodel is adapted from an existing one to reflect thenewly adopted sentimental norms.
The temporalchanges in individuals?
opinions can be efficientlycaptured via online model adaptation at the levelsof both global and personalized models.Our proposed solution can also be understoodfrom the perspective of multi-task learning (Ev-geniou and Pontil, 2004; Jacob et al, 2009).
In-tuitively, personalized model adaptations can beconsidered as a set of related tasks in individualusers, which contribute to a shared global modeladaptation.
In particular, we assume the distinctways in which users express their opinions canbe characterized by a linear classifier?s parame-ters, i.e., the weights of textual features.
Personal-ized models are thus achieved via a series of lin-ear transformations over a globally shared classi-fier?s parameters (Wang et al, 2013), e.g., shiftingand scaling the weight vector.
This globally sharedclassifier itself is obtained via another set of lineartransformations over a given base classifier, whichcan be estimated from an isolated collection be-forehand and serves as a prior for shared sentimentclassification.
The shared global model adaptationmakes personalized model estimation no longerindependent, such that regularity is formed acrossindividualized learning tasks.We empirically evaluated the proposed solu-tion on two large collections of reviews, i.e.,Amazon and Yelp reviews.
Extensive experimentresults confirm its effectiveness: the proposedmethod outperformed user-independent classifica-tion methods, several state-of-the-art model adap-tion methods, and multi-task learning algorithms.2 Related WorkText-based sentiment classification forms thefoundation of sentiment analysis (Liu, 2012; Pangand Lee, 2008).
There are two typical types ofstudies in sentiment classification.
The first isclassifying input text units (such as documents,sentences and phrases) into predefined categories,e.g., positive v.s., negative (Pang et al, 2002;Gao et al, 2014) and multiple classes (Pang andLee, 2005).
Both lexicon-based and learning-based solutions have been explored.
The secondis identifying topical aspects and correspondingopinions, e.g., developing topic models to predictfine-grained aspect ratings (Titov and McDonald,2008; Wang et al, 2011).
However, all thoseworks emphasize population-level analysis, whichapplies a global model on all users and thereforefails to recognize the heterogeneity in which dif-ferent users express their diverse opinions.Our proposed solution is closely related tomulti-task learning, which exploits the relatednessamong multiple learning tasks to benefit each sin-gle task.
Tasks can be related in various ways.A typical assumption is that all learnt models areclose to each other in some matrix norms (Evge-niou and Pontil, 2004; Jacob et al, 2009).
This hasbeen empirically proved to be effective for captur-ing preferences of individual users (Evgeniou etal., 2007).
Task relatedness has also been imposedvia constructing a common underlying representa-tion across different tasks (Argyriou et al, 2008;Evgeniou and Pontil, 2007).
Our solution postu-lates task relatedness via a two-level model adap-tation procedure.
The global model adaptation ac-counts for the homogeneity and shared dynamicsin users?
opinions; and personalized model adap-tation realizes heterogeneity in individual users.The idea of model adaptation has been exten-sively explored in the context of transfer learn-ing (Pan and Yang, 2010), which focuses on ap-plying knowledge gained while solving one prob-lem to different but related problems.
In opinionmining community, transfer learning is mostly ex-ploited for domain adaptation, e.g., adapting sen-timent classifiers trained on book reviews to DVDreviews (Blitzer et al, 2006; Pan et al, 2010).Personalized model adaptation has also been stud-ied in literature.
The idea of linear transformationbased model adaptation is introduced in (Wang etal., 2013) for personalized web search.
Al Boniet al applied a similar idea to achieve personal-ized sentiment classification (Al Boni et al, 2015).
(Li et al, 2010) developed an online learning al-gorithm to continue training personalized classi-fiers based on a given global model.
However, allof these aforementioned solutions perform modeladaptation from a fixed global model, such thatthe learning of personalized models is independentfrom each other.
Data sparsity again is the ma-jor bottleneck for such solutions.
Our solution as-sociates individual model adaptation via a sharedglobal model adaptation, which leverages obser-vations across users and thus reduces preferencelearning complexity.8563 MethodologyWe propose to build personalized sentiment classi-fiers via shared model adaptation for both a globalsentiment model and individualized models.
Oursolution roots in the social psychology theoriesabout humans?
dispositional tendencies, e.g., so-cial norms and the evolution of social norms overtime.
In the following discussions, we will firstbriefly discuss the social theories that motivate ourresearch, and then carefully describe the modelassumptions and technical details about the pro-posed personalized model adaptation solution.3.1 The Evolution of Social NormsSocial norms create pressures to establish so-cialization of affective experience and expression(Shott, 1979).
Within the limit set by social normsand internal stimuli, individuals construct theirsentiment, which is not automatic, physiologicalconsequences but complex consequences of learn-ing, interpretation, and social influence.
This mo-tivates us to build a global sentiment classificationmodel to capture the shared basis on which usersexpress their opinions.
For example, the phrase?a waste of money?
generally represents negativeopinions across all users; and it is very unlikelythat anybody would use it in a positive sense.
Onthe other hand, members of some segments of asocial structure tend to feel certain emotions moreoften or more intensely than members of othersegments (Hochschild, 1975).
Personalized modeladaptation from the shared global model becomesnecessary to capture the variability in affective ex-pressions across users.
For example, the word?expensive?
may indicate some users?
satisfactionwith their received service.Studies in social psychology also suggest thatsocial norms shift and spread through infectioustransfer mediated by webs of contact and influ-ence over time (Ostrom, 2014; Ehrlich and Levin,2005).
Members inside a social structure influ-ence the other members; confirmation of shiftedbeliefs leads to the development and evolution ofsocial norms, which in turn regulate the shared so-cial behaviors as a whole over time.
The evolv-ing nature of social norms urges us to take a dy-namic view of the shared global sentiment model:instead of treating it as fixed, we further assumethis model is also adapted from a predefined one,which serves as prior for sentiment classification.All individual users are coupled and contribute tothis shared global model adaptation.
This two-level model adaptation assumption leads us to theproposed multi-task learning solution, which willbe carefully discussed in the next section.3.2 Shared Linear Model AdaptationIn this paper, we focus on linear models for per-sonalized sentiment classification due to their em-pirically superior performance in text-based sen-timent analysis (Pang et al, 2002; Pang and Lee,2005).
We assume the diverse ways in which usersexpress their opinions can be characterized by dif-ferent settings of a linear model?s parameters, i.e.,the weights of textual features.Formally, we denote a given set of opinion-ated text documents from user u as Du={(xud, yud)}|Du|d=1, where each document xudis rep-resented by a V -dimensional vector of textual fea-tures and yudis the corresponding sentiment label.The task of personalized sentiment classificationis to estimate a personalized model y = fu(x)for user u, such that fu(x) best captures u?s opin-ions in his/her generated text content.
Insteadof assuming fu(x) is solely estimated from useru?s own opinionated data, which is prone to over-fitting, we assume it is derived from a globallyshared sentiment model fs(x) via model adapta-tion (Al Boni et al, 2015; Wang et al, 2013), i.e.,shifting and scaling fs(x)?s parameters for eachindividual user.
To simplify the following discus-sions, we will focus on binary classification, i.e.,yd?
{0, 1}, and use the logistic regression as ourreference model.
But the developed techniques aregeneral and can be easily extended to multi-classclassification and generalized linear models.We only consider scaling and shifting opera-tions, given rotation requires to estimate muchmore free parameters (i.e., O(V2) v.s., O(V ))but contributes less in final classification perfor-mance (Al Boni et al, 2015).
We further assumethe adaptations can be performed in a group-wisemanner (Wang et al, 2013): features in the samegroup will be updated synchronously by enforc-ing the same shifting and scaling operations.
Thisenables the observations from seen features to bepropagated to unseen features in the same groupduring adaptation.
Various feature grouping meth-ods have been explored in (Wang et al, 2013).Specifically, we define g(i) ?
j as a fea-ture grouping method, which maps feature i in{1, 2, .
.
.
, V } to feature group j in {1, 2, .
.
.
,K}.A personalized model adaptation matrix can thenbe represented as a 2K-dimensional vector Au=(au1, au2, .
.
.
, auK, bu1, bu2, .
.
.
, buK), where aukand buk857represent the scaling and shifting operations infeature group k for user u accordingly.
Pluggingthis group-wise model adaptation into the logisticfunction, we can get a personalized logistic regres-sion model Pu(yd= 1|xd) for user u as follows,Pu(yd= 1|xd) =11 + e?
?Kk=1?g(i)=k(aukwsi+buk)xi(1)where wsis the feature weight vector in the globalmodel fs(x).
As a result, personalized modeladaptation boils down to identifying the optimalmodel transformation operation Aufor each userbased on wsand Du.In (Al Boni et al, 2015; Wang et al, 2013),fs(x) is assumed to be given and fixed.
Itleads to isolated estimation of personalized mod-els.
Based on the social norms evolution theory,fs(x) should also be dynamic and ever-changingto reflect shifted social norms.
Hence, we im-pose another layer of model adaptation on top ofthe shared global sentiment model fs(x), by as-suming itself is also adapted from a predefinedbase sentiment model.
Denote this base classi-fier as f0(x), which is parameterized by a featureweight vector w0and serves as a prior for senti-ment classification.
Then wscan be derived viathe same aforementioned model adaptation proce-dure: ws= Asw?0, where w?0is an augmented vec-tor of w0, i.e., w?0= (w0, 1), to facilitate shiftingoperations, and Asis the adaptation matrix for theshared global model.
We should note Ascan takea different configuration (i.e., feature groupings)from individual users?
adaptation matrices.Putting these two levels of model adaptationtogether, a personalized sentiment classifier isachieved via,wu= AuAsw?0(2)which can then be plugged into Eq (1) for person-alized sentiment classification.We name this resulting algorithm as Mutli-Task Linear Model Adaptation, or MT-LinAdaptin short.
The benefits of shared model adapta-tion defined in Eq (2) are three folds.
First, thehomogeneity in which users express their diverseopinions are captured in the jointly estimated sen-timent model fs(x) across users.
Second, thelearnt individual models are coupled together toreduce preference learning complexity, i.e., theycollaboratively serve to reduce the models?
overallprediction error.
Third, non-linearity is achievedvia the two-level model adaptation, which intro-duces more flexibility in capturing heterogeneityin different users?
opinions.
In-depth discussionsof those unique benefits will be provided when weintroduce the detailed model estimation methods.3.3 Joint Model EstimationThe ideal personalized model adaptation should beable to adjust the individualized classifier fu(x) tominimize misclassification rate on each user?s his-torical data in Du.
In the meanwhile, the sharedsentiment model fs(x) should serve as the basisfor each individual user to reduce the predictionerror, i.e., capture the homogeneity.
These two re-lated objectives can be unified under a joint opti-mization problem.In logistic regression, the optimal adaptationmatrix Aufor an individual user u, together withAscan be retrieved by a maximum likelihood es-timator (i.e., minimizing logistic loss on a user?sown opinionated data).
The log-likelihood func-tion in each individual user is defined as,L(Au, As) =|Du|?d=1[ydlogPu(yd= 1|xd) (3)+ (1?
yd) logPu(yd= 0|xd)]To avoid overfitting, we penalize the transforma-tions which increase the discrepancy between theadapted model and its source model (i.e., betweenwuand ws, and between wsand w0) via a L2 reg-ularization term,R(A) =?12||a?
1||2+?22||b||2(4)and it enforces scaling to be close to one and shift-ing to be close to zero.By defining a new model adaptation matrix?A ={Au1, Au2, .
.
.
, AuN, As} to include all unknownmodel adaptation parameters for individual usersand shared global model, we can formalize thejoint optimization problem in MT-LinAdapt as,maxL(?A)=N?i=1[L(Aui)?R(Aui)]?R(As) (5)which can be efficiently solved by a gradient-based optimizer, such as quasi-Newton method(Zhu et al, 1997).Direct optimization over?A requires synchro-nization among all the users.
But in practice, userswill generate their opinionated data with differ-ent paces, such that we have to postpone modeladaptation until all the users have at least one ob-servation to update their own adaptation matrix.858This delayed model update is at high risk of miss-ing track of active users?
recent opinion changes,but timely prediction of users?
sentiment is alwayspreferred.
To monitor users?
sentiment in realtime,we can also estimate MT-LinAdapt in an asyn-chronized manner: whenever there is a new ob-servation available, we update the correspondinguser?s personalized model together with the sharedglobal model immediately.
i.e., online optimiza-tion of MT-LinAdapt.This asychronized estimation of MT-LinAdaptreveals the insight of our two-level model adapta-tion solution: the immediate observations in user uwill not only be used to update his/her own adap-tation parameters in Au, but also be utilized to up-date the shared global model, thus to influence theother users, who do not have adaptation data yet.Two types of competing force drive the adapta-tion among all the users: ws= Asw?0requirestimely update of global model across users; andwu= Auwsenforces the individual user to con-form to the newly updated global model.
This ef-fect can be better understood with the actual gra-dients used in this asychronized update.
We illus-trate the decomposed gradients for scaling opera-tion in Auand Asfrom the log-likelihood part inEq (5) on a specific adaptation instance (xud, yud):?L(Au,As)?auk=?ud?gu(i)=k(asgs(i)w0i+bsgs(i))xudi(6)?L(Au,As)?asl=?ud?gs(i)=laugu(i)w0ixudi(7)where ?ud= yud?
Pu(yud= 1|xud), and gu(?)
andgs(?)
are feature grouping functions in individualuser u and shared global model fs(x).As stated in Eq (6) and (7), the update of scalingoperation in the shared global model and individ-ual users depends on each other; the gradient withrespect to global model adaptation will be accu-mulated among all the users.
As a result, all usersare coupled together via the global model adapta-tion in MT-LinAdapt, such that model update ispropagated through users to alleviate data sparsityissue in each single user.
This achieves the effectof multi-task learning.
The same conclusion alsoapplies to the shifting operations.It is meaningful for us to compare our pro-posed MT-LinAdapt algorithm with those dis-cussed in the related work section.
Different fromthe model adaptation based personalized senti-ment classification solution proposed in (Al Boniet al, 2015), which treats the global model asfixed, MT-LinAdapt adapts the global model tocapture the evolving nature of social norms.
Asa result, in (Al Boni et al, 2015) the individual-ized model adaptations are independent from eachother; but in MT-LinAdapt, the individual learningtasks are coupled together to enable observationsharing across tasks, i.e., multi-task learning.
Ad-ditionally, as illustrated in Eq (6) and (7), nonlin-ear model adaptation is achieved in MT-LinAdaptbecause of the different feature groupings in indi-vidual users and global model.
This enables ob-servations sharing across different feature groups,while in (Al Boni et al, 2015) observations canonly be shared within the same feature group, i.e.,linear model adaptation.
Multi-task SVM intro-duced in (Evgeniou and Pontil, 2004) can be con-sidered as a special case of MT-LinAdapt.
InMulti-task SVM, only shifting operation is con-sidered in individual users and the global modelis simply estimated from the pooled observationsacross users.
Therefore, only linear model adapta-tion is achieved in Multi-task SVM and it cannotleverage prior knowledge conveyed in a predefinedsentiment model.4 ExperimentsIn this section, we perform empirical evaluationsof the proposed MT-LinAdapt model.
We verifiedthe effectiveness of different feature groupings inindividual users?
and shared global model adapta-tion by comparing our solution with several state-of-the-art transfer learning and multi-task learningsolutions for personalized sentiment classification,together with some qualitative studies to demon-strate how our model recognizes users?
distinct ex-pressions of sentiment.4.1 Experiment Setup?
Datesets.
We evaluated the proposed model ontwo large collections of review documents, i.e.,Amazon product reviews (McAuley et al, 2015)and Yelp restaurant reviews (Yelp, 2016).
Each re-view document contains a set of attributes such asauthor ID, review ID, timestamp, textual content,and an opinion rating in discrete five-star range.We applied the following pre-processing steps onboth datasets: 1) filtered duplicated reviews; 2) la-beled reviews with overall rating above 3 stars aspositive, below 3 stars as negative, and removedthe rest; 3) removed reviewers who posted morethan 1,000 reviews and those whose positive re-view ratio is more than 90% or less than 10%859(little variance in their opinions and thus easy toclassify).
Since such users can be easily capturedby the base model, the removal emphasizes com-parisons on adapted models; 4) sorted each user?sreviews in chronological order.
Then, we per-formed feature selection by taking the union oftop unigrams and bigrams ranked by Chi-squareand information gain metrics (Yang and Pedersen,1997), after removing a standard list of stopwordsand porter stemming.
The final controlled vo-cabulary consists of 5,000 and 3,071 textual fea-tures for Amazon and Yelp datasets respectively;and we adopted TF-IDF as the feature weightingscheme.
From the resulting data sets, we randomlysampled 9,760 Amazon reviewers and 11,733 Yelpreviewers for testing purpose.
There are 105,472positive reviews and 37,674 negative reviews inthe selected Amazon dataset; 108,105 positive re-views and 32,352 negative reviews in the selectedYelp dataset.?
Baselines.
We compared the performance ofMT-LinAdapt against seven different baselines,ranging from user-independent classifiers to sev-eral state-of-the-art model adaption methods andmulti-task learning algorithms.
Due to space limit,we will briefly discuss the baseline models below.Our solution requires a user-independent classi-fier as base sentiment model for adaptation.
Weestimated logistic regression models from a sepa-rated collection of reviewers outside the preservedtesting data on Amazon and Yelp datasets accord-ingly.
We also included these isolated base mod-els in our comparison and name them as Base.
Inorder to verify the necessity of personalized sen-timent models, we trained a global SVM basedon the pooled adaptation data from all testing re-viewers, and name it as Global SVM.
We also es-timated an independent SVM model for each sin-gle user only based on his/her adaptation reviews,and name it as Individual SVM.
We included aninstance-based transfer learning method (Brightonand Mellish, 2002), which considers the k-nearestneighbors of each testing review document fromthe isolated training set for personalized modeltraining.
As a result, for each testing case, we esti-mated an independent classification model, whichis denoted as ReTrain.
(Geng et al, 2012) usedL2 regularization to enforce the adapted modelsto be close to the global model.
We appliedthis method to get personalized logistic regressionmodels and refer to it as RegLR.
LinAdapt devel-oped in (Al Boni et al, 2015) also performs group-wise linear model adaptation to build personaliza-tion classifiers.
But it isolates model adaptation inindividual users.
MT-SVM is a multi-task learn-ing method, which encodes task relatedness via ashared linear kernel (Evgeniou and Pontil, 2004).?
Evaluation Settings.
We evaluated all the mod-els with both synchronized (batch) and asynchro-nized (online) model update.
We should note MT-SVM can only be tested in batch mode, becauseit is prohibitively expensive to retrain SVM re-peatedly.
In batch evaluation, we split each user?sreviews into two sets: the first 50% for adapta-tion and the rest 50% for testing.
In online eval-uation, once we get a new testing instance, wefirst evaluate the up-to-date personalized classifieragainst the ground-truth; then use the instance toupdate the personalized model.
To simulate thereal-world situation where user reviews arrive se-quentially and asynchronously, we ordered all re-views chronologically and accessed them one at atime for online model update.
In particular, we uti-lized stochastic gradient descent for this online op-timization (Kiwiel, 2001).
Because of the biasedclass distribution in both datasets, we computedF1 measure for both positive and negative class ineach user, and took macro average among users tocompare the different models?
performance.4.2 Effect of Feature GroupingIn MT-LinAdapt, different feature groupings canbe postulated in individual users?
and sharedglobal model adaptation.
Nonlinearity is intro-duced when different grouping functions are usedin these two levels of model adaptation.
Therefore,we first investigated the effect of feature groupingin MT-LinAdapt.We adopted the feature grouping method named?cross?
in (Wang et al, 2013) to cluster fea-tures into different groups.
More specifically, weevenly spilt the training collection into N non-overlapping folds, and train a single SVM modelon each fold.
Then, we create a V ?
N matrixby putting the learned weights from N folds to-gether, on which k-means clustering is applied toextract K feature groups.
We compared the batchevaluation performance of varied combinations offeature groups in MT-LinAdapt.
The experimentresults are demonstrated in Table 1; and for com-parison purpose, we also included the base classi-fier?s performance in the table.In Table 1, the two numbers in the first col-umn denote the feature group sizes in personal-ized models and global model respectively.
Andall indicates one feature per group (i.e., no fea-860Table 1: Effect of different feature groupings inMT-LinAdapt.MethodAmazon YelpPos F1 Neg F1 Pos F1 Neg F1Base 0.8092 0.4871 0.7048 0.3495400-800 0.8318 0.5047 0.8237 0.4807400-1600 0.8385 0.5257 0.8309 0.4978400-all 0.8441 0.5423 0.8345 0.5105800-800 0.8335 0.5053 0.8245 0.4818800-1600 0.8386 0.5250 0.8302 0.4962800-all 0.8443 0.5426 0.8361 0.51221600-all 0.8445 0.5424 0.8357 0.5106all-all 0.8438 0.5416 0.8361 0.5100ture grouping).
The adapted models in MT-LinAdapt achieved promising performance im-provement against the base sentiment classifier,especially on the Yelp data set.
As we increasedthe feature group size for global model, MT-LinAdapt?s performance kept improving; whilewith the same feature grouping in the sharedglobal model, a moderate size of feature groupsin individual users is more advantageous.These observations are expected.
Because theglobal model is shared across users, all their adap-tation reviews can be leveraged to adapt the globalmodel so that sparsity is no longer an issue.
Sincemore feature groups in the global model can beafforded, more accurate estimation of adaptationparameters can be achieved.
But at the individ-ual user level, data sparsity is still the bottleneckfor accurate adaptation estimation, and trade-offbetween observation sharing and estimation accu-racy has to be made.
Based on this analysis, weselected 800 and all feature groups for individualmodels and global model respectively in the fol-lowing experiments.4.3 Personalized Sentiment Classification?
Synchronized model update.
Table 2 demon-strated the classification performance of MT-LinAdapt against all baselines on both Amazonand Yelp datasets, where binomial tests on win-loss comparison over individual users were per-formed between the best algorithm and runner-upto verify the significance of performance improve-ment.
We can clearly notice that MT-LinAdaptsignificantly outperformed all baselines in nega-tive class, and it was only slightly worse thanMT-SVM on positive class.
More specifically,per-user classifier estimation clearly failed to ob-tain a usable classifier, due to the sparse obser-vations in single users.
Model-adaptation basedbaselines, i.e., RegLR and LinAdapt, slightly im-proved over the base model.
But because theadaptations across users are isolated and the basemodel is fixed, their improvement is very lim-ited.
As for negative class, MT-LinAdapt outper-formed Global SVM significantly on both date-sets.
Since negative class suffers more from thebiased prior distribution, the considerable per-formance improvement indicates effectiveness ofour proposed personalized sentiment classifica-tion solution.
As for positive class, the perfor-mance difference is not significant between MT-LinAdapt and MT-SVM on Amazon data set norbetween MT-LinAdapt and Global SVM on Yelpdata set.
By looking into detailed results, wefound that MT-LinAdapt outperformed MT-SVMon users with fewer adaptation reviews.
Further-more, though MT-SVM benefits from multi-tasklearning, it cannot leverage information from thegiven base classifier.
Considering the biased classprior in these two data sets (2.8:1 on Amazon and3.3:1 on Yelp), the improved classification per-formance on negative class from MT-LinAdapt ismore encouraging.Table 2: Classification results in batch mode.MethodAmazon YelpPos F1 Neg F1 Pos F1 Neg F1Base 0.8092 0.4871 0.7048 0.3495Global SVM 0.8352 0.5403 0.8411 0.5007Individual SVM 0.5582 0.2418 0.3515 0.3547ReTrain 0.7843 0.4263 0.7807 0.3729RegLR 0.8094 0.4896 0.7103 0.3566LinAdapt 0.8091 0.4894 0.7107 0.3575MT-SVM 0.8484 0.5367 0.8408 0.5079MT-LinAdapt 0.8441 0.5422?0.8358 0.5119??
indicates p-value<0.05 with Binomial test.?
Asynchronized model update.
In online modelestimation, classifiers can benefit from immedi-ate update, which provides a feasible solution fortimely sentiment analysis in large datasets.
Inthis setting, only two baseline models are appli-cable without model reconstruction, i.e., RegLRand LinAdapt.
To demonstrate the utility of onlineupdate in personalized sentiment models, we illus-trate the relative performance gain of these modelsover the base sentiment model in Figure 1.
The x-axis indicates the number of adaptation instancesconsumed in online update from all users, i.e., the1st review means after collecting the first reviewof each user.MT-LinAdapt converged to satisfactory perfor-mance with only a handful of observations in eachuser.
LinAdapt also quickly converged, but its per-formance was very close to the base model, sinceno observation is shared across users.
RegLRneeds the most observations to estimate satisfac-8610 2 4 6 8 10 12 14 16 18# documents-30.0%-25.0%-20.0%-15.0%-10.0%-5.0%0.0%5.0%RelativePerformanceof Pos F1(%) Amazon DatasetRegLRLinAdaptMT-LinAdapt 0 2 4 6 8 10 12 14 16 18# documents-30.0%-25.0%-20.0%-15.0%-10.0%-5.0%0.0%5.0%10.0%RelativePerformanceof Neg F1(%) Amazon DatasetRegLRLinAdaptMT-LinAdapt0 2 4 6 8 10 12 14 16 18# documents-25.0%-20.0%-15.0%-10.0%-5.0%0.0%5.0%10.0%15.0%RelativePerformanceof Pos F1(%) Yelp DatasetRegLRLinAdaptMT-LinAdapt 0 2 4 6 8 10 12 14 16 18# documents-40.0%-30.0%-20.0%-10.0%0.0%10.0%20.0%30.0%40.0%RelativePerformanceof Neg F1(%) Yelp DatasetRegLRLinAdaptMT-LinAdaptFigure 1: Relative performance gain between MT-LinAdapt and baselines on Amazon and Yelp datasets.tory personalized models.
The improvement inMT-LinAdapt demonstrates the benefit of sharedmodel adaptation, which is vital when the individ-uals?
adaptation data are not immediately availablebut timely sentiment classification is required.0 20000 40000 60000 80000 100000 120000 140000timestamp0.00.20.40.60.81.0F1 MeasureposF1negF10246810Euclidean Distance|ws -w0 ||ws -wu |Figure 2: Online model update trace on Amazon.It is meaningful to investigate how the sharedglobal model and personalized models are updatedduring online learning.
The shift in the sharedglobal model reflects changes in social norms, andthe discrepancy between the shared global modeland personalized models indicates the variancesof individuals?
opinions.
In particular, we calcu-lated Euclidean distance between global model wsand base model w0and that between individual-ized model wuand shared global model wsdur-ing online model updating.
To visualize the re-sults, we computed and plotted the average Eu-clidean distances in every 3000 observations dur-ing online learning, together with the correspond-ing variance.
To illustrate a comprehensive pictureof online model update, we also plotted the cor-responding average F1 performance for both pos-itive and negative class.
Because the Euclideandistance between wsand w0is much larger thanthat between wsand wu, we scaled ||ws?w0|| by0.02 on Amazon dataset in Figure 2.
Similar re-sults were observed on Yelp data as well; but dueto space limit, we do not include them.As we can clearly observe that the differencebetween the base model and newly adapted globalmodel kept increasing during online update.
Atthe earlier stage, it is increasing much faster thanthe later stage, and the corresponding classifica-tion performance improves more rapidly (espe-cially in negative class).
The considerably largevariance between w0and wsat the beginning in-dicates the divergence between old and new socialnorms across users.
Later on, variance decreasedand converged with more observations, which canbe understood as the formation of the new so-cial norms among users.
On the other hand, thedistance between personalized models and sharedglobal model fluctuated a lot at the beginning; withmore observations, it became stable later on.
Thisis also reflected in the range of variance: the vari-ance is much smaller in later stage than earlierstage, which indicates users comply to the newlyestablished social norms.862Table 3: Shared model adaptation for cold start on Amazon and Yelp.Amazon YelpObs.
Shared-SVM MT-SVM MT-LinAdapt Shared-SVM MT-SVM MT-LinAdaptPos F1 Neg F1 Pos F1 Neg F1 Pos F1 Neg F1 Pos F1 Neg F1 Pos F1 Neg F1 Pos F1 Neg F11st0.9004 0.7013 0.9264 0.7489 0.9122 0.7598 0.7882 0.5537 0.9040 0.7201 0.8809 0.73062nd0.9200 0.6872 0.9200 0.7319 0.8945 0.7292 0.7702 0.5266 0.8962 0.6959 0.8598 0.69683rd0.9164 0.6967 0.9164 0.7144 0.8967 0.7260 0.7868 0.5278 0.9063 0.7099 0.8708 0.70694.4 Shared Adaptation Against Cold StartCold start refers to the challenge that a statisticmodel cannot draw any inference for users be-fore sufficient observations are gathered (Scheinet al, 2002).
The shared model adaptation in MT-LinAdapt helps alleviate cold start in personalizedsentiment analysis, while individualized modeladaptation method, such as RegLR and LinAdapt,cannot achieve so.
To verify this aspect, we sep-arated both Amazon and Yelp reviewers into twosets: we randomly selected 1,000 reviewers fromthe isolated training set and exhausted all theirreviews to estimate a shared SVM model, MT-LinAdapt and MT-SVM.
Then those models weredirectly applied onto the testing reviewers for eval-uation.
Again, because it is time consuming to re-train a SVM model repeatedly, only MT-LinAdaptperformed online model update in this evaluation.We report the performance on the first three obser-vations from all testing users accordingly in Ta-ble 3.MT-LinAdapt achieved promising performanceon the first testing cases, especially on the negativeclass.
This indicates its estimated global model ismore accurate on the new testing users.
BecauseMT-SVM cannot be updated during this onlinetest, only its previously estimated global modelfrom the 1,000 training users can be applied here.As we can notice, its performance is very similarto the shared SVM model (especially on Amazondataset).
MT-LinAdapt adapts to this new collec-tion of users very quickly, so that improved per-formance against the static models at later stage isachieved.4.5 Vocabulary StabilityOne derivative motivation for personalized senti-ment analysis is to study the diverse use of vo-cabulary across individual users.
We analyzed thevariance of words?
sentiment polarities estimatedin the personalized models against the base model.Table 4 shows the most and the least variable fea-tures on both datasets.
It is interesting to find thatwords with strong sentiment polarities tend to bemore stable across users, such as ?disgust,?
?re-gret,?
and ?excel.?
This demonstrates the signTable 4: Top six words with the highest and lowestvariances of learned polarities by MT-LinAdapt.AmazonHighestcheat healthi enjoy-readastound the-wrong the-amazLowestmistak favor excelregret perfect-for greatYelpHighesttotal-worth lazi was-yummiadvis impress so-friendLowestomg veri-good hungrifrustrat disgust a-mustof conformation to social norms.
There are alsowords exhibiting high variances in sentiment po-larity, such as ?was-yummi,?
?lazi,?
and ?cheat,?which indicates the heterogeneity of users?
opin-ionated expressions.5 ConclusionsIn this work, we proposed to perform personal-ized sentiment classification based on the notionof shared model adaptation, which is motivatedby the social theories that humans?
opinions arediverse but shaped by the ever-changing socialnorms.
In the proposed MT-LinAdapt algorithm,global model sharing alleviates data sparsity issue,and individualized model adaptation captures theheterogeneity in humans?
sentiments and enablesefficient online model learning.
Extensive experi-ments on two large review collections from Ama-zon and Yelp confirmed the effectiveness of ourproposed solution.The idea of shared model adaptation is generaland can be further extended.
We currently used atwo-level model adaptation scheme.
The adapta-tion can be performed at the user group level, i.e.,three-level model adaptation.
The user groups canbe automatically identified to maximize the effec-tiveness of shared model adaptation.
In addition,this method can also be applied to domain adapta-tion, where a domain taxonomy enables a hierar-chically shared model adaptation.6 AcknowledgmentsWe thank the anonymous reviewers for their in-sightful comments.
This paper is based upon worksupported by the National Science Foundation un-der grant IIS-1553568.863References[Al Boni et al2015] Mohammad Al Boni, Keira QiZhou, Hongning Wang, and Matthew S Gerber.2015.
Model adaptation for personalized opinionanalysis.
In Proceedings of ACL.
[Argyriou et al2008] Andreas Argyriou, TheodorosEvgeniou, and Massimiliano Pontil.
2008.
Con-vex multi-task feature learning.
Machine Learning,73(3):243?272.
[Bars?ade and Gibson1998] Sigal G Bars?ade and Don-ald E Gibson.
1998.
Group emotion: A view fromtop and bottom.
Research on managing groups andteams, 1:81?102.
[Blitzer et al2006] John Blitzer, Ryan McDonald, andFernando Pereira.
2006.
Domain adaptation withstructural correspondence learning.
In Proceedingsof the 2006 EMNLP, pages 120?128.
ACL.
[Brighton and Mellish2002] Henry Brighton and ChrisMellish.
2002.
Advances in instance selection forinstance-based learning algorithms.
Data miningand knowledge discovery, 6(2):153?172.
[Briley et al2000] Donnel A Briley, Michael W Morris,and Itamar Simonson.
2000.
Reasons as carriersof culture: Dynamic versus dispositional models ofcultural influence on decision making.
Journal ofconsumer research, 27(2):157?178.
[Ehrlich and Levin2005] Paul R Ehrlich and Simon ALevin.
2005.
The evolution of norms.
PLoS Biol,3(6):e194.
[Evgeniou and Pontil2004] Theodoros Evgeniou andMassimiliano Pontil.
2004.
Regularized multi?tasklearning.
In Proceedings of the 10th ACM SIGKDD,pages 109?117.
ACM.
[Evgeniou and Pontil2007] A Evgeniou and Massimil-iano Pontil.
2007.
Multi-task feature learning.
Ad-vances in neural information processing systems,19:41.
[Evgeniou et al2007] Theodoros Evgeniou, Massimil-iano Pontil, and Olivier Toubia.
2007.
A convex op-timization approach to modeling consumer hetero-geneity in conjoint estimation.
Marketing Science,26(6):805?818.
[Gao et al2014] Wenliang Gao, Nobuhiro Kaji, NaokiYoshinaga, and Masaru Kitsuregawa.
2014.
Collec-tive sentiment classification based on user leniencyand product popularity.
?
?, 21(3):541?561.
[Geng et al2012] Bo Geng, Yichen Yang, Chao Xu,and Xian-Sheng Hua.
2012.
Ranking model adapta-tion for domain-specific search.
IEEE Transactionson Knowledge and Data Engineering, 24(4):745?758.
[Hochschild1975] Arlie Russell Hochschild.
1975.The sociology of feeling and emotion: Selected pos-sibilities.
Sociological Inquiry, 45(2-3):280?307.
[Hu et al2013] Xia Hu, Lei Tang, Jiliang Tang, andHuan Liu.
2013.
Exploiting social relations for sen-timent analysis in microblogging.
In Proceedings ofthe 6th WSDM, pages 537?546.
ACM.
[Jacob et al2009] Laurent Jacob, Jean-philippe Vert,and Francis R Bach.
2009.
Clustered multi-tasklearning: A convex formulation.
In NIPS, pages745?752.
[Kiwiel2001] Krzysztof C Kiwiel.
2001.
Convergenceand efficiency of subgradient methods for quasi-convex minimization.
Mathematical programming,90(1):1?25.
[Li et al2010] Guangxia Li, Steven CH Hoi, KuiyuChang, and Ramesh Jain.
2010.
Micro-bloggingsentiment detection by collaborative online learning.In ICDM, pages 893?898.
IEEE.
[Liu2012] Bing Liu.
2012.
Sentiment analysis andopinion mining.
Synthesis Lectures on Human Lan-guage Technologies, 5(1):1?167.
[Max2014] Woolf Max.
2014.
A statisti-cal analysis of 1.2 million amazon reviews.http://minimaxir.com/2014/06/reviewing-reviews.
[McAuley et al2015] Julian McAuley, Rahul Pandey,and Jure Leskovec.
2015.
Inferring networks ofsubstitutable and complementary products.
In Pro-ceedings of the 21th ACM SIGKDD InternationalConference on Knowledge Discovery and Data Min-ing, pages 785?794.
ACM.
[Ostrom2014] Elinor Ostrom.
2014.
Collective actionand the evolution of social norms.
Journal of Natu-ral Resources Policy Research, 6(4):235?252.
[Pan and Yang2010] Sinno Jialin Pan and Qiang Yang.2010.
A survey on transfer learning.
Knowl-edge and Data Engineering, IEEE Transactions on,22(10):1345?1359.
[Pan et al2010] Sinno Jialin Pan, Xiaochuan Ni, Jian-Tao Sun, Qiang Yang, and Zheng Chen.
2010.Cross-domain sentiment classification via spectralfeature alignment.
In Proceedings of the 19thWWW, pages 751?760.
ACM.
[Pang and Lee2005] Bo Pang and Lillian Lee.
2005.Seeing stars: Exploiting class relationships for senti-ment categorization with respect to rating scales.
InProceedings of the 43rd ACL, pages 115?124.
ACL.
[Pang and Lee2008] Bo Pang and Lillian Lee.
2008.Opinion mining and sentiment analysis.
Founda-tions and trends in information retrieval, 2(1-2):1?135.
[Pang et al2002] Bo Pang, Lillian Lee, and Shivaku-mar Vaithyanathan.
2002.
Thumbs up?
: sentimentclassification using machine learning techniques.
InProceedings of EMNLP, pages 79?86.
ACL.864[Schein et al2002] Andrew I Schein, AlexandrinPopescul, Lyle H Ungar, and David M Pennock.2002.
Methods and metrics for cold-start recom-mendations.
In Proceedings of the 25th annualinternational ACM SIGIR conference on Researchand development in information retrieval, pages253?260.
ACM.
[Sherif1936] Muzafer Sherif.
1936.
The psychology ofsocial norms.
[Shott1979] Susan Shott.
1979.
Emotion and sociallife: A symbolic interactionist analysis.
Americanjournal of Sociology, pages 1317?1334.
[Tan et al2011] Chenhao Tan, Lillian Lee, Jie Tang,Long Jiang, Ming Zhou, and Ping Li.
2011.
User-level sentiment analysis incorporating social net-works.
In Proceedings of the 17th ACM SIGKDD,pages 1397?1405.
ACM.
[Titov and McDonald2008] Ivan Titov and Ryan T Mc-Donald.
2008.
A joint model of text and aspectratings for sentiment summarization.
In ACL, vol-ume 8, pages 308?316.
Citeseer.
[Wang et al2011] Hongning Wang, Yue Lu, andChengXiang Zhai.
2011.
Latent aspect rating anal-ysis without aspect keyword supervision.
In Pro-ceedings of the 17th ACM SIGKDD, pages 618?626.ACM.
[Wang et al2013] Hongning Wang, Xiaodong He,Ming-Wei Chang, Yang Song, Ryen W White, andWei Chu.
2013.
Personalized ranking model adap-tation for web search.
In Proceedings of the 36thACM SIGIR, pages 323?332.
ACM.
[Wiebe et al2005] Janyce Wiebe, Theresa Wilson, andClaire Cardie.
2005.
Annotating expressions ofopinions and emotions in language.
Language re-sources and evaluation, 39(2-3):165?210.
[Yang and Pedersen1997] Yiming Yang and Jan O Ped-ersen.
1997.
A comparative study on feature se-lection in text categorization.
In ICML, volume 97,pages 412?420.
[Yelp2016] Yelp.
2016.
Yelp dataset chal-lenge.
https://www.yelp.com/dataset_challenge.
[Zhu et al1997] Ciyou Zhu, Richard H Byrd, PeihuangLu, and Jorge Nocedal.
1997.
Algorithm 778: L-bfgs-b: Fortran subroutines for large-scale bound-constrained optimization.
ACM Transactions onMathematical Software (TOMS), 23(4):550?560.865
