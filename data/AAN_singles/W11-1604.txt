Workshop on Monolingual Text-To-Text Generation, pages 27?33,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 27?33,Portland, Oregon, 24 June 2011. c?2011 Association for Computational LinguisticsComparing Phrase-based and Syntax-based Paraphrase GenerationSander WubbenTilburg UniversityP.O.
Box 901355000 LE TilburgThe Netherlandss.wubben@uvt.nlErwin MarsiNTNUSem Saelandsvei 7-9NO-7491 TrondheimNorwayemarsi@idi.ntnu.noAntal van den BoschTilburg UniversityP.O.
Box 901355000 LE TilburgThe Netherlandsantal.vdnbosch@uvt.nlEmiel KrahmerTilburg UniversityP.O.
Box 901355000 LE TilburgThe Netherlandse.j.krahmer@uvt.nlAbstractParaphrase generation can be regarded as ma-chine translation where source and target lan-guage are the same.
We use the Moses statisti-cal machine translation toolkit for paraphras-ing, comparing phrase-based to syntax-basedapproaches.
Data is derived from a recentlyreleased, large scale (2.1M tokens) paraphrasecorpus for Dutch.
Preliminary results indicatethat the phrase-based approach performs bet-ter in terms of NIST scores and produces para-phrases at a greater distance from the source.1 IntroductionOne of the challenging properties of natural lan-guage is that the same semantic content can typicallybe expressed by many different surface forms.
Asthe ability to deal with paraphrases holds great po-tential for improving the coverage of NLP systems,a substantial body of research addressing recogni-tion, extraction and generation of paraphrases hasemerged (Androutsopoulos and Malakasiotis, 2010;Madnani and Dorr, 2010).
Paraphrase Generationcan be regarded as a translation task in which sourceand target language are the same.
Both ParaphraseGeneration and Machine Translation (MT) are in-stances of Text-To-Text Generation, which involvestransforming one text into another, obeying certainrestrictions.
Here these restrictions are that the gen-erated text must be grammatically well-formed andsemantically/translationally equivalent to the sourcetext.
Addionally Paraphrase Generation requiresthat the output should differ from the input to a cer-tain degree.The similarity between Paraphrase Generationand MT suggests that methods and tools originallydeveloped for MT could be exploited for ParaphraseGeneration.
One popular approach ?
arguably themost successful so far ?
is Statistical Phrase-basedMachine Translation (PBMT), which learns phrasetranslation rules from aligned bilingual text corpora(Och et al, 1999; Vogel et al, 2000; Zens et al,2002; Koehn et al, 2003).
Prior work has exploredthe use of PBMT for paraphrase generation (Quirk etal., 2004; Bannard and Callison-Burch, 2005; Mad-nani et al, 2007; Callison-Burch, 2008; Zhao et al,2009; Wubben et al, 2010)However, since many researchers believe thatPBMT has reached a performance ceiling, ongo-ing research looks into more structural approachesto statistical MT (Marcu and Wong, 2002; Och andNey, 2004; Khalilov and Fonollosa, 2009).
Syntax-based MT attempts to extract translation rules interms of syntactic constituents or subtrees ratherthan arbitrary phrases, presupposing syntactic struc-tures for source, target or both languages.
Syntacticinformation might lead to better results in the areaof grammatical well-formedness, and unlike phrase-based MT that uses contiguous n-grams, syntax en-ables the modeling of long-distance translation pat-terns.While the verdict on whether or not this approachleads to any significant performance gain is stillout, a similar line of reasoning would suggest thatsyntax-based paraphrasing may offer similar advan-tages over phrase-based paraphrasing.
Consideringthe fact that the success of PBMT can partly be at-tributed to the abundance of large parallel corpora,27and that sufficiently large parallel corpora are stilllacking for paraphrase generation, using more lin-guistically motivated methods might prove benefi-cial for paraphrase generation.
At the same time,automatic syntactic analysis introduces errors in theparse trees, as no syntactic parser is perfect.
Like-wise, automatic alignment of syntactic phrases maybe prone to errors.The main contribution of this paper is a systematiccomparison between phrase-based and syntax-basedparaphrase generation using an off-the-shelf statis-tical machine translation (SMT) decoder, namelyMoses (Koehn et al, 2007) and the word-alignmenttool GIZA++ (Och and Ney, 2003).
Training dataderives from a new, large scale (2.1M tokens) para-phrase corpus for Dutch, which has been recentlyreleased.The paper is organized as follows.
Section 2 re-views the paraphrase corpus from which providestraining and test data.
Next, Section 3 describes theparaphrase generation methods and the experimen-tal setup.
Results are presented in Section 4.
InSection 5 we discuss our findings and formulate ourconclusions.2 CorpusThe main bottleneck in building SMT systems isthe need for a substantial amount of parallel alignedtext.
Likewise, exploiting SMT for paraphrasing re-quires large amounts of monolingual parallel text.However, paraphrase corpora are scarce; the situa-tion is more dire than in MT, and this has causedsome studies to focus on the automatic harvestingof paraphrase corpora.
The use of monolingual par-allel text corpora was first suggested by Barzilayand McKeown (2001), who built their corpus us-ing various alternative human-produced translationsof literary texts and then applied machine learn-ing or multi-sequence alignment for extracting para-phrases.
In a similar vein, Pang et al (2003) used acorpus of alternative English translations of Chinesenews stories in combination with a syntax-based al-gorithm that automatically builds word lattices, inwhich paraphrases can be identified.So-called comparable monolingual corpora, forinstance independently written news reports describ-ing the same event, in which some pairs of sentencesexhibit partial semantic overlap have also been in-vestigated (Shinyama et al, 2002; Barzilay and Lee,2003; Shen et al, 2006; Wubben et al, 2009)The first manually collected paraphrase corpus isthe Microsoft Research Paraphrase (MSRP) Corpus(Dolan et al, 2004), consisting of 5,801 sentencepairs, sampled from a larger corpus of news arti-cles.
However, it is rather small and contains no sub-sentential allignments.
Cohn et al (2008) developeda parallel monolingual corpus of 900 sentence pairsannotated at the word and phrase level.
However, allof these corpora are small from an SMT perspective.Recently a new large-scale paraphrase corpus forDutch, the DAESO corpus, was released.
The cor-pus contains both samples of parallel and compa-rable text in which similar sentences, phrases andwords are aligned.
One part of the corpus is manu-ally aligned, whereas another part is automaticallyaligned using a data-driven aligner trained on thefirst part.
The DAESO corpus is extensively de-scribed in (Marsi and Krahmer, 2011); the summaryhere is limited to aspects relevant to the work athand.The corpus contains the following types of text:(1) alternative translations in Dutch of three liter-ary works of fiction; (2) autocue text from televionbroadcast news as read by the news reader, and thecorresponding subtitles; (3) headlines from similarnews articles obtained from Google News Dutch;(4) press releases about the same news topic fromtwo different press agencies; (5) similar answers re-trieved from a document collection in the medicaldomain, originally created for evaluating question-answering systems.In a first step, similar sentences were automati-cally aligned, after which alignments were manu-ally corrected.
In the case of the parallel book texts,aligned sentences are (approximate) paraphrases.
Toa lesser degree, this is also true for the news head-lines.
The autocue-subtitle pairs are mostly exam-ples of sentence compression, as the subtitle tendsto be a compressed version of the read autocue text.In contrast, the press releases and the QA answers,are characterized by a great deal of one-to-manysentence alignments, as well as sentences left un-aligned, as is to be expected in comparable text.Most sentences in these types of text tend to haveonly partial overlap in meaning.28Table 1: Properties of the manually aligned corpusAutosub Books Headlines News QA Overallaligned trees 18 338 6 362 32 627 11 052 118 68 497tokens 217 959 115 893 179 629 162 361 2 230 678 072tokens/sent 11.89 18.22 5.51 14.69 18.90 9.90nodes 365 157 191 636 318 399 271 192 3734 1 150 118nodes/tree 19.91 30.12 9.76 24.54 31.64 16.79uniquely aligned trees (%) 92.93 92.49 84.57 63.61 50.00 84.10aligned nodes (%) 73.53 66.83 73.58 53.62 38.62 67.62Next, aligned sentences were tokenized andparsed with the Alpino parser for Dutch (Bouma etal., 2001).
The parser provides a relatively theory-neutral syntactic analysis which is a blend of phrasestructure analysis and dependency analysis, with abackbone of phrasal constituents and arcs labeledwith syntactic function/dependency labels.The alignments not only concern paraphrases inthe strict sense, i.e., expressions that are semanti-cally equivalent, but extend to expressions that aresemantically similar in less strict ways, for instance,where one phrase is either more specific or moregeneral than the related phrase.
For this reason,alignments are also labeled according to a limitedset of semantic similarity relations.
Since these rela-tions were not used in the current study, we will notdiscuss them further here.The corpus comprises over 2.1 million tokens,678 thousand of which are manually annotated and1,511 thousand are automatically processed.To give a more complete overview of the sizesof different corpus segments, some properties of themanually aligned corpus are listed in Table 1.
Prop-erties of the automatically aligned part are similar,except for the fact that it only contains text of thenews and QA type.3 Paraphrase generationPhrase-based MT models consider translation as amapping of small text chunks, with possible re-ordering (Och and Ney, 2004).
Operations such asinsertion, deletion and many-to-one, one-to-manyor many-to-many translation are all covered in thestructure of the phrase table.
Phrase-based modelshave been used most prominently in the past decade,as they have shown to outperform other approaches(Callison-Burch et al, 2009).One issue with the phrase-based approach is thatrecursion is not handled explicitly.
It is gener-ally acknowledged that language contains recursivestructures up to certain depths.
So-called hierarchi-cal models have introduced the inclusion of non-terminals in the mapping rules, to allow for recur-sion (Chiang et al, 2005).
However, using a genericnon-terminal X can introduce many substitutionsin translations that do not make sense.
By mak-ing the non-terminals explicit, using syntactic cat-egories such as NP s and V P s, this phenomenonis constrained, resulting in syntax-based translation.Instead of phrase translations, translation rules interms of syntactic constituents or subtrees are ex-tracted, presupposing the availability of syntacticstructures for source, target, or both languages.Incorporating syntax can guide the translationprocess and unlike phrase-based MT syntax it en-ables the modeling of long-distance translation pat-terns.
Syntax-based systems may parse the data onthe target side (string-to-tree), source side (tree-to-string), or both (tree-to-tree).In our experiments we use tree-to-tree syntax-based MT.
We also experiment with relaxing theparses by a method proposed under the label ofsyntax-augmented machine translation (SAMT), de-scribed in (Zollmann and Venugopal, 2006).
Thismethod combines any neighboring nodes and labelspreviously unlabeled nodes, removing the syntacticconstraint on the grammar1.We train all systems on the DAESO data (218,102lines of aligned sentences) and test on a held-outset consisting of manually aligned headlines that ap-1This method is implemented in the Moses package in theprogram relax-parse as option SAMT 429Table 2: Examples of output of the phrase-based and syntax-based systemsSource jongen ( 7 ) zwaargewond na aanrijding boy (7) severely-injured after crashPhrase-based 7-jarige gewond na botsing 7-year-old injured after collisionSyntax-based jongen ( 7 ) zwaar gewond na aanrijding boy (7) severely injured after crashSource jeugdwerkloosheid daalt vooral bij voldoende opleiding youth-unemployment drops especially with adequate trainingPhrase-based werkloosheid jongeren daalt , vooral bij voldoende studie unemployment youths drops, especially with sufficient studySyntax-based * jeugdwerkloosheid daalt vooral in voldoende opleiding youth-unemployment drops especially in adequate trainingSource kritiek op boetebeleid ns criticism of fining-policy nsPhrase-based * kritiek op de omstreden boetebeleid en criticism of the controversial andSyntax-based kritiek op omstreden boetebeleid nederlandse spoorwegen criticism of controversial fining-policy dutch railwaysSource weer bestuurders radboud weg again directors radboud [hospital] leavingPhrase-based * weer de weg ziekenhuis again the leaving hospitalSyntax-based alweer bestuurders ziekenhuis weg yet-again directors hospital leavingpeared in May 2006.2 We test on 773 headlines thathave three or more aligned paraphrasing referenceheadlines.
We use an SRILM (Stolcke, 2002) lan-guage model trained on the Twente news corpus3.To investigate the effect of the amount of trainingdata on results, we also train a phrase-based modelon more data by adding more aligned headlines orig-inating from data crawled in 2010 and aligned usingtf.idf scores over headline clusters and Cosine sim-ilarity as described in (Wubben et al, 2009), result-ing in an extra 612,158 aligned headlines.Evaluation is based on the assumption that a goodparaphrase is well-formed and semantically similarbut structurally different from the source sentence.We therefore score the generated paraphrases notonly by an MT metric (we use NIST scores), butalso factor in the edit distance between the inputsentence and the output sentence.
We take the 10-best generated paraphrases and select from these theone most dissimilar from the source sentence in termof Levenshtein distance on tokens.
We then weighNIST scores according to their corresponding sen-tence Levenshtein Distance, to calculate a weighted2Syntactic trees were converted to the XML format used byMoses for syntax-based MT.
A minor complication is that theword order in the tree is different from the word order in thecorresponding sentence in about half of the cases.
The technicalreason is that Alpino internally produces dependency structuresthat can be non-projective.
Conversion to a phrase structure treetherefore necessitates moving some words to a different posi-tion in the tree.
We performed a subsequent reordering of thetrees, moving terminals to make the word order match the sur-face word order.3http://www.vf.utwente.nl/?druid/TwNC/TwNC-main.htmlaverage score.
This implies that we penalize sys-tems that provide output at Levenshtein distance 0,which are essentially copies of the input, and notparaphrases.
Formally, the score is computed as fol-lows:NISTweightedLD = ?
?i=LD(1..8)(i ?Ni ?NISTi)?i=LD(1..8)(i ?Ni)where ?
is the percentage of output phrases that havea sentence Levenshtein Distance higher than 0.
In-stead of NIST scores, other MT evaluation scorescan be plugged into this formula, such as METEOR(Lavie and Agarwal, 2007) for languages for whichparaphrase data is available.4 ResultsFigure 1 shows NIST scores per Levenshtein Dis-tance.
It can be observed that overall the NIST scoredecreases as the distance to the input increases, indi-cating that more distant paraphrases are of less qual-ity.
The relaxed syntax-based approach (SAMT)performs mildly better than the standard syntax-based approach, but performs worse than the phrase-based approach.
The distribution of generated para-phrases per Levenshtein Distance is shown in Fig-ure 2.
It reveals that the Syntax-based approachestend to stay closer to the source than the phrase-based approaches.In Table 2 a few examples of output from bothPhrase- and Syntax-based systems are given.
The302 4 6 8 10246810LevenshteinDistanceNISTscorePhrasePhrase extra dataSyntaxSyntax relaxedFigure 1: NIST scores per Levenshtein distancetop two examples show sentences where the phrase-based approach scores better, and the bottom twoshow examples where the syntax-based approachscores better.
In general, we observe that thephrase-based approach is often more drastic with itschanges, as shown also in Figure 2.
The syntax-based approach is less risky, and reverts more tosingle-word substitution.The weighted NIST score for the phrase-basedapproach is 7.14 versus 6.75 for the syntax-basedapproach.
Adding extra data does not improve thephrase-based approach, as it yields a score of 6.47,but the relaxed method does improve the syntax-based approach (7.04).5 Discussion and conclusionWe have compared a phrase-based MT approachto paraphrasing with a syntax-based MT approach.The Phrase-based approach performs better in termsof NIST score weighted by edit distance of the out-put.
In general, the phrase-based MT system per-forms more edits and these edits seem to be morereliable than the edits done by the Syntax-based ap-proach.
A relaxed Syntax-based approach performsbetter, while adding more data to the Phrase-basedapproach does not yield better results.
To gain a bet-ter understanding of the quality of the output gener-ated by the different approaches, it would be desir-able to present the output of the different systems tohuman judges.
In future work, we intend to com-pare the effects of using manual word alignmentsfrom the DAESO corpus instead of the automaticalignments produced by GIZA++.
We also wish to0 2 4 6 8 100100200300LevenshteinDistanceNPhrasePhrase extra dataSyntaxSyntax relaxedFigure 2: Distribution of generated paraphrases per Lev-enshtein distancefurther explore the effect of the nature of the datathat we train on: the DAESO corpus consists of var-ious data sources from different domains.
Our aimis also to incorporate the notion of dissimilarity intothe paraphrase model, by adding dissimilarity scoresto the model.31ReferencesIon Androutsopoulos and Prodromos Malakasiotis.2010.
A survey of paraphrasing and textual entailmentmethods.
Journal of Artificial Intelligence Research,38:135?187, May.Colin Bannard and Chris Callison-Burch.
2005.
Para-phrasing with bilingual parallel corpora.
In ACL ?05:Proceedings of the 43rd Annual Meeting on Associ-ation for Computational Linguistics, pages 597?604,Morristown, NJ, USA.
Association for ComputationalLinguistics.Regina Barzilay and Lillian Lee.
2003.
Learning toparaphrase: an unsupervised approach using multiple-sequence alignment.
In NAACL ?03: Proceedings ofthe 2003 Conference of the North American Chapter ofthe Association for Computational Linguistics on Hu-man Language Technology, pages 16?23, Morristown,NJ, USA.
Association for Computational Linguistics.Regina Barzilay and Kathleen McKeown.
2001.
Extract-ing paraphrases from a parallel corpus.
In Proceedingsof Meeting of the Association for Computational Lin-guistics, pages 50?57, Toulouse, France.Gosse Bouma, Gertjan van Noord, and Robert Malouf.2001.
Alpino: Wide-coverage computational analy-sis of Dutch.
In Walter Daelemans, Khalil Sima?an,Jorn Veenstra, and Jakub Zavre, editors, Computa-tional Linguistics in the Netherlands 2000., pages 45?59.
Rodopi, Amsterdam, New York.Chris Callison-Burch, Philipp Koehn, Christof Monz,and Josh Schroeder.
2009.
Findings of the 2009Workshop on Statistical Machine Translation.
InProceedings of the Fourth Workshop on StatisticalMachine Translation, pages 1?28, Athens, Greece,March.
Association for Computational Linguistics.Chris Callison-Burch.
2008.
Syntactic constraintson paraphrases extracted from parallel corpora.
InProceedings of the Conference on Empirical Meth-ods in Natural Language Processing, EMNLP ?08,pages 196?205, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.David Chiang, Adam Lopez, Nitin Madnani, ChristofMonz, Philip Resnik, and Michael Subotin.
2005.
Thehiero machine translation system: extensions, evalua-tion, and analysis.
In Proceedings of the conference onHuman Language Technology and Empirical Methodsin Natural Language Processing, HLT ?05, pages 779?786, Stroudsburg, PA, USA.
Association for Compu-tational Linguistics.Trevor Cohn, Chris Callison-Burch, and Mirella Lapata.2008.
Constructing corpora for the development andevaluation of paraphrase systems.
Computational Lin-guistics, 34(4):597?614.Bill Dolan, Chris Quirk, and Chris Brockett.
2004.Unsupervised construction of large paraphrase cor-pora: Exploiting massively parallel news sources.
InProceedings of the 20th International Conference onComputational Linguistics, pages 350?356, Morris-town, NJ, USA.Maxim Khalilov and Jose?
A. R. Fonollosa.
2009.
N-gram-based statistical machine translation versus syn-tax augmented machine translation: comparison andsystem combination.
In Proceedings of the 12th Con-ference of the European Chapter of the Associationfor Computational Linguistics, EACL ?09, pages 424?432, Stroudsburg, PA, USA.
Association for Compu-tational Linguistics.Philip Koehn, Franz Josef Och, and Daniel Marcu.
2003.Statistical phrase-based translation.
In Proceedings ofthe 2003 Conference of the North American Chapterof the Association for Computational Linguistics onHuman Language Technology-Volume 1, pages 48?54.Association for Computational Linguistics.Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris C.Burch, Marcello Federico, Nicola Bertoldi, BrookeCowan, Wade Shen, Christine Moran, Richard Zens,Chris Dyer, Ondrej Bojar, Alexandra Constantin, andEvan Herbst.
2007.
Moses: Open source toolkit forstatistical machine translation.
In ACL.
The Associa-tion for Computer Linguistics.Alon Lavie and Abhaya Agarwal.
2007.
Meteor: an au-tomatic metric for mt evaluation with high levels ofcorrelation with human judgments.
In Proceedingsof the Second Workshop on Statistical Machine Trans-lation, StatMT ?07, pages 228?231, Stroudsburg, PA,USA.
Association for Computational Linguistics.Nitin Madnani and Bonnie J. Dorr.
2010.
Gener-ating phrasal and sentential paraphrases: A surveyof data-driven methods.
Computational Linguistics,36(3):341?387.Nitin Madnani, Necip Fazil Ayan, Philip Resnik, andBonnie J. Dorr.
2007.
Using paraphrases for pa-rameter tuning in statistical machine translation.
InProceedings of the Second Workshop on StatisticalMachine Translation, StatMT ?07, pages 120?127,Stroudsburg, PA, USA.
Association for ComputationalLinguistics.Daniel Marcu and William Wong.
2002.
A phrase-based,joint probability model for statistical machine trans-lation.
In Proceedings of the ACL-02 conference onEmpirical methods in natural language processing -Volume 10, EMNLP ?02, pages 133?139, Stroudsburg,PA, USA.
Association for Computational Linguistics.Erwin Marsi and Emiel Krahmer.
2011.
Construction ofan aligned monolingual treebank for studying seman-tic similarity.
(submitted for publication).32Franz J. Och and Hermann Ney.
2003.
A systematiccomparison of various statistical alignment models.Comput.
Linguist., 29(1):19?51, March.Franz Josef Och and Hermann Ney.
2004.
The align-ment template approach to statistical machine transla-tion.
Comput.
Linguist., 30:417?449, December.Franz J. Och, Christoph Tillmann, and Hermann Ney.1999.
Improved alignment models for Statistical Ma-chine Translation.
In Proceedings of the Joint Work-shop on Empirical Methods in NLP and Very LargeCorpora, pages 20?28, Maryland, USA.Bo Pang, Kevin Knight, and Daniel Marcu.
2003.Syntax-based alignment of multiple translations: Ex-tracting paraphrases and generating new sentences.
InHLT-NAACL.Chris Quirk, Chris Brockett, and William Dolan.
2004.Monolingual machine translation for paraphrase gen-eration.
In Dekang Lin and Dekai Wu, editors, Pro-ceedings of EMNLP 2004, pages 142?149, Barcelona,Spain, July.
Association for Computational Linguis-tics.Siwei Shen, Dragomir R. Radev, Agam Patel, and Gu?nes?Erkan.
2006.
Adding syntax to dynamic program-ming for aligning comparable texts for the generationof paraphrases.
In Proceedings of the COLING/ACL2006 Main Conference Poster Sessions, pages 747?754, Sydney, Australia, July.
Association for Compu-tational Linguistics.Yusuke Shinyama, Satoshi Sekine, Kiyoshi Sudo, andRalph Grishman.
2002.
Automatic paraphrase acqui-sition from news articles.
In Proceedings of HumanLanguage Technology Conference (HLT 2002), pages313?318, San Diego, USA.Andreas Stolcke.
2002.
SRILM - An Extensible Lan-guage Modeling Toolkit.
In In Proc.
Int.
Conf.
onSpoken Language Processing, pages 901?904, Denver,Colorado.S.
Vogel, Franz Josef Och, and Hermann Ney.
2000.
Thestatistical translation module in the verbmobil system.In KONVENS 2000 / Sprachkommunikation, Vortrgeder gemeinsamen Veranstaltung 5.
Konferenz zur Ve-rarbeitung natrlicher Sprache (KONVENS), 6.
ITG-Fachtagung ?Sprachkommunikation?, pages 291?293,Berlin, Germany, Germany.
VDE-Verlag GmbH.Sander Wubben, Antal van den Bosch, Emiel Krahmer,and Erwin Marsi.
2009.
Clustering and matchingheadlines for automatic paraphrase acquisition.
InE.
Krahmer and M. Theune, editors, The 12th Eu-ropean Workshop on Natural Language Generation,pages 122?125, Athens.
Association for Computa-tional Linguistics.Sander Wubben, Antal van den Bosch, and Emiel Krah-mer.
2010.
Paraphrase generation as monolingualtranslation: Data and evaluation.
In B. Mac NameeJ.
Kelleher and I. van der Sluis, editors, Proceedings ofthe 10th International Workshop on Natural LanguageGeneration (INLG 2010), pages 203?207, Dublin.Richard Zens, Franz Josef Och, and Hermann Ney.
2002.Phrase-based statistical machine translation.
In Pro-ceedings of the 25th Annual German Conference onAI: Advances in Artificial Intelligence, KI ?02, pages18?32, London, UK.
Springer-Verlag.Shiqi Zhao, Xiang Lan, Ting Liu, and Sheng Li.
2009.Application-driven statistical paraphrase generation.In Proceedings of the Joint Conference of the 47thAnnual Meeting of the ACL and the 4th Interna-tional Joint Conference on Natural Language Process-ing of the AFNLP: Volume 2 - Volume 2, ACL ?09,pages 834?842, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Andreas Zollmann and Ashish Venugopal.
2006.
Syntaxaugmented machine translation via chart parsing.
InProceedings of the Workshop on Statistical MachineTranslation, StatMT ?06, pages 138?141, Stroudsburg,PA, USA.
Association for Computational Linguistics.33
