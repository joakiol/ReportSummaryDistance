Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing, pages 596?605,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsMulti-Objective Optimization for the Joint Disambiguation ofNouns and Named EntitiesDirk Weissenborn, Leonhard Hennig, Feiyu Xu and Hans UszkoreitLanguage Technology Lab, DFKIAlt-Moabit 91cBerlin, Germany{dirk.weissenborn, leonhard.hennig, feiyu, uszkoreit}@dfki.deAbstractIn this paper, we present a novel approachto joint word sense disambiguation (WSD)and entity linking (EL) that combines a setof complementary objectives in an exten-sible multi-objective formalism.
Duringdisambiguation the system performs con-tinuous optimization to find optimal prob-ability distributions over candidate senses.The performance of our system on nomi-nal WSD as well as EL improves state-of-the-art results on several corpora.
Theseimprovements demonstrate the importanceof combining complementary objectives ina joint model for robust disambiguation.1 IntroductionThe task of automatically assigning the correctmeaning to a given word or entity mention ina document is called word sense disambiguation(WSD) (Navigli, 2009) or entity linking (EL)(Bunescu and Pasca, 2006), respectively.
Suc-cessful disambiguation requires not only an un-derstanding of the topic or domain a document isdealing with, but also a deep analysis of how an in-dividual word is used within its local context.
Forexample, the meanings of the word ?newspaper?,as in the company or the physical product, oftencannot be distinguished by the global topic of thedocument it was mentioned in, but by recogniz-ing which type of meaning fits best into the localcontext of its mention.
On the other hand, for anambiguous entity mention such as a person name,e.g., ?Michael Jordan?, it is important to recognizethe domain or topic of the wider context to distin-guish, e.g., between the basketball player and themachine learning expert.The combination of the two most com-monly employed reference knowledge bases forWSD and EL, WordNet (Fellbaum, 1998) andWikipedia, in BabelNet (Navigli and Ponzetto,2012), has enabled a new line of research towardsthe joint disambiguation of words and named en-tities.
Babelfy (Moro et al, 2014) has shownthe potential of combining these two tasks ina purely knowledge-driven approach that jointlyfinds connections between potential word senseson a global, document level.
On the other hand,typical supervised methods (Zhong and Ng, 2010)trained on sense-annotated datasets are usuallyquite successful in dealing with individual wordsin their local context on a sentence level.
Hoffartet al (2011) recognize the importance of combin-ing both local and global context for robust dis-ambiguation.
However, their approach is limitedto EL and optimization is performed in a discretesetting.We present a system that combines disambigua-tion objectives for both global and local contextsinto a single multi-objective function.
The result-ing system is flexible and easily extensible withcomplementary objectives.
In contrast to priorwork (Hoffart et al, 2011; Moro et al, 2014) wemodel the problem in a continuous setting basedon probability distributions over candidate mean-ings instead of a binary treatment of candidatemeanings during disambiguation.
Our approachcombines knowledge from various sources in onerobust model.
The system uses lexical and ency-clopedic knowledge for the joint disambiguationof words and named entities, and exploits localcontext information of a mention to infer the typeof its meaning.
We integrate prior statistics fromsurface strings to candidate meanings in a ?nat-ural?
way as starting probability distributions foreach mention.The contributions of our work are the following:?
a model for joint nominal WSD and EL thatoutperforms previous state-of-the-art systemson both tasks?
an extensible framework for multi-objective596disambiguation?
an extensive evaluation of the approach onmultiple standard WSD and EL datasets?
the first work that employs continuous op-timization techniques for disambiguation (toour knowledge)?
publicly available code, resources andmodels at https://bitbucket.org/dfki-lt-re-group/mood2 ApproachOur system detects mentions in texts and disam-biguates their meaning to one of the candidatesenses extracted from a reference knowledge base.The integral parts of the system, namely mentiondetection, candidate search and disambiguationare described in detail in this section.
The modelrequires a tokenized, lemmatized and POS-taggeddocument as input; the output are sense-annotatedmentions.2.1 Knowledge SourceWe employ BabelNet 2.5.1 as our referenceknowledge base (KB).
BabelNet is a multilingualsemantic graph of concepts and named entitiesthat are represented by synonym sets, called Ba-bel synsets.
It is composed of lexical and encyclo-pedic resources, such as WordNet and Wikipedia.Babel synsets comprise several Babel senses, eachof which corresponds to a sense in another knowl-edge base.
For example the Babel synset of?Neil Armstrong?
contains multiple senses in-cluding for example ?armstrong#n#1?
(WordNet),?Neil Armstrong?
(Wikipedia).
All synsets are in-terlinked by conceptual-semantic and lexical re-lations from WordNet and semantic relations ex-tracted from links between Wikipedia pages.2.2 Mention Extraction & Entity DetectionWe define a mention to be a sequence of tokens ina given document.
The system extracts mentionsfor all content words (nouns, verbs, adjectives, ad-verbs) and multi-token units of up to 7 tokens thatcontain at least one noun.
In addition, we applya NER-tagger to identify named entity (NE) men-tions.
Our approach distinguishes NEs from com-mon nouns because there are many common nounsalso referring to NEs, making disambiguation un-necessarily complicated.
For example, the word?moon?
might refer to songs, films, video games,etc., but we should only consider these meaningsif the occurrence suggests that it is used as a NE.2.3 Candidate SearchAfter potential mentions are extracted, the sys-tem tries to identify their candidate meanings, i.e.,the appropriate synsets.
Mentions without anycandidates are discarded.
There are various re-sources one can exploit to map surface strings tocandidate meanings.
However, existing methodsor resources especially for NEs are either miss-ing many important mappings1or contain manynoisy mappings2.
Therefore, we created a can-didate mapping strategy that tries to avoid noisymappings while including all potentially correctcandidates.
Our approach employs several heuris-tics that aim to avoid noise.
Their union yieldsan almost complete mapping that includes the cor-rect candidate meaning for 97-100% of the exam-ples in the test datasets.
Candidate mentions aremapped to synsets based on similarity of their sur-face strings or lemmas.
If the surface string orlemma of a mention matches the lemma of a syn-onym in a synset that has the same part of speech,the synset will be considered as a candidate mean-ing.
We allow partial matches for BabelNet syn-onyms derived from Wikipedia titles or redirec-tions.
However, partial matching is restricted tosynsets that belong either to the semantic category?Place?
or ?Agent?.
We make use of the seman-tic category information provided by the DBpe-dia ontology3.
A partial match allows the sur-face string of a mention to differ by up to 3 to-kens from the Wikipedia title (excluding every-thing in parentheses) if the partial string occurredat least once as an anchor for the correspondingWikipedia page.
E.g., for the Wikipedia title Arm-strong School District (Pennsylvania), the fol-lowing surface strings would be consideredmatches: ?Armstrong School District (Pennsylva-nia)?, ?Armstrong School District?, ?Armstrong?,but not ?School?
or ?District?, since they werenever used as an anchor.
If there is no match we trythe same procedure applied to the lowercase formsof the surface string or the lemma.
For persons weallow matches to all partial names, e.g., only firstname, first and middle name, last name, etc.In addition to the aforementioned candidate ex-traction we also match surface strings to candidateentities mentioned on their respective disambigua-1e.g., using only the synonyms of a synset2e.g., partial matches for all synonyms of a synset3http://wiki.dbpedia.org/Ontology597tion pages in Wikipedia4.
For cases where ad-jectives should be disambiguated as nouns, e.g.,?English?
as a country to ?England?, we allowcandidate mappings through the pertainment rela-tion from WordNet.
Finally, frequently annotatedsurface strings in Wikipedia are matched to theircorresponding entities, where we stipulate ?fre-quently?
to mean that the surface string occurs atleast 100 times as anchor in Wikipedia and the en-tity was either at least 100 times annotated by thissurface string or it was annotated above average.The distinction between nouns and NEs im-poses certain restrictions on the set of potentialcandidates.
Candidate synsets for nouns are nounsynsets considered as ?Concepts?
in BabelNet (asopposed to ?Named Entities?)
in addition to allsynsets of WordNet senses.
On the other hand,candidate synsets for NEs comprise all nominalBabel synsets.
Thus, the range of candidate setsfor NEs properly contains the one for nouns.
Weinclude all nominal synsets as potential candidatesfor NEs because the distinction of NEs and sim-ple concepts is not always clear in BabelNet.
Forexample the synset for ?UN?
(United Nations) isconsidered a concept whereas it could also be con-sidered a NE.
Finally, if there is no candidate for apotential nominal mention, we try to find NE can-didates for it before discarding it.2.4 Multi-Objective DisambiguationWe formulate the disambiguation as a continuous,multi-objective optimization problem.
Individualobjectives model different aspects of the disam-biguation problem.
Maximizing these objectivesmeans assigning high probabilities to candidatesenses that contribute most to the combined ob-jective.
After maximization, we select the candi-date meaning with the highest probability as thedisambiguated sense.
Our model is illustrated inFigure 1.Given a set of objectivesO the overall objectivefunction O is defined as the sum of all normalizedobjectives O ?
O given a set of mentions M :O(M) =?O?O|MO||M |?O(M)Omax(M)?Omin(M).
(1)The continuous approach has several advan-tages over a discrete setting.
First, we can ex-4provided by DBpedia at http://wiki.dbpedia.org/Downloads2014Armstrong- Armstrong_(crater) 0.6- Neil_Armstrong 0.2- Louis_Armstrong 0.1...jazz- jazz_(music) 0.3- jazz_(rhetoric) 0.3- ...Mentions Mplay- play_(game) 0.4- play_(instrument) 0.2- ...Armstrong- Armstrong_(crater) 0.3- Neil_Armstrong 0.1- Louis_Armstrong 0.5- ...Mentions MObjectives...While not_converged or i < max_iterationsplay- play_(game) 0.1- play_(instrument) 0.6- ...jazz- jazz_(music) 0.8- jazz_(rhetoric) 0.1- ...Figure 1: Illustration of our multi-objective ap-proach to WSD & EL for the example sen-tence: Armstrong plays jazz.
Mentions are disam-biguated by iteratively updating probability distri-butions over their candidate senses with respect tothe given objective gradients?Oi.ploit well established continuous optimization al-gorithms, such as conjugate gradient or LBFGS.Second, by optimizing upon probability distribu-tions we are optimizing the actually desired result,in contrast to densest sub-graph algorithms wherenormalized confidence scores are calculated after-wards, e.g., Moro et al (2014).
Third, discreteoptimization usually works on a single candidateper iteration whereas in a continuous setting, prob-abilities are adjusted for each candidate, which iscomputationally advantageous for highly ambigu-ous documents.We normalize each objective using the differ-ence of its maximum and minimum value for agiven document, which makes the weighting ofthe objectives different for each document.
Themaximum/minimum values can be calculated ana-lytically or, if this is not possible, by running theoptimization algorithm with only the given objec-tive for an approximate estimate for the maximumand with its negated form for an approximate min-imum.
Normalization is important for optimiza-tion because it ensures that the individual gradi-ents have similar norms on average for each ob-jective.
Without normalization, optimization is bi-ased towards objectives with large gradients.Given that one of the objectives can be appliedto only a fraction of all mentions (e.g., only nomi-nal mentions), we scale each objective by the frac-tion of mentions it is applied to.Note that our formulation could easily be ex-tended to using additional coefficients for each ob-598jective.
However, these hyper-parameters wouldhave to be estimated on development data andtherefore, this method could hurt generalization.Prior Another advantage of working with prob-ability distributions over candidates is the easy in-tegration of prior information.
For example, theword ?Paris?
without further context has a strongprior on its meaning as a city instead of a per-son.
Our approach utilizes prior information inform of frequency statistics over candidate synsetsfor a mention?s surface string.
These priors arederived from annotation frequencies provided byWordNet and Wikipedia.
We make use of oc-currence frequencies extracted by DBpedia Spot-light (Daiber et al, 2013) for synsets containingWikipedia senses in case of NE disambiguation.For nominal WSD, we employ frequency statis-tics from WordNet for synsets containing Word-Net senses.
Laplace-smoothing is applied to allprior frequencies.
The priors serve as initializa-tion for the probability distributions over candi-date synsets.
Note that we use priors ?naturally?,i.e., as actual priors for initialization only and notduring disambiguation itself.
They should not beapplied during disambiguation because these pri-ors can be very strong and are not domain inde-pendent.
However, they provide a good initializa-tion which is important for successful continuousoptimization.3 Disambiguation Objectives3.1 Coherence ObjectiveJointly disambiguating all mentions within a doc-ument has been shown to have a large impact ondisambiguation quality, especially for named enti-ties (Kulkarni et al, 2009).
It requires a measure-ment of semantic relatedness between conceptsthat can for example be extracted from a semanticnetwork like BabelNet.
However, semantic net-works usually suffer from data sparsity where im-portant links between concepts might be missing.To deal with this issue, we adopt the idea of usingsemantic signatures from Moro et al (2014).
Fol-lowing their approach, we create semantic signa-tures for concepts and named entities by runninga random walk with restart (RWR) in the seman-tic network.
We count the times a vertex is vis-ited during RWR and define all frequently visitedvertices to be the semantic signature (i.e., a set ofhighly related vertices) of the starting concept ornamed entity vertex.Our coherence objective aims at maximizingthe semantic relatedness among selected candidatesenses based on their semantic signatures Sc.
Wedefine the continuous objective using probabilitydistributions pm(c) over the candidate set Cmofeach mention m ?M in a document as follows:Ocoh(M) =?m?Mc?Cm?m??Mm?6=mc?
?Cm?s(m, c,m?, c?
)s(m, c,m?, c?)
= pm(c) ?
pm?(c?)
?
1((c, c?)
?
S)pm(c) =ewm,c?c?
?Cmewm,c?, (2)where 1 denotes the indicator function and pm(c)is a softmax function.
The only free, optimizableparameters are the softmax weights wm.
This ob-jective includes all mentions, i.e., MOcoh= M .
Itcan be interpreted as finding the densest subgraphwhere vertices correspond to mention-candidatepairs and edges to semantic signatures betweencandidate synsets.
However, in contrast to a dis-crete setup, each vertex is now weighted by itsprobability and therefore each edge is weighted bythe product of its adjacent vertex probabilities.3.2 Type ObjectiveOne of the biggest problems for supervised ap-proaches to WSD is the limited size and synsetcoverage of available training datasets such asSemCor (Miller et al, 1993).
One way to cir-cumvent this problem is to use a coarser set of se-mantic classes that groups synsets together.
Pre-vious studies on using semantic classes for dis-ambiguation showed promising results (Izquierdo-Bevi?a et al, 2006).
For example, WordNet pro-vides a mapping, called lexnames, of synsets into45 types, which is based on the syntactic cate-gories of synsets and their logical groupings5.
InWordNet 13.5% of all nouns are ambiguous withan average ambiguity of 2.79 synsets per lemma.Given a noun and a type (lexname), the percentageof ambiguous nouns drops to 7.1% for which theaverage ambiguity drops to 2.33.
This indicatesthat exploiting type classification for disambigua-tion can be very useful.Similarly, for EL it is important to recognizethe type of an entity mention in a local context.5http://wordnet.princeton.edu/man/lexnames.5WN.html599For example, in the phrase ?London beats Manch-ester?
it is very likely that the two city names referto sports clubs and not to the cities.
We utilize anexisting mapping from Wikipedia pages to typesfrom the DBpedia ontology, restricting the set oftarget types to the following: ?Activity?, ?Organ-isation?, ?Person?, ?Event?, ?Place?
and ?Misc?for the rest.We train a multi-class logistic regression modelfor each set of types that calculates probabilitydistributions qm(t) over WN- or DBpedia-types tgiven a noun- or a NE-mention m, respectively.The features used as input to the model are the fol-lowing:?
word embedding of mention?s surface string?
sum of word embeddings of all sentencewords excluding stopwords?
word embedding of the dependency parseparent?
collocations of surrounding words as inZhong et al (2010)?
POS tags with up to 3 tokens distance to m?
possible types of candidate synsetsWe employed pre-trained word embeddings fromMikolov et al (2013) instead of the words them-selves to increase generalization.Type classification is included as an objectivein the model as defined in equation 3.
It puts typespecific weights derived from type classificationon candidate synsets, enforcing candidates of fit-ting type to have higher probabilities.
The objec-tive is only applied to noun, NE and verb men-tions, i.e., MOtyp= Mn?MNE?Mv.Otyp(M) =?m?MOtyp?c?Cmqm(tc) ?
pm(c) (3)3.3 Regularization ObjectiveBecause candidate priors for NE mentions can bevery high, we add an additional L2-regularizationobjective for NE mentions:OL2(M) = ?
?2?m?MNE?wm?22(4)The regularization objective is integrated in theoverall objective function as it is, i.e., it is not nor-malized.Dataset |D| |M| KBSemEval-2015-13 (Sem15) 4 757 BN(to be published)SemEval-2013-12 (Sem13) 13 1931 BNSemEval-2013-12 (Sem13) 13 1644 WN(Navigli et al, 2013)SemEval-2007-17 (Sem07) 3 159 WN(Pradhan et al, 2007)Senseval 3 (Sen3) 4 886 WN(Snyder and Palmer, 2004)AIDA-CoNLL-testb (AIDA) 216 4530 Wiki(Hoffart et al, 2011)KORE50 (KORE) 50 144 Wiki(Hoffart et al, 2012)Table 1: List of datasets used in experiments withinformation about their number of documents (D),annotated noun and/or NE mentions (M ), andtheir respective target knowledge base (KB): BN-BabelNet, WN-WordNet, Wiki-Wikipedia.4 Experiments4.1 DatasetsWe evaluated our approach on 7 different datasets,comprising 3 WSD datasets annotated with Word-Net senses, 2 datasets annotated with Wikipediaarticles for EL and 2 more recent datasets anno-tated with Babel synsets.
Table 1 contains a list ofall datasets.Besides these test datasets we used SemCor(Miller et al, 1993) as training data for WSD andthe training part of the AIDA CoNLL dataset forEL.4.2 SetupFor the creation of semantic signatures we choosethe same parameter set as defined by Moro et al(2014).
We run the random walk with a restartprobability of 0.85 for a total of 1 million steps foreach vertex in the semantic graph and keep ver-tices visited at least 100 times as semantic signa-tures.The L2-regularization objective for named enti-ties is employed with ?
= 0.001, which we foundto perform best on the training part of the AIDA-CoNLL dataset.We trained the multi-class logistic regressionmodel for WN-type classification on SemCor andfor DBpedia-type classification on the trainingpart of the AIDA-CoNLL dataset using LBFGSand L2-Regularization with ?
= 0.01 until con-vergence.Our system optimizes the combined multi-objective function using Conjugate Gradient600System KB DescriptionIMS (Zhong andNg, 2010)WN supervised, SVMKPCS (Hoffartet al, 2011)Wiki greedy densest-subgraph oncombined mention-entity,entity-entity measuresKORE (Hoffartet al, 2012)Wiki extension of KPCS withkeyphrase relatedness mea-sure between entitiesMW (Milne andWitten, 2008)Wiki Normalized Google Dis-tanceBabelfy (Moroet al, 2014)BN greedy densest-subgraph onsemantic signaturesTable 2: Systems used for comparison during eval-uation.
(Hestenes and Stiefel, 1952) with up to a maxi-mum of 1000 iterations per document.We utilized existing implementations fromFACTORIE version 1.1 (McCallum et al, 2009)for logistic regression, NER tagging and Conju-gate Gradient optimization.
For NER tagging weused a pre-trained stacked linear-chain CRF (Laf-ferty et al, 2001).4.3 SystemsWe compare our approach to state-of-the-art re-sults on all datasets and a most frequent sense(MFS) baseline.
The MFS baseline selects thecandidate with the highest prior as described insection 2.4.
Table 2 contains a list of all sys-tems we compared against.
We use Babelfy as ourmain baseline, because of its state-of-the-art per-formance on all datasets and because it also em-ployed BabelNet as its sense inventory.
Note thatBabelfy achieved its results with different setupsfor WSD and EL, in contrast to our model, whichuses the same setup for both tasks.4.4 General ResultsWe report the performance of all systems in termsof F1-score.
To ensure fairness we restrictedthe candidate sets of the target mentions in eachdataset to candidates of their respective referenceKB.
Note that our candidate mapping strategy en-sures for all datasets a 97%?100% chance that thetarget synset is within a mention?s candidate set.This section presents results on the evaluationdatasets divided by their respective target KBs:WordNet, Wikipedia and BabelNet.WordNet Table 3 shows the results on threedatasets for the disambiguation of nouns to Word-System Sens3 Sem07 Sem13MFS 72.6 65.4 62.8IMS 71.2 63.3 65.7Babelfy 68.3 62.7 65.9Our 68.8 66.0 72.8Table 3: Results for nouns on WordNet annotateddatasets.System AIDA KOREMFS 70.1 35.4KPCS 82.2 55.6KORE-LSH-G 81.8 64.6MW 82.3 57.6Babelfy 82.1 71.5Our 85.1 67.4Table 4: Results for NEs on Wikipedia annotateddatasets.Net.
Our approach exhibits state-of-the-art re-sults outperforming all other systems on two of thethree datasets.
The model performs slightly worseon the Senseval 3 dataset because of one docu-ment in particular where the F1 score is very lowcompared to the MFS baseline.
On the other threedocuments, however, it performs as good or evenbetter.
In general, results from the literature are al-ways worse than the MFS baseline on this dataset.A strong improvement can be seen on the SemEval2013 Task 12 dataset (Sem13), which is also thelargest dataset.
Our system achieves an improve-ment of nearly 7% F1 over the best other system,which translates to an error reduction of roughly20% given that every word mention gets anno-tated.
Besides the results presented in Table 3, wealso evaluated the system on the SemEval 2007Task 7 dataset for coarse grained WSD, where itachieved 85.5% F1 compared to the best previ-ously reported result of 85.5% F1 from Ponzettoet al (2010) and Babelfy with 84.6%.Wikipedia The performance on entity linkingwas evaluated against state-of-the-art systems ontwo different datasets.
The results in Table 4demonstrate that our model can compete with thebest existing models, showing superior results es-pecially on the large AIDA CoNLL6test datasetcomprising 216 news texts, where we achievean error reduction of about 16%, resulting in anew state-of-the-art of 85.1% F1.
On the otherhand, our system is slightly worse on the KOREdataset compared to Babelfy (6 errors more in to-tal), which might be due to the strong priors and6the largest, freely available dataset for EL.601System Sem13 Sem15MFS 66.7 71.1Babelfy 69.2 ?Best other ?
64.8Our 71.5 75.4Table 5: Results for nouns and NEs on BabelNetannotated datasets.System Sem13 Sem15 AIDAMFS 66.7 71.1 70.1Otyp68.1 73.8 78.0Ocoh+OL268.1 69.6 82.7Ocoh+Otyp+OL271.5 75.4 85.1Table 6: Detailed results for nouns and NEs onBabelNet annotated datasets and AIDA CoNLL.the small context.
However, the dataset is rathersmall, containing only 50 sentences, and has beenartificially tailored to the use of highly ambiguousentity mentions.
For example, persons are mostof the time only mentioned by their first names.It is an interesting dataset because it requires thesystem to employ a lot of background knowledgeabout mentioned entities.BabelNet Table 5 shows the results on the 2 ex-isting BabelNet annotated datasets.
To our knowl-edge, our system shows the best performance onboth datasets in the literature.
An interesting ob-servation is that the F1 score on SemEval 2013with BabelNet as target KB is lower compared toWordNet as target KB.
The reason is that ambigu-ity rises for nominal mentions by including con-cepts from Wikipedia that do not exist in WordNet.For example, the Wikipedia concept ?formal lan-guage?
becomes a candidate for the surface string?language?.4.5 Detailed ResultsWe also experimented with different objectivecombinations, namely ?type only?
(Otyp), ?coher-ence only?
(Ocoh+OL2) and ?all?
(Ocoh+Otyp+OL2), to evaluate the impact of the different objec-tives.
Table 6 shows results of employing individ-ual configurations compared to the MFS baseline.Results for only using coherence or type exhibitvarying performance on the datasets, but still con-sistently exceed the strong MFS baseline.
Com-bining both objectives always yields better resultscompared to all other configurations.
This find-ing is important because it proves that the objec-tives proposed in this work are indeed comple-mentary, and thus demonstrates the significance ofcombining complementary approaches in one ro-bust framework such as ours.An additional observation was that DBpedia-type classification slightly overfitted on the AIDACoNLL training part.
When removing DBpedia-type classification from the type objective, resultsincreased marginally on some datasets except forthe AIDA CoNLL dataset, where results decreasedby roughly 3% F1.
The improvements of usingDBpedia-type classification are mainly due to thefact that the classifier is able to correctly clas-sify names of places in tables consisting of sportsscores not to the ?Place?
type but to the ?Organi-zation?
type.
Note that the AIDA CoNLL dataset(train and test) contains many of those tables.
Thisshows that including supervised objectives into thesystem helps when data is available for the do-main.4.6 GeneralizationWe evaluated the ability of our system to gener-alize to different domains based on the SemEval2015 Task 13 dataset.
It includes documents fromthe bio-medical, the math&computer and generaldomains.
Our approach performs particularly wellon the bio-medical domain with 86.3% F1 (MFS:77.3%).
Results on the math&computer domain(58.8% F1, MFS: 57.0%), however, reveal thatperformance still strongly depends on the docu-ment topic.
This indicates that either the employedresources do not cover this domain as well as oth-ers, or that it is generally more difficult to dis-ambiguate.
Another potential explanation is thatenforcing only pairwise coherence does not takethe hidden concepts computer and maths into ac-count, which connect all concepts, but are neveractually mentioned.
An interesting point for futureresearch might be the introduction of an additionalobjective or the extension of the coherence objec-tive to allow indirect connections between candi-date meanings through shared topics or categories.Besides these very specific findings, the model?sability to generalize is strongly supported by itsgood results across all datasets, covering a varietyof different topics.5 Related WorkWSD Approaches to WSD can be distinguishedby the kind of resource exploited.
The two mainresources for WSD are sense annotated datasetsand knowledge bases.
Typical supervised ap-602proaches like IMS (Zhong and Ng, 2010) trainclassifiers that learn from existing, annotated ex-amples.
They suffer from the sparsity of senseannotated datasets that is due to the data acqui-sition bottleneck (Pilehvar and Navigli, 2014).There have been approaches to overcome thisissue through the automatic generation of suchresources based on bootstrapping (Pham et al,2005), sentences containing unambiguous rela-tives of senses (Martinez et al, 2008) or exploit-ing Wikipedia (Shen et al, 2013).
On the otherhand, knowledge-based approaches achieve goodperformances rivaling state-of-the-art supervisedsystems (Ponzetto and Navigli, 2010) by using ex-isting structured knowledge (Lesk, 1986; Agirreet al, 2014), or take advantage of the structure ofa given semantic network through connectivity orcentrality measures (Tsatsaronis et al, 2007; Nav-igli and Lapata, 2010).
Such systems benefit fromthe availability of numerous KBs for a variety ofdomains.
We believe that both knowledge-basedapproaches and supervised methods have unique,complementary abilities that need to be combinedfor sophisticated disambiguation.EL Typical EL systems employ supervised ma-chine learning algorithms to classify or rank can-didate entities (Bunescu and Pasca, 2006; Milneand Witten, 2008; Zhang et al, 2010).
Com-mon features include popularity metrics based onWikipedia?s graph structure or on name mentionfrequency (Dredze et al, 2010; Han and Zhao,2009), similarity metrics exploring Wikipedia?sconcept relations (Han and Zhao, 2009), andstring similarity features.
Mihalcea and Csomai(2007) disambiguate each mention independentlygiven its sentence level context only.
In contrast,Cucerzan (2007) and Kulkarni et al (Kulkarniet al, 2009) recognize the interdependence be-tween entities in a wider context.
The most sim-ilar work to ours is that of Hoffart et al (2011)which was the first that combined local and globalcontext measures in one robust model.
However,objectives and the disambiguation algorithm differfrom our work.
They represent the disambigua-tion task as a densest subgraph problem where theleast connected entity is eliminated in each itera-tion.
The discrete treatment of candidate entitiescan be problematic especially at the beginning ofdisambiguation where it is biased towards men-tions with many candidates.Babelfy (Moro et al, 2014) is a knowledge-based approach for joint WSD and EL that alsouses a greedy densest subgraph algorithm for dis-ambiguation.
It employs a single coherence modelbased on semantic signatures similar to our coher-ence objective.
The system?s very good perfor-mance indicates that the semantic signatures pro-vide a powerful resource for joint disambiguation.However, because we believe it is not sufficientto only enforce semantic agreement among nounsand entities, our approach includes an objectivethat also focuses on the local context of mentions,making it more robust.6 Conclusions & Future WorkWe have presented a novel approach for thejoint disambiguation of nouns and named enti-ties based on an extensible framework.
Our sys-tem employs continuous optimization on a multi-objective function during disambiguation.
Theintegration of complementary objectives into ourformalism demonstrates that robust disambigua-tion can be achieved by considering both the localand the global context of a mention.
Our modeloutperforms previous state-of-the-art systems fornominal WSD and for EL.
It is the first systemthat achieves such results on various WSD and ELdatasets using a single setup.In future work, new objectives should be inte-grated into the framework and existing objectivescould be enhanced.
For example, it would be in-teresting to express semantic relatedness contin-uously rather than in a binary setting for the co-herence objective.
Additionally, using the entiremodel during training could ensure better com-patibility between the different objectives.
At themoment, the model itself is composed of differentpre-trained models that are only combined duringdisambiguation.AcknowledgmentThis research was partially supported by theGerman Federal Ministry of Education andResearch (BMBF) through the projects ALLSIDES (01IW14002), BBDC (01IS14013E), andby the German Federal Ministry of Economicsand Energy (BMWi) through the project SD4M(01MD15007B), and by Google through a Fo-cused Research Award granted in July 2013.603References[Agirre et al2014] Eneko Agirre, Oier Lopez de La-calle, and Aitor Soroa.
2014.
Random walks forknowledge-based word sense disambiguation.
Com-putational Linguistics, 40(1):57?84.
[Bunescu and Pasca2006] Razvan C Bunescu and Mar-ius Pasca.
2006.
Using encyclopedic knowledge fornamed entity disambiguation.
In EACL, volume 6,pages 9?16.
[Cucerzan2007] Silviu Cucerzan.
2007.
Large-scalenamed entity disambiguation based on wikipediadata.
In EMNLP-CoNLL, volume 7, pages 708?716.
[Daiber et al2013] Joachim Daiber, Max Jakob, ChrisHokamp, and Pablo N Mendes.
2013.
Improvingefficiency and accuracy in multilingual entity extrac-tion.
In Proceedings of the 9th International Confer-ence on Semantic Systems, pages 121?124.
ACM.
[Dredze et al2010] Mark Dredze, Paul McNamee,Delip Rao, Adam Gerber, and Tim Finin.
2010.Entity disambiguation for knowledge base popula-tion.
In Proc.
of the 23rd International Conferenceon Computational Linguistics, pages 277?285.
As-sociation for Computational Linguistics.
[Fellbaum1998] Christiane Fellbaum.
1998.
WordNet.Wiley Online Library.
[Han and Zhao2009] Xianpei Han and Jun Zhao.2009.
Named entity disambiguation by leverag-ing wikipedia semantic knowledge.
In Proc.
of the18th ACM conference on Information and knowl-edge management, pages 215?224.
ACM.
[Hestenes and Stiefel1952] Magnus Rudolph Hestenesand Eduard Stiefel.
1952.
Methods of conjugategradients for solving linear systems, volume 49.
Na-tional Bureau of Standards Washington, DC.
[Hoffart et al2011] Johannes Hoffart, Mohamed AmirYosef, Ilaria Bordino, Hagen F?urstenau, Man-fred Pinkal, Marc Spaniol, Bilyana Taneva, StefanThater, and Gerhard Weikum.
2011.
Robust disam-biguation of named entities in text.
In Proc.
of theConference on Empirical Methods in Natural Lan-guage Processing, pages 782?792.
Association forComputational Linguistics.
[Hoffart et al2012] Johannes Hoffart, Stephan Seufert,Dat Ba Nguyen, Martin Theobald, and GerhardWeikum.
2012.
Kore: keyphrase overlap related-ness for entity disambiguation.
In Proc.
of the 21stACM international conference on Information andknowledge management, pages 545?554.
ACM.
[Izquierdo-Bevi?a et al2006] Rub?en Izquierdo-Bevi?a,Lorenza Moreno-Monteagudo, Borja Navarro,and Armando Su?arez.
2006.
Spanish all-wordssemantic class disambiguation using cast3lb corpus.In MICAI 2006: Advances in Artificial Intelligence,pages 879?888.
Springer.
[Kulkarni et al2009] Sayali Kulkarni, Amit Singh,Ganesh Ramakrishnan, and Soumen Chakrabarti.2009.
Collective annotation of wikipedia entities inweb text.
In Proc.
of the 15th ACM SIGKDD in-ternational conference on Knowledge discovery anddata mining, pages 457?466.
ACM.
[Lafferty et al2001] John D. Lafferty, Andrew McCal-lum, and Fernando C. N. Pereira.
2001.
Condi-tional random fields: Probabilistic models for seg-menting and labeling sequence data.
In Proceed-ings of the Eighteenth International Conference onMachine Learning, ICML ?01, pages 282?289, SanFrancisco, CA, USA.
Morgan Kaufmann PublishersInc.
[Lesk1986] Michael Lesk.
1986.
Automatic sense dis-ambiguation using machine readable dictionaries:how to tell a pine cone from an ice cream cone.
InProc.
of the 5th annual international conference onSystems documentation, pages 24?26.
ACM.
[Martinez et al2008] David Martinez, Oier LopezDe Lacalle, and Eneko Agirre.
2008.
On the use ofautomatically acquired examples for all-nouns wordsense disambiguation.
J. Artif.
Intell.
Res.(JAIR),33:79?107.
[McCallum et al2009] Andrew McCallum, KarlSchultz, and Sameer Singh.
2009.
FACTORIE:Probabilistic programming via imperatively definedfactor graphs.
In Neural Information ProcessingSystems (NIPS).
[Mihalcea and Csomai2007] Rada Mihalcea and An-dras Csomai.
2007.
Wikify!
: linking documents toencyclopedic knowledge.
In Proc.
of the sixteenthACM conference on Conference on information andknowledge management, pages 233?242.
ACM.
[Mikolov et al2013] Tomas Mikolov, Ilya Sutskever,Kai Chen, Greg S Corrado, and Jeff Dean.
2013.Distributed representations of words and phrasesand their compositionality.
In Advances in NeuralInformation Processing Systems, pages 3111?3119.
[Miller et al1993] George A Miller, Claudia Leacock,Randee Tengi, and Ross T Bunker.
1993.
A se-mantic concordance.
In Proc.
of the workshop onHuman Language Technology, pages 303?308.
As-sociation for Computational Linguistics.
[Milne and Witten2008] David Milne and Ian H Witten.2008.
Learning to link with wikipedia.
In Proc.
ofthe 17th ACM conference on Information and knowl-edge management, pages 509?518.
ACM.
[Moro et al2014] Andrea Moro, Alessandro Raganato,and Roberto Navigli.
2014.
Entity linking meetsword sense disambiguation: A unified approach.Transactions of the Association for ComputationalLinguistics, 2.604[Navigli and Lapata2010] Roberto Navigli and MirellaLapata.
2010.
An experimental study of graph con-nectivity for unsupervised word sense disambigua-tion.
Pattern Analysis and Machine Intelligence,IEEE Transactions on, 32(4):678?692.
[Navigli and Ponzetto2012] Roberto Navigli and Si-mone Paolo Ponzetto.
2012.
Babelnet: The auto-matic construction, evaluation and application of awide-coverage multilingual semantic network.
Arti-ficial Intelligence, 193:217?250.
[Navigli et al2013] Roberto Navigli, David Jurgens,and Daniele Vannella.
2013.
Semeval-2013 task 12:Multilingual word sense disambiguation.
In SecondJoint Conference on Lexical and Computational Se-mantics (SEM), volume 2, pages 222?231.
[Navigli2009] Roberto Navigli.
2009.
Word sense dis-ambiguation: A survey.
ACM Computing Surveys(CSUR), 41(2):10.
[Pham et al2005] Thanh Phong Pham, Hwee Tou Ng,and Wee Sun Lee.
2005.
Word sense disambigua-tion with semi-supervised learning.
In Proc.
of thenational conference on artificial intelligence, vol-ume 20, page 1093.
Menlo Park, CA; Cambridge,MA; London; AAAI Press; MIT Press; 1999.
[Pilehvar and Navigli2014] Mohammad Taher Pilehvarand Roberto Navigli.
2014.
A large-scalepseudoword-based evaluation framework for state-of-the-art word sense disambiguation.
Computa-tional Linguistics, 40(4):837?881.
[Ponzetto and Navigli2010] Simone Paolo Ponzettoand Roberto Navigli.
2010.
Knowledge-richword sense disambiguation rivaling supervisedsystems.
In Proc.
of the 48th annual meetingof the association for computational linguistics,pages 1522?1531.
Association for ComputationalLinguistics.
[Pradhan et al2007] Sameer S Pradhan, Edward Loper,Dmitriy Dligach, and Martha Palmer.
2007.Semeval-2007 task 17: English lexical sample, srland all words.
In Proc.
of the 4th InternationalWorkshop on Semantic Evaluations, pages 87?92.Association for Computational Linguistics.
[Shen et al2013] Hui Shen, Razvan Bunescu, and RadaMihalcea.
2013.
Coarse to fine grained sense dis-ambiguation in wikipedia.
Proc.
of SEM, pages 22?31.
[Snyder and Palmer2004] Benjamin Snyder and MarthaPalmer.
2004.
The english all-words task.
InSenseval-3: Third International Workshop on theEvaluation of Systems for the Semantic Analysis ofText, pages 41?43.
[Tsatsaronis et al2007] George Tsatsaronis, MichalisVazirgiannis, and Ion Androutsopoulos.
2007.Word sense disambiguation with spreading activa-tion networks generated from thesauri.
In IJCAI,volume 7, pages 1725?1730.
[Zhang et al2010] Wei Zhang, Jian Su, Chew Lim Tan,and Wen Ting Wang.
2010.
Entity linking leverag-ing: automatically generated annotation.
In Proc.of the 23rd International Conference on Compu-tational Linguistics, pages 1290?1298.
Associationfor Computational Linguistics.
[Zhong and Ng2010] Zhi Zhong and Hwee Tou Ng.2010.
It makes sense: A wide-coverage word sensedisambiguation system for free text.
In Proc.
ofthe ACL 2010 System Demonstrations, pages 78?83.Association for Computational Linguistics.605
