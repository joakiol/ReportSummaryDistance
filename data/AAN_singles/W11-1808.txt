Proceedings of BioNLP Shared Task 2011 Workshop, pages 51?55,Portland, Oregon, USA, 24 June, 2011. c?2011 Association for Computational LinguisticsModel Combination for Event Extraction in BioNLP 2011Sebastian Riedela, David McCloskyb, Mihai Surdeanub,Andrew McCalluma, and Christopher D. Manningba Department of Computer Science, University of Massachusetts at Amherstb Department of Computer Science, Stanford University{riedel,mccallum}@cs.umass.edu{mcclosky,mihais,manning}@stanford.eduAbstractWe describe the FAUST entry to the BioNLP2011 shared task on biomolecular event ex-traction.
The FAUST system explores sev-eral stacking models for combination usingas base models the UMass dual decomposi-tion (Riedel and McCallum, 2011) and Stan-ford event parsing (McClosky et al, 2011b)approaches.
We show that using stacking isa straightforward way to improving perfor-mance for event extraction and find that it ismost effective when using a small set of stack-ing features and the base models use slightlydifferent representations of the input data.
TheFAUST system obtained 1st place in three outof four tasks: 1st place in Genia Task 1 (56.0%f-score) and Task 2 (53.9%), 2nd place in theEpigenetics and Post-translational Modifica-tions track (35.0%), and 1st place in the In-fectious Diseases track (55.6%).1 IntroductionTo date, most approaches to the BioNLP event ex-traction task (Kim et al, 2011a) use a single modelto produce their output.
However, model combina-tion techniques such as voting, stacking, and rerank-ing have been shown to consistently produce higherperforming systems by taking advantage of multi-ple views of the same data.
The Netflix Prize (Ben-nett et al, 2007) is a prime example of this.
Systemcombination essentially allows systems to regular-ize each other, smoothing over the artifacts of each(c.f.
Nivre and McDonald (2008), Surdeanu andManning (2010)).
To our knowledge, the only previ-ous example of model combination for the BioNLPshared task was performed by Kim et al (2009).
Us-ing a weighted voting scheme to combine the out-puts from the top six systems, they obtained a 4%absolute f-score improvement over the best individ-ual system.This paper shows that using a straightforwardmodel combination strategy on two competitivesystems produces a new system with substantiallyhigher accuracy.
This is achieved with the frame-work of stacking: a stacking model uses the outputof a stacked model as additional features.While we initially considered voting and rerank-ing model combination strategies, it seemed thatgiven the performance gap between the UMass andStanford systems that the best option was to in-clude the predictions from the Stanford system intothe UMass system (e.g., as in Nivre and McDon-ald (2008)).
This has the advantage that one model(Umass) determines how to integrate the outputs ofthe other model (Stanford) into its own structure,whereas in reranking, for example, the combinedmodel is required to output a complete structure pro-duced by only one of the input models.2 ApproachIn the following we briefly present both the stackingand the stacked model and some possible ways ofintegrating the stacked information.2.1 Stacking ModelAs our stacking model, we employ the UMass ex-tractor (Riedel and McCallum, 2011).
It is based ona discriminatively trained model that jointly predictstrigger labels, event arguments and protein pairs in51binding.
We will briefly describe this model but firstintroduce three types of binary variables that willrepresent events in a given sentence.
Variables ei,tare active if and only if the token at position i hasthe label t. Variables ai,j,r are active if and only ifthere is an event with trigger i that has an argumentwith role r grounded at token j.
In the case of anentity mention this means that the mention?s head isj.
In the case of an event j is the position of its trig-ger.
Finally, variables bp,q indicate whether or nottwo entity mentions at p and q appear as argumentsin the same binding event.Two parts form our model: a scoring function, anda set of constraints.
The scoring function over thetrigger variables e, argument variables a and bindingpair variables b iss (e,a,b) def=?ei,t=1sT (i, t) +?ai,j,r=1sR (i, j, r)+?bp,q=1sB (p, q)with local scoring functions sT (i, t)def=?wT, fT (i, t)?, sR (i, j, r)def= ?wR, fR (i, j, r)?and sB (p, q)def= ?wB, fB (p, q)?.Our model scores all parts of the structure in iso-lation.
It is a joint model due to the nature of theconstraints we enforce: First, we require that eachactive event trigger must have at least one Theme ar-gument; second, only regulation events (or Catalysisevents for the EPI track) are allowed to have Causearguments; third, any trigger that is itself an argu-ment of another event has to be labelled active, too;finally, if we decide that two entities p and q are partof the same binding (as indicated by bp,q = 1), thereneeds to be a binding event at some trigger i thathas p and q as arguments.
We will denote the set ofstructures (e,a,b) that satisfy these constraints asY .Stacking with this model is simple: we onlyneed to augment the local feature functions fT (i, t),fR (i, j, r) and fB (p, q) to include predictions fromthe systems to be stacked.
For example, for everysystem S to be stacked and every pair of event types(t?, tS) we add the featuresfS,t?
,tS (i, t) ={1 hS (i) = tS ?
t?
= t0 otherwiseto fT (i, t).
Here hS (i) is the event label given to to-ken i according to S. These features allow differentweights to be given to each possible combination oftype t?
that we want to assign, and type tS that Spredicts.Inference in this model amounts to maximizings (e,a,b) over Y .
Our approach to solving thisproblem is dual decomposition (Komodakis et al,2007; Rush et al, 2010).
We divide the problem intothree subproblems: (1) finding the best trigger labeland set of outgoing edges for each candidate trigger;(2) finding the best trigger label and set of incomingedges for each candidate trigger; (3) finding the bestpairs of entities to appear in the same binding.
Dueto space limitations we refer the reader to Riedel andMcCallum (2011) for further details.2.2 Stacked ModelFor the stacked model, we use a system based on anevent parsing framework (McClosky et al, 2011a)referred to as the Stanford model in this paper.
Thismodel converts event structures to dependency treeswhich are parsed using MSTParser (McDonald etal., 2005).1 Once parsed, the resulting dependencytree is converted back to event structures.
Using theStanford model as the stacked model is helpful sinceit captures tree structure which is not the focus inthe UMass model.
Of course, this is also a limita-tion since actual BioNLP event graphs are DAGs,but the model does well considering these restric-tions.
Additionally, this constraint encourages theStanford model to provide different (and thus moreuseful for stacking) results.Of particular interest to this paper are the fourpossible decoders in MSTParser.
These four de-coders come from combinations of feature order(first or second) and whether the resulting depen-dency tree is required to be projective.2 Each de-coder presents a slightly different view of the dataand thus has different model combination proper-ties.
Projectivity constraints are not captured in theUMass model so these decoders incorporate novelinformation.To produce stacking output from the Stanford sys-tem, we need its predictions on the training, devel-1http://sourceforge.net/projects/mstparser/2For brevity, the second-order non-projective decoder is ab-breviated as 2N, first-order projective as 1P, etc.52UMass FAUST+AllR P F1 R P F1GE T1 48.5 64.1 55.2 49.4 64.8 56.0GE T2 43.9 60.9 51.0 46.7 63.8 53.9EPI (F) 28.1 41.6 33.5 28.9 44.5 35.0EPI (C) 57.0 73.3 64.2 59.9 80.3 68.6ID (F) 46.9 62.0 53.4 48.0 66.0 55.6ID (C) 49.5 62.1 55.1 50.6 66.1 57.3Table 1: Results on test sets of all tasks we submitted to.T1 and T2 stand for task 1 and 2, respectively.
C standsfor CORE metric, F for FULL metric.opment and test sets.
For predictions on test and de-velopment sets we used models learned from the thecomplete training set.
Predictions over training datawere produced using crossvalidation.
This helps toavoid a scenario where the stacking model learns torely on high accuracy at training time that cannot bematched at test time.Note that, unlike Stanford?s individual submissionin this shared task, the stacked models in this paperdo not include the Stanford reranker.
This is becauseit would have required making a reranker model foreach crossvalidation fold.We made 19 crossvalidation training folds for Ge-nia (GE) (Kim et al, 2011b), 12 for Epigenetics(EPI), and 17 for Infectious Diseases (ID) (Kim etal., 2011b; Ohta et al, 2011; Pyysalo et al, 2011,respectively).
Note that while ID is the smallest andwould seem like it would have the fewest folds, wecombined the training data of ID with the trainingand development data from GE.
To produce predic-tions over the test data, we combined the trainingfolds with 6 development folds for GE, 4 for EPI,and 1 for ID.3 ExperimentsTable 1 gives an overview of our results on the testsets for all four tasks we submitted to.
Note thatfor the EPI and ID tasks we show the CORE metricnext to the official FULL metric.
The former is suit-able for our purposes because it does not measureperformance for negations, speculations and cellularlocations?all of these we did not attempt to predict.We compare the UMass standalone system to theFAUST+All system which stacks the Stanford 1N,1P, 2N and 2P predictions.
For all four tasks weSystem SVT BIND REG TOTALUMass 74.7 47.7 42.8 54.8Stanford 1N 71.4 38.6 32.8 47.8Stanford 1P 70.8 35.9 31.1 46.5Stanford 2N 69.1 35.0 27.8 44.3Stanford 2P 72.0 36.2 32.2 47.4FAUST+All 76.9 43.5 44.0 55.9FAUST+1N 76.4 45.1 43.8 55.6FAUST+1P 75.8 43.1 44.6 55.7FAUST+2N 74.9 42.8 43.8 54.9FAUST+2P 75.7 46.0 44.1 55.7FAUST+All 76.4 41.2 43.1 54.9(triggers)FAUST+All 76.1 41.7 43.6 55.1(arguments)Table 2: BioNLP f-scores on the development section ofthe Genia track (task 1) for several event categories.observe substantial improvements due to stacking.The increase is particular striking for the EPI track,where stacking improves f-score by more than 4.0points on the CORE metric.To analyze the impact of stacking further, Ta-ble 2 shows a breakdown of our results on the Ge-nia development set.
Presented are f-scores for sim-ple events (SVT), binding events (BIND), regulationevents (REG) and the set of all event types (TOTAL).We compare the UMass standalone system, variousStanford-standalone models and stacked versions ofthese (FAUST+X).Remarkably, while there is a 7 point gap betweenthe best individual Stanford system and the stand-alone UMass systems, integrating the Stanford pre-diction still leads to an f-score improvement of 1.This can be seen when comparing the UMass, Stan-ford 1N and FAUST+All results, where the latterstacks 1N, 1P, 2N and 2P.
We also note that stack-ing the projective 1P and 2P systems helps almostas much as stacking all Stanford systems.
Notably,both 1P and 2P do not do as well in isolation whencompared to the 1N system.
When stacked, how-ever, they do slightly better.
This suggests that pro-jectivity is a missing aspect in the UMass standalonesystem.The FAUST+All (triggers) and FAUST+All (ar-guments) lines represent experiments to determinewhether it is useful to incorporate only portions of53the stacking information from the Stanford system.Given the small gains over the original UMass sys-tem, it is clear that stacking information is only use-ful when attached to triggers and arguments.
Ourtheory is that most of our gains come from when theUMass and Stanford systems disagree on triggersand the Stanford system provides not only its trig-gers but also their attached arguments to the UMasssystem.
This is supported by a pilot experimentwhere we trained the Stanford model to use theUMass triggers and saw no benefit from stacking(even when both triggers and arguments were used).Table 3 shows our results on the development setof the ID task, this time in terms of recall, precisionand f-score.
Here the gap between Stanford-onlyresults, and the UMass results, is much smaller.
Thisseems to lead to more substantial improvements forstacking: FAUST+All obtains a f-score 2.2 pointslarger than the standalone UMass system.
Also notethat, similarly to the previous table, the projectivesystems do worse on their own, but are more usefulwhen stacked.Another possible approach to stacking conjoinsall the original features of the stacking model withthe predicted features of the stacked model.
Thehope is that this allows the learner to give differ-ent weights to the stacked predictions in differentcontexts.
However, incorporating Stanford predic-tions by conjoining them with all features of theUMass standalone system (FAUST+2P-Conj in Ta-ble 3) does not help here.We note that for our results on the ID task weaugment the training data with events from the GEtraining set.
Merging both training sets is reasonablesince there is a significant overlap between both interms of events as well as lexical and syntactic pat-terns to express these.
When building our trainingset we add each training document from GE once,and each ID training document twice?this lead tosubstantially better results than including ID dataonly once.4 DiscussionGenerally stacking has led to substantial improve-ments across the board.
There are, however, someexceptions.
One is binding events for the GE task.Here the UMass model still outperforms the bestSystem Rec Prec F1UMass 46.2 51.1 48.5Stanford 1N 43.1 49.1 45.9Stanford 1P 40.8 46.7 43.5Stanford 2N 41.6 53.9 46.9Stanford 2P 42.8 48.1 45.3FAUST+All 47.6 54.3 50.7FAUST+1N 45.8 51.6 48.5FAUST+1P 47.6 52.8 50.0FAUST+2N 45.4 52.4 48.6FAUST+2P 49.1 52.6 50.7FAUST+2P-Conj 48.0 53.2 50.4Table 3: Results on the development set for the ID track.stacked system (see Table 2).
Likewise, for full pa-pers in the Genia test set, the UMass model still doesslightly better with 53.1 f-score compared to 52.7f-score.
This suggests that a more informed com-bination of our systems (e.g., metaclassifiers) couldlead to better performance.5 ConclusionWe have presented the FAUST entry to the BioNLP2011 shared task on biomolecular event extraction.It is based on stacking, a simple approach for modelcombination.
By using the predictions of the Stan-ford entry as features of the UMass model, we sub-stantially improved upon both systems in isolation.This helped us to rank 1st in three of the four taskswe submitted results to.
Remarkably, in some caseswe observed improvements despite a 7.0 f-scoremargin between the models we combined.In the future we would like to investigate alter-native means for model combination such as rerank-ing, union, intersection, and other voting techniques.We also plan to use dual decomposition to encouragemodels to agree.
In particular, we will seek to incor-porate an MST component into the dual decomposi-tion algorithm used by the UMass system.AcknowledgmentsWe thank the BioNLP shared task organizers for setting thisup and their quick responses to questions.
This work was sup-ported in part by the Center for Intelligent Information Re-trieval.
We gratefully acknowledge the support of the DefenseAdvanced Research Projects Agency (DARPA) Machine Read-ing Program under Air Force Research Laboratory (AFRL)prime contract no.
FA8750-09-C-0181.54ReferencesJames Bennett, Stan Lanning, and Netflix.
2007.
Thenetflix prize.
In KDD Cup and Workshop in conjunc-tion with KDD.Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-nobu Kano, and Jun?ichi Tsujii.
2009.
Overview ofBioNLP?09 shared task on event extraction.
In Pro-ceedings of the Workshop on BioNLP: Shared Task,pages 1?9.
Association for Computational Linguistics.Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, RobertBossy, and Jun?ichi Tsujii.
2011a.
Overviewof BioNLP Shared Task 2011.
In Proceedings ofthe BioNLP 2011 Workshop Companion Volume forShared Task, Portland, Oregon, June.
Association forComputational Linguistics.Jin-Dong Kim, Yue Wang, Toshihisa Takagi, and Aki-nori Yonezawa.
2011b.
Overview of the Genia Eventtask in BioNLP Shared Task 2011.
In Proceedingsof the BioNLP 2011 Workshop Companion Volume forShared Task, Portland, Oregon, June.
Association forComputational Linguistics.Nikos Komodakis, Nikos Paragios, and Georgios Tziri-tas.
2007.
MRF optimization via dual decomposition:Message-passing revisited.
In ICCV.David McClosky, Mihai Surdeanu, and Chris Manning.2011a.
Event extraction as dependency parsing.
InProceedings of the Association for Computational Lin-guistics: Human Language Technologies 2011 Confer-ence (ACL-HLT?11), Main Conference, Portland, Ore-gon, June.David McClosky, Mihai Surdeanu, and Christopher D.Manning.
2011b.
Event extraction as dependencyparsing in BioNLP 2011.
In BioNLP 2011 SharedTask.Ryan T. McDonald, Fernando Pereira, Kiril Ribarov, andJan Hajic.
2005.
Non-projective dependency pars-ing using spanning tree algorithms.
In Proceedingsof HLT/EMNLP.
The Association for ComputationalLinguistics.Joakim Nivre and Ryan McDonald.
2008.
Integratinggraph-based and transition-based dependency parsers.In Proceedings of ACL-08: HLT, pages 950?958,Columbus, Ohio, June.
Association for ComputationalLinguistics.Tomoko Ohta, Sampo Pyysalo, and Jun?ichi Tsujii.
2011.Overview of the Epigenetics and Post-translationalModifications (EPI) task of BioNLP Shared Task2011.
In Proceedings of the BioNLP 2011 WorkshopCompanion Volume for Shared Task, Portland, Oregon,June.
Association for Computational Linguistics.Sampo Pyysalo, Tomoko Ohta, Rafal Rak, Dan Sul-livan, Chunhong Mao, Chunxia Wang, Bruno So-bral, Jun?ichi Tsujii, and Sophia Ananiadou.
2011.Overview of the Infectious Diseases (ID) task ofBioNLP Shared Task 2011.
In Proceedings ofthe BioNLP 2011 Workshop Companion Volume forShared Task, Portland, Oregon, June.
Association forComputational Linguistics.Sebastian Riedel and Andrew McCallum.
2011.
Ro-bust biomedical event extraction with dual decomposi-tion and minimal domain adaptation.
In BioNLP 2011Shared Task.Alexander M. Rush, David Sontag, Michael Collins, andTommi Jaakkola.
2010.
On dual decomposition andlinear programming relaxations for natural languageprocessing.
In Proc.
EMNLP.Mihai Surdeanu and Christopher D. Manning.
2010.
En-semble models for dependency parsing: Cheap andgood?
In Proceedings of the North American Chapterof the Association for Computational Linguistics Con-ference (NAACL-2010), Los Angeles, CA, June.55
