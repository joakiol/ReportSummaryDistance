Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 814?824,Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational LinguisticsUnsupervised Information Extraction with Distributional Prior KnowledgeCane Wing-ki Leung1, Jing Jiang1, Kian Ming A. Chai2, Hai Leong Chieu2, Loo-Nin Teow21School of Information Systems, Singapore Management University, Singapore2DSO National Laboratories, Singapore{caneleung,jingjiang}@smu.edu.sg, {ckianmin,chaileon,tloonin}@dso.org.sgAbstractWe address the task of automatic discovery ofinformation extraction template from a giventext collection.
Our approach clusters candi-date slot fillers to identify meaningful tem-plate slots.
We propose a generative modelthat incorporates distributional prior knowl-edge to help distribute candidates in a docu-ment into appropriate slots.
Empirical resultssuggest that the proposed prior can bring sub-stantial improvements to our task as comparedto a K-means baseline and a Gaussian mixturemodel baseline.
Specifically, the proposedprior has shown to be effective when coupledwith discriminative features of the candidates.1 IntroductionInformation extraction (IE) is the task of extract-ing information from natural language texts to fill adatabase record following a structure called a tem-plate.
Such templates are usually defined basedon the domain of interest.
For example, the do-main in the Sixth Message Understanding Confer-ence (MUC-6, 1995) is management succession, andthe pre-defined template consists of the slots posi-tion, the person leaving, the person joining, and theorganization.Previous research on IE often requires the pre-definition of templates.
Template construction isusually done manually by domain experts, and an-notated documents are often created to facilitate su-pervised learning approaches to IE.
However, bothmanual template construction and data annotationare labor-intensive.
More importantly, templates andannotated data usually cannot be re-used in new do-mains due to domain dependency.
It is therefore nat-ural to consider the problem of unsupervised tem-plate induction and information extraction.
This isthe topic of this paper.There have been a few previous attempts to ad-dress the unsupervised IE problem (Shinyama andSekine, 2006; Sekine, 2006; Rosenfeld and Feld-man, 2006; Filatova et al, 2006).
These approacheshave a commonality: they try to cluster candidateslot fillers, which are often nouns and noun phrases,into slots of the template to be constructed.
How-ever, most of them have neglected the following im-portant observation: a single document or text seg-ment tends to cover different slots rather than re-dundantly fill the same slot.
In other words, duringclustering, candidates within the same text segmentshould be more likely to be distributed into differentclusters.In this paper, we propose a generative model thatincorporates this distributional prior knowledge.
Wedefine a prior distribution over the possible labelassignments in a document or a text segment suchthat a more diversified label assignment is preferred.This prior is based on the Poisson distribution.
Wealso compare a number of generative models forgenerating slot fillers and find that the Gaussian mix-ture model is the best.
We then combine the Poisson-based label assignment prior with the Gaussian mix-ture model to perform slot clustering.
We find thatcompared with a K-means baseline and a Gaussianmixture model baseline, our combined model withthe proposed label assignment prior substantiallyperforms better on two of the three data sets we usefor evaluation.
We further analyze the results on thethird data set and find that the proposed prior willhave little effect if there are no good discriminativefeatures to begin with.
In summary, we find that814our Poisson-based label assignment prior is effectivewhen coupled with good discriminative features.2 Related WorkOne common approach to unsupervised IE is basedon automatic IE pattern acquisition on a cluster ofsimilar documents.
For instance, Sudo et al (2003)and Sekine (2006) proposed different methods forautomatic IE pattern acquisition for a given domainbased on frequent subtree discovery in dependencyparse trees.
These methods leveraged heavily on theentity types of candidates when assigning them totemplate slots.
As a consequence, potentially dif-ferent semantic roles of candidates having the sameentity type could become indistinguishable (Sudo etal., 2003; Sekine, 2006).
This problem is alleviatedin our work by exploiting distributional prior knowl-edge about template slots, which is shown effectivewhen coupled with discriminative features of can-didates.
Filatova et al (2006) also considered fre-quent subtrees in dependency parse trees, but theirgoal was to build templates around verbs that arestatistically important in a given domain.
Our work,in contrast, is not constrained to verb-centric tem-plates.
We aim to identify salient slots in the givendomain by clustering.Marx et al (2002) proposed the cross-componentclustering algorithm for unsupervised IE.
Their al-gorithm assigned a candidate from a document toa cluster based on the candidate?s feature similaritywith candidates from other documents only.
In otherwords, the algorithm did not consider a candidate?srelationships with other candidates in the same doc-ument.
Our work is based on a different perspec-tive: we model label assignments for all candidatesin the same document with a distributional prior thatprefers a document to cover more distinct slots.
Weshow empirically that this prior improves slot clus-tering results greatly in some cases.Also related to our work is open domain IE, whichaims to perform unsupervised relation extraction.TEXTRUNNER (Banko et al, 2007), for example,automatically extracts all possible relations betweenpairs of noun phrases from a given corpus.
The maindifference between open domain IE and our workis that open domain IE does not aim to induce do-main templates, whereas we focus on a single do-main with the goal of inducing a template that de-scribes salient information structure of that domain.Furthermore, TEXTRUNNER and related studies onunsupervised relation extraction often rely on highlyredundant information on the Web or in large cor-pus (Hasegawa et al, 2004; Rosenfeld and Feldman,2006; Yan et al, 2009), which is not assumed in ourstudy.We propose a generative model with a distribu-tional prior for the unsupervised IE task, whereslot fillers correspond to observations in the model,and their labels correspond to hidden variables wewant to learn.
In the machine learning literature,researchers have explored the use of similar priorknowledge in the form of constraints through modelexpectation.
For example, Grac?a et al (2007) pro-posed to place constraints on the posterior proba-bilities of hidden variables in a generative model,while Druck et al (2008) studied a similar problemin a discriminative, semi-supervised setting.
Thesestudies model constraints as features, and enforcethe constraints through expected feature values.
Incontrast, we place constraints on label assignmentsthrough a probabilistic prior on the distribution ofslots.
The proposed prior is simple and easy to inter-pret in a generative model.
Nevertheless, it will beinteresting to explore how the proposed prior can beimplemented within the posterior constraint frame-work.3 Problem OverviewIn this section, we first formally define our unsuper-vised IE problem.
We then provide an overview ofour solution, which is based on a generative model.3.1 Problem DefinitionWe assume a collection of documents or short textsegments from a certain domain.
These documentsor text segments describe different events or enti-ties, but they are about the same topic or aspect ofthe domain.
Examples of such collections includea collection of sentences describing the educationalbackground of famous scientists and a collection ofaviation incident reports.
Our task is to automati-cally discover an IE template from this collection.The discovered template should contain a set of slotsthat play different semantic roles in the domain.815Input text:Topic: Graduate Student Seminar LunchDates: 13-Apr-95Time: 12:00 PM - 1:30 PMPostedBy: Edmund J. Delaney on 5-Apr-95 at 16:24 from andrew.cmu.eduAbstract:The last Graduate Student Seminar Series lunch will be held on Thursday, April 13 from noon-1:30 p.m. in room207, Student Activities Center.
Professor Sara Kiesler of SDS will speak on Carving A Successful Research Niche.Output:Slot Slot Filler(s)Slot 1 (start time) 12:00PMSlot 2 (end time) 1:30PM, 1:30 p.m.Slot 3 (location) room 207, Student Activities CenterSlot 4 (speaker) Professor Sara KieslerSlot 4 (irrelevant information) Edmund J. DelaneyFigure 1: An input text from a seminar announcement collection and the discovered IE template.
Note that the slotsare automatically discovered and the slot names are manually assigned.To construct such a template, we start with identi-fying candidate slot fillers, hereafter referred to ascandidates, from the input text.
Then we clusterthese candidates with the aim that each cluster willrepresent a semantically meaningful slot.
Figure 1gives an example of an input text from a collectionof seminar announcements and the resulting tem-plate discovered from the collection.
As we can see,the template contains some semantically meaningfulslots such as the start time, end time, location andspeaker of a seminar.
Moreover, it also contains aslot that covers an irrelevant candidate.
We call suchslots covering irrelevant candidates garbage slots.We can make two observations on the mappingfrom candidates to template slots from real data,such as the text in Figure 1.
Firstly, a templateslot may be filled by more than one candidate froma single document, although this number has beenobserved to be small.
For example, the templateslot end time in Figure 1 has two slot fillers: ?1:30PM?
from the semi-structured header and ?1:30p.m.?
from within the abstract.
Secondly, a docu-ment tends to contain candidates that cover differenttemplate slots.
We believe that this observation is aconsequence of the fact that a document will tend toconvey as much information as possible.
We furtherexploit these observations in Section 4.3.2 A General SolutionRecall that our general solution to the unsupervisedIE problem is to cluster candidate slot fillers in orderto identify meaningful slots.
We leave the details ofhow to extract the candidates to Section 7.1.
In thissection, we assume that we have a set of candidatesx = {xi,j}, where xi,j is the j-th candidate fromthe i-th document in the collection.
We cluster thesecandidates intoK groups for a givenK.Let yi,j ?
{1, .
.
.
,K} denote the cluster label forxi,j and y denote the set of all the yi,j?s.
Let xi andyi denote the sets of all the xi,j?s and the yi,j?s in thei-th document respectively.
We assume a generativemodel for x and y as follows.
For the i-th documentin our collection, we assume that the number of can-didates is known and we draw a label assignment yiaccording to some distribution parameterized by ?.Then for the j-th candidate, we generate xi,j fromyi,j according to a generative model parameterizedby ?.
Since the labels y are hidden, the observedlog-likelihood of the parameters given the observa-tions x isL(?,?)
= log p(x; ?,?
)=?ilog?yip(xi,yi; ?,?
)=?ilog?yip(yi; ?
)?jp(xi,j |yi,j ; ?).
(1)816DniK(a) A multinomial prior.DniKK-1K-1(b) The proposed Poisson-basedprior.Figure 2: Generative models with different label assign-ment priors.
D denotes the number of documents in thegiven collection, ni denotes the number of candidates inthe i-th document, andK is the number of slots (clusters).For a given functional form of p(yi; ?)
andp(xi,j |yi,j ; ?
), the best model parameters can be es-timated by maximizing Eq.
(1).
In the next section,we detail two designs of the prior p(yi; ?
), followedby different generative models for the distributionp(xi,j |yi,j ; ?)
in Section 5.
Then we describe theestimation of model parameters in Section 6.4 Label Assignment PriorThe label assignment prior, p(yi; ?
), models thegeneration of labels for candidates in a document.In this section, we first describe a commonly usedmultinomial prior, and then introduce the proposedPoisson-based prior for the unsupervised IE task.4.1 A Multinomial PriorUsually, one would assume that the labels forthe different candidates in the same documentare generated independently, that is, p(yi; ?)
=?j p(yi,j ; ?).
Under this model, we assume thateach yi,j is generated from a multinomial distribu-tion parameterized by?, where ?y denotes the prob-ability of generating label y.
Our objective functionin Eq.
(1) then becomes:L(?,?)
= log p(x; ?,?
)=?i,jlog?y?yp(xi,j |y; ?).
(2)Figure 2(a) depicts a generative model with thismultinomial prior in plate notation.
Note that the in-dependence assumption on label assignment in thismodel does not capture our observation that candi-dates in a document are likely to cover different se-mantic roles.4.2 The Proposed Poisson-based PriorWe propose a prior distribution that favors morediverse label assignments.
Our proposal takesinto consideration the following three observations.Firstly, candidates in the same document are likelyto cover different semantic roles.
The proposed priordistribution should therefore assign higher probabil-ity to a label assignment that covers more distinctslots.
Secondly, the same piece of information is notlikely to be repeated many times in a document.
Ourdesign thus allows a slot to generate multiple fillersin a document, up to a limited number of times.Thirdly, there may exist candidates that do not be-long to slots in the extracted template.
Therefore, weintroduce a dummy slot or garbage slot to the labelset to collect such candidates.
Yet, we shall not as-sume any prior/domain knowledge about candidatesgenerated by the garbage slot as they are essentiallyirrelevant in the given domain.We now detail the prior that exploits the aboveobservations.
First, we fix the K-th slot (or cluster)in the label set to be the garbage slot.
For each ofthe non-garbage slot k = 1, .
.
.
,K ?
1, we also fixthe maximum number of fillers that can be gener-ated, which we denote by ?k.
There is no ?K for thegarbage slot because the number of fillers is not con-strained for this slot.
This allows all candidates in adocument to be generated by the garbage slot.
Letni be the number of candidates in the i-th document.Given K, {?k}K?1k=1 and ni, the set of possible labelassignments for the i-th document can be generated.We illustrate this with an example.
Let K = 2 and?1 = 1.
The label set is {1, 2}, where 2 representsthe garbage slot.
Let the number of candidates beni = 2.
The possible label assignments within thissetting are (1, 2), (2, 1) and (2, 2).The set of possible label assignments for the i-th document is the sample space on which we placethe prior distribution p(yi; ?).
We need a prior thatgives a higher probability to a more diverse labelassignment.
For a given yi for the i-th document,let ni,k be the number of candidates in the docu-ment that have been assigned to slot k. That is,ni,k def=?nij=1 1(yi,j = k), where 1(?)
is the indica-tor variable.
We propose the following distributionbased on the Poisson distribution:817p(yi; ?)
def= Z?1iK?1?k=1Poisson(ni,k; ?k), (3)where Zi is the normalizing constant, and ?k is themean parameter of the k-th Poisson distribution,k = 1, .
.
.K ?
1.
The absence of a factor thatdepends on ni,K reflects the lack of prior knowl-edge on the number of garbage slot fillers.
Fig-ure 2(b) depicts the proposed generative model withthe Poisson-based prior in plate notation.5 Generating Slot FillersDifferent existing generative models can be used tomodel the generation of a slot filler given a label, thatis, p(x|y; ?).
We explore four of them for our task,namely, the naive Bayes model, the Bernoulli mix-ture model, the Gaussian mixture model, and a lo-cally normalized logistic regression model proposedby Berg-Kirkpatrick et al (2010).5.1 Multinomial Naive BayesIn the multinomial naive Bayes model, features ofan observation x are assumed to be independent andeach generated from a multinomial distribution.
Wefirst introduce some notations.
Let f denote a fea-ture (e.g.
entity type) and Vf denote the set of possi-ble values for f .
Let xf ?
Vf be the value of featuref in x (e.g.
person).
For a given label y, feature ffollows a multinomial distribution parameterized by?y,f , where ?y,f,v denotes the probability of featuref taking the value v ?
Vf given label y.
The func-tional form of the conditional probability of x givena label y is thenp(x|y; ?)
=?fp(xf |y; ?)
=?f?y,f,xf .
(4)5.2 Bernoulli Mixture ModelIn the naive Bayes model our features are definedto be categorical.
For the Bernoulli mixture model,as well as the Gaussian mixture model and the lo-cally normalized logistic regression model in thenext subsections, we first convert each observationx into a binary feature vector x ?
{0, 1}F where Fis the number of binary features.
An example of abinary features is ?the entity type is person?.We assume that, for a given label y, observationsare generated from a multivariate Bernoulli distribu-tion parameterized by?y,f , where?y,f,v denotes theprobability of feature f taking the value v ?
{0, 1}given label y.
The conditional probability of x giveny can then be written asp(x|y; ?)
=?fp(xf = 1|y; ?
)xf ?
p(xf = 0|y; ?
)1?xf=?f?y,f,xf .
(5)5.3 Gaussian Mixture ModelIn the Gaussian mixture model, we assume that agiven label y generates observations with a mul-tivariate Gaussian distribution N (?y,?y), where?y ?
RF is the mean and ?y ?
RF?F is the co-variance matrix of the Gaussian.
If we assume thatthe different feature dimensions are independent andhave the same variance, that is, ?y = ?2yI , where Iis the identity matrix, then the conditional density ofx given y isp(x|y; ?)
= 1(2??2y)F/2exp(??x?
?y?22?2y).
(6)5.4 Locally Normalized Logistic RegressionBerg-Kirkpatrick et al (2010) proposed a methodfor incorporating features into generative models forunsupervised learning.
Their method models thegeneration of x given y as a logistic function param-eterized by a weight vector wy, defined as follows:p(x|y; ?)
= exp?x,wy??x?
exp?x?,wy?.
(7)?x,w?
denotes the inner product between x and w.The denominator considers all data points x?
in thedata set, thus Eq.
(7) gives a probability distributionover data points for a given y.8186 Parameter EstimationWe can apply the Expectation-Maximization (EM)algorithm (Dempster et al, 1977) to maximizethe log-likelihood functions under both multinomialprior in Eq.
(2) and the proposed Poisson-based priorin Eq.
(1).
For the multinomial prior, there are stan-dard closed form solutions for the naive Bayes, theBernoulli mixture and the Gaussian mixture models.For locally normalized logistic regression, modelparameters can also be learned via EM, but witha gradient-based M-step (Berg-Kirkpatrick et al,2010).
We leave out the details here and focus on pa-rameter estimation in the proposed generative modelwith the Poisson-based prior.We assume that in the Poisson-based prior, theparameters {?k}K?1k=1 and {?k}K?1k=1 are fixed ratherthan learned in this work.
For the distributionp(x|y; ?
), let ?
(t?1) and ?
(t) denote parameter es-timates from two consecutive EM iterations.
At thet-th iteration, the E-step updates the responsibilitiesof each label assignment yi for each document:?i,yi = p(yi|xi; ?,?
(t?1))= p(yi; ?
)p(xi|yi; ?
(t?1))?y?i p(y?i; ?
)p(xi|y?i; ?
(t?1)), (8)where ?i is a distribution over all possible label as-signments yi?s for the i-th document.
The M-stepupdates the estimates of ?
(t) based on the currentvalues of ?i?s and ?(t?1).
This is done by maximiz-ing the following objective function:?i?yi?i,yi log(p(yi; ?
)?jp(xi,j |yi,j ; ?(t?1))).
(9)The exact formulas used in the M-step forupdating ?
depend on the functional form ofp(xi,j |yi,j ; ?).
As an example, we give the formulasfor the Gaussian mixture model, in which?
containsthe set of means {?
(t)k }Kk=1 and variances {?
(t)k }Kk=1.Taking the derivatives of Eq.
(9) with respect to ?kand to ?k, and then setting the derivations to zero,we can solve for ?k and for ?k to get:?
(t)k =?i?yi ?i,yi?j 1(yi,j = k)xi,j?i?yi ?i,yi?j 1(yi,j = k), (10)?
(t)k =?i?yi ?i,yi?j 1(yi,j = k)||xi,j ?
?
(t)k ||2F?i?yi ?i,yi?j 1(yi,j = k), (11)where 1(?)
is the indicator variable.
We skip thederivations here due to space limit.Closed form solutions also exist for the naiveBayes and the Bernoulli mixture models.
For lo-cally normalized logistic regression, parameters canbe learned with a gradient-based M-step as in themultinomial prior setting.
Existing optimization al-gorithms, such as L-BFGS, can be used for optimiz-ing model parameters in the M-step as discussed in(Berg-Kirkpatrick et al, 2010).7 ExperimentsIn this section, we first describe the data sets we usedin our experiments, detailing the target slots and can-didates in each data set, as well as features we ex-tract for the candidates.
We then describe our evalu-ation metrics, followed by experimental results.7.1 Data SetsWe use three data sets for evaluating our unsuper-vised IE task.
Note that to speed up computation,we only include documents or text segments con-taining no more than 10 candidates in our experi-ments.
The first data set contains a set of seminar an-nouncements (Freitag and McCallum, 1999), anno-tated with four slot labels, namely stime (start time),etime (end time), speaker and location.
We used ascandidates all strings labeled in the annotated dataas well as all named entities found by the StanfordNER tagger for CoNLL (Finkel et al, 2005).
Thereare 309 seminar announcements with 2262 candi-dates in this data set.The second data set is a collection of para-graphs describing aviation incidents, taken from theWikipedia article on ?List of accidents and incidentsinvolving commercial aircraft?
(Wikipedia, 2009).Each paragraph in the article contains one to a fewsentences describing an incident.
In this domain, wetake each paragraph as a separate document, and allhyperlinked phrases in the original Wikipedia arti-cle as candidates.
For evaluation, we manually an-notated the paragraphs of incidents from 2006 to2009 with five slot labels: the flight number (FN),the airline (AL), the aircraft model (AC), the exact819location (LO) of the incident (e.g.
airport name),and the country (CO) where the incident occurred.The entire data set consists of 564 paragraphs with2783 candidates.
The annotated portion consists of74 paragraphs with 395 candidates.The third data set comes from the managementsuccession domain used in the Sixth Message Un-derstanding Conference (MUC-6, 1995).
We extractfrom the original data set al sentences that weretagged with a management succession event, and useas candidates all tagged strings in those sentences.This domain has four target slots, namely PersonIn(the person moving into a new position), PersonOut(the person leaving a position), Org (the corpora-tion?s name) and Post (the position title).
Sentencescontaining candidates with multiple labels (candi-dates annotated as both PersonIn and PersonOut) arediscarded.
The extracted data set consists of 757sentences with 2288 candidates.7.2 FeaturesTo extract features for candidates, we first normal-ize each word to its lower-case, with digits replacedby the token digit.
We extract the following fea-tures for every candidate: the candidate phrase it-self, its head word, the unigram and bigram be-fore and after the candidate in the sentence whereit appeared, its entity type (person, location, or-ganization, and date/time), as well as features de-rived from dependency parse trees.
Specifically, wefirst apply the Stanford lexical parser to our data(de Marneffe et al, 2006).
Then for each candi-date, we follow its dependencies in the correspond-ing dependency parse tree until we find a relationr ?
{nsubj, csubj, dobj, iobj, pobj} in which thecandidate is the dependent.
We then construct a fea-ture (r, v) where v is governor of the relation.7.3 Evaluation Baseline and MethodWe use the standard K-means algorithm (Macqueen,1967) as a non-generative baseline, since K-means iscommonly used for clustering.
To evaluate cluster-ing results, we match each slot in the labeled data tothe cluster that gives the best F1-measure when eval-uated for the slot.
We report the precision (P), re-call (R) and F1-measure for individual slot labels, aswell as the macro- and micro- average results acrossall labels for each experiment.
We conduct 10 trialsof experiment on each model and each data set withdifferent random initializations.
We report the trialsthat give the smallest within-cluster sum-of-squares(WCSS) distance for K-means, and those that givethe highest log-likelihood of data for all other mod-els.
Experimental trials are run until the change inWCSS/log-likelihood between two EM iterations issmaller than 1 ?
10?6.
All trials converged within30 minutes.All models we evaluate involve a parameter K,which is the number of values that y can take on.The value of K is manually fixed in this study.
Asnoted, we use a garbage slot to capture irrelevantcandidates, thus the value of K is set to the numberof target slots plus 1 for each data set.
We empir-ically set the adjustable parameters in the proposedprior, and the weight of the regularization term in thelocally normalized logistic regression model (Berg-Kirkpatrick et al, 2010), denoted by ?.
Exact set-tings are given in the next subsection.
Note that thefocus of our experiments is on evaluating the effec-tiveness of the proposed prior.
We leave the task oflearning the various parameter values to future work.7.4 ResultsEvaluation on existing generative modelsWe first evaluate the existing generative modelsdescribed in Section 5 with the multinomial prior.Table 1 summarizes the performance of Naive Bayes(NB), the Bernoulli mixture model (BMM), theGaussian mixture model (GMM), the locally nor-malized logistic regression (LNLR) model, and K-means.
We only show the F1 measures in the tabledue to space limit.We first observe that NB does not perform wellfor our task.
LNLR, which is an interesting contri-bution in its own right, does not seem to be suitablefor our task as well.
While NB and LNLR are infe-rior to K-means for all three data sets, BMM showsmixed results.
Specifically, BMM outperforms K-means for aviation incidents, but performs poorlyfor seminar announcements.
GMM and K-meansachieve similar results, which is not surprising be-cause K-means can be viewed as a special case ofthe spherical GMM we used (Duda et al, 2001).Overall speaking, results show that GMM is thebest among the four generative models for the distri-820(a) Results on seminar announcements.
No macro- and micro-average result is reportedfor NB and BMM as they merged the etime cluster with the stime cluster.
Numbers inbrackets are the respective measures of the stime cluster when evaluated for etime.Model stime etime speaker location Macro-avg Micro-avg ParameterNB 0.558 (0.342) 0.276 0.172 ?
?
NilBMM 0.822 (0.440) 0.412 0.402 ?
?
NilGMM 0.450 0.530 0.417 0.426 0.557 0.455 NilLNLR 0.386 0.239 0.200 0.208 0.264 0.266 ?
= .0005K-means 0.560 0.574 0.335 0.426 0.538 0.452 Nil(b) Results on aviation incidents.
Target slots are airline (AL) , flight number (FN), aircraftmodel (AC), location (LO) and country (CO).Model AL FN AC LO CO Macro-avg Micro-avg ParameterNB 0.896 0.473 0.676 0.504 0.533 0.618 0.628 NilBMM 0.862 0.794 0.656 0.695 0.614 0.741 0.724 NilGMM 0.859 0.914 0.635 0.576 0.538 0.730 0.692 NilLNLR 0.597 0.352 0.314 0.286 0.291 0.379 0.396 ?
= .0005K-means 0.859 0.936 0.661 0.576 0.538 0.729 0.701 Nil(c) Results on management succession events.
Target slots are person joining (PersonIn),person leaving (PersonOut), organization (Org), and position (Post).Model PersonIn PersonOut Org Post Macro-avg Micro-avg ParameterNB 0.545 0.257 0.473 0.455 0.459 0.437 NilBMM 0.550 0.437 0.800 0.767 0.650 0.648 NilGMM 0.583 0.432 0.813 0.803 0.679 0.676 NilLNLR 0.419 0.245 0.319 0.399 0.351 0.346 ?
= .0002K-means 0.372 0.565 0.835 0.814 0.645 0.665 NilTable 1: Performance summary of the different generative models and K-means in terms of F1.Data set Parameter ValueSeminar announcements {?k}4k=1 {2}4k=1{?k}4k=1 {1}4k=1Aviation incidents {?k}5k=1 {1}5k=1{?k}5k=1 {1}5k=1Management succession {?k}4k=1 {1,2,2,2}{?k}4k=1 {1,2,2,2}Table 2: Parameter settings for p(yi; ?
).bution p(x|y; ?).
We proceed with incorporating theproposed prior into GMM for further explorations.Effectiveness of the proposed priorWe evaluate the effectiveness of the proposedprior by combining it with GMM.
Specifically, thecombined model follows Eq.
(1), with p(yi; ?)
com-puted using the Poisson-based formula in Eq.
(3) andp(xi,j |yi,j ; ?)
following Eq.
(6) as in GMM.We empirically determine the parameters used inp(yi; ?)
to maximize data?s log-likelihood as noted.Table 2 reports the values of {?k}K?1k=1 and {?k}K?1k=1for different data sets.
Recall that ?k specifies themaximum number of candidates that the k-th slot cangenerate, and its value is observed to be small in realdata.
?k specifies the expected number of candidatesthat the k-th slot will generate.Table 3 reports the performance of the combinedmodel (?GMM with prior?)
on the three data sets,along with results of GMM and K-means for easycomparison.
The combined model improves overboth GMM and K-means for seminar announce-ments and aviation incidents, as can be seen from themodels?
macro- and micro-average performance.The advantages brought by the proposed prior aremainly reflected in slots that are difficult to clus-ter under GMM and K-means.
Taking seminar an-nouncements as an example, GMM and K-meansachieve high precision but low recall for stime, andlow precision but high recall for etime.
When exam-ining the clusters produced by these two models, wefound one small cluster that contains mostly stimefillers (thus high precision but low recall), and an-other much larger cluster that contains mostly etimefillers together with most of the remaining stimefillers (thus low precision but high recall for etime).821(a) Results on seminar announcements.Model Metric stime etime speaker location Macro-avg Micro-avgGMM with Prior P 0.964 0.983 0.232 0.253 0.608 0.416R 0.680 0.932 0.952 0.481 0.761 0.738F1 0.798 0.957 0.374 0.331 0.676 0.532GMM P 1.000 0.362 0.300 0.436 0.524 0.407R 0.291 0.984 0.686 0.416 0.594 0.518F1 0.450 0.530 0.417 0.426 0.557 0.455K-means P 0.890 0.434 0.222 0.436 0.496 0.389R 0.408 0.847 0.679 0.416 0.588 0.541F1 0.560 0.574 0.335 0.426 0.538 0.452(b) Results on aviation incidents.Model Metric AL FN AC LO CO Macro-avg Micro-avgGMM with Prior P 1.000 1.000 1.000 0.741 0.833 0.915 0.908R 0.753 0.877 0.465 0.588 0.727 0.682 0.673F1 0.859 0.935 0.635 0.656 0.777 0.782 0.773GMM P 1.000 1.000 1.000 0.563 0.433 0.799 0.724R 0.753 0.842 0.465 0.588 0.709 0.672 0.664F1 0.859 0.914 0.635 0.576 0.538 0.730 0.692K-means P 1.000 0.981 0.830 0.563 0.433 0.761 0.711R 0.753 0.895 0.549 0.588 0.709 0.699 0.691F1 0.859 0.936 0.661 0.576 0.538 0.729 0.701(c) Results on management succession events.Model Metric PersonIn PersonOut Org Post Macro-avg Micro-avgGMM with Prior P 0.458 0.610 0.720 0.774 0.640 0.642R 0.784 0.352 0.969 0.846 0.738 0.731F1 0.578 0.447 0.826 0.809 0.686 0.683GMM P 0.464 0.605 0.725 0.792 0.647 0.648R 0.782 0.336 0.925 0.815 0.715 0.707F1 0.583 0.432 0.813 0.803 0.679 0.676K-means P 0.382 0.515 0.733 0.839 0.607 0.639R 0.363 0.625 0.969 0.791 0.687 0.693F1 0.372 0.565 0.835 0.814 0.645 0.665Table 3: Comparison between the combined model (GMM with the proposed prior), GMM and K-means.This shows that GMM, when used with the multi-nomial prior, and K-means have difficulties sepa-rating candidates from these two slots.
In contrast,the combined model improves the recall of stime to68%, as compared to 29.1% achieved by GMM withthe multinomial prior and 40.8% by K-means, with-out sacrificing precision.
It also improves the preci-sion of etime from 36.2% to 98.3%.For aviation incidents, the advantage of the pro-posed prior is reflected in the location (LO) andcountry (CO) slots, which may confuse the variousmodels as they both belong to the entity type loca-tion.
The proposed prior improves the precision ofthese two slots greatly by trying to distribute theminto appropriate slots in the clustering process.The three models achieve very similar perfor-mance on management succession events as Ta-ble 3(c) shows.
Surprisingly, incorporating thePoisson-based prior into GMM does not seem usefulin separating PersonIn and PersonOut slot fillers.
Toinvestigate the possible reasons for this, we exam-ine feature values in the centriods of the two clusterslearned by the three models.Tables 4 and 5 respectively list the top-10 featuresin the PersonIn cluster and the PersonOut clusterlearned by the combined model1, and their corre-sponding values in the centriods of the two clusters.The two clusters share 3 of the top-5 features, some1We made similar observations from centriods learned inGMM and K-Means, which are therefore not reported here.822Values in the centriod of:Top-10 features PersonIn PersonOuttype:?person?
0.9985 1unigram after:, 0.7251 0.3404unigram before:?s?
0.2705 0bigram after:, ?digits?
0.2105 0.1879bigram after:, who 0.1404 0.0567unigram before:, 0.1067 0.0035dobj:succeeds 0.0906 0unigarm before:succeeds 0.0892 0nsubj:resigned 0.0746 0.0284unigram before:said 0.0673 0Table 4: Top-10 features in the PersonIn cluster, aslearned by GMM with the proposed prior.of them being general context features that might nothelp characterizing candidates from different slots(e.g.
the unigram after the candidate is a comma).Both lists also contain features from dependencyparse trees.
Note that the ?dobj:succeeds?
featurein the PersonIn cluster is in fact contributed by Per-sonOut slot fillers, while the ?nsubj:succeeds?
fea-ture in the PersonOut cluster is contributed by Per-sonIn slot fillers.
Although listed among the top-10, these features have relatively low values in thelearned centriods (about 0.1).
These observationsmay suggest that the management succession dataset lacks strong, discriminative features for all mod-els to effectively distinguish between PersonIn andPersonOut candidates in an unsupervised manner.To conclude, the proposed prior is effective in as-signing different but confusing candidate slot fillersinto appropriate slots, when there exist reasonablefeatures that can be exploited in the label assign-ment process.
This is evident by the improvementsthe proposed prior brings to GMM in the seminarannouncement and aviation incident data sets.8 ConclusionsWe propose a generative model that incorporatesdistributional prior knowledge about template slotsin a document for the unsupervised IE task.
Specifi-cally, we propose a Poisson-based prior that preferslabel assignments to cover more distinct slots in thesame document.
The proposed prior also allows aslot to generate multiple fillers in a document, up toa certain number of times depending on the domainof interest.We experimented with four existing generativeValues in the centriod of:Top-10 features PersonOut PersonIntype:?person?
1 0.9985unigram before:mr. 0.9894 0bigram before:?s?
mr. 0.5213 0unigram after:, 0.3404 0.7251bigram after:, ?digits?
0.1879 0.2105unigram after:was 0.1667 0.0556nsubj:president 0.1667 0.0117nsubj:succeeds 0.1028 0.0102bigram before:, mr. 0.0957 0unigram after:?s 0.0745 0.0073Table 5: Top-10 features in the PersonOut cluster, aslearned by GMM with the proposed prior.models for the task of clustering slot fillers witha multinomial prior, which assumes that labels aregenerated independently in a document.
We thenevaluate the effectiveness of the proposed prior byincorporating it into the Gaussian mixture model(GMM), which is shown to be the best among thefour existing models in our experiments.
By incor-porating the proposed prior into GMM, we can ob-tain significantly better clustering results on two outof three data sets.Further improvements to this work are possible.Firstly, we assume that some adjustable parametersin the proposed prior can be manually fixed, such asthe number of template slots in the output and themaximum numbers of fillers that can be generatedby different slots.
We are looking into methods forautomatically learning such parameters.
This willhelp improve the applicability of our work to differ-ent domains as an unsupervised model.
Secondly,we currently consider in the prior a probability dis-tribution over all possible label assignments for ev-ery document.
This can be computationally expen-sive if input documents are long, or when we aimto discover large templates with large values of K.An alternative is to consider an approximate solutionthat evaluates, for instance, only the top few label as-signments that are likely to maximize the likelihoodof our observations.
This remains as an interestingfuture work of this study.AcknowledgmentsThis work is supported by DSO National Laborato-ries.
We thank the anonymous reviewers for theirhelpful comments.823ReferencesMichele Banko, Michael J Cafarella, Stephen Soderland,Matt Broadhead, and Oren Etzioni.
2007.
Open infor-mation extraction from the web.
In International JointConference on Artificial Intelligence, pages 2670?2676.Taylor Berg-Kirkpatrick, Alexandre Bouchard-Co?te?,John DeNero, and Dan Klein.
2010.
Painless unsuper-vised learning with features.
In Proceedings of HumanLanguage Technologies: The 2010 Annual Conferenceof the North American Chapter of the Association forComputational Linguistics, pages 582?590.Marie-Catherine de Marneffe, Bill MacCartney, andChristopher D. Manning.
2006.
Generating typeddependency parses from phrase structure parses.
InLREC.A.
P. Dempster, N. M. Laird, and D. B. Rubin.
1977.Maximum likelihood from incomplete data via the EMalgorithm.
Journal of the Royal Statistical Society.
Se-ries B (Methodological), 39(1):1?38.Gregory Druck, Gideon Mann, and Andrew McCallum.2008.
Learning from labeled features using gener-alized expectation criteria.
In Proceedings of the31st annual international ACM SIGIR conference onResearch and development in information retrieval,pages 595?602.Richard O. Duda, Peter E. Hart, and David G. Stork.2001.
Pattern classification.
Wiley-Interscience, 2ndedition.Elena Filatova, Vasileios Hatzivassiloglou, and KathleenMcKeown.
2006.
Automatic creation of domaintemplates.
In Proceedings of the COLING/ACL onMain conference poster sessions, COLING-ACL ?06,pages 207?214, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Jenny Rose Finkel, Trond Grenager, and ChristopherManning.
2005.
Incorporating non-local informationinto information extraction systems by gibbs sampling.In Proceedings of the 43rd Annual Meeting of the As-sociation for Computational Linguistics, pages 363?370.Dayne Freitag and Andrew Kachites McCallum.
1999.Information extraction with HMMs and shrinkage.
InProceedings of the AAAI-99 Workshop on MachineLearning for Information Extraction.Joa?o Grac?a, Kuzman Ganchev, and Ben Taskar.
2007.Expectation maximization and posterior constraints.In Proceedings of the Twenty-First Annual Conferenceon Neural Information Processing Systems.Takaaki Hasegawa, Satoshi Sekine, and Ralph Grishman.2004.
Discovering relations among named entitiesfrom large corpora.
In Proceedings of the 42nd An-nual Meeting on Association for Computational Lin-guistics, page 415, Morristown, NJ, USA.
Associationfor Computational Linguistics.J.
B. Macqueen.
1967.
Some methods for classificationand analysis of multivariate observations.
In Proceed-ings of the Fifth Berkeley Symposium on MathematicalStatistics and Probability, Volume 1, pages 281?297.Zvika Marx, Ido Dagan, and Eli Shamir.
2002.
Cross-component clustering for template induction.
In Pro-ceedings of the 2002 ICML Workshop on Text Learn-ing.MUC-6.
1995.
Proceedings of the Sixth Message Under-standing Conference.
Morgan Kaufmann, San Fran-cisco, CA.Benjamin Rosenfeld and Ronen Feldman.
2006.
URES: An unsupervised Web relation extraction system.In Proceedings of the 21st International Conferenceon Computational Linguistics and 44th Annual Meet-ing of the Association for Computational Linguistics,pages 667?674.Satoshi Sekine.
2006.
On-demand information extrac-tion.
In Proceedings of the COLING/ACL Main con-ference poster sessions, pages 731?738.Yusuke Shinyama and Satoshi Sekine.
2006.
Preemptiveinformation extraction using unrestricted relation dis-covery.
In Proceedings of the Human Language Tech-nology Conference of the North American Chapter ofthe Association for Computational Linguistics, pages304?311.Kiyoshi Sudo, Satoshi Sekine, and Ralph Grishman.2003.
An improved extraction pattern representationmodel for automatic ie pattern acquisition.
In Pro-ceedings of the 41st Annual Meeting on Associationfor Computational Linguistics - Volume 1, ACL ?03,pages 224?231, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Wikipedia.
2009.
List of accidents andincidents involving commercial aircraft.http://en.wikipedia.org/wiki/List of accidents andincidents involving commercial aircraft.Yulan Yan, Naoaki Okazaki, Yutaka Matsuo, ZhengluYang, and Mitsuru Ishizuka.
2009.
Unsupervised re-lation extraction by mining Wikipedia texts using in-formation from the web.
In Proceedings of the 47thAnnual Meeting of the ACL and the 4th IJCNLP of theAFNLP.824
