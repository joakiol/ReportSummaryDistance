Connectivity in Bag GenerationArturo  Tru j i l l o  and  S imon Ber ry*School  of Computer  and Mathem~t ica l  Sc iencesThe  Rober t  Gordon  Univers i ty ,  St Andrew St reetAberdeen A l / l  1 f igScot land{iat,cs5s by } (c~_ sct us.
vgu.ac, ul<Abst ract'Fhis l)aper presents a pruning tech-nique which can bc used to reduce thenumber of paths searched in rule-basedb~g generators of the type proposed by(Poznafiski el; al., 1!
)95) and (l'opowMl,1995).
Pruning the search space in thesegenerators is important given the.
com-putational cost of bag generation.
'rhetechnique relies on a connectivity con-straint between the semantic indices as-sociated with each lexical sign in a ba R.Testing the algorithm on a range of sen-tences shows reductions in the~ genera-tion time and the nmnber of edges con-stru cl.cd.1 I n t roduct ionBag generation is a form of natural language gel>er;ttion in which the input is ;~ bag (Mso known asa inultiset: a set in which rcpe~ted elements aresignificant) of lexicM elements and the output is agrammatical sentence or a statistically most prob-able permutation with respect to some.
bmguagemodel.Bag generation has been considered within thest~tistieal and rule-based paradigms of computa-tional linguistics, and catch has handled this prob-lem differently (Chen and Lee, 1994; Whitelock,1994; Popowich, 1995; Tn0illo , 1995).
This pa-per only considers ruh' based approaches to thisproblem.Bag generation has received particulm: atten-tion in lexicalist approaches to MT, as exempli-tied by Shake-and-Bake generation (Beaven, 1992;Whitelock, 1994).
One can also envisage applica-tions of bag generation to generation fi'om mini-*Now at S\[1ARP L~tboral, ories of I"mrope, Ox-h)rd Science \[)ark, Oxford OX4 4CA.
E-ma~il:simon~sh~Lrp.co, nktmdly recursiw', semantic ropresentactions (Cope.s-take ct al., 1995) and other semantic fi'ameworkswhich separate scoping fi'om content information(l{eyle, 1995).
ht these frameworks, the unorderednatllFe ()f predicate or relation sets makes the aI>plict~tion o\[' bag generation techniques attra.ctiw:.A notational convention used in the I)al)er isthat items such as 'dogt' stand for simplitied lex-ical signs of the.
form (Shieber, 198(0:SI'M - -  \[ ttl/I,N = dog  \].
.
.
.
\[ attc:~l = 1 JIn such signs, the semantic argument will be re-ferred to as an qndex' and will be shown as nsubscril)t o a lexeme; in the above exmnple, theindex has been giwm the unique type 1.The term index is borrowed rl'Olll IIPSG (Pol-lard and Sag, 1994) where indices ~u'e used as ar-guments to relations; however these indices tnayalso be equated with dis(-onrse referents in l)lt:I'(Kamp and I{eyle, 1993).
As with most lexical-ist generators, emantic variables ttttlSl; \[)c distin-guished in order to disallow tr;mslationally incor-rect permutations of the target bag.
We distin-guish variables by uniquely typing them.Two assumptions are made regarding \[cxieal-semantic indexing.Assmnpt ion  1 All lea'teal signs must be indexed,including fltnetional and nonprcdicative lements(Calder cl al., 1989).Assumpt ion  2 All le.~ical signs must be con-necled to each other.
7'wo lea:ical signs arc con-nected if they are directly connected; furthermore,the connectivity rclation is h'an.silivc.Def in i t ion 1 7'wo signs, A, 11, are directly con-nccled if there cxisl at least two paths, PathA,Palht3, such that A:PathA is token identical withB:PathB.The indices involved in determining connec-tivity arc; specified as pa.rameters for a pro._ticul;tr formalism, l'k)r exanq)le, in tlPSG,!01play a major role in preventing the generation ofincorrect ranslations.\[CAT=S 1 ~ \[oKr=NP l \[O~T=VP 1) \[SEM=E~\]J LS~M:A~G1 :=~\] L~:M=IEL.,,~o'~=IIljj\[CAT=NP\] \[CAT=Det 1 rcA~'=Na \]2) L~.=I ~ j ~ Ls,~:.,,,~ ~ =l~l L~E~=@\[,,~<----V1\]\]\[CAT=N1\] 3) \ [~ ,_~ j\[oa,,=m\]\[OAT=Eli\ [cKr=PP\]\[CAT=vPlFigureCAT= A \[CAT---- N1SEM:ARG1 :~\ ]  \]CAT= N1 \[OAT = PPSI,'M: ARG1 ~\[~\]\] \]\[ CAT = N 1\[ OA'I'= P \[SEM__@~^lm3~\]\[ --=~J\] \[CAT=NP \]CAT= Vtra rCAT=N p \]1: Simple unification grammar.It will be shown that it is possible to exploitthe connectivity Assumption 2 above in order toachieve a reduction in the number of redundantwfss constructed by both types of generator de-scribed in section 2.3.1 Using Connect iv i ty for Prun ingTake the following bag:Ex.
2 {dogl,thcl,brown:,big:}(corresponding to 'the big brown dog').
Assumethat the next wfss to be constructed by the gen-erator is the NP 'the dog'.
Given the grammarin Figure 1, it is possible to deduce that 'brown'can never be part of a complete NP constructedfrom such a substring.
This can be determinedas follows.
If this adjective were part of such asentence, 'brown' would have to appear as a leafin some constituent that combines with 'the dog'or with a constituent containing 'the dog'.
Fromthe grammar, the only constituents that can com-bine with 'dog' are VP, Vtra and P. However,none of these constituents can have 'brownl'  asa leaf: ill the case of P and Vtra this is trivial,since they are both categories of a ditferent lexi-cal type.
In the case of the VP, 'brownl'  cannotappear as a leaf either because expansions of theVP are restricted to NP complements with 2 astheir semantic index, which in turn would also re-quire adjectives within them to }lave this index.l,'urthermore, 'brown1' cannot OCCUr as a loaf ina deel)er constituent in the VP t)ecause such anoccurrence would be associated with a differentindex.
In such cases 'brown' would modify a dif-ferent noun with a different index:Ex.
a { the\], dog\] , withl ,2 , the~ , lnvwn2 , collar2}A naive implementation f this deduction wouldattempt to expand the VP depth-ill'st, left toright, ill order to accommodate 'brown' in a com-plete derivation.
Since this would not be possible,the NP 'the dog' would be discarded.
This ap-proach is grossly inefficient however.
What is re-quired is a more tractable algorithm which, givena wfss and its associated sign, will be able to deter-mine whether all remaining lexical elements canever form part of a complete sentence which in-cludes that wfss.Note that deciding whether a lexical sign canappear outside a phrase is determined purely bythe grammar, and not by whether the lexical ele-ments share the same index or not.
Thus, a morecomplex grammar would allow 'the man'  from thebagEx.
4 {thel,manl,shaves<l,\],himselfl}even though 'himself' has the same index as 'theI I lan'.3.2 Outer  DomainsThe approach introduced here compiles the rel-evant information of\[line fi'om the grammar anduses it to check for connectivity during bag gener-ation.
The compilation process results in a set of(Sign,Lex,Bindings) triples called outer domains.
'l'his set is based on a unification-based phrasestructure grammar defined as follows:Def in i t ion  2 d grammar is a tuple (N, 7;P,S),where P is a sct of productions ce ~ /3, a is asign, /3 is a list of signs, N is the set of all ee, Tis the set of all signs appearing as elements of \[3which unify with lexical entries, and S is the startsign.Outer domains are defined as follow:Def in i t ion  3 {(Sign,  Lcx, Binds) I Sign C N tOT, Lcx ~ T and there exists a derivationOe ~ /31Signt /32 Le J  /33 or a ~ f11Lez\] /32,S'iqnl /33,and Sign' a unifier for  Sign, Lez j a unifierfor Lcx, and Binds the set of all path pairs<SignPath, LexPalh> such thai Sign':SignPath isIoken identical with LezS :LexPath}Intuitively, the outer domains indicate thatpreterminal category Lex ('an appear in a com-plete sentence with subconstituent Sign, such thatl,cx is not a leaf of Sign.
Using ideas from dataflow analysis (Kennedy, 1981), predictive parserconstructions (Aho et al, 1986) and feature gram-mar compilation (Trujillo, 1994) it is possible toconstruct such a set of triples.
Outer domainsthus represent elements whi(:h may lie outside asubtree of category Sign in a complete sentential103they would be indicated through paths such asSYNSEM :LOCAL:CONTI,INT:INI) EX.
'\[b ensure that only connected lexical signs aregenerated and analysed, the following assumt)tionmust also be made:Assumpt ion  3 A grammar will only generate oranalyse connected lexical signs.2 Bag Generat ion  A lgor i thmsTwo main tyl)es of rule-based bag generators havebeen proposed.
The first type consists of a parsersuitably relaxed to take into account the un-ordered character of tile input (Whitelock, 1994;Popowich, 1995; Trujillo, 1995).
For example, ingenerators based on a chart 1)arser, the hm(tanmn-tal rule is applie(1 only when the edges to be ('om-bined share no \]exical leaves, in contrast to re-quiring that the two edges have source and targetnodes in common.
The other type of generator ap-plies a greedy algorithm to an initial solution inorder Co find a grammatical sentence (1)oznafiskiet al, 1.995).2.1 Redundancy  in Bag Generat ionOne disadvantage with the above generators isthat they construct a nnnd)er of strnctures whichneed Dot have been computed at all.
In buihl--ing these structures, the generator is e\[fcctivelysearching branches of the search space which neverlead to a COml)lete sentence.
Consider the the tbl-lowing input bag:{ dog, barked, the, brown, big}Previous rest,archers (Ih:ew, 1992; l)hillil)s, 1993)have noted that from such a lx~g, tile followingstrings ;u:e generated but none can fi)rtn part ofa (;omplete sentence (note that indices are omit-ted when there is no possibility of conrnsion; #indicates that the subs|ring will never be part of~ complete sentence):Ex.
1 # the dogthe dog barked# the brown dogFor simph'~ cases in chart based generators uchunnecessary strings do not create many problems,but for k)nger sentences, each additional su bstringimplies a further branclt in the search tree to beconsidered.Since tile (;Oml)Utational ('Oml)lexity of thegreedy bag generator (Poznafiski (% al., 1995) ispolynolni&l (i.e.
O(?,.d)), the cf\]'ect of ,'(~(hlnda,ltsul)structnres i not as detrimentM as for parserbased generators.
Neverthelc'ss, a (:ert~in am(rantof mmccesm~ry work is t)erformed.
'lk) show this,consider the test-rewrite sequence for l!'~xaml)h'.
I:Test: (log barked the brown bigR.ewrite: __ barked the dog brown bigTest: barked (the dog) brown bigRewrite:  __ (the dog) barked brown bigTest: ((the (log) barked) brown bigRewr i te :  the brown dog barked __ bigTest: ((the (brown (log)) harked)bigRewr i te :  tile big (brown dog) barked _.Test: ((the (big (brown clog))) barked) ('ter-minate)In this scqnence donble und(,rscorc (__.)
indi-cates the starting position of a moved constituent;the moved constituent i self is given in bold t~ce;the bracketing indicates analysed constituents (forexpository purposes the algorithm has been over-simplified, but the general idea remains the salne).Now consider the step where 'brown' is inserte(l1)etwe(;n '|tie' and 'dog'.
This action causes thecomplete structure for 'the dog barked' to be dis-carded and replaced with that for %he brown (togbarked', which in turn is discarded and replacedby 'the big brown dog barked'.2.2 Prev ious  WorkA number of prnning techniqtms have I)een sug-gested to re(hwe the mnom,t of redundancy in baggenerators.
Brew (19921 proposed a constraintpropagation technique which eliminates branchesduring I)ag generation by considering the nec-essary lh,~ctor-argument relationships that existbetween the component basic signs of categorialsigns.
These relationships form a graph indic:Lt-ing the necessary conditions for a lexical item toform part of a comt/h'.te sentence.
Such graphs can1)e use(l to elinlinate 1;he substrings in l'3xaml)le 1.Unh)rtunately the technique xploits specilic as-l)ects of categorial grammars an(l it is not <:learhow the.y may he used with other formalisms.Trujillo (1995) adapts some of Brew's ideas1,o phrase structure grammars by ('emil|ling l!
'oflow functions and constructing adjacency graphs.While this al)l)roach reduces the size of the searchsl)ace , it; does not prune it; sulllciently for cert,|inclasses of rood|tiers.Phillips (199'.
{) proposes handling ine\[ticiency ~1;the expense of completeness.
Ills idea is to main-l.a.il~ a queue, of rood|liable constituents (e.g.
N Is)in order to delay their combination with otherconstituents until rood|tiers (e.g.
Pl's) have beenana.lysed.
While practical, this approach can leadto alternative wdid sentences not being gen(;r;(.t(~(I.3 Connect iv i ty  Rest r i c t ionsIn scm('hing ILr a~ nmchanisIn that el i.li~,al.es untteCCssitry WISS, it will I)e l)ossible to use indices inlexical signs.
As lnenl;ione(\[ earlier, these indicesderivation.
The following definition specifies howouter domains are used:Def in i t ion4  A lexical sign Lea/ is in theouter domain of Sign' if\[ there is a triple(Sign,Lex, Binds) in outer domains such that Signand Lex unify with Sign I and Lez j respectively, andthere is at least one pair <PathS, PathL> E Bindssuch that Sign':PathS unifies with LezQPathL.In compiling outer domains, inner domains areused to facilitate computation.
Inner domains aredefined as follows:Def in i t ion  5 {(Sign, Lex, Binds) I Sign C N U T,Lex 6 7' and there exists a derivation (~ :~/31LezS f12, with Sign I a unifier for Sign, Le~ s a uni-fier for Lex, and Binds the set of all path pairs<SignPath, LexPath> such that Sign':SignPath istoken identical with LezS :LexPath}The inner domains thus express all the possibleterminal categories which may be derived fromeach nonterminal in the grammar.To be able to exploit connectivity during gen-eration, inner and outer domains contain onlytriples in which Binds has at least one element.In this way, only those lexical categories which aredirectly connected to the sign are taken into ac-count; the implication of this will become clearerlater.As an example, the outer domain of NP as de-rived from the above grammar is:(N P\[sem:arg l:X\],Vtra\[sem:arg2:Y\],{ <sem:argl.,sem:arg2 > } )(NP\[~em:arg~:X\],Vt~a\[sem :arga:Y\],{ <sem:argl,sem:arga > } )(NP\[~o,n:~rgl:X\],P\[~em:~rga:Y\],{ <sem:argl,sem:arg3> })This set indicates that for any NIP, the only ter-minal categories not contained in the subtree withroot NP, and with which the NP shares a seman-tic index, are Vtra and P. For instance, the firsttriple arises from the following tree:SNP/sem:argl:X\] VP\[sem:arg2:X\]Vt ra \ [sem:arg2:X\ ]  NPa.a P run ing  through Outer  Domains  andConnectivityThe pruning technique developed here operateson grammars whose analyses result in connectedleaves.Consider SOllle wfss W constructed from a bag Band with category C; this category, in the form ofa sign, will include syntactic and lexical-semanticinformation.
Such a wfss will have been con-structed during the bag generation process.
Now,either W includes all the input elements as leaves,in which case W constitutes a complete sentence,or there are elements in the input bag which arenot part of W. In the latter case, for bags obeyingAssmnption 2, the following condition holds forany W that can form part of a complete sentence:Cond i t ion  1 Let L be the set of leaves appearingin W, let a be the .graph (V, Fd, where V : {C3U B-  L, and E - -  { {x,y} \] x,y 6 Vand y is inthe outer domain of x}.
Then G is connected.
'lb show that; this condition indeed holds, con-sider a grammatical ordering of some input bagB, represented as the string W:ce.. T&.wBy Assumption 2, the lexical elements in the bag,and therefore in any grammaticM ordering of it,are connected.
Now consider educing this stringusing the production rule:D~75to give the string W':O~,.
D..o2In this case, the signs in W' will also be connected.This can be shown by contradiction:P roo f  1 Assume that there is some sign ~ in W'to which D is not connected.
Then grammar Gwould allow disconnected strings to be generated,contrary to Assumption 3.
7'his is because Dwould not be able to rewrite 7161 in such a waythat both daughters were connected to ~, leadingto a disconnected string.The situation in string W' is analogous to thatin Condition 1.
By identifying signs which aredirectly connected in E, it is possible to determinewhether g is connected and consequently whetherC can form part of a complete derivation, insteadof simply comparing the value of index paths, it ismore restrictive to use outer domains since theygive us precisely those elements which are directlyconnected to a sign and are in its outer domain.3.4 ExampleConsider P~xample 2.
'Ib eliminate the wfss'the dog' from further consideration, a connectedgraph of lexical signs is constructed before gen-eration is started (Figure 2).
This graph is builtby nsing the outer domain of each lexical elementto decide which of the remaining elements couldpossibly share an index with it in a complete sen-tence.1@4dog1big11LhcIbrown iFigure 2: Initial commcted graph.When a new wfss is constructed uring genera-|ion, say by application of the modified fimdame.n-tal rule or during the rewrite phase in a greedy al-gorithm, this initial graph is updated and testedfor connectivity.
If the updated graph is not con-neeted then the proposed wfss cannot form part ofa complete sentence.
Updating the graph involvesthree steps, l"irstly every node in the graph whichis a leaf' of tit(' new wfss is deleted, toge.t.lmr withits associated ares.
Secondly, a new node corre-sponding to tit(: new wNs is added to the graph.Finally, a new arc is added to the graph betweenthe uew node and every other node lying in itsouter domain.
The updated (disconnected) graphthat ensnes after constructing 'the clog' is shownin Figure 3; this NP is therefore rejected.%|it dog'lbig1 4 ~ brown1Figure 3: Updated disconnected graph after thewfss 'the dog' is constructed.4 Compiling ConnectivityDomainsFor reasons of space, the computation of outer do-mains cannot be described fully here.
The broadoutline, however, is as follows.
First, the innerdomains of the grammar are calculated.
This in-volves the calculation of the fixed point of setequations, analogous to those used in the con-struction of First sets for predictive parsers (Ahoet al, 1986; Trujillo, 1994).
Given the inner do-mains of each category in the grammar, the con-struction of the outer domains involves the com-putation of the lixed point of set equations relat-ing the outer domain of a category to the innerdomain of its sisters and to the outer domain ofits mother, in a manner analogous to the eoinpu-tation of Follow sets.I)uring computation, the set of Binds is mono-tonically increased as difDreut ways of directlyconnecting sign and lexeme arc found.5 ResultsThe abow~' pruning tcchnique has been tested onbags of different sizes including different combina-tkms of modifiers.
Sentences were generated usingtwo versions of a modified chart parser.
In one,ew'.ry inactive edge constructed was added to thechart.
In the.
other, every inactive edge was testedto see if it led to a disconnected graph; if it did,then the edge was discarded.
The results of theexperiment are shown in Table 1.
The implemen-tation was in Prolog on a Sun SpareS|at|on 10; thegeneration timings do not include garbage collec-tion time.
The grammar used for the experimentconsisted of simplified, feature-based versions ofthe 11) rules in GPSG; there were 18 rules and50 lexical entries.
Compilation of the outer do-mains for these rules took apt)roximately 37 min-utes, and the resulting set occupies 40K of men>ory.
In the general case, however, tile size of theouter domains is O(n2), where n is the numberof distinct signs; this number can be controlledby employing equivalence classes of different lev-els of specificity for pre-terminal and non-terminalsigns.Chart Gen. + PruningHag size Time Edgcs Time Edges2 0.1 15 8.1 154 0.3 37 (1.4 367 1.5 103 2.0 997 0.9 72 11.0 67I\] 5.1 213 3.9 13812 2.6 133 3.4 12315 9.0 294 7.2 18615 117.6 448 11.1 25317 2.3 126 2.6 1105'l'al~le 1: Effect of pruning (times in secs).Only one reading was generated for each bag,corresponding to one attachment site for PPs.
'l'he tMJe shows that the technique ctm yieht re-ductions in the number of edges (both active audinactive) and time taken, especially for longer sen-tences, while retaining the overheads at an accept-able level.6 ConclusionA technique fl)r pruning the search space of a baggenerator has been implemented and its usefulnessshown in Lhe geueration of different ypes of con-structions.
The technique relies on a connectivityconstraint imposed on the semantic relationships105expressed in the input bag.
In order to apply thealgorithm, outer domains needed to be compiledfrom the grammar; these are used to discard wfssby ensuring l'exical signs outside a wfss can indeedappear outside that string.Exploratory work employing adjacency con-straints during generation has yielded further im-provements in execution time when applied in con-junction with the pruner.
If extended appropri-ately, these constraints could prune the searchspace even further.
This work will be reportedat a later date.AcknowledgmentsTwo anonymous reviewers provided very usefulcomments; we regret not being able to do justiceto all their suggestions.Re ferencesA.
V. Aho, R. Sethi, and J. D. Ullman.
1986.Compilers - Principles, Techniques, and Tools.Addison Wesley, Reading, MA.J.
L. Beaven.
1992.
Lexicalist Unification BasedMachine Translation.
Ph.D. thesis, Depart-ment of Artificial Intelligence, University of Ed-inburgh, Edinburgh, UK.C.
Brew.
1992.
Letting the cat out of the bag:Generation for Shake-and-Bake MT.
In Pro-ceedings of the 14th COLING, pages 610-16,Nantes, France, August.J.
Calder, M. Reape, and H. Zeevat.
1989.
Analgorithm for generation in unification catego-rial grammar.
In Proceedings of the Fourth Eu-ropean Conference of the ACL, pages 233-40,Manchester, England, April.It.H.
Chen and Y.S.
Lee.
1994.
A corrective train-ing algorithm for adaptive learning in bag gen-eration.
In New Methods in Language Process-ing, Manchester, UK.A.
Copestake, D. Flickinger, R. Malouf, S. Riehe-mann, and I.
Sag.
1995.
Translation usingminimal recursion semantics.
In Proceedings ofthe 6th International Conference on Theoreticaland Methodological Issues in Machine Transla-tion, Leuven, Belgium, July.II.
Kamp and U. Reyle.
1993.
From Discourseto Logic - Introduction to Modeltheoretic Se-mantics of Natural Language, Formal Logic andDiscourse Representation Theory, volume 42 ofStudies in Linguistics and Philosophy.
KluwerAcademic, Dordrecht, The Netherlands.Ken Kennedy.
1981.
A survey of data flow analy-sis techniques.
In Muchnick and Jones (1981),chapter 1, pages 5-54.Steven S. Muchnick and Neil D. Jones, editors.1981.
Program Flow Analysis: Theory and Ap-plications.
Software.
Prentice-Hall, EnglewoodCliffs, NJ.J.
D. Phillips.
1993.
Generation of text from log-ical formulae.
Machine Translation, 8(4):209-35.C.
Pollard and I.
Sag.
1994.
Head Driven PhraseStructure Grammar.
Chicago University Press,IL.Fred Popowich.
1995.
Improving the efficiencyof a generation algorithm for Shake and Bakemachine translation using Head-Driven PhraseStructure Grammar.
In Proceedings of NaturalLanguage Understanding and Logic Program-ming V, Lisbon, Portugal, May.V.
Poznafiski, J. L. Beaven, and P. Whitelock.1995.
An efficient generation algorithm for lex-iealist MT.
In Proceedings of the 33rd AnnualMeeting of the Association for ComputationalLinguistics, Boston, MA, June.Uwe Reyle.
1995.
On reasoning with ambigui-ties.
In Proceedings of the Seventh Conferenceof the European Chapter of the Association forComputational Linguistics, pages 1-15, Dublin,Ireland, March.C.
J. Rupp, M. A. Rosner, and R. L. Johnson, ed-itors.
1994.
Constraints, Language and Com-putation.
Academic Press, London.S.
M. Shieber.
1986.
An Introduction toUnification-based Approaches to Grammar, vol-ume 4 of CSLI Lecture Notes.
CSLI, Stanford,CA.A.
Trujillo.
1994.
Computing FIRST and FOL-LOW functions for Feature-Theoretic gram-mars.
In Proceedings of the 15th COLING,pages 875-80, Kyoto, Japan, August.A.
Trujillo.
1995.
Lexicalist Machine Translationof Spatial Prepositions.
Ph.D. thesis, ComputerLaboratory, University of Cambridge, April.Pete Whitelock.
1994.
Shake-and-bake transla-tion.
In Rupp et al (1994), pages 339-59.106
