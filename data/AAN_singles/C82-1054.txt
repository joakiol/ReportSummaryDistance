COL1NG 82, J. Horecky, {e,L )North-Holland Publishing Company(~ Academia, 1982AN IMPROVED LEFT-CORNER PARSING ALGORITHMKenneth M. RossComputer Science LaboratoryCentral Research LaboratoriesTexas Instruments IncorporatedDallas, TexasU.S.A.This paper proposes a series of modif ications to the le f tcorner parsing algorithm for context-free grammars.
I tis argued that the resu l t inga lgor i thm is both e f f i c ientand f lex ib le  and is ,  therefore, a good choice for theparser used in a natural language interface.INTRODUCTIONGr i f f i ths  and Pet.rick (1965) propose several algorithms for recognizing sentencesof context- free grammars in the general case One of these algorithms, the NBT(Non-selective Bottom to Top) Algorithm, has since been cal led a " le f t - corner"algorithm.
Of la te ,  in terest  has been rekindled in le f t -corner  parsers.
Chester(1980) proposes a modif icat ion to the Gr i f f i ths  and Petrick algorithm which "com-bines phrases before i t  has found a l l  of the i r  components."
Slocum (1981) showsthat a le f t -corner  parser inspired by Gr i f f i ths  and Petr ick 's  algorithm and byChester's performs quite well when compared with parsers based on a Cocke-Kasami-Younger algorithm (see Younger 1967).This paper w i l l  propose modif ications to Gr i f f i ths  and Petr ick 's  NBT algorithmwhich resul t  in a more e f f i c ient  parsing algorithm.
A se lect ive version of thisnew algorithm has been implemented in Maclisp on a DEC 2060 and in Lisp MachineLisp on an LMI Lisp Machine.
I t  is being used as the context- free component ofa parser being used to bui ld natural language interfaces at Texas Instruments.This algorithm is l ike  the NBT algorithm and d i f fe rs  from Chester's in that i tdoes not require the grammar to be in a special format.
Any rule of a context-free grammar is acceptable.
The new algorithm builds on the Gr i f f i ths  andPetrick algorithm and is an extension of the algorithm proposed in Ross (1981).The algorithm given in Gr i f f i ths  and Petrick (1965) (henceforth G+P) is a rec-ognit ion algorithm, not a parsing algorithm.
Thus, i t  w i l l  only indicatewhether or not a str ing can be produced from a grammar.
I t  w i l l  not produce aparse tree.
Although algorithms to recognize or parse context- free grammars canbe stated in terms of push-down store automata, G+P state the i r  algorithm in termsof tur ing machines because the algorithm is easier to understand in these terms.A somewhat modified version of the i r  algorithm wi l l  be given in the next section.These modif ications transform the algorithm into a parsing algorithm and alsos impl i fy  i t  a b i t .The G+P algorithm employs two push down stacks.
The modified algorithm to begiven below w i l l  use three, cal led alpha, beta and gamma.
Turing machine instruc-tions are of  the fol lowing form, where A,B,C,D,E and F can be arb i t ra ry  str ings ofsymbols from the terminal and nonterminal alphabet.\[A,B,C\] --> \[D,E,F\] i f  "Conditions"This is to be interpreted as fol lows:333334 K,M.
ROSSI f  A is on top of stack alpha,B is on top of stack beta,C is on top of stack gamma,and "Conditions" are satisfiedthen replace A by D, B by E, and C by F.THE NBT ALGORITHMThe NBT algorithm is a nonselective version of the SBT (Selective Bottom to Top)algorithm, also given in G+P.
The only difference between the two is that theSBT algorithm employs a reachability matrix to selectively eliminate bad pathsbefore trying them.
For more on this, see G+P and Ross (1981).
For the purposeof this paper, i t  is not necessary to say anything more than that the addition ofa reachability matrix modifies the algorithm only slightly and serves only to makethe algorithm more efficient.A version of NBT modified to employ a third stack and to parse rather than recog-nize strings follows.
This algorithm will be modified further throughout hepaper.
(1) \[VI,X,Y\] --> \[~,V2 ... Vn,t X,A Y\]i f  A --> Vl V2 ... Vn is a rule ofthe phrase structure grammarX is in the set of nonterminals andY is anything(2) \[X,t,A\] --> \[A X,~,~\]i f  A is in the set of nonterminals(3) \[B,B,Y\] --> \[~,~,Y\]i f  B is in the set of nonterminals orterminalsTo begin, put the terminal s t r ing  to be parsed followed by END on stack alpha.Put the nonterminal which is to be the root node of the tree to be constructedfollowed by END on stack beta.
Put END on stack gamma.
The symbol t is neithera terminal nor a nonterminal.
I f  END is on top of each stack, the st r ing hasbeen recognized.
I f  none of the tur ing machine instruct ions apply and END is noton the top of each stack, the  path which led to this  s i tuat ion  was a bad path anddoes not y ie ld  a va l id  parse.The rules necessary to give a parse tree can be stated informal ly  ( i .e .
,  not interms of tur ing machine instruct ions)  as fo l lows:When ( I )  is appl ied,  attach V1 beneath A.When (3) is appl ied,  attach ~he B on alpha B as ther ight  daughter of the top,symbol on gamma.Note that there is a formal statement of the parsing version of NBT in Gr i f f i ths(1965).
However, i t  is somewhat more complicated and obscures what is  going onduring the parse.
Therefore, the informal procedure given above w i l l  be usedinstead.In tu i t i ve ly ,  what NBT does is put the symbols on alpha together in a bottom-upmanner with the ult imate goal of constructing a tree that has, at i t s  top, what-ever nonterminal symbol is on top of beta.
So, to parse a sentence of English,NBT would begin with the lex ica l  categories of the words to be parsed as asentence on alpha and the nonterminal "S" on beta.
An appl icat ion of  tur ingmachine inst ruct ion ( I )  reduces this  problem to a simpler one.
( I )  f inds somephrase structure rule containing the symbol that is on top of alpha immediatelyAN ff~PROVED LEFT-CORNER PARSING ALGORITHM 335af ter  the arrow.
So, i f  the f i r s t  symbol on alpha was "det" ,  the phrase s t ructureru le  NP --> det AdjP N would qua l i fy .
By th is  app l i ca t ion  of  ( I ) ,  the problemis reduced to bu i ld ing an AdjP and #inding an N from the symbols on alpha.
Onceth is  is done, the trees fo r  the "det" ,  the "AdjP" and the "N" would be combinedin to  an NP.
By app l i ca t ion  o f  (2) ,  the NP would be put on alpha.
Then a ru lewith NP immediately fo l low ing  the arrow would be looked fo r  so that  ( I )  couldapply again.NBT is a nondeterminist ic  a lgor i thm.
The nondeterminism comes from two places.F i r s t ly ,  ru le  ( I )  can apply in more than one way.
For th is  to happen, therewould need to be two phrase s t ructure  rules with the same nonterminal symbolimmediately a f te r  the arrow.
The fo l lowing two rules are an example o f  th is .X - -> Y Z1 Z2 Z3R - -> Y Rl X2Secondly, ru le  (3) and ru le ( I )  could apply in the same s i tuat ion .
In tu i t i ve ly ,an app l i ca t ion  of  ru le (3) indicates that  a t ree topped by node B was beingsearched fo r  and a tree topped by node B has been found~ so use the tree jus tfound as the tree that  was sought.
Rule ( I )  could apply as well i f  a phrases t ructure  ru le  of  the form X --> B Y1 Y2 .
.
.
Yn ex isted.
Applying ( I )  indicatesthat  the B being sought is not the B that  was jus t  bu i l t .
Rather, the B that  wasjus t  bu i l t  is an in i t ia l  subtree of  the B being sought.RULZS WITH ABBREVIATIONS~ important aspect o f  the modif ied algor ithm being proposed is that  i t  can deald i rec t ly  with rules which employ abbrev iatory  conventions which are u t i l i zed  byl ingu is ts .
Thus, parentheses (expressing opt iona lnodes)  and cur ly  brackets(expressing the fac t  that  one of  the set o f  nodes in brackets should be chosen)can appear in the rules that  the parser accesses when parsing a s t r ing .Assume ~hat ie f t  and r ight  parentheses are put o~ stack beta as separate elements.Also assume chat le f t  and r ight  cur ly  brackets are put on stack beta as separateitems.
Given these assumptions~ to modify NBT to handle rules with parenthesizedelements, the fo l lowing tur ing machine ins t ruct ions  must be added.
(4) IX, ( Cl C2 , .
.
Cn ),Y\]  --> IX,C\] C2 .
.
.
C,~,Y\](5) \ [X , (  C!
C2 .
.
.
Cn ),Y\] --~ \[X,~,V\]For a l l  i ,  Ci = ( Cj Cj+l .
.
.
Cp ) orC1 Cl+i .
.
.
Cm ~ orXi f  X is i.i the sec of  terminals .The f i r s t  ru le  w i l l  apply when the parenthesized node is present.
The second ru\]ew i l l  apply when the node is not present.
The Ci var iab le  handle cases o f  nestedparentheses or  cur ly  brackets.
In formal ly ,  a Ci is a var iab le  that  stands fo r  anonterminal,  a terminal ,  a le f t  parenthesis fol lowed by some number o f  expressionswhich are Ci 's  fol lowed by a r ight  parenthesis ,  or a le f t  cur ly  bracket fo l lowedby some number o f  expressions which are Ci 's  fol lowed by a r ight  cur ly  bracket.The fo l lowing rules are necessary to d i rec t ly  parse with rules containing cur lybrackeLs.
(6) \[X,{ C1 X,Y\] - -~ \ [X ,{ ,Y \ ](7) Ix,{ ~I x , , \ ]  --> \[X,Cl : ,v\]I f  X not = }(8) Ix , :  }ov\] .. .
.
\ [x,o,Y\](~  \[x~ < Cl } ,?
\ ]  - -> \[x,c~,Y\]336 K.M.
ROSS(I0) \[X,:  CI,Y\] --> \ [X , : ,?
\ ]where : is a special symbol which isneither a terminal or a nonterminal symbol,C1 is a Ci type var iable as defined ear l ie r .Once these modif ications are incorporated, the resul t ing algorithm wi l l  be moree f f i c ient  than i f  the NBT algorithm were used with abbreviated rules completelyexpanded into many d i s t inc t  rules.
To see why this  is so, consider a s i tuat ionin which there was a rule of the form X --> ~I A2 .
.
.
An (Z).
I f  th is  wasreplaced by two rules,  X --> A1 A2 .
.
.
An Z and X --> A1 A2 .
.
.
An, the parsewould have to be sp l i t  immediately upon encounteging X.
However, i f  the a l terna-t ive  solut ion being proposed were used, rather than parsing for  AI, A2 .
.
.
.
.
toAn twice, they would only be parsed for  once.
The parse path would not sp l i tunt i l  i t  came time to decide whether we wanted to look for  Z or not.
In general,every rule which has, fo l lowing the arrow, some number of ob l igatory  elementsfol lowed by a parenthesized element w i l l  resu l t  in a savings.
Thus, any such rulecan be parsed with more e f f i c ient ly  than the two rules ~t would be turned into i fparentheses were el iminated.
Note that the addit ional  cost here is quite small.For each parenthesized element, (4) and (5) w i l l  each apply once.
In the a l terna-t ive  so lut ion,  many rules might apply unnecessarily to the parse for  the nodeswhich came before the parenthesized node.There is a class of grammars for  which the solut ion proposed here w i l l  require ab i t  more work than the solut ion where parentheses are simply el iminated from thegrammar.
These are grammars that only have rules inwhich parenthesized itemscome f i r s t  and have no rules in which ob l igatory  items precede optional ones.
Ina grammar with both kinds of rules,  the savings made far  outweigh t~e amount ofextra work needed.
Since the classes of grammars used in parsing systemsgeneral ly have both kinds of rules,  my solut ion w i l l  resul t  in a savings forthese.
Note that a s imi lar  e f f i c iency  argument can be made for  the cur ly bracketcase.The above rules w i l l  handle a l l  occurrences of  parentheses and cur ly bracketsexcept for  those in which the item immediately fo l lowing the arrow in a phrasestructure rule is in parentheses or cur ly brackets.
The algorithm could bemodified to handle these cases d i rec t ly ,  however, th is  w i l l  not increasee f f ic iency.
Items in cur ly brackets or parentheses that immediately fo l low thearrow in a phrase structure rule must be expanded immediately upon encounteringthem.
There is no savings in postponing this  expansion unt i l  run time.
Puttingo f f  the choice of how to expand such a phrase structure rule w i l l  not al low pathsto be mergedtbgether.
Therefore, the best way to handle these is to expand a l lsuch rules into rules that do not have this  property.L ingu is t i ca l l y ,  the above is an interest ing resu l t .
Linguists have claimed thatuse of parentheses s impl i f ies  the grammar.
Since simpler grammars are preferredto more complex ones, a solut ion which collapses two rules to one by parenthesesis preferable to .a solut ion that has two d i s t inc t  rules.
In parsing, we see thatin many instanc'~s, the ~se of one rule with parentheses rather than two ruleswithout results in the parser operating more e f f i c ient ly .
I t  is able to mergeparse paths together which would have been d i s t inc t  had several context- f ree rulesnot been collapsed together as one, using the abbreviatory conventions.
Thus, anotat iona ldev ice  which was or ig ina l ly  proposed to s impl i fy  phrase structure rulesactua l ly  results in a more e f f i c ient  parse in many cases.
Therefore, at least forsome cases, we have addit ional  evidence for  the use of parentheses in phrasestructure rules.AN IMPROVED LEFT-CORNER PARSING ALGORITHM 337DEPTH OR BREADTH FIRST?There has of yet been no discussion of the order in which the algorithm proceeds.The statement of the algorithm is completely neutral in this respect.
However, animplementation must impose some control structure.
When a parse is started, thereis one 3-tuple containing the information on stacks alpha, beta, and gamma.
Ingeneral, there are many different rules of the parsing algorithm that can beapplied after this point.
In order to assure that all possible paths are pursuedto completion, i t  is necessary to proceed in a principled way.One strategy is to push one state as far as i t  wi l l  go.
That is, apply one ofthe rules that are applicable, get a new state, and then apply one of the appli-cable rules to that new state.
This can continue until either no rules apply or aparse is found.
I f  no rules apply, i t  was a bad parse path.
I f  a parse is found,i t  is one of possibly many parses for the sentence.
In either case, the algorithmmust continue on and pursue all other alternative paths.
An easy way to do thisand assure that al l  alternatives are pursued is to backtrack to the last choicepoint, pick another applicable rule, and continue in the manner described earl ier.By doing this until the parser has backed up through all  possible choice points,all parses of the sentence wil l  be found.
A parser that works in this manner isa depth-first backtracking parser.
This is probably the easiest control structureto use for a left-corner parser.Alternative control structures are possible.
For instance, rather than pursuingone path as far as possible, one could go down a parse path to some desireddistance, save that state for later, and come back up to the top and start someother parse path.
The original parse path could be pursued later from the pointat which i t  was stopped.
The problem with such an approach is keeping track ofall the options.In the algorithm being proposed here, the decision of whether the parse proceedsin a depth-first or breadth-first manner is governed by a parameter which isadjustable.
Thus, the parser can proceed to a setable depth down each parse pathbefore going off and pursuing others.
This mechanism works by saving the stateof the parser when i t  reaches the desired depth down a particular parse path.Once all paths are pursued to this depth, the parser is called again with each ofthe states that were saved.To enable the parser to function as described-above, the control structure for adepth-first parser described earl ier is used.
To introduce the ab i l i ty  to proceedin a breadth-first manner, the parser is only given a subset of the input string.Then, the item MORE is inserted after the last item that is given to the parser.I f  no other instructions apply and MORE is on top of stack beta, the parser mustbegin to backtrack as described earl ier.
Additionally, the state must be saved.Once all backtracking is completed, more input is put on beta and parsing beginsagain with each of the saved states.By changing the amount of input that is given, the degree to which the parser pro-ceeds either depth or breadth f i r s t  can be controlled.
I f  one word is given at atime, the parser is compleZely breadth-first.
I f  the entire sentence is given,i t  is completely depth-first.
Any other amount results in some combination of thetwo..
This mechanism enables the algor i thm to eas i ly  incorporate a wel l - formed substr ingtab le .
A l l  that  needs to be done is compare the set o f  saved states and merge theones that  have subgoals in common.
By set t ing  the parameter to d i f fe rent  values,the degree to which the wel l - formed substr ing table is  used can be cont ro l led .This is par t i cu la r ly  important in l ight  o f  Slocum's resu l ts  which ind icate  thatthe overhead involved in maintaining such a table can exceed the savings that  i t338 K.M.
ROSSgives.
By having the degree to which the table :s used be adjustable, the propersett ing can be determined, based on the grammar and the sorts of queries that areasked most often.Addi t ional ly ,  the algorithm can be used to process the sentence word by word as i tis typed in.
When used as the parser in a natural language interface,  this canincrease the speed of a parse since work can proceed as the user is typing andcomposing his input.Bibliography\[1\] Chester, D., A parsing algorithm that extends phrases, American Journal ofComputational L inguist ics,  6-2 (1980) 87-96.\[2\] Gr i f f i ths ,  T., On procedures for constructing structural  descriptions forthree parsing algorithms, Communications of the ACM, 8 (1965) 594.\[3\] Gr i f f i ths ,  T. and Petrick, S.R., On the re la t ive 'e f f i c ienc ies  of context-freegranTnar recognizers, Communications of the ACM, 8 (1965) 289-300.\[4\] Ross, K., Parsing English phrase structure, Ph.D. Dissertat ion, Dept.
ofL inguist ics,  Univ.
of Mass.
(Sept. 1981).\[5\] Slocum, J .
,  A pract ical  comparison of parsing strategies,  Proceedings of the19th Annual Meeting of the ACL, (1981) 1-6.\[6\] Younger, D., Recognition and parsing of context-free language in time n3,Information and Control I0 (1967) 189-208.
