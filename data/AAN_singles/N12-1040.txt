2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 372?376,Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational LinguisticsEvaluating a Morphological Analyser of InuktitutJeremy Nicholson?, Trevor Cohn?
and Timothy Baldwin?
?Department of Computing and Information Systems, The University of Melbourne, Australia?Department of Computer Science, The University of Sheffield, UKjeremymn@csse.unimelb.edu.au, tcohn@dcs.shef.ac.uk, tb@ldwin.netAbstractWe evaluate the performance of an morpho-logical analyser for Inuktitut across a medium-sized corpus, where it produces a useful anal-ysis for two out of every three types.
Wethen compare its segmentation to that of sim-pler approaches to morphology, and use theseas a pre-processing step to a word alignmenttask.
Our observations show that the richer ap-proaches provide little as compared to simplyfinding the head, which is more in line withthe particularities of the task.1 IntroductionIn this work, we evaluate a morphological analyserof Inuktitut, whose polysynthetic morphosyntax cancause particular problems for natural language pro-cessing; but our observations are also relevant toother languages with rich morphological systems.The existing NLP task for Inuktitut is that of wordalignment (Martin et al, 2005), where Inuktitut to-kens align to entire English clauses.
While Langlaiset al (2005) theorises that a morphological analysercould aid in this task, we observed little to no im-provement over a baseline model by making use ofits segmentation.
Nonetheless, morphological anal-ysis does provide a great deal of information, but thetask structure tends to disprefer its contribution.2 Background2.1 InuktitutInuktitut is a macrolanguage of many more-or-lessmutually intelligible dialects (Gordon, 2005).
Themorphosyntax of Inuktitut is particularly marked bya rich polysynthetic suffixing morphology, includingincorporation of arguments into verbal tokens, as innatsiviniqtulauqsimavilli in (1).
This phenomenoncauses an individual token in Inuktitut to be approx-imately equivalent to an entire clause in English.
(1) natsiq-seal-viniq-meat-tuq-eat-lauq-before-sima-ever-vitINT-2s-libut?But have you ever eaten seal meat before?
?Lowe (1996) analyses the morphology as a four-place relationship: one head morpheme, zero ormore lexical morphemes, one or more grammaticalmorphemes, and an optional enclitic.
The morpho-tactics causes, amongst other phenomena, the finalconsonant of a morpheme to assimilate the mannerof the initial consonant of the following morpheme(as in -villi), or to be dropped (as in natsiviniq-).Consequently, morphemes are not readily accessiblefrom the realised surface form, thereby motivatingthe use of a morphological analyser.2.2 Morphological analysisFor many languages with a less rich morphol-ogy than Inuktitut, an inflectional lexicon is of-ten adequate for morphological analysis (for exam-ple, CELEX for English (Burnage, 1990), Lefff forFrench (Sagot et al, 2006) or Adolphs (2008) forGerman).
Another typical approach is to performmorphological analysis at the same time as POS tag-ging (as in Hajic?
and Hladka?
(1998) for the fusionalmorphology in Czech), as it is often the case that372determining the part-of-speech and choosing the ap-propriate inflectional paradigm are closely linked.For highly inflecting languages more generally,morphological analysis is often treated as a segment-and-normalise problem, amenable to analysis byweighted finite state transducer (wFST), for exam-ple, Creutz and Lagus (2002) for Finnish.3 Resources3.1 A morphological analyser for InuktitutThe main resource that we are evaluating in thiswork is a morphological analyser of Inuktitut calledUqa?Ila?Ut.1 It is a rule-based system based on reg-ular morphological variations of about 3200 head,350 lexical, and 1500 grammatical morphemes, withheuristics for ranking the various readings.
The headand lexical morphemes are collated with glosses inboth English and French.3.2 Word alignmentThe training corpus we use in our experiments is asentence-aligned segment of the Nunavut Hansards(Martin et al, 2003).
The corpus consists of about340K sentences, which comprise about 4.0M En-glish tokens, and 2.2M Inuktitut.
The challenge ofthe morphology becomes apparent when we contrastthese figures with the types: about 416K for Inukti-tut, but only 27K for English.
On average, there areonly 5 token instances per Inuktitut type; some 338Ktypes (81%) are singletons.Inuktitut formed part of one of the shared tasksin the ACL 2005 workshop on building and us-ing parallel texts (Martin et al, 2005); for this, theabove corpus was simplistically tokenised, and usedas unsupervised training data.
100 sentences fromthis corpus were phrasally aligned by Inuit anno-tators.
These were then extended into word align-ments, where phrasal alignments of one token inboth the source and target were (generally) calledsure alignments, and one-to-many or many-to-manymappings were extended to their cartesian product,and called probable.
The test set was composed of75 of these sentences (about 2K English tokens, 800Inuktitut tokens, 293 gold-standard sure alignments,1http://inuktitutcomputing.ca/Uqailaut/en/IMA.htmland 1679 probable), which we use to evaluate wordalignments.Our treatment of the alignment problem is mostsimilar to Schafer and Dra?bek (2005) who examinefour systems: GIZA++ models (Och and Ney, 2000)for each source-target direction, another where theInuktitut input has been syllabised, and a wFSTmodel.
They observe that aggregating these resultsthrough voting can create a very competitive systemfor Inuktitut word alignment.4 Experimental approachWe used an out-of-the-box implementation of theBerkeley Aligner (DeNero and Klein, 2007), a com-petitive word alignment system, to construct an un-supervised alignment over the 75 test sentences,based on the larger training corpus.
The defaultimplementation of the system involves two jointly-trained HMMs (one for each source-target direc-tion) over five iterations,2 with so-called compet-itive thresholding in the decoding step; these aremore fully described in DeNero and Klein (2007)and Liang et al (2006).Our approach examines morphological pre-processing of the Inuktitut training and test sets,with the idea of leveraging the morphological in-formation into a corpus which is more amenable toalignment.
The raw corpus appears to be under-segmented, where data sparseness from the manysingletons would prevent reliable alignments.
Seg-mentation might aid in this process by making sub-lexical units with semantic overlap transparent to thealignment system, so that types appear to have agreater frequency through the data.
Through this,we attempt to examine the hypothesis that one-to-one alignments between English and Inuktitut wouldhold with the right segmentation.
On the other hand,oversegmentation (for example, down to the charac-ter level) can leave the resulting sub-lexical items se-mantically meaningless and cause spurious matches.We consider five different ways of tackling Inuk-titut morphology:1.
None: simply treat each Inuktitut token as amonolithic entity.
This is our baseline ap-proach.2Better performance was observed with three iterations, butwe preferred to maintain the default parameters of the system.3732.
Head: attempt to separate the head morphemefrom the non-head periphery.
Our hypothesisis that we will be able to align the clausal headmore reliably, as it tends to correspond to a sin-gle English token more reliably than the othermorphemes, which may not be realised in thesame manner in English.
Head morphs in Inuk-titut correspond to the first one or two syllablesof a token; we treated them uniformly as twosyllables, as other values caused a substantialdegredation in performance.3.
Syllabification: treat the text as if Inuktituthad isolating morphology, and transform eachtoken into a series of single-syllable pseudo-morphs.
This effectively turns the task on itshead, from a primarily one Inukitut-to-manyEnglish token problem to that of one English-to-many Inuktitut.
Despite the overzealousnessof this approach (as most Inuktitut morphemesare polysyllabic, and consequently there will bemany plausible but spurious matches betweentokens that share a syllable but no semantics),Schafer and Dra?bek (2005) observed it to bequite competitive.4.
Morphs: segment each word into morphs,thereby treating the morphology problem aspure segmentation.
This uses the top output ofthe morphological analyser as the oracle seg-mentation of each Inuktitut token.5.
Morphemes: as previous, except include thenormalisation of each morph to a morpheme,as provided by the morphological analyser, asa sort of ?lemmatisation?
step.
The major ad-vantage over the morph approach is due to theregular morphophonemic effects in Inuktitut,which cause equivalent morphemes to have dif-ferent surface realisations.5 Results5.1 AnalyserIn our analysis, the morphological analyser finds atleast one reading for about 218K (= about 65%) ofthe Inuktitut types.
Of the 120K types without read-ings, resource contraints account for about 11K.
3Another 6K types caused difficulties due to punctu-ation, numerical characters or encoding issues, all ofwhich could be handled through more sophisticatedtokenisation.A more interesting cause of gaps forthe analyser was typographical errors (e.g.
*kiinaujaqtaaruasirnirmut for kiinaujaqtaarusiar-nirmut ?requests for proposals?).
This was oftendue to consonant gemination, where it was eithermissing (e.g.
nunavummut ?in Nunavut?
appearedin the corpus as *nunavumut) or added (e.g.
*tamakkununnga instead of tamakkununga ?atthese ones here?).
While one might expect thesekinds of error to be rare, because Inuktitut has anorthography that closely reflects pronunciation,they instead are common, which means that themorphological analyser should probably acceptincorrect gemination with a lower weighting.More difficult to analyse directly is the impactof foreign words (particularly names) ?
these aretypically subjectively transliterated based on Inukti-tut morphophonology.
Schafer and Dra?bek (2005)use these as motivation for an approach based ona wFST, but found few instances to analyse its ac-curacy.
Finally, there are certainly missing roots,and possibly some missing affixes as well, for ex-ample pirru- ?accident?
(cf.
pirruaqi- ?to have anaccident?).
Finding these automatically remains asfuture work.As for tokens, we briefly analysed the 768 tokensin the test set, of which 228 (30%) were not givena reading.
Punctuation (typically commas and peri-ods) account for 117 of these, and numbers another7.
Consonant gemination and foreign words causegaps for at least 16 and 6 tokens, respectively (thatwe could readily identify).5.2 Word AlignmentFollowing Och and Ney (2000), we assess usingalignment error rate (AER) and define precision withrespect to the probable set, and recall with respect to3We only attempted to parse tokens of 30 characters orshorter; longer tokens tended to cause exceptions ?
this couldpresumably be improved with a more efficient analyser.
Whilethe number of analyses will continue to grow with the tokenlength, which has implications in agglutinative languages, herethere are only about 300 tokens of length greater than 40.374Approach Prec Rec AERNone 0.783 0.863 0.195Head 0.797 0.922 0.176Syllabification 0.789 0.881 0.192Morphs 0.777 0.860 0.207Morphemes 0.777 0.863 0.206S&D E-I 0.646 0.829 0.327S&D Syll 0.849 0.826 0.156Table 1: Precision, recall, and alignment error rate forvarious approaches to morphology, with Schafer andDra?bek (2005) for comparisonthe sure set.We present word alignment results of the vari-ous methods ?
contrasted with Schafer and Dra?bek(2005) ?
in Table 1.
The striking result is interms of statistical significance: according to ?2,most of the various approaches to morphology failto give a significantly (P < 0.05) different resultto the baseline system of using entire tokens.
Forcomparison, whereas our baseline system is signifi-cantly better than the baseline system of Schafer andDra?bek (2005) ?
which demonstrates the value thatthe Berkeley Aligner provides by training in bothsource-target directions ?
their syllablised modelis significantly superior in precision (P < 0.001),while their recall is still worse than our model (P <0.05).
Intuitively, this seems to indicate that theirmodel is making fewer judgments, but actually theopposite is true.
It seems that their model achievesbetter performance than ours because it leveragesmany candidate probable alignments into high qual-ity aggregates using a most-likely heuristic on themapping of Inuktitut syllables to English words,whereas the Berkeley Aligner culls the candidate setin joint training.Of the approaches toward morphology that weconsider, only the recall of the head?based sys-tem improves upon the baseline (P < 0.025).This squares with our intuitions, where segment-ing the root morpheme from the larger token al-lows for more effective alignment of the semanti-cally straightforward sure alignments.The three systems that involve a finer segmenta-tion over the tokens are equivalent in performance tothe baseline system.
The oversegmentation seemedto caused the alignment system to abandon an im-plicit preference for monotonicity of the order oftokens between the source and target (which holdspretty well for the baseline system over the test data,thanks partly to the fidelity-focused structure of aHansard corpus): presumably because the alignerperceives lexical similarity between disparate tokensdue to them sharing a sublexical unit.
This relax-ing of monotonicity is most apparent for punctua-tion, where a comma with a correct alignment in thebaseline becomes incorrectly aligned to a differentcomma in the sentence for the segmented system.6 ConclusionThe only improvement toward the task that we ob-served using morphological approaches is that ofhead segmentation, where using two syllables as ahead-surrogate allowed us to capture more of thesure (one-to-one) alignments in the test set.
Onepossible extension would be to take the head mor-pheme as given the analyser, rather than the some-what arbitrary syllabic approach.
For other lan-guages with rich morphology, it may be similarlyvaluable to target substantives for segmentation toimprove alignment.All in all, it appears that the lexical encoding ofmorphology of Inuktitut is so strikingly differentthan English, that the assumption of Inuktitut mor-phemes aligning to English words is untrue or atleast unfindable within the current framework.
Nu-merous common morphemes have no English equiv-alent, for example, -liaq- ?to go to?
which seems toact as a light verb, or -niq-, a (re-)nominaliser forabstract nominals.
While the output of the morpho-logical analyser could probably be used more effec-tively in other tasks, there are still important impactsin word alignment and machine translation, includ-ing leveraging a dictionary (which is based on mor-phemes, not tokens, and as such requires segmenta-tion and normalisation) or considering grammaticalforms for syntactic approaches.ReferencesPeter Adolphs.
2008.
Acquiring a poor man?s inflec-tional lexicon for German.
In Proc.
of the 6th LREC,375Marrakech, Morocco.Gavin Burnage.
1990.
CELEX: A guide for users.
Tech-nical report, University of Nijmegen.Mathias Creutz and Krista Lagus.
2002.
Unsuperviseddiscovery of morphemes.
In Proc.
of the 6th Workshopof ACL SIGPHON, pages 21?30, Philadelphia, USA.John DeNero and Dan Klein.
2007.
Tailoring wordalignments to syntactic machine translation.
In Proc.of the 45th Annual Meeting of the ACL, pages 17?24,Prague, Czech Republic.Raymund G. Gordon, Jr, editor.
2005.
Ethnologue: Lan-guages of the World, Fifteenth Edition.
SIL Interna-tional.Jan Hajic?
and Barbora Hladka?.
1998.
Tagging inflectivelanguages: Prediction of morphological categories fora rich, structured tagset.
In Proc.
of the 36th AnnualMeeting of the ACL and 17th International Conferenceon COLING, pages 483?490, Montre?al, Canada.Philippe Langlais, Fabrizio Gotti, and Guihong Cao.2005.
NUKTI: English-Inuktitut word alignment sys-tem description.
In Proc.
of the ACL Workshop onBuilding and Using Parallel Texts, pages 75?78, AnnArbor, USA.Percy Liang, Ben Taskar, and Dan Klein.
2006.
Align-ment by agreement.
In Proc.
of the HLT Conferenceof the NAACL, pages 104?111, New York City, USA.Ronald Lowe.
1996.
Grammatical sketches: Inuktitut.In Jacques Maurais, editor, Quebec?s Aboriginal Lan-guages: History, Planning and Development, pages204?232.
Multilingual Matters.Joel Martin, Howard Johnson, Benoit Farley, and AnnaMaclachlan.
2003.
Aligning and using an English-Inuktitut parallel corpus.
In Proc.
of the HLT-NAACL2003 Workshop on Building and Using Parallel Texts,pages 115?118, Edmonton, Canada.Joel Martin, Rada Mihalcea, and Ted Pedersen.
2005.Word alignment for languages with scarce resources.In Proc.
of the ACL Workshop on Building and UsingParallel Texts, pages 65?74, Ann Arbor, USA.Franz Josef Och and Hermann Ney.
2000.
Improved sta-tistical alignment models.
In Proc.
of the 38th AnnualMeeting of the ACL, pages 440?447, Saarbru?cken,Germany.Beno?
?t Sagot, Lionel Cle?ment, Eric Villemonte de LaClergerie, and Pierre Boullier.
2006.
The Lefff syntac-tic lexicon for French: Architecture, acquisition, use.In Proc.
of the 5th LREC, pages 1348?1351, Genoa,Italy.Charles Schafer and Elliott Dra?bek.
2005.
Models forInuktitut-English word alignment.
In Proc.
of the ACLWorkshop on Building and Using Parallel Texts, pages79?82, Ann Arbor, USA.376
