Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 1?8,Sydney, July 2006. c?2006 Association for Computational LinguisticsUsing Machine Learning Techniques to Build a Comma Checker forBasqueI?aki Alegria Bertol Arrieta Arantza Diaz de Ilarraza Eli Izagirre Montse MaritxalarComputer Engineering Faculty.
University of the Basque Country.Manuel de Lardizabal Pasealekua, 120018 Donostia, Basque Country, Spain.
{acpalloi,bertol,jipdisaa,jibizole,jipmaanm}@ehu.esAbstractIn this paper, we describe the researchusing  machine  learning  techniques  tobuild a comma checker to be integratedin a grammar checker for Basque.
Afterseveral experiments, and trained with alittle corpus of 100,000 words, the sys?tem guesses correctly not placing com?mas with a precision of 96% and a re?call of 98%.
It also gets a precision of70% and a recall of 49% in the task ofplacing  commas.
Finally,  we  haveshown  that  these  results  can  be  im?proved using a bigger and a more ho?mogeneous  corpus  to  train,  that  is,  abigger corpus written by one unique au?thor.1 IntroductionIn the last years, there have been many studiesaimed  at  building  a  grammar  checker  for  theBasque language (Ansa et al, 2004; Diaz De Il?arraza et al, 2005).
These works have been fo?cused, mainly, on building rule sets ?
?taking intoaccount syntactic information extracted from thecorpus  automatically??
that  detect  some  erro?neous grammar forms.
The research here presen?ted wants to complement the earlier work by fo?cusing on  the  style  and the  punctuation of  thetexts.
To be precise, we have experimented usingmachine learning techniques for the special caseof the comma, to evaluate their performance andto analyse the possibility of applying it in othertasks of the grammar checker.However,  developing  a  punctuation  checkerencounters  one  problem  in  particular:  the  factthat the punctuation rules are not totally estab?lished.
In general, there is no problem when us?ing the  full  stop,  the  question mark or  the ex?clamation mark.
Santos (1998) highlights thesemarks are reliable punctuation marks, while allthe rest are unreliable.
Errors related to the reli?able ones (putting or not the initial  question orexclamation mark depending on the language, forinstance) are not so hard to treat.
A rule set tocorrect some of these has already been definedfor the Basque language (Ansa et al, 2004).
Incontrast, the comma is the most polyvalent and,thus, the least defined punctuation mark (Bayrak?tar et al, 1998; Hill and Murray, 1998).
The am?biguity of the comma, in fact,  has been shownoften (Bayraktar et  al.,  1998; Beeferman et al,1998;  Van  Delden  S.  and  Gomez  F.,  2002).These works have shown the lack of fixed rulesabout the comma.
There are only some intuitiveand  generally  accepted  rules,  but  they  are  notused in a standard way.
In Basque, this problemgets even more evident, since the standardisationand  normalisation  of  the  language  began  onlyabout twenty?five years ago and it  has not fin?ished yet.
Morphology is mostly defined, but, onthe contrary, as far as syntax is concerned, thereis  quite  work  to  do.
In  punctuation  and  style,some basic rules have been defined and acceptedby the Basque Language Academy (Zubimendi,2004).
However,  there  are  not  final  decisionsabout the case of the comma.Nevertheless,  since  Nunberg?s  monograph(Nunberg, 1990), the importance of the commahas  been  undeniable,  mainly  in  these  two  as?pects: i) as a due to the syntax of the sentence(Nunberg, 1990; Bayraktar et al, 1998; Garzia,1997), and ii) as a basis to improve some naturallanguage  processing  tools  (syntactic  analysers,error  detection  tools?
),  as  well  as  to  developsome  new  ones  (Briscoe  and  Carroll,  1995;Jones, 1996).
The relevance of the comma for thesyntax of the sentence may be easily proved withsome clarifying examples where the sentence isunderstood in  one or  other  way,  depending onwhether  a  comma  is  placed  or  not  (Nunberg,1990):a.
Those students who can, contribute to theUnited Fund.b.
Those students who can contribute to theUnited Fund.1In the same sense,  it  is  obvious  that  a  wellpunctuated  text,  or  more  concretely,  a  correctplacement of the commas, would help consider?ably  in  the  automatic  syntactic  analysis  of  thesentence,  and, therefore,  in the development ofmore and better tools in the NLP field.
Say andAkman (1997) summarise the research efforts inthis direction.As an important background for our work, wenote  where  the  linguistic  information  on  thecomma for the Basque language was formalised.This  information  was  extracted  after  analysingthe  theories  of  some experts  in  Basque  syntaxand punctuation (Aldezabal et al, 2003).
In fact,although no final decisions have been taken bythe Basque Language Academy yet,  the theoryformalised in the above mentioned work has suc?ceeded in unifying the main points of view aboutthe  punctuation in  Basque.
Obviously,  this  hasbeen the basis for our work.2 Learning commasWe have designed two different but combinableways to get the comma checker:?
based on clause boundaries?
based directly on corpusBearing  in  mind  the formalised  theory  ofAldezabal et  al.
(2003)1,  we realised that if  wegot to split the sentence into clauses, it would bequite easy to develop rules for detecting the exactplaces where commas would have to go.
Thus,the best way to build a comma checker would beto get, first, a clause identification tool.Recent papers in this area report quite goodresults using machine learning techniques.
Car?reras and M?rquez (2003) get one of the best per?formances in this  task (84.36% in test).
There?fore, we decided to adopt this as a basis in orderto  get  an  automatic  clause  splitting  tool  forBasque.
But  as  it  is  known,  machine  learningtechniques cannot be applied if no training cor?pus is available, and one year ago, when we star?ted this  process,  Basque texts  with this  taggedclause splits were not available.Therefore, we decided to use the second al?ternative.
We  had  available  some  corpora  ofBasque, and we decided to try learning commasfrom raw text, since a previous tagging was notneeded.
The problem with the raw text is that itscommas are not the result of applying consistentrules.1 From now on, we will speak about this as ?the accepted theory of Basquepunctuation?.Related workMachine learning techniques have been appliedin many fields and for  many purposes,  but  wehave found only one reference in the literaturerelated to the use of machine learning techniquesto assign commas automatically.Hardt (2001) describes research in using theBrill tagger (Brill 1994; Brill, 1995) to learn toidentify incorrect commas in Danish.
The systemwas developed by randomly inserting commas ina text, which were tagged as incorrect, while theoriginal  commas  were  tagged  as  correct.
Thissystem identifies incorrect commas with a preci?sion  of  91%  and  a  recall  of  77%,  but  Hardt(2001) does not mention anything about identify?ing correct commas.In  our  proposal,  we have tried  to  carry outboth aspects, taking as a basis other works thatalso use machine learning techniques in similarproblems  such  as  clause  splitting  (Tjong  KimSang E.F. and D?jean H., 2001) or detection ofchunks (Tjong Kim Sang E.F. and Buchholz S.,2000).3 Experimental setupCorporaAs we have mentioned before, some corporain Basque are available.
Therefore, our first taskwas to select the training corpora, taking into ac?count that well punctuated corpora were neededto train the machine correctly.
For that purpose,we looked for corpora that satisfied as much aspossible our ?accepted theory of Basque punctu?ation?.
The  corpora  of  the  unique  newspaperwritten in Basque, called  Egunkaria (nowadaysBerria), were chosen, since they are supposed touse the ?accepted theory of Basque punctuation?.Nevertheless,  after  some brief  verifications, werealised that the texts of the corpora do not fullymatch with our theory.
This can be understoodconsidering that a lot of people work in a news?paper.
That is, every journalist can use his owninterpretation of  the  ?accepted theory?,  even ifall of them were instructed to use it in the sameway.
Therefore, doing this  research, we had inmind that the results we would get were not go?ing to be perfect.To counteract this problem, we also collectedmore  homogeneous  corpora  from  prestigiouswriters: a translation of a book of philosophy anda novel.
Details about these corpora are shown inTable 1.2Size of the corporaCorpora from the newspaper Egunkaria 420,000 wordsPhilosophy texts written by one unique author 25,000 wordsLiterature texts written by one unique author 25,000 wordsTable 1.
Dimensions of the used corporaA short version of the first corpus was used indifferent experiments in order to tune the system(see section 4).
The differences between the re?sults  depending on the type of  the corpora areshown in section 5.EvaluationResults are shown using the standard measures inthis area: precision, recall and f?measure2, whichare calculated based on the test corpus.
The res?ults are shown in two colums ("0" and "1") thatcorrespond to the result categories used.
The res?ults for the column ?0?
are the ones for the in?stances that are not followed by a comma.
On thecontrary, the results for the column ?1?
are theresults for the instances that should be followedby a comma.Since  our  final  goal  is  to  build  a  commachecker,  the precision in the column ?1?
is themost  important  data  for  us,  although the recallfor the same column is also relevant.
In this kindof tools, the most important thing is to first ob?tain all the comma proposals right (precision incolumns ?1?
), and then to obtain all the possiblecommas (recall in columns ?1?
).BaselinesIn  the  beginning,  we  calculated  two  possiblebaselines based on a big part of the newspapercorpora in order to choose the best one.The  first  one  was  based  on  the  number  ofcommas  that  appeared  in  these  texts.
In  otherwords,  we  calculated  how  many  commas  ap?peared in the corpora (8% out of all words), andthen we put commas randomly in this proportionin the test corpus.
The results obtained were notvery good (see Table 2, baseline1), especially forthe  instances  ?followed by  a  comma?
(column?1?
).The second baseline was developed using thelist  of  words appearing before a comma in thetraining corpora.
In the test corpus, a word wastagged as ?followed by a comma?
if it was one ofthe words of the mentioned list.
The results (seebaseline 2, in Table 2) were better, in this case,for the instances followed by a comma (columnnamed  ?1?).
But,  on  the  contrary,  baseline  1provided us with better results for the instancesnot followed by a comma (column named ?0?
).That is why we decided to take, as our baseline,2 f?measure = 2*precision*recall / (precision+recall)the best data offered by each baseline (the onesin bold in table 2).0 1Prec.
Rec.
Meas.
Prec.
Rec.
Meas.baseline 1 0.927 0.924 0.926 0.076 0.079 0.078baseline 2 0.946 0.556 0.700 0,096 0.596 0.165Table 2: The baselinesMethods and attributesWe  use  the  WEKA3 implementation  of  theseclassifiers: the Naive Bayes based classifier (Na?iveBayes),  the  support  vector  machine  basedclassifier  (SMO)  and  the  decision?tree  (C4.5)based one (j48).It  has  to  be  pointed  out  that  commas  weretaken  away  from  the  original  corpora.
At  thesame time, for each token, we stored whether itwas followed by a  comma or not.
That  is,  foreach  word  (token),  it  was  stored  whether  acomma was placed next to it or not.
Therefore,each token in the corpus is equivalent to an ex?ample (an instance).
The attributes of each tokenare based on the token itself and some surround?ing ones.
The application window describes thenumber of tokens considered as information foreach token.Our initial application window was [?5, +5];that means we took into account the previous andfollowing 5 words (with their corresponding at?tributes)  as  valid  information  for  each  word.However, we tuned the system with different ap?plication windows (see section 4).Nevertheless, the attributes managed for eachword can be as complex as we want.
We couldonly use words, but we thought some morpho?syntactic information would be beneficial for themachine to learn.
Hence, we decided to includeas much information as we could extract usingthe shallow syntactic parser of Basque (Aduriz etal.,  2004).
This  parser  uses  the  tokeniser,  thelemmatiser, the chunker and the morphosyntacticdisambiguator  developed by  the  IXA4 researchgroup.The attributes we chose to use for each tokenwere the following:?
word?form?
lemma?
category?
subcategory?
declension case?
subordinate?clause type3 WEKA is a collection of machine learning algorithms for data mining tasks(http://www.cs.waikato.ac.nz/ml/weka/).4 http://ixa.si.ehu.es3?
beginning of chunk (verb, nominal, enti?ty, postposition)?
end of chunk (verb, nominal, entity, post?position)?
part of an apposition?
other  binary  features:  multiple  word  to?ken,  full  stop,  suspension  points,  colon,semicolon,  exclamation  mark  and  ques?tion markWe also included some additional  attributeswhich were automatically calculated:?
number of verb chunks to the beginningand to the end of the sentence?
number of nominal chunks to the begin?ning and to the end of the sentence?
number  of  subordinate?clause  marks  tothe beginning and to the end of the sen?tence?
distance (in tokens) to the beginning andto the end of the sentenceWe also did other experiments using binaryattributes that correspond to most used colloca?tions (see section 4).Besides, we used the result attribute ?comma?to store whether a comma was placed after eachtoken.4 ExperimentsDimension of the corpusIn  this  test,  we  employed the  attributes  de?scribed in section 3 and an initial window of [?5,+5], which means we took into account the pre?vious 5 tokens and the following 5.
We also usedthe C4.5 algorithm initially, since this algorithmgets very good results in other similar machinelearning  tasks  related  to  the  surface  syntax(Alegria et al, 2004).0 1Prec.
Rec.
Meas.
Prec.
Rec.
Meas.100,000 train / 30,000 test 0,955 0,981 0,968 0,635 0,417 0,503160,000 train / 45,000 test 0,947 0,981 0,964 0,687 0,43 0,529330,000 train / 90,000 test 0,96 0,982 0,971 0,701 0,504 0,587Table 3.
Results depending on the size of corpora(C4.5 algorithm; [?5,+5] window).As it  can be seen in table 3, the bigger thecorpus,  the  better  the results,  but  logically,  thetime expended to obtain the results also increasesconsiderably.
That is why we chose the smallestcorpus  for  doing  the  remaining  tests  (100,000words  to  train  and  30,000  words  to  test).
Wethought that the size of this corpus was enough toget good comparative results.
This test, anyway,suggested that the best  results  we could obtainwould  be  always  improvable  using  more  andmore corpora.Selecting the windowUsing the corpus and the attributes described be?fore, we did some tests to decide the best applic?ation window.
As we have already mentioned, insome problems of this type, the information ofthe  surrounding  words  may  contain  importantdata to decide the result of the current word.In this test, we wanted to decide the best ap?plication window for our problem.0 1Prec.
Rec.
Meas.
Prec.
Rec.
Meas.-5+5 0,955 0,981 0,968 0,635 0,417 0,503-2+5 0,956 0,982 0,969 0,648 0,431 0,518-3+5 0,957 0,979 0,968 0,627 0,441 0,518-4+5 0,957 0,98 0,968 0,634 0,446 0,52-5+2 0,956 0,982 0,969 0,65 0,424 0,514-5+3 0,956 0,981 0,969 0,643 0,432 0,517-5+4 0,955 0,982 0,968 0,64 0,417 0,505-6+2 0,956 0,982 0,969 0,645 0,421 0,509-6+3 0,956 0,982 0,969 0,646 0,426 0,514-8+2 0,956 0,982 0,969 0,645 0,425 0,513-8+3 0,956 0,979 0,967 0,615 0,431 0,507-8+8 0,956 0,978 0,967 0,604 0,422 0,497Table  4.
Results  depending  on  the  applicationwindow (C4.5 algorithm; 100,000 train / 30,000test)As it can be seen, the best f?measure for theinstances followed by a comma was obtained us?ing the application window [?4,+5].
However, aswe have said before, we are more interested inthe precision.
Thus, the application window [?5,+2] gets the best precision, and, besides, its f?measure is almost the same as the best one.
Thisis the reason why we decided to choose the [?5,+2] application window.Selecting the classifierWith  the  selected  attributes,  the  corpus  of130,000 words and the application window of [?5, +2], the next step was to select the best classifi?er for our problem.
We tried the WEKA imple?mentation of these classifiers:  the Naive Bayesbased classifier (NaiveBayes), the support vectormachine based classifier (SMO) and the decisiontree based one (j48).
Table 5 shows the resultsobtained:40 1Prec.
Rec.
Meas.
Prec.
Rec.
Meas.NB 0,948 0,956 0,952 0,376 0,335 0,355SMO 0,936 0,994 0,965 0,672 0,143 0,236J48 0,956 0,982 0,969 0,652 0,424 0,514Table 5.
Results depending on the classifier(100,000 train / 30,000 test; [?5, +2] window).As we can see, the f?measure for the instancesnot followed by a comma (column ?0?)
is almostthe same for the three classifiers, but, on the con?trary, there is a considerable difference when werefer  to  the  instances  followed  by  a  comma(column ?1?).
The best f?measure gives the C4.5based classifier (J48) due to the better recall, al?though the best precision is for the support vectormachine  based  classifier  (SMO).
Definitively,the Na?ve Bayes (NB) based classifier was dis?carded, but we had to think about the final goalof our research to choose between the other twoclassifiers.
Since our  final  goal  was to  build  acomma checker, we would have to have chosenthe classifier that gave us the best precision, thatis, the support vector machine based one.
But therecall of the support vector machine based classi?fier was not as good as expected to be selected.Consequently,  we  decided  to  choose  the  C4.5based classifier.Selecting examplesAt this  moment,  the results  we get  seem to bequite good for the instances not  followed by acomma, but  not  so good for  the  instances  thatshould follow a comma.
This could be explainedby the fact that we have no balanced training cor?pus.
In other words, in a normal text, there are alot  of  instances not  followed by a  comma, butthere are not so many followed by it.
Thus, ourtraining  corpus,  logically,  has  very  differentamounts of instances followed by a comma andnot followed by a comma.
That is the reason whythe system will learn more easily to avoid the un?necessary  commas  than  placing  the  necessaryones.Therefore,  we  resolved  to  train  the  systemwith a corpus where the number of instances fol?lowed by a comma and not followed by a commawas the same.
For that purpose, we prepared aperl program that changed the initial corpus, andsaved only x words for each word followed by acomma.In  table  6,  we can see  the  obtained results.One to one means that in that case, the trainingcorpus  had  one  instance  not  followed  by  acomma, for each instance followed by a comma.On the  other  hand,  one to  two means that  thetraining corpus had two instances not  followedby  a  comma  for  each  word  followed  by  acomma, and so on.0 1Prec.
Rec.
Meas.
Prec.
Rec.
Meas.normal 0,955 0,981 0,968 0,635 0,417 0,503one to one 0,989 0,633 0,772 0,164 0,912 0,277one to two 0,977 0,902 0,938 0,367 0,725 0,487one to three 0,969 0,934 0,951 0,427 0,621 0,506one to four 0,966 0,952 0,959 0,484 0,575 0,526one to five 0,966 0,961 0,963 0,534 0,568 0,55one to six 0,963 0,966 0,964 0,55 0,524 0,537Table  6.
Results  depending  on  the  number  ofwords  kept  for  each  comma  (C4.5  algorithm;100,000 train / 30,000 test; [?5, +2] window).As  observed  in  the  previous  table,  the  bestprecision in the case of the instances followed bya comma is the original one: the training corpuswhere  no  instances  were  removed.
Note  thatthese results are referred as normal in table 6.The corpus where a unique instance not fol?lowed by a comma is kept for each instance fol?lowed by a comma gets the best  recall  results,but the precision decreases notably.The  best  f?measure  for  the  instances  thatshould be followed by a comma is obtained bythe one to five scheme, but as mentioned before,a comma checker must take care of offering cor?rect comma proposals.
In other words, as the pre?cision of the original corpus is quite better (tenpoints better), we decided to continue our workwith  the  first  choice:  the  corpus  where  no  in?stances were removed.Adding new attributesKeeping the best results obtained in the tests de?scribed above (C4.5 with the [?5,  +2] window,and not removing any ?not comma?
instances),we thought that giving importance to the wordsthat appear normally before the comma would in?crease our results.
Therefore, we did the follow?ing tests:1) To search a big corpus in order to extractthe most  frequent  one hundred words  that  pre?cede a  comma,  the  most  frequent  one hundredpairs of words (bigrams) that precede a comma,and the most frequent one hundred sets of threewords (trigrams) that precede a comma, and usethem as attributes in the learning process.2) To use only three attributes instead of thementioned three hundred to encode the informa?tion  about  preceding  words.
The  first  attributewould indicate whether a word is or not one of5the  most  frequent  one  hundred  words.
Thesecond attribute would mean whether a word isor not the last part of one of the most frequentone hundred pairs of words.
And the third attrib?ute would mean whether a word is or not the lastpart of one of the most frequent one hundred setsof three words.3) The case (1), but with a little difference:removing the attributes ?word?
and ?lemma?
ofeach instance.0 1Prec.
Rec.
Meas.
Prec.
Rec.
Meas.
(0): normal 0,956 0,982 0,969 0,652 0,424 0,514(1): 300 attributes + 0,96 0,983 0,972 0,696 0,486 0,572(2): 3 attributes + 0,96 0,981 0,97 0,665 0,481 0,558(3): 300 attributes +,no lemma, no word 0,955 0,987 0,971 0,71 0,406 0,517Table 7.
Results depending on the new attributesused (C4.5 algorithm; 100,000 train / 30,000 test;[?5, +2] window; not removed instances).Table 7 shows that case number 1 (putting the300 data as attributes) improves the precision ofputting  commas  (column  ?1?)
in  more  than  4points.
Besides, it also improves the recall, and,thus, we improve almost 6 points its f?measure.The third test gives the best precision, but therecall decreases considerably.
Hence, we decidedto choose the case number 1, in table 7.5 Effect of the corpus typeAs we have said before (see section 3), depend?ing on the quality of the texts, the results couldbe different.In table 8, we can see the results using the dif?ferent types of corpus described in table 1.
Obvi?ously,  to  give  a  correct  comparison,  we  haveused the same size for all the corpora (20,000 in?stances to train and 5,000 instances to test, whichis the maximum size we have been able to ac?quire for the three mentioned corpora).0 1Prec.
Rec.
Meas.
Prec.
Rec.
Meas.Newspaper 0.923 0.977 0.949 0.445 0.188 0.264Philosophy 0.932 0.961 0.946 0.583 0.44 0.501Literature 0.925 0.976 0.95 0.53 0.259 0.348Table 8.
Results depending on the type of corpo?ra (20,000 train / 5,000 test).The first line shows the results obtained usingthe short version of the newspaper.
The secondline  describes  the  results  obtained  using  thetranslation of a book of philosophy, written com?pletely by one author.
And the third one presentsthe  results  obtained  using  a  novel  written  inBasque.In any case, the results prove that our hypo?thesis  was  correct.
Using  texts  written  by  aunique author improves the results.
The book ofphilosophy has the best precision and the best re?call.
It  could be  because it  has  very long sen?tences  and  because  philosophical  texts  use  astricter syntax comparing with the free style of aliterature writer.As it was impossible for us to collect the ne?cessary  amount  of  unique  author  corpora,  wecould not go further in our tests.6 Conclusions and future workWe have used machine learning techniques forthe  task  of  placing  commas  automatically  intexts.
As far as we know, it is quite a novel ap?plication field.
Hardt (2001) described a systemwhich identified incorrect commas with a preci?sion of 91% and a recall of 77% (using 600,000words  to  train).
These  results  are  comparablewith the ones we obtain for the task of guessingcorrectly when not to place commas (see column?0?
in the tables).
Using 100,000 words to train,we obtain 96% of precision and 98.3% of recall.The main reason could be that we use more in?formation to learn.However, we have not obtained as good res?ults as we hoped in the task of placing commas(we  get  a  precision  of  69.6%  and  a  recall  of48.6%).
Nevertheless, in this particular task, wehave  improved  considerably  with  the  designedtests, and more improvements could be obtainedusing more corpora and more specific corpora astexts written by a unique author or by using sci?entific texts.Moreover,  we have detected some possibleproblems that could have brought these regularresults in the mentioned task:?
No fixed rules for commas in the Basquelanguage?
Negative influence when training usingcorpora from different writersIn this sense, we have carried out a little ex?periment with some English corpora.
Our hypo?thesis was that a completely settled language likeEnglish,  where  comma  rules  are  more  or  lessfixed, would obtain better results.
Taking a com?parative English corpus5 and similar learning at?tributes6 to  Basque?s  one,  we  got,  for  the  in?stances  followed  by  a  comma  (column  ?1?
intables), a better precision (%83.3) than the best5 A newspaper corpus, from Reuters6 Linguistic information obtained using Freeling (http://garraf.ep?sevg.upc.es/freeling/)6one obtained for the Basque language.
However,the recall was worse than ours: %38.7.
We haveto take into account that we used less learning at?tributes with the English corpus and that we didnot  change  the  application  window chosen  forthe Basque experiment.
Another application win?dow would have been probably more suitable forEnglish.
Therefore, we believe that with a fewtests  we  easily  would  achieve  a  better  recall.These  results,  anyway,  confirm our  hypothesisand our diagnosis of the detected problems.Nevertheless,  we think the presented resultsfor the Basque language could be improved.
Oneway would  be  to  use  ?information  gain?
tech?niques in order to carry out the feature selection.On the other hand, we think that more syntacticinformation, concretely clause splits tags, wouldbe especially beneficial to detect those commasnamed delimiters by Nunberg (1990).In fact, our main future research will consiston clause identification.
Based on the ?acceptedtheory of the comma?, we can assure that a goodidentification of clauses (together with some sig?nificant linguistic information we already have)would enable us to put commas correctly in anytext,  just  implementing some simple rules.
Be?sides, a combination of both methods ?
?learningcommas  and  putting  commas  after  identifyingclauses??
would  probably  improve  the  resultseven more.Finally,  we contemplate building an ICALL(Intelligent Computer Assisted Language Learn?ing) system to help learners to put commas cor?rectly.AcknowledgementsWe would like to thank all the people who havecollaborated in this research: Juan Garzia,  JoxeRamon  Etxeberria,  Igone  Zabala,  Juan  CarlosOdriozola, Agurtzane Elorduy, Ainara Ondarra,Larraitz Uria and Elisabete Pociello.This research is supported by the Universityof  the  Basque  Country  (9/UPV00141.226?14601/2002) and the Ministry of Industry of theBasque  Government  (XUXENG  project,OD02UN52).ReferencesAduriz  I., Aranzabe  M., Arriola  J., D?az  de  IlarrazaA., Gojenola  K., Oronoz  M., Uria  L.   2004.A  Cascaded  Syntactic  Analyser  for  BasqueComputational  Linguistics  and  Intelligent  TextProcessing.
2945  LNCS  Series.pg.
124?135.Springer Verlag.
Berlin (Germany).Aldezabal I., Aranzabe M., Arrieta B., Maritxalar M.,Oronoz M. 2003.
Toward a punctuation checkerfor Basque.
Atala Workshop on Punctuation.
Paris(France).Alegria I., Arregi  O., Ezeiza N., Fernandez I., UrizarR.
2004.
Design and Development of a Named En?tity  Recognizer  for  an  Agglutinative  Language.First International Joint Conference on NLP (IJC?NLP?04).
Workshop on Named Entity Recognition.Ansa O., Arregi X., Arrieta B., Ezeiza N., FernandezI.,  Garmendia  A.,  Gojenola  K.,  Laskurain  B.,Mart?nez  E.,  Oronoz  M.,  Otegi  A.,  Sarasola  K.,Uria L. 2004.
Integrating NLP Tools for Basque inText Editors.
Workshop on International ProofingTools  and Language Technologies.
University  ofPatras (Greece).Aranzabe M., Arriola J.M., D?az de Ilarraza A.
2004.Towards  a  Dependency  Parser  of  Basque.Proceedings of the Coling 2004 Workshop on Re?cent Advances in Dependency Grammar.
Geneva(Switzerland).Bayraktar M., Say B., Akman V. 1998.
An Analysis ofEnglish Punctuation:  the special  case of  comma.International  Journal  of  Corpus  Linguistics3(1):pp.
33?57.
John  Benjamins  Publishing  Com?pany.
Amsterdam (The Netherlands).Beeferman D.,  Berger  A.,  Lafferty  J.
1998.
Cyber?punc: a lightweight punctuation annotation systemfor speech.
Proceedings of the IEEE InternationalConference on Acoustics, Speech and Signal Pro?cessing, pages 689?692, Seattle (WA).Brill, E. 1994.
Some Advances in rule?based part ofspeech tagging.
In Proceedings of the Twelfth Na?tional Conference on Artificial Intelligence.
Seattle(WA).Brill,  E.  1995.
Transformation?based  error?drivenlearning and natural language processing: a casestudy  in  part  of  speech  tagging.
ComputationalLinguistics 21(4).
MIT Press.
Cambridge (MA).Briscoe T., Carroll J.
1995.
Developing and evaluat?ing a probabilistic lr parser of part?of?speech andpunctuation  labels.
ACL/SIGPARSE 4th  interna?tional Workshop on Parsing Technologies, Prague /Karlovy Vary (Czech Republic).Carreras X., M?rquez L. 2003.
Phrase Recognition byFiltering and Ranking with Perceptrons.
Proceed?ings of the 4th RANLP Conference.
Borovets (Bul?garia).D?az de  Ilarraza A., Gojenola K., Oronoz M.   2005.Design and Development of a System for the De?tection of Agreement Errors in Basque.
CICLing?2005, Sixth International Conference on IntelligentText  Processing  and  Computational  Linguistics.Mexico City (Mexico).Garzia  J.
1997.
Joskera  Lantegi.
Herri  Arduralar?itzaren Euskal Erakundea.
Gasteiz, Basque Country(Spain).7Hardt D. 2001.
Comma checking in Danish.
Corpuslinguistics.
Lancaster (England).Hill R.L., Murray W.S.
1998.
Commas and Spaces:the Point of Punctuation.
11th Annual CUNY Con?ference  on  Human  Sentence  Processing.
NewBrunswick, New Jersey (USA).Jones B.
1996.
Towards a Syntactic Account of Punc?tuation.
Proceedings of the 16th International Con?ference on Computational Linguistics.
Copenhagen(Denmark).Nunberg,  G.  1990.
The  linguistics  of  punctuation.Center for the Study of Language and Information.Leland Stanford Junior University (USA).Say B., Akman V. 1996.
Information?Based Aspectsof  Punctuation.
Proceedings  ACL/SIGPARSE In?ternational  Meeting  on  Punctuation  in  Computa?tional  Linguistics,  pages  pp.
49?56,  Santa  Cruz,California (USA).Tjong Kim Sang E.F. and Buchholz S. 2000.
Intro?duction to the CoNLL?2000 shared task: chunking.In  proceedings  of  CoNLL?2000  and  LLL?2000.Lisbon (Portugal).Tjong Kim Sang E.F. and D?jean H. 2001.
Introduc?tion to the CoNLL?2001 shared task: clause identi?fication.
In proceedings of CoNLL?2001.
Tolouse(France).Van Delden  S.,  Gomez  F.  2002.
Combining  FiniteState Automata and a Greedy Learning Algorithmto Determine the Syntactic Roles of Commas.
14thIEEE International Conference on Tools with Arti?ficial Intelligence.
Washington, D.C. (USA)Zubimendi,  J.R. 2004.
Ortotipografia.
Estilo liburu?aren lehen atala.
Eusko Jaurlaritzaren ArgitalpenZerbitzu  Nagusia.
Gasteiz,  Basque  Country(Spain).8
