Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 311?321, Dublin, Ireland, August 23-29 2014.Picking the Amateur?s Mind ?
Predicting Chess Player Strength fromGame AnnotationsChristian ScheibleInstitute for Natural Language ProcessingUniversity of Stuttgart, Germanyscheibcn@ims.uni-stuttgart.deHinrich Sch?utzeCenter for Informationand Language ProcessingUniversity of Munich, GermanyAbstractResults from psychology show a connection between a speaker?s expertise in a task and the lan-guage he uses to talk about it.
In this paper, we present an empirical study on using linguisticevidence to predict the expertise of a speaker in a task: playing chess.
Instructional chess litera-ture claims that the mindsets of amateur and expert players differ fundamentally (Silman, 1999);psychological science has empirically arrived at similar results (e.g., Pfau and Murphy (1988)).We conduct experiments on automatically predicting chess player skill based on their natural lan-guage game commentary.
We make use of annotated chess games, in which players provide theirown interpretation of game in prose.
Based on a dataset collected from an online chess forum,we predict player strength through SVM classification and ranking.
We show that using textualand chess-specific features achieves both high classification accuracy and significant correlation.Finally, we compare our findings to claims from the chess literature and results from psychology.1 IntroductionIt has been recognized that the language used when describing a certain topic or activity may differstrongly depending on the speaker?s level of expertise.
As shown in empirical experiments in psychology(e.g., Solomon (1990), Pfau and Murphy (1988)), a speaker?s linguistic choices are influenced by the wayhe thinks about the topic.
While writer expertise has been addressed previously, we know of no workthat uses linguistic indicators to rank experts.We present a study on predicting chess expertise from written commentary.
Chess is a particularlyinteresting task for predicting expertise: First, using data from competitive online chess, we can compareand rank players within a well-defined ranking system.
Second, we can collect textual data for experi-mental evaluation from web resources, eliminating the need for manual annotation.
Third, there is a largeamount of terminology associated with chess, which we can exploit for n-gram based classification.Chess is difficult for humans because it requires long-term foresight (strategy) as well as the capacityfor internally simulating complicated move sequences (calculation and tactics).
For these reasons, thegame for a long time remained challenging even for computers.
Players have thus developed generalprinciples of chess strategy on which many expert players agree.
The dominant expert view is that theunderstanding of fundamental strategical notions, supplemented by the ability of calculation, is the mostimportant skill of a chess player.
A good player develops a long-term plan for the course of the game.This view is the foundation of many introductory works to chess (e.g., Capablanca (1921), one of theearliest works).Silman (1999) presents games he played with chess students, analyzing their commentary about theprogress of the game.
He claims that players who fail to adhere to the aforementioned basic princi-ples tend to perform worse and argues that the students?
thought processes reflect their playing strengthdirectly.
Lack of strategical understanding marks the difference between amateur and expert players.Experts are mostly concerned with positional aspects, i.e., the optimal placement of pieces that offers aThis work is licenced under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/3118rm0ZkZ0s7opo0lpa060Z0ZpZpo5Z0Z0O0Z040Z0Z0ZbZ3Z0MBZNZ02POPZ0OPO1S0ZQZRJ0a b c d e f g hFigure 1: Example chess position, white to playlong-lasting advantage.
Amateurs often have tactical aspects in mind, i.e., short-term attacking oppor-tunities and exploits that potentially lead to loss of material for their opponents.
A correlation betweenchess strength and verbalization skills has been shown empirically by Pfau and Murphy (1988), whoused experts to assess the quality of the subjects?
writing.In this paper, we investigate the differences between the mindset of amateurs and experts expressed inwritten game commentary, also referred to as annotated games.
When studying chess, it is best practiceto review one?s own games to further one?s understanding of the game (Heisman, 1995).
Students areencouraged to annotate the games, i.e., writing down their thought process at each move.
We address theproblem of predicting the player?s strength from the text of these annotations.
Specifically, we want topredict the rank of the player at the point when a given game was played.
In competitive play, the rankis determined through a numerical rating system ?
such as the Elo rating system (Elo, 1978) used in thispaper ?
that measures the players?
relative strength using pairwise win expectations.This paper makes the following contributions.
First, we introduce a novel training dataset of gamesannotated by the players themselves ?
collected from online chess forum.
We then formulate the task ofplaying strength prediction.
For each annotated game, each game viewed as a document, we predict therating class or overall rank of the player.
We show that (i) an SVM model with n-gram features succeedsat partitioning the players into two rating classes (above and below the mean rating); and (ii) that rankingSVMs achieve significant correlation between the true and predicted ranking of the players.
In addition,we introduce novel chess-specific features that significantly improve the results.
Finally, we compare thepredictions made by our model to claims from instructional chess literature and results from psychologyresearch.We next give an overview of basic chess concepts (Section 2).
Then, we introduce the dataset (Sec-tion 3) and task (Section 4).
We present our experimental results in Section 5.
Section 6 contains anoverview of related work.2 Basic Chess Concepts2.1 Chess TerminologyWe assume that the reader has basic familiarity with chess, its rules, and the value of individual pieces.For clarity, we review some basic concepts of chess terminology, particularly elementary concepts relatedto tactics and strategy in an example position (Figure 1).1From a positional point of view, white is ahead in development: all his minor pieces (bishops andknights) have moved from their starting point while black?s knight remains on b8.
White has also castled(a move where the rook and king move simultaneously to get the king to a safer spot on either side of theboard) while black has not.
White has a space advantage as he occupies the e5-square (which is in black?s1Modified from the game Dzindzichashvili ?
Yermolinsky (1993) which is the first position discussed in (Silman, 1999)3121.e4 e5 2.Nf3 Nc6 3.Bc4 Nh6 4.Nc3 Bd6 Trying to follow basic opening principals, control center,develop.
etc 5.d3 Na5 6.Bb5 Moved bishop not wanting to trade, but realized after the move that mybishop would be harassed by the pawn on c7 6...c6 7.Ba4 Moved bishop to safety, losing tempo 7...Qf68.Bg5 Qg6 9.O-O b5 Realized my bishop was done, might as well get 2 pawns 10.Nxb5 cxb5 11.Bxb5Ng4 12.Nxe5 Flat out blunder, gave up a knight, at least I had a knight I could capture back 12...Bxe513.Qxg4 Bxb2 14.Rab1 Bd4 15.Rfe1 Moved rook to E file hoping to eventually attack the king.
15...h616.c3 Poor attempt to move the bishop, I realized it after I made the move 16...Bxc3 17.Rec1 Be518.d4 Another crappy attempt to move that bishop 18...Bxd4 19.Rd1 O-O 20.Rxd4 d6 21.Qd1 I don?tremember why I made this move.
21...Qxg5 22.Rxd6 Bh3 23.Bf1 Protecting g2 23...Nc4 24.Rd5 Qg625.Rc1 Qxe4 26.f3 Qe3+ 27.Kh1 Nb2 28.Qc2 Rac8 29.Qe2 Qxc1 30.gxh3 Nc4 31.Qe4 Qxf1#Figure 2: Example of an annotated game from the dataset (by user aevans410, rated 974)half of the board) with a pawn.
This pawn is potentially weak as it cannot easily be defended by anotherpawn.
Black has both of his bishops (the bishop pair) which is considered advantageous as bishopsare often superior to knights in open positions.
Black?s light-square bishop is bad as it is obstructed byblack?s own pawns (although it is outside the pawn chain and thus flexible).
Strategically, black mightwant to improve the position of the light-square bishop, make use of his superior dark-square bishop,and try to exploit the weak e5 pawn.
Conversely, white should try create posts for his knights in black?sterritory.
Tactically, white has an opportunity to move his knight to b5 (written Nb5 in algebraic chessnotation), from where it would attack the pawn on c7.
If the knight could reach c7 (currently defendedby black?s queen), it would fork (double attack) black?s king and rook, which could lead to the trade ofthe knight for the rook on the next move (which is referred to as winning the exchange).
White?s knighton f3 is pinned, i.e., the queen would be lost if the knight moved.
Black can win a pawn by removing thedefender of e5, the knight on f3, by capturing it with the bishop.This brief analysis of the position shows the complex theory and terminology that has developedaround chess.
The paragraph also shows an example of game annotation (although not every move in thegame will be covered as elaborately in practice in amateur analyses).2.2 Elo Rating SystemOur goal in this paper is to predict the ranking of chess players based on their game annotations.
We willgive a brief overview of the Elo system (Elo, 1978) that is commonly used to rank players.
Each playeris assigned a score that is changed after each game depending on the expected and actual outcome.
Onchess.com, a new player starts with an initial rating of 1200 (an arbitrary number chosen for historicalreasons, which has since become a wide-spread convention in chess).
Assuming the current ratings Raand Rbof two players a and b, the expected outcome of the game is defined asEa=11 + 10?Ra?Rb400.Eais then used to conduct a (weighted) update of Raand Rbgiven the actual outcome of the game.Thus, Elo ratings make pairwise adjustments to the scores.
The differences between the ratings of twoplayers predict the probability of one winning against the other.
However, the absolute ratings do notcarry any meaning by themselves.3 Annotated Chess Game DataFor supervised training, we require a collection of chess games annotated by players of various strengths.An annotated chess game is a sequence of chess moves with natural language text commentary associatedto specific moves.
While many chess game collections are available, some of them containing millions ofgames, the majority are unannotated.
The small fraction of annotated games mostly features commentaryby masters rather than amateurs, which is not interesting for a contrastive study.The game analysis forum on chess.com encourages players to post their annotated games for reviewthrough the community.
While several games are posted each day, we can only use a small subset of them.313Parameter Value# games 182# different players 130mean # moves by game 42mean # annotated moves by game 16mean # words by game 114Table 1: Dataset statistics0 500 1000 1500 2000 25000.000.050.100.15Rating (Elo)%Players?
?
?
??????????????????
?
?
?
?
?
?chess.com overallour datasetFigure 3: Rating distribution on chess.com and our dataset.4Each point shows the percentage ofplayers in a bin of width 50 around the value.
Dotted line: Median on our dataset used for binning.Many games are posted without annotations, instead soliciting annotation from the community.
Othersare missing the rating of the player at the time the game was played ?
the user profile shows only thecurrent rating for the player which may differ strongly from their historical one.We first downloaded all available games from the forum archive.
The games are stored in portablegame notation (PGN, Edwards (1994)).
Next, we manually removed games where the annotation hadbeen conducted automatically by a chess program.
We also removed games that had annotations at fewerthan three moves.
The final dataset consists of 182 games with annotations in English and known playerrating.2We reproduce an example game from the data in Figure 2.
This game is typical as the firstcouple of moves are not commented (as opening moves are typically well-known).
Then, the annotatorcomments on select moves that he believes are key to the progress of the game.
Table 1 shows somestatistics about the dataset.The distribution of the ratings in our dataset is shown in Figure 3 in comparison to the overall standardchess rating distribution on chess.com.3Elo ratings assume a normal distribution of players.
We seethat overall, the distributions are quite similar, although we have a higher peak and our sample mean isshifted towards higher ratings (1347 overall vs 1462 on our dataset).
It is more common for mid-levelplayers to request annotation advice than it is for low-rated players (who might not know about thispractice) or high-rated players (who do not look for support by the lower-rated community).The dataset is still somewhat noisy as players may obtain different ratings depending on the type ofvenue (over-the-board tournament vs online chess) or the amount of time the players had available (timecontrol).
Differences in these parameters lead to different rating distributions.4For this reason, the totalordering given through the ratings may be difficult to predict.
Thus, we will conduct experiments both2Available at http://www.ims.uni-stuttgart.de/data/chess3Data from http://www.chess.com/echess/players4cf.
http://www.chess.com/article/view/chesscom-rating-comparisons314on ranking and on classification where the rating range is binned into two rating classes.4 Predicting Chess Strength from Annotations4.1 Classification and RankingThe task addressed in this paper is prediction on the game level, i.e., predicting the strength of the playerof each game at the time when the game was played.
We view a game as a document ?
the concatenationof the annotations at each move ?
and extract feature vectors as described in Section 4.2.
We pursue twodifferent machine learning approaches based on support vector machines (SVMs) to predicting chessstrength: classification and ranking.The simplest way to approach the problem is classification.
For this purpose, we divide the range ofobserved rating into two evenly spaced rating classes at the median of the overall rating range (henceforthamateur and expert).
The classification view has obvious disadvantages.
At the boundaries of the bins,the distinction between them becomes difficult.To predict a total ordering of all players, we use a ranking SVM (Herbrich et al., 1999).
This modelcasts ranking as learning a binary classification function that decides whether rank(x1) > rank(x2) overall possible pairs of example feature vectors x1and x2with differing rank.Note that since Elo ratings are continuous real numbers, it would be conceivable to fit a regressionmodel.
However, Elo is designed as a pairwise ranking measure.
While a relative difference in Elorepresents the probability of one player beating the other, the absolute Elo rating is not directly inter-pretable.54.2 FeaturesWe extract unigrams (UG) and bigrams (BG) from the texts.
In addition, we propose the following twochess-specific feature sets derived from the text:6Notation (NOT).
We introduce two indicators for whether the annotations contain certain types offormal chess notation.
The feature SQUARE is added if the annotation contains a reference to a specificsquare on the chess board (e.g., d4).
If the annotation contains a move in algebraic notation (e.g., Nxb4+,meaning that a knight moved to b4, captured a piece there and put the enemy king in check), the featureMOVE is added.Similarity to master annotations (MS).
This feature is intended to compensate for the lack of trainingdata.
We used a master-annotated database consisting of 500 games annotated by chess masters whichis available online.7As we do not know the exact rating of the annotators, and to avoid strong classimbalances, we cannot make use of the games directly through supervision.
Instead, we calculate thecosine similarity between the centroid8of the n-gram feature vectors of the master games and each gamein the chess.com dataset.
The cosine similarity between each game and the master centroid is addedas a numerical feature.Additionally, the master similarity scores can be used on their own to rank the games.
This can beviewed distant supervision as strength is learned from an external database.
We will evaluate this rankingin comparison with our trained models.5 ExperimentsThis section, contains experimental results on classifying and ranking chess players.
We first presentquantitative evaluation of the classification and ranking models and discuss the effect of chess-specific5Preliminary experiments with SVM regression showed little improvements over a baseline of assigning the mean rating toall games.
This suggests that the distribution of rankings is difficult to model ?
possibly due to the low number of annotatedgames on which the model can be trained.6We also tried using the length of the annotation as well as the number of annotated moves as a feature, which did notcontribute any improvements.7http://www.angelfire.com/games3/smartbridge/famous_games.zip8We also tried a k-NN approach where we computed the mean similarity of a game from our dataset to its k nearestneighbors among the master games (k ?
1, 2, 5,?
), but found that this approach performed worse.315Model Features F(?)1F(?)1F(?
)11 Majority BL 67.2 0.0 33.62 SVM (linear) UG 73.4 71.6 72.53 SVM (linear) UG, BG 74.1 72.0 73.14 SVM (linear) UG, BG, NOT 75.7 74.9 75.35 SVM (linear) UG, BG, NOT, MS 74.2 73.0 73.6(a) Results (F1in %)1 2 3 4 512 **3 **4 ** ?5 **(b) Statistical significance ofdifferences in F1.
**: p < 0.01,*: p < 0.05, ?
: p < 0.1Table 2: Classification resultsClass FeaturesAmateur (?)
bishop, d4, opening, instead, trying, should, did, where, do, even, rook, get, good, he, coming, point i,exchange, thought, did not, his, clock, too, or, on clock, knight forExpert (?)
this, game, can, will, winning, NOT:move, time, draw, because, white, back, black, mate, that, but, moves,can?t, very, on, won, really, so, i know, now, onlyTable 3: Top 25 features with most negative (amateur) and positive (expert) weights (mean over all folds)in the best setup (UG, BG, NOT)features.
Second, we qualitatively compare the predictions of our models with findings and claims fromthe literature about the connection between a player?s mindset and strength.5.1 Experimental SetupTo generate feature vectors, we first concatenate all the annotations for a game, tokenize and lowercasethe texts, and remove punctuation as well as a small number of stopwords.
We exclude rare wordsto avoid overfitting: We remove all n-grams that occur fewer than 5 times, and add the chess-specificfeatures proposed above.
Finally, we L2-normalize each vector.We use linear SVMs from LIBLINEAR and SVMs with RBF kernel from LIBSVM (Chang and Lin,2011).
We run all experiments in a 10-fold cross-validation setup.Wemeasure macro-averaged F1for our classification results.
We evaluate the ranking model using twomeasures: pairwise ranking accuracy (Accr), i.e., the accuracy over the binary ranking decision for eachplayer pair; and Spearman?s rank correlation coefficient ?
for the overall ranking.
To test whether differ-ences between results are statistical significant, we apply approximate randomization (Noreen, 1989) forF1, and the test by Steiger (1980) for correlations, which is applicable to ?.5.2 ClassificationWe first investigate the classification case, i.e., whether we can distinguish players below and above therating mean.
Table 2 shows the results for this experiment.
We show F1scores for the lower and higherhalf of the players (F(?
)1and F(?
)1, respectively), and the macro average of these two scores (F(?)1).
Wefirst note that all SVM classifiers (lines 2?5) score significantly higher than the majority baseline (line 1).When adding bigrams (line 3) and chess-specific notation features (line 4), F1increases.
However, theseimprovements are not statistically significant.
The master similarity feature (line 5) leads to a drop inF1from the previous line.
The relatively low rank correlation between the master similarity scores andthe two classes (?
= 0.334) leads to this effect.
The low correlation itself may occur because the mastergames were annotated by a third party (instead of the players), leading to strong differences in style.There are several reasons for misclassification.
Many errors occur in the dense region around theclass boundary.
Also, shorter game annotations are more difficult to classify than longer ones.
Fordetailed error analysis, we first examine the most positively and negatively weighted features of thetrained models (Table 3).
We will provide a more detailed look into the features in Section 5.4.
We316Model Features Accr?
sig1 MS (standalone) ?
?
0.279 ?2 SVM (linear) UG 58.7 0.266 ?3 SVM (linear) UG, BG 58.8 0.286 ?4 SVM (linear) UG, BG, NOT 60.0 0.307 ?5 SVM (linear) UG, BG, NOT, MS 59.8 0.310 ?6 SVM (RBF) UG 64.0 0.389 ?7 SVM (RBF) UG, BG 63.9 0.395 ?8 SVM (RBF) UG, BG, NOT 63.8 0.400 ?9 SVM (RBF) UG, BG, NOT, MS 63.5 0.397 ?
(a) Ranking results (accuracy in % and ?
)1 2 3 4 5 6 7 8 91234 *5 *6 ?
?7 ?
* ?8 ?
* * ?
?9 ?
?
?
(b) Statistical significance of differences in ?.
**: p < 0.01, *: p < 0.05, ?
: p < 0.1Table 4: Ranking results for standalone master similarity and SVM (linear and RBF kernel).
Check insig column denote significance of correlation with true ranking (p < 0.05).
Numbers in sigdiff columndenote a significant improvement (p < 0.05) in ?
over the respective line.find that there are noticeable differences in the writing styles of amateurs and experts.
According tothe model, one of the most prominent distinctions is that amateurs tend to refer to the opponent as he,whereas experts use white and black more frequently.
However, it is of course not universally true, whichleads to the misclassification of some experts as amateurs.
Another difference in style is that amateurplayers tend to write about the game in the past tense.
This is a manifestation of an important distinction:Amateurs often state the obvious developments of the game (e.g., Flat out blunder, gave up a knightin Figure 2) or speculate about options (e.g., hoping to eventually attack), while experts provide morethorough positional analysis at key points.5.3 RankingWe now turn to ranking experiments (Table 4).
We first evaluate the ranking produced by ordering thegames by their similarity to the master centroid (line 1).
We find that the resulting rank correlation is lowbut significant.The results for the linear SVM ranker are shown in lines 2?5.
Total ranking is considerably more diffi-cult than binary classification of rating classes.
Using a linear SVM, we again achieve low but significantcorrelations.
The linear classifiers (lines 2?5) do not significantly outperform the standalone master sim-ilarity (MS) baseline (line 1).
Chess-specific features (lines 4 and 5) boost the results, outperforming thebigram models (line 3) significantly.
The improvement from adding the MS centroid score feature is notsignificant.We again perform error analysis by examining the feature weights (Table 5).
We find an overall picturesimilar to the classification setup (cf.
Table 3).
The notation feature serves as a good indicator for theupper rating range (cf.
Table 3) as experienced players find it easier to express themselves throughnotation.
We observed that lower players tend to express moves in words (e.g., ?move my knight to d5?
)rather than through notation (Nd5), which could serve as an explanation for why pieces (bishop, knight,rook) appear among the top features for amateur players.However, some features change signs between the two experiments (e.g., king, square).
This effectmay indicate that the binary ranking problem is not linearly separable, which is plausible; mid-ratedplayers may use terms that neither low-rated nor high-rated players use.
Examining correlations at dif-ferent ranking ranges confirms this suggestion.
In top and bottom thirds of the rating scale, the true andpredicted ranks are not correlated significantly.
This means that the ranking SVM only succeeds at rank-ing players in middle third of the rating scale.
To introduce non-linearity, we conduct further experimentswith an SVM with a radial basis function (RBF) kernel.The results of this experiment are shown in lines 6?9 of Table 4.
All RBF models perform better than317Class FeaturesWeaker instead, king, thinking, one my, fight, d4, even, should, should i, bishop, decided, did, i didn?t, opening, feel,put, defense, knight on, black king, been, with my, where, get, cover, pinStronger NOT:move, moves, game, time, won, i know, already, will, stop, way, winning, line, can?t, can, black has, this,MS, king side, computer, threaten, first, back, any way, my knight, win pawn, dTable 5: Top 25 features with most negative (lower rating) and positive (higher rating) weights, meanover all folds (rank(x1) > rank(x2) or vice versa) in the best ranking setup (linear SVM, UG, BG, NOT)Feature Coefficientcapture -0.29take -0.21bishop -1.06knight -0.19rook -0.54king 0.19queen 0.08pawn 0.44pin -0.26fork -0.27Feature Coefficientthreat 0.13danger 0.25stop 0.50weakness 0.34light 0.21dark 0.37variation 0.41winning 0.87losing 0.08like -0.16hate -0.05good -0.27bad 0.52Feature Coefficientwhite 0.74black 0.71he -0.51fight -0.17know 0.41will 0.88thinking -0.44believe -0.02maybe -0.19hoping -0.30Feature Coefficienttime 0.81clock -0.47time pressure -0.12blunder -0.31tempo -0.36checkmate -0.24mate 0.69opening -0.63castle -0.33fall -0.22eat -0.28Table 6: Selected SVM weights in the best 2-class setup, mean over all foldsthe unigram and bigram linear models; all except for the unigram model (lines 7?9) also yield weaklysignificant improvements over the MS baseline.
Adding the notation features (line 8 improves the resultsand leads to improvements with stronger significance.
The RBF kernel makes feature weight analysisimpossible, so we cannot perform further error analysis.5.4 Comparing the Learned Models and Strength Indicators from the Chess LiteratureThere are many conjectures from instructional chess literature and results from psychological researchabout various aspects of player behavior.
In this section, we compare these to the predictions made byour supervised expertise model.
In Table 6, we list selected weights from the best classification model(line 3 in Table 2).
We opt for analzying the classifier rather than the ranker as we find the former moredirectly interpretable.Long-Term vs Short-Term Planning.
The SVM model reflect the short-term nature of the amateurs?thoughts in several ways: (i) Amateurs focus on specific moves rather than long-term plans, and thus,terms like capture and take are deemed predictive for lower ratings.
(ii) Amateurs often think piece-specific (Silman, 1999), particularly about moves with minor pieces (bishop or knight), and these termsreceive high negative weights, pointing to lower ratings.
Related to this, Reynolds (1982) observed thatamateurs often focus on the current location of a piece, whereas experts mostly consider possible futurelocations.
The SVM model learns this by weighting bigrams of the form * on, where * is a piece, asindicators for low ratings.
(iii) Many terms related to elementary tactics (e.g., pin, fork) indicate lower-rated players, whereas terms relating to tactical foresight (e.g., threat, danger, stop) as well as positionalterms (e.g., weakness, light and dark squares, variation) indicate higher-rated players.Emotions.
A popular and wide-spread claim is that weaker chess players often lose because they aretoo emotionally invested in the game and thus get carried away (e.g., Cleveland (1907), Silman (1999)).We experimented with a sentiment feature, counting polar terms in the annotations using a polaritylexicon (Wilson et al., 2005).
However, this feature did not improve our results.Manual examination of features expressing sentiment reveals that both amateurs and experts use sub-jective terms.
We note that the vocabulary of subjective expressions is very constrained for stronger318players while it is open for weaker ones.
Expert players tend to assess positions as winning or losingfor a side, whereas weaker players tend to use terms such as like and hate.
Both terms are identified asindicators of the respective strength class in our models.
Other subjective assessments (e.g., good andbad) are divided among the classes.
Emotional tendencies of amateurs can also be observed throughobjective indicators.
As discussed above, stronger players talk about the game with a more distancedview, often referring to their opponent by their color (white or black) rather than using the pronoun he.Lower-rated players appear to use terms indicating competitions more frequently, such as fight.Confidence.
Silman (1999) argues that weaker players lack confidence, which leads to them losingtrack of their own plans and to eventually follow their opponent?s will (often called losing the initiative).This process is indeed captured by our trained models.
Terms of high confidence (such as know, will) areweighted towards the stronger class, whereas terms with higher uncertainty (such as thinking, believe,maybe, hoping) indicate the weaker class.
This observation is in line with findings on self-assignedconfidence judgments of chess players (Reynolds, 1992).
The sets of terms expressing certainty anduncertainty, respectively, are small in our dataset, so weights for most terms can be learned directly onthe n-grams.Time Management.
It has been suggested that deficiencies in time management are responsible formany losses at the amateur level, particularly in fast games (e.g., blitz chess, where each player has 5minutes to complete the game), for example due to poor pattern recognition skills of beginners (Calder-wood et al., 1988).
In the trained models, we see that the term time itself is actually considered a goodindicator for stronger players.
Time is often used to signify number of moves.
So, when used on its own,time is referring to efficient play, which is indicative of strong players.
Conversely, the terms clock andtime pressure are deemed good features to identify weaker players.Chess Terminology.
As shown in Section 2.1 and throughout this paper, there is a vast amount of chessterminology.
We observe that frequent usage of such terms (e.g., blunder ?
a grave mistake, tempo, check-mate ?
experts use mate, opening, castle) actually indicate a weaker player.
This seems counterintuitiveat first, as we may expect lower-rated players to be less familiar with such terms.
However, it appearsthat they are frequently overused by weaker players.
This also holds for metaphorical terms, such as fallor eat instead of capture.6 Related WorkThe treatment of writer expertise in extralinguistic tasks in NLP has mostly focused on two problems:(i) retrieval of experts for specific areas ?
i.e., predicting the area of expertise of a writer (e.g., Tu et al.
(2010; Kivim?aki et al.
(2013)); and (ii) using expert status in different downstream applications such assentiment analysis (e.g., Liu et al.
(2008)) or dialog systems (e.g., Komatani et al.
(2003)).
Conversely,our work is concerned with predicting a ranking by expertise within a single task.Several publications have dealt with natural language processing related to games.
Chen and Mooney(2008) investigate grounded language learning where commentary describing the specific course of agame is automatically generated.
Commentator expertise is not taken into account in this study.
Branavanet al.
(2012) introduced a model for using game manuals to increase the strength of a computer playingthe strategy video game Civilization II.
Cadilhac et al.
(2013) investigated the prediction of player actionsin the strategy board game The Settlers of Catan.
Our approach differs conceptually from theirs as theirmain focus lies on modeling concrete actions in the game (either predicting or learning them); our goalis to predict player strength, i.e., to learn to compare players among each other.
Rather than explicitlymodeling the game, commentary analysis aims to provide insight into specific thought processes.Work in psychology research by Pfau and Murphy (1988) showed the quality of chess players?
verbal-ization about positions is correlated significantly with their rating.
While they use manual assessmentsby chess masters to determine the quality of a player?s writing, our approach is to learn this distinctionis automatically given the ratings.3197 ConclusionIn this paper, we presented experiments on predicting the expertise of speakers in a task using linguisticevidence.
We introduced a classification and a ranking task for automatically ranking chess players byplaying strength using their natural language commentary.
SVM models succeed at predicting either arating class or an overall ranking.
In the ranking case, we could significantly boost the results by usingchess-specific features extracted from the text.
Finally, we compared the predictions of the SVM withpopular claims from instructional chess literature as well as results from psychology research.
We foundthat many of the traditional findings are reflected in the features learned by our models.AcknowledgementsWe thank Daniel Quernheim for providing his chess expertise, Kyle Richardson and Jason Utt for helpfulsuggestions, and the anonymous reviewers for their comments.ReferencesSRK Branavan, David Silver, and Regina Barzilay.
2012.
Learning to win by reading manuals in a monte-carloframework.
Journal of Artificial Intelligence Research, 43(1):661?704.Anais Cadilhac, Nicholas Asher, Farah Benamara, and Alex Lascarides.
2013.
Grounding strategic conversation:Using negotiation dialogues to predict trades in a win-lose game.
In Proceedings of the Conference on EmpiricalMethods in Natural Language Processing (EMNLP), pages 357?368.Roberta Calderwood, Gary A Klein, and Beth W Crandall.
1988.
Time pressure, skill, and move quality in chess.The American Journal of Psychology, 101(4):481?493.Jos?e R Capablanca.
1921.
Chess Fundamentals.
Harcourt.Chih-Chung Chang and Chih-Jen Lin.
2011.
LIBSVM: A library for support vector machines.
ACM Transactionson Intelligent Systems and Technology (ACM TIST), 2(3):1?27.David L Chen and Raymond J Mooney.
2008.
Learning to sportscast: a test of grounded language acquisition.
InProceedings of the 25th International Conference on Machine learning (ICML), pages 128?135.Alfred A Cleveland.
1907.
The psychology of chess and of learning to play it.
The American Journal of Psychol-ogy, 18(3):269?308.Steven J Edwards.
1994.
Portable game notation specification and implementation guide.Arpad E Elo.
1978.
The Rating of Chessplayers, Past and Present.
Batsford.Dan Heisman.
1995.
The Improving Annotator ?
From Beginner to Master.
Chess Enterprises.Ralf Herbrich, Thore Graepel, and Klaus Obermayer.
1999.
Large margin rank boundaries for ordinal regression.Advances in Neural Information Processing Systems (NIPS), pages 115?132.Ilkka Kivim?aki, Alexander Panchenko, Adrien Dessy, Dries Verdegem, Pascal Francq, Hugues Bersini, and MarcoSaerens.
2013.
A graph-based approach to skill extraction from text.
In Proceedings of TextGraphs-8, pages79?87.Kazunori Komatani, Shinichi Ueno, Tatsuya Kawahara, and Hiroshi G. Okuno.
2003.
Flexible guidance genera-tion using user model in spoken dialogue systems.
In Proceedings of the 41st Annual Meeting of the Associationfor Computational Linguistics (ACL), pages 256?263.Yang Liu, Xiangji Huang, Aijun An, and Xiaohui Yu.
2008.
Modeling and predicting the helpfulness of onlinereviews.
In Proceedings of the 2008 Eighth IEEE International Conference on Data Mining (ICDM), pages443?452.Eric W Noreen.
1989.
Computer Intensive Methods for Hypothesis Testing: An Introduction.
Wiley.H Douglas Pfau and Martin D Murphy.
1988.
Role of verbal knowledge in chess skill.
The American Journal ofPsychology, 101(1):73?86.320Robert I Reynolds.
1982.
Search heuristics of chess players of different calibers.
The American journal ofpsychology, 95(3):383?392.Robert I Reynolds.
1992.
Recognition of expertise in chess players.
The American journal of psychology,105(3):409?415.Jeremy Silman.
1999.
The Amateur?s Mind: Turning Chess Misconceptions into Chess Mastery.
Siles Press.Gregg E A Solomon.
1990.
Psychology of novice and expert wine talk.
The American Journal of Psychology,103(4):495?517.James H Steiger.
1980.
Tests for comparing elements of a correlation matrix.
Psychological Bulletin, 87(2):245.Yuancheng Tu, Nikhil Johri, Dan Roth, and Julia Hockenmaier.
2010.
Citation author topic model in expert search.In Proceedings of the 2010 Conference on Computational Linguistics (Coling): Posters, pages 1265?1273.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005.
Recognizing contextual polarity in phrase-level sen-timent analysis.
In Proceedings of the Conference on Human Language Technology (HLT) and EmpiricalMethods in Natural Language Processing (EMNLP), pages 347?354.321
