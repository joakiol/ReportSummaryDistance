Alternative Phrases and Natural Language InformationRetrievalGann BiernerDivision of InformaticsUniversity of Edinburghgbierner@cogsci.ed.ac.ukAbstractThis paper presents a formal analysis fora large class of words called alternativemarkers, which includes other(than),such(as), and besides.
These wordsappear frequently enough in dialog towarrant serious attention, yet presentnatural language search engines performpoorly on queries containing them.
Ishow that the performance of a searchengine can be improved dramatically byincorporating an approximation of theformal analysis that is compatible withthe search engine?s operational seman-tics.
The value of this approach is that asthe operational semantics of natural lan-guage applications improve, even largerimprovements are possible.1 IntroductionConsider the following examples discovered in acorpus of queries submitted to the Electric Knowl-edge search engine12, the successor of the OnPoint natural language search system described inCooper (1997).
Each consists of a query, a re-sponse (not shown), and then a follow-up query.
(1) What is the drinking age in Afghanistan?What is the drinking age in other countries?
(2) Where can I find web browsers for download?Where can I find other web browsers thanNetscape for download?
(3) Where can I find a list of all the shoe manu-facturers in the world?Where can I find shoes made by Buffalino,such as the Bushwackers?
(4) Where are online auctions indexed?Are there other auction search engines be-sides BidFind?1formerly known as The Electric Monk2http://www.electricknowledge.comIn each case, particular words are used to con-strain the space of appropriate answers: e.g.such (as), other (than), and besides.
I call thesewords, and others like them, alternative mark-ers, and alternative markers along with their syn-tactic argument (e.g.
other countries), I call al-ternative phrases.
Alternative phrases that areclosely bound to the noun phrase to which theyrefer, like those above, I call connected alterna-tive phrases (modeled after similar terminology inHoeksema (1995)).
There are also free alternativephrases, such as Other than Fido, every dog likesgoing for walks, which are not discussed here butare discussed in depth in Bierner (2001).
I havefound queries containing all these forms despitethe fact that no current NLIR system can han-dle them, either ignoring the alternative phraseor, worse, treating the queries as if the alternativemarker were absent.The fact that these phrases define the space ofcorrect answers makes it absolutely necessary tocorrectly interpret them in an IR application.
Theuser requires countries that are not Afghanistan,web browsers that are not Netscape, shoes withsimilar properties to Bushwackers, and auctionsearch engines that are not BidFind.
Answers thatdo not conform are wrong.Another feature of alternative markers are theirpresuppositions.
Through these presuppositions,alternative markers can provide a rich source ofknowledge about the world, as Hearst (1992) hasalready recognized.
For example, these queries im-ply that Afghanistan is a country, Netscape is aweb browser, Bushwackers are shoes, and BidFindis an auction search engine.
Anaphoric resolu-tion can sometimes be critical for these inferences.In (1), for instance, other countries anaphoricallydepends on Afghanistan in the previous query.While not as obviously important to natural lan-guage information retrieval, this property of al-ternative phrases can be used to improve futurequeries (see Section 4.1).The purpose of this paper is, first, to brieflyprovide a well-founded semantic analysis for al-ternative phrases that is amenable to computa-tion.
The main thrust is then to show that amotivated approximation of this analysis can dra-matically improve the results of a practical natu-ral language application?in particular, a naturallanguage search engine.
The value of this two-step approach is that as the operational semanticsof practical applications are gradually extended,progressively more extensive approximations canbe transparently incorporated.2 Previous WorkWork on alternative phrases has previously beenlimited to Hearst?s work in connection with knowl-edge base construction and formal semantics byHoeksema and von Fintel.
Hearst (1992) demon-strates cases where pattern matching can be usedto extract knowledge from some constructionswith alternative phrases and gives the patterns in(5) as examples.
(5) a. such NP as {NP,}* {or|and} NPb.
NP {, NP}* {,} {or|and} other NPc.
NP {,} including {NP,}* {or|and} NPd.
NP {,} especially {NP,}* {or|and} NPThis technique is adequate for the purpose ofacquiring hyponyms from large corpora becausethe goal is to take advantage of easily availableinformation, not to handle a wide variation of lin-guistic phenomena.
Handling a full range of nat-ural language queries requires a deeper approach.For example, pattern matching alone cannot ac-count for anaphoric reference such as in (1) or ex-amples where discourse knowledge invalidates thehyponym relation as in (6).
(6) John?s pet dog, Fido, was sick.So John and the other dogs went for a walk.In contrast, von Fintel (1993) andHoeksema (1995) provide in-depth semanticanalyses of a limited class of alternative phrases;namely they focus entirely on exceptive phrases(ways of referring to exceptions) illustrated by thelexical items but and except (for).
The thrustof their analyses is directed towards how thesewords interact with quantifiers to determine thefinal set of entities.
Since in queries, quantifiersrarely interact with alternative phrases in themanner discussed in Hoeksema and von Fintel?swork, their analyses have not been carried overinto the present work.3 AnalysisI present a formal approach to alternative phrasesthat is wider in scope than the alternatives re-viewed in Section 2 (although less detailed in somerespects than von Fintel and Hoeksema?s work).3.1 Presupposition and AssertionIn my analysis of alternative phrases, I makeuse of the pragmatic view of presuppositionsexplored by Lewis (1979) and Stalnaker (1974)which, stated loosely, sees them as proposi-tions that must be true for an utterance tomake sense.
(For an overview of presup-position, see Beaver (1997).)
The semanticsof lexical entries are separated into assertionand presupposition as in Stalnaker (1974) andKarttunen and Peters (1979).
The idea is alsoused in Webber et al (1999) to capture anaphoric(non-structural) links between discourse con-nectives and material derivable from previousdiscourse, and in Stone and Doran (1997) andStone and Webber (1998) for natural languagegeneration.Lexical entries are written in the followingform, where the semantic parameters scope boththe assertion and presuppositions:word `????
?syn : syntactic categorysem : ?...
{assert : propositionpresup : proposition*3.2 Alternative SetsThe concept of alternative sets plays an impor-tant role in the semantics of alternative phrases.An alternative set is a set of propositions whichdiffer with respect to how one or more argu-ments are filled.
For example, the alternativeset {like(mary, jen), like(mary, bob), ...} repre-sents the entities that Mary likes.
An earlydiscussion of these structures is provided inKarttunen and Peters (1979) where an analysis isgiven for the focus particle even.
Alternative setsare also used by Rooth (1985) and Rooth (1992)to develop a detailed account of focus, particularlywith the focus particle only.My analysis approximates this set of proper-ties as a pair consisting of a set of entities (e.g.
{jen, bob, ...}) and the property they share (e.g.
?x.like(mary, x)).
My analyses of alternativephrases uses the relation alts(p, q) which, intu-itively, specifies that the two sets of entities de-noted by p and q can be found together in at leastone alternative set in the knowledge base.
Thedescription component of the alternative set (i.e.the property) need not be known.
It is importantto note that although here I focus on unifying suchstructures, I also make use of the fact that alts isa relation that is symmetric and reflexive, but nottransitive.The alternative phrases I have analyzed fall intotwo classes: those that assemble a set from ele-ments and those that excise a set from a largerset (as in exceptive phrases).
In either case, oneparticular set of elements is of interest, the fig-ure.
With assembly words, the figure is eitheradmitted into the set or combined with a com-plement to form a set.
With excision, the figureis explicitly excluded from the ground.
The figuremay derive from structurally-related constituents(as with besides), or it may be presupposed (aswith other).3.3 A Grammar FormalismI implement my analyses with Combinatory Cat-egorial Grammar (Steedman, 1996; Steedman,2000).
CCG is a lexicalized grammar that encodesboth the syntactic and semantic properties of aword in the lexicon.
For the analyses presented inthis paper, standard Categorial Grammar suffices.A minor variation is that rather than havingthe basic categories N and NP, I simply use NP.Noun phrases with and without determiners aredistinguished with the bare feature.3.4 An ExampleIn this section, I provide an analysis of one syntac-tic form of other in order to illustrate the semantictechnique described above.
Discussion of alternatesyntactic forms and other alternative markers canbe found in Bierner (2001).The semantic analysis below defines other asan excision word that excludes the figure from theground.
The figure is a free variable that must beprovided from the common ground or discourse,as is the case in (1).other `????
?syn : NPcomp+,eq?/NPbare+sem : ?g??
?assert : ?x.g(x) ?
?f(x)presup : ?x.f(x)?
g(x)alts(f, ?x.g(x) ?
?f(x))The analysis allows the derivation in Figure 1.other countriesNP/NP : ?g?x.g(x) ?
?f(x) NP : country>NP : ?x.country(x) ?
?f(x)presupposition set:{?x.f(x)?
country(x)alts(f, ?x.country(x) ?
?f(x))Figure 1: Derivation for other countriesAt this point, the semantics is dependent on thefree variable f , the figure.
This is reflected by thefact that, in isolation, other countries does notmake sense.
Although such anaphoric reference isdifficult to resolve, in some constructions we canidentify the figure without bringing full resolutiontechniques to bear?as we would have to in (1).Some of these constructions, as in Figure 2, arethose that contain the word than, whose analysisis given below.than `????
?syn : NP\NPeq?,comp+/NPsem : ?x?y{assert : ypresup : alts(x, y)The presupposition set in Figure 2 is the unionof the presuppositions of other and than, asbound during the derivation.
The remainingvariable, f , can be determined solely from thederivation?s presupposition set using the old AIplanning heuristic ?use existing objects?
(Sacer-doti, 1977) to avoid inventing new objects whenothers are already available.
In particular, wecan unify alts(f, ?x.browser(x) ?
?f(x)) andalts(netscape, ?x.browser(x)?
?f(x)), discover-ing that f , the figure, is netscape.
This theninstantiates the remaining presupposition, yield-ing ?x.netscape(x)?
browser(x): i.e.
Netscapeis a browser.
Unifying logical forms to instantiatevariables in this way follows the ?interpretation asabduction?
paradigm (Hobbs et al, 1993), wherethis merging is performed to exploit redundancyfor ?getting a minimal, and hence a best, inter-pretation.
?Similar analyses in terms of alternative sets havebeen developed for many other alternative phrasesin Bierner (2001).In the next section I show that practical applica-tions such as natural language search engines canbenefit from appropriate approximations of thiskind of analysis.4 Natural Language IRThere are a variety of techniques for allowing nat-ural language queries in information retrieval sys-tems.
The simplest approach is simply to re-move the ?function words?
from the query anduse the remaining words in a standard keywordsearch (Alta Vista).
In more complex approaches,pattern matching (the EK search engine), pars-ing (Ask Jeeves), and machine learning (Zelle andMooney, 1993) techniques can support the associ-ation of more appropriate keywords with a query.I will concentrate on the pattern matching tech-nique of the Electric Knowledge search engine andother web browsers than NetscapeNPcomp+/NP : NPcomp?
: (NP\NPcomp+)/NP : NP :?g?x.g(x) ?
?f(x) browser ?x?y.y netscape> >NPcomp+ : ?x.browser(x) ?
?f(x) NP\NPcomp+ : ?y.y<NP : ?x.browser(x) ?
?f(x)presupposition set:????x.f(x)?
browser(x)alts(f, ?x.browser(x) ?
?f(x))alts(netscape, ?x.browser(x) ?
?f(x))Figure 2: Derivation for other web browsers than Netscapeshown how a theory of alternative phrases candrastically improve results.4.1 The EK search engine?s OperationalSemanticsThe Electric Knowledge search engine uses pat-tern recognition to transform a natural languagequestion into a series of increasingly more generalBoolean queries that can be used with standardback-end retrieval techniques.
The question is fil-tered through a hierarchy of regular expressions,and hand-crafted rules are used to extract infor-mation from the question into Boolean expres-sions.
The regular expression matching is aidedby an ISA hierarchy such that generalizations ofkeywords can be captured.
As mentioned in Sec-tion 1, the fact that the presuppositions of alterna-tive phrases encode hyponym information can beuseful in augmenting this aspect of systems likethe EK search engine.This technique suffers from the fact that, in or-der to be tractable, this set of patterns is limitedand important information in the query can belost.
In particular, the Electric Knowledge searchengine does not have patterns that attempt to as-sociate alternative phrases with appropriate piecesof boolean query.To overcome this, an appropriate approxima-tion of the semantic result of my analysis that iscompatible with the back end search system mustbe found.
For the Electric Knowledge search en-gine (similar approaches are certainly possible forother NLIR systems), a hybrid query has been in-troduced to account for alternative phrases, whichcombines a natural language query with furtherrestrictions added in a system-specific language.The syntax is shown in (7).
(7) Query : | : ANSWER NOT NEAR (| word list)(8) What are some web browsers?
: | : ANSWERNOT NEAR (| netscape)The natural language query is separated fromthe restrictions by the : | : symbol.
The restrictionsspecify that the answer to the query must not benear to certain words.The hybrid query in (8), for example, is a trans-formation of the original query What are someother web browsers than Netscape?.
The EK searchengine uses the natural language part of the queryto initially locate possible answering documents.The rest of the query is used when gathering evi-dence for including a document in the final results.The EK search engine finds a location in the docu-ment that should answer the query and then com-pares it against the criteria appended to the end ofthe query.
If it does not meet the criteria (that itnot be near the word Netscape), another locationis tried.
If there are no more possible answers, thedocument is rejected.This is, of course, not exactly what theoriginal query meant.
However, it is su-perior to queries like ??browsers??
AND NOT??netscape??
which rejects all pages containingNetscape, even if they also contain other browsers.The evaluation in Section 5 shows that this op-erational semantics is sufficient to dramaticallyimprove the results for queries with alternativephrases.4.2 The AlgorithmInstead of using the EK search engine?s patternmatching on the initial question, the algorithmdoes a post-analysis of the syntactic structure pro-duced by parsing the question with my analysis.The algorithm recursively descends the deriva-tion, searching for semantic forms that result fromalternative phrases.
The information from the al-ternative phrase is removed and then appended tothe end of the hybrid query in a different form.
InFigure 2, for example, the information other thanNetscape is removed, leaving only web browsers,to form the hybrid query in (8).Physics EE TotalStud Tut Stud Tutin addition to 0 0 0 3 3besides 1 3 0 2 6another 56 124 10 38 228especially 0 1 0 0 1except 0 17 1 1 19other 107 484 36 59 686in particular 0 6 0 0 6such 2 18 3 10 33unlike 0 0 0 1 1Total 166 653 50 114 983Alternative Phrases per DialogDialogs 203 203 66 66 269AP/dialog 0.82 3.22 0.76 1.73 3.65Alternative Phrases in Queries per DialogQuery APs 51 261 16 86 414per dialog 0.25 1.29 0.24 1.3 1.54Table 1: Frequency of Alternative Phrases in Di-alog5 Evaluation5.1 Frequency of Alternative PhrasesFirst, it is useful to determine how many queriescontain alternative phrases in order to judge howlarge a problem this really is.
Unfortunately, thisis complicated by the fact that users, in general,know that such constructions are not understoodby search engines, so they avoid them.
In fact,even in NLIR systems, users often use keywordseven though doing so performs worse than askingnatural language questions.
They do this becausethey do not trust the system.
Work will be neces-sary to improve users?
awareness of NL capabili-ties through advertising and by implementing newuser interfaces.
Work will also be needed to takemore account of the fact that search is often aniterative and even interactive process.
As notedby Lewis and Sparck-Jones (1996), the results oflarge-scale document-retrieval competitions suchas the Text Retrieval Conference (TREC, 2000) donot necessarily reflect the experience many usershave with retrieval systems.In the meantime, I have attempted to find abaseline for this number by considering two cor-pora of human/human dialogs.
The corpora areboth from tutorial situations where a mentor helpsa student through problems in the subject ofPhysics for one corpus (VanLehn et al, 1998; Van-Lehn et al, in press), and Basic Electricity andElectronics (Rose et al, 1999), for the other.
Tu-toring dialogs are an ideal place to look for datarelevant to NLIR because they consist entirely ofone party attempting to elicit information fromthe other.
In some cases, it is the tutor elicitinginformation from the student, and in others it isthe other way around.Table 1 shows the frequencies of some alterna-tive phrases.
A more illuminating statistic is howoften alternative phrases appear in a single dialog.I consider a dialog to be a single session betweenthe student and tutor where the discussion of eachproblem is considered a separate session.
The ta-ble shows that in 269 total dialogs, each dialogcontained, on average, 3.65 alternative phrases.
Ifone only considers alternative phrases that occurin the context of a question, there are, on average,1.54 alternative phrases per dialog.
I consider analternative phrase to be in a question context if itis in the same dialog turn as a question.
Becausetutors ask questions in order to lead the student tothe answer, it is perhaps better to consider just thestudent data, where a quarter of the dialogs con-tained question contexts with alternative phrases.This data is not meant to be considered a rig-orous result, but it is a strong indication that anyquery-answering system is likely to confront an al-ternative phrase during the course of interactingwith a user.
Furthermore, the data shows thatduring the course of the interaction it will be ap-propriate for the system to respond using an al-ternative phrase, which is important when con-sidering more responsive search engines than areavailable today.It is also interesting to note that a wide vari-ety of alternative phrases occur in this data.
(9)contains some examples.
Because excision words,especially other, are by far the most frequent, Ihave only considered them in the evaluation pre-sented here.
(9) a.
The battery is the green cylinderright?
I don?t see anything negativeother than #5.b.
And what do you have in addition tovoltage?c.
Are there any other forces on thatknob besides that one you?ve labeledW1?5.2 Potential ImprovementOf interest is the potential for improving varioussearch engines through a better way of treatingalternative phrases.
To start with, given a set ofqueries containing alternative phrases, it is impor-tant to see how well these systems perform with-out enhancement.
Table 2 shows the performanceof Alta Vista, Ask Jeeves, and the EK search en-gine on eight excision examples taken from theAV Jeeves MonkCancer 2/9, 6 2/5, 3 2/3, 0BidFind 2/7, 5 1/6, 0 0/0, 0Jobs 2/9, 0 2/5, 0 3/9, 6Warts 0/9, 6 1/4, 2 0/1, 1Drinking 4/10, 0 0/5, 1 0/2, 0Browsers 2/8, 6 3/5, 2 0/9, 8Witches 0/10, 10 0/5, 4 0/0, 0Hondo 0/7, 6 1/6, 3 0/0, 0Avr.
Precision 17% 25% 20%Avr.
% falsepositives due tosearching for thefigure67% 53% 58%Table 2: Potential Improvement for NLIR Systemscorpus of EK search engine queries.
For a dataentry ?x/y, z?, y is the total number of returneddocuments and x are those which contain an an-swer to the query.
z are the number of answersthat are wrong because they are about the subjectthat was explicitly being excluded in the query.As the data shows, none of the search enginesfare particularly well.
The precision for all threeis around 20%.
That is, only about one in five ofthe responses contain an answer to the query.
Fur-thermore, from a half to two thirds of the incorrectresponses were specifically about the subject thequery wanted to exclude, displaying little or nounderstanding of excision alternative phrases.The point is not to draw any conclusions aboutthe relative merits of the search engines from thistest.
Rather, it is that each NLIR system showsroom for improvement.
Since I will demonstratethat improvement only for the Electric Knowledgesearch engine, next, this shows that that improve-ment is not due to exceptionally bad prior perfor-mance by the EK search engine.5.3 Enhancing the EK search engineTable 3 shows the results of asking the EK searchengine questions in three different forms: withoutan alternative phrase, with an alternative phrasethat has not been translated, and with the alterna-tive phrase translated as described in Section 4.2.The first row of the table, for instance, refers tothe questions in (10).
The remaining sentencescan be found in Bierner (2001).
Although an im-plementation exists that is capable of performingthe translation in Section 4.2, this was done byhand for this evaluation to abstract away fromparsing issues.
(10) What are some works by Edgar Allan Poe?What are some works by Edgar Allan Poeother than the Raven?What are some works by Edgar Allan Poe?
: | : ANSWER NOT NEAR (| raven)Unfortunately, at the time of this evaluation,Electric Knowledge had taken down their publicportal in favor of providing search for the webpages of specific clients.
This means that the largeindex used to process the queries in Table 2 wasno longer available, and I therefore used differentindices and different queries for this evaluation.I used indices of pages about American historyand literature?each about 11,000 pages.
Thesenew, more specialized, indices have the benefitof abstracting this evaluation away from coverageissues (explaining the differences in precision be-tween Table 2 and Table 3).I created the questions in two ways.
For sev-eral, I began by asking a question without analternative phrase.
I then added an alterna-tive phrase in order to remove some responsesI was not interested in.
For example, whenI asked Who are the romantic poets?, all re-sponses were about female romantic poets.
Itherefore used the query Who are the romanticpoets not including women?
in the evaluation.Some queries were made without first trying thenon-alternative phrase version: What are someepics besides Beowulf?, for example.
Thisvariation reflects the fact that it is unclear which ismore common, excluding clutter from a set of re-sponses or a priori excluding cases that the ques-tioner is not interested in.
The queries also vary intheir syntactic structure, information requested,and alternative phrase used.
The purpose of vary-ing the queries in these ways is to ensure that theresults do not simply reflect a quirk in the EKsearch engine?s implementation.For each query, Table 3 shows total, the numberof documents returned; good, the number of truepositives; and top 5, the number of true positivesin the top five returned documents.
A true pos-itive was given to a document if it contained ananswer to the question, and half a point was givento a document that contained an obvious link toa document with an answer to the question.
Pre-cision is computed for all documents and for thetop five.
It is important to note that the scoresfor the queries without alternative phrases are stillcomputed with respect to the alternative phrase.That is, documents only about the ?Raven?
areconsidered false positives.
In this way, we can viewthese scores as a baseline?what would have hap-pened had the system simply removed the alter-native phrase.
This should be taken with a grainBaseline Original Query HybridTot Good Top 5 Tot Good Top 5 Tot Good Top 5Poe 12 6.5 3 10 0.5 0.5 10 5.5 2.5Romantics 10 0 0 15 0 0 10 3 3Witch Hunts 10 8 3 14 2 1 10 8 5US Wars 15 12 2 0 0 0 16 13 4Sonnets 15 10 5 10 2 0 10 8 4Presidents 15 2 2 15 0 0 15 2 2Epics 10 7 4 10 5 3 10 7 4Dec of Ind 10 2 0 0 0 0 10 5.5 2Avr.
Precision 48% 47.5% 14.9% 15% 58% 66.3%Table 3: Evaluation of Improvement for NLIR Systemsof salt because, in many cases, I chose the querybecause there were documents to remove (as inthe Romantics example).
However, a concern wasthat the transformed query would cause numerousfalse negatives.
This is not the case as seen by thefact that the precision of the transformed query isnot lower than the baseline.
In fact, in no exam-ple was the precision less than the baseline, andat worse, the precision remained the same.Performance on questions containing alterna-tive phrases was quite poor, with an average of15% precision.
This is significantly worse thanthe transformed query, and even the baseline.
Theperformance drop is due to the fact that the com-plex syntax of the query confuses the EK searchengine?s analysis.
The EK search engine is forcedto reduce the query to a simple set of keywords in-cluding the figure, which we were trying to avoid.Thus as predicted in the discussion of poten-tial improvement, not accounting for alternativephrases can greatly increase the number of falsepositives containing the figure (FPF), the verything the query is attempting to exclude.
Table 4shows that in the baseline case, where there is noalternative phrase, on average for 28% of the re-turned documents the only answer was the one wewanted to exclude.
Adding the alternative phrasehas the opposite of the intended effect as the per-centage of FPFs increases to 44% for reasons de-scribed above.
Transforming the query, on theother hand, causes the desired effect, more thanhalving the percentage of FPFs of the baseline.6 ConclusionsIn this paper, I briefly presented a formal anal-ysis for a large class of words called alterna-tive markers.
The analysis elegantly capturesthe desired phenomena by separating assertionand presupposition and making use of alternativephrases and the ?use existing objects?
heuristic.A simple pattern matching approach would fail tocapture examples requiring knowledge and thosewith anaphora.
Furthermore, sophisticated nounphrase detection would be required for many ex-amples.I then show that alternative phrases appear fre-quently enough in dialog to warrant serious atten-tion, yet present natural language search enginesperform poorly on queries containing alternativephrases.
However, by approximating my seman-tic analysis into a form understood by a naturallanguage search engine, I showed that the perfor-mance of that search engine improved dramati-cally.
As the operational semantics of natural lan-guage applications improves, even larger improve-ments are possible.Further improvement is also possible by ap-proaching the problem from the other direction.Alternative phrases can be used to help charac-terize documents beyond the simple word indicesused in many current systems.
This richer datacan be used in the retrieval process to more effec-tively identify appropriate documents.ReferencesDavid Beaver.
1997.
Presupposition.
In Johanvan Benthem and Alice ter Meulen, editors,Handbook of Logic and Language, pages 939?1008.
North Holland, Amsterdam.Gann Bierner.
2001.
Alternative phrases: theoret-ical analysis and practical applications.
Ph.D.thesis, Division of Informatics, University of Ed-inburgh.Edwin Cooper.
1997.
The On Point sys-tem: A natural language search engine for theworld wide web.
Master?s thesis, University ofChicago.Marti Hearst.
1992.
Automatic acquisition of hy-ponyms from large text corpora.
In Proceed-ings of the Fourteenth International ConferenceBaseline Original Query HybridFPF FPF/Tot FPF FPF/Tot FPF FPF/TotPoe 1 .08 1 .1 1 .1Romantics 8 .8 15 1 2 .2Witch Hunts 2 .2 1 .07 0 0US Wars 3 .2 3 .19Sonnets 5 .33 8 .8 2 .2Presidents 5 .33 10 .67 2 .13Epics 0 0 0 0 0 0Dec of Ind 3 .3 2 .228.1% 44% 12.8%Table 4: False Positives Containing Figureon Computational Linguistics, Nantes, France,July.Jerry R. Hobbs, Mark E. Stickel, Douglas E. Ap-pelt, and P. Martin.
1993.
Interpretation as ab-duction.
Artificial Intelligence, 63(1?2):69?142,October.Jacob Hoeksema.
1995.
The semantics of ex-ception phrases.
In Jaap van der Does andJan van Eijck, editors, Quantifiers, Logic, andLanguage, chapter 6, pages 145?177.
CambridgeUniversity Press.Lauri Karttunen and Stanley Peters.
1979.
Con-ventional implicature.
In Choon-Kyu Oh andDavid Dinneen, editors, Syntax and Semantics11: Presupposition.
New York, Academic Press.David Lewis and Karen Sparck-Jones.
1996.
Nat-ural language processing for information re-trieval.
In Communications of the ACM, vol-ume 39, pages 92?101, January.David Lewis.
1979.
Scorekeeping in a languagegame.
Journal of Philosophical Logic, 8:339?359.Mats Rooth.
1985.
Association with Focus.
Ph.D.thesis, University of Massachusetts, Amherst.Mats Rooth.
1992.
A theory of focus interpreta-tion.
Natural Language Semantics, 1:75?116.C.
P. Rose, B.
Di Eugenio, and J. D. Moore.
1999.A dialogue based tutoring system for basic elec-tricity and electronics.
In Proceedings of AI inEducation.Earl Sacerdoti.
1977.
A Structure for Plansand Behavior.
Elsevier/North-Holland, Ams-terdam.Robert Stalnaker.
1974.
Pragmatic presupposi-tions.
Semantics and Philosophy, pages 129?214.Mark Steedman.
1996.
Surface Structure and In-terpretation.
MIT Press, Cambridge Mass.
Lin-guistic Inquiry Monograph, 30.Mark Steedman.
2000.
The Syntactic Process.The MIT Press, Cambridge Mass.Matthew Stone and Christine Doran.
1997.
Sen-tence planning as description using tree adjoin-ing grammar.
In Proceedings of the 35th AnnualMeeting of the Association for ComputationalLinguistics and the 8th Conference of the Eu-ropean Association for Computational Linguis-tics, Madrid, July, pages 198?205.Matthew Stone and Bonnie Webber.
1998.
Tex-tual economy through close coupling of syntaxand semantics.
In International Workshop onNatural Language Generation, pages 178?187,Niagara-on-the-Lake, Canada, August.TREC.
2000. http://trec.nist.gov/.K.
VanLehn, S. Siler, C. Murray, and W.B.Baggett.
1998.
What makes a tutorial event ef-fective?
In M. A. Gernsbacher and S. Derry, ed-itors, Proceedings of the Twentieth Annual Con-ference of the Cognitive Science Society, pages1084?1089, Hillsdale, NJ.K.
VanLehn, S. Siler, C. Murray, T. Yamauchi,and W.B.
Baggett.
in press.
Human tutoring:Why do only some events cause learning?
Cog-nition and Instruction.Kai von Fintel.
1993.
Exceptive constructions.Natural Language Semantics, 1(2):123?148.Bonnie Webber, Alistair Knott, Matthew Stone,and Aravind Joshi.
1999.
Discourse relations:A structural and presuppositional account usinglexicalised tag.
In Proceedings of the 37th Con-ference of the Association for ComputationalLinguistics, pages 41?48, College Park, MD.John M. Zelle and Raymond J. Mooney.
1993.Learning semantic grammars with constructiveinductive logic programming.
In Proceedings ofthe 11th National Conference on Artificial Intel-ligence, pages 817?823, Menlo Park, CA, USA.AAAI Press.
