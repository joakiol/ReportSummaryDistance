Proceedings of the NAACL HLT Workshop on Innovative Use of NLP for Building Educational Applications, pages 19?26,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsInferring Tutorial Dialogue Structure with Hidden Markov ModelingKristyElizabethBoyeraEun YoungHaaRobertPhillipsabMichaelD.WallisabMladen A.VoukaJames C.LesteraaDepartment of Computer Science, North Carolina State UniversitybApplied Research AssociatesRaleigh, NC, USA{keboyer, eha, rphilli, mdwallis, vouk, lester}@ncsu.eduAbstractThe field of intelligent tutoring systems hasseen many successes in recent years.
Asignificant remaining challenge is theautomatic creation of corpus-based tutorialdialogue management models.
This paperreports on early work toward this goal.
Weidentify tutorial dialogue modes in anunsupervised fashion using hidden Markovmodels (HMMs) trained on inputsequences of manually-labeled dialogueacts and adjacency pairs.
The two best-fitHMMs are presented and compared withrespect to the dialogue structure theysuggest; we also discuss potential uses ofthe methodology for future work.1 IntroductionThe field of intelligent tutoring systems has madegreat strides toward bringing the benefits of one-on-one tutoring to a wider population of learners.Some intelligent tutoring systems, called tutorialdialogue systems, support learners by engaging inrich natural language dialogue, e.g., (Graesser etal.
2003; Zinn, Moore & Core 2002; Evens &Michael 2006; Aleven, Koedinger & Popescu2003; Litman et al 2006; Arnott, Hastings &Allbritton 2008; VanLehn et al 2002).
However,creating these systems comes at a high cost: itentails handcrafting each pedagogical strategy thetutor might use and then realizing these strategiesin a dialogue management framework that is alsocustom-engineered for the application.
It is hopedthat the next generation of these systems canleverage corpora of tutorial dialogue in order toprovide more robust dialogue management modelsthat capture the discourse phenomena present ineffective natural language tutoring.The structure of tutorial dialogue hastraditionally been studied by manually examiningcorpora and focusing on cognitive andmotivational aspects of tutorial strategies (e.g.,Lepper et al 1993; Graesser, Person & Magliano1995).
While these approaches yieldedfoundational results for the field, such analysessuffer from two serious limitations:  manualapproaches are not easily scalable to different orlarger corpora, and the rigidity of handcrafteddialogue structure tagging schemes may notcapture all the phenomena that occur in practice.In contrast, the stochastic nature of dialoguelends itself to description through probabilisticmodels.
In tutorial dialogue, some early work hasadapted language processing techniques, namely n-gram analyses, to examine human tutors?
responsesto student uncertainty (Forbes-Riley & Litman2005), as well as to find correlations between localtutoring strategies and student outcomes (Boyer etal.
2008).
However, this work is limited by itsconsideration of small dialogue windows.Looking at a broader window of turns is oftenaccomplished by modeling the dialogue as aMarkov decision process.
With this approach,19techniques such as reinforcement learning can beused to compare potential policies in terms ofeffectiveness for student learning.
Determiningrelevant feature sets (Tetreault & Litman 2008)and conducting focussed experiments for localizedstrategy effectiveness (Chi et al 2008) are activeareas of research in this line of investigation.These approches often fix the dialogue structuresunder consideration in order to compare theoutcomes associated with those structures or thefeatures that influence policy choice.In contrast to treating dialogue structure as afixed entity, one approach for modeling theprogression of complete dialogues involveslearning the higher-level structure in order to infersuccinct probabilistic models of the interaction.For example, data-driven approaches fordiscovering dialogue structure have been applied tocorpora of human-human task-oriented dialogueusing general models of task structure (Bangalore,Di Fabbrizio & Stent 2006).
Encouraging resultshave emerged from using a general model of thetask structure to inform automatic dialogue acttagging as well as subtask segmentation.Our current work examines a modelingtechnique that does not require a priori knowledgeof the task structure:  specifically, we propose touse hidden Markov models (HMMs) (Rabiner1989) to capture the structure of tutorial dialogueimplicit within sequences of tagged dialogue acts.Such probablistic inference of discourse structurehas been used in recent work with HMMs for topicidentification (Barzilay & Lee 2004) and relatedgraphical models for segmenting multi-partyspoken discourse (Purver et al 2006).Analogously, our current work focuses onidentifying dialogic structures that emerge duringtutorial dialogue.
Our approach is based on thepremise that at any given point in the tutorialdialogue, the collaborative interaction is ?in?
adialogue mode (Cade et al 2008) that characterizesthe nature of the exchanges between tutor andstudent; these modes correspond to the hiddenstates in the HMM.
Results to date suggest thatmeaningful descriptive models of tutorial dialoguecan be generated by this simple stochasticmodeling technique.
This paper focuses on thecomparison of two first-order HMMs:  one trainedon sequences of dialogue acts, and the secondtrained on sequences of adjacency pairs.2 Corpus AnalysisThe HMMs were trained on a corpus of human-human tutorial dialogue collected in the domain ofintroductory computer science.
Forty-threelearners interacted remotely with one of fourteentutors through a keyboard-to-keyboard remotelearning environment yielding 4,864 dialoguemoves.2.1 Dialogue Act TaggingThe tutoring corpus was manually tagged withdialogue acts designed to capture the salientcharacteristics of the tutoring process (Table 1).Tag Act ExampleQ Question Where should IDeclare i?EQ Evaluation Question How does that look?S Statement You need aclosing brace.G Grounding Ok.EX Extra-Domain You may useyour book.PF Positive Feedback Yes, that?s right.LF Lukewarm Feedback Sort of.NF Negative Feedback No, that?s not right.Table 1.
Dialogue Act TagsThe correspondence between utterances anddialogue act tags is one-to-one; compoundutterances were split by the primary annotator priorto the inter-rater reliability study.1  This dialogueact tagging effort produced sequences of dialogueacts that have been used in their un-altered formsto train one of the two HMMs presented here(Section 3).2.2 Adjacency Pair IdentificationIn addition to the HMM trained on sequences ofindividual dialogue acts, another HMM wastrained on sequences of dialogue act adjacencypairs.
The importance of adjacency pairs is well-established in natural language dialogue (e.g.,Schlegoff & Sacks 1973), and adjacency pairanalysis has illuminated important phenomena intutoring as well (Forbes-Riley et al 2007).
The1 Details of the study procedure used to collect the corpus, aswell as Kappa statistics for inter-rater reliability, are reportedin (Boyer et al 2008).20intuition behind adjacency pairs is that certaindialogue acts naturally occur together, and bygrouping these acts we capture an exchangebetween two conversants in a single structure.This formulation is of interest for our purposesbecause when treating sequences of dialogue actsas a Markov process, with or without hidden states,the addition of adjacency pairs may offer asemantically richer observation alphabet.To find adjacency pairs we utilize a ?2 test forindependence of the categorical variables acti andacti+1 for all sequential pairs of dialogue acts thatoccur in the corpus.
Only pairs in whichspeaker(acti) ?
speaker(acti+1) were considered.Table 2 displays a list of all dependent adjacencypairs sorted by descending (unadjusted) statisticalsignificance; the subscript on each dialogue act tagindicates tutor (t) or student (s).An adjacency pair joining algorithm was appliedto join statistically significant pairs of dialogueacts (p<0.01) into atomic units according to apriority determined by the strength of the statisticalsignificance.
Dialogue acts that were ?left out?
ofadjacency pair groupings were treated as atomicelements in subsequent analysis.
Figure 1illustrates the application of the adjacency pairjoining algorithm on a sequence of dialogue actsfrom the corpus.Figure 1.
DA Sequence Before/After Joining3 HMM of Dialogue StructureA hidden Markov model is defined by threeconstituents:  1) the set of hidden states (dialoguemodes), each characterized by its emissionprobability distribution over the possibleobservations (dialogue acts and/or adjacencypairs), 2) the transition probability matrix amongobservations (dialogue acts and/or adjacencypairs), 2) the transition probability matrix amongacti acti+1P(acti+1|acti)P(acti+1|?acti)?2val p-valEQs PFt 0.48 0.07 654 <0.0001Gs Gt 0.27 0.03 380 <0.0001EXs EXt 0.34 0.03 378 <0.0001EQt PFs 0.18 0.01 322 <0.0001EQt Ss 0.24 0.03 289 <0.0001EQs LFt 0.13 0.01 265 <0.0001Qt Ss 0.65 0.04 235 <0.0001EQt LFs 0.07 0.00 219 <0.0001Qs St 0.82 0.38 210 <0.0001EQs NFt 0.08 0.01 207 <0.0001EXt EXs 0.19 0.02 177 <0.0001NFs Gt 0.29 0.03 172 <0.0001EQt NFs 0.11 0.01 133 <0.0001Ss Gt 0.16 0.03 95 <0.0001Ss PFt 0.30 0.10 90 <0.0001St Gs 0.07 0.04 36 <0.0001PFs Gt 0.14 0.04 34 <0.0001LFs Gt 0.22 0.04 30 <0.0001St EQs 0.11 0.07 29 <0.0001Gt EXs 0.07 0.03 14 0.002St Qs 0.07 0.05 14 0.0002Gt Gs 0.10 0.05 9 0.0027EQt EQs 0.13 0.08 8 0.0042Table 2.
All Dependent Adjacency Pairshidden states, and 3) the initial hidden state(dialogue mode) probability distribution.3.1  Discovering Number of Dialogue ModesIn keeping with the goal of automaticallydiscovering dialogue structure, it was desirable tolearn n, the best number of hidden states for theHMM, during modeling.
To this end, we trainedand ten-fold cross-validated seven models, eachfeaturing randomly-initialized parameters, for eachnumber of hidden states n from 2 to 15, inclusive.2The average log-likelihood fit from ten-fold cross-2 n=15 was chosen as an initial maximum number of statesbecause it comfortably exceeded our hypothesized range of 3to 7 (informed by the tutoring literature).
The AkaikeInformation Criterion measure steadily worsened above n = 5,confirming no need to train models with n > 15.21validation was computed across all seven modelsfor each n, and this average log-likelihood ln wasused to compute the Akaike Information Criterion,a maximum-penalized likelihood estimator thatprefers simpler models (Scott 2002).
Thismodeling approach was used to train HMMs onboth the dialogue act and the adjacency pair inputsequences.3.2  Best-Fit ModelsThe input sequences of individual dialogue actscontain 16 unique symbols because each of the 8dialogue act tags (Table 1) was augmented with alabel of the speaker, either tutor or student.
Thebest-fit HMM for this input sequence containsnDA=5 hidden states.
The adjacency pair inputsequences contain 39 unique symbols, including alldependent adjacency pairs (Table 2) along with allindividual dialogue acts because each dialogue actoccurs at some point outside an adjacency pair.The best-fit HMM for this input sequence containsnAP=4 hidden states.
In both cases, the best-fitnumber of dialogue modes implied by the hiddenstates is within the range of what is oftenconsidered in traditional tutorial dialogue analysis(Cade et al 2008; Graesser, Person & Magliano1995).4 AnalysisEvaluating the impact of grouping the dialogueacts into adjacency pairs requires a fine-grainedexamination of the generated HMMs to gaininsight into how each model interprets the studentsessions.4.1 Dialogue Act HMMFigure 2 displays the emission probabilitydistributions for the dialogue act HMM.
State 0DA,Tutor Lecture,3 is strongly dominated by tutorstatements with some student questions andpositive tutor feedback.
State 1DA constitutesGrounding/Extra-Domain, a conversational stateconsisting of acknowledgments, backchannels, anddiscussions that do not relate to the computerscience task.
State 2DA, Student Reflection,3 For simplicity, the states of each HMM have been namedaccording to an intuitive interpretation of the emissionprobability distribution.generates student evaluation questions, statements,and positive and negative feedback.
State 3DA iscomprised of tutor utterances, with positivefeedback occurring most commonly followed bystatements, grounding, lukewarm feedback, andnegative feedback.
This state is interpreted as aTutor Feedback mode.
Finally, State 4DA, TutorLecture/Probing, is characterized by tutorstatements and evaluative questions with somestudent grounding statements.Figure 2.
Emission Probability Distributions forDialogue Act HMMThe state transition diagram (Figure 3) illustratesthat Tutor Lecture (0DA) and Grounding/Extra-Domain (1DA) are stable states whose probability ofself-transition is high:  0.75 and 0.79, respectively.Perhaps not surprisingly, Student Reflection (2DA)is most likely to transition to Tutor Feedback (3DA)with probability 0.77.
Tutor Feedback (3DA)transitions to Tutor Lecture (0DA) with probability0.60, Tutor Lecture/Probing (4DA) with probability0.26, and Student Reflection (2DA) with probability0.09.
Finally, Tutor Lecture/Probing (4DA) veryoften transitions to Student Reflection (2DA) withprobability 0.82.22Figure 3.
Transition diagram for dialogue act HMM4.2 Adjacency Pair HMMFigure 4 displays the emission probabilitydistributions for the HMM that was trained on theinput sequences of adjacency pairs.
State 0AP,Tutor Lecture, consists of tutorial statements,positive feedback, and dialogue turns initiated bystudent questions.
In this state, student evaluationquestions occur in adjacency pairs with positivetutor feedback, and other student questions areanswered by tutorial statements.
State 1AP, TutorEvaluation, generates primarily tutor evaluationquestions, along with the adjacency pair of tutorialstatements followed by student acknowledgements.State 2AP generates conversational grounding andextra-domain talk; this Grounding/Extra-Domainstate is dominated by the adjacency pair of studentgrounding followed by tutor grounding.
State 3APis comprised of several adjacency pairs:  studentquestions followed by tutor answers, studentstatements with positive tutor feedback, andstudent evaluation questions followed by positivefeedback.
This Question/Answer state alsogenerates some tutor grounding and studentevaluation questions outside of adjacency pairs.Figure 4.
Emission Probability Distributions forAdjacency Pair HMMFigure 5.
Transition diagram for adjacency pair HMM0DA3DA2DA1DA4DAp > 0.50.1 ?
p ?
0.500.05 ?
p < 0.10AP3AP2AP1APp > 0.50.1 ?
p ?
0.500.05 ?
p < 0.1234.3 Dialogue Mode SequencesIn order to illustrate how the above models fit thedata, Figure 6 depicts the progression of dialoguemodes that generate an excerpt from the corpus.Figure 6.
Best-fit sequences of hidden statesIn both models, the most commonly-occurringdialogue mode is Tutor Lecture, which generates45% of observations in the dialogue act model andaround 60% in the adjacency pair model.Approximately 15% of the dialogue act HMMobservations are fit to each of states StudentReflection, Tutor Feedback, and TutorLecture/Probing.
This model spends the leasttime, around 8%, in Grounding/Extra Domain.The adjacency pair model fits approximately 15%of its observations to each of Tutor Evaluation andQuestion/Answer, with around 8% inGrounding/Extra-Domain.4.4 Model ComparisonWhile the two models presented here describe thesame corpus, it is important to exercise cautionwhen making direct structural comparisons.
Themodels contain neither the same number of hiddenstates nor the same emission symbol alphabet;therefore, our comparison will be primarilyqualitative.
It is meaningful to note, however, thatthe adjacency pair model with nAP=4 achieved anaverage log-likelihood fit on the training data thatwas 5.8% better than the same measure achievedby the dialogue act model with nDA=5, despite theadjacency pair input sequences containing greaterthan twice the number of unique symbols.44 This comparison is meaningful because the models depictedhere provided the best fit among all sizes of models trained forthe same input scenario.Our qualitative comparison begins by examiningthe modes that are highly similar in the twomodels.
State 2AP generates grounding and extra-domain statements, as does State 1DA.
These twostates both constitute a Grounding/Extra-Domaindialogue mode.
One artifact of the tutoring studydesign is that all sessions begin in this state due toa compulsory greeting that signaled the start ofeach session.
More precisely, the initial stateprobability distribution for each HMM assignsprobability 1 to this state and probability 0 to allother states.Another dialogue mode that is structurallysimilar in the two models is Tutor Lecture, inwhich the majority of utterances are tutorstatements.
This mode is captured in State 0 inboth models, with State 0AP implying more detailthan State 0DA because it is certain in the formerthat some of the tutor statements and positivefeedback occurred in response to student questions.While student questions are present in State 0DA, nosuch precise ordering of the acts can be inferred, asdiscussed in Section 1.Other states do not have one-to-onecorrespondence between the two models.
State2DA, Student Reflection, generates only studentutterances and the self-transition probability for thestate is very low; the dialogue usually visits State2DA for one turn and then transitions immediatelyto another state.
Although this aspect of the modelreflects the fact that students rarely keep the floorfor more than one utterance at a time in the corpus,such quick dialogue mode transitions areinconsistent with an intuitive understanding oftutorial dialogue modes as meta-structures thatusually encompass more than one dialogue turn.This phenomenon is perhaps more accuratelycaptured in the adjacency pair model.
Forexample, the dominant dialogue act of State 2DA isa student evaluation question (EQs).
In contrast,these dialogue acts are generated as part of anadjacency pair by State 3AP; this model joins thestudent questions with subsequent positivefeedback from the tutor rather than generating thequestion and then transitioning to a new dialoguemode.
Further addressing the issue of frequentstate transitions is discussed as future work inSection 6.245 Discussion and LimitationsOverall, the adjacency pair model is preferable forour purposes because its structure lends itself morereadily to interpretation as a set of dialogue modeseach of which encompasses more than onedialogue move.
This structural property isguaranteed by the inclusion of adjacency pairs asatomic elements.
In addition, although the set ofemission symbols increased to include significantadjacency pairs along with all dialogue acts, thelog-likelihood fit of this model was slightly higherthan the same measure for the HMM trained on thesequences of dialogue acts alone.
The remainderof this section focuses on properties of theadjacency pair model.One promising result of this early work emergesfrom the fact that by applying hidden Markovmodeling to sequences of adjacency pairs,meaningful dialogue modes have emerged that areempirically justified.
The number of thesedialogue modes is consistent with what researchershave traditionally used as a set of hypothesizedtutorial dialogue modes.
Moreover, thecomposition of the dialogue modes reflects somerecognizable aspects of tutoring sessions:  tutorsteach through the Tutor Lecture mode and givefeedback on student knowledge in a TutorEvaluation mode.
Students ask questions and statetheir own perception of their knowledge in aQuestion/Answer mode.
Both parties engage in?housekeeping?
talk containing such things asgreetings and acknowledgements, and sometimes,even in a controlled environment, extra-domainconversation occurs between the conversants in theGrounding/Extra-Domain mode.Although the tutorial modes discovered may notmap perfectly to sets of handcrafted tutorialdialogue modes from the literature (e.g., Cade etal.
2008), it is rare for such a perfect mapping toexist even between those sets of handcraftedmodes.
In addition, the HMM framework allowsfor succinct probabilistic description of thephenomena at work during the tutoring session:through the state transition matrix, we can see theback-and-forth flow of the dialogue among itsmodes.6 Conclusions and Future WorkAutomatically learning dialogue structure is animportant step toward creating more robust tutorialdialogue management systems.
We have presentedtwo hidden Markov models in which the hiddenstates are interpreted as dialogue modes for task-oriented tutorial dialogue.
These models werelearned in an unsupervised fashion from manually-labeled dialogue acts.
HMMs offer concisestochastic models of the complex interactionpatterns occurring in natural language tutorialdialogue.
The evidence suggests thismethodology, which as presented requires only asequence of dialogue acts as input, holds promisefor automatically discovering the structure oftutorial dialogue.Future work will involve conducting evaluationsto determine the benefits gained by using HMMscompared to simpler statistical models.
Inaddition, it is possible that more general types ofgraphical models will prove useful in overcomingsome limitations of HMMs, such as their arbitrarilyfrequent state transitions, to more readily capturethe phenomena of interest.
The descriptive insightoffered by these exploratory models may also beincreased by future work in which the inputsequences are enhanced with information about thesurface-level content of the utterance.
In addition,knowledge of the task state within the tutoringsession can be used to segment the dialogue inmeaningful ways to further refine model structure.It is also hoped that these models can identifyempirically-derived tutorial dialogue structures thatcan be associated with measures of effectivenesssuch as student learning (Soller & Stevens 2007).These lines of investigation could inform thedevelopment of next-generation natural languagetutorial dialogue systems.AcknowledgmentsThanks to Marilyn Walker and Dennis Bahler forinsightful early discussions on the dialogue and machinelearning aspects of this work, respectively.
Thisresearch was supported by the National ScienceFoundation under Grants REC-0632450, IIS-0812291,CNS-0540523, and GRFP.
Any opinions, findings, andconclusions or recommendations expressed in thismaterial are those of the authors and do not necessarilyreflect the views of the National Science Foundation.25ReferencesAleven, V., K. Koedinger, and O. Popescu.
2003.
Atutorial dialog system to support self-explanation:Evaluation and open questions.
Proceedings of the11th International Conference on ArtificialIntelligence in Education: 39-46.Arnott, E., P. Hastings, and D. Allbritton.
2008.Research methods tutor: Evaluation of a dialogue-based tutoring system in the classroom.
BehavioralResearch Methods 40(3): 694-698.Bangalore, S., Di Fabbrizio, G., and Stent, A.
2006.Learning the structure of task-driven human-humandialogs.
Proceedings of the 21st InternationalConference on Computational Linguistics and 44thAnnual Meeting of the ACL: 201-208.Barzilay, R., and Lee, L. 2004.
Catching the drift:Probabilistic content models, with applications togeneration and summarization.
Proceedings ofNAACL HLT: 113?120.Boyer, K. E., Phillips, R., Wallis, M., Vouk, M., andLester, J.
2008.
Balancing cognitive andmotivational scaffolding in tutorial dialogue.Proceedings of the 9th International Conference onIntelligent Tutoring Systems: 239-249.Cade, W., Copeland, J., Person, N., and D'Mello, S.2008.
Dialog modes in expert tutoring.
Proceedingsof the 9th International Conference on IntelligentTutoring Systems: 470-479.Chi, M., Jordan, P., VanLehn, K., and Hall, M. 2008.Reinforcement learning-based feature selection fordeveloping pedagogically effective tutorial dialoguetactics.
Proceedings of the 1st InternationalConference  on Educational Data Mining: 258-265.Evens, M., and J. Michael.
2006.
One-on-one tutoringby humans and computers.
Lawrence ErlbaumAssociates, Mahwah, New Jersey.Forbes-Riley, K., and Litman, D. J.
2005.
Usingbigrams to identify relationships between studentcertainness states and tutor responses in a spokendialogue corpus.
Proceedings of the 6th SIGdialWorkshop on Discourse and Dialogue: 87-96.Forbes-Riley, K., Rotaru, M., Litman, D. J., andTetreault, J.
2007.
Exploring affect-contextdependencies for adaptive system development.Proceedings of NAACL HLT: 41-44.Graesser, A., G. Jackson, E. Mathews, H. Mitchell, A.Olney, M. Ventura, and P. Chipman.
2003.Why/AutoTutor: A test of learning gains from aphysics tutor with natural language dialog.Proceedings of the Twenty-Fifth Annual Conferenceof the Cognitive Science Society: 1-6.Graesser, A. C., N. K. Person, and J. P. Magliano.
1995.Collaborative dialogue patterns in naturalistic one-to-one tutoring.
Applied Cognitive Psychology 9(6):495?522.Lepper, M. R., M. Woolverton, D. L. Mumme, and J. L.Gurtner.
1993.
Motivational techniques of experthuman tutors: Lessons for the design of computer-based tutors.
Pages 75-105 in S. P. Lajoie, and S. J.Derry, editors.
Computers as cognitive tools.Lawrence Erlbaum Associates, Hillsdale, NewJersey.Litman, D. J., C. P.
Ros?, K. Forbes-Riley, K. VanLehn,D.
Bhembe, and S. Silliman.
2006.
Spoken versustyped human and computer dialogue tutoring.International Journal of Artificial Intelligence inEducation 16(2): 145-170.Purver, M., Kording, K. P., Griffiths, T. L., andTenenbaum, J.
B.
2006.
Unsupervised topicmodelling for multi-party spoken discourse.Proceedings of the 21st International Conference onComputational Linguistics and 44th Annual Meetingof the ACL: 17-24.Rabiner, L. R. 1989.
A tutorial on hidden Markovmodels and selected applications in speechrecognition.
Proceedings of the IEEE 77(2): 257-286.Schlegoff, E., and H. Sacks.
1973.
Opening up closings.Semiotica 7(4): 289-327.Scott, S. L. 2002.
Bayesian methods for hidden Markovmodels: Recursive computing in the 21st century.Journal of the American Statistical Association97(457): 337-352.Soller, A., and R. Stevens.
2007.
Applications ofstochastic  analyses for collaborative learning andcognitive assessment.
Pages 217-253 in G. R.Hancock, and K. M. Samuelsen, editors.
Advancesin latent variable mixture models.
Information AgePublishing.Tetreault, J. R., and D. J. Litman.
2008.
Areinforcement learning approach to evaluating staterepresentations in spoken dialogue systems.
SpeechCommunication 50(8-9): 683-696.VanLehn, K., P. W. Jordan, C. P. Rose, D. Bhembe, M.Bottner, A. Gaydos, M. Makatchev, U.Pappuswamy, M. Ringenberg, and A. Roque.
2002.The architecture of Why2-atlas: A coach forqualitative physics essay writing.
Proceedings ofIntelligent Tutoring Systems Conference: 158?167.Zinn, C., Moore, J. D., and Core, M. G. 2002.
A 3-tierplanning architecture for managing tutorial dialogue.Proceedings of the 6th International Conference onIntelligent Tutoring Systems: 574-584.26
