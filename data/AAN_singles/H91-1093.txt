EVALUATING TEXT UNDERSTANDING SYSTEMSBeth M. SundheimNaval  Ocean Systems CenterCode 444San Diego, CA 92152-5000PROJECT GOALSThe Naval Ocean Systems Center is extendingthe scope of previous efforts in the area ofevaluating English text analysis systems and isseeking to refine the methodology in order toobtain performance benchmarks on aninformation extraction task for recall,precision, overgeneration, and fallout for avariety of systems.
The methodology is alsointended to enable the collection of qualitativedata on the relative validity of the text analysistechniques as applied to the task of informationextraction.RECENT RESULTSThe third evaluation began in October, 1990; adry-run phase was completed in February,1991.
Twelve sites reported results for thedry-run test at a meeting held on 13-15February, 1991.
The test required extractinginformation on terrorist incidents (incidenttype, date, location, perpetrator, target,instrument, outcome, etc.)
from relevantmessages in a blind test on 100 previouslyunseen texts in the test set.
The results ofthis test are summarized in a paper foundelsewhere in this volume.PLANS FOR THE COMING YEAROfficial testing will be done in May, 1991, andthe Third Message Understanding Conference(MUC-3) will be held May 21-23 at the NavalOcean Systems Center.
A proceedings will bepublished on the basis of this conference.
Theresults of the evaluation will be analyzed todiscover whether conclusions can be drawnconcerning the correlation among taskperformance, text analysis capabilities, andtheoretical approach.In addition to the official measures, unofficialmeasures will be obtained of performance onpart icular l inguist ic phenomena (e.g.,conjunction), as measured by the informationextracted in particular sets of instances.
Thatis, text segments exemplifying a selectedphenomenon will be marked for special scoringif successful handling of the phenomenon seemsto be required in order to fill one or moretemplate slots correctly for that segment.419
