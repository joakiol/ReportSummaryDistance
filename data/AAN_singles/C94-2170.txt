Tools for Extracting and Structuring Knowledge from Texts.Autlmrs: Antoine Ogonowski* (Anloinc.Ogonowski@crli.gsi.fr), Marie Luce lterviou***(Marie-l,uce.Herviou@dcr.cdf.fr) and t;,va Dauphin** (sylvic.rcgnier@siege.aerospaliale.fi')The authors wish to Ihank M. Bernard*, G Cldmencin*, S. Lacep*, R. l,eblond**, MG. Monteil***, G. Morizc* andB.
Nonnicr* lbr their collaboration while working on tiffs project and precious advice lot the prcparation o1' this note.
* GSl-I!rli I pl.
ties Marscillais , 94227 Charcnton Codex FRANCF.
** AF, R()SPATIAI~E C(2R.
12 rue Pasteur, 13P76, 92 t52 Surcsnncs Cedcx I,'RANCI:i*** Elcclricitd e France (EDF), Research Ccnler, I Av du Gdndral de Gaulle, 92141 Clamart FRANCliAbstract  : We demonstrate an approach and an accompanying UNIX toolbox for performing wtriouskinds of Knowledge tT, xlractions and Structuring.
The goal is to "practically" enhance the productivilywhile constructing resources for NLP systems on the basis of large corpora of technical texts,.
Users arelexicon/grammar builders, terminologists and knowledge ngineers.
We stay open to already exploredmethods in this or neighbouring activities but put a greater stress on the use of linguistic knowledge.The originality of the work presented here lies in the scope of applications addressed and in the degreeof use of linguistic knowledge.I.
IntroductionNincc NIA ~ \]laS started moving from toyproblems to ,'eal applications one of the biggestdifficully has been Knowledge Acquisition (KA)of different lypes (lexical, grammatical, domainand application specific).
A lot of the neededinl'ormation resides (in an implicit or explicitform) in texts that most of the time now exist inmachine readable form.It seems however too difficul/ to fully automatethe KA process although steps have to be taken inthat direction \[WIL93\].
Tools to help users dealwith large corpora have been developed l'or sometime, most of these however rely either on crudenon linguistic approaches or mostly on statisticmethods (eg \[CAL90\]).
Credit should also begiven to new approaches based on neural netsespecially for dealing with Machine P, eadableI)ictiouaries (eg Ill)E90\]).This project, note i l lustrates a morelinguistic and "open" approach (not ignoring theachievements of existing methods), basing itselfon exist ing large e lectronic  d ict ionar iescompatible with thc GI:';Nt,',\[A:,X model \[GI';N90\].The EIJRI';KA project Gt:~,NELEX (5 years,39 MEcu, 250 man years) has produced publicmodels encompassing nlorphoh)gica\[, syntacticand semantic knowledge in both monolingual(Fretlch, English and soon Italian and Portuguese)as well as bilingual contexts.The tools that the authors want to discusshere are developed in the context of the closelyrelated EUREKA project GRAA1/ (acronym forGrammars that can be Reused to At, tomaticallyIThis 23Ml{cu, 150 man years prqiec!
is conduclcd by aninternational consortium currently gathering inFrance:GSI-I'Mi (project leader), I';DF, Adrospalialc and IRIT; inItaly: IRST, Centre Ricerclle FLAT; in Switzerland:ISSCO; in Greece: 11 ,SP; in l;inhmd: 1 ,ingsoft, Nokia; inPortugal: II,TliC.Analyse Languages).
This projecl IGRA921 hasIhe following objectives:?
the development of granunars that arceasily maintainable and reusable (ie differenttypes of NLP applications can be built on theirbasis)* the development  of tools (parsers,generators as well as workbenches l'or gralnmarconstruction, customisation and integration inspccilqc application enviromnents)?
delivery ol' industrial level applications.This 4 year project is currently divided intoseveral subl~rojccts ("SPs") one of which is called"KES" (Knowledge b2xtraction and Structuring)and aims :_tt the second and third types of GRAALgoals.The three partners of this mentioned SP: El)t;,AEROSPATIALE and GSI-Erl i  have built amodular extensiblc toolbox that should covermost el' the needs that may occur in "any"knowledge xtraction process and now wdidate theperformance of lhe toolbox on severalapplications.For the partners, Knowledge Extraction coversneeds arising in wu'ious types of applicationsranging l'rom "terminology construction andenrichment" (problem largely studied these years\[TER00\], \[LEX92\] ...), "extension of lexiconscoverage", lhrough "grammar development" up to"construction o1' Large Knowledge Bases" for AIsystems, or for technology assessment surveypurposes.
This means thai potential users of thetoolbox range Irom lerminology experts, lexiconand grammar writers to knowledge ngineers.Two languages are currently considered: Frenchand English, but the tools developed should beeasily adaptable to other languages10492.
The  ApproachRather than developing a new automaticKA theory we have opted for a "practical"approach i.e.
a set of tools that can assist the userin a bootstrapping process.2.1 Principles: Our platform integrates all theresources and processes allowing to proceed fi'omraw texts to a structured set of knowledge items(taken to mean words, terms, coucepts, links, rulesetc.)
extracted fi'om these texts.Partners believe that the future industrial tools areto use much more linguistic knowledge than thetools currently avai lable on the market (eg\[SAT92\]).
Our goal is not to be 100% exact atthe different stages of processing but to help theuser rapidly explore various hypotheses.2.2 Phases: Three main phases organise theKES process: "Corpus Characterisation","Extraction" and "Structuring".The first step takes as input text in a "KES"SGML format and performs a linguistic taggingof these texts (for more details see section 3.1.1).The "extraction" and "structuring" phases are thereal core of the KES process: implemented ascooperat ive processes (rather than purelysequential operations) they allow the manipulationof information found in the results of theprevious stage, in the input texts or in lexicons,according to different criteria:linguistic information (morpho-syntacticlags, syntactic properties, thematic roles ...),statistical considerat ions (frequencies,weights...),"factual data" (eg.
typographical structureindicators uch as "title", or "lists" markups...)This in order to select, extract, group items ofinformation and link them together.
(c.f, section3.1.2.
for details of the process).The main idea is to manipulate "properties" addedto words, terms or texts (see the SATO approach)like tags, statistical information, links .
.
.
.
; ournovel contribution is to use linguistic informationin all steps to add or control these properties (wecan use more information than \[ANI90\]) whilestaying open to different modelling choices.Furthermore, one of our constant concerns is toestablish well-defined and standardised exchangeformats (SGML DTDs) between the different stepsensuring modular i ty  and s impl i fy ing dataimport/export from/to application databases ortools manipulating textual data.3.
The  Too lsOur tools are developed in a modnlar wayin C++, based on standards like OSF/MOTIF,SGML and run under the SUN OS UNIXoperating system.3.1 Current State: Two groups of tools composethe current toolbox.
GCE \[GCE93\] - the first one,implements (in batch mode) a parameterisedcorpus characterisation and a first extraction of"interesting" items.
EAEKES the second tool ismuch more interactive and accounts for the moredomain specific part of extraction as well as forknowledge structuring and validation.3.1,1 Corpus Characterisation +preliminary extractionGCE (Graal Corpus Explorat ion) has beendeveloped by the partners in a previous phase ofGRAAL and is a set of software tools that ran inbatch on a corpus perform a morpho-syntacticanalysis (pattern-matching approach),  andproduce structured ata representing :- l ists of tagged words (GENELEXcategories),predictions on the categories of unknownstrings ("date", "numeral", proper noun...)based on "morpho-graphic" patterns & context,lists of syntactic groups (Noun Phrases thatappear to be potential terms of the domain,verbal forms...),various statistical information (rangingfrom frequencies of particular punctuations tofi'equencies of syntactic patterns),Thus the tool can produce several representationsof the corpus (eg: lemmatised, with various levelsof tags etc ..).GCE uses for its purpose large GENELEXlexicons (French 55000 simple words and18 000 compound words, English 40 000 words)and a constraint grammar like approach.Because GCE performs a bottom-up analysisusing a large coverage lexicon and makes lexicalcategory predictions on unknown words theresults are usually very satisfactory and constitutea valuable starting point for the subsequent phases,even for texts in very technical domains.3.1.2 Extraction and StructuringHere the implementing software tool calledEAEKES is based on GSI-Er l i 's  A lethSACsoftware (based in turn on GSI-Erl i 's experiencein the E.C.A.I.M.
project Menelas).EAEKES'  main goal is to allow for bothinteractive and batch knowledge extraction andcharacterisation.
It automatically bases itself onthe GCE results.The most basic operation consists in manuallycreating domains of information and manually(either by typing them in, or by mouse selectionin source text) inserting items 2 into them.The tool in this mode of operation allows thenavigation between items (on the basis of the linksbetween them) and domains of information in asomewhat "hypertext" style (mouse clicking).The user can also interactively change both termsand domains inter-rclationship (in a cut/paste way)automatically maintaining inverse links.2 items can be made up of parts of words, words, phrases,or even disjoint ext elements.1050The second mode of operation offers thepossibility to describe selection patterns that arethen applied on the corpus in a batch mode.The selection patterns are coupled with adescription of actions that are 1o be performed\[brining together "KES rules".The actions can among other perform "parsinglike operations" by using a type of chart likerepresenlation f the analysed text.Most often however users will perform actions thatextract identified parts of text and assign it somechmacteristics and or link them to other alreadyextracted items.The reader will find below examples of patternsthat can be specified and examples of actionsperformed with matching items.Tim types of patterns can be:morl2hoDdgical- for example: "all wordsbeginning with "aqu" or containing the infix"bydro" are to be placed in the domainI '  i I  t , i f t~ , l r  "~simple contextual patterns -eg  "all wordsthat are not adverbs and immediately precedeverbs rehtted to the verb "to flow" are to becharactcrised as nouns denoting liquefiedbodies4; Note that the type of relations that areto hold between verbs can be what is found in arich GENEL .X dictionary", but can also beuser defined criteria .s~ntact i c  example: all NP headsfollowing a l'orm el' "obtained by" are to beplaced in lhe domains "methods"; all phrases ofthe type "all <NP-head>'like'<enumeration -~heads>" describe an 'is a' relationship betweenthe NP head and each one of the enumerationheads (ex: "lhe data processing methods like%5 automatic lassificalion, formal links .... ) ,combinations of the above 6 types.The above mentioned types of rules are to beprovided by the user, this however is a task toodifficult for some users that are not linguists orknowledge engineers.
Therefore the toolboxprovides a library of basic rules that can either beused as such or serve as starting patterns that usersmay refine and adapt.Whether the extraction is made by "hand"or by rules it can be performed on any of the3 wu'iotls application domains offer dEgrEes Of suchrEguhu'i/ies- some applicalions in chemish'y being perhapstile most ilhtsu'ative (the above "hydro" would probablyassign a different donmin in chElnistry).
84 presuming that we are dealing with a tEclmical text.5 rEguhu'ities like these have been observed in technicaltEXtS (eg cf IROU921).6 users with different skills wrile differenl types ofrules.
For instance aKnowlEdgE engineer usually does 9not use the notion of a syntagmatic head.forms output by GCE.
It is thus possible tocombine forms as they appeared in the source textwith results of lemmatisation, taking into accountfrequency data, logical markups or co-occurrences.
The extraction process can be made"information sensitive" i.e.
the selection patternscan be made to check whether a knowledge item isnot already classified somewhere (by another ule,by the user or in an external som'ce 7) ; thus, it ispossible to use all the information available on anitem, coming fi'om the original corpus or externalresources  7.Therefore information predicted by the rules canbe used in other rules thus achieving a bootstraptype of effect.
Facilities are awfilable to keep trackof the dependeucies between hypotheses, the usercan interactively explore retrieval of hypothesesand see the effect on the extracted knowledge.This extracted knowledge (set ofknowledge items) can be interactively checkedand cleaned up.Once checked the knowledge items can bestructured: various types of links can be made,dmnains can be divided into subdomains anditems dispatched into them 8.Several ways are available to accomplish this task:Manually selecting and moving itemsusing the mouse.- Rules similar to the extraction patterns canalso be applied on the extracted set ofknowledge ilems (eg: all items placed in thedomain of "energy production" that begin withthe strings "atom" ,"nucl" or contain the word"fission" are to be moved into the subdontain"energy production by nuclear means").
9These structuring rules can also establish linksbetween items, it is therefore possible toperform actions like: check for "inclusion" ofitem in another one and if positive link themwith an "generic" link.
Because both thepossibilities of the rule language as well as theavaihtbility of large stocks of l inguisticknowledge the previous ly  ment ioned"inclusion tests" can range from simplecharacter string matching to testing fornote that such an external source is the GENELEXcompatible dictionary but may also be a thesanrus thatthe user is trying to enrich, but eotdd also be anontology in tile context of ExpErt Systelnconslruclion (el' I MIZ931).
Tile toolbox's underlyingdata model can in a "mEta model way" host a largevariety of rEsourcEs.the user Call have two modes of operation Either anunconstrained where any "domain" or link can becreated or a "model" guided mode in which the"adminislrator" user has to specify the links used, thetypes of domains, the types of itEmS and specify foreach the possible interrelationships.note that stteh rules can implement some simpleforms of gencralisation sUatcgy.7057example the variation o1' the prepositions usedin a corresponding position in several terms.Note that established links can also be tested inthe rules and for example it is possible to detect"shortcut links" in hierarchies of items.
Theseidentified links can then be presented to theuser for further operations.The standard type of result display is in aworkview which can handle lists of items and listsof l inks between items.
Some graphicalmanipulation is also possible.
(cf figures )F/chLeJ- Eonnandes RJdoCaJlulo cotlrallt~: A3Zfl->(TG)->P, VION~,,0,?
,~,,,,?
: \[ JFig.
l: textual modeHere the uscr works in a navigation mode; the window inthe foreground ol' this view corresponds to a to theknowledge item "ilot nucldaire" of type "term".
Through aroll-down menu one can view all occurrences of tile lerm.The "spread sheet" like window ("work view") in thebackground allows to manage sets of links (cf firstcohunn), knowledge items (second cohunns) andattributes of knowledge items (not shown here).Note that the steps during which the user writesdifferent extraction rules and visnalises theirresults, can also be used in grammar engineeringtasks.
There exists in fact a third viewing mode(not shown here) in which the user may see theplaces in his corpus where a rule applies.
Nothiugprohibits the rules from being "normal" parsingrules, that the user wants to explore.This type of use has however beenreserved for a subsequent phase of the SP - afterJnly 1994 -and thus has not been fully exploredyet.3.2 Outline of an example sessionWe will illustrate the working of out" toolbox in thecontext of an application whose goal is to enrichan existing thesanrus.I.
A large corpus (10 MBs) of texts in the domainof informatics is batch processed by GCE,yielding lists of nouns, adjectives, potential terms,unknown words and statistics...2.
Using a spell checker called fi'om within theEAEKES system, the user eliminates unknownwords that in fact were misspelled technical terms.3.
The remaining unknown words are studied incontext thanks to the retrieval of the sentencewhere they occurred.
The pertinent ones (verytechnical terms, domain specific proper nouns like"Unix", "Saltou" ...) are kept.4.
The most frequent nouns and noun phrases areobserved.
Extraction rules allow to extract themost "productive" NP heads allowing to build"domains" such as : "machines" (dl) ,  methods(d2), languages (d3)...
This extraction is made"information sensitive" : the existing thesaurus isused to help defining these domains.
Then, theNPs based on these heads are dispatched: "Unixmachines", "IBM machiues" in d l ,  "statisticmethods" in d2, "C programming language" in d3,etc ...5.
With rules using syntactic or semanticinformation found in the GENELEX dictionary(for example,  synonyms of "method" and"processing") and using contextual patterns (egvariants of the form "...methods uch as ..." ) otheritems are dispatched: in d2 we will then find itemslike "document classification"; "data processing","textual data processing", 'Tormal links", "Saltontheory" ...).6.
Graphical facilities allow to establish linksbetween the differen!
items: eg "isa links" between"data processing" and "textual data processiug",between "textual data processing" aud "documentclassification" etc...7.
The structured results are then exported(encoded according to an SGML DTD) in order tobe recovered by a terminology managementsystem which will allow their integration in theoriginal thesaurus.4.
Where are we?The set of tools described here is a prototype audfilrther work is planned in both the LRE projectTRANSTERM and the continuation of thisGRAAL subproject.S.
Conc lus ionsWe haw; presented all approach snpported by atoolbox corresponding to the aims of industrialactors ill the field of NLP.
The objectives targetedarc an increase in the productivity of peoplemanipulat ing large corpora.
Rather thanintroducing a new theory of automatic KA we1052have presented a "lmtctical '' approach allowing thecombinatiol~ of automatic and "hand" methodswhich can be based on largo generic repositoriesof knowledge, working in a bootslrap type ofcooporatiOll.References\[ANI90\] "An Application of l,exical Sen-iantics toKnowledge Acquisition froin (~orpora"; P. Anickand J. I'usicjovsky ill Prec.
O1: (\]olil lg 1990.\[CAL90\] "Acquisition of Lexical Informationfrom a l+arge 'Fcxtual Italian Corpus", N. Calzohlriand R. Bindi in Prec.
o1: Coling 1990.\[GC\[{931 "l"tude de cotyJus: utz prdalablendcessaire pour I'adaptation des syst&#tes de 7',4attx besoins des utilisateurs", |~.
Dauphin, inproceedings of "Troisibmes Journdes ScientifiquesTA, TAO, Traductique", to bc published as an"URF, F'" publication Universild do Montrdal.\[GEN90\] "(;17NI?I,KX project : I'2URIOKA .fin"linguistic engineering", B. Normier and M. Nossinin Proc of International workshop on electronicdictionaries 1990.IGRA921 "Outline IQtreka GRAAI,";Coliilg 1992(hitcrlmtional Project Presentations Volume).l lDE90\] "Very l,argo Neural Nolworks for Word-~OllSe l)isalnbiguation" N. ldc and J. V~roiiis inPrec.
of ECAlgO 1990.\[LEX92\] "Su@u:e grammatical Analysis .fi>r theextraction of  terminological norm phrases",Ikmrigault Didier in Proe of Coling 1992.\[MIZ93\] "Knowledge Acquisition alM Ontology"Ri ichiro Mizoguchi, in Prec.
of KB&KS93 --International Conference on Building and Sharingof Very IAil'ge-Scalo Knowledge Bases 1993.\[ROU92\] "l~laboration de Techniques d'analyseadaptdes ~l la construction tie bases dcconnaissances" F. Rousselot and II.
Migmlll t{nsaisin Prec.
of Coling 1992.ISAT921 : "l/analyse du co#~te#lu textuel eft rue (\[e/a constrttctiott de thdsattrus et de I'indexationassistde par ordimtteur : applications possiblesavec SATO", S. Bcrtrand.Gastaldy, G. Pagola,"l)ocunlentation ct bil)lioth\[;qucs", Avri l - Juin1992.ITF, R901 "77+lvnino v. 1.0 ."
rapport de recherche"Novembre 1990, par Ic groupe RI)LC (Recherchecl l )ove loppement  ell L ingu is l ique(!oniputalionnellc), (\]entre d'Analyse de Tcxtespar ()rdinaleur, Universitd u Qudbec, Montrdal.\[W11,93\] "7'owards Automated KtwwledgeAcquisition" Yorrick Wilks and Sergei Nirenburgin Prec.
o\[ KB&KS 93 - International (7onferelicoOll I~tlilding alld Slial'ill\[ ~, of Very \],algC-ScaloKnowledge Bases 1993.l_qchier {~.
'oil i 1il a n dc,'-i A ido,j-J" /- J  <S~_~_ ,.4o:->-.
t .
.
.
.
.
.
.I;ig2 Graphical Mode:All objects and links can bc (lisphtccd and updated using file mouse and keyboard.I|crc the user w'orking (m nuclear emergency manuals has chosen to display part of the extractedlit~guistic c<mff~o.vilion links: "nttcldaire" "occurs in" "ilot nucldaire" and "baliment auxilliaim nucl&iire",but also thesaurus like links : "ilot nucleairc" apl~cars to be a generic term of "balimcnt auxilliarcl'OtlclOtlf ~,1053
