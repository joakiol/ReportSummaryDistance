Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 817?822,Dublin, Ireland, August 23-24, 2014.UWB: Machine Learning Approach to Aspect-Based Sentiment AnalysisTom?a?s Brychc?
?nNTIS ?
New Technologiesfor the Information Society,Faculty of Applied Sciences,University of West Bohemia,Univerzitn??
8, 306 14 Plze?nCzech Republicbrychcin@kiv.zcu.czMichal KonkolNTIS ?
New Technologiesfor the Information Society,Faculty of Applied Sciences,University of West Bohemia,Univerzitn??
8, 306 14 Plze?nCzech Republickonkol@kiv.zcu.czJosef SteinbergerDepartment of ComputerScience and Engineering,Faculty of Applied Sciences,University of West Bohemia,Univerzitn??
8, 306 14 Plze?nCzech Republicjstein@kiv.zcu.czAbstractThis paper describes our system partici-pating in the aspect-based sentiment anal-ysis task of Semeval 2014.
The goalwas to identify the aspects of given tar-get entities and the sentiment expressed to-wards each aspect.
We firstly introducea system based on supervised machinelearning, which is strictly constrained anduses the training data as the only sourceof information.
This system is then ex-tended by unsupervised methods for latentsemantics discovery (LDA and semanticspaces) as well as the approach based onsentiment vocabularies.
The evaluationwas done on two domains, restaurants andlaptops.
We show that our approach leadsto very promising results.1 IntroductionThe majority of current sentiment analysis ap-proaches tries to detect the overall polarity of asentence (or a document) regardless of the targetentities (e.g.
restaurants) and their aspects (e.g.food, price).
By contrast, the ABSA (aspect basedsentiment analysis) task is concerned with identi-fying the aspects of given target entities and esti-mating the sentiment polarity for each mentionedaspect.The aspect scenario can be decomposed intotwo tasks: aspect extraction and aspect sentimentclassification (Liu, 2012).The task of aspect extraction is to recognizeaspects of the entity and more generally can beseen as an information extraction task.
The ba-sic approach is finding frequent nouns and nounThis work is licensed under a Creative Commons At-tribution 4.0 International Licence.
Page numbers and pro-ceedings footer are added by the organisers.
Licence de-tails: http://creativecommons.org/licenses/by/4.0/phrases (Liu et al., 2005; Blair-Goldensohn etal., 2008; Moghaddam and Ester, 2010; Long etal., 2010).
Aspect extraction can be also seen asa special case of the general information extrac-tion problem.
The most dominant methods arebased on sequential learning (e.g.
HMM ?
HiddenMarkov Models (Rabiner, 2010) or CRF ?
Condi-tional Random Fields (Lafferty et al., 2001)).
An-other group of methods use topic models (Mei etal., 2007; Titov and McDonald, 2008; Blei et al.,2003).Aspect sentiment classification determineswhether the opinions on different aspects arepositive, negative, or neutral.
While lexicon-basedapproaches use a list of aspect-related sentimentphrases as the core resource (Ding et al., 2008; Huand Liu, 2004), the key issue for learning methodsis to determine the scope of each sentimentexpression, i.e., whether it covers the aspect inthe sentence (Jiang et al., 2011; Boiy and Moens,2009).The most of the research in aspect-level senti-ment analysis has been done in English, however,there were some attempts to tackle the aspect-leveltask in other languages (e.g.
in Czech (Steinbergeret al., 2014)).The rest of the article is organized as follows.In Section 2, we summarize the ABSA shared task(Pontiki et al., 2014).
Then, we give a descriptionof our participating system (Section 3).
In Section4, we discuss our results in the task.
We partic-ipated with both the constrained and the uncon-strained variants of the system.2 The ABSA taskDatasets consisting of customer reviews withhuman-authored annotations identifying the men-tioned aspects of the target entities and the senti-ment polarity of each aspect were provided.
Theexperiments were run in two domains: restaurantand laptop reviews.817Each team could submit two versions of sys-tems ?
constrained and unconstrained.
The con-strained system uses only the training data andother resources (such as lexicons) for training.
Theunconstrained system can use additional data.We use another definition of these types, whichis not against the rules.
Our constrained systemsare based purely on ABSA training data, with-out any external knowledge such as dictionaries orrules.
Our unconstrained systems use additionaldictionaries, rule-based extensions and unlabeleddata.
From our point of view, hand-crafted dictio-naries and rules are external knowledge and thus itis the same as adding external data.The task consists of the four subtasks.2.1 Subtask 1: Aspect term extractionGiven a set of sentences with pre-identified enti-ties (restaurants or laptops), the task is to identifythe aspect terms present in the sentence and returna list containing all the distinct aspect terms.I liked the service and the staff, but not the food.?
{service, staff, food}2.2 Subtask 2: Aspect term polarityFor a given set of aspect terms within a sentence,the task is to determine the polarity of each aspectterm: positive, negative, neutral or conflict (i.e.,both positive and negative).I hated their fajitas, but their salads were great.?
{fajitas: negative, salads: positive}2.3 Subtask 3: Aspect category detectionGiven a predefined set of aspect categories, thetask is to identify the aspect categories discussedin a given sentence.
Aspect categories are typi-cally coarser than the aspect terms of Subtask 1,and they do not necessarily occur as terms in thegiven sentence.For example, the following categories were de-fined for the restaurants?
domain: food, service,price, ambience and anecdotes/miscellaneous.The restaurant was expensive, but the menu wasgreat.
?
{price, food}2.4 Subtask 4: Aspect category polarityGiven a set of pre-identified aspect categories, thetask is to determine the polarity (positive, nega-tive, neutral or conflict) of each aspect category.The restaurant was expensive, but the menu wasgreat.
?
{price: negative, food: positive}3 System descriptionWe use machine learning approach to all subtasks.For aspect term extraction we use CRF.
For theother three tasks we use the Maximum Entropyclassifier.
We use the Brainy (Konkol, 2014) im-plementation of these algorithms.During the data preprocessing, we use simpleword tokenizer based on regular expressions.
Alltokens are lowercased for tasks 2 and 4.We will firstly describe all the features used inthis paper because the tasks share some of them.These features are then referenced in the descrip-tions of individual subtasks.Words (W) ?
Word occurrence on a given posi-tion in the context window.Bag of Words (BoW) ?
Occurrence of a word ina sentence (or context window).Bigrams (B) ?
Bigram occurrence on a given po-sition in the context window.Bag of Bigrams (BoB) ?
Occurrence of a bigramin a sentence (or context window).Tf-idf ?
Term frequency?inverse document fre-quency for all tokens in the sentence.Learned Dictionary (LD) ?
Dictionary of termsbased on training data.Suffixes (S) ?
Suffix of a word (2-4 characters).Sentiment Dictionary (SD) ?
Dictionary createdusing semi-automatic triangulation method(Steinberger et al., 2012).
The score is nor-malized.Senti Wordnet (SW) ?
See (Baccianella et al.,2010).LDA ?
See Section 3.1.Word Clusters (WC) ?
See Section 3.2.
Clusteroccurrence on a given position in the contextwindow.Bag of Clusters (BoC) ?
Same as word clusters,but without information about position.818We use two features that are not in commonuse in similar tasks ?
Latent Dirichlet Allocationand word clusters based on semantic spaces.
Boththese features use large amount of unlabeled datato discover latent semantics.
We downloaded therestaurant reviews from http://opentable.com.
This corpus consists of 409,665 reviews(documents) with about 27 million words.
Theopentable corpus is used as the training data forthese features.
Unfortunately, we did not find anylarge corpus for laptop domain, thus presented un-supervised features are used in restaurant domainonly.We devote the following two subsections to de-scribe these features.
Then we introduce our ap-proach to the individual tasks.3.1 Latent Dirichlet AllocationThe Latent Dirichlet Allocation (LDA) (Blei et al.,2003) is a topic model that is assumed to provideuseful information for particular subtasks.
We useLDA implementation from the MALLET (McCal-lum, 2002) software package.
For each experi-ment we always train the 400 topics LDA (no sig-nificant difference was observed between differentnumbers of topics) with 1,000 iterations of Gibbssampling.
The hyperparameters of Dirichlet dis-tributions were initially set to ?
= 50/K, whereK is the number of topics and ?
= 0.1.
This set-ting is recommended by (Griffiths and Steyvers,2004).
The topic probabilities are directly used asnew features to the classifier.3.2 Word clustersWe use same approach as presented in (Brychc?
?nand Konop?
?k, 2014), where word clusters derivedfrom semantic spaces improved language model-ing.
As recommended by these authors, we useCOALS (Correlated Occurrence Analogue to Lex-ical Semantics) (Rohde et al., 2004) and HAL(Hyperspace Analogue to Language) (Lund andBurgess, 1996) for representing the word mean-ing and the Repeated Bisection algorithm for clus-tering.
Similar approach has been already usedfor sentiment analysis in (Habernal and Brychc?
?n,2013) and (Brychc?
?n and Habernal, 2013).The parameters of semantic spaces are set asfollows.
For both semantic spaces we use a four-word context window (in both directions).
HALuses a matrix consisting of 50,000 columns, whichkeeps the largest amount of information.
COALSuses a matrix with only 14,000 columns (as rec-ommended by the authors of the algorithm).
TheSVD reduction was not used in our experiments.Implementation of the HAL, COALS algo-rithms is available in an open source package S-Space (Jurgens and Stevens, 2010).
For cluster-ing, we use the implementation from the CLUTOsoftware package (Karypis, 2003).
As a measureof the similarity between two words, we use thecosine similarity of word vectors.For both semantic spaces the word vectors areclustered into four different depths: 100, 500,1,000, and 5,000 clusters (i.e.
eight different clus-ter sets).
The occurrences of particular clustersrepresent additional features to the classifiers.3.3 Aspect term extractionOur approach for aspect term extraction is basedon Conditional Random Fields (CRF).
The choicewas based on similarity with the named entityrecognition task, where CRF are regarded as thecurrent state of the art (Konkol and Konop??k,2013).
We use the BIO model for representing as-pect terms (Ramshaw and Marcus, 1999).The constrained feature set consists of: W, BoW,B, LD, S. It is extended by WC for the uncon-strained case.3.4 Aspect term polarityDuring the detection of the aspect term polarities,the words affecting the sentiment of the aspectterm are assumed to be close in most of cases.Thus we use a context window of 10 words in bothdirections around the target aspect term.
We as-sume the further the word or bigram is from thetarget aspect term, the lower impact it has on thepolarity label.
To model this assumption we usea weight for each word and bigram feature takenfrom the Gaussian distribution according to thedistance from the aspect term.
The mean is setto 0 and the variance is optimized on training data.As a feature set for the constrained approach weuse only BoW, BoB and for the unconstrained ap-proach we use BoC, SD, SW above that.3.5 Aspect category detectionAspect category detection is based on a set of bi-nary Maximum Entropy classifiers, one for eachclass.
The final decision is simply assembled fromdecisions of individual classifiers.For this task we use BoW, Tf-Idf for the con-strained approach and add LDA, BoC for uncon-strained approach.819Team Const.
Rank P [%] R[%] F1[%] Rank ACC[%]AspecttermsRestaurantsBest ?
1.
85.35 82.71 84.01 1.
80.95UWB U 7.
82.70 76.28 79.36 4.
77.69UWB C 12.
83.28 70.28 76.23 12.
72.13Average ?
14-15.
76.74 67.26 70.78 18.
69.15Semeval Baseline ?
?
?
?
47.15 ?
64.28LaptopsBest ?
1.
84.80 66.51 74.55 1.
70.49UWB U ?
?
?
?
4.
66.67UWB C 14.
77.33 49.54 60.39 10.
62.54Average ?
14.
68.97 50.45 56.20 16.
59.01Semeval Baseline ?
?
?
?
35.64 ?
51.07AspectcategoriesBest ?
1.
91.04 86.24 87.58 1.
82.92UWB U 4.
84.36 78.93 81.55 8.
72.78UWB C 5.
85.09 77.37 81.04 9.
72.78Average ?
11.
76.00 72.26 73.79 12-13.
69.51Semeval Baseline ?
?
?
?
63.89 ?
65.66Table 1: Comparison of our constrained (C) and unconstrained (U) system with Semeval baseline, bestand average results.
P , R, and F1denote the precision, recall and F-measure, respectively, used formeasuring aspect term and category detection.
ACC denotes the accuracy, used for measuring aspectterm and category sentiment polarity detection.3.6 Aspect category polarityFor this task we always take the whole sentenceinto account.
We cannot take a limited windowas we do not know where exactly the category ismentioned in the sentence.
Moreover, it can be atseveral positions.
To distinguish between differ-ent categories we again use standalone MaximumEntropy classifier for each category.The constrained feature set consists of: BoW,BoB, Tf-Idf.
It is extended by BoC, LDA, SD, SWfor the unconstrained case.4 ResultsThe ABSA task was a competition between re-search teams from around the world.
There were21 to 32 submitted systems for individual tasks.We have submitted both constrained (no ex-ternal knowledge, dictionaries or rules) and un-constrained systems for all tasks, except uncon-strained system for aspect term extraction in thelaptops domain.Table 1 shows results of our systems (UWB)and compares them with the best and average sys-tems as well as with the Semeval baseline.
Theaverage system is not any particular system.
It isrepresented by average rank and metrics (metricsare averaged separately).Our systems performed quite well.
In alltasks, we outperform the Semeval baseline sys-tem.
Moreover, we are always above average (F-measure and accuracy) in all tasks.
We were threetimes in the fourth place and our unconstrainedsystems were always in top ten.Table 2 presents the 10-fold cross-validation re-sults on restaurant training data.
We can clearlysee, that any of our extension (LDA, clusters, sen-timent vocabularies) brings at least some improve-ment.5 ConclusionThis paper covers our participation in the ABSAtask of Semeval 2014.
The ABSA task consistsof 4 subtasks.
For each subtask we propose bothconstrained (no external knowledge) and uncon-strained approach.
The constrained versions ofour system are based purely on machine learningtechniques.
The unconstrained versions extend theconstrained feature set by LDA, semantic spacesand sentiment dictionaries.The proposed approaches achieved very goodresults.
The constrained versions were alwaysabove average, often by a large margin.
The un-constrained versions were ranked among the bestsystems.820P [%] R[%] F1[%]Constrained 68.72 82.14 74.83Constrained + WC 76.77 82.51 79.53(a) Aspect term extractionACC[%]Constrained 65.91Constrained+BoC 70.05Constrained+SD+SW 68.13All 71.02(b) Aspect term polarityP [%] R[%] F1[%]Constrained 74.56 80.69 77.51Constrained + LDA 75.96 81.94 78.84Constrained + BoC 77.01 81.42 79.16All 77.28 81.62 79.39(c) Aspect category extractionACC[%]Constrained 66.69Constrained+LDA 67.85Constrained+BoC 68.61Constrained+SD+SW 69.28All 70.20(d) Aspect category polarityTable 2: 10 fold cross-validation results on the restaurants training data for individual features.
P , R,and F1denote the precision, recall and F-measure, respectively, used for measuring aspect term andcategory detection.
ACC denotes the accuracy, used for measuring aspect term and category sentimentpolarity detection.AcknowledgementsThis work was supported by grant no.
SGS-2013-029 Advanced computing and informationsystems, by the European Regional DevelopmentFund (ERDF) and by project ?NTIS - New Tech-nologies for Information Society?, European Cen-tre of Excellence, CZ.1.05/1.1.00/02.0090, and byproject MediaGist, EU?s FP7 People Programme(Marie Curie Actions), no.
630786.ReferencesStefano Baccianella, Andrea Esuli, and Fabrizio Sebas-tiani.
2010.
Sentiwordnet 3.0: An enhanced lexicalresource for sentiment analysis and opinion mining.In Nicoletta Calzolari (Conference Chair), KhalidChoukri, Bente Maegaard, Joseph Mariani, JanOdijk, Stelios Piperidis, Mike Rosner, and DanielTapias, editors, Proceedings of the Seventh Interna-tional Conference on Language Resources and Eval-uation (LREC?10), Valletta, Malta, may.
EuropeanLanguage Resources Association (ELRA).Sasha Blair-Goldensohn, Kerry Hannan, Ryan McDon-ald, Tyler Neylon, George Reis, and Jeff Reynar.2008.
Building a sentiment summarizer for lo-cal service reviews.
In Proceedings of WWW-2008workshop on NLP in the Information Explosion Era.David M. Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent dirichlet allocation.
Journal of Ma-chine Learning Research, 3:993?1022.Erik Boiy and Marie-Francine Moens.
2009.
Amachine learning approach to sentiment analysisin multilingual web texts.
Information retrieval,12(5):526?558.Tom?a?s Brychc?
?n and Ivan Habernal.
2013.
Un-supervised improving of sentiment analysis usingglobal target context.
In Proceedings of the In-ternational Conference Recent Advances in Natu-ral Language Processing RANLP 2013, pages 122?128, Hissar, Bulgaria, September.
INCOMA Ltd.Shoumen, BULGARIA.Tom?a?s Brychc?
?n and Miloslav Konop??k.
2014.
Seman-tic spaces for improving language modeling.
Com-puter Speech & Language, 28(1):192 ?
209.Xiaowen Ding, Bing Liu, and Philip S. Yu.
2008.
Aholistic lexicon-based approach to opinion mining.In Proceedings of the Conference on Web Search andWeb Data Mining.Thomas L. Griffiths and Mark Steyvers.
2004.
Find-ing scientific topics.
Proceedings of the NationalAcademy of Sciences of the United States of Amer-ica, 101(Suppl 1):5228?5235, April.Ivan Habernal and Tom?a?s Brychc??n.
2013.
Semanticspaces for sentiment analysis.
In Text, Speech andDialogue, volume 8082 of Lecture Notes in Com-puter Science, pages 482?489, Berlin Heidelberg.Springer.Minqing Hu and Bing Liu.
2004.
Mining and summa-rizing customer reviews.
In Proceedings of the tenthACM SIGKDD international conference on Knowl-edge discovery and data mining, KDD ?04, pages168?177, New York, NY, USA.
ACM.Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, andTiejun Zhao.
2011.
Target-dependent twitter sen-821timent classification.
In Proceedings of the 49th An-nual Meeting of the Association for ComputationalLinguistics.David Jurgens and Keith Stevens.
2010.
The s-spacepackage: An open source package for word spacemodels.
In In Proceedings of the ACL 2010 SystemDemonstrations.George Karypis.
2003.
Cluto - a clustering toolkit.Michal Konkol and Miloslav Konop??k.
2013.
Crf-based czech named entity recognizer and consolida-tion of czech ner research.
In Ivan Habernal andV?aclav Matou?sek, editors, Text, Speech and Dia-logue, volume 8082 of Lecture Notes in ComputerScience, pages 153?160.
Springer Berlin Heidel-berg.Michal Konkol.
2014.
Brainy: A machine learn-ing library.
In Leszek Rutkowski, Marcin Ko-rytkowski, Rafa Scherer, Ryszard Tadeusiewicz,Lotfi A. Zadeh, and Jacek M. Zurada, editors, Artifi-cial Intelligence and Soft Computing, volume 8468of Lecture Notes in Computer Science.
SpringerBerlin Heidelberg.John Lafferty, Andrew McCallum, and FernandoPereira.
2001.
Conditional random fields: Prob-abilistic models for segmenting and labeling se-quence data.
In Proceedings of International Con-ference on Machine Learning.Bing Liu, Minqing Hu, and Junsheng Cheng.
2005.Opinion observer: Analyzing and comparing opin-ions on the web.
In Proceedings of InternationalConference on World Wide Web.Bing Liu.
2012.
Sentiment Analysis and Opinion Min-ing.
Morgan & Claypool Publishers.Chong Long, Jie Zhang, and Xiaoyan Zhu.
2010.
Areview selection approach for accurate feature ratingestimation.
In Proceedings of Coling 2010: PosterVolume.Kevin Lund and Curt Burgess.
1996.
Producinghigh-dimensional semantic spaces from lexical co-occurrence.
Behavior Research Methods Instru-ments and Computers, 28(2):203?208.Andrew Kachites McCallum.
2002.
Mallet: A ma-chine learning for language toolkit.Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su,and ChengXiang Zhai.
2007.
Topic sentiment mix-ture: modeling facets and opinions in weblogs.
InProceedings of International Conference on WorldWide Web.Samaneh Moghaddam and Martin Ester.
2010.
Opin-ion digger: an unsupervised opinion miner fromunstructured product reviews.
In Proceeding ofthe ACM conference on Information and knowledgemanagement.Maria Pontiki, Dimitrios Galanis, John Pavlopou-los, Harris Papageorgiou, Ion Androutsopoulos, andSuresh Manandhar.
2014.
Semeval-2014 task 4:Aspect based sentiment analysis.
In Proceedings ofthe International Workshop on Semantic Evaluation(SemEval 2014), Dublin, Ireland.Lawrence Rabiner.
2010.
A tutorial on hidden markovmodels and selected applications in speech recogni-tion.
In Proceedings of the IEEE, pages 257?286.Lance A Ramshaw and Mitchell P Marcus.
1999.
Textchunking using transformation-based learning.
InNatural language processing using very large cor-pora, pages 157?176.
Springer.Douglas L. T. Rohde, Laura M. Gonnerman, andDavid C. Plaut.
2004.
An improved method forderiving word meaning from lexical co-occurrence.Cognitive Psychology, 7:573?605.Josef Steinberger, Mohamed Ebrahim, Maud Ehrmann,Ali Hurriyetoglu, Mijail Kabadjov, Polina Lenkova,Ralf Steinberger, Hristo Tanev, Silvia Vzquez, andVanni Zavarella.
2012.
Creating sentiment dictio-naries via triangulation.
Decision Support Systems,53(4):689 ?
694.Josef Steinberger, Tom?a?s Brychc?
?n, and MichalKonkol.
2014.
Aspect-level sentiment analysisin czech.
In Proceedings of the 5th Workshop onComputational Approaches to Subjectivity, Senti-ment and Social Media Analysis, Baltimore, USA,June.
Association for Computational Linguistics.Ivan Titov and Ryan McDonald.
2008.
Modeling on-line reviews with multi-grain topic models.
In Pro-ceedings of International Conference on World WideWeb.822
