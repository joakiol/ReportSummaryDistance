UNIVERSITY OF PENNSYLVANIA :DESCRIPTION OF THE UNIVERSITY OF PENNSYLVANI ASYSTEM USED FOR MUC- 6Breck BaldwinJeff Reyna rMike CollinsJason EisnerAdwait RatnaparkhiJoseph RosenzweigAnoop SarkarSrinivasUniversity of PennsylvaniaDepartment of Computer and Information Science s200 South 33rd StreetPhiladelphia, PA 19104breck@linc.cis .upenn.edu, jcreynar@linc .cis .upenn.edu(215) 898-032 6INTRODUCTIO NBreck Baldwin and Jeff Reynar informally began the University of Pennsylvania's MUC-6 coreference effor tin January of 1995 .
For the first few months, tools were built and the system was extended at weekly 'hacksessions .'
As more people began attending these meetings and contributing to the project, it grew to include eightgraduate students .
While the effort was still informal, Mark Wasson, from Lexis-Nexis, became an advisor to th eproject .
In July, the students proposed to the faculty that we formally participate in the coreference task .
By thattime, we had developed some of the system's infrastructure and had implemented a simplistic coreference resolutionsystem which resolved proper nouns by means of string matching .
After much convincing, the faculty agreed at th eend of July that we could formally participate in MUC-6 .
We then began an intensive effort with full-tim eparticipation from Baldwin and Reynar, and part-time efforts from the other authors .
In August we were givenpermission from Yael Ravin of IBM's Information Retrieval group to use the IBM Name Extraction Module [3] .
Wewere also given access to a large acronym dictionary which Peter Flynn maintains for a world wide web site inIceland (http ://curia.ucc .ie/info/net/acronyms/acro.html).The vast majority of our system was developed in August and September.
Our efforts prior to that timewere mostly directed towards implementing a parallel-file data structure which allowed new components to be adde dquickly with minimal effort .
The ease of incorporating new components was demonstrated by the addition of a ful lsyntactic parser two weeks prior to the evaluation .
In this data structure, enhancements to the input data, such astokenization, part-of-speech tags, or parse trees, are stored in separate, aligned files .
As a result, building a newmodule which requires input from earlier components is as simple as loading the files created by those componentsand performing the necessary processing .
The fact that modules further along in the pipeline do not alter the outpu tof earlier components means that output files can be read-only .
As a result, the system is afforded a measure o frobustness : if one component fails, further components will not necessarily be crippled and no downstrea mcomponent can alter the output of an earlier component .177This simple data structure, which was inspired by a pretty-printing convention used by Lexis-Nexis t odisplay multiple levels of textual annotation, also allowed people to write software in the programming language oftheir choice .
Ultimately, the majority of the code written explicitly for MUC was in Perl 4, but some programs wer ealso written in C and several different shell languages .
Other system components not developed explicitly for MUCwere written in Lisp and C++.Despite the advantages of this approach, the parallel-file data structure had some drawbacks .
First, becausethe system was built using many small tools, the number of files grew to be quite large, nearly 100 per article .
As aresult, disk space became a problem .
Second, because of the large number of files and the number of processe sreading each of them, file access time accounted for a significant portion of the time required to run the system .
Ittook approximately 12 minutes to process an average length article when processing was done in batch mode .Processing input files in groups allowed the overhead for loading dictionaries and statistical models to be reduce dbecause it could be averaged over many articles .Our coreference resolution system was built from several components, each of which addressed differen ttypes of coreference .
The philosophy behind this methodology was that high precision components could be linkedtogether serially to build an easily extensible, modular system .
We focused on building high precision component son the assumption that many high precision, moderate recall components, when linked together, would yield asystem with good overall recall .
This goal was met with varying degrees of success .
Unfortunately, only one of thethree components which posited coreference emerged as being highly precise : the proper name matching component .We utilized off-the-shelf components whenever possible .
Most of these tools were developed at Penn .
As aresult, the majority of our efforts went into writing parsers and preprocessing utilities which allowed various pre -existing tools to communicate with one another and produce output which could be used by other tools further in th eprocessing pipeline .
Thus, we were freed to spend time developing the task-specific components of the system an dperforming data analysis .
Although no time was spent developing tools particularly for the MUC task prior t oJanuary, many hours went into developing some of the off-the-shelf components we used, such as Eric Brills part-of-speech tagger [2] and Lance Ramshaw and Mitch Marcus' Noun Phrase Detector [10] .
We estimate the tota lnumber of hours spent on the project itself to be roughly 1800, distributed among the eight graduate students wh oworked on the project.
The vast majority of these hours were contributed between the end of July and competitio nweek in early October .Table 1 shows the performance of our system when simple formatting errors, which hurt performance o ntwo of the 30 test files, were corrected.
Table 2 contains our official system performance figures .
Table 3 contain ssystem performance when optional elements were treated as if required .
This set of scores is presented in order toallow comparison between scores for various system components without having to deal with the adjustment to th enumber of correct items which results from different components marking coreference between different numbers ofoptional elements .Recall 973/1540 .6 3Precision 973/1345 .72Table 1 : System Performance without Formatting Errors .Recall 848/1529 .55Precision 848/ 1345 .63Table 2 : Official System Performance .Recall973/1627.60178Precision973/1345.72Table 3 : System Performance without Formatting Errors but with optional elements treated as required .THE SYSTEMThroughout the system description section, words and phrases which appear in articles will be displayed i nitalics .
Figure 1 contains a system flowchart .
Databases are shown in drums and system modules are shown i nrectangles.End of Sentence Detectio nThe first step in our processing pipeline is end-of-sentence detection .
Sentence boundaries are identifiedusing a maximum entropy model developed explicitly for MUC-6 .
This model was built quickly using a generalmaximum entropy modeling tool which will be discussed in a forthcoming paper [11] .
Sentence final punctuation i sdefined to include only periods, exclamation points and question marks ; we do not attempt to mark sentenceboundaries indicated by semi-colons, commas or conjunctions .
Only instances of sentence-final punctuation whic hare immediately followed by white space or symbols which may legitimately follow sentence boundaries, such a squotation marks, were considered to be potential sentence boundaries .
For convenience, we define any sequence ofwhite-space separated tokens to be a word while discussing this stage of processing .The maximum entropy model was trained using the dry run and training portions of the MUC-6 coreferenc eannotated data, which included SGML annotated sentence boundaries .
The model used binary-valued features of theword to which the putative end-of-sentence marker was conjoined, as well as binary-valued features of the precedin gand following words .
These features included whether the word was a corporate designator, such as Corp .
or Inc ., oran honorific, such as Dr. or Ms. ; whether the word was upper-case ; whether the word was a likely monetary value ;whether the word was likely to be a percentage ; whether the word was a number ; whether the word containedpunctuation indicative of ellipsis ; and features indicating whether the word ended in various non-alphanumericcharacters .179I End of Sentence Detector ITokenizationIIAdwait's TaggerI'Eric's Tagger1IX-Tag Tagger )Tag Votin g!Noun Phrase Detector IINamed Entity Tool-~ La Hack 2Acronyms IIParserIPleonastic-It DetectorI--In- I Bride of CogNIACI..ICoreference Annotated TextIGender/Number/Animacy Detector IFigure 1 : System flowchart .We did not subject this component to rigorous testing, but did examine its output for approximately 300blind test sentences and found that only one error was made .
We intend to further refine this component and subject i tto automatic testing against a sentence-detected corpus in the near future .TokenizationOnce sentence boundaries are identified, tokenization begins .
We developed our tokenizer solely for th eMUC coreference task because of specific tokenization requirements .
The combination of the character-based natureof the scoring software and the requirements of various tools that punctuation be separated from words forced us t obuild a tokenizer which maintains a character offset mapping for all of the tokens in the input messages .
A trivia lerror in this system caused two of the 30 test messages to be garbled sufficiently that the scorer detected virtually n ocorrect coreference in them .
This is why we are presenting both official and unofficial scores .In addition to maintaining the character offset mapping, the tokenizer performs four non-standard tasks .
Thefirst is the alteration of headline word capitalization .
The Wall Street Journal adheres to standard conventions forcapitalization of words in headlines, but since capitalization is an important cue for coreference resolution, w eattempted to eliminate capitalization which resulted solely from these conventions .
Headline words which werecapitalized in the body of the text anywhere other than sentence-initial position remained capitalized, as did thos ewhich were frequently capitalized other than in sentence-initial position in the Treebank Wall Street Journal corpu s[8] .
All other uppercase words were converted to lowercase .The second non-standard task addressed by the tokenizer is the extraction of date information .
The datelinefield is parsed to determine when each article was written .
This information is later used to posit coreference betweenwords or phrases such as today, tomorrow, this week, this year, and dates, such as November 20, 1995 .The third non-standard component determines whether 's or ' is a genitive marker or part of a companyname.
When it is actually part of a company name, it does not indicate possession of the following noun phrase .This step was necessary because the part-of-speech taggers and the noun phrase detector required genitive markers t obe tokenized separately, while non-genitive instances of 's or ' were required to remain attached .
For instance ,180McDonald's, when it refers to the fast-food chain, should be treated as a single token, while Mary's should beseparated into two tokens : Mary and 's.The final unique task the tokenizer addresses is hyphenated-word splitting .
Since coreference is allowedbetween portions of hyphenated words which are themselves words, such as Apple in the phrase a joint Apple-IBMventure, determining whether a portion of a hyphenated word may participate in coreference is important .
Theheuristic we use is similar to the one used to determine whether a headline word should be downcased .
That is, whenone or more of the words which comprise a hyphenated word exists on their own within the article, then th ehyphenated word is split into multiple tokens .Unfortunately, because of the nature of the training data used by the noun phrase detector, bare hyphen scause serious noun phrase detection errors .
For simplicity, and because of time limitations, we opted not to retrai nthe noun phrase detector.
As a result, multiple tokenizations of each article are maintained .
In one of thetokenizations, hyphenated words are left unaltered .
In the other version, hyphenated words are split into multipl etokens based on the above criteria.
Also, the tokenizer is responsible for maintaining the mapping between these tw otokenizations so that the output of tools which use different tokenization schemes can be combined .Part-of-Speech TaggingSeveral components of the MUC coreference system, such as the noun phrase detector, require part-of-speech (POS) tags for all of the words in an article .
We combined the output of the following three POS tagger susing a simple voting scheme : Eric Brill's Rule Based Tagger version 1 .14 [2], the XTAG tagger, which is animplementation of Ken Church's PARTS tagger [4] and Adwait Ratnaparkhi's Maximum Entropy Tagger [11] .
Eachof these taggers uses the Penn Treebank tagset [8] .These three taggers, which were trained on the Penn Treebank Wall Street Journal corpus, tag pre-tokenizedtext .
The tag actually used by the MUC system is determined by a majority voting scheme, in which a tag is chose nas the "winner" if at least two of the taggers postulate it.
In the rare event that all three taggers disagree, the systemuses the tag assigned by the maximum entropy tagger .
In most cases, the majority voting scheme eliminates error sthat are esoteric to a single tagger, and should therefore perform better than any single tagger .
We did not have timeto empirically verify this hypothesis, but intend to do so in the future .
We may also improve upon the voting modelby incorporating information regarding which tagger proposed each tag .Basal Noun Phrase DetectionTo identify noun phrases, the system uses Lance Ramshaw and Mitch Marcus' basal noun phrase detecto r[10] .
Basal noun phrases are those noun phrases in the lowest level of embedding in the Penn Treebank' sannotations .
Intuitively, they are the smallest noun phrases in a parse .
For example, chief executive officer andInternational Business Machines are both basal noun phrases, but chief executive officer of International BusinessMachines is not, since it contains nested noun phrases .
Ramshaw and Marcus' noun phrase detector is based on Eri cBrill's work on learning transformational rules for part-of-speech tagging .
It was trained using a section of the taggedand parsed Treebank Wall Street Journal corpus disjoint from the MUC-6 test data .We postprocess the output of their tool to make it more appropriate for the coreference task .
For instance, i tbrackets noun phrases containing genitives in the following way : [Noun Phrase 1] ['s Noun Phrase 2] .
But, we prefer[Noun Phrase 1] 's [Noun Phrase 2] since it is more appropriate for further processing steps .
In addition, wemanually added some transformations to the set learned from the treebank .
These transformations generalized onlearned ones .
For instance, rules were learned which involved days of the week, but due to sparsity of training data,they were learned only for a subset of the seven days of the week .
We manually added the missing cases .
We did no tindependently measure the performance of their tool using this modified rule set, but may do so in the future .181Knowledge Source sWe experimented with various knowledge sources during system development, including WordNet [9], th eXTAG morphological analyzer [6], Roget's publicly available 1911 thesaurus, the Collins dictionary, a version ofthe American Heritage dictionary for which the University of Pennsylvania has a site license and the Gazetteer .
OnlyWordNet, the XTAG morphological analyzer and the Gazetteer were used in the final system .We extracted a geographic name database from a publicly available version of the Gazetteer which wedownloaded from the Center for Lexical Research.
This database contains names of continents, islands, island groups ,countries, provinces, cities and airports .
This information is used when performing type checking prior to positin gcoreference between entities .The XTAG morphology database [6] was originally extracted from the 1979 edition of the Collins EnglishDictionary and the Oxford Advanced Learner's Dictionary of Current English, and then edited and augmented by hand .It contains approximately 317,000 inflected items, along with their root forms and inflectional information, such ascase, number and tense.
Thirteen parts of speech are differentiated : noun, proper noun, pronoun, verb, verb particle ,adverb, adjective, preposition, complementizer, determiner, conjunction, interjection, and noun/verb contraction .Nouns and verbs are the largest categories, with approximately 213,000 and 46,500 inflected forms, respectively .Tagging for Gender, Number and AnimacyTo resolve pronouns which typically select for a gendered antecedent as well as those that typically selec tfor an animate antecedent, gendered or non-gendered, the WordNet 1 .5 lexical database [9] for nouns is used to tageach potential antecedent with respect to these semantic features .
In addition, rudimentary morphological analysis o fthe head of a noun phrase is performed and several databases are consulted to determine whether a particular nou nphrase refers to a male, a female, or a person of either gender .
Also, some singular count nouns, such as committee ,may be the antecedents of plural pronouns .
WordNet is also consulted to tag such nouns as possibly having sets ofindividuals as their referent .WordNet's noun database is organized as an inheritance lattice .
For example, the entry for man is linked todaughter nodes which include the entries bachelor, boyfriend, eunuch, etc .
Assuming that a semantic feature such asmaleness generally will propagate from a parent in the hierarchy to its children, one can test the gender of a give nnoun by examining its ancestors .
If one of the ancestors is the entry male, for example, it may be concluded that th eword itself typically denotes an entity which is male .
Similarly, the WordNet entry socialgroup tends to subsumenouns which can have groups of individuals as their referents .Unfortunately, the WordNet taxonomy is more like a tree than a lattice, so that many useful multipl einheritance links do not exist .
For example, the entry for uncle is not a descendant of the entry for man, although anuncle is clearly a type of man .
Additionally, as with any semantic inheritance hierarchy, not all features are alway spassed down from parent to child, so that strictly monotonic reasoning is not valid .To ameliorate these deficiencies and complications, the query to WordNet takes the form of a Boolean quer yabout the ancestors of a given word entry .
For example, an OR operator is used to tag as male words which ar edescendants of either the male node or the kinsman node, which subsumes uncle .
This supplants the missin ginheritance link, which would be needed in a complete semantic taxonomy, between male and kinsman .
To prune ou tdescendants of an entry such as man which do not inherit the semantic feature of maleness, an AND NOT operatorcan be used to exclude subclasses of the class of descendants of male .
Additionally, to circumvent problems withsolely relying on the Boolean query, a word's definition is also examined in a rudimentary way, to check for ke ywords that indicate semantic features of the potential referents of this word, such as the word someone, whic hsuggests a human referent .For polysemous words, WordNet may give conflicting evidence because of the word's multiple senses .
Forexample, end is judged as potentially compatible with a human referent, because an end is a type of football player .But in most contexts, this sense of end will be wrong and this word should not be considered as the potentia lantecedent for a pronoun such as he .182Therefore, the evidence from WordNet is weighted on a scale of plausibility .
The evidence for uncle i sconsidered more plausible than that for end because both senses of uncle in WordNet have the entry person amon gtheir ancestors .
On the other hand, only one of the thirteen senses for end has person as its ancestor .
Moreover, no tall of the senses of end are equally likely to occur .
The WordNet semantic concordance provides frequenc yinformation from a fraction of the Brown Corpus for senses of end and other words in the noun database.
Thesecounts can be used to estimate the probabilities of WordNet word senses .
When no data is available from thesemantic concordance for some senses of a word, the gaps in frequency are smoothed .
If no data is available for anysense of the word, the uniform distribution is assumed .The evidence from WordNet is then weighted according to how likely it is that the sense for which th eevidence is obtained is the correct sense of the word seen in the input file .
A more sophisticated approach woul dinvolve using word-sense disambiguation techniques to guess the correct sense of the word, and then only quer yWordNet about that particular sense .
However, the method employed in the current system is able to discriminat ereliably on a coarse level between cases like end and uncle .
A weight of 1 .0 is assigned to the person feature foruncle, whereas only 0.024 is assigned to this feature in end .As a second source of evidence about the gender or animacy of noun phrase referents, two tables of genderedfirst names, compiled by Mark Kantrowitz and Bill Ross and freely available from the Computing ResearchLaboratory of New Mexico State University, are consulted .
The table of first names overlaps with place names andtime words .
For example, Canada and Tuesday are women's names .
In such cases, the evidence from the table i sdiscarded .
This evidence is weighted separately from the WordNet look-up results .Finally, a rough analysis of the suffix morphology of the word is undertaken .
Nouns ending in "-man "which do not end in "-woman" tend to denote male humans .
However, due to the inherent gender bias of language ,words such as chairman can also be used to refer to women .
Hence such words also count as evidence of a femalereferent, but to a lesser degree.
This results in both the male weight and the female weight being set to non-zerovalues .
The difference in weighting between the two is currently based on intuition, though corpus methods migh tyield a more exact estimate of how much weight to give the female reading based on how often such words areactually used to refer to women .Pleonastic It DetectionIt is often used anaphorically in Wall Street Journal Text .
Nonetheless, identifying instances of pleonasticit, which do not corefer, is still significant .
The system identifies these instances of it by scanning tagged text andapplying partly syntactic and partly lexical tests .
Most of these tests are described in [7], but some additional test swere added to increase coverage .
The fifteen rules used to detect pleonastic it are shown below in table 4 .
Part ofspeech tags follow words and a slash, and are specified using the Penn Treebank tagset .
Disjunctions are indicatedusing a vertical bar, (I), and optional elements are surrounded by brackets, ([]) .
S abbreviates sentence ; NP mean snoun phrase ; and VP stands for verb phrase .
We abbreviate CA for comparative adjectives, such as larger or smaller;SA for superlatives, such as greatest or largest ; MA for modal adjectives, such as necessary or uncertain ; MV formodal verbs, like could or will ; CV for cognitive verbs, such as recommended or hoped; and CADV and SADV forcomparative and superlative adverbs .183It is (CA/JJR I SA/JJR I not) MA/JJ that S It (is not I may be) (CA/JJR I SA/JJR I not) MA/JJ .
.
.I MV appreciatelbelieve it if .
.
.
It MV be (MA/JJ I CVNBD) .
.
.It is (CA/JJR I SA/JJR I not) CVNBD that S It (seemslappearslmeanslfollows) [that] SNP makeslfinds it MA/JJ [for NP] to VP .
.
.
It is time to VP .
.
.It is thanks to NP that S It is (CADV/RB I SADVIRB) adj/JJ .
.
.It (signalslisNBZ) ?/NNP ?/POS ?/NN .
.
.
.
.
.
(makes I made) it clear that SIt is a (CADV/RB I SADV/RB) MA/JJ NP .
.
.
Would n't it be (CA/JJR I SA/JJR I not) MA/JJ .
.
.It is (CA/JJR I SA/JJR I not) MA/JJ [for NP] to VP .
.
.Table 4 : Pleonastic it detection rules .La Hack 2The first component of the system which actually marks coreference between entities is called La Hack 2 .It's performance is shown in table 5 .
Our first attempt at a coreference system, La Hack 1, posited coreferencebetween identical upper case words in the text, and was written to test the validity of the system's SGML annotatio nand to test the tokenizer.
La Hack 2 was written to do more sophisticated string matching .
It uses several knowledgesources, including the IBM Name Extraction Module, and a simple unification system to produce coreference chains .The knowledge sources are used to determine whether an entity is of type person, place, corporation or other .
Mostof the entities which La Hack 2 annotates are proper nouns, but the date information extracted by the tokenizer i sused here as well .
The majority of the strings annotated are noun phrases detected by the noun phrase detector, bu tsome sub-noun phrase units are annotated as well .
Proper nouns which are portions of longer noun phrases may b eannotated .
For example, Apple in the phrase Apple stock prices would be annotated if there were other references t oApple in the article .La Hack 2 makes four passes through each article .
On the first, it builds coreference chains containin galternate forms of corporate and person names as identified by the Name Extraction Module .
These variant referencesinclude references to people by first name only, last name only, last name and an honorific, and references whic homit middle names.
For instance, General Colin Powell could be referred to as General Powell, Colin, Powell, Mr.Powell and so forth .
Variant corporate names may be references which exclude corporate designators, use acronym sor omit a company's industry.
For example, Apple Computer Inc. might be referred to as Apple, Apple Inc ., etc .The next processing step looks for date matches, and those alternate forms not identified by the IBM tool .The third step looks for upper case string matches which are not variant name references or which do not contai ncorporate designators or honorifics .
Product names, some acronyms and miscellaneous other upper case words areentered into coreference chains in this stage .
The final stage is an upper case substring match which is targeted a tfinding coreference chains which were missed by the named entity tool and the other stages as well .The purpose of the simple type system is mainly to prevent coreference chains from being created by th esubstring matching stage which contain substrings of different types .
For instance, Apple is a substring of AppleCEO John Sculley, but they cannot be coreferent since John Sculley is a person and Apple is a corporation .184Recall 468/1627 29 %Precision 468/546 86%Table 5 : La Hack 2 performance .ParserThe parser we use has been developed over the past 6 months by Michael Collins, and is a continuation ofthe work on prepositional phrase attachment described in [5] .
It was trained on 33000 sentences from the Wall Stree tJournal Treebank [8] .
As yet no extensive performance tests have been made, but both recall and precision on labele dedges is over 80%.
The parser was used to spot syntactic patterns which signaled coreference of noun phrases withi nsentences, such as appositive relations and predicate nominative constructions .
The performance of this component isshown in table 6 .Given a maximal noun phrase, we find the head non-recursive noun phrase through a left-recursive descentof the parse tree.
For example Fred Bloggs, president of ACME, who was elected yesterday would be reduced to FredBloggs .
In addition, if either of the noun phrases involves conjunction, as in president of General Motors and forme rCEO of Ford, both minimal noun phrases, president and former CEO would be recovered .We mark one noun phrase, called NP1, as being coreferent with a second noun phrase, NP2, because of a nappositive relationship if NP1 is the head of a parent noun phrase, and NP2 is also a direct descendant of this paren tnoun phrase .
For example, in the phrase John Smith, president of ACME, a former worker at Eastern, John Smit his coreferent with both president and a former worker.
Note that the parser incorporates punctuation into thestatistical model, so a comma between two noun phrases is seen as a strong indication of an appositive relationship .The Wall Street Journal uses constructions similar to appositives to indicate relationships other tha ncoreference.
For example, such constructions are used with place names, such as Frankfurt, Germany or SmithBarney, Harris Upham & Co .
, New York ; ages, such as Al Bert, 49 ; and dates, such as March 31, 1989 .
Theseconstructions are a source of error in appositive recognition .
In addition, the parser confuses some instances o fconjunction with appositives .
For this reason, semantic filtering is required to raise precision .
We found that thefollowing strategy worked remarkably well : given the two proposed minimal noun phrases, if the first one has acapitalized head, and the second head begins with a lower-case letter, accept the pair as coreferent .
Note that thi swould deal correctly with all the above examples .
A few additional cases were caught by allowing pairs where thefirst head word was on a list of honorifics, such as president, chairman, journalist, or CEO, and the second head wascapitalized .
This heuristic correctly handles cases such as ACME 's president, Bill Jones .
Also, a later processin gstage removes indefinite cases from those proposed as appositives .
While not appearing in the final output, thes ecases are used to aid in positing other types of coreference .Definite cases of predicate nominative constructions are also markable .
As a result, syntactic patterns of th etype 'NP is NP' are also recognized, as are constructions involving the verbs remain or become, which function in asimilar way to be .
These could appear in sentential clauses or in relative clauses, such as Fred Flintstone, who isWilma's husband .
As is the case with appositives, indefinites are filtered from the final output, but are marked andused in later processing .Several verbs function similarly to become and remain, but subcategorize for a prepositional phrase headedby as, with the object of this prepositional phrase being coreferent with the subject of the verb .
A list of these verbs ,including serve, work, continue and resign, was compiled and these patterns were used as well .It was found that most verb phrases, regardless of the verb head, which take both a noun phrase, NP1, and aprepositional phrase headed by as with an object, NP2, imply coreference between NPI and NP2 .
This was extendedto include patterns of the form 'verb npl (to be np2) .'
Some examples are shown below.
Underlined entities arecoreferent .18 5Mr.
Casey succeeds M. James Barrett, 50, as president of Genetic TherapyBut the mainstream civil-rights leadership generally avoided the rhetoric of "law and order," regarding it.
as acote for keeping blacks backWe consider our Butthead to be an endearing.
fun-loving guy," a spokesman say sIn addition, patterns were implemented to identify phrases containing monetary figures in which alternaterepresentations of the amount are present.
Some such phrases are : $53 , or 20 cents a share, 23 billion marks (1 5billion dollars) and profits climbed to 11 million dollars .Recall 97/ 1627 6 %Precision 97/139 70%Table 6 : Syntactic Pattern Performance .Parsing enables regular expressions to be written which apply to trees rather than surface text .
Thesepatterns are simpler and more intuitive than equivalent surface regular expressions .
It is trivial to add new patterns tothe system, since the parser has effectively abstracted away many of the complications of the surface text .
Whileregular expressions could catch many of the phenomena we have described, they will become increasingly comple xas they attempt to capture long range dependencies in the text and will also become increasingly inaccurate .Bride of CogNIA CResolution of pronouns and lower-case anaphors was handled by a program called Bride of CogNIAC, whic his an extension of CogNIAC, [1] .
CogNIAC was designed to perform pronominal resolution in highly ambiguou scontexts and is distinguished from other approaches to pronominal resolution in the following ways.
First, it wasdesigned to have high precision, rather than high recall .
Second, it ranks the relative salience of an anaphor' scandidate antecedents in a partial order rather than a total order .
This means that two candidate antecedents can beequally salient.
And, third, it requires that there be a unique antecedent for an anaphor .
Uniqueness is achieved b yeliminating competing antecedents using semantic information or by preferring some candidate antecedents ove rothers .
CogNIAC will not commit to a resolution if a unique referent cannot be found .Bride of CogNIAC also handles lower-case definite descriptions using various knowledge sources to d osemantic classification of noun phrases into categories such as person, male, female, place, thing, singular an dplural .
It also employs the pleonastic-it filter described above and a quoted speech component not present i nCogNIAC .
Bride of CogNIAC performs resolution on basal noun phrase detected and part-of-speech tagged text .
Italso relies on proper noun anaphora information provided by La Hack 2 and syntactic anaphora information posite dby the parser .
System performance prior to running Bride of CogNIAC, the last component which posits coreference ,is shown in table 7 .Recall 564/ 1627 35 %Precision 564/648 82%Table 7: La Hack 2 and Syntactic Pattern Performance .Bride of CogNIAC attempts to determine whether fuzzy string matches such as the unions and unionsindicate coreference .
The combined performance of this component in conjunction with above components is show nin table 8 .
It equates markables which share a common head noun using various metrics of similarity .
The biggest18 6difficulty is to prevent Bride of CogNIAC from marking too many things as coreferent .
As a result, variousheuristics are used to reduce the number of entities marked .
For example, coreference is not posited if :?
The number of words in the antecedent noun phrase is less than the number of words in the anaphor .?
The words in either string are on a stop-word list .?
Possessive or prepositional modifier conflicts exist .Recall 729/ 1627 45 %Precision 729/992 79 %Table 8: Performance with lower case string matching added .The second and final task addressed by Bride of CogNIAC is the resolution of pronominals and words whic hbehave like pronominals, such as company .
Performance for this component alone is shown in table 9 .
Overal lofficial results are shown in table 2.
Overall unofficial results are shown in table 1 .Recall 245/1627 15 %Precision 245/423 58%Table 9 : Pronoun component performance .We were disappointed by the performance of the pronoun resolution component .
In examining the outpu tbriefly, the mistakes made were due to knowledge-base failures and bugs more than issues inherent to the pronou nresolution algorithm .
This is clearly an aspect of the task where better knowledge representation would improv esystem performance .CONCLUSIONWe found the MUC-6 coreference task to be challenging and enjoyable for several reasons .
First, most of u sare accustomed to working alone and we enjoyed the opportunity to work as a team, especially since this fostere dresearch contacts which might not have otherwise been made .
Second, unlike' typical research work, participation i nMUC lasted a finite amount of time and there were clearly defined goals and success metrics .
Third, the task exposedsome of us to research areas with which we only had passing familiarity .
We hope that MUC will continue t oencourage participation from new sites by focusing on sub-tasks relevant to information extraction .THANKSWe would especially like to thank Aravind Joshi and Mitch Marcus who allowed us to take time off fro mwork directly related to our graduate studies to participate in the MUC-6 coreference task .
We would also like tothank Mark Wasson for helpful comments on tokenization and for providing the inspiration for our data structure ;Yael Ravin for giving us access to the Name Extraction Module and for documenting it so that we could quickl yincorporate it into the coreference system ; Peter Flynn for providing us with a large hand-built acronym dictionarywhich he maintains on a world wide web site in Iceland; and Christy Doran for analyzing some of the coreferencedata and providing us with many linguistic insights .18 7RESPONSE FILE FOR WALKTHROUGH ARTICL E<DOC><DOCID> wsj94_026.0231 </DOCID><DOCNO> 940224-0133 .
</DOCNO><HL> marketing & media -- Advertising :@ <COREF ID="3">John Dooner</COREF> will succeed <COREF ID="4">James</COREF >@ at helm of <COREF ID="6">McCann-Erickson</COREF >@ ----@ by Kevin Goldman <IHL ><DD> 02/24/94 </DD><SO> WALL STREET JOURNAL (J), PAGE B8 </SO><CO> IPG K </CO><IN> ADVERTISING (ADV), ALL ENTERTAINMENT & LEISURE (ENT) ,FOOD PRODUCTS (FOD), FOOD PRODUCERS, EXCLUDING FISHING (OFP) ,RECREATIONAL PRODUCTS & SERVICES (REC), TOYS (TMF) </IN><TXT><p>One of the many differences between <COREF ID=" 11 " TYPE="IDENT" REF="4">Robert L .
James</COREF> ,<COREF ID=" 12" TYPE="IDENT" REF="4">chairman</COREF> and <COREF ID=" 13" TYPE="IDENT "REF="4">chief executive officer</COREF> of <COREF ID=" 14" TYPE="IDENT" REF="6">McCann -Erickson</COREF>, and <COREF ID="15" TYPE="IDENT" REF="3">John J .
Dooner Jr.</COREF> ,<COREF ID="16">the agency<ICOREF>'s <COREF ID=" 17" TYPE="IDENT" REF="3">president</COREF >and <COREF ID="18" TYPE="IDENT " REF="3">chief operating officer</COREF>, is quite telling : <COREFID="19" TYPE="IDENT" REF="4">Mr.
James</COREF> enjoys sailboating, while <COREF ID="20 "TYPE="IDENT" REF="3">Mr .
Dooner</COREF> owns a powerboat .</p><p>Now, <COREF ID="22" TYPE="IDENT" REF="4">Mr .
James</COREF> is preparing to sail into the sunset, an d<COREF ID="24" TYPE="IDENT " REF="3">Mr .
Dooner</COREF> is poised to rev up the engines to guid eInterpublic Group's <COREF ID="27" TYPE="IDENT" REF="6">McCann-Erickson</COREF> into the 21s tcentury .
<COREF ID="29">Yesterday</COREF>, <COREF ID="30" TYPE="IDENT "REF="6">McCann</COREF> made official what had been widely anticipated : <COREF ID="32" TYPE="IDENT"REF="4">Mr .
James</COREF>, 57 years old, is stepping down as chief executive officer on July 1 and wil lretire as chairman at the end of the year .
<COREF ID="39">He</COREF> will be succeeded by <COREF ID="40 "TYPE="IDENT" REF="3">Mr .
Dooner</COREF>, 45 .</p><p>It promises to be a smooth process, which is unusual given the volatile atmosphere of the <CORE FID="318">advertising</COREF> business .
But <COREF ID="47" TYPE="IDENT" REF="3">Mr.Dooner</COREF> has <COREF ID="48">a big challenge</COREF> that will be <COREF ID="50 "TYPE="IDENT" REF="3">his</COREF> <COREF ID="51" TYPE="IDENT" REF="48">to ppriority</COREF> .
"<COREF ID="52" TYPE="IDENT" REF="39">I</COREF>'m going to focu son strengthening <COREF ID="53">the creative work</COREF>," <COREF ID="54" TYPE="IDENT "REF="39">he</COREF> says .
"There is room to grow.
<COREF ID="57">We</COREF> can make furthe rimprovements in terms of the perception of <COREF ID="61" TYPE="IDENT" REF="57">our</COREF ><COREF ID="62" TYPE="IDENT" REF="53">creative work</COREF> .
"</p><p>Even Alan Gottesman, an analyst with PaineWebber, who believes<COREF ID="67" TYPE="IDENT "REF="6">McCann</COREF> is filled with "vitality" and is in "great shape," says that from a creative standpoint ,"You wouldn't pay to see <COREF ID="72" TYPE="IDENT" REF="6">their</COREF> reel" of <COREFID="74">commercials<JCOREF> .</p><p>While <COREF ID="75" TYPE="IDENT" REF="6">McCann</COREF>'s world-wide billings rose 12% to $6 .4billion last year from $5.7 billion in 1992, <COREF ID="82" TYPE="IDENT" REF="16">the agency</COREF >188still is dogged by the loss of the key creative assignment for the prestigious Coca-Cola Classic account .
"<COREFID="86" TYPE="IDENT" REF="3">I</COREF> would be less than honest to say <COREF ID="87 "TYPE="IDENT" REF="3">I</COREF>'m not disappointed not to be able to claim creative leadership for <CORE FID="89">Coke</COREF>,"<COREF ID="90" TYPE="IDENT" REF="3">Mr .
Dooner</COREF> says .</p><p><COREF ID="91" TYPE="IDENT" REF="6">McCann</COREF> still handles promotions and media buying for <COREF ID="93" TYPE="IDENT" REF="89">Coke</COREF> .
But the bragging rights to<COREF ID="95" TYPE="IDENT" REF="89">Coke</COREF>'s ubiquitous advertising belongs to <CORE FID="97">Creative Artists Agency</COREF>, <COREF ID="98" TYPE="IDENT" REF="97">the big Hollywoo dtalent agency</COREF>.
"<COREF ID="99" TYPE="IDENT" REF="57">We</COREF> are striving to have astrong renewed creative partnership with Coca-Cola," <COREF ID=" 102" TYPE="IDENT" REF="3">Mr .Dooner</COREF> says .
However, odds of that happening are slim since <COREF ID="105">word</COREF >from <COREF ID="313" TYPE="IDENT" REF="89">Coke</COREF> headquarters in Atlanta is that <CORE FID="312" TYPE="IDENT" REF="97">CAA</COREF> and other ad agencies, such as Fallon McElligott, willcontinue to handle <COREF ID="314" TYPE="IDENT" REF="89">Coke</COREF> advertising .</p><p><COREF ID=" 112" TYPE="IDENT" REF="3">Mr .
Dooner</COREF>, who recently lost 60 pounds ove r<COREF ID=" 115" TYPE="IDENT" REF="39">three-and-a-half months</COREF>, says now that <CORE FID=" 116" TYPE="IDENT" REF="3">he</COREF> has "reinvented" himself, <COREF ID=" 118" TYPE="IDENT "REF="3">he</COREF> wants to do the same for <COREF ID=" 120" TYPE="IDENT" REF=" 16">th eagency</COREF>.
For <COREF ID="121" TYPE="IDENT" REF="3">Mr .
Dooner</COREF>, it meansmaintaining <COREF ID=" 123" TYPE="IDENT" REF="3">his</COREF> running and exercise schedule, and fo r<COREF ID=" 125" TYPE="IDENT" REF="16">the agency</COREF>, <COREF ID=" 126" TYPE="IDENT "REF=" 16">i</COREF> means developing more global campaigns that nonetheless reflect local cultures .
One<COREF ID="310" TYPE="IDENT" REF="6">McCann</COREF> account, "<COREF ID=" 131 "TYPE="IDENT" REF="39">I</COREF> Can't Believe <COREF ID=" 132" TYPE="IDENT "REF="6">It</COREF>'s Not Butter," a butter substitute, is in 11 countries, for example .</p><p><COREF ID="137" TYPE="IDENT" REF="6">McCann</COREF> has initiated a new so-called globa lcollaborative system, composed of world-wide account directors paired with creative partners .
In addition, Peter Kimwas hired from WPP Group's J .
Walter Thompson last September as vice chairman, chief strategy officer, world -wide .</p><p><COREF ID=" 147" TYPE="IDENT" REF="3">Mr.
Dooner</COREF> doesn't see a creative malaise permeating<COREF ID=" 149" TYPE="IDENT" REF=" 16">the agency</COREF> .
<COREF ID=" 150" TYPE="IDENT "REF="3">He</COREF> points to several campaigns with pride, including <COREF ID=" 153">th eTaster</COREF>'s Choice commercials that are like a running soap opera .
"<COREF ID=" 157" TYPE="I DENT" REF= " 153">It</COREF>'s a $19 million campaign with the recognition of a $200 million campaign, "<COREF ID=" 161 " TYPE="IDENT" REF="3">he</COREF> says of <COREF ID=" 162" TYPE="IDENT "REF="74">the commercials</COREF> that feature a couple that must hold a record for the length of <CORE FID=" 168">time</COREF> dating before kissing .</p><p>Even so, <COREF ID=" 170" TYPE="IDENT" REF="3">Mr .
Dooner</COREF> is on the prowl for more creativ etalent and is interested in acquiring <COREF ID=" 173" TYPE="IDENT" REF=" 16">a hot agency</ COREF>.
<COREF ID=" 174" TYPE="IDENT" REF="39">He</COREF> says <COREF ID=" 175 "TYPE="IDENT" REF="39">he</COREF> would like to finalize <COREF ID=" 176" TYPE="IDENT "REF="29">an acquisition "yesterday</COREF> .
<COREF ID=" 177" TYPE="IDENT" REF="39">I</COREF>'mnot known for patience .
"</p><p><COREF ID=" 179" TYPE="IDENT" REF="3">Mr .
Dooner</COREF> met with <COREF ID=" 180">MartinPuris</COREF>, <COREF ID=" 181 " TYPE="IDENT" REF=" 180">president</COREF> and <COREF ID=" 182 "189TYPE="IDENT" REF="180">chief executive officer</COREF> of <COREF ID=" 183 ">Ammirati &Puris</COREF>, about <COREF ID=" 184" TYPE="IDENT" REF="6">McCann</COREF>'s acquiring the agenc ywith billings of $400 million, but nothing has materialized.
"There is no question," says <COREF 1D"191 "TYPE="IDENT" REF="3">Mr.
Dooner</COREF>, "that <COREF ID=" 192" TYPE="IDENT "REF="57">we</COREF> are looking for quality acquisitions and <COREF ID=" 194" TYPE="IDENT "REF=" 183">Ammirati & Puris</COREF> is a quality operation .
There are some people and entire agencies that<COREF ID=" 199" TYPE="IDENT" REF="3">I</COREF> would love to see be part of the <COREF ID="311 "TYPE="IDENT" REF="6">McCann<JCOREF> family ."
<COREF ID="202" TYPE="IDENT" REF="3">Mr .Dooner</COREF> declines to identify possible acquisitions .</p><p><COREF ID="204" TYPE="IDENT" REF="3">Mr .
Dooner</COREF> is just gearing up for the headaches ofrunning one of the largest world-wide agencies .
(There are no immediate plans to replace <COREF ID="210 "TYPE="IDENT" REF="3">Mr .
Dooner</COREF> as <COREF ID="211" TYPE="IDENT "REF="3">president</COREF> ; <COREF ID="212" TYPE="IDENT" REF="4">Mr .
James</COREF> operated aschairman, chief executive officer and president for a period of <COREF ID="217" TYPE="IDENT "REF="168">time</COREF> .)
<COREF ID="218" TYPE="IDENT" REF="4">Mr .
James</COREF> is filled wit hthoughts of enjoying <COREF ID="220" TYPE="IDENT" REF="4">his</COREF> three hobbies : <COREFID="222">sailing</COREF>, skiing and hunting .</p><p>Asked why <COREF ID="224" TYPE="IDENT" REF="4">he</COREF> would choose to voluntarily exit whil e<COREF ID="226" TYPE="IDENT" REF="4">he</COREF> still is so young, <COREF ID="227 "TYPE="IDENT" REF="4">Mr .
James</COREF> says it is <COREF ID="229" TYPE="IDENT "REF=" 168">time</COREF> to be a tad selfish about how <COREF ID="231 " TYPE="IDENT "REF="4">he</COREF> spends <COREF ID="232" TYPE="IDENT" REF="4">his</COREF> days .
<COREFID="234" TYPE="IDENT" REF="4">Mr.
James</COREF>, who has a reputation as <COREF ID="237">a nextraordinarily tough taskmaster</COREF>, says that because <COREF ID="238" TYPE="IDENT "REF="4">he</COREF> "had <COREF ID="239" TYPE="IDENT" REF=" 168">a great time</COREF>" i n<COREF ID="240" TYPE="IDENT" REF="318">advertising</COREF>," <COREF ID="241" TYPE="IDENT "REF="237">he<JCOREF> doesn't want to "talk about the disappointments ."
In fact, when <COREFID="244">he</COREF> is asked <COREF ID="245" TYPE="IDENT" REF="244">his</COREF> opinion of thenew batch of <COREF ID="315" TYPE="IDENT" REF="89">Coke</COREF> ads from <COREF ID="249 "TYPE="IDENT" REF="97">CAA<JCOREF>, <COREF ID="250" TYPE="IDENT" REF="4">Mr .James</COREF> places <COREF ID="251" TYPE="IDENT" REF="4">his</COREF> hands over <COREFID="253" TYPE="IDENT" REF="4">his</COREF> mouth .
<COREF ID="255">He</COREF> shrugs .
<COREFID="256" TYPE="IDENT" REF="255">He</COREF> doesn't utter <COREF ID="257" TYPE="IDENT "REF="105">a word</COREF> .
<COREF ID="258" TYPE="IDENT" REF="255">He</COREF> has, <COREFID="259" TYPE="IDENT" REF="255">he</COREF> says, fond memories of working with <COREF ID="316 "TYPE="IDENT" REF="89">Coke</COREF> executives .
"<COREF ID="262" TYPE="IDENT "REF="89">Coke</COREF> has given <COREF ID="263" TYPE="IDENT" REF="57">us</COREF> grea thighs," says <COREF ID="265" TYPE="IDENT" REF="4">Mr .
James</COREF>, sitting in <COREF ID="266 "TYPE="IDENT" REF="255">his</COREF> plush office, filled with photographs of <COREF ID="269 "TYPE="IDENT" REF="222">sailing</COREF> as well as huge models of, among other things, a Dutch tugboat .</p><p><COREF ID="273">He</COREF> says <COREF ID="274" TYPE="IDENT" REF="273">he</COREF> feels a"great sense of accomplishment ."
In 36 countries, <COREF ID="278" TYPE="IDENT "REF="6">McCann</COREF> is ranked in the top three ; in 75 countries, <COREF ID="281" TYPE="IDENT "REF="6">it</COREF> is in the top 10 .</p><p>Soon, <COREF ID="283" TYPE="IDENT" REF="4">Mr.
James<ICOREF> will be able to compete in as man ysailing races as <COREF ID="285" TYPE="IDENT" REF="4">he</COREF> chooses .
And concentrate on<COREF ID="286" TYPE="IDENT" REF="4">his</COREF> duties as rear commodore at the New York Yach tClub .</p><p>190Maybe <COREF ID="290">he</COREF>11 even leave something from <COREF ID="292" TYPE="IDENT "REF="290">his</COREF> office for <COREF ID="294" TYPE="IDENT" REF="3">Mr .
Dooner</COREF>.Perhaps a framed page from <COREF ID="296">the New York Times</COREF>, dated Dec .
8, 1987, showing ayear-end chart of the stock market crash earlier that year.
<COREF ID="301" TYPE="IDENT" REF="4">Mr.James</COREF> says <COREF ID="302" TYPE="IDENT" REF="4">he</COREF> framed <COREF ID="303 "TYPE="IDENT" REF="296">it</COREF> and kept <COREF ID="304" TYPE="IDENT "REF="296">it</COREF> by <COREF ID="305" TYPE="IDENT" REF="4">his</COREF> desk as a "persona lreminder.
<COREF ID="308" TYPE="IDENT" REF="296">It<JCOREF> can all be gone like that .
"</p></TXT ></DOC >REFERENCES[I] Baldwin, B .
CogNIAC : A Discourse Processing Engine .
University of Pennsylvania Department o fComputer and Information Sciences Ph .D.
Thesis, 1995 .
[2] Brill, Eric .
Some Advances in Transformation-Based Part of Speech Tagging .
In Proceedings of th eTwelfth National Conference on Al, (AAAI-94), Seattle, Washington, 1994 .
[3] Byrd, R ., Ravin, Y .
and Prager, J .
Lexical Assistance at the Information Retrieval User Interface .
InProceedings of the Fourth Annual Symposium on Document Analysis and Information Retrieval, Las Vegas ,Nevada, April 1995 .
[4] Church, K .
A Stochastic Parts Program and Noun Phrase Parser for Unrestricted Text .
In Proceedings ofthe Second Conference on Applied Natural Language Processing .
February 1988 .
[5] Collins, M. and Brooks, J .
Prepositional Phrase Attachment through a Backed-off Model .
InProceedings of the Third Workshop on Very Large Corpora, June 1995 .
[6] Karp, D ., Schabes, Y ., Zaidel, M. and Egedi, D .
.
A Freely Available Wide Coverage Morphologica lAnalyzer for English .
Proceedings of the 15th International Conference on Computational Linguistics, 1992 .
[7] Lappin, S .
and Leass, H. An Algorithm for Pronominal Anaphora Resolution .
ComputationalLinguistics, vol .
20, num.
4, pp .
538-53 9[8] Marcus M., Santorini, B .
and Marcinkiewicz, M., Building a Large Annotated Corpus of English : thePenn Treebank .
Computational Linguistics, vol .
19, num .
2, 1993 .
[9] Miller, G., Beckwith, R ., Fellbaum, C ., Gross, D .
and Miller, K. Five Papers on WordNet.
CognitiveScience Laboratory, Princeton University, No .
43, July 1990 .
[10] Ramshaw, L .
and Marcus, M .
Text Chunking Using Transformation-Based Learning .
In Proceedings ofthe Third Workshop on Very Large Corpora, June 1995 .
[11] Ratnaparkhi, A .
Forthcoming .191
