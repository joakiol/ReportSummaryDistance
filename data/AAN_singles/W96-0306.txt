Acquisition of Semantic Lexicons: Using Word SenseDisambiguation to Improve PrecisionBonnie J. Dorr and Doug JonesDepartment of Computer Science andInstitute for Advanced Computer StudiesUniversity of MarylandA.
V. Williams BuildingCollege Park, MD 20742{bonnie,jones } @umiacs.umd.eduAbstractThis paper addresses the problem of large-scale acquisition of computational-semantic lexicons frommachine-readable resources.
We describe semantic filters designed to reduce the number of incorrectassignments (i.e., improve precision) made by a purely syntactic technique.
We demonstrate hatit is possible to use these filters to build broad-coverage lexicons with minimal effort, at a depth ofknowledge that lies at the syntax-semantics nterface.
We report on our results of disambiguatingthe verbs in the semantic filters by adding WordNet 1sense annotations.
We then show the resultsof our classification on unknown words and we evaluate these results.1 IntroductionThis paper addresses the problem of large-scale acquisition of computational-semantic lexicons frommachine-readable resources.
We describe semantic filters designed to reduce the number of incorrectassignments (i.e., improve precision) made by a purely syntactic technique.
We demonstrate hatit is possible to use these filters to build broad-coverage lexicons with minimal effort, at a depth ofknowledge that lies at the syntax-semantics nterface.
We report on our results of disambiguatingthe verbs in the semantic filters by adding WordNet sense annotations.
We then show the resultsof our classification on unknown words and we evaluate these results.As machine-readable resources (i.e., online dictionaries, thesauri, and other knowledge sources)become readily available to NLP researchers, automated acquisition has become increasingly moreattractive.
Several researchers have noted that the average time needed to construct a lexicalentry by hand can be as much as 30 minutes (see, e.g., (Neff and McCord, 1990; Copestake t al.,1995; Walker and Amsler, 1986)).
Given that most large-scale NLP applications require lexiconsof 20-60,000 words, automation of the acquisition process has become a necessity.Previous research in automatic acquisition focuses primarily on the use of statistical techniques,such as bilingual alignment (Church and Hanks, 1990; Klavans and Tzoukermann, 1996; Wu andXia, 1995), or extraction of syntactic onstructions from online dictionaries and corpora (Brent,1993; Dorr, Garman, and Weinberg, 1995).
Others who have taken a more knowledge-based (in-terlingual) approach (Lonsdale, Mitamura, and Nyberg, 1996) do not provide a means for system-atically deriving the relation between surface syntactic structures and their underlying semanticrepresentations.
Those who have taken more argument structures into account, e.g., (Copestakeet al, 1995), do not take full advantage of the systematic relation between syntax and semanticsduring lexical acquisition.1We used Version 1.5 of WordNet, available at http://www.cogsci.princeton.edu/~wn.42!We adopt the central thesis of Levin (1993), i.e., that the semantic lass of a verb and itssyntactic behavior are predictably related.
We base our work on a correlation between semanticclasses and patterns of grammar codes in the Longman's Dictionary of Contemporary English(LDOCE) (Procter, 1978).
We extend this work by coupling the syntax-semantics relation with apre-defined association between WordNet (Miller, 1985) word senses and Levin's verbs in order togroup the full Set of LDOCE verbs into semantic lasses.While the LDOCE has been used previously in automatic extraction tasks (Alshawi, 1989;Farwell, Guthrie, and Wilks, 1993; Boguraev and Briscoe, 1989; Wilks et al, 1989; Wilks etal., 1990) these tasks are primarily concerned with the extraction of other types of informationincluding syntactic phrase structure and broad argument restrictions or with the derivation ofsemantic structures from definition analyses.
The work of Sanfilippo and Poznanski (1992) ismore closely related to our approach in that it attempts to recover a syntactic-semantic relationfrom machine-readable dictionaries.
However, they claim that the semantic lassification of verbsbased on standard machine-readable dictionaries (e.g., the LDOCE) is "a hopeless pursuit \[since\]standard ictionaries are simply not equipped to offer this kind of information with consistencyand exhaustiveness.
"Others have also argued that the task of simplifying lexical entries on the basis of broad semanticclass membership is complex and, perhaps, infeasible (see, e.g., Boguraev and Briscoe (1989)).However, a number of researchers (Fillmore, 1968; Grimshaw, 1990; Gruber, 1965; Guthrie et al,1991; Hearst, 1991; Jackendoff, 1983; Jackendoff, 1990; Levin, 1993; Pinker, 1989; Yarowsky, 1992)have demonstrated conclusively that there is a clear relationship between syntactic ontext andword senses; it is our aim to exploit this relationship for the acquisition of semantic lexicons.We first describe the LDOCE verb classification resulting from a purely syntactic approachto deriving semantic lasses.
We then describe a semantic filter designed to reduce the number ofincorrect assignments made by the syntactic technique; we show how this filter can be enhanced witha method that accounts for multiple word senses.
Finally we show the results of our classificationof unknown verbs, and we evaluate these results.
Our results clearly indicate that the resolution ofpolysemy is a key component to developing an effective semantic filter.2 Verb Classif ication Based on Syntact ic  BehaviorWe build on the syntactic filter approach of (Dorr, Garman, and Weinberg, 1995), in which verbswere automatically classified into semantic lasses using syntactic encodings in LDOCE.
This earlierapproach produced a ranked assignment of verbs to the semantic lasses from (Levin, 1993) basedon syntactic tests (e.g., whether a verb occurs in a dative construction such as Mary gave John thebook).
2 The syntactic approach alone was demonstrated to classify Levin verbs with 47% accuracy(i.e., 1812 correct verb classifications out of 3851 possible assignments).The measure of success used in the purely syntactic approach is flawed in that the "accuracy"factor was based on the number of correct assignments in the five top-ranked assignments producedby their algorithm.
A better measure of the efficacy of the algorithm would be to examine the ratioof correct assignments to the total number of assignments.
The algorithm in (Dorr, Garman,and Weinberg, 1995) is correct only 13% of the time (1812 correct assignments out of 13761 totalassignments) if given up to 5 assignments per verb.
If given up to 15 assignments, the situation2Levin's emantic lasses are labeled with numbers ranging from 9 to 57; the actual number of semantic lasses is191 (not 46) due to many class subdivisions under each major class, These 191 classes cover 2813 verbs that occurin the LDOCE.
Since verbs may occur in multiple classes, the number of possible assignments of LDOCE verbs intoclasses is 3851.43would deteriorate further: even though 2607 out of 3851 possible assignments would be correct,these correct assignments constitute only 6.5% of the total number of assignments made by thealgorithm.We borrow terminology from Information Filtering (see, e.g., (Lewis, 1992)) to characterizethese results.
In particular, Recall is the number of correct categorizations the algorithm givesdivided by the number of correct categorizations already given in the database.
Precision, onthe other hand, is the number of correct categorizations that the algorithm gives divided by thetotal number of categorizations that it gave.
In these terms, the algorithm in (Dorr, Garman, andWeinberg, 1995) achieves a recall of 67.7%, but a precision of 6.5% if given up to 15 semantic lassassignments per verb.In addition to low precision, the purely syntactic filter described above was tested only on verbsthat are in (Levin, 1993) and it did not take into account he problem of multiple word senses.
Theremainder of this paper describes the formulation and refinement of semantic filters that increasesthe precision of this earlier experiment, while extending the coverage to novel verbs (i.e., ones notoccurring in (Levin, 1993)) and addressing the polysemy problem.3 Semantic Filter: Increasing PrecisionWe take as our starting point 7767 LDOCE verbs, approximately 5000 of which do not occur inLevin's classes.
Each of these verbs was assigned up to 15 possible semantic lasses, ranked by thedegree of likelihood that the verb belongs to that class, giving a total of 113,106 ranked assignments.As described above, the syntactic filter discovers 2607 of the 3851 assignments of LDOCE verbsfound in Levin's semantic lasses.
These assignments are particularly interesting because we knowthey are correct, and we can see how high the program ranks the correct assignments.To create a semantic filter, we take a semantic lass from Levin and extend it with relatedverbs from WordNet.
We call this extended list a semantic field.
Verbs that do not occur in thesemantic field of a particular class fail to pass through the semantic filter for that class, by definition.We first examined ifferent semantic relations provided by WordNet (synonymy, hyponymy, bothsynonyms and hyponyms, and synonyms of synonyms) in order to determine which one would bemost appropriate for constructing semantic fields for each of Levin's 191 verb classes.
We evaluatedthe performance of these different relations by examining the degree of class coverage of the relationusing a prototypical verb from each class.
3For example, the Change of State verbs of the break subclass (Class 45.1) contains the verbsbreak, chip, crack, crash, crush, fracture, rip, shatter, smash, snap, splinter, split, tear.
The fullsemantic field contains the union of the related verbs for every verb in the original Levin class.Thus, if we build our semantic field on the basis of the synonymy relation, all synonyms of verbsin a particular class would be legal candidates for membership in that class.
For Class 45.1, usingthe synonymy relation would result in a field size of 185 (i.e., there are 185 WordNet synonyms forthe 13 verbs in the class); by contrast, the hyponymy relation would yield a field size of 245.To choose a relation to use for the semantic field, we looked at verbs semantically related to theprototypical verb in each class, and checked how many of the verbs in each class would be includedin the filter.
We examined several relations based on combinations of synonymy and hyponymy.We considered the best candidate to be the one that matched the greatest proportion of the verbsin Levin's semantic lasses when given the prototype verb.
The best relation, synonyms of the3A verb is considered to be prototypical with respect to a class if it conforms to all of Levin's membership testsfor that class.
These tests are based on grammaticahty of usage in certain well-defined contexts (e.g., the dativeconstruction).44All FilteredTotal Assignments 40,248 4168Right Assignments 2,607 2607Wrong Assignments 37,641 1561Precision (Right/Total) 6.5% 62.5%Table 1: Increasing Precision with the Semantic Filterprototype verb, matched an average of 20% of the Levin verbs, while having an average size of 11verbs.
The average size of Levin's semantic lasses is 22 verbs.Let us now:look at the behavior of the synonymy-based semantic filter.
Of the 113,106 assign-ments of LDOCE verbs to Levin classes given by the syntactic filter, 6029 (19%) pass through thesemantic filter.
Clearly, the semantic filter constrains the possible assignments, but the questionto ask is whether the constraint improves the accuracy of the assignments.
To answer this, wefirst examined the 2813 verbs in LDOCE that also appear in Levin to see if they matched Levin'scategorization.Without the semantic filter, the syntactic filter provides up to 15 semantic-class a signments foreach of the 2813 verbs, giving 40,248 assignments, asshown in Table 1.
2,607 of these assignments(6.5%) are correct.
When we add the semantic filter, the number of assignments drops to 4168,10% of the unfiltered assignments.
2607 of these (62.5%) are correct, a twelve-fold improvementover the unfiltered assignments.By Right Assignments, we mean: cases in which the system assigns a verb to a given Levinclass, when that verb appears in that class in Levin's book.
By Wrong Assignments, we mean:cases in which the system assigns a verb to a given Levin class, when that verb does not appear inthat class in Levin's book.It is important o point out that even though the semantic filter is based on words in Levin,it still sometimes categorized the Levin verb incorrectly.
Since the filter is based on synonyms ofLevin verbs, in some cases, a synonym of a verb from some other class will appear in the set thatdoes not belong there.
In this case, there are 1561 assignments known to be wrong, out of a totalof 4168 assignments.
For example, the verb scatter is a synonym of break in WordNet.
Becausethe verb break occurs in each of these classes, the semantic filter based on synonyms assigns catterto classes 10.6 (Cheat Verbs), 23.2 (Split Verbs), 40.8.3 (Hurt Verbs), 45.1 (Break Verbs), 48.1.1(Appear Verbs).
But the correct class for scatter is 9.7 (Spray/Load Verbs).
This illustrates thedifficulty of using an approach that does not account for multiple word senses.
We will address thispoint further in section 3.Setting aside the polysemy problem, we see that this semantic filter is very useful for reducingthe number of incorrect assignments.4 Per fo rmance  on Nove l  WordsWe now examine how well it performs on unknown words by constructing a semantic filter basedon three different proportions of the original 2813 Levin verbs: (a) 50%, (b) 70%, and (c) 90%,chosen randomly.
4 We then checked whether the "unknown" verbs (those not used to  construct4We chose randomly selected subsets: First we selected a random 90% of the Levin verbs, then we chose 77.7% ofthose to give 70% of the Levin verbs.
In turn, 71.4% of those give the verbs for the 50% study.45Semantic-Filter Assignments to Levin ClassesLevin50%70%90%100%Original Number of 6Assignments Total \[Wrongknown 11282\[novel 1325known 1179812628novel 809 663known 1234113632novel 266 271all known \[2607\[ 4168 \[GuessesI Right1752 I 470 I 1282841 429 412I 8301 1798360 303\[ 1291 I 2341158 1131561\] 2607Ratios IPrecision I Recall73.2% I 100.0% I49.0% 31.1%68.4%\] 100.0%\[45.7% 37.5%64.5% I 100.0% I41.7% 42.5%62.5% I 100.0%\[Original Syntactic-Filter Assignments to Levin ClassesLevin Original I Number of Assignments RatiosAssignments I Total I Wrong I Right Precision IRecovery100% Known \ ]2607\[40248\[  37641\[ 2607 6.5%\[ 100%Table 2: Undisambiguated Synonymsthe semantic filter) were assigned to their correct classes.Table 2 summarizes the recall and precision results for semantic filtering on these three differentproportions of Levin verbs.
Consider the rows that show the behavior of the experiment which uses50% of Levin's verbs, and tries to guess the remaining verbs using synonymy.
Recall that thereare 2607 verbs all together.
In this case, 1282 verbs were chosen at random to use in constructingthe filter.
We call these the "known" verbs.
This leaves 1325 for use in evaluating the semanticfilter--we call these the "novel" verbs.
For the 1282 known verbs, the filter made 1752 assignmentsto semantic lasses.
There were 470 wrong assignments and 1282 right ones, giving a precision rateof 73.2% and recall rate of 100.0% .5 The Effect of Disambiguat ionAs mentioned previously, the problem with the semantic filter we have defined is that it is notsensitive to multiple word senses of the particular verbs in the semantic lasses.
For example, thereare 23 senses of the verb break in WordNet.
This includes senses which correspond to the Changeof State verbs, such as Sense 9, "break, bust, cause to break", the synonyms of which are destroy,ruin, bust up, wreck, wrack.
But it also includes irrelevant senses, such as Sense 7, "break dance",the synonyms of which are dance, do a dance, perform a dance.
Clearly, the semantic filter wouldbehave better if we used word senses in creating the fields.
As an attempt o address the polysemyproblem, we conducted an exploratory study in which the verbs in Levin's semantic lasses weredisambiguated by hand: each verb received as many WordNet senses as were applicable.The performance of the various filters is shown in Table 3.
To see the effect of disambiguation,compare the difference between undisambiguated and disambiguated synonyms.
Precision hasincreased from 62.5% to 85.3%.
For novel verbs, in the experiment which uses 50% of the verbs and46Undisambiguated SynonymsKnown NovelRecall Precision Recall Precision%Levin100%90%70%5O%100.0% 62.5%100.0% 64.5%100.0% 68.4%100.0% 73.2%0.0% 0.0%42.5% 41.7%37.5% 45.7%31.1% 49.0%Disambiguated SynonymsKnown NovelRecall Precision Recall Precision%Levin100%9o%70%5o%100.0% 85.3%100.0% 86.2%100.0% 88.3%100.0% 91.7%0.0% 0.0%29.3% 63.9%26.1% 68.5%21.6% 70.8%Disambiguated Hyponyms of Hypernyms% KnownLevin Recall Precision100% 100.0% 37.7%9O% 100.0% 39.O%70% 100.0% 41.5%50% 100.0% 45.8%NovelRecall Precision0.0% 0.0%68.8% 29.5%63.0% 31.1%58.6% 34.6%Union of Disambiguated Synonymswith Hyponyms of Hypernyms%LevinlOO%90%70%50%Known NovelRecall Precision Recall Precision100.0% 37.6%100.0% 38.9%100.0% 41.4%100.0% 45.8%o.o% o.o%69.5% 29.7%64.4% 31.5%59.6% 34.9%Table 3: Comparison of Filters47tries to guess the rest, the precision increases from 49.0% to 70.8%.
But notice also that the recalldecreases: with disambiguation (in the 50% study), recall drops from 31.1% for undisambiguatedverbs to 21.6% for disambiguated verbs.
The reason for this is that the undisambiguated filterscontain numerous assignments which are correct but are included only accidentally.Table 3 also shows the performance of two other semantic filters based on hyponyms.
We foundthat using hyponyms of hypernyms (going up one level in abstraction, and then one level backdown) gave much better recall than plain synonymy, although the precision is lower.
We also builta filter based on the union of synonyms with hyponyms of hypernyms.
The effect of the synonymson this filter was negligible, presumably since synonyms are often hyponyms of hypernyms.
Theresults for both of these filters are shown in Table 3.6 Conclusion and Future WorkOur main result is that the semantic field substantially reduces the number of incorrect assignmentsgiven by the syntactic filter.
One of our goals is to assign new verbs, i.e., all of the verbs in LDOCE,to the semantic lasses of Levin.
Since there are 7767 verbs in LDOCE, and there are 191 semanticclasses in Levin, there are 1,483,497 potential assignments of verbs to these semantic lasses.
Thesyntactic filter reduces the number of assignments under consideration to 113,106 (7.6% of thenumber of potential assignments) while preserving 67% of the assignments we know to be correct.The various semantic filters in turn reduce the number of assignments further.
For example, thebroad semantic filter reduced the 113,106 verbs that passed through the syntactic filter down to6029 assignments, 19% of the number of assignments based on syntax and 0.4% of the potentialassignments.Our goal throughout the acquisition task is to eliminate as many incorrect assignments aspossible while preserving the correct assignments, and in this respect we are encouraged by thethe behavior of the semantic filter on "unknown" verbs.
Recall that to assess this behavior, weexcluded randomly selected Levin verbs from the semantic filter, and saw how the filter behavedon these  verbs.AcknowledgementsThe research reported herein was supported, in part, by Army Research Office contract DAAL03-91-C-0034 through Battelle Corporation, NSF NYI IRI-9357731, Alfred P. Sloan Research FellowAward BR3336, and a General Research Board Semester Award.
We would like to thank JulieDahmer, Charles Lin, and David Woodard for their help in annotating the verbs.
We would alsolike to thank Karen Kohl for permission to use her WordNet annotations for Part One of Levin'sbook as hints for WordNet senses for Part Two.ReferencesAlshawi, H. 1989.
Analysing the Dictionary Definitions.
In B. Boguraev and T. Briscoe, editor,Computational Lexicography for Natural Language Processing.
L0ngman , London, pages 153-169.Boguraev, B. and T. Briscoe.
1989.
Utilising the LDOCE Grammar Codes.
In B. Boguraev andT.
Briscoe, editor, Computational Lexicography for Natural Language Processing.
Longman,London, pages 85-116.48Brent, M. 1993.
Unsupervised Learning of Lexical Syntax.
Computational Linguistics, 19:243-262.Church, K. and P. Hanks.
1990.
Word Association Norms, Mutual Information and Lexicography.Computational Linguistics, 16:22-29.Copestake, A., T. Briscoe, P. Vossen, A. Ageno, I. Castellon, F. Ribas, G. Rigau, H. Rodr~guez,and A. Samiotou.
1995.
Acquisition of Lexical Translation Relations from MRDS.
MachineTranslation, 9.Dorr, B., J. Garman, and A. Weinberg.
1995.
From Syntactic Encodings to Thematic Roles:Building Lexical Entries for Interlingual MT.
Machine Translation, 9.FarweU, D., L. Guthrie, and Y. Wilks.
1993.
Automatically Creating Lexical Entries for ULTRA,a Multilingt~al MT System.
Machine Translation, 8(3).Fillmore, C.J.
1968.
The Case for Case.
In E. Bach and R.T. Harms, editor, Universals inLinguistic Theory.
Holt, Rinehart, and Winston, pages 1-88.Grimshaw, J.
1990.
Argument Structure.
MIT Press, Cambridge, MA.Gruber, J.S.
1965.
Studies in Lexical Relations.
Ph.D. thesis, MIT, Cambridge, MA.Guthrie, J., L. Guthrie, Y. Wilks, and H. Aidinejad.
1991.
Subject-Dependent Co-occurrence andWord Sense Disambiguation.
In Proceedings of the 29th Annual Meeting of the Association forComputational Linguistics, pages 146-152, University of California, Berkeley, CA.Hearst, M. 1991.
Noun Homograph Disambiguation Using Local Context in Large Text Corpora.In Using Corpora, University of Waterloo, Waterloo, Ontario.Jackendoff, R. 1983.
Semantics and Cognition.
MIT Press, Cambridge, MA.Jackendoff, R. 1990.
Semantic Structures.
MIT Press, Cambridge, MA.Klavans, J.L.
and E. Tzoukermann.
1996.
Dictionaries and Corpora: Combining Corpus andMachine-readable Dictionary Data for Building Bilingual Lexicons.
Machine Translation, 10.Levin, B.
1993.
English Verb Classes and Alternations: A Preliminary Investigation.
Chicago, IL.Lewis, David Dolan.
1992.
Representation a d Learning in Information Retrieval.
Ph.D. thesis,University of Massachusetts, Amherst.Lonsdale, D., T. Mitamura, and E. Nyberg.
1996.
Acquisition of Large Lexicons for PracticalKnowledge-Based MT.
Machine Translation, 9.Miller, G. 1985.
WORDNET: A Dictionary Browser.
In Proceedings of the First InternationalConference on Information in Data, University of Waterloo Centre for the New OED, Waterloo,Ontario.Neff, M. and M. McCord.
1990.
Acquiring Lexical Data from Machine-Readable Dictionary Re-sources for Machine Translation.
In Third International Conference on Theoretical and Method-ological Issues in Machine Translation of Natural Languages (TMI-90), Austin, Texas.Pinker, S. 1989.
Learnability and Cognition: The Acquisition of Argument Structure.
MIT Press,Cambridge, MA.49Procter, P. 1978.
Longman Dictionary of Contemporary English.
Longman, London.Sanfilippo, A. and V. Poznanski.
1992.
The Acquisition of Lexical Knowledge from CombinedMachine-Readable Dictionary Resources.
In Proceedings of the Applied Natural Language Pro-cessing Conference, pages 80-87, Trento, Italy.Walker, D. and R. Amsler.
1986.
The Use of Machine-readable Dictionaries in SublanguageAnalysis.
In R. Grishman and R. Kittredge, editors, Analyzing Language in Restricted Domains.Lawrence Erlbaum Associates, Hillsdale, New Jersey, pages 69-83.Wilks, Y., D. Fass, C.M.
Guo, J.E.
McDonald, and T. Plate.
1990.
Providing Machine TractableDictionary Tools.
Machine Translation, 5(2):99-154.Wilks, Y., D. Fass, C.M.
Guo, J.E.
McDonald, T. Plate, and B.M.
Slator.
1989.
A TractableMachine Dictionary as a Resource for Computational Semantics.
In B. Boguraev and T. Briscoe,editor, Computational Lexicography .for Natural Language Processing.
Longman, London, pages85-116.Wu, D. and X. Xia.
1995.
Large-Scale Automatic Extraction of an English-Chinese TranslationLexicon.
Machine Translation, 9.Yarowsky, D. 1992.
Word-Sense Disambiguation: Using Statistical Models of Roget's CategoriesTrained on Large Corpora.
In Proceedings of the Fourteenth International Conference on Com-putational Linguistics, pages 454-460, Nantes, France.50
