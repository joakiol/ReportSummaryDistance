Proceedings of the 2th Workshop of Natural Language Processing for Improving Textual Accessibility (NLP4ITA), pages 11?19,Atlanta, Georgia, 14 June 2013. c?2013 Association for Computational LinguisticsOpen Book: a tool for helping ASD users?
semantic comprehensionEduard BarbuUniversity of Jae?nParaje de Las LagunillasJae?n, 23071, Spainebarbu@ujaen.esMaria Teresa Mart?
?n-ValdiviaUniversity of Jae?nParaje de Las LagunillasJae?n, 23071, Spainmaite@ujaen.esLuis Alfonso Uren?a-Lo?pezUniversity of Jae?nParaje de Las LagunillasJae?n, 23071, Spainlaurena@ujaen.esAbstractPersons affected by Autism Spectrum Dis-orders (ASD) present impairments in so-cial interaction.
A significant percentile ofthem have inadequate reading comprehensionskills.
In the ongoing FIRST project we builda multilingual tool called Open Book thathelps the ASD people to better understand thetexts.
The tool applies a series of automatictransformations to user documents to identifyand remove the reading obstacles to compre-hension.
We focus on three semantic compo-nents: an Image component that retrieves im-ages for the concepts in the text, an idiom de-tection component and a topic model compo-nent.
Moreover, we present the personaliza-tion component that adapts the system outputto user preferences.1 IntroductionAutism Spectrum Disorders are widespread and af-fect every 6 people in 10000 according to AutismEurope site1.
The disorder is chiefly characterizedby impairments in social interaction and by repet-itive and stereotyped behaviour (Attwood, 2007).People affected by ASD are not able to communi-cate properly because they lack an adequate theoryof mind (Baron-Cohen, 2001).
Therefore, they arenot able to infer the other persons?
mental states:beliefs, emotions or desires.
This lack of empathyprevents the people with ASD to have a fulfilled so-cial life.
Their inability to understand others leadsto the incapacity to communicate their wishes anddesires and to social marginalization.1http://www.autismeurope.org/The FIRST project seeks to make a small steptowards integration of ASD people in the informa-tion society by addressing their reading comprehen-sion ability.
It is well known that many of the ASDpeople have a wide range of language difficulties.Psychological studies showed that they have prob-lems understanding less common words (Gillispie,2008), have difficulty comprehending polysemouswords (Fossett and Mirenda, 2006) and have trou-bles dealing with figurative language (Douglas et al2011).
The absence of good comprehension skillsimpedes the ASD students to participate in curricu-lum activities or to properly interact with their col-leagues in chats or blogs.
To enhance the readingcomprehension of ASD people we are developing asoftware tool.
It is built by partners in Academia andIndustry in close collaboration with teams of psy-chologists and clinicians.
It operates in a multilin-gual setting and is able to process texts in English,Spanish and Bulgarian languages.
Based on litera-ture research and on a series of studies performedin the United Kingdom, Spain and Bulgaria with avariety of autistic patients ranging from children toadults the psychologists identified a series of obsta-cles in reading comprehensions that the tool shouldremove.
From a linguistic point of view they canbe classified in syntactic obstacles (difficulty in pro-cessing relative clauses, for example) and semanticobstacles (difficulty in understanding rare or special-ized terms or in comprehension of idioms, for exam-ple).
The tool applies a series of automatic transfor-mations to user documents to identify and removethe reading obstacles to comprehension.
It also as-sists the carers , persons that assist the ASD peoplein every day life tasks, to correct the results of auto-11matic processing and prepare the documents for theusers.
This paper will focus on three essential soft-ware components related to semantic processing: asoftware component that adds images to conceptsin the text, a software component that identifies id-iomatic expressions and a component that computesthe topics of the document.
Moreover, we presentthe personalization component that adapts the sys-tem output to user preferences.
The rest of the paperhas the following structure: the next section brieflypresents other similar tools on the market.
Section3 presents a simple procedure for identifying theobstacles ASD people have in reading comprehen-sions.
Section 4 shows the architecture of the seman-tic processing components and the personalizationcomponent.
The last section draws the conclusionsand comments on the future work.
Before present-ing the main part of the article we make a brief note:throughout the paper we will use whenever possiblethe term ?user?
instead of ASD people or patients.2 Related WorkA number of software tools were developed to sup-port the learning of ASD people.
Probably themost known one is Mind Reading2, a tool thatteaches human emotions using a library of 412 ba-sic human emotions illustrated by images and video.Other well known software is VAST-Autism3, a toolthat supports the understanding of linguistic units:words, phrase and sentences by combining spokenlanguage and images.
?Stories about me?
is an IPadapplication4 that allows early learners to composestories about themselves.
All these tools and othersfrom the same category are complementary to OpenBook.
However, they are restricted to pre-storedtexts and not able to accommodate new pieces ofinformation.
The main characteristics that sets asideour tool is its scalability and the fact that it is the onlytool that uses NLP techniques to enhance text com-prehension.
Even if the carers correct the automaticprocessing output, part of their work is automatized.2http://www.jkp.com/mindreading/index.php3http://a4cwsn.com/2011/03/vast-autism-1-core/4http://www.limitedcue.com/our-apps/3 Obstacles in text comprehensionMost of the automatic operations executed by theOpen Book tool are actually manually performed bythe carers.
They simplify the parts of the text that aredifficult to understand.
We compared the texts be-fore and after the manual simplification process andregistered the main operations.
The main simplifica-tion operations ordered by frequency performed bycarers for 25 Spanish documents belonging to dif-ferent genders: rent contracts, newspaper articles,children literature, health care advices, are the fol-lowing:1.
Synonymous (64 Operations).
A noun or an ad-jective is replaced by its less complex synonym.2.
Sentence Splitting (40 Operations).
A long sen-tence is split in shorter sentences or in a bulletlist.3.
Definition (34 Operations).
A difficult term isexplained using Wikipedia or a dictionary.4.
Near Synonymous (33 Operations).
The termis replaced by a near synonym.5.
Image (27 Operations) A concept is illustratedby an image.6.
Explanation (24 Operations).
A sentence isrewritten using different words.7.
Deletion (17 Operations).
Parts of the sentenceare removed.8.
Coreference(17 Operations).
A coreferenceresolution is performed.9.
Syntactic Operation (9 Operations).
A trans-formation on the syntactic parse trees is per-formed.10.
Figurative Language (9 Operations).
An idiomor metaphor is explained.11.
Summarization (3 Operations).
The content ofa sentence or paragraph is summarized.The most frequent operations with the exceptionof Sentence Splitting are semantic in nature: replac-ing a word with a synonym, defining the difficult12terms.
The only obstacle that cannot be tackled au-tomatically is Explanation.
The Explanation entailsinterpretation of the sentence or paragraph and can-not be reduced to simpler operations.A similar inventory has been done in English.Here the most frequent operation are Sentence Split-ting, Synonyms and Definition.
The operations aresimilar across English and Spanish but their orderingdiffers slightly.4 The Semantic SystemIn this paper we focus on three semantic compo-nents meant to augment the reading experience ofthe users.
The components enhance the meaningof documents assigning images to the representa-tive and difficult concepts, detecting and explainingthe idiomatic expressions or computing the topics towhich the documents belong.In addition to these components we present an-other component called Personalization.
Strictlyspeaking, the personalization is not related to se-mantic processing per se but, nevertheless, it hasan important role in the final system.
Its roleis to aggregate the output of all software compo-nents,including the three ones mentioned above, andadapt it according to user?s needs.All the input and output documents handled byNLP components are GATE (Cunningham et al2011) documents.
There are three reasons whyGATE documents are preferred: reusability, extensi-bility and flexibility.
A GATE document is reusablebecause there are many software components devel-oped both in academy and industry, most of themcollected in repositories by University of Sheffield,that work with this format.
A GATE document isextensible because new components can add theirannotations without modifying previous annotationsor the content of the document.
Moreover, in casethere is no dependence between the software com-ponents the annotations can be added in parallel.
Fi-nally, a GATE document is flexible because it al-lows the creation of various personalization work-flows based on the specified attributes of the anno-tations.
The GATE document format is inspired byTIPSTER architecture design5 and contains in ad-dition to the text or multimedia content annotations5http://www.itl.nist.gov/iaui/894.02/related projects/tipster/grouped in Annotation Sets and features.
The GATEformat requires that an annotation has the followingmandatory features: an id, a type and a span.
Thespan defines the starting and the ending offsets ofthe annotation in the document text.Each developed software component adds its an-notations in separate name annotation sets.
Thecomponents are distributed and exposed to the out-side world as SOAP web services.
Throughout therest of the paper we will use interchangeably theterms: component, software component and webservice.For each semantic component we discuss:?
The reasons for its development.
In general,there are two reasons for the development of acertain software component: previous studiesin the literature and studies performed by ourpsychologists and clinicians.
In this paper wewill give only motivations from previous stud-ies because the discussion of our clinicians andpsychologist studies are beyond the purpose ofthis paper.?
Its architecture.
We present both the foreseencharacteristics of the component and what wasactually achieved at this stage but we focus onthe latter.?
The annotations it added.
We discuss all thefeatures of the annotations added by each com-ponent.4.1 The Image Web ServiceIn her landmark book, ?Thinking in Pictures: MyLife with Autism?, Temple Grandin (1996), a scien-tist affected by ASD, gives an inside testimony forthe importance of pictures in the life of ASD peo-ple:?Growing up, I learned to convert abstract ideasinto pictures as a way to understand them.
I visu-alized concepts such as peace or honesty with sym-bolic images.
I thought of peace as a dove, an Indianpeace pipe, or TV or newsreel footage of the signingof a peace agreement.
Honesty was represented byan image of placing one?s hand on the Bible in court.A news report describing a person returning a walletwith all the money in it provided a picture of honestbehavior.
?13Grandin suggests that not only the ASD peopleneed images to understand abstract concepts but thatmost of their thought process is visual.
Other studiesdocument the importance of images in ASD: Kanaand colleagues (2006) show that the ASD people usemental imagery even for comprehension of low im-agery sentences.
In an autobiographic study Grandin(2009) narrates that she uses language to retrievepictures from the memory in a way similar to an im-age retrieval system.The image component assigns images to conceptsin the text and to concepts summarizing the meaningof the paragraphs or the meaning of the whole doc-ument.
Currently we are able to assign images tothe concepts in the text and to the topics computedfor the document.
Before retrieving the images fromthe database we need a procedure for identifyingthe difficult concepts.
The research literature helpswith this task, too.
It says that our users have diffi-culty understanding less common words (Lopez andLeekam, 2003) and that they need word disambigua-tion (Fossett and Mirenda, 2006).From an architectural point of view the ImageWeb Service incorporates three independent sub-components:?
Document Indexing.
The Document Index-ing sub-component indexes the document con-tent for fast access and stores all offsets of theindexing units.
The indexed textual units arewords or combinations of words (e.g., terms).?
Difficult Concepts Detection.
The difficultconcepts are words or terms (e.g.
named enti-ties) disambiguated against comprehensive re-sources: like Wordnet and Wikipedia.
Thissub-component formalizes the notion ?difficultto understand?
for the users.
It should be basedon statistical procedures for identifying rareterms as well as on heuristics for evaluating theterm complexity from a phonological point ofview.
For the time being the sub-componentsearches in the document a precompiled list ofterms.?
Image Retrieval.
This sub-component re-trieves the images corresponding to difficultconcepts from image databases or from websearching engines like Google and Bing.The Image Web Service operates in automatedmode or in on-demand mode.
In the automatedmode a document received by the Image Web Ser-vice is processed according to the working flow inFigure 1.
In the on-demand mode the user high-lights the concepts (s)he considers difficult and theweb service retrieves the corresponding image or setof images.
The difference between the two modesof operations is that in the on-demand mode the dif-ficult concept detection is performed manually.Once the GATE document is received by the sys-tem it is tokenized, POS (Part of Speech) taggedand lemmatized (if these operations were not alreadyperformed by other component) by a layer that is notpresented in Figure 1.
Subsequently, the documentcontent is indexed by Document Indexing subcom-ponent.
For the time being the terms of the doc-ument are disambiguated against Wordnet.
The Im-age Retrieval component retrieves the correspondingimages from the image database.The current version uses the ImageNet Database(Deng et al 2009) as image database.
The Ima-geNet database pairs the synsets in Princeton Word-net with images automatically retrieved from Weband cleaned with the aid of Mechanical Turk.
Be-cause the wordnets for Spanish and Bulgarian are ei-ther small or not publicly available future versions ofthe Web Service will disambiguate the terms againstWikipedia articles and retrieve the image illustratingthe article title.
All annotations are added in ?Im-ageAnnotationSet?.
An annotation contains the fol-lowing features:?
Image Disambiguation Confidence is the con-fidence of the WSD (Word Sense Disambigua-tion) algorithm in disambiguating a concept.?
Image URL represents the URL address of theretrieved image?
Image Retrieval Confidence is the confidenceof assigning an image to a disambiguated con-cept.In the on-demand mode the images are also re-trieved from Google and Bing Web Services andthe list of retrieved images is presented to the carerand/or to the users.
The carer or user selects the im-age and inserts it in the appropriate place in the doc-ument.14Figure 1: The Image Web Service.4.2 The Idiom Detection Web ServiceIn the actual linguistic discourse and lexicographicalpractice the term ?idiom?
is applied to a fuzzy cat-egory defined by prototypical examples: ?kick thebucket?, ?keep tabs on?, etc.
Because we cannotprovide definitions for idioms we venture to spec-ify three important properties that characterize them(Nunberg et al 1994) :?
Conventionality.The meaning of idioms are notcompositional.?
Inflexibility.
Idioms appear in a limited rangeof syntactic constructions.?
Figuration.
The line between idioms andother figurative language is somewhat blurredbecause other figurative constructions likemetaphors: ?take the bull by the horns?
or hy-perboles: ?not worth the paper it?s printed on?are also considered idioms.The figurative language in general and the id-ioms in particular present particular problems forour users as they are not able to grasp the meaningof these expressions (Douglas et al 2011).
To facil-itate the understanding of idiomatic expressions oursystem identifies the expressions and provide defini-tions for them.The actual Idiom Web Service finds idiomatic ex-pressions in the user submitted documents by simpletext matching.
The final version of Idiom Web Ser-vice will use a combination of trained models andhand written rules for idiom detection.
Moreover, itis also envisaged that other types of figurative lan-guage like metaphors could be detected.
At the mo-ment the detection is based on precompiled lists ofidioms and their definitions.
Because the compo-nent works by simple text matching, it is languageindependent.
Unlike the actual version of the IdiomWeb Service the final version should be both lan-guage and domain dependent.
The architecture ofthis simple component is presented in Figure 2 .Figure 2: The Idiom Web Service.The GATE input document is indexed by the doc-ument indexing component for providing fast ac-cess to its content.
For each language we compiledlist of idioms from web sources, dictionaries andWikipedia.
All idiom annotations are added in the?IdiomAnnotationSet?.
An annotation contains thefollowing features:?
Idiom Confidence represents the confidence thealgorithm assigns to a particular idiom detec-tion.?
Definition represents the definition for the ex-tracted idiom.4.3 The Topic Models Web ServiceThe mathematical details of the topics models aresomewhat harder to grasp but the main intuition be-hind is easily understood.
Consider an astrobiologydocument.
Most likely it will talk about at least threetopics: biology, computer models of life and astron-omy.
It will contain words like: cell, molecules, liferelated to the biology topic; model, computer, data,number related to computer models of life topic andstar, galaxy, universe, cluster related with astronomytopic.
The topic models are used to organize vast15collections of documents based on the themes or dis-courses that permeate the collection.
From a practi-cal point of view the topics can be viewed as clus-ters of words (those related to the three topics in theexample above are good examples) that frequentlyco-occur in the collection.
The main assumption be-hind Latent Dirichlet Allocation (LDA) (Blei et al2003), the simplest topic model technique, is thatthe documents in the collections were generated by arandom process in which the topics are drawn froma given distribution of topics and words are drawnfrom the topics themselves.
The task of LDA andother probabilistic topic models is to construct thetopic distribution and the topics (which are basicallyprobability distributions over words) starting withthe documents in the collection.The Topic Models Web Service is based on animplementation of LDA.
It assigns topics to theuser submitted documents, thus informing about thethemes traversing the documents and facilitating thebrowsing of the document repository.
The topicsthemselves perform a kind of summarization of doc-uments showing, before actual reading experience,what the document is about.The architecture of the Topic Models Web Serviceis presented in Figure 3.Figure 3: The Topic Model Web Service.Once a document is received it is first dispatchedto the Feature Extraction Module where it is POStagged and lemmatized and the relevant features areextracted.
As for training models, the features areall nouns, name entities and verbs in the document.Then the Topic Inferencer module loads the appro-priate domain model and performs the inference andassigns the new topics to the document.
There arethree domains/genders that the users of our systemare mainly interested in: News, Health Domain andLiterature.
For each of these domains we train topicmodels in each of the three languages of the project.Of course the system is easily extensible to other do-mains.
Adding a new model is simply a matter ofloading it in the system and modifying a configura-tion file.The output of the Web System is a document inthe GATE format containing the most important top-ics and the most significant words in the topics.
Thelast two parameters can be configured (by defaultthey are set to 3 and 5 respectively).
Unlike the an-notations for the previous components the annota-tion for Topic Model Web Service are not added forspan of texts in the original document.
This is be-cause the topics are not necessarily words belongingto the original document.
Strictly speaking the top-ics are attributes of the original document and there-fore they are added in the ?GateDocumentFeatures?section.
An example of an output document contain-ing the section corresponding to the document topicsis given in Figure 4.Figure 4: The GATE Document Representation of theComputed Topic Model.Currently we trained three topic models cor-responding to the three above mentioned do-mains/genres for the Spanish language:?
News.
The corpus of news contains morethan 500.000 documents downloaded from theweb pages of the main Spanish newspapers (ElMundo, El Pais, La Razon, etc.
.
.
).
The topicmodel is trained using a subset of 50.000 docu-ments and 400 topics.
The optimum number ofdocuments and topics will be determined when16the users test the component.
However, oneconstraint on the number of documents to usefor model training is the time required to per-form the inference: if the stored model is toobig then the inference time can exceed the timelimit the users expect.?
Health Domain.
The corpus contains 7168Spanish documents about general health is-sues (healthy alimentation, description of thecauses and treatments of common diseases,etc.)
downloaded from medlineplus portal.
Thetopic model is trained with all documents and100 topics.
In the future we will extend boththe corpus and the topic model.?
Literature.
The corpus contains literature intwo genders: children literature (121 Spanishtranslation of Grimm brothers stories) and 336Spanish novels.
Since for the time being thecorpus is quite small we train a topic modelwith 20 topics just for the system testing pur-poses.For the English and the Bulgarian language wehave prepared corpora for each domain but we havenot trained a topic model yet.
To create the trainingmodel all corpora should be POS tagged, lemma-tized and the name entities recognized.
The featuresfor training the topic model are all nouns, name en-tities and verbs in the corpora.4.4 PersonalizationThe role of the Personalization Web Service is toadapt the output of the system to the user?s expe-rience.
This is achieved by building both static anddynamic user profiles.
The static user profiles con-tain a number of parameters that can be manuallyset.
Unlike the static profiles, the dynamic ones con-tain a series of parameters whose values are learntautomatically.
The system registers a series of ac-tions the users or carers perform with the text.
Forexample, they can accept or reject the decisions per-formed by other software components.
Based onediting operations a dynamic user profile will bebuilt incrementally by the system.
Because at thisstage of the project the details of the dynamic pro-file are not yet fully specified we focus on the staticprofile in this section.The architecture of the Personalization compo-nent is presented in Figure 5.Figure 5: The Personalization Web Service.In addition to the web services presented in theprevious sections (The Idiom Web Service and TheImage Web Service) the Personalization Web Ser-vice receives input from Anaphora Web Service andSyntax Simplification Web Service.
The Anaphoracomponent resolves the pronominal anaphora andthe Syntax Simplification component identifies andeliminates difficult syntactic constructions.
The Per-sonalization component aggregates the input fromall web services and based on the parameters speci-fied in the static profile (the wheel in Figure 5) trans-forms the aggregate document according to the userpreferences.
The personalization parameters in thestatic profile are the following:1.
Image Disambiguation Confidence.
The imageannotation is dropped when the correspondingconcept disambiguation confidence is less thanthe threshold.2.
Image Retrieval Confidence.
The image an-notation is dropped when the assigned imageis retrieved with a confidence lower than thethreshold.3.
Idiom Confidence.
The idiom annotation isdropped when the assigned idiom confidence isless than the threshold.4.
Anaphora Confidence.
The pronominalanaphora annotations are dropped when theanaphor is solved with a confidence less thanthe threshold.5.
Anaphora Complexity.
The parameter assessthe complexity of anaphors.
If the anaphora17complexity score is less than the specifiedthreshold it drops the resolved pronominalanaphora.6.
Syntactic Complexity.
It drops all annotationsfor which the syntactic complexity is less thanthe threshold.The user can also reject the entire output of a cer-tain web service if he does not need the functionality.For example, the user can require to display or notthe images, to resolve or not the anaphora, to sim-plify the sentences or not, etc.
In case the output ofa certain web service is desired the user can spec-ify the minimum level of confidence accepted.
Anyannotation that has a level of confidence lower thanthe specified threshold will be dropped.
In additionto the parameters related to document content thestatic profile includes parameters related to graphi-cal appearance (e.g.
fonts or user themes) that arenot discussed here.5 Conclusions and further workIn this paper we presented three semantic compo-nents to aid ASD people to understand the texts.The Image Component finds, disambiguates and as-signs Images to difficult terms in the text or re-lated to the text.
It works in two modes: auto-mated or on-demand.
In the automated mode a doc-ument is automatically enriched with images.
Inthe on-demand mode the user highlights the con-cepts (s)he considers difficult and the web serviceretrieves the corresponding images.
Further devel-opment of this component will involve disambigua-tion against Wikipedia and retrieval of images fromthe corresponding articles.
The Idiom Componentfinds idioms and other figurative language expres-sions in the user documents and provides definitionsfor them.
Further versions of the component willgo beyond simple matching and will identify othercategories of figurative language.
The Topic Mod-els component helps organizing the repository col-lection by computing topics for the user documents.Moreover it also offers a summarization of the doc-ument before the actual reading experience.
Finallythe Personalization component adapts the systemoutput to the user experience.
Future versions of thecomponent will define dynamic user profiles in addi-tion to the static user profiles in the current version.Our hope is that the Open Book tool will be usefulfor other parts of populations that have difficultieswith syntactic constructions or semantic processing,too.AcknowledgmentsWe want to thank the three anonymous reviewerswhose suggestions helped improve the clarity of thispaper.
This work is partially funded by the EuropeanCommission under the Seventh (FP7 - 2007-2013)Framework Program for Research and Technologi-cal Development through the FIRST project (FP7-287607).
This publication reflects only the viewsof the authors, and the Commission cannot be heldresponsible for any use which may be made of theinformation contained therein.ReferencesTony Attwood.
2007.
The complete guide to AspergerSyndrome.
Jessica Kingsley Press.Simon Baron-Cohen.
2001.
Theory of mind and autism:a review.
Int Rev Ment Retard, 23:169?184.David M. Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent dirichlet alcation.
J. Mach.
Learn.Res., 3:993?1022, March.Hamish Cunningham, Diana Maynard, KalinaBontcheva, Valentin Tablan, Niraj Aswani, IanRoberts, Genevieve Gorrell, Adam Funk, An-gus Roberts, Danica Damljanovic, Thomas Heitz,Mark A. Greenwood, Horacio Saggion, JohannPetrak, Yaoyong Li, and Wim Peters.
2011.
TextProcessing with GATE (Version 6).Jia Deng, Wei Dong, R. Socher, Li-Jia Li, Kai Li, andLi Fei-Fei.
2009.
ImageNet: A large-scale hierarchi-cal image database.
In Computer Vision and PatternRecognition, 2009.
CVPR 2009.
IEEE Conference on,pages 248?255.
IEEE, June.K.H.
Douglas, K.M.
Ayres, J. Langone, and V.B.
Bram-lett.
2011.
The effectiveness of electronic text andpictorial graphic organizers to improve comprehensionrelated to functional skills.
Journal of Special Educa-tion Technology, 26(1):43?57.Brenda Fossett and Pat Mirenda.
2006.
Sight wordreading in children with developmental disabilities:A comparison of paired associate and picture-to-textmatching instruction.
Research in Developmental Dis-abilities, 27(4):411?429.William Matthew Gillispie.
2008.
Semantic Process-ing in Children with Reading Comprehension Deficits.Ph.D.
thesis, University of Kansas.18Temple Grandin.
1996.
Thinking In Pictures: and OtherReports from My Life with Autism.
Vintage, October.Temple Grandin.
2009.
How does visual thinking workin the mind of a person with autism?
a personal ac-count.
Philosophical Transactions of the Royal So-ciety B: Biological Sciences, 364(1522):1437?1442,May.Rajesh K. Kana, Timothy A. Keller, Vladimir L.Cherkassky, Nancy J. Minshew, and Marcel AdamJust.
2006.
Sentence comprehension in autism:Thinking in pictures with decreased functional con-nectivity.B.
Lopez and S. R. Leekam.
2003.
Do children withautism fail to process information in context ?
Journalof child psychology and psychiatry., 44(2):285?300,February.Geoffrey Nunberg, Ivan Sag, and Thomas Wasow.
1994.Idioms.
Language.19
