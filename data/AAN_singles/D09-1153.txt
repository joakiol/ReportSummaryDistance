Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1475?1483,Singapore, 6-7 August 2009.c?2009 ACL and AFNLPChinese Semantic Role Labeling with Shallow ParsingWeiwei Sun and Zhifang Sui and Meng Wang and Xin WangInstitute of Computational LinguisticsPeking UniversityKey Laboratory of Computational LinguisticsMinistry of Education, Chinaweiwsun@gmail.com;{szf,wm}@pku.edu.cn;xinwang.cpku@gmail.com;AbstractMost existing systems for Chinese Seman-tic Role Labeling (SRL) make use of fullsyntactic parses.
In this paper, we evalu-ate SRL methods that take partial parses asinputs.
We first extend the study on Chi-nese shallow parsing presented in (Chenet al, 2006) by raising a set of addi-tional features.
On the basis of our shal-low parser, we implement SRL systemswhich cast SRL as the classification ofsyntactic chunks with IOB2 representationfor semantic roles (i.e.
semantic chunks).Two labeling strategies are presented: 1)directly tagging semantic chunks in one-stage, and 2) identifying argument bound-aries as a chunking task and labeling theirsemantic types as a classification task.
Forboth methods, we present encouraging re-sults, achieving significant improvementsover the best reported SRL performancein the literature.
Additionally, we putforward a rule-based algorithm to auto-matically acquire Chinese verb formation,which is empirically shown to enhanceSRL.1 IntroductionIn the last few years, there has been an increas-ing interest in Semantic Role Labeling (SRL) onseveral languages, which consists of recognizingarguments involved by predicates of a given sen-tence and labeling their semantic types.
Nearlyall previous Chinese SRL research took full syn-tactic parsing as a necessary pre-processing step,such as (Sun and Jurafsky, 2004; Xue, 2008; Dingand Chang, 2008).
Many features are extracted toencode the complex syntactic information.
In En-glish SRL research, there have been some attemptsat relaxing the necessity of using full syntacticparses; better understanding of SRL with shallowparsing is achieved by CoNLL-2004 shared task(Carreras and M`arquez, 2004).
However, it is stillunknown how these methods perform on other lan-guages, such as Chinese.To date, the best SRL performance reported onthe Chinese Proposition Bank (CPB) correspondsto a F-measure is 92.0, when using the hand-crafted parse trees from Chinese Penn Treebank(CTB).
This performance drops to 71.9 when areal parser is used instead1(Xue, 2008).
Com-paratively, the best English SRL results reporteddrops from 91.2 (Pradhan et al, 2008) to 80.56(Surdeanu et al, 2007).
These results suggest thatas still in its infancy stage, Chinese full parsingacts as a central bottleneck that severely limits ourability to solve Chinese SRL.
On the contrary, Chi-nese shallow parsing has gained a promising re-sult (Chen et al, 2006); hence it is an alternativechoice for Chinese SRL.This paper addresses the Chinese SRL problemon the basis of shallow syntactic information atthe level of phrase chunks.
We first extend thestudy on Chinese chunking presented in (Chen etal., 2006) by raising a set of additional features.The new set of features yield improvement overthe strong chunking system described in (Chen etal., 2006).
On the basis of our shallow parser, weimplement lightweight systems which solve SRLas a sequence labeling problem.
This is accom-plished by casting SRL as the classification of syn-tactic chunks (e.g.
NP-chunk) into one of semanticlabels with IOB2 representation (?).
With respectto the labeling strategy, we distinguish two differ-ent approaches.
The first one directly recognizessemantic roles by an IOB-type sequence tagging.The second approach divides the problem into twoindependent subtasks: 1) Argument Identification(AI) and 2) Semantic Role Classification (SRC).1This F-measure is evaluated on the basis of hand-craftedword segmentation and POS tagging.1475A Chinese word consists of one or more char-acters, and each character, in most cases, is a mor-pheme.
The problem of how the words are con-structed from morphemes, known as word for-mation, is very important for a majority of Chi-nese language processing tasks.
To capture Chi-nese verb formation information, we introduce arule-based algorithm with a number of heuristics.Experimental results indicate that word formationfeatures can help both shallow parsing and SRL.We present encouraging SRL results on CPB2.The best F-measure performance (74.12) withgold segmentation and POS tagging can beachieved by the first method.
This result yieldsignificant improvement over the best reportedSRL performance (71.9) in the literature (Xue,2008).
The best recall performance (71.50) can beachieved by the second method.
This result is alsomuch higher than the best reported recall (65.6) in(Xue, 2008).2 Related WorkPrevious work on Chinese SRL mainly focused onhow to implement SRL methods which are suc-cessful on English, such as (Sun and Jurafsky,2004; Xue and Palmer, 2005; Xue, 2008; Dingand Chang, 2008).
Sun and Jurafsky (2004) didthe preliminary work on Chinese SRL withoutany large semantically annotated corpus of Chi-nese.
Their experiments were evaluated only onten specified verbs with a small collection of Chi-nese sentences.
This work made the first attempton Chinese SRL and produced promising results.After the CPB was built, (Xue and Palmer, 2005)and (Xue, 2008) have produced more completeand systematic research on Chinese SRL.
Dingand Chang (2008) divided SRC into two sub-tasksin sequence.
Under the hierarchical architecture,each argument should first be determined whetherit is a core argument or an adjunct, and then beclassified into fine-grained categories.
Chen etal.
(2008) introduced an application of transduc-tive SVM in Chinese SRL.
Because their experi-ments took hand-crafted syntactic trees as input,how transductive SVMs perform in Chinese SRLin realistic situations is still unknown.Most existing systems for automatic ChineseSRL make use of a full syntactic parse of the sen-tence in order to define argument boundaries and2Our system is available athttp://code.google.com/p/csrler/to extract relevant information for training clas-sifiers to disambiguate between role labels.
Onthe contrary, in English SRL research, there havebeen some attempts at relaxing the necessity of us-ing syntactic information derived from full parsetrees.
For example, Hacioglu and Ward (2003)considered SRL as a chunking task; Pradhan etal.
(2005) introduced a new procedure to incor-porate SRL results predicted respectively on fulland shallow syntactic parses.
Previous work onEnglish suggests that even good labeling perfor-mance has been achieved by full parse based SRLsystems, partial parse based SRL systems can stillenhance their performance.
Though better under-standing of SRL with shallow parsing on Englishis achieved by CoNLL-2004 shared task (Carrerasand M`arquez, 2004), little is known about howthese SRL methods perform on Chinese.3 Chinese Shallow ParsingThere have been some research on Chinese shal-low parsing, and a variety of chunk defini-tions have been proposed.
However, most ofthese studies did not provide sufficient detail.In our system, we use chunk definition pre-sented in (Chen et al, 2006), which provideda chunk extraction tool.
The tool to extractchunks from CTB was developed by modify-ing the English tool used in CoNLL-2000 sharedtask, Chunklink3, and is publicly available athttp://www.nlplab.cn/chenwl/chunking.html.
Thedefinition of syntactic chunks is illustrated in LineCH in Figure 1.
For example, ????
?/the in-surance company?, consisting of two nouns, is anoun phrase.With IOB2 representation (Ramshaw and Mar-cus, 1995), the problem of Chinese chunking canbe regarded as a sequence labeling task.
In thispaper, we first implement the chunking methoddescribed in (Chen et al, 2006) as a strong base-line.
To conveniently illustrate, we denote a wordin focus with a fixed window w?2w?1ww+1w+2,where w is current token.
The baseline featuresincludes:?
Uni-gram word/POS tag feature: w?2, w?1,w, w+1, w+2;?
Bi-gram word/POS tag feature: w?2w?1,w?1w, w w+1, w+1w+2;3http://ilk.uvt.nl/team/sabine/chunklink/chunklink 2-2-2000 for conll.pl1476WORD: ??
??
??
??
?
?
??
??
??
??
?
?POS: [P] [NT] [NN NN] [AD] [P] [NR] [NN] [VP] [NN NN]CH: [PP NP] [NP] [ADVP] [PP NP NP ] [VP] [NP]M1: B-A* I-A*4B-A0 B-AM-ADV B-A2 I-A2 I-A2 B-V B-A1M2-AI: B-A I-A B-A B-A B-A I-A I-A B-V B-AM2-SRC: AM-TMP A0 AM-ADV A2 Rel A1Until now, the insurance company has provided insurance services for the Sanxia Project.Figure 1: An example from Chinese PropBank.That means 18 features are used to represent agiven token.
For instance, the bi-gram Word fea-tures at 5th word position (???/company?)
inFigure 1 are ??
??
?, ???
??
?, ???
??,??
?
?.To improve shallow parsing, we raised an addi-tional set of features.
We will discuss these fea-tures in section 5.4 SRL with Shallow ParsingThe CPB is a project to add predicate-argumentrelations to the syntactic trees of the CTB.
Similarto English PropBank, the semantic arguments of apredicate are labeled with a contiguous sequenceof integers, in the form of AN (i.e.
ArgN ); the ad-juncts are annotated as such with the label AM (i.e.ArgM) followed by a secondary tag that representsthe semantic classification of the adjunct.
The as-signment of argument labels is illustrated in Figure1, where the predicate is the verb ??
?/provide?.For example, the noun phrase ????
?/the in-surance company?
is labeled as A0, meaning that itis the proto-Agent of ??
; the preposition phrase????
?/until now?
is labeled as AM-TMP, in-dicating a temporal component.4.1 System ArchitectureSRL is a complex task which has to be decom-posed into a number of simpler decisions and tag-ging schemes in order to be addressed by learn-ing techniques.
Regarding the labeling strategy,we can distinguish at least two different strategies.The first one consists of performing role identifi-cation directly as IOB-type sequence tagging.
Thesecond approach consists of dividing the probleminto two independent subtasks.4The semantic chunk labels here are B-AM-TMP and I-AM-TMP.
Limited to the document length, we cannot put alldetailed chunk labels in one line in Figure 1.4.1.1 One-stage StrategyIn the one-stage strategy, on the basis of syntac-tic chunks, we define semantic chunks which donot overlap nor embed using IOB2 representation.Syntactic chunks outside a chunk receive the tagO.
For syntactic chunks forming a chunk of typeA*, the first chunk receives the B-A* tag (Begin),and the remaining ones receive the tag I-A* (In-side).
Then a SRL system can work directly byusing sequence tagging techinique.
Since the se-mantic annotation in the PropBank corpus doesnot have any embedded structure, there is no lossof information in this representation.
The line M1in Figure 1 illustrates this semantic chunk defini-tion.4.1.2 Two-stage StrategyIn the two-stage architecture, we divide ChineseSRL into two subtasks: 1) semantic chunking forAI, in which the argument boundaries are pre-dicted, and 2) classification for SRC, in which thealready recognized arguments are assigned role la-bels.
In the first stage, we define semantic chunksB-A which means begin of an argument and I-Awhich means inside of an argument.
In the secondstage, we solve SRC problem as a multi-class clas-sification.
The lines M2-AI and M2-SRC in Fig-ure 1 illustrate this two-stage architecture.
For ex-ample, the noun phrase ????
?/the insurancecompany?
is proto-Agent, and thus should be la-beled as B-A in the AI chunking phase, and thenbe tagged as A0.
The phrase ?????
?/for theSanxia Project?
consists of three chunks, whichshould be labeled as B-A, I-A, and I-A respectivelyin the AI chunking phase, then these three chunksas a whole argument should be recognized as A2.4.1.3 Chunk-by-ChunkThere is also another semantic chunk definition,where the basic components of a semantic chunkare words rather than syntactic chunks.
A goodelection for this problem is chunk-by-chunk pro-1477cessing instead of word-by-word.
The motivationis twofold: 1) phrase boundaries are almost alwaysconsistent with argument boundaries; 2) chunk-by-chunk processing is computationally less ex-pensive and allows systems to explore a relativelylarger context.
This paper performs a chunk-by-chunk processing, but admitting a processing bywords within the target verb chunks.4.2 FeaturesMost of the feature templates are ?standard?,which have been used in previous SRL research.We give a brief description of ?standard?
features,but explain our new features in detail.54.2.1 Features for Semantic ChunkingIn the semantic chunking tasks, i.e.
the one-stagemethod and the first step in the two-stage method,we use the same set of features.
The featuresare extracted from three types of elements: syn-tactic chunks, target verbs, links between chunksand target verbs.
They are formed making useof words, POS tags and chunks of the sentence.Xue (2008) put forward a rough verb classifica-tion where verb classes are automatically derivedfrom the frame files, which are verb lexicon forthe CPB annotation.
This kind of verb class in-formation has been shown very useful for ChineseSRL.
Our system also includes this feature.
In ourexperiments, we represent a verb in two dimen-sions: 1) number of arguments, and 2) number offramesets.
For example, a verb may belong to theclass ?C1C2,?
which means that this verb has twoframesets, with the first frameset having one argu-ment and the second having two arguments.To conveniently illustrate, we de-note a token chunk with a fixed contextwi?1[ckwi...wh...wj]wj+1, where whis thehead word of this chunk ck.
The complete list offeatures is listed here.Extraction on Syntactic ChunksChunk type: ck.Length: the number of words in a chunk.Head word/POS tag.
The rules described in(Sun and Jurafsky, 2004) are used to extract headword.IOB chunk tag of head word: chunk tag of headword with IOB2 representation (e.g.
B-NP, I-NP).5The source code of our system also provides lots of com-ments for implementation of all features.Chunk words/POS tags context.
Chunk con-text includes one word before and one word after:wi?1and wj+1.POS tag chain: sequential containers of eachword?s POS tag: wi... wj.
For example, this fea-ture for ??????
is ?NN NN?.Position: the position of the phrase with respectto the predicate.
It has three values as before, afterand here.Extraction on Target Verbs Given a target verbwvand its context, we extract the following fea-tures.Predicate, its POS tag, and its verb class.Predicate IOB chunk tag context: the chain ofIOB2 chunk tags centered at the predicate withina window of size -2/+2.Predicate POS tag context: the POS tags ofthe words that immediately precede and follow thepredicate.Number of predicates: the number of predicatesin the sentence.Extraction on Links To capture syntactic prop-erties of links between the chunks and the verbs,we use the following features.Path: a flat path is defined as a chain of basephrases between the token and the predicate.
Atboth ends, the chain is terminated with the POStags of the predicate and the headword of the to-ken.Distance: we have two notions of distance.
Thefirst is the distance of the token from the predicateas a number of base phrases, and the second is thesame distance as the number of VP chunks.Combining Features We also combine abovefeatures as some new features.Conjunctions of position and head word, tar-get verb, and verb class, including: position wh,position wv, position whwv, position class,and position whclass.Conjunctions of position and POS tag ofhead word, target verb, and verb class, in-cluding: position whwv, position wh, andposition whclass.4.2.2 Features for SRCIn the SRC stage of the two-stage method, dif-ferent from previous work, our system only usesword-based features, i.e.
features extracted fromwords and POS tags, to represent a given argu-ment.
Experiments show that a good semantic1478role classifier can be trained by using only word-based features.
To gather all argument positioninformation predicted in AI stage, we design acoarse frame feature, which is a sequential collec-tion of arguments.
So far, we do not know thedetailed semantic type of each argument, and weuse XP as each item in the frame.
To distinguishthe argument in focus, we use a special symbolto indicate the corresponding frame item.
For in-stance, the Frame feature for argument ????
is XP+XP+XP+XP+V+!XP, where !XP meansthat it is the argument in focus.Denote 1) a given argumentwi?2wi?1[wiwi+1...wj?1wj]wj+1wj+2, and2) a given predicate wv.
The features for SRC arelisted as follows.Words/POS tags context of arguments: the con-tents and POS tags of the following words: wi,wi?1, wi?2, wi+1, wi+2, wj, wj+1, wj?1, wj?2,wj+1, wj+2; the POS tags of the following words:wi+1, wi+2, wj+1, wj+2.Token Position.Predicate, its POS, and its verb class.Coarse Frame.Combining features: conjunctions of bound-ary words, including wi?1wj+1and wi?2wj+2;conjunction of POS tags of boundary words, in-cluding wi?1wj+1and wi?2wj+2; conjunctionof token position, boundary words, and predi-cate word, including position wiwj, wiwjwv;position wiwjwv; conjunction of token posi-tion, boundary words?
POS tags, and predicateword, also including position wiwj, wiwjwv;position wiwjwv; conjunction of predicate andframe; conjunction of target verb class and frame;conjunction of boundary words?
POS tags, andpredicate word.5 Automatic Chinese Verb FormationAnalyzing5.1 Introduction to Chinese Word FormationChinese words consist of one or more charac-ters, and each character, in most cases, is a mor-pheme which is the smallest meaningful unit ofthe language.
According to the number of mor-phemes, the words can be grouped into two sets,simple words (consisting of one morpheme) andcompound words (consisting of two morphemesor more).
There are 9 kinds of word formation inChinese compound words, and table 1 shows thedetail with examples.
Note that, attributive-headand complementarity are not for Chinese verbs.Types Examplesreduplication ??(look)??
(think)affixation ??(intensify)??
(feel)subject-verb ??(hear)??
(dictate)verb-object ??
(quit smoking)??
(haircut)verb-complement ??(inform)??
(plant)verb-result ??(exceed)??
(boil)adverbial-head ??(retreat)??
(misuse)coordinate ??(cherish)??
(chase)attributive-head* ??(rumor)??
(hospital)complementarity* ??(paper)??
(horse)Table 1: Example Words with FormationThe internal structure of a word constraints itsexternal grammatical behavior, and the formationof a verb can provide very important informationfor Chinese SRL.
Take ???/exceed?
as an ex-ample, the two characters are both verbal mor-phemes, and the character ???
means ?pass?
andthe character ???
with the meaning of ?over?shows the complement of the action of ???.
Inthis word, ???
is usually collocated with an ob-ject, and hence a Patient role should comes af-ter the verb ????.
Note that, the verb ??
?,however, is unlikely to have an object.
Take ???/haircut?
as another example, the first charac-ter ???
is a verbal morpheme with the meaningof ?cut?
and the second character ???
is a nomi-nal morpheme with the meaning of ?hair?.
In thisword, ???
acts as the object of ??
?, and the word????
is unlikely to have an Patient any more inthe sentential context.5.2 Verb Formation Analyzing MethodTo automatically analyze verb formation, we in-troduce a rule-based algorithm.
Pseudo code inAlgorithm 1 illustrates our algorithm.
This algo-rithm takes three string (one or more Chinese char-acters) sets as lexicon knowledge:?
adverbial suffix set A: strings in A are usu-ally realized as the modifier in a adverbial-head type word, e.g.
?/not, ?/not,?/always,?/both,?/all.?
object head setO: strings inO are usually re-alized as the head in a verb-object type word,e.g.
?/change,?/get,?/talk,?/send.1479Algorithm 1: Verb Formation Analyzing.Data: adverbial suffix set A, object head setO, complement suffix set Cinput : word W = c1...cnand its POS Poutput: head character h, adverbial charactera, complement character c, objectcharacter obeginh = c = a = o = null;if n = 4 and c1= c3and c2= c4thenreturn Verb formation of W?= c1c3;else if n = 3 and c2= c3thenh = c1, c = c2;else if n = 2 and c1= c2thenh = c1;else if n = 1 thenh = c1;else if cn?
C and cn?1cn?
C andP=?VV?
thenh = c1, c = cn/cn?1cn;else if c1?
A thena = c1, h = c2...cn;else if c1?
O and P=?VV?
thenh = c1, o = c2...cn;end?
complement suffix set C: strings in C areusually realized as complement in a verb-complement type word: e.g.
?/out, ?/in,?/finish,?/come,?
?/not.Note that, to date there is no word formationannotation corpus, so direct evaluation of our rule-based algorithm is impossible.
This paper makestask-oriented evaluation which measures improve-ments in SRL.5.3 Using Word Formation Information toimprove Shallow ParsingThe majority of Chinese nouns are of typeattributive-head.
This means that for most nounsthe last character provides very important infor-mation indicating the head of the noun.
For ex-ample, the word formations of ??
?/peach?, ???/willow?
and ????/boxtree?
(three differentkinds of trees), are attributive-head and they havethe same head word ??/tree?.
While for verbs, themajority are of three types: verb-object, coordi-nate and adverbial-head.
For example, words ??
?/enlarge?, ??
?/make more drastic?
and ???/accelerate?
have the same head ??/add?.
Thehead morpheme is very useful in alleviating thedata sparseness in word level.
However, for anygiven word, it is very hard to accurately find thehead.
In the shallow paring experiments, we usea very simple rule to get a pseudo head character:1) extracting the last word for a noun, and 2) ex-tracting the first word for a verb.
The new featuresinclude:Pattern 1: conjunction of pseudo head of wi?1and POS tags of wi?1and wi.Pattern 2: conjunction of pseudo head of wiandPOS tags of wi?1and wi.Pattern 3: conjunction of length/POS tags ofwi?1, wi, wi+1.5.4 Using Verb Formation Information toimprove SRLWe use some new verb formation features to im-prove our SRL system.
The new features are listedas follows.
The first four are used in semanticchunking task, and all are used in SRC task.First/last characters.Word length.Conjunction of word length and first/last char-acter.Conjunction of token position and first/lastcharacter.The head string of a verb (e.g.
???
in ????
).The adverbial string of a verb (e.g.
???
in ????
).The complement string of a verb (e.g.
???
in????
).The object string of a verb (e.g.
???
in ????
).6 Results and Discussion6.1 Experimental Setting6.1.1 DataExperiments in previous work are mainly based onCPB and CTB, but the experimental data prepar-ing procedure does not seem consistent.
For ex-ample, the sum of each semantic role reported in(Ding and Chang, 2008) is extremely smaller thanthe corresponding occurrence statistics in origi-nal data files in CPB.
In this paper, we mod-ify CoNLL-2005 shared task software6to pro-cess CPB and CTB.
In our experiments, we usethe CPB 1.0 and CTB 5.0.
The data is dividedinto three parts: files from chtb 081 to chtb 899are used as training set; files from chtb 041 to6http://www.lsi.upc.edu/?srlconll/soft.html1480chtb 080 as development set; files from chtb 001to chtb 040, and chtb 900 to chtb 931 as test set.The data setting is the same as (Xue, 2008).
Theresults were evaluated for precision, recall and F-measure numbers using the srl-eval.pl script pro-vided by CoNLL-2005 shared task.6.1.2 ClassifierFor both syntactic and semantic chunking, weused TinySVM along with YamCha7(Kudo andMatsumoto, 2000; Kudo and Matsumoto, 2001).In the chunking experiments, all SVM classifierswere realized with a polynomial kernel of de-gree 2.
Pair-wise strategy is used to solve multi-class classification problem.
For the SRC ex-periments, we use a linear SVM classifier, alongwith One-Vs-All approach for multi-class classifi-cation.
SVMlin8, a fast linear SVM solvers, is usedfor supervised learning.
l2-SVM-MFN (modifiedfinite newton) method is used to solve the opti-mization problem (Keerthi and DeCoste, 2005).6.2 Shallow Parsing PerformanceP(%) R(%) F?=1Baseline 93.54 93.00 93.27Ours 93.83 93.39 93.61Table 2: Shallow parsing performanceTable 2 summarizes the overall shallow pars-ing performance on test set.
The first line showsthe performance of baseline.
Comparing the bestsystem performance 94.13 F-measure of CoNLL2000 shared task (Syntactic Chunking on English),we can see Chinese shallow parsing has reacheda comparable result, tough the comparison of nu-meric performance is not very fair, because of dif-ferent languages, different chunk definition, dif-ferent training data sizes, etc..
The second lineOurs shows the performance when new featuresare added, from which we can see the word for-mation based features can help shallow parsing.Table 3 shows the detailed performance of nounphrase (NP) and verb phrase (VP), which make upmost of phrase chunks in Chinese.
Our new fea-tures help NP more, whereas the effect of new fea-tures for VP is not significant.
That is in part be-cause most VP chunk recognition error is causedby long dependency, where word formation fea-7http://chasen.org/?taku/index.html.en8http://people.cs.uchicago.edu/?vikass/svmlin.htmlP(%) R(%) F?=1NP(Baseline) 90.84 90.05 90.44NP(Ours) 91.42 90.78 91.10VP(Baseline) 94.44 94.55 94.50VP(Ours) 94.65 94.74 94.69Table 3: Performance of NP-chunk and VP-chunktures do not work.
Take the sentences below forexample:1.
[V P??????]?
(Therefore (we)achieve victory.)2.
[ADV P??]
[V P????]
??????????
(Therefore the major changeshave not been met before.
)The contexts of the word ???/therefore?
in thetwo sentences are similar, where ????
is fol-lowed by verbal components.
In the second sen-tence, the word ???/therefore?
will be correctlyrecognized as an adverbial phrase unless classifierknows the following component is a clause.
Un-fortunately, word formation features cannot sup-ply this kind of information.6.3 SRL PerformanceP(%) R(%) A(%) F?=1(Xue, 2008) 79.5 65.6 ?
71.9M1?
79.02 69.12 ?
73.74M1+ 79.25 69.61 ?
74.12M2?/AI 80.34 75.11 ?
77.63M2+/AI 80.01 75.15 ?
77.51M2?/SRC ?
?
92.57 ?M2+wf/SRC ?
?
93.25 ?M2+/SRC ?
?
93.42 ?M2?AI+SRC 76.48 71.50 ?
73.90Table 4: Overall SRL performance of differentmethodsTable 4 lists the overall SRL performance num-bers on test set using different methods mentionedearlier; these results are based on features com-puted from gold standard segmentation and POStagging, but automatic recognized chunks, whichis parsed by our improved shallow parsing sys-tem.
For the AI and the whole SRL tasks, wereport the precision (P), recall (R) and the F?=1-measure scores, and for the SRC task we reportthe classification accuracy (A).
The first line (Xue,14812008) shows the SRL performance reported in(Xue, 2008).
To the authors?
knowledge, this re-sult is best SRL performance in the literature.
Line2 and 3 shows the performance of the one-stagesystems: 1) Line M1?
is the performance withoutword formation features; 2) Line M1+ is the per-formance when verb formation features are added.Line 4 to 8 shows the performance of the two-stagesystems: 1) Line M2?/AI and M2+/AI shows theperformance of AI phase without and within wordformation features respectively; 2) Line M2?/SRCshows the SRC performance with trivial word-based features (i.e.
frame features and verb forma-tion features are not used); 3) Line M2+wf/SRC isthe improved SRC performance when coarse verbformation features are added; 4) Line M2+/SRCis the SRC performance with all features; 5) LineM2?AI+SRC shows the performance of SRL sys-tem, which uses baseline features to identify argu-ments, and use all features to classify arguments.6.4 DiscussionThe results summarized in Table 4 indicate thataccording to the-state-of-the-art in Chinese pars-ing, SRL systems based on shallow parsing out-performs the ones based on full parsing.
Com-parison between one-stage strategy and two-stagestrategy indicates 1) that there is no significant dif-ference in the F-measure; and 2) that two-stagestrategy method can achieve higher recall whileone-stage strategy method can achieve higher pre-cision.
Both the one-stage strategy and two-stagestrategy methods yield significant improvementsover the best reported SRL performance in the lit-erature, especially in terms of recall performance.Comparison SRL performance with full parsesand partial parses indicates that both models havestrong and weak points.
The full parse basedmethod can implement high precision SRL sys-tems, while the partial parse based methods canimplement high recall SRL systems.
This is fur-ther justification for combination strategies thatcombine these independent SRL models.Generally, Table 4 shows that verb formationfeatures can enhance Chinese SRL, especially forfine-grained role classification.
The effect of wordformation in formation in both shallow parsingand SRL suggests that automatic word formationanalyzing is very important for Chinese languageprocessing.
The rule-based algorithm is just a pre-liminary study on this new topic, which requiresNum of words P (%) R (%) F?=1Length = 1 84.69% 75.48% 79.82Length = 2 82.14% 74.21% 77.97Length = 3 75.43% 63.98% 69.24Length = 4 75.71% 65.63% 70.32Length = 5 72.46% 64.38% 68.18Length = 6 72.97% 66.21% 69.43Length = 7 77.03% 67.65% 72.04Length = 8 74.39% 57.28% 64.72Length = 9 66.67% 51.16% 57.89Length = 10 68.08% 58.28% 62.80Length = 11+ 67.40% 57.71% 62.18Table 5: SRL performance with arguments of dif-ferent lengthmore research effort.Though our SRC module does not use any pars-ing information, our system can achieve 93.42%accuracy, comparing the best gold parse based re-sult 94.68% in the literature.
This result suggeststhat Chinese SRC system, even without parsing,can reach a considerable good performance.
Themain reason is that in Chinese, arguments with dif-ferent semantic types have discriminative bound-ary words, which can be extracted without pars-ing.
It is very clear that the main bottleneck forChinese SRL is to accurately identify argumentsrather than to disambiguate their detailed seman-tic types.Table 5 summarizes the labeling performancefor argument of different length.
It is not surpris-ing that arguments are more and more difficult torightly recognize as the increase of their length.But the performance decline slows up when thelength of arguments is larger than 10.
In otherwords, some of the arguments that are composedof many words can still be rightly identified.
Themain reason for this point is that these argumentsusually have clear collocation words locating at ar-gument boundaries.
Take the sentences below forexample,3.
??
[A1 .
.
.
.
.
.?]
(including ...
etc.
)the object of the verb ???/include?
has a defi-nite collocation word ??/etc.
?, and therefore thisobject is easy to be recognized as a A1.7 ConclusionIn this paper, we discuss Chinese SRL on the ba-sis of partial syntactic structure.
Our systems ad-vance the state-of-the-art in Chinese SRL.
We first1482extend the study on Chinese shallow parsing andimplement a good shallow parser.
On the ba-sis of partial parses, SRL are formulated as a se-quence labeling problem, performing IOB2 deci-sions on the syntactic chunks of the sentence.
Weexploit a wide variety of features based on words,POS tags, and partial syntax.
Additionally, wediscuss a language special problem, i.e.
Chineseword formation.
Experimental results show thatcoarse word formation information can help shal-low parsing, especially for NP-chunk recognition.A rule-based algorithm is put forward to automat-ically acquire Chinese verb formation, which isempirically shown to enhance SRL.AcknowledgmentsThis work is supported by NSFC Project60873156, 863 High Technology Project ofChina 2006AA01Z144 and the Project of Toshiba(China) R&D Center.We would like to thank Weiwei Ding for hisgood advice on this research.We would also like to thank the anonymous re-viewers for their helpful comments.ReferencesXavier Carreras and Llu?
?s M`arquez.
2004.
Introduc-tion to the conll-2004 shared task: Semantic rolelabeling.
In Hwee Tou Ng and Ellen Riloff, edi-tors, HLT-NAACL 2004 Workshop: Eighth Confer-ence on Computational Natural Language Learn-ing (CoNLL-2004), pages 89?97, Boston, Mas-sachusetts, USA, May 6 - May 7.
Association forComputational Linguistics.Wenliang Chen, Yujie Zhang, and Hitoshi Isahara.2006.
An empirical study of Chinese chunking.In Proceedings of the COLING/ACL 2006 MainConference Poster Sessions, pages 97?104, Sydney,Australia, July.
Association for Computational Lin-guistics.Yaodong Chen, Ting Wang, Huowang Chen, and Xis-han Xu.
2008.
Semantic role labeling of Chineseusing transductive svm and semantic heuristics.
InProceedings of the Third International Joint Confer-ence on Natural Language Processing: Volume-II.Weiwei Ding and Baobao Chang.
2008.
Improv-ing Chinese semantic role classification with hier-archical feature selection strategy.
In Proceedingsof the 2008 Conference on Empirical Methods inNatural Language Processing, pages 324?333, Hon-olulu, Hawaii, October.
Association for Computa-tional Linguistics.Kadri Hacioglu and Wayne Ward.
2003.
Target worddetection and semantic role chunking using supportvector machines.
In NAACL ?03: Proceedings ofthe 2003 Conference of the North American Chapterof the Association for Computational Linguistics onHuman Language Technology, pages 25?27, Morris-town, NJ, USA.
Association for Computational Lin-guistics.S.
Sathiya Keerthi and Dennis DeCoste.
2005.
A mod-ified finite newton method for fast solution of largescale linear svms.
J. Mach.
Learn.
Res., 6:341?361.Taku Kudo and Yuji Matsumoto.
2000.
Use of supportvector learning for chunk identification.
In Proceed-ings of the 2nd workshop on Learning language inlogic and the 4th conference on Computational natu-ral language learning, pages 142?144, Morristown,NJ, USA.
Association for Computational Linguis-tics.Taku Kudo and Yuji Matsumoto.
2001.
Chunkingwith support vector machines.
In NAACL ?01: Sec-ond meeting of the North American Chapter of theAssociation for Computational Linguistics on Lan-guage technologies 2001, pages 1?8, Morristown,NJ, USA.
Association for Computational Linguis-tics.Sameer Pradhan, Kadri Hacioglu, Wayne Ward,James H. Martin, and Daniel Jurafsky.
2005.
Se-mantic role chunking combining complementarysyntactic views.
In Proceedings of the Ninth Confer-ence on Computational Natural Language Learning(CoNLL-2005), pages 217?220, Ann Arbor, Michi-gan, June.
Association for Computational Linguis-tics.Sameer S. Pradhan, Wayne Ward, and James H. Mar-tin.
2008.
Towards robust semantic role labeling.Comput.
Linguist., 34(2):289?310.L.
A. Ramshaw and M. P. Marcus.
1995.
Text chunk-ing using transformation-based learning.
In Pro-ceedings of the 3rd ACL/SIGDAT Workshop on VeryLarge Corpora, Cambridge, Massachusetts, USA,pages 82?94.Honglin Sun and Daniel Jurafsky.
2004.
Shallow se-mantc parsing of Chinese.
In Daniel Marcu Su-san Dumais and Salim Roukos, editors, HLT-NAACL2004: Main Proceedings.Mihai Surdeanu, Llu?
?s M`arquez, Xavier Carreras, andPere Comas.
2007.
Combination strategies for se-mantic role labeling.
J. Artif.
Intell.
Res.
(JAIR),29:105?151.Nianwen Xue and Martha Palmer.
2005.
Automaticsemantic role labeling for Chinese verbs.
In in Pro-ceedings of the 19th International Joint Conferenceon Artificial Intelligence, page 2005.Nianwen Xue.
2008.
Labeling chinese predicateswith semantic roles.
Computational Linguistics,34(2):225?255.1483
