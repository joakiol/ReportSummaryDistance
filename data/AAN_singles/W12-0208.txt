Proceedings of the EACL 2012 Joint Workshop of LINGVIS & UNCLH, pages 49?53,Avignon, France, April 23 - 24 2012. c?2012 Association for Computational LinguisticsSimilarity Patterns in WordsGrzegorz KondrakDepartment of Computing ScienceUniversity of AlbertaEdmonton, Alberta, Canada, T6G 2E8gkondrak@ualberta.caAbstractWords are important both in historical lin-guistics and natural language processing.They are not indivisible abstract atoms;much can be gained by considering smallerunits such as morphemes, phonemes, syl-lables, and letters.
In this presentation,I attempt to sketch the similarity pat-terns among a number of diverse researchprojects in which I participated.1 IntroductionLanguages are made up of words, which con-tinuously change their form and meaning.
Lan-guages that are related contain cognates ?
re-flexes of proto-words that survive in some formin the daughter languages.
Sets of cognates reg-ularly exhibit recurrent sound correspondences.Together, cognates and recurrent sound corre-spondences provide evidence of a common originof languages.Although I consider myself more a computerscientist than a linguist, I am deeply interestedin words.
Even though many NLP algorithmstreat words as indivisible abstract atoms, I thinkthat much can be gained by considering smallerunits: morphemes, phonemes, syllables, and let-ters.
Words that are similar at the sub-word leveloften exhibit similarities on the syntactic and se-mantic level as well.
Even more important, as wemove beyond written text towards speech and pro-nunciation, the make-up of words cannot be ig-nored anymore.I commenced my NLP research by investigat-ing ways of developing computer programs forvarious stages of the language reconstruction pro-cess (Kondrak, 2002a).
From the very start, Iaimed at proposing language-independent solu-tions grounded in the current advances in NLP,bioinformatics, and computer science in general.The algorithms were evaluated on authentic lin-guistic data and compared quantitatively to pre-vious proposals.
The projects directly related tolanguage histories still form an important part ofmy research.
In Section 2, I refer to several of mypublications on the subject, while in Section 3,I focus on other NLP applications contributionsthat originate from my research on diachronic lin-guistics.2 Diachronic NLPThe comparative method is the technique appliedby linguists for reconstructing proto-languages.
Itconsists of several stages, which include the iden-tification of cognates by semantic and phoneticsimilarity, the alignment of cognates, the deter-mination of recurrent sound correspondences, andfinally the reconstruction of the proto-forms.
Theresults of later steps are used to refine the judg-ments made in earlier ones.
The comparativemethod is not an algorithm, but rather a collectionof heuristics, which involve intuitive criteria andbroad domain knowledge.
As such, it is a verytime-consuming process that has yet to be accom-plished for many language families.Since the comparative method involves detec-tion of regularities in large amounts of data, it isnatural to investigate whether it can be performedby a computer program.
In this section, I dis-cuss methods for implementing several steps ofthe comparative method that are outlined above.The ordering of projects is roughly chronologi-cal.
For an article-length summary see (Kondrak,2009).492.1 AlignmentIdentification of the corresponding segments insequences of phonemes is a necessary step inmany applications in both diachronic and syn-chronic phonology.
ALINE (Kondrak, 2000) wasoriginally developed for aligning correspondingphonemes in cognate pairs.
It combines a dy-namic programming alignment algorithm with ascoring scheme based on multi-valued phoneticfeatures.
ALINE has been shown to generatemore accurate alignments than comparable algo-rithms (Kondrak, 2003b).Bhargava and Kondrak (2009) propose a dif-ferent method of alignment, which is an adapta-tion of Profile Hidden Markov Models developedfor biological sequence analysis.
They find thatProfile HMMs work well on the tasks of multiplecognate alignment and cognate set matching.2.2 Phonetic SimilarityIn many applications, it is necessary to algorith-mically quantify the similarity exhibited by twostrings composed of symbols from a finite al-phabet.
Probably the most well-known measureof string similarity is the edit distance, which isthe number of insertions, deletions and substitu-tions required to transform one string into another.Other measures include the length of the longestcommon subsequence, and the bigram Dice coef-ficient.
Kondrak (2005b) introduces a notion of n-gram similarity and distance, and shows that editdistance and the length of the longest commonsubsequence are special cases of n-gram distanceand similarity, respectively.Another class of similarity measures are specif-ically for phonetic comparison.
The ALINE algo-rithm chooses the optimal alignment on the ba-sis of a similarity score, and therefore can also beused for computing phonetic similarity of words.Kondrak (2001) shows that it performs well on thetask of cognate identification.The above algorithms have the important ad-vantage of not requiring training data, but theycannot adapt to a specific task or language.
Re-searchers have therefore investigated adaptivemeasures that are learned from a set of trainingpairs.
Mackay and Kondrak (2005) propose a sys-tem for computing string similarity based on PairHMMs.
The parameters of the model are auto-matically learned from training data that consistsof pairs of strings that are known to be similar.Kondrak and Sherif (2006) test representativesof the two principal approaches to computingphonetic similarity on the task of identifying cog-nates among Indoeuropean languages, both in thesupervised and unsupervised context.
Their re-sults suggest that given a sufficiently large train-ing set of positive examples, the learning algo-rithms achieve higher accuracy than manually-designed metrics.Techniques such as Pair HMMs improve onthe baseline approaches by using a set of similarwords to re-weight the costs of edit operations orthe score of sequence matches.
A more flexibleapproach is to learn from both positive and nega-tive examples of word pairs.
Bergsma and Kon-drak (2007a) propose such a discriminative al-gorithm, which achieves exceptional performanceon the task of cognate identification.2.3 Recurrent Sound CorrespondencesAn important phenomenon that allows us to dis-tinguish between cognates and borrowings orchance resemblances is the regularity of soundchange.
The regularity principle states that achange in pronunciation applies to sounds in agiven phonological context across all words in thelanguage.
Regular sound changes tend to producerecurrent sound correspondences of phonemes incorresponding cognates.Although it may not be immediately appar-ent, there is a strong similarity between the taskof matching phonetic segments in a pair of cog-nate words, and the task of matching words intwo sentences that are mutual translations.
Theconsistency with which a word in one languageis translated into a word in another language ismirrored by the consistency of sound correspon-dences.
Kondrak (2002b) proposes to adapt analgorithm for inducing word alignment betweenwords in bitexts (bilingual corpora) to the taskof identifying recurrent sound correspondences inword lists.
The method is able to determine corre-spondences with high accuracy in bilingual wordlists in which less than a third the word pairs arecognates.Kondrak (2003a) extends the approach to theidentification of complex correspondences that in-volve groups of phonemes by employing an algo-rithm designed for extracting non-compositionalcompounds from bitexts.
In experimental evalu-ation against a set of correspondences manually50identified by linguists, it achieves approximately90% F-score on raw dictionary data.2.4 Semantic SimilarityOnly a fraction of all cognates can be detectedby analyzing Swadesh-type word lists, which areusually limited to at most 200 basic meanings.
Amore challenging task is identifying cognates di-rectly in bilingual dictionaries, which define themeanings of words in the form of glosses.
Themain problem is how to quantify semantic simi-larity of two words on the basis of their respectiveglosses.Kondrak (2001) proposes to compute similarityof glosses by augmenting simple string-matchingwith a syntactically-informed keyword extraction.In addition, the concepts mentioned in glossesare mapped to WordNet synsets in an attempt toaccount for various types of diachronic seman-tic change, such as generalization, specialization,and synechdoche.Kondrak (2004) presents a method of combin-ing distinct types of cognation evidence, includ-ing the phonetic and semantic similarity, as wellas simple and complex recurrent sound correspon-dences.
The method requires no manual parame-ter tuning, and performs well when tested on cog-nate identification in the Indoeuropean word listsand Algonquian dictionaries.2.5 Cognate SetsWhen data from several related languages is avail-able, it is preferable to identify cognate sets si-multaneously across all languages rather than per-form pairwise analysis.
Kondrak et al (2007) ap-ply several of the algorithms described above to aset of diverse dictionaries of languages belongingto the Totonac-Tepehua family in Mexico.
Theyshow that by combining expert linguistic knowl-edge with computational analysis, it is possible toquickly identify a large number of cognate setswithin the family, resulting in a basic comparativedictionary.
The dictionary subsequently servedas a starting point for generating lists of puta-tive cognates between the Totonacan and Mixe-Zoquean families.
The project eventually culmi-nated in a proposal for establishing a super-familydubbed Totozoquean (Brown et al, 2011).Bergsma and Kondrak (2007b) present amethod for identifying sets of cognates acrossgroups of languages using the global inferenceframework of Integer Linear Programming.
Theyshow improvements over simple clustering tech-niques that do not inherently consider the transi-tivity of cognate relations.Hauer and Kondrak (2011) present a machine-learning approach that automatically clusterswords in multilingual word lists into cognate sets.The method incorporates a number of diverseword similarity measures and features that encodethe degree of affinity between pairs of languages.2.6 Phylogenetic TreesPhylogenetic methods are used to build evolution-ary trees of languages given data that may includelexical, phonological, and morphological infor-mation.
Such data rarely admits a perfect phy-logeny.
Enright and Kondrak (2011) explore theuse of the more permissive conservative Dollophylogeny as an alternative approach that pro-duces an output tree minimizing the number ofborrowing events directly from the data.
The ap-proach which is significantly faster than the morecommonly known perfect phylogeny, is shown toproduce plausible phylogenetic trees on three dif-ferent datasets.3 NLP ApplicationsIn this section, I mention several NLP projectswhich directly benefitted from insights gained inmy research on diachronic linguistics.Statistical machine translation in its origi-nal formulation disregarded the actual forms ofwords, focusing instead exclusively on their co-occurrence patterns.
In contrast, Kondrak et al(2003) show that automatically identifying ortho-graphically similar words in bitexts can improvethe quality of word alignment, which is an impor-tant step in statistical machine translation.
Theimproved alignment leads to better translationmodels, and, consequently, translations of higherquality.Kondrak (2005a) further investigates wordalignment in bitexts, focusing on on identifyingcognates on the basis of their orthographic sim-ilarity.
He concludes that word alignment linkscan be used as a substitute for cognates for thepurpose of evaluating word similarity measures.Many hundreds of drugs have names that ei-ther look or sound so much alike that doctors,nurses and pharmacists sometimes get them con-fused, dispensing the wrong one in errors that may51injure or even kill patients.
Kondrak and Dorr(2004) apply anumber of similarity measures tothe task of identifying confusable drug names.They find that a combination of several measuresoutperforms all individual measures.Cognate lists can also assist in second-language learning, especially in vocabulary ex-pansion and reading comprehension.
On the otherhand, the learner needs to pay attention to falsefriends, which are pairs of similar-looking wordsthat have different meanings.
Inkpen et al (2005)propose a method to automatically classify pairsof words as cognates or false friends, with focuson French and English.
The results show that it ispossible to achieve very good accuracy even with-out any training data by employing orthographicmeasures of word similarity.Transliteration is the task of converting wordsfrom one writing script to another.
Transliterationmining aims at automatically constructing bilin-gual lists of names for the purpose of trainingtransliteration programs.
The task of detectingphonetically-similar words across different writ-ing scripts is quite similar to that of identifyingcognates, Sherif and Kondrak (2007) applies sev-eral methods, including ALINE, to the task of ex-tracting transliterations from an English-Arabicbitext, and show that it performs better than editdistance, but not as well as a bootstrapping ap-proach to training a memoriless stochastic trans-ducer.
Jiampojamarn et al (2009) employ ALINEfor aligning transliterations from distinct scriptsby mapping every character to a phoneme that isthe most likely to be produced by that character.They observe that even such an imprecise map-ping is sufficient for ALINE to produce high qual-ity alignments.Dwyer and Kondrak (2009) apply the ALINEalgorithm to the task of grapheme-to-phonemeconversion, which is the process of producing thecorrect phoneme sequence for a word given its or-thographic form.
They find ALINE to be an excel-lent substitute for the expectation-maximization(EM) algorithm when the quantity of the trainingdata is small.Jiampojamarn and Kondrak (2010) confirmthat ALINE is highly accurate on the task of letter-phoneme alignment.
When evaluated on a man-ually aligned lexicon, its precision was very closeto the theoretical upper bound, with the numberof incorrect links less than one in a thousand.Lastly, ALINE has also been used for the map-ping of annotations, including syllable breaksand stress marks, from the phonetic to ortho-graphic forms (Bartlett et al, 2008; Dou et al,2009).4 ConclusionThe problems involved in language reconstructionare easy to state but surprisingly hard to solve.
Assuch, they lead to the development of new meth-ods and insights that are not restricted in applica-tion to historical linguistics.
Although the goal ofdeveloping a program that performs a fully auto-matic reconstruction of a proto-language has yetto been attained, the research conducted towardsthis goal has been, and is likely to continue to in-fluence other areas of NLP.AcknowledgmentsThis paper refers to research projects that wereconducted jointly with the following colleagues:Susan Bartlett, David Beck, Shane Bergsma,Aditya Bhargava, Cecil Brown, Colin Cherry,Philip Dilts, Bonnie Dorr, Qing Dou, ElanDresher, Ken Dwyer, Jessica Enright, OanaFrunza, Bradley Hauer, Graeme Hirst, DianaInkpen, Sittichai Jiampojamarn, Kevin Knight,Wesley Mackay, Daniel Marcu, and Tarek Sherif.ReferencesSusan Bartlett, Grzegorz Kondrak, and Colin Cherry.2008.
Automatic syllabification with structuredSVMs for letter-to-phoneme conversion.
In Pro-ceedings of ACL-08: HLT, pages 568?576.Shane Bergsma and Grzegorz Kondrak.
2007a.Alignment-based discriminative string similarity.In Proceedings of ACL, pages 656?663.Shane Bergsma and Grzegorz Kondrak.
2007b.
Mul-tilingual cognate identification using integer linearprogramming.
In Proceedings of the RANLP Work-shop on Acquisition and Management of Multilin-gual Lexicons, pages 11?18.Aditya Bhargava and Grzegorz Kondrak.
2009.
Mul-tiple word alignment with Profile Hidden MarkovModels.
In Proceedings of the Student ResearchWorkshop at NAACL-HLT, pages 43?48.Cecil H. Brown, David Beck, Grzegorz Kondrak,James K. Watters, and S?ren Wichmann.
2011.
To-tozoquean.
International Journal of American Lin-guistics, 77(3):323?372, July.Qing Dou, Shane Bergsma, Sittichai Jiampojamarn,and Grzegorz Kondrak.
2009.
A ranking approach52to stress prediction for letter-to-phoneme conver-sion.
In Proceedings of ACL-IJCNLP, pages 118?126.Kenneth Dwyer and Grzegorz Kondrak.
2009.
Re-ducing the annotation effort for letter-to-phonemeconversion.
In Proceedings of ACL-IJCNLP, pages127?135.Jessica Enright and Grzegorz Kondrak.
2011.
Theapplication of chordal graphs to inferring phyloge-netic trees of languages.
In Proceedings of IJCNLP2011: 5th International Joint Conference on Natu-ral Language Processing, pages 545?552.Bradley Hauer and Grzegorz Kondrak.
2011.
Clus-tering semantically equivalent words into cognatesets in multilingual lists.
In Proceedings of IJCNLP2011: 5th International Joint Conference on Natu-ral Language Processing, pages 865?873.Diana Inkpen, Oana Frunza, and Grzegorz Kondrak.2005.
Identification of cognates and false friends infrench and english.
In Proceedings of the Interna-tional Conference on Recent Advances in NaturalLanguage Processing (RANLP 2005), pages 251?257.Sittichai Jiampojamarn and Grzegorz Kondrak.
2010.Letter-phoneme alignment: An exploration.
In Pro-ceedings of ACL, pages 780?788.Sittichai Jiampojamarn, Aditya Bhargava, Qing Dou,Kenneth Dwyer, and Grzegorz Kondrak.
2009.
Di-recTL: a language-independent approach to translit-eration.
In Named Entities Workshop: Shared Taskon Transliteration, pages 28?31.Grzegorz Kondrak and Bonnie Dorr.
2004.
Identifica-tion of confusable drug names: A new approach andevaluation methodology.
In Proceedings of COL-ING 2004: 20th International Conference on Com-putational Linguistics, pages 952?958.Grzegorz Kondrak and Tarek Sherif.
2006.
Evalu-ation of several phonetic similarity algorithms onthe task of cognate identification.
In Proceedingsof the COLING-ACL Workshop on Linguistic Dis-tances, pages 43?50.Grzegorz Kondrak, Daniel Marcu, and Kevin Knight.2003.
Cognates can improve statistical translationmodels.
In Proceedings of HLT-NAACL, pages 46?48.
Companion volume.Grzegorz Kondrak, David Beck, and Philip Dilts.2007.
Creating a comparative dictionary ofTotonac-Tepehua.
In Proceedings of the ACLWorkshop on Computing and Historical Phonology(9th Meeting of SIGMORPHON), pages 134?141.Grzegorz Kondrak.
2000.
A new algorithm for thealignment of phonetic sequences.
In Proceedingsof NAACL 2000: 1st Meeting of the North Ameri-can Chapter of the Association for ComputationalLinguistics, pages 288?295.Grzegorz Kondrak.
2001.
Identifying cognates byphonetic and semantic similarity.
In Proceedingsof NAACL 2001: 2nd Meeting of the North Amer-ican Chapter of the Association for ComputationalLinguistics, pages 103?110.Grzegorz Kondrak.
2002a.
Algorithms for Lan-guage Reconstruction.
Ph.D. thesis, University ofToronto.Grzegorz Kondrak.
2002b.
Determining recur-rent sound correspondences by inducing translationmodels.
In Proceedings of COLING 2002: 19th In-ternational Conference on Computational Linguis-tics, pages 488?494.Grzegorz Kondrak.
2003a.
Identifying complexsound correspondences in bilingual wordlists.
InProceedings of CICLing 2003: 4th InternationalConference on Computational Linguistics and In-telligent Text Processing, pages 432?443.Grzegorz Kondrak.
2003b.
Phonetic alignmentand similarity.
Computers and the Humanities,37(3):273?291.Grzegorz Kondrak.
2004.
Combining evidence incognate identification.
In Proceedings of CanadianAI 2004: 17th Conference of the Canadian Soci-ety for Computational Studies of Intelligence, pages44?59.Grzegorz Kondrak.
2005a.
Cognates and word align-ment in bitexts.
In Proceedings of MT Summit X:the Tenth Machine Translation Summit, pages 305?312.Grzegorz Kondrak.
2005b.
N-gram similarity and dis-tance.
In Proceedings of SPIRE: the 12th Interna-tional Conference on String Processing and Infor-mation Retrieval, pages 115?126.Grzegorz Kondrak.
2009.
Identification of cognatesand recurrent sound correspondences in word lists.Traitement automatique des langues et langues an-ciennes, 50(2):201?235, October.Wesley Mackay and Grzegorz Kondrak.
2005.
Com-puting word similarity and identifying cognateswith Pair Hidden Markov Models.
In Proceedingsof CoNLL-2005: 9th Conference on ComputationalNatural Language Learning, pages 40?47.Tarek Sherif and Grzegorz Kondrak.
2007.
Boot-strapping a stochastic transducer for arabic-englishtransliteration extraction.
In Proceedings of ACL2007: 45th Annual Meeting of the Association forComputational Linguistics, pages 864?871.53
