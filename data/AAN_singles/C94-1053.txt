r O,, Plmming Argumcnl;  l;iv0 l- ,xtsXiaorong Hua.ngFachbereich Inforlnatik, Uniw:rsiti\[t, des S+ul,rlandes6(i0d\].
Saarbr i icken,  (l(~rlltTi,liy, etnail: huang~3cs.uni-sb.deAbst rac tThis paper presents PI?OVF, I?,I"f a text planner forargumentative texts.
I~I~OVI'\]\]~II~ nain feature isthat it combines global hierarchical planning and llti-phmned organization of text with respect to local de-rivation relations in a complementary way.
The formersplits the task of presenting a particular pronf intosubtasks of llresenting sul)proot~.
"\['lie lati, er silnli\[al;cs\]iow the next intermediate onchision to Im l)resenl,edis chosell under the guida.nce o\[ the local \['ocils.1.
In t roduct ionThis pallor presents a, text planner for l,h,' w,rlmliz~t-tion of natural deduction (ND) st, yle proofs \[Gm,:Uq.Several similar attempi;s can be lbulld in previouswork.
I)eveloped before the era of NL genl!ral.
))li,the system EXPOUND of D. (Thesl.er \[Che76\] call I>echaracterized as an exatnl+le of direct translatio'a: Al-though a sophisticated linearizatioii is applied on theinput ND proofs, the steps are then I:ranslated loc-ally in a template driven way.
ND i>rool:s were testedas input to an early version of the MUMI~,I,I'; sys-tern of D. McDonald \[McD83\], the Irllain aim however,was to show the fl~asibility of the architecture.
Amore receitt attempt can be foilnd in 'l'lI\[Nl(li;ll.\[1'\]P93\], whMI implements sew~ral interesting but isol-ated proof presentation strategies, witliout giving ;lcomprehensive underlying model.Our computational model can therelbre I>e viewed;is the first serious attempt at a comprehensive conipu-tational model that produces adeqilate argillneill, al,iw~te?l,s froln N\]) si,yle proofs.
The inaill nilll is I,+) sh+:,vhow existing text planning techlliques Call \[)t~ adaptedfor this particular apl)iication, q'o test its feasibility,this computational model is imldelilenl,ed lit a sysl,enlcalled PROVERH.Most current NL text pialillers assiiltle thai, \[ali-guage generation is planned I>eh~vior ~tlid there-fore adopt a hiera.rchical platiliilig aplll'oach \[Iiov88,Moo89, Da192, Rei91\].
Nonetheless there!
is psycllolo-gical ,~vidence that language has an ullplaluled, si~oti-.taneous aspect ms well \[Och79\].
Based on this ol~sei'va-l, ion, researchers have exploited organizing text withrespect to some local relations.
Sibun \[Sib90\] itnl+>merited a system generating descripticms for oltiectswith a strong domain sl.ructure, such as houses, chipsalld families.
Once a discourse is st.;i,l'l,~;(I, local strllc-lures suggest the next objects awtilalfle.
\[nstead ofplanning globally, short-range sl;rategies ~tre cnlpl~tyedto ol'gallize ~t short seglrl<!lll, or' text.
l?roni a collll)ltl, a-ti~mnl point of view, a hierarchical planner elaboratesrecursively on the initial commmiicatiw~ goal mitil theIhtal sultgoals can be achieved by ++l>plyivg a prlmitiw'~operator.
A text generator based on the local organ-ization, in contrast, repeatedly chooses a part of therenmiNing t.ask and carries it out.The macroplanner of \]'IgOVER.B combines hier-arcDical planTdng with local orgaMzation in a uniformplanning framework. '
the hierarchical planning is real-ized by so-called top-dowu presentation operators thatsplit the task of presenting a particular proof intosubtasks of presenting subproofs.
While the over-all planning mechanism follows the RS'l.
'-lmsed plan-ning approach \[Moo89, Reigl\], the Idaiming operatorslilt)re cl<+sely Feselllllle the schellHl+ta ill schema-basedphtnning \[McK85, Iqtr88\].
l \]ottom-up resentationOilel'O, tOl'S ~tl'(~ (ll~vised to Sil/Itll;t|,e \[,lie tLltpl,~tllll~d RS-i>ect;, where the next intermediate cotichlsion to lmpresenLed is chosen under the gttidance of the localfc>cus tnechanisnt in a lllore SpOlttarleous way.
}'Jil:cetop-dmvn operal,ors enibody explicit coinnnnticativeliOrlilS, they are ai',wiys given a higher priority.
Onlywheil lie l;op-dOWtl pr<?selil;atioit operator is apl>licabh;,will a bot,toiil-ttp present,alien operator be chosen.This distinction betweeii plalllled alld illiplaltrledpresentation loads to a w;ry natural seglnenl;ation ofthe discourse int.o an allciilional hierarchy, since, fol..h>willg t.he theory of (.Irosz and Sidner \[CS86\], there is+l Oll+P-to-olle COl'l'esl)Oltdellce betweeli  the ititelit, iolialhierarrhy and the al;tentional hierarchy.
'\['his atl;en-t,iemal hierarchy iv used to itlltke, r@Jz'encc choices forinference ilietliods and for previously presented inter-nimiiat,e conclusions, 'l'he inference choices itl'l~ thetllailt COliCerll of the iliieroitllmner of PR, O Vl'.'l~II(see\[llua{)dlq).2.
(hmtext  o f  Our  ResearchTim text planner discussed hi this paper is the mac-roplanner of I'ROVI'H~,IJ, which translates machine-f<mml iwool's in sew~rM steps into u~ttural lallgl.lage.PI:OVEI~II adopts a rcconslr'uclive approach: Oncea l~roof in a m~u:hhie oriented forlnalistn is genel'~d;cdin the proof dewdopnwnt envh'onlnent fI--MKRP, anew proof' l, hat, m<+re resetnbles those found in mai;h-enmt,ical tex.tl)ooks is reconstructed \[lhla94a\].
The re-construcl,<~d proo\[" is ~t proof lT"ce, where proof nodesave derived from their children by applying an infer-c'nce tnel, hod (also called a justilical,ion).
Most of thesteps are justified by Lhe application of a definition329_ sgr(U, 1,'),, , U ~ ~ ~(U, 1,,, *),,u(ul, 1,,, *), Ul E U Du, ul C (;' _~z~zl)snl)gr\[r,  ' 1  " mo ; ~ _r,, - -T -~UUl , ,  E  Ds, 'gr(F' *) D,_i!1: ,,, * 1,, - -g l :  I" - - ' "   )2 -,rsolFigure 1: An Example lnlmt Proofor a theorem, the rest are justified by inference rulesof the natural deduction (ND) ealcuhls, such as the"Case" rule.
Figure 1 is an examph', of a segment ofa possible input proof, where some nodes are labeledfor convenience.The justifications "Du", "Dsubgr", "Ds", "Dg", and"Tsol" stand for the definitions of unit element, ofsubgroup, of subset, of group, and the theorem aboutsolution, respectively.The input proof tree is also augmented with anordered list of nodes, being roots of subproofs plannedin this order.
The proof in Figure 1 is associated withthe list: (\[2\], \[a\], \[4\], \[l\]).3.
The  F ramework  o f  the  Macrop lannerTl,e macroplanner of PROVERB elaborates on com-municat ive  goals, selects and orders pieces of inforrl~a-tion to fullill these goals.
The output is an ordered sc'-quenee of proof communicat ive act iuteu~ions (PCAs).PCAs can be viewed as speech acts in our domain ofapplication.P lann ing  PrameworkPROVERB combines the two above mentionedpresentation modes by encoding communicat.ionknowledge for both top-down planning and bottom-uppresentation in form of operators in a uniform plan-ning framework.
Since top-down presentation operat-ors embody e?plieit communicatiw~ norms, they aregiven a higher priority.
A botl.om-up presentation ischosen only when no top-down presentation operal,orapplies.
The overall planning framework is realizedby the fimction present .
Taking as inpul, a subproof,Present  repeatedly executes a hasic planning cycleunl,il the inlmt subproof is eouw!yed.
F, ach cycle car-ries out Olle presentation operal, or, where Present al-ways tries first to choose and apply a top-down op-erator, if impossible, a Imttom.-up opc:rator will hechosen.
~l~he function Present  is first called wil.
}l t,heentire proof as the presentation task.
The execution ofa top-down presentation operator may generate sub-tasks by calling it recursively.
The discourse producedby each call to Present  tbrms an attentioual unit(compare the subsection below).The  D iscourse  Mode l  and the A. t tent iomd Hier-archyThe discourse carried out so far is recorded in a dis-course model.
Rather than recording |he semantic oh-jeets and their properties, our discourse model consistsbasically of the part of the input proof tree which hasalready been conveyed.
The discourse model is alsosegmented into an allenl ional hierarchy, where, sub-proofs posted by a top-down presentation operatorsas subtasks constitute attentional units.
The.
follow-ing are some notions useful for the formulation of theprese,\]tation perators:?
Task is the subproof in the input proof whosepresentation is the current task.?
Local focus is the intermediate conclusion lmstpresented, while the semantic objects involved int;he local tbcus are called the focal centers.Proof  Comlnunieat ivc,  ActsP(.,'As are the primil;ive actions plammd during themacroplanning to achiew.
?
communical;ive goals.
Likespeech acts, PCAs can be defined in terms of the com-mmlicative goals they fulfill as well as tlu-qr possibleverbalizations.
Based on an analysis of proofs in math-enuttical textlmoks, each PCA has as goal a combin-ation o17 the lbllowing sllhgoals:1.
CoIweying a st.ep of the deriwttion.
'.Phe simplest\]'CA is the operator Derive.
hlstantiated as be-(Der ive  Reasons: l ag  ,5'I, EI C -- $2)Intermediate-Results  : nilDerived-Formula:  a G $2Method: def-subset)depending on the reference choices, a possibleverbalization is given as following:"lb;cause a is an eh'.ment of 51 and ,%.is a subset of S,.,, according to the detin-ition of subset, a is an elelne/Lt of S:!."2.
I.Jpdates o\[' I.he glob:d attentional structure.These I~CAs som,'t.imes also convey ~L partial planfor tim further l)resentation.
IBlfects of this groupof I'CAs include: creal, ing new attentional units,setting up partially premises and the goal of anew unit, closing t.he current unit, or l'ealloeal;ingthe attention of the reader from one attentionalunit to another.
The PCA(Begin-Cases Goal : l,'ormulaAssumptions: (A I~))creates two atteD.tional units with A and II as theassumptions, and Formula as the goal by produ-cing the verbalization:"To prow" Formula, let us consider thetwo cases by assuming A and B.
"Thirteen PCAs are currently employed in PRO-VEI?t3.
See \[Ilua94b\] for more details.330St ructure  of the  P lamf ing  OI)eratorsAlthough top-down and bottom-up presentationactivities are of a eoneel)tually dift~rent nature, thecorresponding communication knowledge is uniformlyencoded as presentat ion  oper'ators i|l a planning frame-work, similar to the plan operators in other generationsystems \[Hov88, Moo89, Da192, ILeigl\].
In general,presentation operators map an original presentationtask into a seqnenee of subtasks and finally into a se-quence of PCAs.
All of thenr haw~ the following fourslots:?
P ro@ a proof schema, which characterizes the.syntactical structure of a proof segment for wllichthis operator is designed.
It plays 1;t1(.'
role of the.goal slot in the traditional l)lanning franrework.?
Appl icabi l i ty  Condi t ion:  a pre(\[icate..?
Acts: a procedure which essentially carries outit seqtlellce of preselfl;atioli acts.
They are eitherprimitive PCAs, or are recursive calls to the pro-cedure Present  for subproofs.?
Features: a list of features which helps to selectthe best of a set of aI)l)licable operators.4.
Top-Down P lann ing' I 'h is  sect ion  e laborM;es  oil the co ln ln t ln icat ive  normsconcerning how a proof to he presented can Im splitinto sitbproofs, as well ~us how the hierarchically-structured subprooN can lie maplied onto some lineearorder for presentation.
In contrast with operators em-ployed in RST-b~se(l plmuters that split goals accord-ing to the rhetorical structures, our operators encodestandard schemata for presenting proofs, which (:oil-lain subgoals.
The top-down presentation operatorsare roughly divided into two cate.gories:?
schemata-based operators encoding complexschemata for the presentation of proofs of a sl)e-cilie pattern (twelve o1' tlwm are currently i,ltcg-rated in P IgOVERI I ) ,?
general operators embodying general pr,~senta-lion norms, concerning splitting proofs and or-dering subgoals.F t- \[,' (1 i- (7i~-rv -o  ~ ",~,,,~:r Lcasl.
:Figure 2: A Schmmt Involving CasesLet us first look at an operator devised tbr proof seg-ments containing eases.
'l'he.
eorreslmnding schenra ofsuch a proof tree is shown in Figure 2.
Under twocircumstances a writer lnay recognize that 11(; is con-fronted with a proof segment containing cases.
First,when the snbproof that has the structure of l"igure.
2 isthe current presentation task, tested by (task ?L1) 1.Second, when the disjunction I,' V G has just beenpresented in the bottom-up mode, tested by (local-\['octls "?L4).
Under both circumstances, a teammate-alien norm motiwttes the writer to First present thepart leading to 1,' V G (in the second case this subgoalhas ah'eady been aehiew3d), and then to proceed withthe two cases.
It enforces also that certain PCAs beused to mediat.e between 1)arts of l)roofs.
This proced-ure is exactly captured by the presentation operatorbelow.Case- Impl ic i t?
Proof: as given in lqgure 2?
Applicability Condition: ((task ?LI) V(local-l~,,',s '?1;4)) A (,,oi,-conveyed (?L., 7l~-,))?
Acts:1. if ?L4 has not been conveyed, then l)resenl;'7174 (subgoal 1)2. a PCA with the verbalization: "First, let usconside.r the first east., by assuming F."3. preselfl; ?L2 (subgoal 2)4. a PCA wit, h the vm'balization: "Next, weconsider the se.cond case by assuming (;.
"5, presel,t '?La (subgoal 3)(i. mark "71)1 as conw.ye(l?
lL, atures: (top-down compulsory implicit)q'he f l~atm'e  values can be divided into two groups:those characterizing the style, of the 1;ext this oper-ator produces, and those concerning other planningaspects.
"Implicit" is a stylistie feature value, indic-ating that the splitting of the p,'oof into the three sub-goals is not made explicit.
In its explicit dnal Case-Expl ic i t  a PCA is added to the beginning of the Actsslot., wlfich l)ro(hiee.s tim verbalization:"To prow~ Q, let us first prove F V G, andconsider the two eases sel)arately.
"The feature, wdue "COmlmlsory" indicates thai.
if theapplicallility condition is satisfied, and the style of theOl)(~r;tl,{:,r (:Oll\['orlns to the ghd)al style the texl.
planneris (:olrlruitted to, this operator should be chosen.
Twoweaker vahms also retlect the speci\[icii,y of plan oper-ators: "speci\[ic" and "general".
(h,neral l)resental.ion operators perform a simpletask according to some general text organization prin-ciples.
They either?
enforce a linearization on subprool~ to be presen-ted, or?
split the task of the presentation of a proof withordered snhproofs into sul)t.asks.t Labels stand fro" the ?m'respondhlg nodes331The first ordering operator operationalizes a gen-eral ordering strategy called minimal oad principle.This principle predicates that a writer usually presentsshorter branches beibre longer ones.
The argument ofLevelt is rather simple: When one branch is chosen tobe described first, the writer has to have the choicenode flagged in his memory for return.
If he followsthe shorter branch first., the duratiml of the load willbe shorter.
The eonerete operator is omitted.Note that, the subproofs being ordered are sub-proofs conceptually planned while the correspm,dingproof is constructed.
There are two other orderingoperators based on general ordering principles: thelocal focus principle and the proof time order principle\[IIua94b\].The invocation of an ordering operator is alwaysfollowed by the invocation of a splitting operator,which actually posts subgoals by calling the functionPresent  with the ordered goals subsequently.5.
Bot tom-up  Presentat ionThe bottom-up resentation process simulates the un-planned part of proof presentation.
Instead of split-ting presentation goals into subgoals according tostandard schernata, it follows the local derivation re-lation to find a next proof node or subproof to bepresented, in this sense, it is similar to the local organ-ization techniques used in \[Sib90\].
When no top-downpresentation operator applies, I~ROVI'2RB chooses abottom-up operator.The  Local  FocusThe node to be presented next is suggested by themechanism of local focus.
Although logically any proofnode having the local focus as a child could be choserlfor the next step, usually the one with the greatest se-mantic overlapping with the focol cenier's is preferred.As mentioned above, focal centers are senmntic ob-jects mentioned in the proof node which is the localfocus.
This is based on the observation that if onehas proved a property about some semantic obje.cts,one tends to continue to talk about these particularobjects before turning to new ohjects.
Let ns examinethe situation when the proof below is awn.iting I~,'ese,,L-ation.j~\] : or,, ,  b)' \[a\] .7-0(., b) A :e(I,, .
)Assume that node \[1\] is the local focus, the set;{a, b} are the focal centers, \[3\] is a previously presen-ted node and node \[5\] is the current task.
\[2\] is chosenas the next node to be presented, since it, does not(re)introduce any new semantic object and it.s overlapwith the focal centers ({a, b}) is larger than those of\[4\] ({~}).The Bot tom-Up Presentat io l l  OperatorsUnder different circumstances the deriwH, ion of thenext-node is also presented in different ways, Thecorresponding presentation knowledge is encoded asbottom-np presentation operators.
The one most fre-quent.ly used presents one.
step of derivation:Derlve.-Bot tom-Up?
Proof: ?Nodel~...l?Node,~?M?
Noden+ l?
Applicability Condition: ?Noden+ 1 is suggestedby the focus mechar, ism as the next node, and?No&a,..., ?Node,, are conveyed.?
Acts: a PCA that conveys the fact that ?Node,+1is derived from the premises '?Nodq,..., ?Nodenby applying ?M.?
Features: (bottom-up general explicit detailed)If the conclusion ?Node,+l, the premises and themethod ?M are instantiated to a G S1, (a G ,92,S~ G S.,), def s'ubse.t respectively, the following w.~rbal-ization can be produced:"Since a is an element of S~, and $1 is asubset of S.,, a is an element of oe2 accordingto the definition of subset.
"A lrivial suhproof may be presented as a single de-riwttion by ornitting the intermediate nodes.
'this nezls.ubproof is also suggested by the local focus.
This issinmlated by a bottom-up operator called S impl i fy-Bot tom-Up.
Currently seven bottom-up operatorsare it,l.egrated in PROVERB.6.
Verba l i za t ion  o f  PCAsMacroplanning produces a sequence of PCAs.
Ourmieroplanner is restricted to the treatment of the re f-eremite choices for the inference methods and for thepreviously presented intermediate conclusions.
Whilethe former depelMs on static salience relating l,o thedomain kuowledge, the latter is similar to subsequentrefi.
'rences, and is therelbre sensitive to the context,in particular to it:s segmentation i to attenl,ional hier-archy.
Dne to space restrictions, we only show the fol-lowing piece of a prcverbal message as an example, he-i,lg a PCA enriched with reflq'ence dmices for reasonsaml nn!l.hod by the microplanner \[IluaDdh, IIua94b\].
(Derive Reasons: (((ELE a U) explicit)((SUBSET U F) omit))Conclusion: (ELE a F)Method: (Dof-Subsot omit))Our surface generator TAG-GI'~N \[Ki194\] producesthe ul, terance:"Since a is an element of U, a is an elementof F."Notice, only the l'\[~ason labeled as "explicit" is verb-alized.Finally, to demonstrate the type of proofs currentlygenerated by PI~OVER.B, below is the complete out-l)ut \['or a proof constructed by f2-MKIIP:Thc, orem: Let /'~ be a grou I) and U a subgroup of F,if I and Iv are unit elements of F and U respectively,then 1 = 1?
:.332Proof :Let F be a group, U be a subgroup of /,', 1 he aunit element of F and lu  be a unit element of U.According to the definition of unit eleme,lt, Iu rE U.Therefore there is an X,  X C U.
Now suppose that~tl is such an X.
According to the definition of ilnit.
\[Che711\]element, ut * 1u = ut.
Since U is a subgrmtp of t:',U C F. "lqterefore 1u E F. Similarly ul G F, since \[\[);,19'-'\]ul G U.
Since F is a group, F is asemigroui).
Becauseu l*  lcr = ul, 1u is asolut ion of tile equation " l  *X = \[EP93\]ul.
Since 1 is a unit element of /" ,  vx * 1 = ul.
Since1 is a unit element of F, 1 C F. Because tq ~ \[', 1is a solution of the equation ul * X = ul.
Since F isa group, lry = 1 by the uniqueness of solution.
This \[Gen35\]conclusion is independent of the choice of the elementut.
\[CSsq7.
Conc lus ion  and  lh l tu re  "Work\[ll~,vss\]This paper puts forward an architecture that comlfinesseveral estahlished NL generation techniques adaptedfor a particular application, namely the presentationof ND style proofs.
We hope that this architecture isalso of general interest beyond this particular applic-ation.The most important feature of this model is thathierarchical planning and unplanned spontaneouspresentation are integrated in a nnitbrm framework.~Ibp-down hierarchical planning views language gmmr-ation ,'~s planned behavior.
Bmsed on explicit colnn!u-nicative knowledge ncoded as schemata, hierarchicalplanning splits a presentation task into sul~tasks.
Al-though our overall presentation mechanism has muchin common with that of H.ST-Imsed text planm.,rs, the \[I,:i\]9,1\]top-down planning operators contain mostly complexpresentation schemata, like those in schema-basedplamfing.
Since schemata-based planning covers only \[Mct)83\]proofs of some particular structure, it is complenlen-ted by a mechanism called hottom-up presentation.Bottom-up presentation aims at simulating the un-planned part of proof presentation, where, a proof node \[McI(.85\]or a subproof awaiting present.ation is chosen as thenext to he presented via the local derivation relations.
\[Moo89\]Since more than one such node is often available, thelocal focus mechanism is employed to single out.
thecandidate having the strongest semantic links with the \[Och7!J\]focal centers.
The distinction between l~lanned andunplanned behavior enables a very natural segment- \[ParS8\]ation of the discourse into an attentional hierarchy.This provide an appropriate basis for a discourse the-ory which handles reference choices \[Iluagdb}.
\[l'~ei91\]Compared with proofs found in mathematical  text-books, the output of PROVERB is still to ,  tediousand inflexible.
The tediousness i largely ascril)ed to \[Sibg0\]the lack of plan level knowledge of the input proofs,which distinguishes crucial steps from unimportantdetails.
Therefore, sophisticated plan recognitiontechniques are necessary.
The inflexibility of text cur-rently produced is partly inherited from the schemata-based approach, for which a fine-grained plamfing interms of single PCAs might he a remedy.
It is alsopartly due to the fixed lexicon choice, which we arecurrently reimplcnmntiug.References\[Ilua94a\]\[ltuag,ll,\]\[IIua94 b\]l).
Chester.
The translation o\[ formal proofsinto English.
Artificial Intelligence, 1976.R.
Dale.
Generating Re/erring I'Txpressio,Js.MVI" Press, 1092.A.
Edgar and P..\].
Pelletier.
Natural angnageexplat)llttiott of lla.Lllr;tl de.dllctiolt proofs, inPr'oe.
of the first Conf.
of the t'aeqic Assoc.for Comp.
Linguistics, 1993.G.
Qentzen.
Untersuchungen (iber das logischeSchliegen 1.
Math.
Zeitsehrift, 1935.B.
J. Grosz and C. L. Sidaer.
Attention, inten-tions, and the structure of discourse.
Compu-tational Liug.istics, 1986.E.
It.
\[Iovy.
(/enerating Natural Language un-der Progm,tie Coustrints.
L;twrence ErlbaumAssociates, \[IillsdMe, 1988.X.
IIuang.
Reconstructing proofs at the asser-tion h-'vel.
In Proc.
o\] l~th CADE, 199,1, forth-eOlllitlg.X.
IIuitng.
Pl~tnning Reference Choices for Ar-gumentatiw: ~D:xts.
In Proe.
of the 7th Inter-national Wo,'kshol~ on Natural Language Gen-e.ratiott, 199,1, forthcoming.X.
IIuang.
A Reconstructive Approach to Hu-man Oriented Proof P~vsentation.
PlID thesis,(lniversitiit des Satarlatndes, (-lermally, 1994,forthcoming.A.
Kilger.
Using U'I'AQs for increment:d;tnd parallel generatitm.
Computationallntelli-\[lence, forthcoming, 11994.1).
l).
McDonald.
Natural language gen-eration its ;t COmlmt,'ttionM prn\[~leln.
InBrady/llcrwick: Computational Models of Dis-course.
MI'\]."
Press, 1983.\[(.
R. MeI(ec~wn.
Te:L't (~eneratlon, CambridgeUniversity Press, 1985.J.
I).
Moore.
A Reactive Approach to l:2xphm-ation i.
Expert arm Adoice-Gioin9 Systems.PhD thesis, Univ.
of California, 1989.E.
Ochs, I'lamled ;tml ulq)lanned discourse.Synt.x and ?
'em~mlies, 1979.C.
P;tris.
Taih~ring object descriptions to ztuser's lewd of experti:;e. Compulutional Lin-guisl.
:s, 1988.N.
l{eithinger.
Eine parallch~ Architektur zurinkrententeller Dialogbeitriige.
Pill) thesis, Uni-versitiit ies Saarlrtndes, 1991.P.
Sibun.
The loc;tl org,'tnization of text.
InI(.R.
McKeown eta1, editors, Proc.
of the 5thInternational Workshop on Natural Language(?ener.tion, 1990..~3
