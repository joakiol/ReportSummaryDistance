Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 1009?1016,Sydney, July 2006. c?2006 Association for Computational LinguisticsNovel Association Measures Using Web Search with Double CheckingHsin-Hsi Chen Ming-Shun Lin Yu-Chuan WeiDepartment of Computer Science and Information EngineeringNational Taiwan UniversityTaipei, Taiwanhhchen@csie.ntu.edu.tw;{mslin,ycwei}@nlg.csie.ntu.edu.twAbstractA web search with double checkingmodel is proposed to explore the web asa live corpus.
Five association measuresincluding variants of Dice, Overlap Ratio,Jaccard, and Cosine, as well as Co-Occurrence Double Check (CODC), arepresented.
In the experiments on Ruben-stein-Goodenough?s benchmark data set,the CODC measure achieves correlationcoefficient 0.8492, which competes withthe performance (0.8914) of the modelusing WordNet.
The experiments on linkdetection of named entities using thestrategies of direct association, associa-tion matrix and scalar association matrixverify that the double-check frequenciesare reliable.
Further study on named en-tity clustering shows that the five meas-ures are quite useful.
In particular,CODC measure is very stable on word-word and name-name experiments.
Theapplication of CODC measure to expandcommunity chains for personal name dis-ambiguation achieves 9.65% and 14.22%increase compared to the system withoutcommunity expansion.
All the experi-ments illustrate that the novel model ofweb search with double checking is fea-sible for mining associations from theweb.1 IntroductionIn statistical natural language processing, re-sources used to compute the statistics are indis-pensable.
Different kinds of corpora have madeavailable and many language models have beenexperimented.
One major issue behind the cor-pus-based approaches is: if corpora adopted canreflect the up-to-date usage.
As we know, lan-guages are live.
New terms and phrases are usedin daily life.
How to capture the new usages isan important research topic.The Web is a heterogeneous document collec-tion.
Huge-scale and dynamic nature are charac-teristics of the Web.
Regarding the Web as alive corpus becomes an active research topic re-cently.
How to utilize the huge volume of webdata to measure association of information is animportant issue.
Resnik and Smith (2003) em-ploy the Web as parallel corpora to provide bi-lingual sentences for translation models.
Kellerand Lapata (2003) show that bigram statistics forEnglish language is correlated between corpusand web counts.
Besides, how to get the wordcounts and the word association counts from theweb pages without scanning over the whole col-lections is indispensable.
Directly managing theweb pages is not an easy task when the Webgrows very fast.Search engine provides some way to returnuseful information.
Page counts for a query de-note how many web pages containing a specificword or a word pair roughly.
Page count is dif-ferent from word frequency, which denotes howmany occurrences a word appear.
Lin and Chen(2004) explore the use of the page counts pro-vided by different search engines to compute thestatistics for Chinese segmentation.
In additionto the page counts, snippets returned by websearch, are another web data for training.
Asnippet consists of a title, a short summary of aweb page and a hyperlink to the web page.
Be-cause of the cost to retrieve the full web pages,short summaries are always adopted (Lin, Chen,and Chen, 2005).Various measures have been proposed tocompute the association of objects of differentgranularity like terms and documents.
Rodr?guezand Egenhofer (2003) compute the semantic1009similarity from WordNet and SDTS ontology byword matching, feature matching and semanticneighborhood matching.
Li et al (2003) investi-gate how information sources could be used ef-fectively, and propose a new similarity measurecombining the shortest path length, depth andlocal density using WordNet.
Matsuo et al(2004) exploit the Jaccard coefficient to build?Web of Trust?
on an academic community.This paper measures the association of termsusing snippets returned by web search.
A websearch with double checking model is proposedto get the statistics for various association meas-ures in Section 2.
Common words and personalnames are used for the experiments in Sections 3and 4, respectively.
Section 5 demonstrates howto derive communities from the Web using asso-ciation measures, and employ them to disam-biguate personal names.
Finally, Section 6 con-cludes the remarks.2 A Web Search with Double CheckingModelInstead of simple web page counts and complexweb page collection, we propose a novel model,a Web Search with Double Checking (WSDC), toanalyze snippets.
In WSDC model, two objects Xand Y are postulated to have an association if wecan find Y from X (a forward process) and find Xfrom Y (a backward process) by web search.
Theforward process counts the total occurrences of Yin the top N snippets of query X, denoted asf(Y@X).
Similarly, the backward process countsthe total occurrences of X in the top N snippets ofquery Y, denoted as f(X@Y).
The forward andthe backward processes form a double check op-eration.Under WSDC model, the association scoresbetween X and Y are defined by various formulasas follows.??????
?++===OtherwiseYfXfYXfXYfYXforXYfifYXeVariantDic)()()@()@(0)@(0)@(0),((1))()())@(),@((,(YfXfYXfXYfminY)XineVariantCos ?=(2)))@(),@(()()())@(),@((YXfXYfmaxYfXfYXfXYfmin(X,Y)cardVariantJac?+=(3){ })}(),({)@(),@(),(YfXfminYXfXYfminYXrlapVariantOve = (4)???????===????????
?
OtherwiseYXforXYfifYXCODCYfYXfXfXYfloge?
)()@()()@(0)@(0)@(0),((5)Where f(X) is the total occurrences of X in thetop N snippets of query X, and, similarly, f(Y) isthe total occurrences of Y in the top N snippets ofquery Y.  Formulas (1)-(4) are variants of theDice, Cosine, Jaccard, and Overlap Ratio asso-ciation measure.
Formula (5) is a functionCODC (Co-Occurrence Double-Check), whichmeasures the association in an interval [0,1].
Inthe extreme cases, when f(Y@X)=0 or f(X@Y)=0,CODC(X,Y)=0; and when f(Y@X)=f(X) andf(X@Y)=f(Y), CODC(X,Y)=1.
In the first case, Xand Y are of no association.
In the second case,X and Y are of the strongest association.3 Association of Common WordsWe employ Rubenstein-Goodenough?s (1965)benchmark data set to compare the performanceof various association measures.
The data setconsists of 65 word pairs.
The similarities be-tween words, called Rubenstein and Goodenoughrating (RG rating), were rated on a scale of 0.0 to4.0 for ?semantically unrelated?
to ?highly syn-onymous?
by 51 human subjects.
The Pearsonproduct-moment correlation coefficient, rxy, be-tween the RG ratings X and the associationscores Y computed by a model shown as followsmeasures the performance of the model.yxiniixy ssnyyxxr)1())((1??
?=?=                             (6)Where x  and y  are the sample means of xi andyi, and sx and sy are sample standard deviations ofxi and yi and n is total samples.Most approaches (Resink, 1995; Lin, 1998; Liet al, 2003) used 28 word pairs only.
Resnik(1995) obtained information content fromWordNet and achieved correlation coefficient0.745.
Lin (1998) proposed an information-theoretic similarity measure and achieved a cor-relation coefficient of 0.8224.
Li et al (2003)combined semantic density, path length anddepth effect from WordNet and achieved the cor-relation coefficient 0.8914.1010100 200 300 400 500 600 700 800 900VariantDice 0.5332 0.5169 0.5352 0.5406 0.5306 0.5347 0.5286 0.5421 0.5250VariantOverlap 0.5517 0.6516 0.6973 0.7173 0.6923 0.7259 0.7473 0.7556 0.7459VariantJaccard 0.5533 0.6409 0.6993 0.7229 0.6989 0.738 0.7613 0.7599 0.7486VariantCosine 0.5552 0.6459 0.7063 0.7279 0.6987 0.7398 0.7624 0.7594 0.7501CODC (?=0.15) 0.5629 0.6951 0.8051 0.8473 0.8438 0.8492 0.8222 0.8291 0.8182Jaccard Coeff* 0.5847 0.5933 0.6099 0.5807 0.5463 0.5202 0.4855 0.4549 0.4622Table 1.
Correlation Coefficients of WSDC Model on Word-Word ExperimentsModel RG RatingResnik(1995)Lin(1998)Li et al(2003)VariantCosine(#snippets=700)WSDCCODC(?=0.15,#snippets=600)WSDCCorrelation Coefficient - 0.7450 0.8224 0.8914 0.7624 0.8492chord-smile 0.02 1.1762 0.20 0 0 0rooster-voyage 0.04 0 0 0 0 0noon-string 0.04 0 0 0 0 0glass-magician 0.44 1.0105 0.06 0 0 0monk-slave 0.57 2.9683 0.18 0.350 0 0coast-forest 0.85 0 0.16 0.170 0.0019 0.1686monk-oracle 0.91 2.9683 0.14 0.168 0 0lad-wizard 0.99 2.9683 0.20 0.355 0 0forest-graveyard 1 0 0 0.132 0 0food-rooster 1.09 1.0105 0.04 0 0 0coast-hill 1.26 6.2344 0.58 0.366 0 0car-journey 1.55 0 0 0 0.0014 0.2049crane-implement 2.37 2.9683 0.39 0.366 0 0brother-lad 2.41 2.9355 0.20 0.355 0.0027 0.1811bird-crane 2.63 9.3139 0.67 0.472 0 0bird-cock 2.63 9.3139 0.83 0.779 0.0058 0.2295food-fruit 2.69 5.0076 0.24 0.170 0.0025 0.2355brother-monk 2.74 2.9683 0.16 0.779 0.0027 0.1956asylum-madhouse 3.04 15.666 0.97 0.779 0.0015 0.1845furnace-stove 3.11 1.7135 0.18 0.585 0.0035 0.1982magician-wizard 3.21 13.666 1 0.999 0.0031 0.2076journey-voyage 3.58 6.0787 0.89 0.779 0.0086 0.2666coast-shore 3.6 10.808 0.93 0.779 0.0139 0.2923implement-tool 3.66 6.0787 0.80 0.778 0.0033 0.2506boy-lad 3.82 8.424 0.85 0.778 0.0101 0.2828Automobile-car 3.92 8.0411 1 1 0.0144 0.4229Midday-noon 3.94 12.393 1 1 0.0097 0.2994gem-jewel 3.94 14.929 1 1 0.0107 0.3530Table 2.
Comparisons of WSDC with Models in Previous ResearchesIn our experiments on the benchmark data set,we used information from the Web rather thanWordNet.
Table 1 summarizes the correlationcoefficients between the RG rating and the asso-ciation scores computed by our WSDC model.We consider the number of snippets from 100 to900.
The results show that CODC > VariantCo-sine > VariantJaccard > VariantOverlap > Vari-antDice.
CODC measure achieves the best per-formance 0.8492 when ?=0.15 and total snippetsto be analyzed are 600.
Matsuo et al (2004)used Jaccard coefficient to calculate similaritybetween personal names using the Web.
The co-efficient is defined as follows.1011)()(),(YXfYXfYXCoffJaccard ?
?=                                  (7)Where f(X?Y) is the number of pages includingX?s and Y?s homepages when query ?X and Y?
issubmitted to a search engine; f(X?Y) is the num-ber of pages including X?s or Y?s homepageswhen query ?X or Y?
is submitted to a search en-gine.
We revised this formula as follows andevaluated it with Rubenstein-Goodenough?sbenchmark.
)()(),( *YXfYXfYXCoffJaccardss?
?=                             (8)Where fs(X?Y) is the number of snippets inwhich X and Y co-occur in the top N snippets ofquery ?X and Y?
; fs(X?Y) is the number of snip-pets containing X or Y in the top N snippets ofquery ?X or Y?.
We test the formula on the samebenchmark.
The last row of Table 1 shows thatJaccard Coeff* is worse than other models whenthe number of snippets is larger than 100.Table 2 lists the results of previous researches(Resink, 1995; Lin, 1998; Li et al, 2003) and ourWSDC models using VariantCosine and CODCmeasures.
The 28 word pairs used in the ex-periments are shown.
CODC measure can com-pete with Li et al (2003).
The word pair ?car-journey?
whose similarity value is 0 in the papers(Resink, 1995; Lin, 1998; Li et al, 2003) is cap-tured by our model.
In contrast, our model can-not deal with the two word pairs ?crane-implement?
and ?bird-crane?.4 Association of Named EntitiesAlthough the correlation coefficient of WSDCmodel built on the web is a little worse than thatof the model built on WordNet, the Web pro-vides live vocabulary, in particular, named enti-ties.
We will demonstrate how to extend ourWSDC method to mine the association of per-sonal names.
That will be difficult to resolvewith previous approaches.
We design two ex-periments ?
say, link detection test and namedentity clustering, to evaluate the association ofnamed entities.Given a named-entity set L, we define a linkdetection test to check if any two named entitiesNEi and NEj (i?j) in L have a relationship R usingthe following three strategies.?
Direct Association: If the double checkfrequency of NEi and NEj is larger than 0,Figure 1.
Three Strategies for Link Detectioni.e., f(NEj@NEi)>0 and f(NEi@NEj)>0,then the link detection test says ?yes?, i.e.,NEi and NEj have direct association.
Oth-erwise, the test says ?no?.
Figure 1(a)shows the direct association.?
Association Matrix: Compose an n?n bi-nary matrix M=(mij), where mij=1 iff(NEj@NEi)>0 and f(NEi@NEj)>0; mij=0if f(NEj@NEi)=0 or f(NEi@NEj)=0; and nis total number of named entities in L.  LetMt be a transpose matrix of M.  The matrixA=M?Mt is an association matrix.
Herethe element aij in A means that total aijcommon named entities are associatedwith both NEi and NEj directly.
Figure 1(b)shows a one-layer indirect association.Here, aij=3.
We can define NEi and NEjhave an indirect association if aij is largerthan a threshold ?.
That is, NEi and NEjshould associate with at least ?
commonnamed entities directly.
The strategy ofassociation matrix specifies: if aij?
?, thenthe link detection test says ?yes?, other-wise it says ?no?.
In the example shownin Figure 1(b), NEi and NEj are indirectlyassociated when 0<??3.?
Scalar Association Matrix: Compose abinary association matrix B from the asso-ciation matrix A as: bij=1 if aij>0 and bij=0if aij=0.
The matrix S= B?Bt is a scalar as-1012sociation matrix.
NEi and NEj may indi-rectly associate with a common named en-tity NEk.
Figure 1(c) shows a two-layerindirect association.
The ?
= ?= nk kjikij bbs 1denotes how many such an NEk there are.In the example of Figure 1(c), two namedentities indirectly associate NEi and NEj atthe same time.
We can define NEi and NEjhave an indirect association if sij is largerthan a threshold ?.
In other words, if sij >?,then the link detection test says ?yes?,otherwise it says ?no?.To evaluate the performance of the abovethree strategies, we prepare a test set extractedfrom domz web site (http://dmoz.org), the mostcomprehensive human-edited directory of theWeb.
The test data consists of three communi-ties: actor, tennis player, and golfer, shown inTable 3.
Total 220 named entities are considered.The golden standard of link detection test is: wecompose 24,090 (=220?219/2) named entitypairs, and assign ?yes?
to those pairs belongingto the same community.Category Path in domz.org # of Person NamesTop: Sports: Golf: Golfers  10Top: Sports: Tennis: Players:Female (+Male)  90Top: Arts: People: Image Galleries:Female (+Male): Individual 120Table 3.
Test Set for Association Evaluation ofNamed EntitiesWhen collecting the related values for com-puting the double check frequencies for anynamed entity pair (NEi and NEj), i.e., f(NEj@NEi),f(NEi@NEj), f(NEi), and f(NEj), we considernaming styles of persons.
For example, ?Alba,Jessica?
have four possible writing: ?Alba, Jes-sica?, ?Jessica Alba?, ?J.
Alba?
and ?Alba, J.?We will get top N snippets for each naming style,and filter out duplicate snippets as well as snip-pets of ULRs including dmoz.org andgoogle.com.
Table 4 lists the experimental re-sults of link detection on the test set.
The preci-sions of two baselines are: guessing all ?yes?
(46.45%) and guessing all ?no?
(53.55%).
Allthe three strategies are better than the two base-lines and the performance becomes better whenthe numbers of snippets increase.
The strategyof direct association shows that using doublechecks to measure the association of named enti-ties also gets good effects as the association ofcommon words.
For the strategy of associationmatrix, the best performance 90.14% occurs inthe case of 900 snippets and ?=6.
When largernumber of snippets is used, a larger threshold isnecessary to achieve a better performance.
Fig-ure 2(a) illustrates the relationship between pre-cision and threshold (?).
The performance de-creases when ?>6.
The performance of the strat-egy of scalar association matrix is better than thatof the strategy of association matrix in some ?and ?.
Figure 2(b) shows the relationship be-tween precision and threshold ?
for some numberof snippets and ?.In link detection test, we only consider the bi-nary operation of double checks, i.e., f(NEj@NEi)> 0 and f(NEi@NEj) > 0, rather than utilizing themagnitudes of f(NEj@NEi) and f(NEi@NEj).Next we employ the five formulas proposed inSection 2 to cluster named entities.
The samedata set as link detection test is adopted.
An ag-glomerative average-link clustering algorithm isused to partition the given 220 named entitiesbased on Formulas (1)-(5).
Four-fold cross-validation is employed and B-CUBED metric(Bagga and Baldwin, 1998) is adopted to evalu-ate the clustering results.
Table 5 summarizesthe experimental results.
CODC (Formula 5),which behaves the best in computing associationof common words, still achieves the better per-formance on different numbers of snippets innamed entity clustering.
The F-scores of theother formulas are larger than 95% when moresnippets are considered to compute the doublecheck frequencies.Strategies 100 200 300 400 500 600 700 800 900DirectAssociation 59.20% 62.86% 65.72% 67.88% 69.83% 71.35% 72.05% 72.46% 72.55%AssociationMatrix71.53%(?=1)79.95%(?=1)84.00%(?=2)86.08%(?=3)88.13%(?=4)89.67%(?=5)89.98%(?=5)90.09%(?=6)90.14%(?=6)Scalar Asso-ciationMatrix73.93%(?=1,?=6)82.69%(?=2,?=9)86.70%(?=4,?=9)88.61%(?=5,?=10)90.90%(?=6,?=12)91.93%(?=7,?=12)91.90%(?=7,?=18)92.20%(?=10,?=16)92.35%(?=10,?=18)Table 4.
Performance of Link Detection of Named Entities1013(a)                                                                            (b)Figure 2.
(a) Performance of association matrix strategy.
(b) Performance of scalar association matrixstrategy (where ?
is fixed and its values reference to scalar association matrix in Table 4)100 200 300 400 500 600 700 800 900P 91.70% 88.71% 87.02% 87.49% 96.90% 100.00% 100.00% 100.00% 100.00%R 55.80% 81.10% 87.70% 93.00% 89.67% 93.61% 94.42% 94.88% 94.88%VariantDiceF 69.38% 84.73% 87.35% 90.16% 93.14% 96.69% 97.12% 97.37% 97.37%P 99.13% 87.04% 85.35% 85.17% 88.16% 88.16% 88.16% 97.59% 98.33%R 52.16% 81.10% 86.24% 93.45% 92.03% 93.64% 92.82% 90.82% 93.27%VariantOverlapF 68.35% 83.96% 85.79% 89.11% 90.05% 90.81% 90.43% 94.08% 95.73%P 99.13% 97.59% 98.33% 95.42% 97.59% 88.16% 95.42% 100.00% 100.00%R 55.80% 77.53% 84.91% 88.67% 87.18% 90.58% 88.67% 93.27% 91.64%VariantJaccardF 71.40% 86.41% 91.12% 91.92% 92.09% 89.35% 91.92% 96.51% 95.63%P 84.62% 97.59% 85.35% 85.17% 88.16% 88.16% 88.16% 98.33% 98.33%R 56.22% 78.92% 86.48% 93.45% 92.03% 93.64% 93.64% 93.27% 93.27%VariantCosineF 67.55% 87.26% 85.91% 89.11% 90.05% 90.81% 90.81% 95.73% 95.73%P 91.70% 87.04% 87.02% 95.93% 98.33% 95.93% 95.93% 94.25% 94.25%R 55.80% 81.10% 90.73% 94.91% 94.91% 96.52% 98.24% 98.24% 98.24%CODC(?=0.15)F 69.38% 83.96% 88.83% 95.41% 96.58% 96.22% 97.07% 96.20% 96.20%Table 5.
Performance of Various Scoring Formulas on Named Entity Clustering5 Disambiguation Using Association ofNamed EntitiesThis section demonstrates how to employ asso-ciation mined from the Web to resolve the ambi-guities of named entities.
Assume there are nnamed entities, NE1, NE2, ?, and NEn, to be dis-ambiguated.
A named entity NEj has m accom-panying names, called cue names later, CNj1,CNj2, ?, CNjm.
We have two alternatives to usethe cue names.
One is using them directly, i.e.,NEj is represented as a community of cue namesCommunity(NEj)={CNj1, CNj2, ?, CNjm}.
Theother is to expand the cue names CNj1, CNj2, ?,CNjm for NEj using the web data as follows.
LetCNj1 be an initial seed.
Figure 3 sketches theconcept of community expansion.
(1) Collection: We submit a seed toGoogle, and select the top N returnedsnippets.
Then, we use suffix trees toextract possible patterns (Lin and Chen,2006).
(2) Validation: We calculate CODC scoreof each extracted pattern (denoted Bi)with the seed A.
If CODC(A,Bi) isstrong enough, i.e., larger than a1014threshold ?, we employ Bi as a newseed and repeat steps (1) and (2).
Thisprocedure stops either expected numberof nodes is collected or maximumnumber of layers is reached.
(3) Union: The community initiated by theseed CNji is denoted by Commu-nity(CNji)={Bji1, Bji2, ?, BBjir}, where Bjikis a new seed.
The Cscore score, com-munity score, of BjikB  is the CODC scoreof Bjik with its parent divided by thelayer it is located.
We repeat Collec-tion and Validation steps until all thecue names CNji (1?i?m) of NEj areprocessed.
Finally, we have)()( 1 jimij CNCommunityNECommunity =?=Figure 3.
A Community for a Seed ?????
(?Chien-Ming Wang?
)In a cascaded personal name disambiguationsystem (Wei, 2006), association of named enti-ties is used with other cues such as titles, com-mon terms, and so on.
Assume k clusters, c1 c2 ...ck, have been formed using title cue, and we tryto place NE1, NE2, ?, and NEl into a suitablecluster.
The cluster c  is selected by the similar-ity measure defined below.
)()(1),(1 iisiqjpnscoreCpncountrcNEscore?= ?=             (9)),(maxarg)kq1(c qqj cNEscorec ?
?=                     (10)Where pn1, pn2, ?, pns are names which appearin both Community(NEj) and Community(cq);count(pni) is total occurrences of pni in Commu-nity(cq); r is total occurrences of names in Com-munity(NEj); Cscore(pni) is community score ofpni.If score(NEj, c ) is larger than a threshold,then NEj is placed into cluster c .
In other words,NEj denotes the same person as those in c .
Welet the new Community( c ) be the old Commu-nity( c )?
{CNj1, CNj2, ?, CNjm}.
Otherwise, NEjis left undecided.To evaluate the personal name disambiguation,we prepare three corpora for an ambiguous name????
?
(Chien-Ming Wang) from UnitedDaily News Knowledge Base (UDN), GoogleTaiwan (TW), and Google China (CN).
Table 6summarizes the statistics of the test data sets.
InUDN news data set, 37 different persons arementioned.
Of these, 13 different persons occurmore than once.
The most famous person is apitcher of New York Yankees, which occupies94.29% of 2,205 documents.
In TW and CNweb data sets, there are 24 and 107 different per-sons.
The majority in TW data set is still theNew York Yankees?s ?Chien-Ming Wang?.
Heappears in 331 web pages, and occupies 88.03%.Comparatively, the majority in CN data set is aresearch fellow of Chinese Academy of SocialSciences, and he only occupies 18.29% of 421web pages.
Total 36 different ?Chien-MingWang?s occur more than once.
Thus, CN is anunbiased corpus.UDN TW CN# of documents 2,205 376 421# of persons 37 24 107# of persons ofoccurrences>1 13 9 36Majority  94.29% 88.03% 18.29%Table 6.
Statistics of Test CorporaM1 M2P 0.9742 0.9674 (?0.70%)R 0.9800 0.9677 (?1.26%) UDNF 0.9771 0.9675 (?0.98%)P 0.8760 0.8786 (?0.07%)R 0.6207 0.7287 (?17.40%) TWF 0.7266 0.7967 (?9.65%)P 0.4910 0.5982 (?21.83%)R 0.8049 0.8378 (?4.09%) CNF 0.6111 0.6980 (?14.22%)Table 7.
Disambiguation without/with Commu-nity Expansion1015Table 7 shows the performance of a personalname disambiguation system without (M1)/with(M2) community expansion.
In the news data set(i.e., UDN), M1 is a little better than M2.
Com-pared to M1, M2 decreases 0.98% of F-score.
Incontrast, in the two web data sets (i.e., TW andCN), M2 is much better than M1.
M2 has 9.65%and 14.22% increases compared to M1.
It showsthat mining association of named entities fromthe Web is very useful to disambiguate ambigu-ous names.
The application also confirms theeffectiveness of the proposed association meas-ures indirectly.6 Concluding RemarksThis paper introduces five novel associationmeasures based on web search with doublechecking (WSDC) model.
In the experiments onassociation of common words, Co-OccurrenceDouble Check (CODC) measure competes withthe model trained from WordNet.
In the experi-ments on the association of named entities,which is hard to deal with using WordNet,WSDC model demonstrates its usefulness.
Thestrategies of direct association, association ma-trix, and scalar association matrix detect the linkbetween two named entities.
The experimentsverify that the double-check frequencies are reli-able.Further study on named entity clusteringshows that the five measures ?
say, VariantDice,VariantOverlap, ariantJaccard, VariantCosineand CODC, are quite useful.
In particular,CODC is very stable on word-word and name-name experiments.
Finally, WSDC model isused to expand community chains for a specificpersonal name, and CODC measures the associa-tion of community member and the personalname.
The application on personal name disam-biguation shows that 9.65% and 14.22% increasecompared to the system without community ex-pansion.AcknowledgementsResearch of this paper was partially supported byNational Science Council, Taiwan, under thecontracts 94-2752-E-001-001-PAE and 95-2752-E-001-001-PAE.ReferencesA.
Bagga and B. Baldwin.
1998.
Entity-Based Cross-Document Coreferencing Using the Vector SpaceModel.
Proceedings of 36th COLING-ACL Con-ference, 79-85.F.
Keller and M. Lapata.
2003.
Using the Web to Ob-tain Frequencies for Unseen Bigrams.
Computa-tional Linguistics, 29(3): 459-484.Y.
Li, Z.A.
Bandar and D. McLean.
2003.
An Ap-proach for Measuring Semantic Similarity betweenWords Using Multiple Information Sources.
IEEETransactions on Knowledge and Data Engineering,15(4): 871-882.D.
Lin.
1998.
An Information-Theoretic Definition ofSimilarity.
Proceedings of the Fifteenth Interna-tional Conference on Machine Learning, 296-304.H.C.
Lin and H.H.
Chen.
2004.
Comparing Corpus-based Statistics and Web-based Statistics: ChineseSegmentation as an Example.
Proceedings of 16thROCLING Conference, 89-100.M.S.
Lin, C.P.
Chen and H.H.
Chen.
2005.
An Ap-proach of Using the Web as a Live Corpus forSpoken Transliteration Name Access.
Proceedingsof 17th ROCLING Conference, 361-370.M.S.
Lin and H.H.
Chen.
2006.
Constructing aNamed Entity Ontology from Web Corpora.
Pro-ceedings of 5th International Conference on Lan-guage Resources and Evaluation.Y.
Matsuo, H. Tomobe, K. Hasida, and M. Ishizuka.2004.
Finding Social Network for Trust Calcula-tion.
Proceedings of 16th European Conference onArtificial Intelligence, 510-514.P.
Resnik.
1995.
Using Information Content to Evalu-ate Semantic Similarity in a Taxonomy.
Proceed-ings of the 14th International Joint Conference onArtificial Intelligence, 448-453.P.
Resnik and N.A.
Smith.
2003.
The Web as a Paral-lel Corpus.
Computational Linguistics, 29(3): 349-380.M.A.
Rodr?guez and M.J. Egenhofer.
2003.
Determin-ing Semantic Similarity among Entity Classes fromDifferent Ontologies.
IEEE Transactions onKnowledge and Data Engineering, 15(2): 442-456.H.
Rubenstein and J.B. Goodenough.
1965.
Contex-tual Correlates of Synonymy.
Communications ofthe ACM, 8(10): 627-633.Y.C.
Wei.
2006.
A Study of Personal Name Disam-biguation.
Master Thesis, Department of ComputerScience and Information Engineering, NationalTaiwan University, Taiwan.1016
