Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1070?1080,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsTailor knowledge graph for query understanding: linking intent topics bypropagationShi Zhaoz.s@pku.edu.cnYan Zhangzhy@cis.pku.edu.cnDepartment of Machine Intelligence, Peking University, Beijing, ChinaKey Laboratory on Machine Perception, Ministry of Education, Beijing, ChinaAbstractKnowledge graphs are recently used forenriching query representations in anentity-aware way for the rich facts or-ganized around entities in it.
How-ever, few of the methods pay attention tonon-entity words and clicked websites inqueries, which also help conveying userintent.
In this paper, we tackle the prob-lem of intent understanding with innova-tively representing entity words, refinersand clicked urls as intent topics in a uni-fied knowledge graph based framework,in a way to exploit and expand knowl-edge graph which we call ?tailor?.
Wecollaboratively exploit global knowledgein knowledge graphs and local contexts inquery log to initialize intent representa-tion, then propagate the enriched featuresin a graph consisting of intent topics us-ing an unsupervised algorithm.
The ex-periments prove intent topics with knowl-edge graph enriched features significantlyenhance intent understanding.1 IntroductionQuery understanding is the process of generating arepresentation which characterizes a user?s searchintent (Croft et al., 2010), which is of vital im-portance for information retrieval.
However, usersare remarkably laconic in describing their infor-mation needs due to anomalous state of knowledge(Belkin et al., 1982), resulting in vague and under-specified queries, which makes it especially dif-ficult to understand and locate what they intendedfor in mountains of web data.
The problem is oftensignificantly compounded that people convey theirintent rather in a series of behaviors called a searchsession than a single query, leaving a wealth ofclues including query reformulations, page visits,dwell times, etc.
What?s more, as entities are tak-ing center stage (Yin and Shah, 2010), string-levelor phrase-level modeling of intent soon hits thebottleneck, calling for an entity-aware perspective.Knowledge repositories, better known asknowledge graphs, such as Wikipedia, DBpediaand Freebase, have been recently utilized for en-hancing query understanding for the large amountsof world knowledge they?ve harvested about en-tities and facts.
A widely accepted way to useknowledge graph is tying queries with it by anno-tating entities in them, also known as entity link-ing.However, information need is conveyed throughmore than entities.
Quite a few non-entity words,aka refiners or modifiers, as well as many urls arebarely included in knowledge graph, while theyplay an irreplaceable role in intent understand-ing.
For example, a user may query toyota, volvoor just enter car soup, cars for sale and clickwww.carsoup.com, which should be encoded ina form that we could perceive their closeness inintent.
That?s why at-a-glance info cards aboutmerely recognized entity in the query are far fromenough and previous methods disregarding refin-ers and urls are too limited to cover queries in ma-jority.We move one step further to tailor knowledgegraph for representing more than entity words.
Wecollect refiners and clicked urls along with en-tity words and model intents they represent us-ing knowledge graph based features.
We useFreebase1, one of the largest available knowledgegraph, in our work and our method can be easilygeneralized to other knowledge repositories.We put up an idea of intent topic which canbe query words or urls, whether mean an entityor not, representing an atomic information need.We identify them with intent features by exploit-ing global knowledge in Freebase and local con-1http://www.freebase.com1070texts in query sessions.
Notice the new concepthere is distinguished from query intent or queryfacet in previous literature for it is in a holisticview, not specifically meaning subtopics around acertain query.Our intuitive observations as follows inspire usto represent intent features with topics and do-mains in knowledge graph and propagate the en-riched features in the intent topic graph.1) Query words and urls within the same sessiontend to indicate the same query intent.2) Intent topics sharing similar query intent oftenrelate to similar topics in knowledge graph.3) Knowledge graph domains sketch the query in-tent briefly.Observation 1 indicates domain coherencywithin sessions is a good starting point to gener-ate intent features, along with Observation 2 and 3lay the basis of proximity that the propagation relyon.To the best of our knowledge, we?re the first torepresent intent behind entity words, refiners andurls in a unified knowledge graph based frame-work, in a way to exploit and expand knowledgegraph which we call ?tailor?.Our contributions include:?
An innovative and unified framework to rep-resent intent topics, whether they can directlylink to an entity in knowledge graph or not.?
A novel algorithm to generate a specified in-tent topic graph, which enables learning in-tent features in an unsupervised propagationmethod.?
With intent topic graph we can better under-stand user intent conducting session-basedcontextualization and potentially find highly-related intent topic.The rest of the paper is organized as follows.
Sec-tion 2 tells our methods to map queries to Freebaseand initialize intent features.
Section 3 is abouthow we model intent topics in a unified graph andthe propagation framework to learn intent features.We provide experiments and analysis in Section 4.Related work and conclusions are presented at theend of the paper.2 Labeling intent topic nodes withFreebase-enriched featuresIn Freebase, facts around a certain topic and multi-faceted intents they reflect is more like a globaldomain distribution, what facet do users exactlyintend for is difficult to locate until in a specifiedcontext, namely a query session.We take a line in query log as a query, exhibit-ing an interaction with the search engine, includ-ing query words and page clicks.
And a sequenceof queries with a certain time interval constitutea session, completely conveying an informationneed.In existing knowledge graph, only a small partof urls are contained in views of web pages be-yond number online.
Even for query words, wecan merely get access to some of them, which wecall entity words and the rest refiners.
To avoidmisunderstanding, the url intent topics in the fol-lowing will specially refer to the clicks without di-rectly matched concepts in knowledge graph, oth-erwise they?ll be taken as entity intent topic.In this section, we propose a framework ofknowledge graph enriched representation of in-tent topics, the following propagation in Section3bases on it.2.1 Freebase as a knowledge graphFreebase has over 39 million concepts, aka top-ics, about real-world entities like people, placesand things stored as nodes in a graph.
They?relinked to each other with annotated egdes namedas property.
These edges actually represent facts.There are over a billion such facts or relations thatmake up the graph and they?re all available forfree.
Properties are grouped into types, types aregrouped into domains, which gives a broad viewof knowledge in addtion to specific topics.We can tap into Freebase through dump data orAPI2.
In our work, we retrieve related Freebasetopics with relevance scores for entity words viaFreebase search API, which is based on combina-tion of topic?s inbound and outbound link countsin Freebase and Wikipedia as well as a popularityscore computed by Google, and all the facts abouta given topic through Freebase topic API.
We useT = {t1, t2, ...tn}, D = {d1, d2, ...dn} to denoteall Freebase topics and domains used in our work.2.2 Enriching entities and queries withFreebaseWe represent a query?s candidate intent topics bythree sets, Eq, Rq, Cq, where Eqincludes entitywords and clicks which have equivalents in Free-base, Rqthe refiner words and Cqthe rest clicks.2http://developers.google.com/freebase/1071Global knowledge in Freebase can directly enricheach e in Eqwith Freebase topics represented invector te, for each candidate topic there?s a Free-base domain distribution vector dt.
As for the restinRqand Cq, they can learn features in later prop-agation process.For any topic tiin te, the relevance of entitywords e and knowledge graph topic tiis estimatedas follows:tei=RelevanceScore(e, ti)maxtj?TRelevanceScore(e, tj)(1)And the domain vector dtifor tiis:dtij=pr(dj|ti)?dk?Dpr(dk|ti)(2)pr(dj|ti) =# of links of tiin domain dj# of all links in domain dj(3)Then we?ll get a knowledge graph enriched in-tent description of the query by combining that ofe, r, c.tqi=?e?Eqteiwq(e) +?r?Rqtriwq(r) +?c?Cqtciwq(c)(4)wq(e) = NCountq(e)?
(e) (5)Here tetrtccorrespond to the topic vector of eachentity, refiner and click respectively.
The weightindicates how dominant it is in conveying intentin the query.
It is in proportion to the normalizedcount as well as each occurrence?s quality denotedby ?(e).
Such as for entity words in Equation (5),the quality ?
(e) can be estimated with the help ofentity linking methods, which describes the proba-bility of e as a candidate reference.
That for clicksand refiners will be explained later.The query?s domain feature can be calculated asfollows:dqi=?tj?Tdtjitqj?dk?D?tj?Tdtjktqj(6)It describes the probability of query q in domaindi, in which tqjcan be calculated by Equation (4)and dtjivia facts around topic tjby Equation (2).2.3 Contextualized intent depiction ofsessionsThe aforesaid enriched features we get aboutqueries rely heavily on global knowledge in Free-base, reflecting prior distribution in the featurespace.
In this part, we derive a contextualized de-scription of session intent in a local view by aggre-gating all the global knowledge we get about thesession?s queries.
The ambiguity of a single querycan be alleviated by looking at the dominant do-main within the session.The intent features tsand dsof session s canbe represented by computations on its query setQs= {q1, q2, ...qn} with time-order decay.tsi=?q?Qstqi?rank(q)?tj?T?q?Qstqj?rank(q)(7)where we put an exponential decay controlled bydecay factor ?.
We get domain feature the sameway as Equation (6).We?ll put up an unsupervised method of learn-ing knowledge graph based intent representationof refiners and clicks in the following part.3 Propagating intent features in theintent topic graphIn this section, our idea is to characterize entities,refiners and urls uniformly as intent topics, tailor-ing knowledge graph to intent topic graph so as toenrich representations by propagation.3.1 Modeling intent topic graphAs in last section, with dsfeaturing the context,candidate intent topics in sessions can make intenttopic nodes now.
We use the concept intent topicto stress words with local contexts tell a specifiedinformation need, thus making a node.
Taking en-tity word fl as an example, it can be recognizedas the topic Florida in Freebase, while the intentbehind it can hardly be mapped to a single intenttopic, such as travel domain in hollywood fl, ed-ucation domain in community college in florida,and florida department of health actually conveyintent in government domain.So each intent topic node is identified with itsname string and Freebase-enriched intent featurest and d. They?re directly linked by co-occurringin the same line in the query log and implicitlyrelated via intent features similarities, so that con-stitute a large graph G =< V,E,W >, where?w ?
W denotes an explicit edge weight and?v ?
V an intent topic.
With intent topics andtheir relations modeled in a graph, we can betterunderstand the query space so as to find the in-tended query faster.
We realize it by aggregatingmassive sessions.1072The implicit intent similarity ISim of any nodepair n and v can be encoded as follows.ISimn,v= ?SSimn,v+?DSimn,v+?TSimn,v(8)where SSim denotes the names?
string similar-ity, DSim the similarity of their domain featureand TSim the topic vector similarity, with ?, ?and ?
controlling the weight.
The parameters mayvary due to different scenarios.
We just providea framework of modeling nodes?
intent features,which actually mirror their proximity in query in-tent.To put it in more details, we use jaccard sim-ilarity for name shinglings and cosine similarityfor domain and topic vector.
As query log in-duced intent topic graph is of considerable largesize, the pair-wise similarity is computationallyprohibitive, hence we use Local Sensitive Hash(Indyk and Motwani, 1998) for each similaritymetric so as to compute ISim just in candidateset.
We use random hyperplane based hash fam-ily proposed in (Charikar, 2002) and set the hashcode dimension and hash table numbers empiri-cally to ensure the number of nodes falling intoeach bucket is relatively stable.3.2 Merging nodesAlthough our idea of specifying intent topics bycontext better models the multi-facets of queries,it obviously also brings a sparse issue.
For exam-ple, in one session user query beep lyrics and clickwww.lyricsandsongs.com, lyrics is tagged with thesong beep and the musician Pussycat Dolls, in an-other scenario lyrics occurs with the song whatyou know and url www.dapslyrics.com, intents be-hind these two nodes are so similar that theyshould come into one, otherwise connections be-tween the two intent-coherent urls may be lost.To avoid that, we conduct a merge process tointegrate nodes with exactly the same names andcontexts into one, combing linked nodes and intentfeatures together.For a set of nearly duplicate nodes ?
the cal-culation of new node?s features can be written as:?t =?u?
?tu|?|(9)?d =?u?
?du|?|(10)In other words, we gather candidate nodes re-trieved by LSH and then calculate ISim for themwith ?
setting to 0.
Only node pairs with ISimhigher than a merge threshold ?
can be seen asduplicates.
The merge process is summarized inAlgorithm 1.Algorithm 1: Merging similar nodesInput: G =< V,E,W >, ?, ?, ?, ?Output:?G =<?V ,?E,?W >beginInitialize ??
?for v ?
V doFind dupset ?vwith ISim?,?,?if ?u ?
V, ?u?
?
and ?v?
?u6= ?then?v?
?v?
?uRemove ?ufrom ?Add ?vto ?for ?
?
?
doMerge nodes in ?
into new node v?Update G with replacing nodes in ?with v?3.3 Label propagationWe utilize knowledge graph induced intent fea-tures instead of manually labels as constraints toconduct label propagation(Zhu and Ghahramani,2002).
The idea is that node labels are propa-gated to nearby nodes via weighted edges untilconvergence, as highly weighted edges indicatehigh probability of sharing labels.Nodes in our work have soft labels, where eachdimension of intent features denotes a label, suchas a topic or domain of knowledge graph.
As de-scribed in aforesaid observations, it is intuitivelyreasonable to propagate on the basis of explicitedges and implicit intent similarities.
We illustratethe propagation with topic feature, that of domainfeature is similar.We use matrix Yt?
R|V |?|T|to denote the in-tent topic graph?s initial topic feature labels, withelement Ytikindicating node vi?s relevance to tk,wherer tk?
T. Ytis initialized based on theresults of the feature enriching step in Section 2,with no manually-labelled instances needed in ourmodel.
As only part of nodes can directly mapto Freebase topics, those are initialized as labellednodes, then propagate t to their linked neighbors.The number of unlabelled data is written as u,while that of labelled data l and the total numberof nodes N .1073The transition matrix T indicates the impact ofnodes on each other.
Note that here the wijcanbe replaced by other similarity measures such asISim in Section 3.2.Tij=wij?Nk=1wkj(11)LetD denote anN?N diagonal matrix with dii=?jTij.
Then we can get a normalized version oftransition matrix P = D?1T .The normalized transition matrix can be splitinto 4 sub-matrices.P =[PllPluPulPuu](12)At each step, we propagate and clamp the labelleddata and repeat until Y converges, the propagationstep can be written as:?Yu= PuuYu+ PulYl(13)As is shown in (Zhu and Ghahramani, 2002; Zhuet al., 2003) the solution to the propagation con-verges to:?Yu= (I ?
Puu)?1PulYl(14)3.4 The propagation framework for intentfeaturesWe carry the propagation in an iterative processillustrated in Algorithm 2.Algorithm 2: Intent feature propagationInput: G, Ytl,YdlOutput:?G,?Ytu,?YduInitialize YtlYdwith results of Section2repeatMerge similar nodes according toAlgorithm 1Compute matrix Prepeat?Ytu= PuuYtu+ PulYtluntil Convergence;Recompute?P with?Ytrepeat?Ydu=?PuuYdu+?PulYdluntil Convergence;until no dups;Since intent features include both domain vec-tor and topic vector, we propagate them in an alter-nating way.
At first we label nodes as described inSection 2, though missing refiners?
and some urls?intent features, they are just used for initialization.Then we propagate Freebase topic features basedon explicit edge weights, so that more nodes inintent topic graph have topic features now.
Thenfetching the learned topic features, we reinput itinto domain feature propagation, which means werecalculate the transition matrix combining the im-plicit learned TSim into edge weight, then prop-agate domain vector of labelled nodes through thegraph.
At each iteration, we first update Yt, theninput it to update Yd, therefore merge near dupli-cate intent topics to update the whole graph.4 Experiments4.1 Data preparation4.1.1 Search logsWe use AOL search log data for experiments.
Itincludes 20 million web queries collected covering500K users over three months in 2006.Table 1: The query set# of sessions 35140# of queries 271127# of users 21378# of urls 63019We preprocess the query log by keeping urls oc-curring more than 3 times and queries with 2 to40 characters, then extract sessions considering 25minutes duration.
While user session segmenta-tion can be improved with more sophisticated al-gorithms, this simple low-cost heuristic performsadequately for our purposes.
We then move on tomap queries to Freebase and empirically filter ses-sions that are less entity-centric.
We use an anno-tation tool especially for short text (Ferragina andScaiella, 2012) called Tagme3to recognize entitiesand observe only 16% of all the queries are ex-actly an entity itself, which means most of queriesdo have refiner words to convey information need.To ensure the precision of recognized entities, weset a significant threshold and bottom line thresh-old , queries should have at least one recognizedentity with a likelihood above significant level,and those below bottom line are ignored.
Theyare 0.19 and 0.05 in our work, which may varywith entity recognition method.
The normalized3http://tagme.di.unipi.it/1074loca?on?organiza?on?business?book?internet?travel?
film?educa?on?music?sports?government?broadcast?people?computer?
tv?avia?on?celebri?s?
medicine?fic?onal_universe?periodicals?biology?architecture?
cvg?media_common?visual_art?military?automo?ve?influence?food?percentageQuery?set?Test?session?set?Freebase?topics?Freebase?facts?Figure 1: Unbalanced domain distributions in Freebase comparing against query set.
Only domains withtop proportions are shown.Table 2: Examples of labelled intent topic nodes with learned featureIntent topic nodes Original in Freebase After propagation Annotationtravel.yahoo.com Yahoo!
Travel(internet, 0.87),(projects, 0.13)(location, 0.13),(travel, 0.11),(organization, 0.08),(business, 0.08) ...Yahoo!
Travel offerstravel guides, bookingand reservation services.map questwww.mapquest.comMapQuest(organization, 0.6),(book, 0.4)(location, 0.13),(organization, 0.09),(travel, 0.09),(automotive, 0.06)...MapQuest is an Ameri-can free online web map-ping service.likelihood is used as wq(e).
Then we drop ses-sions where tagged entity words weight less thanrefiners as well as the ones with too many entitywords spotted indicating disperse intents.
For eachrecognized entity, only Freebase topics with rele-vance over 0.3 are kept.
The query set we finallyget is shown in Table 1.4.1.2 FreebaseTo enrich query representations, we collect a sub-set of Freebase including more than 7 millionsfacts and 4 millions topics in total which alsocontain 150 thousand topical equivalent websites,though less than 3% urls in query set are covered.The facts and entities in Freebase is rather un-balanced across domains especially against that ofrecoginized entities in query set as shown in Fig-ure 1.
Thus the original global knowledge we useabout domain distribution may cause bias, whichmakes tailoring necessary for intent understand-ing.For both generality and precision, we keep mostof Freebase domains except several extreme in-complete ones, instead of retaining a small numberof representative domains like many researchersdo (Li et al., 2013; Yu et al., 2014; Lin et al.,2012).
But generality comes at a price that somedomains are confusing and mixed used which wethen choose to merge, like celebrities and people,periodicals and books, tv and broadcast, etc.
Wefinally keep 50 of all 76 domains.4.2 Intent topic graph4.2.1 Building the graphWe leverage both Freebase and search sessions toenrich intent topics.
We set ?
to 0.9 in calcula-tion of session?s intent features.
After labelingthe session log, we roughly make a graph with335206 intent topic nodes, 119364 of them havebeen labelled with Freebase topic feature, othersonly have domain feature.
Then we conduct amerge process with ?
set to 0.7, ?
to 0.3 and ?
to0.75 in order to merge nodes with duplicate namesand similar contexts.
We find 46659 duplicate setscovering 140768 nodes.
Then we ignore nodeswith few links and rare names to reduce sparsity.Finally we?ve got a graph of 209351 intent topicsto initialize the propagation, including 78932 la-belled nodes.
The merge and propagation progressget converged in less than 4 rounds.We?ll further evaluate the graph with case studyand a session intent understanding task.4.2.2 Case StudyWe demonstrate intent features are good interpre-tations for query intent, whether they?re labelled inSection 2 or learned by propagation in Section 3.We can see in Table 2 that as nodes?
original1075Table 3: Examples of unlabelled intent topic nodes with learned featureIntent topic node intent features Annotation Similarity nodeswww.bnm.com (The Hertz Corporation, 0.25), (South-west Florida International Airport,0.17), (Punta Gorda Airport, 0.13),(Supercar, 0.09), (Sports car, 0.08)...(aviation, 0.23), (business, 0.21), (lo-cation, 0.14), (automotive, 0.11)...Online bookingof discountrentals at ma-jor airports,worldwide.www.arac.comwww.rentalcars.comwww.hertz.comwww.alamo.comrent a carcheap rental carswww.mobtime.com (Software, 0.18), (Mobile phone,0.11), (100% Totally Free Ringtones,0.10), (Motorola, 0.09), (Free Cell,0.08), (Verizon Wireless, 0.04)...(computer, 0.23), (cvg, 0.21), (music,0.19), (business, 0.11) ...MobTime CellPhone Manageris a PC soft-ware to manageor sync mobilephones.cellphones.about.comcell softwarecell to pcreviews ofcellphone wallpapertypes in Freebase are not proper for describing in-tent, the intent features they get after propagationtend to be more explainable, such as the travelsite often co-occurs with city names, tourist attrac-tions, hotels and so on, thus indicating its intent intravel and location domain.Table 3 shows examples which have no equiv-alents in Freebase.
Although some of them maybe accessible in other ontologies, we only takethem as examples to show our propagation methodmakes it possible to depict intents behind urls andwords in a knowledge graph based way while be-yond the capacity of knowledge graph.4.3 Session intent understanding task4.3.1 Experiment SetupThe evaluation of query understanding has longbeen a challenging task.
To judge whether the con-cepts in query are successfully recognized seemstoo straightforward, and it can hardly be consid-ered understanding the intent until the big ideaabout what kind of topics users emphasis is cap-tured, which can be briefly sketched by distribu-tion across Freebase domains.
Also it is difficult totranslate results of previous log analysis methodsinto knowledge graph domain information, thushardly fit into our evaluation schema.
We takepopularity-based method as baseline.We have few choices but to tag ground truth our-selves for intent understanding evaluation.We randomly select 150 sessions as test set,the domain distribution of which agrees with thewhole query set as shown in Figure 1.
As mas-tering meanings of all Freebase domains is toochallenging, we ask 5 accessors to describe eachsession?s intent broadly with a few natural lan-guage terms, then an expert familiar with Freebaseschema translates the words into matched Free-base domains.
Each test session is tagged by 2accessors and 1 expert, we choose to use the tagsof the cases in which the accessors reached agree-ment as the gold stantard.
For example, if acces-sors tag session intent as pictures, then experts cantranslate it into Freebase visual art domain.
Eachsession has 1?4 tags and 1.6 tags in average.
Thetags cover 30 domains.For each session, we derive the local intent do-main vector dsfollowing the method in Section 2.Here we simply set quality function ?
(r) to a con-stant ?rfor all refiners and?
(c) to ?cfor all clicks,we?ll dive into more specialized weighting methodin future work.
?rand ?care parameters to controlimpact of different kinds of intent topics.
Based onwhether to exploit global intent features of non-entity words, we compare four variations againstone baseline.?
Popularity-based (GP).
We use domains?
fre-quency in the query set as a baseline.?
Entity-based (E).
We only use entity nodes?original intent features without propagation.?
Entity+Clicks (EC).
Both intent features ofentity words and clicks are used, controlledwith ?c.?
Entity+Refiners (ER).
Intent features of en-tity words and refiner words are used, refin-ers?
impact is controlled by ?r.?
Entity+Clicks+Refiners (ECR).
All intenttopics are combined, controlled by ?c, ?r.10760 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 100.10.20.30.40.50.60.70.80.910.6720.6780.6840.6900.6960.7020.7080.7140.720(a) MAP@50 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 100.10.20.30.40.50.60.70.80.910.180.210.240.270.300.330.360.39(b) GMAP@50 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 100.10.20.30.40.50.60.70.80.910.7080.7140.7200.7260.7320.7380.7440.7500.756(c) MAP@100 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 100.10.20.30.40.50.60.70.80.910.3750.4000.4250.4500.4750.5000.5250.5500.575(d) GMAP@10Figure 2: The impact of ?rand ?con ECR methods in four metrics, with vertical axis indicating ?r,horizontal axis as ?c.
The first column on the left denotes ER method, while the bottom row the ECmethod.4.3.2 Evaluation metricsWe use each approach to rank domains accord-ing to its derived weight, then compare it withgolden standard set.
It can be evaluated usingMean Average Precision (MAP), Geometric MAPand Precision@K. We use GMAP because it ismore robust to outliers than the arithmetic mean.For test set of size N , the MAP and GMAP canbe calculated as follows:MAP@k =1NN?i=1APi@k (15)GMAP@k =N???
?N?i=1APi@k (16)4.3.3 Results and analysisWe first study impact of parameters ?rand ?c,which is shown in Figure 2.It roughly demonstrates different combinationsof parameters?
impact on ECR methods, perfor-mance is evaluated in four metrics, with deepercolor indicating better result.Best results comes with a ?clarger than ?rinall four subfigures.
This trend seems more obvi-ous in (d) where right part with larger ?cget betterresults.
Also, deeper colors around diagonal linein (a) (c) indicate a more balanced combinationof refiners and urls are more likely to enhance in-tent understanding.
Thus we conclude clicks has aweak advantage over refiners in improving the re-sult, while combining both with proper parameterscan get the best result.When comparing between MAP and GMAP, wecan see while GMAP stays a high value when am-plifying the impact of clicks, MAP changes withthe variation of ?rfor better or worse.
As GMAPis a more robust metric, we can then infer that in-creasing weight of refiners could bring more out-liers, implying refiners?
intent features are moresusceptible to noise.Then we use ER with ?r= 0.5 as ERopt, ECwith ?c= 0.5 as ECoptand ECR with ?r=0.2, ?c= 0.5 as ECRopt.Figure 3 clearly shows the superior performanceof our model, especially at top positions.
Table 4shows the detailed comparisons between differentmethods.
We can see our knowledge graph basedintent representations perform well in session in-tent understanding.
And refiners?
and clicks?
in-tent features which we learn by propagation con-10770?0.1?0.2?0.3?0.4?0.5?0.6?0.7?0.8?1?
3?
5?
10?
20?
50?Precision@KKGL?E?ER?EC?ECR?Figure 3: Precision@K results for different ap-proaches, by varying number of kTable 4: Comparisons among different methodsK=5 K=10MAP GMAP MAP GMAPGP 0.177 0.000 0.232 0.002E 0.676 0.166 0.707 0.355ECopt0.708 0.412 0.739 0.579ERopt0.688 0.227 0.723 0.421ECRopt0.722 0.412 0.756 0.594tribute a lot to improve naive entity-based method,which do validate an complment effect of theirlearned intent features.5 Related Work5.1 Query intent understandingQuery intent or search intent has been studied in-tensively from various views.A popular paradigm is to label several intentsfor each query, also called facets subgoals andsubtopics in the literature, manully or by min-ing methods and then do classification (Hu et al.,2009; Li et al., 2008) based on that.
Manually in-tent schemas range from 3 top level (Broder, 2002)to fine-grained subcatogories (Rose and Levinson,2004) and taxonomy (Yin and Shah, 2010).
Intenttasks in NTCIR-10 (Sakai et al., 2013) also pro-vide subtopic pools made by accessors.Another view of intent is more generic, min-ing or learning search intents without any kind ofpre-defined intent category and clustering methodis often used.
Methods including (Sadikov et al.,2010; Yamamoto et al., 2012; Cheung and Li,2012) cast intent as represented by a pattern ortemplate consisting of a sequence of semantic con-cepts or lexical items.
(Tan et al., 2012) encodeintent in language models, aware of long-lastinginterests.
(Ren et al., 2014) uses an unsupervisedheterogeneous clustering.
(Yin and Shah, 2010)capture generic intents around a certain named en-tities and model their relationships in a tree tax-onomy and (Wang et al., 2009) mine broad latentmodifiers of intent aspect , which are similar toour motivation, while we model more than intentphrases, but intent topics.
We do not split queriesinto clusters or subtopics relevant to the originalquery to indicate a intent, but link them in an graphwith intent feature similarity, weakly or strongly,in a holistical view.On the other hand, previous research can becategorized by what kind of resources they relyon.
Quite an amount of work leverage query logs(Jiang et al., 2013), including query reformula-tions (Radlinski et al., 2010), click-through data(Li et al., 2008).
There are also works using spon-sered data (Yamamoto et al., 2012) and interactivedata (Ruotsalo et al., 2013).
The new trend of in-tegrating knowledge graph will be discussed next.5.2 Knowledge graph on intentunderstandingInstead of summarizing queries into concepts byclustering, recently there appears a tendency to useconcpets from knowledge graph resources.
Someresearchers manage to build entity graph fromqueries (Bordino et al., 2013a) (Bordino et al.,2013b; Yu et al., 2014), some in a structure view,interpret quries into knowledge base fit template(Pound et al., 2012; Li et al., 2013).
(Pantel et al.,2012) models latent intent to mine entity type dis-tributions.
(Ren et al., 2014) utilizes knowledgegraph resources in a hetrogeneous view.
(Lin etal., 2012) also pays attention to refiners, but re-stricted to limited domains, while our method ismore general.6 ConclusionIn this paper, we tailor knowledge graph to rep-resent query intent behind entity words, refinersand clicked urls in a unified framework, takingthem as intent topic nodes connected in a largegraph.
We manage to get a contextualized intentdepiction exploiting global knowledge in Free-base, then propagate the feature to cover more in-tent topics.
We show in experiments the knowl-edge graph enriched representation is reasonableand explainable, and the intents feature of refinersand clicks can better enhance intent understandingthan methods simply relying on entities.1078There are several directions for future work, in-cluding using both types and domains in Free-base schema, diving into refiners and looking for aproper weighting method, developing a query rec-ommendation framework based on the intent topicgraph and user interest modeling.AcknowledgmentsWe sincerely thank all the anonymous reviewersfor their valuable comments, which have helped toimprove this paper greatly.
This work is supportedby NSFC with Grant No.61370054, and 973 Pro-gram with Grant No.2014CB340405.ReferencesNicholas J Belkin, Robert N Oddy, and Helen MBrooks.
1982.
Ask for information retrieval: Part i.background and theory.
Journal of documentation,38(2):61?71.Ilaria Bordino, Gianmarco De Francisci Morales, Ing-mar Weber, and Francesco Bonchi.
2013a.
Frommachu picchu to rafting the urubamba river: antici-pating information needs via the entity-query graph.In Proceedings of the sixth ACM international con-ference on Web search and data mining, pages 275?284.
ACM.Ilaria Bordino, Yelena Mejova, and Mounia Lalmas.2013b.
Penguins in sweaters, or serendipitous entitysearch on user-generated content.
In Proceedingsof the 22nd ACM international conference on Con-ference on information & knowledge management,pages 109?118.
ACM.Andrei Broder.
2002.
A taxonomy of web search.
SI-GIR Forum, 36(2):3?10, September.Moses S Charikar.
2002.
Similarity estimation tech-niques from rounding algorithms.
In Proceedings ofthe thiry-fourth annual ACM symposium on Theoryof computing, pages 380?388.
ACM.Jackie Chi Kit Cheung and Xiao Li.
2012.
Sequenceclustering and labeling for unsupervised query intentdiscovery.
In Proceedings of the fifth ACM interna-tional conference on Web search and data mining,pages 383?392.
ACM.W Bruce Croft, Michael Bendersky, Hang Li, andGu Xu.
2010.
Query representation and understand-ing workshop.
In SIGIR Forum, volume 44, pages48?53.Paolo Ferragina and Ugo Scaiella.
2012.
Fast andaccurate annotation of short texts with wikipediapages.
IEEE software, 29(1).Jian Hu, Gang Wang, Fred Lochovsky, Jian-tao Sun,and Zheng Chen.
2009.
Understanding user?s queryintent with wikipedia.
In Proceedings of the 18thinternational conference on World wide web, pages471?480.
ACM.Piotr Indyk and Rajeev Motwani.
1998.
Approxi-mate nearest neighbors: towards removing the curseof dimensionality.
In Proceedings of the thirtiethannual ACM symposium on Theory of computing,pages 604?613.
ACM.Daxin Jiang, Jian Pei, and Hang Li.
2013.
Miningsearch and browse logs for web search: A survey.ACM Trans.
Intell.
Syst.
Technol., 4(4):57:1?57:37,October.Xiao Li, Ye-Yi Wang, and Alex Acero.
2008.
Learn-ing query intent from regularized click graphs.
InProceedings of the 31st Annual International ACMSIGIR Conference on Research and Development inInformation Retrieval, SIGIR ?08, pages 339?346,New York, NY, USA.
ACM.Yanen Li, Bo-June Paul Hsu, and ChengXiang Zhai.2013.
Unsupervised identification of synonymousquery intent templates for attribute intents.
In Pro-ceedings of the 22nd ACM international conferenceon Conference on information &#38; knowledgemanagement, CIKM ?13, pages 2029?2038, NewYork, NY, USA.
ACM.Thomas Lin, Patrick Pantel, Michael Gamon, AnithaKannan, and Ariel Fuxman.
2012.
Active objects:Actions for entity-centric search.
In Proceedingsof the 21st international conference on World WideWeb, pages 589?598.
ACM.Patrick Pantel, Thomas Lin, and Michael Gamon.2012.
Mining entity types from query logs via userintent modeling.
In Proceedings of the 50th An-nual Meeting of the Association for ComputationalLinguistics: Long Papers-Volume 1, pages 563?571.Association for Computational Linguistics.Jeffrey Pound, Alexander K Hudek, Ihab F Ilyas, andGrant Weddell.
2012.
Interpreting keyword queriesover web knowledge bases.
In Proceedings of the21st ACM international conference on Informationand knowledge management, pages 305?314.
ACM.Filip Radlinski, Martin Szummer, and Nick Craswell.2010.
Inferring query intent from reformulationsand clicks.
In Proceedings of the 19th internationalconference on World wide web, pages 1171?1172.ACM.Xiang Ren, Yujing Wang, Xiao Yu, Jun Yan, ZhengChen, and Jiawei Han.
2014.
Heterogeneous graph-based intent learning with queries, web pages andwikipedia concepts.
In Proceedings of the 7th ACMInternational Conference on Web Search and DataMining, WSDM ?14, pages 23?32, New York, NY,USA.
ACM.Daniel E. Rose and Danny Levinson.
2004.
Un-derstanding user goals in web search.
In Proceed-ings of the 13th International Conference on World1079Wide Web, WWW ?04, pages 13?19, New York, NY,USA.
ACM.Tuukka Ruotsalo, Jaakko Peltonen, Manuel Eugster,Dorota G?owacka, Ksenia Konyushkova, Kumari-paba Athukorala, Ilkka Kosunen, Aki Reijonen,Petri Myllym?aki, Giulio Jacucci, et al.
2013.
Di-recting exploratory search with interactive intentmodeling.
In Proceedings of the 22nd ACM interna-tional conference on Conference on information &knowledge management, pages 1759?1764.
ACM.Eldar Sadikov, Jayant Madhavan, Lu Wang, and AlonHalevy.
2010.
Clustering query refinements by userintent.
In Proceedings of the 19th international con-ference on World wide web, pages 841?850.
ACM.Tetsuya Sakai, Zhicheng Dou, Takehiro Yamamoto,Yiqun Liu, Min Zhang, Ruihua Song, MP Kato, andM Iwata.
2013.
Overview of the ntcir-10 intent-2task.
Proceedings of NTCIR-10, pages 94?123.Bin Tan, Yuanhua Lv, and ChengXiang Zhai.
2012.Mining long-lasting exploratory user interests fromsearch history.
In Proceedings of the 21st ACM in-ternational conference on Information and knowl-edge management, pages 1477?1481.
ACM.Xuanhui Wang, Deepayan Chakrabarti, and KunalPunera.
2009.
Mining broad latent query aspectsfrom search sessions.
In Proceedings of the 15thACM SIGKDD international conference on Knowl-edge discovery and data mining, pages 867?876.ACM.Takehiro Yamamoto, Tetsuya Sakai, Mayu Iwata, ChenYu, Ji-Rong Wen, and Katsumi Tanaka.
2012.
Thewisdom of advertisers: mining subgoals via queryclustering.
In Proceedings of the 21st ACM inter-national conference on Information and knowledgemanagement, pages 505?514.
ACM.Xiaoxin Yin and Sarthak Shah.
2010.
Building taxon-omy of web search intents for name entity queries.In Proceedings of the 19th international conferenceon World wide web, pages 1001?1010.
ACM.Xiao Yu, Hao Ma, Bo-June (Paul) Hsu, and Jiawei Han.2014.
On building entity recommender systems us-ing user click log and freebase knowledge.
In Pro-ceedings of the 7th ACM International Conferenceon Web Search and Data Mining, WSDM ?14, pages263?272, New York, NY, USA.
ACM.Xiaojin Zhu and Zoubin Ghahramani.
2002.
Learningfrom labeled and unlabeled data with label propa-gation.
Technical report, Technical Report CMU-CALD-02-107, Carnegie Mellon University.Xiaojin Zhu, Zoubin Ghahramani, John Lafferty, et al.2003.
Semi-supervised learning using gaussianfields and harmonic functions.
In ICML, volume 3,pages 912?919.1080
