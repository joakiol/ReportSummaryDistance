The TIGER 700 RMRS Bank:RMRS Construction from DependenciesKathrin SpreyerComputational Linguistics DepartmentSaarland University66041 Saarbru?cken, Germanykathrins@coli.uni-sb.deAnette FrankLanguage Technology LabDFKI GmbH66123 Saarbru?cken, Germanyfrank@dfki.deAbstractWe present a treebank conversionmethod by which we construct anRMRS bank for HPSG parser evalu-ation from the TIGER DependencyBank.
Our method effectively per-forms automatic RMRS semanticsconstruction from functional depen-dencies, following the semantic alge-bra of Copestake et al (2001).
Wepresent the semantics constructionmechanism, and focus on some spe-cial phenomena.
Automatic conver-sion is followed by manual valida-tion.
First evaluation results yieldhigh precision of the automatic se-mantics construction rules.1 IntroductionTreebanks are under development for manylanguages.
They are successfully exploited forthe induction of treebank grammars, train-ing of stochastic parsers, and for evaluat-ing and benchmarking competitive parsingand grammar models.
While parser evalu-ation against treebanks is most natural fortreebank-derived grammars, it is extremelydifficult for hand-crafted grammars that rep-resent higher-level functional or semantic in-formation, such as LFG or HPSG grammars.In a recent joint initiative, the TIGERproject provides dependency-based treebankrepresentations for German, on the basis ofthe TIGER treebank (Brants et al, 2002).Forst (2003) applied treebank conversionmethods to the TIGER treebank, to derivean f-structure bank for stochastic training andevaluation of a German LFG parser.
A moretheory-neutral dependency representation iscurrently derived from this TIGER-LFG tree-bank for cross-framework parser evaluation(Forst et al, 2004).
However, while Penn-treebank style grammars and LFG analysesare relatively close to dependency represen-tations, the output of HPSG parsing is diffi-cult to match against such structures.
HPSGanalyses do not come with an explicit repre-sentation of functional structure, but directlyencode semantic structures, in terms of (Ro-bust) Minimal Recursion Semantics (hence-forth (R)MRS.1 This leaves a gap to bebridged in terms of the encoding of argu-ments vs. adjuncts, the representation of spe-cial constructions like relative clauses, andnot least, the representation of quantifiers andtheir (underspecified) scoping relations.In order to bridge this gap, we constructan RMRS ?treebank?
from a subset of theTIGER Dependency Bank (Forst et al, 2004),which can serve as a gold standard for HPSGparsing for evaluation, and for training ofstochastic HPSG grammar models.
In con-trast to treebanks constructed from analysesof hand-crafted grammars, our treebank con-1RMRS (Copestake, 2003) is a formalism for par-tial semantic representation that is derived from MRS(Copestake et al, 2005).
It is designed for the in-tegration of semantic representations produced byNLP components of different degrees of partiality anddepth, ranging from chunk parsers and PCFGs to deepHPSG grammars with (R)MRS output.1version approach yields a standard for com-parative parser evaluation where the upperbound for coverage is defined by the corpus(here, German newspaper text), not by thegrammar.Our method for treebank conversion effec-tively performs priniciple-based (R)MRS se-mantics construction from LFG-based depen-dency representations, which can be extendedto a general parsing architecture for (R)MRSconstruction from LFG f-structures.The remainder of this paper is organisedas follows.
Section 2 introduces the inputdependency representations provided by theTIGER Dependency Bank, and describes themain features of the term rewriting machinerywe use for treebank conversion, i.e., RMRS se-mantics construction from dependency struc-tures.
Section 3 presents the core of the se-mantics construction process.
We show howto adapt the construction principles of the se-mantic algebra of Copestake et al (2001) toRMRS construction from dependencies in arewrite scenario, and discuss the treatment ofsome special phenomena, such as verbal com-plementation, coordination and modification.Section 4 reports on the treebank construc-tion methodology, with first results of qualitycontrol.
Section 5 concludes.2 From TIGER Dependency Bankto TIGER RMRS Bank2.1 The TIGER Dependency BankThe input to the treebank conversion pro-cess consists of dependency representationsof the TIGER Dependency Bank (TIGER-DB).
The TIGER-DB has been derived semi-automatically from (a subset of) the TIGER-LFG Bank of Forst (2003), which is in turnderived from the TIGER treebank.
The de-pendency format is similar to the Parc 700Dependency Bank (King et al, 2003).
It ab-stracts away from constituency in order to re-main as theory-neutral as possible.
So-calleddependency triples are sets of two-place pred-icates that encode grammatical relations, thearguments representing the head of the depen-dency and the dependent, respectively.
Thesb(mu?ssen~0, Museum~1)oc inf(mu?ssen~0, weichen~3)mood(mu?ssen~0, ind)tense(mu?ssen~0, pres)mod(Museum~1, privat~1001)cmpd lemma(Museum~1, Privatmuseum)case(Museum~1, nom)gend(Museum~1, neut)num(Museum~1, sg)sb(weichen~3, Museum~1)Figure 1: TIGER dependency representationof sentence #8595: Privatmuseum muss wei-chen ?
Private museum deemed to vanish.triples further retain a number of morpholog-ical features from the LFG representations,such as agreement features or tense informa-tion.
Figure 1 displays an example.For the purpose of RMRS construction, thetriples format has advantages and disadvan-tages.
The LFG-derived dependencies offerall the advantages of a functional as opposedto a constituent-based representation.
Thisrepresentation already filters out the seman-tically inappropriate status of auxiliaries asheads; their contribution is encoded by fea-tures such as perf or fut, which can bedirectly translated into features of semanticevent variables.
Most importantly, the tripleslocalise dependencies which are not locally re-alised in phrase structure (as in long-distanceconstructions), so that there is no need foradditional mechanisms to identify the argu-ments of a governing predicate.
Moreover,the dependency representation format is to alarge extent uniform across languages, in con-trast to phrase-structural encoding.
There-fore, the dependency-based semantics con-struction mechanism can be quickly ported toother languages.The challenges we face mainly concern alack of specific types of phrase structure in-formation that are crucial for RMRS compo-sition.
Linear precedence, e.g., plays a crucialrole when it comes to multiple modification orcoordination.
Yet, it is possible to reconstructthe surface order from the indices attached tothe Pred values in the triples.
Part-of-speechinformation, which is useful to trigger differ-ent types of semantics construction rules, canbe induced from the presence or absence of2certain morphological features, yet to a lim-ited extent.For our current purpose of treebank con-version, we are dependent on the specific in-put format of the TIGER-DB, while in a moregeneral parsing context, one could ensure thatmissing information of this type is included inthe input to semantics construction.2.2 Treebank ConversionSimilar to the TIGER to TIGER-DB conver-sion (Forst, 2003; Forst et al, 2004), we areusing the term rewriting system of Crouch(2005) for treebank conversion.
Originally de-signed for machine translation, the system is apowerful rewriting tool that has been appliedto other tasks, such as frame semantics con-struction (Frank and Erk, 2004), or inductionof knowledge representations (Crouch, 2005).The input to the system consists of aset of facts in a prolog-like term representa-tion.
The rewrite rules refer to these facts inthe left-hand side (LHS), either conjunctively(marked by ?,?)
or disjunctively (marked by?|?).
Expressions on the LHS may be negated(by prefix ?-?
), thereby encoding negative con-straints for matching.
A rule applies if andonly if all facts specified on the LHS are satis-fied by the input set of facts.
The right-handside (RHS) of a rewrite rule defines a conjunc-tion of facts which are added to the input setof facts if the rule applies.
The system furtherallows the user to specify whether a matchedfact will be consumed (i. e., removed from theset of facts) or whether it will be retained inthe output set of facts (marked by prefix ?+?
).2The system offers powerful rule encodingfacilities in terms of macros and templates.Macros are parameterized patterns of (possi-bly disjunctive) facts; templates are parame-terized abstractions over entire (disjunctive)rule applications.
These abstraction meanshelp the user to define rules in a perspiciousand modular way, and significantly enhance2The system additionally features optional rules(??=>?
), as opposed to deterministic rewriting (?==>?
).However, given that the input structures for RMRSconstruction are disambiguated, and since our targetstructures are underspecified semantic structures, wecan define the semantics deterministically.the maintainability of complex rule sets.The processing of rules is strictly ordered.The rules are applied in the order of textualappearance.
Each rule is tested against thecurrent input set of facts and, if it matches,produces an output set of facts that providesthe input to the next rule in sequence.
Eachrule applies concurrently to all distinct sets ofmatching facts, i.e.
it performs parallel appli-cation in case of alternative matching facts.3 RMRS Construction fromDependenciesWithin the framework of HPSG, every lex-ical item defines a complete (R)MRS struc-ture.
The semantic representation of a phraseis defined as the assembly and combinationof the RMRSs of its daughters, according tosemantic constraints, which apply in parallelwith syntactic constraints.
In each compo-sition step, the RMRSs of the daughters arecombined according to semantic compositionrules that define the semantic representationof the phrase, cf.
(Copestake et al, 2005).
Fol-lowing the scaffolding of the syntactic struc-ture in this way finally yields the semantics ofthe sentence.For the present task, the input to semanticsconstruction is a dependency structure.
Asestablished by work on Glue Semantics (Dal-rymple, 1999), semantics construction fromdependency structures can in similar waysproceed recursively, to deliver a semantic pro-jection of the sentence.
Note, however, thatthe resource-based approach of Glue Seman-tics leads to alternative derivations in case ofscope ambiguities, whereas RMRS targets anunderspecified semantic representation.For (R)MRS construction from dependen-cies we follow the algebra for semantics com-position in Copestake et al (2001).
In HPSGimplementations of this algebra, compositionis triggered by phrasal configurations.
Yet,the algebra is neutral with regard to the syn-tactic representation, and can be transposedto composition on the basis of dependency re-lations, much alike the Glue framework.However, the rewriting system we are usingis not suited for a typical recursive application3scheme: the rules are strictly ordered, andeach rule simultaneously applies to all factsthat satisfy the constraints in the LHS.
Thatis, the RMRS composition cannot recursivelyfollow the composition of dependents in theinput structure.
In section 3.2 we present adesign of RMRS that is suited for this con-current application scheme.
Before, we brieflysketch the semantic algebra.3.1 An Algebra for SemanticConstructionCopestake et al (2001) define a semantic en-tity as a 5-tuple ?s1, s2, s3, s4, s5?
such thats1 is a hook, s2 is a (possibly empty) set ofholes, s3 and s4 are bags of Elementary Pred-ications (EPs) and handle constraints, respec-tively, and s5 is a set of equalities holding be-tween variables.
The hook is understood torepresent the externalised part of the seman-tic entity as a pair of a handle and an index(a variable).
It is used for reference in compo-sition: Hooks of semantic arguments fill holes(or slots) of functors.
Holes, in turn, recordgaps in a semantic representation which re-main to be filled.
They, too, are pairs of ahandle and an index; furthermore, holes arelabelled with the grammatical function theybear syntactically.
That is, the labels on holesserve two purposes: They help determine theappropriate operation of composition (see be-low), and they link the semantics to syntax.3EPs (predicate applications) represent thebinding of argument variables to their predi-cators.
An EP h : r(a1, .
.
.
, an, sa1, .
.
.
, sam)consists of the EP?s handle (or label) h, arelation r, and a list of zero or more vari-able arguments a1, .
.
.
, an, followed by zero ormore scopal arguments sa1, .
.
.
, sam (denot-ing handles) of the relation.
Finally, the bag3Copestake et al (2001) mention a third feature tobe included in the hook as an externally visible vari-able, which they instantiate with the index of the con-trolled subject in equi constructions and which is alsoused to implement the semantics of predicative modifi-cation.
However, this feature is not crucial given thatthe underlying syntactic structures represent depen-dencies rather than immediate dominance relations,and therefore make non-local information available lo-cally.
Likewise, the dependency scenario does not ne-cessitate that modifiers externalise their ARG1 argu-ment position (see section 3.3.3).of handle constraints (Hcons) contains con-ditions which (partially) specify the relationsbetween scopal arguments and their scope, i.e.between the scopal argument and the handlesthat may fill the hole.The operators of semantic compositionopl1 , .
.
.
, oplk are drawn from ?
?
?
?
?,where ?
is the set of all semantic entities, andl1, .
.
.
, lk correspond to the labels on holes:An operator opli defines the composition ofa semantic head which has a hole labelled liwith the argument filling that hole as follows:The result of opli(a1, a2) is undefined if a2 hasno hole labelled li, otherwise:1. hook(opli(a1, a2)) = hook(a2);2.
holesl?
(opli(a1, a2)) = holesl?
(a1) ?holesl?
(a2) for all labels l?
6= li;3. eps(opli(a1, a2)) = eps(a1)?
eps(a2);4. eqs(opli(a1, a2)) = Tr(eqs(a1)?
eqs(a2)?
{hook(a1) = holeli(a2)}); where Trstands for the transitive closure.3.2 RMRS DesignAs mentioned earlier, the concurrent nature ofrule application makes it impossible to pro-ceed recursively in a scaffolding way, inher-ent to tree-based analyses, since the rules ap-ply simultaneously to all structures.
RMRSconstruction is therefore designed around onedesignated ?global?
RMRS.
Instead of pro-jecting and accumulating RMRS constraintsstep-wise by recursive composition, we di-rectly insert the meaning descriptions into asingle global RMRS.
Otherwise, compositionstrictly follows the semantic operations of thealgebra of Copestake et al (2001): the compo-sition rules only refer to the hook and slots offunctors and arguments, to achieve the bind-ing of argument variables and the encoding ofscope constraints.Global and Lexical RMRSs.
The globalRMRS features a top handle (Top, usuallythe label of the matrix proposition), sets ofEPs (Rels) and handle constraints (Hcons),respectively, as described in the algebra, anda set of Ing constraints.44Whenever two labels are related via an Ing (in-group) constraint, they can be understood to be con-4+pred(X,Pred),-mo( ,X), -spec( ,X),+?s::?
(X,SemX), +hook(SemX,Hook)==> lb(Hook,Lb), var(Hook,Var)&& add ep(Lb,ep rel,rel,Pred)&& add ep(Lb,ep arg0,arg0,Var).lexical RMRS: [Hook[Lb LbVar Var]]global RMRS: ??????Rels???.
.
.,[Pred nLb LbArg0 Var], .
.
.???Hcons{.
.
.}Ing{.
.
.}?????
?Figure 2: A rule for nominals (top) with re-sulting lexical and global RMRS (bottom).In addition, every predicate in the depen-dency structure projects a lexical RMRS.
Lex-ical RMRSs are semantic entities which con-sist of only a hook (i.e.
a label and a variable),that makes the entity available for referenceby subsequent (composition) rules, whereasthe basic semantic content (which is deter-mined on the basis of the predicate?s category,and comprises, at least, EPs for the relationand the ARG0)5 is uniformly maintained inthe bags of the global RMRS, yet still an-chored to the lexical hook labels and variables.Figure 2 shows an example of a lexicalRMRS with its links to the global RMRS, anda simplified version of the corresponding rule:The rule applies to predicates, i.e.
pred fea-tures, with a value Pred.
It introduces thelexical RMRS, i.e., the hook?s label and vari-able, and adds the predicate?s basic semanticcontent to the global RMRS, here the relationrepresented by Pred and the ARG0 variable,which is co-referent with the hook?s variable.Composition.
The semantic compositionof arguments and functors is driven by thepredicate arg(Fctor,N,Arg), where N en-codes the argument position, Fctor and Argare indices of functor and argument, respec-joined.
This is relevant, e.g., for intersective modifi-cation, since a quantifier that outscopes the modifiednoun must also take scope over the modifier.5The category information required to define theconcrete basic semantics is not explicit in the depen-dencies, but is induced from the grammatical functionborne by the predicate, as well as the presence or ab-sence of certain morphological features (section 2.1).+arg(X,2,Arg), +g f(Arg,?oc fin?
),+comp form(Arg,dass)get lb(X,LbX), get lb(Arg,LbA)==> sort(Lb,h), sort(LbP,h)&& add ep(LbX,ep arg2,argx,LbP)&& add ep(LbP,ep rel,rel,?prpstn m rel?
)&& add ep(LbP,ep arg0,arg0,Lb)&& add qeq(Lb,LbA).lexical RMRSs:X:[Hook[Lb LbX]]Arg:[Hook[Lb LbA]]global RMRS:?????Rels???..,?
?X vLb LbXArg2 LbP??,?
?prpstn m relLb LbPArg0 Lb?
?,[Arg vLb LbA],..???Hcons{.
.
., Lb qeq LbA , .
.
.}????
?Figure 3: Sample argument binding rule trig-gered by arg(X,2,Arg) (top), referred lexicalRMRSs and resulting global RMRS (bottom).tively.6 We interpret the arg-predicate as aslot/hole of the functor, such that the bindingof the argument to the functor comes downto filling the hole, in the sense of the alge-bra described above: This is steered by thepreviously defined hooks of the two semanticentities, in that the matching rule introducesan EP with an attribute ARGN that is an-chored to the externalised label in the func-tor?s hook.
The value of the attribute ARGNis the hook variable or hook label of the argu-ment, depending on the category.
A slightlymore complicated example is shown in Figure3, it involves the introduction of an additionalproposition and a scope constraint.
This ruleperforms the composition of a declarative fi-nite clausal object (oc fin) with its verbalhead.
It assigns a proposition relation as thevalue of the verb?s ARG2, which in turn hasan ARG0 that takes scope over the hook labelof the matrix verb in the object clause.In general, composition does not depend onthe order of rule applications.
That is, thefact that the system performs concurrent rule6The arg predicates are introduced by a set ofpreprocessing rules which reconstruct the argumentstructure by referring to the local grammatical func-tions of a predicate and testing for (morphological)features typically borne by non-arguments.
E.g.,pron type( ,expl) identifies an expletive pronoun.5????????Rels?????????.
.
.,???
?wissen vLb hArg0 eArg1 xArg2 1????,???
?versammeln vLb 1Arg0 eArg1 2Arg2 x????,???
?pronoun q relLb hArg0 2Rstr 3Body h???
?,[pron null uLb 4Arg0 2], .
.
.?????????Hcons{.
.
., 3 qeq 4 , .
.
.}???????
?Figure 4: Control analysis with unspecified coreference in [.
.
.
], als so gut wie er kaumein anderer die Studentenmassen [.
.
.]
zu versammeln wu?te.
?
[.
.
.]
when hardly anybodyknew how to rally the crowd of students [.
.
.]
as well as he did.
(from corpus sentence # 8074).applications in a cascaded rule set is not prob-lematic for semantics construction.
Though,we have to ensure that every partial structureis assigned a hook, prior to the application ofcomposition rules.
This is ensured by statingthe rules for lexical RMRSs first.Scope constraints.
By introducing handleconstraints, we define restrictions on the pos-sible scoped readings.
This is achieved bygradually adding qeq relations to the globalHcons set.
Typically, this constraint relatesa handle argument of a scopal element, e.g.
aquantifier, and the label of the outscoped el-ement.
However, we cannot always fully pre-dict the interaction among several scoping el-ements.
This is the case, inter alia, for themodification of verbs by more than one scopaladverb.
This ambiguity is modeled by meansof a UDRT-style underspecification, that is,we leave the scope among the modifiers un-specified, but restrict each to outscope theverb handle.73.3 Selected Phenomena3.3.1 Verbal complements.The treebank distinguishes three kinds of ver-bal complements: infinitival phrases goveredby a raising verb or by a control verb, andfinite clausal arguments.Infinitival complements.
Raising verbsdo not assign an ARG1, and the infinitival ar-gument is bound via an additional propositionwhich fills the ARG2 position of the governor.A handle constraint requires the proposition7This is in accordance with the German HPSGgrammar of Crysmann (2003), and will also beadapted in the ERG (p.c.
D. Flickinger).to take scope over the label of the infinitive.Modal verbs lend themselves most naturallyto the same analysis, by virtue of identicalannotation in the dependency triples.The implementation of RMRS for equiconstructions relies on external lexicon re-sources, since the underlying dependencystructures do not encode the coreference be-tween the controlled subject and the exter-nal controller.
Instead, the controlee is anno-tated as a null pronoun.
In order to differ-entiate subject from object control, we enrichthe transfer input with a list of static factss_control(Pred) and o_control(Pred), re-spectively, which we extracted from the Ger-man HPSG grammar (Crysmann, 2003).
Therules refer to these facts, and establish the ap-propriate bindings.
If no information aboutcoreference is available (due to sparse lexicaldata), the controlled subject appears in theRMRS as an unbound pronoun, as assumedin the syntactic structure.
This is shown inFig.
4.
In the manual correction phase, thesecases are corrected in the output RMRS, byintroducing the missing control relation.Finite complements.
For finite clausalcomplements we assume the basic analysis il-lustrated in section 3.2.
But finite clauses arenot necessarily declarative, they can also haveinterrogative meaning.
In RMRS, this dis-tinction is typically drawn in a type hierarchy,of which we assume a simplified version:message m relprop ques m rel imp m relprpstn m rel int m relGerman embedded clauses are usually markedby one of the complementizers dass (that)6?????????????????????Rels?????????????????????????????????.
.
.,????
?def q relLb 10Arg0 4Rstr 7Body h????
?,[Achtung nLb 1Arg0 4],???????
?und cLb hArg0 xL hndl 13R hndl 16L index 4R index 17????????,???????
?implicit conj relLb 16Arg0 17L hndl 14R hndl 15L index 5R index 6????????,????
?def q relLb 11Arg0 5Rstr 8Body h????
?,[Zuneigung nLb 2Arg0 5],????
?def q relLb 12Arg0 6Rstr 9Body h????
?,[Liebe nLb 3Arg0 6], .
.
.?????????????????????????????????Hcons{.
.
., 7 qeq 1 , 8 qeq 2 , 9 qeq 3 , 13 qeq 10 , 14 qeq 11 , 15 qeq 12 , .
.
.}????????????????????
?Figure 5: RMRS for the coordinate NP ihre Achtung, ihre Zuneigung und Liebe ?
their esteem,their affection and love (from corpus sentence # 8345).or ob (whether), in initial position, butmay occur without it, though less fre-quently.
If a complementizer is present,this is recorded as comp_form(_,dass) (resp.comp_form(_,ob)), and we can fully deter-mine the kind of message relation from itslexical form, i.e., prpstn m rel for declar-ative and int m rel for interrogative ones.In the absence of an overt complementizer,we could introduce the underspecified typeprop ques m rel, but rather chose to use adefault rule for the declarative reading prp-stn m rel, which occurs far more often.
Thisreduces the manual correction effort.3.3.2 CoordinationThe HPSG analysis of coordinate structurestakes the form of a binary, right-branchingstructure.
Since semantics construction inHPSG proceeds along this tree, an RMRS fora coordinate phrase likewise mirrors the recur-sive organisation of conjuncts in the syntax.Each partial coordination introduces an im-plicit conj rel, while the meaning contributedby the lexical conjunction is conveyed in theEP which spans the entire coordination.By contrast, the dependency structurespreserve the flat LFG-analysis of coordina-tion as a set of conjuncts.
To overcome thisdiscrepancy between source and target struc-tures, we define specialised rules that mimicrecursion in that they process the conjunctsfrom right to left, two at a time, thereby build-ing the desired, binary-structure semantics forthe coordination.
Fig.
5 shows a sample out-put RMRS for coordinated NPs.8 Note thatwe posit the L/R hndl handle arguments tooutscope each label that takes scope over thenoun.
This accounts for scope ambiguitiesamong quantifiers and scopal adjectives.3.3.3 Recursive ModificationThe algebra of Copestake et al (2001) de-fines modifiers to externalise the variable ofthe ARG1.
This, however, runs into problemswhen a construction needs to incorporate theinherent event variable (ARG0) of a modifieras an argument, as e.g.
in recursive modifica-tion.
In these cases, the ARG0 variable is notaccessible as a hook for composition.In contrast, we identify the hook vari-able of modifiers with their ARG0 variable.This enables a uniform account of recur-sive intersective modification, since the in-herent variable is legitimatly accessible viathe hook, whereas the ARG1?like any otherargument?is bound in a slot-filling opera-tion.9 The corresponding rule and an exampleoutput RMRS are displayed in Fig.
6: When-ever the dependency relation mo is encoun-tered, no matter what the exact pred value,the semantics contributed by the head of the8The semantic contribution of the possessive pro-nouns has been neglected for ease of exposition.9Similarly, this treatment of modification correctlyaccounts for modification in coordination structures,as in the NP ihrer munteren und farbenfreudigen In-szenierung ?
of her lively and colourful production(from corpus sentence # 9821).7+mo(X,M), +pred(M,Pred),-scopal(Pred),+?s::?
(M,SemM), +hook(SemM,Hook),+lb(Hook,LbM),get var(X,VarX), get lb(X,LbX)==> var(Hook,VarM)&& add ep(LbM,ep rel,rel,Pred)&& add ep(LbM,ep arg0,arg0,VarM)&& add ep(LbM,ep arg1,argx,VarX)&& add ing(LbM,LbX).??????????????Rels???????????????????.
.
.,??
?liegen vLb 1Arg0 2Arg1 x???,??
?hoch rLb 3Arg0 4Arg1 2???,??
?sehr rLb 5Arg0 eArg1 4??
?, .
.
.???????????????????Ing{.
.
., 3 ing 1 , 5 ing 3 , .
.
.}?????????????
?Figure 6: Rule defining the lexical RMRS formodifiers (top), resulting global RMRS forthe recursive modification in liege [.
.
.]
sehrhoch ?
[.
.
.]
is at a very high level (from cor-pus sentence # 8893).dependency can be unambiguously identifiedas the argument of the semantic head.
In fact,given that modifiers are in this way locallyannotated as mo dependents in the triples, wecan bind the ARG1 already when defining thelexical RMRS of the modifier.4 The TIGER 700 RMRS Bank4.1 Design and methodologyTreebank Design.
Our aim is to make avai-lable manually validated RMRS structures for700 sentences of the TIGER-DB.
Since theunderlying data is contiguous newspaper text,we chose to select a block of consecutive sen-tences instead of a random sample.
In thisway, the treebank can be further extendedby annotation of intersentential phenomena,such as co-reference or discourse relations.However, we have to accommodate for gaps,due to sentences for which there are rea-sonable functional-syntactic, but (currently)no sound semantic analyses.
This problemarises for sentences involving, e.g., ellipticalconstructions, or else ungrammatical or frag-mented sentences.
We will include, but ex-plicitly mark such sentences for which we canonly obtain partial, but no fully sound seman-tic analyses.
We will correspondingly extendthe annotation set to yield a total of 700 cor-rectly annotated sentences.The composition rules are designed torecord their application by way of rule-specificidentifiers.
These may serve as a filteringmeans in case the analysis of certain phenom-ena as assumed in the treebank is incompati-ble with the grammar to be evaluated.Quality Control.
For compilation of amanually controlled RMRS bank, we imple-mented a cascaded approach for quality con-trol, with a feedback loop between (i) and (ii):(i) Manual sample-based error-detection.We are using the application markers ofspecific construction rules to select sampleRMRSs for phenomenon-based inspection, aswell as random sampling, in order to detectproblems that can be corrected by adjust-ments of the automatic conversion procedure.
(ii) Adjustment of conversion rules.
Theconstruction rules are modified to adjust er-rors detected in the automatic conversion pro-cess.
Errors that cannot be covered by generalrules need to be manually corrected in (iii).
(iii) Manual control.
Finally, we performmanual control and correction of errors thatcannot be covered by automatic RMRS con-struction.
Here, we mark and separate thephenomena that are not covered by the state-of-the-art in RMRS-based semantic theory.Viewing and editing support.
The in-spection of RMRSs is supported by convert-ing the underlying XML format to HTML.RMRSs can thus be comfortably viewed ina browser, with highlighting of coreferences,display of agreement features, and links ofEPs to the surface forms they originated from.Correction is supported by an XSLT-basedinteractive editing tool.
It enables the user tospecify which EPs, arguments or constraintsare to be added/removed.
With each change,the HTML representation is updated, so thatthe result is immediately visible for verifica-tion.
The tool features a simple mechanismfor version maintenance and retrieval, and8avg # ofabs # in % corrections/sent.validated 700 100 2.24odd 28 4fully perfect 281 40.14 0corrected 419 59.86 3.75<5 corrections 601 85.86 0.96avg # ofabs # in % corrections/sent.validated 100 100 1.3odd 5 5fully perfect 68 68 0corrected 32 32 4.2<5 corrections 88 88 0.44Table 1: Evaluation of current data set forcomplete correction (top) and for correctionignoring part-of-speech (bottom).separate storage for fully validated structures.4.2 First ResultsThe transfer grammar comprises 74 rewriterules for converting dependency structures toRMRS, plus 34 macros and templates.In a first validation experiment on the ba-sis of 100 structures, we classified 20% of theRMRSs as involving errors that can be cap-tured by adjustments of the automatic con-version rules (see step (ii) above), while 59%were fully correct.10After improvement of the rules we evalu-ated the quality of the automatic constructionprocedure by validating the 700 sentences ofthe treebank.
Average counts for this sam-ple are 15.57 tokens/sentence, 15.92 depen-dencies/sentence.
Table 1 (top) summarisesthe results.
Of the 700 structures, 4% con-tained phenomena which we do not analyse atall.
40% required no correction at all.
For the59% that needed manual correction, the aver-age count of units to be corrected per sentencewas 3.75.
The number of RMRSs that neededless than the average of corrections was 601,i.e.
85.86%.
The time needed for inspectionand correction was 5 mins 12 secs/sentence,calculated on the entire data set.Error analysis.
A large portion of the er-rors did not concern the RMRS as such, but10This evaluation did not perform correction of part-of-speech tags (cf.
below, error analysis).simply the part-of-speech tags, encoded in therelation names.
If part-of-speech errors areignored, the number of correct RMRSs in-creases from 41% to 68%.
The results of vali-dation without part-of-speech correction, cal-culated on a third sample of 100 sentences,are given in Table 1 (bottom).Significant structural errors arise primarilyin the context of modification.
This is dueto the TIGER annotation scheme.
For exam-ple, certain adjunct clauses are embedded inmain clauses as mo dependents, yet the em-bedding conjunction is, again, annotated as amodifier of the embedded clause.
This leadsto erroneous analyses.
Refinement of the rulescould considerably improve accuracy, but dis-tinguishing these cases from ordinary modifi-cation is not always possible, due to missingcategory information.While modifiers turned out challenging inthe mapping from dependencies to semantics,we did not observe many errors in the treat-ment of arguments: the rules that map de-pendents to semantic arg predicates yield avery precise argument structure.5 ConclusionWe presented a method for semantics con-struction that converts dependency structuresto RMRSs as they are output by HPSG gram-mars.
By applying this method to the TIGERDependency Bank, we construct an RMRSBank that allows cross-framework parser eval-uation for German.
Our method for RMRSconstruction can be transposed to dependencybanks for other languages, such as the PARC700 Dependency Bank for English (King etal., 2003).
The choice of RMRS also ensuresthat the semantic bank can be used for com-parative evaluation of HPSG grammars withlow-level parsers that output partial seman-tics in terms of RMRS, such as the RASPparser of Carroll and Briscoe (2002).While the formalism of (R)MRS has its ori-gins in HPSG, we have shown that RMRS se-mantics construction can be carried over todependency-based frameworks like LFG.
Infuture research, we will investigate how thesemantic algebra of Copestake et al (2001)9compares to Glue Semantics (Dalrymple,1999).
Our construction rules may in fact bemodified and extended to yield semantics con-struction along the lines of Glue Semantics,with hooks as resources and Rels, Hconsand Ing sets as meaning language.
In this sce-nario, the composition rules would consumethe hook of the semantic argument, so thatresource-sensitivity is assured.
Scope ambi-guities would not result in alternative deriva-tions, since RMRS makes use of scope under-specification in the meaning language.Related work in Dyvik et al (2005) presentsMRS construction from LFG grammars ina correspondence architecture, where seman-tics is defined as a projection in individ-ual syntactic rules.
Our architecture followsa description-by-analysis (DBA) approach,where semantics construction applies to fullyresolved syntactic structures.
This architec-ture is especially suited for the present taskof treebank creation, where grammars for agiven language may not have full coverage.Also, in a DBA architecture, incomplete rulesets can still yield partially annotated, i.e.,unconnected semantic structures.
Likewise,this construction method can deal with par-tially analysed syntactic input.Finally, our method can be extended to afull parsing architecture with deep semanticoutput, where care should be taken to pre-serve structural or categorial information thatwe identified as crucial for the purpose ofprinciple-driven semantics construction.AcknowledgementsThe research reported here was conductedin cooperation with the TIGER project andhas partially been supported by the projectQUETAL (DFKI), funded by the GermanMinistry for Education and Research, grantno.
01 IW C02.
Special thanks go to DanFlickinger and Berthold Crysmann for adviceon theoretical and grammar-specific issues.We also thank Martin Forst, who provided uswith the TIGER DB dependency structures,Berthold Crysmann for providing HPSG lex-ical resources, and Ulrich Scha?fer for XSLT-scripts used for visualisation.ReferencesS.
Brants, S. Dipper, S. Hansen, W. Lezius, andG.
Smith.
2002.
The TIGER Treebank.
InProceedings of the Workshop on Treebanks andLinguistic Theories, Sozopol, Bulgaria.C.
Carroll and E. Briscoe.
2002.
High precisionextraction of grammatical relations.
In Proceed-ings of COLING 2002, pages 134?140.A.
Copestake, A. Lascarides, and D. Flickinger.2001.
An Algebra for Semantic Construction inConstraint-based Grammars.
In Proceedings ofthe ACL 2001, Toulouse, France.A.
Copestake, D. Flickinger, I.
Sag, and C. Pol-lard.
2005.
Minimal Recursion Semantics.
toappear.A.
Copestake.
2003.
Report on the Design ofRMRS.
Technical Report D1.1a, University ofCambridge, University of Cambridge, UK.R.
Crouch.
2005.
Packed Rewriting for MappingSemantics to KR.
In Proceedings of the SixthInternational Workshop on Computational Se-mantics, IWCS-05, Tilburg, The Netherlands.B.
Crysmann.
2003.
On the efficient implemen-tation of German verb placement in HPSG.
InProceedings of RANLP 2004, Bulgaria.M.
Dalrymple, editor.
1999.
Semantics and Syn-tax in Lexical Functional Grammar: The Re-source Logic Approach.
MIT Press.H.
Dyvik, V. Rose?n, and P. Meurer.
2005.
LFG,Minimal Recursion Semantics and Translation.In Proceedings of the LFG 2005 Conference,Bergen, Norway.
to appear.M.
Forst, N. Bertomeu, B. Crysmann, F. Fouvry,S.
Hansen-Schirra, and V. Kordoni.
2004.
To-wards a Dependency-Based Gold Standard forGerman Parsers: The Tiger Dependency Bank.In S. Hansen-Schirra, S. Oepen, and H. Uszkor-eit, editors, Proceedings of LINC 2004, Geneva,Switzerland.M.
Forst.
2003.
Treebank Conversion ?
Estab-lishing a testsuite for a broad-coverage LFGfrom the TIGER treebank.
In Proceedings ofLINC?03, Budapest, Hungary.A.
Frank and K. Erk.
2004.
Towards an LFGSyntax?Semantics Interface for Frame Seman-tics Annotation.
In A. Gelbukh, editor, Com-putational Linguistics and Intelligent Text Pro-cessing, LNCS, Vol.
2945.
Springer, Heidelberg.T.H.
King, R. Crouch, S. Riezler, M. Dalrymple,and R. Kaplan.
2003.
The PARC 700 Depen-dency Bank.
In Proceedings of LINC 2003, Bu-dapest, Hungary.10
