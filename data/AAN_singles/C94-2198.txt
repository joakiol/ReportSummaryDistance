WORD CLASS D ISCOVERY FOR POSTPROCESSINGCHINESE HANDWRIT ING RECOGNIT IONChao-Huang ChangE000/CCI~, Bui lding 11, Industr ia l  Technology Research Inst i tuteChutung,  Hsinchu 31015, TAIWAN, R.O.C.SummaryThis article presents a novel Chinese class n-grammodel for contextual postprocessing of haudwritingrecognition results.
The word classes in the modelare automatically discovered by a corpus-based simu-lated anuealing procedure.
Three other language mod-els, least-word, word-frequency, and the powerflfl inter-word character bigram model, have been constructedfor comparison.
Extensive xperiments on large textcorpora show that the discovered class bigram modeloutperforms the other three competing models.1.
INTRODUCTIONClass-based language models (Brown et al, 1992)havebeen proposed for dealing with two problems con-fronted by the well-known word n-gram language mod-els (1) data sparseness: the amount of training datais insufficient for estimating the huge number of pa-rameters; and (2) domain robustness: the model is notadaptable to new application domains.
The classescan be either linguistic ategories or statistical wordclusters.
The tbrmer includes morphological features(Lee L. et al, 1993), grammatical parts-of-speech (Der-ouault and MeriMdo, 1986; Church, 1989; Chang andChen, 1993a), and semantic categories.
The latter usesword classes discovered by the computer using statis-tical characteristics in very large corpora.
There haverecently been several groups working on corpus-basedword class discovery such as Brown ct al.
(1992),Jardino and Adda (1993), Schutze (1993), and Changand Chen (1993b).
However, the practical value ofword class discovery needs to be proved by real-worldapplications.
In this paper, we apply the discoveredword classes to language models for contextual post-processing o\[" Chinese handwriting recognition.The Chinese language has more than 10,000 char-acter categories.
Therefore, the problem of Chinesecharacter recognition is very challenging and has at-tracted many researchers.
The tield has usually dividedinto three types: on-line recognition, printed characterrecognition, and handwriting recognition, in the orderof difficulty.
The recognition systems have been re-ported to have character accuracies ranging h'om 60%to 99%, by character recognizers for different ypes oftexts from different producers.
Misrecognitions and/orrejections are hard to avoid due to the problems of dif-ferent fonts, charaeters with similar shape, charactersegmentation, different writers, and algorithmic mper-fections.
Therefore, contextual postprocessing of therecognition results is very useful in both reducing thenumber of recognition errors and saving the time inhuman proofreading.Contextual postprocessing of character recognitionresults is not novel: Shinghal (1983) and Sinha (1988)proposed approaches for English; Sugimura nd Saito(1985) dealt with the reject correction of Japanesecharacter ecognition; and several researchers (ChouB.
and Cbang, 1992; Lee II.
et al, 1993) presented ap-proaches for postprocessing Chinese character recogni-tion, just to name a thw.Three large text corpora have been used in theexperiments: 10-million-character 1991ud for collect-ing character bigrams and word frequencies, 540-thousand-character day7 for word class discovery, and92-thousand-character poll2 for evaluating postpro-cessing language modelsA simulated annealing approach is used for discov-ering the statistical word classes in the training cor-pus.
The discovery process converges to an optimalclass assignment to the words, with a minimal perplex-ity for a predefined number of classes.
The discoveredword classes are then used in the class bigram languagemodel for postprocessing.We have used a state-of-the-art Chinese handwritingrecognizer (Li et al, 1992) developed by ATC, CCL,ITRI, Taiwan as the basis of our experiments.
TheCCL/IICCR handwritten character database (5401character categories, 200 samples each category) (riLl ctal., 1991) was automatically sorted according to char-acter quality (Chou S. and Yu, 1993).
The recognizerproduces N best category candidates for each charactersample in the test part of the database.
The postpro-cessor then uses as its input the category candidatesfor the pol?2 corpus and chooses one of the candidatesfor each character as its output.For comparison, we have also implemented threeother language models: a least-word model, a word-frequency model, and the powerful inter-word char-acter bigram model (Lee L. et al, 1993).
We haveconducted extensive xperiments with the discoveredclass bigram (changing the number of classes) andthese three competitive models on character samples1221with different quality.
The experimental results showthat our discovered class bigram model outperformsthe three competing models.2.
WORD CLASS D ISCOVERYWe describe in this section the problem of corpus-basedword class discovery and the simulated annealing ap-proach tbr the problem.2.1 The  prob lemLet T= Wl,W2, ...,wL be a text corpus with L words;V = vl, v~, ..., VNv be the vocabulary composed of theNV distinct words in T; and C = C1,C2,... ,CNc bethe set of classes, where NC is a predefined number ofclasses.
The word class discovery problem can be for~mulated as follows: Given V and C (with afixed NC),find a class assignment ?
from V to C which maxi-mizes the estimated probability of T, \[~(T), accordingto a specific probabilistic language model.For a class bigram model, find ?
: V --+ C to maxi-mize ~(T) = ~I/L=I p(wi I?(wl))p(?(wi)l?
(wi-1))))Alternatively, perplexity (Jardino an d Adda, 1993)or average mutual information (Brown et al, 1992) canbe used as the characteristic value for optimization.Perplexity, PP,  is a well-known quality metric for lan-guage models in speech recognition: PP  = /5(T)-~.The perplexity for a class bigram model is:L 1-(p(w~l?(wd)p(?(wdl?
(w~-0))) P P = cxp(-i=1where wj is the j-th word in the text and ~b(wj) isthe class that wj is assigned to.For class N-gram models with fixed NC, lower per-plexity indicates better class assignment of the words.The word class discovery problem is thus defined: findthe class assignment of the words to minimize the per-plexity of the training text.2.2 The s imula ted  annea l ing  approachThe word class discovery problem can be consideredas a combinatorial optimization problem to be solvedwith a simulated annealing approach.
Jardino andAdda (1993) used the approach for antomatically clas-sifying French and German words.
The four compo-nents (Kirkpatrick et al, 1983) of a simulated anneal-ing algorithm are (1) a specification of conf igurat ion,(2) a random move generator  for rearrangementsof the elements in a configuration, (3) a cost tim(:-l i on  for evaluating a configuration, (4) an annea l ings( 'hedule that specifies time and duration to decreasethe control parameter (or temperature).
The configu-ration is clearly the class assignment q~, for the wordclass discovery problem.
The move generator is alsostraightforward -- randomly choosing a word to be re-assigned to a randomly chosen class.
Perplexity canserve as the cost fimction to evaluate the quality ofword classification.
The Metropolis algorithm speci-fies the annealing schedule.
The discovery procedure isthus: (1) Initialize: Assign the words randomly to thepredefined number of classes to have an initial config-uration; (2) Move: R,eassign a randomly selected wordto a randomly selected class (Monte Carlo principle);(3) Accept or Backtrack: If the perplexity is changedwithin a controlled limit (decreases or increases withinlimit), the new configuration is accepted; otherwise,undo the reassignment (Metropolis Mgorithm, see be-tow); and (4) Loop: Iterate the above two steps untilthe perplexity converges.Metropol is  a lgor i thm (Jardino and Adda, 1993):The original Monte Carlo optimization accepts a newconfiguration only if the perplexity decreases, suffersfrom the local minimum problem.
Metropolis et alproposed in 1953 that a worse configuration can be ac-cepted according to the control parameter cp.
The newconfiguration is accepted if cxp(APP/cp) is greaterthan a random number between 0 and 1, where APP isthe difference of perplexities for two consecutive steps.cp is decreased logarithmically (multiplied by an an-nealing factor a f)  after a fixed number of iterations.3.
CONTEXTUAL POSTPROCESSING OFHANDWRIT ING RECOGNIT IONThe problem of contextual postprocessing can be de-scribed as follows: The character ecognizer producestop K candidates (with similarity score) for each char-acter in the input stream; the postprocessor then de-cides which of the K candidates i correct based on thecontext and a language model.
Let the recognizer pro-dace the candidate matrix M for the input sequence oflength N:Cll C2t Caj .
.
.
.
CN~C12 C22 Ca2 .., CN.~C~K C,2~ Cadre .,.
CNKthe postprocessor is to find the combination withhighest probability according to the language model:0 = 01,02 .... ON =argmax P(OIM)The overall probability can be divided into twoparts: pattern recognition probability and linguisticprobability, P(OI M) = f 'pn(OlM) * PLM(OIM).
Theformer is produced by the recognizer, while the latteris defined by thr language model.This problem can be reformnlated as one of findingthe optimal path in a word lattice, since word is thesmallest meaningful nit in the Chinese language.
Theword lattice is formed with the words proposed by aword hypothesizer, which is composed of a dictionarymarcher and some lexical rules.
Thus, PrM(O\[M) =max~l~paths P(path), where a path is a word sequenceformed by a character combination i M.3.1 Least-word model  (LW)A simple language model is based on a dictionary (ac-tually a wordlist).
The characteristic function of themodel is the number of words in the word-lattice path.The best path is simply one with the least number of1222words, l'cM (OIM) -: ( -1)*  #words-in-the-path.
Thisis similar to the principle of Max|reran Mal.ching illChinese word segmentation.3.2 Word- f r ( :queney mode l  (WF)Another simple model is based on the word frequenciesof the words in the word-lattice pai;h. '\['his can beconsidered as a word unigram language model.
Thepath probal)ility is tit(; product of word probabilitiesof the words in the path.a.3 I n te r -word  ( 'haraeter  b ig ram mode l  ( IWC B)l,ee b. el aL (1993) recently presented a novel |(leacalled word-latticcobased Chinese character bigram forChinese language modeling.
Basically, they approxi~mate the eii)ct of word I)igr;mls by applying characterbigrams to the boundary characters of adjacent words.
'l!he approach is simple and very effective.
\]t can alsobe considered as one of class-base.d bigram models, using morl)hological features the lirst and last charac-ters of a word.
Wc luM implemented a variation ofthe model, called inter-word character l)igram model.Word probal)ilities and Chinese character bigrams wer('.built from the 10-million-character UI) ('orlms.
'l?hepath probability is computed as the product ol" wordprobabilities and inter-word character bigram proba-bilities of the words in the path.
This model is one ofthe best among the existing Chinese language models,and has been successfully applic, d to Chinese homo-t)hone (lisambiguation and linguistic decoding (l,ee /,.c~ el., 1993).3.4 D iscovered  ('lass 1)|gram mode lOur novel language model uses the word classes discovered by the simulated anneMing procedure as the1)asis of (:lass bigram language model.
The ram,her ofclasses (NC) can be selected according I;o the size oftraining corl)uS.Every word in the training corI)uS is assigned to acertain class after the training process converges witha minimal perplexity.
Thus, we can store the class in--dices in the corresponding le.xicM entries in the dictio-nary.
Words in a word-lattice path ;~re then au|;otllat-ieMly mapped to the.
class indices through dictionarylook-up.
The path 1)robability is thus the product o\['lexical l)robabilities and contextuM class bigram l)robabilities, as in a usual (:lass bigrmn language model.4.
EXPE I I , IMENTAL  RESULTS4.1 The  eorpora  and word  b lgra lnsThe 1991 U l) newsl)aper corpus (199lad) of approxi-mately 10,000,000 characters has beeo used for collect-ing the character bigrams and word frequencies used inthe lWCll  model.
A sul)corpus of 1991ud, day7, wasused for word (;lass discovery.
'l!he subcorpns is first segmented automat|rally intosentences, then into words by our Viterbid)ased wordidentification program VSG.
SI, atistics of the day7 sub-corpus arc; summarized: 42,537 senteuces, 2;t,9"/7 wor(btypes (3,37'7 I-character, 16,004 2-character, 2,4611 3-character, 2,135 4-character), and 355,347 word-tokens(189,838 I character, 150,267 2-character, 10,783 3-character, 4,460 d-character).A sin,pie program is then used for counting the wordcollocation frequencies for the 23,977x23,977 word bigram, iu which only 203,304 entries arc; nonzero.
Af-ter that, the full word bigram is stored in compressedform.
'Fhe simulated anneMing procedm:e is w~ry time-consuming; that is why we have used the smMler day7rather than the original 1991ud corpus for word classdiscove.ry.
For example, it took 201.2 CPU hours ona I)EC 3000/500 AXP workstation to classify 23,977words into 200 classes with 50,000 trials in each of 416iterations, using the day7 corpus.An iudelmndent, set of news abstract artMes, polL2,were collected for evaluating the l)erforntance of lan--guage models, polL2 is cli\[\['erenl; from day7 in bothpulAisher and time period poll2 contains 6,930 sen-tences or !t2,710 (Jhiuese characters.4.2 l lanc lwr i t ing  recogn i t ionWe have used a state-of-the art Chinese handwritingrecognizer (I,i el el., 1992) de.veloped by ATC, (XII,,\['I'll\], Taiwan as the basis of our experiments.
The(',(JlffllCCl/.
hamlwritten character tie|abase (5401character categories, 2(10 samples each category) ('IS|el el., 1991)was first automatically sorted accordingI.o character quality (Chou S. and Yu, 1993), then wasdivided into two t~m'l,s: the odd-rank s~mq)les \]))r |;rMning the recognizer, the.
eves-rank samples as iteM-outtest data.We have used for our experiments three sets of char-acter samples, CQI0, CQ20, and CQ30, which are thesaml)les with quMity ranks 10, 20, and 30, respectively.The recognition results; are sumu,arized in Table l (a) .The table shows the n,unbers of character samples inwhich position the correct character categories wereranked by the recognizer.
There are, for example, 5,270character samples ranked 1, 105 ranked 2, 15 ranked 3~..., aud 4 ranked after 10, for CQI0.
The error rates, interms of character categories, would be 2.43%, '3.48%,and 4.07%, for (JQI0, CQ20, and (X230, respe.ctiw~ly.4.3 Word class d iscoveryThe day7 subcorlms was used for discovering wordclasses.
Tim initial contiguration is: Words with tYe-quency less tlum m (currently set to 6) are assigne'dto Class-0, the unseen word (:lass (Jardino and Adda1993); i)ttnctuation marks are assigned to a speciMclass Class-l; aud l 4 character numl)er words are as-signed to Classes 2 .5, resl)ectively; all other words areassigne.d to Class--0.
The word-types assigne(t o thesix spe.cial classes classes 0-5 are not subject to reas-signment.
'\['he control \[)a.ra/tleter (7.\]) is initially set to0.1 and the amlealing factor af 0.9.We have conducted rmmbers of experiments with1223Table 1: Handwrit ing Recognition ResultsI rank \[ CQ10 \[ CQ20 \[ CQ3O I1 5270 5213 51812 105 133 1623 15 20 294 2 11 75 3 2 56 2 7 37-10 0 0 3>10 4 15 11(a) Number of Correct Character Categories' 2 \ [ rank\ [CQJOlCQOlCQ30\ ]1 90778 88924 896992 1451 2994 2112!3  178 168 3994 2 86 385 1.35 0 1996 64 95 627-10 0 0 4>10 50 391 145out 52 52 52(b) Number of Correct Characters in po1?2different predefined number of classes NC.
The auto-matie discovery procedure stops when the perplexityconverges or the control parameter approaches to zero.The converged perplexities range from 670 to 1200,depending on NC.
Classifications with higher NC havelower training set perplexities.
However, we have tocareful about the problem of overtraining due to insuf-ficient training data.
See Chang and Chen (1993b) fordiscussion on the problem.A statistical langnage model must be able to dealwith the problem of unseen words and bigrams, in real-world applications.
We adopt a simple linear smooth-ing scheme, similar to Jardino and Adda (1993).
Theinterpolation parameters ct and ??
are set to 1 - 10 -'~and 0.1, respectively.4.4 Contextua l  postproeess ingThe po l l2  corpus of 92,710 Chinese characters wasused for evaluating the performance of contextual post-processing.
The recognition resnlts for the three sets ofcharacter samples were used as the basis of evalnation.Table 1 (b) shows the recognition results in terms of thepo l i2  corpus.
The corpus contains 52 uncommon char-acters which do not belong to any of the 5401 charactercategories.
The table shows the nmnbers of charactersin the corpus in which position the correct characterswere ranked by the recognizer.
For example, there are90,778 characters ranked 1, 1451 ranked 2, 178 ranked3, ..., and 50 ranked after 10, in terms of the CQI0samples.
The recognition error rate for CQ10 wouldbe 2.08%, without contextual postprocessing.
3'he er-For rate for CQ20, 4.08%, is higher than that for CQ30,3.25%, because some very common characters, e.g., ;/~, ~ in CQ20 samples are misrecognized.
We set thenumber of candidates K to 6 in the experiments, as atradeoff or better performance.
Therefore, the char-acters ranked after 6 and the 52 uncomnmn charactersare impossible to recover using the postprocessor.
TheoptimM results a language model can do are thus witherror rates 0.11%, 0.48%, and 0.22%, for CQ10, CQ20,and CQ30, respectively.The changes the postprocessor makes can be classi-fied into three types: wrong-to-correct (XO), correct-to-wrong (OX), and wrong-to-wrong (XX).
In the XOtype, a wrong character (i.e., a recognition error) is cot:rected; in the OX type, a correct character is changedto a wrong one; and in the XX type, a wrong char-acter is changed to another different wrong one.
Theperformance of the postprocessor can be evaluated asthe net gain, @XOs - #OXs .
'Fable 2: Postprocessing Results for the CQ10, CQ2,CQ30 Character SamplesModel I xo\[ oxlxx A?ai l R(%)No Grammar 0 0 0 0 3.14Least Word 1713 1361 67 351 2.76Word Freq.
2417 702 149 1714 1.29IWCB 2563 668 204 1895 1.10NC = 50 2349 2071 134 2148 0.82NC=100 2354 201 133 2153 0.81NC= 150 2351 192 128 2159 0.81NC=200 2355 212 131 2143 0.82NC = 250 2361 240 135 2120 0.85NC=300 2348 232 141 2116 0.86NC : 500 2317 311 153 2006 0.97Table 2 summarizes the experimental results of post-processing \['or the three sets of character samples.
Thecolumns XO, OX, XX, and Gain list the average num-bers of characters in types XO, OX, XX, and XO-OX, respectively.
The last column ER lists the overallerror rates after postprocessing with the various lan-guage models.
The No Grammar row lists the errorrates without postprocessing; the rows Least Word,Word Freq., and IWCB show the results for the Least;-Word, Word-Frequency, and Inter-word Character Bi-gram models; and tire NC rows show the results fordiscovered class bigram models with different nnmbersof classes.
We observe from Table 2 that:?
Our discovered class bigram model out-performedthe other three models in general.
The order ofperformance is: NC = 200 > IWCI3  > Wt  ~' >LW.
The average error rates are - Kecognizer:3.14%, LW:2.76%, WF:1.29%, lWCB:I.10%, andNC = 200: 0.82%.In other words, our NC = 200 rednced the errorrate by 73.89%, while IWCB reduced it by 64.97%,7224WF by 58.92%, and LW by 12.10%.
Note that a0.27% average of the characters arc always wrong;that; is, the least error rate is 9.27%.
le, xcludingthese characters, the NC = 200 model reducedthe error rate by 80.84%!?
The l,east-word model is not sufficient (it has neg-ative gain for CQ10), and the Word-frequencymodel is much better, reducing the error rates bymore than Iifty percent.?
Our model outperformed the powerful \[WCBmodel, except for CQ20.
The difference of CQ20performance is just 0.05%, while our model out-performed IWCB by much larger margins, 0.51%and 0.4:3%, tbr CQ10 and CQ30, respeetiw~ly.
Be-sides, the storage requirement of otlr model ismuch less than that of 1WCB model.?
The IWCB model usually corrects more errorsthan ours, while it also commits much more OXmistakes.?
The optimal NC vahtes for the discovered classbigram models are 200 for CQ10 and CQ20, and150 for CQ30.
This is consistent to the commonrule of thumb: the size of training data shouldbe at least ten times the number of parameters,which suggests a NC value of 189 for the size ofthe ctay7 corpus (355,347 words).The N(; = 500 models are apparently over-trained, which is consistent to the evaluation oftest t(,t perplexities we discussed in (?hang andChen (1993b).5.
CONCLUDING REMARKSWe have proposed using auton,aticaliy discovered wordclasses in Chinese class n-gram models for r.ont.ex-tual postproeessing of handwriting recognition results.Three other language models have been constructed forcomparison, gxtensive xl)eriments on large text colpora show that the discovered class bigram languagemodel has outperformed all the three competing mod-els, including the powerful inter-word character bigrammodel.
Future works include (1) applying the discov-ered class bigram models to linguistic decoding in Chi-nese speech recognizer; and (2) studying other auto-matic discovery approaches.AcknowledgementsThanks are due to the Chinese llandwriting l{.ecogni-lion group, ATC/CCL/ITIL\] for the character recog-nizer, especially Y.-C. l,ai for preparing the recognitionresults.
This paper is a partial result of the project no.37112100 conducted by the.
H'I{I under sponsorship ofthe Minister of F, conomie Affairs, R.O.C.ReferencesBrown, l).l,'., V.J.
Della l)ietra, P.V.
de Soaza, J.C.Lai, and ILl,.
Mercer (1992).
Class-hased n-grammodels of natural anguage.
Computational Lin-.quistics, 18, pp.
467- 479.Chang, C.-II.
and C.-D. Chen (1993a).
HMM-basedpart-of-speech tagging for Chinese corpora.
InProc.
of the Workshop on Very Large Corpora(WVLUI), Columbus, Ohio, USA, pp.
40 47.Chang, CAl.
and C.-I).
Chen (1993b).
Automaticclustering of Chinese characters and words.
InProc.
of IgOCLINC VI, pages 57-78, Chitou,Nantou, Taiwan, pp.
57 78.Chou, B.II.
anti J.S.
Chang (11992).
Applying lan-guage modeling to Chinese character recognition.In Proc.
of ROCLING V, Taipei, Taiwan, pp.261- 286.
(in Chinese).Chou, S.-1,.
and S.-S. Yu (11993).
Sorting qualitiesof handwritten Chinese characters for setting upa research database.
In Proc.
of IG'DAIG93,Tsukuba, Japan, Pl).
474 477.Church, g. (1989).
A stochastic parts program andnoun phrase parser for unresticted text.
in Proc.of ICA,S'5'P-89, C, lasgow, Scotland, pp.
695 698.1)erouault, A. aim B. Merialdo (1986).
Naturallanguage modeling for phoneme-to-text transcrip-tion.
H'JEE Trans.
PAMI, 8, pp.
742-74:9.3ardino, M. and G. Adda (1993).
Automatic wordclassification using simulated annealing.
In Proc.of ICASS1~-93, II, Minneapolis, Minnesota, USA,pp.
41-44.Kirkpatriek, S., C.I).
Gelatt, Jr., and M.P.
Vecchi(1983).
Optimization by simulal;ed annealing.Science, 220, pp.
671 680.Lee, H.-J., C.-H. Tung, and C.-H. Chang Chien(:1993).
A Markov bmguage model in Chi-nese text recognition.
In .l'roc.
of ICDAR-93,'l?suknba, Japan, pp.
72 75.Lee, L.-S. et al(1993).
Golden Mandar in  (I1) - animproved single-chip real-time Mar, darin dictationmachine \['or Chinese language with very large vo-cabulary.
In Proc.
of ICASSP-93, 11, Minneapo-lis, Minnesota, USA, pp.
503-506.l,i, T.-F., S.-S. Yu, II.-F. Sun, and S.-L. Chou (1992).llandwritten Chinese character recognition usingBayes rule.
In Proc.
of ICCPCOL-92, Florida,USA, pp.
406 dill.Sehutze, 1t.
(1993).
Part-of-speech induction fromscratch.
In Proc.
of AUL-93, Columbus, Ohio,USA, pp.
251- 258.Shinghal, R. (1983).
A hybrid algorithm for contex-tual text recognition.
Pattern Recognition, 16,pp.
251 267.Sinha, R. and B. Prasada (1988).
Visual text recog-nition through contextual processing.
Patterntgecognition.
2l, pp.
463-479.Sugimura, S. and T. Saito (1985).
A study of r(~ec.-lion correction for character recognition based onbinary n-gram.
IE\[CE Japau, J68-D, pp.
64-71.
(in Japanese).
'lhq L.-T. et al(1991).
Recognition of handprintedcharacters by feature matching.
In Proc.
of 1991l"irst National Workshop on Character Rcco.qni-lion, tlsinchu, q'aiwan, pp.
166 175.1225
