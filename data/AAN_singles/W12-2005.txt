The 7th Workshop on the Innovative Use of NLP for Building Educational Applications, pages 44?53,Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational LinguisticsExploring Grammatical Error Correction withNot-So-Crummy Machine Translation?Nitin Madnani Joel TetreaultEducational Testing ServicePrinceton, NJ, USA{nmadnani,jtetreault}@ets.orgMartin ChodorowHunter College of CUNYNew York, NY, USAmartin.chodorow@hunter.cuny.eduAbstractTo date, most work in grammatical error cor-rection has focused on targeting specific er-ror types.
We present a probe study intowhether we can use round-trip translations ob-tained from Google Translate via 8 differentpivot languages for whole-sentence grammat-ical error correction.
We develop a novelalignment algorithm for combining multipleround-trip translations into a lattice using theTERp machine translation metric.
We furtherimplement six different methods for extract-ing whole-sentence corrections from the lat-tice.
Our preliminary experiments yield fairlysatisfactory results but leave significant roomfor improvement.
Most importantly, though,they make it clear the methods we proposehave strong potential and require further study.1 IntroductionGiven the large and growing number of non-nativeEnglish speakers around the world, detecting andcorrecting grammatical errors in learner text cur-rently ranks as one of the most popular educationalNLP applications.
Previously published work hasexplored the effectiveness of using round-trip ma-chine translation (translating an English sentenceto some foreign language F, called the pivot, andthen translating the F language sentence back to En-glish) for correcting preposition errors (Hermet andDe?silets, 2009).
In this paper, we present a pilotstudy that explores the effectiveness of extending?cf.
Good Applications for Crummy Machine Translation.Ken Church & Ed Hovy.
Machine Translation, 8(4).
1993this approach to whole-sentence grammatical errorcorrection.Specifically, we explore whether using the con-cept of round-trip machine translation via multi-ple?rather than single?pivot languages has the po-tential of correcting most, if not all, grammaticalerrors present in a sentence.
To do so, we de-velop a round-trip translation framework using theGoogle Translate API.
Furthermore, we propose anovel combination algorithm that can combine theevidence present in multiple round-trip translationsand increase the likelihood of producing a whole-sentence correction.
Details of our methodology arepresented in ?3 and of the dataset we use in ?4.
Sincethis work is of an exploratory nature, we conduct adetailed error analysis and present the results in ?5.Finally, ?6 summarizes the contributions of this pi-lot study and provides a discussion of possible futurework.2 Related WorkTo date, most work in grammatical error detectionhas focused on targeting specific error types (usu-ally prepositions or article errors) by using rule-based methods or statistical machine-learning clas-sification algorithms, or a combination of the two.Leacock et al (2010) present a survey of the com-mon approaches.
However, targeted errors such aspreposition and determiner errors are just two of themany types of grammatical errors present in non-native writing.
One of the anonymous reviewers forthis paper makes the point eloquently: ?Given thefrequent complexity of learner errors, less holistic,error-type specific approaches are often unable to44disentangle compounded errors of style and gram-mar.?
Below we discuss related work that uses ma-chine translation to address targeted errors and somerecent work that also focused on whole-sentence er-ror correction.Brockett et al (2006) use information about massnoun errors from a Chinese learner corpus to engi-neer a ?parallel?
corpus with sentences containingmass noun errors on one side and their correctedcounterparts on the other.
With this parallel corpus,the authors use standard statistical machine transla-tion (SMT) framework to learn a translation (correc-tion) model which can then be applied to unseen sen-tences containing mass noun errors.
This approachwas able to correct almost 62% of the errors foundin a test set of 150 errors.
In our approach, we do nottreat correction directly as a translation problem butinstead rely on an MT system to round-trip translatean English sentence back to English.Park and Levy (2011) use a noisy channel modelto achieve whole-sentence grammar correction; theylearn a noise model from a dataset of errorful sen-tences but do not rely on SMT.
They show that thecorrections produced by their model generally havehigher n-gram overlap with human-authored refer-ence corrections than the original errorful sentences.The previous work that is most directly rele-vant to our approach is that of Hermet and De?silets(2009) who focused only on sentences containingpre-marked preposition errors and generated a sin-gle round-trip translation for such sentences via asingle pivot language (French).
They then simplyposited this round-trip translation as the ?correc-tion?
for the original sentence.
In their evaluationon sentences containing 133 unique preposition er-rors, their round-trip translation system was able tocorrect 66.4% of the cases.
However, this was out-performed by a simple method based on web counts(68.7%).
They also found that combining the round-trip method with the web counts method into a hy-brid system yielded higher performance (82.1%).In contrast, we use multiple pivot languages togenerate several round-trip translations.
In addition,we use a novel alignment algorithm that allows us tocombine different parts of different round-trip trans-lations and explore a whole new set of correctionsthat go beyond the translations themselves.
Finally,we do not restrict our analysis to any single type oferror.
In fact, our test sentences contain several dif-ferent types of grammatical errors.Outside of the literature on grammatical error de-tection, our combination approach is directly relatedto the research on machine translation system com-bination wherein translation hypotheses producedby different SMT systems are combined to allow theextraction of a better, combined hypothesis (Ban-galore et al, 2001; Rosti et al, 2007; Feng et al,2009).
However, our combination approach is dif-ferent in that all the round-trip translations are pro-duced by a single system but via different pivot lan-guages.Finally, the idea of combining multiple surfacerenderings with the same meaning has also been ex-plored in paraphrase generation.
Pang et al (2003)propose an algorithm to align sets of parallel sen-tences driven entirely by the syntactic representa-tions of the sentences.
The alignment algorithm out-puts a merged lattice from which lexical, phrasal,and sentential paraphrases could simply be read off.Barzilay and Lee (2003) cluster topically relatedsentences into slotted word lattices by using mul-tiple sequence alignment for the purpose of down-stream paraphrase generation from comparable cor-pora.
More recently, Zhao et al (2010) performround-trip translation of English sentences via dif-ferent pivot languages and different off-the-shelfSMT systems to generate candidate paraphrases.However, they do not combine the candidate para-phrases in any way.
A detailed survey of paraphrasegeneration techniques can be found in (Androut-sopoulos and Malakasiotis, 2010) and (Madnani andDorr, 2010).3 MethodologyThe basic idea underlying our error correction tech-nique is quite simple: if we can automatically gen-erate alternative surface renderings of the meaningexpressed in the original sentence and then pick theone that is most fluent, we are likely to have pickeda version of the sentence in which the original gram-matical errors have been fixed.In this paper, we propose generating such alter-native formulations using statistical machine trans-lation.
For example, we take the original sentence Eand translate it to Chinese using the Google Trans-45Original Both experience and books are very important about living.Swedish Both experience and books are very important in live.Italian Both books are very important experience and life.Russian And the experience, and a very important book about life.French Both experience and the books are very important in life.German Both experience and books are very important about life.Chinese Related to the life experiences and the books are very important.Spanish Both experience and the books are very important about life.Arabic Both experience and books are very important for life.Figure 1: Illustrating the deficiency in using an n-gram language model to select one of the 8 round-trip translationsas the correction for the Original sentence.
The grammatical errors in the Original sentence are shown in italics.
Theround-trip translation via Russian is chosen by a 5-gram language model trained on the English gigaword corpus eventhough it changes the meaning of the original sentence entirely.late API.
We then take the resulting Chinese sen-tence C and translate it back to English.
Sincethe translation process is designed to be meaning-preserving, the resulting round-trip translation E?can be seen as an alternative formulation of the orig-inal sentence E. Furthermore, if additional pivot lan-guages besides Chinese are used, several alterna-tive formulations of E can be generated.
We use 8different pivot languages: Arabic, Chinese, Span-ish, French, Italian, German, Swedish, Russian.
Wechose these eight languages since they are frequentlyused in SMT research and shared translation tasks.To obtain the eight round-trip translations via eachof these pivot languages, we use the Google Trans-late research API.13.1 Round-Trip Translation CombinationOnce the translations are generated, an obvious so-lution is to pick the most fluent alternative, e.g.,using an n-gram language model.
However, sincethe language model has no incentive to preserve themeaning of the sentence, it is possible that it mightpick a translation that changes the meaning of theoriginal sentence entirely.
For example, considerthe sentence and its round-trip translations shownin Figure 1.
For this sentence, a 5-gram languagemodel trained on gigaword picks the Russian round-trip translation simply because it has n-grams thatwere seen more frequently in the English gigawordcorpus.Given the deficiencies in statistical phrase-basedtranslation, it is also possible that no single round-1http://research.google.com/university/translate/trip translation fixes all of the errors.
Again, con-sider Figure 1.
None of the 8 round-trip transla-tions is error-free itself.
Therefore, the task is morecomplex than simply selecting the right round-triptranslation.
We posit that a better approach will beto combine the evidence of correction produced byeach independent translation model and increase thelikelihood of producing a final whole-sentence cor-rection.
Additionally, by engineering such a combi-nation, we increase the likelihood that the final cor-rection will preserve the meaning of the original sen-tence.In order to combine the round-trip translations,we developed a heuristic alignment algorithm thatuses the TERp machine translation metric (Snoveret al, 2009).
The TERp metric takes a pair of sen-tences and computes the least number of edit opera-tions that can be employed to turn one sentence intothe other.2 As a by-product of computing the editsequence, TERp produces an alignment between thetwo sentences where each alignment link is definedby an edit operation.
Figure 2 shows an example ofthe alignment produced by TERp between the orig-inal sentence from Figure 1 and its Russian round-trip translation.
Note that TERp also allows shiftingwords and phrases in the second sentence in orderto obtain a smaller edit cost (as indicated by the as-terisk next to the word book which has shifted fromits original position in the Russian round-trip trans-lation).Our algorithm starts by treating the original sen-tence as the backbone of a lattice.
First, it cre-2Edit operations in TERp include matches, substitutions, in-sertion, deletions, paraphrase, synonymy and stemming.46ates a node for each word in the original sentenceand creates edges between them with a weight of1.
Then, for each of the round-trip translations, itcomputes its TERp alignment with the original sen-tence and aligns it to the backbone based on the editoperations in the alignment.
Specifically, each in-sertion, substitution, stemming, synonymy and para-phrase operation lead to creation of new nodes thatessentially provide an alternative formulation for thealigned substring from the backbone.
Any duplicatenodes are merged.
Finally, edges produced by dif-ferent translations between the same pairs of nodesare merged and their weights added.
Figure 3(a)shows how our algorithm aligns the Russian round-trip translation from Figure 1 to the original sentenceusing the TERp alignment from Figure 2.
Figure3(b) shows the final lattice produced by our algo-rithm for the sentence and all the round-trip transla-tions from Figure 1.-- and [I]both -- the [S]experience -- experience [M]-- , [I]and -- and [M]books -- book [T] [*]are -- a [S]very -- very [M]important -- important [M]about -- about [M]living -- life [Y].
-- .
[M]Figure 2: The alignment produced by TERp between theoriginal sentence from Figure 1 and its Russian round-trip translation.
The alignment operations are indicatedin square brackets after each alignment link: I=insertion,M=match, S=substitution, T=stemming and Y=WordNetsynonymy.
The asterisk next to the work book denotesthat TERp chose to shift its position before computing anedit operation for it.3.2 Correction GenerationFor each original sentence, we computed six possi-ble corrections from the round-trip translations andthe combined lattice:1.
Baseline LM (B).
The most fluent round-triptranslation out of the eight as measured by a5-gram language model trained on the Englishgigaword corpus.2.
Greedy (G).
A path is extracted from the TERplattice using a greedy best-first strategy at eachnode, i.e., at each node, the outgoing edge withthe largest weight is followed.3.
1-Best (1): The shortest path is extractedfrom the TERp lattice by using the OpenFSTtoolkit.3.
This method assumes that, like G, thecombined evidence from the round-trip trans-lations itself is enough to produce a good finalcorrection and no external method for measur-ing fluency is required.44.
LM Re-ranked (L).
An n-best (n=20) list isextracted from the lattice using the OpenFSTtoolkit and re-ranked using the 5-gram giga-word language model.
The 1-best rerankeditem is then extracted as the correction.
Thismethod assumes that an external methodof measuring fluency?the 5-gram languagemodel?can help to bring the most grammati-cal correction to the top of the n-best list.5.
Product Re-ranked (P).
Same as L except there-ranking is done based on the product of thecost of each hypothesis in the n-best list andthe language model score, i.e., both the evi-dence from the round-trip translations and thelanguage model is weighted equally.6.
Full LM Composition (C).
The edge weightsin the TERp lattice are converted to probabil-ities.
The lattice is then composed with a tri-gram finite state language model (trained ona corpus of 100, 000 high-scoring student es-says).5 The shortest path through the composedlattice is then extracted as the correction.
Thismethod assumes that using an n-gram languagemodel during the actual search process is betterthan using it as a post-processing tool on an al-ready extracted n-best list, such as for L andP.3http://www.openfst.org/4Note that the edge weights in the lattice must be convertedinto costs for this method (we do so by multiplying the weightsby ?1).5We adapted the code available at http://www.ling.ohio-state.edu/?bromberg/ngramcount/ngramcount.html to perform the LM composition.47bothexperience1and1 ,1books1book1are1very1important2about2living1life1.1andthe111a111(a)bothexperience1and1,kboosvybooskthemare2uerl2igportantfabo.tinieorkiuink mkiuekkk1andthekkkakkmreatedtokthekexperiencevkkk(b)Original(O)Bothexperienceandbooksareveryimportantaboutliving.BaselineLM(B)Andtheexperience,andaveryimportantbookaboutlife.Greedy(G)Bothexperienceandbooksareveryimportantaboutlife.1-best(1)Bothexperienceandthebooksareveryimportantaboutlife.LMRe-ranked(L)Andtheexperienceandthebooksareveryimportantinlife.ProductRe-ranked(P)Bothexperienceandbooksareveryimportantaboutlife.LMComposition(C)Bothexperienceandbooksareveryimportantinlife.(c)Figure3:(a)showstheoutputofouralignmentalgorithmfortheRussianround-triptranslationfromFigure1.(b)showsthefinalTERplatticeafteraligningalleightround-triptranslationsfromFigure1.(c)showsthecorrectionsfortheoriginalsentence(O)producedbythesixtechniquesdiscussedin3.2.ThecorrectionproducedbytheFullLMCompositiontechnique(C)fixesboththeerrorsintheoriginalsentence.48No.
of Errors Sentences Avg.
Length1 61 14.42 45 19.93 29 24.24 14 29.4> 4 13 38.0Table 1: The distribution of grammatical errors for the162 errorful sentences.Figure 3(c) shows these six corrections as computedfor the sentence from Figure 1.4 CorpusTo assess our system, we manually selected 200sentences from a corpus of essays written by non-native English speakers for a college-level Englishproficiency exam.
In addition to sentences contain-ing grammatical errors, we also deliberately sam-pled sentences that contained no grammatical errorsin order to determine how our techniques performin those cases.
In total, 162 of the sentences con-tained at least one error, and the remaining 38 wereperfectly grammatical.
For both errorful as wellas grammatical sentences, we sampled sentences ofdifferent lengths (under 10 words, 10-20 words, 20-30 words, 30-40 words, and over 40 words).
The162 errorful sentences varied in the number and typeof errors present.
Table 1 shows the distribution ofthe number of errors across these 162 sentences.Specifically, the error types found in these sen-tences included prepositions, articles, punctuation,agreement, collocations, confused words, etc.
Someonly contained a handful of straightforward errors,such as ?In recent day, transportation is one of themost important thing to support human activity?,where day and thing should be pluralized.
On theother hand, others were quite garbled to the pointwhere it was difficult to understand the meaning,such as ?Sometimes reading a book is give me in-formation about the knowledge of life so that I canprevent future happened but who knows that when itwill happen and how fastly can react to that hap-pen.?
During development, we noticed that theround-trip translation process could not handle mis-spelled words, so we manually corrected all spellingmistakes which did not result in a real word.66A total of 82 spelling errors were manually corrected.5 EvaluationIn order to evaluate the six techniques for generatingcorrections, we designed an evaluation task wherethe annotators would be shown a correction alongwith the original sentence for which it was gener-ated.
Since there are 6 corrections for each of the200 sentences, this yields a total of 1, 200 units forpairwise preference judgments.
We chose two anno-tators, both native English speakers, each of whomannotated half of the judgment units.Given the idiosyncrasies of the statistical machinetranslation process underlying our correction tech-niques, it is quite possible that:?
A correction may fix some, but not all, of thegrammatical errors present in the original sen-tence, and?
A correction may be more fluent but mightchange the meaning of the original sentence.?
A correction may introduce a new disfluency,even though other errors in the sentence havebeen largely corrected.
This is especially likelyto be the case for longer sentences.Therefore, the pairwise preference judgment taskis non-trivial in that it expects the annotators to con-sider two dimensions: that of grammaticality and ofmeaning.
To accommodate these considerations, wedesigned the evaluation task such that it asked theannotators to answer the following two questions:1.
Grammaticality.
The annotators were askedto choose between three options: ?Originalsentence sounds better?, ?Correction soundsbetter?
and ?Both sound about the same?.2.
Meaning.
The annotators were asked to choosebetween two options: ?Correction preservesthe original meaning?
and ?Correction changesthe original meaning?.
It should be noted thatdetermining change in or preservation of mean-ing was treated as a very strict judgment.
Subtlechanges such as the omission of a determinerwere deemed to change the meaning.
In somecases, the original sentences were too garbledto determine the original meaning itself.49C > O C = O C < OMeaning = 1 S D FMeaning = 0 F F FTable 2: A matrix illustrating the Success-Failure-Drawevaluation criterion for the 162 errorful sentences.
Therows represent the meaning dimension (1 = meaning pre-served, 0 = meaning changed) and the columns representthe grammaticality dimension (C > O denotes correc-tion being more grammatical than the original, C = Odenotes they are about the same and C < O denotes thatthe correction is worse).
Such a matrix is computed foreach of the six techniques.5.1 EffectivenessFirst, we concentrate our analysis on the originalsentences which contain at least one grammatical er-ror.
We aggregated the results of the pairwise pref-erence judgments for each of the six specific correc-tion generation techniques and applied the strictestevaluation criterion by computing the following, foreach technique:?
Successes.
Only those sentences for whichthe correction generated by method is not onlymore grammatical but also preserves the mean-ing.?
Failures.
All those sentences for which the cor-rection is either less grammatical or changesthe original meaning.?
Draws.
Those sentences for which the correc-tion preserves the meaning but sounds aboutthe same as the original.Table 2 shows a matrix of the six possible com-binations of grammaticality and meaning for eachmethod and demonstrates which cells of the matrixcontribute to which of the above three measures:Successes (S), Failures (F) and Draws (D).In addition to the six techniques, we also posit anoracle in order to determine the upper bound on theperformance of our round-trip translation approach.The oracle picks the most accurate correction gen-eration method for each individual sentence out ofthe 6 that are available.
For sentences where none ofthe six techniques produce an adequate correction,the oracle just picks the original sentence.
Table 3shows how the various techniques (including the or-acle) perform on the 162 errorful sentences as mea-sured by this criterion.
Based on this criterion, thegreedy technique performs the best compared to theothers since it has a higher success rate (36%) anda lower failure rate (31%).
The oracle shows that60% of the errorful sentences are fixed by at leastone of the six correction generation techniques.
Weshow examples of success and failure for the greedytechnique in Figure 4.5.2 Effect of sentence lengthFrom our observations on development data (notpart of the test set), we noticed that Google Trans-late, like most statistical machine translation sys-tems, performs significantly better on shorter sen-tences.
Therefore, we wanted to measure whetherthe successes for the best method were biased to-wards shorter sentences and the failures towardslonger ones.
To do so, we measured the mean andstandard deviation of lengths of sentences compris-ing the successes and failures of the greedy tech-nique.
Successful sentences had an average lengthof approximately 18 words with a standard devia-tion of 9.5.
Failed sentences had an average lengthof 23 words with a standard deviation of 12.31.These numbers indicate that although the failuresare somewhat correlated with larger sentence length,there is no evidence of a significant length bias.5.3 Effect on grammatical sentencesFinally, we also carried out the same Success-Failure-Draw analysis for the 38 sentences in ourtest set that were perfectly grammatical to beginwith.
The analysis differs from that of errorful sen-tences in one key aspect: since the sentences are al-ready free of any grammatical errors, no correctioncan be grammatically better.
Therefore, sentencesfor which the correction preserves the meaning andis not grammaticality worse will count as successesand all other cases will count as failures.
There areno draws.
Table 4 illustrates this difference and Ta-ble 5 presents the success and failure rates for all sixmethods.
The greedy technique again performs thebest out of all six methods and successfully retainsthe meaning and grammaticality for almost 80% of50Method Success Draw FailureBaseline LM (B) 21% (34) 9% (15) 70% (113)Greedy (G) 36% (59) 33% (52) 31% (51)1-best (1) 32% (52) 30% (48) 38% (62)LM Re-ranked (L) 30% (48) 17% (27) 54% (87)Product Re-ranked (P) 23% (37) 38% (61) 40% (64)LM Composition (C) 19% (31) 12% (20) 69% (111)Oracle 60% (97) 40% (65) -Table 3: The success, draw and failure rates for the six correction generation techniques and the oracle as computed forthe 162 errorful sentences from the test set.
The oracle picks the method that produces the most meaning-preservingand grammatical correction for each sentence.
For sentences that have no adequate correction, it picks the originalsentence.
Numbers in parentheses represent counts.SuccessThat?s why I like to make travel by using my own car.That?s why I like to travel using my own car.Having discuss all this I must say that I must rather prefer to be a leader than just a member.After discussing all this, I must say that I would prefer to be a leader than a member.FailureAnd simply there is fantastic for everyoneAll magical and simply there is fantastic for allI hope that share a room with she can be certainly kindle, because she is likely meand so will not be problems with she.I hope that sharing a room with her can be certainly kindle, because it is likely thatI and so there will be no problems with it.Figure 4: Two examples of success and failure for the Greedy (G) technique.
Original sentences are shown firstfollowed by the corrections in bold.
Grammatical errors in the original sentences are in italics.the grammatical sentences.7C > O C = O C < OMeaning = 1 - S FMeaning = 0 - F FTable 4: A matrix illustrating the Success-Draw-Failureevaluation criterion for the 38 grammatical sentences.There are no draws and sentences for which correctionspreserve meaning and are not grammatically worse countas successes.
The rest are failures.6 Discussion & Future WorkIn this paper, we explored the potential of a noveltechnique based on round-trip machine translationfor the more ambitious and realistic task of whole-sentence grammatical error correction.
Although theidea of round-trip machine translation (via a singlepivot language) has been explored before in the con-text of just preposition errors, we expanded on it sig-nificantly by combining multiple round-trip transla-7An oracle for this setup is uninteresting since it will simplyreturn the original sentence for every sentence.Method Success FailureBaseline LM (B) 26% (10) 74% (28)Greedy (G) 79% (30) 21% (8)1-best (1) 61% (23) 39% (15)LM Re-ranked (L) 34% (13) 66% (25)Product Re-ranked (P) 42% (16) 58% (22)LM Composition (C) 29% (11) 71% (25)Table 5: The success and failure rates for the six correc-tion generation techniques as computed for the 38 gram-matical sentences from the test set.tions and developed several new methods for pro-ducing whole-sentence error corrections.
Our oracleexperiments show that the ideas we explore have thepotential to produce whole-sentence corrections fora variety of sentences though there is clearly roomfor improvement.An important point needs to be made regard-ing the motivation for the round-trip translation ap-proach.
We claim that this approach is useful notjust because it can produce alternative renderings ofa given sentence but primarily because each of those51renderings is likely to retain at least some of mean-ing of the original sentence.Most of the problems with our techniques arisedue to the introduction of new errors by GoogleTranslate.
One could use an error detection sys-tem (or a human) to explicitly identify spans con-taining grammatical errors and constrain the SMTsystem to translate only these errorful spans whilestill retaining the rest of the words in the sentence.This approach should minimize the introduction ofnew errors.
Note that Google Translate does notcurrently provide a way to perform such selectivetranslation.
However, other open-source SMT sys-tems such as Moses8 and Joshua9 do.
Furthermore,it might also be useful to exploit n-best translationoutputs instead of just relying on the 1-best as wecurrently do.As an alternative to selective translation, onecould simply extract the identified errorful spans andround-trip translate each of them individually.
Forexample, consider the sentence: ?Most of all, luckis null prep no use without a hard work.?
where thepreposition of is omitted and there is an extraneousarticle a before ?hard work?.
With this approach,one would simply provide Google Translate with thetwo phrasal spans containing the errors, instead ofthe entire sentence.More generally, although we use Google Trans-late for this pilot study due to its easy availability, itmight be more practical and useful to rely on an in-house SMT system that trades-off translation qualityfor additional features.We also found that the language-model basedtechniques performed quite poorly compared to theother techniques.
We suspect that this is due to thefact that Google Translate already employs large-order language models trained on trillions of words.Using lower-order models trained on much smallercorpora might simply introduce noise.
However, adetailed analysis is certainly warranted.In conclusion, we claim that our preliminary ex-ploration of large-scale round-trip translation basedtechniques yielded fairly reasonable results.
How-ever, more importantly, it makes it clear that, withadditional research, these techniques have the poten-8http://www.statmt.org/moses9https://github.com/joshua-decodertial to be very effective at whole-sentence grammat-ical error correction.AcknowledgmentsWe would like to thank Aoife Cahill, Michael Heil-man and the three anonymous reviewers for theiruseful comments and suggestions.
We would alsolike to thank Melissa Lopez and Matthew Mulhol-land for helping with the annotation.ReferencesIon Androutsopoulos and Prodromos Malakasiotis.2010.
A Survey of Paraphrasing and Textual Entail-ment Methods.
J. Artif.
Int.
Res., 38(1):135?187.Srinivas Bangalore, German Bordel, and Giuseppe Ric-cardi.
2001.
Computing Consensus Translation fromMultiple Machine Translation Systems.
In Proceed-ings of ASRU, pages 351?354.Regina Barzilay and Lillian Lee.
2003.
Learning to Para-phrase: An Unsupervised Approach Using Multiple-Sequence Alignment.
In Proceedings of HLT-NAACL2003, pages 16?23.Chris Brockett, William B. Dolan, and Michael Gamon.2006.
Correcting ESL Errors Using Phrasal SMTTechniques.
In Proceedings of the 21st InternationalConference on Computational Linguistics and 44thAnnual Meeting of the Association for ComputationalLinguistics, pages 249?256.Yang Feng, Yang Liu, Haitao Mi, Qun Liu, and Ya-juan Lu?.
2009.
Lattice-based System Combinationfor Statistical Machine Translation.
In Proceedings ofthe 2009 Conference on Empirical Methods in Natu-ral Language Processing: Volume 3 - Volume 3, pages1105?1113.Matthieu Hermet and Alain De?silets.
2009.
Using Firstand Second Language Models to Correct PrepositionErrors in Second Language Authoring.
In Proceedingsof the Fourth Workshop on Innovative Use of NLP forBuilding Educational Applications, pages 64?72.Claudia Leacock, Martin Chodorow, Michael Gamon,and Joel Tetreault.
2010.
Automated GrammaticalError Detection for Language Learners.
SynthesisLectures on Human Language Technologies.
MorganClaypool.Nitin Madnani and Bonnie J. Dorr.
2010.
GeneratingPhrasal and Sentential Paraphrases: A Survey of Data-driven Methods.
Computational Linguistics, 36(3).Bo Pang, Kevin Knight, and Daniel Marcu.
2003.Syntax-based Alignment of Multiple Translations: Ex-tracting Paraphrases and Generating New Sentences.In Proceedings of HLT-NAACL, pages 102?109.52Y.
Albert Park and Roger Levy.
2011.
Automated WholeSentence Grammar Correction using a Noisy ChannelModel.
In Proceedings of the 49th Annual Meetingof the Association for Computational Linguistics: Hu-man Language Technologies - Volume 1, pages 934?944.Antti-Veikko Rosti, Necip Fazil Ayan, Bing Xiang, Spy-ros Matsoukas, Richard Schwartz, and Bonnie Dorr.2007.
Combining Outputs from Multiple MachineTranslation Systems.
In Human Language Technolo-gies 2007: The Conference of the North AmericanChapter of the Association for Computational Linguis-tics; Proceedings of the Main Conference, pages 228?235.Matthew Snover, Nitin Madnani, Bonnie Dorr, andRichard Schwartz.
2009.
Fluency, Adequacy, orHTER?
Exploring Different Human Judgments witha Tunable MT Metric.
In Proceedings of the FourthWorkshop on Statistical Machine Translation at the12th Meeting of the European Chapter of the Associa-tion for Computational Linguistics (EACL-2009).Shiqi Zhao, Haifeng Wang, Xiang Lan, and Ting Liu.2010.
Leveraging Multiple MT Engines for Para-phrase Generation.
In COLING, pages 1326?1334.53
