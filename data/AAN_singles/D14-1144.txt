Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1385?1390,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsLanguage Transfer Hypotheses with Linear SVM WeightsShervin MalmasiCentre for Language TechnologyMacquarie UniversitySydney, NSW, Australiashervin.malmasi@mq.edu.auMark DrasCentre for Language TechnologyMacquarie UniversitySydney, NSW, Australiamark.dras@mq.edu.auAbstractLanguage transfer, the characteristic sec-ond language usage patterns caused by na-tive language interference, is investigatedby Second Language Acquisition (SLA)researchers seeking to find overused andunderused linguistic features.
In this pa-per we develop and present a methodologyfor deriving ranked lists of such features.Using very large learner data, we showour method?s ability to find relevant can-didates using sophisticated linguistic fea-tures.
To illustrate its applicability to SLAresearch, we formulate plausible languagetransfer hypotheses supported by currentevidence.
This is the first work to ex-tend Native Language Identification to abroader linguistic interpretation of learnerdata and address the automatic extractionof underused features on a per-native lan-guage basis.1 IntroductionIt has been noted in the linguistics literature sincethe 1950s that speakers of particular languageshave characteristic production patterns when writ-ing in a second language.
This language transferphenomenon has been investigated independentlyin a number of fields from different perspectives,including qualitative research in Second LanguageAcquisition (SLA) and more recently though pre-dictive computational models in NLP.Motivated by the aim of improving foreign lan-guage teaching and learning, such analyses are of-ten done manually in SLA, and are difficult toperform for large corpora.
Smaller studies yieldpoor results due to the sample size, leading toextreme variability (Ellis, 2008).
Recently, re-searchers have noted that NLP has the tools to uselarge amounts of data to automate this analysis,using complex feature types.
This has motivatedstudies in Native Language Identification (NLI), asubtype of text classification where the goal is todetermine the native language (L1) of an authorusing texts they have written in a second language(L2) (Tetreault et al., 2013).Despite the good results in predicting L1s, fewattempts have been made to interpret the featuresthat distinguish L1s.
This is partly because nomethods for an SLA-oriented feature analysis havebeen proposed; most work focuses on testing fea-ture types using standard machine learning tools.The overarching contribution of this work is todevelop a methodology that enables the transfor-mation of the NLI paradigm into SLA applicationsthat can be used to link these features to their un-derlying linguistic causes and explanations.
Thesecandidates can then be applied in other areas suchas remedial SLA strategies or error detection.2 Related WorkSLA research aims to find distributional differ-ences in language use between L1s, often referredto as overuse, the extensive use of some linguis-tic structures, and underuse, the underutilizationof particular structures, also known as avoidance(Gass and Selinker, 2008).
While there have beensome attempts in SLA to use computational ap-proaches on small-scale data,1these still use fairlyelementary techniques and have several shortcom-ings, including in the manual approaches to an-notation and the computational artefacts derivedfrom these.Conversely, NLI work has focused on automaticlearner L1 classification using Machine Learningwith large-scale data and sophisticated linguisticfeatures (Tetreault et al., 2012).
Here, featureranking could be performed with relevancy meth-ods such as the F-score:1E.g.
Chen (2013), Lozan?o and Mendikoetxea (2010) andDi?ez-Bedmar and Papp (2008).1385F (j) ?(?x(+)j?
?xj)2+(?x(?)j?
?xj)21n+?1n+?i=1(x(+)i,j?
?x(+)j)2+1n??1n??i=1(x(?)i,j?
?x(?
)j)2(1)The F-score (Fisher score) measures the ratiobetween the intraclass and interclass variance inthe values of feature j, where x represents the fea-ture values in the negative and positive examples.2More discriminative features have higher scores.Another alternative method is Information Gain(Yang and Pedersen, 1997).
As defined in equation(2), it measures the entropy gain associated withfeature t in assigning the class label c.G(t) = ?
?mi=1Pr (ci) log Pr (ci)+ Pr (t)?mi=1Pr (ci|t) log Pr (ci|t)+ Pr (?t)?mi=1Pr (ci|?t) log Pr (ci|?t)(2)However, these methods are limited: they do notprovide ranked lists per-L1 class, and more impor-tantly, they do not explicitly capture underuse.Among the efflorescence of NLI work, a newtrend explored by Swanson and Charniak (2014)aims to extract lists of candidate language transferfeatures by comparing L2 data against the writer?sL1 to find features where the L1 use is mirrored inL2 use.
This allows the detection of obvious ef-fects, but Jarvis and Crossley (2012) note (p. 183)that many transfer effects are ?too complex?
to ob-serve in this manner.
Moreover, this method is un-able to detect underuse, is only suitable for syn-tactic features, and has only been applied to verysmall data (4,000 sentences) over three L1s.
Ad-dressing these issues is the focus of the presentwork.3 Experimental Setup3.1 CorpusWe use TOEFL11, the largest publicly availablecorpus of English L2 texts (Blanchard et al.,2013), containing 11 L1s with 1,100 texts each.33.2 FeaturesAdaptor grammar collocations Per Wong et al.
(2012), we utilize an adaptor grammar to discoverarbitrary length n-gram collocations.
We exploreboth the pure part-of-speech (POS) n-grams as2See Chang and Lin (2008) for more details.3Over 4 million tokens in 12,100 texts.well as the more promising mixtures of POS andfunction words.
We derive two adaptor grammarswhere each is associated with a different set of vo-cabulary: either pure POS or the mixture of POSand function words.
We use the grammar pro-posed by Johnson (2010) for capturing topical col-locations:Sentence?
Docjj ?
1, .
.
.
,mDocj?
j j ?
1, .
.
.
,mDocj?
DocjTopicii ?
1, .
.
.
, t;j ?
1, .
.
.
,mTopici?Words i ?
1, .
.
.
, tWords?WordWords?Words WordWord?
w w ?
Vpos;w ?
Vpos+fwVposcontains 119 distinct POS tags based on theBrown tagset and Vpos+fwis extended with 398function words.
The number of topics t is set to50.
The inference algorithm for the adaptor gram-mars are based on the Markov Chain Monte Carlotechnique made available by Johnson (2010).4Stanford dependencies We use Stanford de-pendencies as a syntactic feature: for eachtext we extract all the basic dependencies re-turned by the Stanford Parser (de Marneffe etal., 2006).
We then generate all the variationsfor each of the dependencies (grammatical rela-tions) by substituting each lemma with its cor-responding POS tag.
For instance, a gram-matical relation of det(knowledge, the)yields the following variations: det(NN, the),det(knowledge, DT), and det(NN, DT).Lexical features Content and function wordsare also considered as two feature types related tolearner?s vocabulary and spelling.3.3 Extracting Linear SVM Feature WeightsUsing the extracted features, we train linear Sup-port Vector Machine (SVM) models for eachL1.
We use a one-vs-rest approach to find fea-tures most relevant to each native language.
L2-regularization is applied to remove noisy featuresand reduce the size of the candidate feature list.More specifically, we employ the LIBLINEARSVM package (Fan et al., 2008)5as it is well-suited to text classification tasks with large num-bers of features and texts as is the case here.4http://web.science.mq.edu.au/%7Emjohnson/Software.htm5http://www.csie.ntu.edu.tw/%7Ecjlin/liblinear/1386In training the models for each feature, the SVMweight vector6is calculated according to (3):w =?i?iyixi(3)After training, the positive and negative weightsare split into two lists and ranked by weight.The positive weights represent overused features,while features whose absence (i.e.
underuse) isindicative of an L1 class will have large negativeweights.
This yields two candidate language trans-fer feature lists per L1.4 ResultsWe now turn to an analysis of the output from oursystem to illustrate its applicability for SLA re-search.
Table 1 lists some elements from the un-deruse and overuse lists for various L1s.
The listsare of different feature types.
They have been cho-sen to demonstrate all feature types and also a va-riety of different languages.
For reasons of space,only several of the top features are analysed here.Hindi L1 writers are distinguished by certainfunction words including hence, thus, and etc, anda much higher usage rate of male pronouns.
It hasbeen observed in the literature (Sanyal, 2007, forexample) that the English spoken in India still re-tains characteristics of the English that was spokenduring the time of the Raj and the East India Com-pany that have disappeared from other English va-rieties, so it sounds more formal to other speakers,or retains traces of an archaic business correspon-dence style; the features noted fit that pattern.The second list includes content words overusedby Arabic L1 learners.
Analysis of content wordshere, and for other L1s in our data, reveals veryfrequent misspellings which are believed to be dueto orthographic or phonetic influences (Tsur andRappoport, 2007; Odlin, 1989).
Since Arabic doesnot share orthography with English, we believemost of these are due to phonetics.
Looking atitems 1, 3 and 5 we can see a common pattern:the English letter u which has various phonetic re-alizations is being replaced by a vowel that moreoften represents that sound.
Items 2 and 5 are alsophonetically similar to the intended words.For Spanish L1 authors we provide both under-use and overuse lists of syntactic dependencies.The top 3 overuse rules show the word that is veryoften used as the subject of verbs.
This is almost6See Burges (1998) for a detailed explanation.certainly a consequence of the prominent syntac-tic role played by the Spanish word que which, de-pending on the context, is equivalent to the Englishwords whom, who, which, and most commonly,that.
The fourth rule shows they often use this as adeterminer for plural nouns.
A survey of the cor-pus reveals many such errors in texts of Spanishlearners, e.g.
this actions or this emissions.
Thefifth rule shows that the adjectival modifier of aplural noun is often being incorrectly pluralised tomatch the noun in number as would be required inSpanish, for example, differents subjects.Turning to the underused features in Spanish L1texts, we see that four related features rank highly,showing that these is not commonly used as a de-terminer for plural nouns and which is rarely usedas a subject.
The final feature shows that no isavoided as a determiner.
This may be becausewhile no mostly has the same role in Spanish as itdoes in English, it cannot be used as a determiner;ning?un must be used instead.
We hypothesize thatthis construction is being avoided as placing no be-fore a noun in Spanish is ungrammatical.
This ex-ample demonstrates that our two list methodologycan not only help identify overused structures, butalso uncovers the related constructs that are beingunderutilized at their expense.The final list in Table 1 is of underused Adap-tor Grammar patterns by Chinese learners.
Thefirst three features show that these writers signif-icantly underuse determiners, here an, other andthese before nouns.
This is not unexpected sinceChinese learners?
difficulties with English articlesare well known (Robertson, 2000).
More inter-estingly, we find underuse of features like even ifand might, along with others not listed here suchas could VB7plus many other variants related tothe subjunctive mood.
One explanation is that lin-guistic differences between Chinese and Englishin expressing counterfactuals could cause them toavoid such constructions in L2 English.
Previousresearch in this area has linked the absence of sub-junctive linguistic structures in Chinese to differ-ent cognitive representations of the world and con-sequences for thinking counterfactually (Bloom,2014), although this has been disputed (Au, 1983;Garbern Liu, 1985).Adaptor Grammars also reveal frequent use ofthe ?existential there?8in German L1 data while7e.g.
could be, could have, could go and other variants8e.g.
There is/are ..., as opposed to the locative there.1387Overuse UnderuseHindi Arabic Spanish Spanish Chinese#2: thus #2: anderstand #1: nsubj(VBP,that) #2: det(NNS,these) #12: an NN#4: hence #4: mony #2: nsubj(VBZ,that) #3: nsubj(VBZ,which) #16: other NN#22: his #6: besy #3: nsubj(VB,that) #6: nsubj(VB,which) #18: these NNS#30: etc #15: diffrent #4: det(NNS,this) #7: nsubj(VBP,which) #19: even if#33:rather #38: seccessful #25: amod(NNS,differents) #10: det(NN,no) #68: mightTable 1: Example transfer candidates and rankings from the overuse/underuse lists for various L1s andfeatures types, in order: Hindi function words, Arabic content words, Spanish dependencies (2) andChinese Adaptor Grammars.English Spanish English Spanishdiferent diferente conclution conclusi?onconsecuence consecuencia desagree Neg.
affix des-responsability responsabilidad especific espec?
?ficooportunity oportunidad necesary necesarioTable 2: Highly ranked English misspellings ofSpanish learners and their Spanish cognates.they are highly underused in French L1 data.
Theliterature supports our data: The German equiv-alent es gibt is common while French use is farmore constrained (Cappelle and Loock, 2013).Lexical analysis also revealed Spanish?Englishorthographic transfer, listed in Table 2.
This listincludes many cognates, in contrast with the Ara-bic L1 data where most misspellings were pho-netic in nature.We also observe other patterns which remainunexplained.
For instance, Chinese, Japanese andKorean speakers make excessive use of phrasessuch as however, first and second.
One possibil-ity is that this relates to argumentation styles thatare possibly influenced by cultural norms.
Morebroadly, this effect could also be teaching ratherthan transfer related.
For example, it may be casethat a widely-used text book for learning Englishin Korea happens to overuse this construction.Some recent findings from the 2013 NLI SharedTask found that L1 Hindi and Telugu learners ofEnglish had similar transfer effects and their writ-ings were difficult to distinguish.
It has beenposited that this is likely due to shared culture andteaching environments (Malmasi et al., 2013).Despite some clearcut instances of overuse,9more research is required to determine the causalfactors.
We hope to expand on this in future workusing more data.9More than half of the Korean scripts contained asentence-initial however.5 Discussion and ConclusionUsing the proposed methodology, we generatedlists of linguistic features overused and underusedby English learners of various L1 backgrounds.Through an analysis of the top items in theseranked lists, we demonstrated the high applicabil-ity of the output by formulating plausible languagetransfer hypotheses supported by current evidence.We also showcased the method?s generalizabilityto numerous linguistic feature types.Our method?s output consists of two ranked listsof linguistic features: one for overuse and theother for underuse, something which had not beenaddressed by research to date.
We also foundAdaptor Grammar collocations to be highly infor-mative for this task.This work, an intersection of NLP, MachineLearning and SLA, illustrates how the various dis-ciplines can complement each other by bringingtogether theoretical, experimental and computa-tional issues.
NLP provides accurate and auto-mated tagging of large corpora with sophisticatedfeatures not available in corpus linguistics, e.g.with state-of-the-art dependency parsing.
Sophis-ticated machine learning techniques then enablethe processing of large quantities of data (thou-sands of times the size of manual studies) in a waythat will let SLA researchers explore a variety ofassumptions and theoretical analyses.
And con-versely, NLP can benefit from the long-term studyand language acquisition insights from SLA.In terms of NLI, this work is the first attempt toexpand NLI to a broad linguistic interpretation ofthe data, including feature underuse.
NLI systemsachieve classification accuracies of over 80% onthis 11-class task, leading to theoretical questionsabout the features that make them so effective.This work also has a backwards link in this regardby providing qualitative evidence about the under-pinning linguistic theories that make NLI work.1388The work presented here has a number of ap-plications; chief among them is the developmentof tools for SLA researchers.
This would enablethem to not just provide new evidence for previ-ous findings, but to also perform semi-automateddata-driven generation of new and viable hypothe-ses.
This, in turn, can help reduce expert effort andinvolvement in the process, particularly as suchstudies expand to more corpora and emerging lan-guage like Chinese (Malmasi and Dras, 2014b)and Arabic (Malmasi and Dras, 2014a).The brief analysis included here represents onlya tiny portion of what can be achieved with thismethodology.
We included but a few of the thou-sands of features revealed by this method; prac-tical SLA tools based on this would have a greatimpact on current research.In addition to language transfer hypotheses,such systems could also be applied to aid devel-opment of pedagogical material within a needs-based and data-driven approach.
Once languageuse patterns are uncovered, they can be assessedfor teachability and used to create tailored, L1-specific exercises and teaching material.From the examples discussed in Section 4 thesecould include highly specific and targeted studentexercises to improve spelling, expand vocabularyand enrich syntactic knowledge ?
all relative totheir mother tongue.
Such exercises can not onlyhelp beginners improve their fundamental skillsand redress their errors but also assist advancedlearners in moving closer to near-nativeness.The extracted features and their weights couldalso be used to build statistical models for gram-matical error detection (Leacock et al., 2014).Contrary to the norm of developing error checkersfor native writers, such models could be specifi-cally targeted towards learners or even particularL1?L2 pairs which could be useful in Computer-Assisted Language Learning (CALL) systems.One limitation here is that our features maybe corpus-dependent as they are all exam essays.This can be addressed by augmenting the data withnew learner corpora, as they become available.While a strength here is that we compared each L1against others, a paired comparison only againstnative texts can be insightful too.There are several directions for future work.The first relates to clustering the data within thelists.
Our intuition is that there might be coher-ent clusters of related features, with these clusterscharacterising typical errors or idiosyncrasies, thatare predictive of a particular L1.
As shown in ourresults, some features are highly related and maybe caused by the same underlying transfer phe-nomena.
For example, our list of overused syntac-tic constructs by Spanish learners includes threehigh ranking features related to the same transfereffect.
The use of unsupervised learning meth-ods such as Bayesian mixture models may be ap-propriate here.
For parse features, tree kernelscould help measure similarity between the treesand fragments (Collins and Duffy, 2001).Another avenue is to implement weight-basedranking methods to further refine and re-rank thelists, potentially by incorporating the measuresmentioned in Section 2 to assign weights to fea-tures.
As the corpus we used includes learnerproficiency metadata, it may also be possible tocreate proficiency-segregated models to find thefeatures that characterise errors at each languageproficiency level.
Finally, the use of other lin-guistic features such as Context-free Grammarphrase structure rules or Tree Substitution Gram-mars could provide additional insights.In addition to these further technical investiga-tions, we see as a particularly useful direction thedevelopment of an SLA research tool to conduct alarge SLA study with a wide range of experts.
Webelieve that this study makes a contribution to thisarea and hope that it will motivate future work.ReferencesTerry Kit-Fong Au.
1983.
Chinese and English coun-terfactuals: the Sapir-Whorf hypothesis revisited.Cognition, 15(1):155?187.Daniel Blanchard, Joel Tetreault, Derrick Higgins,Aoife Cahill, and Martin Chodorow.
2013.TOEFL11: A Corpus of Non-Native English.
Tech-nical report, Educational Testing Service.Alfred H Bloom.
2014.
The linguistic shaping ofthought: A study in the impact of language on think-ing in China and the West.
Psychology Press.Christopher JC Burges.
1998.
A tutorial on SupportVector Machines for Pattern Recognition.
Data min-ing and knowledge discovery, 2(2):121?167.Bert Cappelle and Rudy Loock.
2013.
Is there in-terference of usage constraints?
: A frequency studyof existential there is and its French equivalent ilya in translated vs. non-translated texts.
Target,25(2):252?275.1389Yin-Wen Chang and Chih-Jen Lin.
2008.
Featureranking using linear svm.
Causation and PredictionChallenge Challenges in Machine Learning, Volume2, page 47.Meilin Chen.
2013.
Overuse or underuse: A cor-pus study of English phrasal verb use by Chinese,British and American university students.
Interna-tional Journal of Corpus Linguistics, 18(3).Michael Collins and Nigel Duffy.
2001.
ConvolutionKernels for Natural Language.
In Advances in Neu-ral Information Processing Systems, pages 625?632.Marie-Catherine de Marneffe, Bill Maccartney, andChristopher D. Manning.
2006.
Generating typeddependency parses from phrase structure parses.
InProceedings of the Fifth International Conferenceon Language Resources and Evaluation (LREC?06),pages 449?454, Genoa, Italy.Mar?
?a Bel?en Di?ez-Bedmar and Szilvia Papp.
2008.The use of the English article system by Chineseand Spanish learners.
Language and Computers,66(1):147?176.Rod Ellis.
2008.
The Study of Second Language Ac-quisition, 2nd edition.
Oxford University Press, Ox-ford, UK.Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin.
2008.
LIBLINEAR:A library for large linear classification.
Journal ofMachine Learning Research, 9:1871?1874.Lisa Garbern Liu.
1985.
Reasoning counterfactuallyin Chinese: Are there any obstacles?
Cognition,21(3):239?270.Susan M. Gass and Larry Selinker.
2008.
Second Lan-guage Acquisition: An Introductory Course.
Rout-ledge, New York.Scott Jarvis and Scott Crossley, editors.
2012.
Ap-proaching Language Transfer Through Text Classi-fication: Explorations in the Detection-based Ap-proach.
Multilingual Matters, Bristol, UK.Mark Johnson.
2010.
PCFGs, Topic Models, AdaptorGrammars and Learning Topical Collocations andthe Structure of Proper Names.
In Proceedings ofthe 48th Annual Meeting of the Association for Com-putational Linguistics, pages 1148?1157, Uppsala,Sweden, July.
Association for Computational Lin-guistics.Claudia Leacock, Martin Chodorow, Michael Gamon,and Joel Tetreault.
2014.
Automated grammati-cal error detection for language learners.
SynthesisLectures on Human Language Technologies, 7(1):1?170.Cristobal Lozan?o and Amaya Mendikoetxea.
2010.
In-terface conditions on postverbal subjects: A corpusstudy of L2 English.
Bilingualism: Language andCognition, 13(4):475?497.Shervin Malmasi and Mark Dras.
2014a.
Arabic Na-tive Language Identification.
In Proceedings of theArabic Natural Language Processing Workshop (co-located with EMNLP 2014), Doha, Qatar, October.Association for Computational Linguistics.Shervin Malmasi and Mark Dras.
2014b.
ChineseNative Language Identification.
Proceedings of the14th Conference of the European Chapter of the As-sociation for Computational Linguistics, April.Shervin Malmasi, Sze-Meng Jojo Wong, and MarkDras.
2013.
NLI Shared Task 2013: MQ Submis-sion.
In Proceedings of the Eighth Workshop on In-novative Use of NLP for Building Educational Ap-plications, pages 124?133, Atlanta, Georgia, June.Association for Computational Linguistics.Terence Odlin.
1989.
Language Transfer: Cross-linguistic Influence in Language Learning.
Cam-bridge University Press, Cambridge, UK.Daniel Robertson.
2000.
Variability in the use of theEnglish article system by Chinese learners of En-glish.
Second Language Research, 16(2):135?172.Jyoti Sanyal.
2007.
Indlish: The Book for EveryEnglish-Speaking Indian.
Viva Books Private Lim-ited.Ben Swanson and Eugene Charniak.
2014.
DataDriven Language Transfer Hypotheses.
EACL 2014,page 169.Joel Tetreault, Daniel Blanchard, Aoife Cahill, andMartin Chodorow.
2012.
Native Tongues, Lostand Found: Resources and Empirical Evaluations inNative Language Identification.
In Proceedings ofCOLING 2012, pages 2585?2602, Mumbai, India,December.
The COLING 2012 Organizing Commit-tee.Joel Tetreault, Daniel Blanchard, and Aoife Cahill.2013.
A report on the first native language identi-fication shared task.
In Proceedings of the EighthWorkshop on Innovative Use of NLP for Build-ing Educational Applications, pages 48?57, Atlanta,Georgia, June.
Association for Computational Lin-guistics.Oren Tsur and Ari Rappoport.
2007.
Using classifierfeatures for studying the effect of native languageon the choice of written second language words.
InProc.
Workshop on Cognitive Aspects of Computat.Language Acquisition, pages 9?16.Sze-Meng Jojo Wong, Mark Dras, and Mark John-son.
2012.
Exploring Adaptor Grammars for Na-tive Language Identification.
In Proc.
Conf.
Em-pirical Methods in Natural Language Processing(EMNLP), pages 699?709.Yiming Yang and Jan O Pedersen.
1997.
A compara-tive study on feature selection in text categorization.In ICML, volume 97, pages 412?420.1390
