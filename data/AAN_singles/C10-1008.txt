Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 62?70,Beijing, August 2010A Hierarchical Classifier Applied to Multi-way Sentiment DetectionAdrian Bickerstaffe and Ingrid ZukermanFaculty of Information TechnologyMonash Universitybickerstaffe.adrian@gmail.com,Ingrid.Zukerman@monash.eduAbstractThis paper considers the problem ofdocument-level multi-way sentiment de-tection, proposing a hierarchical classifieralgorithm that accounts for the inter-classsimilarity of tagged sentiment-bearingtexts.
This type of classifier also pro-vides a natural mechanism for reducingthe feature space of the problem.
Our re-sults show that this approach improves onstate-of-the-art predictive performance formovie reviews with three-star and four-star ratings, while simultaneously reduc-ing training times and memory require-ments.1 IntroductionA key problem in sentiment detection is to deter-mine the polarity of sentiment in text.
Much of thework on this problem has considered binary senti-ment polarity (positive or negative) at granularitylevels ranging from sentences (Yu and Hatzivas-siloglou, 2003; Mao and Lebanon, 2006; McDon-ald et al, 2007) to documents (Wilson et al, 2005;Allison, 2008).This paper considers the more general problemof multi-way sentiment classification for discrete,ordinal rating scales, focusing on the documentlevel, i.e., the problem of predicting the ?star?
rat-ing associated with a review.
This is a supervisedlearning task involving textual reviews that havebeen tagged with a rating.
Ultimately, the goalis to use classifiers which have been trained ontagged datasets to predict the ratings of untaggedreviews.Typical approaches to the rating scale probleminclude standard k-way classifiers, e.g., (Pang andLee, 2005).
However, these methods do not ex-plicitly account for sample similarities, e.g., thesamples with a ?four star?
rating being more sim-ilar to ?three star?
samples than to ?one star?
sam-ples.
Consequently, these methods generally donot perform well, while methods which incor-porate sample similarity information achieve im-proved performance (Pang and Lee, 2005).Sample similarity in the multi-way sentimentdetection setting has previously been consid-ered by using Support Vector Machines (SVMs)in conjunction with a metric labeling meta-algorithm (Pang and Lee, 2005); by taking a semi-supervised graph-based learning approach (Gold-berg and Zhu, 2006); and by using ?optimalstacks?
of SVMs (Koppel and Schler, 2006).However, each of these methods have short-comings (Section 2).
Additionally, during thelearning process, all approaches employ a set ofword/punctuation features collected across all rat-ing categories.
Hence, the number of features maybe very large compared to the number of trainingsamples, which can lead to the model overfittingthe data.The main contribution of this paper is the use ofhierarchical classifier trees which combine stan-dard binary classifiers to perform multi-way clas-sification (another approach to reduce multi-classclassification to binary classifications is describedin (Beygelzimer et al, 2009)).
The hierarchi-cal classifier accounts for inter-class similarity by62means of tree structures which are obtained usinginter-class similarity measures in conjunction witha shortest-spanning algorithm.
The tree structuresreduce training times since they require only k?1nodes for a k-rating problem.
Training times arefurther reduced by the fact that classifier nodeslower in the tree consider fewer rating classes thanthose higher up, thereby naturally reducing thenumber of training samples relevant to lower-levelnodes.
Additionally, the tree structures offer ameans to safely cull irrelevant features at non-rootnodes of the tree, thus reducing the dimensionalityof the training data for these nodes without loss ofinformation.
Our experiments show that our newclassifier outperforms state-of-the-art methods onaverage, achieving improvements of up to 7.00%and 7.72% for three-way and four-way classifica-tion problems respectively (Section 4).2 Related WorkPang and Lee (2005) incorporated informa-tion about label similarities using metric labeling,where label relations were encoded via a distancemetric.
The output of standard k-ary classifierswas then modified such that similar items weremore likely to be assigned similar labels.
Metriclabeling required a label-corrected item-similarityfunction, which was based on the observation thatthe Percentage of Positive Sentences (PSP) in re-views increased as their ratings increased.
Notice,however, that item similarity was not incorporatedinto the first stage of classifier training.
Metric la-beling adjusted the output of the classifiers onlyafter they were trained without considering rat-ing similarities.
Our approach accounts for inter-category relationships from the outset of classifierdesign, rather than addressing this issue with lateradjustments.Goldberg and Zhu (2006) proposed a semi-supervised learning approach to the rating infer-ence problem in scenarios where labeled train-ing data is scarce.
Using a graph-based opti-misation approach, Goldberg and Zhu demon-strated that the inclusion of unlabeled reviews inthe learning process could produce significantlyhigher prediction accuracy than predictors trainedwithout unlabeled data.
This approach outper-formed competing methods when it consideredrelatively small numbers of labeled samples fromthe four-category movie review dataset (Pang andLee, 2005).
However, the graph-based methoddid not perform well when a large number of la-beled samples was available.
Furthermore, Gold-berg and Zhu?s graph-based learning method wastransductive: new samples could not be classifieduntil they were added to the graph ?
a problemavoided by our approach.Koppel and Schler (2006) considered neutralexamples, which may express a mixed opinion ormay not express any opinion at all, in additionto positive/negative samples.
Their experimentsshowed that neutral examples often did not lieclose to the positive/negative decision boundaryas previously believed.
This gave rise to the ideaof ?optimal stacks?
of SVMs, which were pair-wise combinations of binary classifiers that distin-guish between two categories for the ternary pos-itive/neutral/negative problem (instead of a sin-gle binary classifier trained using only positiveand negative samples).
The search for an opti-mal stack is exponential in time.
Hence, findingsuitable stacks is feasible for the ternary problem,but becomes intractable for larger numbers of cat-egories (in the general case).Snyder and Barzilay (2007) proposed the?Good Grief?
algorithm, which considers multi-ple aspects of a situation (e.g., a restaurant re-view that covers service, ambiance and food), andyields a prediction that minimises the dissatisfac-tion (grief) regarding these aspects.
This methodsignificantly outperformed baseline methods andindividual classifiers.
At present, we do not con-sider separately different aspects of a review ?
atask we intend to undertake in the future.3 Multiclass SVM ClassifiersSince SVMs are binary classifiers, they are oftenemployed for binary sentiment detection.
How-ever, as seen above, it is not straightforward touse SVMs for multi-way classification, particu-larly when there is inter-class similarity.One might initially expect that a hierarchicalSVM classifier could be built using pairwise com-parisons of adjacent class labels.
However, pair-wise comparisons alone do not form a complete63classifier, raising the question of how to com-bine pairwise classifications.
The standard tech-niques to build k-way SVM classifiers are OVAand OVO (Hsu and Lin, 2002), and DAGSVMschemes (Platt et al, 2000).
An OVA classifierrequires k SVMs for a k-category problem, wherethe ith SVM is trained using all samples from theith category versus all other samples.
A sampleis classified by evaluating all k trained SVMs,and the label of the class which maximizes thedecision function is chosen.
The OVO schemetrains k(k?1)2 classifiers derived from a pairwisecomparison of the target categories.
A predic-tion is made by evaluating each SVM and record-ing ?votes?
for the favoured category: the classwith the most votes is selected as the predictedcategory.
The DAGSVM scheme builds a Di-rected Acyclic Graph (DAG) where each non-leafnode has an SVM that discriminates between twoclasses.
A DAGSVM is iteratively constructed ina top-down fashion by forming a list of all theclass labels, and creating a decision node that dis-criminates between the first and last element of thelist.
This decision node yields two child nodes,each of which omits one of the two classes thatwere compared.
Each of these nodes then dis-criminates between the first and last element inits list of classes, and so on.
This process con-tinues for each decision path until only one ele-ment remains in the list.
A sample is classifiedby successively making decisions down the graphuntil a leaf node is reached.
Like OVO, DAGSVMschemes require training k(k?1)2 decision nodes.All three techniques suffer from long trainingtimes ?
an issue that is exacerbated by large datasets such as our corpus of approximately 5000movie reviews (Section 4.1).
Additional problemsassociated with these techniques are: (1) thereis no bound on the generalisation error of OVA,(2) OVO schemes tend to overfit, and (3) the per-formance of a DAGSVM relies on the order inwhich classes are processed.
This order is basedon the class labels (rather than similarity betweensamples), and no practical method is known to op-timize this order.Overfitting also arises when the number of fea-tures is very large compared to the number oftraining samples.
In this case, the SVM trainingprocess may discover a decision plane that sepa-rates the training data well, but performs poorlyon unseen test samples.
While SVM training al-gorithms use regularisation to address the overfit-ting problem, research has shown that a careful re-duction in feature vector dimensionality can helpcombat overfitting (Weston et al, 2003).A fundamental problem with the above threeschemes is that the similarity between samples ofnearby classes is not considered.
Instead, cate-gories are assumed to be independent.
This prob-lem may be addressed by considering SVM re-gression (SVM-R) (Smola and Scho?lkopf, 1998),where class labels are assumed to come from adiscretisation of a continuous function that mapsthe feature space to a metric space.
However,SVM-R, like the SVM schemes described here,trains on the entire feature set for all the classesin the dataset.
In the case of sentiment detection,where words and punctuation marks are com-monly taken as features, the sheer number of fea-tures may overwhelm the number of training sam-ples, and lead to the model overfitting the data.SVM-R also poses the question of how to quan-tise the regressor?s output to produce discrete classpredictions.3.1 The MCST-SVM ClassifierTo address the above problems, we build a deci-sion tree of SVMs that reduces the set of possibleclasses at each decision node, and takes relativeclass similarity into account during the tree con-struction process.
We construct the decision treeas a Minimum Cost Spanning Tree (MCST), de-noted MCST-SVM, based on inter-class similaritymeasured from feature values (Lorena and de Car-valho, 2005).
Each of the decision tree leaves cor-responds to a target class, and the interior nodesgroup classes into disjoint sets.
For each internalnode in the MCST, an SVM is trained to sepa-rate all the samples belonging to classes in its leftsubtree from those in its right subtree.
We use lin-ear SVMs, which have been shown to be effectivetext classifiers (Pang et al, 2002; Pang and Lee,2005), and set the SVM parameters to match thoseused in (Pang and Lee, 2005).1 Figure 1 contrasts1SVMs are implemented using the C/C++ libraryliblinear, a variant of libsvm (Chang and Lin, 2001).64* vs ***** vs **** vs ** ** vs ***** vs ******* vs *****/**/*** vs *****/** vs **** vs ** *******Figure 1: Top section of DAGSVM (left) versus MCST-SVM (right).the DAGSVM and MCST-SVM approaches for afour-class example.The MCST is constructed using Kruskal?s al-gorithm (1956), which works in polynomial time(Algorithm 1).
This algorithm requires a mea-sure of the similarity between every pair ofclasses, which is calculated using the distancebetween a representative vector for each class(Section 3.2).
The MCST is iteratively built ina bottom-up fashion, beginning with all classesas singleton nodes.
In each iteration, the algo-rithm constructs a node comprising the most sim-ilar sets of classes from two previously generatednodes.
The similarity between two sets of classesis the shortest distance between the representa-tive vectors of the classes in each set.
For in-stance, the shortest distance between the sets ofclasses {*/**} and {***/****} is min{dist(*,***),dist(*,****), dist(**,***), dist(**,****)}.
An SVMis then trained to discriminate between the chil-dren of the constructed nodes.With respect to the example in Figure 1, theclasses {*} and {**} are first found to be the mostsimilar, thus forming a node which discriminatesbetween these two classes.
In the next iteration,the classes {**} and {***} are found to be thenext most similar, producing a new node whichdiscriminates between {*/**} and {***}.
Sincethe most similar sets are considered lower in thetree, the sets closer to the root of the tree are pro-gressively more dissimilar, until the root node dis-criminates between the two most dissimilar sets ofclasses.Our approach resembles DAGSVMs in that thestructure of the decision tree is important.
How-ever, unlike DAGSVMs, the MCST-SVM struc-ture is inferred on the basis of similarity be-tween the observed features of the data, whichare known, rather than the labels of the classes,which we are trying to predict.
We assume thatclasses with adjacent labels are similar in the fea-ture space, but if this does not happen in the train-ing data, the MCST-SVM will yield a structurethat exploits inter-class similarity irrespective ofclass labels.
Further, our reliance on featuressupports experimentation with different methodsfor calculating inter-class similarity (Section 3.2).An additional advantage of MCST-SVM classi-fiers over the other schemes is that MCST-SVMrequires only k ?
1 decision nodes for a k-classproblem (and a maximum of k ?
1 decisions tomake a prediction).
That is, only k ?
1 SVMsmust be trained, thereby reducing training time.3.2 Class Similarity MeasuresAs mentioned in Section 3.1, the constructionof an MCST-SVM classifier requires the compu-tation of a similarity measure between classes.The MCST-SVM method may use any measureof inter-class similarity during the tree construc-tion stage, and many such methods exist (e.g., lin-ear discriminant analysis to order a tree of clas-sifiers (Li et al, 2007)).
We elected to use classprototypes to calculate similarity since they haveachieved good performance in previous MCST-SVM applications (Lorena and de Carvalho, 2005;Bickerstaffe et al, 2007), and are fast to computeover many documents with a large feature space.65Algorithm 1 Constructing the MCST-SVM1: Let V be a set of graph vertices, where eachvertex vi ?
V represents rating class i and itsavailable training samples.
?i compute ri, theclass representative for rating class i.2: Let E be a set of graph edges.
?i, j where i 6=j, compute ei,j ?
E, the distance betweenclass representatives ri and rj .3: Sort the members of E in ascending order.4: ?i, let Si = vi, and add Si as a singleton nodeto the MCST-SVM tree T .5: Let i = 0 and j = 0 be counting variables.6: while i < |V | ?
1 do7: Select the j-th edge according to the order-ing of inter-class distances.8: if the vertices of the edge are in disjoint setsSp and Sq then9: Define Sp as a positive class and Sq as anegative class.10: Let St = Sp ?
Sq, and add a new nodecontaining St to T .11: Connect the left and right branches of thenode containing St to the nodes contain-ing Sp and Sq respectively.12: Remove Sp and Sq.13: i = i+ 1.14: end if15: j = j + 1.16: end while17: Train a binary SVM for each non-leaf node ofT .18: Return the MCST-SVM tree T .We first determine a representative feature vectorfor each class, and then calculate the distance be-tween these representative vectors.Determining a representative vector.
Each re-view is represented as a vector of boolean at-tributes, where each attribute indicates the pres-ence or absence of a word or punctuation mark inthe text.
We elect to use boolean attributes sincethey have been shown to be advantageous overterm-frequency approaches for sentiment detec-tion, particularly when SVMs are employed (Panget al, 2002).
We considered two ways of deter-mining a representative vector: centroid and sam-ple selection.?
Centroid.
Given N boolean feature vectorsai of length n, compute the centroid vectorm with valuesmj =1NN?i=1ai,j for j = 1, .
.
.
, n .
(1)This measure produces a representative vec-tor that contains the proportion of trainingsamples for which each feature occurs.?
Sample selection.
From the training samplesof each class, select one sample which max-imises the average Tanimoto coefficient (Tan-imoto, 1957) with respect to all other sam-ples in that class.
The Tanimoto coefficientis an extension of cosine similarity whichyields the Jaccard coefficient for boolean fea-ture vectors.
Given two boolean vectors aand b, the Tanimoto coefficient is defined asdt(a, b) =a ?
b?a?2 + ?b?2 ?
a ?
b , (2)where larger values of dt indicate a higherdegree of similarity between boolean vec-tors.
This measure chooses a representativevector which on average has the most ?over-lap?
with all other vectors in the class.
Weuse Tanimoto distance, rather than the classi-cal cosine similarity measure, since we em-ploy boolean valued features instead of term-frequency features.Calculating distance between vectors.
Wepropose two methods to perform this task: Eu-clidean distance and the Tanimoto coefficient.?
Euclidean distance is used when the vec-tors that represent a class are centroid vectors(real-valued).?
The Tanimoto coefficient is used when therepresentative vectors of a class are booleanvalued.
It is calculated using Equation 2.3.3 Irrelevant Feature CullingThe MCST-SVM scheme provides a naturalmechanism for reducing the dimensionality offeature vectors in order to address the overfitting66problem.
This is due to the fact that each inter-nal decision node is trained using only the sam-ples that belong to the classes relevant to thisnode.
The reviews for these classes are likelyto omit some of the words that appear in the re-views for classes that are relevant to other nodes,in particular in the lower layers of the tree.
Con-sequently, an internal node can be trained usinga subset of the features that occur in the entiretraining dataset.
This subset contains only thosefeatures which are observed in the samples rel-evant to training the node in question.2 Sec-tion 4.2 shows that when tested on ?real world?datasets, this method can remove thousands ofirrelevant features and improve classifier perfor-mance, while reducing memory requirements andtraining times.4 Experiments and ResultsIn this section, we evaluate the MCST-SVM clas-sifier described in Section 3.
First, we system-atically compare the performance of the differ-ent variants of this method: (1) with or with-out culling irrelevant features, and (2) using thecentroid/Euclidean-distance combination or theTanimoto coefficient to measure inter-class simi-larity.
We then compare the best of these methodswith Pang and Lee?s (2005).
Our results show thata combination of relatively small improvementscan achieve a substantial boost in classifier per-formance, yielding significant improvements overPang and Lee?s results.All our experiments are performed with 10-foldcross validation, and the results are assessed usingclassification accuracy.3 ?Significance?
refers tostatistical significance determined by a paired t-test, with p < 0.05.4.1 DatasetOur experiments were conducted on the SentimentScale dataset (v1.0),4 which comprises four sub-corpora of 1770, 902, 1307 and 1027 movie re-views with an associated mapping to a three and2The root node always considers all classes and thereforeconsiders all features across the whole training dataset.3We also have results for mean absolute error (MAE),which confirm our classification accuracy results.4http://www.cs.cornell.edu/People/pabo/moviereview-data .four-star rating for each review.5 Each sub-corpusis written by a different author (denoted Author A,B, C and D respectively), thus avoiding calibrationerror between individual authors and their ratings.Review texts are automatically filtered to leaveonly subjective sentences (motivated by the re-sults described in (Pang and Lee, 2004)); the meannumber of words per review in each subjective-filtered sub-corpus is 435, 374, 455 and 292 re-spectively.4.2 MCST-SVM VariantsTable 1 summarizes the results for the four MCST-SVM variants (the results that are statistically sig-nificant compared to the centroid/no-culling op-tion are boldfaced).Feature culling.
Our results show that featureculling produces some improvement in classi-fier accuracy for all the three-class and four-class datasets.
The impact of feature cullingis statistically significant for all the four-classdatasets when coupled with the Tanimoto coeffi-cient.
However, such an effect was not observedfor the centroid/Euclidean-distance measure.
Inthe three-class datasets, the improvements fromfeature culling are marginal for Authors A, Band C, but statistically significant for Author D(4.61%), both when using the centroid/Euclidean-distance measure and the Tanimoto coefficient.We posit that feature culling affects Author D be-cause it reduces the overfitting problem, whichcaused the initially poor performance of MCST-SVM without culling on this author?s short re-view texts (the reviews by this author, with 292words on average, are the shortest in the Senti-ment Scale dataset by a large margin, Section 4.1).Despite this improvement, all the MCST-SVMvariants (as well as Pang and Lee?s methods) ex-hibit worse performance for Authors B and D,who have shorter reviews, than for Authors Aand C.The culling of irrelevant features also has thebenefit of reducing node training times and facil-5In principle, classifiers for the three- and four-class rat-ings of the Sentiment Scale dataset could be enumerated us-ing optimal stacks of SVMs.
However, we wish to directlycompare our method with Pang and Lee?s (2005).
Higher-discrimination datasets (for which optimal stacks are infeasi-ble) will be tested in the future.67Centroid, Tanimoto, Centroid, Tanimoto,no culling no culling with culling with cullingThree-classAuthor A 70.396 70.396 71.017 71.997Author B 60.556 60.556 61.111 61.111Author C 75.154 75.481 76.231 76.923Author D 59.608 59.608 64.216 64.216Four-classAuthor A 62.429 63.810 63.090 65.720Author B 49.111 49.792 50.622 52.890Author C 64.846 65.689 65.692 66.985Author D 49.118 49.626 51.177 51.873Table 1: Performance accuracy (percentage correct predictions) for MCST-SVM variants.itating a memory-efficient implementation.
Forexample, without feature culling, the nodes ofan MCST-SVM for Author A in the four-classdataset take training samples with 19752 features.In contrast, when irrelevant feature culling is ap-plied, the number of features for each of thetwo non-root decision nodes reduces to 15445and 17297.
This corresponds to a total spacesaving of 6582 features ((19752 ?
15445) +(19752 ?
17297)), yielding an in-memory re-duction of 16.7%.
Such memory reductions areparticularly important for large datasets that mayhave trouble fitting within typical memory limita-tions.
Node training times are also reduced by upto approximately 10%.Class similarity measures.
As mentionedabove, Table 1 shows that the Tanimoto co-efficient, coupled with feature culling, yieldsmarginally better results than the centroid/no-culling option for most authors in the three-classdataset, and significantly better results for all theauthors in the four-class dataset.
The Tanimotocoefficient generally matches or outperforms thecentroid/Euclidean-distance measure both withfeature culling (Columns 4 and 5 in Table 1) andwithout feature culling (Columns 2 and 3).
How-ever, without feature culling, these improvementsare not statistically significant.For most cases in the three-star dataset, the treestructures found using the Tanimoto coefficientare identical to those found using the Euclidean-centroid option, hence the performance of theclassifier is unchanged.
For some validation folds,the Tanimoto coefficient discovered tree structuresthat differed from those found by the Euclidean-centroid option, generally yielding small accuracyimprovements (e.g., 0.98% for Author A in thethree-star dataset, with feature culling).
The Tan-imoto coefficient provides a greater benefit forthe four-class dataset.
Specifically, when featureculling is used (Columns 4 and 5 in Table 1), accu-racy improves by 2.63% and 2.27% for Authors Aand B respectively (statistically significant), andby 1.29% and 0.70% for Authors C and D respec-tively.
This may be explained by the fact that thereare many more tree structures possible for thefour-class case than the three-class case, therebyincreasing the impact of the inter-class similaritymeasure for the four-class case.
However, this im-pact is significant only in conjunction with featureculling.4.3 Comparison with Pang and Lee (2005)Figure 2 compares the performance of the algo-rithms presented in (Pang and Lee, 2005) againstthe performance of the best MCST-SVM variant,which employs feature culling and uses the Tan-imoto coefficient to compute inter-class similar-ity (Section 4.2).
As per (Pang and Lee, 2005),REG indicates SVM-R, which is the baseline ordi-nal regression method.
The suffix ?+PSP?
denotesmethods that use the metric labeling scheme.
Weexcluded DAGSVM from our results to main-tain consistency with Pang and Lee?s experiments.However, according to (Platt et al, 2000), the per-formance difference between DAGSVM and OVAis not statistically significant.Generally, the MCST-SVM is competitiveagainst all the classifiers presented in (Pang andLee, 2005), and in some cases significantly out-performs these methods.
Specifically, the hierar-68404550556065707580Author A Author B Author C Author DClassificationaccuracyOVAOVA+PSPREGREG+PSPBest MCST(a) Three-class data.404550556065707580Author A Author B Author C Author DClassificationaccuracyOVAOVA+PSPREGREG+PSPBest MCST(b) Four-class data.Figure 2: Best MCST-SVM versus competing methods.chical classifier outperforms OVA+PSP by 7% inthe three-class case for Author A (statistically sig-nificant), while in the four-class case the MCST-SVM outperforms the best competing methodsby 7.72%, 3.89% and 4.98% for Authors A, B,and C respectively (statistically significant).
Thesmall improvement of 0.87% for Author D indi-cates that our approach has the most impact forreviews that contain a relatively large amount ofsubjective text.5 Conclusion and Future WorkThis paper described a hierarchical classifier ap-plied to multi-way sentiment detection.
The clas-sifier is built by exploiting inter-class similari-ties to arrange high-performance binary discrim-inators (SVMs) into a tree structure.
Since ourinter-class similarity measures are based on sam-ple features, they make the problem of structuredetermination tractable, and enable experimenta-tion with different similarity measures.
The re-sultant structures provide a natural mechanism toremove irrelevant features at each level of thetree, thus reducing the dimensionality of the fea-ture space, which in turn reduces memory require-ments.
Importantly, these benefits are achievedwhile improving upon state-of-the-art classifica-tion performance, in particular with respect tohigher-discrimination datasets.The MCST-SVM classifier can be generalisedto any number of classes, and is extendable inthe sense that the classifier algorithm employedin each tree node may be replaced by other clas-sifier algorithms as technology advances.
TheMCST-SVM classifier is also versatile, and maybe applied to variations on the rating classificationproblem, e.g., traditional text classification.The MCST-SVM algorithm is not specific tosentiment detection.
However, it has several prop-erties which make it particularly suitable for therating inference problem.
Firstly, the MCST-SVMaccounts for inter-class similarity and is thereforecapable of capturing the ordinal nature of ratings.Secondly, the tree structures permit irrelevant fea-ture culling, which in turn reduces memory re-quirements and training times.Future work will involve testing our approachwith higher-discrimination datasets, developingmethods to pre-process review texts (e.g., im-proved negation tagging, and incorporating part-of-speech tagging), and further addressing theproblem of overfitting.
To this effect we willinvestigate different feature selection algorithms,e.g., (Weston et al, 2003), and their utilisationwithin the classifier trees.
We also propose toconsider aspects of reviews (Snyder and Barzilay,2007), and investigate other methods that mea-sure class similarity, such as selecting typical in-stances (Zhang, 1992).AcknowledgmentsThis research is supported in part by ARC grantLP0883416 and GapBuster Worldwide.69ReferencesAllison, B.
2008.
Sentiment detection using lexically-based classifiers.
In Proceedings of the 11th Inter-national Conference on Text, Speech and Dialogue,pages 21?28, Brno, Czech Republic.Beygelzimer, A., J. Langford, and P. Ravikumar.
2009.Error-correcting tournaments.
In Proceedings ofthe 20th International Conference on AlgorithmicLearning Theory, pages 247?262, Porto, Portugal.Bickerstaffe, A., A.
Lane, B. Meyer, and K. Mar-riott.
2007.
Building smart diagram environmentswith domain-specific gesture recognizers.
In Pro-ceedings of the 7th IAPR International Workshopon Graphics Recognition, pages 145?156, Curitiba,Brazil.Chang, C.C.
and C.J.
Lin, 2001.
LIBSVM: alibrary for support vector machines.
Soft-ware available at http://www.csie.ntu.edu.tw/?cjlin/libsvm.Goldberg, A.B.
and X. Zhu.
2006.
Seeing starswhen there aren?t many stars: Graph-based semi-supervised learning for sentiment categorization.
InTextGraphs: Workshop on Graph Based MethodsFor NLP, pages 45?52, New York, New York.Hsu, C. W. and C. J. Lin.
2002.
A comparison ofmethods for multi-class support vector machines.IEEE Transactions on Neural Networks, 13(2):415?425.Koppel, M. and J. Schler.
2006.
The importance ofneutral examples for learning sentiment.
Computa-tional Intelligence, 22(2):100?109.Kruskal, J.
B.
1956.
On the shortest spanning subtreeand the traveling salesman problem.
Proceedings ofthe American Mathematical Society, 7(1):48?50.Li, T., S. Zhu, and M. Ogihara.
2007.
Hierarchicaldocument classification using automatically gener-ated hierarchy.
Journal of Intelligent InformationSystems, 29(2):211?230.Lorena, A. C. and A. C. P. L. F. de Carvalho.
2005.Minimum spanning trees in hierarchical multiclassSupport Vector Machines generation.
Innovationsin Applied Artificial Intelligence, 3533:422?431.Mao, Y. and G. Lebanon.
2006.
Isotonic conditionalrandom fields and local sentiment flow.
In Proceed-ings of the 20th Annual Conference on NIPS, pages961?968, British Columbia, Canada.McDonald, R., K. Hannan, T. Neylon, M. Wells, andJ.
Reynar.
2007.
Structured models for fine-to-coarse sentiment analysis.
In Proceedings of the45th Annual Meeting of the ACL, pages 432?439,Prague, Czech Republic.Pang, B. and L. Lee.
2004.
A sentimental educa-tion: Sentiment analysis using subjectivity summa-rization based on minimum cuts.
In Proceedings ofthe 42nd Annual Meeting of the ACL, pages 271?278, Barcelona, Spain.Pang, B. and L. Lee.
2005.
Seeing stars: Exploitingclass relationships for sentiment categorization withrespect to rating scales.
In Proceedings of the 43rdAnnual Meeting of the ACL, pages 115?124, AnnArbor, Michigan.Pang, B., L. Lee, and S. Vaithyanathan.
2002.
Thumbsup?
Sentiment classification using machine learningtechniques.
In Proceedings of the Conference onEmpirical Methods in NLP, pages 79?86, Philadel-phia, Pennsylvania.Platt, J. C., N. Cristinini, and J. Shawe-Taylor.
2000.Large margin DAGs for multiclass classification.Advances in Neural Information Processing Sys-tems, 12:547?553.Smola, A. and B. Scho?lkopf.
1998.
A Tutorial onSupport Vector regression.
Technical Report COLTNC-TR-98-030, University of London.Snyder, B. and R. Barzilay.
2007.
Multipleaspect ranking using the Good Grief algorithm.In Proceedings of HLT/NAACL, pages 300?307,Rochester, New York.Tanimoto, T.T.
1957.
IBM internal report.Weston, J., A. Elisseff, B. Scho?lkopf, and M. Tipping.2003.
Use of the zero-norm with linear models andkernel methods.
Journal of Machine Learning Re-search, 3:1439?1461.Wilson, T., J. Wiebe, and P. Hoffmann.
2005.
Recog-nizing contextual polarity in phrase-level sentimentanalysis.
In Proceedings of the Conference on Em-pirical Methods in NLP, pages 347?354, Vancouver,Canada.Yu, H. and V. Hatzivassiloglou.
2003.
Towards an-swering opinion questions: Separating facts fromopinions and identifying the polarity of opinion sen-tences.
In Proceedings of the Conference on Em-pirical Methods in NLP, pages 129?136, Sapporo,Japan.Zhang, J.
1992.
Selecting typical instances ininstance-based learning.
In Proceedings of the9th International Workshop on Machine Learning,pages 470?479, Aberdeen, Scotland.70
