Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 177?180,Suntec, Singapore, 4 August 2009.c?2009 ACL and AFNLPMining User Reviews: from Specification to SummarizationXinfan MengKey Laboratory ofComputational Linguistics(Peking University)Ministry of Education, Chinamxf@pku.edu.cnHoufeng WangKey Laboratory ofComputational Linguistics(Peking University)Ministry of Education, Chinawanghf@pku.edu.cnAbstractThis paper proposes a method to ex-tract product features from user reviewsand generate a review summary.
Thismethod only relies on product specifica-tions, which usually are easy to obtain.Other resources like segmenter, POS tag-ger or parser are not required.
At fea-ture extraction stage, multiple specifica-tions are clustered to extend the vocabu-lary of product features.
Hierarchy struc-ture information and unit of measurementinformation are mined from the specifi-cation to improve the accuracy of featureextraction.
At summary generation stage,hierarchy information in specifications isused to provide a natural conceptual viewof product features.1 IntroductionReview mining and summarization aims to extractusers?
opinions towards specific products fromreviews and provide an easy-to-understand sum-mary of those opinions for potential buyers ormanufacture companies.
The task of mining re-views usually comprises two subtasks: productfeatures extraction and summary generation.Hu and Liu (2004a) use association miningmethods to find frequent product features and useopinion words to predict infrequent product fea-tures.
A.M. Popescu and O. Etzioni (2005) pro-poses OPINE, an unsupervised information ex-traction system, which is built on top of the Kon-wItAll Web information-extraction system.
In or-der to reduce the features redundancy and pro-vide a conceptual view of extracted features, G.Carenini et al (2006a) enhances the earlier workof Hu and Liu (2004a) by mapping the extractedfeatures into a hierarchy of features which de-scribes the entity of interest.
M. Gamon et al(2005) clusters sentences in reviews, then labeleach cluster with a keyword and finally providea tree map visualization for each product model.Qi Su et al (2008) describes a system that clus-ters product features and opinion words simulta-neously and iteratively.2 Our ApproachTo generate an accurate review summary for aspecific product, product features must be iden-tified accurately.
Since product features are of-ten domain-dependent, it is desirable that the fea-tures extraction system is as flexible as possible.Our approach are unsupervised and relies only onproduct specifications.2.1 Specification MiningProduct specifications can usually be fetched fromweb sites like Amazon automatically.
Those mate-rials have several characteristics that are very help-ful to review mining:1.
Nicely structured, provide a natural concep-tual view of products;2.
Include only relevant information of theproduct and contain few noise words;3.
Except for the product feature itself, usuallyalso provide a unit to measure this feature.A typical mobile phone specification is partiallygiven below:?
Physical features?
Form: Mono block with full keyboard?
Dimensions: 4.49 x 2.24 x 0.39 inch?
Weight: 4.47 oz?
Display and 3D?
Size: 2.36 inch?
Resolution: 320 x 240 pixels (QVGA)1772.2 ArchitectureThe architecture of our approach.
is depicted inFigure 1.
We first retrieve multiple specificationsfrom various sources like websites, user manu-als etc.
Then we run clustering algorithms onthe specifications and generate a specification tree.And then we use this specification tree to extractfeatures from product reviews.
Finally the ex-tracted features are presented in a tree form.Specifications ReviewsAppearanceSizeThicknessPrice...SizePriceThickness...2 FeatureExtractionSize: smallThickness: thinprice: low1 Clustering3 SummaryGenerationFigure 1: Architecture Overview2.3 Specification ClusteringUsually, each product specification describes aparticular product model.
Some features arepresent in every product specification.
But thereare cases that some features are not available in allspecifications.
For instance, ?WiFi?
features areonly available in a few mobile phones specifica-tions.
Also, different specifications might expressthe same features with different words or terms.So it is necessary to combine multiple specifica-tions to include all possible features.
Clusteringalgorithm can be used to combine specifications.We propose an approach that takes following in-herent information of specifications into account:?
Hierarchy structure: Positions of featuresin hierarchy reflect relationships between fea-tures.
For example, ?length?, ?width?
featureare often placed under ?size?
feature.?
Unit of measurement: Similar features areusually measured in similar units.
Thoughdifferent specification might refer the samefeature with different terms, the units of mea-surement used to describe those terms areusually the same.
For example, ?dimension?and ?size?
are different terms, but they sharethe same unit ?mm?
or ?inch?.Naturally, a product can be viewed as a tree offeatures.
The root is the product itself.
Each nodein the tree represents a feature in the product.
Acomplex feature might be conceptually split intoseveral simple features.
In this case, the complexfeature is represented as a parent and the simplefeatures are represented as its children.To construct such a product feature tree, weadopt the following algorithm:?
Parse specifications: We first build a dic-tionary for common units of measurement.Then for every specification, we use regularexpression and unit dictionary to parse it to atree of (feature, unit) pairs.?
Cluster specification trees: Given multiplespecification trees, we cluster them into a sin-gle tree.
Similarities between features are acombination of their lexical similarity, unitsimilarity and positions in hierarchy:Sim(f1, f2) =Simlex(f1, f2)+ Simunit(f1, f2)+ ?
?
Simparent(f1, f2)+ (1?
?)
?
Simchildren(f1, f2)The parameter ?
is set to 0.7 empirically.
IfSim(f1, f2) is larger than 5, we merge fea-tures f1 and f2 together.After clustering, we can get a specification treeresembles the one in subsection 2.1.
However,this specification tree contains much more featuresthan any single specification.2.4 Features ExtractionFeatures described in reviews can be classified intotwo categories: explicit features and implicit fea-tures (Hu and Liu, 2004a).
In the following sec-tions, we describe methods to extract features inChinese product reviews.
However, these meth-ods are designed to be flexible so that they can beeasily adapted to other languages.1782.4.1 Explicit Feature ExtractionWe generate bi-grams in character level for everyfeature in the specification tree, and then matchthem to every sentence in the reviews.
There mightbe cases that some bi-grams would overlap or con-catenated.
In these cases, we join those bi-gramstogether to form a longer expression.2.4.2 Implicit Feature ExtractionSome features are not mentioned directly but canbe inferred from the text.
Qi Su et al (2008) in-vestigates the problem of extracting those kindsof features.
There approach utilizes the associa-tion between features and opinion words to findimplicit features when opinion words are presentin the text.
Our methods consider another kind ofassociation: the association between features andunits of measurement.
For example, in the sen-tence ?Amobile phone with 8 mega-pixel, not verycommon in the market.?
feature name is absent inthe sentence, but the unit of measurement ?megapixel?
indicates that this sentence is describing thefeature ?camera resolution?.We use regular expression and dictionary of unitto extract those features.2.5 Summary GenerationThere are many ways to provide a summary.
Huand Liu (2004b) count the number of positive andnegative review items towards individual featureand present these statistics to users.
G. Careniniet al (2006b) and M. Gamon et al (2005) bothadopt a tree map visualization to display featuresand sentiments associated with features.We adopt a relatively simple method to generatea summary.
We do not predict the polarities of theuser?s overall attitudes towards product features.Predicting polarities might entail the constructionof a sentiment dictionary, which is domain depen-dent.
Also, we believe that text descriptions of fea-tures are more helpful to users.
For example, forfeature ?size?, descriptions like ?small?
and ?thin?are more readable than ?positive?.Usually, the words used to describe a productfeature are short.
For each product feature, we re-port several most frequently occurring uni-gramsand bi-grams as the summary of this feature.
InFigure 2, we present a snippet of a sample sum-mary output.?
mobile phone: not bad, expensiveo appearance: cool color: white size: small, thino camera functionality: so-so, acceptable picture quality: good picture resolution: not higho entertainment functionality: powerful game: fun, simpleFigure 2: A Summary Snippet3 ExperimentsIn this paper, we mainly focus on Chinese prod-uct reviews.
The experimental data are retrievedfrom ZOL websites (www.zol.com.cn).
Wecollected user reviews on 2 mobile phones, 1 digi-tal camera and 2 notebook computers.
To evaluateperformance of our algorithm on real-world data,we do not perform noise word filtering on thesedata.
Then we have a human tagger to tag featuresin the user reviews.
Both explicit features and im-plicit features are tagged.No.
of Clustering Mobile Digital NotebookSpecifications Phone Camera Computer1 153 101 1025 436 312 21110 520 508 312Table 1: No.
of Features in Specification Trees.The specifications for all 3 kinds of productsare retrieved from ZOL, PConline and IT168 web-sites.
We run the clustering algorithm on the spec-ifications and generate a specification tree for eachkind of product.
Table 1 shows that our clusteringmethod is effective in collecting product features.The number of features increases rapidly with thenumber of specifications input into clustering al-gorithm.
When we use 10 specifications as input,the clustering methods can collect several hundredfeatures.Then we run our algorithm on the data and eval-uate the precision and recall.
We also run the al-gorithms described in Hu and Liu (2004a) on thesame data as the baseline.From Table 2, we can see the precision of base-line system is much lower than its recall.
Examin-ing the features extracted by baseline system, wefind that many mistakenly recognized features arehigh-frequency words.
Some of those words ap-pear many times in text.
They are related to prod-179Product ModelNo.
of Hu and Liu?s Approach the Proposed ApproachFeatures Precision Recall F-measure Precision Recall F-measureMobile Phone 1 507 0.58 0.74 0.65 0.69 0.78 0.73Mobile Phone 2 477 0.59 0.65 0.62 0.71 0.77 0.74Digital camera 86 0.56 0.68 0.61 0.69 0.78 0.73Notebook Computer 1 139 0.41 0.63 0.50 0.70 0.74 0.72Notebook Computer 2 95 0.71 0.88 0.79 0.76 0.88 0.82Table 2: Precision and Recall of Product Extraction.uct but are not considered to be features.
Someexamples of these words are ?advantages?, ?dis-advantages?
and ?good points?
etc.
And manyother high-frequency words are completely irrel-evant to product reviews.
Those words include?user?, ?review?
and ?comment?
etc.
In contrast,our approach recognizes features by matching bi-grams to the specification tree.
Because thosehigh-frequency words usually are not present inspecifications.
They are ignored by our approach.Thus from Table 2, we can conclude that our ap-proach could achieve a relatively high precisionwhile keep a high recall.Product Model PrecisionMobile Phone 1 0.78Mobile Phone 2 0.72Digital camera 0.81Notebook Computer 1 0.73Notebook Computer 2 0.74Table 3: Precision of Summary.After the summary is given, for each word insummary, we ask one person to decide whetherthis word correctly describe the feature.
Table 3gives the summary precision for each productmodel.
In general, on-line reviews have severalcharacteristics in common.
The sentences are usu-ally short.
Also, words describing features usu-ally co-occur with features in the same sentence.Thus, when the features in a sentence are correctlyrecognized, Words describing those features arelikely to be identified by our methods.4 ConclusionIn this paper, we describe a simple but effectiveway to extract product features from user reviewsand provide an easy-to-understand summary.
Theproposed approach is based only on product spec-ifications.
The experimental results indicate thatour approach is promising.In future works, we will try to introduce otherresources and tools into our system.
We will alsoexplore different ways of presenting and visualiz-ing the summary to improve user experience.AcknowledgmentsThis research is supported by National NaturalScience Foundation of Chinese (No.60675035)and Beijing Natural Science Foundation(No.4072012).ReferencesM.
Hu and B. Liu.
2004a.
Mining and Summariz-ing Customer Reviews.
In Proceedings of the 2004ACM SIGKDD international conference on Knowl-edge discovery and data mining, pages 168-177.ACM Press New York, NY, USA.M.
Hu and B. Liu.
2004b.
Mining Opinion Featuresin Customer Reviews.
In Proceedings of NineteenthNational Conference on Artificial Intelligence.M.
Gamon, A. Aue, S. Corston-Oliver, and E. Ringger.2005.
Pulse: Mining Customer Opinions from FreeText.
In Proceedings of the 6th International Sym-posium on Intelligent Data Analysis.A.M.
Popescu and O. Etzioni.
2005.
Extracting Prod-uct Features and Opinions from reviews.
In Pro-ceedings of the Conference on Empirical Methodsin Natural Language Processing(EMNLP).Giuseppe Carenini, Raymond T. Ng, and Adam Pauls.2006a.
Multi-Document Summarization of Evalua-tive Text.
In Proceedings of the conference of theEuropean Chapter of the Association for Computa-tional Linguistics.Giuseppe Carenini, Raymond T. Ng, and Adam Pauls.2006b.
Interactive multimedia summaries of evalu-ative text.
In Proceedings of Intelligent User Inter-faces (IUI), pages 124-131.
ACM Press, 2006.Qi Su, Xinying Xu, Honglei Guo, Zhili Guo, Xian Wu,Xiaoxun Zhang, Bin Swen.
2008.
Hidden Senti-ment Association In Chinese Web Opinion Mining.In Proceedings of the 17th International Conferenceon the World Wide Web, pages 959-968.180
