Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1216?1224,October 25-29, 2014, Doha, Qatar.
c?2014 Association for Computational LinguisticsAn Iterative Link-based Method for Parallel Web Page MiningLe Liu1, Yu Hong1, Jun Lu2, Jun Lang2, Heng Ji3, Jianmin Yao11School of Computer Science & Technology, Soochow University, Suzhou, 215006, China2Institute for Infocomm Research, Singapore, 1386323Computer Science Department, Rensselaer Polytechnic Institute, Troy, NY 12180, USAgiden@sina.cn,{tianxianer,lujun59,billlangjun}@gmail.comjih@rpi.edu,jyao@suda.edu.cnAbstractsIdentifying parallel web pages from bi-lingual web sites is a crucial step of bi-lingual resource construction for cross-lingual information processing.
In thispaper, we propose a link-based approachto distinguish parallel web pages from bi-lingual web sites.
Compared with the ex-isting methods, which only employ theinternal translation similarity (such ascontent-based similarity and page struc-tural similarity), we hypothesize that theexternal translation similarity is an effec-tive feature to identify parallel web pages.Within a bilingual web site, web pagesare interconnected by hyperlinks.
Thebasic idea of our method is that the trans-lation similarity of two pages can be in-ferred from their neighbor pages, whichcan be adopted as an important source ofexternal similarity.
Thus, the translationsimilarity of page pairs will influenceeach other.
An iterative algorithm is de-veloped to estimate the external transla-tion similarity and the final translationsimilarity.
Both internal and externalsimilarity measures are combined in theiterative algorithm.
Experiments on sixbilingual websites demonstrate that ourmethod is effective and obtains signifi-cant improvement (6.2% F-Score) overthe baseline which only utilizes internaltranslation similarity.1 IntroductionParallel corpora have played an important role inmultilingual Natural Language Processing, espe-cially in Machine Translation (MT) and Cross-lingual Information Retrieval(CLIR).
However,it?s time-consuming to build parallel corporamanually.
Some existing parallel corpora aresubject to subscription or license fee and thus notfreely available, while others are domain-specific.Therefore, a lot of previous research has focusedon automatically mining parallel corpora fromthe web.In the past decade, there have been extensivestudies on parallel resource extraction from theweb (e.g., Chen and Nie, 2000; Resnik 2003;Jiang et al., 2009) and many effective Web min-ing systems have been developed such asSTRAND, PTMiner, BITS and WPDE.
For mostof these mining systems, there is a typical paral-lel resource mining strategy which involves threesteps: (1) locate the bilingual websites (2) identi-fy  parallel web pages from these bilingual web-sites and (3) extract bilingual resources from theparallel web pages.In this paper, we focus on the step (2) which isregarded as the core of the mining system(Chunyu, 2007).
Estimating the translation simi-larity of two pages is the most basic and keyproblem in this step.
Previous approaches havetried to tackle this problem by using the infor-mation within the pages.
For example, in theSTRAND and PTMiner system, a structural fil-tering process that relies on the analysis of theunderlying HTML structure of pages is used todetermine a set of pair-specific structural values,and then the values are used to decide whetherthe pages are translations of one another.
TheBITS system filters out bad pairs by using a largebilingual dictionary to compute a content-basedsimilarity score and comparing the score with athreshold.
The WPDE system combines URLsimilarity, structure similarity with content-basedsimilarity to discover and verify candidate paral-lel page pairs.
Some other features or rules suchas page size ratio, predefined hypertexts whichlink to different language versions of a web pageare also used in most of these systems.
Here, allof the mining systems are simply using the in-formation within the page in the process of find-1216ing parallel web pages.
In this paper, we attemptto explore other information to identify parallelweb pages.On the Internet, most web pages are linked byhyperlinks.
We argue that the translation similar-ity of two pages depends on not only their inter-nal information but also their neighbors.
Theneighbors of a web page are a set of pages,which link to the page.
We find that the similari-ty of neighbors can provide more reliable evi-dence in estimating the translation similarity oftwo pages.The main issues are discussed in this paper asfollows:?
Can the neighbors of candidate page pairsreally contribute to estimating the translationsimilarity??
How to estimate the translation similarity ofcandidate page pairs by using their neighbors?Our method has the following advantages:High performanceThe external and internal information is com-bined to verify parallel page pairs in our method,while in previous mining systems, only internalinformation was used.
Experimental results showthat compared with existing parallel page pairidentification technologies, our method obtainsboth higher precision and recall (6.2% and 6.3%improvement than the baseline, respectively).
Inaddition, the external information used in ourmethod is a more effective feature than internalfeatures alone such as structural similarity andcontent-based similarity.Language independentIn principle, our method is language inde-pendent and can be easily ported to new lan-guage pairs, except for the language-specific bi-lingual lexicons.
Our method takes full ad-vantage of the link information that is language-independent.
For the bilingual lexicons in ourexperiments, compared to previous methods, ourmethod does not need a big bilingual lexicon,which is good news to less-resource languagepairs.Unsupervised and fewer parametersIn previous work, some parameters need to beoptimized.
Due to the diversity of web pagestyles, it is not trivial to obtain the best parame-ters.
Some previous researches(Resnik, 2003;Zhang et al., 2006) attempt to optimize parame-ters by employing machine learning method.
Incontrast, in our method, only two parametersneed to be estimated.
One parameter remainsstable for different style websites.
Another pa-rameter can be easily adjusted to achieve the bestperformance.
Therefore, our method can be usedin other websites with different styles, withoutmuch effort to optimize these parameters.2 Related WorkA large amount of literature has been publishedon parallel resource mining from the web.
Ac-cording to the existing form of the parallel re-source on the Internet, related work can be cate-gorized as follows:Mining from bilingual websitesMost existing web mining systems aimed atmining bilingual resource from the bilingualwebsites, such as PTMiner (Nie et al., 1999),STRAND (Resnik and Smith, 2003), BITS (Maand Liberman, 1999), PTI (Chen et al., 2004).PTMiner uses search engines to pinpoint thecandidate sites that are likely to contain parallelpages, and then uses the collected URLs as seedsto further crawl each web site for more URLs.Web page pairs are extracted based on manuallydefined URL pattern matching, and further fil-tered according to several criteria.
STRAND us-es a search engine to search for multilingualwebsites and generated candidate page pairsbased on manually created substitution rules.Then, it filters some candidate pairs by analyzingthe HTML pages.
PTI crawls the web to fetch(potentially parallel) candidate multilingual webdocuments by using a web spider.
To determinethe parallelism between potential document pairs,a filename comparison module is used to checkfilename resemblance, and a content analysismodule is used to measure the semantic similari-ty.
BITS was the first to obtain bilingual web-sites by employing a language identificationmodule, and then for each bilingual website, itextracts parallel pages based on their content.Mining from bilingual web pagesParallel/bilingual resources may exist not onlyin two parallel monolingual web pages, but alsoin single bilingual web pages.
Jiang et al.
(2009)used an adaptive pattern-based method to mineinteresting bilingual data based on the observa-tion that bilingual data usually appears collec-tively following similar patterns.
They found thatbilingual web pages are a promising source ofup-to-date bilingual terms/sentences which covermany domains and application scenarios.
In ad-dition, Feng et al.
(2010) proposed a new method1217to automatically acquire bilingual web pagesfrom the result pages of a search engine.Mining from comparable corpusSeveral attempts have been made to extractparallel resources from comparable corpora.Zhao et al.
(2002) proposed a robust, adaptiveapproach for mining parallel sentences from abilingual comparable news collection.
In theirmethod, sentence length models and lexicon-based models were combined under a maximumlikelihood criterion.
Smith et al.
(2010) foundthat Wikipedia contains a lot of comparable doc-uments, and adopted a ranking model to selectparallel sentence pairs from comparable docu-ments.
Bharadwaj et al.
(2011) used a SVM clas-sifier with some new features to identify parallelsentences from Wikipedia.3 Iterative Link-based Parallel WebPages MiningAs mentioned, the basic idea of our method isthat the similarity of two pages can be inferredfrom their neighbors.
This idea is illustrated inFigure 1.A DECBA?D?E?C?B?
?Figure 1 Illustration of the link-based methodIn Figure 1, A, B, C, D and E are some pagesin the same language; while A?, B?, C?, D?
and E?are some pages in another language.
The solidblack arrows indicate the links between thesepages.
For example, page A points to C, page B?points to C?
and so on.
Then the page set {A, B,D, E} is called the neighbors of page C. Similar-ly, the page set {A?, B?, D?, E?}
contains theneighbors of page C?.
If the page pairs : <A, A?>,<B, B?>, <D, D?> and <E, E?> have high transla-tion similarities, then it can be inferred that pageC and C?
have a high probability to be a pair ofparallel pages.
Every page has its own neighbors.For each web page, our method views link-in andlink-out hyperlinks as the same.
Thus, the linkedpages will influence each other in estimating thetranslation similarity.
For example, the similari-ties of two pairs <A, A?> and <C, C?> will influ-ence each other.
It is an iterative process.
Wewill elaborate the process in the following sec-tions.Since our goal is to find parallel pages in aspecific website, the key task is to evaluate thetranslation similarity of two pages (which are indifferent languages) as accurately as possible.The final similarity of two pages should dependboth on their internal similarity and external sim-ilarity.
The internal similarity means the similari-ty estimated by using the information in the pageitself, such as the structure similarity and thecontent-based similarity of the two pages.
On theother hand, the external similarity of two pages isthe similarity depending on their neighbors.
Thefinal translation similarity is called the En-hanced Translation Similarity (ETS).
The ETSof two pages can be calculated as follows:(   )        (   )  (   )(   )   [   ]              (1)Where,    (   ) is the internal translation simi-larity of two pages: e and c;     (   ) representsthe external translation similarity of pages e andc.
(   ) indicates the final similarity of twopages, which combines the internal with externaltranslation similarity.In this paper, we conduct the experiments onEnglish-Chinese parallel page pair mining.
How-ever, our method is language-independent.
Thus,it can be applied to other language pairs by onlyreplacing a bilingual lexicon.
The symbol e and calways indicate an English page and a Chinesepage respectively in this paper.
In the followingsections, we will describe how to calculate the(   ) and     (   ) step by step.3.1 PreprocessingThe input of our method is a bilingual website.This paper aims to find English/Chinese parallelpages.
So a 3-gram language model is used toidentify (or classify) the language of a certaindocument.
The performance of the languageidentification module achieves 99.5% accuracythrough in-house testing.
As a result, a set ofEnglish pages and a set of Chinese pages are ob-tained.
In order to get the neighbors of a page,for each bilingual website, two networks are con-structed based on the hyperlinks, one for Englishpages and another for Chinese pages.3.2 The Internal Translation SimilarityFollowing Resnik and Smith (2003), three fea-tures are used to evaluate the internal translationsimilarity of two pages:1218The size ratio of two pagesThe length ratio of two documents is the sim-plest criterion for determining whether two doc-uments are parallel or not.
Parallel documentstend to be similar in length.
And it is reasonableto assume that for text E in one language and textF in another language, length(E) ?
C?length(F),where C is a constant that depends on the lan-guage pair.
Here, the content length of a webpage is regarded as its length.The structure similarity of two pagesThe HTML tags describe and control a webpage?s structure.
Therefore, the structure similar-ity of two pages can be calculated by theirHTML tags.
Here, the HTML tags of each pageare extracted (except the visual tags such as ?B?,?FONT?.)
as a linear sequence.
Then the struc-ture similarity of two pages is computed by com-paring their linearized sequences.
In this paper,the LCS algorithm (Dan, 1997) is adopted to findthe longest common sequences of the two HTMLtag sequences.
The ratio of LCS length and theaverage length of two HTML tag sequences areused as the structure similarity of the two pages.The content-based translation similarity oftwo pagesThe basic idea is that if two documents areparallel, they will contain word pairs that are mu-tual translations (Ma, 1999).
So the percentage oftranslation word pairs in the two pages can beconsidered as the content-based similarity.
Thetranslation words of two documents can be ex-tracted by using a bilingual lexicon.
Here, foreach word in English document, we will try tofind a corresponding word in Chinese document.Finally, the internal translation similarity oftwo pages is calculated as follows:(   )       (   )  (   )(   )   [   ]        (2)Where,     (   )  and        (   )  are the con-tent-based and structural similarity of page   andrespectively.
In addition, the size ratio of twopages is used to filter invalid page pairs.3.3 The External and Enhanced Transla-tion SimilarityAs described above, the external translationsimilarity of two pages depends on their neigh-bors:(   )     (  ( )   ( )) (3)Where, PG(x), a set of pages, is the neighbors ofpage x.
Obviously, the similarity of two sets re-lies on the similarity of the elements in the twosets.
Here, the elements are namely web pages.So,     (   ) equals to    (  ( )   ( )), and(  ( )   ( ))  depends on    (     )(       belongs to    ( )   ( ) , respectively)and    (   ) .
According to Equation (1),(   )  depends on    (   )  and     (   ) .Therefore, it is a process of iteration.
(   )will converge after a certain number of iterations.Thus,     (   )  is defined as the enhancedsimilarity of page   and   after the i-th iteration,and the same is for(   ) and     (  ( )( )) .
(  ( )   ( ))  is computed bythe following algorithm:Algorithm 1: Estimating the external transla-tion similarityInput:      ( )   ( )Output:(   )Procedure:?
0?
( )?
( )While        and       are both not empty:?
((   ))?
+        (   )Remove   fromRemove   from(   )       ( ( )  ( ))(   ( )     ( ) )Algorithm 2 Estimating the enhanced transla-tion similarityInput:      , (the English and Chinese page set)Output:    (   )Initialization: Set ETS(e, c) random value orsmall valueProcedure:LOOP:For each   in    :For each   in   :(   )(   )(   )     (   )Parameters normalizationUNTIL    (   ) is stableAlgorithm 1 tries to find the real parallel pairsfrom   ( ) and   ( ).
The similarity of   ( )and   ( ) is calculated based on the similarity1219values of these pairs.
Finally,    (   ) is calcu-lated by the following algorithm 2.In Algorithm 2, the input    and    are Englishand Chinese page sets in a certain bilingual web-site.
We use algorithm 2 to estimate the en-hanced translation similarity.3.4 Find the Parallel Page PairsAt last, the enhanced translation similarity ofevery pair is obtained, and the parallel page pairscan be extracted in terms of these similarities:Algorithm 3 Finding parallel page pairsInput:(   )(or       )Output:  Parallel Page Pairs List :Procedure:LOOP:(   (   ))Add       toRemove   fromRemove   fromUNTIL size of     >       (or    (   )  <)This algorithm is similar to Algorithm 1 ineach bilingual website.
The input      is aninteger threshold which means that only toppage pairs will be extracted in a certainwebsite.
It needs to be noted that      is al-ways less than      and     .
While the inputis another kind of threshold that isused for extracting page pairs with high transla-tion similarity.4 Experiments and Analysis4.1 Experimental setupOur experiments focus on six bilingual websites.Most of them are selected from HK governmentwebsites.
All the web pages were retrieved byusing a web site download tool: HTTrack1.
Wenotice that a small amount of pages doesn?t al-ways contain valuable contents.
So, we put athreshold (100 bytes in our experiment) on theweb pages' content to filter meaningless pages.
Inorder to evaluate our method, the bilingual pagepairs of each website are annotated by a humanannotator.
Finally, we got 23109 pages and11684 bilingual page pairs in total for testing.1 http://www.httrack.com/The basic information of these websites is listedin Table 1.It?s time-consuming to annotate whether twopages is parallel or not.
Note that if a websitecontains N English pages and M Chinese pages,an annotator has to label N*M page pairs.
To thebest of our knowledge, there is no large scale andpublic parallel page pair dataset with human an-notation.
So we try to build a reliable and large-scale dataset.In our experiments, URL similarity is used toreduce the workload for annotation.
For a certainwebsite, firstly, we obtain its URL pattern be-tween English and Chinese pages manually.
Forexample, in the website ?www.gov.hk?, the URLpairs like:http://www.gov.hk/en/about/govdirectory/   (English)http://www.gov.hk/sc/about/govdirectory/   (Chinese)The URL pairs always point to a pair of paral-lel pages.
So <?/en/?,?/sc/?> is considered as aURL pattern that was used to find parallel pages.For the other URLs that can?t match the pattern,we have to label them by hand.
The column ?Nopattern pairs?
in Table 1 shows that the numberof parallel page pairs which mismatch any pat-terns.Table 1 Number of pages and bilingual page pairs ofeach websitesSite ID En/Ch pagesTotalpairsNo pat-tern pairsURLS1 1101/1098 1092 20 www.gov.hkS2 501/497 487 7 www.customs.gov.hkS3 995/775 768 12 www.sbc.edu.sgS4 4085/3838 3648 4 www.swd.gov.hkS5 660/637 637 0 www.landsd.gov.hkS6 4733/4626 4615 8 www.td.gov.hktotal 12075/11471 11684 51Each website listed in Table 1 has a URL pat-tern for most parallel web pages.
Some previousresearches used the URL similarity or patterns tofind parallel page pairs.
However, due to the di-versity of web page styles and website mainte-nance mechanisms, bilingual websites adopt var-ied naming schemes for parallel documents (Shi,et al, 2006).
The effect of URL pattern-basedmining always depends on the style of website.In order to build a large dataset, the URL patternis not used in our method.
Our method is able tohandle bilingual websites without URL patternrules.In addition, an English-Chinese dictionarywith 64K words pairs is used in our experiments.Algorithm 3 needs a threshold       or1220.
It is very hard to tune thebecause it varies a lot in different websites andlanguage pairs.
However, Table 1 shows that thenumber of parallel pages is smaller than that ofEnglish and Chinese pages.
Here, for each web-site, the      is set to the number of Chinesepages (which is always smaller than that of Eng-lish pages).
In this way, the precision will neverreach 100%, but it is more practical in a real ap-plication.
As a result, in some experiments, weonly report the F-score, and the precision andrecall can be calculated as follows:(            )(4)(            )(5)Where,        for each website is listed in the?Total  pairs?
column of Table 1.4.2 Results and AnalysisPerformance of the BaselineLet?s start by presenting the performance of abaseline method as follows.
The baseline onlyemploys the internal translation similarity forparallel web pages mining.
Algorithm 3 is alsoused to get the page pairs in baseline system.Here, the input    (   )  is replaced by(   ) .
The parameter   in Equation 2 is adiscount factor.
For different   values, the per-formance of baseline system on six websites isshown in Figure 2.
In the Figure 2, it shows thatwhen   is set to 0.6, the baseline system achievesthe best performance.
The precision, recall andF-score are 85.84%, 87.55% and 86.69% respec-tively.
So in the following experiments, we al-ways set ?
to 0.6.Figure 2 Performances of baseline system with differ-ent   valuePerformance of Our MethodAs described in Section 3, our method com-bines the internal with external translation simi-larity in estimating the final translation similarity(i.e., ETS) of two pages.
So, the discount factorin Equation (1) is important in our method.Besides, as shown in Algorithm 2, the iterativealgorithm is used to calculate the similarity.
Then,one question is that how many iterations are re-quired in our algorithm.
Figure 3 shows the per-formance of our method on each website.
Its hor-izontal axis represents the number of iterationsand the vertical axis represents the F-score.
Andfor each website, the F-scores with different(range from 0.2 to 0.8) are also reported in thisfigure.
From Figure 3, it is very easy to find thatthe best iteration number is 3.
For almost all thewebsites, the performance of our methodachieves the maximal values and converges afterthe third iteration.
In addition, Figure 3 also indi-cates that our method is robust for different web-sites.
In the following experiments, the iterationnumber is set to 3.Next, let?s turn to the discount factor  .
Figure4 reports the experimental results on the wholedataset.
Here, the horizontal axis represents thediscount factor   and the vertical axis representsthe F-score.
means that only the internalsimilarity is used in the algorithm, so the F-scoreequals to that in Figure 2 when      .
On thecontrary,     means that only the externalsimilarity is used in the method, and the F-scoreis 80.20%.
The performance is lower than thebaseline system when only the external link in-formation is used, but it is much better than theperformance of the content-based method andstructure-based method whose F-scores are 64.82%and 64.0% respectively.
Besides, it is shownfrom Figure 4, the performance is improved sig-nificantly when the internal and external similari-ty measures are combined together.
Furthermore,it is somewhat surprising that the discount factoris not important as we previously expected.
Infact, if we discard the cases that   equals to 0 or1, the difference between the maximum and min-imum F-score will be 0.76% which is very small.This finding indicates that the internal and exter-nal similarity can easily be combined and wedon?t need to make many efforts to tune this pa-rameter when our method is applied to otherwebsites.
The reason of this phenomenon is that,no matter how much weight (i.e., 1-  ) was as-signed  to the internal similarity, the internal sim-ilarity always provides a relatively good initial60657075808590950 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1Performance(%)?F-score Precision Recall1221Figure 3 Experiment results of our method on each websiteiterative direction.
In the following experiments,the parameter ?
is set to 0.6.Figure 4 The F-scores of our method with differentthe value of ?The weight of pagesThe weight of the neighbor pages should alsobe considered.
For example, in the most websites,it is very common that most of the web pagescontain a hyperlink which points to the homep-age of the website.
While in most of the Eng-lish/Chinese websites, almost every English pagewill link to the English homepage and each Chi-nese page will point to Chinese homepage.
TheEnglish and Chinese homepages are probablyparallel, but they will be helpless to find parallelweb pages, because they are neighbors of almostevery page in the site.
On the contrary, some-times the parallel homepages have negative ef-fects on finding parallel pages They will increasethe translation similarity of two pages which arenot indeed mutual translations.
So it is necessaryto amend the Algorithm 1.The weight of each page is calculated accord-ing to its popularity:( )( )(6)where ( ) indicates the weight of page  ,   isthe number of all pages,     ( ) is the numberof pages pointing to page   and   is a constantfor smoothing.In this paper, the weights of pages are used intwo ways:Weight 1: The 9th line of Algorithm 1 isamended by the page weight as follows:?
(   )  ( ( )   ( ))Weight 2: The pages with low weight are re-moved from the input of Algorithm 1.The experiment results are shown in Table 2.Table 2 The effect of page weightType No Weight Weight 1 Weight 2F-score (%) 92.91 92.78 92.75Surprisingly, no big differences are found afterthe introduction of the page weight.
The side ef-fect of popular pages is not so large in our meth-od.
In the neighbor pages of a certain page, thepopular pages are the minority.
Besides, the iter-ative process makes our method more stable androbust.The impact of the size of bilingual lexiconThe baseline system mainly combines the con-tent-based similarity with structure similarity.86.6992.1592.4292.6792.7892.8392.9192.8392.6192.4080.207981838587899193950 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1F-score(%)?1222And two kinds of similarity measures are alsoused in our method.
As Ma and Liberman (1999)pointed out, not all translators create translatedpages that look like the original page whichmeans that the structure similarity does not al-ways work well.
Compared to the structure simi-larity, the content-based is more reliable and haswider applicability.
Furthermore, the bilinguallexicon is the only information that relates to thelanguage pairs, and other features (such as struc-ture and link information) are all language inde-pendent.
So, it?s important to investigate the ef-fect of lexicon size in our method.
We test theperformance of our method with different size ofthe bilingual dictionary.
The experiment resultsare shown in Figure 5.
In this figure, the horizon-tal axis represents the bilingual lexicon size andthe vertical axis represents the F-score.
With thedecline of the lexicon size, the performances ofboth the baseline method and our method aredecreased.
However, we can find that the descentrate of our method is smaller than that of thebaseline.
It indicates that our method does notneed a big bilingual lexicon which is good newsfor the low-resource language pairs.Figure 5 The impact of the size of bilingual lexiconError analysisErrors occur when the two pages are similar interms of structure, content and their neighbors.For example, Figure 6 illustrates a typical webpage structure.
There are 5 parts in the web page:,  ,  ,   and  .
Part   always contains themain content of this page.
While part  ,  ,   andalways contain some hyperlinks such as ?home?in part   and ?About us?
in part  .
Links inand   sometimes relate to the content of the page.For such a kind of non-parallel page pairs, let?sassume that the two pages have the same struc-ture (as shown in Figure 6).
In addition, theircontent part   is very short and contains thesame or related topics.
As a result, the links inother 4 parts are likely to be similar.
In this case,our method is likely to regard the two pages asparallel.MUBL RFigure 6 A typical web page structureThere are about 920 errors when our systemobtains its best performance.
By carefully inves-tigating the error page pairs, we find that morethan 90% errors fall into the category discussedabove.
The websites used in our experimentsmainly come from Hong Kong government web-sites.
Some government departments regularlypublish quarterly or monthly work reports on oneissue through their websites.
These reports lookvery similar except the publish date and somedata in them.
The other 10% errors happen be-cause of the particularity of the web pages, e.g.very short pages, broken pages and so on.5 Conclusions and Future WorkParallel corpora are valuable resources for a lotof NLP research problems and applications, suchas MT and CLIR.
This paper introduces an effi-cient and effective solution to bilingual languageprocessing.
We first explore how to extract paral-lel page pairs in bilingual websites with link in-formation between web pages.
Firstly, we hy-pothesize that the translation similarity of pagesshould be based on both internal and externaltranslation similarity.
Secondly, a novel iterativemethod is proposed to verify parallel page pairs.Experimental results show that our method ismuch more effective than the baseline systemwith 6.2% improvement on F-Score.
Further-more, our method has some significant contribu-tions.
For example, compared to previous work,our method does not depend on bilingual lexi-cons, and the parameters in our method have lit-tle effect on the final performance.
These fea-tures improve the applicability of our method.In the future work, we will study some methodon extracting parallel resource from existing par-allel page pairs, which are challenging tasks dueto the diversity of page structures and styles.
Be-sides, we will evaluate the effectiveness of ourmined data on MT or other applications.78808284868890929464K 32K 16K 8K 4K 2K 1KF-score(%)Lexicon SizeBaseline Our Method1223AcknowledgmentsThis research work has been sponsored by Na-tional Natural Science Foundation of China(Grants No.61373097 and No.61272259), oneNational Natural Science Foundation of JiangsuProvince (Grants No.BK2011282), one MajorProject of College Natural Science Foundation ofJiangsu Province (Grants No.11KJA520003) andone National Science Foundation of Suzhou City(Grants No.SH201212).The corresponding author of this paper, ac-cording to the meaning given to this role bySchool of computer science and technology atSoochow University, is Yu HongReferenceChen, Jiang and Jianyun Nie.
2000.
Automatic con-struction of parallel English-Chinese corpus forcross-language information retrieval.
Proceedingsof the sixth conference on Applied Natural Lan-guage Processing, 21?28.Resnik, Philip and Noah A. Smith.
2003.
The Web asa Parallel Corpus.
Meeting of the Association forComputational Linguistics 29(3).
349?380.Kit, Chunyu and Jessica Yee Ha Ng.
2007.
An Intelli-gent Web Agent to Mine Bilingual Parallel Pagesvia Automatic Discovery of URL Pairing Patterns.Web Intelligence and Intelligent Agent TechnologyWorkshops, 526?529.Zhang, Ying, Ke Wu, Jianfeng Gao and Phil Vines.2006.
Automatic Acquisition of Chinese-EnglishParallel Corpus from the Web.
Joint Proceedings ofthe Association for Computational Linguistics andthe International Conference on ComputationalLinguistics, 420?431.Nie, Jianyun, Michel Simard, Pierre Isabelle andRichard Durand.
1999.
Cross-language informationretrieval based on parallel texts and automatic min-ing of parallel texts from the Web.
Proceedings ofthe 22nd annual international ACM SIGIR confer-ence on Research and development in informationretrieval, 74?81.Ma, Xiaoyi and Mark Y. Liberman.
1999.
BITS: AMethod for Bilingual Text Search over the Web.Machine Translation Summit VII.Chen, Jisong, Rowena Chau and Chung-Hsing Yeh.2004.
Discovering Parallel Text from the WorldWide Web.
The Australasian Workshop on DataMining and Web Intelligence, vol.
32, 157?161.Dunedin, New Zealand.Jiang, Long, Shiquan Yang, Ming Zhou, Xiaohua Liuand Qingsheng Zhu.
2009.
Mining Bilingual Datafrom the Web with Adaptively Learnt Patterns.Proceedings of the Joint Conference of the 47thAnnual Meeting of the ACL and the 4th Interna-tional Joint Conference on Natural Language Pro-cessing of the AFNLP, vol.
2, 870?878.Yanhui Feng, Yu Hong, Zhenxiang Yan, JianminYao and Qiaoming Zhu.
2010.
A novel method forbilingual web page acquisition from search engineweb records.
Proceedings of the 23rd InternationalConference on Computational Linguistics: Posters,294?302.Zhao, Bing and Stephan Vogel.
2002.
Adaptive Paral-lel Sentences Mining from Web Bilingual NewsCollection.
IEEE International Conference on DataMining, 745?748.Smith, Jason R., Chris Quirk and Kristina Toutanova.2010.
Extracting parallel sentences from compara-ble corpora using document level alignment.
Hu-man Language Technologies: The 2010 AnnualConference of the North American Chapter of theAssociation for Computational Linguistics, 403?411.Bharadwaj, Rohit G. and Vasudeva Varma.
2011.Language independent identification of parallelsentences using wikipedia.
Proceedings of the 20thInternational Conference Companion on WorldWide Web, 11?12.
Hyderabad, India.Gusfield, Dan.
1997.
Algorithms on Strings, Treesand Sequences: Computerss Science and Computa-tional Biology.
Cambridge University PressShi, Lei, Cheng Niu, Ming Zhou and Jianfeng Gao.2006.
A DOM Tree Alignment Model for MiningParallel Data from the Web.
Proceedings of the21st International Conference on ComputationalLinguistics and the 44th annual meeting of the As-sociation for Computational Linguistics, 489?496.1224
