Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 977?988,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsA temporal model of text periodicities using Gaussian ProcessesDaniel Preot?iuc-Pietro, Trevor CohnDepartment of Computer ScienceUniversity of SheffieldRegent Court, 211 Portobello StreetSheffield, S1 4DP, United Kingdom{daniel,t.cohn}@dcs.shef.ac.ukAbstractTemporal variations of text are usually ig-nored in NLP applications.
However, text usechanges with time, which can affect manyapplications.
In this paper we model peri-odic distributions of words over time.
Focus-ing on hashtag frequency in Twitter, we firstautomatically identify the periodic patterns.We use this for regression in order to fore-cast the volume of a hashtag based on pastdata.
We use Gaussian Processes, a state-of-the-art bayesian non-parametric model, witha novel periodic kernel.
We demonstrate thisin a text classification setting, assigning thetweet hashtag based on the rest of its text.
Thismethod shows significant improvements overcompetitive baselines.1 IntroductionTemporal changes in text corpora are central to ourunderstanding of many linguistic and social phe-nomena.
Social Media platforms and the digital-ization of libraries provides a vast body of times-tamped data.
This allows studying of the complextemporal patterns exhibited by text usage includ-ing highly non-stationary distributions and period-icities.
However, temporal effects have been mostlyignored by previous work on text analysis or at bestdealt with by making strong assumptions such assmoothly varying parameters with time (Yogatamaet al 2011) or modelled using a simple uni-modaldistri bution (Wang and McCallum, 2006).
This pa-per develops a temporal model for classifying mi-croblog posts which explicitly incorporates mul-timodal periodic behaviours using Gaussian Pro-cesses (GPs).We expect text usage to follow multiple period-icities at different scales.
For example, people onSocial Media might talk about different topics dur-ing and after work on weekdays, talk every Fridayabout the weekend ahead, or comment about theirfavorite weekly TV show during its air time.
Giventhis, text frequencies will display periodic patterns.This applies to other text related quantities like co-occurrence values or topic distributions over time,as well as applications outside NLP like user be-haviour (Preot?iuc-Pietro and Cohn, 2013).Modelling temporal patterns and periodicities canbe useful to tasks like text classification.
For exam-ple a tweet containing ?music?
is normally attributedto a general hashtag about music like #np (now play-ing).
However, knowing time, if it occurs during the(weekly periodic) air time of ?American Idol?
it ismore likely for it to belong to #americanidol or ifits mentioned in the days building up to the VideoMusic Awards to be assigned to #VMA.In NLP, temporal models have treated time inoverly simplistic ways and without regard to period-icities.
We propose a model that first broadly iden-tifies several types of temporal patterns: a) periodic,b) constant in time, c) falling out of use after enjoy-ing a brief spell of popularity (e.g.
internet memes,news).
This is performed automatically only usingtraining data and makes no assumptions on the exis-tence or the length of the periods we aim to model.We demonstrate the approach by modelling frequen-cies of hashtag occurrences in Twitter.
Hashtags areuser-generated labels included in tweets by their au-thors in order to assign them to a conversation andcan be considered as a proxy for topics.To this end, we make use of Gaussian Pro-cesses (GP) (Rasmussen and Williams, 2005), a977Bayesian non-parametric model for regression.
Us-ing the Bayesian evidence we automatically performmodel selection to classify temporal patterns.
Weaim to use the most suitable model for extrapolation,i.e.
predicting future values from past observations.The GP is fully defined by the covariance structureassumed between the observed points, and its hy-perparameters, which can be automatically learnedfrom data.
We also introduce a new kernel suitableto model the periodic behaviour we observe in text:periods of low frequency followed by bursts at reg-ular time intervals.
We demonstrate that the GP ap-proach is more general and gives better results thanfrequentist models (e.g.
autoregressive models) be-cause it incorporates uncertainty explicitly and ele-gantly, in addition to automatic model selection andparameter fitting.To demonstrate the practical importance of ourapproach, we use our GP prediction as a prior in aNa?
?ve Bayes model for text classification showingimprovements over baselines which do not accountfor temporal periodicities.
Our approach extends tomore general uses, e.g.
to discriminative text regres-sion and classification.
More broadly, we aim to es-tablish GPs as a state-of-the-art model for regressionand classification in NLP.
To our knowledge, this isthe first paper to use GP regression for forecastingand model selection within a NLP task.All the hashtag time series data and the imple-mentation of the PS kernel in the popular open-source Gaussian Processes packages GPML1 andGPy2 are available on the author?s website3.2 Related WorkTime varying text patterns have been of particularinterest in topic modelling.
Griffiths and Steyvers(2004) analyse evolution of topics over time, butwithout modelling time explicitly.
Extensions thatmodel time make different assumptions, usually re-garding smoothing proprieties in (Wang and McCal-lum, 2006; Blei and Lafferty, 2006; Wang et al2008; Hennig et al 2012).
Yogatama et al(2011)proposed a regulariser for generalised linear modelsthat encourages local temporal smoothness.1http://www.gaussianprocess.org/gpml/code2https://github.com/SheffieldML/GPy3http://www.preotiuc.roModelling periodicities is one of the standard ap-plications of Gaussian Processes (Rasmussen andWilliams, 2005).
Recent work by Wilson and Adams(2013) and Durrande et al(2013) show how differ-ent periods can be identified from data.
In general,methods that assume certain periodicities at daily orweekly levels were proposed e.g.
in (McInerney etal., 2013).
GPs were used with text by Polajnar etal.
(2011) and for Quality Estimation regression in(Cohn and Specia, 2013; Shah et al 2013).Temporal patterns for short, distinctive lexicalitems such as hashtags and memes were quanti-tatively studied (Leskovec et al 2009) and clus-tered (Yang and Leskovec, 2011) in Social Media.
(Yang et al 2012) studies the dual role of hashtags,of bookmarks of content and symbols of commu-nity membership, in the context of hashtag adoption.
(Romero et al 2011) analyses the patterns of tem-poral diffusion in Social Media finding that hashtagshave also a persistence factor.For predicting future popularity of hashtags, Tsurand Rappoport (2012) use linear regression with awide range of features.
(Ma et al 2012; Ma etal., 2013) frame the problem as classification intoa number of fixed intervals and applies all the stan-dard classifiers.
None of these studies model period-icities, although the former stresses their importancefor accurate predictions.
For predicting the hashtaggiven the tweet text, Mazzia and Juett (2011) usesthe Na?
?ve Bayes classifier with the uniform and em-pirical prior or TF-IDF weighting.3 Gaussian ProcessesIn this paper we consider Gaussian Process (GP)models of regression (Rasmussen and Williams,2005).
GP is a probabilistic machine learningframework incorporating kernels and Bayesian non-parametrics which is widely considered as state-of-the-art for regression.
The GP defines a prior overfunctions which applied at each input point gives aresponse value.
Given data, we can analytically inferthe posterior distribution of these functions assum-ing Gaussian noise.
The kernel of the GP defines thecovariance in response values as a function of its in-puts.We can identify two different set-ups for a regres-sion problem.
If the range of values to be predicted978lies within the bounds of the training set we call theprediction task as interpolation.
If the range of theprediction is outside the bounds, then our problemthat of extrapolation.
In this respect, extrapolation isconsidered a more difficult task and the covariancekernel which incorporates our prior knowledge playsa major role in the prediction.There is the case when multiple covariance ker-nels can describe our data.
For choosing the rightkernel and its hyperparameters only using the train-ing data we employ Bayesian model selection whichmakes a trade-off between the fit of the trainingdata and model complexity.
We now briefly give anoverview of GP regression, kernel choice and modelselection.
We refer the interested reader to (Ras-mussen and Williams, 2005) for a detailed introduc-tion to GPs.3.1 Gaussian Process RegressionConsider a time series regression task where we onlyhave one feature, the value xt at time t. Our trainingdata consists of n pairs D = {(t, xt)}.
The modelwill need to predict values xt for values of t greaterthan those in the dataset.GP regression assumes a latent function f thatis drawn from a GP prior f(t) ?
GP(m, k(t, t?
))where m is the mean and k a kernel.
The predic-tion value is obtained by the function evaluated atthe corresponding data point, xt = f(t) + , where ?
N (0, ?2) is white-noise.
The GP is defined bythe mean m, here 0, and the covariance kernel func-tion, k(t, t?
).The posterior at a test point t?
is given by:p(x?|t?,D) =?fp(x?|t?, f) ?
p(f |D) (1)where x?
and t?
are the test value and time.
The pos-terior p(f |D) shows our belief over possible func-tions after observing the training set D. The predic-tive posterior can be solved analytically with solu-tion:x?
?
N (kT?
(K + ?2nI)?1t,k(t?, t?)?
kT?
(K + ?2nI)?1k?
)(2)where k?
= [k(t?, t1)...k(t?, tn)]T are the kernelevaluations between the test point and all the train-ing points,K = {k(ti, tj)}i=1..nj=1..n is the Gram matrix3/1 4/1 5/1 6/1GoldSEPS(24)Figure 1: Interpolation for #goodmorning over 3 dayswith SE and PS(p=24,s=3) kernels.
Prediction varianceshown in grey for PS(24).
Crosses represent trainingpoints.over the training points and t is the vector of train-ing points.
The posterior of x?
includes the meanresponse as well as its variance, thus expressing theuncertainty of the prediction.
In this paper, we willconsider the forecast as the expected value.
Due tothe matrix inversion in 2, inference takesO(n3) timewhere n is the number of training points.3.2 KernelsThe covariance kernel together with its parametersfully define the GP (we assume 0 mean).
The kernelinduces similarities in the response between pairs ofdata points.
Intuitively, if we want a smooth func-tion, closer points should have high covariance com-pared to points that are further apart.
If we want aperiodic behaviour points at period length intervalsshould have the highest covariance.
Usually, this isdefined by an isotropic kernel, which means its in-variant to all rigid motions.For interpolation, a standard kernel (e.g.
squaredexponential) that encourages smooth functions isnormally used.
Figure 1 shows regression over 3days for #goodmorning when only a random thirdof the values of the function are observed.
We seethat both the SE kernel and a periodic kernel (PS,see below) give good results.However, for extrapolation, the choice of the ker-nel is paramount.
The kernel encodes our prior beliefabout the type of function wish to learn.
To illustratethis, in Figure 3, we show the time series for #good-morning over 2 weeks and plot the regression for the979future week learned by using different kernels.In this study we will use multiple kernels, eachmost suitable for a specific category of temporal pat-terns in our data.
This includes a new kernel inspiredby observed word occurrence patterns.
The kernelswe use are:Constant (C): The constant kernel is kC(t, t?)
=c.
Its mean prediction will always be the value c andits assumption is that the signal is modeled only byGaussian noise centred around this value.
This de-scribes the data best when we have a noisy signalaround a stationary mean value.Squared exponential (SE): The SE kernel or theRadial Basis Function (RBF) is the standard kernelused in most interpolation settings.kSE(t, t?)
= s2 ?
exp?(t?
t?
)22l2(3)This gives a smooth transition between neighbour-ing points and best describes time series with asmooth shape e.g.
a uni-modal burst with a steadydecrease.
However, its uncertainty grows with forpredictions well into the future.
Its two parameterss and l are the characteristic lengthscales along thetwo axes.
Intuitively, they control the distance of in-puts on a particular axis from which the functionvalues become uncorrelated.
Using the SE kernelcorresponds to Bayesian linear regression with aninfinite number of basis functions (Rasmussen andWilliams, 2005).Linear (Lin): The linear kernel describes a linearrelationship between outputs.kLin(t, t?)
= s2 + ?t ?
t??
(4)This can be obtained from linear regression by hav-ing N (0, 1) priors on the corresponding regressionweights and a prior of N (0, s2) on the bias.Periodic (PER): The periodic kernel represents aSE kernel in polar coordinates.kPER(t, t?)
= s2 ?
exp?2 ?(sin2(2pi(t?
t?
)2/p)l2)(5)It has a sinusoidal shape and is good at modellingperiodically patterns that oscillate between low andhigh frequency.
s and l are characteristic length-scales as in the SE kernel and p is the period.25 50 75 100 12500.20.40.60.81s=1s=5s=50Figure 2: Behaviour of the PS kernel (p=50) with varyings.
Values normalized in [0,1] interval.Periodic spikes (PS): For textual time series, likeword frequencies, we identify the following periodicbehaviour: abrupt rise in usage, usually with a peak,followed by periods of low occurrence, which canbe short (e.g.
during the night) or long lived (e.g.
theentire week except for a few hours).
For modellingwe introduce the following kernel:kPS(t, t?)
= cos(sin(2pi ?
(t?
t?)2p))?
exp(s cos(2pi ?
(t?
t?)2)p?
s)(6)The kernel is parameterised by its period p and ashape parameter s. The period indicates the time in-terval between the peaks of the function, while theshape parameter controls the width of the spike.
Thebehaviour of the kernel is illustrated in Figure 2.
Weconstrain s ?
1.In Figure 3 we see that the forecast is highly de-pendent on the kernel choice.
We expect that forperiodic data the PER and PS kernels will forecastbest, maybe with the PS kernel doing a better jobbecause it captures multiple modes of the daily in-crease in volume.
We use for both kernels a periodof 168 hours.
This is because although a daily pat-tern exists, the weekly is stronger, with the day ofthe week influencing the volume of the hashtag.
TheNRMSE (Normalized Root Mean Square Error) inTable 1 on the held out data confirms this finding,with PS showing the lowest error.98003/110/117/100.20.40.60.81#goodmorningGoldConstLinear SE Per(168)PS(168)Figure 3: Extrapolation for #goodmorning over 3 weeks with GPs using different kernels.Const Lin SE PER PSNLML -41 -34 -176 -180 -192NRMSE 0.213 0.214 0.262 0.119 0.107Table 1: Negative Log Marginal Likelihood (NLML)shows the best fitted model for the time series in Figure 3.NRMSE computed on the third unobserved week.
Lowervalues are better in both cases.3.3 Model selection and optimisationWe now briefly discuss the concepts of model se-lection in the GP framework, by which we refer tochoosing the model (kernel) from a set Hi and op-timising the model hyperparameters ?.
In our GPBayesian inference scheme, we can compute theprobability of the data given the model which in-volves the integral over the parameter space.
Thisis called the marginal likelihood or evidence and isuseful for model selection using only the trainingset:p(x|D, ?,Hi) =?fp(x|D, f,Hi)p(f |?,Hi) (7)Our first goal is to fit the kernel by minimizingthe negative log marginal likelihood (NLML) withrespect to the kernel parameters ?.
This approxima-tion is also known as type II maximum likelihood(ML-II).
Conditioned on kernel parameters, the evi-dence of a GP can be computed analytically.Our second goal is to use the evidence formodel selection because it balances the data fit andthe model complexity by automatically incorporat-ing Occam?s Razor (Rasmussen and Ghahramani,2000).
Because the evidence must normalise, com-plex models which can account for many datasetsachieve low evidence.
One can think of the evidenceas the probability that a random draw of the param-eter values from the model class would generate thedataset D. This way, complex models are penalisedbecause they can describe many datasets, while thesimple models can describe only a few datasets, thusthe chance of a good data fit being very low.
This isfor example the case of the periodic bursts in Fig-ure 3.
Although the periodic kernel can fit the data,it will incur a high model complexity penalty.
ThePS kernel in this respect is a simpler model and canfit the data and is thus chosen as the right model.When the dataset is observed, the evidence can se-lect between the models.
More generally, the modelchoice actually gives us an implicit classification ofthe temporal patterns into classes: a steady signalwith noise (C kernel), a signal with local temporalpatterns (SE kernel), an oscilating periodic pattern(PER kernel) or a pattern with abrupt periodic peaks(PS kernel).We use the NLML for optimising the hyperpa-rameters only using training data.
For optimising thehyperparameters of the kernel defined in Equation 6,it is important to first identify the right period.
Weconsider as possible periods all integer values lessthan half the size of the training set, and then tunethe shape parameter using gradient descent to min-imise NLML.
We then take the argmin value ofthose considered.
We show the NLML for a sampleregression in Figure 4.The likelihood shows that there are multiplecanyons in the likelihood, which can lead a convexoptimisation method to local optima.
These appearwhen p is equal or an integer multiple of the mainperiod of the data, in this case 24.
The lowest val-ues are obtained when p = 168, allowing the modelto accommodate the day of week effect.
Our proce-dure is not guaranteed to reach a global optima, but98140 80 120 160 2001255075100?1000?5000Period pShape sNLMLFigure 4: NLML for #goodmorning on the training set asa function of the 2 kernel parameters.is a relatively standard technique for fitting periodickernels (Duvenaud et al 2013).The flexibility of the GP framework allows us tocombine kernels (e.g.
SE ?PS or PS+Lin) in orderto identify a combination of trends (Duvenaud et al2013; Go?nen and Alpaydin, 2011).
Experiments on asubset of data showed no major benefits of combin-ing kernels, but the computational time and modelcomplexity increased drastically due to the extra hy-perparameters.
Because we will model a proportionof words within a limited time frame, there are fewlinear trends in the data.
It might seem limiting thatwe only learn a single period, although we couldcombine periodic kernels with different periods to-gether.
But, as we have seen in the #goodmorningexample (with overlapping weekly and daily pat-terns), if there is a combination of periods the modelwill select a single period which is the least commonmultiple.4 DataFor our experiments we used data collected fromTwitter using the public Gardenhose stream (10%representative sample of the entire Twitter stream).The data collection interval was 1 January ?
28February 2011.
For simplicity in the classificationtask, we filtered the stream to include only tweetsthat have exactly one hashtag.
These represent ap-proximately 7.8% of our stream.As text processing steps, we have tokenised all thetweets and filtered them to be written in English us-ing the Trendminer pipeline (Preot?iuc-Pietro et al2012).
We also remove duplicate tweets (retweetsand tweets that had the same first 6 content tokens)because they likely represent duplicate content, au-tomated messages or spam which would bias thedataset, as also stated by Tsur and Rappoport (2012).In our experiments we use the first month of dataas training and the second month as testing.
Notethe challenging nature of this testing configurationwhere predictions must be made for up to 28 daysinto the future.
We keep a total 1176 of hashtagswhich appear at least 500 times in both splits ofthe data.
The vocabulary consists of all the tokensthat occur more than 100 times in the dataset andstart with an alphabetic letter.
After processing, ourdataset consists of 6,416,591 tweets with each hav-ing on average 9.55 tokens.5 Forecasting hashtag frequencyWe treat our task of forecasting the volume of aTwitter hashtag as a regression problem.
Because thetotal number of tweets varies depending on the dayand hour of day, we chose to model the proportion oftweets with the given tag in that hour.
Given a timeseries of these values as the training set for a hash-tag, we aim to predict the values in the testing set,extrapolating to the subsequent month.Hashtags represent free-form text labels that au-thors add to a tweet in order to enable other users tosearch them to participate in a conversation.
Someusers use hashtags as regular words that are integralto the tweet text, some hashtags are general and re-fer to the same thing or emotion (#news, #usa, #fail),others are Twitter games or memes (#2010diss-apointments, #musicmonday).
Other hashtags re-fer to events which might be short lived (#world-cup2022), long lived (#25jan) or periodic (#raw,#americanidol).
We chose to model hashtags be-cause they group similar tweets (like topics), reflectreal world events (some of which are periodic) andpresent direct means of evaluation.
Note that thisapproach could be applied to many other temporalproblems in NLP or other domains.
We treat eachregression problem independently, learning for eachhashtag its specific model and set of parameters.5.1 MethodsWe choose multiple baselines for our prediction taskin order to compare the effectiveness of our ap-98203/110/117/124/131/107/214/221/228/200.51#fyiGoldPS Const#fyi03/110/117/124/131/107/214/221/228/200.51#confessionhourGoldPS SE#confessionhour03/110/117/124/131/107/214/221/228/200.51#failGoldPER Const#fail03/110/117/124/131/107/214/221/228/200.51#breakfastGoldPS Const#breakfast03/110/117/124/131/107/214/221/228/200.51#rawGoldPS Const#rawFigure 5: Sample regressions and their fit using different methods.proach.
These are:Mean value (M): We use as prediction the meanof the values in the training set.
Note that this is thesame as using a GP model with a constant kernel (+noise) with a mean equal to the training set mean.Lag model with GP determined period (Lag+):The prediction is the mean value in the training set ofthe values at lag ?
where ?
is the period rounded tothe closest integer as determined by our GP model.This is somewhat similar to an autoregressive (AR)model with all the coefficients except ?
set to 0.We highlight that given the period ?
this is a verystrong model as it gives a mean estimate at eachpoint.
Comparing to this model we can see if the GPmodel can recover the underlying function that de-scribed the periodic variation and filter out the noisein the observations.
Correctly identifying the periodis very challenging as we discuss below.GP regression: Gaussian Process regression us-ing only the SE kernel (GP-SE), the periodic ker-nel (GP-PER), the PS kernel (GP-PS).
The methodthat chooses between kernels using model selectionas described in Section 3.3 is denoted as GP+.
Wewill also compare to GP regression the linear kernel(GP-Lin), but we will not use this as a candidate formodel selection due the poor results shown below.983HashtagLag(p) Const SE PER PSNRMSE NLML NRMSE NLML NRMSE NLML NRMSE NLML NRMSE#fyi 0.1578 -322 0.1404 -320 0.1898 -321 0.1405 -293 0.1456#confessionhour 0.0404 -85 0.0107 -186 0.0012 -90 0.0327 -88 0.0440#fail 0.1431 -376 0.1473 -395 0.4695 -444 0.1387 -424 0.1390#breakfast 0.1363 -293 0.1508 -333 0.1773 -293 0.1514 -367 0.1276#raw 0.0464 -1208 0.0863 -1208 0.0863 -1323 0.0668 -1412 0.0454Table 2: NRMSE shows the best performance for forecasting and NLML shows the best model for all the regressionsin Figure 5.
Lower is better.5.2 ResultsWe start by qualitatively analysing a few sample re-gressions that are representative of each category oftime series under study.
These are shown in Figure 5.For clarity, we only plotted a few kernels on each fig-ure.
The full evaluation statistics in NRMSE and theBayesian evidence are show in Table 2.For the hashtag #fyi there is no clear pattern.
Forthis reason the model that uses the constant kernelperforms best, being the simplest one that can de-scribe the data, although the others give similar re-sults in terms of NRMSE on the held-out testingset.
While functions learned using this kernel neverclearly outperform others on NRMSE on held-outdata, this is very useful for interpretation of the timeseries, separating noisy time series from those thathave an underlying periodic behaviour.The #confessionhour example illustrates a be-haviour best suited for modelling using the SE ker-nel.
We notice a sudden burst in volume whichdecays over the next 2 days.
This is actuallythe behaviour typical of ?internet memes?
(thishashtag tags tweets of people posting things theywould never tell anyone) as presented in Yang andLeskovec (2011).
These cannot be modelled with aconstant kernel or a periodic one as shown by the re-sults on held-out data and the time series plot.
Theperiodic kernels will fail in trying to match the largeburst with others in the training data and will at-tribute to noise the lack of a similar peak, thus dis-covering wrong periods and making bad predictions.In this example, forecasts will be very close to 0 un-der the SE kernel, which is what we would desirefrom the model.The periodic kernel best models hashtags that ex-hibit an oscillating pattern.
For example, this bestfits words that are used frequently during the dayand less so during the night, like #fail.
Here, the pe-riod is chosen to be one week (168) rather than oneday (24) because of the weekly effect superimposedon the daily one.
Our model recovers that there isa daily pattern with people tweeting about their orothers?
failures during the day.
On weekends how-ever, and especially on Friday evenings, people havebetter things to do.The PS kernel introduced in this paper modelsbest hashtags that have a large and short lived burstin usage.
We show this by two examples.
First, wechoose #breakfast which has a daily and weekly pat-tern.
As we would expect, a big rise in usage oc-curs during the early hours of the day, with veryfew occurrences at other times.
Our model discov-ers a weekly pattern as well.
This is used mainlyfor modelling the difference between weekends andweekdays.
On weekends, the breakfast tag is moreevenly spread during the hours of the morning, be-cause people do not have to wake up for work andcan have breakfast at a more flexible time than dur-ing the week.
In the second example, we present ahashtag that is associated to a weekly event: #rawis used to discuss a wrestling show that airs ev-ery week for 2 hours on Monday evenings in theU.S.. With the exception of these 2 hours and thehour building up to it, the hashtag is rarely used.This behaviour is modelled very well using our ker-nel, with a very high value for the shape parame-ter (s = 200) compared to the previous example(s = 11) which captures the abrupt trend in usage.
Inall cases, our GP model chosen by the evidence per-forms better than the Lag+ model, which is a verystrong method if presented with the correct period.This further demonstrates the power of the GaussianProcess framework to deal with noise in the trainingdata and to find the underlying function of the timevariation of words.In Table 3 we present sample tags identified as984Const SE PER PS#funny #2011 #brb #ff#lego #backintheday #coffee #followfriday#likeaboss #confessionhour #facebook #goodnight#money #februarywish #facepalm #jobs#nbd #haiti #funny #news#nf #makeachange #love #nowplaying#notetoself #questionsidontlike #rock #tgif#priorities #savelibraries #running #twitterafterdark#social #snow #xbox #twitteroff#true #snowday #youtube #ww49 268 493 366Table 3: Sample hashtags for each category.
The last lineshows the total number of hashtags of each type.Lag+ GP-Lin GP-SE GP-PER GP-PS GP+7.29% -3.99% -34.5% 0.22% 7.37% 9.22%Table 4: Average relative gain over mean (M) predictionfor forecasting on the entire month using the differentmodelsbeing part of the 4 hashtag categories, and the totalnumber of hashtags in each.As a means of quantitative evaluation we com-pute the relative NRMSE compared to the Mean (M)method for forecasting.
We choose this, because weconsider that NRMSE is not comparable between re-gression tasks due to the presence of large peaks inmany time series, which distort the NRMSE values.The results are presented in Table 4 and show thatour Gaussian Process model using model selectionis best.
Remarkably, it consistently outperforms theLag+ model, which shows the effectiveness of theGP models to incorporate uncertainty.
The GP-PSmodel does very well on its own.
Although chosen inthe model selection phase in only a third of the tasks,it performs consistently well across tasks because ofits ability to model well all the periodic hashtags,be they smooth or abrupt.
The GP-Lin model doesworse than the average, mostly due to uni-modaltime series which don?t have high occurrences in thetesting part of the data.5.3 DiscussionLet us now turn to why the GP model is betterfor discovering periodicities than classic time seriesmodelling methods.
Measuring autocorrelation be-tween points in the time series is used to discoverthe hidden periodicities in the data and in buildingAR models.
However, the downsides of this methodare: a) the incapacity of accurately finding the cor-rect periods, because all integer multiples of the cor-0 100 200 300?0.200.20.40.60.8LagSampleAutocorrelationSample Autocorrelation FunctionFigure 6: Sample autocorrelation for #confessionhour0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1?70?60?50?40?30?20?10Normalized Frequency  (?pi rad/sample)Power/frequency (dB/rad/sample)Periodogram Power Spectral Density EstimateFigure 7: Power spectral density for #rawrect period will be feasible candidates and b) it leadsto incorrect conclusions when there is autocorre-lated noise.
The second case is illustrated in Fig-ure 6 where #confessionhour shows autocorrelationbut, as seen in Figure 5, lacks a periodic component.Another approach to discovering periods in datais by computing the power spectral density.
Thishas been used in the GP framework by Wilson andAdams (2013).
For some time series, this gives agood indication of the period, as represented by apeak in the periodogram at that value.
This fails todiscover the correct period when dealing with largebursts like those exhibited by the #raw time seriesas shown in Figure 7.
The lowest frequency spikecorresponds to the correct period of 168, but alsoother candidate periods are shown as possible.
Thereason for this is its reliance on the Fourier Trans-form which decomposes the time series into a sumof oscillating patterns.
These cannot model step-functions and other non-smoothly varying signals.A further discussion falls out of the scope and spaceconstraints of this paper.985Tweet Time Prior Rank PredictionBruins Goal!!!
Patrice Bergeron makes it 3-1 Boston 2-3am, 2 Feb 2011E: 0.00017 7 #fbP: 0.00086 1 #bruinsi need some of Malik people 3-4am, 2 Feb 2011E: 0.00021 7 #ffP: 0.00420 1 #thegameAlfie u doughnut!
U didn?t confront Kay?
SMH 7-8pm, 3 Feb 2011E: 0.00027 8 #nowplayingP: 0.00360 1 #eastendersTable 5: Example of tweet classification using the Na?
?ve Bayes model with the two different priors (E - empirical, P -GP forecast).
Rank shows the rank in probability of the correct class (hashtag) under the model.
Time is G.M.T.6 Text based predictionIn this section we demonstrate the usefulness ofour method of modelling in an NLP task: predict-ing the hashtag of a tweet based on its text.
In con-trast to this classification approach for suggesting atweet?s hashtag, information retrieval methods basedon computing similarities between tweets are veryhard to scale to large data (Zangerle et al 2011).We choose a simple model for prediction, theNa?
?ve Bayes Classifier.
This method provides uswith a straightforward way to incorporate our priorknowledge of how frequent a hashtag is in a certaintime frame.
This Na?
?ve Bayes model (NB-P) usesthe forecasted values for the respective hour as theprior on the hashtags.For comparison we use the Most Frequent (MF)baseline and the Na?
?ve Bayes with empirical prior(NB-E) which doesn?t use any temporal forecastinginformation.
Because there are more than 1000 pos-sible classes we show the accuracy of the correcthashtag being amongst the top 1,5 or 50 hashtagsas well as the Mean Reciprocal Rank (MRR).
Theresults are shown in Table 6.The results show that incorporating the forecastedvalues as a more informative prior for classificationwe obtain better predictions.
The improvements areconsistent in all the Match values.
Also, we high-light that a 9% improvement in the forecasting taskcarries over to about a 2% improvement in classifi-cation.
We show a few examples in which the GPlearned prior makes a difference in classification inTable 5 together with the values for both priors.With these experiments, we highlighted that thereare performance gains even with only adding a moreinformative prior that uses periodicity information.This motivates future work to add this informationto discriminative classifiers thus avoiding the needMF NB-E NB-PMatch@1 7.28% 16.04% 17.39%Match@5 19.90% 29.51% 31.91%Match@50 44.92% 59.17% 60.85%MRR 0.144 0.237 0.252Table 6: Results for hashtag classification.for the Na?
?ve Bayes decomposition.
The modellingframework offered by the GPs can accommodateclassification, although scaling issues arise when us-ing a large number of features or output classes.
Ef-forts to scale GPs to a large number of variablesare well understood (Candela and Rasmussen, 2005)and we will try to incorporate this in future work.7 ConclusionPeriodicities play an important role when analysingthe temporal dimension of text.
We have presenteda framework based on Gaussian Process regressionfor identifying periodic patterns and their parame-ters using only training data.
We divided the periodicpatterns into 2 categories: oscillating and periodicbursts by performing model selection using bayesianevidence.
The periodicities we have discovered haveproven useful in an NLP classification task.In future work, we aim to model time continu-ously and to perform discriminative clustering in or-der to make better use of the learned periodicites.We will consider incorporating periodicities in otherapplications, such as topic models.AcknowledgementsThis research was funded by the Trendminerproject, EU FP7-ICT Programme, grant agreementno.287863.
The authors would like to thank JamesHensman, Nicolas Durrande and Neil Lawrence foradvice on Gaussian Processes, Chris Dyer and NoahSmith for discussions about periodicities in NLP.986ReferencesDavid Blei and John Lafferty.
2006.
Dynamic topicmodels.
In Proceedings of the 23rd International con-ference on Machine learning, ICML ?06.Joaquin Quin?onero Candela and Carl Edward Ras-mussen.
2005.
A Unifying View of Sparse Approx-imate Gaussian Process Regression.
Journal of Ma-chine Learning Research (JMLR), 6:1939?1959, De-cember.Trevor Cohn and Lucia Specia.
2013.
Modelling An-notator Bias with Multi-task Gaussian Processes: AnApplication to Machine Translation Quality Estima-tion.
In Proceedings of the Association of Computa-tional Linguistics, ACL ?13.Nicolas Durrande, James Hensman, Magnus Rattray, andNeil Lawrence.
2013.
Gaussian Process modelsfor periodicity detection.
In Submitted to JRSSb,http://arxiv.org/abs/1303.7090.David Duvenaud, James Robert Lloyd, Roger Grosse,Joshua B. Tenenbaum, and Zoubin Ghahramani.2013.
Structure discovery in nonparametric regressionthrough compositional kernel search.
In Proceedingsof the International Conference on Machine Learning,ICML ?13.Mehmet Go?nen and Ethem Alpaydin.
2011.
Multi-ple Kernel Learning Algorithms.
Journal of MachineLearning Research (JMLR), 12:2211?2268, July.Thomas L. Griffiths and Mark Steyvers.
2004.
Find-ing scientific topics.
Proceedings of the NationalAcademy of Sciences of the United States of America,(Suppl 1):5228?5235, April.Philipp Hennig, David H. Stern, Ralf Herbrich, and ThoreGraepel.
2012.
Kernel topic models.
Journal of Ma-chine Learning Research (JMLR) - Proceedings Track,22:511?519.Jure Leskovec, Lars Backstrom, and Jon Kleinberg.2009.
Meme-tracking and the dynamics of the newscycle.
In Proceedings of the 15th ACM SIGKDD Inter-national conference on Knowledge discovery and datamining, KDD ?09.Zongyang Ma, Aixin Sun, and Gao Cong.
2012.
Willthis #hashtag be popular tomorrow?
In Proceedings ofthe 35th International ACM SIGIR conference on Re-search and development in information retrieval, SI-GIR ?12.Zongyang Ma, Aixin Sun, and Gao Cong.
2013.
On pre-dicting the popularity of newly emerging hashtags inTwitter.
Journal of the American Society for Informa-tion Science and Technology, 64(7):1399?1410.Allie Mazzia and James Juett.
2011.
Sug-gesting hashtags on Twitter.
In http://www-personal.umich.edu/ amazzia/pubs/545-final.pdf.James McInerney, Alex Rogers, and Nicholas R Jennings.2013.
Learning periodic human behaviour modelsfrom sparse data for crowdsourcing aid delivery indeveloping countries.
In Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelli-gence, UAI ?13.Tamara Polajnar, Simon Rogers, and Mark Girolami.2011.
Protein interaction detection in sentences viaGaussian Processes: a preliminary evaluation.
In-ternational Journal Data Mining and Bioinformatics,5(1):52?72, February.Daniel Preot?iuc-Pietro and Trevor Cohn.
2013.
MiningUser Behaviours: A Study of Check-in Patterns in Lo-cation Based Social Networks.
In Proceedings of theACM Web Science Conference, Web Science ?13.Daniel Preot?iuc-Pietro, Sina Samangooei, Trevor Cohn,Nicholas Gibbins, and Mahesan Niranjan.
2012.Trendminer: An architecture for real time analysis ofsocial media text.
Proceedings of the Sixth Interna-tional AAAI Conference on Weblogs and Social Media,Workshop on Real-Time Analysis and Mining of SocialStreams.Carl Edward Rasmussen and Zoubin Ghahramani.
2000.Occam?s razor.
In Advances in Neural InformationProcessing Systems, NIPS 13.Carl Edward Rasmussen and Christopher K. I. Williams.2005.
Gaussian Processes for Machine Learning.MIT Press.Daniel M. Romero, Brendan Meeder, and Jon Klein-berg.
2011.
Differences in the mechanics of informa-tion diffusion across topics: idioms, political hashtags,and complex contagion on Twitter.
In Proceedings ofthe 20th International conference on World wide web,WWW ?11.Kashif Shah, Trevor Cohn, and Lucia Specia.
2013.An Investigation on the Effectiveness of Features forTranslation Quality Estimation.
In MT Summit ?13.Oren Tsur and Ari Rappoport.
2012.
What?s in a hash-tag?
Content based prediction of the spread of ideasin microblogging communities.
In Proceedings of thefifth ACM International conference on Web search anddata mining, WSDM ?12.Xuerui Wang and Andrew McCallum.
2006.
Topics overtime: a non-Markov continuous-time model of topi-cal trends.
In Proceedings of the 12th ACM SIGKDDInternational conference on Knowledge discovery anddata mining, KDD ?06.Chong Wang, David M. Blei, and David Heckerman.2008.
Continuous time Dynamic topic models.
InProceedings of the Twenty-Fourth Conference on Un-certainty in Artificial Intelligence, UAI ?08.Andrew Gordon Wilson and Ryan Prescott Adams.
2013.Gaussian Process covariance kernels for pattern dis-987covery and extrapolation.
In Proceedings of the Inter-national Conference on Machine Learning, ICML ?13.Jaewon Yang and Jure Leskovec.
2011.
Patterns of tem-poral variation in online media.
In Proceedings of thefourth ACM International conference on Web searchand data mining, WSDM ?11.Lei Yang, Tao Sun, Ming Zhang, and Qiaozhu Mei.
2012.We know what @you #tag: does the dual role affecthashtag adoption?
In Proceedings of the 21st Interna-tional conference on World Wide Web, WWW ?12.Dani Yogatama, Michael Heilman, Brendan O?Connor,Chris Dyer, Bryan R. Routledge, and Noah A. Smith.2011.
Predicting a scientific community?s responseto an article.
In Proceedings of the Conference onEmpirical Methods in Natural Language Processing,EMNLP ?11.Eva Zangerle, Wolfgang Gassler, and Gunther Specht.2011.
Recommending #-tags in twitter.
In Proceed-ings of the Workshop on Semantic Adaptive SocialWeb, UMAP ?11.988
