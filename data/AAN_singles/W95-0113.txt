Development of a Partially Bracketed Corpus withPart-of-Speech Information OnlyHsin-Hsi Chen and Yue-Shi LeeDepartment ofComputer Science and Information EngineeringNational Taiwan UniversityTaipei, Taiwan, R.O.C.E-mail: hh_chen@csie.ntu.edu.twAbstractResea/ch based on a treebank is active for many natural language applications.
However, the work tobuild a large scale treebank is laborious and tedious.
This paper proposes a probabilistic hunker to helpthe development of a partially bracketed corpus.
The chunker partitions the part-of-speech sequence intosegments called chunks.
Rather than using a treebank as our training corpus, a corpus which is taggedwith part-of-speech information only is used.
The experimental results show the probabilistic hunker hasmore than 92% correct rate in outside test.
The well-formed partially bracketed corpus is a milestone in thedevelopment of a treebank.
Besides, the simple but effective chunker can also be applied to many naturallanguage applications.1.
IntroductionResearch based on a treebank, i.e., a corpus annotated with syntactic structures, is active for many naturallanguage applications \[1-5\].
Framis \[1\] proposes a methodology to extract selectional restrictions at avariable level of abstraction from the Penn Treebank.
Chen and Chen \[2\] propose a probabilistic hunkerto decide the implicit boundaries of constituents and utilize the linguistic knowledge to extract he nounphrases by a finite state mechanism.
In their study, Susanne Corpus is used as a trainmg corpus for theirchunker.
Pocock and Atwell \[3\] investigate statistical grammars extracted from Spoken English Corpus(SEC), and apply these grammars to find the grammatically optimal path through a word lattice.
Thestochastic parsers are also developed in \[4,5\].
All these applications employ the syntactic informationextracted from different treebanks and show the satisfactory results.However, the work to build a large scale treebank is laborious and tedious.
Very few large-scaletreebanks are currently available specially for languages other than English.
In this paper, we propose aprobabilistic hunker to help the development of a partially bracketed corpus, i.e., a simpler version of atreebank.
The chunker partitions the part-of-speech sequence into segments called chunks.
Rather thanusing a treebank as our training corpus, a corpus which is tagged with part-of-speech information only isused.
In the following sections we first introduce the experimental framework of our model.
Lancaster-Oslo/Bergen (LOB) Corpus and Susanne Corpus are adopted.
Then a tag mapper and a probabilisticchunker are described.
Before concluding the experimental results are demonstrated.2.
Experimental FrameworkBecause the probabilistic hunker proposed in this paper is based on syntactic tags (parts of speech), apart-of-speech tagger is needed.
A word sequence W is input to the part-of-speech tagger and a part-of-162speech sequence P is generated.
The output of the tagger is the input of the chunker.
The probabilisticchunker partitions P into C, i.e., a sequence of chunks.
Each chunk contains one or more parts of speech.Consider the example "Attorneys for the mayor said that an amicable property settlement has beenagreed upon .".
This 15-word sentence is input to the part-of-speech tagger and a part-of-speech sequence"NNS IN ATI NPT VBD CS AT JJ NN NN HVZ BEN VBN IN ."
is generated.
The probabilisticchunker then partitions this sequence into several chunks.
The chunked result is shown as follows.\[NNS\] \[INATINPT \] \[VBD\] \ [CS\]  \ [AT\]  \[ J JNNNN \] \[ HVZ BEN \] \[VBN\] \ [ IN \ ] \ [ .
\]However, the pei-formance evaluation of the chunker is a sticky work.
To evaluate the performance of thechunker, Susanne Corpus, which is a modified and condensed version of Brown Corpus, is adopted.
But,the tagging sets \[6,7\] of LOB Corpus and Susanne Corpus are different.
The latter has finer tags than theformer.
Thus, a tag mapper is introduced inthe experimental framework shown as Figure 1.~!.
:: .
r .~ : .
.~ .
.
:~  :~.j - ':~'~-~  "~-:' :"~ i  i" : : : ' : : : :~:'~:' :~:i ' : : : :  - " .
: i' ::'~': ..... ' ' :: ::::: '::::: ::: : ..... ..........::: : ::"~!~:!
:'~:" '| a ~.
~ .
:.i~ li ~.~.ii::.
:i ~ ':: '  ' :'~ ~ .~ " ":' "~ :':':':':':':':':":""" " ':":' ' ':':':'~ ~i~il"::............. : ::  ' '  :~' " ...: .~ |CFigure 1.
Experimental FrameworkIn our experiments, he test sentence Ps comes from Susanne Corpus.
It is a part-of-speech sequence.The corresponding syntactic structure T is regarded as an evaluation criterion for the probabilistic chunker.It is sent to the performance evaluation model.
The tag mapper in this figure is used to transform theSusanne part-of-speech into LOB part-of-speech.
Through the tag mapper, Ps is converted into PI.
Then,PI is input to the probabilistic hunker and a chunk sequence C is produced.
Finally, the performanceevaluation model reports the evaluation results according to C and T.3.
A Tag MapperThe tagging set of Susanne Corpus is extended and modified from LOB Corpus.
They have 424 and 153tags, respectively.
To map a Susanne tag into a LOB tag manually is a tedious work.
Thus, an automatictag mapping algorithm is provided.
By our investigation, we found that words are good clues to relatethese two tagging sets.
Therefore, the first step in automatic tag mapping is to collect words from SusanneCorpus for each Susanne tag.
Table 1 lists some examples.Table 1.
Words Extracted from Susanne Corpus for Some Susanne TagsSusannelTags Words LOB TagsCC and plus & And ond CCIW with WITHOUT without WITH With INNNluxNN 2WMphysics math politics mathematics Athleticsassociates<apos>m am ai<bbold> <bital> r rLNNNNSBEM<No Match>163Column three in Table 1 denotes the correct mapping to LOB tags.
The second step is to find thecorresponding LOB tags from LOB Corpus for each word collected at the first step.
Table 2 shows thesample results.Table 2.
LOB Tags Extracted from LOB Corpus for Each Word in Table 1Susanne TagsCCIWNNluxNNJ2VBMYTLWords (LOB Tags)and ( CC RB" RB NC ) plus ( IN JJ NN &FW ) & ( CC )with ( IN IN" RI NC ) without ( IN RI )physics ( NN ) politics ( NN NNS ) mathematics ( NN )associates ( NNS VBZ )am ( BEM &FW ) ai ( HVZ BEZ BER )Those words which cannot be found in LOB Corpus are removed.
Symbol * denotes that all thewords cannot be found in LOB Corpus.
The third step is to find the corresponding LOB tag for eachSusanne tag.
For each Susanne tag, the frequency of LOB tags is calculated and the most frequent LOBtag is regarded as the result.
For example, LOB tags NN and NNS in row three of Table 2 appear threeand one times, respectively.
Thus, Susanne tag NNlux is mapped to LOB tag NN.
After examining all theSusanne tags by these three steps, three cases have to be considered:(1) Unique Tag.
Only one LOB tag remains.
(2) Multiple Tags.
More than one LOB tags remain.
(3) No Match.When all the words extracted from Susanne Corpus for a Susanne tag cannot be found in LOBCorpus, the Susanne tag is mapped to "No Match".
Some of these words are characteristicwords such as YTL 1.The experimental results are shown in Table 3.Table 3.
Experimental Results for Ta:Mapping Types SubtypesUnique Tag CorrectWrongMultiple Tags IncludeExcludeNo Match CorrectWrongMappingNumber of Mapping151711331026In Table 3, "Include" denotes that the correct ag belongs to the remaining multiple tags and "Exclude" denotes that the correct ag is not mcluded in the remaining tags.
Note that the ditto tags are notconsidered in this experiment.
This is because the mapping for ditto tags can be obtained by human easily.Therefore, only 310 Susanne tags are resolved in this experiment.
The experimental results how that thenumber of multiple tags is large.
Thus, two heuristic rules are introduced to reduce the number of multipletags.1Tag YTL means "begin italics/boldface".164First, those LOB tags which are similar to Susanne tag are selected.
For example, Susanne tag NNJ2can be mapped tO LOB tags NNS or VBZ in the above experiment.
NNS has two common characters withNNJ2, so that Susanne tag NNJ2 is mapped to LOB tag NNS.
Under this heuristic rule, the experimentalresults are showia m Table 4.Table 4.
Experimental Results After Applying the First Heuristic RuleMapping TypesUnique TagMUltiple TagsNo MatchSubtypesCorrectWrongIncludeExcludeCorrectWrongNumber of Mappin 822222281026Next, let us consider an example.
Susanne tag IW can be mapped to LOB tags IN or RI in the aboveexperiment.
Thus, the first heuristic rule has no effects.
We examine the tag mapping for the precedingand subsequent three tags of 1W.
They are listed as follows.
(-1) Susanne Tag lit is mapped to(-2) Susanne Tag IIx is mapped to(-3) Susanne Tag IO is mapped to(**) Susanne Tag IW is mapped to(+2) Susanne Tag JB is mapped to(+3) Susanne Tag JBo is mapped toLOB Tag IN.LOB Tag IN.LOB Tag IN.LOB Tag IN RI.LOB Tag JJ.LOB Tag AP.Note that only tags which have the same first character as IW are considered, that is,.
only (-I), (-2) and (-3)are considered.
In these three mappings, LOB tag IN is the most frequent and the only one mapping, andIN is a candidate for IW.
Thus, Susanne tag IW is mapped to LOB tag IN.
The above procedure formsthe second heuristic rule.
The experimental results after applying two heuristic rules are shown as follows.Table 5.
Experimental Results After Applying Two HeuristicMapping TypesUnique TagMultiple TagsNo MatchSubtypes Numbe rCorrectWrongIncludeExcludeCorrectWrongRulesof Mapping23222181026Three tags - say, FA, FB and GG, must be treated in particular.
For example, Susanne Corpus tagsgenitive case noun as \[John NP 's_GG\], but LOB Corpus tags it as \[John's_PN$\].
Two Susanne tags maybe mapped into One LOB tag.
Ignoring these three special tags, only nineteen Susanne tags have wrongmapping in Uniq0e-Tag case.4.
A Probabilistic ChunkerGale and Church, \[8\] propose d~ 2, a X2-1ike statistic, to measure the association between two words.
Table6 illustrates a twr-by-two contingency table for words w I and w 2.165Table 6.
A Contingency TableWord w 1Word w 2 a bc dCell a counts the number of sentences that contain both w I and w 2.
Cell b (c) counts the number ofsentences that contain w 2 (Wl) but not w I (w2).
Cell d counts the number of sentences that does notcontain both w 1 and w 2.
That is, if N is the total number of sentences, d=N-a-b-c. Based on thiscontingency table, (~2 is defined as follows:(a*d +b 'c )  242 = (a+ b)* (a+c)* (b  +d)* (c+d)(I) 2 is bounded between 0 and 1.
For different applications, there are different definitions for thecontingency table.
Instead of using the above definition, a modified version is shown as follows.Definition 1: (For Two Parts of Speech)a=F(Pl,P2)b=F(P2)-F(P l,p 2 )c=F(P 1)-F(p l,P2)d=N-a-b-cwhere Pi denotes part-of-speech i,F(p 1,P2) is the frequency of which P2 follows p 1,F(Pl) and F(P2) are the frequencies of Pl and P2, andN is the corpus size in terms of the number of words in training corpus.Based on this definition and ~2 measure, consider the sentence "The Fulton County Grand Jury said Fridayan investigation ...", which has tag sequence "ATI NP NPL JJ NN VBD NR AT NN ...".
Its syntacticstructure for the first seven words is shown in Figure 2.ATI NPI IThe FultonFigure 2.NPL JJ NN VND NRI 1 1 1 ICountry Grand Jury said FridaymumThe Syntactic Structure for the First Seven Words166The 4 2 distribution for these parts of speech is shown in Figure 3.
Position i (x axis) is the locationbetween parts of speech Pi and Pi+ 1'"1000000100001oo1 tiont 2 3 4 5 6 7ATI NP NPL JJ NN VND NRFigure 3.
The ~2 Distribution for the First Seven WordsFigure 3 shows that there are four local minimal positions, i.e., positions 1, 3, 5 and 6.
They can beregarded as the boundaries of chunks.
That is, ATI and NP belong to different chunks.
Similarly, (NPLand JJ), (NN and VND) and (VND and NR) have the same situation.
Let us discuss these conceptsformally.
For a!probabilistic chunker, the generalized contingency table is defined as follows.Definition 2: (For Two Chunks)a=F(cl,c 2)b=F(c2)-F(cl,c 2)c=F(Cl)-F(cl,c 2)d=N-a-b-cwhere c i denotes chunk i,.F(cl,c2) is the frequency of which c 2 follows el,F(cl) and F(c2) are the frequencies ofc 1 and c2, andN is the corpus size m terms of the number of words in training corpus.Let the tag sequence P be P l, P2, .-., Pn.
Assume there are two possible chunked results.
The first iscomposed oftw0 chunks, i.e., \[Pl, P2 ..... Pi\] and \[Pi+l, Pi+2, --., Pn\], and is regarded as a correct result.The second is also composed of two chunks, i.e., \[Pl, P2, -.., Pi-l\] and \[Pi, Pi+l, -.., Pn\], but is regarded asa wrong result, iSince \[Pl, P2, ..., Pi\] is a chunk, \[Pl, P2 ..... Pi-1\] is very likely to be followed by Pi.
Inother words,F(\[Pl, P2, ..-, Pi-1\]) ~ F(\[Pl, P2 .... , Pi\]) ........................................................ (1)Similarly,F(\[Pi+I, Pi+2, --', Pn\]) '~' F(\[Pi+2, Pi+3, ---, Pn\])Because Pi and Pi+l are in two different chunks,F(\[Pi, Pi+l,.--., Pn\]) << F(\[Pi+I, Pi+2, .-., Pn\]) ................................................ (2)Similarly,F(\[Pl, P2, ---, Pi+l\]) << F(\[Pl, P2, ..-, Pi\])167For the first chunked result, we can obtain the following contingency table:a# = F(\[Pl, P2, -.., Pi\],\[Pi+l, Pi+2, ..-, Pn\])b# = F(\[pl, P2, ---, Pi\]) - F(\[Pl, P2, .-., Pi\],\[Pi+l, Pi+2, ..., Pn\])c# = F(\[Pi+I, Pi+2, .-., Pn\]) - F(\[Pl, P2 ..... Pi\],\[Pi+l, Pi+2, .-., Pn\])d # = N - a # - b # - c #Similarly, the following contingency table is obtained for the second chunked result:a& = F(\[pl, P2 ....  , Pi-l\],\[Pi, Pi+l, ..., Pn\])b& = F(\[Pl, P2, ..., Pi-l\]) - F(\[Pl, P2, ..., P i-l\],\[Pi, Pi+2, ..., Pn\])c& = F(\[Pi, Pi+l, --., Pn\]) "F(\[Pl ,  P2 .... , P i-l\],\[Pi, Pi+2, ..., Pn\])d & = N -a & - b & - c &It is obvious that a # = a &.
By formula (1), we know that b # ~b &.
By formula (2), we can derive c # >>c &.
Since N >> a, b and c, d # ,~, d &.
Therefore,(a #* d #_b  #* c #) << (a &*  d &_b  &*  c &)(a # + b #) ~ (a & + b &)(a # + c #) >> (a & + c &)(b # + d # ) ,~, (b & + d &)(c # + d #) ~ (c & + d &)andd(\[P, ,  P2, ..., P,\],\[P,+., P,+2, .--, P.\])(a ' *  d" - b"* c") 2(a" + b')* (a" + c")* (b" + d')* (c" + d")<< (a ~ * d ~ _ b ~* c~) 2(a & + b ~) * (a ~ + c ~) * (b ~ + d ~) * (c ~ + d ~)= ~2(\[pl, P2,---, Pi-l\],\[Pi, PJ+i, ..., P,\])The above derivation tells us: the local minimums of the ~b 2 distribution denote plausible boundaries of  twochunks.
To simplify Definition 2, Definitions 3 and 4 are formulated.Def in i t ion 3: (For Two Parts of Speech)a = F(\[Pi\],\[Pi+l\])b = F(\[Pi\]) - F(\[Pi\],\[Pi+l\])e = F(\[Pi+l\]) - F(\[Pi\],\[Pi+l\])d=N-a -b  -cwhere Pi denotes part-of-speech i,F(\[Pi\],\[Pi+l\] ) is the frequency of which Pi+l follows Pi,F(\[Pi\] ) and F(\[Pi+l\]) are the frequencies of Pi and Pi+l, andN is the corpus size in terms of the number of words in training corpus.168It is clear that Definition 3 is the same as Definition 1.
Based on Definitions 3, the probabilistic hunker ispresented as follows.
Note that N is the length of the tag sequence and the last chunk is always a one-tagchunk (punctuation).Probabilistic Chunker(A_Sequence Of Tags)BeginOutput("\[");Position=l;Calculate ~2 a for Current Position By Definition 3;Position=Position+ 1;While(Position<N)BeginCalculate ,l,2b for Current Position By Definition 3;Output(A_Sequence Of Tags\[Position-l\]);If (,l,2a < ,I,2b) Then Output("\]\[");~2a=(I)2b;Position=Position+ l;EndEndOutput(A_Sequence Of Tags\[N-l\]);Output("\]\[");Output(A_Sequence Of Tags\[N\]);Output("\]");Definition 4: (For Three Parts of Speech)Left Chunka = F(\[pi, Pi+l\],\[Pi+2\])b = F(\[Pi+2\]) - F(\[pi, Pi+l\],\[Pi+2\])c = F(\[Pi, Pi+l\]) "F(\[Pi, Pi+l\],\[Pi+2\])d=N-a-b  -cwhere Pi denotes part-of-speech i,F(\[Pi, Pi+l\],\[Pi+2\]) is the frequency of which Pi+l,Pi+2 follows Pi,F(\[pi, Pi+l\]) and F(\[Pi+2\]) are the frequencies of (pi, Pi+l) and Pi+2, andN is the corpus size m terms of the number of words in training corpus.Right Chunka = F(\[Pi\],\[pi+ 1, Pi+2\])b = F(\[Pi+l , Pi+2\]) - F(\[Pi\],\[Pi+I, Pi+2\])c = F(\[Pi\]) - F(\[Pi\],\[Pi+l, Pi+2\])d=N-a-b  -cwhere Pi denotes part-of-speech i,F(\[Pi\],\[Pi+I, Pi+2\]) is the frequency of which Pi+l,Pi+2 follows Pi,F(\[pi\]) and F(\[Pi+l, Pi+2\]) are the frequencies of Pi and (Pi+l, Pi+2), andN is the corpus size in terms of the number of words m training corpus.169Based on Definitions 4, the probabilistic chunker is presented as follows.Probabilistic_Chunker(A_Sequence Of Tags)BeginOutput("\[");Position= 1;While(Position<(N- 1))BeginCalculate qb2a for Current Position By Left Chunk of Definition 4;Calculate dp2b for Current Position By Right Chunk of Definition 4;Output(A_Sequence Of Tags\[Position-l\]);If (dp2 a < dp2b) Then Output("\]\[");Position=Position+ 1;EndOutput(A_Sequence Of Tags\[N-l\]);Output("\]\[");Output(A_Sequence Of Tags\[N\]);Output("\]");EndProbabilistic hunker based on Definition 3 concerns the dp 2 distribution between two parts of speech.
Foreach while loop, probabilistic chunker based on Definition 4 processes three parts of speech and concernsthe dp 2 distribution between them.5.
Experimental ResultsLOB Corpus, which is a million-word collection of present-day British English texts, is adopted as thesource of training data.
Susanne Corpus is adopted as the source of testing data for evaluating theperformance of our probabilistic chunker.
This corpus contains one tenth of Brown Corpus, but involvesmore syntactic and semantic information than Brown Corpus.For evaluating the performance, a criterion \[2\], i.e., the content of each chunk should be dominated byone non-terminal node in Susanne parse field, is adopted.
The performance evaluation model compares thechunked result C with the corresponding syntactic structure T. Accordmg to this criterion, theexperimental results for Definitions 3 and 4 are shown in Table 7 as follows.FileTable 7.
Experimental Results for Definition 3 and 4Correct Rate for Definition 3 II Correct Rate for Definition 4A0I 80.31% 79.71%G0I 79.28% 79.72%J01 76.42% !
77.17%N01 87.82% 90.10%Average 81.13% 81.91%170The experimental results demonstrate hat Definition 4 (three parts of speech) is more powerful thanDefinition 3 (two parts of speech).
Assume the chunk length is the number of tags in a chunk.
Thedistribution of Chunk length is listed in Tables 8 and 9.Table 8.
The Distribution of Chunk Length for Definition 31 I 2 3 1 4 1 5  6 I 7 81  9A01 i 654 392 180 38 10 0 1 0 0G01 715 431 167 37 09 1 I 0 0J01 645 392 162 57 13 2 1 0 0 iN01 777 418 172 55 05 1 1 0 0Table1 IA01 543G01 652J01 573N01 6859.
'\]373395336386The Distribution of Chunk Length for Definition 4I 314  5 1 6 1 7  8171 56 23 05 1 0163 64 13 04 0 1190 51 21 10 5 1197 49 21 04 2 0One-tag chunks cover about 50%.
We further analyze what grammatical components constitute the one-tag chunks and find that most of the one-tag chunks contam punctuation marks, nouns and verbs.
This isbecause proper name forms the bare subject or object.
Verb is presented in the form of third person andsingular, past tense, or base form.
These three cases form about 62% of one-tag chunks.By analyzing the error chunked results, we find that many errors result from conjunctions.
Besides,some tags cannot be located at the end of the chunks.
Therefore, the heuristic rule is applied to improve theperformance.
The tags that cannot be located at the end of chunks are listed as follows:(01) AT (Singular Article)(03) BED (were)(05) BEG (being)(07) BER (are, 're)(09) CC (Coordinating Conjunction)(11) IN (Preposition)(13) WDTR (WH-Determiner)(02) ATI (Singular or Plural Article)(04) BEDZ (was)(06) BEM (am, 'm)(08) BEZ (is, 's)(10) CS (Subordinating Conjunction)(12) PP$ (Possessive Determiner)Applying this heuristic rule, the experimental results are listed in Table 10.
It shows the usefulness ofthe heuristic rulel The performance increases about 10%.Table 10.
ExFilei A01G01J01N01Averagemrimental Results after Applyin\[ Correct Rate for Definition 392.39%the Heuristic RuleCorrect Rate for Definition 489.19%93.15% 90.92%91.30% 89.89%94.86%92.95%94.69%91.23%1716.
Concluding RemarksTo process real text is indispensable for a practical natural language system.
Probabilistic method providesa robust way to tackle with the unrestricted text.
This paper proposes a probabilistic hunker to help thedevelopment of a partially bracketed corpus.
Rather than using a treebank as our training corpus, LOBCorpus which is tagged with part-of-speech information only is used.
The experimental results show theprobabilistic chunker has more than 92% correct rate in outside test.
The well-formed partially bracketedcorpus is a milestone in the development of a treebank.
In addition, the simple but effective chunker canalso be applied to many natural language applications such as extracting the predicate-argument structures\[9,10\], grouping words \[11\] and gathering collocation \[12\].The evaluation criterion adopted in this paper is not very strict.
Under a strict criterion, the methodproposed in this paper may not be suitable for short-fat trees.
That is, it is suitable for tall-thin trees.
Tosolve this problem, a more general definition which considers more parts of speech in contingency table isneeded.
However, that introduces another problem: the more the general definitions we use, the larger thetagged corpus we need.
This paper also presents a tag mapper.
It sets up the mapping between differenttagging sets.
Such an algorithm facilitates the development of a large-scale tagged corpus from differentsources.
By the way, much more reliable statistic information can be trained from the large-scale taggedcorpus, so that the feasibility of the chunker is assured.
Besides the above problem, the critical points forlocal minimum are not obvious in some cases.
Thus their determination is also demanded inthe future.References\[1\] Framis, F.R.
(1994) "An Experiment on Learning Appropriate Selectional Restrictions from a ParsedCorpus," Proceedings ofCOLING, pp.
769-774, 1994.\[2\] Chen, KH.
and Chen, H.H.
(1994) "Extracting Noun Phrases from Large-Scale Texts: A HybridApproach and its Automatic Evaluation," Proceedings ofACL, pp.
234-241, 1994.\[3\] Pocock, R.J. and Atwell, E.S.
(1993) "Treebank-Tramed Probabilistic Parsmg of Lattices,"Technical Report 93.
30, School of Computer Studies, Leeds University, 1993.\[4\] Pereira, F. and Schabes, Y.
(1992) "Inside-Outside Reestimation from Partially Bracketed Corpora,"Proceedings of ACL, pp.
128-135, 1992.\[5\] Weischedel, R., et al (1991) "Partial Parsing: A Report of Work in Progress," Proceedings ofDARPA Speech and Natural Language Workshop, p. 204-209, 1991.\[6\] Sampson, G. (1993) "The Susanne Corpus," 1CAMEdournal, 17, 125-127, 1993.\[7\] Johansson, S. (1986) The Tagged LOB Corpus: Users' Manual, Bergen: Norwegian ComputingCenter for Humanities, 1986.\[8\] Gale, W.A.
and Church, K.W.
(1991) "Identifying Word Correspondences in Parallel Texts,"Proceedings of DARPA Speech and Natural Language Workshop, p. 152-157, 1991.\[9\] Church, K.W.
(1988) "A Stochastic Parts Program and Noun Phrase Parser for Unrestricted Text,"Proceedings of Applied Natural Language Processing, pp.
136-143, 1988.\[10\] Church, K.W., et al (1989) "Parsing, Word Association and Typical Predicate-ArgumentRelations," Proceedings of Parsing Technologies Workshop, p. 389-398, 1989.\[11\] Hindle, D. (1990) "Noun Classification from Predicate-Argument Structures," Proceedings of ACL,pp.
268-275, 1990.\[12\] Smadja, F. (1993) "Retrieving Collocations from Text: Xtract," Computational Linguistics, 19(1),pp.
143-178, 1993.172
