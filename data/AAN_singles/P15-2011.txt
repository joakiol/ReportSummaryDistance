Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 63?68,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsSimplifying Lexical Simplification:Do We Need Simplified Corpora?Goran Glava?sUniversity of ZagrebFaculty of Electrical Engineeringand Computinggoran.glavas@fer.hrSanja?StajnerUniversity of WolverhamptonResearch Group inComputational LinguisticsSanjaStajner@wlv.ac.ukAbstractSimplification of lexically complex texts,by replacing complex words with theirsimpler synonyms, helps non-nativespeakers, children, and language-impairedpeople understand text better.
Recentlexical simplification methods rely onmanually simplified corpora, which areexpensive and time-consuming to build.We present an unsupervised approach tolexical simplification that makes use of themost recent word vector representationsand requires only regular corpora.
Resultsof both automated and human evaluationshow that our simple method is as ef-fective as systems that rely on simplifiedcorpora.1 IntroductionLexical complexity makes text difficult to under-stand for various groups of people: non-nativespeakers (Petersen and Ostendorf, 2007), chil-dren (De Belder and Moens, 2010), people withintellectual disabilities (Feng, 2009; Saggion etal., 2015), and language-impaired people suchas autistic (Martos et al, 2012), aphasic (Car-roll et al, 1998), and dyslexic (Rello, 2012) peo-ple.
Automatic simplification that replaces com-plex words with their simpler synonyms is thusneeded to make texts more understandable for ev-eryone.Lexical simplification systems still predomi-nantly use a set of rules for substituting long andinfrequent words with their shorter and more fre-quent synonyms (Devlin and Tait, 1998; De Belderand Moens, 2010).
In generating the substitutionrules (i.e., finding simple synonyms of a complexword), most systems refer to lexico-semantic re-sources like WordNet (Fellbaum, 1998).
The non-existence of lexicons like WordNet for a vast num-ber of languages diminishes the impact of thesesimplification methods.The emergence of the Simple Wikipedia1shifted the focus towards the data-driven ap-proaches to lexical simplification, ranging fromunsupervised methods leveraging either the meta-data (Yatskar et al, 2010) or co-occurrence statis-tics of the simplified corpora (Biran et al, 2011)to supervised methods learning substitutions fromthe sentence-aligned corpora (Horn et al, 2014).Using simplified corpora improves the simplifica-tion performance, but reduces method applicabil-ity to the few languages for which such corporaexist.The research question motivating this work re-lates to achieving comparable simplification per-formance without resorting to simplified corporaor lexicons like WordNet.
Observing that ?sim-ple?
words appear in regular (i.e., ?complex?, notsimplified) text as well, we exploit recent ad-vances in word vector representations (Penning-ton et al, 2014) to find suitable simplifications forcomplex words.
We evaluate the performance ofour resource-light approach (1) automatically, ontwo existing lexical simplification datasets and (2)manually, via human judgements of grammatical-ity, simplicity, and meaning preservation.
The ob-tained results support the claim that effective lex-ical simplification can be achieved without usingsimplified corpora.2 Related WorkSystems for lexical simplification are still domi-nantly rule-based, i.e., they rely on a set of sub-stitutions, each consisting of a complex word andits simpler synonym, which are in most cases ap-plied regardless of the context in which the com-plex word appears.
Constructing substitution rulesinvolves identifying synonyms, usually in Word-1https://simple.wikipedia.org63Net, for a predefined set of complex words (Car-roll et al, 1998; Bautista et al, 2009), and thenchoosing the ?simplest?
of these synonyms, typ-ically using some frequency-based (Devlin andTait, 1998; De Belder and Moens, 2010) or length-based heuristics (Bautista et al, 2009).
The mainshortcomings of the rule-based systems includelow recall (De Belder and Moens, 2010) and mis-classification of simple words as complex (andvice versa) (Shardlow, 2014).The paradigm shift from knowledge-based todata-driven simplification came with the creationof Simple Wikipedia, which, aligned with the?original?
Wikipedia, constitutes a large compara-ble corpus to learn from.
Yatskar et al (2010) usedthe edit history of Simple Wikipedia to recognizelexical simplifications.
They employed a proba-bilistic model to discern simplification edits fromother types of content changes.
Biran et al (2011)presented an unsupervised method for learningsubstitution pairs from a corpus of comparabletexts from Wikipedia and Simple Wikipedia, al-though they exploited the (co-)occurrence statis-tics of the simplified corpora rather than its meta-data.
Horn et al (2014) proposed a supervisedframework for learning simplification rules.
Usinga sentence-aligned simplified corpus, they gener-ated the candidate rules for lexical simplification.A context-aware binary classifier, trained and eval-uated on 500 Wikipedia sentences (annotated viacrowdsourcing), then decides whether a candidaterule should be applied or not in a certain context.The main limitation of the aforementionedmethods is the dependence on simplified corporaand WordNet.
In contrast, we propose a resource-light approach to lexical simplification that re-quires only a sufficiently large corpus of regulartext, making it applicable to the many languageslacking these resources.3 Resource-Light Lexical SimplificationAt the core of our lexical simplification method,which we name LIGHT-LS, is the observation that?simple?
words, besides being frequent in simpli-fied text, are also present in abundance in regu-lar text.
This would mean that we can find sim-pler synonyms of complex words in regular cor-pora, provided that reliable methods for measuring(1) the ?complexity?
of the word and (2) semanticsimilarity of words are available.
LIGHT-LS sim-plifies only single words, but we fully account forthis in the evaluation, i.e., LIGHT-LS is penalisedfor not simplifying multi-word expressions.
In thiswork, we associate word complexity with the com-monness of the word in the corpus, and not withthe length of the word.3.1 Simplification Candidate SelectionWe employ GloVe (Pennington et al, 2014), astate-of-the-art model of distributional lexical se-mantics to obtain vector representations for allcorpus words.
The semantic similarity of twowords is computed as the cosine of the angle be-tween their corresponding GloVe vectors.
Foreach content word (noun, verb, adjective, or ad-verb) w, we select as simplification candidates thetop n words whose GloVe vectors are most sim-ilar to that of word w. In all experiments, weused 200-dimensional GloVe vectors pretrained onthe merge of the English Wikipedia and Gigaword5 corpus.2For each content word w, we selectn = 10 most similar candidate words, excludingthe morphological derivations of w.3.2 Goodness-of-Simplification FeaturesWe rank the simplification candidates according toseveral features.
Each of the features captures oneaspect of the suitability of the candidate word toreplace the original word.
The following are thedescriptions for each of the features.Semantic similarity.
This feature is computed asthe cosine of the angle between the GloVe vectorof the original word and the GloVe vector of thesimplification candidate.Context similarity.
Since type-based distri-butional lexico-semantic models do not discernsenses of polysemous words, considering only se-mantic similarity between the original and can-didate word may lead to choosing a synonym ofthe wrong sense as simplification of the complexword.
The simplification candidates that are syn-onyms of the correct sense of the original wordshould be more semantically similar to the contextof the original word.
Therefore, we compute thisfeature by averaging the semantic similarities ofthe simplification candidate and each content wordfrom the context of the original word:csim(w, c) =1|C(w)|?w??C(w)cos(vw,vw?
)2http://www-nlp.stanford.edu/data/glove.6B.200d.txt.gz64where C(w) is the set of context words of the orig-inal word w and vwis the GloVe vector of theword w. We use as context a symmetric windowof size three around the content word.Difference of information contents.
The primarypurpose of this feature is to determine whether thesimplification candidate is more informative thanthe original word.
Under the hypothesis that theword?s informativeness correlates with its com-plexity (Devlin and Unthank, 2006), we choosethe candidate which is less informative than theoriginal word.
The complexity of the word is es-timated by its information content (ic), computedas follows:ic(w) = ?
logfreq(w) + 1?w??Cfreq(w?)
+ 1where freq(w) is the frequency of the word w in alarge corpus C, which, in our case, was the GoogleBook Ngrams corpus (Michel et al, 2011).
Thefinal feature value is the difference between theinformation contents of the original word and thesimplification candidate, approximating the com-plexity reduction (or gain) that would be intro-duced should the simplification candidate replacethe original word.Language model features.
The rationale for hav-ing language model features is obvious ?
a sim-plification candidate is more likely to be a com-patible substitute if it fits into the sequence ofwords preceding and following the original word.Let w?2w?1ww1w2be the context of the originalword w. We consider a simplification candidatec to be a good substitute for w if w?2w?1cw1w2is a likely sequence according to the languagemodel.
We employed the Berkeley languagemodel (Pauls and Klein, 2011) to compute thelikelihoods.
Since Berkeley LM contains only bi-grams and trigrams, we retrieve the likelihoodsfor ngrams w?1c, cw1, w?2w?1c, cw1w2, andw?1cw1, for each simplification candidate c.3.3 Simplification AlgorithmThe overall simplification algorithm is given in Al-gorithm 1.
Upon retrieving the simplification can-didates for each content word (line 4), we computeeach of the features for each of the simplificationcandidates (lines 5?8) and rank the candidates ac-cording to feature scores (line 9).
We choose asthe best candidate the one with the highest aver-age rank over all features (line 12).
One impor-tant thing to notice is, that even though LIGHT-LSAlgorithm 1: Simplify(tt)1: subst ?
?2: for each content token t ?
tt do3: all ranks ?
?4: scs ?
most similar(t)5: for each feature f do6: scores ?
?7: for each sc ?
scs do8: scores ?
scores ?
f(sc)9: rank ?
rank numbers(scores)10: all ranks ?
all ranks ?
rank11: avg rank ?
average(all ranks)12: best ?
argmaxsc(avg rank)13: if ic(best) < ic(tt) do14: bpos ?
in pos(best , pos(tt))15: subst ?
subst ?
(tt , bpos)16: return substhas no dedicated component for deciding whethersimplifying a word is necessary, it accounts forthis implicitly by performing the simplificationonly if the best candidate has lower informationcontent than the original word (lines 13?15).
Sincesimplification candidates need not have the samePOS tag as the original word, to preserve gram-maticality, we transform the chosen candidate intothe morphological form that matches the POS-tagof the original word (line 14) using the NodeBoxLinguistics tool.34 EvaluationWe evaluate the effectiveness of LIGHT-LS auto-matically on two different datasets but we also lethumans judge the quality of LIGHT-LS?s simplifi-cations.4.1 Replacement TaskWe first evaluated LIGHT-LS on the datasetcrowdsourced by Horn et al (2014) where manualsimplifications for each target word were collectedfrom 50 people.
We used the same three evalua-tion metrics as Horn et al (2014): (1) precision isthe percentage of correct simplifications (i.e., thesystem simplification was found in the list of man-ual simplifications) out of all the simplificationsmade by the system; (2) changed is the percentageof target words changed by the system; and (3) ac-curacy is the percentage of correct simplificationsout of all words that should have been simplified.3https://www.nodebox.net65Table 1: Performance on the replacement taskModel Precision Accuracy ChangedBiran et al (2011) 71.4 3.4 5.2Horn et al (2014) 76.1 66.3 86.3LIGHT-LS 71.0 68.2 96.0LIGHT-LS?s performance on this dataset isshown in Table 1 along with the performance ofthe supervised system by Horn et al (2014) andthe unsupervised system by Biran et al (2011),which both used simplified corpora.
The resultsshow that LIGHT-LS significantly outperforms theunsupervised system of Biran et al (2011) andperforms comparably to the supervised systemof Horn et al (2014), which requires sentence-aligned simplified corpora.
The unsupervised sys-tem of Biran et al (2011) achieves precision sim-ilar to that of LIGHT-LS but at the cost of chang-ing only about 5% of complex words, which re-sults in very low accuracy.
Our method numeri-cally outperforms the supervised method of Hornet al (2014), but the difference is not statisticallysignificant.4.2 Ranking TaskWe next evaluated LIGHT-LS on the SemEval-2012 lexical simplification task for English (Spe-cia et al, 2012), which focused on ranking a targetword (in a context) and three candidate replace-ments, from the simplest to the most complex.
Toaccount for the peculiarity of the task where thetarget word is also one of the simplification can-didates, we modified the features as follows (oth-erwise, an unfair advantage would be given to thetarget word): (1) we excluded the semantic sim-ilarity feature, and (2) we used the informationcontent of the candidate instead of the differenceof information contents.We used the official SemEval task evaluationscript to compute the Cohen?s kappa index for theagreement on the ordering for each pair of can-didates.
The performance of LIGHT-LS togetherwith results of the best-performing system (Jauharand Specia, 2012) from the SemEval-2012 taskand two baselines (random and frequency-based)is given in Table 2.
LIGHT-LS significantly out-performs the supervised model by Jauhar and Spe-cia (2012) with p < 0.05, according to the non-parametric stratified shuffling test (Yeh, 2000).An interesting observation is that the competitivefrequency-based baseline highly correlates withTable 2: SemEval-2012 Task 1 performanceModel ?baseline-random 0.013baseline-frequency 0.471Jauhar and Specia (2012) 0.496LIGHT-LS 0.540our information content-based feature (the higherthe frequency, the lower the information content).4.3 Human EvaluationAlthough automated task-specific evaluations pro-vide useful indications of a method?s performance,they are not as reliable as human assessment ofsimplification quality.
In line with previous work(Woodsend and Lapata, 2011; Wubben et al,2012), we let human evaluators judge the gram-maticality, simplicity, and meaning preservation ofthe simplified text.
We compiled a dataset of 80sentence-aligned pairs from Wikipedia and SimpleWikipedia and simplified the original sentenceswith LIGHT-LS and the publicly available systemof Biran et al (2011).
We then let two annota-tors (with prior experience in simplification an-notations) grade grammaticality and simplicity forthe manual simplification from Simple Wikipediaand simplifications produced by each of the twosystems (total of 320 annotations per annotator).We also paired the original sentence with eachof the three simplifications (manual and two sys-tems?)
and let annotators grade how well the sim-plification preserves the meaning of the originalsentence (total of 240 annotations per annotator).We averaged the grades of the two annotators forthe final evaluation.
All grades were assigned on aLikert (1?5) scale, with 5 being the highest grade,i.e., all fives indicate a very simple and completelygrammatical sentence which fully preserves themeaning of the original text.
The inter-annotatoragreement, measured by Pearson correlation coef-ficient, was the highest for grammaticality (0.71),followed by meaning preservation (0.62) and sim-plicity (0.57), which we consider to be a fair agree-ment, especially for inherently subjective notionsof simplicity and meaning preservation.The results of human evaluation are shown inTable 3.
In addition to grammaticality (Gr), sim-plicity (Smp), and meaning preservation (MP), wemeasured the percentage of sentences with at leastone change made by the system (Ch).
The re-sults imply that the sentences produced by LIGHT-66Table 4: Example simplificationsSource SentenceOriginal sentence The contrast between a high level of education and a low level of political rights wasparticularly great in Aarau, and the city refused to send troops to defend the Berneseborder.Biran et al (2011) simpl.
The separate between a high level of education and a low level of political rights wasparticularly great in Aarau , and the city refused to send troops to defend the Berneseborder.LIGHT-LS simpl.
The contrast between a high level of education and a low level of political rights wasespecially great in Aarau, and the city asked to send troops to protect the Berneseborder.Table 3: Human evaluation resultsSource Gr Smp MP ChOriginal sentence 4.90 3.36 ?
?Manual simplification 4.83 3.95 4.71 76.3%Biran et al (2011) 4.63 3.24 4.65 17.5%LIGHT-LS 4.60 3.76 4.13 68.6%Biran et al (2011) Ch.
3.97 2.86 3.57 ?LIGHT-LS Ch.
4.57 3.55 3.75 ?LS are significantly simpler (p < 0.01; pairedStudent?s t-test) than both the original sentencesand sentences produced by the system of Biranet al (2011).
The system of Biran et al (2011)produces sentences which preserve meaning bet-ter than the sentences produced by LIGHT-LS, butthis is merely because their system performs nosimplifications in over 80% of sentences, whichis something that we have already observed on thereplacement task evaluation.
Furthermore, annota-tors found the sentences produced by this systemto be more complex than the original sentences.On the contrary, LIGHT-LS simplifies almost 70%of sentences, producing significantly simpler textwhile preserving grammaticality and, to a large ex-tent, the original meaning.In order to allow for a more revealing com-parison of the two systems, we additionally eval-uated each of the systems only on sentences onwhich they proposed at least one simplification(in 70% of sentences for LIGHT-LS and in only17.5% of sentences for the system of Biran et al(2011)).
These results, shown in the last two rowsof Table 3, demonstrate that, besides simplicityand grammaticality, LIGHT-LS also performs bet-ter in terms of meaning preservation.
In Table 4 weshow the output of both systems for one of the fewexample sentences in which both systems made atleast one change.Since LIGHT-LS obtained the lowest averagegrade for meaning preservation, we looked deeperinto the causes of changes in meaning introducedby LIGHT-LS.
Most changes in meaning stemfrom the inability to discern synonymy from relat-edness (or even antonymy) using GloVe vectors.For example, the word ?cool?
was the best simpli-fication candidate found by LIGHT-LS for the tar-get word ?warm?
in the sentence ?Water temper-atures remained warm enough for development?.5 ConclusionWe presented LIGHT-LS, a novel unsupervisedapproach to lexical simplification that, unlike ex-isting methods, does not rely on Simple Wikipediaand lexicons like WordNet, which makes it ap-plicable in settings where such resources are notavailable.
With the state-of-the-art word vec-tor representations at its core, LIGHT-LS requiresnothing but a large regular corpus to perform lexi-cal simplifications.Three different evaluation settings have shownthat LIGHT-LS?s simplifications based on multiplefeatures (e.g., information content reduction, con-textual similarity) computed on regular corporalead to performance comparable to that of systemsusing lexicons and simplified corpora.At the moment, LIGHT-LS supports onlysingle-word simplifications but we plan to extendit to support multi-word expressions.
Other linesof future research will focus on binding LIGHT-LSwith methods for syntax-based (Zhu et al, 2010)and content-based (Glava?s and?Stajner, 2013) textsimplification.AcknowledgementsThis work has been partially supported by theMinistry of Science, Education and Sports, Re-public of Croatia under the Grant 036-1300646-1986.
We thank the anonymous reviewers for theiruseful comments.67ReferencesSusana Bautista, Pablo Gerv?as, and R. Ignacio Madrid.2009.
Feasibility analysis for semi-automatic con-version of text to improve readability.
In Proceed-ings of the Second International Conference on In-formation and Communication Technology and Ac-cessibility (ICTA), pages 33?40.Or Biran, Samuel Brody, and No?emie Elhadad.
2011.Putting it simply: A context-aware approach to lex-ical simplification.
In Proceedings of the ACL-HLT2011, pages 496?501.
ACL.John Carroll, Guido Minnen, Yvonne Canning, Siob-han Devlin, and John Tait.
1998.
Practical sim-plification of english newspaper text to assist apha-sic readers.
In Proceedings of AAAI-98 Workshopon Integrating Artificial Intelligence and AssistiveTechnology, pages 7?10.Jan De Belder and Marie-Francine Moens.
2010.
Textsimplification for children.
In Proceedings of the SI-GIR Workshop on Accessible Search Systems, pages19?26.Siobhan Devlin and John Tait.
1998.
The use of a psy-cholinguistic database in the simplification of textfor aphasic readers.
Linguistic Databases, pages161?173.Siobhan Devlin and Gary Unthank.
2006.
Help-ing aphasic people process online information.
InProceedings of the 8th International ACM SIGAC-CESS Conference on Computers and Accessibility(ASSETS), pages 225?226.
ACM.Christiane Fellbaum.
1998.
WordNet.
Wiley OnlineLibrary.Lijun Feng.
2009.
Automatic readability assessmentfor people with intellectual disabilities.
In ACMSIGACCESS Accessibility and Computing, num-ber 93, pages 84?91.
ACM.Goran Glava?s and Sanja?Stajner.
2013.
Event-centeredsimplification of news stories.
In Proceedings of theStudent Workshop held in conjunction with RANLP,pages 71?78.Colby Horn, Cathryn Manduca, and David Kauchak.2014.
Learning a lexical simplifier using wikipedia.In Proceedings of ACL 2014 (Short Papers), pages458?463.Sujay Kumar Jauhar and Lucia Specia.
2012.
UOW-SHEF: SimpLex ?
lexical simplicity ranking basedon contextual and psycholinguistic features.
InProceedings of the SemEval-2012, pages 477?481.ACL.Juan Martos, Sandra Freire, Ana Gonz?alez, David Gil,and Maria Sebastian.
2012.
D2.1: Functional re-quirements specifications and user preference sur-vey.
Technical report, FIRST project.Jean-Baptiste Michel, Yuan Kui Shen, Aviva PresserAiden, Adrian Veres, Matthew K. Gray, Joseph P.Pickett, Dale Hoiberg, Dan Clancy, Peter Norvig,and Jon Orwant.
2011.
Quantitative analysis ofculture using millions of digitized books.
Science,331(6014):176?182.Adam Pauls and Dan Klein.
2011.
Faster and smallern-gram language models.
In Proceedings of ACL-HLT 2011, pages 258?267.
ACL.Jeffrey Pennington, Richard Socher, and Christopher DManning.
2014.
GloVe: Global vectors for wordrepresentation.
In Proceedings of EMNLP 2014,pages 1532?1543.Sarah E. Petersen and Mari Ostendorf.
2007.
Textsimplification for language learners: A corpus anal-ysis.
In Proceedings of Workshop on Speech andLanguage Technology for Education (SLaTE).Luz Rello.
2012.
DysWebxia: A Model to ImproveAccessibility of the Textual Web for Dyslexic Users.In ACM SIGACCESS Accessibility and Computing.,number 102, pages 41?44.
ACM, New York, NY,USA, January.Horacio Saggion, Sanja?Stajner, Stefan Bott, SimonMille, Luz Rello, and Biljana Drndarevic.
2015.Making it simplext: Implementation and evaluationof a text simplification system for spanish.
ACMTransactions on Accessible Computing, 6(4):14.Matthew Shardlow.
2014.
Out in the open: Find-ing and categorising errors in the lexical simplifica-tion pipeline.
In Proceedings of LREC 2014, pages1583?1590.Lucia Specia, Sujay Kumar Jauhar, and Rada Mihal-cea.
2012.
SemEval-2012 Task 1: English lexicalsimplification.
In Proceedings of the SemEval 2012,pages 347?355.
ACL.Kristian Woodsend and Mirella Lapata.
2011.
Learn-ing to simplify sentences with quasi-synchronousgrammar and integer programming.
In Proceedingsof EMNLP 2011, pages 409?420.
ACL.Sander Wubben, Antal Van Den Bosch, and EmielKrahmer.
2012.
Sentence simplification by mono-lingual machine translation.
In Proceedings of ACL2012 (Long Papers), pages 1015?1024.
ACL.Mark Yatskar, Bo Pang, Cristian Danescu-Niculescu-Mizil, and Lillian Lee.
2010.
For the sake of sim-plicity: unsupervised extraction of lexical simplifi-cations from Wikipedia.
In Proceedings of NAACL2010, pages 365?368.
ACL.Alexander Yeh.
2000.
More accurate tests for thestatistical significance of result differences.
In Pro-ceedings of COLING 2000, pages 947?953.
ACL.Zhemin Zhu, Delphine Bernhard, and Iryna Gurevych.2010.
A monolingual tree-based translation modelfor sentence simplification.
In Proceedings of theCOLING 2010, pages 1353?1361.
ACL.68
