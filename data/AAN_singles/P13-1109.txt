Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1105?1115,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsGraph Propagation for Paraphrasing Out-of-Vocabulary Words inStatistical Machine Translation?Majid Razmara1 Maryam Siahbani1 Gholamreza Haffari2 Anoop Sarkar11 Simon Fraser University, Burnaby, BC, Canada{razmara,msiahban,anoop}@sfu.ca2 Monash University, Clayton, VIC, Australiareza@monash.eduAbstractOut-of-vocabulary (oov) words or phrasesstill remain a challenge in statistical machinetranslation especially when a limited amount ofparallel text is available for training or whenthere is a domain shift from training data totest data.
In this paper, we propose a novelapproach to finding translations for oov words.We induce a lexicon by constructing a graph onsource language monolingual text and employa graph propagation technique in order to findtranslations for all the source language phrases.Our method differs from previous approachesby adopting a graph propagation approach thattakes into account not only one-step (from oovdirectly to a source language phrase that has atranslation) but multi-step paraphrases from oovsource language words to other source languagephrases and eventually to target language transla-tions.
Experimental results show that our graphpropagation method significantly improves per-formance over two strong baselines under intrin-sic and extrinsic evaluation metrics.1 IntroductionOut-of-vocabulary (oov) words or phrases still re-main a challenge in statistical machine translation.SMT systems usually copy unknown words verba-tim to the target language output.
Although this ishelpful in translating a small fraction of oovs suchas named entities for languages with same writ-ing systems, it harms the translation in other typesof oovs and distant language pairs.
In general,copied-over oovs are a hindrance to fluent, highquality translation, and we can see evidence of thisin automatic measures such as BLEU (Papineniet al, 2002) and also in human evaluation scoressuch as HTER.
The problem becomes more se-vere when only a limited amount of parallel text isavailable for training or when the training and testdata are from different domains.
Even noisy trans-lation of oovs can aid the language model to better?This research was partially supported by an NSERC,Canada (RGPIN: 264905) grant.
The third author was sup-ported by an early career research award from Monash Uni-versity to visit Simon Fraser University.re-order the words in the target language (Zhanget al, 2012).Increasing the size of the parallel data can re-duce the number of oovs.
However, there will al-ways be some words or phrases that are new to thesystem and finding ways to translate such wordsor phrases will be beneficial to the system.
Re-searchers have applied a number of approaches totackle this problem.
Some approaches use pivotlanguages (Callison-Burch et al, 2006) while oth-ers use lexicon-induction-based approaches fromsource language monolingual corpora (Koehn andKnight, 2002; Garera et al, 2009; Marton et al,2009).Pivot language techniques tackle this problemby taking advantage of available parallel data be-tween the source language and a third language.Using a pivot language, oovs are translated into athird language and back into the source languageand thereby paraphrases to those oov words areextracted (Callison-Burch et al, 2006).
For eachoov, the system can be augmented by aggregatingthe translations of all its paraphrases and assignthem to the oov.
However, these methods requireparallel corpora between the source language andone or multiple pivot languages.Another line of work exploits spelling and mor-phological variants of oov words.
Habash (2008)presents techniques for online handling of oovwords for Arabic to English such as spelling ex-pansion and morphological expansion.
Huang etal.
(2011) proposes a method to combine sub-lexical/constituent translations of an oov word orphrase to generate its translations.Several researchers have applied lexicon-induction methods to create a bilingual lexiconfor those oovs.
Marton et al (2009) use a mono-lingual text on the source side to find paraphrasesto oov words for which the translations are avail-able.
The translations for these paraphrases are1105then used as the translations of the oov word.These methods are based on the distributional hy-pothesis which states that words appearing in thesame contexts tend to have similar meaning (Har-ris, 1954).
Marton et al (2009) showed that thismethod improves over the baseline system whereoovs are untranslated.We propose a graph propagation-based exten-sion to the approach of Marton et al (2009) inwhich a graph is constructed from source languagemonolingual text1 and the source-side of the avail-able parallel data.
Nodes that have related mean-ings are connected together and nodes for whichwe have translations in the phrase-table are an-notated with target-side translations and their fea-ture values.
A graph propagation algorithm is thenused to propagate translations from labeled nodesto unlabeled nodes (phrases appearing only in themonolingual text and oovs).
This provides a gen-eral purpose approach to handle several types ofoovs, including morphological variants, spellingvariants and synonyms2.Constructing such a huge graph and propagat-ing messages through it pose severe computationalchallenges.
Throughout the paper, we will see howthese challenges are dealt with using scalable algo-rithms.2 Collocational Lexicon InductionRapp (1995) introduced the notion of a distribu-tional profile in bilingual lexicon induction frommonolingual data.
A distributional profile (DP) ofa word or phrase type is a co-occurrence vectorcreated by combining all co-occurrence vectors ofthe tokens of that phrase type.
Each distributionalprofile can be seen as a point in a |V |-dimensionalspace where V is the vocabulary where each wordtype represents a unique axis.
Points (i.e.
phrasetypes) that are close to one another in this high-dimensional space can represent paraphrases.
Thisapproach has also been used in machine trans-lation to find in-vocabulary paraphrases for oovwords on the source side and find a way to trans-late them.2.1 Baseline SystemMarton et al (2009) was the first to successfullyintegrate a collocational approach to finding trans-1Here on by monolingual data we always mean monolin-gual data on the source language2Named entity oovs may be handled properly by copyingor transliteration.lations for oov words into an end-to-end SMT sys-tem.
We explain their method in detail as we willcompare against this approach.
The method re-lies on monolingual distributional profiles (DPs)which are numerical vectors representing the con-text around each word.
The goal is to find words orphrases that appear in similar contexts as the oovs.For each oov a distributional profile is created bycollecting all words appearing in a fixed distancefrom all occurrences of the oov word in the mono-lingual text.
These co-occurrence counts are con-verted to an association measure (Section 2.2) thatencodes the relatedness of each pair of words orphrases.Then, the most similar phrases to each oov arefound by measuring the similarity of their DPs tothat of the oov word.
Marton et al (2009) usesa heuristic to prune the search space for findingcandidate paraphrases by keeping the surroundingcontext (e.g.
L R) of each occurrences of theoov word.
All phrases that appear in any of suchcontexts are collected as candidate paraphrases.For each of these paraphrases, a DP is constructedand compared to that of the oov word using a sim-ilarity measure (Section 2.2).The top-k paraphrases that have translations inthe phrase-table are used to assign translations andscores to each oov word by marginalizing transla-tions over paraphrases:p(t|o) =?sp(t|s)p(s|o)where t is a phrase on the target side, o is the oovword or phrase, and s is a paraphrase of o. p(s|o)is estimated using a similarity measure over DPsand p(t|s) is coming from the phrase-table.We reimplemented this collocational approachfor finding translations for oovs and used it as abaseline system.Alternative ways of modeling and comparingdistributional profiles have been proposed (Rapp,1999; Fung and Yee, 1998; Terra and Clarke,2003; Garera et al, 2009; Marton et al, 2009).We review some of them here and compare theirperformance in Section 4.3.2.2 Association MeasuresGiven a word u, its distributional profile DP (u)is constructed by counting surrounding words (ina fixed window size) in a monolingual corpus.DP (u) = {?A(u,wi)?
| wi ?
V }1106The counts can be collected in positional3 (Rapp,1999) or non-positional way (count all the wordoccurrences within the sliding window).
A(?, ?
)is an association measure and can simply be de-fined as co-occurrence counts within sliding win-dows.
Stronger association measures can also beused such as:Conditional probability: the probability for theoccurrence of each word in DP given the occur-rence of u: CP(u,wi) = P (wi|u) (Schu?tze andPedersen, 1997)Pointwise Mutual Information: this measure isa transformation of the independence assumptioninto a ratio.
Positive values indicate that wordsco-occur more than what we expect under the in-dependence assumption (Lin, 1998):PMI(u,wi) = log2 P (u,wi)P (u)P (wi)Likelihood ratio: (Dunning, 1993) uses the like-lihood ratio for word similarity:?
(u,wi) =L(P (wi|u); p) ?
L(P (wi|?u); p)L(P (wi|u); p1) ?
L(P (wi|?u); p2)where L is likelihood function under the assump-tion that word counts in text have binomial distri-butions.
The numerator represents the likelihoodof the hypothesis that u and wi are independent(P (wi|u) = P (wi|?u) = p) and the denomina-tor represents the likelihood of the hypothesis thatu and wi are dependent (P (wi|u) 6= P (wi|?u) ,P (wi|u) = p1, P (wi|?u) = p2 )4.Chi-square test: is a statistical hypothesis testingmethod to evaluate independence of two categori-cal random variables, e.g.
whether the occurrenceof u and wi (denoted by x and y respectively) areindependent.
The test statistics ?2(u,wi) is thedeviation of the observed counts fx,y from theirexpected values Ex,y:?2(u,wi) :=?x?{wi,?wi}?y?
{u,?u}(fx,y ?
Ex,y)2Ex,y2.3 Similarity MeasuresVarious functions have been used to estimatethe similarity between distributional profiles.3e.g., position 1 is the word immediately after, position -1is the word immediately before etc.4Binomial distribution B(k;n, ?)
gives the probability ofobserving k heads in n tosses of a coin where the coin pa-rameter is ?.
In our context, p, p1 and p2 are parameters ofBinomial distributions estimated using maximum likelihood.Given two distributional profiles DP (u) andDP (v), some similarity functions can be definedas follows.
Note that A(?, ?)
stands for the variousassociation measures defined in Sec.
2.2.Cosine coefficient is the cosine the angle betweentwo vectors DP (u) and DP (v):cos(DP (u), DP (v)) =?wi?V A(u,wi)A(v, wi)?
?wi?V A(u,wi)2?
?wi?V A(v, wi)2L1-Norm computes the accumulated distancebetween entries of two distributional profiles(L1(?, ?)).
It has been used as word similarity mea-sure in language modeling (Dagan et al, 1999).L1(DP (u), DP (v)) =?wi?V|A(u,wi)?A(v, wi)|Jensen-Shannon Divergence is a symmetric ver-sion of contextual average mutual information(KL) which is used by (Dagan et al, 1999) asword similarity measure.JSD(DP (u), DP (v)) =KL(DP (u), AV GDP (u, v))+KL(DP (v), AV GDP (u, v))AV GDP (u, v) ={A(u,wi) +A(v, wi)2 | wi ?
V}KL(DP (u), DP (v)) =?wi?VA(u,wi)logA(u,wi)A(v, wi)3 Graph-based Lexicon InductionWe propose a novel approach to alleviate the oovproblem.
Given a (possibly small amount of) par-allel data between the source and target languages,and a large monolingual data in the source lan-guage, we construct a graph over all phrase typesin the monolingual text and the source side of theparallel corpus and connect phrases that have sim-ilar meanings (i.e.
appear in similar context) to oneanother.
To do so, the distributional profiles ofall source phrase types are created.
Each phrasetype represents a vertex in the graph and is con-nected to other vertices with a weight defined by asimilarity measure between the two profiles (Sec-tion 2.3).
There are three types of vertices in thegraph: i) labeled nodes which appear in the par-allel corpus and for which we have the target-side1107translations5; ii) oov nodes from the dev/test setfor which we seek labels (translations); and iii) un-labeled nodes (words or phrases) from the mono-lingual data which appear usually between oovnodes and labeled nodes.
When a relatively smallparallel data is used, unlabeled nodes outnumberlabeled ones and many of them lie on the pathsbetween an oov node to labeled ones.Marton et al (2009)?s approach ignores thesebridging nodes and connects each oov node to thek-nearest labeled nodes.
One may argue that theseunlabeled nodes do not play a major role in thegraph and the labels will eventually get to the oovnodes from the labeled nodes by directly connect-ing them.
However based on the definition of thesimilarity measures using context, it is quite possi-ble that an oov node and a labeled node which areconnected to the same unlabeled node do not shareany context words and hence are not directly con-nected.
For instance, consider three nodes, u (un-labeled), o (oov) and l (labeled) where u has thesame left context words with o but share the rightcontext with l. o and l are not connected since theydo not share any context word.Once a graph is constructed based on simi-larities of phrases, graph propagation is used topropagate the labels from labeled nodes to unla-beled and oov nodes.
The approach is based onthe smoothness assumption (Chapelle et al, 2006)which states if two nodes are similar according tothe graph, then their output labels should also besimilar.The baseline approach (Marton et al, 2009) canbe formulated as a bipartite graph with two typesof nodes: labeled nodes (L) and oov nodes (O).Each oov node is connected to a number of labelednodes, and vice versa and there is no edge betweennodes of the same type.
In such a graph, the sim-ilarity of each pair of nodes is computed usingone of the similarity measures discussed above.The labels are translations and their probabilities(more specifically p(e|f)) from the phrase-tableextracted from the parallel corpus.
Translationsget propagated to oov nodes using a label prop-agation technique.
However beside the differencein the oov label assignment, there is a major differ-ence between our bipartite graph and the baseline(Marton et al, 2009): we do not use a heuristic to5It is possible that a phrase appears in the parallel corpus,but not in the phrase-table.
This happens when the word-alignment module is not able to align the phrase to a targetside word or words.reduce the number of neighbor candidates and weconsider all possible candidates that share at leastone context word.
This makes a significant differ-ence in practice as shown in Section 4.3.1.We also take advantage of unlabeled nodes tohelp connect oov nodes to labeled ones.
The dis-cussed bipartite graph can easily be expanded to atripartite graph by adding unlabeled nodes.
Fig-ure 1 illustrate a tripartite graph in which unla-beled nodes are connected to both labeled and oovnodes.
Again, there is no edge between nodesof the same type.
We also created the full graphwhere all nodes can be freely connected to nodesof any type including the same type.
However,constructing such graph and doing graph propa-gation on it is computationally very expensive forlarge n-grams.3.1 Label PropagationLet G = (V,E,W ) be a graph where V is the setof vertices,E is the set of edges, andW is the edgeweight matrix.
The vertex set V consists of la-beled VL and unlabeled VU nodes, and the goal ofthe labeling propagation algorithm is to computesoft labels for unlabeled vertices from the labeledvertices.
Intuitively, the edge weight W (u, v) en-codes the degree of our belief about the similarityof the soft labeling for nodes u and v. A soft labelY?v ?
?m+1 is a probability vector in (m + 1)-dimensional simplex, where m is the number ofpossible labels and the additional dimension ac-counts for the undefined ?
label6.In this paper, we make use of the modified Ad-sorption (MAD) algorithm (Talukdar and Cram-mer, 2009) which finds soft label vectors Y?v tosolve the following unconstrained optimizationproblem:minY?
?1?v?VLp1,v||Yv ?
Y?v||22 + (1)?2?v,up2,vWv,u||Y?v ?
Y?u||22 + (2)?3?vp3,v||Y?v ?Rv||22 (3)where ?i and pi,v are hyper-parameters (?v :?i pi,v = 1)7, and Rv ?
?m+1 encodes our priorbelief about the labeling of a node v. The first6Capturing those cases where the given data is not enoughto reliably compute a soft labeling using the initial m reallabels.7The values of these hyper-parameters are set to their de-faults in the Junto toolkit (Talukdar and Crammer, 2009).1108o1o2o3l1l2l3u1 u2 u3 u4 u5t11 : p11t12 : p12t13 : p13t21 : p21t22 : p22t23 : p23t31 : p31t32 : p32t33 : p33O : oov nodes L : labeled nodesU : unlabeled nodessim(o1, l1)Figure 1: A tripartite graph between oov, labeled and unlabeled nodes.
Translations propagate either directly from labelednodes to oov nodes or indirectly via unlabeled nodes.term (1) enforces the labeling of the algorithm tomatch the seed labeling Yv with different extentfor different labeled nodes.
The second term (2)enforces the smoothness of the labeling accordingto the graph structure and edge weights.
The lastterm (3) regularizes the soft labeling for a vertexv to match a priori label Rv, e.g.
for high-degreeunlabeled nodes (hubs in the graph) we may be-lieve that the neighbors are not going to producereliable label and hence the probability of unde-fined label ?
should be higher.
The optimiza-tion problem can be solved with an efficient iter-ative algorithm which is parallelized in a MapRe-duce framework (Talukdar et al, 2008; Rao andYarowsky, 2009).
We used the Junto label prop-agation toolkit (Talukdar and Crammer, 2009) forlabel propagation.3.2 Efficient Graph ConstructionGraph-based approaches can easily become com-putationally very expensive as the number ofnodes grow.
In our case, we use phrases in themonolingual text as graph vertices.
These phrasesare n-grams up to a certain value, which can re-sult in millions of nodes.
For each node a distribu-tional profile (DP) needs to be created.
The num-ber of possible edges can easily explode in sizeas there can be as many as O(n2) edges where nis the number of nodes.
A common practice tocontrol the number of edges is to connect eachnode to at most k other nodes (k-nearest neigh-bor).
However, finding the top-k nearest nodes toeach node requires considering its similarity to allthe other nodes which requires O(n2) computa-tions and since n is usually very large, doing suchis practically intractable.
Therefore, researchersusually resort to an approximate k-NN algorithmssuch as locality-sensitive hashing (?
; Goyal et al,2012).Fortunately, since we use context words as cuesfor relating their meaning and since the similar-ity measures are defined based on these cues, thenumber of neighbors we need to consider for eachnode is reduced by several orders of magnitude.We incorporate an inverted-index-style data struc-ture which indicates what nodes are neighborsbased on each context word.
Therefore, the setof neighbors of a node consists of union of all theneighbors bridged by each context word in the DPof the node.
However, the number of neighbors tobe considered for each node even after this dras-tic reduction is still large (in order of a few thou-sands).In order to deal with the computational chal-lenges of such a large graph, we take advantage ofthe Hadoop?s MapReduce functionality to do bothgraph construction and label propagation steps.4 Experiments & Results4.1 Experimental SetupWe experimented with two different domains forthe bilingual data: Europarl corpus (v7) (Koehn,1109Dataset Domain Sents TokensFr EnBitext Europarl 10K 298K 268KEMEA 1M 16M 14MMonotext Europarl 2M 60M ?Dev-set WMT05 2K 67K 58KTest-set WMT05 2K 66K 58KTable 1: Statistics of training sets in different domains.2005), and European Medicines Agency docu-ments (EMEA) (Tiedemann, 2009) from Frenchto English.
For the monolingual data, we usedFrench side of the Europarl corpus and we usedACL/WMT 20058 data for dev/test sets.
Table 1summarizes statistics of the datasets used.From the dev and test sets, we extract all sourcewords that do not appear in the phrase-table con-structed from the parallel data.
From the oovs, weexclude numbers as well as named entities.
Weapply a simple heuristic to detect named entities:basically words that are capitalized in the originaldev/test set that do not appear at the beginning ofa sentence are named entities.
Table 2 shows thenumber of oov types and tokens for Europarl andEMEA systems in both dev and test sets.Dataset Dev Testtypes tokens types tokensEuroparl 1893 2229 1830 2163EMEA 2325 4317 2294 4190Table 2: number of oovs in dev and test sets for Europarl andEMEA systems.For the end-to-end MT pipeline, we usedMoses (Koehn et al, 2007) with these stan-dard features: relative-frequency and lexical trans-lation model (TM) probabilities in both direc-tions; distortion model; language model (LM)and word count.
Word alignment is done usingGIZA++ (Och and Ney, 2003).
We used distortionlimit of 6 and max-phrase-length of 10 in all theexperiments.
For the language model, we used theKenLM toolkit (Heafield, 2011) to create a 5-gramlanguage model on the target side of the Europarlcorpus (v7) with approximately 54M tokens withKneser-Ney smoothing.4.1.1 Phrase-table IntegrationOnce the translations and their probabilities foreach oov are extracted, they are added to the8http://www.statmt.org/wpt05/mt-shared-task/phrase-table that is induced from the parallel text.The probability for new entries are added as anew feature in the log-linear framework to betuned along with other features.
The value ofthis newly introduced feature for original entriesin the phrase-table is set to 1.
Similarly, the valueof original four probability features in the phrase-table for the new entries are set to 1.
The entiretraining pipeline is as follows: (i) a phrase table isconstructed using parallel data as usual, (ii) oovsfor dev and test sets are extracted, (iii) oovs aretranslated using graph propagation, (iv) oovs andtranslations are added to the phrase table, intro-ducing a new feature type, (v) the new phrase tableis tuned (with a LM) using MERT (Och, 2003) onthe dev set.4.2 EvaluationIf we have a list of possible translations for oovswith their probabilities, we become able to eval-uate different methods we discussed.
We word-aligned the dev/test sets by concatenating them toa large parallel corpus and running GIZA++ onthe whole set.
The resulting word alignments areused to extract the translations for each oov.
Thecorrectness of this gold standard is limited to thesize of the parallel data used as well as the qualityof the word alignment software toolkit, and is not100% precise.
However, it gives a good estimateof how each oov should be translated without theneed for human judgments.For evaluating our baseline as well as graph-based approaches, we use both intrinsic andextrinsic evaluations.
Two intrinsic evaluationmetrics that we use to evaluate the possibletranslations for oovs are Mean Reciprocal Rank(MRR) (Voorhees, 1999) and Recall.
Intrinsicevaluation metrics are faster to apply and are usedto optimize different hyper-parameters of the ap-proach (e.g.
window size, phrase length, etc.
).Once we come up with the optimized values forthe hyper-parameters, we extrinsically evaluatedifferent approaches by adding the new transla-tions to the phrase-table and run it through the MTpipeline.4.2.1 MRRMRR is an Information Retrieval metric used toevaluate any process that produces a ranked list ofpossible candidates.
The reciprocal rank of a listis the inverse of the rank of the correct answer inthe list.
Such score is averaged over a set, oov set1110in our case, to get the mean-reciprocal-rank score.MRR = 1|O||O|?i=11rankiO = {oov}In a few cases, there are multiple translations foran oov word (i.e.
appearing more than once in theparallel corpus and being assigned to multiple dif-ferent phrases), we take the average of reciprocalranks for each of them.4.2.2 RecallMRR takes the probabilities of oov translationsinto account in sorting the list of candidate trans-lations.
However, in an MT pipeline, the languagemodel is supposed to rerank the hypotheses andmove more appropriate translations (in terms offluency) to the top of the list.
Hence, we alsoevaluate our candidate translation regardless of theranks.
Since Moses uses a certain number of trans-lations per source phrase (called the translation ta-ble limit or ttl which we set to 20 in our experi-ments) , we use the recall measure to evaluate thetop ttl translations in the list.
Recall is another In-formation Retrieval measure that is the fraction ofcorrect answers that are retrieved.
For example, itassigns score of 1 if the correct translation of theoov word is in the top-k list and 0 otherwise.
Thescores are averaged over all oovs to compute re-call.Recall = |{gold standard} ?
{candidate list}||{gold standard}|4.3 Intrinsic ResultsIn Section 2.2 and 2.3, different types of associa-tion measures and similarity measures have beenexplained to build and compare distributional pro-files.
Table 3 shows the results on Europarl whenusing different similarity combinations.
The mea-sures are evaluated by fixing the window size to4 and maximum candidate paraphrase length to 2(e.g.
bigram).
First column shows the associationmeasures used to build DPs.
As the results show,the combination of PMI as association measureand cosine as DP similarity measure outperformsthe other possible combinations.
We use these twomeasures throughout the rest of the experiments.Figure 2 illustrates the effects of different win-dow sizes and paraphrase lengths on MRR.
As thefigure shows, the best MRR is reached when usingwindow size of 4 and trigram nodes.
Going fromtrigram to 4-gram results in a drop in MRR.
OneAssoc cosine(%) L1norm(%) JSD(%)MRR RCL MRR RCL MRR RCLCP 1.66 4.16 2.18 5.55 2.33 6.32LLR 1.79 4.26 0.13 0.37 0.5 1.00PMI 3.91 7.75 0.50 1.17 0.59 1.21Chi 1.66 4.16 0.26 0.55 0.03 0.05Table 3: Results of intrinsic evaluations (MRR and Recall)on Europarl, window size 4 and paraphrase length 23.5?3.7?3.9?4.1?4.3?2?
3?
4?
5?
6?
7?MRR?(%)?Window?Size?unigram?
bigram?
trigram?
quadgram?Figure 2: Effects of different window sizes and paraphraselength on the MRR of the dev set.reason would be that distributional profiles for 4-grams are very sparse and that negatively affectsthe stability of similarity measures.Figure 3 illustrates the effect of increasing thesize of monolingual text on both MRR and recall.1?
refers to the case of using 125k sentences forthe monolingual text and the 16?
indicates usingthe whole Europarl text on the source side (?
2Msentences).
As shown, there is a linear correla-tion between the logarithm of the data size andthe MRR and recall ratios.
Interestingly, MRR isgrowing faster than recall by increasing the mono-lingual text size, which means that the scoringfunction gets better when more data is available.The figure also indicates that a much bigger mono-lingual text data can be used to further improve thequality of the translations, however, at the expenseof more computational resources.MRR?Ra?o?Recall?Ra?o?0123450 1x 2x 4x 8x 16xMono-text Size RatioFigure 3: Effect of increasing the monolingual text size onMRR and Recall.1111Graph Neighbor MRR % RCL %Bipartite 20 5.2 12.5Tripartite 15+5 5.9 12.6Full 20 5.1 10.9Baseline 20 3.7 7.2Table 4: Intrinsic results of different types of graphs whenusing unigram nodes on Europarl.Type Node MRR % RCL %Bipartite unigram 5.2 12.5bigram 6.8 15.7Tripartite unigram 5.9 12.6bigram 6.9 15.9Baseline bigram 3.9 7.7Table 5: Results on using unigram or bigram nodes.4.3.1 Graph-based ResultsTable 4 shows the intrinsic results on the Eu-roparl corpus when using unigram nodes in eachof the graphs.
The results are evaluated on thedev-set based on the gold alignment created us-ing GIZA++.
Each node is connected to at most20 other nodes (same as the max-paraphrase-limitin the baseline).
For the tripartite graph, eachnode is connected to 15 labeled nodes and 5 un-labeled ones.
The tripartite graph gets a slight im-provement over the bipartite one, however, the fullgraph failed to have the same increase.
One rea-son is that allowing paths longer than 2 betweenoov and labeled nodes causes more noise to prop-agate into the graph.
In other words, a paraphraseof a paraphrase of a paraphrase is not necessarilya useful paraphrase for an oov as the translationmay no longer be a valid one.Table 5 also shows the effect of using bigramsinstead of unigrams as graph nodes.
There is animprovement by going from unigrams to bigramsin both bipartite and tripartite graphs.
We did notuse trigrams or larger n-grams in our experiments.4.4 Extrinsic ResultsThe generated candidate translations for the oovscan be added to the phrase-table created usingthe parallel corpus to increase the coverage of thephrase-table.
This aggregated phrase-table is to betuned along with the language model on the devset, and run on the test set.
BLEU (Papineni etal., 2002) is still the de facto evaluation metric formachine translation and we use that to measurethe quality of our proposed approaches for MT.In these experiments, we do not use alignment in-formation on dev or test sets unlike the previoussection.Table 6 reports the Bleu scores for different do-mains when the oov translations from the graphpropagation is added to the phrase-table and com-pares them with the baseline system (i.e.
Moses).Results for our approach is based on unigram tri-partite graphs and show that we improve over thebaseline in both the same-domain (Europarl) anddomain adaptation (EMEA) settings.Table 7 shows some translations found by oursystem for oov words.oov gold standard candiate listspe?cialementundoneparticularlyespeciallyspecialparticularparticularlyspecificonlyparticularshouldandespeciallyassentiment approvalsupportagreementapprovalaccessionwill approveendorsesTable 7: Two examples of oov translations found by ourmethod.5 Related workThere has been a long line of research on learningtranslation pairs from non-parallel corpora (Rapp,1995; Koehn and Knight, 2002; Haghighi et al,2008; Garera et al, 2009; Marton et al, 2009;Laws et al, 2010).
Most have focused on ex-tracting a translation lexicon by mining monolin-gual resources of data to find clues, using prob-abilistic methods to map words, or by exploit-ing the cross-language evidence of closely relatedlanguages.
Most of them evaluated only high-frequency words of specific types (nouns or con-tent words) (Rapp, 1995; Koehn and Knight, 2002;Haghighi et al, 2008; Garera et al, 2009; Laws etal., 2010) In contrast, we do not consider any con-straint on our test data and our data includes manylow frequency words.
It has been shown that trans-lation of high-frequency words is easier than lowfrequency words (Tamura et al, 2012).Some methods have used a third language(s)as pivot or bridge to find translation pairs (Mannand Yarowsky, 2001; Schafer and Yarowsky, 2002;Callison-Burch et al, 2006).1112Corpus System MRR Recall Dev Bleu Test BleuEuroparl Baseline ?
?
28.53 28.97Our approach 5.9 12.6 28.76 29.40*EMEA Baseline ?
?
20.05 20.34Our approach 3.6 7.4 20.54 20.80** Statistically significant with p < 0.02 using the bootstrap resampling significance test (in Moses).Table 6: Bleu scores for different domains with or without using oov translations.Context similarity has been used effectively inbilingual lexicon induction (Rapp, 1995; Koehnand Knight, 2002; Haghighi et al, 2008; Gar-era et al, 2009; Marton et al, 2009; Laws et al,2010).
It has been modeled in different ways: interms of adjacent words (Rapp, 1999; Fung andYee, 1998), or dependency relations (Garera et al,2009).
Laws et al (2010) used linguistic analy-sis in the form of graph-based models instead of avector space.
But all of these researches used anavailable seed lexicon as the basic source of simi-larity between source and target languages unlikeour method which just needs a monolingual cor-pus of source language which is freely availablefor many languages and a small bilingual corpora.Some methods tried to alleviate the lack of seedlexicon by using orthographic similarity to extracta seed lexicon (Koehn and Knight, 2002; Fiser andLjubesic, 2011).
But it is not a practical solutionin case of unrelated languages.Haghighi et al (2008) and Daume?
and Jagarla-mudi (2011) proposed generative models based oncanonical correlation analysis to extract transla-tion lexicons for non-parallel corpora by learning amatching between source and target lexicons.
Us-ing monolingual features to represent words, fea-ture vectors are projected from source and targetwords into a canonical space to find the appropri-ate matching between them.
Their method relieson context features which need a seed lexicon andorthographic features which only works for phylo-genetically related languages.Graph-based semi-supervised methods havebeen shown to be useful for domain adaptation inMT as well.
Alexandrescu and Kirchhoff (2009)applied a graph-based method to determine simi-larities between sentences and use these similari-ties to promote similar translations for similar sen-tences.
They used a graph-based semi-supervisedmodel to re-rank the n-best translation hypothe-sis.
Liu et al (2012) extended Alexandrescu?smodel to use translation consensus among simi-lar sentences in bilingual training data by devel-oping a new structured label propagation method.They derived some features to use during decodingprocess that has been shown useful in improvingtranslation quality.
Our graph propagation methodconnects monolingual source phrases with oovs toobtain translation and so is a very different use ofgraph propagation from these previous works.Recently label propagation has been used forlexicon induction (Tamura et al, 2012).
They useda graph based on context similarity as well as co-occurrence graph in propagation process.
Similarto our approach they used unlabeled nodes in la-bel propagation process.
However, they use a seedlexicon to define labels and comparable corpora toconstruct graphs unlike our approach.6 ConclusionWe presented a novel approach for inducing oovtranslations from a monolingual corpus on thesource side and a parallel data using graph prop-agation.
Our results showed improvement overthe baselines both in intrinsic evaluations and onBLEU.
Future work includes studying the effectof size of parallel corpus on the induced oov trans-lations.
Increasing the size of parallel corpus onone hand reduces the number of oovs.
But, onthe other hand, there will be more labeled para-phrases that increases the chance of finding thecorrect translation for oovs in the test set.Currently, we find paraphrases for oov words.However, oovs can be considered as n-grams(phrases) instead of unigrams.
In this scenario,we also can look for paraphrases and translationsfor phrases containing oovs and add them to thephrase-table as new translations along with thetranslations for unigram oovs.We also plan to explore different graph propa-gation objective functions.
Regularizing these ob-jective functions appropriately might let us scaleto much larger data sets with an order of magni-tude more nodes in the graph.1113ReferencesAndrei Alexandrescu and Katrin Kirchhoff.
2009.Graph-based learning for statistical machine trans-lation.
In Proceedings of Human Language Tech-nologies: The 2009 Annual Conference of the NorthAmerican Chapter of the Association for Compu-tational Linguistics, NAACL ?09, pages 119?127,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.C.
Callison-Burch, P. Koehn, and M. Osborne.
2006.Improved statistical machine translation using para-phrases.
In Proceedings of the main conferenceon Human Language Technology Conference of theNorth American Chapter of the Association of Com-putational Linguistics, pages 17?24.
Association forComputational Linguistics.O.
Chapelle, B. Scho?lkopf, and A. Zien, editors.
2006.Semi-Supervised Learning.
MIT Press, Cambridge,MA.Ido Dagan, Lillian Lee, and Fernando C. N. Pereira.1999.
Similarity-based models of word cooccur-rence probabilities.
Mach.
Learn., 34(1-3):43?69,February.Hal Daume?, III and Jagadeesh Jagarlamudi.
2011.
Do-main adaptation for machine translation by miningunseen words.
In Proceedings of the 49th AnnualMeeting of the Association for Computational Lin-guistics: Human Language Technologies: short pa-pers - Volume 2, HLT ?11, pages 407?412, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Ted Dunning.
1993.
Accurate methods for the statis-tics of surprise and coincidence.
Comput.
Linguist.,19(1):61?74, March.Darja Fiser and Nikola Ljubesic.
2011.
Bilingual lexi-con extraction from comparable corpora for closelyrelated languages.
In RANLP, pages 125?131.Pascale Fung and Lo Yuen Yee.
1998.
An ir approachfor translating new words from nonparallel, compa-rable texts.
In Proceedings of the 36th Annual Meet-ing of the Association for Computational Linguis-tics and 17th International Conference on Computa-tional Linguistics - Volume 1, ACL ?98, pages 414?420.
Association for Computational Linguistics.Nikesh Garera, Chris Callison-Burch, and DavidYarowsky.
2009.
Improving translation lexicon in-duction from monolingual corpora via dependencycontexts and part-of-speech equivalences.
In Pro-ceedings of the Thirteenth Conference on Compu-tational Natural Language Learning, CoNLL ?09,pages 129?137, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Amit Goyal, Hal Daume III, and Raul Guerra.
2012.Fast Large-Scale Approximate Graph Constructionfor NLP.
In Proceedings of the Conference on Em-pirical Methods in Natural Language Processing,EMNLP ?12.Nizar Habash.
2008.
Four techniques for online han-dling of out-of-vocabulary words in arabic-englishstatistical machine translation.
In Proceedings of the46th Annual Meeting of the Association for Compu-tational Linguistics on Human Language Technolo-gies: Short Papers, pages 57?60.
Association forComputational Linguistics.Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick,and Dan Klein.
2008.
Learning bilingual lexiconsfrom monolingual corpora.
In ACL, pages 771?779.Zellig Harris.
1954.
Distributional structure.
Word,10(23):146?162.Kenneth Heafield.
2011.
Kenlm: Faster and smallerlanguage model queries.
In Proceedings of the SixthWorkshop on Statistical Machine Translation, pages187?197.Chung-Chi Huang, Ho-Ching Yen, Ping-Che Yang,Shih-Ting Huang, and Jason S Chang.
2011.
Us-ing sublexical translations to handle the oov prob-lem in machine translation.
ACM Transactions onAsian Language Information Processing (TALIP),10(3):16.Philipp Koehn and Kevin Knight.
2002.
Learning atranslation lexicon from monolingual corpora.
InProceedings of the ACL-02 workshop on Unsuper-vised lexical acquisition - Volume 9, ULA ?02, pages9?16, Stroudsburg, PA, USA.
Association for Com-putational Linguistics.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondr?ej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: opensource toolkit for statistical machine translation.
InProceedings of the 45th Annual Meeting of the ACLon Interactive Poster and Demonstration Sessions,ACL ?07, pages 177?180, Stroudsburg, PA, USA.ACL.P.
Koehn.
2005.
Europarl: A parallel corpus for statis-tical machine translation.
In MT summit, volume 5.Florian Laws, Lukas Michelbacher, Beate Dorow,Christian Scheible, Ulrich Heid, and HinrichSchu?tze.
2010.
A linguistically grounded graphmodel for bilingual lexicon extraction.
In Proceed-ings of the 23rd International Conference on Com-putational Linguistics: Posters, COLING ?10, pages614?622, Stroudsburg, PA, USA.
Association forComputational Linguistics.Dekang Lin.
1998.
Automatic retrieval and clusteringof similar words.
In Proceedings of the 36th AnnualMeeting of the Association for Computational Lin-guistics and 17th International Conference on Com-putational Linguistics - Volume 2, ACL ?98, pages768?774, Stroudsburg, PA, USA.
Association forComputational Linguistics.1114Shujie Liu, Chi-Ho Li, Mu Li, and Ming Zhou.
2012.Learning translation consensus with structured la-bel propagation.
In Proceedings of the 50th AnnualMeeting of the Association for Computational Lin-guistics: Long Papers - Volume 1, ACL ?12, pages302?310, Stroudsburg, PA, USA.
Association forComputational Linguistics.Gideon S. Mann and David Yarowsky.
2001.
Mul-tipath translation lexicon induction via bridge lan-guages.
In Proceedings of the second meeting ofthe North American Chapter of the Association forComputational Linguistics on Language technolo-gies, NAACL ?01, pages 1?8, Stroudsburg, PA,USA.Yuval Marton, Chris Callison-Burch, and PhilipResnik.
2009.
Improved statistical machine trans-lation using monolingually-derived paraphrases.
InProceedings of the 2009 Conference on EmpiricalMethods in Natural Language Processing: Volume1 - Volume 1, EMNLP ?09, pages 381?390, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Comput.
Linguist., 29(1):19?51, March.Franz Josef Och.
2003.
Minimum error rate trainingfor statistical machine translation.
In Proceedings ofthe 41th Annual Meeting of the ACL, Sapporo, July.ACL.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: a method for automatic eval-uation of machine translation.
In Proceedings ofthe 40th Annual Meeting on Association for Com-putational Linguistics, ACL ?02, pages 311?318,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Delip Rao and David Yarowsky.
2009.
Rankingand semi-supervised classification on large scalegraphs using map-reduce.
In Proceedings of the2009 Workshop on Graph-based Methods for Nat-ural Language Processing, TextGraphs-4.
Associa-tion for Computational Linguistics.Reinhard Rapp.
1995.
Identifying word translations innon-parallel texts.
In Proceedings of the 33rd an-nual meeting on Association for Computational Lin-guistics, ACL ?95, pages 320?322.
Association forComputational Linguistics.Reinhard Rapp.
1999.
Automatic identification ofword translations from unrelated english and germancorpora.
In Proceedings of the 37th annual meet-ing of the Association for Computational Linguisticson Computational Linguistics, ACL ?99, pages 519?526.
Association for Computational Linguistics.Charles Schafer and David Yarowsky.
2002.
Induc-ing translation lexicons via diverse similarity mea-sures and bridge languages.
In proceedings of the6th conference on Natural language learning - Vol-ume 20, COLING-02, pages 1?7, Stroudsburg, PA,USA.
Association for Computational Linguistics.Hinrich Schu?tze and Jan O. Pedersen.
1997.
Acooccurrence-based thesaurus and two applicationsto information retrieval.
Inf.
Process.
Manage.,33(3):307?318, May.Partha Pratim Talukdar and Koby Crammer.
2009.New Regularized Algorithms for TransductiveLearning.
In European Conference on MachineLearning (ECML-PKDD).Partha Pratim Talukdar, Joseph Reisinger, MariusPas?ca, Deepak Ravichandran, Rahul Bhagat, andFernando Pereira.
2008.
Weakly-supervised acqui-sition of labeled class instances using graph randomwalks.
In Proceedings of the Conference on Em-pirical Methods in Natural Language Processing,EMNLP ?08.Akihiro Tamura, Taro Watanabe, and Eiichiro Sumita.2012.
Bilingual lexicon extraction from compara-ble corpora using label propagation.
In EMNLP-CoNLL, pages 24?36.Egidio L. Terra and Charles L. A. Clarke.
2003.
Fre-quency estimates for statistical word similarity mea-sures.
In HLT-NAACL.Jorg Tiedemann.
2009.
News from opus - a collectionof multilingual parallel corpora with tools and inter-faces.
In N. Nicolov, K. Bontcheva, G. Angelova,and R. Mitkov, editors, Recent Advances in Natu-ral Language Processing, volume V, pages 237?248.John Benjamins, Amsterdam/Philadelphia.Ellen M. Voorhees.
1999.
TREC-8 Question Answer-ing Track Report.
In Proceedings of the 8th TextRetrieval Conference, pages 77?82.Jiajun Zhang, Feifei Zhai, and Chengqing Zong.
2012.Handling unknown words in statistical machinetranslation from a new perspective.
In Natural Lan-guage Processing and Chinese Computing, pages176?187.
Springer.1115
