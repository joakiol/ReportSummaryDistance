Linguistically Annotated Reordering:Evaluation and AnalysisDeyi Xiong?Institute for Infocomm ResearchMin Zhang?
?Institute for Infocomm ResearchAiti Aw?Institute for Infocomm ResearchHaizhou Li?Institute for Infocomm ResearchLinguistic knowledge plays an important role in phrase movement in statistical machine trans-lation.
To efficiently incorporate linguistic knowledge into phrase reordering, we propose a newapproach: Linguistically Annotated Reordering (LAR).
In LAR, we build hard hierarchical skele-tons and inject soft linguistic knowledge from source parse trees to nodes of hard skeletons duringtranslation.
The experimental results on large-scale training data show that LAR is comparableto boundary word-based reordering (BWR) (Xiong, Liu, and Lin 2006), which is a very compet-itive lexicalized reordering approach.
When combined with BWR, LAR provides complementaryinformation for phrase reordering, which collectively improves the BLEU score significantly.To further understand the contribution of linguistic knowledge in LAR to phrase reordering,we introduce a syntax-based analysis method to automatically detect constituent movement inboth reference and system translations, and summarize syntactic reordering patterns that arecaptured by reordering models.
With the proposed analysis method, we conduct a comparativeanalysis that not only provides the insight into how linguistic knowledge affects phrase move-ment but also reveals new challenges in phrase reordering.1.
IntroductionThe phrase-based approach is a widely accepted formalism in statistical machine trans-lation (SMT).
It segments the source sentence into a sequence of phrases (not necessarilysyntactic phrases), then translates and reorders these phrases in the target.
The reasonfor the popularity of phrasal SMT is its capability of non-compositional translations and?
1 Fusionopolis Way #21-01 Connexis Singapore 138632.
E-mail: dyxiong@i2r.a-star.edu.sg.??
1 Fusionopolis Way #21-01 Connexis Singapore 138632.
E-mail: mzhang@i2r.a-star.edu.sg.?
1 Fusionopolis Way #21-01 Connexis Singapore 138632.
E-mail: aaiti@i2r.a-star.edu.sg.?
1 Fusionopolis Way #21-01 Connexis Singapore 138632.
E-mail: hli@i2r.a-star.edu.sg.Submission received: 24 October 2008; revised submission received: 12 March 2010; accepted for publication:21 April 2010.?
2010 Association for Computational LinguisticsComputational Linguistics Volume 36, Number 3local word reorderings within phrases.
Unfortunately, reordering at the phrase level isstill problematic for phrasal SMT.
The default distortion-based reordering model simplypenalizes phrase movement according to the jump distance, without considering anylinguistic contexts (morphological, lexical, or syntactic) around phrases.In order to utilize lexical information for phrase reordering, Tillman (2004) andKoehn et al (2005) propose lexicalized reordering models which directly conditionphrase movement on phrases themselves.
One problem with such lexicalized reorderingmodels is that they are restricted only to reorderings of phrases seen in training data.To eliminate this restriction, Xiong, Liu, and Lin (2006) suggest using boundary wordsof phrases (i.e., leftmost/rightmost words of phrases), instead of phrases, as reorderingevidence.
Although these lexicalized reordering models significantly outperform thedistortion-based reordering model as reported, only using lexical information (e.g.,boundary words) is not adequate to move phrases to appropriate positions.Consider the following Chinese example with its English translation:[VP [PP(while)(develop)(related)(legislation)] [VP [VV(consider)] [NP [DNP [NP(this) (referendum)] [DEG(of)]] [NP(results)]]]]1consider the results of this referendum while developing related legislationIn this example, boundary words and are able to decide that the translation of thePP phrase ... should be postponed until some phrase that succeeds it is translated.But they cannot provide further information about exactly which succeeding phraseshould be translated first.
If high-level linguistic knowledge, such as the syntacticcontext VP?PP VP, is given, the position of the PP phrase can be easily determinedsince the pre-verbal modifier PP in Chinese is frequently translated into a post-verbalcounterpart in English.In this article, we focus on linguistically motivated phrase reordering, which in-tegrates high-level linguistic knowledge in phrase reordering.
We adopt a two-stepstrategy.
In the first step, we establish a hierarchical skeleton in phrasal SMT by in-corporating Bracketing Transduction Grammar (BTG) (Wu 1997) into phrasal SMT.
Inthe second step, we inject soft linguistic information into nodes of the skeleton.There are two significant advantages to using BTG in phrasal SMT.
First, BTG is ableto generate hierarchical structures.2 This not only enhances phrasal SMT?s capabilityfor hierarchical and long-distance reordering but also establishes a platform for phrasalSMT to incorporate knowledge from linguistic structure.
Second, phrase reordering isrestricted by the ITG constraint (Wu 1997).
Although it only allows two orders (straightor inverted) of nodes in any binary branching structure, it is broadly verified that theITG constraint has good coverage of word reorderings on various language pairs (Wu,Carpuat, and Shen 2006).
This makes phrase reordering in phrasal SMT a more tractabletask.After enhancing phrasal SMT with a hard hierarchical skeleton, we further injectsoft linguistic information into the nodes of the skeleton.
We annotate each BTG node1 In this article, we use Penn Chinese Treebank phrase labels (Xue et al 2000).2 Chiang (2005) also generates hierarchical structures in phrasal SMT.
One difference is that Chiang?shierarchical grammar is lexicon-sensitive because the model requires at least one pair of aligned words ineach rule except for the ?glue rule.?
The other difference is that his grammar allows multiplenonterminals.
These two differences make Chiang?s grammar more expressive than the BTG but at thecost of learning a larger model.536Xiong et al Linguistically Annotated Reorderingwith syntactic and lexical elements by projecting the source parse tree onto the BTGbinary tree.
The challenge, of course, is that BTG hierarchical structures are not alwaysaligned with the linguistic structures in the source language parse tree.
To address thisissue, we propose an annotation algorithm.
The algorithm is able to label any BTGnodes during decoding with very little overhead, regardless of whether the BTG nodesare aligned with syntactic constituent nodes in the source parse tree.
The annotatedlinguistic elements are then used to guide phrase reordering under the ITG constraint.We call this two-step phrase reordering strategy linguistically annotated reorder-ing (LAR) (Xiong et al 2008a).
Xiong, Liu, and Lin (2006) also adapt a two-step reorder-ing strategy based on BTG.
However, they use boundary words as reordering featuresat the second step.
To distinguish this from our work, we call their approach boundaryword?based reordering (BWR).
LAR and BWR can be considered as two reorderingvariants for BTG-based phrasal SMT, which have similar training procedures.
Further-more, they can be combined.We evaluate LAR vs. BWR using the automatic metric BLEU (Papineni et al 2002).The BLEU scores show that LAR is comparable to BWR and significantly improvesphrase reordering when combined with BWR.We want to further study what happens when we combine BWR with LAR.
Inparticular, we want to investigate to what extent the integrated linguistic knowledge(from LAR) changes phrase movement in an actual SMT system, and in what directionthe change takes place.
The investigations will enable us to have a better understandingof the relationship between phrase movement and linguistic context, and therefore toexplore linguistic knowledge more effectively in phrasal SMT.Because syntactic constituents are often moved together across languages duringtranslation (Fox 2002), we particularly study how linguistic knowledge affects syntacticconstituent movement.
To that end, we introduce a syntax-based analysis method.
Weparse source sentences, and align the parse trees with reference translations as well assystem translations.
We then summarize syntactic reordering patterns using context-free grammar (CFG) rules from the obtained tree-to-string alignments.
The extractedreordering patterns clearly show the trace of syntactic constituent movement in bothreference translations and system translations.With the proposed analysis method, we analyze the combination of BWR and LARvs.
BWR alone.
There are essentially three issues that are addressed in this syntax-basedcomparative analysis.1.
The first issue concerns syntactic constituent movement in human/machine translations.
Fox (2002) investigates syntactic constituentmovement in human translations.
We study syntactic constituentmovement in both human translations and machine translations that aregenerated by an actual SMT system and compare them.2.
The second issue concerns the change of phrase movement after richlinguistic knowledge is integrated into phrase reordering.
To gain a betterinsight into this issue, we study phrase movement patterns for 13 specificsyntactic constituents.3.
The last issue concerns which constituents remain difficult to reorder eventhough rich linguistic knowledge is employed.The rest of the article is structured as follows.
Section 2 introduces backgroundinformation about BTG-based phrasal SMT and phrase reordering under the ITG537Computational Linguistics Volume 36, Number 3constraint.
Section 3 describes algorithms which extract training instances for reorder-ing models of BWR and LAR.
Section 4 introduces the BWR model as our baselinereordering model.
Section 5 describes LAR and the combination of LAR with BWR.Section 6 elaborates the syntax-based analysis method.
Section 7 reports our evaluationresults on large-scale data.
Section 8 demonstrates our analysis results and addresses thevarious issues discussed above.
Section 9 discusses related work.
And finally, Section 10summarizes our main conclusions.2.
Background2.1 BTG-Based Phrasal SMTWe establish a unified framework for BTG-based phrasal SMT in this section.
Thereare two kinds of rules in BTG, lexical rules (denoted as rl) and merging rules (denotedas rm):3rl : Ap ?
x/yrm : Ap ?
[Al, Ar]|?Al, Ar?
(1)A lexical rule translates a source phrase x into a target phrase y and generates a leafnode A in the BTG tree.
Merging rules combine left and right neighboring phrases Aland Ar into a larger phrase Ap in an order o ?
{straight, inverted}.
In this article, we use?[]?
to denote a straight order and ????
an inverted order.We define a BTG derivation D as a sequence of independent applications of lexicaland merging rules (D = ?rl1..nl , rm1..nm?).
Given a source sentence, the decoding task ofBTG-based SMT is to find a best derivation, which yields the best translation.4We assign a probability to each rule using a log-linear model with different featuresand corresponding weights ?, then multiply them to obtain P(D).
To keep in line withthe common understanding of standard phrasal SMT (Koehn, Och, and Marcu 2003),here we re-organize these features into a translation model (PT), a reordering model(PR), and a target language model (PL) as follows:P(D) = PT(rl1..nl) ?
PR(rm1..nm )?R ?
PL(e)?L ?
exp(|e|)?w (2)where exp(|e|) is the word penalty.The translation model is defined asPT(rl1..nl) =nl?i=1P(rli)P(rl) = p(x|y)?1 ?
p(y|x)?2 ?
plex(x|y)?3 ?
plex(y|x)?4 ?
exp(1)?5 (3)where p(?)
represents the phrase translation probabilities in both directions, plex(?)
de-notes the lexical translation probabilities in both directions, and exp(1) is the phrasepenalty.3 The subscripts l, r, p of A do not mean that we categorize A into three different nonterminals.
We use themto represent the left node, right node, and parent node.4 In this article, we use c to denote a source sentence and e a target sentence.538Xiong et al Linguistically Annotated ReorderingSimilarly, the reordering model is defined on the merging rules as follows:PR(rm1..nm ) =nm?i=1P(rmi ) (4)One of the most important and challenging tasks in building a BTG-based phrasal SMTsystem is to define P(rm).2.2 Reordering Under the ITG ConstraintUnder the ITG constraint, three nodes {Al, Ar, Ap} are involved when we consider theorder o between the two children {Al, Ar} in any binary subtrees.
Therefore it is naturalto define the ITG reordering P(rm) as a function as follows:P(rm) = f (Al, Ar, Ap, o) (5)where o ?
{straight, inverted}.Based on this function, various reordering models are built according to differentassumptions.
For example, the flat reordering model in the original BTG (Wu 1996)assigns prior probabilities for the straight and inverted order assuming the order ishighly related to the properties of language pairs.
It is formulated asP(rm) ={ps, o = straight1 ?
ps, o = inverted(6)Supposing French and English are the source and target language, respectively, thevalue of ps can be set as high as 0.8 to prefer monotone orientations because the twolanguages have similar word orders in most cases.The main problem of the flat reordering model is also the problem of the standarddistortion model (Koehn, Och, and Marcu 2003): Neither model considers linguisticcontexts.
To be context-dependent, the ITG reordering might directly model the condi-tional probability P(o|Al, Ar).
This probability could be calculated using the maximumlikelihood estimate (MLE) by taking counts from training data, in the manner of thelexicalized reordering model (Tillman 2004; Koehn et al 2005):P(o|Al, Ar) =Count(o, Al, Ar)Count(Al, Ar)(7)Unfortunately this lexicalized reordering method usually leads to a serious data sparse-ness problem under the ITG constraint because Al and Ar become larger and larger dueto the merging rules, and are finally unseen in the training data.To avoid the data sparseness problem yet be contextually informative, attributesof Al and Ar, instead of nodes themselves, are used as reordering evidence in a newperspective of the ITG reordering (Xiong, Liu, and Lin 2006).
The new perspective treatsthe ITG reordering as a binary-classification problem where the possible order straightor inverted between two children nodes is the target class which the reordering modelpredicts given Al, Ar, and Ap.539Computational Linguistics Volume 36, Number 33.
Reordering Example ExtractionBecause we consider the ITG reordering as a classification problem, we need to obtaintraining instances to build a classifier.
Here we refer to a training instance as a reorder-ing example, which is formally defined as a triple of (o, bl, br) where bl and br are twoneighboring blocks and o ?
{straight, inverted} is the order between them.The block is a pair of aligned source phrase and target phraseb = (ci2i1 , ej2j1) (8)where b must be consistent with the word alignment M?
(i, j) ?
M, i1 ?
i ?
i2 ?
j1 ?
j ?
j2 (9)By this, we require that no words inside the source phrase ci2i1 are aligned to wordsoutside the target phrase ej2j1 and that no words outside the source phrase are aligned towords inside the target phrase.
This definition is similar to that of the bilingual phraseexcept that there is no length limitation over blocks.
Figure 1 shows a word alignmentmatrix between a Chinese sentence and English sentence.
In the matrix, each block canbe represented as a rectangle, for example, blocks (c44, e44), (c54, e54), (c74, e94) in red rectangles,and (c32, e33), (c31, e31) in blue rectangles.In this section, we discuss two algorithms for extracting reordering examples fromword-aligned bilingual data.
The first algorithm AExtractor (described in Section 3.1)extracts reordering examples directly from word alignments by extending the bilin-gual phrase extraction algorithm.
The second algorithm TExtractor (described in Sec-tion 3.2) extracts reordering examples from BTG-style trees which are built from wordalignments.Figure 1A word alignment matrix between a Chinese sentence and English sentence.
Bold dots representjunctions which connect two neighboring blocks.
Red and blue rectangles are blocks which areconnected by junction J2.540Xiong et al Linguistically Annotated Reordering3.1 AExtractor: Extracting Reordering Examples from Word AlignmentsBefore we describe this algorithm, we introduce the concept of junction in the wordalignment matrix.
We define a junction as a vertex shared by two neighboring blocks.There are two types of junctions: a straight junction, which connects two neighboringblocks in a straight order (e.g., black dots J1 ?
J4 in Figure 1) and an inverted junction,which connects two neighboring blocks in an inverted order (e.g., the red dot J5 inFigure 1).The algorithm for AExtractor is shown in Figure 2.
This completes three sub-tasksas follows.1.
Find blocks (lines 4 and 5).
This is similar to the standard phrase extractionalgorithm (Och 2002) except that we find blocks with arbitrary length.2.
Detect junctions and store blocks in the arrays of detected junctions (lines 7and 8).
Junctions that are included the current block can be easily detectedby looking at the previous and next blocks.
A junction can connectmultiple blocks on its left and right sides.
For example, the secondjunction J2 in Figure 1 connects two blocks on the left side and three blockson the right side.
To store these blocks, we maintain two arrays (left andright) for each junction.3.
Select block pairs from each detected junction as reordering examples(lines 12?16).
This is the most challenging task for AExtractor.
Because ajunction may have n blocks on its left side and m blocks on its right side,we will obtain nm reordering examples if we enumerate all block pairs.This will quickly increase the number of reordering examples, especiallyFigure 2AExtractor.541Computational Linguistics Volume 36, Number 3those with the straight order.
To keep the number of reordering examplestractable, we define various selection rules r to heuristically select specialblock pairs as reordering examples.We define four selection rules as follows.1.
strINV: We select the smallest blocks (in terms of the target length) forstraight junctions, and the largest blocks for inverted junctions.
Take thestraight junction J2 in Figure 1 as an example, the extracted reorderingexample is (straight, | five,| flights).2.
STRinv: We select the largest blocks (in terms of the target length) forstraight junctions, and the smallest blocks for inverted junctions.
Stilltaking the straight junction J2 as an example, this time the extractedreordering example is (straight, | The last five,|flights all fail due to accidents).3.
RANDOM: For any junction, we randomly select one block pair from itsarrays.4.
COMBO: For each junction, we first select two block pairs using selectionrule strINV and STRinv.
If there are unselected blocks, we randomly selectone block pair from the remaining blocks.3.2 TExtractor: Extracting Reordering Examples from BTG-Style TreesA potential problem for AExtractor is caused by the use of heuristic selection rules:keeping some block pairs as reordering examples while abandoning other block pairs.The kept block pairs are not necessarily the best training instances for tuning an ITGorder predictor.
To avoid this problem we can extract reordering examples from theBTG trees of sentence pairs.
Reordering examples extracted in this way are naturallysuitable for BTG order prediction.There are various ways to build BTG trees over sentence pairs.
One can use BTG toproduce bilingual parses of sentence pairs, similar to the approaches proposed by Wu(1997) and Zhang and Gildea (2005) but using the more sophisticated reordering modelsBWR or LAR.
After parsing, reordering examples can be extracted from bilingual parsetrees and a better reordering model is therefore induced from the extracted reorderingexamples.
Using the better reordering model, the bilingual sentences are parsed again.This procedure is run iteratively until no performance gain is obtained in terms oftranslation or parsing accuracy.
Formally, we can use expectation-maximization (EM)training in this procedure.
In the expectation step, we first estimate the likelihood of allBTG trees of sentence pairs with the current BTG model.
Then we extract reorderingexamples and collect counts for them, weighted with the probability of the BTG treewhere they occur.
In the maximization step, we can train a more accurate reorderingmodel with updated reordering examples.
Unfortunately, this method is at high com-putational cost.Instead, here we adopt a less expensive alternative method to produce BTG treesover sentence pairs.
Supposing we have word alignments produced by GIZA++, wethen use the shift-reduce algorithm (SRA) introduced by Zhang, Gildea, and Chiang(2008) to decompose word alignments into hierarchical trees.
The SRA can guaranteethat each node is a bilingual phrase in the decomposition tree.
If the fan-out of a nodeis larger than two, we binarize it from left to right: for two neighboring child nodes, if542Xiong et al Linguistically Annotated Reorderingthey are also neighboring on both the source and target sides, we combine them andcreate a new node to dominate them.
In this way, we can transform the decompositiontree into a BTG-style tree.
Note that not all multi-branching nodes can be binarized.
Weextract reordering examples only from binary nodes.Figure 3 shows the BTG-style tree which is built from the word alignment in Figure 1according to the method mentioned here.
From this tree, we can easily extract four re-ordering examples in a straight order and one reordering example in an inverted order.4.
Boundary Word-Based ReorderingFollowing the binary-classification perspective of the ITG reordering, Xiong, Liu, andLin (2006) propose a reordering model which exploits the maximum entropy (MaxEnt)classifier for BTG order predictionPRb (rm) = P?
(o|Al, Ar, Ap) =exp(?i ?ihi(o, Al, Ar, Ap))?o?
exp(?i ?ihi(o?, Al, Ar, Ap))(10)where the functions hi ?
{0, 1} are reordering features and the ?i are the weights of thesefeatures.Xiong, Liu, and Lin (2006) define reordering features using the boundary words ofthe source/target sides of both children {Al, Ar}.
Supposing that we have a reorderingexample (inverted, 7 15 | on July 15, | held its presidential andparliament elections), leftmost/rightmost source words {, 15,,} and targetwords {on, 15, held, elections} will be extracted as boundary words.
Each boundary wordwill form a reordering feature as followshi(o, Al, Ar, Ap) ={1, fn = bval, o = inverted0, otherwisewhere fn denotes the feature name, and bval is the corresponding boundary word.There are two reasons why boundary words are used as important clues forreordering:1.
Phrases frequently cohere across languages (Fox 2002).
In cohesive phrasemovement, boundary words directly interact with the external contexts ofFigure 3The BTG-style tree built from the word alignment in Figure 1.
We use ([i, j], [p, q]) to denote a treenode, where i, j and p, q are the beginning and ending indices in the source and target language,respectively.543Computational Linguistics Volume 36, Number 3phrases.
This suggests that boundary words might contain information forphrase reordering.2.
The quantitative analysis in Xiong, Liu, and Lin (2006, page 525) furthershows that boundary words indeed contain information for orderprediction.To train a BWR model, we follow three steps.
First, we extract reordering examplesfrom word-aligned bilingual data as described in the last section, then generate reorder-ing features using boundary words from the reordering examples, and finally estimatefeature weights.5.
Linguistically Annotated ReorderingIn order to employ more linguistic knowledge in the ITG reordering, we annotate eachBTG node involved in reordering using linguistic elements from the source-side parsetrees.
The linguistic elements include: (1) the head word hw, (2) the part-of-speech (POS)tag ht of the head word, and (3) its syntactic category sc.
In this section, we describe theannotation algorithm and the LAR model, as well as the combination of LAR and BWR.5.1 Annotation AlgorithmThere are two steps to annotating a BTG node using source-side parse tree information:(1) determining the sequence on the source side which is exactly covered by the node,then (2) annotating the sequence according to the source-side parse tree.
If the sequenceis exactly covered by a single subtree in the source-side parse tree, it is called a syntacticsequence, otherwise it is a non-syntactic sequence.
One of the challenges in this an-notation is that phrases (BTG nodes) do not always cover syntactic sequences; in otherwords, they are not always aligned to constituent nodes in the source-side tree.
To solvethis problem, we generate a pseudo head word and composite category which consistsof the syntactic categories of three relevant constituents for the non-syntactic sequences.In this way, our annotation is capable of labelling both syntactic and non-syntacticphrases and therefore providing linguistic information for any phrase reordering.The annotation algorithm is shown in Figure 4.
For a syntactic sequence, the an-notation is trivial.
Annotation elements directly come from the subtree that covers thesequence exactly.
For a non-syntactic sequence, the process is more complicated.
Firstly,we need to locate the smallest subtree c?
covering the sequence (line 6).
Secondly, wetry to identify the head word/tag of the sequence (lines 7?12) by using its head worddirectly if it is within the sequence.
Otherwise, the word within the sequence which isnearest to hw will be assigned as the head word of the sequence.
Finally, we determinethe composite category of the sequence (lines 13?15), which is formulated as L-C-R.L/R refers to the syntactic category of the left/right boundary node of s, which is thehighest leftmost/rightmost sub-node of c?
not overlapping the sequence.
If there is nosuch boundary node (the sequence s is exactly aligned to the left/right boundary of c?
),L/R will be set to NULL.
C is the syntactic category of c?.
L, R, and C together describethe external syntactic context of s. The composite category we define for non-syntacticphrases is similar to the CCG-style category in Zollmann, Venugopal, and Vogel (2008).Figure 5 shows a syntactic parse tree for a Chinese sentence, with the head wordannotated for each internal node.
Some sample annotations are given in Table 1.544Xiong et al Linguistically Annotated ReorderingFigure 4The Annotation Algorithm.Figure 5A syntactic parse tree with the head word annotated for each internal node.
The superscripts onleaf nodes denote their surface positions from left to right.5.2 Reordering ModelThe linguistically annotated reordering model PRa is a MaxEnt-based classificationmodel, which can be formulated asPRa (rm) = p?
(o|Aapp , Aall , Aarr ) =exp(?i ?ihi(o, Aapp , Aall , Aarr ))?o?
exp(?i ?ihi(o?, Aapp , Aall , Aarr ))(11)where the feature functions hi ?
{0, 1} are defined using annotated linguistic elementsof each BTG node.
Here we use the superscripts al, ar, and ap to stress that the BTG nodesare linguistically annotated.545Computational Linguistics Volume 36, Number 3Table 1Annotation samples according to the tree shown in Figure 5.sequence hw ht sc?1, 2?
 NN NULL-NP-NN?2, 3?
 NN NP?2, 4?
 VV NP-IP-NP?3, 4?
 VV NP-IP-NPhw/ht = the head word/tag, respectively; sc = syntactic category.Each merging rule involves three nodes (Aapp , Aall , Aarr ) and each node has threelinguistic elements (hw, ht, sc).
Therefore, the model has nine features in total.
Takingthe left node Aall as an example, the model could use its head word w as a feature asfollows:hi(o, Aapp , Aall , Aarr ) ={1, Aall .hw = w, o = straight0, otherwiseTraining an LAR model also takes three steps.
Firstly, we extract annotated reorder-ing examples from source-side parsed, word-aligned bilingual data using the reorderingexample extraction algorithm and the annotation algorithm.
We then generate featuresusing the linguistic elements of these examples.
Finally we tune feature weights to buildthe MaxEnt model.5.3 Combining LAR and BWRLAR and BWR can be combined at two different levels:1.
Feature level.
Because both LAR and BWR are trained under themaximum entropy principle, we can combine linguistically annotatedfeatures from LAR and boundary word features from BWR together andtrain a single MaxEnt model.
We call this method All-in-One combination.2.
Model level.
We can also train two reordering models separately andintegrate them into BTG-based SMTP(D) = PT(rl1..nl ) ?PRb (rm1..nm )?Rb ?PRa (rm1..nm )?Ra ?PL(e)?L ?
exp(|e|)?w (12)where PRb is the BWR reordering model and PRa is the LAR reorderingmodel.
We call this combination BWR+LAR.We will empirically compare these two combination methods in Section 7.4.6.
A New Syntax-Based Reordering Analysis MethodIn order to understand the influence of linguistic knowledge on phrase reordering, wepropose a syntax-based method to analyze phrase reordering.
In this analysis method,546Xiong et al Linguistically Annotated Reorderingwe leverage the alignments between source-side parse trees and reference/systemtranslations to summarize syntactic reordering patterns and calculate syntax-basedmeasures of precision and recall for each syntactic constituent.6.1 OverviewThe alignment between a source parse tree and a target string is a collection of rela-tionships between parse tree nodes and their corresponding target spans.5 A syntacticreordering pattern (SRP) is defined as??
?
?1...?n ?
[i1]...[in]?The first part of an SRP is a CFG structure on the source side and the second part[i1]...[in] indicates the order of target spans ?T1 ...?Tn of nonterminals ?1...?n on the targetside.6Let?s take the VP structure VP ?
PP1VP2 as an example to explain how the pre-cision and recall can be obtained.
On the target side, the order of PPT1 and VPT2might be [1][2] or [2][1].
Therefore we have two syntactic reordering patterns for thisstructure:?VP ?
PP1VP2 ?
[1][2]?
and ?VP ?
PP1VP2 ?
[2][1]?Suppose that the two reordering patterns occur a times in the alignments betweensource parse trees and reference translations, b times in the alignments between sourceparse trees and system translations, and c times in both alignments.
Then the reorderingprecision/recall for this structure is c/b and c/a, respectively.
We can further calculatethe F1-score as 2 ?
c/(a + b).
These syntax-based metrics intuitively show how well thereordering model can reorder this structure.
By summarizing all reordering patterns ofall constituents, we can obtain an overall precision, recall, and F1-score for the testedreordering model.This new syntax-based analysis for reordering is motivated in part by recent workwhich transforms the order of nodes in the source-side parse tree before translation(Xia and McCord 2004; Collins, Koehn, and Kucerova 2005; Li et al 2007; Wang,Collins, and Koehn 2007).
Here we focus on the order transformation of syntactic con-stituents performed by reordering models during translation.
In addition to aligningparse trees with reference translations, we also align parse trees with system transla-tions so that we can learn the movement of syntactic constituents carried out by thereordering models and investigate the performance of the reordering models by com-paring both alignments.For notational convenience, we denote syntactic reordering patterns that are ex-tracted from the alignments between source parse trees and reference translations asREF-SRP and those from the alignments between source parse trees and system trans-lations as SYS-SRP.
We refer to those present in both alignments under some conditions5 We adopt the definition of span from Fox (2002): Given a node n that covers a word sequence sp...si...sqand a word alignment matrix M, the target words aligned to n are {ti : ti ?
M(si )}.
We define the targetspan of node n as nT = (min({ti}), max({ti})).
Note that nT may contain words that are not in {ti}.6 Please note that the order of structures may not be defined in some cases (see Section 6.3).547Computational Linguistics Volume 36, Number 3that will be described in Section 6.4 as MATCH-SRP.
To conduct a thorough analysis onthe reorderings, we carry out the following steps on the test corpus (source sentences +reference translations):1.
Parse source sentences.2.
Generate word alignments between source sentences and referencetranslations as well as word alignments between source sentences andsystem translations.3.
According to the word alignments of Step 2, for each multi-branchingnode ?
?
?1...?n in the source parse tree generated in Step 1, find thetarget spans ?T1 ...?Tn and their order [i1]...[in] in the reference and systemtranslations, respectively.4.
Generate REF-SRPs, SYS-SRPs, and MATCH-SRPs according to the targetorders generated in Step 3 for each multi-branching node.5.
Summarize all SRPs and calculate the precision and recall as describedabove.We further elaborate Steps 2?4 in the Sections 6.2?6.4.6.2 Generating Word AlignmentsTo obtain word alignments between source sentences and multiple reference transla-tions, we pair the source sentences with each of the reference translations and includethe created sentence pairs in our bilingual training corpus.
Then we run GIZA++ on thenew corpus in both directions, and apply the ?grow-diag-final?
refinement rule (Koehnet al 2005) to produce the final word alignments.To obtain word alignments between source sentences and system translations, westore the word alignments within each phrase pair in our phrase table.
When we outputthe system translation for a source sentence, we trace back the original source phrasefor each target phrase in the system translation.
This will generate a phrase alignmentbetween the source sentence and system translation.
Given the phrase alignment andword alignments within the phrase stored in the phrase table, we can easily obtain wordalignments between the whole source sentence and system translation.6.3 Generating Target Spans and OrdersGiven the source parse tree and the word alignment between a source sentence anda reference/system translation, for each multi-branching node ?
?
?1...?n, we firstlydetermine the target span ?Ti for each child node ?i following Fox (2002).
If one childnode is aligned to NULL, we define a special target span for it.
The order for this specialtarget span will remain the same as the child node occurring in ?1...?n.Two target spans may overlap with each other because of inherent divergencesbetween two languages or noise in the word alignment.
When this happens on twoneighboring nodes ?i and ?i+1, we combine these two nodes together and redefine atarget span ?Ti&i+1 for the combined node.
This process will be repeated until no moreneighboring nodes can be combined.
For example, the target span of nodes a and b in548Xiong et al Linguistically Annotated ReorderingFigure 6An example source parse tree with the word alignment between the source sentence and thetarget translation.
Dotted lines show the word alignment.Figure 6 overlap ((1, 3) vs. (2, 2)).
Therefore these two nodes are to be combined into anew node, whose target span is (1, 3).After performing all necessary node combinations, if there are no more overlaps, wecall the multi-branching node reorderable, otherwise non-reorderable.
To get a clearerpicture of the reorderable nodes, we divided them into two categories: fully reorderable if all target spans of child nodes don?t overlap; partially reorderable if some child nodes are combined due tooverlapping.In Figure 6, both nodes a and c are fully reorderable nodes.7 Node d is a partiallyreorderable node.
Node g is a non-reorderable node because (1) the target spans of itschild nodes d and f overlap, and (2) child nodes d and f cannot be combined becausethey are not neighbors.Because we have multiple reference translations for each source sentence, we candefine multiple orders for {?Ti }n1.
If one node is non-reorderable in all reference trans-lations, we call it REF-non-reorderable, otherwise REF-reorderable.
To specify thereorderable attribute of a node in the system translation, we prefix ?SYS-?
to {non-reorderable, reorderable, fully-reorderable, partially-reorderable}.6.4 Generating SRPsAfter we obtain the orders of the child nodes for each multi-branching node, we gener-ate REF-SRPs and SYS-SRPs from the fully/partially reorderable nodes.
We obtain the7 Their target translations are interrupted by the other node?s translation.
We will discuss this situation inSection 8.5.549Computational Linguistics Volume 36, Number 3MATCH-SRP for each multi-branching node by comparing the obtained SYS-SRP withthe REF-SRPs for this node under the following conditions:1.
Because we have multiple reference translations, we may have differentREF-SRPs.
We compare the SYS-SRP with the REF-SRP where thereference translation for this node (the sequence within the target span ofthe node defined by the REF-SRP) has the shortest Levenshtein distance(Navarro 2001) to that of the system translation.2.
If there are combined nodes in SYS/REF-SRPs, they are treated as a unitwhen comparing, without considering the order within each combinednode.
If the order of the SYS-SRP and the selected REF-SRP matches, wehave one MATCH-SRP for the node.Let?s give an example to explain these conditions.
Suppose that we are processingthe structure VP ?
PP1ADVP2VP3.
We obtain four REF-SRPs from four different ref-erence translations and one SYS-SRP from the system output.
Here we only show theorders:Ref.a : [3][1][2]Ref.b : [3][2][1]Ref.c&d : [2][3][1]SYS : [3][1&2]References c and d have the same order.
Therefore we have three different REF-SRPsfor this structure.
In the SYS-SRP, PP1 and ADVP2 are combined and moved to the rightside of VP3.
Supposing that the system translation for this structure has the shortest editdistance to that of Reference b, we use the order of Reference b to compare the systemorder.
In the Reference b order, both PP1 and ADVP2 are also moved to the right side ofVP3.
Therefore the two orders of Reference b and SYS match.
We have one matched SRPfor this structure.7.
EvaluationOur system is a BTG-based phrasal SMT system, developed following Section 2.
Weintegrate the boundary word?based reordering model and the linguistically annotatedreordering model into our system according to our reordering configuration.
We car-ried out various experiments to evaluate the reordering example extraction algorithmsof Section 3, the linguistically annotated reordering model vs. boundary word?basedreordering model, and the effects of linguistically annotated features on the Chinese-to-English translation task of the NIST MT-05 using large scale training data.7.1 Experimental SetupWe ran GIZA++ (Och and Ney 2000) on the parallel corpora (consisting of 101.93MChinese words and 112.78M English words) listed in Table 2 in both directions andthen applied the ?grow-diag-final?
refinement rule (Koehn, Och, and Marcu 2003) to550Xiong et al Linguistically Annotated ReorderingTable 2Corpora used.Corpus LDC catalog Chinese words English wordsUnited Nations LDC2004E12 68.63M 76.99MHong Kong News LDC2004T08 15.07M 15.89MSinorama Magazine LDC2005T10 10.26M 9.64MFBIS LDC2003E14 7.09M 9.28MXinhua LDC2002E18 0.40M 0.43MChinese News Translation LDC2005T06 0.28M 0.31MChinese Treebank LDC2003E07 0.10M 0.13MMultiple Translation Chinese LDC2004T07 0.10M 0.11MTotal ??
101.93M 112.78Mobtain many-to-many word alignments.
From the word-aligned corpora, we extractedbilingual phrases.We used all corpora listed in Table 2 except for the United Nations corpus to trainour reordering models, which consist of 33.3M Chinese words and 35.79M Englishwords.
We ran the reordering example extractor AExtractor and TExtractor of Section 3on the chosen word-aligned corpora.
We then extracted boundary word features fromthe reordering examples.
To extract linguistically annotated features, we parsed theChinese side of the chosen parallel text using a Chinese parser (Xiong, Liu, and Lin2005) which was trained on the Penn Chinese Treebank with an F1-score of 79.4%.
Weran the off-the-shelf MaxEnt toolkit8 to tune the reordering feature weights with theiteration number set to 100 and Gaussian prior to 1 to avoid overfitting.We built our 4-gram language model using the SRILM toolkit (Stolcke 2002), whichwas trained on the Xinhua section of the English Gigaword corpus (181.1M words).We selected 580 short sentences (not exceeding 50 characters per sentence) from theNIST MT-02 evaluation test data as our development set (18 words/31 characters persentence).
The NIST MT-05 test set includes 1,082 sentences with an average of 27.4words/47.6 characters per sentence.
The reference corpus for the NIST MT-05 test setcontains four translations per source sentence.
Both the development and test sets werealso parsed using the parser mentioned above.Our evaluation metric is the case-insensitive BLEU-4 (Papineni et al 2002) using theshortest reference sentence length for the brevity penalty.
The model feature weights aretuned on the development set to maximize BLEU using MERT (Och 2003).
Statisticalsignificance in BLEU score differences is tested by paired bootstrap re-sampling (Koehn2004).7.2 Bias in AExtractorAs described in Section 3, AExtractor selectively extracts reordering examples.
Thisselective extraction raises three questions:1.
Is it necessary to extract all reordering examples?8 Available at: http://homepages.inf.ed.ac.uk/s0450736/maxent toolkit.html.551Computational Linguistics Volume 36, Number 32.
If it is not necessary, do the heuristic selection rules impose any bias onthe reordering model?
For example, if we use the strINV selection rule,meaning that we always extract the largest block pairs for invertedreordering examples, does the reordering model prefer swappings onlarger blocks to those on smaller blocks?3.
Does the bias have a strong impact on the performance in terms of BLEUscore?The answer to the first question is no.
Firstly, it is practically undesirable to extractall reordering examples because even a very small training set will produce millions ofreordering examples if we enumerate all block pair combinations.
Secondly, extractingall reordering examples introduces a great amount of noise into training and thereforeundermines the final reordering model.
In Table 3, we show the number of reorder-ing examples extracted using different extraction algorithms and selection rules.
TheAExtractor with the COMBO selection rule extracts the largest number of reorderingexamples.
However, it does not obtain the highest BLEU score compared with otherselection rules which extract a smaller number of reordering examples.
This empiricallysuggests that there is no need to extract all reordering examples.To answer the second question, we trace the best BTG trees produced on the test setby our system.
The BWR reordering model is trained on reordering examples which areextracted using different selection rules.
Then we calculate the average number of wordson the target side which are covered by binary nodes in a straight order.
We refer to thisnumber as straight average length.
Similarly, inverted average length is calculated onall binary nodes in an inverted order.
The third and fourth columns of Table 3 show thetwo average variables.
Comparing these average numbers, we clearly observe that twoselection rules indeed impose noticeable bias on the reordering model. The strINV selection rule, which always extracts the largest block pairs forinverted reordering examples, has the largest inverted average length.This indicates that the strINV rule biases the reordering model towardslarger swappings. On the contrary, the STRinv selection rule, which extracts the largest blockpairs for straight reordering examples and smallest pairs for invertedreordering examples, has the largest straight average length and aTable 3Comparison of reordering example extraction algorithms and selection rules.
We only use BWRas the reordering model for this comparison.Ext.
Alg.
Reordering Straight Inverted BLEU(Sel.
rule) Examples Avg.
Len.
Avg.
Len.AExtractor (strINV) 10.06M 15.8 14.5 32.37AExtractor (STRinv) 10.06M 17.3 12.8 32.47AExtractor (RANDOM) 10.06M 14.7 11.8 32.24AExtractor (COMBO) 23.27M 13.8 13.5 32.10TExtractor 14.30M 15.0 14.1 29.95552Xiong et al Linguistically Annotated Reorderingrelatively much smaller inverted average length.
This suggests that theSTRinv rule makes the reordering model prefer smaller swappings.Note that the selection rules RANDOM and COMBO do not impose bias on the lengthof extracted reordering examples compared with strINV and STRinv.
The latter two se-lection rules have special preferences on the length of reordering examples and transferthese preferences to the reordering models as shown in Table 3.Because the preference for reordering larger/smaller blocks is imposed by thereordering example extraction algorithm with special selection rules, one might wonderwhether we can allow the decoder to decide its own reordering preference.
We add twonew features to our translation model: reordering count penalty (rc) and reorderinglength penalty (rl).
We accumulate rc whenever two neighboring BTG nodes are re-ordered.
And at the same time we add the number of words which are covered by thesetwo neighboring nodes to rl.
Their weights are tuned using MERT to maximize BLEUscore on the development set with other model feature weights.
These two featuresare similar to the widely used word/phrase penalty features.
Tuning the weights ofthe word/phrase penalty features, we can allow the decoder to favor shorter or longerphrases.
Similarly, with the two new features rc and rl, we can allow the decoder tofavor shorter or longer reorderings.We conducted experiments using reordering examples which are extracted with theRANDOM and COMBO selection rules because these two rules do not impose bias onthe length of reordering examples.
Observing the optimized weights of rc and rl onthe development set, we find that the decoder rewards larger rc but smaller rl.
Thismeans that the decoder prefers shorter reorderings to longer reorderings.
However, theBLEU scores on the test set are 31.89 and 32.0 for RANDOM and COMBO, respectively,which are worse than the BLEU scores of RANDOM and COMBO without using rcand rl in Table 3, and also worse than the performance of strINV and STRinv whichimpose preferences on reordering examples.
This seems to suggest that the preferencefor shorter/longer reorderings imposed by the reordering example extraction algorithmis better than that decided by the decoder itself.Finally, for the last question, we observe from Table 3 that BLEU scores are not thatmuch different although we have quite the opposite bias imposed by different selectionrules.
The changes in BLEU score, which happen when we shift from one selection ruleto the other, are limited to a maximum of 1.2%.
Among the four selection rules, theSTRinv rule achieves the highest BLEU score.
The reason might be that the bias towardssmaller swappings imposed by this rule helps the decoder to reduce incorrect long-distance swappings (Xiong et al 2008b).7.3 AExtractor vs. TExtractorWe further compared the two algorithms for reordering example extraction.
In Table 3,we find that TExtractor significantly underperforms in comparison to AExtractor.
Thisis because the transformation from decomposition trees to BTG trees is not complete.Many crossing links due to errors and noise in word alignments generated by GIZA++make it impossible to build BTG nodes over the corresponding words.
It would be betterto use alignments induced by the ITG and EM procedure described in Section 3.2 butthis has a very high cost.Given the comparison in Table 3, we use AExtractor with the STRinv selection ruleto extract reordering examples for both BWR and LAR in all experiments describedbelow.553Computational Linguistics Volume 36, Number 37.4 LAR vs. BWRTable 4 shows the results of the different integration of BWR and LAR into our systems.Only using LAR achieves a BLEU score of 32.17, which is comparable to that of BWR.This suggests that LAR is promising given that: LAR uses many fewer features than BWR does.
According to our statistics,LAR contains only 166.1k linguistically annotated features whereas BWRhas 451.4k boundary word features. Syntactic divergences between the source and target languages as well asparse errors prevent the effective use of syntactic knowledge for phrasereordering (see the in-depth analysis in Section 8.2.2).Although BWR marginally outperforms LAR (32.47 vs. 32.17), simple boundaryword features are not adequate to move phrases to appropriate positions becausethey cannot recognize syntactic contexts which are very relevant to phrase reordering.Therefore the best way to reorder a phrase is to combine BWR and LAR so that wecan use syntactic information on the one hand and not worry too much about syntacticdivergences on the other hand.As described in Section 5.3, we can combine BWR and LAR at two levels: the featurelevel and the model level.
When we combine them at the model level, we achieve anabsolute improvement of 0.83 and 1.13 BLEU points over BWR and LAR, respectively,which are both statistically significant (p < 0.01).
This shows that LAR and BWR arecomplementary to each other and in particular that using linguistic knowledge cansignificantly improve a very competitive lexicalized reordering model (BWR).The other combination method All-in-One (at the feature level) also obtains signif-icant improvements over BWR and LAR but marginally underperforms compared toBWR+LAR.
In our later experiments we use the combination method BWR+LAR.7.5 Varying Training Data SizeTo investigate how LAR improves BWR when we vary our training data size, we carriedout experiments on three different training data sets: FBIS (7.09M Chinese words, 9.28MEnglish words); Large1, which includes all corpora listed in Table 2 except for the UnitedNations corpus (33.3M Chinese words, 35.79M English words); and Large2, whichTable 4BLEU scores for LAR, BWR, and their combinations.Reordering Configuration BLEUBWR 32.47LAR 32.17All-in-One 33.03**++BWR+LAR 33.30**++** = Significantly better than BWR (p < 0.01); ++ = significantly better than LAR (p < 0.01).554Xiong et al Linguistically Annotated ReorderingTable 5BLEU scores on different training data sets.
Large1 refers to the corpora listed in Table 2 exceptfor the United Nations corpus.
Large2 includes all corpora listed in Table 2.Training Data BWR BWR+LAR ImprovementFBIS 24.97 26.52 1.55Large1 29.96 30.78 0.82Large2 32.47 33.30 0.83consists of Large1 and the United Nations corpus (101.93M Chinese words, 112.78English words).
The language model remains the same for these three data sets becauseit is trained on a much larger data set (181.1M words).Table 5 shows the results.
We observe that BWR+LAR is able to achieve a largerimprovement of 1.55 BLEU points over BWR on smaller training data.
When we enlargethe training data set from FBIS to Large1, both BWR and BWR+LAR improve quite abit.
The difference between them is narrower, 0.82 BLEU points, but still significant.When we continue to use more training data (Large2), the improvement obtained byintegrating LAR becomes stable at the 0.8 level.7.6 Effects of Linguistically Annotated FeaturesWe conducted further experiments to evaluate the effects of individual linguistically an-notated features.
Using the reordering configuration of BWR+LAR, we augment LAR?sfeature pool incrementally: firstly using only syntactic categories9(sc) as features (170features in total), then constructing composite categories (cc) for non-syntactic phrases(sc + cc) (8.6K features), and finally introducing head words and their POS tags intothe feature pool (sc + cc + hw + ht) (166.1K features).
This series of experiments demon-strates the impact and degree of contribution made by each feature for reordering.The experimental results are presented in Table 6, from which we have the followingobservations:1.
Syntactic category alone improves the performance statisticallysignificantly.
The baseline feature set sc with only 170 features improvesthe BLEU score from 32.47 to 32.87.2.
Other linguistic information, provided by the categories of boundarynodes (cc) and head word/tag pairs (hw + ht), also improves phrasereordering.
Producing composite categories for non-syntactic BTG nodesand integrating head word/tag pairs into LAR as reordering features areboth effective, indicating that context information complements syntacticcategory for capturing reordering patterns.9 For a non-syntactic node, we only use the single category C, without constructing the composite categoryL-C-R.555Computational Linguistics Volume 36, Number 3Table 6The effect of the linguistically annotated reordering model.
(sc) is the baseline feature set,(sc + cc) and (sc + cc + hw + ht) are extended feature sets for LAR.Reordering Configuration BLEUBWR 32.47BWR + LAR (sc) 32.87*BWR + LAR (sc + cc) 33.06**BWR + LAR (sc + cc + hw + ht) 33.30**++* = almost significantly better than BWR (p < 0.075); ** = significantly better than BWR (p < 0.01); ++ =significantly better than BWR + LAR (sc) (p < 0.01).8.
AnalysisWe first obtain system translations of the test corpus.
We generate word alignmentsbetween source sentences and system/reference translations as described in Section 6.2.Then we follow the analysis steps of Section 6.1 to investigate syntactic constituentmovement in the reference translations and system translations which are generatedusing two different reordering configurations: BWR+LAR vs. BWR.
In LAR, we use thebest reordering feature set (sc + cc + hw + ht).8.1 Syntactic Constituent Movement: OverviewIf a syntactic constituent is fully reorderable or partially reorderable, it is considered tobe movable as a unit.
To denote the proportion of syntactic constituents to be moved asa unit, we introduce two variables REF-R-rate and SYS-R-rate, which are defined asSYS-R-rate =count(SYS-reorderable nodes)count(multi-branching nodes)(13)REF-R-rate =count(REF-reorderable nodes)count(multi-branching nodes)(14)Table 7 shows the statistics of REF/SYS-reorderable nodes on the test corpus.
Fromthis table, we have the following observations:1.
A large number of nodes are REF-reorderable, accounting for 79.82% of allthe multi-branching nodes.
This number shows that, in referencetranslations, a majority of syntactic constituent movement acrossChinese?English can be performed by directly permuting constituents in asub-tree.2.
The R-rates of BWR and BWR+LAR are 77.46% and 81.79%, respectively.The R-rate of BWR+LAR is obviously higher than that of BWR, whichsuggests that BWR+LAR tends towards moving more syntacticconstituents together than BWR does.
We will discuss this further later.556Xiong et al Linguistically Annotated ReorderingTable 7Statistics of multi-branching and REF/SYS-reorderable nodes per sentence.BWR BWR+LARmulti-branching node 18.68REF-reorderable node 14.91REF-R-rate 79.82%SYS-fully-reorderable node 13.16 14.01SYS-partially-reorderable node 1.31 1.26SYS-R-rate 77.46% 81.79%8.2 Syntactic Constituent Movement among Multiple Reference Translations8.2.1 Differences in Movement Orientation.
Because each source sentence is translated byfour different human experts, we would like to analyze the differences among referencetranslations, especially on the orders of constituents being translated.
Table 8 showsthe overall distribution over the number of different orders for each multi-branchingconstituent among the reference translations.In most cases (75.4%), four reference translations have completely the same orderfor syntactic constituents.
This makes it easier for our analysis to compare the systemorder with the reference order.
However, there are 22% cases where two different ordersare provided, which shows the flexibility of translation.
According to our study, nounphrases taking DNP or CP modifiers, as well as DNPs and CPs themselves, are morelikely to be translated in two different orders.
Table 9 shows the percentages in whichtwo different orders for these constituents are observed in the reference corpus.DNP and CP are always used as pre-modifiers of noun phrases in Chinese.
Theyoften include the particle word  (of ) at the ending position.
The difference is thatDNP constructs a phrasal modifier whereas CP constructs a relative-clause modifier.There is no fixed reordering pattern for DNP and CP and therefore for NP which takesDNP/CP as a pre-modifier.
In the DNP ?
NP DEG structure, the DEG () can beTable 8Distribution of number of different orders by which syntactic constituents are translated inreferences.Number of different orders 1 2 3 4Percentage 75.40 22 2.33 0.33Table 9Two-order translation distribution of 4 NP-related constituents.Constituent 2-order translation percentageNP ?
DNP NP 16.93NP ?
CP NP 9.43CP ?
IP DEC 24.79DNP ?
NP DEG 34.58557Computational Linguistics Volume 36, Number 3translated into ?s or of, which are both appropriate in most cases, depending on thetranslator?s preference.
If the former is chosen, the order of DNP and therefore theorder for NP ?
DNP NP will both be straight: [1][2].
Otherwise, the two orders will beinverted: [2][1].
Similarly, there are also different translation patterns for CP ?
IP DECand NP ?
CP NP.
CP can be translated into ?that + clause?
or adjective-like phrasesin English.
Figure 7 shows an example where the CP constituent is translated into anadjective-like phrase.
Although the ?that + clause?
must be placed behind the nounphrase which it modifies, the order for adjective-like phrases is flexible (see Figure 7).For those constituents with different reference orders, we compare the order ofthe system translation to that of the reference translation which has the shortest editdistance to the system translation as described herein so that we can take into accountthe potential influence of different translations on the order of syntactic constituents.8.2.2 REF-Non-Reorderable Constituents.
We also study REF-R-rates for the 13 most fre-quent constituents listed in Table 10.
We find that two constituents, VP1 ?
PP VP2 andNP1 ?
CP NP2, have the lowest REF-R-rates, 58.20% and 61.77%, respectively.
Thismeans that about 40% of them are REF-non-reorderable.
In order to understand thereasons why they are non-reorderable in reference translations, we further investigateREF-non-reorderable cases for the constituent type VP1 ?
PP VP2 and roughly classifythe reasons into three categories as follows.1.
Outside interruption.
The reordering of PP and VP2 is interrupted byother constituents outside VP1.
For example, the Chinese sentence [NP/somebody ] [VP1 [PP.../when...] [VP2 [/say NP[...] ] ] ] is translatedinto when..., somebody said ....
Here the translation of the first NP which isoutside VP1 is inserted between the translations of PP and VP2 andtherefore interrupts their reordering.
Outside interruption accounts for21.65% of REF-non-reorderable cases.2.
Inside interruption.
The reordering of PP and VP2 is interrupted by thecombination of PP?s subnodes with VP2?s subnodes.
Inside interruptionaccounts for 48.45% of REF-non-reorderable cases, suggesting that it is themajor factor which decreases the reorderability of VP ?
PP VP.
Becauseboth PP and VP have their own complex sub-structures, the insideFigure 7An example of the translation of NP ?
CP NP.
This constituent can be translated in twodifferent orders: 1) the recently adopted statistical method (straight order); 2) the statisticalmethod recently adopted (inverted order).558Xiong et al Linguistically Annotated ReorderingTable 10F1-scores ( BWR+LAR vs. BWR) for the 13 most frequent constituents in the test corpus.Constituents indicated in bold have relatively lower F1 score for reordering.Type Constituent Percent.
(%) SYS-R-rate (%) F1-score (%)BWR BWR+LAR BWR BWR+LARVPVP ?
VV NP 8.12 79.22 84.10 76.97 80.53VP ?
ADVP VP 4.30 63.45 65.86 70.83 73.67VP ?
PP VP 1.87 60.32 70.37 39.29 40.33VP ?
VV IP 1.82 79.35 86.14 77.16 82.26NPNP ?
NN NN 6.88 84.68 85.18 76.17 79.10NP ?
NP NP 5.12 82.13 84.93 69.25 72.17NP ?
DNP NP 2.14 69.75 74.83 56.68 56.61NP ?
CP NP 2.12 59.67 73.43 48.75 54.48Misc.IP ?
NP VP 6.78 71.99 79.80 63.22 65.79PP ?
P NP 3.63 80.63 85.95 82.75 84.93CP ?
IP DEC 3.51 83.94 87.89 69.91 72.24QP ?
CD CLP 2.74 66 65 67.52 68.47DNP ?
NP DEG 2.43 85.98 89.84 67.5 68.75interruption is very complicated and includes a variety of cases, some ofwhich are quite unexpected.
Here we show two frequent examples ofinside interruption:a.
The preposition in the PP and the verb word/phrase of VP2 arealigned to only one target word or one continuous phrase.
Forexample,.../pressure,.../be confident of,.../suffer from, and so on.
This is caused by the lexical divergenceproblem.b.
The PP is first combined with the verb word of VP2 in an invertedorder, then combined with the remainder of VP2 in a straight order.For example, [PP [P] [omission1]] [VP [VV	] [omission2]]might be translated into learned from omission1 that omission2.3.
Parse error.
This accounts for 29.90% of REF-non-reorderable cases.Although these reasons are summarized from our analysis on the constituent typeVP ?
PP VP, they can be used to explain other REF-non-reorderable constituents, suchas NP ?
CP NP.8.3 Syntactic Constituent Movement in System Translations8.3.1 Overall Reordering Precision and Recall of Syntactic Constituents.
By summarizing allsyntactic reordering patterns (REF-SRP, SYS-SRP, and Match-SRP) for all constituents,we can calculate the overall reordering precision and recall of syntactic constituents.Table 11 shows the results for both BWR+LAR and BWR, where BWR+LAR clearlyoutperforms BWR.559Computational Linguistics Volume 36, Number 3Table 11Syntactic reordering precision and recall of BWR+LAR vs. BWR on the test corpus.Precision Recall F1BWR 70.89 68.79 69.83BWR+LAR 71.32 73.08 72.198.3.2 The Effect of Linguistic Knowledge on Phrase Movement.
To understand the changein phrase movement caused by linguistic knowledge, we further investigate how wellBWR and BWR+LAR reorder certain constituents, especially those with high distribu-tion probability.
Table 10 lists the 13 most frequent constituents, which jointly accountfor 51.46% of all multi-branching constituents.
Except for NP ?
DNP NP, the reorder-ing F1 score of all these constituents in BWR+LAR is better than that in BWR.Our hypothesis for the phrase movement change in BWR+LAR is that the integratedlinguistic knowledge makes phrase movement in BWR+LAR pay more respect to syn-tactic constituent boundaries.
The overall R-rates of BWR+LAR vs. BWR described inSection 8.1 indicate that BWR+LAR tends towards moving more syntactic constituentstogether than BWR does.
We want to know whether this is also true for a specificconstituent type.
The fourth and fifth columns in Table 10 present the R-rate for eachindividual constituent type that we have analyzed.
It is obvious that the R-rate ofBWR+LAR is much higher than that of BWR for almost all constituents.
This indicatesthat higher R-rate is one of the reasons for the higher performance of BWR+LAR.To gain a more concrete understanding of this change, we show two examples forthe reordering of VP ?
PP VP in Figure 8.
In both examples, BWR fails to move the PPconstituent to the right of the VP constituent, whereas BWR+LAR does it successfully.By tracing the binary BTG trees generated by the decoder, we find that BWR generateda very different BTG tree from the source parse tree whereas the BTG tree in BWR+LARalmost matches the source parse tree.
In the first example, BWR combines the VP phraseFigure 8Two examples for the translation of VP ?
PP VP.
Square brackets indicate combinations in astraight order and angular brackets represent combinations in an inverted order.560Xiong et al Linguistically Annotated Reordering with  and then combines .
The preposition word  is combined withthe NP phrase NHK, which makes the translation of NHK interrupt the reordering ofVP ?
PP VP in this example.
The BWR tree in the second example is even worse.
Thenon-syntactic phrase   in the VP phrase is first combined with  ,which is a sub-phrase of PP preceding VP in an inverted order.
The remaining part ofthe VP phrase is then merged.
This merging process continues regardless of the sourceparse tree.
The comparison of BTG trees of BWR+LAR and BWR in the two examplessuggests that reordering models should respect syntactic structures in order to capturereorderings under these structures.Our observation on phrase movement change resonates with the recent efforts inphrasal SMT that allow the decoder to prefer translations which show more respectfor syntactic constituent boundaries (Cherry 2008; Marton and Resnik 2008; Yamamoto,Okuma, and Sumita 2008).
Mapping to syntactic constituent boundaries, or in otherwords, syntactic cohesion (Fox 2002; Cherry 2008), has been studied and used in earlysyntax-based SMT models (Wu 1997; Yamada and Knight 2001).
But its value hasreceded in more powerful syntax-based models (Galley et al 2004; Chiang 2005) andnon-syntactic phrasal models (Koehn, Och, and Marcu 2003).
Marton and Resnik (2008)and Cherry (2008) use syntactic cohesion as a soft constraint by penalizing hypotheseswhich violate constituent boundaries.
Yamamoto, Okuma, and Sumita (2008) imposethis as a hard constraint on the ITG constraint to allow reorderings which respect thesource parse tree.
They all report significant improvements on different language pairs,which indicates that syntactic cohesion is very useful for phrasal SMT.
Our analysisdemonstrates that linguistically annotated reordering provides an alternative way toincorporate syntactic cohesion into phrasal SMT.8.4 Challenges in Phrase Reordering and SuggestionsWe highlight three constituent types in Table 10 (indicated in bold) which are muchmore difficult to reorder, as indicated by their relatively lower F1 scores.
The lower F1scores indicate that BWR+LAR is not fully sufficient for reordering these constituentsalthough it performs much better than BWR.
We find two main reasons for the lower F1scores and provide suggestions accordingly as follows.1.
Constrained decoding.
We observe that in reorderable constituents whichinvolve long-distance reorderings, their boundaries are easily violated byphrases outside them.
To prohibit boundary violations, we proposeconstrained decoding.
In constrained decoding, we define special zonesin source sentences.
Reorderings and translations within the zones cannotbe interrupted by fragments outside the zones.
We can also define otherconstrained operations on the zones.
For example, we can prohibitswappings in any zones which contain punctuation (Xiong et al 2008b).The beginning and ending positions of a zone are automatically learned.To be more flexible, they are not necessarily constituent boundaries.Constrained decoding is different from both soft constraints (Cherry 2008;Marton and Resnik 2008) and hard constraints (Yamamoto, Okuma, andSumita 2008).
It can be considered as in between both of these because it isharder than the former but softer than the latter.2.
Integrating special reordering rules.
Some constituents are indeednon-reorderable as we discussed in Section 8.2.2.
Inside or outside561Computational Linguistics Volume 36, Number 3interruptions have to be allowed to obtain fluent translations for theseconstituents.
However, the allowance of interruptions is sometimesbeyond the representability of BTG rules.
For example, to solve the lexicaldivergence problem, bilingual rules with aligned lexicons have to beintroduced.
To capture reorderings of these constituents, we propose tointegrate special reordering rules with richer contextual information intoBTG to extend BTG?s ability to deal with interruptions.
Completelyreplacing BTG with richer formalisms, such as hierarchical phrase(Chiang 2005) and tree-to-string (Liu, Liu, and Lin 2006) or string-to-tree(Marcu et al 2006), introduces a huge extra cost.
Instead, integrating asmall number of reordering rules into BTG to model reorderings ofnon-reorderable constituents would be more desirable.8.5 DiscussionIn the definition of syntactic reordering patterns, we only consider the relative orderof individual constituents on the target side.
We do not consider whether or not theyremain contiguous on the target side.
It is possible that other words are inserted be-tween spans of two contiguous constituents.
We use the term gap to refer to whenthis happens.
The absence of a gap in the definition of syntactic reordering patternsmay produce more matched SRPs and therefore lead to higher precision and recall.Table 12 shows the revised overall precision and recall of syntactic reordering patternswhen we also compare gaps.
The revised results show that BWR+LAR still significantlyoutperforms BWR.
This also applies to the 13 constituents identified in Table 10.
Theanalysis results obtained before are still valid when we consider gaps.9.
Related Work9.1 Linguistically Motivated Phrase ReorderingThere are various approaches which are devoted to incorporating linguistic knowledgeinto phrase reordering.
Generally, these approaches can be roughly divided into threecategories: (1) reordering the source language in a preprocessing step before decodingbegins; (2) estimating phrase movement with reordering models; and (3) capturingreorderings by synchronous grammars.
The preprocessing approach applies manual orautomatically extracted reordering knowledge from linguistic structures to transformthe source language sentence into a word order that is closer to the target sentence.The second reordering approach moves phrases under certain reordering constraintsand estimates the probabilities of movement with linguistic information.
In the thirdTable 12Revised overall precision and recall of BWR+LAR vs. BWR on the test corpus when we considerthe gap in syntactic reordering patterns.Precision Recall F1BWR (gap) 46.28 44.91 45.58BWR+LAR (gap) 48.80 50 49.39562Xiong et al Linguistically Annotated Reorderingapproach, reordering knowledge is included in synchronous rules.
The last two cate-gories reorder the source sentence during decoding, which distinguishes them from thefirst approach.
Note that some researchers integrate multiple reordering approaches inone decoder (Lin 2004; Quirk, Menezes, and Cherry 2005; Ge, Ittycheriah, and Papineni2008).9.1.1 The Preprocessing Approach.
In early work, Brown et al (1992) describe an approachto reordering French phrases in a preprocessing step.
Xia and McCord (2004) present apreprocessing approach which automatically learns reordering patterns based on CFGproductions.
Since then, the preprocessing approach seems to have been more popular.Collins, Koehn, and Kucerova (2005) propose reordering German clauses with six typesof manual rules.
Similarly, Wang, Collins, and Koehn (2007) reorder Chinese parse treesusing fine-grained human-written rules, mostly concentrating on VP and NP structures.Li et al (2007) improve the preprocessing approach by generating n-best reorderedsource sentences with reordering knowledge automatically learned from the alignmentsbetween source parse trees and target translations.
The approach proposed in Li et alalso enhances the connection between the preprocessing and decoding by adding asource reordering probability feature.
Other approaches introduced in Nie?n and Ney(2001), Popovic?
and Ney (2006), and Zhang, Zens, and Ney (2007) use morphological,POS, and chunk knowledge in the preprocessing approach, respectively.9.1.2 Estimating Phrase Movement with Embedded Reordering Models.
Under the IBM con-straint (Zens and Ney 2003), the early work uses a distortion-based reordering modelto penalize word movements (Koehn, Och, and Marcu 2003).
Similarly, under the ITGconstraint, the corresponding model is the flat model which assigns a prior probabilityto the straight or inverted order (Wu 1996).
These two models don?t respect the contentof phrases which are moved.
To address this issue, lexicalized reordering models whichare sensitive to lexical information about phrases are introduced (Tillman 2004; Koehnet al 2005; Kumar and Byrne 2005; Al-Onaizan and Papineni 2006).
Xiong, Liu, andLin (2006) introduce a more flexible reordering model under the ITG constraint usingdiscriminative features which are automatically learned from a training corpus.
Zhanget al (2007) propose a model for syntactic phrase reordering which uses syntacticknowledge from source parse trees.
Our reordering approach is most similar to those inXiong, Liu, and Lin (2006) and Zhang et al but extends them further by using syntacticknowledge and allowing non-syntactic phrase reordering.9.1.3 Capturing Reorderings by Synchronous Grammars.
Wu (1997) and Eisner (2003) usesynchronous grammars to capture reorderings between two languages.
Chiang (2005)introduces formal synchronous grammars for phrase-based translation.
In his work,hierarchical reordering knowledge is included in synchronous rules which are automat-ically learned from word-aligned corpus.
In linguistically syntax-based models, string-to-tree (Marcu et al 2006), tree-to-string (Huang, Knight, and Joshi 2006; Liu, Liu, andLin 2006), and tree-to-tree (Zhang et al 2008) translation rules, just to name a few, areexplored.
Linguistical reordering knowledge is naturally included in these syntax-basedtranslation rules.9.2 Automatic Analysis of ReorderingAlthough there is a variety of work on phrase reordering, automatic analysis of phrasereordering is not widely explored in the SMT literature.
Chiang et al (2005) propose563Computational Linguistics Volume 36, Number 3an automatic method to compare different system outputs in a fine-grained mannerwith regard to reordering.
In their method, common word n-grams occurring in bothreference translations and system translations are extracted and generalized to part-of-speech tag sequences.
A recall is calculated for each certain tag sequence to indicate theability of reordering models to capture this tag sequence in system translations.
Popovicet al (2006) use the relative difference between WER (word error rate) and PER (positionindependent word error rate) to indicate reordering errors.
The larger the difference, themore reordering errors there are.Callison-Burch et al (2007) propose a constituent-based evaluation that is very simi-lar to our method in Steps (1)?(3).
They also parse the source sentence and automaticallyalign the parse tree with the reference/system translations.
The difference is that theyhighlight constituents from the parse tree to enable human evaluation of the translationsof these constituents, rather than automatically analyzing constituent movement.
Theyuse this method for human evaluation in the shared translation task of the 2007 and2008 ACL Workshop on Statistical Machine Translation.Fox (2002) systematically studies syntactic cohesion between French and Englishusing human translations and alignments.
Compared with her work, our analysis hereincludes, but is not limited to, an investigation of syntactic cohesion in an actual MTsystem.10.
ConclusionWe have presented a novel linguistically motivated phrase reordering approach:Linguistically Annotated Reordering.
The LAR approach incorporates soft linguisticknowledge from the source parse tree into hard hierarchical skeletons generated byBTG in phrasal SMT.
To automatically learn reordering features, we have introducedalgorithms for reordering example extraction and linguistic annotation.
We have alsoproposed a new syntax-based analysis method to detect syntactic constituent movementin human/machine translations.We have conducted experiments on large-scale training data to evaluate LAR andBWR as well as the reordering example extraction algorithms.
Our evaluation resultsshow that:1.
Extracting reordering examples directly from word alignments is muchbetter than from BTG-style trees which are built from word alignments.2.
Selection rules which bias the reordering model towards smallerswappings improve translation quality.3.
BWR+LAR significantly outperforms BWR, which suggests that theintegration of linguistic knowledge improves reordering; and tuning twoseparate reordering models is better than the All-in-One combinationmethod.We have further analyzed the outputs of BWR+LAR vs. BWR using the proposedsyntax-based analysis method.
Our analysis results show that:1.
BWR+LAR achieves a significantly higher reordering precision and recallthan BWR does with regard to syntactic constituent movement.564Xiong et al Linguistically Annotated Reordering2.
For most reorderable constituents, integrating source-side linguisticknowledge into the reordering model can significantly improvereorderings by guiding reordering models to prefer hypotheses that paymore respect to constituent boundaries.3.
For non-reorderable constituents or constituents involving long-distancereorderings, integrating source-side linguistic knowledge into thereordering model is not sufficient to avoid illegal boundary violations or tocapture reordering patterns.To avoid illegal boundary violations in long-span constituents, we suggest con-strained decoding, which protects special zones in the source sentence from beinginterrupted by phrases outside the zones.
Beginning and ending positions of the zonesare automatically learned using lexical and syntactic knowledge.
To capture complex re-orderings which cross constituent boundaries, phrasal SMT should integrate reorderingrules with richer contextual information.AcknowledgmentsWe would like to thank the three anonymousreviewers for their helpful comments andsuggestions.ReferencesAl-Onaizan, Yaser and Kishore Papineni.2006.
Distortion models for statisticalmachine translation.
In Proceedingsof the 21st International Conference onComputational Linguistics and 44thAnnual Meeting of the Association forComputational Linguistics, pages 529?536,Sydney.Brown, Peter F., Stephen A. Della Pietra,Vincent J. Della Pietra, John D. Lafferty,and Robert L. Mercer.
1992.
Analysis,statistical transfer, and synthesis inmachine translation.
In Proceedingsof the Fourth International Conference onTheoretical and Methodological Issues inMachine Translation, pages 83?100,Montreal.Callison-Burch, Chris, Cameron Fordyce,Philipp Koehn, Christof Monz, and JoshSchroeder.
2007.
(Meta-) evaluation ofmachine translation.
In Proceedings of theSecond Workshop on Statistical MachineTranslation, pages 136?158, Prague.Cherry, Colin.
2008.
Cohesive phrase-baseddecoding for statistical machinetranslation.
In Proceedings of ACL-08: HLT,pages 72?80, Columbus, OH.Chiang, David.
2005.
A hierarchicalphrase-based model for statistical machinetranslation.
In Proceedings of the 43rdAnnual Meeting of the Association forComputational Linguistics, pages 263?270,Ann Arbor, MI.Chiang, David, Adam Lopez, NitinMadnani, Christof Monz, Philip Resnik,and Michael Subotin.
2005.
The hieromachine translation system: Extensions,evaluation, and analysis.
In Proceedings ofHuman Language Technology Conference andConference on Empirical Methods in NaturalLanguage Processing, pages 779?786,Vancouver.Collins, Michael, Philipp Koehn, and IvonaKucerova.
2005.
Clause restructuring forstatistical machine translation.
InProceedings of the 43rd Annual Meeting of theAssociation for Computational Linguistics,pages 531?540, Ann Arbor, MI.Eisner, Jason.
2003.
Learning non-isomorphictree mappings for machine translation.
InThe Companion Volume to the Proceedings of41st Annual Meeting of the Association forComputational Linguistics, pages 205?208,Sapporo.Fox, Heidi.
2002.
Phrasal cohesion andstatistical machine translation.
InProceedings of the 2002 Conference onEmpirical Methods in Natural LanguageProcessing, pages 304?311,Philadelphia, PA.Galley, Michel, Mark Hopkins, Kevin Knight,and Daniel Marcu.
2004.
What?s in atranslation rule?
In Proceedings of theHuman Language Technology Conferenceof the North American Chapter of theAssociation for Computational Linguistics:HLT-NAACL 2004, pages 273?280,Boston, MA.Ge, Niyu, Abe Ittycheriah, and KishorePapineni.
2008.
Multiple reorderings inphrase-based machine translation.
InProceedings of the ACL-08: HLT SecondWorkshop on Syntax and Structure in565Computational Linguistics Volume 36, Number 3Statistical Translation (SSST-2), pages 61?68,Columbus, OH.Huang, Liang, Kevi Knight, and AravindJoshi.
2006.
Statistical syntax-directedtranslation with extended domain oflocality.
In Proceedings of the 7th Conferenceof the Association for Machine Translationof the Americas, pages 66?73,Cambridge, MA.Koehn, Philipp.
2004.
Statistical significancetests for machine translation evaluation.
InProceedings of EMNLP 2004, pages 388?395,Barcelona.Koehn, Philipp, Amittai Axelrod, AlexandraBirch Mayne, Chris Callison-Burch,Miles Osborne, and David Talbot.
2005.Edinburgh system description for the2005 IWSLT speech translationevaluation.
In Proceedings of theInternational Workshop on SpokenLanguage Translation 2005, pages 78?85,Pittsburgh, PA.Koehn, Philipp, Franz Joseph Och, andDaniel Marcu.
2003.
Statisticalphrase-based translation.
In Proceedings ofthe 2003 Human Language TechnologyConference of the North American Chapter ofthe Association for Computational Linguistics,pages 58?54, Edmonton.Kumar, Shankar and William Byrne.
2005.Local phrase reordering models forstatistical machine translation.
InProceedings of Human Language TechnologyConference and Conference on EmpiricalMethods in Natural Language Processing,pages 161?168, Vancouver.Li, Chi-Ho, Minghui Li, Dongdong Zhang,Mu Li, Ming Zhou, and Yi Guan.
2007.
Aprobabilistic approach to syntax-basedreordering for statistical machinetranslation.
In Proceedings of the 45thAnnual Meeting of the Association ofComputational Linguistics, pages 720?727,Prague.Lin, Dekang.
2004.
A path-based transfermodel for machine translation.
InProceedings of the 20th InternationalConference on Computational Linguistics(Coling 2004), pages 625?630, Geneva.Liu, Yang, Qun Liu, and Shouxun Lin.
2006.Tree-to-string alignment template forstatistical machine translation.
InProceedings of the 21st InternationalConference on Computational Linguistics and44th Annual Meeting of the Association forComputational Linguistics, pages 609?616,Sydney.Marcu, Daniel, Wei Wang, AbdessamadEchihabi, and Kevin Knight.
2006.
SPMT:Statistical machine translation withsyntactified target language phrases.
InProceedings of the 2006 Conference onEmpirical Methods in Natural LanguageProcessing, pages 44?52, Sydney.Marton, Yuval and Philip Resnik.
2008.
Softsyntactic constraints for hierarchicalphrased-based translation.
In Proceedingsof ACL-08: HLT, pages 1003?1011,Columbus, OH.Navarro, Gonzalo.
2001.
A guided tour toapproximate string matching.
ACMComputing Surveys, 33(1):31?88.Nie?n, Sonja and Hermann Ney.
2001.Morpho-syntactic analysis forreordering in statistical machinetranslation.
In Proceedings of MT SummitVIII, pages 247?252, Santiago deCompostela.Och, Franz Josef.
2002.
Statistical MachineTranslation: From Single-Word Models toAlignment Templates.
Ph.D. thesis, RWTHAachen University, Germany.Och, Franz Josef.
2003.
Minimum error ratetraining in statistical machine translation.In Proceedings of the 41st Annual Meeting ofthe Association for Computational Linguistics,pages 160?167, Sapporo.Och, Franz Josef and Hermann Ney.
2000.Improved statistical alignment models.
InProceedings of the 38th Annual Meeting of theAssociation for Computational Linguistics,pages 440?447, Hong Kong.Papineni, Kishore, Salim Roukos, ToddWard, and Wei-Jing Zhu.
2002.
BLEU: Amethod for automatic evaluation ofmachine translation.
In Proceedings of 40thAnnual Meeting of the Association forComputational Linguistics, pages 311?318,Philadelphia, PA.Popovic, Maja, Adria` de Gispert, DeepaGupta, Patrik Lambert, Hermann Ney,Jose?
B. Marin?o, Marcello Federico, andRafael Banchs.
2006.
Morpho-syntacticinformation for automatic error analysisof statistical machine translation output.In Proceedings on the Workshop onStatistical Machine Translation, pages 1?6,New York, NY.Popovic?, Maja and Hermann Ney.
2006.Pos-based word reorderings for statisticalmachine translation.
In Proceedings of theFifth International Conference on LanguageResources and Evaluation (LREC 2006),pages 1278?1283, Genoa.Quirk, Chris, Arul Menezes, and ColinCherry.
2005.
Dependency treelettranslations: Syntactically informedphrasal smt.
In Proceedings of the 43rd566Xiong et al Linguistically Annotated ReorderingAnnual Meeting of the ACL, pages 271?279,Ann Arbor, MI.Stolcke, Andreas.
2002.
SRILM?anextensible language modeling toolkit.In Proceedings of the 7th InternationalConference on Spoken LanguageProcessing (ICSLP 2002), pages 901?904,Denver, CO.Tillman, Christoph.
2004.
A unigramorientation model for statistical machinetranslation.
In Proceedings of the HumanLanguage Technology Conference of the NorthAmerican Chapter of the Association forComputational Linguistics (HLT-NAACL2004): Short Papers, pages 101?104,Boston, MA.Wang, Chao, Michael Collins, and PhilippKoehn.
2007.
Chinese syntactic reorderingfor statistical machine translation.
InProceedings of the 2007 Joint Conference onEmpirical Methods in Natural LanguageProcessing and Computational NaturalLanguage Learning (EMNLP-CoNLL),pages 737?745, Prague.Wu, Dekai.
1996.
A polynomial-timealgorithm for statistical machinetranslation.
In Proceedings of the 34thAnnual Meeting of the Association forComputational Linguistics, pages 152?158,Santa Cruz, CA.Wu, Dekai.
1997.
Stochastic inversiontransduction grammars and bilingualparsing of parallel corpora.
ComputationalLinguistics, 23(3):377?403.Wu, Dekai, Marine Carpuat, and Yihai Shen.2006.
Inversion transduction grammarcoverage of Arabic-English wordalignment for tree-structured statisticalmachine translation.
In Proceedingof the IEEE/ACL 2006 Workshop onSpoken Language Technology (SLT 2006),pages 234?237, Aruba.Xia, Fei and Michael McCord.
2004.Improving a statistical MT systemwith automatically learned rewritepatterns.
In Proceedings of the 20thInternational Conference on ComputationalLinguistics (Coling 2004), pages 508?514,Geneva.Xiong, Deyi, Qun Liu, and Shouxun Lin.2005.
Parsing the penn chinese treebankwith semantic knowledge.
In Proceedings ofThe 2nd International Joint Conference onNatural Language Processing (IJCNLP-05),pages 70?81, Jeju Island.Xiong, Deyi, Qun Liu, and Shouxun Lin.2006.
Maximum entropy based phrasereordering model for statistical machinetranslation.
In Proceedings of the 21stInternational Conference on ComputationalLinguistics and 44th Annual Meeting of theAssociation for Computational Linguistics,pages 521?528, Sydney.Xiong, Deyi, Min Zhang, Aiti Aw, andHaizhou Li.
2008a.
A linguisticallyannotated reordering model forBTG-based statistical machinetranslation.
In Proceedings of ACL-08:HLT, Short Papers, pages 149?152,Columbus, OH.Xiong, Deyi, Min Zhang, Aiti Aw, Haitao Mi,Qun Liu, and Shouxun Lin.
2008b.Refinements in BTG-based statisticalmachine translation.
In Proceedingsof the Third International Joint Conferenceon Natural Language Processing,pages 505?512, Hyderabad.Xue, Nianwen, Fei Xia, Shizhe Huang, andAnthony Kroch.
2000.
The bracketingguidelines for the Penn Chinese treebank(3.0).
Technical report IRCS 00-07,University of Pennsylvania Institute forResearch in Cognitive Science,Philadelphia.Yamada, Kenji and Kevin Knight.
2001.
Asyntax-based statistical translation model.In Proceedings of 39th Annual Meeting of theAssociation for Computational Linguistics,pages 523?530, Toulouse.Yamamoto, Hirofumi, Hideo Okuma, andEiichiro Sumita.
2008.
Imposingconstraints from the source tree on ITGconstraints for SMT.
In Proceedings of theACL-08: HLT Second Workshop on Syntaxand Structure in Statistical Translation(SSST-2), pages 1?9, Columbus, OH.Zens, Richard, and Hermann Ney.
2003.A comparative study on reorderingconstraints in statistical machinetranslation.
In Proceedings of the 41stAnnual Meeting of the Association forComputational Linguistics (ACL),pages 144?151, Sapporo, Japan.Zhang, Dongdong, Mu Li, Chi-Ho Li, andMing Zhou.
2007.
Phrase reorderingmodel integrating syntactic knowledgefor SMT.
In Proceedings of the 2007 JointConference on Empirical Methods inNatural Language Processing andComputational Natural LanguageLearning (EMNLP-CoNLL), pages 533?540,Prague.Zhang, Hao and Daniel Gildea.
2005.Stochastic lexicalized inversiontransduction grammar for alignment.
InProceedings of the 43rd Annual Meeting of theAssociation for Computational Linguistics,pages 475?482, Ann Arbor, MI.567Computational Linguistics Volume 36, Number 3Zhang, Hao, Daniel Gildea, and DavidChiang.
2008.
Extracting synchronousgrammar rules from word-levelalignments in linear time.
In Proceedings ofthe 22nd International Conference onComputational Linguistics (Coling 2008),pages 1081?1088, Manchester.Zhang, Min, Hongfei Jiang, Aiti Aw, HaizhouLi, Chew Lim Tan, and Sheng Li.
2008.
Atree sequence alignment-based tree-to-treetranslation model.
In Proceedings of ACL-08:HLT, pages 559?567, Columbus, OH.Zhang, Yuqi, Richard Zens, and HermannNey.
2007.
Chunk-level reordering ofsource language sentences withautomatically learned rules for statisticalmachine translation.
In Proceedingsof SSST, NAACL-HLT 2007 / AMTAWorkshop on Syntax and Structure inStatistical Translation, pages 1?8,Rochester, NY.Zollmann, Andreas, Ashish Venugopal, andStephan Vogel.
2008.
The CMUsyntax-augmented machine translationsystem: SAMT on hadoop with N-bestalignments.
In Proceedings of InternationalWorkshop on Spoken Language Translation(IWSLT), pages 18?25, Honolulu, HI.568
