Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 575?583,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsGraph-Cut-Based Anaphoricity Determination for Coreference ResolutionVincent NgHuman Language Technology Research InstituteUniversity of Texas at DallasRichardson, TX 75083-0688vince@hlt.utdallas.eduAbstractRecent work has shown that explicitly iden-tifying and filtering non-anaphoric mentionsprior to coreference resolution can improvethe performance of a coreference system.We present a novel approach to this task ofanaphoricity determination based on graphcuts, and demonstrate its superiority to com-peting approaches by comparing their effec-tiveness in improving a learning-based coref-erence system on the ACE data sets.1 IntroductionCoreference resolution is the problem of identifyingwhich noun phrases (NPs, or mentions) refer to thesame real-world entity in a text or dialogue.
Accord-ing to Webber (1979), coreference resolution canbe decomposed into two complementary tasks: ?
(1)identifying what a text potentially makes availablefor anaphoric reference and (2) constraining the can-didate set of a given anaphoric expression down toone possible choice.?
The first task is nowadays typ-ically formulated as an anaphoricity determinationtask, which aims to classify whether a given men-tion is anaphoric or not.
Knowledge of anaphoric-ity could improve the precision of a coreference sys-tem, since non-anaphoric mentions do not have anantecedent and therefore do not need to be resolved.Previous work on anaphoricity determination canbe broadly divided into two categories (see Poe-sio et al (2004) for an overview).
Research in thefirst category aims to identify specific types of non-anaphoric phrases, with some identifying pleonas-tic it (using heuristics [e.g., Paice and Husk (1987),Lappin and Leass (1994), Kennedy and Boguraev(1996)], supervised approaches [e.g., Evans (2001),Mu?ller (2006), Versley et al (2008)], and distribu-tional methods [e.g., Bergsma et al (2008)]), andothers identifying non-anaphoric definite descrip-tions (using rule-based techniques [e.g., Vieira andPoesio (2000)] and unsupervised techniques [e.g.,Bean and Riloff (1999)]).On the other hand, research in the second cat-egory focuses on (1) determining the anaphoricityof all types of mentions, and (2) using the result-ing anaphoricity information to improve coreferenceresolution.
For instance, Ng and Cardie (2002a)train an anaphoricity classifier to determine whethera mention is anaphoric, and let an independently-trained coreference system resolve only those men-tions that are classified as anaphoric.
Somewhat sur-prisingly, they report that using anaphoricity infor-mation adversely affects the performance of theircoreference system, as a result of an overly conser-vative anaphoricity classifier that misclassifies manyanaphoric mentions as non-anaphoric.
One solu-tion to this problem is to use anaphoricity infor-mation as soft constraints rather than as hard con-straints for coreference resolution.
For instance,when searching for the best partition of a set ofmentions, Luo (2007) combines the probabilities re-turned by an anaphoricity model and a coreferencemodel to score a coreference partition, such that apartition is penalized whenever an anaphoric men-tion is resolved.
Another, arguably more popular,solution is to ?improve?
the output of the anaphoric-ity classifier by exploiting the dependency betweenanaphoricity determination and coreference resolu-575tion.
For instance, noting that Ng and Cardie?sanaphoricity classifier is too conservative, Ng (2004)first parameterizes their classifier such that its con-servativeness can be varied, and then tunes this pa-rameter so that the performance of the coreferencesystem is maximized.
As another example, De-nis and Baldridge (2007) and Finkel and Manning(2008) perform joint inference for anaphoricity de-termination and coreference resolution, by using In-teger Linear Programming (ILP) to enforce the con-sistency between the output of the anaphoricity clas-sifier and that of the coreference classifier.While this ILP approach and Ng?s (2004) ap-proach to improving the output of an anaphoricityclassifier both result in increased coreference per-formance, they have complementary strengths andweaknesses.
Specifically, Ng?s approach can di-rectly optimize the desired coreference evaluationmetric, but by treating the coreference system as ablack box during the optimization process, it doesnot exploit the potentially useful pairwise probabil-ities provided by the coreference classifier.
On theother hand, the ILP approach does exploit such pair-wise probabilities, but optimizes an objective func-tion that does not necessarily have any correlationwith the desired evaluation metric.Our goals in this paper are two-fold.
First, moti-vated in part by previous work, we propose a graph-cut-based approach to anaphoricity determinationthat combines the strengths of Ng?s approach andthe ILP approach, by exploiting pairwise corefer-ence probabilities when co-ordinating anaphoricityand coreference decisions, and at the same time al-lowing direct optimization of the desired corefer-ence evaluation metric.
Second, we compare ourcut-based approach with the five aforementioned ap-proaches to anaphoricity determination (namely, Ngand Cardie (2002a), Ng (2004), Luo (2007), De-nis and Baldridge (2007), and Finkel and Manning(2008)) in terms of their effectiveness in improv-ing a learning-based coreference system.
To ourknowledge, there has been no attempt to performa comparative evaluation of existing approaches toanaphoricity determination.
It is worth noting, inparticular, that Luo (2007), Denis and Baldridge(2007), and Finkel and Manning (2008) evaluatetheir approaches on true mentions extracted fromthe answer keys.
Since true mentions are com-posed of all the NPs involved in coreference rela-tions but only a subset of the singleton NPs (i.e.,NPs that are not coreferent with any other NPs) ina text, evaluating the utility of anaphoricity deter-mination on true mentions to some extent defeatsthe purpose of performing anaphoricity determina-tion, which precisely aims to identify non-anaphoricmentions.
Hence, we hope that our evaluation onmentions extracted using an NP chunker can revealtheir comparative strengths and weaknesses.We perform our evaluation on three ACE coref-erence data sets using two commonly-used scor-ing programs.
Experimental results show that (1)employing our cut-based approach to anaphoric-ity determination yields a coreference system thatachieves the best performance for all six data-set/scoring-program combinations, and (2) amongthe five existing approaches, none performs consis-tently better than the others.The rest of the paper is organized as follows.
Sec-tion 2 describes our learning-based coreference sys-tem.
In Section 3, we give an overview of the fivebaseline approaches to anaphoricity determination.Section 4 provides the details of our graph-cut-basedapproach.
Finally, we present evaluation results inSection 5 and conclude in Section 6.2 Baseline Coreference Resolution SystemOur baseline coreference system implements thestandard machine learning approach to coreferenceresolution (see Ng and Cardie (2002b), Ponzetto andStrube (2006), Yang and Su (2007), for instance),which consists of probabilistic classification andclustering, as described below.2.1 The Standard Machine Learning ApproachWe use maximum entropy (MaxEnt) classification(Berger et al, 1996) in conjunction with the 33 fea-tures described in Ng (2007) to acquire a model, PC ,for determining the probability that two mentions,mi and mj , are coreferent.
Hence,PC(mi,mj) = P (COREFERENT | mi,mj).In the rest of the paper, we will refer to PC(mi,mj)as the pairwise coreference probability between miand mj .
To generate training instances, we em-ploy Soon et al?s (2001) procedure, relying on thetraining texts to create (1) a positive instance for576each anaphoric mention, mj , and its closest an-tecedent, mi; and (2) a negative instance for mjpaired with each of the intervening mentions, mi+1,mi+2,.
.
., mj?1.
When training the feature-weightparameters of the MaxEnt model, we use 100 it-erations of the improved iterative scaling (IIS) al-gorithm (Della Pietra et al, 1997) together with aGaussian prior to prevent overfitting.After training, the coreference model is used toselect an antecedent for each mention in a test text.Following Soon et al (2001), we select as the an-tecedent of each mention, mj , the closest preced-ing mention that is classified as coreferent with mj ,where mention pairs with pairwise probabilities of atleast 0.5 are considered coreferent.
If no such men-tion exists, no antecedent will be selected for mj .
Inessence, we use a closest-first clustering algorithmto impose a partitioning on the mentions.3 Baseline Approaches to AnaphoricityDeterminationAs mentioned previously, we will use five existingapproaches to anaphoricity determination as base-lines in our evaluation.
Common to all five ap-proaches is the acquisition of an anaphoricity model,PA, for determining the probability that a mention,mj , is anaphoric.
Hence,PA(mj) = P (ANAPHORIC | mj)To train PA, we again employ MaxEnt modeling,and create one training instance from each mentionin a training text.
Hence, each instance represents asingle mention and consists of 37 features that arepotentially useful for distinguishing anaphoric andnon-anaphoric mentions (see Ng and Cardie (2002a)for a detailed description of these features).1The classification of a training instance ?
oneof ANAPHORIC or NOT ANAPHORIC ?
is deriveddirectly from the coreference chains in the associ-ated training text.
Like the coreference model, theanaphoricity model is trained by running 100 iter-ations of IIS with a Guassian prior.
The resultingmodel is then applied to a test text to determine the1While we train the anaphoricity model using the Ng andCardie (2002a) feature set, it should be clear that any featuresthat are useful for distinguishing anaphoric and non-anaphoricmentions can be used (e.g., those proposed by Uryupina (2003)and Elsner and Charniak (2007)).probability that a mention is anaphoric.In the rest of this section, we provide an overviewof the five baseline approaches to anaphoricity deter-mination.
We will characterize each approach alongtwo dimensions: (1) whether it attempts to improvePA, and if so, how; and (2) whether the resultinganaphoricity information is used as hard constraintsor soft constraints by the coreference system.3.1 Ng and Cardie (2002a)Ng and Cardie (N&C) do not attempt to improve PA,simply using the anaphoricity information it pro-vides as hard constraints for coreference resolution.Specifically, the coreference system resolves onlythose mentions that are determined as anaphoric byPA, where a mention is classified as anaphoric if theclassification threshold is at least 0.5.3.2 Ng (2004)PA may not be ?sufficiently?
accurate, however,as N&C report a significant drop in the perfor-mance of their coreference system after incorpo-rating anaphoricity information, owing in part totheir overly conservative anaphoricity model thatmisclassifies many anaphoric mentions as non-anaphoric.
To address this problem, Ng (2004) at-tempts to improve PA by introducing a thresholdparameter c to adjust the conservativeness of PAas follows.
Given a specific c (0 ?
c ?
1), amention mj is classified as anaphoric by PA if andonly if PA(mj) ?
c. It should be easy to seethat decreasing c yields progressively less conserva-tive anaphoricity models (i.e., more mentions willbe classified as anaphoric).
The parameter c is tunedusing held-out development data to optimize the per-formance of the coreference system that employsanaphoricity information (as hard constraints).In essence, Ng?s approach to improving PA treatsthe coreference system as a black box, merely se-lecting the value for c that yields the best score ac-cording to the desired coreference evaluation met-ric on the held-out data.
In particular, unlike someof the anaphoricity determination approaches dis-cussed later on, this approach does not attempt to co-ordinate the anaphoricity decisions and the pairwisecoreference decisions.
Nevertheless, as mentionedbefore, a unique strength of this approach lies in itsability to optimize directly the desired coreference577evaluation metric.3.3 Luo (2007)Among the five anaphoricity determination ap-proaches, Luo?s (2007) is the only one whereanaphoricity information is exploited as soft con-straints by the coreference model, PC .Specifically, Luo?s algorithm attempts to find themost probable coreference partition of a given setof mentions.
To do so, it scores a partition us-ing the probabilities provided by PA and PC .
Letus illustrate how this can be done via the follow-ing example.
Given a document with four men-tions, m1, .
.
.
,m4, and a partition of the mentions,{[m1,m3,m4], [m2]}, automatically produced bysome coreference system, Luo?s algorithm scoresthe partition by considering the mentions in thedocument in a left-to-right manner.
As the firstmention in the document, m1 is not anaphoric,and the probability that it is non-anaphoric is 1 ?PA(m1).
Then, the algorithm processes m2, whichaccording to the partition is non-anaphoric, andthe probability of its being non-anaphoric is 1 ?PA(m2).
Next, it processes m3, which is coref-erent with m1 with probability PC(m1,m3).
Fi-nally, it processes m4, which is coreferent with m1and m3.
The probability that m4 is coreferent withthe cluster consisting of m1 and m3 is defined tobe max(PC(m1,m4), PC (m3,m4)), according toLuo?s algorithm.
The score of this partition is theproduct of these four probabilities, two provided byPA and two by PC .
As can be seen, a partitionis penalized whenever a mention that is unlikely tobe anaphoric (according to PA) is being resolved tosome antecedent according to the partition.Nevertheless, it is computationally infeasible toscore all possible partitions given a set of mentions,as the number of partitions is exponential in thenumber of mentions.
To cope with this computa-tional complexity, Luo employs the algorithm pro-posed in Luo et al (2004) to heuristically search forthe most probable partition by performing a beamsearch through a Bell tree.
In essence, only the mostpromising nodes in the tree are expanded at eachstep of the search process, where the ?promise?
ofa node is defined in terms of the probabilities pro-vided by PA and PC , as described above.
Details ofthis process can be found in Luo et al (2004).3.4 Denis and Baldridge (2007)As mentioned before, Denis and Baldridge (D&B)aim to improve the outputs of PA and PC by em-ploying Integer Linear Programming (ILP) to per-form joint inference for anaphoricity determinationand coreference resolution.
The ILP approach is mo-tivated by the observation that the outputs of thesetwo models have to satisfy certain constraints.
Forinstance, if PC determines that a mention, mj , isnot coreferent with any other mentions in the as-sociated text, then PA should determine that mj isnon-anaphoric.
In practice, however, since PA andPC are trained independently of each other, this andother constraints cannot be enforced.ILP provides a framework for jointly determininganaphoricity and coreference decisions for a givenset of mentions based on the probabilities providedby PA and PC , such that the resulting joint deci-sions satisfy the desired constraints while respectingas much as possible the probabilistic decisions madeby the independently-trained PA and PC .
Specifi-cally, an ILP program is composed of an objectivefunction to be optimized subject to a set of linearconstraints, and is created for each test text D as fol-lows.
Let M be the set of mentions in D, and P bethe set of mention pairs formed from M (i.e., P ={(mi,mj) | mi,mj ?
M, i < j}).
Each ILP pro-gram has a set of indicator variables.
In our case, wehave one binary-valued variable for each anaphoric-ity decision and coreference decision to be made byan ILP solver.
Following D&B?s notation, we use yjto denote the anaphoricity decision for mention mj ,and x?i,j?
to denote the coreference decision involv-ing mentions mi and mj .
In addition, each variableis associated with an assignment cost.
Specifically,let cC?i,j?
= ?
log(PC(mi,mj)) be the cost of settingx?i,j?
to 1, and c?C?i,j?
= ?
log(1 ?
PC(mi,mj)) bethe complementary cost of setting x?i,j?
to 0.
We cansimilarly define the cost associated with each yj , let-ting cAj = ?
log(PA(mj)) be the cost of setting yj to1, and c?Aj = ?
log(1 ?
PA(mj)) be the complemen-tary cost of setting yj to 0.
Given these costs, weaim to optimize the following objective function:min ?(mi,mj)?PcC?i,j?
?
x?i,j?
+ c?C?i,j?
?
(1 ?
x?i,j?
)+ ?mj?McAj ?
yj + c?Aj ?
(1 ?
yj)578subject to a set of manually-specified linear con-straints.
D&B specify four types of constraints: (1)each indicator variable can take on a value of 0 or 1;(2) if mi and mj are coreferent (x?i,j?=1), then mj isanaphoric (yj=1); (3) if mj is anaphoric (yj=1), thenit must be coreferent with some preceding mentionmi; and (4) if mj is non-anaphoric, then it cannot becoreferent with any mention.
Note that we are mini-mizing the objective function, since each assignmentcost is expressed as a negative logarithm value.
Weuse lp solve2, an ILP solver, to solve this program.It is easy to see that enforcing consistency usingILP amounts to employing anaphoricity informa-tion as hard constraints for the coreference system.Since transitivity is not guaranteed by the above con-straints, we follow D&B and use the aggressive-merge clustering algorithm to put any two mentionsthat are posited as coreferent into the same cluster.3.5 Finkel and Manning (2008)Finkel and Manning (F&M) present one simple ex-tension to D&B?s ILP approach: augmenting theset of linear constraints with the transitivity con-straint.
This ensures that if x?i,j?=1 and x?j,k?=1,then x?i,k?=1.
As a result, the coreference decisionsdo not need to be co-ordinated by a separate cluster-ing mechanism.4 Cut-Based Anaphoricity DeterminationAs mentioned in the introduction, our graph-cut-based approach to anaphoricity determination is mo-tivated by Ng?s (2004) and the ILP approach, aim-ing to combine the strengths of the two approaches.Specifically, like Ng (2004), our approach allows di-rect optimization of the desired coreference evalua-tion metric; and like the ILP approach, our approachco-ordinates anaphoricity decisions and coreferencedecisions by exploiting the pairwise probabilitiesprovided by a coreference model.
In this section,we will introduce our cut-based approach, startingby reviewing concepts related to minimum cuts.4.1 The Minimum Cut Problem SettingAssume that we want to partition a set of n objects,{x1, x2, .
.
.
, xn}, into two sets, Y1 and Y2.
We havetwo types of scores concerning the x?s and the Y ?s:2Available from http://lpsolve.sourceforge.net/membership scores and similarity scores.
The mem-bership score, memYi(xj), is a non-negative quan-tity that approximates the ?affinity?
of xj to Yi.
Onthe other hand, the similarity score, sim(xj , xk), isa non-negative quantity that provides an estimate ofthe similarity between xj and xk.Informally, our goal is to maximize each object?snet happiness, which is computed by subtracting itsmembership score of the class it is not assigned tofrom its membership score of the class it is assignedto.
However, at the same time, we want to avoidassigning similar objects to different classes.
Moreformally, we seek to minimize the partition cost:?xj?Y1,xk?Y2sim(xj, xk)+?x?Y1memY2(x)+?x?Y2memY1(x)There exists an efficient algorithm for solving thisseemingly intractable problem when it is recast asa graph problem.
So, let us construct a graph, G,based on the available scores as follows.
First, wecreate two nodes, s and t (called the source andthe sink, respectively), to represent the two classes.Then, we create one ?object?
node for each of then objects.
For each object, xj , we add two directededges, one from s to xj (with weight memY1(xj))and the other from xj to t (with weight memY2(xj)).Moreover, for each pair of object nodes, xj and xk,we add two directed edges (one from xj to xk andanother from xk to xj), both of which have weightsim(xj , xk).
A cut in G is defined as a partition ofthe nodes into two sets, S and T , such that s ?
S,t ?
T ; and the cost of the cut, cost(S, T ), is thesum of the weights of the edges going from S toT .
A minimum cut is a cut that has the lowest costamong all the cuts of G. It can be proved that find-ing a minimum cut of G is equivalent to minimizingthe partition cost defined as above.
The main advan-tage of recasting the above minimization problem asa graph-cut problem is that there exist polynomial-time maxflow algorithms for finding a minimum cut.4.2 Graph ConstructionNext, we show how to construct the graph to whichthe mincut-finding algorithm will be applied.
Theultimate goal is to use the mincut finder to parti-tion a given set of mentions into two subsets, so thatour coreference system will attempt to resolve onlythose mentions that are in the subset correspond-ing to ANAPHORIC.
In other words, the resulting579anaphoricity information will be used to identify andfilter non-anaphoric mentions prior to coreferenceresolution.
The graph construction process, whichtakes as input a set of mentions in a test text, is com-posed of three steps, as described below.Step 1: Mimicking Ng and Cardie (2002a)To construct the desired graph, G, we first createthe source, s, and the sink, t, that represent theclasses ANAPHORIC and NOT ANAPHORIC, respec-tively.
Then, for each mention mn in the input text,we create one node, n, and two edges, sn and nt,connecting n to s and t. Next, we compute wsnand wnt, the weights associated with sn and nt.A natural choice would be to use PA(mn) as theweight of sn and (1?wsn) as the weight of nt.
(Wewill assume throughout that wnt is always equal to1 ?
wsn.)
If we apply the mincut finder to the cur-rent G, it should be easy to see that (1) any noden where wsn > 0.5 will be assigned to s, (2) anynode n where wsn < 0.5 will be assigned to t,and (3) any remaining node will be assigned to oneof them.
(Without loss of generality, we assumethat such nodes are assigned to s.) Hence, the setof mentions determined as anaphoric by the mincutfinder is identical to the set of mentions classified asanaphoric by PA, thus yielding a coreference systemthat is functionally equivalent to N&C?s.
This alsoimplies that G shares the same potential weaknessas PA: being overly conservative in determining amention as anaphoric.Step 2: Mimicking Ng (2004)One way to ?improve?
G is to make it functionallyequivalent to Ng?s (2004) approach.
Specifically,our goal in Step 2 is to modify the edge weights inG (without adding new edges or nodes) such that themincut finder classifies a node n as anaphoric if andonly if PA(mn) ?
c for some c ?
[0, 1].
Now, recallfrom Step 1 that the mincut finder classifies a noden as anaphoric if and only if wsn ?
0.5.
Hence,to achieve the aforementioned goal, we just need toensure the property that wsn ?
0.5 if and only ifPA(mn) ?
c. Consequently, we compute wsn usinga sigmoid function:wsn = 11 + e???
(PA(mn)?c)where ?
is a constant that controls the ?steepness?of the sigmoid.3 It should be easy to verify that thesigmoid satisfies the aforementioned property.
Asnoted before, wnt = 1 ?
wsn for each node n. In-spired by Ng (2004), the value of the parameter cwill be tuned based on held-out development data tomaximize coreference performance.Step 3: Incorporating coreference probabilitiesLike Ng?s (2004) approach, the current G suffersfrom the weakness of not exploiting the pairwiseprobabilities provided by PC .
Fortunately, theseprobabilities can be naturally incorporated into G assimilarity scores.
To see why these pairwise prob-abilities are potentially useful, consider two men-tions, mi and mj , in a text D that are coreferent andare both anaphoric.
Assume that the graph G con-structed from D has these edge weights: wsi = 0.8,wsj = 0.3, and wij = wji = 0.8.
Without the sim-ilarity scores, the mincut finder will correctly deter-mine mi as anaphoric but incorrectly classify mj asnon-anaphoric.
On the other hand, if the similarityscores are taken into account, the mincut finder willcorrectly determine both mentions as anaphoric.The above discussion suggests that it is desirableto incorporate edges between two nodes, i and j,when mi and mj are likely to be coreferent (i.e.,PC(mi,mj) ?
c2 for some constant c2).
In our im-plementation, we tune this new parameter, c2, jointlywith c (see Step 2) on development data to maxi-mize coreference performance.
While it is possibleto imagine scenarios where incorporating pairwiseprobabilities is not beneficial, we believe that theseprobabilities represent a source of information thatcould be profitably exploited via learning appropri-ate values for c and c2.43One of the main reasons why we use a sigmoid function(rather than a linear function) is that the weights will still fallwithin the [0, 1] interval after the transformation, a property thatwill turn out to be convenient when the pairwise coreferenceprobabilities are incorporated (see Step 3).
?
is chosen so thatthe difference between two weights after the transformation isas close as possible to their difference before the transformation.With this criterion in mind, we set ?
to 0.42 in our experiments.4Incorporating the coreference probabilities can potentiallyidentify some of the anaphoric mentions that would be misclas-sified otherwise.
However, note that the minimum cut algorithmdoes not maintain the notion of directionality that would allowone to determine that a discourse-new mention (i.e., the firstmention of a coreference chain) is not anaphoric.
In particu-lar, the algorithm tends to classify all members of a coreferencechain, including the first mention, as anaphoric.
We did not ex-5805 Evaluation5.1 Experimental SetupFor evaluation, we use the ACE Phase II coreferencecorpus, which is composed of three sections: Broad-cast News (BNEWS), Newspaper (NPAPER), andNewswire (NWIRE).
Each section is in turn com-posed of a training set and a test set.
For eachsection, we train an anaphoricity model, PA, anda coreference model, PC , on the training set, andevaluate PC (when used in combination with differ-ent approaches to anaphoricity determination) on thetest set.
As noted before, the mentions used are ex-tracted automatically using an in-house NP chunker.Results are reported in terms of recall (R), precision(P), and F-measure (F), obtained using two corefer-ence scoring programs: the MUC scorer (Vilain etal., 1995) and the CEAF scorer (Luo, 2005).5.2 Results and Discussions?No Anaphoricity?
baseline.
Our first baseline isthe learning-based coreference system described inSection 2, which does not employ any anaphoric-ity determination algorithm.
Results using the MUCscorer and the CEAF scorer are shown in row 1 ofTables 1 and 2, respectively.
As we can see, MUCF-score ranges from 55.0 to 61.7 and CEAF F-scoreranges from 55.3 to 61.2.Duplicated Ng and Cardie (2002a) baseline.Next, we evaluate our second baseline, which isN&C?s coreference system.
As seen from row 2 ofTables 1 and 2, MUC F-score ranges from 50.5 to60.0 and CEAF F-score ranges from 54.5 to 59.4.In comparison to the first baseline, we see drops inF-score in all cases as a result of considerable pre-cipitation in recall, which can in turn be attributedto the misclassification of many anaphoric mentionsby the anaphoricity model.
More specifically, MUCF-score decreases by 1.7?5.5%, whereas CEAF F-score decreases by 0.5?1.8%.
These trends are con-sistent with those reported in N&C?s paper.Duplicated Ng (2004) baseline.
Our third base-line is Ng?s (2004) coreference system.
Recall thatthis resolver requires the tuning of the conservative-ness parameter, c, on held-out data.
To ensure a faircomparison between different resolvers, we do notplicitly address this issue, simply letting the coreference clus-tering algorithm discover that first mentions are non-anaphoric.rely on additional data for parameter tuning.
Rather,we reserve 13 of the available training data for tuningc, for which we tested values from 0 to 1 in steps of0.01, and use the remaining 23 of the data for trainingPA and PC .
Results are shown in row 3 of Tables1 and 2, where MUC F-score ranges from 57.0 to61.9 and CEAF F-score ranges from 55.5 to 60.6.
Incomparison to the first baseline, we obtain mixed re-sults: MUC F-score increases by 2.0% and 0.2% forBNEWS and NPAPER, respectively, but drops by0.1% for NWIRE; CEAF F-score increases by 0.2%and 1.1% for BNEWS and NPAPER, respectively,but drops by 0.6% for NWIRE.Duplicated Luo (2007) baseline.
Results of ourfourth baseline, in which the anaphoricity and pair-wise coreference probabilities are combined to scorea partition using Luo?s system, are shown in row 4of Tables 1 and 2.
Here, we see that MUC F-scoreranges from 55.8 to 62.1 and CEAF F-score rangesfrom 56.3 to 61.5.
In comparison to the first base-line, performance improves, though insignificantly,5in all cases: MUC F-score increases by 0.2?0.8%,whereas CEAF F-score increases by 0.3?1.0%.Duplicated Denis and Baldridge (2007) base-line.
Our fifth baseline performs joint inferencefor anaphoricity determination and coreference res-olution using D&B?s ILP approach.
Results areshown in row 5 of Tables 1 and 2, where MUCF-score ranges from 56.2 to 63.8 and CEAF F-score ranges from 56.9 to 61.5.
In comparison tothe first baseline, MUC F-score always increases,with improvements ranging from 1.2% to 2.1%.CEAF results are mixed: F-score increases signifi-cantly for BNEWS, drops insignificantly for NPA-PER, and rises insignificantly for NWIRE.
The dif-ference in performance trends between the two scor-ers can be attributed to the fact that the MUCscorer typically under-penalizes errors due to over-merging, which occurs as a result of D&B?s usingthe aggressive-merge clustering algorithm.
In addi-tion, we can see that D&B?s approach performs atleast as good as Luo?s approach in all but one case(NPAPER/CEAF).Duplicated Finkel and Manning (2008) baseline.Our sixth baseline is F&M?s coreference system,5Like the MUC organizers, we use Approximate Random-ization (Noreen, 1989) for significance testing, with p=0.05.581Broadcast News Newspaper NewswireApproach to Anaphoricity Determination R P F R P F R P F1 No Anaphoricity 57.7 52.6 55.0 60.8 62.6 61.7 59.1 58.1 58.62 Duplicated Ng and Cardie (2002a) 40.3 67.7 50.5?
52.1 70.6 60.0 43.0 69.3 53.1?3 Duplicated Ng (2004) 51.9 63.2 57.0 60.0 63.8 61.9 59.3 57.7 58.54 Duplicated Luo (2007) 55.4 56.1 55.8 60.6 63.7 62.1 58.4 59.2 58.85 Duplicated Denis and Baldridge (2007) 57.3 55.1 56.2?
63.8 63.7 63.8?
60.4 59.3 59.8?6 Duplicated Finkel and Manning (2008) 56.4 55.3 55.8 63.8 63.7 63.8?
59.7 59.2 59.57 Graph Minimum Cut 53.1 67.5 59.4?
57.9 71.2 63.9?
54.1 69.0 60.6?Table 1: MUC scores for the three ACE data sets.
F-scores that represent statistically significant gains and drops withrespect to the ?No Anaphoricity?
baseline are marked with an asterisk (*) and a dagger (?
), respectively.Broadcast News Newspaper NewswireApproach to Anaphoricity Determination R P F R P F R P F1 No Anaphoricity 63.2 49.2 55.3 64.5 54.3 59.0 67.3 56.1 61.22 Duplicated Ng and Cardie (2002a) 55.9 53.3 54.5 60.7 56.3 58.5 60.6 58.2 59.43 Duplicated Ng (2004) 62.5 49.9 55.5 63.5 57.0 60.1 65.6 56.3 60.64 Duplicated Luo (2007) 62.7 51.1 56.3 64.6 55.4 59.6 67.0 56.8 61.55 Duplicated Denis and Baldridge (2007) 63.8 51.4 56.9?
62.6 53.6 57.8 67.0 56.8 61.56 Duplicated Finkel and Manning (2008) 63.2 51.3 56.7?
62.6 53.6 57.8 66.7 56.7 61.37 Graph Minimum Cut 61.4 57.6 59.4?
64.1 59.4 61.7?
65.7 61.9 63.8?Table 2: CEAF scores for the three ACE data sets.
F-scores that represent statistically significant gains and drops withrespect to the ?No Anaphoricity?
baseline are marked with an asterisk (*) and a dagger (?
), respectively.which is essentially D&B?s approach augmentedwith transitivity constraints.
Results are shown inrow 6 of Tables 1 and 2, where MUC F-score rangesfrom 55.8 to 63.8 and CEAF F-score ranges from56.7 to 61.3.
In comparison to the D&B baseline, wesee that F-score never improves, regardless of whichscoring program is used.
In fact, recall slightly de-teriorates, and this can be attributed to F&M?s ob-servation that transitivity constraints tend to producesmaller clusters.
Overall, these results suggest thatenforcing transitivity for coreference resolution isnot useful for improving coreference performance.Our graph-cut-based approach.
Finally, weevaluate the coreference system using the anaphoric-ity information provided by our cut-based approach.As before, we reserve 13 of the training data forjointly tuning the two parameters, c and c2, and usethe remaining 23 for training PA and PC .
For tun-ing, we tested values from 0 to 1 in steps of 0.1 forboth c and c2.
Results are shown in row 7 of Ta-bles 1 and 2.
As we can see, MUC F-score rangesfrom 59.4 to 63.9 and CEAF F-score ranges from59.4 to 63.8, representing a significant improvementover the first baseline in all six cases: MUC F-scorerises by 2.0?4.4% and CEAF F-score rises by 2.6?4.1%.
Such an improvement can be attributed to alarge gain in precision and a smaller drop in recall.This implies that our mincut algorithm has success-fully identified many non-anaphoric mentions, butin comparison to N&C?s approach, it misclassifiesa smaller number of anaphoric mentions.
Moreover,our approach achieves the best F-score for each data-set/scoring-program combination, and significantlyoutperforms the best baseline (D&B) in all but twocases, NPAPER/MUC and NWIRE/MUC.6 ConclusionsWe have presented a graph-cut-based approach toanaphoricity determination that (1) directly opti-mizes the desired coreference evaluation metricthrough parameterization and (2) exploits the proba-bilities provided by the coreference model when co-ordinating anaphoricity and coreference decisions.Another major contribution of our work is the em-pirical comparison of our approach against five ex-isting approaches to anaphoricity determination interms of their effectiveness in improving a coref-erence system using automatically extracted men-tions.
Our approach demonstrates effectiveness androbustness by achieving the best result on all threeACE data sets according to both the MUC scorerand the CEAF scorer.
We believe that our cut-basedapproach provides a flexible mechanism for co-ordinating anaphoricity and coreference decisions.582AcknowledgmentsWe thank the three anonymous reviewers for theirinvaluable comments, Kazi Saidul Hasan for hishelp on using lp solve, and NSF for its gracious sup-port of this work under Grant IIS-0812261.
The de-scription of the minimum cut framework in Section4.1 was inspired by Pang and Lee (2004).ReferencesD.
Bean and E. Riloff.
1999.
Corpus-based identificationof non-anaphoric noun phrases.
In Proc.
of the ACL,pages 373?380.A.
Berger, S. Della Pietra, and V. Della Pietra.
1996.
Amaximum entropy approach to natural language pro-cessing.
Computational Linguistics, 22(1):39?71.S.
Bergsma, D. Lin, and R. Goebel.
2008.
Distributionalidentification of non-referential pronouns.
In Proc.
ofACL-08:HLT, pages 10?18.S.
Della Pietra, V. Della Pietra, and J. Lafferty.
1997.Inducing features of random fields.
IEEE Transac-tions on Pattern Analysis and Machine Intelligence,19(4):380?393.P.
Denis and J. Baldridge.
2007.
Global, joint determina-tion of anaphoricity and coreference resolution usinginteger programming.
In Proc.
of NAACL/HLT, pages236?243.M.
Elsner and E. Charniak.
2007.
A generativediscourse-new model for text coherence.
TechnicalReport CS-07-04, Brown University.R.
Evans.
2001.
Applying machine learning toward anautomatic classification of it.
Literary and LinguisticComputing, 16(1):45?57.J.
R. Finkel and C. Manning.
2008.
Enforcing transitiv-ity in coreference resolution.
In Proc.
of ACL-08:HLTShort Papers (Companion Volume), pages 45?48.C.
Kennedy and B. Boguraev.
1996.
Anaphor for every-one: Pronominal anaphora resolution without a parser.In Proc.
of COLING, pages 113?118.S.
Lappin and H. Leass.
1994.
An algorithm for pronom-inal anaphora resolution.
Computational Linguistics,20(4):535?562.X.
Luo, A. Ittycheriah, H. Jing, N. Kambhatla, andS.
Roukos.
2004.
A mention-synchronous corefer-ence resolution algorithm based on the Bell tree.
InProc.
of the ACL, pages 135?142.X.
Luo.
2005.
On coreference resolution performancemetrics.
In Proc.
of HLT/EMNLP, pages 25?32.X.
Luo.
2007.
Coreference or not: A twin modelfor coreference resolution.
In Proc.
of NAACL-HLT,pages 73?80.C.
Mu?ller.
2006.
Automatic detection of nonreferential itin spoken multi-party dialog.
In Proc.
of EACL, pages49?56.V.
Ng.
2007.
Shallow semantics for coreference resolu-tion.
In Proceedings of IJCAI, pages 1689?1694.V.
Ng and C. Cardie.
2002a.
Identifying anaphoric andnon-anaphoric noun phrases to improve coreferenceresolution.
In Proc.
of COLING, pages 730?736.V.
Ng and C. Cardie.
2002b.
Improving machine learn-ing approaches to coreference resolution.
In Proc.
ofthe ACL, pages 104?111.V.
Ng.
2004.
Learning noun phrase anaphoricity to im-prove conference resolution: Issues in representationand optimization.
In Proc.
of the ACL, pages 151?158.E.
W. Noreen.
1989.
Computer Intensive Methods forTesting Hypothesis: An Introduction.
John Wiley &Sons.C.
Paice and G. Husk.
1987.
Towards the automaticrecognition of anaphoric features in English text: theimpersonal pronoun ?it?.
Computer Speech and Lan-guage, 2.B.
Pang and L. Lee.
2004.
A sentimental education:Sentiment analysis using subjectivity summarizationbased on minimum cuts.
In Proc.
of the ACL, pages271?278.M.
Poesio, O. Uryupina, R. Vieira, M. Alexandrov-Kabadjov, and R. Goulart.
2004.
Discourse-new de-tectors for definite description resolution: A surveyand a preliminary proposal.
In Proc.
of the ACL Work-shop on Reference Resolution.S.
P. Ponzetto and M. Strube.
2006.
Exploiting semanticrole labeling, WordNet and Wikipedia for coreferenceresolution.
In Proc.
of HLT/NAACL, pages 192?199.W.
M. Soon, H. T. Ng, and D. Lim.
2001.
A machinelearning approach to coreference resolution of nounphrases.
Computational Linguistics, 27(4):521?544.O.
Uryupina.
2003.
High-precision identification of dis-course new and unique noun phrases.
In Proc.
of theACL Student Research Workshop.Y.
Versley, A. Moschitti, M. Poesio, and X. Yang.
2008.Coreference systems based on kernels methods.
InProc.
of COLING, pages 961?968.R.
Vieira and M. Poesio.
2000.
Processing definite de-scriptions in corpora.
In S. Botley and A. McEnery,editors, Corpus-based and Computational Approachesto Discourse Anaphora, pages 189?212.
UCL Press.M.
Vilain, J. Burger, J. Aberdeen, D. Connolly, andL.
Hirschman.
1995.
A model-theoretic coreferencescoring scheme.
In Proc.
of MUC-6, pages 45?52.B.
L. Webber.
1979.
A Formal Approach to DiscourseAnaphora.
Garland Publishing, Inc.X.
Yang and J. Su.
2007.
Coreference resolution usingsemantic relatedness information from automaticallydiscovered patterns.
In Proc.
of ACL, pages 528?535.583
