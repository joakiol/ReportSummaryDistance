Semantic Parsing for Biomedical Event ExtractionDeyu Zhou1 and Yulan He21School of Computer Science and Engineering, Southeast University,China2Knowledge Media Institute, The Open University, UKAbstractWe propose a biomedical event extraction system, HVS-BioEvent, which employs the hiddenvector state (HVS) model for semantic parsing.
Biomedical events extraction needs to deal withcomplex events consisting of embedded or hierarchical relations among proteins, events, and theirtextual triggers.
In HVS-BioEvent, we further propose novel machine learning approaches for eventtrigger word identification, and for biomedical events extraction from the HVS parse results.
Ourproposed system achieves an F-score of 49.57% on the corpus used in the BioNLP?09 shared task,which is only two points lower than the best performing system by UTurku.
Nevertheless, HVS-BioEvent outperforms UTurku on the extraction of complex event types.
The results suggest that theHVS model with the hierarchical hidden state structure is indeed more suitable for complex eventextraction since it can naturally model embedded structural context in sentences.1 IntroductionIn the past few years, there has been a surge of interests in utilizing text mining techniques to pro-vide in-depth bio-related information services.
With an increasing number of publications reporting onprotein-protein interactions (PPIs), much effort has been made in extracting information from biomedicalarticles using natural language processing (NLP) techniques.
Several shared tasks, such as LLL [7] andBioCreative [4], have been arranged for the BioNLP community to compare different methodologies forbiomedical information extraction.Comparing to LLL and BioCreative which primarily focus on a simple representation of relations ofbio-molecules, i.e.
protein-protein interaction, the BioNLP?09 Shared Task [5] involves the recognitionof bio-molecular events in scientific abstracts, such as gene expression, transcription, protein catabolism,localization and binding, plus (positive or negative) regulation of proteins.
The task concerns the detailedbehavior of bio-molecules, and can be used to support the development of biomedical-related databases.In the BioNLP?09 shared task evaluation, the system constructed by UTurku [2] achieved an F-score of51.95% on the core task, the best results among all the participants.In this paper, we describe a system, called HVS-BioEvent, which employs the hidden vector statemodel (HVS) to automatically extract biomedical events from biomedical literature.
The HVS model hasbeen successfully employed to extract PPIs [9].
However, it is not straightforward to extend the usageof the HVS model for biomedical events extraction.
There are two main challenges.
First, comparingto the trigger words used for PPIs which are often expressed as single words or at most two words, thetrigger words for biomedical event are more complex.
For example, controlled at transcriptional andpost-transcriptional levels, spanning over 6 words, is considered as the trigger word for the regulationevent.
In addition, the same word can be the trigger word for different types of biomedical events indifferent context.
Second, biomedical events consist of both simple events and complex events.
Whilesimple events are more similar to PPIs which only involve binary or pairwise relations, complex eventsinvolve both n-ary (n > 2) and nested relations.
For example, a regulation event may take anotherevent as its theme or cause which represents a structurally more complex relation.
Being able to handleboth simple and complex events thus poses a huge challenge to the development of our HVS-BioEventsystem.The rest of the paper is organized as follows.
Section 2 presents the overall process of the HVS-BioEvent system, which consists of three steps, trigger words identification, semantic parsing based on395the HVS model, and biomedical events extraction from the HVS parse results.
Experimental results arediscussed in section 3.
Finally, section 4 concludes the paper.2 Biomedical Event ExtractionWe perform biomedical event extraction with the following steps.
At the beginning, abstracts are re-trieved from MEDLINE and split into sentences.
Protein names, gene names, trigger words for biomed-ical events are then identified.
After that, each sentence is parsed by the HVS semantic parser.
Finally,biomedical events are extracted from the HVS parse results using a hybrid method based on rules andmachine learning.
All these steps process one sentence at a time.
Since 95% of all annotated eventsare fully annotated within a single sentence, this does not incur a large performance penalty but greatlyreduces the size and complexity of the problem.
The remainder of the section will discuss each of thesteps in details.2.1 Event Trigger Words IdentificationEvent trigger words are crucial to biomedical events extraction.
In our system, we employ two ap-proaches for event trigger words identification, one is a hybrid approach using both rules and a dictio-nary, the other treats trigger words identification as a sequence labeling problem and uses a MaximumEntropy Markov Model (MEMM) to detect trigger words.For the hybrid approach using both rules and a dictionary, firstly, we constructed a trigger dictionaryfrom the original GENIA event corpus [6] by extracting the annotated trigger words.
These trigger wordswere subsequently lemmatized and stemmed.
However, the wide variety of potential lexicalized triggersfor an event means that lots of triggers lack discriminative power relative to individual event types.
Forexample, in certain context, through is the trigger word for the binding event type and are is the triggerword for localization.
Such words are too common and cause potential ambiguities and therefore lead tomany false positive events extracted.
We could perform disambiguation by counting the co-occurrenceof a event trigger and a particular event type from the training data and discard those event triggers whoseco-occurrence counts are lower than certain threshold for that event type.
After this filtering stage, still,there might be cases where one trigger might representing multiple event types, we thus define a set ofrules to further process the trigger words matched from the constructed dictionary.In the second approach, we treat trigger words identification as a sequence labeling problem and traina first-order MEMM model [8] from the BioNLP?09 shared task training data.
As in typical named entityrecognition tasks, the training data are converted into BIO format where ?B?
refers to the word which isthe beginning word of an event trigger, ?I?
indicates the rest of the words (if the trigger contains morethan one words) and ?O?
refers to the other words which are not event triggers.
The features used in theMEMM model was extracted from the surface string and the part-of-speech information of the wordscorresponding to (or adjacent to) the target BIO tags.2.2 Semantic Parsing using the HVS ModelThe Hidden Vector State (HVS) model [3] is a discrete Hidden Markov Model (HMM) in which eachHMM state represents the state of a push-down automaton with a finite stack size.
State transitionsare factored into separate stack pop and push operations constrained to give a tractable search space.The sequence of HVS stack states corresponding to the given parse tree is illustrated in Figure 1.
Theresult is a model which is complex enough to capture hierarchical structure but which can be trainedautomatically from only lightly annotated data.In the HVS-based semantic parser, conventional grammar rules are replaced by three probabilitytables.
Let each state at time t be denoted by a vector of Dt semantic concept labels (tags) ct =[ct[1], ct[2], ..ct[Dt]] where ct[1] is the preterminal concept label and ct[Dt] is the root concept label(SS in Figure 3).
Given a word sequence W , concept vector sequence C and a sequence of stack popoperations N , the joint probability of P (W,C, N) can be decomposed asP (W,C, N) =T?t=1P (nt|ct?1)P (ct[1]|ct[2 ?
?
?Dt])P (wt|ct) (1)396enhanced tyrosine phosphorylation of STAT1Positive_regulationPhosphorylationSiteProteinDummyPositive_regulationSSSitePositive_regulationSSPhosphorylationSitePositive_regulationSSDummyPhosphorylationSitePositive_regulationSSProteinPhosphorylationSitePositive_regulationSSIFN-alphaDummySSsent_start sent_endSSDummySS SESSSEFigure 1: Example of a parse tree and its vector state equivalent.where nt is the vector stack shift operation and takes values in the range 0, ?
?
?
, Dt?1, and ct[1] = cwt isthe new pre-terminal semantic label assigned to word wt at word position t.Thus, the HVS model consists of three types of probabilistic move, each move being determined by adiscrete probability table: (1) popping semantic labels off the stack - P (n|c); (2) pushing a pre-terminalsemantic label onto the stack - P (c[1]|c[2 ?
?
?D]); (3) generating the next word - P (w|c).
Each of thesetables are estimated in training using an EM algorithm and then used to compute parse trees at run-timeusing Viterbi decoding.
In training, each word string W is marked with the set of semantic conceptsC that it contains.
For example, the sentence IFN-alpha enhanced tyrosine phosphorylation of STAT1contains the semantic concept/value pairs as shown in Figure 1.
Its corresponding abstract semanticannotation is:Positive regulation(Site(Phosphorylation(protein)))where brackets denote the hierarchical relations among semantic concepts1.
For each word wk of atraining sentence W , EM training uses the forward-backward algorithm to compute the probability ofthe model being in stack state c when wk is processed.
Without any constraints, the set of possible stackstates would be intractably large.
However, in the HVS model this problem can be avoided by pruningout all states which are inconsistent with the semantic concepts associated with W .
The details of howthis is done are given in [3].For the sentences in the BioNLP?09 shared task, only event information is provided.
However, theabstract semantic annotation as shown above is required for training the HVS model.
We propose Algo-rithm 1 to automatically convert the annotated event information into the abstract semantic annotations.An example of how the abstract annotations are generated is given as follows.Sentence: According to current models the inhibitory capacity of I(kappa)B(alpha) would be mediatedthrough the retention of Rel/NF-kappaB proteins in the cytosol.Corresponding Events: E1 Negative regulation: inhibitory capacity Theme: I(kappa)B(alpha)E2 Positive regulation: mediated Theme: E1Candidate annotation generation (Steps 1-4 of Algorithm 1):Negative regulation(Protein) Negative regulation(Protein(Positive regulation))Abstract annotation pruning (Steps 5-14 of Algorithm 1):Negative regulation(Protein(Positive regulation))2.3 Biomedical Events Extraction From HVS Parse ResultsBased on HVS parse results, it seems straightforward to extract the event information.
However, afterdetailed investigation, we found that sentences having the same semantic tags might contain differentevents information.
For example, the two sentences shown in Table 1 have the same semantic parsingresults but with different event information.This problem can be solved by classification.
For the semantic tags which can represent multipleevent information, we considered each event information as a class and employed hiddenMarkov supportvector machines (HM-SVMs) [1] for disambiguation among possible events.
The features used in HM-SVMs are extracted from surface strings and part-of-speech information of the words corresponding to(or adjacent to) trigger words.1We omit SS and SE here which denote sentence start and end.397Algorithm 1 Abstract semantic annotation generation.Input: A sentence W =< w1, w2, ?
?
?
, wn >, and its event information Ev =< e1, e2, ?
?
?
, em >Output: Abstract semantic annotation A1: for each event ei =<Event type:Trigger words Theme:Protein name ...> do2: Sort the Trigger words, Protein name, and other arguments based on their positions in W and geta sorted list t1, t2, ..., tk3: Generate an annotation as t1(t2(..tk)), add it into the annotation list A4: end for5: for each annotation ai ?
A do6: if ai contains another event then7: Replace the event with its corresponding annotation am8: end if9: end for10: for each annotation ai ?
A do11: if ai is a subset of another annotation in A then12: Remove ai from the annotation list A13: end if14: end for15: Reorder annotations in A based on their positions in WSentence We concluded that CTCF expression and activity is con-trolled at transcriptional and post-transcriptional levelsCONCLUSION: IL-5 synthesis by human helper T cellsis regulated at the transcriptional levelParseresultsSS+Protein(CTCF) SS+Protein+Gene Expression(expression)SS+Protein+Gene Expression+Regulation( controlled...levels)SS+Protein(IL-5) SS+Protein+Gene Expression(synthesis)SS+Protein+Gene Expression+Regulation( regulated)Events E1 Gene expression:expression Theme: CTCF E1 Gene expression: synthesis Theme: IL-5E2 Regulation: controlled...levels Theme: E1 E2 Regulation: regulated Theme: E1E3 Regulation: controlled...levels Theme: CTCFTable 1: An example of the same semantic parse results denoting different event information3 Results and DiscussionExperiments have been conducted on the training data of the BioNLP?09 shared task which consists of800 abstracts.
After cleaning up the sentences which do not contain biomedical events information, 2893sentences were kept.
We split the 2893 sentences randomly into the training set and the test set at theratio of 9:1 and conducted the experiments ten times with different training and test data each round.Method Recall (%) Precision (%) F-score (%)Trigger Word IdentificationDictionary+Rules 46.31 53.34 49.57MEMM 45.43 40.91 42.99Event Extraction from HVS Parse ResultsNo classification 43.57 52.85 47.77With Classification 46.31 53.34 49.57Table 2: Experimental results based on 10 fold cross-validation.Table 2 shows the performance evaluated using the approximate recursive matching method adoptedfrom the BioNLP?09 share task evaluation mode.
To evaluate the performance impact of trigger wordidentification, we also report the overall performance of the system using the two approaches we pro-posed, dictionary+rules and MEMM.
The results show that the hybrid approach combining a triggerdictionary and rules gives better performance than MEMM which only achieved a F-score around 43%.For biomedical event extraction from HVS parse results, employing the classification method presentedin Section 2.3 improves the overall performance from 47.77% to 49.57%.The best performance that HVS-BioEvent achieved is an F-score of 49.57%, which is only two pointslower than UTurku, the best performing system in the BioNLP?09 share task.
It should be noted that ourresults are based on 10-fold cross validation on the BioNLP?09 shared task training data only since wedon?t have the access to the BioNLP?09 test set while the results generated by UTurku were evaluatedon the BioNLP?09 test set.
Although a direct comparison is not possible, we could still speculate that398Simple Events Complex EventsEvent Class HVS-BioEvent UTurku Event Class HVS-BioEvent UTurkulocalization 61.40 61.65 binding 49.90 44.41gene expression 72.44 73.90 regulation 36.57 30.52transcription 68.30 50.23 negative regulation 40.61 38.99protein catabolism 70.27 52.17phosphorylation 56.52 77.58Table 3: Per-class performance comparison in F-score (%) between HVS-BioEvent and UTurku.HVS-BioEvent is comparable to the best performing system in the BioNLP?09 shared task.The results on the five event types involving only a single theme argument are shown in Table 3as Simple Events.
For the complex events such as ?binding?, ?regulation?
and ?negative regulation?events, the results are shown in Table 3 as Complex Events.
We notice that HVS-BioEvent outperformsUTurku on the extraction of the complex event types, with the performance gain ranging between 2%and 7%.
The results suggest that the HVS model with the hierarchical hidden state structure is indeedmore suitable for complex event extraction since it could naturally model embedded structural context insentences.4 ConclusionsIn this paper, we have presented HVS-BioEvent which uses the HVS model to automatically extractbiomedical events from text.
The system is able to offer comparable performance compared with thebest performing system in the BioNLP?09 shared task.
Moreover, it outperforms the existing systemson complex events extraction which shows the ability of the HVS model in capturing embedded andhierarchical relations among named entities.
In future work we will explore incorporating arbitrarylexical features into the HVS model training in order to further improve the extraction accuracy.References[1] Y. Altun, I. Tsochantaridis, and T. Hofmann.
Hidden markov support vector machines.
In Interna-tional Conference in Machine Learning, pages 3?10, 2003.
[2] Jari Bjorne, Juho Heimonen, Filip Ginter, Antti Airola, Tapio Pahikkla, and Tapio Salakoski.
Extract-ing complex biological events with rich graph-based feature sets.
In Proceedings of the Workshopon BioNLP, pages 10?18, 2009.
[3] Yulan He and Steve Young.
Semantic processing using the hidden vector state model.
ComputerSpeech and Language, 19(1):85?106, 2005.
[4] Lynette Hirschman, Alexander Yeh, Christian Blaschke, and Alfonso Valencia.
Overview of biocre-ative: critical assessment of information extraction for biology.
BMC Bioinformatics, 2005.
[5] Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshinobu Kano, and Jun?ichi Tsujii.
Overview ofbionlp?09 shared task on event extraction.
In Proceedings of the Workshop on BioNLP, pages 1?9,2009.
[6] Jin-Dong Kim, Tomoko Ohta, and Jun?ichi Tsujii.
Corpus annotation for mining biomedical eventsfrom literature.
BMC Bioinformatics, 9(10), 2008.
[7] Claire Ne?dellec.
Learning Language in Logic - Genic Interaction Extraction Challenge.
In LearningLanguage in Logic workshop (LLL05), pages 31?37, 2005.
[8] Nam Nguyen and Yunsong Guo.
Comparisons of sequence labeling algorithms and extensions.
InProceedings of the ICML, pages 681?688, 2007.
[9] Deyu Zhou, Yulan He, and Chee Keong Kwoh.
Extracting protein-protein interactions from medlineusing the hidden vector state model.
International Journal of Bioinformatics Research and Applica-tions, 4(1):64?80, 2008.399
