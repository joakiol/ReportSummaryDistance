SAGE :a Sentence Parsing and Generation SystemJean-Marie Lancel, Miyo Otani, Nathalie ShnoninUsp Sogeti Innoestion118 rue de Tocque~ille, 75017 Pads, FranceE-mail: lancelOcsinn.uucp, otaniOc~inn.uucp, ~imon~tOcsin~t.eu~pLaurence DanlosLADL - UNRSTour Ueatrale, Uni~er~itg Pads VII, ,\[ piac~ Ju~i~u, 75005 Pariz, FranceAbstracts:SAG~ (Sentence Analysis and GEneration system)is an operational parsing and generating system.
Itis used as a Natural Language Frontend for Espritproject Eeteam-316, whose purpose is to advise anovice user through a cooperative dialogue.The aim of our system is to validate the use of aLexice)n-Grammar (drawn from the LADL studies)ior sentence-parsing and generation, and to imple~~aent )~nguistic knowledge in a declarative way u~-ing a formMism based upon Functional Descrip-tions (FD).
We have ales devvloped the parser andthe g~ueratio~ module so that they share informa~tion~ and knowledge bases as much as possible:they work on the same semazLtic dictionary andthe same linguistic knowledge bases, except th~they kave their own graznmar.
We have also iresp|emented a tracking of semantic objects that havebeen f~istantiated during a dialogue session: the so-called Token History is provided for semantic ref-vrence and anaphor resolution during parsing andfor pronoun production during generation.After introducing to Esteam-316, this paper de-,cribelJ the ~nguistic knowledge bases required bySAGE, and then foctmes on the Generation Mod-nleo Sv.ctlon 4 explains how pronouns are handled.The last section is a brief evaluation of our presentWO1"k  o:t ~introduction to the appli-cat io l i  of SAGE_ ne pro'sing and generating system described here~ used as a Natural Language Frontend for F~.,prlt project Esteam-316, which is an Advice-Gi~ring system \[Decitre 871 \[Bruffaerts 86\]0 A coopera-tive interactive Man-Machine Interface carries outdialogue functionalities such as recognition of userqueries, explanation of domaln~concepts, explana-tion of solutions proposed by the Problem Solver,etc.
To describe it briefly, this Dialogue Managerhandles the pragmatic level of a dialogue, wherea~the Natural Language Frontend SAGE deals withlinguistic inferences?
The chosen l~guage is }~n-glish.The Dialogue Manager and SAGS ~h~re the samelemantic objects, using a formalism b~ed uponFunctional Descriptions (FD~) \[Kay 81\].
The Parserof SAGE extracts the met~uing of the user's querymad represents it with nested FDs.
Ox~ the otherhand, the Dialogue Manager sends the GeneratorFDs which describe the semantic onte, nts of theanswer.Our previous work \[Lancel 86\] was based on a uni-que dictionary and a granunar shared by both aparser and a generation module.
The grammarformalism required the mixing of syntactic and se-mantic informations in the same structure, whichimplied the complete rewriting of grautmar whenchanging from one application domain to another.It could not handle transformational processes suchas interrogative and imperative transformations?The system presented here fulfills the four follow-ing requirements:1. definition of linguistic knowledge bases quit?able for both parsing and generation;2. integration of lexicon-grammar theory intothe previous fortnalism, in order to provideprecise syntactic information;8. modulari~ation: a change of application359should not lead to a complete rewriting, butonly to an extension of the semantic levels;4. proper pronoun h~dl ing, both when parsingI reference resolution) and when generating pronoun synthesis).The section 2 describes the linguistic dictionariesof SAGE.
The section 3 explains how those dictio-naries are exploited by the generation module.
Inthe section 4, we will detail what kind of processesare required by pronoun handling.2 L ingu is t i c  knowledge  basefor  pars ing  and  generat ionThere are three linguistic levels handled by our sys~tern: morphological, syntactic, and lastly semantic.The first one will not be explained here, since theost innovative aspects of our linguistic knowledgees are provided by the two other levels: we areable to take into account a wide range of cons-tructions of a given language using the lexicon~grammar and we use a totally declarative formal-ism.2 .1  Pars ing  versus  generat ionThe main feature of SAGE is that the Parsingand Generation processed are carr iedout using thesame dictionaries.These dictionaries are interpreted by two separategrammars, one for parsing and one for generation,both of them being language-dependent bu  notlencies, with differeht levels of correctne~ for pa~sing and generation.
This allows a very wide ra~tgeof sentence structures in generation, and semanticinferences to avoid ambiguities.
The LADL Le~iocon-Grammar covers nearly all French constr~c~tione.
As far as we know, an equlvaIent amountof work is still not available for English.
There~fore, we developed a Lexicon~Grammar cont~mga few English verbs and nouns.
The correspondingconstructions are drawn from \[LONGMAN 81\].To give an idea of this lexicon-grammar, wepresen~below the information stored for the verb tuanto* The standaxd construction is \[ Subject ~-'Verb ~ Direct Object \];o The subject must be a bureau being; there?fore, it is a~lowed to be a noun group, but notclause or a verb phrase;, The direct object may be a human being~a *The mother wants her ch~d ~, a non-human enotity as in "He wants t im~, or a thai-clause ~ in"Mary wants that John settles down in PariS;?
The ~hat-clau~e can be reduced in the follow~ing forms:- \]Noun group -~ Adjective\] or NAd~ if theverb hf be (e.g "The teacher wants the ~ze~is~ ready/or tomorroef );- \[Verb at the complete infinitive form -~complements\] or To Vin/O if the concept of the sub?ject of this clause is the same as that of the suboject of want (e.g.
~Mary wants to settle down in- \[Noun group ~ Verb at the complete infiniotive form -\[- complements\] or NTo Vinf when thetwo subjects are different (e.g.
"Mary wants h~rfriend~ to settle down in Pari~.~);?
The whole cl~nse may be transformed intothe passive form.domain-dependent.
This is a major conclusion drawn ~ .
.
- .
.
for  she sake of read~bifity and maintenaace, vexbsfrom our studies: a parser and a generatton moo- are so,ted into different tables.
One table epecioule can hardly share the same grammar ules, forthe heuristics required by these two processes arefundamentally different.
Unlike parsing, a gener-ation process has nothing to do with a sequenceof "left-to-right ~ procedures \[Danlos 87a, Danloe87b\].
Moreover, a given heuristic of clause tran~formation is strongly dedicated to a parsing or  toa generation process (see section 3).2.2 Syntactic Knowledge Baseties several standard features, syntactic onstrucotions as well as valencies that are common to evoery verb of the same table.
For inJtaace, in ot~'lexicon-grammar, want belongs to the table t~oble_NV8 whose standard construction is ~ hur~t~subject in a noun group, with a non-humu directobject in a noun group, construction of which maybe transformed into the paasive form.Here is how one construction of the verb stunt i~coded, using Fenctional Descriptions (FD):This syntactic level is domain-independent: cons-tructions of verbs, predicative nouns and adjectivesalong with their corresponding valency are listed ina lexicon-grammar.This lexicon-grammar is based on the theory deveLoped by \[Gross 75, Gross 86\] and the studies carriedout by the LADL on French constructions.
It pro~rides accurate specifications of the acceptable va~syntax.want +~\[ table = tab.NVSlinguiettc.defln|tioa ~- clause_ws~tverb = \[ word -- want \]obJe~tl\[ duct!oa = ((Tov fo xoo) (NAdJ 100))= ((NToWf I00)) \] \]tab.NVS ~-~?360\[ .ub jec t  =\[ distribution = ((*human 100)}noun.phzmm = {(noun.phrase I00)} \]objectl =\[ distribution = ( (*non.human I00)(*human 100) }noun.phrmm = {(noun.phrase I00)} \]traneformation = ((passive 100)} \]The texical codes (NTo Vin/, To VinfO and NAd3)are specified in a FD, stating the conditions of va-lidity of the code and the consequences on the com~ponez~Lts: To VinfO should be chosen if the subjectof the current sentence and that of the main clauserepresent the same concept; in this case the subjectshouM be omitted and the verb should be in theinfinitive form.The ~umeric values ranging from 0 up to 100, is acoefficient on the correctness of the correspondingconstl~ctions.
When generating a syntactic om-ponent, lexical codes that axe allowed are the ones.4 with a coefficient greater than a certain value, 70in our implementation.
When parsing sentences,accepted constructions would be of a coefficientgreater than another milestone, 30 for instance.The values 0, 30, 70, 100 are of course quite arbi-trary.
But they allow the parsing of constructionsthat ~xe often understood by most of the peoplebut m'e syntactically incorrect: the correspondinglexica~ codes will have a coefllcient between 30 and70.2.3  Semant ic  knowledge  baseThe semantic level is highly domain-dependent sinceit dents with concepts.
The application domainchose~ by the Esteam-316 project is financial advice-giving for non-expert users.
Therefore, the Man-Machiue interface handles intention concepts suchas *serface_requeet and *surface.inform which arethe intention o/asklng/or something and the inten-tion o/stating something, financial concepts uchas *emergency_fend which is a certain amount ofmoney available at ans/ time and provided for emer-gency c~ee, and lastly domain-independent con-cepts such as *t0ant ~.Those concepts are organised in a semantic net-work, using the links/s_a and ezample.
Moreover,the semantic sub-items are specified in a aehemo.For instance, the concept *want is specified by:\[ isj~ = *po6ltionechema =\[ actor = \[ iLa = *human \]ZThe c~osen convention is to put a star a{ the begin-ning of a concept identifier, but this ls purely for thesake of readability.object \]synthesis  =( \[ Ung~istic~eflnition = clause_want \] ) \]As seen in section 2.1, the semantic objects ac~tually handled by the user and system during adialogue are called token& Inside the system, tookene are instances of concepts - -  or more preciselyd schemata ~.2.4 L ink between concepts  and  syn-tact ic  s t ructuresMapping between semantic schemata nd syntacticstructures i ,pecified in FDs named llnguiatlc def.initions, This is am important feature of our KB: itis the linguistic definitions that make explicit thecorrespondance b tween token slots and syntacticcomponents of sentences, clauses and noun groups?Using them, the same token may be synthesisedas a noun phrase or a clause, according to syntac-tic constraints.
A noun phrase or a clause requiredifferent grammar ules in the generation process.For instance, let us consider the following token :\[ insta~tce-of = *transactionbuyer = *Maryobject = *car \]It may be expressed with a clause Mary buy8 ?
car:meaning =\[ instance-of : *transactionbuyer = *Maryobject = *car \]subject = \[ meaning = *Mary \]verb = \[ word = buy \]object = \[ meaning = *car \]\]or with a noun phrase Mary% purchase of a car:.\[ meaning =\[ instance_of ---- *transactionbuyer = *Maryobject -- *Car \]subjectlve.genltive -- \[ meaning = *Mary \]predicative-noun = \[ word = purchase \]objective-complement = \[ meaning --- car \] \]The last two FDs shown above are the syntacticstructuru produced by two different linguistic defoinitions linked to the same concept *tra~sasKonoThe choice between the two is made by the genera-tion module either under semantic onstraLnts de.clared in the semantic dictionary, .or under linguis-tic restrictions pecified by the generation gram-mar, or by the lexicon-grammar.361Linguistic definitions do not only allow the synthe~sis of totally different schemata using the same gen-eration grammar rules, but also provide the parserwith extended capacities for handling complex nounphrases or sentences and for extracting a specificmeaning with the specific slot identifiers (b~yer~object, year) out of a standard syntactical cons-truction of the noun~ or verb--predicate.3 Generat ion3.1 Genera l  heur ist ic  of the Gener-at ion Modu leThe generation process is top-down, with back-tracking.
The generation algorithm consists of build-ing a complex object of several nested FDs recur-sively.The highest level deals with the surface syntac-tic form: assertion, question, order.
This levelcorresponds to the intention concepts like *sur-face_request Then comes the inner structure ofthe sentence: generally speaking, a subject, a verband objects with several optional adverbials.
Thiscorresponds to doma~n-~oncepts (e.g, *smerfen.cy_/~nd} or general concepts (e.g.
*~ant).
LMtlythere is the noun group structure with preposition,determiner, noun.
There is ~ specific grammar rulefor each level.Briefly, a gr~nmax rule specifies under what con~ditions a given rule may be applied, what kindsof rules are to be chosen for the synthesis of eachSyntactic Component, and what actions are to becarried out on the structure (such as choosing thenumber and person of a verb according to the sub-ject within a sentence}.# ?The current level is built in a loop starting from itssemantic ontents (a token}: through the conceptcorresponding to the token, the interpreter choosesa linguistic definition, then a syntactic structure inthe lexicon-grammar.These FDs plus the corresponding grammar uleare functionally unified ~ with the current object.Then, one syntactic ode such as To Vin\]O or ~ou~-phrase is chosen according to the grmmmar rule andthe validity condition of the code.
The FD of th~code is unified with the current object.This is where our declarative KBs baaed on Func-tional Descriptions prove to be ei~cient.
The smn~heuristic based on functional unification is used fortotally different structures uch as noun phrase orclause.
Therefore, this loop is allowed to be totallyrecursive.~n the meaning of yunctional ~nificai~on \[Kay 81\].At this stage of the process, the generation modulomay add several modifiers to the current level~ thatare adverbi~d~ in sentences, or adjectives in ~oungroups: this adjunction is a\]~o carried through f~u~cotional unification since the modifiers ~e also d~scribed in a FD just like any grammsx rule or le)~ical code.For instance after functional unifications, the cur~rent syntactic component corresponding to ~\[ ~a~ear" is:memdng =\[ inatance~of = ~w~tactor ~ ~u~subject\[ memah~g = *u~rdistribution = {(*human 100))noun~ph~a~ = {(noun-ph~ 100)} \]vorb = \[ wo~ = w~nt \]object1 =\[ meaning = \[ i~ta~c~.~ ~ *c~ \]distributlon = { (*noLkuman I00)(?~u~n ~oo)}reduction = ( (ToVinf0 100)(NAdj 100))clause = ((lgToVlnf X00))noun.phr~m -~ {(noun-phr~mtransformation -- ((pmmlvel 100)) \]00))x \]Then trmmfomations are processed whenewr theyare needed, such as for questions (which puts theverb in the interrogative form and inserts an ~ux-iliary verb before the subject), or negations or pa~sive transformations, ~ranaformations are speci~fled in FDs similar to grammar rules, with validityconditious and actions,,but also with a specific slotstating whether they must be applied befm'e or ~-ter the standard grammar rules.Thk  synthesk loop k carried out on every nynt~cotic suN-component, that is for instance on subject~verb ud  objects of a clause.If every sub-component is cmTectly synthesised inturn, the actions of the global rule are applied o~the current component.Other tran~ormations may be cL~ri~cl out, lead~ing only to the re, ordering of objects in a clauM,which may depend on whether the objects ere ex~pre~ed through pronouu.
A ditransitive/dat~vetransformation is a perfect example: st~rtlng froma sentence whose meaning is "The poslman f~ea\]t~c~'y l~.e letts~,, the final sentence may becmn~~The postman gi~es her the l~teP or ~The po~o.ma~ fg~ea it ~o Mar l  or " The postmaa gi~es i~ ~heP .There ends the body of the loop.
If a failure o~curs during this loop, backtracking choose~ anotherlinguistic definition ~d/or  .another grammar ruleo362texte~ generat iox~~?h?
f?,llowing token, ~tade of several n~ted toke~,sya~heahed ~ a~nder athat delay d~ you wat~~oar ~t~erCen~ fund a~ailablef~ i~:\[ ha~t~ur~f =~ %~x~3quost~oa~r = %yetem~or?~ = weakproposition =propoa|tlo~ =\[ h~tan~of= *w~utpropo~itlon =\[ h~stance~of = *e~erg~ncyAundagent = *ueerdelay =- *unknown \ ] I l lThe ,~ombintgio~ of the tokems %ur/aee.~cqge~ a~d'~in/o~c~.r~/produc?~ a Wh-questiono The questionfocut~ on the delay of the token *emercency~und~di,~r,d by ~he special object %akno~: ~histr~ffm~m the ~IverbiM of delay of the ~trncture~th~ ~n~rgeney fund is available ~t dd d~y~ intogh~ ~po~nd ~nt~rrogative pronoun ~der  t~lmftd~l~, ~h~ ~t~_~c~ga~ive pronoun b~ moved to th~b~g~,~ing ~' th~ ~ntence, coming from the n~tedae~c~ fu~ a~a~bl~ f. As the verb of the e la~?gpr~:a~ing the token %mtrf/sgty..fu~gd is ~o ge, theco.traction adopted for the direct object of theverb ~#s~t is NAd~: th~ verb ?0 h~ is removed.
Thep~s~,ive your is synthesised from the slot a~en~of th~ token %m~rqenc~/.~endoronoun handling par oand generatio~th~ ?
~guh~ic ~brmation ~ needed for referencex~so\]utlOno The ehsracteristic~ stored for each to-ken are the tm~t ~mnber within the dialogue (~turn ie over whenever one of the two locutors ha~fiuished speaking), the sentence number within thetm~n~ the locutor (during pa~sing, the locutor isthe ~mer, where~ during gen~ation, ~t is the sys-tem), the type of the token (entity or relation)~ andthe linguistic ?xpregsion (noun phrase, pronoun,demormtrative pronoun, clause).The Token History i~ updated by three proce~se~:the parsing module, the application (here the gs-team-316 Dislogue Manager) ~nd the generation~odnle?
Of comae, it i~ vexy hnporg~nt for theDi~log~e Mauager that if one token h produced bythe parsing of one sentence, then the geueratlonmodule would synthesi~ the s~ne sentence fromthe same token.After analysis of the user~ sentence, the History isupdated with the tokens of the sentence, which areall fn~t com~idered as new.
The Dialogue Managerreceives the new tokens~ sometimea with ~ list offormer tokens to which a given new one mW refer:a typical ease i~ when a pronoun/~ found in theu~r~ sentence; th~n the parser h~ to rc~olv~ references on morpholo~c~ syntactic ~md semanticgronnds~ in order to prepare the dialcger~s prag-matic inference.
It i~ the Di~ogue Man~.ger whir.his in charge of defining the final sta~as of e~.ch newtoken through pragmatic inferences:when it corresponds to a pronoun, the toke~to which it refer8otherwise, whether it ~ a redefinition oftoken previously used, or a totally new one.If a sentence generation ~ueceeds, the generationmodule updates the History with the linguistic ~n~formation of the synthesised tokens.4o~ ~ro~oun ~ynthes is~ro~ou~ handling requires the r~cord~ag of ~l gh~~;~n~:~eI~g ~?~c~ (tokens)?
A token may be anen~y (e.g.
aa instance of the concept %at) org x'~s~io~ b~tw~en e~t ies  (e.g.
an instance dyo~ made ~ ~on~ i~es~meW~o~ thetokens are thewrong inv~tm~nt~), ~ud also the relation intro-du?,~d by Otag (?Tou made zt wrong investments),~nd the r?lation cmg'esponding to the whole ~n-Du~i~g  d~bgu% the system record8 the~e token~~ g ~b~e~ llistory.
Besides the token~ themselves,The generation grammar checks wheth~.r each itemto be generated may be ~ynthesised by ~ pronoun?The first step is to choose the appropriate prono~tno*J~he second step consists of verifying that the cho~son pronoun will not be ambiguous for the u~eraccording to the History of Token~0The computing of the morphological for~ of th~pronoun and the checking of ambiguity ~re verycomplex and require the handling of ~emantic, nywtactic and morphological constraints?
For preciseexplanations and comparison with other ~tudies,see \[Danlos 88\].3635 Evaluat ion of SAGE and itsgenerat ion ModuleThe parsing and generation grammar formalismare intended to support a changing from Englishto French.
For instance, both the order of syn-thesis of the syntactic omponents of a clause or anoun phrase and the pronoun synthesis control arespecified eclaxatively.
This allows the reusabilityand adaptability of this Natural Language Fron.tend through the creation of an adapted seman-tic dictionary and the extension of grammars, pro-vided that the application is able to make infer-ences on semantic, or even pragmatical levels (whichis the case of Eeteam-316 Dialogue Manager).SAGE runs on Sun workstations.
It is able to parsecomplex assertions (I want to buy a car in riseyears.
), Yes/No questions (Could I put 500 dol-lars into my emergency-fund~), and ar.knowlege-men~ expressions ( Yes.
No.
OK.~.rt c~m synthesise complex assertions with infini-tive clauses and adverbials, imperative sentences,Yes/No-questions, and Wh-questlons.
The inter-rogative pronouns of Wh-questions may stem ei-ther from the main clause (as in What do you buyf)or from nested clauses (as in How much do youwant to investf).
As far as we know in the genera-tion realm, it seems that the most similar work isthe synthesis system PHRED citejacobs.
Sentenceproduction in PHRED is a. recursive process di-vided into three phases: 1) pattern-concept fe ch-Lug, 2) pattern restriction, and 3) pattern interpre-tation.
Their objectives axe similar to 1) the choiceof a linguistic definition, 2) the verification of se-mantic distribution and the application of a lexicalcode on the Syntactic Component, 3) the genera-tion of the syntact sub-components.
Other studies(Danlos, McKeown, Appelt) are more related tothe strategies for text production than to sentencegeneration heuristics.It can also synthesise complex assertions with in-finitive clauses and adverbials, imperative sentences,Yes/No-questions, and Wh-questions.
The inter-rogative pronouns of Wh-questions may stem ei-ther from the main clause (as in What do you buyf}or from nested clauses (as in How much do yout~ant o investf).Pronoun handling is currently developed.\[Danlos 88\] Laurence Danlos, Fiammetta Namer,Morphological and cross dependencies in thesynthesis of personal pronouns in Romance lan-guages, Coling'88.\[Danlos 87a\] Laurence Danlos, A French and En-glish Syntactic Gomponent for Generation, Nat-ural Language Generation: New R.ssults in Ar-tificial Intelligence, Psychology and Linguis-tics, Kempen G. ed, Dortrecht/Boston, Mart-inus Nijhoff Publishers, 1987.\[Danlos 87b\] Laurence Danlos, The linguistic ba-sis of text generation, Cambridge UniversityPress.\[Decitre 87\] Paul Decitre, Thomas Grossi, C16o Jul-lien, Jean-Philippe Solwy, Planning for Pro-blem-Solving in Advice-Gluing Dialogue, ACLEuropean Chapter, Copenhague, 1987.\[Gross 86\] Maurice Grogs, Lexicon-Grammar, TheRepresentation of Compound Words, l l th In-ternational Conference on Computational Lin-guistics, Proceedings, Coling'86, 1986.\[Gross 75\] Maurice Gross, M~thodea en syntaze,R~gime des constructions compl~tlees, Hermann,1975.\[Jacobs 85\] Paul S. Jacobs, PHRED: A Genera-tor for Natural Language Interfaces, Compu-tational Linguistics, Vol.
11, No 4, 1985.\[Kay 81\] Martin KAY, Unification Grammars, Xe-rox Publication, 1981.
(Lancel 86\] Jean-Maxis Lancel, FranCois Rousselot,Nathalie Simonin, A Grammar used for Par-sing and Generation, l l th International Con-ference on Computational Linguistics, Proceed-ings, Coling'86, 1986.\[Longman 81\] Longman Dictionary of Contempo-rary English, Longman Group Limited, 1978,Corrections 1981.\[Simonin 87\] Nathalie Simonin, An Approach of Creosting Structured Text, First European Work-shop on Natural Laaguage Generation, Roy-anmont Abbey, 1987.References\[Bruffaerts 86\] Bruffaerts A., Henin E. and Mar-lair V., An Expert System Prototype for Finan-cial Counseling, Research Report 507, PhilipsReseaxch Laboratory Brussels, 1986.364
