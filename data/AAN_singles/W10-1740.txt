Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 276?281,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsAdaptive Model Weighting and Transductive Regression forPredicting Best System CombinationsErgun Bic?iciKoc?
University34450 Sariyer, Istanbul, Turkeyebicici@ku.edu.trS.
Serdar KozatKoc?
University34450 Sariyer, Istanbul, Turkeyskozat@ku.edu.trAbstractWe analyze adaptive model weight-ing techniques for reranking using in-stance scores obtained by L1 regular-ized transductive regression.
Compet-itive statistical machine translation isan on-line learning technique for se-quential translation tasks where wetry to select the best among com-peting statistical machine translators.The competitive predictor assigns aprobability per model weighted bythe sequential performance.
We de-fine additive, multiplicative, and loss-based weight updates with exponentialloss functions for competitive statisti-cal machine translation.
Without anypre-knowledge of the performance ofthe translation models, we succeed inachieving the performance of the bestmodel in all systems and surpass theirperformance in most of the languagepairs we considered.1 IntroductionWhen seen as independent instances, systemcombination task can be solved with a sequen-tial learning algorithm.
Online learning algo-rithms enable us to benefit from previous goodmodel choices to estimate the next best model.We use transductive regression based machinetranslation model to estimate the scores foreach sentence.We analyze adaptive model weighting tech-niques for system combination when the com-peting translators are SMT models.
We useseparate model weights weighted by the se-quential performance.
We use additive, mul-tiplicative, or loss based weight updates toupdate model weights.
Without any pre-knowledge of the performance of the transla-tion models, we are able to achieve the per-formance of the best model in all systems andwe can surpass its performance as well as theregression based machine translation?s perfor-mance.The next section reviews the transductiveregression approach for machine translation,which we use to obtain instance scores.
In sec-tion 3 we present competitive statistical ma-chine translation model for solving sequentialtranslation tasks with competing translationmodels.
Section 4 presents our results and ex-periments and the last section gives a sum-mary of our contributions.2 Transductive Regression BasedMachine TranslationTransduction uses test instances, which cansometimes be accessible at training time, tolearn specific models tailored towards the testset.
Transduction has computational advan-tages since we are not using the full train-ing set and a smaller set of constraints existto satisfy.
Transductive regression based ma-chine translation (TRegMT) aims to reducethe computational burden of the regression ap-proach by reducing the dimensionality of thetraining set and the feature set and also im-prove the translation quality by using trans-duction.Regression Based Machine Translation:Let n training instances be represented as(x1,y1), .
.
.
, (xn,yn) ?
X?
?Y ?, where (xi,yi)corresponds to a pair of source and target lan-guage token sequences.
Our goal is to finda mapping f : X?
?
Y ?
that can convert agiven set of source tokens to a set of target to-kens that share the same meaning in the targetlanguage.276We use feature mappers ?X : X?
?FX = RNX and ?Y : Y ?
?
FY =RNY to represent the training set.
Then,MX ?
RNX?n and MY ?
RNY ?n such thatMX = [?X(x1), .
.
.
,?X(xn)] and MY =[?Y (y1), .
.
.
,?Y (yn)].
The ridge regressionsolution using L2 regularization is found as:HL2 = arg minH?RNY ?NX?MY ?HMX ?2F +?
?H?2F .
(1)Two main challenges of the regression basedmachine translation (RegMT) approach arelearning the regression function, g : X?
?FY , and solving the pre-image problem, which,given the features of the estimated targetstring sequence, g(x) = ?Y (y?
), attempts tofind y ?
Y ?
: f(x) = arg miny?Y ?
||g(x) ?
?Y (y)||2.
Pre-image calculation involves asearch over possible translations minimizingthe cost function:f(x) = arg miny?Y ??
?Y (y)?H?X(x)?2 .
(2)We use n-spectrum weighted word featuremappers (Taylor and Cristianini, 2004) whichconsider all word sequences up to order n.L1 Regularized Regression for Learning:HL2 is not a sparse solution as most of the co-efficients remain non-zero.
L1 norm behavesboth as a feature selection technique and amethod for reducing coefficient values.HL1 = arg minH?RNY ?NX?MY ?HMX ?2F +?
?H?1 .
(3)Equation 3 presents the lasso (least absoluteshrinkage and selection operator) (Tibshirani,1996) solution where the regularization termis defined as ?H?1=?i,j |Hi,j |.
We use for-ward stagewise regression (FSR) (Hastie etal., 2006) and quadratic programming (QP) tofind HL1 .
The details of the TRegMT modelcan be read in a separate submission to thetranslation task (Bicici and Yuret, 2010).3 Competitive Statistical MachineTranslationWe develop the Competitive Statistical Ma-chine Translation (CSMT) framework for se-quential translation tasks when the compet-ing models are statistical machine translators.CSMT uses the output of different translationmodels to achieve a translation performancethat surpasses the translation performance ofall of the component models or achieves theperformance of the best.CSMT uses online learning to update theweights used for estimating the best perform-ing translation model.
Competitive predictorassigns a weight per model estimated by theirsequential performance.
At each step, m com-ponent translation models are executed in par-allel over the input source sentence sequenceand the loss lp[n] of model p at observationn is calculated by comparing the desired datay[n] with the output of model p, y?p[n].
CSMTmodel selects a model based on the weightsand the performance of the selected model aswell as the remaining models to adaptively up-date the weights given for each model.
Thiscorresponds to learning in full information set-ting where we have access to the loss for eachaction (Blum and Mansour, 2007).
CSMTlearning involves two main steps: estimationand weight update:y?c[n] = E(w[n],x[n]), (estimation)lp[n] = y[n]?
y?p[n], (instance loss)Lp[n] =?ni=1 lp[i]2, (cumulative loss)w[n+ 1] = U(w[n], y?c[n],L[n]), (update)(4)where w[n] = (w1[n], .
.
.
, wm[n]) for m mod-els, Lp is the cumulative squared loss of modelp, L[n] stores cumulative and instance losses,and y?c[n] is the competitive model estimatedfor instance n. The learning problem is findingan adaptive w that minimizes the cumulativesquared error with appropriate estimation andupdate methods.Related Work: Multistage adaptive filter-ing (Kozat and Singer, 2002) combines theoutput of multiple adaptive filters to outper-form the best among them where the firststage executes models in parallel and the sec-ond stage updates parameters using the per-formance of the combined prediction, y?c[n].Macherey and Och (2007) investigate differentapproaches for system combination includingcandidate selection that maximize a weightedcombination of BLEU scores among differentsystem outputs.
Their system uses a fixedweight vector trained on the development set277to be multiplied with instance BLEU scores.3.1 Estimating the Best PerformingTranslation ModelWe use additive, multiplicative, or loss basedupdates to estimate model weights.
Wemeasure instance loss with trLoss(y[i], y?p[i]),which is a function that returns the transla-tion performance of the output translation ofmodel p with respect to the reference transla-tion at instance i.
1-BLEU (Papineni et al,2001) is one such function with outputs in therange [0, 1].
Cumulative squared loss of thep-th translation model is defined as:Lp[n] =n?i=1trLoss(y[i], y?p[i])2.
(5)We use exponentially re-weighted prediction toestimate model performances, which uses ex-ponentially re-weighted losses based on theoutputs of the m different translation models.We define the additive exponential weightupdate as follows:wp[n+ 1] =wp[n] + e??
lp[n]m?k=1(wk[n] + e??
lk[n]), (6)where ?
> 0 is the learning rate and the de-nominator is used for normalization.
The up-date amount, e??
lp[n] is 1 when lp[n] = 0 and itapproaches zero with increasing instance loss.Perceptrons, gradient descent, and Widrow-Huff learning have additive weight updates.We define the multiplicative exponentialweight update as follows:wp[n+ 1] = wp[n]?e??
lp[n]2m?k=1wk[n] e??
lk[n]2, (7)where we use the squared instance loss.
Equa-tion 7 is similar to the update of Weighted Ma-jority Algorithm (Littlestone and Warmuth,1992) where the weights of the models thatmake a mistake are multiplied by a fixed ?such that 0 ?
?
< 1.We use Bayesian Information Criterion(BIC) as a loss based re-weighting technique.Assuming that instance losses are normallydistributed with variance ?2, BIC score is ob-tained as (Hastie et al, 2009):BICp[n] =Lp[n]?2+ dp log(n), (8)where ?2 is estimated by the average of modelsample variances of squared instance loss anddp is the number of parameters used in model pwhich we assume to be the same for all models;therefore we can discard the second term.
Themodel with the minimum BIC value becomesthe one with the highest posterior probabilitywhere the posterior probability of model p canbe estimated as (Hastie et al, 2009):wp[n+ 1] =e?12BICp[n]m?k=1e?12BICk[n].
(9)The posterior probabilities become modelweights and we basically forget about the pre-vious weights, whose information is presum-ably contained in the cumulative loss, Lp.
Wedefine multiplicative re-weighting with BICscores as follows:wp[n+ 1] = wp[n]?e?12BICpm?k=1wk[n] e?
12BICk.
(10)Model selection: We use stochastic or de-terministic selection to choose the competitivemodel for each instance.
Deterministic choicerandomly selects among the maximum scor-ing models with minimum translation lengthwhereas stochastic choice draws model p withprobability proportional to wp[n].
Random-ization with the stochastic model selectiondecreases expected mistake bounds in theweighted majority algorithm (Littlestone andWarmuth, 1992; Blum, 1996).Auer et al (2002) show that optimal fixedlearning rate for the weighted majority algo-rithm is found as ?
[n] =?m/L?
[n] whereL?
[n] = min1?i?m Li[n], which requires priorknowledge of the cumulative losses.
We use?
=?m/(0.05n) for constant ?.4 Experiments and DiscussionWe perform experiments on the system com-bination task for the English-German (en-de), German-English (de-en), English-French278(en-fr), English-Spanish (en-es), and English-Czech (en-cz ) language pairs using the trans-lation outputs for all the competing systemsprovided in WMT10.
We experiment in a sim-ulated online learning setting where only thescores obtained from the TRegMT system areused during both tuning and testing.
We donot use reference translations in measuring in-stance performance in this simulated settingfor the results we obtain be in line with sys-tem combination challenge?s goals.4.1 DatasetsWe use the training set provided in WMT10 toindex and select transductive instances from.The challenge split the test set for the transla-tion task of 2489 sentences into a tuning set of455 sentences and a test set with the remain-ing 2034 sentences.
Translation outputs foreach system is given in a separate file and thenumber of system outputs per translation pairvaries.
We have tokenized and lowercased eachof the system outputs and combined these ina single N -best file per language pair.
We useBLEU (Papineni et al, 2001) and NIST (Dod-dington, 2002) evaluation metrics for measur-ing the performance of translations automati-cally.4.2 Reranking ScoresThe problem we are solving is online learn-ing with prior information, which comes fromthe comparative BLEU scores, LM scores, andTRegMT scores at each step n. The scoringfunctions are explained below:1.
TRegMT: Transductive regression basedmachine translation scores as found byEquation 2.
We use the TRegMT scoresobtained by the FSR model.2.
CBLEU: Comparative BLEU scores weobtain by measuring the average BLEUperformance of each translation relativeto the other systems?
translations in theN -best list.3.
LM: We calculate 5-gram language modelscores for each translation using the lan-guage model trained over the target cor-pus provided in the translation task.To make things simpler, we use a single priorTRegMT system score linearly combining thethree scores mentioned with weights learnedon the tuning set.
The overall TRegMT sys-tem score for instance n, model i is referred asTRegScorei[n].Since we do not have access to the refer-ence translations nor to the translation modelscores each system obtained for each sentence,we estimate translation model performance bymeasuring the average BLEU performance ofeach translation relative to other translationsin the N -best list.
Thus, each possible transla-tion in the N -best list is BLEU scored againstother translations and the average of thesescores is selected as the CBLEU score for thesentence.
Sentence level BLEU score calcula-tion avoids singularities in n-gram precisionsby taking the maximum of the match countand 12|si| for |si| denoting the length of thesource sentence si as used in (Macherey andOch, 2007).4.3 Adaptive Model WeightingWe initialize model weights to 1/m for allmodels, which are updated after each instanceaccording to the losses based on the TRegMTmodel.
Table 1 presents the performanceof the algorithms on the en-de developmentset.
We have measured their performanceswith stochastic (stoc.)
or deterministic (det.
)model selection when using only the weights ormixture weights obtained when instance scoresare also considered.
Mixture weights are ob-tained as: wi[n] = wi[n] TRegScorei[n], forinstance n, model i.Baseline performance obtained with randomselection has .1407 BLEU and 4.9832 NISTscores.
TRegMT model obtains a performanceof .1661 BLEU and 5.3283 NIST with rerank-ing.
The best model performance among the12 en-de translation models has .1644 BLEUand 5.2647 NIST scores.
Therefore, by usingTRegMT score, we are able to achieve betterscores.Not all of the settings are meaningful.
Forinstance, stochastic model selection is used foralgorithms having multiplicative weight up-dates.
This is reflected in the Table 1 by lowperformance on the additive and BIC models.Similarly, using mixture weights may not re-sult in better scores for algorithms with multi-plicative updates, which resulted in decreased279Additive Multiplicative BIC BIC WeightingSetting BLEU NIST BLEU NIST BLEU NIST BLEU NISTStoc., W .1419 5.0016 ?.003 .1528 5.1710 ?.001 .1442 5.0468 .1568 ?.001 5.2052 ?.005Stoc., M .1415 5.0001 .1525 5.1601 ?.001 .1459 5.0619 ?.004 .1566 ?.001 5.2030 ?.006Det., W .1644 5.3208 .1638 5.2571 .1638 5.2542 .1646 5.2535Det., M .1643 5.3173 .1536 5.1756 .1530 5.1871 .1507 5.1973Table 1: Performances of the algorithms on the development set over 100 repetitions.
W:Weights, M: Mixture.performance in Table 1.
Decreased perfor-mance with BIC hints that we may use othertechniques for mixture weights.Table 2 presents reranking results on all ofthe language pairs we considered with the ran-dom, TRegMT, and CSMT models.
Randommodel score lists the random model perfor-mance selected among the competing trans-lations randomly and it can be used as abaseline.
Best model score lists the perfor-mance of the best model performance.
CSMTmodels are named with the weighting modelused (Add for additive, Mul for multiplicative,BICW for BIC weighting), model selectiontechnique (S for stochastic, D for determinis-tic), and mixtures model (W for using onlyweights, M for using mixture weights) withhyphens in between.
Our challenge submis-sion is given in the last row of Table 2 wherewe used multiplicative exponential weight up-dates, deterministic model selection, and onlythe weights during model selection.
For thechallenge results, we initialized the weights tothe weights obtained in the development set.We have presented scores that are betterthan or close to the best model in bold.
Weobserve that the additive model performs thebest by achieving the performance of the bestcompeting translation model and performingbetter than the best in most of the languagepairs.
For the en-de language pair, addi-tive model score achieves even better than theTRegMT model, which is used for evaluatinginstance scores.5 ContributionsWe have analyzed adaptive model weightingtechniques for system combination when thecompeting translators are statistical machinetranslation models.
We defined additive, mul-tiplicative, and loss-based weight updates withexponential loss functions for the competitivestatistical machine translation framework.Competitive SMT via adaptive weighting ofvarious translators is shown to be a powerfultechnique for sequential translation tasks.
Wehave demonstrated its use in the system com-bination task by using the instance scores ob-tained by the TRegMT model.
Without anypre-knowledge of the performance of the trans-lation models, we have been able to achieve theperformance of the best model in all systemsand we are able to surpass its performance aswell as TRegMT?s performance with the addi-tive model.AcknowledgmentsThe research reported here was supported inpart by the Scientific and Technological Re-search Council of Turkey (TUBITAK).
Thefirst author would like to thank Deniz Yuretfor helpful discussions and for guidance andsupport during the term of this research.ReferencesAuer, Cesa-Bianchi, and Gentile.
2002.
Adaptiveand self-confident on-line learning algorithms.JCSS: Journal of Computer and System Sci-ences, 64.Ergun Bicici and Deniz Yuret.
2010.
L1 regular-ized regression for reranking and system combi-nation in machine translation.
In Proceedings ofthe ACL 2010 Joint Fifth Workshop on Statis-tical Machine Translation and Metrics MATR,Uppsala, Sweden, July.
Association for Compu-tational Linguistics.Avrim Blum and Yishay Mansour.
2007.
Learn-ing, regret minimization and equilibria.
InNoam Nisan, Tim Roughgarden, Eva Tar-dos, and Vijay V. Vazirani, editors, Algorith-mic Game Theory (Cambridge University Press,2007).Avrim Blum.
1996.
On-line algorithms in machinelearning.
In In Proceedings of the Workshop onOn-Line Algorithms, Dagstuhl, pages 306?325.Springer.280en-de de-en en-fr en-es en-czModel BLEU NIST BLEU NIST BLEU NIST BLEU NIST BLEU NISTRandom .1490 5.6555 .2088 6.4886 .2415 6.8948 .2648 7.2563 .1283 4.9238Best model .1658 5.9610 .2408 6.9861 .2864 7.5272 .3047 7.7559 .1576 5.4480TRegMT .1689 5.9638 .2357 6.9254 .2947 7.7107 .3049 7.8156 .1657 5.5632Add-D-W .1697 5.9821 .2354 6.9175 .2948 7.7094 .3043 7.8093 .1642 5.5463Add-D-M .1698 5.9824 .2353 6.9152 .2949 7.7103 .3044 7.8091 .1642 5.5461Mul-S-W .1574 5.7564 .2161 6.5950 .2805 7.4599 .2961 .7.6870 .1572 5.4394Mul-D-W .1618 5.8912 .2408 6.9854 .2847 7.5085 .2785 7.4133 .1612 5.5119BIC-D-W .1614 5.8852 .2408 6.9853 .2842 7.5022 .2785 7.4132 .1623 5.5236BIC-D-M .1580 5.7614 .2141 6.5597 .2791 7.4309 .2876 7.5138 .1577 5.4488BICW-S-W .1621 5.8795 .2274 6.8142 .2802 7.4873 .2892 7.5569 .1565 5.4126BICW-S-M .1618 5.8730 .2196 6.6493 .2806 7.4948 .2849 7.4845 .1561 5.4099BICW-D-W .1648 5.9298 .2355 6.9112 .2807 7.4648 .2785 7.4134 .1534 5.3458Challenge .1567 5.73 .2394 6.9627 .2758 7.4333 .3047 7.7559 .1641 5.5435Table 2: CSMT results where bold corresponds to scores better than or close to the best model.Underlined scores are better than both the TregMT model and the best model.George Doddington.
2002.
Automatic evaluationof machine translation quality using n-gram co-occurrence statistics.
In Human Language Tech-nology Research, pages 138?145.Trevor Hastie, Jonathan Taylor, Robert Tibshi-rani, and Guenther Walther.
2006.
Forwardstagewise regression and the monotone lasso.Electronic Journal of Statistics, 1.Trevor Hastie, Robert Tibshirani, and JeromeFriedman.
2009.
The Elements of StatisticalLearning: Data Mining, Inference and Predic-tion.
Springer-Verlag, 2nd edition.S.S.
Kozat and A.C. Singer.
2002.
Further re-sults in multistage adaptive filtering.
ICASSP,2:1329?1332.Nick Littlestone and Manfred K. Warmuth.
1992.The Weighted Majority Algorithm.
TechnicalReport UCSC-CRL-91-28, University of Califor-nia, Santa Cruz, Jack Baskin School of Engi-neering, October 26,.Wolfgang Macherey and Franz J. Och.
2007.
Anempirical study on computing consensus transla-tions from multiple machine translation systems.In EMNLP-CoNLL, pages 986?995.Kishore Papineni, Salim Roukos, Todd Ward, andWei-Jing Zhu.
2001.
Bleu: a method for au-tomatic evaluation of machine translation.
InACL, pages 311?318.
ACL.J.
Shawe Taylor and N. Cristianini.
2004.
Ker-nel Methods for Pattern Analysis.
CambridgeUniversity Press.Robert J. Tibshirani.
1996.
Regression shrinkageand selection via the lasso.
Journal of the RoyalStatistical Society, Series B, 58(1):267?288.281
