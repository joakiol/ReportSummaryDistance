BioNLP 2008: Current Trends in Biomedical Natural Language Processing, pages 112?113,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsDetermining causal and non-causal relationships in biomedical text byclassifying verbs using a Naive Bayesian ClassifierPieter van der Horn Bart Bakker Gijs GeleijnsePhilips Research LaboratoriesHigh Tech Campus 12a, 5656 AE Eindhoven, The Netherlands{pieter.van.der.horn,bart.bakker,gijs.geleijnse,jan.korst,sergei.kurkin}@philips.comJan Korst Sergei Kurkin1 IntroductionSince scientific journals are still the most importantmeans of documenting biological findings, biomed-ical articles are the best source of information wehave on protein-protein interactions.
The mining ofthis information will provide us with specific knowl-edge of the presence and types of interactions, andthe circumstances in which they occur.There are various linguistic constructions that candescribe a protein-protein interaction, but in this pa-per we will focus on subject-verb-object construc-tions.
If a certain protein is mentioned in the sub-ject of a sentence, and another protein in the ob-ject, we assume in this paper that some interaction isdescribed between those proteins.
The verb phrasethat links the subject and object together plays animportant role in this.
However, there are a greatmany different verbs in the English language thatcan be used in a description of a protein-protein in-teraction.
Since it is practically impossible to manu-ally determine the specific biomedical meanings forall of these verbs, we try to determine these mean-ings automatically.
We define two classes of protein-protein interactions, causal and non-causal, and us-ing a Naive Bayesian Classifier, we predict for agiven verb in which class it belongs.
This processis a first step in automatically creating a useful net-work of interacting proteins out of information frombiomedical journals.2 PreprocessingThe protein-protein interactions we are interested inare described in the subject, the object and the in-terlinking verb phrase of a sentence.
To determinewhich parts of the sentence make up this construc-tion, we need to preprocess the sentence.
For this,we use the Genia Chunker1 to break the sentenceinto different chunks (in particular we are interestedin noun phrases and verb phrases).
We combinethis information with the result of the Stanford De-pendency Parser2 to determine how these differentchunks (phrases) are connected to each other.3 ClassificationThe subject-verb-object construction can beschematically represented as follows:[(state of) protein] [verb] [(state of) protein]We make a distinction between two classes ofverbs.
One class describes a strict causal relationand the other covers all other types of meanings(non-causal).
Table 1 shows some example verbsfor the two classes.Class Examplescausal activate, inhibit, causenon-causal interact, require, bindTable 1: Two classes of verbs.Since we leave out the information of the statesof the proteins in this work, the first class coverspositive, negative and neutral causal relations.
Thesecond class includes not just verbs that describe acorrelation (interact), but also verbs such as require1http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA/tagger/2http://nlp.stanford.edu/downloads/lex-parser.shtml112and bind that describe a biologically important rela-tionship, but not specifically a causal one.We use a Naive Bayesian Classifier to estimatethe probability P (ci|V ) that a given verb belongs toa certain class.
In the retrieved subject-verb-objectconstructions, such a verb V will occur a numberof times, each time in combination with a specificordered pair of proteins ppj , one in the subject andone in the object.
Each pair ppj independently con-tributes to the estimation of P (ci|V ).V = {pp1, pp2, ..., ppn} (1)P (ci|V ) =P (ci) ?
?nj=1 P (ppj |ci)P (pp1, pp2, ..., ppn) (2)4 Experimental resultsTo test our approach, we retrieved a set of subject-verb-object relations from PubMed.
We choose totest our approach on yeast proteins rather than e.g.human proteins to avoid Named Entity Recognitionproblems.To get rid of any excess information, the verbphrases are normalized.
We assume the last verbin the phrase to be the relevant verb and check thedirection of the relation (active or passive form ofthat verb).
Finally, the verb is stemmed.
For thoseverbs that are in the passive form, the order of theprotein pairs around it was reversed, and, for simpli-fication, verb phrases that describe a negation wereremoved.
More than one protein can occur in thesubject and/or object, so we count each possible pairas an occurrence around the particular verb.We used the 6 verbs as shown in Table 1 as a start-ing set to test the classifier.
They represent the dif-ferent types within each class, and of these it is clearthey belong in that specific class.
By using Word-Net3 we can augment this set.
Table 1 shows theresults of the different tests, using different param-eter settings in WordNet to augment the training set(?l1?
means recursive level 1, ?s2?
means WordNetsenses 1 to 2, ?sa?
means all WordNet senses aretaken).
It contains the number of verbs classified inthe leave-one-out cross validation (V), the numberof verbs that were correctly classified (C), the preci-sion (P = CV ) and the probability Q that a random3http://wordnet.princeton.edu/V C P Qno WN 6 3 0.50 0.66l1/s1 13 7 0.54 0.50l1/s2 18 13 0.72 0.05l1/sa 19 14 0.74 0.03l2/s1 19 12 0.63 0.18l2/s2 27 21 0.78 2.96E-3l2/sa 55 32 0.58 0.14l3/s1 26 20 0.77 4.68E-3l3/s2 42 35 0.83 7.55E-6l3/sa 73 43 0.59 0.08Table 2: Results for different settings.classifier would perform as good or better than thisclassifier, given by Equation 3Q =V?i=C(Vi)pi ?
(1?
p)V?i (3)5 Conclusions and future workGiven an appropriate set of known verbs, we canpredict the meanings of unknown verbs with reason-able confidence.
This automatic prediction is veryuseful, since it is infeasible to manually determinethe meanings of all possible verbs.
We used twoclasses of verbs, making the distinction between re-lations that describe proteins affecting other proteins(causal relation) and any other relation (non-causalrelation).
Verbs like require and bind describe bi-ologically distinct interactions however, and prefer-ably should be put into classes separate from gen-eral correlations.
We chose to use a two-way dis-tinction as a first step however, which was still bio-logically relevant.
In order to create a more detailednetwork of interacting proteins, one can take theseother types into account as well.Furthermore, it would be useful to separate thecausal relationship into positive and negative rela-tions.
This specific distinction however is not justdescribed in the connecting verb, but also in possi-ble state descriptions in the noun phrases.
Furtherresearch is necessary to extract these descriptionsfrom the text.
Finally, it would be useful to lookat different syntactical constructions, other than justsubject and object.113
