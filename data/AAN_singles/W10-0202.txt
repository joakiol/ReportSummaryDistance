Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 10?16,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsEmotion Detection in Email Customer CareNarendra Gupta, Mazin Gilbert, and Giuseppe Di FabbrizioAT&T Labs - Research, Inc.Florham Park, NJ 07932 - USA{ngupta,mazin,pino}@research.att.comAbstractPrompt and knowledgeable responses to cus-tomers?
emails are critical in maximizing cus-tomer satisfaction.
Such emails often con-tain complaints about unfair treatment due tonegligence, incompetence, rigid protocols, un-friendly systems, and unresponsive personnel.In this paper, we refer to these emails as emo-tional emails.
They provide valuable feedbackto improve contact center processes and cus-tomer care, as well as, to enhance customer re-tention.
This paper describes a method for ex-tracting salient features and identifying emo-tional emails in customer care.
Salient fea-tures reflect customer frustration, dissatisfac-tion with the business, and threats to eitherleave, take legal action and/or report to au-thorities.
Compared to a baseline system us-ing word ngrams, our proposed approach withsalient features resulted in a 20% absolute F-measure improvement.1 IntroductionEmails are becoming the preferred communicationchannel for customer service.
For customers, it is away to avoid long hold times on call centers phonecalls and to keep a record of the information ex-changes with the business.
For businesses, it of-fers an opportunity to best utilize customer servicerepresentatives by evenly distributing the work loadover time, and for representatives, it allows time toresearch the issue and respond to the customers ina manner consistent with business policies.
Busi-nesses can further exploit the offline nature of thischannel by automatically routing the emails involv-ing critical issues to specialized representatives.
Be-sides concerns related to products and services, busi-nesses ensure that emails complaining about unfairtreatment due to negligence, incompetence, rigidprotocols and unfriendly systems, are always han-dled with care.
Such emails, referred to as emotionalemails, are critical to reduce the churn i.e., retain-ing customers who otherwise would have taken theirbusiness elsewhere, and, at the same time, they are avaluable source of information for improving busi-ness processes.In recurring service oriented businesses, a largenumber of customer emails may contain routinecomplaints.
While such complaints are importantand are addressed by customer service represen-tatives, our purpose here is to identify emotionalemails where severity of the complaints and cus-tomer dissatisfaction are relatively high.
Emotionalemails may contain abusive and probably emotion-ally charged language, but we are mainly interestedin identifying messages where, in addition to theflames, the customer includes a concrete descrip-tion of the problem experienced with the companyproviding the service.
In the context of customerservice, customers express their concerns in manyways.
Sometimes they convey a negative emotionalcomponent articulated by phrases like disgustedand you suck.
In other cases, there is a minimumemotional involvement by enumerating factual sen-tences such as you overcharged, or take mybusiness elsewhere.
In many cases, boththe emotional and factual components are actuallypresent.
In this work, we have identified eight dif-10ferent ways that customers use to express their emo-tions in emails.
Throughout this paper, these wayswill be referred to as Salient Features.
We cast theidentification of emotional email as a text classifi-cation problem, and show that using salient featureswe can significantly improve the identification ac-curacy.
Compared to a baseline system which usesBoosting (Schapire, 1999) withnword n-grams fea-tures, our proposed system using salient features re-sulted in improvement in f-measure from 0.52 to0.72.In section 2, we provide a summary of previouswork and its relationship with our contribution.
Insection 3, we describe our method for emotion de-tection and extraction of salient features.
A series ofexperiments demonstrating improvement in classifi-cation performance is presented in section 4.
Weconclude the paper by highlighting the main contri-bution of this work in section 5.2 Previous WorkExtensive work has been done on emotion detec-tion.
In the context of human-computer dialogs, al-though richer features including acoustic and intona-tion are available, there is a general consensus (Lit-man and Forbes-Riley, 2004b; Lee and Narayanan,2005) about the use of lexical features to signifi-cantly improve the accuracy of emotion detection.Research has also been done in predicting ba-sic emotions (also referred to as affects) within text(Alm et al, 2005; Liu et al, 2003).
To render speechwith prosodic contour conveying the emotional con-tent of the text, one of 6 types of human emotions(e.g., angry, disgusted, fearful, happy, sad, and sur-prised) are identified for each sentence in the run-ning text.
Deducing such emotions from lexical con-structs is a hard problem evidenced by little agree-ment among humans.
A Kappa value of 0.24-0.51was shown in Alm et al (2005).
Liu et al (2003)have argued that the absence of affect laden surfacefeatures i.e., key words, from the text does not implyabsence of emotions, therefore they have relied moreon common-sense knowledge.
Instead of deducingtypes emotions in each sentence, we are interestedin knowing if the entire email is emotional or not.Additionally we are also interested in the intensityand the cause of those emotions.There is also a body of work in areas of creatingSemantic Orientation (SO) dictionaries (Hatzivas-siloglou and McKeown, 1997; Turney and Littman,2003; Esuli and Sebastiani, 2005) and their use inidentifying emotions laden sentences and polarity(Yu and Hatzivassiloglou, 2003; Kim and Hovy,2004; Hu and Liu, 2004) of those emotions.
Whilesuch dictionaries provide a useful starting point,their use alone does not yield satisfactory results.
InWilson et al (2005), classification of phrases con-taining positive, negative or neutral emotions is dis-cussed.
For this problem they show high agreementamong human annotators (Kappa of 0.84).
Theyalso show that labeling phrases as positive, negativeor neutral only on the basis of presence of key wordfrom such dictionaries yields a classification accu-racy of 48%.
An obvious reason for this poor per-formance is that semantic orientations of words arecontext dependent.Works reported in Wilson et al (2005); Pang et al(2002) and Dave et al (2003) have attempted tomitigate this problem by using supervised meth-ods.
They report classification results using a num-ber of different sets of features, including unigramword features.
Wilson et al (2005) reports an im-provement (63% to 65.7% accuracy) in performanceby using a host of features extracted from syntac-tic dependencies.
Similarly, Gamon (2004) showsthat the use of deep semantic features along withword unigrams improve performances.
Pang et al(2002) and Dave et al (2003) on the other handconfirmed that word unigrams provide the best clas-sification results.
This is in line with our experi-ence as well and could be due to sparseness of thedata.
We also used supervised methods to predictemotional emails.
To train predictive models weused word ngrams (uni-, bi- and tri-grams) and anumber of binary features indicating the presence ofwords/phrases from specific dictionaries.Spertus (1997) discusses a system called Smokywhich recognizes hostile messages and is quite sim-ilar to our work.
While Smoky is interested in iden-tifying messages that contain flames, our researchon emotional emails looks deeper to discover thereasons for such flames.
Besides word unigrams,Smoky uses rules to derive additional features forclassification.
These features are intended to cap-ture different manifestations of the flames.
Simi-11larly, in our work we also use rules (in our case im-plemented as table look-up) to derive additional fea-tures of emotional emails.3 Emotion detection in emailsWe use supervised machine learning techniques todetect emotional emails.
In particular, our emotiondetector is a statistical classifier model trained usinghand labeled training examples.
For each example,a set of salient features is extracted.
The major com-ponents of our system are described below.3.1 ClassifierFor detecting emotional emails we used Boostex-ter as text classification.
Our choice of machinelearning algorithm was not strategic and we have noreason to believe that SVMs or maximum entropy?based classifiers will not perform equally well.Boostexter, which is based on the boosting family ofalgorithms, was first proposed by Schapire (1999).
Ithas been applied successfully to numerous text clas-sification applications (Gupta et al, 2005) at AT&T.Boosting builds a highly accurate classifier by com-bining many ?weak?
base classifiers, each one ofwhich may only be moderately accurate.
Boost-ing constructs the collection of base classifiers iter-atively.
On each iteration t, the boosting algorithmsupplies the base learner weighted training data andthe base learner generates a base classifier ht.
Setof nonnegative weights wt encode how important itis that ht correctly classifies each email.
Generally,emails that were most often misclassified by the pre-ceding base classifiers will be given the most weightso as to force the base learner to focus on the ?hard-est?
examples.
As described in Schapire and Singer(1999), Boostexter uses confidence rated base clas-sifiers h that for every example x (in our case it is thecustomer emails) output a real number h(x) whosesign (-1 or +1) is interpreted as a prediction(+1 indi-cates emotional email), and whose magnitude |h(x)|is a measure of ?confidence.?
The output of the finalclassifier f is f(x) =?Tt=1 ht(x), i.e., the sum ofconfidence of all classifiers ht.
The real-valued pre-dictions of the final classifier f can be mapped onto aconfidence value between 0 and 1 by a logistic func-tion;conf(x = emotional email) =11 + e?f(x).The learning procedure in boosting minimizes thenegative conditional log likelihood of the trainingdata under this model, namely:?iln(1 + e?yif(xi)).Here i iterates over all training examples and yi isthe label of ith example.3.2 Feature extractionEmotional emails are a reaction to perceived exces-sive loss of time and/or money by customers.
Ex-pressions of such reactions in emails are salient fea-tures of emotional emails.
For our data we haveidentified the eight features listed below.
Whilemany of these features are of general nature and canbe present in most customer service related emo-tional emails, in this paper we make no claims abouttheir completeness.1.
Expression of negative emotions: Explic-itly expressing customers affective statesby phrases like it upsets me, I amfrustrated;2.
Expression of negative opinions aboutthe company: by evaluative expres-sions like dishonest dealings,disrespectful.
These could also beinsulting expressions like stink, suck,idiots;3.
Threats to take their business elsewhere:by expression like business elsewhere,look for another provider.
Theseexpressions are neither emotional or evaluative;4.
Threats to report to authorities: federalagencies, consumer protection.These are domain dependent names of agen-cies.
The mere presence of such names impliescustomer threat;5.
Threats to take legal action: seekretribution, lawsuit.
These ex-pressions may also not be emotional orevaluative in nature;6.
Justification about why they should have beentreated better.
A common way to do this is12to say things like long time customer,loyal customer, etc.
Semantic orienta-tions of most phrases used to express this fea-ture are positive;7.
Disassociate themselves from the company,by using phrases like you people, yourservice representative, etc.
Theseare analogous to rule class ?Noun Phrases usedas Appositions?
in Spertus (1997).8.
State what was done wrong to them: grosslyovercharged, on hold for hours,etc.
These phrases may have negative orneutral semantic orientations.In addition to the word unigrams, salient features ofemotional emails are also used for training/testingthe emotional email classifier.
While labeling thetraining data, labelers look for salient features withinthe email and also the severity of the loss perceivedby the customer.
For example, email 1 in Fig.
1 is la-beled as emotional because customer perception ofloss is severe to the point that the customer may can-cel the service.
On the other hand, email 2 is notemotional because customer perceived loss is not se-vere to the point of service cancellation.
This cus-tomer would be satisfied in this instant if he/she re-ceives the requested information in a timely fashion.To extract salient features from an email, eightseparate lists of phrases customers use to expresseach of the salient features were manually created.These lists were extracted from the training dataand can be considered as basic rules that identifyemotional emails.
In the labeling guide for criticalemails labelers were instructed to look for salientfeatures in the email and keep a list of encounteredphrases.
We further enriched these lists by: a) us-ing general knowledge of English, we added vari-ations to existing phrases and b) searching a largebody of email text (different from testing) for differ-ent phrases in which key words from known phrasesparticipated.
For example from the known phraselied to we used the word lied and found aphrase blatantly lied.
Using these lists weextracted eight binary salient features for each email,indicating presence/absence of phrases from the cor-responding list in the email.1.
You are making this very difficultfor me.
I was assured thatmy <SERVICE> would remain at<CURRENCY> per month.
But youraised it to <CURRENCY> permonth.
If I had known you weregoing to go back on your word,I would have looked for anotherInternet provider.
Presentbill is <CURRENCY>, including<CURRENCY> for <SERVICE>.2.
I cannot figure out my currentcharges.
I have called severaltimes to straighten out a problemwith my service for <PHONENO1>and <PHONENO2>.
I am tired ofbeing put on hold.
I cannot getthe information from the automatedphone service.Figure 1: Email samples: 1) emotional; 2) neutral4 Experiments and evaluationWe performed several experiments to compare theperformance of our emotional email classifier withthat using a ngram based text classifier.
For theseexperiments we labeled 620 emails as training ex-amples and 457 emails as test examples.
Trainingexamples were labeled independently by two differ-ent labelers1 with relatively high degree of agree-ment among them.
Kappa (Cohen, 1960) value of0.814 was observed versus 0.5-0.7 reported for emo-tion labeling tasks (Alm and Sproat, 2005; Litmanand Forbes-Riley, 2004a).
Because of the relativelyhigh agreement among these labelers, with differ-ent back ground, we did not feel the need to checkthe agreement among more than 2 labelers.
Table1 shows that emotional emails are about 12-13% ofthe total population.Set Number of examples Critical EmailsTraining 620 12%Test 457 13%Table 1: Distribution of emotional emails1One of the labeler was one of the authors of this paper andother had linguistic back ground.13Due to the limited size of the training data weused cross validation (leave-one-out) technique onthe test set to evaluate outcomes of different exper-iments.
In this round robin approach, each examplefrom the test set is tested using a model trained onall remaining 1076 (620 plus 456) examples.
Testresults on all 457 test examples are averaged.Throughout all of our experiments, we computedthe classification accuracy of detecting emotionalemails using precision, recall and F-measure.
No-tice for our test data a classifier with majority votehas a classification accuracy of 87%, but since noneof the emotional emails are identified, recall and F-measure are both zero.
On the other hand, a clas-sifier which generates many more false positivesfor each true positive, will have a lower classifi-cation accuracy but a higher (non-zero) F-measurethan the majority vote classifier.
Fig.
2 shows pre-cision/recall curves for different experiments.
Theblack circles represent the operating point corre-sponding to the best F-measure for each curve.
Ac-tual values of these points are provided in Table 2.As a baseline experiment we used word ngramfeatures to train a classifier model.
The graph la-beled as ?ngram features?
in Fig.
2 shows the per-formance of this classifier.
The best F-measure inthis case is only 0.52.
Obviously this low perfor-mance can be attributed to the small training set andthe large feature space formed by word ngrams.Recall Prec.
F-Mes.Ngram Features 0.45 0.61 0.52Rule based:Threshholding onSalient Features counts?
4 0.41 0.93 0.57?
3 0.63 0.74 0.68?
2 0.81 0.53 0.63Salient Features 0.77 0.65 0.70ngram &Salient Features 0.65 0.81 0.72Ngram &Random Features 0.57 0.67 0.61Table 2: Recall and precision corresponding to best F-measure for different classifier modelsFigure 2: Precision/Recall curves for different experi-ments.
Large black circles indicate the operating pointwith best F-Measure4.1 Salient featuresThe baseline system was compared with a similarsystem using salient features.
First, we used a sim-ple classification rule that we formulated by look-ing at the training data.
According to this rule, ifan email contained three or more salient features itwas classified as an emotional email.
We classifiedthe test data using this rule and obtained and an F-measure of 0.68 (see row labeled as ?
3 in Table 2).Since no confidence thresholding can be used withthe deterministic rule, its performance is indicatedby a single point marked by the gray circle in Fig.
2.This result clearly demonstrates high utility of oursalient features.
To verify that the salient featuresthreshold count of 3 used in our simple classificationrule is the best, we also evaluated the performance ofthe rule for the salient features with threshold countof 2 and 4 (row labeled as ?
2 and ?
4 in Table 2).In our next set experiments, we trained a clas-sifier model using salient features alone and withword ngrams.
Corresponding cross validation re-sults on the test data are annotated in Table 2 and in14Fig.
2 as ?Salient Features?
and ?N-grams & SalientFeatures?, respectively.
Incremental improvement inbest F-measure clearly shows: a) BoosTexter is ableto learn better rules than the simple rule of identify-ing three or more salient features.
b) Even thoughsalient features provide a significant improvementin performance, there is still discriminative informa-tion in ngram features.
A direct consequence of thesecond observation is that the detection accuracy canbe further improved by extending/refining the phraselists and/or by using more labeled data so that toexploit the discriminative information in the wordngram features.Salient Features of emotional emails are the con-sequence of our knowledge of how customers reactto their excessive loss.
To empirically demonstratethat eight different salient features used in identifi-cation of emotional emails do provide complemen-tary evidence, we randomly distributed the phrasesin eight lists.
We then used them to extract eightbinary features in the same manner as before.
BestF-measure for this experiment is shown in the lastrow of Table 2, and labeled as ?N-gram & RandomFeatures?.
Degradation in performance of this ex-periment clearly demonstrates that salient featuresused by us provide complimentary and not redun-dant information.5 ConclusionsCustomer emails complaining about unfair treat-ment are often emotional and are critical for busi-nesses.
They provide valuable feedback for improv-ing business processes and coaching agents.
Fur-thermore careful handling of such emails helps toimprove customer retention.
In this paper, we pre-sented a method for emotional email identification.We introduced the notion of salient features foremotional emails, and demonstrated high agreementamong two labelers in detecting emotional emails.We also demonstrated that extracting salient fea-tures from the email text and using them to train aclassifier model can significantly improve identifi-cation accuracy.
Compared to a baseline classifierwhich uses only the word ngrams features, the addi-tion of the salient features improved the F-measurefrom 0.52 to 0.72.
Our current research is focusedon improving the salient feature extraction process.More specifically by leveraging publically availableSemantic orientation dictionaries, and by enrichingour dictionaries using phrases extracted from a largecorpus by matching syntactic patterns of some seedphrases.ReferencesAlm, Cecilia and Richard Sproat.
2005.
Emotionalsequencing and development in fairy tales.
InProceedings of the First International Conferenceon Affective Computing and Intelligent Interac-tion.Alm, Cecilia Ovesdotter, Dan Roth, and RichardSproat.
2005.
Emotions from text: machinelearning for text-based emotion prediction.
InHLT ?05: Proceedings of the conference on Hu-man Language Technology and Empirical Meth-ods in Natural Language Processing.
Associationfor Computational Linguistics, Morristown, NJ,USA, pages 579?586.Cohen, J.
1960.
A coefficient of agreement for nom-inal scales.
Educational and Psychological Mea-surement 20(1):37?46.Dave, Kushal, Steve Lawrence, and David M. Pen-nock.
2003.
Mining the peanut gallery: Opinionextraction and semantic classification of productreviews.
In Proceedings of WWW.
pages 519?528.Esuli, A. and F. Sebastiani.
2005.
Determin-ing the semantic orientation of terms throughgloss classificaion.
In Proceedings of CIKM-05,14th ACM International Conference on Informa-tion and Knowledge Management.
Bremen, DE.,pages 617?624.Gamon, M. 2004.
Sentiment classification on cus-tomer feedback data: Noisy data large featurevectors and the role of linguistic analysis.
In Pro-ceedings of COLING 2004.
Geneva, Switzerland,pages 841?847.Gupta, Narendra, Gokhan Tur, Dilek Hakkani-Tu?r,Srinivas Banglore, Giuseppe Riccardi, and MazinRahim.
2005.
The AT&T Spoken LanguageUnderstanding System.
IEEE Transactions onSpeech and Audio Processing 14(1):213?222.Hatzivassiloglou, Vasileios and Kathleen McKeown.1997.
Predicting the semantic orientation of ad-15jectives.
In Proceedings of the Joint ACL/EACLConference.
pages 174?181.Hu, Minqing and Bing Liu.
2004.
Mining and sum-marizing customer reviews.
In Proceedings of theACM SIGKDD Conference on Knowledge Dis-covery and Data Mining (KDD).
pages 168?177.Kim, Soo-Min and Eduard Hovy.
2004.
Determin-ing the sentiment of opinions.
In Proceedings ofthe International Conference on ComputationalLinguistics (COLING).Lee, Chul Min and Shrikanth S. Narayanan.
2005.Toward detecting emotions in spoken dialogs.IEEE Transactions on Speech and Audio Process-ing 13(2):293?303.Litman, D. and K. Forbes-Riley.
2004a.
Annotat-ing student emotional states in spoken tutoringdialogues.
In Proceedings of the 5th SIGdialWorkshop on Discourse and Dialogue (SIGdial).Boston, MA.Litman, D. and K. Forbes-Riley.
2004b.
Predictingstudent emotions in computer-human tutoring di-alogues.
In Proceedings of the 42nd Annual Meet-ing of the Association for Compuational Linguis-tics (ACL).
Barcelone, Spain.Liu, Hugo, Henry Lieberman, and Ted Selker.
2003.A model of textual affect sensing using real-worldknowledge.
In IUI ?03: Proceedings of the 8thinternational conference on Intelligent user inter-faces.
ACM Press, Miami, Florida, USA, pages125?132.Pang, Bo, Lillian Lee, and ShivakumarVaithyanathan.
2002.
Thumbs up?
Sentimentclassification using machine learning techniques.In Proceedings of the 2002 Conference on Em-pirical Methods in Natural Language Processing(EMNLP).
Philadelphia, Pennsylvania, pages79?86.Schapire, R.E.
1999.
A brief introduction to boost-ing.
In Proceedings of IJCAI.Schapire, R.E.
and Y.
Singer.
1999.
Improvedboosting algorithms using confidence-rated pre-dictions.
Machine Learning 37(3):297?336.Spertus, Ellen.
1997.
Smokey: Automatic recogni-tion of hostile messages.
In In Proc.
of Innova-tive Applications of Artificial Intelligence.
pages1058?1065.Turney, P. and M. Littman.
2003.
Measuring praiseand criticism: Inference of semantic orientationfrom association.
ACM Transactions on Informa-tion Systems 21(4):315?346.Wilson, Theresa, Janyce Wiebe, and Paul Hoffmann.2005.
Recognizing contextual polarity in phrase-level sentiment analysis.
In HLT ?05: Proceed-ings of the conference on Human Language Tech-nology and Empirical Methods in Natural Lan-guage Processing.
Association for ComputationalLinguistics, Morristown, NJ, USA, pages 347?354.Yu, Hong and Vasileios Hatzivassiloglou.
2003.
To-wards answering opinion questions: Separatingfacts from opinions and identifying the polarity ofopinion sentences.
In Proceedings of the Confer-ence on Empirical Methods in Natural LanguageProcessing (EMNLP).16
