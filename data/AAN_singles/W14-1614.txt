Proceedings of the Eighteenth Conference on Computational Language Learning, pages 130?140,Baltimore, Maryland USA, June 26-27 2014.c?2014 Association for Computational LinguisticsTreebank Translation for Cross-Lingual Parser InductionJ?org TiedemannDep.
of Linguistics and PhilologyUppsala Universityjorg.tiedemann@lingfil.uu.se?Zeljko Agi?cLinguistics DepartmentUniversity of Potsdamzagic@uni-potsdam.deJoakim NivreDep.
of Linguistics and PhilologyUppsala Universityjoakim.nivre@lingfil.uu.seAbstractCross-lingual learning has become a popu-lar approach to facilitate the developmentof resources and tools for low-density lan-guages.
Its underlying idea is to makeuse of existing tools and annotations inresource-rich languages to create similartools and resources for resource-poor lan-guages.
Typically, this is achieved by eitherprojecting annotations across parallel cor-pora, or by transferring models from one ormore source languages to a target language.In this paper, we explore a third strategyby using machine translation to create syn-thetic training data from the original source-side annotations.
Specifically, we applythis technique to dependency parsing, us-ing a cross-lingually unified treebank foradequate evaluation.
Our approach drawson annotation projection but avoids the useof noisy source-side annotation of an unre-lated parallel corpus and instead relies onmanual treebank annotation in combinationwith statistical machine translation, whichmakes it possible to train fully lexicalizedparsers.
We show that this approach signif-icantly outperforms delexicalized transferparsing.1 IntroductionThe lack of resources and tools is a serious problemfor the majority of the world?s languages (Bender,2013).
Many applications require robust tools andthe development of language-specific resources isexpensive and time consuming.
Furthermore, manytasks such as data-driven syntactic parsing requirestrong supervision to achieve reasonable resultsfor real-world applications, since the performanceof fully unsupervised methods lags behind by alarge margin in comparison with the state of theart.
Cross-lingual learning has been proposed asone possible solution to quickly create initial toolsfor languages that lack the appropriate resources(Ganchev and Das, 2013).
By and large, thereare two main strategies that have been proposedin the literature: annotation projection and modeltransfer.1.1 Previous Cross-Lingual ApproachesAnnotation projection relies on the mapping of lin-guistic annotation across languages using paral-lel corpora and automatic alignment as basic re-sources (Yarowsky et al., 2001; Hwa et al., 2005;T?ackstr?om et al., 2013a).
Tools that exist for thesource language are used to annotate the sourceside of the corpus and projection heuristics are thenapplied to map the annotation through word align-ment onto the corresponding target language text.Target language tools can then be trained on theprojected annotation assuming that the mapping issufficiently correct.
Less frequent, but also possi-ble, is the scenario where the source side of the cor-pus contains manual annotation (Agi?c et al., 2012).This addresses the problem created by projectingnoisy annotations, but it presupposes parallel cor-pora with manual annotation, which are rarely avail-able, and expensive and time-consuming to pro-duce.Model transfer instead relies on universal fea-tures and model parameters that can be transferredfrom one language to another.
Abstracting awayfrom all language-specific parameters makes it pos-sible to train, e.g., delexicalized parsers that ignorelexical information.
This approach has been usedwith success for a variety of languages, drawingfrom a harmonized POS tagset (Petrov et al., 2012)that is used as the main source of information.
Oneadvantage compared to annotation projection isthat no parallel data is required.
In addition, train-ing can be performed on gold standard annotation.However, model transfer assumes a common fea-130ture representation across languages (McDonald etal., 2013), which can be a strong bottleneck.
Sev-eral extensions have been proposed to make theapproach more robust.
First of all, multiple sourcelanguages can be involved to increase the statisticalbasis for learning (McDonald et al., 2011; Naseemet al., 2012), a strategy that can also be used inthe case of annotation projection.
Cross-lingualword clusters can be created to obtain additionaluniversal features (T?ackstr?om et al., 2012).
Tech-niques for target language adaptation can be usedto improve model transfer with multiple sources(T?ackstr?om et al., 2013b).1.2 The Translation ApproachIn this paper, we propose a third strategy, basedon automatically translating training data to a newlanguage in order to create annotated resources di-rectly from the original source.
Recent advancesin statistical machine translation (SMT) combinedwith the ever-growing availability of parallel cor-pora are now making this a realistic alternative.
Therelation to annotation projection is obvious as bothinvolve parallel data with one side being annotated.However, the use of direct translation brings twoimportant advantages.
First of all, using SMT, wedo not accumulate errors from two sources: the tool?
e.g., tagger or parser ?
used to annotate the sourcelanguage of a bilingual corpus and the noise com-ing from alignment and projection.
Instead, we usethe gold standard annotation of the source languagewhich can safely be assumed to be of much higherquality than any automatic annotation obtained byusing a tool trained on that data.
Moreover, usingSMT may help in bypassing domain shift problems,which are common when applying tools trained(and evaluated) on one resource to text from an-other domain.
Secondly, we can assume that SMTwill produce output that is much closer to the inputthan manual translations in parallel texts usuallyare.
Even if this may seem like a short-comingin general, in the case of annotation projection itshould rather be an advantage, because it makes itmore straightforward and less error-prone to trans-fer annotation from source to target.
Furthermore,the alignment between words and phrases is inher-ently provided as an output of all common SMTmodels.
Hence, no additional procedures have to beperformed on top of the translated corpus.
Recentresearch (Zhao et al., 2009; Durrett et al., 2012)has attempted to address synthetic data creationfor syntactic parsing via bilingual lexica.
We seekto build on this work by utilizing more advancedtranslation techniques.Further in the paper, we first describe the toolsand resources used in our experiments (?2).
Weelaborate on our approach to translating treebanks(?3) and projecting syntactic annotations (?4) for anew language.
Finally, we provide empirical evalu-ation of the suggested approach (?5) and observea substantial increase in parsing accuracy over thedelexicalized parsing baselines.2 Resources and ToolsIn our experiments, we rely on standard resourcesand tools for both dependency parsing and ma-chine translation without any special enhancements.Since we are primarily trying to provide a proofof concept for the use of SMT-derived synthetictraining data in dependency parsing, we believe itis more important to facilitate reproducibility thanto tweak system components to obtain maximumaccuracy.We use the Universal Dependency Treebank v1(McDonald et al., 2013) for annotation projection,parser training and evaluation.
It is a collectionof data sets with consistent syntactic annotationfor six languages: English, French, German, Ko-rean, Spanish, and Swedish.1The annotation isbased on Stanford Typed Dependencies for English(De Marneffe et al., 2006) but has been adaptedand harmonized to allow adequate annotation oftypologically different languages.
This is the firstcollection of data sets that allows reliable evalua-tion of labeled dependency parsing accuracy acrossmultiple languages (McDonald et al., 2013).
Weuse the dedicated training and test sets from thetreebank distribution in all our experiments.
As ar-gued in (McDonald et al., 2013), most cross-lingualdependency parsing experiments up to theirs reliedon heterogeneous treebanks such as the CoNLLdatasets for syntactic dependency parsing (Buch-holz and Marsi, 2006; Nivre et al., 2007a), mak-ing it difficult to address challenges like consistentcross-lingual analysis for downstream applicationsand reliable cross-lingual evaluation of syntacticparsers.
More specifically, none of the previousresearch could report full labeled parsing accura-cies, but rather just unlabeled structural accuraciesacross different attachment schemes.
Followingthe line of McDonald et al.
(2013) regarding the1https://code.google.com/p/uni-dep-tb/131emphasized importance of homogenous data andthe assignment of labels, we only report labeledattachment scores (LAS) in all our experiments.As it is likely the first reliable cross-lingual pars-ing evaluation, we also choose their results as thebaseline reference point for comparison with ourexperiments.For dependency parsing, we use MaltParser(Nivre et al., 2006a)2due to its efficiency in bothtraining and parsing, and we facilitate MaltOpti-mizer (Ballesteros and Nivre, 2012)3to bypass thetedious task of manual feature selection.
Malt-Parser is a transition-based dependency parserthat has been evaluated on a number of differentlanguages with competitive results (Nivre et al.,2006b; Nivre et al., 2007b; Hall et al., 2007) and itis widely used for benchmarking and applicationdevelopment.
Although more accurate dependencyparsers exist for the task of monolingual supervisedparsing, it is not clear that these differences carryover to the cross-lingual scenario, where baselinesare lower and more complex models are more likelyto overfit.
The use of a transition-based parser alsofacilitates comparison with delexicalized transferparsing, where transition-based parsers are domi-nant so far (McDonald et al., 2011; McDonald etal., 2013).
We leave the exploration of additionalparsing approaches for future research.For machine translation, we select the popularMoses toolbox (Koehn et al., 2007) and the phrase-based translation paradigm as our basic frame-work.
Phrase-based SMT has the advantage ofbeing straightforward and efficient in training anddecoding, while maintaining robustness and relia-bility for many language pairs.
More details aboutthe setup and the translation procedures are givenin Section 3 below.
The most essential ingredientfor translation performance is the parallel corpusused for training the translation models.
For ourexperiments we use the freely available and widelyused Europarl corpus v7 (Koehn, 2005).4It is com-monly used for training SMT models and includesparallel data for all languages represented in theUniversal Treebank except Korean, which we will,therefore, leave out in our experiments.
For tuningwe apply the newstest 2012 data provided by the an-nual workshop on statistical machine translation.5For language modeling, we use a combination of2http://www.maltparser.org/3http://nil.fdi.ucm.es/maltoptimizer/4http://www.statmt.org/europarl/5http://www.statmt.org/wmt14DE EN ES FR SVDE 94 M 94 M 96 M 81 MEN 2.0 M 103 M 105 M 89 MES 1.9 M 2.0 M 104 M 89 MFR 1.9 M 2.0 M 2.0 M 91 MSV 1.8 M 1.9 M 1.8 M 1.9 Mmono 22.9 M 17.1 M 6.3 M 6.3 M 2.3 MTable 1: Parallel data and monolingual data usedfor training the SMT models.
Lower-left triangle= number of sentence pairs; upper-right triangle= number of tokens (source and target languagetogether); bottom row = number of sentences inmonolingual corpora.Europarl and News data provided from the samesource.
The statistics of the corpora are given inTable 1.3 Translating TreebanksThe main contribution of this paper is the empiricalstudy of automatic treebank translation for parsertransfer.
We compare three different translationapproaches in order to investigate the influence ofseveral parameters.
All of them are based on auto-matic word alignment and subsequent extraction oftranslation equivalents as common in phrase-basedSMT.
In particular, word alignment is performed us-ing GIZA++ (Och and Ney, 2003) and IBM model4 as the final model for creating the Viterbi wordalignments for all parallel corpora used in our ex-periments.
For the extraction of translation tables,we use the Moses toolkit with its standard settingsto extract phrase tables with a maximum of seventokens per phrase from a symmetrized word align-ment.
Symmetrization is done using the grow-diag-final-and heuristics (Koehn et al., 2003).
We tunephrase-based SMT models using minimum errorrate training (Och, 2003) and the development datafor each language pair.
The language model is astandard 5-gram model estimated from the mono-lingual data using modified Kneser-Ney smoothingwithout pruning (applying KenLM tools (Heafieldet al., 2013)).Our first translation approach is based on a verysimple word-by-word translation model.
For this,we select the most reliable translations of singlewords from the phrase translation tables extractedfrom the parallel corpora as described above.
Werestrict the model to tokens with alphabetic char-acters only using pre-defined Unicode character132sets.
The selection of translation alternatives isbased on the Dice coefficient, which combines thetwo essential conditional translation probabilitiesgiven in the phrase table.
The Dice coefficient is infact the harmonic mean of these two probabilitiesand has successfully been used for the extraction oftranslation equivalents before (Smadja et al., 1996):Dice(s, t) =2 p(s, t)p(s) + p(t)= 2(1p(s|t)+1p(t|s))?1Other association measures would be possible aswell but Smadja et al.
(1996) argue that the Dicecoefficient is more robust with respect to low fre-quency events than other common metrics such aspointwise mutual information, which can be a seri-ous issue with the unsmoothed probability estima-tions in standard phrase tables.
Our first translationmodel then applies the final one-to-one correspon-dences to monotonically translate treebanks wordby word.
We refer to it as the LOOKUP approach.Note that any bilingual dictionary could have beenused to perform the same procedure.The second translation approach (WORD-BASEDMT) is slightly more elaborate but still restrictsthe translation model to one-to-one word mappings.For this, we extract all single word translation pairsfrom the phrase tables and apply the standard beam-search decoder implemented in Moses to translatethe original treebanks to all target languages.
Themotivation for this model is to investigate the im-pact of reordering and language models while stillkeeping the projection of annotated data as simpleas possible.
Note that the language model mayinfluence not only the word order but also the lex-ical choice as we now allow multiple translationoptions in our phrase table.The final model implements translation basedon the entire phrase table using the standard ap-proach to PHRASE-BASED SMT.
We basically runthe Moses decoder with default settings and the pa-rameters and models trained on our parallel corpora.Note that it is important for the annotation trans-fer to keep track of the alignment between phrasesand words of the input and output sentences.
TheMoses decoder provides both, phrase segmentationand word alignment (if the latter is coded into thephrase tables).
This will be important as we willsee in the annotation projection discussed below.ORIGINALDE EN ES FR SV14.0 0.00 7.90 13.3 4.20WORD-BASED MTDE EN ES FR SVDE ?
49.1 62.6 52.8 60.4EN 43.3 ?
27.6 34.8 0.00ES 54.9 25.1 ?
12.3 18.3FR 68.2 39.6 32.8 ?
57.8SV 34.1 5.20 21.6 33.7 ?PHRASE-BASED MTDE EN ES FR SVDE ?
51.5 57.3 58.8 46.8EN 49.3 ?
50.3 61.7 14.6ES 65.9 66.7 ?
62.8 49.0FR 58.0 53.7 44.7 ?
38.2SV 43.9 43.6 49.6 57.1 ?Table 2: Non-projectivity in synthetic treebanks.4 Transferring AnnotationThe next step in preparing synthetic training data isto project the annotation from the original treebankto the target language.
Given the properties of adependency tree, where every word has exactly onesyntactic head and dependency label, the annota-tion transfer is trivial for the two initial translationmodels.
All annotation can simply be copied us-ing the dictionary LOOKUP in which we enforcea monotonic one-to-one word mapping betweensource and target language.In the second approach, we only have to keeptrack of reordering, which is reported by the de-coder when translating with our model.
Note thatthe mapping is strictly one-to-one (bijective) asphrase-based SMT does not allow deletions or in-sertions at any point.
This also ensures that wewill always maintain a tree structure even thoughreordering may have a strong impact on projectiv-ity (see Table 2).
An illustration of this type ofannotation transfer is shown in the left image ofFigure 1.The third model, full PHRASE-BASED SMT, re-quires the most attention when transferring anno-tation across languages.
Here we have to rely onthe alignment information and projection heuris-tics similar to the ones presented in related work(Hwa et al., 2005).
In their work, Hwa et al.
(2005)define a direct projection algorithm that transfersautomatic annotation to a target language via wordalignment.
The algorithm defines a number of133CONJNOUNPRONVERBADPNOUN.QueDieuluivienneenaide!ThatGodhelphimcomein!CONJNOUNNOUNPRONVERBADP.expl nsubj iobjroot adpmodadpobjpexplnsubjadpobjiobjrootadpmod pCONJNOUNPRONVERBADPNOUN.QueDieuluivienneenaide!GodDUMMYhelpDUMMYDUMMYhim!NOUNCONJVERBADPNOUNPRON.expl nsubj iobjrootadpmodadpobjpnsubjexplrootadpmodadpobjiobj pCONJNOUNPRONVERBADPNOUN.QueDieuluivienneenaide!Godhelphim!NOUNVERBPRON.expl nsubj iobjroot adpmodadpobjpnsubjrootiobjpFigure 1: Transferring annotation from French to an English translation with a WORD-BASED translationmodel (left) and with a PHRASE-BASED translation model (middle and right).
Annotation projection usingthe Direct Projection Algorithm by Hwa et al.
(2005) (middle) and our approach (right).heuristics to handle unaligned, one-to-many, many-to-one and many-to-many alignments.
As a side ef-fect, this approach produces several dummy-nodesin the target language to ensure a complete pro-jection of the source language tree (see Hwa et al.
(2005) for more details).In our approach, we try to make use of the addi-tional information provided by the SMT decoder toavoid dummy-nodes and relations that may nega-tively influence the induced target language parser.Compared to the annotation projection approachof Hwa et al.
(2005), the situation in our PHRASE-BASED SMT setting is slightly different.
Here, wehave two types of alignments that can be consideredwhen relating source and target language items: (i)the alignment between phrases (pairs of consec-utive n-grams) and (ii) the phrase-internal wordalignment on which phrase extraction is based.
Theprimary information used for annotation transferis still the latter which has the same properties asdescribed by Hwa et al.
(2005) (except that we havetruly many-to-many alignments in our data whichwere not available in their experiments).Note that words may be unaligned in phrase-based SMT as the phrase extraction algorithm usedin Moses includes unaligned adjacent tokens.
How-ever, for these unaligned words, we know to whichphrase they belong and can also identify the corre-sponding phrase in the other language using phrasealignment information.
This makes it possible toavoid the creation of dummy-nodes altogether andinstead to link unaligned words to existing nodesbased on the given phrase segmentation.Similarly, we define heuristics for handling one-to-many, many-to-one and many-to-many align-ments that avoid the creation of dummy-nodes.
Themain procedure is illustrated in Figure 2.The key feature of this projection algorithm isthat ambiguous alignments are handled by attach-ing words to the nodes that are highest up in thedependency tree (the procedure find highest() re-turns the node with minimum distance to the rootof the tree).
This ensures that we avoid cyclesand isolated cliques in the graph.
Furthermore,unaligned words are attached to the head of thetarget phrase they belong to, which seems to be themost appropriate place without further knowledge.The procedures in trg phrase() and in src phrase()make use of the phrase segmentation used in thetranslation process.One complication is the search for the corre-sponding target head word in cases where thesource language head is not aligned or aligned tomultiple target language words.
Figure 3 showsthe head alignment procedure that we define in ourprojection algorithm.
Procedure find aligned() re-turns the rightmost word of all words aligned to thegiven source language word s. Other heuristics orlinguistically motivated rules based on POS tagsand general language properties would be possiblehere as well.
If s is not aligned, we move up inthe dependency tree until we hit ROOT or find analigned word.
If we are at the root position wereturn ROOT as this does not require further map-pings.
The effect of this algorithm is illustrated bythe right-hand side image in Figure 1.5 Parsing Across LanguagesIn this section, we present the results of two ex-perimental batches.
First, we establish the base-134Input: source tree S, target sentence T ,word alignment A, phrase segmentation POutput: syntactic heads head[],word attributes attr[]1 treeSize = max distance to root(S) ;2 attr = [] ;3 head = [] ;4 for t ?
T do5 if is unaligned trg(t,A) then6 for t?
?
in trg phrase(t,P) do7 [sx,..,sy] = aligned to(t?)
;8 ?s = find highest([sx,..,sy],S) ;9?t = find aligned(?s,S,T,A) ;10 attr[t] = DUMMY ;11 head[t] =?t ;12 end13 else14 [sx,..,sy] = aligned to(t) ;15 s = find highest([sx,..,sy],S) ;16 attr[t] = attr(s) ;17 ?s = head of(s,S) ;18?t = find aligned(?s,S,T,A) ;19 if?t == t then20 [sx,..,sy] = in src phrase(s,P) ;21 s* = find highest([sx,..,sy],S) ;22 ?s = head of(s*,S) ;23?t = find aligned(?s,S,T,A) ;24 head[t] =?t ;25 end26 end27 endFigure 2: Annotation projection algorithm.lines by comparing monolingual supervised pars-ing to delexicalized transfer parsing following theapproach of McDonald et al.
(2013).
Second, wepresent the results obtained with parsers trainedon target language treebanks produced using ma-chine translation and annotation projection.
Here,we also look at delexicalized models trained ontranslated treebanks to show the effect of machinetranslation without additional lexical features.5.1 Baseline ResultsFirst we present the baseline parsing scores.
Thebaselines we explore are: (i) the monolingual base-line, i.e., training and testing using the same lan-guage data from the Universal Dependency Tree-bank and (ii) the delexicalized baseline, i.e., apply-ing delexicalized parsers across languages.For the monolingual baseline, MaltParser mod-els are trained on the original treebanks with uni-versal POS labels and lexical features but leavingout other language-specific features if they exist inthe original treebanks.
The delexicalized parsersare trained on universal POS labels only for eachlanguage and are then applied to all other languagesInput: node s, source tree S with root ROOT,target sentence T , word alignment AOutput: node t*1 if s == ROOT then2 return ROOT ;3 end4 while is unaligned src(s,A) do5 s = head of(s,S) ;6 if s == ROOT then7 return ROOT ;8 end9 end10 p = 0 ;11 t* = undef ;12 for t?
?
aligned(s,A) do13 if position(t?,T) > p then14 t* = t?
;15 p = position(t?,T) ;16 end17 end18 return t* ;Figure 3: Procedure find aligned().without modification.
For all models, features andoptions are optimized using MaltOptimizer.
Theaccuracy is given in Table 3 as a set of labeled at-tachment scores (LAS).
We include punctuationin our evaluation.
Ignoring punctuation generallyleads to slightly higher scores as we have noted inour experiments but we do not report those num-bers here.
Note also that the columns represent thetarget languages (used for testing), while the rowsdenote the source languages (used in training), asin McDonald et al.
(2013).From the table, we can see that the baselinescores are compatible with the ones in the orig-inal experiments presented by (McDonald et al.,2013), included in Table 3 for reference.
The dif-ferences are due to parser selection, as they use atransition-based parser with beam search and per-ceptron learning along the lines of Zhang and Nivre(2011) whereas we rely on greedy transition-basedparsing with linear support vector machines.
In thefollowing, we will compare results to our baselineas we have a comparable setup in those experi-ments.
However, most improvements shown belowalso apply in comparison with (McDonald et al.,2013).5.2 Translated TreebanksNow we turn to the experiments on translated tree-banks.
We consider two setups.
First, we look atthe effect of translation when training delexical-ized parsers.
In this way, we can perform a directcomparison to the baseline performance presented135MONOLINGUALDE EN ES FR SV72.13 87.50 78.54 77.51 81.28DELEXICALIZEDDE EN ES FR SVDE 62.71 43.20 46.09 46.09 50.64EN 46.62 77.66 55.65 56.46 57.68ES 44.03 46.73 68.21 57.91 53.82FR 43.91 46.75 59.65 67.51 52.01SV 50.69 49.13 53.62 51.97 70.22MCDONALD ET AL.
(2013)DE EN ES FR SVDE 64.84 47.09 48.14 49.59 53.57EN 48.11 78.54 56.86 58.20 57.04ES 45.52 47.87 70.29 63.65 53.09FR 45.96 47.41 62.56 73.37 52.25SV 52.19 49.71 54.72 54.96 70.90Table 3: Baselines ?
labeled attachment score(LAS) for monolingual and delexicalized transferparsing.
Delexicalized transfer parsing results ofMcDonald et al.
(2013) included for reference.above.
The second setup then considers fully lexi-calized models trained on translated treebanks.
Themain advantage of the translation approach is theavailability of lexical information and this finalsetup represents the real power of this approach.In it, we compare lexicalized parsers trained ontranslated treebanks with their delexicalized coun-terparts and avoid a direct comparison with thedelexicalized baselines as they involve differenttypes of features.5.3 Delexicalized ParsersTable 4 presents the scores obtained by trainingdelexicalized parsing models on synthetic data cre-ated by our translation approaches presented earlier.Feature models and training options are the sameas for the delexicalized source language modelswhen training and testing on the target languagedata.
Note that we exclude the simple dictionaryLOOKUP approach here, because this approachleads to identical models as the basic delexicalizedmodels.
This is because words are translated one-to-one without any reordering which leads to ex-actly the same annotation sequences as the sourcelanguage treebank after projecting POS labels anddependency relations.From the table, we can see that all but one modelimprove the scores obtained by delexicalized base-line models.
The improvements are quite substan-tial up to +6.38 LAS.
The boost in performanceWORD-BASED MTDE EN ES FR SVDE ?
48.12(4.92)50.84(4.75)52.92(6.83)55.52(4.88)EN 49.53(2.91)?
57.41(1.76)58.53(2.07)57.82(0.14)ES 45.48(1.45)48.46(1.73)?
58.29(0.38)55.25(1.43)FR 46.59(2.68)47.88(1.13)59.72(0.07)?
52.31(0.30)SV 52.16(1.47)49.14(0.01)56.50(2.88)56.71(4.74)?PHRASE-BASED MTDE EN ES FR SVDE ?
45.43(2.23)47.26(1.17)49.14(3.05)53.37(2.73)EN 49.16(2.54)?
57.12(1.47)58.23(1.77)58.23(0.55)ES 46.75(2.72)46.82(0.09)?
58.22(0.31)54.14(0.32)FR 48.02(4.11)49.06(2.31)60.23(0.58)?
55.24(3.23)SV 50.96(0.27)46.12?3.0155.95(2.33)54.71(2.74)?Table 4: Translated treebanks: labeled attachmentscore (LAS) for delexicalized parsers trained onsynthetic data created by translation.
Numbers insuperscript show the absolute improvement overour delexicalized baselines.is especially striking for the simpleWORD-BASEDtranslation model considering that the only differ-ence to the baseline model is word order.
Theimpact of the more complex PHRASE-BASED trans-lation model is, however, difficult to judge.
In14 out of 20 models it actually leads to a drop inLAS when applying phrase-based translation in-stead of single-word translation.
This is somewhatsurprising but is probably related to the additionalambiguity in annotation projection introduced bymany-to-many alignments.
The largest drop can beseen for Swedish translated to English, which evenfalls behind the baseline performance when usingthe PHRASE-BASED translation model.5.4 Lexicalized ParsersThe final experiment is concerned with lexicalparsers trained on translated treebanks.
The mainobjective here is to test the robustness of fully lexi-calized models trained on noisy synthetic data cre-ated by simple automatic translation engines.
Ta-ble 5 lists the scores obtained by our models whentrained on treebanks translated with our three ap-proaches (dictionary LOOKUP, WORD-BASED MTand full PHRASE-BASED translation).
Again, weuse the same feature model and training options asfor the source language model when training mod-els for the target languages.
This time, of course,this refers to the features used by the lexicalizedbaseline models.The capacity of the parsing models increases dueto the lexical information which is now included.In order to see the effect of lexicalization, we com-136DETDETNOUNVERBADPNOUNCONJADPDETNOUNADJ.Toussesproduitssontdequalite?etd?unefraicheurexemplaires.Allhisproductsarehigh-qualityandacoldmulletcopies.DETDETNOUNVERBNOUNADPCONJDETNOUNNOUNADJ.det possnsubjrootadpmodadpobjccconjdetadpobjamodpdetpossnsubjrootadpobjadpmodccdetadpobj adpobjamodpFigure 4: Problematic annotation projection with ambiguous word alignment.pare the performance now with the correspondingdelexicalized models.
Note that the LOOKUP ap-proach relates to the delexicalized baseline modelswithout any translation.As we can see, all models outperform their cor-responding delexicalized version (with one excep-tion), which demonstrates the ability of the trainingprocedure to pick up valuable lexical informationfrom the noisy translations.
Again, we can seesubstantial absolute improvements of up to +7.31LAS showing the effectiveness of the translationapproach.
Note that this also means that we outper-form the delexicalized baselines in all cases by alarge margin, even if we should not directly com-pare these models as they draw on different fea-ture sets.
Once again, we can also see that thevery simple methods are quite successful.
Even thevery basic LOOKUP approach leads to significantimprovements with one minor exception.
Surpris-ingly, no gain can be seen with the PHRASE-BASEDtranslation approach.
The translation quality is cer-tainly better when manually inspecting the data.However, the increased complexity of annotationprojection seems to pull down the parsers inducedon that kind of data.
A question for future workis whether the performance of those models canbe improved by better projection algorithms andheuristics that lead to cleaner annotations of other-wise better translations of the original treebanks.One possible reason for this disappointing re-sult could be the unreliable mapping of POS labelsacross many-to-many alignments.
Figure 4 illus-trates a typical case of link ambiguity that leads toerroneous projections.
For example, the mappingof the label ADP onto the English word quality isdue to the left-to-right procedure applied in our pro-jection algorithm and the mapping of the NOUNlabel to the English adjective cold is due to thelink to fraicheur.
How much these errors effect ourparsing models trained on the projected treebanksis difficult to estimate and further investigations arerequired to pinpoint these issues and to find waysof addressing problems that may occur in variouscontexts.Nevertheless, the overall results are very positive.The experiments clearly show the potentials of thetranslation approach.
Note that this paper presentsthe first attempt to study the effect of translation oncross-lingual parser induction.
Further optimiza-tion of the translation process and the connectedannotation projection procedures should lead tofurther improvements over our basic models.6 Conclusions and Future WorkIn this paper, we have addressed the problem ofcross-lingual parser induction by using statisticalmachine translation to create synthetic training data.Our SMT approach avoids the noisy source-side137LOOKUPDE EN ES FR SVDE ?
48.63(5.43)52.66(6.57)52.06(5.97)58.78(8.14)EN 48.59(1.97)?
57.79(2.14)57.80(1.34)62.21(4.53)ES 47.36(3.33)49.13(2.40)?
62.24(4.33)57.50(3.68)FR 47.57(3.66)54.06(7.31)66.31(6.66)?
57.73(5.72)SV 51.88(1.19)48.84(0.29)54.74(1.12)52.95(0.98)?WORD-BASED MTDE EN ES FR SVDE ?
51.86(3.74)55.90(5.06)57.77(4.85)61.65(6.13)EN 53.80(4.27)?
60.76(3.35)63.32(4.79)62.93(5.11)ES 49.94(4.46)49.93(1.47)?
65.60(7.31)59.22(3.97)FR 52.07(5.48)54.44(6.56)65.63(5.91)?
57.67(5.36)SV 53.18(1.02)50.91(1.77)60.82(4.32)59.14(2.43)?PHRASE-BASED MTDE EN ES FR SVDE ?
50.89(5.46)52.54(5.28)54.99(5.85)59.46(6.09)EN 53.71(4.55)?
60.70(3.58)62.89(4.66)64.01(5.78)ES 49.59(2.84)48.35(1.53)?
64.88(6.66)58.99(4.85)FR 51.83(3.81)53.81(4.75)65.55(5.32)?
59.01(3.77)SV 53.22(2.26)49.06(2.94)58.41(2.46)58.04(3.33)?Table 5: Translated treebanks: labeled attachment score (LAS) for lexicalized parsers trained on syntheticdata.
Numbers in superscript show the absolute improvements over the delexicalized models based on thesame translation strategy.annotations of traditional annotation projection andmakes it possible to train fully lexicalized target lan-guage models that significantly outperform delexi-calized transfer parsers.
We have also demonstratedthat translation leads to better delexicalized modelsthat can directly be compared with each other asthey are based on the same feature space.We have compared three SMT methods for syn-thesizing training data: LOOKUP-based translation,WORD-BASED translation and full PHRASE-BASEDtranslation.
Our experiments show that even noisydata sets and simple translation strategies can beused to achieve positive results.
For all three ap-proaches, we have recorded substantial improve-ments over the state of the art in labeled cross-lingual parsing (McDonald et al., 2013).
Accordingto our results, simple word-by-word translationsare often sufficient to create reasonable translationsto train lexicalized parsers on.
More elaboratedphrase-based models together with advanced anno-tation projection strategies do not necessarily leadto any improvements.As future work, we want to improve our modelby (i) studying the impact of other SMT propertiesand improve the quality of treebank translation,(ii) implementing more sophisticated methods forannotation projection and (iii) using n-best listsprovided by SMT models to introduce additionalsynthetic data using a single resource.
We also aimat (iv) applying our approach to transfer parsingfor closely related languages (see Agi?c et al.
(2012)and Zeman and Resnik (2008) for related work),(v) testing it in a multi-source transfer scenario(McDonald et al., 2011) and, finally, (vi) comparingdifferent dependency parsing paradigms within ourexperimental framework.Multi-source approaches are especially appeal-ing using the translation approach.
However, initialexperiments (which we omit in this presentation)revealed that simple concatenation is not sufficientto obtain results that improve upon the single-besttranslated treebanks.
A careful selection of appro-priate training examples and their weights givento the training procedure seems to be essential tobenefit from different sources.7 AcknowledgementsThis work was supported by the Swedish ResearchCouncil (Vetenskapsr?adet) through the project onDiscourse-Oriented Machine Translation (2012-916).138References?Zeljko Agi?c, Danijela Merkler, and Da?sa Berovi?c.2012.
Slovene-Croatian Treebank Transfer UsingBilingual Lexicon Improves Croatian DependencyParsing.
In Proceedings of IS-LTC 2012, pages 5?9.Miguel Ballesteros and Joakim Nivre.
2012.
MaltOp-timizer: An Optimization Tool for MaltParser.
InProceedings of EACL 2012, pages 58?62.Emily M. Bender.
2013.
Linguistic Fundamentals forNatural Language Processing: 100 Essentials fromMorphology and Syntax.
Morgan & Claypool Pub-lishers.Sabine Buchholz and Erwin Marsi.
2006.
CoNLL-X Shared Task on Multilingual Dependency Parsing.In Proceedings of CoNLL 2006, pages 149?164.Marie-Catherine De Marneffe, Bill MacCartney, andChristopher D. Manning.
2006.
Generating TypedDependency Parses from Phrase Structure Parses.
InProceedings of LREC 2006, pages 449?454.Greg Durrett, Adam Pauls, and Dan Klein.
2012.
Syn-tactic Transfer Using a Bilingual Lexicon.
In Pro-ceedings of EMNLP-CoNLL 2012, pages 1?11.Kuzman Ganchev and Dipanjan Das.
2013.
Cross-Lingual Discriminative Learning of Sequence Mod-els with Posterior Regularization.
In Proceedings ofEMNLP 2013, pages 1996?2006.Johan Hall, Jens Nilsson, Joakim Nivre, G?ulsen Eryi?git,Be?ata Megyesi, Mattias Nilsson, and Markus Saers.2007.
Single Malt or Blended?
A Study in Mul-tilingual Parser Optimization.
In Proceedings ofthe CoNLL Shared Task Session of EMNLP-CoNLL2007, pages 933?939.Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H.Clark, and Philipp Koehn.
2013.
Scalable Mod-ified Kneser-Ney Language Model Estimation.
InProceedings of ACL 2013, pages 690?696.Rebecca Hwa, Philip Resnik, Amy Weinberg, ClaraCabezas, and Okan Kolak.
2005.
Bootstrap-ping Parsers via Syntactic Projection across ParallelTexts.
Natural Language Engineering, 11(3):311?325.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical Phrase Based Translation.
In Pro-ceedings of NAACL-HLT 2003, pages 48?54.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Christopher J. Dyer, Ond?rej Bojar,Alexandra Constantin, and Evan Herbst.
2007.Moses: Open Source Toolkit for Statistical MachineTranslation.
In Proceedings of ACL 2007, pages177?180.Philipp Koehn.
2005.
Europarl: A Parallel Corpus forStatistical Machine Translation.
In Proceedings ofMT Summit 2005, pages 79?86.Ryan McDonald, Slav Petrov, and Keith Hall.
2011.Multi-Source Transfer of Delexicalized DependencyParsers.
In Proceedings of EMNLP 2011, pages 62?72.Ryan McDonald, Joakim Nivre, Yvonne Quirmbach-Brundage, Yoav Goldberg, Dipanjan Das, Kuz-man Ganchev, Keith Hall, Slav Petrov, HaoZhang, Oscar T?ackstr?om, Claudia Bedini, N?uriaBertomeu Castell?o, and Jungmee Lee.
2013.Universal Dependency Annotation for MultilingualParsing.
In Proceedings of ACL 2013, pages 92?97.Tahira Naseem, Regina Barzilay, and Amir Globerson.2012.
Selective Sharing for Multilingual Depen-dency Parsing.
In Proceedings of ACL 2012, pages629?637.Joakim Nivre, Johan Hall, and Jens Nilsson.
2006a.MaltParser: A Data-Driven Parser-Generator for De-pendency Parsing.
In Proceedings of LREC 2006,pages 2216?2219.Joakim Nivre, Johan Hall, Jens Nilsson, G?ulsen Eryi?git,and Svetoslav Marinov.
2006b.
Labeled Pseudo-Projective Dependency Parsing with Support VectorMachines.
In Proceedings of CoNLL 2006, pages221?225.Joakim Nivre, Johan Hall, Sandra K?ubler, Ryan Mc-Donald, Jens Nilsson, Sebastian Riedel, and DenizYuret.
2007a.
The CoNLL 2007 Shared Task onDependency Parsing.
In Proceedings of the CoNLLShared Task Session of EMNLP-CoNLL 2007, pages915?932.Joakim Nivre, Johan Hall, Jens Nilsson, AtanasChanev, G?uls?en Eryi?git, Sandra K?ubler, SvetoslavMarinov, and Erwin Marsi.
2007b.
MaltParser: ALanguage-Independent System for Data-Driven De-pendency Parsing.
Natural Language Engineering,13(2):95?135.Franz Josef Och and Hermann Ney.
2003.
A System-atic Comparison of Various Statistical AlignmentModels.
Computational Linguistics, 29(1):19?52.Franz Josef Och.
2003.
Minimum Error Rate Trainingin Statistical Machine Translation.
In Proceedingsof ACL 2003, pages 160?167.Slav Petrov, Dipanjan Das, and Ryan McDonald.
2012.A Universal Part-of-Speech Tagset.
In Proceedingsof LREC 2012, pages 2089?2096.Frank Smadja, Vasileios Hatzivassiloglou, and Kath-leen R. McKeown.
1996.
Translating Colloca-tions for Bilingual Lexicons: A Statistical Approach.Computational Linguistics, 22(1):1?38.139Oscar T?ackstr?om, Ryan McDonald, and Jakob Uszko-reit.
2012.
Cross-lingual Word Clusters for DirectTransfer of Linguistic Structure.
In Proceedings ofNAACL 2012, pages 477?487.Oscar T?ackstr?om, Dipanjan Das, Slav Petrov, RyanMcDonald, and Joakim Nivre.
2013a.
Token andType Constraints for Cross-lingual Part-of-speechTagging.
Transactions of the Association for Com-putational Linguistics, 1:1?12.Oscar T?ackstr?om, Ryan McDonald, and Joakim Nivre.2013b.
Target Language Adaptation of Discrimi-native Transfer Parsers.
In Proceedings of NAACL2013, pages 1061?1071.David Yarowsky, Grace Ngai, and Richard Wicen-towski.
2001.
Inducing Multilingual Text AnalysisTools via Robust Projection Across Aligned Corpora.In Proceedings of HLT 2011, pages 1?8.Daniel Zeman and Philip Resnik.
2008.
Cross-Language Parser Adaptation between Related Lan-guages.
In Proceedings of IJCNLP 2008, pages 35?42.Yue Zhang and Joakim Nivre.
2011.
Transition-basedDependency Parsing with Rich Non-local Features.In Proceedings of ACL 2011, pages 188?193.Hai Zhao, Yan Song, Chunyu Kit, and Guodong Zhou.2009.
Cross Language Dependency Parsing Using aBilingual Lexicon.
In Proceedings of ACL-IJCNLP2009, pages 55?63.140
