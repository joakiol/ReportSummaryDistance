A Syntactic and Morphological Analyzer for aText-to-Speech SystemThomas  Russ iIns t i tu te  of  E lec t ron ics ,  Swiss Federa l  Ins t i tu te  of  Techno logy  (ETH)CH 8092 Zfir ich, Swi tzer land ,  e -maih  russ i@st ra t i .e thz .chAbstractThis paper presents a system which analyzes an in-'put text syntactically and morphologically and con-verts the text from the graphemic to the phonetic:representation (or vice versa).
We describe the gram-mar formaSsm used and report a parsing experimentwhich compared eight parsing strategies within the:h'amework of chart parsing.
Although the morpho-logical and syntactic analyzer has been developed fora text-to-speech system for German, it is languageindependent and general enough to be used for dia-log systems, NL-interfaces or speech recognition sys-tems.1 Introduct ion\]n order to convert text to speech one must firstderive an underlying abstract linguistic represen-tation for the text.
There are at least two rea-.,sons why a direct approach (e.g,, letter-to-soundrules) is inadequate.
Firstly, rules for pronounc-ing words must take into consideration morpheme:;trueture, e.g., <sch> is pronouced differently inthe German words "16sch+en" ("extinguish") and"Hgs+chen" (diminutive of "trousers"), and syn-tactic structure, e.g., to solve noun-verb arnbigui-~ies such as "Sucht" ("addiction") and "sucht" ("to~earch").
Secondly, sentence duration pattern andfundamental frequency contour depend largely ont;he structure of the sentence.While most commercial, but also some laboratorytext-to-speech (TTS) systems use letter-to-soundrules without taking into account the morphologi-cal structure of a word, recently developed systems\[1,2,3\] incorporate morphological nalysis.
Althoughthe influence of syntax on prosody is widely acknowl-edged \[2,3\], most TTS systems lack syntax analysisl.l,3\] or use some kind of phrase-level parsing \[2\] toobtain information on the syntactic structure of a:;entence.
"_~'his  motivated more by current echno-logical limitations than by linguistic insights.We areconvinced that in order to achieve highly intelligibleand natural~sounding speech, not only the phonologi-cal and morphological but also the syntactic, seman-~,ic and even discourse structure of a text must be~,aken into account - although this is not yet feasible.As a step toward such a model, we have developeda morphological nd syntactic analyzer that is basedon simple but powerful formalisms which are linguis-tically well-motivated and computationMly effective.2 Morphological  and Syntac-tic AnalysisIn our TTS system, morphological nalysis consistsof three stages: segmentation, parsing and genera-tion.
The segmentation module finds possible waysto partition the input string into dictionary entries(morphs).
Spelling changes, e.g., schwa-insertion orelision, are covered by morphographemic rules.
Theparsing module of the morphological nalysis uses aword grammar to accept or reject combinations ofdictionary entries and to percolate features from thelexicon to the syntactic analyzer.
The generationmodule of the Inorphologica\] analysis generates thephonetic transcription by concatenating the phoneticstrings, which are stored as part of each morph entry,and by applying morphophonetic rules.
The syntac-tic analysis is based on a sentence grammar and aparser that takes as input the result of the morpho-logical analyzer.
It assigns to each sentence its sur-face syntactic structure.
The syntactic structure ofthe sentence and the phonetic transcription of eachword are used at a later stage to determine prosodicfeatures uch as duration pattern and flmdamentalfrequency contour.3 UTN FormalismMorphographemic and morphophonetic rules arewritten ill a Kimmo-style formalism \[4 i. Unlikethe original two-level model, a word grammar isused to parse the lexical strings and to determinethe category of the overall word formed by severalmorphs.
.To express word and sentence grammars,we have developed a grammar formalism, calledUnification-based Transition Networks (UTN), I~sskeleton are nondeterministic reeursive transitionnetworks (RTNs), which are equivalent o comex~-free gramnmrs.
A transition network speciIies thelinear precedence and immediate dominance relation443within a constituent.
Each label of a transition de-notes a preterminal, a constituent or an e-transition.As opposed to labels in RTNs, which are monadic,labels in UTNs are complex categories (features ma-trices).
Each transition contains a set of attributeequations, which specify the constraints that mustbe satisfied between complex categories in a network.Our notation of attribute equations is very similarto that commonly used in unification-based rule for-malisms such as PArR  \[5\].
The UTN formalism isfully declarative.
It ix based on concatenation andrecursion, which is reflected in the topology of thenetworks, and unification, which is used for match-ing, equality testing and feature passing.
Althoughthe UTN formalism is somewhat similar to ATNs!6!, it is much more concise and elegant because ofits simplicity and declarativeness.
The implemen-tation of several grammars for German syntax andmorphosyntax revealed that transition networks arewell-suited to design 1 and test grammars.
We be-lieve that this formalism meets the general criteriaof linguistic naturalness and mathematical power.in addition, the parsing experiment reported belowshows that efficient parsers can be implemented forthe UTN formalism.The design of our TTS system requires efIicient pars-ing algorithms and a flexible parser environment tocompare several search and rule invocation strate-gies.
Active chart parsing 18\] is well-suited for thatpurpose.
We have implemented a general chartparser that can be parameterized fox several searchand rule invocation strategies.
The aim of the ex-periment reported below was to investigate to whatextent a parser can be directed by using the FIRST,FOLLOW and REACHABILITY relations \[9,8} andcombinations thereof, thereby reducing the nunrberof edges, the nmnber of applications of the funda-mental rule and parsing time.Str AE IE TOT FR TIME--B-2-- 89763 l ~  96812_ ~ 1 - ~~B3- 123344 ~10080~ 133424 ~_1 .~_~__~87 86 60121 I 1.00ATable 1: Parsing sentence set SI with grammar GIstrategy, uses the FIRST relation to test whetherthe next input symbol is in the FIRST set of the ac-tive edge each time an empty active edge is created.Strategy T3, a top-down strategy with lookahead,uses the FOLLOW set to test whether the next imput symbol belongs to the FOLLOW set of the imactive edge each time an inactive edge is created.Strategy T4 combines the selectivity of strategy T2and lookahead of strategy T3.
Strategy B1 imple-ments a left-corner algorithm \[19\].
Strategy B2 is ,~left-corner parser directed by a top-down filter basedon the t lEACHABILITY relation \[10\].
Strategy B3implements a left-corner algorithm with lookaheadsimilar to that of strategy T3, while strategy B4 addsa top-down filter and lookahead to the left-corner al--gorithm.4?2 Grammars  and  :~_?est SetsFor the experiment presented h~re, we used a gram--mar (GI) for German syntax:" that has been devel-oped for our TTS system and a grammar (El i)  forEnglish syntax a (GII) to compare our ~esults withthose of other experiments (\[7,11,10\]).
Our s~entencesets consist of 35 German sentences (set SI, with anaverage sentence length of 9.8 words) and 39 Englishsentences (set SII, with an average sentence lengthof 15.3 words) from Tomita \[7\], pp.
185-189.4.1 Ru le  Invocat ion  S t ra teg iesWe compared eight parsing strategies, i.e., four top-down (T1 to T4) and four bottom-up (El to B4)strategies.
The top-down strategies are variants ofEarley's algorithm, the bottom-up strategies vari-ants of the left-corner algorithm \[9\].
T1, a pure top-down strategy, implements Earley's algorithm with-out lookahead.
Strategy T2, a directed top-down1To compare the UTN formalism with rule-based for-mal isms, we translated several grammars to transi t ion net-works.
As an example, the grammar GI I I  found in Tomita 'sbook \[7\] with about  220 rules was translated to a stronglyequivalent network grarrm~ar of 37 transi t ion networks.
Wegot the impression that it is easier to write and modify a net-work grammar  of several dozen networks (that can be dis-played and edited graphical ly) than one of several hundredsof rules.4.3 Resu l t sTables 1 and 2 show the results of parsing sets SIand SII with grammars GI and GII, respectively.
Wemeasured for all strategies (T1 to B4) the number ofactive (AE) and inactive (IE) edges, the total num-ber of edges (TOT = AE+IE)  and parsing time 4(TIME).
Since the UTN formalism is based on uni-fication, a time- and space-consuming operation, wealso indicate the number of applications of the funda-mental rule (FR) to show the relation between pars-ing strategy and FR applications.2This g rammar  consists of 48 networks, 770 transit ions,1246 unif ication equations and describes a substant ia l  part  ofGerman syntax.This g rammar  is a strongly equivalent, network grammarof Tornita's g rammar  GIII.4 Parsing t ime is ind icated relative to the fastest algorithm.444T1T22t23T4B 1B 2B3B491578 16946169160 16946176288 13880155173 13880 I210021 493721990{}1 227971169299 40022184984 194151TOT10852486106 5468990168 4422669053 44226259393 168871121798 75509209321 138232104399 6501654689 1.50 I1.08 {1.35 I1.00 I3.00 I1.56 I2.68 I1.55 ITable 2: Parsing sentence set SII with grammar GIIOur experiments confirm the results of Shann andWir6n \[10,1111 that parsing efficiency depends heavilyon the grammar, the language, the grammar formal-ism and the sentence set.
Nevertheless, by carefullytuning a parsing strategy, a significant increase inefficiency is gained.frndireeted top-down parsing performs better thanundirected bottom-up.
This coincides with the re-sults of Wir6n.
Directed strategies 5 outperformundirected strategies with respect to parsing timeand memory.
This holds for top-down and bottom-up strategies.Previous experiments \[11,10,7\] did not investi-gate the influence of lookahead in top-down parsing.However, using lookahead (the FOLLOW relation)sig:tfificantly reduces the number of edges, the num-bex of applications of the fundamental rule and pars-ing time.Directed top-down parsing with lookahead is asfast as left-corner parsing with top-down fih.ering andlookahead.
The difference between the two strate-gies is statistically insignificant when considering allexperiments conducted with all German grammarsand several sentence sets.
However, it is uncertainto what extent this slatement can be generalized toother types of grammars and languages.
Ba~sed onthe results of our experiments, both strategies (T4and B4) are suited as main strategies in our TTSsystem.5 Conc lud ing  RemarksWe have presented a language~-independenl modelfor syntactic and morphological analysis.
Specialemphasis has been laid on the description of theUTN formalism and a parser experiment which com-par{'d different rule invocation strategies.
The ana-lyzer is fully implemented in Common Lisp and itsapplication in a text-to-speech system has signitl-eantly improved the quality of the synthetic speech.Since the grapheme-to-phoneme conversion is bidi-reclional, our approach may also be promising forspeech recognition.5The algorithm of TomJta can be considered a maximallydirected charl-parser that uses the FIRST trod FOLLOW re-lation to construct an Lit-table at compile time.References\[1\]\[2\]\[3\]A. Pounder and M. Kommenda.
MorphologicalAnalysis for a German Text-to-Speech System.In Proceedings of the llth International Confer?ence on Computational Linguistics, pages 263-268, 1986.D.H.
Klatt.
Review oftext-to.-speech onversionfor English.
Journal of the Acoustical Society ofAmerica, 82(3):737-793, September 1987.W Daelemans.
Grafon: A Grapheme-to-Phoneme C.onversion System for Dutch.
In Pro-ceedings of the 12th International Conferenceon Computational Linguistics, pages 133-138,1988.\[4\] K. Koskenniemi.
Two-level Morphology: AGeneral Computational Model for Word-FormRecognition and Production.
PhD thesis, Uni-versity of Helsinki, 1983.\[5\] S. M. Shieber.
An Introduction to Unification-Based Approaches to Grammar.
CSLI LectureNotes 4, Center for the Study of Language andInformation, 1986.\[6\] M. Bates.
The Theory and Practice of Aug-mented rl)ansition Network Grammars.
In L.Bole, editor, Natural Lang'aage Communicationwith Computers, pages 191--259, Springer Ver-lag, 1978.\[7\] M. Tomita.
Efficient t~arsing for Natural Lar~-guage.
Kluwer Academic Publishers, 1986.\[8\] M. Kay.
Algorithm schemata nd data strucuresin syntactic processing.
In St. Allfin: editor,Tezt Processing: Text Analysi'.~ and Geueration,Y~x~ Typology and A~tribution, pages 327-358,Almqvist and Wiksell International, Stockholm,Sweden, 1982.\[9 i A.V.
Aho and 3.D.
Ulhnan.
The Theory ofParsing, ~?
'ansla~zo'n, a d Compiling.
Auto-matte Computation, Prentice-Hall Inc., Engle-wood Cliffs, N.Y., 1972.\[101 P. Shann.
The selectiov of a parsing strategyfor an on-line machine translation system in asublanguage domain.
A new practical compari-son.
In Proc.
of the International Workshop onParsin 9 Technologies, pages 264-276, CarnegieMellon University, 1989.\[11\] M. Wir6n.
A comparison of rule-invocationstrategies in context-free chart parsing.
InACL Proceedings, Third E~ropean Conference,pages 226-233, Association for ComputationalLinguistics, 1987.445
