Proceedings of the ACL Workshop on Building and Using Parallel Texts, pages 119?124,Ann Arbor, June 2005. c?Association for Computational Linguistics, 2005Shared Task: Statistical Machine Translation between European LanguagesPhilipp KoehnSchool of InformaticsUniversity of EdinburghEdinburgh, EH8 9LW, UKpkoehn@inf.ed.ac.ukChristof MonzUMIACSUniversity of MarylandCollege Park, MD 20742, USAchristof@umiacs.umd.eduAbstractThe ACL-2005 Workshop on Paral-lel Texts hosted a shared task onbuilding statistical machine translationsystems for four European languagepairs: French?English, German?English,Spanish?English, and Finnish?English.Eleven groups participated in the event.This paper describes the goals, the taskdefinition and resources, as well as resultsand some analysis.Statistical machine translation is currently thedominant paradigm in machine translation research.Annual competitions are held for Chinese?Englishand Arabic?English by NIST (sponsored by the USmilitary funding agency DARPA), which creates aforum to present and compare novel ideas and leadsto steady progress in the field.One of the advantages of statistical machine trans-lation is that the currently applied methods are fairlylanguage-independent.
Building a new machinetranslation system for a new language pair is notmuch more than a matter of running a training pro-cess on a training corpus of parallel text (a text inone language paired with a translation in another).It is therefore possible to hold a competitionwhere research groups have only a few weeks tobuild machine translation systems for language pairsthat they have not previously worked on.
We effec-tively demonstrated this with our shared task.
For in-stance, seven teams built Finnish?English machinetranslation systems, a language pair that was cer-tainly not of their immediate concern before.In contrast to the bigger NIST competition, wewanted to keep the barrier of entry as low as possi-ble.
We provided not only training data from the Eu-roparl corpus (Koehn, 2005), but also additional re-sources: sentence and word alignments, the decoderPharaoh1 (Koehn, 2004b), and a language model,so that participation was feasible even as a graduatelevel class project.Using about 15 million words of translated text,participants were asked to build a phrase-based sta-tistical machine translation system.
The focus ofthe task was to build a probabilistic phrase transla-tion table, since most of the other resources wereprovided ?
for more on phrase-based statisticalmachine translation, refer to Koehn et al (2003).The participants?
systems were compared by howwell they translated 2000 previously unseen test sen-tences from the same domain.The shared task operated within an extremelyshort timeframe.
The workshop and hence theshared task was accepted on February 22, 2005 andannounced on March 3.
The official test data wasmade available on April 3, results were due oneweek later.
Despite this tight schedule, eleven re-search groups participated and built a total of 32 ma-chine translation systems for the four language pairs.1 GoalsWhen setting up this competition, we were moti-vated by a number of goals.
We set out to:Create a platform to demonstrate the effective-ness of novel ideas: The research community iseasily balkanized, where different groups work on1http://www.isi.edu/licensed-sw/pharaoh/119different data sets and under different conditions,so that it becomes often hard to assess, how effec-tive a novel method is.
By creating an environmentwith common test and training sets, language model,preprocessing, and even decoder, the effect of othermodel choices can be more easily demonstrated.Work on new language pairs, new problems:Different language pairs pose different challenges.We picked Finnish?English and German?Englishfor the special problems of rich morphology, wordorder, which are a challenge to current phrase-basedSMT methods.Enable more researchers to get engaged inSMT research: One of our main goals with provid-ing as many resources as possible was to keep thebarrier of entry low.
Participants could use the wordalignment and other resources and focus on phraseextraction.
We hoped to attract researchers that arerelatively new to the field.
We were satisfied to learnthat many entries are by graduate students workingon their own.Promote and create free resources: Academicresearch thrives on freely available resources.
Thefield of statistical machine translation has beenblessed with a long tradition of freely available soft-ware tools ?
such as GIZA++ (Och and Ney, 2003)?
and parallel corpora ?
such as the CanadianHansards2.
Following this lead, we made wordalignments and a language model available for thiscompetition in addition to our previously publishedresources (Europarl and Pharaoh).
The competitioncreated resources as well.
Most teams agreed toshare system output and their model files.
You candownload them from the competition web site3.Promote work on European language pairs:Finally, we wanted to promote work on Europeanlanguages.
The increasing economic and politicalties within the European Union create a huge needfor translation services.
We would like to see re-searchers rise to the challenge of creating high qual-ity machine translation systems to fill these needs.We are very grateful for the strong participation,especially by researchers who are relatively new tothe field.2http://www.isi.edu/natural-language/download/hansard/3http://www.statmt.org/wpt05/mt-shared-task/2 Rules of EngagementWe set up a machine translation competition forfour language pairs.
We chose Spanish?English andFrench?English, because many researchers wouldbe familiar with these languages.
We choseGerman?English for its special problems with wordorder (such as nested constructions and split verbgroups) and morphology.
Finally, we pickedFinnish?English for the rich agglutinative morphol-ogy of Finnish.Statistical machine translation systems are typi-cally trained on sentence-aligned parallel corpora.We selected Europarl4, a freely available parallelcorpus in eleven languages.
In addition, we alsomade a word alignment available, which was de-rived using a variant of the current default methodfor word alignment ?
Och and Ney (2003)?s refinedmethod.Figure 1 details some properties of the parallelcorpora.
The training corpus is most of the Europarlcorpus, only the text of sessions from last quarter ofthe year 2000 was reserved for testing.
The corpushas the size of roughly 15 million English words in700,000 sentences ?
these numbers differ for each ofthe four parallel corpora due to the different numberof discarded sentences during sentence alignmentand after enforcing a 40 word length limit for sen-tences.The number of foreign words differs even moredramatically.
The effect of Finnish morphologymanifests itself in a low number of words (just over11 million), but a high number of distinct words(more than 5 times as many as in the English half).The test corpus consists of 2000 sentences alignedacross all five languages.
Note that the output ofeach system is compared against the same Englishreferences for all source languages.
The number oftotal words, distinct words, and words not seen in thetraining data reflects again the morphology effect.For researchers willing to create their own wordalignment, we suggested the use of GIZA++5, animplementation of the IBM word-based machinetranslation models, which also assisted the creationof the provided word alignments.We trained a language model on the English part4http://www.statmt.org/europarl/5http://www.fjoch.com/GIZA++.html120Spanish?English French?English Finnish?English German?EnglishTraining corpusSentences 730,740 688,031 716,960 751,088Source words 15,676,710 15,323,737 11,318,287 15,256,793English words 15,222,105 13,808,104 15,492,903 16,052,269Distinct source words 102,886 80,349 358,345 195,291Distinct English words 64,123 61,627 64,662 65,889Test corpusSentences 2,000Source words 60,276 65,029 41,431 54,247English words 57,945Distinct source words 7,782 7,285 11,996 8,666Distinct English words 6,054Unseen source words 209 143 737 377Figure 1: Properties of the Europarl training and test corpora used in the shared taskof the Europarl corpus using the SRI language mod-eling toolkit (Stolke, 2002).
Finally, we suggestedthe use of Pharaoh (Koehn, 2004b), a phrase-basedmachine translation decoder.How well does this setup match the state of theart?
The MIT system using the Pharaoh decoder(Koehn, 2004a) proved to be very competitive inlast year?s NIST evaluation.
However, the field ismoving fast, and a number of steps help to improveupon the provided baseline setup, e.g., larger lan-guage models trained on general text (up to a bil-lion words have been used), better reodering mod-els (e.g., suggested by Tillman (2004) and Ochet al (2004)), better language-specific preprocessing(Koehn and Knight, 2003) and restructuring (Collinset al, 2005), additional feature functions such asword class language models, and minimum errorrate training (Och, 2003) to optimize parameters.Some of these steps (e.g., improved reorder-ing models) go beyond the current capabilities ofPharaoh.
However, we are hopeful that freely avail-able software continues to match or at least followclosely the state of the art.We announced the shared task on March 3, andprovided all the resources mentioned above (also adevelopment test corpus to track the quality of sys-tems being developed).
The test schedule called forthe translation of 2000 sentence for each of the fourlanguage pairs in the week between April 3?10.
Weallowed late submissions up to April 17.3 ResultsEleven teams from eight institutions in Europe andNorth America participated, see Figure 2 for a com-plete list.
The figure also indicates, if a team usedthe Pharaoh decoder (eight teams), the provided lan-guage model (seven teams) and the provided wordalignment (four did, three of those with additionalpreprocessing or additional data).Translation performance was measured using theBLEU score (Papineni et al, 2002), which measuresn-gram overlap with a reference translation.
In ourcase, we only used a single reference translation,since the test set was taken from a held-out portionof the Europarl corpus.
On the other hand we used arelatively large number of test sentences to guaran-tee that the BLEU results are stable despite the factthat we used only one reference translation for eachsentence.Shared tasks like this one, of course, bring out thecompetitive spirit of participants and can draw criti-cisms about being a horse race.
From an outside per-spective, however, it is far more interesting to learnwhich methods and ideas proved to be successful,than who won the competition.Taking stock of the results ?
see Figure 3 ?
oneobserves a very packed field at the top.
While theparticipants from the University of Washington pro-duced the best translations for every single languagepair, the distance to many other participant scores121ID Team Pharaoh LM Word Al.cmu-b Carnegie Mellon University, USA - Bing Zhao yes yes nocmu-j Carnegie Mellon University, USA - Ying (Joy) Zhang yes yes noglasgow University of Glasgow, UK yes yes yes+nrc National Research Council, Canada no no norali University of Montreal / RALI, Canada yes yes nosaar Saarland University, Germany yes yes yesuji University Jaume I, Spain yes yes yes+upc-j Polytechnic University of Catalonia, Spain - Jesus Gimenez yes yes noupc-m Polytechnic University of Catalonia, Spain - Marta Ruiz no no noupc-r Polytechnic University of Catalonia, Spain - Rafael Banchs no no nouw University of Washington, USA yes no yes+Figure 2: The eleven participating teams: the table also lists, if the Pharaoh decoder, the provided languagemodel, and the provided word alignment was used (yes+ indicates additional preprocessing)is within a BLEU percentage point or two.
As onemight have expected, the scores are best for Spanishand French, and worst for Finnish.
Figure 4 showssome typical output of the submitted systems.The proceedings to the workshop include detailedsystem descriptions of all participants.
Novel phraseextraction approaches were proposed, along withbetter preprocessing, language modeling, rescoring,and other ideas.
We are certain that better perfor-mance can be achieved by combining some of themethods used by different participants.And hence, we would like to pose the challenge tothe research community to build and test better sys-tems using the provided resources.
We will gladlylist additional results on the competition web site.4 SurveyFollowing the end of the competition, we sent out aquestionnaire to the participants.
One of the ques-tions what they would like to see different in a po-tential future competition.We listed four potential changes: 70% of the re-spondends checked translation from English, 50%checked out of domain test data, 40% checked morelanguage pairs, 0% checked fewer language pairs.Additional suggestions were: alternatives to theBLEU scoring method (maybe human judgment byparticipants themselves), transitive translation usingpivot languages, translation of resource-poor lan-guages, and more time to prepare for the task.5 OutlookGiven the short timeframe, one should view the sys-tem performances (albeit very competitive with thestate of the art) as a baseline effort on the task ofopen domain text translation between European lan-guages.We hope that future researchers will use the pro-vided environment as a test bed for their machinetranslation systems.
We will continue to publish anyscores reported to us.Since we placed much of the systems?
output on-line, the interested reader may be inspired to moreclosely explore the quality and shortcomings.
Evensome of the model files have been made available,so it is even possible to download and install someof the systems.ReferencesCollins, M., Koehn, P., and Kucerova, I.
(2005).Clause restructuring for statistical machine trans-lation.
In Proceedings of the 43rd Meetingof the Association for Computational Linguistics(ACL?05), Main Volume, pages 531?540, Ann Ar-bor, Michigan.Koehn, P. (2004a).
The foundation for statistical ma-chine translation at MIT.
In Proceedings of Ma-chine Translation Evaluation Workshop 2004.Koehn, P. (2004b).
Pharaoh: a beam search decoderfor statistical machine translation.
In 6th Confer-ence of the Association for Machine Translation122Spanish-EnglishSystem BLEU 1/2/3/4-gram precision (bp)uw 30.95 64.1/36.6/24.0/16.3 (1.000)upc-r 30.07 63.1/35.8/23.2/15.6 (1.000)upc-m 29.84 63.9/35.5/23.0/15.5 (0.995)nrc 29.08 62.7/34.9/22.2/14.7 (1.000)rali 28.49 62.4/34.5/21.9/14.4 (0.992)upc-j 28.13 61.5/33.8/21.4/14.1 (1.000)saar 26.69 61.0/33.1/20.7/13.5 (0.973)cmu-j 26.14 61.2/32.4/19.8/12.6 (0.986)uji 21.65 59.7/27.8/15.2/8.7 (1.000)French-EnglishSystem BLEU 1/2/3/4-gram precision (bp)uw 30.27 64.8/36.8/23.8/16.0 (0.981)upc-r 30.20 63.9/36.2/23.3/15.6 (0.998)nrc 29.53 63.7/35.8/22.7/14.9 (0.997)rali 28.89 62.6/34.7/22.0/14.6 (1.000)cmu-b 27.65 63.1/34.0/20.9/13.3 (0.995)cmu-j 26.71 61.9/33.0/20.3/13.1 (0.984)saar 26.29 60.8/32.5/20.1/12.9 (0.982)glasgow 23.01 57.3/28.0/16.7/10.5 (1.000)uji 21.25 59.8/27.7/14.8/8.3 (1.000)Finnish-EnglishSystem BLEU 1/2/3/4-gram precision (bp)uw 22.01 59.0/28.6/16.1/9.4 (0.979)nrc 20.95 57.8/27.2/14.8/8.4 (0.996)upc-r 20.31 56.6/26.0/14.3/8.3 (0.993)rali 18.87 55.2/24.7/13.1/7.1 (0.998)saar 16.76 58.4/26.3/14.2/8.0 (0.819)uji 13.79 60.0/23.2/10.8/5.3 (0.821)cmu-j 12.66 53.9/21.7/10.7/5.7 (0.775)German-EnglishSystem BLEU 1/2/3/4-gram precision (bp)uw 24.77 62.2/31.8/18.8/11.7 (0.965)upc-r 24.26 59.7/30.1/17.6/11.0 (1.000)nrc 23.21 60.3/29.8/17.1/10.3 (0.979)rali 22.91 58.9/29.0/16.8/10.3 (0.982)saar 20.48 58.0/27.5/15.5/9.2 (0.938)cmu-j 18.93 59.2/26.8/14.3/8.1 (0.914)uji 18.89 59.3/25.5/13.0/7.2 (0.976)Figure 3: The scores for the participating systems(BLEU and its components n-gram-precision andbrevity penalty)in the Americas, AMTA, Lecture Notes in Com-puter Science.
Springer.Koehn, P. (2005).
Europarl: A parallel corpus forstatistical machine translation.
In MT Summit X(submitted).Koehn, P. and Knight, K. (2003).
Empirical methodsfor compound splitting.
In Proceedings of Meet-ing of the European Chapter of the Association ofComputational Linguistics (EACL).Koehn, P., Och, F. J., and Marcu, D. (2003).
Statisti-cal phrase based translation.
In Proceedings of theJoint Conference on Human Language Technolo-gies and the Annual Meeting of the North Ameri-can Chapter of the Association of ComputationalLinguistics (HLT-NAACL).Och, F. J.
(2003).
Minimum error rate training forstatistical machine translation.
In Proceedingsof the 41st Annual Meeting of the Association ofComputational Linguistics (ACL).Och, F. J., Gildea, D., Khudanpur, S., Sarkar, A.,Yamada, K., Fraser, A., Kumar, S., Shen, L.,Smith, D., Eng, K., Jain, V., Jin, Z., and Radev,D.
(2004).
A smorgasbord of features for statis-tical machine translation.
In Proceedings of theJoint Conference on Human Language Technolo-gies and the Annual Meeting of the North Ameri-can Chapter of the Association of ComputationalLinguistics (HLT-NAACL).Och, F. J. and Ney, H. (2003).
A systematic compar-ison of various statistical alignment models.
Com-putational Linguistics, 29(1):19?52.Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J.(2002).
BLEU: a method for automatic evalua-tion of machine translation.
In Proceedings of the40th Annual Meeting of the Association of Com-putational Linguistics (ACL).Stolke, A.
(2002).
SRILM - an extensible languagemodeling toolkit.
In Proceedings of the Interna-tional Conference on Spoken Language Process-ing.Tillman, C. (2004).
A unigram orientation modelfor statistical machine translation.
In Proceed-ings of the Joint Conference on Human LanguageTechnologies and the Annual Meeting of the NorthAmerican Chapter of the Association of Computa-tional Linguistics (HLT-NAACL).123ReferenceWe know all too well that the present Treaties are inadequate and that the Union will need a betterand different structure in future , a more constitutional structure which clearly distinguishes thepowers of the Member States and those of the Union .Input SpanishSabemos muy bien que los Tratados actuales no bastan y que , en el futuro , sera?
necesario desarrol-lar una estructura mejor y diferente para la Unio?n Europea , una estructura ma?s constitucional quetambie?n deje bien claras cua?les son las competencias de los Estados miembros y cua?les pertenecena la Unio?n .Best system (Spanish?English)we all know very well that the current treaties are not enough and that , in the future , it willbe necessary to develop a structure better and different for the european union , a structure moreconstitutional also make it clear what the competences of the member states and what belongs tothe union .Worst System (Spanish?English)we know very well that the current treaties not enough and that , in the future , will be necessarydevelop a better structure and different to the european union , a structure more constitutional thatalso be well clear the powers of the member states and what belong to the union .Input FrenchNous savons tre`s bien que les Traite?s actuels ne suffisent pas et qu ?
il sera ne?cessaire a` l ?
avenirde de?velopper une structure plus efficace et diffe?rente pour l ?
Union , une structure plus consti-tutionnelle qui indique clairement quelles sont les compe?tences des e?tats membres et quelles sontles compe?tences de l ?
Union .Best system (French?English)we know very well that the current treaties are not enough and that it will be needed in the futureto develop a structure more effective and different for the union , a structure more constitutionalwhich clearly indicates what are the competence of member states and what are the powers of theunion .Input FinnishTieda?mme oikein hyvin , etta?
nykyiset perustamissopimukset eiva?t ole riitta?via?
ja etta?
tulevaisu-udessa on tarpeen kehitta?a?
unionille parempi ja toisenlainen rakenne , siis perustuslaillisempirakenne , jossa mys ilmaistaan selkea?mmin , mita?
ja?senvaltioiden ja unionin toimivaltaan kuuluuBest system (Finnish?English)we know very well that the existing founding treaties do not need to be developed for the unionand a different structure , therefore perustuslaillisempi structure , which also expresses clearlywhat the member states and the union ?s competence is not sufficient and that better in the future .Input GermanUns ist sehr wohl bewusst , dass die geltenden Vertra?ge unzula?nglich sind und ku?nftig eine andere, effizientere Struktur fu?r die Union entwickelt werden muss , na?mlich eine sta?rker konstitutionellausgepra?gte Struktur mit einer klaren Abgrenzung zwischen den Befugnissen der Mitgliedstaatenund den Kompetenzen der Union .Best system (German?English)the union must be developed , with a major institutional structure with a clear demarcationbetween the powers of the member states and the competences of the union is well aware that theexisting treaties are inadequate and in the future , a different , more efficient structure for us .Figure 4: The first sentence of the test corpus and system translations124
