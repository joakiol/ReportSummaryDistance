Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 277?282,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsEnd-to-End Relation Extraction Using Distant Supervisionfrom External Semantic RepositoriesTruc-Vien T. Nguyen and Alessandro MoschittiDepartment of Information Engineering and Computer ScienceUniversity of Trento38123 Povo (TN), Italy{nguyenthi,moschitti}@disi.unitn.itAbstractIn this paper, we extend distant supervision(DS) based on Wikipedia for Relation Extrac-tion (RE) by considering (i) relations definedin external repositories, e.g.
YAGO, and (ii)any subset of Wikipedia documents.
We showthat training data constituted by sentencescontaining pairs of named entities in target re-lations is enough to produce reliable supervi-sion.
Our experiments with state-of-the-art re-lation extraction models, trained on the abovedata, show a meaningful F1 of 74.29% on amanually annotated test set: this highly im-proves the state-of-art in RE using DS.
Addi-tionally, our end-to-end experiments demon-strated that our extractors can be applied toany general text document.1 IntroductionRelation Extraction (RE) from text as defined inACE (Doddington et al, 2004) concerns the extrac-tion of relationships between two entities.
This istypically carried out by applying supervised learn-ing, e.g.
(Zelenko et al, 2002; Culotta and Sorensen,2004; Bunescu and Mooney, 2005) by using a hand-labeled corpus.
Although, the resulting models arefar more accurate than unsupervised approaches,they suffer from the following drawbacks: (i) theyrequire labeled data, which is usually costly to pro-duce; (ii) they are typically domain-dependent asdifferent domains involve different relations; and(iii), even in case the relations do not change, theyresult biased toward the text feature distributions ofthe training domain.The drawbacks above would be alleviated if datafrom several different domains and relationshipswere available.
A form of weakly supervision,specifically named distant supervision (DS) whenapplied to Wikipedia, e.g.
(Banko et al, 2007; Mintzet al, 2009; Hoffmann et al, 2010) has been recentlydeveloped to meet the requirement above.
The mainidea is to exploit (i) relation repositories, e.g.
theInfobox, x, of Wikipedia to define a set of relationtypes RT (x) and (ii) the text in the page associatedwith x to produce the training sentences, which aresupposed to express instances of RT (x).Previous work has shown that selecting the sen-tences containing the entities targeted by a given re-lation is enough accurate (Banko et al, 2007; Mintzet al, 2009) to provide reliable training data.
How-ever, only (Hoffmann et al, 2010) used DS to de-fine extractors that are supposed to detect all the re-lation instances from a given input text.
This is aharder test for the applicability of DS but, at thesame time, the resulting extractor is very valuable:it can find rare relation instances that might be ex-pressed in only one document.
For example, the re-lation President(Barrack Obama, United States) canbe extracted from thousands of documents thus thereis a large chance of acquiring it.
In contrast, Pres-ident(Eneko Agirre, SIGLEX) is probably expressedin very few documents, increasing the complexityfor obtaining it.In this paper, we extend DS by (i) consideringrelations from semantic repositories different fromWikipedia, i.e.
YAGO, and (2) using training in-stances derived from any Wikipedia document.
Thisallows for (i) potentially obtaining training data277for many more relation types, defined in differentsources; (ii) meaningfully enlarging the size of theDS data since the relation examples can be extractedfrom any Wikipedia document 1.Additionally, by following previous work, wedefine state-of-the-art RE models based on kernelmethods (KM) applied to syntactic/semantic struc-tures.
We use tree and sequence kernels that canexploit structural information and interdependenciesamong labels.
Experiments show that our modelsare flexible and robust to Web documents as weachieve the interesting F1 of 74.29% on 52 YAGOrelations.
This is even more appreciable if we ap-proximately compare with the previous result on REusing DS, i.e.
61% (Hoffmann et al, 2010).
Al-though the experiment setting is different from ours,the improvement of about 13 absolute percent pointsdemonstrates the quality of our model.Finally, we also provide a system for extractingrelations from any text.
This required the definitionof a robust Named Entity Recognizer (NER), whichis also trained on weakly supervised Wikipedia data.Consequently, our end-to-end RE system is appli-cable to any document.
This is another major im-provement on previous work.
The satisfactory REF1 of 67% for 52 Wikipedia relations suggests thatour model is also successfully applicable in real sce-narios.1.1 Related WorkRE generally relates to the extraction of relationalfacts, or world knowledge from the Web (Yates,2009).
To identify semantic relations using ma-chine learning, three learning settings have been ap-plied, namely supervised methods, e.g.
(Zelenkoet al, 2002; Culotta and Sorensen, 2004; Kamb-hatla, 2004), semi supervised methods, e.g.
(Brin,1998; Agichtein and Gravano, 2000), and unsuper-vised method, e.g.
(Hasegawa et al, 2004; Bankoet al, 2007).
Work on supervised Relation Extrac-tion has mostly employed kernel-based approaches,e.g.
(Zelenko et al, 2002; Culotta and Sorensen,2004; Culotta and Sorensen, 2004; Bunescu andMooney, 2005; Zhang et al, 2005; Bunescu, 2007;Nguyen et al, 2009; Zhang et al, 2006).
However,1Previous work assumes the page related to the Infobox asthe only source for the training data.Algorithm 2.1: ACQUIRE LABELED DATA()DS = ?Y AGO(R) : Instances of Relation Rfor each ?Wikipedia article : W ?
?
Freebasedo????????????
?S ?
set of sentences fromWfor each s ?
Sdo????????
?E ?
set of entities from sfor each E1 ?
E and E2 ?
E andR ?
Y AGOdo??
?if R(E1, E2) ?
YAGO(R)then DS ?
DS ?
{s,R+}else DS ?
DS ?
{s,R?
}return (DS)such approaches can be applied to few relation typesthus distant supervised learning (Mintz et al, 2009)was introduced to tackle such problem.
Another so-lution proposed in (Riedel et al, 2010) was to adaptmodels trained in one domain to other text domains.2 Resources and Dataset CreationIn this section, we describe the resources for the cre-ation of an annotated dataset based on distant super-vision.
We use YAGO, a large knowledge base ofentities and relations, and Freebase, a collection ofWikipedia articles.
Our procedure uses entities andfacts from YAGO to provide relation instances.
Foreach pair of entities that appears in some YAGO re-lation, we retrieve all the sentences of the Freebasedocuments that contain such entities.2.1 YAGOYAGO (Suchanek et al, 2007) is a huge seman-tic knowledge base derived from WordNet andWikipedia.
It comprises more than 2 million entities(like persons, organizations, cities, etc.)
and 20 mil-lion facts connecting these entities.
These includethe taxonomic Is-A hierarchy as well as semantic re-lations between entities.We use the YAGO version of 2008-w40-2 with amanually confirmed accuracy of 95% for 99 rela-tions.
However, some of them are (a) trivial, e.g.familyNameOf ; (b) numerical attributes that changeover time, e.g.
hasPopulation; (c) symmetric, e.g.hasPredecessor; (d) used only for data management,e.g.
describes or foundIn.
Therefore, we removedthose irrelevant relations and obtained 1,489,156 in-stances of 52 relation types to be used with our DSapproach.2782.2 FreebaseTo access to Wikipedia documents, we used Free-base (March 27, 2010 (Metaweb Technologies,2010)), which is a dump of the full text of allWikipedia articles.
For our experiments, we used100,000 articles.
Out of them, only 28,074 articlescontain at least one relation for a total of 68,429 ofrelation instances.
These connect 744,060 entities,97,828 dates and 203,981 numerical attributes.Temporal and Numerical ExpressionWikipedia articles are marked with entities like Per-son or Organization but not with dates or numeri-cal attributes.
This prevents to extract interestingrelations between entities and dates, e.g.
John F.Kennedy was born on May 29, 1917 or between en-tities and numerical attributes, e.g.
The novel Gonewith the wind has 1037 pages.
Thus we designed18 regular expressions to extract dates and other 25to extract numerical attributes, which range from in-teger number to ordinal number, percentage, mone-tary, speed, height, weight, area, time, and ISBN.2.3 Distant Supervision and generalizationDistant supervision (DS) for RE is based on thefollowing assumption: (i) a sentence is connectedin some way to a database of relations and (ii)such sentence contains the pair of entities partic-ipating in a target relation; (iii) then it is likelythat such sentence expresses the relation.
In tra-ditional DS the point (i) is implemented by theInfobox, which is connected to the sentences bya proximity relation (same page of the sentence).In our extended DS, we relax (i) by allowingfor the use of an external DB of relations suchas YAGO and any document of Freebase (a col-lection of Wikipedia documents).
The alignmentbetween YAGO and Freebase is implemented bythe Wikipedia page link: for example the linkhttp://en.wikipedia.org/wiki/James Cameron refersto the entity James Cameron.We use an efficient procedure formally describedin Alg.
2.1: for each Wikipedia article in Free-base, we scan all of its NEs.
Then, for each pairof entities2 seen in the sentence, we query YAGO to2Our algorithm is robust to the lack of knowledge about theexistence of any relation between two entities.
If the relationretrieve the relation instance connecting these enti-ties.
Note that a simplified version of our approachis the following: for any YAGO relation instance,scan all the sentences of all Wikipedia articles to testpoint (ii).
Unfortunately, this procedure is impossi-ble in practice due to millions of relation instancesin YAGO and millions of Wikipedia articles in Free-base, i.e.
an order of magnitude of 1014 iterations3.3 Distant Supervised Learning withKernelsWe model relation extraction (RE) using state-of-the-art classifiers based on kernel methods.
Themain idea is that syntactic/semantic structures areused to represent relation instances.
We followed themodel in (Nguyen et al, 2009) that has shown sig-nificant improvement on the state-of-the-art.
Thiscombines a syntactic tree kernel and a polynomialkernel over feature extracted from the entities:CK1 = ?
?KP + (1?
?)
?
TK (1)where ?
is a coefficient to give more or less impactto the polynomial kernel,KP , and TK is the syntac-tic tree kernel (Collins and Duffy, 2001).
The bestmodel combines the advantages of the two parsingparadigms by adding the kernel above with six se-quence kernels (described in (Nguyen et al, 2009)).CSK = ?
?KP +(1??)
?
(TK+?i=1,..,6SKi) (2)Such kernels cannot be applied to Wikipedia doc-uments as the entity category, e.g.
Person or Orga-nization, is in general missing.
Thus, we adaptedthem by simply removing the category label in thenodes of the trees and in the sequences.
This datatransformation corresponds to different kernels (see(Cristianini and Shawe-Taylor, 2000)).4 ExperimentsWe carried out test to demonstrate that our DS ap-proach produces reliable and practically usable re-lation extractors.
For this purpose, we test them oninstance is not in YAGO, it is simply assumed as a negativeinstance even if such relation is present in other DBs.3Assuming 100 sentences for each article.279DS data by also carrying out end-to-end RE evalua-tion.
This requires to experiment with a state-of-the-art Named Entity Recognizer trained on Wikipediaentities.Class Precision Recall F-measurebornOnDate 97.99 95.22 96.58created 92.00 68.56 78.57dealsWith 92.30 73.47 81.82directed 85.19 51.11 63.89hasCapital 93.69 61.54 74.29isAffiliatedTo 86.32 71.30 78.10locatedIn 87.85 78.33 82.82wrote 82.61 42.22 55.88Overall 91.42 62.57 74.29Table 1: Performance of 8 out of 52 individual relationswith overall F1.4.1 Experimental settingWe used the DS dataset generated from YAGO andWikipedia articles, as described in the algorithm(Alg.
2.1).
The candidate relations are generatedby iterating all pairs of entity mentions in the samesentence.
Relation detection is formulated as a mul-ticlass classification problem.
The One vs. Reststrategy is employed by selecting the instance withlargest margin as the final answer.
We carried out5-fold cross-validation with the tree kernel toolkit4(Moschitti, 2004; Moschitti, 2008).4.2 Results on Wikipedia REWe created a test set by sampling 200 articles fromFreebase (these articles are not used for training).An expert annotator, for each sentence, labeled allpossible pairs of entities with one of the 52 rela-tions from YAGO, where the entities were alreadymarked.
This process resulted in 2,601 relation in-stances.Table 1 shows the performance of individual clas-sifiers as well as the overall Micro-average F1 forour adapted CSK: we note that it reaches an F1-score of 74.29%.
This can be compared with theMicro-average F1 of CK1, i.e.
71.21%.
The lowerresult suggests that the combination of dependencyand constituent syntactic structures is very impor-tant: +3.08 absolute percent points on CK1, whichonly uses constituency trees.4http://disi.unitn.it/ moschitt/Tree-Kernel.htmClass Precision Recall F-measureEntity Detection 68.84 64.56 66.63End-to-End RE 82.16 56.57 67.00Table 2: Entity Detection and End-to-end Relation Ex-traction.4.3 End-to-end Relation ExtractionPrevious work in RE uses gold entities available inthe annotated corpus (i.e.
ACE) but in real appli-cations these are not available.
Therefore, we per-form experiments with automatic entities.
For theirextraction, we follow the feature design in (Nguyenet al, 2010), using CRF++ 5 with unigram/featuresand Freebase as learning source.
Dates and numer-ical attributes required a different treatment, so weuse the patterns described in Section 2.3.
The resultsreported in Table 2 are rather lower than in standardNE recognition.
This is due to the high complexityof predicting the boundaries of thousands of differ-ent categories in YAGO.Our end-to-end RE system can be applied to anytext fragment so we could experiment with it andany Wikipedia document.
This allowed us to carryout an accurate evaluation.
The results are shown inTable 2.
We note that, without gold entities, RE fromWikipedia still achieves a satisfactory performanceof 67.00% F1.5 ConclusionThis paper proposes two main contributions to Re-lation Extraction: (i) a new approach to distant su-pervision (DS) to create training data using relationsdefined in different sources, i.e.
YAGO, and poten-tially using any Wikipedia document; and (ii) end-to-end systems applicable both to Wikipedia pagesas well as to any natural language text.The results show:1.
A high F1 of 74.29% on extracting 52 YAGOrelations from any Wikipedia document (notonly from Infobox related pages).
This re-sult improves on previous work by 13.29 abso-lute percent points (approximated comparison).This is a rough approximation since on onehand, (Hoffmann et al, 2010) experimented5http://crfpp.sourceforge.net280with 5,025 relations, which indicate that our re-sults based on 52 relations cannot be comparedwith it (i.e.
our multi-classifier has two ordersof magnitude less of categories).
On the otherhand, the only experiment that can give a re-alistic measurement is the one on hand-labeledtest set (testing on data automatically labelledby DS does not provide a realistic outcome).The size of such test set is comparable withours, i.e.
100 documents vs. our set of 200documents.
Although, we do not know howmany types of relations were involved in thetest of (Hoffmann et al, 2010), it is clear thatonly a small subset of the 5000 relations couldhave been measured.
Also, we have to considerthat, in (Hoffmann et al, 2010), only one rela-tion extractor is supposed to be learnt from onearticle (by using Infobox) whereas we can po-tentially extract several relations even from thesame sentence.2.
The importance of using both dependency andconstituent structures (+3.08% when addingdependency information to RE based on con-stituent trees).3.
Our end-to-end system is useful for real appli-cations as it shows a meaningful accuracy, i.e.67% on 52 relations.For this reason, we decided to make available theDS dataset, the manually annotated test set and thecomputational data (tree and sequential structureswith labels).ReferencesEugene Agichtein and Luis Gravano.
2000.
Snowball:Extracting relations from large plain-text collections.In Proceedings of the 5th ACM International Confer-ence on Digital Libraries, pages 85?94.Michele Banko, Michael J. Cafarella, Stephen Soderland,Matthew Broadhead, and Oren Etzioni.
2007.
Openinformation extraction from the web.
In Proceedingsof IJCAI, pages 2670?2676.Sergey Brin.
1998.
Extracting patterns and relationsfrom world wide web.
In Proceedings of WebDBWorkshop at 6th International Conference on Extend-ing Database Technology, pages 172?183.Razvan Bunescu and Raymond Mooney.
2005.
A short-est path dependency kernel for relation extraction.
InProceedings of HLT-EMNLP, pages 724?731, Vancou-ver, British Columbia, Canada, October.Razvan C. Bunescu.
2007.
Learning to extract relationsfrom the web using minimal supervision.
In Proceed-ings of ACL.Michael Collins and Nigel Duffy.
2001.
Convolutionkernels for natural language.
In Proceedings of NeuralInformation Processing Systems (NIPS?2001), pages625?632.Nello Cristianini and John Shawe-Taylor.
2000.
AnIntroduction to Support Vector Machines and OtherKernel-based Learning Methods.
Cambridge Univer-sity Press, Cambridge, United Kingdom.Aron Culotta and Jeffrey Sorensen.
2004.
Dependencytree kernels for relation extraction.
In Proceedings ofACL, pages 423?429, Barcelona, Spain, July.George Doddington, Alexis Mitchell, Mark Przybocki,Lance Ramshaw, Stephanie Strassel, and RalphWeischedel.
2004.
The automatic content extraction(ace) programtasks, data, and evaluation.
In Proceed-ings of LREC, pages 837?840, Barcelona, Spain.Takaaki Hasegawa, Satoshi Sekine, and Ralph Grishman.2004.
Discovering relations among named entitiesfrom large corpora.
In Proceedings of ACL, pages415?422, Barcelona, Spain, July.Raphael Hoffmann, Congle Zhang, and Daniel S. Weld.2010.
Learning 5000 relational extractors.
In Pro-ceedings of ACL, pages 286?295, Uppsala, Sweden,July.Nanda Kambhatla.
2004.
Combining lexical, syntactic,and semantic features with maximum entropy modelsfor information extraction.
In The Companion Volumeto the Proceedings of ACL, pages 178?181, Barcelona,Spain, July.Metaweb Technologies.
2010.
Freebase wikipedia ex-traction (wex), March.Mike Mintz, Steven Bills, Rion Snow, and Daniel Juraf-sky.
2009.
Distant supervision for relation extractionwithout labeled data.
In Proceedings of ACL-AFNLP,pages 1003?1011, Suntec, Singapore, August.Alessandro Moschitti.
2004.
A study on convolution ker-nels for shallow statistic parsing.
In Proceedings ofACL, pages 335?342, Barcelona, Spain, July.Alessandro Moschitti.
2008.
Kernel methods, syntax andsemantics for relational text categorization.
In Pro-ceedings of CIKM, pages 253?262, New York, NY,USA.
ACM.Truc-Vien T. Nguyen, Alessandro Moschitti, andGiuseppe Riccardi.
2009.
Convolution kernels onconstituent, dependency and sequential structures forrelation extraction.
In Proceedings of EMNLP, pages1378?1387, Singapore, August.281Truc-Vien T. Nguyen, Alessandro Moschitti, andGiuseppe Riccardi.
2010.
Kernel-based re-ranking fornamed-entity extraction.
In Proceedings of COLING,pages 901?909, China, August.Sebastian Riedel, Limin Yao, and Andrew McCallum.2010.
Modeling relations and their mentions with-out labeled text.
In Machine Learning and Knowl-edge Discovery in Databases, volume 6323 of LectureNotes in Computer Science, pages 148?163.
SpringerBerlin / Heidelberg.Fabian M. Suchanek, Gjergji Kasneci, and GerhardWeikum.
2007.
Yago - a core of semantic knowl-edge.
In 16th international World Wide Web confer-ence, pages 697?706.Alexander Yates.
2009.
Extracting world knowledgefrom the web.
IEEE Computer, 42(6):94?97, June.Dmitry Zelenko, Chinatsu Aone, and AnthonyRichardella.
2002.
Kernel methods for relationextraction.
In Proceedings of EMNLP-ACL, pages181?201.Min Zhang, Jian Su, Danmei Wang, Guodong Zhou, andChew Lim Tan.
2005.
Discovering relations betweennamed entities from a large raw corpus using treesimilarity-based clustering.
In Proceedings of IJC-NLP?2005, Lecture Notes in Computer Science (LNCS3651), pages 378?389, Jeju Island, South Korea.Min Zhang, Jie Zhang, Jian Su, , and Guodong Zhou.2006.
A composite kernel to extract relations betweenentities with both flat and structured features.
In Pro-ceedings of COLING-ACL 2006, pages 825?832.282
