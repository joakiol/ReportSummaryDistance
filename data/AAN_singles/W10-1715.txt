Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 115?120,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsMore Linguistic Annotation for Statistical Machine TranslationPhilipp Koehn, Barry Haddow, Philip Williams, and Hieu HoangUniversity of EdinburghEdinburgh, United Kingdom{pkoehn,bhaddow,p.j.williams-2,h.hoang}@inf.ed.ac.ukAbstractWe report on efforts to build large-scaletranslation systems for eight Europeanlanguage pairs.
We achieve most gainsfrom the use of larger training corpora andbasic modeling, but also show promisingresults from integrating more linguistic an-notation.1 IntroductionWe participated in the shared translation task ofthe ACL Workshop for Statistical Machine Trans-lation 2010 in all language pairs.
We continuedour efforts to integrate linguistic annotation intothe translation process, using factored and tree-based translation models.
On average we out-performed our submission from last year by 2.16BLEU points on the same newstest2009 test set.While the submitted system follows the factoredphrase-based approach, we also built hierarchicaland syntax-based models for the English?Germanlanguage pair and report on its performance on thedevelopment test sets.
All our systems are basedon the Moses toolkit (Koehn et al, 2007).We achieved gains over the systems from lastyear by consistently exploiting all available train-ing data, using large-scale domain-interpolated,and consistent use of the factored translationmodel to integrate n-gram models over speechtags.
We also experimented with novel domainadaptation methods, with mixed results.2 Baseline SystemThe baseline system uses all available trainingdata, except for the large UN and 109 corpora, aswell as the optional LDC Gigaword corpus.
It usesa straight-forward setup of the Moses decoder.Some relevant parameter settings are:?
maximum sentence length 80 words?
tokenization with hyphen splitting?
truecasing?
grow-diag-final-and alignment heuristic?
msd-bidirectional-fe lexicalized reordering?
interpolated 5-gram language model?
tuning on newsdev2009?
testing during development on newstest2009?
MBR decoding?
no reordering over punctuation?
cube pruningWe used most of these setting in our submissionlast year (Koehn and Haddow, 2009).The main difference to our baseline systemfrom the submission from last year is the use of ad-ditional training data: larger releases of the NewsCommentary, Europarl, Czeng, and monolingualnews corpora.
The first two parallel corpora in-creased roughly 10-20% in size, while the Czengparallel corpus and the monolingual news corporaare five times and twice as big, respectively.We also handled some of the corpus preparationsteps with more care to avoid some data incon-sistency problems from last year (affecting mostlythe French language pairs).An overview of the results is given in Table 1.The baseline outperforms our submission fromlast year by an average of +1.25 points.
The gainsfor the individual language pairs track the increasein training data (most significantly for the Czech?English pairs), and the French?English data pro-cessing issue.Note that last year?s submission used specialhandling of the German?English language pair,which we did not replicate in the baseline system,but report on below.The table also contains results on the extensionsdiscussed in the next section.115Language Pair ?09 Baseline GT Smooth.
UN Data Factored BeamSpanish-English 24.41 25.25 (+0.76) 25.48 (+0.23) 26.03 (+0.55) 26.20 (+0.17) 26.22 (+0.02)French-English 23.88 25.23 (+1.35) 25.37 (+0.14) 25.92 (+0.55) 26.13 (+0.21) 26.07 (?0.08)German-English 18.51 19.47 (+0.96) 19.51 (+0.04) - 21.09 (+0.24) 21.10 (+0.01)Czech-English 18.49 20.74 (+2.25) 21.19 (+0.45) - 21.33 (+0.14) 21.32 (?0.01)English-Spanish 23.27 24.20 (+0.93) 24.65 (+0.45) 24.65 (+0.30) 24.37 (?0.28) 24.42 (+0.05)English-French 22.50 23.83 (+1.33) 23.72 (?0.11) 24.70 (+0.98) 24.74 (+0.04) 24.92 (+0.18)English-German 14.22 14.68 (+0.46) 14.81 (+0.13) - 15.28 (+0.47) 15.34 (+0.06)English-Czech 12.64 14.63 (+1.99) 14.68 (+0.05) - - -avg +1.25 +0.17 +0.60 +0.14 +0.03Table 1: Overview of results: baseline system and extensions.
On average we outperformed our sub-mission from last year by 1.87 BLEU points on the same newstest2009 test set.
For additional gains forFrench?English and German?English, please see Tables 7 and 8.Czech?EnglishCorpus Num.
Tokens Pplx.
WeightEU 29,238,799 582 0.054Fiction 15,441,105 429 0.028Navajo 561,144 671 0.002News (czeng) 2,909,322 288 0.127News (mono) 1,148,480,525 175 0.599Subtitles 23,914,244 526 0.019Techdoc 8,322,958 851 0.099Web 4,469,177 441 0.073French?EnglishCorpus Num.
Tokens Pplx.
WeightEuroparl 50,132,615 352 0.105News Com.
2,101,921 311 0.204UN 216,052,412 383 0.089News 1,148,480,525 175 0.601Table 2: English LM interpolation: number of to-kens, perplexity, and interpolation weight for thedifferent corpora2.1 Interpolated Language ModelThe WMT training data exhibits an increasing di-versity of corpora: Europarl, News Commentary,UN, 109, News ?
and seven different sourceswithin the Czeng corpus.It is well known that domain adaptation is animportant step in optimizing machine translationsystems.
A relatively simple and straight-forwardmethod is the linear interpolation of the languagemodel, as we explored previously (Koehn andSchroeder, 2007; Schwenk and Koehn, 2008).We trained domain-specific language modelsseparately and then linearly interpolated them us-ing SRILM toolkit (Stolke, 2002) with weights op-Language Pair Cased UncasedSpanish-English 25.25 26.36 (+1.11)French-English 25.23 26.29 (+1.06)German-English 19.47 20.63 (+1.16)Czech-English 20.74 21.76 (+1.02)English-Spanish 24.20 25.47 (+1.27)English-French 23.83 25.02 (+1.19)English-German 14.68 15.18 (+0.50)English-Czech 14.63 15.13 (+0.50)avg +0.98Table 3: Effect of truecasing: cased and uncasedBLEU scorestimized on the development set newsdev2009.See Table 2 for numbers on perplexity, corpussizes, and interpolation weights.
Note, for in-stance, the relatively high weight for the NewsCommentary corpus (0.204) compared to the Eu-roparl corpus (0.105) in the English languagemodel for the French-English system, despite thelatter being about 25 times bigger.2.2 TruecasingAs last year, we deal with uppercase and lowercaseforms of the same words by truecasing the corpus.This means that we change each surface word oc-currence of a word to its natural case, e.g., the, Eu-rope.
During truecasing, we change the first wordof a sentence to its most frequent casing.
Duringde-truecasing, we uppercase the first letter of thefirst word of a sentence.See Table 3 for the performance of this method.In this table, we compare the cased and uncasedBLEU scores, and observe that we lose on averageroughly one BLEU point due to wrong casing.116Count Count of Count Discount Count*1 357,929,182 0.140 0.1402 24,966,751 0.487 0.9753 8,112,930 0.671 2.0144 4,084,365 0.714 2.8585 2,334,274 0.817 4.088Table 4: Good Turing smoothing, as in theFrench?English model: counts, counts of counts,discounting factor and discounted count3 ExtensionsIn this section, we describe extensions over thebaseline system.
On average, these give us im-provements of about 1 BLEU point over the base-line.3.1 Good Turing SmoothingTraditionally, we use raw counts to estimate con-ditional probabilities for phrase translation.
How-ever, this method gives dubious results for rarecounts.
The most blatant case is the single oc-currence of a foreign phrase, whose sole Englishtranslation will receive the translation probability11 = 1.Foster et al (2006) applied ideas from languagemodel smoothing to the translation model.
GoodTuring smoothing (Good, 1953) uses counts ofcounts statistics to assess how likely we will seea word (or, in our case, a phrase) again, if we haveseen it n times in the training corpus.
Instead ofusing the raw counts, adapted (lower) counts areused in the estimation of the conditional probabil-ity distribution.The count of counts are collected for the phrasepairs.
See Table 4 for details on how this ef-fects the French?English model.
For instance,we find singleton 357,929,182 phrase pairs and24,966,751 phrase pairs that occur twice.
TheGood Turing formula tells us to adapt singletoncounts to 24,966,751357,929,182 = 0.14.
This means for ourdegenerate example of a single occurrence of asingle French phrase that its single English transla-tion has probability 0.141 = 0.14 (we do not adjustthe denominator).Good Turing smoothing of the translation tablegives us a gain of +0.17 BLEU points on average,and improvements for 7 out of 8 language pairs.For details refer back to Table 1.Model BLEUBaseline 14.81Part-of-Speech 15.03 (+0.22)Morphogical 15.28 (+0.47)Table 5: English?German: use of morphologicaland part-of-speech n-gram models3.2 UN DataWhile we already used the UN data in the lan-guage model for the Spanish?English and French?English language pairs, we now also add it to thetranslation model.The corpus is very large, four times bigger thanthe already used training data, but relatively outof domain, as indicated by the high perplexity andlow interpolation weight during language modelinterpolation (recall Table 2).Adding the corpus to the four systems gives im-provements of +0.60 BLEU points on average.For details refer back to Table 1.3.3 POS n-gram ModelThe factored model approach (Koehn and Hoang,2007) allows us to integrate 7-gram models overpart-of-speech tags.
The part-of-speech tags areproduced during decoding by the phrase mappingof surface words on the source side to a factoredrepresentation of surface words and their part-of-speech tags on the target side in one translationstep.We previously used this additional scoring com-ponent for the German?English language pairswith success.
Thus we now applied to it all otherlanguage pairs (except for English?Czech due tothe lack of a Czech part-of-speech tagger).We used the following part-of-speech taggers:?
English: mxpost1?
German: LoPar2?
French: TreeTagger3?
Spanish: TreeTaggerFor English?German, we also used morpholog-ical tags, which give better performance than justbasic part-of-speech tags (+0.46 vs. +0.22, see Ta-ble 5).
We observe gains for all language pairsexcept for English?Spanish, possibly due to the1www.inf.ed.ac.uk/resources/nlp/local doc/MXPOST.html2www.ims.uni-stuttgart.de/projekte/gramotron/SOFTWARE/LoPar.html3www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/117Model BLEUBaseline 14.81Part-of-Speech 15.03 (+0.22)Morphogical 15.28 (+0.47)Table 6: English?German: use of morphologicaland part-of-speech n-gram modelsLanguage Pair Baseline with 109French?English 25.92 27.15 (+1.23)English?French 24.70 24.80 (+0.10)Table 7: Use of large French?English corpusfaulty use of the Spanish part-of-speech tagger.We gain +0.14 BLEU points on average (includ-ing the ?0.28 drop for Spanish).
For details referback to Table 1.3.4 Bigger Beam SizesAs a final general improvement, we adjusted thebeam settings during decoding.
We increased thepop-limit from 5,000 to 20,000 and the translationtable limit from the default 20 to 50.The decoder is quite fast, partly due to multi-threaded decoding using 4 cores machines (Had-dow, 2010).
Increasing the beam sizes sloweddown decoding speed from about 2 seconds persentence to about 8 sec/sentence.However, this resulted only in minimal gains,on average +0.03 BLEU.
For details refer back toTable 1.3.5 109 CorpusLast year, due to time constraints, we were notable to use the billion word 109 corpus for theFrench?English language pairs.
This is largestpublicly available parallel corpus, and it doesstrain computing resources, for instance forcingus to use multi-threaded GIZA++ (Gao and Vogel,2008).Table 7 shows the gains obtained from us-ing this corpus in both the translation model andthe language model opposed to a baseline sys-tem trained with otherwise the same settings.
ForFrench?English we see large gains (+1.23), but notfor English?French (+0.10).Our official submission for the French?Englishlanguage pairs used these models.
They did not in-clude a part-of-speech language model and biggerbeam sizes.Model BLEUBaseline 19.51+ compound splitting 20.09 (+0.58)+ pre-reordering 20.03 (+0.52)+ both 20.85 (+1.34)Table 8: Special handling of German?EnglishLanguage Pair Baseline Weighted TMSpanish-English 26.20 26.15 (?0.05)French-English 26.11 26.30 (+0.19)German-English 21.09 20.81 (?0.28)Czech-English 21.33 21.21 (?0.12)English-German 15.28 15.01 (?0.27)avg.
?0.11Table 9: Interpolating the translation model withlanguage model weights3.6 German?EnglishFor the German?English language direction, weused two additional processing steps that haveshown to be successful in the past, and again re-sulted in significant gains.We split large words based on word frequen-cies to tackle the problem of word compounds inGerman (Koehn and Knight, 2003).
Secondly, were-order the German input to the decoder (and theGerman side of the training data) to align moreclosely to the English target language (Collinset al, 2005).The two methods improve +0.58 and +0.52 overthe baseline individually, and +1.34 when com-bined.
See also Table 8.3.7 Translation Model InterpolationFinally, we explored a novel domain adaptionmethod for the translation model.
Since the in-terpolation of language models is very success-ful, we want to interpolate translation models sim-ilarly.
Given interpolation weights, the resultingtranslation table is a weighted linear interpolationof the individual translation models trained sepa-rately for each domain.However, while for language models we have aeffective method to find the interpolation weights(optimizing perplexity on a development set), wedo not have such a method for the translationmodel.
Thus, we simply recycle the weights weobtained from language model interpolation (ex-cluding the weighting for monolingual corpora).118Model BLEUphrase-based 14.81factored phrase-based 15.28hierarchical 14.86target syntax 14.66Table 10: Tree-based models for English?GermanOver the Spanish?English baseline system, weobtained gains of +0.39 BLEU points.
Unfortu-nately, we did not see comparable gains on the sys-tems optimized by the preceding steps.
In fact, in4 out of 5 language pairs, we observed lower BLEUscores.
See Table 9 for details.We did not use this method in our submission.4 Tree-Based ModelsA major extension of the capabilities of the Mosessystem is the accommodation of tree-based mod-els (Hoang et al, 2009).
While we have not yetcarried out sufficient experimentation and opti-mization of the implementation, we took the occa-sion of the shared translation task as a opportunityto build large-scale systems using such models.We build two translation systems: One usingtree-based models without additional linguistic an-notation, which are known as hierarchical phrase-based models (Chiang, 2005), and another sys-tem that uses linguistic annotation on the targetside, which are known under many names such asstring-to-tree models or syntactified target models(Marcu et al, 2006).Both models are trained using a very similarpipeline as for the phrase model.
The main dif-ference is that the translation rules do not have tobe contiguous phrases, but may contain gaps withare labeled and co-ordinated by non-terminal sym-bols.
Decoding with such models requires a verydifferent algorithm, which is related to syntacticchart parsing.In the target syntax model, the target gaps andthe entire target phrase must map to constituentsin the parse tree.
This restriction may be relaxedby adding constituent labels such as DET+ADJ orNP\DET to group neighboring constituents or indi-cate constituents that lack an initial child, respec-tively (Zollmann and Venugopal, 2006).We applied these models to the English?German language direction, which is of particu-lar interest to us due to the rich target side mor-phology and large degree of reordering, resultingin relatively poor performance.
See Table 10 forexperimental results with the two traditional mod-els (phrase-based model and a factored model thatincludes a 7-gram morphological tag model) andthe two newer models (hierarchical and target syn-tax).
The performance of the phrase-based, hierar-chical, and target syntax model are close in termsof BLEU.5 ConclusionsWe obtained substantial gains over our systemsfrom last year for all language pairs.
To a largepart, these gains are due to additional training dataand our ability to exploit them.We also saw gains from adding linguistic an-notation (in form of 7-gram models over part-of-speech tags) and promising results for tree-basedmodels.
At this point, we are quite satisfied be-ing able to build competitive systems with thesenew models, which opens up major new researchdirections.Everything we described here is part of the opensource Moses toolkit.
Thus, all our experimentsshould be replicable with publicly available re-sources.AcknowledgementThis work was supported by the EuroMatrixPlusproject funded by the European Commission (7thFramework Programme).ReferencesChiang, D. (2005).
A hierarchical phrase-basedmodel for statistical machine translation.
InProceedings of the 43rd Annual Meeting ofthe Association for Computational Linguistics(ACL?05), pages 263?270, Ann Arbor, Michi-gan.
Association for Computational Linguistics.Collins, M., Koehn, P., and Kucerova, I.
(2005).Clause restructuring for statistical machinetranslation.
In Proceedings of the 43rd AnnualMeeting of the Association for ComputationalLinguistics (ACL?05), pages 531?540, Ann Ar-bor, Michigan.
Association for ComputationalLinguistics.Foster, G., Kuhn, R., and Johnson, H. (2006).Phrasetable smoothing for statistical machinetranslation.
In Proceedings of the 2006 Con-ference on Empirical Methods in Natural Lan-guage Processing, pages 53?61, Sydney, Aus-119tralia.
Association for Computational Linguis-tics.Gao, Q. and Vogel, S. (2008).
Parallel implemen-tations of word alignment tool.
In ACL Work-shop on Software Engineering, Testing, andQuality Assurance for Natural Language Pro-cessing, pages 49?57.Good, I. J.
(1953).
The population frequency ofspecies and the estimation of population param-eters.
Biometrika, 40:237?264.Haddow, B.
(2010).
Adding multi-threaded de-coding to moses.
The Prague Bulletin of Math-ematical Linguistics, (93):57?66.Hoang, H., Koehn, P., and Lopez, A.
(2009).
Aunified framework for phrase-based, hierarchi-cal, and syntax-based statistical machine trans-lation.
In Proceedings of IWSLT.Koehn, P. and Haddow, B.
(2009).
Edinburgh?ssubmission to all tracks of the WMT2009shared task with reordering and speed improve-ments to Moses.
In Proceedings of the FourthWorkshop on Statistical Machine Translation,pages 160?164, Athens, Greece.
Associationfor Computational Linguistics.Koehn, P. and Hoang, H. (2007).
Factored trans-lation models.
In Proceedings of the 2007Joint Conference on Empirical Methods in Nat-ural Language Processing and ComputationalNatural Language Learning (EMNLP-CoNLL),pages 868?876.Koehn, P., Hoang, H., Birch, A., Callison-Burch,C., Federico, M., Bertoldi, N., Cowan, B., Shen,W., Moran, C., Zens, R., Dyer, C. J., Bo-jar, O., Constantin, A., and Herbst, E. (2007).Moses: Open source toolkit for statistical ma-chine translation.
In Proceedings of the 45thAnnual Meeting of the Association for Com-putational Linguistics Companion Volume Pro-ceedings of the Demo and Poster Sessions,pages 177?180, Prague, Czech Republic.
Asso-ciation for Computational Linguistics.Koehn, P. and Knight, K. (2003).
Empirical meth-ods for compound splitting.
In Proceedings ofMeeting of the European Chapter of the Associ-ation of Computational Linguistics (EACL).Koehn, P. and Schroeder, J.
(2007).
Experimentsin domain adaptation for statistical machinetranslation.
In Proceedings of the Second Work-shop on Statistical Machine Translation, pages224?227, Prague, Czech Republic.
Associationfor Computational Linguistics.Marcu, D., Wang, W., Echihabi, A., and Knight,K.
(2006).
Spmt: Statistical machine transla-tion with syntactified target language phrases.In Proceedings of the 2006 Conference on Em-pirical Methods in Natural Language Process-ing, pages 44?52, Sydney, Australia.
Associa-tion for Computational Linguistics.Schwenk, H. and Koehn, P. (2008).
Large anddiverse language models for statistical machinetranslation.
In Proceedings of the 3rd Interna-tional Joint Conference on Natural LanguageProcessing (IJCNLP).Stolke, A.
(2002).
SRILM - an extensible lan-guage modeling toolkit.
In Proceedings of theInternational Conference on Spoken LanguageProcessing.Zollmann, A. and Venugopal, A.
(2006).
Syntaxaugmented machine translation via chart pars-ing.
In Proceedings on the Workshop on Statis-tical Machine Translation, pages 138?141, NewYork City.
Association for Computational Lin-guistics.120
