Proceedings of the ACL-08: HLT Workshop on Mobile Language Processing, pages 13?18,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsInformation extraction using finite state automata and syllable n-gramsin a mobile environmentChoong-Nyoung Seon Harksoo Kim Jungyun SeoComputer Science and Engi-neeringComputer and CommunicationsEngineeringComputer Science and Engi-neeringSogang University Kangwon National University Sogang UniversitySeoul, Korea Chuncheon, Korea Seoul, Koreawilowisp@gmail.com nlpdrkim@kangwon.ac.kr seojy@sogang.ac.krAbstractWe propose an information extraction systemthat is designed for mobile devices with lowhardware resources.
The proposed system ex-tracts temporal instances (dates and times) andnamed instances (locations and topics) fromKorean short messages in an appointmentmanagement domain.
To efficiently extracttemporal instances with limited numbers ofsurface forms, the proposed system uses well-refined finite state automata.
To effectivelyextract various surface forms of named in-stances with low hardware resources, the pro-posed system uses a modified HMM based onsyllable n-grams.
In the experiment on in-stance boundary labeling, the proposed systemshowed better performances than traditionalclassifiers.1 IntroductionRecently, many people access various multi-mediacontents using mobile devices such as a cellularphone and a PDA (personal digital assistant).
Ac-cordingly, users?
requests on NLP (natural lan-guage processing) are increasing because theywant to easily and simply look up the multi-mediacontents.
Information extraction is one of usefulapplications in NLP that helps users to easilyaccess core information in a large amount of freetexts.
Unfortunately, it is not easy to implement aninformation extraction system in mobile devicesbecause target texts include many morphologicalvariations (e.g.
blank omission, typos, word ab-breviation) and mobile devices have many hard-ware limitations (e.g.
a small volume of a mainmemory and the absence of an arithmetic logic unitfor floating-point calculation)There are some researches on information ex-traction from short messages in a mobile device,and Cooper?s research (Cooper, 2005) is represent-ative.
Cooper predefined various syntactic patternswith placeholders and matched an input messageagainst the syntactic patterns.
Then, he extractedtexts in the placeholders and assigned them theattribute name of the placeholders.
This methodhas some advantages like easy implementation andfast response time.
However, it is inadequate toapply Cooper?s method to languages with partially-free word-order like Korean and Japanese becausea huge amount of syntactic patterns should be pre-defined according as the degree of freedom onword order increases.
Kang (2004) proposed aNLIDB (natural language interface to database)system using lightweight shallow NLP techniques.Kang raised problems of deep NLP techniquessuch as low portability and error-proneness.
Kangproposed a lightweight approach to natural lan-guage interfaces, where translation knowledge issemi-automatically acquired and user questions areonly syntactically analyzed.
Although Kang?s me-thod showed good performances in spite of usingshallow NLP techniques, it is difficult to apply hismethod to mobile devices because his method stillneeds a morphological analyzer with a large size ofdictionary.
In this paper, we propose an informa-tion extraction system that is designed for mobiledevices with low hardware resources.
The pro-posed system extracts appointment-related infor-mation (i.e.
dates, times, locations, and topics)from Korean short messages.This paper is organized as follows.
In section 2,we proposed an information extraction system fora mobile device in an appointment domain.
In sec-13tion 3, we explain experimental setup and reportsome experimental results.
Finally, we draw someconclusions in section 4.2 Lightweight information extraction sys-temFigure 1 shows an overall architecture of the pro-posed system.OutputNormalizationPartExtraction PartInputShort MessageTemporal instanceextractionConverting machine-manageable formsDate/Time extractionresultsNamed instanceextractionRanking instancesLocation/Topicextraction resultsDate/TimeFSAsn-gram statisticsFigure 1.
The system architectureAs shown in Figure 1, the proposed system con-sists of an extraction part and a normalization part.In the extraction part, the proposed system firstextracts temporal instance candidates (i.e.
datesand times) using FSA (finite-state automata).
Then,the proposed system extracts named instance can-didates (i.e.
locations and topics) using syllable n-grams.
Finally, the proposed system ranks the ex-tracted instances and selects the highest one pertarget category.
In the normalization part, the pro-posed system converts the temporal instances intosuitable forms.2.1 Information extraction using finite stateautomataAlthough short messages in an appointment do-main often include many incorrect words, temporalinstances like dates and times are expressed as cor-rect as possible because they are very important toappointment management.
In addition, temporalinstances are expressed in tractable numbers ofsurface forms in order to make message receiverseasily be understood.
In MUC-7, these kinds oftemporal instances are called TIMEX (Chinchor,1998), and it has known that TIMEX can be easilyextracted by using FSA (Srihari, 2001).
Based onthese previous works, the proposed system extractstemporal instances from short messages by usingFSA, as shown in Figure 2.Figure 2.
An example of FSA for date extraction2.2 Information extraction using statisticalsyllable n-gramsUnlike dates and times, locations and topics notonly have various surface forms, but also theirconstituent words are not included in a closed set.In MUC-7, these kinds of named entities are calledNAMEX (Chinchor, 1998), and many researcheson NAMEX have been performed by using rulesand statistics.
Generally, rule-based methods showhigh precisions but they have a weak point that it ishard to maintain a system when new words arecontinuously added to the system (Goh, 2003).
Sta-tistical methods guarantee reasonable perfor-mances but they need large-scale languageresource and complex floating point operations.Therefore, it is not suitable to apply previous tradi-tional approaches to mobile devices with manyhardware limitations.
To resolve this problem, wepropose a statistical model based on syllable n-grams, as shown in Figure 3.Figure 3.
Statistical information extraction14The extraction of named instances has two kinds ofproblems; a instance boundary detection problemand a category assigning problem.
If we can use aconventional morphological analyzer, the instanceboundary detection problem is not big.
However, itis not easy to use a morphological analyzer in amobile device because of hardware limitations andusers?
writing habitations.
Users often ignore wordspacing and this habitation lowers the performanceof the morphological analyzer.
To resolve thisproblem, we adopt a syllable n-gram model thatperforms well in word boundary detection for lan-guages like Chinese with no spacing betweenwords (Goh, 2003; Ha, 2004).
We first define 9labels that represent boundaries of named instancecandidates by adopting BIO (begin, inner, and out-er) annotation scheme, as shown in Table 1 (Hong,2005; Uchimoto, 2000).Tag Description Tag DescriptionLB Begin of a location TB Begin of a topicLI Inner of  a location TI Inner of a topicLE End of a location TE End of a topicLS A single-syllable loca-tionTS A single-syllabletopicOT Other syllableTable 1.
The definition of instance boundary labelsThen, based on a modified HMM (hidden Markovmodel), the proposed system assigns boundary la-bels to each syllable in an input message, as fol-lows.LetnS ,1  denote a message which consists of asequence of n syllable,nsss ,...,, 21 , and let nL ,1  de-note the boundary label sequence,nlll ,...,, 21 , of  nS ,1 .Then, the label annotation problem can be formallydefined as findingnL ,1  which is the result of Equa-tion (1).
),(maxarg)(),(maxarg)|(maxarg)(,1,1,1,1,1,1,1,1,1,1,1nnLnnnLnnLdefnSLPSPSLPSLPSLnnn===(1)In Equation (1), we dropped )(,1 nSP  as it is constantfor allnL ,1 .
Next, we break Equation (1) into bite-size pieces about which we can collect statistics, asshown in Equation (2).?=??
?=niiiiiiinn sllPslsPSLP11,11,11,1,1,1,1 ),|(),|(),(  (2)We simplify Equation (2) by making the followingtwo assumptions: one is that the current boundarylabel is only dependent on the previous boundarylabel, and the other is that current boundary label isaffected by its contextual features.
?=?=niiiiinn llPlsPSLP11*,1,1 )|()|(),(   (3)In Equation (3), )|(* ii lsP  is a modified observationprobability that is adopted from a class probabilityin na?ve Bayesian classification (Zheng, 1998) asshown in Equation (4).
The reason why we modifyan original observation probability )|( ii lsP  inHMM is its sparseness that is caused by a size li-mitation of training corpus in a mobile environ-ment.
?==fjiijiii lsPlPZlsP1* )|()(1)|(   (4)In Equation (4), f  is the number of contextual fea-tures, and ijs  is the jth feature of the ith syllable.
Zis a normalizing factor.
Table 2 shows the contex-tual features that the proposed system uses.Feature Composition Meaning1is  is  The current syllable2is  ii ss 1?The previous syllable and thecurrent syllable3is  1+ii ssThe current syllable and thenext syllableTable 2.
The composition of contextual featuresIn Equation (1), the max scores are calculated byusing the well-known Viterbi algorithm (Forney,1973).After performing instance boundary labeling,the proposed system extracts syllable sequenceslabeled with the same named categories.
For ex-ample, if a syllable sequence is labeled with ?TSOT LB LI LI?, the proposed system extracts thesub-sequence of syllables labeled with ?LB LI LI?,15as a location candidate.
Then, the proposed systemranks the extracted instance candidates by usingsome information such as position, length, and adegree of completion, as shown in Equation (5).iiii CompletionLengthPosition)Rank(NI ?+?+?= ???
(5)In Equation (5), iPosition  means the distance fromthe beginning of input message to the ith namedinstance candidate iNI .
In Korean, important wordstend to appear in the latter part of a message.Therefore, we assume that the latter part an in-stance candidate appears in, the more important theinstance candidate is.
iLength  means the length of aninstance candidate.
We assume that the longer aninstance candidate include is, the more informativethe instance candidate is.
iCompletion  means whethera sequence of instance boundary labels is complete.We assume that instance candidates with completelabel sequences are more informative.
To check thedegree of completion, the proposed system usesFSA, as shown in Figure 4.
In the training corpus,every transition is legal.
Therefore most of candi-dates were satisfied the completion condition.However, sometimes the completion condition isnot satisfied, when the candidate was extractedfrom the boundary of a sentence.
Accordingly thecondition gave an effect to the rank.Figure 4.
The FSA for checking label completionIn the experiments, we set ?
, ?
,  and ?
to 1, 2,and 10, respectively.2.3 Normalization of temporal instancesIt is inadequate for the proposed system to use theextracted temporal instances as database instanceswithout any processing because the temporal in-stances consist of various forms of human-readablestrings like ?January 24, 2008?.
Therefore, the pro-posed system should normalize the temporal in-stances into machine-manageable forms like?20080124?.
However, the normalization is noteasy because temporal instances often include therelative information like ?this Sunday?
and ?aftertwo days?.
To resolve this problem, the proposedsystem converts relative temporal instances intoabsolute temporal instances by using a messagearrival time.
For example, if a message includesthe temporal instance ?after two days?, the pro-posed system checks arrival time information ofthe message.
Then, the proposed system adds adate in the arrival time information to two days.Figure 5 shows an example of date normalization.Figure 5.
An example of date normalization3 Evaluation3.1 Data sets and experimental settingsWe collected 6,190 short messages simulated in anappointment scheduling domain.
These messagescontain 4,686 locations and 4,836 topics.
Eachmessage is manually annotated with the boundarylabels in Table 1.
The manual annotation was doneby 2 graduate students majoring in natural lan-guage processing and post-processed by a studentin a doctoral course for consistency.
In order toexperiment the proposed system, we divided theannotated messages into the training corpus andthe testing corpus by a ratio of four (4,952 messag-es) to one (1,238 messages).
Then, we performed5-fold cross validation and used a precision, a re-call rate, and a F1-measure as performance meas-ures.
In this paper, we did not evaluate theperformances on the temporal instance extractionbecause performances of the proposed method arefully dependent on the coverage of pre-constructedFSA.3.2 Experimental results16To choose the proper size of language models in amobile environment, we evaluated performancevariations of the proposed system, as shown inFigure 6.Figure 6.
The performance variations according to thesize of language modelsAs shown in Figure 6, the system using syllableunigrams showed much lower performances thanthe systems using syllable bigrams or syllable tri-grams.Bigram Trigram# of features 54,711 158,525Size of DB 1.33M 2.83MTable 3.
Space requirements of language models.However, as shown in the Table 3, although thenumber of syllable trigrams was three times largerthan the number of syllable bigrams, the differenceof performances between the system using syllablebigrams and the system using syllable trigrams wasnot big (about 1%).
Based on this experimentalresult, we conclude that the combination of sylla-ble unigrams and syllable bigrams, as shown inTable 2, is the most suitable language model formobile devices with low hardware resources.To evaluate the proposed system, we calculatedtwo types of performances.
One is boundary labe-ling performances that measure whether the pro-posed system can correctly annotate a test corpuswith boundary labels in Table 1.
The other is ex-traction performances that measure whether theproposed system can correctly extract named in-stances from a test corpus by using Equation (5).Table 4 shows the boundary labeling performancesof the proposed system in comparisons with thoseof representative classifiers.Model Precision RecallrateF1-measureNB 62.74% 75.17% 68.34%SVM 67.29% 67.58% 67.37%CRF 70.98% 66.27% 68.45%Proposedsystem 74.81% 77.20% 75.91%Table 4.
The comparison of boundary labeling perfor-mancesIn Table 4, NB is a classifier using na?ve Bayesianstatistics, and SVM is a classifier using a supportvector machine.
CRF is a classifier using condi-tional random fields.
As shown in Table 4, theproposed system outperformed the comparativemodels in all measures.
Based on this fact, wethink that the modified HMM may be more effec-tive in a labeling sequence problem.Table 5 shows the extraction performances of theproposed system.
In Table 5, the reason why theperformances on the topic extraction are lower isthat topic instances can consist of more varioussyllables (e.g.
the topic instance, ?a meeting inSamsung Research Center?, includes the location,?Samsung Research Center?
).Category Precision Recall rate F1-measureLocation 79.37% 76.33% 77.78%Topic 58.54% 55.20% 56.72%Table 5.
The extraction performancesTable 6 shows performance variations according asthe parameters in Equation (5) are changed.
Asshown in Table 6, the differences between perfor-mances are not big, and the proposed modelshowed the best performance at (?=1, ?=2, ?=5) or(?=1, ?=2, ?=10).
On the basis of this experiments,we set ?, ?, and ?
to 1, 2, and 5, respectively.(?,?,?)
Precision of LocationRecall rateof LocationF1-measureof Location(1,1,1) 79.23% 76.20% 77.65%(1,1,5) 79.28% 76.24% 77.69%17(1,1,10) 79.30% 76.26% 77.71%(1,2,5) 79.37% 76.33% 77.78%(1,2,10) 79.37% 76.33% 77.78%(?,?,?)
Precision of TopicRecall rateof TopicF1-measureof Topic(1,1,1) 58.09% 54.76% 56.28%(1,1,5) 58.09% 54.76% 56.28%(1,1,10) 58.11% 54.78% 56.30%(1,2,5) 58.54% 55.20% 56.72%(1,2,10) 58.54% 55.20% 56.72%Table 6.
The performance variations according to para-meter changesTo evaluate usefulness of the proposed model in areal mobile phone environment, we measured anaverage response time of 100 short messages in amobile phone with XSCALE PXA270 CPU,51.26MB memory, and Windows mobile 5.0.
Weobtained an average response time of 0.0532seconds.4 ConclusionWe proposed an information extraction system fora mobile device in an appointment managementdomain.
The proposed system efficiently extractstemporal instances with limited numbers of surfaceforms by using FSA.
To effectively extract varioussurface forms of named instances with low hard-ware resources, the proposed system uses a mod-ified HMM based on syllable n-grams.
In theexperiment on instance boundary labeling, the pro-posed system outperformed traditional classifiersthat showed good performances in a labeling se-quence problem.
On the experimental basis, wethink that the proposed method is very suitable forinformation extraction applications with manyhardware limitations.AcknowledgmentsThis research (paper) was funded by SamsungElectronics.5 ReferenceChooi Ling Goh, Masayuki Asahara, Yuji Matsumoto.2003.
Chinese unknown word identification usingcharacter-based tagging and chunking.
Proceedingsof ACL-2003 Interactive Posters and Demonstrations,197-200.G.
David Forney, JR. 1973.
The Viterbi Algorithm Pro-ceedings of the IEEE, 61(3):268-278.Hong Shen, Anoop Sarkar.
2005.
Voting Between Mul-tiple Data Representations for Text Chunking.
Cana-dian Conference on AI 2005.
389-400.In-Su Kang, Seung-Hoon Na, Jong-Hyeok Lee, GijooYang.
2004.
Lightweight Natural Language DatabaseInterfaces.
Proceedings of the 9th International Con-ference on Application of Natural Language to In-formation Systems.
76-88.Juhong Ha, Yu Zheng, Byeongchang Kim, Gary Geun-bae Lee, Yoon-Suk Seong.
2004.
High Speed Un-known Word Prediction Using Support VectorMachine for Chinese Text-to-Speech Systems.IJCNLP:509-517Kiyotaka Uchimoto, Qing Ma, Masaki Murata, HiromiOzaku, and Hitoshi Isahara.
Named Entity ExtractionBased on A Maximum Entropy Model and Trans-formation Rules.
In Proceedings of the 38th AnnualMeeting of Association for Computational Linguis-ticsNancy A. Chinchor.
1998.
MUC-7 named entity taskdefinition, Proceedings of the Seventh Message Un-derstanding Conference.Richard Cooper, Sajjad Ali, Chenlan Bi, 2005.
Extract-ing Information from Short Messages, NLDB 2005,LNCS 3513, pp.
388-391.Rohini Srihari, Cheng Niu, Wei Li.
2001.
A hybrid ap-proach for named entity and sub-type tagging.
InProc.
6th Applied Natural Language Processing Con-ference.Zijian Zheng.
Naive Bayesian classifier committees.Proceedings of the 10th European Conference onMachine Learning.
Berlin: Springet-Verlag (1998)196-207.SVM_light: http://svmlight.joachims.org/CRF++: http://crfpp.sourceforge.net/18
