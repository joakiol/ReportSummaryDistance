Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 760?768,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsRelaxed Marginal Inference and its Application to Dependency ParsingSebastian Riedel David A. SmithDepartment of Computer ScienceUniversity of Massachusetts, Amherst{riedel,dasmith}@cs.umass.eduAbstractRecently, relaxation approaches have beensuccessfully used for MAP inference on NLPproblems.
In this work we show how to extendthe relaxation approach to marginal inferenceused in conditional likelihood training, pos-terior decoding, confidence estimation, andother tasks.
We evaluate our approach for thecase of second-order dependency parsing andobserve a tenfold increase in parsing speed,with no loss in accuracy, by performing in-ference over a small subset of the full factorgraph.
We also contribute a bound on the errorof the marginal probabilities by a sub-graphwith respect to the full graph.
Finally, whileonly evaluated with BP in this paper, our ap-proach is general enough to be applied withany marginal inference method in the innerloop.1 IntroductionIn statistical natural language processing (NLP) weare often concerned with finding the marginal proba-bilities of events in our models or the expectations offeatures.
When training to optimize conditional like-lihood, feature expectations are needed to calculatethe gradient.
Marginalization also allows a statis-tical NLP component to give confidence values forits predictions or to marginalize out latent variables.Finally, given the marginal probabilities of variables,we can pick the values that maximize these marginalprobabilities (perhaps subject to hard constraints) inorder to predict a good variable assignment.11With a loss function that decomposes on the variables, thisamounts to Minimum Bayes Risk (MBR) decoding, which isTraditionally, marginal inference in NLP has beenperformed via dynamic programming (DP); how-ever, because this requires the model to factor ina way that lends itself to DP algorithms, we haveto restrict the class of probabilistic models we con-sider.
For example, since we cannot derive a dy-namic program for marginal inference in second or-der non-projective dependency parsing (McDonaldand Satta, 2007), we have non-projective languagessuch as Dutch using second order projective mod-els if we want to apply DP.
Some previous workhas circumvented this problem for MAP inferenceby starting with a second-order projective solutionand then greedily flipping edges to find a better non-projective solution (McDonald and Pereira, 2006).In order to explore richer model structures, theNLP community has recently started to investigatethe use of other, well-known machine learning tech-niques for marginal inference.
One such technique isMarkov chain Monte Carlo, and in particular Gibbssampling (Finkel et al, 2005), another is (loopy)sum-product belief propagation (Smith and Eisner,2008).
In both cases we usually work in the frame-work of graphical models?in our case, with factorgraphs that describe our distributions through vari-ables, factors, and factor potentials.
In theory, meth-ods such as belief propagation can take any graphand perform marginal inference.
This means that wegain a great amount of flexibility to represent moreglobal and joint distributions for NLP tasks.The graphical models of interest, however, areoften too large and densely connected for efficientinference in them.
For example, in second orderoften very effective.760dependency parsing models, we have O(n2) vari-ables and O(n3) factors, each of which may haveto be inspected several times.
While belief prop-agation is still tractable here (assuming we followthe approach of Smith and Eisner (2008) to enforcetree constraints), it is still much slower than sim-pler greedy parsing methods, and the advantage sec-ond order models give in accuracy is often not sig-nificant enough to offset the lack of speed in prac-tice.
Moreover, if we extend such parsing models to,say, penalizing all pairs of crossing edges or scoringsyntax-based alignments, we will need to inspect atleast O(n4)factors, increasing our efficiency con-cerns.When looking at the related task of finding themost likely assignment in large graphical models(i.e., MAP inference), we notice that several recentapproaches have significantly sped up computationthrough relaxation methods (Tromble and Eisner,2006; Riedel and Clarke, 2006).
Here we start witha small subset of the full graph, and run inferencefor this simpler problem.
Then we search for factorsthat are ?violated?
in the solution, and add them tothe graph.
This is repeated until no more new factorscan be added.
Empirically this approach has shownimpressive success.
It often dramatically reduces theeffective network size, with no loss in accuracy.How can we extend or generalize MAP relax-ation algorithms to the case of marginal inference?Roughly speaking, we answer it by introducing anotion of factor gain that is defined as the KL di-vergence between the current distribution with andwithout the given factor.
This quantity is then usedin an algorithm that starts with a sub-model, runsmarginal inference in it and then determines thegains of the not-yet-added factors.
In turn, all fac-tors for which the gain exceeds some threshold areadded to the current model.
This process is repeateduntil no more new factors can be found or a maxi-mum number of iterations is reached.We evaluate this form of relaxed marginal infer-ence for the case of second-order dependency pars-ing.
We follow Smith and Eisner?s tree-aware be-lief propagation procedure for inference in the innerloop of our algorithm.
This leads to a tenfold in-crease in parsing speed with no loss in accuracy.We also contribute a bound on the error onmarginal probabilities the sub-graph defines with re-spect to the full graph.
This bound can be used bothfor terminating (although not done here) and under-standing the dynamics of inference.
Finally, whileonly evaluated with BP so far, it is general enoughto be applied with any marginal inference method inthe inner loop.In the following, we first give a sketch of thegraphical model we apply.
Then we briefly discussmarginal inference.
In turn we describe our relax-ation algorithm for marginal inference and some ofits theoretic guarantees.
Then we present empiricalsupport for the effectiveness of our approach, andconclude.2 Graphical Models of Dependency TreesWe give a brief overview of the graphical model weapply in our experiments.
We chose the grandpar-ents and siblings model, together with language spe-cific multiroot and projectivity options as taken fromSmith and Eisner (2008).
All our models are definedover a set of binary variables Lij that indicate a de-pendency between token i and j of the input sen-tence W .2.1 Markov Random FieldsFollowing Smith and Eisner (2008), we define aprobability distribution over all dependency trees asa collection of edges y for a fixed input sentenceW .
This distribution is represented by an undirectedgraphical model, or Markov random field (MRF):pF (y)def=1Z?i?F?i (y) (1)specified by an index set F and a correspondingfamily (?i)F of factors ?i : Y 7?
<+.
Here Zis the partition function ZF =?y?i ?i (y).We will restrict our attention to binary factors thatcan be represented as ?i (y) = e?i?i(y) with binaryfunctions ?i (y) ?
{0, 1} and weights ?i ?
<.2 This2These ?i are also called sufficient statistics or feature func-tions, not to be confused with the features whose weighted sumforms the weight ?i.
The restriction to binary functions is with-out loss of generality since we can combine constraints on par-ticular variable assignments into potential tables with severaldimensions.761leads topF (y)def=1Zexp(?i?F?i?i (y))as an alternative representation for pF .
Note thatwhen ?i (y) = 1 we will say that ?i fires for y.Note that a factor function ?i(y) can depend onany part of the observed input sentenceW ; however,for brevity we will suppress this extra argument to?i.2.2 Hard and Soft Constraints on TreesA particular model specifies its preference for set ofdependency edges over another by a set of hard andsoft constraints.
We use hard constraints to rule outa priori illegal structures, such as trees where a wordhas two parents, and soft constraints to raise or lowerthe score of trees that contain particular good or badsubstructures.A hard factor (or constraint) ?i evaluates an as-signment y with respect to some specified condi-tion and fires only if this condition is violated; inthis case it evaluates to 0.
It is therefore ruling outall configurations in which the condition does nothold.
Note that a hard constraint ?i corresponds to?i = ??
in our loglinear representation.For dependency parsing, we consider two partic-ular hard constraints, each of which touches all edgevariables in y: the constraint Tree requires that alledges form a directed spanning tree rooted at theroot node 0; the constraint PTree enforces the morestringent condition that all edges form a projectivedirected tree.
As in (Smith and Eisner, 2008), weused algorithms from edge-factored parsing to com-pute BP messages for these factors.
In our experi-ments, we enforced one or the other constraint de-pending on the projectivity of given treebank data.A soft factor ?i acts as a soft constraint thatprefers some assignments to others.
This is equiv-alent to saying that its weight ?i is finite.
Note thatthe weight of a soft factor is usually itself composedas a sum of (sub-)weights wj for feature functionsthat have the same input-output behavior as ?i (y)when conditioned on the current sentence.
It is thesewj which are adjusted at training time.We use three kinds of soft factors from Smith andEisner (2008).
In the full model, there are: O(n2)LINKi,j factors that judge dependency edges in iso-lation; O(n3) GRANDi,j,k factors that judge pairsof dependency edges in a grandparent-parent-childchain; and O(n3) SIBi,j,k factors that judge pairs ofdependency edges that share the same parent.3 Marginal InferenceFormally, given our set of factors F and an observedsentence W , marginal inference amounts to calcu-lating the probability ?Fi that our binary features ?iare active.
That is, for each factor ?i?Fidef=?
?i(y)=1pF (y) = EF [?i] (2)For compactness, we follow the convention of Wain-wright and Jordan (2008) and represent the belief fora variable using the marginal probability of its cor-responding unary factor.
Hence, if we want to calcu-late pF (Lij) we use ?FLINKij in place.
Moreover wewill use ?F?idef= 1?
?Fi when we need the probabilityof the event ?i (y) = 0.The two most prominent approaches to marginalinference in general graphical models are MarkovChain Monte Carlo (MCMC) and variational meth-ods.
In a nutshell, MCMC iteratively generates aMarkov chain that yields pF as its stationary distri-bution.
Any expectation ?Fi can then be calculatedsimply by counting the corresponding statistics inthe generated chain.Generally speaking, variational methods framemarginal inference as an optimization problem.
Ei-ther in the sense of minimizing the KL divergenceof a much simpler distribution to the actual distribu-tion pF , as in mean field methods.
Or in the sense ofmaximizing a variational representation of the log-partition function over the setM of valid mean vec-tors (Wainwright and Jordan, 2008).
Note that thevariational representation of the log partition func-tion involves an entropy term that is intractable tocalculate in general and therefore usually approxi-mated.
Likewise, the set of constraints that guaran-tee vectors ?
to be valid mean vectors is intractablylarge and is often simplified.Because we use belief propagation (BP) as base-line to compare to, and as a subroutine in our pro-posed algorithm, a brief characterization of it is inorder.
BP can be seen as a variational method that762uses the Bethe Free Energy as approximation to theentropy, and the setML of locally consistent meanvectors as an outer bound onM.
A mean vector islocally consistent if its beliefs on factors are consis-tent with the beliefs of the factor neighbors.BP solves the variational problem by iterativelyupdating the beliefs of factors and variables basedon the current beliefs of their neighbors.
When ap-plied to acyclic graphical models BP yields the exactmarginals at convergence.
For general graphs, BP isnot guaranteed to converge, and the beliefs it calcu-lates are generally not the true marginals; however,in practice BP often does converge and lead to accu-rate marginals.4 Relaxed Incremental Marginal InferenceGenerally the runtime and accuracy of a marginal in-ference method depends on size, density, tree-widthand interaction strength (i.e.
the magnitude of itsweights) of the Graphical Model.
For example, inBelief Propagation the number of messages we haveto send in each iteration scales with the number offactors (and their degrees).
This means that whenwe add a large number of extra factors to our model,such as the O(n3) grandparent and sibling factorsfor dependency parsing, we have to pay a price interms of speed, sometimes even accuracy.However, on close inspection often many of theadditional factors we use to model some higher or-der interactions are somewhat unnecessary or redun-dant.
To illustrate this, let us look at a second or-der parsing model with grandparent factors.
Surelydeterminers are not heads of other determiners, andthis should be easy to encourage using LINK fea-tures only.
Hence, a grandparent factor that dis-courages a determiner-determiner-determiner chainseems unnecessary.This raises two questions: (a) can we get awaywithout most of these factors, and (b) can we effi-ciently tell which factors should be discarded.
Wewill see in section 5 that question (a) can be an-swered affirmatively: with a only fraction of all sec-ond order factors we can calculate marginals that arevery close to the BP marginals, and when used inMBR decoding, lead to the same trees.Question (b) can be approached by looking at howa similar problem has been tackled in combinato-rial optimization and MAP inference.
Riedel andClarke (2006) tackled the MAP problem for depen-dency parsing by an incremental approach that startswith a relaxation of the problem, solves it, and addsadditional constraints only if they are violated.
Ifconstraints were added, the process is repeated, oth-erwise we terminate.4.1 Evaluating Candidate FactorsTo develop such an incremental relaxation approachto marginal inference, we generalize the notion of aviolated constraint.
What does it mean for a factor tobe violated with respect to the solution of a marginalinference problem?One answer is to interpret the violation of a con-straint as ?adding this constraint will impact our cur-rent belief?.
To assess the impact of adding factor?i to a sub-graph F ?
?
F we can then use the fol-lowing intuition: if the distribution F ?
?
{i} is verysimilar to the distribution corresponding to F ?, it isprobably safe to say that the marginals we get fromboth are close, too.
If we use the KL divergence be-tween the (distributions of) F ?
?
{i} and F ?
for ourinterpretation of the above mentioned closeness, wecan define a potential gain for adding ?i as follows:gF ?
(?i)def= DKL(pF ?
||pF ??
{i}).Together with a threshold  on this gain we cannow adapt the relaxation approach to marginal in-ference by simply replacing the question, ?Is ?i vi-olated??
with the question, ?Is gF ?
(i) > ??
Wecan see the latter question as a generalization of theformer if we interpret MAP inference as the zero-temperature limit of marginal inference (Wainwrightand Jordan, 2008).The form of the gain function is chosen to be eas-ily evaluated using the beliefs we have already avail-able for the current sub-graph F ?.
It is easy to show(see Appendix) that the following holds:Proposition 1.
The gain of a factor ?i with respectto the sub-graph F ?
?
F isgF ?
(?i) = log(?F?
?i + ?F ?i e?i)?
?F?i ?i (3)That is, the gain of a factor ?i depends on twoproperties of ?i.
First, the expectation ?F?i that?i fires under the current model F ?, and second,763its loglinear weight ?i.
To get an intuition for thisgain, consider the limit lim?F?i ?1gF ?
(?i) of a fac-tor with positive weight that is expected to be activeunder F ?.
In this case the gain becomes zero, mean-ing that the more likely ?i fires under the currentmodel, the less useful will it be to add according toour gain.
For lim?F?i ?0gF ?
(?i) the gain also disap-pears.
Here the confidence of the current model in ?ibeing inactive is so high that any single factor whichindicates the opposite cannot make a difference.Fortunately, the marginal probability ?F?i is usu-ally available after inference, or can be approxi-mated.
This allows us to maintain the same basicalgorithm as in the MAP case: in each ?inspectionstep?
we can use the results of the last run of infer-ence in order to evaluate whether a factor has to beadded or not.4.2 AlgorithmAlgorithm 1 shows our proposed algorithm, RelaxedMarginal Inference.
We are given an initial factorgraph (for example, the first order dependency pars-ing model), a threshold  on the minimal gain a fac-tor needs to have in order to be added, and a solver Sfor marginal inference in the partial graphs we gen-erate along the way.We start by finding the marginals ?
for the initialgraph.
These marginals are then used in step 4 tofind the factors that would, when added in isolation,change the distribution substantially (i.e., by morethan  in terms of KL divergence).
We will referto this step as separation, in line with cutting planeterminology.
The factors are added to the currentgraph, and we start from the top unless there wereno new factors added.
In this case we return the lastmarginals ?.Clearly, this algorithm is guaranteed to converge:either we add at least one factor per iteration untilwe reach the full graph F , or we converge before.However, it is difficult to make any general state-ments about the number of iterations it takes untilconvergence.
Nevertheless, in our experiments wefind that algorithm 1 converges to a much smallergraph after a small number of iterations, and hencewe are always faster than inference on the full graph.Finally, note that calculating the gain for all fac-tors in F \ F ?
in step 4 (separation) takes time pro-Algorithm 1 Relaxed Marginal Inference.1: require:F ?:init.
graph, : threshold, S:solver, R: max.
it2: repeatFind current marginals using solver S3: ??
marginals(F?, S)Find factors with high gain not yet added4: ?F ?
{i ?
F \ F?|gF ?
(?i) > }Add factors to current graph5: F ?
?
F ?
?
?FCheck: no more new factors were added or R reached6: until ?F = ?
or iteration >Rreturn the marginals for the last graph F ?7: return ?portional to |F \ F ?|.4.3 AccuracyWe have seen how to evaluate the potential gainwhen adding a single factor.
However, this doesnot tell us how good the current sub-model is withrespect to the complete graph.
After all, while allremaining factors individually might not contributemuch, in concert they may.
We therefore present a(calculable) bound on the KL divergence of the par-tial graph from the full graph that can give us confi-dence in the solutions we return at convergence.Note that for this bound we still only need fea-ture expectations from the current model.
More-over, we assume all weights ?i are positive?withoutloss of generality since we can always replace ?iwith its negation 1 ?
?i and then change the signof ?i (Richardson and Domingos, 2006).Proposition 2.
Assume non-negative weights, letF ?
?
F be a subset of factors, Gdef= F \ F ?
and?def= ?
?G?1 ?
?
?G, ?G?
?
0.
Then1.
for the KL divergence between F ?
and the fullnetwork F we have:DKL(pF ?
||pF)?
?.2.
for the error we make when estimating ?i?s trueexpectation ?Fi by ?F ?i we have:?
(e?
?
1)?F?
?i ?
?Fi ?
?F ?i ?
(e?
?
1)?F?i .764This says that (1) we get closer to the full distri-bution and that (2) our marginals closer to the truemarginals, if the remaining factors G either havea low total weight ?
?G?, or the current belief ?Galready assigns high probability to the features ?Gbeing active (and hence ??
?G, ?G?
is small).
Thelatter condition is the probabilistic analog to con-straints already being satisfied.
Finally, since ?
canbe easily calculated, we plan to investigate its utilityas a convergence criterion in future work.4.4 Related WorkOur approach is inspired by earlier work on re-laxation algorithms for performing MAP inferenceby incrementally tightening relaxations of a graph-ical model (Anguelov et al, 2004; Riedel, 2008),weighted Finite State Machine (Tromble and Eisner,2006), Integer Linear Program (Riedel and Clarke,2006) or Marginal Polytope (Sontag et al, 2008).However, none of these methods apply to marginalinference.Sontag and Jaakkola (2007) compute marginalprobabilities by using a cutting plane approach thatstarts with the local polytope and then optimizessome approximation of the log partition function.Cycle consistency constraints are added if they areviolated by the current marginals, and the process isrepeated until no more violations appear.
While thisapproach does tackle marginalization, it is focusedon improving its accuracy.
In particular, the opti-mization problems they solve in each iteration are infact larger than the problem we want to relax.Our approach is also related to edge deletionin Bayesian networks (Choi and Darwiche, 2006).Here edges are removed from a Bayesian network inorder to find a close approximation to the full net-work useful for other inference-related tasks (suchas combined marginal and MAP inference).
Thecore difference to our approach is the fact that theyask which edges to remove from the full graph, in-stead of which to add to a partial graph.
This re-quires inference in the full model?the very opera-tion we want to avoid.5 ExperimentsIn our experiments we seek to answer the followingquestions.
First, how fast is our relaxation approachcompared to full marginal inference at comparabledependency accuracy?
This requires us to find thebest tree in terms of marginal probabilities on thelink variables (Smith and Eisner, 2008).
Second,how good is the final relaxed graph as an approxima-tion of the full graph?
Finally, how does incrementalrelaxation scale with sentence length?5.1 Data and ModelsWe trained and tested on a subset of languagesfrom the CoNLL Dependency Parsing SharedTasks (Nivre et al, 2007): Dutch, Danish, Italian,and English.
We apply non-projective second ordermodels for Dutch, Danish and Italian, and a projec-tive second order model for English.
To be able tocompare inference on the same model, we trainedusing BP on the full set of LINK, GRAND, and SIBfactors.Note that our models would rank highly amongthe shared task submissions, but could surely be fur-ther improved.
For example, we do not use any lan-guage specific features.
Since our focus in this paperis speeding up marginal inference, we will search forbetter models in future work.5.2 Runtime and Dependency AccuracyIn our first set of experiments we explore the speedand accuracy of relaxed BP in comparison to full BP.To this end we first tested BP configurations with atmost 5, at most 10, and at most 50 iterations to findthe best setup in terms of speed and accuracy.
Smithand Eisner (2008) use 5 iterations but we found thatby using 10 iterations accuracy could be slightly im-proved.
Running at most 50 iterations led to thesame accuracy but was significantly slower.
Hencewe only report BP results with 10 iterations here.For relaxed BP we tested along three dimensions:the threshold  on the gain of factors, the maximumnumber of BP iterations in the inner loop of relaxedBP, and the maximum number of relaxation itera-tions.
A configuration with maximum relaxation it-erations R, threshold , and maximum BP iterationsB will be identified by RelR,,B .
In all settings weuse the LINK factors and the hard factors as initialgraph F ?.Table 1 shows the results for several configura-tions and our four languages in terms of unlabeleddependency accuracy (percentage of correctly iden-765Dutch Danish English ItalianConfiguration Acc.
Time Acc.
Time Acc.
Time Acc.
TimeBP 84.9 0.665 88.1 1.44 88.3 2.43 87.4 1.68Rel?,0.0001,5 85.0 0.120 88.1 0.234 88.2 0.575 87.4 0.261Rel?,0.0001,50 84.9 0.121 88.2 0.236 88.3 0.728 87.4 0.266Rel1,0.0001,50 84.9 0.060 88.2 0.110 88.4 0.352 87.4 0.132Table 1: Dependency accuracy (%) and average parsing time (sec.)
using second order models.tified heads) in comparison to the gold data, and av-erage parsing time in seconds.
Here parsing timeincludes both time spent for marginal inference andthe MBR decoding step after the marginals are avail-able.We notice that by relaxing BP with no limit on thenumber of iterations we gain a 4-6 fold increase inparsing speed across all languages when using thethreshold  = 0.0001, while accuracy remains ashigh as for full BP.
This can be achieved with fewerBP iterations (at most 5) in each round of relaxationthan full BP needs per sentence (at most 10).
Intu-itively this makes sense: since our factor graphs aresmaller in each iteration there will be fewer cyclesto slow down convergence.
This only has a smallimpact on overall parsing time for languages otherthan English, since for most sentences even full BPconverges after less than 10 iterations.We also observe that running just one iteration ofour relaxation algorithm (Rel1,0.0001,50) is enough toachieve accurate solutions.
This leads to a twofoldspeed-up in comparison to running relaxation untilconvergence (primarily because of fewer calls to theseparation routine), and a 7-13 fold speed-up (ten-fold on average) when compared to full BP.5.3 Quality of Relaxed SubgraphsHow large is the fraction of the full graph neededfor accurate marginal probabilities?
And do we re-ally need our relaxation algorithm with repeated in-ference or could we instead just prune the graph inadvance?
Here we try to answer these questions, andwill focus on the Danish dataset.
Note that our re-sults for the other languages follow the same pattern.In table 2, we present the average ratio of the sizesof the partial and the full graph in terms of the sec-ond order factors.
We also show the total runtimeneeded to find the subgraph and run inference in it.Configuration Size Time Err.
Acc.BP 100% 1.44 ?
88.1Rel?,0.1,50 ?
0% 0.12 0.20 87.5Rel?,0.0001,50 0.8% 0.24 0.012 88.2Rel1,0.0001,50 0.8% 0.11 0.015 88.2Pruned0.1 42% 0.56 0.022 88.0Pruned0.5 22% 0.40 0.098 87.7Table 2: Ratio of partial and full graph size (Size),runtime in seconds (Time), avg.
error on marginals(Err.)
and tree accuracy (Acc.)
for Danish.As a measure of accuracy for marginal probabilitieswe find the average error in marginal probability forthe variables of a sentence.
Note that this measuredoes not necessarily correspond to the true error ofour marginals because BP itself is approximate andmay not return the correct marginals.The first row shows the full BP system, workingon 100% of the factor graph.
The next three rowslook at relaxed marginal inference.
We notice thatwith a low threshold  = 0.1 we pick almost no ad-ditional factors (0.003%), and this does affect accu-racy.
However, by lowering the threshold to 0.0001and adding about 0.8% of the second order factors,we already match the dependency accuracy of fullBP.
On average we are also very close to the BPmarginals.Can we find such small graphs without runningextra iterations of inference?
One approach couldbe to simply cut off factors ?i with absolute weights|?i| that fall under a certain threshold t. In the finalrows of the table we test such an approach with t =0.1, 0.5.We notice that pruning can reduce the second or-der factors to 42% while yielding (almost) the sameaccuracy, and close marginals.
However, it is 5 timesslower than our fastest approach.
When reducing7660 20 40 600204060Sentence LengthTimeBPPrunedRelaxedRelaxed 1 It.Figure 1: Total runtimes by sentence length.size further to about 20%, accuracy drops below thevalues we achieved with our relaxation approach at0.8% of the second order factors.
Hence simplepruning removes factors that do have a low weight,but are still important to keep.5.4 Runtime with Varying Sentence LengthWe have seen how relaxed BP is faster than fullBP on average.
But how does its speed scale withsentence length?
To answer this question figure 1shows a plot of runtime by sentence length for fullBP, pruned BP with threshold 0.1, Rel?,0.0001,50 andRel1,0.0001,50.The graph indicates that the advantage of relaxedBP over both full BP and Pruned BP becomes evenmore significant for longer sentences, in particularwhen running only one iteration.
This shows that byusing our technique, second order parsing becomesmore practical, in particular for very long sentences.6 ConclusionWe have presented a novel incremental relaxation al-gorithm that can be applied to marginal inference.Instead of adding violated constraints in each iter-ation, it adds factors that significantly change thedistribution of the graph.
This notion is formalizedby the introduction of a gain function that calculatesthe KL divergence between the current network withand without the candidate factor.
We show how thisgain can be calculated and provide bounds on the er-ror made by the marginals of the relaxed graph inplace of the full one.Our algorithm led to a tenfold reduction in run-time at comparable accuracy when applied to multi-lingual dependency parsing with Belief Propagation.It is five times faster than pruning factors by theirabsolute weight, and results in smaller graphs withbetter marginals.In future work we plan to apply relaxed marginalinference to larger joint inference problems withinNLP, and test its effectiveness with other marginalinference algorithms as solvers in the inner loop.AcknowledgmentsThis work was supported in part by the Center forIntelligent Information Retrieval and in part by SRIInternational subcontract #27-001338 and ARFLprime contract #FA8750-09-C-0181.
Any opinions,findings and conclusions or recommendations ex-pressed in this material are the authors?
and do notnecessarily reflect those of the sponsor.Appendix: Proof SketchesFor Proposition 1 we use the primal form of the KL diver-gence (Wainwright and Jordan, 2008)D`p?F ||pF?= log`ZFZ?1F???
?
?F ?
, ?F ?
?F?
?and represent the ratio ZFZ?1F?
of partition functions asZFZF?=Xye??F?
,?F?
(y)?ZF?e??G,?G(y)?
= EF?he?
?G,?G?iwhere Gdef= F \ F ?.
With G = {i} we get the desired gain.For Proposition 2, part 1, we first pick a simple upper boundon ZFZ?1F?
by replacing the expectation with e?
?G?1 .
Insert-ing this into the primal form KL divergence leads to the givenbound.
For part 2 we represent pF using pF?pF (y) = ZF?Z?1F e??G,?G(y)?pF?
(y)and reuse our above representation of ZFZ?1F?
.
This givespF (y) = EF?he??G,?G(y)?i?1pF?
(y) e?
?G,?G(y)?which can be upper bounded by lower bounding the expectationand upper bounding the log-linear term.
For the latter we usee?
?G?1 , for the first Jensen?s inequality givesEF?he??G,?G(y)?i?1?
eEF?
[??G,?G(y)?]
= eD?G,?F?GEwhere the equality follows from linearity of expectations.
Thisyields pF (y) ?
pF?
(y) e?
and therefore upper bounds on ?Fiand ?F?i.
Basic algebra then gives the desired error interval for?Fi in terms of ?F?i .767ReferencesD.
Anguelov, D. Koller, P. Srinivasan, S. Thrun, H.-C.Pang, and J. Davis.
2004.
The correlated correspon-dence algorithm for unsupervised registration of non-rigid surfaces.
In Advances in Neural InformationProcessing Systems (NIPS ?04), pages 33?40.Arthur Choi and Adnan Darwiche.
2006.
A varia-tional approach for approximating bayesian networksby edge deletion.
In Proceedings of the Proceedingsof the Twenty-Second Conference Annual Conferenceon Uncertainty in Artificial Intelligence (UAI-06), Ar-lington, Virginia.
AUAI Press.Jenny Rose Finkel, Trond Grenager, and ChristopherManning.
2005.
Incorporating non-local informa-tion into information extraction systems by gibbs sam-pling.
In Proceedings of the 43rd Annual Meeting ofthe Association for Computational Linguistics (ACL?05), pages 363?370, June.R.
McDonald and F. Pereira.
2006.
Online learningof approximate dependency parsing algorithms.
InProceedings of the 11th Conference of the EuropeanChapter of the ACL (EACL ?06), pages 81?88.Ryan McDonald and Giorgio Satta.
2007.
On the com-plexity of non-projective data-driven dependency pars-ing.
In IWPT ?07: Proceedings of the 10th Inter-national Conference on Parsing Technologies, pages121?132, Morristown, NJ, USA.
Association for Com-putational Linguistics.J.
Nivre, J.
Hall, S. Kubler, R. McDonald, J. Nilsson,S.
Riedel, and D. Yuret.
2007.
The conll 2007 sharedtask on dependency parsing.
In Conference on Em-pirical Methods in Natural Language Processing andNatural Language Learning, pages 915?932.Matt Richardson and Pedro Domingos.
2006.
Markovlogic networks.
Machine Learning, 62:107?136.Sebastian Riedel and James Clarke.
2006.
Incremen-tal integer linear programming for non-projective de-pendency parsing.
In Proceedings of the Conferenceon Empirical methods in natural language processing(EMNLP ?06), pages 129?137.Sebastian Riedel.
2008.
Improving the accuracy and ef-ficiency of MAP inference for markov logic.
In Pro-ceedings of the 24th Annual Conference on Uncer-tainty in AI (UAI ?08), pages 468?475.David A. Smith and Jason Eisner.
2008.
Dependencyparsing by belief propagation.
In Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing (EMNLP), pages 145?156, Hon-olulu, October.D.
Sontag and T. Jaakkola.
2007.
New outer bounds onthe marginal polytope.
In Advances in Neural Infor-mation Processing Systems (NIPS ?07), pages 1393?1400.David Sontag, T. Meltzer, A. Globerson, T. Jaakkola, andY.
Weiss.
2008.
Tightening LP relaxations for MAPusing message passing.
In Proceedings of the 24th An-nual Conference on Uncertainty in AI (UAI ?08).Roy W. Tromble and Jason Eisner.
2006.
A fastfinite-state relaxation method for enforcing global con-straints on sequence decoding.
In Joint Human Lan-guage Technology Conference/Annual Meeting of theNorth American Chapter of the Association for Com-putational Linguistics (HLT-NAACL ?06), pages 423?430.Martin Wainwright and Michael Jordan.
2008.
Graphi-cal Models, Exponential Families, and Variational In-ference.
Now Publishers.768
