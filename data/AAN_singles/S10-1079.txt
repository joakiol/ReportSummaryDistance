Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 355?358,Uppsala, Sweden, 15-16 July 2010.c?2010 Association for Computational LinguisticsUoY: Graphs of Unambiguous Verticesfor Word Sense Induction and DisambiguationIoannis Korkontzelos, Suresh ManandharDepartment of Computer ScienceThe University of YorkHeslington, York, YO10 5NG, UK{johnkork, suresh}@cs.york.ac.ukAbstractThis paper presents an unsupervisedgraph-based method for automatic wordsense induction and disambiguation.
Theinnovative part of our method is the as-signment of either a word or a word pairto each vertex of the constructed graph.Word senses are induced by clustering theconstructed graph.
In the disambiguationstage, each induced cluster is scored ac-cording to the number of its vertices foundin the context of the target word.
Our sys-tem participated in SemEval-2010 wordsense induction and disambiguation task.1 IntroductionThere exists significant evidence that word sensedisambiguation is important for a variety of nat-ural language processing tasks: machine transla-tion, information retrieval, grammatical analysis,speech and text processing (Veronis, 2004).
How-ever, the ?fixed-list?
of senses paradigm, where thesenses of a target word is a closed list of defini-tions coming from a standard dictionary (Agirreet al, 2006), was long ago abandoned.
The rea-son is that sense lists, such as WordNet (Miller,1995), miss many senses, especially domain-specific ones (Pantel and Lin, 2002).
The miss-ing concepts are not recognised.
Moreover, sensescannot be easily related to their use in context.Word sense induction methods can be dividedinto vector-space models and graph based ones.In a vector-space model, each context of a targetword is represented as a feature vector, e.g.
fre-quency of cooccurring words (Katz and Gies-brecht, 2006).
Context vectors are clustered andthe resulting clusters represent the induced senses.Recently, graph-based methods have been em-ployed for word sense induction (Agirre andSoroa, 2007).
Typically, graph-based methodsrepresent each context word of the target word asa vertex.
Two vertices are connected via an edgeif they cooccur in one or more instances.
Oncethe cooccurrence graph has been constructed, dif-ferent graph clustering algorithms are applied topartition the graph.
Each cluster (partition) con-sists of a set of words that are semantically relatedto the particular sense (Veronis, 2004).
The poten-tial advantage of graph-based methods is that theycan combine both local and global cooccurrenceinformation (Agirre et al, 2006).Klapaftis and Manandhar (2008) presented agraph-based approach that represents pairs ofwords as vertices instead of single words.
Theyclaimed that single words might appear with morethan one senses of the target word, while they hy-pothesize that a pair of words is unambiguous.Hard-clustering the graph will potentially identifyless conflating senses of the target word.In this paper, we relax the above hypothesis be-cause in some cases a single word is unambiguous.We present a method that generates two-word ver-tices only when a single word vertex is unambigu-ous.
If the word is judged as unambiguous, then itis represented as a single-word vertex.
Otherwise,it is represented as a pair-of-words vertex.The approach of Klapaftis and Manandhar(2008) achieved good results in both evaluationsettings of the SemEval-2007 task.
A test in-stance is disambiguated towards one of the in-duced senses if one or more pairs of words rep-resenting that sense cooccur in the test instance.This creates a sparsity problem, because a cooc-currence of two words is generally less likely thanthe occurrence of a single word.
We expect our ap-proach to address the data sparsity problem with-out conflating the induced senses.2 Word Sense InductionIn this section we present our word sense in-duction and disambiguation algorithms.
Figure3551 shows an example showing how the sense in-duction algorithm works: The left side of partI shows the context nouns of four snippets con-taining the target noun ?chip?.
The most rele-vant of these nouns are represented as single wordvertices (part II).
Note that ?customer?
was notjudged to be significantly relevant.
In addition,the system introduced several vertices represent-ing pairs of nouns.
For example, note the vertex?company potato?.
The set of sentences contain-ing the context word ?company?
was judged asvery different from the set of sentences contain-ing ?company?
and ?potato?.
Thus, our systemhypothesizes that probably ?company?
and ?com-pany potato?
are relevant to different senses of?chip?, and allows them to be clustered accord-ingly.
Vertices whose content nouns or pairs ofnouns cooccur in some snippet are connected withan edge (part III and right side of part I).
Edgeweights depend upon the conditional probabilitiesof the occurrence frequencies of the vertex con-tents in a large corpus, e.g.
w2,6in part III.
Hard-clustering the graph produces the induced sensesof ?chip?
: (a) potato crisp, and (b) microchip.In the following subsections, the system is de-scribed in detail.
Figure 2 shows a block diagramoverview of the sense induction system.
It consistsof three main components: (a) corpus preprocess-ing, (b) graph construction, and (c) clustering.In a number of different stages, the system usesa reference corpus to count occurrences of wordor word pairs.
It is chosen to be large because fre-quencies of words in a large corpus are more sig-nificant statistically.
Ideally we would use the webor another large repository, but for the purposes ofthe SemEval-2010 task we used the union of allsnippets of all target words.2.1 Corpus PreprocessingCorpus preprocessing aims to capture words thatare contextually related to the target word.
Ini-tially, all snippets1that contain the target word arelemmatised and PoS tagged using the GENIA tag-ger2.
Words that occur in a stoplist are filtered out.Instead of using all words as context, only nounsare kept, since they are more discriminative thanverbs, adverbs and adjectives, that appear in a va-riety of different contexts.1We refer to instances of the target word as snippets, sincethey can be either sentences or paragraphs.2www-tsujii.is.s.u-tokyo.ac.jp/GENIA/taggerFigure 1: An example showing how the proposedword sense induction system works.Nouns that occur infrequently in the referencecorpus are removed (parameter P1).
Then, log-likelihood ratio (LL) (Dunning, 1993) is em-ployed to compare the distribution of each nounto its distribution in reference corpus.
The nullhypothesis is that the two distributions are simi-lar.
If this is true, LL is small value and the cor-responding noun is removed (parameter P2).
Wealso filter out nouns that are more indicative in thereference corpus than in the target word corpus;i.e.
the nouns whose relative frequency in the for-mer is larger than in the latter.
At the end of thisstage, each snippet is a list of lemmatised nounscontextually related to the target word.2.2 Constructing the GraphAll nouns appearing in the list of the previousstage output are represented as graph vertices.Moreover, some vertices representing pairs ofnouns are added.
Each noun within a snippet iscombined with every other, generating(n2)pairs.Log-likelihood filtering with respect to the refer-ence corpus is used to filter out unimportant pairs.Thereafter, we aim to keep only pairs that mightrefer to a different sense of the target word thantheir component nouns.
For each pair we constructa vector containing the snippet IDs in which theyoccur.
Similarly we construct a vector for eachcomponent noun.
We discard a pair if its vector isvery similar to both the vectors of its componentnouns, otherwise we represent it as a vertex pair.Dice coefficient was used as a similarity measureand parameter P4as threshold value.Edges are drawn based on cooccurrence of thecorresponding vertices contents in one or moresnippets.
Edges whose respective vertices con-tents are infrequent are rejected.
The weight ap-356Figure 2: A: Block diagram presenting the system overview.
B, C, D: Block diagrams further analysingthe structure of complex components of A. Parameter names appear within square brackets.plied to each edge is the maximum of the condi-tional probabilities of the corresponding verticescontents (e.g.
w2,6, part III, figure 1).
Low weightedges are filtered out (parameter P3).2.3 Clustering the GraphChinese Whispers (CW) (Biemann, 2006) wasused to cluster the graph.
CW is a randomisedgraph-clustering algorithm, time-linear to thenumber of edges.
The number of clusters it pro-duces is automatically inferred.
Evaluation hasshown that CW suits well in sense induction appli-cations, where class distributions are often highlyskewed.
In our experiments, CW produced lessclusters using a constant mutation rate (5%).To further reduce the number of induced clus-ters, we applied a post-processing stage, whichexploits the one sense per collocation property(Yarowsky, 1995).
For each cluster li, we gener-ated the set Siof all snippets that contain at leastone vertex content of li.
Then, any clusters laandlbwere merged if Sa?
Sbor Sa?
Sb.3 Word Sense DisambiguationThe induced senses are used to sense-tag each testinstance of the target word (snippet).
Given a snip-pet, each induced cluster is assigned a score equalto the number of its vertex contents (single or pairsof words) occurring in the snippet.
The instance isassigned to the sense with the highest score or withequal weights to all highest scoring senses.4 Tuning parameter and inducing sensesThe algorithm depends upon 4 parameters: P1thresholds frequencies and P3collocation weights.P2is the LL threshold and P4the similarity thresh-old for discarding pair-of-nouns vertices.We chose P1?
{5, 10, 15}, P2?
{2, 3, 4, 5, 10, 15, 25, 35}, P3?
{0.2, 0.3, 0.4}and P4?
{0.2, 0.4, 0.6, 0.8}.
The parameter tun-ing was done using the trial data of the SemEval-2010 task and on the noun data of correspond-ing SemEval-2007 task.
Parameters were tunedby choosing the maximum supervised recall.
Forboth data sets, the chosen parameter values wereP1?
10, P3?
0.4 and P4?
0.8.
Due to thesize difference of the datasets, for the Semeval-2010 trial data P2?
3, while for the SemEval-2007 noun data P2?
10.
The latter was adoptedbecause the size of training data was announced tobe large.
We induced senses on the training dataand then disambiguated the test data instances.5 Evaluation resultsThree different measures, V-Measure, F-Score,and supervised recall on word sense disambigua-tion task, were used for evaluation.
V-Measureand F-Score are unsupervised.
Supervised recallwas measured on two different data splits.
Table 1shows the performance of our system, UoY, for allmeasures and in comparison with the best, worstand average performing system and the randomand most frequent sense (MFS) baselines.
Resultsare shown for all words, and nouns and verbs only.357System V-Msr F-Sc S-R80S-R60AllUoY 15.70 49.76 62.44 61.96Best 16.20 63.31 62.44 61.96Worst 0.00 16.10 18.72 18.91Average 6.36 48.72 54.95 54.27MFS 0.00 63.40 58.67 58.25Random 4.40 31.92 57.25 56.52NounsUoY 20.60 38.23 59.43 58.62Best 20.60 57.10 59.43 58.62Average 7.08 44.42 47.85 46.90Worst 0.00 15.80 1.55 1.52MFS 0.00 57.00 53.22 52.45Random 4.20 30.40 51.45 50.21VerbsUoY 8.50 66.55 66.82 66.82Best 15.60 72.40 69.06 68.59Average 5.95 54.23 65.25 65.00Worst 0.10 16.40 43.76 44.23MFS 0.00 72.70 66.63 66.70Random 4.64 34.10 65.69 65.73Table 1: Summary of results (%).
V-Msr: V-Measure, F-Sc: F-Score, S-RX: Supervised recallunder data split: X% training, (100-X)% testTable 2 shows the ranks of UoY for all evalu-ation categories.
Our system was generally veryhighly ranked.
It outperformed the random base-line in all cases and the MFS baseline in measuresbut F-Score.
No participant system managed toachive higher F-Score than the MFS baseline.The main disadvantage of the system seems tobe the large number of induced senses.
The rea-sons are data sparcity and tuning on nouns, thatmight have led to parameters that induce moresenses.
However, the system performs best amongsystems that produce comparable numbers of clus-ters.
Table 3 shows the number of senses of UoYand the gold-standard.
UoY produces significantlymore senses than the gold-standard, especially fornouns, while for verbs figures are similar.The system achieves low F-Scores, because thismeasure favours fewer induced senses.
Moreover,we observe that most scores are lower for verbsthan nouns.
This is probably because parametersare tuned on nouns and because in general nounsappear with more senses than verbs, allowing oursystem to adapt better.
As an overall conclusion,each evaluation measure is more or less biased to-wards small or large numbers of induced senses.6 ConclusionWe presented a graph-based approach for wordsense induction and disambiguation.
Our ap-proach represents as a graph vertex an unambigu-ous unit: (a) a single word, if it is judged as unam-biguous, or (b) a pair of words, otherwise.
Graphedges model the cooccurrences of the content ofV-Msr F-Sc S-R80S-R60All 2 15 1 1Nouns|Verbs 1|3 18|6 1|16 1|15Table 2: Ranks of UoY (out of 26 systems)All Nouns VerbsGold-standard 3.79 4.46 3.12UoY 11.54 17.32 5.76Table 3: Number of sensesthe vertices that they join.
Hard-clustering thegraph induces a set of senses.
To disambiguatea test instance, we assign it to the induced sensewhose vertices contents occur mostly in the in-stance.
Results show that our system achieves veryhigh recall and V-measure performance, higherthan both baselines.
It achieves low F-Scores dueto the large number of induced senses.ReferencesE.
Agirre and A. Soroa.
2007.
Semeval-2007 task 02:Evaluating word sense induction and discriminationsystems.
In proceedings of SemEval-2007, CzechRepublic.
ACL.E.
Agirre, D. Martinez, O. Lopez de Lacalle, andA.
Soroa.
2006.
Two graph-based algorithms forstate-of-the-art wsd.
In proceedings of EMNLP,Sydney, Australia.
ACL.C.
Biemann.
2006.
Chinese whispers - an efficientgraph clustering algorithm and its application to nat-ural language processing problems.
In proceedingsof TextGraphs, New York City.
ACL.T.
Dunning.
1993.
Accurate methods for the statisticsof surprise and coincidence.
Computational Lin-guistics, 19(1):61?74.G.
Katz and E. Giesbrecht.
2006.
Automatic identifi-cation of non-compositional multi-word expressionsusing latent semantic analysis.
In proceedings of theACL workshop on Multi-Word Expressions, Sydney,Australia.
ACL.I.
Klapaftis and S. Manandhar.
2008.
Word sense in-duction using graphs of collocations.
In proceedingsof ECAI-2008, Patras, Greece.G.
Miller.
1995.
Wordnet: a lexical database for en-glish.
Communications of the ACM, 38(11):39?41.P.
Pantel and D. Lin.
2002.
Discovering word sensesfrom text.
In proceedings of KDD-2002, New York,NY, USA.
ACM Press.J.
Veronis.
2004.
Hyperlex: lexical cartography for in-formation retrieval.
Computer Speech & Language,18(3):223?252, July.D.
Yarowsky.
1995.
Unsupervised word sense disam-biguation rivaling supervised methods.
In proceed-ings of ACL, Cambridge, MA, USA.
ACL.358
